{"article_publication_date": "01-01-2004", "fulltext": "\n Separation and Information Hiding Peter W. O Hearn Hongseok Yang John C. Reynolds Queen Mary Seoul \nNational Carnegie Mellon University of London University University Abstract We investigate proof rules \nfor information hiding, using the recent formalism of separation logic. In essence, we use the separating \nconjunction to partition the internal resources of a module from those accessed by the module s clients. \nThe use of a logical con\u00adnective gives rise to a form of dynamic partitioning, where we track the transfer \nof ownership of portions of heap storage between pro\u00adgram components. It also enables us to enforce separation \nin the presence of mutable data structures with embedded addresses that may be aliased. Categories and \nSubject Descriptors: D.2.4 [Software Engineer\u00ading]: Program Veri.cation class invariants; D.3.3 [Programming \nLanguages]: Language Constructs and Features modules, pack\u00adages General Terms: Languages, Theory, Veri.cation \nKeywords: Separation Logic, Modularity, Resource Protection 1 Introduction Modularity is a key concept \nwhich programmers wield in their struggle against the complexity of software systems. When a pro\u00adgram \nis divided into conceptually distinct modules or components, each of which owns separate internal resources \n(such as storage), the effort required for understanding the program is decomposed into circumscribed, \nhopefully manageable, parts. And, if separa\u00adtion is correctly maintained, we can regard the internal \nresources of one module as hidden from its clients, which results in a narrowing of interface between \nprogram components. The .ipside, of course, is that an ostensibly modular program organization is undermined \nwhen internal resources are accessed from outside a module. It stands to reason that, when specifying \nand reasoning about pro\u00adgrams, if we can keep track of the separation of resources between Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 04, January \n14 16, 2004, Venice, Italy. Copyright 2004 ACM 1-58113-729-X/04/0001 ...$5.00 program components, then \nthe resultant decomposition of the spec\u00adi.cation and reasoning tasks should confer similar bene.ts. Un\u00adfortunately, \nmost methods for specifying programs either severely restrict the programming model, by ruling out common \nprogram\u00adming features (so as to make the static enforcement of separation feasible), or they expose the \ninternal resources of a module in its speci.cation in order to preserve soundness. Stated more plainly, \ninformation hiding should be the bedrock of modular reasoning, but it is dif.cult to support soundly, \nand this presents a great challenge for research in program logic. To see why information hiding in speci.cations \nis desirable, sup\u00adpose a program makes use of n different modules. It would be un\u00adfortunate if we had \nto thread descriptions of the internal resources of each module through steps when reasoning about the \nprogram. Even worse than the proof burden would be the additional anno\u00adtation burden, if we had to complicate \nspeci.cations of user pro\u00adcedures by including descriptions of the internal resources of all modules \nthat might be accessed. A change to a module s internal representation would necessitate altering the \nspeci.cations of all other procedures that use it. The resulting breakdown of modularity would doom any \naspiration to scalable speci.cation and reasoning. Mutable data structures with embedded addresses (pointers) \nhave proven to be a particularly obstinate obstacle to modularity. The problem is that it is dif.cult \nto keep track of aliases, different copies of the same address, and so it is dif.cult to know when there \nare no pointers into the internals of a module. The purpose of this paper is to investigate proof rules \nfor information hiding using separation logic, a recent formalism for reasoning about mutable data struc\u00adtures \n[36]. Our treatment draws on work of Hoare on proof rules for data abstraction and for shared-variable \nconcurrency [16, 17, 18]. In Hoare s approach each distinct module has an associated resource invariant, \nwhich describes its internal state, and scoping constraints are used to separate the resources of a module \nfrom those of client programs. We retain the resource invariants, and add a logical con\u00adnective, the \nseparating conjunction *, to provide a more .exible form of separation. We begin in the next section \nby describing the memory model and the logic of pre-and post-conditions used in this work. We then describe \nour proof rules for information hiding, followed by two examples, one a simple memory manager module \nand the other a queue module. Both examples involve the phenomenon of resource ownership transfer, where \nthe right to access a data structure trans\u00adfers between a module and its clients. We work through proofs, \nand failed proofs, of client code as a way to illustrate the consequences of the proof rules. After giving \nthe positive examples we present a counterexample, which shows that our principal new proof rule, the \nhypothetical frame rule, is incompatible with the usual Hoare logic rule for con\u00adjunction; the new rule \nis thus unsound in models where commands denote relations, which validate conjunction. The problem is \nthat the very features that allow us to treat ownership transfer lead to a subtle understanding where \nOwnership is in the eye of the As\u00adserter . The remainder of the paper is occupied with a semantic analysis. \nThis revolves around a notion of precise predicates, which are ones that unambiguously identify a portion \nof state. In essence, we ask the Asserter to be unambiguous when specifying which resource is owned; \nwhen this is the case, we .nd that our proof rules are sound. Familiarity with the basics of separation \nlogic, as presented in [36], would be helpful in reading the paper. We remind the reader in par\u00adticular \nthat the rules for disposing or dereferencing an address are such that it must be known to point to something \n(not be dangling) in the precondition for a rule to apply. For example, in the putative triple {true}[x] \n:= 7{???}, where the contents of heap address x is mutated to 7, there is no assertion we can use in \nthe postcondition to get a valid triple, because x might be dangling in a state satisfy\u00ading the precondition. \nSo, in order to obtain any postcondition for [x] := 7, the precondition must imply the assertion x *true \nthat . x is not dangling. The local way of thinking encouraged by separation logic [26] is stretched \nby the approach to information hiding described here. We have found it useful to use a .gurative language \nof rights when thinking about speci.cations, where a predicate p at a program point asserts that I have \nthe right to dereference the addresses in p here . 1.1 Contextual Remarks The link between modularity \nand information hiding was developed in papers of Hoare and Parnas in the early 1970s [16, 17, 28, 29]. \nParnas emphasized that poor information distribution amongst components could lead to almost invisible \nconnections between supposedly independent modules , and proposed that information hiding was a way to \ncombat this problem. Hoare suggested using scoping restrictions to hide a particular kind of information, \nthe in\u00adternal state of a module, and showed how these restrictions could be used in concert with invariants \nto support proof rules that did not need to reveal the internal data of a module or component. These \nideas in.uenced many subsequent language constructs and speci.\u00adcation notations. Most formal approaches \nto information hiding work by assuming a .xed, a priori, partitioning between program components, usu\u00adally \nexpressed using scoping restrictions, or typing, or simply using cartesian product of state spaces. In \nsimple cases .xed partition\u00ading can be used to protect internal resources from outside tamper\u00ading. But \nin less simple situations, such as when data is referred to indirectly via addresses, or when resources \ndynamically transfer between program components, correct separation is more dif.cult to maintain. Such \nsituations are especially common in low-level systems programs whose purpose is to provide .exible, shared \nac\u00adcess to system resources. They are also common in object-oriented programs. An unhappy consequence \nis that modular speci.cation methods are lacking for widely-used imperative or object-oriented programming \nlanguages, or even for many of the programming pat\u00adterns commonly expressed in them. The essential point \nis that .xed partitioning does not cope naturally with systems whose resource ownership or interconnection \nstruc\u00adture is changing over time. A good example is a resource manage\u00adment module, that provides primitives \nfor allocating and deallocat\u00ading resources, which are held in a local free list. A client program should \nnot alter the free list, except through the provided primi\u00adtives; for example, the client should not \ntie a cycle in the free list. In short, the free list is owned by the manager, and it is (intuitively) \nhidden from client programs. However, it is entirely possible for a client program to hold an alias to \nan element of the free list, after a deallocation operation is performed; intuitively, the ownership \nof a resource transfers from client to module on disposal, even if many aliases to the resource continue \nto be held by the client code. In a language that supports address arithmetic the potential dif.culties \nare compounded: the client might intentionally or unintentionally obtain an address used in an internal \nrepresentation, just by an arith\u00admetic calculation. A word of warning on our use of module before we \ncontinue: The concept of module we use is just a grouping of procedures that share some private state. \nThe sense of private will not be determined statically, but will be the subject of speci.cations and \nproof rules. This allows us to approach modules where correct protection of module internals would be \nimpossible to determine with a compile\u00adtime check in current programming languages. The approach in this \npaper might conceivably be used to analyze the information hiding in a language that provides an explicit \nmodule notation, but that is not our purpose here. The point is that it is possible to program modules, \nin the sense of the word used by Parnas, whether or not one has a speci.c module construct at one s disposal. \nFor example, the pair of malloc() and free() in C, together with their shared free list, might be considered \nas a module, even though their correct usage is not guaranteed by C s compile-time checking. Indeed, \nthere is no existing program\u00adming language that correctly enforces information hiding of mu\u00adtable data \nstructures, largely because of the dynamic partitioning issue mentioned above, and this is an area where \nlogical speci.ca\u00adtions are needed. We emphasize that the issue is not one of safe versus unsafe programming \nlanguages; for instance, middleware programs written in garbage-collected, safe languages, often per\u00adform \nexplicit management of certain resources, and there also own\u00adership transfer is essential to information \nhiding. Similarly, although we do not consider the features of a full-blown object-oriented language, \nour techniques, and certainly our prob\u00adlems, seem to be relevant. Theories of objects have been developed \nthat account for hiding in a purely functional context (e.g., [30]), but mutable structures with embedded \naddresses, or object id s, are fun\u00addamental to object-oriented programming. A thoroughgoing theory should \naccount for them directly, confronting the problems caused when there are potential aliases to the state \nused within an object. These contextual remarks do not take into account some recent work that attempts \nto address the limitations of .xed partitioning and the dif.culties of treating mutable data structures \nwith embed\u00added addresses. We will say more on some of the closely related work at the end of the paper. \n 2 The Storage Model We consider a model where a heap is a .nite partial function taking addresses to \nvalues: H def = Addresses -.n Values This set has a partial commutative monoid structure, where the unit \nis the empty function and the partial combining operation *: H\u00d7H -H is the union of partial functions \nwith disjoint domains. More formally, we say that h1#h2 holds for heaps h1 and h2 when dom(h1)ndom(h2)={}. \nIn that case, h1 *h2 denotes the com\u00adbined heap h1 .h2. When h1#h2 fails, h1 *h2 is unde.ned. In particular, \nnote that if h =h1 *h2 then we must have that h1#h2. The subheap order =is subset inclusion of partial \nfunctions. We will work with a RAM model, where the addresses are natural numbers and the values are \nintegers def def Addresses = {0,1,2,...} Values = {...,-1,0,1,...} The results of this paper go through \nfor other choices for Addresses and Values, and thus cover a number of other naturally occurring models, \nsuch as the cons cell model of [36] and the hierarchical memory model of [1]. Our results also apply \nto traditional Hoare logic, where there is no heap, by taking the trivial model where Addresses is empty \n(and Values non-empty). A natural model of separation that is not an instance of the par\u00adtial functions \nmodel construction above is the trees with dangling pointers model of [6]; it would be interesting to \naxiomatize the es\u00adsentials of these separation models, by identifying a subclass of the partial monoid \nmodels of [32]. To interpret variables in the programming language and logic, the state has an additional \ncomponent, the stack , which is a mapping from variables to values; a state is then a pair consisting \nof a stack and a heap: S def def = Variables .Values States = S\u00d7H. We treat predicates semantically in \nthis paper, so a predicate is just a set of states. def Predicates = P (States) The powerset of states \nhas the usual boolean algebra structure, where .is intersection, .is union, \u00acis complement, true is the \nset of all states, and false is the empty set of states. We use p,q, r, sometimes with subscripts and \nsuperscripts, to range over predi\u00adcates. Besides the boolean connectives, we will need the lifting of \n*from heaps to predicates: def p*q = {(s,h)|.h0,h1.h=h0 *h1,and (s,h0). p,and (s,h1).q}. As a function \non predicates we have a total map * from Predicates \u00d7Predicates to Predicates which, to the right of \ndef, =uses the partial map, *: H\u00d7H-H in its de.nition. This overload\u00ading of *will always be disambiguated \nby context. *has a unit emp, the set {(s,[])|s . S} of states whose heap component is empty. It also \nhas an implication adjoint -*, though that will play no role in the present paper. Note that emp is distinct \nfrom the empty set false of states. We use x .E to denote a predicate that consists of all pairs (s,h) \nwhere h is a singleton in which x points to the meaning of E: h(s(x))=[[E]]s. The points-to relation \nx.E,F for binary cons cells is syntactic sugar for (x .E)*(x+1.F). We will also use quanti.ers and recursive \nde.nitions in examples in what should be a clear way. The syntax for the programming language considered \nin this paper is given by the following grammar. E ::= x,y,... |0 |1 |E+E |E\u00d7E |E-E B ::= false |B.B|E \n=E |E < E C ::= x:=E |x:=[E]|[E]:=E |x:=cons(E,...,E) | dispose(E)|skip |C;C|if Bthen Celse C | while \nBC|letrec k=C,...,k=Cin C|k For simplicity we consider parameterless procedures only. The ex\u00adtension \nto all .rst-order procedures raises no new dif.culties, but lengthens the presentation. Higher-order \nfeatures, on the other hand, are not straightforward. We assume that all the procedure identi.ers are \ndistinct in any letrec declaration. When proce\u00addure declarations do not have recursive calls, we write \nlet k1 = C1,...,kn =Cn in C to indicate this. The command x:=cons(E1,...,En)allocates nconsecutive cells, \ninitializes them with the values of E1,...,En, and stores the address of the .rst cell in x. We could \nalso consider a command for variable\u00adlength allocation. The contents of an address E can be read and \nstored in x by x:=[E], or can be modi.ed by [E]:=F. The com\u00admand dispose(E)deallocates the address E.In \nx:=[E], [E]:=F and dispose(E), the expression E can be an arbitrary arithmetic expression; so, this language \nallows address arithmetic. This inclusion of address arithmetic does not represent a general commitment \nto it on our part, but rather underlines the point that our methods do not rely on ruling it out. In \nexamples it is often clearer to use a .eld-selection notation rather than arithmetic, and for this we \nuse the following syntactic sugar: E.i:=F def =[E+i-1]:=Fx:=E.idef =x:=[E+i-1]. Each command denotes \na (nondeterministic) state transformer that faults when heap storage is accessed illegally, and each \nexpression determines a (heap independent) function from stacks to values. The semantics will be given \nin Section 7. 3 Proof System The form of judgment we use is the sequent Gf{p}C{q} which states that \ncommand Csatis.es its Hoare triple, under certain hypotheses. Hypotheses are given by the grammar G ::= \ne |{p}k{q}[X],G subject to the constraint that no procedure identi.er kappears twice. An assumption {p}k{q}[X] \nrequires k to denote a command that modi.es only the variables appearing in set X and that satis.es the \nindicated triple. 3.1 Proof Rules for Information Hiding We begin with a special-case, programmer-friendly, \nproof rule, that is a consequence of a more fundamental, logician-friendly, rule to be described later. \nModular Non-Recursive Procedure Declaration Rule G f{p1 *r}C1{q1 *r}. . . G f{pn *r}Cn{qn *r} G,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] \nf{p}C{q} G f{p *r}let k1 = C1,...,kn = Cn in C{q *r} In this rule k1,...kn is a grouping of procedures \nthat share private state described by resource invariant r. In a resource management module, the ki would \nbe operations for allocating and freeing re\u00adsources, and r would describe unallocated resources (perhaps \nheld in a free list). The rule distinguishes two views of such a module. When reasoning about the client \ncode C, we ignore the invariant and its area of storage; reasoning is done in the context of interface \nspeci.cations {pi}ki{qi}that do not mention r. The perspective is different from inside the module; the \nimplementations Ci operate on a larger state than that presented to the client, and veri.cations are \nperformed in the presence of the resource invariant. The two views, module and client, are tied up in \nthe conclusion of the rule. The modular procedure rule is subject to variable conditions: we require \na set Y (of private variables), and the conditions are C does not modify variables in r, except through \nusing k1,...,kn;  Y is disjoint from p, q, C and the context G,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] ; \n Ci only modi.es variables in Xi,Y .  The idea behind these conditions is that we must be sure that \nclient code does not alter variables used within a module, but we must also allow some overlap in variables \nto treat various examples. A rigorous formulation of what these conditions mean has been placed in an \nappendix at the end of the paper. We will continue to state the necessary side conditions as we present \nour proof rules, but there will be little harm if the reader skates over them, or understands them in \nan intuitive way, while reading the paper. We only stress that the modi.es clauses refer exclusively \nto the stack, where the new part of the paper involves the heap, and *. It is also possible to consider \ninitialization and .nalization code. For instance, if, in addition to the premises of the modular proce\u00addure \nrule, we have G f{p}init{p *r}and G f{q *r}.nal{q}, then we can obtain G f{p}init;(let k1 = C1,...,kn \n= Cn in C); .nal {q}. In our examples we will not consider initialization or .nalization since they present \nno special logical dif.culties. In the modular procedure rule, the proof of {p}C{q} about the client \nin the premises can be used with any resource invariant r.As a result, this reasoning does not need to \nbe repeated when a module representation is altered, as long as the alteration continues to sat\u00adisfy \nthe interface speci.cations {pi}ki{qi}. This addresses one of the points about reasoning that survives \nlocal changes discussed in the Introduction. However, the choice of invariant r is not speci.ed by programming \nlanguage syntax let k1 = C1,...,kn = Cn in C in the modular pro\u00adcedure rule. In this it is similar to \nthe usual partial correctness rule for while loops, which depends on the choice of a loop invariant. \nIt will be convenient to consider an annotation notation that spec\u00adi.es the invariant, and the interface \nspeci.cations {pi}ki{qi},asa directive on how to apply the modular procedure rule; this is by Interface \nSpeci.cations {p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] Resource Invariant: r Private Variables: Y Internal Implementations \nC1,...,Cn Table 1. Module Speci.cation Format analogy with the use of loop invariant annotations as directives \nto a veri.cation condition generator. We will use the format for module speci.cations in Table 1. This \ninstructs us to apply the modular procedure rule in a particular way, to prove G,Interface Speci.cations \nf{p}C{q} for client code C, and to prove G f{pi *r}Ci{qi *r}for the bodies. We emphasize that this module \nformat is not of.cially part of our programming language or even our logic; however, its role as a directive \non how to apply the modular procedure rule in examples will, we hope, be clear. The modular procedure \nrule can be derived from a standard rule for parameterless procedure declarations, and the following \nmore basic rule. Hypothetical Frame Rule G,{pi}ki{qi}[Xi](for i=n) f{p}C{q} G,{pi *r}ki{qi *r}[Xi,Y ](for \ni=n) f{p *r}C{q *r} where C does not modify variables in r, except through using k1,...,kn; and  Y \nis disjoint from p, q, C, and the context G,{p1}k{q1}[X1],...,{pn}k{qn}[Xn] .  The notation {pi}ki{qi}[X1](for \ni=n) in the rule is a shorthand for {p1}k1{q1}[X1],...,{pn}kn{qn}[Xn], and similarly for {pi * r}ki{qi \n*r}[X1,Y ](for i=n). In examples we will use the modular procedure rule, but will phrase our theoretical \nresults in terms of the hypothetical frame rule. The hypothetical frame rule is so named because of its \nrelation to the ordinary frame rule from [20, 26]. The hypothetical rule allows us to place invariants \non the hypotheses as well as the conclusion of sequents, whereas the ordinary rule includes invariants \non the conclusion alone. (The ordinary frame rule is thus a special case of the hypothetical rule, where \nn = 0.) 3.2 Other Proof Rules We have standard Hoare logic rules for various constructs, along with \nthe rule of consequence. p .pG f{p'}C{q'} q'.q G,{p}k{q}[X] f{p}k{q} G f{p}C{q} G f{p .B}C{p} G f{p}C1{q} \nG f{q}C2{r} G f{p}while BC{p .\u00acB} G f{p}C1;C2{r} G f{p .B}C {q} G f{p .\u00acB}C'{q} G f{p}if Bthen C else \nC'{q} In addition, we allow for the context G to be permuted. The rule for possibly recursive procedure \ndeclarations uses the pro\u00adcedure speci.cations in proofs of the bodies: G,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] \nf{p1}C1{q1}. . . G,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] f{pn}Cn{qn} G,{p1}k1{q1}[X1],...,{pn}kn{qn}[Xn] \nf{p}C{q} G f{p}letrec k1 = C1,...,kn = Cn in C{q} where Ci only modi.es variables in Xi. In case none \nof the ki are free in the Cj we can get a simpler rule, where the {pi}ki{qi}[Xi] hypotheses are omitted \nfrom the sequents for the Cj. Using let rather than letrec to indicate the case where a procedure declaration \nhappens to have no recursive instances, we can derive the modular non-recursive procedure declaration \nrule of the previous section from the hypothetical frame rule and the stan\u00addard procedure rule just given. \nWe can also derive a modular rule for recursive declarations. The ordinary frame rule is G f{p}C{q} G \nf{p *r}C{q *r} where C does not modify any variables in r. This is a special case of the hypothetical \nrule, but we state it sep\u00adarately because the ordinary rule will be used without restriction, while we \nwill place restrictions on the hypothetical rule. One rule of Hoare logic, which is sometimes not included \nexplicitly in proof systems, is the conjunction rule. G f{p}C{q} G f{p'}C{q'} G f{p .p'}C{q .q'} The \nconjunction rule is often excluded because it is an example of an admissible rule: one can (usually) \nprove a metatheorem, which says that if the premises are derivable then so is the conclusion. However, \nit is not an example of a derived rule: one cannot con\u00adstruct a generic derivation, in the logic, of \nthe conclusion from the premises. We will see in Section 6 that the hypothetical frame rule can affect \nthe admissible status of the conjunction rule. Finally, we have axioms for the basic commands, where \nx,m,n are assumed to be distinct variables. G f{E . }[E] := F {E .F} G f{E . }dispose(E){emp} x =m G \nfx := cons(E1,...,Ek){x .E1[m/x],...,Ek[m/x]} .emp G f{x = n .emp}x := E {x =(E[n/x]) .emp} G f{E .n \n.x = m}x :=[E] {x = n .E[m/x] .n} These axioms describe the effect of each command on only one, or sometimes \nno, heap cells. Typically, their effects can be extended using the frame rule: for example, we can infer \n{(x .3) *(y . 4)}[x] := 7{(x .7) *(y .4)}by choosing y .4 as the invariant in the frame rule. Interface \nSpeci.cations {emp}alloc{x . , }[x] {x . , }free{emp}[] Resource Invariant: list( f ) Private Variables: \nf Internal Implementations if f = nil then x := cons( , ) (code for alloc) else x := f ; f := x.2; x.2:= \nf ; f := x; (code for free) Table 2. Memory Manager Module  4 A Memory Manager We consider an extended \nexample, of an idealized memory manager that doles out memory in chunks of size two. The speci.cations \nand code are given in Table 2. The internal representation of the manager maintains a free list, which \nis a singly-linked list of binary cons cells. The free list is pointed to by f , and the predicate list( \nf ) is the representation in\u00advariant, where def list( f ) ..( f = nil .emp) .(.g. f . ,g *list(g)) This \npredicate says that f points to a linked list (and that there are no other cells in storage), but it \ndoes not say what elements are in the head components. For the implementation of alloc, the manager places \ninto x the address of the .rst element of the free list, if the list is nonempty. In case the list is \nempty the manager calls the built-in allocator cons to get an extra element. The interaction between \nalloc and cons is a microscopic idealization of the treatment of malloc in Section 8.7 of [22]. There, \nmalloc manages a free list but, occasionally, it calls a system routine sbrk to request additional memory. \nBesides .xed versus variable sized allocation, the main difference is that we assume that cons always \nsucceeds, while sbrkmight fail (return an error code) if there is no extra memory to be given to malloc.We \nuse this simple manager because to use a more complex one would not add anything to the points made in \nthis section. When a user program gives a cell back to the memory manager it is put on the front of the \nfree list; there is no need for interaction with a system routine here. The form of the interface speci.cations \nare examples of the local way of thinking encouraged by separation logic; they refer to small pieces \nof storage. It is important to appreciate the interaction be\u00adtween local and more global perspectives \nin these assertions. For example, in the implementation of free in Table 2 the variable x contains the \nsame address after the operation completes as it did before, and the address continues to be in the domain \nof the global program heap. The use of emp in the postcondition of free does not mean that the global \nheap is now empty, but rather it implies that the knowledge that x points to something is given up in \nthe postcondition. We say intuitively that free transfers ownership to the manager, where ownership confers \nthe right to dereference. It is interesting to see how transfer works logically, by considering a proof \noutline for the implementation of free. {list( f ) * (x . , )} x.2:= f ; {list( f ) * (x . , f )} {list(x)} \nf := x; {list( f )} {list( f ) * emp} The most important step is the middle application of the rule of \ncon\u00adsequence. At that point we still have the original resource invariant list( f ) and the knowledge \nthat x points to something, separately. But since the second .eld of what x points to holds f , we can \nob\u00adtain list(x) as a consequence. It is at this point in the proof that the original free list and the \nadditional element x are bundled together; the .nal statement simply lets f refer to this bundled information. \nA similar point can be made about how alloc effects a transfer from the module to the client. We now \ngive several examples from the client perspective. Each proof, or attempted proof, is done in the context \nof the interface speci.cations of alloc and free. The .rst example is for inserting an element into the \nmiddle of a linked list. {(y .a, z) * (z .c,w)} alloc; {(y .a, z) * (z .c,w) * (x . , )} {(y .a, z) * \n(x . , ) *(z .c, w)} x.2:= z; x.1:= b;y.2:= x {(y .a, x) * (x .b,z) *(z .c,w)} Here, in the step for \nalloc we use the interface speci.cation, to\u00adgether with the ordinary frame rule. If we did not have the \nmodular procedure rule we could still ver\u00adify this code, by threading the free list through and changing \nthe interface speci.cation. That is, the interface speci.cations would become {list( f )}alloc{list( \nf ) * x . , } {list( f ) * x . }free{list( f )} thus exposing the free list, and the proof would be {(y \n.a, z) * (z .c,w) * list( f )} alloc; {(y .a, z) * (z .c,w) * (x . , ) *list( f )} {(y .a, z) * (x . \n, ) *(z .c, w) * list( f )} x.2:= z; x.1:= b;y.2:= x {(y .a, x) * (x .b,z) *(z .c,w) *list( f )}. Although \ntechnically correct, this inclusion of the free list in the proof of the client is an example of the \nbreakdown of modularity described in the Introduction. One might wonder whether this hiding of invariants \ncould be viewed as a simple matter of syntactic sugar, instead of being the subject of a proof rule. \nWe return to this point in Section 6. We can similarly reason about deletion from the middle of a linked \nlist, but it is more interesting to attempt to delete wrongly. {(y .a, x) * (x .b,z) *(z .c,w)} free; \n{(y .a, x) * (z .c,w)} y := x.2; {???} This veri.cation cannot be completed, because after doing the \nfree operation the client has given up the right to dereference x. This is a very simple example of the \nrelation between ownership transfer and aliasing; after the free operation x and f are aliases in the \nglobal state, and the incorrect use of the alias by the client has been rightly precluded by the proof \nrules. (A more positive example of aliasing, which incidentally would not be amenable to unique-reference \ndisciplines, would be a program to dispose nodes in a graph.) Similarly, suppose the client tried to \ncorrupt the manager, by sneak\u00adily tying a cycle in the free list. {emp}alloc; free; x.2 := x {???} Once \nagain, there is no assertion we can .nd to .ll in the ???, be\u00adcause after the free statement the client \nhas given up the right to dereference x (emp will hold at this program point). And, this pro\u00adtection \nhas nothing to do with the fact that knotting the free list con\u00adtradicts the resource invariant. For, \nsuppose the statement x.2:= x was replaced by x.1:= x. Then the .nal assignment in this sequence would \nnot contradict the resource invariant, when viewed from the perspective of the system s global state, \nbecause the list( f ) pred\u00adicate is relaxed about what values are in head components. How\u00adever, from \nthe point of view of the interface speci.cations, the client has given up the right to dereference even \nthe .rst component of x. Thus, separation prevents the client from accessing the internal storage of \nthe module in any way whatsoever. Finally, it is worth emphasizing that this use of * to enforce separa\u00adtion \nprovides protection even in the presence of address arithmetic which, if used wrongly, can wreak havoc \nwith data abstractions. Suppose the client tries to access some memory address, which might or might \nnot be in the free list, using [42] := 7. Then, for this statement to get past the proof rules, the client \nmust have the right to dereference 42, and therefore 42 cannot be in the free list (by separation). That \nis, we have two cases {42 . * p}[42] := 7; alloc {42 .7 * p *x . , } and {p}[42] := 7; {???}alloc {???} \nwhere p does not imply that 42 is in the domain of its heap. In the .rst case the client has used address \narithmetic correctly, and the 42 . in the precondition ensures that 42 is not one of the cells in the \nfree list. In the second case the client uses address arithmetic potentially incorrectly, and the code \nmight indeed corrupt the free list, but the code is (in the .rst step) blocked by the proof rules. 5 \nThe Eye of the Asserter In Table 3 we give a queue module. In the speci.cation we use a predicate listseg(x,a,y) \nwhich says that there is an acyclic linked list from x to y has the sequence a in its head components. \nThe vari\u00adable Q denotes the sequence of values currently held in the queue; it is present in the resource \ninvariant, as well as in the interface spec\u00adi.cations. (Technically, we would have to ensure that the \nvariable Q was added to the s component of our semantics.) This exposing of abstract variables is standard \nin module speci.cations, as is the inclusion of assignment statements involving abstract variables Interface \nSpeci.cations {Q =a .z =n .P(z)}enq{Q =a\u00b7(n).emp}[Q] {Q =(m)\u00b7a .emp}deq{Q =a .z =m .P(z)}[Q,z] {emp}isempty?{(w \n=(Q =e)).emp}[w] Resource Invariant: listseg(x,Q,y)* (y . , ) Private Variables: x,y,t listseg Predicate \nDe.nition def listseg(x,a,y) .. if x =y then (a =[].emp) ( else .v,z,a' . (a =(v)\u00b7a'.x .v,z)* P(v) ) \n* listseg(z,a' ,y) Internal Implementations Q :=Q\u00b7(z); (code for enq) t :=cons( , ); y.1:=z; y.2:=t; \ny :=t Q :=cdr(Q); (code for deq) z :=x.1; t :=x; x :=x.2; dispose(t) w :=(x =y) (code for isempty?) Table \n3. Queue Module, Parametric in P(v) whose only purpose is to enable the speci.cation to work. This queue \nmodule keeps a sentinel at the end of its internal list, as is indicated by (y . , )in the resource invariant. \nThe sentinel does not hold any value in the queue, but reserves storage for a new value. An additional \nfeature of the treatment of queues is the predicate P, which is required to hold for each element of \nthe sequence a. By instantiating P in various ways we obtain versions of the queue module that transfer \ndifferent amounts of storage. P(v)= emp: plain values are transferred in and out of the queue, and no \nstorage is transferred with any of these values;  P(v)= v . , : binary cons cells, and ownership of \nthe stor\u00adage associated with them, are transferred in and out of the queue;  P(v)= list(v): linked lists, \nand ownership of the storage as\u00adsociated with them, are transferred in and out of the queue.  To illustrate \nthe difference between these cases, consider the fol\u00adlowing attempted proof steps in client code. {Q \n=(n)\u00b7a .emp} deq {Q =a .z =n .P(z)} z.1:=42 {???} In case P(v)is either emp or list(v)we cannot .ll \nin ??? because we do not have the right to dereference z in the precondition of z.1:= 42. However, if \nP(v)is v . , then we will have this right, and a valid postcondition is (Q =a.z =n .z .42, ). Conversely, \nif we replace z.1:=42 by code that traverses a linked list then the third de.nition of P(v)will enable \na veri.cation to go through, where the other two will not. On the other hand there is no operational \ndistinction between these three cases: the queue code just copies values. The upshot of this discussion \nis that the idea of ownership transfer we have alluded to is not determined by instructions in the program\u00adming \nlanguage alone. Just what storage is, or is not, transferred de\u00adpends on which de.nition of P we choose. \nAnd this choice depends on what we want to prove. This phenomenon, where Ownership is in the eye of the \nAsserter , can take some getting used to at .rst. One might feel ownership transfer might be made an \nexplicit operation in the programming language. In some cases such a programming practice would be useful, \nbut the simple fact is that in real programs the amount of resource transferred is not always determined \noperationally; rather, there is an understanding between a module writer, and program\u00admers of client \ncode. For example, when you call malloc() you just receive an address. The implementation of malloc() \ndoes not include explicit statements that transfer each of several cells to its caller, but the caller \nunderstands that ownership of several cells comes with the single address it receives. 6 A Conundrum \nIn the following 0 is the assertion emp that the heap is empty, and 1 says that it has precisely one \nactive cell, say x (so1is x . ). Consider the following instance of the hypothetical frame rule, where \ntrue is chosen as the invariant: {0 .1}k{0}[]f{1}k{false} {(0 .1)*true}k{0 *true}[]f{1 *true}k{false \n*true} The conclusion is de.nitely false in any sensible semantics of se\u00adquents. For example, if k denotes \nthe do-nothing command, skip, then the antecedent holds, but the consequent does not. However, we can \nderive the sequent in the premise: {0 .1}k{0} Consequence {0}k{0} Ordinary Frame {0 .1}k{0}{0 *1}k{0 \n*1} Consequence Consequence {1}k{0} {1}k{1} Conjunction {1 .1}k{1 .0} Consequence {1}k{false} This shows \nthat we cannot have all of: the usual rule of conse\u00adquence, the ordinary frame rule, the conjunction \nrule, and the hy\u00adpothetical frame rule. It also shows that the idea of treating infor\u00admation hiding as \nsyntactic sugar for proof and speci.cation forms should be approached with caution: one needs to be careful \nthat in\u00adtroduced sugar does not interact badly with expected rules, in a way that contradicts them. The \ncounterexample can also be presented as a module, and can be used to show a similar problem with the \nmodular procedure rule. Given this counterexample, the question is where to place the blame. There are \nseveral possibilities. 1. The speci.cation {0 .1}k{0}. This is an unusual speci.ca\u00adtion, since in the \nprogramming languages we have been using there is no way to branch on whether the heap is empty. 2. \nThe invariant true. Intuitively, a resource invariant should precisely identify an unambiguous area of \nstorage, that owned by a module. The invariant list(f )in the memory manager is unambiguous in this sense, \nwhere true is perhaps not.  3. One of the rules of conjunction, consequence, or the ordinary frame rule. \nWe pursue the .rst two options in the remainder of the paper, by de.ning a model of the programming language \nand investigating a notion of precise predicate. 7 A Denotational Model Until now in work on separation \nlogic we have used operational semantics, but in this paper we use a denotational semantics. By using \ndenotational semantics we will be able to reduce the truth of a sequent G f{p}C{q} to the truth of a \nsingle semantic triple {p}[[C]].{q} where . maps each procedure identi.er in G to a greatest or most \ngeneral relation satisfying it. In the case of the hypothetical frame rule, we will be able to compare \ntwo de\u00adnotations of the same command for particular instantiations of the procedure identi.ers, rather \nthan having to quantify over all possi\u00adble instantiations. Our choice to use denotational semantics here \nis entirely pragmatic: The greatest relation is not always de.nable by a program, but the ability to \nrefer to it leads to signi.cant simpli.\u00adcations in proofs about the semantics. Recall that a state consists \nof a pair, of a stack and a heap. A com\u00admand is interpreted as a binary relation States .States .{fault} \nthat relates an input state to possible output states, or a special out\u00adput, fault, which indicates an \nattempted access of an address not in the domain of the heap. In fact, because we use a fault-avoiding \ninterpretation of Hoare triples, it would be possible to use the do\u00admain States .P (States) .{fault} \ninstead. Using the more general domain lets us see clearly that if a command nondeterministically chooses \nbetween fault and some state, then the possibility of faulting will mean that the command is not well \nspeci.ed according to the semantics of triples. This is not an essential point; the more constrained \ndomain could be used without affecting any of our results. This domain of relations is inappropriate \nfor total correctness be\u00adcause it does not include a speci.c result for non-termination, so that our \nsemantics will not distinguish a command C from one that nondeterministically chooses C or divergence. \nWe will not consider all relations, but rather only those that validate the locality properties of the \n(ordinary) frame rule. We say that a relation c:States .States .{fault}is safe at a state (s,h) when \n\u00ac((s,h)[c] fault). We just list the properties here, and refer the reader to [39] for further explanation \nof them. The locality proper\u00adties are: 1. Safety Monotonicity: for all states (s,h) and heaps h1 such \nthat h#h1,if c is safe at (s,h), it is also safe at (s,h *h1). 2. Frame Property: for all states (s,h) \nand heaps h1 such that  ' h#h1,if c is safe at (s,h) and (s,h *h1)[c](s ,h '), then there is a subheap \nh ' 0 =h ' such that ' h ' 0#h1, h ' 0 *h1 = h ' , and (s,h)[c](s ,h ' 0). Commands will be interpreted \nusing the following domain. The poset LRel of local relations is the set of all re\u00ad lations c satisfying \nthe safety monotonicity and frame properties, ordered by subset inclusion. LEMMA 1. LRel is a chain-complete \npartial order with a least el\u00adement. The least element is the empty relation, and the least upper bound \nof a chain is given by the union of all the relations in the chain. The meaning of a command is given \nin the context of an environ\u00adment ., that maps procedure identi.ers to relations in LRel. . .ProcIds \n.LRel [[C]]. .LRel The semantics of expressions depends only on the stack [[E]]s .Ints [[B]]s .{true,false} \n(where s .S). The valuations are standard and omitted. Selected valuations for commands are in Table \n4. The main point to note is the treatment of fault. We have included only the basic commands and sequential \ncomposition. The interpretation of con\u00additionals is as usual, a procedure call applies the environment \nto the corresponding variable, and while loops and letrec receive stan\u00addard least .xed-point interpretations, \nwhich are guaranteed to exist by Lemma 1. LEMMA 2. For each command C, [[C]] is well-de.ned: for all \nen\u00advironments ., [[C]]. is in LRel, and [[C]]. is continuous in . when environments are ordered pointwise. \nIt is entertaining to see the nondeterminism at work in the semantics of cons in this model. In particular, \nsince we are aiming for partial correctness, the semantics does not record whether a command ter\u00adminates \nor not; for instance, x := 1;y := 1 has the same denotation as a command that nondeterministically picks \neither x := 1;y := 1 or divergence. Such a nondeterministic command can be expressed in our language \nas x := cons(0);dispose(x);y := cons(0);dispose(y); if (x = y) then (x := 1;y := 1) else (while (x = \nx) skip) The reader may enjoy verifying that this is indeed equivalent to x := 1;y := 1 in the model. \n 8 Semantics of Sequents In this section we give a semantics where a sequent G f{p}C{q} says that if \nevery speci.cation in G is true of an environment, then so is {p}C{q}. To interpret sequents we de.ne \nsemantic cousins of the modi.es clauses and Hoare triples. If c .LRel is a relation then modi.es(c,X) \nholds if and only if whenever y . X and ' ' (s,h)[c](s ,h '), we have that s(y)= s (y). {p}c{q}holds \nif and only if for all states (s,h) in p, 1. \u00ac((s,h)[c] fault); and '' 2. if (s,h)[c](s ,h ') then state \n(s ,h ') is in q. Now we can de.ne the semantics: A sequent {p1}k1{q1}[X1] ...,{pn}kn{qn}[Xn] f{p}C{q} \nholds if and only if for (s,h) . States and a . States .{fault}, (s,h)[[[x := E]].]a .. a =(s[x . [[E]]s],h) \n(s,h)[[[x := cons(E1,...,En)]].]a .. . m. (m,...,m + n - 1. dom(h)) () . a =(s[x . m],h * [m . [[E1]]s,...,m \n+ n - 1 . [[En]]s])(s,h)[[[x :=[E]]].]a .. if [[E]]s . dom(h) then a =(s[x . h([[E]]s)],h) else a = fault \n(s,h)[[[[E] := F]].]a .. if [[E]]s . dom(h) then a =(s,h[[[E]]s . [[F]]s]) else a = fault (s,h)[[[dispose(E)]].]a \n.. if [[E]]s . dom(h) then a =(s,h ' ) for h ' s.t. h '* ([[E]]s . h([[E]]s)) = h else a = fault ()() \n' '' (s,h)[[[C1;C2]].]a .. .(s ,h ' ).(s,h)[[[C1]].](s ,h ' ) . (s ,h ' )[[[C2]].]a. (s,h)[[[C1]].]fault \n. a = fault where .x f gives the least .xed-point of f , and seq(c1,c2), b . c1;c2 and d1,...,dn are \nde.ned as follows: ()() ' '' (s,h)[seq(c1,c2)]a .. .(s ,h ' ).(s,h)[c1](s ,h ' ) . (s ,h ' )[c2]a. (s,h)[c1]fault \n. a = fault (s,h)[b . c1;c2]a .. if b(s)= true then (s,h)[c1]a else (s,h)[c2]a (d1,...,dn)= .x(.d1,...,dn \n. LReln .(F1,...,Fn)) (where Fi =[[Ci]].[k1 . d1,...,kn . dn]) Table 4. Selected Valuations for all environments \n., if both { pi}.(ki){qi} and modi.es(.(ki),Xi) hold for all 1 = i = n, the triple { p}([[C]].){q} also \nholds. 9 Precise Predicates We know from the counterexample in Section 6 that we must re\u00adstrict the hypothetical \nframe rule in some way, if it is to be used with the standard semantics. Before describing the restriction, \nlet us retrace some of our steps. We had a situation where ownership could transfer between a module \nand a client, which made essential use of the dynamic nature of *. But we had also got to a position \nwhere ownership is determined by what the Asserter asserts, and this put us in a bind: when the Asserter \ndoes not precisely specify what storage is owned, different splittings can be chosen at differ\u00adent times \nusing the nondeterministic semantics of *; this fools the hypothetical frame rule. It is perhaps fortuitous \nthat the nondeter\u00adminism in * has not gotten us into trouble in separation logic before now. A way out \nof this problem is to insist that the Asserter pre\u00adcisely nail down the storage that he or she is talking \nabout. A predicate p is precise if and only if for all states (s,h), there is at most one subheap hp \nof h for which (s,hp) . p. Intuitively, this de.nition says that for each state (s,h), a precise predicate \nunambiguously speci.es the portion of the heap h that is relevant to the predicate. Formulae that describe \ndata structures are often precise. Indeed, the de.nition might be viewed as a for\u00admalization of a point \nof view stressed by Richard Bornat, that for practically any data structure one can write a formula or \nprogram that searches through a heap and picks out the relevant cells. Bornat used this idea of reading \nout the relevant cells in order to express spatial separation in traditional Hoare logic [4]. An example \nof a precise predicate is the following one for list seg\u00adments: def listseg(x,y) .. (x = y . emp) . () \nx = y ..z. (x . z) * listseg(z,y) This predicate is true when the heap contains a non-circular linked \nlist (and nothing else), which starts from the cell x and ends with y. Note that because of x= y in the \nsecond disjunct, the predicate listseg(x,y) says that if x and y have the same value in a state (s,h), \nthe heap h must be empty. If we had left x = y out of the second disjunct, then listseg(x,y) would not \nbe precise: listseg(x,x) could be true of a heap containing a non-empty circular list from x to x (and \nnothing else), and also of the empty heap, a proper subheap. For this reason, the list segment predicate \nin [36] is not precise, if we wrap it in an existential quanti.er over the sequence parameter. If p is \na precise predicate then there can be at most one way to split any given heap up in such a way as to \nsatisfy p * q; the splitting, if there is one, must give p the unique subheap satisfying it. This leads \nto an important property of precise predicates. LEMMA 3. A predicate p is precise if and only if p *- \ndistributes over .: for all predicates q and r, we have p * (q . r)=(p * q) . (p * r). We also have closure \nproperties of precise predicates. LEMMA 4. For all precise predicates p and q, all (possibly im\u00adprecise) \npredicates r, and boolean expressions B, all the predicates p . r, p * q, and (B . p) . (\u00ac B . q) are \nprecise. 10 Soundness All of the proof rules from Section 3.2 are sound in the denota\u00adtional model. The \nmain result of the paper concerns the hypotheti\u00adcal frame rule and, by implication, the modular procedure \nrule. THEOREM 5. (a) The hypothetical frame rule is sound for .xed preconditions p1,...,pnifandonlyif \np1,...,pn are all precise. (b) The hypothetical frame rule is sound for a .xed invariant r if and only \nif r is precise.  Theorem 5(a) addresses point 1 from Section 6: it rules out the precondition 0. 1 \nin the conundrum, which is not precise. Theorem 5(b) addresses point 2: it rules out the invariant true, \nwhich is not precise. And this result covers the queue and memory manager examples, where the preconditions \nand invariants are all precise. There are two main concepts used in the proof of the theorem. The greatest \nrelation. We identify the greatest relation for a speci.cation {p}k{q}[X], which is the largest local \nrelation satisfying it. This allows us to reduce the truth of a sequent, which of.cially involves quanti.cation \nover all environments, to the truth of a single triple for a single environment.  Simulation. To show \nthe soundness of the hypothetical frame rule we need to connect the meaning of a command in one context \nto its meaning in another with an additional invariant and additional modi.es sets. We develop a notion \nof simula\u00adtion relation between commands to describe this connection.  In the next two subsections we \nde.ne these concepts and state some of their properties, and then we sketch their relevance in the proof \nof the theorem. 10.1 The Greatest Relation For each speci.cation {p}-{q}[X], de.ne great(p,q, X) (s,h)[great(p,q,X)]fault \ndef ..(s,h) . p *true ' (s,h)[great(p,q,X)](s ,h ') def ' ..(1) s(y)= s (y) for all variables y .X; \nand (2) .hp,h1.(hp *h1 = h .(s,hp) . p) ' =..h ' q.hq'#h1 .hq '*h1 = h '.(s ,hq') .q The .rst equivalence \nsays that great(p,q,X) is safe at (s, h) just when p holds in (s,hp) for some subheap hp of h. The second \nequivalence is about state changes. The condition (1) means that great(p,q, X) can modify only those \nvariables in X. Condition (2) says that great(p,q,X) demonically chooses a subheap hp of the initial \nheap h that satis.es p (i.e., (s,hp) . p), and disposes all cells ' in hp; then, it angelically picks \nfrom q a new heap h ' (i.e., (s ,h ') . qqq) and allocates h ' to get the .nal heap h ' . q LEMMA 6. \nThe relation great(p, q,X) is in LRel, and satis\u00ad.es {p}-{q} and modi.es(-,X). Moreover, it is the greatest \nsuch: for all local relations c in LRel, we have that {p}c{q}.modi.es(c,X)=.c .great(p,q, X). The greatest \nenvironment for a context G is the largest environment, in the pointwise order, satisfying all the procedure \nspeci.cations in G. It maps k to great(p,q,X) when {p}k{q}[X] .G; otherwise, it maps k to the top relation \nStates \u00d7(States .{fault}). Greatest environments give us a simpler way to interpret sequents and proof \nrules. A sequent G f{p}C{q}holds just if the triple {p}([[C]].){q}holds for the greatest environment \n. satisfying G, leading to PROPOSITION 7. For all predicates p, q, p ' and q ' , commands C, and contexts \nG and G' , we have the following equivalence: the proof rule G f{p}C{q}'' G'f{p }C{q } '' holds if and \nonly if we have {p}[[C]].{q}=.{p }[[C]].'{q } for the greatest environments . and .' that, respectively, \nsatisfy G and G' . 10.2 Simulation Let R : States . States be a binary relation between states. For c,c1 \nin LRel, we say that c1 simulates c upto R, denoted c[sim(R)]c1, just if the following properties hold: \nGeneralized Safety Monotonicity:if (s,h)[R](s1,h1), and c is safe at (s,h), then c1 is safe at (s1,h1). \nGeneralized Frame Property:if (s,h)[R](s1,h1), c is safe at ' ' (s,h), and (s1,h1)[c1](s1,h1'), then \nthere is a state (s ,h ') such ' '' that (s,h)[c](s ,h ') and (s ,h ')[R](s1,h ' 1). c[sim(R)]c1 says \nthat for R-related initial states (s,h) and (s1,h1), when we have enough resources at (s,h) to run c \nsafely, we also have enough resources at (s1,h1) to run c1 safely; and in that case, every state transition \nfrom (s1,h1) in c1 can be tracked by a transi\u00adtion from (s, h) in c. Suppose r is a predicate. The following \nrelation Rr plays a central role in the analysis of the hypothetical frame rule. def (s,h)[Rr](s1,h1) \n..s = s1 ..hr.h1 = h *hr .(s,hr) .r The next result gives us a way to connect hypotheses in the premise \nand conclusion of the hypothetical rule, and additionally provides the characterization of precise predicates \nthat is at the core of The\u00adorem 5. PROPOSITION 8. (a) A predicate p is precise if and only if great(p,q, \nX)[sim(Rr)]great(p *r,q *r,X) holds for for all predicates r and q, and sets X of variables. (b) A predicate \nr is precise if and only if great(p,q, X)[sim(Rr)]great(p *r,q *r,X) holds for all predicates p, q and \nsets X of variables. The detailed proof of Theorem 5 relies on developing machinery that allows us to \napply this key proposition; this development, and the proof of the proposition itself, is nontrivial, \nand will be left to the full paper. However, the relevance of the proposition can be seen by considering \na special case of the hypothetical frame rule, for the key case of procedure call, and where the modi.ed \nvariables are held .xed: {p1}k{q1}[X1] f{p}k{q} {p1 *r}k{q1 *r}[X1] f{p *r}k{q *r} We give a proof of \nthe following proposition about this special case; it is the central step for showing Theorem 5. PROPOSITION \n9. (a) The above special case of the hypothetical frame rule is sound for a .xed precondition p1 if and \nonly if p1 is precise. (b) The above special case is sound for a .xed invariant r if and only if r is \nprecise.  Note that the if direction of the proposition is implied by the same direction of Theorem \n5, and that for the only-if direction, the propo\u00adsition implies the theorem. The proof of this proposition \nuses a lemma that characterizes sim(Rr) using Hoare triples. LEMMA 10. Local relations c and c1 are related \nby sim(Rr) if and only if for all predicates p,q, we have {p}c{q}=.{p *r}c1{q *r}. Proof: [of Proposition \n9] Using Proposition 7 and Lemma 10, we can simplify the above spe\u00adcial case of the hypothetical frame \nrule as follows: for all predicates p,q, if { p1}k1{q1}[X1] f{ p}k{q} holds, then { p1 * r}k1{q1 * r}[X1] \nf{ p * r}k{q * r} holds .. (. Proposition 7) for all predicates p,q, if { p}great(p1,q1,X1){q} holds, \nthen { p * r}great(p1 * r,q1 * r,X1){q * r} holds .. (. Lemma 10) great(p1,q1,X1)[sim(Rr)]great(p1 * \nr,q1 * r,X1) Now, Proposition 8(a) gives (a) of this proposition, and Proposi\u00adtion 8(b) gives (b) of \nthis proposition. 10.3 Supported and Intuitionistic Predicates There is a relaxation of the notion of \nprecise predicate that can be used to provide further suf.cient conditions for soundness. A pred\u00adicate \nis supported if, for any stack and heap, the collection of sub\u00adheaps making it true (while holding the \nstack constant) is empty or has a least element. A predicate is intuitionistic if it is closed under \nheap extension. THEOREM 11. The hypothetical frame rule is sound in the follow\u00ading cases: (a) the preconditions \np1,...,pn are supported, and the postcon\u00additions q1,...,qn are intuitionistic; or (b) the resource invariant \nr is supported, and the postconditions q1,...,qn are intuitionistic.  Notice that the .rst point does \nnot contradict the only if part of Theorem 5(a), because it mentions postconditions in addition to preconditions. \nLikewise, the second point does not contradict The\u00adorem 5(b), because it mentions postconditions as well \nas the re\u00adsource invariant. This result about supported predicates would give us a version of the hypothetical \nframe rule appropriate when we are not interested in nailing down de.nite portions of memory using assertions, \nas might be the case in a garbage-collected language. 11 Related and Future Work As we have emphasized, \nreliance on .xed resource partitioning has been an obstacle to the development of modular methods of \npro\u00adgram speci.cation that are applicable to widely used programming languages. Because the separating \nconjunction * is a logical con\u00adnective, which depends on the state, it allows us to describe situa\u00adtions \nwhere the partition between a module and its clients changes over time. For example, with a resource \nmanager module the re\u00adsources transfer back and forth between the module and a client, as allocation \nand deallocation operations are performed, but correct operating relies on separation being maintained \nat all times. A different reaction to the limitations of .xed partitioning has been the development of \nthe assume-guarantee method of reasoning about program components [24, 21]. While this has proven success\u00adful, \nwe are unsure whether it could be pro.tably applied to mutable data structures with embedded pointers. \nIn any case, when parti\u00adtioning can be ensured, be it .xed or dynamic, an invariant-based methodology \nleads to pleasantly modular speci.cations and proofs. Perhaps the most signi.cant previous work that \naddresses infor\u00admation hiding in program logics, and that confronts mutable data structures, is that \nof Leino and Nelson [23] (also, [12]). They use abstract variables (like our use of the variable Q in \nTable 3) to spec\u00adify modules, and they develop a subtle notion of modular sound\u00adness that identi.es situations \nwhen clients cannot access the inter\u00adnal representation of a module. This much is similar in spirit to \nwhat we are attempting, but on the technical level we are not at all sure if there is any relationship \nbetween the separating conjunction and their notion of modular soundness. The information-hiding problems \ncaused by pointers have been a concern for a number of years in the object-oriented types com\u00admunity \n(e.g., [19, 10, 15] ). A focal point of that work has been a concept of con.nement , which disallows \nor controls pointers into data representations. Some con.nement systems use techniques similar to regions, \nwith control over the number and direction of pointers across region boundaries. The advantage of con.nement \nschemes is their use of static typing, or static analysis, to provide algorithmic guarantees of information \nhiding properties. Conversely, separation logic is more .exible, not just because it is based on logic \nrather than types, but also because it allows any number of pointers from the outside, requiring only \nthat these pointers not be dereferenced without permission. Current con.nement schemes have dif.culty \nwith ownership transfer that involves aliasing (because they tend to rely on unique pointers), such as \na program that disposes all of the elements in a graph, or with examples where resource partitioning \ndepends on arithmetic properties. Recent work on the semantics of con.nement uses heap partition\u00ading \nin an essential way [3, 33], thus suggesting the prospect of a deeper connection between type systems \nfor con.nement and log\u00adics of separation. There is also the possibility of promoting the heap partitioning \noperation * used in the semantic models to a type operator in the source language; an immediate step \ncould even be attempted to obtain a form of alias types with information hiding [37]. Further uni.cation \nalong these lines could be valuable. It is striking that many proof systems for object-oriented languages \nwork by exposing class invariants or other descriptions of internal states at method call sites (e.g., \n[13, 34]). Of course, the developers of such systems have rightly been careful, as unsoundness can very \neasily result if one incorrectly hides invariants. It seems plausible, however, that taking explicit \naccount of separation or con.nement could lead to an improved logic of objects. Further a.eld in aims, \nbut closer in technique, are logics of mo\u00adbile and concurrent processes that have been developed by Cardelli, \nCaires and Gordon [9, 5]; related ideas have also been used to study semi-structured data [8, 7]. Cardelli \net. al. use subsets of a commu\u00adtative monoid, as in the general models of bunched logic [31, 32], but \nthe interaction between logic and program dynamics is very different to that here. The models of [9, \n5] do not satisfy the prop\u00aderties (such as the frame property) that drive our approach to infor\u00admation \nhiding. Furthermore, although the pointers from outside phenomenon certainly occurs in their setting, \nbased as it is on the p-calculus, they do not use the conjunction * (or | in their nota\u00adtion) to control \nthese pointers/names; rather, they employ a form of new name quanti.er, following Gabbay and Pitts [14]. \nDespite the surface similarity of logical structure, we do not feel that we fully understand the relationship \nbetween the two approaches. An intriguing question is if there is a link between the hypothet\u00adical frame \nrule and the data abstraction provided by polymorphic types. Polymorphic typing can be used to hide the \ntype in a data ab\u00adstraction [35, 25], but this is not the same thing as hiding dynamic resources. For \nexample, if we hide the type of a reference, polymor\u00adphic typing does not guarantee that the reference \nis not aliased, and accessible from outside the data abstraction. Still, the hypothetical frame rule \nensures that a proof of client code can be used with any (precise) representation invariant, so there \nis an obvious intuitive analogy with polymorphic functions; the client should be paramet\u00adrically polymorphic \nin the resource invariant. If this analogy can be made precise it may provide the basis for an approach \nto data re.nement, and encapsulated components as .rst-class values, that accounts for mutable structures \nand dynamic ownership transfer. We have stayed in a sequential setup in this paper, but the ideas seem \nrelevant to concurrent programming. Indeed, the treatment by Hoare in [17] revolves around the concept \nof spatial separa\u00adtion, and the work here grew out of an attempt to directly adapt that approach, and \nits extension by Owicki and Gries [27], to sep\u00adaration logic. In unpublished notes from August 2001, \nO Hearn described proof rules for concurrency using * to express heap sepa\u00adration, and showed program \nproofs where storage moved from one process to another. The proof rules were not published, because O \nHearn was unable to establish their soundness. Then, in August 2002, Reynolds showed that the rules were \nunsound if used without restriction, and this lead to our focus on precise assertions. Both the promise \nand subtlety of the proof rules had as much to do with information hiding as concurrency, and it seemed \nunwise to attempt to tackle both at the same time. At the time of Reynolds s discovery we had already \nbegun work on the hypothetical frame rule, and the counterexample appears here as the conundrum in Section \n6. Work is underway on the semantics of the concurrent logic, and we are hopeful that a thorough account \nof the concurrency proof rules will be forthcoming. Finally, in this paper we have concentrated on program \nproving, but there have been striking successes in software model check\u00ading [2, 11], which use abstraction \nto bridge the gap between in.\u00adnite state language models and the .nite state models expected by model \nchecking algorithms; in essence, abstract interpretations are chosen, and sometimes re.ned, that allow \nfor the synthesis of loop invariants. We wonder if one might synthesize resource invariants describing \nheap-sensitive properties as well, and use this to parti\u00adtion the model checking effort. For this to \nbe workable the imme\u00addiate challenge is to devise expressive heap abstractions [38] that are compatible \nwith an information-hiding rule like the hypotheti\u00adcal frame rule. Acknowledgements. We have bene.tted \ngreatly from discus\u00adsions with Josh Berdine, Richard Bornat and Cristiano Calcagno. O Hearn s research \nwas supported by the EPSRC project Lo\u00adcal Reasoning about State . Reynolds s research was partially supported \nby an EPSRC Visiting Fellowship at Queen Mary, University of London, by National Science Foundation Grant \nCCR-0204242, and by the Basic Research in Computer Science (http://www.brics.dk/) Centre of the Danish \nNational Research Foundation. Yang was supported by grant No. R08-2003-000\u00ad10370-0 from the Basic Research \nProgram of the Korea Science &#38; Engineering Foundation. Yang would like to thank EPSRC for supporting \nhis visit to University of London in 2002, during which he .rst got involved in this work. 12 References \n[1] A. Ahmed, L. Jia, and D. Walker. Reasoning about hierarchical stor\u00adage. In 18th LICS, 2003. [2] T. \nBall and S. Rajamani. Checking temporal properties of software with boolean programs. Proceedings of \nthe Workshop on Advances in Veri.cation, 2000. [3] A. Banerjee and D. Naumann. Representation independence, \ncon.ne\u00adment and access control. In 29th POPL, 2002. [4] R. Bornat. Proving pointer programs in Hoare \nlogic. Mathematics of Program Construction, 2000. [5] L. Cardelli and L Caires. A spatial logic for concurrency. \nIn TACS 01, LNCS 2255:1 37, Springer, 2001. [6] L. Cardelli, P. Gardner, and G. Ghelli. Querying trees \nwith pointers. Unpublished notes, 2003. [7] L. Cardelli, P. Gardner, and G. Ghelli. A spatial logic for \nquerying graphs. Proceedings of ICALP 02. [8] L. Cardelli and G. Ghelli. A query language for semistructured \ndata based on the ambient logic. Proceedings of ESOP 01. [9] L. Cardelli and A. D. Gordon. Anytime, anywhere. \nModal logics for mobile ambients. In 27th POPL, 2000. [10] D. Clarke, J. Noble, and J. Potter. Simple \nownership types for object containment. ECOOP, LNCS 2072, 2001. [11] J. Corbett, M. Dwyer, J. Hatcliff, \nS. Laubach, C. P.as.areanu, Robby, and H. Zheng. Bandera: extracting .nite-state models from Java source \ncode. In International Conference on Software Engineering, pages 439 448, 2000. [12] K.R.M. Leino D. \nDetlefs and G. Nelson. Wrestling with rep exposure. Digital SRC Research Report 156, 1998. [13] F. de \nBoer. A WP calculus for OO. In FOSSACS, 1999. [14] M. Gabbay and A. Pitts. A new approach to abstract \nsyntax involving binders. In 14th LICS, 1999. [15] C. Grothoff, J. Palsberg, and J. Vitek. Encapsulating \nobjects with con.ned types. OOPSLA, pp241 253, 2001. [16] C.A.R. Hoare. Proof of correctness of data \nrepresentations. Acta Informatica 4, 271-281, 1972. [17] C.A.R. Hoare. Towards a theory of parallel programming. \nIn Hoare and Perrot, editors, Operating Systems Techniques. Academic Press, 1972. [18] C.A.R. Hoare. \nMonitors: An operating system structuring concept. C.ACM, 17(10):549 557, October 1974. [19] J. Hogg, \nD. Lea, R. Holt, A. Wills, and D. de Champeaux. The Geneva convention on the treatment of object aliasing. \nOOPS Mes\u00adsenger, April, 1992. [20] S. Isthiaq and P.W. O Hearn. BI as an assertion language for mutable \ndata structures. In 28th POPL, 2001. [21] C.B. Jones. Speci.cation and design of (parallel) programs. \nIFIP Conference, 1983. [22] B. Kernighan and D. Ritchie. The C programming language. Prentice Hall, 1988. \n[23] K.R.M. Leino and G. Nelson. Data abstraction and information hid\u00ading. ACM TOPLAS 24(5): 491-553, \n2002. [24] J. Misra and K.M. Chandy. Proofs of networks of processes. IEEE Transactions of Software Engineering, \nJuly, 1981. [25] J.C. Mitchell and G.D. Plotkin. Abstract types have existential type. ACM TOPLAS 10(3):470-502, \n1988. [26] P. O Hearn, J. Reynolds, and H. Yang. Local reasoning about pro\u00adgrams that alter data structures. \nIn Proceedings of Computer Science Logic, pages 1 19, 2001. LNCS 2142. [27] S. Owicki and D. Gries. An \naxiomatic proof technique for parallel programs I. Acta Informatica, 6:319 340, 1976. [28] D.L. Parnas. \nInformation distribution aspects of design methodology. IFIP Congress (1) 1971: 339-344, 1972. [29] D.L. \nParnas. On the criteria to be used in decomposing systems into modules. C.ACM, 15(12):1053 1058, 1972. \n[30] B.C. Pierce and D.N. Turner. Simple type-theoretic foundations for object-oriented programming. \nJournal of Functional Programming, 4(2):207 247, 1994. [31] D.J. Pym. The Semantics and Proof Theory \nof the Logic of Bunched Implications. Kluwer Applied Logic series, 2002. [32] D.J. Pym, P.W. O Hearn, \nand H. Yang. Possible worlds and resources: the semantics of BI. TCS, to appear, 2003. [33] U. Reddy \nand H. Yang. Correctness of data representations involving heap data structures. Proceedings of ESOP, \n2003. [34] B. Reus, M. Wirsing, and R. Hennicker. A Hoare calculus for ver\u00adifying Java realizations of \nOCL-constrained design models. FASE Proceedings, LNCS 2029, pp300 316, 2001. [35] J.C. Reynolds. Types, \nabstraction and parametric polymorphism. IFIP Proceedings, pp513-523, 1983. [36] J.C. Reynolds. Separation \nlogic: a logic for shared mutable data struc\u00adtures. Invited Paper, 17th LICS, 2002. [37] D. Walker and \nJ.G. Morrisett. Alias types for recursive data structures. In Types in Compilation, pp177 206, 2000. \n[38] R. Wilhelm, M. Sagiv, and T. Reps. Shape analysis. In Compiler Construction, pp1 17, 2000. [39] \nH. Yang, and P. O Hearn. A semantic basis for local reasoning. In Proceedings of FOSSACS 02, pp402 416, \n2002. 13 Appendix: Variable Conditions 13.1 Side Conditions and Modi.es Sets We now clarify the side \nconditions for the hypothetical frame rule. To begin with, note that in the rule we are using comma between \nthe Xi and Y for union of disjoint sets; the form of the rule therefore assumes that Xi and Y are disjoint. \nThe disjointness requirement for Y enforces that we do not observe the changes of a variable in Y while \nreasoning about C; as a result, reasoning in client code is independent of variables in Y .We give a \ntechnical de.nition of several variants on a notion of disjointness of a set of variables X from a set \nof variables, a command, a predicate, or a context. X is disjoint from a set Y if their variables do \nnot overlap; X is disjoint from a command C if X does not intersect with the free variables of C; X is \ndisjoint from predicate r if the predicate is invariant under changes to values of variables in X; X \nis disjoint from context G if for all {p}k{q}[Y ] in G, X is disjoint from p, q and Y . This de.nes the \nsecond side condition. The .rst side condition can be made rigorous with a relativized ver\u00adsion of the \nusual notion of set of variables modi.ed by a command. We describe this using a set Modi.es(C)(G;G') \nof variables associ\u00adated with each command, where we split the context into two parts. The two most important \nclauses in the de.nition concern procedure call. Modi.es(k)(G;G')= X, if {p}k{q}[X] . G Modi.es(k)(G;G')= \n{}, if {p}k{q}[X] . G' The upshot is that Modi.es(C)(G;G') reports those variables modi\u00ad.ed by C, except \nthat it doesn t count any procedure calls for pro\u00adcedures in G' . For the other commands, the relativized \nnotion of modi.es set is de.ned usual. For a compound command C with immediate subcommands C1,...,Cn, \nthe set Modi.es(C)(G;G') is the union .iModi.es(Ci)(G;G'). Two of the basic commands are as follows: \nModi.es(x := E)(G;G')= {x} Modi.es([x] := E)(G;G')= {} For [x] := E the modi.es set is empty because \nthe command alters the heap but not the stack. We are now in a position to state the .rst side condition \nrigorously: it means Modi.es(C)(G; {p1}k1{q1}[X1],...,{pn}kn{qn}[Xn]) is disjoint from r. The modi.es \nconditions for the the ordinary frame and recursive procedure rules do not mention the except through \nclause. These can be formalized by taking G' to be empty in Modi.es(C)(G;G'). An important point is that \nthe free variables of the resource invari\u00adant are allowed to overlap with the Xi. This often happens \nwhen using abstract variables to specify the behaviour of a module, as exempli.ed by the treatment of \nthe abstract variable Q in the queue module in Table 3. The complexity of modi.es clauses is a general \nirritation in pro\u00adgram logic, and one might feel that this problem with modi.es clauses could be easily \navoided, simply by doing away with assign\u00adment to variables, so that the heap component is the only part \nof the state that changes. While this is easy to do semantically, obtaining a satisfactory program logic \nis not as straightforward. The most im\u00adportant point is the treatment of abstract variables. For example, \nin the queue module the variable q is used in interface speci.cations as well as the invariant. If we \nwere to try to place this variable into the heap then separation would not allow us to have it in both \nan in\u00adterface speci.cation and an invariant. If some other approach could be developed as an alternative \nto the changing abstract variables, that was itself not more complex, then perhaps we could .nally do \naway with modi.es conditions. In situations where one wants to capture only structural integrity properties \nof data structures, rather than correctness properties, it is often possible to avoid abstract variables. \nFor example, one some\u00adtimes wants to ensure, for example, that a data structure has the correct shape \nand has no dangling pointers, without giving a com\u00adplete description of the data that is represented. \nBecause abstract variables are not required (or less often required) in such situations we might get \nsome way with a logic simpler than the one here, that does not require modi.es clauses. 13.2 On Existentials \nand Free Variables In [26, 36] there is an inference rule for introducing existential vari\u00adables in preconditions \nand postconditions. {p}C{q} x . free(C) {.x.p}C{.x.q} The side condition cannot be stated in the formalism \nof this paper. For, a procedure speci.cation {p}k{q}[X] identi.es the variables, X, that k might modify, \nbut not those that k might read from. We can get around this problem by adding a free variable compo\u00adnent \nto the sequent form, thus having (Y ) G f{p}C{q}. This constrains the variables appearing in C and all \nthe procedures ki, but not the preconditions and postconditions. This would allow us to describe the \nexistential rule as (Y ) G f{p}C{q} x . Y (Y ) G f{.x.p}C{.x.q} Another reasonable approach is to have \na distinct class of logical variables, that cannot be assigned to in programs. For technical simplicity, \nwe do not explicitly pursue either of these extensions in the current paper.   \n\t\t\t", "proc_id": "964001", "abstract": "We investigate proof rules for information hiding, using the recent formalism of separation logic. In essence, we use the separating conjunction to partition the internal resources of a module from those accessed by the module's clients. The use of a logical connective gives rise to a form of dynamic partitioning, where we track the transfer of ownership of portions of heap storage between program components. It also enables us to enforce separation in the presence of mutable data structures with embedded addresses that may be aliased.", "authors": [{"name": "Peter W. O'Hearn", "author_profile_id": "81332519314", "affiliation": "Queen Mary University of London", "person_id": "PP43122327", "email_address": "", "orcid_id": ""}, {"name": "Hongseok Yang", "author_profile_id": "81100355747", "affiliation": "Seoul National University", "person_id": "PP39039167", "email_address": "", "orcid_id": ""}, {"name": "John C. Reynolds", "author_profile_id": "81100470240", "affiliation": "Carnegie Mellon University", "person_id": "PP39044240", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/964001.964024", "year": "2004", "article_id": "964024", "conference": "POPL", "title": "Separation and information hiding", "url": "http://dl.acm.org/citation.cfm?id=964024"}