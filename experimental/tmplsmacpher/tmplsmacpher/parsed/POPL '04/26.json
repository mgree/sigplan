{"article_publication_date": "01-01-2004", "fulltext": "\n Non-linear Loop Invariant Generation using Gr\u00a8 obner Bases Sriram Sankaranarayanan, Henny B. Sipma, \nand Zohar Manna * Department of Computer Science, Stanford University, Stanford, CA 94305, USA. {srirams,sipma,zm}@theory.stanford.edu \nAbstract We present a new technique for the generation of non-linear (al\u00adgebraic) invariants of a program. \nOur technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation \nproblem to a numerical constraint solving problem. So far, the literature on invariant generation has \nbeen focussed on the construction of linear invariants for linear programs. Consequently, there has been \nlittle progress toward non-linear invariant genera\u00adtion. In this paper, we demonstrate a technique that \nencodes the conditions for a given template assertion being an invariant into a set of constraints, such \nthat all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the \nprogram. We discuss some trade-offs between the completeness of the tech\u00adnique and the tractability of \nthe constraint-solving problem gener\u00adated. The application of the technique is demonstrated on a few \nexamples. Categories and Subject Descriptors: F.3.1 [Verifying Programs]: Invariants, I.1.2 [Algorithms]:Algebraic \nAlgorithms, F.4.1 [Mathe\u00admatical Logic]:Logic and Constraint Programming, F.3.2 [Seman\u00adtics of Programming]: \nProgram Analysis. General Terms: Algorithms, Languages, Theory, Veri.cation. Keywords: Program Analysis, \nVeri.cation, Invariant Generation, Symbolic Computation, Ideals, Gr\u00a8obner Bases, Constraint Pro\u00adgramming. \n* This research was supported in part by NSF grants CCR\u00ad01-21403, CCR-02-20134 and CCR-02-09237, by ARO \ngrant DAAD19-01-1-0723, by ARPA/AF contracts F33615-00-C-1693 and F33615-99-C-3014, and by NAVY/ONR contract \nN00014-03\u00ad1-0939. Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. POPL 04, January 14 16, 2004, Venice, Italy. Copyright 2004 ACM 1-58113-729-X/04/0001 ...$5.00 \n 1 Introduction An invariant of a program at a location is an assertion that is true of any program state \nreaching the location. The importance of the automatic invariant generation problem for the veri.cation, \nand the analysis of programs is well-known. Invariant assertions can be used directly to establish properties \nof a program, or used indirectly to obtain lemmas for proving other safety and liveness properties of \nthe program [20]. An assertion is said to be inductive at a program location if it holds the .rst time \nthe location is reached, and is preserved un\u00adder every cycle back to the location. Inductive assertions \nhave been traditionally used to prove programs correct, starting with the Floyd-Hoare method of inductive \nassertions for verifying partial\u00adcorrectness [14, 16]. It can be shown that any inductive assertion is \ninvariant, and furthermore, all known techniques to establish in\u00advariants use inductive assertions. In \nthis sense, invariant generation methods are, in fact, inductive assertion generation methods. Traditionally, \ninvariant generation has been performed us\u00ading the iterative technique under the framework of abstract\u00adinterpretation \n[10, 11]. Since an invariant is true of every reach\u00adable state of a program, any over-approximation of \nthe set of reach\u00adable states is an invariant. To generate such an over-approximation, the iterative technique \nstarts from the initial states of the program, and iterates until no more states can be added. In order \nto con\u00adverge, the technique uses a heuristic guess called widening to in\u00adformally guess the limit of \na sequence of iterative steps. How\u00adever, widening may sometimes produce over-approximations that are \ntoo large to be useful. This technique has been applied with numerous re.nements to generate invariants, \nespecially linear in\u00advariants [18, 11, 15, 6, 26, 5, 4]. However, apart from a few ex\u00adceptions [3, 22], \nthere has been little progress on the generation of non-linear invariants involving multiplication. One \nof the rea\u00adsons for this may be the lack of algorithmic improvements needed to de.ne reasonable assertion \nmanipulation techniques for the do\u00admain of non-linear assertions. Polyhedra, for instance, have been \nwidely studied with advances in polyhedral invariant generation going hand in hand with algorithmic improvements \nin polyhedral manipulation techniques. As an alternative to the iterative strategy, we have proposed \na constraint-based technique to generate linear invariants [9]. The main idea there is to .x a template \ncandidate assertion, and gener\u00adate constraints on the coef.cients in order to guarantee its inductive\u00adness. \nAny solution to these constraints corresponds to an inductive assertion. The technique does not rely \non widening heuristics, and can potentially generate stronger invariants than the iterative tech\u00adIn this \npaper, we present a technique to generate algebraic inductive assertions of the form p(x1,...,xn)=0, \nwhere p is a polynomial of .xed degree with real coef.cients. Similar to our previous work, we translate \nthe invariant generation into a constraint solving prob\u00adlem using a theory that describes the consequences \nof assertions. However, the theory used for linear invariants is different from that needed for algebraic \ninvariants. In the linear case, Farkas Lemma [23] provides a straightforward way to encode the conditions \nfor being an invariant. For the non-linear case, we demonstrate that Gr\u00a8obner bases [12] can be used \nto reduce the invariant generation problem to a non-linear constraint solving problem that is shown to \nbe in the parametric linear form [2]. We then discuss solution techniques to these constraints, and show \nthat any solution to these constraints is an invariant, thus proving the soundness of our tech\u00adnique. \nEven though completeness seems achievable in theory, we .nd that insistence on completeness makes the \nconstraint solving intractable. Hence, we present tractable relaxations that make our technique feasible. \nWe demonstrate our technique on a few exam\u00adples. Gr\u00a8obner bases are also used in the work of M\u00a8uller-Olm \nand Seidl, which presents a backward propagation-based method for non\u00adlinear programs without branch \nconditions [22]. The use of widen\u00ading/narrowing is avoided by observing that ideals in certain poly\u00adnomial \nrings (called Noetherian Rings) satisfy the ascending chain condition. The technique is shown to be exact \nfor polynomial con\u00adstants, i.e, invariants of the form x =p, where x is a program vari\u00adable and p is \na polynomial in the program variables. However, their technique is applicable only to programs where \nall conditional branches are abstracted by non-deterministic choices. In contrast, our technique sacri.ces \ncompleteness for the ability to handle alge\u00adbraic branch conditions. The rest of the paper is organized \nas follows: Section 2 presents some preliminary de.nitions along with a statement of the prob\u00adlem. The \nconstraint generation technique is described in section 3. Techniques for solving these constraints are \ndiscussed in section 4. In section 5, the technique is illustrated with a few examples. Sec\u00adtion 6 concludes \nwith some ideas for future work. The appendix presents a few results alluded to in the paper. 2 Preliminaries \nIn this section, we introduce the theory of ideals, which is at the heart of our technique, and present \nour computational model of transition systems. Algebraic Assertions We begin by presenting some de.nitions \nand results from ideal the\u00adory. Informally, an ideal is a set of equations between polynomials along \nwith all their consequences. Ideals can be used to deduce facts about the set of points that satisfy \ntheir underlying equations. Some of the results in this section are stated in general terms with\u00adout \nproofs. Details can be found in most standard texts on algebra and algebraic geometry [12, 21]. Let R \nbe the set of reals and C be the set of complex numbers obtained as the algebraic closure of the reals. \nLet {x1,...,xn} be a set of variables. The set of polynomials on the variables, whose coef.cients are \ndrawn from the real (complex) numbers is denoted by R[x1,...,xn](C [x1,...,xn]). We shall work with these \nrings even though the results can be applied to many other rings, including Z[x1,...,xn], the ring of \ninteger polynomials. De.nition 1 (Algebraic Assertions) An algebraic assertion . is V an assertion of \nthe form i pi(x1,...,xn)=0 where each pi . R[x1,...,xn]. The degree of an assertion is the maximum among \nthe degrees of the polynomials that make up the assertion. The set of points in the complex plane that \nsatisfy an algebraic as- V sertion is called a variety. Given an assertion . =i(pi((x)=0), its corresponding \nvariety is de.ned as Variety(.)={(z .C n |(.i)pi((z)=0} De.nition 2 (Ideals) A set I .R[x1,...,xn]is \nan ideal, if and only if 1. 0 .I, 2. Ifp1,p2 .I then p1 +p2 .I, 3. Ifp1 .I and p2 .R[x1,...,xn]then \np1 p2 .I.  An ideal generated by a set of polynomials P, denoted by ((P))is the smallest ideal containing \nP. Equivalently, g1,...,gm .R[x1,\u00b7\u00b7\u00b7,xn], ((P))=g1 p1 +\u00b7\u00b7\u00b7+gm pm | p1,...,pm .P An ideal I is said to \nbe .nitely generated if there is a .nite set P such that I =((P)). A famous theorem due to Hilbert states \nthat all ideals in R[x1,...,xn]are .nitely generated. As a result, algebraic assertions can be seen as \nthe generators of an ideal and vice-versa. Any ideal de.nes a variety, which is the set of the common \nzeros of all the polynomials it contains. This cor\u00adrespondence between ideals and varieties is one of \nthe fundamen\u00adtal observations involving algebraic assertions called the Hilbert s Nullstellensatz. We \nstate the relevant (and the easy) direction of this theorem below: Theorem 1 (Hilbert s Nullstellensatz) \nConsider an algebraic assertion .. Let I =((.)) be the ideal generated by . in R[x1,...,xn], and f (x1,...,xn).R[x1,...,xn].If \nf .I, then (.(z .C n).((z).(f ((z)=0) i.e, .(z) |=(f (z)=0). PROOF. Let . = f1 =0 .\u00b7\u00b7\u00b7. fm =0 and f .I. \nHence, we can express f as f =g1 f1 +\u00b7\u00b7\u00b7+gm fm for some g1,...,gm . R[x1,...,xn]. Let (z . C n be such \nthat .((z) holds. Then, f ((z)=.mi=1(gi((z)fi((z))=0, since each fi((z)=0. Therefore, we have shown that \n((.z .C n).((z).(f ((z)=0) The theorem shows that membership in an ideal I leads to semantic entailment \nin the variety induced by I. Hence, an ideal is (infor\u00admally) a Consequence-Closed set of polynomials. \nWhile a sim\u00adilar statement can be made in the converse, it is not relevant to the overall soundness of \nour technique, and therefore, we omit it from the discussion. Note that even though the ideals are de.ned \nin R[x1,...,xn], the varieties along with the consequence relations are de.ned over the complex numbers, \nwhich subsume the reals. This is a technicality that arises from the fact that the reals are not algebraically \nclosed. Example 1 Consider the ideal I =(({x2 +1})). The variety cor\u00adresponding to this ideal is the \nset V ={i,-i}, which are the com\u00adplex roots of unity. Any other member of the ideal can be expressed \nas p \u00b7 (x2 +1), where p is an arbitrary polynomial over x. It can be easily seen that each of these polynomials \nis zero at the points where x2 +1 =0, i.e, (. p . I) p(i)=0 . p(-i)=0 In the remainder of this subsection, \nwe use the concept of ideals to derive a systematic algorithm for determining, for a given assertion \n. and a polynomial f , whether f . ((.)). Assume that all the poly\u00adnomials are drawn from R[x1,...,xn], \nand all consequence relations of the form .1 |=.2 are over the domain of complex numbers. Let X ={x1,...,xn} \nbe a set of variables. A power-product over r1 r2 rn X is of the form x \u00b7\u00b7\u00b7 xn , where each ri . N. The \nset of power 1 x2 products will be denoted by PP.A term (also a monomial)is ofthe form c\u00b7 p where c . \nR and p . PP. The set of terms will be denoted by Term. De.nition 3 (Term Orderings) A term ordering \n< is a total and strict ordering on PP that satis.es the following properties: 1. (.t . PP)1 = t, 2. \nif (t1 = t2)then (.t . PP)t1t = t2t.  These orderings can be extended to terms by ignoring the coef.\u00adcients \nand just comparing the power-products. Term orderings will be used to induce a reduction relation over \npolynomials. Many term orderings are used in the literature, the most common being the lexicographic \nand total-degree lexico\u00adgraphic orderings. We assume a linear ordering . on the variables in X. Assuming \nthat x1 . x2 .\u00b7\u00b7\u00b7. xn, the lexicographic extension .lex is de.ned as follows: r1 rn q1 qn x1 \u00b7\u00b7\u00b7 xn .lex \nx1 \u00b7\u00b7\u00b7 xn iff (.i)ri <qi . (. j <i)rj =qj The ordering is lexicographic on the tuple hr1,...,rn) correspond\u00adr1 \nrn ing to a term x1 \u00b7\u00b7\u00b7 xn . A variant of this ordering is called the total\u00addegree lexicographic ordering, \nwhich .rst compares power prod\u00aducts by their total degree, de.ned as the sum of the powers of all the \nvariables. For terms with the same total degree, the lexicographic ordering is used to resolve the tie. \nIn general, the choice of ordering does have a bearing on the complexity of the algorithms, but such \nan effect is beyond the scope of this paper. Given a polynomial g, we de.ne its lead term (denoted LT(g))to \nbe the largest among all its terms w.r.t. a given term-ordering. De.nition 4 (Reduction) Let f , g be \npolynomials, and < be a gterm-ordering. The reduction relation over polynomials, -. is de\u00adg .ned as: \nf -. f' iff there exists term t in f s.t. LT(g)divides p, and f ' t = f - g LT(g) The reduction, in effect \ncancels out the term t that was selected. If no such reduction can be made, then f is said to be a normal-form \ng w.r.t. -. . The reduction can also be extended to a .nite set P of PgP polynomials as f -. f' iff (. \ng . P) f -. f ' . The reduction -. can be shown to be terminating for any .nite set of polynomials P \nas a direct consequence of the de.nition of term-orderings. PP By -, we denote the re.exive transitive \nclosure of the relation -.. A normal form f of the reduction is a polynomial such that there is no further \nreduction that can be carried out on f . The reduction is said to be con.uent if every polynomial reduces \nto a unique normal form. These de.nitions along with their properties are explained in standard textbooks \non term-rewriting systems [1]. If I =((P)), then the reduction relation induced by P can be used to check \nmembership of a given polynomial f in I according to the following theorem: Theorem 2 (Ideal Membership) \nLet I =((P))be an ideal, and f P be a polynomial. If f -0 then f . I. PROOF. Proof proceeds by induction \non the length of the deriva\u00adtion. It is trivially true for zero length derivations, since 0 . I. Let \nP P f -. f' -0. It follows that f' = f - tg, for some suitable term t, and some g . P. Since f'. I (the \ninduction hypothesis), and g . P. Therefore f' +tg . I. Thus, f . I. Example 2 Assume a set of variables \nx,y,z with a precedence or\u00addering x > y > z. Consider the ideal I =((f : x2 - y, g : y - z, h : x +z)), \nand the polynomial p =x2 - y2. We shall use the total lexi\u00adcographic ordering. From the de.nition of \nthe ordering relation, it follows that x2 > z. The lead term in the polynomial f : x2 - zis f x2, which \ndivides the term t : x2 in p. Thus, p -. p' , where 2 x p' =(x2 - y2)- (x2 - y)=(-y2 +y) x2  p tf LT(f \n) The following sequence of reductions shows the membership of p in the ideal h2 h2 g2 g p -. - zx - \ny-. z2 - y-. - yz +z-. - z2 +z2 = 0 I thus p -0, and hence p . I. However, the reduction sequence f ggg \np -. - y2 +y -. - yz +y -. - z2 +y -. - z2 +z reaches a normal-form without showing the ideal membership. \nP Since the reduction -. may not be con.uent, it is not possible to use the theorem to decide membership \nusing an arbitrary ideal basis P. However, given an ideal I, there is a special set of generators G G \nsuch that I =((G)), and the reduction relation -. induced by G is con.uent. Such a basis for I is variously \ncalled the Gr\u00a8obner Basis or Standard Basis of I. Theorem 3 (Gr\u00a8Let I =((P))be an ideal and f be obner \nBasis) G a polynomial. Let G be the Gr\u00a8obner basis of I. f -0 iff f . I. PROOF. A proof of this theorem \ncan be found in any standard text or survey on this topic [12, 21]. Since any reduction is terminating, \nTheorem 3 provides a decision procedure for ideal membership. We shall use NFG(p) to denote G the normal \nform of a polynomial p under -. The subscript G in NFG(p) may be dropped if it is evident from the context. \nThe standard algorithm for computing the Gr\u00a8obner basis of an ideal is known as the Buchberger algorithm. \nThere are numerous im\u00adplementations of this algorithm available with standard computer\u00adalgebra packages \nand polynomial computation libraries. As an example, the library GROEBNER implements many improvements \nover the standard algorithm [30]. Example 3 Consider again the ideal from Example 2; I =((f : ' x2 - \ny, g : y - z, h : x +z)). The Gr\u00a8obner basis for I is G = { f : z2 - z, g : y - z, h : x +z}. With this \nbasis, every reduction of p : x2 - y2 will yield a normal form 0.  Templates Our technique for invariant \ngeneration aims to .nd polynomials which satisfy certain properties. To represent these sets of poly\u00adnomials \nwe use templates, which are polynomials with coef.cients that are linear expressions over some set of \ntemplate variables. In this subsection, we show that the theory of ideals can be natu\u00adrally extended \nto templates. In particular, we show that there ex\u00adist con.uent reductions on templates that allow the \ngeneration of constraints on the template variables, such that the resulting set of polynomials is precisely \nthe set of polynomials that belong to the corresponding ideal. De.nition 5 (Templates) Let A be a set \nof template variables and L(A) be the domain of all linear expressions over variables in A of the form \nc0 +c1a1 +...+cnan, where each ci is a real valued coef.cient. A template over A,X is a polynomial over \nvariables in X with coef.cients drawn from L(A). Example 4 Let A ={a1,a2,a3}, hence L(A) is the set of \nexpres\u00adsions L(A)={c0 +c1a1 +c2a2 +c3a3 | c0,...,c3 . R} The set of templates lies in the ring L(A)[x1,...,xn]. \nAs an example, consider the template (2a2 +3)x1x22 +(3a3)x2 +(4a3 +a1 +10) De.nition 6 (Semantics of \nTemplates) Given a set of template variables A, an A-environment (if A is clear from the context, then \nsimply an environment) is a map a that assigns real values to each variable in A. Hence, this map can \nbe naturally extended to map expressions in L(A)to their corresponding values in R, and to map polynomials \nin L(A)[x1,...,xn]to their corresponding polynomials in R[x1,...,xn]. Example 5 The environment a =ha1 \n=0,a2 =1,a3 =2), maps the template (2a2 +3)x1x22 +(3a3)x2 +(4a3 +a1 +10) from Example 4 to the polynomial \n5x1x22 +6x2 +18 g The reduction -. for polynomials can be extended to a reduction for templates in a \nnatural way. De.nition 7 (Reduction of Templates) Let p be a polynomial in ' R[x1,...,xn] and f , f be \ntemplates over A and {x1,...,xn}. The p ' reduction relation is de.ned as: f -. f iff the lead term LT(p) \ndivides a term c \u00b7 t in f with coef.cient c(a0,...,am)and c \u00b7 t ' f = f - p LT(p) Note that the reduction \nis de.ned to be the same as the reduction relation over polynomials. This can, in turn, be extended to \nsets G of polynomials to de.ne reductions -. over templates for sets of polynomials G. Henceforth, we \nshall use the symbols f ,g with subscripts to denote templates and the symbols h,p to denote poly\u00adnomials. \nExample 6 Let p be the polynomial x2 - y, with LT(p)=x2. Con\u00adsider the template f : ax2 +by2 +cz2 +dz \n+e p ' The lead term LT(p)divides the term ax2 in f . Therefore, f -. f, where 2 ax ' f : (ax2 +by2 +cz2 \n+dz+e)- (x2 - y)=by2 +cz2 +dz+e+ay x2 Given a template f and an ideal I, we are interested in .nding \nthose environments a such that a(f ) . I. We achieve this by obtaining constraints on the environment \nvariables A such that any solution a satis.es a(f ). I. The properties of the Gr\u00a8obner basis reduction \nover polynomials can be extended smoothly to templates. Proofs of these results can be found in the appendix. \nWe .rst show that the extension of reduc\u00adtion is consistent w.r.t. the semantics of templates under any \nA\u00adenvironment. The con.uence of Gr\u00a8obner basis reduction over tem\u00adplates, guarantees that a unique normal \nform exists for any template (Theorem 11). The template membership theorem (Theorem 13) proves that if \nf1 = NFG(f ) is the normal form of f , then for each environment a, a(f ). ((G))iff a(f1) is identically \nzero. Theorem 4 (Zero Polynomial Theorem) A polynomial p is zero for all the possible values of x1,...,xn \niff all its coef.cients are identically zero. PROOF. Proof proceeds by induction on the number of variables \nn. For n = 1, the result is immediate from the fundamental theorem of algebra, restricting the number \nof roots of a non-zero univariate polynomial of degree n. Therefore, a non-zero polynomial cannot be \nzero everywhere. Let us assume that the result is true for all poly\u00adnomials in n - 1 variables. Let p \n= p0 +p1xn +...+pmxm, where n each pi is a polynomial in x1,...,xn-1. For any value a1,...,an-1 of these \nn - 1 variables, the polynomial p = p0(a1,...,an-1)+ p1(a1,...,an-1)xn +\u00b7\u00b7\u00b7 + pm(a1,...,an-1)xm is identically \nzero n for all xn and hence each pi is identically zero for all possible val\u00adues a1,...,an-1. Using the \ninductive hypothesis, every coef.cient in each pi is zero, and hence, all the coef.cients of p are zero. \nGiven a template f and an ideal I with Gr\u00a8obner basis G, we .rst compute NFG(f ), and then, equate each \ncoef.cient of the normal form to zero to obtain a set of equations over the template variables A. Any \nsolution to this set of equations yields an A environment a such that a(f ). I (and conversely). Example \n7 Let I be the ideal ((x2 -y, y -z, z + x)) of Example 2 with Gr\u00a8obner basis G = {x + z, y -z,z2 -z}. \nWe are interested in polynomials represented by the template ax2 + by2 + cz2 + dz + e that are members \nof the ideal. The normal form of this template is (a + b + c + d)z + e Equating each coef.cient in the \nnormal form to zero, we obtain a + b + c + d = 0 e = 0 From this, we can generate all instances of the \ntemplate that be\u00ad 2 long to I. Some examples are x2 -y, y2 -z, 2x2 -z2 -z. On the other hand, x2 + y2 \n-z. I, as the coef.cients do not satisfy the constraints.  Transition Systems and Invariants We begin \nby de.ning transition systems in general. De.nition 8 (Transition System) A transition system is a tuple \nhV,L,T ,e0,T), where V is a set of variables, Lisasetof loca\u00adtions, T is a set of transitions. A state \ns is an interpretation of the variables in V. Each transition t . T is a tuple hl1,l2,.t), where l1 and \nl2 are the pre-and post-locations of the transition. The transition relation .t is a .rst-order assertion \nover V .V ' , where V denotes the current-state variables and V ' denotes the next-state variables. The \nlocation e0 . Listhe initial location, and T is a .rst-order assertion over V denoting the initial condition. \ninteger i, j,s where(s = 0 . j = j0) l0: while (\u00b7\u00b7\u00b7) do l1: (s, j) :=(s + i, j -1) Figure 1. A program \nto multiply two numbers. It is a well known fact from the pioneering work of Floyd and Hoare [14, 16], \nthat if . is an inductive assertion map then .(l) is invariant at l. Furthermore, for general transition \nsystems, given any invariant . at l, there is an inductive assertion map . such that ..() impliestheinvariant \n.Infact,allknowninvariantgeneration l. methods are inductive assertion generation methods.   Algebraic \nTransition Systems We now specialize general transition systems into algebraic transi\u00adtion systems. De.nition \n11 (Algebraic Transition System) An algebraic tran\u00adsition system is a transition system hV,L,T ,e0,T), \nsuch that, for each transition t, the transition relation .t is an algebraic asser\u00adtion over V .V ' , \nand the initial condition T is an algebraic asser\u00adtion over V. Example 8 Consider the loop program to \nmultiply two numbers shown in Figure 1. The corresponding transition system is given by V = {i, j,s, \nj0} L = {l0} T = {t1}, where ' s -s -i = 0 j '- j + 1 = 0 . t1:l0,l0, .. .. i '-i = 0 Transition systems \nare the standard representation for many types of programs. A more detailed presentation of these systems \ncan be found in [20]. Given a transition system, we de.ne its transi\u00adtion graph with locations labeled \nby vertices and edges labeled by transitions, such that each edge connects the pre-location and the post-location \nof its labeling transition. Given a path p in this graph, we de.ne the transition relation .p corresponding \nto p as the rela\u00adtional composition of all the transition relations labeling the edges along the path. \nDe.nition 9 (Invariant) Let P =hV,L,T ,l0,T) be a transition system. An invariant at a location l . L \nis de.ned as an assertion . over V , such that . holds on all the states that can be reached at location \nl. An invariant of the transition system is an assertion . which holds at all the locations of the transition \nsystem. Given a domain of assertions D,an assertion-map for a transition system is a map . : L .D that \nassociates each location of the tran\u00adsition system with an assertion. De.nition 10 (Inductive Assertion \nMap) An assertion map . is said to be inductive iff the following conditions hold: Initiation The assertion \nat l0 subsumes the initial condition, T |= .(l0) Consecution For each transition t from li to l j, .(li) \n. .t |= .(lj)' j ' 0 - j0 = 0 e0 = l0 which is an algebraic transition system. For algebraic transition \nsystems in general, the composition of tran\u00adsition relations along a path may lie outside the domain \nof algebraic transitions. However, if the transition relations are separable, that is, each variable \nin V ' is expressed as a polynomial expression over the variables in V , we can compose relations along \nany path. For instance, the transition system in Example 8 is separable. Corresponding to general assertion \nmaps, we de.ne an algebraic assertion map ., wherein each location l is mapped to an asser\u00adtion .(l) \nof the form p = 0. We shall use .(l) to denote both the assertion p = 0 and the polynomial p. 3 Constraint \nGeneration In this section, we present the basic algorithm for invariant gener\u00adation in algebraic transition \nsystems. Given an algebraic transition system, we .rst de.ne a template map that maps each location to \na template over a set of abstract coef.cient variables A. We then generate constraints on all the template \nvariables A, guaranteeing that any solution to these constraints corresponds to an inductive assertion \nmap. De.nition 12 (Template Map) Let P =hV,L,T ,l0,T)be an alge\u00adbraic transition system. Assuming a set \nof template variables A, an When the variables in A are instantiated to real values, the invari\u00adant template \nis then specialized to a polynomial assertion map. The problem that we intend to tackle in this section \nis as follows: Given an algebraic transition system with a template map, compute con\u00adstraints on the \ntemplate variables A, such that any solution to these constraints specializes the template to a valid \ninductive assertion map. The solution to the problem involves encoding the initiation and the consecution \nconditions that any inductive assertion map must satisfy. In practice, if the transitions can be composed, \nit is more effective to do this over partial maps by selecting a suitable set of cutpoints. The example \nbelow shows a (rather lengthy) template that will be used as a running example. Example. Consider the \nexample transition system in Example 8. Since there is one location l0, we set the .(l0) to be a generic \nquadratic form on {s, i, j, j0} as shown below: . . a0s2 +a1s +a2si +a3sj +a4sj0 +a5i2+ .(l0) : a6i +a7ij \n+a8ij0 +a9 j2+ . . a10 j +a11 jj0 +a12 j02 +a13 j0 +a14  Encoding Initiation Initiation is expressed \nby encoding the membership of .(l0) to the ideal generated by the initial assertion T, i.e., .(l0) . \n((T)) which in turn implies T |= .(l0) by the Nullstellensatz. The following are the steps involved in \nthe encoding: 1. Compute the Gr\u00a8obner basis G for ((T)), 2. Reduce the template .(l0) using G, to compute \nf = NF(.(l0)), 3. For each term in f , equate the coef.cient expression of the term to zero, in order \nto obtain a constraint. The overall ini\u00adtiation constraint is the conjunction of all the constraints \nthus obtained.  Example 9 We now generate initiation constraints for the system in Example 8. The Gr\u00a8obner \nbasis of T : s = 0 . j - j0 = 0 is G = {s, j - j0}. The normal form of .(l0) w.r.t. G is f =a5i2 +a6i+(a7 \n+a8)ij0 +(a9 +a11 +a12)j02 +(a10 +a13)j0 +a14 Setting each coef.cient expression to zero, we obtain the \nconstraints a5 = a6 = a14 = 0 a7 +a8 = 0 a9 +a11 +a12 = 0 a10 +a13 = 0  Encoding Consecution For each \nlocation li and for each transition t : li,lj,. , consecution can be expressed by the implication ' (.(li)= \n0) . . |=(.(lj)= 0) There are two cases to consider here, one when the antecedent .(li)= 0 . . is satis.able, \ni.e., t is an enabled transition; the other case occurs when the antecedent is unsatis.able, i.e., t \nis disabled. The disabled case consists of encoding . |= .(li)= 0 This is achieved by computing the normal \nform of the reduction of .(li) by the Gr\u00a8obner basis of ((.)). The normal form is set to be identical \nto a scalar different from zero. Thus all the terms in this normal form except the constant term have \ntheir coef.cients set to zero, and the constant term is required to be non-zero. The rest of the section \ndeals with the enabled case. An Exact but Impractical Encoding The .rst approach to encoding the enabled \ncase of the consecution condition is similar to that of the initiation condition, i.e., to com\u00adpute the \nGr\u00a8obner basis of the ideal generated by .(li)= 0 ..t. The ' normal form of .(lj)is computed and constraints \non the template variables that ensure that this normal form is identical to zero are obtained. However, \nthe assertion .(li)=0..t contains a template. Hence, a variant of the Gr\u00a8obner basis construction, resulting \nin a basis known as the Comprehensive Gr\u00a8obner basis [28], is required. The comprehensive basis is a \nset of condition-basis pairs (.,G), where . is a non-linear constraint on the template variables, and \nG is a Gr\u00a8obner basis involving template polynomials with non-linear coef.cient expressions. For each \nsuch pair, computing the nor\u00ad ' mal form of .(lj)under G, and equating each coef.cient of each normal \nform to zero yields constraints .1 over the template vari\u00adables. The overall constraint for the pair \nis . . .1. Unfortunately, this approach, though exact, is impractical, because the number of condition-basis \npairs produced on a generic polynomial template is large, and the nonlinear constraints produced make \nthe constraint solving problem intractable, even for simple programs. Hence, we resort to an alternative \napproach that uses a stronger con\u00adsequence relation to avoid the explicit construction of the compre\u00adhensive \nGr\u00a8obner basis but in doing so, we sacri.ce completeness. A Practical Alternative The original consecution \ncondition for a the assertion map . re\u00adquires that the values after the transition are zero whenever \nthe val\u00adues before the transition is taken are zero. We de.ne three increas\u00adingly stronger relations \non the values of the invariant before and after the transition. De.nition 13 (Alternative Consequence \nRelations) Let t be the transition li,lj,. and . be an algebraic assertion map. We de.ne the following \nincreasingly stronger notions of consecution: 1. . satis.es polynomial-scale consecution (PS) for t iff \nthere exists a polynomial p such that . |=(.(lj)'- p.(li)= 0) 2. . satis.es constant-scale consecution \n(CS) for t iff there exists a real valued parameter . s.t. . |=(.(lj)'- ..(li)= 0) 3. . satis.es constant-value \nconsecution (CV) for t iff ' . |=(.(lj)-.(li)=0) 4. . satis.es local-consecution (LC) for t iff ' . |=(.(lj)=0) \nLC consecution states that .(lj)' is zero upon taking the transition, independent of .(li). CV consecution \nencodes the fact that the nu\u00admerical value of the assertion does not change through the transi\u00adtion. \nThe CS consecution on the other hand encodes the fact that the numerical value of the assertion after \nthe transition is taken is a con\u00ad 2. Introducing a real parameter ., we set each coef.cient of the polynomial \n. f -g to zero, obtaining constraints involving the template variables, and the parameter .. 3. The \nresulting constraint involving the template variables, and the parameter . is existentially quanti.ed \nby ..  The overall constraint for the consecution of t is a disjunction of the constraints for the enabled \ncase and that for the disabled case. We illustrate this by encoding the consecution for our running example. \nExample 10 Returning to the transition system in Example 8, The only transition is t1, with transition \nrelation .. ' s -s -i =0 j '- j +1 =0 i '-i =0 stant multiple of the numerical value prior to the transition. \nEach .t1: .. .. consecution can be seen as a generalization of the next consecu\u00ad j0 '- j0 =0 tion. For \ninstance, CV consecution can be seen as CS consecution for . =1. Similarly, LC consecution is again a \nspecial case of CS which corresponds to the Gr\u00a8obner basis {s '-s -i, j '- j +1,i '- 0 - j0}, generated \nunder the total-degree lexicographic ordering for . =0. CS consecution results when the polynomial p \nin PS i, j ' consecution is of degree 0. We now show that any assertion map with the precedence that \nsatis.es PS consecution also satis.es (exact) consecution. This implies similar results for CV and CS \nconsecutions. ' s > j ' > i ' > j0 ' >s > j > i > j0 The normal form of .'(l0)is given by Theorem 5 Let \nt : li,lj,. be a transition, and . be a polynomial .. a0s2 +(2a0 +a2)si +(a1 -a3)s +a3sj+ assertion \nmap. ' f = 1. If . satis.es CV consecution for t then it satis.es CS conse\u00ad cution. a4sj0 +(a0 +a2 +a5)i2 \n+(a1 -a3 +a6 -a7)i+ (a3 +a7)ij +(a4 +a8)ij0 +a9 j2+ (a10 -2a9)j +a11 jj0 +a12 j02+ ..... ..... 2. If \n. satis.es CS consecution for t then it satis.es PS consecu\u00adtion. 3. If . satis.es PS consecution for \nt then it satis.es (exact) con\u00adsecution.  PROOF. (1) and (2) follow directly from the de.nitions. We \nshall prove (3). Since . satis.es PS, . p such that, ' . |=(.(lj)-p.(li)=0) Assuming that .(li)=0 . ., \nwe obtain ' '' .(lj)-p \u00b7.(li)=.(lj)-p \u00b70 =.(lj)=0 Thus, assuming .(li)=0 . ., we obtain .(lj)' =0. This \nshows that . satis.es consecution w.r.t. t. Thus, if an assertion map satis.es initiation, and any of \nthe three restricted consecutions for each transition, then it is an inductive assertion map. In practice, \nwe .nd that using CS consecution pro\u00adduces useful invariants without making the constraint solving prob\u00adlem \nintractable. The following theorem suggests a method to en\u00adcode CS consecution: Theorem 6 Let G ={g1,...,gm} \nbe the Gr\u00a8obner basis of asser\u00adtion ., and p1,p2 be polynomials. Let p ' =NFG(pi), for i =1,2 i ' and \n. be a real-valued parameter. If p ' 1 -.p2 =0, then . |=(p1 -.p2 =0) The enabled case of consecution \nis encoded using CS consecution as follows: 1. Let f = NFG(.(li)) and g = NFG(.(lj)'), where G is the \nGr\u00a8obner basis of .. (a13 -a11)j0 +(a9 -a10 +a14) The template .(l0)remains unaltered by the reduction. \nHence, set\u00adting (..)NF(.(l0)')=. \u00b7NF(.(l0)) gives us the following constraints for the enabled case: \na0 =.a0 2a0 +a2 =.a2 a0 +a2 +a5 =.a5 a1 -a3 =.a1 a1 -a3 +a6 -a7 =.a6 a3 =.a3 a3 +a7 =.a7 a4 =.a4 a4 +a8 \n=.a8 a9 =.a9 a10 -2a9 =.a10 a9 -a10 +a14 =.a14 a11 =.a11 a13 -a11 =.a13 a12 =.a12 The solution to these \nconstraints is discussed in the next section. As mentioned above, the normal form of .(l0) w.r.t. the \nGr\u00a8obner basis for . is itself, thus yielding the following constraints for the disabled case. a1 =a2 \n=\u00b7\u00b7\u00b7=a13 =0 . a14 =0 The overall constraint for a template map being inductive is given by the conjunction \nof the initiation and the consecution constraints. Let .T be the initiation constraint and .t be the \nconstraint corre\u00adsponding to the consecution for transition t. Then the overall con\u00adstraints . are given \nby ^ . = .T . .t t.T Theorem 7 (Soundness) For any solution a of ., the instantiation of the template \nmap . with the solution values is an inductive as\u00adsertion map. PROOF. Since the solution set satis.es \n., it must satisfy each in\u00addividual .t along with .T. Since the constraint set satis.es the .T, the normal \nform of [[.(l0)]] is identically zero. By Theorem 8, [[.(li)]] .((T)), and by Theorem 1, T |=[[.(li)]] \n= 0. Thus initia\u00adtion holds. Similarly, the constraints for consecution ensure that for some ., [[NF(.(lj)')]] \n-.[[NF(.(li))]] = 0 This implies .t |=[[.(lj)']] -.[[.(li)]] = 0 by Theorem 6. Therefore, [[.]] satis.es \nCS consecution for each transition t. Thus we have shown that [[.]] satis.es the conditions of initiation \nand consecution for each transition. Therefore [[.]] is an inductive assertion map. The converse of this \ntheorem (completeness) does not hold due to our choice of a stronger consecution condition that is satis.ed \nby fewer inductive assertion maps. So far, we have reduced the invari\u00adant generation problem for algebraic \ntransition systems to a set of constraints, such that any solution to these constraints forms an in\u00advariant. \nSolution methods to these constraints are discussed in the next section. The complexity of the constraint \ngeneration process is linear in the size of the transition relation and the number of template variables. \nThe Gr\u00a8obner bases need to be computed only over initial condi\u00adtions and transitions, which can be done \nef.ciently. The number of Gr\u00a8obner basis computations is linear in the program size. The reduction process \ncan also be done ef.ciently, the number of reduc\u00adtions required being roughly linear in the size of the \ntemplate to be reduced, if the template is a generic polynomial of a .xed degree.  4 Solving Constraints \nIn this section, we discuss techniques for solving the system of equations generated by the method described \nin Section 3. The constraints corresponding to the initiation and the disabled case for consecution are \nlinear whereas the constraints corresponding to the enabled case of consecution vary depending on the \nconsecution re\u00adlation used. For the LC and CV cases, these constraints are linear equalities. For the \nCS consecution the constraints are non-linear, more speci.cally Parametric Linear Constraints. We shall \n.rst dis\u00adcuss the structure of these constraints in detail and then discuss solution techniques. We do \nnot discuss techniques for the more general PS consecution. The constraint types are summarized in Figure \n2. De.nition 14 (Parametric Linear Constraint) Let A be the set of abstract variables and . be a set \nof multiplier variables. A para\u00admetric linear constraint is of the form l0 + .1l1 + \u00b7\u00b7\u00b7+ .mlm = 0 where, \nl0,...,lm . L(A) are linear expressions in A and . = {.1,...,.m}, .i .R. A linear constraint is of the \nform l0 = 0. Similarly, a transform is of the form c0 + c1.1 + \u00b7\u00b7\u00b7+ cm.m = 0 where, c0,...,cm .R. The \nconstraint is factorizable iff l0 = c1l1 = \u00b7\u00b7\u00b7 = cmlm for some real constants c1,...cm. In such a case \nwe express the constraint as l0 + .1l1 + \u00b7\u00b7\u00b7+ .mlm = l0(1 + c1.1 + \u00b7\u00b7\u00b7+ cm.m) a product of a linear constraint \nand a transform constraint. The con\u00adstraint generation algorithm provides us with a set of constraints. \nSome of the constraints (initiation constraints) are linear whereas the constraints from consecution \nare parametric linear constraints. The parameters in . are all existentially quanti.ed. In the remain\u00adder \nof this section we discuss some techniques to eliminate the quanti.ers.  Elimination by Splitting The \nsimplest technique for elimination is a CLP-style [17] elimina\u00adtion algorithm that maintains the linear \nconstraints in a constraint store and repeatedly linearizes the remaining constraints. The main advantage \nof this technique is its ef.ciency. It has been observed to be fast and memory ef.cient in practice. \nFurthermore, it preserves the parametric linear form throughout the elimination process. On the other \nhand, it may not be able to remove all instances of the parameter. In such a case, we resort to more \ngeneral elimination techniques. The following is a brief sketch of the technique: Constraint-Store The \nconstraint store is a set of linear constraints over the variables in A. We store these constraints in \nterms of a matrix that is always kept in a reduced row form using the standard Gaussian elimination. \nThe operations supported by the store include the addition of a new constraint and the sim\u00adpli.cation \nof a given parametric linear constraint to a normal form. The following are the major steps involved: \n1. Each linear constraint is added to the constraint store and each transform constraint is used to eliminate \none of the multipliers involved in the constraint system by rewriting it in terms of the remaining parameters. \n 2. Each factorizable constraint leads to a split into two cases, one where the linear constraint is \nadded to the store, and the other where the transform constraint is applied to remove one multiplier \nfrom the system. Care must be taken to avoid in\u00adconsistent branches on a split. For instance a split \non a = 0in a branch should not be followed by a split on a = 0.  The steps shown above are repeated \nuntil the branch is unsatis.able or all the constraints have been linearized. In almost all the ob\u00adserved \ncases, a majority of the branches are completely linearized, and only a few branches with unresolved \nparametric linear con\u00adstraints remain. The latter can be resolved by generating more lin\u00adear constraints \nas hints to help simplify the non-linear constraints further. These constraints can be obtained by choosing \npaths p start\u00ading from l0 ending in l and encoding the condition T ..p |= .(l)' where .p represents the \ncomposition of the transition relations along p. Soundness can be shown to be preserved by these op\u00aderations. \nFurthermore, the solution set can also be shown to be preserved. Condition Restriction Constraint types \nInitiation linear equalities Consecution Local (LC) Constant Value (CV) Constant Scale (CS) Polynomial \nScale (PS) linear equalities linear equalities parametric linear non-linear algebraic Figure 2. Constraints \nobtained from different conditions for inductive assertions Example 11 To illustrate the technique, we \nsolve the constraints for the enabled case of consecution for Example 8, recalled below from Example \n10. a0 = .a0 2a0 + a2 = .a2 a0 + a2 + a5 = .a5 a1 -a3 = .a1 a1 -a3 + a6 -a7 = .a6 a3 = .a3 a3 + a7 = \n.a7 a4 = .a4 a4 + a8 = .a8 a9 = .a9 a10 -2a9 = .a10 a9 -a10 + a14 = .a14 a11 = .a11 a13 -a11 = .a13 a12 \n= .a12 Factorizing, (1 -.)a0 = 0,weget 1 -. = 0 or a0 = 0,1 -. = 0. In the .rst case, we rewrite all \noccurrences of . by 1, resulting in the constraints a0 = a2 = a3 = a4 = a9 = a10 = a11 = 0 a1 -a7 = 0 \nRepeating the strategy on the other branch, we obtain a0 = a3 = a4 = a9 = a11 = a13 = 0 2a0 + a2 = .a2 \na0 + a2 + a5 = .a5 a1 -a3 = .a1 a1 -a3 + a6 -a7 = .a6 a3 + a7 = .a7 a4 + a8 = .a8 a10 -2a9 = .a10 a9 \n-a10 + a14 = .a14 a13 -a11 = .a13 By simplifying and repeating the strategy, we .nally obtain a0 = a1 \n= \u00b7\u00b7\u00b7= a14 = 0 Thus combining with the initiation constraints, we obtain a{0,2,3,4,5,6,9,10,11,12,13,14} \n= 0 a1 -a7 = 0 a7 + a8 = 0 This in turn simpli.es to yield: a1 = a7 = -a8, while all the other coef.cients \nare zero. This corresponds to the invariant s = i( j0 - j)  Generic Elimination Techniques Ifthesimpleeliminationbyfactorizationtechniquefails,weresort \n. to more general techniques for quanti.er elimination. We summa\u00adrize the viable approaches to this problem. \nThe .rst generic elimi\u00adnation technique casts the constraints obtained as a matrix equation B(a = 0 where \n(a is a vector of variables from A, and B is a parametric matrix whose entries are linear expressions \nover the parameters. As a rule, the matrices involved are sparse in terms of the number of non\u00adzero entries \ninvolving the parameters. The resulting problem can be treated using Gaussian Elimination with a few \nmodi.cations. There has been some attention to solving these types of constraints [24, 2]. In contrast \nto constraints tailored to parametric linear constraints, more general quanti.er elimination techniques \nmay be used. Since the constraints are non-linear with real-valued variables, we can use real quanti.er \nelimination tools to solve these constraints. A brief summary of the related work on this topic follows. \nTarski [25], established the decidability of quanti.er elimination over the theory of reals with multiplication. \nHowever, the algo\u00adrithm suggested by Tarski is non-elementary. This was remedied by Collins [7] using \na technique called Cylindric Algebraic De\u00adcomposition. Collins and Hong [8] present an ef.cient version \nof this technique called Partial Cylindric Algebraic Decomposi\u00adtion, implemented in the tool QEPCAD. \nAn alternative approach called the elimination at test point technique is taken by Weispfen\u00adning [27, \n29]. The method is ef.cient over low degree polynomials and has been implemented in the tool REDLOG [13]. \nEven though these methods have high time and space complexities, we .nd that for most constraints we \ndo not require these generic elimination techniques.  5 Applications To show the viability of our approach, \nwe present some application examples.  Generalized Readers-Writers Consider the following transition \nsystem with variables r, w, k, k0, c1, c2, modeling a generalization of the readers-writers problem. \nV = {r, w, k,c1,c2,k0} L = {l0} T = {t1,t2,t3,t4}  . w = 0 r ' = r + 1 = k -c1 .. id(w,c1,c2,k0) .. \n. .  y1 =x1 . y2 =x2 y3 =1 . y4 =0 k ' =k - c2 real y1,y2,y3,y4,x1,x2 where . .. t2: l0,l0, id(r,c1,c2,k0) \nl0: while (y1 = y2)do . w =0 ' r =r - 1 k ' =k +c1 .. .. t3: l0,l0, .. l1 a : if (y1 = y2)then (y1,y4):=(y1 \n- y2,y4 +y3) l1 b : if (y3 =1)then return (q =y4, r =y1) id(w,c1,c2,k0) r =0 .... .... . w ' =w - 1 k \n' =k +c2 .. .. t4: l0,l0, y3 (y2,y3):=(y22 , ) lc 1: 2 id(r,c1,c2,k0) T : (r =0 . w =0 . k =k0) e0 =l0 \nThe number of readers and writers are represented by r and w re\u00adspectively. Initially we assume k =k0 \ntokens to be present. Transi\u00adtion t1 models a reader obtaining access by checking if no writers are present, \nand obtaining c1 tokens. Similarly transition t2 models a writer entering by obtaining c2 tokens. Transition \nt3,t4 model the readers and the writers giving up access. The target assertion at l0 is a generic degree \ntwo template. The simpli.cation and factorization technique was suf.cient to eliminate all the quanti.ers. \nThe .nal invariants obtained are rc1 +wc2 +k =k0 . rw =0 The former accounts for the tokens during the \nrun of the program, while the latter establishes mutual exclusion between the readers and the writers. \n LCM-GCD Algorithm Figure 4. Hardware Style Division Algorithm Hardware Style Division Algorithm Figure \n4 shows a procedure, taken from [19], to divide two numbers x1 and x2, which we model as reals, in order \nto apply our technique. The branch conditions that involve inequalities are modeled as non\u00addeterministic \nchoices. The cutpoints used are l0 and l1. The target invariant at locations l0 and l1 were degree two \ntemplates, yield\u00ading a total of 56 template variables. Expressing the program as a transition system, \nwe obtain four transitions, one self-loop around l0, two loops around l1 and one transition from l0 to \nl1. The con\u00adstraints generated were simpli.ed using factorization and lineariza\u00adtions. All but two of \nthe cases in the result were linear. The remain\u00ading two cases contained simple two variable quanti.er \nelimination instances that were resolved by hand. The following invariants were obtained at l0 and l1: \n.(l0): y1 =x1 .(l1): true .(l0): y4 =0 .(l1): true .(l0): .1 = y2 - y3x2 =0 .(l1): .1 = y2 - y3x2 =0 \nOn strengthening the transition relations with the invariants above, . y1 =x1. and repeating the process, \nwe obtained additional invariant .2: integer x1,x2,y1,y2,y3,y4 where y2 =y3 =x2. . y1y3 +y2y4 - y3x1 \n=0at l0,l1. y4 =0 The loop exits when y3 =1, q =y4, r =y1. Substituting this on the . l1: while (y1 \n> y2)do invariants obtained at l1, we obtain that .2: x1 =r +qy2 and y2 = l1 a : (y1,y4):=(y1 - y2,y4 \n+y3) l2: while (y2 > y1)do x2. Therefore, we can infer x1 =r +x2q at the loop exit. This shows .. one \nof the speci.cations of the division algorithm, the other being y1 < x1, which lies outside the domain \nof algebraic invariants. Note that some additional invariants are required to justify the fact that the \ndivision in l1 c is applied to integers that are always even. These invariants are, however, not expressible \nin our assertion language.  6 Conclusion l2 a : (y2,y3):=(y2 - y1,y3 +y4) {y1 = GCD(x1,x2), y3 +y4 \n=LCM(x1,x2)} Figure 3. Simultaneous LCM-GCD algorithm Figure 3 shows a program that calculates the lcm \nand gcd of in\u00adtegers x1 and x2. The integers are modeled as reals for our pur-In this paper, we presented \na reduction from the algebraic invariant pose and the loop conditions at the head of the while loops \nare generation problem for algebraic transition systems to a paramet\u00adabstracted to non-deterministic \nchoices since they lie outside the ric linear constraint solving problem, so that any solution to the \ndomain of algebraic assertions. This leads to a transition relation constraints corresponds to an inductive \nassertion. The technique with two loops around the single location l0. The target invariant has many \nadvantages; .rst of all, the degree of the desired invari\u00adfor location l0 is a generic degree two template. \nThe application ant does not affect the constraint problem. Secondly, the constraint of the technique \nproduced constraints that resolved completely on solving problem can almost always be handled by simple \nelimina\u00adfactorization and simpli.cation. The resulting invariant obtained tion techniques. With a good \nconstraint handling strategy, we are at l0 is y1y3 +y2y4 =x1x2. Applying the exit condition y1 =y2 con.dent \nthat the technique will scale to larger examples. On the yields, y1(y3 +y4)=x1x2. Assuming that y1 = \nGCD(x1,x2)and other hand, a drawback of the technique is its lack of completeness y3 +y4 =LCM(x1,x2), \nthe invariant states that LCM(x1,x2)\u00b7 GCD(x1,x2)=x1x2 arising from the restrictions placed on the consecution \ncondition. While many tried and tested methods in the .eld of static analy\u00ad sis and program veri.cation \ndo not insist on completeness, the lack Note that correctness cannot be inferred directly since LCM and \nof completeness can sometimes cause these methods to miss ob-GCD functions cannot be expressed algebraically. \nvious invariants for subtle reasons, as has been observed in tradi\u00adtional invariant generation technique \nusing widening [9]. We are working on identifying useful classes of systems where restricted notions \nof consecution suf.ce. Currently inequalities are handled as non-deterministic choices. We are developing \nmodi.cations of the technique that are able to reason with loops involving inequali\u00adties. The technique \nalso requires that the degree bounds on the target as\u00adsertion be known a priori. This is a drawback for \nsome applications and effective strategies on selecting the degree bounds of the invari\u00adant need to be \nstudied. We are also working on comparisons with related approaches like [22] that may yield techniques \nto eliminate some of these drawbacks. Acknowledgements: We would like to thank the anonymous review\u00aders \nfor their detailed comments on an earlier version of this paper.  7 References [1] BAADER,F., AND NIPKOW,T. \nTerm Rewriting and All That. Cambridge University Press, 1998. [2] BALLARIN, C., AND KAUERS, M. Solving \nparametric lin\u00adear systems: an experiment with constraint algebraic pro\u00adgramming. In Eighth Rhine Workshop \non Computer Algebra (2002), pp. 101 114. [3] BENSALEM, S., BOZGA, M., FERNANDEZ, J.-C., GHIRVU, L., AND \nLAKHNECH, Y. A transformational approach for generating non-linear invariants. In Static Analysis Sympo\u00adsium \n(June 2000), vol. 1824 of LNCS, Springer Verlag. [4] BENSALEM, S., LAKHNECH,Y., AND SAIDI,H. Pow\u00aderful \ntechniques for the automatic generation of invariants. In Computer-Aided Veri.cation (1996), vol. 1102 \nof LNCS, pp. 323 335. [5] BJ\u00d8RNER, N. S., BROWNE, A., AND MANNA, Z. Automatic generation of invariants \nand intermediate assertions. Theoret\u00adical Comput. Sci. 173, 1 (Feb. 1997), 49 87. [6] BULTAN,T., GERBER, \nR., AND PUGH, W. Symbolic model checking of in.nite state systems using Presburger arithmetic. In Computer-Aided \nVeri.cation (June 1997), vol. 1254 of LNCS, springer, pp. 400 411. [7] COLLINS, G. Quanti.er elimination \nfor real closed .elds by cylindrical algebraic decomposition. In Automata Theory and Formal Languages \n(1975), H.Brakhage, Ed., vol. 33 of LNCS, pp. 134 183. [8] COLLINS,G.E., ANDHONG,H.Partialcylindricalalgebraic \ndecomposition for quanti.er elimination. Journal of Symbolic Computation 12, 3 (sep 1991), 299 328. [9] \nCOL\u00b4 ON, M., SANKARANARAYANAN, S., AND SIPMA,H. Linear invariant generation using non-linear constraint \nsolv\u00ading. In Computer Aided Veri.cation (July 2003), F. Somenzi and W. H. Jr, Eds., vol. 2725 of LNCS, \nSpringer Verlag, pp. 420 433. [10] COUSOT,P., AND COUSOT, R. Abstract Interpretation: A uni.ed lattice \nmodel for static analysis of programs by con\u00adstruction or approximation of .xpoints. In ACM Principles \nof Programming Languages (1977), pp. 238 252. [11] COUSOT,P., AND HALBWACHS, N. Automatic discovery of \nlinear restraints among the variables of a program. In ACM Principles of Programming Languages (Jan. \n1978), pp. 84 97. [12] COX, D., LITTLE, J., AND O SHEA,D. Ideals, Varieties and Algorithms: An Introduction \nto Computational Algebraic Geometry and Commutative Algebra. Springer, 1991. [13] DOLZMANN, A., AND STURM, \nT. REDLOG: Computer al\u00adgebra meets computer logic. ACM SIGSAM Bulletin 31,2 (June 1997), 2 9. [14] FLOYD, \nR. W. Assigning meanings to programs. Proc. Sym\u00adposia in Applied Mathematics 19 (1967), 19 32. [15] HENZINGER, \nT. A., AND HO,P. HYTECH: The Cornell hybrid technology tool. In Hybrid Systems II (1995), vol. 999 of \nLNCS, pp. 265 293. [16] HOARE, C. A. R. An axiomatic basis for computer program\u00adming. Commun. ACM 12, \n10 (1969), 576 580. [17] JAFFAR, J., AND LASSEZ, J.-L. Constraint logic program\u00adming. In Principles of \nProgramming Languages(POPL) (Jan. 1987), pp. 111 119. [18] KARR,M.Af.nerelationshipsamongvariablesofaprogram. \nActa Inf. 6 (1976), 133 151. [19] MANNA,Z. Mathematical Theory of Computation. McGraw-Hill, 1974. [20] \nMANNA, Z., AND PNUELI,A. Temporal Veri.cation of Re\u00adactive Systems: Safety. Springer-Verlag, New York, \n1995. [21] MISHRA, B., AND YAP, C. Notes on Gr\u00a8obner bases. Infor\u00admation Sciences 48 (1989), 219 252. \n[22] M \u00a8 ULLER-OLM, M., AND SEIDL, H. Polynomial constants are decidable. In Static Analysis Symposium \n(SAS 2002) (2002), vol. 2477 of LNCS, pp. 4 19. [23] SCHRIJVER,A. Theory of Linear and Integer Programming. \nWiley, 1986. [24] SIT, W. Y. An algorithm for solving parametric linear sys\u00adtems. Journal of Symbolic \nComputation 13, 3 (April 1992), 353 394. [25] TARSKI, A. A decision method for elementary algebra and \ngeometry. Univ. of California Press, Berkeley 5 (1951). [26] TIWARI, A., RUESS, H., SA\u00a8IDI, H., AND SHANKAR,N. \nA technique for invariant generation. In TACAS 2001 (2001), vol. 2031 of LNCS, Springer-Verlag, pp. 113 \n127. [27] WEISPFENNING, V. The complexity of linear problems in .elds. Journal of Symbolic Computation \n5, 1-2 (April 1988), 3 27. [28] WEISPFENNING, V. Comprehensive Gr\u00a8obner bases. Journal of Symbolic Computation \n14 (1992), 1 29. [29] WEISPFENNING, V. Quanti.er elimination for real algebra the quadratic case and \nbeyond. In Applied Algebra and Error-Correcting Codes (AAECC) 8 (1997), pp. 85 101. [30] WINDSTEIGER,W., \nAND BUCHBERGER, B. Groebner: A library for computing gro \u00a8 Tech. bner bases based on saclib. rep., RISC-Linz, \n1993. 8 Appendix In this appendix, we shall prove a few useful theorems mentioned in other results along \nwith the con.uence of the Gr\u00a8obner basis re\u00adduction on templates. The key idea is to reduce any failure \nof con\u00ad.uence on templates to a failure of con.uence on the instantiation of the template under an appropriate \nenvironment. Two templates ' Claim 1 Let f , f be templates and a be any environment. 1. a( f + g)= a( \nf )+ a(g), 2. c \u00b7 a( f )= a(c \u00b7 f ), for any c . R.  p '' Theorem 8 (Consistency) Let f -. f for templates \nf , f over template variables in A. Then, for an arbitrary A-environment pa, a( f ) -. a( f ' ) or a( \nf )= a( f ' ). Conversely, if for some a, pp '' a( f ) -. h then there is a f such that h = a( f ' ) \nand f -. f. ' c\u00b7t PROOF. We have that f = f - LT(p) p for some term c \u00b7 t in f wherein c(a0,...,am) is \na linear expression. If a(c)= 0 then a( f )= a( f ' ), or else, if a(c)= 0 then we have that a( f ' )= \na(c\u00b7t) p a( f ) - LT(p) p. In this case, a( f ) -. a( f ' ). p On the other hand, let a( f ) -. h, for \nsome template f and polyno\u00admial p. Let a(c) \u00b7 t be the term in a( f ) that LT(p) divides. Hence, the \nresult of the reduction is, a(c)t ct h = a( f ) - p = a( f - p) LT(p) LT(p) p' ct Therefore, setting \nf = f - LT(p) p,wehave a( f ' )= h and f -. ' f . Theorem 9 (Template Identity) Two templates f1, f2 \nover tem\u00adplate variables A are not identical iff there is an environment a such that a( f1) = a( f2). \nPROOF. Since f1 = f2, we have that f1 - f2 is a non-zero template. Let t be a term in f1 - f2, with a \nnon-zero coef.cient expression c. Let a be an environment s.t. a(c)= 0. Hence a( f1 - f2) = 0. Thus we \nhave that a( f1) = a( f2). The other direction is immediate from the de.nition of identical templates. \nTheorem 10 (Normal Form Theorem) A template f is a normal G form under -. iff for each environment a, \na( f ) is a normal form G under -.. PROOF. To prove the forward implication, assume that f is a nor-GG \nmal form under -. . However assume that a( f ) -. h for some a. By the reverse direction of the consistency \ntheorem (Theorem 8), G '' we have that there exists f such that f -. f and a( f ' )= h. This contradicts \nour assumption that f is in normal form. To prove the reverse implication, let us assume that f is not \nin nor-G mal form. Then there is a reduction f -. f ' . Let t be the term in f that is replaced by the \nreduction and c be its non-zero coef.cient. By Theorem 8, we have that for each environment a, a( f )= \na( f ' ) G or a( f ) -. a( f ' ). We .nd an environment a such that a(c)= 0. G For such an environment \na( f ) -. a( f ' ), since a(c)= 0. Thus G a( f ) is not in normal form w.r.t. -. . Theorem 11 (Con.uence \nof Templates) Let GbeaGr\u00a8obner ba-GG sis and f be a template. Let f -f1 and f -f2, where f1, f2 are G \nnormal forms. We have that f1 = f2 and hence -. is con.uent for templates. PROOF. Assuming otherwise, \ni.e., f1 = f2, we have by Theorem 9 that a( f1) = a( f2) for some a. Furthermore, Theorem 10 implies \nthat a( f1) and a( f2) are in normal forms. By the forward direction G of Theorem 8, we have that a( \nf ) -a( fi), i = 1,2. Hence, by the con.uence of the Gr\u00a8obner basis reduction over real polynomials, \nwe have that a( f1)= a( f2), thus leading to a contradiction. Theorem 12 (Normal Forms for Templates) \nLet f be a template over variables A. Let G be the Gr\u00a8obner basis of I =(G). Then, for any A-environment \na, a(NFG( f )) = NFG(a( f )) PROOF. The proof is by induction over the length of the minimal ' sequence \nof reductions from f to f = NF( f ). For zero length derivations, f = NF( f ), we have that a( f ) is \na normal form. Hence, a(NF( f )) = a( f )= NF(a( f )). Assuming that the theorem holds for templates \nwhich have a length GG n or less derivation to their normal forms, let f -. f1 -n NF( f ). G Hence, by \nTheorem 8, we have that a( f )= a( f1) or a( f ) -. a( f1). In either case NF(a( f1)) = NF(a( f )). Applying \nthe induc\u00adtion to f1, we have that a(NF( f1)) = NF(a( f1)). Hence a(NF( f )) = a(NF( f1)) = NF(a( f1)) \n= NF(a( f )) Theorem 13 (Template Membership) Let f be a template and G ' beaGr\u00a8obner basis, such that \nI =((G)). Let f = NFG( f ). For each environment a, a( f ) . Iiff a( f ' ) is identically zero. ' PROOF.Given \nf ,G such that f = NFG( f ), for any environment a, we have that a( f ' )= a(NF( f )) = NF(a( f )). Hence, \nif a( f ' ) is identically zero, then NF(a( f )) is identically zero, and therefore, a( f ) . (G). Let \na( f ) . (G), hence NFG(a( f )) is identically zero. However, a( f ' )= a(NF( f )) = NF(a( f )) = 0, \nand hence, a(NF( f )) = a( f ' ) is identically zero.  \n\t\t\t", "proc_id": "964001", "abstract": "We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples.", "authors": [{"name": "Sriram Sankaranarayanan", "author_profile_id": "81100300829", "affiliation": "Stanford University, Stanford, CA", "person_id": "PP36026615", "email_address": "", "orcid_id": ""}, {"name": "Henny B. Sipma", "author_profile_id": "81100593555", "affiliation": "Stanford University, Stanford, CA", "person_id": "PP14204909", "email_address": "", "orcid_id": ""}, {"name": "Zohar Manna", "author_profile_id": "81100089034", "affiliation": "Stanford University, Stanford, CA", "person_id": "PP15021756", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/964001.964028", "year": "2004", "article_id": "964028", "conference": "POPL", "title": "Non-linear loop invariant generation using Gr&#246;bner bases", "url": "http://dl.acm.org/citation.cfm?id=964028"}