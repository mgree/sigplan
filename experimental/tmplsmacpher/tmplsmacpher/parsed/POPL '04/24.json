{"article_publication_date": "01-01-2004", "fulltext": "\n A Type System for Well-Founded Recursion* Derek Dreyer School of Computer Science Carnegie Mellon University \nPittsburgh, PA 15213 dreyer@cs.cmu.edu Abstract In the interest of designing a recursive module extension \nto ML that is as simple and general as possible, we propose a novel type system for general recursion \nover effectful expressions. The presence of effects seems to necessitate a backpatching semantics for \nrecursion similar to that of Scheme. Our type system ensures statically that recursion is well-founded \nthat the body of a recursive expression will evaluate without attempting to access the unde.ned recursive \nvariable which avoids some unnecessary run-time costs associ\u00adated with backpatching. To ensure well-founded \nrecursion in the presence of multiple recursive variables and separate compilation, we track the usage \nof individual recursive variables, represented statically by names . So that our type system may eventually \nbe integrated smoothly into ML s, reasoning involving names is only required inside code that uses our \nrecursive construct and need not infect existing ML code, although instrumentation of some existing code \ncan help to improve the precision of our type system. Categories and Subject Descriptors D.3.1 [Programming \nLanguages]: Formal De.nitions and The\u00adory; D.3.3 [Programming Languages]: Language Constructs and Features \nRecursion, Modules; F.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs Type structure \n General Terms Languages, Theory Keywords Type systems, recursion, recursive modules, effect systems \n* This material is based on work supported in part by NSF grants CCR-9984812 and CCR-0121633. Any opinions, \n.ndings, and conclusions or recommendations in this publication are those of the author(s) and do not \nre.ect the views of this agency. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 04, January 14 16, 2004, Venice, Italy. Copyright 2004 ACM 1-58113-729-X/04/0001 \n...$5.00 1 Introduction A distinguishing feature of the programming languages in the ML family, namely \nStandard ML [21] and Objective Caml [25], is their strong support for modular programming. The module \nsystems of both languages, however, are strictly hierarchical, prohibiting cyclic dependencies between \nprogram modules. This restriction is unfor\u00adtunate because it means that mutually recursive functions \nand types must always be de.ned in the same module, regardless of whether they belong conceptually in \nthe same module. As a consequence, recursive modules are one of the most commonly requested exten\u00adsions \nto the ML languages. There has been much work in recent years on recursive module ex\u00adtensions for a variety \nof functional languages. One of the main stumbling blocks in designing such an extension for an impure \nlan\u00adguage like ML is the interaction of module-level recursion and core\u00adlevel computational effects. \nSince the core language of ML only permits recursive de.nitions of .-abstractions (functions), recursive \nlinking could arguably be restricted to modules that only contain fun bindings. The banishing of all \ncomputational effects, however, would place a severe restriction on recursive module programming. Some \nrecursive module proposals attempt to ameliorate this restric\u00adtion by splitting modules into a recursively \nlinkable section and an initialization section, and only subjecting the former to syntactic restrictions \n[10]. While such a construct is certainly more .exi\u00adble than one that forbids effects entirely, it imposes \na structure on recursive modules that is rather arbitrary. Others have suggested abandoning ML-style \nmodules altogether in favor of mixin mod\u00adules [3, 17] or units [13], for which recursive linking is the \nnorm and hierarchical linking a special case. For the purpose of extend\u00ading ML, though, this would constitute \na rather drastic revision of the language. 1.1 Recursion and Effects In the interest of designing a recursive \nmodule extension to ML that is as simple and general as possible, suppose that we were to introduce a \nnew form of structure declaration structure rec X = M in which the structure M may refer to itself recursively \nas X, and there are no a priori limitations on M. How should recursion inter\u00adact with any computational \neffects that may occur during evaluation of M? structure rec X = struct structure A = struct val debug \n= ref false fun f(x) = ...X.B.g(x-1)... end structure B = struct val trace = ref false fun g(x) = ...X.A.f(x-1)... \nend end Figure 1. Example of Recursive Module with Effects functor myA (X : SIG) = ... functor yourB \n(X : SIG) = ... structure rec X = struct structure A = myA(X) structure B = yourB(X) end Figure 2. Separate \nCompilation of Recursive Modules Under the standard interpretation of recursion via a .xed-point op\u00aderator, \nthe new recursive structure declaration would be tantamount to structure X = .x(X.M), where .x(X. M) \nevaluates to its unrolling M[.x(X.M)/X].1 Such a .xed-point semantics has the property that any computational \neffects in M are re-enacted at ev\u00adery recursive reference to X. While there is nothing inherently wrong \nwith this behavior, it is un\u00addesirable for many intended uses of recursive modules. For exam\u00adple, consider \nthe declaration of two mutually recursive structures A and B in Figure 1. Here, debug and trace are externally-accessible \ndebugging .ags used by f and g, respectively. Under the above .xed-point semantics, every recursive reference \nbetween f and g prompts a re-evaluation of the entire module, including the creation of brand new ref \ncells for debug and trace. In other words, each recursive call operates in an entirely different mutable \nstate, so set\u00adting debug to true externally would not alter the fact that !debug is false during all \nrecursive calls to X.A.f and X.B.g. An alternative semantics for recursion that exhibits more appropri\u00adate \nbehavior with respect to computational effects is the backpatch\u00ading semantics of Scheme [19], in which \nstructure rec X = M would evaluate as follows: First, X is bound to a fresh location containing an unde.ned \nvalue; then, M is evaluated to a module value V; .nally, X is backpatched with V. If the evaluation of \nM attempts to dereference X, a run-time error is reported. Unlike the .xed-point semantics, backpatching \nensures that the effects in M only happen once. One might argue that what the backpatching semantics \nreally achieves is the ability to write excessively recursive de.nitions. In the example in Figure 1, \nthe effectful de.nitions of debug and trace do not really participate in the recursion. One might there\u00adfore \nimagine a semantics for structure rec that models the re\u00adcursion via a .xed-point, but hoists the effects \noutside of the .xed\u00adpoint so that they only occur once. However, while hoisting the ef\u00ad 1We use M[N/X] \nto denote the capture-avoiding substitution of NforXinM. fects may result in the same behavior as the \nbackpatching semantics when the effect in question is state, it is well-known that the same is not true \nfor continuations, as it matters whether a continuation is captured inside or outside of the recursive \nde.nition [14]. Moreover, hoisting the effects is impossible in the context of sep\u00adarate compilation. \nIn particular, consider Figure 2, which shows how the structures A and B from Figure 1 may be developed \napart from each other by abstracting each one over the recursive variable X. The structure rec linking \nthem may also be compiled sepa\u00adrately, in which case we do not have access to the implementations of \nmyA and yourB and there is no way to hoist the effects out of myA(X) and yourB(X). The backpatching semantics \nthus seems to be a simpler, cleaner and more general approach. 1.2 Well-Founded Recursion Russo employs \nthe backpatching semantics described above in his recursive module extension to Moscow ML [28]. Russo \ns exten\u00adsion has the advantage of being relatively simple, largely because the type system does not make \nany attempt to statically ensure that structure rec X = Mis well-founded, i.e., that the evaluation of \nM will not dereference X. If possible, though, compile-time error detection is preferable. In addition, \nstatically ensuring well-foundedness would allow recur\u00adsive modules to be implemented more ef.ciently. \nIn the absence of static detection, there are two well-known implementation choices: (1) the recursive \nvariable X can be implemented as a pointer to a value of option type (initially NONE), in which case \nevery derefer\u00adence of X must also perform a tag check to see if it has been back\u00adpatched yet, or (2) \nX can be implemented as a pointer to a thunk (initially fn () => raise Error), in which case every derefer\u00adence \nof X must also perform a function call. Either way, mutually recursive functions de.ned across module \nboundaries will be no\u00adticeably slower than ordinary ML functions. If recursion is stati\u00adcally known to \nbe well-founded, however, the value pointed to by X will be needed only after X has been backpatched, \nso each ac\u00adcess will require just a pointer dereference without any additional tag check or function \ncall. In this paper we propose a type-theoretic approach to ensuring well\u00adfounded recursive de.nitions \nunder a backpatching semantics of re\u00adcursion. The basic idea is to model recursive variables statically \nas names, and to use names to track the set of recursive variables that a piece of code may attempt to \ndereference when evaluated. Our use of names is inspired by the work of Nanevski on a core language for \nmetaprogramming and symbolic computation [23], although it is closer in detail to his work (concurrent \nwith ours) on using names to model control effects [24]. Names are important both for tracking uses of \nmultiple recursive variables in the presence of nested recursion and for supporting separate compilation \nof recursive modules. An equally important feature of our approach is that recursive modules may invoke \nfunc\u00adtions de.ned in existing ML code without requiring them to be changed or recompiled to account for \nname reasoning. Neverthe\u00adless, as we discuss in Section 3.3, there are useful recursive module idioms \nfor which instrumentation of existing ML code appears to be unavoidable if one wants to statically ensure \nthat the recursion is well-founded. As there are a number of dif.cult issues surrounding static (type) \ncomponents of recursive modules [5, 8], we restrict our attention here to the dynamic (code) components \nof recursive modules. Cor\u00adrespondingly, we develop our type system at the level of recursive (core-level) \nexpressions. We do not intend this as an extension to the core language of ML, but as the basis of a \nfuture extension to the module language. 1.3 Overview The remainder of the paper is organized as follows: \nIn Section 2 we introduce the notion of evaluability, which ensures that a program is safe to evaluate \neven if it contains free references to unde.ned re\u00adcursive variables. Through a series of examples, we \nillustrate how a simple approach to tracking evaluability suffers from a number of theoretical and practical \nproblems. In Section 3 we present our core type system for solving these problems, in the context of \nthe (pure) simply-typed .-calculus. While effects necessitate the backpatch\u00ading semantics of recursion, \nall of the subtleties involving names can in fact be explored here in the absence of effects. We give \nthe static and dynamic semantics of our core language, along with meta-theoretic properties including \ntype safety. In Section 4 we show how to encode an unrestricted form of re\u00adcursion by extending the language \nwith memoized computations. While this unrestricted construct does not ensure well-founded re\u00adcursion, \nit is useful as a fallback in circumstances where our type system is too weak to observe that a recursive \nterm is well-founded. In Section 5 we compare our approach with related work on well\u00adfounded recursion \nand recursive modules. Finally, in Section 6 we conclude and suggest future work.  2 Evaluability Consider \na general recursive construct of the form rec(x :t.e), representing an expression e of type tthat may \nrefer to its ulti\u00admate value recursively as x. What is required of e to ensure that rec(x :t.e) is well-founded? \nCrary et al. [5] require that e be valu\u00adable (that is, pure and terminating) in a context where x is \nnot. We generalize their notion of valuability to one permitting effects, which we call evaluability: \na term may be judged evaluable if its evaluation does not access an unde.ned recursive variable. Thus, \nto ensure rec(x :t.e) is well-founded, the expression e must be evalu\u00adable in a context where uses of \nthe variable x are non-evaluable. An expression can be non-evaluable and still well-formed, but only \nevaluable expressions are safe to evaluate in the presence of unde\u00ad.ned recursive variables. Formally, \nwe might incorporate evaluability into the type system by dividing the typing judgment into one classifying \nevaluable terms (Gf e . t) and one classifying non-evaluable terms (Gf e . t). (There is an implicit \ninclusion of the former in the latter.) In ad\u00addition, we need to extend the language with a notion of \nunde.ned variables, which are bound in the context as x . t, as opposed to or\u00addinary variables which \nare bound as x : t. The distinction between them can be seen from their typing rules: x : t. G x . t. \nG Gf x . tGf x . t Given these extensions, we can now give the following typing rule for recursive expressions: \nG,x . tf e . t Gf rec(x :t.e) . t 2.1 The Evaluability Judgment While true evaluability is clearly an \nundecidable property, there are certain kinds of expressions that we can expect the type system to recognize \nas evaluable. For instance, recall the example from Figure 1, which recursively de.nes a pair of submodules, \neach of which is a pair of a ref expression and a .-abstraction. In general, all values and tuples of \nevaluable expressions should be considered evaluable. In addition, ref(e), !e, and e1:= e2 should all \nbe evalu\u00adable as long as their constituent expressions are. Evaluability is thus independent of computational \npurity. There is, however, a correspondence between non-evaluability and computational impurity in the \nsense that both are hidden by .\u00adabstractions and unleashed by function applications. In ML we assume \n(for the purpose of the value restriction) that all function applications are potentially impure. In \nthe current setting we might similarly assume for simplicity that all function applications are po\u00adtentially \nnon-evaluable. Unfortunately, this assumption has one major drawback: it implies that we can never evaluate \na function application inside a recursive expression! Furthermore, it is usually unnecessary: while functions \nde.ned inside a recursive expression may very well be hiding ref\u00aderences to an unde.ned variable, functions \nde.ned in existing ML code will not. For example, instead of de.ning local state with a ref expression, \nsuppose that we wish to de.ne a mutable array in submodule A (of Figure 1) by a call to the array creation \nfunction: ... structure A = struct val a = Array.array(n,0) fun f(x) = ...Array.update(a,i,m)... fun \ng(x) = ...X.B.f(x-1)... end ... The call to Array.array is perfectly evaluable, while a call to the function \nA.g inside the above module might not be. Lumping them together and assuming the worst makes the evaluability \njudgment far too conservative. 2.2 A Partial Solution At the very least, then, we should distinguish \nbetween the types of total and partial functions. For present purposes, a total arrow type t1 . t2 classi.es \na function whose body is evaluable, and a partial arrow type t1 . t2 classi.es a function whose body \nis potentially non-evaluable:2 G,x : sf e . tG,x : sf e . t Gf .x.e . s. tGf .x.e . s. t Correspondingly, \napplications of total evaluable functions to evalu\u00adable arguments will be deemed evaluable, whereas applications \nof partial functions will be assumed non-evaluable: Gf e1 . s. tGf e2 . sGf e1 . s. tGf e2 . s Gf e1(e2) \n. tGf e1(e2) . t The total/partial distinction addresses the concerns discussed in the previous section, \nto an extent. Existing ML functions can now be classi.ed as total, and the arrow type t1->t2 in ML proper \nis syn\u00adonymous with a total arrow. Thus, we may now evaluate calls to 2The total/partial nomenclature \narises from viewing non\u00adevaluability as a kind of computational effect. existing ML functions in the \npresence of unde.ned recursive vari\u00adables, as those function applications will be known to be evaluable. \nHowever, there are still some serious problems. 2.3 Problems Nested Recursion First, consider what happens \nwhen we use general recursion to de.ne a recursive function, such as factorial: rec(f : int . int. fn \nx => ... x * f(x-1) ...) Note that we are forced to give the recursive expression a partial arrow type \nbecause the body of the factorial function uses the recur\u00adsive variable f. Nonetheless, exporting factorial \nas a partial func\u00adtion is bad because it means that no application of factorial can ever be evaluated \ninside a recursive expression! To mend this problem, we observe that while the factorial func\u00adtion is \nindeed partial during the evaluation of the general recur\u00adsive expression de.ning it, it becomes total \nas soon as f is back\u00adpatched with a de.nition. One way to incorporate this observa\u00adtion into the type \nsystem is to revise the typing rule for recursive terms rec(x :t.e) so that we ignore partial/total discrepancies \nwhen matching the declared type t with the actual type of e. For example, in the factorial de.nition \nabove, we would allow f to be declared with a total arrow int . int, since the body of the de.nition \nhas an equivalent type modulo a partial/total mismatch. Unfortunately, such a revised typing rule is \nonly sound if we pro\u00adhibit nested recursive expressions. Otherwise, the rule may allow a truly partial \nfunction to be erroneously assigned a total type, as the following code illustrates: rec(x : t. let val \nf = rec(y : unit . t.fn ()=>x) in f() end ) The trouble here is that the evaluation of the recursive \nexpression de.ning f results only in the backpatching of y, not x. It is therefore unsound for that expression \nto make the type of fn() => x total. In short, the problem is that the total/partial dichotomy is too \ncoarse because it does not distinguish between uses of different recursive variables. In the type system \nof Section 3, we will be able to give f a more appropriate type specifying that f will dereference x \nwhen applied, but not y. Higher-Order Functions Another problem with the total/partial distinction arises \nin the use of higher-order functions. Suppose we wish to use the Standard Basis map function for lists, \nwhich can be given the following type (for any s and t): valmap : (s . t) . (s list . t list) Since the \ntype of map is a pure ML type, all the arrows are total, which means that we cannot apply map to a partial \nfunction, as in the following: rec (X : SIG. let val f: s . t = ... val g: s list . t list =map f ... \n) Given the type of map, this is reasonable: unless we know how map is implemented, we have no way of \nknowing that evaluating map f will not try to apply f, resulting in a potential dereference of X. Nevertheless, \nwe should at least be able to replace map f with its eta-expansion fn xs=> map fxs, which is clearly \nevaluable since it is a value. Even its eta-expansion is ill-typed, however, because the type of f still \ndoes not match the argument type of map. The way we propose to resolve this problem is to view a partial/total \ntype mismatch not as a sign that the offending ex\u00adpression (in this case, map f) is ill-typed, but merely \nthat it is potentially non-evaluable. The type system of Section 3 will re\u00ad.ect this intuition, and will \ncorrespondingly consider the function fn xs=> map fxs to be well-typed with a partial arrow, but not \na total one. Separate Compilation Russo points out a problem with sepa\u00adrate compilation of recursive \nmodules in Moscow ML [28] that the system we have sketched thus far suffers from as well: there is no \nway to refer to a recursive variable without dereferencing it. For in\u00adstance, recall the separate compilation \nscenario from Figure 2. The code in Figure 2 is ill-typed under our current setup because, un\u00adder call-by-value \nsemantics, the functor applications myA(X) and yourB(X) will begin by evaluating the recursive variable \nX, which is unde.ned. What we really intended, however, was not for the functor applica\u00adtions to dereference \nthe recursive variable X and pass the resulting module value as an argument, but rather to pass the recursive \nvari\u00adable X as an argument itself without dereferencing it. The way to account for this intended semantics \nis to treat a recursive variable not as a (potentially divergent) expression, but as a value of a new \nlocation type that must be dereferenced explicitly. This idea will be .eshed out further in the next \nsection.  3 A Type System for Well-Founded Recursion In this section we present a type system for well-founded \nrecursion that addresses all the problems enumerated in the previous section. To address the nested recursion \nproblem, we generalize the judg\u00adment of evaluability to one that tracks uses of individual recursive \nvariables. We achieve this by introducing along with each recursive variable a name that is used as a \nstatic representative of the variable. The new evaluability judgment has the form G f e : t [S], with \nthe interpretation under context G, term e has type t and is evaluable modulo the names in set S . In \nother words, e will evaluate without dereferencing any recursive variables except possibly those whose \nassociated names appear in S. Following Nanevski [23], we call a .nite set of names a support. Our previous \njudgment of evaluability (G f e . t) can be understood as evaluability modulo the empty sup\u00adport (G f \ne : t [0/]), while non-evaluability (G f e . t) corresponds to evaluability modulo some non-empty support. \nSimilarly, we generalize the types of functions to bear a support indicating which particular recursive \nvariables may be dereferenced in their bodies. Thus, the total arrow type of the previous section becomes \nan arrow type bearing empty support, while the partial arrow type corresponds to an arrow type bearing \nsome non-empty support. To address the higher-order function problem, we employ a novel judgment of type \nequivalence modulo a support, which allows type mismatches in an expression to be ignored so long as \nthey only involve names that are in the support of the expression. The intu\u00adVariables x, y, z . Variables \nNames X,Y,Z . Names Supports S,T . P.n(Names) S Types s, t ::= 1 |t1 \u00d7t2 |t1 -.t2 |.X.t |boxS(t) Terms \ne, f ::= x |()|(e1,e2)|pi(e) |.x.e | f (e) |.X.e | f (S) |box(e) |unbox(e) |rec(X C x : t.e) Values v \n::= x |()|(v1,v2)|.x.e |.X.e Typing Contexts G ::= 0/ |G,x : t |G,X Figure 3. Core Language Syntax ition \nbehind this judgment is that we are only interested in tracking uses of unde.ned recursive variables; \nsince the names that appear in the support of an expression correspond to recursive variables that must \nbe de.ned before the expression can be evaluated, they can be safely ignored when typing it. To address \nthe separate compilation problem, our type system treats recursive variables as values of a new box type \nclassifying (po\u00adtentially uninitialized) memory locations. Recursive expressions in our type system have \nthe form rec(X C x : t.e)3, introducing (in the scope of e) the name X and the recursive variable x, \nwhich is bound in the context with type boxX(t). The type of x indicates that x is a memory location \nand that any expression attempting to dereference (unbox) it must have X in its support. Consequently, \nwhat we previ\u00adously wrote as rec(x :t.e) would now be written as rec(X Cx : t.e'), where e' replaces \noccurrences of the expression x in e with an ex\u00adplicit dereference of the value x (written unbox(x)). \nIn addition, note that we no longer need to distinguish recursive variables from ordinary variables through \na separate context binding like x .t;a recursive variable is distinguished simply by its box type. 3.1 \nSyntax The syntax of our core language is given in Figure 3. We assume the existence of countably in.nite \nsets of names (Names) and variables (Variables), and use S and T to range over supports. We often write \nthe name X as shorthand for the singleton support {X}. The type structure of the language is as follows. \nUnit (1) and pair S types (t1 \u00d7t2) require no explanation. An arrow type (t1 -.t2) bears a support on \nthe arrow, which indicates the set of names whose associated recursive variables must be de.ned before \na func\u00adtion of this type may be applied. We will sometimes write t1 .t2 0/ as shorthand for an arrow \ntype with empty support (t1 -.t2). The language also provides the ability to abstract an expression over \na name. The type .X.t classi.es name abstractions .X.e, which suspend the evaluation of their bodies \nand are treated as values. Application of a name abstraction, f (S), allows the name parameter of f to \nbe instantiated with a support S, not just a single name. 3Our notation here is inspired by, but not \nto be confused with, Harper and Lillibridge s notation for labels and variables in a mod\u00adule calculus \n[16]. They use labels to distinguish external names of module components from internal a-variable names. \nIn our recur\u00adsive construct, both X and x are bound inside e. The reasons for allowing names to be instantiated \nwith supports are discussed in Section 3.3. Lastly, the location type boxS(t) classi.es a memory location \nthat will contain a value of type t once the recursive variables associ\u00adated with the names in S have \nbeen de.ned. Locations are most commonly introduced by recursive expressions, but they may also be introduced \nby box(e), which evaluates e and then boxes the resulting value, i.e., stores it at a new location. Since \neach boxing may potentially create a new location, box(v) is not a value; the only values of location \ntype are variables. The elimination form for location types is unbox(e), which dereferences the location \nresult\u00ading from the evaluation of e. We will sometimes write box(t) as shorthand for box0/ (t). Notational \nConventions In the term .x.e, the variable x is bound in e; in the term .X.e and type .X.t, the name \nX is bound in e and t; in the term rec(X C x : t.e), the name X and variable x are bound in e. As usual, \nwe identify terms and types that are equivalent modulo a-conversion of bound variables/names. For notational \nconvenience, we enforce several implicit require\u00adments on the well-formedness of contexts and judgments. \nA con\u00adtext G is well-formed if (1) it does not bind the same variable/name twice, and (2) for any pre.x \nof G of the form G',x : t, the free names of t are bound in G'. A judgment of the form Gf\u00b7\u00b7\u00b7is well-formed \nif (1) G is well-formed, and (2) any free names appearing to the right of the turnstile are bound in \nG. We assume and maintain the implicit invariant that all contexts and judgments are well-formed. 3.2 \nStatic Semantics The main typing judgment has the form G fe : t [S]. The support S represents the set \nof names whose associated recursive variables we may assume have been de.ned (backpatched) by the time \ne is evaluated. Put another way, the only recursive variables that e may dereference are those associated \nwith the names in S. The static semantics is carefully designed to validate this assumption. The rules \nof the type system (Figure 4) are designed to make ad\u00admissible the principle of support weakening, which \nsays that if G fe : t [S] then G fe : t [T] for any T .S. Thus, for instance, since a variable x does \nnot require any support, Rule 1 allows x to be assigned any support S .dom(G), not just the empty support. \nThe remainder of the rules may be summarized as follows. Unit needs no support (Rule 2), but pairs and \nprojections require the support of their constituent expressions (Rules 3 and 4). A func- T tion .x.e \nhas type s -.t in any support S, so long as the body e is well-typed under the addition of support T \n(Rule 5). To evaluate a function application f (e), the support must contain the supports of f and e, \nas well as the support on f s arrow type (Rule 6). Although a name abstraction .X.e suspends the evaluation \nof e, the body is typechecked under the same support as the abstrac\u00adtion itself (Rule 7). In other words, \none can view .X. t as another kind of arrow type that always bears empty support (compare with Rule 5 \nwhen T = 0/). Note also that our assumptions about the well\u00adformedness of judgments ensures that the \nsupport S cannot contain X, since S .dom(G) and X .dom(G). Restricting name abstrac\u00adtions in this way \nis motivated by the fact that, in all our intended uses of name abstractions, the body of the abstraction \nis a value (with empty support). Term well-formedness: G f e : t [S] G(x)=t G f x : t [S] (1) G f( ) \n:1 [S] (2) G f e1 : t1 [S] G f e2 : t2 [S] G f( e1,e2) : t1 \u00d7 t2 [S] (3) G f e : t1 \u00d7 t2 [S] G f pi(e): \nti [S] (4) G,x : s f e : t [S . T] (5) T G f .x.e : s -. t [S] T G f f : s -. t [S] G f e : s [S] T \n. S (6) G f f (e): t [S] G,X f e : t [S] G f f : . X.t [S] (7) (8) G f .X.e : . X.t [S] G f f (T): t[T/X][S] \nG f e : t [S] G f e : boxT(t)[S] T . S (9) (10) G f box(e): boxT(t)[S] G f unbox(e): t [S] G,X,x : boxX(t)f \ne : s [S] G,X f s = X t (11) G f rec(X C x : t.e): t [S] G f e : s [S] G f s = S t (12) G f e : t [S] \nType equivalence: G f t1 = S t2 G f s1 = S s2 G f t1 = S t2 (13) (14) G f 1 = S1 G f s1 \u00d7 t1 = S s2 \u00d7 \nt2 S . S1 =T =S . S2 G f s1 = T s2 G f t1 = T t2 (15) S1S2 G f s1 -. t1 = S s2 -. t2 G,X f t1 = S t2 \n(16) G f. X.t1 = S . X.t2 S . S1 =T =S . S2 G f t1 = T t2 (17) G f boxS1 (t1)= S boxS2 (t2) Figure 4. \nCore Language Static Semantics Instantiating a name abstraction f of type . X.t with a support T has \nthe type resulting from substituting T for X in t (Rule 8). The substitution t[T/X]is de.ned by replacing \nevery support S appear\u00ading in t with S[T/X], which is in turn de.ned as follows: def S . T -{ X} if X \n. SS[T/X]= S ifX . S Since boxing an expression .rst evaluates it, box(e)has the same support as e (Rule \n9). Furthermore, box(e)may be given a location type boxT(t)with arbitrary T since the resulting location \ncontains a de.ned value and may be unboxed immediately. Unboxing an expression e of type boxT(t)is only \npermitted if the recursive vari\u00adables associated with the names in T have been de.ned, i.e., ifTis contained \nin the support S (Rule 10). Rules 11 and 12 are the most interesting rules in the type system since they \nboth make use of our type equivalence judgment, de.ned in Figure 4. The judgment G f t1 = S t2 means \nthat t1 and t2 are equivalent types modulo the names in support S, i.e., that t1 are t2 are identical \ntypes if we ignore all occurrences of the names in 0/X S. For example, the types t1 -. t2 and t1 -. t2 \nare equivalent modulo any support containing X. The intuition behind our type equivalence judgment is \nthat, once a recursive variable has been backpatched, its associated name can be completely ignored for \ntypechecking purposes because we only care about tracking uses of unde.ned recursive variables. If the \nsupport of e is S, then by the time e is evaluated, the recursive vari\u00adables associated with the names \nin S will have been de.ned. Thus, 0/ in the context of typing e under support S, the types t1 -. t2 and \nS t1 -. t2 are as good as equivalent since they only differ with re\u00adspect to the names in S, which are \nirrelevant. (Note: when checking S1S2 equivalence of arrow types s1 -. t1 and s2 -. t2 modulo S, we compare \nthe argument types and result types at the extended mod\u00adulus S . S1 =S . S2. This makes sense because \na function of one of these types may only be applied with S . S1 in the support. The rule for box can \nbe justi.ed similarly.) This notion of equivalence modulo a support is critical to the typing of recursive \nterms (Rule 11). Recall the factorial example from Section 2.2, adapted to our present type system: rec(F \nC f : int . int. fn x => ... x * unbox(f)(x-1) ...) The issue here is that the declared type of F does \nnot match the F actual type of the body, int -. int. Once F is backpatched, however, the two types do \nmatch modulo F. Correspondingly, our typing rule for recursive terms rec(XCx : t. e) works as follows. \nFirst, the context G is extended with the name X, as well as the recursive variable x of type boxX(t). \nThis loca\u00adtion type binds the name and the variable together because it says that X must be in the support \nof any expression that attempts to dereference (unbox) x. The rule then checks that e has some type s \nin this extended context, under a support S that does not include X (since x is unde.ned while evaluating \ne). Finally, it checks that s and t are equivalent modulo X. It is easiest to understand this last step \nas a generalization of our earlier idea of ignoring discrep\u00adancies between partial and total arrows when \ncomparing s and t. The difference here is that we ignore discrepancies with respect to a particular name \nX instead of all names, so that the rule behaves properly in the presence of multiple names (nested recursion). \nIn contrast, Rule 12 appears rather straightforward, allowing a term with type s and support S to be \nassigned a type that is equivalent to s modulo the names in S. In fact, this rule solves the higher-order \nfunction problem described in Section 2.2! Recall that we wanted to apply an existing higher-order ML \nfunction like map to a partial function, i.e., one whose arrow type bears non-empty support: rec (X C \nx : SIG. let X val f : s -. t = ... X val g: s list -. t list =fn xs => map fxs ... ) The problem here \nis that the type of f does not match the argument type s. t of map. Intuitively, though, this code ought \nto typecheck: if we are willing to add X to the support of g s arrow type, then x must be backpatched \nbefore g is ever applied, so X should be ignored when typing the body of g. Rule 12 encapsulates this \nreasoning. Since g is speci.ed with type X s list -. t list, we can assume support X when typecheck\u00ading \nits body (mapf xs). Under support X, Rule 12 allows us to assign f the type s . t, as it is equivalent \nto f s type modulo X. Thus, g s body is well-typed under support X.  3.3 Name Abstractions and Non-strictness \nWe have so far illustrated how the inclusion of supports in our typ\u00ading and equivalence judgments addresses \nthe .rst two problems de\u00adscribed in Section 2.3. Our system addresses the problem of sep\u00adarate compilation \nas well by (1) making the dereferencing of a re\u00adcursive variable an explicit operation, and (2) providing \nthe ability to abstract an expression over a name. Recall the separate compilation scenario from Figure \n2. Since re\u00adcursive variables in our core language are no longer dereferenced implicitly, we might attempt \nto rewrite the linking module as: structure rec X C x: SIG = structure A = myA(x) structure B = yourB(x) \nend The recursive variable x is now a value of location type boxX (SIG), so passing it as an argument \nto myA and yourB does not dereference it. Assuming then that myA and yourB are non-strict, i.e., that \nthey do not dereference their argument when applied, the recursion is indeed well-founded. But what types \ncan we give to myA and yourB to re.ect the property that they are non-strict? Suppose that myA s return \ntype is SIG A. We would like to give it the type boxX (SIG) . SIG A, so that (1) its argument type matches \nthe type of x, and (2) the absence of X on the arrow indicates that myA can be applied under empty support. \nHowever, this type makes no sense where myA is de.ned, because the name X is not in scope outside of \nthe recursive module. This is where name abstractions come in. To show that myA is non\u00adstrict, it is \nirrelevant what particular support is required to unbox its argument, so we can use a name abstraction \nto allow any name or support to be substituted for X. Figure 5 shows the resulting well\u00adtyped separate \ncompilation scenario, in which the type of myA is . X.boxX (SIG) . SIG A. Our recursive construct is \nstill not quite as .exible for separate com\u00adpilation purposes as one might like. In particular, suppose \nthat we wanted to parameterize myA over just yourB instead of both myA and yourB. There is no way in \nour system to extract a value of type boxX (SIG B) from x without unboxing it. It is easy to remedy this \nproblem, however, by generalizing the recursive construct to an n-ary one, rec(.X C.x :.t..e), where \neach of the n recursive variables xi is boxed separately with type boxXi (ti). Name abstractions can \nalso be used to express non-strictness of general-purpose ML functors, which in turn allows better static \nde\u00adtection of well-founded recursion in certain cases. For instance, the recursive module in Figure 6 \nprovides a type C.t, which is myA = .X. .x: boxX (SIG). ... yourB = .X. .x: boxX (SIG). ... structure \nrec X C x : SIG = struct structure A = myA{X}(x) structure B = yourB{X}(x) end Figure 5. Revised Separate \nCompilation Scenario structure rec C : ORDERED = struct datatype t = ...CSet.set... fun compare (x,y) \n= ...CSet.compare(a,b)... end and CSet = MakeSet(C) Figure 6. Recursive Data Structure Example de.ned \nin terms of sets of itself.4 The de.nition of module C refers recursively to the CSet module, which is \nde.ned by apply\u00ading the MakeSet functor to the C module. The only way we can be sure that the recursion \nis well-founded is if we know that the application of the MakeSet functor will not attempt to apply the \npartial function C.compare, i.e., that the MakeSet functor is non\u00adstrict. With name abstractions, we \ncan instrument the implemen\u00adtation of MakeSet in order to assign it a non-strict type5 such as . X.boxX \n(ORDERED) . SET. Similarly, name abstractions can be used to give more precise types to core-level ML \nfunctions. For instance, suppose we had access to the code for the map function. By wrapping the de.nition \nof map in a name abstraction, we could assign the function the type X0/X . X. (s -. t) -. (s list -. \nt list) This type indicates that map will turn a value of any arrow type into a value of the same arrow \ntype, but will not apply its argument in the process. Given this type for map, we can write our recursive \nmodule example involving map the way we wanted to write it originally in Section 2.3: rec (X C x : SIG. \nlet X val f: s -. t = ... X val g: s list -. t list = map {X} f ... ) The more precise non-strict type \nfor map allows us to avoid eta\u00adexpanding map f, but it also requires having access to the imple\u00admentation \nof map. Furthermore, it requires us to modify the type of map, infecting the existing ML infrastructure \nwith names. It is therefore important that, in the absence of this solution, our type system is strong \nenough (thanks to Rule 12) to typecheck at least the eta-expansion of map f, without requiring changes \nto existing ML code. Unfortunately, there is no corresponding way to eta\u00adexpand the functor application \nMakeSet(C) in the example from Figure 6. To statically ensure that the recursion in that example is 4See \nOkasaki [26] for similar, more realistic examples, such as bootstrapped heaps . 5For simplicity, we are \nignoring here that the result signature SET really depends on the type components of the functor argument. \nwell-founded, it appears that one must have access to the implemen\u00adtation of the MakeSet functor in order \nto instrument it with name abstractions and assign it a more precise non-strict interface. This example \nalso illustrates why it is useful to be able to instantiate a name abstraction with a support instead \nof a single name. In par- S ticular, suppose that f s type were s -.t for some non-singleton support \nS. The de.nition of g would become map S f, which is only possible given the ability to instantiate map \nwith a support. Finally, note that while our system does not contain any notion of subtyping, it is important \nto be able to coerce a non-strict function into an ordinary (potentially strict) arrow type. The coercion \nfrom .X.boxX(s) .t to s .t[0//X] is easily encodable within our language as . f ..x. f (0/)(box(x)). \n 3.4 Dynamic Semantics We formalize the dynamic semantics of our core language in terms of a virtual \nmachine. Machine states (.;C;e) consist of a store .,a continuation C, and an expression e currently \nbeing evaluated. We sometimes use . to stand for a machine state. A continuation C consists of a stack \nof continuation frames F,as shown in Figure 7. A store . is a partial mapping from variables (of location \ntype) to storable things. A storable thing . is either a term (e) or nonsense (?). By .(x) we denote \nthe storable thing stored at x in ., which is only valid if something (possibly nonsense) is stored at \nx.By .[x ..] we denote the result of creating a new location x in . and storing . at it. By .[x :=.] \nwe denote the result of updating the store . to store . at x, where x is already in dom(.). We denote \nthe empty store by e. The dynamic semantics of the language is shown in Figure 7 as well. It takes the \nform of a stepping relation . . Rules 18 . .' through 31 are all fairly straightforward. Rule 32 says \nthat, in order to evaluate rec(X C x : t.e), we create a new location x in the store bound to nonsense, \npush the recursive frame rec(X C x : t. ) on the continuation stack, and evaluate e. (We can always ensure \nthat x is not already a location in the store by a-conversion.) Once we have evaluated e to a value v, \nRule 33 performs the backpatching step: it stores v at location x in the store and returns v. Finally, \nif a location is ever dereferenced (unboxed), Rule 31 simply looks up the value it is bound to in the \nstore. 3.5 Type Safety Observe that the machine is stuck if we attempt to unbox a location that is bound \nto nonsense. The point of the type safety theorem is to ensure that this will never happen for well-formed \nprograms. We begin by de.ning a notion of well-formedness for stores, which is dependent on a notion \nof a run-time context. A run-time context is a context that only binds variables representing memory \nloca\u00adtions, i.e., variables of box type. In addition, we distinguish back\u00adpatchable locations and connect \nthem to their associated names by introducing a new context binding form X C x : t, which behaves semantically \nthe same as the two bindings X, x : boxX(t), but is distinguished syntactically. DEFINITION 3.1 (RUN-TIME \nCONTEXTS). A context G is run\u00adtime if the only bindings in G take the form X C x : t or x : boxT(t). \nDEFINITION 3.2 (STORE WELL-FORMEDNESS). A store . is well-formed, denoted G f. [S], if: Continuations \nC ::= |C .F Continuation Frames F ::= ( ,e)|(v, )|pi( ) | (e) |v( ) | (T) |box( ) |unbox( ) |rec(X C \nx : t. ) ..' Small-step semantics: . (e1,e2)not a value (18) (.;C;(e1,e2)) .(.;C .( , e2);e1) (19) (.;C \n.( , e);v) .(.;C .(v, );e) (20) (.;C .(v1, );v2) .(.;C;(v1,v2)) (21)(.;C;pi(e)) .(.;C .pi( );e) (22) \n(.;C .pi( );(v1,v2)) .(.;C;vi) (23)(.;C;e1(e2)) .(.;C . (e2);e1) (24)(.;C . (e);v) .(.;C .v( );e) (25)(.;C \n.(.x.e)( );v) .(.;C;e[v/x]) (26)(.;C;e(T)) .(.;C . (T);e) (27)(.;C . (T);.X.e) .(.;C;e[T/X]) (28)(.;C;box(e)) \n.(.;C .box( );e) x .dom(.) (29)(.;C .box( );v) .(.[x.v];C;x) (30) (.;C;unbox(e)) .(.;C .unbox( );e) .(x)= \nv (31) (.;C .unbox( );x) .(.;C;v) x .dom(.) (32)(.;C;rec(X C x : t.e)) .(.[x.?];C .rec(X C x : t. );e) \n(33)(.;C .rec(X C x : t. );v) v];C;v).(.[x := Figure 7. Core Language Dynamic Semantics 1. G is run-time \nand dom(.)= vardom(G) 2. .X C x : t .G. if X .S then .v. .(x)= v and G fv : t [S] 3. .x : boxT(t) .G. \n.v. .(x)= v and G fv : t [S]  Continuation well-formedness: GfC : tcont [S] (34) Gf : tcont [S] GfF \n: t.s[S] GfC : scont [S] (35) GfC .F : tcont [S] GfC : scont [S] Gfs=S t (36) GfC : tcont [S] Continuation \nframe well-formedness: GfF : t1 .t2 [S] Gfe : t2 [S] (37) Gf( ,e): t1 .t1 \u00d7t2 [S] Gfv : t1 [S] (38) Gf(v, \n): t2 .t1 \u00d7t2 [S] i .{1,2} (39) Gfpi( ): t1 \u00d7t2 .ti [S] Gf (T): .X.t.t[T/X][S] Gfe : s[S] Gf (e): s.t.t[S] \n(40) Gfv : s.t[S] Gfv( ): s.t[S] (41) (42) (43) Gfbox( ): t.boxT(t)[S] (44) Gfunbox( ): box(t).t[S] \nX C x : t.GGfs=X t (45) Gfrec(X C x : t. ): s.t[S] Figure 8. Well-formedness of Core Continuations Essentially, \nthe judgment Gf.[S] says that Gassigns types to all locations in the domain of ., and that all locations \nmap to appropriately-typed values except those backpatchable ones asso\u00adciated with names which are not \nin the support S. We de.ne well-formedness of continuations and continuation frames via the judgments \nGfC : tcont [S]and GfF : t1 .t2 [S], de.ned in Figure 8. The former judgment says that continuation C \nexpects a value of type tto .ll in its ; the latter judgment says that F expects a value of type t1 to \n.ll in its and that F produces a value of type t2 in return. The only rule that is slightly unusual is \nRule 45 for recursive frames rec(XCx : t. ). Since this frame is not a binder for X or x, Rule 45 requires \nthat X C x : tbe in the context. This is a safe assumption since rec(X C x : t. )only gets pushed on \nthe stack after a binding for x has been added to the store. We can now de.ne a notion of well-formedness \nfor a machine state, which requires that the type of its expression component matches the type of the \nhole in the continuation component: DEFINITION 3.3 (MACHINE STATE WELL-FORMEDNESS). A machine state .is \nwell-formed, denoted Gf.[S],if .=(.;C;e), where: 1. Gf.[S] 2. .t. GfC : tcont [S]and Gfe : t[S]  We \ncan now state the preservation and progress theorems leading to type safety: ' THEOREM 3.4 (PRESERVATION). \nIf Gf.[S]and ..., then ' '' .G,S' . Gf.[S']. DEFINITION 3.5 (TERMINAL STATES). A machine state .is terminal \nif it has the form (.; ;v). DEFINITION 3.6 (STUCK STATES). A machine state .is stuck '' if it is non-terminal \nand there is no state .such that .... THEOREM 3.7 (PROGRESS). If Gf.[S], then .is not stuck. Note that \nwhen .=(.;C .unbox( );x), the well-formedness of . implies that Gfx : box(t)[S]for some type t. The well-formedness \nof .then ensures that there is a value v such that .(x)=v,so . can make progress by Rule 31. COROLLARY \n3.8 (TYPE SAFETY). Suppose 0/fe : t[0/]. Then for any machine state .,if (e; ;e).*., then .is not stuck. \nThe full meta-theory of our language (along with proofs) appears in the companion technical report [7]. \n 3.6 Practical Issues Ef.cient Implementation Our dynamic semantics treats values of type boxS(t) as \nmemory locations that will eventually contain values of type t. It is quite likely, though, that values \nof type t(i.e., the kinds of values one wants to de.ne recursively) have a naturally boxed representation. \nFor instance, in the case of recursive mod\u00adules, twill typically be a record type, and a module value \nof type t will be represented as a pointer to a record stored on the heap. Only one level of pointer \nindirection is needed to implement back\u00adpatching. Thus, a direct implementation of our semantics that \nrep\u00adresents all values of type boxS(t) as pointers to values of type t will introduce an unnecessary \nlevel of indirection when values of type tare already pointers. Our semantics, however, does not re\u00adquire \none to employ such a na\u00a8ive representation. Indeed, for types t with naturally boxed representations, \na realistic implementation of our semantics should represent values of type boxS(t)the same as values \nof type tand should compile the unbox ing of such values as a no-op. (See Hirschowitz et al. [18] for \nan example of such a compilation strategy.) At the level of our type system, though, there is still an \nimportant semantic distinction to be made between tand boxS(t)that transcends such implementation details. \nEffects Since we have modeled the semantics of backpatching operationally in terms of a mutable store, \nit is easy to incorporate some actual computational effects into our framework as well. In the companion \ntechnical report [7] we extend the language and type safety proof with primitives for mutable state and \ncontinuations. The extensions are completely straightforward and are essentially oblivious to the presence \nof supports in typing judgments. Types t ::= \u00b7\u00b7\u00b7 | compS(t) Terms e ::= \u00b7\u00b7\u00b7 | delay(e) | force(e) S \n. S1 = T = S . S2 G f t1 =T t2 (46) G f compS1 (t1) =S compS2 (t2) G f e : t [S . T] (47) G f delay(e) \n: compT(t)[S] G f e : compT(t)[S] T . S (48) G f force(e) : t [S] Figure 9. Static Semantics for Memoized \nComputations Typechecking It is also important that our language admit a practical typechecking algorithm. \nIn the implicitly-typed form of the language that we have used here, it is not obvious that such an algorithm \nexists because terms do not have unique types. For ST example, if .x.e has type s -. t, it can also be \ngiven s -. t for any T . S. It is easy to eliminate this non-determinism, how\u00adever, by making the language \nexplicitly-typed. In particular, if .\u00adabstractions are annotated as .T x : s.e and boxed expressions \nare annotated as boxT(e), along with the revised typing rules G,x : s f e : t [S . T] G f e : t [S] T \nG f .T x : s.e : s -. t [S] G f boxT(e) : boxT(t)[S] then it is easy to synthesize unique types for explicitly-typed \nterms up to equivalence modulo a given support S. (See the companion technical report for details [7].) \nIt remains an important question for future work how much of the type and support information in explicitly-typed \nterms can be inferred.  4 Encoding Unrestricted Recursion Despite all the efforts of our type system, \nthere will always be recur\u00adsive terms rec(X Cx : t.e) for which we cannot statically determine that e \ncan be evaluated without dereferencing x. For such cases it is important to have a fallback approach \nthat would allow the pro\u00adgrammer to write rec(X Cx : t.e) with the understanding that the recursion may \nbe ill-founded and dereferences of x will be saddled with an additional run-time cost. One option is \nto add a second unrestricted recursive term construct, with the following typing rule: G,x :1 . t f e \n: t [S] G f urec(x : t.e) : t [S] Note that we do not introduce any name X, so there are no restric\u00adtions \non when x can be dereferenced. Since the dereferencing of x may diverge and cannot therefore be a mere \npointer dereference, we assign x the thunk type 1 . t instead of box(t), with dereferencing achieved \nby applying x to (). Adding an explicit urec construct, however, makes for some redundancy in the recursive \nmechanisms of the language. It would be preferable, at least at the level of the theory, to .nd a way \nto encode unrestricted recursion in terms of our existing recursive construct. We achieve this by extending \nthe language with primitives for mem\u00adoized computations. The syntax and static semantics of this exten- \nMachine States . ::= \u00b7\u00b7\u00b7 | Error Continuation Frames F ::= \u00b7\u00b7\u00b7 | force( ) | memo(x, ) x . dom(.) (49)(.;C;delay(e)) \n. (.[x .e];C;x) (50) (.;C;force(e)) . (.;C .force( );e) .(x)= e (51)(.;C . force( );x) . (.[x :=?];C \n.memo(x, );e) (52) (.;C . memo(x, );v) . (.[x :=v];C;v) .(x)= ? (53) (.;C . force( );x) . Error Figure \n10. Dynamic Semantics for Memoized Computations sion are given in Figure 9. First, we introduce a type \ncompS(t) of locations storing memoized computations. A value of this type is S essentially a thunk of \ntype 1 -. t whose result is memoized after the .rst application. The primitive delay(e) creates a memoized \nlocation x in the store bound to the unevaluated expression e. When x is forced (by force(x)), the expression \ne stored at x is evaluated to a value v, and then v is written back to x. During the evaluation of e, \nthe location x is bound to nonsense; if x is forced again during this stage, the machine raises an error. \nThus, every force of x must check to see whether it is bound to an expression or nonsense. Despite the \ndiffer\u00adence in operational behavior, the typing rules for memoized com\u00adputations appear just as if compS(t), \ndelay(e) and force(e) were S shorthand for 1 -. t, .().e and e(), respectively. We use comp(t) sometimes \nas shorthand for comp0/ (t). We can now encode urec via a recursive memoized computation: def urec(x \n: t.e)= force(rec(X Cx : comp(t).delay(e[.().force(unbox(x))/x]))) It is easiest to understand this encoding \nby stepping through it. First, a new recursive location x is created, bound to nonsense. Then, the delay \ncreates a new memoized location y bound to the ex\u00adpression e[.../x]. Next, the rec backpatches x with \nthe value y and returns y. Finally, y is forced, resulting in the evaluation of e[.../x] to a value v, \nand y is backpatched with v. If the recursive variable (encoded as .().force(unbox(x))) is dereferenced \n(applied to ()) during the evaluation of e[.../x], it will result in another forcing of y, raising a \nrun-time error. Essentially, one can view the rec in this encoding as merely ty\u00ading the recursive knot \non the memoized computation, while the memoization resulting from the force is what actually performs \nthe backpatching. Observe that if we were to give comp(t) a non\u00admemoizing semantics, i.e., to consider \nit synonymous with 1 . t, the above encoding would have precisely the .xed-point semantics of recursion. \nMemoization ensures that the effects in e only happen once, at the .rst force of the recursive computation. \nThe dynamic semantics for this extension is given in Figure 10. To evaluate delay(e), we create a new \nmemoized location in the store and bind e to it (Rule 49). To evaluate force(e), we .rst evaluate e (Rule \n50). Once e evaluates to a location x, we look x up in the store. If x is bound to an expression e, we \nproceed to evaluate e,but .rst push on the continuation stack a memoization frame to remind us that the \nresult of evaluating e should be memoized at x (Rules 51 and 52). If x is instead bound to nonsense, \nthen we must be in the middle of evaluating another force(x), so we step to an Error state which halts \nthe program (Rule 53). Extending the type safety proof of Section 3.5 to handle memoized computations \nis straightforward; the details appear in the companion technical report [7]. 5 Related Work Well-Founded \nRecursion Boudol [4] proposes a type system for well-founded recursion that, like ours, employs a backpatching \nse\u00admantics. Boudol s system tracks the degrees to which expressions depend on their free variables, where \nthe degree to which e depends on x is 1 if x appears in a guarded position in e (i.e., under an un\u00adapplied \n.-abstraction), and 0 otherwise. What we call the support of an expression corresponds in Boudol s system \nto the set of vari\u00adables on which the expression depends with degree 0. Thus, while there is no distinction \nbetween recursive and ordinary variables in Boudol s system, his equivalent of rec(x :t.e) ensures that \nthe eval\u00aduation of e will not dereference x by requiring that e depend on x with degree 1. In our system \nan arrow type indicates the recursive variables that may be dereferenced when a function of that type \nis applied. An ar\u00adrow type in Boudol s system indicates the degree to which the body 01 of a function \ndepends on its argument. Thus, s -. t and s -. t classify functions that are strict and non-strict in \ntheir arguments, respectively. As we discussed in Section 3.3, the ability to identify non-strict functions \nis especially important for purposes of sepa\u00adrate compilation. For example, in order to typecheck our \nseparate compilation scenario from Figure 2, it is necessary to know that the separately-compiled functors \nmyA and yourB are non-strict. In contrast to our system, which requires the code from Figure 2 to be \nrewritten as shown in Figure 5, Boudol s system can typecheck the code in Figure 2 as is. The reason \nis that function applications of the form f (x) (i.e., where the argument is a variable) are treated \nas a special case in his semantics: while the expression x depends on the variable x with degree 0, the \nexpression f (x) merely passes x to f without dereferencing it. This implies that ordinary .-bound variables \nmay be instantiated at run time with recursive variables. Thus, viewed in terms of our semantics, Boudol \ns system treats all variables as implicitly having box type. The simplicity of Boudol s system is achieved \nat the expense of being rather conservative. In particular, a function application f (e) is considered \nto depend on all the free variables of f with degree 0. ' Suppose that f is a curried function .y..z.e \n' , where e dereferences a recursive variable x. In Boudol s system, even a single application of f will \nbe considered to depend on x with degree 0 and thus cannot appear unguarded in the recursive term de.ning \nx. To address the limitations of Boudol s system, Hirschowitz and Leroy [17] propose a generalization \nof it, which they use as the target language for compiling their call-by-value mixin module cal\u00adculus \n(see below). Speci.cally, they extend Boudol s notion of de\u00adgrees to be arbitrary integers: the degree \nto which e depends on x becomes, roughly, the number of .-abstractions under which x appears in e. Thus, \ncontinuing the above example, the function ' .y..z.e would depend on x with degree 2, so instantiating \nthe .rst argument would only decrement that degree to 1, not 0. Nevertheless, Hirschowitz and Leroy s \nsystem still suffers from a paucity of types. Consider the same curried function example, ex\u00ad ' cept \nwhere we let-bind .y..z.e .rst instead of applying it directly: ' let f = .y..z.e in f (e). The most \nprecise degree-based type one 10 can give to f when typing the body of the let is t1 -. t2 -. t3. This \ntype tells us nothing about the degree to which f depends on the recursive variable x dereferenced by \ne ' . Thus, Hirschowitz and Leroy s system must conservatively assume that f (e) may derefer\u00adence x. \nIn contrast, our type system can assign f a type such as 0/X t1 -. t2 -. t3, which would allow its .rst \nargument (but not its second) to be instantiated under the empty support. We believe the let expression \nabove is representative of code that one might want to write in the body of a recursive module, which \nsuggests that our name-based approach is a more appropriate foun\u00addation for recursive modules. However, \nthe weaknesses of the degree-based approaches are not necessarily problematic in the par\u00adticular applications \nfor which they were developed. For the pur\u00adpose of compiling mixin modules, the primary feature required \nof Hirschowitz and Leroy s target language is the ability to link mu\u00adtually recursive .-abstractions \nthat have been compiled separately. As we have illustrated in Section 3.3, our language supports this \nfeature as well. Weak Polymorphism and Effect Systems There seems to be an analogy between the approaches \ndiscussed here for tracking well\u00adfounded recursion and the work on combining polymorphism and effects \nin the early days of ML. Boudol s 0-1 distinction is reminis\u00adcent of Tofte s distinction between imperative \nand applicative type variables [30]. Hirschowitz and Leroy s generalization of Boudol is similar to the \nidea of weak polymorphism [15] (implemented by MacQueen in earlier versions of the SML/NJ compiler), \nwherein a type variable a carries a numeric strength representing, roughly, the number of function applications \nrequired before a ref cell is cre\u00adated storing a value of type a. Our system has ties to effect systems \nin the style of Talpin and Jouvelot [29], in which an arrow type in\u00addicates the set of effects that may \noccur when a function of that type is applied. For us, the effect in question is the dereferencing of \nan unde.ned recursive variable. A common criticism leveled at both effect systems and weak poly\u00admorphism \nis that functional and imperative implementations of a polymorphic function have different types, and \nit is impossible to know which type to expect when designing a speci.cation for a module separate from \nits implementation [31]. To a large extent, this criticism does not apply to our type system: names infect \ntypes within recursive modules, but the external interface of a module will be the same regardless of \nwhether or not the module is imple\u00admented recursively. To ensure that certain recursive modules (like \nthe one in Figure 6) are well-founded, however, one needs to ob\u00adserve that a general-purpose functor \n(like the MakeSet functor) is non-strict, and it is debatable whether the (non-)strictness of such a \nfunctor should be re.ected in its speci.cation. Choosing not to ex\u00adpose strictness information in the \nspeci.cation of a functor imposes fundamental limitations on how the functor can be used, not just in \nour system, but in any type system for well-founded recursion. Strictness Analysis One can think of static \ndetection of well\u00adfounded recursion as a kind of non-strictness analysis, in contrast to the well-known \nproblem of strictness analysis [1]. Both prob\u00adlems are concerned with identifying whether an expression, \nsuch as the body of a function, will access the value of a particular variable when evaluated. Strictness \nanalysis, however, is used as an optimization technique for lazy languages, in which any func\u00adtion may \nbe conservatively classi.ed as non-strict. In call-by\u00advalue languages, on the other hand, functions are \nstrict by default observing that a function is non-strict requires us to explicitly treat its argument \nas boxed and to show that applying the function will not unbox it. It is thus unclear how techniques \nfrom strictness anal\u00adysis might be applied to the well-founded recursion problem. Names The idea of using \nnames in our type system is inspired by Nanevski s work on using a modal logic with names to model a \nmetaprogramming language for symbolic computation [23]. (His use of names was in turn inspired by Pitts \nand Gabbay s FreshML [27].) Nanevski uses names to represent unde.ned sym\u00adbols appearing inside expressions \nof a modal . type. These ex\u00adpressions can be viewed as pieces of uncompiled syntax whose free names must \nbe de.ned before they can be compiled. Our use of names is conceptually closer to Nanevski s more recent \nwork (concurrent with ours) on using names to model control ef\u00adfects for which there is a notion of handling \n[24]. As mentioned earlier, one can think of the dereferencing of a recursive variable as an effect that \nis in some sense handled by the backpatching of the variable. Formally, though, Nanevski s system is \nquite dif\u00adferent, especially in that it does not employ any judgment of type equivalence modulo a support. \nMonadic Recursion There has been considerable work recently on adding effectful recursion to Haskell. \nSince effects in Haskell are isolated in monadic computations, adding a form of recursion over effectful \nexpressions requires an understanding of how recur\u00adsion interacts with monads. Erk\u00a8ok and Launchbury \n[11] propose a monadic .xed-point construct m.x for de.ning recursive compu\u00adtations in monads that satisfy \na certain set of axioms. They later show how to use m.x to de.ne a recursive form of Haskell s do construct \n[12]. Friedman and Sabry [14] argue that the backpatch\u00ading semantics of recursion is fundamentally stateful, \nand thus de.n\u00ading a recursive computation in a given monad requires the monad to be combined with a state \nmonad. This approach allows recursion in monads that do not obey the Erk\u00a8ok-Launchbury axioms, such as \nthe continuation monad. The primary goal of our type system is to statically ensure well\u00adfounded recursion \nin an impure call-by-value setting, and thus the work on recursive monadic computations for Haskell (which \navoids any static analysis) is largely orthogonal to ours. Nevertheless, the dynamic semantics of our \nlanguage borrows from recent work by Moggi and Sabry [22], who give an operational semantics for the \nmonadic metalanguage extended with the Friedman-Sabry m.x. Recursive Modules Most recursive module proposals \nrestrict the form of the recursive module construct so that recursion is not de\u00ad.ned over effectful expressions. \nOne exception is Russo s exten\u00adsion to Moscow ML [28], which employs an unrestricted form of recursion \nsimilar to our urec construct from Section 4. Another is Leroy s experimental extension to O Caml [20], \nwhich permits arbitrary effects in recursive modules but restricts backpatching to modules of pointed \ntype, i.e., modules that export only functions and lazy computations. This restriction enables more ef.cient \nim\u00adplementation, since for pointed types there is an appropriate bot\u00adtom value with which to initialize \nthe recursive variable. One can apply the same optimization to our urec(x : t.e) in the case that t is \npointed. Our system, however, permits examples like the one in Figure 1, which Leroy s extension does \nnot. Crary, Harper and Puri [5] give a foundational account of recursive modules that models recursion \nvia a .xed-point at the module level. For the .xed-point semantics to make sense, they require that the \nbody of a .xed-point module is valuable (i.e., pure and terminat\u00ading) in a context where the recursive \nvariable is non-valuable. Our judgment of evaluability from Section 2 can be seen as a general\u00adization \nof valuability. Similarly, Flatt and Felleisen s proposal for units [13] divides the recursive module \nconstruct into a recursive section, restricted to contain only valuable expressions, and an un\u00adrestricted \ninitialization section evaluated after the recursive knot is tied. Duggan and Sourelis [9, 10] study \na mixin module extension to ML, which allows function and datatype de.nitions to span module boundaries. \nLike Flatt and Felleisen, they con.ne such extensible function de.nitions to the mixin section of a mixin \nmodule, sep\u00adarate from the effectful initialization section. There have also been several proposals based \non Ancona and Zucca s calculus CMS for purely functional call-by-name mixin modules [3]. In one direction, \nrecent work by Ancona et al. [2] extends CMS with computational effects encapsulated by monads. They \nhandle recursive monadic computations using a recursive do construct based on Erk\u00a8ok and Launchbury s \n[12]. In another direc\u00adtion, Hirschowitz and Leroy [17] transfer CMS to a call-by-value setting. Their \ntype system performs a static analysis of mixin mod\u00adules to ensure well-founded recursive de.nitions, \nbut it requires the strictness dependencies between module components to be written explicitly in the \ninterfaces of modules. 6 Conclusion and Future Work We have proposed a novel type system for general \nrecursion over effectful expressions, to serve as the foundation of a recursive mod\u00adule extension to \nML. The presence of effects seems to necessitate a backpatching semantics for recursion similar to that \nof Scheme. Our type system ensures statically that recursion is well-founded, avoiding some unnecessary \nrun-time costs associated with back\u00adpatching. To ensure well-founded recursion in the presence of multiple \nrecursive variables and separate compilation, we track the usage of individual recursive variables, represented \nstatically by names. Our core system is easily extended to account for the com\u00adputational effects of \nmutable state and continuations. In addition, we extend our language with a form of memoized computation, \nwhich allows us to write arbitrary recursive de.nitions at the ex\u00adpense of an additional run-time cost. \nThe explicitly-typed version of our type system admits a straightfor\u00adward typechecking algorithm, and \ncould serve as a target language for compiling a recursive extension to ML. An important direction for \nfuture work is to determine the extent to which names should be available to the ML programmer. This \nwill depend heavily on the degree to which types involving names can be inferred when typechecking recursive \nmodules. Another key direction for future work is to scale our approach to the module level. In addition \nto the issues involving recursion at the level of types [8], there is the question of how names and recursion \ninteract with other module-level features such as type generativity. We are currently investigating this \nquestion by combining the lan\u00adguage presented here with our previous work on a type system for higher-order \nmodules [6].  Acknowledgments The author would like to thank Bob Harper and Karl Crary for in\u00advaluable \ndiscussions and guidance throughout the development of this work. References [1] Samson Abramsky and \nChris Hankin, editors. Abstract Inter\u00adpretation of Declarative Languages. Ellis Horwood Limited, 1987. \n[2] Davide Ancona, Sonia Fagorzi, Eugenio Moggi, and Elena Zucca. Mixin modules and computational effects. \nIn 2003 International Colloquium on Languages, Automata and Pro\u00adgramming, Eindhoven, The Netherlands, \n2003. [3] Davide Ancona and Elena Zucca. A primitive calculus for module systems. In International Conference \non Principles and Practice of Declarative Programming, volume 1702 of Lecture Notes in Computer Science, \npages 62 79. Springer-Verlag, 1999. [4] Gerard Boudol. The recursive record semantics of objects revisited. \nResearch report 4199, INRIA, 2001. To appear in the Journal of Functional Programming. [5] Karl Crary, \nRobert Harper, and Sidd Puri. What is a recursive module? In 1999 Conference on Programming Language \nDe\u00adsign and Implementation (PLDI), pages 50 63, Atlanta, GA. [6] Derek Dreyer, Karl Crary, and Robert \nHarper. A type system for higher-order modules. In 2003 ACM Symposium on Prin\u00adciples of Programming Languages, \npages 236 249, 2003. [7] Derek Dreyer, Robert Harper, and Karl Crary. A type system for well-founded \nrecursion. Technical Report CMU-CS-03\u00ad163, Carnegie Mellon University, July 2003. [8] Derek R. Dreyer, \nRobert Harper, and Karl Crary. Toward a practical type theory for recursive modules. Technical Report \nCMU-CS-01-112, School of Computer Science, Carnegie Mellon University, March 2001. [9] Dominic Duggan \nand Constantinos Sourelis. Mixin modules. In 1996 ACM SIGPLAN International Conference on Func\u00adtional \nProgramming, pages 262 273, Philadelphia, Pennsyl\u00advania, June 1996. [10] Dominic Duggan and Constantinos \nSourelis. Parameterized modules, recursive modules, and mixin modules. In 1998 ACM SIGPLAN Workshop on \nML, pages 87 96, Baltimore, Maryland, September 1998. [11] Levent Erk\u00a8ok and John Launchbury. Recursive \nmonadic bind\u00adings. In 2000 International Conference on Functional Pro\u00adgramming, pages 174 185, Paris, \nFrance, 2000. [12] Levent Erk\u00a8ok and John Launchbury. A recursive do for Haskell. In 2002 Haskell Workshop, \nOctober 2002. [13] Matthew Flatt and Matthias Felleisen. Units: Cool modules for HOT languages. In 1998 \nACM SIGPLAN Conference on Programming Language Design and Implementation, pages 236 248, Montreal, Canada, \nJune 1998. [14] Daniel P. Friedman and Amr Sabry. Recursion is a compu\u00adtational effect. Technical Report \nTR546, Indiana University, December 2000. [15] John Greiner. Weak polymorphism can be sound. Journal \nof Functional Programming, 6(1):111 141, 1996. [16] Robert Harper and Mark Lillibridge. A type-theoretic \nap\u00adproach to higher-order modules with sharing. In Twenty-First ACM Symposium on Principles of Programming \nLanguages, pages 123 137, Portland, OR, January 1994. [17] Tom Hirschowitz and Xavier Leroy. Mixin modules \nin a call\u00adby-value setting. In 2002 European Symposium on Program\u00adming, volume 2305 of Lecture Notes \nin Computer Science, pages 6 20, 2002. [18] Tom Hirschowitz, Xavier Leroy, and J. B. Wells. Compilation \nof extended recursion in call-by-value functional languages. In 2003 International Conference on Principles \nand Practice of Declarative Programming, Uppsala, Sweden. [19] Richard Kelsey, William Clinger, and Jonathan \nRees (eds.). Revised5 report on the algorithmic language Scheme. Higher-Order and Symbolic Computation, \n11(1), September 1998. [20] Xavier Leroy. A proposal for recursive modules in Objective Caml, May 2003. \nAvailable from the author s web site. [21] Robin Milner, Mads Tofte, Robert Harper, and David Mac-Queen. \nThe De.nition of Standard ML (Revised). MIT Press, 1997. [22] Eugenio Moggi and Amr Sabry. An abstract \nmonadic seman\u00adtics for value recursion. In 2003 Workshop on Fixed Points in Computer Science, April 2003. \n[23] Aleksandar Nanevski. Meta-programming with names and necessity. In 2002 International Conference \non Functional Programming, pages 206 217, Pittsburgh, PA, 2002. A sig\u00adni.cant revision is available as \na technical report CMU-CS\u00ad02-123R, Carnegie Mellon University. [24] Aleksandar Nanevski. A modal calculus \nfor effect handling. Technical Report CMU-CS-03-149, Carnegie Mellon Univer\u00adsity, June 2003. [25] Objective \nCaml. http://www.ocaml.org. [26] Chris Okasaki. Purely Functional Data Structures. Cam\u00adbridge University \nPress, 1998. [27] Andrew M. Pitts and Murdoch J. Gabbay. A metalanguage for programming with bound names \nmodulo renaming. In Roland Backhouse and Jos\u00b4e Nuno Oliveira, editors, Math\u00adematics of Program Construction, \nvolume 1837 of Lecture Notes in Computer Science, pages 230 255. Springer, 2000. [28] Claudio V. Russo. \nRecursive structures for Standard ML. In International Conference on Functional Programming, pages 50 \n61, Florence, Italy, September 2001. [29] Jean-Pierre Talpin and Pierre Jouvelot. The type and effect \ndiscipline. Information and Computation, 111(2):245 296, 1994. [30] Mads Tofte. Operational Semantics \nand Polymorphic Type Inference. PhD thesis, University of Edinburgh, 1988. [31] Andrew K. Wright. Simple \nimperative polymorphism. Lisp and Symbolic Computation, 8(4):343 355, 1995.  \n\t\t\t", "proc_id": "964001", "abstract": "In the interest of designing a recursive module extension to ML that is as simple and general as possible, we propose a novel type system for general recursion over effectful expressions. The presence of effects seems to necessitate a backpatching semantics for recursion similar to that of Scheme. Our type system ensures statically that recursion is well-founded---that the body of a recursive expression will evaluate without attempting to access the undefined recursive variable---which avoids some unnecessary run-time costs associated with backpatching. To ensure well-founded recursion in the presence of multiple recursive variables and separate compilation, we track the usage of individual recursive variables, represented statically by \"names\". So that our type system may eventually be integrated smoothly into ML's, reasoning involving names is only required inside code that uses our recursive construct and need not infect existing ML code, although instrumentation of some existing code can help to improve the precision of our type system.", "authors": [{"name": "Derek Dreyer", "author_profile_id": "81100381796", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P414177", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/964001.964026", "year": "2004", "article_id": "964026", "conference": "POPL", "title": "A type system for well-founded recursion", "url": "http://dl.acm.org/citation.cfm?id=964026"}