{"article_publication_date": "01-01-2004", "fulltext": "\n Tridirectional Typechecking Joshua Dun.eld Frank Pfenning joshuad@cs.cmu.edu fp@cs.cmu.edu Carnegie \nMellon University Pittsburgh, PA ABSTRACT In prior work we introduced a pure type assignment system that \nencompasses a rich set of property types, including intersections, unions, and universally and existentially \nquanti.ed dependent types. This system was shown sound with respect to a call-by-value oper\u00adational semantics \nwith effects, yet is inherently undecidable. In this paper we provide a decidable formulation for this \nsys\u00adtem based on bidirectional checking, combining type synthesis and analysis following logical principles. \nThe presence of unions and existential quanti.cation requires the additional ability to visit sub\u00adterms \nin evaluation position before the context in which they occur, leading to a tridirectional type system. \nWhile soundness with re\u00adspect to the type assignment system is immediate, completeness requires the novel \nconcept of contextual type annotations, intro\u00adducing a notion from the study of principal typings into \nthe source program. Categories and Subject Descriptors: F.3.3 [Logics and Mean\u00adings of Programs]: Studies \nof Program Constructs Type structure; D.3.1 [Programming Languages]: Formal De.nitions and Theory General \nTerms: Languages, Theory Keywords: Type re.nements, intersection types, union types, de\u00ad pendent types \n 1. INTRODUCTION Over the last two decades, there has been a steady increase in the use of type systems \nto capture program properties such as control .ow [15], memory management [22], aliasing [20], data structure \ninvariants [11, 7, 28] and effects [21, 14], to mention just a few. Ideally, such type systems specify \nrigorously, yet at a high level of abstraction, how to reason about a certain class of program proper\u00adties. \nThis speci.cation usually serves a dual purpose: it is used to relate the properties of interest to the \noperational semantics of the programming language (for example, proving type preservation), and it is \nthe basis for concrete algorithms for program analysis (for example, via constraint-based type inference). \nWhile the type-based approach has been successful for use in automatic program analysis (for example, \nfor optimization during Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. POPL 04, January 14 16, 2004, Venice, Italy. Copyright 2004 ACM 1-58113-729-X/04/0001 ...$5.00. \n compilation), it has been less successful in making the expressive type systems directly available to \nthe programmer. One reason for this is the dif.culty of .nding the right balance between the brevity \nof the additional required type declarations and the feasibility of the typechecking problem. Another \nis the dif.culty of giving precise and useful feedback to the programmer on ill-typed programs. In prior \nwork [9] we developed a system of pure type assign\u00adment designed for call-by-value languages with effects \nand proved progress and type preservation. The intended atomic program prop\u00aderties are data structure \nre.nements [11, 10, 28], but our approach does not depend essentially on this choice. Atomic properties \ncan be combined into more complex ones through intersections, unions, and universal and existential quanti.cation \nover index domains. As a pure type assignment system, where terms do not contain any types at all, it \nis inherently undecidable [4]. In this paper we develop an annotation discipline and typecheck\u00ading algorithm \nfor our earlier type assignment system. The major contribution is the type system itself which contains \nseveral novel ideas, including an extension of the paradigm of bidirectional type\u00adchecking to union and \nexistential types, leading to the tridirectional system. While type soundness follows immediately by \nerasure of annotations, completeness requires that we insert contextual typing annotations reminiscent \nof principal typings [13, 25]. Decidability is not obvious; we prove it by showing that a slightly altered \nleft tridirectional system is decidable (and sound and complete with re\u00adspect to the tridirectional system). \nThe basic underlying idea is bidirectional checking [18] of pro\u00adgrams containing some type annotations, \ncombining type synthesis with type analysis, .rst adapted to property types by Davies and Pfenning [7]. \nSynthesis generates a type for a term from its im\u00admediate subterms. Logically, this is appropriate for \ndestructors (or elimination forms) of a type. For example, the .rst product elimina\u00adtion passes from \ne :A*B to fst(e):A. Therefore, if we can gener\u00adate A *B we can extract A. Dually, analysis veri.es that \na term has a given type by verifying appropriate types for its immediate sub\u00adterms. Logically, this is \nappropriate for constructors (or introduc\u00adtion forms) of a type. For example, to verify that .x. e :A \n. B we assume x :A and then verify e :B. Bidirectional checking works for both the native types of the \nunderlying programming language and the layer of property types we construct over it. However, the simple \nbidirectional model is not suf.cient for what we call inde.nite property types: unions and existential \nquanti.ca\u00adtion. This is because the program lacks the prerequisite structure. For example, if we synthesize \nA . B, the union of A and B, for an expression e, we now need to distinguish the cases: the value of \ne might have type A or it might have type B. Determining the proper scope of this case distinction depends \non how e is used, that is, the position in which e occurs. This means we need a third di\u00adrection (whence \nthe name tridirectional): we might need to move to a subexpression, synthesize its type, and only then \nanalyze the expression surrounding it. Since the tridirectional type system (like the bidirectional one) \nrequires annotations, we want to know that any program well typed in the type assignment system can be \nannotated so that it is also well typed in the tridirectional system. But with intersection types, such \na completeness property does not hold for the usual notion of type annotation (e : A)(as previously noted \n[16, 6, 23]), a prob\u00adlem exacerbated by scoping issues arising from quanti.ed types. We therefore extend \nthe notion of type annotation to contextual typing annotation, (e : G1 f A1 ,...,Gn f An ), in which \nthe programmer can write several context/type pairs. The idea is that an annotation Gk f Ak may be used \nwhen eis checked in a context matching Gk . This idea might also be applicable to arbitrary rank polymorphism, \na possibility we plan to explore in future work. Unlike the bidirectional system, the inde.nite property \ntypes that necessitate the third direction make decidability of typechecking nontrivial. Two ideas come \nto the rescue. First, to preserve type safety in a call-by-value language with effects, the type of a \nsub\u00adterm ecan only be brought out if the term containing it has the form E[e]for some evaluation context \nE, reducing the nondeterminism; this was a key observation in our earlier paper [9]. Second, one never \nneeds to visit a subterm more than once in the same deriva\u00adtion: the system which enforces this is sound \nand complete. The remainder of the paper is organized as follows. Section 2 presents a simple bidirectional \ntype system. Section 3 adds re.ne\u00adments and a rich set of types including intersections and unions, using \ntridirectional rules; this is the simple tridirectional system. In Section 4, we explain our form of \ntyping annotation and prove that the simple tridirectional system is complete with respect to the type \nassignment system. Section 5 restricts the tridirectional rules and compensates by introducing left rules \nto yield a left tridirec\u00adtional system. We prove soundness and completeness with respect to the simple \ntridirectional system, prove decidability, and use the results in [9] to prove type safety. Finally, \nwe discuss related work (Section 6) and conclude (Section 7).  2. THE CORE LANGUAGE In a pure type assignment \nsystem, the typing judgment is e : A, where e contains no types (eliding contexts for the moment). In \na bidirectional type system, we have two typing judgments: e . A, read e synthesizes A, and e . A, read \ne checks against A. The most straightforward implementation of such a system consists of two mutually \nrecursive functions: the .rst, corresponding to e . A, takes the term e and either returns A or fails; \nthe second, corre\u00adsponding to e . A, takes the term e and a type A and succeeds (returning nothing) or \nfails. This raises a question: Where do the types in the judgments e . A come from? More generally: what \nare the design principles behind a bidirectional type system? Avoiding uni.cation or similar techniques \nassociated with full type inference is fundamental to the design of the bidirectional sys\u00adtem we propose \nhere. The motivation for this is twofold. First, for highly expressive systems such as the ones under \nconsideration here, full type inference is often undecidable, so we need less au\u00adtomatic and more robust \nmethods. Second, since uni.cation glob\u00adally propagates type information, it is often dif.cult to pinpoint \nthe source of type errors. We think of the process of bidirectional typechecking as a bottom\u00adup construction \nof a typing derivation, either of e . A or e . A. Given that we want to avoid uni.cation and similar \ntechniques, we need each inference rule to be mode correct, terminology borrowed from logic programming. \nThat is, for any rule with conclusion e . A we must be able to determine A from the information in the \npremises. Conversely, if we have a rule with premise e . A,we must be able to determine Abefore traversing \ne. However, mode correctness by itself is only a consistency re\u00adquirement, not a design principle. We \n.nd such a principle in the realm of logic, and transfer it to our setting. In natural deduction, we \ndistinguish introduction rules and elimination rules. An intro\u00adduction rule speci.es how to infer a proposition \nfrom its compo\u00adnents; when read bottom-up, it decomposes the proposition. For example, the introduction \nrule for the conjunction A * B decom\u00adposes it to the goals of proving A and B. Therefore, a rule that \nchecks a term against A*Busing an introduction rule will be mode correct. G f e1 . A1 G f e2 . A2 (*I) \nG f (e1 ,e2 ). A1 * A2 Conversely, an elimination rule speci.es how to use the fact that a certain proposition \nholds; when read top-down, it decomposes a proposition. For example, the two elimination rules for the \ncon\u00adjunction A* B decompose it to A and B, respectively. Therefore, a rule that infers a type for a term \nusing an elimination rule will be mode correct. G f e . A* B G f fst(e). A (*E1 ) G f e . A* B G f snd(e). \nB (*E2) If we employ this design principle throughout, the constructors (corresponding to the introduction \nrules) for the elements of a type are checked against a given type, while the destructors (correspond\u00ading \nto the elimination rules) for the elements of a type synthesize their type. This leads to the following \nrules for functions, in which rule (.I) checks against A . B and rule (.E) synthesizes the type A . Bof \nits subject e1 . G,x:A f e . BG f e1 . A. BG f e2 . A (.I)(.E) G f .x.e . A . BG f e1 e2 . B What do \nwe do when the different judgment directions meet? If we are trying to check e . A then it is suf.cient \nto synthesize a type e . A' and check that A' = A. More generally, in a system with subtyping, it is \nsuf.cient to know that every value of type A' also has type A, that is, A' = A. G f e . A' G f A' = A \n(sub) G f e . A In the opposite direction, if we want to synthesize a type for ebut can only check eagainst \na given type, then we do not have enough information. In the realm of logic, such a step would correspond \nto a proof that is not in normal form (and might not have the sub\u00adformula property). The straightforward \nsolution would be to allow source expressions (e : A)via a rule G f e . A G f (e : A). A Unfortunately, \nthis is not general enough due to the presence of intersections and universally and existentially quanti.ed \nproperty types. We discuss the issues and our solution in detail in Section 4. For now, only normal terms \nwill typecheck in our system. These correspond exactly to normal proofs in natural deduction. We can \ntherefore already pinpoint where annotations will be required in the full system: exactly where the term \nis not normal. This will be the case where destructors are applied to constructors (that is, as redexes) \nand at certain let forms. In addition we permit datatypes d with constructors c(e) and corresponding \ncase expressions case eof ms, where the match ex\u00adpressions mshave the form c1 (x1 ). e1 | ...cn (xn ). \nen . The constants care the constructors and case the destructor of elements Types A, B, C ::= 1 | A \n. B | A *B | d Terms e ::= x | u | .x. e | e1 e2 | .x u. e | () | (e1 ,e2 )| fst(e)| snd(e) | c(e)| case \ne of ms Matches ms ::= \u00b7 | c(x). e|ms Values v ::= x | .x. e | () | (v1,v2) Eval. contexts E ::=[] | \nE(e)| v(E) | (E, e)| (v, E)| fst(E)| snd(E) | c(E)| case E of ms e ' e '' .R E[e ' ]. E[e '' ] (.x. e)v \n[v/x]e fst(v1,v2 ) v1 .R .R .x u. e [.x u. e/u]e snd(v1,v2 ) v2 .R .R case c(v)of ...c(x). e... [v/x]e \n.R Figure 1: Syntax and semantics of the core language of type d. This means expressions c(e)are checked \nagainst a type, while the subject of a case must synthesize its type. Assuming con\u00adstructors have type \nA . d, this yields the following rules. c : A . dG fe . AG fe . dG fms .d B (dI)(dE) G fc(e). dG fcase \ne of ms . B c : A . d G,x:A fe . BG fms .d B G f\u00b7.d BG fc(x). e | ms .d B We have elided here a syntactic \ncondition that the left-hand sides of a case expression with subject d cover all constructors for a type \nd. Note that in the elimination rule (dE), we move from e . d to x:A (which may be read x.A), checking \neach branch against B. In addition we have .xed points, which involve both directions: to check .x u. \ne . A, we assume u:A (which should be read u.A) and check e against A. Here we have a new form of variable \nu that does not stand for a value, but for an arbitrary term, because the reduction form for .xed point \nexpressions reduces .x u. e to [.x u. e / u]e (the substitution of .x u. e for u in e). Wedo not exploit \nthis generality here, but our design is clearly consistent with common syntactic restriction on the formation \nof .xed points in call-by-value languages. The syntax and semantics of our core language is given in \nFigure 1. A capital E denotes an evaluation context a term with a hole [] representing the part of the \nterm where a reduction may occur. The semantics is a straightforward call-by-value small-step formu\u00adlation. \n[e ' /x]e denotes the substitution of e ' for x in e. Figure 2 shows the subtyping and typing rules for \nthe initial lan\u00adguage. The subtyping rules are standard except for the presence of the context G, used \nby the subtyping rules for index re.nements and index quanti.ers, which we add in the next section. Variables \nmust appear in G,so(var) is a synthesis rule deriving x . A. The subsumption rule (sub) is an analysis \nrule deriving e . B, but its .rst premise is a synthesis rule e . A. This means both A and B are available \nwhen the subtyping judgment A =B is invoked; no complex constraint management is necessary. For introduction \nand elimination rules, we follow the principles outlined above. Note that in practice, in applications \ne1 e2 , the function e1 will usually be a variable or, in a curried style, another application since \nwe synthesize types for these, e1 e2 itself needs no annotation. Ours is not the only plausible formulation \nof bidirectionality. Xi [26] used a contrasting style, in which several introduction forms have synthesis \nrules as well as checking rules, for example: G fe1 . A1 G fe2 . A2 G f(e1 ,e2 ). A1 *A2 Xi s formulation \nreduces the number of annotations to some extent; for example, in case (x, y)of ... the pair (x, y)must \nsynthesize, but under our formulation (x, y)never synthesizes and so requires an annotation. However, \nours seems to be the simplest plausible formulation and has a clear logical foundation in the notion \nof in\u00adtroduction and elimination forms corresponding to constructors and destructors for elements of \na type under the Curry-Howard isomor\u00adphism. Consequently, a systematic extension should suf.ce to add \nfurther language constructs. Furthermore, any term in normal form will need no annotation except at the \noutermost level, so we should need annotations in few places besides function de.nitions. In any case, \nif a system based on our formulation turns out to be inconve\u00adnient, adding rules such as the one above \nshould not be dif.cult. 3. PROPERTY TYPES The types present in the language so far are tied to constructors \nand destructors of terms. For example, the type A . B is realized by constructor .x. e and destructor \ne1 e2 , related to the introduction and elimination forms of . by a Curry-Howard correspondence. In this \nsection we are concerned with expressing richer proper\u00adties of terms already present in the language. \nThe only change to the term language is to add typing annotations, discussed in Section 4; otherwise, \nonly the language of types is enriched: Types A, B, C ::= ... | d(i)| A . B | T| .a:.. A | A . B | .| \nSa:.. A The basic properties are data structure invariants, that is, proper\u00adties of terms of the form \nc(e). All other properties are independent of the term language and provide general mechanisms to combine \nsimpler properties into more complex ones, yielding a very general type system. In this paper we do not \nformally distinguish between ordinary types and property types, though such a distinction has been useful \nin the study of re.nement types [11, 10]. Our formulation of property types is fully explained and justi\u00ad.ed \nin [9] for a pure type assignment system; here, we focus on the bidirectionality of the rules. We do \nnot extend the operational semantics: it is easiest to erase annotations before executing the program. \nHence, type safety follows directly from the result for the type assignment system [9]. 3.1 Intersections \nA value v has type A . B if it has type A and type B. Because this is an introduction form, we proceed \nby checking v against A and B. Conversely, if e has type A . B then it must have both type A and type \nB, proceeding in the direction of synthesis. G fv . AG fv . B (.I) G fv . A . B G fe . A . BG fe . A \n. B (.E1 )(.E2) G fe . AG fe . B While these rules combine properties of the same term (and are therefore \nnot an example of a Curry-Howard correspondence), the erasure of the terms still yields the ordinary \nlogical rules for con\u00adjunction. Therefore, by the same reasoning as for ordinary types, the directionality \nof the rules follows from logical principles. Usually, the elimination rules are a consequence of the \nsubtyp\u00ading rules (via the (sub) typing rule), but once bidirectionality is enforced, this is not the \ncase and the rules must be taken as prim\u00aditive. Note that the introduction form (.I) is restricted to \nvalues because its general form for arbitrary expressions e is unsound in the presence of mutable references \nin call-by-value languages [7]. G fB1 =A1 G fA2 =B2 (.)(1) G fA1 . A2 =B1 . B2 G f1 =1 G(x)= A G,x:A \nfe . B  (var)(.I) G fx . AG f.x. e . A . B G fA1 =B1 G fA2 =B2 (*)(d) G fA1 *A2 =B1 *B2 G fd =d G \nfe1 . A . BG fe2 . A (.E) G fe1 e2 . B G fe . AG fA =BG(u)= A G,u:A fe . A (sub)(.xvar) G fe . BG fu \n. AG f.x u. e . A G fe1 . A1 G fe2 . A2 G fe . A *BG fe . A *B (*I)(*E1 )(*E2 ) G f(e1 ,e2 ). A1 *A2 \nG ffst(e). AG fsnd(e). B (.x) (1I) G f() . 1 c : A . dG fe . AG fe . dG fms .d Bc : A . dG,x:A fe . \nBG fms .d B (dI)(dE) G fc(e). dG fcase e of ms . BG f\u00b7.d BG fc(x). e|ms .d B Figure 2: Subtyping and \ntyping in the core language The subtyping rules for our system are designed following the well-known \nprinciple that A =B only if any (closed) value of type A also has type B. Thus, whenever we must check \nif an expression e has type B we are safe if we can synthesize a type A and A =B. The subtyping rules \nthen naturally decompose the structure of A and B by so-called left and right rules that closely mirror \nthe rules of a sequent calculus. In fact, ignoring G for now, we can think of subtyping as a single-antecedent, \nsingle-succedent form of the sequent calculus. G fA =B1 G fA =B2 (.R) G fA =B1 . B2 G fA1 =BG fA2 =B \n(.L1 )(.L2 ) G fA1 . A2 =BG fA1 . A2 =B We omit the common distributivity rule relating intersection \nand function types, which is unsound with mutable references [7] and does not directly .t into the logical \npattern of our rules.  3.2 Greatest Type A greatest type Tcan be thought of as the 0-ary form of inter\u00adsection \n(.). The rules are simply (TI)(TR) G fv . T G fA =T There is no elimination or left subtyping rule for \nT. Its typing rule is a 0-ary version of (.I), and the value restriction is also re\u00adquired [9].  3.3 \nRe.ned Datatypes In our system, each datatype is re.ned as in [6, 8, 9] by an atomic subtyping relation \n. over datasorts d. Each datasort iden\u00adti.es a subset of values of the form c(v). For example, datasorts \ntrue and false identify singleton subsets of values of the type bool. We further re.ne datatypes by indices \ndrawn from some constraint domain, exactly as in [9] which closely followed Xi and Pfen\u00adning [28], Xi \n[26, 27], and Dun.eld [8]. The type d(i)is the type of values having datasort d and index i. To accommodate \nindex re.nements, we extend G to allow index variables a, b and propositions P as well as program variables. \nBe\u00adcause the program variables are irrelevant to the index domain, we can de.ne a restriction function \nG that yields its argument G without program variable typings (Figure 3). No variable may be declared \ntwice in G, but ordering is now signi.cant because of dependencies. Our formulation, like Xi s, requires \nonly a few properties of the constraint domain: There must be a way to decide a consequence relation \nG |= P whose interpretation is that given the index variable typings and propositions in G, the proposition \nP must hold. Because  Figure 3: Propositions P, contexts G, and the restriction func\u00adtion G we have \nboth universal and existential quanti.ers over elements of the constraint domain, the constraints must \nremain decidable in the presence of quanti.ers, though we have not encountered quanti.er . alternations \nin our examples. There must also be a relation i = j denoting index equality, and a judgment G fi : . \nwhose interpre\u00adtation is that i has index sort . in G. Note the strati.cation: terms have types, indices \nhave index sorts; terms and indices are distinct. The proof of safety in [9] requires that |= be a consequence \nrela\u00ad . tion, that = be an equivalence relation, that \u00b7| = ., and that |= and fhave expected substitution \nand weakening properties [8]. Each datatype has an associated atomic subtyping relation on datasorts, \nand an associated sort whose indices re.ne the datatype. . In this paper, the only index sort is the \nnatural numbers N with = and the arithmetic operations +, -, *. Then G |= P is decidable provided the \nequalities in P are linear. We add an in.nitary de.nite type .a:.. A, introducing an index variable a \nuniversally quanti.ed over indices of sort .. One can also view . as a dependent function type on indices \n(instead of arbitrary terms). Example. Assume we de.ne a datatype of integer lists: a list is either \nNil() or Cons(h, t)for some integer h and list t. Re.ne this type by a datasort odd if the list s length \nis odd, by a datasort even if it is even. We also re.ne the lists by their length, so Nil has type 1 \n. even(0), and Cons has type (.a:N. int *even(a) . odd(a + 1)) . (.a:N. int *odd(a) . even(a + 1)). Writing \nNil() as Nil, the function .x repeat..x. case x of Nil . Nil | Cons(h,t) . Cons(h,Cons(h,repeat(t))) \n checks against .a:N. list(a). even(2 *a). The subtyping rule for datatypes checks the datasorts d1 ,d2 \nand (separately) the indices i, j: . d1 .d2 G fi = j (d) G fd1 (i)=d2 (j) . P ::= .| i = j | ... G ::= \n\u00b7| G, x:A | G, a:. | G, P \u00b7 = \u00b7 G, x:A = G G, a:. = G,a:. G, P = G,P To maintain re.exivity and transitivity \nof subtyping, we require . to be re.exive and transitive. We assume the constructors c are typed by a \njudgment G f c : A . d(i)where A is any type and d(i)is some re.ned type. Now, however, the type A . \nd(i)need not be unique; indeed, a constructor should often have more than one re.ned type. The rule for \nconstructor application is G f c :A . d(i) G f e . A (dI) G f c(e). d(i) To derive G f case e of ms . \nB, we check that all the matches in ms check against B, under a context appropriate to each arm; this \nis how propositions P arise. The context G may be contradictory (G |= .) if the case arm can be shown \nto be unreachable by virtue of the index re.nements of the constructor type and the case subject. In \norder to not typecheck unreachable arms, we have G |= . (contra) G f e . A We also do not check case \narms that are unreachable by virtue of the datasort re.nements. For a complete accounting of how we type \ncase expressions and constructors, see [8]. The typing rules for . are G, a:. f v . AG f e . .a:..A G \nf i :. (.I)(.E) G f v . .a:..A G f e . [i/a]A By our general assumption, the index variable a added to \nthe context must be new, which can always be achieved via renaming. The directionality of these rules \nfollows our general scheme. As for intersections, the introduction rule is restricted to values in order \nto maintain type preservation in the presence of effects. One potentially subtle issue with the introduction \nrule is that v cannot reference a in an internal type annotation, because that would violate a-conversion: \none could not safely rename a to b in .a:.. A, which is the natural scope of a. We describe our solution, \ncontextual typing annotations, in Section 4. The subtyping rules for . are G f [i/a]A = BG f i :. G,b:. \nf A = B (.L) (.R) G f .a:.. A = BG f A = .b:.. B The left rule allows one to instantiate a quanti.ed \nindex variable a to an index i of appropriate sort. The right rule states that if A = B for an arbitrary \nb:. then A is also a subtype of .b:.. B.Of course, b cannot occur free in A. As written, in (.L) and \n(.E) we must guess the index i; in prac\u00adtice, we would plug in a new existentially quanti.ed index vari\u00adable \nand continue, using constraint solving to determine i. Thus, even if we had no existential types S in \nthe system, the solver for the constraint domain would have to allow existentially quanti.ed variables. \n 3.4 Inde.nite Property Types We now have a system with de.nite types ., T, .. The typing and subtyping \nrules are both orthogonal and internally regular: no rule mentions both T and .,(TI) is a 0-ary version \nof (.I), and so on. However, one cannot express the types of functions with indeterminate result type. \nA standard example is the .lter function on lists of integers: .lter fl returns the elements of l for \nwhich f returns true. It has the ordinary type .lter :(int.bool). list . list. Indexing lists by their \nlength, the re.ned type should look like .lter :.n:N . (int.bool). list(n). list( ) To .ll in the blank, \nwe add dependent sums Sa:.. A, quantifying existentially over index variables, as in [28, 26]. Then we \ncan ex\u00adpress the fact that .lter returns a list of some inde.nite length m as follows1: .lter :.n:N \n. (int.bool). list(n). (Sm:N . list(m)) For similar reasons, we also occasionally would like union types \nand the empty type, which should also be considered inde.nite. We discuss unions .rst. On values, the \nbinary inde.nite type is simply a union in the ordinary sense: if v :A . B then either v :A or v :B. \nThe introduction rules directly express the simple logical interpretation, again using checking for the \nintroduction form. G f e . AG f e . B (.I1 )(.I2 ) G f e . A . BG f e . A . B No restriction to values \nis needed for the introductions, but, du\u00adally to intersections, the elimination must be restricted. A \nsound formulation of the elimination rule in a type assignment form [9] without a syntactic marker2 requires \nan evaluation context E around the subterm of union type. G, x:A f E[x]:C G f e ' :A . B G,y:B f E[y]:C \nG f E[e ' ]:C This is where the third direction is necessary. We no longer move from terms to their \nimmediate subterms, but when typecheck\u00ading e we may have to decompose it into an evaluation context E \nand subterm e ' . Using the analysis and synthesis judgments we have G, x:A f E[x]. C G f e ' . A . B \nG,y:B f E[y]. C (.E) G f E[e ' ]. C Here, if we can synthesize a union type for e ' which is in eval\u00aduation \nposition in E[e ' ] and check E[x]and E[y]against C, as\u00adsuming that x and y have type A and type B respectively, \nwe can conclude that E[e ' ]checks against C. Note that the assumptions x:A and y:B can be read as x.A \nand y.B so we do indeed transi\u00adtion from . A . B to . A and  . B. While typechecking still somehow \nfollows the syntax, there may be many choices of E and e ' , leading to excessive nondeterminism. The \nsubtyping rules are standard and dual to the intersection rules. G f A1 = BG f A2 = B (.L) G f A1 . A2 \n= B G f A = B1 G f A = B2 (.R1 )(.R2 ) G f A = B1 . B2 G f A = B1 . B2 The 0-ary inde.nite type is the \nempty or void type .; it has no values and therefore no introduction rules. For an elimination rule (.E), \nwe proceed by analogy with (.E): G f e ' . . (.E) G f E[e ' ]. C As before, the expression must be an \nevaluation context E with e ' in evaluation position. For T we had one right subtyping rule; for ., following \nthe principle of duality, we have one left rule: 1The additional constraint m = n could be expressed \nby a subset sort [27, 26]. ' 2Pierce [17] used an explicit marker case e of x . e as the union elimination \nform. This is technically straightforward but a heavy burden on the programmer, particularly as markers \nwould also be needed to eliminate S types, which are especially common in code without re.nements; legacy \ncode would have to be extensively marked to make it typecheck. (.L) G f.=A For existential dependent \ntypes, the introduction rule presents no dif.culties, and proceeds using the analysis judgment. G fe \n. [i/a]AG fi : . (SI) G fe . Sa:.. A For the elimination rule, we follow (.E) and (.E): G fe ' . Sa:..A \nG,a:., x:A fE[x]. C (SE) G fE[e ' ]. C Again, there is a potentially subtle issue: the index variable \na must be new and cannot be mentioned in an annotation in E. The subtyping for S is dual to that of .. \nG, a:. fA =BG fA =[i/b]BG fi : . (SL) (SR) G fSa:.. A =BG fA =Sb:.. B  3.5 Properties of Subtyping Our \nsubtyping rules are the same as in [9] except for the addition of products A *B. Since the premises are \nsmaller than the con\u00adclusion in each rule, and we assume decidability for the constraint domain, we immediately \nobtain that G fA =B is decidable. Re\u00ad.exivity and transitivity are admissible, which follows quite eas\u00adily \n[9]. 3.6 The Tridirectional Rule Considering .E to be the 0-ary version of the .E for the binary inde.nite \ntype, what is the unary version? It is: G fe ' . A G,x:A fE[x]. C (direct) G fE[e ' ]. C One might expect \nthis rule to be admissible. However, due to the restriction to evaluation contexts, it is not. As a simple \nexample, consider append : .a:N. list(a). .b:N. list(b). list(a + b) .lterpos : .n:N. list(n). Sm:N. \nlist(m) f .lterpos [... ]. Sm:N. list(m) Goal: f append [42](.lterpos [... ]) . Sk:N. list(k) where [42]is \nshorthand for Cons(42, Nil)and [...]is some literal list. Here we cannot derive the goal, because we \ncannot introduce the k on the type checked against. To do so, we would need to introduce the index variable \nm representing the length of the list returned by .lterpos [... ], and use m + 1 for k. But .lterpos \n[... ] is not in evaluation position, because append [42] will need to be evaluated .rst. However, append \n[42] synthesizes only type .b:N. list(b) . list(1 + b), so we are stuck. However, using rule (direct) \nwe reduce append [42](.lterpos [... ]) . Sk:N. list(k) to x : .b:N. list(b).list(1+b)fx (.lterpos [... \n]) . Sk:N. list(k) Since x is a value, (.lterpos [...]) is in evaluation position. Apply\u00ading the existential \nelimination rule, we need to derive x:.b:N. list(b).list(1+b),m:N,y:list(m)fxy . Sk:N. list(k) Now we \ncan complete the derivation with (SI), using 1 + m for k and several straightforward steps.  4. CONTEXTUAL \nTYPING ANNOTATIONS Our tridirectional system so far has the property that only terms in normal form have \ntypes. For example, (.x. x)() neither synthe\u00adsizes nor checks against a type. This is because the function \npart of an application must synthesize a type, but there is no rule for .x. e to synthesize a type. \nBut annotations are not as straightforward as they might seem. In our setting, two issues arise: checking \nagainst intersections, and index variable scoping. 4.1 Checking Against Intersections Consider the following \nfunction, which conses 42 to its argu\u00adment. cons42 =(.x. (.y. Cons(42, x))()):(odd . even). (even . odd) \nThis does not typecheck: .y. Cons(42, x) needs an annotation. Observe that by rule (.I), cons42 will \nbe checked twice: .rst against odd . even, then against even . odd. Hence, we can\u00adnot write (.y. Cons(42, \nx)) :(1 . even) it is correct only when checking cons42 against odd . even. Moreover, we cannot write \n(.y. Cons(42, x)) :(1 . even). (1 . odd) We need to use 1 . even while checking cons42 against odd . \neven, and 1 . odd while checking cons42 against even . odd. Exasperatingly, union types are no help here: \n(.y. Cons(42, x)) : (1 . even). (1 . odd)is a value of type 1 . even or of type 1 . odd, but we do not \nknow which; following (.E), we must suppose it has type 1 . even and then check its application to 1, \nand then suppose it has type 1 . odd and check its application to 1. Only one of these checks will succeed \na different one, de\u00adpending on which conjunct of (odd . even) . (even . odd) we happen to be checking \ncons42 against but according to (.E) both need to succeed. Pierce [16] and Reynolds [19] addressed this \nproblem by allow\u00ading a function to be annotated with a list of alternative types; the typechecker chooses \nthe right one. Davies followed this approach in his datasort re.nement checker, allowing a term to be \nannotated with (e : A, B, ... ). In that notation, the above function could be written as cons42 =(.x. \n((.y. Cons(42, x)) : 1 . even, 1 . odd)()) :(odd . even). (even . odd) Now the typechecker can choose \n1 . even when checking against 1 . odd. This notation is easy to use and effective but intro\u00adduces additional \nnondeterminism, since the typechecker must guess which type to use. 4.2 Index Variable Scoping Some \nfunctions need type annotations inside their bodies, such as this (contorted) identity function on lists. \nid = .x. (.z. x)() : .a:N. list(a). list(a) In a bidirectional system, the function part of an application \nmust synthesize a type, but we have no rule to synthesize a type for a .\u00adabstraction. So we need an annotation \non (.z. x). We need to show that the whole application checks against list(a), so we might try .z. x \n: 1 . list(a) But this would violate variable scoping. a-convertibility dictates that .a:N. list(a) \n. list(a)and .b:N. list(b) . list(b)must be indistinguishable which would be violated if we permitted \n.x. ((.z. x): 1 . list(a))() . .a:N. list(a). list(a) but not .x. ((.z. x): 1 . list(a))() . .b:N. list(b). \nlist(b) Xi already noticed this problem and introduced a term-level ab\u00adstraction over index variables, \n.a.e, to mirror universal index quan\u00adti.cation .a:.. A [26]. But this violates the basic principle of \nproperty types that the term should remain unchanged, and fails in the presence of intersections. For \nexample, we would expect the reverse function on lists, rev, to satisfy rev :(.a:N. list(a). list(a)) \n. ((Sb:N. list(b)) . Sc:N. list(c)) but the .rst component of the intersection would demand a term\u00adlevel \nindex abstraction, while the second would not tolerate one.  4.3 Contextual Subtyping We address these \ntwo problems by a method that extends and improves the notation of comma-separated alternatives. The \nessen\u00adtial idea is to allow a context to appear in the annotation along with each type: e ::= ... | (e \n: G1 fA1 , ..., Gn fAn ) where each context Gk declares the types of some, but not necessar\u00adily all, \nfree variables in e. In the .rst approximation we can think of such an annotated term as follows: if \nGk f e . Ak then G f (e : G1 f A1 , ..., Gn f An ). Ak if the current assumptions in G validate the assumptions \nin Gk . For example, the second judgment below is not derivable, since x:odd does not validate x:even \n(because odd =even). x:even f((.y. Cons(42, x)) : x:even f1 . odd, x:odd f1 . even). 1 . odd x:odd f((.y. \nCons(42, x)) : x:even f1 . odd, x:odd f1 . even). 1 . odd In practice, this should signi.cantly reduce \nthe nondeterminism associated with type annotations in the presence of intersection. However, we still \nneed to generalize the rule in order to correctly handle index variable scoping. Returning to our earlier \nexample, we would like to .nd an anno\u00adtation As allowing us to derive f.x. ((.z. x): As)() . .a:N. list(a). \nlist(a) The idea is to use a locally declared index variable (here, b) .x. ((.z. x):(b:N,x:list(b)f1 \n. list(b))) to make the typing annotation self-contained. Now, when we check if the current assumptions \nfor x validate local assumption for x,we are permitted to instantiate b to any index object i. In this \nexam\u00adple, we could substitute a for b. As a result, we end up checking (.z. x) . 1 . list(a), even though \nthe annotation does not men\u00adtion a. Note that in an annotation e :(G0 f A0 ),As, all index variables \ndeclared in G0 are considered bound and can be renamed consistently in G0 and A0 . In contrast, the free \nterm variables in G0 may actually occur in e and so cannot be renamed freely. These considerations lead \nto a contextual subtyping relation ; : (G0 fA0 ) ; (G fA) which is contravariant in the contexts G0 and \nG. It would be covari\u00adant in A0 and A, except that in the way it is invoked, G0 , A0 , and G are known \nand A is generated as an instance of A0 . This should become more clear when we consider its use in the \nnew typing rule (G0 fA0 ) ; (G fA) G fe . A (ctx-anno) G f(e :(G0 fA0 ),As). A Typings As ::= G fA | \nG fA, As Terms e ::= ... | (e : As) Values v ::= ... | (v : As) Eval. contexts E ::= ... | (E : As) \nFigure 4: Language additions for contextual typing annotations (;-empty) (\u00b7fA) ; (G fA) G fi : .0 ([i/a]G0 \nf[i/a]A0 ) ; (G fA) (;-ivar) (a:.0 ,G0 fA0 ) ; (G fA) G |= P (G0 fA0) ; (G fA) (;-prop) (P, G0 fA0 ) \n; (G fA) G fG(x)=B0 (G0 fA0 ) ; (G fA) (;-pvar) (x:B0 ,G0 fA0 ) ; (G fA) Figure 5: Contextual subtyping \n where we regard the annotations as unordered (so G0 fA0 could occur anywhere in the list). In the bidirectional \nstyle, G, e, G0 , A0 and As are known when we try this rule. While .nding a derivation of (G0 f A0 ) \n; (G f A)we generate A, which is the synthe\u00adsized type of the original annotated expression e,if infact \ne checks against A. It is also possible that (G0 fA0 ) ; (G fA)fails to have a derivation (when G0 and \nG have incompatible declarations for the term variables occurring in them), in which case we need to \ntry another annotation (Gk fAk ). The formal rules for contextual subtyping are given in Figure 5. Besides \nthe considerations above, we also must make sure that any possible assumptions P about the index variables \nin G0 are indeed entailed by the current context, after any possible substitution has been applied (this \nis why we traverse G0 from left to right). While the examples above are arti.cial, similar situations \narise in ordinary programs in the common situation when local function de.nitions reference free variables. \nTwo small examples of this kind are given in Figure 6 presented in the style of ML; we have omitted the \nevident constructor types and, following the tradition of implementations such as Davies , written typing \nannotations inside bracketed comments. The essence of the completeness result we prove in Section 4.5 \nis that annotations can be added to any term that is well typed in the type assignment system to yield \na well typed term in the tridirectional system. For this result to hold, ; must be re.exive, (G fA) ; \n(G fA). Furthermore, in a judgment G f(e :(G1 fA1 ,...,Gn fAn )) . A we must be able to consistently \nrename index variables in G, all Gk , and e. This different treatment of index variables and term variables \narises from the fact that index variables are associated with property types and so do not appear in \nexpressions, only in types. Re.exivity (together with proper a-conversion) is suf.cient for completeness: \nin the proof of completeness, where we see G fe : A we can simply add an annotation (G f A). But it would \nbe absurd to make programmers type in entire contexts not only is the length impractical, but whenever \na declaration is added every contextual annotation in its scope would have to be changed! Re.exivity \nof ; follows easily from the following lemma. LEMMA 1. (G2 fA) ; (G1,G2 fA). true .bool, false .bool \neven .nat, odd .nat evenlist .list, oddlist .list, emptylist .evenlist eq :(even *odd . false) . (odd \n*even . false) . (nat *nat . bool) (*[ member :(even *oddlist . false) . (odd *evenlist . false) . (nat \n*list . bool)]*) fun member (x, xs)= (*[ mem :x:even f(evenlist . bool). (oddlist . false), x:odd f(evenlist \n. false). (oddlist . bool), x:nat fnatlist . bool ]*) let fun mem xs = case xs of Nil . False | Cons(y, \nys). eq(x, y)orelse mem ys in mem xs end (*[ append :.a:N..b:N. list(a)*list(b). list(a +b)]*) fun append \n(xs, ys)= (*[ app :c:N,ys:list(c)f.a:N. list(a). list(a +c)]*) let fun app xs =case xs of Nil . ys | \nCons(x, xs). Cons(x, app xs) in app xs end Figure 6: Example of contextual annotations PROOF. By induction \non G2 . COROLLARY 2(REFLEXIVITY). (G fA); (G fA).  4.4 Soundness Let |e| denote the erasure of all typing \nannotations from e. THEOREM 3(SOUNDNESS,TRIDIRECTIONAL). If G fe . A or G fe . A then G f|e| :A. PROOF. \nBy straightforward induction on the derivation.  4.5 Completeness We cannot just take a derivation G \nfe :A in the type assignment system and obtain a derivation G f e . A in the tridirectional system. For \nexample, f.x. x :A . A for any type A, but in the tridirectional system .x. x does not synthesize a type. \nHowever, if we add a typing annotation, we can derive f(.x. x :(fA . A)). A . A Clearly, the completeness \nresult must be along the lines of If G f e :A, then there is an annotated version e ' of e such that \nG f e ' . A. To formulate this result (Corollary 12, a special case of Theorem 11) we need a few de.nitions \nand lemmas. DEFINITION 4. A term is in synthesizing form if it has any of the forms x, e1 e2 ,u, (e :As), \nfst(e), snd(e). ' '' DEFINITION 5. e extends a term e, written e .e iff e is e with zero or more additional \ntyping annotations and e ' contains no type annotations on the roots of terms in synthesizing form. \nDEFINITION 6. e ' lightly extends a term e, written e ' .. e iff e ' is e with zero or more typing annotations \nadded to lists of typing annotations already present in e. That is, we can replace (e :As) with (e :As, \nA ' ), but cannot replace e with (e :A ' ). PROPOSITION 7. .and .. are re.exive and transitive. PROOF. \nObvious from the de.nitions. LEMMA 8. If e value and e ' .e then e ' value. PROOF. By a straightforward \ninduction on e ' (in the base case, making use of (v :As)value). ' LEMMA 9(LIGHT EXTENSION). If e .. \ne then (1) G fe . A implies G fe ' . A, (2) G fe . A implies G fe ' . A. PROOF. By induction on the derivation \nof the typing judgment. All cases are straightforward: either e and e ' must be identical (for instance, \nfor (1I)), or we apply the IH to all premises, which leads directly to the result. Recall that the rule \n(.I) led to the need for more than one typ\u00ading annotation on a term. It should be no surprise, then, \nthat the (.I) case in the completeness proof is interesting. Applying the induction hypothesis to each \npremise v :A, v :B yields two pos\u00ad '' ' sibly different annotated terms v and v such that v . A and \nAB A vB ' . B. But given a notion of monotonicity under annotation, we can incorporate both annotations \ninto a single v ' such that v ' . A and v ' . B. However, the obvious formulation of monotonicity If \ne . A and e ' .e then e ' . A does not hold: given a list of annotations As the type system must use \nat least one of them it cannot ignore them all. Thus f(() : (fT)). 1 is not derivable, even though f() \n. 1 is derivable and (() :(fT)).(). However, further annotating (() :(fT))to (() :(fT), (f1))yields a \nterm that checks against both Tand 1. Note that this further annotation was light we added a typing to \nan existing annotation. This observation leads to Lemma 10. LEMMA 10 (MONOTONICITY UNDER ANNOTATION). \n' ''' (1) If G fe . A and e .e then there exists e .. e such that G fe '' . A. ' ''' (2) If G fe . \nA and e .e then there exists e .. e such that G fe '' . A. PROOF. By induction on the typing derivation. \nTHEOREM 11 (COMPLETENESS,TRIDIRECTIONAL). If G f e :A and e ' .e then '' ''' '' (i) there exists e \nsuch that e .e and G fe . A 11 1 '' ''' '' (ii) there exists e such that e .e and G fe . A 22 2 PROOF. \nBy induction on the derivation of G fe :A. COROLLARY 12. If G fe :A then there exists e ' .e such ' '' \n'' that G fe . A and there exists e .e such that G fe . A.  5. THE LEFT TRIDIRECTIONAL SYSTEM In the \nsimple tridirectional system, the contextual rules are highly nondeterministic. Not only must we choose \nwhich contextual rule to apply, but each rule can be applied repeatedly with the same context E; for \n(direct), which does not even break down the type of e ' , this repeated application is quite pointless. \nThe system in this Rules of the simple tridirectional system absent in the left tridirectional system: \nSubtyping G fA =B Simple tridirectional checking G fe . A Contextual subtyping (G0 fA0 ); (G fA) Simple \ntridirectional synthesis G fe . A Constraint satisfaction G |= P Left tridirectional checking G;. fe \n.L A Index expression sorting G fi :. Left tridirectional synthesis G;. fe .L A Data constructor typing \nG fc :A . d(i) . appear linearly in e . I e and in evaluation position in e . I e Figure 7: Judgment \nforms appearing in the paper G fe ' . A G,x:A fE[x]. C (direct) G fE[e ' ]. C G fe ' . . (.E) G fE[e \n' ]. C G, x:A fE[x]. C G fe ' . A . B G,y:B fE[y]. C (.E) G fE[e ' ]. C G fe ' . Sa:..A G,a:., x:A fE[x]. \nC (SE) G fE[e ' ]. C Rules new or substantially altered in the left tri\u00addirectional system: (var) G;x:A \nfx .L A e ' not a linear var G;.1 fe ' .L AG;.2, x:A fE[x].L C (directL) G;.1,.2 fE[e ' ].L C ., x:.I \ne (.L) G;., x:.fe .L C G;., x:A fe .L CG;., x:B fe .L C (.L) G;., x:A . B fe .L C G, a:.;., x:A fe \n.L C (SL) G;., x:Sa:.. A fe .L C G;., x:A fe .L CG;., x:B fe .L C (.L1)(.L2 ) G;., x:A . B fe .L CG;., \nx:A . B fe .L C G fi :.G;., x:[i/a]A fe .L C (.L) G;., x:.a:.. A fe .L C Rules of the left tridirectional \nsystem identical to the simple tridirectional system, except for the linear contexts .: G(x)=A G,x:A;\u00b7fe \n. BG;.1 fe1 . A . BG;.2 fe2 . A (var)(.I)(.E) G;\u00b7fx . AG;\u00b7f.x. e . A . BG;.1 ,.2 fe1 e2 . B G;. fe . \nAG fA =BG(u)=A G,u:A;\u00b7fe . A (sub)(.xvar)(.x) G;. fe . BG;\u00b7fu . AG;\u00b7f.x u. e . A G;.1 fe1 . A1 G;.2 fe2 \n. A2 G;. fe . A *BG;. fe . A *B (1I)(*I)(*E1)(*E2) G;\u00b7f() . 1 G;.1,.2 f(e1,e2 ). A1 *A2 G;. ffst(e). \nAG;. fsnd(e). B G fc :A . d2(i) G fd2(i)=d1(j) G;. fe . AG |= . . I e (dI)(contra) G;. fc(e). d1(j) G;. \nfe . A G;. fe . d(i) G;\u00b7fms .d(i) B (dE) G;. fcase e of ms . B . I v G;. fv . AG;. fv . BG;. fe . A \n. BG;. fe . A . B (TI)(.I)(.E1 )(.E2 ) G;. fv . T G;. fv . A . BG;. fe . AG;. fe . B G, a:.;. fv . AG;. \nfe . .a:..A G fi :.G;. fe . [i/a]AG fi :. (.I)(.E)(SI) G;. fv . .a:..A G;. fe . [i/a]AG;. fe . Sa:.. \nA G;. fe . AG;. fe . B (G0 fA0 ); (G fA) G fe . A (.I1 )(.I2 )(ctx-anno) G;. fe . A . BG;. fe . A . \nBG f(e :(G0 fA0 ),As). A Figure 8: The left tridirectional system, with the part of the simple tridirectional \nsystem (upper left corner) from which it substan\u00adtially differs. The .gure also summarizes the simple \ntridirectional system: The complete typing rules for the simple tridirectional system can be obtained \nby removing the second context ., including premises of the form . I e, from the lower rules, along with \nthe rules in the upper left corner. Hence the subscripts .L , .L are elided. Thm. 11 Thm. 20 . . G \nf e . AG;. f e .L A G f e . AG;. f e .L A Simple Left tridirectional tridirectional system system . \n. Thm. 3 Thm. 18  Figure 9: Connections between our type systems section has only one contextual rule \nand disallows repeated appli\u00adcation. Inspired by the sequent calculus formulation of Barbanera et al. \n[2], it replaces the contextual rules with one contextual rule (directL), closely corresponding to (direct), \nand several left rules, shown in the upper right hand corner of Figure 8. In combination, these rules \nsubsume the contextual rules of the simple tridirectional system. The typing judgments in the left tridirectional \nsystem are G;. f e .L AG;. f e .L A where . is a linear context whose domain is a new syntactic cate\u00adgory, \nthe linear variables x, y and so forth. These linear variables correspond to the variables introduced \nin evaluation position in the (direct) rule, and appear exactly once in the term e, in evaluation position. \nWe consider these linear variables to be values, like ordi\u00adnary variables. The rule (directL) is the \nonly rule that adds to the linear context, and is the true source of linearity: x appears exactly once \nin evalu\u00adation position in E[x]. It requires that the subterm e ' being brought out cannot itself be \na linear variable, so one cannot bring out a term more than once, unlike with (direct). To maintain linearity, \nthe linear context is split among subterms. For example, in (*I) (Figure 8), the context . = .1,.2 is \nsplit between e1 and e2 . To maintain the property that linear variables appear in evaluation position, \nin rules such as (.I) that type terms that cannot contain a variable, the linear context is empty. After \nsome preliminary de.nitions and lemmas, we prove that this new left tridirectional system is sound and \ncomplete with re\u00adspect to the simple tridirectional system from Section 3. (See also Figure 9). DEFINITION \n13. Let FLV(e)denote the set of linear variables appearing free in e. Furthermore, let . I e if and only \nif (1) for every x . dom(.), x appears exactly once in e, and (2) FLV(e). dom(.). (Similarly de.ne FLV(ms)and \n. I ms.) PROPOSITION 14 (LINEARITY). If G;. f e .L C or G;. f e .L C then . I e. Similarly, if G;. f \nms .d(i) C then . I ms. PROOF. By induction on the derivation. For (contra), (TI), (.L), use the appropriate \npremise. DEFINITION 15. Let . I e if and only if (1) for every x . dom(.), there exists an E such that \ne =E[x]and x / . FLV(E), and (2) FLV(e). dom(.). (It is clear that . I e implies . I e.) LEMMA 16. If \nD derives G;. f e .L C or G;. f e .L C by ''' ' a rule R and . I e, then for each premise G ;. f e .L \nC or '''' '' G ;. f e .L C of R, it is the case that . I e . PROOF. Straightforward. 5.1 Soundness DEFINITION \n17. A renaming . is a variable-for-variable sub\u00adstitution from one set of variables (dom(.)) to another, \ndisjoint set. When a renaming is applied to a term, [.]e, it behaves as a substi\u00adtution, and can substitute \nthe same variable for multiple variables. Unlike a substitution, however, it can also be applied to contexts. \nA renaming from linear variables to ordinary program variables, . = x/x,... , may be applied to a linear \ncontext .: [.]. yields an ordinary context G by renaming all variables in dom(.). In the other direction, \na renaming . from ordinary program variables to linear variables may be applied to an ordinary context \nG: [.]G yields a zoned context G ' ;., where dom(G ' )=dom(G)-dom(.)and dom(.)is the image of . on G \nrestricted to dom(.). THEOREM 18 (SOUNDNESS,LEFT RULE SYSTEM). If . re\u00adnames linear variables to ordinary \nprogram variables and G;. f e .L C (resp. G;. f e .L C) and . I e and dom(.). dom(.), then G, [.]. f \n[.]e . C (resp. G, [.]. f [.]e . C). The condition . I e is trivially satis.ed if . =\u00b7 and e contains \nno linear variables, which is precisely the situation for the whole program. PROOF. By induction on the \ntyping derivation. We use Lemma 16 to satisfy the linearity condition whenever we apply the IH. Most \ncases are completely straightforward, except for the rules not present in the simple tridirectional system. \nFor (var), it is given that dom(.). dom(.), so we can apply (var). For(directL), use the IH on the .rst \npremise, let x be new, and use the IH on the second premise with the renaming ., x/x; ap\u00adply properties \nof substitution and weakening to yield derivations to which (direct) can be applied. For the left rules, \nuse a different re\u00adnaming ., x ' /x where x ' is new for each premise, then apply the IH to yield derivation(s) \ntyping [., x ' /x]E[x](by . I e, e = E[x]). Use (var) to obtain a typing of [.]x. Finally, apply the \ncorrespond\u00ading tridirectional rule, such as (.E) for the (.L) case. 5.2 Completeness We now show completeness: \nIf a term can be typed in the sim\u00adple tridirectional system, it can be typed in the left tridirectional \nsystem. First, a small lemma: LEMMA 19. If G;x:A f x .L B and G;., x:B f e .L C then G;., x:A f e .L \nC. PROOF. By induction on the .rst derivation. THEOREM 20 (COMPLETENESS,LEFT RULE SYSTEM). If . renames \nordinary program variables to linear variables and G f e . C (resp. G f e . C) and . I [.]e where [.]G \n= G ' ;., then [.]G f [.]e .L C (resp. [.]G f [.]e .L C). PROOF. By induction on the typing derivation. \nMost of the cases can be handled as follows: Restrict . to variables appearing in subterms of e (if any). \nApply the IH to all premises. Reason that if . ' is a restriction of . to a subterm e ' , then the result \nof applying ''' ' the IH namely [. ]G f [. ]e .L A implies [.]G f [.]e .L A. Finally, reapply the original \nrule. However, this fails for the rules that are absent or modi.ed in the left tridirectional system: \n(direct), (.E), (.E), (SE). In each of the cases for these rules, there are two subcases: If the subterm \ne ' is not a variable renamed by ., then we ap\u00adply the IH to the premise typing e ' , make a new linear \nvari\u00adable x, apply the IH to the contextual premises as needed, ap\u00adply the corresponding left rule (or \ndo nothing in the (direct) case) to show E[x].L C, then apply (directL). If e ' is a variable in dom(.), \nwe apply the IH to all premises, apply the corresponding left rule (or do nothing in the (direct) case), \nthen use Lemma 19.  5.3 Decidability of Typing THEOREM 21. G;. fe .L A is decidable. PROOF. Weimposeanorder \n< on two judgments J1 = G1 ;.1 f e1 .. A1 and J2 = G2;.2 fe2 .. A2 . When ordering terms, we consider \nlinear variables to be smaller than any other terms; for ex\u00adample, (x,e2 )is smaller than (y, e2 )). \nWhen ordering types (that is, type expressions), we consider all index expressions to be of equal size. \nThe order is de.ned as follows. 1. If e1 is smaller than e2 then J1 < J2 .If e1 is the same size as e2 \n: 2. If the directions of the judgments differ, the synthesis judg\u00adment is smaller than the checking \njudgment. If the directions are the same: 3. If both judgments are checking judgments and A1 is smaller \nthan A2 then J1 < J2. If both judgments are synthesis judgments, G1 = G2 , .1 = .2 , A1 is as small as, \nor smaller than, some type in (G1 ;.1), and A1 is larger than A2 , then J1 < J2. Otherwise: 4. If the \nnumber of times any of the type constructors ., S, ., ., ., Tappear in .1 is less than the number of \ntimes they appear in .2 then J1 < J2 .  Now we show that for every rule, each premise is smaller than \nthe conclusion. For most premises, the .rst criterion alone makes the premise smaller. The second criterion \nis for (sub). The third crite\u00adrion is needed for rules such as (.I) and (.E). Note that a synthe\u00adsis \njudgment whose type expression becomes larger is considered smaller! Synthesis judgments eventually bottom \nout at rules like (ctx-anno) and (*E1), in which the term becomes smaller, or at rules (var), (.xvar)or \n(var), where the type synthesized is taken from G or .. Since all the type expressions in G and . are \n.nite, there is no problem. The fourth criterion is for the left rules, where the term, direction, and \ntype do not change. The second premise of (directL) is smaller than its conclusion because we consider \nlinear variables to be the smallest terms and (directL) does not permit e ' to be a linear variable. \n 5.4 Type Safety If \u00b7;\u00b7fe .L A in the left tridirectional system, from Theorem 18 we know \u00b7fe . A. Then \nby Theorem 3, \u00b7f|e| : A in our type assignment system [9]. That is, type erasure suf.ces to get a typing \nderivation in the type assignment system. It follows from [9] s Theorem 3, Type Preservation and Progress, \nthat |e| either diverges or evaluates to a value of type A.  6. RELATED WORK Re.nements, intersections, \nunions. The notion of datasort re.ne\u00adment combined with intersection types was introduced by Freeman \nand Pfenning [11]. They showed that full type inference was de\u00adcidable under the so-called re.nement \nrestriction by using tech\u00adniques from abstract interpretation. Interaction with effects in a call-by-value \nlanguage was .rst addressed conclusively by Davies and Pfenning [7] who introduced the value restriction \non intersec\u00adtion introduction, pointed out the unsoundness of distributivity, and proposed a practical \nbidirectional checking algorithm. Index re.nements were proposed by Xi and Pfenning [28]. As mentioned \nearlier, the necessary existential quanti.er S led to dif\u00ad.culties [26] because elaboration must determine \nthe scope of S, which is not syntactically apparent in the source program. Xi ad\u00addressed this by translating \nprograms into a let-normal form before checking index re.nements, which is akin to typechecking the orig\u00adinal \nterm in evaluation order. Because of the speci.c form of Xi s translation, our tridirectional system \nadmits more programs, even when restricted to just index re.nements and quanti.ers. Nonethe\u00adless, we \nconjecture that Xi s idea of traversing the entire program strictly in evaluation order is applicable \nin our signi.cantly more complex setting to eliminate the nondeterminism inherent in the (directL) rule; \nwe plan to pursue this in further research. Intersection types [4] were .rst incorporated into a practical \nlan\u00adguage by Reynolds [19]. Pierce [17] gave examples of program\u00adming with intersection and union types \nin a pure .-calculus using a typechecking mechanism that relied on syntactic markers. The .rst systematic \nstudy of unions in a type assignment framework [2] identi.ed several issues, including the failure of \ntype preservation even for the pure .-calculus when the union elimination rule is too unrestricted. It \nalso provided a framework for our more specialized study of a call-by-value language with possible effects. \nSome work on program analysis in compilation uses intersection and union types to infer control .ow properties \n[24, 15]. Because of the goals of these systems for program analysis and control .ow information, the \nspeci.c forms of intersection and union types are quite different from ours. Soft typing systems designed \nfor type in\u00adference under dynamic typing [3] are somewhat similar, allowing intersection, union, and \neven conditional types [1]. Again, due to the different setting and goal, the technical realization differs \nsub\u00adstantially from our work. Partial inference systems. Our system shares several properties with Pierce \nand Turner s local type inference [18]. Their language has subtyping and impredicative polymorphism, \nmaking full type inference undecidable. Their partial inference strategy is formu\u00adlated as a bidirectional \nsystem with synthesis and checking judg\u00adments, in a style not too far removed from ours. However, in \norder to handle parametric polymorphism without using nonlocal methods such as uni.cation, they infer \ntype arguments to polymor\u00adphic functions, which seems to substantially complicate matters. Hosoya and \nPierce [12] further discuss this style, particularly its effectiveness in achieving a reasonable number \nof annotations. Our system does not yet have parametric polymorphism. Prior research, either with (in \n[26]) or without (in [7]) a syntactic distinc\u00adtion between ordinary and property types, is not conclusive. \nHow\u00adever, the work on local type inference suggests that, at least, pre.x polymorphism in the style of \nML should be amenable to a consis\u00adtent treatment with bidirectional rules. Principal typings. A principal \ntype of e is a type that represents all types of e in some particular context G.A principal typing [13] \nof e is a pair (G, A)of a context and a type, such that (G, A)rep\u00ad '' '' resents all pairs (G ,A ) such \nthat G fe : A . These de.ni\u00ad tions depend on some idea of representation, which varies from type system \nto type system, making comparisons between systems dif.cult. Wells [25] improved the situation by introducing \na gen\u00aderal notion of representation. Since full type inference seems in any case unattainable, we have \nnot investigated whether principal typ\u00adings might exist for our language. However, the idea of assigning \na typing (rather than just a type) to a term appears in our system in the form of contextual typing annotations, \nenabling us to solve some otherwise very unpleasant problems regarding the scope of quanti.ed index variables. \n 7. CONCLUSION In [9], we developed a type assignment system with a rich set of property type constructors. \nThat system is sound in a standard call\u00adby-value semantics, but is inherently undecidable. In this paper, \nby taking a tridirectional version of the type assignment system, we have obtained a rich yet decidable \ntype system. Every program well-typed under the type assignment system has an annotation with contextual \ntypings that checks under the tridirectional rules. Contextual typing annotations should be useful in \nother settings, such as systems of parametric polymorphism in which subtyping is decidable. In order \nto show decidability, and as a .rst important step to\u00adwards a practical implementation, we also presented \na less nonde\u00adterministic left tridirectional system and proved it to be decidable and sound and complete \nwith respect to the tridirectional system. We are in the process of formulating a let-normal version \nof the left tridirectional system. Such a system would drastically reduce the nondeterminism in (directL) \nby forcing the typechecker to tra\u00adverse subterms in evaluation order, while being sound and complete \nwith respect to the left tridirectional system. Once this is done, we plan to develop a prototype implementa\u00adtion \nof the let-normal system that should help us answer questions regarding the practicality of our design \non realistic programs. The main questions will be (1) if the required annotations are reasonable in size, \n(2) if type checking is ef.cient enough for interesting pro\u00adgram properties, and (3) if the typing discipline \nis accurate enough to track properties in complex programs. The preliminary experi\u00adence with re.nement \ntypes, including both datasort re.nements [5] and index re.nements [28], gives reason for optimism, but \nmore research and experimentation is needed. Acknowledgments. This work supported in part by the National \nScience Foundation under grant CCR-0204248; the .rst author was also supported in part by an NSF Graduate \nResearch Fellowship. We thank Jonathan Moody, Sungwoo Park, and the anonymous re\u00adviewers for their useful \ncomments. We also thank Rowan Davies for many fruitful discussions regarding the subject of this paper. \n 8. REFERENCES [1] Alexander Aiken, Edward L. Wimmers, and T. K. Lakshman. Soft typing with conditional \ntypes. In ACM Symp. Principles of Programming Languages, pages 163 173, 1994. [2] Franco Barbanera, Mariangiola \nDezani-Ciancaglini, and Ugo de Liguoro. Intersection and union types: syntax and semantics. Inf. and \nComp., 119:202 230, 1995. [3] R. Cartwright and M. Fagan. Soft typing. In SIGPLAN Conf. Programming Language \nDesign and Impl. (PLDI), volume 26, pages 278 292, 1991. [4] M. Coppo, M. Dezani-Ciancaglini, and B. \nVenneri. Functional characters of solvable terms. Zeitschrift f. math. Logik und Grundlagen d. Math., \n27:45 58, 1981. [5] Rowan Davies. A practical re.nement-type checker for Standard ML. In Algebraic Methodology \nand Software Tech. (AMAST 97), pages 565 566. Springer LNCS 1349, 1997. [6] Rowan Davies. Practical re.nement-type \nchecking. PhD thesis proposal, Carnegie Mellon University, 1997. [7] Rowan Davies and Frank Pfenning. \nIntersection types and computational effects. In Int l Conf. Functional Programming (ICFP 00), pages \n198 208, 2000. [8] Joshua Dun.eld. Combining two forms of type re.nements. Technical Report CMU-CS-02-182, \nCarnegie Mellon University, September 2002. [9] Joshua Dun.eld and Frank Pfenning. Type assignment for \nintersections and unions in call-by-value languages. In Found. Software Science and Computational Structures \n(FOSSACS 03), pages 250 266, Warsaw, Poland, April 2003. Springer LNCS 2620. [10] Tim Freeman. Re.nement \ntypes for ML. PhD thesis, Carnegie Mellon University, 1994. CMU-CS-94-110. [11] Tim Freeman and Frank \nPfenning. Re.nement types for ML. In SIGPLAN Conf. Programming Language Design and Impl. (PLDI), volume \n26, pages 268 277. ACM Press, 1991. [12] Haruo Hosoya and Benjamin C. Pierce. How good is local type \ninference? Technical Report MS-CIS-99-17, University of Pennsylvania, June 1999. [13] Trevor Jim. What \nare principal typings and what are they good for? Technical memorandum MIT/LCS/TM-532, MIT, November \n1995. [14] Yitzhak Mandelbaum, David Walker, and Robert Harper. An effective theory of type re.nements. \nTechnical Report TR-656-02, Princeton, December 2002. [15] Jens Palsberg and Christina Pavlopoulou. From \npolyvariant .ow information to intersection and union types. J. Func. Prog., 11(3):263 317, 2001. [16] \nBenjamin C. Pierce. Programming with intersection types and bounded polymorphism. PhD thesis, Carnegie \nMellon University, 1991. Technical Report CMU-CS-91-205. [17] Benjamin C. Pierce. Programming with intersection \ntypes, union types, and polymorphism. Technical Report CMU-CS-91-106, Carnegie Mellon University, 1991. \n[18] Benjamin C. Pierce and David N. Turner. Local type inference. In ACM Symp. Principles of Programming \nLanguages, pages 252 265, 1998. Full version in ACM Trans. Prog. Lang. Sys., 22(1):1 44, 2000. [19] John \nC. Reynolds. Design of the programming language Forsythe. Technical Report CMU-CS-96-146, Carnegie Mellon \nUniversity, 1996. [20] Fred Smith, David Walker, and Greg Morrisett. Alias types. In European Symp. on \nProgramming (ESOP 00), pages 366 381, Berlin, Germany, March 2000. [21] Jean-Pierre Talpin and Pierre \nJouvelot. The type and effect discipline. Inf. and Comp., 111(2):245 296, 1994. [22] Mads Tofte and Jean-Pierre \nTalpin. Region-based memory management. Inf. and Comp., 132(2):109 176, 1997. [23] J. B. Wells and Christian \nHaack. Branching types. In European Symp. on Programming (ESOP 02), pages 115 132, 2002. [24] J.B. Wells, \nAllyn Dimock, Robert Muller, and Franklyn Turbak. A calculus with polymorphic and polyvariant .ow types. \nJ. Func. Prog., 12(3):183 317, May 2002. [25] Joe Wells. The essence of principal typings. In Int l Coll. \nAutomata, Languages, and Programming, volume 2380 of LNCS, pages 913 925. Springer, 2002. [26] Hongwei \nXi. Dependent types in practical programming. PhD thesis, Carnegie Mellon University, 1998. [27] Hongwei \nXi. Dependently typed data structures. Revision superseding WAAAPL 99, February 2000. [28] Hongwei Xi \nand Frank Pfenning. Dependent types in practical programming. In ACM Symp. Principles of Programming \nLanguages, pages 214 227, 1999.  \n\t\t\t", "proc_id": "964001", "abstract": "In prior work we introduced a pure type assignment system that encompasses a rich set of property types, including intersections, unions, and universally and existentially quantified dependent types. This system was shown sound with respect to a call-by-value operational semantics with effects, yet is inherently undecidable.In this paper we provide a decidable formulation for this system based on bidirectional checking, combining type synthesis and analysis following logical principles. The presence of unions and existential quantification requires the additional ability to visit subterms in evaluation position before the context in which they occur, leading to a <i>tridirectional</i> type system. While soundness with respect to the type assignment system is immediate, completeness requires the novel concept of <i>contextual type annotations</i>, introducing a notion from the study of principal typings into the source program.", "authors": [{"name": "Joshua Dunfield", "author_profile_id": "81100605091", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P653509", "email_address": "", "orcid_id": ""}, {"name": "Frank Pfenning", "author_profile_id": "81100157780", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP39030152", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/964001.964025", "year": "2004", "article_id": "964025", "conference": "POPL", "title": "Tridirectional typechecking", "url": "http://dl.acm.org/citation.cfm?id=964025"}