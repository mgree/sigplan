{"article_publication_date": "01-01-2004", "fulltext": "\n Simple Relational Correctness Proofs for Static Analyses and Program Transformations Nick Benton Microsoft \nResearch 7 J J Thomson Avenue Cambridge CB3 0FB, UK nick@microsoft.com Abstract We show how some classical \nstatic analyses for imperative pro\u00adgrams, and the optimizing transformations which they enable, may be \nexpressed and proved correct using elementary logical and de\u00adnotational techniques. The key ingredients \nare an interpretation of program properties as relations, rather than predicates, and a real\u00adization \nthat although many program analyses are traditionally for\u00admulated in very intensional terms, the associated \ntransformations are actually enabled by more liberal extensional properties. We illustrate our approach \nwith formal systems for analysing and transforming while-programs. The .rst is a simple type system which \ntracks constancy and dependency information and can be used to perform dead-code elimination, constant \npropagation and program slicing as well as capturing a form of secure information .ow. The second is \na relational version of Hoare logic, which sig\u00adni.cantly generalizes our .rst type system and can also \njustify opti\u00admizations including hoisting loop invariants. Finally we show how a simple available expression \nanalysis and redundancy elimination transformation may be justi.ed by translation into relational Hoare \nlogic. Categories and Subject Descriptors: F.3.2 [Logics and Mean\u00adings of Programs]: Semantics of Programming \nLanguages De\u00adnotational semantics, Partial evaluation, Program analysis; F.3.1 [Logics and Meanings \nof Programs]: Specifying and Verifying and Reasoning about Programs Logics of programs, Invariants; \nD.3.4 [Programming Languages]: Processors Compilers, Optimization; General Terms: Languages, Theory, \nVeri.cation Keywords: Program analysis, optimizing compilation, types, de\u00adnotational semantics, partial \nequivalence relations, Hoare logic, de\u00adpendency, information .ow, security Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 04, January 14 16, 2004, Venice, Italy. \nCopyright 2004 ACM 1-58113-729-X/04/0001 ...$5.00 1 Introduction Although static program analyses are \nroutinely proved correct, the soundness of the optimizing transformations which they enable is much less \nfrequently addressed. Much of the work which has been done on formalizing and validating analysis-based \ntransformations comes from the functional programming community (see Section 5 for related work) the \nliterature on optimizations for imperative languages contains few formal speci.cations of transformations, \nlet alone proofs of their correctness. One might think that this is be\u00adcause the correctness of most \nimperative optimizations is entirely trivial, but what literature there is on the subject [22, 18, 19, \n20] (not to mention the occasional behaviour of real optimizing com\u00adpilers) indicates that this is not \nso. Why is proving correctness of analysis-based transformations hard? We wish to establish that, given \nthe results of a static analysis, the original program and the transformed program are observationally \nequivalent. The .rst problem is that many transformations involve locally replacing some part P of a \nlarger program C[P] with a new version Pi which is not generally observationally equivalent to P (i.e. \nP ~ Pi), though they are equivalent in that particular context: C[P] ~C[Pi]. Simply having an analysis \nwhich (albeit correctly) de\u00adduces that certain predicates .(P) hold of program fragments does not straightforwardly \nallow one to justify such transformations un\u00adless the predicates .(\u00b7) also somehow involve sets of contexts \nC[\u00b7], which is often not the case. The second dif.culty in proving correctness of optimizing trans\u00adformations \nis that program analyses, especially for imperative lan\u00adguages, are often speci.ed in a very intensional \nway. For example, an assignment [x := a]l may reach a certain program point if there is an execution \nof the program where x was last assigned a value at l when the program point is reached . Notions such \nas program point and where a variable was last assigned are not present in natural operational or denotational \nsemantics, so the correctness of these analyses is frequently formulated in terms of a new (and es\u00adsentially \nbogus) instrumented semantics which tracks the extra in\u00adformation. Even where the instrumented semantics \nis related back to the original one, the relation is usually a rather weak form of ade\u00adquacy which certainly \ndoes not help with establishing equivalences: the instrumented semantics will generally have a weaker \nequational theory than the original one. This paper demonstrates that, at least in some simple cases, \nboth of these dif.culties can be overcome by use of elementary ideas which are commonplace in the semantics \ncommunity, but which have not previously been fully exploited in the context of compiler analyses and \ntransformations. The .rst dif.culty is approached by taking seriously the notion of the semantics of \ntypes as (special kinds of) relations, rather than predicates. Typed lambda calculi are routinely presented \nusing judgements of the form G fM = Mi : A which does not assert under assumptions G, M equals Mi and \nthey both have type A , but rather under assumptions G, M and Mi are equal at type A . Such calculi can \nbe modelled by interpreting types as partial equivalence relations over some untyped universe such as \nD8. Many program analyses are presented as non-standard type systems, and partial equivalence relations \nhave been used to give semantics to these non-standard types (equivalently, elements of abstract domains), \nat least in the cases of binding-time [15] and security analyses [26]. However, even in those cases, \nthe emphasis has been on simple typing judgements rather than equational rea\u00adsoning. Our approach is \nto treat all abstract properties as relations, including those which have naive interpretations as predicates \n(e.g. X is 5 ), and to present transformations by giving rules for deriving (non-standard) typed equations \nin context. The second dif.culty, the apparently intensional nature of proper\u00adties, is often something \nof a red herring, attributable to a confusion between certain analysis algorithms and the semantics of \nthe in\u00adformation they produce. Of course, analyses relating to properties such as time or space usage \ncan only be justi.ed relative to seman\u00adtic models which make those aspects of computation explicit. But \nmany transformations performed by optimizing compilers can be justi.ed using more extensional semantics, \nnot only in the weak sense that every input program is provably equivalent to its trans\u00adformed version, \nbut also in the stronger sense that there is a generic correctness argument for all programs. The true \npreconditions for applying a transformation tend to be extensional ( this command does not change the \nvalue of X+Y ) even if an analysis algorithm only discovers those properties if a stronger intensional \nproperty holds ( this command does not contain any assignments to X or Y ). As a facetious example of \nthe difference between the intensional and extensional approaches, consider why the following transfor\u00admation \nis correct: X:=7; X:=7; Y := Y+1; ==> Y := Y+1; Z:=X; Z:=7; The extensional answer is when X is evaluated \non the last line, its value will always be 7 . The intensional answer is something like the only de.nition \nof X which reaches its use on line 3 is the one on line 1, and the right hand side of that de.nition \ndoes not contain any variable which is assigned to in lines 1 or 2 . This may well be an accurate account \nof how an algorithm works, but it is not a good basis for thinking about what it establishes. Things \nget even worse if we consider a sequence like X:=7; X:=7; X:=7;  Y := Y+1; ==> Y := Y+1; ==> Y := Y+1; \n X:=7; X:=7; Z:=X; Z:=7; Z:=7; After the .rst transformation, the intensional justi.cation for the \nchange to line 4 refers to the de.nition of X on line 3. But after the second transformation, that de.nition \nhas gone, which complicates proving the correctness of the combined transformation. Problems of this \nsort occur both in real compilers (keeping analysis results sound during transformations is notoriously \ntricky) and in proofs (see for example the discussion of interference between forward analyses and backward \ntransformation patterns in [20]). Another familiar example of the intensional/extensional distinction \narises in optimizing compilation of lazy functional languages [9]. Some analysis algorithms aimed at \ndetecting when CBN can be replaced by CBV look for functions which always evaluate their arguments ( \nneededness ), which is an intensional property. Their correctness (and that of the associated transformation) \ncan be es\u00adtablished in terms of the extensional property of strictness, which is much easier to reason \nabout. Of course, since the extensional prop\u00aderty is also weaker (holds of more functions) one is then \nnaturally led to reformulate the analysis to establish the extensional property more directly.  2 The \nLanguage of while-Programs The syntax and denotational semantics of the language of while\u00adprograms are \nentirely standard (see, e.g. [34]). To .x notation, they are brie.y summarized in Figure 1. We sometimes \nuse Ft as a metavariable ranging over t exp where t .{int,bool}. The denotational semantics is given \nin the category of .-complete partial orders (predomains) and continuous functions. We write i\u00b7l : D \n. D. for the injection of a domain into its lift and (\u00b7)* : (D .Di ) .(D..Di ) for the associated extension \noperation. ..When R .D \u00d7D, R..D.\u00d7D. is the relation de.ned by R. = {(ixl,iyl) |(x,y) .R}.{(.,.)} If f \n: D .E, x .D and y .E then we de.ne f [x .y] : D .E in the usual way: y if z = x ( f [x .y])(z)= f (z) \notherwise The denotational semantics is fully abstract with respect to the ob\u00advious operational semantics \nand de.nition of observational equiva\u00adlence.  3 Dependency, Dead Code and Constants In this section \nwe present DDCC, a simple analysis and transfor\u00admation system for while-programs which tracks dependency \nand constancy information, enabling optimizations such as constant\u00adfolding and dead-code elimination. \nAs indicated in the introduc\u00adtion, the system is presented as a non-standard type system for deriving \ntyped equalities between expressions and between com\u00admands. 3.1 DDCC Syntax and Semantics 3.1.1 Formulae \nWe begin by de.ning the syntax of some non-standard types for expressions. For t .{int,bool}, c .[[t]]: \nft := Ft |{c}t |.t |Tt Intuitively, {c}t is the type of t-expressions equal to the constant c, .t is \nthe type of t-expressions whose value we do not know, whilst Tt is the type of t-expressions whose value \nwe do not care about. Ft is an empty expression type, which we have included Syntax X .V = {X,Y,...} \nn .Z b .B = {true, false} iop .{+,\u00d7,-,...}. Z \u00d7Z .Z bop .{<,=,...}. Z \u00d7Z .B lop . {.,.,...}. B \u00d7B .B \nintexp.E := n |X |E iop E bool exp .B := b |E bop E |not B |B lop B com .C := skip |X:=E |C;C |if B thenC \nelseC |while B doC Denotational Semantics S .S = V .Z [[B]] .S .B [[E]] .S .Z [[b]]S = b[[n]]S = n [[E1 \nbop E2]]S =([[E1]]S) bop ([[E2]]S)[[X]]S = S(X) [[B1 lop B2]]S =([[B1]]S) lop ([[B2]]S)[[E1 iop E2]]S \n=([[E1]]S) iop ([[E2]]S) [[notB]]S = \u00ac([[B]]S) [[C]] .S .S. [[skip]] = .S.iSl [[X:=E]] = .S.iS[X .[[E]]S]l \n[[C1;C2]] = [[C2]]*.[[C1]] [[if B thenC1 elseC2]] = .S.[[B]]S =. [[C1]]S | [[C2]]S [[while B doC]] = \nfix f ..S.[[B]]S =. f *([[C]]S) |iSl Figure 1. Syntax and Semantics of whilePrograms for completeness.1 \nSemantically, the denotation of ft is a binary relation on [[t]]: [[Ft]] = 0/ [[{c}t]] = {(c,c)} [[.t]] \n= {(x,x) |x .[[t]]} [[Tt]] = [[t]] \u00d7[[t]] Types for states are then .nite maps from variables to types \nfor int exps, written as lists with the usual conventions. In particular, writing F,X : fint implies \nthat X does not occur in F. F := -|F,X : fint State types are interpreted as binary relations on S: [[-]] \n= S \u00d7S [[F,X : fint]] = [[F]] n{(S,Si) |(S(X),Si(X)) .[[fint]]}  3.1.2 Entailment There is a subtyping \nrelation =on expression types, which is ax\u00adiomatised as follows: Ft =ft {c}t =.t ft =Tt ft =ft t =fii \nft =fi fi tt ft =fii t 1This is really just a matter of taste. Ft does not appear in many interesting \nderivations. The above induces a depth-and width-subtyping relation on state types: F =- F,X : fint =F \nF,X : Fint =Fi F =Fi fint =fi int F =Fi ,X : Tint F,X : fint =F,X : fi int Because F,X : Tint =F and \nF =F,X : Tint, absence of a variable from a state type is equivalent to it being present with type Tint. \nLEMMA 1. 1. For all ft and F, [[ft]] and [[F]] are partial equivalence rela\u00adtions. 2. The =relation \non state types is re.exive and transitive. 3. If ft =fi t then [[ft]] .[[fi t]]. 4. If F =Fi then [[F]] \n.[[Fi]].  3.1.3 Judgements DDCC has two basic forms of judgement. For expressions, with F,Fi.t exp, \nwe have judgements of the form fF ~Fi : F .ft whilst for commands, C,Ci.com, there are judgements of \nthe form fC ~Ci : F .Fi We write f C : F . Fi as shorthand for f C ~ C : F . Fi and similarly for single-subject \nexpression judgements. If we de.ne [[F . ft]] . (S . [[t]]) \u00d7 (S . [[t]]) ={( f , f i) |.(S,Si) . [[F]]. \n( fS, f iSi) . [[ft]]} [[F . Fi]] . (S . S.) \u00d7 (S . S.) ={( f , f i) |.(S,Si) . [[F]]. ( fS, f iSi) . \n[[F]].} then the intended meanings of the judgements are: |= Ft ~ Ft i : F . ft = ([[Ft]], [[Ft i]]) \n. [[F . ft]] |= C ~ Ci : F . Fi= ([[C]], [[Ci]]) . [[F . Fi]] LEMMA 2. [[F . ft]] and [[F . Fi]] are \nadmissible partial equiv\u00adalence relations. Some basic rules for deriving DDCC judgements are shown in \nFig\u00adure 2. The rules for expressions refer to abstract versions o op of each primitive binary operator \nop in the language. A typical de.nition is that for multiplication: \u00d7x Fint {0}int {n}int .int Tint Fint \nFint Fint Fint Fint Fint {0}int Fint {0}int {0}int {0}int {0}int {m}int Fint {0}int {m \u00d7 n}int .int Tint \n.int Fint {0}int .int .int Tint Tint Fint {0}int Tint Tint Tint The general correctness condition for \nabstract operations is familiar from abstract interpretation: De.nition 1. We say o op soundly abstracts \nthe operation op if i .(x,xi) . [[ft]],(y,yi) . [[fi op yi) . [[ft ot]]. t]]. (xopy,xop fi The most interesting \nof the rules in Figure 2 are those for condi\u00adtionals and while-loops. Observe that for two conditionals \nto be related, not only do their true and false branches have to be pair\u00adwise related, but they also \nhave to agree on which branch is taken; this is expressed by the use of .bool in the premises of the \nrule. Similar considerations apply to the rule for while-loops, which en\u00adsures that related loops execute \nin lockstep.  3.2 Equations Using only the rules in Figure 2, most of the interesting judgements one \ncan prove relate a phrase to itself at some type. In other words, they constitute an analysis system \nbut not yet a program transfor\u00admation system. However, the advantage of our formulation is that program \ntransformations can now be speci.ed and justi.ed simply by adding new inference rules whose soundness \nmay be straightfor\u00adwardly and independently checked in terms of the semantics. 3.2.1 Basic equations \nOur .rst set of transformation rules express universally applicable structural equivalences for while-programs, \nwithout requiring any of the extra information gathered by the analysis. Sequential unit laws: f C : \nF . Fi [D-SU1] f (skip;C) ~ C : F . Fi f C : F . Fi [D-SU2] f (C;skip) ~ C : F . Fi Associativity: f \n(C1;C2);C3: F . Fi f ((C1;C2);C3) ~ (C1;(C2;C3)) : F . Fi In practice, one usually identi.es programs \nup to associativity of sequential composition, rather than making explicit use of the rule above. Commuting \nconversion for conditional: f C3: Fi. Fii f if B thenC1 elseC2: F . Fi [D-CC] f (if B thenC1 elseC2);C3 \n~ if B then (C1;C3) else (C2;C3) : F . Fii Equivalent branches for conditional: f C1 ~ C2: F . Fi [D-BrE] \nf if B thenC1 elseC2 ~ C1: F . Fi Loop unrolling: f while B doC : F . Fi [D-LU1] f while B doC ~ if \nB thenC;(while B doC) else skip : F . Fi f while B doC : F . Fi [D-LU2] f while B doC ~ while B do (C;if \nB thenC else skip) : F . Fi Self-assignment elimination: f X:=X ~ skip: F, X : fint . F,X : fint [D-SAs] \nIn conjunction with the core rules, the rules above can be used to derive many of the basic equalities \none might expect.2 From a prag\u00admatic point of view, however, they are somewhat unwieldy: even very simple \nproofs get quite large, with many applications of the symmetry and transitivity rules and many repeated \nsub-derivations. Reformulating the rules as logically equivalent versions which can be applied in more \ngeneral contexts helps immensely. For example, a better formulation of one of the skip rules is the following: \nf Ci~ Cii : Fi. Fii f C ~ skip : F . Fi [D-SU1 ] f (C;Ci) ~ Cii : F . Fii Presenting rules in this style \nis essentially trying to produce a sys\u00adtem with a kind of cut-elimination property, but we leave serious \nconsideration of proof-theoretic matters to future work.  3.2.2 Optimizing Transformations In this \nsection we consider some more interesting rules, in which equations are predicated on information in \nthe type system. 2Though the rules presented are in no sense complete. There are sound rules (arithmetic \nidentities and equivalences for nested conditionals, for example) which are not consequences of the ones \nwe have given. Subtyping and Structural fC ~Ci : F.-[D-CT1] fC ~Ci : F, X : Fint .Fi [D-CT2] fFt~Fti \n: F.Tt[D-ET1] ~Fi~Fii fFtt: F.ft fFtt: F.ft Fi=Fft=ft fFt~Fti: F, X : Fint .ft[D-ET2] [D-ESym] [D-ESub] \ni fFti~Ft: F.ft fFt~Fti : Fi.ft ii ~Fii fC ~Ci : F1 .FFF2 =FfFt~Fi : F.ft fFi.f 21 =F12 ttt: Ft [D-CSub] \n[D-ETr] ii ~Fii fC ~Ci: F1 .FfFtt: F.ft 2 i ifCi~Cii : Fi fC ~Ci : F.FfC ~Ci : F.F.F [D-CSym] [D-CTr] \nifC ~Cii: Fi fCi~C : F.F.F Expressions fX ~X : F, X : fint .fint [D-V] fn ~n : F.{n}int [D-N] ~Gii \nfFt~Gt: F.ft fFti t: F.ft fb ~b : F.{b}bool [D-B] [D-op] i fFtop Fti~Gtop Gi t: F.(ftop ft o) Commands \ni ii fC1 ~C1 i : F.FfC2 ~C2 i : Fi.Ffskip~skip : F.F[D-Skip] [D-Seq] ii f(C1;C2) ~(C1i;C2i) : F.F i \n fE ~Ei : F,X : fint .fint fB ~Bi: F..bool fC ~Ci: F.F [D-Ass] [D-Whl] i fX:=E ~X:=Ei: F, X : fint .F,X \n: ff(while B doC) ~(while Bi doCi) : F.F int ii fB ~Bi : F..bool fC1 ~C1 i : F.FfC2 ~C2 i : F.F[D-If] \ni f(if B thenC1 elseC2) ~(if Bi thenC1 i elseC2i) : F.F Figure 2. Core DDCC System Dead assignment elimination: \nf(X:=E) ~skip: F, X : fint .F,X : Tint [D-DAs] Intuitively, the dead assignment rule says that an assignment \nto a variable is equivalent to skip if we are in a context in which the value of that variable does not \nmatter. Constant folding: fFt: F.{c}t [D-CF] fFt~c : F.{c}t Known branch: i fB : F.{true}fC1 ~Ci: F.F \n[D-KBT] ii f(if B thenC1 elseC2) ~Ci : F.F i fB : F.{false}fC2 ~Ci: F.F [D-KBF] ii f(if B thenC1 elseC2) \n~Ci : F.F Dead while: fB : F.{false} [D-DWh] f(while B doC) ~skip : F.F Divergence: fB : F.{true}fC \n: F.F [D-Div] i f(while B doC) : F.F The type Fi in the conclusion of the rule above is arbitrary because \nthe loop will diverge when executed in any state in the domain of F. The following is an easy induction, \nrelying on Lemmas 1 and 2: THEOREM 1. Assuming the abstract operations satisfy the cor\u00adrectness condition \ngiven in De.nition 1, the core DDCC rules of Figure 2 and the additional rules of Section 3.2 are all \nsound: fFt~Fti: F.ft =.|= Ft~Fti : F.ft ii fC ~Ci : F.F=.|= C ~Ci: F.F   3.3 Example Transformations \nThese rules are suf.cient to capture some non-trivial transforma\u00adtions, including constant propagation, \ndead-code elimination and program slicing [33]. Some example derivations are shown in Fig\u00adure 3. We leave \nit as an exercise to prove larger examples, such as the slicing transformation: Constants, known branches \nand dead code: D1: [D-V] [D-N] [D-N] fX : F, X : {3}.{3}f3 : F,X : {3}.{3}f7 : F,X : {3}.{7} [D-=] [D-Ass] \nfX = 3 : F, X : {3}.{true}fX:=7 : F,X : {3}.F,X : {7} [D-KBT] f(if X = 3 then X:=7 elseskip) ~(X:=7) \n: F,X : {3}.F,X : {7} D2: [D-V] [D-N] fX : F, X : {7},Z : Tint .{7}f1 : F,X : {7},Z : Tint .{1} [D-+] \nfX + 1 : F,X : {7},Z : Tint .{8} [D-CF] fX + 1 ~8 : F, X : {7},Z : Tint .{8} [D-Ass] Z:=X + 1 f : F,X \n: {7},Z : Tint .F,X : {7}, Z : {8} F,X : {7},Z : {8}= F,X : Tint,Z : {8} ~Z:=8 [D-CSub] Z:=X + 1 f \n: F, X : {7},Z : Tint .F,X : Tint,Z : {8} ~Z:=8 D3: f(8) : F, X : Tint,Z : Tint .{8}[D-DAss] f(X:=7) \n~skip : F, X : {3},Z : Tint .F,X : Tint,Z : Tint fZ:=8 : F, X : Tint,Z : Tint .F,X : Tint, Z : {8}[D-SU1 \n] f(X:=7;Z:=8) ~Z:=8 : F,X : {3}, Z : Tint .F,X : Tint,Z : {8} D1 D2 [D-Seq] (if X = 3 then X:=7 elseskip;Z:=X \n+ 1) f : F, X : {3} ~(X:=7;Z:=8) , Z : Tint .F, X : Tint,Z : {8} D3 [D-CTr] (if X = 3 then X:=7 else \nskip;Z:=X + 1) f : F,X : {3} ~(Z:=8) ,Z : Tint .F,X : Tint, Z : {8} Figure 3. Examples of DDCC Transformations \nI:=1; I:=1; S:=0; P:=1; P:=1 while I<N do ( ==> while I<N do ( S := S+I; P := P*I; P := P*I;  I \n:= I+1;) I := I+1;) at type N : .int .P : .int. Here we expressed the fact that we were only interested \nin the .nal value of P simply by transforming it at a result type which only constrains the value of \nthat variable to be preserved all the others (in particular S) are typed at Tint and so are allowed \nto take any value.  3.4 Secure Information Flow It is worth observing that the T,. fragment of our \ncalculus can be seen as a non-interference type system. Figure 4 presents a version of a type system \nfor secure information .ow due to Smith and Vol\u00adpano [27]. In this system, a security level, s, is either \nlow (L)or high (H). A context . is then a .nite map from variables to security levels: . := -|.,X : sint \nGiven such a context, the type system assigns a security level (sint or sbool) to each expression and \n(scom) to each command. The property which the type system ensures is that any typeable com\u00admand does \nnot allow information to .ow (either directly, via as\u00adsignment, or indirectly, via control .ow) from \nhigh security vari\u00adables to low security ones. We de.ne a translation (\u00b7)* from the Smith/Volpano system \ninto DDCC as follows: Expression types: L* t = .t and Ht * = Tt. * Contexts: -= -and (.,X : sint)* = \n.* ,X : s* int. Judgements: (. fF : st)* = fF ~F : .* .s* t (. fC : Lcom)* = fC ~C : .* ..* (. fC : Hcom)* \n= fC ~skip : .* ..* THEOREM 2. For any judgement J derivable in the Smith/Volpano system, J* is derivable \nin DDCC PROOF. This is a simple induction, relying on the dead assignment axiom in the case of high assignment \nstatements, sequential unit for high sequential compositions and the equivalent branch rule for high \nconditionals. De.nition 2. In the context of a security type assignment ., a com\u00admand C satis.es strong \nsequential noninterference if |= C ~C : .*..* . .,X : sint f X : sint . f n : sint . f b : sbool . f \nE : sint . f Ei : sint ., X : sint f E : sint + similar for bop and lop . f E iopEi : sint .,X : sint \nf X:=E : scom . f C : scom . f Ci : scom . f B : sbool . f C : scom . f Ci : scom . f C;Ci : scom . f \nif B thenC elseCi : scom . f B : Lbool . f C : Lcom . f F : Lt. f C : Hcom . f while B doC : Lcom . f \nF : Ht. f C : Lcom Figure 4. Smith/Volpano Type System This version of non-interference is the semantic \nsecurity property intended by Smith and Volpano, though the actual property estab\u00adlished by the soundness \nproof in [27] is more syntactic and inten\u00adsional, as it is de.ned in terms of their particular typing \nrules. Our notion of intereference is strong because it is termination-sensitive: varying the high-security \ninputs affects neither the low-security out\u00adputs nor the termination behaviour. In the absence of any \ntermina\u00adtion analysis, this is enforced by the rather brutal approach of mak\u00ading all high-security commands \ntotal. The weaker notion of non\u00adinterference that is achieved by the earlier system of Volpano, Smith \nand Irvine [29] does not seem to translate directly into DDCC. Even without constant tracking, DDCC is \nmarginally more power\u00adful than the Smith/Volpano system. For example, if H is a high\u00adsecurity variable, \nand L is low-security then the following are easily shown to satisfy non-interference in DDCC, but would \nbe rejected by the Smith/Volpano system: 1. ifH>3thenH:=L;L:=1 else L := 1 2. L:=H;L:=3  4 Relational \nHoare Logic There are many common optimizing transformations which are not captured by DDCC. In particular: \nIt does not capture any transformations that take advantage of the fact that one knows statically which \nway a boolean test must have evaluated if one is within a particular branch of a conditional, or either \nin the body of or have just left a while\u00adloop. For example, the judgement f (if X = 3 thenY :=X elseY \n:=3) ~ (Y :=3) : X : . . Y : {3} is semantically valid but not derivable. It cannot express the preservation \nof the values of expressions, except where they are statically known to be a particular con\u00adstant. These \nmeans even trivial code-motion transformations cannot be derived. We can address these shortcomings by \nmaking piecemeal additions to the system, such as quanti.cation over variables ranging over integers \nor PERs. However, there is a simple and elegant system, which we call Relational Hoare Logic (RHL), into \nwhich many of these extensions or alternative type systems can be embedded. Unlike DDCC, RHL does not \nlook like a conventional type-based analysis system it has a rather general syntax for relations and \nis parameterized on some system for deciding the entailment rela\u00adtion between them. The intention is \nthat more speci.c analyses and transformations can formulated as subsystems of RHL by restrict\u00ading the \nsyntax of assertions and providing particular approximations to the entailment relation. Another way \nin which RHL goes beyond DDCC is that it is not restricted to partial equivalence relations, which deserves \nsome comment. PERs are certainly privileged: they are the basis of equational rea\u00adsoning, and we will \nnearly always be trying to prove that one pro\u00adgram phrase is related to another by a PER so that we can \nperform a rewrite in some context. However, in order to establish that a two phrases are related by a \nPER, we often have to do some lo\u00adcal reasoning using more general relations. This is familiar in the \nsemantics of polymorphic type theories: types are interpreted by PERs, and polymorphism by quanti.cation \nover PERs, but para\u00admetricity theorems and equivalence results for implementations of abstract dataypes \narise from substituting more general relations. To give some intuition for why this might be so, consider \nproving the equivalence X:=-Y; X:=Y; Z := Z-X; ==> Z := Z+X; X := -X; at, say, Y : .int,Z : .int . \nX : .int,Y : .int,Z : .int. If we try to to establish that the two commands are related by this PER by \nrelating their intermediate states (though this is not the only approach one could take), we will need \nto use the relation that the value of X in one state is the negation of that in the other, which is not \na PER. RHL is an extremely simple variation on traditional Floyd-Hoare logic [13]. Instead of assertions \nwhich denote predicates on states and judgements which say that terminating execution of a command in \na state satisfying a precondition will yield a state satisfying a postcondition, we directly axiomatise \nwhen a pair of commands map a given pre-relation into a given post-relation. Binary rela\u00adtions on states \nare simply speci.ed by boolean expessions of the language over variables tagged with an indication of \nwhich of the two states they refer to. At .rst sight, this may seem frighteningly simple-minded, but \nit actually works rather nicely. In this presen\u00adtation we do not consider quanti.cation over metavariables \n( ghost variables ) denoting integers: their addition is straighforward, but simple global analyses seem \nto be expressible without them. fC ~Ci : F .(B(1).Bi(2)) .FifD ~Di : F .not(B(1).Bi(2)) .Fi fskip~skip \n: F .F [R-Skip] [R-If] fif B thenC else D ~if Bi thenCi else Di : F .(B(1)= Bi(2)) .Fi fD ~Di : Fi.Fii \n fC ~Ci : F .Fi [R-Seq] fX := E ~Y := Ei : F[E(1)/X(1),Ei(2)/Y (2)] .F [R-Ass] ; Di : F .Fii fC ; D ~Ci \n fC ~Ci : F .(B(1).Bi(2)) .F .(B(1)= Bi(2)) [R-Whl] fwhile B doC ~while Bi doCi : F .(B(1)= Bi(2)) .F \n.not(B(1).Bi(2)) fC ~Ci : F1 .F2 |= Fi 1 =F1 |= F2 =Fi 2 [R-Sub] fC ~Ci : Fi 1 .Fi 2 fCi~Cii : F .Fi \n fC ~Ci : F .Fi|= PER(F .Fi) fC ~Ci : F .Fi|= PER(F .Fi) [R-Sym] [R-Tr] fC ~Cii : F .FifCi~C : F .Fi \n Figure 5. Core Relational Hoare Logic 4.1 RHL Syntax and Semantics 4.1.1 Syntax We de.ne generalized \nexpressions and relational assertions as fol\u00adlows: gexp .GE := n |X(1)|X(2)|GE iop GE relexp .F := b \n|GE bop GE |notF |F lop F We overload the notation (\u00b7)(1) and (\u00b7)(2) to stand for homomor\u00adphic embeddings \nint exp .gexp and bool exp .relexp in the obvious way. The basic judgement form is f C ~ Ci : F .Fi (though \nthe use of ~for arbitrary relations is arguably bad). 4.1.2 Semantics The semantics of generalized expressions \nas integer-valued func\u00adtions of two states, and of relational assertions as relations on states is unsurprising: \n[[GE]] . S \u00d7S .Z [[n]](S1, S2)= n [[X(1)]](S1, S2)= S1(X) [[X(2)]](S1, S2)= S2(X) [[E iop F]](S1, S2)=([[E]](S1,S2)) \niop ([[F]](S1,S2)) [[F]] . S \u00d7S [[true]] = S \u00d7S [[false]] = 0/ [[E bop F]] = {(S1,S2) |([[E]](S1, S2)) \nbop ([[F]](S1, S2)) = true}[[F lop Fi]] = {(S1,S2) |([[F]](S1, S2)) lop ([[Fi]](S1, S2)) = true}[[notF]] \n= (S \u00d7S) \\[[F]] The intended meaning of judgements is given by |= C ~Ci : F .Fi =.(S1, S2) .[[F]]. ([[C]](S1),[[Ci]](S2)) \n.[[Fi]]. We will also need some auxiliary semantic judgements, whose meanings are as follows: |= F =Fi= \n[[F]] .[[Fi]] |= PER(F) = ([[F]] .[[F]] .[[F]]) and ([[F]]-1 .[[F]]) LEMMA 3. 1. For all GE,GEi,X,S,Si: \n[[GE[GEi/X(1)]]](S,Si)  =[[GE]](S[X .[[GEi]](S,Si)], Si) And similarly for X(2)and Si .  2. For all \nF,GE,X: [[F[GE/X(1)]]]  = {(S,Si) |(S[X .[[GE]](S, Si)],Si) .[[F]]} And similarly for X(2)and Si . \n3. For all F and Fi , [[F]] and [[F .Fi]] are admissible relations.  4.1.3 Inference Rules The core \nrules for RHL are shown in Figure 5. Observe that, as was the case in DDCC, the basic rules ensure that \nthe same conditional branches are taken and that loops are executed the same number of times on the two \nsides. Note also that one could add distinct semantic judgements for symmetry and transitivity, rather \nthan re\u00adquiring both. The assignment rule is surprisingly liberal, but there is no reason to require \nthe assigned variables to be the same in both commands. 4.2 Equations As with DDCC, we will specify optimizing \ntransformations by adding extra (sound) rules to the core. But even before we do that, RHL can justify \nsome useful transformations. Here s an example of removing a redundant evaluation: Z:=Y +1 X(1)=X(2). \nX(1)=X(2). 1. f : . by ~Z:=XY (1)+1 =X(2) Z(1)=Z(2. [R-Ass]  X:=Y +1 Y (1)+1 =Y (2)+1. X(1)=X(2). 2. \nf : . ~X:=Y +1 Y (1)+1 =Y (2)+1 Y (1)+1 =X(2) by [R-Ass] Y (1)+1 =Y (2)+1. 3. |=(Y (1)=Y (2))= by logic \nY (1)+1 =Y (2)+1 X:=Y +1 X(1)=X(2). 4. f : Y (1)=Y (2). by ~X:=Y +1 Y (1)+1 =X(2) [R-Sub] applied to \n2. and 3. X:=Y +1;Z:=Y +1 X(1)=X(2). 5. f : Y (1)=Y (2). ~X:=Y +1;Z:=XZ(1)=Z(2) by [R-Seq] applied to \n4. and 1. 4.2.1 Basic Equations The basic equations we presented in the context of DDCC are still valid \nfor RHL, with the exception of self-assignment elimination. 4.2.2 Optimizing Transformations Dead assignment: \nfX:=E ~skip : F[E(1)/X(1)].F [R-DAssl] fskip ~X:=E : F[E(2)/X(2)].F [R-DAssr] These rules subsume our \nprevious dead-assignment and self\u00adassignment rules. Known branch: fC ~D : F .Fi [R-KBTl] fif B thenC \nelseCi~D : F .B(1).Fi fCi~Di : F .Fi [R-KBFl] fif B thenC elseCi~Di : F .\u00acB(1).Fi Plus two similar rules \nwith the conditional on the right. (The fact that our relations are no longer assumed symmetric leads \nto a slightly unfortunate proliferation of variants.) Dead while: fwhileB doC ~skip: F .notB(1).F .notB(1)[R-DWhll] \nPlus the variant with skip on the left. Soundness is a simple induction, relying on Lemma 3: THEOREM \n3. For all C,Ci ,F,Fi,if fC ~Ci : F .Fi is derivable using the rules in Figure 5 and Section 4.2 then \n|=C ~Ci : F .Fi . 4.3 Examples With these rules, one can prove the correctness of many traditional compiler \noptimizations, including various forms of code motion and predicated transformation. Producing proofs \nin RHL is fairly straightforward, so we just give a couple of small examples of the sort of thing one \ncan prove. Invariant hoisting: while I<N do X := Y+1; X := Y+1; ==> while I<N do I := I+X; I := I+X; \n at type F .F where F is I(1)=I(2).N(1)=N(2).Y (1)= Y (2). Note that the lifting is only valid because \nwe do not care about the .nal value of X. The proof makes two uses of the dead-assignment rule, which \nis a common pattern for per\u00adforming code-motion in RHL: one effectively adds skipsto both sides to make \nthem the same shape , shows the equiva\u00adlence using the congruence rules and then removes the skips. Sophisticated \ndead-code: if X>3 then Y=X else Y=7 ==> skip at type (X(1) =X(2). Y (1) > 2 .Y (2) > 2). (Y (1) > 2 \n.Y (2) > 2). I.e. if all that matters about the value of Y in the rest of the derivation is that it is \ngreater than 2, then the conditional has no effect. This is proved by using the condi\u00adtional rule to \nshow the equivalence of the two branches and then applying the equivalent branch rule. The main weakness \nof RHL as presented here relates to its treat\u00adment of loops. Since we insist that transformed programs \nhave the same termination behaviour as the original, but have no non\u00adtrivial termination analysis, this \nis hardly suprising. I believe it is possible to add sound rules which can justify some cases of loop \ndistribution/fusion, but more ambitious loop optimizations seem to require either a language with restricted \niteration constructs or a logic which can reason about termination. 4.4 Embedding Simpler Logics in RHL \nRHL is powerful but hardly suitable for direct implementation in a compiler. However, it can provide \na useful framework for de\u00adveloping sound type and transformation systems which are more speci.c. One \nwould start by identifying a restricted sublanguage of relational assertions. For example, several useful \nanalyses can be formulated using only partial equivalence relations generated from axioms such as: fPER(E(1)=E(2)) \nfPER(B(1)=B(2)) fPER(B(1).B(2)) plus rules stating that PERs are closed under conjunction, disjoint union \nand the arrow constructor. Our earlier DDCC system is of this form, with state relations being formed \nas conjunctions of primitive assertions of the forms X(1)=X(2)and X(1)=n .X(2)=n. The rules of DDCC can \nthen be presented as derived rules in RHL. A natural question is whether the usual Hoare logic can be \nem\u00adbedded in RHL. One s .rst thought might be that a partial cor\u00adrectness judgement {P}C{Q}would be equivalent \nto the squared RHL judgement fC ~C : P(1).P(2).Q(1).Q(2), but this is not the case because C s termination \nbehaviour might differ on two states satisfying P. Nor can one simply intersect the pre-and post\u00adrelations \nwith the identity relation on states, since we do not have syntax for that global identity relation. \nIf we .x C, however, we can conjoin the pre-and post-relations with X(1) =X(2) for every variable X occurring \nin C and thus effectively recover Hoare logic.3 Going the other way, one can soundly extend RHL with \nthe squared versions of valid total correctness judgements [P]C[Q]. As a simple, concrete example of \nthe embedding approach, Fig\u00adure 6 presents (a very naive version of) a type system AERC for available \nexpression analysis and removal of redundant evaluation. State types T are .nite sets {Xi =Ei | 1 = i \n= n} of equalities be\u00adtween variables and expressions (in which the same variable may occur multiple \ntimes on the left) and we write T = Ti for T . Ti . The macros kill and gen are de.ned by kill(T, X)={(Xi \n=Ei). T | Xi =X . X . Ei} {X =E} if X . E gen(X,E)= {} otherwise The translation of the AERC into RHL \nis indexed by a .nite set V of variables. De.ne T* =(X(1) =X(2)).(X(1) =E(1)) V X.V (X=E).T It is easy \nto see that for any T, |=PER(TV * )and that T = Ti implies V = Ti* T* V . The following asserts the soundness \nof the translation, and hence of AERC: THEOREM 4. For any expressions E,F and commands C,D all of whose \nvariables occur in V, T* {1,2}. 1. If f E ~ F : T . t then |=V = (E(i) =F(j))for i, j . V . Ti* 2. If \nf C ~ D : T . Ti in AERC then f C ~ D : T* V in RHL. PROOF. The interesting case is the AERC rule for \nassignment, which generates the following veri.cation condition in RHL: if T* T* |=V = (E(1) =Ei(2))then \n|=V = (kill(T, X). gen(X,E). * gen(X,Ei))V [E(1)/X(1),Ei(2)/X(2)], which is straightforward to check. \n5 Related Work As we said in the introduction, there has been a good deal of work on proving the correctness \nof optimizing transformations for functional languages, especially from the group at Northeastern [30, \n28, 32, 31] but also by Amtoft on strictness analysis [5], Dami\u00adani and Giannini on dead-variables [10, \n11], Kobayashi on dead\u00advariables [17] and Benton and Kennedy on effects [8]. Damiani and Giannini explicitly \nuse PERs in giving the semantics of their anal\u00adysis system but give a more algorithmic account its use \nin transfor\u00admation. Benton and Kennedy present optimizing transformations as equations in context, but \nderive those (rather clumsily) from a predicate-based semantics for the analysis. Recently Lacey et al. \n[19] described how some of the classical [16, 12, 4] transformations considered here (dead code elimination, \nconstant folding and a simple code-motion transformation) can be formulated as conditional rewrite rules \non control .ow graphs. The rewrites are predicated on temporal logic formulae expressing (in\u00adtensionally) \nthe contexts in which the rewrites may be applied. The 3The civilised way to do this is to index all \nour judgements by .nite sets of variable names. authors then use a small-step operational semantics to \nverify that under these conditions, their transformations preserve the observ\u00adable behaviour of programs. \nLacey et al. express strongly the view that more traditional semantic techniques, in particular denotational \nones, are either unable to express the properties which justify op\u00adtimizing transformations or can only \ndo so at the cost of complex proofs and mathematically sophisticated techniques. I believe the present \npaper provides some evidence to the contrary. Lerner et al. [20] have built an implementation of a domain \nspeci.c language for specifying and justifying rewrites on a simple imper\u00adative language which interfaces \nto a theorem prover for checking the supplied justi.cation. This system also uses a (rather restricted) \nlanguage of temporal logic formulae for specifying optimizations over .ow graphs. Kozen and Patron [18] \ndescribe an algebraic approach to proving some traditional optimizations correct. There is no mention \nof rela\u00adtions in their work, and they abstract rather severely from the actual language (there are no \nassignments, just unspeci.ed atomic pro\u00adgrams including one which makes a variable unde.ned ), but the \nconnections between their work and ours seem worth further study. The work that is most closely related \nto that presented here has been done in the contexts of credible compilation [24, 25] and translation \nvalidation [21, 36]. These both take the view that formal veri.ca\u00adtion of complete optimizing compilers \nis impractical, but that one might realistically produce a correctness proof relating the input and output \nof particular compilations. Translation validation tries to do this without modifying the compiler, using \nan independent tool that tries to infer that the output is a correct translation of the input. Credible \ncompilation envisages an instrumented compiler produc\u00ading a putative proof that the transformations it \nperformed in each particular case were safe; these proofs can then be examined by a comparatively simple \nproof-checker. The basic technical ideas used in credible and validated compilation are very close indeed \nto the ones presented here (developed quite independently). The main dif\u00adference is that we use the language \nof types, denotational semantics and PERs instead of that of control-.ow graphs, operational seman\u00adtics \nand simulation relations. Inspired by Rinard s work, Yang [35] has recently used a version of relational \nHoare logic in reasoning about the correctness of the Schorr-Waite graph marking algorithm. The idea \nof directly axiomatising a logic of PERs [3] and more general relations was inspired by the work of Abadi \net al on a formal logic for parametric polymorphism [2]. We have already mentioned some of the large \namount of recent work using PERs (and domain-theoretic projections) to give se\u00admantics to analyses for \nnon-interference, slicing, secure informa\u00adtion .ow, binding time analysis. An elegant general calculus, \nDCC, for such dependency-based analyses has been de.ned by Abadi et al. [1]. DCC seems comparable to \na higher-order version of our DDCC, though it is not explicitly presented as an equational cal\u00adculus \nand is more directly in the style of type systems for secure information .ow. The work of Hughes on type \nspecialization [14] seems to have in\u00adteresting connections with (a higher-order version of) the work \npre\u00adsented here. Hughes has formulated a type-based analysis which essentially uses a form of singleton \ntype, and proved the correct\u00adness of an associated transformation system which changes types. Singleton \ntypes and their PER semantics have also been studied in some depth by Aspinall [6]. f X ~ X : T. int \n[A-V] f n ~ n : T. int [A-N] f b ~ b : T. bool [A-B] f X ~ E : T.{X = E}. int [A-Red] f skip ~ skip: \nT. T[A-Skp] i ii f E ~ Ei : T. int f F ~ Fi : T. int f C1 ~ C1 i : T. Tf C2 ~ C2 i : Ti. T[A-iop] (+ \nsimilar bop and lop) [A-Seq] ii f E iop F ~ Ei iop Fi : T. int f (C1;C2) ~ (C1i ;C2i ) : T. T f B ~ \nBi : T. bool f C ~ Ci : T. T f E ~ Ei : T. int [A-Whl] [A-Ass] f (while B doC) ~ (while Bi doCi) : T. \nT f X:=E ~ X:=Ei : T. (kill(T,X) . gen(X, E) . gen(X,Ei)) ii i f B ~ Bi : T. bool f C1 ~ C1 i : T. Tf \nC2 ~ C2 i : T. Tf C ~ Ci : T. T[A-If] [A-CSym] i i f (if B thenC1 elseC2) ~ (if Bi thenC1 i elseC2i \n) : T. Tf Ci~ C : T. T ii f C ~ Ci : T1 . T2 T1 = T1 T2 = T2 f E ~ Ei : T. tTi= T f Ft~ Fti : T. t [A-CSub] \n[A-ESub] [A-ESym] ii f C ~ Ci : T1 . T2 f E ~ Ei : Ti. t f Fti~ Ft: T. t if Ci~ Cii : Ti~ Fi~ Fii f \nC ~ Ci : T. T. Tf Ftt: T. t f Fti t: T. t [A-CTr] [A-ETr] f C ~ Cii : Ti~ Fii . Tf Ftt: T. t Figure 6. \nAERC: Available Expressions and Redundant Computation 6 Conclusions and Further Work We have shown how \nsome very elementary techniques can be used to prove the combined correctness of analyses and transformations \nfor simple imperative programs. From a purely semantic perspec\u00adtive, there is nothing very surprising \nhere. But that is as it should be: we have .nally shown that something that appears simple actually is \nsimple. One obvious shortcoming of the present work is that it says nothing about concrete inference \nor transformation algorithms. Although there are bene.ts in factoring a correctness proof into the sound\u00adness \nof a declarative set of inference rules and the correctness of an inference algorithm, one does ultimately \nhave to provide both parts. Although there seems no reason why the approach taken here should not carry \nover to the control-.ow graphs more commonly used in optimizing compilers for imperative languages, proving \ndi\u00adrectly that analyses as they are actually implemented in real com\u00adpilers imply our extensional properties \nseems likely to be somewhat messy. Combining our extensional relational approach to correct\u00adness with \na more algorithmic, but still declarative, framework for specifying transformations (such as that of \nLacey et al.) seems a more reasonable next step. Relational Hoare logic is a promising formalism which \ncertainly merits further study. A limitation of the system presented here is that it cannot justify any \ntransformations which remove loops, except in the special case that they can be completely unrolled at \ncompile-time. This naturally suggests investigating a total\u00adcorrectness variant of the logic, but one \nmight also consider a ver\u00adsion which allows termination-improving transformations. A fur\u00adther possibility \nis to axiomatise the version of relational lifting which maps Fto {(d, di) . S.\u00d7 S.| (d = isl. di = isil)=. \n(s,si) . F}. This is inappropriate for optimizations, but seems use\u00adful in reasoning about termination-insensitive \ninformation .ow [7]. There are many natural ways to develop the ideas here, both in terms of the language \nfeatures and analyses addressed (higher\u00adtypes, higher-typed store, dynamic allocation) and in terms of \nthe features of the logics (e.g. quanti.cation, conjunctive and disjunc\u00adtive types). Doing some of these \nwould require working with rela\u00adtions on recursively-de.ned domains, for which we expect to use the techniques \ndescribed by Pitts [23]. If the technique extends to imperative programs with higher-typed store, a promising \nidea is to look at optimizations on low level code that are justi.ed by rela\u00adtional invariants passed \ndown from a high-level compiler. Acknowledgements. Thanks to Tony Hoare, Andrew Kennedy, David Naumann, \nMatthew Parkinson, Claudio Russo and the ref\u00aderees for useful discussions, feedback and pointers to related \nwork. 7 References [1] M. Abadi, A. Banerjee, N. Heintze, and J. G. Riecke. A core calculus of dependency. \nIn Conference Record of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Pro\u00adgramming Languages \n(POPL), pages 147 160. ACM Press, January 1999. [2] M. Abadi, L. Cardelli, and P.-L. Curien. Formal parametric \npolymorphism. Theoretical Computer Science, 121, 1993. [3] M. Abadi and G. D. Plotkin. A PER model of \npolymorphism and recursive types. In Proceedings of the 5th Annual IEEE Symposium on Logic in Computer \nScience (LICS), pages 355 365. IEEE Computer Society Press, June 1990. [4] A. V. Aho, R. Sethi, and J. \nD. Ullman. Compilers: Principles, Techniques and Tools. Addison Wesley, 1986. [5] T. Amtoft. Minimal \nthunki.cation. In P. Cousot, M. Falaschi, G. Fil`e, and A. Rauzy, editors, Proceedings of the 3rd Inter\u00adnational \nWorkshop on Static Analysis, Padova, Italy, volume 724 of Lecture Notes in Computer Science, pages 218 \n229. Springer-Verlag, September 1993. [6] D. Aspinall. Subtyping with singleton types. In L. Pacholski \nand J. Tiuryn, editors, Computer Science Logic, 8th Interna\u00adtional Workshop (CSL 94), number 933 in Lecture \nNotes in Computer Science. Springer-Verlag, 1995. [7] A. Banerjee and D. Naumann. Secure information \n.ow and pointer con.nement in a Java-like language. In Proceedings of the 15th IEEE Computer Security \nFoundations Workshop (CSFW), pages 253 267. IEEE Computer Society Press, June 2002. [8] N. Benton and \nA. Kennedy. Monads, effects and transfor\u00admations. In Third International Workshop on Higher Order Operational \nTechniques in Semantics (HOOTS), Paris, vol\u00adume 26 of Electronic Notes in Theoretical Computer Science. \nElsevier, September 1999. [9] P. N. Benton. Strictness Analysis of Lazy Functional Pro\u00adgrams. PhD thesis, \nComputer Laboratory, University of Cam\u00adbridge, December 1992. [10] F. Damiani. Useless-code Detection \nand Elimination for PCF with Algebraic Datatypes. In 4th International Conference on Typed Lambda Calculi \nand Applications (TLCA), volume 1581 of Lecture Notes in Computer Science, pages 83 97. Springer-Verlag, \n1999. [11] F. Damiani and P. Giannini. Automatic useless-code detec\u00adtion and elimination for hot functional \nprograms. Journal of Functional Programming, pages 509 559, 2000. [12] M S. Hecht. Flow Analysis of Computer \nPrograms. Elsevier North-Holland, 1977. [13] C. A. R. Hoare. An axiomatic basis for computer program\u00adming. \nCommunications of the ACM, 12(10):576 585, October 1969. [14] J. Hughes. Type specialization for the \nlambda calculus. In Proceedings of the Dagstuhl Seminar on Partial Evaluation, 1996. [15] S. Hunt and \nD. Sands. Binding time analysis: A new PER\u00adspective. In Proceedings ACM SIGPLAN Symposium on Par\u00adtial \nEvaluation and Semantics-Based Program Manipulation (PEPM), June 1991. [16] G. A. Kildall. A uni.ed approach \nto global program optimiza\u00adtion. In Proceedings of the 1st ACM SIGACT-SIGPLAN Sym\u00adposium on Principles \nof Programming Languages (POPL), pages 194 206. ACM Press, 1973. [17] N. Kobayashi. Type-based useless \nvariable elimination. In Proceeedings of the ACM Symposium on Partial Evaluation and Semantics-Based \nProgram Manipulation, 2000. [18] D. Kozen and M. Patron. Certi.cation of compiler optimiza\u00adtions using \nKleene algebra with tests. In Proceedings of the 1st International Conference in Computational Logic, \nvol\u00adume 1861 of Lecture Notes in Arti.cial Intelligence. Springer-Verlag, 2000. [19] D. Lacey, N. D. \nJones, E. Van Wyk, and C. C. Frederiksen. Proving correctness of compiler optimizations by temporal logic. \nIn Proceedings of the 29th Annual ACM SIGPLAN -SIGACT Symposium on Principles of Programming Lan\u00adguages, \nPortland, January 2002. [20] S. Lerner, T. Millstein, and C. Chambers. Automatically prov\u00ading the correctness \nof compiler optimizations. In Proceed\u00adings of the ACM SIGPLAN 2003 Conference on Programming Language \nDesign and Implementation (PLDI), June 2003. [21] G. C. Necula. Translation validation for an optimizing \ncom\u00adpiler. In Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation \n(PLDI), pages 83 95, 2000. [22] F. Nielson. Program transformations in a denotational setting. ACM Transactions \non Programming Languages and Systems (TOPLAS), 7(3):359 379, July 1985. [23] A.M. Pitts. Relational properties \nof domains. Information and Computation, 127, 1996. [24] M. Rinard. Credible compilation. Technical Report \nMIT\u00adLCS-TR-776, Massachusets Institute of Technology, March 1999. [25] M. Rinard and D. Marinov. Credible \ncompilation with point\u00aders. In Proceedings of the FLoC Workshop on Run-Time Re\u00adsult Veri.cation, July \n1999. [26] A. Sabelfeld and D. Sands. A PER model of secure informa\u00adtion .ow in sequential programs. \nHigher-Order and Symbolic Computation, 14(1):59 91, March 2001. [27] G. Smith and D. Volpano. Secure \ninformation .ow in a multi\u00adthreaded imperative language. In Conference Record of the 25th ACM Symposium \non Principles of Porgramming Lan\u00adguages (POPL), January 1998. [28] P. A. Steckler and M. Wand. Lightweight \nclosure conversion. ACM Transactions on Programming Languages and Systems (TOPLAS), pages 48 86, January \n1997. Original version ap\u00adpeared in Proceedings 21st ACM Symposium on Principles of Programming Languages, \n1994. [29] D. Volpano, G. Smith, and C. Irvine. A sound type system for secure .ow analysis. Journal \nof Computer Security, 4:167 187, December 1996. [30] M. Wand. Specifying the correctness of binding-time \nanal\u00adysis. In Conference Record of the 20th ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLan\u00adguages (POPL), pages 137 143. ACM, January 1993. [31] M. Wand and W. D. Clinger. Set constraints \nfor destructive ar\u00adray update optimization. Journal of Functional Programming, 11(3):319 346, May 2001. \nPreliminary version appeared in International Conference on Computer Languages, 1998. [32] M. Wand and \nI. Siveroni. Constraint systems for useless vari\u00adable elimination. In Proceedings 26th ACM Symposium \non Principles of Programming Languages, pages 291 302, 1999. [33] M. Weiser. Program slicing. IEEE Transactions \non Software Engineering, 10(4):352 357, July 1984. [34] G. Winskel. The Formal Semantics of Programming \nLan\u00adguages. MIT Press, 1993. [35] H. Yang. Veri.cation of the Schorr-Waite graph marking al\u00adgorithm by \nre.nement. Slides from talk at Dagstuhl Seminar 03101, March 2003. [36] L. Zuck, A. Pnueli, Y. Fang, \nand B. Goldberg. VOC: A methodology for the translation validation for optimizing compilers. Journal \nof Universal Computer Science, 9(3):223 247, 2003.   \n\t\t\t", "proc_id": "964001", "abstract": "We show how some classical static analyses for imperative programs, and the optimizing transformations which they enable, may be expressed and proved correct using elementary logical and denotationaltechniques. The key ingredients are an interpretation of program properties as relations, rather than predicates, and a realization that although many program analyses are traditionally formulated in very intensional terms, the associated transformations are actually enabled by more liberal extensional properties.We illustrate our approach with formal systems for analysing and transforming while-programs. The first is a simple type system which tracks constancy and dependency information and can be used to perform dead-code elimination, constant propagation and program slicing as well as capturing a form of secure information flow. The second is a relational version of Hoare logic, which significantly generalizes our first type system and can also justify optimizations including hoisting loop invariants. Finally we show how a simple available expression analysis and redundancy elimination transformation may be justified by translation into relational Hoare logic.", "authors": [{"name": "Nick Benton", "author_profile_id": "81100165244", "affiliation": "Microsoft Research, Cambridge, UK", "person_id": "P208599", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/964001.964003", "year": "2004", "article_id": "964003", "conference": "POPL", "title": "Simple relational correctness proofs for static analyses and program transformations", "url": "http://dl.acm.org/citation.cfm?id=964003"}