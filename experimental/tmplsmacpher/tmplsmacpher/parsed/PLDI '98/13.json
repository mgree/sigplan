{"article_publication_date": "05-01-1998", "fulltext": "\n An implementation of complete, asynchronous, distributed garbage collection Fabrice Le Fessant, Ian \nPiumarta, Marc Shapiro INRIA Roquencourt, B.P. 105, 78153 Le Chesnay Cedex, Ihmce (Email: {Fulrrtce. \nLe-fwont, Iun. Piumurb, Mrrrc. Shupirv}Qinria. fr) Abstract Most existing reference-based distributed \nobject systems in-clude some kind of acyclic garbage collection, but fail to provide acceptable collection \nof cyclic garbage. Those that do provide such GC currently suffer from one or more prob-lems: synchronous \noperation, the need for expensive global consensus or termination algorithms, susceptibility to com-mmication \nproblems, or an algoritlm that does riot scale. We present a simple, complete, fault-tolerant, asyxichronous \nexteusion to the (acyclic) cleanup protocol of the SSP Chains system This extension is scalable, consumes \nfew resources, and could easily be adapted to work in other reference-based distributed object systems-rendering \nthem usable for very large-scale applications. Keywords: storage nlanagement, garbage collection, refer-ence \ntracking, distributed object systems. 1 Introduction Autorriatic garbage collection is an important feature \nfor ruoderu high-level languages. Although there is a lot of ac-cumulated experience in local garbage \ncollection, distributed prograrmling still lacks effective cyclic garbage collection. A local garbage \ncollector should be cormA and complete. A distributed garbage collector should also be usynclk7wkous \n(other spaces corltinue to work during a local garbage collec-tion in one space), f&#38;t-tohmt (it works \neven with unreli-able cormiuriications arid space crashes), and sculuble (since networks are connecting \nlarger numbers of computers over increasing distances). Previously published distributed garbage collection \nalgo-rithms fail in one or more of these requirements. In this pa-per we present a distributed garbage \ncollector for distributed languages that provides all three of these desired properties. Moreover, the \nalgorithrrl is simple to impleruexlt and COII-sumes very few resources. The algoritlm described in this \npaper was developed as part of a reference-based distributed object system for Objective-CAML (a dialect \nof ML with object-oriented ex- Permission to make digital w hard cop** of all or part of thls work for \npersonal or classroom usa ia granted without in provided that copies are not mada or distrlbutad for \nprofit OT oomnnrcial advan- tage and that copies bear this notiu and tha full citation on ti tit Paw \n70 copy othwwin. to republiih. to pcet on ..rv.r. 0) to redistribute to Lisa, require prior specific \npermission and/or a fee. BIGPLAN 98 Montreal, Canada 0 1998 ACM 0-89791.987-%/98/0006...$6.00 tensions). \nRemote references are managed using the Stub-Scion Pair Chains (SSPC) system, extended with our cyclic \ndetection algorithm. Although our system is based on traus-parent distributed references, our design \nassuruptions are weak enough to support other kinds of distributed languages; those based on cliamels, \nfor example (x-calculus [8], join- calculus [3], and others). The next two sections of the paper introduce \nthe basic mechanisms of remote references and the SSPC system for acyclic distributed garbage collection. \nSection 4 describes our cycle detection algorithrri, arid includes a short example showing how it works. \nSection 5 briefly investigates some issues related to our algorithm. Sections 6 arid 7 analyze the algorithm \nim greater depth, and discuss some of the im-plementation issues surrourlding it. The final two sections \ncompare our algorithm with other recent work in distributed garbage collection and present our conclusions. \n2 Basics We consider a distributed system consisting of a set of spaces. Each space is a process, that \nhas its own memory, its own local roots, and its own local garbage collector. A space can corrmnmicate \nwith other spaces (on the same computer or a different one) by sending asynchronous messages. These messages \nmay be lost, duplicated or delivered out of order. Distributed computation is effected by sending messages \nthat invoke procedures in remote objects. These remote procedure calls (RPCs) have the same components \nas a lo-cal procedure call: a distinguished object that is to per-form the call, zero or more arguments \nof arbitrary (includ-ing reference) type, arid am optional result of arbitrary type. The result is delivered \nto the caller synchronously; in other words, the caller blocks for the duration of the procedure call. \nEncoding an argument or result for inclusion in a IIES-sage is called marshaling; decoding by the message \nrecipient is called unrnarslialing. When an argument or result of an RPC has a reference type (i.e. it \nrefers to an object) then this reference can serve for further RPCs from the recipieut of the reference \nback to the argument/result object. The object is also protected from garbage collection while it remains \nreachable; i.e. until the last (local or remote) reference to it is deleted. III the following sections \nwe will write naruex(A) to indi-cate a variable called nume located OIL space X that contains information \nabout object A. We will write u is immused to b to mean the variable u is set to the maximuui of variable \nu and variable b. is received by X, a field of ~tubx(R) called stubstamp is increased tu the time-stamp \nof the message. For h&#38;x(R), Figure 1: A reference from A in space X to B in space Y. 2.1 Remote \nreferences Marshaled references to local or remote objects are sent in messages to be used in remote \ncomputations (e.g. for remote invocation). Such a reference R from object A in space X to object B in \nspace Y is represented by two objects: stubx(R) and sciorly (R). These are represented concretely by: \n. a local pointer in X from A to st,ubx(R); and l a local pointer in Y from scriorw(R) to B. A scion \ncorresponds to an incoming reference, and is treated as a root during local garbage collection. An object \nhaving one or more incoming references from remote spaces is therefore considered live by the local garbage \ncollector, even in the absence of any local reference to that object. The stub is a local proxy for some \nremote object. It contains the location of its associated matching scion. Each scion has at most one \nmatching stub, and each stub has exactly one matching scion. If several spaces contain stubs referring \nto some object B, then each will have a unique matching scion in B s space: one scion for each stub. \nA reference R is created by space Y and exported to some other space X as follows. First a new scion \nS&#38;W(R) is created and marshaled into a message. The marshaled representation encodes the location \nof ~iony (R) relative to X. The message is then sent to to X, where the location is unrnarshaled to create \nstubx (R). 3 Stub-Scion Pair Chains The SSPC system [13] is a mechanism for distributed refer-ence tracking \nsimilar to Network Objects [I] and supporting acyclic distributed garbage collection. It differs from \nNet-work Objects in several important respects, such as: a re-duction of the number of messages required \nfor sending a reference, lower latencies, fault-tolerance, and support for object migration. However, \nwe will only describe here the part needed to understand its garbage collector. The garbage collector \nis based on reference listing (an extension of reference counting that is better suited to un-reliable \ncommunications), with time-stamps on messages to avoid race conditions. The following explanation is \nbased on the example shown in Figure 1. This simple example is easily generalizable to situations having \nmore references and spaces. Each message is stamped by its sender with a IIIOIIO-tonically increasing \ntime. When a message containing R is sent by Y to X, the time-stamp of the message is stored in ycior~y \n(R) in a field called scionstamp. When the message stubstamp contains the time-stamp of the most recent \nmes-sage containinrr R that was received from Y. Similar1.y for ---0 ycior~y(R), scionstamp is the time-stamp \nof the last mes-sage containing R that was sent to X. When object A becomes unreachable, ~tiubx(R) is \ncol- lected by the local garbage collector of space X. When sWx(R) is finalized, a value called thresholdx[Y] \nis in-crsused to the stubstamp field of X. thresholdx[Y] there-fore contains the time-stamp of the last \nmessage received from Y that contained a reference to an object whose stub has since been reclaimed by \nthe local garbage collector. After each garbage collection in space X, a message LIVE is sent to all \nthe spaces in the immediate vicinity. The immediate vicinity of space X is the set of spaces that have \nstubs and scions whose associated scions and stubs are in X. The LIVE message sent to space Y contains \nthe names of all the scions in Y that are still reachable from stubs in X. The value of thresholdx[Y] \nis also sent in the LIVE message to Y. This value allows space Y to determine the most recent message \nthat had been received by X from Y at the time the LIVE message was sent. Space Y extracts the list of \nscion names on receipt of the LIVE message. This list is compared to the list of existing scions in Y \nwhose matching stubs are located in X. Any existing scions that are not mentioned in the list are now \nknown to be unreachable from X, and are called suspect. A suspect scion can be deleted, y77Jvided there \nis no danger that a reference to it is currently i71 tw7bsit between X arid Y. To prevent an incorrect \ndeletion of a suspect scion, the scionstamp field of suspect scions is compared to the thresholdx [Y] \ncontained in the LIVE message. If thresholdx[Y] > scionstamp(scicrrcy(R)) then some stub referred to \nby a message sent after the last one containing R has been collected. This implies that the last message \ncontaining R was received be:fors the LIVE was sent, and so any stub created for R from this message \nmust no longer exist in space X. The suspect scion can therefore be deleted safely. To prevent out-of-order \nmessages from violating this last condition, any messages from Y marked with a time-stamp smaller than \nthe current value of thresholdx[Y] are re-fused by space X. (thresholdx[Y] must therefore be ini-tialized \nwith a time-stamp smaller than the time-stamp of the first messages to be received.) This mechanism is \ncalled threshold-filtering. The LIVE messaee can be extended by a missing time-stamps field, to inform \nthe space Y of the time-stamps which are smaller than thresholdx[Y] and which have not been received \nin a message yet. Y then has the possibility of re-sending the corresponding messages using a new time-stamp \nand newly-created scions, since older messages will be refused by the threshold-filtering. The above \nalgorithm does not prevent premature dele-tion of scions contained in messages that are delayed in trun-sit. \nThese deletions are however safe, since such delayed messages will be refused by the threshold-filtering. \nThis situation can occur o111y if a more recent message arrives before some other delayed message, und \nthe more recent message causes the creation of stubs that are sub-sequently deleted by a local garbage \ncollection before the arrival of the delayed message. This can not happen with FIFO cornrnuuications \n(such as TCP/IP). Moreover, thresholc A-recent remote trace duriug which the scion s chain was fourid \nfilteririg of delayed messages is uot problematical for applica- tious usiug uureliable corrmuuicatious \n(such as UDP), siuce these applications should be designed to fuuctiou correctly eveu in the presence \nof message loss. Threshold-filtering aud message loss due to faulty corrmuuicatiou are iudistiuguish- \nable to the applicatiou. The above distributed garbage collectiou mechanism is fuult-tolerwbt. Uureliable \ncouimuuicatious can not create darigling poiuters, aud scious are uever deleted in the case of crashed \nspaces that coutaiu matching stubs (which suy-ports extensions for handling crash recovery). Moreover, \nit is sculuble because each space orily sends amd receives uies-sages in its immediate viciuity, arid \nusyndrrwnous because local garbage collectious in each space are allowed at ariy time with 110 need to \nsynchronize with other spaces. However, the mechauisrn is riot complete. Distributed cycles will uever \nbe deleted because of the use of refererice- listing. The remainder of this paper preseuts our coutri- \nbutiou: au algorithni to detect arid cut distributed cycles, rerideriug the SSPC garbage collector complete. \n4 Detection of free distributed cycles The detector of free distributed cycles is au exteusiou to the \nSSPC garbage collector. Spaces may elect to use the acvclic SSPC GC without the detector exteusiom le.e. \nfor I \\ scalability reasous). Spaces that choose to be irivolved in the detectiou of cycles are called \nyarticipatiug spaces; other spaces are called mou-participatiug spaces. Our detector will only detect \ncycles that lie eutirely withiu a set of participat- iug spaces. 4.1 Overview The algorithm is based \nou date propagatiou aloug chains of remote poiuters. The useful property of this propagatiou is that \nreachable stubs receive iucreasiug dates, whereas u11-reachable stubs (belougiug to a distributed cycle) \nare eveu-tually marked with coustaut dates. A threshold date is coruputed by a central server. Stubs \nmarked with dates iuferior to this threshold are krowu to have coustaut dates, and are therefore unreachable. \nEach participatiug space serids the ruinimurri local date that it wishes to protect to the central server \n(stubs with these dates should uot be collected). This iuformatiou is based riot only 011 the dates marked \nomlocalstubs, but also OIL the old dates propagated to outgoiug refereuces. The algorithm is asyuchrouous \n(most values are COIII-puted conservatively), toleraut to unreliable coxumuuicatious (using old values \nin coruputatious is always safe, siuce most trausrriitted values are rriouotouically increasing) aud \nbeuigu to the uorrnal SSPC garbage collector (uou-participating spaces cau work with au overlapyiug cluster \nof participatiug spaces, eveu if they do riot take part iu cycle detection). 4.2 Data structures and \nmessages Stubs are exteuded with a time-stamp called stubdate. This is the time of the most receut trace \n(possibly 011 a rerrlote site) duriug which the stub s chain was fourid to be rooted. Stubs have a secoud \ntime-stamp, called olddate, which is the value of stubdate for the previous trace. Scious are extended \nwith a time-stamp called sciondate. This is a copy of the most receutly propagated stubdate from the \nsciou s matching stub-i.e. the time of the most to be rooted. The stubdates fro111 a space are propagated \nto their matching scious in some other space by seuding a STUBDATES message. STUBDATES 111essages are \nstaqxd with the tinle of the trace that geuerated them Each site has a vector, called cyclicthreshold, \ncoutaiuing the time-stamp of the last STUBDATES Iuessage received from each renlote space. The cyclicthreshold \nvalue for a remote space is periodi- cally propagated back to that space by sending it a THRESH- OLD \nmessage. The eruissiou of THRESHOLD Irlessages can be delayed by saviug the cyclicthreshold values for \na giveu time in a set called CyclicThresholdToSend uutil a partic- ular event. Each site cau protect \noutgoing references from remote garbage collection. For this, it computes a time called lo-calmin, which \nis sent iu a LOCALMIN message to a dedicated site, the Detwtion Serve7; where the niiuimuru localmin \nof all spaces is ulaintaiued in a variable called globalmin. LO-CALMIN messages are ackuowledged by the \nDetection Server by seudiug back ACK messages. Fiually, to compute localmin, each site maimtains a per- \nspace value, called ProtectNow, coutainimg the uew dates to be protected at uext local garbage collectiou. \nThese values are saved iu a per-space table, called Protected Set, to be re-used and thus protected for \nsome other local garbage collectious.  4.3 The algorithm A Lamport clock is used to simulate global \ntime at each participating space. 4.3.1 Local propagation The curreut date of the Lamport clock is \niucremeuted before each local garbage collection aud used to mark local roots. Each scion s sciondate \nis marked with a date received from its matching stub. These dates are propagated from the local roots \naud scioms to the stubdate field of all reachable stubs during the mark phase of garbage collectiou. \nIf a stub is reachable from differeut roots marked with differert dates then it is marked with the largest \ndate. Such propagatiou is easy to imylerneut, with miuor modi-ficatious to a traciug garbage collector. \nThe scions are sorted by dec7eusiny sciondate, ad the Object IIleIIlory traced from each sciou iu turn. \nDuring the trace, the stubdate for any visited un7fbufked stub is increased to the sciondate of the scion \nfrom which the trace began. 4.3.2 Remote propagation A Irlodified LIVE message, called STUBDATES, is \nsent to all participatiug spaces ii the vicimity after a local garbage col-lectiorl. This message serves \nto propagate the dates from all stubs to their IIlatctlirlg scions. These dates will be yropa-gated (locally, \nfrom scious to stubs) by the receiving space at uext local garbage collection in that space. A Lamport \nclock is implemented by sending the current date in all messages. (In our case, only those messages used \nfor the detection of free cycles are concerned). When such a message is received, the current local date \nis increased to be strictly greater then the date in the message. increment current-date; FIFOmdd(cyclicthresholdtosend-set. \n(current-datecyclic-threshold[])); Markfrom~oot(local-roots,current-date); V scion E sorted-scions,{ \nif scionscion-date < globalmin then scion.pointer := NULL; else if scionscion-date = NOW then Mark-from-root(scion.pointer,current-date); \nelse Mark-from-root(scion.pointer,scion.scion-date); 1 V space E spaces, { V stub E space.stubs, { if \nstub.stubdate > stub.olddate then decrease protect-now[space] to stub.olddate; stub.olddate := stubstub-date:} \nFIFOadd(protected-set[space], (protect-now[space],current-date)); protect-now[space] := current-date; \nSend(space,STUBDATES,current-date, {V stub E space.stubs, (stub.stub-id,stub.stubxlate)}); icafmin := \nmin(protected-set[]) Send(server,LOCALMIN,current-date,localmin); Figure 2: Pseudo-code for a local garbage \ncollec-tion. The Protected Sets and Cyclicthreshold-T&#38;end Set are implemented by FIFO queues with \nthree functions (add, head and remove).  4.3.3 Characterisation of free cycles Local roots are marked \nwith the current date, which is al- ways increasing. Reachable stubs are therefore marked with increasing \ndates. On the other hand, the dates on stubs in-cluded in unreachable cycles evolve iu two different \nphases. In the first phase, the largest date on the cycle is propagated to every stub in the cycle. In \nthe second phase, no new date can reach the cycle from a local root, and therefore the dates on the stubs \nin the cycle will remain constaut forever. Since uureacliable stubs have constant dates, whereas reachable \nstubs have increasing dates, it is possible to com-pute au increasiug threshold date called globalmin. \nReacb-able stubs and scious are always marked with dates larger than globalmin. On the other baud, globalmin \nwill even-tually become greater than the date of the stubs belonging to a given cycle. Scions whose dates \nare smaller tham the current glob-almin are not traced during a local garbage collection. Stubs which \nwere only reachable from these scions will therefore be collected. The normal acyclic SSPC garbage collector \nwill then remove their associated scions, and eventually the entire cycle. 4.3.4 Computation of globalmin \nglobalmin is computed by a dedicated space (the Detection Server) as the miriimum of the localmin values \nsent to it by each participating space. The central server always COIII- aglobalmin could be computed \nwith R lazy distributed consensus. However, a central server is easier to implement (it CRII simply be \nReceive(space,STUBDATES, gc-date ,stub-set, threshold) = increase cyclicthreshold[space] to gc-date; \noldJcionret := space.scions; spacescions := (}; V scion E old-scion-set, { find(scion.scion-id,stubset, \nfound, stub-date); if found or scionscionstamp > threshold then { if scionscionstamp < threshold then \nincrease scion.scion-date to stub-date; spacescions := space.scions U {scion} Figure 3: Pseudo-code \nfor the STUBDATES handler. The find function looks for a scion identifier in the set of stubs received \nin the message. If the stub is found in the set then found is set to true, and stub_date is set to the \ndate on the associated stub. If the scionstamp is greater than the threshold in the message then the \nscion is kept alive and its date is not set. Receive(space,LOCALMIN,gcdate,localmin) = if gcdate>threshold-date[space] \nthen { increase threshold-date[space] to current-date; localmin[space]:=localmin; globalmin:= min(localmin[]); \nSend(space,ACK,gc-date,globalmin); 1 Figure 4: Pseudo-code for the Detection Server. The message is treated \nonly if garbage collection date is the lattest date received from the space. putes globalmin from the \nmost recently received v&#38;e of localmin sent to it from each space. (See the pseudo-code in Figure \n4.) 4.3.5 Computation of localmin localmin is recomputed after each local garbage collection in a given \nparticipating space. (The pseudo-code is shown in Figure 2.) We now introduce the notiom of a prdubly-reudhuble \nstub. A stub is probably-reachable either when it has been used by the mutator for a remote operation \n(such as an invocation) since the last local garbage collection, or when its stubdate is increased during \nthe local trace. This uotion is neither a lower uor au upper approxima-tion of reachability. A stub might \nbe both reachable and not probably-reachable at the same time; it might also be probably-reachable and \nriot reachable at some other time. However, on any reachable cbairt of remote refereuces there is at \nleast oue probably-reachable stub for each different date OII the chain. Therefore, since each space \nwill protect the date of its probably-reachable stubs, all dates 011 the chain will be protected . To \ndetect probably-reachable stubs after the local trace, the previous stubdate of each stub (stored the \nolddate one of t.he participating spaces), and local networks (where such R collector is most useful) \noften have (I centralized structure. 15.5 Receive(server,ACK,gcAate,globalmin) = Receive(space,THRESHOLD,cyckthreshold) \n= FIFOhead(cyclicthresholdtosend-set, (datexyclic-thresholds-toJend[])); if date 5 gc-date then { repeat \n{ FIFO~emove(cyclicthresholdtosend~et, (date,cyclic-thresholds-toJend[])); } until (date == gcdate); \nV snace E soaces. { Send(sp&#38;e,THfiESHOLD, cyclic-thresholds-tosend[space]); Figure 5: Pseudo-code \nfor the ACK message handler. Old values in the CyclicthresholdToSend Set can be discarded, since they \nare smaller than those which will be sent in the THRESHOLD messages. Their cor-responding ProtectNow \nvalues in the PGotscted Sets will therefore also be removed when the THRESHOLD messages is received. \n field), is compared to the newly-propagated stubdate. For each participating space in the immediate \nvicinity, a date (called ProtectNow) contains the minimum olddate of all stubs which have been detected \nas probably-reachable since the last local garbage collection. The value of ProtectNow for each space \nis saved in a per-space set, called Protected Set, after each garbage col-lection. ProtectNow is then \nre-initialized to the current date. The localmin for the space is then computed as the min-imum of all \nProtectNow values in all the Protected Sets. This new value of localmin is sent to the detection server \ni11 a LOCALMIN message. The next value of globalmin will be smaller than these olddates. All olddates \nassociated with stubs that were de-tected probably-reachable since some of the latest garbage collections \nwill therefore be protected by the new value of globalmin: stubs and scions marked with those dates will \nnot he collected. globalmin must protect the olddates rather than the stubdates. This is because the \nscions associated with probably-reachable stubs must be protected against collection, and these scions \nare marked with the olddate of their match-ing stub. III fact globalmin not only protects the associ-ated \nscions, but also all references that are reachable from probably-reachable stubs and which are marked \nwith the olddates of these stubs. 4.3.6 Reduction of the Protected Set STUBDATES and LOCALMIN messages \nboth contain the date of the local garbage collection during which they were sent. When a STUBDATES message \nis received (see Figure 3), the per-space threshold CyclicThreshold is increased to the GC date contained \nin the message. The CyclicThreshold for each participating space is saved in the CyclicThresh-oldToSend \nSet before each local garbage collection. Each LOCALMIN message received by the Detection Server is acknowledged \nby a ACK message containing the same GC date. When this ACK message is received (see Figure 3The slightly \ncryptic phrase some of the latest garbage collec. tions will be explained in full in the next section. \nFIFO-head(protected-set[space], (protect-nowgcdate)); while (gcdate 5 cyclic-threshold) { FIFO-remove(protected-set[space], \n(protect-now, gcdate)); FIFO-head(protected-set[space], (protect-now, gcdate)); 1 Figure 6: Pseudo-code \nfor the THRESHOLD handler. 5) , the CyclicThresholds saved in the CyclicThreshold-ToSend Set for the \nlocal garbage collection started at the GC date of the ACK message are sent to their associated space \nin THRESHOLD messages. Older values (for older lo-cal garbage collections) in the CyclicThresholdToSend \nSet are discarded (This is perfectly safe. When a space receives a THRESHOLD messaee it will uerform \nall of the actions that should have been peyformed &#38;r any previous THRESHOLD messages that were lost). \nWhen a CyclicThreshold date is received in a THRESH-OLD message, all older ProtectNow values in the Protected \nSet associated with the sending space are removed. (See Figure 6.) These values will no longer participate \nin the computation of globalmin. We can now explain the cryptic phrase some of the lat-est garbage collections \nthat appeared in the previous sec-tion. The olddate OIL a probably-reachable stub is protected by a ProtectNow \nin a Protected Set. It will continue to be protected for a certain time, until several events have oc-curred. \nThe new stubdate must first be sent to the match-ing scion in a STUBDATES message. From there it is prop-agated \nfrom by a local trace to any outgoing stubs (new probably-reachable stubs in that space will be detected \ndur-ing this trace). The new localmin for that must then be received and used by the detection server \n(ensuring that the olddates 011 the newly detected probably-reachable stubs are protected by next values \nof globalmin). After this, the ACK message received from the detection server will trigger a THRESHOLD \nmessage containing a Cyclicthreshold equal to the GC date of the STUBDATES message (or greater if other \nSTUBDATES ~nessages have been received before the local garbage collection). Only after this THRESHOLD \nmes-sage is received will the the Protectlou be removed from its Protected Set.  4.4 Example Figures \n7, 8 and 9 show a simple example of distributed detection of free cycles. Spaces A and B are participating \nspaces; space C is the detection server. The system contains two distributed cy-Cks c( 1) aId c(2), each \nCOIltaiIliIlg two objects: OA(1) and o,(l) for C(I), oA(2) aId o,(2) for C(2). c(I) is 1Ocally reachable \nin A, whereas C(2) has been unreachable since date 2. A local garbage collection in A at date 6 has prop-agated \nthis date to ~t~ba(l), which was previously marked with date 2. The Protected Set associated with B contains \na single entry: a ProtectNow 2 at date 6. III figure 7, a local garbage collection occurs in B at date \n8. The date 6, marked on ~ci~~un~(l), is propagated to ~t*ub~(l) which was previously marked with 2. \nB saves the gc-date . . . . . . . . . . . . . . . . . . . ~-I . . . . . . dates (A,ST\"BDATES,t8,{6,2>) \ncurrent date = 6 current date = 8 (A,THRESHOLD,6) + &#38;........\"\" Protected = {(space = A;GCdate =6; \n= 8; protectNow = 2)) = 211 Figure 7: After a local garbage collection at date 8 on 5pace B, the new \nlocalmin 2 is sent to the detection server C. After the acknowledgment, the cyclic threshold 6 message \nis sent to A, which will remove this entry from its protected set. new ProtectNow 2 associated with A \nin its Protected Set. It theu sends a STUBDATES message with the new stub-dates to A, and a LOCALMIN \nmessage with its new localmin 2 to the detection server. After saving this new localmin, the detection \nserver sends an ACK message to J3 containing the same date as the original LOCALMIN message. A glob- \nalmin value (possibly uot up-to-date) cam be piggybacked on this message. After reception of this ACK \nmessage, B serlds a THRESHOLD message to A coutaiuiug the date of the last STUBDATES rnessage received \nfrom A. A conse- quently removes the associated ProtectNow entry from its protected set, which is uow \nempty. III figure 8, a local garbage collectiou occurs in A at date 16. The curreut date 10 is propagated \nto ~tuba(l), previ-ously marked with 6. The ProtectNow associated with B is therefore decreased to 6. \nytub~((2) doe.5 not participate in the computation of ProtectNow, since is still marked with 2. This \nProtectNow is t&#38;err saved in the Protected Set, arld the new localmin (6) is sent to the detection \nserver. After the reception of the ACK ulessage from C, a THRESHOLD message is sent ot B which removes \nthe associated entry from its Protected Set. However, its localmin on the de-tection server is still \neyual to 2, thus, preventing globalain from iucreasing. In figure 9, a local garbage collectiou occurs \nin B at date 12. The new localtin computed in J3 is equal to 6. The new globalmin is therefore iucreased \nto 6. All scions marked with smaller dates will riot be traced, starting from the IIIO-ment that A and \nB receive this new value of globalrnin. ComqueIitly YkmA (2) ad YchfLB (2) will IlOt be traced iI subsequent \ngarbage collections, and Oa(2), O,(2), &#38;,&#38;s(Z) ad st UbA(2)Will be coh?cted by local garbage \nCOllectiOIlS. At the Same time, y&#38;Or~A (2) aId yckm~ (2) will be collected by the SSPC garbage collector \nwhen STUBDATES messages that d0 IlOt COIltaiIl YihbB(2) aIld YtiUbA(2) are received by A and B respectively. \nThe cycle C(2) has now beer1 entirely collected. 5 Related issues 5.1 New remote references and non-participating \nspaces When a uew remote refereuce is created, the stub olddate is set to the current date and the sciondate \nis iuitialiaed with a special date called NOW. Moreover, each time a scion location is resent to its \nassociated space, a new stub may be created if the previous oue had already beem collected. sciondate \nis therefore re-initialized to NOW each time its scion s location is resent in a message. Scions marked \nwith NOW propagate the current date at each garbage collection. A newly-created scion therefore behaves \nas a normal local root, until a new date is prop-agated by a STUBDATES message fro111 its matching stub. \nThe SSPC threshold is then compared to the scionstamp to eusure that all messages coutaiuiug the sciou \nhave been received before fixing the sciondate. This mechanism is also used to allow incomiug refer-ences \nfrom uou-participating spaces. (STUBDATES IIW-sages will never be received from non-participating spaces.) \nThe sciondates of their associated scions will therefore re-main at NOW forever, and they will act as \nlocal roots. Dis-tributed cycles that include these remote references will never be collected. This is \nsafe, aud does uot impact the complete- lie55 of the algorithm for participating spaces. We must also \ncope with outgoing refereuces to non-parti- cipating spaces. We must avoid putting entries in the Pro- \n(B,STUBDATES,10,(10,2~) current date = 10 current date = 8 b '.'.'.'.~.~.'.'. '. ::;: 'C.'.' 6 -p? 6 \nB Protected = { (space GC date protectNow Figure (B,THRESHOLD,8) t .*... . . . . . ..* ) = B; = 10; \n(A,ACK,lO,Z) = 6)) \\2\\ \",LOCALMIN,lO,'~~~~~ Protected = ( (space = A; GC date 8: protectNow 1 2)) 8: \nAfter a new local garbage collection in A, lOCalninA is increased to 6. tected Sets for non-participatingspaces,since \nnoTHRESH-OLD messages will he received to remove such entries. (This would prevent localmin and hence \nglobalmin from increas-ing, thus stalling the detection process.) A space must there-fore only send STUBDATES \nmessages to, and create entries in the protected sets for, known participating spaces. The list of participating \nspaces is maintained by the detection server, and is sent to other participating spaces whenever necessary \n(when new participating space arrives, when a space quits the detection process, or if a space is suspected \nof having crashed or is being too slow to respond). 5.2 Coping with mutator activity The mutator can \ncreate and delete remote references in the interval between local garbage collections. Dates on a remotely-reachable \nobject might therfore never increase be-cause of a phantom reference : each time a local garbage collection \noccurs in a space from which the object is reach- able, the rnutator gives the reference on the object \nto an-other space and deletes the local reference -just before the collection. Greater dates might therefore \nnever be propa-gated to the object and the object would be detected as a free cycle, whereas it is still \nreachable (see Figure 10 for an example). Such transient references may move from stubs to scions (for \ninvocation) or from scions to stubs (by reference pass-ing). In the first case, we mark the invoked scions \nwith the current date (This prevents globalmin from stalling). In the second case, we ensure that each \ntime a stub is used by the mutator (for invocation, or copy to/from another space) its olddate is used \nto increase the ProtectNow associated with the space of its matching scion. The date of the ProtectNow \ntherefore always contains the minimum olddate of all the stubs that have been used in the interval between \ntwo local current date = 2 current date = 5 1ocalmin = 2 localmin = 5 Figure 10: With its local reference \nto Or, A invokes stub1 which creates a new local reference in B to 02. A deletes its local reference \nRI, and performs a new local garbage collection. alvbr is therefore re-marked with 2, and local!rIinA \nis increased to 5. This is incorrect, since the cycle is reachable from B. This is the reason why the \nexternal mutator activity must be monitored by the detector of free cycles. garbage collections. This \nprotects any object reachable from these stubs against such transient phantom references . 5.3 Fault \ntolerance Our algorithm is tolerant to message loss and out-oforder delivery. The STUBDATES, THRESHOLD, \nLOCALMIN and ACK rressages are only accepted if their sates are greater than those of the previously \nreceived such message. More-over, the computations are always conservative when using old values. Even \nLOCALMIN messages may he lost: no ACK messages will be sent and therefore no THRESHOLD will be (A,STUBDATES,12.(10,2~) \ncurrent date = 10 current date = 3 (A,THRESHOLD,lO) Protected = ( Protected = ( (space = B; (space \n= A; GC date = 10; GC date = 12; protectNow = 6)) (B,ACK,12,6) protectNow = 6)) C globalmin = 6 \") (C.LOCALMIN.12.6) \nI localmins: A -> 6 B -> 6 I Figure 9: After a new local garbage collection in B, localmin~ is set to \n6, and globalmin is increased to 6. Thus, the free cycle marked with 2 will be collected since its date \nis now smaller than globalmin. to other spaces, which will continue to protect the dates that one STUBDATES \nmessage awl one THRESHOLD message the lost LOCALMIN messages would have protected. sent for each space \nin the immediate vicinity. The first two Crashed spaces (or spaces that are too slow to respond) messages \ncan be concatenated into a single network message. are handled by the detection server, which can exclude \nany Hence there are only two messages sent for each space in the suspected space from the detection process \nby sending a spe- vicinity. The STUBDATES message contains one ideutil?er cial message to all participating \nspaces. The participating and one date for each live stub referring to the destination spaces set the \nsciondates for scions whose matching stubs space, plus the SSPC threshold time-stamp. The THRESH-are \nin the suspect space(s) to NOW, and remove all entries for OLD message contains only the CyclicThreshold \nvalue for the suspected spaces in their Protected Sets. the destination space. Finally, the detection \nserver may also crash. This does One LOCALMIN wessage is also sent to the detection not stop acyclic \ngarbage collection, and only deluya cyclic server, and one ACK message sent back from the server. garbage \ncollection. A detection server can be restarted, and The Protected Set contains triples for each space \nin the dynamically rebuild the list of participating spaces through vicinity. For a space X in the vicinity \nof Y, the number some special recovery protocol. It then waits for each par-of triples for X in the Protected \nSet of Y is equal to the ticipating space to send a new localmin value before corn-number of local garbage \ncollections that have occurred on Y puting a new up-to-date value for globalmin. since the last garbage \ncollection 011 X. If the frequencies of the garbage collections in the different participating spaces \nare similar, the Protected Set should not grow too much. Analysis If one space requires too many garbage \ncollections, and its We can estimate the worst-case time needed to collect a Protected Set becomes too \nlarge, it should avoid perform-newly unreachable cycle. It is the time needed to propagate ing cyclic \ndetection after each garbage collection (but not dates greater than those on the cycle to all reachable \nstubs. stop garbage collections) until sufficient entries in its Pro-Assuming that spaces perform local \ngarbage collections at tected Set have been removed. approximately the same rate, we define a period \nto be the Finally, a very large number of spaces may use the same time necessary for spaces to perform \na new local garbage detection server. The server only contains two dates per collection. The time needed \nto collect the cycle is equal to participating space, and the computation of the minimum the product \nof the length of the largest chain of reachable of this array should not be expensive. references by \nthe period: 7 Implementation Our algorithm has been incorporated into an implernenta-We can also estimate \nthe number and the size of the mes- tion of the SSP Chains system written in Objective-CAMLsages that \nare sent after a local garbage collection. There is [S], using Unix Thread [6]. the and nlodules one \nLIVE message (sent by the SSPC garbage collector), plus The Objective-Can11 irrlplementatioIl of SSPC \nconsists of 1300 lines of code, of which 200 are associated with the cyclic GC algorithIu. The propagation \nof dates by tracing was iulplerrleated as a rrlinor Irlodification to the existing CarIll garbage collector \n[2]. The Harkfromroot (roots) fuuc- tioa was changed into Hark-fromroot (roots ,date), which ruarks stubs \nreachable froru a set of roots with the giveu date. This function is then applied first to the norulal \nlocal roots with the current date (which is always greater than all the dates on scions), and then to \nsets of scions sorted by decreasing dates. Each reachable stub is therefore only Inarked once, with the \ndate of the first root froul which it is reachable. Finalization of stubs (required for updating the \nthresh- old when they are collected) is irrlplernented by using a list of pairs. Each pair contains a \nweak poiater to a stub and a stubstamp field. After a garbage collection, the weak point- ers are tested \nto deterrrlirie if their referent objects are still live. The stubstamp field is used to update the threshold \nif the weak pointer is found to be dangling. The Protected Set is iIupleruented as a FIFO queue for each \nparticipating space. The head of the queue contains the ProtectNow value, which can be Irlodified by \nthe Irlutator between local rrarbalre collections. When a THRESHOLD Iriessage is receked, entries are \nreuloved frorrl the tail of the queue until the last entry has a date greater than the one in the rnessage. \nFinally, localmin is corrlputed as the rrlinixnuru of all eritries in all queues. Objective-CAML has \nhigh-level capabilities to autonlat-ically Iuarshal and unmarslial syulbolic ~mssages, easing the iruplerrierrtatiom \nof corriplex protocols. Sonic rnodificatiou of the conipiler and the standard object library was needed \nto enable dynaniic creation of classes of stubs and dyaaniic type verification for SSPC. However, these \nrrlodifications are not related to either the acyclic GC or the cycle detector al-goritlirn. 8 Related \nwork 8.1 Hughes algorithm Our algorithm was inspired Hughes algorithm. In Hughes algorithm, each local \ngarbage collection provokes a global trace and propagates the starting date of the trace. How- ever, \nthe threshold date is conlputed by a terniination al- goritlnl (due to Rana Ill]). The date OIL a stub \ntherefore represents the starting date of the niost recent global trace in which the stub was detected \nas reachable. If the tliresli- old is the starting date of a terrrliaated global trace, then any stub \nInarked with a strictly srrlaller date has rot been detected as reachable by this terruinated global \ntrace. It can therefore be collected safely. However, the termination algorithm used in this algo-rithIn \nrequires a global clock, instantaneous coIrlrnunication, and does not support failures. Moreover, each \nlocal garbage collection in one space triggers new coniputations in all of the participating spaces. \nSuch behavior is not suitable for a large-scale fault-tolerant systerri.  8.2 Recent work Detecting \nfree cycles has been addressed by several researchers. A good survey can be found iI1 [lo]. We will only \npresent more recent work below. All three of the recent algorithms are based 011 partition- ingintogroups \nof spaces or nodes. Cycles are only collected when they are included entirely within a single partition. \nHeuristics are used to irnyrove the partitioning. These al- goritlirns are complex, and nlay be difficult \nto iuiplenlent. Moreover, their efficiency depends greatly on the choice of heuristic for selecting suspect \nobjects . Maheslnvari and Liskov s [7] work is based OIL back-tracing. The group is traced in the opposite \ndirection to references, starting fro111 objects that are suspected to belong to an unreachable cycle. \nAn heuristic based on distance selects suspected objects . If the backward trace does not em- counter \na local root, the object is on a free cycle. Their detector is asyaclironous, fault-tolerant, and well-adapted \nto large-scale systems. Nevertheless, back-tracing requires extra data structures for each reruote reference. \nFurtlier- rnore, every suspected cycle needs one trace, whereas our algoritliui collects all cycles concurrently. \nRodrigues and Jones s (121 cyclic garbage collector was inspired by Lang et al.[4], dividing the network \ninto groups of processes. The algoritllul collects cycles of garbage COII-tained entirely within a group. \nThe Iuaiu irrlproverrlerlt is that only suspect objects (according to an heuristics such as Maheshwari \nand Liskov s distance) are traced. Global synchronization is needed to terrrlinate the detection. It \nis difficult to know how the algorithm behaves when the group becomes very large. The DMOS garbage collector \n[9] lras sorue desirable proy-erties: safety, conipleteness, non-disruptiveness, increnlem-tality, and \nscalability. Spaces are divided into a nurrlber of disjoint blocks (called cars ). Cars froru different \nspaces are grouped together into traius. Reachable data is copied froni cars in one train to cars in \nother trains. Unreachable data arid cycles contained ia one car or one train are left behind and can \nbe collected. Conipleteness is guaranteed by the order of collections. This algorithm is highly COIII-plex \nand has not been iulpleu~emted. Moreover, problenls relating to fault-tolerance are riot addressed by \nthe authors. 9 Conclusion We have described a complete distributed garbage collector, created by extending \nan acyclic distributed garbage collector with a detector of distributed garbage cycles. Our garbage collector \nhas sonie desirable properties: asynchrony between participating spaces, fault-tolerance (niessages can \nbe lost, participating spaces and servers can crash), low resource requireuierits (Iuernory, ruessages \nand tinie), arid finally ease of iniplernentation. It seeuls well adapted to large-scale distributed \nsysterris since it supports non-participating spaces, arid consequently clusters of cyclically-collected \nspace5 within larger groups of interoperating spaces. We are currently working OIL a new irupleruerltatioa \nfor the Join-Calculus language. Future work includes the han-dling of overlapping sets of participating \nspaces, protocols for server recovery, arid perforniance rnesurenients. Acknowledgments The authors would \nlike to thank Neilze Dorta for her study of receat cyclic garbage collectors. We also thank Jean-Jacques \nLevy and Da&#38;en Doligez for their valuable COIII-rnents and suggestions 011 iulprovirig this paper. \n References Andrew Birrell, Greg Nelson, Sum11 Owicki, and Ed- 111 ward Wobber. Network objects. In \nPrvceedirrysof the 14th ACM Symposium ON Opwutirrg Systemv Prirrci-pies, pages 217-230, Asheville, NC \n(USA), December 1993. Daden Doligez and Xavier Leroy. A concurrent, gem- PI eratiorial garbage collector \nfor a multithreaded imyle-mentation of ML. In Prw. of the 2Uth Arrnuul ACM SIGPLAN-SIGACT Syrrrp. on \nPrinciple of Prvyrum-rnirry Larry., pages 113-123, Charleston SC (USA), Jan-uary 1993. CBdric Fournet, \nGeorges Gonthier, Jean-Jacques LBvy, Luc Maranget, and Didier R&#38;y. A calculus of mobile agents. 111LNCS, \nvolume 1119, 1996. 131 w Bernard Lang, Christiau Quei~mx, and Jose Piquer. Garbage collecting the world. \nIII Prvc. uf the 19th Arr-nuul ACM SIGPLAN-SIGACT Sywp. 07r P7irrciples of Pn+mmmircy Lung., Albuquerque, \nNew Mexico (USA), January 1992. X. Leroy. The objective-cad system software. Techi- [51 cal report, \nINRIA, 1996. Xavier Leroy. Unix system programming in card light. Technical Report No. 147, INRIA, Le \nChesnay, Sauce, 1993. 161 U. Maheslwari ad B. Liskov. Collectirlg distributed 171 garbage cycles by \nback tracing. In Prr nciples of Dis- tributed Cornputiny, 1997. Robin Miher, Joactiini Parrow, and David \nWalker. A I31 calculus of mobile processes I and II. I7bforrrrutiurr und Currbpututiun, 100:l -40 &#38; \n41 -77, September 1992. R.L. Hudson R. Morrison J. Eliot B. Moss D.S. Mumro. Garbage collecting the world: \nOne car at a the. 111 OOPSLA, Atlanta (U.S.A.), October 1997. David Plainfoss~ and Marc Shapiro. A survey \nof dis-tributed garbage collection techniques. In Prvc. Id. Workshop07r Memory kfurbu~errbent, Kinross \nScotland (UK), September 1995. S. P. F&#38;ma. A distributed solution to the distributed termination \nproblem. h~fvrrnutio7r P7wessi7rg Lettew, 1743-46, July 1983. Helena Rodrigues and Richard Jones. A cyclic \ndistributed garbage collector for network objects. III Workshop vrr Distributed Alyorithms (WDAG), Bologna \n(Italy), October 1996. Marc Shapiro, Peter Dickman, and David Plainfoss&#38; SSP chains: Robust, distributed \nreferences supporting acyclic garbage collection. Rapport de Recherche 1799, INRIA, Rocquencourt (France), \nNovember 1992.   \n\t\t\t", "proc_id": "277650", "abstract": "Most existing reference-based distributed object systems include some kind of acyclic garbage collection, but fail to provide acceptable collection of cyclic garbage. Those that do provide such GC currently suffer from one or more problems: synchronous operation, the need for expensive global consensus or termination algorithms, susceptibility to communication problems, or an algorithm that does not scale. We present a simple, complete, fault-tolerant, asynchronous extension to the (acyclic) cleanup protocol of the SSP Chains system. This extension is scalable, consumes few resources, and could easily be adapted to work in other reference-based distributed object systems---rendering them usable for very large-scale applications.", "authors": [{"name": "Fabrice Le Fessant", "author_profile_id": "81100431247", "affiliation": "INRIA Roquencourt, B.P. 105, 78153 Le Chesnay Cedex, France", "person_id": "PP40035905", "email_address": "", "orcid_id": ""}, {"name": "Ian Piumarta", "author_profile_id": "81100232407", "affiliation": "INRIA Roquencourt, B.P. 105, 78153 Le Chesnay Cedex, France", "person_id": "PP39033659", "email_address": "", "orcid_id": ""}, {"name": "Marc Shapiro", "author_profile_id": "81100431017", "affiliation": "INRIA Roquencourt, B.P. 105, 78153 Le Chesnay Cedex, France", "person_id": "PP39042494", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277715", "year": "1998", "article_id": "277715", "conference": "PLDI", "title": "An implementation of complete, asynchronous, distributed garbage collection", "url": "http://dl.acm.org/citation.cfm?id=277715"}