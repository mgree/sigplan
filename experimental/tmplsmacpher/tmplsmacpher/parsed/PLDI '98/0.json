{"article_publication_date": "05-01-1998", "fulltext": "\n Complete Removal of Redundant Expressions Rastislav Bodik Rajiv Gupta Mary Lou Soffa Dept. of Computer \nScience University of Pittsburgh Pittsburgh, PA 15260 {bodik,gupta,soffa}Pcs.pitt.edu Abstract Partial \nredundancy elimination (PRE), the most important component of global optimizers, generalizes the removal \nof common subexpressions and loop-invariant computations. Because existing PRE implementations are based \non code motion, they fail to completely remove the redundancies. In fact, we observed that 73% of loop-invariant \nstatements cannot be eliminated from loops by code motion alone. In dynamic terms, traditional PRE eliminates \nonly half of re- dundancies that are strictly partial. To achieve a complete PRE, control flow restructuring \nmust be applied. However, the resulting code duplication may cause code size explosion. This paper focuses \non achieving a complete PRE while incurring an acceptable code growth. First, we present an al- gorithm \nfor complete removal of partial redundancies, based on the integration of code motion and control flow \nrestruc-turing. In contrast to existing complete techniques, we re- sort to restructuring merely to remove \nobstacles to code mo- tion, rather than to carry out the actual optimization. Guiding the optimization \nwith a profile enables addi-tional code growth reduction through selecting those dupli- cations whose \ncost is justified by sufficient execution-time gains. The paper develops two methods for determining \nthe optimization benefit of restructuring a program region, one based on path-profiles and the other \non data-flow frequency analysis. Furthermore, the abstraction underlying the new PRE algorithm enables \na simple formulation of speculative code motion guaranteed to have positive dynamic improve-ments. Finally, \nwe show how to balance the three trans-formations (code motion, restructuring, and speculation) to achieve \na near-complete PRE with very little code growth. We also present algorithms for efficiently computing \ndy-namic benefits. In particular, using an elimination-style data-flow framework, we derive a demand-driven \nfrequency analyzer whose cost can be controlled by permitting a bounded degree of conservative imprecision \nin the solution. Keywords: partial redundancy elimination, control flow restructuring, speculative execution, \ndemand-driven fre-quency data-flow analysis, profile-guided optimization. Psrmiwion to make digital or \nhard copier of all or part 01 this work for psrronal or dassroom use is granted without 1.0 provided \nthat copies am not made or distributed for profit or commwcial advan- tage and that copies bear thii \nnotice and the full citation on 6~ first paw. To oopy othwivise, to republish. to post on Seders or to \nredistribute to lists, requires prior spedtic permi8don and/or a 190. BIGPLAN 96 Montreal, Canada 1 \nIntroduction Partial redundancy elimination (PRE) is a widely used and effective optimization aimed at \nremoving program state-ments that are redundant due to recomputing previously produced values [26]. PRE \nis attractive because by tar-geting statements that are redundant only along some ex-ecution paths, it \nsubsumes and generalizes two important value-reuse techniques: global common subexpression elimi-nation \nand loop-invariant code motion. Consequently, PRE serves as a unified value-reuse optimizer. Most PRE \nalgorithms employ code motion [ll, 12, 14, 15, 16, 17, 24, 261, a program transformation that reorders \ninstructions without changing the shape of the control flow graph. Unfortunately, code-motion alone fails \nto remove routine redundancies. In practice, one half of computa-tions that are strictly partially redundant \n(not redundant along some paths) are left unoptimized due to code-motion obstacles. In theory, even the \noptimal code-motion algo-rithm [24] breaks down on loop invariants in while-loops, unless supported by \nexplicit do-until conversion. Recently, Steffen demonstrated that control flow restructuring can re- \nmove from the program all redundant computations: includ-ing conditional branches [30]. While his property-oriented \nexpansion algorithm (Poe) is complete, it causes unneces-sary code duplication. As the first step towards \na complete PRE with afford-able code growth, this paper presents a new PRE algorithm based on the integration \nof code motion and control flow restructuring, which allows a complete removal of redun- dant expressions \nwhile minimizing code duplication. No prior work systematically treated combining the two trans-formations. \nWe control code duplication by restricting its scope to a code-motion preventing (CMP) region, which \nlo-calizes adverse effects of control flow on the desired value reuse. Whereas the Poe algorithm applied \nto expression elimination (denoted PoePRE) uses restructuring to carry out the entire transformation, \nwe apply the more economi-cal code-motion transformation to its full extent, resorting to restructuring \nmerely to enable the necessary code motion. The resulting code growth is provably not greater than that \nof PoePRE; on spec95, we found it to be three times smaller. Second, to answer the overriding question \nof how com-plete a feasible PRE algorithm is allowed to be, we move from theory to practice by considering \nprofile information. Using the dynamic amount of eliminated computations as the measure of optimization \nbenefit, we develop a profile- guided PRE algorithm that limits the code growth cost 8 ,966 ACM 0-89791-9674/96/0006...96.00 \nfor (1,) ( it (0) . . = o+di 01s. it (P) break; if (Q) . . 01s. R; 91 . . I a+bi -a+di duplicated lo \nmake [atb] fu//yredun&#38;nl ,... duplicated lo allow code motion of[atb] : duplicaled for complele optimization \nof [ctdj duplicated for partial optimization of[ctQ .: 1 1 c!- -I a) source program b) PoePRE of [a+b] \nc) our optimization of [a +b] d) our optimization of [c+d] e) tradeoff variant of d) Figure 1: Complete \nPRE through integration by sacrificing those value-reuse opportunities that are infre- quent but require \nsignificant duplication. Third, we describe how and when speculative code motion can be used instead \nof restructuring, and how to guarantee that speculative PRE is profitable. Finally, we demonstrate that \na near-complete PRE with very little code growth can be achieved by inte-grating the three PRE transformations: \npure code motion, restructuring, and speculative code motion. All algorithms in this paper rely in a \nspecific way on the notion of the CMP region which is used to reduce both code duplication and the program \nanalysis cost. Thus, we make the PRE optimization more usable not only by increas- ing its effectiveness \n(power) through cost-sensitive restruc-turing, but also by improving its efficiency (implementa-tion). \nWe develop compile-time techniques for determining the impact of restructuring a program region on the \ndy-namic amount of eliminated computations. The run-time benefit corresponds to the cumulative execution \nfrequency of control flow paths that will permit value reuse after the restructuring. We describe how \nthis benefit can be obtained either using edge profiles, path-profiles [7], or through data-flow frequency \nanalysis [27]. As another contribution, we reduce the cost of frequency analysis by presenting a frequency \nanalyzer derived from a new demand-driven data-flow analysis framework. Based on interval analysis, the \nframework enables formulation of an- alyzers whose time complexity is independent of the lattice size. \nThis is a requirement of frequency analysis whose lat- tice is of infinite-height. Due to this requirement, \nexisting demand frameworks are unable to produce a frequency an-alyzer [18, 22, 291. Furthermore, we \nintroduce the notion of approximate data-flow frequency information, which con-servatively underestimates \nthe meet-over-all-paths solution, keeping the imprecision within a given degree. Approxima-tion permits \nthe analyzer to avoid exploring program paths of code motion and control flow restructuring. guaranteed \nto provide insignificant contribution (frequency-wise) to the overall solution. Besides PRE, the demand-driven \napproximate frequency analysis is applicable in in-terprocedural branch correlation analysis [lo] and \ndynamic optimizations [5]. Let us illustrate our PRE algorithms on the loop in Fig- ure l(a). Assume \nno statement in the loop defines variables a, b, c, or d. Although the computations [a+b] and [c+d] are \nloop-invariant, removing them from the loop with code mo- tion is not possible. Consider first the optimization \nof [a+b]. This computation cannot be moved out of the loop because it would be executed on the path En, \n0, P, Ex, which does not execute [a + b] in the original program. Because this could slow down the program \nand create spurious excep-tions, PRE disallows such unsafe code motion [24]. The desired optimization \nis only possible if the CFG is restructured. The PoePRE algorithm [30] would produce the program in Figure \nl(b), which was created by duplicat- ing each node on which the value of [a+ b] was available only on \na subset of incoming paths. While [a + b] is fully opti-mized, the scope of restructuring is unnecessarily \nlarge. Our complete optimization (ComPRE) produces the program in Figure l(c), where code duplication \nis applied merely to en-able the necessary code motion. In this example, to move [a + b] out of the loop, \nit is sufficient to separate out the offending path En, 0, P, Ez which is encapsulated in the CMP region \nhighlighted in the figure. As no opportunities for value reuse remain, the resulting optimization of \n[a + b] is complete. Because restructuring may generate irreducible programs, as in Figure l(c), we also \npresent a restructuring transformation that maintains reducibility. Hoisting the loop invariant [a + \nb] out of the loop was prevented by the shape of control flow. Our experiments show that the problem \nof removing loop invariant code (LI) has not been sufficiently solved: a complete LI is prevented for \n73% of loop-invariant expressions. In some cases, a sim- ple transformation may help. For example, [a \n+ b] (but not [c + d]) can be optimized by peeling off one loop iteration and performing the traditional \nLI [l], producing the pro-gram Figure l(b). In while-loops, LI can often be enabled with more economical \ndo-until conversion. The example pre-sented does not allow this transformation because the loop exit \ndoes not post-dominate the loop entry. In effect, our restructuring PRE is always able to perform the \nsmallest necessary do-until conversion for an arbitrary loop. Next, we optimize the computation [c+d] \nin Figure I(c). Our optimization performs a complete PRE of [c + 6] by du- plicating the shaded CMP region \nand subsequently perform-ing the code motion (Figure l(d)). The resulting program may cause too much \ncode growth, depending on the sizes of duplicated basic blocks. Assume the size of block S out- weighs \nthe run-time gains of eliminating the upper [c + 4. In such a case, we select a smaller set of nodes \nto duplicate, as shown in Figure l(e). When only block Q is duplicated, the optimization is no longer \ncomplete; however, the op-timization cost measured as code growth is justified with the corresponding \nrun-time gain. In Section 3.2, speculative code motion is used to further reduce code duplication. In \nsummary, this paper makes the following contributions: We present an approach for integrating two widely \nused code transformation techniques, code motion and code restructuring. The result is an algorithm for \nPRE that is complete (i.e., it exploits all opportunities for value reuse) and minimizes the code growth \nnecessary to achieve the code motion. We show that restricting the algorithm to code motion produces \nthe traditional code-motion PRE [17, 241. Profile-guided techniques for limiting the code growth through \nintegration of selective duplication and specu- lative code motion are developed. We develop a demand-driven \nfrequency analyzer based on a new elimination data-flow analysis framework. The notion of approximate \ndata-flow information is de- lined and used to improve analyzer efficiency. Our experiments compare the \npower of code-motion PRE, speculative PRE, and complete PRE. Section 2 presents the complete PRE algorithm. \nSection 3 describes profile-guided versions of the algorithm and Sec-tion 4 presents the experiments. \nSection 5 develops the demand-driven frequency analyzer. The paper concludes with a discussion of related \nwork. 2 Complete PRE In this section, we develop an algorithm for complete re-moval of partial redundancies \n(ComPRE) based on the inte- gration of code motion and control flow restructuring. Code motion is the \nprimary transformation behind ComPRE. To reduce code growth, restructuring is used only to enable hoisting \nthrough regions that prevent the necessary code motion. The smallest set of motion-blocking nodes is \niden- tified by solving the problems of availability and anticipabil- ity on an expressive lattice. We \nalso show that when control flow restructuring is disabled, ComPRE becomes equivalent to the optimal \ncode-motion PRE algorithm [24]. An expression is partially redundant if its value is com- puted on some \nincoming control flow path by a previous expression. Code-motion PRE eliminates the redundancy by hoisting \nthe redundant computation along all paths until it reaches an edge where the reused value is available \nalong either all paths or no paths. In the former case, the com-putation is removed; in the latter, it \nis inserted to make the original computation fully redundant. Unfortunately, code motion may be blocked \nbefore such edges are reached. Nodes that prevent the desired code motion are characterized by the following \nset of conditions: 1. hoisting of expression e across node n is necessary when . . . a) an optimization \ncandidate follows n: there is a compu- tation of e downstream from n on some path, and b) there is a \nvalue-reuse opportunity for e at node n: a computation of e precedes n on some path. 2. hoisting of e \nacross n is disabled when c) any path going through n does not compute e in the source program: such \npath would be impaired by the computation of e. All three conditions are characterizable via solutions \nto the data-flow problems of anticipability and availability, which are defmed as follows. Definition \n1 Let p be any path from the start node to a node n. The expression e is available at n along p iff e \nis computed on p without subsequent redefinition of its operands. Let r be any path from n to the end \nnode. The expression e is anticipated at n along r iff e is computed on r before any of its operands \nare defined. The availability of e at the entry of n w.r.t. the incoming paths is defined as: Must all \nAVAL[n, e] = No if e is available along no paths. May some 1 Anticipability (ANTIC) is defined analogously. \nGiven this refined value-reuse definition, code motion is nec- essary when a) and b) defined above hold \nmutually. Hence, Necessary[n, e] = ANZ ICi [n, e] # NO A AVAILi [n, e] # NO. Code motion is disabled \nwhen the condition c) holds: Disabled[n, e] = ANTICi,[n, e] # Must A AVAZLi,[n,e] # Most. A node n prevents \nthe necessary code motion for e when the motion is necessary but disabled at the same time. By way of \nconjunction, we get the code motion-preventing condition: Preuented[n, e] = Necessary[n, e] A Disabled[n, \ne] = ANZ ICi,[n, e] = May A AVAILi,[n, e] = May The predicate Prevented characterizes the smallest set \nof nodes that must be removed for code motion to be enabled. . AVAILPMWI o AVAIL=No motion becomes possible \nR ; . ANrlc44ur j code molion L-J o ANTlC=No i i t ,... III *. a) code motion prevented by CMP region \nb) CMP region diluted via code duplication c) complete PRE of [a+b] Figure 2: Removing obstacles Definition \n2 Code Motion Preventing region, denoted CMP[e], is the set of nodes that prevent hoisting of a computation \ne: CMP[e] = {n ) ANTICin[n,e] = May A AVAIL,,[n,e] = May}. To enable code motion, ComPRE removes obstacles \npre-sented by the CMP region by duplicating the entire region, as illustrated in Figure 2. The central \nidea is to factor the May-availability that holds in the entire region into Must-and No-availability, \nto hold respectively in each region copy. An alternative view is that we separate within the region the \npaths with Must-and No-availability. To achieve this, we can observe that a) no region entry edge is \nMay-available, and b) the solution of availability within the region depends solely on solutions at entry \nedges (the expression is neither computed nor killed within the region). Hence, the desired factoring \ncan be carried out by attaching to each region copy the subset of either Must or No entry edges, as shown \nin Figure 2(c). After the CMP is duplicated, the condition Prevented is false on each node, enabling \ncode motion. The ComPRE algorithm, shown in Figure 3, has the following three steps: 1. Compute anticipability \nand availability. The problems use the lattice L = ({T, Must, No, May}, A). Note that the flow functions \nare distributive under the least com-mon element operator A, which is defined using the partial order \nC shown below. Distributivity property implies that data-flow facts are not approximated at control flow \nmerge points. Intuitively, this is because L is the powerset lattice of {No, Must}, which are the only \nfacts that may hold along an individual path. kT\\ Must The partial order E: No \\Ma; 2. Remove CMP regions \nvia control flow restructuring. Given an expression e, the CMP region is identified by examining the \ndata-flow solutions locally at each node. Line 2 in Figure 3 duplicates each CMP node and line 3 adjusts \nthe control flow edges, so that the new copy of the region hosts the Must solution. Restructuring ne-to \ncode motion via restructuring. cessitates updating data-flow solutions within the CMP region (lines \n4-12). While the ANTZC solution is not altered, the previously computed AVAIL solution is in- validated \nbecause some paths flowing into the region were eliminated when region entry edges were discon-nected. \nFor the expression e, AVAIL becomes either Must or No in the entire region. For other expressions, the \nsolution may become (conservatively) imprecise. In other words, splitting a May path into Must/No paths \nfor e might have also split a May path for some other expression. Therefore, line 6 resets the initial \nguess and lines lo-12 recompute the solution within the CMP. 3. Optimize the program. The code motion \ntransforma-tion is carried out by replacing each original compu-tation e with a temporary variable t,. \nThe tempo-rary is initialized with a computation inserted into each No-available edge that sinks either \ninto a May/Must-availability path or into an original computation. The insertion edge must also be Must-anticipated, \nto verify hoisting of the original computation to the edge. Theorem 1 (Completeness). ComPRE is optimal \nin that it minimizes the number of computations on each path. Proof. First, each original computation \nis replaced with a temporary. Second, no computation is inserted where its value is available along any \nincoming path. Hence, no addi- tional computations can be removed. Cl Within the domain of the Morel \nand Renviose code-motion transformation, where PRE is accomplished by hoisting optimization candidates \n(but not other statements) [26], ComPRE achieves minimum code growth. This fol-lows from the fact that \nafter CMP restructuring, no program node can be removed or merged with some other node with- out destroying \nany value reuse, as shown by the following observations. Prior to Step 2, each node n may belong to CMP \nregions of multiple offending expressions. Duplication of n during restructuring can be viewed as partitioning \nof control flow paths going through n: each resulting copy of n is a path partition that does not contain \nboth a Must-and a No-available path, for any offending expression. The Outside this domain, further code \ngrowth reduction is possible by moving instructions out of the CMP before its duplication. Step 1: Data-flow \nanalysis: anticipability, availability. s Input: control flow graph G = (N,E,start,end), each node contains \na single assignment z := e, s Comp(n, e): node n computes an expression e, s Transp(n,e): node n does \nnot assign any variable in e, . boundary conditions: for each expression e ANT/C,,t[end, e] := AVA/L;,[start, \ne] := No, s initial guess: set all vectors to TS, where S is the number of candidate expressions. Solve \niteratively. if Comp(n, e), if -Comp(n, e)AANT/C;,[n,e] := 7 Transp(n, e), ANT/C,,t[n, e] otherwise. \n ANTK.,,t[n,e] := A ANT/C;,[m, e] mr+wx(n) AVA/L;Jn,e] := /j AVAbt[m, e] mCpred(n) AVA/LOUt[n, e] := \nfz(AVAU;,[n, e]) if Comp(n, e) A Transp(n, e), if 7 Transp(n, e). otherwise.  Step 2: Remove CMP regions: \ncontrol flow restructuring. s modify G so that no CMP nodes exists, for any expression e. 1 for each \nexpression e do duplicate all CMP[e] nodes to create a copy of the CMP. n~ $, is a copy of node n hosting \nAVAIL = Must. 2 N := N u {rz~ ~* ] n E CMP[e]} attach new nodes to perform the restructuring 3 E =((E \nu {(wurt, u) I (n,u) E E A u Z CMf [el) U u, n,~ $~) 1 (u, n) 6 E A AVA/L,,t[u, e] = Must} U ~[u ~~k \n!?i ! ~?~!$z]?!l~AlL..~[u, e] = Must} update data-flow solutions within CMP and its copy 4 for each \nnode n E CMP[e] do 5 ANT/C;,[nM,,J := ANTIC;&#38;] ANT/C,,&#38;,,&#38; := ANT/C,,&#38;] 6 AVA/L;,[nM,,J \n:= AVA/L;,[n] := TS AVA/L,,t[nM,,t] := AVAIL,,&#38;] := TS 7 AVA/L;J~M~~~, e] := AVAIL,,~[~M,,~,~] := \nMust 8 AVAIL;&#38;, e] := AVAIL,,t[n, e] := No 9 end for reanalyze availability inside both CMP copies \n10 for each expression e not yet processed do 11 re-compute AVA/L(n, e ], AVA/L.[~M~~~, e ], n E CMP[e] \n12 end for 13 end for Step 3: Optimize: code motion. Insert[(n, m), e] e ANTIC;,[m, e] = Must A AVA/L,,t[n, \ne] = No A (AVA/L;,[m, e] = May V Comp(m, e)) Replace[n, e] ts Comp(n, e) Figure 3: ComPRE: the algorithm \nfor complete PRE. following properties of Step 2 can be verified: 1) the number of path partitions (node \ncopies) created at a given node is independent of the order in which expressions are considered (in line \nl), 2) each node copy is reachable from the start node, and 3) for any two copies of n there is an expression \ne such that remerging the two copies and their incoming paths will prevent code motion of e across the \nresulting node. To compare ComPRE with a restructuring-only PRE, we consider PoePRE, a version of Steffen \ns complete algo- rithm [30] that includes minimization of duplicated nodes but is restricted in that \nonly expressions are eliminated (as is the case in ComPRE). Elimination is carried out using a temporary, \nas in Step 3. Theorem 2 ComPRE does not create more new nodes than PoePRE. Proof outline. The proof is \nbased on showing that the PoePRE-optimized program after minimization has no less nodes than the same \nprogram after CMP restructuring. It can be shown that, given an original node n, for any two copies of \nn created by CMP restructuring, there are two distinct copies of n created by PoePRE such that the mini- \nmization cannot merge them without destroying some value reuse opportunity. In fact, PoePRE can be expressed \nas a form of Com- PRE on a (non-strictly) larger region: for each computation e, PoePRE duplicates {nlAiVTICin[n, \ne] E {Must, May} A AVAZLi,[n, e] = May}, which is a superset of CMP[e]. Algorithm complexity. Data-flow \nanalysis in Step 1 and in lines lo-12 requires O(NS) steps, where N is the flow graph size and S the \nnumber of expressions. The restructur-ing in Step 2, however, may cause N to grow exponentially, as each \nnode may need to be split for multiple expressions. Because in practice a constant-factor code-growth \nbudget is likely to be defined, the asymptotic program size will not change. Therefore, the running time \nof Step 2, which dom-inates the entire algorithm, is O(NS ). 2.1 Optimal Code-Motion PRE Besides supporting \na complete PRE, the notion of the CMP region also facilitates an efficient formulation of code-motion \nPRE, called CM-PRE. In this section, we show that our com- plete algorithm can be naturally constrained \nby prohibiting the restructuring, and that such modification results in the Same optimization as the \noptimal motion-only PRE [17, 241. In comparison to ComPRE, the constrained CM-PRE algorithm bypasses \nthe CMP removal; the last step (trans-formation) is unchanged (Figure 3). The first step (data-flow analysis) \nis modified with the goal to prevent hoisting across a node n when such motion would subsequently be \nblocked by a CMP region on each path flowing into node n. First, anticipability is computed as in ComPRE. \nSecond, availability is modified to include detection of CMP nodes. When a CMP node is found, instead \nof propagating forward May-availability, the solution is adjusted to No. Such ad- justment masks those \nvalue reuse opportunities that cannot be exploited without restructuring. The result of masking is that \ncode motion is prevented from entering paths that cross a CMP region (see predicate Insert in Step 3 \nof Figure 3). The modified flow function for the AVAIL problem fol-lows. The third line detects a CMP \nnode. No-availability is now extended to mean that the value might be available along some path but value \nreuse is blocked by a CMP region along that path. Must if Comp(n, e) A 7hrwp(n, e), if -Transp(n, e), \nfit(x) = ;; if z = May A ANTZCi [n, e] = May, l X otherwise. Given a maximal fixed point solution to \nredefined AVAIL, CM-PRE performs the unchanged transformation phase (Figure 3, Step 3). It is easy to \nshow that the resulting optimization is complete under the immutable shape of the control flow graph. \nThe proof is analogous to that of Theo- rem 1: alI original computations are removed and no compu- tation \nhas been inserted where an optimization opportunity not blocked by a CMP exists. Besides exploiting all \nopportunities, a PRE algorithm should guarantee that the live ranges of inserted temporary variables \nare minimal, in order to moderate the register pres-sure. The live range is minimal when the insertion \npoint specified by the predicate Insert cannot be delayed, that is, moved further in the direction of \ncontrol flow. Theorem 3 (Shortest live ranges). Given the CMP- restructured (or original) control flow \ngraph, ComPRE (CM-PRE) is optimal in that it minimizes the live range lengths of inserted temporary variables. \n Proof. An initialization point Insert cannot be delayed ei-ther because it would become partially redundant, \ndestroy-ing completeness, or because its temporary variable is used in the immediate successor. Cl Existing \nPRE algorithms find the live-range optimal placement in two stages. First, computations are hoisted as \nhigh as possible, maximizing the removal of redundancies. Later, the placement is corrected through the \ncomputation of delayability [24]. Our formulation specifies the optimal placement directly, as we never \nhoist into paths where a blocking CMP will be subsequently encountered. However, note that after the \nabove redefinition, fz is no longer monotone: given ANTIC,,[n,e] = May, $1 = May, xz = Must, we have \nx1 C 22 but fG(xi) = No e fi(xs) = Must. Although a direct approach to solving such system of equations \nmay produce conservatively imprecise solution, the desired maximal fixed point is easily obtained using \nbit-vector GEN/KILL operations as follows. First, compute ANTIC as in Figure 3. Second, solve the well-known \navailability property, denoted AVOll, which holds when the expression is computed along all incoming \npaths: AV.11 ($ A VA IL = Must. Finally, we compute AV,,,, which characterizes some-paths availability \nand also encapsulates CMP detection: AV,,,, H AVAIL # No. The pair of solu- tions (AVOWS,AXome) can be \ndirectly mapped to the desired solution of AVAIL. The GEN and KILL sets [l] for the AV,,,, problem are \ngiven below. The value of the initial guess is false, the meet operator is the bit-wise or. GEN = CompA \nTransp KILL = -Transp V (AVAIL # Must A ANTIC # Must) -Transp v (-AVolt A ANTIC # Most) The condition \n(AVAIL # Must A ANTIC # Must) detects the CMP node. While it is less strict than that in Defini-tion \n2, it is equivalent for our purpose, as it is safe to kill :~.~~~.~~ CMP[atb] co@d /or mdudbilily . \n9 0 s/rig/e loop ,_,....IH- entry node I? cd s 1 c!- a) source program b) reducible ComPFUl of [a+b] \nFigure 4: Reducible restructuring. (See Figure l(c)) when there is no reuse (AVAIL = No) or when there \nis no hoisting (ANTIC = No). The less strict condition is bene- ficial because computing and testing \nMust requires one bit per expression, while two bits are required for May. Con-sequently, we can substitute \nANTIC # Must with TAN,,,,, where AN,!1 is defined analogously to AVOl,. As a result, we obtain the same \nimplementation complexity as the algo- rithms in [17, 241: three data-flow problems must be solved, each \nrequiring one bit of solution per expression. In conclusion, the CMP region is a convenient abstrac-tion \nfor terminating hoisting when it would unnecessarily extend the live ranges. It also provides an intuitive \nway of explaining the shortest-live-range solution without applying the corrective step based on delayability \n[24]. Furthermore, the CMP-based, motion-only solution can be implemented as efficiently as existing \nshortest-live-range algorithms. 2.2 Reducible Restructuring Duplicating a CMP region may destroy reducibility \nof the control flow graph. In Figure l(c), for example, ComPRE resulted in a loop with two distinct entry \nnodes. Even though PoePRE preserves reducibility on the same loop (Figure l(b)), like other restructuring-based \noptimizations [4, 10, 301, it is also plagued by introducing irreducibility. One way to deal with the \nproblem is to perform all opti-mizations that presuppose single-entry loops prior to PRE. However, many \nalgorithms for scheduling (which should fol-low PRE) rely on reducibility. After ComPRE, a reducible \ngraph can be obtained with additional code duplication. An effective algorithm for nor-malizing irreducible \nprograms is given in [23]. To suppress an unnecessary invocation of the algorithm, we can employ a simple \ntest of whether irreducibility may be created af-ter a region duplication. The test is based upon examining \nonly the CMP entry and exit edges, rather than the entire program. Assuming we start from a reducible \ngraph, re-structuring will make a loop L irreducible only if multiple CMP exit edges sink into L, and \nat least one region entry is outside L (i.e., is not dominated by L s header node). If such a region \nis duplicated, target nodes of region exit edges may become the (multiple) loop entry nodes. Consider \nthe loop in Figure 4(a). Two of the three exits of CMp[a + b] fall into the loop. After restructuring, \nthey will become loop entries, as shown in Figure l(c). Rather than applying a global algorithm like \n[23], a straightforward approach to make the affected loop re- ducible is to peel off a part of its \nbody. The goal is to extend the replication scope so that the region exits sink onto a sin- gle loop \nnode, which will then become the new loop entry. Such a node is the closest common postdominator (within \nthe loop) of all the offending region exits and the original loop entry. Figure 4(a) highlights node \nc+d whose duplica- tion after CMP restructuring will restore reducibility of the loop. The postdominator \nof the offending exits is node Q, which becomes the new loop header. 3 Profile-Guided PRE While the CMP \nregion is the smallest set of nodes whose duplication enables the desired code motion, its size is often \nprohibitive in practice. In this section, relying on the pro- file to estimate optimization benefit, \ncomplete PRE is made more practical by avoiding unprofitable code replication. First, we extend ComPRE \nby inhibiting restructuring in response to code duplication cost and the expected dynamic benefit. The \nresulting profile-guided algorithm duplicates a CMP region only when the incurred code growth is justi- \nfied by a corresponding run-time gain from eliminating the redundancies. Second, the notion of the CMP \nregion is com- bined with profiling to formulate a speculative code-motion PRE that is guaranteed to \nhave a positive dynamic effect, despite impairing certain paths. The third algorithm in-tegrates both \nrestructuring and speculation and selects a profitable subgraph of the CMP for each. While profitably \nbalancing the cost and benefit under a given profile is NP- hard, the empirically small number of hot \nprogram paths promises an efficient algorithm [4, 191. Finally, to support profile guiding, we show how \nan estimate of the run-time gain thwarted by a CMP region can be obtained using edge profiles, frequency \nanalysis [27], or path profiles [7]. 3.1 Selective Restructuring We model the profitability of duplicating \na CMP region R with a cost-benefit threshold predicate T(R), which holds if the region optimization benefit \nexceeds a constant mul-tiple of the region size. Our metric of benefit is the dy- namic amount of computations \nwhose elimination will be enabled after R is duplicated, denoted Rem(R). That is, T(R) = Rem(R) > c .size(R). \nWhen T(R) = true for each region R, the algorithm is equivalent to the complete Com-PRE. When T(R) = \nfalse for each region, the algorithm reduces to the code-motion-only CM-PRE. Obviously, pred-icate T \ndetermines only a sub-optimal tradeoff between ex-ploiting PRE opportunities and limiting the code growth. \nIn particular, it does not explicitly consider the instruction cache size and the increase in register \npressure due to intro- duced temporary variables. We have chosen this form of T in order to avoid modeling \ncomplex interactions among com-piler stages. In the implementation, T is supplemented with a code growth \nbudget (for example, in [6], code is allowed to grow by about 20%). First, we present an algorithm for \ncomputing the opti-mization benefit Rem(R). The method is based on the fact Step 1: compute anticipability \nand availability. (unchanged) Step 2: Partial restructuring: remove profitable CMP regions. 1 for each \ncomputation e do 2 for each disconnected subregion Ri of CMP[e] do build the largest connected subregion \n 3 select a node from R and collect all connected CMP nodes determine optimization benefit Rem(R;) 4 \ncarry out frequency analysis of AVAlL on R; if profitable, duplicate (lines 2-12 of Fig. 3) 5 if T(R;) \nthen duplicate Ri 6 end for 7 end for 8 recompute the AVAlL solution, using fi from Section 2.1 Step \n3: Optimize: code motion. (unchanged) Figure 5: PgPRE: profile-guided version of ComPRE. that the CMP \nscope localizes the entire benefit thwarted by the region: to compute the benefit, it suffices to examine \nonly the paths within the region. Consider an expression e and its CMP region R = CMP[e]. For each region \nezit edge a = (n, m) (i.e., n E CMP[e], m e CMP[e]), the value of ANTICin[m,e] is either Must or No, \notherwise m would be in CMP[e]. Let EzitMurt(R) be the set of the Must exit edges. The dynamic benefit \nis derived from the observation that each time such an edge is executed, any outgoing path contains exactly \none computation of e that can be eliminated if: i) R is duplicated and ii) the value of e is available \nat the exit edge. Let ex(a) be the execution frequency of edge a and p(AVAI&#38;[n, e] = Must) the probability \nthat the value e is available when n is executed. After the region is dupli- cated, the expected benefit \nconnected with the exit edge a is ex(a).p(AVAIL,,t[n, e] = Must), which corresponds to the number of \ncomputations removed on all paths starting at a. The benefit of duplicating the region R is thus the \nsum of all exit edge benefits 0 Rem(R) = c ex(a).p(AVA&#38;,t[n, e] = Must). o=(n,m)EEsitr~,,,(R) The \nprobability p is computed from an edge profile using frequency analysis [27]. In the frequency domain, \nthe prob- ability of each data-flow fact occurring, rather than the fact s mere boolean meet-over-all-paths \nexistence, is com-puted by incorporating the execution probabilities of control flow edges into the data-flow \nsystem. Because the frequency analyzer cannot exploit bit-vector parallelism, but instead computes data-flow \nsolutions on floating point numbers, it is desirable to reduce the cost of calculating the probabili- \nties. The CMP region lends itself to effectively restricting the scope of the program that needs to be \nanalyzed. Because all region entry edges are either Must-or A/o-available, the probability of e being \navailable on these edges are 1 and 0, respectively. Therefore, the probability p at any exit edge can \nonly be influenced by the paths within the region. As a result, it is sufficient to perform the frequency \nanalysis for expression e on CMP[e], using entry edges as a precise boundary condition for the CMP data-flow \nequation system. In Section 5 we reduce the cost of frequency analysis through a demand-driven approach. \nThe algorithm (PgPRE) that duplicates only profitable CMP regions is given in Figure 5. It is structured \nas its complete counterpart, ComPRE: after data-flow analysis, we proceed to eliminate CMP regions, separately \nfor each expression. While in ComPRE it was sufficient to treat all nodes from a single CMP together, \nselective duplication ben-efits from dividing the CMP into disconnected subregions, if any exist. Intuitively, \nhoisting of a particular expression may be prevented by multiple groups of nodes, each in a different \npart of the procedure. Therefore, line 3 groups nodes from a connected subregion and frequency analysis \ndetermines the benefit of the group (line 4). After all prof-itable regions are eliminated, the motion-blocking \neffect of CMP regions remaining in the program must be captured. All that is needed is to apply the CM-PRE \nalgorithm from Section 2.1 on the improved control flow graph. Blocked hoisting is avoided by recomputing \navailability (line 8) us-ing the re-defined flow function fz from Section 2.1, which asserts No-availability \nwhenever a CMP is detected. 3.2 Speculative Code-Motion PRE In code-motion PRE, hoisting of a computation \ne is blocked whenever e would need to be placed on a control flow path p that does not compute e in the \noriginal program. Such spec- ulative code motion is prevented because executing e along path p could \na) raise spurious exceptions in e (e.g., over-flow, wrong address), and b) outweigh the dynamic benefit \nof removing the original computation of e. The former re-striction can be relaxed for instruction that \ncannot except, leading to safe speculation. New processor generations will support control-speculative \ninstructions which will suppress raising the exception until the generated value is eventually used, \nallowing unsafe speculation [25]. The latter problem is solved in [20], where an aggressive code-motion \nPRE nav-igated by path profiles is developed. The goal is to allow speculative hoisting, but only into \nsuch paths on which dy-namic impairment would not outweigh the benefit of elimi- nating the computation \nfrom its original position. Next, we utilize the CMP region to determine i) the prof- itability of speculative \ncode motion and ii) the positions of speculative insertion points that minimize live ranges of tem- porary \nvariables. Figure 6 illustrates the principle of specu- lative PRE [20]. Instead of duplicating the CMP \nregion, we hoist the expression into all No-available entry edges. This makes all exits fully available, \nenabling complete removal of original computations along the I\\/lust exits. In our example, [o + 51 is \nmoved into the No-available region entry edge ez. This hoisting is speculative because [a+b] is now executed \non each path going through ez and es, which previously did not contain the expression. The benefit is \ncomputed as follows. The dynamic amount of computations is decreased by the execution frequency eE(eq) \nof the Must-anticipable exit edge (following which a computation was removed), and increased by the frequency \nex(ez) of the No-available entry edge (into which the computation was inserted). Since speculation is \nalways associated with a CMP region, we are able to obtain a simple (but precise) profitability test: \nspeculative PRE of an expression is profitable if the total execution frequency of Must-anticipable exit \nedges exceeds that of No-availaible entry edges. Note that the benefit is calculated locally by examining \nonly entry/exit edges, and not the paths within the region, which was necessary in selective restructuring. \nHence, the speculative benefit is independent from branch correlation and edge profiles are as precise \nas path profiles in the case of speculative-motion PRE. As far as temporary live ranges are concerned, \ninsertion into entry edges results in a shortest-live-range solution, and Theorem 3 still holds. i l \nAVAlL=Mw 0 AVAIL=No . ANTIc=Mur 0 ANTlC=No Optimization benefit: -ex(eZ) -Inssrtion iex(e4) -removal \nexh4J-exte2J .I ., i Figure 6: Speculative code-motion PRE.  3.3 Partial Restructuring, Partial Speculation \nIn Section 3.1, edge profiles and frequency analysis were used to estimate the benefit Rem of duplicating \na region. An alternative is to use path profiles [3, 71, which are con-venient for establishing cost-benefit \noptimization trade-offs [4, 19,201. To arrive at the value of the region benefit with a path profile, \nit is sufficient to sum the frequencies of Must-Most paths, which are paths that cross any region entry \nedge that is Must-available and any exit edge that is Must-anticipated. These are precisely the paths \nalong which value reuse exists but is blocked by the region. While there is an exponential number of \nprofiled acyclic paths, only 5.4% of procedures execute more than 50 distinct paths in spec96 [19]. This \nnumber drops to 1.3% when low-frequency paths accounting for 5% of total frequency are removed. Since \nwe can afford to approximate by disregarding these infrequent paths, summing individual path frequencies \nconstitutes a feasible algorithm for many CMP regions. Furthermore, because they encapsulate branch correlation, \npath profiles compute the benefit more precisely than frequency analysis based on correlation-insensitive \nedge profiles. Moreover, the notion of individual CMP paths leads to a better profile-guided PRE algorithm. \nConsidering the CMP region as an indivisible duplication unit is overly conserva-tive. While it may not \nbe profitable to restructure the entire region, the region may contain a few paths Must-Must paths that \nare frequently executed and are inexpensive to dupli-cate. Our goal is to hnd the largest subset (frequency-wise) \nof region paths that together pass the threshold test T(R). Similarly, speculative hoisting into all \nentry edges may fail the profitability test. Instead, we seek to find a subset of entry edges that maximizes \nthe speculative benefit. In this section, we show how partial restructuring and speculation are carried \nout and combined. Partial speculation selects for speculative insertion only a subset Z of the No region \nentries. The selection of entries in-fluences which subset R of region exits will be able to exploit \nvalue reuse. R consists of all Must exits that will become Must-available due to the insertions in I. \nThe rationale be-hind treating entries separately is that some entries may en-able little value reuse, \nhence they should not be speculated. Note that No entry edges are the only points where specu-lative \ninsertion needs to be considered: insertions inside the region would be partially redundant; insertions \noutside the region would extend the live-ranges. Partial speculation is optimal if the difference of \ntotal frequencies of R and Z is maximal (but non-negative). Although this problem is NP- speculation \nL.pro/&#38;.&#38; r no/ proli8bL9 L CMP([c+d]) No-path peeled oft ...A a) source progmm b) speculation \nmade profi table Figure 7: Integrating speculation and restructuring. hard, the small number of entry \nedges observed in practice (typically less than 10) makes the problem tractable. An interesting observation \nis that to determine optimal partial speculation, a) edge profiles are not inferior to path profiles \nand b) frequency analysis is not required. Therefore, to ex-ploit the power of path profiles, partial \nrestructuring, rather than (speculative) code motion alone, must be used. This becomes more intuitive \nonce we realize that without control flow restructuring, one is restricted to consider only an in- dividual \nedge (but not a path) for expression insertion and removal. To compare the CMP-based partial speculation \nwith the speculative PRE in [20], we show how to efficiently compute the benefit by defining the CMP \nregion and how to apply edge profiles with the same precision as path profiles. In acyclic code, we achieve \nthe same precision; in cyclic code, we are more precise in the presence of loop-carried reuse. The task \nof partial restructuringis to localize a subgraph of the CMP that has a small size but contains many \nhot Must-Must paths. By duplicating only such a subregion, we are effectively peeling off only hot paths \nwith few in-structions. In Figure l(e), only the (presumably hot) path through the node Q was separated. \nAgain, the problem of finding an optimal subregion, one whose benefit is maxi- mized but passes the T(R) \npredicate and is smaller than a constant budget, is NP-hard. However, the empirically very small number \nof hot paths promises an efficient exhaustive-search algorithm. Integrating partial speculation and restructuring \noffers additional opportunities for improving the cost-benefit ra-tio. We are no longer restricted to \npeeling off hot Must-Must paths and/or selecting No-entries for speculation. When the high frequency \nof a No entry prevents speculation, we can peel off a hot No-available path emanating from the entry, \nthereby reducing entry edge frequency and allowing the speculation, at the cost of some code duplication. \nFig-ure 7(a) shows an example program annotated with an edge profile. Because peeling hot Must-Must paths \nfrom the high- lighted CMP([c+d) would duplicate all blocks except S, we try speculation. To eliminate \nthe redundancy at the CMP exit edge Y with frequency ex(Y) = 100, a computation must be inserted into \nNo-entries B and C. While B is low- frequency (lo), C is not (loo), hence the speculation is dis- advantageous, \nas ez(Y) = 100 < ez(B) + ez(C) = 10 + 100. Now assume that the exit branch in Q is strongly biased and \nthe path C, Q, X has a frequency of 100. That is, after edge C is executed, the execution will always \nfollow to X. We can peel off this No-available path, as shown in (b), effec-tively moving the speculation \npoint C off this path. After peeling, the frequency of C becomes 0 and the speculation is profitable, \nez(Y) = 100 > ez(B) + G(C) = 10 + 0. 4 Experiments We performed the experiments using the HP Labs VLIW \nback-end compiler elcor, which was fed specs5 benchmarks that were previously compiled, edge-profiled, \nand inlined (only specssint) by the Impact compiler. Table 1 shows program sizes in the total number \nof nodes and expres- sions. Each node corresponds to one intermediate state- ment. Memory requirements \nare indicated by the column max space, which gives the largest nodes-expressions product among all procedures. \nThe running time of our rather inef- ficient implementation behaved quadratically in the number of procedure \nnodes; for a procedure with 1,000 nodes, the PRE time was about 5 seconds on PA-8000. Typically, the \ncomplete PRE ran faster than the subsequent dead code elimination. Experiment 1: Disabling effects of \nCMP regions. The column labeled optimizable gives the percentage of ex- pressions that reuse value along \nsome path; 13.9% of (static) expressions have partially redundant computations. The next column prevented-CMP \nreports the percentage of op- timizable expressions whose complete optimization by code motion is prevented \nby a CMP region. Code-motion PRE will fail to fully optimize 30.5% of optimizable expressions. For comparison, \ncolumn prevented-POE reports expressions that will require restructuring in PoePRE. Experiment 2: Loop \ninvariant expressions. Next, we determined what percentage of loop invariant (LI) expres-sions can be \nremoved from their invariant loops with code motion. The column loop invar shows the percentage of op- \ntimizable expressions that pass our test of loop-invariance. The following column gives the percentage \nof LI expressions that have a CMP region; an average of 72.5% of LI compu-tations cannot be hoisted from \nall enclosing invariant loops without restructuring. Experiment 3: Eliminated computations. The col-umn \nglobal CSE reports the dynamic amount of computa- tions removed by global common subexpression elimination; \nthis corresponds to all full redundancies. The column com-plete PRE gives the dynamic amount of all partially \nredun-dant statements. The fact that strictly partial redundancies contribute only 1.7% (the difference \nbetween complete PRE and global CSE) may be due to the style of Impact s inter-mediate code (e.g., multiple \nvirtual registers for the same variable). We expect a more powerful redundancy analysis to perform better. \nFigure 8 plots the dynamic amount of strictly partial redundancies removed by various PRE tech-niques. \nCode-motion PRE yields only about half the benefit of a complete PRE. Furthermore, speculation results \nin near- complete PRE for most benchmarks, even without special hardware support (i.e., safe speculation). \nSpeculation was carried out on the CMP as whole. Note that the graph ac-counts for the dynamic impairment \ncaused by speculation. Table 1: Experience with PRE based on control flow restructuring. Figure 8: Benefit \nof various PRE algorithms: dynamic op-count decrease due to strictly partial redundancies. Each algorithm \nalso completely removes full redundancies. The measurements indicate that an ideal PRE algorithm should \nintegrate both speculation and restructuring. Using restructuring when speculation would waste a large \nportion of benefit will provide an almost complete PRE with small code growth. Experiment 4: Code growth. \nFinally, we compare the code growth incurred by ComPRE and PoePRE. To make the experiment feasible, we \nlimited procedure size by 3,000 nodes and made the comparison only on procedures that did not exceed \nthe limit in either algorithm. Overall, ComPRE created about three times less code growth than PoePRE. \n5 Demand-Driven Frequency Analysis Not amenable to bit-vector representation, frequency anal-ysis [27] \nis an expensive component of profile-guided opti-mizers. We have shown that ComPRE allows restricting \nthe scope of frequency analysis within the CMP region without a loss of accuracy. However, in large CMP \nregions the cost may remain high, and path profiles cannot be used as an efficient substitute when numerous \nhot paths fall into the region. One method to reduce the cost of frequency anal-ysis is computing on \ndemand only the subset of data flow solution that is needed by the optimization. In this section, we \ndevelop a demand-driven frequency analyzer which reduces data-flow analysis time by a) exam- ining only \nnodes that contribute to the solution and, option- ally, b) terminating the analysis prematurely, when \nthe solu- tion is determined with desired precision. Besides PRE, the analyzer is suitable for optimizations \nwhere acceptable run-ning time must be maintained by restricting analysis scope, as in run-time optimizations \n[5] or interprocedural branch removal [lo]. Frequency analysis computes the probability that a data- \nflow fact will occur during execution. Therefore, the proba- bility Yattice is an infinite chain of real \nnumbers. Because existing demand-driven analysis frameworks are built on it-erative approaches, they \nonly permit lattices of finite size [18] or finite height [22, 291 and hence cannot derive a fre- quency \nanalyzer. We overcome this limitation by designing the demand-driven analyzer based upon elimination \ndata-flow methods [28] whose time complexity is independent of the lattice shape. We have developed a \ndemand-driven anal-ysis framework motivated by the Allen-Cocke interval elim-ination solver [2]. Next, \nusing the framework, a demand-driven algorithm for general frequency data-flow analysis was derived [8]. \nWe present here the frequency solver spe-cialized for the problem of availability. Definitions. Assume \na forward data-flow problem specified with an equation system  = jn(n7%EpPed(n)xm) (X:,...,X; = (fm \nm~pred(n)sn)r.. . 1fns(n,xd) Vector xn = (Xi,. . . , xi) is the solution for a node n, vari-able x , \ndenotes the fact associated with expression e. The equation system induces a dependence graph EG whose \nnodes are variables xc and edges represent flow functions f i: an edge (z&#38;, zz) exists if the value \nof zz is computed from 2;, m E pred(n). The graph EG is called an exploded graph [22]. The data flow \nproblems underlying ComPRE are separable, hence zz only depends on x&#38;,. In value-based PRE [9], constant \npropagation [29], and branch correlation analysis [lo], edges (z$, xz), d # e, may exist, complicat-ing \nthe analysis. The analyzer presented here handles such general exploded graphs. Requirements. The demand-driven \nanalyzer grew out of four specific design requirements: 1. Demand-driven. Rather than computing x, for \neach node n, we determine only the desired xk, i.e. the so-lution for expression e at a node n. Analysis \nspeed-up is obtained by further requiring that only nodes transitively contributing to the value of xf, \nare vis-ited and examined. To guarantee worst-case behavior, when solutions for all EG nodes are desired, \nthe solver s time complexity does not exceed that of the exhaustive Allen-Cocke method, O(N ), where \nN is the number of EG nodes. 2. Lattice-independent. The amount of work per node does not depend on \nlattice size, only on the EG shape. 3. On-line. The analysis is possible even when EG is not completely \nknown prior to the analysis. To save time and memory, our algorithm constructs EG as analysis progresses. \nThe central idea of on-demand construc-tion is to determine a flow function fi only when its target variable \nxz is known to contribute to the desired solution. Furthermore, the solver must produce the so-lution \neven when EG is irreducible, which can happen even when the underlying CFG is reducible. 4. Informed. \nIn the course of frequency analysis, the con-tribution weight of each examined node to the desired solution \nmust be known. This information is used to develop a version of the analyzer that approximates frequency \nby disregarding low-contribution nodes with the goal of further restricting analysis scope.  The ezhahaustiueinterval \ndata-flow analysis [2] computes xn for all n as follows. First, loop headers are identified to partition \nthe graph into hierarchic acyclic subregions, called intervals. Second, forward substitution of equations \nis per-formed within each interval to express each node solution in terms of its loop header. The substitution \nproceeds in the interval order (reverse postorder), so that each node is vis-ited only once. Third, mutual \nequation dependences across loop back-edges are reduced with a loop breaking rule I,: xn = S(Xn,Xk) + \nxn = L(g(x*)). The second and third step remove cyclic dependences from all innermost loops in EG; they \nare repeated until all nesting levels are processed and all solutions are expressed in terms of the start \nnode, which is then propagated to all previously reduced equations in the final propagation phase [2]. \nThe demand-driven interval analysis substitutes only those equations and reduces only those intervals \non which the desired 2: is transitively dependent. To find the relevant equations, we back-substitute \nequations (flow functions) into the right-hand side of x: along the EG edges. The edges are added to \nthe exploded graph on-line, whenever a new EG node is visited, by first computing the flow function of \nthe node and then inserting its predecessors into the graph. As in [2], we define an EG interval to be \na set of nodes dominated by the sink of any back-edge. In an irreducible EG, a back-edge is each loop \nedge sinking onto a loop entry node. Because the EG shape is not known prior to analysis, on-line identification \nof EG intervals relies only on the struc- ture of the underlying control flow graph. When the CFG node \nof an EG node z is a CFG loop entry, then x may be an EG loop entry, and we conservatively assume it \nis an interval head. Within each interval, back-substitutions are performed in reversed interval order. \nSuch order provides lattice-independence, as each equation needs to be substi- tuted only once per interval \nreduction, and there are at most N reductions. To find interval order on an incomplete EG, we observe \nthat within each EG interval, the order is con- sistent with the reverse postorder CFG node numbering. \nTo loop-break cyclic dependencies along an interval back-edge, the loop is reduced before we continue \ninto the preced-ing interval, recursively invoking reductions of nested loops. This process achieves \ndemand analysis of relevant intervals. The desired solution is obtained when z , is expressed exclu-sively \nusing constant terms. At this point, we have also iden-tified an EG subgraph that contributes to zi, \nand removed from it all cyclic dependences. A forward substitution on the subgraph will yield solutions \nfor all subgraph nodes which can be cached in case they are later desired (worst-case run-ning time). \nThis step corresponds to the propagation phase in [2], and to caching in [18, 291. The framework instance \ncalculates the probability of ex-pression e being available at the exit of node n during the execution: \nxc,, - p(AVAIL,,t[n,e] = Must) E R. Let p(a) denote the probability of edge a being taken, given its \nsink node is executed. We relate the edge probability to the sink (rather than the source, as in exhaustive \nanalysis [27]) be-cause the demand solver proceeds in the backward direction. The frequency flow function \nreturns probability 1 when the node computes the expression e and 0 when it kills the ex-pression. Otherwise, \nthe sum of probabilities on predeces-sors weighted by edge execution probabilities is returned. Predicates \nCamp and Transp are defined in Figure 3. 1.0 if Comp(n, e) A Transp(n, e), 0.0 if TTransp(n, e),a I \n x, = c p((m, n)).xk otherwise. I nEpred(n) The demand frequency analyzer is shown in Figure 9. Two \ndata structures are used : sol accumulates the con-stant terms of the desired probability r:; rhs is \nthe current right-hand side of xz after all back-substitutions. The vari-ables sol and rhs are organized \nas a stack, the top being used in the currently analyzed interval. The algorithm treats rhs both as a \nsymbolic expression and as a working set of pend-ing nodes (or yet unsubstituted variables, to be precise). \nFor example, the value of rhs may be 0.25*m+0.4*k, where the weights are contributions of nodes m and \nk to the desired probability z ,. If e is never available at m, and is available at k with probability \n0.5, then it is available at node n with probability 0.25 * 0 + 0.4 * 0.5 = 0.2. More formally, the con-tribution \nweight of a node represents the probability that a path from that node to n without a computation or \na kill of the expression e will be executed. First, the rhs is set to 1.0 * n in line 1. Then, flow func-tions \nare back-substituted into rhs in post-order (line 3). Substitutions are repeated until all variables \nhave been re-placed with constants (line 2), which are accumulated in sol. If a substituted node z computes \nthe expression e, its weight rhs[x] is added to the solution and z is removed from the rhs by the assignment \nrhs[z] := 0.0 (line 6). In the simple case when x is not a loop entry node (line 12), its contribution \nc is added to each predecessor s contribution, weighted by the edge probability p. If z is a loop entry \nnode (line 8), then before continuing to the loop predecessor, all self-dependences of x are found in \na call to reduceloop. The procedure reduceloop mimics the main loop (lines I-5) but it pushes new entries \non the stacks to initiate a reduc- tion of a new interval and also marks the loop entry node to stop \nwhen back-substitution collected cyclic dependences along all cyclic paths on the back-edge edge (y,x). \nThe result of reduceloop is returned in a sol-&#38;s pair (s,r), where s is the constant and r the set \nof unresolved vari-ables, e.g. x = r + s = 0.32 + 0.1. If EG is reducible, the set r contains only x. \nThe value r[x] = 0.3 is the weight of the z s self-dependence, which is removed by the loop breaking \nrule derived for frequency analysis from the sum of infinite geometric sequence (lines 10-11). After \nthe al-gorithm terminates, the stack visited (line 14) specifies the order in which forward substitution \nis performed to cache the results. Also shown in Figure 9 is an execution trace of the demand-driven \nanalysis. It computes the probability that the expression computed in nodes F, H, and killed in A, D, \nis available at node C. All paths where availability holds are highlighted. Approximate Data-Flow Analysis. \nOften, it is neces-sary to sacrifice precision of the analysis for its speed. We define here a notion \nof approximate data flow information, which allows the analyzer a predetermined degree of con-servative \nimprecision. For example, given a 5% imprecision level (e = 0.05), the analyzer may output available: \n0.7, when the maximal fixed point solution is available: 0.75. The intention of permitting underestimation \nis to reduce the analysis cost. When the analyzer is certain that the contri- bution of a node (and all \nits incoming paths) to the overall solution is less than the imprecision level, it can avoid an-alyzing \nthe paths and assume at the node the most conser-vative data-flow fact. Because the algorithm in Figure \n9 was designed to be informed, it naturally extends to approximate analysis. By knowing the precise contribution \nweight of each node as the analysis progresses, whenever the sum of weights in rhs at the highest interval \nlevel falls below e (the while-condition in line 2), we can terminate and guarantee the desired pre-cision. \nAn alternative scenario is more attractive, however. When a low-weight node is selected in line 3, we \nthrow it away. We can keep disregarding such nodes until their total weights exceed e. In essence, this \napproach performs analy-sis along hot paths [4], and on-line region formation [21]. The idea of terminating \nthe analysis before it could find the precise solution was first applied in the implementa-tion of inter-procedural \nbranch elimination [lo]. Stopping after visiting a thousand nodes resulted in two magnitudes of analysis \nspeedup, while most optimization opportunities were still discovered. However, without the approsimate \nfre-quency analyzer developed in this paper, we were unable to a) determine the benefit of restructuring, \nb) select a prof- itable subset of nodes to duplicate, and c) get a bound on the amount of opportunities \nlost due to early termination. Algorithm complexity. In an arbitrary exploded graph, reduce_loop may \nbe (recursively) invoked on each node. Hence, each node may be visited at most NE times, where NE = NS \nis the number of EG nodes, N the number of CFG nodes, and S the number of optimized expressions. With \ncaching of results, then each node is processed in at most one invocation of the algorithm in Figure \n9, yielding worst-case time complexity of 0( Ni) = O(N2Sa). Since real programs have loop nesting level \nbound by a small con-stant, the expected complexity is (NS), as in [2]. Although most existing demand-driven \ndata-flow algo-rithms ([18, 221, [29] in particular) can be viewed (like ours) to operate on the principle \nof back-substituting flow func-tions into the right-hand side of the target variable, they do not focus \non specifying a profitable order of substitutions (unlike ours) but rely instead on finding the fixed \npoint it-eratively. Such an approach fails on infmite-height lattices where CFG loops keep always iterating \ntowards a better ap-proximation of the solution. Note that breaking each con-trol flow cycle by inserting \na widening operator [13] does not appear to resolve the problem because widening is a local adjustment \nprimarily intended to approximate the solution. Therefore, in frequency analysis, too many iterations \nwould be required to achieve an acceptable approximation. Instead of fixing the equation system locally, \na global approach of structurally identifying intervals and reducing their cyclic dependences seems necessary. \nWe have shown how to iden- tify intervals and perform substitutions in interval order on demand, even \nwhen the exploded graph is not known prior to the analysis. We believe that existing demand methods can \nbe extended to operate in a structural manner, enabling the application of loop-breaking rules. This \nwould make the methods reminiscent of the elimination algorithms [28]. 6 Conclusion and Related Work \nThe focus of this paper is to improve program tmns-formations that constitute value-reuse optimizations \ncom-monly known as Partial Redundancy Elimination (PRE). In the long history of PRE research and implementation, \nthree distinct transformations can be identified. The sem-inal paper by Morel and Renviose [26] and its \nderivations [ll, 14, 15, 16, 17, 241 employ pure, non-speculative code motion. Second, the complete PRE \nby Steffen [30] is based on control flow restructuring. Third, navigated by path pro-file information, \nGupta et al apply speculative code motion in order to avoid code-motion obstacles by controlled im-pairment \nof some paths [ZO]. In this work, we defined the code-motion-preventing (CMP) region, which is a CFG \nsubgraph localizing adverse effects of control flow on the desired value reuse. The notion of the CMP \nis applied to enhance and integrate the three existing PRE transformations in the following ways, 1. \nCode motion and restructuring are integrated to remove all redun- dancies at minimal code growth cost \n(ComPRE). 2. Morel and Renviose s original method is expressed as a restricted (motion-only) case of \nthe complete algorithm (CM-PRE). 3. We develop an algorithm whose power adjusts contin- Input: node n, \nexpression e. Output: in sol, the probability of e being available at the exit of n. so1 : stack of reals \n(names sol, rhs refer always to top of stack) rhs : stack of sets of unsubstituted nodes n with weights \nrha[n] oost-dfs : post-order numbering of CFG nodes t sol := 0; rhs := {}; rhs[n] := 1.0 2 while rhs \nnot empty do 3 select from rhs a node z with smallest post-dfs(z) I substitute(z) 5 end while procedure \nsubstitute(node z) if z has not been visited, determine its flow function if I computes or kills e, adjust \nsol and remove z from rhs if Comp(z,e) A Transp(z, e) then 5 SO/ := sol + rhs[z]; rhs[z] := 0.0; return \n7 else if ~Transp(n,e) then rhs[z] := 0.0; return back-edge is each edge that meets a loop-entry edge \n3 if back-edge (y, Z) exists then assume one back-edge per node substitute for y until z occurs on the \nr.h.s. 9 (s, v) := reduceJoop(y, z) apply loop breaking rule: sum of infinite geom. sequence 10 c := \nrhs[z]/(l -r[~]) 11 rhs := rhs + c x r; sol := sol + c x a 12 else c := rhs[z] substitute acyclic predecessors \nfor each non-backedge node z C pred(z) do  13 rhs[z] := rhs[r] + c x p((z, z)) end for z is now fully \nsubstituted 14 rhs[z] := 0.0; viaited.push(z) end substitute function reduceJoop(node u, node u) 15 mark \nv; so/.push(O); rha.posh({}); rhs[u] := p((u,v)) 16 while rhs contains unmarked nodes do 17 select from \nrha an unmarked node z with lowest post-dfs(z) 18 substitute(z) 19 end while 20 unmark V; return (aol.pop(), \nrhs.pop()) end reduceJoop post-dfs: H, G, F, . . Input: n = C Output: p = 0.2818 1 sol := 0; rhs = 1.0 \n* :C 4 substitute(C) 12 c := 1.0 13 rha := 0.2 * H + 0.3 * G + 0.5 *B 4 substitute(H) 6 sol := sol + \nrhs[H] := 0 + 0.2 6 rhs = 0.3 * G + 0.5 * B 4 substitute(G) 12 c := 0.3 13 rhs := 0.5 * B + 0.3 *A 4 \nsubstitute(B) 9 reduceJoop(E, B) 15 mark B; sol1 := 0; rhsl := 0.9 *E 18 substitute(E) 12 c := 0.9; 13 \nrhsl := 0.36 *D + 0.45 + B + 0.09 * F 18 substitute(F) 6 sol1 := so/l + rhsl[fl := 0 + 0.09 6 rhsl = \n0.36 * D + 0.45 * B 18 substitute(D) 7 That := 0.45 + B 20 unmark B; return (0.09,0.45 *B) 10 c := 0.5/(1 \n-0.45) = 0.91 11 rhs := 0.5 * B + 0.3 *A + 0.91 * 0.45 * B 11 sol := 0.2 + 0.91*0.09 := 0.2818 13 rhs \n:= 0.91 * B + 0.3 * A + 0.91 * 0.1 * A 14 rhs := 0.391~ A 4 substitute(A) 7 sol := 0.2818 unchanged t \nFinal probability 7 rha := 0.0 Figure 9: Demand-driven frequency analysis for availability of computations, \nand a trace of its execution. ually between the motion-only and the complete PRE in response to the program \nprofile (PgPRE). 4. We demon- strate that speculation can be navigated precisely by edge profiles alone. \n5. Path profiles are used to integrate the three transformations and balance their power at the level \nof CMP paths. While PRE is significantly improved through effective program transformations presented \nin this paper, a large orthogonal potential lies in detecting more redundancies. Some techniques have \nused powerful analysis to uncover more value reuse than the traditional PRE analysis [9, 111. However, \nusing only code motion, they fail to completely exploit the additional reuse opportunities. Thus, the \ntrans-formations presented here are applicable in other styles of PRE as well, for example in elimination \nof loads. Ammons and Larus [4] developed a constant propagation optimization based on restructuring, \nnamely on peeling of hot paths. In their analysis/transformation framework, re-structuring is used not \nonly to exploit optimization opportu-nities previously detected by the analysis, as is our case, but \nalso to improve the analysis precision by eliminating control flow merges from the hot paths. Even though \nour PRE can-not benefit from hot path separation (our distributive data-flow analysis preserves reuse \nopportunities across merges), a more complicated analysis (e.g., redundancy of array bound checks) would \nbe improved by their approach. After the analysis, their algorithm recombines separated paths that present \nno useful opportunities. It is likely that path recom-bination can be integrated with code motion, as \npresented in this paper, to further reduce the code growth. In a global view, we have identified four \nmain issues with path-sensitive program optimizations [8]: a) solving non-distributive problems without \nconservative approxima-tion (e.g. non-linear constant propagation), b) collecting distinct opportunities \n(e.g., variable has different constant along each path), c) exploiting distinct opportunities (e.g., \nenabling folding of path-dependent constants through re-structuring), and d) directing the analysis effort \ntowards hot paths. In the approach of Ammons and Larus, all four is-sues are attacked uniformly by separation \nof hot paths, their subsequent individual analysis, and recombination. Our ap- proach is to reserve restructuring \nfor the actual transforma-tion. This implies a different overall strategy: a) we solve non-distributive \nproblems precisely along all paths by cus-tomizing the data-flow name space [9], b) we collect distinct \nopportunities through demand-driven analysis as in branch elimination [lo], which is itself a form of \nconstant propa-gation, c) we exploit all profitable opportunities with eco-nomical transformations, and \nd) avoid infrequent program regions using the approximation frequency analysis (the last three presented \nin this paper). 7 Acknowledgments We are indebted to the elcor and Impact compiler teams for providing \ntheir experimental infrastructure. Sadun Anik, Ben-Chung Cheng, Brian Dietrich, John Gyllenhaal, and \nScott Mahlke provided invaluable help during the imple-mentation and experiments. Comments from Glenn \nAm-mons, Evelyn Duesterwald, Jim Larus, Mooly Sagiv, Bern-hard Steffen, and the anonymous reviewers helped \nto im-prove the presentation of the paper. This research was par- tially supported by NSF PYI Award CCR-9157371, \nNSF grant CCR-9402226, and a grant from Hewlett-Packard to the University of Pittsburgh. References Alfred \nV. Aho, Ravi Sethi, and Jeffrey D. Ullman. Compilers PI Principles, Techniques, and Tools. Addison Wesley, \n1986. F. E. Allen and J. Cocke. A program data flow analysis procedure. CA CM, 19(3):137-147, March 1976. \nPI Glenn Ammons, Thomas Ball, and James R. Larus. Exploit- [31 ing hardware performance counters with \nflow and context sensitive profiling. In Proceedings of the ACM SIGPLAN 97 Conf. on Prog. Language Design \nand Impl., pages 85-96, 1997. Glenn Ammons and James L. Larus. Improving data-flow analysis with path \nprofiles. In Proceedings of the ACM SIG-PLAN 98 Conference on Programming Language Design and Implementation, \n1998. [41 Joel Auslander, Matthai Philipose, Craig Chambers, Su-san J. Eggers, and Brian N. Bershad. \nFast, effective dynamic compilation. In Proceedings ofthe A CM SIGPLAN 96 Con- ference on Programming \nLanguage Design and Implementa- tion, pages 14S-159,21-May 1996. 151 A. Ayers, R. Schooler, and R. Gottlieb. \nAggressive inlining. In Proceedings of the ACM SIGPLAN 97 Conf. on Prog. Language Design and Impl., pages \n134-145, June 1997. 161 Thomas Bali and James R. Larus. Efficient path profiling. In 29th Annual IEEE/ACM \nInternational Symposium on Microarchitecture, pages 46-57, 1996. [71 P31 Rastislav Bodik. Path-Sensitive \nCompilation. PhD thesis, University of Pittsburgh, in preparation. Rastislav Bodik and Sadun Anik. Path-sensitive \nvalue-flow analysis. In Conference Record of the 25th A CM SIGPLA N-SIGACT Symposium on Principles of \nProgramming Lan-guages, January 1998. PI WI Rastislav Bodik, Rajiv Gupta, and Mary Lou Soffa. Inter-procedural \nconditional branch elimination. In Proceedings of the A CM SIGPLAN 97 Conf. on Prog. Language Design \nand Impl., pages 146-158, June 1997. Dll Preston Briggs and Keith D. Cooper. Effective partial re-dundancy \nelimination. In Proceedings of the Conference on Programming Language Design and Implementation, pages \n159-170, June 1994. PI F. Chow, S. Ghan, R. Kennedy, S.-M. Liu, R. Lo, and P. Tu. A new algorithm for \npartial redundancy elimination based on SSA form. In Proceedings of Ihe ACM SIGPLAN 97 Conf. on Prog. \nLanguage Design and Impl., pages 273-286, June 1997. P31 P. Cousot and R. Cousot. Abstract intrepretation: \na unified lattice model for static analysis of programs by construction or approximation of fixpoints. \nIn Conference Record of the 4th ACM Symposium on Principles of Programming Lan-guages, pages 238-252, \nJanuary 1977. Dhanajay M. Dhamdhere, Barry K. Rosen, and Kenneth F. [I41 Zadeck. How to analyze large \nprograms eWciently and infor-matively. In Proceedings of the ACM SIGPLAN 92 Con-ference on Programming \nLanguage Design and Implementa- tion, pages 212-223, July 1992. Dhananjay M. Dhamdhere. Practical adaptation \nof the global optimization algorithm of Morel and Renvoise. ACM Transactions on Programming Languages \nand Systems, 13(2):291-294, April 1991. 1151 K. Drechsler and M. Stadel. A solution to a problem with \nMorel and Renvoise s global optimization by suppression of partial redundancies . A CM Transactions on \nProgramming Languages and Systems, 10(4):635-640, October 1988.  I161 K. Drechsler and M. Stadel. A \nvariation of Knoop, Riithing, and Steffen s lazy code motion. ACM SIGPLAN Notices, 28(5):635-640, May \n1993.  P 71 [I81 Evelyn Duesterwald, Rajiv Gupta, and Mary Lou Soffa. A practical framework for demand-driven \ninterprocedural data flow analysis. ACM Transactions on Programming Lan-guages and Systems, 19(6):992-1030, \nNovember 1997. [191 R. Gupta, D. Berson, and J.Z. Fang. Resource-sensitive profile-directed data flow \nanalysis for code optimization. In 90th Annual IEEE/ACM International Symposium on Mi-croarchitecture, \npages 358-368, December 1997. R. Gupta, D. Berson, and J.Z. Fang. Path profile guided par-tial redundancy \nelimination using speculation. In IEEE In-ternational Conference on Computer Languages, May 1998. PO1 \nWI Richard E. Hank, Wen-Mei W. Hwu, and B. Ramakrishna Rau. Region-based compilation: An introduction \nand mo-tivation. In 28th Annual IEEE/ACM International Sympo-sium on Microarchitecture, Ann Arbor, Michigan, \n1995. Susan Horwitz, Thomas Reps, and Mooly Sagiv. Demand Interprocedural Dataflow Analysis. In Proceedings \nof the Third ACM SIGSOFT Symposium on the Foundations of Software Engineering, pages 104-115, October \n1995. WI Johan Janssen and Henk Corporaal. Controlled node split-ting. In Compiler Conslruction, 6th \nInternational Conjer-ence, volume 1060 of Springer Lecture Notes in Computer Science, pages 44-58, Sweden, \nApril 1996. [231 Jens Knoop, Oliver Riithing, and Bernhard Steffen. Optimal code motion: Theory and \npractice. ACM Trans. on Progr. Languages and Systems, 16(4):1117-1155,1994. [241 S. A. Mahlke, W. Y. \nChen, R. A. Bringmann, R. E. Hank, [251 W.M. W. Hwu, B. R. Rau, and M. S. Schlansker. Sen-tinel scheduling \nfor VLIW and superscalar processors. A CM Transactions on Computer Systems, 11(4):376-408,1993. E. Morel \nand C. Renviose. Global optimization by supression of partial redundancies. CACM, 22(2):96-103, 1979. \n  WI 1271 G. Ramalingam. Data flow frequency analysis. In Proceed-ings of the ACM SIGPLAN 96 Conj. on \nProgr. Language Design and Implementation, pages 267-277, June 1996. [=I Barbara G. Ryder and Marvin \nC. Paull. Elimination al-gorithms for data flow analysis. ACM Computing Surveys, 18(3):277-316, September \n1986. Mooly Sagiv, Thomas Reps, and Susan Horwitz. Precise in-terproceduraldataflow analysis with applications \nto constant propagation. Theoretical Computer Science, 167(1-2):131-170,1996. WI Bernhard Steffen. Property \noriented expansion. In Proc. Int. Static Analysis Symposium (SAS 96), volume 1145 of LNCS, pages 22-41, \nGermany, September 1996. Springer. [301 \n\t\t\t", "proc_id": "277650", "abstract": "Partial redundancy elimination (PRE), the most important component of global optimizers, generalizes the removal of common subexpressions and loop-invariant computations. Because existing PRE implementations are based on <i>code motion</i>, they fail to completely remove the redundancies. In fact, we observed that 73% of loop-invariant statements cannot be eliminated from loops by code motion alone. In dynamic terms, traditional PRE eliminates only half of redundancies that are strictly partial. To achieve a <i>complete</i> PRE, control flow <i>restructuring</i> must be applied. However, the resulting code duplication may cause code size explosion.This paper focuses on achieving a complete PRE while incurring an acceptable code growth. First, we present an algorithm for <i>complete</i> removal of partial redundancies, based on the <i>integration</i> of code motion and control flow restructuring. In contrast to existing complete techniques, we resort to restructuring merely to remove obstacles to code motion, rather than to carry out the actual optimization.Guiding the optimization with a profile enables additional code growth reduction through selecting those duplications whose cost is justified by sufficient execution-time gains. The paper develops two methods for determining the optimization benefit of restructuring a program region, one based on path-profiles and the other on data-flow frequency analysis. Furthermore, the abstraction underlying the new PRE algorithm enables a simple formulation of speculative code motion guaranteed to have positive dynamic improvements. Finally, we show how to balance the three transformations (code motion, restructuring, and speculation) to achieve a near-complete PRE with very little code growth.We also present algorithms for efficiently computing dynamic benefits. In particular, using an elimination-style data-flow framework, we derive a demand-driven frequency analyzer whose cost can be controlled by permitting a bounded degree of conservative imprecision in the solution.", "authors": [{"name": "Rastislav Bod&#237;k", "author_profile_id": "81100033082", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "P239460", "email_address": "", "orcid_id": ""}, {"name": "Rajiv Gupta", "author_profile_id": "81100027751", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "PP39072720", "email_address": "", "orcid_id": ""}, {"name": "Mary Lou Soffa", "author_profile_id": "81452611636", "affiliation": "Dept. of Computer Science, University of Pittsburgh, Pittsburgh, PA", "person_id": "PP39032771", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277653", "year": "1998", "article_id": "277653", "conference": "PLDI", "title": "Complete removal of redundant expressions", "url": "http://dl.acm.org/citation.cfm?id=277653"}