{"article_publication_date": "05-01-1998", "fulltext": "\n Quality and Speed in Linear-scan Register Allocation Omri Traub, Glenn Holloway, Michael D. Smith Harvard \nUniversity Division of Engineering and Applied Sciences Cambridge, MA 02138 {otraub, holloway, smith}@ \neecs. harvard. edu ments to the linear-scan approach that improve output code Abstract without destroying \nthe linear character of the algorithm. A linear-scan algorithm directs the global allocation of reg- \nDespite the increasing speeds of modern processors, it has ister candidates to registers based on a simple \nlinear sweep never been more important to find and use efficient compi- over the program being compiled. \nThis approach to register lation techniques. The demand for highly optimizing code allocation makes sense \nfor systems, such as those for generation is increasing as processors become more com- dynamic compilation, \nwhere compilation speed is impor- plex. One response is the trend towards whole-program tant. In contrast, \nmost commercial and research optimizing optimization [6,15]. The success of this approach depends compilers \nrely on a graph-coloring approach to global regis- heavily on near-linear optimization techniques. Another \nter allocation. In this paper, we compare the performance of growing trend seeks to optimize application \ncode at load or a linear-scan method against a modern graph-coloring run time. For example, Hoeltzle \net al. [lo] and Poletto et al. method. We implement both register allocators within the [ 131 describe \nthe benefits of techniques in adaptive optimi- Machine SUIF extension of the Stanford SUIF compiler zation \nand dynamic code generation respectively. To be system. Experimental results show that linear scan is \nmuch acceptably responsive, these techniques must operate at faster than coloring on benchmarks with \nlarge numbers of speeds measured in a reasonable number of cycles per gen- register candidates. We also \ndescribe improvements to the erated instruction. linear-scan approach that do not change its linear \ncharacter, but allow it to produce code of a quality near to that pro- Both graph-coloring and linear-scan \nallocators use liveness duced by graph coloring. information to find an assignment of register candidates \nto the machine registers. To achieve this goal, a graph-coloring Keywords: global register allocation, \ngraph coloring, linear allocator summarizes liveness information as an interfer- scan, binpacking ence \ngraph, with nodes representing register candidates and edges connecting nodes whose corresponding candidates \n1 Introduction are live at the same time and therefore cannot coexist in a register. For a k-register \ntarget machine, finding a k-coloring Fast compilation tools are essential for high software pro- of the \ninterference graph is equivalent to assigning the can- ductivity. The register allocation phase of code \ngeneration is didates to registers without conflict. often a bottleneck, and yet good register allocation \nis neces- The standard graph-coloring method, adapted for register sary for making today s processors \nreach their peak effi- allocation by Chaitin et al. [4,5], iteratively builds an inter- ciency. It is \nthus important to understand the trade-off ference graph and heuristically attempts to color it. If the \nbetween speed of register allocation and the quality of tbe heuristic succeeds, the coloring results \nin a register assign- resulting code. In this paper, we investigate a fast approach ment. If it fails, \nsome register candidates are spilled to mem- to register allocation, called linear scan, and we compare \nit ory, spill code is inserted for their occurrences, and the to the widely-used graph-coloring method. \nThis fair com- whole process repeats. In practice, the cost of the graph-col- parison shows linear scan \nto be faster than coloring under oring approach is dominated by the construction of succes- most conditions, \nespecially on programs with large numbers sive graphs, which is potentially quadratic in tbe number of \nof variables competing for the same registers. Since emit- register candidates. Since a single compilation \nunit may ting high quality code was our first priority in implementing have thousands of candidates (including \ncompiler-generated our linear scan allocator, we describe some novel improve- temporaries), coloring \ncan be expensive. In contrast to graph coloring, a linear-scan allocator begins with a view of liveness \nas a lifetime interval. A lifetime interval of a register candidate is the segment of the pro- gram that \nstarts where the candidate is first live in the static linear order of the code and ends where it is \nlast live. A lin- 0 ,998 ACM o-89791.9874/98/0006...66.00 ear-scan allocator visits each lifetime interval \nin turn, according to its occurrence in the static linear code order, and considers how many intervals \nare currently active. The number of active intervals represents the competition for available machine \nregisters at this point in the program. When there are too many active lifetimes to fit, a Simple heuristic \nchooses which of them to spill to memory and the scan proceeds. Because it only tries to detect and resolve \nconflicts locally, rather than for an entire compilation unit at once, linear scan can operate faster \nthan graph coloring. Pre- vious linear-scan allocators run in time linear in the size of the procedure \nbeing compiled. In Section 2, we describe our version of a linear-scan alloca- tor. Our algorithm is \nbased on a variant of linear scan, called binpacking, that Digital Equipment Corporation uses in its \ncommercial compiler products [l]. We describe several improvements to the binpacking approach. The most \nsignif- icant change involves our algorithm s ability to allocate reg- isters and rewrite the instruction \nstream in a single scan; all current linear-scan algorithms of which we are aware allo- cate and rewrite \nin separate passes. By allocating and rewriting simultaneously, we introduce flexibility into the register \nallocation process by giving spilled allocation can- didates multiple chances to reside in a register \nduring their lifetimes. Because of this flexibility, our approach requires a second pass to resolve the \nlinear-scan assumptions with the non-linearity of a procedure s control-flow graph (CFG). Because the \nsecond pass entails a dataflow analysis, its worst-case asymptotic complexity is quadratic in the pro- \ngram size. However, as we explain in Section 2.6, it can be engineered to give linear performance in \nall cases. In Sec- tion 3, we describe our experiments, which use the Machine SUIF code generation framework \nto compare the perfor- mance of our linear-scan algorithm against a modern graph coloring algorithm [7]. \nSection 4 discusses related efforts in linear-scan register allocation, and Section 5 summarizes our \ncontributions. Second-chance binpacking Two important goals guide the design of our register alloca- \ntion algorithm: speed of allocation and quality of code pro- duced. In the spirit of the linear-scan \nfamily of allocators, we seek to keep the allocation time to a minimum by avoid- ing expensive, iterative \ncomputations such as the ones used in graph-coloring register allocation. Furthermore, unlike any other \nallocation technique of which we are aware, the algorithm described below performs allocation and code \nrewriting in a single pass over the instructions of a proce dure. This approach influences many of our \ndesign deci- sions. After Section 2.1 introduces the general concepts behind a binpacking allocator, \nSection 2.2 outlines the tech- nique and focuses on the novel aspects of our algorithm. Section 2.3 describes \nhow we handle spills during the linear allocate/rewrite phase, while Section 2.4 discusses the sec- ond \nphase of our algorithm which resolves the assumptions made during the linear first phase with the non-linear \nflow of a CFG. Section 2.5 presents two optimizations related to the creation of spill code and the elimination \nof moves. Sec- tion 2.6 summarizes the computational complexity of our algorithm. 2.1 Allocation candidates \nand lifetime holes We begin by describing some preliminary concepts about the objects that we wish to \nallocate. In our allocator, we seek to assign registers to both program variables and com- piler-generated \ntemporaries. We shall refer to all allocation candidates generically as temporaries. When examining the \nlifetime of a temporary, we observe that it may contain one or more intervals during which no useful \nvalue is maintained. These intervals are termed life-time holes. Figure 1 illustrates several kinds of \nlifetime holes that can appear in the lifetime of a temporary. Even if we assign a register r to a temporary \nt for t s entire lifetime, we can assign another temporary u to r during t s lifetime if u s lifetime \nfits inside a lifetime hole in t. In Figure 1, tem- porary T3 fits entirely in Tl s lifetime hole, and \nthus both could be assigned the same register. We use a single reverse pass over the code to compute \nlifetimes and lifetime holes. 2.2 The binpacking model The register allocation model that we adopt views \nthe machine registers as bins into which temporary lifetimes are packed. The constraint on a bin is that \nit may contain only one valid value at any given point in the program execution. Assuming that we have \nan infinite resource machine with an unbounded number of registers and that our task is to choose the \nsmallest subset of registers that can be assigned to lifetimes, we can minimize this number in two ways. \nFirst, we can assign two non-overlapping lifetimes to the same register. Second, we can assign two temporaries \nto the same register if the lifetime of one is entirely contained in a lifetime hole of the other. Under \nboth these approaches, the constraint on a register (bin) is preserved. A binpacking allocator scans \nthe code in a forward linear order, processing the temporaries as they are encountered in the program \ntext. The processing of a temporary t involves the allocation oft to a register if t is not currently \nassigned a register. We can view an unoccupied register as containing a lifetime hole that extends to \na later point in the program where it is no longer free. With this view, the selection of a register \nto allocate to t involves the search for a register with a hole big enough to contain the entire lifetime \nof t. If we have multiple registers with holes large enough to contain t s entire lifetime, we heuristically \nchoose the register with the smallest hole that is larger than t s lifetime. Once we assignt to a register \nr, we would replace all references to t with references to r (assuming infinite registers). In reality, \nthe number of registers available on a given machine is fixed. If at some point in the linear scan there \nare more overlapping lifetimes than there are available regis- ters, some of these values will need to \nbe spilled into mem- ory. The traditional approach to linear-scan allocation fist walks the sorted list \nof lifetime intervals deciding which temporaries live in a register and which live in memory. A second \nphase then scans the procedure code and rewrites each operand with a reference to the appropriate register \nor to memory. For the purposes of discussion, we assume a load/store architecture where a register is \nalways required, Linear-ordering of blocks -b Bl B2 B3 B4 I I B2 B3 Tl r T4+- . . T2 w r . . tT1 T3 W \nr T4 . . tT4 T4t.. T4 s lifetime . . t T4 in T4 (a) An example CFG (b) A linear ordering for the example \nCFG with temporary lifetimes overlaid. with lifetime holes indicatedfor each temporary. Figure 1. Example \nillustrating the concept of a linear ordering of a procedure s basic blocks, and the lifetimes and lifetime \nholes for the temporaries in this procedure. Notice that a block boundary can cause a hole to begin or \nend in the linear view of the program. and so a reference to a spilled temporary is modeled as a point \nlifetime interval corresponding to the load or store of the spilled temporary. These point lifetimes \nare always assigned a register during allocation.  2.3 Second-chance allocation Early on in the design \nof our binpacking register allocator, we noticed that it is possible to allocate registers to tempo- \nraries and rewrite temporary references all in a single linear passover the program text. When we encounter \na temporary t for the fist time, we interrupt the rewriting process and determine an allocation for t. \nIf we must spill another tem- porary to create a free register for t, we proceed in a manner identical \nto the approaches that separate the allocation and rewriting phases-a temporary u currently residing \nin a reg- ister r is spilled to memory and t is assigned to r. Such spill- ing decisions are based on \na priority heuristic that compares the distance to each temporary s next reference, weighted by the depth \nof the loop it occurs in, picking the lowest-pri- ority temporary for eviction. Our system is unique \namong linear-scan allocators in that a spill point marks a split in the lifetime of the evicted temporary \nU. All references to u up to this point have already been rewritten to use register r. Our algorithm \ndoes not go back and change this fact. The spill decision affects only future references to U. When encountering \na later reference to this spilled tempo- rary u, we must find it a register to occupy during the instruction \nthat uses it. If the reference is a read of U, we find a free register r (possibly evicting another temporary \nin the process) and insert a load of U S memory location into r. Once we have allocated u to this new \nregister r, we allow u to remain in r until some higher-priority temporary evicts it (or U S lifetime \nends). In effect, we have split U S lifetime again. The benefit of this approach is that we do not have \nto reload u if we make another reference to it in the near future. We do not need any special mechanisms \nto prefer- ence a later spill load to the same register as the last spill load [3]. In this approach, \nwe optimistically, rather than pes- simistically, plan for u s future references. Since we already have \nto support lifetime splits due to our emphasis on a sin- gle allocate/rewrite pass, our allocator supports \nthis optimis- tic approach naturally. If the next reference to a spilled temporary u is a write, our \nallocator performs a similar optimistic decision. We allocate u to a register r (possibly spilling the \ncurrent temporary in this register), and we postpone the store of this new value for u back into memory \nuntil some other temporary causes the allocator to evict u. All following references to u are rewritten \nto use r, and if we reach the end of u s lifetime, we may never have to produce the postponed store. \nWe call our optimistic handling of spilled temporaries sec- ond chance, because we give temporaries a \nsecond (or third, etc.) chance at finding a register home. This second-chance approach is completely \ngeneralized to provide a temporary lifetime with a (potentially) new register for every split in its \nlifetime. There is one other optimization that we perform while allo- cating and rewriting. Similar to \nthe case where we do not create another load of a spilled temporary t from memory if t is already in \na register, we can optimize the rewrite process so that it does not create a store of a temporary u currently \nresiding in a register r when evicting U, if the value for u in r matches the value for u in memory. \nTo perform this optimi- zation, we maintain information about the consistency of Bl il: Rl c . . 1 [ \nTl not live} (Tl inRl] i7: st Rl,Tl B2 B2 B3 {Tl in Rl) {Tl in mem} i2: . . i--T1 i2: . . t Rl I I I \nI i3: . . cT1 [Tl in mem} . . . i.5: st Rl,Tl i6: Id R2,Tl i3: . . cR2 {Tl in R2) B4 {Tl in R2) i4: \n. . t Tl i4: R2 c . . (a) An example CFG before allocation. The CFG (b) The CFG afer allocation. Only \ninstructions associated contains 5 temporary lifetimes, but only Tl s with Tl are shown. The linear allocation \norder is Bl-B2-B3-B4. references are shown. The allocation assumptions for Tl before resolution are shown \nas sets at the top and bottom of each block. Figure 2. Example of conjlict resolution at CFG edges. Assume \nthat none of the temporaries contain lifetime holes and that we have only two registers Rl and R2. When \nthe allocator encountersil in Bl, it assigns Tl to Rl and rewrites Tl in il and then i2 to use Rl. When \nthe allocator encounters the third lifetime in B2, it spills Tl to memory (i5). When it encounters i3 \nin B3, it inserts a load of Tl from memory (i6); this time Tl is given register R2--a second-chance allocation. \nThe linear scan completes afer rewriting T1 in i3 and then i4 to use R2 During resolution, the allocator \ninserts a store (i7) at the top of B3 and a load (i8) at the bottom of B2. the value in I with respect \nto the value in U S memory home. sibilities that require resolution. If the temporary was in a Any spill \nof u to or from memory makes the memory home register at the bottom of the predecessor block but in mem- \nconsistent with 1. Any write of a value to r invalidates the ory at the top of the successor block, we \ninsert a store consistency of the memory and register values. When we instruction (but only if a temporary \ns allocated register and come to a point where we decide to evict u from r, we avoid memory home are \ninconsistent). If the temporary moved the generation of a store spill if u is evicted from r during from \nmemory to a register, we insert a load instruction. If one of U S lifetime holes (a store is not needed \nsince the next the temporary was in two different registers across the edge, reference will overwrite \nthe current value) or if the values of we insert a move instruction. While processing an edge, we u in \nr and in memory are consistent. are careful to model the data movement across the edge in a manner that \nproduces the correct resolution instructions in 2.4 Resolution the semantically-correct order, even in \nthe case where two (or more) temporaries swap their allocated registers. This As we mentioned earlier, \nthe above approach to register processing is similar to replacing SSA phi-nodes by a set of allocation \ncomes with a cost. In giving a temporary a second equivalent move operations [12]. Figure 2 gives a simple \nchance and multiple register locations at different intervals example of resolution. in the temporary \ns lifetime, we can potentially create con- The linear processing of the CFG can also lead to unneces- \nflicts in the allocation assumptions at the basic block bound- sary spill loads. Continuing with the \nexample in Figure 2, aries. The linear processing of the allocation/rewrite phase assume that we remove \nthe shortest lifetime from block B3. of our approach incompletely models the program control With this \nchange, the allocator as currently described would flow. To maintain program semantics, we follow the \nalloca- still insert the load of Tl into R2 for the rewrite in i3. This tion/rewrite phase with a traversal \nof the CFG edges, resolv- is because the linear ordering assumes that the last action in ing any mismatch \nin the allocation assumptions across each block B2 for Tl left Tl in memory. This is a pessimistic edge. \nassumption since there is no control-flow edge directly con- We can resolve any conflicts between the \nallocation necting B2 and B3. We would like to be able to take advan- assumptions across CFG edges by \ninserting an appropriate set of load, store, or move instructions. During the alloca- 1. If the block \nat the head of the edge has only a single predecessor, we tion pass we maintain a map that gives us information \non place the resolution code at the top of this block If the block at the tail of the edge has only a \nsingle succes&#38;, we place the resolution code at the the location of a temporary at the top and bottom \nof each bottom of this block. If the edge is a critical edge, we split the edge, safely basic block. \nAcross a control flow edge, there are three pos- creating a location to place the resolution code. tage \nof the fact that one of our registers will be unused from the top of B3 till i3 and thus allocate Tl \nto this register for the entire length of B3. The best choice is to allocate Tl to Rl at the top of B3 \n(eliminating the generation of any reso- lution code across the edge Bl-B3); however, this choice would \nrequire us to reconstruct the binpacking state when the linear traversal transitions between two blocks \nnot con- nected by a control-flow edge. We consider this too expen- sive an operation considering that \nRl may be needed for another temporary (as in the original example in Figure 2) before the use of Tl \nin i3. An alternative solution is to run a later code motion pass that tries to sink stores and hoist \nloads until they meet. When loads and stores to the same stack location meet, we can replace the two \noperations with a move from the store s source register to the load s destina- tion register. The resulting \nmove may then be eliminated by subsequent copy propagation and dead-code elimination passes. Though we \ndo not perform any dataflow analyses during register allocation to minimize the generation or improve \nthe placement of spill code, we do perform, during the reso- lution phase of our allocator, one dataflow \nanalysis for cor- rectness. If we decided not to insert a store instruction when evicting a temporary \n(see Section 2.3), we used the fact that the memory and register contents were consistent. This assumption \nmay hold along one or more paths through the control flow graph, but not necessarily through all paths \nreaching the point where the consistency information was used. In order to determine if and where spill \nstores need to be inserted to guarantee consistency along all paths, we solve the following iterative \nbit-vector dataflow problem. Each bit vector used in our analysis requires as many bits as there are \nallocation temporaries that are live across basic block boundaries. During the linear scan, we maintain \na working bit vector called ARE-CONSISTENT. Let A, be the bit in ARE-CONSISTENT corresponding to a temporary \n1. A, is set as long as t is allocated to a register r and the con- tents of r are consistent with t \ns memory home. As described in Section 2.3, a write to r clears A,, and a spill of t sets A,. We will \nnot generate a spill store for t during evic- tion of t from r if A, is set. We save a local copy of \nARE-CONSISTENT at the end of each basic block. This copy is used in the subsequent dataflow analysis. \nAlso during the linear scan, we generate the local GEN and KILL sets for each basic block b. The bit \nvector WROTE_TR(b) corresponds to the KILL set. Let W, be the bit in WROTE-TR(b) corresponding to a temporary \nt. W, is initially clear; it is set whenever a register r allocated to t is written in b. The bit vector \nUSED-CONSISTENCY(b) cor-responds to the GEN set. Let U, be the bit in USED-CONSISTENCY(b) corresponding \nto a temporary t. U, is initially clear; it is set whenever W, is clear and we usedA, to inhibit the \ngeneration of a spill store. In other words, U, is set whenever the inhibiting of a spill store relies \non assumptions of consistency not local to b. Once we have completed the linear scan for the allocate/ \nrewrite phase, we iterate to find a fixed point for the follow- ing dataflow equations: USED-C-out(b) \n= v USED-C-in(s) s E succ(b) USED-Cjn( b) = USED-CONSISTENCY(b) u (USED-C-out(b) -WROTE-TR(b)) For all \nblocks b, we initially set USED-C-in(b) equal to USED-CONSISTENCY(b). During resolution processing, we \ninsert a spill store for a temporaryt during the processing of a CFG edge p-s if the bit for t in USED-C-in(s) \nis set and the bit in ARE-CONSISTENT(p) is clear. These edges represent the beginnings of paths reaching \nprogram points where the con- sistency of t s register and memory home was exploited, but where the register \nand memory were not consistent. The placement of this spill store follows the same placement rules as \nthe other resolution code.  2.5 Move optimizations Modern computing systems typically impose usage \nconven- tions for registers. The caller-saved registers, for example, are not preserved across procedure \ncalls. As described so far, our algorithm only allows a temporary to be assigned to a register if that \nregister is free for the temporary s entire remaining lifetime. Under such a restriction, all temporaries \nlive across calls compete solely for the Cal&#38;-saved regis- ters, In a graph-coloring register allocator, \nthis is equivalent to adding an interference edge to the caller-saved registers. In our algorithm, we \nrepresent the constraints on register usage by considering the intervals in which a register is free \nfor use as its lifetime holes. A temporary can now fit inside a register s lifetime hole or another temporary \ns lifetime hole. In order to overcome the problem described above, we allow in our algorithm for a temporary \nto be assigned to a register with a lifetime hole that is not large enough to con- tain the entire lifetime. \nThe algorithm heuristically searches for the largest of these insufficiently-large holes. When a register \ns lifetime hole expires, we check to see if there is still a temporary contained in it. If there is one, \nwe evict the temporary from that register at this point (corresponding to a call site, for example). \nWhen evicting a temporary t from a register rt that is needed by some convention, we could insert a spill \nstore, reloading its value the next time we need it through our second-chance mechanism. But it might \nbe true at this point that some other register r, now contains a hole that could contain t s remain-ing \nlifetime. If t s lifetime fits in the lifetime hole in r,, it is more efficient to insert a move from \nrt to rJ now than insert a store now and a load later, provided that t is not evicted from rs before \nt s next reference. We therefore insert the move now only if we can find an empty register r, and if \nevicting t from r, would result in a spill store. We refer to this mechanism as early second chance. \nAlthough a move instruction can be more efficient than a load-store instruction pair, we also want to \neliminate moves during register allocation when possible. During our linear scan, we perform a check, \nin the spirit of move coalescing, that attempts to assign both the source and destination of a move to \nthe same register; such moves are eliminated by a separate peephole pass. The check works as follows: \nonce we have assigned a register to the source of a move instruc- tion, we check to see if that register \nhas a hole starting immediately after the move s source use and if the lifetime of the move s destination \ntemporary fits within this hole. If so, we bypass the normal allocation mechanism and rewrite the move \ndestination to use the same register as the move source. We have implemented only a limited version \nof the move elimination optimization. In order to satisfy the Digital Alpha calling convention, our Alpha \ncode generator inserts move operations from the parameter registers to the sym- bolic names of the parameters \nat the top of a procedure. We can easily eliminate these moves using our move optimiza- tion. If we leave \nthem in the code, they can noticeably degrade the performance of call-intensive programs. Our current \nimplementation performs the move optimization only when the source of a move is already in a register. \nIt would be straightforward to extend our implementation to attempt move optimization after allocation \nof a general move source. 2.6 Complexity analysis The conflict resolution step of our algorithm, which \nwe feel is essential for maximizing the quality of the output code, does not have a linear time bound. \nIts worst-case complex- ity is dominated by that of the dataflow calculation described above. However, \nthis dataflow analysis can be replaced so that our allocator runs in linear time. The first two phases \nof the algorithm, computation of life- times and holes, then allocation and rewriting, are mani- festly \nlinear.2 Each is a single sweep over the instructions of the program being compiled. Allocation has a \nconstant fac- tor proportional to the number of available registers, since it may scan the register state \nin order to choose and assign a register. The sweep over edges during conflict resolution is also effectively \nlinear: in real programs most flow nodes have an out degree of one or two so that the number of edges \ngrows as the number of nodes, and not quadratically. If the equations for USED-C-in(b) and USED-C-out(b) \ngiven above are solved by the standard iterative bit-vector calculation, then conflict resolution has \na worst-case run- ning time of O(N2) bit-vector operations, where N is the size of the program. If the \nsize of the bit-vectors is the number of temporaries, then the bound is cubic, since the total number \nof register candidates is typically proportional to the size of the program. The common experience with \nthe standard method, however, is that it terminates in two or three itera- 2. We assume the liveness \ninformation used in finding lifetimes and holes is available when register allocation begins. The cost \nof gathering and storing it is amortized in over many optimizations a typical optimizing compiler. tions \nat most, which brings its time cost down to O(N) bit- vector operations. In our implementation, the time \nspent in this dataflow calcu- lation rarely reaches one percent of the time consumed by the overall algorithm. \nWe have therefore not attempted to tune this phase. For situations in which strict linearity is necessary, \none could easily replace our iterative dataflow calculation with a more conservative solution. To ensure \nthat we avoid a spill store only when legal, we can conser- vatively initialize the working copy of the \nARE-CONSISTENT bit vector at the top of each block b encountered during the linear scan. We initialize \nit with the intersection of the saved ARE-CONSISTENT bit vectors at the bottom of all b s predecessor \nblocks. We assume that any predecessor with an uninitialized bit vector clears all bits in the working \nbit vector. In our experiments, conflict resolution including dataflow analysis has never consumed more \nthan five percent of the total time for allocation. Sacrificing strict linearity has not had a major \nimpact.  3 Experimental evaluation To compare fairly our linear-scan register allocator with a graph-coloring \nallocator, we have implemented them both in the Machine SUIF extension [14] of the Stanford SUIF compiler \nsystem [ 161. SUIF makes it easy to mix and match compiler passes. Keeping the rest of the compiler fixed, \nwe created two alternative register allocation passes, identical in every respect except the central \nregister assignment algo- rithms. In both passes, for example, we use shared libraries to construct CFGs \nand perform liveness and loop-depth analysis, with the results attached to the CFG prior to regis- ter \nallocation. Moreover we use a common set of utilities for scanning the code and updating it to insert \nspill instructions or to reflect register assignments. Loop depth is used in the same way to weight occurrence \ncounts in both allocators. In each case, register allocation is preceded by dead code elim- ination and \nfollowed by a peephole optimization pass that removes moves that can safely collapse into the preceding \nor succeeding instruction. The coloring method used is an implementation of that described by George \nand Appel [7]. This is a pure coloring approach in the style originated by Chaitin [5] and refined by \nBriggs et al. [2]. Its principal departure from that style is that it integrates register coalescing \n(copy propagation) into the coloring phase of allocation, rather than performing it repeatedly beforehand \nin a loop. The usual Chaitin-Briggs method builds a new interference graph after each success- ful round \nof coalescing. George and Appel take the costly graph-building operation out of the inner loop. They \nreport that it also improves code significantly by eliminating more copy instructions. Our implementation \nis faithful to the pub- lished algorithm [7] with two exceptions: l We use a lower-triangular bit matrix, \nrather than a hash table, to record the adjacency relation of the interference graph. Benchmark alvinn \ndoduc eqntott espresso fPPPP tom&#38;v compress m88ksim sort WC Instruction counts Second-chance Graph \nbinp acking coloring 5859032035 5850062031 1610607538 1565260889 2782873030 2777476231 1510435454 1390526882 \n6775315066 6262634084 9878244999 9694580392 6531688057 6531662363 94956007702 91999060755 1112471957 \n1101374080 1030126044 989670114 1046734 1046722 Ratio (binpack/GC) 1.002 1.029 1.002 1.086 1.082 1.019 \n1.000 1.032 1.010 1.041 1.000 Run time (set) Ratio (binpack/GC) Second-chance Graph binp acking coloring \n20.56 20.67 7.36 7.23 6.92 6.90 3.54 3.34 25.79 24.73 23.91 24.76 14.29 14.36 281.30 275.79 2.97 2.90 \n4.35 4.02 0.92 0.91 0.995 1.018 1.003 1.060 1.043 0.966 0.995 1.020 1.024 1.082 1.011 Table 1: A comparison \nof the dynamic instruction counts and the run times of executables using either our second-chance binpacking \napproach or George/Appel s graph-coloring approach. l We perform liveness analysis only once, before \nallo- cation, rather than once per round of coloring. For both linear scan and graph coloring, temporaries \nthat are live only within a single basic block are excluded from dataflow analysis, which greatly reduces \nbit vector sizes and makes repeated dataflow analysis unnecessary between coloring iterations. The latter \nsimplification is possible for both linear scan and graph coloring, because the temporaries generated \nby spill code insertion are live only within a single basic block. Glo- bal liveness information is not \naffected by such temporaries. When targeting the Digital Alpha, our graph-coloring allo- cator deals \nseparately with general-purpose registers and floating-point registers. On current Alpha implementations, \ndata moved between register files must go through memory, and each register operand of a given instruction \ncan only reside in one file or the other. With coloring, the non-linear costs of building the interference \ngraph and choosing tem- poraries to spill make it more efficient to solve the two smaller problems separately. \n(This is the approach used, for example, in the compiler for which George and Appel designed their algorithm.) \nOur linear-scan algorithm, on the other hand, processes both register files at once. 3.1 Run times We \ncompare the quality of generated code on a number of benchmarks. Table 1 presents run-time results both \nin terms of instruction counts and actual run times. For each metric, we also calculate the ratio of \nthe result under linear scan to the result under graph coloring. Larger ratios mean poorer performance \nof the linear-scan-produced executable. The target machine for these experiments is a Digital Alpha run- \nning Digital UNIX 4.0. Most benchmarks are from the SPEC92 suite, except for compress and m88ksim (SPEC95) \nand sort and WC (UNIX utilities). The instruction count results were obtained using the HALT tool within \nMachine SUIF to instrument each benchmark after code generation. The run-time results were obtained with \nthe UNIX time Benchmark alvinn doduc eqntott espresso fPPPP li tomatv compress m8sksim sort Second-chance \nbinpacking 0% 0.460% 0.001% 0.783% 18.561% 0% 0% 0% 0.030% 1.339% Graph coloring 0% 0.492% 0800% 0.148% \n13.397% 0% 0% 0% 0.045% 0.905% Table 2: Percentage of total dynamic instructions due to spill code for \neach allocation approach. If no spill code was inserted during register allocation, the percentage is \nreported as simply 0% . command on a lightly-loaded Alpha. Each time is the best of five consecutive \nruns. Overall, our approach produces executables that are of a quality near to those produced by coloring. \nTo help explain the variation in the instruction count results, Table 2 pre- sents a statistic indicating \nwhat percentage of the total dynamic instruction count was due to spill code inserted by the register \nallocator. This counts load, store, and move instructions inserted for allocation candidates only. Five \nof our benchmarks (alvinn, li, tomcatv, compress, and WC) had no spill code under either approach. For \nthese applications, the difference in the dynamic instruction counts in Table 1 is entirely due to the \nlack of move coalescing in our algorithm. We expect that we could remove much of this difference by following \nregister allocation by copy propagation and dead- code elimination optimizations. q evict loads q resolve \nloads evict stores resolve stores evict moves resolve moves Benchmark-scheme Figure 3. A categorization \nof the spill code inserted by each allocator Results for our binpacking approach are labelled with a \n-b while those for coloring are labelled with -c . For each benchmark, we normalize the counts to the \ntotal spill code inserted with binpacking. We have separated the eviction spill code inserted during \nour linear scan and the coloring algorithm s spill phase from the resolve spill code inserted during \nour resolution phase. For the applications with spill code, Figure 3 presents a detailed look at the \ncomposition of the spill code produced both by second-chance binpacking and by graph coloring. In both \ndoduc and m88ksim, binpacking produces less spill code than coloring. The majority of the difference \nis due to the insertion of extra spill loads during coloring. Our bin- packing produces more spill code \nthan coloring for eqntoft, espresso, fippp, and sort. A significant proportion of this increase appears \ndue to extra stores (resolution and evic- tion). These stores can, as in the case of eqntott, lead to \na large number of resolution loads. A review of the output code shows that a global optimization pass \nrun after alloca- tion can eliminate unnecessary load/store pairs as well as partially redundant spill \ninstructions using hoisting and sinking techniques. In order to evaluate the advantages of our second-chance \nbinpacking over traditional two-pass binpacking, we created a version of our allocator that assigns a \nwhole lifetime to either memory or register. This implementation still takes advantage of lifetime holes \nduring allocation. We observed two classes of applications with respect to the performance of this allocator. \nThe first, represented best by the word- count (WC) benchmark, contains those applications whose performance \ndegrades substantially under binpacking with- out second chance. The WC benchmark ran 38% slower (1445466 \nvs. 1046734 dynamic instructions) when allo- cated using two-pass binpacking than it did when allocated \nwith our second-chance approach. The WC benchmark has a large number of temporaries that are live throughout \na loop that contains a procedure call to an I/O routine. Our second- chance mechanism manages to allocate \nsome of the tempo- raries to caller-saved registers, evicting them just before the procedure call but \navoiding unnecessary stores. The two- pass binpacking approach, however, is not able to use the caller-saved \nregisters (there is no hole in a caller-saved reg- ister large enough to contain the lifetimes of the \ntemporaries Module (Benchmark) cvrin.c (espresso) tw1drv.f (fpppp) fPPPP.f(fPPPP) Average number of \nAllocation time (set) Register Interferencegraph Second-chance Graph coloring candidates edges binpacking \n245 1061 0.4 1.5 6218 51796 8.8 3.7 6697 116926 15.8 4.5 Table 3: A comparison of the allocation times. \nThe average number of register candidates and interference graph edges refer to the coloring allocator. \nThese numbers cover all coloring iterations. live across the call), thus evicting temporaries out of \nthe callee-saved registers. Since this algorithm does not avoid unnecessary stores, costly spill code \nis inserted inside the loop. The other class of applications, exemplified by eqn- rott, has almost identical \nperformance under two-pass bin- packing and second-chance binpacking (2783984589 vs. 2782873030 dynamic \ninstructions). The eqnfott benchmark spends a vast majority of its time in the procedure cmppt(), which \ncontains a very small number of temporaries and therefore requires no spilling.  3.2 Compile times To \nevaluate the compilation speed of the two methods, we timed both on representative modules from the benchmark \nset. Table 3 shows results obtained by timing only the core parts of the allocators on a lightly-loaded \nAlpha. In particu- lar, we record the time of day after setup activities common to both allocators, such \nas CFG construction, loop analysis, liveness analysis, etc., and then r&#38;ord the time of day again \nafter allocation. The difference in these two recorded times is summed over all procedures in a compiled \nmodule to pro- duce the times in Table 3. Each is the best of five consecu- tive runs. The table also \nincludes the average number of register candidates per procedure in the module and the average number \nof edges in their interference graphs. While the coloring allocator is actually faster on small prob- \nlems, its performance rapidly becomes worse on programs with lots of competing register candidates. These \nnumbers illustrate that a coloring allocator slows down significantly as the complexity of the interference \ngraph increases.  4 Related work The phrase linear scan was used by the developers of the C dynamic \ncode generator to describe the register allocator in their system [13]. Having tried graph coloring, \nthey developed a simpler method that scans a sorted list of the lifetimes and at each step considers \nhow many lifetimes are currently active and thus in competition for the available registers. When there \nare too many active lifetimes to fit, the longest active lifetime is spilled to memory and the scan proceeds. \nNo attempt is made to take advantage of lifetime holes or to allocate partial lifetimes. Nevertheless, \nin con- text of a run-time code generator, the improvement in com- pilation speed obtained by using linear \nscan instead of coloring justifies a modest decrease in run-time speed. Digital Equipment Corporation \nhas used a linear-scan algo- rithm for many years in the GEM optimizing code genera- tor, a compiler \nback-end used in several of its compiler products [l]. The GEM approach to binpacking and treat- ment \nof lifetime holes [3] was the starting point for our work on linear-scan allocation. Binpacking evolved \nfrom work done in the production quality compiler-compiler project at CMU [11,17]. However, the discovery \nof linear- scan register allocation at Digital was almost an accident: its first implementation was intended \nas a throw-away mod- ule, meant to be replaced by a more elaborate scheme. When the throw-away turned \nout to perform better than its more complicated replacement, it was shipped with the product instead \n191. Digital s allocator uses history preferencing , which allows load instructions to be omitted by \nremembering which values in memory are mirrored in registers. Our sec- ond chance method subsumes history \npreferencing and adds the dual optimization of avoiding a store instruction when a register s value can \nbe shown to exist in memory already or never be needed in memory again. Laurie Hendren and a group from \nMcGill University have experimented with an alternative representation for interfer- ence graphs which \nthey call cyclic interval graphs [8]. This data structure provides more fine grain information about \nthe overlap between two temporary lifetimes, especially those extending around a loop. Hendren s algorithm \ncovers points of maximal pressure with a fat cover, a set of non- overlapping intervals that can fit \ninto one register. This idea is very similar to binpacking. Hendren also introduces the concept of a \nchameleon interval, a temporary that is assigned different colors, or registers, at different points \nin its lifetime. In his recent book, Bob Morgan presents a hybrid approach to register allocation [12]. \nHe first runs a limiting pass which reduces the register pressure by introducing spill code for temporaries \nthat are live through loops. He then runs his register allocator in three phases: he starts by using \ngraph-coloring to allocate temporaries that are live across basic blocks. He then uses Hendren s representation \nand algorithm to allocate those local temporaries that can occupy the same registers as the global temporaries. \nHis final phase uses a standard local algorithm to allocate the purely local temporaries. [4] G. Chaitin \net al., Register Allocation via Coloring, Conclusions ComputerLanguages, 6, pp. 47-57,198l. Linear-scan \nmethods of register allocation are fast and effective. They can enable the interprocedural optimization \nof large programs, and they are appropriate for run-time code generation. They avoid the risk of the \ncompile-time performance degradation that graph-coloring methods suf- fer on certain program inputs. \nWe have presented and studied a new implementation of lin- ear-scan, called second-chance binpacking. \nThis approach performs register allocation and instruction rewriting in a single pass, and it pays more \nattention to spill code minimi- zation than other linear-scan approaches. We have made a fair comparison \nof this new method with a well-designed coloring algorithm and found linear scan to be competitive in \noutput quality and much less prone to slow down on com- plex inputs. We believe there remain ways of \ntuning the sec- ond-chance binpacking algorithm so that the run-time performance of generated code more \nuniformly matches that of a coloring allocator. 6 Acknowledgments We are grateful to Steve Hobbs, Bob \nMorgan, and August Reinig of Digital Equipment Corporation for their helpful discussions on the use of \nbinpacking in the GEM compiler. We would also like to thank Max Poletto of MIT for his explanation of \nthe use of linear scan in dynamic code gener- ation. This research was funded in part by a NSF Young \nInvestiga- tor award (grant no. CCR-9457779), a DARPA grant no. NDA904-97-C-0225, and research gifts \nfrom AMD, Digital Equipment, HP, Intel, and Microsoft. 7 References [l] D. S. Blickstein, P. W. Craig, \nC. S. Davidson, R. N. Faiman, K. D. Glossop, R. P. Grove, S. 0. Hobbs and W. B. Noyce, The GEM Optimizing \nCompiler System, Digital Equipment Corporation Technical Journal, 4(4):121-135, 1992. [2] P. Briggs, \nK. Cooper, and L. Torczon, Improvements to Graph Coloring Register Allocation, ACM Transactions on Programming \nLanguages and Systems, 16(3):428-455, May 1994. [3] C. K. Burmeister, K. W. Harris, W. B. Noyce and S. \n0. Hobbs, U.S. patent number 5,339,428. [5] G. J. Chaitin, Register Allocation and Spilling via Graph \nColoring, SZGPZAN Notices, 17(6):201-107, June 1982. [6] M. F. Fernandez, Simple and Effective Link-time \nOptimization of Modula-3 Programs, SIGPLAN Notices, 30(6):103-l 15, June 1995. [7] L. George and A. Appel, \nIterated Register Coalesc- ing, ACM Transactions on Programming Languages and Systems, 18(3):30&#38;324, \nMay 1996. [8] L. J. Hendren, G. R. Gao, E. R. Altman and C. Muk- erji, A Register Allocation Framework \nBased on Hierar- chical Cyclic Interval Graphs, Proc. 4th International Compiler Construction Conference, \npp. 176-19 1, October 1992. [9] S. 0. Hobbs, Personal communication, July 1997. [lo] U. Hoeltze, Adaptive \nOptimization for Self: Recon- ciling High Performance with Exploratory Programming, Ph.D. thesis, Stanford \nUniversity, March 1995. [ 111 B. Leverett, Register Allocation in Optimizing Com- pilers, Ph.D. thesis, \nCMU-CS-81-103, Carnegie-Mellon University, February 198 1. [ 121 R. Morgan, Building an Optimizing Compiler, \nDigital Press, Boston, 1998. [ 131 M. Poletto, D. R. Engler and M. F. Kaashoek, tee: a System for Fast, \nFlexible and High-level Dynamic Code Generation, SIGPLAN Notices, 32(5):109-121, May 1997. [14] M. Smith, \nExtending SUIF for Machine-dependent Optimizations, Proc. First SUIF Compiler Workshop, Stanford, CA, \npp. 14-25, January 1996. URL: http:// www.eecs.harvard.edu/machsuif. [IS] D. W. Wall, Global Register \nAllocation at Link Time, SIGPLAN Notices, 21(7):264-275, July 1986. [16] R. Wilson et al., SUIF: An Infrastructure \nfor Research on Parallelizing and Optimizing Compilers, ACM SIGPLAN Notices, 29 (1994), pp. 3 l-37. URL: \nhttp:// suif.stanford.edu. [17] W. Wulf, R. K. Johnsson, C. B. Weinstock, S. 0. Hobbs and C. M. Geschke, \nThe Design of an Optimizing Compiler, American Elsevier, New York, 1975.  \n\t\t\t", "proc_id": "277650", "abstract": "A <i>linear-scan</i> algorithm directs the global allocation of register candidates to registers based on a simple linear sweep over the program being compiled. This approach to register allocation makes sense for systems, such as those for dynamic compilation, where compilation speed is important. In contrast, most commercial and research optimizing compilers rely on a graph-coloring approach to global register allocation. In this paper, we compare the performance of a linear-scan method against a modern graph-coloring method. We implement both register allocators within the Machine SUIF extension of the Stanford SUIF compiler system. Experimental results show that linear scan is much faster than coloring on benchmarks with large numbers of register candidates. We also describe improvements to the linear-scan approach that do not change its linear character, but allow it to produce code of a quality near to that produced by graph coloring.", "authors": [{"name": "Omri Traub", "author_profile_id": "81100251902", "affiliation": "Harvard University, Division of Engineering and Applied Sciences, Cambridge, MA", "person_id": "P212171", "email_address": "", "orcid_id": ""}, {"name": "Glenn Holloway", "author_profile_id": "81100132825", "affiliation": "Harvard University, Division of Engineering and Applied Sciences, Cambridge, MA", "person_id": "P98433", "email_address": "", "orcid_id": ""}, {"name": "Michael D. Smith", "author_profile_id": "81100077421", "affiliation": "Harvard University, Division of Engineering and Applied Sciences, Cambridge, MA", "person_id": "PP39026087", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277714", "year": "1998", "article_id": "277714", "conference": "PLDI", "title": "Quality and speed in linear-scan register allocation", "url": "http://dl.acm.org/citation.cfm?id=277714"}