{"article_publication_date": "05-01-1998", "fulltext": "\n Exploiting Idle Floating-Point Resources For Integer Execution S.Subramanya Sastry Subbarao Palacharla \nJames E. Smith Computer Sciences Dept. Computer Sciences Dept. Dept. of ECE University of Wisconsin-Madison \nUniversity of Wisconsin-Madison University of Wisconsin-Madison sastry@cs.wisc.edu subbarao@cs.wisc.edu \njes@ece.wisc.edu Abstract In conventional superscalar microarchitectures with partitioned in- teger and \nfloating-point resources, all floating-point resources are idle during execution of integer programs. \nPalacharla and Smith [26] addressed this drawback and proposed that the floating-point subsystem be augmented \nto support integer operations. The hard- ware changes required are expected to be fairly minimal. To \nexploit these idle floating resources, the compiler must iden- tify integer code that can be profitably \noffloaded to the augmented floating-point subsystem. In this paper, we present two compiler al- gorithms \nto do this. The bmic scheme offloads integer computation to the floating-point subsystem using existing \nprogram loads/stores for inter-partition communication. For the SPECINT95 benchmarks, we show that this \nscheme offloads from 5% to 29% of the total dy- namic instructions to the floating-point subsystem. The \nadvanced scheme inserts copy instructions and duplicates some instructions to further offload computation. \nWe evaluate the effectiveness of the two schemes using timing simulation. We show that the advanced scheme \ncan offload from 9% to 41% of the total dynamic instruc- tions to the floating-point subsystem. In doing \nso, speedups from 3% to 23% are achieved over a conventional microarchitecture. Introduction Most current \nsuperscalar processors [17, 18, 16, 41 are based on the microarchitecture shown in Figure 1. The instruction \nfetch unit reads multiple instructions from the instruction cache, decodes them, and places them in instruction \nbuffers for execution by the integer and floating-point subsystems. The integer subsystem con- tains \nthe integer register file, integer instruction buffers, and a num- ber of integer functional units that \noperate on integer operands. The floating-point subsystem is similar to the integer subsystem except \nits functional units perform floating-point arithmetic, and it does not control the execution of load \nand store instructions. For the purpose of this work, the most important feature of this microarchitecture \nis the partitioning of processor resources into in- teger and floating-point subsystems. There are a \nnumber of rea- @ 1998 ACM 0-89791.9874/98/0006...$5,00 Figure 1: Datapath of a conventional microarchitecture. \nsons, both technical and historical, for this partitioning. The two most pertinent to our discussion \nfollow. Dividing the hardware into two simpler subsystems tends to make both control and data paths faster. \nIn each of the indi- vidual subsystems, there are fewer register Ele ports, fewer data bus sources and \ndestinations, and fewer alternatives for many control decisions, as compared with a processor where all \nthe units, registers and busses are shared. The result is a faster clock cycle. Using two subsystems \nallows specialization. In particular, the register files, data paths, and functional units can be of \ndifferent widths. In older machines, especially when hard- ware costs were much higher, this was very \nimportant. In- teger data could be half the width of floating-point data (or sometimes even less). This \nreason, however, is fast disap- pearing - the current trend is to make both integer and floating- point \ndata 64 bits wide. This trend reinforces the optimiza- tion described in this paper. The main disadvantage \nof the partitioned approach is that it can lead to an imbalance in resource usage. In particular, it \nleads to idle floating-point resources (instruction buffers, issue logic, and func- tional units) during \nexecution of integer programs. A large number of common programs (compilers, editors, databases, operating \nsys- tems) [28,22] are integer programs that execute very few (if any) floating-point operations. Palacharla \nand Smith [26] addressed this drawback and proposed a more general microarchitecture in which the floating-point \nsubsystem can also execute integer instructions. The hardware modifications required of existing architectures \nare minimal and are similar in spirit to the Intel MMX extensions to the IA-32 instruction set [20] and \nthe Sun SPARC Visual Instruc- tion Set (VIS) extensions [19]. The floating-point functional units are \naugmented to support simple integer and logical operations. The more complex operations, integer multiplication \nand division, are fairly rare and do not have to be included. The simple integer units can be embedded \nin the existing floating-point units and do not require additional busses. With today s transistor budgets, \nthis additional hardware cost is small. . Additional opcodes have to be added to the instruction set \nto control the new integer instructions. This is probably a more significant consideration because it \nrequires instruction set extensions and re-compilation. In our study, we used 22 extra opcodes. In the \nrest of the paper, the integer subsystem is called the msub- system and the augmented floating-point \nsubsystem is called the FP, subsystem. In order to use the proposed microarchitecture ef- fectively, \nthe compiler must identify integer operations that can be offloaded to the augmented floating-point subsystem, \ni.e., the com- piler has to partition the program by assigning instructions to the INT and FP, subsystems. \nThis paper presents and evaluates com- piler algorithms for achieving such code partitioning. The most \nim- portant goal of our algorithms is to maximize the utilization of the floating-point resources during \nexecution of integer code. The main source of difficulty in doing so is handling inter-partition commu- \nnication. Such communication can be achieved either through ex- isting program loads/stores or through \nthe use of copy instructions that move data between the INT and the FP= register files. Al- ternatively, \ncommunication can be entirely avoided by duplicating code. The problem is in striking the right balance \nbetween these communication mechanisms while maximizing the resultant bene- fits. In this paper, we present \ntwo code partitioning schemes. The first scheme, called the basic partitioning scheme only uses ex- isting \nprogram loads and stores for inter-partition communication. The second scheme, called the advanced partitioning \nscheme adds copy instructions and code duplication for inter-partition communi- cation. We use simulations \nto study the effectiveness of these com-piler schemes. Results for the SPEC95 integer benchmarks show \nthat the compiler can offload from 9% to 41% of the total dynamic instructions to the FP, subsystem. \nThis results in performance im- provements ranging from 2.5% to 23.1% on a 4-way (2 int + 2 fp) issue \nmachine. Before presenting further details of the proposed schemes, let us understand current microarchitectures \nin a little more detail. Con- sider the function shown in Figure 2 that computes the floating- point \nvector sum c[] = a[] + b[]. Instructions 13 and 14 are floating- point load instructions. Even though \nthey are called floating-point instructions, they actually issue from the integer instruction buffers \n(Figure 1) and execute in the load/store unit of the integer subsys- tem. This unit computes the effective \nmemory address and sends it to the data cache. The data cache retrieves the data (if there is a hit) \nor gets it from memory (if there is a cache miss) and sends the data over to the floating-point register \nfile - via the appropriate Load- data path shown in Figure 1. Instruction 15, a floating-point add void \nfp-vector-sum(int n, 11: move float c[l, 12: blez float aLI, $L23 : float b[l) 13: 1.8 ( 14: 1.s int \nI; 15: add.s 16: 9.9 for (i = 0; i < n; i++1 17: addu cl11 = a[il+b[il; 18: addu 19: addu 110: addu \n111: slt 112: bne $2, SO, SL23 C function to compute SL21: j $31 floating-point vector sum Assembly \nfor the C code Figure 2: Example floating-point code. instruction, executes entirely in the floating-point \nsubsystem. In- struction 16 is a floating-point store which computes the effective address in the load/store \nunit of the integer subsystem. The value to be stored is retrieved from the floating-point register file \nand gets written into the data cache. The only other instruction that will be of interest to us is the \nconditional branch instruction 112 which checks for loop termination and sends the outcome back to the \nin- struction fetch unit. If the above example were computing an integer vector sum instead of a floating-point \nvector sum, then the floating-point re- sources would be completely idle. However, if the floating-point \nadder could also perform integer adds, then the integer add could be offloaded to the floating-point \nsubsystem by using the same code as shown above, with the one exception that instruction I5 would have \na new opcode specifying integer add of floating-point regis- ters . In the rest of the paper, we will \nstrive for this type. of function offloading, as well as offloading of some branch decisions. The rest \nof the paper is organized as follows. Section 2 dis- cusses related work. Section 3 presents some terminology \nand de- scribes the data structure used by the algorithms. Section 4 dis- cusses the goals of the partitioning \nalgorithms. Section 5 presents the basic partitioning scheme used by the compiler, In Section 6, the \nadvanced partitioning scheme is presented. In Section 7, we present the evaluation methodology and then \npresent performance improvements resulting from the partitioning schemes discussed in Sections 5 and \n6. We present our conclusions in Section 8. 2 Related work A number of clustered/partitioned architectures \nfor exploiting fine grain instruction level parallelism have been proposed in the liter- ature [24, 15, \n13, 12, 27, 8, 91. All of these architectures attempt to reduce hardware complexity to obtain a faster \nclock cycle. In all these architectures, the hardware resources are uniformly parti- tioned across multiple \nclusters resulting in homogeneous clusters. However, in the superscalar architecture considered in this \npaper, the clusters are heterogeneous and only one of the clusters (INT subsystem) can address memory. \nSince all loads and stores always execute on one cluster, it is much harder to achieve balanced parti- \ntioning for integer programs, because memory addressing and ac- cess forms a big portion of program execution \nin most integer pro- gKUIlS. Although, in this example, the floating-point resources are nearly idle \neven when executing floating-point code! This is not uacommoa. aad the techniques proposed in this paper \ncaa probably be effective with floating-point code. In the context of VLIW machines (ELI, Multiflow TRACE, \nLC- VLIW), there has been prior work to partition code across chskr~ [14, 23, 5, 3, 111. Ellis BUG (bottom-up \ngreedy) assignment al- gorithm in the Bulldog compiler [14] assigns instructions to func- tional units \nin all clusters. The algorithm is based on the assump- tion that functional units are the only limiting \nresource in the ma- chine. Inter-cluster communication bandwidth is not considered a limiting resource.. \nIn his thesis [5], Banerjia shows that when inter- cluster communication resources are scarce, the excessive \ncopies introduced by BUG can hurt performance. Capitanio, Dutt, and Nicolau [3] present compiler schemes \nto achieve balanced code partitions while minimizing inter-cluster com- munication. However, this study \napplied the code partitioning tech- niques ody to straight-line loop bodies of floating-point codes. \nUnlike the BUG algorithm, the partitioning algorithms presented by Banerjia [5], Capitanio et al. [3], \nand Desoli [ll] attempt to maximize utilization of hardware resources in all clusters while minimizmg \ninter-cluster communication. In this respect, these al- gorithms am similar in spirit to our partitioning \nalgorithms. The main difference is that these algorithms are based on a statically- scheduled machine \nmodel with homogeneous clusters, whereas our algorithms are for a dynamically-scheduled superscalar machine \nwith heterogeneous clusters. This simplifies the problem since it is not necessary to schedule for individual \nissue slots. A further difference between our approaches is that these earlier algorithms do not consider \ncode duplication as a means of eliminating inter- cluster communication. In the Multicluster architecture \n[15], the hardware takes care of inter-cluster communication automatically. The compiler does not insert \nexplicit copy instructions. The hardware performs inter- cluster copying based on the architectural registers \nused by the operands of an instruction. The compiler performs code partition- ing by assigning registers \nto instruction operands. The primary objective of the partitioning algorithms is to achieve load balance \nbetween clusters. Since all hardware resources including the reg- ister Ele are partitioned equally between \nthe clusters, load balance is considered far more important than the the increased commu- nication between \nclusters. Again, code duplication is not used to eliminate some of this communication, though it is recognized \nas a possible improvement to their algorithms. The MMX extensions to the IA-32 instruction set [l] are \naimed at speeding up multimedia programs by Performing multiple bit, byte, or word operations in parallel \nlike a SIMD processor. RI maintain backward compatibility and avoid changes to the oper- ating system, \nthese extensions were implemented by augmenting the floating-point subsystem to perform these integer \noperations by using the floating-point registers to hold the integer data To ex- ploit these MMX extensions \nto their full potential, it is necessary to vector&#38;e sub-word integer operations. However, for programs \nthat do not have any SIMD parallelism (non-multimedia programs), the compiler can still profitably exploit \nthese MMX extensions in the manner described in this paper. 3 Terminology and Data Structures In this \nsection, we first describe the data structure used by the par- titioning algorithms. We then present \nsome terminology to aid sub- sequent discussion. The primary data structure used in code partitioning \nis the reg- ister dependence graph (RDG) which represents all the register de- pendences in a program. \nThe RDG is a directed graph which has a node corresponclmg to each static instruction in the program. \nThere is an edge from node 2); to node vj if instruction i produces a value that could be consumed by \ninstruction j. These edges are deter- mined by solving the reaching-defrnitiom dataflow problem [2]. \nLoad and store instructions are special-cased in the RDG to sim- plify the partitioning algorithms. Each \nload instruction is split into two nodes - one representing the load address and the other repre- senting \nthe loaded value. Similarly, each store instruction is split into two nodes - one representing the store \naddress and the other representing the store value. This is done because a load instruc- tion computes \nthe address in the INT subsystem, but the value can be loaded into either subsystem. Likewise, the value \nbeing stored can come from either the INT subsystem or the FP, subsystem. Figure 3 shows C code from \ninvalidate-for-call, a fre- quently executed function in the SPEC benchmark gee. The for loop in the \nprogram runs through all pseudo registers and does some bookkeeping for those that are invalidated by \nfunction calls. The figure shows assembly code compiled for a conventional mi- croarchitecture. The Egure \nalso shows the RDG for the program fragment. Nodes 2,8, and 11 correspond to load instructions and have \nbeen split. Address nodes have the suffix a while value nodes have the sufEx v . To show that both nodes \ncorrespond to a single program instruction, the split nodes have been enclosed in a bigger oval node. \nSimilarly, node 14 corresponds to a store instruction and has been split. Given the RDG, the backward \nslice of G with respect to a node v, denoted by Backward-Slice(G, v), is defined to be the set of all \nnodes from which v can be reached. Similarly, thefonvard slice of G with respect to v, denoted by Forward-SZice(G, \nv), is de- Ened to be the set of all nodes that can be reached from v. Note that backward slices, as \ndefined, do not go past load-value nodes. Similarly, forward slices do not go past address nodes. This \nis the primary difference from the traditional definition of slices [21]. Given this definition of a \nforward slice, all forward slices in a RDG terminate at memory addresses, call arguments, return values, \nbranch outcomes, or store values. Using these terminal nodes, we define various computational slices \nas follows. The L&#38;t slice of a program is defined to be the set of all instruc- tions that contribute \nto the computation of addresses for load/store instructions. Given the RDG G of a program, let LS(G) \n= Set of load/store address nodes in G. Then, LdSt slice = UvE~.q,$3ackward-Slice(G, v). In Figure 3, \nLS(G) = {2u, 8a, lla, 14a); the L&#38;t slice has been marked. A branch slice is defined to be the set \nof instructions involved in computing a branch outcome. This can be computed by starting from a branch \nnode and computing its backward slice. Store value, call argument, and return value slices are defined \nsimilarly. 4 Partitioning Goals In an out-of-order superscalar processor, instruction window size and \nissue width primarily determine how much instruction level parallelism QLP) can be exploited by the hardware. \nBigger the in- struction window and wider the issue width, more the ILP that can aThe RDG is based on \nthe assembly code shown. However, in the compiler, it is baaed on the intermediate representation of \nthe program. extern unsigned long regs-invalidated-by-call; for (regno = 0; regno < FIRST~PSEUIIO~REGISTER; \nregno++l if (regs-invalidated-by-call h (1 << regnol) C delete-equiv_regLregno); if (reg-tick[regno] \n>= 0) reg-tick[regnol++; LdSt SILe 1 Program fragment in C fromgcc 11: *O\"e $16, so 12: 13: 14: SL5: \n1W Sra andi $2, regs-invalidated -by-call II$2 = n&#38;.invalidated~by~cP 8 (I<< rqno) 15: 16: beq move \n17:18:19: j,E'sll delete-equiv-reg 110: addu Ill:112: 1W bltz 113: 114: addu SW re&#38;tlck(n@ml++ SL4: \n115: 116: addu slt $16. $16. 1 S2. S16. 66 I I re o++ , I $ P = repno < FIRST_PSEUD&#38;REGISTER 117: \nbne $2; SO,.SL5 Assembly code for the program Instruction format is : <op> <dsh, urcl>, <sct Z> Figure \n3: An example program fragment. be exploited. In the augmented architecture, since the FP, sub- system \nis capable of executing integer instructions, if properly ex- ploited, this effectively doubles the window \nsize and issue width for integer programs. Thus, our partitioning schemes concentrate on maximizing the \nutilization of the floating-point instruction window and issue logic while keeping to a minimum any resulting \ncommu- nication and instruction overheads. In our machine model, since only the INT subsystem can exe- \ncute loads and stores, all loads and stores are assigned to the INT partition. As discussed previously, \nthe MSt slice of a program computes load and store addresses. Potentially, portions of this LdSt slice \ncould be assigned to the FP, partition. However, since all memory addresses are ultimately needed in \nthe INT subsystem, this necessitates the use of copy instructions on some address com- putation paths. \nThis is undesirable since memory addressing and access tend to be on the critical path of most programs, \ninteger or floating-point. Hence, in our partitioning algorithms, we assign the complete LdSt slice of \na program to the INT partition. Calling conventions impose further restrictions on our schemes. These \nconventions require integer-valued arguments and return val- ues to be passed/returned in integer registers. \nSo, call argument and return value nodes are always assigned to the INT partition. Fur- ther, if call \nargument and return value slices are assigned to the FP, partition, copies would be required to adhere \nto calling con- ventions. If it is unprofitable to introduce these copies, these slices would instead \nbe assigned to the INT partition. The remaining computational slices, branch slices and store- value \nslices, are potential candidates for assignment to the FP, par- tition. Some of these slices can be assigned \nto the FP, partition without requiring any inter-partition communication. It is shown by Palacharla and \nSmith [26] (and is borne out by our simulations) that the LdSt slices of integer programs account for \nclose to 50% of all dynamic instructions executed. This puts an upper bound on the size of the FP,, partition \nthat our algorithms can identify. Calling conventions and communication overheads would reduce this size \nfurther. Based on these observations, we decided to let the partition- ing schemes greedily assign as \nmuch of the branch and store-value slice to the FP, partition as possible. The goal of the partition- \ning algorithms is to maximize the size of the FP, partition. The limitations of these greedy partitioning \nstrategies are discussed in Section 6.6. We are now ready to present details of our code parti- tioning \nschemes. The next section discusses the basic partitioning scheme. 5 Basic Partitioning Scheme In this \nsection, we present the basic partitioning scheme that at- tempts to partition the program without introducing \nextra instruc- tions for inter-partition communication. It achieves all inter-partition communication \nthrough existing program loads/stores. We first de- scribe the conditions that need to be satisfied by \nthe INT and FP, partitions to adhere to this restriction. We then describe a partition- ing algorithm \nthat identifies partitions satisfying these conditions. 5.1 Partitioning conditions Given a program P \nand its RDG G, the goal is to partition G into a INT partition, I(G), and a FP, partition, F(G), that \nsatisfy the following conditions: 1. F(G) and 1(G) are disjoint. 2. If v E F(G), then Backward-SZice(G,v) \nfl I(G) -0. For a node v E F(G), this condition specifies that v or any of its ancestors should not receive \nany value from I(G) via a register.  3. If v E F(G), then Forurard-SZice(G, V) n I(G) = 0. For a node \nv E F(G), this condition specifies that v or any of its descendants should not supply any value to I(G) \nvia a register.  The last two conditions are a manifestation of the restriction not to introduce any \nextra communication instructions in the program. It can easily be shown that failure to satisfy either \nof these two con-ditions necessitates the use of extra copy instructions to maintain correctness of the \ngenerated assembly code.  5.2 Partitioning Algorithm We now present a simple algorithm to find the largest \nset F(G) that satisfies the partitioning conditions. We aim for the largest set because the goal of our \nalgorithms is to maximize the size of the FP, partition. Let G, be the undirected graph corresponding \nto G, i.e. G, consists of the same vertices and edges as G, but the edges are undirected. Then, the partitioning \nconditions can be in- terpreted as: If v E F(G,), then v is not reachable from any node in I(G,). So, \nevery connected component in G, either belongs to I(G,) or F(G,) but is not shared between the two partitions. \nSince load/store address nodes, argument and return-value nodes are assigned to the INT partition, connected \ncomponents contain- ing these nodes are assigned to the INT partition. All other compo- nents are assigned \nto the FP, partition. These components contain instructions that compute only branch outcomes and store \nvalues. Consider the graph in Figure 4 which corresponds to the exam- ple presented in Figure 3. The \npartitions identified by the basic par- titioning algorithm are marked. The graph has four connected \ncom- ponents. One component consists of the nodes {llv, 12,13,14v}. This component computes the store \nvalue for the store instruction 114. Since this component does not contain any load/store address nodes, \nit is assigned to FP,. In contrast, all the other components contain load/store address nodes and hence \nare assigned to INT. Figure 4 also shows the partitioned assembly code. Integer instruc- tions that execute \nin FP, are shownin bold with a p suffix. The load and store instructions (Ill and 114) are italicized \nto point out that these instructions are converted to floating-point load and store instructions.  5.3 \nLimitations of the Basic Partitioning Scheme The basic partitioning algorithm is simple and efficients. \nHow- ever, it misses opportunities to assign more computation to the FP, partition because of the restriction \nnot to introduce extra instruc- tions. Consider the partitioning in Figure 4 again. The branch slices \n{1,15,16,17} and {1,15,2v,3,4,5} contain the address- ing instructions I1 and 115 and hence, could not \nbe assigned to FP,. However, if we relax the restriction on introducing extra in- structions in the program, \nwe could assign these branch slices to the FP, subsystem as shown below. Suppose the architecture has \nin- structions to copy values directly between the INT and FP, register files4. Then, copy instructions \ncan be inserted in the INT subsys- tem to copy the results of I1 and 115 to the FP, subsystem. This allows \nthe earlier branch slices to execute in FPa. Figure 5 shows the resulting assembly code and the associated \nRDG. In this ex- ample, copy instructions have enabled the offloading of five more instructions to FP,. \nSince 11, is outside the loop, copy overheads are incurred every loop iteration only for instruction \n115,. For this example, code duplication can be used to achieve the same partitioning as realized by \ninserting copy instructions. In the Linear in the number of nodes and edges of the RDG. %uch instructions \nin a number of instruction sets (e.g. MIPS [lo] and arepresentWha R). 122 C code fragment of our example \nshown in Figure 3, the loop induc- tion variable regno is used both for address computation as well as \nfor branch computation. By duplicating regno in FP,, the two pieces of code can proceed independently \nwithout any communication6. Figure 6 shows the assembly code and the associated RDG when this is done. \nIld and 115d are duplicated instructions and enable five more instructions (relative to the basic partitioning \nscheme) to be offloaded to the FP, subsystem. Since Ild is outside the loop, overheads are incurred each \nloop iteration only for instruction 115d. Calling conventions further limit the ability of the basic \nparti- tioning algorithm to offload computation to the FP, partition. All components containing argument \nand return value nodes are as- signed to the INT partition by the basic partitioning scheme. Copy instructions \ncan alleviate this problem too. One could let the par- titioning algorithm ignore the restrictions imposed \nby the calling conventions and later, when necessary, introduce copy instructions to adhere to these \nconventions. Thus, copy instructions and code duplication can achieve better code partitioning. However, \ncopy and duplicate instructions not only increase the size of the FP, partition, but can also increase \nthe total number of dynamic instructions executed, which can degrade performance. Care must be taken \nto minimize the drawbacks of copy and duplicate instructions. The advanced partitioning scheme to be \npresented in the next section uses a cost model to determine where copy instructions or duplicate code \nwill help. 6 Advanced Partitioning Scheme In this section, we study advanced partitioning techniques \nthat give better partitions than the basic partitioning scheme. As discussed previously, this is achieved \nthrough the use of copy instructions to achieve inter-partition communication and through code dupli- \ncation to eliminate inter-partition communication. However, it is important to minimize overheads introduced \nby these instructions. We now present a cost model that enables this. 6.1 Cost Model The cost model \nto be presented computes profitability of offload- ing integer instructions to FP, while taking into \naccount any over- heads introduced due to copies and duplicates. Intuitively, the ben- eEt from a copy \nor a duplicated instruction is the number of extra dynamic instructions that will execute in the FP, \nsubsystem as a result of the copy/duplicate. Given a RDG G, Let scopy be the set of nodes in G for which \ncopy instructions are inserted. Let SdUpl be the set of nodes in G which are duplicated. Let SC be the \nset of nodes in G that can be moved from INT to FP, as a result of the copies and duplicates. The nodes \nin S, execute in FP, yielding a bigger FP, partition. However, execution of nodes in Scopy and Sdupl \nintroduces over- head in the program. This is quantified by the following equations. Benefit = CvESf \nno Overhead = oco~~* Cv~s~.,~~ nWv) + odupl * ~~~~~~~~ - B(u) where B(I) : Basic block containing instruction \nI nB : Runtime execution count of basic block B 61%ere is control flow communication between the two \nthrough the shared fetch unit as shown in Figure 1. __ ----- _____------ \\ , 11: move $16, $0 1 $LS: \n, 12: 1W $2, regs_invalidated_by_call I : 13: sra $2, $2. $16 1'14: andi gr ;;, ;J; 15: bw 16: lllO\"e \n$41 $1; 17: jai delete-equiv-reg Ia: 1W 53. rextick 19: sll $2, $16, 2 110: addu $2, $2, $3 111: 1W SfO, \nOfPI 112: b1tr.a SfO. SL4 113: addu, c SfO. sro, 1 114: SW SfO, Of$2J $L4: 115: addu $16, $16, 1 \\ 116: \ns1t $2, $16, 66 117: bne $2, so, SL5 Figure 4: Basic code partitioning. LdSt Slice 11: lllO\"e $16. $0 \n1lc: cp~to~comp $16, Sf2 SL5: 12: IW Sf4, regs-invalidated-by-call 13: .S.,C Sf4. Sf4. bf2 14: uuli,a \n$f4, Sfl, 0x1 15: bwl.a ;:4,,:;, t&#38;4 16: mO\"e 17: jai delete-equiv-reg 18: 1-d $3, reg-tick 19: sll \n;2\", g,$; 110: addu 111: IW Sfb, OiSZJ 112: b1tr.c .wJ, G.4 113: adau,c OfO. SfO. 1 114: SW SfO, Of.%?1 \nSL4: 115: addu $16. $16, 1 115~: cp~to~comp $16, $f2 116: *lt,a Sf4, Sf2, 66 117: bn~,C Sf4. $0, SLS \n Figure 5: Partitioning with copy instructions. ocopy : Overhead of a copy instruction o&#38;pr : Overhead \ndue to duplication Then, Profit = Benefit -Overhead  It is beneficial to introduce copy and duplicate \ninstructions only if Profit > 0. Thus, the problem reduces to determining Scopy , S&#38;pl, and S, that \nmaximize Profit. To compute Profit, nB, the execution count of basic block B, needs to be estimated for \nall basic blocks. In this study, we obtained nn using basic-block executionprofrles. For functions that \nare not covered by the profile, we usedprobabilistic estimates for execution counts. If pn is the probability \nthat basic block B executes and dn is the loop nesting depth of B, then no is set to pn * 5dB. pn s are \ncomputed on the assumption that both directions of a branch are equally likely to be taken. The copy \nand duplication overheads, oco,, and o&#38;pi, were de- termined empirically. We experimented with different \nvalues for these parameters and picked the values that provided the best re- sults. For our benchmarks, \nwe empirically found that ocopy be- tween 3 and 6 and o&#38;pi between 1.5 and 3 yield the best results. \nNext, we discuss the heuristics the compiler uses to determine prof- itable Scopy, sduplr and SC. 6.2 \nCopying versus duplication The advanced partitioning algorithm can either duplicate an in- struction \nor insert a copy instruction. Code duplication avoids inter- partition communication whereas copy instructions \ncause inter-par- tition communication. However, when a node u is duplicated, all of its parents should \neither be duplicated or copy instructions should be inserted for them. If the parents are duplicated \ntoo, then the duplication effect fans out along the backward slice. This can be avoided if the result \nof u is copied instead. Thus, the decision of duplicating u depends on whether its parents communicate \nwith the FP, partition, and, if so, whether they are copied or dupli- cated. This decision can change \nwith any change in the status of these parents. A simple heuristic is presented below that makes these \ndecisions during a prepass of the partitioning algorithm. Let ~1,. . . , U.+ be the parents of v. Initially, \nduplxost(v) = IXI and copyinyzost(v) = oCopy* ng(,) for all nodes v. The duplication cost is ileratively \ncomputed as: dupkost(v) = odupl * nB(,,) + cf=, min(cof&#38;ngdost(ui), dUpl-COSt(Ui)) v is duplicated \nonly if dupkcost < copying-cost. This heuristic is based on the assumption that if v is to be duplicated, \nthen each 123 *1: move Ild: PQv.ra 12: SL5: lw 13: .x., Q 14: andi,a 15: b-&#38;a 16: move 17: L? 18: \n19: sll 110: addu Ill: lw 112: b1tz.a 113: l aau,a 114: SW SL4: 115: addu 115d: ddu, c1 116: l 1t,a 117: \nh*,a $16, $0 bf2. $0 Sf4, regs-invalidate~by-call Sf4. str. $f2 $f4, $f4, 0x1 g4, g, sr.4 delete-e&#38;v-reg \n$3, reg-tick $2. $16, 2 $2, $2, $3 SfO, OiS2J wo. bL4 wo. SfO. 1 SfO, OlS2) $16, $16, 1 Ff2. Sf2. 1 str, \n$f2, 66 Sf4. $0. $LS Figure 6: Partitioning with code duplication. of the parents of v either needs \nto be copied or duplicated. This can yield non-optimal solutions because irrespective of whether u is \nduplicated or not, a parent might still be copied/duplicated and hence v need not be charged with the \ncommunication overhead for that parent. If Odupl 2 ocopy, no node will be duplicated. So, we require \nthatOdupl < OCOpY. This is reasonable because code duplication can lead to inter-partition independence \nunlike copy instructions. 6.3 Algorithm for introducing copy instructions and du-plication code We are \nnow ready to present an algorithm that identifies sites to introduce copy instructions and duplicate \ncode to increase the size of the FP, partition. We restrict the algorithm to introduce copies only from \nINT to FP,. This restriction keeps the decision proce- dure simple and also simplifies the actual insertion \nof copies and duplicates. As a result, if a node u is assigned to INT, Backward- SZice(G, V) is also \nassigned to INT. There are two distinct phases of the algorithm. Initially, the LdSt slice is assigned \nto the INT partition. In the first phase of the algorithm, the INT partition is expanded to include instructions \nthat are not profitable for execution in the FP, subsystem. This expansion is done by analyzing the instructions \non the boundary between the INT and FP, partitions. The boundary is made up of INT nodes some of whose \nchildren are not in INT. For each child of a boundary instruction, the algorithm checks if it is beneficial \nto retain the child instruction in the FP, subsystem. If not, the boundary is expanded to include the \nchild in the INT partition. During the second phase of the algorithm, copies and dupli- cates are tentatively \nintroduced for instructions on the INT bound- ary. Then, for each connected component (in the undirected \nRDG) containing these copies and duplicates, Profit is computed using the cost model presented earlier. \nUnprofitable (Profit < 0) com-ponents are assigned to INT during this phase. The algorithm is presented \nbelow. 0: G = RDG for the function; 1: Assign LdSt slice to the INT partition; 2: B&#38;y = Boundary \nof the INT partition; 3: S = Non-INT children of nodes on B&#38;y; ,******* Phase 1 ******, 4: while \n(S#0) do { 5: Pick a node u from S; 6: Let P = FP, nodes in Backward-Slice(G,u); 7: Compute loss, the \nloss to FP, if P is assigned to INT; 8: if (loss<O) then { /* Expand bdry */ 9: Move P to INT and update \nB&#38;-y; 10 : Add FP, children of nodes in P to S; 11: } 12: elsif (loss=O) then /*Defer decision*/ \n13: Add FP, children of nodes in P to S; 14: Remove nodes in P from S; 15: } 16: Use Bdry to compute \nScopy and Sdupl; 17: Tentatively, introduce copies and duplicates in G for nodes in S,,,, and Sdvpl; \n18: Let G, = Undirected graph corresponding to G; 19: for each u in Scopy and sdupl do { 20: Let C = \nConnected component of G, containing 21; 21: Compute Profit for C; 22: if (Profit<O) { 23: Assign C \nto INT; 24: Remove copies and duplicates from C; 25: } 26: } The primitive step in the first phase of \nthe algorithm is the com- putation of loss if a FP, node u is moved to INT. As mentioned ear- 124 her, \nif zc is moved to INT, all FP, nodes in Backward-SZice( G, U) also get assigned to INT. loss is this \naccumulated loss and is com-puted as follows. P = Set of FP, nodes in Backward-Slice(G, U) = {v 1 v E \nBackward-SZice(G,u); v $ INT} Q = Boundary nodes that are parents of nodes in P = {v 1 v E B&#38;y; 3~ \nE P such that v is U S parent} Consider node u. It can be verified that for both these examples, loss \n= 1 for both u and v. Hence, the boundary of the INT parti- tion does not change. Let us now compute \nProfit for both these examples. For example 1, S, = {u, v}, Scopy = {z}, Profit = -2. For example 2, \nS, = {u, v,p, q}, SCOpy = {x}, Profit = 18. The reason for this behavior is because Phase 1 uses only \nLocal in- formation, i.e. while analyzing u, v is not examined. Further, only the immediate children \nof u are examined, not all its descendants. While computing loss, all nodes in P are considered to be \nin INT. Let us now examine the equation for loss and account for each of the terms there. In the first \nsummation, the Erst term(n,J arises because u no longer executes in FP,. If u has children in FP, and \nis assigned to INT, then u has to be copied if those children are to execute in FP,. The second term, \no(u), accounts for this overhead. The second summation accounts for changes in copying overheads of nodes \nin Q. For a node v E Q, a(v) is computed as follows. Since v is in INT , either: l v does not have any \nchild in FP,. In this case, v no longer needs to be copied/duplicated when P gets moved to INT. So, 6(v) \n= -overhead. Depending on whether v is copied or duplicated, overhead is either copying-cost(v) or duplication-cost(v). \nl v has at least one child in FP,. In this case, irrespective of what happens to P, there is no change \nin the status of v. So, 6(v) = 0. In line 12, if loss = 0, this is considered to be insufficient intor- \nmation to assign P to INT. The decision is deferred until children of nodes in P are examined. It is \npossible to make a better decision when these children are examined because a bigger portion of the graph \nis analyzed. At the end of Phase 1, the boundary of the INT partition will have stabilized. At this point, \nthe sets Scopy and Sdupl can be com-puted by examining the nodes on the boundary. S, is the set of nodes \nthat are not in INT. For this partitioning, Profit can be computed using the earlier specified cost model. \nHowever, this so- lution is not necessarily the best possible solution. It is possible to improve on \nthis solution further. The first phase of the algorithm expands the INT boundary by making decisions \nabout whether it is unp@table to move a node u (and its backward slice) from FP, to INT. However, if \nu is retained in FP, , it is not necessarily prof- itable. An example should make this clear. Example \n1 Example 2 Figure 7: Examples for Phase 1 of the advanced scheme. In the examples of Figure 7, suppose \nx has been assigned to INT. For both these examples, Bdry = {z},S = {u,v}. In Phase 1 of the algorithm, \nnodes u and u are successively examined. all nodes in Q are in INT since they are in B&#38;y. Thus, \nit is necessary to refine the solution further. This is done during Phase 2. Initially, copies and duplicates \nare tentatively intro- duced for all nodes in S,,, and Sdopl. Note that introducing these copies and \nduplicates disconnects the graph at several places. For example, in Figure 5, the copies 1, and 15, introduce \na new con- nected component (2,, 3,4,5,16,17, l,, 15,) in the undirected RDG. Let G, denote the undirected \nversion of the RDG. After the copies and duplicates are introduced, the cost model is applied to each \nindividual connected component of G, containing a copy or a duplicate instruction. All unprofitable (Profit \n< 0) components are assigned to INT and the copies and duplicates in that compo- nent are eliminated. \n 6.4 Interaction with calling conventions As discussed in Section 6.6, calling conventions require all \ninteger- valued arguments and return values to be passed/returned in integer registers. This constrains \nthe partitioning algorithms in how much code can be offloaded to FP,. One solution to get around this \nre- striction is to perform code partitioning by ignoring calling conven- tion restrictions and introducing \ncopies where necessary. However, it is important to evaluate the benefit in introducing such copies. \nLet us consider how call arguments (both actual as well as for- mal) are handled. Return value nodes \nare handled just like call argument nodes. Within a function, if the call arguments that are passed in \n(formal parameters) are required in FP,, these values have to be copied to FP,. Similarly, if the computation \nof the call arguments (actual parameters) takes place in FP,, then these values have to be copied to \nINT at call sites. This is the only case when copies are introduced from FP, to INT. For each formal \nparameter, a dummy node is introduced repre- senting the definition of the parameter. All these dummy \nnodes are pre-assigned to INT. Once this is done, the partitioning algorithm previously presented evaluates \nthe benefit of introducing copies for these dummy nodes automatically. Actual parameter nodes are handled \ndifferently. Initially, all computation of actual parameter values is assigned to FP,. During Phase 1, \nthe equation for loss is extended to account for copies re- quired for actual parameter nodes. If a node \nu E P is an actual parameter node, then the Erst term of the equation for this node changesfrom [nU + \n(Y(U)] to -copying-cost(u) because it is ben- eficial to move an actual parameter node to INT since a \ncopy is no longer needed for it. Further, during phase 2, when the cost model is applied to each connected \ncomponent (line 21 of the algorithm), the cost of introducing a copy from FP, to INT is considered an \nextra overhead in computing Profit. 6.5 Optimality Issues The advanced algorithm can yield non-optimal \nsolutions for a num- ber of reasons. First, as discussed earlier, the decisions for copying a node or \nduplicating it are made non-optimally. Second, during Phase 1, better solutions might be obtained by \nusing global infor- mation. Though the algorithm can yield non-optimal solutions, we found that these \nheuristics successfully yield bigger FP, partitions using very few copy and duplicate instructions. The \nnumber of ex- tra dynamic instructions executed due to copies and duplicates is less than 1% for most \nbenchmarks. Further, the increase in static code size is also negligible. 6.6 Limitations of the partitioning \nschemes A major underlying assumption in our schemes is that the floating- point subsystem of superscalar \narchitectures can be augmented to support integer operations wihwt affecting the latency of these op-erations, \ni.e. a single cycle add in INT will still take a single cycle in FP,. If the hardware does not support \nany single-cycle latency operations in the floating-point subsystem, then single-cycle result paths will \nhave to be added when single-cycle integer operations are supported. This potentially introduces an additional \nhardware cost. An alternative would be to modify the algorithms to account for the increased latency \nof integer operations when they are moved to FP,. However, in such a case, the resulting performance \nimprove- ments would be smaller. Both the partitioning algorithms presented earlier greedily as- sign \nas much computation as possible to FP, without considering whether this would underutilize the INT unit. \nThe rationale behind this decision was discussed in Section 4. The primary assump- tion there was that \nmost integer codes perform significant memory access. However, for functions that perform very little \nor no mem- ory access, this strategy can backfire. For example, the run func- tion from the compress \nbenchmark, that generates random numbers does not access memory at all. As a result, our partitioning \nschemes move the entire function from INT to FP,! However, for integer programs, we expect this kind \nof behavior to be rare. Nevertheless, the algorithms could be improved to consider load balance while \nperforming code partitioning. The cost model presented does not take into account the avail- ability \nof extra floating-point registers for register allocation. When some of the integer code is offloaded \nto FP,, this can reduce the register pressure on the integer register file and can thus reduce register \nspills/refills. However, at the same time, there might be an increase in register saves/restores across \ncalls. In our simulations, we found that there was a decrease in loads by 3.7% for go. At the other extreme, \nthere was an increase in loads of about 2.6% for gee. Considering that most spills/refills and saves/restores \nhit in the cache, these small changes in loads/stores might not be a significant performance factor. \nHowever, if these effects are accounted for in the cost model, better results might be obtained. In the \ncurrent schemes, all integer-valued arguments are passed in integer registers as required by calling \nconventions. If the par- titioning algorithms deem it profitable, call arguments are copied to/from FP,. \nBy performing interprocedural analysis, it might be possible to reduce some of the copy overheads across \ncalls by pass-ing integer arguments in floating-point registers. 7 Performance Results In this section, \nwe Erst present our evaluation methodology. We then present results for the effectiveness of the two \npartitioning schemes and the net performance improvement over a conventional microarchitecture. 7.1 Evaluation \nMethodology We used gee-2.7. I as the base compiler for our work. The com- piler was modified to generate \ncode for the extended SimpleScalar [7] instruction set which is based on the MIPS instruction set. The \nSimpleScalar instruction set was extended by using new opcodes to encode integer instructions executing \nin the floating-point subsys- tem. We used 22 new opcodes for our study. All integer operations except \ninteger multiply and divide are supported in the floating- point subsystem. Our simulation study shows \nthat except for ijpeg which has about 3% of integer multiplications and divisions, all other benchmarks \nhave negligible amount of these operations. Fur- ther, this keeps the hardware cost to a minimum since \ninteger mul- tiply and divide operations tend to be expensive (in terms of die area) to implement. Code \npartitioning is performed on the intermediate representa- tion of the program after all the initial machine-independent \nopti- mizations [Z] are complete. Register allocation is performed after code partitioning. Operands \nof instructions assigned to the FP, partition are allocated floating-point registers. We used a cycle-based \ntiming simulator derived from the Sim- pleSca.lar tool set [7]. The timing simulator models both a con- \nventional microarchitecture as well as a microarchitecture with the augmented floating-point subsystem. \nBoth microarchitectures are identical in all other respects. The machine parameters we used in our simulations \nare presented in Table 1. We used programs from the SPECint95 benchmark suite to con- duct our evaluation. \nThe benchmarks and the inputs used are given in Table 2. For the conventional microarchitecture, the \nbench- mark programs are compiled by the base compiler (unmodified gee-2.7.1). All the benchmarks are \ncompiled at the -03 optimiza- tion level which enables common subexpression elimination, loop invariant \nremoval, and jump optimizations among others. All the benchmarks were simulated to completion. 7.2 Percentage \nof computation offloaded to FP, Size of the FP-a partition 34 3a 30 ca, 28 e: a6 A t( 22 b se 16 14 \n12 10 8 6 4 2 0 Figure 8: Size of the FP, partition. Figure 8 shows the percentage of total dynamic \ninstructions of- floaded by the compiler for each of the benchmark programs. The graph shows the size \nof the FP, partition for both the basic and the Parameter 4-way I S-way Fetch width any 4 instructions \nany 8 instructions I-cache 64KB, Zway set-associative I 128 byte lines,1 cycle hit time,6 cycle miss \npenalty I Branch Predictor 1 McFarting s gshrue [25] with 32K 2-bit counters, 15 bit global historv I \nUnc&#38;&#38;ional control flow instructions predicted perfectly - ^__. 0 :--L.A:-.. Decode/Renamewidth \n1 any 4 instructions I ally 0 ,USU u.l ~ .I. .1*/n Issue win . 1 lo muro rp I 32 i&#38;32 fp ldow SIZE \n 1 Max. in-flight instructions 1 32 64 ReGe width 4 I 8 Functional Units 2Int+2Fpunits 4Int+4Fpuaita \nFunctional Unit Latency 6 cycle mul, 12 cycle div, 1 c-.>- C---^-r I Issue Mechanism up to 4 ops/cycle \nI --- out-of-orderissue I loads may execute when prior store addresses are known Physical Registers 48 \ni&#38;48 fp 80 i&#38;30 fp D-cache 32KB, Zway set-associative, write-back, write-allocate 32 byte lines,1 \ncycle hit time,6 cycle miss penalty one load/store port I two load/store ports Table 1: Machine parameters. \nBenchmark 11compress li I gee 1 m88ksim I go I tippeg I per1 Input II testin I browselsp I stmt.i I ctlraw, \ndhrybig I 2stone9.in I vigo.ppm I scrabbl.pI Table 2: Benchmark programs. Performance Improvements on \na 4-way machine advanced partitioning schemes. Because all the benchmark pro- grams are integer programs \nthat execute negligible floating-point Basic scheme operations, the bars in the graph correspond to \nthe amount of inte- Advanced scheme ger computation that the compiler is able to identify and offload \nto 19. the FP, subsystem. Overall, the compiler is successful in offload- 3 10. ing a sizable fraction \nof the total computation to the FP, subsystem. 16. 8 17. In the case of ijpeg, m88krim, compress, and \ngee, more than 20% LI IS. of the total computation is supported in the FP, subsystem. The i 14. i 13. \nP 12. graph also shows that the advanced partitioning scheme generates 4 Il. bigger partitions than \nthe basic scheme for all benchmarks. For go and compress, the partitions generated by the advanced parti- \ntioning scheme are almost twice the size of those generated by the basic scheme. Zjpeg benefits the most \nfrom the advanced scheme: the FP, computation increases from 10.7% to 32.1%. However, for li, the advanced \nscheme does not perform better than the ba- sic scheme because li is call intensive and has a number \nof small functions. While the advanced partitioning scheme might be able to of- Figure 9: Speedups on \na 4-way machine. fload more computation, the percentages must be judged in con- junction with the change \nin the instruction cache performance and the total number of instructions executed due to the extra instruc- \ndue to both the basic and advanced partitioning schemes are pre- tions introduced. Hence, we studied \nthe overhead introduced by the sented. Form88ksim, ijpeg, andcompress, improvements over 10% advanced \npartitioning scheme. For all the benchmarks, we found are achieved with the advanced partitioning scheme. \nIn the case of the change in static code size to benegligible. As aresult, there was m88ksim, an impressive \nimprovement of 23% is achieved with the very little change in instruction cache hit rates for all the \nbench- advanced partitioning scheme. Overall, with the advanced parti- marks. The increase in the number \nof dynamic instructions exe- tioning scheme, the hardware is capable of providing modest to cuted is \nalso small. The maximum increase is 4% for compress. impressive performance improvements. Copies account \nfor 3.4% and 0.6% is due to duplicates. Overall, As expected, performance increases as more instructions \nare these results show that the advanced partitioning scheme is success- offloaded to the FP, subsystem. \nHowever, the performance does ful in increasing the FP, partition sizes without introducing a lot of \nnot directly reflect the size of the FP, partitions for two reasons. overhead. First, the critical path \nof execution may not be affected by parti- tioning. For example, in programs that are dominated by loads \nand 7.3 Performance improvements on a 4-way issue machine stores, performance is largely determined by \nthe available cache bandwidth. Second, as discussed in Section 6.6, INT resources Figure 9 shows the \nperformance improvements obtained by the pro- could be underutilized due to load imbalance. This translates \nto posed microarchitecture over a conventional microarchitecture for lower performance than expected. \nFor example, for m88ksim, with a 4-way issue (2 int + 2 fp) machine. Performance improvements the advanced \nscheme, the INT subsystem is idle 12.4% of the CY- cles in which the FP= subsystem is executing one or \nmore instruc- tions. This partly explains why performance only hnproves by about 2.6% even though the \nsize of the partition increases by 12%. This problem also occurs to a lesser degree in ijpeg. The graph \nalso shows that except for li and m88ksim, the ad- vanced partitioning scheme yields much better performance \nim- provements than the basic partitioning scheme. In the case of li, the increase in the size of the \nFP, partition is very small. For m88ksim, load imbalance seems to be the problem as mentioned earlier. \n 7.4 Performance improvements on a 8-way issue machine Performance Improvements on a B-way machlne Figure \n10: Speedups on a &#38;way machine. Figure 10 shows the performance improvements on a I-way is- sue (4 \nint + 4 fp) machine. As expected, the improvements are much smaller because the issue width of INT gets \nwithin the range of the average parallelism in a program. So, the extra issue band- width of the FP, \nsubsystem is not exploited as much. Programs like m88kshn, which have enough parallelism are able to \nexploit the presence of a bigger instruction window and wider issue and execution bandwidth,  7.5 Applicability \nto floating-point programs We also experimented with the partitioning schemes on some floating- point \nprograms from the SPEC92 and SPEC95 benchmark suites. For floating-point programs, there is not as much \nroom for obtain- ing performance improvements since the floating-point subsystem is utilized for Performing \nfloating-point computation. Since our algorithms do not attempt to balance load acmss the partitions, \nwe expected slowdowns when these algorithms were applied to floating-point programs because the offloaded \ninteger instructions would compete with the floating-point instructions for issue and execution resources. \nHowever, for all but one of the benchmarks that we tried, there was negligible change (slowdown/speedup) \nin running time because the algorithms attempt to offload only branch and store-value slices to Pp,. \nFor floating-point programs, most of the store-value slices and some of the branch slices are already \nin FP,. In these programs, integer computation offloaded to PP, is very small. However, for one of the \nSPEC92 benchmarks, ear, as much as 18% of integer (branch and store-value) computation was offloaded \nto PP, that resulted in 18% speedup on a 4-way issue machine. Thus, it appears that the algorithms presented \nhere can be applied to floating-point programs as well without hurting perfor- mance and even improving \nperformance in certain cases. It might be possible to further improve performance on these programs if \nthe algorithms are improved to account for load balance across the partitions. 8 Conclusions In current \nsuperscalar processors, all floating-point resources are idle during the execution of integer programs. \nThis problem can be alleviated if the floating-point subsystem is augmented to execute integer instructions \nand the compiler can identify integer instruc- tions that can execute in such an augmented floating-point \n(Fp,) subsystem. The required modifications are minor and the resultant micmarchitecture stays similar \nto a conventional microarchitecture. However, compiler support is required to identify integer compu- \ntation that can execute in the FP, subsystem. We presented and evaluated two code partitioning schemes \nto do this and evaluated them. Our evaluation shows two things. First, for our benchmarks, the compiler \nis able to offload a significant fraction, from 9% to 41%, of the total computation in integer programs \nto the FP, sub- system. Second, the partitions identified by the compiler can speed up programs by 3% \nto 23% over a conventional 4-way issue super- scalar Processor. For three of the benchmarks, compress, \nijpeg, and m88luim, the performance improved from 11% to 23%. Hence, we believe that with minimal hardware \nsupport, idle floating-point resources on current superscalar processors can be profitably ex- ploited \nby the compiler to speed up integer programs. 9 Acknowledgements This work was supported in part by NSF \nGrants MIP-9505853 and MIP-9307830 and by the U.S. Army Intelligence Center and Fort Huachuca under Contract \nDABT63-95-C-0127 and ARPA order no, D346. The views and conclusions contained herein are those of the \nauthors and should not be interpreted as necessarily repre- senting the official policies or endorsements, \neither expressed or implied, of the U. S. Army Intelligence Center and Fort Huachuca, or the U.S. Government. \nWe would like to thank Prof. Charles Fis- cher, Prof. Susan Horwitx, Satish Chandra, Amir Roth, Glenn \nAm- mons, Yiannakis Sazeides at UW-Madison and Anurag Acharya at UCSB for providing us with useful comments \non earlier drafts of this paper. Thanks arc due to Sanjiv Banerjia for providing us with chapters of \nhis thesis and pointing us to other related work. We would also like to thank the anonymous referees \nfor their comments and suggestions that helped improve the content and presentation of the paper. References \n[l] Alex Peleg, Sam Wilkie, and Uri Weiser. How Intel Built MMK Tech- nology.Communication offhe ACM, \n40(l)%-38, January 1997. [2] Alfred V. Aho, Ravi Se&#38;i, and Jeffrey D. Ullman. Compilers : Ptin- ciples, \nTechniques and Took Addison Wesley, 1988. [3] Andrea Capitanio, Nikil Dutt, and Alexandra Nicolau. Partitioned \nRegister Files for VLIWs: A Preliminary Analysis of Tradeoffs. In Proceedings of the 25th Annual Intemational \nSymposium on Microar- chitecntre, pages 292-300, December 1992. [4] Ashok Kumar. The HI-PA8000 RISC CPU: \nA High Performance Out-of-OrderProcessor. In Proceedings ofthe Hot Chips VIII, pages9-20, August 1996. \n [5] Sanjeev Banerjia. Instruction ScheaWng And Fetch Mechanisms For Clustered VLIWPmcessors. PhD thesis, \nDept. of Electrical and Com- puter Engineering, North Carolina State Ut&#38;rsity, 1998. [6] Digital \nEquipment Corporation. Alpha Architecture Handbook, Ver-sion 3, October 1996. [7] Doug Burger, Todd M. \nAustin, and Steve Bennett Evaluating Future Microprocessors: The SimpleScalar Tool Set. Technical Report \nCS- TR-96-1308 (Available from http://www.cs.wisc.edu/trs.html), Uni- versity of Wisconsin-Madison, July \n1996. [8] Eric Rote&#38;erg, Quinn Jacobson, Yiannakis Sazeidcs, and Jim Smith. Trace Processors. In \nProceedings of the 30thAnnual Inkrnational Symposium on Microarchitecture, pages 138-148, December 1997. \n[9] G. S. Sohi, S. E. Breach, and T. N. Vijaykumar. Muhiscalar Proces- sors. In Proceedings of the 22ndAnnual \nInternational Symposium on Computer Architecture, pages 41a25, June 1995. [IO] Gerry Kane and Joe Heir&#38;h. \nMIPS RISCArchikcture. Prentice Hall, 1992. [l l] Giuseppe Desoli. Instruction Assignment For Clustered \nVLIW DSP Compilers: A New Approach. Technical Report HPL-98-13, HP Labs, January 1998. [12] Gregory A. \nKemp and Manoj Franklin. PEWS: A Decentmlixed Dy- namic Scheduler for ILP Processing. In Proceedings \nof the Intema- tional Conference on Parallel Processing, volume I, pages 239-246, 1996. [13] J.A.Fisher. \nVery Long Instruction Word Architectures and ELI-512. In Proceedings of the 10th Annual International \nSymposium on Com- puter Architecture, pages 140-150, June 1983. 1141 John R. Ellis. Bulldog: A Compiler \nfor VLIWArchitectures. PhD thesis, Yale University, 1985. [15] Keith I. Fsrkas, Paul Chow, Norman P. \nJouppi, and Zvonko Vranesic. The Multicluster Architecture: Reducing Cycle lime Through Psxti- tioning. \nIn Proceedings of the 30th Annual International Symposium on Micrvarchikcture, pages 149-159, December \n1997. [16] Jim Keller. lhe 21264: A Superscalar Alpha Processor with Out-of- Order Execution, October \n1996. 9th Annual Microprocessor Forum, San Jose, California [17] Linley Gwennap. MIPS RlCOOO Uses Decoupled \nArchitecture. Mi- croprocessor Report, 8(14), October 1994. [18] Linley Gwennap. UltraSpam Unleashes \nSPARC Performance. Micrv-processor Report, 8(13), October 1994. [19] Linley Gwennap. UltraSpam Adds Multimedia \nInstructions. Micro-processor Report, 8(16), December 1995. [20] Linley Gwennap. Intel s MMX Speeds Multimedia \nMicmprocessor Report, 10(3), March 1996. [21] Mark Weiser. Program Slicing. IEEE Transactions on SopVare \nEngi- neering, 10(4):352-357, July 1984. [22] Ann Marie Grixxafti Maynard, Colette M. Donnelly, and Bret \nR. Ol- sxewski. Contrasting Characteristics and Cache Performance of Tech- nical and Multi-User Commercial \nWorkloads. In Proceedings of the Siath International Conference on Architectural Supportfor Pmgram-m$ \nLanguages and Operating Systems, pages 145-156, October [23] P.Geoffrey Lowney,Stefan Freudenberger, \nThomas Karzes, W.D.Lichtenstein, Robert P. Nix, John S. O Donnel, and John C.Ruttenberg. The Multiflow \nTrace Scheduling Compiler. The Journal of Supercomputing, 7(1):51-142, May 1993. [24] Robert P. Colwell, \nRobert P Nix, John J. O Donnell, David B. Pa- pworth, and Paul K. Rodman. A VLIW Architecture for a Trace \nScheduling Compiler. IEEE Transactions on Computers, 37(S), Au-gust 1988. [25] Scott McFdng. Combining \nBranch Predictors. Technical Report DEC WRJ., Technical Note TN-36, DEC Western Research Labora- tory, \n1993. [26] Subbarao Palacharla and J. E. Smith. Decoupling Integer Execution in Superscalar Processors. \nIn ProceedingJ of the 28#hAnnual Interna- tional Symposium on Micraarchitecture, pages 285-290, November \n1995. [U] Subbarao Palacharla, Norman R Jouppi, and J. E. Smith. Complexity- Effective Supermlar Processors. \nIn Proceedings of the 24th Annual International Symposium on Computer Architecture, June 1997. [28] Zarka \nCvetanovic and Dileep Bhandarkar. Charactetixation of Alpha AXP Performance Using TP and SPEC Workloads. \nIn Pmceedings of the 21st Annual International Symposium on Computer Architecture, April 1994.  \n\t\t\t", "proc_id": "277650", "abstract": "In conventional superscalar microarchitectures with partitioned integer and floating-point resources, all floating-point resources are idle during execution of integer programs. Palacharla and Smith [26] addressed this drawback and proposed that the floating-point subsystem be augmented to support integer operations. The hardware changes required are expected to be fairly minimal.To exploit these idle floating resources, the compiler must identify integer code that can be profitably offloaded to the augmented floating-point subsystem. In this paper, we present two compiler algorithms to do this. The <i>basic</i> scheme offloads integer computation to the floating-point subsystem using existing program loads/stores for inter-partition communication. For the SPECINT95 benchmarks, we show that this scheme offloads from 5% to 29% of the total dynamic instructions to the floating-point subsystem. The <i>advanced</i> scheme inserts copy instructions and duplicates some instructions to further offload computation. We evaluate the effectiveness of the two schemes using timing simulation. We show that the advanced scheme can offload from 9% to 41% of the total dynamic instructions to the floating-point subsystem. In doing so, speedups from 3% to 23% are achieved over a conventional microarchitecture.", "authors": [{"name": "S. Subramanya Sastry", "author_profile_id": "81100217492", "affiliation": "Computer Sciences Dept., University of Wisconsin-Madison", "person_id": "PP39078389", "email_address": "", "orcid_id": ""}, {"name": "Subbarao Palacharla", "author_profile_id": "81100590656", "affiliation": "Computer Sciences Dept., University of Wisconsin-Madison", "person_id": "P270893", "email_address": "", "orcid_id": ""}, {"name": "James E. Smith", "author_profile_id": "81100084769", "affiliation": "Dept. of ECE, University of Wisconsin-Madison", "person_id": "PP39026477", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277709", "year": "1998", "article_id": "277709", "conference": "PLDI", "title": "Exploiting idle floating-point resources for integer execution", "url": "http://dl.acm.org/citation.cfm?id=277709"}