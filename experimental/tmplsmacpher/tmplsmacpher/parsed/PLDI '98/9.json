{"article_publication_date": "05-01-1998", "fulltext": "\n Type-Based Alias Analysis* Amer Diwan Kathryn S. McKinley J. Eliot B. Moss Department of Computer Science \nDepartment of Computer Science Stanford University, Stanford, CA 94305 University of Massachusetts, Amherst, \nMA 010034610 (650)723-4013 Abstract This paper evaluates three alias analyses based on program- ming \nlanguage types. The first analysis uses type compati- bility to determine aliases. The second extends \nthe lirst by using additional high-level information such as field names. The third extends the second \nwith a flow-insensitive analy- sis. Although other researchers suggests using types to dis- ambiguate \nmemory references, none evaluates its effective- ness. We perform both static and dynamic evaluations \nof type-based alias analyses for Modula-3, a statically-typed type-safe language. The static analysis \nreveals that type com- patibility alone yields a very imprecise alias analysis, but the other two analyses \nsignificantly improve alias precision. We use redundant load elimination (RLE) to demonstrate the ef- \nfectiveness of the three alias algorithms in terms of the oppor- tunities for optimization, the impact \non simulated execution times, and to compute an upper bound on what a perfect alias analysis would yield. \nWe show modest dynamic improve- ments for (RLE), and more surprisingly, that on average our alias analysis \nis within 2.5% of a perfect alias analysis with respect to RLE on 8 Modula-3 programs. These results \nil- lustrate that to explore thoroughly the effectiveness of alias analyses, researchers need static, \ndynamic, and upper-bound analysis. In addition, we show that for type-safe languages like Modula-3 and \nJava, a fast and simple alias analysis may be sufficient for many applications. 1 Introduction To exploit \nmemory systems, multiple functional units, and the multi-issue capabilities of modem uniprocessors, compil- \ners must reorder instructions. For programs that use pointers, the compiler s alias analysis dramatically \naffects its ability to reorder instructions, and ultimately performance. Alias anal- ysis disambiguates \nmemory references, enabling the com- The authors can be reached electronically via Internet addresses \ndi-wandcs.stanford.edu, {mckinley,moss} @cs.umass.edu. This work was supported by the National Science \nFoundation under grants CCR- 9211272 and CCR-9525767 and by gifts from Sun Microsystems Labora- tories, \nInc., Hewlett-Packard, and Digital Equipment. Kathryn S. McKinley is suppotted by an NSF CAREER Award \nCCR-9624209. Amer Diwan was also supported by the Air Force Materiel Command and ARPA award num- ber: \nF30602-95-C-0098. 8 1996 ACM 0-8979%987.4/98/0006...$5.00 piler to reorder statements that do pointer \naccesses. Despite its importance, few commercial or research com- pilers implement non-trivial alias \nanalysis. Three reasons alias analysis is not implemented are: (1) Many alias anal- yses are prohibitively \nslow and thus impractical for produc- tion use. (2) The alias analyses in the literature require the \nentire program (or some representation of it), which inhibits separate compilation and compiling libraries. \n(3) Most alias analyses have been evaluated only statically, and thus we do not know the effectiveness \nof these algorithms with respect to the optimizations that use them. To address these concerns, this \npaper explores using fast alias analyses that rely on pro- gramming language types. While prior work \n[l, 61 mentions using type compatibility for alias analysis, none evaluates the idea or presents the \ndetails of an algorithm. This paper describes and evaluates three fast alias analy- ses based on programming \nlanguage types. The tirst analy- sis ( IjyeDecl) uses type compatibility to determine aliases. The second \n(Field?lpeDecl) uses other high-level properties, such as field names to improve on the tirst. The third \n(SM- FieldQpeRefs) improves the second by incorporating a flow- insensitive pass to include the effects \nof variable assignments and references. This pass is similar to Steensgaard s algo- rithm [32]. We statically \nevaluate our alias algorithms using the num- ber of alias pairs (the traditional method). We also evaluate \nTBAA based on its static and dynamic effects on an optimiza- tion, In addition, we evaluate TBAA with \nrespect to an upper bound on the same optimization. Each of the evaluation met- rics reveals different \nstrengths and weaknesses in our alias algorithms, and we believe this range of metrics, and espe- cially \nupper-bound analysis, is necessary to understand the effectiveness of any alias analysis. Our static \nevaluation reveals that the simplest type-based alias analysis is very imprecise, but that for our Modula-3 \nbenchmarks, the other two alias analyses significantly reduce the number of intraprocedural aliases of \na reference to on av- erage 3.4 references (ranging from .3 to 20.8). We find that TBAA is much less \neffective for interprocedural aliases. We also evaluate TBAA by measuring the static and sim- ulated \nrun-time impact on an intraprocedural optimization that depends on alias analysis: redundant load elimination \n(RLE). RLE combines loop invariant code motion and com- mon subexpression elimination of memory references. \nTBAA andRLE combine to improve simulated program performance modestly, by an average of 4%, and up to \n8% on a DEC Alpha 3000-500 [12] for 8 Modula-3 benchmarks. Wealso compareTBAA to an upper bound that \nrepresents the best any alias analysis algorithm could hope to do for RLE. This comparison shows that \na perfect alias analysis could at most eliminate an average of 2.5% more heap loads. In addi- tion, we \nmodify TBAA for incomplete programs and demon- strate, using RLE, that it performs as well as it does \non com- plete programs. These results and TBAA S fast time complex- ity suggest that TBAA is a practical \nand promising analysis for scalar optimization of type-safe programs. The remainder of this paper is \norganized as follows. Sec- tion 2 describes our type-based alias analysis algorithms. Section 3 presents \nour evaluation methodology, and uses it to evaluate TBAA. Section 4 extends and evaluates TBAA for incomplete \nprograms. Section 5 discusses related work in alias analysis. Section 6 concludes. 2 Type-Based Alias \nAnalysis This section describes type-based alias analyses (TBAA) in which the compiler has access to \nthe entire program except for the standard libraries. TBAA assumes a type-safe pro- gramming language \nsuch as Modula-3 [25] or Java [33] that does not support arbitrary pointer type casting (thisfeature \nis supported in C and C++). We begin with our terminology, and then discuss using type declarations, \nobject field and ar- ray access semantics, and modifications to the set of possible types via variable \nassigmnents to disambiguate memory ac- cesses. 2.1 Memory Reference Basics Table 1 lists the three kinds \nof memory references in Modula- 3 programs, their names, and a short description. Table 1: Kinds of Memory \nReferences 1 Notation I D.f 1 Name I oualifv 1 Description I 1 Access field f of obiect 13 1 P1 1 Derefeience \n1 Dereference pointer-p - p[ i] ) Subscript ( Arrayp withsubscript i We call a non-empty string of memory \nreferences, for exam- ple aA . b [ i I . c, an accesspath (dP) [22]. Without loss of generality, we assume \nthat distinct object fields have different names. We also define: J3v (PI: The static type of dP p, Subtypes(T): \nThe set of subtypes of type T, which includes T. In Modula-3 and other type-safe languages, an object \nof type T can legally access objects of type Subtypes (T). Each of our alias analyses refines the type \nof objects to which an dP (memory reference) may refer. If two dPs may have the same type, then the analyses \ndetermines they may access the same location. l hese types of memory references are, of course, not unique \nto Modula- 3. TYPE T = OBJECT f, g: T; END; Sl = T OBJECT . . . END; S2= T OBJECT . . . END; S3= T OBJECT \n. . . END; VAR t: T, s: Sl; u: s2; Figure 1: Type Hierarchy Example 2.2 TBAA Using Type Declarations \nTo use type declarations to disambiguate memory references, we simply examine the declared type of an \naccess path dP, and then assume the dP may reference any object with the same declared type or subtype. \nWe call this version of TBAA, l)peDecl. More formally, given two dPs p and q, Z)pe- Decl (p, q) determines \nthey may be aliases if and only if: Subtypes (me (p)) rl Subtypes (Type (9)) # 8. Consider the example \nin Figure 1. Since Sl is a subtype of T, objects of type T can reference objects of type S 1. Thus, Subtypes \n(me (t)) rl Subtypes (Qpe (s)) # Q) Subtypes (Qpe (t)) rl Subtypes (I&#38;e (u)) # 0 Subtypes (Qpe (s)) \nrl Subtypes (?) pe (u)) = 0 In other words, t and s may reference the same location, and t and u may \nreference the same location, but s and u may not reference the same location since they have different \ntypes. Note that ?LpeDecl is not transitive. Table 2: Fieldl)peDecl (dP 1, dP 2) Algorithm Case AP 1 \nAP 2 PieldTypeDecl (AP 1, AP 2) 1 P P hue 2 P.f q.g (f = g) A FieJdTypeDecZ (p, 4) 3 P.f 6 AddressTaken \nCp . f ) A 2.3 Using Field Access Qpes We next improve the precision of 74rpeDecI using the type declarations \nof fields and other high level information in the program. We call this version of type-based alias analysis \nFieldQpeDecl. It distinguishes accesses such as t . f and t . g, f # g, that WeDecl misses. The FieldQyeDecl \nal- gorithm appears in Table 2. Given dP 1 and dP2, it returns true if dP 1 and dP2 may be aliases. It \nuses AddressTaken, which returns true if the program ever takes the address of its argument. For example, \nAddressmen (p . f) is true if the program takes the address of field f of an object in the set %eDecl \n(p). AddressTaken (q [ i I ) returns true if the program takes the address of some element of an array \nof q s type. In Modula-3, programs may take the addresses of mem- ory locations in only two ways: via \nthe pass-by-reference parameter passing mechanism, and via the WITH statement, which creates a temporary \nname for an expression. For sim- plicity we assume that aggregate accesses, such as assign- ments between \ntwo records, have been broken down into ac- cesses of each component. The seven cases in Table 2 determine \nthe following. 1: Identical dPs always alias each other. 2: Two qualified expressions may be aliases \nif they access the same field in potentially the same object. 3-4: A pointer dereference may reference \nthe same location as a qualified or subscripted expression only if their types are compatible and the \nprogram may take the ad- dress of the qualified or subscripted expression. 5: In Modula-3, a subscripted \nexpression cannot alias a qualified expression. 6: Two subscripted expressions are aliases if they may \nsub- script the same array. Field?LpeDecl ignores the actual subscripts. 7: For all other cases of dPs, \nincluding two pointer deref- erences, FieldQpeDecl uses OpeDecl to determine aliases. Java programs \nwould have similar rules. For C++ pro- grams, the rules must be more conservative to handle arbi- trary \npointer casts and pointer arithmetic. 2.4 Using Assignment QpeDecl is conservative in the sense that \nit assumes that the program uses types in their full generality. For instance, pro- grams often use list \npackages that support linking objects of different types to link objects of only one type. We thus im- \nprove on l)peDecl by examining the effects of explicit and implicit assignments to determine more accurately \nthe types of objects an dP may reference in a flow-insensitive manner. We call this algorithm SMmeRefs \n(Selectively Merge Type References). Unlike Z)peDecl, which always merges the de- clared type of an dP \nwith all of its subtypes, SMITLpeRefs only merges a type with a subtype when a statement assigns some \nreference of subtype S to a reference of type T. As an example, consider applying TjpeDecl to the following \npro- gram given the type hierarchy in Figure 1: VAR t: T := NEW (I ); s: St := NEW (Sl); Since TypeDecl \nonly considers declared types, it assumes that t and s may reference the same location because it is \nsemantically correct for objects of type T to reference objects of type Sl. By inspecting the code however, \nit is obvious that t and s never reference the same location since there is no explicit or implicit assignment \nbetween the two. SMlllpe- Refs proves independence in this situation as follows: if the program never \nassigns an object of type S 1 to a reference of (* Step 1: put each type in its own set *) for all pointer \ntypes T do Group := Group + {{T}} (* Step 2: merge sets because of assignments *> for all implicit and \nexplicit pointer assignments, a : =b, do Ta:= me(a); Tb:= Type(b); ifTa#Tb then let Ga,Gb E Group,suchthat \nTa E Ga,Tb E Gb Group:=Group-{Ga}-{Gb}+{GaUGb} (* Step 3: Construct TypeRefsTable *) for all types t \ndo let g E Group, t E g TypeRefsTable (t) = g rl Subtypes (t) Figure 2: Selective Type Merging type \nT (directly or indirectly), then t and s cannot possibly be aliases. Notice that if there is any such \nassignment, SM- QpeRefs assumes that dPs of type T may be aliased to dPs of type S 1. We call these assignments \nmerges. Figure 2 presents the algorithm to selectively merge types.2 This algorithm produces a Il)lpeRefsTable \nwhich takes a declared type T as an argument and returns all the types potentially referenced by an dP \ndeclared to be of type T. Given two dP p and q, SM?LpeRefs (p,q) determines they may be aliases if and \nonly if: WeRefsTable (Z&#38;e (p)) n VpeRefsTable (?Lpe (q)) # 0 In Figure 2, each set S = {Tl, . . \n. , Tk} in Group represents an equivalence class of types such that an dP with a declared type T E S \nmay reference any objects of type Ti E S. For example, given the set S = {Tl,T2} E Group, dPs with declared \ntype Tl may reference any object of type Tl or T2. Step 1 initializes Group, such that each declaredtypeis \nin an independent set and an dP declared with type T is thus assumed to reference only objects of type \nT. Step 2 exam- ines all the assignment statements and merges the type sets if the types of the left \nand right hand sides are different.3 Step 2 does not consider the order of the instructions and is therefore \nAow insensitive. Step 3 then filters out infeasible aliases from Group, creating asymmetry in the SMTypeRefs \nrelationship.4 For instance, an dP with declared type T in Figure 1 may reference objects of type T or \ntype sl, but an dP declared as Sl may not reference objects of type T. The final result of Step 3 is \nthe WeRefsTable. Figure 3 uses the the type declarations in Figure 1 to il- lustrate how the selective \nmerging algorithm works, The A more precise but slower formulation maintains a separate group for each \ntype. In our experiments, the difference between the two variations was insignificant. 3Step 2 is similar \nto Steensgaard s algorithm [32]. 41f we took Steensgaard s algorithm [32] and applied it to user defined \ntypes, it would not discover this asymmetry. VAR sl: Sl := NEW (Sl); ~2: S2 := NEW (S2); ~3: S3 := NEW \n(S3); t: T; BEGIN t := sl; (* Statement 1 *) t := ~2, (* Statement 2 *) END; Figure 3: Example to Illustrate \nSMvpeRefs Figure 4: Selective Merging for Figure 3 VAR declarations declare and initialize variables \nto newly al- located objects of their declared types. Step 1 thus initial- izes each declared type in \na set of its own, as shown in Fig- ure 4(a) where each oval represents a set in Group. Fig-ure 4(b) shows \nGroup after Step 2 merges types T and Sl, the types for the first assignment; and Figure 4(c) shows that \nthe second assignment causes Step 2 to merge S2 with T and S 1. S3 remains in a set by itself. Step 3 \nof the merge algo- rithm then creates asymmetry for the subtype declarations in the QpeRefsTable, as \nshown in Table 3. Notice SMQpeRefs determines dPs declared to be of type T may not reference objects \nof type ~3, but ?h>eoecl must assume they may. Table 3: QpeRefsTable for Figure 3 Type TypeRefsTable \n(Type) T 1 T,Sl,S2 We obtain the final version of our TBAA algorithm SMField- Y&#38;peRefs (Fields+Selectively \nMerge Type References) by us- ing SM?lpeRefs for QpeDecl in the FieldnpeDecl algo-rithm in Table 2. \n2.5 Complexity The complexity of this type-based alias analysis (TBAA) is dominated by step 2 of SM @peRefs. \nThis step makes a sin- gle linear pass through the program and at each pointer as- signment unions two \nsets of types. The complexity of TBAA is thus O(n) bit-vector steps, where n is the number of in- structions \nin the program. Each bit-vector step takes time pro- portional to the number of types in the program. \nThe time to use the results of the TBAA may, of course, be more than lin- ear time, For instance, computing \nall the may-alias pairs us- ing TBAA (or any otherpoints-to analysis) takes O(e2) time, where e is the \nnumber of memory expressions in the program.  3 Evaluation This section evaluates type-based alias analysis \nusing static and dynamic metrics, and a limit analysis. We first review the strengths and weaknesses \nof static and dynamic metrics, and thus motivate our limit analysis. Static Evaluation. The majority \nof previous work on alias analysis [2, 4, 6, 7, 9, 15, 20, 21, 22, 30, 32, 351 mea- sures static properties, \nsuch as the sizes of the may alias and points-to sets. Static properties enable comparisons between the \nprecision of two alias analyses using the size of their static points-to sets; the smaller the set the \nmore precise the analy- sis. Static properties have, however, two main disadvantages. (1) Static properties \ncannot tell us if the analysis is effective with respect to its clients. For example, even if the alias \nsets are small, the analysis may not differentiate the pointers that will enable optimizations to improve \nperformance or increase the effectiveness of other analyses. (2) Static properties do not enable comparisons \nbetween the eflectiveness of two alias analyses with different strengths and weaknesses. For exam- ple, \nthe size of the points-to sets of two analyses may be the same, but the analyses may disambiguate different \npointers. A static analysis that compares the resulting number of opti- mization opportunities remedies \nsome of this problem. Dynamic Evaluation. A few researchers recently eval- uated alias analyses by measuring \nthe execution-time im- provement due to an optimization that uses alias analysis [19, 36, 8, 171. Using \nrun-time improvements complements static metrics, since run-time improvements directly measure the impact \nof the alias analysis on its clients (usually com- piler optimizations). However, one of their disadvantages \nis that the results are specific to the given program inputs. Limit Evaluation. Both static and dynamic \nevaluation have an additional significant shortcoming: these properties do not tell us how much room \nfor improvement there is in the alias analysis (except in the unusual case of an alias anal- ysis that \ndisambiguates all memory references). We would like to know if the aliases really exist at run-time, \nand if any imprecision in the alias analysis causes missed opportunities for optimizations or other clients \nof the analysis. To detect imprecision and its impact, we also use a run-time limit anal- ysis to determine \nmissed optimization opportunities and their causes for a given program input. No previous work on alias \nanalysis uses this metric. The remainder of this section is organized as follows. Sec- tions 3.1 and \n3.2 describe our experimental framework and benchmark programs. Section 3.3 presents the static alias \npairs for our analyses. Section 3.4 presents the simulated run-time improvements due to our alias analysis \nfor redun- dant load elimination. Section 3.5 evaluates the room for im- provement in our analysis. Table \n4: Description of Benchmark Programs Figure 5: Compilation Framework 3.1 Environment Figure 5 ihustrates \nour compilation framework. The front end reads a Modula-3 module and generates a file contain- ing a \ntyped abstract syntax tree (AST) for the compiled mod- ule, The whole program optimizer (WPO) reads in \nthe ASTS for a collection of modules, analyzes and transforms them, and then it writes out the modified \nAST for each module and a file with the corresponding low-level stack machine code. The stack representation \nis the input language for a back end based on GCC. WPO implements all optimizations and analy- ses presented \nin this paper.  3.2 Benchmarks For each benchmark in our suite, Table 4 gives the num- ber of non-comment, \nnon-blank lines of code. For the non- interactive programs, Table 4 also gives the number of in- structions \nexecuted, the percent of instructions that are mem- ory loads from the heap, and the percent of instructions \nthat are memory loads from the stack and global area (other). None of these programs were written to \nbe benchmarks, but other researchers have used several of them in previous studies [16, 101. Table 4 \ncontains the data for the origi- nal programs (i.e., without the optimizations proposed here) but with \nGCC S standard optimizations turned on, which in- clude register allocation and instruction scheduling \n(except for m2 tom3). Due to a compiler bug in GCC, we were unable to perform the standard optimizations \non m2 t om3, which ex- plains its unusually large number of other loads. The num- bers in Table 4 do \nnot include instructions or memory refer- ences from the standard libraries. 3.3 Static Evaluation Table \n5 evaluates the relative importance of the three TBAA: TypeDeel: TBAA using only type declarations; FieldType- \nDecl: TBAA using ?jvpeDecl and field declarations; and SM- FieldQpeRefs: TBAA using FieldmeDecl and assignment \nstatements. The References column gives the total number of heap memory references in the source of the \nbenchmark pro- grams. For each of the analyses, the table contains the num- ber of local (L Alias) and \nglobal (G Alias) alias pairs. Local alias pairs are heap memory references within the same pro- cedure \nthat may alias each other, and global alias pairs are heap memory references not necessarily within the \nsame pro- cedure that may alias each other. Since each memory refer- ence trivially aliases itself, we \nexclude this pair. Note that since SMFieldTypeRefs is strictly more powerful than Field- I&#38;eDecl, \nand FieldTypeDecl is strictly more powerful than ?SrpeDecl,we can use static metrics to compare the three. \nFrom the table, we see that TypeDecl performs a lot worse than FieldQpeDecl, and that flow-insensitive \nmerging us- ing SMl?ieldI@peRefs offers little improvement over Field- I)lpeDecl. SMField?)lpeRefs improves \nlocal and global alias pairs on postcard, and the number of global aliases for m3 cg. On average, each \nheap reference may alias 4.7 other intraproceduralreferences using TypeDecl, 3.4 references us- ing FieldQpeDecl, \nand 3.4 references using SMFieldQpe- Refs. The range is from 0.3 to 20.8 references for SMField- QpeRefs. \nOn average, each heap reference may alias 54.1 other interprocedural references using TypeDecl, 12.7 \nrefer- ences using FieldTypeDecl, and 12.7 references using SM- FieldQpeRefs. The range is from 2 to \n27.7 references for SMF ieldTypeRefs. The number of interprocedural aliases is much higher than the number \nof intraprocedural aliases, sug- gesting that TBAA is probably too imprecise for interproce- dural optimizations. \nIn the next two sections, we show that even though our analysis does not disambiguate all intrapro- cedural \nmemory references (i.e., the local aliases are greater than zero), it may be precise enough for some \napplications.  3.4 Optimization Results This section measures the static and simulated execution-time \nimpact of TBAA on redundant load elimination (RLE). We first describe our implementation of RLE, and \nthen show its impact on execution time. Section 3.5 then describes a limit analysis that demonstrates \nthat with respect to RLE, there is Program format dfomat WrjtP.-I+klP. -L------n k-tree dom m2tom3 postcard \nm3cgL Table 5: Alias Pairs I I TypeDecl FieldTpeDecl -_ GAlim 1 GAh ReferencesT.Aliaf-_ 1 ----LAlias \n1 177 I 206 15 221 4.5L , _ I , ---, 1.56 554 2665 1 293 1 1286 1 171_._ 3x3 2089 1I 235 1 507 1 I 31n \nI 2322 14 464 _ 17.2 I 444 1 --10830 719 3811 162:6 612 213,I1 74144 . 177.X __ wiss.--- _. . 800 932 \n29550 589 21802 904 19036 41856 18824 25048 1038 4208 30890 1623 5278 4515 16521 1409449 6154 121476 \nSMFieldTjpeRefsLAlia~ 1 GAli= 133 I 2w ---, 293 1 1286 235 1 507 74 464 719 3811 1328-_-. 965: . --.J \n589 21802 18826 25048 1615 5262 6153 120525 is available on every path to s. RLE therefore improves \nper- formance by enabling the replacement of costly memory ref- nl erences with fast register references. \nSince RLE Operates on memory references its effectiveness depends directly on the quality of the alias \ninformation (and also on the back end). To t 3 enable RLE across calls, RLE is preceded by a mod-ref \nanaly- := t[il := lIj] sis which summarizes the access paths that are referenced and 4 modiied by each \ncall. For example, in order to hoist a mem- C&#38; ory reference Out Of a 100~ COutaining a Call, TBAA \nneeds   \\?7- Figure 6: Eliminating Loop Invariant Memory Loads ~~~~-~~~~ Figure 7: Eliminating Redundant \nMemory Loads little or no room for improvement in TBAA. 3.4.1 Redundant Load Elimination Redundant load \nelimination (RLE) combines variants of loop invariant code motion (similar to register promotion [S]) \nand common subexpression elimination [ 11, which most optimiz- ing compilers perform. RLE differs from \nclassic loop invari- ant code motion and common subexpression elimination in that it eliminates redundant \nloads instead of redundant com- putation. We expect RLE to be a profitable optimization since loads are \nexpensive on modem machines and architects ex- pect they will only get more expensive [18]. RLE hoists \nmemory references out of loops if the reference is loop invariant and is executed on every iteration \nof the loop, leaving it up to the back end to place the hoisted memory ref- erence in a register. For \nexample in Figure 6, the access path a. b^ is redundant on all paths, and loop invariant code mo- tion \nmoves it into the loop header. As shown in Figure 7, RLE also replaces redundant memory expressions by \nsimple variable references, which the back end may place in a reg- ister. A memory expression at statement \ns is redundant if it to know whether the call changes the value of the memory reference. Note that even \nthough RLE uses interprocedural mod-ref information, it does not eliminate redundant loads across procedure \nboundaries. 3.4.2 hpact of TBAA on RLE Table 6 gives the number of access paths that RLE removes statically \nin each of our benchmark programs for each variant of TBAA: IlypeDecl, FieldQpeDecl, and SMFieIdQpeRefs, \nBy comparing Table 6 and Table 5, we see that the differ- ences between the number of local alias pairs \nis the strongest indicator of optimization opportunities for RLE. In partic- ular, the big differences \nbetween the number of alias pairs for IIfrpeDecl and Field llpeDecl result in an increase in the number \nof redundant loads found by RLE. In contrast, the reductions in the number of alias pairs between Fieldme- \nDecl and SMField?LpeRefs does not change the number of redundant loads found by RLE. (These reductions \nare how- ever smaller than the others.) Table 6: Number of Redundant Loads Removed Statically We also \nmeasured execution times using a detailed (and validated [.5]) simulator for an Alpha 21064 workstation \nwith one difference: rather than simulating an SK primary cache we simulated a 32K primary cache to eliminate \nvariations due to conflict misses that we observed in an 8K direct mapped 111 Figure 8: Impact of RLE \ncache. Also, we only measured the execution time spent in user code since that is the only code that \nwe were able to analyze. Execution times are normalized with respect to the execution time of the original \nprogram without RLE, but with all of Gee s optimizations. (GCC eliminatesIEdUUdaUt loads without any \nassignments to memory between them.) Figure 8 illustrates the simulated execution time impact of TBAA \non RLE relative to the original execution time. The graph has three bars for each non-interactive benchmark. \nEach bar represents the execution time due to RLE and a dif- ferent alias analysis: TypeDecl (types only), \nFieldQpeDecl (types and fields), and SMFieldQpeRefs (types, fields, and merges). TBAA enablesRLE to improve \nprogram performance from 1% to 8%, and on average 4%. Since RLE is just one of many optimizations that \nbenefits from alias analysis, the full impact of alias analysis on execution time should be higher. Also, \ncontrary to what the data in Table 5 and Table 6 suggest, the threevariants of TBAA have roughly the \nsame performance as far as RLE is concerned. These results make two important points. First, a more \nprecise alias analyses is not necessar- ily better; it all depends on how the alias analysis is used. \nSecond, static metrics, such as alias pairs are insufficient by themselves for evaluating alias analyses. \n 3.5 Comparing TBAA to an Upper Bound How much precision does TBAA lose in order to achieve its fast \ntime bound? It is easy to contrive examples where TBAA fails to disambiguate memory references while \nmany other alias analyses succeed. This section demonstrates, using a limit study, that for RLE and our \nbenchmark programs, there is little to be gained from an alias analysis that is more precise t.hTBAA. \nFigure 9 compares heap loads that are redundant at run time before and after applying RLE. A redundant \nload is when two consecutive loads of the same address load the same value in the same procedure activation. \nWe measure Figure 9: Comparing TBAA to an Upper Bound . Figure 10: Source of Redundant Loads after Optimizations \nthese loads using ATOM[31], a binary rewriting tool for the Alpha. We instrument every load in an executable, \nrecord- ing its address and value. If the most recent previous load of an address is redundant with the \ncurrent load, we mark it as redundant. (Elsewhere we describe this process in more detail [13].) In Figure \n9, the black bars give the fraction of heap references that are redundant in the original program. The \nwhite bars give the fraction of heap references that are redundant after TBAA and RLE (this fraction \nis with respect to the original number of heap references). These results are specific to program inputs. \nFigure 9 shows that our optimizations eliminate between 37% and 87% of the redundant loads in these programs. \nMoreover, for 6 of the 8 benchmark programs, only 5% or fewer of the remaining loads are redundant. However, \nslisp and ktree still have many redundant loads. To un- derstand the source of all the remaining redundant \nloads, we manually classilied them as follows: 1. Encapsulation: RLE could not eliminate a redundant \nexpression because it was implicit in our high-level (AST) intermediate representation. For example, \nthe subscript expression for an open array involves an im- plicit memory reference to the dope vector. \nConditional: RLE did not eliminate a redundant expres- sion because it was only partially redundant, \ni.e., redun- dant along some paths but not along others. Partial re- dundancy elimination would catch \nthese. Breakup: RLE did not eliminate a redundant expression because it consisted of multiple smaller \nexpressions and our optimizer does not do copy propagation. Alias failure: TBAA did not disambiguate \ntwo memory references. Rest: we don t know the reason why RLE did not elimi- nate the redundant loads \nsince we did not determine the reason for the entire list of redundant expressions (which is labor intensive). \n The first category is due to a limitation of representation, not TBAA or RLE. Categories 2 and 3 are \nlimitations in our implementation of RLE, rather than TBAA. The fourth Cate-gory, alias failure, corresponds \nto limitations of TBAA. The fithcategorymay bea limitation of RLEOrTBAAOrtherep- resent&#38;ion. Each \nbar in Figure 10 breaks down the Redun- dant after Optimizations bar from Figure 9 into the above five \ncategories. Figure 10 illustrates that Encapsulation (dope vector ac- cesses to index open arrays) is \nthe most significant source of the remaining redundant loads. Figure 10 also shows that we did not encounter \na single situation when optimization failed due to inadequacies in our alias analysis. Those redundant \nloads that could be due to failed analysis are categorized as Rest, and on average, are less than 2.5% \nof the remaining loads. Thus, for RLE on these programs and their inputs, there is not much room for \nimprovement in our simple and fast alias analysis. 3.6 Summary of Results This section evaluated TBAA \nusing four different metrics: l Number of static alii pairs. l Run-lime improvement due to an optimization \nthat uses TBAA(RLE). l Number of opportunities exposed by TBAA for RLE. l An upper-bound for TBAA with \nrespect to RLE. Each of these four metrics exposes different information about TBAA. The first metric, \nnumber of static alias pairs, tells us two things. (1) For our benchmark programs, SM- FieldQpeRefs offers \nlittle or no precision over Fieldwe- Decl. (2) FieldmeDecl is potentially a much better alias analysis \nthan TQpeDecl. Even though FieldQpeDecl of-fers little performance improvement over QpeDecl for RLE, \nFieldlIlpeDecl should probably be the algorithm of choice since it does gives more precise results (without \nmuch added complexity) which may be important for other optimizations that use alias analysis. The second \nmetric, run-time improvement, indicates the how much an optimization or analysis really matters to the \nbottom line: performance. Our experiments find that the ma- jority of the run-time improvement comes \nfrom TypeDecl. Field llpeDecl improves performance only slightly. The re- sults also illustrate that \nthe run-time improvement due to our analysis and optimization is relatively smalk on average 4% improvement. \nIf run-time improvement is the only metric we use, then we might conclude that TBAA is a very impre- \ncise alias analysis. However, upper-bound analysis reveals that TBAA in fact performs about as well as \nany alias anal- ysis could perform with respect to RLE and our benchmarks programs. The third metric, \nnumber of opportunities exposed by TBAA for RLE, reveals that FieldQpeDecl enables many more opportunities \nfor RLE than QpeDecl. However, our run-time measurements find that FieldllpeDecl is only slightly better \nthan meDec1. If we had used only run-time improvements to evaluate our analysis we might conclude that \nQpeDecl is the algorithm of choice. However, the num- ber of opportunities metric tells us that FieldQpeDecl \nis in- deed significantly better than YQpeDecl. Perhaps with differ- ent benchmark inputs Field IlpeDecl \nmay improve perfor- mance significantly more than meDec1. Finally, the upper-bound analysis for RLE using \nTBAA re- veals that a more precise alias analysis for RLE would yield few benefits: there is little or \nno room for improvement in TBAA with reSpeCttoRLE. To summarize, the four metrics tell us different informa- \ntion about the different levels of TBAA. For this reason, we feel that all of these metrics should be \nused together in a thor- ough evaluation of an alias analysis (or for that matter any compiler analysis). \n3.7 Cumulative Results Figure 11 shows the cumulative impact of two sets of op- timizations: method invocation \nresolution [14] plus inlin- ing (Mnv + Inlining) and RLE. Method resolution uses TBAA (and other analyses) \nto help resolve method invoca- tions on object fields and array elements. While we expected method resolution \nand inlining to expose more opportunities for RLE, they did not. On studying the interactions of RLE \nwith method invocations and inlining using limit analysis, we found that inlining exposes more redundant \nexpressions but they are usually conditional (Section 3.5). Thus, while partial redundancy elimination \ncan eliminate these redundant loads, RLE cannot. We plan to implement and evaluate partial re- dundancy \nelimination of memory expressions in future work.  4 Analyzing Incomplete Programs Most prior pointer \nalias analyses for the heap are whole- program analyses, i.e., the compiler assumes it is analyzing the \nentire program, including libraries, making a closed world assumption. Many situations arise when the \nentire program is not available: for instance, during separate compilation, or compiling libraries without. \nall their potential clients, or com- Figure 11: Cumulative Impact of Optimizations piling incomplete \nprograms. In unsafe languages such as C++, alias analyses must as- sume that unavailable code may affect \nall pointers in arbitrary ways. For type-safe languages like Modula-3 and Java, the compiler can use \ntype-safety and a type-based alias analysis to make stronger type-safety assumptions about unavailable \ncode. It can assume that unavailable code will not violate the type system of the language. For example, \nconsider the following procedure declaration using the types declared in Figure 1. PROCEDUREfQxS.1; q:S2)=... \nIn an unsafe language, if some of the callers of f are not available for analysis, the compiler must \nassume that p and q are aliases. For a type-safe language, a type-based analysis can safely assume that \np and q are not aliases since they have incompatible types. Itvo components of TBAA rely on properties \nother than the type system of the language: AddressZhken and type merg- ing. Since unavailable code may \npass the address of a qual- ified expression or subscript expression to avaiktble code we revise Addresslbken \nas follows. AddressTaken (p) is true: 1. if the program ever takes p s address (for instance to pass \nit by reference or as part of a WITH), or 2. if f is a pass-by-reference formal and p and f have the \nsame type.  Since Modula-3 requires the types of pass-by-reference formals and actuals to be identical, \nthe second clause needs to check only for type equality, not type compatibility. Note that this new definition \nof AddressTaken considers instruc- tions in the program for available code (1) and considers only the \ntype system for unavailable code (2). Since unavailable code may cause merges of types, we make SMFieldQpeRefs \nmore conservative at merges. We merge any two types (related by the subtype relation) to Figure 12: Open \nand Closed World Assumptions which it has access since unavailable code may assign them. Since Modula-3 \nuses structural type equivalence, unavailable code can access most types because it can construct its \nown copy of the types. Exceptions to this ability are Branded types in Modula-3. These types essentially \nobserve name equivalence and may not be reconstructed by unavailable code. Figure 12 compares the simulated \nrun-time improvement due to redundant load elimination using TBAA when assum- ing that the entire program \nis available (closed world) and assuming it is not available (open world). Notice that in our experiments, \nthe open-world assumption has an insignificant impact on the effectiveness Of TBAA With reSpeCt to RLE. \nThis result however reflects the results in Table 6, since SM- FieldTypeRefs, which is most affected \nby the open world as- sumption, does not enable any additional opportunities for RLE over FieldTQpeDecl. \nWith respect to the static metrics, we found that they were the same for the open-world and closed-world \nassumptions with one difference: M3CG had about 80 more alias pairs (interprocedurally) with the open- \nworld assumption than with the closed world assumption. However, the additional alias pairs did not reduce \nthe effec- tiVeneSSOf RLE.  5 Related Work Alias analysis must consider an unbounded number of paths \nthrough an unbounded collection of data, and is therefore harder than traditional data-flow analyses. \nThe literature con- tains many algorithms for alias analysis [2,4,6,7,9,15, 19, 8, 20, 21,22, 30, 32, \n35, 361. The key differences between the algorithms stem from where and how they approximate the unbounded \ncontrol paths and data. The approximation determines the precision and efficiency of the algorithm, and \nthese alias analyses range from precise exponential time al- gorithms to less precise nearly linear time \nalgorithms. Our work differs from previous work in two ways: (1) It is type-based instead of instruction-based. \n(2) We evaluate our alias algorithm with respect to an optimization, redun- dant load elimination, and \nits upper bound, rather than us- ing static measurements as used by most work on alias anal- ysis [2, \n4, 6, 7, 9, 15, 20, 21, 22, 30, 32, 351. Our upper bound measurement is similar to Wall s 1341, which \nassumes a perfect alias analysis to find an upper bound on instruc- tion level parallelism. Wall [34] \ndoes not evaluate an existing alias analysis as we do, but just gives the potential of a perfect alias \nanalysis for instruction level parallelism. Aho, et al. [l] and Chase, et al. [6] were among the first \nto notice that using programming language types could improve alias analysis, but did not present algorithms \nthat did so. Our alias algorithm is most similar to those of Rinard and Diniz [26], Steensgaard [321, \nand Ruf 127,281. Rinard and Diniz use type equality to disambiguate mem- ory references. The type system \nthey use is a subset of C++ that does not have inheritance and is thus weaker than Modula-3 s or Java \ns type systems. Steensgaard uses an instruction-based alias algorithm which uses non-standard types, \nnot programming language types, to obtain a fast alias analysis. His type inference algorithm is similar \nto our selec- tive type merging; however, he does not use programming language types, and in particular \ninheritance, to prune the merge sets as we do. Ruf shows how to use programming language types to partition \ndata-flow analyses: each partition represents code that can be analyzed independently and thus a different \nanalysis can be used on each partition [28]. Ruf uses his scheme to partition programs for alias analyses, \nbut does not use the programming language types in the analysis. Ruf 1271 compares a context sensitive \nalias analysis to a con- text insensitive alias analysis and finds, for his benchmarks, that they are \ncomparable in precision. Our work supports his in that we also find that a simple alias analysis can \nyield very precise results. Cooper and Lu [8] describe and evaluate register promo- tion, an optimization \nthat moves memory references out of loops and into registers. They evaluate register promotion with two \nalias analyses: a trivial analysis and a flow-sensitive alias analysis. They used the number of instructions \nexecuted as their performance metric and found that the more powerful alias analysis did not significantly \nimprove performance, Our results support theirs: for many applications a fast and simple alias analysis \nmay be sufficient. Shapiro and Horwitz [29] evaluate the impact of three flow insensitive alias analyses \non a range of optimizations. They evaluate their algorithms by counting optimization opportuni- ties \nrather than any of the metrics that we use. They find that clients of alias analysis may run faster with \na more precise alias analysis than with a less precise alias analysis. Sim- ilarly, Ghiya and Hendren \n[17] use pointer analysis to im- prove scalar optimizations, and present run-time improve- ments. This \nwork was concurrent with ours, They do not present a limit study. Debray et al. [ 1 l] describe an alias \nanalysis for executable code. They evaluate their algorithm by measuring the per- centage of loads eliminated \nby redundant load elimination. They do not present execution time improvements or a limit study for their \nalias analysis. Since we ignore control flow, our algorithm achieves a O(Instructions x Qpes) time complexity \nthat is asymptot- ically as fast as the fastest existing alias analysis [32]. 6 Conclusions This paper \ndescribes and evaluates three algorithms that use programming language types to disambiguate memory refer- \nences. The lirst analysis uses type compatibility to determine aliases. The second extends the first \nby using additional high- level information such as field names and types. The third, TBAA, extends the \nsecond with a flow-insensitive analysis. We show that the algorithm that uses only type compatibility \nis very imprecise whereas the other two analyses are much better at disambiguating memory references \nin the same pro- cedure. We also evaluateTBAA with respect to redundant load elimination (RLE), one of \nits many potential clients. Our results show that TBAA and RLE improve program perfor- mance by up to \n8%, and on average 4%. We demonstrate that with respect to RLE and these benchmark programs, TBAA is \nvery precise; a more precise analysis could only enable RLE to eliminate on average an additional 2.5% \nof redundant ref- erences, and at most 6%. Because TBAA relies on type-safety, it can be conservative \nin the face of incomplete, type-safe pro- grams without losing effectiveness. Our results show that as \nfar as RLE is concerned, TB AA performs just as well with an open-world assumption as with a closed-world \nassumption. TBAA achieves its fast time bound and accuracy because of type safety, and our results confirm \na common (but to our knowledge, untested) belief that type safety can be used to improve program performance. \nTaken together, these results suggest that type-based alias analysis can be effective, and that a thorough \nevaluation of alias analyses with respect to their clients is necessary to understand their strengths \nand weaknesses. References 111Alfred V. Aho, Ravi Sethi, and Jeffrey D. Ulhnan. Compilers: Principles, \nTechniques, and Tools. Addison-Wesley, 1986. PI John Banning. An efficient way to find side effects of \nprocedure calls and aliases of variables. In Conference Record of the Sixth Annual ACM SIGACT/SIGPL&#38;V \nSymposiumon Principles of Programming Languages, pages 29-41, San Antonio, Texas, January 1979. [31 Rodney \nM. Bates. K-trees. Personal communication, November 1994. [41 Michael Burke, Paul R. Carini, Jong-Deok \nChoi, and Michael Hind. Efficient flow-insensitive alias analysis in the presence of pointers. Technical \nReport 19546, IBM T.J. Watson Research Center, Yorktown Heights, NY, September 1994. PI Brad Calder, \nDirk Grunwald, and Joel Emer. A system level perspective on branch architecture performance. In 28th \nInternational Symposium on Microarchitecture, pages 199-206, November 1995. [61 David R. Chase, Mark \nWegman, and F. Kenneth &#38;deck. Analysis of pointers and structures. In Pmceedings ofthe ACM SIGPWV \n90 Conference on Programming Language Design and Implementation, pages 296-310, 1990. [7] Jong-Deok \nChoi, Michael Burke, and Paul Carini. Efficient flow-sensitive interprocedural computation of pointer-induced \naliases and side effects. In Conference Record of the Twentieth Annual ACM SIGAClYSIGPLANSymposium on \nPrinciples of Programming Languages, pages 232-245, Charleston, SC, January 1993. [S] Keith Cooper and \nJohn Lu. Register promotion in c programs. In Proceedings of the ACM SIGPLAN 97 Conference on Programming \nLanguage Design and Implementation, Las Vegas, Nevada, June 1997. [9] Keith D. Cooper and Ken Kennedy. \nFast interprocedural alias analysis. In Conference Record of the Sixteenth Annual ACM SIGACT/SIGPLswSymposium \non Principles of Programming Languages, pages 49-59, 1989. .O] Jeffery Dean, Greg DeFouw, David Grove, \nVassily Litvinov, and Craig Chambers. Vortex: An optimizing compiler for object-oriented languages. In \nProceedings of the ACM SIGPL4N 96 Conference on Object-Oriented Programming Systems, Languages, and Applications, \npages 83-100, San Jose, CA, October 1996. [ 1 l] Saumya Debray, Robert Muth, and Matthew Weippert. Alias \nanalysis of executable code. In Conference Record of the Twentyfifth Annual ACM SIGPLAIVSIGACTSymposium \non Principles of Programming Languages, 1998. [ 121 Digital Equipment Corporation. DEC3OOO 300/400/..~/600/800 \nModels: System Programmer s Manual, 1 edition, September 1993. First Printing. [131 Amer Diwan. Understanding \nand improving the perfkmance of modem programming Languages. PhD thesis, University of Massachusetts, \nAmherst, MA 01003, October 1996. [ 141 Amer Diwan, Eliot Moss, and Kathryn S. McKinley. Simple and effective \nanalysis of statically typed object-oriented programs. In Proceedings of the ACM SIGPLAN 96 Conference \non Object-Oriented Programming Systems, Languages, and Applications, San Jose, CA, October 1996. [ 151 \nMaryam Emami, Rakesh Ghiya, and Laurie J. Hendren. Context-sensitive interprocedural Points-to analysis \nin the presence of function pointers. In Proceedings of the ACM SIGPLAN 94 Conference on Programming \nLanguage Design and Implementation, pages 242-256, June 1994. [ 161 Mary F. Femandez. Simple and effective \nlink-time optimization of Modula-3 programs. In Proceedings of Conference on Programming Language Design \nand Implementation, pages 103-115, La Jolla, CA, June 1995. SIGPLAN, ACM Press. [ 171 Rakesh Ghiya and \nLaurie J. Hendren. Putting pointer analysis to work. In Conference Record of the Twenty$fth Annual ACM \nSIGPIAN/SIGACTSymposium on Principles of Programming Languages, 1998. [ 181 John Hennessy and David Patterson. \nComputer Architecture A Quantitative Approach. Morgan-Kaufmann, 1995. [ 19) Joseph Hummel, Laurie J. \nHe&#38;en, and Alexandru Nicolau. A general data dependence test for dynamic, pointer-based data structures. \nIn Proceedings of the ACM SIGPL.AN 94 Conference on Programming Language Design and Implementation, pages \n218-229, 1994. [20] William Landi and Barbara G. Ryder. Pointer-induced aliasing: a problem classification. \nIn Conference Record of the Eighteenth Annual ACM SIGACTBIGPLAN Symposium on Principles of Programming \nLanguages, pages 93-103, Orlando, FL, January 1991. [21] William Landi and Barbara G. Ryder. Interprocedural \nside effect analysis with pointer aliasing. In Proceedings of the ACM SIGPLAN 92 Conference on Programming \nLanguage Design and Implementation, pages 235-248, San Francisco, CA, June 1992. [22] James R. Lams and \nPaul N. HilEnger. Detecting conflicts between structure accesses. In Proceedings of the ACM SIGPLAN 88 \nCor$erence on Programming Language Design and Implementation, pages 21-34, Atlanta, GA, June 1988. [23] \nBarbara Liskov and John Guttag. Abstraction and Specification in Program Development. MIT Press, 1986. \n[24] Farshad Nayeri, Benjamin Hurwitz, and Frank Manola. Generalizing dispatching in a distributed object \nsystem. In Proceedings of European Conference on Object-Oriented Programming, pages 450-473, Bologna, \nItaly, July 1994. [25] Greg Nelson, editor. Systems Programming with Modtda-3. Prentice Hall, New Jersey, \n1991. [26] Martin C. Rinard and Pedro C. Diniz. Commutativity analysis: A new analysis framework for \nparallelizing compilers. In Proceedings of the ACM SIGPLAN 96 Conference on Programming Language Design \nand Implementation, Philadelphia, PA, June 1996. [27] Eric Ruf. Context-insensitive alias analysis reconsidered. \nIn Proceedings of the ACM SIGPLAN 95 Conference on Programming Language Design and Implementation, pages \n13-22, La Jolla, CA, June 1995. [28] Erik Ruf. Partitioning dataflow analyses using types. In ~0~197, \nParis, France, January 1997. [29] Marc Shapiro and Susan Horwitz. The effects of the precision of pointer \nanalysis. In Pascal Van Hentemyck, editor, Lecture Notes in Computer Science, 1302, pages 16-34. Springer-Verlag, \n1997. Proceedings from the 4th International Static Analysis Symposium. [30] Marc Shapiro and Susan Horwitz. \nFast and accurate flow-insensitive points-to analysis. In Conference Record of the Twentyfourth Annual \nACM SIGPLANXIGACT Symposium on Principles of Programming Languages, Paris, France, January 1997. [31] \nAmitabh Srivastava and Alan Eustace. ATOM A system for building customized program analysis tools. In \nProceedings of the ACM SIGPLAN 94 Conference on Programming Language Design and Implementation, pages \n196-205, Orlando, FL, June 1994. Association of Computing Machinery. [32] Bjame Steensgaard. Points-to \nanalysis in almost linear time. In Conference Record of the Twentythird Annual ACM SIGPLAN/SIGACTSymposium \non Principles of Programming Languages, pages 32-41. Association of Computing Machinery, January 1996. \n[33] Sun Microsystems Computer Corporation. 7%~ Java language specijication, 1.0 beta edition, October \n1995. [34] David W. Wall. Limits of instruction-level parallelism. In Proceedings of the Fourth International \nConference on Architectural Support for Programming Languages and Operating Systems, pages 176-189, \nSanta Clara, California, 1991. [35] William E. Weihl. Interprocedural data flow analysis in the presence \nof pointers, procedure variables and label variables. In Conference Record of the Seventh Annual ACM \nSIGACVSIGPLANSymposium on Principles of Programming Languages, pages 83-94, Las Vegas, Nevada, January \n1980. [36] Robert P. Wilson and Monica S. Lam. Efficient context-sensitive pointer analysis for C programs. \nIn Proceedings of the ACM SIGPLAN 95 Conference on Programming Language Design and Implementation, pages \n1-12, La Jolla, CA, June 1995. Association of Computing Machinery. \n\t\t\t", "proc_id": "277650", "abstract": "This paper evaluates three alias analyses based on programming language types. The first analysis uses type compatibility to determine aliases. The second extends the first by using additional high-level information such as field names. The third extends the second with a flow-insensitive analysis. Although other researchers suggests using types to disambiguate memory references, none evaluates its effectiveness. We perform both static and dynamic evaluations of type-based alias analyses for Modula-3, a statically-typed type-safe language. The static analysis reveals that type compatibility alone yields a very imprecise alias analysis, but the other two analyses significantly improve alias precision. We use redundant load elimination (RLE) to demonstrate the effectiveness of the three alias algorithms in terms of the opportunities for optimization, the impact on simulated execution times, and to compute an upper bound on what a perfect alias analysis would yield. We show modest dynamic improvements for (RLE), and more surprisingly, that on average our alias analysis is within 2.5% of a perfect alias analysis with respect to RLE on 8 Modula-3 programs. These results illustrate that to explore thoroughly the effectiveness of alias analyses, researchers need static, dynamic, and upper-bound analysis. In addition, we show that for type-safe languages like Modula-3 and Java, a fast and simple alias analysis may be sufficient for many applications.", "authors": [{"name": "Amer Diwan", "author_profile_id": "81100202872", "affiliation": "Department of Computer Science, Stanford University, Stanford, CA", "person_id": "PP15025608", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "Department of Computer Science, University of Massachusetts, Amherst, MA", "person_id": "P157900", "email_address": "", "orcid_id": ""}, {"name": "J. Eliot B. Moss", "author_profile_id": "81406593781", "affiliation": "Department of Computer Science, University of Massachusetts, Amherst, MA", "person_id": "PP39023945", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277670", "year": "1998", "article_id": "277670", "conference": "PLDI", "title": "Type-based alias analysis", "url": "http://dl.acm.org/citation.cfm?id=277670"}