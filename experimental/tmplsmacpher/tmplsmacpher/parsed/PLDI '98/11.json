{"article_publication_date": "05-01-1998", "fulltext": "\n Improving Performance by Branch Reordering MINGHUI YANG*, GANG-RYUNG UHf, AND DAVID B. WHALLEY* *Department \nof Computer Science, Florida State University, Tallahassee, FL 32306430 e-mail: {myang,whalley) @cs.fsu.edu; \nphone: (850) 644-3506 tLucent Technologies, 1247 S. Cedar Crest Blvd., Allentown, PA 18103-6209 e-mail: \nuh@lucent.com; phone: (650) 7122447 ABSTRACT The conditional branch has long been considered an expen- \nsive operation. The relative cost of conditional branches has increased as recently designed machines \nare now rely- ing on deeper pipelines and higher multiple issue. Reduc- ing the number of conditional \nbranches executed can often result in a substantial performance benefit. This paper describes a code-improving \ntransformation to reorder sequences of conditional branches. First, sequences of branches that can be \nreordered are detected in the control flow. Second profiling information is collected to predict the \nprobability that each branch will transfer control out of the sequence. Third, the cost of performing \neach condi- tional branch is estimated. Fourth, the most beneficial ordering of the branches based on \nthe estimated probability and cost is selected. The most beneficial ordering often included the insertion \nof additional conditional branches that did not previously exist in the sequence, Finally, the control \nflow is restructured to reff ect the new ordering. The results of applying the transformation were significant \nreductions in the dynamic number of instructions and branches, as well as decreases in execution time. \n1. INTRODUCTION Sequences of conditional branches occur frequently in programs, particularly in nonnumerical \napplications. Sometimes these branches may be reordered to effectively reduce the dynamic number of branches \nencountered dur- ing program execution. One type of reorderable sequence consists of branches comparing \nthe same variable or expression to constants. These sequences may occur when a multiway statement, such \nas a C switch statement, does not have enough cures to warrant the use of an indirect jump from a table. \nAlso, control statements may often compare the same variable more than once. Consider the following code \nsegment in Figure l(a). Assume that there is typically more than one blank read per line and EOF is only \nread once. Many astute programmers may realize that the order of the statements may be changed to improve \nperformance. In fact, we found that the authors Q 1998 ACM 0-8979%987.4/98/0008...$6.00 of most Unix \nutilities were quite performance conscious and would attempt to manually reorder such statements. A conventional \nmanual reordering shown in Figure l(b) would improve performance by performing the three com- parisons \nin reverse order. In fact, the most commonly used characters (e.g. letters, digits, punctuation symbols) \nhave an ASCII value that is greater than a blank (32), carriage return (lo), or EOF (-1). Figure l(c) \nshows an improved reordering of the statements that increases the static number of if statements and \nassociated conditional branches, but normally reduces the dynamic number of conditional branches encountered \nduring the execution. while ((c.getahar()) I= EOF) if (a I. '\\n') xi (a) Original Code Segment whih (1) \n( a I gatchar()i if (a I- ) Yt also if (c I. '\\Il') Xi elaa if (cl I. EOF) break, Oh. Zi I @) Conventional \nReordering whilr (I) ( e -gdxfhrr() i if (a > ' ') 2; 019. if (a -- ) Yi elm. if (c I- \\xI ) xi slae \nlf (a I= EOF) brmrk; elma zt 1 (c) Improved Reordering Figur e 1: Example Sequence of Comparisons with \nthe Same Variable Manually reordering a sequence of comparisons of a common variable or inserting extra \nif statements to achieve performance benefits, as shown in Figures l(b) and l(c), can lead to obscure \ncode. A general improving trans- formation to automatically reorder branches may help encourage the use \nof good software engineering principles by performance conscious programmers. This paper describes a \nmethod for reordering code to reduce the number of branches executed. Figure 2 presents an overview of \nthe compilation process for reordering branches. A lirst compilation pass is applied to a C source program. \nAll conventional optimizations are applied except for filling delay slots. Sequences of reorderable branches \ncomparing a common variable are detected in the control flow and an executable file is produced that \nis instrumented to collect profiling information about how often each branch in a sequence will transfer \ncontrol out of the sequence. This profile data and an estimated cost for executing each branch is used \nduring a second compilation pass to select the most beneficial branch sequence ordering. Delay slots \nare filled after branch reordering and the final executable is produced. The transformation was frequently \napplied with reductions in instructions executed and execu- tion time. Figure 2: Overview of Compilation \nProcess for Branch Reordering 2. RELATED WORK There has been some research on other techniques for avoiding \nthe execution of conditional branches. Loop unrolling has been used to avoid executions of the condi- \ntional branch associated with a loop termination condition [DaJ96]. Loop unswitching moves a conditional \nbranch with a loop-invariant condition before the loop and dupli- cates the loop in each of the two destinations \nof the branch lAlC711. Different search methods based on static heuris- tics for the cases associated \nwith a multiway statement have been studied lSpu941. Conditional branches have also been avoided by code \nduplication lMuW951. This method deter- mines if there are paths where the result of a conditional branch \nwill be known and duplicates code to avoid execu- tion of the branch. The method of avoiding conditional \nbranches using code duplication has been extended using interprocedural analysis [BGS97]. Finally, conditional \nbranches have been coalesced together into an indirect jump from a jump table [UhW971. There have also \nbeen studies about reordering or aligning basic blocks to minimize pipeline penalties associ- ated with \nconditional branches [CaG94, YJK971. However, this reordering or aligmnent of basic blocks does not change \nthe order or number of conditional branches executed. Instead, it only changes whether the branches will \nfall through or be taken. 3. DETECTING A REORDERARLE SEQUENCE The approach used for finding a sequence \nof reorder- able branches that compare a common variable required associating branch targets with ranges \nof values. Definition 1. A range is a set of contiguous integer values. Definition 2. A range condition \nis a branch or a pair of consecutive branches that tests if an integer variable is within a range. Definition \n3. A consecutive sequence of range conditions [R&#38;.,Rn] is a path, where each node is a range condition \ntesting the same variable and each edge is a control-jaw transition to the next range condition in the \nsequence. Definition 4. A reorderable sequence of range conditions is a consecutive sequence of range \nconditions, where the range conditions may be interchanged in any permutation with no effect on the semantics \nof the program. The possible types of ranges and the corresponding range conditions are shown in Table \n1, where v stands for the branch variable and c represents a constant. When a range is a single value \nor a range is unbounded in one direction, a single conditional branch can be used to test if the variable \nis within the range. Two conditional branches are needed when a range is bounded and spans more than \na single value, as depicted in Form 4 in Table 1. Table 1: Ranges and Corresponding Range Conditions \nFigure 3(a) depicts a sequence of two range condi- tions. Rl and R2 are range conditions that can consist \nof one or two branches that check to see if a variable is in a range. Tl and T2 are target blocks of \nthe range conditions and the corresponding range of values for the range condi- tion is given to the \nright of these blocks. T3 is the default target block when neither range condition is satisfied. Fig- \nure 3(b) shows how the sequence can be reordered. (a) OriginalSequence @)Reordered Sequence Figure 3: \nExample of Reordering Range Conditions with No Intervening Side Effects  Definition 5. nYo ranges are \nnonoverlapping ifthey do not have any common values. Definition 6. A side emct in a range condition is \nan instruction that updates a variable or a register and the updated value can reach a use of that variable \nor register outside of the range condition. Theorem 1. A sequence of two consecutive nonoverlap- ping \nrange conditions can be reordered with no semantic effect on the program if the sequence can only be \nentered through the first range condition, the two range conditions contain only pairs of comparisons \nand conditional branches, and the sequence has no side effects. Proof: Consider the original and reordered \nsequences of range conditions in Figure 3. The two sequences are semantically equivalent given that (1) \nthe state of the pro- gram is equivalent in both sequences when blocks Tl, T2, and T3 are reached, (2) \nblocks Tl, T2, and T3 are always reached in both sequences under the same conditions, and (3) no new \nerror exceptions are raised. Condition 1 is satisfied since the range conditions Rl and R2 have no side \neffects. Condition 2 is satisfied since the ranges associated with Tl, T2, and T3 are nonoverlapping, \nthere are no assignments in either range condition that can atfect the other, and the only predecessor \nof the second range condition is the first range condition. Condition 3 can be satisfied by considering \nthe following two facts. First, no new error exceptions can be introduced after exit- ing the reordered \nsequence due to conditions 1 and 2. Sec- ond, no new error exceptions can be introduced in Rl or R2 since \ncomparison and conditional branch instructions can- not raise error exceptions on the target architecture. \n0 Given Theorem 1, it can be shown through induction that a sequence of nonoverlapping range conditions \ntesting the same variable can be reordered with no semantic effect on the program if the sequence can \nonly be entered through the tlrst range condition, the sequence contains only pairs of comparisons and \nconditional branches, and the sequence has no side effects. The inductive proofs are not given in this \npaper due to lack of space and that these proofs were straightforward. The detection of a sequence of \nreorderable range conditions was accomplished using the algorithm in Figure 4. Instead of storing a sequence \nof branches, we instead store a sequence of ranges. The algorithm frrst finds two nonoverlapping range \nconditions comparing the same vari- able. Afterwards, it repeatedly detects an additional nonoverlapping \nrange condition until no more range condi- tions with nonoverlapping ranges can be found. FOR each block \nB DO IF (Bisnotmarked AND B has a branch that compares a variable V to a constant) THEN IF (FindJIrst/Dvo~Conds(B, \nV, Rl, R2, N)) THEN Ranges = {Rl, R2); C=N; mark blocks associated with Rl and R2; WHILE Find-Range-Cond(Rangcs, \nV, C, R, N) DO Ranges += R; C=N; mark block(s) associated with R; Store info about Ranges for profiling; \nBOOL FUNCTION FindJlrst_Two_Conds(B, V, Rl, R2, N) < IF (Find-Range-Cond({}, V, B, Rl, Nl) AND Find-Range-Cond(R1, \nV, Nl, R2, N2)) THTN N=N2; RRTuRN TRVE, ELSE Rt=Rl; IF (Find-Range-Cond(Rt, V, B, Rl, Nl) AND Find-Range-Cond(R1, \nV, Nl, R2, N2)) THTN N=N2; RRTURN TRvq RETURN FALSE; 1 BOOL FUNCTION Find-Range-Cond(Ranges, V, B, R, \nN) f IF (B has a branch that compares V to a constant C) THEN IF branch operator is == THEN R = C..C; \nN = B s fall-through succ; RETURN Nonoverlapping(R, Ranges); ELSE IF branch operator is != THEN R = C..C; \nN = B s taken succ; RETURN NonoverIapping(R, Ranges); ELSE IF (B s branch and the branch of a succ S \nof B form a bounded range R AND B and S have a common SIICC AND Nonoverlapping(R, Ranges)) THEN N 5: \nthe succ of S not associated with R; RETuF4N TRUE; ELSE sVV1Tt-X (branch operator) CASE < : R = MIN..C-1; \nI = C..MAX; CASE <= : R = MIN **C*, I = C+l..MAX; CASE >&#38;: R= C MAX. I = MIN..C-1; CASE 2 : R = &#38;1.&#38;X; \nI = MIN..C; IF (NonoverIapping(R, Ranges)) THEN N = B s fail-through succ; RRTURNTR~ ELSE N = B s taken \nsucc; RZTURN Nonoverlapping(1, Ranges); R~TDRN FALSE; 1 Figure 4: Detecting a Reorderable Sequence Figure \n5 shows an example of detecting a sequence be altered to meet these restrictions. For instance, the range \n of range conditions. Figures 5(a) and S(b) show a C code segment and the corresponding control flow \nproduced by the compiler. Figure 5(c) shows the sequence of reorder- able range conditions that are detected \nusing the algorithm in Figure 4. Note that all of the ranges are nonoverlapping. if (CJ k-- a &#38;&#38; \ncl <= 2 11 a >r A ii&#38; c <. 2 ) Tli .1s. if (a == - I T2i (a) C Code Segment (c) Reorderable Range \nConditions Figure 5: Example of Detecting Range Conditions A more complete set of branches that compare \na common variable to constants may be detected by propa- gating value ranges through both successors \nof each branch (i.e. detecting a DAG of branches instead of a path of range conditions) [UhW971. There \nwere two reasons why reordering was limited to sequences of range conditions. First, there were very \nfew cases that we examined where a sequence of range conditions did not capture the entire set of branches \ncomparing a common variable to constants. Second, we show in this paper that it is possible to start \nwith a sequence and guarantee an improved reordered sequence with respect to profile and cost estimates. \n4. MAKING SEQUENCES REORDERARLE It may appear that the restrictions in Theorem 1 would result in few \nreordemble sequences of range condi- tions being detected. In fact, most of the sequences could conditions \ncan be duplicated to ensure that the sequence is always entered at the head. Likewise, if a basic block \ncon- taining Rl did have a preceding side effect, then it could be split apart into the portion with \nthe side effect and the por- tion without one. Only the latter portion containing the range condition \nwould be reordered. Finally, there will typ- ically be no assignments of registers or variables associated \nwith a range condition. The branch variable may be loaded into a register preceding the first range condition. \nAny sub- sequent loads of the branch variable in the sequence would be redundant and are usually eliminated \nby the compiler. Thus, each range condition could usually be accomplished with just comparison and branch \ninstructions since the value of the branch variable was typically available in a register and the constants \ntested in the range condition could be represented in the comparison instructions for most ranges of \nvalues. Theorem 1 can be extended to allow other instructions to produce the values being compared, as \nlong as these instructions have no side effects and do not affect previous range conditions in the original \nsequence. Sometimes intervening side effects do exist between range conditions. Rather than attempting \nto reorder such sequences directly, we instead determine if we can move the side effects out of the sequence \nby duplicating code. Figure 6(a) shows a sequence of two range conditions with an intervening side effect \nS, which is actually in a block containing R2. Figure 6(b) portrays how the side effect can be moved \nafter R2 by duplicating S on both transitions from the range condition. Note that the transitions from \nP2 and P3 require that the side effect S be placed in separate basic blocks. The resulting sequence of \nrange conditions now has no intervening side effects and can be reordered. Pl T R Tl 8-a F q : TT2  \nt-2P2 w IT31 (a) Original Sequence (b) Transformed Sequence Figure 6: Moving Side Effects from a Sequence \nof Iwo Range Conditions  Theorem 2. A side effect between two consecutive range conditions can be duplicated \nto follow the second range condition with no semantic effect on the program if the side efsect does not \naffect the branch variable of the second range condition and the sequence can only be entered through \nthefirst range condition. Proof: Consider the original and transformed sequences of range conditions \nin Figure 6. The two sequences are semantically equivalent given that (1) state of the program is equivalent \nin both sequences when blocks T2 and T3 are reached, (2) blocks TZ and T3 are always reached in both \nsequences under the same conditions, and (3) no new error exceptions are raised. Condition 1 is satisfied \nsince the range condition R2 in the transformed sequence has no side effects, S is executed in both sequences \nwhen T2 or T3 is reached after executing R2, and S is not executed if T2 or T3 is reached without executing \nR2. Condition 2 is satisfied since S does not affect the branch variable of R2. Condition 3 can be satis- \nfied by noting that no new side effects are introduced in the transformed sequence. o Given Theorem 2, \nit can be shown through induction that a sequence of range conditions with intervening side effects can \nbe transformed to have no intervening side effects and still have the same semantic effect on the program \nif the side effects do not affect the branch variable of the range conditions and the sequence is only \nentered through the first range condition. 5. PRODUCING THE PROFILE INFORMATION The profiling code for \nreordering range conditions checks if the common variable is within ranges of values. The compiler needs \nto know how often each range condi- tion in the sequence would have a transition out of the sequence \ngiven it was executed when the head of the sequence is encountered. The instrumentation code for obtaining \nprofile information about the sequence was entirely inserted at the head of the sequence to check every \nrange condition in the sequence. However, additional ranges have to be determined from the ones calculated \nby the algorithm in Figure 4. Definition 7. An explicit range is a range that is checked by a range condition. \nDefinition 8. A default range is a range that is not checked by a range condition. Consider the original \nsequence of range conditions in Figure 7(a), There am additional ranges associated in the default target \nTD since these ranges will span any remain- ing values not covered by the other ranges. It is assumed \nin this figure that MIN < cl, c2+1< 13, and c4 < MAX. Fig-ure 7(b) shows an equivalent sequence with \nthese default ranges explicitly checked. Figure 7(c) shows a reordered sequence of range conditions, \nwhere the range condition for the last default range in 7(b) was placed first in the sequence. Once a \npoint is reached in the sequence where there is only a single target possible, then all remaining range \nconditions need not be explicitly tested as shown in Figure 7(d). The compiler calculated these remaining \nranges by sorting the explicit ranges and adding the minimum number of ranges to cover the remaining \nvalues. [c2+1..&#38;1] [d+l..MAXl (a) Original Sequence (b) Equivalent Original Sequence [&#38;?+l..c3-11 \n(c) Reordered Sequence (d) Equivalent Reordered Sequence Figure 7: Example of Reordering Default Range \nConditions 6. SELECTING THE SEQUENCE ORDERING The ordering for a reorderable sequence of range conditions \nwas chosen by using the factors specified in the following two definitions. Definition 9. pi is the probability \nthat range condition Ri will exit the sequence of range conditions. Each pi was calculated using the \nprofile information indi- cating how often the corresponding range condition Ri would exit the sequence \nif it was executed. The accuracy of this probability depends on the correlation of the branch results \nbetween using the training data set and the test data set. It has been found that conditional branch \nresults can often be accurately predicted using profile data [FiF92]. Definition 10. ci is the cost of \ntesting range condition Ri. Each ci was estimated by determining the number of instructions required \nfor the corresponding range condition. This cost includes the conditional branch(es), associated comparison(s), \nand any instructions that produce the values being compared. (A more accurate cost estimate could be \nobtained by estimating the latency and pipeline stalls asso- ciated with these instructions.) Some factors \nof the cost can vary depending upon the ordering of range conditions selected. In these cases, a conservative \nestimation of the cost was used. Definition 11. The Cost([RI,...,Rn]) is the estimated cost of executing \na sequence of range conditions. The explicit cost of a sequence of range conditions is calcu- lated as \na sum of products. One factor is the probability that a range condition will be reached and will exit \nthe sequence, which is equal to the probability that the range condition will be satisfied since the \nrange conditions are associated with nonoverlapping ranges. The other factor is the cost of performing \nthe instructions in that range condi- tion and all preceding range conditions in the sequence. Equation \n1 represents the explicit cost of executing a sequence of n range conditions, where every range associ- \nated with the sequence is explicitly checked. ExpZicit_Cost([R1,. . . , R,]) = p1c1+ pz(c1+ c2) + * * \n + p,&#38; + c2 + * * * + C ) (1) Theorem 3. A sequence of hvo consecutive nonoverlap- ping range conditions \ncan be optimally ordered with respect to the probability and cost estimates as [Ri,Rj] whenpi/c% 2 pj&#38; \nProof: An optimal ordering of two consecutive nonoverlap- ping range conditions can be achieved when \nthe explicit cost of the selected ordering is less than or equal to the explicit cost of the other ordering. \nExplicit-Cost([Ri, Rj]) I Explicit-Cost([Rj, Ri]) PiCi + pj(Ci + C j) I PjC j + pi(Cj + Ci) PiCi + PjCi \n+ PjCj I PjCj + PiCj + PiCi PjCi I PiCj PilCi Pjlcj I Pilci 2 PjlCj Intuitively, this means that it \nis desirable to first execute the range conditions that have a high probability of exiting the sequence \nalong with a low cost. Given Theorem 3, it can be shown through induction that an entire sequence of \nexplicitly specified nonoverlapping range conditions can be optimally ordered. However, there is also \na default cost, which occurs when no range condition is satisfied and the control trans- fers to the \ndefault target. Equation 2 shows the complete cost of a sequence, where only the first n ranges are explicit. \nCost([R1,. . . , R,]) = Explicit-Cost([R1, , . . , R,]) + a--(p1+ ***+pn))(CI +***+c,) (2) Once only \na single target remains, then the range conditions associated with that target need not be tested. Consider \nagain the example in Figure 7(a). The three targets of the range conditions are Tl, T2, and TD. Each \nof these targets could be potentially used as the default target and its asso- ciated range conditions \nwould not have to be tested. The TD target has three associated ranges. If any of these ranges are explicitly \nchecked, then Theorem 3 should be used to establish its best position relative to the other explicitly \nchecked range conditions to achieve the lowest cost for the sequence. If TD will be used as the default \ntar- get, then at least one of the three range conditions should not be explicitly checked. Definition \n12. mindefault(Ti) is the minimum cost of any ordering of a range condition sequence, where Ti is used \nas the default target. For each potential default target having m associated ranges, there are 2m-1 possible \ncombinations of these range conditions that do not have to be explicitly checked. The compiler used the \nordering pz/cl 2 . . . 2 pm/cm between the m ranges of a target to consider only m possible combina- \ntions of default range conditions, ((Rm), (Rm-Z&#38;z), . . . . (R&#38;...&#38;t} }. The compiler selected \nthe lowest cost combi- nation of default ranges by calculating the minimum cost of the sequence excluding \nthe range conditions associated with each of these sets. Assume that t is the number of unique targets \nout of the sequence. The compiler then cal- culatesthe minimum of (mindefault(T l), mindefault(Ts), . \n..) mindefault(Tt)) . Note that only the cost of n sequences have to be considered, where n is the total \nnumber of ranges for all of the targets. Our approach is not guaranteed to be optimal. How- ever, we \nalso implemented an exhaustive approach to find the lowest cost sequence. Our approach always selected \nthe optimal sequence for every reorderable sequence in every test program for the training data sets. \nEquation 3 represents the cost of executing a sequence of n-l explicitly checked range conditions, where \nonly range condition i is a default range. COst([Rl, * * * 9 Ri-l,Ri+l,* * - 9 Rnl) = PlCl + ** +pi-l(Cl \n+ *+ C&#38;l) + Pi+l(Cl + * + Ci-1 + Ci+l) + * * +Pn(C1+ +Ci-1+Ci+l+ +Cn) + pi(Cl + * + C&#38;l+ \nCi+l + *  + Cn) (3)  However, Equation 3 can be rewritten as Equation 4, where the cost of a sequence \nof range conditions with a default range can be calculated by subtracting the diierence from Equation \n1. CostURl,. . . ,Ri-l,Ri+l,. . . ,R,l) = COSt([Rl, s e s 7 R,]) + Pi(Ci+l + * * * + c,) -Ci(pi + * \n + p,) (4) The ordering of a sequence of range conditions was selected using the algorithm in Figure \n8. The algorithm lirst uses Equation 1 to calculate the cost of the optimal sequence when all of the \nrange conditions are explicitly checked. It then uses Equation 4 to avoid calculating the complete cost \nof the n different sequences. The complexity of the algorithm O(n), where n is the number of ranges in \nthe sequence. /* Assume the range conditions are sorted in descending order of PiKi. Calcu&#38;emec~twithallrangeconditiomexplicitlychecked. \n*/ RXplicit~cost -0.0; cost m 0; FOR i e 1 to n DO cost += c![il; Rxplicit~cost += P[i]*cost; /* tcost[i] \n= Ci+l + . . . + Cn and tprob[i] = Pi + Pi+1 + . . . + Pn. * / tcost[n] = 0; tprobtn] -Ptnli POR i -n-l \ndownto 1 DO tcost[i] P c[i+l] + tcost[i+ll I tprob[i] -P[i] + tprob[i+ll; /* Nowfind the sequence with \nthe lowest cwt. * / Lowest-Cost I Explicit-Costi FOR each unique target T DO cost I lzsplicit~Cost; Elim_Cost \n-0; POR each range Ri in T from lowest to highest P[i]/C[i] DO Cost ++ P[i]*(tcost[i] -El*Cost) -C[i]*tprob[ilr \nIF Cost < Lowest-Cost THEN LowestJ2ost P cost; Best-Soqusnce = current soquonce; Eli=Cost += C[i]t Figure \n8: Sequence Ordering Selection Algorithm 7. IMPROVING THE SELECTED SEQUENCE Other improvements were obtained \nafter the ordering decision was made. The compiler can determine the best ordering of the two branches \nwithin a single range condi- tion that is of type Form 4 shown in Table 1. The compiler assumed that \nboth branches would be executed in estimat- ing the cost for selecting the range condition ordering. \nIf the result of the tlrst branch indicates that the range condi- tion is not satisfied, then the second \nbranch need not be executed. Assume that such a range condition, Ri, is the ith range condition in the \nsequence and is associated with the range [cl.4 The probability that the value of the com- mon variable \nis below or above the range [cl..c2] at the point that the range condition is performed can be deter- \nmined as follows. We know that the range conditions asso- ciated with the sequence [R&#38;Rz,...&#38;l] \nhave already been tested and the value of the common variable cannot be in these ranges if Ri is reached. \nGiven that there are n total range conditions, the compiler examined the probability for each of the \nremaining ranges, [Ri+Z,Ri+Z,...,RRn],to deter- mine the probability that v < cl versus that v > c2. \nBased on these probabilities, the branch is placed first that is most likely to determine if the range \ncondition is not satisfied. Another improvement that was performed after the range conditions have been \nordered is to eliminate redun- dant comparisons. For instance, consider Figure 9(a). There are two consecutive \nrange conditions that test if the common variable is in the ranges [c+l..max] and [c..c]. Figure 9(b) \nshows a semantically equivalent comparison and branch for the first range condition. The comparison instruction \nwithin the second range condition becomes redundant and the compiler eliminates it. firstcomparison: \nIcW?c+l} 1crp7c; firstbranch: PC=IC>rnO->Ll; Pc!=IC>O->Ll; second comparison: 1cnv7c; secondbranch: Pc~Ic==o->L2~ \nPC=IC=~O->L2~ (a) Before 01) After Figure 9: Eliminating Redundant Comparisons Example 8. APPLYING \nTHE TRANSFORMATION Once a branch ordering has been selected, the com- piler will apply the reordering \ntransformation. Figure 10(a) shows a control-flow segment containing a sequence of three explicit range \nconditions (Rl, R2, and R3) and two intervening side effects (Sl and S2). Figure 10(b) shows the control \nflow with the replicated range conditions (Rl , R2 , and R3 ) inserted. The predecessors of the first \norigi- nal range condition now have transitions to the first repli- cated range condition. Note that \nthe target TD in Figure 10(a) has a fall-through predecessor. Code starting at the target block TD was \nduplicated until an unconditional jump, return, or indirect jump was found. This approach avoided increasing \nthe number of unconditional jumps executed from the reordered sequence and also simplitied the estimation \nof the cost of a reordered sequence. A simi- lar approach has been used when transforming code to improve \nbranch prediction [YoS94]. Figure 10(c) shows the control flow with the two intervening side effects \ndupli- cated to allow the sequence of range conditions to be reordered. T2 is also duplicated to avoid \nan extra uncondi- tional jump. Figure 10(d) shows the control flow after reordering the range conditions. \nR4 was one of the original default range conditions and is now explicit and tirst in the replicated sequence. \nRl and R2 have also been reversed. Figure 10(e) shows the code after applying dead code elim- ination. \nThe original range conditions Rl and R2 were deleted, while range condition R3 remains since it was still \nreachable from another path. Other optimizations, such as code repositioning and branch chaining to minimize \nuncon- ditional jumps, were also reinvoked to improve the code. 9. RESULTS Table 3 shows the three different \nsets of heuristics used when translating switch statements. The front end used Heuristic Set I, which \nam the same heuristics used in the pee front end [Joh79], when compiling for a SPARC IPC and a SPARC \n20. The authors used the dual loop method [CDV86] and found that indirect jumps on the SPARC Ultra I \nwere about four times more expensive than indirect jumps on the SPARC IPC or SPA&#38;C 20 [Uh97]. Therefore, \nHeuristic Set II used for the Ultra only generated an indirect jump when n 2 16. Finally, Heuristic Set \nIII always generated a linear search, which achieved the maxi- mum benefit from reordering. (a) Original \nSequence @) After Duplicating the Sequence (c) After Eliminating Intervening Side Effects T T (d) After \nReordering Range Conditions (e) After Dead Code Elimination Figure 10: Applying the Reordering Transformation \nTerm Definition II Number of cases in a switch statement. nl Number of possible values between the first \nand last case. Heuristic Set Indirect Jump Binary Search Linear Search I n24&#38;&#38; !indirectjump \n!indirectjump &#38;&#38; m13n &#38;&#38;n28 Ibinary-search II n216&#38;&#38; !indirectjump !indirect&#38;mp \n&#38;&#38; III m53n never &#38;&#38;n28 never Ibinary-search always Table 2: Heuristics Used for Translating \nswitch Statements Measurements were collected on the code generated for the SPARC architecture by the \nvpo compiler [BeD88] using the ease environment [DaW91]. Table 3 shows the test programs used for this \nstudy. We chose these non- numerical applications since they tend to have complex control flow and a \nhigher density of conditional branches. Table 4 shows the dynamic frequency measurements that were obtained. \nThe Original Znsts column contains the number of instructions executed with all of vpo s conven-tional \noptimizations applied. We present in the rest of the table the percentage change in the number of instructions \nProgram Description awk Pattern Scanning and Processing Language cb A Simple C Program Beautifier CPP \nC Compiler Preprocessor ctags Generates Tag File for vi deroff Removes nroflComtruct.s grep Searches \na File for a String or Regular Expression hyphen Lists Hyphenated Words in a File join Relational Database \nOperator lex Lexical Analysis Program Generator lUOff Text Formatter Pr Prepares File(s) for Printing \nPa Generates a Permuted Index sdiff Displays Files Side-by-Side sed StreamEditor SOli Sorts and Collates \nLines WC Displays Count of Lines, Words, and Characters yacc Parsing Program Generator Table 3: Test \nPrograms and branches executed after reordering sequences of range conditions. The reordering transformation \nhad signilicant benefits both in reducing the total number of instructions and conditional branches. \nThe original default target in a sequence was almost always selected as the default target for the reordered \nsequence. However, the profile data also 1 Switch Reordered Trans-Original lation program Heuris-Insts \nInsts Branches tiCS - awk 13,611,150 -2.02% -4.19% d-l 17,100,927 -7.65% -15.46% CPP 18,883,104 -0.13% \n-0.19% ctags 71,889,513 -9.10% -14.72% deroff 15,460,307 -1.53% -2.63% grep 9,256,749 -3.60% -8.31% hyphen \n18,059,OlO +3.42% +3.40% join 3,552,801 -1.68% -2.12% lex 10,005,018 -4.56% -10.39% Set I IUOff 25,307,809 \n-2.48% -6.35% Pr 73,051,342 -16.25% -29.96% Ptx 20,059,901 -9.18% -13.28% .%I8 14,558,535 -16.09% -37.03% \nsed 14,229,310 -1.16% -2.03% sort 23,146,400 -47.20% -57.38% WC 25,818,199 -15.05% -26.26% yacc 25,127,817 \n-0.25% -0.44% average 23,477,465 -7.91% -13.37% awk 13,552,831 -2.97% -6.15% cb 17,100,927 -7.65% -15.46% \nCPP 18,880,116 -0.13% -0.19% WY 71,824,093 -9.02% -14.64% deroff 15,451,383 -1.39% -2.38% km 9,938,414 \n-10.53% -22.04% hyphen 18,059,OlO +3.42% +3.40% join 3,552,801 -1.68% -2.12% lex 10,003,391 -4.57% -10.40% \nSet II IKOff 25,313,527 -2.50% -6.39% Pr 73,051,352 -16.25% -29.96% Pfi 20,059,901 -9.18% -13.28% sdiff \n14,558,530 -16.09% -37.03% sed 14,243,263 -1.28% -2.32% SOtt 23,146,400 -47.20% -57.38% WC 25,818,199 \n-15.05% -26.26% yacc 25,127,817 -0.25% -0.44% average 23,510,571 -8.37% -14.30% -awk 13,651,335 -3.63% \n-7.44% cb 19,662,207 -21.79% -37.41% CPP 30,477,974 -28.37% -41.85% ctags 72,222,399 -9.13% -14.73% deroff \n15,491,185 -1.40% -2.39% km 11,810,072 -32.04% -51.42% hyphen 18,059,OlO +3.42% +3.40% join 3,552,801 \n-1.68% -2.12% lex 10,028,151 -4.77% -10.73% Set III tUOff 25,339,678 -2.53% -6.45% Pr 73,051,352 -16.25% \n-29.96% Ptx 20,059,901 -9.18% -13.28% sdiff 14,558,530 -16.09% -37.03% sed 15,368,724 -10.07% -17.01% \nSOti 23,146,434 -47.20% -57.38% WC 25,818,199 -15.05% -26.26% YXC 25,168,370 -0.47% -0.76% average 24.556.842 \n-12.72% -20.75% Bible 4: Dynamic Frequency Measurements indicated that one of the original default ranges \nwas fre- quently satisfied and was explicitly checked in the reordered sequence. Also, comparison instructions \nbecame redundant and were eliminated much more often when an original default range became an explicit \nrange in the reordered sequence. One may notice that the transforma- tion had a slight negative impact \non hyphen, which occurred for a couple of reasons. First, different test input data was used as compared \nto the training input data for the results presented in the table. When we used the same test input data \nas the training input data, the number of branches never increased. Second, the reordering transfor- \nmation was applied after all optimiiations except for filling delay slots. Sometimes delay slots would \nbe filled from the other successor and would not execute a useful instruction. One should note that inconsistent \nfilling of delay slots also sometimes resulted in increased performance benefits. The transformation \nmay also have very significant benefits when a program executes most of its instructions in a reorderable \nsequence, such as in sort. The differences between using the different sets of heuristics indicates that \nthe effectiveness of branch reordering increases as indirect jumps become more expensive. It is also \ninteresting to note that the total number of instructions executed after reorder- ing often decreased \nas fewer indirect jumps were generated. This shows that profile information should be used to decide \nif an indiiect jump should be generated or branch reordering should instead be applied. Branch prediction \nmeasurements shown in Table 5 were obtained for the SPARC Ultra I, which supports branch prediction with \na (0,2) predictor with 2048 entries. The authors anticipated that the number of branch mispre- dictions \nwould decrease since the number of total branches executed was substantially reduced. Fewer mispredictions \nhad been observed when branches were coalesced into indi- rect jumps [Uh97]. However, the misprediction \nresults for branch reordering were mixed. Nine of the test programs had fewer mispredictions after reordering \nand the remain- ing eight had increases. Overall, the average number of &#38;predictions increased. We \nsuspect that adding more branches to a sequence caused additional mispredictions to Original Reordered \nhst Program Mispreds hhpreds Ratio awk 243,027 -0.46% N/Acb 440,712 +5.77% 51.41 389,566 -1.75% N/A Z&#38;S \n569,753 +225.50% 5.04 deroff 62,819 -2.87% N/A grep 115,007 -4.30% N/A hyphen 266,177 +84.12% -2.76 join \n50,440 -5.62% N/A lex 66,534 +1.93% 355.47 lUOff 141,167 -0.93% N/A pr 750,570 +0.33% 4,793.65 Pm 215,218 \n+37.58% 22.78 Sdiff 156,440 -5.35% N/A sed 83,579 -1.84% N/A sort 171,619 -10.41% N/AWC 481,767 +0.18% \n4,519.65 YSC 373,825 *0.55% 30.28 average 269.307 +18.97% 1,221.94 Table 5: Branch Prediction Measurements \nUsing a (0.2) Predictor with 2048 Entries  occur. But the average ratio of decreasedinstructions Switch \nReordered executedto the increasednumber of branch mispredictions Trans- FYO- Total was 1221.94 to 1 \nfor these eight programs. Thus, the lation gram Illsts Avg SeqLen IJeuris- Seqs Seqs increasein mispredictions \nwasfar outweighedby the bene- orig After II-T T 1 fit of reducing the number of instructions executed. \nCom-tics parableresults were obtained using other branchpredictors asshownin Table6. II (0.1) Predictor \nII RBX-ReOr- hut Inst !ntries dered deed Mis-Mis- Ratio Ratio Preds preds 32 +16.65% 681.20 +17.37% \n1313.47 64 +21.96% 720.73 +21.15% 1082.02 128 +21.91% 8583.19 +20.60% 1091.28 256 +21.91% 972.81 +20.21% \n953.70 512 +19.61% 5852.38 +18.09% 1200.25 1024 +20.45% 13331.71 +18.88% 1217.61 2048 +20.59% 13311.73 \n+18.97% 1221.94 verage +21.43% 6207.69 +19.32% 1154.32 f Table6: Branch PredictionMeasurements The execution \ntime measurementsshown in Table 7 were obtained from the averagereported user times of ten executions \nof each program using the C run-time library function times(). The execution time decreasewas not as \nsignificant as the reduction in instructions executed on thesemachines. One should note that in Table \n4 the mea-surementsfrom the codecompiled by our compiler did not include the C run-time library code. \nHowever, the library codedid contributeto the execution times. 41 Table7: Execution Times Table 8 showsstatic \nmeasurementsfor the sameset of programs. There was only about a 5% increasein the number of instructions \ngenerated. The Total Seqscolumn represents the total number of reorderable sequences detectedin each \nprogram. The Seqscolumn indicates the percentageof thesesequencesthat were actually reordered. The single \nmost common factor that preventeda sequence from being reorderedwasthat profile dataindicated that the \nsequencewas never executed. Using multiple setsof pro-file data to provide better test coveragewould \nincreasethis percentage.The Avg SeqLen showsthe averagenumber of branches in each reordered sequence \nbefore and after reordering. The length of each reordered sequencetypi-cally increased since often one \nor more default ranges becameexplicit after reordering. Heuristic SetIII resulted in fewer sequencessinceno \nbinary searchesweregenerated when translating switch statements. Each binary search generatedfor Heuristic \nSets I and II resulted in several reorderablesequencesbeing detected. awk +1.91% 48 16.67% 2.88 3.75 \ncb +8.32% 12 83.33% 2.50 2.80 CPP +1.57% 15 33.33% 220 3.20 ctags +9.48% 28 39.29% 2.64 3.36 deroff +1.58% \n38 23.68% 2.67 289 grep +3.51% 7 28.57% 3.50 4.50 hyphen +8.70% 3 100.00% 2.67 3.33 join +7.61% 8 37.50% \n3.33 3.67 Iex +8X% 95 58.95% 2.55 2.95 SetI MOff +1.62% 87 21.84% 2.95 3.53 Pr +2.40% 10 50.00% 3.00 \n4.20 Ptx +1.47% 4 75.00% 3.00 4.33 Sdiff +3.48% 8 37.50% 2.67 3.33 sed +4.22% 34 47.06% 2.88 3.50 sort \n+3.68% 16 56.25% 2.33 2.78 WC +10.20% 3 33.33% 5.00 5.00 yacc +6.4290 35 77.14% 3.70 4.48 +4.98% 26 48.20% \n2.97 3.62 -awk +2.05% 56 19.64% 3.91 4.55 cb +8.3290 12 83.33% 2.50 2.80 CPP +1.57% 16 31.25% 2.20 3.20 \nctags +9.47% 29 37.93% 2.64 3.36 deroff +1.7690 41 24.39% 3.00 3.20 grep +4.11% 19 36.84% 2.57 2.86 hyphen \n+8.7090 3 100.00% 2.67 3.33 join +7.61% 8 37.50% 3.33 3.67 lex +8.98% 103 58.25% 2.68 3.07 Set II MOff \n+1.73% 93 25.81% 2.83 3.33 pr +2.62% 11 54.55% 3.67 4.67 Ptx +1.47% 5 60.00% 3.00 4.33 Sdiff +3.4990 \n10 40.00% 3.00 3.50 sed +4.32% 41 51.22% 2.81 3.29 sort +3.68% 16 56.25% 2.33 2.78 WC +10.20% 3 33.33% \n5.00 5.00 Y=c +6.42% 35 77.14% 3.70 4.48 +5.09% 29 48.67% 3.05 3.61 awk +1.97% 42 30.95% 18.15 18.69 \ncb +11.17% 6 66.67% 5.50 7.75 CPP +2.4790 16 37.50% 14.33 16.50 -gs +6.50% 21 38.10% 3.50 4.50 deroff \n+1.2390 34 20.59% 5.29 5.57 grep +3.2990 9 44.44% 8.00 8.50 hyphen +8.70% 3 100.00% 2.67 3.33 join +7.61% \n37.50% 3.33 3.67 lex +6.25% 5: 59.26% 6.16 7.00 Set III IUOff +1.71% 46 32.61% 6.00 6.87 Pr f2.6290 \n11 54.55% 3.67 4.67 Pa +1.4790 5 60.00% 3.00 4.33 Sdiff +3.49% 10 40.00% 3.00 3.50 sed +5.32% 25 48.00% \n7.75 8.58 sort +3.76% 11 63.64% 3.57 4.29 WC +10.20% 3 33.33% 5.00 5.00 Y== +6.64% 29 79.31% 4.52 5.65 \ni-4.96% 19 49.79% 6.08 6.96 I w Table8: StaticMeasurements Figures 11, 12, and 13 show the distribution \nof the number of branchesin reorderedsequencesfor eachof the three heuristic sets. Note that most of \nthe original sequencescontained only two or three branches. This showsthat much of the benefit for reordering \ncomesfrom short sequences of branches that would never be translated into indirect jumps. 100 80 Average:2.91 \n80 60 60 40 40 20 20 1000 LimliIl 0 2 4 6 8 10 12 14 16 18 original sequence La@ Figure 11: Sequence \nLength for Heuristic Set I 100I- 80 Average: 3.05 80 Average:3.61 60 40 40 20 20 1000 E 600 L 2 4 6 \n8 10 12 14 16 2 4 6 8 10 12 14 16 original Sequence Length ReordmdSequenmLength Figure 12: Sequence Length \nfor Heuristic Set II ;L ...,,.., ;6.;,,.-,-. 1 5 10 IS 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 \n95 lIN10.5 orighlSequenceL.eogth 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100105 RendefedSeqwoceLengtb \nFigure 13: Sequence Length for Heuristic Set III 10. FUTURE WORK There are several areas in which reordering \nbranches could be extended. A sequence of range conditions is one of several approaches that could be \nused to determine a tar- get associated with the value of an expression. Essentially, a sequence of range \nconditions is a linear search. Some of these other approaches include performing a binary search, using \na jump table, and hashing [Spu94]. Profile dam could be used to more effectively apply these other approaches \nas a semi-static search method and to decide when each method or a combination of methods is most beneficial. \nA different type of sequence of branches that can be reordered using profile data would consist of consecutive \nbranches with a common successor. Figure 14(a) shows a C source code segment containing relational and \nlogical expressions and Figure 14(b) shows the corresponding con- trol-flow graph. The sequence of branches \nin blocks 1, 2, and 3 have block 4 as a common successor. Likewise, the sequence of branches in blocks \n4 and 5 have block 7 as a common successor. Figure 14(c) shows these two sequences of branches after \nreordering. Note that a reorderable sequence of branches with common successors cannot contain intervening \nside effects. While side effects could be moved out of such a sequence, the resulting sequence would \nnot contain a common successor block. Interprocedural analysis could be used to determine if invoked \nfunctions do not cause a side effect. Avoiding the execution of a function call, such as depicted in \nblock 2, could have significant performance benefits. Figure 14(d) depicts that a sequence of branches \nwith a common succes- sor can be viewed as a single block containing a branch since such a sequence would \nhave only two possible suc- cessors. The first sequence (blocks 3, 1, and 2) has two successors(blocks \n5 and 6). Likewise, the second sequence (blocks 5 and 4) also has two successors (blocks 6 and 7). Figure \n14(e) shows that these sequences can be reordered when there are no side effects between the sequences. \nif(a~=OLLf().-l&#38;Lb.=2 IIcr..3&#38;Ed..4) Tli allIe TZi (a) C Source Code Segment (b) Before Reordering \nBranches (c) After Reordering Branches y---jy.. A- S 1 j 3 , (d) Before Reordering Sequences (e) AtIer \nReordering Sequences Figure 14: Reordering Branches with Common Successors Obtaining profile data for \na sequence of branches with a common successor will differ from obtaining profile data for a sequence \nof nonoverlapping range conditions testing a common variable. While at most one range condi- tion will \nbe satisfied for a given execution of a sequence of nonoverlapping range conditions testing the same \nbranch variable, more than one branch in a sequence of branches with a common successor could branch \nto the common suc- cessor. Thus, all combinations of branch results would have to be obtained using an \narray of profile counters. This approach may be reasonable for a small sequence length (e.g. n I 7), \nwhich seem to handle most branch sequences with a common successor [Yan98]. 11. CONCLUSIONS This paper \ndescribed an approach for using profile information to decrease the number of conditional branches executed \nby reordering branch sequences. An algorithm for detecting a reorderable sequence of branches testing \na com- mon variable was presented. Profiling was performed to estimate the probability that each branch \nwill transfer con- trol out of the sequence. The most beneficial orderings for these sequences with respect \nto profiling and cost estimates were obtained. The results showed significant reductions in the number \nof branches and instructions executed, as well as decreases in execution time. ACKNOWLEDGEMENTS The authors \nthank Jack Davidson for allowing vpo to be used for this research. Michael Sjodin, Chris Healy, and the \nanonymous reviewers provided several helpful sugges- tions that improved the quality of the paper. We \nalso thank Mooly Sagiv for reviewing the final version of this paper. REFERENCES [AlC71] F. Allen and \nJ. Cocke, A Catalogue of Opti- mizing Transformations, pp. l-30 in Design and Optimization of Compilers, \ned. R. Rustin, Prentice-Hall, Englewood Cliffs, NJ (1971). [BeDaS] M. E. Benitez and J. W. Davidson, \nA Portable Global Optimizer and Linker, Proceedings of the SIGPLAN 88 Symposium on Programming Language \nDesign and Implementation, pp. 329-338 (June 1988). [BGS97] R. Bodik, R. Gupta, and M. Soffa, Interproce- \ndural Conditional Branch Elimination, Pro-ceedings of the SIGPLAN 97 Conference on Programming Language \nDesign and Imple- mentation, pp. 146-158 (June 1997). [CaG94] B . Calder and D. Grunwald, Reducing Branch \nCosts via Branch Alignment, Proceedings of the Sixth International Conference on Architec- tural Support \nfor Programming Languages and Operating Systems, pp. 242-251 (October 1994). [CDV86] R. M. Clapp, L. \nDuchesneau, R. A. Volz, T. N. Mudge, and T. Schultze, Toward Real-Time Performance Benchmarks for Ada, \nCommuni- cations of the ACM 19(8) pp. 760-778 (August lDJ961 Paw911 P-3321 lJoh791 [MuW95] K3pu941 l-U@71 \nIuhW971 [Yan981 [YJK97] [YoS94] 1986). J. W. Davidson and S. Jinturkar, Aggressive Loop Unrolling in \na Retargetable, Optimizing Compiler: Proceedings of Compiler Construc- tion Conference, pp. 59-73 (April \n1996). J. W. Davidson and D. B. Whalley, A Design Environment for Addressing Architecture and Compiler \nInteractions, Microprocessors and Microsystems 15(9) pp. 459-472 (November 1991). J. A. Fisher and S. \nM. Freudenberger, Predict- ing Conditional Branch Directions from Previ- ous Runs of a Program, Proceedings \nof the Fifth International Conference on Architec- tural Support for Programming Languages and Operating \nSystems, pp. 85-95 (October 1992). S. C. Johnson, A Tour Through the Portable C Compiler, Unix Programmer \ns Manual, 7th Edition 2B p. Section 33 (January 1979). F. Mueller and D. B. Whalley, Avoiding Con- ditional \nBranches by Code Replication, Pro- ceedings of the SIGPLAN 95 Conference on Programming Language Design \nand Imple- mentation, pp. 56-66 (June 1995). D. A. Spuler, Compiler Code Generation for Multiway Branch \nStatements as a Static Search Problem, Technical Report 94/03, James Cook University, Townsville, Australia \n(Jan- uary 1994). G. Uh, Effectively Exploiting Indirect Jumps, PhD Dissertation, Florida State University, \nTallahassee, FL (December 1997). G. R. Uh and D. B. Whalley, Coalescing Con- ditional Branches into Efficient \nIndirect Jumps, Proceedings of the International Static Analysis Symposium, pp. 315-329 (September 1997). \nMinghui Yang, Improving Per$ormance by Branch Reordering, Masters Thesis, Florida State University, Tallahassee, \nFL (1998). C. Young, D. S. Johnson, D. R. Karger, and M. D. Smith, Near-optimal Intraprocedural Branch \nAlignment, Proceedings of the SIG- PLAN 97 Conference on Programming Lan- guage Design and Implementation, \npp. 183-193 (June 1997). C. Young and M. D. Smith, Improving the Accuracy of Static Branch Prediction \nUsing Branch Correlation, Proceedings of the Sixth International Conference on Architectural Sup- port \nfor Programming Languages and Operat- ing Systems, pp. 232-241 (October 1994).  \n\t\t\t", "proc_id": "277650", "abstract": "The conditional branch has long been considered an expensive operation. The relative cost of conditional branches has increased as recently designed machines are now relying on deeper pipelines and higher multiple issue. Reducing the number of conditional branches executed can often result in a substantial performance benefit. This paper describes a code-improving transformation to reorder sequences of conditional branches. First, sequences of branches that can be reordered are detected in the control flow. Second, profiling information is collected to predict the probability that each branch will transfer control out of the sequence. Third, the cost of performing each conditional branch is estimated. Fourth, the most beneficial ordering of the branches based on the estimated probability and cost is selected. The most beneficial ordering often included the insertion of additional conditional branches that did not previously exist in the sequence. Finally, the control flow is restructured to refflect the new ordering. The results of applying the transformation were significant reductions in the dynamic number of instructions and branches, as well as decreases in execution time.", "authors": [{"name": "Minghui Yang", "author_profile_id": "81100352792", "affiliation": "Department of Computer Science, Florida State University, Tallahassee, FL", "person_id": "PP14126278", "email_address": "", "orcid_id": ""}, {"name": "Gang-Ryung Uh", "author_profile_id": "81311485605", "affiliation": "Lucent Technologies, 1247 S. Cedar Crest Blvd., Allentown, PA", "person_id": "PP39053704", "email_address": "", "orcid_id": ""}, {"name": "David B. Whalley", "author_profile_id": "81100296923", "affiliation": "Department of Computer Science, Florida State University, Tallahassee, FL", "person_id": "P64341", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277711", "year": "1998", "article_id": "277711", "conference": "PLDI", "title": "Improving performance by branch reordering", "url": "http://dl.acm.org/citation.cfm?id=277711"}