{"article_publication_date": "05-01-1998", "fulltext": "\n Generational Abstract Stack Collection and Profile-Driven Perry Cheng Robert Harper Peter Lee School \nof Computer Science Carnegie Mellon University 5000 Forbes Avenue Pittsburgh, This paper presents two \ntechniques for improving garbage collection performance: generational stack collection and profile-driven \npretenuring. The first is applicable to stack-based implementations of functional languages while the \nsec- ond is useful for any generational collector. We have imple- mented both techniques in a generational \ncollector used by the TIL compiler (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996), and have \nobserved decreases in garbage col-lection times of as much as 70% and 30%, respectively. Functional languages \nencourage the use of recursion which can lead to a long chain of activation records. When a collection \noccurs, these activation records must be scanned for roots. We show that scanning many activation records \ncan take so long as to become the dominant cost of garbage collection. However, most deep stacks unwind \nvery infre-quently, so most of the root information obtained from the stack remains unchanged across \nsuccessive garbage collec-tions. Generationalstock collectiongreatly reduces the stack scan cost by reusing \ninformation from previous scans. Generational techniques have been successful in reducing the cost of \ngarbage collection (Ungar 1984). Various com-plex heap arrangements and temu-ing policies have been pro- \nposed to increase the effectiveness of generational techniques by reducing the cost and frequency of \nscanning and copy-ing. In contrast, we show that by using profile information to make lifetime predictions, \npretenuring can avoid copying data altogether. In essence, this technique uses a refinement of the generational \nhypothesis (most data die young) with a locality principle concerning the age of data: most allo-cations \nsites produce data that immediately dies, while a few allocation sites consistently produce data that \nsurvives many collections. The primary author may be contacted at pschengBcs.cmu.edu. This research was \nsponsored in part by the Advanced Research Projects Agency CSTO under the title The Fox Project: Advanced \nLanguages for Systems Software, ARPA Order No. C533, issued by ESC/ENS under Contract No. F19628-95-C-0050. \nThe views and conclusions contained in this document are those of the author and should not be interpreted \nas representing the official policies, either expressed or implied, of the Advanced Research Projects \nAgency or the U.S. Government. 0 1996 ACM 0-89791.9874/98/0006...(6.00 PA 15213-3891 1 Introduction \nPretenuring Garbage collection is a technique for automatic memory management whereby the programmer \nis freed from explicit deallocation of heap storage (McCarthy 1960; Knuth 1969; Wilson 1994). Copying \ngarbage collectors reclaim space in two steps: scanning the stack for roots and then copying data reachable \nfrom these roots into an unused area of mem- ory. The area vacated by the live data is known to contain \nonly garbage and may be reclaimed. A simple kind of copy- ing garbage collector is the semispace collector \n(Fenichel and Yochelson 1969) using Cheney s algorithm (Cheney 1970). Unfortunately, semispace collectors \ncannot usually attain ef-ficient memory usage and good performance.(Ungar 1984) Using the observation \nthat most objects die quickly (Ungar 1984), generational collectors can arrange heap areas and schedule \ncollections to improve performance. Generational collection successfully reduces the cost of copying \ndata. However, for programs with deep call chains, the cost of scanning the stack for roots can be high. \nIn our study, we observe that root processing can take up to 70% of the total garbage collection cost. \nSince most deep stacks are not frequently unwound (Table 2), most of the old stack frames are unchanged \nacross successive collections. If we can determine which stack frames are unchanged, then the cost of \nroot scanning can be reduced by reusing the information from the previous collection. This technique, \ncalled genera-tional stack collection, is like generational garbage collection in that old stack frames \nare tenured to reduce processing frequency. Generational techniques work by dividing the heap into different \nregions called generations. Objects that survive ini-tial minor collections of the nursery (the first \ngeneration) are more likely to survive many more collections. These objects are promoted into areas that \nare less frequently collected. The advantage is that if the collections of the older areas are sufficiently \ndelayed, then a large fraction of these objects will have died, making the collection worthwhile. However, \nlong-lived objects are typically copied several times before they are tenured. Multiple generations can \nmake the tenuring prediction more accurate but could cause even more copying of the data that survives. \nAn alternative approach to using runtime per-object predictions is to classify objects based on their \nallocation site and use profile results to predict life-times. This technique can yield information concerning \nthe predicted lifetime of objects before the final execution. Its success relies on the information returned \nby heap profiling. If, as we later show, an allocation site is a good predictor for the age of an object, \nthen tenuring policies can be effec- tively based on allocation sites. Our empirical data shows significant \nreductions in data copying. Section 2 gives background material and some details on the implementation. \nSection 3 presents the initial empiri- cal results from using the standard techniques. Section 4 describes \ngenerational stack scanning with performance re- sults. Section 5 motivates and describes pretenuring \nwith performance results. Section 6 explores extensions and im- provements to generational stack collection \nand pretenuring. Section 7 presents related work and section 8 summarizes the results and points to future \ndirections. 2 Background In order to make sensible empirical comparisons, we have implemented two baseline \ngarbage collectors, a semispace collector and a generational collector. Some background ma-terial on \nthese baseline collectors is presented in this section. Next, the representation of the data and stack \nthat arises from the TIL compiler is discussed. The explanation of trac- ing the stack will reinforce \nthe notion that scanning the stack is relatively costly as a result of the optimizing technology. Finally, \nthe hardware, the benchmarks, and the measure-ment techniques are given. 2.1 Semispace and Generational \nCollection Our semispace collector (Fenichel and Yochelson 1969) uses Cheney s copy algorithm (Cheney \n1970). The resizing strat- egy is parameterized over a target liveness ratio r. In par- ticular, if the \nliveness ratio after a collection was I , then the heap is resized by the factor r /r. In our tests, \na target ratio value of r = 0.10 was used. The generational collector we use is similar to the one used \nin (Ungar 1984). There are many parameters that can be explored with generational collection. For simplicity, \nour collector has two generations, a nursery and a tenured gen- eration The heap resizing policy for \nthe tenured generation is based on deviations from a preset target liveness ratio of 0.3. The nursery \nis never made larger than the secondary cache (512K for our setup), following the advice of several researchers \nincluding Diwan and Tarditi (Tarditi and Diwan 1994). For benchmarking reasons, the nursery is sometimes \nmade significantly smaller. At each minor collection, we immediately promote all live objects from the \nnursery to the tenured generation. Large arrays are not allocated in the nursery and promoted to the \ntenured area; instead, they reside in a region managed by a mark-sweep algorithm. Finally, we use a simple \nwrite barrier technique, a sequential store buffer (Appel 1989), to handle pointer updates that may create \nintergenerational references. * 2.2 TIL TIL (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996) \nis an optimizing compiler for Standard ML (SML) that exploits several key technologies: intensional polymorphism, \nIf a reference from an older generation is created to a younger generation with a pointer update, then \nsimply collecting the younger generation could lead to a dangling pointer. However, the mutator can store \nall pointer updates into a table which is used by the run-time system at each garbage collection. For \nnon-pointer updates, no special action is needed. nearly tag-free garbage collection, conventional functional \nlanguage optimizations, and loop optimizations. With these technologies, it is usually possible to determine \nthe type and therefore representation of values. Unlike traditional functional language compilers that \nuse a universal data rep- resentation to implement polymorphism, TIL does not tag integers nor,does it \nalways box floating-point values. particular, TIL performs sufficient type analysis to provide tag-free \nunboxed word-sized integers and aligned unboxed floating-point arrays. At runtime, heap-allocated objects \nare represented by records, pointer arrays, and non-pointer ar- rays. The intensional polymorphism optimizations \nimprove runtime performance of monomorphic code at the expense of slower polymorphic code that passes \ntypes at runtime. Further, the garbage collector s interaction with the pro- gram is also more complex. \nTIL also uses a stack to manage activation records rather than using heap-allocated frames. Again, we \nare trading the performance benefits of a stack against greater complexity in the garbage collector. \nThe entire runtime system consists of about 7000 lines of C and assembly code. Of that, 3500 lines comprise \nthe garbage collector (including all of the techniques that were examined) and another 1500 lines provide \nsupport code like pretty-printing, heap profiling, and debugging. The rest of the code provides support \nfor l/O, signals, and internally used data structures. 2.3 Stack Scanning At any execution point, data \nis live if it is accessed as the program continues to execute. A conservative estimate of accessible \ndata is reachable data. (Some reachable data may be unnecessary for program completion.) Thus, a collector \nonly needs to retain data that is accessible by following all pointers starting from root values. Roots \nare directly acces-sible values such as registers and stack slots. The difficulty with accurately determining \nthe root set stems from the presence of callee-save registers and poly-morphism (Tarditi, Morrisett, \nCheng, Stone, Harper, and Lee 1996). First, with callee-save registers, the contents of a register or \nstack slot may come from caller frames so stack frames cannot be decoded in isolation. Instead, the stack \nscan must start from the initial frame and maintain the pointer status of the register set as the scan \nprogresses. Sec-ond, since polymorphism introduces variable types, the com- piler cannot statically compute \nwhether a particular value is a pointer or not. As a result, the compiler must sometimes communicate \nto the collector the correspondence between values and their dynamic types. When the garbage collector \nis called by the mutator, the return address indicates the current execution point of the mutator. By \nindexing into a table of auxiliary information (called a trace table) with this return address, we can \ndeter- mine the frame layout of the GC-caller frame. Then, from the return address of the GC-caller frame, \nwe can decode its caller frame. Continuing in this way, we finally reach the initial frame. From the \ninitial frame, we begin determining the root set by adding registers and stack slots as we traverse the \nstack downwards again. Note that the stack scan is two- pass as a result of callee-save registers. This \ncomplex scheme of decoding stack frames in the runtime system relieves the mutator from always having \nto tag stack slots even for stack frames that may not survive to a garbage collection. +A boxed object \nis stored in memory and represented by a pointer. 1 Program 1 lines 1 Description Table 1: Benchmark \nprograms Table 2: Allocation characteristics of benchmarks But what type of information is available \nin this trace table? The return address, which serves as a key to the trace table entry, and the stack \nframe size are necessary. In addition, for each general-purpose register and stack slot, we record its \ntrace. There are four types of traces: pointer, non-pointer, callee-save register, or compute. A pointer \ntrace indicates that the compiler has statically determined that the value is a pointer and needs to \nbe traced. A non-pointer trace indicates that the value is not a root. Registers or stack slots that \nare marked callee-save have additional information in the table that indicates which reg-ister the value \nis saved from. Finally, the compute trace is use when the compiler could not statically determine the \npointer status of a value. Additional information indicates where the type of such a value resides. From \nthis type, the nmtime computes whether the value should be included in the root set or not. Figure 1 \ngives an example of a stack frame. The left portion of the diagram gives a stack frame which is described \nby the corresponding trace table entry on the right. Their correspondence is established by the return \naddress which is always in the first stack slot and indexes into the trace table. From the second table \nentry, we see that this frame has six slots. The second slot, described by the third table entry, is \na non-pointer while the third and fourth slots are both pointers. Note that the fourth slot contains \na runtime type which is used to describe the contents of the fifth slot. In this case, since the type \nis a record, the collector will know that the fifth slot must be traced. Finally, the sixth slot contains \nthe spilled value of register 10. Whether this slot needs to be traced depends on the state of register \n10 from the previous stack frame. Finally, the table entry contains trace information on the register \nset. 3 Hardware, Benchmarks, and Measurement Methods To evaluate the effectiveness of generational stack \nmark-ers and pretenuring, we compare four techniques: semis-pace collection, generational collection, \ngenerational collec-tion with stack markers, and generational collection with stack markers and pretenuring. \nThe validity of the compar- ison is strengthened by the fact that each technique is tested under identical \nconditions: the same language and compiler, same hardware, and same benchmarks. The empirical results \nwere gathered on a DEC 3000/500 Alpha workstation which features a 21064 microprocessor. This chip has \nsplit instruction and data caches. Both caches are direct-mapped and sized at SK with cache lines of \n32 ENTRY 1 ENTRY 2 ENTRY 3 ENTRY 4 ENTRY 5 COMPUTE: STACK 4 ENTRY 6 ICOMPUTE: CALLEE slcj ENTRY 7 . ..Trace \nInfo on Registers... Figure 1: Example of a stack frame (left) and its corresponding table entry (right) \n bytes. It uses a write-through policy with a 4 entry write buffer and performs write-around on write \nmisses. This model also has a second-level off-chip 512K cache with a write-allocate policy (DEC 1994b; \nDEC 1994a). The par- ticular machine used has 96MB of main memory and runs OSF/l ~2.0. The sampled data \nis taken from runs of eleven SML (Mil-ner, Tofte, and Harper 1990) programs (many are de facto standard \nbenchmarks (Appell992)) compiled with TIL. Ta-ble 1 describes the benchmark programs, which range in \nsize from 73 lines to about 2000 lines of code. They cover a range of application areas including scientific \ncomput-ing, list-processing, systems programming, and compilers. Larger benchmarks could not be included \nbecause the cur-rent version of TIL does not yet support the SML module system. Table 2 describes the \nallocation behaviors of the benchmarks. The New Frames in Stack column refers to stack frames encountered \nby the collector that were not present during the last collection. Tables 3, 4, 5, and 6 show the time \nperformances of the benchmarks with various collection techniques. In each of the configurations explored, \ndata from ten runs were col-lected and the arithmetic mean is reported. In all cases, the standard error \nis under 1%. Times are reported in sec-onds and measured with UNIX virtual timers. Total, GC, Client \ndenote the total execution time of the program, the time spent in garbage collections, and the time spent \nin the mutator, respectively. (Of course, Total = GC + Client.) Also, NumGC and Copied respectively denote \nthe number of garbage collections and the amount of data in bytes copied during all collections. Since \ndifferent garbage collection techniques use different amounts of memory (if unconstrained), a direct \ncomparison of the techniques without some control would be unfair. A reasonable way to render the comparison \nfair would be to limit each technique to a fixed amount of memory. For copy- ing collectors, the absolute \nminimum amount of memory (Min) needed to run would be twice the maximum amount of live data a program \nhas during execution since a garbage collection may occur at any moment. Thus, we choose vari- ous multiples \n(designated lc) of this minimal value for each program and compare the performance of various techniques \nwhere the collector is permitted Ic * Min memory. 4 Initial results We consider the initial result obtained \nby using the two base- line collector techniques. Table 3 shows the time and space performance of the \nbenchmarks under semispace collection with k values of 1.5, 2, and 4. For programs with little long- \nlived data, the time spent in garbage collection should be inversely proportional to k since the time \nspent in any one garbage collection is approximately constant. In particular, FFT and Checksum experienced \nimprovements in GC times of 1.7 and 2.4 times as k increases from 1.5 to 4. (Note that an ideal linear \nimprovement would cause a speedup of -!-= 2.7.) Programs that have long-lived data benefit even 1.5 more \ngreatly from large values of k since each collection is relatively more expensive for such programs. \nIn particu-lar, Grobner and Knuth-Bendix experienced improvements of 4.1 and 4.4. Thus, these numbers \nare in accordance with the observation that FFT and Chksum generate no long-lived data while Grijbner \nand Knuth-Bendix do. Although there are minor fluctuations, the client time is relatively undisturbed \nby k. Consequently, changes in total times di-rectly reflect changes in GC times. Table 4 shows the performance \nof the benchmarks under generational collection. Most programs GC times improved by a factor of 2.5 when \nk is increased from 1.5 to 4. A notable exception is Knuth-Bendix where the time worsened by 5%. In the \ncase of Knuth-Bendix, almost all the data that sur-vives the nursery remains alive to the end of the \nprogram. Because there are no major collections, the extra amount of memory given is unused. It is plausible \nthat the time slightly worsens since the runtime system now has the over-head of managing more memory \nwithout any client benefit. On the other hand, we note that PlA s GC time improved dramatically from \n71s to 4.2s. The 17-fold decrease indi-cates some interesting behavior. Although the total number of \ngarbage collections remains approximately the same as k varies, the number of major garbage collections \nis severely affected by k since there is a significant amount of data that is copied on major collection. \nIn particular, PIA exhibits an allocation behavior that is not amenable to generational collection: PlA \ns tenured data tends to die rapidly. Even multiple generations would not ameliorate the problem be-cause \nany data that is tenured will most likely die before the next collection. Even a cursory glance at tables \n3 and 4 show that gen- Program 1 Chksnm Color FFT CTriihner__ _----- cxs k = 1.5 I k = 2.0 I k Number \nof _ __ 1I 11742----I 1 8795 1I 1 5579 1 3422 1 I 59 I 39 I I I 1107 --~ I I 656 1I Knuth-Bendix I 107 \n) 65 1 Lexeen I 31 I 19 I Life 4070 2987 Peg 3479 2404 PIA 1145 620 Simple 149 87 II Data II = 4.0 \nII k = 1.5 4388 11 (5294192 1302 11 109582416 17 11 63237932 250 11 152993208 i II copied bytes) k = \n2.0 4714200 64778048 42109916 902Ot.iACn /  26 11 262692124 I 148075968 I ~~~~ 7 11 776968t 30 1 46909028 \n1459 23594284 1514t5272 1069 88500416 61710880 222 678858984 362369260 33 815835344 467707256 k = 4.0 \n2353408 15230424 22159764 114213888 -_------ I 54428764 I 1 16992816 1 6244820 27084864 128563500 176086208 \n Table 3: Time and space usage for semispace collector erational collection wins. However, there are \nspecial cases where semispace collectors can do much better than gener-ational collectors. Some programs \nallocate data intensively but have almost no long-lived data or have relatively expen-sive root processing. \nIn these cases, the cost of GC is almost constant so GC cost is solely dependent on collection fre-quency. \nWith such programs and fixed memory constraints, the size of a semispace is larger than the nursery area \nof a generational collector. Thus, CC frequency decreases in a semispace collector so the overall cost \nof GC is lower. Aside from such special cases, we see that generational collection generally improves \nGC time dramatically, from 20% to 80%. Moreover, the generational collector has im- proved cache effects: \nthe allocation area remains perma-nently in the secondary cache and long-lived data is now grouped together. \nMost programs experience a client time improvement of 10% to 35%. Only FFT did not have this benefit \nsince the relative lack of garbage collections in this program dampens any possibility of cache interactions \nre- sulting from data movement. We now consider individually the performance of the benchmarks under \ngenerational collection to find opportu-nities for improvement. FFT spends about 0.2% of its time in \nGC and further optimization is not worthwhile. Chk-sum spends about 10% of its time in garbage collection \nbut each collection on average takes only about 0.2 milliseconds. Most of the cost here is overhead associated \nwith calling the garbage collector. In this case, the cost of each GC is nearly constant, and the only \nway to further reduce the cost is by tuning the collector code and increasing the nursery size. The high \n32% GC time for Peg is an artifact of the high mu-tation rate of this program. This is quite apparent \nfrom the last column of Table 2 which shows Peg having 4 orders of magnitude more updates than any other \nbenchmark. The simple sequential store list records a mutated site repeat-edly, causing a great overhead \nin root processing. A more realistic approach such as card-marking (Sobalvarro 1988) would probably ameliorate \nmost of the problems. As for Knuth-Bendix, Color, and Lexgen, all three are characterized by deep stacks \nand will be analyzed in section 5. Section 6 then explores heap profiling and pretenting and their applicability \nto the remaining benchmarks. 5 Generational Stack Collection We begin by breaking down the GC cost of \nKnuth-Bendix, Color, and Lexgen in the left column of Table 5. In most programs, the cost of generational \ngarbage collection is usu- ally dominated by the cost of scanning and copying the heap (GC-copy) rather \nthan by the cost of root processing (GEstack), since the stack is typically much smaller then the heap. \nSome functional programs (Knuth-Bendix, Color, and Lexgen), however, are highly non-tail recursive and \nhave a deep stack. For such programs (see column 2 of Table 5), the cost of scanning the stack can be \nas high as 95% of the cost of garbage collection. However, the stack allocation pattern of such programs \ntypically does not involve having rapid alternation of stack growth and shrinkage. For exam-ple, Table \n2 indicates that for Knuth-Bendix, only 116.9 of the 1336.5 stack frames that the collector traverses \non aver- age have changed since the last collection. Rather, once the stack is deep, most of the ancestral \nframes tend to remain activated for many garbage collections. We can take advan- tage of this by not \nrescanning the part of the stack that did Program Chksum 1 FFT Number of GCs k = 1.5 1 k = 2.0 1 k 29513 \nI 21986 I I 191 I 191 I  Data copied (bytes) Avg Frame = 4.0 k=1.5 1 k=2.01 k=4.0 Depth 10993 1012 I \n1832 I 536 4.0 19 Table 4: Time and space usage for generational collector not change. Instead, we save \nthe information from a previ- ous garbage collection and reuse the parts of the information corresponding \nto the unchanged part of the stack. In our generational collector, since objects in the nursery are always \npromoted, we do not need to consider roots resid-ing in frames that were present in previous collections. \nEven if our collector were designed so that it must recognize all stack roots at each minor collection, \nit is still advantageous to have amortized the cost of decoding the stack frames by storing the decoded \nresults, namely the register state and root list. Maintaining such information is a matter of bookkeep-ing. \nThe tricky part is knowing how much of the stack has not changed since the last collection. Certainly \none can maintain a special slot per stack frame containing an ini- tially unset flag that indicates whether \nit has been scanned by the collector. On a future collection, if the flag is set, then the collector \nknows that this frame has not changed. However, this increases the stack frame size and requires ex-tra \ninstructions for every stack frame. Since most frames die before a collection, this technique penalizes \nprograms that do not have deep stack behavior or do not require frequent garbage collections. To achieve \ngood performance for deep stacks while not penalizing the average program, the technique used must not \nsignificantly affect the mutator but instead place the bulk of the cost in garbage collection. This can \nbe achieved with the following addition to the collector: each time we scan the stack, we change the \nreturn address of every nth stack frame (n is a parameter best chosen to balance the gains of information \nreuse against the cost of the bookkeep-ing) to a special stub function while recording the original return \naddress in a table. When a function returns from such a marked frame, it transfers to the stub function \nwhich notes that this particular frame has been deactivated, and then continues at the original return \naddress recorded in the table. Our tests use a value of n = 25. This almost works. Unfortunately, functions \ndo not al-ways return normally. If an exception is raised, the ex-ception handlers are invoked in stack \norder until there is a matching handler. This matching handler may correspond to a frame that is arbitrarily \nfar up in the stack. In particu-lar, control may jump past many marked frames without the normal return. \nConsequently, some action must be taken or else the collector will not later know that the intervening \nframes are stale. Fortunately, it suffices to maintain a value M that is updated at every raised exception \nso that it con-tains the shallowest stack pointer value that occurred as a result of raised exceptions. \nLater the garbage collector sim-ply takes the shallower value of M and the value(s) in the table to obtain \nthe deepest stack frame that is safe to reuse. An alternative implementation for dealing with ex-ceptions \nthat is consistent with stack-allocated activation records moves the bookkeeping cost from the raising \nof an exception into the collector by having the collector walk the chain of exception handlers at each \ncollection to determine if any handlers that were raised since the last collection jumped past a marked \nframe. Deferring the handling of exceptions to a collection is advantageous for programs that frequently \nraise exceptions. In compilers where the run- Without stack markers With stack markers GC stack% GC 2.93 \n20.61% 2.96 9.77 26.99% 2.51 0.09 13.48% 0.10 I Grobner 1.11I- I I 5.18% 1.13 i 1 7.69% 11 -i.Sk t UR \nI 8 07 I 6.14 I 1.92 I 76.09% II 2.62 I 0.70 1 1.92 1 26.83% 11 67.5% Table 5: Breakdown of GC cost \nat k = 4 of generational collection without and with stack markers. All times are measured in seconds. \ntime system is responsible for unwinding the stack on raised exceptions, remembering which stack frames \nare no longer active is simple. Given the two possible implementation strategies, we chose the first \none since it does not entail modifying the compiler. (Such modifications tend to make the performance \ncomparisons questionable.) The results are displayed in the rightmost column of Table 5. The GC times \nare drastically reduced for all three target programs, with relative decreases ranging from 13% to 74%. \nFor completeness, we show the result of the other benchmarks. It is worth noting that the stack markers \nposes only a very slight cost for the other programs, averaging at 3%. 6 Heap Profiling and Pretenuring \nAs stated previously, generational collection takes advantage of the widely varying lifetimes of different \nheap-allocated ob-jects. The traditional temuing policy promotes an object if it survives one or several \ncollections. This policy has the dis- advantage that an object may be copied several times before being \nplaced in the right generation. Rather than discov-ering at runtime whether objects survive through promotion, \nwe could try to use profile data to predict the survival rate without copying. Clearly, it would be infeasible \nto uniquely identify each object because that would require too much data and the same objects do not \nrecur in different program runs. Instead, we speculate that objects allocated from the same point in \nthe program would tend to have similar life-times. To test this hypothesis, heap profiles were gathered \nto study the average lifetimes of objects created at different program allocation sites. To obtain heap \nprofiles, the com-piler was modified so that, when emitting allocation code, an allocation site identifier \nis prepended to each allocated object. During a garbage collection, each copied object s allocation site \nidentifier is inspected and the entry corre- sponding to that site is updated. about object deaths, we \nalso scan The 3% should actually be lower. fact of debugging code and timing code. perform time measurements \nof the stack the times and most of the 3% increase moval of this code will result in a small benchmarks. \nTo gather information the allocation area after Its measurability is an arti- Calling UNIX getrusage \nto markers technique distorts is attributable to this, Re- uniform improvement on all each collection \nto locate dead objects and update their al-location site entries. This information allows the profiler \nto compute the number, size, and average age of objects ema-nating from each allocation site. Profiled \nprograms typically run 50% to 200% slower than their unprofiled versions. For concreteness, abbreviated \noutputs of the heap profile generated for the Knuth-Bendix and Nqueen benchmarks are included in Figure \n2. Only allocation sites that con-tribute at least 1% of allocated or copied objects are in-cluded. The \nallocI shows the relative amount of data al-located at each site while the copied% shows the relative \namount of data allocated at each site that is eventually copied. The old% indicates the percentage of \ndata gener-ated at each site that survives at least one minor collection. Two complementary trends are \nobvious. In Knuth-Bendix, 90% of allocated data is generated by sites whose survival rate, to 4 significant \ndigits, is 0. Conversely, over 96% of data that is copied are allocated from sites whose survival rate \nis at least 80%. (These sites are marked with <--in the table.) The polarity is even more striking for \nthe Nqueen benchmark, where 99% of the copied data are generated from only 4 sites. From such profiles, \nwe can identify allocation sites that consistently produce long-lived objects and pretenure these objects. \nThat is, objects from these sites are directly allo-cated into the older generation. This is beneficial \nin that the liveness ratio of the younger generation is decreased, thus lowering the amount of objects \ncopied at each collec- tion and speeding up the collection process. In our tests, we pretenure objects \nallocated from sites whose old % cutoff is at least 80%. Considering the bimodality of the data, this \npretenuring policy is relatively insensitive to the particular cutoff chosen. Unfortunately, simply allocating \ndata into the older area breaks an invariant. An object directly allocated into an older generation may \nhave a reference to an object in a younger generation. Of course, pointer mutations also break this invariant \nand we could deal with these new intergener-ational references in the same way. This write barrier ap-proach \nwould be correct but too slow (Zorn 1989). One might suggest relaxing the tenuring condition for such \nob- jects so that they are promoted at every minor collection. Unfortunately, particularly for young \ngenerations, survival of even one collection indicates long-lived-ness, Therefore, even allocating them \nin a young generation and then im-mediately promoting them will lead to substantially more IEEE=====================- \nKnuth-Bendix EI==I=II====I=xE============~========= allot allot allot avg copied copied copied size/ \nage site % size count % old size % allot size ____________________-------------------------------------------------------------- \n10897 41.07% 113345036 16192148 0.00 1344.6 231 0.00 0.00 10911 17.60% 48576375 16192125 0.00 0.0 0 0.00 \n0.00 10842 10.14% 27981107 3997301 0.00 941.7 84 0.00 0.00 10764 7.84% 21646982 3092426 0.00 1217.5 84 \n0.00 0.00 10856 4.34% 11991840 3997280 0.00 0.0 0 0.00 0.00 10789 3.36% 9269365 1324195 0.00 969.6 56 \n0.00 0.00 10778 3.35% 9259011 3086337 0.00 0.0 0 0.00 0.00 10803 1.44% 3967959 1322653 0.00 0.0 0 0.00 \n0.00 10891 0.05% 139076 34769 86.60 1205.8 120496 1.01 0.87 <--10926 0.04% 119142 13238 95.94 521.9 164817 \n1.39 1.38 <--10920 0.05% 139076 34769 99.52 1404.0 236996 2.00 1.70 <--10707 0.21% 593016 148254 99.83 \n1075.8 972328 8.19 1.64 <--10921 0.05% 139076 34769 99.33 1399.9 236740 1.99 1.70 <--10709 0.24% 667024 \n166756 99.81 1092.7 1096688 9.24 1.64 <--10701 0.48% 1316872 329218 99.80 1336.8 2255800 19.00 1.71 <--10711 \n0.06% 175508 43877 99.58 1294.7 297180 2.50 1.69 <--10692 0.06% 158640 39660 99.60 1476.0 275420 2.32 \n1.74 <--10703 0.46% 1276600 319150 99.79 1297.0 2175008 18.32 1.70 <--10702 0.46% 1276600 319150 99.79 \n1297.0 2175008 18.32 1.70 <--10708 0.24% 667024 166756 99.81 1092.7 1096688 9.24 1.64 <--10710 0.06% \n175508 43877 99.59 1294.8 297200 2.50 1.69 <-- -------------heap profile end : short ----------------------------------------- \nShowing only entries with allot % > 1.00 or with copy % > 1.00 21 of 2048 entries displayed. Using a \n(% old) cutoff of 80%, targeted sites comprise 96.02% copied and 2.48% allocated. =I============================= \nNqueens =========================~==~~-=~=~==== allot allot allot avg copied copied copied size/ site \n% size count % old size % allot size age-----------------_---------------------------------------------------------------- \n 10757 39.98% 11662960 2915740 0.19 38.6 22560 0.62 0.00 10758 20.20% 5893923 841989 0.21 39.5 12404 \n0.34 0.00 10759 14.43% 4209945 841989 0.21 39.5 8860 0.24 0.00 10750 3.80% 1107600 184600 0.00 0.0 0 \n0.00 0.00 10751 3.16% 923000 184600 0.00 0.0 0 0.00 0.00 10752 3.16% 923000 184600 0.01 49.9 65 0.00 \n0.00 10753 3.16% 923000 184600 0.00 0.0 0 0.00 0.00 10755 3.16% 923000 184600 0.01 45.9 120 0.00 0.00 \n10754 2.53% 738400 184600 0.02 42.2 176 0.00 0.00 10748 2.92% 852000 170400 99.88 129.7 1872295 51.23 \n2.20 <--10749 2.34% 681600 170400 99.88 129.7 1497836 40.98 2.20 <--10756 0.19% 56800 14200 99.88 129.7 \n124816 3.42 2.20 <--10764 0.19% 56800 14200 99.88 129.7 124816 3.42 2.20 -c---------------heap profile \nend : short ---_------_-___--------------------- Showing only entries with allot % > 1.00 or with copy \n% > 1 .OO 13 of 2048 entries displayed. Using a (% old) cutoff of 80%,  targeted sites comprise 99.04% \ncopied and 5.65% allocated. allot size number of bytes allocated from this site allot % percentage of \nbytes allocated from this site allot count number of objects allocated from this site old % percentage \nof objects that survive the first collection after its creation avg age average age of objects when they \ndie copied size number of bytes allocated from this site that were copied during all collections copied \n% percentage of bytes allocated from this site that were copied during all collections Table 6: Time \nand space usage for generational collector with pretenuring 130 Relative CC time 120 . . . . . . . . \n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ., . . . . . . . . . . . \n. . . . . Technique: m Generational B Table 7: Relative copying than the pretenuring. Instead, we remember \nthe area of the older generation that has been directly allocated into and scan this region with the \ncollector on the next col-lection. This is a win over copying since copying objects is slower than only \nscanning them for the (hopefully) few young generation pointers. From the profiles, it is clear that \nthis optimization would be useful only for four of the benchmarks: Knuth-Bendix, Lexgen, Nqueen, and \nSimple. Since this optimization is se- lective based on the heap profile results, the remaining pro-grams \ncannot suffer from this optimization. Table 6 contains the performance figures under a generational collector \nwith generational stack collection and pretennring. The code sequence for allocating objects into the \npre-tenured region is somewhat longer than the normal alloca-tion code sequence, so there is a possibility \nthat the client time might increase as a result of pretenuring. On the other hand, there may be improved \ncache effects since all the sur-viving objects are pretenured into a single memory region. Quite likely \nboth of these effects are small and so do not greatly change the client time. In fact, the Client% Decrease \ncolumn of Table 6 shows that, on average, there is a slight decrease in the client time. More importantly, \nthe addition of pretenuring reduces the GC times of the four benchmarks Stack Markers Pretenuring with \nStack Markers CC time at lc = 4.0 by 33%, 27%, 50%, and 12%, respectively. The final column indicates \nthe relative decrease in total execution time. Since GC is already taking a relatively small percentage \nof total execution time (around lo%), Amdahl s Law restricts the magnitude of the decrease in total execution \ntime. In these benchmarks, the average decrease in total time is 4%. The reduction in GC time due to \npretenuring is not as large as one might expect from the reductions in the amount of data copied (71%, \n18%, 4%, and 44%). Although data is pretenured accurately, we must still scan the data to check for references \nto the younger generation. Thus, the cost of the collection is still proportional to the amount of live \ndata though with a smaller constant. This is rather unfortunate since most of the pretenured data will \nnot have references to the younger generation. There are different approaches one could take to reduce \nthe cost of the heap scan associated with pretenuring. When the data is allocated into the older generation \ndirectly, we could at the same time group them according to their al-location sites. This permits the \nscan to be specialized or omitted altogether and should lead to a reduction in in-struction count and \nmemory traffic. A more interesting but much harder improvement is to perform a control-flow and dataflow \nanalysis on objects allocated from the targeted sites. Abstractly, we have a set of target sites S. At \neach allocation site s, we would like to determine a set of sites P(s) such that any object that reaches \ns was allocated at a site in P(s). Then we can classify each target site s by whether P(s) C S. If so, \nthen there is no need to scan ob-jects arising from s since all such objects will have already been pretenmed \nanyhow. There is even the possibility of ad- ditionally pretenuring objects in P(s) so that objects from \nsite s do not have to be scanned. However, there is a danger of over-tenuring if P(s) is so large that \neven objects that are unlikely to live on their own become tenured. We indicate some preliminary results \nof such an extension in the next section. 7 Discussion and Extensions 7.1 Generational Stack Collection \nGenerational stack collection can also be used with non- generational collectors since the issue of root \nprocessing and heap copying are orthogonal. Further, the placement policy of stack markers presented \nabove is just one of several pos- sible choices. Also, a more dynamic policy of marker place- ment may \nachieve better performance with fewer markers. If activation records are heap-allocated, then the benefit \nof generational stack collection depends on the relative cost of the bookkeeping to that of interpreting \nactivation records that are heap-allocated. Given the cost of scanning a deep stack, one might ask whether \nheap-allocated activation record might be more ad-vantageous than using a stack as generational collectors \nwith heap-allocated record provide automatic tenuring of the frames. However, if the call depth is high, \nmany heap-allocated records might have to be copied at some point whereas the stack implementation never \ncopies frames. Fur-ther, in a compiler that supports &#38;lee-save registers, the state of the registers \ncannot be determined from the most recent frame. Thus, either a generational technique like the one presented \nhere would have to be added or the mutator must bear some runtime cost by maintaining a mask register \n(Appel 1992). In a system like TIL where types are passed at runtime for polymorphic code, maintaining \na mask register would entail an even greater cost. 7.2 Pretenuring Since the TIL compiler does not currently \nhave a data-flow analysis on allocated objects, the effectiveness of reducing scans of pretenured objects \nis tested by manually analyz-ing the allocation pattern of the Nqueens benchmark. After data flow analysis \nreveals the dependence of allocation sites, pretenured objects are divided into two groups. One group \nis shown to contain objects that point only to pretenured ob-jects while the other group contains objects \nthat may point to objects allocated in the nursery. By removing the scans on objects in the first group, \nthe GC time of Nqueens is further reduced by another SO%, reducing the overall GC% time to 1.3%. This \nresult is promising and an automated system for detecting such sites would be needed to make this optimization \nuseful. Some useful techniques that may help with this problem are region inference (Tofte and Talpin \n1993; Tofte and Talpin 1994; Aiken, Fahndrich, and Levien 1995; Birkedal, Tofte, and Vejlstrup 1996), \ndataflow analy-sis (Allen and Cocke 1970; Kennedy 1981), and control flow analysis (Shivers 1991). For \nthe remaining objects which may point to the nurs-ery, another optimization is possible. We pretenure \ndata from different allocation sites into separate areas. Then, some areas may require no scanning because \nthey contain no pointers. Other areas may permit specialized scans. For example, in an area that contains \nrecords*, no decoding of the tag word is needed. Instead, the collector can directly examine only the \nfields that are known to contain pointer. In general, the effectiveness of pretenuring is dependent on \nthe tenuring policy of the generational collector used. In some systems, objects in the nursery are not \nimmediately promoted but are copied/compacted back to the nursery. Counter bits within each object record \nthe number of minor collections the object has survived. When some threshold is reached, the object is \nthen promoted to the tenured gen-eration. Since objects that are tenured are copied several times before \nbeing promoted, pretenuring in such systems is likely to yield an even greater benefit than in the system \nwe studied. Finally, most recent versions of generational collectors support several generations. To \nobtain the maxi- mum benefit from pretenuring, one must consider the aver-age age of the target sites \n(column 6 of Tables 6 and 7) to determine which generation an object should be pretenured to. Underestimations \nof the correct generation would lead to extra data copying while overestimations would lead to overtenuring \n(which unnecessarily ties up memory until the next sufficiently major collection). 8 Related Work Fateman \nfound that some Franz Lisp programs spend from 25% to 40% of their time in garbage collection (Fateman \n1983). Of the 300 or so combinations of LISP systems and benchmarks that could report GC times, the average \nwas 38%. Ungar (Ungar 1984) showed the effectiveness of generational garbage collection in reducing pause \ntimes and improving overall performance. Shaw analyzed extensively four programs running on a commercial \nCommon Lisp sys-tem and found that generation checks alone can cost as much as 15% of total execution \ntime (Shaw 1988). Zorn investi-gated the GC cost of eight large programs using a com-mercial Common Lisp \nsystem and found that simulated GC times should be between 10% to 20% (Zorn 1989). Barrett and Zorn (Barrett \nand Zorn 1993) used lifetime predictors to improve memory overhead and reference locality in the context \nof explicit memory management. They also studied a mechanism that allows effective reclamation of tenured \ngarbage through a process of untenuring (Barrett and Zorn 1995). Diwan and Tarditi (Tarditi and Diwan \n1994) found the overall cost of automatic storage management under SML/NJ to be between 22% to 40%. They \nfound that allo-cation and root processing can be a significant fraction of the total cost. Rijjemo and \nRunciman (Rijjemo and Runciman 1996) used heap profiling to study the the lifetime behav-ior of data \nin the context of Haskell. Wilson (Wilson 1994) pointed out the importance of keeping root scanning costs \nlow in incremental garbage collection techniques. 9 Conclusions and Future Work Generally, even a simple \ngenerational collector outperforms a semispace collector by a factor of two or more in terms of *generated \nby monomorphic code garbage collection time, often also accompanied with a sig- nificant gain in the \nclient time from improved cache locality. However, there are special cases when a semispace collector \ncan outperform a generational collector: restricted memory usage such as when the total amount of memory \nused fits inside the cache, a monotonically growing set of long-lived data, or when long-lived data dies \nquickly once tenured. It might be advantageous for a collector to alternate between these strategies \nby testing for the above conditions dynami-cally. For deeply non-tail recursive programs with a runtime \nimplementation that uses stack-allocated activation records, caching the results of stack scans from \nprevious collections can speed up collections. We observe relative decreases in GC times of up to 74% \nwith generational stack collection. Finally, profiling the heap to gather lifetime data for ob-jects \nallocated from certain program points seems to provide highly accurate data for some of the programs \nwe studied. Even a simple pretenuring policy can reduce the collection time by up to 50% without increasing \nclient times. Incremental and concurrent collectors reduce pause times by performing collections that \nare more frequent but less disruptive. Nonetheless, they must synchronize on the root set. (That is, \nthough garbage in the heap may be gradu-ally removed, the stack scan is still performed atomically.) \nIn this setting, caching the results of stack scans can be helpful in reducing synchronization costs. \nThe usefulness of heap pretenuring rests largely on the predictability of ob- ject lifetimes based on \nallocation sites. Barrett and Zorn observed this predictability for four substantial C programs in (Barrett \nand Zorn 1993). One might speculate that this condition is more likely to hold for languages that allocate \nheavily such as Haskell, LISP, and Java. There are many directions to go from here: exploration of more \ngenerations, generation resizing policies, tenuring policy, control-flow analysis to automatically eliminate \npre-tenuring scans, opportunistic garbage collection, tag-free collection, write barrier techniques. \nOne interesting direc-tion is to reexamine all of the GC ideas with the attitude of aggressively using \nprofile data and type information to gen- erate specialized hybrid garbage collectors. Finally, more \nand bigger programs need to be analyzed to avoid having too few or only unrealistic datapoints. Acknowledgements \nChris Stone deserves thanks for general discussions about garbage collection, advice on benchmarking, \nand, as usual, a thorough review of this paper. Greg Morrisett provided useful discussions for the idea \nof using stack markers to im- plement generational stack collection. David Tarditi, Lars Birkedal, Edoardo \nBiagioni, Ken Cline, and David Eckhardt deserve thanks for careful reviews on a draft of this paper. \nReferences Aiken, A., M. FBhndrich, and R. Levien (1995). Better static memory management: Improving \nregion-based analysis of higher-order languages. Technical Report CSD-95-866, University of California \nat Berkeley. Allen, F. and J. Cocke (1970). A program data flow anal- ysis procedure. In Communications \nof the ACM, pp. 137-147. Appel, A. W. (1989, February). Simple generational garbage collection and fast \nallocation. In Software Practice and Experience, pp. 171-183. Appel, A. W. (1992). Compiling with Continuations. \nCambridge, Massachusetts: Cambridge University Press. Appel, A. W., J. S. Mattson, and D. Tarditi (1989). \nA lex- ical analyzer generator for Standard ML. Distributed with Standard ML of New Jersey. Barrett, \nD. and B. Zorn (1993). Using lifetime predictors to improve memory allocation performance. In ACM Programming \nLanguages Design and Implementation (PLDI), pp. 187-196. Barrett, D. and B. Zorn (1995). Garbage collection \nusing a dynamic threatening boundary. In A CM SIGPLAN, pp. 301-314. Biagioni, E., R. Harper, P. Lee, \nand B. Milnes (1994). Signatures for a network protocol stack: A systems application of Standard ML. \nIn LFP, pp. 55-64. Birkedal, L., M. Tofte, and M. Vejlstrup (1996). From region inference to von neumann \nmachines via region representation inference. In Proc. of Principles of Pro-gramming Languages (POPL). \nCheney, C. (1970). A nonrecursive list compacting algo-rithm. In Communication of the ACM, pp. 677-678. \nDEC (1994a). DEC 3000 300/400/500/600/700/800/900 AXP Models: System Programmer s Manual. May-nard, Massachusetts: \nDigital Equipment Corporation. DEC (1994b). DECchip 21064 and DECchip 21064A Al- pha AXP Microprocessors. \nMaynard, Massachusetts: Digital Equipment Corporation. Ekanadham, K. and Arvind (1987). SIMPLE: An exer-cise \nin future scientific programming. Technical Re-port Computation Structures Group Memo 273, MIT, Cambridge, \nMA, July 1987. Simultaneously published as IBM/T. J. Watson Research Center Research Re-port 12686, Yorktown \nHeights, NY. Fateman, R. (1983, August). Garbage collection over-head. Provate communication. cited in \nD. Un-gar, The Design and Evaluation of a High Perfor-mance Smalltalk System, Ph.D. Thesis, UC Merkeley, \nUCN/CSE 86/287, March 1986. Fenichel, R. R. and J. C. Yochelson (1969). A LISP garbage-collector for \nvirtual memory computer sys-tems. In Communications of the ACM, pp. 4611-612. Hornof, L. (1992, May). \nCompiling Prolog to Standard ML: Some optimizations. Undergraduate honors the-sis, Carnegie Mellon University. \nAvailable as Technical Report CMU-CS-92-166, September 1992. Jones, R. and R. Lins (1996). Garbage Collection: \nAlgo-rithms for Automatic Dynamic Memory Management. New York, NY: John Wiley and Sons. Kennedy, K. (1981). \nA survey of data flow analysis tech-niques. In S. Munchnick and N. Jones (Eds.), Program Flow Analysis: \nTheory and Applications, pp. 5-54. Prentice-Hall. Knuth, D. (1969). The Art of Computer Programming, \nVol. 1: Fundamental Algorithms. Reading, Mas-sachusetts: Addison-Wesley. McCarthy, J. (1960). Recursive \nfuntions of symbolic ex-pressions and their computation by machine. In Com-naunications of the ACM, pp. \n184-195. Milner, R., M. Tofte, and R. Harper (1990). The Defini- tion of Standard ML. Cambridge, Massachusetts: \nThe MIT Press. Reade, C. (1989). Elements of Functional Programming. Reading, Massachusetts: Addison-Wesley. \nRajemo, N. and C. Runciman (1996). Lag, drag, void and use - heap profiling and space-efficient compilation \nre-visited. In ACM SIGPLAN International Conference on Functional Programming, pp, 34-41. Shaw, R. (1988, \nFebruary). Empirical Analysis of a LISP System. Ph. D. thesis, Stanford University. Shivers, 0. (1991, \nMay). Control Flow Analysis of Higher Order Languages. Ph. D. thesis, Carnegie Mellon Uni- versity. Sobalvarro, \nP. (1988, February). A lifetime-based garbage collector for LISP systems on general-purpose comput- ers. \nMaster s thesis, MIT. Tarditi, Morrisett, Cheng, Stone, Harper, and Lee (1996). TIL: A type-directed \noptimizing compiler for ML. In ACM Programming Languages Design and Implemen- tation (PLDI), pp. 181-192. \nTarditi, D. and A. Diwan (1994). Measuring the cost of storage management. Technical Report CMU-CS-94-201, \nCarnegie Mellon University. Tofte, M. and J.-P. Talpin (1993, July). A theory of stack allocation in \npolymorphically typed languages. Tech-nical Report Computer Science 93/15, University of Copenhagen. \nTofte, M. and J.-P. Talpin (1994). Implementation of the typed call-by-value X-calculus using a stack \nof regions. In Proc. of Principles of Programming Lan- guages (POPL). Ungar, D. M. (1984). Generation \nscavenging: A non-disruptive high-performance storage reclamation algo-rithm. In A CM SIGSOFT/SIGPLA \nN, pp. 157-167. Waugh, K. G., P. McAndrew, and G. Michaelson (1990, August). Parallel implementations \nfrom function pro-totypes: a case study. Technical Report Computer Sci-ence 90/4, Heriot-Watt University, \nEdinburgh. Wilson, P. (1994). Uniprocessor garbage collection tech-niques. In Technical report, University \nof Texas. Ex-panded version to appear in ACM Computing Surveys. Yan, T. (1996). Grobner basis computation. \nPersonal communications. Zom, B. (1989, December). Comparative Performance Evaluation of Garbage Collection \nAlgorithms. Ph. D. thesis, University of California at Berkeley.  \n\t\t\t", "proc_id": "277650", "abstract": "This paper presents two techniques for improving garbage collection performance: generational stack collection and profile-driven pretenuring. The first is applicable to stack-based implementations of functional languages while the second is useful for any generational collector. We have implemented both techniques in a generational collector used by the TIL compiler (Tarditi, Morrisett, Cheng, Stone, Harper, and Lee 1996), and have observed decreases in garbage collection times of as much as 70% and 30%, respectively.Functional languages encourage the use of recursion which can lead to a long chain of activation records. When a collection occurs, these activation records must be scanned for roots. We show that scanning many activation records can take so long as to become the dominant cost of garbage collection. However, most deep stacks unwind very infrequently, so most of the root information obtained from the stack remains unchanged across successive garbage collections. <i>Generational stack collection</i> greatly reduces the stack scan cost by reusing information from previous scans.Generational techniques have been successful in reducing the cost of garbage collection (Ungar 1984). Various complex heap arrangements and tenuring policies have been proposed to increase the effectiveness of generational techniques by reducing the cost and frequency of scanning and copying. In contrast, we show that by using profile information to make lifetime predictions, <i>pretenuring</i> can avoid copying data altogether. In essence, this technique uses a refinement of the generational hypothesis (most data die young) with a locality principle concerning the age of data: most allocations sites produce data that immediately dies, while a few allocation sites consistently produce data that survives many collections.", "authors": [{"name": "Perry Cheng", "author_profile_id": "81451593218", "affiliation": "School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA", "person_id": "PP39070309", "email_address": "", "orcid_id": ""}, {"name": "Robert Harper", "author_profile_id": "81100140064", "affiliation": "School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA", "person_id": "PP39029370", "email_address": "", "orcid_id": ""}, {"name": "Peter Lee", "author_profile_id": "81100384353", "affiliation": "School of Computer Science, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA", "person_id": "PP39040384", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277718", "year": "1998", "article_id": "277718", "conference": "PLDI", "title": "Generational stack collection and profile-driven pretenuring", "url": "http://dl.acm.org/citation.cfm?id=277718"}