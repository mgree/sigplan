{"article_publication_date": "05-01-1998", "fulltext": "\n A New Algorithm for Scalar Register Promotion Based on SSA Form A.V.S. Sastry, Roy D.C. Ju Performance \nDelivery Laboratory Hewlett Packard Company 11000 Wolfe Road, MS 42 U5 Cupertino, CA 95014, USA 1. ABSTRACT \nWe present a new register promotion algorithm based on Static Single Assignment (SSA) form. Register \npromotion is aimed at promoting pro- gram names from memory locations to regis- ters. Our algorithm is \nprofile-driven and is based on the scope of intervals. In cases where a complete promotion is not possible \nbecause of the presence of function calls or pointer refer- ences, the proposed algorithm is capable \nof eliminating loads and stores on frequently exe-cuted paths by placing loads and stores on less frequently \nexecuted paths. We also describe an efficient method to incrementally update SSA form when new definitions \nare cloned from an existing name during register promotion. On SPECInt95 benchmarks, our algorithm removes \nabout -12 % of memory operations which access scalar variables. 2. INTRODUCTION Traditionally C compilers \nallocate global variables in memory[Muc97]. The reason is that global variables are visible throughout \nthe entire program, i.e. the effect of modifying a global variable by a function must be seen by any \nother function that is called subsequently. With this simplistic allocation strategy, visibility is achieved, \nbut each use of a global variable requires a load instruction and an assignment requires a store instruction. \nIf global variables are used in frequently executed program paths, such as loops, then these loads and \nstores can degrade program performance significantly. Moreover, the presence of loads and stores can \ninhibit other optimizations.  Register promotion optimization aims at allocating global variables to \nvirtual registers in certain parts of a program in order to improve the overall program performance. \nIf a 0 1996 ACM 0-89791.987-4/98/0006...$5.00 variable is promoted to a virtual register in a particular \nregion (a set of connected nodes with a single entry and multiple exits), loads must be inserted at the \nregion entry, and stores must be inserted at the region exits to ensure that the value in the virtual \nregister and the value in memory are consistent before entering and after exiting the region. In this \npaper, we describe a new algorithm for register promotion of variables that hold scalar values. Variables \nconsidered for promotion are global scalar variables, address exposed local scalar variables, and scalar \ncomponents of structure variables. Our algorithm is based on Static Single Assignment (SSA) form, which \nis a widely-used intermediate representation in optimizing compilers [CFR+91]. The existing register \npromotion algorithms in the literature are loop based [Mah92, LuC971 and are not designed to work on \nSSA representation. To the best of our knowledge, ours is the first register promotion algorithm that \nis based on SS A representation. The algorithm traverses each interval in an interval tree and promotes \nvariables in a bottom-up manner. An interval is a strongly connected component of a control flow graph[Muc97]. \nPromotion in an interval results in the insertion of loads and stores in the parent interval, and these \nloads and stores are considered for elimination when the parent interval is processed. The algorithm \nuses profile information to estimate the benefit of promotion to decide when to promote a variable to \na register. If there are function calls or aliased pointer references, then complete promotion may not \nbe possible. In such cases our algorithm eliminates loads and stores occurring on fi-equently executed \npaths by placing loads and stores on the paths containing function calls or pointer references if these \npaths are executed less frequently. Insertion of stores introduces new SSA names requiring an update \nof the SSA form. To solve this problem, we describe a geneml method to incrementally update the SSA graph \nwhen cloned definitions of a variable are added to the program. Such a method can find its use in other \ntransformations, such as loop unrolling and compensation code generation, which may also duplicate definitions \nfrom an existing name. We present experimental results to show the impact of register promotion on the \nnumber of loads and stores executed and on register pressure based on the programs from the SPECInt95 \ntest suite. Although register promotion can improve program performance by reducing loads and stores \nexecuted in the program, it increases register pressure by creating more virtual registers that need \nto be colored. The rest of the paper is organized as follows. In the next section we discuss the background \nfor the paper. Section 4 describes the general strategy for register promotion and presents the new algorithm. \nSection 5 describes the experimental results. Section 6 discusses related work. Section 7 concludes this \npaper. 3. BACKGROUND We assume that a program is in Static Single Assignment form. Under SSA form, every \nprogram name has a unique definition. A phi function with a new definition is inserted at a control flow \nconfluence point to join multiple reaching definitions from different predecessors. A phi function is \nimplemented as an explicit phi instruction in our compiler. SSA form has simplified the design and implementation \nof some optimizations and has made other optimizations more effective. SSA representation has been widely \nadopted in optimizing compilers, and a number of optimization algorithms have been developed based on \nSSA form. Examples are conditional constant propagation [WeZ91], dead store elimination [CFR+91], global \nvalue numbering [RWZSS], global code motion [Cli95], etc. To identify definitions to and uses from memory \nlocations, we tag memory locations with unique identifiers called memory resources as in [LuC97]. A singleton \nmemory resource represents a single memory location. An aggregate resource contains a set of singleton \nresources representing multiple memory locations. Aggregate resources are used for expressing the uncertainty \nin the uses or definitions of memory locations. The aliasing relationship between aggregate resources \nis expressed by using common memory singleton resources. A load instruction of a scalar variable is tagged \nwith a singleton resource and is a use of that resource. Similarly a store instruction of a scalar variable \ndefines a singleton resource. A function call, pointer store instruction, or an array assignment defines \nan aggregate resource, and a function call, a pointer load instruction, or an array reference uses an \naggregate resource. In the rest of the paper, a load and a store refer to a singleton load and a singleton \nstore, respectively. For aggregate loads and stores we use the term aliased loads and aliased stores \nwhich include function calls and pointer references. For the sake of discussion, we assume that a function \ncall may modify and use all memory singleton resources from global variables. In essence each global \nvariable in the program is associated with amemory resource. We put singleton resources in SSA form in \norder to treat them uniformly with register resources and apply optimizations, such as global value numbering \nand dead code elimination, to memory instructions as well. An occurrence of a resource in a program is \ncalled a reference. Every reference has a resource associated with it. After SSA construction, more than \none singleton resource may represent the same memory location. When we leave SSA form, all of the singleton \nmemory resources that refer to the same memory location must be replaced by one unique name and the alias \nsets in aggregate resources have to be readjusted to use this name. In order to do so, we keep track \nof the original name of every newly created singleton. main0 x0= . . . { for (i=O;i<lOO;i++) x++; f \nfor (i=O;i<lO;i++) foo0; x,;= $y =tI r2= rl+l x2=st [] r2 (a> I 1 r x3+&#38;x4) x4=foo() x3 I 0) Figure \n1. (a) A program (b) SSArepresentation of x No more than one SSA name corresponding to a single memory \nlocation may be live at any program point. 4. THE PROMOTION ALGORITHM 4.1 Overview Let us consider the \nexample in Figure l(a). In the first loop, the global variable x is incremented 100 times. Subsequently, \na function foo() is called 10 times. Before register promotion, variable x has to be loaded from and \nstored back to memory in every iteration of the first loop. Figure l(b) shows the SSA representation \nof memory location x. x0 represents the x defined before entering the loop. The store to x inside the \nfirst loop is renamed to x2, and a phi instruction is inserted at the loop entry. The function call foo() \ncan potentially modify and use the value of x. The potential use is reached by x3, which is defined by \nan inserted phi instruction, and the potential redefinition of x is renamed to x4. We list two approaches \nto promote the value of x based on different scopes. In the first approach which considers the entire \nprogram, we promote the value of x in the tirst loop into a register and store the content of the register \nbefore every aliased load. We also reload the value of x into the register immediately after every aliased \nstore. In this example, promotion would result in inserting a load and a store before and after the call \nto fooo, respectively. This approach does not consider the structure of a program. Although we have reduced \nthe number of loads and stores from 200 to 21, we will introduce redundant loads and stores in the second \nloop. In the second approach, instead of the entire program, program intervals (which are often natural \nloops) are considered as the scope for promotion. Before entering an interval, the variable is loaded \nfrom memory into a virtual register. Any loads or stores in the interval are replaced by copy instructions \nbased on the virtual register. Upon exiting the interval, the value of the virtual register is stored \nback to memory. Within an interval we place stores before aliased loads, and place loads after aliased \nstores. Using this method we can reduce the number of loads and stores for the example in Figure 1 to \ntwo: a load before entering the first loop and a store after exiting the Erst loop. The interval based \napproach assumes that each interval entry or exit edge of an interval is not a critical edge. An edge \nis a critical edge if its source has multiple successors and its target has multiple predecessors. A \ncritical edge can always be removed by inserting a basic block on the edge. The target of an interval \nexit edge is called a tail and is outside the interval, For loading a value to a virtual register before \nentering the interval we need a basic block that strictly dominates all of the basic blocks in the interval. \nFor a proper interval, such a basic block is called a preheader, which is the predecessor of the interval \nentry excluding the loop back edge. In the case of an improper interval, which has multiple entry basic \nblocks, the unique preheader for the purpose of register promotion is the least common dominator of all \nof the entry basic blocks. The driver of the interval based register promotion algorithm is shown in \nFigure 2. The routine constructSSAWebs() constructs SSA webs in a given interval. Promotion in an interval \nis performed by the routine promoteIn1nterva.Q. Recall that after we perform SSA renaming, a memory resource \ngets multiple names. Some of these names are connected through phi instructions. We define a notion of \nan SSA web to be the set of SSA names that are connected to each other by phi instructions. In the running \nexample above, the SSA web consists of (x0,x1,x2,x3,x4). In the next section we discuss the construction \nof SSA webs within an interval, promoteInlntewal(lnterval intvl} / for each child interval, ch, of Interval \nintvl do ( promoteInInterval(ch); I //Promote in the current interval. Set webs = constructSSAWebs(lntv1~; \nfor each web w in webs do { promoteln Web(w); I cleanup(); I Figure 2. Promotion algorithm based on intervals. \n4.2 Construction of Memory SSA Webs Based on the second promotion approach, a memory SSA web is the unit \nof promotion within an interval. A memory SSA web in an interval is the set of all singleton memory resources \nthat are connected to each other by phi instructions in the interval. We define the relation connected \nbetween two names: x and y, as below l x connected to x l x connected to y if x and y are both operands \nof a phi instruction in the current interval. This relation is symmetric and reflexive. The transitive \nclosure of the connectivity relation partitions all of the names in the interval into a set of equivalence \nclasses of names. We call such an equivalent class an SSA web or simply a web. A variable definition \ncontaining a pointer store or a call, which generates new names, gives rise to multiple webs. Consider \nan example x = . . foo0 Both foo() and bar0 potentially define and use x. After SSA renaming, the code \nis represented as xl = ., x2 = foo () uses xl x3 = bar () uses x2 In this example, there are three SSA \nwebs, (xl), (x2}, and (x3}, corresponding to x, and each of which is considered individually for promotion. \nThus the call to bar0 need not be considered when promoting xl. Finer grained units of promotion expose \nmore opportunities for promotion. SSA webs in an interval can be constructed by a simple union- End algorithm \n[AHU74] as shown in Figure 3. constructSSAWebs(Interva1 intvl) ( for each resource r in the interval \n( web(r) = {r); ) for each phi instruction xo = phi(xI,..., xJ of intvl ( rep-x0 = FIND(xo); . . . . \nrep-x,,= FIND&#38;J; UNION(rep-xo, . . . . UNION(rep-.x,-I, rep-x,Jj; I A web represented by rep-x is \nall the elements of its set web(rep-x)= ( Xi I rep-x = FIND(XJ } I Figure 3. Memory SSA web construction \nalgorithm. We define several sets of resources and references associated with a web. These sets are used \nby the web promotion algorithm. The set WebReferences consists of all the references of the resources \nof the web. All web references can be collected by scanning the instructions in the interval in a single \npass. By processing references in a web, we also associate several related sets with a web to be used \nlater. These sets are webResources:The equivalence class of all the names in the web. WebReferences: \nThe set of references of all the webResources in the current interval. deflesources: The set of singleton \nresources of web deEned in the current interval. 1iveInResource: a unique resource that is defined in \nan ancestor interval. loadReferences: The set of references that are singleton loads of the web. StoreReferences: \nThe set of references that are singleton stores of the web. aliasedL.mdReferences: The set of potentially \nuse resources of the web. pointer loads and function calls. references that can These correspond to aliasedStoreReferences: \nThe set of references that can potentially define one of the web resources. correspond to pointer stores \nand function calls. These 1iveOutResources: The set of resources that are deEned in the web, but have \nuses outside the interval. loaa!waifed: The set of pairs (x,i) where x is a resource, and i is an instruction \nbefore which a load of x is inserted. I [ x4+5glJ$x3 ; 1 stores-added The set of pairs (x,i) where x \nis a resource, and i is an instruction before which a store of x is inserted. The loads-added and stores-added \nsets are discussed in the next section in determining profitability. Following are certain properties \nof these sets. These properties are based on the fact that assuming all memory updates single threaded, \nno two singleton resources that represent the same memory location may have their live ranges interfering \nwith each other. l There is at most one live-in resource for a web. l Each aliased store defines a unique \nresource in the web. l Each aliased load uses a unique resource in the web. l There is at most one resource \nof the web that is live-out of each exit of the interval containing the web. 4.3 Profitability Considerations \nIn order to eliminate existing loads and stores in the web, we may have to insert some new loads and \nstores on paths containing aliased loads and stores. Promotion is beneficial if the execution frequency \nof the new loads and stores is less than that of the original loads an stores in the web. Consider the \nexample discussed below. If b3 and M are not very frequently executed, then the load in b5 can be eliminated \nby placing loads at the ends of blocks b3 and b4. We use the phi structure of the web to identify basic \nblocks where loads and stores should be added. We call a phi operand a leaf, if this operand is not defined \nby a phi instruction. The set of loads added is given by loads-added= ( (x,i) I x is a leaf that is not \ndefined by a store of the web and there is an instruction t = phi( ,,., x:L ,.,, ). and i is the last \ninstruction of basic block L. ) (x,i) means that a load of resource x has to be added before the instruction \ni. We assume that the last instruction of any basic block is an explicit branch instruction. In the example \nabove, by examining the phi instruction we can see that loads have to be added at b3 and b4. To determine \nthe program points to add stores, we partition aliased loads into two sets, namely the ones using phi \nresources, and the others using stores of the web. Notice that we don t need to place a store for an \naliased load that uses a resource which is either deEned outside the current interval or is defined by \nan aliased store. The stores-added set is determined as stores-added= ( (x,i) I x is a store, and there \nis a phi instruction t = phi( . . . . x:L,..) such that an aliased load depends on t, i is the last instruction \nin L.} + ( (x,i) I x is a store, and x is used by an aliased load in instruction i. ) If there are two \nelements (x,i), and (xj) in the stores-added set and the instruction i dominates j, we eliminate (xJ) \nfrom the set. These sets can be computed by scanning the phi instructions of the web and by using the \naliasedLoadReferencesof the web. The profit of promotion is the difference between the execution frequency \nof the loads/stores added and the loads/stores deleted. profit = ( freq(ldRef) I 1dRef is a load reference \nwhose resource is deflned by a phi or a store ) + { freq(stRef) I stRef is a store reference } - ( freq(i) \nI (x,i) is in loads-added} - ( freq(i) I (x,i) is in stores-added }  In some cases, it may be profitable \nto replace loads, but the profit diminishes if we eliiinate stores. Based on the cost of removing stores, \nwe can decide not to remove stores, In such cases a variable resides in memory and in a virtual register \nsimultaneously. 4.4 Web Promotion A web is a basic unit for promotion. Within an interval a variable \ncan exist as several SSA memory webs. Bach web is considered independently for promotion. This finer \ndistinction of webs make the promotion algorithm more effective. The web promotion algorithm is shown \nin Figure 4. For every web we Erst compute the benefit of promotion as discussed in the previous subsection, \nIf it is beneficial and there are no definitions in the web, we add a load in the preheader and replace \nall of the loads in the web by copy instructions. If there are definitions in the web, then we invoke \nprocedure replaceLoadsByCopies(). In these steps we ensure that the program is maintained under SSA form \nafter the loads are replaced by copy instructions. These copy instructions are eliminated later. promoteInWeb(web) \n( profit = computeProjit(web); if(pro$t >= 0) ( ifWfs0 = (1) / aad a load to the preheader and replace \nall loads in the web by copy instructions. } else { initVRMap(); insertL.oadsAtPhiLeaves(); replaceLoadsByCopies(); \nif ( profitable to remove stores ) ( insertStoresForAliasedLoads(); insertStoresAtIntervalTails(); deleteStores(); \nI I if there are aliased loads in web, add a dummy aliased load in the preheader that aliases the live-in \nresource of web. } else { if there are aliased loads, loads or stores in the web then add a dummy aliased \nload in the preheader that aliases the live-in resource I I Figure 4. Algorithm for promotion in a web. \n After having promoted in an inner interval, we want to summarize the information for the parent interval. \nIf there are abased loads, such as function calls and pointer loads, in the inner interval, then we have \nto assume that the value of the live-in resource must be valid in memory before entering the interval. \nIn order to do so, we define a dummy load that aliases the live-in resource and add it to the preheader \nof the interval. Dummy aliased loads serve the purpose of aliased loads, and the algorithm deletes them \nafter promotion. Similarly, if a web could not be promoted for a profitability reason, a dummy load is \ninserted in the interval preheader. To facilitate the update of SSA form, we maintain a mapping, called \nvrMap, from singleton resources to virtual registers. If vrMap[res] is a valid virtual register, then \nit implies that the value of the singleton memory resource is always available in that virtual register. \nThe routine initVRMap() inserts a copy instruction, t = v, immediately after a store St lx] = v and adds \nthe mapping x-X to the vrMap. The routine insertLoadsAtF hiLeaves() adds loads to the web. For each element \n(x,i) in the loads-added set, it adds a load t = Id [xl before the instruction i. The routine replaceLoadsByCopies() \nas shown in Figure 5 replaces each load whose resource is defined by a store or a phi instruction. replaceLoadsByCopies() \n{ for each load t = ld [xl in web ( if (x is defined by a store or a phi instruction ) ( v = materializeStoreklue(x); \nreplace load by a copy 2 = v I I Figure 5. Load replacement in a web. The procedure materializeStoreValue() \nshown in Figure 6 is used to materialize the value of a singleton memory resource in a virtual register. \nIt assumes that all of the necessary loads or copy instructions have been inserted in the web. It recursively \nvisits the connected phi instructions associated with the web to materialize the value of each phi operand \nand adds it to the vrMap. For a leaf operand of a phi, if it is not defined by a store, we get the load \nfrom the appropriate predecessor basic block of the phi instruction. Such a load exists because it was \nadded by the insertLoadsAtPhiLeaves() routine. resource materializeStoreValue(memRes) ( if (memRes -> \nr is in vrMap) return c else ( // memRes must be defined by a phi instruction, let phi be memRes=phi(xl:Ll,...,xn:Ln); \nfor each phi source xi ( if (xi is a leaf and not a store) ( //there must be a load t = Id [xi] in Li \n// added by insertLoadsAtLeaves() ti = t / else ti = materializeStoreValue(xi); add the phi instruction \nto = phi(tl:Ll,...,tn:Ln) after memRes=phi(xl:Ll,...,xn:Ln) . add memRes->tO to vrMap return to; I I \nFigure 6. Algorithm to materialize store value in a register. Notice that the parameter to materializeStoreValue() \nis always deEned by a store or a phi instruction. This property holds for the recursive call as well \nas for the call from replaceLoadsB yCopies(). In the routine replaceLoadsByCopies(), for every load t \n= Id [xl that is defined by a phi instruction or a store, we materialize the value of x using materializeStoreValue() \nand replace the load by a copy t = vrMap[xl . The program is maintained under SSA form after load replacement. \nStore insertion for aliased loads is handled by the routine insertStoresForAliasedLoads(). For each element \n(x,i) of the set stores-added, we insert a store St [xl = vrMap[xl . If there are any web definitions \ndefined by a phi or store instruction in the web that are live outside the interval, we need to insert \nstores in the tail block of each exit edge of the interval. The function insertStoresAtIntervalTails() \ninserts immediately after the store (store is removed after SS A these stores. Each exit edge has a unique \nlive-out definition update). The value of xl is materialized in a virtual register which is the immediately \ndominating definition that reaches using materializeStoreValue(). It creates definitions tl and the exit \nblock. We materilaize the store value of the live-out t4. The value of t5 is stored before the function \ncall in b2. resource using materializeStoreValue() in each interval tail and store that value in the \ntail. Adding new stores creates new SSA names. We perform an incremental update of SSA form to accommodate \nthe newly generated names. Both the routines insertStoresForAliasedLoads() and insertStoresAtIntervalTails() \nperform an incremental update after the stores are inserted in the web. To illustrate the algorithm, \nwe consider the following example that contains a function calI on a less frequently executed path. mW> \n( for (i=O; i< lOO;i++) ( x++; if (x < 30) foo(); 1 I The SSA graph for variable x is shown below before \npromotion. xl=~(xO,x4) bl tl =ld xl; t2 =t1+1; x2 =st[]t2; 1 ( xs=foo() lb2 b4 Figm-e 7. SSA graph for \nthe example before promotion By examining all of the phi instructions in the interval, we determine that \nwe have to add a load of x0 at the end of b0 and a load of x3 at the end of b2. To eliminate the store \nwe have to add a store before foo(). A store has to be added at b4, which is the tail block. In this \nexample foo() is executed less frequently, so it is beneficial to place a load and a store in b2. The \ntransformed program after promotion is shown in Figure 8 below. A copy of t5 = t2 is placed in bl Assuming \nthat x4 was live-out upon the exit before promotion, its value t4 is stored in the tail block b4. Memory \nphi instructions which define xl and x4 become dead after the transformation and thus can be removed. \nbl Figure% The SSA graph after promotion of x. The store in basic block bl will be deleted after the \nSSA graph has been updated. For intervals with multiple exits, we need to insert multiple stores of a \nlive out resource in each of the interval tails. Uses of the live out resource in the enclosing ancestor \nintervals may be reached by the new definitions added. In such case, one has to rename these uses to \nrefer to the new definition. In some cases, both a new definition and an old one can reach a use. This \nwould require combining these two definitions using a phi instruction and renaming the use with the phi \ndefinition. In general, after insertion of new definitions at the interval tail, one has to update the \nSSA graph. In the next subsection we consider the problem of incremental update of an SSA graph when \nnew definitions for an existing resource are introduced in the source program. This method is used to \nperform the SSA update after store insertion in the register promotion algorithm. The incremental update \nalgorithm is quite general and it can be used in other algorithms such as loop unrolling where multiple \ndefinitions are generated for a resource, and for incrementally converting resources to SSA form. When \na compiler phase adds a new resource with multiple definitions and uses to the code stream, the resource \ncan be converted into SSA form by using the incremental update algorithm. 4.5 Incremental SSA Update \nb2 b5 =x0 b6 Figure 9. Example 2: Before SSA update The problem of incremental SSA update for cloned \ndefinitions can be illustrated by Example 2 in Figure 9 and 10, which show the original code and transformed \ncode, respectively. There are six basic blocks in this interval. For simplicity, we do not split the \nedge from b2 to b5. In Figure 9, memory resource xc, is defined in bl. Each of b3, b4, and b5 contains \na use of x0. Assume that register promotion creates two stores: one in b2 and the other in b3 while promoting \nthe web containing xu. To preserve the single assignment property, we cannot have the targets of cloned \ndefinitions be xo. Thus, we rename the target of the new definition in b2 x1 and the one in b3 x2. With \nthe two new names, phi instructions have to be inserted and the original uses of ~0 need be renamed properly \nas shown in Figure 10. Three phi instructions are inserted at bl, b5 and b6, respectively, which are \nthe iterative dominance frontier [CFR+91] of the basic blocks containing the new definitions, i.e. b2 \nand b3. Based on the reachability in control flow to be shown in detail in our algorithm, the use at \nb3 is renamed x2, the use at b4 renamed xl, and the use at b5 renamed x3. One can find that the phi instruction \nat b6 is dead and can be eliminated because there is no use of the target, x4. In this subsection, we \ndevelop a systematic and efficient process to incrementally update SSA form specifmally for a transformation \nthat duplicates a set of new definitions from one or more existing definitions, such as the example in \nFigure 9. Figure 11 shows the algorithm to incrementally I1x4 = $(-)I I b6 Figure 10. Example 2: After \nSSA update and before removing dead phi instructions update SSA form for this transformation. Function \nupdateSSAForClonedResources() performs such an incremental SSA form update. The first input is oldResSet, \nwhich contains an existing set of resources under SSA form. These resources were originally renamed from \nthe same variable during SSA construction. The definitions of these resources may or may not be dead \nafter this SSA update. The second input is clonedResSet, which contains a set of new resources cloned \nfrom those in oldResSet. During register promotion, the definitions of these new resources have been \ninserted into the instruction stream. Because the definitions in both oldResSet and clonedResSet may \nbe live, Step 1 starts out by collecting the basic blocks which contains all of these definitions. We \nthen compute the iterative dominance frontier for the collected basic blocks in initDefBBSet. A phi instruction \nis placed at the beginning of each basic block in iterDomFrontBBSet. The resource created as the target \nfor each phi instruction is added to phiTargetResSet. We also combine the resources in oldResSet, clonedResSet, \nand phiTargetResSet to form allDefResSet. In Step 2, each use reference of a resource in oldResSet is \nrenamed according to the reaching definition computed by computeReachingDef(). If the reaching definition \nis from a phi instruction, this phi instruction is added to phiWorkSet. Since SSA form has a property \nthat the definition of a variable dominates all of its uses, the computeReachingDef() function traverses \nthe dominator tree bottom-up to find the reaching definition for a given use instruction. If there is \na definition in the same basic block as the use, this definition is the reaching definition only if the \ndefinition precedes the use. In Step 3, we process the created phi instructions which are triggered live \nrecursively by the uses of the resources in oldResSet. For a live phi instruction, we add the reaching \ndefinition from each predecessor as a source operand in the phi instruction. Note that a source operand \nin a phi instruction is treated as live at the end of the respective predecessor. We ensure that each \nphi instruction is entered phiWorkSet no more than once. In Step 4, we achieve efficient dead code elimination \nby deleting every definition which has no use. This allows us to delete (1) the dead definitions of the \nresources in oldResSet, (2) any inserted redundant phi instructions in Step 1, and (3) any dead definition \nof the cloned resources in clonedResSet. For example, the phi instruction defining x5 in bl in Figure \n10 will be deleted, because there is no use of x5. The phi instruction defining x4 in b6 is also dead \nand will be removed. As a result, we guarantee that there is no dead code introduced due to the cloning \nof the resources in oldResSet after applying the incremental SSA update algorithm. updateSSAForClonedResources(oldResSet, \nClonedResSet) oldResSet: a set of existing resources under SSA form where these resources were originally \nrenamedfrom the same name during SSA construction. clonea!ResSet:a set of new resources, which are cloned \nfrom the resources in olaXesSet. / //Step 1: initDejBBSet = / basic block BB I for every resource in \noldResSet and clonedResSet, BB is the basic block where the resource is de@ed); iterDomFrontBBSet = the \niterative dominance frontier of initDe@BSet; phiTargetResSet= 0; Place a phi instruction with target \nresource targetRes at each basic block in the iterDomFrontBBSet, andphiTargetResSet += targetRes; allDefResSet= \nolaResSet + clonedResSet + PhiTargetResSet; phiWorkSet = (1; //Step 2: for every use reference useRef \nof each resource in 0ldResSet do ( thislnst = the instruction containing useRe$ ola!Res= the resource \nin useRe$ reachingDefles=computeReachingDeflthisInst, allDefResSet); if (0ldRes != reachingDefles) ( \nreplace oldRes with reachingDejRes in useRe$ ijj reachingDefies is defined by a phi instruction, philnst \n) { phiWorkSet + = philnst; /- //Step 3: while ( phiWorkSet != {I ) f thisPhiInst = a phi instruction \nretrieved and removed from vhiWorkSer * Mark th&#38;Phiinst as live;*- for each predecessor predBB of \nthe basic block containing thisPhiInst do ( Create a virtual use instruction, uselnst, at the end of \npredBB; reachingDefRes=computeReachingDefluselnst, allDejResSet); Place reachingDe@es as a source resource \nin thisPhiInst in association with predBB; if (reachingDefles is defined by a phi instruction, dephilnst, \nand dejPhiInst not marked live) { phi WorkSet + = a?ejPhiInst; I I / I!! Step 4: for every resource, \nres, in allDefResSet ( thisInst = the instruction that defines res; // thislnst may be a phi instruction \nor an //instruction defining a resource from /! oldResSet or clonedResSet: if (there is no use reference \nof res) delete thislnst; I I Resource ComputeReachingDeflinst, allDejResSet) / currBB = the basic block \ncontaining inst; ifl allDejResSet has a resource, dejRes, defined in currBB &#38;&#38; defies is defined \nby an instruction preceding inst ) ( return defies; I Traverse each basic block, thisBB, in the dominator \ntree from currBB toward the root { if (a resource, defies, in allDefResSet is defined at thisBB) return \ndepes; I I Figure 11. An algorithm to incrementally update SSA form for cloned definitions. Our algorithm \nof incremental SSA update for cloned resources has advantages compared to a prior work [CSS96], which \nalso proposed a method to incrementally update SSA form. Their work dealt with one inserted definition \nat a time and has to compute iterative dominance frontier for every inserted definition, which requires \na linear time computation with respect to the number of nodes (=n) in the control flow graph. For m definitions, \nthey need O(m x n) time to compute iterative dominance frontier. In our algorithm, multiple definitions \nincluding the cloned ones and the old ones are handled simultaneously. We can use a linear time algorithm \n[SrG95] to compute the iterative dominance frontier for multiple definitions to place phi instructions. \nThe SSA update for the deletion of old definitions and the insertion of cloned new definitions are handled \nsimultaneously. Therefore, our algorithm is more efficient in terms of compilation time. In addition, \nour algorithm removes any dead definitions of the cloned resources and old resources and any inserted \ndead phi instructions. As a nice side effect, our SSA update algorithm guarantees that no dead code is \ncaused by the transformation which clones definitions. 5. EXPERIMENTAL RESULTS The proposed algorithms \nof register promotion and SSA incremental update have been implemented in our compiler. In order to measure \nthe effect of register promotion, we measured static and dynamic costs of loads and stores. The benchmarks \nare from the SPECInt95 test suite. The static cost of an operation is simply the number of occurrences \nof that operation in the program. The dynamic cost of an operation is the summation of the execution \nfrequency of the containing basic block for every occurrence of the operation. Table lgives the static \nnumbers of loads and stores before and after the register promotion phase. In most of the benchmarks \nthe static numbers of loads and stores increase due to register promotion. Table 2 gives the dynamic \ncost of memory operations before and after register promotion. In both of these tables, loads and stores \nrefer to the singleton loads and singleton stores. Except for vortex, there is a signiticant reduction \nof memory operations in all of the benchmarks. The benchmark go uses a number of global variables including \nfreelist, mvp, etc. which are successfully promoted by our algorithm. The benchmark ijpeg shows a significant \nreduction in loads even though only few stores could be eliminated. Table 3 shows the impact of register \npromotion on register allocation. For each benchmark, we selected routines that had opportunities for \npromotion and computed the number of colors needed to color the register interference graph. Register \npromotion indeed increases register pressure and requires more registers to color the graph. The effect \nis more pronounced on routines that require smaller numbers of colors. I I I I I Benchmarks Static Loads \nStatic Stores Total B&#38;R After (464impro.) Before After (% of hPW Before Atb (a of impro.) go 1229 \n1405 -14.3 558 544 2.5 1787 1949 -9.1 li 771 799 -3.6 567 591 -4.2 1338 1390 -3.9 ibeg 327 346 -5.8 238 \n231 2.9 565 577 -2.1 per1 2714 2865 -5.6 2834 2843 -0.3 5548 5708 -2.9 m88k 2151 2168 -0.8 1292 1231 \n4.7 3443 3399 1.3 SC 12690 14119 -11.3 4249 3938 7.3 16939 3938 -6.6 compr 95 94 1.0 71 70 1.4 166 164 \n1.2 vortex 7986 8383 -5.0 4762 4719 0.9 12748 13102 -2.8 - Table 1: Effect of register promotion on static \ncounts of memory operations Dynam : Loads F go li Before 11346241 3 1436460 Alter 8455997 26242721 (pro \nof impro ) 25.5 16.5 t Meg 5885845 10774089 8695017 25.7 19.3 18096246 16651273 8.0 23071776 20056225 \n13.1 35526549 33781490 4.9 14877989 14853592 Tab ? 2: Effect of .egister womotion on dynamic counts of \nmemory operations Table 3: Effect of register promotion on register pressure 6. RELATED WORK Although \nregister promotion is a well known optimization, there has not much work been published in this area. \nRecently [LuC97] presented a loop based register promotion algorithm for scalar variables. For each loop \nnest, the algorithm computes the set of variables that can be promoted in the loop. Any variabie that \nhas an ambiguous use in the loop is not considered for promotion. For variables that are promotable in \ncurrent loop but not in the enclosing outer loop, loads and stores arc inserted at the loop preheader \nand tails. The paper also shows that pointer analysis does not greatly improve the results of register \npromotion. Since this algorithm does not use profiling information, it is also restrictive in the sense \nthat the presence of function calls precludes any promotion even if these calls are executed very infrequently. \nIt is not clear how the algorithm can be extended to incorporate profile information. This algorithm \nis not designed to work on SSA representation. Compared to this algorithm, our algorithm inserts loads \nand stores in the enclosing interval, relying on the recursive promotion of the outer interval to propagate \nthese loads and stores to the appropriate interval. The global variable migration optimization of the \nIMPACT compiler promotes global scalar variables, array elements, or local variables in super blocks \n[Mah92]. This algorithm is also loop based and uses profiling information. Typically, function calls \nor unknown pointer references that are less frequently executed will not be included in a superblock. \nIf there are function calls in the super block that are not side- effect free, promotion is not attempted \nin that superblock. This algorithm is not designed to work on SSA representation, either. Steve Carr \ns work on scalar replacement [CaK94] promotes array elements to scalar registers that are used across \nmultiple iterations in a loop nest. Their work uses dependence information to identify loops for such \nopportunities. 7. CONCLUSION We presented a new register promotion algorithm based on Static Single Assignment \n(SSA) form. Our algorithm is profile-driven and is based on the scope of intervals. In the presence of \nfunction calls or pointer references, the proposed algorithm is capable of eliminating loads and stores \non frequently executed paths by placing loads and stores on less frequently executed paths. We also proposed \nan efficient algorithm to incrementally update SSA form due to new names introduced by register promotion. \nExperimental results for the SPECInt95 benchmarks show -12% reduction in dynamic counts of memory accesses \nof scalar variables because of register promotion. 8. ACKNOWLEDGMENTS We would like to thank Vatsa Santhanam \nfor sharing his insights on register promotion on SSA representation and Carol Thompson for providing \nus with useful comments on an earlier draft of this paper. Thanks to Rick Hank for sharing his knowledge \nof global variable migration. We  would also like to acknowledge the encouragement and support of the \noptimizer team at Performance Delivery Laboratory, Hewlett Packard. 9. REFERENCES [AHLJ74]A.V. Aho, J.E. \nHopcroft, and J.D. Ullman, The Design and Analysis of Computer Algorithms, Addison- Wesley, Reading, \nMass., 1974. [CaK94]S. Carr and K. Kennedy, Scalar Replacement in the Presence of Conditional Control \nFlow, Software -Practice and Experience, Vol. 24(l), pp. 51-77, January 1994. [CSS96]J. Choi, V. Sarkar, \nand E. Schonberg, Incremental Computation of Static Single Assignment Form, Proceedings of the 1996 Conference \non Compiler Construction, April 1996. [Cli95]C. Click, Global Code Motion Gloabl Value Numbering , Proceedings \nof the 1995 SIGPLAN Conference on Programming Language Design and Implementation, pp 246-257, June 1995. \n[CFR+91] R. Cywon, J. Ferrante, B. Rosen, M. Wegman, and F. Zadeck, Efficiently Computing Static Single \nAssignment Form and Control Dependence Graph, ACM Trans. on Programming Languages and Systems, 13(4):452- \n490, October 1991. [LuC97]J. Lu and K. Cooper, Register Promotion in C Programs, Proceedings of the 1997 \nSIGPLAN Conference on Programming Language Design and Implementation, pp 308-319, June 1997. [Mah92]S. \nMahlke, Design and Implementation of a Portable Global Code Optimizer, MS. thesis, Dept. of Electrical \nand Computer Engineering, University of Illinois, Urbana, IL, Sept. 1992. [RWZ88lB.K. Rosen, M.N. Wegman, \nand F.K. Zadeck, Global Value Numbers and Redundant Computations, In Conference Record of the Fifteenth \nACM Symposium on the Principles of Programming Languages, Jan. 1988. [SrG95]V.C. Sreedhar and G.R. Gao, \nA Linear Time Algorithm for Placing f-nodes, In ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, January 1995. [Muc97]S. Muchnick, Advanced Compiler Design and Implementation, Morgan Kaufmann \nPublishers, 1997. IWeZ91lM.N. Wegman and F.K. Zadeck, Constant Propagation with Conditional Branches, \nACM Trans. on Programming Languages and Systems, 13(2):181-210, April 1991. \n\t\t\t", "proc_id": "277650", "abstract": "We present a new register promotion algorithm based on Static Single Assignment (SSA) form. Register promotion is aimed at promoting program names from memory locations to registers. Our algorithm is profile-driven and is based on the scope of intervals. In cases where a complete promotion is not possible because of the presence of function calls or pointer references, the proposed algorithm is capable of eliminating loads and stores on frequently executed paths by placing loads and stores on less frequently executed paths. We also describe an efficient method to incrementally update SSA form when new definitions are cloned from an existing name during register promotion. On SPECInt95 benchmarks, our algorithm removes about ~12% of memory operations which access scalar variables.", "authors": [{"name": "A. V. S. Sastry", "author_profile_id": "81100216969", "affiliation": "Performance Delivery Laboratory, Hewlett Packard Company, 11000 Wolfe Road, MS 42 U5, Cupertino, CA", "person_id": "PP31032525", "email_address": "", "orcid_id": ""}, {"name": "Roy D. C. Ju", "author_profile_id": "81451594942", "affiliation": "Performance Delivery Laboratory, Hewlett Packard Company, 11000 Wolfe Road, MS 42 U5, Cupertino, CA", "person_id": "P249895", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277656", "year": "1998", "article_id": "277656", "conference": "PLDI", "title": "A new algorithm for scalar register promotion based on SSA form", "url": "http://dl.acm.org/citation.cfm?id=277656"}