{"article_publication_date": "05-01-1998", "fulltext": "\n Data Transformations for Eliminating Conflict Gabriel Rivera, Chau-Wen Tseng Department of Computer \nScience University of Maryland College Park, MD 20742 {rivera,tseng}@cs.umd.edu Abstract Many cache misses \nin scientific programs are due to con-flicts caused by limited set associativity. We examine two compile-time \ndata-layout transformations for eliminating con-flict misses, concentrating on misses occuring on every \nloop iteration. Inter-variable padding adjusts variable base ad- dresses, while intra-variable padding \nmodifies array dimen-sion sizes. Two levels of precision are evaluated. PADLITE only uses array and column \ndimension sizes, relying on as- sumptions about common array reference patterns. PAD analyzes programs, \ndetecting conflict misses by linearizing array references and calculating conflict distances between \nuniformly-generated references. The Euclidean algorithm for computing the gcd of two numbers is used \nto predict conflicts between different array columns for linear alge-bra codes. Experiments on a range \nof programs indicate PADLITE can eliminate conflicts for benchmarks, but PAD is more effective over a \nrange of cache and problem sizes. Padding reduces cache miss rates by 16% on average for a 16K direct-mapped \ncache. Execution times are reduced by 6% on average, with some SPEC95 programs improving up to 15%. 1 \nIntroduction Because of the increasing gap between processor and mem-ory speeds, programs can achieve \nhigh performance only if they use caches effectively. Due to hardware constraints, caches have limited \nset associatiuity, where memory addresses can only be mapped to one of k locations in a k-way asso-ciative \ncache. Conflict misses may occur when too many data items map to the same set of cache locations, caus- \ning cache lines to be flushed from cache before they may be reused, despite sufficient capacity in the \noverall cache. Conflict misses have been found to be a significant source of poor performance in scientific \nprograms, particularly within loop nests [18]. We believe compiler transformations can be very effective \nin eliminating conflict misses for scientific programs with regular access patterns. We evaluate two \ncompiler trans-formations to eliminate conflict misses: inter-and intra-variable padding [3, 211. Unlike \nstandard compiler transfor- This research was supported in part by NSF grant #CCR9711514 and NSF CAREER \nAward #ASC9625531 in New Technologies. Permission to make digital or hard copie8 of all or pen of thiq \nwork for personal or classroom ume ia Stanted without fee provided that copies are not made or distributsd \nfor piofit or commercial advan-taw and that copies bear thie notice and the iull citation on the first \npaSe. To copy othsrwi~e. lo republish. to pea on sawen w to redistribute lo list*. raquirss prior qwcific \npermission and/or (I fee. SIGPIAN 98 Montreal, Canada 0 1998 ACM 0-89791~9874/98/0006,.,$5,00 real S, \nA(N), B(N) -> do i = 1,N S = S + A(i)*B(i) Figure 1: Inter-Variable real A(N,N), B(N,N) -> do i = 2,N-1 \ndo j = 2,N-1 Misses real A(N), DUM(PAD) , B(N) Paddine: (Change real A(N+PAD,N), B(j,i) = (A(j-l,i)+A(j,i-l)+A(j+l,i)+A(j,i+l))/4 \nFigure 2: Intra-Variable Padding (Change mations which restructure the computation the program, these \ntwo techniques modify data layout. Both padding transformations cussed in the literature, but we are \nthe first Base Addr) B(N,N) Dim. Size) performed by the program s have been dis-to: 1) develop and implement \nefficient, practical compile-time padding heuristics, 2) empirically evaluate padding transformations \nover a large collection of programs, and 3) investigate preci-sion of analysis needed to guide padding \nfor different cache and problem sizes. 1.1 Severe Conflicts We begin by examining two motivating examples \nfor padding transformations. In Figure 1, unit-stride references to A(i) and B(i) provide spatial locality, \nleading to cache reuse. However, if A and B are separated by a multiple of the cache size and the cache \nis direct mapped, every access to B(i) will map to the same cache line as the previous A(i) access and \nvice versa. As a result, every reference will produce a conflict miss. To regain the benefits of spatial \nreuse, inter-variable padding may be applied as shown in Figure 1. In Figure 2, the stencil computation \nexhibits much spa-tial and temporal reuse between the references to A. How- ever, if the column size \nof A is a multiple of the cache size, columns of A will conflict, eliminating reuse between refer-ences \nto A. To regain spatial reuse, intra-variable padding applied to the columns of A can change its internal \nlayout so that columns no longer map to conflicting locations on the cache, as shown in Figure 2. Both \nof these examples show instances of severe conflict misses, when references cause cache lines to be flushed \nto memory on every loop iteration. In linear algebra kernels, semi-severe conflicts may exist which occur \nregularly on a large percentage of loop iterations. In this paper, we de-velop and evaluate several heuristics \nfor applying data layout transformations to eliminate these severe conflict misses. 2 Padding Heuristics \nWe present PADLITE and PAD, two heuristics for guiding both inter-and intra-variable padding. PADLITE \nonly re-quires knowledge of array dimension sizes to choose pads. To replace analysis, PADLITE relies \non assumptions about data access patterns found in real programs. In compari-son, PAD analyzes array \nreferences in the program to choose pads. PAD is more precise, at the expense of greater com-plexity. \nFor convenience, we refer to the inter-variable padding portion of PADLITE and PAD as INTERPADLITE and \nINTER- PAD, respectively. Similarly, the intra-variable padding por-tion of PADLITE and PAD are refered \nto as INTRAPADLITE and INTRAPAD, respectively. We also present LINPAD~ and LINPAD~, two intra-variable \npadding heuristics for eliminat- ing conflict misses in linear algebra codes that are applica-ble to \nboth PADLITE and PAD. We describe each padding heuristic separately, then show how they are combined \nto form PADLITE and PAD. For each heuristic, we present a pad condition which when true indicates padding \nshould be applied. In this paper we refer to the cache size as C,, the cache line size as L,, and the \ncolumn size of an array as Cal,. The conflict distance between two locations is the difference in addresses \nmod C,. When the conflict distance is less than L,, a conflict miss may arise unless the addresses are \nactually located on the same cache line. 2.1 Inter-variable Padding We begin by describing INTERPADLITE \nand INTERPAD. The analysis required by INTERPADLITE is sufficiently simple that it can be conveniently \nperformed by the linker, mak-ing INTERPADLITE a good heuristic for performing inter-variable padding \nat link time.  2.1.1 INTERPADLITE Motivated by the assumption that severe conflicts commonly arise from \ninterference between references to variables of the same size, INTERPADLITE attempts to separate base \nad-dresses of equally-size variables from one another on the cache. While separation by one cache line \nwill ensure that references of the form B(i) and C(i) do not conflict, a larger separation may be required \nfor references such as B(i) and C(i-2). Therefore, a value M, typically a small number of cache lines, \nis chosen as a minimum separation distance for these base addresses. In Section 4.3, we give results \nsupport-ing the choice of M = 4 cache lines. This value is adopted for M in the remaining discussion. \nPadding is performed in a simple, greedy fashion. Vari-able base addresses are initially undefined and \nthen assigned one at a time. The first variable is assigned to location 0. The next available location, \n0 + the size of the first variable, is considered as a tentative location for the second variable. Similarly, \non each iteration, the next available location is considered as a tentative location for the next variable. \nThe tentative location may be incremented, or padded, if it is not acceptable. A variable s tentative \nlocation is rejected when it has a conflict distance less than A4 from some other equally-sized variable \nwhose base address has been already assigned. When this pad condition occurs, the tentative location \nis in- cremented as necessary. This test-and-pad step is repeated, ending as soon as a location suitably \nspaced from all equally- sized variables has been found. In the event that the location is incremented \nbeyond its original position by a distance larger than the cache size, no satisfactory base address is \npossible and the initial tentative location is assigned. For this case to occur, a base address must \nmap to each block of size 2M on the cache. Satisfactory base addresses will be found for all variables \ntherefore when the number of variables of the same size does not exceed C,/(2M) (while INTERPADLITE can \nsuccessfully lay out C,/M such variables when base addresses are placed multiples of M apart from one \nother, less regular spacings may result, permitting the assignment of fewer variables). For example, \nif C, = 2048 and M = 16, up to 64 equally-sized variables are guaranteed to be padded a distance at least \nM from one another. In our experiments on a 16K cache, INTERPADLITE has always found a satisfactory layout. \n 2.1.2 INTERPAD To eliminate severe conflict misses, INTERPAD considers pairs of array references with \nconstant conflict distances on each loop iteration. Such pairs are commonly uniformly gener-ated references \n[9] extended for conforming arrays, arrays that have equal dimension sizes in all but their highest di-mension \nand possess equal-sized elements. A pair of uni- formly generated references to d-dimensional conforming \nar-rays A and B has the form A(il + ~1, is + ~2, . . . . id + rd) and B(~I + SI, i2 + ~2, . . . . id \n+ sd), where each ij iS an integer variable or the value 0, and each Tj and Sj is some constant integer \nvalue. Uniformly generated references may include references nested in for loops with indices i,, references \nto l-dimensional arrays of different size, and references with integer subscripts (in which case i, reduces \nto 0). We can calculate the memory address of a multidimen- sional array reference by linearizing its \nsubscripts. Subtract-ing two linearized references gives their distance. When the distance is computed \nbetween any two uniformly generated references on a given loop iteration, we obtain an expression in \nwhich all ij terms cancel: ,~aseAdd7(A)-BaseAddr(B)+~([r,-sjlS=~~S*)l (1) j=l k=l In this expression, \nBaseAddr(A) and BaseAddr(B) are the base addresses of A and B, Se is the common element size, and Sk \nis the common size of dimension A. A lower bound of 0 is assumed in each dimension, but other lower bounds \nIA,, and in,, may be accounted for by adding In,, -~A,J to the factor [rj -s3]. Taking the mod of the \ncache size C, yields the conflict distance between the references. Base addresses are selected by INTERPAD \nusing a greedy approach similar to INTERPADLITE. Variables begin with undefined base addresses which \nare assigned in turn. For each variable A, we first consider the next available base ad- dress. For all \nvariables B with defined base addresses, we compute the conflict distances between the uniformly gen-erated \nreferences of A and B over all loops. If any distance in any loop < L,, the tentative location is incremented \nas nec- essary to eliminate this pad condition and the test repeats. Observe that making the conflict \ndistance L, or greater is a sufficient (though not necessary) condition for eliminating severe conflicts \nbetween two references. As with PADLITE, if this location is incremented beyond its initial position \nby a distance larger than the cache size, the heuristic has failed to find a satisfactory address and \ndefaults to the original ten-tative location. In our experiments PAD has always found a non-conflicting \nbase address. We should point out that this technique can easily be do k generalized for multilevel caches. \nThe only modification is do j to compute conflict distances with respect to each cache con- do i figuration \nand then to pad as needed if any distance is less A(i, j), A(i,k) than the corresponding cache line size. \nThe same is true for Figure 3: Simplified Linear Algebra Computation INTRAPAD, described later. 2.2 Intra-variable \nPadding for Stencil Codes The next two sections describe heuristics for INTRAPADLITE and INTRA PAD, the \nintra-variable padding portion of PADLITE and PAD. These heuristics are designed to elim-inate severe \nconflicts commonly occurring in stencil com- putations. Additional intra-variable padding heuristics \nare described later in Section 2.3. INTRAPADLITE pads arrays based only on array dimension sizes. INTRAPAD \nagain ap-plies analysis of uniformly generated references.  2.2.1 INTRAPADLITE INTRAPADLITE continues \nusing the parameter M, now as the minimum distance of separation between nearby columns (or, for arrays \nwith dimensionality 3 or higher, subarrays). For example, given a large enough M, maintaining a separa- \ntion of M on the cache between the first elements of adjacent columns will ensure that references such \nas B(i, j-1) and B(i+l, j) do not conflict. For each array, INTRAPADLITE determines whether Cal, or 2Co1, \nare within M of a mul- tiple of C, (whether either Cal, or 2Co1, have conflict dis-tances < M with 0.) \nIf so, the column size is increased as needed to eliminate this pad condition. Provided C, > 3M, a pad \nof 2M (in units of array elements) or less is always sufficient. INTRAPADLITE pads arrays of higher dimension-ality \nin a similar manner. When 1 or 2 times the size of any subarray is within M of a multiple of C,, lower \ndimension sizes are increased so that this condition is no longer true.  2.2.2 IN~I RAPAD INTRAPAD again \nconsiders uniformly generated references, this time to find references to the Same array accessing mem-ory \nlocations apart by a fixed distance. By the definition given earlier, two references to the same array \nare uniformly generated as long as they are of the form A(il + ~1, i2 + r2, . . . . id+rd), A(il -t-S], \ni2 +Sz, . . . . id+sd), again where each i, is an unmodified variable or 0, and each rJ and sj is an \narbitrary integer. All other conditions are always satisfied since the two references access the same \narray. Expression 1 in this special case reduces to j=1 k=l since the base addresses (and any array lower \nbounds) cancel each other out. Stated in terms of expression 2, intra-array padding modifies the Sk values \nfor each array as needed to produce non-conflicting distances between the array s uni-formly generated \nreferences. For each array, the heuristic considers the uniformly gen-erated references to only that \narray in each loop. If the conflict distance between a pair of references in any loop is less than L,, \na pad of one element is attempted on each of the lower dimensions in turn until this pad condition is \nno longer true. An upper bound on pad size is imposed to ensure termination. However, small pads have \nsufficed in practice. In our experiments on an 16K cache, arrays USU-ally require pads of 2 or fewer \nelements, padding at most 3 elements. 2.3 Intra-variable Padding for Linear Algebra Codes Memory access \npatterns common in linear algebra compu-tations may also lead to frequent conflict misses. Consider the \nsimplified loop nest shown in Figure 3. As the values of j and k vary, there exist column sizes of A \n(e.g., 256, 384, 512) which lead to frequent conflict misses. Though these semi-severe conflict misses \ndo not occur on every loop itera- tion, they may occur in a high percentage of these iterations, considerably \ndegrading performance. To eliminate these conflicts, we develop two intra-variable padding heuristics, \nLINPAD~ and LINPAD~, designed for lin- ear algebra computations. LlNPAD2 is more comprehensive than LINPAD~, \nbut as a result is more aggressive in padding. Either heuristic may be incorporated into INTRAPADLITE \nor INTRAPAD, increasing the likelihood that the transfor-mations will pad a given array in any program. \nSection 2.4 discusses how these padding heuristics may be combined. 2.3.1 LINPAD~ LINPAD 1 avoids column \nsizes with large powers of two as fac- tors. In particular, the pad condition holds when the column size \nis evenly divided by 2L,. Since C, is a power of two, any column size which is a multiple of a large \npower of two will share a large greatest common divisor (gcd) with the cache size. Thus, multiples of \nthe column size will thus map to a small number of locations on the cache. Consider Figure 3, given C, \nand Cal, (both in units of array elements). If we let d = gcd(C,, Cal,), it follows that (C,/d)Col, 3 \n0 (mod C,), implying only the first C,/d multiples of Cal, will map to distinct locations on the cache. \nThis can lead to excessive conflict misses when d is large. For example, supposing C, = 1024 and Cal, \n= 768, we find d = gcd(C,, Cal,) = 256. Thus, 4 x Cal, E 0 (mod C,), meaning any two values jCo1, and \nkCoZ, will have a conflict distance of 0 when j -Ic is a multiple of 4. Under this column size, the references \nin Fig- ure 3 will conflict in approximately l/4 of the iterations of the j loop. LINPAD~ thus pads array \ncolumns as necessary to avoid the pad condition. 2.3.2 hNPAD2 LINPAD2 avoids column sizes Cal, where \nfor small values of j, jCo1, is within a cache line (Lb) of a multiple of C,. For instance, given C, \n= 1024, Cal, = 273, and L, = 4, we reject Cal, since 15 x 273 E -1 (mod C,). It also follows that 30 \nx 273 z -2 (mod C,) and 45 x 273 E -3 (mod C,), meaning columns apart by either 15, 30, or 45 may conflict. \nThe LINPAD2 pad condition, that columns j apart have a conflict distance less than L,, subsumes the LINPAD~ \npad condition where the conflict distance must be zero. More formally, given Cal,, we first define a \nconflicting j value as one for which jCo1, is within L, of a multiple of C,. Next, as described below, \nwe compute a parameter j* as the the smallest tolerable conflicting j value. Finally, Heuristic Analyses \nPad FirstConpictqT, T , c, c , Ls) Needed Conditionif r < L, then return c INTERPADLITE var size A base \naddrs < M else return FirstConflict (~ , r mod T , c , [r/r Jc + c, LLq) L INTRAPADLITE var sizeSdims \nA[1..2]Col, < M INTERPAD var sizeSdims FirstConpict(C,, Cal,, L,) A ref addrs < L, INTRAPAD +subscriptsreturn \nFirslCon..ict*(C,, Cal,, 0, 1, L,) LINPAD 1 A[l..j]Col, = 0 var size+dimsFigure 4: Functions for Computing \nFirstConflict LINPAD2 A[l..j]Col, < L, we decide to reject Cal, if there exists a conflicting j value \nsuch that 0 < j < j*. This requires only finding the smallest positive conflicting j value since larger \nconflicting j values are irrelevant. The function shown in Figure 4 performs this task. FirstConflict \nmakes the initial call to a recursive aux-iliary function FirstConflict*. The latter is a generalization \nof the Euclidean algorithm for computing the greatest com-mon denominator. At each call, the invariant \nis maintained that (mod C,) either (c col, E 7 ) or (c col, f -r ), and that for 0 < n < c , j = n is \nnot conflicting with respect to parameter L,. Since successive T values form the sequence of remainders \ncomputed by the Euclidean algorithm, r de- creases at each recurrence. Thus, we need only compare r to \nL,, returning c as the smallest conflicting value once r is smaller. Coleman and McKinley use a related \nalgorithm for finding non-conflicting tile sizes [? I. The value j* is selected to meet three criteria. \nFirst, j* must be small enough to avoid excessive or infinite testing of successively larger column sizes. \nThis is needed since transformations using LINPAD2 iteratively test larger and larger column sizes until \nthe heuristic decides not to reject. We accomplish this by limiting j* to C,/L,, since any Cal, for which \ngcd(Col,,C,) = L, has a FirstConflict value of C,/L,. For instance, if C, = 1024 and L, = 4, then given \na Cal, where gcd(CoZ,, C,) = 4, or equivalently, a Cal, which is a multiple of 4 but not of 8, it holds \nthat jCo1, is at least 4 or at most -4 (mod C,) when 0 < j < 256 = C,/L, and that 256Co2, E 0 (mod C,). \nThus, FirstConflict(l024, Cal,, 4) = 256. It follows that with j* 5 256, the search for a non- conflicting \ncolumn size will terminate within 8 iterations, since every sequence of 8 consecutive integers contains \na value with a gcd of 4 with C,, and thus a FirstConflict value at least j*. In general, 2L, iterations \nare always sufficient when j* 5 C,/L,. Second, j* should be large enough to substantially reduce conflict \nmisses in linear algebra computations. We have de- termined experimentally that over a set of programs \nwith arrays of varying sizes, the overall impact of padding im-proves with increases in j* until about \n129, after which ben-efits diminish. Finally, we impose another upper bound on the value of j* based \non the number of columns. Since ac-cesses to columns j apart do not occur when there are fewer than j \ncolumns, j* need not be greater than the row size (&#38;). Thus, LINPAD2 uses a j* equal to 129 unless \neither ceiling reduces this amount. To summarize: j* = min(129, R,, C,/L,) 2.4 Combined Padding Heuristics \nNow that we have presented each padding heuristic, we com- bine them into the actual PADLITE and PAD \nalgorithms. Both PADLITE and PAD consist of first applying intra-variable padding, then applying inter-variable \npadding. Intra-variable padding must be performed first, because it changes array sizes and thus variable \nbase addresses. Table 1: Properties for Padding Heuristics 2.5 PAD LITE PADLITE first gathers information \non array and dimension sizes. Next it performs intra-variable padding, combining INTRAPADLITE and LTNPAD~ \nby testing both pad condi-tions, trying larger pads when either condition is true. It then applies inter-variable \npadding with INTERPADLITE. We chose LINPAD~ because PADLITE is unable to recognize lin-ear algebra codes \nand will apply intra-array padding indis-criminately. LINPAD~ is less aggressive than LINPAD2, and is \nthus less likely to introduce unnecessary pads. 2.6 PAD PAD first gathers information on array and dimension \nsizes, then extracts uniformly-generated references from each loop nest. Next it performs intra-variable \npadding, combining INTRAPAD and LINPAD2 by testing both pad conditions, trying larger pads when either \ncondition is true. Since PAD may analyze array references, it tests LINPAD2 only for ar-rays appearing \nin computations of the form shown in Fig-ure 3. PAD then applies inter-variable padding with INTER-PAD. \nWe chose LINPAD2 because PAD is able to apply it only to arrays appearing in linear algebra codes. In \nSection 4.5 we present data to justify our choice of intra-variable padding heuristics for PADLITE and \nPAD. 2.7 Summary of Heuristics Table 1 summarizes the required analyses and pad condi-tions for all heuristics. \nFrom the column ANALYSES NEEDED, we see INTERPADLITE uses only variable sizes and that INTRAPADLITE inspects \narray dimensions in addition. LINPAD~ and LINPAD2 require only column sizes as well. INTERPAD and INTRAPAD \nanalyze array subscripts to com-pute exact conflict distances. The column PAD CONDITION indicates how \neach heuris- tic decides to advance base addresses or increase column sizes. This decision generally \ninvolves computing conflict distances between various quantities. INTERPADLITE pads when the conflict \ndistance between base addresses is less than the minimum distance M. INTRAPADLITE pads when the conflict \ndistance for either CoZs or 2Co1, is less than M. INTERPAD and INTRAPAD both compute conflict dis-tances \nof linearized array references, padding when it is less than the cache line size L,. LINPAD~ pads when \ntwo nearby columns have a conflict distance of zero. LINPAD2 pads when two nearby columns have a conflict \ndistance less than Ls. Figure 5 summarizes the general structure of both IN-TERPADLITE and INTERPAD. \nBoth heuristics maintain a tentative base address addr which is padded in the pre-sense of conflicts. \nThe decision of whether and how much to pad is abstracted by the neededPad function and relates to the \npad conditions shown in Table 1. For instance, IN-TERPADLITE determines how much padding is needed by \nBaseAddress + NULL V vars A addr * 0 foreach var A repeat padsize + 0 foreach var B where BaseAddress \n# NULL padsize + max(padsize, neededPad(A, addr, B)) if padsize > 0 then adds + addr +padsize until padsize \n= 0 BaseAddress + addr addr + addr + sizeOf Figure 5: General INTERPADLITE and INTERPAD Algorithm foreach \nvar A repeat padsize t max(neededStencilPad(A), neededLinAlgPad(A)) if padsize > 0 then increase Cola(A) \nby padsize until padsize = 0 Figure 6: General INTRAPADLITE and INTRAPAD Algorithm computing which increment \nto adds is required to yield a conflict distance < M between addr and BaseAddr(B). Figure 6 summarizes \nthe general structure of intra-variable padding in both PADLITE and PAD. The function needed-StencilPad \nbased on the INTRAPADLITE or INTRAPAD con-ditions of Table 1. The function neededLinAlgPad returns pad \nsizes uses the LINPADI or LINPAD2 conditions. A more general algorithm handles arrays of dimensionality \nhigher than two. Sample Transformations Examining the application of PADLITE and PAD will illus-trate \nthese heuristics and their limitations. Figure 7 expands on Figure 2, showing the key loop nests of JACOBI, \nan itera-tive solver for partial differential equations (the convergence test is not shown). In this \nkernel, A and B are both N x N ar-rays. Our transformations assume a write-allocating/write- back cache, \nso any two accesses may conflict, whether write or read. We consider outcomes when altering the values \nof parameters N, C, (the cache size), and L, (the cache line size.) For simplicity, we assume only stencil \nintra-variable padding heuristics are used in the following examples. All values discussed are in units \nof JACOBI array elements. N = 512. Cs = 2048, Ls = 4 PADLITE begins with IN-TRAPADLITE, which finds N \ntoo small to induce intra-array padding. INTERPADLITE begins, putting A at location 0, making the tentative \nlocation for B 512 x 512 10, mod C,. B is therefore advanced by M. PAD begins with INTRAPAD. INTRAPAD \nfinds that no A references conflict with one an-other and that B does not have multiple references in \nany loop. Therefore, the column sizes of A and B are unchanged. INTERPAD puts A at 0 and finds B references \nconflict in both loops. B s tentative location is therefore padded by 5. Thus, both heuristics perform \nadequately for these pa-rameters. Inter-variable conflicts appear in both loops, and both PAD and PADLITE \nare successful in eliminating them. N = 512, Cs = 1024, Ls = 4 With C, = 1024, INTRA- PADLITE increments \nthe column size of A since 2 N mod C, is 0. 8 pad elements are sufficient for M = 16. A s column size, \nand thus B s, are increased to 520. INTERPADLITE begins, placing A at 0. The tentative address for B \nis 520 x 512 E 0, mod C,. The sizes of A and B are still equal, so B is padded by do i = 2,N-1 do j = \n2,N-1 B(j,i) = 0.25 * (A(j-l,i) + A(j,i-1) + A(j+l,i) + A(j,i+l)) do i = 2,N-1 do j = 2,N-1 A(j,i) = \nB(j,i) Figure 7: Key Loop Nests in JACOBI M. INTRAPAD finds that references A( j , i-1) and A ( j , i+l) \nhave conflict distance 0. Padding A s column size by 2 elim- inates all conflicts. INTERPAD places A \nat 0 and then places B immediately at 514 x 512, since A and B are no longer con-forming. Therefore, \nunder these parameters, both PAD and PADLITE again perform adequately, eliminating all severe misses. \nN = 934, Cs = 1024, Ls = 4 In this case, neither heuris-tic finds intra-variable padding necessary. INTERPADLITE \napplies no inter-variable padding as well since B at 934 x 934 f 932 (mod C,) is sufficiently spaced \nfrom A. INTERPAD however computes a conflict distance of 2 between B (j , i) and A( j , i+l) since 934 \nx 934 -934 3 -2 (mod Cs) and pads B by 6 elements. PADLITE therefore fails to eliminate the existing \nsevere conflict misses. Analysis enables PAD to find a layout eliminating these conflicts. 4 Experimental \nEvaluation 4.1 Evaluation Framework To experimentally evaluate inter-and intra-variable padding, we implemented \nboth transformations in the Stanford SUIF compiler [22]. Additional transformations are performed to \ngive the compiler control over variable base addresses. First, local array and structure variables are \npromoted into the global scope (globalization). Formal parameters to functions do not need to be promoted, \nsince they represent variables declared elsewhere. Variables in Fortran common blocks are split into \nseparate variables if permitted by sequence asso-ciation. Otherwise they remain in a single common block \nand can not be padded. Global variables are then made into fields of a large structured variable, resulting \nin a single variable containing all of the variables to be optimized. The compiler can now modify variable \nbase addresses by reorder- ing fields in the structure and inserting pad variables. The compiler also \ndetermines whether intra-variable padding can be safely applied to each array, by determining whether \nthe array violates storage association or is passed as a parameter to a procedure. We used the SUIF compiler \nto optimize several scien-tific kernels and applications taken from the NAS, SPEC92, and SPEC95 benchmarks \nsuites. Costs of applying PAD and PADLITE were a very small percentage of overall compilation time. Various \ncompile-time measures of the progress of our padding algorithms were collected. The original and padded \nversions of each program were then simulated for several cache configurations using SHADE from Sun Microsystems. \nOur base cache configuration was a 16K direct-mapped cache with 32B lines. Where desired we simulated \na 16-way asso-ciative cache in place of a fully-associative cache. We also timed the original and optimized \nversions of each program on a number of architectures. The resulting observations demonstrate the potential \neffectiveness of our transforma-tions. I (Intra) (Inter) Y Program Description Lines Global UAf. Arrays \nArrays Max TotaI Bytes Siie Arrays Refs Safe Padded # Incr # Incr skip IlKI. KERNELS -AD132 2D AD1 Integration \nFragment (Liv8) 63 6 T 100 6 64 0.0 ~~0~256 Choleskv Factorization 165 5 100 4 0.2 DGEFA256 Gaussian \nElimination w/Pivoting 75 2 100 2 0.4 DOT256 Vector Dot Product (Liv3) 32 2 100 32 ERLE64 3D Tridiagonal \nSolver 612 23 100 ; 32 i:: EXPLODE 2D Explicit Hydrodynamics (Livl8) 64 9 100 9 304 0.0 IRR500K Relaxation \nover Irregular Mesh 196 4 100 0 0.0 JACOBI512 2D Jacobi Iteration w/Convergence 52 2 100 2 40 0.0 LINPACKD \nGaussian Elimination w/Pivoting 795 6 99 1 0.0 MlJLT300 Matrix Multiplication (Liv21) 29 3 100 3 0.0 \nRB512 2D Red-Black Over-Relaxation 52 1 100 1 0.0 SHAL512 Shallow Water Model 235 15 100 14 20 384 0.3 \nSIMPLE 2D Hydrodynamics 1346 37 100 37 0.0 NA BENCH .RKS y APPBT block-TrnbagonaI PDE Solver 4441 42 \n95 26 APPLU Parabolic/Elliptic PDE Solver 3417 34 100 17 APPSP Scalar-Pentadiagonal PDE Solver 3991 41 \n87 23 BUK Integer Bucket Sort 305 5 100 1 CGM Sparse Conjugate Gradient 855 11 95 0 ---I- - EMBAR Monte \nCarlo 265 3 80 1 FFTPDE 3D Fast Fourier Transform 773 7 60 0 MGRID Multigrid Solver 680 12 81 1 0 1 0.0 \nSPE( 15 BENCHMARKS 3868 33 100 17 0.0 APSI Pseudospectral Air Pollution 7361 23 95 22 0.0 FPPPP 2 Electron \nIntegral Derivative 2784 23 16 0.0 HYDR02D Navier-Stokes 4292 9 ii 9 48 0.0 MGRID Multigrid Solver 484 \n10 80 3 0.0 SU2COR Vector Quantum Water Model 2332 14 PO30 71 SWIM Shallow Physics 429 117 14 2 0 :: \nTOMCATVTURBBD Mesh Turbulence 190 38 100 2Y2 Isotropic Generation 2100 9 94 iti WAVE5 Maxwell s Equations \n7764 57 85 42 0:o SPEC92 BENCHMARKS DODUC lhermohydrauhcal Modeheation 5334 91 90 64 00 MDLJDP2 Molecular \nDynamics (double prec) 4316 25 86 18 0:o MDLJSP2 Molecular Dynamics (single prec) 3885 23 86 i: 0.0 NASA7 \nNASA Ames Fortran Kernels 1204 38 95 0.0 ORA Ray Tracing 453 0 100 0 0.0 Table 2: Compile-Time Statistics \nfor PAD (16K direct-mapped cache, 32B lines) 4.2 Compile-Time Statistics only a small amount of padding \nis needed. The increase in memory size after both inter-and intra-variable padding is Table 2 lists a \nnumber of compile-time statistics collected almost negligible, and is under 1% for all programs. for \neach program while applying PAD to our base cache. The first three columns describe each program. GLOBAL \nARRAYS indicates the number of global (or globalized) ar-4.3 impact on Cache Miss Rates rays. % UNIF. \nREFS shows the percent of references in We now examine the effectiveness of padding heuristics in the \nprogram the compiler classifies as uniformly generated. eliminating conflict misses in benchmark programs \nthrough The next four columns present statistics for intra-variable cache simulations. We evaluate the \nimpact of several factors, padding. ARRAYS SAFE is the number of arrays which can including transformations, \nanalysis, associativity, and cache be safely padded if desired. We see that most references are size. \nIn the figures, the X-axis lists programs, the Y-axis uniformly generated, but the compiler finds many \narrays presents cache miss rates or miss rate improvements, both in larger programs which cannot be safely \npadded. ARRAYS in percentages. Miss rate improvements are calculated as PADDED contains the number of \narrays actually padded (none the difference in the miss rate. Reducing the cache miss if blank). MAX \n# INCR is the maximum number of ele- rate from 10% to 8% would yield an improvement of 2%, ments by which \nany array is padded. TOTAL # INCR is the for instance. If the miss rate jumps from 10% to 12%, the total \nnumber of elements by which all arrays are padded. degradation would yield an improvement of -2%. Though \nintra-variable padding is typically profitable when applied, PAD discovers opportunities for these transforma-Overall \nImpact Figure 8 presents cache miss rates for the tions in only 6 out of our 36 benchmark programs. original \nprogram and the version optimized by PAD. We The next column BYTES SKIPPED shows the total num- see that \nconflict misses are eliminated for many programs, ber of bytes used for inter-variable padding. We see \ninter- dropping the average miss rate from 16.8% to 7.9%. The variable padding is needed more frequently, \nwith the com-average percentage reduction in miss rates for each program piler applying padding to fifteen \nprograms. The final col-is 16%. Padding is more successful for kernels than entire umn % SIZE INCR displays \nthe percent increase in the total applications. size of all global variables following padding. Results \nshow MISS Rate Improv. Vs Orb MISS Rate Improv. Vs 01 :Ig MISS Rate Improv. Vs Pad MISS Rate $otB&#38;!cikT8~ \n&#38;i.AlIbl. .!. 0000c.00~~ 1Ei2k 884k q 6k IQlGk(Pad) Figure 12: Impact of Cache Size on Intra-variable \nPadding (Direct-mapped Cache) EIM=l IBBM=2 KIM=6 EIM=16 f z 2 f 0 g -2 a -4 E 3 -6 g -8  Figure 13: \nImpact of Minimum Inter-variable Separation for PADLITE (16K Direct-mapped Cache) 82k q 4k q 6k 8116k \n(Pad) 1 Figure 14: Impact of Precision of Analysis on Padding for Varying Cache Sizes (Direct-mapped \nCache) I q Alpha 21064 q BUltraSparc2 q Pentium2 g Figure 15: Impact of Padding on Program Execution \nTime 45 Associativity We examine the effect of higher associativity on padding in two ways. First, we \ncompare miss rate im-provements for padding with higher set associative caches in Figure 9. Differences \nare calculated between PAD on a direct-mapped cache and the original program on higher set-associative \ncaches. Though PAD is not successful at elimi-nating conflicts in some cases (FFTPDE, FPPP, WAVE and \nNASA7), it is significantly more effective than a-way and 4- way associative caches for many programs \n(ADI, CHOL, EXPL, SHAL, SWIM, TOMCATV). 16-way associative caches are re-quired to achieve comparable \nimprovements. In Figure 10 we compare the impact of padding as set- associativity increases. Differences \nare calculated between PAD and the original program for l-, 2-, and 4-way asso-ciative caches. Results \nshow some programs (DGEFA, DOT, JACOBI) benefit from padding on direct-mapped caches but not for higher \nset-associative caches. Other programs expe-rience decreasing benefits (ADI, EXPL, SHAL, APPSP, TOM- \nCATV). Both sets of experiments show that the impact of padding decreases for higher set-associative \ncaches, but can still be significant. Effect of Cache Size on Padding Figure 11 demonstrates the impact \nof cache size on padding. Differences in miss rates between PAD and the original program are calculated \nfor different cache sizes. In general, padding becomes more important for smaller caches, when the ratio \nof problem to cache size increases. For some programs (DGEFA, JACOBI, RB, SWIM, TOMCATV) padding becomes \nmore effective as cache sizes decrease. In others (ADI, CHOL, DOT, EXPL, SHAL, APPSP) improvements remain \nconstant. Intra-variable Padding Figure 12 examines miss rates im-provements due to intra-variable padding \nfor different cache sizes. Differences in miss rates between PAD (inter-and intra-variable padding) and \nINTERPAD (inter-variable padding only) are calculated. Results show intra-variable padding is useful \nfor only a few programs on a 16K cache, but has wider applicability as the cache size decreases. We always \napply inter-variable padding after intra-variable padding, otherwise improvements may actually be due \nto changing array base addresses. Minimum Separation Distance PADLITE separates vari-ables by a minimal \ndistance M (in terms of L,) when ap-plying padding. M must be large enough to avoid conflict misses in \ntypical codes, yet small enough to avoid wasting memory. Figure 13 compares miss rates of PADLITE for \ndif- ferent values of M, compared to M = 4. We see that M = 1 is insufficient for eliminating conflict \nmisses in several pro-grams. Other values of M yield miss rates similar to M = 4, except for APPSP and \nTVRB3D. Over all programs, M = 4 is outperformed only by TOMCATV with &#38;f = 8,16. Precision of Analysis \nFigure 14 looks at miss rates im-provements due to the precision of intra-variable padding for different \ncache sizes. The difference in miss rates for PAD and PADLITE are calculated. Results indicate the additional \nanalysis of PAD is rarely useful on a 16K cache, but is more effective for smaller caches. Several programs \n(SHAL, SIM- PLE, APPLV, HYDR02D, SWM, TOMCATV, TVRB3D, MDLJDP2) benefit on a 2K cache. PAD slightly increases \nmiss rates for some codes (EXPL). Precise analysis thus becomes more im-portant as opportunities for \nconflicts increase. 4.4 Impact on Execution Time To determine the impact on actual program performance, \noriginal and padded versions of each program were timed on a DEC Alpha 21064, Sun UltraSparc2, and Intel \nPentium2. Figure 15 presents the percentage improvement in execution time for PAD over the original program. \nMany kernels speed up significantly, but large improvements are only found for a few applications (APPSP, \nSWIM, TOMCATV). Results demon-strate that observed miss rate reductions translate into av-erage execution \ntime improvements of 6.0% for Alpha, 7.5% for UltraSparc2, and 5.9% for Pentium2. 4.5 Varying Problem \nSizes To compare the PADLITE and PAD heuristics more thor-oughly, we examined cache simulations for four \nkernels as we varied the problem sizes from 250 to 520. Two stencil codes compute explicit hydrodynamics \n(EXPL) and shallow water modeling (SHAL), while two linear algebra codes com- pute Gaussian elimination \nwith partial pivoting (DGEFA) and Cholesky factorization (CHOL). We measured miss rates for the original \nprogram (for both the base 16K direct-mapped cache, and a 16-way associative cache), as well as optimized \nversions of each program (PADLITE and PAD) on the base cache. Optimizations Results are shown in Figure \n16. The X-axis represents problem sizes, while the Y-axis presents the cache miss rate. We see each kernel \nexperiences severe conflict misses on a direct-mapped cache for many problem sizes, particularly powers \nof two. Conflict misses are especially prevalent for CHOL. The 16-way associative cache can elim- inates \nall cache conflicts, except for some problems sizes for CHOL. PADLITE is able to eliminate most conflict \nmisses in EXPL, SHAL and DGEFA, but misses padding opportunities for many CHOL problems sizes. In comparison, \nPAD appears sufficiently powerful to consistently eliminate severe conflict misses for all four kernels. \nCompiler-directed padding can thus be beneficial in avoiding severe conflict misses. For CHOL padding \nsometimes even improves miss rates compared to the 16-way associative cache. PAD is shown to be more \nstable than PADLITE for the four kernels over the range of problem sizes tested. Intra-variable Padding \nWe also use varying problem sizes to compare the effectiveness of LINPAD~ and LINFAD2. To compare the \ntwo heuristics, we applied LINPAD~ or LIN-PAD:! followed by INTERPADLITE, subtracting the result from \napplying INTERPADLITE alone. Results are shown in Figure 17. The X-axis represents problem sizes, while \nthe Y-axis presents the change in cache miss rate. We see both LINPAD~ and LINPAD2 produce fairly ran-dom \nperturbations in cache miss rates for the stencil codes EXPL and SHAL, yielding both improvements and \ndegrada-tions. LTNPAD~ applies padding frequently, leading to many large perturbations in cache miss \nrates. LINPAD~ applies padding occasionally, with only small changes in miss rates. These results justify \nour decision to use LTNPAD 1 in PADLITE. LINFAD2 is reserved for PAD, where it is applied only to lin- \near algebra codes. PAD thus does not apply LINPAD2 to either EXPL or SHAL. The benefits of LWPAD~ and \nLMFAD2 are visible in the miss rate improvements of linear algebra codes DGEFA and CHOL in Figure 17. \nFor DGEFA, LINPAD~ is sufficient to elim- inate severe conflicts. LWPAD2 does no harm but is not able \nto eliminate additional conflict misses. For CHOL LINPADI eliminates conflicts for several problem sizes, \nbut LINPAD~ can find many additional problems sizes which benefit from intra-variable padding. Overall, \nthe two heuristics appear quite useful for linear algebra codes, less so for stencil codes. 4.6 Discussion \nIn general, we found small inter-variable pads are sufficient to eliminate the worst of the severe conflict \nmisses. Both PADLITE and PAD are successful for benchmark programs. 2 a0 60 60 5 E &#38;j 40 20 0 250 \n260 270 260 290 300 310 320 330 340 350 360 370 360 390 400 410 420 430 440 450 460 470 460 490 500 510 \n520 o g 70 60 50 3 g jj UJ 4. 30 20 10 0 250 260 270 260 290 300 310 320 330 240 350 360 370 360 390 \n400 410 420 430 440 450 460 470 460 490 500 510 520 w 0 5 I 01 II,,,I,,,, ll-rn ,,,., ,rTlrTlr_lr_lr_lr_ \n,.,,,,, I 250 260 270 260 290 300 310 320 330 340 350 360 370 360 390 400 410 420 430 440 450 460 470 \n460 490 500 510 520 50 a? 0 40 a 4 30 ij .c 20 0 10 0 250 260 270 260 290 300 310 320 330 340 350 360 \n370 360 390 400 410 420 430 440 450 460 470 460 490 500 510 520 I+ Original -s--PadLlte ++ .. Pad --.R \n--16-way Assoc. 1 Figure 16: Impact of Optimizations on Cache Miss Rates for Varying Problem Sizes However, \nPAD is more powerful, as demonstrated by results and Lam provide a concise definition and summary of \nim- from smaller cache sizes and varying problem sizes. Many portant types of data locality [23]. Gannon \net al. introduce programs benefit from inter-variable padding, relatively few the notion of uniformly \ngenerated references as a means of require intra-variable padding. Results indicate padding discovering \ngroup reuse between references to the same ar-transformations become more important as the ratio of ap- \nray [9]. Most compiler researchers have concentrated on plication data to cache size increases, so precise \nanalysis computation-reordering transformations. Loop permutation may become more important for real-world \nprograms with and tiling are the primary optimization techniques [9, 17, large data sets. Our results \nshow not all programs were 231, though loop fission (distribution) and loop fusion have greatly improved, \nbut the impact is significant for some pro- also been found to be helpful [15, 171. Coleman and McKin- \ngrams. However, more powerful analysis is needed to prove ley show how to select tile sizes which avoid \nconflict misses the safety of padding for large programs. using the Euclidean algorithm [7]. McKinley \nand Temam perform a study of loop-nest ori-ented cache behavior for scientific programs and conclude \n5 Related Work that conflict misses cause half of all cache misses and most Data locality has been recognized \nas a significant perfor-intra-nest misses [18]. Researchers have examined meth-mance issue for both scalar \nand parallel architectures. Wolf ods to eliminate conflict misses using hardware [ll, 131 or la 250 260 \n270 280 290 300 310 320 330 340 350 360 370 360 390 400 410 420 430 440 450 460 470 460 490 500 510 520 \n8 -4- f -6. 0 5 -a-. i .!g -IO-250 260 270 260 290 300 310 320 330 340 350 360 370 360 390 400 410 420 \n430 440 450 460 470 460 490 500 510 520 E 10 4 8 a 6 P 250 260 270 260 290 300 310 320 330 340 350 \n360 370 360 390 400 410 420 430 440 450 460 470 480 490 500 510 520 g 30 g 25 0 20 g 15 3 0 5% 5  250 \n260 270 260 290 300 310 320 330 340 350 330 370 360 390 400 410 420 430 440 460 460 470 480 490 500 510 \n520 1 +LinPadl --s--LinPad2 1 Figure 17: Impact of Intra-variable Padding on Cache Miss Rates for Varying \nProblem Sizes operating systems support [2, 41. These techniques are gen- to improve locality for parallel \nprograms [6]. More recently, eral and apply to a wide range of programs. However, for O Boyle &#38; Knijnenburg \n[19] and Kandemir et al. [14] in- many scientific Fortran codes we can achieve similar or bet- vestigate \narray transpose as a technique for improving data ter performance using inexpensive data layout transforma-locality \nin uniprocessors. Manjikian and Abdelrahman per-tions. Many researchers have investigated the related \nprob-form cache partitioning, spacing out variables as far as pos- lem of avoiding memory bank conflicts \nin vector systems [5], sible in a cache, in order to reduce conflict misses in parallel but do not discuss \ncompiler techniques. programs after loop fusion [15]. McFarling shows compiler A number of researchers \nhave examined data layout trans-transformations of code sequences can help eliminate con-formations, \nusually in the context of parallel programs. flict misses in the instruction cache [16]. Jeremiassen \nand Eggers automatically eliminate false shar- Many researchers have also examined the problem of ing \nin explicitly parallel programs by changing the place-deriving estimates of cache misses in order to \nhelp guide ment of variables [12]. Amarasinghe et al. demonstrate the data locality optimizations [8, \n9, 231. These models typi-utility of data layout transformations for eliminating con-cally can predict \nonly capacity misses because they assume a flict misses in parallel applications [l]. They find it to \nbe fully-associative cache. Temam et al. establish that conflict significant in eliminating adverse cache \neffects, though spe-misses can significantly degrade performance and present an cialized optimizations \nare necessary to reduce computation analytical method for detecting and counting the number of overhead \nfor modified array subscripts. Cierniak and Li ex-cache misses due to conflicts [20]. Ghosh et al. calculate \namine combining array transpose and loop transformations conflict misses more accurately by counting \nthe number of integer solutions to cache miss equations, linear Diophantine equations that exactly specify \nthe cache line to which each reference is mapped for every loop [lo]. They demonstrate how to use cache \nmiss equations to select array paddings to eliminate conflict misses and block sizes for tiling. Because \nof the complexity and expense of their more pre-cise algorithms, both Temam et al. and Ghosh et al. have \nonly evaluated their algorithms on a few kernels. In com-parison, we use a simplified version of cache \nmiss equations to detect when large numbers of conflict misses will occur, then apply padding until severe \nconflicts are mostly elimi-nated. Because we avoid calculating the number of conflict misses directly, \nwe can inexpensively guide padding trans-formations for much larger programs than before. Conclusions \n In this paper, we develop a number of techniques for elim- inating cache conflicts misses in scientific \nprograms. We develop and evaluate heuristics for guiding two data-layout transformations, inter-and intra-variable \npadding. We demonstrate the practicality of our heuristics by applying them to a large collection of \nkernels and benchmark pro-grams over a range of cache and problem sizes. Our heuris-tics are limited \nto regular computation patterns; more re-search is needed to extend them to a wider range of pro- grams. \nHowever, preliminary experimental results for scien- tific Fortran codes are encouraging. Our prototype \ncompiler achieves respectable improvements on average and signifi-cant improvements for some programs. \nOur results indi-cate data layout transformations should become a standard optimization for advanced \ncompilers. As processor speeds continue to increase relative to memory latencies, locality optimizations \nshould become even more important for fu-ture processors. References J. .4nderson, S. Amarasinghe, and \nM. Lam. Data and com-putation transformation for multiprocessors. In Proceedings PI of the Fijth Practice \nof 1995. B. Bershad, flict misses Proceedings PI ACM SZGPLAN Symposium on Principles and Parallel Programming, \nSanta Barbara, CA, July D. Lee, T. Romer, and B. Chen. Avoiding con-dynamically in large direct-mapped \ncaches. In of the S&#38;h Internalional ConjeTence on Archi- teclsral Supporl for Programming Languages \nand Operating Systems (ASPLOS-VI), San Jose, CA, October 1994. W. B&#38;sky, R. Fitzgerald, and M. Scott. \nSimple but effective techniques for NUMA memory management. In Proceedings of the Twelfth Symposium on \nOperating Systems Principles, Lit&#38;field Park, AZ, December 1989. [31 E. Bugnion, J. Anderson, T. \nMowry, M. Rosenblum, and [41 M. Lam. Compiler-directed page coloring for multiproces- sors. In Proceedings \nof the Eighth Znternalional Conference on Architectural Supporl for Programming Languages and Operating \nSystems (ASPLOS-VIII), Boston, MA, October 1996. 151 D. Calahan. Performance evaluation of static and \ndynamic memory systems on the Gray-2. In Proceedings of the Sec-ond International Conference on Supercomputing, \nSt. Malo, France, July 1988. 161 M. Cierniak and W. Li. Unifying data and control transfor-mations for \ndistributed shared-memory machines. In Pro-ceedings of the SZGPLAN 95 Conference on Programming Language \nDesign and Implementation, La Jolla, CA, June 1995. 171 S. Coleman and K. S. McKinley. Tile size selection \nusing cache organization and data layout. In Proceedings of the SZGPLAN 95 Conference on Programming \nLanguage De-sign and Implementalion, La Jolla, CA, June 1995. J. Ferrante, V. Sarkar, and W. Thrash. \nOn estimating and 181 enhancing cache effectiveness. In W. Banejee, D. Gelernter, A. Nicolau, and D. \nPadua, editors, Languages and Compil-ers jOT Parallel Compuling, Fourth Znternalional Workshop, Santa \nClara, CA, August 1991. Springer-Verlag. D. Gannon, W. Jalby, and K. Gallivan. Strategies for cache \nPI and local memory management by global program trans-formation. Journal of Parallel and Distributed \nComputing, 5(5):587-616, October 1988. S. Ghosh, M. Martonosi, and S. Malik. Cache miss equations: An \nanalytical representation of cache misses. In Proceedings oj the 1997 ACM Znlernalional Conference on \nSupercom-prting, Vienna, Austria, July 1997. PO1 A. Gonzalez, M. Valero, N. Topham, and J. Parcerisa. \nElim-inating cache conflict misses through XOR-based placement functions. In Proceedings of the 1997 \nACM Znternalional Conference on Supercomputing, Vienna, Austria, July 1997. 1111 T. Jeremiassen and \nS. Eggers. Reducing false sharing on PI shared memory multiprocessors through compile time data transformations. \nIn Proceedinps of Ihe Fijth ACM SZGPLAN Symposium on Principles and Practice of Parallel Program-ming, \nSanta Barbara, CA, July 1995. N. Jouppi. Improving direct-mapped cache performance by the addition of \na small fully-associative cache and prefetch buffers. In Proceedings of the 17th International Symposium \non Compuler Archilecture, Seattle, WA, May 1990. 1131 M. Kandemir, J. Ramanujam, and A. Choudhary. A \ncom-piler algorithm for optimizing locality in loop nests. In Pro-ceedings of the 1997 ACM International \nConference on Su-percompu6ng, Vienna, Austria, July 1997. t141 N. Manjikian and T. Abdelrahman. Fusion \nof loops for par- 051 allelism and locality. IEEE Transactions on Parallel and Distributed Systems, \n8(2):193-209, February 1997. [1 51 S. McFarling. Program optimization for instruction caches. In Proceedings \nof the Third Znlernalional Conference on AT-chilectural SIlQQoTt for Programming Languages and OQeT-sting \nSystems (ASPLOS-III), pages 257-270, Boston, MA, April 1989. K. S. McKinley, S. Carr, and C.-W. Tseng. \nImproving data locality with loop transformations. ACM Transactions on Programming Languages and Systems, \n18(4):424-453, July 1996. P71 K. S. McKinley and 0. Temam. A quantitative analysis of loop nest locality. \nIn Proceedings of Ihe Eighth Znlerna-tional Conference on Architectural supporl jot Programming Languages \nand Operating Systems (ASPLOS-VIII), Boston, MA, October 1996. P31 M. O Boyle and P. Knijnenburg. Non-singular \ndata transfor-mations: Definition, validity, and applications. In Proceed- PJI ings of the 1997 ACM \nZnternational Conference compuling, Vienna, Austria, July 1997. 0. Temam, C. Fricker, and W. Jalby. Cache \nphenomena. In Proceedings of the 1994 ACM RZCS Conference on MeasuTemenl 64 Modeling Systems, Santa Clara, \nCA, May 1994. PO1 PI J. Torrellas, M. Lam, and J. Hennessy. Shared ment optimizations to reduce multiprocessor \nrates. In Proceedings of Ihe 1990 Znternalional on Parallel Processing, St. Charles, IL, August R. Wilson \net al. SUIF: An infrastructure for PI on Super- interference SIGMET-CompuleT data place-cache miss Conference \n1990. research on parallelizing and optimizing compilers. ACM SZGPLAN No- tices, 29(12):31-37, December \n1994. [231 M. E. Wolf and M. Lam. A data locality optimizing al-gorithm. In Proceedings of the SZGPLAN \n91 Conjer-ence on Programming Language Design and Zmplementa-lion, Toronto, Canada, June 1991.  \n\t\t\t", "proc_id": "277650", "abstract": "Many cache misses in scientific programs are due to conflicts caused by limited set associativity. We examine two compile-time data-layout transformations for eliminating conflict misses, concentrating on misses occuring on every loop iteration. Inter-variable padding adjusts variable base addresses, while intra-variable padding modifies array dimension sizes. Two levels of precision are evaluated. PADLITE only uses array and column dimension sizes, relying on assumptions about common array reference patterns. PAD analyzes programs, detecting conflict misses by linearizing array references and calculating <i>conflict distances</i> between uniformly-generated references. The Euclidean algorithm for computing the <i>gcd</i> of two numbers is used to predict conflicts between different array columns for linear algebra codes. Experiments on a range of programs indicate PADLITE can eliminate conflicts for benchmarks, but PAD is more effective over a range of cache and problem sizes. Padding reduces cache miss rates by 16% on average for a 16K direct-mapped cache. Execution times are reduced by 6% on average, with some SPEC95 programs improving up to 15%.", "authors": [{"name": "Gabriel Rivera", "author_profile_id": "81100575821", "affiliation": "Department of Computer Science, University of Maryland, College Park, MD", "person_id": "PP39077917", "email_address": "", "orcid_id": ""}, {"name": "Chau-Wen Tseng", "author_profile_id": "81410592010", "affiliation": "Department of Computer Science, University of Maryland, College Park, MD", "person_id": "P44284", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277661", "year": "1998", "article_id": "277661", "conference": "PLDI", "title": "Data transformations for eliminating conflict misses", "url": "http://dl.acm.org/citation.cfm?id=277661"}