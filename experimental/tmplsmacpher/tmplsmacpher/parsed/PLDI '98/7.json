{"article_publication_date": "05-01-1998", "fulltext": "\n Partial Online Cycle Elimination in Inclusion Constraint Graphs Manuel FBhndrich* Jeffrey S. Foster* \nZhendong Su* Alexander Aiken* EECS Department University of California, Berkeley 387 Soda Hall #1776 \nBerkeley, CA 94720-1776 {manuel,jfoster,zhendong,aiken}@cs.berkeley.edu Abstract Many program analyses \nare naturally formulated and im-plemented using inclusion constraints. We present new re-sults on the \nscalable implementation of such analyses based on two insights: first, that online elimination of cyclic \ncon-straints yields orders-of-magnitude improvements in analy- sis time for large problems; second, that \nthe choice of con- straint representation affects the quality and efficiency of online cycle elimination. \nWe present an analytical model that explains our design choices and show that the model s predictions \nmatch well with results from a substantial ex-periment. Introduction Inclusion constraints are a natural \nvehicle for expressing a wide range of program analyses including shape analysis, closure analysis, soft \ntyping systems, receiver-class predic-tion for object-oriented programs, and points-to analysis for pointer-based \nprograms, among others [Rey69, JM79, Shi88, PS91, AWL94, Hei94, And94, FFK+96, MW97]. Such anal- yses \nare efficient for small to medium size programs, but they are known to be impractical for large analysis \nproblems. Inclusion constraint systems have natural graph repre-sentations. For example, the constraints \nX 2 y 5 2 are represented by nodes for the quantities X,Y, and 2 and directed edges (X, Y) and (Y, 2) \nfor the inclusions. Resolv-ing the constraints corresponds to adding new edges to the graph to express \nrelationships implied by, but not explicit in, the initial system. In this example, the transitive edge \n(X, 2) represents the implied constraint X C 2. The performance of constraint resolution can be im-proved \nby simplifying the constraint graph. Periodic simpli-fication performed during resolution helps to scale \nto larger analysis problems [FA96, FF97, MWS I], but performance is still unsatisfactory. One problem \nis deciding the frequency at which to perform simplifications to keep a well-balanced cost-benefit tradeoff. \nSimplification frequencies in past ap- *Supported in part by an NDSEG fellowship, NSF Young Inves-tigator \nAward CCR-9457812, NSF Grant CCR-9416973, and a gift from Rockwell Corporation. Psrmisaion lo make digital \nor hard copies of aII or part of this work for personal or classroom we is granted without fee provided \nthat copies are not made or distributed for profit or commercial sdvan-tape and that copies bear this \nnotice end the lull citation on the firs1 page. To copy otherwiss. lo republish, to post on servera or \nlo rsdistribute to lists. requires prior specific permission and/or a fee. SIGPLAN 98 Montrssl. Canada \nQ 1998 ACM 0-89791~987-4/98/0006...$5.00 proaches range from once for an entire module to once for every \nprogram expression. In this paper we show that cycle elimination in the con-straint graph (a particular \nsimplification) is one key to mak- ing inclusion constraint analyses scale to large problems with good \nperformance. Cyclic constraints have the form Xl c x2 E x3 . . . C X,, C_ Xr where the Xi are set variables. \nAll variables on such a cycle are equal in all solutions of the constraints, and thus the cycle can be \ncollapsed to a single variable. We take an extreme approach to simplification frequency by performing \ncycle detection and elimination online, i.e., at every update of the constraint graph. At first glance, \nthis approach seems overly expensive, since the best known algorithm for online cycle detection performs \na full depth-first search for half of all edge additions [Shm83]. Our contribution is to show that partial \nonline cycle de-tection can be performed cheaply by traversing only cer-tain paths during the search \nfor cycles. This approach is inspired by a non-standard graph representation called in-ductive form (IF) \nintroduced in [AWSS]. In practice, our approach requires constant time overhead on every edge ad- dition \nand finds and eliminates about 80% of all variables involved in cycles. For our benchmarks, this approach \nradi-cally improves the scaling behavior, making analysis of large programs practical. Furthermore, we \nprovide an analytical model to explain the performance of particular graph repre- sentations. Except \nours, all implementations of inclusion constraint solvers we are aware of employ a standard graph represen-tation \nin which all edges are stored in adjacency lists and variable-variable edges always appear in successor \nlists. For example, the constraint X E y, between variables X and Y, is represented as a successor edge \nfrom node X to node y. Our measurements show that this standard form (SF), which is the one described \nin [Hei92] for use in set-based analysis (SBA), can also substantially benefit from partial online cycle \nelimination. As our benchmark we study a points-to analysis for C [And94, SH97] implemented using both \nSF and IF. For large programs (more than 10000 lines), online cycle elimi-nation reduces the execution \ntime of our SF implementation by up to a factor of 13. Our implementation using IF and partial online \ncycle elimination outperforms SF with cycle elimination by up to a factor of 4, resulting in an overall \nspeedup over standard implementations by up to 50. Our measurement methodology uses a single well-engineered \nconstraint solver to perform a number of exper- iments using SF and IF with and without cycle elimination. \nWe validate our results by comparing with Shapiro and Hor- witz s SF implementation (SH) of the same \npoints-to anal-ysis [SH97]. Experiments show that our implementation of points-to analysis using SF without \ncycle elimination closely matches SH on our benchmarks. In Section 2, we define a language for set constraints, \nthe particular constraint formalism we shall use. We also present the graph representations SF and IF \nand describe our cycle elimination algorithm. In Section 3 we describe the version of points-to analysis \nwe study. Section 4 presents measurements illustrating the efficacy of our cycle elimi-nation algorithm. \nSection 5 studies an analytical model that explains why IF can outperform SF. Finally, Section 6 presents \nrelated work, and Section 7 concludes. 2 Definitions 2.1 Set Constraints In this paper we use a small \nsubset of the full language of set constraints [HJ90, AW92]. Constraints in our constraint language are \nof the form L 2 R, where L and R are set expressions. Set expressions consist of set variables X, Y, \n. . . from a family of variables Vars, terms constructed from n-ary constructors c E Con, an empty set \n0, and a universal set 1. L,RE se ::= X]c(sei,...,se,))O)l Each constructor c is given a unique signature \nS, specifying the arity and variance of c. Intuitively, a constructor c is covatiant in an argument if \nthe set denoted by a term c(. . .) becomes larger as the argument increases. Similarly, a constructor \nc is contravariant in an argument if the set denoted by a term c(. . . ) becomes smaller as the argument \nincreases. We define solutions to set constraints without restricting ourselves to a particular model \nfor set expressions. We simply assume that each constructor c is also equipped with an interpretation \n&#38;. Given a vatiable assignment A of sets to variables, set expressions are interpreted as follows2: \n[X] A = A(X) [c(sel,... , se,)] A = qL(l[sel] A,. . . , [se,] A) A solution to a system of constraints \n{ Li C &#38;} is a variable assignment A such that [Lil A C I[&#38;] A for all i. 2.2 Constraint Graphs \nSolving a system of constraints involves computing an ex-plicit solved form of all solutions or of a \nparticular solu-tion. We study two distinct solved forms: Standard form SF represents the least solution \nexplicitly and is commonly used for implementing SBA [Hei92]. Inductive form IF com- putes a representation \nof all solutions and is usually used with more expressive constraints and in type-based analy-ses [AW93, \nMW97]. As an aside, it is worth noting that for some analysis problems we require a representation of \nall so- lutions because no least solution exists. For the purposes of Standard models are the termset \nmodel [Hei92, Kos93] or the ideal model IAW931. 2The inte&#38;re&#38;ion of 0 and 1 depends on the model \nand is not shown. SU{XEX} w s SU{se&#38;l} ++ S SU{OEse} * S SU {c(sel,. . . ,se,) C c(se:,. . . , se \n,)} +3 s u ui {se&#38; c se:} c covariant in i {sei > se:} c contravariant in i 1 S U {c(. . . ) s d(. \n. . )} ti no solution ifd#c S U {c(. . . ) s 0) * no solution S U { 1 C 0) e no solution S U { 1 E a!(. \n. . )} * no solution Figure 1: Resolution rules R for SF and IF comparing the two forms we shall implicitly \nassume through- out that with respect to the variables of interest constraint systems have least solutions. \nThe solved form of a constraint system is a directed graph G = (V, E) closed under a transitive closure \nrule, where the edges E represent atomic constraints and the vertices V axe variables, sources, and sinks. \nSources are constructed terms appearing to the left of an inclusion, and sinks axe constructed terms \nappearing to the right of an inclusion. For the purposes of this paper, we treat 0 and 1 as constructors. \nA constraint is atomic if it is one of the three forms XCY variable-variable constraint 2.; !( 5 source-variable \nconstraint -. . . variable-sink constraint We use the set of resolution rules R shown in Figure 1 to \ntransform constraints into atomic form. Each rule states that the system of constraints on the left has \nthe same so-lutions as the system on the right. In a resolution engine these rules are used as left-to-right \nrewrite rules. The next sections describe how constraint graphs are rep- resented and closed by the two \nforms SF and IF. Both forms use adjacency lists to represent edges. Every edge (X,Y) in a graph is represented \nexclusively either as a predecessor edge (X E pred(y)) or as a successor edge (y E succ(X)).  2.3 Standard \nForm Standard form (SF) represents edges in constraint graphs as follows: XCY X-Y successor edge c(...) \nG x c(...) ...+X predecessor edge X &#38; c(. . . ) X-c(. . . ) successor edge We draw predecessor edges \nin graphs using dotted arrows and successor edges using plain arrows. New edges are added by the transitive \nclosure rule: L.....cX-R e LCR Given a predecessor edge L -.-cX and a successor edge at X-R, a new constraint \nL c R is generated. We generate a constraint instead of an edge because rules in Figure 1 Lo c x i = \nl..k 2 g Ri i = l..m IF Rl 1Close Lk Figure 2: Example may apply. Note that in this case, L is always \nof the form c(. . . ). This closure rule combined with rules R of Figure 1 produces a Final graph containing \nan explicit form of the least solution LS of the constraints [Hei92]. SF makes the least solution explicit \nby propagating sources forward to all reachable variables via the closure rule. The particular choice \nof successor and predecessor representation is motivated by the need to implement the closure rule locally. \nGiven a variable X, the closure rule must be applied exactly to all combinations of predecessor and the \nsuccessor edges of X. Figure 2 shows an example system of constraints, the ini- tial SF graph, and the \nresulting closed SF graph (left). The example assumes that set expressions L1 . . . Lk are sources and \nRI... R, are sinks. The closure of the standard form adds transitive edges from each source Li to all \nvariables reachable from X i.e., Yi . . . Yt, 2. Note that the edges from Ll . . . Lk to 2 are added \n1 times each, namely along all 1 edges Yi-2. The total work of closing the graph is 2kl edge additions, \nof which k(l -1) additions are redundant, plus the work resulting from the km constraints Li C Rj (not \nshown). To see why cycle elimination can asymptotically reduce the amount of work to close a graph, suppose \nthere is an ex- tra edge 2-X in Figure 2, forming a strongly connected component X, Yi , . . . , Yl, \n2. If we collapse this component before adding the transitive edges Li *****+Yj, none of the 2kl transitive \nedge additions Li *..+Yj are performed (the km constraints Li E Rj are still produced of course). 2.4 \nInductive Form Inductive form (IF) exploits the fact that a variable-variable constraint X C Y can be \nrepresented either as a successor I Close constraints in SF and IF edge (Y E succ(X)) or as a predecessor \nedge (X E Fed(Y)). The representation for a particular edge is chosen as a func- tion of a fixed total \norder o : Vars + N on the variables. Edges in the constraint graph are represented as follows: X-Y if \no(X) > o(Y) a successor edgeXCY X--Y if o(X) < o(Y) i a predecessor edge The choice of the order o(a) \ncan have substantial impact on the size of the closed constraint graph and the amount of work required \nfor the closure. We assume that the order o(-) is randomly chosen. Choosing a good order is hard, and \nwe have found that a random order performs as well or better than any other order we picked. The other \ntwo kinds of edges are represented as in stan- dard form, and the closure rule also remains unchanged: \nL....+X-R H L E R Notice that L may be a source or a variable-unlike SF, where L is always a source. \nIn IF the closure rule can therefore directly produce transitive edges between vari-ables. (This is not \nto say that the closure of SF does not produce new edges between variables, but for SF such edges always \ninvolve the resolution rules R of Figure 1.) The clo-sure rule combined with the resolution rules R produces \na final graph in inductive form [AW93]. The least solution of the constraints is not explicit in the \nclosed inductive form. However, it is easily computed as follows: LS(Y) ={c(. . . ) 1 c(. . . ) . . ..+Y} \nu insert-succ-edge (vertex from, vertex to) { // variable vertices : o(from) > o(to) if ( pred-chain \n(from, to)) { // Cycle found collapse-cycle (...); I else insert-into-successor-list (from, to); 1 Figure \n3: Algorithms By the ordering o(.), we have o(X) < o(Y) for all X....+Y. Thus there exists a variable \n21 with minimum index o(&#38;) that has no predecessor edges to any other variables and LS(&#38;) = {c(. \n. .) [ c(. . .) . ..+Z~}. Then AS(&#38;) is com-puted using LS(2j) for j < i and (1). The time to compute \nLS for all variables is O(pJc) worst case, where p is the num- ber of edges and /c is the number of distinct \nsources in the final graph. In the rest of the paper, solving a system of constraints under IF always \nincludes the computation of the least solution. The right side of Figure 2 shows the initial and ha1 \ngraph for the example constraints using IF. Note that some variable-varjable edges in IF are predecessor \nedges (dotted), whereas all variable-variable edges in SF are successor edges (solid). The ordering on \nthe variables assumed in the ex-ample is o(X) < o(2) < o(yi). Note the extra variable-variable edge X \n*..+2 added by the closure rule for IF. As a result of this edge, the closure of IF adds edges from X \nto all a. Each of the variables &#38;, . . . , Yl, 2 has a single predecessor edge to X, and thus their \nleast solution is equal to LS(X) = {LI,... , Lk}. The total work of closing the graph is 1 + m edge additions, \nof which 1 -1 additions are redundant, namely the addition of edge X....+Z through all yi, plus the work \nfor the km transitive constraints Li 5 Rj (not shown). The work to compute the least solution is proportional \nto 1.  2.5 Cycle Detection In this subsection we describe our cycle detection algorithm. Definition \n2.1 (Path) A path of length k from a vertex u to a vertex v in a constraint graph G = (V, E) is a sequence \nof vertices (~0 , . . . ,Vk), such that U = 210, V = ok, l..Vk-1 are variable nodes, and vi-i-i E E \nor v~~~.~~.+~v~ E E for i = l..k. A path is simple if all vertices on the path are distinct. Definition \n2.2 (Chain) A chain in a constraint graph is a simple path (X0,. . . , xk) consisting entirely of SUCCeSSOr \nedges XS-~-X~ for i = l..k (a successor chain), or con-sisting entirely of predecessor edges Xi-1 ...++Xi \nfor i = l..k (a predecessor chain). A path (X0,. . . , xk) forms a cycle if X0 = Xk and k 2 1. AS we \nshow in Section 4, cycles in constraint graphs are a major contributor to constraint resolution times. \nIt is thus important to detect and eliminate cycles. Cycles can always be replaced with a single variable, \nsince all variables on a cycle must be equal in all solutions of the constraints. pred-chain (vertex \nfrom, vertex to) { // TRUE if pred. chain to --> from if (from == to) return (TRUE); else { mark( from \n); // from is visited for each v in predecessors of from if (! marked(v) &#38;&#38; o(v) < o(from)) if \n(pred-chain (v, to)) return (TRUE); return (FALSE); 1 1 for cycle detection Figure 4: A cyclic graph \nin IF Our algorithm (Figure 3) for online cycle elimination is a straight-forward implementation of the \nfollowing idea. When adding a successor edge X-Y, we search (using pred-chain) along all predecessor \nedges starting from X for a predecessor chain JJ . . ..++X. Similarly, if we add a predeces- sor edge \nX ....+JJ, we search (using succ-chain, not shown) along all successor edges starting from Y for a successor \nchain y-+X. If such a chain exists, then we have found a cycle that can be eliminated. The search algorithm \non the right in Figure 3 differs from depth-fist-search merely in that the next visited vertex must be \nless than the cur-rent vertex in the variable order o(.). Note that for IF this condition is already \nimplied by the graph representa-tion; we include it for clarity and to make the algorithm work for SF. \nDetection for SF is slightly different since all variable-variable edges in SF are successors. Consequently, \nwhen adding a successor edge X-Y, we search (using succ-chain) along all successor edges starting from \nY for a successor chain y-+X. The condition that we only fol-low successor edges if they point to lower \nindexed variables is crucial for SF. Without it, a full depth-first-search is per- formed at every graph \nupdate, which is impractical. Re-stricting the search to edges pointing to lower indexed vari-ables reduces \nsearch time but results in only partial cycle detection. For IF, cycle detection not only depends on \nthe order o(.) but also on the order in which edges are added to the graph. Consider the example in Figure \n4. Our approach detects this cycle only if the successor edge X3-X1 is added last, since in this case, \nthe predecessor chain Xl ....+Xz ...+X3 is found. If the cycle is closed by adding either of the other \nedges the cycle is not detected. However, the closure of IF adds a transitive edge XZ-Xl and the sub-cycle \n(Xl, X2) is detected in all cases. It is a theorem that for any ordering of variables, IF exposes at \nleast a two-cycle for every non-trivial strongly connected component (SCC).3 Thus, using inductive form \nguarantees at least part of every non-trivial SCC is eliminated by our method; this result does not hold \nfor SF. A non-trivial strongly connected component consists of at least two vertices. Figure 5: Example \npoints-to graph Once a cycle is found, we must collapse it to obtain any performance benefits in the \nsubsequent constraint resolu-tion. Collapsing a cycle involves choosing a witness variable on the cycle \n(we use the lowest indexed variable to preserve inductive form), redirecting the remaining variables \non the cycle to the witness (through forwarding pointers), and com- bining the constraints of all variables \non the cycle with those of the witness. Finally, note that although some cycles may be found in the initial \nconstraints, many cycles only arise during reso-lution through the application of the resolution rules \nR. In the majority of our benchmarks, less than 20% of the vari-ables that are in strongly connected \ncomponents in the final graph also appear in strongly connected components in the initial graph. 3 Case \nStudy: Andersen s Points-to Analysis For a C program, points-to analysis computes a set of ab- stract \nmemory locations (variables and heap) to which each expression could point. Andersen s analysis computes \na points-to graph [And94]. Graph nodes represent abstract memory locations, and there is an edge from \na node z to a node y if x may contain a pointer to y. Informally, Ander-sen s analysis begins with some \ninitial points-to relationships and closes the graph under the rule: For an assignment ei = e2, anything \nin the points- to set for e2 must also be in the points-to set for el. Figure 5 shows the points-to \ngraph computed by Andersen s analysis for a simple C program. 3.1 Formulation using Set Constraints Andersen \ns set formulation of points-to graphs consists of a set of abstract locations {II , . . . , In}, together \nwith set vari- ables Xl,, . . . , Xl, denoting the set of locations pointed to by 11, . . . , In. The \nexample in Figure 5 has the set formulation gb 1 ~;p x:: = {I:} The association between a location li \nand its points-to set Xl, is implicit in Andersen s formulation and results in an ad-hoc resolution algorithm. \nWe use a different formulation that makes this association explicit and enables us to use a generic set \nconstraint solver. We model locations by pairing location names and noints-to set variables with a construc- \ntor ref({li},Xli) akin to reference types in languages like ML lMTH901. Unlike th; type system of ML, \nwhich is equality-based, we need inclusion constraints. It is well known that sub-typing of references \nis unsound in the presence of update e:r &#38;e : ref(O,~,T) (AdW e : 7 T C_ ref(l,T, iT) *e : 7 7 fresh \n(Deref) el=e2 : 72 Figure 6: Constraint generation for Andersen s analysis operations (e.g., Java arrays \n[GJSSG]). A sound approach is to turn inclusions between references into equality for their contents: \nref(X) C ref(y) * X = Y. We adapt this technique to a purely inclusion-based sys-tem using a novel approach. \nWe intuitively treat a refer- ence 1. as an object with a location name and two methods get : void + \nXl, and set : Xi, + void, where the points-to set of the location acts both as the range of the get func- \ntion and the domain of the set function. Updating a lo- cation corresponds to applying the set function \nto the new value. Dereferencing a location corresponds to applying the get function. Translating this \nintuition, we add a third argument to the ref constructor that corresponds to the domain of the set function, \nand is thus contravariant. A location 1. is then represented by ref(1., Xl.,x) (to improve readability \nwe overline contravariant arguments). To update an un-known location T with a set 7, it suffices to add \na con- straint T c ref(l,l,T). For example, if ref(&#38;,Xl,,z) C T, then the transitive constraint ref(Z=, \nXl.,x) c ref(l,l,n is equivalent to 7 c Xl, (due to contravariance), which is the desired effect. Dereferencing \nis analogous, but involves the covariant points-to set of the ref constructor. To formally express Andersen \ns points-to graph, we must associate with each location 1, a set variable yl= for the set of abstract \nlocation names and a constraint Xl, E ref (&#38;, 1,0) that constrains YJ~ to be a superset of all names \nof locations in the points-to set Xi,. The points-to graph is then defined by the least solution for \n&#38;. In our implementation we avoid using the location names 16 and the variables Yl,, and instead \nderive the points-to graph directly from the constraints. 3.2 Constraint Generation Figure 6 gives a \nsubset of the constraint-generation rules for Andersen s analysis. For the full set of rules, see [FFA97]. \nThe rules assign a set expression to each program expression and generate a system of set constraints \nas side conditions. The solution to the set constraints describes the points-to graph of the program. \nWe write T for set expressions denot-ing locations. To avoid separate rules for L- and R-values, we infer \nsets denoting L-values for every expression. In (Var), the type ref&#38;, XI.,%) associated with x therefore \ndenotes the location of x and not its contents. We briefly describe the other rules in Figure 6. The \nAST Node* 700 035 1078 1412 a284 a305 302, ssss sac30 6326 0518 0752 811, 10046 15170 ma8 20900 31210 \n38802 38874 41497 40292 51223 53874 56938 71091 87301 LOC 428 a03 344 324 574 445 1179 652 1640 1805 \n298, 4903 a316 4D30 12046 5761 03.58 a5120 15214 12845 1831a a3943 31105 36155 a1583 2,381 59689 TotEll \n#Vers 171 319 210 a64 3% 207 510 241 1024 1378 1811 1855 1971 2764 3587 ,111 5617 ,009 78.99 0565 0005 \n12806 13848 9539 11490 11690 13401 Nodes -73z 637 360 415 516 sa5 850 304 1804 2028 a**5 3095 aaoo 4578 \n6171 la213 9694 11630 12514 15058 9735 13708 20735 1537a 10067 18083 a1837 I  Initid i Edges #VSAr* \nIrll 6 a97 B a10 10 5 a40 4 a 329 0 3 176 4 48, 0 ?I a41 17 7 loao a0 7 1292 17. 0 140, 0 1008 a9 t 144a \n50 15 2317 0 3 3380 30 la 6283 10 6691 i:: 19 6507 63 a4 0904 155 63 868, 34 0450 347 :: 3631 108 1040, \n340 :: 9740 91 37 12271 333 140 10058 400 58 11097 108 87 address-of operator (Addr) adds a level of \nindirection to its operand by adding a ref constructor. The dereferencing op-erator (Deref) does the \nopposite, removing a ref and making the fresh variable 7 a superset of the points-to set of r. The second \nconstraint in the assignment rule (Asst) transforms the right-hand side 72 from an L-value to an R-value \n3, as in (Deref) (recall these rules infer sets representing L- values). The first constraint ~1 s ref(l,l,z) \nmakes 71 a subset of the points-to set of ~1. The final constraint 72 E 71 expresses exactly the intuitive \nmeaning of assignment: the points-to set 5 of the left-hand side contains at least the points-to set \n72 of the right-hand side. For example, the first statement of Figure 5, a = &#38;b, generates the constraints \n71 = ref(L,&#38;.,K) C ref(l, 1,711, and so 71 E XL, and 72 = ref(0, ref(.&#38;, Xl,,%), . . .) 5 ref(1, \nK,a), and so ref(&#38;,Xl,,K) C 72. The final constraint 72 5 71 implies the desired effect, namely ref(b, \nXI,,~) E Xl,. 4 Measurements In this section we compare the commonly used implementa- tion strategy of \nset-based analysis [Hei92], which represents constraint graphs in standard form (SF), with the inductive \nform (IF) of [AW93]. We give empirical evidence that cycles in the constraint graph are the key inhibitors \nto scalabil-ity for both forms and that our online cycle elimination is cheap and improves the running \ntimes of both forms signif- icantly. Using online cycle elimination, analysis times us-ing inductive \nform come close to analysis times with perfect and zero-cost cycle elimination (measured using an oracle \nto predict cycles). Furthermore, on medium to large programs IF outperforms SF by factors of 2-4. This \nlatter result is surprising, and we explore it on a more analytical level in Section 5. Our measurements \nuse the C benchmark programs shown in Table 1. For each benchmark, the table lists the number of abstract \nsyntax tree (AST) nodes, the number of lines in the preprocessed source, the number of set variables, \nthe total number of distinct nodes in the graph (sources, variables, and sinks), and the number of edges \nin the initial Table 1: Benchmark data common to all experiments Experiment 1 Description SF-Plain I \nStandard form. no cycle elimination IF-Plain Inductive form; no c&#38;zle elimination SF-Oracle Standard \nform, with full (oracle) cycle elimination IF-Oracle Inductive form, with full (oracle) cycle elimination \nSF-Online Standard from, using IF online cycle elimination IF-Online Inductive form, with online cycle \nelimiuation Table 4: Experiments constraints (before closing the graph). Furthermore, the table contains \nthe combined size of all non-trivial strongly connected components (SCC), the number of components, and \nthe size of the largest component, both for the initial graph (before closure) and for the final graph \n(in any experi- ment). The difference in the combined size of SCCs between the initial and the final \ngraph shows the need for online cycle elimination. If all cycles were present in the initial graph, online \ncycle elimination would be unnecessary. We use a single well-engineered constraint resolution li-brary \nto compare SF and IF. To validate that our results are not a product of our particular implementation, \nwe compare our implementation of standard form to an independent im- plementation of points-to analysis \nwritten in C by Shapiro and Horwitz [SH97]. Their implementation corresponds to SF without cycle elimination, \nand we empirically verify that our implementation of SF produces the same trend on our benchmark suite. \nThe scatter plot in Figure 12 shows that our implementation of SF without cycle elimination is usu- ally \nbetween 2 times faster and 2 times slower than SH (hor- izontal lines) on a subset of the benchmarks4 \nwith a few exceptions where our implementation is significantly faster (flex, li, cvs, inform), and one \nprogram where our imple-mentation is substantially slower (tar). We performed the six experiments shown \nin Table 4. The first two are plain runs of the points-to analysis using SF and IF without cycle elimination. \nSF-Plain corresponds to clas- sic implementations of set-based analyses. The experiments SF-Oracle and \nIF-Oracle precompute the strongly connected components of the final graph and use that information as \nNot all benchmarks ran through SH. IF-Ph,rl Work 441 782 557 672 15362 428 19821 742 24887 3648 9844 \n169253 132260 6718.36 3047616 177872021 2231538 28462390 Q6349223 1623679.5 181?5919 130Pi98316 6702128 \n362820558 78018098 267208OQ3 490070572 Time(s) 008 0:13 0.09 0.13 0.46 0.11 0.61 0.15 1.30 0.61 1.21 \n5.38 3.63 14.48 64.43 4349.04 62.20 669.97 2287.20 359.31 433.98 2988.00 161.33 8686.46 1903.74 6605.69 \n12159.00 Edges aQo 606 412 446 1278 280 1204 366 3168 3027 4016 21860 4291 36280 72045 1740142 15736 \n306771 6Q3860 222182 250474 640161 116513 14,264, 741816 922422 1084147 300 661 450 406 2332 381 1733 \n520 5070 3992 4916 14Q501 ,085 28285, 678170 10363Q138 27498 8582058 43941107 .5606608 5842830 3879,130 \n8Q1083 140867874 23276456 414QQ85, 179010002 Time(s) 0.06 0.11 0.10 0.10 0.17 0.10 0.10 0.14 0.60 0.50 \n0.85 3.45 0.86 8.07 12.51 1629.02 4.70 134.45 624.01 90.64 80.30 610.8, 22.96 2077.24 373.30 686.Q2 \n2966.48 Edges 322 686 450 488 663 301 1008 376 2302 2.571 3552 3826 2927 4838 8412 13360 12954 15485 \n10967 31091 18711 -26364 26050 32318 - Work 907 762 483 542 078 414 1251 570 3309 3378 4326 GOOK 4030 \n6578 13796 76391 20795 4,806 119389 OS132 37260 -43685 179301 123335 - s Time(s) ---Km 0.10 0.07 0.10 \n0.15 0.13 0.33 0.13 0.62 0.72 1.44 1.24 1.06 1.Q8 3.31 10.62 6.61 6.00 12.24 14.53 6.81 - 9.08 10.15 \n15.46 - Edges 261 688 369 432 850 272 832 317 2407 2655 3640 6606 2682 1296, 34029 470045 13100 133477 \n268863 11543, 84316 -67253 532076 343268 Be .hnlMk allroots diff.diffh Dnngrnm genetic ks 1 ft co lpr+o* \nrcMor compiler c.ssembler ML-typecheek eqntott sinwlntor l~S*-l?? flex-2.4.7 pmake mnke-3.72.1 inform-5.5 \ntnr-1.11.2 screen-3.6.2 EVB-1 .a agmls-1.1 e*premo gawk-3.0.3 povmy-2.2 Edges 384 ,11 610 515 3386 315 \n3766 402 5777 2733 5219 17908 15667 29935 76789 113042, 98301 364732 74,878 236017 278820 963242 214220 \n1706442 859093 1653812 2710342 Table 2: Benchmark data for IF-Plain, SF-Plain, IF-Oracle, and SF-Oracle \nn- Elim. Edges Work The(*) Elim. Edges Work TitlW(*) 10 -xc 408 o.00 7 286 305 0.08 7 697 767 0.11 607 \n656 0.12 IS 493 536 0.11 : 407 441 0.00 6 602 556 0.13 2 444 494 0.11 31 1136 1742 0.23 13 1182 2006 \n0.20 4 308 419 0.11 1 270 380 0.11 44 1390 1800 0.29 22 1241 1828 0.24 15 448 669 0.16 10 356 526 0.14 \n64 2893 4168 0.0, 15 3079 4849 0.71 17 2703 3524 0.72 6 3013 3961 0.64 70 4061 5016 1.13 26 4004 4831 \n1.00 238 6519 11168 1.67 40 21158 148172 4.00 163 4074 6264 1.10 56 SD31 0408 1.02 206 ,344 14366 2.89 \nQl 32521 130041 4.40 269 10943 18121 3.65 141 58106 126138 6.83 1284 28386 1669.51 30.25 678 1260930 \n3285073 06.88 279 14678 23842 6.50 12.5 15246 25828 4.92 660 21413 83686 14.94 291 213492 484218 21.86 \n786 40498 283025 40.10 479 471810 1740032 54.40 422 35374 110442 18.64 260 168QTQ 3,815, 20.13 674 24216 \n50122 0.20 413 153672 347858 14.92 781 39728 235411 40.6, 553 384080 1044965 46.29 581 30677 52408 12.91 \n263 89744 1,1,94 13.20 1075 46568 314633 63.55 830 901331 4086267 113.63 1231 41390 155881 27.89 515 \n54.5501 1126267 55.61 1438 36103 176OQ7 31.16 615 SQOBSQ ll?b?31 74.42 1292 8,130 336573 58.63 782 1382071 \n8037706 224.80 Table 3: Benchmark data for IF-Online and SF-Online AST 700 936 1078 1412 2284 2306 3027 \n3333 6269 5326 6316 0762 811, 10040 15119 16828 29960 31210 36892 38874 41407 49282 51223 53874 56038 \n71081 8,391 see #Vnrs 10 13 23 14 37 7 'IO 2, 104 a9 06 206 232 290 357 1736 356 775 866 606 831 804 \n75.5 1201 1773 17913 1678 jF-Olacl Work 284 OS? 393 481 1181 373 1024 403 3470 3476 4367 QJQ2 3868 16140 \n49028 786496 2114, 234533 484661 178675 136277 106422 905743 591302 - Time(n) 0.07 0.10 0.09 0.14 0.15 \n0.11 0.21 0.13 0.63 0.74 0.83 1.15 0.81 2.05 3.79 29.73 4.99 12.71 21.24 13.44 8.15 - 11.28 44.35 28.83 \n- an oracle. Whenever a fresh set variable is created, the or-acle predicts to which strongly connected \ncomponent the variable will eventually belong. We substitute the witness variable of that component for \nthe fresh variable. As a re- sult, the oracle experiment uses only a single variable (wit-ness) for each \nstrongly connected component, and thus the graphs are acyclic. Since the oracle experiments avoid all \nunnecessary work related to cycles in the constraint graph (perfect cycle elimination), they provide \nlower bounds for the last two experiments, IF-Online and SF-Online, which use the online cycle detection \nand elimination algorithm de-scribed in Section 2.5. Furthermore, the oracle experiments directly compare \nthe graph representations of IF and SF, independently of cycle elimination. Table 2 shows the results \nfor the first four experiments. For each benchmark and experiment, we report the number of edges in the \nfinal graph, the total number of edge addi- tions (Work) including redundant ones, and the execution \ntime in seconds. Note the large number of redundant edge additions for SF-Plain and IF-Plain. All experiments \nwere performed using a single processor on a SPARC Enterprise-5000. The reported CPU times are best out \nof three runs. As mentioned in Section 2.4, all reported times for IF include the time to compute the \nleast solution. Figure 7 plots the analysis time for both SF-Plain and IF-Plain without cycle elimination \nagainst the number of AST nodes of the parsed program. As the size exceeds 15000 AST nodes there are \nmany benchmarks where the analysis becomes impractical. Without cycle elimination, SF generally outperforms \nIF be- cause cycles add many redundant variable-variable edges in IF that lead to redundant work. The \nlow numbers for the oracle runs IF-Oracle and SF-Oracle in Table 2 show that the bulk of work and execution \ntime is attributable to strongly connected components in the constraint graph. Without cycles, the points-to \nanalysis scales very well for both IF and SF. Our oracle approach failed for the three programs, screen, \ngawk, and povray, hence the missing points. Table 3 reports the measurement results for the online cycle \nelimination experiments. In addition to the informa-tion shown for the plain and oracle experiments, \nthe ta-ble contains the number of variables that were eliminated 91 6000 - 20000 40000 60000 8OOcxl AST \nnodes Figure 7: SF and IF without cycle elimination * 20 - ++ 0; + 10 - xx + ++ + 5- r: , $.. + 2- + \n+ 1 - + i$ :g +: 0.5 F I .+., . I . ( I . +  0.01 0.1 10 loo 1000 10000 Adolute time(s) SF-Plain Figure \n9: Speedups through online cycle detection through cycle detection. Online cycle elimination is very \neffective for medium and large programs. Figure 8 plots the analysis times for online cycle elimination \nand the ora-cle experiments (note the scale change). The fastest analy-sis times are achieved by IF-Oracle, \nfollowed by SF-Oracle, IF-Online, and then SF-Online. IF-Online stays relatively close to the oracle \ntimes, while SF-Online performs some-what worse. This indicates that while our cycle detection algorithm \nis not perfect, it comes close. Figure 9 shows the total speedup of our approach over standard implementations \n(IF-Online over SF-Plain), and the speedup obtained solely through online cycle elimina-tion (SF-Online \nover SF-Plain). To show that our techniques help scaling, we plot the speedups vs. the absolute execution \ntime of SF-Plain. As the execution time of the standard implementation grows, our speedup also grows. \nFor very small programs, the cost of cycle elimination outweighs the benefits, but for medium and large \nprograms, online cycle elimination improves analysis times substantially, for large programs by more \nthan an order of magnitude. The performance benefit of inductive over standard form is illustrated more \nclearly in Figure 10. In this plot, we 250 200 150 100 50 0 20000 40000 60000 80000 AST nodes Figure \n8: Analysis times with cycle detection and oracle 5 4.5 - 3.5 - . 3 - 2.5 - . . 2 - 0 . 1.5 - l * . \no . 1 foe . l . 0.66 +- 2 __________-_ --_ ____2 ___-_- _-_- _________-_-- - _-___ -_-.-- ------_-_- \n 0 20000 40000 60000 80000 AST nodes Figure 10: Speedups through inductive form can see that IF-Online \nis consistently faster for medium and large-sized programs (at least 10,000 AST nodes) than SF-Online.6 \nFor large programs the difference is significant, with IF-Online outperforming SF-Online by over a factor \nof 3.8 for the largest program. For very small programs, IF is at most 50% slower than SF, which in absolute \ntimes means only fractions of seconds. We can explain the performance difference of IF and SF by comparing \nthe fraction of variables on cycles found by IF-Online and SF-Online (Figure 11). Throughout, SF finds \nonly about half as many variables on cycles as IF, and the remaining cycles slow down SF. One reason \nfor this differ-ence is that for SF, the cycle detection only searches suc-cessor chains. The analog \nto predecessor chains in SF are increasing chains. Searching increasing chains in SF results in a higher \ndetection rate (57%), but the much higher cost outweighs any benefits. Our model in Section 5 explains \nwhy SF finds fewer cy-cles. The probability of finding chains of length greater than The outlier is the \nprogram flex; although flex is a large program, it contains large iuitialised arrays. Thus as far as \npoints-to analysis is concerned, it actually behaves like a small program. 1.2 IF-Online l SF-Online \n+ 1 l * P + * 0 l * ** 0 4 0.8 -* :, .o* 0 . l * . + . + . 0.6 -+* + ++ * .I + + + OL 0 20000 40000 \n60000 80000 AST nodes Figure 11: Fraction of variables on cycles found online 2 is small. Thus cycles \nof larger size are detected with small probability. IF counteracts this trend by adding transitive variable-variable \nedges, thereby shortening cycle lengths. 5 An Analytical Model In the last section, we saw that IF-Online \nand IF-Oracle both outperform SF-Online and SF-Oracle respectively, and that the simple online cycle \nelimination strategy is very effective, especially for IF. In this section we analytically compare the \ntwo different representations and answer three questions: (Ql) Why is IF a better representation than \nSF? (Q2) Why is partial online cycle elimination fast? (Q3) Why is the cycle elimination strategy more \neffective for IF? To answer these questions analytically, we need a tractable model of constraint graphs. \nWe use the follow-ing simplifications and assumptions: l We assume that graph closure adds no edges through \nthe resolution rules R. That is, we only consider edges added directly through the graph closure rule. \n. We consider random graphs G = (V, E) with n variable nodes, m source or sink nodes, and we assume for \nall pairs of distinct nodes u and v there is an edge (u, v) E E with probability p, for some constant \np. l We consider only edges added through simple paths. Thus, the results correspond to the cases where \nwe have perfect cycle detection i.e., IF-Oracle and SF-Oracle. These are strong assumptions. Nevertheless, \nthis model pre-dicts our measurements quite well. The following two theo-rems summarize the results in \nthis section. Theorem 5.1 For random graphs with p = $ and ratio L?l=z the expected number of edge additions \nfor SF is approx!mately 2.5 times more than that for IF. 10 2 1 0.5 0.1 100 1000 10000 100000 AST nodes \n Figure 12: Relative execution times of Shapiro and Horwitz s SF implementation of C points-to analysis \n(SH) over SF-Plain Theorem 5.2 For random graphs with p = f, the ex-pected number of variable nodes \nreachable through prede-cessor or successor chains in IF from any given node is no more than 2.2. The \nparameters p and f are taken from our experiments described in Section 4. The probabilities p = i and \np = $ are the the approximate densities of the initial and final IF graphs, respectively. Theorem 5.1 \nanswers the first question (Ql). It explains why SF-Oracle does on average 4.1 times more work than IF-Oracle. \nThe second question (Q2) is answered by Theo-rem 5.2. We expect partial online cycle detection to follow \nvery few edges. We observe empirically that the number of reachable variables is close to two. To answer \nthe third ques-tion (Q3), notice that since cycle detection searches chains in order of variable index, \nthe probability of detecting a long cycle is exponentially small. However, in IF edges between variables \nare added to the constraint graph, thus shortening some long cycles and increasing the probability of \ndetecting cycles. Although the same idea for detecting cycles can be applied to SF, it does not work \nas well since SF adds no transitive edges between variables. Figure 11 shows that for IF our simple strategy \nI?nds on average 80% of the variables involved in cycles, whereas the same strategy finds only 40% when \nused with SF. In the rest of the section, we establish Theorem 5.1 and Theorem 5.2. We introduce some \nnotation and terminology used in the following discussion. We use u and v to denote either variable nodes \nor source and sink nodes, X or Xi to denote variable nodes, and c or c to denote source and sink nodes. \nA total order on the n variables is chosen uniformly at random from among all n! possible permutations. \nFinally, we say a graph edge (u, v) is added through a path p if (u, v) would be added by the graph closure \nrule considering only the nodes and edges of p.  5.1 Edge Additions in Standard Form During the graph \nclosure process edges may be added more than once because an edge may be implied by more than one path \nin the constraint graph (cf. Figure 2). Thus, a 93 constraint solver does work proportional to the number \nof 1. Pi (u, v) = I&#38;J if u and v are variable nodes; edge additions, including redundant additions \nalong differ-ent paths. Define the random variables XfL,V, to be the number of additions of the edge \n(u, v) through simple paths from u to v for the standard form. To calculate the total expected num-ber \nof edge additions, it suffices to calculate the expected number of additions E(X&#38;,) of a given edge \n(u,v) and sum over all possible edges. For the standard form we consider two kinds of edges, (c, X) and \n(c,c ). We now calculate E(X&#38;)) and Notice that the edge (c,X) must be added through a simple path \nfrom c to X. For edges of the form (c, c ), we also need only consider the simple paths from c to c . \nFor each simple path from c to X of length i + 1, there are ( T1) choices of intermediate variable nodes. \nFor each simpie path from c to c of length i + 1, there are (y) choices of intermediate variable nodes. \nIn both cases, each combi- nation of variable nodes may appear in i! possible orders. The probability \nthat any particular sequence of the i + 2 nodes (including c and X or c and c ) is a path is p + . We \nobtain the following: W&#38;I ,I.  g p ; 1) i!pi+l W&#38;)) = i=l \\ / E(X&#38;))= 2 0; i!p + i=l \\-/ \n Since there are mn. possible edges of the form (c, X) and m(m -1) possible edges of the form (c,c ), \nthe expected number of edge additions for the standard form is given by E(X ) = mnE(X&#38;)) + m(m -l)E(X&#38;,)) \n5.2 Edge Additions in Inductive Form Defme the random variables X&#38;l to be the number of ad- ditions \nof the edge (u,v) through simple paths from u to v for the inductive form. We need to consider four kinds \nof edges: (Xr, Xe), (X,c), (c, X), and (cr,ce). Notice that the probability that a given edge (u,v) is \nadded through a simple path p of 1 2 3 nodes from u to v depends only on 1. Thus we let Pi(u,v) denote \nthe probability that the edge (u,v) is added through a simple path from u to v with i nodes. We have \nthe following equations: i!pif1Pi+2(Xly X2) = E(X[F,,=,l) = 2 ; i!pi+ Pi+2(c,c ) id 0 We next calculate \nfor any 1 1 3 the probability PI (u, v) for any nodes u and v. Lemma 5.3 Let o(.) be a random total order \non the vari- ables. Given a simple path p from u to v with 2 nodes, the following holds: 2. Pi(u, v) \n= &#38; if one of u and v is a variable node and the other is a constructed node; 3. Pl (u, v) = 1 if \nboth u and v are constructed nodes.  Proof. We prove the first case. Similar arguments apply to the \nother two cases. We first show Pl(u,v) 5 &#38;. Recall that o(X) is the index of variable X. Assume the \nedge (21, v) is added through apath (u,Xr,... , Xl-s,v), we claim that O(U) and o(v) are the smallest \nindices on the path, i.e., O(U) < o(Xi) and o(v) < o(Xi) for all 1 5 i 2 1 - 2. For paths with three \nnodes, this claim is true by the closure rule, since the edge is only added if u +...+Xl and Xi + v are \nin the graph and, these edges imply that o(u) and o(v) are less than o(Xr). Suppose the claim is true \nfor paths with at most k 2 3 nodes. Consider a path ( IL, Xl,. . . ,X,-r, v) with k+l nodes such that \nthe edge (u, v) is added through the path. Notice there must exist a Xi with 1 5 i 5 k -1 such that the \nedges (u, Xi) and (Xi,v) are added and O(U) < o(Xi) and o(v) < o(Xi). By induction, the claim holds for \nthe shorter paths (u, . . . ,Xi)and(Xi,... , v). Thus, o(u) and o(v) must be the smallest indices on \nthe path. There are n! possible orderings on the n variables and we claim that there are (7)(2(E -2)!)(n \n-Z)! of th em satisfying the above condition. There are (1) possible ways of choosing the indices for \nthe 1 variables on the path. There are 2 ways of ordering u and v, and (I -2)! ways of ordering the rest \nof the variables on the path. For the other (n -1) variables we can order them in (n -1)! ways. Thus \nwe have (;) (2(Z - 2)!)(n -I)! fi(%V) 5 I 71. 2 = l(l-l) We now show Pl(u,v) 2 &#38;. Let o(e) be an \nordering such that O(U) and o(v) are the smallest indices on the path &#38;,X1,... , Xl,v). We show that \nthe edge (u, v) is added through the path. The claim is clearly true for paths with three nodes. Suppose \nthe claim holds for paths with at most k nodes. Consider a path (u, Xl,. . . , Xk-1, v) with k + 1 nodes \nsuch that O(U) and o(v) have the smallest indices. Let Xi be the node such that o(Xi) < o(Xj) for all \n1 5 j 5 k - 1 with i # j. By induction, the claim holds for the two sub-paths (u, . . . ,Xi) and(Xi,... \n, v), i.e., the edges (u, Xi) and (Xi,v) are added through the respective subpaths. Thus, the edge (u, \nv) is added through the given path. Therefore, 0 fi(u,v) 2 q&#38;j. Since there are m(m -1) edges of \nthe form (c,c ), 2mn edges of the form (X, c) or (c, X), and n(n -1) edges of the form (Xl, X2), the \nexpected number of edge additions for the inductive form is given by E(XIF) = m(m -l)E(X[:,c~l) + 2mnE(X$,d \n+ n(n -~)W%,X~))  5.3 Comparison To directly compare SF and IF it is necessary to make an additional \nassumption about the density of the initial graph. In the following calculation, we assume p = $, which \nsays that a typical initial graph has @$ edges. In practice, initial constraint graphs are sparse; all \nour benchmark pro-grams produce initial graphs of approximately this density. We have the following approximation \n[Knu73] (2) Using equation (2) we simplify E(XsF) and E(XIF) as follows E(X ) x m(E-1) -l-mcm~l)~ To \nobtain Theorem 5.1, we relate the expected edge ad- ditions to the amount of work done to close the constraint \ngraphs. Since we consider only simple paths, the expected number of edge additions corresponds to the \ncase where there are no cycles (i.e., the oracle runs in Section 4). For our benchmark programs, the \ntypical ratio of z is about $ (See Table 1). Thus, asymptotically, E(XsF)/E(XIF) is about 2.5, i.e., \nusing the standard form, we expect to do 2.5 times as much work as using the inductive form. On our benchmarks \nwe have measured an average of 4.1 times more work for SF. 5.4 Cost of Online Cycle Elimination Next \nwe establish that the expected number of reachable nodes from any given node is small. This result explains \nwhy the simple heuristic for detecting cycles is very cheap. Let X be any variable node and let RX be \nthe random variable denoting the number of nodes reachable from X through a predecessor chain. Using \nthe same method for calculating the expected number of edge additions, we con- sider all simple paths \nstarting with X involving only variable nodes. We thus have Next, we approximate E(Rx). Let p = $ for \nsome con-stant k. Then < ;(ek-l-k) The value of p here is the probability of an edge being present in \nthe final constraint graph, not the initial one. If P= $, i.e., k = 2 (which holds roughly for our benchmarks) \nwe have E(Rx) < ;(e2-1 -2) x 2.2 completing the proof of Theorem 5.2. Note that for graphs denser than \np = 2 the value E(Rx) climbs sharply-our method relies on s;arse graphs. 6 Related Work There are three \nstrands of related work: constraint simplifi-cation, points-to analysis, and sub-cubic time analyses. \nThe importance of simplifications on constraint graphs has been recognized before. In contrast to our \nonline ap-proach, prior work has focused on periodic simplification. In [FA96] the authors describe several \nsimplifications to re-duce the heap requirements of graphs for a more complex constraint language. They \ngive performance results ob-tained through simplifications at regular depths in the ab-stract syntax \ntree traversal. Simplification cost outweighs potential benefits when simplifications are performed fre-quently. \nSeveral papers explore the theoretical foundations of con- straint simplification [TS96, Pot96, FF97]. \nAmong these, [FF97] implemented several simplifications in the context of a static debugger for Scheme. \nConstraint graphs are gen-erated separately for each module, simplified, and finally merged. They report \nsubstantial reduction in constraint graph sizes and speedups of analysis times. Marlow and Wadler use \nset constraints in a type system for Erlang [MW97]. Their system performs simplifications similar to \n[FA96, FF97] for every function declaration. They report that performance is poor for large sets of mutually \nrecursive functions, which must be analyzed together. Points-to analysis with set constraints,is in Andersen \ns thesis [And94]. Recent work by Shapiro and Horwitz [SH97] contrasts Andersen s set based points-to \nanalysis with the unification based points-to analysis of Steensgaard [SteSG]. They conclude that while \nAndersen s analysis is substan- tially more precise than Steensgaard s, its running time is impractical. \nHowever, our implementation of Andersen s points-to analysis is generally competitive with [SH97] s im- \nplementation of Steensgaard s algorithm. Inclusion constraint resolution algorithms usually have at least \nO(n3) time complexity. The lack of progress in achiev- ing scalable implementations of these algorithms \nhas encour- aged interest in asymptotically faster algorithms that are ei- ther less precise or designed \nfor special cases. Steensgaard s system is an example of the former; the linear time closure-analysis \nalgorithm for functional programs with bounded type size is an example of the latter [Mos96, HM97]. We \nplan to study the impact of online cycle elimination on the performance of closure analysis in future \nwork. 7 Conclusions We have shown that online elimination of cyclic constraints in inclusion constraint \nbased program analyses yields orders-of-magnitude improvements in execution time. Our partial online \ncycle detection algorithm is cheap but effective and works best on a non-standard representation of constraint \ngraphs. Acknowledgments We would like to thank David Gay, Raph Levien, and the anonymous referees for \nhelpful comments on improving the paper. Special thanks go to Mark Shapiro and Susan Hor- witz for providing \ntheir Points-to implementations for com-parison. References [And941 [AW92] [AW93] [AWL941 [FA96] [FFS \nI] [FFA97] [FFK+96] [GJS96] [Hei92] [Hei94] [HJ90] [HM97] [JM79] L. 0. Andersen. Program Analysis and \nSpecial- ization for the C Progmmmkzg Language. PhD thesis, DIKU, University of Copenhagen, May 1994. \nDIKU report 94/19. A. Aiken and E. Wimmers. Solving Systems of Set Constraints. In Symposium on Logic \nin Com- puter Science, pages 329-340, June 1992. A. Aiken and E. Wimmers. Type Inclusion Con-straints \nand Type Inference. In Proceedings of the 1993 Conference on Functional Programming Languages and Computer \nArchitecture, pages 31- 41, Copenhagen, Denmark, June 1993. A. Aiken, E. Wimmers, and T.K. Lakshman. \nSoft typing with conditional types. In Twenty-First Annual ACM Symposium on Principles of Pro- gramming \nLanguages, January 1994. M. Ftindrich and A. Aiken. Making Set-Constraint Based Program Analyses Scale. \nIn First Workshop on Set Constraints at CP g6, Cambridge, MA, August 1996. Available as Technical Report \nCSD-TR-96-917, University of California at Berkeley. C. Flanagan and M. Felleisen. Componential Set-Based \nAnalysis. In PLDI 97 [PLD97]. J. Foster, M. Ftindrich, and A. Aiken. Flow-Insensitive Points-to Analysis \nwith Term and Set Constraints. Technical Report UCB//CSD-97-964, U. of California, Berkeley, August 1997. \nC. Flanagan, M. Flat&#38; S. Krishnamurthi, S. Weirich. and M. Felleisen. Catching Bugs in the Web of \nProgram Invariants. In Pioceekgs of the 1996 ACM SIGPLAN Conference on Pro- gramming Language Design \nand Implementation, pages 23-32, May 1996. James Gosling, Bill Joy, and Guy Steele. The Java Language \nSpec$cation, chapter 10, pages 199-200. Addison Wesley, 1996. N. Heintze. Set Based Program Analysis. \nPhD thesis, Carnegie Mellon University, 1992. N. Heintze. Set Based Analysis of ML Programs. In Proceedings \nof the 1994 ACM Conference on LISP and FPrnctional Programming, pages 306-17, June 1994. N. Heintae and \nJ. Jaffar. A decision procedure for a class of Herbrand set constraints. In Sympo- sium on Logic in Computer \nScience, pages 42-51, June 1990. N. Heintze and D. McAllester. Linear-Time Sub-transitive Control Flow \nAnalysis. In PLDI 97 [PLD97]. N. D. Jones and S. S. Muchnick. Flow Anal-ysis and Optimization of LISP-like \nStructures. In Sk&#38;h Annual ACM Symposium on Principles of Programming Languages, pages 244-256, Jan-uary \n1979. [Knu73] [Koz93] [MosSG] [MTHSO] [MW97] [PLD97] [Pot961 [PS91] @w691 [SH97] [ShiSS] [Shm83] [Ste96] \n[TSSG] D. Knuth. The Art of Computer Programming, Fundamental Algorithms, volume 1. Addison-Wesley, Reading, \nMass., 2 edition, 1973. D. Kozen. Logical Aspects of Set Constraints. In E. Bijrger, Y. Gurevich, and \nK. Meinke, editors, Proc. 1993 Conf. Computer Science Logic (CSL 93), volume 832 of Lecture Notes in \nComputer Science, pages 175-188. Springer-Verlag, 1993. C. Mossin. Flow Analysis of Typed Higher-Order \nPrograms. PhD thesis, DIKU, Department of Computer Science, University of Copenhagen, 1996. Robin Milner, \nMads Tofte, and Robert Harper. The Definition of Standard ML. MIT Press, 1990. S. Marlow and P. Wadler. \nA Practical Subtyping System For Erlang. In Proceedings of the Inter- national Conference on Functional \nProgramming (ICFP 97), June 1997. Proceedings of the 1997 ACM SIGPLAN Confer-ence on Programming Language \nDesign and Im- plementation, June 1997. F. Pottier. Simplifying Subtyping Constraints. In Proceedings \nof the 1996 ACM SIGPLAN Inter-national Conference on Functional Programming (ICFP 961, pages 122-133, \nJanuary 1996. J. Palsberg and M. I. Schwartzbach. Object-Oriented Type Inference. In Proceedings of the \nACM Conference on Object-Oriented program-ming: Systems, Languages, and Applications, October 1991. J. \nC. Reynolds. Automatic Computation of Data Set Definitions, pages 456-461. Information Pro-cessing 68. \nNorth-Holland, 1969. M. Shapiro and S. Horwitz. Fast and ACCU-rate Flow-Insensitive Points-To Analysis. \nIn Pro- ceedings of the 84th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Program- ming Languages, \npages 1-14, January 1997. 0. Shivers. Control Flow Analysis in Scheme. In Proceedings of the ACM SIGPLAN \n88 Confer- ence on Programming Language Design and Im- plementation, pages 164-174, June 1988. 0. Shmueli. \nDynamic Cycle Detection. Informa-tion Processing Letters, 17(4):185-188, 8 Novem- ber 1983. B. Steensgaard. \nPoints-to Analysis in Almost Linear Time. In Proceedings of the i&#38;d Annual ACM SIGPLAN-SIGACT Symposium \non Ptin-ciples of Programming Languages, pages 32-41, January 1996. V. Trifonov and S. Smith. Subtyping \nCon-strained Types. In Proceedings of the 3rd Inter- national Static Analysis Symposium, pages 349- 365, \nSeptember 1996.  \n\t\t\t", "proc_id": "277650", "abstract": "Many program analyses are naturally formulated and implemented using inclusion constraints. We present new results on the scalable implementation of such analyses based on two insights: first, that online elimination of cyclic constraints yields orders-of-magnitude improvements in analysis time for large problems; second, that the choice of constraint representation affects the quality and efficiency of online cycle elimination. We present an analytical model that explains our design choices and show that the model's predictions match well with results from a substantial experiment.", "authors": [{"name": "Manuel F&#228;hndrich", "author_profile_id": "81100288438", "affiliation": "EECS Department, University of California, Berkeley, 387 Soda Hall #1776, Berkeley, CA", "person_id": "P187043", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey S. Foster", "author_profile_id": "81338488852", "affiliation": "EECS Department, University of California, Berkeley, 387 Soda Hall #1776, Berkeley, CA", "person_id": "PP39068596", "email_address": "", "orcid_id": ""}, {"name": "Zhendong Su", "author_profile_id": "81100108298", "affiliation": "EECS Department, University of California, Berkeley, 387 Soda Hall #1776, Berkeley, CA", "person_id": "PP14047875", "email_address": "", "orcid_id": ""}, {"name": "Alexander Aiken", "author_profile_id": "81100399954", "affiliation": "EECS Department, University of California, Berkeley, 387 Soda Hall #1776, Berkeley, CA", "person_id": "P13911", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/277650.277667", "year": "1998", "article_id": "277667", "conference": "PLDI", "title": "Partial online cycle elimination in inclusion constraint graphs", "url": "http://dl.acm.org/citation.cfm?id=277667"}