{"article_publication_date": "09-27-2010", "fulltext": "\n Higher-order Representation of Substructural Logics Karl Crary Carnegie Mellon University Abstract \n We present a technique for higher-order representation of substruc\u00adtural logics such as linear or modal \nlogic. We show that such log\u00adics can be encoded in the (ordinary) Logical Framework, without any linear \nor modal extensions. Using this encoding, metatheoretic proofs about such logics can easily be developed \nin the Twelf proof assistant. Categories and Subject Descriptors I.2.3 [Deduction and Theo\u00adrem Proving]: \nDeduction General Terms Languages. Keywords Logical frameworks, linear logic, modal logic, mecha\u00adnized \nmetatheory. 1. Introduction The Logical Framework (or LF) [8] provides a powerful and .ex\u00adible framework \nfor encoding deductive systems such as program\u00adming languages and logics. LF employs an elegant account \nof bind\u00ading structure by identifying object-language variables with LF vari\u00adables, object-language contexts \nwith (fragments of) the LF context, and object-language binding occurrences with LF lambda abstrac\u00adtion. \nThis account of binding, often called higher-order abstract syntax [15], automatically handles most operations \nthat pertain to binding, including alpha-equivalence, substitution, and variable\u00adfreshness conventions \n[4]. Since the object-language context is maintained implicitly, as part of the built-in LF context, \nthe structural properties of LF contexts (such as weakening and contraction) automatically apply to the \nobject language as well. Ordinarily this is desirable, but it poses a problem for encoding substructural \nlogics that do not possess those properties.1 For example, linear logics [7] (by design) satisfy neither \nweakening nor contraction, so it would seem that they cannot be encoded in LF. One solution to this problem \nis to extend LF with linear features. Linear LF [5] extends LF with linear assumptions and connectives. \nThis provides the ability to encode linear logics. However, linearity has yet to be implemented in Twelf \n[16], the proof assistant that 1 Substructural logics may be de.ned in various different ways. For our \npurposes, we de.ne substructural logic to mean any logic in which it is not the case that every bound \nvariable can be freely used, or not, throughout its scope. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. implements LF, in part due to unresolved complications \nthat linear\u00adity creates in its metalogical apparatus. Consequently, Linear LF is not currently an option \nfor those engaged in formalizing metathe\u00adory. Moreover, Linear LF does not give us any assistance with \nother substructural logics, such as af.ne, strict, or modal logic. Another option is to break with standard \nLF practice and model object-language contexts explicitly [6]. Explicit contexts can be reconciled with \nhigher-order abstract syntax, thereby retaining many of the bene.ts of LF. Once contexts are explicit, \nit is easy to state inference rules that handle the context in an appropriate way for a substructural \nlogic. However, the explicit context method is clumsy to work with and sacri.ces some of the advantages \nof LF. For example, although substitution is still free (since the syntax of terms is unchanged), the \nsubstitution lemma is not. The explicit context method is typically used internally within a proof, rather \nthan in the of.cial formalization of a logic. In this paper we advocate a more general and workable ap\u00adproach \nin which we look at substructural logic from a slightly dif\u00adferent perspective. Rather than viewing a \nsubstructural logic from the perspective of its contexts (that is, collections of assumptions), we suggest \nit is pro.table to look at it from the perspective of its individual assumptions. The essence of linear \nlogic is not that type-checking splits the context when it checks a (multiplicative) term with multiple \nsub\u00adterms. The essence of linear logic is that an assumption is used ex\u00adactly once. The latter property \ncan be stated on an assumption-by\u00adassumption basis, without reference to contexts. Thus, wherever an \nassumption is introduced, as part of the typing rule that introduced it, we can check that that assumption \nis used linearly. Pfenning [13] proposed enforcing linearity using a meta\u00adjudgement that traced the use \nof an assumption throughout a typ\u00ading derivation. Avron, et al. [3] later used a similar approach for \nmodal logic. Unfortunately, the meta-judgement approach is very awkward to use in practice. Also both \nwere able to prove adequacy for their encodings, neither (so far as we are aware) proved any further \nresults using their encodings. Fortunately, we need not use a meta-judgement. We observe that the proof \nterms alone are enough to track the use of restricted assumptions. There is no need to examine typing \nderivations, and therefore no need for a meta-judgement. The idea of linearity as a judgement over proof \nterms dates to the early days of LF. Avron et al. [1, 2] suggested that linearity can be expressed by \nimposing a lattice structure on proof terms and de.ning linear proof terms as those that are strict and \ndistributive, when viewed as a function of their linear variables. In this paper, we suggest a simpler \nformulation of linearity, based on tracking variables through the proof terms of linear logic. This allows \nfor a clean, practical de.nition of linearity. We express linear logic using two judgements, the usual \ntyping judgement: ICFP 10, September 27 29, 2010, Baltimore, Maryland, USA. Copyright &#38;#169; 2010 \nACM 978-1-60558-794-3/10/09. . . $10.00 of : term -> tp -> type. c  and a linearity judgement: linear \n: (term -> term) -> type. The judgement linear(.x.Mx) should be read as the variable x is used linearly \n(i.e., is used exactly once) in Mx. In this paper, we illustrate the use of a substructural judgement \n(such as linear) in three settings: linear logic, dependently typed linear logic, and judgemental modal \nlogic [14]. Many other sub\u00adstructural logics including af.ne logic and strict logic can be han\u00addled analogously. \nSome others, such as ordered logic [17, 18], can\u00adnot, because the rules of the logic make it impossible \nto handle as\u00adsumptions independently. We brie.y discuss the latter in Section 5. The full Twelf development \ncan be found on-line at:2 www.cs.cmu.edu/~crary/papers/2009/substruct.tar In our discussion, we assume \nfamiliarity with the Logical Framework, and with linear and modal logic. Some familiarity with Twelf \nmay also be helpful. The sections on adequacy are technical, but the remainder of the paper should be \naccessible to the casual practitioner. Throughout the paper, we will consider alpha-equivalent ex\u00adpressions \nto be identical. We will do so in both the object language and the meta-language. 2. Linear Logic We \nbegin by representing the syntax of linear logic in the usual fashion. The LF encoding, with the standard \non-paper notation written alongside it for reference, is shown in Figure 1. The type atom ranges over \na .xed set of atomic propositions. On paper, we represent linear logic with the typing judgment G; . \nf M : A. In this, the .rst context, G, represents the un\u00adrestricted context (i.e., truth), and the second \ncontext, ., repre\u00adsents the linear context (i.e., resources). To simplify the notation, we adopt the \nconvention that the linear context is unordered. Thus (., .') refers to a context that can be split into \ntwo pieces . and .' that may possibly be interleaved. We also adopt the convention that all the variables \nappearing in either context must be distinct. The encoding of the static semantics, as discussed previously, \nis given by two judgements: of : term -> tp -> type. linear : (term -> term) -> type. We read of MA \nas M is of type A, and we read linear ([x:term] M x) as x is used linearly in (M x). Note that [x:term] \nis Twelf s concrete syntax for LF lambda abstraction3 (.x:term.). Twelf can usually infer the domain \ntype, leaving just [x]. We proceed rule-by-rule to show the encoding of the static semantics. Variables \nThe rule for linear variables states that a linear variable may be used provided there are no other linear \nvariables in scope: G; x:A f x : A There is no typing rule for variables in the encoding; that is handled \nautomatically by higher-order representations. However, there is a linearity rule that states that x \nis linear in x: 2 The development checks under the latest Twelf build, available at twelf. plparty.org/wiki/Download. \nSome earlier versions contain a bug that prevent the development from checking. 3 Keep in mind the distinction \nbetween lambda abstraction in LF, which represents binding, and lambda abstraction in the object language \n(llam). tp : type. A ::= atomic : atom -> tp. a lolli : tp -> tp -> tp. | A -A tensor : tp -> tp -> tp. \n| A . A with :tp->tp->tp. | A &#38; A plus :tp->tp->tp. | A + A one : tp. | 1 zero : tp. | 0 top : tp. \n|T ! :tp->tp. | !A term : type. M ::= x llam : (term -> term) -> term. | .x.M lapp : term -> term -> \nterm. | MM tpair : term -> term -> term. | M . M lett : term -> (term -> term -> term) -> term | let \nx . x = M in M pair : term -> term -> term. |(M, M) pi1 : term -> term. | p1M pi2 : term -> term. | p2M \nin1 : term -> term. | in1M in2 : term -> term. | in2M case : term -> (term -> term) -> (term -> term) \n-> term. | case(M, x.M.x.M) star : term. |* leto : term -> term -> term. | let * = M in M any : term \n-> term. | any M unit : term. | () bang : term -> term. | !M letb : term -> (term -> term) -> term. | \nlet !x = M in M Figure 1. Linear logic syntax linear/var : linear ([x] x). The rule for unrestricted \nvariables states that an unrestricted vari\u00adable may be used provided there are no linear variables in \nscope: G(x)= A G; E f x : A As with linear variables, there is no typing rule for unrestricted vari\u00adables \nin the encoding. There is also no linearity rule for unrestricted variables. Linear implication The introduction \nrule for linear implication is: G; (.,x:A) f M : B G; . f .x.M : A -B  This is encoded using two rules: \nof/llam : of (llam ([x] M x)) (lolli A B) <-({x:term} of x A -> of (M x) B) <-linear ([x] M x). linear/llam \n: linear ([y] llam ([x] M y x)) <-({x:term} linear ([y] M y x)).  Note that {x:term} is Twelf s concrete \nsyntax for the dependent function space (.x:term.). Again, Twelf can usually infer the domain type, leaving \njust {x}. The typing rule has the usual typing premise, plus a second premise that requires that the \nargument be used linearly in the body. The linearity rule says that a variable y is linear in a function \n(llam ([x] M y x)) if it is linear in its body (Myx) for any choice of x. The elimination rule splits \nthe linear context between the func\u00adtion and argument: G; . f M : A -B G; . ' f N : A G; (., . ' ) f \nMN : B This is encoded using three rules: of/lapp : of (lapp M N) B <-of M (lolli A B) <-of N A. linear/lapp1 \n: linear ([x] lapp (M x) N) <-linear ([x] M x). linear/lapp2 : linear ([x] lapp M (N x)) <-linear ([x] \nN x).  The typing rule is standard. There are two linearity rules, one for each way a linear variable \nmight be used. The .rst linearity rule says that x is linear in (lapp (M x) N) if it is linear in (M \nx) and does not appear in N. (Since implicitly bound meta-variables such as M and N are quanti.ed on \nthe outside, stating N without a dependency on x means that x cannot appear free in N.) The second linearity \nrule provides the symmetric case. Multiplicative conjunction The introduction rule for tensor is: G; \n. f M : A G; . ' f N : B G; (., . ' ) f M . N : A . B This is encoded using three rules, in a similar \nfashion to function application: of/tpair : of (tpair M N) (tensor A B) <-of M A <-of N B. linear/tpair1 \n: linear ([x] tpair (M x) N) <-linear ([x] M x). linear/tpair2 : linear ([x] tpair M (N x)) <-linear \n([x] N x). The elimination rule is: G; . f M : A . B G; (. ' ,x:A, y:B) f N : C G; (., . ' ) f let x \n. y = M in N : C In the encoding, the typing rule requires that x and y are linear in N. As in previous \ncases where the linear context is split, there are two linearity rules depending on whether a linear \nvariable is used in the let-bound term or the body: of/lett : of (lett M ([x] [y] N x y)) C <-of M (tensor \nA B) <-({x} ofxA -> {y} ofy B->of (Nx y)C) <-({y} linear ([x] N x y)) <-({x} linear ([y] N x y)). linear/lett1 \n: linear ([z] lett (M z) ([x] [y] N x y)) <-linear ([z] M z). linear/lett2 : linear ([z] lett M ([x] \n[y] N z x y)) <-({x} {y} linear ([z] N z x y)).  Additive conjunction The introduction rule for with \ndoes not split the context: G; . f M : A G; . f N : B G; . f(M, N) : A &#38; B In the encoding, there \nis one linearity rule, requiring that linear variables be linear in both constituents of the pair: of/pair \n: of (pair M N) (with A B) <-ofM A <-ofN B. linear/pair : linear ([x] pair (M x) (N x)) <-linear ([x] \nM x) <-linear ([x] N x).  The elimination rules are straightforward: G; . f M : A &#38; B G; . f M : \nA &#38; B G; . f p1M : A G; . f p2M : B of/pi1 : of (pi1 M) A <-ofM (withA B). of/pi2 : of (pi2 M) B \n<-ofM (withA B). linear/pi1 : linear ([x] pi1 (M x)) <-linear ([x] M x). linear/pi2 : linear ([x] pi2 \n(M x)) <-linear ([x] M x).  Disjunction The introduction rules for plus are straightforward: G; . f \nM : A G; . f M : B G; . f in1M : A + B G; . f in2M : A + B of/in1 : of (in1 M) (plus A B) <-ofM A. \nof/in2 : of (in2 M) (plus A B) <-ofM B. linear/in1 : linear ([x] in1 (M x)) <-linear ([x] M x). linear/in2 \n: linear ([x] in2 (M x)) <-linear ([x] M x).  The elimination rule splits the context into two pieces, \none for the discriminant and one used by both arms: G; . f M : A + B G; (. ' ,x:A) f N1 : C G; (. ' ,x:B) \nf N2 : C G; (., . ' ) f case(M, x.N1, x.N2): C In the encoding, the typing rule requires that each \narm s bound variable be used linearly. The linearity rules provide the two cases, one when the variable \nis used linearly in the discriminant, and one in which is it used linearly in both arms: of/case : of \n(case M ([x] N1 x) ([x] N2 x)) C <-ofM(plusA B) <-({x}of xA->of(N1 x)C) <-({x}of xB->of(N2 x)C) <-linear \n([x] N1 x) <-linear ([x] N2 x).  linear/case1 : linear ([y] case (M y) ([x] N1 x) ([x] N2 x)) <-linear \n([y] M y). linear/case2 : linear ([y] case M ([x] N1 y x) ([x] N2 y x)) <-({x} linear ([y] N1 y x)) \n<-({x} linear ([y] N2 y x)). Exponentiation The introduction rule for exponentiation requires that the \nlinear context be empty: G; E f M : A G; E f !M :!A In the encoding, this means there is no linearity \nrule, since variables cannot be linear in exponents: of/bang : of (bang M) (! A) <-of M A.  The elimination \nrule splits the context and adds the newly bound variable to the unrestricted context: G; . f M :!A (G,x:A); \n. ' f N : C G; (., . ' ) f let !x = M in N : C In the encoding, the unrestricted nature of x is handled \nby not checking that x is linear in (N x). The linearity rules work in the usual fashion: of/letb : of \n(letb M ([x] N x)) B <-ofM(! A) <-({x}of xA->of(Nx)B). linear/letb1 : linear ([y] letb (M y) N) <-linear \nM. linear/letb2 : linear ([y] letb M ([x] N y x)) <-({x} linear ([y] N y x)). Units The unit for tensor \nis 1: G; . f M : 1 G;. ' f N : C G; E f* : 1 G;(., . ' ) f let * = M in N : C The encoding is straightforward, \nwith no linearity rule for introduc\u00adtion since variables cannot be linear in *: of/star : of star one. \nof/leto : of (leto M N) C <-of Mone <-of NC. linear/leto1 : linear ([x] leto (M x) N) <-linear ([x] \nM x). linear/leto2 : linear ([x] leto M (N x)) <-linear ([x] N x).  The unit for with , T, is more \ninteresting. It stands for an unknown collection of resources, and consequently has an introduction form \nbut no elimination form: G; . f () : T The encoding provides that any variable is linear in unit: of/unit \n: of unit top. linear/unit : linear ([x] unit). The unit for plus, 0, represents falsehood. Accordingly, \nit has an elimination form but no introduction form. The elimination form behaves a little bit like (); \nany resources not used to prove 0 may be discarded: G; . f M :0 G; (., . ' ) f any M : C  In the encoding \nthere are two linearity rules. A variable is linear in (any M ) if it is linear in M or if it does not \nappear in M at all: of/any : of (any M) T <-of M zero. linear/any1 : linear ([x] any (M x)) <-linear \nM. linear/any2 : linear ([x] any M). Note that it is tempting but incorrect to simplify this to the \nsingle rule: linear/any-wrong : linear ([x] any (M x)). That rule would allow x to be used multiple \ntimes in (M x), which is not permitted. It would be tantamount to moving the entire linear context into \nthe unrestricted context, rather than merely discarding any unused resources. 2.1 Adequacy It seems intuitively \nclear that the preceding is a faithful represen\u00adtation of linear logic. We wish to go further and make \nthe corre\u00adspondence rigorous, following the adequacy argument of Harper et al. [8]. Adequacy establishes \na isomorphism between the object language (linear logic in this case) and its encoding in LF. As usual, \nan isomorphism is a bijection that respects the relevant operations. For syntax, the only primitively \nmeaningful operation is substi\u00adtution. (Other operations are given by de.ned semantics.) Thus, an isomorphism \nfor syntax is a bijective translation that respects sub\u00adstitution. Our translation for syntax (written \n'-') is standard, so we will omit the obvious details of its de.nition and simply state its adequacy \ntheorem for reference: DEFINITION 2.1. Translation of variable sets is de.ned: THEOREM 2.2 (Syntactic \nadequacy). 1. Let Type be the set of linear logic types. Then there exists a bijection '-' between Type \nand LF canonical forms P such that fLF P : tp. (Variables cannot appear within types, so there is no \nsubstitution to respect.) 2. Let S be a set of variables and let TermS be the set of linear logic terms \nwhose free variables are contained in S. Then there exists a bijection '-' between TermS and LF canonical \nforms P such that 'S' fLF P : term. Moreover, '-' respects substitution: '[M/x]N' =['M'/x]'N'.  For \nsemantic adequacy, we wish to establish a bijective transla\u00adtion between typing derivations and LF canonical \nforms.4 The usual statement of adequacy for typing is something to the effect of: DEFINITION 2.3. Translation \nof contexts is de.ned: 'x1:A1,..., xn:An ' = x1 :term, dx1 :of x1 'A1 ',..., xn:term, dxn:of xn 'An ' \n NON-THEOREM 2.4. There exists a bijection between derivations of the judgement G f M : A and LF canonical \nforms P such that 'G' fLF P : of 'M''A'. Unfortunately, this simple statement of adequacy does not work \nin the presence of linearity. Consider the judgement E; x:a f (). () : T.T. It has two derivations, depending \non which conjunct is chosen to consume the assumption: E; x:a f () : T E; E f () : T E; E f () : T E; \nx:a f () : T E; x:a f ().() : T.T E; x:a f ().() : T.T However, the LF type corresponding to that judgement, \n{x:term} of x (atomic a) -> of (tpair unit unit) (tensor top top) contains only one canonical form, \nnamely: [x:term] [dx:of x (atomic a)] of/tpair of/unit of/unit  So linear-logic typing derivations are \nnot in bijection with the LF encoding of typing in general. Our isomorphism must take linearity into \naccount, and not only where linearity is a premise of a typing rule. Consequently, we establish a correspondence \nbetween each linear-logic typing derivation on the one hand, and an LF proof of typing paired with a \ncollection of LF proofs of linearity on the other. Alas, this is notationally awkward when compared with \nthe usual adequacy theorem. DEFINITION 2.5. An encoding structure for G; . f M : A is a pair (P,H) of \nan LF canonical form P and a .nite mapping H from variables to LF canonical forms, such that: 'G, .' \nfLF P : of 'M''A', and  Domain(H) = Domain(.), and  For each variable y in Domain(.), 'Sy ' fLF H(y): \nlinear ([y:term] 'M '), where Sy = Domain(G, .) \\{y}.   4 That is, we view typing derivations as having \nno operations to respect. Harper et al. suggest that substitution of derivations for assumptions is a \nmeaningful operation on typing derivations, and prove that their translation respects such substitutions. \nThis could be done in our setting as well. How\u00adever, we take the view that when substituting derivations \nfor assumptions, we care only that the resulting derivation exists (this being the standard substitution \nlemma), and not about the identity of that resulting derivation. THEOREM 2.6 (Semantic adequacy). There \nexists a bijection '-' between derivations of the judgement G; . f M : A and encoding structures for \nG; . f M : A. Proving adequacy is typically straightforward but tedious once it is stated correctly. \nThe same is true here, but the tedium is a bit more pronounced because of the need to manipulate encoding \nstructures, rather than just canonical forms. We give a few cases by way of example: Proof Sketch First, \nby induction on derivations, we construct the translation and show it is type correct. Suppose ' is the \nderivation: G; x:A f x : A Then ''' def (dx, {x . linear/var}). = Suppose ' is the derivation: G(x)= \nA G; E f x : A Then ''' def (dx, \u00d8). = Suppose ' is the derivation: '1 . . . . G; (.,x:A) f M : B G; \n. f .x.M : A -B Let ''1 ' =(P1,H1). By induction, (P1,H1) is an encod\u00ading structure for G; (.,x:A) f \nM : B, so: 'G, .', x:term, dx:of x 'A' fLF P1 : of 'M''B' and 'Domain(G, .)' fLF H1(x): linear ([x] 'M') \nTherefore: 'G; .' fLF of/llam (H1(x)) ([x] [dx] P1) : of (llam ([x] 'M')) (lolli 'A''B') So let ''' =(of/llam \n(H1(x)) ([x] [dx] P1),H) def where for each y in Domain(.), H(y)= linear/llam ([x] H1(y)). Suppose ' \nis the derivation: '1 '2 . . . . . . . . G; .1 f M : A -B G; .2 f N : A G; (.1, .2) f MN : B Let ''1 \n' =(P1,H1) and let ''2 ' =(P2,H2). By induction (P1,H1) is an encoding structure for G; .1 f M : A -B \nand (P2,H2) is an encoding structure for G; .2 f N : A. Let y . Domain(.1, .2) be arbitrary. Let S = \nDomain(G) and Si = Domain(.i). Then either y . S1 and y . S2 or vice versa. Suppose the former. Then: \n  'S . S1 \\{y}' fLF H1(y): linear ([y] 'M') Also, since y . Domain(.2), y is not free in N or (consequently) \nin 'N'. Therefore: 'S . S1 . S2 \\{y}' fLF linear/lapp1 (H1(y)) : linear ([y] lapp 'M''N') The other case \nis symmetric. So let ''' =(of/lapp P2 P1,H), where for each y in Domain(.1, .2), def linear/lapp1 (H1(y)) \n(if y . S1) H(y)= linear/lapp2 (H2(y)) (if y . S2) Et cetera. It remains to show that '-' is a bijection. \nTo do so, we exhibit an inverse L--. The interesting cases are those that split the context. We give \nthe application case as an example. Suppose (of/lapp P2 ' P ' 1,H ' ) is an encoding structure for G; \n. f O : B '. Then O has the form M ' N ', and 'G; .' fLF P1 ' : of 'M '''A ' -B '', and 'G; .' fLF P2 \n' : of 'N '' 'A ''. We must sort . into two pieces. De.ne: .1 = {(y:C) . . |.R.H ' (y)= linear/lapp1 \nR} .2 = {(y:C) . . |.R.H ' (y)= linear/lapp2 R} H ' = {y . R | H ' (y)= linear/lapp1 R} 1 H2 ' = {y . \nR | H ' (y)= linear/lapp2 R} Note that .=.1, .2. Also note that, by the de.nition of .1 and .2, no variable \nin .1 appears free in N ' or vice versa. Therefore it is easy to show that no assumption in '.1 ' appears \nfree in P ' 2 and vice versa. Hence5 'G; .1 ' fLF P1 ' : of 'M '''A ' -B '' and 'G; .2 ' fLF P2 ' : of \n'N '''A ''. Also, Domain(Hi' ) = Domain(.i). Therefore (P ' 1,H 1' ) is an encoding structure for G; \n.1 f M ' : A ' -B '' and (P ' 2,H 2) is an encoding structure for G; .2 f N ' : A ' . Let ' i = L(P \n' i,H i' )-. Then ' 1 is a derivation of G; .1 f M ' : A ' -B ' and ' 2 is a derivation of ' A ' P ' \nP '' G; .2 f N : . So let L(of/lapp 21,H )-be the derivation: ' 1 ' 2 . . . . . . . . G; .1 f M ' : \nA ' -B ' G; .2 f N ' : A ' G; (.1, .2) f M ' N ' : B ' We can show, by induction over LF canonical forms, \nthat L-\u00adis fully de.ned over encoding structures. It is easy to verify that '-' and L--are inverses. \nTherefore '-' is bijective. D When the linear context is empty, the H portion of an encoding structure \nis empty, and we recover the usual notion of adequacy: COROLLARY 2.7. There exists a bijection between \nderivations of the judgement G; E f M : A and LF canonical forms P such that 'G' f P : of 'M ''A'. 5 \nThis fact, that non-appearing variables may be omitted from the context, requires a strengthening lemma \nfor LF that is proved by Harper and Pfen\u00adning [9, Theorem 6.6]. 2.2 Metatheory To demonstrate the practicality \nof our encoding, we proved the sub\u00adject reduction theorem in Twelf. We give the de.nition of reduction \nin Figure 2. Reduction is encoded with the judgement: reduce : term -> term -> type. We will not discuss \nthe encoding of reduction and its adequacy, as they are standard. We prove subject reduction by a series \nof four metatheorems. To make the development more accessible to readers not familiar with Twelf s logic \nprogramming notation for proofs, we give those metatheorems in English. LEMMA 2.8 (Composition of linearity). \nSuppose the ambient context is made up of bindings of the form x:term (and other bindings not subordinate6 \nto linear). If linear ([x] M1 x) and linear ([x] M2 x) are derivable, then linear ([x] M1 (M2 x)) is \nderivable. The next lemma is usually glossed over in proofs on paper: LEMMA 2.9 (Reduction of closed \nterms). Suppose the ambient context is made up of bindings of the form x:term (and other bindings not \nsubordinate to reduce). If ({x:term} reduce M1 (M2 x)) is derivable, then there exists M2 :term such \nthat M2 = ([_] M2 ). LEMMA 2.10 (Subject reduction for linear). Suppose the ambi\u00adent context is made \nup of bindings of the form x:term,dx:of xA (and other bindings not subordinate to reduce or of). If ({x} \nreduce (M x) (M x)) and ({x} ofx A->of (M x) B) and linear ([x] M x) are derivable, then linear ([x] \nM x) is derivable. Proof Sketch By induction on the .rst derivation. Cases involving sub\u00adstitution (most \nof the beta-reduction cases) use Lemma 2.8. Multiple-subterm compatibility cases use Lemma 2.9 to show \nthat reduction of subterms not mentioning a linear variable will not create such a reference. THEOREM \n2.11 (Subject reduction for of). Suppose the ambient context is made up of bindings of the form x:term,dx:of \nx A (and other bindings not subordinate to reduce or of). If reduce M M and of M T are derivable, then \nof M T is derivable. Proof Sketch By induction on the .rst derivation. Cases with linearity premises \n(reduce/llam, reduce/lett, and reduce/case) use Lemma 2.10 to show that the linearity premises are pre\u00adserved \nby reduction. COROLLARY 2.12. If G; . f M : A and M -. M ' then G; . f M ' : A. Proof Immediate from \nSubject Reduction and Adequacy. 6 Subordinate is a term of art in Twelf. Informally, s is subordinate \nto t if s can contribute to t. More precisely, a type family s is subordinate to an type family t if \nthere exist types S and T belonging to s and t such that objects of type S can appear within objects \nof type T [20]. If s is not subordinate to t, then assumptions whose types belong to s can be ignored \nwhile considering t. (.x.M)N -. [N/x]M let x . y = M . N in O -. [M, N/x, y]Op1(M, N) -. Mp2(M, N) -. \nN case(in1M, x.N1, x.N2) -. [M/x]N1 case(in2M, x.N1, x.N2) -. [M/x]N2 let * = * in M -. M ' '' '' M -. \nMM -. MN -. NM -. MN -. N ' '' '' let !x =!M in N -. [M/x]N .x.M -. .x.M MN -. MN M . N -. M . N '' '''' \nM -. MN -. NM -. MN -. NM -. MM -. M '' '' let x . y = M in N -. let x . y = M ' in N (M, N) -. (M ,N \n' ) p1M -. p1Mp2M -. p2M ''' '' '' M -. MM -. MM -. MN1 -. N1 N2 -. N2 M -. MN -. N in1M -. in1M ' in2M \n-. in2M ' case(M, x.N1, x.N2) -. case(M ' , x.N ' 1, x.N ' 2) let * = M in N -. let * = M ' in N ' M \n-. M ' M -. M ' M -. M ' N -. N ' any M -. any M ' !M -. !M ' let !x = M in N -. let !x = M ' in N ' \nM -. M Figure 2. Linear logic reduction tp : type. A ::= ... \u00b7\u00b7\u00b7 atomic : atom -> tp. | a const : constant \n-> term -> tp. | c(M) pi : tp -> (term -> tp) -> tp. | .x:A.B term : type. M ::= ... \u00b7\u00b7\u00b7 ulam : (term \n-> term) -> term. | .!x.M uapp : term -> term -> term. | M @ M Figure 3. Linear logic syntax (dependently \ntyped) 3. Dependently Typed Linear Logic Adding dependent types to linear logic is straightforward syntacti\u00adcally. \nThe revised syntax is shown in Figure 3. We delete atomic propositions, and replace them with constants \nthat take a single term parameter. (That parameter may be a unit or tuple, which pro\u00advides implicit support \nfor zero or multiple parameters.) In the static semantics, a new wrinkle arises. Now that terms can appear \nwithin types, the typing rules must ensure that linear variables are not used within types. However, \na variable might appear within a term s type without appearing in the term itself. This is obvious because \nour lambda abstractions are unlabelled, but it would still be the case even if all bindings were labeled \nwith types. This is because of the equivalence rule: G; . f M : A G f A ' type A =\u00df A ' G; . f M : A \n' Using the equivalence rule, a term s type can mention any variable in scope. Therefore, we must enforce \nthe rule s requirement that no linear variables appear in . '. A linearity judgement on terms alone will \nnot suf.ce. One solution to this problem is to make linearity a judgement over typing derivations, rather \nthan over proof terms. However, that would make linearity a dependently typed meta-judgement, which would \nbe too cumbersome to work with in practice. It is better to maintain linear as a judgement over proof \nterms. Instead, we change our view of unrestricted variables. In non\u00addependently typed linear logic, \nwe viewed unrestrictedness as merely the absence of a linearity restriction. Now we will view un\u00adrestrictedness \nas conferring an af.rmative capability; speci.cally, the capability to appear within types. We add a \nnew judgement unrest that applies to unrestricted variables. We extend that judgement to terms by saying \nthat a term is unrestricted if all its free variables are unrestricted: unrest : term -> type. unrest/llam \n: unrest (llam ([x] M x)) <-({x} unrest x -> unrest (M x)). unrest/lapp : unrest (lapp M N) <-unrest \nM <-unrest N. ... Note that, within the unrest judgement, all bound variables are taken to be unrestricted, \neven linear ones. Only unrestricted terms are permitted to serve as the parameter to a constant. On paper, \nthis is written c : A . type G; E f M : A G f c(M) type where we assume some pre-speci.ed collection \nof axioms of the form c : A.type. In our encoding, the well-formedness judgement for types is wf: tp->type. \nThe constant rule is written: wf/const : wf (const C M) <-cparam C A <-of M A <-unrest M.  We assume \nthere exists a unique cparam rule for each axiom c : A . type. The remaining wf rules are uninteresting \n(but note that the rule for pi introduces an unrestricted variable). Our existing typing rules must be \naltered in two ways. First, now that types can be ill-formed, several rules must add a wf premise. This \nis straightforward. Second, the rules for the exponential must be rewritten to use the unrest judgement: \nof/bang : of (bang M) (! A) <-of MA <-unrest M. of/letb : of (letb M ([x] N x)) B <-of M(! A) <-({x}of \nxA ->unrest x->of(Nx)B) <-wf B.  We also have the new rules for unrestricted functions and applica\u00adtion: \nG f A type (G,x:A); . f M : B G; . f (.!x.M):.x:A.B G; . f M :.x:A.B G; E f N : A G; . f M @ N :[N/x]B \nof/ulam : of (ulam ([x] M x)) (pi A ([x] B x)) <-wf A <-({x} of x A -> unrest x -> of (M x) (B x)). of/uapp \n: of (uapp M N) (B N) <-ofM(piA ([x]Bx)) <-of N A <-unrest N. linear/ulam : linear ([y] ulam ([x] M \ny x)) <-({x} linear ([y] M y x)). linear/uapp : linear ([x] uapp (M x) N) <-linear ([x] M x). And .nally \nequivalence: of/equiv : of M A <-of M A <-wf A <-equiv A A .  The addition of dependent types complicates \nthe proof of subject reduction in a number of ways, but nearly all are orthogonal to linearity. One issue \nthat does relate to linearity is we require one additional lemma to show that unrestrictedness is preserved \nby reduction: LEMMA 3.1 (Subject reduction for unrest). Suppose the ambi\u00adent context is made up of bindings \nof the form x:term,ex:unrest x and bindings of the form x:term (and other bindings not subor\u00addinate to \nreduce or unrest). If reduce M M and unrest M are derivable, then unrest M is derivable. 3.1 Adequacy \n Adequacy for dependently typed linear logic proceeds in much the same fashion as before. We must make \nfour changes. First, we revise syntactic adequacy of types, now that types are not closed: THEOREM 3.2 \n(Syntactic adequacy). 1. Let S be a set of variables and let TypeS be the set of linear logic types \nwhose free variables are contained in S. Then there exists a bijection '-' between TypeS and LF canonical \nforms P such that 'S' fLF P : tp. Moreover, '-' respects substitu\u00adtion: '[M/x]A' =['M'/x]'A'. 2. Let \nS be a set of variables and let TermS be the set of linear logic terms whose free variables are contained \nin S. Then there exists a bijection '-' between TermS and LF canonical forms P such that 'S' fLF P : \nterm. Moreover, '-' respects substitution: '[M/x]N' =['M'/x]'N'.  Second, we de.ne a translation for \nunrestricted contexts: ' x1:A1,..., xn:An ' = x1 :term, dx1 :of x1 'A1 ',ex1 :unrest x1 ..., xn:term, \ndxn:of xn 'An ',exn:unrest xn and we alter the .rst clause of the de.nition of encoding structures to \nread: ' G' , '.' fLF P : of 'M''A' Third, we state adequacy for typing and for well-formedness of types \nsimultaneously: THEOREM 3.3 (Semantic adequacy). 1. There exists a bijection '-' between derivations \nof the judge\u00adment G; . f M : A and encoding structures for G; . f M : A. 2. There exists a bijection \n'-' between derivations of the judge\u00adment G f A type and LF canonical forms P such that ' G' fLF P : \nwf 'A'. Fourth, we state a new lemma to deal with unrest derivations: LEMMA 3.4. 1. Suppose G; . f M \n: A. Then there exists a unique LF canonical form P such that ' G, .' fLF P : unrest 'M '. 2. Suppose \nthere exists an LF canonical form P such that ' G' , '.' fLF P : unrest 'M'. Then no variable in Domain(.) \nappears free in M . 3. Suppose there exists an LF canonical form P such that ' G' , '.' fLF P : wf 'A'. \nThen no variable in Domain(.) appears free in A.  We give the adequacy case for unrestricted application \nto illus\u00ad trate how Lemma 3.4 is used. Proof Sketch of Theorem 3.3 Suppose ' is the derivation: ' 1 \n. ' 2 . . . . . . . G; . f M : .x:A.B G; E f N : A G; . f M @ N :[N/x]B Let '' 1 ' =(P1,H1) and let \n'' 2 ' =(P2,H2). By induction (P1,H1) is an encoding structure for G; . f M :.x:A.B and (P2,H2) is an \nencoding structure for G; E f N : A. By Lemma 3.4, there exists a unique Q such that ' G' fLF unrest \n'N'. So let ''' def (of/uapp Q P2 P1,H), where for = each y in Domain(.), H(y)= linear/uapp (H1(y)). \nAs an example of the de.nition of the inverse, suppose P ' 2 P '' (of/uapp Q ' 1,H ) is an encoding structure \nfor G; . f O : C. Then O has the form M ' @ N ' and C has the form ' P ' [N /x]B '. Also, ' G' , '.' \nfLF 1 : of 'M '''.x:A ' .B '', and ' G' , '.' fLF P2 ' : of 'N '''A '', and ' G' , '.' fLF Q ' : unrest \n'N ''. '' ' Let H1 = {y . R|H (y)= linear/uapp R}. Then (P1' ,H1) is an encoding structure for G; . f \nM ' :.x:A ' .B ' . Let ' '' 1 = L(P ' 1,H1)-. By Lemma 3.4, no variable in Domain(.) appears free in \nN ' . (In this case but not in some others this fact could also be ascertained by inspection of H '.) \nTherefore, ' G' fLF P ' 2 : of 'N '''A ''. Consequently, (P2' , \u00d8) is an encoding structure ' = L(P ' \nfor G; E f N : A '. Let ' ' 22, \u00d8)-. P '' Then let L(of/uapp Q ' 2 P ' 1,H )-be the derivation: ' ' ' \n' 1 2 . . . . . . . . G; . f M ' :.x:A ' .B ' G; E f N ' : A ' '' '  tp : type. A ::= atomic : atom \n-> tp. a arrow : tp -> tp -> tp. | A . A box :tp->tp. | DA term : type. M ::= x lam : (term -> term) \n-> term. | .x.M app : term -> term -> term. | MM bx : term -> term. | box M letbx : term -> (term -> \nterm) -> term. | let box x = M in M Figure 4. Modal logic syntax Since Q ' is uniquely determined by \nLemma 3.4, it is easy to verify that '-' and L--are inverses. D 4. Modal Logic There are (at least) \ntwo ways to specify modal logic. One is using an explicit notion of Kripke worlds and accessibility [19]. \nSuch a formulation does not behave as a substructural logic (in that all assumptions are available throughout \ntheir scope) and can be encoded in LF without dif.culty [3, 10]. A second, which we consider here, is \njudgemental modal logic [14]. Judgemental modal logic distinguishes between two sorts of assumption, \ntruth and validity. Although judgemental modal logic has no explicit notion of Kripke worlds, one can \nthink of truth as applying to only the current world, and validity as applying to all worlds. Consequently, \nthe introduction rule for DA, which internalizes validity, must require that no truth assumptions are \nused. This is accomplished with the rule: G; E f M : A G; . f box M : DA  Here, G is the validity context \nand . is the truth context. Whatever truth assumptions exist are discarded while type checking M. Since \nassumptions in . are unavailable in M despite being in scope, judgemental modal logic behaves as a substructural \nlogic. We express this restriction using a judgement reminiscent of linear, indicating that an assumption \nis used locally to the current world: local : (term -> term) -> type. The judgement local([x] Mx) should \nbe read as the variable x is used locally (i.e., not within boxes) in Mx . The syntax of modal logic \nis given in Figure 4. In the interest of brevity, we omit discussion of the possibility modality here. \nA treatment of possibility appears in the full Twelf development. Variables The rules for variables allow \nthe use of any variable in the context: .(x)= A G(x)= A G; . f x : A G; . f x : A  As usual, there is \nno typing rule for variables in the encoding, but there are two locality rules. First, x is local in \nx: local/var : local ([x] x). Second, we wish to say that x is local in every variable (truth or validity) \nother than x. The easiest way to express this is to generalize to all terms M that do not contain x: \nlocal/closed : local ([x] M). Implication The introduction rule for implication is: G; (.,x:A) f M : \nB G; . f .x.M : A . B This is encoded using two rules, reminiscent of the ones for linear implication: \nof/lam : of (lam ([x] M x)) (arrow A B) <-({x}ofx A->of(Mx)B) <-local ([x] M x). local/lam : local ([y] \nlam ([x] M y x)) <-({x} local ([y] M y x)).  The function s argument is a truth assumption, so it must \nbe used locally in the body. The elimination rule for implication is straightforward: G; . f M : A . \nB G; . f N : A G; . f MN : B of/app : of (app M N) B <-ofM(arrowA B) <-of N A. local/app : local ([x] \napp (M x) (N x)) <-local ([x] M x) <-local ([x] N x).  Necessity Recall the introduction rule for necessity: \nG; E f M : A G; . f box M : DA  This is encoded with the single rule: of/bx : of (bx M) (box A) <-ofM \nA.  The important thing here is the absence of any locality rule for bx. The only way to show that a \nvariable is local in (bx M) is using the local/closed rule, which requires that the variable not appear \nin M, as desired. The elimination rule for necessity is: G; . f M : DA (G,x:A); . f N : C G; . f let \nbox x = M in N : C This is encoded using two rules: of/letbx : of (letbx M ([x] N x)) B <-ofM (boxA) \n<-({x} ofxA->of (Nx)B). local/letbx : local ([x] letbx (M x) ([y] N x y)) <-local ([x] M x) <-({y} local \n([x] N x y)). Since the variable introduced by letbx is a validity assumption, we do not check that \nit is local in the body. Metatheory Subject reduction for modal logic follows the same development as \nfor linear logic in Section 2.2, with local stand\u00ading in for linear. One lemma must be generalized: since \nlocal variables can appear multiple times in modal logic, composition of locality must allow the local \nvariable to appear (locally) in the scope of substitution (M1 below), as well as in the substitutend \n(M2 below): LEMMA 4.1 (Composition of locality). Suppose the ambient con\u00adtext is made up of bindings \nof the form x:term (and other bindings not subordinate to local). If ({y} local ([x] M1 x y)) and ({x} \nlocal ([y] M1 x y) and local ([x] M2 x) are deriv\u00adable, then local ([x] M1 x (M2 x)) is derivable. 4.1 \nAdequacy Syntactic adequacy for modal logic is again standard: DEFINITION 4.2. Translation of variable \nsets is de.ned: '{x1,..., xn}' = x1:term,..., xn:term THEOREM 4.3 (Syntactic adequacy). 1. Let Type \nbe the set of modal logic types. Then there exists a bijection '-' between Type and LF canonical forms \nP such that fLF P : tp. (Variables cannot appear within types, so there is no substitution to respect.) \n 2. Let S be a set of variables and let TermS be the set of modal logic terms whose free variables are \ncontained in S. Then there exists a bijection '-' between TermS and LF canonical forms P such that 'S' \nfLF P : term. Moreover, '-' respects substitution: '[M/x]N' =['M'/x]'N'.  Semantic adequacy again encounters \na challenge; this time the opposite problem from the one we saw with linear logic. In the encoding of \nlinear logic there were too few typing derivations; here there are too many. The problem lies in the \nlocal judgement. Unlike linear, which expressed a property that could be satis.ed in many ways, local \nexpresses a fact that essentially can be satis.ed in only one way, by the variable not appearing in any \nboxes. In this regard, local is more like unrest than linear. However, unlike unrest, derivations of \nlocal are not unique. The problem stems from the fact that the local/closed rule can apply to terms that \nalso have another rule. For example, sup\u00adpose M and N are closed terms. Then local ([x] app M N) has \nat least two derivations: local/closed and (local/app local/closed local/closed). One solution to the \nproblem would be to restrict local/closed to variables (and add another rule for closed boxes). This \nwould ensure that local derivations are unique (like unrest derivations). We could impose the restriction \nby creating a judgement (say, var) to identify variables, and then rewrite the local/closed rule as: \nlocal/closed-varonly : local ([y] X) <-var X.  However, this solution has a signi.cant shortcoming; \nthe substitu\u00adtion lemma would no longer be a free consequence of higher-order representation. Under such \na regime, variable assumptions would take the form ({x:term} of x A -> var x -> ...whatever...) Consequently, \nwe would only obtain substitution for free when the substitutend possesses a var derivation; that is, \nwhen the substi\u00adtutend is another variable. The general substitution lemma would have to be proved and \nused explicitly. A better solution is to rephrase adequacy to quotient out the excess derivations: DEFINITION \n4.4. Translation of contexts is de.ned: 'x1:A1,..., xn:An ' = x1 :term, dx1 :of x1 'A1 ',..., xn:term, \ndxn:of xn 'An ' DEFINITION 4.5. Let ~be the least congruence over LF canonical = ~P ' forms such that \nP = for any P, P ' : local F (where F : term -> term). An encoding structure for G; . f M : A is a nonempty \nequivalence class (under ~ =) of LF canonical forms P such that: 'G, .' fLF P : of 'P ''A', and  For \nevery y in Domain(.), there exists an LF canonical form Qy such that 'Sy ' fLF Qy : local ([y:term] 'M \n'), where  Sy = Domain(G, .) \\{y}. Observe that since the issue in modal logic is too many locality \nderivations (in contrast to linear logic where it was too few), we have no need to make a mapping from \nvariables to locality deriva\u00adtions an explicit component of the encoding structure. Instead, it is convenient \nsimply to quantify them existentially, as above. THEOREM 4.6 (Semantic adequacy). There exists a bijection \nbe\u00adtween derivations of the judgement G; . f M : A and encoding structures for G; . f M : A. Proof Sketch \nWe give one case in each direction, by way of example. Suppose ' is the derivation: ' 1 . . . . G; (.,x:A) \nf M : B G; . f .x.M : A . B Let '' 1 ' = P1. By induction, P1 is an encoding structure for G; (.,x:A) \nf M : B, so: 'G, .', x:term, dx:of x 'A' fLF P1 : of 'M''B' and, for every y . Domain(.,x:A), there exists \na Qy such that: 'Domain(G, .,x:A) \\{y}' fLF Qy : local ([y:term] 'M ') In particular, x . Domain(.,x:A), \nso: 'Domain(G, .)' fLF Qx : local ([x:term] 'M ') Therefore: 'G, .' fLF of/lam Qx P1 : of '.x.M''A . \nB' Also, for every y . Domain(.), 'Domain(G, .) \\{y}' fLF local/lam ([x:term] Qy ) : local ([y:term] \n'.x.M') So let ''' be the equivalence class containing of/lam Qx P1, which is an encoding structure for \nG; . f .x.M : A . B. As an example of the de.nition of the inverse, suppose (of/bx P ' ) belongs to an \nencoding structure for G; . f O : C. Then O has the form box M ', and C has the form DA '. Also, 'G, \n.' fLF P ' : of 'M '''A ''. Further, for every y in Domain(.), there exists Qy such that 'Sy ' fLF Qy \n: local ([y:term] bx 'M ''), where Sy = Domain(G, .) \\{y}. Each Qy must be local/closed, so no y in Domain(.) \nappears in M '. Therefore 'G' fLF P ' : of 'M '''A ''. The second criterion of encoding structures is \nvacuously satis\u00ad.ed for an empty truth context, so P ' belongs to an encoding structure for G; E f M \n' : A '. Let ' ' = LP ' -. Then let Lof/bx P ' -be the derivation: ' ' . . . . ' : A ' P ''  Suppose \nof/bx P ' ~of/bx P ''. Then P ' = = ~. By induction, -= LP '' LP ' -, so Lof/bx P ' -= Lof/bx P '' \n-. It is easy to verify that, for appropriate ' and P, L'''-= ' and 'LP-' ~ = P. Therefore '-' and L--are \ninverses. D 5. Conclusion The Logical Framework is not only (nor even primarily) a type the\u00adory. More \nimportantly, it is a methodology for representing deduc\u00adtive systems using higher-order representation \nof syntax and se\u00admantics, and a rigorous account of adequacy. Where applicable, the LF methodology provides \na powerful and elegant tool for for\u00admalizing programming languages and logics. There are two reasons \nit might not apply. First, limitations of ex\u00adisting tools for LF, such as Twelf, might prevent one from \ncarrying out the desired proofs once a system were encoded in LF. Second, there might be an inherent \nproblem representing the desired deduc\u00adtive system adequately using a higher-order representation. When \na language cannot be cleanly represented in a higher-order fashion, it often indicates that something \nabout the language is suspect, such as an incorrect (or at least nonstandard) notion of binding and/or \nscope. In some cases, however, languages with unconventional notions of binding or scope are nevertheless \nsensible. Substructural logics are probably the most important example. In this paper, we show that many \nsubstructural logics can be given a clean higher-order representation by isolating its substructuralness \n(e.g., linearity or locality) and expressing that as a judgement over proof terms. Our strategy applies \nto other substructural logics as well. For example, af.ne logic and strict logic can each be encoded \nalong very similar lines as linear logic. We conjecture that contextual modal logic [11] is encodable \nalong similar lines as judgemental modal logic. This is a good avenue for future work. The logic of bunched \nimplications [12] is another. On the other hand, since our method relies on enforcing sub\u00adstructuralness \non an assumption-by-assumption basis, there are some substructural logics it does not support, such as \nordered logic [17, 18]. In ordered logic, the context is taken to be ordered and assumptions must be \nprocessed in order. It appears that we can\u00adnot enforce this restriction on assumptions independently, \nas the very nature of the restriction is that assumptions are not indepen\u00addent. The usability of one \nassumption can depend on the disposition of every other assumption in scope. References [1] Arnon Avron, \nFurio Honsell, and Ian A. Mason. Using typed lambda calculus to implement formal systems on a machine. \nTechnical Report ECS-LFCS-87-31, Department of Computer Science, University of Edinburgh, July 1987. \n[2] Arnon Avron, Furio Honsell, and Ian A. Mason. An overview of the Edinburgh Logical Framework. In \nGraham Birtwistle and P. A. Subrahmanyam, editors, Current Trends in Hardware Veri.cation and Automated \nTheorem Proving. Springer, 1989. [3] Arnon Avron, Furio Honsell, Marino Miculan, and Cristian Paravano. \nEncoding modal logics in logical frameworks. Studia Logica, 60(1), January 1998. [4] Brian Aydemir, Arthur \nChargu\u00b4 eraud, Benjamin C. Pierce, Randy Pol\u00adlack, and Stephanie Weirich. Engineering formal metatheory. \nIn Thirty-Fifth ACM Symposium on Principles of Programming Lan\u00adguages, San Francisco, California, January \n2008. [5] Iliano Cervesato and Frank Pfenning. A linear logical framework. In Eleventh IEEE Symposium \non Logic in Computer Science, pages 264 275, New Brunswick, New Jersey, July 1996. [6] Karl Crary. Explicit \ncontexts in LF. In Workshop on Logical Frameworks and Meta-Languages: Theory and Practice, Pittsburgh, \nPennsylvania, 2008. Revised version at www.cs.cmu.edu/~crary/ papers/2009/excon-rev.pdf. [7] Jean-Yves \nGirard. Linear logic. Theoretical Computer Science, 50:1 102, 1987. [8] Robert Harper, Furio Honsell, \nand Gordon Plotkin. A framework for de.ning logics. Journal of the ACM, 40(1):143 184, January 1993. \n[9] Robert Harper and Frank Pfenning. On equivalence and canonical forms in the LF type theory. ACM Transactions \non Computational Logic, 6(1), 2005. [10] Tom Murphy, VII. Modal Types for Mobile Code. PhD thesis, Carnegie \nMellon University, School of Computer Science, Pittsburgh, Pennsylvania, May 2008. [11] Aleksandar Nanevski, \nFrank Pfenning, and Brigitte Pientka. A contex\u00adtual modal type theory. ACM Transactions on Computational \nLogic, 9(3), 2008. [12] Peter W. O Hearn and David J. Pym. The logic of bunched implica\u00adtions. Bulletin \nof Symbolic Logic, 5(2), 1999. [13] Frank Pfenning. Structural cut elimination in linear logic. Techni\u00adcal \nReport CMU-CS-94-222, Carnegie Mellon University, School of Computer Science, December 1994. [14] Frank \nPfenning and Rowan Davies. A judgmental reconstruction of modal logic. Mathematical Structures in Computer \nScience, 11(4):511 540, 2001. [15] Frank Pfenning and Conal Elliott. Higher-order abstract syntax. In \n1988 SIGPLAN Conference on Programming Language Design and Implementation, pages 199 208, Atlanta, Georgia, \nJune 1988. [16] Frank Pfenning and Carsten Sch\u00a8urmann. Twelf User s Guide, Version 1.4, 2002. Available \nelectronically at http://www.cs.cmu.edu/ ~twelf. [17] Jeff Polakow. Ordered Linear Logic and Applications. \nPhD thesis, Carnegie Mellon University, School of Computer Science, Pittsburgh, Pennsylvania, August \n2001. [18] Jeff Polakow and Frank Pfenning. Natural deduction for intuitionistic non-commutative linear \nlogic. In 1999 International Conference on Typed Lambda Calculi and Applications, volume 1581 of Lecture \nNotes in Computer Science, L Aquila, Italy, April 1999. Springer. [19] Alex Simpson. The Proof Theory \nand Semantics of Intuitionistic Modal Logic. PhD thesis, University of Edinburgh, 1994. [20] Roberto \nVirga. Higher-Order Rewriting with Dependent Types. PhD thesis, Carnegie Mellon University, School of \nComputer Science, Pittsburgh, Pennsylvania, 1999.   \n\t\t\t", "proc_id": "1863543", "abstract": "<p>We present a technique for higher-order representation of substructural logics such as linear or modal logic. We show that such logics can be encoded in the (ordinary) Logical Framework, without any linear or modal extensions. Using this encoding, metatheoretic proofs about such logics can easily be developed in the Twelf proof assistant.</p>", "authors": [{"name": "Karl Crary", "author_profile_id": "81100253026", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2338172", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863565", "year": "2010", "article_id": "1863565", "conference": "ICFP", "title": "Higher-order representation of substructural logics", "url": "http://dl.acm.org/citation.cfm?id=1863565"}