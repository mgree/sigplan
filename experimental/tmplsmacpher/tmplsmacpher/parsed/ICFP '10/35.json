{"article_publication_date": "09-27-2010", "fulltext": "\n Instance Chains: Type Class Programming Without Overlapping Instances J. Garrett Morris Mark P. Jones \nPortland State University {jgmorris,mpj}@cs.pdx.edu Abstract Type classes have found a wide variety \nof uses in Haskell programs, from simple overloading of operators (such as equality or ordering) to complex \ninvariants used to implement type-safe heterogeneous lists or limited subtyping. Unfortunately, many \nof the richer uses of type classes require extensions to the class system that have been incompletely \ndescribed in the research literature and are not universally accepted within the Haskell community. This \npaper describes a new type class system, implemented in a prototype tool called ilab, that simpli.es \nand enhances Haskell\u00adstyle type-class programming. In ilab, we replace overlapping in\u00adstances with a \nnew feature, instance chains, allowing explicit al\u00adternation and failure in instance declarations. We \ndescribe a tech\u00adnique for ascribing semantics to type class systems, relating classes, instances, and \nclass constraints (such as kind signatures or func\u00adtional dependencies) directly to a set-theoretic model \nof relations on types. Finally, we give a semantics for ilab and describe its implementation. Categories \nand Subject Descriptors D.3.2 [Programming Lan\u00adguages]: Language Classi.cations Applicative (functional) \nlan\u00adguages; F.3.3 [Logics and Meanings of Programs]: Studies of Pro\u00adgram Constructs Type structure General \nTerms Design, Languages Keywords Quali.ed types, Type classes, Overlapping instances, Fucntional dependencies, \nHaskell 1. Introduction Type classes are a widely used, studied, and extended feature of the Haskell \nprogramming language. Some extensions, such as multi\u00adparameter type classes, functional dependencies, \nand type func\u00adtions, have been extensively studied and debated. In contrast, the overlapping instances \nextension has received relatively little atten\u00adtion, despite its use in several interesting examples \nof type-level programming. One example of overlapping instances is the smart construc\u00adtors in Wouter \nSwierstra s solution to the expression problem in Haskell [18]. We discuss this example in detail in \nSection 2.2.2, but preview that discussion here. His solution uses a coproduct con- Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 10, September 27 29, \n2010, Baltimore, Maryland, USA. Copyright &#38;#169; 2010 ACM 978-1-60558-794-3/10/09. . . $10.00 structor \nt:+:u and a subtyping relation f:<:g, which is im\u00adplemented with the following overlapping instance declarations: \ninstance f :<:f instance f :<: (f :+: g) instance f :<:h . f:<: (g :+: h) The restrictions on overlapping \ninstances in Haskell constrain the use of this relation in several ways. Most signi.cantly, :<: only \nrecurses on the right-hand side of a :+:, limiting its use to list\u00adlike (rather than tree-like) coproducts. \nThere is also an unresolv\u00adable overlap between the .rst and third instances. This overlap causes Hugs, \none implementation of Haskell, to reject the instances outright, and will cause GHC, another Haskell \nimplementation, to issue type errors for some otherwise-valid predicates (see Sec\u00adtion 2.2.2 for more \ndetails). These issues are typical of those encountered by Haskell pro\u00adgrammers using overlapping instances. \nWe argue that overlapping instances lack modularity, lack speci.cation, and that they signi.\u00adcantly complicate \nreasoning about type-level programming. This paper proposes an alternative approach to type-class pro\u00adgramming, \nreplacing overlapping instances with a new feature called instance chains. Using instance chains, we \ncould rewrite Swierstra s subtyping example as: instance f :<:f else f :<: (g :+: h) if f :<:g else f \n:<: (g :+: h) if f :<:h else f :<: g fails Our version expresses the alternation between the three instances \ndirectly instead of relying on the overlapping instances mechanism. As a result, it recurses on both \nsides of the :+: operator, and re\u00adsolves the overlap between the .rst and third instances. We can also \nclose the de.nition of :<: in the last line of the declaration. This example highlights the major features \nof instance chains: explicit alternation within instance declarations, and explicit failure in both predicates \nand instance declarations. We argue that reasoning about programs with instance chains is simpler than \nreasoning about pro\u00adgrams with overlapping instances despite the additional syntax. This paper proceeds \nas follows. Section 2 describes type classes and some frequently used extensions. In the process, we \ndevelop an intuitive semantics for type classes (following the lead of Jones and Diatchki [7]). We then \nexamine several interesting examples of type-class programming that use overlapping instances and func\u00adtional \ndependencies. We identify places where existing type-class programming techniques are unclear or could \nbe improved. Section 3 describes the type class system implemented by our prototype tool ilab. In designing \nilab, we identi.ed some us\u00adage patterns that are implemented in Haskell using overlapping in\u00adstances, \nand made those patterns expressible directly, simplifying coding and removing the need for overlapping \ninstances. The key features of ilab are: instance chains, allowing programmers to ex\u00adpress alternation \ndirectly in instance declarations; and explicit fail\u00adure, allowing programmers to de.ne and test when \npredicates do not hold. We explain these features and their consequences. We re\u00advisit the earlier examples \nof type-class programming, showing how to simplify and improve them using instance chains.  Of course, \nthis is not the .rst attempt to simplify type-level programming in Haskell: much entertainment has resulted \nfrom the odd or incompletely speci.ed interaction of otherwise-reasonable extensions to the Haskell type-class \nsystem. To avoid repeating this experience, Section 4 formalizes a set-theoretic semantics for type classes. \nWe highlight several places where instance chains simplify reasoning about type classes compared to overlapping \ninstances. We also state properties, such as soundness and completeness, that link the implementation \nof a type-class system to its semantics, and provide a basis for programmers to reason about type-class \nprograms. In the process, we connect the semantics of type classes to Jones theory of quali.ed types. \nSection 5 discusses the implementation of ilab and describes the algorithms that ilab uses to validate \nsets of instances and to (attempt to) prove predicates. Section 6 discusses related work, while Section \n7 discusses future work and concludes. 2. Background 2.1 Type classes Type classes [21] provide an extensible \nmechanism for giving prin\u00adcipal types to overloaded functions. For instance, we can de.ne a type class \nfor equality: class Eq t where (==) :: t . t . Bool The type of == is now constrained, or quali.ed, by \na predicate mentioning the Eq class: (==) :: Eq t . t . t . Bool We can explain this quali.ed polymorphic \ntype using set notation. The == function can assume types from the set {t . t . Bool | t . Eq} We conclude \nthat one should view type classes as speci.cations of sets of types, not just as tools for typing overloaded \nfunctions. Type classes are populated by instance declarations. If we had a primitive integer comparison \nfunction primIntEq, then we could write an Eq instance for Int as follows instance Eq Int where x == \ny = primIntEq x y Instance declarations themselves may use quali.ed polymorphism. For example, the de.nition \nof Eq for lists reads: instance Eq t . Eq [t] where [] == [] = True (x:xs) == (y:ys) = x == y &#38;&#38; \nxs == ys _ == _ = False As type classes correspond to sets of types, instance declarations correspond \nto assertions about those sets. The .rst declaration asserts that Int . Eq. The second asserts that t \n. Eq =. [t] . Eq. Together, these assertions require that Eq include the subset {Int, [Int], [[Int]],... \n} of the set Type of all types. There have been numerous proposals to extend Haskell s class system. \nIn the next sections, we discuss those relevant to our work. 2.1.1 Multi-parameter type classes Although \nWadler and Blott [21] focus on type classes with a single parameter (which correspond to sets of types \nwith associated op\u00aderators), they proposed that type classes could also apply to more than one parameter. \nFor example, the multi-parameter type class class Elems c e where ... could describe the relation that \nthe elements of (collection) c have type e. This class might be populated for lists: instance Eq t . \nElems [t] t where ... and for sets: instance Ord t . Elems (Set t) t where ... For this example, we assume \nSets are implemented by balanced binary trees, and so a type t must have an ordering before we can construct \na value of type Set t. The type class Ord captures this constraint. Just as single-parameter type classes \ncan be interpreted as sets of types, multi-parameter type classes can be interpreted as rela\u00adtions on \ntypes (i.e., sets of tuples of types). Assuming the instances for Eq above, and that we have an instance \nof Ord for Int, we would expect Elems to include the following subset of Type \u00d7 Type {([Int], Int), (Set \nInt, Int), ([[Int]], [Int]), ... } 2.1.2 Functional dependencies One of the operations of the Elems \nclass might be an insert function with type insert :: Elems c e . e . c . c Using it, we could write \nthe function insert2 c = insert True (insert x c) to insert both the Boolean constant True and the character \nconstant x into the collection c. This function has the type: (Elems c Bool, Elems c Char) . c . c While \none could imagine a collection type c that satis.ed both quali.ers, we may wish to require homogeneity. \nThat constraint can be expressed by adding a functional dependency [6, 10] to the de.nition of Elems: \nclass Elems c e | c . e where ... This requires that the value of parameter c uniquely determines the \nvalue of parameter e, or, equivalently, that for any two predicates Elem c e and Elem c e , if c = c \n, then e = e . This would make the de.nition of insert2 above a type error, because it would require \nthat Char = Bool The functional dependency is a property of the relation itself, not of the constraints \non it; for example, the Elems class from Section 2.1.1 had this functional dependency, even though we \nhad not yet added the constraint. However, were we to add an instance instance Elems [Int] Char where \n... that interpreted characters by their ASCII values, then both the predicates Elems [Int] Int and Elems \n[Int] Char would hold and the relation would no longer have the functional dependency. With the functional \ndependency constraint on the Elems class, a program could not contain both this instance and the instance \nElems [t] t from the previous section.  2.1.3 Overlapping instances Two instances overlap if they could \napply to the same predicate. For example, consider a type class C with the following instances: instance \nC (a, [b]) where ... instance C ([a], b) where ...  Either of these instances could be used to solve \nthe predicate C ([a], [b]). However, the compiler has no guarantee that the class methods are implemented \nequivalently for both instances, and so a program with both instances may have multiple distinct inter\u00adpretations. \nTo avoid this kind of (potential) incoherence, Haskell 98 prohibits any overlap between instances. This \nrestriction is sometimes inconvenient. The Show class in\u00adcludes types whose values have a textual representation: \nclass Show t where show :: t . String Haskell s syntax for lists surrounds the elements with brackets \nand separates them with commas for example, [1,2,3]. We could write a Show instance that used this syntax: \ninstance Show t . Show [t] where ... Haskell also has special syntax to allow lists of characters to \nbe written as strings, as in \"string\", for example. We might like to add a special instance of Show to \nhandle this case: instance Show [Char] where ... but that would not be allowed because this instance \noverlaps with the more general instance. Peyton Jones et al. [13] describe an extension to the Haskell \ntype-class system that allows instances to overlap as long as one of them is more speci.c than the other, \nusing substitutions to make the notion of more speci.c precise. Given two instances instance Q1 . P1 \nwhere ... instance Q2 . P2 where ... the instances overlap if P1 ~ P2 (i.e., P1 uni.es with P2) The .rst \ninstance is more speci.c than the second if there is a substitution S such that P1 = S P2 but there is \nno substitution T such that T P1 = P2 . This extension would allow the two instances of Show, but would \nprohibit the two instances of C at the beginning of this section because neither is a substitution instance \nof the other. A full description of how overlapping instances affect the se\u00admantics of type classes is \nbeyond the scope of this paper; however, we do mention some of the dif.culties in Section 2.3.  2.2 \nType-class programming This section describes two (simpli.ed) examples from the literature that use the \nextensions of the Haskell type-class system described earlier. We focus on examples that use overlapping \ninstances be\u00adcause of their relative complexity in both implementation and se\u00admantics. We will return \nto these examples in Section 3 to demon\u00adstrate instance chains. 2.2.1 Type-level arithmetic In this section, \nwe describe the implementation of several mathe\u00admatical operations at the type level using Peano arithmetic \nand type classes, based on work by Thomas Hallgren [2]. We begin by representing Peano numbers at the \ntype level using two data types, one for zero and one for successor. We do not provide value-level constructors \nfor these types because we only intend to use them at the type level. data Z; data S n Similarly, we \nwill introduce types to represent Boolean values: data T; data F Hallgren de.nes a class Lte to implement \nthe = relation at the type level as follows: class Lte m n b | mn . b instance Lte Z (S n) T instance \nLte (S n) Z F instance Lte m n b . Lte (S m) (S n) b As indicated by the functional dependency, Hallgren \nhas actually de.ned the characteristic function of the = relation, using addi\u00adtional type constructors \nT and F to represent the corresponding Boolean values. This allows him more .exibility in using the Lte \nclass because he can now determine, not only when one number is less than or equal to another, but also \nwhen that property fails. Hallgren goes on to use the Lte class to de.ne insertion sort at the type level. \nHowever, the Haskell implementation that he was using (Hugs 98) could not solve the type constraints \nin his insertion sort example. His code works in ilab without modi.cation, so we do not reproduce it \nhere. Instead, we try to de.ne another operation on Peano numbers: greatest common divisor. This is not \nan arbitrary choice: for ex\u00adample, work on typing low-level data structures in Haskell has relied on \na type-level GCD operator [1]. We begin by de.ning a (bounded) subtraction operation: class Subt m n \np | mn . p --p = m-n instance Subt Z n Z instance Subt m Z m instance Subt m n (S p) . Subt m (S n) p \nWe use this to implement Euclid s algorithm for GCD: class Gcd m n p | mn . p --p = gcd(m,n) instance \nGcd m m m instance (Lte n m T, Subt m n m , Gcd m n p) . Gcd m n p instance (Lte n m F, Subt n m n , \nGcd m n p) . Gcd m n p However, both GHC and Hugs reject this trio of instances. While it is true that \nthe conclusions of the second and third instances (trivially) unify, there is no actual overlap between \nthose instances. For both instances to apply to the same predicate Gcd m n p, both the predicates Lte \nn m T and Lte n m F would have to hold. However, the functional dependency in Lte makes it impossible \nfor both predicates to hold.  2.2.2 The expression problem In this section, we return to the example \npresented in the introduc\u00adtion. We describe its context, a Haskell solution to the expression problem \nthat relies on multi-parameter type classes and overlapping instances, and highlight the dif.culties \nthese extensions introduce. The expression problem [20] is a benchmark for comparing language expressiveness \nand modularity. The starting point is to de.ne, by cases, a data type for arithmetic expressions, as \nwell as an operation over that data type. For example, the data type might contain integer constants \nand addition, and the operation might be evaluation, consuming an expression and generating an integer \nvalue. The challenge is to extend the data type with both a new case (such as multiplication) and a new \noperation (such as pretty-printing). This extension should be done without changing or recompiling the \noriginal code, and without losing static type safety. Though de.nition of types by cases is standard \nin both func\u00adtional and object-oriented languages, the expression problem is usually challenging in either \nparadigm. In many functional lan\u00adguages, adding a new case to an existing data type requires chang\u00ading \nthe de.nition of the data type and all the functions that use it; in many object-oriented languages, \nadding a new operation requires changing the de.nition of the base class and its subclasses. Wouter Swierstra \nproposed a Haskell solution to the expression problem in Data Types ` a la Carte [18]. His solution works \nby constructing coproducts of functor type constructors (using a type constructor :+:), injecting values \ninto these coproducts (using a :<: type class), and then de.ning operations over coproducts using one \ntype class per operation. We highlight some details that arise in the construction of coproducts.  The \ntype constructor f:+:g represents the coproduct of the functor type constructors f and g, and is de.ned \nsimilarly to the standard Haskell Either type: data (f :+: g) e = Inl (f e) | Inr (g e) The type constructors \nfor various possible expressions will also be functors but the use of functors is irrelevant to the remainder \nof this presentation. Suppose that we have a type constructor Const for integer constants and a type \nconstructor Add for additions. The type of an expression containing either constants or sums could be \nbuilt using the coproduct Const :+: Add. Constants would be in\u00adjected into the expression type using \nthe Inl value constructor, and sums using the Inr constructor. We could extend the expression type by \nadding a new type to the coproduct. For instance, if the type Multiply represents multiplications, we \ncould construct ex\u00adpressions with the coproduct Const :+: (Add :+: Multiply). We would still inject constants \ninto these new expressions using Inl, but additions would be injected using Inl .Inr and multipli\u00adcations \nusing Inr .Inr. It is somewhat tiresome to construct different injection func\u00adtions for each type in \neach possible coproduct. Swierstra alleviates this by de.ning a type class f:<:g to indicate that there \nis an injection from fe to ge for any type e. The class is de.ned by: class f :<: g where inj :: f e \n. ge Swierstra populates this class using three instances. The .rst says that :<: is re.exive, with the \nobvious injection: instance f :<: f where inj = id (A) The second instance checks the left-hand side \nof the :+: type: instance f :<: (f :+: g) where inj = Inl (B) The .nal instance recurses on the right \nside of the :+: type: instance (f :<: h) . f:<: (g :+: h) (C) where inj = Inr . inj Swierstra comments \non the overlap between instances (B) and (C): because (B) is a substitution instance of (C), predi\u00adcates \nwill be checked against (C) only if they fail to match (B), and the set of instances will behave as expected. \nMore interest\u00adingly, instances (A) and (C) overlap at predicates of the form (f :+: g) :<: (f :+: g) \nbut neither is a substitution instance of the other. As a result, Hugs will reject this set of instances \nout\u00adright for having unresolved overlap. GHC accepts the instances, but attempting to use the inj function \nwith such a predicate will result in a type error. This error occurs at the usage of inj, not at the \nambiguous overlap in the de.nition of :<:. Although the :+: type constructs a coproduct of types, the \nsubtype relation :<: cannot fully exploit it because the recursive case only descends the right-hand \nside. Thus, while the predicate Sum :<: (Const :+: (Sum :+: Product)) holds, the predicate Sum :<: ((Const \n:+: Sum) :+: Product) does not, because it requires recursion on the left-hand side of the :+: operator. \nThis forces a list-like use of the :+: con\u00adstructor; for instance, if t and u are already coproducts, \nwe would not be able to inject components of t into the coprod\u00aduct t:+:u. To .x this, we could replace \ninstance (B) with instance (f :<: g) . f:<: (g :+: h) (B-2) where inj = Inl . inj However, (B-2) and \n(C) are each substitution instances of the other. The Haskell compiler no longer has a way to order these \ninstances, and so a program containing (B-2) and (C) would be rejected.  2.3 Challenges Haskell programmers \nhave three main challenges when using over\u00adlapping instances. We summarize them here. Lack of modularity. \nIn Data Types a la Carte , the three in\u00ad `stances of :<: are presented together, and in order from most \nto least speci.c. However, Haskell imposes no requirement that the instances be presented together, or \nin any particular order, or even in the same module. A programmer has no way to know whether a particular \ninstance will be overlapped before it is used. In fact, GHC only attempts to determine which instance \nis most speci.c at call sites, and so will accept ambiguously overlapping instances that is, cases where \ntwo instances apply to the same predicate and neither is more speci.c than the other and not re\u00adport \nan error unless the programmer attempts to use an overloaded function at one of the ambiguous types. \nAmbiguity could be intro\u00adduced in a library but not discovered until some client of the library uses \none of the types at which the instances are ambiguous. Logical consistency. The syntax of instance declarations \nin Haskell suggests logical implication. For example, the Eq instance for lists begins: instance Eq t \n. Eq [t] and can be read as an implication t . Eq =. [t] . Eq. Even in Haskell 98, this interpretation \ndoes not completely cover the meaning of the declaration. Because Haskell 98 instances cannot overlap, \nthe only way that [t] can be in Eq is for t to be in Eq, so a more accurate interpretation would be t \n. Eq .. [t] . Eq. The meaning of overlapping instances is more obscured. A par\u00adticular instance only \napplies if a more speci.c instance could not be found. Furthermore, if the preconditions of the most \nspeci.c instance are not met, the compiler does not check to see if less speci.c instances might be applicable \nbut instead immediately is\u00adsues an error. As a result, it is impossible to interpret the meaning of an \nindividual instance declaration without referring to the other instances in the program. While the syntax \nof instances still sug\u00adgests a logical interpretation, applying that interpretation gives an incomplete \nand potentially incorrect meaning. Lack of speci.cation. Peyton Jones et al. [13] describe some is\u00adsues \nintroduced by overlapping instances. However, they do not consider the interaction of overlapping instances \nwith some other type-class system features, such as improvement. Research on functional dependencies \nin class systems [6, 7, 17] generally does not mention overlapping instances, and recent work by Schrijvers \net al. [14] related to type classes explicitly excludes overlap. Without a speci.cation to de.ne the \ncorrect behavior, code must be tailored to a particular implementation. For example, Kiselyov et al. \n[9] discover signi.cant incompatibilities between GHC and Hugs and end up tailoring their code to GHC. \nSimilarly, Swierstra s :<: instances are not accepted by Hugs. 3. Features of the ilab type-class system \nAs part of the High Assurance Systems Programming1 project at Portland State University, we are designing \na dialect of Haskell (called Habit) for use in low-level systems programming tasks. 1 http://hasp.cs.pdx.edu \n One of our goals is to preserve and expand the possibilities of type-class programming while simplifying \nthe underlying model of type classes. As background to this effort, we surveyed type-level programming \nin Haskell, using both the existing research literature and the Hackage database of Haskell libraries \nas resources [11]. Based on the results of our survey, we have developed the ilab type-class system and \nprototype implementation. We use ilab to experiment with features of the Haskell type-class system; it \nis not a complete implementation of either Haskell or Habit type classes, but implements features central \nto both. Despite their history, the features of ilab are not tied to other features of Habit; they could \njust as well be applied to Haskell or other Haskell dialects. The remainder of this section describes \nthe features of ilab and shows how they simplify and improve the examples from Section 2.2. 3.1 Design \nof the ilab type-class system The ilab class system is based on the Haskell 98 class system, extended \nwith overlapping instances and functional dependencies. However, rather than support overlapping instances \nin ilab, we added new features based on the usage patterns implemented using overlapping instances in \nHaskell. These features support and extend Haskell-style type-level programming while avoiding the complex\u00adity \nthat would be introduced by overlapping instances. For the remainder of the paper, we use Habit instance \nsyntax for examples using ilab features, and continue to use Haskell syn\u00adtax for examples that do not \nrely on any ilab-speci.c functionality. The Habit syntax for instance declarations is given by the following \nBNF-like grammar, where non-terminals have initial caps, optional elements are surrounded by brackets, \nand optional repeatable ele\u00adments are surrounded by braces. Pred ::= ClassName Type {Type} [fails] Context \n::= Pred {, Pred} Clause ::= Pred [if Context] [where Decls] Chain ::= instance Clause {else Clause} \nThere are, of course, additional constraints on instance chain declarations all the clauses in a chain \nmust refer to the same class, and fails clauses cannot contain method de.nitions as well as other restrictions \nas in Haskell. Habit s syntax differs from that of Haskell 98 in three ways: 1. Predicates may include \nthe fails keyword, indicating that the given type tuple is not in the named class; 2. Clauses may be \nchained together using the else keyword, al\u00adlowing a programmer to indicate explicit alternation; and, \n 3. The instance being de.ned appears to the front of the instance declaration, calling attention to \nit even in the presence of long or complex preconditions.  Habit uses additional features, such as the \nfunctional notation pro\u00adposed by Jones and Diatchki [7]. For example, the Haskell instance declaration: \ninstance (Lte n m T, Subt m n m , Gcd m n p) . Gcd m n p can be expressed in Habit as: instance Gcd m \nn = Gcd (Subt m n) n if Lte n m T Because it is a prototype tool and functional notation is orthogonal \nto our other goals, ilab does not support rewriting passes such as those used to implement functional \nnotation. In ilab we would have to use the following version instead: instance Gcd m n p if Lte n m T, \nSubt m n m , Gcd m n p This is the form we will use for the remainder of the paper. Next, we explore \nthe new features introduced by ilab, and some of their consequences. 3.1.1 Explicit alternation Many \nof the examples we found use overlapping instances to im\u00adplement alternation between instances. This \napproach is fragile, ob\u00adscures the programmer s intention, and limits the algorithms the programmer can \nencode. In ilab, a class can be populated by multiple, non-overlapping instance chains, where each chain \nmay contain multiple clauses (separated by the keyword else). Unlike between chains, we make no limitation \non overlap between the clauses within a single chain. During instance selection, the clauses within an \ninstance chain are checked in order. Using instance chains allows clearer expression of programmer intentions \nand simpli.es the encoding of algorithms that would be complex or impossible to express with overlapping \ninstances. For example, in Section 2.2.2, we presented the class :<: and the three instances used to \npopulate it. These instances implement a simple conditional by making the alternative clause more general \nthan the consequent. ilab allows a more direct expression of the conditional: instance f :<: f where \n... else f :<: (f :+: g) where ... else f :<: (g :+: h) if f :<: h where ...  3.1.2 Explicit failure \nSome of the examples we found attempted to encode failure of the instance search [9]. However, lacking \na mechanism to encode failure directly, the examples used a combination of the class and module system \nto prevent the user from solving certain constraints. While this approach works, it leads to confusing \nerror messages and cannot be used as a building block for more complex instance schemes. Making failure \nexplicit in both predicates and instance declarations signi.cantly simpli.es coding these patterns. By \nde.ning the characteristic function of the = relation instead of the relation itself (as discussed in \nSection 2.2.1), Hallgren could express both properties of the form m = n and \u00ac(m = n). With explicit \nfailure, we can de.ne the = relation directly: instance Lte Z n else Lte (S m) (S n) if Lte m n else \nLte m n fails Because we implement the relation directly, we no longer need the third parameter to the \nLte class or the functional dependency. One use of explicit failure is in the de.nition of closed classes. \nFor example, at one point [16], the crypto package de.ned a class AESKey and three instances for types \nWord128, Word192, and Word256, the only valid key lengths for AES encryption. To prevent users from adding \ninvalid types to the class, AESKey was not exported. As a consequence, users could not write type signatures \nsuch as: AESKey a . a . ByteString . ByteString In ilab, we can close the AESKey class with the following \ninstance chain: instance AESKey Word128 else AESKey Word192 else AESKey Word256 else AESKey a fails No \nadditional instances of AESKey can be added because they would overlap with the (last clause of the) \nexisting instance, so there is no need to hide the class.  3.1.3 Backtracking search Haskell instance \nsearch never backtracks: if no two instance heads unify, then no predicate could be solved by more than \none instance. However, combined with overlapping instances, this complicates reasoning about instances. \nEven if an instance could apply to a predicate, it will not be checked if a more speci.c instance exists \nanywhere in the program, and failure to prove the preconditions of the most speci.c instance causes instance \nsearch to fail rather than to attempt to use less speci.c instances. ilab instance search backtracks \nwhen it can disprove the pre\u00adcondition of an instance (either because of a fails clause or because of \na functional dependency). When backtracking, ilab checks clauses within an instance chain in order. The \norder in which ilab checks instance chains is unimportant because clauses in different chains are not \nallowed to overlap.  3.2 Type-class programming, revisited In this section, we demonstrate how the examples \nfrom Section 2.2 are changed and improved using the features of ilab. Section 2.2.1 includes several \nexamples of implementing type\u00adlevel arithmetic using type classes. The .rst example is the char\u00adacteristic \nfunction for the = relation. Section 3.1.2 described how this example can be improved using instance \nchains. Next, we at\u00adtempted to de.ne a Gcd class. We de.ne the class as before, but populate it with \na single instance chain that uses the Lte relation: 1 instance Gcd m m m 2 else Gcd m n p 3 if Lte n \nm, Subt m n m , Gcd m n p 4 else Gcd m n p 5 if Lte n m fails, Subt n m n , Gcd m n p 6 else Gcd m \nn p fails As the clauses overlap, we have combined them into an instance chain. We also add the clause \nat line 6, closing the Gcd class. Section 2.2.2 describes a solution to the expression problem. The solution \nrelies on a type constructor :+: to construct coprod\u00aducts of types, and a type class :<: for subtypes. \nHowever, the im\u00adplementation of :<: is asymmetric it recurses only on the right\u00adhand side of a :+: type. \nWe can implement it symmetrically: 1 instance f :<:f 2 where inj = id 3 else f :<: (g :+: h) fails if \nf :<: g, f :<:h 4 else f :<: (g :+: h) if f :<:g 5 where inj = Inl . inj 6 else f :<: (g :+: h) if f \n:<:h 7 where inj = Inr . inj 8 else f :<: g fails Lines 1-2 provide a base case, and correspond to instance \n(A) in the original implementation. Line 8 serves as the other base case. We explicitly close the class \nto ensure that we have evidence for backtracking in the middle clauses of the instance. Lines 6-7 recurse \non the right-hand side of a :+: constructor, and correspond to instance (C). Lines 4-5 replace instance \n(B). Unlike the original implementation, this clause recurses on the left-hand side of the :+: constructor. \nIf both f:<:g and f:<:h hold, ilab would select the left injection because of the ordering of the respective \nclauses. This behavior may be surprising to programmers, so we add the additional (but optional) clause \nat Line 3 to rule out this kind of injection completely. 4. A semantics for type classes The history \nof Haskell type-class research is littered with proposals to extend, enhance, or simplify writing type-class \nprograms. Some of these proposals, while sensible as proposed, have led to unex\u00adpected interactions with \nother features, or have proven dif.cult for programmers to understand. We hope to avoid a similar fate \nfor instance chains by de.ning a semantics for type classes and for instance chains, providing a basis \nfor understanding their use and implementation and a foundation for future research in type classes. \nPrevious work has focused on translating programs in a lan\u00adguage with type classes into programs in a \nlanguage without type classes (for example, by introducing dictionaries of type-speci.c method implementations \nand transforming quali.ers into extra pa\u00adrameters [21]). This approach con.ates the meaning of type classes \nwith their implementation, making it dif.cult or impossible to de\u00ad.ne properties of type classes without \nreference to a particular im\u00adplementation, or to prove properties of the implementation itself. This \ncon.ation is particularly unfortunate when it comes to under\u00adstanding the interaction of type-class features \nor when the imple\u00admentation itself is suspect, such as in the interaction between func\u00adtional dependencies \nand overlapping instances. This section elaborates the intuitive understanding of type classes as relations \non types to give a full semantics for ilab type classes. We follow a standard approach from mathematical \nlogic: .rst, we characterize models of type classes. Then, we de.ne a property that holds when a given \nmodel describes a particular type\u00adclass program; we use this property to capture properties of imple\u00admentations \nsuch as soundness or completeness. This approach does not attempt to capture the details of type class \nimplementations such as substitutions, improvement, simpli.cation, etc. Rather, it describes the meaning \nof type classes and provides a basis both for reasoning about programs that use type classes and for \nevaluating type-class implementations. 4.1 Modeling type classes Single parameter type classes, such \nas Eq or Ord, are naturally mod\u00adeled by sets of types. Let Type refer to the set of all types. Writing \nM(Eq) for the model of the Eq class, we can say that M(Eq) . Type or, equivalently, M(Eq) . P(Type). \nThis approach extends to multi-parameter type classes by using relations on types instead of sets of \ntypes. Just as (the models of) Eq and Ord are subsets of Type, (the model of) a class like Elems (see \nSection 2.1) is a subset of Type \u00d7 Type, or equivalently, M(Elems) . P(Type2). A three\u00adparameter class \nwould be modeled by an element of P(Type3), and so forth. The number of arguments to a class is called \nits arity, and we will write arity(C) (where C ranges over the set of class names ClassName) to refer \nto the arity of class C. For example, we have arity(Eq)=1 and arity(Elems)=2. Using the arity function, \nwe can write a general rule that captures the examples so far: for a class C, we have M(C) . P(Typearity(C)) \nA program will typically contain a number of type classes. To model an entire program, we use a function \nfrom ClassName to models of the individual classes. We can then describe a model of a program as a dependently \ntyped function M :(C : ClassName) . P(Typearity(C)) This is not the only possible structure for M; we \nwill discuss some of the design choices further when describing the handling of constraints. Next, we \nde.ne a family of relations M |= x that hold if M models x . We develop this family of relations bottom-up \n, starting from single predicates and working towards full programs. Predicates. Predicates are the simplest \nparts of a type-class sys\u00adtem. We de.ne predicates with the following grammar f ::= holds | fails Flags \np ::= C Tt f Predicates  e@Tt = e  (SP . C (S T.) f ); a@Tt if .S. dom(S) . Tx . S T. = Tt ((.Tx. P \n. C .Tf ); a)@Tt = a@Tt otherwise Figure 1. The restriction of an axiom a to the type tuple Tt Here \nTt is an (arbitrary-size) tuple of types. As Haskell predicates cannot express failure, the Haskell predicate \nCTt is equivalent to the ilab predicate C Tt holds. Predicates correspond directly to the model of type \nclasses: M |=(C Tt holds) .. Tt . M(C) M |=(C Tt fails) .. Tt /. M(C) The presence of .ags within predicates \nmakes possible a simple syntactic de.nition of the negation of a predicate: C Tt holds = C Tt fails C \nTt fails = C Tt holds Contexts. Contexts, or lists of predicates, occur frequently: P ::= Tp Contexts \nAs above, Tp is an arbitrary-size tuple of predicates. We model con\u00adtexts as conjunctions. A context \nis modeled if all of its predicates are modeled: M |= P .. .p . P. M |= p We write the negation of a \ncontext P as P. The negation of a context is modeled if the negation of one of its predicates is modeled: \nM |= P .. .p . P. M |= p Axioms. We turn to the axioms of ilab, instance chains. The syntax of instance \nchains is given by: a ::= (.Tx. P . p); a | e Axiom schemes Because instance chains may contain polymorphic \nclauses, we re\u00adfer to them as axiom schemes. Rather than attempting to model axiom schemes directly, \nwe .rst specialize them to concrete ax\u00adioms, removing any polymorphism in the process. Intuitively, we \nspecialize an axiom scheme a by enumerating each type tuple that matches the arity of the class mentioned \nin a, and then attempting to restrict each clause to that tuple. Some examples may clarify specialization. \nConsider the in\u00adstance chain instance C Int else C Bool else D t . Ct which corresponds to the axiom \n(() . C Int holds) ; (() . C Bool holds); (.t. (D t holds) . C t holds); e where we have omitted empty \nquanti.ers. Note that the last clause contains quali.ed polymorphism. If our set of types were limited \nto {Bool, Int, Float}, we would generate the following concrete axioms from this instance chain: (() \n. C Int holds); ((D Int holds) . C Int holds); e (() . C Bool holds); ((D Bool holds) . C Bool holds); \ne ((D Float holds) . C Float holds); e Note particularly the lack of quanti.ers: there is no polymorphism \nin concrete axioms. Alternatively, consider the instance chain instance Eq t . Eq [t] With the type constructors \n{Int, []}, where [] constructs the list type, we would generate the following concrete axioms ((Eq Int \nholds) . Eq [Int] holds); e ((Eq [Int] holds) . Eq [[Int]] holds); e . . . We begin formalizing specialization \nby de.ning the syntax of concrete axioms, which follows the syntax of axiom schemes closely, but omits \nthe quanti.ers. . ::= (P . p); . | e Concrete axioms Whether e denotes a concrete axiom or axiom scheme \nshould be obvious from context. Next, we de.ne the restriction of an axiom a to a particular type tuple \nTt , written a@Tt . This operation removes the polymorphism from a by attempting to instantiate the type \nvariables in each clause so that the instance head matches Tt ; when that is not possible, the clause \nis dropped. The de.nition of a@Tt is shown in Figure 1. (We refer to the variables mentioned by a substitution \nS as dom(S), and abuse notation by treating the vector of quanti.ed variables as a set.) We can now give \nthe concrete axioms generated from a given axiom scheme. An empty axiom e generates exactly one concrete \naxiom, also e. If all the clauses in a (non-empty) axiom scheme a are for class C, then the set of concrete \naxioms generated from a is t . Typearity(C) {a@Tt | T} The set of concrete axioms for a given program \nmay be in.nite, but because we can determine whether a concrete axiom was spe\u00adcialized from a particular \naxiom scheme by uni.cation, it is still recursive. We now describe the modeling of concrete axioms. The \nempty axiom is trivially modeled: M |= e The concrete axiom (P . p); . is modeled by the two disjuncts \nthat it represents: if P is modeled, then p must be modeled; alter\u00adnatively, if P is modeled, then . \nmust be modeled: M |= ((P . p); .) .. M |= P =. M |= p . M |= P =. M |= . Axioms correspond to statements \nabout the inclusion or exclu\u00adsion of particular tuples within the model of a class. Other aspects of \ntype-class systems can be modeled as properties of all the tuples. We describe several such properties \nnext. Functional dependencies. Our implementation supports the use of functional dependencies, both to \nconstrain instance declarations and to introduce improvement into the deduction algorithm. Func\u00adtional \ndependencies were originally proposed for class systems as a mechanism to induce improving substitutions \n[6]; these improve\u00adments, in turn, are only valid because of properties of the underly\u00ading relations \n[10]. Here, we formalize functional dependencies as properties of the models of classes. The Elems class \nfrom Section 2.1 class Elems c e | c . e  has a functional dependency stating that the parameter c deter\u00admines \nthe parameter e. We can phrase this with the same language used to describe functions: given two predicates \nElems c e and Elems c e , if c = c then e = e . We generalize the syntax of functional dependency constraints \nas follows: X, Y . N Index sets d ::= C : X . Y Functional dependencies The Elems class would generate \nthe constraint Elems : {0} . {1}, indicating that the 0th parameter of the class determines the 1st parameter. \nThe class: class F t u v | tv . u would generate the constraint F : {0, 2} . {1}. Modeling these constraints \nis a straightforward extension of the single-parameter version given above. M |= C : {X} . {Y} ...Tt, \nT. . M(C). Tt |X = T.|X =. Tt |Y = .T|Y If Tz is a tuple and X is a subset of N, then we write Tz|X to \nrefer to the tuple consisting of those elements ofTz indexed by the elements of X. Appealingly, this \nis exactly the de.nition of a functional dependency used in the theory of relational databases [10]. \nFunctional dependencies are not the only possible use of the constraint mechanism; for example, it could \nalso be used to model class arities, kind signatures, or Haskell-style superclasses. We describe two \nof those applications next. Arities. We have chosen to bake the arity of classes into the de.nition of \nmodels. Alternatively, we could have chosen models over arbitrary sequences of types, with the following \nstructure: M : ClassName . P(Type* ) This de.nition would allow the model of a single class to contain \ntuples of various lengths. We could then enforce separate arity constraints on classes. An arity constraint \nof the form arity(C)= x would require that any tuple in the model of C have length x. We could model \nthis constraint by: M |= arity(C)= x .. .Tt . M(C). length(Tt)= x Note that, unlike the de.nition of \n|= heretofore, this relation ex\u00adpresses a property of all tuples in the model of a class. Kinds. A similar \napproach could be used to capture the kind sig\u00adnature of a type class. Suppose that the type system were \nequipped with some set of kinds ranged over by k, and that, for any kind k, the set Typek . Type, is \nall the types of kind k. In this setting, classes are assigned kind signatures C : Tk where the nth element \nof the kind signature is the kind of the nth argument to the class. Kind signatures are validated by: \nM |= C : Tk .. .Tt . M(C). .i.ti . Typeki Programs. We model (the classes and instances of) a program \nwith a pair A|., consisting of a set of axioms A and a set of con\u00adstraints .. In ilab, the constraint \nset will only contain functional dependencies; however, an application to Haskell or Habit would include \nadditional constraints such as kind signatures, superclass constraints, etc. A program is modeled when \nall of its axioms and all of its dependencies are modeled: M |= A|. .. (.a . A. M |= a) . (.d . .. M \n|= d) These rules are not generative. A given program A|. may have one, many, or no models. A program \nwith con.icting instance declarations has no models. On the other hand, we do not constrain predicates \nthat are not mentioned in the program. For example, if a program contains neither an assertion that C \nBool holds nor an assertion that C Bool fails, then that program could admit (at least) two models: one \nin which Bool . M(C) and another in which Bool ./M(C). We say that A|. is consistent if it has at least \none model. A predicate p is a theorem of A|. if it holds in all models of the program; that is: p is \na theorem of A|. .. (M |= A|.=. M |= p) Informally, a particular implementation of a type-class system \nis sound if it proves only theorems and complete if it proves all theorems. To formalize this, we must \nformalize our notion of the implementation of a type-class system.  4.2 Predicates, evidence and proof \nThe preceding section focusses the meaning of type classes; this section builds upon Jones theory of \nquali.ed types to begin de\u00adscribing their implementation. Jones [4] describes the extension of the polymorphic \n.-calculus with quali.ed types. He uses a notion of evidence to close the gap between the quali.ers in \na type and their implementation in a term. For example, the evidence for a type-class predicate Eq Int \nis a function that implements the equality check for integers, while the evidence for a subtype predicate \nt . tl is a function embedding values of type t into values of type tl. To capture the use of evidence \nin computations, Jones extends the term language of the polymorphic .-calculus with expressions for evidence \nabstraction, application, and construction. For our purposes, we only need to consider evidence construction; \nthe remainder of Jones theory can be applied to ilab intact. Jones represents evidence construction with \na three-place rela\u00adtion P I e : p indicating that e is evidence for predicate p, given evidence for the \npredicates in P. He assumes a set of base axioms such as \u00d8 I Eq Int and Eq t I Eq [t]. We will use an \nalternative relation A|. I e : p that diverges from his in two ways: His set of base axioms corresponds \nto our model of a program, so we augment the evidence relation with the program A|.; and,  We will omit \nthe set of assumptions P, as it is trivial to reintro\u00adduce and will play no further role in our discussion. \nIt would be valuable for implementing features of Haskell beyond the scope of this paper, such as existential \ntypes or GADTs.  Evidence construction does not precisely model the process of proving that a predicate \nexists. There are a number of predicates in ilab that generate no evidence, such as classes without methods \nor negative predicates. However, we do not wish for all negative pred\u00adicates to be trivially provable \nsimply because their evidence can always be constructed. Also, evidence construction involves details \nthat are irrelevant for our purposes, such as the implementations of class methods. To avoid these dif.culties, \nwe will use proof expres\u00adsions instead of evidence. Proof expressions capture the reasoning steps made \nby the deduction algorithm, and there must be a trans\u00adlation from a proof for a predicate p to evidence \nfor p. Proofs may also capture details that are not observable from the generated ev\u00adidence, such as \nrecursion, naming of common subexpressions, etc. To connect differences in proof expressions to differences \nin evi\u00addence, we introduce a notion of equivalence for proof expressions, written p ~pl. We require that, \nif p ~pl, then the evidence gen\u00ad == erated from p is not observably different from the evidence gener\u00adated \nfrom pl. Note that this relation is one-way; it is not likely that p ~ = pl for arbitrary proofs p and \npl that generate observably equiv\u00adalent evidence. Equivalence is a statement only about the evidence \n generated from proofs, not about what they prove; that is: A|. I p : p . = p l =A|. I p l : p. p ~=. \nSection 5 discusses the details of ilab proof expressions and proof equivalence. We will refer to an \nalgorithm for .nding p such that A|. I p : p for given A|. and p as a deduction algorithm. The rest of \nthis section will discuss deduction algorithms in general; Section 5 discusses the particular deduction \nalgorithm implemented in ilab and the details of its proof expressions. We can now formalize the notions \nof soundness and complete\u00adness. A deduction algorithm is sound if it only proves predicates that are \ntheorems: .p. A|. I p : p =. p is a theorem of A|. (SOUNDNESS) A deduction algorithm is complete if it \ncan prove any theorem: p is a theorem of A|.=..p. A|. I p : p (COMPLETENESS) Soundness is an essential \nproperty of type-class systems because it connects the implementation to the programmer s model of type \nclasses. We can ensure completeness with suf.cient syntac\u00adtic restrictions on class and instance declarations: \nfor example, Haskell 98 s type-class system is complete. However, these syntac\u00adtic restrictions make \nexpressing many type-class programs dif.cult or impossible. Alternatively, some implementations use pragmatic \nmeasures to ensure termination, such as a (programmer-adjustable) limit to the total number of deduction \nsteps. In ilab, we make no effort to ensure completeness or termination, ensuring greater ex\u00adpressiveness \nas a result. We hope to return to this issue in future work, and .nd a set of restrictions that ensure \ncompleteness while allowing more programs than are allowed by other class systems. The evidence generated \nfrom a deduction algorithm is used in translating programs with type classes. If the deduction algorithm \ncould generate different evidence to prove the same predicate, then the translated program could have \nmultiple meanings. To avoid this incoherence, any two pieces of evidence generated for the same predicate \nmust be semantically indistinguishable, a property Jones calls Uniqueness of Evidence [5]. The notion \nof evidence being semantically indistinguishable corresponds to proof equivalence, so we restate this \nfor our purposes as Equivalence of Proof: A|. I p : p . A|. I p l : p =. p ~= p l (EOP) ilab type classes \nare open: new axioms or constraints may be added to existing programs, adding to or re.ning the meaning \nof classes. To formalize this, we call a program A*|.* an extension of program A|. if: 1. A|. and A*|.* \nare consistent; and, 2. A . A* and . . .*.  Our de.nition differs from the standard de.nition of extension \nin logic in that we require that the exact axioms from A be included in A*, not just that A*|.* prove \nall the theorems of A|.. Asa consequence, we might hope that, if a predicate is a theorem in both programs, \nthen the proofs in each program will be equivalent. We call this property Stability of Proofs: A|. I \np : p . A*|.*I p l : p =. p ~l (SOP) = p Because the Haskell 98 class system permits no overlap between \ninstances, its proofs are stable. Overlapping instances preclude stable proofs: when more speci.c overlapping \ninstances are added, the proofs of some predicates will change to use the new instances. By restricting \noverlap to instance chains, ilab restores stability while still allowing many of the programs that could \nbe written using overlapping instances. We will discuss proofs of ilab s properties following the dis\u00adcussion \nof the ilab deduction algorithm in Section 5.  4.3 Application to other type-class systems As ilab s \nextensions to the type-class mechanism could be applied to other languages, the techniques used in the \nprevious subsections to model type classes and to reason about type-class implementa\u00adtions could be applied \nto other languages, other implementations of Habit, or other type-class systems. Among the goals of ilab \nwas to avoid the complexity of over\u00adlapping instances; by applying our modeling techniques to over\u00adlapping \ninstances, we can see to what extent we achieved our goal. Overlapping instances are not as modular as \nilab s axioms: to de\u00adtermine whether an axiom applies to a predicate, we must deter\u00admine whether it is \nthe most speci.c axiom that matches the pred\u00adicate. Making this determination requires knowing the axioms \nin the remainder of the program, so it would not be possible to de\u00ad.ne the meaning of an axiom without \nthe remainder of the pro\u00adgram as context. Overlapping instances also preclude the stability of proofs: \nbecause a program can be extended with more speci.c axioms, the proofs of theorems of the original program \nmay change in the extension. While we expected that making implicit aspects of overlapping instances \nexplicit would reduce complexity from the beginning of the ilab design process, comparing the models \nand properties of ilab with those of systems with overlapping instances gives a solid basis for this \nintuition. 5. Mechanics This section describes our prototype implementation of ilab. The presentation \nis divided into two subsections: Section 5.1 discusses the validation of source axioms and Section 5.2 \ndescribes proof expressions and a deduction algorithm for ilab. Functional dependencies will play a larger \nrole in this section than heretofore. Some preliminaries will simplify the remaining discussion. Section \n4 used a set . to refer to all the functional dependencies in a program. In this section, we will usually \nonly be interested in the functional dependencies that apply to a particular predicate, and so will use \nthe following (overloaded) function: fundeps.(C)= {XY | C : XY . .}.{N \u00d8} fundeps.(C Tt f ) = fundeps.(C) \nThe set . will be omitted when it is obvious from context. To en\u00adsure that fundeps.(C) is never empty, \nwe have added the depen\u00addency N \u00d8 to the functional dependencies for any class. This de\u00adpendency treats \nall positions as determining, so it will give the be\u00adhavior expected were there no functional dependencies \nat all. Later rules will be able to assume that all classes have at least one func\u00adtional dependency \nconstraint. Of course, any relation satis.es the dependency N \u00d8, so adding it does not affect the modeling \nof programs. When considering predicates and functional dependencies, it is useful to consider the predicates \nwithout including any of the parameters that are determined by the functional dependency. For instance, \nto know whether the instances instance Eq t . Elems [t] t instance Elems [Int] Char overlap, it is not \nenough to unify Elems [t] t with Elems [Int] Char. Rather, we must take the functional dependency for \nElems into account, and attempt to unify Elems [t] with Elems [Int], which succeeds, in this particular \ncase, showing that the instances do overlap. We can generalize this idea to any relation on predicates \nR and index set Y by writing pRpl mod Y to indicate the result of pRpl without considering the elements \nindexed by Y. Formally, we de.ne  (C Tt f )R(Cl T. f l) mod Y .. (C (Tt |N\\Y ) f )R(C (T.|N\\Y ) f l). \nThe name of this operation is chosen by analogy with modular arithmetic: as arithmetic modulo x does \nnot consider powers of x, so operations modulo the index set Y do not consider the elements indexed by \nY. 5.1 Validation There are two tasks in validating ilab axioms: ensuring that there are no overlaps, \nand checking that the relevant functional depen\u00addencies are respected. To determine whether two instances \noverlap, we apply a vari\u00adation of the scheme used in Haskell 98. We say that two instance clauses .Tx. \nP . p and .Ty. Pl . pl overlap if .(XY) . fundeps(p). .U. dom(U) . Tx .Ty UU . (p ~ pl mod Y . p ~ pl \nmod Y) U where we write p ~ pl to indicate that U is the most general uni.er of p and pl. Note that if \np and pl mention the same class name C, then fundeps(p) = fundeps(C) = fundeps(pl). Otherwise, p and \npl cannot unify, so the choice to quantify over fundeps(p) is irrelevant. Our de.nition of overlap differs \nfrom the Haskell de.nition in two ways. First, ilab axioms have explicit quanti.ers, whereas all free \ntype variables in Haskell axioms are implicitly quanti.ed. Second, we take account of the various ways \nin which predicates can contradict each other. Predicates may overlap if their .ags disagree (having \nproofs that both CTt holds and CTt fails would be dif.cult to model, even though the two predicates do \nnot unify). Predicates may also overlap even if they differ in the determined parameters of some functional \ndependency, as in the example of Elems [t] t and Elems [Int] Char. Two axioms a and al overlap if some \nclause from a overlaps some clause from al. This is as strict as the Haskell 98 restriction on overlap; \nhowever, because clauses within a single instance chain are free to overlap, ilab still offers greater \nexpressivity. The overlap check is not enough to ensure that instances do not violate functional dependencies; \nwe must also ensure that any quanti.ed variables in determined positions are actually deter\u00admined. To \ndo this, we make use of the theory of functional de\u00adpendencies [7, 10]. Let TV(p) be all the free type \nvariables mentioned in the type tuple of predicate p. The induced functional dependencies, Fp, of a predicate \np are the dependencies {TV(p|X ) TV(p|Y ) | XY . fundeps(p)} Note that, unlike the class constraints, \nthese are functional depen\u00addencies over sets of type variables, not over index sets. By exten\u00adsion, for \na context P, let FP be the union of the induced functional dependencies for each predicate p . P. The \nclosure of a set J with respect to a set of functional depen\u00ad + dependencies is broken into multiple \nindependent checks. The consistency check is incorporated into ilab s expanded over\u00adlap check. The covering \ncheck is implemented as described in the last few paragraphs. A .nal note: while a functional dependency \ndoes not inherently include or exclude any tuples from a class, each tuple in a class with a dependency \nexcludes all other tuples that would violate the dependency. This can create multiple avenues to prove \nthat a tuple is excluded from a class: either via a negative axiom, or via a (non-overlapping) positive \naxiom combined with a functional dependency. Luckily, as these proofs generate the same evidence, we \ncan allow both without jeopardizing Equivalence of Proofs.  5.2 Solving This section describes the inference \nalgorithm used to prove predi\u00adcates in ilab. Intuitively, to prove a predicate p, we try each of the \navailable axioms in sequence. At each step, we compare the current axiom (.Tx. P . pl); a to the target \npredicate p. There are three cases in which we might be able to prove p: either p and pl do not match, \nso the current clause cannot apply to p, but we can prove p from a; or p and pl match but we can disprove \none of the pre\u00adconditions in P and prove p from a; or p and pl match and we can prove the preconditions. \nThis intuition is somewhat complicated by the presence of func\u00adtional dependencies. Recall the Elems \nclass from Section 2.1 and suppose we are trying to prove Elems T U for some types T and U. If we can \nprove Elems T = U for some type U =U, then the func\u00adtional dependency assures us that we will not be \nable to prove Elems T U. Similarly, if we are trying to prove that Elems T U fails and can prove that \nElems T U holds, then the functional de\u00adpendency assures us that Elems T U fails. Before formally describing \nthe ilab deduction algorithm, we will describe its proof expressions. The structure of ilab proof expressions \nmatches the possible reasoning steps mentioned above. To avoid noise, our proof expressions omit steps \nin which the current axiom does not match the target predicate. Let n range over some countably in.nite \nsource of names. We assume that each axiom clause has a unique identifying name (because these are an \nartifact of the proof expressions, they would not need to be provided by the programmer), and so we will \nuse the following syntax for axiom schemes: a ::= (n : .Tx. P . p); a Axiom schemes This differs from \nthe previous syntax only by adding the name n; because names are irrelevant outside construction of proof \nexpres\u00adsions, this change does not affect the other sections of this paper. A predicate is usually proved \nbecause it matches some axiom clause and the preconditions of that axiom are provable. We de\u00adscribe this \ncase with the proof expression n(Tp) where n is the name of the axiom clause that matched, and Tp are \nthe proofs of that clause s preconditions. Alternatively, as discussed above, a nega\u00ad tive predicate \nC Tt fails may be proven by proving some C T. holdsdencies F, written Jis intuitively the set of all \nelements deter- F such that for some functional dependency, Tt and T. agree on the de\u00ad termining parameters \nbut disagree on the determined. We capture minable from J using the functional dependencies in F. Formally, \nwe de.ne J + F as the smallest set such that: this case with the proof expression exclp where p is the \nproof of the + F ; and, 2. if XY . F and X . J1. J . Jexcluding predicate. Finally, axioms that match \nthe target predicate may not apply because their preconditions can be contradicted. We + F , then Y \n. J Now, consider an instance clause .Tx. P . C Tt f . We can ensure the axiom being skipped, i is the \nindex of the contradicted precon\u00adthat all variables in Tt are properly determined if: dition, p is the \nproof expression for the contradiction, and pl is the + F . capture that with the proof expression [n, \ni, p]pl where n identi.es .XY . fundeps(C). TV(Tt|Y ) . (TV(Tt |X )) + remainder of the proof. . FP \nIntuitively, only the positive portion of the proof contributes We require that all clauses in ilab instance \nchains pass this check. to the construction of evidence, so we can de.ne equivalence for In previous \nwork on type classes and functional dependen-ilab proofs inductively by ignoring skip steps. Additionally \nas cies [7, 17], the process of validating instances against functional mentioned in the last section, \nit may be possible to prove some S pl = p .i. A I pi : S Pi (MATCH) ((n : .Tx. P . pl); a) I n(pTi): \np .(XY) . fundeps(p). S pl = p mod Y .i. A I pi : S Pi a I p : p ((n : .Tx. P . pl); a) I [n, i, pi]p \n: p (STEP-CONTRA) .(XY) . fundeps(p). S pl = p mod Y S pl == p .i. A I pi : S Pi p is negative (MATCH-EXCL) \n((n : .Tx. P . pl); a) I excl n(pTi): p .(XY) . fundeps(p).(pl \" p mod Y . pl \" p mod Y) a I p : ppl \nis positive (STEP-POS) ((n : .Tx. P . pl); a) I p : p pl \" ppl \" pa I p : ppl is negative (STEP-NEG) \n((n : .Tx. P . pl); a) I p : p Figure 2. The ilab deduction system predicates either via a negative \naxiom or via exclusion by a (non\u00adoverlapping) positive axiom. To account for this, we make excl p equivalent \nto any other proof. Equivalence for ilab proofs is given by the following assertions: . p ~ p = q == \nq p ~= q =l]p ~, ql]q . [n, i, p=[n, il excl p ~l = p We can prove a predicate from an axiom set if we \ncan prove it from some axiom in the set: .a . A.a I p : p A, . I p : p Because ilab prohibits overlap \nbetween clauses in separate in\u00adstance chains, there cannot be more than one axiom in the set that matches \na given predicate, let alone more than one that proves it. The deduction rules for a I p : p are given \nin Figure 2. We continue to use the fundeps(p) shorthand instead of passing the constraint set . in to \nall the inference rules. We also omit the regular side condition that substitutions must only mention \nthe quanti.ed variables. Rule MATCH is intuitive: if an axiom matches the target predi\u00adcate, and we can \nprove the preconditions of the axiom, then we can prove the predicate. Rule STEP-CONTRA is similarly \nintuitive. In a regular pattern, we require only that the axiom and rule match modulo (the deter\u00admining \nparameters of) some functional dependency. Rule MATCH-EXCL captures the case where we can prove a negative \npredicate by showing a positive predicate that agrees mod\u00adulo a functional dependency. We gave an example \nof this case at the beginning of this section. Finally, there are two rules for skipping an axiom because \nit does not match the target predicate. The positive version (STEP-POS) makes the usual allowance for \nfunctional dependencies. The negative version (STEP-NEG) does not need to make this allowance because \na negative predicate cannot be excluded by functional dependencies.  5.3 Properties of the ilab deduction \nalgorithm Section 4.2 describes several properties of deduction algorithms. We are currently developing \nformal proofs of those properties for ilab; we sketch some of them in this section. Equivalence and Stability \nof Proofs are relatively easy to es\u00adtablish because ilab does not allow instances to overlap. To gen\u00aderate \ntwo inequivalent proofs of the same predicate would require two different axiom clauses that both unify \nwith the predicate be\u00ading proved. Were these clauses in separate axioms, ilab would re\u00adject the axioms \nas overlapping. Were they in the same clause, they would be ordered such that, once the .rst (whichever \nit happened to be) applied, ilab would not proceed to the second. A similar argument shows stability \nof ilab proofs. The proof of soundness is along the same lines. If a set of axioms are valid, then none \nof the conclusions of the clauses in one axiom overlap the conclusions of the other axioms. As a result, \nthe only sources of unsoundness must originate within a single axiom. However, ilab will prove at most \none conclusion from any single axiom. This rules out all sources of unsoundness. In this work, we have \nfocussed on expressiveness of ilab at the cost of formal termination or completeness properties. We imagine \nthat an approach similar to the one taken by Volpano and Smith [19] to show the undecidability of ML \ntypeability with overloading could be applied to the ilab deduction algorithm. We hope to return to issues \nof completeness and termination in future work. 6. Related work Although they have been implemented in \nboth Haskell and other languages, such as BitC [15], overlapping instances do not appear to have received \nmuch attention in prior research. Peyton Jones et al. [13] consider some of the issues with overlapping \ninstances and other features of Haskell current at the time, such as context reduction. However, as the \ncombination of functional dependencies and type classes had not yet been proposed, they do not anticipate \nmany of the interactions that motivated the work in this paper. The use of overlapping instances is not \nquite as sparse. We have already discussed Swierstra s [18] use of overlapping instances. Kiselyov et \nal. [9] use overlapping instances and functional depen\u00addencies to de.ne a library for heterogeneous lists \nin Haskell, and Kiselyov and L\u00a8ammel [8] take a similar approach in de.ning an object system in Haskell. \nIn both cases, the authors .nd ways to avoid overlapping instances, but at the cost of additional code \ncom\u00adplexity. The Hackage collection of Haskell libraries also includes a number of examples that use \noverlapping instances. Heeren and Hage [3] describe a technique for providing addi\u00adtional information \nto the type checker in the form of type-class di\u00adrectives, speci.ed separately from the Haskell source \ncode. While specifying type-class directives separately allows them to be ap\u00adplied to existing Haskell \ncode, it also limits their usability. In par\u00adticular, while they can specify that a particular predicate \nis excluded from a class, or that a class is closed, they cannot use that informa\u00adtion in an instance \nprecondition or quali.ed type. Their directives do include some of the uses of explicit exclusion, such \nas closing classes or ensuring that classes are disjoint. Maier [10] summarizes the theory of functional \ndependencies as used in the database community. Jones [6] originally proposed the use of functional dependencies \nin type-class systems. Hallgren [2] describes some uses of functional dependencies for type-level com\u00adputation, \nwhich we used for examples in Section 2.2.1. Alternative notation for functional dependencies was discussed \nby Neubauer et al. [12] and by Jones and Diatchki [7].  Sulzmann et al. [17] describe an alternative \napproach to imple\u00admenting functional dependencies. In the course of describing their implementation, \nthey establish properties of classes with functional dependencies to make type inference sound, complete, \nand termi\u00adnating but do not discuss the soundness of the class system directly. They also do not consider \nthe interaction between overlapping in\u00adstances and functional dependencies. Later work by Schrijvers \net al. [14] proposes an alternative to functional dependencies called type functions and describes an \nimplementation. They explicitly exclude any overlap between type functions. 7. Conclusion and future \nwork This paper has explored a new type-class feature, instance chains. We have motivated its development \nfrom existing Haskell type\u00adlevel programming, and demonstrated how type-level program\u00adming can be simpli.ed \nand enhanced with instance chains. We have described a semantic framework for reasoning about type classes \nand their implementations, showed how we can model a type class system with instance chains and functional \ndependencies, and pre\u00adsented a deduction algorithm for such a type system. There is also signi.cant opportunity \nfor future work in this area; we outline some possibilities next. Overlap check. The overlap check as \nimplemented in ilab is sig\u00adni.cantly more restrictive than it needs to be. As discussed in Sec\u00adtion 2.2.1, \nthe preconditions of instances may prevent them from applying to the same predicate. We would like to \nimprove the ilab overlap check so that it takes account of semantic overlap that is, when two axioms \nactually cover the same cases as opposed to the purely syntactic notions of overlap used in this paper. \nTo do so, we will need to determine not just when the hypotheses of two axioms contradict, but also when \nthe possible conclusions of two hypothe\u00adses contradict a potentially expensive search. We hope to apply \nexisting refutation methods to limit this search. Default implementations. We have discussed coding alternatives \nusing overlapping instances at some length; another use of overlap\u00adping instances in existing Haskell \ncode, particularly serialization and generic programming libraries, is to provide default implemen\u00adtations \nof classes while allowing type-speci.c implementations to be de.ned later. We have developed a pattern \nthat encodes default implementations using instance chains instead of overlapping in\u00adstances. We anticipate \ntesting this pattern against examples of de\u00adfault instances, and hope to report on the results in the \nfuture. Greatest and least models. Section 4 effectively uses the least model of a set of instances to \ndetermine its consequences. As it includes failure and functional dependencies, the greatest model of \na set of ilab instances, unlike in Haskell 98, need not include all predicates. We hope that further \nstudy of greatest models will inform alternative approaches to recursive instances and the termi\u00adnation \nand completeness of deduction algorithms. Integration into Habit. As discussed in Section 3, the develop\u00adment \nof ilab was an intermediate step in the development of a di\u00adalect of Haskell called Habit. Habit includes \nmany features omitted by ilab, including Haskell-style superclasses, type-level naturals, explicit representation \nof binary formats, etc. We hope to extend the techniques used in the modeling and implementation of ilab \nin de\u00adveloping the Habit type-class system. We are also interested to see how features like type-level \nnaturals affect the ilab type-class sys\u00adtem, and how much we can implement using ilab features without \nbaking operations into the compiler. We also believe that instance chains would be a valuable addition \nto Haskell, or to other Haskell dialects besides Habit. Acknowledgements. We would like to thank Tim \nChevalier, James Hook, Justin Bailey, Andrew Tolmach, and the rest of the HASP group for comments and \nsuggestions on drafts of this paper. References [1] I. S. Diatchki and M. P. Jones. Strongly typed memory \nareas: pro\u00adgramming systems-level data structures in a functional language. In Haskell 06, pages 72 83, \nPortland, Oregon, USA, 2006. ACM. [2] T. Hallgren. Fun with functional dependencies, or (draft) types \nas values in static computations in Haskell. In Proc. of the Joint CS/CE Winter Meeting, 2001. [3] B. \nHeeren and J. Hage. Type class directives. In PADL 05, pages 253 267. Springer-Verlag, 2005. [4] M. P. \nJones. A theory of quali.ed types. In B. K. Bruckner, editor, ESOP 92, volume 582. Springer-Verlag, London, \nUK, 1992. [5] M. P. Jones. Quali.ed Types: Theory and Practice. Cambridge University Press, 1994. [6] \nM. P. Jones. Type classes with functional dependencies. In ESOP 2000, pages 230 244, London, UK, 2000. \nSpringer-Verlag. [7] M. P. Jones and I. S. Diatchki. Language and program design for functional dependencies. \nIn Haskell Symp., pages 87 98, Victoria, BC, Canada, 2008. ACM. [8] O. Kiselyov and R. L\u00a8ammel. Haskell \ns overlooked object system. Draft; Submitted for publication; online since 10 Sept. 2005. [9] O. Kiselyov, \nR. L\u00a8ammel, and K. Schupke. Strongly typed hetero\u00adgeneous collections. In Haskell 04, pages 96 107, Snowbird, \nUtah, USA, 2004. ACM Press. [10] D. Maier. The Theory of Relational Databases. Computer Science Press, \n1983. [11] J. G. Morris. Experience report: Using Hackage to inform language design. In Haskell 10, Baltimore, \nMaryland, USA, 2010. ACM. [12] M. Neubauer, P. Thiemann, M. Gasbichler, and M. Sperber. A func\u00adtional \nnotation for functional dependencies. In Haskell 01, Firenze, Italy, September 2001. [13] S. Peyton Jones, \nM. P. Jones, and E. Meijer. Type classes: an explo\u00adration of the design space. In Haskell 97, Amsterdam, \nThe Nether\u00adlands, June 1997. [14] T. Schrijvers, S. Peyton Jones, M. Chakravarty, and M. Sulzmann. Type \nchecking with open type functions. In IFCP 08, pages 51 62, Victoria, BC, Canada, 2008. ACM. [15] J. \nShapiro, S. Sridhar, and S. Doerrie. BitC (0.11 transitional) language speci.cation. http://www.bitc-lang.org/docs/bitc/spec.html. \nLast accessed June 15, 2010. [16] D. Steinitz. Exporting a type class for type signatures. http: //www.haskell.org/pipermail/haskell-cafe/2008-November/ \n050409.html, November 2008. [17] M. Sulzmann, G. J. Duck, S. Peyton Jones, and P. J. Stuckey. Under\u00adstanding \nfunctional dependencies via constraint handling rules. JFP, 17(1):83 129, 2007. [18] W. Swierstra. Data \ntypes `a la carte. JFP, 18(04):423 436, 2008. [19] D. M. Volpano and G. S. Smith. On the complexity of \nML typeabil\u00adity with overloading. In FPCA 91, pages 15 28, Cambridge, Mas\u00adsachusetts, USA, 1991. Springer-Verlag. \n[20] P. Wadler. The expression problem. http://homepages.inf.ed.ac. uk/wadler/papers/expression/expression.txt, \n1998. [21] P. Wadler and S. Blott. How to make ad-hoc polymorphism less ad hoc. In POPL 89, pages 60 \n76, Austin, Texas, USA, 1989. ACM.    \n\t\t\t", "proc_id": "1863543", "abstract": "<p>Type classes have found a wide variety of uses in Haskell programs, from simple overloading of operators (such as equality or ordering) to complex invariants used to implement type-safe heterogeneous lists or limited subtyping. Unfortunately, many of the richer uses of type classes require extensions to the class system that have been incompletely described in the research literature and are not universally accepted within the Haskell community.</p> <p>This paper describes a new type class system, implemented in a prototype tool called <b>ilab</b>, that simplifies and enhances Haskell-style type-class programming. In <b>ilab</b>, we replace overlapping instances with a new feature, <i>instance chains</i>, allowing explicit alternation and failure in instance declarations. We describe a technique for ascribing semantics to type class systems, relating classes, instances, and class constraints (such as kind signatures or functional dependencies) directly to a set-theoretic model of relations on types. Finally, we give a semantics for <b>ilab</b> and describe its implementation.</p>", "authors": [{"name": "J. Garrett Morris", "author_profile_id": "81470649402", "affiliation": "Portland State University, Portland, OR, USA", "person_id": "P2338238", "email_address": "", "orcid_id": ""}, {"name": "Mark P. Jones", "author_profile_id": "81100557950", "affiliation": "Portland State University, Portland, OR, USA", "person_id": "P2338239", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863596", "year": "2010", "article_id": "1863596", "conference": "ICFP", "title": "Instance chains: type class programming without overlapping instances", "url": "http://dl.acm.org/citation.cfm?id=1863596"}