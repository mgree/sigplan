{"article_publication_date": "09-27-2010", "fulltext": "\n Parametricity and Dependent Types Jean-Philippe Bernardy Patrik Jansson Ross Paterson Chalmers University \nof Technology and City University London University of Gothenburg ross@soi.city.ac.uk {bernardy,patrikj}@chalmers.se \nAbstract Reynolds abstraction theorem shows how a typing judgement in System F can be translated into \na relational statement (in second order predicate logic) about inhabitants of the type. We obtain a similar \nresult for a single lambda calculus (a pure type system), in which terms, types and their relations are \nexpressed. Working within a single system dispenses with the need for an interpretation layer, allowing \nfor an unusually simple presentation. While the uni.cation puts some constraints on the type system (which \nwe spell out), the result applies to many interesting cases, including dependently-typed ones. Categories \nand Subject Descriptors F.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs Type Structure \nGeneral Terms Languages, Theory Keywords Pure type system, Abstraction theorem, Free theorems 1. Introduction \nReynolds [1983] de.ned a relational interpretation of System F types, and showed that interpretations \nof a term of that type in related contexts yield related results. He was thus able to constrain interpretations \nof polymorphic types. Wadler [1989] observed that if a type has no free variables, the relational interpretation \ncan thus be viewed as a parametricity property satis.ed by all terms of that type. Such properties have \nbeen used in a variety of situations. A few examples include: program transformation The fold/build rule \ncan be used to re\u00admove intermediate lists [Gill et al. 1993]. Its correctness can be proved using the \nparametricity condition derived from the type of the function build [Johann 2002]. testing The testing \nof a polymorphic function can often be re\u00adduced to testing a single monomorphic instance. Bernardy et \nal. [2010a] present a scheme for constructing such a monomorphic instance for which the correctness proof \nrelies on parametricity. automatic program inversion It is possible to write a function that inverts \na polymorphic function given as input. The inver\u00adsion process essentially relies on the parametric behaviour \nof the input function, and therefore its correctness relies on the corresponding parametricity condition \n[Voigtl\u00a8 ander 2009a]. Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. ICFP 10, September 27 29, 2010, Baltimore, Maryland, USA. Copyright c &#38;#169; 2010 ACM \n978-1-60558-794-3/10/09. . . $10.00 generic programming In a certain style of generic programming, functions \ncan be type-indexed. However, in some cases it is useful to show that functions behave uniformly for \nall types. Vytiniotis and Weirich [2009] use parametricity to show that certain casting functions are \nequivalent to the identity. encoding of inductive types Via Church-encodings, inductive types can be \nencoded in pure System F. The proof of isomorphism relies on the parametricity condition. Hinze [2005] \ngives an illuminating example. Parametricity in System F is useful enough that there has been much research \nto transport it to related calculi. Johann and Voigtl\u00a8 ander [2005] have applied it to a system with \nexplicit strict\u00adness; Vytiniotis and Weirich [2010] to F. extended with represen\u00adtation types; Takeuti \n[2004] sketches how it can be applied to the .-cube, Neis et al. [2009] to a system with dynamic casting. \nIn this paper, we apply Reynolds idea to dependently-typed systems. In fact, we go one step further and \ngeneralize to a large class of pure type systems [Barendregt 1992]. By targeting pure type systems (PTSs), \nwe aim to provide a framework which uni.es previous descriptions of parametricity and forms a basis for \nfuture studies of parametricity in speci.c type systems. As a by-product, we get parametricity for dependently\u00adtyped \nlanguages. Our speci.c contributions are: A concise de.nition of the translation of types to relations \n(Def\u00adinition 4), which yields parametricity propositions for PTSs.  A formulation (and a proof) of the \nabstraction theorem for a useful class of PTSs (Theorem 1). A remarkable feature of the theorem is that \nthe translation from types to relations and the translations from terms to proofs are uni.ed.  An extension \nof the translation to inductive de.nitions (Sec\u00adtion 4). Our examples use a notation close to that of \nAgda [Norell 2007], for greater familiarity for users of dependently\u00adtyped functional programming languages. \n A demonstration by example of how to derive free theorems for (and as) dependently-typed functions \n(sections 3.1 and 5). Two examples of functions that we tackle are:  generic catamorphism fold : ((F \n, mapF ): Functor) . (A : *) . (FA . A) . \u00b5 F . A, which is a generic catamorphism function de.ned within \na dependently-typed language (see Section 5.2). generic cast gcast :(F : * . *) . (ut : U ) . Maybe (F \n(El u) . F (El t)), which comes from a mod\u00adelling of representation types with universes (see Sec\u00adtion \n5.3). In both cases, the derived parametricity condition yields useful properties to reason about the \ncorrectness of the function.  2. Pure type systems In this section we brie.y review the notion of PTS \nas described by Barendregt [1992, sec. 5.2], and the basic intuitions behind it. We introduce our notation \nalong the way, as well as our running example type system. De.nition 1 (Syntax of terms). A PTS is a \ntype system over a .\u00adcalculus with the following syntax: T = C constant |||| V T T .V :T . T .V :T . \nT variable application abstraction dependent function space We often write (x : A) . B for .x : A. B, \nand sometimes just A . B when x does not occur free in B. The typing judgement of a PTS is parametrized \nover a speci.ca\u00adtion S =(S, A, R), where S.C, A . C\u00d7S and R . S\u00d7S\u00d7S. The set S speci.es the sorts, A \nthe axioms (an axiom (c, s) .A is often written c : s), and R speci.es the typing rules of the function \nspace. A rule (s1,s2,s2) is often written s1 r s2. The rules for typing judgements in a PTS are given \nin Figure 1. An attractive feature of PTSs is that the syntax for types and values is uni.ed. It is the \ntype of a term that tells how to interpret it (as a value, type, kind, etc.). the .-cube Barendregt [1992] \nde.ned a family of calculi each with S = {*, D}, A = {* : D} and R a selection of rules of the form s1 \nr s2, for example: The (monomorphic) .-calculus has R. = {* r *}, corre\u00adsponding to ordinary functions. \n System F has RF = R. .{D r *}, adding (impredicative) universal quanti.cation over types.  System \nF. has RF. = RF .{D r D}, adding type-level functions.  The Calculus of Constructions (CC) has RCC = \nRF. .{* r D}, adding dependent types.  Here * and D are conventionally called the sorts of types and \nkinds respectively. Notice that F is a subsystem of F., which is itself a subsystem of CC. (We say that \nS1 =(S1, A1, R1) is a subsystem of S2 = (S2, A2, R2) when S1 .S2, A1 .A2 and R1 .R2.) In fact, the .-cube \nis so named because the lattice of the subsystem relation between all the systems forms a cube, with \nCC at the top. sort hierarchies Dif.culties with impredicativity1 have led to the development of type \nsystems with an in.nite hierarchy of sorts. The pure part of such a system can be captured in the following \nPTS, which we name I.. De.nition 2 (I.). I. is a PTS with this speci.cation: S = {*i | i . N}  A = \n{*i : *i+1 | i . N}  R = {(*i,*j ,*max(i,j)) | i, j . N} Compared to the monomorphic .-calculus, * has \nbeen expanded into the in.nite hierarchy *0,*1,... In I., the sort *0 (abbrevi\u00adated *) is called the \nsort of types. Type constructors, or type-level functions have type * . *. The set of types (*), the \nset of type constructors (* . *) and similar have type *1 (the sort of kinds). Terms like *1 and * . \n*1 have type *2, and so on. Impredicativity can in fact coexist with an in.nite hierarchy of sorts, as \nCoquand [1986] has shown. For example, in the Gen\u00ad 1 It is inconsistent with strong sums [Coquand 1986]. \naxiom c : s .A f c : s G f A : s start G,x : A f x : A G f A : B G f C : s weakening G,x : C f A : B \nG f A : s1 G,x : A f B : s2 product (s1,s2,s3) .R G f (.x: A. B): s3 G f F :(.x :A. B)G f a : A application \nG f Fa : B[x . a] G,x : A f b : B G f (.x : A. B): s abstraction G f (.x: A. b):(.x:A. B) G f A : B G \nf B' : s B = \u00df B' conversion G f A : B' Figure 1. Typing judgements of the PTS (S, A, R) eralized Calculus \nof Constructions (CC.) of Miquel [2001], im\u00adpredicativity exists for the sort * (conventionally called \nthe sort of propositions), which lies at the bottom of the hierarchy. De.nition 3 (CC.). CC. is a PTS \nwith this speci.cation: S = {*}.{Di | i . N}  A = {* : D0}.{Di : Di+1 | i . N}  R = {* r *, * r Di, \nDi r * | i . N}. {(Di, Dj , Dmax(i,j)) | i, j . N}  Both CC and I. are subsystems of CC., with * i in \nI. corre\u00adsponding to Di in CC.. Because D in CC corresponds to D0 in CC., we often abbreviate D0 as D. \nMany dependently-typed programming languages and proof as\u00adsistants are based on variants of I. or CC., \noften with the addition of inductive de.nitions [Dybjer 1994; Paulin-Mohring 1993]. Such tools include \nAgda [Norell 2007], Coq [The Coq development team 2010] and Epigram [McBride and McKinna 2004]. 2.1 PTS \nas logical system Another use for PTSs is as logical systems: types correspond to propositions and terms \nto proofs. This correspondence extends to all aspects of the systems and is widely known as the Curry-Howard \nisomorphism. The judgement f p : P means that p is a witness, or proof of the proposition P. In the logical \nsystem reading, an inhabited type corresponds to a tautology and dependent function types correspond \nto universal quanti.cation. Predicates over a type A have type A . s, for some sort s: a value satis.es \nthe predicate whenever the returned type is inhabited. Similarly, binary relations between values of \ntypes A1 and A2 have type A1 . A2 . s. For this approach to be safe, it is important that the system \nbe consistent: some types must be uninhabited, or equivalently each witness p must reduce to a normal \nform. This is the case for the systems used here. In fact, in I. and similarly rich type systems, one \nmay both rep\u00adresent programs and logical formulae about them. In the following sections, we make full \nuse of this property: we encode programs and parametricity statements about them in the same type system. \n 3. Types to relations We start by de.ning the relational interpretation of a term, as a syn\u00adtactic translation \nfrom terms to terms. As we see in Section 3.1, it is a generalization of the classical rules given by \nReynolds [1983], extended to application and abstraction. In this section, we assume that the only constants \nare sorts. We also assume for each sort s another sort ssof parametricity propositions about terms of \ntype s. In our examples, we simply choose ss = s. We shall return to the general case in Section 6.2. \nDe.nition 4 ([ ] , translation from types to relations). Given a natural number n (the arity of relations), \nwe assume for each variable x, fresh variables x1,...,xn and xR. We write A for the n terms Ai, each \nobtained by replacing each free variable x in A with xi. Correspondingly, x:A stands for n bindings (xi \n: Ai). We de.ne a mapping [ ] from T to T as follows: [ s] = .x:s. x . ss [ x] = xR [ .x : A. B] = .f \n:(.x : A. B). .x : A. .xR :[ A] x. [ B] (fx) [ Fa] = [ F] a [ a] [ .x:A. b] = .x:A. .xR :[ A] x. [ b] \n Note that for each variable x free in A, the translation [ A] has free variables x1,...,xn and xR. There \nis a corresponding replication of variables bound in contexts, which is made explicit in the following \nde.nition. De.nition 5 (translation of contexts). [[G,x : A] = [[G]],x:A,xR :[ A] x Note that each tuple \nx : A in the translated context must satisfy the relation [ A] , as witnessed by xR. Thus, one may interpret \n[[G]] as n related environments. In order for a PTS to be able to express both programs and para\u00admetricity \npropositions about them, it must satisfy certain closure conditions, for which we coin the term re.ective: \nDe.nition 6 (re.ective). A PTS (S, A, R) is re.ective if for each sort s .S .ss .S .s ' .S such that \ns : s ' .A  for each axiom s : s ' .A  ' ss : ss.A s r ss' .R for each rule (s1,s2,s3) .R (ss1,ss2,ss3) \n.R s1 r ss3 .R We can then state our main result: Theorem 1 (abstraction). Given a re.ective PTS (S, \nA, R), G f A : B =. [[G]] f [ A] : [ B] A Proof. By induction on the derivation. A brief sketch of the \nproof is given in appendix A. The above theorem can be read in two ways. A direct reading is as a typing \njudgement about translated terms: if A has type B, then [ A] has type [ B] A. The more fruitful reading \nis as an abstraction theorem for pure type systems: if A has type B in environment G, then n interpretations \nA in related environments [[G]] are related by [ B] . Further, [ A] is a witness of this proposition \nwithin the type system. In particular, closed terms are related to themselves: Corollary 2 (parametricity). \nf A : B =.f [ A] : [ B] A example systems Note that both I. and CC. are re.ective, with ss = s. Therefore \nwe can write programs in these systems and derive valid statements about them, using [ ] , within the \nsame PTS. We proceed to do so in the rest of the paper. 3.1 Examples: the .-cube In this section, we \nshow that [ ] specializes to the rules given by Reynolds [1983] to read a System F type as a relation. \nHaving shown that our framework can explain parametricity theorems for System-F-style types, we move \non to progressively higher-order constructs. In these examples, the binary version of parametricity is \nused (arity n =2). For examples using the unary version (arity n =1) see Section 5.3. While the systems \nof the .-cube are not re.ective, they are embedded in CC., which is. This means that our translation \nrules take System F types to terms in CC. (instead of second order propositional logic). The possibility \nof using a different PTS for the logic is discussed in Section 6.3. types to relations Note that, by \nde.nition, [ *] T1 T2 = T1 . T2 . * Assuming that types inhabit the sort *, this means that types are \ntranslated to relations (as expected). Here we also use * on the right side as the sort of propositions \n(s* = *), but other choices are possible, as we shall discuss in Section 6.2. function types Applying \nour translation to non-dependent func\u00adtion types, we get: [ A . B] : [ *] (A . B)(A . B) [ A . B] f1 \nf2 = .a1 : A. .a2 : A. [ A] a1 a2 . [ B] (f1 a1)(f2 a2) That is, functions are related iff they take \nrelated arguments into related outputs. type schemes System F includes universal quanti.cation of the \nform .A:*. B. Applying [ ] to this type expression yields: [ .A : *. B] : [ *] (.A : *. B)(.A : *. B) \n[ .A : *. B] g1 g2 = .A1 : *. .A2 : *. .AR :[ *] A1 A2. [ B] (g1 A1)(g2 A2) In words, polymorphic values \nare related iff instances at related types are related. Note that as A may occur free in B, the variables \nA1, A2 and AR may occur free in [ B] . type constructors With the addition of the rule D r D, one can \nconstruct terms of type * . *, which are sometimes known as type constructors, type formers or type-level \nfunctions. As Voigtl\u00a8 ander [2009b] remarks, extending Reynolds-style parametricity to sup\u00adport type \nconstructors appears to be folklore. Such folklore can be precisely justi.ed by our framework by applying \n[ ] to obtain the relational counterpart of type constructors: [ * . *] : [ D] (* . *)(* . *) [ * . *] \nF1 F2 = .A1 : *. .A2 : *. [ *] A1 A2 . [ *] (F1 A1)(F2 A2)  That is, a term of type [ * . *] F1 F2 is \na (polymorphic) function converting a relation between any types A1 and A2 to a relation between F1 A1 \nand F2 A2,a relational action. dependent functions In a system with the rule * r D, value variables may \noccur in dependent function types like .x : A. B, which we translate as follows: [ .x : A. B] : [ *] \n(.x : A. B)(.x : A. B) [ .x : A. B] f1 f2 = .x1 : A. .x2 : A. .xR :[ A] x1 x2. [ B] (f1 x1)(f2 x2)  \nproof terms We have used [ ] to turn types into relations, but we can also use it to turn terms into \nproofs of abstraction properties. As a simple example, the relation corresponding to the type T = .A \n: *. A . A, namely [ T ] f1 f2 = .A1 : *. .A2 : *. .AR :[ *] A1 A2. .x1 : A1. .x2 : A2. AR x1 x2 . AR \n(f1 A1 x1)(f2 A2 x2) states that functions of this type map related inputs to related out\u00adputs. From \na term id = .A : *. .x:A. x of this type, by Theorem 2 we obtain a term [ id] : [ T ] id id, that is, \na proof of the abstraction property: [ id] A1 A2 AR x1 x2 xR = xR 4. Constants and data types While the \nabove development assumes pure type systems with C = S, it is possible to add constants to the system \nand retain parametricity, as long as each constant is parametric. That is, for each new axiom f k : A \n(where k is an arbitrary constant and A an arbitrary term such that f A : s, not a mere sort) we require \na term [ k] such that the judgement f [ k] : [ A] k holds. (Additionally, \u00df\u00adconversion rules involving \nthose constants must preserve types.) One source of constants in many languages is data type de.ni\u00adtions. \nIn the rest of the this section we detail how to handle such de.nitions (in a system extending I.). \n4.1 Inductive families Many languages permit data type declarations like those in Fig\u00adure 2. Dependently \ntyped languages typically allow the return types of constructors to have different arguments, yielding \ninductive fam\u00adilies [Dybjer 1994; Paulin-Mohring 1993] such as the family Vec, in which the type is indexed \nby the number of elements. Data family declarations of sort s (* in the examples) have the typical form:2 \ndata T (a :A): .n: N.s where c : .b: B. (.x : X.Ta i) . Ta v Arguments of the type constructor T may \nbe either parameters a, which scope over the constructors and are repeated at each recursive use of T \n, or indices n, which may vary between uses. Data constructors c have non-recursive arguments b, whose \ntypes are otherwise unrestricted, and recursive arguments with types of a constrained form, which cannot \nbe referred to in the other terms. Such a declaration can be interpreted as a simultaneous decla\u00adration \nof formation and introduction constants T : .a: A. .n :N.s c : .a: A. .b:B. (.x : X.Ta i) . Ta v  and \nalso an eliminator to analyse values of that type: T -elim : .a : A. .P :(.n: N. Tan . s). Casec ..n:N. \n.t:T an. P nt where the type Casec of the case for each constructor c is .b:B. .u :(.x:X.Ta i). (.x : \nX.P i (ux)) . P v (cabu) with beta-equivalences (one for each constructor c): T -elim aP e v (cabu)= \nebu (.x:X.T -elim aP e i (ux)) We shall often use corresponding pattern matching de.nitions in\u00adstead \nof these eliminators [Coquand 1992]. 2 We show only one of each element here, but the generalization \nto arbitrary numbers is straightforward. data Bool : * where true : Bool false : Bool data Nat : * where \nzero : Nat succ : Nat . Nat data . : * where --no constructors data T : * where tt : T data List (A : \n*): * where nil : List A cons : A . List A . List A data Vec (A : *): Nat . * where nilV : Vec A zero \nconsV : A . (n : Nat) . Vec An . Vec A (succ n) data S (A : *)(B : A . *): * where , :(a : A) . Ba . \nS AB data = (A : *)(a : A): A . * where re. : = Aaa Figure 2. Example inductive families For example, \nthe de.nition of List in Figure 2 gives rise to the following constants: List : (A : *) . * nil : (A \n: *) . List A cons : (A : *) . A . List A . List A List-elim :(A : *) . (P : List A . *) . P (nil A) \n. ((x : A) . (xs : List A) . P xs . P (consAx xs)) . (l : List A) . Pl In the following sections, we \nconsider two ways to de.ne an abstraction proof [ k] : [ t] k for each constant k : t introduced by the \ndata de.nition. 4.2 Deductive-style translation First, we de.ne each proof as a term (using pattern \nmatching to simplify the presentation). We begin with the translation of the equation for each constructor: \n[ T -elim aP e v] (cabu) ([[c] aaR bbR uuR)= [ ebu (.x : X.T -elim aP e i (ux))]] To turn this into \na pattern matching de.nition of T-elim, we need a suitable de.nition of [ c] , and similarly for the \nconstructors in v. The only arguments of [ c] not already in scope are bR and uR, so we package them \nas a dependent pair, because the type of uR may depend on that of bR. Writing (x: A) \u00d7 B for S A (.x:A. \nB), and elements of this type as (a, b), omitting the arguments A and .x : A. B, we de.ne3 [ T ] : [ \n.a : A. .n:N.s] T [ T ] aaR v [ v] (cabu)=(bR :[ B] b) \u00d7 [ .x:X.Ta i] u [ T ] aaR uuR t = .  [ c] \n: [ .a:A. .b : B. (.x:X.Ta i) . Ta v] c [ c] aaR bbR uuR =(bR,uR) ' 3 The de.nition of [ T ] relies \non the weak elimination constant to sort ss . and the translation of T-elim becomes [ T -elim aP e v] \n(cabu)(bR,uR)= [ ebu (.x: X.T -elim aP e i (ux))]] Because [ T ] yields . unless the constructors match, \nthese clauses provide complete coverage. The reader may have noted by now that the argument lists of \nthe translated constants tend to be quite long. The use of the translated constants can be substantially \nsimpli.ed using implicit arguments (arguments which can be inferred from contextual knowledge). We avoid \nusing them in this paper to explicitly show the underlying ma\u00adchinery, but the Agda library implementing \nthe translation makes heavy use of implicit arguments for convenience. Booleans To get an intuition of \nthe meaning of the above trans\u00adlation scheme we proceed to apply it to a number of examples, starting \nwith the data type for Booleans. We obtain: [ Bool] : [ *] Bool Bool [ Bool] true true = T [ Bool] false \nfalse = T [ Bool] = . [ true] : [ Bool] true true [ true] = tt [ false] : [ Bool] false false [ false] \n= tt (We use T for nullary constructors as it is the identity of \u00d7.) parametricity and elimination Reynolds \n[1983] and Wadler [1989] assume that each type constant K : * is translated to the identity relation, \nas we have done for Bool above. This de.nition is certainly compatible with the condition required by \nTheorem 1 for such constants: [ K ] : [ *] KK , but so are many other relations. Are we missing some \nrestriction for constants? This question might be answered by resorting to a translation to pure terms \nvia Church encodings [B\u00a8ohm and Berarducci 1985], as Wadler [2007] does. However, in the hope to shed \na different light on the issue, we give another explanation, using our machinery. Consider a base type, \nsuch as Bool : *, equipped with construc\u00adtors true : Bool and false : Bool. In order to derive parametricity \ntheorems in a system containing such a constant Bool, we must de.ne [ Bool] , satisfying f [ Bool] : \n[ *] Bool. What are the re\u00adstrictions put on the term [ Bool] ? First, we must be able to de.ne [ true] \n: [ Bool] true. Therefore, [ Bool] true must be inhabited. The same reasoning holds for the false case. \nSecond, to write any useful program using Booleans, a way to test their value is needed. This may be \ndone by adding a con\u00adstant if : Bool . (A : *) . A . A . A, such that if trueAxy -.\u00df x and if falseAxy \n-.\u00df y. (This special case of Bool-elim is suf.cient for the present example.) Now, if a program uses \nif , we must also de.ne [ if ] of type [ Bool . (A : *) . A . A . A] if for parametricity to work. Let \nus expand the type of [ if ] and attempt to give a de.nition case by case: [ if ] :(b1 b2 : Bool) . (bR \n:[ Bool] b1 b2) . (A1 A2 : *) . (AR :[ *] A1 A2) . (x1 : A1) . (x2 : A2) . (xR : AR x1 x2) . (y1 : A1) \n. (y2 : A2) . (yR : AR y1 y2) . AR (if b1 A1 x1 y1)(if b2 A2 x2 y2) [ if ] true true bR x1 x2 xR y1 \ny2 yR = xR [ if ] true false bR x1 x2 xR y1 y2 yR =? [ if ] false true bR x1 x2 xR y1 y2 yR =? [ if ] \nfalse false bR x1 x2 xR y1 y2 yR = yR (From this example onwards, we use a layout convention to ease \nthe reading of translated types: each triple of arguments, corresponding to one argument in the original \nfunction, is written on its own line if space permits.) In order to complete the above de.nition, we \nmust provide a type-correct expression for each question mark. In the case of the second equation, this \nmeans that we must construct an expression of type AR x1 y2. Neither xR : AR x1 x2 nor yR : AR y1 y2 \ncan help us here. The only liberty left is in bR :[ Bool] true false. If we let [ Bool] true false be \n., then this case can never be reached and we need not give an equation for it. This reasoning holds \nsymmetrically for the third equation. Therefore, we have the restrictions: [ Bool] xx = some inhabited \ntype [ Bool] xy = . if x= y We have some freedom regarding picking some inhabited type , so we choose \n[ Bool] xx = T, yielding an encoding of the iden\u00adtity relation. In general, for any base type, the identity \nis the most permissive relation which allows for a de.nition of the translation of the eliminator. An \nintuition behind parametricity is that, the more programs know about a type, the more restricted parametricity \ntheorems are. Through the Bool example, we have seen how our framework captures this intuition, in a \n.ne grained manner. We revisit this idea in Section 5.4. lists and vectors From the de.nition of List \nin Figure 2, we have the constant List : * . *, so List is an example of a type constructor, and thus \n[ List] is a relation transformer. The relation transformer we get by applying our scheme is exactly \nthat given by Wadler [1989]: lists are related iff their lengths are equal and their elements are related \npoint-wise. [List] :[ * . *] List List [List] A1 A2 AR nil nil = T [List] A1 A2 AR (cons x1 xs1)(cons \nx2 xs2)= AR x1 x2 \u00d7 [List] A1 A2 AR xs1 xs2 [List] A1 A2 AR = . [ nil] : [[(A : *) . List A] nil nil \n[ nil] A1 A2 AR = tt [ cons] : [[(A : *) . A . List A . List A] cons cons [ cons] A1 A2 AR x1 x2 xR xs1 \nxs2 xsR =(xR, xsR) The translations of the constants of Vec are given in Figure 3. list rearrangements \nThe .rst example of parametric type exam\u00adined by Wadler [1989] is the type of list rearrangements: R \n=(A : *) . List A . List A. Intuitively, functions of type R know nothing about the actual argument type \nA, and therefore they can only produce the output list by taking elements from the input list. In this \nsection we recover that result as an instance of Theorem 1. Applying the translation to R yields: [R] \n: R . R . * [R] r1 r2 =(A1 A2 : *) . (AR :[ *] A1 A2) . (l1 : List A1) . (l2 : List A2) . (lR : [List] \nA1 A2 AR l1 l2) . [List] A1 A2 AR (r1 A1 l1)(r2 A2 l2) In words: two list rearrangements r1 and r2 are \nrelated iff for all types A1 and A2 with relation AR, and for all lists l1 and l2 point\u00adwise related \nby AR, the resulting lists r1 A1 l1 and r2 A2 l2 are also point-wise related by AR. By corollary 2 (parametricity), \nwe have, for any r: f r : R =.f [ r] : [ R] rr  Vec : [[(A : *) . Nat . *] Vec Vec A1 A1 AR zero zero \nnilV nilV = T[ Vec] A1 A1 AR (succ n1)(succ n2) nR (consV n1 x1 xs1)(consV n2 x2 xs2)= AR x1 x2 \u00d7 (nR \n: [Nat] n1 n2) \u00d7 [Vec] A1 A1 AR n1 n2 nR xs1 xs2 xsR Vec] A1 A1 AR n1 n2 nR xs1 xs2 = . [ nilV ] : [[(A \n: *) . Vec A zero] nilV nilV ] A1 A1 AR = tt consV : [[(A : *) . A . (n : Nat) . Vec An . Vec A (succ \nn)]] consV [ consV ] A1 A1 AR x1 x2 xR n1 n2 nR xs1 xs2 xsR =(xR, (nR, xsR)) [ Vec-elim] : [ (A : *) \n. (P :(n : Nat) . Vec n A . *) . (en : P zero (nilV A)) . (ec :(x : A) . (n : Nat) . (xs : Vec n A) \n. P n xs . P (succ n)(consV Ax nxs)) . (n : Nat) . (v : Vec n A) . Pnv] Vec-elim [ Vec-elim] A1 A2 AR \nP1 P2 PR en1 en2 enR ec1 ec2 ecR zero zero nilV nilV = enR [ Vec-elim] A1 A2 AR P1 P2 PR en1 en2 enR \nec1 ec2 ecR (succ n1)(succ n2) nR (consV x1 n1 xs1)(consV x2 n2 xs2)(xR, (nR, xsR)) = ecR x1 x2 xR n1 \nn2 nR xs1 xs2 xsR (Vec-elim A1 P1 en1 ec1 n1 xs1)(Vec-elim A2 P2 en2 ec2 n2 xs2) ([[Vec-elim] A1 A2 AR \nP1 P2 PR en1 en2 enR ec1 ec2 ecR n1 n2 nR xs1 xs2 xsR) Figure 3. Deductive translation of Vec constants. \n([ Nat] is the identity relation.) In words: applying r preserves (point-wise) any relation existing \nbetween input lists. By specializing AR to a function (AR a1 a2 = f a1 = a2) we obtain the well-known \nresult: f r : R =. (A1 A2 : *) . (f : A1 . A2) . (l : List A1) . map f (r A1 l) = r A2 (mapf l) (This \nform relies on the facts that [ List] preserves identities and composes with map.) proof terms We have \nseen that applying [ ] to a type yields a parametricity property for terms of that type. However, by \nTheo\u00adrem 1 we can also apply [ ] to a term of that type to obtain a proof of the property. Consider a \nlist rearrangement function odds that returns every second element from a list. odds :(A : *) . List \nA . List A odds A nil = nil A odds A (cons x nil)= consAx nil odds A (cons x (cons xs)) = cons Ax (odds \nA xs) Any list rearrangement function must satisfy the parametricity con\u00addition seen above. We know by \nTheorem 1 that [ odds] is a proof that odds satis.es parametricity. Expanding it yields: [ odds] : [[(A \n: *) . List A . List A] odds odds [ odds] A1 A2 AR nil nil = tt [ odds] A1 A2 AR (cons x1 nil)(cons x2 \nnil)(xR, )= (xR, tt) [ odds] A1 A2 AR (cons x1 (cons xs1)) (cons x2 (cons xs2)) (xR, ( , xsR)) = (xR, \n[ odds] A1 A2 AR xs1 xs2 xsR) We see that [ odds] performs essentially the same computation as odds, \non two lists in parallel. However, instead of building a new list, it keeps track of the relations (in \nthe R-subscripted variables). This behaviour stems from the last two cases in the de.nition of [ odds] \n. Performing such a computation is enough to prove the parametricity condition.  4.3 Inductive-style \ntranslation Inductive de.nitions offer another way of de.ning the translations [ c] of the constants \nassociated with a data type, an inductive de.ni\u00adtion in contrast to the deductive de.nitions of the previous \nsection. Given an inductive family data T (a : A): K where c : C by applying our translation to the \ncomponents of the data\u00addeclaration, we obtain an inductive family that de.nes the rela\u00adtional counterparts \nof the original type T and its constructors c at the same time: data [ T ] ([[a:A]]): [ K] (Ta) where \nc :[ C] (ca) It remains to supply a proof term for the parametricity of the elimination constant T-elim. \nIf the inductive family has the form data T (a:A): .n : N.s where c : .b : B. (.x :X.Ta i) . Ta v then \nthe proof [ T-elim] can be de.ned using [ T ] -elim and T-elim as follows: [ T-elim] : [ .a : A. .P :(.n: \nN. Tan . s). .e:Casec. .n:N. .t:T an. P nt] T-elim [ T-elim aP e] = [ T ] -elim aaR (.[ n : N,t:T an] \n. [ P nt] (T-elim aP ent)) (.[ b:B,u:(.x : X.Ta i)]]. [ ebu] (.x: X. T-elim aP e i (ux))) Deductive \nand inductive-style translations de.ne the same relation, but the objects witnessing the instances of \nthe inductively de.ned\u00adrelation record additional information, namely which rules are used to prove membership \nof the relation. However, since the same constructor never appears in more than one case of the inductive \nde.nition, that additional content can be recovered from a witness of the deductive-style; therefore \nthe two styles are truly isomorphic. Booleans Applying the above scheme to the data-declaration of Bool \n(from Figure 2), we obtain: data [ Bool] : [ *] Bool where [ true] :[ Bool] true [ false] : [ Bool] false \n The main difference from the deductive-style de.nition is that it is possible, by analysis of a value \nof type [ Bool] , to recover the arguments of the relation (either all true, or all false). The elimination \nconstant for Bool is Bool-elim :(P : Bool . *) . P true . P false . (b : Bool) . Pb Similarly, our new \ntype [ Bool] (with n =2) has an elimination constant with the following type: [ Bool] -elim : (C :(a1 \na2 : Bool) . [ Bool] a1 a2 . *) . C true true [ true] . C false false [ false] . (b1 b2 : Bool) . (bR \n:[ Bool] b1 b2) . C b1 b2 bR As an instance of the above scheme, we can de.ne [ Bool-elim] using the \nelimination constants [ Bool] and [ Bool] -elim as follows (where t = true and f = false): [ Bool-elim] \n: (P1 P2 : Bool . *) . (PR :[ Bool . *] P1 P2) . (x1 : P1 t) . (x2 : P2 t) . (PR tt [ t] x1 x2) . (y1 \n: P1 f ) . (y2 : P2 f ) . (PR ff [ f ] y1 y2) . (b1 b2 : Bool) . (bR :[ Bool] b1 b2) . PR b1 b2 bR (Bool-elim \nP1 x1 y1 b1) (Bool-elim P2 x2 y2 b2) [ Bool-elim] P1 P2 PR x1 x2 xR y1 y2 yR =[ Bool] -elim (.b1 b2 bR \n. PR b1 b2 bR (Bool-elim P1 x1 y1 b1) (Bool-elim P2 x2 y2 b2)) xR yR lists For List, as introduced in \nFigure 2, we have the following translation: data [ List] ([[A : *]]): [ *] (List A) where [ nil] : [ \nList A] (nil A) [ cons] : [ A . List A . List A] (cons A) or after expansion (for n =2): data [ List] \n(A1 A2 : *)(AR :[ *] A1 A2): List A1 . List A2 . * where [ nil] : [ List] A1 A2 AR (nil A1)(nil A2) [ \ncons] :(x1 : A1) . (x2 : A2) . (xR : AR x1 x2) . (xs1 : List A1) . (xs2 : List A2) . (xsR :[ List] A1 \nA2 AR xs1 xs2) . [ List] A1 A2 AR (cons A1 x1 xs1) (cons A2 x2 xs2) The above de.nition encodes the same \nrelational action as that given in Section 4.2. Again, the difference is that the derivation of a relation \nbetween lists l1 and l2 is available as an object of type [ List] A1 A2 AR l1 l2. proof terms The proof \nterm for the list-rearrangement example can be constructed in a similar way to the inductive one. The \nmain difference is that the target lists are also built and recorded in the [ List] structure. In short, \nthis version has more of a computational .avour than the inductive version. [ odds] : [[(A : *) . List \nA . List A] odds odds [ odds] A1 A2 AR nil nil [ nil] = [ nil] A1 A2 AR [ odds] A1 A2 AR (cons nil)(cons \nnil) ([[cons] x1 x2 xR nil nil [ nil]]) = [ cons] A1 A2 AR x1 x2 xR (nil A1)(nil A2) ([[nil] A1 A2 AR) \n[ odds] A1 A2 AR (cons (cons )) (cons (cons )) ([[cons] x1 x2 xR xs1 xs2 ([[cons] xs1 xs2 xsR)) = [ \ncons] A1 A2 AR x1 x2 xR (odds A1 xs1)(odds A2 xs2) ([[odds] A1 A2 AR xs1 xs2 xsR)  vectors We can apply \nthe same translation method to inductive families. For example, Figures 4 and 5 give the translation \nof the family Vec, corresponding to lists indexed by their length. The relation obtained by applying \n[ ] encodes that vectors are related if their lengths are the same and if their elements are related \npoint\u00adwise. The difference with the List version is that the equality of lengths is encoded in [ consV \n] as a Nat (identity) relation. 5. Applications In this section we shall see how examples going beyond \nWadler [1989] can be expressed in our setting. All examples .t within the system I. augmented with inductive \nde.nitions. 5.1 Type classes What if a function is not parametrized over all types, but only types equipped \nwith decidable equality? One way to model this difference in a pure type system is to add an extra parameter \nto capture the extra constraint. For example, a function nub : Nub removing duplicates from a list may \nbe given the following type: Nub =(A : *) . Eq A . List A . List A The equality requirement itself may \nbe modelled as a mere comparison function: Eq A = A . A . Bool. In that case, the parametricity statement \nis amended with an extra requirement on the relation between types, which expresses that eq1 and eq2 \nmust respect the AR relation. Formally: [ Eq A] eq1 eq2 =(a1 : A1) . (a2 : A2) . AR a1 a2 . (b1 : A1) \n. (b2 : A2) . AR b1 b2 . [ Bool] (eq1 a1 b1)(eq2 a2 b2) [ Nub] n1 n2 = (A1 A2 : *) . (AR :[ *] A1 A2) \n. (eq1 : Eq A1) . (eq2 : Eq A2) . [ Eq A] eq1 eq2 . (l1 : List A1) . (l2 : List A2) . [ List A] l1 l2 \n. [List A] (n1 A1 eq1 l1)(n2 A2 eq2 l2) So far, this is just con.rming the informal description in Wadler \n[1989]. But with access to full dependent types, one might wonder: what if we model equality more precisely, \nfor example by requiring eq to be re.exive? Eq ' A =(eq : A . A . Bool) \u00d7 Re. eq Re. eq =(x : A) . eqx \nx = true In the case of Eq ', the parametricity condition does not become more exciting. It merely requires \nthe proofs of re.exivity at A1, A2 to be related. This extra condition adds nothing new: since there \nis at most one element in (and thus proof of) x = y, one already expects proofs to be related. The observations \ndrawn from this simple example can be gener\u00adalized in two ways. First, proof arguments do not strengthen \npara\u00admetricity conditions in useful ways. One often does not care about the actual proof of a proposition, \nbut merely that it exists, so know\u00ading that two proofs are related adds nothing. Secondly, type-classes \n data [Vec] ([[A : *]]): [ Nat . *] (Vec A) where nilV ] :[ Vec A zero] (nilV A)[ consV ] : [[(x : A) \n. (n : Nat) . Vec An . Vec A (succ n)]] (consV A) data [Vec] (A1 A2 : *)(AR : A1 . A2 . *):(n1 n2 : Nat) \n. (nR :[ Nat] n1 n2) . Vec A1 n1 . Vec A2 n2 . * where [nilV ] : [Vec] A1 A2 AR zero zero [ zero] (nilV \nA1)(nilV A2) [consV ] :(x1 : A1) . (x2 : A2) . (xR : AR x1 x2) . (n1 : Nat) . (n2 : Nat) . (nR :[ Nat] \nn1 n2) . (xs1 : Vec A1 n1) . (xs2 : Vec A2 n2) . (xsR : [Vec] A1 A2 AR n1 n2 nR xs1 xs2) . [Vec] A1 A2 \nAR (succ n1)(succ n2)([succ] n1 n2 nR)(consV A1 x1 n1 xs1)(consV A2 x2 n2 xs2) Figure 4. Inductive translation \nof Vec, both before and after expansion. [ Vec-elim ] : [ (A : *) . (P :(n : Nat) . Vec n A . *) . (en \n: P zero (nilV A)) . (ec :(x : A) . (n : Nat) . (xs : Vec n A) . P n xs . P (succ n)(consV Ax nxs)) . \n (n : Nat) . (v : Vec n A) . Pnv] Vec-elim [ Vec-elimAP enec] =[ Vec] -elim A AR (. [n : Nat, v : Vec \nn A] . [Pnv] (Vec-elim AP en ec v)) enR (. [x : A, n : Nat, xs : Vec n A] . [ecx nxs] (Vec-elim AP en \nec xs)) Figure 5. Proof term for Vec-elim using the inductive-style de.nitions. may be encoded as their \ndictionary of methods [Wadler and Blott 1989]. Indeed, even if a type class has associated laws, they \nhave little impact on the parametricity results.  5.2 Constructor classes Having seen how to apply our \nframework both to type constructors and type classes, we now apply it to types quanti.ed over a type \nconstructor, with constraints. Voigtl\u00a8ander [2009b] provides many such examples, using the Monad constructor \nclass. They .t well in our framework. For the sake of brevity, we do not detail them more here. We can \nhowever detail the de.nition of the simpler Functor class, which can be modelled as follows: Functor \n=(F : * . *) \u00d7 ((XY : *) . (X . Y ) . FX . FY ) Our translation readily applies to the above de.nition, \nand yields the following relation between functors: [ Functor] (F1, map1)(F2, map2) =(FR :(A1 A2 : *) \n. (AR : A1 . A2 . *) . (F1 A1 . F2 A2 . *)) \u00d7 ((X1 X2 : *) . (XR : X1 . X2 . *) . (Y1 Y2 : *) . (YR \n: Y1 . Y2 . *) . (f1 : X1 . Y1) . (f2 : X2 . Y2) . ((x1 : X1) . (x2 : X2) . (xR : XR x1 x2) . YR (f1 \nx1)(f2 x2)) . (y1 : F1 X1) . (y2 : F2 X2) . (yR : FR XR y1 y2) . FR YR (map1 f1 y1)(map2 f2 y2)) In words, \nthe translation of a functor is the product of a rela\u00adtion transformer (FR) between functors F1 and F2, \nand a witness (mapR) that map1 and map2 preserve relations. Such Functors can be used to de.ne a generic \nfold operation, which typically takes the following form: data \u00b5 ((F , map): Functor): * where In : F \n(\u00b5 (F, map)) . \u00b5 (F, map) fold : ((F , map): Functor) . (A : *) . (FA . A) . \u00b5 (F , map) . A fold (F, \nmap) A f (In d)= f (map (\u00b5 (F , map)) A (fold (F , map) A f) d)  Note that the \u00b5 datatype is not strictly \npositive, so its use would be prohibited in many dependently-typed languages to avoid incon\u00adsistency. \nHowever, if one restricts oneself to well-behaved functors (yielding strictly positive types), then consistency \nis restored both in the source and target systems, and the parametricity condition derived for fold is \nvalid. One can see from the type of fold that it behaves uniformly over (F , map) as well as A. By applying \n[ ] to fold and its type, this observation can be expressed (and justi.ed) formally and used to reason \nabout fold. Further, every function de.ned using fold, and in general any function parametrized over \nany functor enjoys the same kind of property. Gibbons and Paterson [2009] previously made a similar obser\u00advation \nin a categorical setting, showing that fold is a natural trans\u00adformation between higher-order functors. \nTheir argument heavily relies on categorical semantics and the universal property of fold, while our \ntype-theoretical argument uses the type of fold as a start\u00ading point and directly obtains a parametricity \nproperty. However some additional work is required to obtain the equivalent property using natural transformations \nand horizontal compositions from the parametricity property. 5.3 Generic cast Continuing to apply our \nframework to terms of increasingly rich types, the next candidate is dependently typed. An important \napplication of dependent types is that of generic programming with universes, as in the work of Altenkirch \nand McBride [2003]; Benke et al. [2003]. The basic idea is to represent the universe of types as data, \nand provide an interpretation func\u00adtion from values of this data type to types (in *). Generic functions \ncan then be written by pattern matching on the type representation. While universes usually capture large \nclasses of types, we use as an example a very simple universe of types for Booleans and natural numbers, \nas follows.4 data U : * 1 where bool : U nat : U El : U . * El bool = Bool El nat = Nat An example of \na dependently-typed, generic function is gcast, which for any type context F and any two (codes for) \ntypes u and t, returns a casting function between F (El u) and F (El t), if u and t are the same (and \nnothing otherwise). gcast :(F : * . *) . (ut : U ) . Maybe (F (El u) . F (El t)) gcast F bool bool = \njust (. x . x) gcast F nat nat = just (. x . x) gcast F = nothing data Maybe (A : *): * where nothing \n: Maybe A just : A . Maybe A The function gcast is deemed safe if it returns the identity function whenever \nit returns something. Vytiniotis and Weirich [2009] show that this theorem can be deduced from the type \nof gcast alone, by parametricity. While the result can be re-derived in a simple way by reasoning directly \non the de.nition of gcast, there is a good reason for using parametricity: as the universe is extended \nto a realistic de.nition, the de.nition of gcast gets more complex, but its type remains the same, and \ntherefore the argument relying on parametricity is unchanged. The rest of this section is devoted to \nrederiving the result using our framework. The .rst step is to encode the theorem. We can encode that \nan arbitrary function f : A . B is the identity as the formula (x : A) . fx ~x. Note that because the \ninput and = output types of the cast are not de.nitionally equal, we must use a heterogeneous equality \n(~ =), de.ned as follows: data ~(A : *)(a : A):(B : *) . B . * where = ' ~ re. := AaAa Now, gcast is \nnot a direct conversion function: sometimes it returns no result; its result is wrapped in Maybe. Hence \nwe use a helper function to lift the identity predicate to a Maybe type: onMaybe :(A : *) . (A . *) . \nMaybe A . * onMaybe A P nothing = T onMaybe A P (just a)= Pa The theorem can then be expressed as follows: \nTheorem 3 (gcast is safe). (F : * . *) . (ut : U ) . (x : F (El u)) . onMaybe (F (El u) . F (El t)) (. \ncast . cast x ~x) = (gcastF ut) 4 For the present section, U : * would be suf.cient, but we de.ne U \n: *1 to permit a different de.nition of [ U ] in the next section. We remark that onMaybe is in fact \nthe deductive version of [ Maybe] , for the unary version of [ ] . We take this as a hint to use the \nunary version of [ ] , and derive relations of the following types: [ U ] : U . *1 [ El] :(u : U ) . \n(uR :[ U ] u) . [ *] (El u) [ gcast] :(F : * . *) . (FR :[ * . *] F) . (u : U ) . (uR :[ U ] u) . (t \n: U ) . (tR :[ U ] t) . [ Maybe] (F (El u) . F (El t)) (. cast . (x : F (El u)) . FR (El u) ([[El] u \nuR) x . FR (El t) ([[El] t tR)(cast x)) (gcastF ut) Additionally, we can de.ne paramU : paramU :(u : \nU ) . [ U ] u paramU bool =[ bool] paramU nat =[ nat]  We can then use [ gcast] to prove the theorem. \nThe idea is to specialize it to the types and relations of interest: lemma1 :(F : * . *) . (ut : U ) \n. (x : F (El u)) . [ Maybe] (F (El u) . F (El t)) '' ~ (. cast . (x : F (El u)) . x = x . ' ~ cast x \n= x) (gcastF ut) ~ lemma1 F utx =[ gcast] F (.tR y . y = x) u (paramU u) t (paramU t) ' ~ By .xing \nx ' to x in the argument to [ Maybe] , the condition x = x is ful.lled, and the proof is complete. The \nremarkable feature of this proof is that it is essentially independent of the de.nitions of U and El: \nonly their types matter. Adding constructors in U would not change anything in the proof: [ gcast] isolates \nTheorem 3 from the actual de.nitions of U , El and gcast; it can be generated automatically from gcast. \nIn summary, we have proved the correctness of gcast in three steps: 1. Model representation types within \nour dependently-typed lan\u00adguage; 2. use [ ] to obtain parametricity properties of any function of interest; \n 3. prove correctness by using the properties.  We think that the above process is an economical way \nto work with parametricity for extended type systems. Indeed, step one of the above process is becoming \nan increasingly popular way to develop languages with exotic type systems as an embedding in a dependently-typed \nlanguage [Oury and Swierstra 2008]. By providing (an automatic) step two, we hope to spare language designers \nthe effort to adapt Reynolds abstraction theorem for new type systems in an ad-hoc way. 5.4 A partially \nconstrained universe So far we have only seen universes which are either completely un\u00adconstrained (like \n*) and translate to arbitrary relations, or universes which are completely constrained (like Bool or \nU in the previ\u00adous section) and translate to the identity relation. In this section we show that a middle \nground is also possible. Suppose that we want the same universe as in the above section, but with only \nlimited capabilities to dispatch on the type. That is, we allow users to de.ne functions that have special \nbehaviour for Booleans, but are otherwise oblivious to the actual type at which they are used. This particular \nfunctionality may be encoded by only providing an eliminator for U with restricted capabilities: typeTest \n:(u : U ) . (F : * . *) . F Bool . ((A : *) . FA) . F (El u) typeTest bool F AB AGen = AB typeTest t \nF AB AGen = AGen (El t) This restriction of elimination allows us to relax the de.nitions of [ U ] and \n[ El] , by translating the cases that do not involve bool to an arbitrary relation (for n =2): [ U ] \n: U . U . *1 [ U ] bool bool = T [ U ] bool = . [ U ] bool = . [ U ] u1 u2 =[ *] (El u1)(El u2) \n [ El] :(u1 u2 : U ) . (uR :[ U ] u1 u2) . [ *] (El u1)(El u2) [ El] bool bool r =[ Bool] [ El] u1 u2 \nr = r Given the above de.nitions, free theorems involving U reduce to the constrained case if presented \nwith Booleans, and to the unconstrained case otherwise. While the above is a toy example, it points the \nway towards more sophisticated representations of universes. An example would be an encoding of fresh \nabstract type variables, as in Neis et al. [2009]. 6. Discussion 6.1 Proof A detailed sketch of the proof \nof Theorem 1 is available online [Bernardy et al. 2010b]. Beyond the pen-and-paper version, we also have \na machine-checked proof, for the unary case, as an Agda pro\u00adgram [Bernardy 2010]. A few improvements \nare necessary before it can be considered a fully-machine-checked proof: some substitution lemmas need \nto be proved;  the top-level structure needs some super.cial restructuring to pass the termination-check \nof the Agda system;  proofs of some lemmas given by Barendregt [1992] should be formalized.  6.2 Different \nsource and target sorts Even though the sort-mapping function s used in all our examples has been the \nidentity, there are other possible choices. For example, I. is re.ective with *si = * i+k, for any natural \nk. Other examples can be constructed by mapping s to fresh sorts. The following system (I. +) is re.ective \nwith *si = \u00a3i and \u00a3 i = \u00a3i. De.nition 7 (I. +). I. + is a PTS with this speci.cation: S = {*i | i . \nN} . {\u00a3i | i . N}  A = {\u00a3i : \u00a3i+1 | i . N}.{*i : *i+1 | i . N}  R = {(*i,*j ,*max(i,j)) | i, j . N} \n{(\u00a3i, \u00a3j , \u00a3max(i,j)) | i, j . N} {* i r \u00a3j | i \" j . N}   6.3 Different source and target systems \nFor simplicity, we have chosen to use the same source and target PTS in Theorem 1. However, the theorem \nmay be generalized to the case where source and target are different. One way to relax the hypothesis \nis to allow any source PTS which is a subsystem of the target one, keeping the same conditions for the \ntarget PTS. For example, using this generalization, we see that all the para\u00admetricity statements about \nterms in the .-cube are expressible and provable in the generalized calculus of constructions (CC.). \nIn\u00addeed, we observe that CC. is re.ective with s = s and,  All eight systems of the .-cube are embedded \nin CC.  While extending our abstraction to subsystems is useful, further generalization is possible. \nFor example, parametricity theorems (and proofs) generated from terms in the .-cube will never use the \nhigher sorts of CC.. Specifying necessary and suf.cient conditions for the two-system case is left as \nfuture work. 6.4 Internalizing the meta-theorem Theorem 1 and Corollary 2 (f A : B =.f [ A] : [ B] A) \nare meta-theorems. One can instantiate the corollary by choosing spe\u00adci.c terms A and B; then [ A] is \na proof of [ B] A in the system, de\u00adrived from the structure of f A : B. Our examples consist of many \nsuch instantiations. However, one would like to go further and make a general statement about about all \nvalues of type B within the system. That is, for a type B, to de.ne paramB :(.x : B. [ B] x ... x), as \nwe did with paramU in Section 5.3, essentially making the semantics of the type available for reasoning \nwithin the system. In particular, for any constant k : B, we could de.ne [ k] = paramB k. One way to \nproceed is to assert parametricity at all types, with a constant paramB for each B. This approach was \napplied to CC by Takeuti [2004], extending similar axiom schemes for System F by Plotkin and Abadi [1993]. \nFor each a : D and P : a, Takeuti de.ned a relational interpretation (P) and a kind (|P : a|) such that \n(P) :(|P : a|). Then for each type T : *, he postulated an axiom paramT :(.x : T. (T) xx), conjecturing \nthat such axioms did not make the system inconsistent. For closed terms P, Takeuti s translations (P) \nand (|P : a|) resemble our [ P] and [ a] P respectively (with n =2), but the pattern is obscured by an \nerror in the translation rule for the product D r *, and the omission of a witness xR for the relationship \nbetween values x1 and x2 in the rules corresponding to the product * r D. Another approach would be to \nprovide access to the terms via some form of re.ection. 6.5 Related work Some of the many studies of \nparametricity have already been men\u00adtioned and analysed in the rest of the paper. In this section we \ncom\u00adpare our work to only a couple of the most relevant pieces of work. One direction of research is \nconcerned with parametricity in extensions of System F. Our work is directly inspired by Vytiniotis and \nWeirich [2010], which extend parametricity to (an extension of) F.: indeed, F. can be seen as a PTS with \none more product rule than System F. Besides supporting more sorts and function spaces, an orthogo\u00adnal \nextension of parametricity theory is to support impure features in the system. For example, [Johann and \nVoigtl\u00a8ander 2005] stud\u00adied how explicit strictness modi.es parametricity results. It is not obvious \nhow to support such extensions in our framework. Another direction of research is concerned with better \nunder\u00adstanding of parametricity. Here we shall mention only [Wadler 2007], which gives a particularly \nlucid presentation of the abstrac\u00adtion theorem, as the inverse of Girard s Representation theorem [Girard \n1972]. Our version of the abstraction theorem differs in the following aspects compared to that of Wadler \n(and to our knowl\u00adedge all others): 1. Instead of targeting a logic, we target its propositions-as-types \ninterpretation, expressed in a PTS.  2. We abstract from the details of the systems, generalizing to \na class of PTS s. 3. We add that the translation function used to interpret types as relations can also \nbe used to interpret terms as witnesses of those relations. In short, the [ A] part of G f A : B =. [[G]] \nf [ A] : [ B] A is new. This additional insight depends heav\u00adily on using the propositions-as-types interpretation. \n It also appears that the function [ ] (for the unary case) has been discovered independently by Monnier \nand Haguenauer [2010], for a very different purpose. They use [ ] as a compilation function from CC to \na language with singleton types only, in order to en\u00adforce phase-distinction. Type preservation of the \ntranslation scheme is the main formal property presented by Monnier and Haguenauer. We remark that this \nproperty corresponds to the abstraction theo\u00adrem for CC.  6.6 Future work Our explanation of parametricity \nfor dependent types has opened a whole range of interesting topics for future work. We should investigate \nwhether our framework can be applied (and extended if need be) to more exotic systems, for example those \nincorporating strictness annotations (seq) or non-termination. We should extend our translation to support \nnon-informative function spaces, as found for example in Coq. In Coq, the sort * of CC is split into \ntwo separate sorts, one for types (Set) and one for propositions (Prop). Inhabitants of Set can depend \non inhabitants of Prop: for example, a program may depend on a certain property to terminate. However, \ncomputational content can never leak from Prop to Set: programs may only depend on the existence of a \nproof; it is forbidden to inspect their structure. In such a situation, our translation scheme appears \nto generate parametricity results that are too weak, as we have brie.y alluded to in Section 5.1. The \nreason is that we always assume that computational content may be transferred from the argument of a \nfunction to its result. We could modify the translation to omit the super.uous relation parameter in \nsuch cases. Reynolds abstraction theorem can be understood as an embed\u00adding of polymorphic lambda calculus \ninto second order proposi\u00adtional logic. Wadler [2007] showed that Girard s representation the\u00adorem [Girard \n1972] can be understood as the corresponding pro\u00adjection. In this work we have shown that the embedding \ncan be generalized for more complex type systems. The question of how the projection generalizes naturally \narises, and should also be ad\u00addressed. It is straightforward to derive translated types using our schema, \nbut tedious. Providing [ ] as a meta-function would greatly ease experimentation with our technique. \nAnother direction worth ex\u00adploring is to provide the parametricity axiom (param ) as a meta\u00adfunction \nin a logical framework. We presented only simple examples. Applying the results to more substantial applications \nshould be done as well. 7. Conclusion We have shown that it is not only possible, but easy to derive \nparametricity conditions in a dependently-typed language. Further, it is possible to analyse parametricity \nproperties of custom languages, via their embedding in a dependently-typed host language. Acknowledgments \nThanks to Andreas Abel, Thierry Coquand, Peter Dybjer, Marc Lasson, Guilhem Moulin, Ulf Norell, Nicolas \nPouillard and anony\u00admous reviewers for providing us with very valuable feedback. References T. Altenkirch \nand C. McBride. Generic programming within dependently typed programming. In Proc. of the IFIP TC2/WG2.1 \nWorking Confer\u00adence on Generic Programming, pages 1 20. Kluwer, B.V., 2003. H. P. Barendregt. Lambda \ncalculi with types. Handbook of logic in computer science, 2:117 309, 1992. M. Benke, P. Dybjer, and \nP. Jansson. Universes for generic programs and proofs in dependent type theory. Nordic J. of Computing, \n10(4):265 289, 2003. J.-P. Bernardy. A proof of the abstraction theorem for pure type sys\u00adtems (unary \ncase). http://www.cse.chalmers.se/~bernardy/ParDep/html/ Theorem.html, 2010. J.-P. Bernardy, P. Jansson, \nand K. Claessen. Testing polymorphic properties. In Proc. of ESOP 2010, volume 6012 of LNCS. Springer, \n2010a. J.-P. Bernardy, P. Jansson, and R. Paterson. An abstraction theorem for pure type systems. Available \nfrom http://www.cse.chalmers.se/~bernardy/ ParDep/abstraction-pts.pdf, 2010b. C. B\u00a8ohm and A. Berarducci. \nAutomatic synthesis of typed lambda\u00adprograms on term algebras. Theor. Comp. Sci., 39(2-3):135 154, 1985. \nT. Coquand. An analysis of Girard s paradox. In Proc. of LICS 1986, pages 227 236. IEEE Comp. Society \nPress, 1986. T. Coquand. Pattern matching with dependent types. In Proc. of the Workshop on Types for \nProofs and Programs, pages 66 79, 1992. P. Dybjer. Inductive families. Formal Aspects of Computing, 6(4):440 \n465, 1994. J. Gibbons and R. Paterson. Parametric datatype-genericity. In Proc. of WGP 2009, pages 85 \n93, Edinburgh, Scotland, 2009. ACM. A. Gill, J. Launchbury, and S. L. Peyton Jones. A short cut to deforestation. \nIn Proc. of FPCA, pages 223 232, Copenhagen, Denmark, 1993. ACM. J. Y. Girard. Interpr\u00b4etation fonctionnelle \net elimination des coupures de l arithmetique d ordre sup\u00b4erieur\u00b4. Th`ese d \u00b4etat, Universit\u00b4e de Paris \n7, 1972. R. Hinze. Church numerals, twice! J. Funct. Program., 15(1):1 13, 2005. P. Johann. A generalization \nof short-cut fusion and its correctness proof. Higher-Order and Symbol. Comput., 15(4):273 300, 2002. \nP. Johann and J. Voigtl\u00a8ander. The impact of seq on free theorems-based program transformations. Fundam. \nInf., 69(1-2):63 102, 2005. C. McBride and J. McKinna. The view from the left. J. Funct. Program., 14(01):69 \n111, 2004. A. Miquel. Le Calcul des Constructions implicite: syntaxe et s\u00b4emantique. Th`e Paris 7, 2001.ese \nde doctorat, Universit\u00b4 S. Monnier and D. Haguenauer. Singleton types here, singleton types there, singleton \ntypes everywhere. In Proc. of PLPV 2010, pages 1 8, Madrid, Spain, 2010. ACM. G. Neis, D. Dreyer, and \nA. Rossberg. Non-parametric parametricity. In Proc. of ICFP 2009, pages 135 148, Edinburgh, Scotland, \n2009. ACM. U. Norell. Towards a practical programming language based on dependent type theory. PhD thesis, \nChalmers Tekniska H\u00a8ogskola, 2007. N. Oury and W. Swierstra. The power of Pi. In Proc. of ICFP 2008, \npages 39 50, Victoria, BC, Canada, 2008. ACM. C. Paulin-Mohring. Inductive de.nitions in the system Coq \n rules and properties. In Typed Lambda Calculi and Applications, pages 328 345. Springer, 1993. G. Plotkin \nand M. Abadi. A logic for parametric polymorphism. In LNCS, volume 664, page 361 375. Springer-Verlag, \n1993. J. C. Reynolds. Types, abstraction and parametric polymorphism. Informa\u00adtion processing, 83(1):513 \n523, 1983. I. Takeuti. The theory of parametricity in lambda cube. Manuscript, 2004. The Coq development \nteam. The Coq proof assistant, 2010. J. Voigtlander.\u00a8Bidirectionalization for free! (Pearl). In Proc. \nof POPL 2009, pages 165 176, Savannah, GA, USA, 2009a. ACM. J. Voigtl\u00a8ander. Free theorems involving \ntype constructor classes: Funct. pearl. SIGPLAN Not., 44(9):173 184, 2009b. G f A : B =. [[G]] f [ A] \n: [ B] A axiom f s : s ' f (.x : s. x . s ) : s . ss ' start G f A : s G, x : A f x : A [[G]] f [ A] \n: A . s [[G]], x : A, xR : [ A] x f xR : [ A] x weakening G f A : B G f C : s G, x : C f A : B [[G]] \nf [ A] : [ B] A [[G]] f [ C] : C . s [[G]], x : C, xR : [ C] x f [ A] : [ B] A product G f A : s1 G, \nx : A f B : s2 G f (.x : A. B) : s3 [[G]] f [ A] : A . ss1 [[G]], x : A, xR : [ A] x f [ B] : B . ss2 \n[[G]] f (.f : (.x : A. B). .x : A. .xR : [ A] x. [ B] (f x)) :(.x : A. B) . s 3 application G f F : (.x \n: A. B) G f a : A G f F a : B[x . a] [[G]] f [ F] : (.x : A. .xR : [ A] x. [ B] (F x)) [[G]] f [ a] : \n[ A] a [[G]] f [ F] a [ a] : [ B[x . a]]] (F a) abstraction G f A : s1 G, x : A f B : s2 G, x : A f b \n: B G f (.x : A. b) : (.x : A. B) [[G]] f [ A] : A . ss1 [[G]], x : A, xR : [ A] x f [ B] : B . ss2 [[G]], \nx : A, xR : [ A] x f [ b] : [ B] b [[G] f (.x : A. .xR : [ A] x. [ b]]) : (.x : A. .xR : [ A] x. [ B] \nb) conversion G f A : B G f B ' : s B = \u00df B ' G f A : B ' [[G]] f [ A] : [ B] A [[G]] f [ B ' ] : B' \n. s [ B] =\u00df [ B ' ] [[G]] f [ A] : [ B ' ] A Figure 6. Outline of a proof of Theorem 1 by induction \nover the derivation of G f A : B. D. Vytiniotis and S. Weirich. Type-safe cast does no harm: Syntactic \nparametricity for F. and beyond. Preliminary version of Parametricity, Type Equality and Higher-order \nPolymorphism , 2009. D. Vytiniotis and S. Weirich. Parametricity, type equality, and higher-order polymorphism. \nJ. Funct. Program., 20(2):175 210, 2010. P. Wadler. Theorems for free! In Proc. of FPCA 1989, pages 347 \n359, Imperial College, London, United Kingdom, 1989. ACM. P. Wadler. The Girard Reynolds isomorphism. \nTheor. Comp. Sci., 375(1 3):201 226, 2007. P. Wadler and S. Blott. How to make ad-hoc polymorphism less \nad hoc. In POPL 89, pages 60 76. ACM, 1989. A. Proof of the abstraction theorem In this appendix we \nsketch the proof of our main theorem, using the following lemma: Lemma 4 (translation preserves \u00df-reduction). \nA -.\u00df * A ' =. [ A] -.\u00df * [ A ' ]  Proof sketch. The proof proceeds by induction on the derivation of \nA -. * \u00df A '. The interesting case is where the term A is a \u00df\u00adredex (.x : B. C) b. That case relies on \nthe way [ ] interacts with substitution: [ b[x . C]]]= [ b]][x . C][xR . [ C]]] The remaining cases \nare congruences. Theorem (abstraction). In a re.ective PTS, G f A : B =. [[G]] f [ A] : [ B] A Proof \nsketch. A derivation of [[G]] f [ A] : [ B] A is constructed by induction on the derivation of G f A \n: B, using the syntactic prop\u00aderties of PTSs. We have one case for each typing rule: each type rule translates \nto a portion of a corresponding relational typing judge\u00adment, as shown in Figure 6. For convenience, \nthe proof uses a variant form of the abstrac\u00adtion rule; equivalence of the two systems follows from Barendregt \n[1992, Lemma 5.2.13]. The conversion case uses Lemma 4.    \n\t\t\t", "proc_id": "1863543", "abstract": "<p>Reynolds' abstraction theorem shows how a typing judgement in System F can be translated into a relational statement (in second order predicate logic) about inhabitants of the type. We (in second order predicate logic) about inhabitants of the type. We obtain a similar result for a single lambda calculus (a pure type system), in which terms, types and their relations are expressed. Working within a single system dispenses with the need for an interpretation layer, allowing for an unusually simple presentation. While the unification puts some constraints on the type system (which we spell out), the result applies to many interesting cases, including dependently-typed ones.</p>", "authors": [{"name": "Jean-Philippe Bernardy", "author_profile_id": "81372591366", "affiliation": "Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden", "person_id": "P2338230", "email_address": "", "orcid_id": ""}, {"name": "Patrik Jansson", "author_profile_id": "81100413171", "affiliation": "Chalmers University of Technology and University of Gothenburg, Gothenburg, Sweden", "person_id": "P2338231", "email_address": "", "orcid_id": ""}, {"name": "Ross Paterson", "author_profile_id": "81100274068", "affiliation": "City University, London, United Kingdom", "person_id": "P2338232", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863592", "year": "2010", "article_id": "1863592", "conference": "ICFP", "title": "Parametricity and dependent types", "url": "http://dl.acm.org/citation.cfm?id=1863592"}