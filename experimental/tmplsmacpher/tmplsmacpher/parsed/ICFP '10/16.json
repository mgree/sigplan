{"article_publication_date": "09-27-2010", "fulltext": "\n Security-Typed Programming within Dependently Typed Programming Jamie Morgenstern* Daniel R. Licata \n* Carnegie Mellon University {jamiemmt,drl}@cs.cmu.edu Abstract Several recent security-typed programming \nlanguages, such as Aura, PCML5, and Fine, allow programmers to express and en\u00adforce access control and \ninformation .ow policies. In this paper, we show that security-typed programming can be embedded as a \nlibrary within a general-purpose dependently typed programming language, Agda. Our library, Aglet, accounts \nfor the major fea\u00adtures of existing security-typed programming languages, such as decentralized access \ncontrol, typed proof-carrying authorization, ephemeral and dynamic policies, authentication, spatial \ndistribu\u00adtion, and information .ow. The implementation of Aglet consists of the following ingredients: \nFirst, we represent the syntax and proofs of an authorization logic, Garg and Pfenning s BL0, using dependent \ntypes. Second, we implement a proof search procedure, based on a focused sequent calculus, to ease the \nburden of con\u00adstructing proofs. Third, we represent computations using a monad indexed by pre-and post-conditions \ndrawn from the authorization logic, which permits ephemeral policies that change during execu\u00adtion. We \ndescribe the implementation of our library and illustrate its use on benchmark examples considered in \nthe literature. Categories and Subject Descriptors F.3.3 [Logics and Meanings Of Programs]: Studies of \nProgram Constructs Type structure; F.3.1 [Logics and Meanings Of Programs]: Specifying and Veri\u00adfying \nand Reasoning about Programs General Terms Languages, Security, Veri.cation 1. Introduction Security-typed \nprogramming languages allow programmers to specify and enforce security policies, which describe both \naccess control who is permitted to access sensitive resources? and in\u00adformation .ow what are they permitted \nto do with these resources once they get them? Aura [24] and PCML5 [9] enforce access con\u00ad * This research \nwas sponsored in part by the National Science Foundation under grants CCF-0702381 and CNS-0716469, and \nby the Pradeep Sindhu Computer Science Fellowship. The views and conclusions contained in this document \nare those of the author and should not be interpreted as repre\u00adsenting the of.cial policies, either expressed \nor implied, of any sponsoring institution, the U.S. government or any other entity. Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 10, September 27 29, \n2010, Baltimore, Maryland, USA. Copyright c &#38;#169; 2010 ACM 978-1-60558-794-3/10/09. . . $10.00 trol \nusing dependently typed proof-carrying authorization (PCA): the run-time system requires every access \nto a sensitive resource be accompanied by a proof of authorization [7], while the type sys\u00adtem aids programmers \nin constructing correct proofs. Fable [37] and Jif [14] enforce information .ow properties using type \nsystems that restrict the use of values that depend on private information. Fine [38] combines these \ntechniques to enforce both. These lan\u00adguages type systems employ a number of advanced techniques, such \nas dependently typed authorization proofs, indexed monads of computations at a place and on behalf of \na principal [8], infor\u00admation .ow types, and af.ne types for ephemeral security policies. Dependently \ntyped programming languages provide a rich lan\u00adguage of type-level data and computation. One promising \nappli\u00adcation of dependent types is constructing domain-speci.c type sys\u00adtems as libraries, rather than \nnew language designs this allows the language designer to exploit the implementation, metatheory, and \ntools of the host language. In this paper, we apply this methodology to security typed programming, and \nshow that security-typed pro\u00adgramming can be embedded within a general-purpose dependently typed programming \nlanguage, Agda [32]. We implement a library, Aglet, which accounts for the major features of existing \nsecurity\u00adtyped programming languages, such as Aura, PCML5, and Fine: Decentralized Access Control: Access \ncontrol policies are ex\u00adpressed as propositions in an authorization logic, Garg and Pfen\u00adning s BL0 [21]. \nThis permits decentralized access control policies, expressed as the aggregate of statements made by \ndifferent princi\u00adpals about the resources they control. In our embedding, we rep\u00adresent BL0 s propositions \nand proofs using dependent types, and exploit Agda s type checker to validate the correctness of proofs. \nDependently Typed PCA: Primitives that access resources, such as .le system operations, require programmers \nto provide a proof of authorization, which is guaranteed by the type system to be a well-formed proof \nof the correct proposition. Ephemeral and Dynamic Policies: Whether or not one may ac\u00adcess a resource \nis often dependent upon the state of a system. For example, in a conference management server, authors \nmay submit a paper, but only before the submission deadline. Fine accounts for ephemeral policies using \na technique called af.ne types, which re\u00adquires a substructural notion of variables. Because Agda does \nnot currently provide substructurality, we show that one can instead account for ephemeral policies using \nan indexed monad. Following Hoare Type Theory [31], we de.ne a type o G A G', which rep\u00adresents a computation \nthat, given precondition G, returns a value of type A, with postcondition G'. Here, G and G' are propositions \nfrom the authorization logic, describing the state of resources in the system. For example, consider \nthe operation in a conference man\u00adagement server that closes submissions and begins reviewing. We represent \nthis by a computation of type o (InPhase Submission) Unit (InPhase Reviewing) Given the conference is \nin phase Submission, this computation re\u00ad  turns a value of type Unit, and the state of the conference \nhas been changed to Reviewing. For comparison between the approaches, we adapt Fine s conference management \nexample to our indexed monad. Aglet also permits dynamic acquisition and generation of policies e.g., \ngenerating a policy based on reading the state of the conference management server from a database on \nstartup. Authentication: Following previous work by Avijit and Harper [8], we model authentication with \nan indexed monad of computa\u00adtion on behalf of a principal, which tracks the currently authen\u00adticated \nuser. This monad is equipped with a sudo operation for switching users, given appropriate credentials. \nWe show that com\u00adputation on behalf of a principal is a special case of our policy\u00adindexed monad o G \nA G . Spatial distribution: We also show that our policy-indexed monad can be used to model spatial distribution \nas in PCML5. Information Flow: Information .ow policies constrain the use of values based on what went \ninto computing them, e.g. tainting user input to avoid SQL injection attacks. We represent informa\u00adtion \n.ow using well-established techniques, such as indexed mon\u00adads [36] and applicative functors [38]. Compile-time \nand Run-time Theorem Proving: Dependently typed PCA admits a sliding scale between static and dynamic \nver\u00adi.cation. At the static end, one can verify, at compile-time, that a program complies with a statically-given \nauthorization policy. This veri.cation consists of annotating each access to a resource with an authorization \nproof, whose correctness is ensured by type checking. However, in many programs, the policy is not known \nat compile time e.g., the policy may depend upon a system s state. Such pro\u00adgrams may dynamically test \nwhether each operation is permitted before performing it, in which case dependently typed PCA ensures \nthat the correct dynamic checks are made and that failure cases are handled. A program may also mix static \nand dynamic veri.cation: for example, a program may dynamically check that an expected policy is in effect, \nand then, in the scope of that check, deduce con\u00adsequences statically. Security-typed languages use theorem \nprovers to reduce the burden of static proofs (as in Fine) and to implement dynamic checks (as in PCML5). \nWe have implemented a certi.ed theorem prover for BL0, based on a focused sequent calculus. Our theorem \nprover can be run at compile-time and at run-time, ful.ll\u00ading both of these roles. The theorem prover \nalso saves programmers from having to understand the details of the authorization logic, as they often \ndo not need to write proofs manually. The remainder of this paper is organized as follows: In Sec\u00adtion \n2, we show a variety of examples adapted from the litera\u00adture, which demonstrate that Aglet accounts \nfor programming in the style of Aura, PCML5, and Fine. In Section 3, we describe the implementation of \nAglet, including the representation of the logic and the implementation of the theorem prover. We discuss \nrelated work in Section 4 and future work in Section 5. The Agda code for this paper is available from \nhttp://www.cs.cmu.edu/~drl. 2. Examples In this section, we show that Aglet supports security-typed pro\u00adgramming \nin the style of Aura, PCML5, and Fine by implementing a number of the benchmark examples considered in \nthe literature. We brie.y review Agda s syntax, referring the reader to the Agda Wiki(wiki.portal.chalmers.se/agda/). \nDependent function types are written as (x : A) -B. An implicit dependent function space is written {x \n: A} -B or . {x} -B and arguments to implicit functions are inferred. Non-dependent functions are writ\u00adten \nA -B. Anonymous functions are written . e. Named x \u00ad functions are de.ned clausally by pattern matching. \nLists are con\u00adstructed by [] and :: (note that : is used for type annotations). Set is the classi.er \nof classi.ers in Agda. Admin says (.r..o..f. (HR says employee(r) . System says owns(o, f) . o says mayread(r, \nf)) . mayread(r, f)) System says owns(Jamie, secret.txt) HR says employee(Dan) HR says employee(Jamie) \nJamie says mayread(Dan, secret.txt) Jamie says mayread(Jamie, secret.txt) Figure 1. Sample access control \npolicy 2.1 File IO with Access Control First, we show a dependently typed .le system interface, a standard \nexample of security typed programming [8, 38, 39]. 2.1.1 Policy To begin, we specify an authorization \npolicy for .le system opera\u00adtions in BL0 (Figure 1): First, the principal Admin says that for any reader, \nowner, and .le, if human resources says the reader is an em\u00adployee, and the system administrator says \nthe owner owns the .le, and the owner says the reader may read a .le, then the reader may read the .le. \nAdmin is a distinguished principal whose statements will be used to govern .le system operations. Second, \nthe system administrator says Jamie owns secret.txt. Third, human resources says both Dan and Jamie are \nemployees. Fourth, Jamie says Dan and Jamie may read the .le. This policy illustrates decentralized access \ncontrol using the says modality: the policy is the aggregate of statements by different principals about \nresources they control. For the principal Dan to read secret.txt, it will be suf.cient to deduce the \ngoal Admin says mayread(Dan, secret.txt). This proposition is provable from the above policy because \nof three properties of says : First, says is closed under instantiation of universal quanti.ers (that \nis, k says .x.A(x) entails .x.k says A(x)). Second, says distributes over implications (k says (A . B) \nentails ((k says A) . (k says B)). Third, every principal believes that every statement of every other \nprincipal has been made (k says A entails k ' says (k says A)) though it is not the case that every principal \nbelieves that every statement of every other principal is true. Thus, the goal can be proved by using \nthe .rst clause of the policy (Admin says ...), instantiating the quanti.ers, and using the other statements \nin the policy to satisfy the preconditions. In Agda, we represent this .rst clause as the .rst element \nof the following context (list of propositions): Gpolicy = (Prin \"Admin\" says (.e principal \u00b7.e principal \n\u00b7.e filename \u00b7 let owner = . (iS (iS i0)) reader = . (iS i0) file = . i0 in ( ( (Prin \"HR\" says (a-(Employee \n\u00b7 reader))) . (Prin \"System\" says (a-(Owner \u00b7 (owner , file)))) . (owner says (a-(Mayread \u00b7 (reader , \nfile))))) . (a-(Mayread \u00b7 (reader , file)))))) :: (Prin \"Admin\" says (.e principal \u00b7 .e filename \u00b7 (Prin \n\"System\" says (a-(Owner \u00b7 (. iS i0 , . i0)))) . (a-(MayChown \u00b7 (. iS i0 , . i0))))) :: []  The second \nelement of the list expresses an additional policy clause, not discussed above, which states that an \nowner of a .le may change its ownership. Variables are represented as de Bruijn indices (i0, iS), constants \nare represented as injections of strings (Prin \"Admin\"), and atomic propositions are tagged with a po\u00adlarity \n(a+ or a-), which can be thought of as a hint to the theorem prover. Quanti.ers are written .e t \u00b7 A, \nwhere t is the domain of quanti.cation and A is the body of the quanti.er. Atomic proposi\u00adtions are written \np \u00b7 t, where p is a proposition constant such as Mayread and t is a term (see Section 3.1 for details). \nNext, we de.ne a context representing a particular .le system state. This context includes all the employee, \nownership, and may\u00adread facts mentioned above, with one additional clause saying that Dan may su as Jamie. \nGstate = (Prin \"System\" says (a-(Owner \u00b7 (Prin \"Jamie\" , File \"secret\u00b7txt\")))) :: (Prin \"HR\" says (a-(Employee \n\u00b7 (Prin \"Dan\")))) :: (Prin \"HR\" says (a-(Employee \u00b7 (Prin \"Jamie\")))) :: (Prin \"Jamie\" says (a-(Mayread \n\u00b7 (Prin \"Dan\" , File \"secret\u00b7txt\")))) :: (Prin \"Jamie\" says (a-(Mayread \u00b7 (Prin \"Jamie\" , File \"secret\u00b7txt\")))) \n:: (Prin \"Admin\" says (a-(MaySu \u00b7 (Prin \"Dan\" , Prin \"Jamie\")))) :: [] Gall = Gpolicy ++ Gstate Finally, \nwe let Gall stand for the append of Gpolicy and Gstate.  2.1.2 Compile-time Theorem Proving We now explain \nthe use of our theorem prover: goal = a-(Mayread \u00b7 (Prin \"Dan\" , File \"secret\u00b7txt\")) proof? : Maybe (Proof \nGall goal) proof? = prove 15 theProof : Proof Gall goal theProof = solve proof? The term proof? sets \nup a call to the theorem prover, attempting to prove mayread(Dan, secret.txt) using the policy speci.ed \nby Gall. Sequent calculus proofs are represented by an Agda type family (O ; . ; G ; k) f A, where O \nbinds individual vari\u00adables, . is a context of claims assumptions, G is context of truth assumptions, \nand k, the view, is a principal from whose point of view the judgement is made. Informally, the role \nof the view is that, in a sequent whose view is k, k says A entails A; see Section 3.1 for details about \nthe logic. In this example, O and . will always be empty, G will represent a policy, as above, and the \nview k will be Prin \"Admin\" we abbreviate such a sequent by Proof G A. The context and proposition arguments \nto prove can be inferred by Agda, and so are left as implicit arguments. The term theProof checks that \nthe theorem prover succeeds at compile-time in this in\u00adstance. The function solve has type: solve : . \n{A} (s : Maybe A) . {p : Check (isSome s)} . A The argument p, of type Check (isSome s), is a proof that \ns is equal to Some s for some s . Because this argument is implicit, Agda will attempt to .ll it in by \nuni.cation, which will succeed when s is de.nitionally equal to a term of the form Some s . In this example, \nthe call to the theorem prover in the term proof? proves the goal, computing de.nitionally to Some s \nfor a proof s of mayread(Dan, secret.txt). Thus, we can use solve to extract this proof s . In general, \na call to the theorem prover on a context and a proposition that have no free Agda variables will always \nbe equal to either Some p or to None. Generic operations: 0 : TCtx+ [] . (A : Set) . (A . TCtx+ []) . \nSet return : . { G A} . A . 0 G A (\\ _ . G) _>>=_ : . {A B GG G } . (0 G A G ) . ((x : A) 0 (G x) B \nG )  G B G . 0 weakenPre : . {A GG Gn} . (Good Gn . Good G) . 0 G A G . G . Gn . 0 GnA G weakenPost \n: . {A GG Gn} . 0 G A G . ((x : A) . (Gnx . G x)) . ((x : A) -> (Good (G x) . Good (Gn x))) . 0 G A \nGn getLine : . {G} . 0 G String (\\ _ . G) print : . {G} . String . 0 G Unit (\\ _ . G) error : . {A GG \n} . String . 0 G A G acquire : . {A GG } . (Gn : TCtx+ []) . (Good G . Good (Gn ++ G)) . 0 (Gn ++ G)A \nG 0 G A G . 0 G A G File-speci.c operations: sudo : . { G A G .. } . (k1 k2 : _) Replace (a+ (As \u00b7 k1)) \n(a+ (As \u00b7 k2)) G. . ((x : A) . Replace (a+ (As \u00b7 k2)) (a+ (As \u00b7 k1)) (. x) (G x)) . (Proof G (a-(MaySu \n\u00b7 (k1 , k2)))) . 0 . A . . 0 G A G  read : . {G} (k : _) (file : _) . Proof G ( (a-(Mayread \u00b7 (k , \nfile))) . (a+ (As \u00b7 k))) . 0 G String (. _ . G) create : . {G} (k : _) . Proof G ( (a-(User \u00b7 k)) . \n(a+ (As \u00b7 k)))  . 0 G String  (. new . (Prin \"System\" says (a-(Owner \u00b7 (k , File new)))) :: G) chown \n: . { G.} . (k k1 k2 : _) . (f : _) . Replace (Prin \"System\" says (a-(Owner \u00b7 (k1 , f)))) (Prin \"System\" \nsays (a-(Owner \u00b7 (k2 , f)))) G. . (Proof G ( (a+ (As \u00b7 k)) . (a-(MayChown \u00b7 (k , f))))) . 0 G Unit (\\ \n_ . .) Figure 2. File IO with Authorization  2.1.3 Computations We present a monadic interface for \n.le operations in Figure 2. This .gure shows both the generic IO operations, as well as three .le-speci.c \noperations for reading, creating, and changing the owner of a .le. The type o G A G represents a computation \nwith precondition G and postcondition G . The Agda type of a con\u00adtext is TCtx+ [] (a context of positive \ntruth assumptions, with no free individual variables see Section 3.1). The postcondition is a function \nfrom A s to contexts, so the postcondition may depend on the computation s result (see create below). \nThe generic op\u00aderations are typed as follows: Because return is not effectful, its postcondition is its \nprecondition. Bind (>>=) chains together two computations, where the postcondition of the .rst is the \nprecondi\u00adtion of the second. Both pre-and postconditions can be weakened to larger and smaller contexts, \nrespectively; the Good predicate can be ignored until Section 2.1.4 below. Primitives like getLine (reading \na line of input) and print do not change the state and do not require proofs. The postcondition of error \nis arbitrary, as it never terminates successfully. The remaining computations are de.ned as follows: \n Read The function read takes a principal k, a .le f, and a proof argument. The proof ensures that the \nprincipal k is authorized to access the .le (Mayread(k,f)) and that the principal k is the currently \nauthenticated user (As(k)). We use the proposition As to model computation on behalf of a principal [8]. \nThe proof is checked in the context G that is the precondition of the computa\u00adtion, ensuring that it \nis valid in the current state of the world. read delivers the contents of the .le and leaves the state \nunchanged. An example call to read looks like this: Gj= Gall as \"Jamie\" jread : 0 Gj String (. _ Gj) \njread = read (Prin \"Jamie\") (File \"secret\u00b7txt\") (solve (prove 17)) jreadprint : 0 Gj Unit (. _ Gj) jreadprint \n= jread >>= . x print (\"the secret is: \" ^ x) The function call Gall as k is shorthand for adding the \nproposi\u00adtion As(k) to the context Gall. The computation jread reads the .le secret.txt as principal Jamie; \nthe proof argument is sup\u00adplied by a call to the theorem prover, which statically veri.es that the required \nfact is derivable from the policy given by Gall. The computation jreadprint reads the .le and then prints \nthe result. Create The type of create is similar to read, in that it takes a principal and a proof that \nthe principal can create a .le (in this case, the fact that the principal is a registered user is deemed \nsuf.cient). It returns a String, the name of the created .le, and illustrates why postconditions must \nbe allowed to depend on the return value of the computation: the postcondition says that the principal \nis the owner of the newly created .le. Thus, after a call to create(k), the postconditions signify System \nsays Owner(k,f), where f is the name of the new .le. Chown To specify chown, we use a type Replace x \ny G., which means that . is the result of replacing exactly one occur\u00adrence of x in G with y. Replace \n(whose de.nition is not shown) is de.ned by saying that (1) there is a de Bruijn index i showing that \nx is in G and (2) . is equal to the output of the function replace y i, which recurs on the index i and \nreplaces the indicated element by y. The type of chown should be read as follows: if the principal k \nas whom the computation is running has the authority to change the owner of a .le, and replacing owns(k,f) \nwith owns(k , f) in G produces ., then we can produce a computation which changes the owner of f from \nk to k , leaving the remaining context unchanged. Next, we show an example call to chown, using a context \nGstate that is the result of replacing the fact that Jamie owns secret.txt with Dan owning that .le. \nThe computation dchown runs as Dan; it changes the owner of the .le from Dan to Jamie, and then runs \na computation drdprnt, de.ned below, that reads the .le. proveReplace is a tactic used to prove that \nGall is Gall with the ownership of secret.txt changed. solve (prove 15) calls the theorem prover to statically \nverify that Dan has permission to chown secret.txt. Gstate = replace {_} {Gstate} (Prin \"System\" says \n(a-(Owner \u00b7 (Prin \"Dan\" , File \"secret\u00b7txt\")))) i0 Gall = Gpolicy ++ Gstate dchown : 0 (Gall as \"Dan\") \nUnit (. _ Gall as \"Dan\") dchown = chown (Prin \"Dan\") (Prin \"Dan\") (Prin \"Jamie\") (File \"secret\u00b7txt\") \n(solve proveReplace) (solve (prove 15)) >> drdprnt Sudo Following Avijit and Harper [8], we now give \na well-typed version of the Unix command sudo, which allows switching princi\u00adpals during execution. A \n.rst cut for the type of sudo is as follows: sudo1 : . { G A G } (k1k2:_) (Proof G (a-(MaySu \u00b7 (k1 , \nk2)))) 0 ((a+ (As \u00b7 k2)) :: G)A(. _ (a+ (As \u00b7 k2)) :: G ) 0 ((a+ (As \u00b7 k1)) :: G)A(. _ (a+ (As \u00b7 k1)) \n:: G ) If there is a proof that k1 may sudo as k2 (e.g., a password was provided), and As(k1) is in the \nprecondition, then it is permissible to run a subcomputation as k2. This subcomputation has a postcon\u00addition \nsaying that it terminates running as k2, and then the overall computation returns to running as k1. Because \nour contexts are or\u00addered (represented as lists rather than sets), sudo has the type in Figure 2, which \nallows the As facts to occur anywhere in the con\u00adtext. sudo s type may be read: if replacing As(k1) with \nAs(k2) in G equals ., and if replacing As(k2) with As(k1) in . equals G , and k2 has permission to su \nas k1, then a computation with preconditions . and postconditions . can produce a computation with preconditions \nG and postconditions G . The following example call to sudo de.nes a computation as Dan that su s as \nJamie to run the computation jreadprint de\u00ad.ned above: drdprnt : 0 (Gall as \"Dan\") Unit (. _ Gall as \n\"Dan\") drdprnt = sudo (Prin \"Dan\" ) (Prin \"Jamie\") (solve proveReplace) (. _ solve proveReplace) (solve \n(prove 15)) jreadprint This requires proving that Gstate as \"Jamie\" and Gstate as \"Dan\" are related by \nreplacing As(Prin \"Jamie\") with As(Prin \"Dan\") (in both directions). Our tactic proveReplace proves all \nof these equalities. Additionally, the theorem prover statically ver\u00adi.es Dan may su as Jamie under the \npolicy Gall as \"Dan\". Acquire The function acquire allows a program to check whether a proposition is \ntrue in the state of the world. This con\u00adstruct is inspired by acquire in PCML5, but there are slight \ndif\u00adferences: in PCML5, acquire does theorem proving to prove an arbitrary proposition from the policy, \nwhereas here acquire only veri.es the truth of state-dependent atomic facts (which have no evidence) \nand statements of principals (whose only evidence is a digital signature [9, 24]). The function acquire \ntakes two contin\u00aduations: one to run if the check is successful, whose precondition is extended with \nthe proposition, and an error handler, whose pre\u00adcondition is the current context, to run if the check \nfails. In fact, we allow acquire to test an entire context at once: given a context Gn, a computation \nwith preconditions G extended with Gn (the success continuation), and a computation with preconditions \nG (the error continuation), acquire returns a computation with preconditions G. We use the notation acquire \nGn / _ no. s yes. f to write a call to acquire in a pattern-matching style. The _ elides a Good argument, \nwhich is explained below.  main : 0 [] Unit (. _ []) main = acquire (Gall as \"Jamie\") / _ no. error \n\"acquiring policy failed\" yes. weakenPost jreadprint (. _ ()) _ This example call begins and ends in \nthe empty context. The call to acquire examines the system state to check the truth of each of the propositions \nin Gall as \"Jamie\". If all of these are true, then we run jreadprint and use weakening to forget the \npostconditions. If some proposition cannot be veri.ed, then main calls error.  2.1.4 Verifying Policy \nInvariants When authoring the above monadic signature for .le IO, the pro\u00adgrammer may have in mind some \ninvariants to which policies G must adhere. For example, a call to chown (above) would have un\u00adexpected \nconsequences if there ever were more than one copy of System says owns(k,f) in G (only one copy would \nbe replaced, leaving a .le with two owners in the postcondition). Our interface permits programmers to \nspecify context invariants using a predicate Good G. The intended invariant of our interface is that \na monadic computation o G A G should have the property that G satis\u00ad.es Good if G does. To achieve this, \nthe weakening operations and acquire require preconditions G be accompanied by a proof of Good G, and \nthe programmer must verify that operations such as read, chown, and sudo preserve the invariant. Because \nof this in\u00advariant, it is not necessary to make each monadic operation require a proof that the precondition \nis Good. This means, that when writ\u00ading a client program, the programmer needs only to verify that the \ninitial policy and those in calls to weakening and acquire satisfy the invariants. In the above examples, \nwe took Good to be the trivially true invariant, so the proofs could be elided with an _. As mentioned \nabove, a useful invariant to enforce is that for every .le f there is at most one statement of the form \nSystem says Owner(_ , f) in the context. This is de.ned in Agda as follows: Good : TCtx+ [] Set Good \nG = . {k k f} (a : (Prin \"System\" says (a-(Owner \u00b7 (k , f)))) . G) (b : (Prin \"System\" says (a-(Owner \n\u00b7 (k , f)))) . G) Equal a b Then we may prove that the postcondition of each operation is Good if the \nprecondition is; e.g. ChownPreservesGood : . {G. k1 k2 f} Replace (Prin \"System\" says (a-(Owner \u00b7 (k1 \n, f)))) (Prin \"System\" says (a-(Owner \u00b7 (k2 , f)))) G. Good G Good . In the companion code, we revise \nthe above examples so that they maintain this invariant, using a tactic to generate the proofs.  2.2 \nFile IO with Access Control and Information Flow Next, we extend the above .le signature with information \n.ow, adapting an example from Fine [38]. First, we de.ne a type Tracked A L which represents a value \nof type A tracked with security level L, where L is a list of .lenames and U appends two lists. Following \nFine, we de.ne Tracked as an abstract functor that distributes over functions (though different type \nstructures for information .ow, such as an indexed monad [36], can be used in other examples): Tracked \n: Set Label Set fmap : . {A B L} (A B) Tracked A L Tracked B L _8_ : . {A B L1 L2} Tracked (A B) L1 Tracked \nA L2 Tracked B (L1 U L2) An application f 8 x joins the security levels of the function and the argument. \nNext, we give .ow-sensitive types to read and write: read tags the value with the .le it was read from, \nand write requires a proof of MayAllFlow provs file, representing the fact that all of the .les upon \nwhich the written string depends may .ow into file. read : . {G} (k : _) (file : _) Proof G ((a-(Mayread \n\u00b7 (k , file))) . (a+ (As \u00b7 k))) 0 G (Tracked String [ file ]) (. _ G) write : . {G provs} (k : _) (file \n: _) Tracked String provs Proof G ( (a-(Maywrite \u00b7 (k , file))) . (a+ (As \u00b7 k)) . (MayAllFlow provs file)) \n0 G Unit (. _ G) For example, we can read two .les and write their concatenation to secret.txt: go : \n0 (G as \"Jamie\") Unit (\\ _ (G as \"Jamie\")) go = read (Prin \"Jamie\") (File \"file1.txt\") (solve (prove \n15)) >>= \\ s read (Prin \"Jamie\") (File \"file2\u00b7txt\") (solve (prove 15)) >>= \\ s write (Prin \"Jamie\") (File \n\"secret\u00b7txt\") ((fmap String.string-append s) 8 s ) (solve (prove 15)) Here the theorem prover shows that \nboth file1.txt and file2.txt may .ow into secret.txt, according to the policy. This proof obligation \nresults from the fact that (fmap String.string-append s) 8 s has type Tracked String [ \"file1.txt\" , \n\"file2.txt\" ].  2.3 Spatial Distribution with Information Flow PCML5 investigates PCA for the spatially \ndistributed programming language ML5 [29]. Here, we show how to embed an ML5-style type system, which \ncan be combined with the above techniques for access control and information .ow. PCML5 considers additional \naspects of distributed authorization, such as treating the policy itself as a distributed resource, which \nwe leave to future work. ML tracks where resources and computations are located using modal types of \nthe form A@w. For example, database.read : (key value) @ server says that a function that reads from \n- the database must be run at the server, while javascript.alert : (string unit) @ client says that a \ncomputation that - pops up a browser alert box must be run at the client. Network communication is expressed \nin ML5 using an operation get : (unit A)@w A@w that (under some conditions which we elide here) goes \nto w to run the given computation and brings the resulting value back to w . In other work [27], we have \nshown how to build an ML5-like type system on top of an indexed monad of computations at a place, o wA, \nwith a rule get : o w A - o wA. Here, observe that this monad indexing can be represented using a proposition \nAt(w), where get is given a type analogous to sudo: get : (w1 w2 : _) . {G A G .. } Replace (a+ (At \u00b7 \nw1)) (a+ (At \u00b7 w2)) G. Replace (a+ (At \u00b7 w2)) (a+ (At \u00b7 w1)) . G 0 . A (\\ _ . ) 0 G (Tracked A w2) (\\ \n_ G )  Additionally, we combine spatial distribution with information .ow, tagging the return value \nof the computation with the world it is from. The postcondition must be independent of the return value, \nas there is in general no coercion either way between A and Tracked A L. Information .ow can be used \nin this setting to force strings to be escaped before they are sent back to the client e.g. to prevent \nSQL injection attacks: sanitize : Tracked String (client) HTML str : Tracked String (server) HTML Strings \nfrom the client must be escaped before they can be included in an HTML document, whereas strings from \nthe server are as\u00adsumed to be non-malicious, and can be included directly. In our technical report [28], \nwe extend this example with a sim\u00adple database interface that enforces both authorization and spatial \ndistribution database handles are only used at the server.  2.4 ConfRM: A Conference Management System \nSwamy et al. [38] present an example of a conference management server, ConfRM, adapted from CONTINUE \n[26] and its access con\u00adtrol policy [18]. Here, we show an excerpt of an authorization pol\u00adicy for ConfRM, \na proof-carrying monadic interface to the com\u00adputations which perform actions, and the main event loop \nof the server. This example uses ephemeral policies: authorization to per\u00adform actions, such as submitting \na paper or a review, depend on the phase of the conference (submission, noti.cation,. . . ). 2.4.1 Policy \nWe formalize ConfRM s policy using terms of various types: actions represent requests to the web server; \nprincipals rep\u00adresent users; papers and strings are used to specify actions; roles de.ne whether a user \nis an Author, PCMember, and so on. The policy is also dependent on the phase of the conference (e.g., \nan Author may submit a paper during the submission phase). The proposition May \u00b7 (k , a) states that \nk may perform ac\u00adtion a. Each action is a .rst-order term constructed from some arguments (e.g., Submit, \nReview, Readscore, Read all have papers, while Progress has two phases, the phase the conference is in \nbefore and after it is progressed). Fine speci.es the policy as a collection of Horn clauses, which are \nsimple to translate to our logic, as in the following clause: clause1 = ((.e principal \u00b7.e string \u00b7 let \nauthor = iS i0 papername = i0 in (((a-(InPhase \u00b7 (Submission))) . ((a-( InRole \u00b7 (author , Author))))) \n. (a-(May \u00b7 (author , (Submit \u00b7 papername))))))) This proposition reads: for all authors and paper names, \nif the conference is in the submission phase, and the principal is an author, then the principal may \nsubmit a paper. We have also begun to reformulate the policy using the says modality, e.g. to allow authors \nto share their paper scores with their coauthors. saysClause = ((.e principal \u00b7.e paper \u00b7.e principal \n\u00b7 let primary = i0 paper = (iS i0) coauthor = (iS (iS i0)) in (( ((a-(InPhase \u00b7 (Notification)))) . ((a-(Author \n\u00b7 (primary , paper) ))) . (primary says (a-(May \u00b7 (coauthor , (Readscore \u00b7 paper)))))) . (a-(May \u00b7 (coauthor \n, (Readscore \u00b7 paper))))))) This rule states that, for any principal author, paper paper, and principal \ncoauthor, if the conference is in noti.cation phase, and author is the author of paper, and author says \ncoauthor may read the scores for paper, then coauthor may read the scores for paper. Similarly, using \nsays, it is straightforward to specify a policy allowing PC members to delegate reviewing assignments \nto subreviewers.  2.4.2 Actions Rather than de.ning a command for each action doRead, doSubmit, etc. \nwe use type-level computation to write one command for processing all actions; this simpli.es the code \nfor the main loop presented below and allows for straightforward addition of actions. The generic command \nfor processing an action, doaction, has the following type: doaction : . {G} (k : _) (a : _) (e : ExtraArgs \nG a) Proof G (a-(May \u00b7 (k , a))) . (a+ (As \u00b7 k)) 0 G (Result a) (. r PostCondition a G e k r) doaction \ntakes a principal k, an action a to perform, and some ExtraArgs for a, along with a proof that the computation \nis run\u00adning as k, and that k may perform a. In this example, a Proof ab\u00adbreviates a sequent whose view \nis PCChair, rather than Admin. It returns a Result, and has a PostCondition, both of which are de\u00adpendent \nupon the action being performed. In Agda, ExtraArgs, Result, and PostConditions are functions de.ned \nby recursion on actions, which compute a Set,a Set, and a context, respectively. Several actions, such \nas Submitting a paper, require extra data that is not part of the logical speci.cation (e.g., the contents \nof the paper should not be part of the proposition which authorizes it to be submitted). ExtraArgs produces \nthe set of additional arguments each action requires. ExtraArgs : TCtx+ [] Term [] (action) Set ExtraArgs \nG (Review \u00b7 _) = Term [] (string) ExtraArgs G (Submit \u00b7 _) = Term [] (string) ExtraArgs G (Progress \u00b7 \n(p1 , p2)) = S (. . Replace (a-(InPhase \u00b7 p1)) (a-(InPhase \u00b7 p2)) G.) ExtraArgs G _ = Unit Reviews and \npaper submissions require their contents, represented as terms of type string (the Agda type Term [] \n(string) is an injection of strings into the language of .rst-order terms that we use to represent propositions, \nas described in Section 3 below). Progressing the phase of the conference requires a proof that the conference \nis in the .rst phase, along with a new context in the resulting phase, which we represent by a pair of \na new context . and a proof of Replace. Next, we specify the result type of an action: Result : Term \n[] (action) Set Result (Submit \u00b7 _) = Term [] (paper) Result (Review \u00b7 _) = Unit Result (BeAssigned \u00b7 \n_) = Unit Result (Readscore \u00b7 _) = String Result (Read \u00b7 _) = String Result (Progress \u00b7 _) = Unit Readscore \nand Read return a paper s reviews and contents, while submit produces a Term [] paper, a unique id for \nthe paper. Finally, we de.ne the PostCondition of each action, which is dependent upon the action itself, \nthe precondition, the extra ar\u00adguments for the action, the principal performing the action, and the Result \nof the action. Submitting a paper extends the pre\u00adconditions with two propositions: one saying the paper \nhas been submitted, and one saying the submitting principal is its author. Reviewing and Assigning a \npaper add that the paper is reviewed  fix : . {A G } ((. {G} 0 G A G ) (. {G} 0 G A G ) ) (. {G} 0 G \nA G )} main : . {G} 0 G Unit (. _ []) main = fix loop where loop : (. {G} 0 G Unit (. _ [])) (. {G} \n0 G Unit (. _ [])) loop rec {G}= {-1-} prompt \"Enter an action:\" >>= . astr case (parseAction astr) None. \nerror \"Unknown action\" Some. . actionArgs let a = (fst actionArgs) args = (snd actionArgs) in {-2-} \nprompt \"Who are you?\" >>= . ustring let u = parsePrin ustring in {-3-} acquire [ ((a-(MaySu \u00b7 (Prin \"Admin\" \n, u)))) ] /_ no. error \"Unable to su\" {-4-} yes. case make-replace None. error \"oops, not running as \nadmin\" Some. . asadmin {-5-} case (inputToE a _ args) None. error \"Bad input (e.g. not in phase)\" Some. \n. args {-6-} (sudo (Prin \"Admin\") u (snd asadmin) (\\x (snd (repAsPost (snd asadmin) {a} x))) (lfoc i0 \ninit-) {-7-} (prove/dyn 15 _ _ >>= none. error \"Unauthorized action\" some. . canDoAction {-8-} doaction \nu a args canDoAction) ) {-9-} >>= . _ rec Figure 3. ConfRM Main Loop by or assigned to the principal, \nrespectively. Readscore and Read leave the conditions unchanged. The postcondition of Progress is the \n.rst component of its ExtraArgs, i.e. the context determined by replacing the current phase with the \nresulting one. PostCondition : (a : Term [] (action)) (G : TCtx+ []) ExtraArgs G a (k : Term [] (principal)) \nResult a TCtx+ [] PostCondition (Submit \u00b7 y) G ekr = (a-(Submitted \u00b7 r )) :: (a-(Author \u00b7 (k , r))) :: \nG PostCondition (Review \u00b7 y) G ekr = (a-(Reviewed \u00b7 (k , y))) :: G PostCondition (BeAssigned \u00b7 y) G ekr \n= (a-(Assigned \u00b7 (k , y))) :: G PostCondition (Readscore \u00b7 y) G ekr = G PostCondition (Read \u00b7 y) G ekr \n= G PostCondition (Progress \u00b7 (ph1 , ph2)) G ekr = (fst e) In writing the main server loop, we will use \nthe following monadic wrapper of our theorem prover, in order to test at run time whether a given proposition \nholds in the current state of the server: prove/dyn : . {G1} Nat (G : TCtx+ []) (A : Propo-[]) 0 G1 (Maybe \n(Proof G A)) (. _ G1)  2.4.3 Server Main Loop In Figure 3 we show the code for the main loop of the \nConfRM server, implemented using the interface described above. The main loop serves requests made by \nprincipals who wish to perform ac\u00adtions. Because the requests are not determined until run-time, and \nauthorization depends on the system state (the phase of the confer\u00adence, the role of a principal), this \nexample uses entirely dynamic veri.cation of security policies: the server dynamically checks that each \nrequest is authorized just before performing it, using our the\u00adorem prover at run-time. The type system \nensures that the appro\u00adpriate dynamic check is made. Informally, the server loop works by (1) reading \nin an action and its arguments, (2) reading in a princi\u00adpal, (3) acquiring the credentials to su as that \nprincipal, (4) comput\u00ading the precondition of the su, (5) computing the postconditions of performing \nthe action, (6) su-ing as the principal, (7) proving the principal may perform the action, (8) performing \nthe action, and (9) recurring. The fact that we have coalesced all of the actions into one primitive \ncommand makes this code much more concise than it would be otherwise, when we would have to repeat essentially \nthis code as many times as there are actions.  This code is rendered in Agda as follows. fix permits \nan IO computation to be de.ned by general recursion. Because its type is restricted to the monad, it \ndoes not permit non-terminating ele\u00adments of other types, such as Proof. This .xed-point combinator abstracts \nover the precondition, so it may vary in recursive calls, but leaves the postcondition .xed throughout \nthe loop; we leave more general loop invariants to future work. First, main is given the type . {G} o \nG Unit (. _ []): given any precondi\u00adtion, the computation returns unit and an empty postcondition (we \ndo not expect to run any code following main so it is not worth\u00adwhile to track the postconditions). main \nis de.ned by taking the .xed point of the axillary function loop, which is abstracted over the recursive \ncall. On line (1), the loop prompts the user to en\u00adter an action to perform, parseAction then parses \nthe string to produce a : action and args: InputArgs, and raises an er\u00adror otherwise. (2) The loop prompts \nfor a username, parses it into a Term [] principal. (3) The loop attempts to acquire creden\u00adtials that \n\"Admin\" may su as the principal (e.g., by prompting for a password). (4) The loop calls the functions \nmake-replace to produce the preconditions for the su, by replacing (As (Prin \"Admin\")) with a+ (As u). \n(5) The loop calls inputToE to pro\u00adduce the ExtraArgs for the action from the args; for Progress, this \nfunction computes the postcondition of the action from the cur\u00adrent context. (6) The loop su-s as the \nprincipal. The .rst replace argument to su is the result of step (4), the proof argument is the assumption \nacquired in step (3), the second replace argument is discussed below. (7) The loop calls the theorem \nprover at run-time to prove the principal may perform the requested action. (8) The loop calls doaction \nand (9) recurs. The second replace argument to su is generated using a proof that As is preserved in \nthe PostCondition of an action: postPreservesAs : . {a G e k r k } (a+ (As \u00b7 k ) . G) ((a+ (As \u00b7 k )) \n. PostCondition a G e k r) This is another example of using Agda to verify invariants of the pre-and \npost-conditions, as in Section 2.1.4.  2.4.4 Dynamic Policy Acquisition Finally, we describe an example \nof dynamic policy acquisition in Figure 4: we read the reviewers paper assignments from a database, parse \nthe result into a context, acquire the context, and start the main server loop with those preconditions. \nThis is simple in a dependently typed language because contexts themselves are data. The function getReviewerAsgn \ntakes a string, representing a path to the database, and returns the list of reviewers for each paper. \nThe function parseReviewers then turns each of these lists into lists of propositions, each stating the \nparsed reviewer is a reviewer of the paper. A more realistic ConfRM implementation would read a variety \nof other propositions from the database as well  getReviewerAsgn : . {G} String 0 G (List (List String)) \n(. _ G) parseReviewers : List String TCtx+ [] mkPolicy : . {G} 0 G (TCtx+ []) (. _ G) mkPolicy = getReviewerAsgn \n\"papers.db\" >>= . asgn return (ListM.fold [] (. x . y parseReviewers x ++ y) asgn) start = mkPolicy {[]} \n>>= . ctx acquire ctx / _ no. error \"policy not accepted\" yes. main Figure 4. ConfRM Policy Acquistion \n(which papers have been submitted, reviewed, etc.) The computa\u00adtion mkPolicy calls getReviewerAsgn and \nparses the results. The computation start uses mkPolicy to generate an initial policy, ac\u00adquires these \npreconditions, and starts the main sever loop. 3. Implementation Our Agda implementation consists of \nabout 1400 lines of code. We have also written about 1800 lines of example code in the embed\u00added language, \nincluding policies, monadic interfaces to primitives, and example programs. In this section, we describe \nthe implemen\u00adtation of the logic, the theorem prover, and the indexed monad. 3.1 Representing BL0 BL0 \n[21] extends .rst-order intuitionistic logic with the modal\u00adity k says A. While a variety of de.nitions \nof says have been studied (Abadi [2] overviews some of the approaches), in BL0, says is treated as a \nnecessitation (D) modality, and not as a lax modality (i.e. a monad) [1, 8, 22, 24]. The de.nition of \nsays in BL0 supports exclusive delegation, where a principal delegates responsibility for a proposition \nto another principal, without retaining the ability to assert that proposition himself. For example, \nconsider a policy that payroll says .t.(HR says employee(t)) . MayBePaid(t). Under what circumstances \ncan we conclude payroll says MayBePaid(Alice)? The fact that HR says employee(Alice) should be suf.cient. \nHowever, the fact that payroll says employee(Alice) should not, as the in\u00adtention of the policy is that \npayroll delegates responsibility for the employee predicate to human resources, without retaining the \nability to assert employee instances itself. When says is treated as a lax modality, payroll says employee(Alice) \nim\u00adplies payroll says HR says employee(Alice), which is enough to conclude the goal. Abstractly, we wish \nk says A to imply k ' says (k says A), but not k says (k ' says A). The modal\u00adity satis.es several other \naxioms: for example, principals say all consequences the statements they have made (k says (p . q) en\u00adtails \n(k says p . k says q)) and principals believe what they say is true (k says ((k says s) . s)). 3.1.1 \nTerms, Types, and Atomic Propositions In the above examples, we used a variety of atomic propositions \n(Mayread, Owns, etc.), which refer to several datatypes (principals, papers, conference phases, etc.). \nWe have parametrized the repre\u00adsentation of BL0 and its theorem prover over such datatypes and atomic \npropositions by de.ning a generic datatype of .rst-order terms, with free variables, over a given signature. \nThis allows us to specify the types, terms, and propositions for an example concisely, while exploiting \na datatype-generic de.nition of weakening, substi\u00adtution, etc., which are necessary to state the inference \nrules of the logic. The following excerpt from the signature for ConfRM illus\u00adtrates what programmers \nwrite to de.ne an individual example: data BaseType : Set where string paper role action phase principal \n: BaseType data Const : BaseType -> Set where Prin : String -> Const principal Paper : String -> Const \npaper PCChair Reviewer Author Public : Const role Init Presubmission Submission ... : Const phase data \nFunc : BaseType -> Type -> Set where Review BeAssigned ... : Func action (paper) Progress : Func action \n(phase . phase) data Atom : Type -> Set where InPhase : Atom (phase) Assigned ... : Atom (principal . \npaper) May : Atom (principal . action) As : Atom (principal) The programmer de.nes a datatype of base \ntypes, a datatype giving constants of each type, a datatype of function symbols, and a datatype of atomic \npropositions over a given type. Additionally, the programmer must de.ne a couple of operations on these \ntypes (equality, enumeration of all elements of a .nite type) which in a future version of Agda could \nbe generated automatically [5]. Types are BaseTypes, unit and pair types (t1 . t 2). The terms over a \nsignature are given by a datatype Term O t, where O, an individual context (ICtx), represents the free \nvariables of the term. An ICtx is a list of BaseTypes, and represents a context of individual variables \ne.g. the context x1 : t1,...,xn : tn will be represented by the list t1 :: ... :: tn :: []. Variables \nare rep\u00adresented by well-scoped de Bruijn indices, which are pointers into such a list i0 says x . (x \n:: l), and iS says that x . (y :: l) if x . l. Terms are either variables (t i), where i: t . O is a \nde Bruijn index, constants, applications of function symbols (f \u00b7 t), or [] and (t1 , t2) for unit and \nproduct types. Atomic propositions are represented by a datatype Aprop O. An atomic proposition p \u00b7 t \nconsists of an Atom paired with a term of the ap\u00adpropriate type. We have de.ned weakening and substitution \ngener\u00adically on terms and propositions, and proved several properties of them (e.g. functoriality of \nweakening).  3.1.2 Propositions BL0 propositions include conjunction, disjunction, implication, universal \nand existential quanti.cation, and the says modality: A, B, C ::= P | A . B | A . B | A . B |T |. |.x \n: t.s |.x : t.A | k says A In Figure 5, we represent this syntax in Agda. Propositions (Propo) are indexed \nby a context of free variables, and additionally by a po\u00adlarity (+ or -), which will be helpful in de.ning \na focused sequent calculus below. Because the syntax of propositions is polarized, there are two injections \na-and a+ from atomic propositions Aprop to negative and positive propositions, respectively. Additionally, \nthe shifts . and . include negative into positive and vice versa. The re\u00admaining datatype constructors \ncorrespond to the various ways of forming propositions in the above grammar. For example, the _ . _ constructor \ntakes two terms of type Propo+ O and returns a term of type Propo+ O. The constructor .i (existential \nquanti.cation over individuals), takes a positive proposition, in a context with one new free variable \nof type t , and returns a positive proposition in the original context O. We have suppressed the shifts \nup to this point in the paper for readability. We could suppress shifts in our Agda code by imple\u00admenting \na simple translation that, given an unpolarized proposition  data Propo : Polarity ICtx Set where _._: \n. {O} Propo+ O Propo-O Propo-O .i_ : . {O t} Propo-(t :: O) Propo-O a-: . {O} Aprop O Propo-O . : . {O} \nPropo+ O Propo-O _._: . {O} Propo+ O Propo+ O Propo+ O _._: . {O} Propo+ O Propo+ O Propo+ O . : . {O} \nPropo+ O T : . {O} Propo+ O .i_ : . {O t} Propo+ (t :: O) Propo+ O _says_ : . {O} Term O principal Propo-O \nPropo+ O a+ : . {O} Aprop O Propo+ O . : . {O} Propo-O Propo+ O Figure 5. Agda Representation of BL0 \nPropositions and an intended polarization of each atom, computes a polarized proposition with minimal \nshifts.  3.1.3 Proofs -. A. The context O gives types to individual variables (e.g. it is extended by \n.), and the context G contains propositions that are assumed to be true (e.g. it is extended by .) these \nare the standard contexts k Sequent calculus. Sequents in BL0 have the form O; .; G focus (choice) steps \nof like-polarity connectives to be chained to\u00adgether, but does not force inversion (pattern-matching) \nsteps to be chained together. We use weak, rather than full, focusing because it is slightly easier to \nrepresent in Agda, and because it can some\u00adtimes lead to shorter proofs if one internalizes the identity \nprinci\u00adples (which say that A entails A) though we do not exploit this fact in our current prover. The \npolarity of k says A is as follows: A is negative, but k says A itself is positive. As a simple check \non this, observe that k says A is invertible on the left one can always immediately make the claims assumption \nbut not on the right because saysR clears the true assumptions. For example, a policy is often of the \nform k1 says A1,...kn says An, with a goal of the form k- k ' says B. It is necessary to use claimsL \nto turn all propositions of the form k says A in G into claims in . before using saysR on the goal if \none uses saysR .rst, the policy would be discarded. This polarization is analogous to D in Pfenning and \nDavies [33] and to ! in linear logic [6], which is reasonable given that says is a necessitation modality. \nOur sequent calculus has three main judgements: . [A+ Right focus: O; .; G ] --. [A k k Neutral sequent: \nO; .; G-. C \u00ad  Left focus: O; .; G  ] >C of .rst-order logic. The context . contains claims, assumptions \nof Here . consists of claims k claims A -and G consists of posi\u00adthe form k ' claims A; claims is the \njudgement underlying the tive propositions. For convenience in the Agda implementation, we says connective \n[21, 33]. Finally, k, the view of the sequent, is the principal on behalf of whom the inference is made.The \nrules for says are as follows: break out a one-step left-inversion judgement O; .; G k -. A+ C, which \napplies a left rule to the distinguished proposition A+ and >I k O; .; [] -. A SAYSR k0 O; .;G - . k \nsays A k0 O; ., (k claims A); G, (k says A) - . C SAYSL k0 O;.; G, (k says A) - . C k0 O; (.,k claims \nA); (G,A) - . Ck = k0 CLAIMSL k0 O; (.,k claims A); G - . C In order to show k says A, one empties the \ncontext G of true assumptions, and reasons on behalf of k with the goal A (rule saysR). It is necessary \nto empty G because the facts in it may depend on claims by the principal k0, which are not valid when \nreasoning as k. The rule saysL says that if one is reasoning from an assumption k says A, one may proceed \nusing a new assumption that k claims A. Claims are used by the rule claimsL, which allows passage from \na claim k claims A to an assumption that A is actually true. This rule makes use of a preorder on principals, \nand asserts that any statements made by a greater principal are accepted as true by lesser principals. \nFocused sequent calculus. To help with de.ning a proof search procedure, we present BL0 as a weakly-focused \nsequent calculus. Garg [21] describes both an unfocused sequent calculus and a fo\u00adcused proof system \nfor FHH, a fragment of BL0; here we give a focused sequent calculus for all of BL0. Focusing [6] is a \nproof\u00adtheoretic technique for reducing inessential non-determinism in proof search, by exploiting the \nfact that one can chain together cer\u00adtain proof steps into larger steps. In the Agda code above, we po\u00adlarized \nthe syntax of propositions, dividing them into positive and negative classes. Positive propositions, \nsuch as disjunction, require choices on the right, but are invertible on the left: a goal C is prov\u00adable \nunder assumption A+ if and only if it is provable under the left rule s premises. Dually, negative propositions \ninvolve choices on the left but are invertible on the right. Weak focusing [34] forces then reverts to \na neutral sequent. The rules are a fairly simple inte\u00adgration of the idea of weak focusing [34] with \nthe focusing inter\u00adpretation of says described above. The interested reader can .nd the inference rules \nfor these judgements in the extended version of this paper [28]. Agda Representation In Figure 6, we \nshow an excerpt of the Agda representation of this sequent calculus. First, we de.ne a record type for \na Ctx, which tuples together the O, ., G, and k parts of a sequent we write T for such a tuple. G is \nrepresented as a list of propositions; . is represented as a list of pairs of a principal and a proposition, \nwritten p claims A; k is a term of type principal. Record .elds are selected by writing R.x, where the \ntype of the record is R and the desired .eld is x (e.g., Ctx.rk selects the principal from a Ctx record). \nNote that Ctx is a dependent record: the true context, the claims context, and the view can mention the \nvariables bound in the individual context rO. We write TCtx+ O for List (Propo+ O). We de.ne several \nhelper functions on Ctxs: sayCtx clears the Ctx of true propositions, and changes the view of the context \nto its second argument. ictx (not shown) is shorthand for Ctx.rO. addTrue and addClaim (not shown) add \na true proposition onto G or a claim onto ., respectively. addVar adds a variable to O, and weakens the \nrest of the context. When writing down the calculus on paper, it is obvious that extending O does not \naffect G or .; any variables bound in O will be bound in O ' . O. However, in Agda, it is necessary to \nexplicitly coerce F O to F O ' for type families F dependent on O. We have de.ned weakening functions \nfor many of the types indexed by O: terms (weakenTerm), propositions, claims, true contexts (weakenT+), \nclaims contexts (weakenC), and so on. There are 4 judgments in our weakly-focused sequent calculus; analogously, \nthere are 4 mutually recursive datatype declarations representing these judgements in Agda, with one \ndatatype construc\u00adtor for each inference rule. We show the constructors .L (for the left focus judgement), \n.L and saysL (for the left inversion judge\u00adment), saysR (for the right focus judgement), and claimsL \n(for  record Ctx : Set where field rO : ICtx rG+ : List (Propo+ rO) --pairs written (k claims A) r. \n: List (Term rO principal \u00d7 Propo-rO) rk :TermrO principal addVar : (. : Ctx) (A : Type) Ctx addVar .t \n= record {rO =(t :: Ctx.rO .); rG+ = (weakenT+ (Ctx.rG+ .) iS) ; r. = (weakenC (Ctx.r. .) iS) ; rk = \n(weakenTerm (Ctx.rk .) iS)} sayCtx : (. : Ctx) (k : Term (Ctx.rO .) principal) Ctx sayCtx . k = (record \n{rO = Ctx.rO . ; rG+ = [] ; r. = Ctx.r. . ; rk = k}) mutual data _.L_>_ : (. : Ctx) Propo-(ictx .) Propo-(ictx \n.) Set where .L: . {.t A C} (t : Term (ictx .) t) . .L (substlast A t) > C . .L .i_ {ictx .}{t}A>C ... \ndata _.I_>_ : (. : Ctx) (Propo+ (ictx .)) Propo-(ictx .) Set where .L: . {.t A C} (addTrue (addVar .t) \nA) . (weakenP C iS) . .I(.e t A) > C saysL : . {. k s B} addClaim . (k claims s) . C . .I (k says s) \n> C ... data _.R_ : (. : Ctx) Propo+ (ictx .) Set where saysR : . {. k A} (sayCtx . k) . A . .R (k says \nA) ... data _._: (. : Ctx) Propo-(ictx .) Set where claimsL : . {. k A C} (k claims A) . Ctx.r. . . \n.LA>C k = Ctx.rk . . . C ... Figure 6. Agda representation of proofs (exceprt) the neutral sequent judgement). \nFor the most part, the rules are a straightforward transcription of the sequent calculus rules [28]. \nIn .L, the function substlast substitutes a term for the last variable in a proposition; we have implemented \nsubstitution for individual variables for each of the syntactic categories. In .L, it is necessary to \nweaken the goal with the new variable, which is tacit in on-paper presentations. Properties Because the \nsequent calculus is cut-free, consistency of closed proofs is immediate: Consistency: For all principals \nk, there is no derivation of k []; []; [] -.. .. Proof: no rule concludes . in right focus, and in the \nempty context no left focus or left inversion rules apply. Identity and cut can be proved using the usual \nsyntactic meth\u00adods, adapting Garg s proof [21] for an unfocused sequent calculus to weak focusing, following \nPfenning and Simmons [34].  3.2 Proof Search We have implemented a simple proof-producing theorem prover \nfor BL0: prove : Nat (. : Ctx) (A : Propo-(ictx .)) Maybe (. . A) prove takes a depth bound, a context, \nand a proposition, and attempts to .nd a proof of . f A with at most the given depth. The prover is certi.ed: \nwhen the prover succeeds, it returns a proof, which is guaranteed by type checking to be well-formed. \nWhen the prover fails, it simply returns None. The prover is implemented by around 200 lines of Agda \ncode. Our prover is quite na\u00efve, but it suf.ces to prove the examples in this paper. For the most part, \nthe prover backchains over the focus\u00ading rules. However, whereas the above sequent calculus was only \nweakly focused, the prover is fully focused, in that it eagerly applies invertible rules, which avoids \nbacktracking over different applica\u00adtions of them. If the goal is right-invertible, the prover applies \nright rules. Once the goal is not right-invertible (an atom or a shift . A+), the prover fully left-inverts \nall of the assumptions in G. Inverting a context G breaks up the positive propositions using left rules, \ngen\u00aderating a list of non-invertible contexts T1, ..., Tk such that, if for every i, Ti f C, then T f \nC. Once the sequent has been fully inverted, the prover tries right-focusing (if the goal is a shift \n. A+) and left-focusing on all assumptions in G and claims in ., until one of these choices succeeds. \nThe focus phases involves further backtracking over choices (e.g., which branch of a disjunction to take). \nThe focus rules for quanti.ers (.E and .I) require guess\u00ading an instantiation of the quanti.er. Our current \nimplementation is brute-force: it simply computes all terms of a given type in a given context and tries \neach of them in turn we have only considered individual types with .nitely many inhabitants. The prover \nachieves tolerable compile times on the small ex\u00adamples we have considered so far (1 to 13 seconds). \nIf it proves too slow for some examples, we have several options: First, we can improve our implementation \ne.g. by implementing uni.ca\u00adtion, which will eliminate much of the branching from quanti.ers, or by doing \na better job of clause selection. Second, we could con\u00adnect Agda with an external theorem prover, following \nKariso [25]. Garg has implemented theorem prover for BL0 in ML [21], which we could integrate soundly \nby writing a type checker for the certi.\u00adcates it produces. Third, we could optimize Agda itself, by \n.xing some known inef.ciencies in Agda s compile-time evaluation.  3.3 Computations The monadic interfaces \npresented in Section 2 are currently treated as re.nement types on Haskell s IO monad, which is exposed \nthrough the Agda foreign function interface. The implementations of proof-carrying .le operations simply \nignore their proof argu\u00adments. fix is compiled using general recursion in Haskell. In this operational \nmodel, programs written in Aglet adhere to the secu\u00adrity policies, but no guarantees are made about programs \nthat can access, e.g., the raw .le system operations. We discuss alternatives in Section 5 below. 4. \nRelated Work Aglet implements security-typed programming in the style of Aura [24], PCML5 [9], Fine [38], \nand previous work by Avijit and Harper [8] (henceforth AH), which integrate authorization log\u00adics into \nfunctional/imperative programming languages. Our main contribution relative to these languages is to \nshow how to support security-typed programming within an existing dependently-typed language. There are \nalso some technical differences between these languages and ours:  First, Aura, PCML5, and AH interpret \nsays as a lax modality, whereas BL0 interprets it as a necessitation modality to support ex\u00adclusive delegation; \nFine uses .rst-order classical logic and does not directly support the says modality. The context-clearing \nnecessita\u00adtion modality is more challenging to represent than a lax modality. Second, unlike these four \nlanguages, our language treats propo\u00adsitions and proofs as inductively de.ned data, which has several \napplications: In Aura, all proof-carrying primitives log the supplied proofs for later audit; the programmer \ncould implement logged operations on top of our existing interface by writing a function toString : Proof \nG A -> String by recursion over proofs. Recursion over propositions is also essential for writing our \ntheo\u00adrem prover inside of Agda. Third, our indexed monad of computations allows us to encode computation \non behalf of a principal, following AH. In Aura, all computation proceeds on behalf of a single distinguished \nprincipal self. In PCML5, a program can authenticate as different princi\u00adpals, but the credentials are \nless precise: in PCML5, the program authenticates as k, whereas in AH the program acquires only the ability \nto su from a given k ' to k which may be a useful restric\u00adtion if the program is subsequently no longer \nrunning as k '. Fine does not track authentication as a primitive notion, though it seems likely it could \nbe encoded using an As predicate and af.ne types. Fourth, in PCML5, acquire uses theorem proving to deduce \nconsequences of the policy, whereas in our language acquire only tests whether a state-dependent atom \nor a statement by a principal is literally in the policy, and a separate theorem prover deduces consequences \nfrom the policy. We separate theorem proving from acquire so that we may also use the same theorem prover \nat compile-time to statically discharge proof obligations. PCML5 and AH make use of a theorem prover \nonly at run-time, whereas Fine uses theorem proving only at compile-time. Fifth, PCML5 is a language \nfor spatially distributed authoriza\u00adtion, where resources and policies are located at different sites \non a network. We have shown how to support ML5-style spatial distri\u00adbution using our indexed monad, but \nwe leave spatial distribution of policies to future work. Sixth, the operational semantics of both PCML5 \nand AH in\u00adclude a proof-checking reference monitor; we have not yet consid\u00adered such an implementation. \nSeveral other languages provide support for verifying security properties by type checking. For example, \nFournet et al. [19] de\u00advelop a type system for a process calculus, and Bengtson et al. [11] for F#, both \nof which can be used to verify authorization policies and cryptographic protocols. This work addresses \nimportant issues of concurrency, which we do not consider here. A technical dif\u00adference is that, in their \nwork, proofs are kept behind the scenes (e.g., in F7, propositions are proved by the Z3 theorem prover). \nIn contrast, our language makes the proof theory directly available to the programmer, so that propositions \nand proofs can be computed with (for logging or run-time theorem proving) and so that proofs can be constructed \nmanually when a theorem prover fails. Another example of a language that does not give the programmer \ndirect ac\u00adcess to the proof theory is PCAL [13], an extension of BASH that constructs the proofs required \nby a proof-carrying .le system [23]; proof construction is entirely automated, but sometimes inserts \nrun\u00adtime checks. Our indexed monad was inspired by HTT [30]. RIF [12] also investigates applications \nof indexed monads to security-typed pro\u00adgramming, but there are some technical differences: First, RIF \nis a new language where re.nement types (using .rst-order classical logic) and a re.ned state monad are \nprimitive notions, whereas we embed an authorization logic and an indexed monad in an existing dependently \ntyped language. Second, RIF s monad is indexed by predicates on an explicit representation of the system \nstate, whereas we index by policies G that describe an implicit ambient state. Many security-typed languages \naddress the problem of enforc\u00ading information .ow policies (see Abadi et al. [4], Chothia et al. [15] \nfor but a couple of examples). We follow Russo et al. [36], Swamy et al. [38] in representing information \n.ow using an ab\u00adstract type constructor (e.g., a monad or an applicative functor). Fable [37] takes a \ndifferent approach to verifying access-control, information .ow, and integrity properties, by providing \na type of labelled data that is treated abstractly outside of certain policy por\u00adtions of the program. \nThis mechanism facilitates checking security properties (by choosing the labels appropriately and implementing \npolicy functions) and proving bi-simulation properties of the pro\u00adgrams that adhere to these policies. \nDeYoung and Pfenning [16] describe a technique for represent\u00ading access control policies and stateful \noperations in a linear autho\u00adrization logic. Our approach to verifying context invariants, as in Section \n2.1.4, is inspired by their work. The literature describes a growing body of authorization log\u00adics [1 \n3, 17, 20, 21]. We chose BL0 [21], a simple logic that sup\u00adports the expression of decentralized policies \nand whose says con\u00adnective permits exclusive delegation. Appel and Felten [7] pioneered the use of proof-carrying \nautho\u00adrization, in which a system checks authorization proofs at run-time. Several systems have been \nbuilt using PCA [10, 23, 40]. Like many security-typed languages, we use dependently typed PCA to check \nauthorization proofs at compile-time through type checking. 5. Conclusion In this paper, we have described \nAglet, a library embedding security-typed programming in a dependently-typed programming language. There \nare many interesting avenues for future work: First, we may consider embedding an authorization logic \nsuch as full BL [20] that accounts for resources that change over time. Second, we have currently implemented \nthe monadic computation interface on top of unguarded Haskell IO commands, which pro\u00advides security guarantees \nfor well-typed programs. To maintain security in the presence of ill-typed attackers, we may instead \nim\u00adplement our interface using a proof-carrying run-time system such as PCFS [23]. Following PCML5 [9], \nwe may then be able to prove a progress theorem showing that well-typed programs always pass the reference \nmonitor. Another intriguing possibility is to formalize the operational behavior of computations directly \nwithin Agda e.g. using an algebraic axiomatization [35]. Third, in this paper we have shown examples \nof entirely static and entirely dynamic veri.\u00adcation; we would like to consider examples that mix the \ntwo. This will require using re.ection to represent Agda judgements as data, so that our theorem prover \ndoes not get stuck on open Agda terms. Fourth, we have shown a few small examples of using Agda to reason \nabout the class of contexts that is possible given a particular monadic interface. In future work, we \nwould like to explore ways of systematizing this reasoning (e.g., by using linear logic to describe transformations \nbetween contexts, as in DeYoung and Pfenning [16]). We would also like to use Agda to analyze global \nproperties of a particular monadic interface (such as proving a principal can never access a resource). \nOnce we have circumscribed the contexts generated by a particular interface, we can prove such properties \nby induction on BL0 proofs. Fifth, we would like to implement more signi.cant examples, such as a larger \nportion of ConfRM. Acknowledgements We thank Frank Pfenning, Robert Harper, Kumar Avijit, Deepak Garg, \nand Rob Simmons for helpful discus\u00adsions about this work. We thank Frank Pfenning, Robert Harper, and \nseveral anonymous referees for feedback on previous drafts of this article.  References [1] M. Abadi. \nAccess control in a core calculus of dependency. In Internatonal Conference on Functional Programming, \n2006. [2] M. Abadi. Variations in access control logic. In International Confer\u00adence on Deontic Logic \nin Computer Science, pages 96 109. Springer- Verlag, 2008. [3] M. Abadi, M. Burrows, B. Lampson, and \nG. Plotkin. A calculus for access control in distributed systems. ACM Transactions on Program\u00adming Languages \nand Systems, 15(4):706 734, September 1993. [4] M. Abadi, A. Banerjee, N. Heintze, and J. G. Riecke. \nA core calculus of dependency. In ACM Symposium on Principles of Programming Languages, pages 147 160. \nACM Press, 1999. [5] T. Altenkirch and C. McBride. Generic programming within depen\u00addently typed programming. \nIn IFIP TC2 Working Conference on Generic Programming, Schloss Dagstuhl, 2003. [6] J.-M. Andreoli. Logic \nprogramming with focusing proofs in linear logic. Journal of Logic and Computation, 2(3):297 347, 1992. \n [7] A. W. Appel and E. W. Felten. Proof-carrying authentication. In ACM Conference on Computer and Communications \nSecurity, pages 52 62, 1999. [8] K. Avijit and R. Harper. A language for access control. Technical Report \nCMU-CS-07-140, Carnegie Mellon University, Computer Sci\u00adence Department, 2007. [9] K. Avijit, A. Datta, \nand R. Harper. Distributed programming with distributed authorization. In ACM SIGPLAN-SIGACT Symposium \non Types in Language Design and Implementation, 2010. [10] L. Bauer, S. Garriss, J. M. Mccune, M. K. \nReiter, J. Rouse, and P. Rutenbar. Device-enabled authorization in the Grey System. In Proceedings of \nthe 8th Information Security Conference, pages 431 445. Springer Verlag LNCS, 2005. [11] J. Bengtson, \nK. Bhargavan, C. Fournet, A. Gordon, and S. Maffeis. Re.nement types for secure implementations. In Computer \nScience Logic, 2008. [12] J. Borgstr\u00f6m, A. D. Gordon, and R. Pucella. Roles, Stacks, Histories: A Triple \nfor Hoare. Technical Report MSR-TR-2009-97, Microsoft Research, 2009. [13] A. Chaudhuri and D. Garg. \nPCAL: Language support for proof\u00adcarrying authorization systems. In Proceedings of the 14th European \nSymposium on Research in Computer Security, September 2009. [14] S. Chong, A. C. Myers, K. Vikram, and \nL. Zheng. Jif reference manual. Available from http://www.cs.cornell.edu/jif/doc/jif-3.3.0/manual.html, \nFebruary 2009. [15] T. Chothia, D. Duggan, and J. Vitek. Type-based distributed access control (extended \nabstract). In Computer Security Foundations Work\u00adshop, 2003. [16] H. DeYoung and F. Pfenning. Reasoning \nabout the consequences of authorization policies in a linear epistemic logic. In Workshop on Foundations \nof Computer Security, 2009. [17] H. DeYoung, D. Garg, and F. Pfenning. An authorization logic with explicit \ntime. In IEEE Computer Security Foundations Symposium, 2008. [18] D. J. Dougherty, K. Fisler, and S. \nKrishnamurthi. Specifying and reasoning about dynamic access-control policies. In International Joint \nConference on Automated Reasoning, pages 632 646. Springer, 2006. [19] C. Fournet, A. D. Gordon, and \nS. Maffeis. A type discipline for authorization in distributed systems. In Computer Science Logic, 2007. \n[20] D. Garg. Proof Theory for Authorization Logic and its Application to a Practical File System. PhD \nthesis, Carnegie Mellon University, 2009. [21] D. Garg. Proof search in an authorization logic. Technical \nReport CMU-CS-09-121, Computer Science Department, Carnegie Mellon University, April 2009. [22] D. Garg \nand F. Pfenning. Non-interference in constructive authoriza\u00adtion logic. In Computer Security Foundations \nWorkshop, pages 183 293, 2006. [23] D. Garg and F. Pfenning. PCFS: A proof-carrying .le system. Tech\u00adnical \nReport CMU-CS-09-123, Carnegie Mellon University, 2009. [24] L. Jia, J. A. Vaughan, K. Mazurak, J. Zhao, \nL. Zarko, J. Schorr, and S. Zdancewic. Aura: A programming language for authorization and audit. In ACM \nSIGPLAN International Conference on Functional Programming, 2008. [25] K. Kariso. Integrating Agda and \nautomated theorem proving tech\u00adniques. Talk at Dependently Typed Programming Workshop, 2010. [26] S. \nKrishnamurthi. The CONTINUE server (or, How I administered PADL 2002 and 2003). In International Symposium \non Practical Aspects of Declarative Languages, pages 2 16. Springer-Verlag, 2003. [27] D. R. Licata and \nR. Harper. A monadic formalization of ML5. In Pre-preceedings of Workshop on Logical Frameworks and Meta\u00adlanguages: \nTheory and Practice, July 2010. [28] J. Morgenstern and D. R. Licata. Security-typed programming within \ndependently typed programming. Technical Report CMU-CS-10-114, Carnegie Mellon University, 2010. [29] \nT. Murphy, VII. Modal Types for Mobile Code. PhD thesis, Carnegie Mellon, January 2008. Available as \ntechnical report CMU-CS-08-126. [30] A. Nanevski, G. Morrisett, and L. Birkedal. Polymorphism and sep\u00adaration \nin Hoare Type Theory. In ACM SIGPLAN International Con\u00adference on Functional Programming, pages 62 73, \nPortland, Oregon, 2006. [31] A. Nanevski, G. Morrisett, A. Shinnar, P. Govereau, and L. Birkedal. Ynot: \nReasoning with the awkward squad. In ACM SIGPLAN Inter\u00adnational Conference on Functional Programming, \n2008. [32] U. Norell. Towards a practical programming language based on de\u00adpendent type theory. PhD thesis, \nChalmers University of Technology, 2007. [33] F. Pfenning and R. Davies. A judgmental reconstruction \nof modal logic. Mathematical Structures in Computer Science, 11:511 540, 2001. [34] F. Pfenning and R. \nJ. Simmons. Substructural operational semantics as ordered logic programming. In IEEE Symposium on Logic \nIn Com\u00adputer Science, pages 101 110, Los Alamitos, CA, USA, September 2009. IEEE Computer Society. [35] \nG. Plotkin and M. Pretnar. Handlers of algebraic effects. In European Symposium on Programming, pages \n80 94. Springer-Verlag, 2009. [36] A. Russo, K. Claessen, and J. Hughes. A library for light-weight information-.ow \nsecurity in Haskell. In ACM SIGPLAN Symposium on Haskell, pages 13 24. ACM, 2008. [37] N. Swamy, B. J. \nCorcoran, and M. Hicks. Fable: A language for en\u00adforcing user-de.ned security policies. In IEEE Symposium \non Security and Privacy, pages 369 383. IEEE Computer Society, 2008. [38] N. Swamy, J. Chen, and R. Chugh. \nEnforcing stateful authorization and information .ow policies in Fine. In European Symposium on Programming, \n2010. [39] J. A. Vaughan, L. Jia, K. Mazurak, and S. Zdancewic. Evidence\u00adbased audit. In IEEE Computer \nSecurity Foundations Symposium, June 2008. [40] E. Wobber, M. Abadi, M. Burrows, and B. Lampson. Authentication \nin the Taos operating system. ACM Transactions On Computer Systems, 12(1):3 32, 1994.   \n\t\t\t", "proc_id": "1863543", "abstract": "<p>Several recent security-typed programming languages, such as Aura, PCML5, and Fine, allow programmers to express and enforce access control and information flow policies. In this paper, we show that security-typed programming can be embedded as a library within a general-purpose dependently typed programming language, Agda. Our library, Aglet, accounts for the major features of existing security-typed programming languages, such as decentralized access control, typed proof-carrying authorization, ephemeral and dynamic policies, authentication, spatial distribution, and information flow. The implementation of Aglet consists of the following ingredients: First, we represent the syntax and proofs of an authorization logic, Garg and Pfenning's BL<sub>0</sub>, using dependent types. Second, we implement a proof search procedure, based on a focused sequent calculus, to ease the burden of constructing proofs. Third, we represent computations using a monad indexed by pre- and post-conditions drawn from the authorization logic, which permits ephemeral policies that change during execution. We describe the implementation of our library and illustrate its use on a number of the benchmark examples considered in the literature.</p>", "authors": [{"name": "Jamie Morgenstern", "author_profile_id": "81470644639", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2338179", "email_address": "", "orcid_id": ""}, {"name": "Daniel R. Licata", "author_profile_id": "81100639330", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2338180", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863569", "year": "2010", "article_id": "1863569", "conference": "ICFP", "title": "Security-typed programming within dependently typed programming", "url": "http://dl.acm.org/citation.cfm?id=1863569"}