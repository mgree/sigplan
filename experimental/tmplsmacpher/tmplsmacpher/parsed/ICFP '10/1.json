{"article_publication_date": "09-27-2010", "fulltext": "\n The Gentle Art of Levitation James Chapman Pierre-\u00c9variste Dagand Peter Morris Institute of Cybernetics, \nTallinn Conor McBride University of Nottingham University of Technology University of Strathclyde pwm@cs.nott.ac.uk \njames@cs.ioc.ee {dagand,conor}@cis.strath.ac.uk Abstract We present a closed dependent type theory whose \ninductive types are given not by a scheme for generative declarations, but by encod\u00ading in a universe. \nEach inductive datatype arises by interpreting its description a .rst-class value in a datatype of descriptions. \nMore\u00adover, the latter itself has a description. Datatype-generic program\u00adming thus becomes ordinary programming. \nWe show some of the resulting generic operations and deploy them in particular, useful ways on the datatype \nof datatype descriptions itself. Simulations in existing systems suggest that this apparently self-supporting \nsetup is achievable without paradox or in.nite regress. Categories and Subject Descriptors D.1.1 [Programming \nTech\u00adniques]: Applicative (Functional) Programming; D.3.3 [Language Constructs and Features]: Data types \nand structures General Terms Design, Languages, Theory 1. Introduction Dependent datatypes, such as the \nubiquitous vectors (lists indexed by length) express relative notions of data validity. They allow us \nto function in a complex world with a higher standard of basic hygiene than is practical with the context-free \ndatatypes of ML\u00adlike languages. Dependent type systems, as found in Agda [Norell 2007], Coq [The Coq \nDevelopment Team], Epigram [McBride and McKinna 2004], and contemporary Haskell [Cheney and Hinze 2003; \nXi et al. 2003], are beginning to make themselves useful. As with rope, the engineering bene.ts of type \nindexing sometimes outweigh the dif.culties you can arrange with enough of it. The blessing of expressing \njust the right type for the job can also be a curse. Where once we might have had a small collection \nof basic datatypes and a large library, we now must cope with a cornucopia of .nely confected structures, \nsubtly designed, subtly different. The basic vector equipment is much like that for lists, but we implement \nit separately, often retyping the same code. The Agda standard library [Danielsson 2010], for example, \nsports a writhing mass of list-like structures, including vectors, bounded-length lists, difference lists, \nre.exive-transitive closures the list is petrifying. Here, we seek equipment to tame this gorgon s head \nwith re.ection. The business of belonging to a datatype is itself a notion rel\u00adative to the type s declaration. \nMost typed functional languages, Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. ICFP 10, September 27 29, 2010, Baltimore, Maryland, USA. Copyright \nc &#38;#169; 2010 ACM 978-1-60558-794-3/10/09. . . $10.00 including those with dependent types, feature \na datatype declara\u00adtion construct, external to and extending the language for de.ning values and programs. \nHowever, dependent type systems also allow us to re.ect types as the image of a function from a set of \ncodes a universe construction [Martin-L\u00f6f 1984]. Computing with codes, we expose operations on and relationships \nbetween the types they re.ect. Here, we adopt the universe as our guiding design principle. We abolish \nthe datatype declaration construct, by re.ecting it as a datatype of datatype descriptions which, moreover, \ndescribes itself. This apparently self-supporting construction is a trick, of course, but we shall show \nthe art of it. We contribute a closed type theory, extensible only de.nitionally, nonetheless equipped \nwith a universe of inductive families of datatypes;  a self-encoding of the universe codes as a datatype \nin the universe datatype generic programming is just programming;  a bidirectional type propagation \nmechanism to conceal artefacts of the encoding, restoring a convenient presentation of data;  examples \nof generic operations and constructions over our uni\u00adverse, notably the free monad construction;  datatype \ngeneric programming delivered directly, not via some isomorphic model or view of declared types.  We \nstudy two universes as a means to explore this novel way to equip a programming language with its datatypes. \nWe warm up with a universe of simple datatypes, just suf.cient to describe itself. Once we have learned \nthis art, we scale up to indexed datatypes, en\u00adcompassing the inductive families [Dybjer 1991; Luo 1994] \nfound in Coq and Epigram, and delivering experiments in generic pro\u00adgramming with applications to the \ndatatype of codes itself. We aim to deliver proof of concept, showing that a closed the\u00adory with a self-encoding \nuniverse of datatypes can be made practi\u00adcable, but we are sure there are bigger and better universes \nwaiting for a similar treatment. Benke, Dybjer and Jansson [Benke et al. 2003] provide a useful survey \nof the possibilities, including exten\u00adsion to inductive-recursive de.nition, whose closed-form presenta\u00adtion \n[Dybjer and Setzer 1999, 2000] is both an inspiration for the present enterprise, and a direction for \nfuture study. The work of Morris, Altenkirch and Ghani [Morris 2007; Mor\u00adris and Altenkirch 2009; Morris \net al. 2009] on (indexed) containers has informed our style of encoding and the equipment we choose to \ndevelop, but the details here re.ect pragmatic concerns about inten\u00adsional properties which demand care \nin practice. We have thus been able to implement our work as the basis for datatypes in the Epi\u00adgram \n2 prototype [Brady et al.]. We have also developed a strati.ed model of our coding scheme in Agda and \nCoq1. 1 This model is available at http://personal.cis.strath.ac.uk/~dagand/levitate.tar.gz  2. The \nType Theory One challenge in writing this paper is to extricate our account of datatypes from what else \nis new in Epigram 2. In fact, we demand relatively little from the setup, so we shall start with a vanilla \ntheory and add just what we need. The reader accustomed to de\u00adpendent types will recognise the basis \nof her favourite system; for those less familiar, we try to keep the presentation self-contained. 2.1 \nBase theory We adopt a traditional presentation for our type theory, with three mutually de.ned systems \nof judgments: context validity, typing, and equality, with the following forms: G f VALID G is a valid \ncontext, giving types to variables G f t :T term t has type T in context G G f s = t :Ts and t are equal \nat type T in context G The rules are formulated to ensure that the following sanity checks hold by induction \non derivations G f t :T . G f VALID . G f T : SET G f s = t :T . G f s:T . G f t :T and that judgments \nJ are preserved by well-typed instantiation. G; x:S;. f J . G f s:S . G;.[s/x] f J[s/x] We specify equality \nas a judgment, leaving open the details of its implementation, requiring only a congruence including \nordinary computation (\u00df-rules), decided, e.g., by testing a-equivalence of \u00df-normal forms [Adams 2006]. \nCoquand and Abel feature promi\u00adnently in a literature of richer equalities, involving .-expansion, proof-irrelevance \nand other attractions [Abel et al.; Coquand 1996]. Agda and Epigram 2 support such features, Coq currently \ndoes not, but they are surplus to requirements here. Context validity ensures that variables inhabit \nwell-formed sets. G f S : SET x . G f VALID G;x :S f VALID The basic typing rules for tuples and functions \nare also standard, save that we locally adopt SET : SET for presentational purposes. Usual techniques \nto resolve this typical ambiguity apply [Courant 2002; Harper and Pollack; Luo 1994]. A formal treatment \nof strat\u00adi.cation for our system is a matter of ongoing work. G; x: S; . f VALID G f s:S G f S = T : \nSET G; x:S;. f x : S G f s:T G f VALID G f VALID G f VALID G f SET : SET G f 1: SET G f []:1 G f S : \nSET G;x :S f T : SET G f (x :S)\u00d7T : SET G f s : S G; x:S f T :SET G f t : T[s/x] G f [s, t]x.T :(x : \nS)\u00d7T G f p:(x :S)\u00d7T G f p : (x:S) \u00d7T G f p0 p:S G f p1 p: T[p0 p/x] G f S : SET G;x :S f T : SET G f \n(x:S).T : SET G f S : SET G f f :(x:S).T G;x :S f t :T G f s : S G f .Sx.t : (x: S).T G f fs: T[s/x] \nNotation. We subscript information needed for type synthesis but not type checking, e.g., the domain \nof a .-abstraction, and suppress it informally where clear. Square brackets denote tuples, with a LISP-like \nright-nesting convention: [ab] abbreviates [a,[b,[]]]. The judgmental equality comprises the computational \nrules be\u00adlow, closed under re.exivity, symmetry, transitivity and structural congruence, even under binders. \nWe omit the mundane rules which ensure these closure properties for reasons of space. G f S : SET G;x \n:S f t :T G f s:S G f (.Sx.t) s = t[s/x] : T[s/x] G f s:S G; x: S f T : SET G f s:S G;x : S f T : SET \nG; s:S f t : T[s/x] G;s:S f t : T[s/x] G f p0 ([s,t]x.T ) = s : S G f p1 ([s,t]x.T ) = t :T[s/x] Given \na suitable strati.cation of SET, the computation rules yield a terminating evaluation procedure, ensuring \nthe decidability of equality and thence type checking.  2.2 Finite enumerations of tags It is time for \nour .rst example of a universe. You might want to offer a choice of named constructors in your datatypes: \nwe shall equip you with sets of tags to choose from. Our plan is to implement (by extending the theory, \nor by encoding) the signature En : SET #(E :En) : SET where some value E : En in the enumeration universe \ndescribes a type of tag choices #E. We shall need some tags valid identi.ers, marked to indicate that \nthey are data, not variables scoped and substitutable so we hardwire these rules: G f VALID G f VALID \ns a valid identi.er G f Tag : SET G f s:Tag Let us describe enumerations as lists of tags, with signature: \nnE:En cE (t :Tag)(E :En):En What are the values in #E? Formally, we represent the choice of a tag as \na numerical index into E, via new rules: G f VALID G f n:#E G f 0: #(cE tE) G f 1+n:#(cE tE) However, \nwe expect that in practice, you might rather refer to these values by tag, and we shall ensure that this \nis possible in due course. Enumerations come with further machinery. Each #E needs an eliminator, allowing \nus to branch according to a tag choice. For\u00admally, whenever we need such new computational facilities, \nwe add primitive operators to the type theory and extend the judgmental equality with their computational \nbehavior. However, for compact\u00adness and readability, we shall write these operators as functional programs \n(much as we model them in Agda). We .rst de.ne the small product p operator: p : (E : En)(P:#E . SET). \nSET p nE P . 1 p (cE tE) P . P 0 \u00d7p E .x.P (1+x) This builds a right-nested tuple type, packing a Pi \nvalue for each i in the given domain. The step case exposes our notational convention that binders scope \nrightwards as far as possible. These tuples are jump tables , tabulating dependently typed functions. \nWe give this functional interpretation the eliminator we need by the switch operator, which, unsurprisingly, \niterates projection: switch : (E : En)(P :#E . SET).p EP.(x :#E).Px switch (cE tE) Pb 0 . p0 b switch \n(cE tE) Pb (1+x) . switch E (.x.P(1+x)) (p1 b) x The p and switch operators deliver dependent elimination \nfor .nite enumerations, but are rather awkward to use directly. We do  G l exprEx C term . type G l \nSET = T C T ' G l T '= t C t' G l (t :T ) C t'. T ' G l f C f'. (x: S).T ' G; x:S;. f VALID G l S = s \nC sG;x:S;. l x C x . S G l fs C f ' s'. T[s'/x] G l p C p'. (x : S)\u00d7T G l p C p'. (x : S)\u00d7T G l p0 p \nC p0 p'. S G l p1 p C p1 p'. T[p0 p'/x] Figure 1. Type synthesis not write the range for a .-abstraction, \nso it is galling to supply P for functions de.ned by switch. Let us therefore .nd a way to recover the \ntedious details of the encoding from types.  2.3 Type propagation Our approach to tidying the coding \ncruft is deeply rooted in the bidirectional presentation of type checking from Pierce and Turner [Pierce \nand Turner 1998]. They divide type inference into two communicating components. In type synthesis, types \nare pulled out of terms. A typical example is a variable in the context: G;x : S; . f VALID G; x: S; \n. f x :S Because the context stores the type of the variable, we can extract the type whenever the variable \nis used. On the other hand, in the type checking phase, types are pushed into terms. We are handed a \ntype together with a term, our task consists of checking that the type admits the term. In doing so, \nwe can and should use the information provided by the type. Therefore, we can relax our requirements \non the term. Consider .-abstraction: G f S : SET G;x :S f t :T G f .Sx.t : (x:S) .T The of.cial rules \nrequire an annotation specifying the domain. However, in type checking, the .-type we push in determines \nthe domain, so we can drop the annotation. We adapt this idea, yielding a type propagation system, whose \npurpose is to elaborate compact expressions into the terms of our underlying type theory, much as in \nthe de.nition of Epi\u00adgram 1 [McBride and McKinna 2004]. We divide expressions into two syntactic categories: \nexprIn into which types are pushed, and exprEx from which types are extracted. In the bidirectional spirit, \nthe exprIn are subject to type checking, while the exprEx variables and elimination forms admit type \nsynthesis. We embed exprEx into exprIn, demanding that the synthesised type coincides with the type proposed. \nThe other direction only necessary to apply abstractions or project from pairs takes a type annotation. \nType synthesis (Fig. 1) is the source of types. It follows the exprEx syntax, delivering both the elaborated \nterm and its type. Terms and expressions never mix: e.g., for application, we instan\u00adtiate the range \nwith the term delivered by checking the argument expression. Hardwired operators are checked as variables. \nDually, type checking judgments (Fig. 2) are sinks for types. From an exprIn and a type pushed into it, \nthey elaborate a low\u00adlevel term, extracting information from the type. Note that we inductively ensure \nthe following sanity checks : G l e C t . T . G f t : T G l T = e C t . G f t : T G l type = exprIn C \nterm G l s C s'. S G l SET = S = T G l T = s C s' G f VALID G l SET = SET C SET G l SET = S C S' G;x:S' \nl SET = T C T ' G l SET = (x:S) .T C (x: S').T' G;x:S l T = t C t' G l (x:S) .T = .x.t C .Sx.t' G l \nSET = S C S' G;x:S' l SET = T C T ' G l SET = (x :S)\u00d7T C (x: S')\u00d7T' ' G l S = s C sG l T[s'/x] = t C \nt' ' G l (x:S) \u00d7T = [s,t] C [s,t']x.T G l (x : S).(y:T).U[[x,y]x.T /p] = f C f' G l (p:(x : S)\u00d7T).U =.f \nC .((x:S) \u00d7T)p. f' (p0 p)(p1 p) G f VALID G f VALID G l SET = 1 C 1 G l 1 = [] C [] G f VALID G l En \n= E C E' G l En = [] C nE G l En = [ t, E] C cE tE' G f E :En G l #E = t C n t = t0 G l #(cE tE) = t \nC 0 G l #(cE t0 E) = t C 1+n G f E :En G l #E = n C n' ' G l #(cE tE) = 0 C 0 G l #(cE t0 E) = 1+n C \n1+n # G l p E (. Ex.T) = [tC t' # G l (x:#E).T = [tC switch E (.#Ex.T) t' Figure 2. Type checking Canonical \nset-formers are checked: we could exploit SET : SET to give them synthesis rules, but this would prejudice \nour future strati.cation plans. Note that abstraction and pairing are free of annotation, as promised. \nMost of the propagation rules are unre\u00admarkably structural: we have omitted some mundane rules which \njust follow the pattern, e.g., for Tag. However, we also add abbreviations. We write .f , pronounced \nuncurry f for the function which takes a pair and feeds it to f one component at a time, letting us \nname them individually. Now, for the .nite enumerations, we go to work. Firstly, we present the codes \nfor enumerations as right-nested tuples which, by our LISP convention, we write as unpunctuated lists \nof tags [ t0 ... tn]. Secondly, we can denote an element by its name: the type pushed in allows us to \nrecover the numerical index. We retain the numerical forms to facilitate generic operations and ensure \nthat shadowing is punished .ttingly, not fatally. Finally, we express functions from enumerations as \ntuples. Any tuple-form, [] or [_,_], is accepted by the function space the generalised product if it \nis accepted by the small product. Propagation .lls in the appeal to switch, copying the range information. \nOur interactive development tools also perform the reverse transformation for intelligible output. The \nencoding of any spe\u00adci.c enumeration is thus hidden by these translations. Only, and rightly, in enumeration-generic \nprograms is the encoding exposed. Our type propagation mechanism does no constraint solving, just copying, \nso it is just the thin end of the elaboration wedge. It can afford us this assembly language level of \ncivilisation as En universe speci.es not only the representation of the low-level values in each set \nas bounded numbers, but also the presentation of these values as high-level tags. To encode only the \nformer, we should merely need the size of enumerations, but we extract more work from these types by \nmaking them more informative. We have also, en passant, distinguished enumerations which have the same \ncardinality but describe distinct notions: #[ red blue] is not #[ green orange].  3. A Universe of Inductive \nDatatypes In this section, we describe an implementation of inductive types, as we know them from ML-like \nlanguages. By working with fa\u00admiliar datatypes, we hope to focus on the delivery mechanism, warming up \ngently to the indexed datatypes we really want. Dy\u00adbjer and Setzer s closed formulation of induction-recursion \n[Dyb\u00adjer and Setzer 1999], but without the -recursion . An impredicative Church-style encoding of datatypes \nis not adequate for dependently typed programming, as although such encodings present data as non-dependent \neliminators, they do not support dependent induc\u00adtion [Geuvers 2001]. Whilst the .-calculus captures \nall that data can do, it cannot ultimately delimit all that data can be. 3.1 The power of S In dependently \ntyped languages, S-types can be interpreted as two different generalisations. This duality is re.ected \nin the notation we can .nd in the literature. The notation Sx:A(Bx) stresses that S-types are dependent \nsums , generalising sums over arbitrary arities, where simply typed languages have .nite sums. On the \nother hand, our choice, (x:A)\u00d7(Bx), emphasises that S\u00adtypes generalise products, with the type of the \nsecond component depending on the value of the .rst. Simply typed languages do not express such relative \nvalidity. In ML-like languages, datatypes are presented as a sum-of\u00adproducts. A datatype is de.ned by \na .nite sum of constructors, each carrying a product of arguments. To embrace these datatypes, we have \nto capture this grammar. With dependent types, the notion of sum-of-products translates into sigmas-of-sigmas. \n 3.2 The universe of descriptions While sigmas-of-sigmas can give a semantics for the sum-of\u00adproducts \nstructure in each node of the tree-like values in a datatype, we need to account for the recursive structure \nwhich ties these nodes together. We do this by constructing a universe [Martin-L\u00f6f 1984]. Universes are \nubiquitous in dependently typed program\u00adming [Benke et al. 2003; Oury and Swierstra 2008], but here we \ntake them as the foundation of our notion of datatypes. To add inductive types to our type theory, we \nbuild a universe of datatype descriptions by implementing the signature presented in Figure 3, with codes \nmimicking the grammar of datatype declara\u00adtions. We can read a description D : Descn as a pattern functor \non SETn, with [D] its action on an object, X, soon to be instantiated recursively. The superscripts indicate \nthe SET-levels at which we expect these objects in a strati.ed system. This is but an informal notation, \nto give a .avour of the strati.ed presentation. Note that the functors so described are strictly positive, \nby construction. Descriptions are sequential structures ending in 1, indicating the empty tuple. To build \nsigmas-of-sigmas, we provide a S code, interpreted as a S-type. To request a recursive component, we \nhave ind\u00d7 D, where D describes the rest of the node. These codes give us sigmas-of-sigmas with recursive \nplaces. An equivalent, more algebraic presentation could be given, as illustrated in Section 5. We admit \nto being a little coy, writing of implementing a signature without clarifying how. A viable approach \nwould simply be to extend the theory with constants for the constructors and an Descn : SETn+1 1 : Descn \nS (S : SETn)(D:S .Descn) : Descn ind\u00d7 (D:Descn) : Descn _ ] : Descn . SETn . SETn [ [ 1] X . 1 [ S SD] \nX . (s:S)\u00d7[Ds]X [ ind\u00d7 D] X . X \u00d7[D] X Figure 3. Universe of Descriptions operator for [D] . In Section \n4, you will see what we do instead. Meanwhile, let us gain some intuition by developing examples.  3.3 \nExamples We begin with the natural numbers, now working in the high-level expression language of Section \n2.3, exploiting type propagation. NatD : Descn NatD . S #[ zero suc][ 1 ( ind\u00d7 1)] Let us explain its \nconstruction. First, we use S to give a choice between the zero and suc constructors. What follows depends \non this choice, so we write the function computing the rest of the description in tuple notation. In \nthe zero case, we reach the end of the description. In the suc case, we attach one recursive argument \nand close the description. Translating the S to a binary sum, we have effectively described the functor: \nNatD Z . 1+Z Correspondingly, we can see the injections to the sum: [ zero] : [NatD] Z [ suc (z:Z)] : \n[NatD] Z The pattern functor for lists needs but a small change: ListD : SETn .Descn ListD X . S #[ nil \ncons][ 1 ( S X ._. ind\u00d7 1)] The suc constructor becomes cons, taking an X followed by a recursive argument. \nThis code describes the following functor: ListD XZ . 1+ X\u00d7Z Of course, we are not limited to one recursive \nargument. Here are the node-labelled binary trees: TreeD : SETn .Descn TreeD X . S #[ leaf node] [ 1 \n( ind\u00d7 ( S X ._. ind\u00d7 1))] Again, we are one evolutionary step away from ListD. However, instead of a \nsingle call to the induction code, we add another. The interpretation of this code corresponds to the \nfollowing functor: TreeD XZ . 1+Z \u00d7X \u00d7Z From the examples above, we observe that datatypes are de.ned \nby a S whose .rst argument enumerates the constructors. We call codes .tting this pattern tagged descriptions. \nAgain, this is a clear reminder of the sum-of-products style. Any description can be forced into this \nstyle with a singleton constructor set. We characterise tagged descriptions thus: TagDescn : SETn+1 TagDescn \n. (E :En) \u00d7(p E ._. Descn) de : TagDescn .Descn de ...E..D. S #E (switch E (._.Descn) D) It is not such \na stretch to expect that the familiar datatype declara\u00adtion might desugar to the de.nitions of a tagged \ndescription.  3.4 The least .xpoint So far, we have built pattern functors with our Desc universe. \nBeing polynomial functors, they all admit a least .xpoint, which we now construct by tying the knot: \nthe element type abstracted by the functor is now instantiated recursively: G f D : Descn G f D : Descn \nG f d :[D] (\u00b5D) G f \u00b5D: SETn G f con d : \u00b5D Tagged descriptions are very common, so we abbreviate: + \n\u00b5: TagDescn . SETn\u00b5+ T . \u00b5(de T) We can now build datatypes and their elements, e.g.: Nat . \u00b5+ [[ zero \nsuc],[ 1 ( ind\u00d7 1)]] : SETn con [ zero] : Nat con [ suc (n : Nat)] : Nat But how shall we compute with \nour data? We should expect an elimination principle. Following a categorical intuition, we might provide \nthe fold , or iterator , or catamorphism : cata : (D:Descn)(T :SETn) .([D] T .T) .\u00b5D.T However, iteration \nis inadequate for dependent computation. We need induction to write functions whose type depends on inductive \ndata. Following Benke et al. [2003], we adopt the following: ind : (D:Descn)(P : \u00b5D. SETk). ((d : [D] \n(\u00b5D)) .All D (\u00b5D) Pd .P(con d)). (x :\u00b5D).Px indDPm (con d) . md (all D (\u00b5D) P (indDPm) d) Here, All DXPd \nstates that P : X . SETk holds for every subobject x : X in D, and all DXPpd is a dependent map , applying \nsome p : (x : X).Px to each x contained in d. The de.nition (including an extra case, introduced soon) \nis in Figure 4.2 So, ind is our .rst operation generic over descriptions, albeit hardwired. Any datatype \nwe de.ne comes with induction.  Note that the very same functors [D] also admit greatest .x\u00adpoints: \nwe have indeed implemented coinductive types this way, but that is another story.  3.5 Extending type \npropagation We now have low level machinery to build and manipulate induc\u00adtive types. Let us apply cosmetic \nsurgery to reduce the syntactic overhead. We extend type checking of expressions: # G l #E = c C n G \nl [Dn] (\u00b5( S #ED)) = [t C t ' G l \u00b5( S #ED) = c[t C con [n,t ' ] Here c[t denotes a tag applied to a \nsequence of arguments, and # [t that sequence s repackaging as a right-nested tuple. Now we can just \nwrite data directly. zero : Nat suc (n:Nat) : Nat Once again, the type explains the legible presentation, \nas well as the low-level representation. We may also simplify appeals to induction by type propagation, \nas we have done with functions from pairs and enumerations. G l (d :[D] (\u00b5D)).All D (\u00b5D)(.\u00b5Dx.P) d .P[con \nd/x] ' = f C f ' G l (x : \u00b5D).P = Of C ind D (.\u00b5Dx.P) f 2 To pass the termination checker, we had to \ninline the de.nition of all into ind in our Agda model. A simulation argument shows that the de.nition \npresented here terminates if the inlined version does. Hence, although not directly structural, this \nde.nition is indeed terminating. This abbreviation is no substitute for the dependent pattern match\u00ading \nto which we are entitled in a high-level language built on top of this theory [Goguen et al. 2006]. It \ndoes at least make assembly language programming mercifully brief, albeit hieroglyphic. plus : Nat.Nat.Nat \nplus . O.[(._.._..y.y)(._. ..h.._..y. suc (hy))] This concludes our introduction to the universe of \ndatatype descriptions. We have encoded sum-of-products datatypes from the simply-typed world as data \nand equipped them with computation. We have also made sure to hide the details by type propagation. 4. \nLevitating the Universe of Descriptions In this section, we will ful.l our promises and show how we im\u00adplement \nthe signatures, .rst for the enumerations, and then for the codes of the Descn universe. Persuading these \nprograms to per\u00adform was a perilous pedagogical peregrination for the protagonist. Our method was indeed \nto hardwire constants implementing the signatures speci.ed above, in the .rst instance, but then attempt \nto replace them, step by step, with de.nitions: Is 2 + 2 still 4? , No, it s a loop! . But we did .nd \na way, so now we hope to convey to you the dizzy feeling of levitation, without the falling. 4.1 Implementing \n.nite enumerations In Section 2.2, we speci.ed the .nite sets of tags. We are going to implement (at \nevery universe level) the En type former and its constructors. Recall: En : SETn nE : En cE (t : Tag)(E \n: En):En The nE and cE constructors are just the nil and cons or ordinary lists, with elements from Tag. \nTherefore, we implement: En . \u00b5(ListD Tag) nE . nil cE tE . cons tE Let us consider the consequences. \nWe .nd that the type theory does not need a special type former En, or special constructors nE and cE. \nMoreover, the p EP operator, computing tuple types of Ps by recursion on E need not be hardwired: we \ncan just use the generic ind operator, as we would for any ordinary program. Note, however, that the \nuniverse decoder #E is hardwired, as are the primitive 0 and 1+ that we use for low-level values, and \nindeed the switch operator. We cannot dispose of data altogether! We have, however, gained the ordinariness \nof the enumeration codes, and hence of generic programs which manipulate them. Our next step is similar: \nwe are going to condense the entire naming scheme of datatypes into itself.  4.2 Implementing descriptions \nThe set of codes, Desc, is already some sort of datatype; as with En, we ought to be able to describe \nit, coding of Descn in Descn+1, spiralling upwards. Hence, this code would be a .rst-class citizen, born \nwith the generic equipment of datatypes. 4.2.1 First attempt Our .rst attempt gets stuck quite quickly: \nDescDn : Descn+1 .... .. 1 1 DescDn . de S , S SETn .S. {?} .... .. ind\u00d7 ind\u00d7 1 Let us explain where \nwe stand. Much as we have done so far, we .rst offer a constructor choice from 1, S, and ind\u00d7. You may \nnotice that the tagged notation we have used for the Descn constructors now .ts the facts: these were \nactually the tags we are de.ning. For 1, we immediately reach the end of the description.  All : (D:Descn)(X \n: SETn)(P:X . SETk) all : (D : Descn)(X :SETn)(P:X . SETk) (xs : [D] X). SETk (p:(x :X).Px)(xs:[D] X) \n.All D X P xs All 1 XP [] . 1 all 1 XPp [] . [] All ( S SD) XP [s,d] . All (Ds) XPd all ( S SD) XPp [s,d] \n. all (Ds) XPpd All ( ind\u00d7 D) XP [x, d] . Px\u00d7All DXPd all ( ind\u00d7 D) XPp [x,d] . [px, all DXPpd] All ( \nhind\u00d7 HD) XP [f ,d] . ((h:H).P (fh))\u00d7All DXPd all ( hind\u00d7 HD) XPp [f ,d] . [.h.p (fh),all DXPpd] . Figure \n4. De.ning and collecting inductive hypotheses For ind\u00d7, there is a single recursive argument. Describing \nS is Expanding de - and propagating types as in Figure 2 reveals problematic. Recall the speci.cation \nof S: the awful truth: Descn . \u00b5( S #[ 1 S ind\u00d7 hind\u00d7] S (S :SETn)(D:S .Descn) : Descn switch [ 1 S ind\u00d7 \nhind\u00d7](._.Descn+1) . 1 So, we .rst pack a SETn , S, as well we might when working in Descn+1. We should \nthen like a recursive argument indexed by S, but that is an exponential, and our presentation so far \ndelivers only S SETn .S. hind\u00d7 S 1 ind\u00d7 1 .. .. ) S SETn ._. ind\u00d7 1sums-of-products. To code our universe, \nwe must .rst enlarge it!  4.2.2 Second attempt In order to capture a notion of higher-order induction, \nwe add a code hind\u00d7 that takes an indexing set H. This amounts to give a recursive subobject for each \nelement of H. hind\u00d7 (H : SETn)(D: Descn) : Descn [ hind\u00d7 HD] X . (H .X)\u00d7[D] X Note that up to isomorphism, \nind\u00d7 is subsumed by hind\u00d7 1. However, the apparent duplication has some value. Unlike its coun\u00adterpart, \nind\u00d7 is .rst-order: we prefer not to demand dummy func\u00adtions from 1 in ordinary data, e.g. suc(._. n). \nIt is na\u00efve to imagine that up to isomorphism, any representation of data will do. First\u00ad # The recursion \nshows up only because we must specify the return type of the general-purpose switch, and it is computing \na Descn+1! Although type propagation allows us to hide this detail when de.n\u00ading a function, we cannot \nreadily suppress this information and check types when switch is fully applied. We are too close to give \nup now. If only we did not need to supply that return type, especially when we know what it must be! \nWe eliminate the recursion by specialising switch: switchD : (E :En).(p E ._. Descm).#E .Descm The magician \ns art rests here, in this extension. We conceal it behind a type propagation rule for switchD which we \napply with higher priority than for switch in general. = [t C t ' # G l p E .#Ex.Descm G l #E .Descm \n= [t C switchD Et' As a consequence, our de.nition above now propagates without in\u00adorder representations \nare .nitary by construction, and thus admit a richer, componentwise decidable equality than functions \nmay in general possess.3 troducing recursion. Of course, by pasting together the declaration We are now \nable to describe our universe of datatypes: of Descn and its internal copy, we have made it appear in \nits own type. Hardwired as a trusted fait accompli, this creates no regress, 1nn+DescDDesc:. . although \none must assume the de.nition to recheck it. ... . 1 1 Our Agda model does not formalise the switchD \nconstruction. Instead, we exhibit the isomorphism between declared and encoded S ind\u00d7 S SETn .S. hind\u00d7 \nS 1 ind\u00d7 1 DescDn . de .. .. .. , .. .. .. descriptions. Here, switchD lets us collapse this isomorphism, \nop\u00ad erationally identifying de.ned and coded descriptions. There are other ways to achieve a suf.cient \nspecialisation to avoid a recursive code, e.g., extending Descn with specialised codes for .nite sums \nand products, pushing the switch into the interpreta\u00ad tion of codes, rather than the code itself. Here, \nwe prefer not to add codes to Descn which are otherwise unmotivated. hind\u00d7 S SETn ._. ind\u00d7 1 The 1 and \nind\u00d7 cases remain unchanged, as expected. We success\u00ad fully describe the S case via the higher-order \ninduction, branching on S. The hind\u00d7 case just packs a SETn with a recursive argument. At a .rst glance, \nwe have achieved our goal. We have described the codes of the universe of descriptions. The .xpoint of \n[DescDn]is a datatype just like Descn, in SETn+1. Might we be so bold as to take Descn . \u00b5DescDn as the \nlevitating de.nition? If we do, we shall come down with a bump! To complete our levitation, just as in \nthe magic trick, requires hidden assistance. Let us explain the problem and reveal the invisible cable \nwhich .xes it. 4.2.3 Final move The de.nition Descn . \u00b5DescDn is circular, but the offensive recursion \nis concealed by a prestidigitation. 3 E.g., extensionally, there is one function in #[] .Nat; intensionally, \nthere is a countable in.nitude which it is dangerous to identify de.nitionally. We have levitated Desc \nat every level. Beyond its pedagogical value, this exercise has several practical outcomes. First, it \ncon\u00ad .rms that each Desc universe is just plain data. As any piece of data, it can therefore be inspected \nand manipulated. Moreover, it is expressed in a Desc universe. As a consequence, it is equipped, for \nfree, with an induction principle. So, our ability to inspect and program with Desc is not restricted \nto a meta-language: we have the necessary equipment to program with data, so we can program over datatypes. \nGeneric programming is just programming.  4.3 The generic catamorphism In Section 3.4, we hardwired \na dependent induction principle, but sometimes, iteration suf.ces. Let us construct the catamorphism. \nWe proceed by induction on the data in \u00b5D: the non-dependent return type T is readily propagated. Given \na node xs and the in\u00adduction hypotheses, the method ought to build an element of T. Provided that we \nknow how to make an element of [D] T, this step will be performed by the algebra f . Let us take a look \nat this jigsaw:  cata : (D: Desc)(T :SET).([D] T .T).\u00b5D.T cata DTf . O.xs..hs.f {?} The hole remains: \nwe have xs : [D] \u00b5D and hs : All D \u00b5D (._.T) xs to hand, and we need a [D] T. Now, xs has the right shape, \nbut its components have the wrong type. However, for each such component, hs holds the corresponding \nvalue in T. We need a function to replace the former with the latter: this pattern matching sketch yields \nan induction on D. We .ll the hole with replace D (\u00b5D) T xs hs. replace : (D:Desc)(X, Y : SET) (xs : \n[D] X).All DX (._. Y) xs.[D] Y replace 1 XY [] [] . [] replace ( S SD) XY [s,d] d' . [s, replace (Ds) \nXYdd' ] replace ( ind\u00d7 D) XY [x, d][y,d' ] . [y,replace DXYdd' ] replace ( hind\u00d7 HD) XY [f ,d][g,d' ] \n. [g,replace DXYdd' ] We have shown how to derive a generic operation, cata, from a pre-existing generic \noperation, ind, by manipulating descriptions as data: the catamorphism is just a function taking each \nDesc value to a datatype speci.c operation. This is polytypic programming, as in PolyP [Jansson and Jeuring \n1997], made ordinary.  4.4 The generic free monad In this section, we try a more ambitious generic operation. \nGiven a functor a signature of operations represented as a tagged description we build its free monad, \nextending the signature with variables and substitution. Let us recall this construction in, say, Haskell. \nGiven a functor f, the free monad over f is given thus: data FreeMonad f x = Var x | Op (f (FreeMonad \nf x)) Provided f is an instance of Functor, we may take Var for return and use f s fmap to de.ne \u00bb= as \nsubstitution. Being an inductive type, FreeMonad arises by a pattern functor: FreeMonadD FXZ . X +FZ \nOur construction takes the functor as a tagged description, and given a set X of variables, computes \nthe tagged description of the free monad pattern functor. _ * : TagDesc. SET .TagDesc [E, D] * X . [[ \nvar ,E], [ S X 1,D]] We simply add a constructor, var, making its arguments S X 1 just an element of \nX. E and D stay put, leaving the other construc\u00adtors unchanged. Unfolding the interpretation of this \nde.nition, we .nd an extended sum, corresponding to the X+ in FreeMonadD. Taking the .xpoint ties the \nknot and we have our data. Now we need the operations. As expected, .x. var x plays the r\u00f4le of return, \nmaking variables terms. Meanwhile, bind is indeed substitution, which we now implement generically, making \nuse of cata. Let us write the type, and start .lling in the blanks: subst : (D:TagDesc)(X,Y : SET).(X \n.\u00b5+(D*Y)). \u00b5+(D*X).\u00b5+(D*Y) subst DXY s . cata (de (D*X)) (\u00b5+(D*Y)) {?} We are left with implementing \nthe algebra of the catamorphism. Its role is to catch appearances of var x and replace them by s x. This \ncorresponds to the following de.nition: apply : (D:TagDesc)(X,Y : SET).(X .\u00b5+(D*Y)). [de (D*X)] (\u00b5+(D*Y)).\u00b5+(D*Y) \napply DXY s [ var x] . s x apply DXY s [c,xs] . con [c,xs] Object Role Status En Build .nite sets Levitated \nDesc Describe pattern functors Levitated Interpret descriptions Hardwired \u00b5, con[_] De.ne, inhabit .xpoints \nHardwired ind, All, all Induction principle Hardwired Table 1. Summary of constructions on Descriptions \nWe complete the hole with apply DXY s. Every tagged descrip\u00adtion can be seen as a signature of operations: \nwe can uniformly add a notion of variable, building a new type from an old one, then providing the substitution \nstructure.  4.5 Skyhooks all the way up? In this section, we have seen how to levitate descriptions. \nAlthough our theory, as presented here, takes SET : SET, our annotations indicate how a strati.ed theory \ncould code each level from above. Wedonotrelyontheparadoxicalnatureof SET :SET to.attenthe hierarchy \nof descriptions and .t large inside small. We shall now be more precise about what we have done. Let \nus .rst clarify the status of the implementation. The kit for making datatypes is presented in Table \n1. For each operation, we describe its role and its status, making clear which components are self-described \nand which ones are actually implemented. In a strati.ed system, the self-encoded nature of Desc appears \nonly in a set polymorphic sense: the principal type of the encoded description generalises to the type \nof Desc itself. We encode this much in our set polymorphic model in Agda and in our Coq model, crucially \nrelying on typical ambiguity [Harper and Pollack]. We step outside current technology only to replace \nthe declared Desc with its encoding. Even this last step, we can approximate within a standard pred\u00adicative \nhierarchy. Fix a top level, perhaps 42. We may start by declaring Desc42 : SET43. We can then construct \nDescD41 : Desc42 and thus acquire an encoded Desc41. Although Desc41 is en\u00adcoded, not declared, it includes \nthe relevant descriptions, includ\u00ading DescD40. We can thus build the tower of descriptions down to Desc0, \nencoding every level below the top. Description of descrip\u00adtions forms a spiral , rather than a circle. \nWe have modelled this process exactly in Agda, without any appeal to dependent pattern matching, induction-recursion, \nor set polymorphism. All it takes to build such a sawn-off model of encodings is inductive de.nition \nand a cumulative predicative hierarchy of set levels. 5. A Universe of Inductive Families So far, we \nhave explored the realm of inductive types, building on intuition from ML-like datatypes, using type \ndependency as a descriptive tool in Desc and its interpretation. Let us now make dependent types the \nobject as well as the means of our study. Dependent datatypes provide a way to work at higher level of \nprecision a priori, reducing the sources of failure we might otherwise need to manage. For the perennial \nexample, consider vectors lists indexed by length. By making length explicit in the type, we can prevent \nhazardous operations (the type of head demands vectors of length suc n) and offer stronger guarantees \n(pointwise addition of n-vectors yields an n-vector). However, these datatypes are not individually inductive. \nFor instance, we have to de.ne the whole family of vectors mutually, in one go. In dependently typed \nlanguages, the basic grammar of datatypes is that of inductive families. To capture this grammar, we \nmust account for indexing.  5.1 The universe of indexed descriptions We presented the Desc universe \nas a grammar of strictly positive endofunctors on SET and developed inductive types by taking a .xpoint. \nTo describe inductive families indexed by some I : SET, we play a similar game with endofunctors on the \ncategory SETI , families of sets X, Y : I . SET for objects, and for morphisms, families of functions \nin X ..Y, de.ned pointwise: X ..Y . (i:I).Xi .Yi An indexed functor in SETI . SETJ has the .avour of \na device driver, characterising responses to a given request in J where we may in turn make subrequests \nat indices chosen from I. When we use indexed functors to de.ne inductive families of datatypes, I and \nJ coincide: we explain how to make a node .t a given index, including subnodes at chosen indices. E.g., \nif we are asked for a vector of length 3, we choose to ask in turn for a tail of length 2. To code up \nvalid notions of response to a given request, we introduce IDesc and its interpretation: IDesc (I :SET) \n: SET [_] :(I:SET). IDesc I .(I . SET). SET An IDescI speci.es just one response, but a request-to-response \nfunction, R : I .IDesc I, yields a strictly positive endofunctor .X..i. [Ri]IX : SETI . SETI whose .xpoint \nwe then take: G f I : SET G f R:I .IDesc I G f \u00b5IR:I . SET G f I :SET G f R : I .IDesc I IDesc (I :SET) \n: SET var (i:I) : IDesc I k (A: SET) : IDesc I (D:IDesc I) \u00d7(D : IDesc I) : IDesc I S (S : SET)(D:S .IDesc \nI) : IDesc I . (S : SET)(D:S .IDesc I) : IDesc I [_ ] :(I:SET). IDesc I .(I . SET). SET var i]IX . Xi \nk K]I X . K D \u00d7D' ]IX . [D]IX \u00d7[D' ]IX S SD]IX . (s:S) \u00d7[Ds]IX [ . SD]IX . (s:S) .[Ds]IX Figure 6. Universe \nof indexed descriptions  5.2 Examples Natural numbers: For basic reassurance, we upgrade NatD: upgrade \nNatD : IDesc 1 upgrade NatD . S (#[ zero suc]) [( k1)( var [] \u00d7 k1)] Note that trailing 1 s keep our \nright-nested, []-terminated tuple structure, and with it our elaboration machinery. We can sim\u00adilarly \nupgrade any inductive type. Moreover, IDesc I can now code a bunch of mutually inductive types, if I \nenumerates the bunch [Paulin-Mohring 1996; Yakushev et al. 2009]. Indexed descriptions: Note that IDesc \nI is a plain inductive type, parametrised by I, but indexed trivially. IDescD : (I : SET).IDesc 1 . . \n. IDescD I . S var . G f i : I G f x:[Ri]I (\u00b5IR) G f con x:\u00b5IR i We de.ne the IDesc grammar in Figure \n6, delivering only ( k I \u00d7 k1) k \u00d7 S .... .... ( k SET \u00d7 k1) ( var [] \u00d7 var [] \u00d7 k1) ( S SET .S.( . S \n._. var []) \u00d7 k1) # .... .... strictly positive families. As well as indexing our descriptions, we have \nrefactored a little, adopting a more compositional algebra of . ( S SET .S.( . S ._. var []) \u00d7 k1) Therefore, \nthis universe is self-describing and can be levitated.codes, where Desc is biased towards the right-nested \ntuples. We As before, we rely on a special purpose switchID operator to buildnow have var i for recursive \nsubrequests at a chosen index i, with the .nite function [...] without mentioning IDesc. Vectors: So \nfar, our examples live in IDesc 1, with no interesting tupling by right-associative \u00d7 and higher-order \nbranching by .. Upgrade your old Desc to a trivially indexed IDesc 1 as follows! upgrade : Desc .IDesc \n1 upgrade 1 . k1 upgrade ( S SD) . S S .s. upgrade (Ds) upgrade ( ind\u00d7 D) . var [] \u00d7upgrade D upgrade \n( hind\u00d7 HD) . ( . H ._. var []) \u00d7upgrade D To deliver induction for indexed datatypes, we need the holds \neverywhere machinery. We present AllI and allI in Figure 5, with a twist where Desc admits the all construction, \nIDesc is closed under it! The AllI operator for a description indexed on I is strictly positive in turn, \nand has a description indexed on some (i : I)\u00d7Xi. indexing. Let us at least have vectors. Recall that \nthe constructors vnil and vcons are de.ned only for zero and suc respectively: data Vec (X : SET) : (i:Nat). \nSET where vnil : Vec X zero vcons : (n:Nat) .X .Vec Xn.Vec X ( suc n) One way to code constrained datatypes \nis to appeal to a suitable notion of propositional equality == on indices. The constraints are expressed \nas Henry Ford equations in the datatype. For vectors: VecD : SET .Nat.IDesc Nat Induction on indexed \ndescriptions is then hardwired thus: D VecD Xi . S D vnil ( k ( zero == i))  indI : (I:SET) .(R:I .IDesc \nI)(P:((i:I)\u00d7\u00b5IR i). SET). # vcons( S Nat .n. k X \u00d7 var n \u00d7 k ( suc n == i)) ((i:I)(xs:[Ri]I (\u00b5IR)). [AllI(Ri)(\u00b5IR) \nxs] P .P [i,con xs]). (i:I)(x:\u00b5IR i).P [i,x] indI RPmi (con xs) . m i xs (allIRi (\u00b5IR) P (..i..xs.indI \nRPm) xs) You may choose vnil for any index you like as long as it is zero; in the vcons case, the length \nof the tail is given explicitly, and the index i must be one more. Our previous 1-terminated tuple types \ncan now be seen as the trivial case of constraint-terminated tupleThe generic catamorphism, cataI, is \nconstructed from indI as before. Its type becomes more elaborated, to deal with the indexing: cataI :(I \n:SET)(R:I .IDesc I) types, with elaboration supplying the witnesses when trivial. In this paper, we remain \nanxiously agnostic about propositional equality. Any will do, according to conviction; many variations \nare (T :I . SET).((i:I).[Ri] T .Ti) .\u00b5IR..T popular. The homogeneous identity type used in Coq is ill-suited \nto dependent types, but its heterogeneous variant (forming equations AllI : (I:SET).(D : IDesc I)(X \n:I . SET). [D]IX .IDesc ((i: I) \u00d7Xi) AllI ( var i) Xx . var [i,x] AllI ( k K) Xk . k1 AllI (D \u00d7D' ) X \n[d,d' ] . AllIDXd \u00d7AllID' Xd' AllI ( S SD) X [s,d] . AllI(Ds) Xd AllI ( . SD) Xf . . S .s.AllI(Ds) X \n(fs) allI : (I:SET).(D :IDesc I)(X :I . SET)(P : ((i:I)\u00d7Xi) . SET) . ((x:(i:I)\u00d7Xi).Px).(xs:[D]IX).[AllID \nX xs] P allI ( var i) XPpx . p [i,x] allI ( k K) XPpk . [] allI (D \u00d7D' ) XPp [d,d' ] . [allIDXPpd,allID' \nXPpd' ] allI ( S SD) XPp [s, d] . allI(Ds) XPpd allI ( . SD) XPpf . .a.allI(Da) XPp (fa) Figure 5. Indexed \ninduction predicates regardless of type) allows the translation of pattern matching with structural recursion \nto indI [Goguen et al. 2006]. The extensional equality of Altenkirch et al. [2007] also sustains the \ntranslation. However, sometimes, the equations are redundant. Looking back at Vec, we .nd that the equations \nconstrain the choice of constructor and stored tail index retrospectively. But inductive fam\u00adilies need \nnot store their indices [Brady et al. 2003]! If we analyse the incoming index, we can tidy our description \nof Vec as follows: VecD (X : SET) : Nat .IDesc Nat VecD X zero . k1 VecD X ( suc n) . k X \u00d7 var n The \nconstructors and equations have simply disappeared. A similar example is Fin (bounded numbers), speci.ed \nby: data Fin : (n: Nat). SET where fz : (n:Nat) .Fin ( suc n) fs : (n:Nat) .Fin n .Fin ( suc n) In this \ncase, we can eliminate equations but not constructors, since both fz and fs both target suc: FinD : Nat.IDesc \nNat FinD zero . S #[] [] FinD ( suc n) . S #[ fz fs] [( k1)( var n)] This technique of extracting information \nby case analysis on indices applies to descriptions exactly where Brady s forcing and detagging optimisations \napply in compilation. They eliminate just those constructors, indices and constraints which are redundant \neven in open computation. In closed computation, where proofs can be trusted, all constraints are dropped. \nTagged indexed descriptions: Let us re.ect this index analysis technique. We can divide a description \nof tagged indexed data in two: .rst, the constructors that do not depend on the index; then, the constructors \nthat do. The non-dependent part mirrors the de.\u00adnition for non-indexed descriptions. The index-dependent \npart sim\u00adply indexes the choice of constructors by I. Hence, by inspecting the index, it is possible \nto vary the menu of constructors. TagIDesc I . AlwaysD I \u00d7IndexedD I AlwaysD I . (E :En)\u00d7(i:I).p E ._.IDesc \nI IndexedD I . (F : I .En)\u00d7(i : I) .p (Fi) ._. IDesc I In the case of a tagged Vec, for instance, for \nthe index zero, we would only propose the constructor nil. Similarly, for suc n, we would only propose \nthe constructor cons. We write de Di to denote the IDesc I computed from the tagged indexed description \nD at index i. Its expansion is similar to the de.nition of de for tagged descriptions, except that it \nmust also append the two parts. We again write \u00b5+ID for \u00b5I (de D) . Typed expressions: We are going to \nde.ne a syntax for a small language with two types, natural numbers and booleans: Ty . #[ nat bool] This \nlanguage has values, conditional expression, addition and comparison. Informally, their types are: val \n: Val ty .ty plus : nat . nat. nat cond : bool .ty.ty.ty le : nat . nat. bool The function Val interprets \nobject language types in the host lan\u00adguage, so that arguments to val .t their expected type. Val : Ty. \nSET Val nat . Nat Val bool . Bool We take Nat and Bool to represent natural numbers and Booleans in the \nhost language, equipped with addition +H and comparison =H. We express our syntax as a tagged indexed \ndescription, indexing over object language types Ty. We note that some constructors are always available, \nnamely val and cond. On the other hand, plus and le constructors are index-dependent, with plus available \njust when building a nat, le just for bool. The code, below, re.ects this intuition, with the .rst component \nuniformly offering val and cond, the second selectively offering plus or le. ExprD : TagIDesc Ty ExprD \n. [ExprAD,ExprID] ExprAD : AlwaysD Ty DD D val k (Val ty) \u00d7 k1 ExprAD . , .ty. cond var bool \u00d7 var ty \n\u00d7 var ty \u00d7 k1 ExprID : IndexedD Ty DD [ plus] ExprID . , ._.[ var nat \u00d7 var nat \u00d7 k1] [ le] Given the \nsyntax, let us supply the semantics. We implement an evaluator as a catamorphism: eval. : (ty:Ty).\u00b5+Ty \nExprD ty .Val ty eval. ty term . cataITy (de ExprD) Val eval. ty term To .nish the job, we must supply \nthe algebra which implements a single step of evaluation, given subexpressions evaluated already. eval. \n: (ty : Ty) .[(de ExprD) ty]Ty Val.Val ty eval. _ ( val x) . x eval. _ ( cond true x _) . x eval. _ ( \ncond false _ y) . y eval. nat ( plus xy) . x +H y eval. bool ( le xy) . x =H y Hence, we have a type-safe \nsyntax and a tagless interpreter for our language, in the spirit of Augustsson and Carlsson [1999], with \nhelp from the generic catamorphism. However, so far, we are only able to de.ne and manipulate closed \nterms. Adding variables, it is possible to build and manipulate open terms, that is, terms in a context. \nWe shall get this representation, for free, thanks to the free indexed monad construction.    5.3 \nFree indexed monad Correspondingly, you can update an old ExprD to a shiny closeTm: In Section 4.4, we \nhave built a free monad operation for simple update : \u00b5+Ty ExprD ..\u00b5+Ty closeTm descriptions. The process \nis similar in the indexed world. Namely, update ty tm . cataITy (de ExprD)(\u00b5+Ty closeTm) given an indexed \nfunctor, we derive the indexed functor coding its (._..[tag,tm].con [1+tag, tm]) ty tm free monad: The \nother direction of the isomorphism is straightforward, the var * (I:SET).(R : TagIDesc I)(X : I . SET) \n.TagIDesc I # : case being impossible. Therefore, we are entitled to reuse the eval. _ * IR . [E, F] \n [ cons var (p0 E),.i.[ k (Ri), (p1 E) i]],F function to de.ne the semantics of closeTm. Just as in the \nuniverse of descriptions, this construction comes with an obvious return and a substitution operation, \nthe bind. Its de.nition is the following: substI : (I:SET) .(X,Y :I . SET).(R:TagIDesc I) (X ..\u00b5+I (RI \n* Y)).\u00b5+I (RI * X)..\u00b5+I (R* IY) substI XYR s it . cataII (de R* X)(\u00b5+Y (R* Y)) (applyI RXY s) it where \napplyI is de.ned as follows: applyI : (I:SET).(R:TagIDesc I)(X,Y :I . SET). (X ..\u00b5+I (R* IY)). [de RI \n* X]I\u00b5+I (RI * Y) ..\u00b5+I (RI * Y) applyI RXY s i [ var,x] . s ix applyI RXY s i [c,ys] . con [c,ys] The \nsubscripted types corresponds to implicit arguments that can be automatically inferred, hence do not \nhave to be typed in. Let us now consider two examples of free indexed monads. Typed expressions: In the \nprevious section, we presented a lan\u00adguage of closed arithmetic expressions. Using the free monad con\u00adstruction, \nwe are going to extend this construction to open terms. An open term is de.ned with respect to a context, \nrepresented by a snoc-list of types: Context : SET [] : Context snoc : Context.Ty.Context An environment \nrealises the context, packing a value for each type: Env : Context. SET Now we would like to give a semantics \nto the open term lan\u00adguage. We proceed in two steps: .rst, we substitute variables by their value in \nthe context; then, we evaluate the resulting closed term. Thanks to eval., the second problem is already \nsolved. Let us focus on substituting variables from the context. Again, we can subdivide this problem: \n.rst, discharging a single variable from the context; then, applying this discharge function on every \nvariables in the term. The discharge function is relative to the required type and a context of the right \ntype. Its action is to map values to themselves, and variables to their value in context. This corresponds \nto the following function: discharge : (G:Context).Env G.Var G ..\u00b5+Ty closeTm discharge G g ty v . con \n[ val,lookup G g ty v] We are now left with applying discharge over all variables of the term. We simply \nhave to .ll in the right arguments to substI, the type guiding us: substExpr : (G:Context). (Var G ..\u00b5+Ty \ncloseTm).. \u00b5+Ty (openTm G)..\u00b5+Ty closeTm substExpr G ty g s tm . substITy (Var G) Empty ExprD s ty tm \nHence completing our implementation of the open terms inter\u00adpreter. Without much effort, we have described \nthe syntax of a well\u00adtyped language, together with its semantics. Indexed descriptions: An interesting \ninstance of free monad is IDesc itself. Indeed, var is nothing but the return. The remaining constructors \nform the carrier functor, trivially indexed by 1. The signature functor is described as follow: . . IDescDSig \n: AlwaysD 1 [ k \u00d7 S .], Env [] . 1 Env (snoc GS) . Env G\u00d7Val S . . k SET .... ._. .. .... In this setting, \nwe de.ne type variables, Var by: IDescDSig . var [] \u00d7 var [] S SET (.S. . S (._. var [])) .. Var : Context \n.Ty . SET Var [] T . [] Var (snoc GS) T . (Var GT)+(S == T) S SET (.S. . S (._. var [])) We get IDesc \nI by extending the signature with variables from I: While Val maps the type to the corresponding host \ntype, Var indexes a value in the context, obtaining a proof that the types match. The lookup function \nprecisely follow this semantics: lookup : (G:Context).Env G.(T :Ty).Var GT .Val T lookup (snoc G .T )[g,t] \nT (right re.) . t lookup (snoc GS)[g,t] T (left x) . lookup GgTx Consequently, taking the free monad \nof ExprD by Var G, we obtain the language of open terms in a context G: openTm G . ExprD* Ty (Var G) \nIn this setting, the language of closed terms corresponds to the free monad assigning an empty set of \nvalues to variables closeTm . ExprD* Ty Empty where Empty : Ty . SET Empty _ . #[] Allowing variables \nfrom an empty set is much like forbidding variables, so closeTm and ExprD describe isomorphic datatypes. \nIDescD : (I :SET) .TagIDesc 1 * IDescD I . [IDescDSig,[._.[],._.[]]] 1 ._.I The fact that indexed descriptions \nare closed under substitution is potentially of considerable utility, if we can exploit this fact: [sD]JX \n. [D]I .i.[si]JX where s : I .IDesc J By observing that a description can be decomposed via substitu\u00adtion, \nwe split its meaning into a superstructure of substructures, e.g. a database containing salaries , ready \nfor traversal operations preserving the former and targeting the latter. 6. Discussion In this paper, \nwe have presented a universe of datatypes for a de\u00adpendent type theory. We started from an unremarkable \ntype theory with dependent functions and tuples, but relying on few other as\u00adsumptions, especially where \npropositional equality is concerned. We added .nite enumeration suf.cient to account for constructor \nchoice, and then we built coding systems, .rst (as a learning ex\u00adperience) for simple ML-like inductive \ntypes, then for the indexed inductive families which dependently typed programmers in Agda, Coq and Epigram \ntake for granted. We adopt a bidirectional type propagation mechanism to conceal artifacts of the encoding, \ngiving a familiar and practicable constructor-based presentation to data.  Crucially to our approach, \nwe ensure that the codes describing datatypes inhabit a datatype with a code. In a strati.ed setting, \nwe avoid paradox by ensuring that this type of codes lives uniformly one level above the types the codes \ndescribe. The adoption of or\u00addinary data to describe types admits datatype-generic operations implemented \njust by ordinary programming. In working this way, we make considerable use of type equality modulo open \ncomputa\u00adtion, silently specialising the types of generic operations as far as the datatype code for any \ngiven usage is known. 6.1 Related work in Generic Programming Generic programming is a vast topic. We \nrefer our reader to Gar\u00adcia et al. [2003] for a broad overview of generic programming in various languages. \nFor Haskell alone, there is a myriad of propos\u00adals: Hinze et al. [2007] and Rodriguez et al. [2008] provide \nuseful comparative surveys. Our approach follows the polytypic programming style, as initi\u00adated by PolyP \n[Jansson and Jeuring 1997]. Indeed, we build generic functions by induction on pattern functors, exploiting \ntype-level computation to avoid the preprocessing phase: our datatypes are, natively, nothing but codes. \nWe have the type-indexed datatypes of Generic Haskell [Hinze et al. 2002] for free. From one datatype, \nwe can compute others and equip them with relevant structure: the free monad construc\u00adtion provides one \nexample. Our approach to encoding datatypes as data also sustains generic views [Holdermans et al. 2006], \nallowing us to rebias the presentation of datatypes conveniently. Tagged de\u00adscriptions, giving us a sum-of-sigmas \nview, are a natural example. Unlike Generic Haskell, we do not support polykinded pro\u00adgramming [Hinze \n2000]. Our descriptions are limited to endo\u00adfunctors on SETI . Whilst indexing is known to be suf.cient \nto encode a large class of higher-kinded datatypes [Altenkirch and McBride 2002], we should rather hope \nto work in a more com\u00adpositional style. We are free to write higher-order programs ma\u00adnipulating codes, \nbut is not yet clear whether that is suf.cient to deliver abstraction at higher kinds. Similarly, it \nwill be interesting to see whether arity-generic programming [Weirich and Casingh\u00adino 2010] arises just \nby computing with our codes, or whether a richer abstraction is called for. The Scrap Your Boilerplate \n[L\u00e4mmel and Peyton Jones 2003] (SYB) approach to generic programming offers a way to construct generic \nfunctions, based on dynamic type-testing via the Typeable type class. SYB cannot compute types from codes, \nbut its dy\u00adnamic character does allow a more .exible ad hoc approach to generic data traversal. By maintaining \nthe correspondence between codes and types whilst supporting arbitrary inspection of codes, we pursue \nthe same .exibility statically. The substitutive character of IDesc may allow us to observe and exploit \nad hoc substructural re\u00adlationships in data, but again, further work is needed if we are to make a proper \ncomparison. 6.2 Generic Programming with Dependent Types Generic programming is not new to dependent \ntypes. Altenkirch and McBride [2002] developed a universe of polykinded types in Lego; Norell [2002] \ngave a formalisation of polytypic program\u00adming in Alfa, a precursor to Agda; Verbruggen et al. [2008, \n2009] provided a framework for polytypic programming in the Coq the\u00adorem prover. However, these works \naim at modelling PolyP or Generic Haskell in a dependently-typed setting for the purpose of proving correctness \nproperties of Haskell code. Our approach is different in that we aim at building a foundation for datatypes, \nin a dependently-typed system, for a dependently-typed system. Closer to us is the work of Benke et al. \n[2003]. This seminal work introduced the usage of universes for developing generic programs. Our universes \nshare similarities to theirs: our universe of descriptions is similar to their universe of iterated induction, \nand our universe of indexed descriptions is equivalent to their universe of .nitary indexed induction. \nThis is not surprising, as we share the same source of inspiration, namely induction-recursion. However, \nwe feel ready to offer a more radical prospectus. Their approach is generative: each universe extends \nthe base type theory with both type formers and elimination rules. Thanks to levitation, we rely only \non a generic induction and a specialised switchD, clos\u00ading the type theory. We explore programming with \ncodes, but also how to conceal the encoding when writing ordinary programs. 6.3 Metatheoretical Status \nThe SET : SET approach we have taken in this paper is convenient from an experimental perspective, and \nit has allowed us to focus primarily on the encoding of universes, leaving the question of strati.cation \n(and with it, consistency, totality, and decidability of type checking) to one side. However, we must \nsurely face up to the latter, especially since we have taken up the habit of constructing the set of \nall sets . A proper account requires a concrete proposal for a system of strati.ed universes which allows \nus to make level\u00adpolymorphic constructions, and we are actively pursuing such a proposal. We hope soon \nto have something to prove. In the meantime, we can gain some con.dence by systemati\u00adcally embedding \npredicative fragments of our theory within sys\u00adtems which already offer a universe hierarchy. We can, \nat the very least, con.rm that in UTT-style theories with conventional induc\u00adtive families of types [Luo \n1994], as found in Coq (and in Agda if one avoids experimental extensions), we build the tower of uni\u00adverses \nwe propose, cut off at an arbitrary height. It is correspond\u00adingly clear that some such system can be \nmade to work, or else that other, longer-standing tools are troubled. A metatheoretical issue open at \ntime of writing concerns the size of the index set I in IDesc I. Both Agda and recent versions of Coq \nallow inductive families with large indices, effectively al\u00adlowing higher-kind .xpoints on SETSET and \nmore. They retain the safeguard that the types of substructures must be as small as the inductively de.ned \nsuperstructure. This liberalisation allows us large index sets in our models, but whilst it offers no \nobvious route to paradox by smuggling a large universe inside a small type, it is not yet known to be \nsafe. We can restrict I as necessary to avoid paradox, provided 1, used to index IDesc itself, is small \n.  6.4 Further Work Apart from the need to nail down a strati.ed version of the system and its metatheory, \nwe face plenty of further problems and oppor\u00adtunities. Although we have certainly covered Luo s criteria \nfor in\u00adductive families [Luo 1994], there are several dimensions in which to consider expanding our universe. \nFirstly, we seek to encompass inductive-recursive datatype fam\u00adilies [Dybjer and Setzer 2001], allowing \nus to interleave the de.ni\u00adtion and interpretation of data in intricate and powerful ways. This interleaving \nseems particularly useful when re.ecting the syntax of dependent type systems. Secondly, we should very \nmuch like to extend our universe with a codes for internal .xpoints, as in [Morris et al. 2004]. The \nexternal knot-tying approach we have taken here makes types like trees with lists of subtrees more trouble \nthan they should be. Moreover, if we allow the alternation of least and greatest .xpoints, we should \nexpect to gain types which are not readily encoded with one external \u00b5.  Thirdly, it would be fascinating \nto extend our universe with ded\u00adicated support for syntax with binding, not least because a universe \nwith internal .xpoints has such a syntax. Harper and Licata have demonstrated the potential for and of \nsuch an encoding [Licata and Harper 2009], boldly encoding the invalid de.nitions along with the valid. \nA more conservative strategy might be to offer improved support for datatypes indexed by an extensible \ncontext of free vari\u00adables, with the associated free monad structure avoiding capture as shown by Altenkirch \nand Reus [1999]. Lastly, we must ask how our new presentation of datatypes should affect the tools we \nuse to build software. It is not enough to change the game: we must enable better play. If datatypes \nare data, what is design? Acknowledgments We are grateful to Jos\u00e9 Pedro Magalh\u00e3es for his helpful comments \non a draft of this paper. We are also grateful to the Agda team, without which levitation would have \nbeen a much more perilous exercise. J. Chapman was supported by the Estonian Centre of Excellence in \nComputer Science, EXCS, .nanced by the European Regional Development Fund. P.-\u00c9. Dagand, C. McBride and \nP. Morris are supported by the Engineering and Physical Sciences Research Council, Grants EP/G034699/1 \nand EP/G034109/1. References A. Abel, T. Coquand, and M. Pagano. A modular type-checking algorithm for \ntype theory with singleton types and proof irrelevance. In TLCA. R. Adams. Pure type systems with judgemental \nequality. JFP, 2006. T. Altenkirch and C. McBride. Generic programming within dependently typed programming. \nIn Generic Programming, 2002. T. Altenkirch and B. Reus. Monadic presentations of lambda terms using \ngeneralized inductive types. In Computer Science Logic. 1999. T. Altenkirch, C. McBride, and W. Swierstra. \nObservational equality, now! In PLPV, 2007. L. Augustsson and M. Carlsson. An exercise in dependent types: \nA well-typed interpreter. Available at http://www.cs.chalmers.se/ ~augustss/cayenne/interp.ps, 1999. \nM. Benke, P. Dybjer, and P. Jansson. Universes for generic programs and proofs in dependent type theory. \nNordic Journal of Computing, 2003. E. Brady, J. Chapman, P.-E. Dagand, A. Gundry, C. McBride, P. Morris, \nand U. Norell. An Epigram implementation. E. Brady, C. McBride, and J. McKinna. Inductive families need \nnot store their indices. In TYPES, 2003. J. Cheney and R. Hinze. First-class phantom types. Technical \nreport, Cornell University, 2003. T. Coquand. An algorithm for type-checking dependent types. SCP, 1996. \nJ. Courant. Explicit universes for the calculus of constructions. In TPHOLs, 2002. N. A. Danielsson. \nThe Agda standard library, 2010. P. Dybjer. Inductive sets and families in Martin-L\u00f6f s type theory. \nIn Logical Frameworks. 1991. P. Dybjer and A. Setzer. A .nite axiomatization of inductive-recursive de.nitions. \nIn TLCA, 1999. P. Dybjer and A. Setzer. Induction-recursion and initial algebras. In Annals of Pure and \nApplied Logic, 2000. P. Dybjer and A. Setzer. Indexed induction-recursion. In Proof Theory in Computer \nScience. 2001. R. Garcia, J. Jarvi, A. Lumsdaine, J. Siek, and J. Willcock. A comparative study of language \nsupport for generic programming. In OOPSLA, 2003. H. Geuvers. Induction is not derivable in second order \ndependent type theory. In TLCA, 2001. H. Goguen, C. McBride, and J. McKinna. Eliminating dependent pattern \nmatching. In Algebra, Meaning and Computation. 2006. R. Harper and R. Pollack. Type checking with universes. \nIn TAPSOFT 89. R. Hinze. Polytypic values possess polykinded types. In MPC. 2000. R. Hinze, J. Jeuring, \nand A. L\u00f6h. Type-indexed data types. In MPC, 2002. R. Hinze, J. Jeuring, and A. L\u00f6h. Comparing approaches \nto generic pro\u00adgramming in Haskell. In Datatype-Generic Programming. 2007. S. Holdermans, J. Jeuring, \nA. L\u00f6h, and A. Rodriguez. Generic views on data types. In MPC. 2006. P. Jansson and J. Jeuring. PolyP \na polytypic programming language extension. In POPL, 1997. R. L\u00e4mmel and S. Peyton Jones. Scrap your \nboilerplate: a practical design pattern for generic programming. In TLDI, 2003. D. R. Licata and R. Harper. \nA universe of binding and computation. In ICFP, 2009. Z. Luo. Computation and Reasoning. Oxford University \nPress, 1994. P. Martin-L\u00f6f. Intuitionistic Type Theory. Bibliopolis\u00b7Napoli, 1984. C. McBride and J. McKinna. \nThe view from the left. JFP, 2004. P. Morris. Constructing Universes for Generic Programming. PhD thesis, \nUniversity of Nottingham, 2007. P. Morris and T. Altenkirch. Indexed containers. In LICS, 2009. P. Morris, \nT. Altenkirch, and C. McBride. Exploring the regular tree types. In TYPES, 2004. P. Morris, T. Altenkirch, \nand N. Ghani. A universe of strictly positive families. IJCS, 2009. U. Norell. Functional generic programming \nand type theory. Master s thesis, Chalmers University of Technology, 2002. U. Norell. Towards a practical \nprogramming language based on dependent type theory. PhD thesis, Chalmers University of Technology, 2007. \nN. Oury and W. Swierstra. The power of Pi. In ICFP, 2008. C. Paulin-Mohring. D\u00e9.nitions inductives en \nth\u00e9orie des types d ordre sup\u00e9rieur. th\u00e8se d habilitation, ENS Lyon, 1996. B. C. Pierce and D. N. Turner. \nLocal type inference. In POPL, 1998. A. Rodriguez, J. Jeuring, P. Jansson, A. Gerdes, O. Kiselyov, and \nB. C. d. S. Oliveira. Comparing libraries for generic programming in Haskell. In Haskell Symposium, 2008. \nThe Coq Development Team. The Coq Proof Assistant Reference Manual. W. Verbruggen, E. de Vries, and A. \nHughes. Polytypic programming in Coq. In WGP, 2008. W. Verbruggen, E. de Vries, and A. Hughes. Polytypic \nproperties and proofs in Coq. In WGP, 2009. S. Weirich and C. Casinghino. Arity-generic datatype-generic \nprogram\u00adming. In PLPV, 2010. H. Xi, C. Chen, and G. Chen. Guarded recursive datatype constructors. In \nPOPL, 2003. A. R. Yakushev, S. Holdermans, A. L\u00f6h, and J. Jeuring. Generic program\u00adming with .xed points \nfor mutually recursive datatypes. In ICFP, 2009.   \n\t\t\t", "proc_id": "1863543", "abstract": "<p>We present a closed dependent type theory whose inductive types are given not by a scheme for generative declarations, but by encoding in a <i>universe</i>. Each inductive datatype arises by interpreting its <i>description</i> - a first-class value in a datatype of descriptions. Moreover, the latter itself has a description. Datatype-generic programming thus becomes ordinary programming. We show some of the resulting generic operations and deploy them in particular, useful ways on the datatype of datatype descriptions itself. Simulations in existing systems suggest that this apparently self-supporting setup is achievable without paradox or infinite regress.</p>", "authors": [{"name": "James Chapman", "author_profile_id": "81436599505", "affiliation": "Tallinn University of Technology, Tallinn, Estonia", "person_id": "P2338134", "email_address": "", "orcid_id": ""}, {"name": "Pierre-&#201;variste Dagand", "author_profile_id": "81413605432", "affiliation": "University of Strathclyde, Glasgow, United Kingdom", "person_id": "P2338135", "email_address": "", "orcid_id": ""}, {"name": "Conor McBride", "author_profile_id": "81100120358", "affiliation": "University of Strathclyde, Glasgow, United Kingdom", "person_id": "P2338136", "email_address": "", "orcid_id": ""}, {"name": "Peter Morris", "author_profile_id": "81100135048", "affiliation": "University of Nottingham, Nottingham, United Kingdom", "person_id": "P2338137", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863547", "year": "2010", "article_id": "1863547", "conference": "ICFP", "title": "The gentle art of levitation", "url": "http://dl.acm.org/citation.cfm?id=1863547"}