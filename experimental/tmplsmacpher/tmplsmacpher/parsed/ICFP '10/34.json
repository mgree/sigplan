{"article_publication_date": "09-27-2010", "fulltext": "\n Experience Report: Haskell as a Reagent Results and Observations on the Use of Haskell in a Python Project \nIustin Pop Google Switzerland iustin@google.com Abstract In system administration, the languages of \nchoice for solving au\u00adtomation tasks are scripting languages, owing to their .exibility, extensive library \nsupport and quick development cycle. Functional programming is more likely to be found in software development \nteams and the academic world. This separation means that system administrators cannot use the most effective \ntool for a given problem; in an ideal world, we should be able to mix and match different languages, \nbased on the problem at hand. This experience report details our initial introduction and use of Haskell \nin a mature, medium size project implemented in Python. We also analyse the interaction between the two \nlanguages, and show how Haskell has excelled at solving a particular type of real\u00adworld problems. Categories \nand Subject Descriptors D.2.12 [Software engineer\u00ading]: Interoperability; D.3.2 [Programming languages]: \nLanguage Classi.cations Applicative (functional) languages General Terms Experimentation, Languages Keywords \nHaskell, Python, Ganeti, System administration 1. Introduction For the past year, our team has developed1 \nand started to use a set of tools implemented in Haskell to solve a speci.c category of prob\u00adlems that \nwere not best expressed in an interpreted language. This required learning a new style of programming, \nbecoming familiar with the tool-chain (compiler, pro.ler, documentation tools, etc.), investigating the \navailable libraries and making sure that our new tools inter-operate well with the Python code. At the \nend, the ques\u00adtion was: is the extra effort needed for maintaining code written in two languages justi.ed? \nDo we get any advantage out of combining two high-level, but quite different, languages? As we try to \nshow in this paper, in our experience the answer is af.rmative, sometimes in non obvious ways. Haskell \ns strong 1 As described later in the paper, while the actual Haskell code has a single author, the entire \nteam has participated in the design and testing of these tools, and therefore the paper uses the we pronoun \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP \n10, September 27 29, 2010, Baltimore, Maryland, USA. Copyright c &#38;#169; 2010 ACM 978-1-60558-794-3/10/09. \n. . $10.00 type system contrasts markedly from Python s laissez-faire ap\u00adproach to types, and its cheap-persistence \nmodel is the opposite of Python s cheap-modi.cation one, while both are in the same high\u00adlevel language \ncategory where complex data-modi.cation pipelines are readily available. Such diametrically opposite \nviews on some topics were very good at highlighting differences, and neither lan\u00adguage was delegated \nto the low-level versus high-level status. We have observed gains from simply having two different lan\u00adguages \nexercise the same API/RPC endpoints; in our case, this meant that the effort spent to standardise the \nmessage types (use\u00adful for Haskell) can lead to a more sound framework on the Python side. Prototyping \nthe same algorithm in both languages led to a bet\u00adter understanding and in a few cases optimisations \nin one language can be carried to the other side. Not all was good, however; a few bumps appeared along \nthe way, in the form of small issues with availability of libraries, per\u00adformance for some operations, \ncompatibility between different ver\u00adsions of the base libraries and the higher dif.culty of advanced \npro\u00adgramming techniques in a functional language. 1.1 Our contribution Past ICFP experience reports \nhave focused on either conversion of software from an imperative language ([Newton and Ko 2009]), or \non using functional programming for an entire project ([Sampson 2009]). Furthermore, reports on the use \nof functional programming refer in general to either use in research institutes and universities ([Cuoq \net al. 2009] and [Balat et al. 2009]) or in commercial software development teams (e.g. [Sampson 2009]). \nWe believe our use of Haskell in combination with Python in an already existing, mature project and in \nthe context of system administration represents a different view on the use of functional programming. \n2. The team and the project Our team is part of Google s corporate IT system administration group, dealing \nwith administration of virtual machines. While most of us have strong Python development skills, and \neveryone is fa\u00admiliar with other system administration languages and tools, we are not, per se, a software \ndevelopment team. Rather the develop\u00adment activities are demand-based and geared towards automation of \nsystem administration. As part of our work, we have developed Ganeti (http://code. google.com/p/ganeti/), \na management tool for clusters of vir\u00adtual machines (e.g. Xen, KVM). Our team has been working on the \nproject since 2006, open-sourced it in September 2007, and it was (before the introduction of the Haskell \ncomponent) written al\u00admost entirely in Python, with just some small bits of shell and other languages, \nmostly for the build system. The objective of Ganeti is to enable easy management of clusters created \nfrom off-the-shelf hardware, without requiring custom or expensive storage or net\u00adwork gear. As such, \nwe use a quantity of other open-source soft\u00adware for managing the physical resources.  For storage management \nwe use DRBD2, a software solution for over-the-network RAID1 storage. Using RAID1 (mirroring) means that \neach virtual disk resides on two physical machines, called the primary and secondary machine respectively. \nA virtual machine can cheaply switch between these two machines (if the other required resources, e.g. \nmemory, are suf.cient), an operation called failover. Switching a virtual disk from the machine pair \n(A,B) to (A,C), an operation called relocation, requires copying the entire disk data from A to C and \nthus it is costly. This dependency of each virtual machine on two physical ma\u00adchines means that the placement \nalgorithm is not as straightforward as in solutions using external storage, where any physical machine \ncan access the entirety of all storage; therefore, we had to develop tools that can automate the layout \ncomputation in order to best use the resources of each physical machine. 2.1 Layout policies We anticipated \nsomewhat early in the development of Ganeti that the actual policies for the layout of virtual machines \nacross (pairs of) physical machines might differ based on site policies and thus decided that the actual \npolicy should be left to external scripts, while Ganeti itself should just implement the mechanism. Thus, \nwe have a documented API (called the IAllocator API) for things like given cluster state X, on what pair \nof machines should new virtual machine with speci.cations Y be placed?. Note that this works the same \nway for non-mirrored storage, where we simply allocate on a single physical machine (in a non-redundant \nsetup). The recursive application of this problem is how many virtual machines can we allocate on a cluster \nbefore we violate site policies or run out of physical resources. The allocation problem is also present \nin a slight different ver\u00adsion: if a physical machine needs to be removed from the cluster (e.g. due \nto hardware failures, or any other reason), the virtual ma\u00adchines which live on this particular machine \nneed to be relocated to another member of the cluster. The question is expressed as: given cluster state \nX, we want to move a virtual machine from physical machine pair (A, B) to (A, x); what is the best choice \nfor x?. We use the same API as above. A third related problem is computing the optimal layout of the \ncurrent cluster. This means responding to the question: given current cluster state X, with physical \nmachine list N and virtual machine list I, how should we relocate the virtual machines for a better layout?. \nThis question is not encoded in the IAllocator API, but we can both extract the cluster state and instruct \nchanges in the layout via other Ganeti APIs. A .nal note is that the layout of virtual machines across \nthe physical machine pairs has both optimisation aspects (e.g. even load distribution) and hard constraints. \nOne important such con\u00adstraint is that if a physical machine fails, all its peers must have enough free \nmemory to failover and run the now of.ine instances. In other words: for a given physical machine A and \nits hosted vir\u00adtual machines Ii, each living on the machine pair (A, xi), does each machine xi have enough \nfree memory to accommodate Ii?. We call this N+1 redundancy, and we .ag in our veri.cation rou\u00adtines \nany physical machines that fail this check. 2.2 Open APIs Another key decision early in the history \nof Ganeti was that, as much as possible, our APIs and data formats should be language agnostic. Thus, \nwe moved (for the inter-node RPC) from the orig\u00ad 2 http://www.drbd.org/, a networked RAID1 driver usable \neither in active-passive or active-active mode inal Twisted3-based RPC and serialisation format to HTTP \nand JSON, and for data storage from Python Pickle format to (again) JSON4. While this decision was not \nmade with any speci.c purpose in mind, it did help during the development of Ganeti as such data formats \nare more stable and very easy to use/modify even from the shell. Later, it was one of the key factors \nthat allowed the use of Haskell.  2.3 Introduction of Haskell The introduction of Haskell in the project \nwas somewhat acciden\u00adtal. The capabilities of Ganeti itself were growing and it was able to manage bigger \nand bigger clusters; but the layout algorithms were still very weak. Thus, at the end of 2008 the author \nof the paper started working towards solving an independent (at that time) prob\u00adlem, that is the automated \ncomputation of the changes needed in cluster state to solve N+1 check failures. The initial version of \nthe algorithm attempted a brute-force search over a limited subset of the solution space, and thus the \nPython implementation was very slow. It was also unwieldy, since throw-away copies of the data are expensive \nin Python and undoing modi.cations in a generic and safe way is not simple. The next step was intended \nto be both a learning experience and a language comparison exercise: how would such an algorithm, the \nsimulation of cluster state changes when virtual machines are being relocated, look in a functional language? \nPeople familiar with functional programming might recognise such an algorithm as a good .t at once; for \nthe author it took a while until he was convinced that indeed such modelling is easier to achieve in \na purely functional way, using persistent data structures. 2.3.1 Time-line N+1 solver Initial forays \ninto the Haskell implementation of the above algorithm proved successful, and after a couple of weeks \nwe had a tool to automatically compute the solution list (a set of move virtual machine I from (A, B) \nto (C, D) commands) needed to solve the N+1 failures in most of the usual cases. The algorithm itself \nwas still rough, and due to its brute-force nature it was very limited in capabilities. One of the biggest \nlimitations was that it wasn t able to tell if it will ever manage to .nd a solution and thus it tried \nto explore the whole solution space (which is too big to compute), thus preventing its use in a fully-automated \nway. Cluster balancer The N+1 solver already provided the infrastruc\u00adture needed for importing data from \nGaneti, so writing a new algo\u00adrithm was a much smaller effort. Thus, the next goal was another missing \npiece of the Ganeti infrastructure, a generic cluster bal\u00adancer that takes the state of the cluster and \ncomputes the next best state. The new algorithm is no longer a brute-force algorithm, but an iterative \none that looks in each step at the current cluster state and computes the next cluster state. This is \ndone without look-ahead, and without keeping history, so its time and space characteristics were very \ngood and we soon started testing this new tool in pro\u00adduction. At this point, the team made a decision: \ndo we keep developing the Haskell implementation of the algorithm, or do we rewrite the algorithm (which \nwas reasonably simple) in Python? The reasons for staying with Haskell were twofold. First, all the problems \nwe attack are basically numerical algorithms, thus they 3 http://twistedmatrix.com/trac/, an event-driven \nnetworking en\u00ad gine written in Python 4 The Protocol Buffers data encoding format, which is used extensively \ninside Google, was not open-sourced at the time we did this conversion; hence the choice of JSON  model \nvery nicely in the pure domain; Haskell was here at its best, and the performance of the program was \nvery good. Second, the en\u00adtire Haskell code-base was trivial at this point (roughly 1500 lines of code, \nincluding comments), so the cost of an eventual rewrite into Python (in case ever needed, e.g. to standardise \non a single language) was deemed low enough as not to be an impediment. A third, non obvious reason for \nthe initial acceptance of these tools was that they came at the right time, and .lled a very big gap \nin our project. The value that they brought was high enough that it helped overcome the barrier of introducing \na new language.  2.3.2 Expansion of the code-base In the months following the initial acceptance, the \nproject entered a phase of signi.cant expansion; after a few weeks of use, the ques\u00adtion changed from \nshould we use this to automate cluster balanc\u00ading? to can we add a new rule/constraint to the algorithm? \n. From the team s perspective, once the initial barrier of accep\u00adtance was overcome and the tools were \nstable, there was no reason to hold back their use. From the development point of view, once the initial \nI/O framework was in place and the core algorithm im\u00adplemented, it was easy to iterate on the code base \nand extend it with new features. Furthermore, after we had some experience with the cluster bal\u00adancing \ntool, we realised that the algorithm we developed could be used for all our allocation/layout problems; \nwhether placement of a new virtual machine, or most ef.cient layout, or computing the maximal cluster \ncapacity. At this point, we were comfortable enough with the stability of the code-base to delegate such \ndeci\u00adsions to it, and continued to iterate on the capabilities of the tools. 2.3.3 Integration with \nGaneti APIs Initially, the Haskell tools were interacting with Ganeti via the command line interface, \nwhich worked but was suboptimal. As described in section 2.2, the APIs provided by Ganeti use standard \nprotocols and data formats, so in time it was rather trivial to extend the Haskell tools to talk to Ganeti \ndirectly. Fortunately, the json, curl and network libraries in Haskell are stable and have all the needed \nfeatures for our use, so from this point of view we have observed no limitations in what regards library \nsupport. The use of the APIs from Haskell led to interesting discoveries about the consistency of our \nPython RPCs, described in section 3.4.  2.4 Results and current status By the summer of 2009, the tools \nwere stable enough that we also released them5 as Open Source under the name ganeti-htools . The work \non them continued and as of February 2010 we have the following capabilities: Local and remote gathering \nof data from Ganeti clusters  Direct job execution for the local transport, or in the case of remote \ntransport, creation of a shell script with the needed commands  Sequencing of jobs customised such that \nwe get the maximum parallelism when executing them in Ganeti  The software package consists of the following \ntools: hbal computes the needed moves to improve the cluster layout hail used as an IAllocator script \nfor Ganeti, for both new virtual machine placement, virtual machine moves and physical ma\u00ad chine evacuations \n5 see the release announcement at http://groups.google.com/group/ ganeti/msg/8a9fef84ff138071 hspace \n computes the available cluster capacity All the tools work based on the same core algorithm: 1. The \ncluster state is analysed and we compute the current nu\u00admerical score based on both hard constraints \nand optimisation scores (a) hard constraints represent extremely undesirable cases that are .agged as \nerrors by Ganeti itself; they degrade the clus\u00adter score heavily (b) optimisation scores are obtained \nby computing the standard deviation of normalised metrics (e.g. percentage free mem\u00adory on all physical \nmachines is expressed as a value in the range [0, 1] and the standard deviation of this vector is used \nas the free memory score metric) (c) at the end all metrics are summed and they result in the .nal cluster \nweight  2. We then iterate over all the possible virtual machines and their moves (in balancing) or \nover all the possible ways to allocate a new virtual machine, and chose the best (according to the new \nscore) state Initially we had only two metrics (percentage memory free, percentage disk free); the current \nversion has many more: percentage free memory, free disk and memory reserved for redundancy  ratio \nof virtual-to-physical CPUs  experimental metrics for load-based balancing (CPU load, memory load, disk \nbandwidth, network bandwidth) of.ine physical machines still hosting virtual machines  virtual machine \nexclusion via tags (for example, preventing two virtual machines used as DNS servers to be hosted on \nthe same physical machine)  The algorithm is known to be imperfect (e.g. since it does not look ahead, \nit can get into a situations from where it cannot execute any more moves), but in practice it works well \nenough that all layout decisions can be done with it, with manual intervention being very rare. After \nthe initial implementation and production deployment, de\u00advelopment proceeded at a somewhat slower pace, \nbut nonetheless we continued to improve the basic algorithm, implement new fea\u00adtures, and keep to date \nwith Ganeti changes. 3. Haskell/Python interaction In the following sections we detail our experiences \nin combining Haskell and Python, and some changes to the (already mature) Python code base as a result \nof gaining experience with Haskell. It is important to note that we don t claim that either Haskell or \nPython absolutely enforces a certain programming paradigm; it s just that each language has certain characteristics \nthat make it easier and more natural to program in a certain way. 3.1 Either String in Python In languages \nwhich have native support for exceptions one can usually .nd many libraries that offer over-the-wire \ntransport of exception; for Python, both Twisted and Pyro6 offer transport of Python exceptions from \nthe server to the client (with just a few restrictions). 6 http://pyro.sourceforge.net/, an advanced \nand powerful Dis\u00adtributed Object Technology system  However, there are few, if any, both lightweight \nand language in\u00addependent RPC libraries that offer this. When moving from Twisted to our HTTP-based RPC \nin Ganeti, we saw this as a regression in functionality, and we planned to solve it at a later time. \nIn the meantime, we started to modify some RPC calls to return a tuple (Boolean, Payload) with the .rst \nmember representing success or failure and the second one being either a string (in case of failure) \nor the actual payload. Since this seemed to be a temporary hack until we got a real exception propagation \nframework in place, we only implemented it for a few RPC calls, in an ad-hoc mode. After discovering \nthe Either String data type in Haskell, we realised that this is exactly what were using in Python. Far \nfrom being a hack, it s a simple and elegant way to transport classless exceptions. We proceeded to rework \nour RPC framework to have this as a basic functionality instead of being implemented in the individual \nRPC calls, and as a result we gained much better error reporting across the entire inter-node communication. \nIt is unfortunate, though, that one has to code algebraic data types by hand in imperative languages; \nfor many types of problems they are the most natural way to express values.  3.2 Persistent data types \nPython has very weak support of persistent data types; it is neither possible to mark a complex data \nstructure read-only (in a generic way) nor to make cheap copies. The only native facility for data copies \nis in the copy module, but the speed of a so-called deep\u00adcopy is slower than a manually-coded attribute-by-attribute \ncopy by a big margin (our tests show factors between three and .ve times). These two reasons tend to \ndrive the architecture to careful in\u00adplace updates, even when this a suboptimal solution. After our ex\u00adperience \nwith Haskell and understanding how much safer copy\u00adand-modify is, compared to in-place modi.cation-and-undo, \nwe reused our serialisation framework for a cheap data-copy function\u00adality. This was facilitated by the \nfact that said framework is based on a two-stage process, .rst converting from custom objects to standard \nPython types which are then serialised via JSON. By doing just the initial custom-object-to-standard-object \nconversion and then its reverse, we managed to get a simple, albeit slow, data copying method. This increased \nthe safety of our code in a number of places, especially as these data types are used in a multi-threaded \nenvi\u00adronment. We envision that careful use of this method can lead to a semi-pure style of programming \nin Python. Of course, the best solution would be to have the ability to freeze arbitrary objects in the \nPython standard library. 3.3 Functional programming features in Python The Python language has adopted \na few functional programming features (sometimes directly from Haskell). How do these compare with their \nnative counterparts? Probably the .rst such feature that Python programmers get accustomed to is a lambda \nexpression. It has, however, a big weak\u00adness: Python differentiates between statements and expression; \nsince lambdas can only contain expressions, they are not as pow\u00aderful as regular functions. As such, \ntheir usage is very limited in Python, and their future in the language is under question7. Fortunately, \nusing functions (de.ned either normally or as lambda expressions) as normal values is indeed possible \nwithout any restrictions, and this is useful enough that (for example) we re using it extensively in \nour Python code-base. Also the list genera\u00adtors are similar in both languages, and can be used to good \neffect in Python too. 7 The original Python 3000 standard proposed to drop them, but this deci\u00adsion was \nreversed during the development cycle Recently, Python has gained partial function application, how\u00adever \nthis was implemented as a library, and not at syntax level. Thus, actually using this feature is less \ndirect; compare for example a very trivial example in Haskell: let fn = map length with the Python version: \nfn = partial(map, len) The latter is more cumbersome to use, as it breaks the normal code .ow (it is \nnot instantly clear that len will be an argument of map, one has to mentally parse the partial function \ncall .rst). Due to this, and to the fact that it is a recent addition to the Python libraries, we have \nnot yet started using partial in our Python code. Another pair of functions present in both languages \nand which we use is any and all. While the original Python implementation (as a library) was similar \nto the Haskell one, the recent conversion to built-in functions dropped the predicate argument. This \nhad two effects: for lists of booleans, their use is simpler, but for lists where we still need to apply \na predicate, the syntax became more complicated: result = any(pred(i) for i in lst) This change is not \na big impediment to their use, but it results in more verbose code. To summarise, the functional programming \ntools present in Python are of mixed quality, making their consistent use hard. It seems that the process \nof adopting them from other languages was not perfect: in some cases they are harder to use, and often \nthey look like additions, rather than integral elements of the language.  3.4 Ganeti API consistency \nGaneti has roughly four sets of APIs that interest us: 1. command line interface; while mostly used by \npeople, this was designed to be scriptable such that many tools use this simple method 2. local UNIX \nsocket, JSON encoded messages; this is the sim\u00adplest (and fastest) method since it relies on local Unix \nsocket permissions and security and thus it doesn t need to do any data encryption 3. HTTP-based, REST-style \nAPI; used for remote querying and administration (called RAPI) 4. the IAllocator API, a plugin-based \nframework for allocation and layout policies; this is an internal API, used between Ganeti and plugin \nscripts  The .rst three API sets are used for querying and changing the cluster state, while the latter \nis used for feeding information back into Ganeti as described in section 2.1. Except for the .rst API, \nwhich is plain text, all use JSON en\u00adcoded messages which translate into native data types in most lan\u00adguages. \nThis should make it straightforward to introduce a generic tool that talks either locally or remotely \nto Ganeti. However, when trying to integrate our Haskell program with Ganeti, we quickly found out that: \n not all APIs exported the same data; the data available via each API was only a sub-set of the data \navailable in Ganeti  even for the same data, the actual naming of various properties differed across \nthe APIs  While any program (independent of the language used) would have discovered these inconsistencies, \nstatic vs. dynamic typing makes a difference here. In Python, it s very easy to adjust data structures \non the .y, since we don t have a strong type system. Changing a certain variable from Boolean to Integer \nwill work most of the time without any changes. As such, it s easier to simply adapt and have code branches \nthat deal with different versions of a data format than adjust an entire ecosystem to a format change. \n In contrast, our experience with Haskell shows it s best if dif\u00adferences are kept entirely at the representation \nlayer (e.g. it is ac\u00adceptable to have a different name for a value in the JSON message) but not in actual \ndata format, since this means introducing alge\u00adbraic data types which will complicate (via excessive \nuse of pattern matching) many of the functions manipulating that particular piece of data. The effort \nneeded to unify the APIs was small, since the dif\u00adferences were somewhat minor; this allowed a streamlined \nHaskell implementation, with multiple backends (each talking to a speci.c Ganeti API) which return the \nsame data structures; the actual al\u00adgorithm is then oblivious to the fact that we used an HTTP query \nor a Unix socket connection to talk to Ganeti. On the Python side, this resulted in a saner API overall, \nwhich should bene.t all its con\u00adsumers.  3.5 A test version of the master daemon in Haskell As described \nbefore, our Haskell project is a set of small tools ex\u00adternal to the main Python code-base. The Ganeti \nsoftware architec\u00adture is moderately complex: on all physical machines, a so-called node daemon runs; \none of these machines is designated as the current master node and it runs two more daemons: the master \ndaemon which is the one actually responsible for the job execu\u00adtion and coordinating the node daemons, \nand remote API daemon which offers the RAPI endpoint described in the previous section. Commands can \nbe submitted either remotely via RAPI, or locally on the master node via a set of Python scripts that \ntalk directly to the master daemon. In this architecture, the node daemons are doing purely I/O re\u00adlated \nwork, talking to LVM, DRBD, and the hypervisor in use. The master daemon manages the cluster con.guration \n(and its replica\u00adtion) and coordinates the interactions between the node daemons. This means a signi.cant \npart of the master daemon is dedicated to abstract data handling: 1. Accepting incoming jobs from clients \n 2. Managing the job queue, replicating the jobs to other nodes and archiving them 3. Executing the \njobs, including managing the locking and syn\u00adchronisation between the different worker threads  As an \nexercise, we tried to see if it is feasible to implement a small subset of the master daemon in Haskell, \nhow a Haskell program that deals heavily with I/O compares to the original Python code, and whether the \nadvantages seen for the original tools are replicated to other parts of the code base. This effort had \nmixed success. At a basic level, we were able to implement the basic functionality (accept jobs, local \nqueue man\u00adagement) and the most basic job type (the null job type), but the continuous use of the I/O \ndomain changed the style of program\u00adming signi.cantly: it looks rather more like our original Python \nversion than expected (this might also be due to our limited ex\u00adperience with Haskell). We developed \nthis Haskell version of the master daemon until we were able to actually run the Python com\u00admand line \nscripts and see a fake cluster, execute job management commands, etc., at which point we declared the \nattempt complete. During the exercise, the use of the GHC pro.ler has revealed some de.ciencies in our \nalgorithm used for job submission and dis\u00adpatching to the worker threads; since this was copied verbatim \nfrom the Python version, we were able to devise improvements that were then back-ported to the original \nmaster daemon implementation8. It would have been possible to detect such inef.ciencies based on the \nPython version, but the pro.ler support for multi-threaded Python code is of very low quality compared \nwith the GHC pro.ler; in this way, we used the GHC tool-chain indirectly for improving the Python code. \nWhile benchmarking the two implementations, a surprising re\u00adsult was that, due to the de.ciencies of \nthe standard String data type in Haskell, serialisation/de-serialisation of JSON messages is actually \nslower in Haskell compared to Python (which uses a C\u00adbased module for speedups). In retrospective, this \nexercise has proven that it would be fea\u00adsible to write more parts of our project in Haskell. Even though \nthe heavy I/O emphasis in some areas does not match entirely Haskell s strengths, there are other advantages \n(like the combina\u00adtion between read-only data-structures and very cheap sparks) that would make a Haskell \nimplementation attractive. 4. Roadblocks While our experiments with Haskell were successful and resulted \ninto production level code, we have had a few small roadblocks along the way. 4.1 Debugging facilities \nLike many other Haskell programmers, we had to debug the famous error message Exception: Prelude.head: \nempty list , followed by an abrupt exit from our program. In standard Python code, this message would \nhave been accom\u00adpanied by a stack trace, including the code fragment that generated such an exception. \nIn Haskell, however, the available options are very primitive: either use Debug.Trace (a low-level facility) \nor implement changes to the pure code-.ow (via the use of a Writer monad). Combined with the effects \nof laziness, this makes debug\u00adging a complex application much more dif.cult for the beginner Haskell \nprogrammer than in a scripting language. Another problem, not particular to Haskell but to compiled languages \nin general, is the inability to quickly debug problems on the deployment systems. Instead, the problem \nmust be replicated on the development machines. By itself this wouldn t be an issue, but it exacerbates \nthe debugging dif.culties. In due time we have learned ways to compensate for both these problems, but \nwe still .nd debugging tools a bit weak in Haskell (e.g. compared to the excellent pro.ler); the author \nis looking forward to developments in this area e.g. [Allwood et al. 2009].  4.2 Status of library packaging \nin Linux distributions While Hackage provides a plethora of libraries, not all of them are available \nin Linux distributions, or at least not in the current stable versions. We re mainly interested in Debian, \nsince it s our test/reference platform. As an end user, due to the static linking, it s very easy to \ndeploy Haskell software: the needed libraries must be available only on a development machine, while \nthe deployment targets do not need them. But packaging software for Debian is different, as it requires \nthat all prerequisites must be available in Debian itself, for hermetic/reproducible builds across all \nsupported architectures. We use just three libraries: json, curl and network; at the beginning of year \n2009, neither the json nor curl were available at all in Debian, and this delayed our packaging efforts. \nToday, all are available in the unstable track, and this allowed us to package ganeti-htools for it, \nbut it is still hard to back-port our software for the current stable version. 8 an example is commit \n009e73d in Ganeti, Optimise multi-job submit  The introduction of the Haskell platform, and the advances \nin packaging of the debian-haskell group however makes this an ob\u00adsolete issue; both developers and end-users \nwill be able to consider the state of Haskell integration on the same level as Python s in future Debian \nversions.  4.3 Rate of change and maintenance effort One surprising .nding during development is that \nsome basic func\u00adtionality, in our case related to error handling (the use of the Control.Exception module), \nchanged so much between GHC 6.8 and 6.10 that is hard to write code that works with both ver\u00adsions, unless \none starts to use conditional compilation (via CPP de.nes, but this has its own problems), or switch \nto another library for error handling (e.g. the extensible exceptions package). Fortunately we were mostly \ninterested in I/O errors, so we were able to revert to the simpler error handling in prelude9. But such \nchanges were surprising to us, and we did pause to consider how much effort will be needed in the future \nto keep backwards compatibility with current deployed systems, while still allowing use on unstable/development \nplatforms. 4.4 String data type speed issues As described in section 3.5, even in our limited experience \nwe have observed the slow speed of the standard String data type. The author s initial reaction was to \nsimply look for other libraries in or\u00adder to solve this problem; but, even though alternatives exist, \nthe String type is still having a privileged position as the default text type, and thus many libraries \nuse it by default; as such, the effort is put on prospective developers to decide can I use library X \nor do I need to .nd an X-bytestring implementation to get reasonable speed? . This situation is unexpected \nin a language and an imple\u00admentation (GHC) that seems in many other ways quite mature, and the author \nbelieves that it adds a non-trivial effort on both sides of the community: on library authors, who need \nto provide bytestring\u00adenabled versions, and on the users of libraries, who need to make sure their mix \nof libraries does work as expected and gives reason\u00adable performance.  4.5 High barrier to entry Lastly, \nwe believe that the most signi.cant problem is the high barrier to entry. Even after the completion of \nthis project, the author feels that his knowledge of Haskell is very much incomplete, and that he is \nfar from being familiar with advanced topics (e.g. applicative programming, generic programming, etc.). \nWhether this is needed or not for small projects is debatable for example, our current code works with \nonly standard Haskell 98 (no language extensions in use) but it might be possible that careful use of \nadvanced programming techniques will reduce and simplify the code. The second remark on this topic refers \nto the dif.culty of co\u00adopting other people to contribute; except for a few trivial patches, in our project \nthe Haskell component remains a one person effort, compared to the Python code which has had around three \nto .ve active contributors (depending on project phase). 5. Summary After using Haskell for slightly \nmore than a year, our conclusion is that even though the adoption barrier is quite high, Haskell is a \ngood asset for solving certain types of problems. The combination with Python has shown to be a success, \nand we have managed to write a set of tools that are used daily for solving real-world problems. For \nthe foreseeable future, our project will remain a dual\u00adlanguage one; rewriting the Haskell part in Python \nis doable, but 9 commit 1cf9747 in htools, Change ExtLoader to only handle I/O errors we would lose the \nadvantages described in the paper for this par\u00adticular kind of problem (numerical algorithms). As to \nthe opposite option, rewriting the Python part in Haskell, there are a few rea\u00adsons why this is not feasible. \nFirst, the Python code-base is signif\u00adicant (around 30K lines of code), and rewriting a project of this \nsize would be a huge effort, which is hard to justify. Second, it is unknown whether our team would be \nable to successfully re\u00adimplement Ganeti in Haskell, given our limited experience with the language. \nWere we to start the project from scratch, today, it would be a different proposition. Both Python and \nHaskell have their advan\u00adtages, and choosing the right language would be a hard decision. Nevertheless, \nafter using Haskell in real life to solve actual pro\u00adduction problems, we believe that both at language \nlevel and at implementation level (GHC) it is a viable choice for projects of similar complexity in the \ndomain of system administration. Acknowledgments Many thanks to the Ganeti team in Google for their support \nduring my initial experiments with Haskell, especially to Guido Trotter and Michael Hanselmann. Also, \nthe subject of this paper would have not existed without Haskell itself, and the many resources created \nby the community that enabled me to learn, write and deploy Haskell. References T. O. Allwood, S. Peyton \nJones, and S. Eisenbach. Finding the needle: stack traces for ghc. In Haskell 09: Proceedings of the \n2nd ACM SIGPLAN symposium on Haskell, pages 129 140, New York, NY, USA, 2009. ACM. ISBN 978-1-60558-508-6. \nV. Balat, J. Vouillon, and B. Yakobowski. Experience report: ocsigen, a web programming framework. In \nICFP 09: Proceedings of the 14th ACM SIGPLAN international conference on Functional programming, pages \n311 316, New York, NY, USA, 2009. ACM. ISBN 978-1-60558-332-7. P. Cuoq, J. Signoles, P. Baudin, R. Bonichon, \nG. Canet, L. Correnson, B. Monate, V. Prevosto, and A. Puccetti. Experience report: Ocaml for an industrial-strength \nstatic analysis framework. In ICFP 09: Proceed\u00adings of the 14th ACM SIGPLAN international conference \non Functional programming, pages 281 286, New York, NY, USA, 2009. ACM. ISBN 978-1-60558-332-7. R. R. \nNewton and T. Ko. Experience report: embedded, parallel computer\u00advision with a functional dsl. In ICFP \n09: Proceedings of the 14th ACM SIGPLAN international conference on Functional programming, pages 59 \n64, New York, NY, USA, 2009. ACM. ISBN 978-1-60558-332-7. C. J. Sampson. Experience report: Haskell in \nthe real world : writing a commercial application in a lazy functional lanuage. In ICFP 09: Proceedings \nof the 14th ACM SIGPLAN international conference on Functional programming, pages 185 190, New York, \nNY, USA, 2009. ACM. ISBN 978-1-60558-332-7.    \n\t\t\t", "proc_id": "1863543", "abstract": "<p>In system administration, the languages of choice for solving automation tasks are scripting languages, owing to their flexibility, extensive library support and quick development cycle. Functional programming is more likely to be found in software development teams and the academic world.</p> <p>This separation means that system administrators cannot use the most effective tool for a given problem; in an ideal world, we should be able to mix and match different languages, based on the problem at hand.</p> <p>This experience report details our initial introduction and use of Haskell in a mature, medium size project implemented in Python. We also analyse the interaction between the two languages, and show how Haskell has excelled at solving a particular type of real-world problems</p>", "authors": [{"name": "Iustin Pop", "author_profile_id": "81470646425", "affiliation": "Google Switzerland, Z&#252;rich, Switzerland", "person_id": "P2338237", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863595", "year": "2010", "article_id": "1863595", "conference": "ICFP", "title": "Experience report: Haskell as a reagent: results and observations on the use of Haskell in a python project", "url": "http://dl.acm.org/citation.cfm?id=1863595"}