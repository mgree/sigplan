{"article_publication_date": "09-27-2010", "fulltext": "\n Lolliproc: to Concurrency from Classical Linear Logic via Curry-Howard and Control Karl Mazurak Steve \nZdancewic University of Pennsylvania {mazurak,stevez}@cis.upenn.edu Abstract While many type systems \nbased on the intuitionistic fragment of linear logic have been proposed, applications in programming \nlan\u00adguages of the full power of linear logic including double-negation elimination have remained elusive. \nMeanwhile, linearity has been used in many type systems for concurrent programs e.g., session types which \nsuggests applicability to the problems of concurrent programming, but the ways in which linearity has \ninteracted with concurrency primitives in lambda calculi have remained somewhat ad-hoc. In this paper \nwe connect classical linear logic and con\u00adcurrent functional programming in the language Lolliproc, which \nprovides simple primitives for concurrency that have a direct logi\u00adcal interpretation and that combine \nto provide the functionality of session types. Lolliproc features a simple process calculus under the \nhood but hides the machinery of processes from programmers. We illustrate Lolliproc by example and prove \nsoundness, strong normalization, and con.uence results, which, among other things, guarantees freedom \nfrom deadlocks and race conditions. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: \nLanguage Constructs and Features General Terms Design, Languages, Theory Keywords Linear logic, Concurrency, \nType systems 1. Introduction: Linearity and Concurrency Since its introduction by Girard in the 1980 \ns [22], linear logic has suggested applications in type system support for concurrency. Intuitively, \nthe appeal of this connection stems from linear logic s strong notion of resource management: if two \nprogram terms use distinct sets of resources, then one should be able to compute them both in parallel \nwithout fear of interference, thereby eliminating problems with race conditions or deadlock. Moreover, \nlinear logic s ability to account for stateful computation [42], when combined with the concurrency interpretation \nabove, suggests that it is a good .t for describing stateful communication protocols in which the two \nendpoints must be synchronized. Indeed, there have been many successful uses of linearity in type systems \nfor concurrent programming. Ideas from linearity play a crucial role in session types [12, 15, 25, 38, \n40], for example, where Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. ICFP 10, September 27 29, 2010, Baltimore, Maryland, USA. Copyright &#38;#169; 2010 ACM \n978-1-60558-794-3/10/09. . . $10.00 they are used to ensure that two end-points of a channel agree on \nwhich side is to send the next message and what type of data should be sent. Linearity is also useful \nfor constraining the behavior of p\u00adcalculus processes [4, 28], and can be strong enough to yield fully\u00adabstract \nencodings of (stateful) lambda-calculi [45]. Given all this, it is natural to seek out programming-language \nconstructs that correspond directly to linear logic connectives via the Curry-Howard correspondence [26]. \nIn doing so, one would hope to shed light on the computational primitives involved and, eventually, to \napply those insights in the contexts of proof theory and programming-language design. Here too, there \nhas been much progress, which falls, roughly, into three lines of work. First, there has been considerable \neffort to study various in\u00adtuitionistic fragments of linear logic [6, 11, 29 31, 39]. This has yielded \ntype systems and programming models that are relatively familiar to functional programmers and have applications \nin man\u00adaging state and other resources [2, 13, 16, 24, 41, 47]. However, such intuitionistic calculi \ndo not exploit concurrency (or non\u00adstandard control operators) to express their operational semantics. \nA second approach has been to formulate proof terms for the se\u00adquent calculus presentation of linear \nlogic. This path leads to proof nets, as in Girard s original work [22] and related calculi [1, 18]. \nThis approach has the bene.t of fully exposing the concurrency inherent in linear logic, and it takes \nfull advantage of the symme\u00adtries of the logical connectives to provide a parsimonious syntax. Yet the \nresulting type systems and programming models, with their fully symmetric operations, are far removed \nfrom familiar func\u00adtional programming languages. A third approach studies natural deduction formulations \nof lin\u00adear logic [10, 14], following work on term assignments for classical (though not linear) logic \n[35 37]. These calculi typically use typing judgments with multiple conclusions, which can be read computa\u00adtionally \nas assigning types to variables that name .rst-class contin\u00aduations. Their operational semantics encode \nthe so-called commut\u00ading conversions which shuf.e (delimited) continuations in such a way as to effectively \nsimulate parallel evaluation. This approach of\u00adfers type systems that are relatively similar to those \nused in standard functional programming languages at the expense of obscuring the connections to concurrent \nprogramming. Contributions This paper introduces Lolliproc, a language in the natural deduction tradition \nthat takes a more direct approach to con\u00adcurrency. Lolliproc is designed .rst as a core calculus for \nconcur\u00adrent functional programming; it gives a Curry-Howard interpreta\u00adtion of classical as opposed to \nintuitionistic linear logic1 that is nonetheless suggestive of familiar functional languages. There are \ntwo key ideas to our approach. First, in contrast with the work mentioned previously, we move from an \nintuitionistic to a classical setting by adding a witness for double-negation elimi\u00ad 1 Girard would say \nfull linear logic or simply linear logic .   1 t . t t . t types nation, which we call yield. Second, \nto recover the expressiveness t &#38; t of linear logic, we introduce an operation go, which corresponds \n. ::= t -. protocol types . &#38; . logically to the coercion from the intuitionistic negation (. - ) \nto .P, . s dual as de.ned analogously to de Morgan s laws in classi\u00ad indices expressions cal logic. \nOperationally, go spawns a new process that executes in i ::= 1 2 e.i parallel to the main thread while \nyield waits for a value sent by an\u00ad (e, e) .x:t.eee(e, e) ::= e x other process. These constructs are \nnovel adaptations of Felleisen &#38; Hieb s control operator [17] to our linear setting. The search for \nappropriate operational semantics for these con\u00ad structs leads us to a simple process language reminiscent \nof Mil\u00ad ner s p-calculus [32] hidden behind an abstract interface. Pro\u00ad inti .t () case e of in1 x . \ne | in2 y . eeyield e  e; ee let (x, y)= e in e . new primitives go 1arJal JaL channel endpoints grams \nare written entirely in a standard linear .-calculus aug\u00admented with the go and yield operations and \nelaborate to processes at run time. As a consequence, our type system isolates the classi\u00ad () inti \n.t (e, e) JaL v values .x:t. e1ar (v, v) ::= ::= v cal multiple-conclusions judgments (captured by \nour typing rules for processes) so that they are not needed to type check source Jal  E; e program \nexpressions. This situation is somewhat analogous to how evaluation contexts EevE(E, e)E E.i reference \ncells are treated in ML location values and heap typ\u00ad ings are needed to describe the operational semantics, \nbut source program type checking doesn t require them. Organization The next Section introduces Lolliproc \ninformally, inti .t (v, E)E let (x, y)= E in e . case E of in1 x . e | in2 y . eyield E E go covering \nboth what we take from the standard intuitionistic linear .-calculus and our new constructs. Given our \ngoal of enabling con- P  P | P.a:.. P ::= processes e current programming in a traditional functional \nsetting, we demon\u00adstrate Lolliproc s functionality by example in Section 3; we show how a system that \nseems to permit communication in only one di\u00ad  .,a \u00b7. channel contexts . .,a\u00b7..,a:. ::= \u00b7 typing contexts \n. .,x:t rection can in fact be used to mimic bidirectional session types. ::= \u00b7 Section 4 gives the formal \ntyping rules and operational seman\u00adtics for Lolliproc and presents our main technical contributions: \na proof of type soundness, which implies both deadlock-freedom and adherence to session types; a proof \nof strong normalization, ruling out the possibility of livelocks or other non-terminating computa\u00adtions; \nand a proof of con.uence, showing that there are no race conditions in our calculus. Lolliproc does remain \nquite restricted, however we have de\u00adliberately included only the bare minimum necessary to demon\u00adstrate \nits concurrent functionality. Section 5 discusses additions to the language that would relax these restrictions, \nincluding un\u00adrestricted (i.e., non-linear) types, general recursion via recursive types, and intentional \nnondeterminism. This approach adheres to our philosophy of starting from a core language with support \nfor well-behaved concurrency, then explicitly introducing potentially dangerous constructs (which, for \ninstance, might introduce race conditions) in a controlled way. This section also concludes with a discussion \nof related work and a comparison of Lolliproc to more conventional classical linear logics. 2. An overview \nof Lolliproc As shown in Figure 1, the types t of Lolliproc include linear func\u00adtions t1 -t2, additive \nproducts t1 &#38; t2 (sometimes pronounced with ), the unit type 1, multiplicative products t1 . t2, \nand addi\u00adtive sums t1 .t2. These types form an intuitionistic subset of linear logic, and they come equipped \nwith standard introduction and elim\u00adination forms and accompanying typing rules. In addition, we have \nthe type , which is notably not the falsity from which everything follows.2 Its purpose will become apparent \nlater. Our syntax for expressions is given by the grammar e in Fig\u00adure 1, and their standard evaluation \nsemantics is summarized in Fig\u00adure 2.3 In Lolliproc, all variables are treated linearly and functions \n2 Such a type in linear logic is the additive false, while is the multiplica\u00ad tive false; we have left \nadditive units out of Lolliproc for simplicity s sake. 3 The typical rule for handling evaluation contexts \nis missing, as this is done at the process level in Lolliproc. Figure 1. Lolliproc syntax [E-APPLAM](.x:t. \ne) v -. {x . v}e [E-LOCALCHOICE] (e1,e2).i -. ei [E-UNIT] (); e -. e [E-LET] let (x1,x2)=(v1,v2) in e \n-. {x1 . v1,x2 . v2}e [E-CASE] case inti 1.t2 v of in1 x1 . e1 | in2 x2 . e2 -. {xi . v}ei Figure 2. \nBasic evaluation rules are call-by-value. Additive pairs (e1,e2) use the same resources to construct \nboth of their components and are thus evaluated lazily and eliminated via projection; multiplicative \npairs (e1,e2), whose components are independent, are evaluated eagerly and eliminated by let-binding \nboth components. We use the sequencing notation e1; e2 to eliminate units () of type 1. Additive sums, \neliminated by case expressions, are completely standard. Our new constructs the go and yield operations, \nalong with channels and processes are perhaps best understood by looking at what motivated their design. \nIn the rest of this section we will see how the desire to capture classicality led to processes with \na simple communication model and how the desire to make that communication more express led back to classical \nlinear logic. We will also see Lolliproc s operational semantics; we defer a full account of its typing \nrules for Section 4. 2.1 Moving to classical linear logic The differences between intuitionistic and \nclassical logic can be seen in their treatment of negation and disjunction. In standard presentations \nof classical linear logic, negation is de.ned via a dualizing operator (-) that identi.es the de Morgan \nduals as shown below:  = 11 = (t1 &#38; t2) = t1 . t2 (t1 . t2) = t1 &#38; t2 (t1 -t2) = t1 . t2 (t1 \n. t2) = t1 -t2 With this de.nition, dualization is clearly an involution that is, (t ) = t. Moreover, \nthe logic is set up so that duals are logically equivalent to negation: t is provable if and only if \nt - is provable. In this way, classical linear logic builds double-negation elimination into its very \nde.nition it is trivial to prove the theorem ((t - ) - ) -t , which is not intuitionistically valid. \nSequent calculus formulations of classical linear logic take ad\u00advantage of these dualities by observing \nthat the introduction of t is equivalent to the elimination of t ; this allows them to be pre\u00adsented \nwith half the typing rules and syntactic forms that would otherwise be required. This symmetric approach \nis extremely con\u00advenient for proof theory but does not allow us to conservatively extend the existing \ntyping rules and operational semantics for the intuitionistic fragment of linear logic already described \nabove. For that, we need a natural-deduction formulation of the type system. Our solution to this problem \nis to forget dualization (for now) and instead add double-negation elimination as a primitive. We take \ninspiration from type systems for Felleisen &#38; Hieb s control and abort operators [17, 34]: in a non-linear \nsetting, control, can be given the type ((t ..) ..) . t , corresponds to double\u00adnegation elimination, \nwhile abort is a functional variant of false elimination that takes . to any type. The operational behavior \nof these constructs is as follows: E control (.c. e) -. (.c. e)(.x. abort Ex ) E abort e -. e Unfortunately, \nabort clearly has no place in a linear system, as it discards evaluation context E and any resources \ncontained therein. What can we do instead? Observe that c has the continuation type t .. (or, in a linear \nsetting, t - ) and that invoking c within the body e returns an answer to the context E. We can reconcile \nthis behavior with a linear system by dropping abort and instead introducing the ability to evaluate \ntwo expression in parallel: E control (.c. e) -. E control 1ar | (.c. e) Jal Here, evaluating a control \nexpression spawns its argument as a child process. The connection between the original evaluation con\u00adtext \nE and the child process is now the channel a: we write 1ar for the receiving endpoint or source of a, \nheld by the parent process, while the Jal passed to the child denotes the sending endpoint or sink. Now \nevaluation can proceed in the right-hand expression until the sink is applied to a value, at which point \nthis answer is passed back to the parent process: ' E control 1ar | E' Jal v -. Ev | EJaL The closed \nchannel token JaL indicates that communication over a is .nished; it also indicates that the child process \nmay now ter\u00adminate, but before process termination actually happens all linear resources in E' must be \nsafely consumed. Linearity is preserved by both of our operations, as neither expressions nor evaluation \ncon\u00adtexts are duplicated or discarded. So far, though, these constructs offer a very poor form of concurrency \nin the rules above, the parent process immediately blocks waiting for the child process to return. To \nallow the parent and child to execute in parallel, we split can control into two oper\u00adations. The .rst, \nwhich we call go, is responsible for generating the channel a and spawning the child process; it immediately \nreturns a source value to the parent, which can keep running: E go (.c. e) -. E 1ar | (.c. e) Jal The \nsecond operation, yield, is used by the parent process to syn\u00adchronize with the child by blocking on \na source: ' E yield 1ar | E' Jal v -. Ev | EJaL  2.2 Typing and extending go and yield How, then, to \ntype check these new operations? Which is to say, what is their logical meaning? The source 1ar has type \n((t - ) - ), and such doubly\u00adnegated types appear so frequently in Lolliproc that we abbreviate them \nas 1tr, pronounced source of t . Invoking yield on such a source returns a t it eliminates the double \nnegation so we have: yield : 1t r-t What about go? At .rst glance, it appears that go takes an expression \nof type 1t r and returns a 1t r it is logically an identity function. This would be sound, but we can \ndo better. The type t - is usually thought of as a continuation that accepts a t , but here it is better \nto think of it as expressing a very simple protocol, one in which a t is sent and there is no further \ncommunication. From this point of view, we can instead think of go as taking a function of type . - , \nand spawning that function as a child process that must communicate according to the protocol .. The \nparent process receives from go a source whose type describes the other side of the protocol .; hence \na yield on the source waits for information to be sent across the sink by the child process, after which \nboth sides continue with the protocol. Which types make sense as protocols? A protocol might be complete \n(i.e., ), it might specify that a value of type t be sent before continuing according to the protocol \n. (i.e., t -.), or it might specify a choice between protocols .1 and .2 (i.e., .1 &#38; .2). For each \nsuch protocol type . we de.ne a dual type .P, as follows:4 P = 1 .1 &#38; .2 = 1. 1 . . 2r t.= .r -. \n1t . P Aside from the extra double-negations corresponding opera\u00adtionally to points at which we must \nsynchronize with yield and logically to explicitly marking where classical reasoning will take place \nthis is exactly the left-hand column of the de.nition of (-) .5 Additionally, since 1tr is de.ned in \nterms of implication, both 1. 1 . . 2r and 1t . .Pr are themselves protocol types, a fact which will \nbecome important as we go on. Thus go witnesses the logical isomorphism between the intu\u00aditionistic negation \nof a type and its dual: go :(. - ) -.P The channel endpoints Jal and 1ar, then, must have the types . \nand .P. Their types will change over the course of evaluation, as communication proceeds over the channel \na; when communication is .nished, the Jal of type will be replaced by JaL of that same type, while the \n1ar of type 1 will simply step to (). With this plumbing in place, we can de.ne our operational se\u00admantics \nfor processes as shown in Figure 3. At the process level we bind channels with .a:.. P ; these binders \nare generated by rule EP-GO and require that we annotate go expressions as go. e. Evaluation blocks when \nyielding on sources or eliminating sinks 4 The choice to de.ne Pas 1 rather than 11r is a simple optimization \nthat saves us from unnecessary synchronization at channel shutdown; our linkt example in the next section \nshows how this can come in handy. 5 In linear logic, the protocol connectives are said to be negative, \nmeaning that their introduction forms are invertible. That is, no additional choice is made in their \nconstruction in contrast to the choice of injection for . and the choice of resource split for ., which \nare both positive connectives.  a not free in E go. v [EP-GO] E go. v -. .a:.. (E 1ar | v Jal) [EP-APPSINK] \n.a:t -.. E1 yield 1ar | E2 Jal v -. .a:.. E1 (v, 1ar) | E2 Jal [EP-REMOTECHOICE] .a:.1 &#38; .2.E1 yield \n1ar | E2 Jal.i -. .a:.i.E1 in.i 1..2 1ar | E2 Jal [EP-CLOSE] .a: .E1 1ar | E2 Jal -. E1 () | .a: .E2 \nJaL [EP-DONE] P | .a: . JaL -. P '' ' e -. eP1 -. P1 P -. P [EP-EVAL][EP-PAR][EP-NEW] Ee -. Ee ' P1 \n| P2 -. P1 ' | P2 .a:t. P -. .a:t. P ' Figure 3. Process evaluation rules = 1ar [E-YIELDOTHER] v [E-APPSOURCE] \n1ar v -. v (yield 1ar) t. yield v -. let (z, u)= yield (gov) in u; z Figure 4. Expression congruence \nrules until a matching pair is in play, at which point the argument or choice bit is relayed across the \nchannel (rules EP-APPSINK and EP-REMOTECHOICE). Note that such communication has the ef\u00adfect of updating \nthe type of the channel at its binding site to re\u00ad.ect the new state of the protocol. The rule EP-CLOSE \nis similar, but exists only to facilitate typing of completed channels and thus does not require a yield. \nEP-DONE eliminates completed processes (reminiscent of 0 in the p-calculus) and their binders. EP-EVAL \nin\u00adtegrates evaluation contexts and expression evaluation with process evaluation, while EP-PAR and EP-NEW \nallow evaluation within processes. (We also de.ne the standard notion of process equiva\u00adlence, given \nin Section 4.) Two .nal points must be addressed by operational semantics: the type 1t r can be inhabited \nby more than just sources, and thus we need evaluation rules for yielding on other sorts of values; sim\u00adilarly, \nour sources all technically have function types, so we must be able to apply them. Figure 4 gives the \nappropriate congruence rules. For the .rst case, we recall our earlier intuition concerning the simpler \n(but less useful) language where yield and go are com\u00adbined into control. Rule E-YIELDOTHER thus synthesizes \na go in such cases, although we must also synthesize a let binding, as we have transformed a value of \ntype 1t r into one of type 1t . 1r. When a source appears in the function position of an applica\u00adtion, \nwe appeal to the intuition from other systems for classical logics [22, 35] that the interaction of a \nterm with type t and an\u00adother with type t should not depend on the order of those terms. Thus, applying \n1ar of type (t - ) - to v of type t - should be the equivalent of .rst yielding on 1ar, then supplying \nthe result to v. Rule E-APPSOURCE makes this so, and it is easy to verify that this property also holds \nin the case of other applications at those types. Although these congruence rules are a bit unusual, \nthe fact that Lolliproc does not introduce a new family of types for channel endpoints turns out to be \na very useful property of the system: for instance, it allows us to bootstrap bidirectional communication \nfrom what appears, at .rst glance, to be a unidirectional language. We will see how this transpires in \nthe next section. 3. Examples Here we demonstrate some of what can be done with Lolliproc by introducing \nseveral concurrency routines of increasing complexity. For ease of explanation and consistency, we write \nfoot when the function foo is parameterized by the type t , and we use capitalized type abbreviations, \ne.g., Bar t . In a real language we would of course want polymorphism either ML-style or the full generality \nof System F with linearity [31]. Futures A future [33] is simply a sub-computation to be calcu\u00adlated \nin a separate thread; the main computation will wait for this thread to complete when its value is needed. \nThis is one of the sim\u00adplest forms of concurrency expressible in Lolliproc. We can de.ne Future t = 1t \n. 1r futuret :(1 -t) -Future t t. futuret = .x:1 -t. go.k:t - .k (x ()) waitt : Future t -t waitt = .f:Future \nt. let (z, u)= yield f in u; z The main process passes a thunk to its newly spawned child; this child \napplies the thunk and sends back the result. More pictorially, the run-time behavior of E futuret g , \nwhere g () -. * v and E - -. * E ' - , is   E futuret g E 1ar * * E ' 1ar  a a  * *  Jal (g ()) \n Jal v  The connection between endpoints of a channel at a given moment in time are given by . arrows. \nSimilarly, for such some 1ar of type * * E linkt vsrc vsnk E YLD(1ar) E JbL a  a  a Jal JbL JaL a \n // //////// * * vsnk (yield vsrc)vsrc vsnk YLD(e) . let (z, u)= yield e in u; z go Jal; vsrc vsnk \nFigure 5. Evaluation of linkt vsrc vsnk Future t , we have * E '' waitt 1ar E '' v a a Jal v * JaL a \nHere the a subscript on evaluation arrows indicates that communi\u00adcation over a has occurred. Since a \nsupports no further communi\u00adcation afterwards its sink has been replaced by the closed channel token \nJaL the connection is then removed. Recall that such a lone JaL indicates a completed process; the child \nprocess in this example is now complete and will disappear. Linking channel endpoints Given a vsrc of \ntype 1t r and vsnk of type t - which may or may not be a literal source and sink we might want to join \nthe two such that vsrc .ows to vsnk without making the parent process wait by yielding on vsrc. In doing \nso, however, we must still somehow produce a value of type ; it can t be the value that applying vsnk \nwould produce, so it must come from some other process. Our solution relies on the ability to pass process \ncompletion tokens from one process to another: linkt : 1tr-(t - ) - linkt = .x:1t r. .f:t - . yield .g: \n- . go g; xf Note that the .nal xf will step to f (yield x) via rule E-APPSOURCE; similarly, rule E-YIELDOTHER \nwill insert a go immediately following the yield. A call to linkt vsrc vsnk thus spawns two processes: \nthe .rst spawns the second with the trivial protocol, then proceeds to wait and link the original arguments; \nthe second uses the sink created for the .rst child to immediately return control to the parent process. \nThis is illustrated in Figure 5; we use the abbreviation YLD(e) for the now common pattern of yielding \nto receive a product, immediately unpacking the resulting pair, and eliminating the left component. Reversing \ndirections So far we have seen only child processes that send information back to their parents. While \nour constructs show bias towards this sort of communication, Lolliproc does allow exchanges in both directions; \na few complications arise, however, due to the unidirectional nature of our so-called dualization. For \ninstance, while the dual of t -. is 1t . .Pr, the dual of 1t ..r is the somewhat unwieldy 1((t ..) - \n).1r rather than the t -.Pfor which we would have hoped. Yet we observe that the former can be transformed \ninto the latter with a yield operation, an uncurrying, a partial application, and a go; we combine these \nsteps into a function send: sendt P. : 1 t . .r-t -.P sendt P. = .s:1 t . .r. let (f, u)= yield s in \nu; .x:t. go. .p:.. f (x, p) Similarly, the dual of 1.1 . .2r is 1((.1 . .2) - ) . 1r; to coerce this \nto . 1 &#38; . 2, we de.ne select as .P1&#38;.P2 select : 1 -.1 . .2r-. 1 &#38; . 2 .P1&#38;.P2 select \n= .s:1 -.1 . .2r. let (f, u)= yield s in u; (go.1 .p1:.1.f in.1 1..2 p1, go.2 .p2:.2.f in.2 1..2 p2) \nTo demonstrate the .rst of these coercions in action, we look to the identity function echo, which spawns \na child process, passes its argument to that child, then receives it back: replyt : 1t . (t - )r- replyt \n= .h:1t . (t - )r. let (y, g)= yield h in gy echot : t -t echot = .x:t. let (z, u)= yield .1t.1I1t.(t \n)I sendt (goreplyt ) x in u; z Here reply is the body of the child process that will receive the initial \nargument and send it back. (The type of replyt could equally well have been written as the equivalent \n1t . (t - ) - r this notation better re.ects how it is used with echo, while the notation given above \nmore closely matches its de.nition.) The execution of echot v for some v of type t is shown in Figure \n6. We can see how, while the initial spawning of the replyt process orients the channel a in the usual \nchild-to-parent direction, the machinery of send spawns another process that sets up a channel b in the \nopposite direction; afterwards, a third channel c is established in the original direction. All this \nis facilitated again by our congruence rules. It is worth noting that, while the value v cycles among \nseveral processes, at no point does a cycle exist in the communication structure the arrows of Figure \n6. That this fact always holds is crucial to our proof of soundness in Section 4. A larger example So \nfar we have seen relatively small examples. As a larger demonstration of the protocols expressible in \nLolliproc, we consider Dif.e-Hellman key exchange, formulated as follows:  * v * YLD(1cr) * YLD(sendt \n.1t.1I 1ar v) YLD(go. .p:.. Jbl (v, Jcl)) echot v * a . .. c . .. .. .. a .. .............. c .. * \n.. .. .... .. .... c JalJbl * JaL b Jbl (v, Jcl) * JbL a * .. .. a .. b .. .. .... .. .. .. b .. .. \n.............. .. .... .. .... .. .. .... .. .. b .... .. . .. .. . .. * .. * ** let (y, g)= YLD(1br) \nin gy Jcl v JcL replyt Jal c b Figure 6. Evaluation of echot v 1. Alice and Bob select secret integers \na and b. 2. Alice and Bob exchange g a mod p and g b mod p in the clear. 3. Alice and Bob compute the \nshared secret (g b)a =(g a)b mod p and use it to encrypt further communication.  Here g is a publicly \nknown generator with certain properties, often 2 or 5, and p is a similarly known large prime number. \nThe shared secret cannot feasibly be computed from the publicly known values a g and g b. For purposes \nof this example, we declare that further communication consists only of Alice sending an encrypted string \nto Bob, and we treat Alice s session as a child process spawned by Bob rather than as a process somewhere \nover the network that initiates contact. We augment Lolliproc with the types Int and String, as well \nas necessary operations over these types: bigrandom : 1 -Int powmod : Int -Int -Int -Int lessthan : Int \n-Int -(1 . 1) encrypt : Int -String -String decrypt : Int -String -String For clarity, we also freely \nuse general let expressions rather than only those that eliminate multiplicative products, and we allow \nthe reuse of variables of type Int. To demonstrate the use of additive products and sums and to add a \nhint of realism we allow Alice or Bob to abort the session after receiving a value from the other party. \nThus the protocol type that must be enforced in Alice s session and a sample implementa\u00adtion of said \nsession are Alice = Int -1 . 1Int . ( &#38;(String - ))rr alice : Int -Int -Int -Alice - alice = .g:Int. \n.p:Int. .n:Int. .s:Alice. let a = bigrandom () in case yield (s (powmod gap)) of in1 s1 . s1 | in2 s2 \n. let (b, s ' )= yield s2 in case lessthan bn of in1 u1 . u1; s ' .1 | in2 u2 . u2; let k = powmod bap \nin (s ' .2) (encrypt k \"I know secrets!\") Since Alice s session is the child process, the point at which \nshe must check for an abort signal from Bob appear as . ., while the point at which she may abort appears \nas &#38; .. In this case, Alice chooses to abort whenever the public key Bob sends her is too small \nin comparison to some parameter n. An implementation of Bob s side of the communication i.e., the parent \nprocess looks very similar. While bob relies on the type Alice to specify the whole communication protocol, \nwe do need type annotations B1 and B2 for our uses of send and select. B1 = 1 &#38; 1((Int . ( &#38; \n(String - ))) - ) . 1r B2 = Int -11 . (String - )r bob : Int -Int -Int -String bob = .g:Int. .p:Int. \n.n:Int. let (a, s) = yield (goAlice (alice g p n)) in case lessthan a n of in1 u1 . u1; (selectB1 s).1; \n\"ERROR1\" | in2 u2 . u2; let s1 = (selectB1 let b = bigrandom b in s).2 in let s2 = sendB2 s1 (powmod \ng b p) in case yield s ' of in1 u . u; \"ERROR2\" | in2 s '' . let k = powmod abp in let (c, u ' )= yield \ns '' in u ' ; decrypt kc For brevity, we do not illustrate an evaluation of bob gp n. We observe, however, \nthat nothing new is going on in this example as compared to echot . We also observe that the de.nitions \nof al\u00adice and bob are relatively straightforward. They could be improved by standard type inference and \nby syntactic sugar that gave the re\u00adpeated generation and consumption of linear variables the appear\u00adance \nof a single variable being mutated [31], but they are generally quite readable. 4. Metatheory We now \ndiscuss the technical aspects of Lolliproc, including the formal proofs of soundness, strong normalization, \nand con.uence. 4.1 Typing The expression typing rules for Lolliproc can be seen in Figure 7. As we discussed \nin the introduction, these typing rules follow the natural-deduction presentation of intuitionistic linear \ncalculi. Our typing judgment .; . f e : t depends both on a channel context . and a term variable context \n.. Term variables x are bound to types t in ., while . contains binders a\u00b7. (representing the ability \n .1;.1 f e1 : 1 .2;.2 f e2 : t [T-UNIT] \u00b7; \u00b7f () : 1 [T-SEQ][T-VAR] \u00b7; x:t f x : t .1 \u00db .2;.1 \u00db .2 f \ne1; e2 : t .; .,x:t1 f e : t2 .1;.1 f e1 : t1 -t2 .2;.2 f e2 : t1 .; . f e : . - [T-LAM][T-APP][T-GO] \n. .; . f .x:t1.e : t1 -t2 .1 \u00db .2;.2 \u00db .2 f e1 e2 : t2 .; . f goe : .P.; . f e1 : t1 .; . f e2 : t2 .; \n. f e : t1 &#38; t2 .; . f e : 1t r [T-WITH][T-SELECT][T-YIELD] .; . f(e1,e2) : t1 &#38; t2 .; . f e.i \n: ti .; . f yield e : t .1;.1 f e1 : t1 .2;.2 f e2 : t2 .1;.2 f e ' : t1 . t2 .2;.2,x1:t1,x2:t2 f e : \nt [T-TENSOR][T-LET] ' .1 \u00db .2;.1 \u00db .2 f (e1,e2): t1 . t2 .1 \u00db .2;.1 \u00db .2 f let (x1,x2)= e in e : t .; \n. f e : ti .1;.1 f e ' : t1 . t2 .2;.2,x1:t1 f e1 : t .2;.2,x2:t2 f e2 : t [T-IN][T-CASE] ' .; . f int1.t2 \ne : t1 . t2 .1 \u00db .2;.1 \u00db .2 f case e of in1 x1 . e1 | in2 x2 . e2 i [T-SINK] a\u00b7.; \u00b7f Jal : . [T-SOURCE] \na \u00b7.; \u00b7f 1ar : .P[TR-DONE] a: ; \u00b7fJaL : Figure 7. Expression typing rules .1 \u00db .2 =. x . dom(.) .1 \u00db \n.2 =. x . dom(.) [U-EMPTY] \u00b7 \u00db \u00b7 = \u00b7 [UT-LEFT][UT-RIGHT] .1,x:t \u00db .2 =.,x:t .1 \u00db .2,x:t =.,x:t \u00a7 ::= \n\u00b7 \u00b7 :.1 \u00db\u00a8.2 =. a . dom(.) .1 \u00db\u00a8.2 =. a . dom(.) [UC-LEFT][UC-RIGHT] \u00db\u00a8::= \u00db\u00db .1,a\u00a7. \u00db\u00a8.2 =.,a\u00a7. .1 \u00db\u00a8.2,a\u00a7. \n=.,a\u00a7. .1 \u00db .2 =. .1 \u00db .2 =. a . dom(.) .1 \u00db .2 =. a . dom(.) [UC-NONE][UC-SRCSNK][UC-SNKSRC] .1\u00db .2 \n=. .1,a \u00b7.\u00db .2,a\u00b7. =.,a:. .1,a\u00b7.\u00db .2,a \u00b7. =.,a:. Figure 8. Context splitting rules .; \u00b7f e : t .,a:. \nf P : t [TP-EXP][TP-NEW] . f e : t . f .a:.. P : t .1 f P1 : t .2 f P2 : [TP-PARLEFT] .1\u00db .2 f P1 | P2 \n: t .1 f P1 : .2 f P2 : t [TP-PARRIGHT] .1\u00db .2 f P1 | P2 : t Figure 9. Process typing rules to send \non the channel a), a \u00b7. (representing the ability to receive on a), and a:. (combining both capabilities). \nBoth varieties of context are linear, in the sense that they permit neither weakening nor contraction. \nMany of our rules are standard for a linear type system, but as linear type systems themselves are not \nquite standard, they still deserve some explanation. Because linear variables cannot be discarded, rules \nthat serve as the leaves of proof trees require contexts that are either empty (as in T-UNIT) or that \ncontain exactly what is being typed (as in T-VAR). Rules with multiple premises vary depending on how \nmany of their subterms will eventually be evaluated. If only one of several will, then all those subexpressions \nshould share the same contexts, as in T-WITH. When multiple subexpressions will be evaluated, as in T-TENSOR, \nthe contexts must be divided among them. We write .1 \u00db .2 and .1 \u00db .2 to denote contexts that can be \nsplit into .1 and .2 and into .1 and .2 respectively; this relation is formally de.ned in Figure 8. The \ntyping rules for our new constructs are straightforward. The types for go. e and yield e have already \nbeen discussed; channel endpoints Jal and 1ar have the types ascribed to them by the channel context \n. by a\u00b7. and a \u00b7. respectively. The closed channel JaL accounts for both endpoints but must be given \nthe type . We write . f P : t for a well-typed process P with channels typed by .; our process typing \nrules are given in Figure 9. No . is needed, as processes never depend on expression variables; rule \nTP-EXP type checks atomic processes in the empty variable context.Rule TP-NEW extendsthechannelenvironmentatbinders. \nAs the .nal type of all processes but our original will always be , rules TP-PARLEFT and TP-PARRIGHT \nrequire that one of their components always have type . Note that TP-PARLEFT and TP-PARRIGHT split their \nchannel context with\u00db rather than simply \u00db. As seen in Figure 8, this allows exactly one a:. binding \nto be decomposed into an a\u00b7. binding and an a \u00b7. binding. This means that, in any well-typed process \nof the form P1 | P2, there can be at most one channel for which one endpoint is in P1 and the other is \nin P2. This restriction substantially cuts down the set of well-typed processes and, as will be seen \nshortly, proves crucial for type soundness.  4.2 Soundness Taking the usual approach and de.ning soundness \nin terms of preservation well-typed terms that step always step to well-typed  P2 = P1 P1 = P2 P2 = \nP3 [EQP-REFL] P = P [EQP-SYM][EQP-TRANS][EQP-COMM] P1 | P2 = P2 | P1 P1 = P2 P1 = P3 '' ' P1 = P1 P2 \n= P2 P = P [EQP-PAR][EQP-NEW][EQP-ASSOC](P1 | P2) | P3 = P1 | (P2 | P3) '' ' P1 | P2 = P1 | P2 .a:.. \nP = .a:.. P a not free in P2 [EQP-SWAP] .a1:.1. .a2:.2.P = .a2:.2. .a1:.1.P [EQP-EXTRUDE] (.a:.. P1) \n| P2 = .a:.. (P1 | P2) Figure 10. Process equivalence rules terms and progress well-typed non-values \ncan always take a step we observe that, while preservation makes sense on both expressions and processes, \nprogress is only a property of well-typed processes, as there are certainly well-typed expressions that \nrequire the process evaluation rules to take a step. Preservation on expressions is straightforward, \nrequiring the usual substitution lemma: Lemma 1 (Substitution). If .; .1,x:t ' , .2 f e : t and . ' ;. \n' f e ' : t ', then ., . ' ;.1, . ' , .2 f{x . e ' }e : t. Lemma 2 (Expression preservation). If .; . \nf e : t and e -. e ', then .; . f e ' : t . We have proved these results in the Coq proof assistant; \nthe proofs are fairly standard, although the linear contexts introduce complexities that can usually \nbe avoided in other systems, e.g., the need to reason about context permutation. Preservation and progress \nfor processes are more complex. We .rst de.ne a process equivalence relation = as shown in Figure 10. \nThis equivalence separates unimportant structural differences in process syntax from the evaluation rules \nof Figure 3, which de\u00adtermine how processes truly evolve. All of these equivalence rules are standard; \nthey state that the precise position of binders, as well as the order and grouping of parallel composition, \nare irrelevant. We next introduce a notion of (not necessarily unique) canoni\u00adcal forms for processes: \na canonically formed process is of the form .a1:.1. ....am:.m.e1 | (e2 | (... | en)) for some m = 0 and \nn = 1. It is easy to see that any process can be put in canonical form by using the process equivalence \nrules. Property 3 (Canonization). For any process P , there exists some ' in canonical form such that \nP = P ' P . Proof. Recall the de.nition of \u00db, which allows only a channel to be split over the two halves \nof a parallel composition. It is not possible to partition the atomic processes in a cycle without going \nthrough at least two edges, thus making it impossible to type check a process with a cyclic communication \ngraph. Finally, we observe that acyclicity of communication graphs is preserved under process evaluation: \nLemma 6 (Acyclicity and evaluation). If the communication graph of P is acyclic and P -. P ', then the \ngraph of P ' is also acyclic. Proof. With respect to evaluation graphs, we observe that all eval\u00aduation \nsteps amount to doing some combination of the following: 1. the creation of a new vertex and a new edge \nconnecting it to one existing vertex, e.g. 8 8 8 e3 e1 . e2 2. the deletion of a single edge, e.g. 8 \n8 8 8 e1 e2 . e1 e2 3. the deletion of a single unconnected vertex, e.g. 8 e . 4. and transferring \nthe endpoint of an edge from one vertex to another by sending it across some other edge, e.g. 8 8 e1 \ne1 8 We de.ne the communication graph of a process P to be the . undirected6 multigraph in which the \nvertices are the atomic pro\u00adcesses (that is, expressions) that make up P and an edge exists 8 8 8  e2 \ne3  e2 e3 for each active channel a within the process, connecting the ex\u00adpressions containing Jal and \n1ar. (No edge exists for JaL.) Since graphs are built out of atomic processes, it is easy to see that \nthis graph structure is invariant under process equivalence. Property 4 (Graph invariance). For any processes \nP and P ' where P = P ', the communication graph of P ' is isomorphic to the communication graph of P \n. We immediately notice a correspondence between well-typedness of a process and the acyclicity of its \ncommunication graph: Lemma 5 (Acyclicity and typing). If . f P : t , then the communication graph of \nP is acyclic. 6 One might imagine that the directed nature of communication in Lolliproc would suggest \ndirected graphs, but undirected graphs both entail stronger acyclicity properties and simplify the proof \nof process preservation. EP-GO involves one use of (1) along with uses of (4) correspond\u00ading to the number \nof channel endpoints in the argument to go. . EP-APPSINK can similarly be seen as a repetition of (4), \nwhile EP-CLOSE and EP-DONE exactly correspond, respectively, to (2) and (3). All other evaluation rules \ndo not impact the communication graph. Only (4) can conceivably create a cycle. If a cycle is created, \nthe .nal step in its creation must be the connection of some atomic processes e1 and e2. But this can \nonly be facilitated by some e3 that is already connected to both e1 and e2, in which case a cycle would \nalready exist! Acyclic graphs can thus never become cyclic through application of these graph operations. \nWe can now tackle preservation and progress; our statements of both lemmas re.ects the idea that both \nprocess typing and process evaluation are performed modulo the process equivalence relation.  Lemma \n7 (Process preservation). If . f P1 : t and there exists '' ''' some P1 and P2 such that P1 = P1 and \nP1 -. P2, then there exists some P2 such that P2 = P2 ' and . f P2 : t. Proof. Mostly straightforward, \ngiven the obvious extensions of Lemma 2 to evaluation contexts and processes. The dif.culty comes from \nthe requirement of the channel context splitting re\u00adlation \u00db that at most one a:. binder be split at \neach step. We must show that, given the canonical form of P2', we can always rearrange the parallel compositions \nsuch that this is the case. Observe, however, that we can always do this if the communi\u00adcation graph \nof P2 ' (and thus its canonical form) is acyclic: we have our parallel compositions cut at most one edge \nat a time, and we will eventually reduce down to atomic processes. From Lemma 5 we already know that \nthe communication graph of P1 and hence also P1 ' is acyclic, and thus from Lemma 6 we can conclude that \nthe graph of P2 ' is acyclic as well. From this we can appropriately rearrange its canonical form to \ncreate a well-typed P2. For progress we must .rst de.ne what it means for a process to be done evaluating. \nWe use one of the simplest such de.nitions: a process has .nished when it contains an atomic process \nthat is a value and that is not Jal, 1ar, or JaL. Our proofs make use of the standard canonical forms \nproperties: all expressions of a given type eventually reduce to certain forms. Some types have more \ncanonical forms than usual, as sources and sinks are both values. Lemma 8 (Progress). If . f P : t , \nthen either P has .nished or there exists some P1 and P2 such that P = P1 and P1 -. P2. Proof. We proceed \nby examining each of the atomic processes within P . If, in doing so, we .nd an appropriate value or \nthe opportunity to take a step, then we are done, but we may encounter an expression e stuck at the elimination \nof a sink or a yield on a source. In that case, we consider the atomic process e ' that contains the \nother endpoint of the channel in question. If e ' itself can take a step, we are done. If e ' is ready \nto communicate with e we stop searching, as we have found a matched source and sink. Otherwise, e ' itself \nis stuck at the elimination of a sink or a yield on a source for some different channel, in which case \nwe recursively continue our search using the same procedure. Because P is well typed, it has an acyclic \ncommunication graph, so this search will eventually terminate in the identi.cation of some matching source \nand sink that are ready to communicate. We then consider the canonical form of P and repeatedly push \nthe appropriate channel binding inwards until the process matches the form of one of our communication \nrules. From progress and preservation, we can state the standard soundness theorem:7 Theorem 9 (Soundness). \nIf \u00b7f P :t , then there exists no P1 such that P = P1, P1 -. * P2, and P2 has not completed but is not \nequivalent to any process that can step further. This soundness property guarantees freedom from deadlocks \nin Lolliproc, but our type system says nothing about whether an expression will evaluate to a single \nvalue or a composition of processes both are considered acceptable .nal outcomes, and there is nothing \npreventing the programmer from, for instance, not matching each call to future with a corresponding call \nto wait. These concerns can be addressed in a language that also includes unrestricted types, however, \nwhich we will discuss in Section 5. 7 We are still working to extend our Coq proofs to preservation and \nprogress on processes; complications arise due to the relatively informal nature, by Coq s standards, \nof our the graph-based reasoning.  4.3 Strong normalization and con.uence Other properties common to \nsimple, typed .-calculi are strong normalization the fact that all sequences of evaluations terminate \nand con.uence the fact that all possible evaluations for a given term converge to the same .nal result. \nAlthough Lolliproc has a non-deterministic operational semantics, it still enjoys these prop\u00aderties. \nTheorem 10 (Strong normalization). If G f P : t , any reduction '' ' sequence P = P1, P1 -. P1, P1 = \nP2, P2 -. P2, ...will eventually terminate in some Pn ' such that there exists no Pn+1 '' ' and Pn+1 \nfor which Pn = Pn+1 and Pn+1 -. Pn+1. Proof. Since everything in our language is linear, subterms are \nnever duplicated; thus we can verify strong normalization by as\u00adsigning non-negative weights w(P ) to \nprocesses P and w(D) to derivations D of G; . f e : t which we abbreviate as w(e) and showing that these \nweights always decrease with evaluation. We de.ne w(.a:.. P ) = 1+ w(P ) and w(P1 | P2)= w(P1)+ w(P2). \nFor channel endpoints, we .rst de.ne the length of a protocol type e(.) as e( )=1, e(t -.)=1+ e(.), and \ne(.1 &#38;.2) = 1+max(e(.1),e(.2)). Whenever Jal has type ., we de.ne w(Jal)= e(.); similarly, when 1ar \nhas type .P, we de.ne w(1ar)=2 \u00b7 e(.) (as larger terms appear on the source side after communication). \nSince process communication always decreases the length of the protocol type, it will consequently decrease \nthe weight of the composite process. We de.ne w(go. e) = 2+3 \u00b7 e(.)+ w(e), ensuring that its evaluation \nalso decreases in weight even as it spawns a new process. The weights of most other expression forms \nare fairly straight\u00adforward; for instance, w(x)= w(()) = 0, w(.x:te)=1+ w(e), w((e1,e2)) = 1+ w(e1)+ \nw(e2), and w((e1,e2)) = 1+ max w(e1), w(e2). The cases for yield and application are tricky, though, \nsince the rules E-YIELDOTHER and E-APPSOURCE ap\u00adpear to increase the size of terms. For yield, we de.ne \nw(yield e)= 1+ w(e) whenever e is either (go. e ' ) or any source; otherwise, given that e is assigned \nthe type 1t r, we de.ne w(yield e) = 1+ w(let (y, z)= yield (got e) in z; y) = 5+ w(got e) = 13+ w(e) \nFor applications, we must conservatively estimate how many times E-APPSOURCE might be applied. For this \nwe .rst de.ne the height of a type h(t ) such that h(t - ) = 1+ h(t ) and h(t )=0 otherwise. Assuming \nthe derivation for e1 e2 gives e1 the type t1 -t2 and e2 the type t1, then we can de.ne w(e1 e2)= 1 + \n14 \u00b7 h(t1)+ w(e1)+ w(e2), since the height of t1 determines the maximum number of yields that could ever \nbe introduced. With these de.nitions in place, it is clear by inspection of our evaluation rules that \nthe weight of a process decreases with each evaluation step. Since weights are never negative, this assures \nus that evaluation always terminates. With strong normalization, we can obtain con.uence directly from \nlocal con.uence (also known as the diamond property). Theorem 11 (Local con.uence). If G f P : t, and \nwe have that P = P1, P = P2, P1 -. P1', and P2 -. P2', then there ''' ' exist some P3, P3, P4, and P4 \nsuch that P1 = P3, P3 -. P3, ' ''' P2 = P4, P4 -. P4, and P3 = P4. Proof. Our expression evaluation rules \nare deterministic, and there is only one way to decompose an expression e into some Ee ' such that some \nexpression or process evaluation rule applies and only one such rule will ever apply. Our only source \nof non\u00addeterminism, then, is the parallel composition of processes. We must thus show that the evaluation \nP1 -. P1 ' does not rule out subsequently applying the same steps that produced P2 -. P2' , and vice-versa. \n We observe that, in a well-typed process, potential evaluation steps can never interfere with each \nother. We have only two end\u00adpoints for each process, so multiple acts of communication can never con.ict, \nand since communication always involves values, it cannot con.ict with some internal evaluation step \non a non-value expression. And of course such internal steps cannot con.ict with each other. It is thus \neasy to see that local con.uence holds. Strong normalization and con.uence show that the concurrency \navailable in Lolliproc is particularly well behaved. Strong normal\u00adization implies that there are no \nlivelocks, while con.uence implies a lack of race conditions, which could otherwise introduce irrecon\u00adcilable \nnondeterminism. 5. Future directions and related work Finally, we examine a few possible future directions \nof this work and look brie.y at related systems. 5.1 Extending Lolliproc Lolliproc is very far from being \na full-.edged programming language. Many of the extensions needed to bridge this gap compilation and \nruntime system, support for processes spread over the network, useful libraries, etc. are beyond the \nscope of this paper, but several obvious extensions do warrant more discussion here. Unrestricted types \nand polymorphism Although we have de.ned Lolliproc such that all variables must be used exactly once, \nthis is clearly an unrealistic simpli.cation; unrestricted types must be ac\u00adcounted for somehow. In earlier \nwork [31] we introduced an intu\u00aditionistic language System F., an extension of the fully polymor\u00adphic \nSystem F in which the distinction between the linear and the unrestricted is handled at the kind level: \na kind * categorizes unre\u00adstricted types, while a kind . categorizes linear types. System F. features \na subkinding relation in which * . ., implying that unre\u00adstricted types may safely be treated as though \nthey were linear. We can extend this approach to encompass Lolliproc by intro\u00adducing a protocol kind \n such that . .. We could then replace our syntactic separation of . types with the appropriate kinding \nrules. . For function types which System F. writes as . rather than the -we use for Lolliproc this gives \nus G f t1 : .1 G f t2 : .2 . = =. .2 = [K-ARR] . G f t1 . t2 : . Here G is an unrestricted context, \nbinding both type variables and, although not relevant to this judgment, unrestricted term variables. \nSince such a system allows quanti.cation over type variables a of kind , we would also require dualized \ntype variables aP, instantiated to .Pwhenever a is instantiated with .. If we also allow .a:.. . to be \na protocol type thus permitting types to be sent between processes we gain even greater .exibility, allowing \npartially speci.ed protocols dependent on protocol type variables. Adopting the techniques of System \nF. also allows us to address the concerns mentioned at the end of Section 4.2: we would know that, if \ne is a well-typed expression of type t that does not contain any channel endpoints, e will eventually \nstep to some isolated value v, regardless of how many processes may be spawned along the way. Here we \nappeal to an alternate operational semantics for System F. that tags values and types as they are substituted \ninto expressions: this semantics guarantees that unrestricted values do not contain tagged linear objects, \nand, since channel endpoints do not appear in source programs, they would always appear tagged. Recursion \nand non-determinism We have proved in Section 4.3 that Lolliproc is both strongly normalizing and con.uent. \nHowever, one does not generally want to program in languages that rule out non-terminating programs, \nand in a concurrent setting it is common to want programs that might evaluate differently depending on \nwhich processes are available to communicate at which times, thus breaking con.uence. One natural companion \nto Lolliproc s existing constructs is recursive types \u00b5a[:.].t , where any as appearing within t expand \nto \u00b5a[:.].t. Such types allow for full general recursion, can be used to encode many standard datatypes \n(e.g., lists over a given type), and, in our setting, enable looping protocols, for which there are many \nobvious applications. For instance, we could write a session\u00adserving server with the type \u00b5a[: ]. 1(. \n. a))r, which could be used to send out any number of sessions for the protocol .. For controlled non-con.uence, \nwe can imagine a family of primitive functions like the one below receivet2 1,t2,t : 1t1r-1t2r\u00ad((t1 -1t2r-t \n)&#38;(1t1r-t2 -t )) -t A call to a receive function waits until a yield on one of its source arguments \ncan succeed, then selects and applies the appropriate function from its additive product argument to \nhandle that result and the other remaining sources. (We would, of course, want syn\u00adtactic sugar for these \nfunctions.) This closely mimics the non-deterministic operations found in many concurrent languages e.g., \nthe join calculus [20, 21] and Erlang [3] while still preserving our linearly typed channels. We would \nalso likely want other constructs to handle cases for which receive is awkward: for instance, we might \nwant non-deterministic analogs of map and fold for several sources of the same type. Proof theory The \nexpression typing rules in (Figure 7), when viewed as a logic, are clearly sound with respect to standard \nclas\u00adsical linear logic. To see why, note that we may consider only case where . is empty, as channels \ndo not occur in source programs. Our only nonstandard rules are then T-GO and T-YIELD, but these are \nboth admissible in standard linear logic. We leave establishing the completeness with respect to the \nnon-exponential fragment of standard linear logic to future work. It would also be interesting to study \nthe relationship between our evaluation rules and proof normalization there seems to be a strong connection \nbetween our de.nition of channel endpoints and focused proofs [46].  5.2 Related work There is a vast \nliterature on linear logic, its proof theory, and related type systems, ranging from applications to \ncategorical semantics we cannot possibly cover it all here. Thus we highlight the work most closely related \nto ours and suggest some connections that might be fruitful for subsequent research. Intuitionistic linear \ntypes The intuitionistic fragment of linear logic has seen much use in programming languages [6, 9, 11, \n29, 30] particularly its connections to memory management [2, 13, 39, 42]. We recently looked at enforcing \nuser-de.ned protocols in a linear variant of System F [31]. De Paiva and Ritter study an in\u00adtuitionistic \nlinear language that, like Lolliproc, is not directly invo\u00adlutive (i.e., t is not identi.ed with t..); \nits operational semantics is reminiscent of the classical calculi described below. Classical natural \ndeduction and control Natural deduction pre\u00adsentations of classical logics [10, 14, 35 37] typically \nuse multiple conclusions judgments of the form: x1:t1,...,xn:tn f e : t, yn+1:tn+1,...,ym:tm By duality, \nsuch a judgment is logically equivalent to x1:t1,...,xn:tn,yn+1:tn+1,...,ym:tm f e : t  This approach \nrecovers the usual shape of the typing judgment and so can be reconciled more easily with type systems \nfor functional programming. Moreover, if we recall that t - is the type of a continuation accepting t \nvalues, it is possible to read the ys above as binding continuations. Operational semantics in this setting \nim\u00adplement commuting conversions, which give rise to nondetermin\u00adism. The correspondence with concurrency \nis obscured, however, because these semantics rely on decomposing a single term (often using evaluation \ncontexts). The connection between classical logic and control operators has been known for some time \n[17, 23, 34]. As mentioned in Section 2, control has the type of double-negation elimination; the more \nfamiliar callcc can similarly be given the type of Peirce s Law. While these operations cannot be directly \nimported to the linear setting, they are a major part of the inspiration for our approach. Linear continuations \nin otherwise unrestricted languages have also been studied, as they indicate certain predictable patterns \nof control .ow [8, 19]. Berdine s dissertation [7], for example, shows how such continuations can be \nused to implement coroutines; Lol\u00adliproc goes further by allowing true concurrent evaluation. Our process \ntyping rules can be seen as an alternative to the multiple conclusion judgment style described above. \nWhile these systems give all auxiliary conclusions a continuation type t - , our helper processes simply \nhave type . A practical consequence of our design is that, since processes appear only at runtime, a \ntype checker for a language based on Lolliproc would not need to implement these rules at all. Linear \nsequent calculi In order to take advantage of the symme\u00adtries discussed in Section 2, languages and proof \nterms based on linear sequent calculi [1, 22] feature a multiplicative disjunction ` and de.ne t1 -t2 \nas t1 ` t2. It has proved dif.cult, however, to .nd intuitions for ` in a standard functional programming \nsetting that .t as naturally as those for ., &#38;, and . [44]. We can encode ` in Lolliproc by noting \nfollowing the logical equivalence: t1 ` t2 .. ((t1 - ) -t2) &#38; ((t2 - ) -t1) We will not be able to \nconstruct an object of this type unless we can eliminate some t - without producing a witness of type \n, which requires the existence of another process and a channel over which we can send the closed channel \ntoken. Thus ` serves as a way of internalizing and at least partially suspending two processes within \none, although it cannot exist in isolation. The choice of projections offered by &#38; internalizes the \ncommutativity of the | constructor of process terms. Zeilberger presented an interesting sequent calculus \n[46] that, while not actually linear, makes use of the connectives of linear logic for their polarity \nand gives a term assignment in which eager positive connectives and lazy negative connectives coexist \nharmo\u00adniously. The dual calculus [43] and Filinski s language [18] are also tightly tied to sequent calculus \nwhile being closer to standard term languages than, e.g., proof nets. All of these languages de.ne pro\u00adgrams \nas interactions between terms and co-terms, departing rather signi.cantly from the norm in functional \nprogramming. Process calculi Many type systems exist for the p-calculus [32], some able to guarantee \nsophisticated properties; Kobayashi [27] gives a good overview of this area. Many of these type systems \nuse linearity in one form or another [4, 28], and, in particular, session types [12, 25, 38, 40] originated \nin this setting. The Singr language, which ensures safety for its light-weight processes through its \ntype system, takes many ideas from the world of process calculi [15]. Programming in a process calculus, \nhowever, is also rather dif\u00adferent from programming in a traditional functional language, and it is not \nalways clear how to best take ideas from that setting while reusing as much standard machinery as possible. \nAdditionally, p\u00adcalculus type systems are not as tightly coupled with logics as .\u00adcalculus type systems \nare, though there has been some work on using p-calculus terms to describe proof reductions [5].  5.3 \nConclusion We have presented Lolliproc, a concurrent language whose de\u00adsign separates source programs \nfrom the processes they spawn at runtime, while retaining a close correspondence to classical lin\u00adear \nlogic. Though simple, Lolliproc can express useful protocols whose well-behaved interactions are enforced \nby session types. It is our hope that Lolliproc will inspire language designers, if not to build their \nnext language on its ideas, then at least to consider what linear types might have to offer in terms \nof concurrency. Whether or not this comes to pass, however, we feel that our approach offers an appealing \npoint in the design space of concurrent calculi. Acknowledgments The authors thank the anonymous reviewers, \nthe Penn PL Club, and the MSR Cambridge types wrestling group for their feedback about this work. Phil \nWadler and Guillaume Munch-Maccagnoni also provided excellent suggestions about how to improve this paper. \nThis work was supported in part by NSF Grant CCF-541040 and some of this research was conducted while \nthe second author was a visiting researcher at Microsoft Research, Cambridge. References [1] Samson Abramsky. \nComputational interpretations of linear logic. Theoretical Computer Science, 111:3 57, 1993. [2] Amal \nAhmed, Matthew Fluet, and Greg Morrisett. L3: A linear language with locations. Fundam. Inf., 77(4):397 \n449, 2007. [3] Joe Armstrong, Robert Virding, Claes Wikstr\u00a8 om, and Mike Williams. Concurrent Programming \nin Erlang. Prentice-Hall, 1996. [4] Emmanuel Beffara. A concurrent model for linear logic. Electronic \nNotes in Theoretical Computer Science, 155:147 168, 2006. [5] G. Bellin and P. J. Scott. On the p-calculus \nand linear logic. Theoret\u00adical Computer Science, 135(1):11 65, 1994. [6] Nick Benton, G. M. Bierman, \nJ. Martin E. Hyland, and Valeria de Paiva. A term calculus for intuitionistic linear logic. In Proceed\u00adings \nof the International Conference on Typed Lambda Calculi and Applications, pages 75 90. Springer-Verlag \nLNCS 664, 1993. [7] Josh Berdine. Linear and Af.ne Typing of Continuation-Passing Style. PhD thesis, \nQueen Mary, University of London, 2004. [8] Josh Berdine, Peter W. O Hearn, Uday S. Reddy, and Hayo Thielecke. \nLinearly used continuations. In Proceedings of the Continuations Workshop, 2001. [9] G. M. Bierman, A. \nM. Pitts, and C. V. Russo. Operational properties of Lily, a polymorphic linear lambda calculus with \nrecursion. In Fourth International Workshop on Higher Order Operational Techniques in Semantics, Montral, \nvolume 41 of Electronic Notes in Theoretical Computer Science. Elsevier, 2000. [10] Gavin Bierman. A \nclassical linear lambda calculus. Theoretical Computer Science, 227(1 2):43 78, 1999. [11] Gavin M. Bierman. \nProgram equivalence in a linear functional lan\u00adguage. Journal of Functional Programming, 10(2), 2000. \n[12] Lu\u00b4is Caires and Frank Pfenning. Session types as intuitionistic linear propositions. In Proceedings \nof the 21st International Conference on Concurrency Theory (CONCUR 2010), Paris, France, August 2010. \nSpringer LNCS. [13] Arthur Chargu\u00b4eraud and Franc\u00b8ois Pottier. Functional translation of a calculus of \ncapabilities. In ICFP 08: Proceeding of the 13th ACM SIGPLAN international conference on Functional programming, \npages 213 224, New York, NY, USA, 2008. ACM.  [14] Valeria de Paiva and Eike Ritter. A parigot-style \nlinear lambda\u00adcalculus for full intuitionistic linear logic. Theory and Applications of Categories, 17(3), \n2006. [15] Manuel F\u00a8ahndrich, Mark Aiken, Chris Hawblitzel, Orion Hodson, Galen Hunt, James R. Larus, \nand Steven Levi. Language support for fast and reliable message-based communication in singularity os. \nSIGOPS Oper. Syst. Rev., 40(4):177 190, 2006. [16] Manuel F\u00a8ahndrich and Robert DeLine. Adoption and \nfocus: Practical linear types for imperative programming. In Proc. of the SIGPLAN Conference on Programming \nLanguage Design, pages 13 24, Berlin, Germany, June 2002. [17] M. Felleisen and R. Hieb. A revised report \non the syntactic theo\u00adries of sequential control and state. Theoretical Computer Science, 103(2):235 \n271, 1992. [18] Andrzej Filinski. Declarative continuations and categorical duality. Master s thesis, \nUniversity of Copenhagen, August 1989. [19] Andrzej Filinski. Linear continuations. In Proc. 19th ACM \nSymp. on Principles of Programming Languages (POPL), pages 27 38, 1992. [20] C. Fournet and G. Gonthier. \nThe Re.exive CHAM and the Join-Calculus. In Proc. ACM Symp. on Principles of Programming Lan\u00adguages (POPL), \npages 372 385, 1996. [21] C\u00b4edric Fournet. The Join-Calculus: a Calculus for Distributed Mobile Programming. \nPhD thesis, Ecole Polytechnique, nov 1998. \u00b4 [22] Jean-Yves Girard. Linear logic. Theoretical Computer \nScience, 50:1 102, 1987. [23] Timothy G. Grif.n. A formulae-as-types notion of control. In Confer\u00adence \nRecord of the Seventeenth Annual ACM Symposium on Principles of Programming Languages, pages 47 58. ACM \nPress, 1990. [24] Michael Hicks, Greg Morrisett, Dan Grossman, and Trevor Jim. Expe\u00adrience with safe \nmanual memory-management in Cyclone. In ISMM 04: Proceedings of the 4th international symposium on Memory \nman\u00adagement, pages 73 84, New York, NY, USA, 2004. ACM. [25] Kohei Honda, Vasco T. Vasconcelos, and Makoto \nKubo. Language primitives and type discipline for structured communication-based programming. In ESOP98, \nvolume 1381 of LNCS, pages 122 138. Springer-Verlag, 1998. [26] W. A. Howard. The formulae-as-types notion \nof contstruction. In To H. B. Curry: Essays on Combinatory Logic, Lambda Calculus, and Formalism. Academic \nPress, 1980. [27] Naoki Kobayashi. Type systems for concurrent programs. In Proceed\u00adings of UNU/IIST \n10th Anniversary Cooloquium, March 2002. [28] Naoki Kobayashi, Benjamin C. Pierce, and David N. Turner. \nLinearity and the Pi-Calculus. Transactions on Programming Languages and Systems, 21(5):914 947, 1999. \n[29] Yves Lafont. The linear abstract machine. Theoretical Computer Science, 59:157 180, 1988. Corrections \nin vol. 62, pp. 327 328. [30] John Maraist, Martin Odersky, David N. Turner, and Philip Wadler. Call-by-name, \ncall-by-value, call-by-need, and the linear lambda cal\u00adculus. In 11 th International Conference on the \nMathematical Foun\u00addations of Programming Semantics, New Orleans, Lousiana, 1995. [31] Karl Mazurak, \nJianzhou Zhao, and Steve Zdancewic. Lightweight linear types in System F. . In TLDI 10: Proceedings of \nthe 5th ACM SIGPLAN workshop on Types in language design and implementation, pages 77 88, New York, NY, \nUSA, 2010. ACM. [32] R. Milner, J. Parrow, and D. Walker. A calculus of mobile processes. Information \nand Computation, 100(1):1 77, 1992. [33] J. Niehren, J. Schwinghammer, and G. Smolka. A concurrent lambda \ncalculus with futures. Theor. Comput. Sci., 364(3):338 356, 2006. [34] C.-H. L. Ong and C. A. Stewart. \nA curry-howard foundation for functional computation with control. In Proc. 24th ACM Symp. on Principles \nof Programming Languages (POPL), pages 215 227, Paris, France, 1997. [35] Michel Parigot. .\u00b5-calculus: \nAn algorithmic interpretation of classi\u00adcal natural deduction. In Proceedings of the International Conference \non Logic Programming and Automated Reasoning, volume 624 of Lec\u00adture Notes in Computer Science, pages \n190 201. Springer, 1992. [36] Michel Parigot. Classical proofs as programs. In Proceedings of the 3rd \nKurt G\u00a8 odel Colloquium, volume 713 of Lecture Notes in Computer Science, pages 263 276. Springer-Verlag, \n1993. [37] Eike Ritter, David J. Pym, and Lincoln A. Wallen. Proof-terms for classical and intuitionistic \nresolution. Journal of Logic and Computa\u00adtion, 10(2):173 207, 2000. [38] Kaku Takeuchi, Kohei Honda, \nand Makoto Kubo. An interaction\u00adbased language and its typing system. In Proceedings of PARLE 94, pages \n398 413. Springer-Verlag, 1994. Lecture Notes in Computer Science number 817. [39] David N. Turner and \nPhilip Wadler. Operational interpretations of lin\u00adear logic. Theoretical Computer Science, 227(1-2):231 \n248, Septem\u00adber 1999. [40] Vasco T. Vasconcelos, Simon J. Gay, and Ant\u00b4onio Ravara. Type check\u00ading a \nmultithreaded functional language with session types. Theoreti\u00adcal Computer Science, 368(1 2):64 87, \n2006. [41] Edsko Vries, Rinus Plasmeijer, and David M. Abrahamson. Unique\u00adness typing simpli.ed. In Implementation \nand Application of Func\u00adtional Languages: 19th International Workshop, IFL 2007, Freiburg, Germany, September \n27-29, 2007. Revised Selected Papers, pages 201 218, Berlin, Heidelberg, 2008. Springer-Verlag. [42] \nPhilip Wadler. Linear types can change the world! In M. Broy and C. Jones, editors, Progarmming Concepts \nand Methods, Sea of Galilee, Israel, April 1990. North Holland. IFIP TC 2 Working Con\u00adference. [43] Philip \nWadler. Call-by-value is dual to call-by-name. In ICFP 03: Proceedings of the eighth ACM SIGPLAN international \nconference on Functional programming, pages 189 201, New York, NY, USA, 2003. ACM. [44] Philip Wadler. \nDown with the bureaucracy of syntax! Pattern matching for classical linear logic. unpublished manuscript, \n2004. [45] Nobuko Yoshida, Kohei Honda, and Martin Berger. Linearity and bisimulation. J. Log. Algebr. \nProgram., 72(2):207 238, 2007. [46] Noam Zeilberger. On the unity of duality. Annals of Pure and Applied \nLogic, 153(1 3):66 96, 2006. [47] Dengping Zhu and Hongwei Xi. Safe Programming with Pointers through \nStateful Views. In Proceedings of the 7th International Sym\u00adposium on Practical Aspects of Declarative \nLanguages, pages 83 97, Long Beach, CA, January 2005. Springer-Verlag LNCS vol. 3350.   \n\t\t\t", "proc_id": "1863543", "abstract": "<p>While many type systems based on the intuitionistic fragment of linear logic have been proposed, applications in programming languages of the full power of linear logic - including double-negation elimination - have remained elusive. Meanwhile, linearity has been used in many type systems for concurrent programs - e.g., session types - which suggests applicability to the problems of concurrent programming, but the ways in which linearity has interacted with concurrency primitives in lambda calculi have remained somewhat ad-hoc. In this paper we connect classical linear logic and concurrent functional programming in the language Lolliproc, which provides simple primitives for concurrency that have a direct logical interpretation and that combine to provide the functionality of session types. Lolliproc features a simple process calculus \"under the hood\" but hides the machinery of processes from programmers. We illustrate Lolliproc by example and prove soundness, strong normalization, and confluence results, which, among other things, guarantees freedom from deadlocks and race conditions.</p>", "authors": [{"name": "Karl Mazurak", "author_profile_id": "81331499117", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P2338143", "email_address": "", "orcid_id": ""}, {"name": "Steve Zdancewic", "author_profile_id": "81384616728", "affiliation": "University of Pennsylvania, Philadelphia, PA, USA", "person_id": "P2338144", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863551", "year": "2010", "article_id": "1863551", "conference": "ICFP", "title": "Lolliproc: to concurrency from classical linear logic via curry-howard and control", "url": "http://dl.acm.org/citation.cfm?id=1863551"}