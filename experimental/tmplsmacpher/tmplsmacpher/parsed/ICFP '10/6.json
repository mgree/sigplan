{"article_publication_date": "09-27-2010", "fulltext": "\n Polyvariant Flow Analysis with Higher-ranked Polymorphic Types and Higher-order Effect Operators Stefan \nHoldermans Vector Fabrics Paradijslaan 28, 5611 KN Eindhoven, The Netherlands stefan@vectorfabrics.com \nJurriaan Hage Dept. of Inf. and Comp. Sciences, Utrecht University P.O. Box 80.089, 3508 TB Utrecht, \nThe Netherlands jur@cs.uu.nl Abstract We present a type and effect system for .ow analysis that makes \nessential use of higher-ranked polymorphism. We show that, for higher-order functions, the expressiveness \nof higher-ranked types enables us to improve on the precision of conventional let\u00adpolymorphic analyses. \nModularity and decidability of the analysis are guaranteed by making the analysis of each program parametric \nin the analyses of its inputs; in particular, we have that higher-order functions give rise to higher-order \noperations on effects. As .ow typing is archetypical to a whole class of type and effect systems, our \napproach can be used to boost the precision of a wide range of type-based program analyses for higher-order \nlanguages. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs and \nFeatures Polymorphism; F.3.2 [Logics and Meanings of Programs]: Semantics of Program\u00adming Languages Program \nanalysis; F.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs Functional con\u00adstructs, \nType structure General Terms Languages, Theory Keywords type-based program analysis, higher-ranked polymor\u00adphism \n1. Introduction The use of polymorphic types in type and effect systems for static program analysis is \nusually limited to ML-style let-polymorphism. This restriction precludes the formal parameters of higher-order \nfunctions from being analysed polyvariantly rather than monovari\u00adantly. In this paper, we consider a \ntype and effect system that allows analyses to be expressed in terms of higher-ranked polymorphic types \nand argue how the resulting polyvariant analyses are more powerful than the analyses obtained from let-polymorphic \nsystems. Speci.cally, our contributions are the following: We present an annotated type and effect system \nfor .ow anal\u00adysis that makes essential use of higher-ranked polymorphism in both annotations and effects \n(Section 5). The resulting anal\u00adysis is polyvariant in its treatment of lambda-bound variables, Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 10, September \n27 29, 2010, Baltimore, Maryland, USA. Copyright c . 2010 ACM 978-1-60558-794-3/10/09... $10.00 applicable \nto all well-typed terms in an explicitly typed lambda\u00adcalculus with Booleans and conditionals (Section \n6.1), and sound with respect to an instrumented, .ow-tracking seman\u00adtics (Section 6.2). The main technical \ninnovations of our system are its use of so\u00adcalled fully .exible types to maintain the modularity of \nthe anal\u00adyses (Section 4.1) and its use of annotation and effect operators to have the analyses of higher-order \nfunctions explicitly param\u00adeterised in the analyses of their arguments (Section 4.2).  For all terms \nwith fully .exibly typed free variables, our system admits best analyses (Section 6.3), which can be \nobtained by means of a strikingly straightforward inference algorithm (Section 7).  We stress that .ow \ntyping is, in a sense, archetypical to a whole class of type and effect systems; as a wide range of other \nanalyses, including binding-time analysis, strictness analysis, and usage analysis, are known to be expressible \nas variations of type\u00adbased control-.ow analysis, we expect our approach to also apply to most if not \nall of these analyses. 2. Motivation Numerous static program analyses depend on information about the \n.ow of control in the program under analysis. Whereas for .rst\u00adorder languages this information is directly \navailable from the pro\u00adgram text, the situation for higher-order languages, in which func\u00adtions or procedures \ncan be passed as arguments to other functions or procedures, is considerably different; for these languages, \none has to deal with the dynamic dispatch problem. Consider, for exam\u00adple, the following program fragment, \nwritten in some typed higher\u00adorder functional language: h : (bool . bool) . bool hf = if f false then \nf true else false. As the function parameter f can, at run-time, be bound to any suitably typed function, \nit is not obvious to what code control is transferred when the condition f false in the body of h is \nevaluated. To cope with the dynamic dispatch problem, several .ow anal\u00adyses have been proposed. Of particular \ninterest are .ow analyses that, in some way or another, take advantage of the structure that is imposed \non programs by a static typing discipline for the lan\u00adguage under analysis; such type-based analyses \ncan typically be more effective than analyses for dynamically typed languages or analyses that ignore \nthe well-typedness of analysed programs (Pals\u00adberg 2001). An important class of type-based analyses is \nthen that of so-called type and effect systems that extend the typing disci\u00adplines of languages as to \nexpress properties beyond just plain data types (Nielson and Nielson 1999).  For instance, to track \nthe .ow of Boolean values through a pro\u00adgram, we can decorate all occurrences of the Boolean constructors \nfalse and true in a program with labels .1, .2, ..., as in hf = if f false.1 then f true.2 else false.3 \n, and adopt an extended type system that annotates the type bool of Boolean values with sets of labels \nidentifying the possible construc\u00adtion sites of these values. The Boolean identity function, id x = x, \nthen, for example, can have the type bool{.1,.2 }. bool{.1 ,.2 }, indicating that if its argument x is \na Boolean constructed at any of the sites labelled with .1 or .2, then so is its result. Assigning the \nfunction id this type prepares it for being passed as an argu\u00adment to the function h above, which can \nbe of type (bool{.1,.2 }. bool{.1,.2 }) . bool{.1 ,.2,.3 }. However, in general the assigned type is \ntoo speci.c as id could be used in other contexts as well. This is suggestive of annotating the argument \nand result types of id with a larger set as to re.ect all uses of id in the program, but this is undesirable \nfor at least two reasons. First, it requires the whole program to be available as information is required \nabout all possi\u00adble uses of id and thus precludes the analysis from being modular. Second, it renders \nthe analysis of program fragments that directly or indirectly use id rather imprecise as the larger set \nshows up for every value that is obtained by applying id, irrespective of the ac\u00adtual argument supplied. \nThis latter issue is known as the poisoning problem (Wansbrough and Peyton Jones 1999). In general, poison\u00ading \ncan be reduced by making the analysis more polyvariant, that is, allowing different uses of an identi.er \nto be analysed indepen\u00addently. One way to make an analysis based on a type and effect system both more \nmodular and more polyvariant is by making use of annotation polymorphism. For example, id can be assigned \nthe polymorphic type .\u00df .bool\u00df . bool\u00df with \u00df ranging over sets of constructor labels. Indeed, this type \ncan be derived from just the de.nition of id and instantiated to a more speci.c type for each use of \nid. The use of polymorphism in type and effect systems is usually limited to ML-style let-polymorphism \n(Damas and Milner 1982), meaning that polymorphic types can only be assigned to identi\u00ad.ers bound at \ntop level or in local de.nitions. This seems like a natural restriction as program analyses are almost \nalways required to be performed fully automatically and ML-style polymorphic types allow for mechanically \nand modularly deriving best anal\u00adyses , which are then typically de.ned in terms of principal types, \nwhereas more expressive uses of polymorphism do not necessarily admit such mechanisation. To see why \nwe may still want to consider less restrictive uses of polymorphism, consider once more applying the \nfunction h from the example above to the Boolean identity function id. In a let-polymorphic type and \neffect system, h can be expected to have a type much like .\u00df .(bool{.1,.2 }. bool\u00df ) . bool\u00df.{.3 }. The \naforementioned polymorphic type of id is then instantiated to bool{.1,.2 }. bool{.1,.2 } and instantiating \nthe variable \u00df in the type of h then yields bool{.1,.2,.3 } as the type obtained for the application \nh id. Note that this result is imprecise in the sense that the Boolean constructed at the site labelled \nwith .1 never .ows to the result of any invocation of h. This imprecision is caused by the restriction \nthat, in an ML-style type and effect system, the formal parameter f of h has to be assigned a monomorphic \ntype. Hence, uses of f in the body of h are analysed monovariantly and subjected to poisoning. Now, if \nthe type and effect system were to somehow allow the parameter f of h to have a polymorphic type, we \ncould have h : (.\u00df .bool\u00df . bool\u00df ) . bool{.2,.3 } with different choices for \u00df for different uses of \nf in the body of h allowing for a more polyvariant analysis. Here, we require h to have a so-called rank-2 \npolymorphic type. In general, the rank of a polymorphic type describes the maximum depth at which universal \nquanti.ers occur in contravariant positions (Kfoury and Tiuryn 1992). As it is well-known that the higher-ranked \nfragment of the polymorphic lambda-calculus does not admit principal types and that type inference is \nundecidable for rank 3 and higher, it is not immediately obvious that higher-ranked polymorphic types \ncan be of any practical use in type and effect systems for fully automatic program analysis. However, \nhere it is crucial that we only need to consider types that are polymorphic in the annotations that decorate \ntypes rather than in the types themselves. As it turns out, higher\u00adranked annotation polymorphism does \nindeed provide a feasible basis for attaining analyses that are fully polyvariant with respect to the \nformal parameters of higher-order functions.1 The main challenge of incorporating higher-ranked polymor\u00adphic \ntypes in a type and effect system is then to take advantage of their expressive power without compromising \nthe modularity of the analysis. For example, the rank-2 type for h that was proposed above is too speci.c \nas it presumes that the function bound to the parameter f will manifest identity-like behaviour, which \nin gen\u00aderal is obviously unacceptably restrictive. Below, we will rise to the challenge and present a \nmodular type and effect system with higher-ranked polymorphic types that admits analyses for higher\u00adorder \nfunctions like h that are adaptive enough for all appropriately typed functions to be passed in as arguments, \nwhile still allowing for the formal parameters of these higher-order functions to be anal\u00adysed polyvariantly. \n3. Preliminaries Throughout this paper, we use, as the language under analysis, an eagerly evaluated \nand simply typed Church-style lambda-calculus with Booleans, conditionals, and general recursion. Assuming \nan abstract set of program labels and a countable in.nite set of variable symbols, . . Lab labels x . \nVar variables, terms in our language are constructed from variables, producers, and consumers; that is, \nwe have t . Tm terms p . Prod producers c . Cons consumers with t ::= x | p. | c. p ::= false | true \n| .x : t.t1 c ::= if t1 then t2 else t3 | t1 t2 | .x t1. All producers and consumers are labelled. A \nproducer is either one of the Boolean constructors false and true or a lambda\u00adabstraction, while consumers \nsubsume conditionals, function ap\u00adplications, and .xed points. As usual, function application asso\u00adciates \nto the left and lambda-abstractions extend as far to the right as possible. Each abstraction is annotated \nwith the type of its formal parameter, where types, 1 This approach is reminiscent of the use of polymorphic \nrecursion in the type-based binding-time analysis of Dussart et al. (1995): while polymor\u00adphic recursion \nin its full, untamed glory renders type inference undecidable, its restriction to binding-time annotations \nhas proven to allow for a very ex\u00adpressive yet workable analysis. See Section 4.3.  Evaluation p. .{ \n} p. [e-prod] t .F p. system and the types from the underlying type system play a crucial r ole in our \napproach as they guide our polyvariant .ow analysis. 4. Key Ideas .p p. t1 .F1 truet2 .F2 [e-if-true] \n(if t1 then t2 else t3).c .F1 .{(.c,.p)}.F2 p. t1 .F1 false.p t3 .F3 p. [e-if-false] (if t1 then t2 \nelse t3).c p. .F1.{(.c,.p)}.F3 .2 t1 .F1 (.x : t.t0).p t2 .F2 p2[x .. p2.2 ]t0 .F0 p. [e-app] (t1 t2).c \n.F1 .F2.{(.c,.p)}.F0 p. t1 .F1 (.x : t.t0).p [x .. (.x t1).c ]t0 .F0 p. [e-.x] (.x t1).c p. .F1.{(.c,.p \n)}.F0 Figure 1. Instrumented natural semantics. Typing G . t : t G(x)= t [t-var] G . x : t [t-false][t-true] \nG . false. : bool G . true. : bool G[x .. t1 ] . t1: t2 [t-abs] G . (.x : t1.t1). : t1 . t2 G . t1: bool \nG . t2: t G . t3: t [t-if ] G . (if t1 then t2 else t3). : t G . t1: t2 . t G . t2: t2 G . t1: t . t \n [t-app][t-.x] G . (t1 t2). : t G . (.x t1). : t Figure 2. The underlying type system. t . Ty types, \nare given by t ::= bool | t1 . t2. An instrumented natural semantics is given in Figure 1 as a set of \ninference rules for deriving judgements of the form t .F , p. indicating that the term t evaluates in \nzero or more steps to the value produced by the .-labelled producer p, while the .ow of values during \nevaluation is captured by the .ow set F, F . Flow = P(Lab \u00d7 Lab) .ow. Concretely, each pair (.c,.p) in \na .ow set F witnesses the con\u00adsumption of a value produced at a program point labelled with .p by a consumer \nlabelled with .c. Note that Boolean values (pro\u00adduced by the constructors false and true) are consumed \nby con\u00additionals, while functions (produced by lambda-abstractions) are consumed by function applications \nand occurrences of the .xed\u00adpoint operator. Evaluation proceeds under a call-by-value strategy; capture-avoiding \nsubstitution, in rules [e-app] en [e-.x], is denoted by [\u00b7 .. \u00b7] . The static semantics of the language \nis presented in Figure 2 in terms of typing rules for deriving judgements G . t : t, expressing that, \nin the type environment G, the term t has the type t. Here, type environments are .nite maps from variables \nto types: G . TyEnv = Var ..n Ty type environments. In the sequel, we are only concerned with well-typed \nterms. The static semantics of Figure 2 is referred to as the underlying type In this section, we discuss \nthe key ideas behind the type and effect system that will be presented in Section 5. Recall that our \nmain objective is to provide a modular .ow analysis that allows lambda\u00adbound variables to be analysed \npolyvariantly rather than monovari\u00adantly. To this end, we associate with each term t in the program a \ntriple t.. &#38; ., consisting of an annotated type t., an annotation ., and an effect .. The idea is \nthat the annotation . describes the possible production sites of the values that t can evaluate to and \nthat the effect . describes the .ow that may be incurred from the evaluation of t. Thus, annotations \nare essentially sets of labels ., while effects are sets of pairs (.,.) consisting of a consumer label \n. and an annotation .. Annotated types are constructed from the type bool .0 of Booleans and annotated \nfunction types of the form t.1.1 -. t..2, where .1 and .2 denote the production sites of, respectively, \nthe argument and the result of a function, and .0 is the so-called latent effect of a function, i.e., \nthe effect that may be observed from applying the function to an argument. Furthermore, and crucially, \nwe allow universal quanti.cation over both annotations and effects to occur anywhere in an annotated \ntype. 4.1 Fully Flexible Types As an example, consider the Boolean negation function produced by .2 ).3 \n).4 (.x : bool.(if x then false.1 else true. Analysing this function may then result in the triple {(.3,\u00df)} \n(.\u00df .bool\u00df -----. bool{.1,.2 }){.4 } &#38; {}, expressing that the .4-labelled lambda-abstraction immediately \n(i.e., .owlessly) produces a function that may have its argument consumed by the conditional labelled \nwith .3 before returning a Boolean that is produced at either .1 or .2. Note that the annotated type \nfor the negation function is polymorphic in the annotation for its argument x and how this is crucial \nfor obtaining an analysis that is modular: whatever Boolean it is applied to, the type of the func\u00adtion \ncan always be instantiated to obtain a suitable analysis for the application. As modularity is a key \naspect of our analysis, let us from now on assume that functions are always analysed with maximum applicability \nin mind and, hence, that all functions have types that are indeed polymorphic in their argument annotations. \nWe shall refer to such types as fully .exible types.  4.2 Annotation and Effect Operators To demonstrate \nhow the notion of fully .exible types extends to higher-order functions, let us consider the second-order \nfunction produced by .5 ).6 ).7 (.f : bool . bool. (f true, which applies its argument to the Boolean \ntrue produced at .5. How can we, for such a function, obtain an analysis that can be regarded as fully \n.exible? Clearly, modularity requires us to be polymorphic in the annotation of the argument function \nf . More\u00adover, as we assume that all functions have fully .exible types, the type of any function to \nbe bound to f will itself be polymor\u00adphic in its argument annotation too, i.e., have a type of the form \n. .\u00df .bool\u00df -. bool. . In general, the latent effect . and the re\u00adsult annotation . of f depend on the \nargument annotation \u00df . We  can make this explicit by writing . and . as functions of \u00df : .0 \u00df .\u00df . \nbool\u00df --. bool.0 \u00df . If we allow annotation and effect ab\u00adstraction in annotated types, then the annotated \ntypes for all func\u00adtions of underlying type bool . bool can be written in this form. For instance, for \nthe annotated type of the negation function from Section 4.1, we have .0 = .\u00df . .{(.3,\u00df .)} and .0 = \n.\u00df . .{.1,.2 }, yielding (.\u00df. .{(.3,\u00df.)}) \u00df . {.1,.2 }) \u00df) .\u00df .bool\u00df - ---------. bool((.\u00df. . Returning \nto the analysis of the second-order function as a whole, modularity once more requires us to assume a \ntype for f that can be instantiated for all possible choices for .0 and .0 and, hence, we end up with \na triple consisting of the rank-2 type .\u00df f ..d0..\u00df0. d0 \u00df {(.6,\u00dff )}.d0 {.5 } (.\u00df .bool\u00df --. bool(\u00df0 \n\u00df ))\u00dff - ---------. bool(\u00df0 {.5 }), the singleton annotation and {.7 } and the empty effect {}. Here, \nthe variables d0 and \u00df0 range over, respectively, effect and annota\u00adtion operators rather than proper \neffects and annotations. Note how both the latent effect {(.6,\u00df f )}.d0 {.5 } and the result annotation \n\u00df0 {.5 } express that for any call of the second-order function, the polymorphic type of the function \nbound to its parameter f is in\u00adstantiated with the annotation {.5 } and that the supplied effect and \nannotation operators are applied accordingly. Essentially, what we have done here amounts to parameterising \nthe analysis of a function by the analyses of its arguments. For a .rst-order function, the analysis \nof an argument is captured by a single annotation that identi.es its possible production sites. For a \nhigher-order function, the analysis of an argument of function type is captured by a proper annotation \nthat identi.es the possible production sites of the supplied function, and effect and annotation operators \nthat describe how the analysis of the argument function depends on the analyses for its own arguments. \nNow, concretely, if we instantiate the annotated type of the second-order function above as to prepare \nit for being applied to the negation function from Section 4.1 and thus supply it with the analysis for \nthe negation function, then, after beta-reducing the effects and annotations, we obtain the instantiated \ntype {(.3,\u00df)} (.\u00df .bool\u00df -----. bool{.1 ,.2 }){.4 } {(.6,{.4 }),(.3,{.5 })} - -----------. bool{.1,.2 \n}. As a .nal example of the use of annotation and effect operators, consider the higher-order abstraction \n(cf. the running example from Section 2) (.f : bool . bool. (if (f false.1 ).2 then (f true.3 ).4 else \nfalse.5 ).6 ).7 and its fully .exible annotated type d0 \u00df .\u00dff ..d0..\u00df0.(.\u00df .bool\u00df --. bool(\u00df0 \u00df))\u00dff {(.2 \n,\u00dff )}.d0 {.1 }.{(.6,\u00df0 {.1 })}.{(.4,\u00dff )}.d0 {.3 }- -------------------------------. bool(\u00df0 {.3 }.{.5 \n}), and how this type can be instantiated with the analysis for the Boolean identity function produced \nby (.x : bool.x).8 to yield the desired polyvariant {}{(.2,.8 ),(.6,.1),(.4,.8)} (.\u00df . bool\u00df -. bool\u00df \n) - ------------. bool{.3 ,.5 }.  4.3 Polymorphic Recursion Being able to associate polymorphic annotated \ntypes with lambda\u00adbound variables naturally induces polymorphic recursion (Mycroft 1984) for .xed points. \nIndeed, as recursive functions are con\u00adstructed as .xed points .x t1 of terms t1 with higher-order types \n(t1 . t2) . t1 . t2 and higher-ranked polymorphism allows for arguments to such t1 to have polymorphic \nannotated types of the . form .\u00df .t.1\u00df -. t.2. , it follows that recursive calls, i.e., uses of its argument \nby t1, may be analysed polyvariantly rather than mono\u00advariantly. As expected, higher-ranked polymorphism \ngives you polymor\u00adphic recursion for free. 5. Flow Analysis with Higher-ranked Types In this section, \nwe present the details of our type and effect system for .ow analysis with higher-ranked polymorphic \ntypes. 5.1 Annotations and Effects We assume to have at our disposal countable in.nite sets of annota\u00adtion \nvariables (ranged over by \u00df ) and effect variables (ranged over by d ): \u00df . AnnVar annotation variables \nd . EffVar effect variables. Annotations and effects are then given by . . Ann annotations . . Eff effects \nwith . ::= \u00df | {} | {.}| .\u00df :: s..1 | .1 .2 | .1 . .2 . ::= d | {} | {(.,.)}| .\u00df :: s..1 | .1 . | .d \n:: s..1 | .1 .2 | .1 . .2. Note that annotations . may contain annotation abstractions .\u00df :: s..1 and \nannotation applications .1 .2, while effects may contain annotation abstractions .\u00df :: s. .1 and annotation \napplications .1 . as well as effect abstractions .d :: s..1 and effect applications .1 .2. Furthermore, \nnote that abstractions over annotations and effects make mention of sorts s, s . Sort sorts. That is, \nto make sure that abstractions and applications in annota\u00adtions and effects are used in meaningful ways \nonly, we depend on sorts to act as the types of annotations and effects. Sorts are then constructed from \ns ::= ann | eff | s1 . s2, where ann denotes the sort of proper annotations, eff the sort of proper effects, \nand s1 . s2 the sort of operators that take annota\u00adtions or effects of sort s1 to annotations or effects \nof sort s2. Storing the sorts of free annotation and effect variables in a sort environ\u00adment S, S . SortEnv \n=(AnnVar . EffVar) ..n Sort sort env., which maps from annotation and effect variables to sorts, rules \nfor assigning sorts to annotations and effects can be given as in Figure 3. In Figure 4, we have a collection \nof rules for de.nitional equiv\u00adalence relations between annotations and effects. These rules allow us, \nwhen necessary, to treat the .-constructor that appears in anno\u00adtations and effects as a commutative, \nassociative, and idempotent operation with {} as unit, and to consider annotations and effects as equal \nup to beta-equivalence and distribution of union over .ow construction.  5.2 Type and Effect System \nThe actual type and effect system is de.ned in terms of rules for deriving judgements of the form  Annotation \nsorting S . . :: s S(\u00df )= s [sa-var][sa-nil] S . \u00df :: s S .{} :: ann [sa-sing] S .{.} :: ann S[\u00df .. s1 \n] . .1 :: s2 [sa-abs] S . .\u00df :: s1..1 :: s1 . s2 S . .1 :: s2 . s S . .2 :: s2 [sa-app] S . .1 .2 :: \ns S . .1 :: ann S . .2 :: ann [sa-union] S . .1 . .2 :: ann Effect sorting S . . :: s S(d )= s [se-var][se-nil] \nS . d :: s S .{} :: eff S . . :: ann [se-sing] S .{(.,.)} :: eff S[\u00df .. s1 ] . .1 :: s2 [se-abs-ann] \nS . .\u00df :: s1..1 :: s1 . s2 S . .1 :: s2 . s S . . :: s2 [se-app-ann] S . .1 . :: s S[d .. s1 ] . .1 :: \ns2 [se-abs-eff ] S . .d :: s1. .1 :: s1 . s2 S . .1 :: s2 . s S . .2 :: s2 [se-app-eff ] S . .1 .2 :: \ns S . .1 :: eff S . .2 :: eff [se-union] S . .1 . .2 :: eff Figure 3. Sorting for annotations and effects. \nS | G.. t : t.. &#38; ., expressing that in the sort environment S and the annotated type environment \nG., the term t can be assigned the annotated type t.as well as the annotation . and the effect .. Annotated \ntypes are given by t.. Ty annotated types with . .1 .2 t.::= bool | t.1-. t.2|.\u00df :: s.t.1 |.d :: s.t.1. \nTypes are considered equal up to alpha-renaming. We require the argument and result annotations .1 and \n.2 and the latent effect . . .1 .2 in an annotated function type t.1-.t.2to be proper annotations and \neffects; this requirement is captured by the rules for type well\u00adformedness, listed in Figure 5. We write \n.t.. for the underlying type that is obtained by removing all annotations and effects from the annotated \ntype t.. If .t.. = t, we say that t.is a completion of t. Annotated type environments G.map variables \nto pairs (t.,.) consisting of an annotated type t.and an annotation .: G.. .= Ty \u00d7 Ann) annotated type \nenv. TyEnv Var ..n (. We write .G.. for the underlying type environment that is obtained by removing \nall annotations and effects from the annotated type environment G.. The rules for .ow typing are given \nin Figure 6. The rule [f\u00advar] expresses that the annotated type t.and the annotation . for a . = .. Annotation \nequivalence . = ... ... = .. ..= . [qa-re.][qa-symm][qa-trans] . = .. = .. . = .. .1 = .. .1 = .. .2 \n= .. 1 12 [qa-abs][qa-app] .\u00df :: s. .1 = .\u00df :: s... .1 .2 = .1 . .. 12 .1 = .1 . .2 = .2 . [qa-union] \n.1 . .2 = .1 .. .. 2 [qa-beta] (.\u00df..11) .2 = [\u00df .. .2 ].11 [qa-unit][qa-idem] . = . .{} . = . . . [qa-comm] \n.1 . .2 = .2 . .1 [qa-ass] .1 . (.2 . .3) = (.1 . .2) . .3 . = .. Effect equivalence . = ... ... = .. \n..= . [qe-re.][qe-symm][qe-trans] . = .. = .. . = .. . = .. [qe-sing] {(., .)}={(.,..)} .1 = .1 . .1 \n= .1 . . = .. [qe-abs-ann][qe-app-ann] .\u00df :: s..1 = .\u00df... .1 . = .1 . .. 1 .1 = .. 1 [qe-abs-eff ] .d \n:: s..1 = .d :: s..1 . .1 = .1 . .2 = .2 . [qe-app-eff ] .1 .2 = .1 . .. 2 .1 = .1 . .2 = .2 . [qe-union] \n.1 . .2 = .1 .. .. 2 [qe-beta-ann] (.\u00df..11) . = [\u00df .. . ].11 [qe-beta-eff ] (.d ..11) .2 = [d .. .2 ].11 \n[qe-unit][qe-idem] . = . .{} . = . . . [qe-comm] .1 . .2 = .2 . .1 [qe-ass] .1 . (.2 . .3) = (.1 . .2) \n. .3 [qe-dist] {(., .1) .{(., .2)}={(.,.1 . .2)} Figure 4. De.nitional equivalence for annotations and \neffects. Well-formedness S . t.wft [w-bool] S . bool wft S . . :: eff S . t.1 wft S . .1 :: ann S . t.2 \nwft S . .2 :: ann . [w-arr]S . t.1.1 -. t.2.2 wft S[\u00df .. s] . t.1 wft S[d .. s] . t.1 wft [w-forall-ann][w-forall-eff \n] S ..\u00df :: s.t.1 wft S ..d :: s.t.1 wft Figure 5. Type well-formedness.  S | G.. t : t.. &#38; . Flow \nanalysis G.(x)=(t.,.) [f-var][f-false][f-true] S | G.. x : t.. &#38; {} S | G.. false. : bool{.} &#38; \n{} S | G.. true. : bool{.} &#38; {} S . t.1 wft S . .1 :: ann S | G.[x .. (t.1,.1)] . t1: t.2.2&#38; \n.0 [f-abs] .0.1 S | G.. (.x : .t.1..t1). : (t.1-. t.2.2 ){.} &#38; {} S | G.. t1: bool.1&#38; .1 S \n| G.. t2: t.. &#38; .2 S | G.. t3: t.. &#38; .3 [f-if ] S | G.. (if t1 then t2 else t3). : t.. &#38; \n.1 .{(.,.1)}. .2 . .3 .2 .0t. .0 S | G.. t1: (t.2-. t.. ).1&#38; .1 S | G.. t2: t.2.2&#38; .2 S | G.. \nt1: (.-. t.. ).1&#38; .1 [f-app][f-.x] S | G.. (t1 t2). : t.. &#38; .1 . .2 .{(.,.1)}. .0 S | G.. (.x \nt1). : t.. &#38; .1 .{(.,.1)}. .0 S[\u00df .. s] | G.. t : t.1. &#38; . S | G.. t : (.\u00df :: s. t.1). &#38; \n. S . .0 :: s [f-gen-ann][f-inst-ann] S | G.. t : (.\u00df :: s. t.1). &#38; . S | G.. t : ([\u00df .. .0 ]t.1). \n&#38; . S[d .. s] | G.. t : t.1. &#38; . S | G.. t : (.d :: s.t.1). &#38; . S . .0 :: s [f-gen-eff ][f-inst-eff \n] S | G.. t : (.d :: s.t.1). &#38; . S | G.. t : ([d .. .0 ]t.1). &#38; . Subtyping S | .G . t : .t.. \n&#38; .. S | .G . t : .t..1 &#38; .1 . = .. S . . :: ann . = .. S . . :: eff .t. . .t S . .t wft S . \n.2 :: ann S . .2 :: eff S | .G . t : .t. &#38; . [f-eq] S | .G . t : .t(.1..2) &#38; (.1 . .2) [f-sub] \n t.. t.. ..= . . ... 1 . ... 2 = .2 . ... t.. .1 = .. .t. .. 1 . t.11 t2 . .22 [s-re.][s-arr] t. ... \n.. .. t.. ..1 t.1-. t.2.2 . t.1 . 1 -. t.2 . 2 t.1 . t.1 . t.1 . t.1 . [s-forall-ann][s-forall-eff ] \n.\u00df :: s.t.1 . .\u00df :: s.t.1 ..d :: s.t.1 . .d :: s. t.1 . Figure 6. Type and effect system for .ow analysis. \nvariable x are to be retrieved from the annotated type environment G. In the call-by-value semantics \nof our language, the evaluation of a variable does not result in .ow; hence, the effect component in \nthe conclusion of rule [f-var] stays empty. For the Boolean producers false. and true. we have axioms \n[f-false] and [f-true] that assign the annotated type bool and a singleton annotation {.} that re.ects \nthe production site .. Producers are already fully evaluated and so no effect is recorded. Lambda-abstractions \n(.x : t.t1). are dealt with by the rule [f\u00adabs]. It states that the body t1 of the abstraction is to \nbe analysed in an extended annotated type environment that maps the formal parameter x to the pair (t.1,.1), \nwhere .1 is a proper annotation and t.1 a possibly polymorphic completion of t that is well-formed with \nrespect to the sorting environment S. While t.1 and .1 are then used as the argument type and annotation \nfor the abstraction, the annotated type t.2 and the annotation .2, obtained from the analysis of the \nbody, both end up in result position; the effect .0 of t1 constitutes the latent effect. The annotation \nand effect for the abstraction as a whole are taken to be {.} and {}, respectively. The rule for conditionals \n(if t1 then t2 else t3).,[f-if ], requires the condition t1 to be of Boolean type and the branches t2 \nand t3 to agree on their annotated types and annotations, which will then be used as the annotated type \nand annotation for the conditional itself. The effect for the conditional is constructed by taking the \nunion over the effects of the three subterms and recording that the Boolean values that may .ow to the \ncondition t1 are possibly consumed at the site labelled with .. In the rule [f-app] for applications \n(t1 t2)., the annotated type t.2 and the annotation .2 of the argument term t2 are to match with the \nargument type and annotation of the function term t1. The annotated type t.and annotation . are then \nretrieved from the result positions in the type of t1. The effect for the application subsumes the effects \nfor its subterms t1 and t2 as well as the possible .ow from the function labels .1 to the application \nsite . and the latent effect .0 of t1. For the .xed point (.x t1). of a term t1, the annotated type t.. \nis retrieved from the type of t1, which is required to be of .0 the form t. -. t. . The effect component \nis then constructed by combining the effect .1 of t1, the singleton effect {(.,.1)} with .1 the annotation \nof t1, and the latent effect .0 of t1. The rules [f-gen-ann] and [f-inst-ann] form a pair of introduc\u00adtion \nand elimination rules for annotation polymorphism. Quanti.\u00adcation over an s-sorted annotation is allowed, \nif the correspond\u00ading binding in the sort environment admits a valid analysis. Instan\u00adtiation requires \nan annotation of appropriate sort to be supplied. Rules [f-gen-eff ] and [f-inst-eff ] are analogue rules \nfor effect poly\u00admorphism. The rule [f-eq] expresses that annotations and effects at top level can always \nbe safely replaced by well-sorted de.nitional equivalents. The rule [f-sub], .nally, is a combined rule \nfor subtyping and subeffecting (Tang and Jouvelot 1995) that allows for overapprox\u00adimation of annotations \nand effects. This rule is typically used im\u00admediately before the rule [f-if ] in order to have the branches \nof a conditional agree on their types and annotations. The rules for sub\u00adtyping are given in the lower \npart of Figure 6. 6. Properties Let us now brie.y review the most important metatheoretical prop\u00aderties \nof our type and effect system.  6.1 Applicability Our .ow analysis is a conservative extension of the \nunderlying type system from Section 3 in the sense that every program typeable in the underlying system \ncan be successfully subjected to the analysis. Furthermore, both systems agree on the shape of types \nassignable. Theorem 1 (Conservative extension). 1. If G . t : t, then there exist G., t., ., and . with \n.G.. = G and .t.. = t, such that [] | G . t : t.. &#38; .. 2. If S | G.. t : t.. &#38; ., then .G... \nt : .t... .  6.2 Semantic Correctness To establish the correctness of the analysis with respect to \nthe in\u00adstrumented natural semantics from Section 3, we consider interpre\u00adtations .\u00b7. of annotations . \nas sets of labels, .{}. = {} ..1 . .2. = ..1. . ..2., and of effects . as .ows, .{}. = {} .{.,. }. = \n{(.,..) | ... ...} ..1 . .2. = ..1. . ..2.. Both interpretations are partial in the sense that they \ndo not account for abstractions, applications, and free variables in annotations and effects. Hence, \nwe only consider closed environments and observe that the type and effect system guarantees all top-level \nannotations and effects to be proper annotations and effects. Lemma 2. If [] | [] . t : t.. &#38; ., \nthen [] . t.wft, [] . . :: ann, and [] . . :: eff. . As proper annotations and effects are always de.nitionally \nequiv\u00adalent to forms without abstractions and applications, we can now formulate the following result. \nTheorem 3 (Semantic soundness). If [] | [] . t : t.. &#38; . and t .F p., then there exist .. and .. \nwith . = .. and . = .., such that . . .... and F . ..... .  6.3 Existence of Best Analyses While Theorem \n1 establishes that all well-typed programs can be analysed, we now wish to state that each analysable \nprogram admits an analysis that is in some sense better than all other analyses for that program. As \nwe are interested in analyses that guarantee modularity, we shall restrict ourselves to analyses that \nprovide fully .exible types. To this end, let . range over both annotation and effect vari\u00adables, together \nreferred to as .ow variables, . . AnnVar . EffVar .ow variables, and let us use overbar notation to denote \nsequences, where we feel free to downcast sequences of .ow variables to sets of .ow variables. We write \ne for the empty sequence, ffv(t.) and ffv(G.) for the set of free, i.e., unbound, .ow variables in, respectively, \nan annotated type t.and an annotated type environment G., and annvars(.i) for the subsequence of annotation \nvariables contained in .i. Then, fully .exible types are de.ned as follows. De.nition 1. An annotated \ntype t.is fully parametric if 1. t.= bool, or d0 .i\u00df 2. t.=(..i :: si.t.1--. t.2(\u00df0\u00dfi. )) for some d0 \nand \u00df0 with (a) t.1 and t.2 fully parametric, (b) .i = {\u00df }. ffv(t.1), and (c) \u00dfi. = annvars(.i). . De.nition \n2. An annotated type t.is fully .exible if 1. t.= bool, or t1\u00df .t2  2. t.=(..i :: si. .-. ..2) for some \n. and .2 with (a) t.1 fully parametric, (b) t.2 fully .exible, and (c) .i = {\u00df }.ffv(t.1). .  Note that \nfull parametricity implies full .exibility and how higher\u00adorder function types give rise to higher-ranked \npolymorphism and higher-order operators over annotations and effects. Full .exibility extends naturally \nto closed type environments. De.nition 3. An annotated type environment G.is fully .exible if ffv(G.)= \n{} and if, for all x, t., and . with G.(x)=(t.,.), we have that t.is fully .exible. . Now, in a fully \n.exible environment, each analysable term ad\u00admits a fully .exible type. Lemma 4. If [] | G.. t : t.... \n&#38; .. with G.fully .exible, then there exist t., ., and . such that t.is fully .exible and G.. t : \nt.. &#38; .. . Amongst all possible analyses for a given term in a given en\u00advironment, we are interested \nin a fully .exible analysis that makes the most accurate prediction about production sites and .ow, i.e., \nthe analysis that results in the smallest types, annotations, and effects. As all fully .exible types \nfor a term agree on their negative positions, the notion of a best analysis can be straightforwardly \nex\u00adpressed in terms of subtyping and de.nitional equivalence. De.nition 4. The triple (t., .,.) consisting \nof a fully .exible annotated type t., an annotation ., and an effect . constitutes a best analysis for \nt in G., if [] | G.. t : t.. &#38; . and if, for all t.. , .. , and .. with [] | G.. t : t.... &#38; \n.. and t.. fully .exible, we have that t.. t.. , ..= . . ..., and ..= . . ... for some ... and ... . \n. Theorem 5 (Existence of best analyses). If [] | G.. t : t.... &#38; .. with t.. fully .exible, then \nthere exist t., ., and ., such that (t.,.,.) is a best analysis for t in G.. . 7. Algorithm In this section, \nwe present an inference algorithm for obtaining best analyses. The algorithm naturally breaks up in two \nparts: a recon\u00adstruction algorithm R that produces annotated types, annotations, and effects for terms \nas well as constraints between .ow variables (Section 7.1), and a procedure S for solving the constraints \npro\u00adduced by R (Section 7.2). A crucial aspect of the algorithm is that the constraints that are generated \nfor the body of a lambda-abstraction are solved locally, allowing for annotations and effects to be generalised \nover at the binding-sites of formal parameters. 7.1 Flow Reconstruction The algorithm R for reconstructing \ntypes, annotations, and effects is given in Figure 7. It takes as input a pair (G.,t) consisting of an \nan\u00adnotated type environment G.and a term t and produces a quadruple (t.,\u00df ,d ,C) consisting of an annotated \ntype t., an annotation vari\u00adable \u00df , an effect variable d , and a .nite set C of constraints over \u00df and \nd as well as any intermediate .ow variables. Constraints are given by q . Constraint constraints C . \nF(Constraint) constraint sets, where q ::= . . \u00df | . . d . That is, a constraint expresses either the \ninclusion of an annotation . in the annotation represented by the annotation variable \u00df or  R(G., x)= \nlet (t., .)= G.(x) \u00df,d be fresh in (t., \u00df,d,{. . \u00df }) R(G., false.)= let \u00df,d be fresh in (bool,\u00df, d ,{{.}. \n\u00df }) R(G., true.)= let \u00df,d be fresh in (bool,\u00df ,d,{{.}. \u00df }) R(G., (.x : t1.t1).)= let (t.1, .i :: si)= \nC(t1, e) \u00df1 be fresh (t.2, \u00df2,d0,C1)= R(G.[x .. (t.1, \u00df1)],t1) X = {\u00df1 }.{.i }. ffv(G.) (.2,.0)= S(C1, \nX,\u00df2, d0) .0 \u00df1 .2 t.= .\u00df1 :: ann...i :: si.t.1-. t.2 \u00df ,d be fresh in (t.,\u00df, d ,{{.}. \u00df }) R(G., (if \nt1 then t2 else t3).)= let (bool, \u00df1,d1,C1)= R(G.,t1) (t.2, \u00df2,d2,C2)= R(G.,t2) (t.3, \u00df3,d3,C3)= R(G.,t3) \nt.= J(t.2,t.3) \u00df ,d be fresh C = {d1 . d }.{{(.,\u00df1)}. d }.{d2 . d }.{d3 . d }. {\u00df2 . \u00df }.{\u00df3 . \u00df }.C1 \n.C2 .C3 in (t.,\u00df, d ,C) R(G., (t1 t2).)= let (t.1, \u00df1,d1,C1)= R(G.,t1) (t.2, \u00df2,d2,C2)= R(G.,t2) .. t. \n\u00df. 0t... .22 -. .= I(t.1) . =[\u00df2 . .. \u00df2 ] . M([ ],t.2,t.2. ) \u00df ,d be fresh C = {d1 . d }.{d2 . d }.{{(., \n\u00df1)}. d }.{..0 .. d }. {.... \u00df }.C1 .C2 in (.t.. ,\u00df, d,C) R(G., (.x t1).)= let (t.1, \u00df1,d1,C1)= R(G.,t1) \n.. 0t..... t..\u00df. -. .= I(t.1) t.. t.) .1 = M([ ], ., . .2 =[\u00df. .. .1 ... ] \u00df ,d be fresh C = {d1 . d \n}.{{(.,\u00df1)}. d }.{.2 (.1 .0. ) . d }. {.2 (.1 ...) . \u00df }.C1 in (.2 (.1 t..),\u00df,d,C) Figure 7. Reconstruction \nalgorithm. the inclusion of an effect . in the effect represented by the effect variable d . We carefully \nmaintain the invariant that all annotated types produced are fully .exible. Turning to the details of \nthe algorithm, the cases for variables and Boolean constants false. and true. are straightforward: we \ngenerate fresh annotation and effect variables and propagate the relevant information from either the \ntype environment G.or the producer label . to the result tuple. More interesting is the case for lambda-abstractions \n(.x : t1.t1). . Here, we .rst make a call to the subsidiary procedure C, given in Figure 8, that produces \na pair (t.1, .i :: si) consisting of a fully parametric (cf. De.nition 1) completion t.1 of t1 and a \nC(bool, .i :: si)=(bool, {}) C(t1 . t2, .i :: si)= let (t.1, .j :: sj)= C(t1, e) \u00df1 be fresh (t.2, .k \n:: sk)= C(t2, (.i :: si,\u00df1 :: ann, .j :: sj)) \u00dfi. :: si. = annvars(.i :: si) \u00dfj. :: sj. = annvars(.j \n:: sj) \u00df0,d0 be fresh d0 .i\u00df1 .j \u00df1 (\u00df0\u00dfi. \u00df1 \u00dfj. ) in (.\u00df1 :: ann...j :: sj . t.1-----. t.2, (d0 :: \nsi . ann . sj . eff,\u00df0 :: si.. ann . sj.. ann, .k :: sk)) Figure 8. Completion algorithm. J(bool,bool)= \nbool .1.2.1..2 J(t.1\u00df1 -. t.12.12 ,t.1\u00df1 -. t.22.22 )= t.1\u00df1 - --. J(t.12,t.22)(.12..22) J(.\u00df :: s.t.11,.\u00df \n:: s.t.21)= .\u00df :: s.J(t.11,t.21) J(.d :: s.t.11,.d :: s.t.21)= .d :: s.J(t.11,t.21) J(t.1,t.2)= fail \nin all other cases Figure 9. Join algorithm. sequence .i :: si that contains the free .ow variables \nof t.1 accom\u00adpanied by their sorts. Then we create a mapping from the formal parameter x to the pair \n(t.1,\u00df1), where \u00df1 is a fresh annotation variable, and use it in a recursive invocation of R for the \nbody t1 of the abstraction. This recursive invocation results in a tuple (t.2,\u00df2,d0,C1). The constraints \nin C1 are then solved with respect to a .nite set of active .ow variables X (see Section 7.2), X . F(AnnVar \n. EffVar) .ow-variable sets, to yield a least solution (.2,.0) for the .ow variables \u00df2 and d0. An annotated \ntype for the abstraction is then formed by quantifying over the argument annotation variable \u00df1 and the \nfree .ow variables .i of the argument type t.1; choosing t.1 and \u00df1 as argument type and annotation; \nchoosing t.2 and .2 as result type and annotation; and, choosing .0 as latent effect. For the annotation \nand effect of the abstraction as a whole, we pick fresh variables \u00df and d and record that . is to be \nincluded in a solution for \u00df . For conditionals (if t1 then t2 else t3). we make recursive calls to \nR for all three subterms. The thus obtained constraint sets C1, C2, and C3 are then combined with the \nconstraints that account for the .ow that is involved with evaluating a conditional to form the constraint \nset C for the conditional as a whole. The annotated type t.for the conditional is obtained by taking \nthe least upper bound of the recursively obtained types t.2 and t.3 with respect to the subtyping relation \nof Figure 6. This least upper bound is computed by the join algorithm J in Figure 9. Note how J makes \nessential use of the invariant that all types are fully .exible (and that the types to join thus agree \nin their argument positions) as well as the fact that types are to be considered equal up to alpha-renaming \n(in the cases for quanti.ed types). In the case for applications (t1 t2)., we make recursive calls to \nR for the function term t1 and the argument term t2. The thus obtained annotated type for t.1 for t1, \nfor which our invariant guarantees that it is fully .exible, is then instantiated by means of a call \nto the auxiliary procedure I (Figure 10), from which we retrieve the  I(.\u00df :: s. t.1)= let \u00df . be fresh \nin [\u00df .. \u00df . ](I(t.1)) I(.d :: s.t.1)= let d. be fresh in [d .. d. ](I(t.1)) I(t.)= t.in all other cases \nFigure 10. Instantiation algorithm. M(S,bool,bool)= id .d0 .i M(S,t.1\u00df1 -. t.2.2 ,t.1\u00df1 --. t.2 . \u00df0 \n\u00dfj )= [d0 .. (..i :: S(.i). .)] . [\u00df0 .. (.\u00dfj :: S(\u00dfj). .2)] . M(S,t.2,t.2. ) M(S,.\u00df :: s. t.1, .\u00df :: \ns,t.1. )= M(S[\u00df .. s], t.1, t.2) M(S,.d :: s.t.1,.d :: s,t.1. )= M(S[d .. s], t.1, t.2) M(S,t., t..)= \nfail in all other cases Figure 11. Matching algorithm. t. \u00df2. . Against these we then match the actual \nargument type t.2 and the actual argument annotation \u00df2, resulting in a substitution ., fully parametric \nparameter type .2 and the parameter annotation . . Subst substitutions. For the matching of t.2 against \nt.2 . we rely on a subsidiary procedure M, given in Figure 11. The substitution . is used to determine \nthe annotated type of the application as a whole from the result type t.. from t1. For the annotation \nand the effect of the application, we generate fresh variables \u00df and d and in the constraint set C we \ninclude constraints obtained for t1 and t2 as well as the constraints that are obtained by considering \nthe .ow incurred by the application. Finally, the case for .xed points (.x t1). is similar to the case \nfor applications with the most important difference that a substi\u00adtution is constructed in two steps \nhere. First, a substitution .1 is constructed by matching the result type of t1 against its fully para\u00admetric \nparameter type. Then, the recursive knot is tied by sub\u00adstituting the result annotation for the annotation \nvariable \u00df . that constitutes the parameter annotation.  7.2 Constraint Solving For solving the constraints \nproduced by the reconstruction algo\u00adrithm R, we rely on a standard worklist algorithm. This algorithm, \nS, is given in Figure 12. As inputs it takes a constraint set C, a set of active .ow variables X that \nare to be considered as constants dur\u00ading solving, an annotation variable \u00df , and an effect variable \nd . As outputs it produces least solutions . and . for \u00df and d under C. During solving there is no need \nfor explicitly distinguishing between annotation constraints and effect constaints. Therefore we take \n. . Ann . Eff .ow terms and write all constraints as . . .. The algorithm maintains a .nite set worklist \nfor keeping track of constraints that are still to be considered. Furthermore, it uses a .nite map analysis \nfrom .ow variables to .ow terms, in which intermediate solutions for \u00df , d , and the .ow variables in \nX and the right-hand sides of C are kept; and a .nite map dependencies that stores, for each .ow variable \n., which constraints need to be reconsidered if the solution for . is updated. S(C, X,\u00df, d)= do (* initialisation \n*) worklist := {} analysis :=[] dependencies :=[] for all (. . .) in C do worklist := worklist .{. . \n. }analysis := analysis[. .. {}] for all . . in ffv(.) do dependencies := dependencies[.. ..{}] for all \n(. . .) in C do for all . . in ffv(.) do dependencies := dependencies[. . .. dependencies(..) .{. . \n. }] for all . in X do analysis := analysis[. .. . ] analysis := analysis[\u00df .. {}][d .. {}] (* iteration \n*) while worklist . = {} do let C1 {. . . } = worklist in do worklist :=C1 if (analysis .) .. analysis(.) \nthen do analysis := analysis[. .. analysis(.) . (analysis . )] for all q in dependencies[. ] do worklist \n:= worklist .{q} (* .nalisation *) return (analysis(\u00df),analysis(d )) Figure 12. Worklist algorithm for \nconstraint solving. After intialisation of the worklist set and the .nite maps, the algorithm proceeds \nby considering constraints from the worklist as long as these are available. In each iteration a constraint \nis selected and tested for satisfaction. Here, we use the .nite map analysis as a substitution and write \nanalysis . for the interpretation of the .ow term . under the subsitution provided by analysis. If a \nconstraint is found unsatis.ed, we update the solution for its right-hand-side .ow variable . and add \nall dependent constraints to the worklist. If the worklist is empty, the algorithm produces a pair consisting \nof the solutions for the .ow variables \u00df and d . These are then guaranteed to consist of .ow terms that, \nbesides from applications and abstractions, are exclusively constructed from concrete labels and the \n.ow variables from X.  7.3 Syntactic Correctness A trivial observation about the completion algorithm \nfrom Figure 8 with respect to the de.ntions from Section 6 is the following: Lemma 6. For all types t, \nthere is a fully parametric t., such that C(t,e)= t.. . Now, the correctness of both the reconstruction \nalgorithm from Figure 7 and the worklist algorithm from Figure 12 with respect to the type and effect \nsystem from Section 5 comes in two parts. First, we have that each analysis produced by the algorithm \nis indeed admitted by the .ow-typing rules of Figure 6. Theorem 7 (Syntactic soundness). If we have that \nR(G.,t)= (t.,\u00df ,d ,C) and S(C,{},\u00df , d )=(.,.) for a fully .exible G., then [] | G.. t : t.. &#38; .. \n. Second, we have that the algorithm produces best analyses for all analysable terms. This result depends \ncrucially on the invariant maintainind by the reconstruction algorithm, i.e., that R always produces \nfully .exible types. In particular, we have that the join algorithm from Figure 9 will not fail if it \ninvoked with two fully .exible completions of a single underlying type.  Lemma 8. If t.1 and t.2 are \nfully .exible with .t.1. = .t.2. = t for some t, then J(t.1,t.2)= t.with .t.. = t. . Similarly, the matching \nalgorithm from Figure 11 is guaranteed to succeed when invoked with one fully .exible and one fully parametric \ncompletion of the same underlying type: Lemma 9. If t.is fully .exible and t.. fully parametric with \n.t.. = .t..., then M([ ],t.,t..)= . with .t..= t.. . Theorem 10 (Syntactic completeness). If [] | G.. \nt : t.... &#38; .. with G.fully .exible, then there are t., \u00df , d , C, ., and . with R(G.,t)=(t.,\u00df , \nd ,C) and S(C,{},\u00df ,d )=(.,.) and (t.,., .) a best analysis for t in G.. . 8. Related Work Early approaches \nto .ow analysis for higher-order languages, e.g., the closure analysis of Sestoft (1991) and the set-based \nanalysis of Heintze (1994), were monovariant, allowing only a single, context\u00adinsensitive analysis result \nto be associated with each of a program s functions. Later work resulted in polyvariant analyses that \nallow for the analysis results associated with at least some identi.ers in a program to be context-sensitive; \nexamples include Shivers k-CFA (1991) and Nielson and Nielson s in.nitary analysis (1997). Polymorphic \ntype and effect systems for .ow analysis, such as F\u00a8 ahndrich s (2008), typically restrict polyvariant \nanalysis results to be associated with let-bound identi.ers only, leaving function parameters to be analysed \nmonovariantly. Exceptions are the ap\u00adproaches of Fax\u00b4 en (1997) and Smith and Wang (2000), who also present \npolymorphic type and effect systems for .ow analysis that allow for function parameters to be analysed \npolyvariantly rather than monovariantly. The most important difference between our approach and both \nthe approach of Fax\u00b4en and that of Smith and Wang is that, while we propose a single analysis, Fax\u00b4en \nand Smith and Wang investigate families of constraint systems parameterised over inference strategies; \nthe choices of strategies that lead to de\u00adcidable analyses in their systems are rather ad hoc. Furthermore, \nthe look-and-feel of the systems of Fax\u00b4en and Smith and Wang differs signi.cantly from ours, as we are, \nto the best of our knowledge, the .rst to consider the use of .rst-class operators on effects and anno\u00adtations. \nGustavsson and Svenningsson (2001) propose constrained type schemes that show a super.cial similarity \nto ours, but do not allow quanti.cation over effect operators; moreover, they do not al\u00adlow type schemes \nto be associated with lambda-bound identi.ers. An important class of type-based .ow analyses makes use \nof intersection types rather than polymorphic types. In general, inter\u00adsection types allow for more .ne-grained \nanalysis results than poly\u00admorphic types (Wells et al. 2002). Kfoury and Wells (1999) show that inference \nis decidable if analyses are restricted to intersection types of .nite rank. Their inference algorithm \nmakes essential use of so-called expansion variables and is arguably much more com\u00adplicated than the \none we give for our analysis in Section 7. Banerjee and Jensen (2003) demonstrate that the restriction \nto rank-2 inter\u00adsection types allows for a simpler algorithm, but only at the expense of decreased precision, \nwhile Mossin (2003) proceeds in the oppo\u00adsite direction and shows that exact .ow analyses can be obtained \nat the expense of a nonelementary recursive inference problem. A major advantage of the use of intersection \ntypes is that they admit principal typings rather than mere principal types (Jim 1996). As type systems \nwith principal typings allow for terms to be typed independently from the types of their free variables, \nanalyses based on intersection typing are even more modular than systems with just principal types. Our \ntype and effect system does not ad\u00admit principal typings, but, interestingly, in practice, the same level \nof modularity can be achieved as for systems with intersection types. That is, if, for a given term, \nthe underlying types of its free variables are given, rather than their annotated types, an analy\u00adsis \ncan be computed for which the best analysis for that term in any given annotated type environment is \na substitution instance. More precisely, if for a given term t, we are given an underlying type environment \nG, such that G . t : t for some type t, then S, G, t., ., and . can be computed, such that S | G.. t \n: t.. &#38; . with .G.. = G and .t.. = t, and, moreover, for each fully .exible G.. with .G... = G, there \nis a computable substitution . mapping annota\u00ad tion variables to annotations and effect variables to \neffects, such that (.t., .., ..) is a best analysis for t in G... The idea is to .rst tentatively guess \na fully parametric completion of the given un\u00adderlying type environment and then, as .ow inference proceeds, \nto gradually adapt this completion by growing a substitution on .ow variables. Then, effectively, our \ntype and effect system admits, in a sense, principal typings, but only as far as annotations and ef\u00adfects \nare concerned. For practical purposes, this suf.ces, because, as real-world higher-order functional languages \nare typically based on the Damas-Milner typing discipline, which itself does not admit principal typings, \nunderlying type environments can be expected to be available for all terms under analysis. The increased \nprecision obtained from the use of polymor\u00adphic recursion in type-based analyses, as realised by Dussart \net al. (1995), is reported on by several authors, including Henglein and Mossin (1994), and Tofte and \nTalpin (1994). To the best of our knowledge, we are the .rst to consider the generalisation to poly\u00admorphic \ntypes for all function arguments rather than for just those of functions from which .xed points are obtained. \n9. Conclusions and Further Work In this paper, we have presented a type and effect system for .ow analysis \nwith higher-ranked polymorphic types and higher\u00adorder effect operators. This system allows us to attain \nprecision beyond what is offered by the ML-style let-polymorphic types that are typically used in polymorphic \neffect systems. The key innovation of our work is the use of fully .exible types, i.e., types that are \nas polymorphic as possible but impose no restrictions on the arguments that can be passed to functions. \nGiven fully .exible types for all free variables, our analysis, which is a conservative extension of \nthe standard Damas-Milner typing discipline, admits best analyses for all programs analysable: such analyses \nare both precise and modular. Our analysis distinguishes between producers and consumers. In the present \npaper we have focused on producers and consumers for Boolean and function values, but our approach applies \nto other data types as well. In particular, although the details are syntac\u00adtically rather heavy, our \nanalysis can be extended to user-de.ned, algebraic data types, as found in modern functional languages \nsuch as Haskell and ML. Accounting for the use of let-polymorphism in the underlying type system is largely \nan orthogonal issue. The .ow analysis presented in this paper is a typical forward analysis: we keep \ntrack of the .ow from producers to consumers. As future work and as part of our research agenda to develop \na reusable framework that can be used to construct precise and modular type and effect systems, much \nlike monotone frameworks (Kam and Ullman 1977) are used to construct data-.ow analyses we aim at formulating \na backward variation of our analysis, in which we keep track, for each production site, at which program \npoints constructed values are consumed. Many static analyses for higher-order languages can, in a type\u00adbased \nformulation, be expressed as variations on .ow analysis. We expect our approach to be of value to these \nanalyses as well and, hence, we plan to de.ne higher-ranked polymorphic type and effect systems for analyses \nsuch as binding-time analysis, strictness analysis, and usage analysis, and to compare the results obtained \nwith those from existing let-polymorphic systems.  If a polyvariant type-based analysis is used to drive \nan optimis\u00ading program transformation, a trade-off arises between the modu\u00adlarity of the analysis and \nthe effectiveness of the transformation. For let-polymorphism, this trade-off may be resolved by differ\u00adentiating \nbetween local and global let-bound identi.ers (Holder\u00admans and Hage 2010). For higher-ranked polymorphism, \na similar measure may be in order, i.e., to obtain more effective transforma\u00adtions, selected lambda-bound \nidenti.ers may have to receive non\u00adfully parametric types. Investigating how the algorithm of Section \n7 can be adapted to such scenarios is a challenging but nevertheless appealing direction for further \nwork. Finally, characterising the difference in expressiveness and the trade-offs in implementation techniques \nbetween our analysis and systems based on intersection types of various ranks promises to be an interesting \ntopic for further research. Acknowledgments This work was supported by the Netherlands Organisation for \nScienti.c Research through its project on Scriptable Compilers (612.063.406) and carried out while the \n.rst author was employed at Utrecht University. The authors would like to thank Arie Mid\u00addelkoop and \nJeroen Weijers for their helpful comments on a draft of this paper, and the anonymous reviewers for their \ninsightful feedback on the submitted version. References Anindya Banerjee and Thomas P. Jensen. Modular \ncontrol-.ow analysis with rank 2 intersection types. Mathemathical Struc\u00adtures in Computer Science, 13(1):87 \n124, 2003. Lu\u00b4is Damas and Robin Milner. Principal type-schemes for func\u00adtional programs. In Conference \nRecord of the Ninth Annual ACM Symposium on Principles of Programming Languages, Al\u00adbuquerque, New Mexico, \nJanuary 1982, pages 207 212. ACM Press, 1982. Dirk Dussart, Fritz Henglein, and Christian Mossin. Polymorphic \nrecursion and subtype quali.cations: Polymorphic binding-time analysis in polynominal time. In Alan Mycroft, \neditor, Static Analysis, Second International Symposium, SAS 95, Glasgow, UK, September 27, 1995, Proceedings, \nvolume 983 of Lecture Notes in Computer Science, pages 118 135. Springer-Verlag, 1995. Manuel F\u00a8 ahndrich \nand Jakob Rehof. Type-based .ow analysis and context-free language reachability. Mathematical Structures \nin Computer Science, 18(5):823 894, 2008. Karl-Filip Fax\u00b4en. Polyvariance, polymorphism and .ow analysis. \nIn Mads Dam, editor, Analysis and Veri.cation of Multiple-Agent Languages, 5th LOMAPS Workshop, Stockholm, \nSweden, June 24 26, 1996, Selected Papers, volume 1192 of Lecture Notes in Computer Science, pages 260 \n278. Springer-Verlag, 1997. J\u00a8orgen Gustavsson and Josef Svenningsson. Constraint abstrac\u00adtions. In Olivier \nDanvy and Andrzej Filinski, editors, Programs as Data Objects, Second Symposium, PADO 2001, Aarhus, Den\u00admark, \nMay 21 23, 2001, Proceedings, volume 2053 of Lec\u00adture Notes in Computer Science, pages 63 83. Springer-Verlag, \n2001. Nevin Heintze. Set-based analysis of ML programs. In Proceedings of the 1994 ACM Conference on \nLISP and Functional Program\u00adming, Orlando, Florida, USA, 27 29 June 1994, pages 306 317. ACM Press, 1994. \nFritz Henglein and Christian Mossin. Polymorphic binding-time analysis. In Donald Sannella, editor, Programming \nLanguages and Systems, ESOP 94, 5th European Symposium on Program\u00adming, Edinburgh, U.K., April 11 13, \n1994, Proceedings, vol\u00adume 788 of Lecture Notes in Computer Science, pages 287 301. Springer-Verlag, \n1994. Stefan Holdermans and Jurriaan Hage. On the r ole of minimal typing derivations in type-driven \nprogram transformation, 2010. To appear in the proceedings of the 10th Workshop on Language Descriptions, \nTools, and Applications (LDTA 2010), Paphos, Cyprus, 27 28 March 2010. Trevor Jim. What are principal \ntypings and what are they good for? In Conference Record of POPL 96: The 23rd ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Language, Papers Presented at the Symposium, St. Petersburg Beach, Florida, \n21 24 January 1996, pages 42 53. ACM Press, 1996. John B. Kam and Jeffrey D. Ullman. Monotone data .ow \nanalysis frameworks. Acta Informaticae, 7:305 317, 1977. Assaf J. Kfoury and Jerzy Tiuryn. Type reconstruction \nin .nite rank fragments of the second-order . -calculus. Information and Computation, 98(2):228 257, \n1992. Assaf J. Kfoury and Joe B. Wells. Principality and decidable type inference for .nte-rank intersection \ntypes. In POPL 99, Proceedings of the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, January 20 22, 1999, San Antonio, TX, pages 161 174. ACM Press, 1999. Christian Mossin. Exact \n.ow analysis. Mathematical Structures in Computer Science, 13(1):125 156, 2003. Alan Mycroft. Polymorphic \ntype schemes and recursive de.ni\u00adtions. In Manfred Paul and Bernard Robinet, editors, Interna\u00adtional \nSymposium on Programming, 6th Colloquium, Toulouse, April 17 19, 1984, Proceedings, volume 167 of Lecture \nNotes in Computer Science, pages 217 228. Springer-Verlag, 1984. Flemming Nielson and Hanne Riis Nielson. \nType and effect sys\u00adtems. In Ernst-R\u00a8udiger Olderog and Bernhard Steffen, editors, Correct System Design, \nRecent Insight and Advances, (to Hans Langmaack on the occasion of his retirement from his professor\u00adship \nat the University of Kiel), volume 1710 of Lecture Notes in Computer Science, pages 114 136. Springer-Verlag, \n1999. Hanne Riis Nielson and Flemming Nielson. In.nitary control .ow analysis: A collecting semantics \nfor closure analysis. In Con\u00adference Record of POPL 97: The 24th ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages, Papers Presented at the Symposium, Paris, France, 15 17 January 1997, pages \n332 345. ACM Press, 1997. Jens Palsberg. Type-based analysis and applications. In Proceed\u00adings of the \n2001 ACM SIGPLAN-SIGSOFT Workshop on Pro\u00adgram Analysis for Software Tools and Engineering, PASTE 01, \nSnowbird, Utah, USA, June 18 19, 2001, pages 20 27. ACM Press, 2001. Peter Sestoft. Analysis and Ef.cient \nImplementation of Functional Languages. PhD thesis, University of Copenhagen, 1991. Olin Shivers. Control-.ow \nAnalysis of Higher-Order Languages. PhD thesis, Carnegie Mellon University, 1991. Scott F. Smith and \nTiejun Wang. Polyvariant .ow analysis with constrained types. In Gert Smolka, editor, Programming Lan\u00adguages \nand Systems, 9th European Symposium on Program\u00adming, ESOP 2000, Held as Part of the European Joint Con\u00adferences \non the Theory and Practice of Software, ETAPS 2000, Berlin, Germany, March 25 April 2, 2000, Proceedings, \nvolume 1782 of Lecture Notes in Computer Sciences, pages 382 396. Springer-Verlag, 2000.  Yan Mei Tang \nand Pierre Jouvelot. Effect systems with subtyp\u00ading. In Proceedings of the ACM SIGPLAN Symposium on Par\u00adtial \nEvaluation and Semantics-Based Program Manipulation, La Jolla, California, USA, June 21 23, 1995, pages \n45 53. ACM Press, 1995. Mads Tofte and Jean-Pierre Talpin. Implementation of the typed call-by-value \n. -calculus using a stack of regions. In Conference Record of POPL 94: 21st ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Languages, Portland, Oregon, January 17 21, 1994, pages 188 201. ACM Press, \n1994. Keith Wansbrough and Simon Peyton Jones. Once upon a poly\u00admorphic type. In POPL 99, Proceedings \nof the 26th ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, January 20 22, 1999, \nSan Antonio, TX, pages 15 28. ACM Press, 1999. Joe B. Wells, Allyn Dimock, Robert Muller, and Franklyn \nA. Tur\u00adbak. A calculus with polymorphic and polyvariant .ow types. Journal of Functional Programming, \n12(3):183 227, 2002.    \n\t\t\t", "proc_id": "1863543", "abstract": "<p>We present a type and effect system for flow analysis that makes essential use of higher-ranked polymorphism. We show that, for higher-order functions, the expressiveness of higher-ranked types enables us to improve on the precision of conventional let-polymorphic analyses. Modularity and decidability of the analysis are guaranteed by making the analysis of each program parametric in the analyses of its inputs; in particular, we have that higher-order functions give rise to higher-order operations on effects. As flow typing is archetypical to a whole class of type and effect systems, our approach can be used to boost the precision of a wide range of type-based program analyses for higher-order languages.</p>", "authors": [{"name": "Stefan Holdermans", "author_profile_id": "81337489874", "affiliation": "Vector Fabrics, Eindhoven, Netherlands", "person_id": "P2338148", "email_address": "", "orcid_id": ""}, {"name": "Jurriaan Hage", "author_profile_id": "81100273210", "affiliation": "Utrecht University, Utrecht, Netherlands", "person_id": "P2338149", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1863543.1863554", "year": "2010", "article_id": "1863554", "conference": "ICFP", "title": "Polyvariant flow analysis with higher-ranked polymorphic types and higher-order effect operators", "url": "http://dl.acm.org/citation.cfm?id=1863554"}