{"article_publication_date": "12-01-1992", "fulltext": "\n Addendum A 92 to the Vancouver, British Columbia, Canada 5-IO October 1992 Proceedings Poster Submission- \n An Object-Oriented Environment for Specification and Concurrent Execution of Genetic Algorithms Report \nby: L. Lemarchand A. Plantec B. Pottier s. zanati Universite de Brentagne Occidentale Abstract Genetic \nalgorithms (GA) mimic natural reproduction to search for complex problem solutions. Their principles \nare shortly explained. A point of interest is the regular and repetitive structure of computation involving \ncommunication, data exchanges, and control phases. Interaction with presentation and analysis tools is \nalso a requirement. This make sense for the definition of a general framework allowing fast building \nof parallel applications in an object-oriented system. A GA workbench is developed using the Smalltalk- \nsystem with parallel machine code generation in mind.  Genetic algorithms principle Genetic algorithms \nhave been used to find optimal solutions to complex problems in various domains such as biology, engineering, \ncomputer science, social science . . . . They are heuristics being used alternatively to simulated annealing, \nhill climbing, or taboo search. In contrast to local search methods, GAS are based on a set of independent \ncomputations controlled by a probabilistic strategy. This is a simulation of natural selection of best \nindividuals inside successive generations. Goldberg s book [ 11 provides an excellent survey of the field. \nFollowing the classical terminology, a solution for a problem under consideration is called an individual. \nThe set of considered individuals is called a population. Each individual has one chromosome string encoding \nits data characteristics. Then, a chromosome is a sequence of alleles representing one quantum of information, \nsuch as bit, digit, letter etc.&#38;is alternative data representation requires coding and decoding in \norder to exchange solutions with the nominal object space. A short example will help to illustrate the \nGA computation process. Suppose we want to find the maximum off (x ) = -x2 + 4x + k on the integer interval \n[0,3 11. We will use an initial random population (PO) of values encoded on a 5 bit binary string chromosome. \nA simple GA computation iterates the following cycle: 1. During the selection, individuals are evaluated \nby the application of a fitness function to their chromosomes. Best individuals give the greatest results. \nThis is simply the computation off(xi), for all Xi in Po. S-10 October 1992 -163-Addendum to the Proceedings \nRepioduction takes care of the proportion of best individuals in the population. Chances of an individual \nto be selected are proportional to the percentage of its fitness value occurrences sum with respect to \nthe sum of all the population fimesses. The result is an equal sized population with a higher percentage \nof good individuals. Crossing-over of individuals consists in mating couples of individuals in order \nto allow a random mixing of their characteristics. GAS expect that such operations can provide the population \nwith improved individuals. The mutation process introduces noise in the progress of the population to \navoid local convergence of the GA. A small percentage of individuals are selected and few changes are \nintroduced on their chromosome alleles. This cycle is repealed until a problem dependent stop condition \nis reached, such as a fixed number of iterations or stability at an extremum value. The example P, population \nwill contain a percentage of a xi value, witif neighboring the expected maximum.  Problems and advantages \nof a parallel implementation The GA characteristics justify their implementation on parallel machines: \nchromosomes and population are expected to be large. Each individual will be represented by a process. \nStep 1 and 4 are pure local computations allowing massive parallelism to take place. Step 3 involves \nfew local communications. Other steps are global control implying synchronization and communication of \nprocesses in order to compute statistics, to detect stop conditions, or to exchange data. On message-passing \nmachines, these tasks are time-consuming and some authors 121 propose to limit control operations to \na small neighborhood. It also remains the possibility to use special system and hardware support for \ncomputing and broadcasting global results [33. This problem is similar to the virtual time synthesis \nfor distributed simulation. Modeling GAS with Smalltalk- Smalltalk-passive objects are animated by sending \nmessages. Classes allow the programmer to define an object as a set of data structures and protocols. \nComputations are embedded into processes that can synchronize using operations on semaphores, or communicate \nusing shared queues. GA model is implemented by basic classes like Chromosome, Population, or GA. Application \nspecific classes inherit from basic classes in order to overload data interpretation. Chromosomes are \nstructured passive data encoding fields of an object. Messages to chromosomes are standard calls requesting \nfitness evaluation, mutation or class conversion. Class Population is a collection of chromosomes. Messages \nto populations sequence the GA cycle: selection, reproduction, crossing-over, mutation, convergence detection. \nApplication specific protocols are located into these classes or their subclasses using class variables \nholding Smalltalk blocks or dynamic method compilations. Search for optimal solutions is executed by \nGA daemons calling a set of standard protocols from previous classes. Currently, sequential or concurrent \nSmalltalk-computations are supported. In the fist case, the GA daemon simply operates on a population. \nIn the second case, animation of an individual is a process evolving with the rest of the population, \nwith respect to synchronization points. Additional classes allow to describe a machine model as a set \nof communicating processes and a network topology. A global GA controller schedules processes. Data are \nexchanged from process to process using shared queues. Conclusion Without the help of a workbench, a \nGA programmer must write a lot of code to bind characteristics together. The task becomes more difficult \nwhen a parallel implementation is considered. The definition of a set of tools to specify and control \nGAS execution must also take account of the experimental part of the problem. The GA workbench has been \nstarted as a student project. Basic classes allow sequential and concurrent execution of simple examples \nwithin the Smalltalk-system. Further works will insist on creation of more complex GA models, parallel \ncode generation and execution, browsers and language for application specification. References 111 D.E.Goldberg, \nGenetic Algorithms, in Search, Optimization &#38; Machine Learning, Addison Wesley, 1989. PI E. G. Talbi, \nP.Bessiere, A Parallel genetic algorithm for the graph partitioning problem available as IMAG Report. \n(Contact bessiere@imag.fr) [3] J.M.Filloque, E.Gauuin, B.Pottier, Eficient Global Computation on a Processor \nNetwork with Programmable Logic, PARLE91, LNCS 505, Springer-Verlag, June 91. OOPSLA W -164 Vancouver, \nBritish Columbia  Contact information: Llemarchand A.Plantec B .Pottier S .Zanati Laboratoire d Informatique \nde Brest, Universite de Brentagne Occidentale 6 av. Le Gorgeu Brest ccdex 29287, France E-mail: pottier@ubolib.cicbfr \nS-10 October 1992 -165-Addendum to the Proceedings  \n\t\t\t", "proc_id": "157709", "abstract": "<p>Genetic algorithms (GA) mimic natural reproduction to search for complex problem solutions. Their principles are shortly explained. A point of interest is the regular and repetititve structure of computation involving communication, data exchanges, and control phases. Interaction with presentation and analysis tools is also a requirement. This make sense for the definition of a general framework allowing fast building of parallel applications in an object-oriented system. A GA workbench is developed using the Smalltalk-80 system with parallel machine code generation in mind.</p>", "authors": [{"name": "L. Lemarchand", "author_profile_id": "81758963257", "affiliation": "", "person_id": "P166384", "email_address": "", "orcid_id": ""}, {"name": "A. Plantec", "author_profile_id": "81100418150", "affiliation": "", "person_id": "PP14147943", "email_address": "", "orcid_id": ""}, {"name": "B. Pottier", "author_profile_id": "81100491541", "affiliation": "", "person_id": "PP31090646", "email_address": "", "orcid_id": ""}, {"name": "S. Zanati", "author_profile_id": "81100367349", "affiliation": "", "person_id": "P258082", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/157709.157742", "year": "1992", "article_id": "157742", "conference": "OOPSLA", "title": "An object-oriented environment for specification and concurrent execution of genetic algorithms", "url": "http://dl.acm.org/citation.cfm?id=157742"}