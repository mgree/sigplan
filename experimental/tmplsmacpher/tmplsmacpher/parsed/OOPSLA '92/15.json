{"article_publication_date": "12-01-1992", "fulltext": "\n 4 >.- Addendum A 92 to the Vancouver, British Columbia, Canada 5-10 October 1992 Proceedings Workshop \nReport- Object-Oriented Reasoning in Information Modeling Report by: Haim Kilov Bellcore Bill Harvey \nInstitute for Information Management Workshop plan and call for participation The conscious use of abstraction \nis very well understood in the programming world. Investigation is needed for better use of abstraction \nin information modeling. One of the major issues here is how to describe information (data + behavior) \nindependently of how it is stored or used. Among the questions to be addressed: . How do you represent \na conceptual schema using an object approach? In particular, how do you represent a relationship? How \ndo you specify object operations? How do you represent operations spanned across several objects? Does \nthe entity-relationship approach to information modeling lack behavior? How can you specify behavior \nin an implementation-independent manner? What is the impedance mismatch problem for the object paradigm? \nIs API specification consistent with the object approach? Is it possible to create an Object SQL and \nnot delete anything from SQL? Is it possible to do object programming in {your favorite programming language}? \n. How can you represent catalogs of data elements and encyclopedic resources for information management \nwith regard to representation of behavior?  Introduction The need for a disciplined approach to information \nmodeling has been acknowledged for some time. The results of other approaches, including miraculous methodologies \nor tools, are well known: as a typical example, consider the August 3 1, 1992, issue of Information Week \nwhere a cover article on data quality informs the reader that (in accordance with an Information Week \nfax vote), only 3 1% of company data are considered acceptably accurate and that most companies . . . \nmanually inspect data and correct obvious errors. Needless to say, that doesn t correct the weaknesses \nin whatever business process is the cause of the bad data in the first place. Information models represented \nin a vague and slippery way result in violating semantic integrity of data and therefore are the most \nimportant reason for these failures. However, some information models are demonstrably better than others, \nand it would be interesting and useful to find out the characteristics of the successful ones. It appears \nthat object-orientation manifested in abstraction, precision, reuse, and extensibility, leads to successes \nnot only in traditional programming, but also in analysis, i.e. in information modeling. This Workshop \nwas in fact an invitation to colleagues from academia and in industry to present their ideas and experience \nin these areas. By no means are the papers presented at this workshop the only ones that deal with object-orientation \nin information modeling: quite a few contributions to OOPSLA conferences and quite a few papers and even \nbooks exist that consider various aspects of this problem. Nevertheless, both academics and practitioners \nare often not satisfied: we are only making our first steps. Unfortunately, some publications try to \nattach object-oriented to just about anything and therefore do a disservice to several very good ideas. \nA disciplined approach to information modeling is based on the explicit acknowledgment of the need to \nunderstand and should provide reusable concepts that help the client, the modeler, and the developer \nin doing so. These concepts should be independent of a particular application, implementation, methodology \n( technique ), or tool, and therefore permit and in fact encourage communication between these. The concepts \nshould be presented in a precise and explicit (i.e. formal) manner-in the only manner that guarantees \nunderstanding. Presented papers Information Modeling Using HP OpenDB Rafuf Ahad (Hewlett-Packard) Applications \nof Formal Methods for Real-Time Systems in Information Modeling Armen Gabrielian (UniView System) Object-Orientation \nand Information Modeling Peter Hartel and Pedro Barros Inacio (Espirito Santo Data Informatica, S.A.) \nInformation Modeling Using Associative Global Arrays in MUMPS Bill Harvey and Bob Skovira (Robert Morris \nCollege) A Representation of Object Behavior in LOTOS Mikael Hedlund (Ascom Tech AG) On the Adequacy \nand Semantic Equivalence of Information Modeling Representations Bruce M. Horowitz (Bellcore) Matching \nInformation Modeling with Object- Oriented Design Ross Huitt and Paul Matthews (Bellcore) Information \nModeling within Carnot Nigel Jacobs (MCC) Information Modeling: Specifying Behavior of Associated Objects \nHaim Kilov and Jim Ross (Bellcore) Modeling Object Behaviors Using Finite State Automata Bruno Mongazon-Cazavet \n(BULL) Expressing Derived Object Types and Their Associations James J. Ode11(Ode11 Associates) Refactoring \nto Support Abstraction and Information Modeling Bill Opdyke (AT&#38;T Bell Laboratories) Abstract Behavior \nTypes for Behavioral ER Design Kevin J. Sullivan (University of Washington) Object-Oriented Approach \nto Modeling Multilevel Database Applications Bhauani Thuraisingham (MITRE Corporation) and Peter Sell \n(Department of Defense) Proceedings of the Workshop were published by Robert Morris College. Discussion \nand problems The following is a somewhat biased summary of the discussions at the Workshop and E-mail \ninterchanges after the Workshop. The organizers want to thank all of the participants (see above) for \nthe discussions at the Workshop and Bruno Mongazon-Cazavet, Bill Opdyke, Armen Gabrielian. and Nigel \nJacobs for E- mail comments and contributions afterward. All possible omissions were unintentional. The \norganizers did not include here agreements on basic issues, like the existence of an abstract object \nmodel, etc. These agreements were considered as given by most Workshop participants. To stress the practical \nvalue of the problems discussed, the organizers of the Workshop consciously decided to include references \nonly to national and international standardization documents rather than to possibly esoteric academic \npape=. Concepts We should clearly distinguish between concepts and environments that support concepts. \nThe concepts should be not just implementation-independent, but notation-independent as well. If a concept \ncan be expressed in a reasonable way using different notations then the choice of a particular notation \nis not important. For instance, whether a precondition for an operation is expressed using predicate \ncalculus, Z, VDM, Eiffel, or some other notation, the semantics of this fragment of a declarative specification \nof behavior remains the same. Also, the concepts should be independent of particular buzzwords used: \nthe same basic concepts are valid, irrespective of whether terms like actors, events, operations, assertions, \netc., are used. In the same manner, basic programming concepts (like iteration, procedure, or recursion) \nare valid, irrespective of the languages used (Algol, Pascal, LISP, Smalltalk, MUMPS, etc.). The need \nfor a concept not described in the traditional programming world is an important discovery: for example, \nthe need to consider relationships rather than just isolated objects ( abstract data types ) is an important \ninformation modeling consideration. Specification of behavioral semantics The papers presented at the \nWorkshop and most of the discussion concentrated on understanding and representing behavior. Understanding \nbehavior The IS0 documents on Open Distributed Processing effectively define behavior as a set of all \npossible sequences of operations. To describe behavior, we have to know the signatures and semantics \nof operations. The concept of a signature is relatively well-known. It has been defined in the ANSI Object \nData Management Reference Model [OODBTG 9 11 as the specification of the number and types of an operation \ns arguments and results. Of course, signatures do not define what operations do. If this fact is not \nexplicitly recognized then very serious problems may and will arise-eg., interoperability or conformance \nbased solely on signatures does not make sense [API 921. A complete definition of what the operation \ndoes (rather than how) is provided by a declarative specification of this operation, i.e., by its pre- \nand postconditions. A declarative specification is needed for human understanding rather than for mechanical \ninterpretation by CASE tools. The definition of behavior can be expressed in a structured natural language--to \nabsorb the shock of its introduction!-but, due to the inevitable ambiguity of a natural language, there \nshould exist a precise specification in a notation based on mathematics which should be relied upon in \ncases of doubt. This is the approach accepted by national and international standardization bodies (e.g., \non Open Distributed Processing [ODP 51, Object Data management Reference Model [OODBTG 911,OSI Systems \nManagement [GRM 921, etc.). Of course, the mathematical specification need not be shown to the customer: \nafter all, it is relatively straightforward to translate from, say, a predicate calculus expression into \nstructured English. This approach has been successfully used in programming and information modeling \nand is referred to in quite a few national and international standards. If such an approach to define \noperations is not used, then understanding an operation is possible only by looking into its implementation-an \napproach that could hardly be recommended. If an operation is not understood properly then its implementation \ncannot be checked for conformance, and, of course, the implementor often will have to create the specification \nbecause the existing one is ambiguous or incomplete. Quite a few papers have agreed on these issues. \nFormalization of specifications is the only way to understandability (even in ER modeling) [ODP 51. Examples \nof this approach have been provided. Reverse engineering of existing models and even methodologies helps \nto understand them, including their shortcomings and missing issues. Schema browsing and representation \nof formal specifications in the schema were touched upon, but not discussed in any amount of detail. \nProcess and approaches Naturally, a precise specification does not appear out of a magic hat: like a \nprogram (or a mathematical proof), it involves insights, reuse, errors, discussions, consideration of \nappropriate examples, etc. It was noted by some participants that this non- formalizable process of generating \nabstract and precise specifications had not been sufficiently emphasized at the Workshop. One of the \ncontributions (by Bill Opdyke) explicitly dealt with these problems; some other papers mentioned them, \nand more contributions would be welcome. Finding good abstractions is highly non-trivial! Are assertions \n(pre- and post-conditions and invariants) sufficient for understanding an operation? There is a need \nto distinguish between the concern for efficient executability and the concern for specification correctness. \nThe first concern needs more than a declarative specification; the second does not. Are pre- and post-conditions \nthe only way to define semantics? No, there are other possibilities, e.g., algebraic definitions of ADTs \nexist. These definitions possibly are mappable onto invariants, pre- and post-conditions; the latter \nare preferable because their properties are relatively well-known, and because they have been successfully \nused in programming methodology and information modeling. User request and state change The choice of \na next operation in the context of a particular invariant may be non-deterministic. An operation is executed \nwhen a user requests its execution. Naturally, an operation can be executed only if it is possible to \nsatisfy the request, i.e., if its precondition is TRUE. After a certain operation is executed, the state \nof the objects referred to in the operation definition may change. This new state will define which operations \nare possible: an operation may be executed if its precondition is implied by the state of its participants. \nNaturally, there may be quite a few operations that can be executed at any time: this is defined by the \nstate of the system. Joint behavior and relationships ADTs alone are insufficient to characterize behavior, \nbecause objects are not isolated. Joint behavior of objects is a rule rather than an exception, and it \nis represented in considering relationship types (i.e., jointly owned assertions) [GRM 921. Hierarchies \nof relationships are, of course, very useful. Joint behavior of objects, although mentioned in some Workshop \ncontributions and in some discussion statements, is still not sufficiently emphasized. However, it is \nthis joint behavior that is essential for information modeling: no object is an island. Contexts (interrelationships \nof molecules) should be considered not just for primitives (entities) associated in molecules, but also \nfor elementary molecules associated in higher-level molecules. This hierarchy, however, has some problems: \nthe lower-level molecules usually cannot be considered as points without internal structure. Some lower- \nlevel features are hidden at the higher levels of abstraction; the extent and kind of feature hiding \nare context-dependent. Particular information-hiding problems have to be contemplated for associations. \nAlthough encapsulation exists, information hiding may be inappropriate because if molecules (associations) \ninteract with each other then their interaction is defined, at least in part, by the components of these \nmolecules. Abstraction and declarative specifications Appropriate scaling (abstraction) is essential \nto understand behavior. It is reasonably easy to define and understand a simple operation or even a simple \nbehavior. However, operations, like objects, do not exist in isolation (their assertions are influenced \nby the context, i.e., invariants for larger associations), and this may make understanding of operations \nwithin a context very difficult; abstraction is needed. A context of an operation may be expressed as \na set of constraints that apply to the operation (the reader may wish to consider constraint-related \npapers from this viewpoint). In other words, a context of an operation is an invariant ( system state \n) that should be preserved by this operation. The same operation may be considered in different contexts \nleading to an interesting interplay between postconditions and invariants. Refinement does not necessarily \nmean implementation: it is possible to refine an information model (e.g., decompose a composite object \nor a composite operation) and still remain within the information modeling frame of reference. This often \nhappens and is essential for understanding an information model. The related phenomenon of propagation \nof triggers has also been discussed; it seems that this problem can be understood substantially better \nusing declarative rather than operational specifications, i.e., postconditions and invariants rather \nthan SQL-like triggers. Generic behavior: a framework Some behavior exists in all applications. This \nbehavior is generic. It represents primitive Create- Read-Update-Delete (CRUD) operations. Usually, extended \nentity-relationship (ER) modeling does not cover application-specific behavior, whereas it does cover \nCRUD: the basic relationship types are in fact defined using operations applied to interrelated objects! \n(For example, the application-specific operation hire an employee incorporates much more than just the \nbasic operation create an employee instance. ) An extended ER approach is usually not computationally \ncomplete: there exist selection and iteration operations between CRUD s, so ER cannot express everything. \nThese considerations do not preclude the usage of CRUD operations in information modeling, in the same \nmanner as computational incompleteness of a (much more complicated) SQL does not preclude its usage in \ndatabase programming. It was noted, however, that each extended ER model has to be precisely defined; \notherwise reasoning about a model is impossible. The definitions should not be in terms of examples (as \noften happens), because it remains unclear what to do with situation not exactly equivalent to these \nexamples. Finding frameworks and reusing them has been discussed. Generic information modeling concepts \ndefined by means of CRUD operations constitute a good example of a reusable framework. There should exist \nnot just a library of frameworks, but also a library of their implementations, e.g., on top of various \nkinds of DBMSs. A typical example: implementations of a dependency association for a relational DBMS \nmay use three tables (for a parent, dependent, and dependency with foreign keys), or two tables (for \na parent and dependent with foreign keys), or just one table (with some violation of normal forms); they \nmay also be provided on top of relational DBMSs with or without referential integrity support. On definitions \nand terminology There exist different definitions of events (necessary conditions, i.e., triggers, for \nexecution (events) vs. sufficient conditions for operations). Consider also, e.g., Apple events (like \nthe ones used in Macintosh application programming). An event can be defined as a non-decomposable change \nof state. It appears that an event is caused by a particular changeof state that happens because the \nstate at the immediately preceding moment of time was different from the state at the current instant \nof time. For example, a speeding ticket is issued if the speed of an automobile at a particular place \nof the road exceeds the permitted speed at that place. Generally, precise definitions are essential for \nconcepts like operation, event, behavior, etc. The following definition of an operation as proposed: \nchange of system state that may be possible when a precondition is satisfied and the result of which \nis satisfaction of a postcondition that define the operation. An operation can be decomposed into component \noperations. It is possible to consider only those features of the state that are of interest and suppress \nthe irrelevant features [ODP 21. An operation should be defined in a way that is independent of whether \nanthropomorphic metaphors (like an object decides, an object sends, etc.) are or are not used. These \nmetaphors are not needed for understanding, but are preferred by some. Examples of such definition (both \nof operation and of behavior) are provided in [OODBTG 911. [ODP 21, [ODP 51. According to Occam s razor, \nwe should not introduce additional concepts (especially if they are not precisely defined) if it is possible \nto get away without them. Even the difference between events and operations led to a heated discussion \nat the Workshop. Some participants expressed an opinion that an event is a bottom-lever instantaneous \nchange of state, and wanted to use different terms at higher levels of system description. This was intertwined \nwith a discussion on temporality. Introduction of other concepts (e.g., activities ) might lead to more \nproblems, especially with respect to differentiating (precisely) between these. Several related concepts \nthat are not precisely defined may lead to confusion. Of course, if a concept that differs from the existing \nones needs to be introduced, it should be, but only when it is clearly understood, i.e., (formally) defined. \nNames are unimportant; semantics (context!) is essential. A name should not be relied upon in understanding \nfeatures of a system. A name may not even be relied upon for guidance: too many terms are overloaded, \nand too many names mean different things to different people. Using a name for understanding is a manifestation \nof relying on assumptions that are not specified explicitly and may therefore lead to grave errors in \ninformation modeling. mote how many definitions of the term relationship exist; note also that an application- \nspecific term like customer may mean different things to different people even within the same organization.] \n  Conclusions The Workshop participants reached violent agreement on many issues. This set of problems \nneeds to be discussed further at OOPSLA 93; the desire to continue has been strongly expressed.  References \n[API 921 ISO/IEC JTCl/SC21. Draft First Report on the New Work Area on Programmatic Interfaces. ISO/IEC \nJTCl/SC21 N 7425. November 17,1992. [GRM 921 ISO/IEC JTCl/SC21/WG4. General Relationship Model. Eastboume \n3 1. December 1992. [ ODP 21 ISO/IEC JTCl/SC21/wG7. Basic Reference Model for Open Distributed Processing \n-Part 2: Descriptive Model. (ISO/IEC JTCl/SC21/WG7 N 70.54, May 1992). [ODP 51 ISO/IEC JTCl/SC21/wG7. \nBasic Reference Model for Open distributed Processing -Part 5: Architectural Semantics. (ISO/IEC JTCl/SC21/WG7 \nN 7056, May 1992). [OODBTG 9 11 Object Data Management Reference Model. (ANSI Accredited Standards Committee. \nX3, Information Processing Systems.) Document Number OODB 89-OlR8.17 September 1991. Contact information: \nHaim Kilov Bellcore, RRC-1 Al 11 444 Hoes Lane Piscataway, NJ 088544182 USA haim@bcr.cc.bellcore.com \nBill Harvey Institute for Information Management Robert Morris College Narrows Run Road Coraopolis, PA \n15108-1189 USA   \n\t\t\t", "proc_id": "157709", "abstract": "", "authors": [{"name": "Haim Kilov", "author_profile_id": "81100225658", "affiliation": "", "person_id": "PP31082477", "email_address": "", "orcid_id": ""}, {"name": "Bill Harvey", "author_profile_id": "81100589635", "affiliation": "", "person_id": "P30438", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/157709.157724", "year": "1992", "article_id": "157724", "conference": "OOPSLA", "title": "Object-oriented reasoning in information modeling", "url": "http://dl.acm.org/citation.cfm?id=157724"}