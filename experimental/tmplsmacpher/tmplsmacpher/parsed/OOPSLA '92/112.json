{"article_publication_date": "12-01-1992", "fulltext": "\n Addendum A 92 to the Vancouver, British Columbia, Canada 5 - 10 October 1992 Report by: William J. \nCollins Lafayette College Abstract A model for verification and testing in an object- oriented CS2 course \nis presented. The model has four stages-two for verification and two for testing-at which student progress \nis evaluated. Students thereby see verification and testing as integral parts of the programming process, \nrather than as addenda. The impact of this model on students programming behavior is discussed. Introduction \nComputing Curricula 1991 [l] recommends that the processes of theory (including proofs) and design (including \ntesting) be emphasized in alI subject areas of computing. This paper describes a model for verifying \nalgorithms and testing units in an object- oriented CS2 course. The purpose of adopting the model is \ntwofold: to promote the benefits of algorithm verification and to encourage a systematic approach toward \nprogram testing. The stages relating to program testing are not new; testing is usually introduced in \nthe CS 1 course and reinforced in CS2. In the best of all possible worlds, the same schedule would apply \nto algorithm verification. Unfortunately, in most curricula, verification is not even introduced in CS \n1. In such an environment, emphasizing verification in CS2 is indispensable.   Proceedings Educators \nSymposium- Verification and Testing in an Object-Oriented CS2 Course The model, updated to reflect \nan object orientation, has been used by the author in the CS2 course since 1988. The language used in \nthe course is Turbo Pascal, version 6.0. This course has Discrete Structures as a corequisite, and the \ntopic of mathematical induction is covered at the beginning of the discrete structures course. As a result, \nstudents have already seen the basic tool for obtaining correctness proofs before any verification is \nrequired in the CS2 course. During the semester, two major projects are assigned in the CS2 course. Each \nof these projects is worth 150 points-the course grade is based on a lOOO-point scale. Each assignment \nincludes a list of functional specifications and two system tests. The Model We now present the model \nas it is used for grading the two programming projects. An outline of the model is shown in Figure 1. \n S-10 October 1992 -285-Addendum to the Proceedings 1 Stage Time Alloted Value 1. Method Interfaces \n1 week 10% 2. Fields and Methods 1 week 30% 3. Component Testing 1 week 30% L 4. System Testing 1 week \n30% Figure 1. The four stages in the model. Each stage is now described in detail. 1. Method Interfaces \nOne week after the project has been assigned, an outline of each objects methods is due. For each method, \nthe outline is in the form of a language- independent method interface, which consists of the method \nheading and the precondition and postcondition of the method. For example, the Add method in a VeryLongInteger \nobject would have the following method interface: Add (A, E, Overflow). Precondition: A and B are instances \nof very long integers of, at most, MaxSize digits each. Postcondition: If the sum of A and B has at most \nMaxSize digits, then that sum has been stored in the calling instance and Overflow has the value False. \nOtherwise Overflow has the value True. Note: Add is not a function because two values, the sum and Overflow, \nare returned. The preconditions and postconditions constitute preliminary verifications of the ADTs. \nThe instructor s evaluation consists mainly in making sure that the preconditions and postcondition are \nconsistent and that the student is headed in the right direction. There are two advantages to having \nstudents submit their method interfaces within a week of the project s assignment. On a conceptual level, \ntheir initial focus is as it should be, on whal rather than how. On a practical level, they need to begin \nwork on the project promptly, but what is required is only a small part of the overall project. 2. Fields \nand Methods During this stage, students supply both the fields in the objects and the method designs \nfor those objects. The following verification tools are used on the method designs: a. Correctness Proof. \nStudents are required to prove the correctness only of recursive calls and non-trivial loop statements. \nThere are two reasons for this restriction. One is that, otherwise, there would be many long and tedious \nproofs. Another is that recursion and looping constitute the greatest barriers to program comprehension \nbecause there is such a disparity between their static appearance and their dynamic execution. Because \nstudents know they will have to prove the correctness of their recursive calls and loop statements, they \ntend to make them as clear and simple as possible. This side benefit of correctness proofs may be even \nmore valuable than the proofs themselves. b. Design Walkthrough. The class is subdivided into peer-review \ngroups. Each group consists of three student units, where a unit consists of one or two students (partnerships \nof two students are legal). Each method design consists of the subalgorithm, Big-O analysis of the subalgorithm, \nand correctness proof, if needed. The design is then verified in the sense that the student tries to \nconvince the other group members that the design is correct. The evaluators must sign the following statement: \nWe have studied the design of and deem that coding can begin after (no, minor, major) changes. If the \ncritics recommend that no changes or only minor changes are needed, but subsequent events indicate that \na major overhaul was required, the project grades of the critics suffer! So far, social pressure has \nprevented the critics from routinely recommending major changes. From the designer s viewpoint, the walkthrough \nis non-punitive because the peer evaluations do not affect the designer s grade (the instructor grades \na copy of the design during the walkthrough). 3. Component Testing As befits an object orientation, \nbottom-up testing is used. Students submit Turbo Pascal units that implement the objects, along with \ndriver programs that validate those implementations. In order to spread out the work, error checking \nis not required during this stage. That is, students can assume that in each message, the method s precondition \nis satisfied. Some integration testing may also be required at this stage if the validation of an object \ns implementation presumes that some subordinate object s implementation has already been validated. OOPSLA \n92 -2&#38;i-Vancouver, British Columbia 4. System Testing At this stage, system tests are run by the \nstudents and, when the project is turned in, by the instructor. As noted earlier, the data values for \ntwo of the system tests are provided to the students when the project is first assigned. If a submitted \nprogram fails either of the system tests, it is returned ungraded to the student. The corrected program \ncan then receive, at most, half credit. This discourages students from submitting programs that are merely \nIimping instead of running. If a program passes the original two system tests, the program is run with \na third system test that was not provided to the students. The final part of the project grade (30%) \nis based on the results of this test and the degree to which the program adheres to the programming standard \nsupplied at the beginning of the course. Results Since this model has been adopted, there have been \nseveral changes in the students programming behavior: The intermediate stages discourage procrastination. \nThe panic is spread over several weeks rather than several hours. The requirements of the first two stages \nare closely related. In the first stage, students specify exactly what a subalgorithm is supposed to \ndo. In the second stage they prove, if necessary, that their version of the subalgorithm does what it \nis supposed to do. Thus students spend more time on algorithms and, unwittingly, obey Harlan Mills dictum \nResist the urge to code. Because a program must pass the given system tests even to be graded, students \nhave become more conscientious about testing. Conclusions The overall impact of adopting the model has \nbeen very positive. As noted above, projects are more likely to bc both on time and correct. From the \ninstructor s viewpoint, this improvement has easily compensated for the additional grading required. \nAlso, as Dijkstra [3] has noted, Teaching to unsuspecting youngsters the effective use of formal methods \nis one of the joys of life because it is so rewarding. Students appreciate the product<orrect programs-but \nnot the process. Students may see the connection between the two eventually (although this may be several \nyears after graduation). A former student, who had resisted verification when he took the course, recently \nconceded that there might bc something to it after all. In a 5,000-line program he was writing for a \nclient, the only working module was the one he had verified during design. References 1. ACM/IEEEXS \nJoint Curriculum Task Force, Computing Curricula, 1991, March 1991. 2. Anderson, R. B., Proving Programs \nCorrect, John Wiley and Sons, 1979. 3. Collins, W. J., Data Structures: An Object- Oriented Approach, \nAddison-Wesley Publishing Company, 1992. 4. Dijkstra, E. W., On the Cruelty of Really Teaching Computer \nScience, Communications of the ACM, Volume 32, Number 12 (December 1989), 1398- 1404. 5. Gilbert, P., \nSoftware Design and Development, Science Research Associates, Inc., 1983.  6. Gries, D., The Science \nof Programming, Springer-Verlag, 1981. 7. Kruse, R. L., Data Structures ana Program Design, Second Edition, \nPrentice-Hall Inc., 1987.  Contact information: William J. Collins Computer Science Department Lafayette \nCollege Easton, PA 18042 email: cb#O@lafayacs.bitnet S-10 October 1992 -287-Addendum to the Proceedings \n  \n\t\t\t", "proc_id": "157709", "abstract": "<p>A model for verification and testing in an object-oriented CS2 course is presented. The model has four stages&#8212;two for verification and two for testing&#8212;at which student progress is evaluated. Students thereby see verification and testing as integral parts of the programming process, rather than as addenda. The impact of this model on students' programming behavior is discussed.</p>", "authors": [{"name": "William J. Collins", "author_profile_id": "81100445154", "affiliation": "", "person_id": "P298804", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/157709.157832", "year": "1992", "article_id": "157832", "conference": "OOPSLA", "title": "Verification and testing in an object-oriented CS2 course", "url": "http://dl.acm.org/citation.cfm?id=157832"}