{"article_publication_date": "01-01-1977", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1977 ACM 0-12345-678-9 $5.00 IMPLEMENTATION OF AN ARRAY BOUND CHECKER * Norihisa Suzuki Department of \nComputer Science Carnegie-Mellon University Pittsburgh, Pa. 15213 and Kiyoshi Ish ihata Department of \nInformation Science University of Tokyo Tokyo, Japan 1. INTRODUCTION not reclaimed if they are still \npointed to, uninitialized variables are not used. This paper describes a system which checks correctness \nof array accesses automatically Since these conditions cannot be with out any inductive assertions or \nhuman completely checked, many compilers produce interaction. For each array access in tke program a \ndynamic checking code so that if the condition fails, condition that the subscript is greater than or \nequal then the program terminates with proper to the lower bound and a condition that the diagnostics. \nThese dynamic checking code subscript is smaller than or equal to the upper sometimes take up much computation \ntime. It is bound are checked and the results indicating within better to have some checking so that \nunexpected the bound, out of bound, or undetermined are overwriting of data will. not occur, but it is \nstill produced. It can check or&#38;inary programs at about very awkward that the computation stops because \nfifty lines per ten seconds, and it shows linear time of error. Moreover, these errors can be traced \nback complexity behavior. to some other errors in the program. If we can find out whether these conditions \nwill be met or not It has been long discussed whether befcme actually running the program, we can program \nverification will. ever become practical, benefit both. by being able to Generate efficient code The \nmain argument against program verification is and by being able to produce more ~eliable progxams that \nit is very hard for a programmer to write by careful examination of errors in the programs. Similar assertions \nabout programs, Even if he can supply techniques can be used to detect enough assertions, he must have \nsome knowledge equivalent subexpressions or sernantical].y redundant statements to do more elaborate \ncodeabout logic in order to prove the lemmas (or movement optimization. verification conditions) obtained \nfrom the verifier. However, there are some assertions about The system we have constructed runs fast \nprograms which must always be true no matter enou~h to b~ used as a preprocessor of a compilm, what the \nprograms do; and yet which cannot be The system first creates logical assertions ch~cked for all cases. \nThese assertions include: immediately before array elements such. that these integer values do not overflow, \narray subscripts are assertions must be true whenever the control passes Witll.ill range, pointers do \nnot fall off NIL, cells are the assertion in order for t~~ aCCeS.S to be -.ralid, These assertions are \nproved using similar techniques as inductive assertion methods. If an array element W This research was \nsupported in part by the lim inside a loop or after a loop a loop invariant is Defense ,(Mtvanced Research \nProjects Agency synthesized. A theorem prover was created which (Contracts: F44620-73-C-O034, monitored \nhas the decision capabilities for a subset of by the Air Force Office of Scientific Research, arithmetic \nformulas. We can this prover to use ancl DfkHC-15-72-C-0308) and in part by the prove some valid formulas, \nbut we can also use it to University of Tokyo Computation Center. generalize nonvalid formulas so that \nw~ can The views expresseci are those of the authors, hypothesize more general loop invariants. Theoretical \nconsiderations on automatic synthesis of loop invariants hav~ been taken into accouut and i+ complete \nformula for loop invariants was obtained. We reduced the problem of loop invariant synthesis to the computation \nof this formula. This new approach of the synthesis of loop invariant will probably give more firmer \nbasis for the automatic generation of loop invariants in general purpose verifiers. 2. THEORETICAL BASIS, \nThe correctness of array accesses can be stated within the theoretical framework of the weak correctness \nof programs, That is , we only have to show that the assertions placed immediately before the array element \nstating that the subscript expressions are within the defined bounds of the array hold, whenever control \nof the program comes to the assertions. The major problem for making an automatic verifier which does \nnot require any assertions by programmers is that the system must sorneh.ow invent loop invariants. Some \nresearch has been conducted toward automating the generation of loop invariants[3,4, 1 o], A common characteristic \nof all the research is that the method depends on heuristics, That is the system proposes some assertion \nas the loop invariant and let the prover decide if the program is provable from the loop invariant. The \ndifficulty is that if it does not work, it is hard to see whether the program is not correct or the heuristics \nare wrong, What we will do here instead is to obtain a complete formula for loop invariants. Just like \nTaylor s series expansion of functions wi].1 give a complete description of the function even though \nthey are not usually calculable and infinite chain of approximations , we obtain an infinite chain of \napproximations to the general loop invariant from this formula. Furthermore, if the assertion we want \nto prove is not a correct assertion wo cannot invent a loop invariant which is true at entry to the loop \nand which is always true whenever control comes baclc to the top of the loop, and finally which implies \nthe exit condition. So, what we can hope to obtain is a formula which is a loop invariant if and only \nif the assertion is correct. This formula is similar to the weakest precondition of Dijkstra [2], What \nis different here is that we are only concerned about weak correctness. The formula is wlp( while CdoS,Q) \n= v i.i>O~W(i,C,S,Q) whmm W(O,C)S,Q)=. Co Q, and W(i+ l,C,S,Q) = C o wlp(S,W(i,C,S,Q)) , for i20. Wlp \nstands for weakest liberal precondition, The definitions of the weakest liberal, precondition wlp(S \n, Q) is that if S is executed in the state satisfying wIP(S , Q) then Q is always true aftex termination \nof S, and no weaker condition satisfies such a condition, Wlp for assignment and conditional statements \nare the same as th.o,se of the weakest precondition. It is easy to see that if wlp( while Cdo S,Q ) \niS true at entry to the program then wlp( while C do S , Q ) is always true whenever control comes back \nto the beginning of the loop. This is because wlp( while Cdo S,Q) AC = wlp( S,wlp( while CdoS,Q)) It \nis easy to see that wlp( while C do S , Q ) A . C 2 Q, ARO whenever the while statenlent terminates, \nQ is true at exit if and only if wlp( while Cdo S,Q)is true at entry. Thus, this is the desired formula. \n Note that no heuristics are involved in wXiting out the loop invariant. The problem is reduced to computing \nthis formula, b i,i20::) W(i,C,S}Q), and we can claim that Vi.j2i200W{i,C, S,Q) is the j-th approximation \nin a sense that it may be a loop invariant and if j-1 st approximation is a loop invariant then j-th \napproximation is certainly a loop invariant. We will invent a procedure for checking whether j-th approximation \nis a loop invariant or not. Let L(j) stand for F i,j2i20~W(i,C, S,Q), the j-th approximation to the loop \ninvariant. Certainly L(j) A 7 C o Q. III order to establish that L(j) to be a loop invariant we have \nto show thtit L(j) is true at entry and also L(j) A C o wlp(S ,L(j)) . But wip($i+(j)) = wlp(S , f[,j2kOaW{i,C,S,Q)) \n= #i,j2i20awlp(S, W(i,C,S,Q)), so C o wIP(S ,W) = b i.j2i20aW(i+l,C,S, Q). That is L(j) A C 2 wlp(.S,L(j)) \nis equivalent to #i,j2i>Oo(W(i,C,S,Q) ~ W(i+l,C,S,Q)). So all we have to prove is to prove these two \nequations. There is a nice thing about this method and that is we can use all the results of computation \nup to j-1 st approximation to compute the j..th approximation, The reason is if W(i,C,.S,Q) was failed \nto be proved then we can use this as an assumption for the next step and also we can back\u00adsubstitute \nthis formula around the loop and we can obtain W(i+l,C,S,Q). This fact suggests an iterative method of \nprovin~ weak correctness of programs without loop invariant. Because of this iterative nature we call \nit the induction iteration method. Induction iteration method. Step I) Greate W(O,C,S,Q) = -c ~ Q. Step \n2) Try to prove, W(i,C,S,Q) from v k,i-12k>0.W(k,C,S,Q). If it is true , the program is correct and the \nproof is done, Step 3) We have to see if W(i,C,S,Q) is true at entry to the looP. Back-substitute this \nW(i,C,S,Q) through the program segment before the while statement. If it can be shown to be false at \nentry, the program is not correct and done. If it cannot be shown to be true, the algorithm halts indicating \nundetermined. Step 4) We will. use W(i,C,S,Q) to prove the next step. So we will create Vk.i~kZO~W{k,C,StQ). \nThen we will. create W(i+ 1,C,S,Q) from W(i,C,S,Q) by the fOrmUla C 3 vdp(S,W(i,C,S,Q)). Step 5) i * \ni+l. Go to step 2). end of algorithm This iteration may never terrninatcb. Particularly if the program \nis not correct we may very well not terminate. If we implement this algorithm, therefore, we have to \nput a bound on the number of iterations which determines the limitation of the system. We have to note \nhere that the size of conditions , cr the size of W(i,C,S,Q), grows more rapidly than linear to the size \nof the program S. The reason, more than anything else, is that because of the rule wlp(if B do S1 else \nS2,R) = (B ~ wlp(Sl,R)) ~ (= B =1wIP(S2,R))) the condition more than doubles in the size each time it \nis back-substituted through conditional statement. Since it is inevitable that the performance of a theorem \nprover is exponential to the size of formula, it is very important to keep the size of the condition \nW(i,C,S,Q) to be constant if wc want to make a system works in linear time. For this reason w~ have developed \na theorem prover which not only proves but also simplifies logical expressions, and modified the semantic \nrules WIP. These practical considerations will be discussed in the next two SeCt@M. 3. Theorem Prover \nThe synthesis of loop invariant is on a firmer ground, but we need to create a powerful theorem prover \nto make a practical system. The domain we are particularly interested in is an integer domain and formulas \nwe have to prove is inequality relations with only universally quantified variables. Before we prove \nthese formulas all the arithmetic expressions and relations are converted to normal forms. Normal forms \nof arithmetic expressions and relations have been discussed in many verification literature[5]. As we \nhave discussed in section 2, the main source of the exponential explosion in most of the verifiers comes \nfrom the g~owih of conditions to be proved, The theoretical limitations at least for the time being forbid \nus to create a theorem prover which behaves better than exponential time complexity. This suggests that \ninstead of spending efforts in creating clever algorithms to reduce the speed of theorem prover by a \nconstant factor, w(? should spend our efforts in creating simplification and generalization methods which \nlimit the growth of conditions even though the size of the programs grow, Since w~ are representing arithmetic \nexpressions in normal forms, the size of ex-pressions do not grow very rapidly by substitution of assignment \nstatement. The problems are created by conditional statements. The detail of algorithms are discussed \nin the next section. In this section we will discuss about powerful theorem prover which are used to \nsimplify conditions. The basic algorithm of the theorem prover is ~ing s linear solver [ 5 ], which is \nbased on the proved. This is shown to be true when cont~ol first enters the loop. To see this is true \nwhen back\u00adsubstituted around the loop we compute wlp(S,-LO\\ti+l <= O) = (A[lvlHIDLE] <= K o -LOW+l <= \nt))A (AIMIODLE]>K o -(LOW+HIGH) DIV 2 <= 0), This is easily shown to be true from the assumptions -LOW-+1 \n<= O and LOW <= HIGH. As you can see the generalization by the prover not only simplifies the problem \nbut also generalizes the approximations of loop invariants to enable proofs in many cases. 4, SYSTEM \nCONI7TGURATION The system configuration is straight forward closely following the implementation suggested \nby the previous two sections. Only simplification not discussed is the treatment of conditional statements. \n4, 1. Extraction of Local Conditions A program is scanned once in the order they are presented as a text. \nWhenever an array element A.[e] is found , conditions lower_bound_of (A) <= e and e < uPPer_bound_of(A) \nare created as the conditions of the innermost statement containing the array element, We call these \nas bound assertions. If the statement is an assignment statement or a conditional statement , the condition \nmust be true immediately before the statement. If the statement is a while statement, the condition must \nbe true at entry and for each subsequent iteration of the loop. 4, 2, Semantic Treatment of Statements. \n Each, bound assertion created for an array access is transformed as it is back-substituted through the \nstatements according to the semantic definitions of the statements. These assertions are at the same \ntime simplified using normalization and th eormn prover, The back-substitution process terminates either \nwhen there are no mom staternen.ts in front, the condition is proved to be true or false, or it hits \na while statement. Since wo cannot iterate on a while statement indefinitely we return the result undetermined \n(U) if we fail to prove or disprove within a certain number of iterations. The semantic definitions of \nstatements are in principle the weakest liberal precondition rules, but vJ@ use some SlrOpllfiCatiOn \nas we tranSfOrm conditions. 1 ) Statement lists. If we have a statement list S 1; S2 and SUPIJOW P is \nthe assertion to prove after S2, then we obtajn precondition of P over S2, w).p(S2,P). If this precondition \nis tru~ or false or undeterm.i.ned, we terminate the process and return the corresponding resu].t. Otherwise \nwe compute the precondition of wl.p(S2,P) over S1 wlp(,51 , IA71p(sz , P)) and return that as the result. \n2) Assignment statement. If we have an assignment to a simple variable x + f(Y), tb en we return Substitllte( \nf (y) , X , P) . 13kre Substitute e , X , p) is an expression obtained from P by substituting all the \noccurrences of X by e. If the ,statement is an assignment to an array element Mel -f(Y), then Substitute(<A,e, \nf(Y)>,A,P) is returned, where <A, e,f (Y)> is an array obtained from A. by substituting e-th element \nby f(Y). 3) If stat~m.ent. In the case of the if-then-else statement if C then S 1 else S2, wc compute \nboth the precondition of P over S 1, wIP(S 1,P) , and the precondition of P over S2, wl.p(S2)P). If any \none of them is false or undetermined, the process terminates immediately with the corresponding result \nas the result of back-substitution, If wI.T(S 1,P) and wl.p(S2, P) are both, true then return true. If \nwlp(s 1,P) is true then we compute ~ C ~ WI p(~2jP) by the theorem prover and return the generalized \nformula. If wlp(S2,P) is true then we compute C ~ vJlp(S l,P) by the theorem prover and return the generalized \nformula. Otherwise we compute (C ~ VJlp(s I, P)) A (=C ~ wlp(.S2,P)) by the theorem prover and return \nthe conjunction of generalized formula. Next, if the statement is if-then statement, namely, if it is \nof the form if C then S; then we compute precondition of P over the statement S , wlp(S , P). If wlp(s \n, P) is false or undetermined, we terminate the computation and return the wlp(S,P) as the value of back-substitution. \nIf wlp(S , P) is true, we return the Suppose x+el <= O , -x+ei? (= O, Z%x+e3 <= Fou~ler-iViotzIun method \nof linear programming. W(0): LO\\ti <= HIGH o This class of prover is quite suit~d for array bound 1 <= \n(LO\\N+tiIGH) DIV 2 checking sluce array subscripts are in many cases or after simplification linear expressions. \nThe prover generally proceeds to W(O): LO\\ti <= HIGH ~ 2 <= LOW+HIGH sb.ow unsatisfiabllity of a set \nof linear inequalltlw. a~{q>. J. O is the set w~ are going to show unsatisfiable, that is x+-e 1 <= \nO n -x+e2 <= O ~ 2Yx+e3 <= O is false. The prover selects x to be the variable eliminated from the set. \nThen we classify this set mto three subsets sucl~ that the coefficients of all the inequalities in the \nflr,st set are positive, the coefficients of all the inequalities in the second set are negative, and \neach ~nequ ality in the third set does not contain x. We add each member of the first set and each member \nof the second set such that terms of x will disappear. We may have to multiply each inequality by some \nconstant to adjust. If any one of them produces a contradictor y formula the proof is successful and \nthe process termj nates. Oth erwlse we replace the origi JI.al set by the union of the newly created \nset and tl? e third subset of the original set, In this case el.rc~ <= O, 2*e2+e3 <= O are the result \nof eliminating x. The procedure is iterated until. we elj m inate all the variables and obtain false \nstatement, in which case the set is unsatisfiable, and otherwise satisfiable. Suppose the set is satisfiable \nand the result of elimination is a linear inequ aljty e <= O. Then -e + 1 <= O is the equation which \nis just sufficient to give unsatisfiabili t y. -e + 1 < = O 1s in a sense the most general assumption. \nAt this moment the system proposes -e+ 1< =0 to be the general.j zation of the lemma and tries to p~ove \nthis instead. If there are several inequalities then each of them is in turn chosen to be the generalized \nlemma. We will illustrate by an example how powerful th me genera).j zation techniques are, VAR A: ARRAY[l:IOO] \nOF T; {u LOW +-1; {2} HIGH +-100 ; {3]. WHILE LO\\I J <= HIGH { 4 ], DO BEGIN MIDDLE + ( LOW + HIGH) DIV \n2 ; {5} IF AIIWDDLE] <= K THEN { 6 } HIGH + MIDDLE-1 ELSE { 7 ~ LOW (-tvlIDDLE+l END, -- This is an essential \npart of a binary search algorithm which will he proved in section 5. One of the condition we have to \nshow is here that 1 <= MIDDLE at { 5 }. Then what we first try to .$~L(IvJis Since this is not provable, \nwe try to see if this is; trite when control first enters the loop. We baclc-substitute W(O) th~ough \ntwo statements and we obtajn true at { 1 } . Now W(1) is formulated as w(l): LOW f= HIGH o (A[(LOW+WGH) \nDIV 2] <= 1<0 (LOW <= ((LO\\4/-WtGH) llIV 2 -1) a 2 c= LOW-l+(LO\\4-hHIGH) DIV 2))A (A[(LOW+HIGH) DIV 2] \n> K > ((LO\\ti-W)GH) DIV 2 +1 <= HIGH ~ 2 <= (LOW-d-ilGH) DIV 2 +l+HIGH)) or W(l): (LOW <= HJGH A A[(LOW+HIGH) \nDIV 2] <= K A LOW-F2 <= HIGH ~ 6 z= 3*LO\\ti-H#IGH) A (LOW <= HIGH /\\ A[(LOW+HIGH) DIV 2] > K A LOW+l \n<= H)GH ~ 2 <= LOW+%HIGH) at { 4 } by back-substituting w(o) th~ough the while body. W(O) ~ W(1) is ( \n2<= LOW+t-llGH A LO\\J J-h2<= HIGH A A[(LOW+HIGH) UIV 2] <= K o 6 <= 3* Low+}41GH) A ( 2 <= LOW+HIGH A \nLOW+-1 <= HIGH A A[(LOW+HIGH) DIV 2] <= K > 2 <= Low-E3tHlGH ) The latter conjunct is vahd, so W(O} ~ \nW{ 1) is simplified to 2 <= LOW+IIIGI-I ~ LO\\4 d+2 <= HIGH A A[(LO\\M+HIGH) DIV 2] <= K z 6 <= 3* LOW+HIGH \n. W< 1 ) is easily shown to be true when control first enters tb.e loop, but not itself provable. Therefore, \nwe compute W(2) by back-substituting W(1) around the loop. That will not be provable again, This iteration \nmany not terminate for some time. Now, let us look at the same example using the generalization by the \nprover. W(O) is not valid when it is computed, The computation is to show the unsatisfiability of LOW \n<= HIGH and LO W+I-IIGH <= 1. The elimination of HIGH generates Z* LOW-1 <= O and if vm have -LOW+l <= \nO vw can show the unsatisfiabilit y . We set Up -LOW+ 1 <= O as the generalization of W(0) LO be general~.zed \nvalue of lC ~ P, Otherwise vw zeturn 4. 5. Preferential elimination of variables. the generalized value \nof (C ~ Wlp($ , P)) A (vC ~ P) 4) While statement. The semantic definition of a while statement W]lih \nC do S relative to a post condition p can be defined in two cases depending on where P comes f rem, The \nfirst case is that P is created as the precondition of S. Then C o P is the first approximation of the \n loop invariant. If P is the precondition of the Stater[lerLt immediately after the Whih? statement in \na statement list, then . c 3 p is the first appro~inlation of the loop invariant. Let these first approximations \nto be W(O). We compute W(0) and if W(O) is true then we return true as the result of the back\u00adsubstitution. \nOtherwise we first back-substitute W(O) through the statements preceding the while statement. If the \nresult is undetermined or false WE! return it as the result, Otherwise we create W(1) by the formula \nC ~ wlp(S , W(0)). We generalize W(O} ~ W{ 1) by the th.eor ~m prover and repeat the similar process. \n4.3. Creation of assumptions. Since there are a number of array accesses, wc want to use the results \nof previous proofs so that wo do not have to do similar deductions over and over again. For this purpose \nwe have a mechanism. for inserting assumptions in the program. All the array accesses are scanned in \nthe order they appear in the text. As soon as the array bound assertions are proved they are inserted \njust in front of the statement in which. the array access occurs. These assumptions are used for proofs \nof other array bound assertions. Since the rest of the bound assertions are always created after these \nassumptions, most of the assumptions are effectively used to prove or to simplify back\u00adsubstituted assertions. \n 4.4. Analysis of loops. I?or each while statement while C do S a set Gf variables of S which may be \nchanged in the course of execution of S is collected. If we want to prove W(i) to be the invariant of \nthis while statement, we first see if any of the variables of W(i) appear in this list of the changed \nvariables. lf they d.o not occur in this list, W(i) will not change by back-substitution and it is an \ninvariant of the looP if W(i) is tru~ at entry. W@ can sav@ the computation to back-substitute in some \ncases. As we generalize and prove condi~ions, the choice of variables to eliminate is important for various \nresons. One strategy may be to try to choose a variable which has only one member in the set of positive \ncoefficient set or in the negative coefficient set. This is because we do not w~flt to explocte the number \nof inequalities. In this system what We do is to choose varial]les which might be changed in the course \nof the execution of the while body. This strategy is useful for generalization because if we can eliminate \nvariables which may be chtm~ed totally from the condition, then we can use the strategy described in \n4,4. and we no longer have to back-substitute the while body to determine the invariance of the condition. \n 5. EXAiVIPLES The following binary search program has been proved that all the array accesses are within \nbounds. The proof required Z CPU seconds. TYPE TABLE=ARRAY[1:1OO] OF INTEGER; PROCEDURE BINAR fSEARCH(VAR \nA:TABLE ;KEY:lNTEGER;VAR MIDDLE:INTEGER); VAR LOW, HIGH: INTEGER: BEGIN {1) HIGH := 100; {2] LOW := 1; \nWHILE LO\\ti < HIGH { 3 } DO BEGIN MIDDLE := (LOW+-HIGH} DIV 2; {4] IF AIMIDDLE]wKEY THEN { 5 } LOW:XHIGH+l \nELSE IF AIMIDDLE] > KEY THEN { 6 ] HIGH := MIDDLE-1 ELSE { 7 ] LOW := MIDDLE+l END; {8) IF AIMIDDLE] \n# KEY THEN MIDDLE := O END; There are three accesses of A, two within the loop and one outside of the \nloop. We are going to show how the system proves that the array accesses are within the ranges. The qroofs \nare not trivial, since iVI1 Di3LE does not change monotonically. Also there is an integer division and \nwe have to make sure that the right truncation is performed when we normalize expressions. We also have \nto prcwe that MIDDLE keeps within range even after the end of the execution of while statement. The \nsystem searches an array element textually from the begirming of the program. It first finds AIMIDK)LE] \nin the ~statement IF AIMIDDLE]=KEY THEN . . . . It creates an assertion 1-MIDDLE <= O at location { 4 \n} to insure the correctness of the array access relative to the lower bound of the array A, This assertion \nis back-substituted and becomes 1-( HIGH+ LOW) DIV2 <=0 at location { 3 }, This is normalized to 2-H1 \nGH -LOW <= O. Since the loop condition ( condition of the while statement ) is -HI.GH + LOW <= O, -HIGH \n+ LOW <= O~ 2 -HIGH -LOW <= O is proposed as the first approximation of the loop invariant. The theorem \nprover generalizes it to 1-LOW<= O, To show that this condition is true when control first enters the \nwhile statem ent this condition is back-substituted to { Z }, At location { Z } it becomes 1-1 <=0 and \nit is proved. For the proof of the inductive hypothesis, 1-LOW<=O isassumed tobetrue at{3}. This is back-substituted \nthrough the loop body. Since there is a three way branch, tb.ree subproblems are created corresponding \nto each branch, A path through branch { 5 } creates AIMHIDLE]~KEY ~ -HIGH <= O , This has to be proved \nby the inductive hypothesis 1-LOW<=O and the loop condition -HIGH +LOW <= O at loop entl-y { 8 }. These \ntwo assumptions imply 1-HIGH <=O and clearly -HIGH <= O. The second subgoal is created by the path through \nlocation { 6 } and, since no modification is done, it is clearly an invariant through this path. The \nfinal subgoal is created by the path th~ough { 7 }, Itis -MIDDLE <= O. at{4} and -LOW -HIGH <= O at \n{3}. This is again proved from the inductive hypothesis and the loop invariant. To prove that MIDDLE \nis smaller than the upper bound of the array A, MIDDLE <= 100 is created and the first approximation \nto the loop invariant at { 3 } becomes HIGH -100 <= O, using the generalization. The three subgoals are \n1) HIGH -100 <= o 2) HIGH + LOW <= 203 3) HIGH -100 <= O. 1) and 3) are the same as by the inductive \nhypothesis. 2) can be shown to be true by the inductive hypothesis and the loop invariant. At this point \ntwo assumptions, 1-MIDDLE <= O and -100 + MIDDLE <= O , are created and stored at { 4 }. The second array \naccess is proved to be within the bounds using these assumptions. The third array access is immediately \nafter the loop. All we have to do is to show that -(-HiGH+LOW <= O) 00 <= MIDDLE <= 100 is true at the \nloop head every time control passes this location. This can be proved similarly. The following is the \noutput from the system. The structure of the program is essentially maintained, and the array elements \nhave modified outputs indicating the results of checking. The format is <array name> [ <check re>ult> \n$ <subscript expression> $ <check result> ] where <check result> is any one of I, O, U. I means the subscript \nis within range, O means the subscript is out of range, and U means that the system cannot determine \neither way. Typical output looks like AII$e$U] + BII$e+f$O] which means e is greater than or equal to \nthe lower bound of A, but it is not clear whether e is less than or equal to the upper bound of A, e+f \nis greater than or equal to the lower bound of B, but it is greater than the upper bound of B. ***X* \nTYPE TABLE=ARRAY[1:1OO] OF INTEGER; PROCEDURE BINARYSEARCH(VAR A:TABLE ;KEY:INTEGER;VAR MIDDLE:INTEGER); \nVAR LOW,WGH:INTEGER; BEGIN HIGH := 100; LOW := 1; WHILE -HIGH+ LOW<= O DO BEGIN MIDDLE := HIGH+LOW \nDIV 2; IF AII$MIDDLE$I]=KEY THEN LO\\# := l+HIGH ELSE IF l+KEY-AII$MIDDLE$l] <=O THEN HIGH := -l+MIDDLE \nELSE LOW := l+MIDDLE END; IF .AII$MIDDLE$I]=KEY THEN MIDDLE := O END;  ***** TIME: 2 CPU SECS The next \nexample is the tree sort. This is to stLow that some of the more difficult arithmetic operations like \nmultiplication by a constant can be handl@d Properly. It is not very difficult for a person to observe \nthat all the array accesses by the subscript J are done correctly, since in the inner most loop J is \nincreasin~ monotonically and the looP condition is J <= N. However, among the array accesses with subscript \nI the second and the third array accesses are not trivial, Even for a human it needs a clear understanding \nof how this program works and how I and J are used. Once we know that J = 2* I at the loop head, we know \nthat since J is m.onotcmically increasing so is 1, I < 100 is maintained because at the loop head the \nvalue of I is eith m the same as the value of J ( or 1 greater than J if J < N and A[J] < A[J+ 1] ) of \nthe previous iteration and at that time J is less than or equal to N. This is informal human reasoning. \nThe array bound ch.eck,er does not use similar reasoning, but it manages to prove this by systematic \ninductive iteration and general;.zation by the prover. Another thing that ne~ds mentioning is that this \nProgram was checked with 16 CPU seconds, which. is within the usable range, especially considering that \nthe system is written in LISP 1.6. ***** VIM? A:ARRAY[l:100] OF T; K,I,J,N:INTEGER; COPY,WORK:T; BEGIN \nK := 100 DIV 2; WHILE 2-K<I= O DO BEGIN I := K; N := 100; COPY := AII$I$I]; J := 2*I; WHILE J-N<= O \nDO BEGIN IF I+J-N<= O THEN IF 1+A[18J$1]-A[H? l+JW]<=O THEN J :~ l+J; IF l+COPY-AIIOJ$I]<= O THEN BEGIN \nAII$IM] := AII$J$I]; I := J; J := 2*I END ELSE J := N+l END; AIIW$I] := COPY; K ;= -1.+K END; K := 100; \nWHILE 2-K<= O DO BEGIN I := 1; N := K; COPY := AII$I$I]; J := 2*I; WHILE J-N<= O DO BEGIN IF l+J-N<= \nO THEN IF 1+A[I$J31]-A[R? l+J$I]<=O THEN J := l+J; IF l+COPY-A[H?J81]<= O THEN BEGIN A[181$I] := AII$J$I]; \nI := J; J := 2*I END ELSE J := N+l END; AII$I$I] := COPY; WORK :E AII$l$l]; AIIl 1[11] := AIRIKM]; AII$KW] \n:= WORK; K := -1+1< END END ***** TIME: 16 CPU SECS This next example is almost identical to the previous \nprogram except the conditional statement has now been changed from IF J<N THEN IF AIJ]<AIJ+I] THEN J \n:= J+l to IF J<N A AIJ]<AIJ+l] THENJ := Ji-1. PASCAI. evaluates logical expression in para] l,el so J+ \n1 may become greater than N. Thus, .. the error has been correctly detected ana this is a valuable information \nto the programmer. VAR A: ARRAY[1:1OO] OF T; K,I,J,N:INTEGER; COPY,WORK:T; BEGIN K := 100 DIV 2; WHL1.E \n2-K<= O DO BEGIN I := K; N := 100; COPY := AIIWI]; J := 2*I; WHILE J-N<= O DO BEGIN IF l+ J-N<= OA l+AIH?J$I]-AIRI \n1+.J$U]<= O THEN J := l+J; IF l+ COP f-A[18J$I]<= O THEN BEGIN A[IW31] := AII$J$II; I := J; J := 2*I \nEND ELSE J := N+1 END; AIIWI] := COPY; K := -1+1{ END; K := 100: WHILE 2-K<= O DO BEGIN I ;= 1; N .- \nK; COPY := AIIM$I]; J := 2d; WHILE J-Nz= O DO BEGIN IF l+J-N<= OA l+AII$J$I]-AII$ l+J$U]<= O THEN J \n:= l+J; IF l+ COPY-AII$?J$I]<= O THEN BEGIN AIH?I$l] := AII$J$I]; I .-,-J; J := 2*I . END ELSE J := N+l \nEND; AIMI$l] := COPY; WORK := A[H?1$1]; AII$ltlI] := AII$K$I]; AII$K$I] := WORK; K := -1+1( END END ***** \nTIME: 20 CPU SECS This final example is taken from lexical analyzer of PASCAL compiler. The program has \nbeen modified from the original program by taking out several repeat statements, so it is not a correct \nprogram from the standpoint of lexical analyzer correctness. However, we have been able to put this \nprogram through the checker without any intermediate assistance. The input is 300 lines of code including \nsome comments. It takes 45 seconds to process. The system actually found an error at location { 1 }. \nWhenever buf len exceeds 256, the system prints out error messages, but it does not reset buflen. Therefore, \nthe following array element BUF[buflen] will be out of bound. The system cannot check the array access \nat location { 2 } , because bufimlex is a global variable, This is the kind of examples we need some \nassistance from the program mer stating the behavior of global variables and parameters. TYPE S7nodm,llECORD \nct ,ndox: INTEGER; Ienyth:subnnlioleh END; TYPE TrQen Ddor:llECORO ct indax: INTEGER; st index: INTEGER; \nleft:l Treenodo; p[ght: TTreQ!?odo EUO; TYPE Troo. ?Treet?odo; TYPE ~orcl!,ltltegor; TYPE CTnodo, >uord; \nTYPE pblord6,!flll RRY[l:31 OF No!sd; VFIR ST: RRRRY11:591 OF STnodo; CT: RROF CTnod~; I{RY[1:581 Top?t-oo:Tree; \nP: Tre G; CLt Pllfll?R: 171fR17Yil:15J OF CHFIR; curl en; subnflnelen; ctl:CHfl R; BUF:FINllilY ll:2551 \nOF CHRR; LET rCRS, LET fEffSOROIGITS:5ETOFCt{fln; f Irst, eof !npui:fJOOLEflN; I :subnnnol en; a:p}40rclti; \nFUHL i IOll 170UllflUP{COHS7 nuri: Inteyor; dcinon: Integer) : {ntegor; Vll Fl CI: Inteyor; BEGII1 q \n:= nur~ DIV donon; IF nuu MOOdonnn. O THEN ROUIIOUI]:. q ELSE RIIUNUUP:= l+q; sh ifi := BIOO~Ehili; \nEt{[l; END; Ien :,= curl on; PROCIDURF COPYLINE(CONST OUHHY:ghoct); ENO: VRfl c: CNRR; BEGIN PROCIOUIIE \nFINOPLRCE(VRR a:p~ord~; Ien:mbnmolen; IF NOT(EOF(INPU7)) VOR f irst:boo lean; Top: Tree; Vflli pinto \ntree: Tree); THEN BEGIN VRR P: Tre Q; bu$lon := 0; L:sub!)nwal en; UNILE NOT(EOLti(INPUT)) 00 ct Iessa, \nct less O,eq:boo\\ean; BEGIN uordinrl: integer; RERD(C); BEGIN URITE (TTY , C); IF Top WIL bllflen :. \nl+buflen; THEN BEGIN IF 256-buf Ion<. O first := TRUE; THEN NRITELN(TTY , ERROR1); E140 {11 ELSE BEGIN \nBUFIISbui len$Ul :. c; BEGIN ENO; L := STIU$TopT. st ind@x$Ul . length; RER!3Lti{DUllNY); IF L=len URITELN \n(TTY); THEN BEGIN bu+indax := 8; ecj : = TRUE; ENO k := ROUNUUI (L>6); ELSE eof input :. TRUE; nord)ncl \n:. 1; EfW; NNILE ~ord ind-k<. Ofioq.TRUE 00 BEGIN PROCEOURENEX_fCH(COtlSTOUlllfY:ghost); IF -C T[U$-l+~ordind+ \nBEGIN TopT . ct inclox$Ul. buf indax := l+buf index; a [I$word indWl IF l-buf index+buf Ien<= O THEN \noq :. FRLSE fHEN IF buf index-buf Ien.1 ELSE tiorilind := l+nordind; THEN CH := BLRtil: ENO; ELSE BEGIN \nIF eq. TRUE COP fLINE(OLIHMY); THEN OKGIN bufindo~ :S 1; first := FRL5E; CH := BUF[1$1$11 I pintcitreo \n:. Top; ENO END [21 ELSE BEGIN ELSE C}{ := BUFIUSbuf itldoWl ; ct les6a:.1-a [UWord ind$U]+ EN[l; CTIU%l+uordit~d+ \nTopl. ct indox$lll <. O; PROCEOUIIEGETNRHE(CONSTOUHliY:ghoiit); ct less O := l+ CTIU$-1+ BEGIN I.Iordi \nnd+Tol]l . ct indexW]<. O; curio!) := 1; IF -ctless O,,l+ cur!]nno [1$1$11 J= CH; a [U$uord illdSUl <= \nO NEXTCH(OUNtiV); THEN ct lessa :. ctlessO; HHILil INSET (CH,LETTERSOROIGITS) 00 IF ct lessa BEGIN THEN \nBEGIN IF -14+curlon<s E P := TopT. right; THEN BEGIN FINOPLllCE(a, Ian, cur Ion :. l+curl on; first, \nP,pint OtreO); curnatia [I$curlen$Il := Cfl IF TopT, right= NIL ENO; THEN TopT .right:. NEXTCH(OUNNY); \np intotree; ENO; ENO END; ELSE BEGIN P := TopT. left; PROCEOURilP17CKSTRING(VllR a:p~ot.do; FINDPLflCC(a, \nIen, VRR Ien:subnfltselen); first, P,pinl Ott.ee); WIR k,shi+i: integer; IF ToPT. left= NIL BEGIN THEN \nToP ?. left i := 8; :=pintotraa; uord indon :\u00ad 8} ENO; shiil := 81 EN(I; klHILE l+i-curlen<. O 00 ENO \nBEGIN ELSE IF l-len+L<= O IF shifl=8 THEN BEGIN THKN BEGIN P := Top T.right; uord indo% :. l+word index; \nFINOPLRCE(a, len, f Irst, a [I$~ord indax$Ul := 0; P,pintotrOO); shift := 1; IF Top?. riyhtuNIL EN(I; \nTHEN TopT. r ighl:= i := l+i; pint OtrQO; IF shi lt=B18000000000 ENO THEN BEGIN ELSE BEGIN k := -B IOOOOOOOOOQD(IO+ \nP := TopT. left; OIEOOOOOOOOQOnO(cummri [I$i$Ul ); FINDPLflCE(ii, len, first, P, K := 2VK; pinto tree); \nEN!J IF Topl. ieft=NIL ELSE k := -B fiOf?Ehift+ THEN TopT. lefit=pintotree; shi f t*ORO (curnmef I$i$Ul \n) ; ENO; aIU%ordit\\da~!Mll := k+a[U$uordindox$U] ; ENO; END; END; PROCEDUREIN ITNOOES(VOR a:p~ol-d6 \n; Ien:suboan alen; pnndo: Tree); BEGIN BEGIN IF 51-avai ICT<= 8 THEN llif17ELN (TTY , ERROR2); IF 51-avai \n1ST<= 8 THEN iiRITELN (TTY , ERHOR3); pnodo? . ct index := avai ICT; pnodo?.st index := avai 1ST; pnodot. \nleft := NIL; pnodo?. right := NIL; EfNJ; K := ROUl10UP(len,6); BEGIN ST[U$.avai IST$UI . length := \nI en; ST[U$avai IST$UI .ct index := avai ICT; EN{]; avail ST := l+avall ST; avail CT := avail CT+k.; \n ENR; BEGIN avail ST := 1; avail CT := 1; Topttwe := NIL; oof input := FflLSE; !4R1TELN(TTY , TITLE); \nWRITELN(TTY); COPYLINE(OUHH f); GETfiRliti (flUllli Y); UHILS( NOT(eof input) 00 BEGIN Ptl Cl;LiTRING(a \n, curl en); FINOPLflCE(a , curlen , first , Toptrea , P); IF Toptmo411L THEN Toptrea :. P; IF first \n THEN BEGIN IN ITNOUES(a , curlen , P); I.IRITE (TTY , FIRSTUSE) ; END ELSE liRITE (TTY , REPEflTEO); \n!JfiITELN (TTY); GETNFIHE(UUNHY) ENU; END *,>tc2(t! TIflE: 65 CPU SECS  6. CONCLUSION. There are \nseveral limitations to what the system can do. One class of problems which this system cannot do is to \ncheck the correctness of array accesses in a loop if the correctness depends on some data whose values \nare set before the execution of the loop. One good example is a very widely used class of techniques \nto speed up the sequential search by storing some exceptional data at the end of the array so that the \ncomparison looP always terminates. The program is VAR A:ARRA { [1:100] OF T; BEGIN A[1OO] + KEY; I+l; \nWHILE AII] > KEY DO I + 1+1; END, The while loop terminates because A[ 100] is the same as KEY and that \nwill make the while condition false, Using our methods we will not be able to prove this, since what \nwe have to prove as the induction step is I <= 100 AA[[] >KEY ~I<=99, Conventional program verifiers \nusing Floyd-Iloare logic system have the similar problem. That is even though a loop does not modify \nsome portion of the data we have to declare these properties as the loop invariant. The first author \nnoticed this problem [7] and has generally called it a frame problem of inductive assertion method , \nborrowing terminology from similar problems in artificial intelligence [6]. The solution to this problem \nis to extend the rules for loops so that properties of data can influence the proofs inside the whil~ \nstatements and after the while statements. Using Hoare s notation the new rule is P()(;v) ~ I(x;v), P()(;v) \nA I(x;v ) A C(x;v ) { S(x;v ) ) I(X;V ), P(x;v) A l(x;v ) A -C(x;v ) ~ Q(x;v ) P(x;v) { while C(x;v) \ndo S(x;v) ] Q(x;v) where x is a set of variables which do not change their values within S(x;v) , v \nis a set of variables which may change their values wj.thin S(x;v) , and v is a set of totally new variables \ncorresponding to v, The correctness and im ple]m.entation of this and other frame problem free rul.m \nfor various syntax constructs are discussed in [7] and [8]. We can use this technique to prove the previously \nunsuccessful problem of linear search. We failed to prove I <= 100 AAII] >KEY ~I<=99 at the loop head, \nbut if we replace I by 1 and back-substitute furth w to the f rent, wo obtain 1 <=100 A <A,1OO,KEY>[J. \n] > KEY o 1 <=99 and which is now a valid statement for m,hich we can show the correctness. Here <A, \n1.00 ,I<)ZY> clenotes an array obtained from A by replacing A[ 1.00] by KEY. The second problem is that \nthe REFERENCES. gerieralization capabilities of the system are not good enough for many problems. Ultimately \nwe must ask the user to give some assertions or on failure the system ought to indicate the reason for \nthe failure and ask the guidance of the user. We can say about the same thing for procedure and function \ncalls and their definitions, When we are checking procedure definitions, conditj.ons afe back-substituted \nin the program just as we treat main programs. However, if we come to the be@.nning of the procedure \nbody we can do two things, Either we say that the conditions cannot be determined and report to the programmer \nthe reason of failur~ , or try to check that these conditions are true at each calling occurrence. We \ncan also use induction iteration method to synthesize entry conditions for recursive programs. Currently \nwe take the former approach but eventually we either have to ask programmers to put in a modest number \nof entry and exit assertions and also t~y to check all calling occurrences to see if the conditions are \nright. The development and the availability of this kind of system will change programming language design \njust as verification and formal semantics have created a great effects on the programming language design. \nWe think we will see a great number of features which enhance security and reliability will be put into \nprogramming systems, so that these properties can be checked at compile time and create more reliable \nprograms with.ou t losing the run-time efficiency. Because the time complexity is good and the size of \na program it can handle is quite substantial, we belj,eve that the production version of tb.is system \nsoon will. he available to the public and verification wj.1.l. be directly benefiting the computing community. \n ACKNOWLEDGEM)WI The first author is thankful for the discussions with Eiiti Goto, Paul Hilfinger, Jim \nMorris, Ben Wegbreit, and Bill, Wulf. [ 1 ] Cousot, P. &#38;R. Cousot, Static verification of dynamic \ntype properties of variables, Research Report # 25, Laboratoim d Informatique, U. S. M, G,, Grenoble. \n [ 2 ] Dijlcstra, E. W., Guarded commands, nondeterminacy and formal derivation of programs, Comm. \nACM 18, 8, August, 1975, pp. 453-457.  [ 3 ] German, S.M. &#38; B. Wegbreit, A synthesizer of inductive \nassertions, IEEE Trans. of Software Engineering, Vol. SE-1, No.1, March 1975, pp.68-75, [ 4 ] lhtz, \nS.M. &#38;Z, Manna, A logical analysis of programs, Comm. ACM 19, 4, April, 1976, pp. 188-206. [ 5 ] \nKing, J.C. A program verifier, Ph.D. thesis, Dept. of Comp. Sci., Carnegie-Mellon University, September \n1969, [ 6 ] McCarthy, J. &#38;P. J, Hayes, Some philosophical problems from the standpoint of artificial \nintelligence, Machine Intelligence 4, American-Elsevier , pp. 463-502.  [ 7 ] Suzuki, N., Automatic \nvwification of programs with complex data structures, PtL.D. thesis, Dept. of Comp. Sci., Stanford University, \nSTAN-CS-76-552, February, 1976.  [ 8 ] .!hlzuki, N., Iteration induction method, In preparation. [ \n9 ] Suzuki, N., Frame problems in Floyd-Hoare logic, In preparation. [ 10 ] Wegbreit, B., The synthesis \nof loop predicates, Comm, ACM! 17, Z, Feb. 1974, pp. 102-112.  \n\t\t\t", "proc_id": "512950", "abstract": "This paper describes a system which checks correctness of array accesses automatically without any inductive assertions or human interaction. For each array access in the program a condition that the subscript is greater than or equal to the lower bound and a condition that the subscript is smaller than or equal to the upper bound are checked and the results indicating within the bound, out of bound, or undetermined are produced. It can check ordinary programs at about fifty lines per ten seconds, and it shows linear time complexity behavior.It has been long discussed whether program verification will ever become practical. The main argument against program verification is that it is very hard for a programmer to write assertions about programs. Even if he can supply enough assertions, he must have some knowledge about logic in order to prove the lemmas (or verification conditions) obtained from the verifier.However, there are some assertions about programs which must always be true no matter what the programs do; and yet which cannot be checked for all cases. These assertions include: integer values do not overflow, array subscripts are within range, pointers do not fall off NIL, cells are not reclaimed if they are still pointed to, uninitialized variables are not used.Since these conditions cannot be completely checked, many compilers produce dynamic checking code so that if the condition fails, then the program terminates with proper diagnostics. These dynamic checking code sometimes take up much computation time. It is better to have some checking so that unexpected overwriting of data will not occur, but it is still very awkward that the computation stops because of error. Moreover, these errors can be traced back to some other errors in the program. If we can find out whether these conditions will be met or not before actually running the program, we can benefit both by being able to generate efficient code and by being able to produce more reliable programs by careful examination of errors in the programs. Similar techniques can be used to detect semantically equivalent subexpressions or redundant statements to do more elaborate code movement optimization.The system we have constructed runs fast enough to be used as a preprocessor of a compiler. The system first creates logical assertions immediately before array elements such that these assertions must be true whenever the control passes the assertion in order for the access to be valid. These assertions are proved using similar techniques as inductive assertion methods. If an array element lies inside a loop or after a loop a loop invariant is synthesized. A theorem prover was created which has the decision capabilities for a subset of arithmetic formulas. We can use this prover to prove some valid formulas, but we can also use it to generalize nonvalid formulas so that we can hypothesize more general loop invariants.Theoretical considerations on automatic synthesis of loop invariants have been taken into account and a complete formula for loop invariants was obtained. We reduced the problem of loop invariant synthesis to the computation of this formula. This new approach of the synthesis of loop invariant will probably give more firmer basis for the automatic generation of loop invariants in general purpose verifiers.", "authors": [{"name": "Norihisa Suzuki", "author_profile_id": "81332530584", "affiliation": "Carnegie-Mellon University, Pittsburgh, Pa", "person_id": "PP43124867", "email_address": "", "orcid_id": ""}, {"name": "Kiyoshi Ishihata", "author_profile_id": "81100201740", "affiliation": "University of Tokyo, Tokyo, Japan", "person_id": "PP43129864", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512950.512963", "year": "1977", "article_id": "512963", "conference": "POPL", "title": "Implementation of an array bound checker", "url": "http://dl.acm.org/citation.cfm?id=512963"}