{"article_publication_date": "01-01-1977", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1977 ACM 0-12345-678-9 $5.00 ON THE COVERING OF LEFT RECURSIVE GRAMMARS, A. NIJHOLT Free University Department \nof Mathematics Amsterdam, The Netherlands ABSTRACT. In this paper we show that some prevailing ideas \non the elimination of left recursion in a context\u00adfree grmar are not valid An algorithm and a proof are \ngiven to show that every proper context\u00adfree grammar is covered by a non left recursive grmar. Keywords: \ncover, left-recursion, context-free grammar, parsing. 1. INTRODUCTION. There exists a well-known method \nfor elimi\u00adnating left recursion in a context-free grammar, The motivation for eliminating left recursion \nis for example that certain parsing algorithms do not work for left recursive grammars. However with \nthis usual method the parses of the original grammar cannot, in general, be recon\u00adstructed in a simple \nWWJ from the parses of the non left-recursive grammar obtained by this method. That is, the new grammar \ndoes not cover the original grammar. There has been some research on the covering of grammars by grammars \nwhich are in a certain nor\u00admal form. In general the possibility to cover a grammar depends on the definition \nof cover which is used. Examples of those definitions can be found in [I,P.2761, [2] and [31, and we \nwill discuss them as far as necessary for our purposes in the next section. In [1] en [2] some remarks \ncan be found from which one could conclude that elimination of left recursion changes the structure of \na grammar in such a way that there is no covering grammar. However, in our opin<.on, and not only in \nthe case of elimination of left recursion, the relation between changes of structure (whatever is meant \nby structure) and covers is not so close as suggested. This point is also discussed, though rather infor\u00admally, \nin the next section. In the case of elimi\u00adnation of left recursion we show in section 3 that this can \nbe done in such a way that the grammar obtained covers the original grammar. In the remainder of this \nintroduction we give some definitions and notational conventions. In section 2 we discuss the definition \nof cover and the usual algorithm for eliminating left recursion. In section 3 we give our algorithm for \neliminating left recursion, which is j ust a slight variation of the usual method, and prove its correctness \nand its covering property. Moreover we give an example of the use of this algorithm and we conclude in \nsection 4 with a result which was inspired by a more practical consideration of the elimination of left \nrecursion. Preliminaries . We review some basic concepts concerning formal grammars. This material can \nalso be found in [11. DEFINITION 1.1. A context free grammar (cfg for short) is a four-tuple G = (N,X,P,S), \nwhere N is the alphabet of nontenninazs, Z is the alphabet of terminals, N n I = @ (the empty set), N \nU ~ =V, S e N, and the set of productions P is a finite subset of N x V*.  Instead of writing (A,a) \n< k , we write A + a in P. Let u, v c V*, then u -v holds if there exist x, y, w<V* and AeNsuch that \nu=xAy, v=~ andA+wisinP, If X<E* we write u = v and if * k Ycil we write u = v. The reflexive-transitive \nclosures on V* of these relations are written as &#38; , =&#38; and ~ respec\u00adk tively, while the transitive \nclosures are written + as &#38;, s and&#38;. ,?, r The set L(G) = {x < Z* /S ~ x} is the bz.guage generated \nby G. If U. === u, = U2 = ... B Ur, then this sequence is called a derivation of Ur from Uo. If instead \nof a the relation ~ or the E relation ~ is used, then this sequence is said to be a leftm;st derivation \nor a rightmost derivation respectively. If in a leftmost or a rightmost deri vation of Ur from Uo, for \neach O < i < r, Ui+, is obtained from Ui by applying production IIi = Ai + yi then, in the case of a \nleftmost deri vation the sequence HOH, . . . ~r_l is said to be a Left parse of u r from Uo, and in the \ncase of a rightmost derivation the sequence Hr_,Hr_2 . . . no is said to be a right parse of Ur to Uo. \ni<r, If U. =Sthen each Ui, o 5 is called a sentential form. A cfg G is said to be ambiguous if there \nis w c L(G) such that w has at least two left parses. A nonterminal A is said to left derive x, where \n+ Xcv, ifA~ xct for some a e V*, DEFINITION 1.2, Let Z, and E2 be alphabets. A function f from Xl into \nZ; is extended to a homo\u00admorphism from Z; into Z; by the conditions f(E) = E and f(a1a2. ..an) = f(a1)f(a2) \n. ..f(an). where E is the empty string and ai, 1 s i < n, is in Z The homomorphism f is called fine if, \nfor 1 each a e I,, f(a) e X2 U{S}. DEFINITION 1.3. A cfg G = (N, Z, P, S) is said to be reduced if each \nelement of V appears in some sentential form and each nonterminal of G can derive a string of terminals. \nCfg G is said to be c?ycle free if there is no derivation of the form A ~ A, f or any AeN. G is said \nto be E-free if there are no productions of the fbrmA + E, where A # S, in P. In the sequel we will only \nconsider grammars which are reduced md cycle f~ee. A cfg G is said to be px~oper i.f it is reduced, cycle \nfree and c-free. A nonterminal A is said to be left-recursiva if A&#38; A@for sone ~eV*. Acf g Gis said \nto be left recursive if G has at least one left recur\u00adsive nonterminal. A cfg G is said to be in Greibach \nnormal J orm (CNF) if G has only productions of the form A + aa, * where acZand acN,or S+ E. 2. ELIMINATION \nOF LEI?T RECURSIOrl, First we give the usual method for elimina\u00adting left recursion. Our starting-point \nis a proper grammar G = (N, X, P, S), where N = {Al, A~, . . ..An}. <. ALGORITHM (1) Seti=l. (2) Let \nthe Ai productions be  Ai+Aiml l...l Aiaml~,16216p .16p where no ~., 15 j s p, begins with A if J k \nk<i. Replace these productions by Ai+ 61162]... l~pl~lcil...l~pci> and Ci+m,l-oolmmla,  cil--olamci \nhere Ci is a new non?zerminal. (3) If i = n, then halt. Otherwise, set i = i + 1 andj=l. (4) Replace \neach production of the form Ai+Aja by the productions Ai + ~lal...l~mti, where Aj + ~ll...l~mare all \nthe Aj-productions. (5) If j = i-1 go to step (2). Otherwise set j =j + 1 andgo to step (4).  In general \nwe want to compare the parses of the original grammar G with the parses of a grammar G! obtained from \nG by transformation. Therefore we give a definition which can be found in [11. We assume that the productions \nof each grammar are numbered for identification. We identify these numbers with the productions. DEFINITION \n2.1. Let G = (N, Z, P, S) and G = (N , X,P , S ) be two cfg s such that L(G) = L(G ). In the following \ntwo conditions x and y are variables with domain {left, right}. Let w E L(G ) and let h : P * +P* be \na homomorphism such that (i) if T* is an x-parse for w with respect to G then h(m ) is a y-parse for \nw with respect to G, and (ii) if IT is a y-parse for wwith respect to G then there exists r such that \nh(?rl) = ?r and 7 is an x parse of w with respect to G .  If in (i) and (ii) both x and y are replaced \nby left! , then G is said to ~eft-cover G. If both x and y are replaced by right then we say that G right \ncovers G. If x is replaced by left and y is replaced by right then we say that G left to-right-covers \nG. The definiton of (complete) cover given in [2] can shown to be equivalent to the definition of right \ncover given here if the cover homomorphism h is fine. EXAMPLE . G with the only production 1. S + ab \nright covers G with productions 1. S+aBand2. B+b.The cover homomorphism h is defined by h(1) = 21. G \ncannot cover G with a cover-homomorphism which is fine. In this paper we will only make use of a fine \nhomomorphism. Therefore the definition of right cover used here and the definition of complete cover \nin [2] are equivalent. Now we can ask whether it is possible that a grammar Gf obtained after eliminating \nleft recursion from a cfg G, covers G. Therefore we consider the follow ing two grammars, G1 and G (only \nthe productions are displayed). G1 with productions G with productions 1. S+so 1. ~+o 5. C+o 2. S+sl \n2. S+l 6. C+l 3. S+o 3. S+oc 7. C+oc 4. S+l 4. S+lc /3. c+lc  G is obtained from G, by eliminating \nleft recursion according to the ususal algorithm. It can easily be verified that G neither left covers \nnor right\u00ad covers G In this case we have G left-to-right\u00ad 1 covers G ,, but that is not true in general \nwhich can be seen by eliminating left recursion from the grammar G2 with the following productions: 1. \nS+Aa 5. A+Ao 2. S+Ab 6, A+A1 3. S+o 7. A+o 4. S+l 8. A+l  Now consider the grammar G; with productions \n1. S+c (&#38;) 5. D+o (1) 2. S+cs (&#38;) 6. D+l (2) 3. S +D (E) 7. C+o (3) 4. S +DS (&#38;) 8. C+l \n(4)  In this case we have G; right-covers G,, where the cover-homomorphism h is defined by h(1) = h(2) \n= h(3) =h(4) =&#38;andh(5) = 1, h(6) =2, h(7) =3 and h(8) = 4, which was already indicated between parentheses \nafter each production displayed above. G; is not left recursive and in the following section we shall \nshow that this is not by accident. Notice that the parse trees of G; do not differ very much of the parse \ntrees of G! . The parse trees have the same skeleton, However G is in Greibach normal form while G; is \nnot. This will turn out to be essential. At this moment it is necessary to look at some re marks in \nthe literature. First we quote from [2, p.679I. We would like to say G! covers G if given a parser \nfor G one can construct a parser for G. The motivation for this is that parsers typically handle grammars \nin some normal form. Presented with an arbitrary grmar G it may be possible to trans\u00adform it into a grammar \nG T which is in this normal form. In what cases can a parser for G be used to produce a parser for G? \nFor example, simple top\u00addown parsers will not tolerate left-recursive rules which allow A ~ Ax for some \nnonterminal A and string x. However, given a grammar G there is a grammar G equivalent to G which has \nno such left-recursive rules. Can one construct a parser for G given a parser for G ? We shall prove \nthat the answer is no, given our definition of covering . However the proof is introduced with the \nfollow\u00ading remark [2, p.6861.  We now embark. on the proof of another negative result by exhibiting \na grammar which cannot be co\u00advered by any grammar in Greibach form, Thus the elimination of left recursive \nchanges the structure of a grammar sufficiently that it cannot have a covering grammar, And then a proof \nis given that cfg G1 we dis played above cannot be right-covered by a cf&#38; in CNF. To us it is not \nclear why one can conclude from this that the elimination of left recursion plays such an important role. \nWe can find the same conception in [11 from which we quote (p.283): We should observe that the condition \nof cycle freedom plus no c-productions is not really very restrictive. Every context-free language without \nE has such a grammar, and moreover, any context-free grammar can be made cycle-free and c-free by simple \ntransformations (...). What is more, if the origi nal grammar is unambiguous then the modified grammar \nleft and right covers it. Non left recursion is a more stringent condition in this sense. While every \ncontext-free language has a non left recursive grammar, there may be no non left-recursive covering grmar. \nWe do not know whether the first part of these remarks (elimination of s-productions) is correct, however \nfor the second part (elimination of left recursion) in [1] the reader is referred to the cfg G which \nwe already discussed above and which 1 is on the contrary a grammar for which we can find a non-left-recursive \ncovering grammar. In the next section we shall show that this remark is not correct. 3. ON THE COVERING \nOF LEFT-RECURSIVE GRAMMARS. In this section we give, and prove the correctness of, an algorithm for the \nelimination of left recursion in a cfg such that the cfg ob\u00adtained right-covers the original grammar. \nALGORITHM 3.1. Elimination of left recursion Input. A proper cfg G = (N, Z, P, S), G is left\u00ad recursive. \n(Output. A no~ left-recursive cfg G which ri&#38;ht\u00adcovers G. L!ethod. The following notations are used. \nLet N = {A ,A .,Ar}. The notation (j): An+P (k), 1 2 means that the production j = An+p is mapped on \na production k of grammar G. Initially we have for each production (k): A.n+p (k). This notation, if \nnecessary, is extended to (jl,jg, . . ..j p) :An+P11P21. ..lPD ( K ,ka, . . ..kp) or we say that the \nproductions (jl 32,..., jp) are mapped on the productions (k, ,k2,. .,kp). (Some of the k. s, 1< i Sp, \nmay be E), L (1) Set i=1 (2) Let the Ai productions be Ai+Aia11Aia21 . ..lAiam B1162. . . Bn  (i1,i2, \n. . ..im. ,,o,im+n where each B,i, 1 < j s n, begins with a terminal or some Ak such that k > i. Ifm= \no, go to step (3). Replace these Ai-productions by Ai+Ci I C.A (s, s) 11 DiA; E,E) i ,,12, . . ..im \n)a21  am 621 ... an i ,1m+2,. ..,1 m+n) m+ 1 where C: ,D: and A: are newly introduced .. . nonterminals \n. (3) If i = r, let G be the resulting grammar, and halt. Otherwise, set i = i + 1 andj = 1. (4) Let \nAi+Ajy11Ajy21,..l Ajy2 (r1,r2,...,rq) be all Ai productions of which the right hand sides begin with \nnonterminal A.. We distinguish between two cases (a) a;d (b).  (a). Qj is defined. Suppose we have Aj \nproductions A.+C IC.A! J j JJ s) and Cj-productions (S, ,S2,. ..,SP) cj+x16, 1x~6*l-. -lxp6p where \nX 1< 1<p, may be a terminal or a !2, nonterminal. Replace each production Ai+A.y ~ ~ (ik)> 15k 5q, by \nAi+x7H;yklX2H:yk] . ..]XpHfyk (rk,rk,. ..,rk) and add productions, for 1 S k 5 p, H! + Q~A! (E)J JJ \nH! +Q; (E)J Q;+ ~k (sL) where H; and Q:, 1s !l<p, are newly introduced nonterminals. (b). ~j is not defined. \nSuppose we have Aj productions A. +X16, 1X2~21. ..lxp6p (S1>S2>. ..,SP) J where X9, 1 5 9. 5 p, may be \na terminal or a . nonterminal . Replace each production A, +A.y ~ ~ (rk), I<k<q, by 1 Ai+x1H~yklx2H~ykl \n. ..lXpH~k (rk,rk, . . ..rk) and add productions, for 1 S L 2 p, H!+ fik (Sk) J !. where H:, 1 SI$p, \nis a newly introduced J nonterminal. (5) Ifj = i -1, go to step (2). Otherwise set j = j + 1 andgo to \nstep (4). End of the algorithm. To prove the correctness of this algorithm we need * some additional \nnotations. Let a c V then we have L(a) is the language generated from a s(u) is a sentence in L(a) rs(a) \nis a right parse of s(a) to a R(a) is the set of right parses of sentences in L(u) to a. EXAMPLE . Let \nG be cfg with productions 3< C+ac1. S* AbC 40 C+d2. A+a then R(aC) = {43n nzo}, R(AbC) = R(A)R(C), \nand if s(bC) = band for a certain n, n ~ o, then rs(bC) = 43n for this sentence. Notice that since in \ngeneral G may be ambiguous (that is, one sentence may have more than one right parse), rs(a) is a set \nof right parses. However, the proof is such that without loss of generality we may assume that rs(a) \nis the representation of one of the right parses in rs(d.) and therefore we can handle rs(a) as a string. \nIn the parse trees we display we will, if possible, use AA or where IA a B cl a = x,x2. ..xn, rather \nthan A A r x2 x BXlX2x 12 n THEOREM 301. Euery proper, Left recursive context-free grmar is right covered \nby a non-left recursive eontext\u00adfree grammar. Proof. Let G = (N, I, P, S) be a proper, left recursive \ncfg. We use the notations given above and in algorithm 3.1., hence N = {A1,A2, . . ..Ar}. The cfg obtained \nafter applying algorithm 3.1. is G =(N , Z,P , S). We have to show L(G ) = L(p), G right covers G and \nG is non-left recursive. In the algorithm a sequence of grammars is obtained in the following way. The \nalgorithm starts with cfg G = G, hence i = 1 in the algorithm. Step (2) 11 produces cfg G2,, hence i \n= 2 and j = 1 in the algorithm. Step (4) is applied and gives cfg G22. For i = 2 step (2) is again applied \nand cfg G is 31 obtained. For i = 3 and j = 1 step (4) is applied, result G32, and for i =3and j =2step \n(4) is once more applied and cfg G is obtained. The 33 algorithm halts if Grr has been reached. Hence, \neach G. i>l, is constructed from G 11 kk wherek=i -1, by applying step (2) of the algo\u00adrithm. Each Gik, \ni > 1 and 1 < k 5 i, is construc\u00adted from G. . , where j = k 1, by applying step (4) of the ~lgorithm. \nCLAIM 1. The transitions from Gkk to Gil by step (2), where i = k + 1, and from Gij to Gik by step (4), \nuhere k = j + 1 and 1 c k s i, are Language and cover preserving. Proof of Claim 1. Notice that initially \nwe start with L(GT1) = L(G) and G ,1 right covers G = G,,, and since the cover relation is transitive \nwe can obtain G (= Grr) right-covers G (= Gil). First we are concerned with step (2), transition of G \nto G. ,i=k+ 1. In G wehave kk11 kk productions Ai+Aicxl/Aia2\\... Aiaml(31~21. ..l@ n which we label \nwith a 1 a2  am and b we obtain the productions l b2  bno In Gil (c ,, C2): Ai+C i I CiA; (dl, d2): \nA;+Di I DiA~  lcx2/...lclm (a;, a;, .... a;): Di+a (b;, b;, ... ,b ): C.+6 1621...lf3n n1 We can verify \nthat this transformation is language\u00adpreserving by comparing trees in Gkk and in Gil with roots Ai and \nnoticing that, since Ci, Di and A; are new nonterminals which can only be derived from Ai, these trees \ncan be considered independent\u00adly from the rest of a parse tree. A ,AA, A 3 ,liDfiA, A. a /l 2 lYi aul \na~;D$A! al ;: U2 6L ~ U3 parse tree in Gkk parse tree in Gil (i=k+l) Suppose we have a sentence w in \nL(A,), then this sentence has the form w = S(6L) S(aul) s(au2) . . . S(aup), where 1 S L s n, the a-indices \nare between 1 and m, and in a leftmost derivation p + 1 successive Ai productions (p 2 O) have been used. \nLet p > 0, then in G a right parse for w kk to Ai is of the form rs(~j)bk rs(aul)aul rs(au2)au2 . . . \nrs(u ~p)a UP and in G. we obtain for the right parse the form 11 rs(~L)b~ rs(aul)a~l rs(au2) a;2 O*O \nrs(aup)a d1(d2)p-1 C2. UP Hence, Gil right-covers Gkk with cover homomor\u00adphism h, if we define h(b~)=bfl, \nl~lsn h(a~)=a8,1Sfl Sm h(cl) = h(c2) = h(dl) = h(d2) = c, where h(cl) = E can be verified by considering \nthe case p = O. Each other production of Gil is mapped on itself by h. Now we treat the transition of \na cfg Gij by step (4) of the algorithmto a cfg Git, where t = j + 1. In Gij the productions Ai+Ajy11Ajy21 \n. ..lAjyq are labeled with y,, y2, . . . . yq. We first consider case (a) of the algorithm, Hence we \nhave in Gij the productions (cl, C2): Aj+C. lC.A! JJJ (d,, d2): A;+Dj/DjA; (al, a2, . . ..am). Dj+u1/a21...lam \nt) (b1,b2, . . .,bn): Cj+611621...16n t) Notice that the values of m, n and q depend on i and j of the \nalgorithm. Since our notation will be clear we omit indices. In Git we obtain by step (4a), for each \nproduction (Yk):Ai+AjYk , where 1 5 k < q, the productions Ai+X,H;yklX2H;ykl . ..lXnH.yk, which we label \nwith We also obtain productionsYk2> . ..YYkn. k 1 ( Cj : H;+Q~A! JJ ( e~ (b; If we observe the parse \ntree s for sentences with respect to G. . lJ and G. lt  it is again sufficient to consider sub-trees \nwith roots A . . 1 A. in G. lJ in G. lt For every combination of i and j (1 < i s r and I < j < i), \nstep (4a) is done once at most. It will be clear from the possible parse trees in G. . immediately related \nto the production of grmar G, lJ and G.It that the transformation in step (ha) is language preserving. \nTo observe the cover-property we only consider the ~ase that in the figures given above A~+C~A~ is used. \nThe case A; + C; can J dd dd be treated similarly. If we have a sentence w in L(Ai) then it is of the \nform w = s Xl) S(di) S(A~) S(yk) and a right parse of w to A. with respect to G. . is of the form 1 IJ \nrs(XL) rs(6L) bk rs (A;) c * rs(Yk) Yk and a right parse of w to Ai with respect to Git is rs(XL) rs(dL) \nb~ rs(A~) c~ rs(Yk) Ykl Now it is clear that we can define the cover homo morphism h, such that Git right \ncovers G. ., where lJ h(b~) = b I<k<n !, h(ep) = c,, I<k<n h(c~) = C l<,Q,<n 2 1sk<nand 1<k 5q. h(yki) \n= Yk> Each other production of Git is mapped on itself by h. The definition h(ei) = c1 can be verified \nby considering the case A.+C.. Now we consider case (b). Hence Cj is not d~fin~d. Suppose we have the \nfollowing Aj productions in G. .: lJ j+xl~llxzazl-..]x a P P We label these productions with bl, b2, \n. . ..b P For Git we obtain by step (4b) for each production (yk): Ai+AjYk , where 1 < k < q, the productions \n(with labels Ykl, yk2, . . ..ykp) Ai+X1H;yklX2H;ykl . . . I XpH~yk, and we obtain also the productions \n(b~): H~+6 I < 1 <p. t Now, in the same way as was done in case (a) one can verify that, to obtain a \ncover-homomorphism one has to define h(b~) = b~, 1 < i? < p, h(ykfl) =Yk> 1<E<p and 1<k< q, and each \nother production of G. has to be mapped It on itself by h. Since now we can conclude that step (2) and \nstep (4) are language-and cover\u00adpreserving we conclude G right covers G. Notice that with algorithm 3.1. \nwe obtain immediately the cover-homomorphism for G and G, since every production obtained after a transformation \nis as indicated between parentheses after each production in the algorithm. CLAIM 2, G is non-left recursive. \nProof of Claim 2. First we notice that, since 6L obtained in step (4) of the algorithm may be the empty \nstring, G does not have to be proper. We make the following observations. OBSERVATION 1. Let L(Ai) and \nL (Ai) denote the languages obtained from Ai in G and G respec\u00adtively. The transformations on the productions \nin step (2) and in step (4) are such that for each i we have L(Ai) = LT(Ai). Since G is a proper grammar \nwe have in G Ai %E and Ci~ E, for each A. 1 and Ci. OBSERVATION 2. For each D. , introduced in step (2),1 \nwe have Di % E. To show this we first prove the following property. Suppose we are in algorithm 3.1, \nat the moment we want to do step (2) for non\u00adterminal Ai. Let Ai+ ~yk be a production in Gii, where i \n5 k. Then we have the following property: if yk ~cinG. then Ai ~ in G. li % The proof of this property \nis by induction on i. Basis. Leti=l, then A+ for k 2 1, is also 1 .%yk a production in G. IfTk_ c, then \nsince G is proper e ave 1+% ence 1 % Induction. Suppose this property holds for all p such that p < \ni. We prove that we may conclude that we may conclude that this property also holds for i. Consicler \nAi+Akyk, where i S k, in Gii. If A, +Akyk is also in G, then we have Ai L ~inG 1 * ify -E. Now~ssume \nAi+I$yk is not in G. Hence this pro\u00ad duction is constructed in step (4) of the algorithm and therefore \nit is of the form *) J2j1 Ai+~Hjn . . . H. H 6.~J wheren <k. To obtain this production we started with \na production Ai+Ajldi in G, where i > ,jl, and in *) Notice that the use of indices here is some\u00adwhat \ndifferent of the use in the algorithm. If they are not necessary we omit the upper\u00adindices of the nonterminals \nH and Q (see step (4)). By ji is meant j with index i. step ~4) we used successively the productions \n**) Aj1+Aj2-~1> A..+A. ~ Ajn+ \\yn of J~ J32 G. , G. G. respectively. Jl, jl Jn, jn J~Yj~ According \nto step (4) we have jp < jq if p < q, and thus by the induction hypothesis A. &#38; A JR J(~+l) * for \n1: ksnand A =A. k J(n+l) Ify.l=s 1 S ~ < n. Therefore we have Ai AA in G ir k &#38;i =Eandallyi &#38;E, \nI<i<nandthis . completes the proof of the property. NOW let k = i in this property, then if Di &#38;E \nin G. and hence in G! , we obtain A. =&#38;. A. in 1+1,1 1 1 G, which contradicts the fact that G is \na proper context-free grammar. OBSERVATIOIJ 3. For each Ai we have Ai is not left recursive . We prove \nthis also by induction, Con sider the following two properties of the algorithm. (~.1) After step (2) \nis executed for i, all Ai\u00adproductions begin with either (a) a terminal or a nonterminal Ak, k > i, or \n (b) Ciand the Ci-productiions begin with a terminal or with a nonterminal \\,k>i.  (4.2) After step \n(4) is executed for i and j, all Ai-productions begin with a terminal or with a nonterminal A fork>j. \n k Recall that N = {Al, A2, ..,,A }. In the proof m r is the number of A<-productions of which the \nright hand sides begin with Ai (see step (2) of algorithm 3,1). We define the score of an instance of \n(4.1) to be r.i. The score of an instance of (.4.2) is r.(i-1) + j, where 1 S j < i. We prove (4,1) and \n(4.2) by induction on the score of an instance of these statements. Basis, For i = 1 we only have instance \n(4.1). The transformation in step (2) is indeed such that, if m = O, all Ai-productions begin with a \nterminal or with a nonterminal Ak, for k > i. And if m > 0 then the Ci-productions begin with a **) For \nconvenience we give the productions in G. G. etc. , instead of the even Jl,jl J2,j2 tually ultimate productions \n A. +C. and C. +Aj2y1 etc. Jl Jl J1 te;minal or a nonterminal Ak, for k > i. Induction. (1) Assume (4,1) \nand (1+.2) for scores less than s, andletiandjbe such that O~j<i <r and r.(i-1) + j = s. Since r.j < \ns all Aj productions begin with either (a) a terminal or A k, fork>j, or (b) Cj and the Cj-productions \nbegin with a terminal or A~, fork>j.  Since the transformation in step-_(4) is such that each new Ai \nproduction begins with the begin-symbol of an Aj-(or Cj ) production and, if this symbol is a non\u00ad terminal \n~thenk > j, we see that each Ai-production begins with a terminal or a nonterminal~, fork > j. (2) Assume \n(4.1) and (4.2) for scores less than s, and let i be such that i.r = s. Since (i-1).r + j < s we have \nthat all Ai-product\u00adions.begin with a terminal or a nonterm;nal A k, fork>j, hence for k 2 i, If in step \n( 2) m = O we have that all Ai-productions begin with a terminal or a nonterminal A k fork >i, If m>0we \nsee that after the transformation all Ci productions begin with the first symbol of the Ai-productions \nwhich begin with a terminal or with a nonterminal A~, for k ~i. This completes the proof that each Ai \nis not left-recursive . OBSERVATION 4. From the two properties in observa\u00adtion 3 it is clear that, fdr \neach i, A. cannot 1 left derive a nonterminal H., O S j < r. From J observation 1 and 2 it follows that, \nfor each i, neither Ci nor Pi can derive c. Moreover D. 1 cannmt left derive H. , O S j < r, since this \nwould J mean there is a nonterminal A O s k < r, which k can left-derive H. . J Nonterminal A; can only \ntie introduced in a derivation by the productions Ai+C.A! A! +D.A! 11 1 11 or Hi+Q.A!. Productions with \nleft-hand side A! 11 1 are A~+DiA~ and A;+D. ~. Since Ci ~c and Di ~E the only possibility for A: to \nbe left\u00adrecursive is that A; can left derive H. and Qi &#38;E. However, then also D. can le;t-derive \nH., 11 which is not true. Therefore, for each i, A: and also Di are not left-recursive. Easily can be \nverified that, for each i, Ci is not left-recursive. OBSERVATION 5. For each i we have Hi and Qi are \nnot left recursive (we omit again the upper indices). The proof of this statement is by in\u00adduction on \ni. First we assume that the d s in step (4) are not equal to E, Basis . Let j be the smallest integer \nsuch that H. J is defined. Let Aj +X6 (if m= O in step (2)) or A.+C and Cj+X6 (ifm > 0 in step (2)), \nthenwe Ji obtain Hj+d or Hj +QjlQjA~ and Qj+6 respectively. Since there are no other nonterminals H I<pSr, \nP defined before, 6 can only begin with a terminal or a nonterminal A 1 s k s r. A nonterminal A k k \ncannot left-derive a nonterminal H 1 <p < r. P Induction. We prove that Hi cannot left derive a nonterminal \nH if p > i. Therefore we assume that P the nonterminals H for t < i, cannot left\u00ad t derive a nonterminal \n3 if p > t. P Suppose Hi is introduced for an Ak production, that is, in step (4) we transformed a production \nAk+A y (where q < i) of G, and after all steps (4) f~r this production have been executed the result \nis A +XHiy where X is a terminal or a k nonterminal \\ fork > k. The last production which was applied \nin step (.4) is then of the form A.+X3 (or Ai+Ci and Ci+X6). Moreover we obtain 1 the production Hi+&#38; \nor Hi+QiA~lQi and Qi+ 6. If 6 begins with a terminal or a nonterminal A k 1 S k < r, then, since A cannot \nleft-derive a k nonterminal H 1 <p < ~, Hi is not left-recur P sive. The other possibility is that 6 \nbegins with a nonterminal H where p < i. Then by the P induction hypothesis H cannot left-derive H. . \nP 1 This completes the proof of the induction step. Now assume 6 = E. Then we can have H. &#38;QiA~ >A!. \nHowever A; cannot left\u00ad11 derive Hi. It is easily possible to give a proof of this statement analogous \nto the proof given above, where instead of the 6 s of step (4) we have to consider the U S of step (2). \nSince the nonterminals H. are not left recursive 1 we immediately obtain that the nonterminals Qi are \nnot left recursive. This completes the proof of observation 5. Since we must conclude that all the nonterminals \nare non-left-recursive we have finished the proof of claim 2 and therefore of theorem 3.1.0 Before closing \nthis section we give an example of an application of algorithm 3.1 . We use a grammar which was also \nused in [1 , p.157]. The cover\u00adhomomorphism of G to G is obtained between paren\u00adtheses after each production. \nHence, we immediately relate every production obtained in the transfor mation, to a production of the \noriginal grammar G. EXAMPLE 3.1 Consider the cfg G with productions 1. (1) 5. A3+A A (5) 1 + 2*3 12 \n 2. Al+a (2) 6. (6) 3+ 3*3 A3+a 2+ 3A1  3. (3) 7. (7) 4. A2+A1b (4)  We follow the steps of the \nalgorithm. (1) i=l (2) AI+A2A3+ (1,2) remains unaltered (3) i=2, j=1 (4) Replace A2+A1b (4), where \nA1+A2A3\\a (1,2)  by A2+A2H;b (4) A2 + aH~b (4) H&#38; (1) 3 + (2) (2) Replace A2+A2H~b I aH~b \\ A3A1 \n(4,4,3) by A2+C2 I C2A; (E,E) A;+D2 I D2A; (E E) D2+H;b (4 fJ2+aH~b\\A A (4 3) 31 i=3, j =1 (3) (4) \nRe@xeA3+A1A2 (5), where A1+A2A31a (1,2)  by A3+A2H;A2 (5) 2 (5) 3+aHlA2 (5) j=2 (4) Replace A3+A2H~A2 \n(5), where A2 +C21C2A~ (E,c) and C2+ aH~bl A3A1 (4,3  11 (5) by 3+ A3H2H1A2 * *aH2HlA (5) 4. LEFT-TO-RIGHT \nCOVER 3 112 H;+ Q;A (e) 2 In the preceding section we saw that each H;+ Q; (E) left-recursive grammar \nG can be right-covered by a non-left recursive grammar G . If we look at the Q;+A1 (3) parsing problem \nthen we want to eliminate left H;+ Q~; (s) recursion since a certain top down parsing method H;+ Q; (E) \nwill not work for a left recursive grammar. We want to make the grammar fitting for this top-down Q; \n+W~b (4) parsing method, and this means in general for a (2) Replace parsing method which produces left \nparses. A3+A3H;H; A21A3A31aH;H; A21aH;A21a (5,6,5,5,7) However our algori~hm is only concerned with right \nby A3+C31C3A+ (E,E) parses. Fortunately we can give the following theorem, This theorem can also be found \nin [3] in A>+D IDA! (E,c) 333  a slightly different form. D3+H~H\\A21A3 (5,6) c3+~H~H\\A2]aH~21a (5,5,7) \nTHEOREM 4.1. Let cfg G right-cover G, then there is a cfg G ,The resulting w=mmar G (see below) has 26 \npro\u00adsuch that G left to right covers G. ductions while the original grammar had 7 product-Proof, Let \nG = (N , X, P , S ) right cover ions, The usual method yields 22 productions. The G = (N, Z, P, S) by \ncover-homomorphism h. We usual method was given in section 2. The cfg G! construct a new grammar G = \n(N , 1, P , S ), has the following productions: s = S! and where N = N u{Rill SiS lP l} and A,+A2A3ja \n(1,2) each R. is not already in N1 . 1 A2+C21C2A; (E,&#38;) P = PI UP2, where A~+D21D2A~ (:E,E) P, = \n{(i ): A+uRil (i): A+ctXi is inP } and D2+H\\b (4) Pn = (i ): R,+X, ~, l(i ): A+uR, is inP.}.L1 L1 If \nT is a parse tree of G for a sentence w then C2+aH~blA3A1 (4,3) there is a corresponding parse tree T \nof G for H~+A (1)3 w which is obtained from T by replacing each Hf+E (2) occurrence of a subtree T: in \nT! of the form A3+C~CA! (E,E) A by a subtree T; 333 Ax of T of the form AR A;+D IDA (E,E) a IY, 333 \n1 D3+H;H;A21A3 (5,6) r xi C3+aH~H~A21aH~A21 a (5,5,7) These occurrences of subtrees in T and T of these \nforms are said to be corresponding. In T; H;+ Q;A;lQ; (E,E) the productions (i ): A+aRi and (i ): Ri+X. \n1 H;+ Q;A;IQ$ (E,E) are said to be connected. Notice, that if rr is a Q;+ Al (3) parse of w with respect \nto T and r is a parse of w with respect to T then for each occurrence Q;+ H% (4) of i in T there is only \none corresponding pair i Notice that G is not proper since H~+E. and if in T . Similarly, for each occurrence \nof i in m there is only one connected occur~ence of ,! 1. Now the proof is rather simple. Let T be a \nparse tree of G for w and T its corresponding parse tree of G . A left parse n for w with respect to \nT in which productions i and j occur can be written in one of the following forms: all . Tr Z . ..i . \n..j!. ..i . ,.i . . ..or b . v ? . ..i . ..i . ..j .. .j . . . . or symmetric cases {first j ), where \ni and i are connected and j! and j are connected. For these cases the right parses with respect to T! \ncan be written as: a . m! : . ..j. ..i... (for case a .), and b . T . ..i. ..j... (for case b .), where \ni corresponds to the connected pair i and i and j corresponds to the connected pair j and j . For i \n#j a form c . n Z ., .i . ..j . ..i . ..j . . . cannot occur in a left parse. For i = j there are no \nproblems as can be seen in what follows. Since the order in which i and j appear in n is the same as \nthe order in which i and j appear in Tr we can define a homomorphism h such that, for each i and i , \nh (i ) = i andh (i ) = E and then G left to right covers G with cover homomorphism h . The composition \nof h and h gives the cover-homomorphism f of G left-to\u00adright covers G, that is, f(i ) = h(h (i )) and \nf(i ) = E for each pair i and i in P , D Since in this theorem G is not left-recursive if G is not left \nrecursive a top-down parsing method can be used for G and the left parses with respect to G can be mapped \non the right parses with respect to G. 5. CONCLIJSIONS. We showed that some remarks concerning left recursion \nin the literature are not true. An algo\u00adrithm was given to transform a left recursive grammar G to an \nnon-left-recursive grammar G such that G right covers G. We showed that the use of right parses in this \nalgorithm is not restrictive in a practical situation in which we want to eli\u00adminate left-recursion to \nhave the possibility to apply a top-down parsing method which yields left parses . There are some problems \nwe did not consider. Can the elimination of &#38; productions be done in such a way that the result is \na covering grammar? According to some remarks in [11, that we gave in section 2, we can conclude that \nif a cfg is ambiguous then elimination of E productions can not lead in general to a covering grammar, \nand if a cfg is unambiguous then there is a covering grammar. However, the following grammar with productions \nS+LSO/LSl10/l and L+&#38; is not ambiguous and we conjecture that this grmar is not right-covered by \nan &#38;-free grammar. Further more we can ask to prove the conjecture that grmar G1 of section 2 cannot \nbe right-covered by a cfg in GNF even if we do not restrict ourselves to a fine cover-homomorphism. ACKNOWLEDGEMENT \nI am grateful to prof. L.A.M. Verbeek for some helpful comments. The research reported in this paper \nhas been carried out at the Twente University of Technology, I thank ms. Marja Verburg for her beautiful \nand careful typing of the manuscript. REFERENCES. 1, Aho A.V. and Unman J.D., The theow o.f parsing, \ntrans2aiion and com~ilkg , Vol. I and II, Prentice Hall, Englwood Cliffs, 1972 and 1973. 2. Gray J. and \nHarrison M.A., On the covering and reduction problems for context\u00adj%e grammars , J. Assoc. Comput. Mach. \n19, (1972), No.4, 675 -698. 3. Nijholt A On the covering of parsable g&#38;nmars , to appear in J. Comp \n. Syst. Sei.  \n\t\t\t", "proc_id": "512950", "abstract": "In this paper we show that some prevailing ideas on the elimination of left recursion in a context-free grammar are not valid. An algorithm and a proof are given to show that every proper context-free grammar is covered by a non-left-recursive grammar.", "authors": [{"name": "A. Nijholt", "author_profile_id": "81100266864", "affiliation": "Free University, Amsterdam, The Netherlands", "person_id": "PP14101128", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512950.512959", "year": "1977", "article_id": "512959", "conference": "POPL", "title": "On the covering of left recursive grammars", "url": "http://dl.acm.org/citation.cfm?id=512959"}