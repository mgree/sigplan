{"article_publication_date": "01-01-1977", "fulltext": "\n EXPRESSION CONTINUITY AND THE FORMAL DIFFERENTIATION OF ALGORITHMS* Permission to make digital or hard \ncopies of part or all of this work or personal or classroom use is granted without fee provided that \ncopies are not made or distributed for profit or commercial advantage and that copies bear this notice \nand the full citation on the first page. To copy otherwise, to republish, to post on servers, or to redistribute \nto lists, requires prior specific permission and/or a fee.&#38;#169; 1977 ACM 0-12345-678-9 $5.00 Eob \nPaige and J. T. Schwartz Com~uter Science Department Courant Institute of Mathematical Sciences New York \nUniversity Abstract: This paper explores the technique of strength reduction or formal differentation \nin a set theoretic context, as recently introduced by Earley. We give pragmatic rules for the recognition \nand treatment of reasonably general cases in which the optimization is applicable, and consider some \nof the problems which arise in actually attempting to install this optimization as part of a compiling \nsystem. 1. Background. Continued development of very high level languages depends in part on our ability \nto recognize common major aspects of programming style as resulting from the application of some standard \ntechnique of program improvement to an underlying program prototype. A technique of program improvement \nthat we are able to perceive as general can become the basis for a general optimization method; and once \nthis method is in hand, we can safely write programs in relatively simple unoptimized forms, since their \nmore complex optimized forms will be seen as obvious improvements, derivable mechanically or semi-mechanically, \nfrom these simple forms. An interesting new high level optimization of this form has recently been described \nby Jay Earley [El]. This optimization was applied by Earley to his proposed language VERS2 [E2]; but \nhis ideas carry over easily to other set\u00adtheoretic languages such as SETL. Earley s optimization technique, \nwhich he calls iterator inversion and which we shall prefer to call formal differentation, generalizes \nthe classical method of reduction in operator strength!, for which see [AI,CI,C2,KI-K5]. The basic formal \nidea of this technique can be put as follows. Suppose that an expression C = f(xl, . . ..xn) will be \nused repeatedly in a program region R, but that its calculation cannot be moved outside R because its \nparameters Xl, . . ..x are modified within R. If we make C available on n each entry to R (by calculating \nit before entry) and keep C available within R by recalculating it each time one of its parameters is \nmodified, then we may be able to avoid all full calculations of C within R. For this approach to be reasonable, \nthere must be some way of recalculatin~ C more easily after its parameters are modified than by calculating \nC afresh each time it is required. For this to be the case, we are likely to require two conditions to \nbe satisfied, which we may describe heuristically as follows: (a) Within R, all changes Xj = h(xl, . \n. ..xn) to the parameters Xj should all be minor! or small! . (b) For each such assignment, there should \nexist an update identity f(xl, . . ..x.  ~_l, h(xl,.., xn), xj+l,..., xn) g(xl>.., xn), f(xl,.., xn)) \n*Work su~ported by NSF under Grant NsF-McS76-00116. 58 which allows the new value f ~TFhJ of f to be \ncalculated from its old value fold by an easy! calculation f ~~~1 = ~(xl!. ..,xn>foLD). If this is the \ncase, then we sav that the expression f is continuous in its ~arameters (relative to the modifications \noccurring within R). The application of this idea in the set-theoretic setting was initiated by Earley \nand has been pushed further by Fong and Unman [Fl ] who made the interesting observation that formal \ndifferentiation in a set-theoretic setting could actually improve the asymptotic beh,avior of an algorithm \nand that this fact coluld be used to develop a theoretical characterization of the situations in which \nthis techniaue applied. In the discussion which follows, we shall pursue Earleyls idea in a less formal \nsense than Fong and Unman, aiming to state pragmatic rules for the discovery and treatment of reasonably \ngeneral cases in which formal differentiation can be applied. 2. Initial Examples. In SETL the computations \ns = s + {x} and s . s - {x} respectively add and delete the value of the element x from the set s. Both \noperations change s only slightly . Similarly, if s and t are sets and the number of elements of A, \n#A, is much smaller than #s, then modifications of the form s = s t A, represent slight changes to \ns. If f is a set of pairs used as a SFTL mapping, then the operation f(x) = z, which replaces all pairs \nwhose first element is x by the pair <x,z> causes f to change slightly. If f is a set of (n+l)-tuples \nused as a multi-parameter mapping, then the indexed assignment f(xl ,. . . ,xn ) = z alters f only slightly. \nIf in a strongly connected region R all changes to variables which are sets or mappings are slight modifications \nof the kind just described, then these variables can be called induction variables within the region \nR. Examples of SETL expressions continuous in all of their parameters are: set union S+t, set intersection \ns * t, and set difference s - t. For example, if we consider the expression s -t, then if s undergoes \ndifferential change s=stA, the value C of s-t can be restored by executing the corresponding code, (1) \nC . C+ (A -t), or C:C.A Similarly, if t undergoes a small change t=t?A , we can update C by performing \n(2) C = C- A or C = C+ (A * s). As Earley has emphasized, expressions involving set-formers provide more \ninteresting examples of this phenomenon of continuity . The SETL expression (3) c.{xeslf(x)g Q} which \ncomputes the set of all values of the set s such that the boolean valued subexpression f(x) ~ q holds \nis a prototypical example. This expression is continuous in s and f, but discontinuous in q. If s is \nvaried slightly by s = s f A then C can be updated by executing (4) C = C t {x= A j f(x) ~q} which represents \na small change to C. When f is changed by executing the indexed assignment f(yO) = z, then C can be updated \nby executing (5) c . if yO e s t,hen C - (if f(y) ~ q then {yO} else nullset) + if z ~ q then {yO] else \nnullset; just before the assignment f(yO) . z. 3. Formal Differentiation of Set Theoretical Expressions \nContinuous in All of Their Parameters. We now formulate a few general rules concerning the formal differentiation \nof set theoretical expressions continuous in all of their free parameters. It must be observed that none \nof the transformations which we are studying can safely be applied to expres\u00adsions containing operations \nwhich cause side effects that are used; for which reason we shall always assume such operations to be \nabsent in the expressions we treat. We also assume that typefinding is applied prior to any attempt to \noptimize by formal differen\u00adtiation; so that object types are known during the analysis of a program \nfor reduction. Consider the set-theoretic expression (1) C={x~sl K(x)} in which K(x) is any boolean-valued \nsubexpression containing only free occurrences of the bound variable x, and containing no free instance \nof the set, s. Suppose that the expression (1) is used in a strongly connected region R and that the \nfollowing conditions hold: (i) The boolean valued subexpression K(x) contains m free occurrences of \nan n-ary mapping f (in which each such occurrence has at least 1 parameter expression involving x? the \nbound variable of the set former); all other free variables occurring in K are loop invariant. (ii) \nf and s are induction variables of R; i.e., inside R, s is only changed by slight modifications of the \nform s = s fA, where A is a small set in comparison with s, and f is only changed by indexed assignments \nof the form  f(Y1,Y2, . . . ,Yn) = z. Then we can formally differentiate the expression (1) in the region \nR. Let C be a compiler-generated variable, to be associated with the value of the set former expres\u00adsion \n(l). We will say that C is available on exit from a program point p if C is equal to the value which \nthe expression (1) would have if evaluated immediately after the statement at p is executed; C is available \non entrance to D if C is available on exit from all predecessor points of p. If C is available onentrance \nto p, and if C is not available on exit from p (which will happen when execution of the state\u00adment at \np changes the value of a parameter upon which the value of expression (1) depends), then we say that \nC is sDoiled at P. To differentiate the expression (1) within a strongly connected region R, we begin \nby making it available on entrance to R. This is done by inserting the assignment c = {XG sIK(x)} into \nRts initialization block. Then , at each point p inside R where the value of the induction variables \ns or f can change, the value of C (which could be spoiled at p) will be updated by inserting appropriate \nslight modifications c = c i cl, where Cl is a small set relative to C; this keeps C available after \nexit from p We sha: 1 now proceed systematically to discuss continuity properties of the expression 1) \nand associated update rules for C for two cases (illustrated by fragmentary examples in section 2 above): \nsmall changes in the set s, and changes to f which result from an indexed assignment. Rule 1 : Either \nbefore or after each occurrence in R of a small change to s, s z s *A, we can insert the differential \nupdate operation (2) C = C i {x= A I K(x)} which preserves the value of (1) in C. Rule 2: Suppose that \nthe boolean subexpression K of (1) contains m free o~currences of the n-ary mapping symbol f. Suppose \nalso that these m occurrences of f appear in r different terms, f(P1 l(x),..., Pin(x)) 7f(P21(x), . ..!D2n \n(x) ), . . ..f(Prl (x)...., Pm(x)), where p ij(x) represents the j-th parameter expression (involving \nx which is the bound variable of the set former) of the i-th term. Then at each point p in R in which \nthe n ary mapping f is changed slightly by an indexed assignment, make the following program transformation: \nRelative Position ~inal Code P f(xl, . . ..yn) =2 Differentiated Code. P-2 = {x c s p,,(x) QY, L... \n! Pin(x) avn Qr 2 . . . MD rl(x) w Y, ~...k Pm(x) EQYn } p-1 c = C-{x~s21K(x)} P f(Y1, . . ..Yn) =Z \np+ 1 C=C+ {x~s21K(x)} It can be shown that rule 2 is a corollary of rule 1. To see this, consider the \nset = {<Pi~(x ), -.. ,Pin(x)>lx E }. Let pi be the mapping whose domain is s and f. wh~se value is pi(x) \n= ~pil(x) l.. .,Pin(x)> . Then for any n-tuple <Yl, . . ..yn>. we have Pi-l(Y1, . . ..YI. ) = {x ~ slpil \n(x) Qyl &#38;...&#38; Pin(x) =Vn}. If s changes by deletion of pi (yl, . . ..yn). then Df changes by \n~letion of the n-tuple <yl, . . ..Yn>. Moreover if s is modified b$ deletion ofj~l pi - (Y1, ,.. ,Yn), \nthen the n-tuple <yl, . . ..yn> is removed from the domain of all the f terms occurring in (l). Next \nwe observe that if C is available on entrance to p (i.e., is available just prior to the modification \nto f by the indexed assignment f(yl, . . ..yn) = z), and if r <y, ,.. .,Yn> ~ .:Df. just before point \np, then the statement f(yl, . . ..yn) = z does not causel~lsi&#38;nificant change in any of the occurrences \nof fin (l). Consequently, C is not spoiled by assignment f(yl, . . ..yn) = z and hence, it remains available. \nSuppose now that in expression (1) C is available on entrance to the program point p. Then we could \nproceed as follows: (1) at P-3, ~ut S2 equal to the set r -1 u p. (Y, ,,. -.,Yn ); (2) at P-2 delete \nS2 from s; (3) at P-1 update i=l 1 C in accordance with rule 1; (4) at p+l add S2 back to s; and (5) \nat P+2, use rule 1 again to update C. This would give us the following code: P-3 = {Xes I P~~(x) ~Y~ \n...&#38; Pin(x) QYn 2 ~... m Prl(x) Q YI &#38;...&#38; Pm(x) Q!cl Yn} p-2s. s-s2 (3) P-1 c = c-{X ES2 \nIK(x)] P f(Y1, . . ..Yn) =2 p+1 s= S+s 2 p+2 C=C+{X=S21K(X)} In this code C is not spoiled by the statement \nf(yl, . . ..yn) = Z. Hence, if C is available on entrance to p-3, then by Rule 1 we know that C remains \navailable on exit from p+2. And now finally, since in (3) the value of the set s is the same before D-2 \nas after p+l , and because s is not used between p-2 and P+I, the code (3) is , equivalent to that shown \nin Rule 2. The assumption that at least one of the parameters in each f term in K involves x (the bound \nvariable of the set former) will usually cause the set S2 to be small in comparison with s. Then, by \nthe continuity properties stated in Rule 1 , we can conclude that the modification to C appearing in \nRule 2 is small compared with the set C itself. The code generated by Rule 2 can be improved by eliminating \nredundancies in the expression K(x)] which appears at locations p-1 and p+l. Suppose we know $=s21 that \nS2 . Ri, where R ,...,Rr are disjoint sets. Then {x GS2 I K(x)} i~l ~1 can be rewritten as U {x GRi I \nK(x)}. Suppose also that in each set {X G Ri I K(x)} K(x) c~~lbe transformed (by elimination of redundant \noperations) into an equivalent but easier-to-evaluate expression Ki(x). Then it may be worthwhile to \nwork with the partition $Ri} of S2 instead of S2 and to rewrite {X c S2 I K(x)} as ~~l{x GRi I Ki(x)} \n. As an exarnp~e of this, observe that if we let Ri = {x G (s-~;. Rk) I PiI(x) Q Y1 &#38;...&#38; Pin(x) \nQ yn}, where RO . 0, ;orm a partition of s2. Moreover, on the set Ri we can replace hen l . . Rr the \nterm f(pil (x) ,.. .,pin(x)) which appears in the expression K at location p-1 of the code generated \nby Rule 2 by f(yl, . . ..yn) (cf. (3) above). This can lead to a version of line p-1 of (3) which is \nrelatively easy to evaluate. As an example of the redundancy elimination method just outlined, consider \nthe following example: (4) c= {x Gslf(f(f(x+ 1) + l)) Q. f(f(x+ 1) + l)}. Suppose that the mapping f \nis changed slightly by an indexed assignment, f(yo) = z which occurs at a program point p. Then to update \nthe value of (U) we proceed as follows. First a partition RI, R2, R3 is computed. (Note that this is \nnot precisely the partition described above: rather, it arises from that partition by a further formal \ntransformation, which for simplicity we omit.) Observe that this partition contains three sets because \nonly three different f terms occur in the boolean subexpression in (4): these are f(x+ 1), f(f(x+ 1) \n+ 1), and f(f(f(x+ 1) + l)). Since f(x + 1) is the only f term of (4) whose Parameter expression involves \nno f term, we put R . {x=s I(x+ 1) QYO}. Since the 1 parameter part of f(f(x + 1) + 1) involves f(x + \n1), we set = {x= (S-RI) I f(x+ 1) + 1 QyO} 2 and similarly, we put = {x e (s-(Rl UR2))I f(f(x+l) + 1) \nQyO}. 3 The code generated to update (4) is then as follows: .{xEslx+laYo}; 1 x G (S-RI) I f(x+l) +1 \n~ YO}; 2 x E (s-(R, * R2)) I f(f(x+l) + 1) @lYO}; R3 = C = C-{x= RI I f(f(f(yO) + 1)) ~f(f(yO) + 1)} \n-{XC R2 I f(f(yO)) ~f(yO)} -{x~R?If(yO) Q YO} ; . f(yo) = z; C = C+ {x= R , I r[rtz+l)) ~ f(3+l)} +{x=R2 \nI f(z) -z} + {xc R31ZQYO); AS noted by Earley, the method of formal differentiation which has been described \ncan be extended in a useful way to apply to various SETL expressions that implicitly contain set formers. \nAmong these are the forall iterator (i.e., (VX C s\\K(x)) , block), the existential and universal quantifiers \n(i.e., Ix=s I K(x) and VXGS I K(x) ), and the compound operator (i.e. [<binop>: x G s I K(x)] e(x) ). \n62 To formally differentiate these expressions, we rewrite them by replacing the implicit set former \nsubpart, x= s I K(x), which they contain with x e {u e s I K(u)}. The set former subex~ression thus ex~osed \ncan then be differentiated usj.ng Rules 1 and 2. Let us now consider more closelv the SETL compound \noperation (5) = [bino~: x G Cl e(x) , c1 an illustrative example of which [+: x G C] e(x) calculates \nthe value ~ e(x). In general, [binop: x ~ Cl e(x) means e(xl) bino~. ..binop e(xn)where Cx=c{x I - xn} \nFor the general case in which the binary operation binoD has an appropriate inverse, inverse binoD (e.g. \narithmetic binary + with -as its inverse), we note that (5) is continuous relative to slight changes \nin C; i.e. , before an occurrence of the code C = Cf A, Cl can be updated by an appropriate inexpensive \nchange, either (6) = Cl MQQ12[U: XG (A C)] e(x); c1 or (6 ) Cl = Cl inverse binop[binop:x (A*C)] e(x); \nApplying the heuristic rule continuous functions of continuous functions are continuous to Cl of (5) \nand C of (1) yields update identities for a more general compound opera\u00adtion form (7) C= [binoD: xc s \nI K(x)] e(x) . In order to formally differentiate the expression (7) in a strongly connected region R, \nwe require all the conditions imposed on (1) to hold, and also require that neither the set s nor the \nn-ary mapping symbol f occurring in K should appear in the subexpres\u00adsion e of (7). If all these conditions \nare met, we differentiate (7) by first making it available on entrance to R. This is accomplished by \ninserting the assignment (7) into R s initialization block. Next, within R at each point p where C can \nbe spoiled by modifi\u00adcations to the induction variables s or f, we can apply the following continuity \nrules for (7) that parallel rules 1 and 2: Rule 3: where s is modified in R by the code s = s ? A, the \nvalue of (7) can be maintained in C by executing (7 ) C = C binoD[binoD: x e (A -s) 1 K(x)] e(x) or (7 \n) C = C inverse binoD[binoD: x C A * slK(x)]e(~) respectively. A similar rule analogous to Rule 2 can \nbe stated to cover the case of changes to f. These rules imply continuity properties for many other high \nlevel SETL operations. The counting operation applied to a set former; i.e., #{x G s I K(x)} can be treated \nas [+: x~s I K(x)] 1. When side effects of the existential and universal quantifiers can be ignored, \nthen the corresponding SETL forms 3X ~ s I K(x) and fx ~ s 1 K(x) can be rewritten as [+: x= s I K(x)] \n1 ~ O and [+: xesl@K(x)]l M O respectively. Set inclusion (the predicate R ~ S) is continuous in both \nS and R since in SETL, R~ S can be handled as [+: x= s I x notin R] 1~ O. 63 4. Differentiation of Set-Formers \nContaining Parameters on which They De~end Discontinuously. Most SETL expressions will not be continuous \nin all the parameters on which they depend. For example, the set former (1) c. {x~slf(x,q)aq} is continuous \nin s and f, but it is discontinuous relative to changes in q. Suppose that the expression (1 occurs in \na strongly connected region R, and suppose also that all changes to s and f are slight within R. Then \nif we know the set D of all values q that q can take inside R, the computation (1) can be removed from \nR according to the following general form: 1 differentiation scheme: (a) define a map C(q) = {x~s I f(x,q) \nQ q} for all values q ~ Dq on entrance to R;  (b) whenever differential changes to s or f occur in R, \nmodify each stored set C(a) according to rules 1 and 2 (cf. section 3) for all values q ~ D ; e.g. after \n  Q s . s + A we can perform the following update code: (~q GDq) C(q) = C(q) f {X~ A I f(x,q) ~q}; \n (c) whenever q changes in R nothing more is needed; (d) replace all computations (1) in R by C(q). \nThree major problems can easily make this approach infeasible:  (a) storage of all the sets C(q) may \nbe too expensive; (b) updating all the sets C(q) when a parameter upon which C depends continuous y \nis modified may waste more time than is saved by avoiding the calculation of C  (c) storage of the \nset Dq may be too expensive. Nevertheless, these problems can be overcome in cases in which we know that \nwhen an expression E must be stored as a map, the map will be continuous relative to differential changes \nin the ,continuity parameters of E (i.e., update operations are only required ove a small part of the \ndomain of the map). Fortunately, this property holds for a few special cases of common occurrence in \nSETL programs. One such example is (2) .{xeslf(x)Qq} c1 If, on entrance to R, Cl is stored as a map Cl(q) \ndefined on Dg, and if s and f are induction variables of R, then (2) can be differentiated profitably. \nAfter the occurrence of s . s + A , we can invoke the update rule (3) (Vx 6 A I f(x) ~Dq) Cl (f(x)) = \nCl (f(X)) * {X};; Whenever the indexed assignment f(xo) . z occurs, the following inexpensive code can \nbe executed:  (4) if X. c s ~ f(xo) ~ Dq then Cl(f(xO)) = Cl(f(xO_)) -{Xo];; f(xo) = z;  if x o G s \n~ f(xO) ~ Dq then Cl(f(xO)) = Cl(f(xO)) + {xO};; Example (2) above typifies the treatment of a somewhat \nbroader class of expressions that can often be differentiated profitably. Within this class we consider \nthe set formers (5) C={X~s I K1(x)~K2(q 1,. ..,qt)] , where ql, . . ..qt are free variables upon which \nC depends discontinuously, We assume that K, of (5) is a subexpression only involving x, parameters upon \nwhich (5) depends continuously, and maps fi upon which C can depend discontinuously but whose occurrences \nin K ~ all have parameters depending on x. K2 of (5) is assumed to be a subexpression only involving \nthe parameters ql ,. . . ,qt on which C depends discontinuously, and 64 also the maps fi. We assume that \nexpressions estimating DQ ,... D Qt are either available at compile time or are computed dynamically \nand are aval ? able on entrance to R. We can simplify (5) by substituting a new free variable b for \nK~(cI ,.. .,at); then we compute Db and keep the value C . C(b) available for every va ueb~D b The preceding \nresults aD~ly in an interesting way to a class of set formers typified by (6) c = {x E s I f(x) ccl} \n, where the relative changed by correction free to a variable q is small chan~es in computation Q = \na set. s and q t cl, Recall relative where from section to indexed #al << #a , 3 that (6) is continuous \nassignments to f. If a is then the corresponding update (7) C = C f {x = S I f(X) c Ql} will often represent \na small change to C. However, because the set former in (7) still requires an iteration over s, this \nupdate computation will often be too expensive to allow profitable differentiation of (6). For this reason, \nit is appropriate in handling (6) to use the identity {x~s/f(x)~ql}=b&#38; {x=slf(x)~b]. The sets C = \n{x G s I f(x) w b} whi~h then appear can be treated by the methods sketched earlier in the present section, \nwhich require that we store a map C (b) for all b in an appropriate domain set Db. Then the u~date operation \n(7) can be replaced by the less expensive code (8) c = c t [+: b~ql] C (b) . Set formers involving boolean \nvalued subexpressions involving comparison operations such as (9) ={xeslf(x) <a] c1 can sometimes be \ntreated as special cases of (6). To see this, let M be the largest q value that needs to be considered, \nand let m be the minimum value of {f(x), x G s} over all f and s that can appear. Putting sa . {b, m \n~ b < q}, we see that (9) is equivalent to {x ~ s I f(x) ~ sq}. If q changes slightly by q . q t ql , \nthen sq changes, also slightly, by sq = sq +{b, q< b<q+al} or by Sq = sq-{b, q-ql<b~q}. Thus to update \nCl we can simply execute (lo) = c1 + [+: q~ b <q+al] C (b) c1 or = c1 -[+:q-ql < b < q] C (b) c1 as appropriate. \nAnother class of special cases derives from (11) c={x= s [c1=f(x)} a set former which despite its close \nresemblance to (6) must be handled very differently. Whereas (6) is continuous in all of its parameters, \n(11) is discontinuous in q. Thus we must save the value of C in a map C(q) defined for all values q Applying \nRule 1 of the last section to (11) we derive the update computation (12) (VQ~ Dq) C(q) = C(q) * {x= A \nI q= f(x)};. When D is small, (12) can be expected to be inexpensive. When Dq is large, we may q wish \nto extend the iteration (12) not over all of Da but only over the smaller set (13) C ={q~Dql (3x~Al q \n~ f(x))} which can be rewritten equivalently as (14) c = [+: xeA]f(x)*D q  5. A Few Preliminary Remarks \non Im~lementation To implement formal differentiation rules sketched in the preceding pages, we will \nneed to perform the following steps: (1) Develop an algorithm which, given parsed SETL code P plus possible \nadditional information including use definition chains, type analysis, declarations describing the relative \nsizes of sets and maps, etc., finds all the expressions E = E(xl, . . ..xn) in P which can profitably \nbe formally differentiated. (2) Formalize rules (as we began to do in sections 3 and 4) for updating \nall basic differentiable forms of SETL expressions. (3) program the transformations (of parsed code \nP) which apply these update rules in several possible ways, one of which is not to apply them at all. \nThese transformations must in effect match nonelementary SETL expressions to basic elementary patterns, \nand must then carry out appropriate symbolic calculations . To avoid involvement with unprofitable cases, \nwe suggest the following heuristic: differentiate an expression E . I?(x1, . . ,xn) only if either (a) \nit is continuous in all the parameters changed within some strongly connected region R; or (b) it is \ndiscontinuous in some parameters which vary within R but the map ~ need\u00aded to store its values is continuous \n: n all the parameters x: in which E is continuous; i.e., only a few values of ~ need to be changed when \nXj is c~anged slightly (recall the discussion of objectins (a) and (b) of the previous section). Since \nthe transformations which are actually applied will leave behind large numbers of expressions which can \nbe simplified very greatly by the application of constant folding, dead code and redundant expression \nelimination, etc. , it is important to incorporate these cleanup optimizations into any formal differentiation \nscheme. (4) Select the most profitable of the program versions which result from application of the \ntransformations (3). In the next section some of our implementation ideas will appear implicitly in our \nmanual optimization of a simple program.  6. How Automatically Can Formal Differentiation be AD plied? \nStudy of an Example. To come to terms with the above question we consider a simple example --Knuth s \nTopological Sort (this example is also studied in Earley, OD. cit.). The input assumed by this algorithm \nis a set s and a set of pairs SD representing an irreflexive transitive relation defined on s; as output, \nit produces a tuple t in which the elements of s are arranged in a total order consistent with the partial \norder SD. A concise SETL form of the algorithm is as follows: (1) t = nultuple; (while ga ~ s \\ sp{a} \n* s ~ nullset) t . t + <a>; /* tuple concatenation */ s =s {a}; end while; The while loop L of (1) contains \nonly one nonembedded expression which is not already in a most reduced form such as might be found in \na table of such forms. This is the existential quantifier (2) 3a es I sp{a} * s~nullset Since use-definition \nanalysis will reveal that a, the bound variable of the quantifier, is used within L, we transform (2) \ninto (3) qa C {x ~ s I sp{a} * s~ nullset}. This prepares for an attempt to differentiate the set former \nexpression {x e s I sp{a} * s w nullset},whose value we will call ZRCOUNT. The elementary pattern describing \nZRCOUNT is {x ~ sIK(x)}, where K(x) is the subexpression SP{X} * s Q nullset. In ZRCOUNT s is already \nin a reduced form. Thus, to reduce the expression ZRCOUNT, we must reduce its subexpression K(x). To \nreduce K(x) we first rewrite it as ((sp{x} * s) S nullset)&#38; (nullset s (sp{x} * s)), which simplifies \nto (SP{X} * s) S nullset. This last expression is in turn transformed into [+: y G (SD{X] * s) I @ y \nG nullset] 1 eQ O, and then again into [+: y G Sp{x} * s] 1 g o. To reduce integer equalities, we will \nalways require that both arguments of ~ be reducible. The parameter O of the preceding expression is \nelementary; the second parameter K2 . [+:y G SP{X} * S1 1 of the immediately preceding equality is reducible \nonly if the subexpression K3 = SP{X} * S is reducible. We observe that K3 is continuous with respect \nto the induction variable s but not with respect to x or SP. However, SP is a region constant of L, and \nhence, K3 can be reduced to a map :3(x) depending onlY on the single discontinuity parameter x. Furthermore \n~3 is continuous relative to small changes in s; i.e. , at each small change s = s k A , K can be updated \nby 3 executing the code (4) (Vy = [+: X = A] SUCC(X)) ~3(y) = ~2(y) f Sp{y} * A;; where Succ(x) = {y \n= s I x e sP{y?} is an auxiliary map introduced when we apply the general differentiation rules sketched \nin the preceding pages. On,ce this transformation has been applied to K3 , we can go back and attempt \nto differentiate the expression K2 . [+: y eY3(x)l 1 which led us to consideration of K The expression \nK2 is discontinuous with respect to changes to x and inde xed 3. assignments to ~3, but continuous (cf. \nRule 3 of section 3) with respect. to differential changes to each set ~3(x). Thus K2 can be reduced \nto a map~ 2(x) (defined over all x G s) depending only on the discontinuity parameter x. The update rules \nwhich must be applied to ~2(y) when R3(Y) = Tq(y) f A is executed ., are respectively as follows: (5) \nX2(Y) = ~2(Y) + [+: We (A -13(Y))] 1 and K2(Y) = Y2(Y) -[+: wc (A* K3(Y))I 1 Since ~3 P lays no direct \nbut only a subsidiary role in our calculations, we can eliminate it by combining update rules (4) and \n(5). This leads to the following update rule for K2, which we shall henceforward call by the more heuristic \nname COUNT: (6) (Yy G [+: x G A] succ(x) )COUNT(y)=COUNT(y )-[+: W = (sP{Y}*A*s)] 1;; Here ~ is as in(4) \nabove. Note that u depends continuously on s, and that by applying the general rules of section 3 we \nsee that succ is to be updated after s = s -A by executing (7) (Vb~ [+: x ~ Al sP{x} * s) succ(b) = succ(b) \n-{x ~ AIx E sP{x}}; ; Once COUNT is reduced, we can reduce ZRCOUNT . {x G SI COUNT(x) QI 0) by immediate \napplication of Rules 1 and 2 of section 3; this eliminates the auxiliary map ~ Combining all these transformations \nand applying appropriate cleanuP, we obtai the following much improved form of the topological sort (1) \nt = nultuple; (Va~ s) COUNT(a) = [+: y~ sp{a} * s] 1; succ(a) ={ye s [ a=sp{y}}; ; ZRCOUNT = {X e s I \nCOUNT(x) ELI O}; (while qa~ ZRCOUNT) t=t+ <a>; (8) ( dy~ succ(a)) COUNT(y) = COUNT(y) -[+: we (sp{y} \n* {a}%S)] 1; ZRCOUNT . ZRCOUNT + U COUNT(Y) w O -{Y] ~ nullset; ; s. s-{a}; (9) (Vb~ sp{a} * s) succ(b) \n= succ(b) -{x= {a} I x= sp{x}}; ;  (lo) ZRCOUNT = ZRCOUNT -{XG {a] lCOUNT(X) ~ o}; end while , A very \ngood optimizer might determine that the expression [+: w= (sp{y} * {al * s)] 1 of (8) is just that the \nconstant 1 , that sp{a} * s of (9) is nullset, and that {x e {a} ICOUNT(X) ~ O} of (10) is simply {a}. \nAlso, s can be eliminated as a dead variable inside L. With these improvements, a final version of the \ntopological sort could be written as follows: t = nultuple; (Va G s) COUNT(a) = [+: y G sp{a} * s] 1; \nsucc(a) . {y =s Ia~sp{y}}; ; ZRCOUNT = {X ~ S I COUNT(x) ~ 0]; (while la ~ ZRCOUNT) t = t + <a>; (Yy \nG succ(a)) COUNT(y) = COUNT(y) -1; ZRCOUNT . ZRCOUNT + IF COUNT(y) ~ O then {y} else nullset; ; ZRCOUNT \n= ZRCOUNT -{al; end while; This final version of the topological sort algorithm will run in a number \nof cycle proportional to the number ~ of elements in the map ~. The original form (1) of the algorithm \nwill require somethinsz like ~ * (11~) * (~1~) cycles, which can be much larger. However, the chain of \nsymbolic transformations which leads from (1) to (4) is Quite long, and it appears doubtful that an automatic \noptimizer will be able to traverse this chain unguided, especially since in this case, and still more \nso in more general cases, there exist competing transformations whose application an automatic system \nwould have to consider. However, it may be practical to design a semi\u00adautomatic system, whose user may \ninteractively signify that he wishes a particular subexpression of a program to be differentiated in \none of several possible ways. This may make it possible to deri~e efficient program versions with more \ncertainty a~d less labor than would be typical if the final program version had to be worked out in an \nentirely manual way. 7. @nclusion Work is currently in progress to produce working SETL algorithms that \ngeneralize and realize the techniques sketched in the preceding pages. Algorithms which perform auxiliary \nfunctions such as preparatory or cleanup transformations are being studied. We expect cleanup to be a \nmajor problem. Our goal is to implement formal differentiation as a semi-manual extension of the optimized \nSETL system currently under development at N.Y.U. [El, B2, Sch3, Stl, St2]. Formal differentiation has \ngreat potential for transforming very high level code to reasonably efficient low level code. As a SETL \nto SETL optimization it works best when a SETL pro~ram is written in a very high style (in which iterative \noperations * abound) . The result of formal differentiation is then highly efficient low style SETL. \nAs is pointed out in [Sch2], program validation can be expected to apply most easily to very high level \nprograms since the required correctness proofs can be expected to be shorter. * In this regard, see the \nremarks in [Ll], regarding a simpler experiment on source-to-source transformation in SETL. 69 Re17erences \nI!Reduction of Operator [Al] Allen, Frances F., Cocke, John, and Kennedy, Ken, Strength, Rice University \nTech. Rep. 476-093-6, August 1974. [Bl] Balzer, Robert, Goldman, Neil, and Wile, David, !!on the Transformational \nImplemen\u00adtation Approach to Programming, UCS/Information Sciences Institute, Marina del Rey, Calif., \nApril 1975. [B21 Burstall, R. M., and Darlington, J., 11A Transformation System for Developing Recursive \nPrograms, D.A.I. Research Report No. 19, University of Edinburgh, March 1976. [cl] Cocke, John and Kennedy, \nKen, ltAn A~gOrithm for Reduction of OperatOr Strength, Rice University Technical Report 476-093-2. [C2] \nCocke, John and Schwartz, J. T., Programming Languages and Their Com~ilers, Courant Institute of Mathematical \nSciences, New York University, 1969. [El] Earley, Jay, ItHigh Level Iterators and a Method for Automatically \nDesigning Data Structure Representation,!f Dept. of Elec. Engr. &#38; Computer Sciences, and the Electronic \nResearch Lab. , Univ. of California, 13erkeley, Calif. , February 1974. [E2] Earley, Jay, ttHigh Level \nOperations in Automatic programming, Dept. of Elec. Engr. &#38; Comp. Sciences and the Electronics Research \nLab., University of California, Berkeley, Calif., October 1973. [Fl] Fong, Amelia C. and Unman, Jeffrey, \nD., J!Induction Variables in Very High Level Languages, Proc. Third ACM SvmDosium on Principles of Programming \nLanKuages, January 1976. [Kl] Kennedy, Ken, !!Reduction in strength Using Hashed Temporaries, SETL Newsletter \nNo . 102, March 12, 1973. [K2] Kennedy, K,en, !!Linear Function Test Replacement, SETL Newsletter No. \n107, May 20, 1973. [K3] Kennedy, Ken, !lGlobal Dead Computation Elimination, SETL Newsletter No. 111, \nAugust 7, 1973. [K4] Kennedy, Ken, llAn Algorithm to Compute Compacted Use Definition Chains, SETL Newsletter \nNo. 112, August 14, 1973. [K5] Kennedy, Ken, I!Variable Subsumption with Constant Folding, SETL Newsletter \nNo. 123, February 1, 1974. [Ll] Liu, S-C., t!An Experiment with Peephole Optimization in SETL, tO aPPear \nin the, Proceedings of the September 1976 Moscow Conference on Very High Level Languages. [s1] Schonberg, \nEd, !!The vERS2 Language of J. Earley Considerd in Relation to SETL, SETL Newsletter No. 124, January \n30, 1974. [Schl] Schwartz, J. T., On Programming : An Interim Re~ort on the SETL Project. Installments \nI, II, Courant Institute of Mathematical Sciences, New York University, New York, 1974. [Sch2] Schwartz, \nJ. T., !!c~~~p~l comments on High Level Dictions, and Specific Suggestions Concerning Converge Iterators \nand Some Related Dictions, ~ Newsletter No . 133B, January 29, 1975. [Sch3] Schwartz, J. T., !!IntrOductOry \nLecture at the June 28 Informal o~timization Symposium , SETL Newsletter No. 135, July 1, 1974. [Sch4] \nSchwartz, J. T., I!Structureless programming, or the Notion of Rubble , and the Reduction of Programs \nto Rubble, SETL Newsletter No. 135A, July 12, 1974. -70 11A Framework for Certain Kinds of High Level \nODtimiZatiOn, [Sch5] Schwartz, J. T. , SFTL Newsletter No. 1?6, Julv 16, 1Q74. [S~h~] Sehwart~, J. T. \nand Paige, R., On Jav Earlev s Method of Iterator Inversion! ,11 SFTL Newsletter No. 138, ~~ril 19, lQ7~. \n[~tl] Standish, Thomas, !!An ~xa~ple Of Program Improvement USin~ .source-to-SoLIrce Transformations, \nDept. of Information and Computer Science, University of California at Irvine, Irvine, Calif., February \n11, 1976. [St2] Standish, Thomas, et al., l!The Irvine program Transformation Catalogue, Dept. of Information \nand Computer Science, University of California at Irvine, Calif. , January 7, 1976. \n\t\t\t", "proc_id": "512950", "abstract": "This paper explores the technique of 'strength reduction' or 'formal differentation' in a set theoretic context, as recently introduced by Earley. We give pragmatic rules for the recognition and treatment of reasonably general cases in which the optimization is applicable, and consider some of the problems which arise in actually attempting to install this optimization as part of a compiling system.", "authors": [{"name": "Bob Paige", "author_profile_id": "81430615160", "affiliation": "Courant Institute of Mathematical Sciences, New York University", "person_id": "P348469", "email_address": "", "orcid_id": ""}, {"name": "J. T. Schwartz", "author_profile_id": "81100404411", "affiliation": "Courant Institute of Mathematical Sciences, New York University", "person_id": "PP31040798", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512950.512957", "year": "1977", "article_id": "512957", "conference": "POPL", "title": "Expression continuity and the formal differentiation of algorithms", "url": "http://dl.acm.org/citation.cfm?id=512957"}