{"article_publication_date": "01-01-1977", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1977 ACM 0-12345-678-9 $5.00 The Competence/Performance Dichotomy in Programming Preliminary Report Vattghan \nR. Pratt Massachusetts Institute of Technology Cambridge, Mass., 02139 Abstract We consider the problem \nof automating some of the duties of programmers. We take as our point of departure the claim that data \nmanagement has been automated to the point where the programmer concerned only about the correctness \n(as opposed to the efficiency) of his program need not involve himself in any aspect of the storage allocation \nproblem. We focus on what we feel is a sensible next step, the problem of automating aspects of control. \nTo accomplish this we propose a definition of control based on a fact/heuristic dichotomy, a variation \nof Chomsk y s competence/performance dichotomy. The dichotomy formalizes an idea originating with McCarthy \nand developed by Green, Hewitt, McDermott, Sussman, Hayes, Kowalski and others. It allows one to operate \narbitrarily on the control component of a program without affecting the program s correctness, which \nis entirely the responsibility of the fact component. The immediate objectives of our research are to \nlearn how to program keeping fact and control separate, and to identify those aspects of control amenable \nto automation. 1. Transferring Responsibility to the Computer. One might characterize the difference \nbetween a tool and a servant (or assistant, to avoid anachronism) solely in terms of intelligent communication. \nA user commands his tool in the simple language of the tool; a master commands his assistant in the rich \nlanguage of the master, putting a heavy demand on the assistant s intelligence. The modern computer began \nas a tool for calculating table% a reasonable objective of artificial intelligence is to make it an intelligent \nassistant. In this paper we outline a step in this direction. As an example of progress to date we may \nconsider storage allocation, the problem of finding a place in memory to store a datum, The machine language \nprogrammer must specify an absolute address for an array. The symbolic assembly language programmer may \nsimply request a given amount of storage at assembly time, leaving the choice of base address up to the \nassembler. The Fortran programmer can store data in two-dimensional arrays This research was supported \nby the Advanced Research Pro&#38;cts Agency of the Department of Defense under Office of Naval Research \ncontract NOO014-75-C-0643. without needing to choose or even be aware of a correspondence between integers \nand pairs of integers for mapping two dimensions into one, The Algol programmer can have multiple simultaneous \nactivations of the same procedure (namely when that procedure calls itself directly or indirectly, i.e. \nrecursively) without having to allocate storage in advance for each such activation. The Lisp programmer \ncan create complex objects (e.g. by appending lists) without having to declare them in advance to the \nstorage allocator and without even having to think up names for them. We observe in this progression \na gradual shift of responsibility for storage management from the programmer to the computer, Every such \nresponsibility the computer can assume means that much less work for the programmer, and, more importantly \nin our opinion, that much less opportunity for clerical oversights on the part of the programmer. One \nmight take the position that such progress, while of value to programmers, is not a step towards an intelligent \nassistant, but merely an application of well-understood techniques from the theory of algorithms. We \ndispute that position; how responsibility is transferred to the computer, whether via well-understood \nalgorithms or magic, is immaterial when it has been transferred. Our objective is to continue this transfer, \nhopefully without having to resort to magic. In this paper we will focus not on data management but on \ncontrol; our objective is to automate some of the control decisions currently made by the programmer. \nIn the following we outline a philosophy of control in terms of interpreters and programs, present an \napproach to separating factual issues ( competence ) from control or heuristic issues ( performance ) \nin programs, and discuss approaches to automating the latter. 2. A Philosophy of Control We adopt the \nviewpoint that an operating computer consists of an interpreter and a program being interpreted, and \nthat the program guides/advises/constrains the interpreter in its choice of operations in much the same \nway as a grammar constrains a speaker. Readers unfamiliar with this viewpoint might consider the regular \nexpression Ax=L(X>O;A=XXA;X: =X-l):,;X=O, a grammar of sorts, where the assignments and tests are terminals, \n; is concatenation and <Y is Kleene closur~ this grammar generates the set of execution sequences associated \nwith one way of computing X! . Out of context, a grammar does not specify which of the sentences in \nits language the speaker should use, any more than does a program specify which execution sequence to \nuse in the absence of an environment. Given an environment, whether a %mple-minded interpreter can choose \nan appropriate execution sequence depends on the nature of the program. In the factorial example, the \ninterpreter can work from left to right in the regular expression, inspecting the tests X>O and X=O to \ndecide whether to execute X>QA=XXA;X:=X-1 again or to end it all by executing X=O , using the environment \nin carrying out the rule never execute a test whose value is false, With this rule, the interpreter s \noptions are so limited by this program that almost no intelligence is needed to choose the right sequence, \nin that the interpreter need not be a large program and need not consult other data bases beyond the \nimmediate environments. This viewpoint of the program as guide is not constrained to execution sequences \nof assignments and tests. The formulae f(0) = 1 and f(n.1) = (n+l)xf(n) can be regarded as advice on \nwhat to do with, say, f(3) , one obvious possibility being to rewrite it repeatedly using the above formulae \nand other facts of arithmetic to end up with f(3) = (2+1)xf(2) = 3xf(2) = ... = 6xf(0) = 6x1 = 6. Again \na simple interpreter will suffice to discover this sequence, say by trying to unify the last term generated \nwith the left hand side of one of the above two identities, where the unifier has enough intelligence \nto unify 3 and n+l. In the above examples the interpreter contributed next to nothing in the collaboration \nbetween program and interpreter. This was about the extent of the power of machine languages on all early \ncomputers. One might be tempted to justify this on the basis of the theoretical observation of Turing \n[21] that small universal interpreters exist, that is, that in the division of labor between program \nand interpreter, all but a small fixed amount of the labor can be allocated to the program. However, \nit has always been understood by language designers, whether consciously or subconsciously, that the \nsavings in hardware possible using a minimal interpreter are more than offset by the resulting inefficiency \nof execution and inconvenience to the programmer, so that even the simplest machines use machine languages \nconsiderably more sophisticated than that implied by Turing s choice of representation of programs to \nbe executed by his universal machine. With the rapidly decreasing ratio of hardware to programmer costs, \nand with the development of services provided by operating systems as a powerful extension of the basic \nmachine language, this division of labor has been steadily shifting, with the interpreter assuming progressively \nmore responsibility in the decision making process. The primary beneficiary of this trend in the division \nof labor is the programmer, in his capacity as writer of his own programs, and as reader/modifier of \nboth his own programs and those of others. The more intelligent the interpreter, the less advice the \nprogrammer need supply to enable the interpreter to accomplish a given task. It is natural to assume \nthat less advice leads to less program-writing effort, but we prefer to de-emphasize this potential benefit \nand instead stress the notorious unreliability of the programmer in comparison to the computer. Less \nadvice means less opportunity for programmer-generated error. If this results in a substantial decrease \nin debugging time, some increase in programming time may be tolerable. However, the greatest beneficiary \nin the end may be the program s user, for whom the cost of a bug in the program may often amount to more \nthan the cost of the program, even if he is the sole purchaser of that program and has absorbed the full \nprogramming costs. 3. Seoaratimz fact and heuristic, We focus on the notions of competence (or fact, \nor epistemology) and performance (or heuristic), which supply a dimension for modularizing programs that \nhas received relatively little attention to date. This dimension originates with Chomsky [21, who argued \nthe relevance of the competence/performance dichotomy to theoretical linguistics. The idea has implicitly \nbeen applied to computer science in various ways which we discuss later. The competence of a deterministic \nprogram is that htformation in the program that contributes to its partial correctness (soundness) and \nnon-deterministic termination (completeness). The performance contributes to the determinism of the program. \nIn this section we shall be concerned simply with making the separation, being content to leave the automation \nof the heuristic component till later. This is a little vague, so let us consider some examples. The \nsimplest domain in which to study the dichotomy is that of function definitions, where one combines identities \nwith information as to when each identity is relevant. This can be observed in the following definition \nof the factorial function: f(x) : if x=O then 1 else xi,f(x-1) We find here two kinds of information. \nOne is factual the definition asserts that f(0)=i and that if x-O then f(x)=x,:,f(x-1). The other is \nprocedural, telling the interpreter in what order to do thing$ the advice given here is to begin with \nthe fact f(0)=l , treating it as f(0)-d (asymmetric =), and if it is inapplicable, to proceed to the \nother fact (with no provision for advice if the second fact is inapplicable, e.g. if the mtsltjply hardware \nis broken). If we were to rewrite this definition separating the competence from the performance, we \nmight write Competence base f(0) = 1. ind: f(x+l) = (x+l)t{f(x) Performance integer(f(x)) LtoR(base)lLtoR(ind) \n, The competence component supplies the two facts, appropriately Iabelled. The performance component \nsays that if you want the expression f(x) transformed into an integer then apply the Left-to-Right transformation \nrule to f(x) using the identity base, and failing that, try the same with the identity ind. This use \nof labels is inessential; whether we write factorial as above or as integer(f(x)) LtoR(<f(0)=l>) I LtoR(<f(x+l)=(x+l):f(x)>) \nis not important so long as we can distinguish the two components, in this case by putting the elements \nof the competence component in meta-brackets, With further syntactic sugaring one might be able to get \nthe definition to look almost the same as the original one. However, there is an aspect of competence \nnot yet discussed that makes it likely that labels would be widely used, and that is the likelihood that \nmuch Of a program s competence component will consist of generally useful facts appealed to by more than \none program. A trivial instance of this is the gcd example below. Now that we have seen an example of \nthe idea, let us (Note that there is no point in keeping separate competence return to definitions. We \nreferred in the beginning to components for separate programs.) soundness and completeness as though \nthe competence componel ilt were an axiom system. Indeed, we shall think of it as just that, without \nthe usual stigma attached in axiom systems to non-independent axioms that is, we shall not object in \nthe least to the presence of axioms that follow from other axioms. The advantage of having a set of logically \nindependent facts in the competence component is that it helps to keep that component small. The disadvantage \nis that it shifts to the interpreter and the performance component the burden of coming up with the relevant \ntheorems. We feel that this task is more appropriate for whoever establishes the correctness component. \nIn this way we keep separate the functions of generating the proof of the program s correctness and executing \nthe program. Our notion of soundness is here one of fidelity to the properties of the problem domain. \nThus no fact in the competence component should be inconsistent with what we know about the domain; being \nable to prove such facts is a sure guarantee of this. The two facts used in the factorial example, if \nnot axiomatic, can at least be proved from whatever definition of factorial one has in mind. Our notion \nof completeness is a bit more subtle. The basic idea is to make sure that there are enough facts around. \nOur objective is to make it possible for the interpreter and the performance component to run using at \nmost the resources specified by the programmer, who may say simply the program should halt on all inputs, \nor, more demandingly, it should not take time greater than sqrt(n)<log2(n). The competence component \nwe gave for factorial is complete with respect to the first of these, but not the second, unless the \ninterpreter does some clever theorem proving; some more facts are needed, such as nz! -\\:~n):<..,oP((n-l) \np(()),:,P(n)oP(2i,n) where P(x) = (x+1)t~(x+2):{...fi(x+n) together with enough facts (or a library \nprocedure) to allow one to evaluate the degree n polynomial P at n points in time O(n log2n) [1]. The \nfollowing example illustrates issues absent from the simple factorial example. define gcd(x,y) : if x-O \nthen y else gcd(y mod x, x) . (Euclid) define gcd(x,y) : if x=O then y (J. Stein) else case [even(x),even(y)] \nof ([t,tl 2~gcd(x/2,y/2)> [t,fl: gcd(x/2,y), [f,tl gcd(y,x), [f,fl: if X?Y then gcd(x-y,y) else gcd(x,y-x)) \nSeparating out the components, we have Competence. base gcd(O,x) = x sym: gcd(x,y) E gcd(y,x) ! add: \ngcd(x,y) = gcd(x,x+y) . corn: gcd(2t,x ,2t,y) = 2t~gcd(x,y) . disj gcd(2tix,2i(y+l) = gcd(x,2i,y+l) Euc: \ngcd(x,y) -gcd(y mod x,x). Performance. (Euclid s algorithm) integer(gcd(x,y)) LtoR(base)lLtoR( Euc) . \n(Stein s algorithm) integer(gcd(x,y)) LtoR(base)lLtoR(com)lLtoR(disj)l even(y)+LtoR(sym) lRtoL(add)lLtoR(sym) \n. (Note the use of RtoL. Also note the use of the test even(y)+ which causes evenI(y) + L to R(sym) to \nfail when y is not even. Tests in the performance component do not compromise any of the advantages of \nthe competence/performance separation. In contrast, if we were to allow assignments, whether explicitly \nin the form of assignments to variables or implicitly by naming values to be returned as the answer, \nwe would then be able to compromise the correctness of the competence component.) (Combined -useful when \nEuc is not known in advance to be applicable e.g. when availability of mod is unknown) LtoR(base)lLtoR(Euc)lLtoR(com)lLtoR(disj)l \neven(y)+LtoR(sy m)lRtoL(add)lLtoR(sym) . In this example we have more facts in the competence component \nthan we need for either one of the two algorithms by itself. Conventional programming styles encourage \nnecessary and sufficient programming, where you write down just enough cases to get the job done. In \nthe competence/performance style, since the use of each fact is unspecified, there isnot the same temptation \nto be necessary, and one feels free to include any seemingly relevant facts. At the same time one runs \nthe risk of not supplying sufficient facts; the if-then-else style forces one to cater for every case, \nwhereas an empty competence component will at least be sound if not complete. Impact of this Dichotomy \non Verification Methods Thanks primarily to the work of Floyd [4], we now understand the relationship \nbetween proving theorems in mathematics and proving that a program is correct, namely that correctness \ncan be expressed in terms of theorems about programs, and that such theorems can be rigorously proved \nusing inference rules analogous to rules used in conventional mathematics. Hoare [9] has made the connection \neven clearer by developing an axiom system modelled on systems developed by Hilbert and Gentzen. Manna \n[151 has shown that such systems are no stronger than conventional (non-program oriented) second-order \nlogic, and Cook [3] has in effect strengthened this by showing that, even when the symbols of the underlying \nlanguage are interpreted as arithmetic operations, such systems are no more powerful than first-order \narithmetic (although his goal was actually to establish completeness of Hoare s method). In the fact/heuristic \nstyle of programming, all of the above results become redundant. Correctness of a program reduces vacuously \nto correctness of the facts making up its competence component. The above results are now implicit in \nthe interpreter, in which is vested the responsibility for sticking to the facts. Thus all that is needed \nto prove the program correct is to prove the individual facts in the competence component. In the example \nof a pay-roll program, verifying the conventional) LISP program that embodies essentially these facts. \nfacts becomes even simpler than proving mathematical theoremS it becomes a matter of having an accountant \ncheck that the facts are in accord with his understanding of the tax laws and related issues. (This observation \nis in accord with a hobby-horse of ours that truth transcends proof [18], that is, that the question \nof whether a formula is true arises independently of the existence of any axiom system in which it can \nbe proved. Proofs are just computations for convincing mere machines limited by Church s Thesis of the \ntruth of propositions. Correctness of a program is defined in terms of whether its facts are true, not \nwhether they are provable. In this way we can factor out from our theory any reliance on the notion of \nproof.) Procedural competence Not all competence components need involve static facts. Sometimes a procedural \nidea is required, where the crux of the idea can be explained in terms of a small fixed number of steps \nof a procedure. Eliciting the appropriate control structure for application of the idea is still an appropriate \ntask for the interpreter. In this case the programmer need only apply a small fragment of what we know \nabout proving programs correct, just enough to verify that a couple of instructions have the desired \neffec~ the interpreter can then be relied on to use the idea correctly. The competence components in \nthe following examples refer to single-instruction programs. In the following, symbols not taking arguments \nare considered universally quantified; all other symbols take on whatever value is assigned to them by \nthe particular world in which they are evaluated. P preserves Q is an abbreviation for P and Q implies \nnext Q Next is a unary modal logical connective (the only procedural concept present) whose meaning \nis after executing one arm operation (e.g. opening the hand, moving the hand so that B is caught (meaning \nthat B is between the fingers of the hand, without the hand necessarily being closed), moving the hand \nto at(B) (meaning that the hand is hovering just over B),) not on(b,b) $ not caught(tableo) $ caught(b) \nand at(c) implies on(b,c) $ on(b,c) and on(b,d) implies c=d $ at(x) and at(y) implies x=y # on(x,b) \nimplies next not caught(b) $ on(x,c) preserves not on(b,c) # on(b,c) implies next (openo implies on(b,c)) \n$ caught(b) implies next (openo or caught(b)) $ openo preserves on(b,c) $ not openo preserves caught(b) \n$ not openo preserves not caught(b) $ The reader familiar with interpreters of theorems (as in [5,6,7,1OJ2,2OI)should \nnot find it hard to see how to interpret these facts as a program, (The monkey-and-bananas problem of \n[12] is the canonical example of this phenomenon.) Three of the predicate symbols, at , caught and open \n, have the appropriate effects on the arm. Note the non-monotonic application Of the first two facts, \ndiscussed in the next paragraph. We have not yet worked out a suitable heuristic component for this example \nor the next; we are at present trying to reconstruct it from an already existing deterministic (i.e. \nAn important decision to make in deciding just what a competence component is is whether to treat the \nfacts exactly as in logic, where the soundness of the whole system can be reduced to the soundness of \nthe individual facts, or whether one is willing to let some facts over-ride others. For example, a program \nto operate a robot arm needs to know somehow that a block cannot be placed on itself. This will prevent \nit from attempting to obey a command such as Put B on B. An obvious approach to conveying this information \nis to supply the fact not(on(b,b)). But if the correctness of the whole competence component reduces \nto the correctness of its facts and if it is correct with the fact not(on(b,b)), it must also be correct \nwithout the fact. It follows that any contribution made by this fact to the correctness of the whole \ncannot be considered in isolation from the wholq we must have lost what we will call monotonicity, the \nability to add facts without increasing the correctness of the program (or conversely, to select any \nsubset of facts from a correct library knowing that the subset will also be correct). In the following \nsystem we eliminate non-monotonicity, and also replace a single modality (next) with a separate modality \nfor every elementary arm operation, represented for convenience here as assignments to the three arm \npredicates at, caught and open. [at(b)=tl is interpreted to mean after making the formula at(b) true, \nwhile <at(b):=t> means m[at(b):=tl= , the dual notion. (A close analogue is Vx, interpreted as after \nsetting x to a random value, and its dual 3X = =Vx= .) Thus [sIP says that no matter what happens as \na result (direct or indirect) of doing s, P will hold; <s>P promises that it is possible for P to hold \nas a result of s terminating when P is just t (true), this asserts that s terminates. [P:=tlP s [P:=niil=P \n$ on(b,c) implies on(dep(c),c) $ otherthan(c) # c $ caught(b) and at(c) implies on(b,c) $ not on(dep(b),b) \nand (not caught(b) or openo) implies <at(b)=t>t 8 not on(dep(b),b) and openo implies <caught(b)=t>t \n$ not openo and caught(b) implies [at(y) =t]caught(b) $ caught(b) implies [openo=milkaught(b) $ not on(x,y) \nimplies [openo=nil]not on(x,y) $ not on(x,y) implies [caught(b) =t]not on(x,y) $ on(b,otherthan(c)) implies \nnot on(b,c) $ The reader can verify for himself that every assertion in this system is valid (given a \nreasonable interpretation of how the blocks world behaves) by itself, unlike the preceding system, where \nin the absence of such pessimistic facts as not(on(b,b)) it would be possible to deduce a computation \nthat put B on B. It is worth noting that in neither of the above systems is the notion of state referred \nto explicitly. This is in contrast to [5] and [12]. See [18] for a rigorous account of how to do this \nwhile keeping the semantics intact. These two examples suggested two ways in which procedural information \nmight be incorporated into facts. This leads one to ask whether there is any limit to how much procedural \ninformation can be put in facts. This depends on what programs one is willing to allow in modalities. \nThe equivalences U81 [aUblP e [a]pA[blp [wblP s [alklP show that excluding union (i.e, non-deterministic \nchoice) and sequencing does not affect what we can say, leading us to include them without any additional \nconcern. Only when we add iteration need we again question whether our fact language has become too rich. \nObviously one can then simply implement an interpreter that executes b when the fact component consists \nof just [b]P, announcing P when it terminates along with the current values of those variables affected \nby b. This is the phenomenon of the richer the language, the more complex the ideas expressible in it. \nIn a weaker language, it is up to the interpreter, with the help of the heuristic component, to figure \nout the complex idea$ the fact component can only contribute relatively simple ideas. Other work. Though \nwe are unaware of any published work in computer science that explicitly draws attention to the distinction \nbetween competence and performance, the idea is implicit in a number of places. The most familiar application \nof the idea is in the wide-spread use of grammars in parsing systems. A grammar, whether for Algol or \nEnglish, can be thought of as a collection of facts about a language. The con tex t-f ree rule A:=BC \nmay be read as the fact An A may be a B concatenated with a C. From such facts one may infer An S may \nbe a THE concatenated with a DOG concatenated with a EATS . The objective of a parser is to recover the \ntrail of reasoning leading up to such an inference. For programming language grammars the performance \ncomponent is essentially empty and the interpreter (i.e. parser) supplies all the performance. Until \nWoods s ATN system [22], the same held for natural language parsers, where the entire grammar resided \nin the context-free component and the parser knew nothing about the special properties of the particular \ngrammar it was to work with. Woods augmented his context-free grammars (represented as transition networks \nto facilitate this augmentation) with a performance component that helped the parser decide what to do \nwhen. All major context-free based systems for natural language being actively worked on today, whether \nor not represented as transition networks, now have a substantial performance component. (Kuno s Harvard \nPredictive Analyzer [Ill, which has an empty performance component, is maintained at IBM Yorktown Heights, \nbut it is not actively being developed or used.) An early advocate of explicit representation of heuristics \nin addition to facts was McCarthy [12]. However, McCarthy s emphasis was on the fact component, and neither \nthat early work nor more recent work paid a proportional amount of attention to heuristics. However, \nthis was made up for in the robot-oriented programs of the late 60 s, notably Green s QA3 system [5] \nand Hewitt s Planner system [7], The former relied on a theorem prover as its interpreter, and had an \nempty performance componen~ this leap into the utopia of fully automated heuristics proved premature. \nHowever, its competence component, consisting of raw facts, precisely matches our own ideals for a competence \ncomponent. Planner was more performance oriented; however, enough of the performance was mixed in with \nthe competence, e.g. by distinguishing antecedent theorems from consequent theorems when these were both \nmerely implications, and by identifying the competence notion of negation with the performance notion \nof unprovability, that we would not wish to class Planner as a paragon of the method we advocate, Planner \ns successors (Hewitt s PLANNER?3/ACTORS/PLASMA [8] and McDermott and Sussman s CONNIVER [13]) have become \nsophisticated performance oriented systems with no distinguishable competence and performance components \nas we envisage them. What distinguishes CONNIVER from PLASMA is CONNIVER s more immediate commitment \nto an int~lligent interpreter, though this intelligence does not extend significantly beyond implementing \nsome good algorithms for handling environments flexibly. More recently McDermott has developed a markedly \nmore intelligent interpreter, supported by a small theorem prover. However, the performance component \nremains inextricably intertwined with the competence. J. Schwartz s notion of rubble programs U9], programs \nconsisting of a rubble of loosely inter-related fragments, captures one aspect of competence components, \nnamely their discreteness. Schwartz s thesis is that any program has such a rubble program as its prototyp~ \nthe programmer begins by formulating the rubble program, then proceeds to optimize it, in the process \norganizing the rubble into a structured unit and at the same time converting operations on sets into \noperations on their elements via the appropriate generalization of reduction in strength. Schwartz proposes \nto automate this optimization. In this, Schwartz comes as close as any to sharing our objectives. Two \nmajor differences are Schwartz s precrccupation with reducing the expense of naive set manipulation and \nhis more ambitious goals concerning automation of control. We ignore optimization possible by reduction \nin strength (formal differentiation) because the examples we work with cannot benefit from this idea \nand we expect to see many more examples in that category. We have relatively modest goals for automating \ncontrol because it appears to us that complete automation is at present enormously difficult. Partial \nautomation seems sensible but begs the question of what part? At present our understanding of control \nstructures does not permit us to carve them up and distribute them between the programmer and the computer, \nwhich is why we propose to work out our fact/heuristic dichotomy in more detail to try to elicit a better \nunderstanding of the heuristic component. Another place in which the idea can be found is in the most \nrecent attempts to implement logic as a programming language, notably those of Hayes [6] and Kowalski \n[IO]. These come as close as any work to meeting our own objectives for separating competence and performance. \nBoth of them have the advantage of inheriting a well-defined semantics from logic (as did QA3), providing \nreassurance that proofs of correctness will not be just optimistic symbol manipulation but will be supported \nby a Tarskian definition of truth, for which to our knowledge no trustworthy substitute has ever been \nsatisfactorily worked out. Hayes pays more attention to the development of a performance component than \ndoes Kowalski, who prefers to rely on the interpreter, which he implements using SL-resolution. Tarnhsnd \n[201 has implemented a version of Kowalski s system that incorporates the missing performance component. \nMarr and Poggio [16] propose applying a four-level version of the competence/performance dichotomy to \nbiologically-related computation. The top two levels resemble our fact and heuristic levels respectively, \nwith their other two levels corresponding respectively to functions and their implementation with digital \nhardware, Discussions with Marr suggest however that their top level is really a set of independent axioms \n(cf. our inclusion of theorems in the fact component) while their next level is a hybrid of our fact \nand heuristic components. 4. Approaches to Automation. As we have little experience to date in separating \nfact from control, we are not in a god position to predict what approaches we will take to automating \ncontrol. The only idea we have had to date concerns the non-monotonic style of programming exemplified \nby our blocks world example. As this idea is moderately interesting, we sketch it here. It was suggested \nby a technique used in R. Weyhrauctt s first-order logic proof checker. We view each fact as a collection \nof optimists and pessimists. To do this we restructure each fact slightly: all logical connective (ignoring \nmodalities for the moment, and assuming that only unary and binary logical connective exist) are replaced \nby A, v and ~ (e.g. P~Qbecomes -PvQ.) and then the -. - s are moved down to the atomic formulae via de \nM&#38;gan s laws (We think of formulae as trees with vertices Iabelled with symbols and having the root \nat the top.) The result is a monotone expression (tsne containing only A s and v s) whose leaves are \nIiterals (possibly-negated atomic formulae). The monotonicity plays an essential role as we shall see. \nNote that this restructuring does not result in the substantial increase of size generally associated \nwith conversion to conjunctive or disjunctive normal form unless s or 4 occur. For example, (AABACADAEAFAGAH)V(IAJAKALAMANAOAP) \nis not altered by our transformation, but is expanded to 64 Iiterais if converted to conjunctive normal \nform. In fact our transformation does no violence to the basic structure of the expression in the absence \nof ~ and ~ ch?.nging only the names of some of the binary logical connective and relocating some negations. \nIf P is an atomic formula we take -P as usual; however, if P is -Q for some atomic formula Q we take \nYP to be Q In this way we can say that for any literal P, P is an optimist for P and the literal -P is \na pessimist for P. Given a fact consisting of the single literal P, any attempt to make P true must meet \nwith instant success since the existence of P as a fact means that P is always true. Thus if P occurs \nas a goal, the fact P is an optimist for that goal. Conversely, -TP is a pessimist for that goal if it \noccurs as a fact, saying that P can never be achieved. Given a fact of the form PvQ the occurrence of \nP in this fact still acts as an optimist for a goal P (and as a pessimist for -P) because all the operators \nabove P in the formula (namely v) are monotone and do not reverse the sense of P. Thus if P is set as \na goal, PvQsays nothing pessimistic about it but is optimistic in the sense that if Q were false then \nP would be forced to be true. We call =Qthe requisite of this optimist. If the goal is -P then PvQis \nonly pessimistic, and says that Q had better be true or 1P will not be achievable. We call Qthe requisite \nof this pessimist. If the fact is PAQ then this is as optimistic as the fact P for the goal P, and as \npessimistic as the fact P for the goal =P, and say that there are no requisites. These ideas generalize \nto arbitrary formulae in the normal form described above, because of the monotonicity. Given a goal P, \nif an optimist P occurs in a fact, then the set of requisites for that optimist are the negations of \nthe siblings in each of the v s encountered going from the occurrence of the optimist to the root of \nthe expression. For example, if the goal is D and the fact is (((AvB)v(CA(DVE)))VF)A(GV(HAI)), then the \nrequisites of the optimist D are (in the order encountered going up the expression) YE, -( AvB), -F and \n~(Gv(HAI)). Similarly if the goal is -D then the requisites of the pessimist D are E, AvB, F and Gv(HAI). \nThis leads to an algorithm for achieving a goal P when P is a literal. First determine the truth of P; \nif true we are done. Now satisfy some requisite of every pessimist for P. This may entail recursively \nsetting requisites as subgoals. If for some pessimist it proves impossible to satisfy any requisite then \nabandon the attempt to satisfy P. Otherwise find an optimist every one of whose requisites can be satisfied; \nsuccess or failure here translates into success or failure in satisfying P. We implemented an interpreter \nbased on this idea and tried it out on the non-monotonic blocks world fact component, with an empty performance \ncomponent. The absence of other facts that might throw the system off the scent allowed our interpreter \nto proceed reasonably quickly to satisfy such goals as on(Bl,B2) in simple situations. Unfortunately. \nthe presence of modalities such as next complicates this approach, and the heuristics we added to the \ninterpreter to deal with the modalities did not seem satisfactory. Our next project is to give some thought \nas to how best to deal with next . The above method may be generalized to deal with ~, which avoids having \nto expand it out and destroy the original expression structure (though this need at worst square the \nexpression size [17], roughly), by treating occurrences of a literal below ~ as both a positive and a \nnegative occurrence. Any segment of a path from that occurrence to the root, with the segment lying between \nconsecutive 4s, may be forced to take on either truth-value, with the siblings at the two s s determining \nhow that value interacts with the rest of the path. We leave the details to the reader. Acknowledgments. \nDavid Marr provided some stimulating argument. Richard Weyhrauch gave me the idea for section 4. References. \nU] Aho, A. V., J. E. Hopcroft and J.D. Unman. The Design and Analysis of Computer Algorithms. Addison-Wesley, \nReading, Mass. 1974. [2] Chomsky, N. Some Aspects of the Theory of Syntax, MIT Press, Cambridge Mass. \n1965. [3] Cook, S.A. Axiomatic and Interpretive Semantics for an Algol Fragment. TR-79, Toronto, Feb. \n1975. [4] Floyd, R.W. Assigning Meanings to Programs. in Mathematical Aspects of Computer Science (cd. \nJ.T. Schwartz), 19-32. 1967. [51 Green, C. Cordell. The Application of Theorem Proving to [22] Woods, \nW. A. Augmented Transition Networks for Natural Question-Answering Systems. Stanford University Computer \nLanguage Analysis. Report No CS-1 to the NSF, Aiken Computation Science Department Report CS-138. 1969. \nLaboratory, Harvard University, Cambridge, Massachusetts. 1969. [61 Hayes, Patrick J. Computation and \nDeduction, Proc. Symp. Math. Found. of Comp. Sci., Czech Acad. of Sciences. 1973. 01 Hewitt, C.E. Description \nand Theoretical Analysis (Using Schemata) of PLANNER: A Language for Proving Theorems and Manipulating \nModels in a Robot, MIT AI Lab TR-258. 1972. [81 --------, P. Bishop, and R. Steiger. A Universal Modular \nACTOR Formalism for Artiicial Intelligence, Proc. IJCAI 3, p. 235.1973. [91 Hoare, C. A. I?. An Axiomatic \nBasis for Computer Programming. CACM ~, 576-580.1969. [101 Kowalski, R. Predicate Logic as Programming \nLanguage, University of Edinburgh Department of Computational Logic Memo 70.1973. [11] Kuno, S. The Predictive \nAnalyzer and a Path Elimination Technique. CACM 8,7,453-462. 1%5. [12] McCarthy, J. Programs with Common \nSense. In Semantic Information Processing (cd. Minsky, M.L.), MIT Press, Cambridge, Mass. 1968. [131 \nMcDermott, D. and G.J. Sussman. The Conniver Reference Manual, MIT AI Lab Memo 259a. 1972. [14] ---------Flexibility \nand Efficiency in a Computer Program for Designing Circuits. Ph.D. Thesis, MIT AI Lab. Sept. 1976. [15] \nManna, Z. Second-order Mathematical Theory of Computation. Proc. 2nd Ann, ACM Symp. on Theory of Computation, \n158-168. May, 1970. [161 Marr, D.C. and T.G. Poggio. From Understanding Computation to Understanding \nNeural Circuitry. MIT AI Memo 357. May 1976. [17] Pratt, V.R. Effect of Basis on the Size of Boolean \nExpressions. Proc. 16th Ann. IEEE Symp. on Foundations of Comp. Sci., 119-121. 1975, [181 Pratt, V.R. \nSemantical Considerations on Floyd-Hoare Logic. Proc. 17th Ann. IEEE Symp. on Foundations of Comp. Sci., \n109-121. 1976. [19] Schwartz, J. A view of Program Genesis and its Implications for Future Programming \nLanguages. In New Directions in Algorithmic Languages (cd. Schuman, S.A.), IRIA. 1976. [20] Tarnlund, \nSten-Ake. An Interpreter for the Programming Language Predicate Logic: Proc. IJCAI 4, p. 601. 1975. [21] \nTuring, A.M. On computable numbers, with an application to the Entscheidungsproblem, Proc. London Math. \nSot., ser. 2, 42, 230-265, E, 544-546. 1936.\n\t\t\t", "proc_id": "512950", "abstract": "We consider the problem of automating some of the duties of programmers. We take as our point of departure the claim that data management has been automated to the point where the programmer concerned only about the correctness (as opposed to the efficiency) of his program need not involve himself in any aspect of the storage allocation problem. We focus on what we feel is a sensible next step, the problem of automating aspects of control. To accomplish this we propose a definition of control based on a fact/heuristic dichotomy, a variation of Chomsky's competence/performance dichotomy. The dichotomy formalizes an idea originating with McCarthy and developed by Green, Hewitt, McDermott, Sussman, Hayes, Kowalski and others. It allows one to operate arbitrarily on the control component of a program without affecting the program's correctness, which is entirely the responsibility of the fact component. The immediate objectives of our research are to learn how to program keeping fact and control separate, and to identify those aspects of control amenable to automation.", "authors": [{"name": "Vaughan R. Pratt", "author_profile_id": "81100298352", "affiliation": "Massachusetts Institute of Technology, Cambridge, Mass.", "person_id": "PP39036582", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512950.512968", "year": "1977", "article_id": "512968", "conference": "POPL", "title": "The competence/performance dichotomy in programming preliminary report", "url": "http://dl.acm.org/citation.cfm?id=512968"}