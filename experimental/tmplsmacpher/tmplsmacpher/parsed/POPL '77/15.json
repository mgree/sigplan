{"article_publication_date": "01-01-1977", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1977 ACM 0-12345-678-9 $5.00 GENERALIZED LEFT CORNER PARSING Alan J. Demers Cornell University Ithacar \nN. Y. 14853 1. Introduction Brosgol [Br] formalizes the notion that parsing methods can be classified \nby the positions at which production rules are recognized. In an LL parser, each rule is recognized at \nthe left end, before the rule s yield has been read; in an LR parser, a rule is recognized at its right \nend, after its yield has been read; and in an LC parser a rule is recognized after the yield of its left \ncorner has been read. We generalize on these techniques by allowing the user to specify arbitrarily for \neach production rule the position at which that rule is to be recognized. The resulting GLC or generalized \nleft corner technique includes the LR, LL, LC, and ELC methods as special cases. It also allows for less \nconventional parsing strategies, such as grammar splitting [K] with certain com\u00adponent grammars parsed \ntop-down and the others parsed bottom-up, as suggested in [AU] . This paper is organized as follows. \nIn Section 2 we give some necessary background and notation. Section 3 defines GLC parsing. A canonical \nGLC(k) parsing technique can be defined analogous to the LR(k) technique. However, the resulting parsers \ntend to be unaccept ably large. We therefore restrict our attention to the SGLC(k) , or simple generalized \nleft corner parsing technique, which is analogous to the SLR(k) tech\u00adnique of DeRemer [D] . We give an \nalgo\u00adrithm for the construction of SGLC(k) parsing tables and prove that the resulting parser is correct. \nIn Section 4 we develop some potentially useful properties of SGLC(l) parsers. We show that there is \na well-defined leftmost position at which each production rule can be recognized, and that a minimal \nleft corner parser can be constructed which recognizes each rule as early as possible. We derive a simple \nexpression relating the size (number of states) of an SGLC(l) parser to the size of the corresponding \nSLR(l) parser. If G is not left-recursive, then the minimal left-corner parser is the smallest parser \nfor G in this class, while the SLR(l) parser is the largest. In Section 5 we ex end the techniques 5 \nof [HSU] to give an O(n ) alqorithm to test whether a grammar with no left recursion is SGLC(l) , and \nif so to compute its minimal left corners. ~. Background In this section we review some basic facts about \ncontext-free grammars and languages. * Let Z be a finite alphabet. Then I denotes the set of all finite-length \n*k strings over 1, and Z denotes the set of all strings of length at most k. For * w E z, we write IwI \nfor the length of w, and k:w to mean the first k s mbols of w (if lwl~k) or w itself (if Iw <k). T A \ncontext free grammar (cfg)is a four-tuple G = (N,Z,P,S), where N and Z are finite, disjoint nonterminal \nand terminal alphabets, respectively; SEN is the start symbol~ and P is a finite set of production rules \nof the form A+a, * where A ENand a E (NUZ); Aand aare respectively the left and right parts of the production. \nWe assume~u~s are numbered from 1 to p, so it makes sense to talk about the ith production of G. We adhere \nto the conventions that: (a) A,B,C. . . denote nonterminals. (b) a,b,c. . . denote terminals. (c) Z,Y,X. \n. . denote symbols in (NLIZ). (d) Z,Y,X. . . denote strings in Z:  * (e) a,f3rY. . . denote strings \nin (NUZ) . (f) e denotes the empty string.  If A+$ is in P, then for any aand y in (NUZ)* we write \naAy~>af3y, and say aAy directly derives a$yin G. The relations ~> and $> (derives and derives nontrivial- \nG ly) are the reflexive and transitive and the transitive closure of ~>, respective\u00ad ly . We omit the \nsubscript G and write =>, * . >, or > when no confusion should result. A string a is a sentential form \nif . S:>(I. L(G) , the language generated by G, is the set of all terminal sentential forms of G; i.e., \n{w sZ* IS~>w }. For any X E (N(JZ) , we define the following sets: FIRST:(X) = {k:w I x~>w }. FOL~(X) \n= {k:w I S~>uXy and y~>w }. LG(X) = {W I X~>W }. and l(x) = {Y \\ x+Ya for some al. Viewing i as a relation, \nwith XAY iff YEA(X), we can define A*(X) and A+(X) as usual. Note that A*(X) # {Y I x~>Ya for some a}. \n*k Finallyr let L1 and L2 be subsets of Z. Then we define = {k:wx I WEL1 and XCL2}. l@kL2 More complete \ndescriptions of the above functions may be found, for example, in [AU] . ~. GLC Parsing In this section \nwe introduce the notion of a generalized left corner parser. We give an algorithm for con strucfion of \na simple generalized left corner (SGLC(k)) parser, which is analogous to the SLR(k) &#38;echnique of \n[D] , and we prove that the resulting parser is correct. Finally, we give a simple space optimization \nwhich can be per\u00adformed automatically as the parser is generated. GLC parsing requires the ability to \nspecify for each production rule the position at which that rule is to be recognized. Our formalism for \nthis is based on the output simulated input grammar of [Br] , and is defined as follows. 3.1: Definition. \nLet GO=(N,Z,PO,S) be a cfg. A recognition rule grammar . based on GO i~ a cfg G=(NH,P,S) , where a) N \n= {1 I l<i<lPOl} is the set of recognition symbols. N and R are disjoint. b) P is defined by 1) P contains \n?~e for each 2EN. 2) Let A+a be the ith production in then P contains exactly one o; production of the \nform A+a1fa2, with a.lct2=a. u ~ is called the left corner or leading part of the pro\u00adduction; a2is its \n~ling part. 3) Nothing else is in P. // Informally, a recognition rule grammar based on G is constructed \nby inserting ? somewhere into the right part of the ith production, for l<i<p. The next lemma gives some \nuseful r~lations between Go and G. 3.2: Lemma. Let Go and G be as in the above definition. Then for \nany XC(NL)Z), a) LG(X) = LGO(X) b) FIRST:(X) = FIRST;O(X) c) FOL:(X) *@O(X) d) 1;(X) ~ 1 Go(x)uit Proof: \nObvious. // When parsing bottom-up, one can interpret reduction by ?+e as announcing that the ith rule \nhas been recognized. Brosgol [Br] has shown that a grammar G is LL(k) if and only if it is LR(k) after \nrecognition rules have been added at the left end of all productions. He gives analogous results for \nLC and ELC grammars. LC and ELC parsers recognize the left corner of each rule bottom-up, then parse \nthe remainder of the rule top-down. A GLC parser operates in the same way, parsing each rule bottom-up \nuntil the recognition symbol is reached, then pushing the remainder of the rule onto the stack and parsing \nit top-down. 3.3: Definition. Let G=(Nu~,Z,P,S) be an rrg. A generalized left corner parser with k-symbol \nlookahead for G is a triple n~=nz~t~h ere a) ~ is a finite set of states containing distinguished states \nQS and O,.x for each X which occurs in the trailing part of some rule of G. b) Action is a function mapping \na.xz k into the set {error,pop,shift} . U {announce i I tsN }. c) Goto maps~~ (NuI) into a. // A GLC \nparser maintains a stack.of states, which it manipulates according to Algorithm 3.4 below. A configuration \nof a GLC parser is a pair ( ,w), where &#38;is the contents of the st$!k, with the top at the right, \nand w is the remaining input. 3.4: Algorithm. GLC Parsing. 1. Let the initial configuration be (QS,W), \nwhere w is the input to be recognized. 2. Repeatedly perform whichever of the following steps is applicable \nuntil the stack is empty or an error action is encountered. Let the current con\u00adfiguration be (Q1.. .Qm,X), \nand let u=k:x. a) If Action(Qm,u)=pop, then pop Qm and Qm_l from the stack. b) If Action (Qm,u)=shift, \nthen read the first symbol a of x and push Goto(Qm,a) onto the stack. c) Suppose Action (Qm,u)=announce \ni. Let A+aiX1. . .Xr be the ith produc\u00ad tion. Pop Iul states, exposing ; then push Goto(Q m ]++) m-lal \nfollowed by QXr, . . ..Q in that xl order.  3. Accept if and only if the parser reaches the end of the \ninput and empties its stack. // The relations ~, ~, and ~ on configurations are defined by this algorithm \nin the usual way. Note that states of the form QX are predictive in the sense that once Qx ap\u00ad pears \nat the top of the stack it can be erased only by recognizing some prefix of the remaining input which \nis in L(X) . Thus , the state behaves much like a state of an LL parser. 3.5: Example. Let G be the rrg \nwhose productions are: T!*F T T F ~jT) F  A GLC(l) parser for G is given in the table in Figure 1. The \nfigure also gives the first few configurations which the machine enters o-n input ( a * a ) . // We \nnext give an algorithm for con\u00adstructing a GLC(l) parser. Our algorithm is similar to the SLR(k) method \nof [D]; thus we call it the SGLC(k) method. While it is possible to give a full GLC(k) parser construction \nalgorithm which is analogous to the LR(k) method, the parsers which result are likely to be unacceptably \nlarge; thus, we have chosen a less powerful but more practical method. As with the LR(k) method, our \nalgo\u00adrithm identifies a parser state with a set of items defined as follows. 3.6: Definition. A GLC(k) \nitem is an object of one of the following forms. a) [Aw.62YI , where A+a(3fy is a production. b) [+.X] \nor [+X.], where X=S or X occurs in the trailing part of some production. // We next define closure and \ntransition operations on sets of items, again in complete analogy with the SLR(k) method. 3.7: Definition. \nLet Q be a set of items. The closure of C), denoted c1(Q) , is the smallest set of items containing Q \nand such that if [A+a.B6] or [+.B] is in cl(Q) and CEA*(B) then [c+.y]Ecl(Q) for each production C+y. \n// 3.8: Definition. An item is essential ~it is of the form [+.X1 or it has at least one symbol to the \nleft of the dot. The basis of a set Q of items is the set of all essential items in Q. Qisa proper item \nset if Q = cl(basis(Q)). // 3.9: Definition. Let O be a set of GLC(0) items; let E (NU1). Then we define \na) goto(Q,X)= {[A+tiX.(3] \\ [AMI.XB]EQ}~ {[+X.] I [+.X]CQ}. b) Goto(Q,X) = cl(goto(Q,X)). Note that \ngoto(Q,X) = basis(Goto(Q,X)). We extend Goto to strings in the obvious way: Goto(Q,e)=Q Goto(Q,aX) =Goto(Goto(Q, \na),X) . The analogous definition for the goto function leads to inconsistencies; so we do not define \ngoto(Q,a) if lcI\\#l. // With the machinery which we have just developed, we can describe the states of \nan SGLC parser quite succinctly as follows. 3.10: Definition. The set of GLC(0) or SGLC states for G \nis the set of all states of the form Goto(Q X,u) , where a&#38;(NUZ)~ X=S or X occurs in the trailing \n 11.z part of some production; and the state does cause additional items to be added QX=C1({ [+.X]]). \nby closure, and these additional items may // have actions defined on them. Where no confusion should \nresult, we abbreviate c1({ [+.X]}) as cl(x) . Hawinq defined the GLC(0) states, we now a~velop the SGLC(k) \naction function, a GLC action function using simple look\u00adaheads of length k. In the SLR(k) method, simple \nlookaheads are calculated using follow sets. The calculation of simple GLC lookaheads also uses follow \nsets; however, for technical reasons having to do with left recursion, we must introduce a second type \nof follow set which considers only the occurrences of a symbol in the trailing part of some production. \n3.11: Definition. Let X be any symbol The k-symbol trailing follow of X, denoted TFOLk(X) , is the set \nof all *IF UEX such that there exists a derivation S&#38;Aw=~aB?yX8w and UEFIRSTk(6W) . // Intuitively, \nTFOLk(X) consists of those strings of at most k terminals which can follow an occurrence of X in a trailing \npart in some sentential form. 3.12: Definition. Let Q be a set of GLC(0) *k items. For any UEI, the SGLC(k) \naction function ACtiOII(Q,U) is defined by: a) Action(Q,u)=shift if 1) Q contains=tem [A+a.a(3], with \nasZ and ucFIRSTk (a@)fBkFOLk(A) , or 2) Q contains [+.a] and us{a}@k TFOLk(a) . b) Action (Q,u)=announce \ni if Q con tains [A+a.?6], with u&#38;FIRSTk(E3)@k FOLk(A) , c) Action(Q,u)=pop if Q contains [+X.] and \nuETFO~X). d) If none of a)-c) apply then Action(Q,u) is undefined or error.  If more than one of a)-c) \napplies, the Action function is said to be incon\u00adsistent, or the set Q is said to contain a conflict \non lookahead u. // A terminal symbol to the right of the dot in some item produces a shift action, and \na recognition symbol to eight of the dot produces an announce action, while a nonterminal to the right \nof the dot does not produce any action directly. Thus , terminals and recognition dsymbols are called \naction symbols. Note, however, that a nonterminal to the right of a dot 3.13: Definition. G is said to \nbe an SGLC(k) grammar if the SGLC(k) action function for the GLC(0) states of G is consistent. // An \ninconsistent action function defines a nondeterministic SGLC(k) machine in the obvious way. In fact \nthe (nondeterministic) SGLC(0),SGLC(l), . . . machines for G all recognize exactly L(G) . In the next \n~ew lemmas we establish this fact, thusProv~ng the correctness of the SGLC(k) parser if the parser is \nconsistent. 3.14: Lemma. Let M=(~,Action,Goto) be the SGLC(k) machine for G. Let x and y be strings \nin Z; and XE(N~~). Then a) If (Q,xY) &#38; (QQ ,Y), where Q = Goto(Q,X)j then X~>x, and b) If (QQx,xY~&#38; \n(Q,y), where Qx= cl(X) , then X=>x. The sequences of moves in a) and b) are assumed never to empty the \nstack. Proof: The proof is by induction on the number of moves of M. Basis: One move. a) The move must \nbe either shift, in which case X=x=a, or announce ~ some some production X+?, in which case x=>f=>e=~. \nb) A state Qx cannot disappear in a single move, so the basis is true vacuously. Inductive Step: a) \nIf more than one step is required, then X N, and Q must be pushed onto the stack by an announce i action \nfor some i. Let the ith production be X + . . .Yr2Yr+l. ..Ys. The sequence of moves 1 must be (Q,x1 \n. ..XSY) L (QQ1,X2. . .XSY) # (QQ1. ..Qr,Xr+Y). .Y) 1-(QQ Qy~. ..Oyr+l,Xr+XS Y)XSY) F (QQ QyS. ..Qyr+2rXr+X~ \nY)X~Y) ; (QQ ,Y), where the announce i action is performed by Qr. From the definitions of the Action \nfunction, Q-must contain the item [A+Y1. ..Yr iY .Y~l ; from the definition r+l of the Goto function, \nQr=Goto(O,yl. . .Yr) , thus Qi=Goto(Qi_l,Yi) for l~i~r. By the inductive hypothesis (a) , Yi~>xi for \nl<i<r. By inductive hypothesis (b) ,  Yi~>xifor r+l<i<s, and the result follows.  b) By definition \nof the Goto function, an item in Goto(QX,a) must have some suffix of a to the left of the dot. Thus, \nan announce action in such z state cannot cause QX to be removed from the stack, and QX must be removed \nby a pop action. The only successor of QX with a pop action defined is Goto(QX,X) . Thus , (QQxrxY) f \n(QQXQ ,Y) * !2 (QrY)I  where Q =Goto(Qx,X) . The inductive hypo\u00ad thesis applies to the sequence (QX,X;) \ni: (QxQ /Y) to yield X=>Xr as desired. // 3.15: Lemma. Let M be as in Lemma 3.14. Then * a) Let X~>x; \nlet yc~ such that k:yc FOLk(X) , and let Q and Q be states such that Goto(Q,X) = Q . Then (Q,xY) ; (QQ \n,Y). b) Let X~>x; let ycZ* such that k:ys TFOLk(X) , and let Q and Qx be states with QX=C1(X). Then \n(QQX,XY) ~ (Q,Y). Proof: The proof is similar to the proof of Lemma 3.14, and is omitted. // 3.15: \nTheorem. The (nondeterministic) SGLC(k) machine for G recognizes L(G) . Proof: Immediate from Lemmas \n3.14 and 3.15.. // 3.17: Corollary. If the SGLC(k) parser for G has no conflicts, then it is correct. \nProof: The SGLC(k) parser is a (determi\u00adnistic) SGLC(k) machine. // We end this section by presenting \na simple space optimization which can be performed on an SGLC(l) parser. 3.18: Definition. The pop-optimized \nSGLC(l) parser for G is constructed from the SGLC(l) parser By deleting states of the form {[+x.]}, for \nall X, and replacing them by the single state Qpop, where Action(Q UC z pop u)== k Goto (Q ,Z)=error \nZe(N~Z). pop // 3.19: Theorem. Let G be SGLC(k). Then the pop-optimized SGLC(k) parser for G is consistent \nand recognizes exactly L(G). Proof: The proof is straightforward, and ~itted. // 3.20: Example. Figure \n2 gives the SGLC states which were used to construct the (pop-optimized) SGLC(l) parser of example 3.5. \n// ~. Properties of SGLC(l) Grammars In this section we present some results on the behavior of SGLC(l) \ngrammars and parsers when the lengths of left corners are changed. In particu lar, we show that for each \nproduction there is a well-defined shortest left corner which can be used in a consistent parser, and \nthat this shortest left corner is independent of the left corners chosen for the other productions. For \nthe special case of grammars without left recursion, we show that a minimal left corner parser, constructed \nusing the shortest possible left corners, is guaranteed to be the smallest parser in the class. First, \nwe develop some useful notation. 4.1: Definition. Let GO be a cfg. The binary operations min and max \nare defined on the productions of rrg s based on Go That is, min chooses the leftmost posi tion of the \nrecognition symbol, and max chooses the rightmost position. We extend min and max to grammars production\u00adby-production; \nthat is, if G and G are rrg s based on GO, then the productions of min(G , G ) are min(p~,p~), where \np; and p! are the ith productions of G and G; respectively. Max(G ,G ) is defined analogously. Finally, \nwe define G, 0 G!! iff min(G ,G ) = G iff max(Gr,G ) = G // 174 The set of all rrq s based on a given \none, and thus has a well-defined inverse. GO clearly forms a lattice, with min as Note also that hi and \nh. commute, if i+j. the greatest lower bound operator and max as least upper bound. The top element of \nthe lattice has recognit~ symbols at the right ends of its productions; the bottom element has the recognition \nsym\u00adbols at the left ends. We shall show that the set of SGLC(l) rrg s for GO is closed under min and \nmax, and hence forms a (sub-) lattice. In fact, we prove the slightly stronger result that for any rrg \ns G and G based on GO, a) If G and G are SGLC(l) then min(G ,G ) is SGLC(l). b) If G is SGLC(l) and G \n< G , then G is SGLC(l) . Once this result has been established, it follows that the SGLC(l) rrg s based \non GO form a sublattice which contains ~. Being a finite lattice, it also has a unique minimum element--not \nbottom, unless GO is LL(l)--called the minimal left corner or SMLC(l) grammar for GO, in which the recognition \nsymbols are as far to the left as possible. To prove these claims, it is sufficient to restrict our \nattention to transforma\u00adtions in which a single recognition symbol is moved one position to the left \nor right. If G < G , then we can transform G to G,, , or vice versa, by a finite sequence of transformations \nof this simple type. Throughout this section, we let GO=(N,Z,PO,S) be a cfg, and G = (NU~,Z,P,S) be some \nrrg based on GO. 4.2: Definition. We define hi to be the function which moves the ith recognition symbol \none position to the left in productions of an rrg based on GO; i.e., hi(A+aX$f3) = A+a$X(? h (C+y) = \nC+y for any other production The function hi can be applied to items and sets of items in almost the \nobvious way; the only difficulty we encounter is in applying hi to the item [A+aX lf3]. Here the obvious \nresult, [A+a~XO(3], is not a legitimate item, since the recog\u00adnition symbol appears to the left of the \ndot. Thus, we define hi([A+aX*f6]) = [+x.]. // If the ith production of G is a top\u00addown rule--i.e., \nif the recognition symbol ? appears at the left end of the rule-\u00adthen of course hi is not defined. Note \nthat whenever it is defined, hi is one-to\u00ad1 We denote by Gi the rrg which results from applying hi to \nall the productions of G. We also subscript the name of a function or relation by i to indicate that \n it is to be computed with respect to Gi. Thus, cl(Q) means the closure of Q with respect to G, while \nCli(Q) means the closure is to be taken with respect to Gi. The following two technical lemmas characterize \nthe interactions between the hi and closure functions. 4.3: Lemma. Let A+aXf~ be the ith pro\u00ad~ti~ G, \nand let Y#X be a symbol in (NLR) . Then a) X:(X) -{2} = X*(X). b) A*(Y) ~ X:(Y) -{2} ~a*(Y) -x (x) Proof: \nStraightforward. // 4.4: Lemma. Let Q be any proper set of ~ms for G. Let A+aXi~ be the ith production \nof G. Then a) hi(basis(Q)) = basis(hi(Q)) b) h~(goto(Q,Y) ~goto(hiiQ),y) C) hi(cl(Q)) ~ cli(hi(Q)) d) \ncli(hi(Q)) ~hi(cl(Q)) -cli(x) e) cli(X) = hi(cl(X)) f) hi(cl(Q) )-cli(X)=hi(cl(Q) -cl(X))  Proof: a) \nThis follows since hi leaves items of the form [+*Y] and [+Y ] unchanged, and does not change the number \nof symbols to the left of the dot in other items. b) Similar to (a). c) By part (a) , and by the definitions \nof basis and closure, we know that basis(cli(hi(Q))) = basis(hi(Q)) = hi(basis(Q)) ~hi(cl(Q)) Now consider \na closure item of cli(hi(Q)). Such an item is of the form [D+*6], where [B+f310C621 c basis(hi(Q)) and \nDEA~(C). By part (a) , hi 1( [B+f31*C62]) is in basis(Q); this item clearly has C at the right of the \ndot. By Lemma 4.3, Dck*(C). Thus , h; ([D+-d]) E cl(Q), as desired. d) Similar to (c), with DEA~(C)-a~(X) \ne) Immediate from Lemma 4.3(a) . f) Immediate from (e) . since R ~ @i~Q) . Substituting the defi\u00ad // \n The next lemma is an important one. It describes how SGLC states change in going from G to Gi. The following \nfunction definit~on is useful for that description. 4.5: Definition. Let Q be a proper set =items for \nG. Then we define @i(Q) = cli(hi(basis(Q))) // 4.6: Lemma. Let G and Gi=hi(G) have SGLC(l) machines \nM and Mi with states Z={ Q1, Q2,.. .} and ~={Rl,R2, ...}, resp. Let the ith production of G be A+aX?f3. \nThen a) Goto(Ry,u) C Oi(Goto(Q ,a)) for *Y any Y#X and any UE(NUZ) . b) Goto(RX,a) ~ @i(Goto(Q,~)) for \nanY as(NUi)+ and any Q&#38;~ such that Goto(Q,X) + fl. c) RX ~ hi(Q) u {[A+ xI}. Proof: We prove part \n(c) first, so it may =voked in the proof of (a) and (b). c) Note that if Goto(Q,X) # ~, then Q contains \nan item with X immediately to the right of the dot. Thus c1(X)-{[+OX]} is a subset of Q. Now by Lemma \n4.4(e) hi(cl(X))-{[+ X] }=hi(cl(x))-hi( [+.x]) = Cl< (x)-{ [+ xl}. Thus hi(QY ~cli(x)-{ [-+-Xl}, and \nthe result follows. (a,b) These are proved by induction on the length of the shortest accessing string \na.. Basis: \\al=o. Part (b) is vacuously true; for part (a), R =cli(y) =cli(hi([+oY])) =cli(hi (basis(Qy)))=Oi \n(Qy) . Inductive Step: Let R =Goto(R,Z) =cli(goto(R,Z)) , for some state R of Mi and some ZE(NUZ). By \nthe inductive hypothesis, R~O (Q) or R=Rx~ hi(Q) {[A+ XI} for some state Q of M. We consider each case \nseparately. Case 1: R C @i(Q) for some state Q in M. We show that R ~ @i(Q ), where Q = Goto(Q,Z) . Clearly \nR =Goto(R,Z) ~ Goto(@i(Q),Z), nitions of Goto and Oi, we get R ~cligoto (clihibasis(0) ,2). By Lemma \n4.4(C) , R ~ cligoto(hicl basis(Q),Z) = cligoto(hi(Q),Z) . Now by Lemma 4 .4(b), R ~clihigoto(Q,Z) = \n@i(Q ), as desired. Case 2: R=Rx. Let Q be any state of M . containing [A+a-Xf!3] . Clearly such a state \nmust exist. Since X appears imme\u00addiately to the right of the dot, cl(x) CQ U{ [+*X]}. Thus , by ~ermna \n4.4(e), Rx=cli(X) =hi(cl(X)) &#38; hi(Q {[+*X1}). By Lemma 4.4(b), goto(hicl(x),z) < higoto(Qu{ [+oX]},Z) \n=hi(basis (Q ) LJ {[*X-]}) =hi(basis(Q ) ) , where the last step follows because hi([A+aX*lf3] )=[+X \n]. Applying Cli to both sides, we get R =@i(Q ), as desired. // Next we show that if Gi is SGLC(l) , \nthen the conditions (a) and (b) in Lemma 4.5 can be strengthened to equality. One preliminary lemma is \nrequired. 4.7: Lemma. Let G be SGLC(l) with parser M, and Let Q be some state of M. If Q contains an \nitem [A+a.$X~] , then no symbol in L*(X) appears immediately to the right of the dot in any item of Q. \nProof: We assume the lemma is false and me a contradiction. Thus, we suppose some symbol in A*(X) occurs \nimmediately to the right of the dot in some item of Q. Without loss of generality we may assume the symbol \nis an action symbol, since for any Y there is an action symbol in I*(Y) . There are three cases to consider: \nCase 3: The symbol is a&#38;Z. Clearly, aEFOL(i) ; thus Q has a shift-announce i conflick on lookahead \na, contrarv to the hypothesis that G is SGLC(I) . Case 2: The symbol is $#1. Since ~ can  appeax adjacent \nto f in a sentential form, there exists some asFOL(i)~FOL(j). Thus, Q has an announce i-announce j conflict \non lookahead a, again contradict ing the SGLC(l)-ness of G. Case 3: The symbol is f itself. In this \n case a=e, A&#38;k*(X) , and thus X&#38;N. Let Q  be any parser state in which an X occurs immediately \nto the right of the dot in some item. Clearly such a state must exist, and it must contain the item [A+ \n$(3]. NOW consider the shortest derivation of a terminal string from X. Clearly this derivation cannot \nmake use of production i, since X occurs in the right part of that production. Thus , there is some other \naction symbol besides f in A*(X). There are two (sub-) cases: Case 3.1: CE~*(X), and C+jy. Clearly ~e=ists \nsome aEFIRST(Y)@FOL(C)~ FIRST(XB)@FOL(A); and thus Q has an announce i-announce j conflict on lookahead \na, a contradiction. Case 3.2: CEA*(X), and C+ay. As in ~ ~, a FIRST(X6)@FOl(A). Thus , Q has a shift-announce \ni conflict, a contrad=n. Thus, in every case the assumption that the lemma is false leads to a violation \nof the SGLC(l) condition,, and the lenuna is proved. // When Giis SGLC(l), the following lemma exactly \ncharacterizes the states of the SGLC machine for Gi in termS Of the states for G. 4.8: Lemma. Let G and \nGi have SGLC(l) machines M and Mi with state sets ~and~, respectively; and suppose that M. is consistent \n(i.e., that Giis SGLC~l)) . Then the states of Mi are Proof: The proof is an induction similar to the \nproof of Lemma 4.5(b) and (c). The basis is identical. Induction Step: Let R =Goto(R,Z) = cli(goto(R/Z)) \n, for some state R of Mi and some Z (N~Z). By the inductive hypothesis, R=@i(Q) for some state Q of \nM, or R=Rx. There are several cases: Case 1: R=@i(Q) and Rcontains .t:he item [A-wxofX(3]. By Lemma \n4.4(c) and (d), hicl basis(Q) ~clihibasis(Q) = hi(cl(basis(Q) )-cli(X) ,  that is, hi(Q) ~ @i(Q) =R~hi(Q)-cli(X). \n Since R contains [A+aQfXf3], by Lemma 4.7 no symbol in A;(X) appears immediately to the right of the \ndot in any iEem of R. Thus, since Goto(R,Z)#%, it follows that Y $ A;(X) . Applying this fact to the \nabove inequality yields goto(R,Z) = goto(hi(Q),Z). Since Z f! XJ(X), clearly 2+X. Thus , hi never moves \nt across Z, and the func\u00adtions goto(. ,Z) and hi commute. Thus goto(R,Z) = hi(goto(Q,Z)) and R =cligoto \n(R,Z)=clihigoto (Q,Z) =@i(Q ) as desired. The remaining cases are similar to this one, and are left \nto the reader. // We are now ready to prove the key lemma for showing that minimal left corners exist. \nWe show that if moving 2 to the left and moving $ to the left separately preserve SGLC(l)-ness, then \nboth f and f can be moved and the resulting grammar will still be SGLC(l). 4.9: Lemma. Let Gi=hi(G) and \nGj=hj (G) both be SGLC(l). Then G. . =hj (hi(G)) =hi(hj(G)) is also SGLC(~;. Proof: Let M, Mi, M., \nand M. be the 3 Ij SGLC(l) machines for G, Gi, Gj, and Gij, respectively, and let the ith and jth productions \nof G be A+aXf~ and C+yYj6. Two applications of Lemma 4.5 show that the states of M. are of three types: \nlj a) o! (@i(Q)) for some state Q of M~ wher~ ~~=clij(hj (.)). b) ~~(cli(x)). c) clij(Y), We show that \nstates of type (a) are con\u00adsistent, as this case is the most com\u00adplex. The proofs for type (b) and (c) \nstates are left to the reader. Consider a state T=@~(R)=@~ (@i(Q)). Inserting definitions for 0! and@i, \nT = clijhjbasis clihib~sis(Q). This simplifies to T = cl,.hdh,basis(Q). ~JJ~ By Lemma 4.4(c) and the \nfact that hiand h. commute, T=cl ijhihjbasis(Q) c hicljhjbasis(Q) =hi@j (Q) . Similarly, TG hj@i(Q). \nNote that application of hileaves all actions unchanged, except possibly for addition of announce i on \nlookaheads in FOL(~) . Moreover, if an announce i action is introduced, then the original set of items \nmust have had some other action defined for every lookahead in FOL(t) . A similar argument applies to \napplications of h.. 3 Both R=@i(Q) and S=@(Q) are con\u00adsistent, since they are s 2 ates of Mi and M ~, \nrespectively. Thus, every conflict J in h. (R) involves an announce j action, 1 and every conflict in \nhi(S) involves an announce i action. Since T chj(R) and  T Ghi(S), we conclude that the only pos\u00ad  \nsible conflicts in T are between announce i and announce j on some lookahead a in FOLij (f) ~ FOLij (S). \nSuppose T has such a conflict. It is easily shown that R must have a Y imme\u00addiately to the right of the \ndot in some item, and that the unique action of R on lookahead a must be announce i. Thus , * IEA:(Y) \n. SimilarlyJ $Caj(x). However, aEAJ(X) implies YcA*(X).J Since by Lemma 4.3(b) k*(X)=A~(X)-{t}, we conclude \nthat YEl~(X), and so fEA~(X). Since ? appears immediately to the left of X in the ith production, and \nsince G. is assumed to be 1 SGLC(l), this violates Lemma 4.7, giving us the desired contradiction and \nproving the lenima. // To-show that the SGLC(l) rrg s based on G~ form a lattice, we must also show \nclosure under max. We give a slightly stronger result--tb.at moving recognition symbols to the right \npreserves SGLC(l)\u00adness. 4.10: Lemma. If Gi is SGLC(l) then G is SGLC(l) . Proof: The essential ideas \nare contained =e proof of Lemma 4.6. The proof of this lemma is left to the reader. // Finally, we have \nreached the promised theorem a%cerking closure under min and max 4.11: Theorem. Let G and G be rrg s \nbased on the same underlying cfg. Then a) If G and G are SGLC(l) , then min(G ,G ) is SGLC(l) . b) If \nG < G and G is SGLC(l) then G is SGLC(l) . Proof: Follow from finitely many appli\u00ad=ns of Lemmas 4.9 \nand 4.10. // 4.12: Corollary. Every SGLC(l) grammar has a well-defined set of minimal left corners. // \nWe now consider the relative sizes of SGLC(l) parsers. We assume all SGLC parsers are pop-optimized. \nFor granmars without left recursion, we can show that if G < G then G has a smaller SGLC(l) parser than \nG . First we relate the sizes of SGLC(l) and SLR(l) parsers. 4.13: Lemma. Let Go be and SLR(l) cfg and \n G be the rrg based on Go in which all top recognition symbols are at the extreme right ends of their \nproductions. Then G is SGLC(l) and top #SGLCstates(G top) = #SLRstates(Go) + 1. Proof: It is easily \nseen that the SGLC(l) parser is isomorphic to the SLR(l) parser, except for the additional state o (Each \nreduce action of the SLR pa~~~~ is simulated by the SGLC parser as an announce move followed immediately \nby a=). // Now let GO be an SLR(l) grammar with no left recursion. The following lemma states. that the \nnumber of SGLC states decreases as recognition symbols are moved. to the left. 4.14: Lemma. Let G and \nGi=hi(G) be SGLC(l) grammars based on Go, with state sets ~ and R , respectively. Let the ith production \nof G be A+aX?~. Then #SGLCstates(Gi) ~ #SGLCstates(G)-~ where 1 if X occurs in some trailing 6= part \nin G, { O otherwise. Proof: The proof is based on Lemma 4.8, which says that the states for G. are \nQ= ~cli(x)}u{~i(~) \\ ~c~}, and on the observation that @l is one-to\u00adone except on states containing [A+aX.~~] \n. Direct application of Lemma 4.8 yields #SGLCstates(Gi) L #SGLCstates(G)+l. However, X is not left-recursive. \nThus , by Lemmas 4.4(d) and 4.7, for any state Qz~ containing [A+a.Xf~], Goto(Q,X)= &#38;a; 161 . This \nstate is distinct but is mapped by Oi into pop {[+X +=RPOP, resulting in a reduction of 1 in the number \nof states. Finally, suppose X occurs in some trailing part of G. Then cl. (X) is not an additional state, \nagain r$sulting in a reduction of 1 in the number of states. // Repeated application of the above lemma \nyields 4.15: Theorem. Let G be an SGLC(l) grammar based on a cfg GO with no left recursion. Then #SGLCstates(G) \n~ #SLRstates(GO) +l+s-t, where s is the number of distinct symbols which occur in trailing parts of \nproductions of G, and t is the total length of all the trailing parts of G. Proof: Follows immediately \nfrom Lemmas 4.13 and 4.14. // Thus, the minimal left corners for GO result in the SGLC(l) parser with \nthe few\u00adest states. ~. Efficient SGLC(l) Testing Hunt, Szymanski and Unman [HSU], using techniques for \nfast composition and transitive closure of sparse rela\u00adtions, have developed an 0(n2) algorithm for testing \nwhether a cfg is SLR(l). Their algorithm can be used almost un\u00adchanged to test whether a grammar G is \nSGLC(l) for a particular choice of left corners. In this section we show how their algorithm can be modified \nto compute the minimal left corners for a grammar G with no left recursion. The algorithm s 0(n2) running \ntime is preserved. The basic approach of the SLR(l) testing algorithm is to construct all pairs of items \nwhich appear together in some parser state. If a conflicting pair of items is generated, the algorithm \nhalts, declaring that its input is not an SLR(I) grammar. The algorithm keeps a queue READY of pairs \nof items which have been shown to occur together. Initially READY contains all pairs of distinct items \nof the form [S+ a] . The items are processed by the following algorithm: while READY # ~ do begin . remove \n(I,J) from READY if CONFLICT(I,J) then error else begin for each (I ,J ) in GEN(I,J) do INSERT(I ,J \n) end end Here GEN(I,J) is the set of all pairs of items which can be produced from (I,J) by a single \napplication of the closure or goto operations. INSERT(I,J) checks to see whether the pair (I,J) has been \nencountered before, and if not adds it to the READY queue. The SGLC testing algorithm is compli\u00adcated \nsomewhat by the fact that the rru for which pairs of items are being gene\u00adrated is actually being changed \nby the algorithm. Initially, all left corners are empty; that is, all recognition symbols are at the \nextreme left ends of their productions. When a conflict is encountered, the algorithm must try to resolve \nthe conflict by moving some recog\u00adnition symbol to the right. Most pairs of items which have already \nbeen processed are unaffected by this change to the grammar. The only exception is that items in which \nthe recognition symbol $, currently being moved,appear immediately to the right of the dot must be processed \nagain, since they can now give rise to additional items by closure. Let GO=(N,Z,PO, S) be the cfg whose \n minimal left corners are to be computed, and assume the productions of G have been numbered from 1 to \np. To !!acilitate moving recognition symbols, the algorithm maintains an array RSPOS[l:p]. The value \nof R$POS[il gives the current posi\u00adtion of i in the ith production. The items used in the algorithm are \nitems in GO--that is, they contain no recognition symbols. The closure and goto operations, however, \nmust behave as if the recognition symbols were present in the positions specified by the current value \nof RSPOS. One more data structure which we require is an array CONT[l:p] of continu\u00adations. The value \nof CONT[i] is the set of pairs of items which have already been processed in which ? appears immediately \nto the right of the dot in one of the items. When I is moved to the right, the item pairs in CONT[i] \nare removed and reprocessed. Finally, we need a procedure DECIDE(I,J) which, when given a conflict\u00ading \npair of items as input, decides which recognition symbol must be moved to the right to resolve the conflict. \nThe complete algorithm follows: 5.1: Algorithm. Computing minimal left =ners. A cfg GO=(N,Z,PO,S).  \nZw!&#38; output : The array RSPOS[l:p] giving the length of the minimal left corner for each production \nof G , or an error indication if GO is got SLR(l) . Method: 1. READY+{ ([+.X], [X+-aj)l XEN,XWEPO}. \n 2. CONT[i]+@ l<i<p  3. RSPOS[i]+O l<i<p  4. while READY#$ do begin  5. remove(I,J) from READY \n 6. if CONFLICT(I,J) then begin  7. i-+DECIDE (I,J) 8. if RSPOS[i] =productionlgth [i] then error \n 9. RSPOS[i] RSPOS[i]+l 10. for each (I ,J ) in CONT[i] do INSERT(I ,J ) 11. CONT[i]+fl 12. end 13. \nelse begin  14. for each 1next to adot in I or J do add (I,J) to CONT[i] 15. for each (I ,J ) in GEN(I,J) \ndo  INSERT(I ,J ) 16. end 17. end  The procedures CONFLICT, INSERT, GEN, and DECIDE are given below. \n// The GEN function is the same one used in the SLR testing algorithm: GEN(I,J) = C uG where C is the \nset of all pairs (K,L) such that K E {I,J} -L comes from I or J by one closure step, and -K #L. G is \nempty unless I and J both have the Same symbol to the right of the dot, in which case G = {(goto(I,X),goto \n(J,X) )}. The CONFLICT function makes use of the following lemma. 5.2: Lemma. An item of the form [+-Y \n] =not occur in any pair. Proof: Suppose [+Y*] and [C+YY ~] occur together in some state. Then [+*YI \nand [C+Y Y61 must occur together. But the only state in which [+-Y] occurs is cl(Y) . Thus , CEX*(Y), \ny=e, and Y:X+(Y) , contrary to our assumption that G. has no left recursion. y // Thus , the only possible \nconflicts are of the forms a) [A-wff3] vs. [C+y a61 with a&#38;FOL(i) b) [A.+a.t~] VS. [C+y.~6] with \nFOL(f) ~ FOL( j) # ~ Of course, FOL(f) and FOL(S) cannot be ~recom~uted, as the positions of f and ~ \nckange ~uring the exe~ution of the algorithm. To avoid this difficulty, we do not compute follow sets \nfor recognition symbols . We consider instead positions in Go By straightforward application of the techniques \nof [HSU], we can compute FOL(p) for each position p in Go, and the relation R such that pRq iff FOL(P) \nnFOL(q) # fl. Both of these can be computed in 0(n2) steps. At any time during exe\u00adcution of the algorithm, \nFOL(f) is simply FOL(p) , where p is the current position of f. The INSERT procedure is based on the \nfollowing definition. 5.3: Definition. Two items I and J are GEN-equivalent if a) I and J correspond \nto the same item of Go, and b) I has a recognition symbol imme\u00addiately to the right of the dot if and \nonly if J does. // GEN-equivalent items behave equi\u00advalently in Algorithm 5.1. Fo,r this reason, after \nmoving 2 it is necessary to reprocess only items from CONT[i]. All other items are GEN-equivalent with \ntheir old and new positions of ~. Following this definition, the INSERT procedure is simply: INSERT(I,J) \n: if no equivalent pair (I ,J ) has been added to READY then add (I,J) to READY Note that there are \n0(n2) equivalence classes of item pairs; thus INSERT can be implemented with a matrix of 0(n2) bits; \nand no more than 0(n2) pairs of items altogether can be added to the READY queue. Now only the DECIDE \nfunction remains to be developed. Given conflicting items I and J, DECIDE must determine which recognition \nsymbol must be moved to resolve the conflict. Luckilyr there are only two types of conflicts which can \noccur. Case 1: Shift-announce conflicts. Let ~+~*1~= [C+y.a6] . It fct-lows from Lemma 4.6 ( applied \nin reverse ) that moving some other recognition symbol 3 to the right must leave some pair (1 ,J ) of \nitems which is GEN-equivalent to (I,J) . Thus , the conflict cannot be resolved without moving f, and \nDECIDE can safely return i. Case 2: Announce announce conflicts. Let I=[A+a.lX~] and J=[C+y.~Y6] conflict \non lookahead a. As in Case 1, the conflict cannot be resolved without moving either i or ~; the question \nis which one should move. Suppose a consistent parser can be produced without moving ?--thus, f moves \nright. Then some state contains [A+a.X~ll~2] and [Csy.~Y6]. Since a FIRST(X )fBFOL(A) , there must be \nsome action symbol in A*(X) with an action defined on lookahead a. Since we assume that moving ? has \nresolved all conflicts, it follows that ~E~*(X) ; thus y=e and YEa*(x) . Similarlyr if 1 can remain sta \n~ ~onary then a=e and X&#38;~~(Y) . Note that the conditions Ysk~(x) and XSk~(Y) cannot occur toqetherr \nsince that would imply XCk~(X) , contrary to our assumption that G has no left recursion. Thus , DECIDE \ncan $afely return if YEk~(X) then i else j  * The relation AO can be precomputed in 0(n2) steps. 5.4: \nTheorem. Algorithm 5.1 correctly computes the minimal left corners for a non-left-recursive grammar GO. \nProof: The proof is a fairly straight\u00adforward formalization of +he above discussion, and is omitted. \n// 6. Conclusions  A new formal parsing algorithm, the SGLC(k) algorithm, has been described. SGLC parsing \nshares most of the virtues of SLR parsing, including applicability to a large class of grammars and ease \nof testing. For grammars without left\u00adrecursion, SGLC(l) parsers are guaranteed to be smaller than the \ncorresponding SLR(l) parsers. References [A] T. Anderson, Syntactic Analysis of LR(k) Languages , Ph.D. \nThesis, Computing Laboratoryr University of Newcastle Upon Tyne. [AU] A.V. Aho and J.D. Unman, The Theory \nof Parsing, Transla~n and Comfiling, Prentice-Hall, ~lewood Cliffs, N.J., 1973. [B] B.M. Brosgol, Deterministic \nTranslation Grammars , Ph.D. Thesis, Center for Research in Computing Technology, Harvard University, \n1974. [c] Y.E. Cho, Simple Left Corner Grammars , Pro;. Seventh Princeton Conference on Information Science \nand Systems~1973. [D] F.L. DeRemer, Simple LR(k) Grammars , CACM, 14:7, 1971. [HSU] H.B. Hunt III, T.G. \nSzymanski and J.D. U1 lman, Operations on Sparse Relations and Efficient Algorithms for Grammar Problems \n, Proc. 15 SWAT, 1974. [K] A.J. Korenjak, A Practical Method for Constructing LR(k) Processors} CACM \n12:11, 196-. [RL] D.J. Rosenkrantz and P.M. Lewis 11, Deterministic Left Corner Parsing , Proc. 11 SWAT, \n1970.  Go to Action * T1? *a)e ( a) ( I QT=QO 3\u00ad 4-- Q1 Q2 Q1 1\u00ad pop pop Q2 2\u00ad 2 2 Q*=Q3 Q8 ---- QF=Q4 \n3\u00ad 4-- Q8 Q ~=Q5 s Q8 ----- Q, =Q6  s Q8 - - Qa=Q7 s Q8 - - - Q8 pop pop pop pop pop Stack Inmt Action \n Qo (a *a) ann 3 QOQ2Q)QTQ( (a*a) shift QOQ2Q)QTQ(Q8 a*a) pop QOQ2Q)QT a*a) ann 4 QoQ2Q)QTQ2Qa a*a) shift \nQ0Q2Q)QTQ2QaQ8 *a) pop QOQ2Q)QTQ2 *a) ann 2 Figure 1. GLC(l) Parser QO . Q2 Q5 +. r T+F*2 +. ( T+o T1*F \nT+. F2 Q3 Q6 F+ 03(T) +.* +. ) F+ .4a Q4 07 +. F +.a Q1 F+ . 3 (T ) +T F+.4a Q8 T+To1*F pop Figure 2. \nSGLC Item Sets 182  \n\t\t\t", "proc_id": "512950", "abstract": "Brosgol [Br] formalizes the notion that parsing methods can be classified by the positions at which production rules are recognized. In an LL parser, each rule is recognized at the left end, before the rule's yield has been read; in an LR parser, a rule is recognized at its right end, after its yield has been read; and in an LC parser a rule is recognized after the yield of its \"left corner\" has been read. We generalize on these techniques by allowing the user to specify arbitrarily for each production rule the position at which that rule is to be recognized. The resulting GLC or generalized left corner technique includes the LR, LL, LC, and ELC methods as special cases. It also allows for less conventional parsing strategies, such as grammar splitting [K] with certain component grammars parsed top-down and the others parsed bottom-up, as suggested in [AU].This paper is organized as follows. In Section 2 we give some necessary background and notation. Section 3 defines GLC parsing. A canonical GLC(k) parsing technique can be defined analogous to the LR(k) technique. However, the resulting parsers tend to be unacceptably large. We therefore restrict our attention to the SGLC(k), or simple generalized left corner parsing technique, which is analogous to the SLR(k) technique of DeRemer [D]. We give an algorithm for the construction of SGLC(k) parsing tables and prove that the resulting parser is correct.In Section 4 we develop some potentially useful properties of SGLC(1) parsers. We show that there is a well-defined leftmost position at which each production rule can be recognized, and that a minimal left corner parser can be constructed which recognizes each rule as early as possible. We derive a simple expression relating the size (number of states) of an SGLC(1) parser to the size of the corresponding SLR(1) parser. If G is not left-recursive, then the minimal left-corner parser is the smallest parser for G in this class, while the SLR(1) parser is the largest.In Section 5 we extend the techniques 5 of [HSU] to give an O(n<sup>2</sup>) algorithm to test whether a grammar with no left recursion is SGLC(1), and if so to compute its minimal left corners.", "authors": [{"name": "Alan J. Demers", "author_profile_id": "81100529925", "affiliation": "Cornell University, Ithaca, N. Y.", "person_id": "P12362", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512950.512966", "year": "1977", "article_id": "512966", "conference": "POPL", "title": "Generalized left corner parsing", "url": "http://dl.acm.org/citation.cfm?id=512966"}