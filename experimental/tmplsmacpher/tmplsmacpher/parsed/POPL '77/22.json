{"article_publication_date": "01-01-1977", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1977 ACM 0-12345-678-9 $5.00 ABSTRACT INTERPRETATION : A UNIFIED LATTICE MODEL FOR STATIC ANALYSIS OF \nPROGRAMS BY CONSTRUCTION OR APPROXIMATION OF FIXPOINTS Patrick Cousot*and Radhia Cousot** Laboratoire \nd Informatique, U.S.M.G., BP. 53 38041 Grenoble cedex, France 1. Introduction A program denotes computations \nin some universe of objects. Abstract interpretation of programs con sists in using that denotation to \ndescribe compu tations in another universe of abstract objects, so that the results of abstract execution \ngive some information on the actual computations. An intuitive example (which we borrow from Sintzoff \n172]) is the rule of signs. The text 1515* 17 may be understood to denote computations on the abstract \nuniverse {(+), (-), (~)} where the se\u00admantics of arithmetic operators is defined by the rule of signs. \nThe abstract execution -1515* 17 => -(+) * (+) e> ( ) * (+) => ( ), proves that 1515 * 17 is a negative \nnumber. Abstract interpre tation is concerned by a particular underlying structure of the usual universe \nof computations (the sign, in our example). It gives a summary of some facets of the actual executions \nof a program. In general this summary is simple to obtain but inaccurate (e.g. 1515+17 => (+)+(+) > (-)+(+) \n=> (f)). Despite its fundamentally in\u00adcomplete results abstract interpretation allows the programmer \nor the compiler to answer ques tions which,do not need full knowled~e of program executions or which \ntolerate an imprecise answer, (e.g. partial correctness proofs of programs ignO\u00adring the termination \nproblems, type checking, pro\u00adgram optimizations which are not carried in the absence of certainty about \ntheir feasibility, . . .). 2. &#38;unmary Section 3 describes the syntax and mathematical semantics of \na simple flowchart language, Scott and Strachey[71]. This mathematical semantics is used in section 4 \nto built a more abstract model of the semantics of programs, in that it ignores the sequencing of control \nflow. This model is taken to be the most concrete of the abstract interpretatiOns of programs. Section \n5 gives the formal definition of the abstract interpretations of a program. * Attach= de Recherche au \nC.N.R.S., Laboratoire Associ6 no 7. ** This work was supported by IRIA SESORI under grants 75-035 and \n75-160. Abstract program properties are modeled by a com plete semilattice, Birkhoff[611. Elementary \nPro\u00adgram constructs are locally interpreted by order preserving functions which are used to associate \na system of recursive equations with a program. The program global properties are then defined as one \nof the extreme fixpoints of that system, Tarski [55]. The abstraction process is defined in section 6. \nIt is shown that the program properties obtained by an abstract interpretation of a program are consis \ntent with those obtained by a more refined inter pretation of that program. In particular, an ab stract \ninterpretation may be shown to be consistent with the formal semantics of the language. Levels of abstraction \nare formalized by showing that con\u00adsistent abstract interpretations form a lattice (section 7). Section \n8 gives a constructive defi nition of abstract properties of programs based on constructive definitions \nof fixpoints. It shows that various classical algorithms such as Kildall [731, Wegbreit[751 compute program \nproperties as limits of finite Kleene[52] s sequences. Section 9 introduces finite fixpoint approximation \nmethods to be used when Kleene ssequences are infinite, Cousot[761. They are shown to be consistent with \nthe abstraction process. Practical examples illus trate the various sections. The conclusion points out \nthat abstract interpretation of programs is a unified approach to apparently unrelated program analysis \ntechniques. 3 . Syntax and Semantics of programs We will use finite flowcharts as a language inde pendent \nrepresentation of progrems. 3.1 Syntax of a Progrwn A program is built from a set Nodes . Each node \nhas successor and predecessor nodes : 2Nodesl (men-succ(n)) n succ, n pred : Nodes+ <=>(ne n-pred(m)) \nHereafter, we note ISl the cardinality of a set S. ~Jhen ]Sl = 1 so that S = {~we sometimes use S to \ndenote x. The node subsets Entries , Assignments !, Tests , Junctions and Exits partition the set Nodes. \n An entry node (n c Entries) has no predecess... and one successor, ((n-nred(n) = @) and - \u00ad(In-succ(n)l \n= l)). An assi~nment node (n c Assignments) has one 3.2 Semantics o-f Pro$warns predecessor and one \nsuccessor (on-pred(n)l =1) and (In succ(n)l = l)). Let Iden= Expr This section develops a simple \nmathematical seman\u00ad be the distinct syntactic categories of identi tics of programs, in the style of \nScott and fiers and expressions. An assignment node n as Strachey[711 . signs the value of the right \nhand side expres\u00adsion expr(n) to the left hand-side identifier id(n) : expr : Assignments ~ Expr id : \nAssignments + Ident A test node (ncTests) has a predecessor and two successors, ((ln pred(n) I = 1) \nand (In succ(n)l = 2)). The true and false successor nodes are respectively denoted n-succ-t(n) and n \nsucc f(n): n-succ t, n succ-f : Tests + Nodes I (Vn c Tests, n succ(n) = {n succ t(n), n succ-f(n)}) \n. Let Bexpr b~ the syntactic category of boo lean expressions, each test node n contains a boolean expression \ntest(n) : test = Tests + Bexpr A junction node (n c Junctions) has one succes\u00adsor and more than one predecessor, \n((l n-succ(n)l 1) and (In-pred(n)l > 1)). Immediate predeces\u00ad sor nodes of a junction node are not junction \nnodes, (~n E Junctions, ~m e n-pred(n), not(m E Junctions)). An exit node n has one predecessor and no \nsucces sor, ((in-pred(n)l = 1) and (n-succ(n) = 0)) The set Arcs of edges of a program is a subset of \nYodes ~ Nodes defined by : Arcs ={<n,m. I (n e Nodes) anl (m ~ n succ(n))} which may be equivalently \ndefined by : Arcs ={~n,m I (m c Nodes) and (n c n-pred(m))}. We will assume that the directed graph Nodes, \nArcs> is connected. We will use the following functions : origin, end : Arcs + Nodes I (Va 6 Arcs, a \n= <origin(a), end(a)>) a succ : Nodes + 2Arcs I a succ(n) = {.n,ms I m e n succ(n)} Arcs a ~red : Nodes \n+ 2 -I *-pred(n) = {<m,n> I m E n-pred(n)} a succ t : Tests + Arcs a succ t(n) = <n, n succ t(n)> a \nsucc f : Tests + Arcs a-succ f(n) = <n, n-succ-f(n)> E.rample : v 4 ~:=1 f  false ( x=lo~ If S is a \nset we denote S0 the complete lattice obtained fromS by adjoining {1S, TS} to it, and imposinq the ordering \nL ~<x<TS for all x E S. Ihe semantic domain Values is a complete latti\u00adce which is the sum of the lattice \nBool = {~, false} and some other primitive domains. Environments are used to hold the bindings of identifiers \nto their values : Env = IdentO + Values We assume that the meaning of an expression expr c Expr in the \nenvironment e c Env is given by val [Eexprl (e) so that : a: Expr + [Env + Values]. In particular the \nprojection val I Bexpr of the function val in domain Bexpr has the functiona\u00adlity : val \\ Bexpr : Bexpr \n+ [Env + BOOII. The state set States consists of the set of -all information configurations that can \noccur during computations : States = Arcs x Env. A state (s c States) consists in a control state (cs(s)) \nand an environment (=(s)), such that : Vs e States, s = <es(s), env(s)>. we use a continuous conditional \nfunction cond(b, ~l!~ ~?i;~q~~lbt~sL~,e_ ~~l~er~~p~~t~e~~s~suse if b then e, else e z ~ to denote cond(b, \ne], e~.  If e c Env, v c Values, x c Ident then e [v/xl = Ay. cond(y = X, V, :(Y)). The state transition \nfunction defines for each state a next state (we consider deterministic programs) : n state : States \n+ States n state(s) = let n be end(cs(s)), e be env(s) within case n in Ass~nments => ~a succ(n),erval \n[[~(n)l (e)/id(n)]> . Tests .>  cond(val [[test(n)] (e) I Bexpr, <a-succ t(n), e>,<a-succ f(n), e>) \nJunctions => <a-succ(n), e> Exits => s esac (Each partial function f on a set S is extended to a continuous \ntotal function on the correspon ding domain S0 by f(l) = J, f(T) = T and f(x)=l if the partial function \nis undefined at x). Let 1 ~nv be the bottom function on Env such that (Vx e Ident , lEnv(x) = Lvalues). \ntrue J Let I states be the subset of initial states : X:=x+l I states = {<a succ(m),lEnv> I m c Entries} \nI A computation sequence with initial state is 6 I states is the sequence : s n = n-staten(is) forn=O, \n1,... where f is the identity function and fn+l = f . fn. -The initial to final state transition function \n. n-state : States + States is the minimal fixpoint of the functional : AF. (n-state o F) Therefore n \nstatem= y (lF. (n-state o F)) States-+States where YD(f) denotes the least fixpoint of f : D + D, Tarski[55]. \n4. Static Semantics of Programs The constructive or operational semantics of pro\u00adgrams defined in section \n3 considers the sequence in which states occur during execution. The funda mental remark of Floydr67] \nis that to prove static properties of programs it is often sufficient to consider the sets of states \nassociated with each program point. Hence, -we define the context Cq at some program point q c Arcs of \na program P to be the set of all environments which may be associated to q in all the possible computation \nsequences of P : E nv Cq c Contexts = 2 Cq ={e I(In > 0, ~is c I-states I <qje> = n staten(is))} The \ncontext vector Cv associates a context to each of the program points of a program : Cv E Context Vectors \n= Arcs + Contexts ~ = kq.{el (3n 2 0, 1 is c I-states I <q,e> = n-staten(i~))} According to the semantics \nof programs, the con text Cv(r) associated to arc r is related to the conte~s Cv(q) at arcs q adjacent \nto r, (end(q) =~rigin(r), ~~). From the defini\u00adtion of the state transition function we can prove the \nequation : Cv(r) = n context(r, Cv) where n-context : Arcs x Context-Vectors + Contexts is defined by \n: n-context(r, Cv) = case origi~r) in Entries =>{~nu} Assignments u Tests u Junctions => env on(r)(n \nstate(<q,e>) u e~v(q) q< a-pred(or~gin(r)) esac (We define env-on : Arcs + [States -2Env] to be kr. \n(ks. cond(r = CS(S), {~(s)}, 0))). Since the equation Cv(r) = n-context(r, Cv) must be valid for each \na=, Cv is a solution ~ the sys\u00adtem of forward equati~s : Cv = F cont(Cv) where F cent : Context Vectors \n+ Context Vectors : is defined by : F-cont(Cv) = Ar . n-context(r, Cv) Context-Vectors is a complete \nlattice with union u such that Cvi U CV2 = Lr. (Cvl(r) u ~(r)). . F-cent is order preserving for the \nordering ~ of COntext Vec tors which is defined by : <=> {Vr < Arcs, Cvl(r) SCv2(r)} Hence it is known \nthat F-cent has fixpoints, Tarski [55]. However, it is t-to exhibit examples which show that these fixpoints \nare not always unique. Fortunately, it can be shown that Cv is included in any solution ~ to the system \nof equa\u00adtions X = F-cent(X), (Cv s~). Tarski[55] shows that this prope=iquely~etermines Cv as the least \nfixpoint of F cent. Thus Cv can be~quivalently de\u00ad fined by : D1 : Cv =Aq. {e I(~n >0, I is c I-states \nI q,e> = n staten(is))} or D2 : Cv = Ycontext_vectors(F-cent) The concrete context vector Cv is such \nthat for any program point q c Arcs of the program P, (u) ~~q) contains at least the environments e which \nmay be associated to q during any exe\u00adcution of P : {lizO, 3 is ~ I states I <q,e> n statel(is)] => {e \ne Cv(q)} ((3) ~(q) contains only the environments e which may be associated to q dtiring an execution \nof P: {e c Cv(q)} > {3i > 0, q is E I-states I <qje> = n-statel(is)} Cv is merely a static summary of \nthe possible exe\u00ad~tions of the program. However, our definitions D] or D2 of Cv cannot be utilized at \ncompile time since the compu~tion of Cv consists in fact in running the program (for al~the possible \ninput data). In practice compilers may consider states which can never occur during program execution \n(e.g. some compilers consider that any program may always per\u00adform a division by zero although this is \nnot the case for most programs). Hence compilers may use abstract contexts satisfying (a) but not necessa\u00adrily \n(~), which therefore correctly approximate the concrete contexts we considered until now. 5. Abstract \nInterpretation of Programs ) 5.1 Formal Definition An abstract interpretation Iofa program P is a tuple \nI =<A Cent, O, S , T ,L , Int> where the set of abstract contexts is a complete o semilattice with ordering \nS, ({x $ y} <=> {X OY=Y}). This implies that A-Cent has a supre mum T. We suppose also A Cent to have \nan infimum L. This implies that A-Cent is in fact a complete lat\u00adtice, but we need only one of the two \njoin and meet opera~ns. The set of context vectors is defined by A Cent = Arcs + A-Cont. Whatever (Cv \n, Cv ) c A ~nt2 may be, we define : Cv T CV = Ar. Cv (r) 0 Cv (r) CV ~ CV = {~r e Arcs , Cv (r) < Cvf \n(r)} Y=ir. Tandi =Ar. L ~. .. <A-Cent, ., Z,T , 1> can be shown to be a com\u00adplete lattice. The function \n: ~ Int : Arcs x A-Cent + A-Cent defines the interpretation of basic instructions. If {C(q) I q e a-pred(n)} \nis the set of input con\u00adtexts of node n, then the output context on exit arc r of n (r < a succ(n)) is \nequal to Int(r, C). Int is supposed to be order preserving - Ya 6 Arcs, U(CV , Cv ) e A~nt2, {~ ~Cv } \n=> {Int(a, Cv ) < Int(a, Cv )} . The local interpretation of elementary program cons tructs which is \ndefined by Int is used to associate a system of equations with the program. We define &#38;t : A Cent \n-> A=nt ) &#38;t(Cv) = kr . Int(r, ~ Cv) w It is easy to show that Int is order preserving. Hence it \nhas fixpoints, Tarski[55]. Therefore the context vector resulting from the abstract inter\u00adpretation I \nof program P, which defines the global properties of P, may be chosen to be one of the extreme solutions \nto the system of equations Cv =Xt(cv).  5.2 TypoLogy of Absiract Interpretations The restriction that \nA-Cent must be a complete semi-lattice is not drastic since Mac Neille[37] showed that any partly ordered \nset S can be embed ded in a complete lattice so that inclusion is pre served, together with all greatest \nlower bounds and lowest upper bounds existing in S. Hence in practice the set of abstract contexts will \nbe a lattice, which can be considered as a join (u) semi lattice or a meet (n) semi lattice, thus giving \nrise to two dual abstract interpretations. It is a pure coincidence that in most examples (see 5.3.2) \nthe n or u operator represents the effect of path converging. The real need for th~ operator is to define \ncompleteness which ensures Int to have extreme fixpoints (see 8.4). The result of an abstract interpretation \nwas defined as a solution to forward (+) equations : the output contexts on exit arcs of node n are defined \nas a function of the input contexts on entry arcs of node n. One can as well consider a system of backward \n(+) equations : a context may be related to its succes sors. Both systems (~, -) may also be combined. \nFinally we usually consider a maximal (+) or mini\u00admal (+) solution to the system of equations, (by agreement, \nmaximal and minimal are related to the ordering s defined by (x s y) <=> (x u y = y) <=> (x o y = x)). \nHowever kno.n examples such as Manna and Shamir[751 show that the suitable solu\u00adtion may be somewhere \nbetween the extreme ones. These choices give rise to the following types of abstract interpretations \n: (n,+,+)(u,+,+) (n,+,+) (u,+,+) . (u,+,+) (n,+,+) (U,+,l) Examples : Kildall[73] uses (n,+,+ ) , Wegbreit[751 \nuses (u,+,+). Tenenbaum[74] uses both (u,+,+) and (n,+,+). 5.3 Exanp2es 5.3.1 static Semantics 0f,?%O$7FCZW \nThe static semanticsof programs we defined in sec\u00adtion 4 is an abstract interpretation : = <Contexts, \nu, ~, Env, 0, n context> lss where Contex~s, U, ~, Env, @, n-context, Context Vectors, ;, ~, F Cent \nrespe~vel~ c~rrespond to A-Cent, ., <, T, 1, ~, A-Cent, ., S, ~t. 5.3.2 Data F20w Analysis Data flow \nanalysis problems (see references in Ullman[75]) may be formalized as abstract inter pretations of programs. \nAvailable expressions give a classical example. An expression is available on arc r, if whenever control \nreaches r, the value of the expression has been previously computed, and since the last com putation \nof the expression, no argument of the ex\u00adpression has had its value changed. Let Exprp be the set of \nexpressionS Occuring in a program P. Abstract contexts will be sets of available expressions, represented \nby boolean vec tors : B vect : Exprp + {g, false} B vect is clearly a complete boolean lattice. The interpretation \nof basic nodes is defined by : avail(r, Bv) let n ~ origin(r) within - case n l.n Entr~s => Ae . false \nAssignments u Tests u Junctions :> he .~generated(n)(e) or(( @ Bv(p)(e)) p~a-pred(n) and transparent(n)(e))) \nesac (Nothing is available on entry arcs. An expression e is available on arc r (exit of node n) if \neither the expression e is generated by n or for all prede\u00ad cessors of n, e is available on p and n does \nnot modify arguments of e). The available expressions are determined by the ma ximal solution (for ordering \nAe , false ~Ae . true) of the system of equations : ~v = ~i~(Bv) . The determination of available expressions, \nback dominators, intervals, . . . requires a forward sys\u00adtem of equations. Some global flow problems, \nnota bly the live variables and very busy expressions require propagating information backward through \nthe program graph, they are examples of backward systems of equations. 5..3.3 Remaxks Our formal definition \nof abstract interpretations has the completeness property since the model en sures the existence of a \nparticular solution to the system of equations and therefore defines at least some global property of \nthe program. It must also have the consistency property, that is define only correct properties of programs. \nOne can distinguish between syntactic and semantic abstract interpretations of a program. Syntactic interpretations \nare proved to be correct by refe\u00adrence to the program syntax (e.g. the algorithm for finding available \nexpressions is justified by rea soning on paths of the program graph). By contrast semantic abstract \ninterpretations must be proved to be consistent with the formal semantics of the language (e.g. constant \npropagation). 6. Consistent Abstract Interpretations An abstract interpretation ~ = <A Cent, ~, ~, T \n, y, ~> of a program is consistent with a con\u00adcrete interpretation I = <C Cent, . , <, T, L, Int> if \nthe context vector ~ resulting from T is a cor rect approximation of fie context vector Cv resul ting \nfrom the more refined interpretationfi. This may be .rigo_rously defined by establishing a corres pondence \n( o! : abstraction) between concrete and ab stract context vectors, and inversely (~ : concreti zation), \nand requiring : 6.0 {Cv~ ~(~)} and {~(Cv) ~ Cv} . In words the abstract context vector must at least \ncontain the concrete one, (but not only the concrete one) . Iff: D + D we note ~ = Arcs + D and b =ArcsO+D \nand~:~+~ = id. (Ar, f(d(r)). We will suppose a and y to satisfy the following hypothesis :  6.1 a : \nC Cent J A Cent, y : A Cent + C Cent 6.2 a and Y are order-preserving 6.3 YZ6 ~, ; = a(Y(~)) 6.4 ~x c \nC Cent, x < y(a(x)) Intuitively, hypothesis 6.2 is necessary because context inclusion (that is property \ncomparison) must be preserved by the abstraction or concreti zation process. 6.3 requires that concretization \nintroduces no loss of information. It implies that a is subjective and y is injective. 6.4 introduces \nthe idea of approximation :the abstraction u,(C) of a concrete context C may introduce some loss of information \nso that when concretizing again y(ct(c)) we may get a larger context y(a(C)) > C. Note that it is easy \nto-prove properties corresponding to 6.1-6.4 for a and ~. Instead of the global hypothesis 6.0 we will \nuse the following local hypothesis on the concrete and abstract interpretations of primitive language \ncons\u00ad tructs : ~ 6.5 and { d(a, x) c Arcs x C~t, Int(a, a(x)) ~ a(~(a, x))} These two hypothesis are \nin fact equivalent (lemma L2 in aDDendix 12). The following schema illustra tes 6.5; i.e. the idea of \nabstract simulation of concrete computations : Suppose we want to compute the concrete output con text \nCO (associated with arc a) resulting from con crete Input contexts C :Co= Int(a, C1). We can I as well \napproximate this computa~i~n in the abstract universe, and get CL = Y(W(a, a(CI))). 6.5 requires C; to \ncontain at least CO, that is Co s CA. On the c~ntrary we do not require C~ to contain lt most Co, that \nis C~ < Co is not compulsory. We will say that I is a refinement of ~, or that ~ is an abstraction of \nI, denoted I g (a, Y)~, if and only if there exist a and y satisfying hypothe\u00adsis 6.1 to 6.5. Note that \nI < (a, y)~ imposes a local consistency of the interpretations I and ~, at the level of pri mitive language \nconstructs (6.5). Theorems T] and T2 of Appendix 12 then prove 6.0 which defines the global consistency \nof I and ~ at the program level. In particular if we take = <Contexts, u, ~, Env, @i, n-context> lss \nany abstract interpretation ~ of P, consistent with 1SS (1SS ~ (a, Y)~) is consistent with the seman \ntics of P, which implies : ~q e Arcs, let &#38; be the result of ~, {gn = O, ~is < I-states I <q,e>=n-staten(is)} \n=> {e E y(~(q))}  As previously noticed, the abstract interpretations will not in general be powerful \nenough to establish the reciprocal. Example : Deductive Sevzznties of Prog~ams Contexts will be predicates \nsuch as P(xl, ..., x ) = Pred over the program variables (xl, ..,x )cI~entn which are the free variables \nin the predic~te. The abstract interpretation is then : = <Pred, ~, =>, ~, false, n pred> lD S 242 where \nn-pred defines Floyd[67] s strongest post The relation = on abstract interpretations defined - condition \n: n-pred(r, Pv) = let(n be=rigin(r)), (p be a pred(origin(r)))within .-. case n In Entri~ =>(~xc Ident, \nx = 1 ) Values Junctions => or (pV(q)) qea~red(n) Tests =>ca~n {a-suc~t(n)} =>Pv(p) and test(n) {a-s.cc-f(n)} \n=>=(p) ~ not test(n) esac Assignments => let (P be Pv(p)), (x be id(n)), (e be expr(n)) within (3v eValue. \n\\ P[v/xl=n==e[vr esac The invariants of the program are defined by the least fixpoint of n~ed (least \nfor ordering? (~>), so that an invaria=lies any other correct as sertion) . The deductive semantics is \neasily validated by pro\u00adving that 1SS s (a, y)IDS, where :  0.: Contexts + Pred  AC.(or ( and (x = \ne(x))) e~C xc Ident Y: Pred + Contexts Ap.{el p[e(x)/x, x e Identl]  The main point is to justify Hoare[67] \ns proof rules by showing : ~ {Ya 6 Arcs, #Pv e Precl, a(n-con~xt(a, Y(Pv)))=> n-pred(a, Pv)} . See Hoare \nand Lauer[74], Ligler[75]. In particular Ligler[75] shows clearly that the proof can be done only when \nconsidering realizable Contexts and pro grams involving clean basic constructs (e.g. cons tructs excluding \nnon-termination, errors, side ef fects, sharing between identifiers, . ..). Once lss S (u, 6) IDS has \nbeen proved, we know that the deductive semantics gives a valid proof techni que, which will never permit \na false theorem to be deduced : ~q c Arcs, let Pv be the result of IDS, {~nz O, 3 is e I states I <q,e> \n= n state (is)} => {Pv(q) => u(e)}  7. The Lattice of Abst~act Interprwtutions The relation S comparing \nthe levels of abstraction of two interpretations is a quasi-ordering since it is : reflexive : (I s (1, \n1)1) where I = Ax .x is the identify function, transitive : (I< (~1, Y1)I )~ (I ~ (~2, Y2)II!) imply \nI < (al O ~2, Y2 o Y1)I . by : {I = I } <=> {(1< I ) and (I < I)} is an equivalence relation. We have \n: {I = (6)1 } <=> {(3 is an isomorphism between the algebras I and I } The proof gives some insight in \nthe abstraction process : 1 {1 = (6)1 } => {(I ~ (6, 6 1)1 ) and (I S7R-1, !3)1)} 2 reciprocally, If \nI< (~ , Y1)I , let ~ (al) be the equivalence relation ~efined on I (properly speaking, on the set of \nabstract contexts of 1) by : {x = (al)y} <=> {cl,(x) =a,(y)} VX e I , each equivalence class Cx, = {x \nG II al(x) = x } has a least upper bound which is Y,(x ). Hence the projection al I yl(I ) of al on yl(I \n) is a bijection from the set Y,(I ) of representers of the equivalence classes on I. Let us show now \nthat under the hypothesis I S (Ul, YI)I and 1 ~ (u2, Y2)I, U1 is bi\u00ad jective. al I yl(If) and a2 \\ y2(I) \nare bisections, hence #X e 1 , ~!x (unique) e YI(I ) such that x = (al IYI(I ))(x). Likewise, x c Y1(I \n) > X e I > ]!X c Y2(1) I X = (~ IY2(I))(X ). Therefore, dx E I , ~!x E Y2(I) 1 x = o (IX2\\y2(I))(X \n). Thus (~11 Y1(I )) . Y is bijyctiOn,~etween (ujl Yl(I )),0 (IX21 (I)) a ~i?;~;;~~e; i ;F~~?! l?~l~l;~o;Y;;l \nec\u00ad 0    (~1I Y1(I )) (~21Y2(I))0 (~21Y2(I))- = (cll]Y1(I )) is a bijection between I and 1 , hence \nal is a bijection between I and I which is trivially an algebraic morphism. (al is isotone, its in\u00adverse \nct~] =yl is isotone and al(~(a, X)) = Int (a, UI(X))) Q.E.D. Let I be the set of abstract interpretations \nof a program, if equivalent interpretations are iden\u00adtified, the quasi ordering ~ becomes a partial or\u00ad \ndering. ) In particular, we can restrict I to be set of in terpretations which abstract 1SS. 1 is then \na lat\u00adtice, (with orderings) which 1s isomorphic with a subset of the lattice of equivalence relations \non Contexts. Example : Let P be a program with a single integer variable, (the generalization is obvious). \nEnvironments will be integers (the value of the variable). Contexts are sets of integers (the set of \nvalues at some program point). A context S may be abstracted by a closed interval a(S) = [rein(S), max(S)]. \nWhen S is infinite the bounds will eventually be -=or += . y([a, b]) = {xl a S x S b}. The abstract contexts \nare then, (cousot[761) : ,/ ., /lCP 11 = /&#38;2,2] 1 A further ct([a, b]) elsif b < Y(+) = [0, The \nabstract abstraction may be : = if a -b then a elsif a 0 then else f fi. y(n) = +~], y(-) =[-myo], y(f) \ncontexts are then : > 0 then [n, n], = [-m, + +CO]. * /\\ This interpretation may be abstracted by two \nnon comparable abstractions : ICP is used b y Kildall[73] for constant propagation. IRS might be used \nto apply the rules of signs. Both interpretations may be abstracted by : T lR = 1 1 which may be used \nto check that any vertex in the program graph is reachable from the entry nodes . Finally, the most abstract \ninterpretation is the upper bound of 1 : = <{1}, A(x, y) . I, t, I, I, ~(a, C) . I> 1 where t is the \nrelation which is always true . We have exhibited a sublattice of I which is : /\\ ~ R \\T/ CS lI lSS \n % 8. Abstract Evacuation of Programs The system of equations : Cv : Rt (Cv) resulting from an interpretation \nI = <A-Cent, ., ~,T,l, Int> of a program P may be solved by .--m el iminatlon me thods, (e.g. Tarjan[75]) \n. Other\u00adwise, One can use an iterative algorithm which computes Kleene s sequence (L4 of Appendix 12) \n: Cv := (C :=:: until C = ~t(C) do C := IX(C) re~eat. C) _ -, 8.1 Correctness If Int is supposed to \nbe a complete morphism (i.e. infinitely distributive over .) then Cv is the least fixpoint of fit. (e.g. \nKildall[fi], since in a semi lattice of mite len,gth, any distributive function is a complete morphism). \nUnder the weaker assumption that Int is continuous, the limit CV of Kleene s sequence can also be shown \nto be the~east fixpoint of fit (e.g. Wegbreit[75], since in a well founded semi~ttice, any isotone function \nis con\u00adtinuous) . Finally, if Int is only supposed to be isotone, Cv is an approximation (2) of the least \nfixpoint ~.g. Kam and Ullman[75]).  8.2 Termination The abstract evaluation terminates iff Kleene s \nsequence is finite. This may be the case because A-Cent is finite (e.g. type checking in ALGOL 60, Naur[65]), \nor a finite subset only is to be consi dered for any particular program (e.g. type che eking in ALGOL \n68), or A Cent may be of finite length m (the length of any strictly increasing chain is bounded by m, \nKildall[73], Wegbreit[75]) or A Cent may satisfy the ascending chain condition (every strictly increasing \nchain is finite, although not bounded). A lattice may have infinite chains, although Int is chosen so \nthat Kleene s sequences are finite. Finally an infinite Kleene s sequence may k arbitrarily truncated \n(to get a lower bound of its limit), some induction principle (Sintzoff [75]) or heuristics (Katz and \nManna[761) may be used to pass to the limit, or approximate it, (Cousot[76]). 6.3 Efficiency In practice \nefficient versions of the Kleene s sequen ce are used. These consist in a symbolic execution of the program \nwhich propagates information along paths of the program until stabilization. A speci fication of order \nof information propagation may lead to optimal algorithms for specific applica tions (references in Tarjan[76]). \n. 8.4 Exumple : Performance Analysis of Programs 9. F-ixpoints Approximation Methods The performance \nof programs may be analyzed by de When the extreme fixpoints of the system of equa riving for each program \npoint the final value of tions established for an abstract interpretation an imaginary counter which \nis incremented each time I of a program P cannot be computed in finitely control goes through that point. \nmany steps, they can be approximated. A more abs\u00ad tract interpretation ~ (I s ~) may be used for Let \nA-Cent be the lattice lR+ of positive real num that purpose (e.g. Tenenbaum[74]). It is often bet\u00ad hers \naugmented by the upper bound m, with natural ter to make approximations in I, for example by ordering \nS. The abstract interpretation : accelerating the convergence of :Cleene s sequences. + 1P = <R , ~, \nS, O, CW, Kir> may be used to derive the mean values of the coun\u00ad 9.1 Finite Iterative and Increasi~~g \nApproximation ters using Kirchhoff s law of conservation of flow : of the Least FixPoint Starting from \na Lower Bound Kir(r, Cv) = let n~e ~rigin(r) within Let I = <A-Cent, ., <, L, T, In.t> be an int~re case \nn In tation of P. When the least f~oint ~ of m Entri&#38; => I {unique entry node} is unreachable, we \nlook for an upper ~und ~ of Junctions u Assignments => Z Cv(p) ~, since according to the correctness \n~e~u~ement pca-pred(n) ~0, Cv Z~(&#38;) and ~~~ implies Cv s y(~). Tests => case r in {a-suc=t(n)} => \nCv(a-pred(n))* 9.1.1 Increasing Approximation Sequence -(test(n) = true). {a-succ-f(n)} => Cv(a-pred(n))* \nLet A=t : A~nt + A~nt be such that : (1-Prob(test(n) =true)). . esac 9.1.1.1 {Vn > 0, C = A~(~) and not(~t(C) \nZ C)}. esac =>{C ; Rt(C~ci?ft~. v\u00ad 9.1.1.2 Every infinite sequence ~, A-lnt(l), . . . . The main difficulty \nis to obtain the probability A intn(~), . . . is not strictly increasing. Prob(test(n) = true) of taking \nthe true path at a =~n. Suppose the values of these probabili The approximation sequence So, . . . . \nSn , . . . is recur\u00ad ties can be determined (from hypothesis on the in\u00ad sively defined by : put data). \n~ For fixed probabilities, the function Klr is clear 9.1.1.3 so =1 ly continuous (although it is not \na co~ete mor phism) since ? S ) then n s = if nOt(Nt(Sn)n+l A~(Sn) else m cc then max( Z ~i(p))= z (f&#38;i(cVi)(p)) \n_ 1=0 pca pred(n) pea-pred(n) ~ Sn fi and max (ni * q) = (~ (ni)) * q. We now prove that 3m finite such \nthat : -- i<A leA O<sl <  <sm=sm+l = The least fixpoint of K~r is the limit of Kleene s Let m be the \nleast natural number (eventually in\u00ad sequence (the length ofihe sequence is in general finite) such that \nSm = S . ~k e [0, m[, we know infinite) : from 9.1.1.3 that not(fi~t~k) ? Sk). Whence by de finition \nof the or~i~?, Sk # Iti(Sk) x Sk\u00ad -Let P be the program begin L : KO to L end . SinCe Sk ?-~(sk) ~ Skis \nalways true~ we can state The number n of iterat-~in th~l~p i~i that Sk ~ ~t(sk) ~ Sk. Besides nGc(Int(Sk) \n~ Sk) ven by the minimal solution to the equation and 9.1.1. l~ply : n = n+ 1 which is co limit of O+ \n1 + I + 1 + . . . = A~i~t(Sk) ~ ~(sk) U Sk k+] -Let P be the program begin while T do I end . The number \nn of times =x=ionv is~s\u00ad and therefore we conclude Sk+ I YS k,~ke[l, m[. ted is given by the minimal \nsolution to the Moreover 9.1 .1 .2 implies that m is finite. Q.E.D. equation n = I + q * n where q is \nthe probabi lity of T to be ,true. n may be determined by Let ~ be the least fixpoint of ~, it is the \nthe limit of Kleene s sequence : grea~~t lower bound of the set of X e A~t such 0 + 1 + q +q* + . . . \n+ q~ + ..+ that Int(X) ~ X (Tarski[55]) hence : which is an infinite series. Its sum is I ~ dX , A=t, \n{tit(X) ~ X} => {=2 X} Since Sm = Sm+l we have ~t(Sm) ? SV and therefore This abstract interpretation \nleads to a system of G 7 Sm, Sm is a correct approximat~on of Z. linear equations. Kleene s sequence \ncorresponds to the Jacobi s iterative method (for numerical coefficients) . 9.1.2 Gevzera2ization of \n.Ueene s Ascending Sequence When A Cent satisfies the a~ending chain condition one can choose ADi~t to \nbe Int and therefore the approximation sequence gene~izes Kleene s sequerr ce and the related methods. \n 9.1.3 Widening in Increasing Approximation se\u00adqz4ances T~definition of the approximate interpretation \nA lnt in 9.1.1 is global. We now indicate a way to construct A-int by local modifications to Int. Let \n(q, r) c Arcsz, we say that the context asso ciated to q is dependent on the context associated to r, \nif andonly if : {]Cve Awnt,~Cc A-Contl Int(q,Cv)#Int(q,C~[C/r])} . (e.g. in a forward system of equations \nthe context associated to q may only depend on the contexts associated with the immediate predec~sor \narcs of q). In the system of equations Cv = Int(Cv) we de\u00ad fine a cycle to be a sequence -1, . . . . \nqn> of arcs, such that vi c [1, n[, Cv(qi.+l) depends on Cv(qi) and ~(ql) depends on ~(qn). (e.g. in \na ~rward interpretation a cycle corresponds to a loop in the program). In any infinite strictly increasing \nKleene s se quenceql, . . . . Cv , . . . since Arcs is finite there is some arc q for T w lch the sequence \nCvl(q), . . ., Q(q), . . . never stabilizes . Therefo~ q must be\u00adlong to a cycle or the contexts associated \nto q transitively depend on the contexts associated to some other arc r which itself belongs to a cycle. \nThe sequence of contexts associated to any arc of that cycle never stabilizes. In order to avoid this \nphenomenon, we introduce : The binary operation V called widening defined by : 9.1.3.1 v : A-Cent x \nA Cent =-A Cent 9.1.3.2 ~(C, C ) : A Cont2, C . C < CV C 9.1.3.3 Every infinite sequence SO, . . . . \nSri,... of the form s co  n= n-1 ,enY . . . (where CO: . . . . Cn, .,. are arbi\u00adtrary abstract contexts) \nis not strictly increasing. The set W arcs of widening arcs, which is one of the minimal sets of arcs \nsuch that any cycle <ql, .2., q_> of the system of equations C; = I%t(C;) contains at least a widening \narc : ~ c ~~1 qi e W-arcs. (e.g. in a forward interpretation on a reducible program graph, W arcs may \nbe chosen to be the set of exit arcs of the junction nodes which are interval headers. On irreducible \ngraphs an arbitrary choice has to be made so that any loop of the program goes through a widening arc). \n The approximate in~pretation A int : Arcs X A Cent + A Cent defined by :  9.1.3.4 A-int = ~(q, Cv) \n. if q e W-arcs then %(q) V Int(q, Cv) eGe Int(q, Cv) - fl As before, we define : 9.1.3.5 A~t = )iCv. \n(Aq, A-int(q, CV)) . Now we have to show that this definition of A~t satisfies the requirements 9.1.1 \n.2 and 9.1.1.1. Let us consider a sequence So = ;, . . . . Sn+l = A int(Sn), . . . We show that this \nsequence is increasing that is to say : 9.1.3.6 Sn~A%t(Sn), ~n~ O. Trivially for n=O, So = ;< A%t(So). \nFor the induction step, suppose the result to be true for n g m. Let us prove that : s m+l Z A=t(S ) \nm+ 1 <-> s m+,(q) ~ A-int(q, Sm+l),~q e Arcs. If q c W-arcs, then A int(q, Sm+l) = Sm+l(q) ~ w(q, Sm+l) \n~ Sm+j(q) o ~(q, Sm+l) >s m+](q) If q ~ W-arcs, then A-int(q, Sm+l) = Int(q, Sm+l) => Int(q, Sm) S A \nint(q, Sm+l) since s-and Int is order preserving. Moreover f~O~)~]~J-arc=nd 9.1.3 .4we get Int(q, S ) \n= A-int(q, Sm) and therefore Sm+l(q~A in~(q,Sm) ~ -(q, Sm+l). . Finally Sm+l ? ~-~t(Sm+l), Q.E.D. =1 \nO  ~ n cannot be strictly increasing since oth=e there would exist some widening arc q for which the \nse\u00adnever stabilize Fences? radlctlng  9.1.3.3. wOuld An infinite sequence S = A%tn(I), . . . thus con \nsn(q) We now prove 9.1 .1.1 that is to say that : Vn>(),S = A%tn(;) n implies Sn ;%(Sn) z A%t(Sn)  \n <=> (s ~%t(S ))(q)~ Act, ~q c Arcs n n => Sri(q) . -(q, Sn) ~ A-int(q, Sn) (see 9.1.3.5) If q c W-arcs, \nwe have A int(q, Sn) = Sri(q) V Int(q, Sn) 2 Sri(q) . Int(q, Sn) by 9.1.3.2. If now q # W-arcs we must \nshow : Sri(q) . Int(q, Sn) ~ Int(q, Sn) <=> Sri(q) . Int(q, Sn) = Int(q, Sn) = Sri(q) ~ ~(q, Sn) <=> \nSri(q) s A-int(q, Sn) by 9.1.3.4 which is true, from 9.1.3.6, Q.E.D. 9.2 Example : Bounds of Integer \nVariables In a PASCAL program operating on arrays, the compi ler should ensure that arrays are subscripted \nonly by indices within bounds. For that purpose one can use the lattice I I of section 7. Let us take \nan obvious example : Q* C3 = [1, 100]co C4=C3+ [I, 1] cl + I c?.  c Gb-&#38;-+D Let us note [a, b] \nwhere a s b the predicate asxsb. The system of equations corresponding to the example is : (o) co=[ ,1 \n (1) cl =[1, II (2) C2=CIUC4 (3) C3=C2n [-m, 1001 (4) C4=C3+ [I, 1] (5) C5 = C2 n [101, +m]  Assi~nmept \nstateme,)ts are treated using an inter val arithmetic (e.g. [i, j] + [k, 11 = [i+k, j+~] naturally extended \nto include the case of the emp\u00adty interval). Similarly tests are treated using an interval logic . Since \nthere exist infinite Kleene s sequences (e.g. [ , 1<[0, 01 < [0, 11 < ... < [O, +~] for the program x \n:= O ; while true do x := X+ 1), we must use an approximation sequence. Hence the results will be somewhat \ninac\u00adcurate but runtime subscript tests may be inserted in the absence of certainty. Let us define the \nwidening V of intervals by : -1, I is the null element of v -ri, j] V rk, 1] [ifk< i then-melse i fi, \n~ .t> j then +melse  j ~] v satisfies the requirements of 9.1.3 . According to 9.I.3.4 the system \nof equations is modified by : (2) C2=C2 v (cl uC4) The corresponding approximation sequence is : Ci=[, \n1for i e[O, 51 * cl =[1, 1] C2 =C2 v (cl uC4) =[ ,1v ([l, II U[ ,1) =[ 1v[1, II =[1: 11 C3 =C2 n [ ~, \n1001 =[1, II n [-~, 1001 =[1, 11 C4=C3+ [I, 11 =[1, 11+[1, II = [2, 23 C2 =C2 v (cl uC4) =[1, l]v([l, \nII U[2, 21) =[1, 11u[I,21 * C2=[1, +@] C3 =C2 n [ ~, 1001 =[1, +~]n[-~, 1001 =[1, 1001 +[1, 11 * C4 \n= [2, 101] Note : cl UC4=[1, loll sc2=[l, +~l stop on that path. C5=C2n [101, +COI =[1, +~ln [101, +ml \n * C5 = [101, + =] exit, stop. The final context on each arc is marked by a star *. Note that the results \nare approximate ones, (e.g. C5). In this example the widening is a very rough ope ration which introduces \na great loss of information. However it can be seen in the trace that tests behave like filters. Furthermore, \nfor PASCAL like languages, one can first use the bounds given in the declaration of x before widening \nto infinite limits. 9.3 Finite Iterative and Dee~easing Approximation of the Least F;xpoint Starting \nfrom an Upper Bound The ascending approximation sequence leads to an  ~per bound Sm = A intm(~) of \nthe least fixpoint cvoffit:mzsm. Moreover %t(Sm) ~ Sm. Since  fit is order preserving, this implies \nthat : s : Mt( s); .... %tn(sm) . .. ..x. m --m - If s is not a fixpoint of Int and the above de seen \n2 lng sequence is finite (e.g. the lattice A-Cent satisfies the descending chain condition) its limit \nis a better approximation of ~ than Sm. When the sequence is infinite or slowly~onvergmg, one can among \nother solutions approximate its li init. 9.3.1 Decreasing Approximation Sequence At step n in the descending \nsequence, we have : xtn 1 (Sm) Y%tn(sm) YG In order to accelerate the convergence, we should ~n~~e next \nst~p find an approximation D such that . Int (Sm) > D ~ Cv. But not knowing Cv, this cha\u00adracterization \nis ~ry weak since D co~d be chosen incorrectly that is to say less than ~ or non com\u00adparable with ~. \nThe fact that ~ is ~e greatest lower bound o~the set of X E A~ont such that =t(X) ~ X gives a correctness \ncriterion for the . choice of D when ~ is unknown, we must have : ~tn+ (sm) ~~~~t(D) On the contrary \nto 9.1.1, this characterization does not provide an efficient construction of D. 9.3.2 Truncated Decreasing \nSequence In front of these difficulties we will enforce con\u00advergence by choosing D such that : 3n 2 \n01 ~t(Sm) ~ D ~~tn+](Sm) ... .. ... (However, we WI1l not artlflclally truncate the The limit of the \ndescending sequence S~ = ~, . . . . decreasing sequence by imposing an arbitrary upper s = Dei%tp(~), \n. . . is an upper bound ~f the grea\u00adbound on n ), t~st fixpoint of fit. v~ Let D lnt : A Cent + A%&#38;t \nbe such that :  9.3.4 Narrotii~ in Tz+uneated Decreasi~ Sequeru?es 9.3.2.1 {~C e ~~} {C> Int(C)} => \n{C ~~t(C) ~~t(C)} By analogy with 9.1 .3 we define now the narrowing 9.3.2.2 V= A~nt, every infinite \nsequence C, operation in order to built a possible construction D lnt(C), . . . . =ntn(C), . . . is not \nstrict of DDi~t by local modifications to Int : ly decreasing. 9.3 .4.1 A : A-Cent x A Cent + A-Cent \nThe truncated decreasing sequence S;, . . ..S~. . . . 9.3 .4.2 Y(C, C ) e A Cont2, is recursively defined \nby : {C 2C ]=>{C?CAC 2C ] 9.3.2.3 S: = S_ 9.3.4.3 Every infinite sequence =O; . . . . . s, s ... s: \n= if (S # fit(S )) @ (S~#D~t(S~)) of the form s A Cl,n. ... n+} ,n n =co 1 s AC:, . . . for arb~trary \nabstract then ~nt(S ) n c~n;e;P;lC el se o CI .  cn  snot strictly decreasing. s fi n  The approximated~terpretation \nD int : Arcs x A Cent + A Cent is defined by : Let us now prove that the truncated decreasing se quence \nis a finite strictly decreasing chain which  9.3.4.4 D-int = k(q, Cv) . if q c N-arcs then Cv(q) A -(q, \n~) terms are greater than ~ the least fixpoint of *t. els= Int(q, Cv) Let p be the least natural number \n(eventually r, LL P infinite) such that S = S Trivially from p+] and 9.1.1 :  D~ixt = ~Cv. (Aq. D-int(q, \nCv))  This definition of Dci~t trivially satisfies the If P > 0 then S; #~(S~), therefore S~~fit(S~. \nrequirement 9.3.2.1 since ~Cv ~ A Cent with pro Then applying 9.3.2.1 we have : perty Cv ~~t(Cv) implies \n=(q) > Int(q, Cv), Vq e A~s. If q= W-arcs th~ 9.3.4.2 impl~s that Cv(q) z Cv(q) A Int(q, Cv) = D int(q, \nCv) z fit(q, CT. Otherwise, ~ q ~ W-arcs Cv(q) ~ But 9.3.2.3 implies S~ # D=t(S~), hence : Int(q, Cv) \n= D int(q, Cv). Hence Cv ~Cili t(Cv) ~ . s; ~ s; :-~(s~) SG Rt(cv) . For the induction step, let us \nsuppose that for The proof of termination (requirement 9.3.2.2) is k< p, wehave : -. very similar to \nthe one outlined for A ltit in sec tion 9.1.3. Since fit is order preserving we have :  9.4 Examp2e \n: Bounds of Integer Variables ~(s;_l ) ;IYJ(sp 2%t (s;_l) s%t(cv) Let us come back to example 9.2. The \nsystem of equations was : == (1) CI =rl, 13 (2) C2 =c1 uC4 (3) C3 = C2 n [-~, 1007  (4) C4=C3+EI, \n1] Since 9.3.2.3 implies S; # Dwt(S~) we have : (5) C5=C2n [101, +~] : -~(s~) : G Si Si+l The ascending \napproximation sequence led to the approximate SOlutiOtl : By recurrence on k the result is true for k< \np. Moreover 9.3.2.2 implies that p is finite. Q.F..D. * c1 =[1, 1] C2= [1,*] C3 =[1, 100] 9.3.3 Generalizatwn \nof Kleene s Descending Se-* C4 = [2, 101] quence C5 = [101, +~] Let us define the narrowing A of intervals \nby : When A Cent satisfies the descend~g chain condi tion, one can choose D int to be ~, in which case \n-[ , I is the null element of A. the final result S = fitp(Sm) is a fixpoint grea\u00ad -[i, j] A [k, !?,1 \n= ter or equal to th~ least fixpoint ~ of &#38;t. [~ i = -@then k else ~-(i, k) fi, _ Lf j = +m then \nL else max(j, k) ~]  Thus narrowing just makes no improvement the requirements of system of equations \ndiscards infinite on finite bounds, 9.3.4. According is modified by : bounds and it satisfies to 9.3.4.4 \nthe (2) C2 =C2 A (Cl U C4) The descending approximation sequence is : C2 =C2 A (Cl U C4) * * * =[1, =[1, \nC2=[1, C3 =C2 C3=[1, stop C5=C2n c5=EI, exit. +COIL + =] 10I] n [-~, 1o11 on that [1OI, 1o11 ([1, A[l, \n1001 n [-~, path. +~] n [1OI, 11 u[2, 1o11 100] +~1 = = 1011) [1, 100] [Iol, 1o11 On that example the \napproximate solution improved so that the least fixpoint is this is not the case in general. 9.5 Dual. \nApproximation Methods ~ The lattice A Cent may be partitionned has been reached but as follows : When \nX ~ Y we have noted The truncated descending tally different from AAS, successive approximatio~s~tarting \nin the partition {Xl X 2 limit S is greater than P X g...__~e sequence since it Int(X)}, !Lfp : y. TDS \nis fundamen\u00adensures that from S remain so thatmtheir the 1T It is clear that the ascending-approximation \nse\u00adquence AAS when starting from I leads to an upper bound of the least fixpoint kfu of fit. and the \ntrunc~ted descending sequence TDS w~ startingLfp and gfp are the least and greatest fixpoints of from \nT leads to an upper bound of the greatest fix\u00adfit. The ascending (AKS) and descending (DKS) point gfp.Hence \nthe AAS and TDS methods are notKleene s sequences converge toward Lfp and gfp dual , therefore when considering \ntheir duals DASrespectively. These limits are reached when Int and TAS we get a means to surround both \nextremeis continuous. !Jhen AKS is infinite we have pro\u00adfixpoints of fit :posed to use an ascending approximation \nsequence (AAS) to approximate !?,fp. Its limit may be some fixpoint fp, or some S such that S~ ~ fit(Sm) \nand m s J Lfp, m Any of the AAS, TDS, DAS, TAS methods may yields a fixpoint fp which is not the fixpoint \n!Lfp or gfp of interest. None of these methods can im prove fp to reach f,fp or gfp, therefore a fix\u00adpoint \nimprovement method is necessary. It is our feeling that such a method could be designed only when considering \nthat A-Cent possesses a richer structure (i.e. for particular applications). Furthermore, in the AAS, \nTDS, DAS, TAS sequences the term of rank n is computed only as a function of the term of rank n-1 , hence \nthese are separ\u00adate steps methods. One can as well imagine to use bound steps methods, where the term \nof rank n is computed as a function of the terms of rank n-1, n-2, . . . . n k. In this last case the \nKleene s sequences may be used to compute the first k terms. After k steps more inform,~.tions about \nthe program would be available to heuristicly accele rate the convergence so that the definition of A-int \nand D int could be more refined. Finally, going deeply into the comparism with nu\u00ad merical analysis methods, \nit is clear that some measure is necessary to control the accuracy of the result. Its definition would \ncertainly also neces\u00ad sitate some additional properties of the abstract contexts . 10. Conelus-ion It \nis our feeling that most program analysis tech niques may be understood as abstract interpreta tions \nof programs. Let us point out global data flow analysis in optimizing compilers (Kildall[731, Morel and \nRenvoise[76] , Schwartz[75], Ullman[75], Wegbreit[ 751 , . ..). type verification (Naur[65], . ..). type \ndiscovery (Cousot[76 ], Sintzoff[72], Tenenbaum[ 74] , . ..). program testing (Henderson [751, . ..) \nsymbolic evaluation of programs (Hewitt et al.[73], Karr[76], . ..). program performance analysis (Wegbreit[76], \n. ..). formalization of program semantics (Hoare and Lauer[74], Ligler[75], Manna and Shamir[75], . ..). \nverification of pro\u00adgram correctness (Floyd[671, Park[691, Sintzoff[75], . . . ), discovery of inductive \ninvariants (Katz and Manna[76], . . .), proofs of program termination (Sites[741, . ..). program transformation \n(Sintzoff [76], ...). ... There is a fundamental unity between all these ap\u00ad parently unrelated program \nanalysis techniques : a new interpretation is given to the program text which allows to built an often \nimplicit system of equations. The problem is either to verify that a solution provided by the user is \ncorrect, or to discover or approximate such a solution. The mathematical model we studied in this paper \nis certainly the weakest which is necessary to unify these techniques, and therefore should be of very \ngeneral scope. It can be considerably enriched for particular applications so that more powerful results \nmay be obtained. Aehowlcxigernents We wish to thank M. Sintzoff for stimulating dis\u00ad cussions. We were \nvery lucky to have F. Blanc do the typing for us. 11. Refereneea Birkhoff [6]. Lattice theory. Amer. \nMath. Sot. Col. Pub. , XXV, Rev. ed. Cousot[76]. Static determination of dynamic proper ties of programs. \nProgramming Symp. Paris. Springer Verlag Lecture Notes, in Comp. Sc. to appear (April). Cousot[76 ]. \nStatic determination of dynamic pro perties of generalized type unions. Submitted for publication. (Sept.) \nFloyd[67]. Assigning meanings to programs. Proc. Symp . in Appl. Math. Vol. 19. Mathematical Aspects \nOf COmputer Science, (J. Schwartz, cd.) AMS, Providence, R.I., 19-32. Henderson[75]. Finite state modelling \nin program development. Proc. Int. Conf. on Reliable soft., Los Angeles, 221-227. Hewitt et al.[73]. \nActor induction and meta evalu ation. Conf. Rec. of the First ACM Symp. on Principles of Programming \nLanguages, Boston, 153-168, (Oct.). Hoare[67]. An axiomatic basis for computer pro gramming. Comm. ACM \n12, 10 (Oct.), 576-580. Hoare and Lauer[74]. Consistent and Complementary formal theories of the semantics \nof program ming languages. Acts Inf. 3, 135 153. Kam and Ullman[75]. Monotone data flow analysis frameworks. \nTR.169, C.S. Lab., Princeton Univ. Karr[76]. Affine relationships among variables of a Program. Acts \nInf. 6, 133 151. Katz and Manna[76]. Logical analysis of programs. Comm. ACM 19, 4(April), 188-206. Kildall[73].A \nunified approach to global program optimization. Conf. Rec. of the First ACM Symp . on Principles of \nProgramming Languages, Boston, 194-206, (Oct.). Kleene[52]. Introduction to metamathematics. Van Nostrand, \nNew York. Ligler[75]. Surface properties of programming lan guage constructs. Int. Symp. on Proving and \nImproving Programs, (G. Huet and G. Kahn, eds.), IRIA, France. Mac Neille[37]. Partially ordered sets. \nTrans. Amer. Math. Sot., 42, 416-460. Manna and Shamir[75]. A new approach to recursive programs. Tech. \nRep. CS 75 539, Comp. Sc. Dep., Stanford U. Morel and Renvoise[76]. Une m6thode globale d &#38;li mination \ndes redondances partielles. Program ming Symp. Paris. Springer Verlag Lecture Notes in Comp. Sc. to appear.(April). \nNaur[651. Checking of operand types in ALGOL com pilers, BIT 5, 151 163. Park[69]. Fixpoint induction \nand proofs of program {Y(x, y),L2, {x s y} -{ f(x) sf(y)}} properties. Machine and D. Mlchle, eds.), \n. . Intelligence Edinburgh 5, (B. U. press, Meltzer 59\u00ad <=> { #(x, y)EL2, {f(xuy) }> f(x) uf(y)}} 78. \n(Hi) : Let F be an order preserving function from Schwartz[75]. Automatic data structure choice in a \nthe complete semi-lattice <L, u, <, T, 1> language of very high level. Comm. ACM ]8, 12 in itself. (Dec.), \n722-728. scott[ 71]. The lattice of flow diagrams. Semantics of Programming Languages. Verlag Lecture \nNotes in Math. (E. Symp. on Springer-Engeler, (m) : Let the in ~ be an complete itself. order-preserving \nsemi-lattice <~, function ~, ~, ~, from ~> cd.), Vol. 188. (Ll) : The fixpoints of F form a non empty \ncomplete Scott and Strachey[71]. Towards a mathematical se\u00ad lattice with supremum g, infimum L such that: \nmantics PRG 6, for Oxford computer languages. U. Comp. Lab. Tech. Mon. b g = u{xl (X e L) A (X S F(x))} \nSintzoff[72]. Calculating properties of programs L = n{xl (x c L) A (F(x) S x)} by valuations on specific \nmodels. Proc. ACM (This result is proved in Tarski[551, pp.286\u00ad conf. on Proving Assertions About Programs. \n287). Note that the fixpoints of F need not SIGPLAN Notices 7, 1, 203-207. form a sublattice of L, Sintzoff[75]. \nfonctions Verifications utilisables d assertions comme valeurs pour les affectant We note fixpoints ~ \nand of Y. ~ the greatest and least des ving variables ext6rieures. and Improving Programs, Int. (G. Symp. \nHuet on and Pro\u00ad (H2) : Let a and 6 be such that : G. Kahn, eds.). IRIA. France. (H2.1) ci Sintzoff[76]. \nEliminating track programs. Proc. on Automata, Languages burgh, (July). blind alleys from of the third \nInt. and Programming, back-Coil. Edin (H2.2) (H2.3) (H2.4) (H2.5) (H2.6) y u is y_is ~x c ~xf order \npreserving ~rd~r prese~ving L, x a(Y(x)) L, x<y(a(x)) Sites[74]. Proving that computer programs terminate \ncleanly, Ph.D. Th., Comp. Sc. Dep., Stanford (H3.1) : (Hi), (~), (H2) and {~x < L, u ., (May) . F(a(x)) \n> ct(F(x))} Tarjan[75]. graphs Solving . Tech. path Rep. problems CS-75-528, on directed Comp. Sc. Dep., \n(H3.2) : (Hi), (=), (H2) and {Es y(F(x)) ~, 2 F(y(=))} Stanford U. (L~) , {H3.1} <=> {H3.2} Tarjan[761. \nanalysis. Stanford Iterative Tech. U. algorithms for Rep. CS-76-547, global Comp. flow Sc. Dep., Proof \n: &#38; E c. ~(a~y(=))) ~ a(F(y(~))) by x = y(~) in H3.1 Tarski[55]. A lattice theoretical fixpoint theorem \n~(~) ~ ct(F(y(~))) from H2.5 and its applications. Pacific journal of Math. y(~(~)) > y(a(F(y(=)))) from \nH2.4 5, 285\u00ad 309. y(~(~)) ~ F(Y(~)) H2.6 and transitivi Tenenbaum[74] . Type determination for very high \nty . level Se., languages. New York U., NSO-3, (Oct.). Courant Inst. of Math. ~x<L Y(~(cL(x))) ~ F(Y(a(x))) \n1 = a(x) in H3.2 Ullman[75]. Data flow analysis. Tech. Rep. 179, y(cl(x)) 2 x H2.6 Dep. of Elec. Eng., \nComp. Sc. Lab., Princeton F(y(ct(x))) 2 F(x) F order preserving u ., (March). in (HI). Wegbreit[75]. \nproperty Vol . SE I, Property sets. No. extraction IEEE trans. 3, (Sept.) in well-founded on Soft. Eng., \nY(~(q(x))) u(y(F(ct(x))))= ~(ct(x)) > ~ F(x) Ci(F(x)) ci(F(x)) transitivity H2.3 H2.5 Wegbreit[76]. Verifying \nprogram performance, J.ACP!, Q.E.D. 23, 4, (Oct.), 691-699. Since H3.I and H3.2 are proved by L2 to be \nequivalent, we choose : 12. Appedix (H3) : (H3.1) or (H3.2) We note L, with mum L. <L, , S, T, L> partial \nordering These definitions a complete S, supremum are given u semilattice T and infi in Birkhoff[61]. \n(L3) : Let F : from the self, L greatest L + L be an order preserving fLInCtiOn semilattice <L, u, S, \n~, L>in it\u00adand g respectively the least and fixpoints of F, then : Note : L is a complete lattice. ~X \ne L, {g U F(x) > X} <=> {g Z X} (proof in Birkhoff [61], p. 49). (The dual of this result is nroved in \nPark We take f is isotone, f is order preserving [691. pp. 66). By duality : or f is monotone to be synonymous \nand mean : ~xc L, {L n F(x) < X} <=> {~ S X} (Tt):Hl, iYF, HZ, H3 imply that the greatest fix\u00ad points \ng and ~ of F and ~ are related by : {a(g) =~ and {g< y(~)} Proof : The existence of g and ~ is stated \nby (Ll). Eva(g) SLl(g) trivially ~i7~(F(g)) sa(g) since g = F(g) ~~F(u(g)) =a(g) H3.1, U isotone, > tran\u00ad \nsitive ~~a(g) L3 Y(g) ~ Y(a(g)) H2,4 Y(z) ~ g H2.6, z transitive. Q.E.D. Replacing <g, ~, ~, ~, >, F, \n~, a, Y, H3.~, H2.4, H2.6> respectively by <~, k, n, s, <, ~, F, y, a, H3.2, H2.3, H2.5> in the above \nproof, we get the dual theorem : (T2) :Hl, fi~ H2, H3 imply that the least fixpoints L and L of F and \n~ are related by : {y(l) 2 k} ~{zsa(~)} According to Scott[71]a subset X ~ L is cal led directed if every \nfinite subset of X has an upper bound (in the sense of S) belonging to X. (An obvious example of a directed \nsub\u00adset is a non empty ascending chain). A func tion f : D + D is called continuous if when\u00adever X c \nL is directed, then f(u{x\\ x E X}) = U{f(x) TX E x}. (H4) : Let F be a continuous function from the \ncom\u00adplete semi lattice <L, U, s, T, 1> in itself. (~) : Let ~ be a continuous function from the com\u00adplete \nsemi-lattice <1, U, Z, ~, 1> in itself. n+ 1 We note FO(x) = x and F (x) =F(Fn(x)).  (L4) : H4(~) implies \nthat F (~) has a least fix\u00ad+m . point it(~) which is the limit u F1(L) of i =() the Kleene s sequence \n1 ~ F(l) ~ . . . ~ Fn(~) <.,. (The proof is easy to adapt from Kleene[52] s proof of the first recursion \ntheorem pp. 348 349) .  \n\t\t\t", "proc_id": "512950", "abstract": "A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe {(+), (-), (&#177;)} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 &#8594; -(+) * (+) &#8594; (-) * (+) &#8594; (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 &#8594; -(+) + (+) &#8594; (-) + (+) &#8594; (&#177;)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, &#8230;).", "authors": [{"name": "Patrick Cousot", "author_profile_id": "81100592699", "affiliation": "Laboratoire d'Informatique, U.S.M.G., BP. 53, 38041 Grenoble cedex, France", "person_id": "PP39049972", "email_address": "", "orcid_id": ""}, {"name": "Radhia Cousot", "author_profile_id": "81100592574", "affiliation": "Laboratoire d'Informatique, U.S.M.G., BP. 53, 38041 Grenoble cedex, France", "person_id": "PP14204543", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512950.512973", "year": "1977", "article_id": "512973", "conference": "POPL", "title": "Abstract interpretation: a unified lattice model for static analysis of programs by construction or approximation of fixpoints", "url": "http://dl.acm.org/citation.cfm?id=512973"}