{"article_publication_date": "10-16-2006", "fulltext": "\n Eliminating Synchronization-Related Atomic Operations with Biased Locking and Bulk Rebiasing Kenneth \nRussell David Detlefs * Sun Microsystems, Inc. david.detlefs@alum.mit.edu kenneth.russell@sun.com Abstract \nThe JavaTMprogramming language contains built-in synchroniza\u00adtion primitives for use in constructing \nmultithreaded programs. Ef\u00ad.cient implementation of these synchronization primitives is nec\u00adessary in \norder to achieve high performance. Recent research [9, 12, 10, 3, 7] has focused on the run-time elimination \nof the atomic operations required to implement ob\u00adject monitor synchronization primitives. This paper \ndescribes a novel technique called store-free biased locking which eliminates all synchronization-related \natomic operations on uncontended ob\u00adject monitors. The technique supports the bulk transfer of object \nownership from one thread to another, and the selective disabling of the optimization where unpro.table, \nusing epoch-based bulk re\u00adbiasing and revocation. It has been implemented in the production version of \nthe Java HotSpotTMVM and has yielded signi.cant per\u00adformance improvements on a range of benchmarks and \napplica\u00adtions. The technique is applicable to any virtual machine-based pro\u00adgramming language implementation \nwith mostly block-structured locking primitives. Categories and Subject Descriptors D.3.4 [Programming \nLan\u00adguages]: Processors Optimization General Terms Algorithms, Languages, Performance Keywords Java, \nsynchronization, monitor, lock, atomic, opti\u00admization, bias, rebias, revoke, reservation 1. Background \nand Motivation The Java programming language contains built-in support for mon\u00aditors to facilitate the \nconstruction of multithreaded programs. Much research has been dedicated to decreasing the execution \ncost of the associated synchronization primitives. A class of optimizations which can be termed lightweight \nlock\u00ading [1, 2, 5] are focused on avoiding as much as possible the use of heavy-weight operating system \nmutexes and condition vari\u00adables to implement Java monitors. The assumption behind these techniques is \nthat most lock acquisitions in real programs are un\u00adcontended. Lightweight locking techniques use atomic \noperations * This work was done while this author was an employee of Sun Microsys\u00adtems, Inc. Copyright \nis held by Sun Microsystems, Inc. OOPSLA 06 October 22 26, 2006, Portland, Oregon, USA. ACM 1-59593-348-4/06/0010. \n upon monitor entry, and sometimes upon exit, to ensure correct syn\u00adchronization. These techniques fall \nback to using OS mutexes and condition variables when contention occurs. A related class of optimizations \nwhich can be termed biased locking [3, 7, 9] rely on the further property that not only are most monitors \nuncontended, they are only entered and exited by one thread during the lifetime of the monitor. Such \nmonitors may be pro.tably biased toward the owning thread, allowing that thread to enter and exit the \nmonitor without using atomic operations. If another thread attempts to enter a biased monitor, even if \nno contention occurs, a relatively expensive bias revocation operation must be performed. The pro.tability \nof such an optimization relies on the bene.t of the elimination of atomic operations being higher than \nthe penalty of revocation. Current re.nements of biased locking techniques [12, 10] de\u00adcrease or eliminate \nthe penalty of bias revocation, but do not opti\u00admize certain synchronization patterns which occur in \npractice, and also impact peak performance of the algorithm. Multiprocessor systems are increasingly \nprevalent; so much so that uniprocessors are now the exception rather than the norm. Atomic operations \nare signi.cantly more expensive on multi\u00adprocessors than uniprocessors, and their use may impact scalability \nand performance of real applications such as javac by 20% or more (Section 6). It is crucial at this \njuncture to enable biased locking optimizations for industrial applications, and to optimize as many \npatterns of synchronization in these applications as possible. 1.1 Contributions This paper presents \na novel technique for eliminating atomic oper\u00adations associated with the Java language s synchronization \nprimi\u00adtives called store-free biased locking (SFBL). It is similar to, and is inspired by, the lock reservation \ntechnique [9] and its re.nements [12, 10]. The speci.c contributions of our work are: We build upon \ninvariants preserved by the Java HotSpot VM to eliminate repeated stores to the object header. Store \nelimination makes it easier to transfer bias ownership between threads.  We introduce bulk rebiasing \nand revocation to amortize the cost of per-object bias revocation while retaining the bene.ts of the \noptimization.  An epoch-based mechanism which invalidates previously held biases facilitates the bulk \ntransfer of bias ownership from one thread to another.  Our technique is the .rst to support ef.cient \ntransfer of bias own\u00adership from one thread to another for sets of objects. Previous tech\u00adniques do not \noptimize the situation in which more than one thread locks a given object. The approaches above support \noptimization of more synchronization patterns in applications than previous tech\u00adFigure 1. Synchronization-related \nstates of an object s mark word. bit.elds tag bits state hash age 0 01 unlocked ptr to lock record 00 \nlightweight locked ptr to heavyweight monitor 10 in.ated 11 marked for GC thread ID epoch age 1 01 biasable \n niques, and allow biased locking to be enabled by default for all applications. 1.2 Organization of \nthis Paper The rest of this paper is organized as follows. Section 2 describes the lightweight locking \ntechnique in the Java HotSpot VM and its invariants. Section 3 describes the basic version of our biased \nlock\u00ading technique. Section 4 describes the bulk rebiasing and revoca\u00adtion techniques used to amortize \nthe cost of bias revocation. Sec\u00adtion 5 improves the scalability of bulk rebiasing and revocation us\u00ading \nepochs. Section 6 discusses results from various benchmarks. Section 7 provides detailed comparisons \nto earlier work. Section 8 describes how to obtain our implementation, and Section 9 con\u00adcludes.  2. \nOverview of Lightweight Locking in the Java HotSpot VM The lightweight locking technique used by the \nJava HotSpot VM[4] has not been described in the literature. Because knowledge of some of its aspects \nis required to understand store-free biased locking (SFBL), we present a brief overview here. The Java \nHotSpot VM uses a two-word object header. The .rst word is called the mark word and contains synchronization, \ngarbage collection and hash code information. The second word points to the class of the object. See \n.gure 1 for an overview of the layout and possible states of the mark word. Our biased locking technique \nrelies on three invariants. First, the locking primitives in the language must be mostly block-structured. \nSecond, optimized compiled code, if it is produced by the virtual machine, must only be generated for \nmethods with block-structured locking. Third, interpreted execution must detect unstructured lock\u00ading \nprecisely. We now show how these invariants are maintained in our VM. Whenever an object is lightweight \nlocked by a monitorenter bytecode, a lock record is either implicitly or explicitly allocated on the \nstack of the thread performing the lock acquisition operation. The lock record holds the original value \nof the object s mark word and also contains metadata necessary to identify which object is locked. During \nlock acquisition, the mark word is copied into the lock record (such a copy is called a displaced mark \nword), and an atomic compare-and-swap (CAS) operation is performed to attempt to make the object s mark \nword point to the lock record. If the CAS succeeds, the current thread owns the lock. If it fails, because \nsome other thread acquired the lock, a slow path is taken in which the lock is in.ated, during which \noperation an OS mutex and condition variable are associated with the object. During the in.ation process, \nthe object s mark word is updated with a CAS to point to a data structure containing pointers to the \nmutex and condition variable. During an unlock operation, an attempt is made to CAS the mark word, which \nshould still point to the lock record, with the displaced mark word stored in the lock record. If the \nCAS succeeds, there was no contention for the monitor and lightweight locking remains in effect. If it \nfails, the lock was contended while it was held and a slow path is taken to properly release the lock \nand notify other threads waiting to acquire the lock. Recursive locking is handled in a straightforward \nfashion. If during lightweight lock acquisition it is determined that the current thread already owns \nthe lock by virtue of the object s mark word pointing into its stack, a zero is stored into the on-stack \nlock record rather than the current value of the object s mark word. If zero is seen in a lock record \nduring an unlock operation, the object is known to be recursively locked by the current thread and no \nupdate of the object s mark word occurs. The number of such lock records implicitly records the monitor \nrecursion count. This is a signi.cant property to the best of our knowledge not attained by most other \nJVMs1. The Java HotSpot VM contains both a bytecode interpreter and an optimizing compiler. The interpreter \nand compiler-generated code create activation records called frames on a thread s native stack during \nactivation (i.e., execution) of Java methods. We des\u00adignate these frames as interpreted or compiled. \nInterpreted frames contain data from exactly one method, while due to inlining, com\u00adpiled frames may \ninclude data from more than one method. Interpreted frames contain a region which holds the lock records \nfor all monitors owned by the activation. During interpreted method execution this region grows or shrinks \ndepending upon the number of locks held. In compiled frames, there is no such region. Instead, lock records \nare allocated by the compiler in a fashion similar to register spill stack slots. During compilation, \nmetadata is generated which describes the set of locks held and the location of their lock records at \neach potential safepoint [15] in compiled code. The presence of lock records allows the runtime system \nto enumerate the locked objects and their displaced mark words within each frame. This information is \nused during various operations internal to the JVM, including bias revocation, which will be described \nlater. The Java Virtual Machine Speci.cation[11] requires that an IllegalMonitorStateException be thrown \nif a monitorexit bytecode is executed without having previously executed a match\u00ading monitorenter. The \ninterpreter detects this situation by checking that a lock record exists for an object being unlocked. \nIt is not spec\u00adi.ed what happens when a monitorenter bytecode is executed in a method followed by removal \nof the corresponding frame from the stack without executing a monitorexit bytecode. In this case a JVM \nmay legally either throw an exception or not. The Java Hotspot VM s interpreter eagerly detects this \nsituation by iterating through the lock records when removing an interpreted frame and forcibly unlocking \nthe corresponding objects. It then throws an exception if any locked objects were found. The Java HotSpot \nclient[8] and server[13] optimizing compil\u00aders will only compile and inline methods if data.ow analysis \nhas proven that all monitorenter and monitorexit operations are prop\u00aderly paired; in other words, every \nlock of a given object has a matching unlock on the same object. Attempts to leave an object locked after \nthe method returns, or to unlock an object not locked by that method, are detected by data.ow analysis. \nSuch methods, which almost never occur in practice, are never compiled or inlined but always interpreted. \nBecause interpreted execution precisely detects unstructured locking, and because compiled execution \nis proven through moni\u00adtor matching to perform correct block-structured locking, it is guar\u00adanteed that \nan object s locking state matches the program s ex\u00adecution at all times. It is never the case that an \nobject s locking state claims that it is owned by a particular thread when in fact the method which performed \nthe lightweight lock has already exited. A 1 An arbitrary Java virtual machine implementation is hereafter \nreferred to as a JVM. Figure 2. State transitions of an object s mark word under biased locking. method \nmay not unlock an object unless precisely that activation, and not one further up the stack, locked the \nobject. These are essen\u00adtial properties enabling both the elimination of the recursion count described \nabove as well as our biased locking technique in general. Complications arise in monitor-related optimizations \nsuch as lock coarsening in JVMs which do not maintain such invariants[16]. In summary, the following \ninvariants in a programming lan\u00adguage and virtual machine are essential prerequisites of our bi\u00adased \nlocking technique. First, the locking primitives in the language must be mostly block-structured. Second, \ncompiled code, if it ex\u00adists in the VM, must only be produced for methods with block\u00adstructured locking. \nThird, interpreted execution must detect illegal locking states eagerly. These three invariants imply \nthat an explicit recursion count for the lock is not necessary. Additionally, some mechanism must be \npresent to record a lock record for the object externally to the object. In the Java HotSpot VM a lock \nrecord is allocated on the stack, although it might be allocated elsewhere.  3. Store-Free Biased Locking \nAssuming the invariants in Section 2, the SFBL algorithm is simple to describe. When an object is allocated \nand biasing is enabled for its data type (discussed further in Section 4), a bias pattern is placed in \nthe mark word indicating that the object is biasable (.gure 1). The Java HotSpot VM uses the value 0x5 \nin the low three bits of the mark word as the bias pattern. The thread ID may be a direct pointer to \nthe JVM s internal representation of the current thread, suitably aligned so that the low bits are zero. \nAlternatively, a dense numbering scheme may be used to allow better packing of thread IDs and potentially \nmore .elds in the biasable object mark word. During lock acquisition of a biasable but unbiased object, \nan at\u00adtempt is made to CAS the current thread ID into the mark word s thread ID .eld. If this CAS succeeds, \nthe object is now biased to\u00adward the current thread, as in .gure 2. The current thread becomes the bias \nowner. The bias pattern remains in the mark word along\u00adside the thread ID. If the CAS fails, another \nthread is the bias owner, so that thread s bias must be revoked. The state of the object will be made \nto appear as if it had been locked by the bias owner using the JVM s under\u00adlying lightweight locking \nscheme. To do this, the thread attempting to bias the object toward itself must manipulate the stack \nof the bias owner. To enable this a global safepoint is reached, at which point no thread is executing \nbytecodes. The bias owner s stack is walked and the lock records associated with the object are .lled \nin with the values that would have been produced had lightweight locking been used to lock the object. \nNext, the object s mark word is updated to point to the oldest associated lock record on the stack. Finally, \nthe threads blocked on the safepoint are released. Note that if the lock were not actually held at the \npresent moment in time by the bias owner, it would be correct to revert the object back to the biasable \nbut unbiased state and re-attempt the CAS to acquire the bias. This possibility is discussed further \nin section 4. If the CAS succeeded, subsequent lock acquisitions examine the object s mark word. If the \nobject is biasable and the bias owner is the current thread, the lock is acquired with no further work \nand no updates to the object header; the displaced mark word in the lock record on the stack is left \nuninitialized, since it will never be examined while the object is biasable. If the object is not biasable, \nlightweight locking and its fallback paths are used to acquire the lock. If the object is biasable but \nbiased toward another thread, the CAS failure path described in the previous paragraph will be taken, \nincluding the associated bias revocation. When an object is unlocked, the state of its mark word is tested \nto see if the bias pattern is still present. If it is, the unlock oper\u00adation succeeds with no other tests. \nIt is not even necessary to test whether the thread ID is equal to the current thread s ID. If another \nthread had attempted to acquire the lock while the current thread was actually holding the lock and not \njust the bias, the bias revoca\u00adtion process would have ensured that the object s mark word was reverted \nto the unbiasable state. Since the SFBL unlock path does no error checking, the cor\u00adrectness of the unlock \npath hinges on the interpreter s detection of unstructured locking. The lock records in interpreter activations \nen\u00adsure that the body of the monitorexit operation will not be executed if the object was not locked \nin the current activation. The guarantee of matched monitors in compiled code implies that no error check\u00ading \nis required in the SFBL unlock path in compiled code. Figure 2 shows the state transitions of the mark \nword of an ob\u00adject under the biased locking algorithm. The bulk rebiasing edge, which is described further \nin sections 4 and 5, is only an effective, not an actual, transition and does not necessarily involve \nan update to the object s mark word. Recursive locking edges, which update the on-stack lock records \nbut not the mark word, and the heavy\u00adweight locking state, which involves contention with one or more \nother threads, are omitted for clarity.  4. Bulk Rebiasing and Revocation Analysis of execution logs \nof SFBL for the SPECjvm98, SPECjbb\u00ad2000, SPECjbb2005 and SciMark benchmark suites yields two insights. \nFirst, there are certain objects for which biased locking is obviously unpro.table, such as producer-consumer \nqueues where two or more threads are involved. Such objects necessarily have lock contention, and many \nsuch objects may be allocated during a program s execution. It would be ideal to be able to identify \nsuch objects and disable biased locking only for them. Second, there are situations in which the ability \nto rebias a set of objects to another Figure 3. Percentage speedups yielded by basic SFBL algorithm and \nadditions of .rst bulk revocation and then also bulk rebiasing.  thread is pro.table, in particular \nwhen one thread allocates many objects and performs an initial synchronization operation on each, but \nanother thread performs subsequent work on them. When attempting to selectively disable biased locking, \nwe must be able to identify objects for which it is unpro.table. If one were able to associate an object \nwith its allocation site, one might .nd patterns of shared objects; for example, all objects allo\u00adcated \nat a particular site might seem to be shared between multiple threads. Experiments indicate this correlation \nis present in many programs[6]. Being able to selectively disable the insertion of the biasable mark \nword at that site would be ideal. However, due to its overhead, allocation site tracking is to the best \nof our knowledge not currently exploited in production JVMs. We have found empirically that selectively \ndisabling SFBL for a particular data type is a reasonable way to avoid unpro.table sit\u00aduations. We therefore \namortize the cost of rebiasing and individual object bias revocation by performing such rebiasing and \nrevoking in bulk on a per-data-type basis. Heuristics are added to the basic SFBL algorithm to estimate \nthe cost of individual bias revocations on a per-data-type basis. When the cost exceeds a certain threshold, \na bulk rebias operation is attempted. All biasable instances of the data type have their bias owner reset, \nso that the next thread to lock the object will reacquire the bias. Any biasable instance currently locked \nby a thread may optionally have its bias revoked or left alone. If bias revocations for individual instances \nof a given data type persist after one or more bulk rebias operations, a bulk revocation is performed. \nThe mark words of all biasable instances of the data type are reset to the lightweight locking algorithm \ns initial value. For currently-locked and biasable instances, the appropriate lock records are written \nto the stack, and their mark words are adjusted to point to the oldest lock record. Further, SFBL is \ndisabled for any newly allocated instances of the data type. The most obvious way of .nding all instances \nof a certain data type is to walk through the object heap, which is how these tech\u00adniques were initially \nimplemented (Section 5 describes the current implementation). Despite the computational expense involved, \nbulk rebiasing and revocation are surprisingly effective. Figure 3 illustrates the bene.ts of the bulk \nrevocation and rebi\u00adasing heuristics compared to the basic biased locking algorithm2. The javac sub-benchmark \nfrom SPECjvm98 computes many iden\u00adtity hash codes, forcing bias revocation of the affected objects since \nthere are no bits available to store the hash code in the biasable state 2 Machine con.guration is 2xAMD \ndescribed in Section 6. (see .gure 1). Bulk revocation bene.ts this and similar situations, here in particular \nbecause our early implementations performed rel\u00adatively inef.cient bias revocation in this case. SPECjbb2000 \nand SPECjbb2005 transfer a certain number of objects between threads as each warehouse is added to the \nbenchmark, not enough to impact scores greatly but enough to trigger the bulk revocation heuristic. The \naddition of bulk rebiasing, which is then triggered at the time of addition of each warehouse, reclaims \nthe gains to be had. Note that the addition of both bulk revocation and rebiasing does not reduce the \npeak performance of biased locking compared to the basic algorithm without these operations. This is \ndiscussed further in Section 7.  5. Epoch-Based Bulk Rebiasing and Revocation Though walking the object \nheap to implement bulk rebias and revocation algorithms is workable for relatively small heaps, it does \nnot scale well as the heap grows. To address this problem, we introduce the concept of an epoch, a timestamp \nindicating the validity of the bias. As shown in .gure 1, the epoch is a bit.eld in the mark word of \nbiasable instances. Each data type has a corresponding epoch as long as the data type is biasable. An \nobject is now considered biased toward a thread T if both the bias owner in the mark word is T, and the \nepoch of the instance is equal to the epoch of the data type. With this scheme, bulk rebiasing of objects \nof class C be\u00adcomes much less costly. We still stop all mutator threads at a safe\u00adpoint; without stopping \nthe mutator threads we cannot reliably tell whether or not a biased object is currently locked. The thread \nper\u00adforming the rebiasing: 1. Increments the epoch number of class C. This is a .xed-width integer, with \nthe same bit-width in the class as in the object headers. Thus, the increment operation may cause wrapping, \nbut as we will argue below, this does not compromise correct\u00adness. 2. Scans all thread stacks to locate \nobjects of class C that are cur\u00adrently locked, updating their bias epochs to the new current bias epoch \nfor class C. Alternatively, based on heuristic considera\u00adtion, these objects biases could be revoked. \n No heap scan is necessary; objects whose epoch numbers were not changed will, for the most part, now \nhave a different epoch number than their class, and will be considered to be in the biasable but unbiased \nstate. The pseudocode for the lock-acquisition operation then looks much like: Listing 1. Biased locking \nacquisition supporting epoch-based bulk rebiasing. void lock(Object* obj, Thread* t) { int lw = obj->lock_word; \nif (lock_state(lw) == Biased &#38;&#38; bias_epoch(lw) == obj->class->bias_epoch) { if (lock_or_bias_owner(lw) \n== t->id) { // Current thread is the bias owner. return; } else { // Need to revoke the object s bias. \nrevoke_bias(obj, t); } } else { // normal locking/unlocking protocol, // possibly with bias acquisition. \n} } Above we made the quali.cation that incrementing a class s bias epoch will for the most part rebias \nall objects of the given class. This quali.cation is necessary because of the .nite width of the epoch \n.eld, which allows integer wrapping. If the epoch .eld is N bits wide, and X is an object of type T, \nthen if 2 N bulk rebiasing operations for class T occur without any lock operation updating the bias \nepoch of X to the current epoch, then it will appear that X is again biased in the current epoch, that \nis, that its bias is valid. Note that this is purely a performance concern it is perfectly permis\u00adsible, \nfrom a correctness viewpoint, to consider X biased. It may mean that if a thread other than the bias \nholder attempts to lock X, an individual bias revocation operation may be required. But a suf.ciently \nlarge value of N can decrease the frequency of this sit\u00aduation signi.cantly: objects that are actually \nlocked between one epoch and the next have their epoch updated to the current epoch, so this situation \nonly occurs with infrequently-locked objects. Fur\u00adther, we could arrange for operations that naturally \nvisit all live ob\u00adjects, namely garbage collection, to normalize lock states, convert\u00ading biased objects \nwith invalid epochs into biasable-but-unbiased objects. (If done in a stop-world collection this can \nbe done with non-atomic stores; in a concurrent marker, however, the lock word would have to be updated \nwith an atomic operation, since the mark\u00ading thread would potentially compete with mutator threads to \nmod\u00adify the lock word.) Therefore, wrapping issues could also be pre\u00advented by choosing N large enough \nto make it highly likely that a full-heap garbage-collection would occur before 2 N bulk rebias operations \nfor a given type can occur. In practice, wrapping of the epoch .eld can be ignored. Bench\u00admarking has \nnot uncovered any situations where individual bias re\u00advocations are provoked due to epoch over.ow. The \ncurrent imple\u00admentation of biased locking in the Java HotSpot VM normalizes object headers during GC, \nso the mark words of biasable objects with invalid epochs are reverted to the unbiased state. This is \ndone purely to reduce the number of mark words preserved during GC, not to counteract epoch over.ow. \nIt is a straightforward extension to support bulk revocation of biases of a given data type. Recall that \nin bulk revocation, unlike bulk rebiasing, it is desired to completely disable the biased locking optimization \nfor the data type, instead of allowing the object to be potentially rebiased to a new thread. Rather \nthan incrementing the epoch in the data type, the biasable property for that data type may be disabled, \nand a dynamic test of this property added to the lock sequence: Listing 2. Biased locking acquisition \nsupporting epoch-based bulk rebiasing and revocation. void lock(Object* obj, Thread* t) { int lw = obj->lock_word; \nif (lock_state(lw) == Biased &#38;&#38; biasable(lw) == obj->class->biasable &#38;&#38; bias_epoch(lw) \n== obj->class->bias_epoch) { This variant of the lock sequence is the one currently imple\u00admented in the \nJava HotSpot VM. Epoch-based rebiasing and revocation may also be extended to rebias objects at a granularity \nbetween the instance and class level. For example, we might distinguish between objects of a given class \nbased on their allocation site; JIT-generated allocation code could be modi.ed to insert an allocation \nsite identi.er in the object header. Each allocation site could have its own epoch, and the locking sequence \ncould check the appropriate epoch for the object: Listing 3. Code structure supporting allocation site-speci.c \nbulk rebiasing. void lock(Object* obj, Thread* t) { int lw = obj->lock_word; if (lock_state(lw) == Biased \n &#38;&#38; biasable(lw) == obj->class->biasable &#38;&#38; bias_epoch(lw) == obj->class-> bias_epoch[obj->alloc_site_id]) \n{ To simplify the allocation path for new instances as well as storage of the per-data-type epochs, a \nprototype mark word is kept in each data type. This is the value to which the mark word of new instances \nwill be set. The epoch is stored in the prototype mark word as long as the prototype is biasable. In \npractice, a single logical XOR operation in assembly code computes the bitwise difference between the \ninstance s mark word and the prototype mark word of the data type. A sequence of tests are performed \non the result of the XOR to determine whether the bias is held by the current thread and currently valid, \nwhether the epoch has expired, whether the data type is no longer biasable, or whether the bias is assumed \nnot held, and the system reacts appropriately. Listing 4 shows the complete SPARC assembly code for the \nlock acquisition path of SFBL with epochs.  6. Results Figure 4 shows the performance impact of our \nbiased locking and epoch-based bulk rebiasing and revocation technique on several industry-standard benchmarks \non a variety of processor architec\u00adtures and con.gurations3. (Figure 5 separates out the Monte Carlo \nbenchmark from the SciMark suite to avoid distorting the graph.) These graphs illustrate not only the \neffectiveness of the technique, but also the relative cost of atomic operations on various CPUs. Absolute \nperformance comparisons with previous work [12, 10] are not possible, because as of this writing a JVM \nimplementing the lock reservation technique has not been publicly released4,5 . Even if such a JVM were \navailable, isolating the effects of the lock reservation or biased locking techniques would be non-trivial. \nDif\u00adferences in the optimizations performed by different dynamic com\u00adpilers can cause even the relative \nspeedup due to this optimization to differ; for example, if the overall generated code quality is low, \nthe relative speedup due to biased locking might be less than if the overall code quality were high. \nWe nonetheless observe that the magnitude of the improvements shown in .gures 4 and 5 is compa\u00adrable \nto previous work [12, 10]. Some benchmarks clearly improve dramatically, while others show little or \nonly modest improvement. In the SPECjvm98 bench\u00admark suite, the db, jack, javac, and jess benchmarks \nshow the most 3 2xP4: 2-CPU 3.06 GHz Hyperthreaded Pentium IV, 4 GB RAM, Solaris 9 2xAMD: 2-CPU 1.8 GHz \nAMD Opteron, 2 GB RAM, Suse Linux 8 SP3 4xAMD: 4-CPU 2.2 GHz Dual-core AMD Opteron, 16 GB RAM, Solaris \n10 2xUS-III: 2-CPU 750 MHz UltraSPARC III, 2 GB RAM, Solaris 8 1xUS-T1: 1-CPU 1.2 GHz 8-core (32-thread) \nUltraSPARC T1, 32 GB RAM, Solaris 10 32-bit JVMs used on all con.gurations. 4 In the week before .nal \nsubmission of this paper, IBM released SPECjbb2005 scores with a JVM, due to ship in September 2006, \nsupport\u00ading an -XlockReservation command line option for the .rst time. 5 Since the .rst availability \nof biased locking in the Sun JVM, BEA has introduced an -Xlazyunlocking JVM command-line option, the \nimple\u00admentation of which is undocumented. Listing 4. SPARC assembly code for SFBL lock acquisition with \nepochs. // inputs: Robj = pointer to object, Rmark = object s mark word, Rtemp = temporary // globals: \nGthread = register containing current thread pointer // effects: sets condition codes before branching \nto DONE label. // EQUAL => fast lock succeeded // NOT EQUAL => fast lock failed, go to slow case in run-time \nsystem // Test whether the lock is currently biased toward our thread and whether the epoch is still \nvalid // Note that the runtime guarantees sufficient alignment of thread pointers to allow age to be \n// placed into low bits and3 Rmark, biased_lock_mask /* 0b111 */, Rtemp cmp Rtemp, bias_pattern /* 0b101 \n*/ br notEqual, false /* annul next instruction */, pn /* predict not taken */, CAS_LABEL ld_ptr [Robj \n+ class_offset], Rtemp ld_ptr [Rtemp + prototype_mark_offset], Rtemp or3 Gthread, Rtemp, Rtemp xor3 Rmark, \nRtemp, Rtemp andcc Rtemp, ~age_mask, Rtemp br equal, true, pt, DONE_LABEL nop // The mark has the bias \npattern and we are not the bias owner in the current epoch. // Figure out more details about the state \nof the mark in order to know what operations can be // legally performed on the object s mark. // If \nthe low three bits in the xor result aren t clear, that means the prototype mark is no longer // biased \nand we have to revoke the object s bias. btst biased_lock_mask, Rtemp br notZero, false, pn, TRY_REVOKE_BIAS \n // Biasing is still enabled for this data type. See whether the epoch of the current bias is still // \nvalid. If not, attempt to rebias the object toward the current thread. btst epoch_mask, Rtemp br notZero, \nfalse, pn, TRY_REBIAS // Epoch of the current bias is still valid but owner is unknown. Try to acquire \nbias using an // atomic operation. If this fails the object s bias will be revoked. Note that we first \nconstruct // the presumed unbiased mark so we don t accidentally destroy another thread s valid bias. \nand3 Rmark, biased_lock_mask | age_mask | epoch_mask, Rmark or3 Gthread, Rmark, Rtemp cas Robj, Rmark, \nRtemp // Test whether bias succeeded; if not, DONE path will revoke bias cmp Rmark, Rtemp br always, \nfalse, pt, DONE nop TRY_REBIAS: // Epoch has expired; attempt to acquire bias anew ld ptr [Robj + class_offset], \nRtemp ld ptr [Rtemp + prototype_mark_offset], Rtemp or3 Gthread, Rtemp, Rtemp cas Robj, Rmark, Rtemp \n // Test whether bias succeeded; if not, DONE path will revoke bias cmp Rmark, Rtemp br always, false, \npt, DONE nop TRY_REVOKE_BIAS: // Try to reset the mark of this object to the prototype value and fall \nthrough to the CAS-based // fast locking. Note that if CAS fails, it means that another thread raced \nto revoke the bias of // this particular object, so it s still okay to continue in the normal locking \ncode. ld_ptr [Robj + class_offset], Rtemp ld_ptr [Rtemp + prototype_mark_offset], Rtemp cas Robj, Rmark, \nRtemp // Fall through to the normal CAS-based lock CAS_LABEL: // Normal CAS-based locking code // ... \nDONE: // Test of condition codes and call to slow case in run-time system if necessary; // continuation \nof program Figure 4. Percentage speedup/slowdown of SPECjvm98, SciMark, SPECjbb, Volano, and SPLASH-2 \nbenchmarks due to biased locking. SciMark suite due to biased locking. improvement, while the others \nwere largely unaffected. The com\u00adposite score is improved by approximately 10-15%. In the SciMark suite, \nthe Monte Carlo benchmark is greatly improved because its inner loop is dominated by synchronization \noverhead. The other benchmarks in this suite are largely unaffected by biased locking and due to the \nbenchmark s scoring system only a roughly 5% overall speedup is attained. The SPECjbb2000 and SPECjbb2005 \nbenchmarks net a 5-10% gain on most systems. The SPLASH-2 [17] benchmarks Water and Barnes are multi\u00adthreaded \nscienti.c applications ported to Java and analyzed by Sal\u00adcianu and Rinard [14]. These two benchmarks \nhave also been run under the lock reservation technique and its re.nements [12, 10]. In our con.guration, \neach of these benchmarks is run with 128 paral\u00adlel compute threads over a duration of approximately 100 \niterations per thread. We note that while our technique yields no speedup for these benchmarks, it also \ndoes not suffer the performance penalty of stop-the-owner lock reservation. The results from these benchmarks \nindicate the relative cost of atomic operations on various CPUs. The Monte Carlo benchmark is effectively \na synchronization microbenchmark and indicates that CMPXCHG is very costly on multiprocessor Intel x86 \nsystems. The SPECjvm98 results support this conclusion, as the largest gains in this suite were also \nachieved on the multiprocessor Intel system. Multiprocessor UltraSPARC and AMD Opteron systems Figure \n6. Scalability of a single-JVM SPECjbb2005 run on Ultra-SPARC T1 before and after the introduction of \nepoch-based bulk rebiasing and revocation. have better CAS and CMPXCHG performance, a conclusion again \nlargely supported by the data. The db benchmark is an exception, where the largest gain was seen on an \nolder UltraSPARC III system; we believe this may be related to relatively poor associativity of the data \ncache on this chip. The UltraSPARC T1 processor has a very cheap CAS instruction, so the gains from biased \nlocking are relatively less on this architecture. The db benchmark from SPECjvm98 is again an outlier, \nwhich we believe again to be related to the data cache con.guration on this chip. The Volano benchmark \nis adversely affected by the SFBL algo\u00adrithm. We believe this is due to the relatively high cost of per-object \nrevocation in our system due to the need to reach a global safepoint. Volano in particular starts hundreds \nof threads to perform I/O, and the cost of a global safepoint increases as the number of concurrent threads \nincreases. This is discussed further in section 7. Figure 6 illustrates the scalability improvements \nof epoch-based bulk rebiasing and revocation. The graphs show the performance of a single-JVM run of \nthe SPECjbb2005 benchmark on an Ultra-SPARC T1 processor. The maximum heap size is set to 3500 MB. In \nthe left graph the bulk rebias and revocation operations are im\u00adplemented by iterating through the object \nheap. In the right graph the epoch-based bulk rebias and revocation technique is used. In Program name \n# lock operations % optimized locks % opt. locks excl. .rst bias % opt. locks fr. earlier work[9] 201 \ncompress 29712 80.308% 74.239% 31.547% 202 jess 25128265 99.946% 99.808% 99.289% 209 db 285377977 99.987% \n99.935% 99.963% 213 javac 77819074 99.918% 97.848% 99.402% 222 mpegaudio 32131 87.632% 83.785% 35.837% \n227 mtrt 6318146 99.571% 99.523% 99.035% 228 jack 77013610 99.993% 96.380% 91.947% SPECjbb2000 786521693 \n94.258% 89.476% 58.544% Volano Client 23449530 75.514% 75.481% 84.333% Volano Server 19292861 76.980% \n76.689% 79.755% Figure 7. Percentages of lock operations optimized by biased locking. this benchmark, \nbulk rebias operations tend to occur at the begin\u00adning of each measurement period, when another concurrent \nworker thread is added to the benchmark. (The cost of these operations is included in the throughput \ncomputation due to the nature of the benchmark.) The ragged throughput curve in the left graph indi\u00adcates \npoor scalability, or alternatively a high degree of variance in throughput, due to the high cost of the \nassociated heap iterations. Epoch-based bulk rebiasing and revocation clearly solve the scal\u00adability \nproblems associated with these operations as the heap size increases. Figure 7 provides as direct a comparison \nas possible of the effec\u00adtiveness of biased locking with that of lock reservation [9]. Column 2 shows \nthe number of lock operations executed in typical runs of several benchmarks6. The absolute number of \nlock operations exe\u00adcuted for any particular benchmark is not crucial; it more generally indicates whether \nthe benchmark is synchronization-intensive. The percentages in columns 3 and 4 indicate the fraction \nof these lock operations which were optimizable by our biased locking imple\u00admentation. Column 3 counts \nthe initial bias of the object toward this overall fraction, while column 4 counts only the number of \nsubse\u00adquent successful biased lock acquisitions. We report both numbers in the interest of full disclosure, \nthough the difference is most sig\u00adni.cant only for the SPECjbb2000 benchmark. The data in column 5 is \nthat presented in Table 5 in [9]; the benchmarks were chosen to match those presented in this earlier \nwork. These statistics indicate that the effectiveness of biased lock\u00ading compares favorably to that \nof lock reservation. The percent\u00adage of optimized lock operations in the synchronization-heavy SPECjvm98 \nbenchmarks is roughly equal in both algorithms. Bi\u00adased locking appears to be able to optimize a much \nlarger percent\u00adage of the lock operations in the SPECjbb2000 benchmark. We believe this is attributable \nto bulk rebiasing, which is heuristically triggered soon after the addition of each new warehouse in \na given run. It appears that this benchmark transfers signi.cant numbers of biased objects between threads. \nHowever, we did not .nd that the relative speedup on this benchmark due to biased locking was sig\u00adni.cantly \ngreater than that due to lock reservation. This indicates that multiple metrics must be used to evaluate \nsuch techniques, and also suggests that the additional optimized synchronized lock oper\u00adations are not \nin the benchmark s critical code path. On the Volano benchmark, biased locking does not optimize as many \nlock oper\u00adations as lock reservation. Note also that this is the benchmark on which biased locking yields \na performance degradation rather than a gain. Here there appears to be a correlation between the percent\u00adage \nof optimized locks and the benchmark s overall performance, 6 Machine con.guration is 2xAMD described \nearlier. though this percentage alone is again not suf.cient to completely evaluate the algorithm.  \n7. Comparison to Earlier Work SFBL is similar to, and is inspired by, lock reservation [9] and its re.nements \n[12, 10]. Lock reservation is directly comparable to our basic biased locking technique described in \nSection 3. Both tech\u00adniques eliminate all atomic operations for uncontended synchro\u00adnization and have \na severe penalty for bias revocation. Our tech\u00adnique avoids subtle race conditions because objects headers \nare not repeatedly updated with non-atomic stores. However, because an explicit recursion count is not \nmaintained, it is more dif.cult in our technique to determine at any given point in time whether a biased \nlock is actually held by a given thread. The global safepoint required for bias revocation in our tech\u00adnique \nis more expensive than the signal used in lock reservation. It can be a barrier to scalability in applications \nsuch as Volano with many threads, many contended lock operations, and ongoing dy\u00adnamic class loading. \nHowever, our experience has been that the combination of these characteristics in an application is rare. \nWe have prototyped a per-thread safepoint mechanism and are inves\u00adtigating its performance characteristics. \nWe also believe a less ex\u00adpensive per-object bias revocation technique is possible for uncon\u00adtended locks \nwhile maintaining the useful locking invariants in the Java HotSpot VM, and plan to investigate this \nin the future. Reservation-based spin locks [12, 10] are comparable to our addition of bulk rebiasing \nand revocation described in Section 4. Both techniques build on top of an underlying biased locking al\u00adgorithm \nto reduce the impact of bias revocation. An advantage of reservation-based spin locks is that they largely \neliminate, rather than reduce or amortize, the cost of bias revocation. However, reservation-based spin \nlocks do not support transfer of bias own\u00adership between threads. The .rst thread to lock a given object \nwill always be the bias owner, and other threads will still need to use atomic operations to enter and \nexit the lock, eliminating the bene.ts of the optimization for these other threads. In contrast, epoch-based \nbulk rebiasing allows direct transfer of biases in the aggregate from one thread to another, at the cost \nof a small number of per-object revocations. Our experience indicates this supports optimization of signi.cantly \nmore synchronization patterns in real programs. Neither reservation-based spin locks nor our algorithm \noptimize the case of a single object or small set of objects being locked and unlocked multiple times \nsequentially by two or more threads, but always in uncontended fashion. Our bulk rebiasing technique \noptimizes this case in the aggregate, when many such objects are locked in this pattern. Ef.cient optimization \nof this synchronization pattern is an important area for future research. Reservation-based spin locks \nappear to adversely impact the peak performance of the lock reservation optimization as can be seen in \nthe published results for db and jack [12, 10]. In contrast, epoch-based bulk rebiasing and revocation \nappear to reduce the ad\u00adverse impacts of the biased locking optimization without impact\u00ading peak performance, \nas shown in Sections 4 and 6. We believe the high cost of per-object bias revocation in our system is \nrespon\u00adsible for the negative impact on the Volano benchmark, and plan to reduce this cost in the future. \nNonetheless, feedback from cus\u00adtomers indicates that our current biased locking implementation yields \ngood results in the .eld with no pathological performance problems. Speculative locking [7], another \nbiased locking technique, elim\u00adinates all synchronization-related atomic operations, but requires a separate \n.eld in each object instance to hold the thread ID. This space increase makes the technique unsuitable \nfor most data types. Additionally, speculative locking does not support the transfer of bias ownership \nfrom one thread to another, nor selective disabling of the optimization where unpro.table. Previous lightweight \nlocking techniques[1, 2, 5] exhibit quite different performance characteristics for contended and uncon\u00adtended \nlocking and contain very different techniques for falling back to heavyweight operating system locks \nunder contention. Some of these techniques use only one atomic operation per pair of lock/unlock operations \nrather than two. Nonetheless, all of these techniques use at least one atomic operation per lock/unlock \nse\u00adquence so are not directly comparable to SFBL. Potentially, any of these techniques could be used \nas the underlying synchronization technique for SFBL or a similar biased locking technique. 8. Availability \nOur technique is implemented in the current development version of the Java HotSpot VM. Binaries for \nvarious architectures and source code can be downloaded from http://mustang.dev.java.net/. The current \nbuild contains the per-data-type epoch-based rebiasing and revocation presented here. The biased locking \noptimization is currently enabled by de\u00adfault and can be disabled for comparison purposes by specifying \n-XX:-UseBiasedLocking on the command line. 9. Conclusion Current trends toward multiprocessor systems \nin the computing in\u00addustry make synchronization-related atomic operations an increas\u00ading impediment to \nthe scalability of applications. Biased locking techniques are crucial to continued performance improvement \nof programming language implementations. We have presented a new biased locking technique which opti\u00admizes \nmore synchronization patterns than previous techniques: It eliminates repeated stores to the object \nheader. Store elimina\u00adtion makes it easier to transfer bias ownership between threads.  It introduces \nbulk rebiasing and revocation to amortize the cost of per-object bias revocation while retaining the \nbene.ts of biased locking.  Epoch-based bulk rebiasing and revocation yield ef.cient bulk transfer of \nbias ownership from one thread to another.  Our technique is applicable to any programming language \nand vir\u00adtual machine with mostly block-structured locking and a few invari\u00adants in the interpreter and \ndynamic compiler. It yields good perfor\u00admance increases on a range of benchmarks with few penalties, \nand customer feedback indicates that it performs well on Java programs in the .eld. We believe our technique \ncan be extended to optimize even more synchronization patterns.  Acknowledgments We thank David Cox, \nour manager, for supporting this work; Gilad Bracha, Dave Dice, Paul Hohensee, Vladimir Kozlov, and Tom \nRodriguez for reviewing early drafts of this paper; and Martin Rinard and Alex Salcianu for access to \ntheir Java ports of the Water and Barnes benchmarks. We also thank the anonymous reviewers for their \nhelpful comments and suggestions.  References [1] Agesen, O., Detlefs, D., Garthwaite, A., Knippel, \nR., Ramakrishna, Y. S., and White, D. An ef.cient meta-lock for ubiquitous synchroniza\u00adtion. In proceedings \nof OOPSLA 99, November 1999, pp. 207 222. [2] Bacon, D. F., Konuru, R., Murthy, C., and Serrano, M. Thin \nlocks: featherweight synchronization for Java. In proceedings of PLDI 98, June 1998, pp. 258 268. [3] \nBacon, D. F. and Fink, S. Method and apparatus to provide concurrency control over objects without atomic \noperations on non\u00adshared objects. U.S. Patent Number 6,772,153, issued August 3, 2004. Assignee: International \nBusiness Machines Corporation. [4] Bak, L. and Lindholm, T. G. Method and apparatus for concurrent thread \nsynchronization. U.S. Patent Number 6,167,424, issued December 26, 2000. Assignee: Sun Microsystems, \nInc. [5] Dice, D. Implementing fast Java monitors with relaxed locks. In proceedings of the Java Virtual \nMachine Research and Technology Symposium (JVM 01), April 2001, pp. 79 90. [6] Dice, D. Personal communication. \n[7] Gomes, B. A., Bak, L., and Stoutamire, D. P.. Method and apparatus for speculatively locking objects \nin an object-based system. U.S. Patent Number 6,487,652, issued November 26, 2002. Assignee: Sun Microsystems, \nInc. [8] Griesemer, R. and Mitrovic, S. A compiler for the Java HotSpotTMvirtual machine. The School \nof Niklaus Wirth, The Art of Simplicity , Jan\u00aduary 2000, p.133 152. [9] Kawachiya, K., Koseki, A., and \nOnodera, T. Lock reservation: Java locks can mostly do without atomic operations. In proceedings of OOPSLA \n02, November 2002, pp. 130 141. [10] Kawachiya, K. Ph.D thesis, Graduate School of Media and Gover\u00adnance \nat Keio University, 2005. [11] Lindholm, T. and Yellin, F. The JavaTMVirtual Machine Speci.cation, Second \nEdition. Addison-Wesley, 1999. [12] Onodera, T., Kawachiya, K., and Koseki, K. Lock reservation for Java \nreconsidered. In proceedings of ECOOP 04, June 2004, pp. 559-583. [13] Paleczny, M., Vick, C., and Click, \nC. The Java HotSpotTMserver compiler. In proceedings of the Java Virtual Machine Research and Technology \nSymposium (JVM 01), April 2001. [14] Salcianu, A., and Rinard, M. Pointer and escape analysis for multithreaded \nprograms. Proceedings of the Eighth ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, \nSnowbird, Utah, June 2001. [15] Schmidt, R. W. System and method for facilitating safepoint synchronization \nin a multithreaded computer system. U.S. Patent Number 6,523,059, issued February 18, 2003. Assignee: \nSun Microsystems, Inc. [16] Stoodley, M. Accelerating Java synchronization in Just-In-Time compiler-generated \ncode. 3rd Workshop on Compiler-Driven Perfor\u00admance, October 2004. http://www.cs.ualberta.ca/~amaral/cascon/CDP04/ \n[17] Woo, S.C., Ohara, M., Torrie, E., Singh, J.P., and Gupta, A. The SPLASH-2 programs: characterization \nand methodological considerations. In Proceedings of the 22nd International Symposium on Computer Architecture, \npages 24 36, Santa Margherita Ligure, Italy, June 1995.  \n\t\t\t", "proc_id": "1167473", "abstract": "The Java&#8482; programming language contains built-in synchronization primitives for use in constructing multithreaded programs. Efficient implementation of these synchronization primitives is necessary in order to achieve high performance.Recent research [9, 12, 10, 3, 7] has focused on the run-time elimination of the atomic operations required to implement object monitor synchronization primitives. This paper describes a novel technique called <i>store-free biased locking</i> which eliminates all synchronization-related atomic operations on uncontended object monitors. The technique supports the bulk transfer of object ownership from one thread to another, and the selective disabling of the optimization where unprofitable, using epoch-based bulk rebiasing and revocation. It has been implemented in the production version of the Java HotSpot&#8482;VM and has yielded significant performance improvements on a range of benchmarks and applications. The technique is applicable to any virtual machine-based programming language implementation with mostly block-structured locking primitives.", "authors": [{"name": "Kenneth Russell", "author_profile_id": "81100588553", "affiliation": "Sun Microsystems, Inc.", "person_id": "PP18009626", "email_address": "", "orcid_id": ""}, {"name": "David Detlefs", "author_profile_id": "81100499495", "affiliation": "MIT", "person_id": "P61233", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167496", "year": "2006", "article_id": "1167496", "conference": "OOPSLA", "title": "Eliminating synchronization-related atomic operations with biased locking and bulk rebiasing", "url": "http://dl.acm.org/citation.cfm?id=1167496"}