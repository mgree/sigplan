{"article_publication_date": "10-16-2006", "fulltext": "\n XSnippet: Mining For Sample Code Naiyana Sahavechaphan National Electronics and Computer Technology \nCenter, Thailand naiyana.sahavechaphan@nectec.or.th Abstract It is common practice for software developers \nto use examples to guide development efforts. This largely unwritten, yet standard, practice of develop \nby example is often supported by exam\u00adples bundled with library or framework packages, provided in text\u00adbooks, \nand made available for download on both of.cial and un\u00adof.cial web sites. However, the vast number of \nexamples that are embedded in the billions of lines of already developed library and framework code are \nlargely untapped. We have developed XSnip\u00adpet, a context-sensitive code assistant framework that allows \ndevel\u00adopers to query a sample repository for code snippets that are rele\u00advant to the programming task \nat hand. In particular, our work makes three primary contributions. First, a range of queries is provided \nto allow developers to switch between a context-independent retrieval of code snippets to various degrees \nof context-sensitive retrieval for object instantiation queries. Second, a novel graph-based code min\u00ading \nalgorithm is provided to support the range of queries and enable mining within and across method boundaries. \nThird, an innovative context-sensitive ranking heuristic is provided that has been experi\u00admentally proven \nto provide better ranking for best-.t code snippets than context-independent heuristics such as shortest \npath and fre\u00adquency. Our experimental evaluation has shown that XSnippet has signi.cant potential to \nassist developers, and provides better cover\u00adage of tasks and better rankings for best-.t snippets than \nother code assistant systems. Categories and Subject Descriptors D.2.3 [Software Engineer\u00ading]: Coding \nTools and Techniques program editors, object\u00adoriented programming General Terms Design, Experimentation \nKeywords Code Assistants, Code Mining, Ranking Code Sam\u00adples, Code Reuse 1. Introduction For sometime, \nreuse has been the cornerstone of modern software development. Today s programmer relies on frameworks \nand li\u00adbraries,such as C++ libraries, Java packages, Eclipse packages, and in-house libraries [4, 1, \n6, 10, 13, 8], that empower the pro\u00adgrammer to create high quality, full-featured applications on-time. \nBut this reliance comes at a price these libraries and frame- Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 06 October 22 26, 2006, Portland, Oregon, \nUSA Copyright c &#38;#169; 2006 ACM 1-59593-348-4/06/0010. . . $5.00 Kajal Claypool Oracle Corporation, \nNashua, NH, USA Kajal.Claypool@oracle.com works represent a steep learning curve due to the sheer number \nof methods, classes, and interfaces. For example, J2SE, the Java standard library, contains thousands \nof classes many of which have extremely complex APIs that prove to be a signi.cant impediment to re-usability. \nIt is common practice for software developers to use examples to guide development efforts. Examples \nare used to enable soft\u00adware tasks of various shapes and sizes, such as: How to implement an Eclipse \nplugin that extends the JDT user interface? How to cor\u00adrectly use java.io.PushBackInputStream? How to \ninstantiate an object of ISelectionService? The importance of examples is often directly proportional \nto the complexity of the library or framework being used and the developer s experience with it. This \nlargely unwritten, yet standard, practice of develop by example is often facilitated by examples bundled \nwith library or framework packages, provided in textbooks, and made available for download on both of.cial \nand unof.cial web sites. In fact, the availability of good, reputable examples can easily become the \nkey factor or the key impediment to the success of a library or a framework. However, the published examples \nare the proverbial tip of the iceberg, covering only a small segment of common development tasks. The \nbulk of the iceberg of examples exists embedded in the billions of lines of code that have already been \ndeveloped! Recognizing that .nding examples (as well as the importance of examples) is the challenge, \nmining techniques [8, 11, 7] have been proposed in the literature to provide code samples based on the \ncontext of code being developed by a programmer. Strathcona [8] uses different structural context descriptions \n(parents, invocations, and types) encapsulated in a class (code under development) to create a set of \nheuristics. Each heuristic is used to query the code repository, returning a set of methods and classes \nwhere the result context matches the query s context. The .nal result is a set of methods and classes \nthat occur most frequently when applying all proposed heuristics. Prospector [11], on the other hand, \nde.nes a query that describes the desired code in terms of input Tin and output type Tout. A query returns \ncode snippets that instantiate an object of Tout from a given input type Tin. Prospector mines signature \ngraphs generated from API speci.cations and jungloid graphs representing code and ranks the results by \nthe shortest path from Tin to Tout. While these techniques take steps in the right direction, each approach \nis limited in the quality of the code snippets retrieved, re\u00adsulting often in too many (often irrelevant) \ncode snippets or in some cases too few or no code snippets. Strathcona, for example, does not specialize \nthe heuristics it employs based on the developer s context and its results straddle the extremities \nin some cases pro\u00adviding too many irrelevant results while in others over-constraining the context to \nprovide too few or no results. Prospector, while per\u00adforming better than Strathcona in general, has its \nown limitations. First, its over-reliance on API information can result in too many ir\u00adrelevant results. \nFor example, two unrelated paths can be connected by generic classes such as Object and ArrayList discounting \nthe diversity in their semantics. Second, the context description is lim\u00adited to only visible input types \nof .elds declared in the boundary of method and class while context information such as the parent is \nignored thereby missing a set of potentially quali.ed hits. This paper presents XSnippet, a code assistant \nsystem that al\u00adlows developers to query a sample repository for code snippets relevant to the object \ninstantiation task at hand. Object instan\u00adtiation is a common problem faced by developers. In the sim\u00adplest \ncase an object instantiation can be handled by a construc\u00adtor invocation. Other more complicated ways \nof instantiating an object include (i) invocation of a static method, often represent\u00ading a singleton \nimplementation. For example, the static invoca\u00adtion JavaUI.getWorkingCopyManager() instantiates an object \nof type IWorkingCopyManager; and (ii) invocation of a sequence of methods that eventually returns the \ninstantiated object. For example, an ISelectionService object can be instantiated by the sequence getViewSite().getWorkbenchWindow().getSelection-Service() \nin the class that extends ViewPart. In particular, XSnip\u00adpet makes the following contributions: Range \nof Queries: XSnippet supports a range of object instan\u00adtiation queries from specialized to generalized. \nThis approach is informed by two hypothesis: 1) a specialized query provides better-.t code samples, \nthat is samples that have a high degree of pertinence to the developer s code context. The more context \nused, the more specialized the query and the better the code samples supplied; 2) a generalized query \nprovides better cover\u00adage in that the generalized query can .nd relevant code samples under a larger \nnumber of scenarios, often .nding code samples where a specialized query might not.  Ranking Heuristics: \nXSnippet supports a set of ranking heuris\u00adtics from context sensitive to context independent. This is \nin\u00adformed by two hypothesis: 1) when multiple samples are avail\u00adable for the same query (often the case), \nranking heuristics are critical to ensure that the best-.t code samples appear as the top snippets; 2) \ncontext-sensitive heuristics provide better rank\u00adings for the best-.t code snippets than the context-independent \nheuristics. However, context-independent heuristics can be used to better rank samples within a given \ngroup of samples.  Mining Algorithm: XSnippet provides an innovative code min\u00ading algorithm that accommodates \nthe range of queries by con\u00adstraining the mining process as needed. The algorithm, based on a graph representation \nof Java source code, is targeted for instantiation of types via: (i) simple constructor invocation; (ii) \nstatic method invocation; and (iii) complex sequence of meth\u00adods. The algorithm can mine code snippets \nthat exist either within the scope of an individual method or that are spread across the boundaries of \ntwo or more methods.  This paper reports on these contributions. We have developed XSnippet as an Eclipse \nplugin that can be invoked from within the Eclipse Java editor. XSnippet requires Eclipse 3.0 or greater, \nand comes with a complete set of instructions for installation. To val\u00adidate our hypothesis and to evaluate \nthe potential bene.ts of XS\u00adnippet a series of experiments have been conducted. In particular, tradeoffs \nhave been studied, examining coverage and ranking for different types of queries ranging from generalized \nto specialized queries, and the usability of the system via a user study. Head\u00adto-head comparisons have \nbeen made between XSnippet and the Prospector code assistant system [11]. Roadmap: The rest of the paper \nis organized as follows: Sec\u00adtion 2 describes the program context and de.nes object-instantiation speci.c \nqueries ranging from specialized to generalized. Section 3 provides the formal model for code snippet \nmining and Section 4 presents the code snippet mining for answering a user query Q. Section 5 de.nes \na set of ranking heuristics from context sensi\u00adtive to context independent. Experimental evaluation of \nXSnippet is given in Section 6. We present related work in Section 7 and conclude in Section 8.  2. \nProgram Context and Queries The context of a program is a rich source of semantic informa\u00adtion that can \nbe harnessed to provide better, more targeted code snippets 1 for solving a programming hurdle. Consider \nthe code snippets shown in Figure 1. Each of these code snippets instanti\u00adate an ICompilationUnit object, \nalbeit with some differences. For example, snippet A instantiates ICompilationUnit from an ISelection \nobject, while snippet E instantiates it from a Map ob\u00adject. The relevancy of the code snippet to a developer \nis depen\u00addent on the lexically visible types in the developer s code. For ex\u00adample, if the developer \ns code contains an IEditorPart object, then snippet C is possibly the most relevant snippet as it shows \nhow an ICompilationUnit object can be instantiated from an IEditorPart object. In this section, we de.ne \nand classify the context of a devel\u00adoper s code (or the code context), and then formally de.ne three \ndifferent types of object-instantiation speci.c queries based on the code context. We assume that all \nqueries are invoked within method scope. 2.1 Types of Programming Context AJava source class is de.ned \nby its: parents the superclass it (the source class) inherits from, as well as the interfaces it implements; \n.elds the named attributes de.ned within its scope; and methods the class behavior de.ned at the granularity \nof methods. We use this basic class structure information to now de.ne code context for a given method \nm contained in class C. Parent Context (CP (m)): The parent context of a method m,de\u00adnoted as CP (m), \nis a set containing the superclass extended by its containing source class C, as well as all interfaces \nimplemented by its containing source class C. Thus, CP (m) = {S, Ii, Ij, ..., Ik}, where m is a method \n(m . C and C is the source class), S the su\u00adperclass of C,and Ii, Ij ... Ik the interfaces implemented \nby C. The parent context CP is a global context in that it is shared by all methods mi . C. Type Context \n(CT (m)): The type context, denoted as CT (m), is the set of the types of all inherited and local .elds, \nas well as all lexically visible types in the scope of a method m. Thus, CT (m) = {{ts},{tf },{tl}},where \nm is a method m . C, {ts} is the set of types for inherited .elds, {tf } is the set of types for all \nlocal .elds, and {tl} is the set of all lexically visible types within the scope of the method. The sets \n{ts} and {tf } de.ne a global context that is shared by all methods mi . C, while {tl} de.nes a local \ncontext particular to the method m. Consider the method m = getCompilationUnit() in the Java-MetricsView \nsource class shown in Figure 2. Here, the parent context CP (m) = {ViewPart, ISelectionListener, IJava-MetricsListener}, \nand the type context CT (m) = {IStructuredSelection, IJavaElement, Text}. all inherited .elds in the \nViewPart.  2.2 Snippet Queries To support procurement of code snippets for the instantiation of a type \ntq from within a method m, we de.ne a set of queries that range from generalized queries resulting in \nall possible code snippets 1 We use the term snippets to imply a fragment of code taken from a larger \nsource code .le.  A. ISelection selection; IStructuredSelection ss = (IStructuredSelection) selection; \nObject obj = ss.getFirstElement(); IJavaElement je = (IJavaElement) obj; IJavaElement ije = je.getAncestor(IJavaElement.COMPILATION \nUNIT); ICompilationUnit cu = (ICompilationUnit) ije B. ISelection selection; IStructuredSelection ss \n= (IStructuredSelection) selection; Object obj = ss.getFirstElement(); IFile f = (IFile) obj; IJavaElement \nije = JavaCore.create(f); ICompilationUnit cu = (ICompilationUnit) ije; C. IEditorPart editor; IEditorInput \ninput = editor.getEditorInput(); IWorkingCopyManager manager = JavaUI.getWorkingCopyManager(); ICompilationUnit \ncu = manager.getWorkingCopy(input); D. JavaEditor editor; Object editorInput = SelectionConverter.getInput(editor); \nICompilationUnit unit = (ICompilationUnit) editorInput; E. Map fMap; IEditorInput input; Object obj = \nfMap.get(input); ICompilationUnit unit = (ICompilationUnit) obj; F. JavaPlugin jp = JavaPlugin.getDefault() \nIWorkingCopyManager manager = jp.getWorkingCopyManager(); CompilationUnitEditor editor; IEditorInput \niei = editor.getEditorInput; ICompilationUnit unit = manager.getWorkingCopy(iei); Figure 1. Code Snippets \nthat Show Six Different Ways of Instantiating an ICompilationUnit Object. public class JavaMetricsView \nextends ViewPart implements ISelectionListener, IJavaMetricsListener { Text message; private ICompilationUnit \ngetCompilationUnit (IStructuredSelection ss) { if (ss.getFirstElement() instanceof IJavaElement) { IJavaElement \nje = (IJavaElement) ss.getFirstElement(); ... a developer is currently at this position .. return (ICompilationUnit) \nje.getAncestor (IJavaElement.COMPILATION UNIT); }}} Figure 2. The JavaMetricsView Class showing the \nMethod get-CompilationUnit(). that instantiate tq to specialized context-based queries that result in \nmore speci.c code snippets for instantiating tq. Generalized Instantiation Query IQG A generalized instanti\u00adation \nquery IQG takes as input a type tq and returns the set of all snippets s, contained in the sample code \nrepository, that instantiate the type tq. The query IQG is given in Equation 1. IQG(tq)=.s .S :scontainstq \ninstantiation (1) A generalized instantiation query IQG is useful when (i) the type tq can be instantiated \nindependent of the code context, for instance via a static method invocation. For example, an IWorkingCopyManager \nobject is often instantiated by the invo\u00adcation of the static method getWorkingCopyManager() of type \nJavaUI irrespective of whether or not the class JavaUI exists in the context; and (ii) there are no code \nsnippets available that meet the requirements of the code context. In such cases, any code snip\u00adpet that \nshows the instantiation of the type tq is considered relevant. In general, IQG returns all code snippets \nthat instantiate tq. Con\u00adsider the query IQG (ICompilationUnit). This query returns all code snippets \nin the repository, a sampling of which is shown in Figure 1. A Type-Based Instantiation Query IQT A type-based \ninstan\u00adtiation query IQT takes as input a type tq and the type context CT (m), where m represents the \nmethod in which the query is invoked, and returns the set of all snippets s, contained in the sample \ncode repository, such that the type tq is instantiated from some type tc . CT (m). The query IQT can \nbe de.ned in terms of IQG as given in Equation 2. IQT (tq, CT (m))=.s .IQG(tq):T (s)nCT (m) (2) Here, \ns denotes a snippet, T (s) the lexically visible types in the code snippet s and CT (m) denotes the type \ncontext of the method m. A type-based instantiation query IQT is useful when the in\u00adstantiation of a \ntype tq is required from some visible type tb in the type context. Consider the code segment shown in \nFigure 3. To highlight any selected .java source in the Eclipse package explorer, the method selectionChanged() \nrequires the instantia\u00adtion of an ICompilationUnit object from an object of the type ISelection. Here, \nCT (selectionChanged()) = {ISelection, IWorkbenchPart, Text, JavaMetrics}. all inherited .elds from ViewPart. \nBased on the code snippets shown in Figure 1, the query IQT (ICompilationUnit, CT (selectionChanged())) \nwill return only code snippets A and B. Parent-Based Instantiation Query IQP A well-de.ned type in a \nlibrary typically has it own unique functionalities with some dependencies on its parents (direct and \nindirect superclasses as well as interfaces). It is our observance that a set of types with the public \nclass JavaMetricsView extends ViewPart implements ISelectionListener, IJavaMetricsListener { Text message; \nJavaMetrics jm; public void createPartControl(Composite parent) { parent.setLayout(new FillLayout()); \nmessage = new Text(parent, SWT.MULTI); message.setText(NO SELECTION MESSAGE); getViewSite().getWorkbenchWindow().getSelectionService(). \naddSelectionListener(this); jm = new JavaMetrics(); jm.addListener(this); } public void setFocus() { \n} public void selectionChanged (IWorkbenchPart part, ISelection selection) { ICompilationUnit cu; } \n} } Figure 3. Code Segment of JavaMetricsView Class showing the Object Instantiation of ICompilationUnit. \nsame or similar parents tend to have more relevant code snippets than types that do not share a parent. \nTo re.ect the relevance of the shared parents (superclass and/or interfaces), a parent-based instantiation \nquery IQP is de.ned as follows. A parent-based instantiation query IQP takes as input a type tq and the \nparent context CP (m), where m . C represents the method in which the query is invoked, and returns the \nset of all snippets s, contained in the sample code repository, such that the containing class of the \nsnippet Cs and the class C either inherit from the same class or implement the same interfaces. IQP (tq, \nCP(m)) = .s .IQG(tq): CP(s) nCP(m) (3) Here, s denotes a snippet, CP (s) the parent context of the snippet, \nCP (m) the parent context of the method m. Consider the code segment in Figure 4. Here, an ICompilation-Unit \nobject in the method run() must capture a .java source .le in the Java editor and add some actions to \nit. Here, IQP (ICompilationUnit, CT (run()) = {IAction}. inherited .elds from AddTraceStatementAction) \ndoes not provide any code snippets that instantiate ICompilationUnit from IAction and other types. However, \nICompilationUnit can be instantiated based on the parent interface IEditorActionDelegate. Thus, while \nthe type-based instantiation query does not provide any re\u00adsults, a parent-based instantiation query \nIQP (ICompilation-Unit, CP (run()) = {IEditorActionDelegate}) returns the codes snippets C and D shown \nin Figure 1.   3. The Source Code Model While text-based source code is the right medium for developers \nwriting code, the textual format itself has limited applicability for analysis, and for our purposes \nof mining code snippets. Consider the sequence of method invocations getViewPart().getWorkbench\u00adWindow().getSelectionService().addSelectionListener(this) \nin the method createPartControl() of the JavaMetricsView class shown in Figure 3. Here, an object of \nthe type ISelectionService is instantiated during the invocation of the method getSelection-Service(). \nHowever, the type ISelectionService is itself not explicitly denoted in this source code, thereby rendering \ntext-based public class AddTraceStatementsEditorAction extends AddTraceStatementsAction implements IEditorActionDelegate \n{ public void run (IAction action) { ICompilationUnit cu; } public void setActiveEditor (IAction action, \nIEditorPart targetEditor) {}} Figure 4. Code Segment of AddTraceStatements-EditorAction Class showing \nObject Instantiation of ICompilationUnit. mining insuf.cient for answering simple queries such as how \ncan we instantiate an object of type ISelectionService . In this section, we de.ne the source code model \n(CM)asa directed acyclic graph CM =(NCM , ECM). An instance of the source code model (or simply a CM \ninstance), cms, corresponds to a source class Cs de.ned in a .java or .class .le. The different types \nof nodes NCM and edges ECM de.ned in CM in concert capture the structure and behavior of a class, and \nprovide a formal model for the code snippet mining described in later sections. Java source code encapsulates \n(i) the class structure:repre\u00adsented by the class inheritance hierarchy, the implemented interface hierarchy, \nand the class s set of members (.elds and methods); and (ii) the class behavior: represented by the computations \nspeci.ed at the granularity of individual methods. The source code model cap\u00adtures all aspects of the \nclass structure. For class behavior, however, it captures the signature, .eld declarations, return types, \nmethod invocations, and assignment statements. All control statements are ignored. In this section, we \ndescribe the different types of nodes (NCM) and edges (ECM) that comprise the source code model CM,and \nshow by example the construction of a source code model instance (cms) of a Java source class. Full details \nof the transformation algorithm that translates a Cs to a corresponding instance cms can be found at \n[16]. 3.1 Nodes in Source Code Model A node in the source code model CM can be categorized as type, \nobject or method node. Figure 5 gives the graphic representation of these different node types. a type \nnode an object node a method node Figure 5. Graphic Representation of the Different Types of Nodes in \nthe Source Code Model CM. A type node can represent (i) a source class -the class Cs for the corresponding \nsource code model instance cms; (ii) a superclass -the direct superclass Csp of a speci.ed source class \nCs; (iii) an interface -the interface is .Is implemented by the speci.ed source class Cs;or (iv)a generic \nclass -a class Cg whose static .eld or method member (including constructor) is referred to or invoked \nwithin the speci.ed source class Cs.A type node is labeled with its domain type2 where the domain type \ncan be either a class or an interface. 2 We use the full path to represent the domain type. However, \nfor brevity we use only the class name in this paper. An object node can represent (i) a class .eld -a \n.eld fs .Fs declared within the scope of the source class Cs; or (ii) a method .eld -a.eld fm declared \nwithin the scope of a method ms where the method ms is contained in the source class Cs.An object node \nis labeled with its domain type a class, an interface or void,and its name a label unique within the \nscope of the method ms or the source class Cs. An exception to this is the name this used to denote a \nreference to the source class Cs. A method node encapsulates the signature as well as the behav\u00adior of \na method, and is labeled with the method s name and the method s modi.er (public, private or protected) \nusing UML nota\u00adtion. The signature of the method is de.ned by the method s re\u00adturn type and an ordered \nlist of the method s parameter types, both of which are represented by type and object nodes as previously \ndescribed. The method s behavior is speci.ed by a set of compu\u00adtations, for example variable declarations \nand method invocations, that are represented by a source code model sub-instance.  3.2 Edges in Source \nCode Model An edge in the source code model CMcan be categorized as in\u00adheritance, implement, composite, \nmethod, assignment or parame\u00adter edge. The inheritance, implement and composite edges together capture \nthe class structure, while the method, assignment and pa\u00adrameter edges represent the class behavior. \nAn inheritance edge represents the relationship between the source class Cs and its direct superclass \nCsp.An implement edge relates the source class Cs to its implemented interface is .Is.A composite edge \ndenotes the relationship between the source class Cs and its declared class .eld fs .Fs or method ms \n.Ms.Fig\u00adure 6(b) depicts the class structure for the source code model in\u00adstance cms that is representative \nof the JavaMetricsView source class (Figure 6(a)). A method edge represents the invocation of a method, \neither a static or a non-static method. The edge is outgoing from the type or object that represents \nthe type or object handle for the given method mi, and is incident on the object returned by the method \nmi.The method edge is labeled with the method name to specify the method mi that is invoked. A special \ncase of the method edge is the object instantiation via the new construct. The object instantiation in \nthis case is treated as a static method invocation and is represented by a method edge labeled new from \nthe input type to an output object. Figure 7(a)-(b) shows the transformation of method invocation and \nconstructor statements respectively to nodes and method edges in a cms.  Figure 7. The Transformation \nof Method Invocation Statements to Nodes and Method Edges. An assignment edge represents the assignment \nof a value (or address). An assignment statement can be (a) equivalent where the two variables have the \nsame domain type; (b) downcast where the domain type of the output variable vo is more speci.c than that \nof the input variable vi;and (c) upcast (opposite of a downcast) where the domain type of the output \nvariable vo is more general than that of input variable vi. Figure 8(a)-(c) show the mapping of the three \ndifferent assignments respectively. 1 (a) cuEditor = targetEditor; (b) (ICompilationUnit) obj; (c) \nobj = icu_1;   1  1  : an equivalent assignment edge : a downcast assignment edge : an upcast assignment \nedge Figure 8. The Mapping of Assignment Statements to Nodes and Assignment Edges in a cms. A parameter \nedge represents the participation of a node np as a parameter for a method mi invoked either in the scope \nof a method ms or in a source code model instance cms. This edge is unique in that the edge is incident \non a method edge that represents the invocation of the method mi that requires this parameter node np. \nFigure 9 shows the mapping of code jm.reset(cu) to nodes and method and parameter edges in a cms. 1 \n3 reset() jm.reset(cu) the parameter edges, the local order number is scoped within the method invocation \nto indicate the order of the parameter in the case of multiple parameters.  4. Snippet Mining The goal \nof the snippet mining is to mine from a given code sample repository all code snippets that satisfy a \ngiven user query Q.  (a) Java source class (b) class structure Figure 6. Mapping from Java Source File \nto Nodes and Structural Edges in cms. Figure 10 outlines the high level steps undertaken by the snippet \nmining process. Given the possibly huge number of code samples in the repository, the SelectionAgent \npre-selects a set of code model instances cmi from the code repository based on the user query Q. This \npre-selection is based in part on the type of the user query (IQG, IQP , IQT ), andinpartonaB+ tree index \nde.ned on all types declared or referred to in the code sample repository. For IQG and IQT queries all \ncode model instances cmi that have a reference to the query type tq are pre-selected using the B+ tree \nindex. For IQP queries, the pre-selected set of code model instances cmi is limited to those that refer \nthe query type tqand that match the parent context (implement the same interface(s) or extend the same \nsuperclass) of the query Q. cm Q instances potential cm instances  The pre-selected code instance set \nCM is passed to the MiningA\u00adgent that controls the overall mining process. The MiningAgent invokes the \nBFSMINE algorithm for every code model instance cmi . CM. The BFSMINE algorithm, a breadth-.rst mining \nal\u00adgorithm, is the crux of our approach. It (BFSMINE algorithm) traverses a code model instance cmi and \nproduces as output a set of paths P that represent the .nal code snippets returned to the user. On completion \nof the BFSMINE phase, the MiningAgent passes the collection of the sets of paths P generated by multiple \ninvocations of the BFSMINE algorithm, to the PruningAgent. The PruningAgent removes (i) all duplicate \npaths p .P with\u00adout modifying their pre-pruning count; (ii) no-op paths, that is paths that do not encapsulate \nmeaningful functionality. No-op paths in\u00adclude initialization statements such as ICompilationUnit cu \n= null; and (iii) non-compilable and non-executable paths, that is paths that can not be veri.ed for \ncorrectness to ensure that they are compilable and executable fragments of code. The pruned mining paths \nare passed to the SnippetFormulationAgent that transforms each path p .P to a corresponding Java code \nsnippet based on the transformation rules outlined in Section 3. The BFSMINE algorithm is a critical \ncomponent of our ap\u00adproach. We detail this algorithm with examples in the following subsections. 4.1 \nBFSMINE Algorithm Figure 11 gives the pseudo-code for the BFSMINE algorithm. Given a user query Q = (tq,CT \n), where tq is the query type and CT the code context in which the query is invoked, and a speci.c code \ninstance cmi, the BFSMINE algorithm initiates the mining process by identifying the set of nodes NQ = \n{nq } such that nq . cmi and the domain of the node nq is tq (domain(nq ) = tq). The set of nodes NQ \nidenti.es all instances in the code model instance cmi where the query type tq is instantiated. In most \ncases, the node nq .NQ is scoped within a method instance mi . cmi.There may be multiple nodes nq within \nthe scope of the same method instance mi. Unless stated otherwise, the BFSMINE algorithm is described \nin the context of one method instance, cmm. The goal of the BFSMINE algorithm is to determine for all \nsuch instances nq , types and eventually code segments that instantiate the node nq and hence the query \ntype tq. For each node nq .NQ, the BFSMINE algorithm recursively traces back along all edges private \nMP BFSMINE (Type tq, Context CT , CM cmi) {MP allMPs; for each method mi . cmi.getMethods(tq) { for each \nnode nq . mi.getNodes(tq) {MP mps = mineIQ(cmi, mi, nq, CT ); allMPs.addPaths(mps); } } return allMPs; \n} private MP mineIQ(CM cmi, Method mi, Node no, Context CT ) {if ni.getDomainType() . CT return null; \nMP allMPs; for each ni . no.getInputNodes() { Edge e = ni.getAnEdgeTo(no); MP mps = createAPath(ni, \ne, no); MP nextPaths = mineIQ(cmi, mi, ni, CT ); if nextPaths == null {allMPs.addPaths(mps); else { \nmps.connectPaths(nextPaths); allMPs.addPaths(mps); } } return allMPs; } Figure 11. The BFSMINE algorithm. \nei,...,ej incident on the node nq 3. The back traversal terminates when it reaches either (i) node ni \n. cmm, such that there are no edges ei incident on it; or (ii) node ni . cmm, such that the domain of \nthe node ni is ti (domain(ni) = ti)and ti is a type de.ned in the context CT of the user query Q (ti \n.CT ). Each traversal from nq to node ni is formulated into a mining path p such that each path records \na forward trace from the termi\u00adnation node ni to the starting node nq . The BFSMINE algorithm terminates \nwhen all nodes nq .NQ have been traced back, and returns the set of paths P to the MiningAgent. EXAMPLE \n1. To illustrate the working of BFSMINE, consider that the BFSMINE algorithm is invoked with the instantiation \nquery 3 Note, this does not include the parameter edge that is incident on a method invocation edge. \nIQ = (tq =ICompilationUnit, CT = {}), and the code model instance corresponding to class JavaMetricsView \nshown in Fig\u00adure 12. In the .rst phase of the BFSMINE algorithm, we identify the set of nodes NQ = {nq \n} such that domain(nq ) = ICompilation\u00adUnit.In this example, NQ = {ICompilationUnit icu1 }, where nq \n= ICompilationUnit icu1 exists in the code model instance of the method getCompilationUnit() de.ned in \nthe JavaMetrics-View class instance. The back traversal phase of the BFSMINE algorithm initiates at the \nnode nq = ICompilationUnit icu1.As ICompilationUnit icu1 has two edges incident on it, the BF-SMINE algorithm \ntraces back along the edges to the nodes I-JavaElement ije1 and IJavaElement ije2. At the node I-JavaElement \nije1, the back traversal is applied recursively till it terminates at the node IStructuredSelection ss. \nSimilarly, the recursive traceback from the node IJavaElement ije2 ter\u00adminates at the node JavaCore. \nAs all paths have been traversed, the traversal phase of the algorithm terminates. The BFSMINE al\u00adgorithm \nterminates with the completion of the traversal phase, as there are no other nodes nq .NQ. The back traversal \nis shown in Figure 13 using broad stroked lines. On termination the BFSMINE algorithm outputs two paths: \n<ss, o1, je, ije1, icu1>, and <JavaCore, ije2, icu1>. In the above example, the back traversal terminates \nwhen nodes with no edges incident on them are reached. The traver\u00adsal can also terminate if a type speci.ed \nin the context CT of the query is reached. Consider the modi.ed query IQ = (tq =I-CompilationUnit, CT \n= {IJavaElement} ). The query IQ now has a speci.ed type context CT = {IJavaElement}. The trace\u00adback \nof the paths, in this case, terminates at IJavaElement ije1 and IJavaElement ije2 respectively resulting \nin the .nal mining paths: <ije1,icu1>, and <ije2,icu1>. Figure 13. Back Traversal for Query IQ = (tq \n=ICompilationUnit, CT = { IFile}). The code model instance of method getCompilationUnit() in class JavaMetricsView \nis shown. The example highlights the back traversal of all edges.  4.2 Extensions to the BFSMINE Algorithm \nConsider the example detailed in Figure 12. The BFSMINE algo\u00adrithm returns two paths: p1 = <ss, o1, je, \nije1, icu1> and p2 = <JavaCore, ije2, icu1>. While valid, these paths are partial and raise additional \nquestions for the user: How is the object ss ob\u00adtained? How are parameters of a speci.c method within \nthe snippet instantiated? The user, in these cases, would likely need to initiate new queries that search \nthe sample repository for possible snippets. We observe that constraining the traversal phase of the \nalgo\u00adrithm to (i) edges incident on a node and (ii) within the scope of method boundaries, limits the \nBFSMINE algorithm to produce only partial snippets in many cases. We now propose extensions to the BFSMINE \nalgorithm to facilitate parameter edge mining as well as across method boundary mining. Mining Parameter \nEdges Traversals along a parameter edge epi incident on a method edge in the traceback path (as de.ned \nin the BFSMINE algorithm) are handled similar to all other types of edges. A back traversal along a parameter \nedge thus launches a recursive traceback at its initiating parameter node np.The key distinction with \nrespect to parameter edges is in the mining paths. While the path itself is constructed as described \nfor the BFSMINE algorithm, each parameter edge traversal represents a sub-path de\u00ad.ned in the context \nof the primary path. The sub-paths constructed by the parameter edge traversals are appended to the primary \npath. The traceback phase and the algorithm terminates as described for BFSMINE algorithm. EXAMPLE 2. \nConsider that the BFSMINE-EXT algorithm (see Figure 14) is invoked with the instantiation query IQ = \n(tq =ICompilationUnit, CT = {}), and the code model instance corresponding to class JavaMetricsView shown \nin Figure 13. The BFSMINE-EXT algorithm traces back over all edges, includ\u00ading the parameter edge ep1 \nincident on the method edge create (). Traceback along the parameter edge ep1 results in the sub\u00adpath \n<ss,o2,if1> that is appended to the primary traceback path <JavaCore, ije2, icu1>. Thus, on completion \nthe BFSMINE-EXT algorithm produces two paths: p1 = <ss, o1, je, ije1, icu1>, and p2 = {<JavaCore, ije2, \nicu1>, <ss,o2,if1>} Mining Across Method Boundaries Traversals across method boundaries are enabled under \ntwo conditions. Case 1: There exists a method parameter node npm in the code instance of the method mi \nsuch that npm represents the parameter object used in the invocation of the method mi. The method mi \nis assumed to be invoked from within a method mj. In this case, the traversal of the BFSMINE algorithm \nis extended to traceback the instantiation of the method parameter node at the invocation point of the \nmethod mi in method mj . The method parameter node npm here provides a hook point for tracing back to \na hitherto un-traced method. The termination condition for the traversal and the mining path construction \nis as described for the BFSMINE algorithm. Case 2: The method edge em in the code model instance of the \nmethod mi encapsulates the invocation of a locally de.ned method mj , such that method mj returns an \nobject Oj of interest during traversal. The BFSMINE algorithm is automatically invoked for all such local \nmethods. To avoid in.nite recursion, this automatic invocation of the BFSMINE algorithm is restricted \nto hitherto un\u00adtraced local methods mj . EXAMPLE 3. Consider the query IQ = (tq = ICompilation-Unit, \nCT = {}). Figure 15 shows the code model instance for the getCompilationUnit() and the selectionChanged() \nmeth\u00adods. With the BFSMINE-EXT algorithm, the traversal phase initi\u00adates at nodes ICompiationUnit icu1 \nand ICompilationUnit icu2 and does not terminate at the IStructuredSelection is, but instead traces back \nthrough the invocation point of the method getCompilationUnit() in the method selectionChanged() to the \ninstantiation of the getCompilationUnit() s parame\u00adter IStructuredSelection iss. The traversal terminates \nat the node ISelection selection in the selectionChanged() method. The back traversal is schematically \ndepicted in Figure 15 using broad stroked lines. On completion, the BFSMINE-EXT al\u00adgorithm results in \ntwo more complete paths: p1 = <selection, private MP BFSMINE-EXT (Type tq, Context CT , CM cmi) {MP allMPs; \nfor each method mi .cmi.getMethods(tq) { for each node nq .mi.getNodes(tq) {MP mps = mineIQ(cmi, mi, \nnq , CT ); allMPs.addPaths(mps); }} return allMPs; } private MP mineIQ(CM cmi, Method mi, Node no, Context \nCT ) {if ni.getDomainType() .CT return null; MP allMPs; for each ni .no.getInputNodes() { Edge e = ni.getAnEdgeTo(no); \nMP mps; if isLocalMethodCall(cmi, ni, e) mps = mineCalledMethod(cmi, ni, no, e, CT ); else mps = createAPath(ni, \ne, no); if e.getParameters() != null {MP paraPaths = mineParameter(cm, m, ni, e, CT ); mps.connectPaths(paraPaths); \n} if ni.isMethodParaNode(mi) {MP callerP aths = mineCallerMethod (cm, m, ni, CT ); mps.connectPaths(callerPaths); \n} MP nextPaths = mineIQ(cmi, mi, ni, CT ); if nextPaths == null {allMPs.addPaths(mps); else { mps.connectPaths(nextPaths); \nallMPs.addPaths(mps); }} return allMPs; } private MP mineCalledMethod(CM cmi, Node ni, Node no, Edge \ne, Context CT ) {metTypemcalled = getALocalMethod(cmi, e); MP allMPs; for each node n .mcalled.getNodes(no.getDomainType()) \n{ MP mps = mineIQ(cmi, mcalled, n, CT ); allMPs.addPaths(mps); } return allMPs; } private MP mineParameter(CM \ncm,metTypem, Node n, Edge e, Context CT ) { MP allMPs; for each parameter node np .e.getParameters() \n{ MP mps = mineIQ(cm, m, np, CT ); allMPs.connectPaths(mps); } return allMPs; } private MP mineCallerMethod(CM \ncm,metTypem, Node n, Context CT ) {MP allMPs; metTypemcaller = cm.getACallerMethod(m); for each node \nn .mcaller.getNodes(n.getDomainType()) { MP mps = mineIQ(cm, mcaller, n, CT ); allMPS.addPaths(mps); \n} return allMPs; } Figure 14. The BFSMINE-EXT algorithm. iss1, ss, o1, je, ije1, icu1>, and p2 = {<JavaCore, \nije2, icu1>, <selection, iss1, ss, o2, if1>}. Figure 16 illustrates the traceback when the second cross \nmethod boundary traversal condition is invoked. Here, we assume that the BFSMINE-EXT algorithm initiates \nat node ICompila\u00adtionUnit cu in method selectionChanged(). The method edge incident on the node ICompilationUnit \ncu encapsulates the in\u00advocation of a local method getCompilationUnit(). In this case, the code model \ninstance of the method getCompilationUnit() is automatically mined to provide more complete code snippets. \nOn termination, the BFSMINE-EXT algorithm produces two mining paths: p1 = <selection, iss1, ss, o1, je, \nije1, icu1>, and p2 = {<JavaCore, ije2, icu1>, <selection, iss1, ss, o2, if1>}.   5. First is the Best: \nRanking the Code Snippets While the snippet mining process returns a set of code snippets all of which \nsatisfying a given user query Q, the .t of these code snippets in solving a particular programming task \nmay, however, vary. On average, a user can only be expected to scan the .rst ten or so code snippets \nreturned by any search or mining process [3]. To best assist developers it is critical that snippets \nwith the potential to be best-.ts be ranked within the .rst 10 or so results. In this section, we present \nthree distinct heuristics, length, frequency and context, to rank the set of code snippets returned by \nthe snippet mining process. 5.1 Ranking by Snippet Length The length heuristic ranks snippets by the \nnumber of lines of code encapsulated in the code snippets the lower the number of lines of code, the \nhigher the rank of the code snippet. This length heuristic is similar to the shortest path heuristic \napplied by Prospector [11]. Figure 17(a) shows the ranking of the code snippets obtained for Q = (tq \n= ICompilationUnit, CT = {}) using the length heuristic. Here code snippets D and E are ranked above \ncode snippets A, B, C and F as they have fewer lines of code. 5.2 Ranking by Frequency of Occurrence \nA common notion, used in many diverse domains, is that of fre\u00adquency the more number of times a particular \nresult occurs, the more popular the result and hence deserving of a higher rank. In the context of code \nsnippets, frequency refers to the number of times identical code snippets written within or across different \nsource classes are mined from the code sample repository in response to a user query Q. Code snippets \nare ranked based on this frequency measure the higher the frequency, the higher the rank of the code \nsnippet. Figure 17(b) gives a sample frequency ranking of the code snippets obtained for Q = (tq = ICompilationUnit, \nCT = {}).  5.3 Ranking by Context Consider the query Q = (tq = ICompilationUnit, CT = {IEditorPart}) \nand the code snippets shown in Figure 17. Careful examination of the code snippets shows that snippet \nC is possibly the best-.t result for this query Q as ICompilationUnit is in\u00adstantiated indirectly from \nIEditorPart. This code snippet C is, however, ranked 3 by the length heuristic and 4 by the frequency \nheuristic. In a similar vein, ICompilationUnit in code snippets D and F is indirectly instantiated from \nthe types JavaEditor and CompilationUnitEditor respectively both specializa\u00adtions of IEditorPart. Hence, \nwhile not an exact match, the code snippets D and F are relevant to the query Q as the code con\u00adtext \n(IEditorPart) can be downcasted to either JavaEditor or CompilationUnitEditor when applying these snippets. \nThe  Code Snippets Length Heuristic Frequency Heuristic Context Heuristic (a) (b) (c) A. ISelection \nselection; IStructuredSelection ss = (IStructuredSelection) selection; Object obj = ss.getFirstElement(); \nIJavaElement je = (IJavaElement) obj; IJavaElement ije = je.getAncestor(IJavaElement.COMPILATION UNIT); \nICompilationUnit cu = (ICompilationUnit) ije 5 1 4 B. ISelection selection; IStructuredSelection ss = \n(IStructuredSelection) selection; Object obj = ss.getFirstElement(); IFile f = (IFile) obj; IJavaElement \nije = JavaCore.create(f); ICompilationUnit cu = (ICompilationUnit) ije; 6 2 5 C. IEditorPart editor; \nIEditorInput input = editor.getEditorInput(); IWorkingCopyManager manager = JavaUI.getWorkingCopyManager(); \nICompilationUnit cu = manager.getWorkingCopy(input); 3 4 1 D. JavaEditor editor; Object editorInput = \nSelectionConverter.getInput(editor); ICompilationUnit unit = (ICompilationUnit) editorInput; 1 3 2 E. \nMap fMap; IEditorInput input; Object obj = fMap.get(input); ICompilationUnit unit = (ICompilationUnit) \nobj; 2 5 6 F. JavaPlugin jp = JavaPlugin.getDefault() IWorkingCopyManager manager = jp.getWorkingCopyManager(); \nCompilationUnitEditor editor; IEditorInput iei = editor.getEditorInput; ICompilationUnit unit = manager.getWorkingCopy(iei); \n4 6 3 Figure 17. Code Snippets Obtained for Q = (tq = ICompilationUnit, CT = {}) shown with Length, Frequency \nand Context Rankings.  length and frequency heuristics, however, rank them as 1 and 4, and 3 and 6, \nrespectively. We posit that contextual information can and should be har\u00adnessed to provide more effective \nranking for a set of code snippets. We now de.ne the context match measure a formal measure for the \nmatch between the context of a code snippet and the context of a developer s code. We use this measure \nto rank the code snippets returned from the snippet mining algorithm. The context match measure, denoted \nas MCT (Q,s), is a quan\u00adtitative measure of how well the parent CPs and type CTs contexts of a code snippet \ns match the parent CPq and type CTq contexts speci.ed in the query Q. Formally, the context match measure \nis given as: MP (Q,s)+MVT (Q,s) MCT (Q,s)= (4) 2 where Q represents the query, s a mined snippet, MP \n(Q,s) the quantitative measure of the match between the direct parents (superclass and interfaces) of \nQ and s,and MVT (Q,s) the value quantifying the match between the lexically visible types encapsu\u00adlated \nin Q and s. The parent context match MP (Q,s) is de.ned as the average of the match between the superclasses \nMS (Q,s) and the match between the interfaces MI (Q,s)of Q and s respectively, and is given as: MS(Q,s)+MI(Q,s) \nMP (Q,s)= (5) 2 where MS(Q,s)=MT (superclass(Q),superclass(s)) (6) and I +S MI(Q,s)= (7) |intf(Q)| +|intf(s)| \nwhere X I =[maxis.intf(s)MT (iq ,is)] (8) iq.intf(Q) X S =[maxiq.intf(Q)MT (is,iq)] (9) is.intf(s) Here, \nsuperclass and intf generically refer to superclass and interfaces respectively, while iq . intf(Q)and \nis . intf(s)are speci.c instances of the interfaces. The term MT (tc, ts) denotes the match between two \ngiven domain types, and MI (Q,s)the average match between the two sets of interfaces intf(Q)and intf(s) \nThe type context match MVT (Q,s), the match of the lexically visible types in the query Q and code snippet \ns, is given as: P tc.type(Q) [maxts.type(s)MT (tc,ts)] MVT (Q,s)= (10) |type(Q)| where type denotes the \ntype context encapsulated in Q and s, tc . type(Q)and ts . type(s) are speci.c types, and MT (Q,s) the \nmatch between two given domain types. The type context match MVT is asymmetric it computes the average \nof the best similarity of each tc with ts . type(s) providing the best .t from the perspective of the \nquery. The type match MT (tc, ts) is computed using a type match algorithm [15].  6. Experimental Evaluation \nXSnippet is a code assistant framework that enables developers to retrieve candidate code snippets for \nsolving a particular pro\u00adgramming task without writing explicit queries. Figure 18 gives an architectural \noverview of the XSnippet framework, and high\u00adlights its three key components, Query Formulation, Snippet \nMin\u00ading and Ranking.The XSnippet system has been developed in Java (SDK 2.0) as an Eclipse plugin, and \ncan be invoked from within the Eclipse Java editor. Figure 19 shows a snapshot of the XSnippet system \nthat extends the Eclipse JDT user inter\u00adface by adding a new action XSnippet: query to the pop-up menu \nof the Java editor for initiating the query, and a new view XSnippet: result for displaying the returned \ncode snippets. The XSnippet framework is available for download as an Eclipse plugin at http://www.cs.uml.edu/~dsl. \nuser request query type and context A series of experiments were conducted to evaluate the potential \nbene.ts of the XSnippet system. In particular, the experiments were designed to test the following hypotheses: \nHypothesis 1: Generalized queries, IQG, provide better cover\u00adage of tasks than the specialized queries \nIQT and IQP (see Sec\u00adtion 6.2 for results). Hypothesis 2: Context-sensitive ranking heuristic provides \nbetter ranks for best-.t code snippets than context-independent heuristics. Similarly, context-independent \nheuristic degrade sharply with the increase in repository size (see Section 6.3 for results). Hypothesis \n3: Specialized queries combined with context-sensitive ranking heuristics provide better rank ordering \nfor best-.t code snippets than generalized queries using context-sensitive ranking heuristics (see Section \n6.4 for results). Hypothesis 4: The XSnippet system provides signi.cant assistance to developers, enabling \nthem to ef.ciently complete a large variety of programming tasks (see Section 6.5 for results). Hypothesis \n5: The context-dependent approach of the XSnippet system allows developers to complete more tasks than \nother pre\u00adviously proposed approaches (see Section 6.6 for results). 6.1 Setup XSnippet: Query XSnippet: \nResult The XSnippet system was deployed on a standalone PC Pentium IV 2.8 GHz with 1 GB RAM running Microsoft \nWindows XP and Eclipse 3.1. The repository used for the experiments contained ap\u00adproximately 2, 000 Java \nclass .les and 22, 000 methods extracted from two standard Eclipse plugins: org.eclipse.jdt.ui and org.eclipse.debug.ui. \nThese Java class .les were automati\u00ad 6.2 Effect of Query Types on Task Completion The .rst set of experiments \nmeasured the number of tasks out of the possible 17 tasks that could be completed using the code snippets \nreturned by the XSnippet system. The type of the instantiation queries was varied from the generic query \nIQG to the specialized type-based IQT and parent-based queries IQP , and the number of tasks that could \nbe completed under each of the query types was measured. The repository was set to contain all of the \nsource code model instances as detailed in Section 6.1. Figure 20 shows the percentage of tasks completed \nby the dif\u00adferent types of queries IQG, IQT and IQP . The x-axis has the different query types and the \ny-axis is the percentage of tasks completed, with 100% representing all 17 tasks. The query IQG performed \nthe best completing all 17 (100%) tasks, the query IQT completed 11 (65%) tasks, while IQP completed \n12 (70%)tasks. 1 0.8 Completed Tasks(%) 0.6 0.4 0.2 0 cally transformed into their corresponding source \ncode model in\u00adstances and subsequently loaded into the example repository. To evaluate the XSnippet system, \nwe designed 17 object\u00adinstantiation speci.c programming tasks. This was a suf.ciently large set to allow \nmeasurements of the effects of different parame\u00adters, including the context of the code, sample availability, \ndif.culty level, and number of queries required to complete tasks. All tasks were based on the Eclipse \nplugin examples from The Java(TM) Developer s Guide to ECLIPSE (The 2nd Edition) [2]. Table 1 highlights \nthe primary characteristics of the tasks in terms of the type being queried (tq), the parent (CT P ) \nand type (CT T ) con\u00adtexts speci.ed in the provided source class Cs, and the base type tb from which \ntq must be directly (or indirectly) instantiated. For each task, the declaration and usage of type tq \ntogether with all necessary Java source classes and jar .les were provided with the object instantiation \nof type tq left incomplete. That is, the code was not compilable so the task was to complete the code \nwith the object instantiation. It should be noted that the code snippets returned by the XSnip\u00adpet system \nvaried in that: (i) some code snippets could be seam\u00adlessly integrated with the code under development, \nthereby en\u00adabling the task to be completed at once; (ii) some code snippets introduced new objects into \nthe context, requiring one or more ad\u00additional queries to complete the task; and (iii) some code snippets \nencapsulated the relaxed type tc . of the type tc in the code con\u00adtext, requiring type modi.cations based \non the type hierarchy to complete the task. Code snippets in any one of the above three cat\u00adegories were \nconsidered to be desirable as long as they allowed the task to be completed. A task was considered to \nbe complete if the code could be compiled and executed, and it enabled the required functionality. Instantiation \nQueries Figure 20. The Percentage of Tasks Supported by the Different Types of Instantiation Queries \n-IQG, IQT ,and IQP . Furthermore, the characteristics of the tasks supported by each of the query types \nwere analyzed. Figure 21 summarizes these char\u00adacteristics and relates them to the characteristics of \nthe best-.t code snippets mined from the example repository. The left shows the repository characteristics. \nThe middle column shows the distribu\u00adtion of the tasks that adhere to the repository and code context \nchar\u00adacteristics. The tasks themselves are broken down into two groups one where tb exists in the code \ncontext and one where tb does not. The vertical lines on the right represent the results, in this case \ncoverage of tasks by each query type. The query IQT was able to support all tasks where (i) the provided \nsource class Cs encapsulated the base type tb; and (ii) snippets where the tq was instantiated from tb \n(tb . tq)were mined from the example repository. Twelve (12) tasks out of the total 17 tasks had the \ntype tb in its code context. Out of these only 10 tasks had snippets where the condition tb . tq was \ntrue. Also, the query IQT was able to support tasks that required object instantiation via either a constructor \nor a static method invocation irrespective of the existence of base type tb in the code context. The \n17th task required an object instantiation based on the static method invocation of the JavaUI class. \nThis task was supported by the IQT query. In summary, the query IQT supported 11 tasks 10 tasks requiring \nobject instantiation of type tq based on the base type tb in the code context and 1 task requiring a \nstatic method invocation. No. tq CT P CT T tb 1. ICompilableUnit ViewPart, ISelectionListener Text, \nJavaMetrics, ISelection IWorkbenchPart, ISelection 2. ICompilableUnit ViewPart, ISelectionListener Text, \nJavaMetrics, IStructuredSelection IWorkbenchPart, ISelection, IStructuredSelection 3. ICompilationUnit \nIElementChangedListener ICompilationUnit, List, ElementChangedEvent ElementChangedEvent 4. ICompilationUnit \nAddTraceStatementsAction, IEditorPart, IAction IEditorPart IEditorActionDelegate 5. IEditorInput AddTraceStatementsAction, \nIEditorPart, IAction IEditorPart IEditorActionDelegate 6. ISelectionService ViewPart, ISelectionListener \nText, Composite ViewPart 7. ITextEditor TextEditorAction - TextEditorAction 8. ITextSelection TextEditorAction \n- TextEditorAction 9. ITextSelection TextEditorAction ITextEditor ITextEditor 10. ProjectViewer AbstractDecoratedTextEditor \nSQLCodeScanner, AbstractDecoratedTextEditor ProjectionSupport Composite 11. IDocument IEditorActionDelegate \nIAction, TextEditor TextEditor 12. ITextSelection IEditorActionDelegate TextEditor, IAction, TextEditor \nIDocument 13. ICompilationUnit AddTraceStatementsAction, IAction JavaEditor IEditorActionDelegate 14. \nIDocument IEditorActionDelegate IAction TextEditor 15. IEditorInput AddTraceStatementsAction, IAction \nIEditorPart IEditorActionDelegate 16. ITextSelection IEditorActionDelegate IAction TextEditor 17. IWorkingCopyManager \nAddTraceStatementsAction, IAction JavaUI IEditorActionDelegate Table 1. Characteristics of the 17 Programming \nTasks. Repository Tasks t exists in context b t tb q t tb q parent context match t'b t q parent context \nmatch  IQ G t b not exist in context static method t q t'b  t q IQ parent context match P t tb q t \nq : the object type being queried t b : the based type from which must be instantiated fromt q t'b : \nthe relaxed type of t b t b t q : the type is instantiated based ont q t b Figure 21. Characteristics \nof the Tasks Supported by the Different Types of Instantiation Queries. The query IQP supported all tasks \nwhere the parent context of the provided source class Cs matched the parent context of the class encapsulating \nthe best-.t code snippet. The existence of the base type tb in the code context, and the constraint tb \n. tq had no impact on IQP performance. Twelve (12) tasks out of the possible 17 had a parent context \nmatch between the source class Cs and the class encapsulating the code snippets, and were completed by \nIQP . Out of these 12 tasks, the tb existed in the code context for only 10 tasks, and the constraint \ntb . tq held for only 8 of the tasks. The query IQG supported all tasks. The constraint tb . tq and on \nthe existence of tb in the code context had no impact on the overall performance of IQG. The results \nreturned by IQG were a superset of the results returned by IQT and IQP .  6.3 Impact of Contextual Information \non Ranking The second set of experiments measured the effectiveness of the different ranking heuristics \nfor different types of queries. Here, effectiveness is de.ned as the ability of the ranking heuristic \nto return the best-.t code snippet in the top-k results. The best-.t code snippet for each of the 17 \ntasks was determined apriori, and these were used to evaluate the different ranking heuristics. In addition, \na combination of these ranking heuristics to hierarchically rank the results .rst by context then within \na group by frequency and subsequently length was introduced and evaluated. All experiments were conducted \nusing the 17 tasks, the three query types and the complete repository set up as described in Section \n6.1. Due to space constraints, the ranking heuristics results for only the IQG is reported. Results for \nthe IQT and IQP were similar and can be found in [16]. Figure 22 shows the cumulative distribution of \nthe best-.t code snippet ranking for the different ranking heuristics. The results are reported for all \n17 tasks supported by IQG. The x-axis is the ranking given as integer numbers and the y-axis is the cumulative \ndistribution. The combination ranking heuristic performed the best with the best-.t code snippet for \nall tasks ranked within the top-33. For 35% of the tasks, the combination heuristic ranked the best-.t \ncode snippet .rst. The context ranking heuristic ranked the best-.t code snippet for all tasks within \nthe top-80.For 35% of the tasks, however, the best-.t code snippets ranked .rst, a result similar to \nthe combination ranking heuristic. Additionally, for 88% of the tasks the context and combination heuristics \nreturned the same rank for the best-.t code snippet. The frequency ranking heuristic placed the best-.t \ncode snippet for all tasks within the top-126, with 23% of the tasks having the best-.t code snippet \n.rst. The length ranking heuristic performed the worst, placing the best-.t code snippet .rst for only \n5% of the tasks. Ranks of Desired Code Snippets by IQ_G Furthermore, the effect of the number of code \nsnippets returned by the query IQG on the stability of the ranking heuristic was analyzed. Figure 23 \nshows the average ranking of the best-.t code snippets for versus the number of result code snippets \nreturned. The x-axis is the number of code snippets returned by the query and the y-axis is the rank \nof the best-.t code snippet. The performance of the length and frequency heuristics degraded sharply \nfor larger numbers result snippets. The combination and context heuristics were relatively stable, even \nfor larger numbers of returned results. This performance difference was attributed to the sensitivity \nof the length and frequency heuristics to the size and richness of the example repository. The numer \nof returned code snippets by IQ_G 1st 2nd 3rd IQT 5 0 1 IQP 4 1 1 IQG 3 2 1 Table 2. Distribution of \nthe Best-Fit Ranks for Different Query Types. 6.4 Effects of Query Types on Ranking The third set of \nexperiments measured the rank of the best-.t code snippets (for a given task) for different query types \n IQT , IQP and IQG. To level the playing .eld, the experiments were conducted using only the 6 tasks \nsupported by all three query types. The ranking heuristic was .xed to the combination heuristic for all \nqueries. Table 2 shows the distribution of the ranks of the best-.t code snippets for the 6 tasks supported \nby the IQT , IQP and IQG queries. Query IQT performed the best, having the the best-.t code snippet ranked \n.rst 5 out of 6 times. Query IQP did the next best, with one fewer top-ranked queries. Query IQG performed \nthe worst returning the best-.t code snippet in .rst only about 1/2 the time. This difference in performance \nwas attributed to the fact that IQT and IQP .ltered out non-candidate code snippets as part of the mining \nand snippet selection process while IQG returned all code snippets mined from the example repository. \nThis effectively deteriorated the overall ranking for IQG. In summary, specialized queries (IQT and IQP \n) provide higher ranking best\u00ad.t code snippets when compared to the generalized query IQG.  6.5 Analysis \nof XSnippet on Assisting Developers The fourth set of experiments analyzed the use of XSnippet in as\u00adsisting \ndevelopers to complete their programming tasks. Four tasks with varying degrees of dif.culty were designed \nfor the study. Ta\u00adble 3 gives a brief description of the four tasks together with a dif.culty rating, \nas well as the ranking of the best-.t snippets re\u00adturned by the system. Detailed descriptions of the \ntasks can be found in [16]. For each task, the declaration and usage of type tq to\u00adgether with all necessary \nJava source .les, jar .les and instructions on code execution were provided, but the object instantiation \nof the type tq was left incomplete. In all four tasks the provided code could not be compiled without \ncompleting the task modi.cations. Volunteers from the UMass-Lowell population were solicited to participate \nin the study. Initially, one group of users was created to complete the tasks without the use of XSnippet. \nThese users were free to use the default Eclipse Java code assistant tool, the Eclipse API browser, search \nonline via Google or use any other means available via the Internet. However, the users struggled for \nover one hour on the .rst task alone and, still unable to complete it, became frustrated and quit. It \nwas therefore assumed for the majority of the users that they would be unable to complete the tasks without \nthe use of XSnippet. For the remainder of the study, each participant was trained to use the XSnippet \nsystem prior to them conducting the study. Participants were then randomly assigned to one of two possible \ngroups. The .rst group was provided hints on the tb from which an object of the query type tq should \nbe instantiated. These hints appeared as comments in the provided source code. The second group was not \ngiven any hints. For each participant, the number of tasks completed together with the development time \nto complete each task was recorded. In addition, the strategy employed to select the result snippet by \neach participant was monitored. A special test harness was developed to conduct the user study. The test \nharness allowed participants to enter demographic and pro\u00ad Task A B C D Description Instantiate ISelectionService \nthat tracks the selec\u00adtion within the package explorer Instantiate ICompilationUnit that represents the \n.java .le selected from the package explorer Instantiate ITextSelection that represents the text selected \nfrom the Text editor Instantiate ICompilationUnit that represents the .java .le appearing on the Java \neditor CT P ViewPart, ISelectionListener ViewPart, ISelectionListener IEditorActionDelegate AddTraceStatementsAction, \nIEditorActionDelegate CT T Text, Composite TextEditor, IAction, IDocument IAction Dif.culty Easy Easy-Medium \nHard Medium-Hard Best-Fit Snippet Ranking 1or 2 7or 8 6, 7 or 10 27 Table 3. Brief Description of the \nFours Tasks Used for the User Study. gramming experience information at the start of the study. For each \ntask, the test harness provided a screen with a brief description of the task, prior to launching the \nEclipse development environment pre-set with all required .les for the task. The test harness automat\u00adically \nrecorded the time taken for the participants to complete each task. On completion of each task, participants \nwere asked to .ll a brief questionnaire that solicited information on the usefulness of the XSnippet \nsystem. All experiments were conducted using the 4 tasks, the generic instantiation query IQG,the combination \nranking heuristic, and the complete repository setup as described in Section 6.1. Participant Statistics \nSixteen participants took part in the study. Out of these, seven participants were randomly binned into \nthe Hint group and nine participants were placed in the NoHint group. Most of the participants were Computer \nScience graduate students with one CS undergraduate in each group. The participants had comparable programming \nexperience (C++ and Java) with most participants having on average about 1 year experience in one or \nboth languages. Only 6 of the participants had used Eclipse as a development environment prior to conducting \nthe study, and none of the participants had any experience with developing Eclipse plugins. Given the \nparticipant population and distribution of program\u00adming experience, the hint group approximated the more \nknowl\u00adedgeable and experienced developers, and the no hint group ap\u00adproximated the novice developers. \nTasks Completed For each participant the number of tasks com\u00adpleted was tracked. Figure 24 summarizes \nthe results for task com\u00adpletion by participants in each group. The x-axis has the tasks and the y-axis \nis the percentage of participants that completed each of four tasks. In the hint group, all participants \ncompleted Task A, B,and D.This 100% completion rate is helped in part by the provided hints the participants \nused the provided hints to select the best\u00ad.t code snippet as opposed to utilizing the snippet ranking. \nFor Task C, type modi.cation in the code snippet was required to complete the task. Participants with \nexperience and knowledge of Java type hierarchy (about 80% of participants) were able to complete the \ntask. In the no hint group, all participants completed Task A and B, 67% of the participants completed \nTask C,and 56% of the participants completed Task D. Participants in the no hint group were observed \nto use ranking of the code snippets as their primary criteria for selection of snippets. For Task D, \nthe best-.t code snippet was ranked 27 accounting for the fewer number of participants that completed \nthe task. For Task C participants had similar problems with the type modi.cation required in the code \nsnippet. Task Development Time For each participant the development time for each task was tracked. The \ndevelopment time included (i) the Eclipse launch time; (ii) the query process time; (iii) the time taken \nfor the participant to select a code snippet from the query task A task B task C task D Tasks results; \nand (iv) the time taken to modify and test the provided source code. Figure 25 shows the time taken by \neach participant to complete the provided task. Development times for participants that did not complete \nthe task were discarded. The x-axis has the tasks and the y-axis is the development time in minutes. \nThe bars for each task represent the hint and no hint groups with the individual participant times marked \non the bars. The lines across the tasks represents the average time taken by the participants to complete \neach task in the hint and no hint groups. Participants in both groups reported similar development times \nfor completing Task A and Task B.For Task C and Task D,par\u00adticipants in the hint group fared better \nselecting the best-.t code snippet based on the provided hints. The lower average develop\u00adment times \nfor Task C and D for the hint group are representa\u00adtive of the improvement due to hints. Most participants \nin the no hint group tried several code snippets for Task C and Task D be\u00adfore hitting upon the best-.t \ncode snippet. This was attributed to the fact that (i) for task C, there were two or more code snippets \nthat encapsulated the lexically visible types in the code context and were ranked higher than the best-.t \ncode snippets; and (ii) for Task D, code snippets returned by the query IQG did not have context match \nwith the provided source code.  6.6 Comparison with Prospector The last set of experiments was designed \nto compare the XSnippet system with another code assistant system. The Prospector [11] Development Time \n(min) 55 50 45 40 35 30 25 20 15 10 5 0 Task A Task B Task C Task D Tasks was chosen for comparison \nas the Strathcona [8] system was not available. The repository for XSnippet was setup as described in \nSec\u00adtion 6.1. The default repository for the Prospector system was used. This repository contained complete \nsource code from Eclipse 3.0 standard plugins, GEF plugins and Eclipse/GEF standard exam\u00adples. In essence, \nthe Prospector repository was a superset of the XSnippet repository. Moreover, as Prospector only reports \nthe top 12 code snippets, the number of code snippets returned by XSnippet was also limited to 12. The \nexperiments measured the percentage of tasks that could be completed using Prospector and XSnippet. The \n17 tasks, shown earlier in Table 1, were used for compar\u00adison. For each task, the IQT and IQG in the \nXSnippet system and the IQ. in the Prospector system, were used to return 12 re- T sults. Each result \nwas inserted in turn into the code, compiled and executed to check if the desired functionality was achieved. \nIf the desired functionality was achieved for at least 1 of the 12 returned results, the task was counted \nas completed. Figure 26 shows the percentage of tasks completed by IQT , IQG and IQ. T . The primary \ntask characteristic used for analyz\u00ading the results was the existence (or lack of) of the base type tb \nin the code context. The x-axis plots the two main criteria used for the comparison, and the y-axis plots \nthe percentage of tasks com\u00adpleted by each query type. The XSnippet IQT performed better than Prospectors \nIQ. for tasks where the tb existed in the code T context. This performance difference can be attributed \nto the fact that Prospector query evaluation is limited to the lexically visible types within the class \nboundary and superclass information is dis\u00adcarded. The XSnippet IQT and Prospectors IQ. performed sim- \nT ilarly for the tasks where tb did not exist in the code context. The query IQG performed the best and \nprovided code snippets for 82% tasks irrespective of whether or not the base type tb existed in the code \ncontext.  7. Related Work Most of previous research on software reuse has focused on the component matching \nto discover relevant components (classes or methods) as a whole that satisfy a given user query Q.These \napproaches include keyword-based [12], faceted [14], signature t_b existed t_b not existed overall T \nand XSnippet IQT and IQG. The results are categorized by the existence of tb in the code context. matching \n[19], speci.cation matching [20, 9], test cases [5], com\u00adment matching [18, 17] and name matching [15]. \nHowever, while they are a necessary step for identifying possible reusable compo\u00adnents from a set of \nrequirements, these works are orthogonal to software reuse that assists by providing code samples. Holmes \net al. [8] have developed Strathcona, an Eclipse plug\u00adin, that enables location of relevant code in an \nexample repository. Their approach is based on six heuristics that match the structural context descriptions \nencapsulated in the developer code with that encapsulated in the example code. The result is a set of \nexamples (source code examples) that occur most frequently when applying all heuristics. This approach \nwhile a good step forward, has some drawbacks: (i) each heuristic is generic, that is it is not tuned \nto a particular task of object instantiation or method invocation. This results often in irrelevant examples; \nand (ii) each heuristic utilizes all de.ned context, irrespective of whether the context is relevant \nor not. This over-constraining of the heuristic can result in too few examples or sometimes no examples. \nIn our work, we use similar contextual information, but tie it with specialized queries thereby providing \n.exibility without the unnecessary constraints. Mandelin et al. [11] have developed techniques for automati\u00adcally \nsynthesizing the Jungloid graph based on a query that de\u00adscribes the desired code in terms of input and \noutput types. Each result corresponds to an object instantiation of a query output type Tout derived \nfrom a given input type Tin. The Jungloid graph is created using both API method signatures and a corpus \nof sample client programs, and consists of chains of objects connected via method calls. The retrieval \nis accomplished by traversing a set of paths from Tin to Tout where each path represents a code frag\u00adment \nand a set of paths in turn composes all code fragments to form a code snippet. The code snippets returned \nby this traversal process are ranked using the length of the paths with the shortest path ranked .rst. \nWhile Prospector provides more re.ned, object\u00adinstantiation speci.c queries than Strathcona, it still \nreturns many irrelevant examples or in some cases too few quali.ed examples. This is primarily because \n(i) API signatures can be over-used. For example, two code segments may be connected by common types \nsuch as List and Set. However, each may expect to contain com\u00adpletely different object types; and (ii) \nthe context description is lim\u00adited to only the visible input types declared within the boundary of the \nmethod and class. The parent context, as described in Section 2, is ignored missing a set of potentially \nquali.ed hits. In our work, we explicitly address the above two limitations, and also provide more generalized \nquery types. In addition, we have developed a context-sensitive ranking heuristic that as per our evaluation, \npro\u00advides better ranking of the best-.t code snippets than the shortest path heuristic used in Prospector. \nHill et al. [7] have developed a method completion tool as a plugin for jEdit 4.2. The tool automatically \ncompletes a method body based on the current context of a method being developed using machine learning. \nTheir approach de.nes each method as a 154-dimensional vector: the number of lines of code, the number \nof arguments, a hash of the return type, the cyclomatic complexity, and the frequency count of each of \nthe 150 Java Language token types. The vector vq of a method being queried is compared to a set of pre-computed \nvectors vt of methods in the example repository, and the best method match is returned to the developer, \nsuch that the difference between vq and vt is small. This enables the devel\u00adoper to see similar methods. \nThe developer can choose to complete the current method. This approach suffers from some of the same \ndrawbacks as Strathcona the approach is general to all types of queries and can not be used to ask a \nmore directed query. Moreover, the approach is in.exible using a complete vector comparison at all times, \nand potentially missing out on partial matches that may be of use. Like Prospector, this approach limits \nthe context to just the type context and does not make use of the parent context. 8. Conclusions and \nFuture Work This paper presents XSnippet, an Eclipse plugin that allows devel\u00adopers to query for relevant \ncode snippets from a sample code repos\u00aditory. Here, relevance is de.ned by the context of the code, both \nin terms of the parents of the class under development as well as lex\u00adically visible types. Figure 27 \nhighlights the primary contributions of this work. Queries, invoked from the Java editor, can range from \nthe generalized object instantiation query that returns all possible code snippets for the instantiation \nof a type, to the more special\u00adized object instantiation queries that return either parent-relevant or \ntype-relevant results. Queries are passed on to a graph-based Snippet Mining module that mines for paths \nthat meet the require\u00adment of the speci.ed query. Paths here can be either within the method scope or \noutside of the method boundaries, ensuring that relevant code snippets that are spread across methods \nare discov\u00adered. All selected snippets are passed on to the Ranking module that supports four types of \nranking heuristics: context-sensitive rank\u00ading, frequency-based ranking, length-based ranking, and a \nranking heuristic that combines the three. Our experimental evaluation of the XSnippet system has shown: \n1) a generalized query provides better coverage of tasks than does a specialized query. In our experiments, \nthe generalized query IQG was able to cover (provide best-.t snippets) for all tasks; 2) a specialized \nquery provides better-.t code samples at a higher rank when used with a context-sensitive ranking algo\u00adrithm; \n3) context-sensitive ranking performs signi.cantly better than context-independent ranking and is less \nsusceptible to vari\u00adations in the size of the repository; 4) XSnippet has the potential to assist developers \nby providing sample code snippets relevant to their task at hand, and to help decrease the overall development \ntime; and 5) XSnippet provides better coverage of tasks and better ranking for best-.t snippets than \nother code assistant systems. Future Work: There are a number of directions in which this work can be \nextended. An immediate direction is a more exten\u00adsive user study that would go beyond general usage to \ninvesti\u00adgating the impact of such a code assistant framework for actual development tasks. Another direction \nis to extend the queries be\u00adyond object instantiation to queries that pertain to the correct us-age of \nmethods. These correspond to discovering embedded se\u00adquences of methods that must be used together to \nensure proper method behavior such as: 1) methods linked by the life cycle of their classes. For example, \nto ensure correct behavior of an object of type IWorkingCopyManager the methods connect, getWorking-Copy \nand disconnect must be used together; and 2) methods com\u00admonly interconnected by an invocation path. \nFor example, method apply of the TextEdit class is commonly used in concert with the method rewriteAST \nof the class ASTRewrite to apply the edit-tree returned by the method rewriteAST() to the given document. \n  References [1] V. R. Basili, L. C. Briand, and W. L. Melo. How reuse in.uences productivity in object-oriented \nsystems. Communications of ACM, 39(10):104 116, 1996. [2] J. D Anjou, S. Fairbrother, D. Kehn, J. Kellerman, \nand P. McCarthy. The Java(TM) Developer s Guide to ECLIPSE (The 2nd Edition). Addison-Wesley Professional, \n2004. [3] O. Drori. Algorithm for Documents Ranking: Idea and Simulation Results. In Proceedings of the \n14th international conference on Software Engineering and Knowledge Engineering, pages 99 102. ACM Press \nNew York, NY, USA, 2002. [4] P. Freeman. Software Reusability. IEEE Computer Society Press, 10662 Los \nVaqueros Circle, Los Alamitos, CA 90720 USA, 1987. [5] J. Goguen, D. Nguyen, J. Meseguer, Luqi, D. Zhang, \nand V. Berzins. Software Component Search. Journal of Systems Integration, 6(1/2):93 134, March 1996. \n[6] G. T. Heineman and W. T. Councill. Component-based Software Engineering. Addison-Wesley Publishing \nCompany, Reading, Massachusetts, 2001. [7] R. Hill and J. Rideout. Automatic method completion. In The \n16th IEEE International Conference on Automated Software Engineering, pages 228 235, 2004. [8] R. Holmes \nand G. C. Murphy. Using structural context to recommend source code examples. In Proceedings of the 27th \nInternational Conference on Software Engineering. ACM Press, 2005. [9] J.-J. Jeng and B. H. C. Cheng. \nSpeci.cation Matching for Software Reuse: A Foundation*. In Proceedings of the 1995 Symposium on Software \nreusability, pages 97 105. ACM Press, 1995. [10] G. T. Leavens and M. Sitaraman. Foundations of Component-Based \nSystems. Cambridge University Press, 2000. [11] D. Mandelin, L. Xu, R. Bodk, and D. Kimelman. Jungloid \nmining: helping to navigate the api jungle. In Conference on Programming Language Design and Implementation \n(PLDI). ACM Press, June 2005. [12] Y. Matsumoto. A Software Factory: An Overall Approach to Software \nProduction. In P. Freeman, editor, Tutorial: Software Reusability. IEEE Computer Society Press, 1987. \n[13] O. Nierstrasz and T. D. Meijler. Research Directions in Software Composition. ACM Computing Surveys, \n27(2):262 264, 1995. [14] R. Prieto-Diaz and P. Freeman. Classifying Software for Reusability. IEEE Software, \n4(1):6 16, 1987. [15] N. Tansalarak and K. T. Claypool. Finding a Needle in the Haystack: A Technique \nfor Ranking Matches between Components. In Proceedings of the 8th International SIGSOFT Symposium on \nComponent-based Software Engineering (CBSE 2005): Software Components at Work, May 2005. [16] N. Tansalarak \nand K. T. Claypool. XSnippet: A Code Assistant Framework. Technical Report 2006-xxx, Department of Computer \nScience, University of Massachusetts -Lowell, March 2006. Available at http://www.cs.uml.edu/techrpts/reports.jsp. \n[17] Y. Ye and G. Fischer. Supporting reuse by delivering taskrelevant and personalized information. \nIn Proceedings of the 24th International Conference on Software Engineering, pages 513 523. ACM Press, \nMay 2002. [18] Y. Ye, G. Fischer, and B. Reeves. Integrating active information delivery and reuse repository \nsystems. In International Symposium on Foundations of Software Engineering, pages 60 68. ACM Press, November \n2000. [19] A. M. Zaremski and J. M. Wing. Signature Matching: a Tool for Using Software Libraries. In \nACM Transactions on Software Engineering and Methodology (TOSEM), pages 146 170. ACM Press, 1995. [20] \nA. M. Zaremski and J. M. Wing. Speci.cation Matching of Software Components. In ACM Transactions on Software \nEngineering and Methodology (TOSEM), pages 333 369. ACM Press, 1997. \n\t\t\t", "proc_id": "1167473", "abstract": "It is common practice for software developers to use <i>examples</i> to guide development efforts. This largely unwritten, yet standard, practice of \"develop by example\" is often supported by examples bundled with library or framework packages, provided in textbooks, and made available for download on both official and unofficial web sites. However, the vast number of examples that are embedded in the billions of lines of already developed library and framework code are largely untapped. We have developed <i>XSnippet</i>, a context-sensitive code assistant framework that allows developers to query a sample repository for code snippets that are relevant to the programming task at hand. In particular, our work makes three primary contributions. First, a range of queries is provided to allow developers to switch between a context-independent retrieval of code snippets to various degrees of context-sensitive retrieval for object instantiation queries. Second, a novel graph-based code mining algorithm is provided to support the range of queries and enable mining within and across method boundaries. Third, an innovative context-sensitive ranking heuristic is provided that has been experimentally proven to provide better ranking for best-fit code snippets than context-independent heuristics such as shortest path and frequency. Our experimental evaluation has shown that <i>XSnippet</i> has significant potential to assist developers, and provides better coverage of tasks and better rankings for best-fit snippets than other code assistant systems.", "authors": [{"name": "Naiyana Sahavechaphan", "author_profile_id": "81385595847", "affiliation": "National Electronics and Computer Technology Center, Thailand", "person_id": "P813677", "email_address": "", "orcid_id": ""}, {"name": "Kajal Claypool", "author_profile_id": "81100573520", "affiliation": "Oracle Corporation, Nashua, NH", "person_id": "PP18004015", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167508", "year": "2006", "article_id": "1167508", "conference": "OOPSLA", "title": "XSnippet: mining For sample code", "url": "http://dl.acm.org/citation.cfm?id=1167508"}