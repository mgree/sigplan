{"article_publication_date": "10-16-2006", "fulltext": "\n Javana: A System for Building Customized Java Program Analysis Tools Jonas Maebe Dries Buytaert Lieven \nEeckhout Koen De Bosschere ELIS, Ghent University, Belgium {jmaebe,dbuytaer,leeckhou,kdb}@elis.UGent.be \nAbstract Understanding the behavior of applications running on high-level language virtual machines, \nas is the case in Java, is non-trivial be\u00adcause of the tight entanglement at the lowest execution level \nbe\u00adtween the application and the virtual machine. This paper proposes Javana, a system for building Java \nprogram analysis tools. Javana provides an easy-to-use instrumentation infrastructure that allows for \nbuilding customized pro.ling tools very quickly. Javana runs a dynamic binary instrumentation tool underneath \nthe virtual machine. The virtual machine communicates with the instrumentation layer through an event \nhandling mechanism for building a vertical map that links low-level native instruction point\u00aders and \nmemory addresses to high-level language concepts such as objects, methods, threads, lines of code, etc. \nThe dynamic binary instrumentation tool then intercepts all memory accesses and in\u00adstructions executed \nand provides the Javana end user with high\u00adlevel language information for all memory accesses and natively \nexecuted instructions. We demonstrate the power of Javana through a number of ap\u00adplications: memory address \ntracing, vertical cache simulation and object lifetime computation. For each of these applications, the \nin\u00adstrumentation speci.cation requires only a small number of lines of code. Developing similarly powerful \npro.ling tools within a vir\u00adtual machine (as done in current practice) is both time-consuming and error-prone; \nin addition, the accuracy of the obtained pro.ling results might be questionable as we show in this paper. \nCategories and Subject Descriptors D.2.5 [Testing and Debug\u00adging]: Tracing; D.3.4 [Processors]: Run-time \nEnvironments General Terms Experimentation, Measurement, Performance Keywords Customized Program Analysis \nTool, Java, Aspect-Oriented Instrumentation 1. Introduction Understanding the behavior of software is \nof primary importance to improve its performance. Application and system software de\u00advelopers need a \ngood understanding of an application s behavior in order to optimize overall system performance. Analyzing \nthe be\u00adhavior of applications written in languages such as C and C++ is a Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 06 October 22 26, 2006, Portland, Oregon, \nUSA. Copyright c . 2006 ACM 1-59593-348-4/06/0010. . . $5.00. well understood problem. However, understanding \nthe behavior of modern software that relies on a runtime system, also called a vir\u00adtual machine (VM), \nis much more challenging. The popularity of high-level language virtualization software has grown signi.cantly \nover the recent years with programming environments such as Java and .NET. The reasons for the increased \npopularity of high-level language virtual machines are portability, security, robustness, au\u00adtomatic \nmemory management, etc. Virtualization though makes the behavior of modern software fairly hard to understand \nbecause of the tight entanglement between the application and the virtualiza\u00adtion software. 1.1 The Javana \nconcept This paper proposes Javana, a system for building customized Java program analysis tools. Javana \ncomes with an easy-to-use instru\u00admentation framework so that only a few lines of instrumentation code \nneed to be programmed for building powerful pro.ling tools. The Javana instrumentation framework provides \nthe end user with both high-level and low-level information. The high-level informa\u00adtion relates to the \nJava application and the VM, such as thread IDs, method IDs, source code line numbers, object IDs, object \ntypes, etc. The low-level information consists of instruction pointers and memory addresses. Running \nthe Java application of interest within the Javana system along with user-speci.ed instrumentation rou\u00adtines \nthen collects the desired pro.les of the Java application. The Javana system consists of a VM along with \na dynamic bi\u00adnary instrumentation tool that runs underneath the VM. The virtual machine communicates \nwith the dynamic binary instrumentation tool through an event handling mechanism. The virtual machine \ninforms the instrumentation layer about a number of events, for example when an object is created, moved \nor collected, or when a method gets compiled or re-compiled, etc. The dynamic binary instrumentation \ntool then catches these events and subsequently builds a vertical map that links instruction pointer \nand memory ad\u00addresses to high-level language concepts. The dynamic binary instrumentation tool also captures \nall na\u00adtively executed machine instructions during a pro.ling run within Javana; this includes instructions \nexecuted in native functions called through the Java Native Interface (JNI). Instrumenting all natively \nexecuted machine instructions causes a substantial slow\u00addown, however, it enables Javana to know for \nall native instruc\u00adtions from what method and thread the instruction comes and to what line of source \ncode the instruction corresponds; and for all ac\u00adcessed memory locations, Javana knows what objects are \naccessed. The Javana concept is also easy to transfer to other virtual ma\u00adchines and other dynamic binary \ninstrumentation tools; building a Javana system is easy to do. Only a few lines of code need to be added \nto the virtual machine to make the virtual machine Javana\u00adenabled as we demonstrate through our proof-of-concept \nimple\u00admentation that combines the Jikes RVM [1] with DIOTA [16, 17]. Our proof-of-concept Javana implementation \nis publicly available at http://www.elis.ugent.be/javana/.  1.2 Applications Javana enables the building \nof vertical pro.ling tools, i.e.,pro.l\u00ading tools that crosscut the Java application, the VM and the native \nexecution layers. Vertical pro.ling tools are invaluable for gaining insight into the overall performance \nand behavior of a Java appli\u00adcation. When looking at the lowest level of the execution stack, i.e., when \nlooking at the individual instructions executed on the host machine, it is hard to understand the application \ns behavior because of the fact that the virtualization software gets intermixed with application code. \nHowever, when the goal is deep understanding of the applica\u00adtion s behavior, the lowest level of the \nexecution stack really is the level to look at. Vertical pro.ling enables gaining such insights and Javana \nmakes vertical pro.ling easy to do. Building equally powerful pro.ling tools without Javana is both tedious \nand error\u00adprone; modifying the virtual machine by adding instrumentation code changes the code and data \nlayout which perturbs the native execution behavior substantially. Dynamic binary instrumentation underneath \nthe virtual machine as done in Javana alleviates this is\u00adsue. In this paper we demonstrate the power \nof Javana through three applications. Our .rst application is memory address tracing. A re\u00adcent study \npublished by Shuf et al. [21] analyzed the memory be\u00ad havior of Java applications based on memory address \ntraces. They instrumented the virtual machine to trace all heap accesses, but did not trace stack accesses. \nWe found that on average 58% of all mem\u00adory accesses in a Java application are non-heap accesses. As \nsuch, not including non-heap accesses in a memory behavior analysis study may signi.cantly skew the overall \nresults. The Javana system captures all memory accesses and consequently is more accurate. In our second \napplication we build a vertical pro.ling tool for analyzing the memory hierarchy behavior of Java applications. \nThis cache performance pro.ling tool tracks cache miss rates per ob\u00adject type and per method and thus \nallows for quickly computing the top most cache miss causing lines of code, the top most cache miss causing \nobject types, etc. This is invaluable information for an application developer who wants to optimize \nthe memory per\u00adformance of his software. Again, we want to emphasize how easy this pro.ling tool was \nto set up only a few lines of instrumenta\u00adtion code are needed. Our third application shows how easy \nit is to build an object lifetime analysis tool in Javana. Previous work [20] has shown that object lifetime \nis an important characteristic which can be used for analyzing and optimizing the memory behavior of \nJava applica\u00adtions. Computing an object s lifetime, although conceptually sim\u00adple, is challenging in \npractice without Javana because the virtual machine needs to be adjusted in numerous ways in order to \ntrack all possible accesses to all objects, including accesses that occur through the Java Native Interface \n(JNI). This requires an in-depth understanding of the virtual machine. Computing object lifetime distributions \nwith Javana on the other hand, is easy to set up and in addition, is guaranteed to deliver accurate object \nlifetimes. 1.3 Paper organization This paper is organized as follows. We .rst detail on the Javana sys\u00adtem \nand subsequently describe the Javana instrumentation language that we developed as part of the Javana \nsystem. We then quantify Javana s performance and demonstrate how powerful Javana is for quickly building \ncustomized Java program analysis tools. Finally, we discuss related work and conclude the paper. Java \nAPI Operating system Hardware Figure 1. The Javana system for pro.ling Java applications.  2. The Javana \nsystem Figure 1 illustrates the basic concept of the Javana system. The top of the execution stack shows \na Java application that is to be pro.led. The Java application together with a number of Java libraries \nruns on top of a virtual machine. The virtual machine translates Java bytecode instructions into native \ninstructions. A dynamic binary instrumentation tool resides beneath the virtual machine and tracks all \nnative instructions executed by the virtual machine. The key point of the Javana system is that the virtual \nmachine informs the dynamic binary instrumentation tool through an event handling mechanism whenever \nan object is created, moved, or deleted; or a method is compiled, or re-compiled; or a thread is cre\u00adated, \nswitched or terminated. The dynamic binary instrumentation tool then uses these events to build vertical \nmaps that associate na\u00adtive instruction pointers and memory addresses with objects, meth\u00adods, threads, \netc. The dynamic binary instrumentation tool also in\u00adtercepts all memory accesses during the execution \nof the Java appli\u00adcation on the virtual machine. This includes instructions executed in native JNI functions, \nbut excludes kernel-level system calls as will be discussed later. Using the vertical maps, the binary \ninstru\u00admentation tool associates native machine addresses to high-level concepts such as objects, methods, \netc. This high-level information along with the low-level information is then made available to the end \nuser through the Javana instrumentation framework. The remainder of this section discusses the Javana \nsystem in more detail. We discuss the events that are triggered by the vir\u00adtual machine, the dynamic \nbinary instrumentation layer in the Ja\u00advana system, the event handling mechanism, the vertical instru\u00admentation, \nthe perturbation of the Javana system and .nally our Javana proof-of-concept implementation. All of the \nsubsections be\u00adlow give more-or-less a general description of what the issues are for building a Javana \nsystem; the .nal subsection then discusses our own proof-of-concept implementation. 2.1 Events triggered \nby the virtual machine The Javana system requires that the virtual machine is instrumented to trigger \nevents. These events communicate information between the virtual machine and the dynamic binary instrumentation \ntool. Our current Javana system supports the following events: Class loading: When a new class is loaded \nand a new object type becomes available, the new class name is communicated to the binary instrumentation \ntool.  Object allocation: When a new object is allocated, the object s type and memory location (object \nstarting address and its size) are communicated.  Object relocation: When an object is copied by the \ngarbage collector, the object s new location is communicated to the instrumentation tool.  Method compilation: \nWhen a method is compiled, its name, memory location and a code to line number map are com\u00admunicated \nto the instrumentation tool.  Method recompilation: When a method is recompiled, the method s location \nand code to line number map are updated in the binary instrumentation tool.  Method relocation: When \ncode is moved by the garbage collec\u00adtor, the code s new location in memory is communicated.  Memory \nfreed during garbage collection: When memory is freed, the address range of the freed memory space is \ncommu\u00adnicated to the binary instrumentation tool.  Java thread creation: When a new Java thread is created, \nthe thread s ID and name are communicated.  Java thread switch: When a Java thread switch occurs, the \nnewly scheduled Java thread s ID is communicated.  Java thread termination: When a Java thread has ended \nexecu\u00adtion, this is communicated to the dynamic binary instrumenta\u00adtion tool.  Java thread stack switch: \nWhen a Java thread stack is relocated, the thread ID, the old stack location and the new stack location \nare communicated.  Note that this event list is just an example event list that could be tracked within \na Javana system. Additional events could be de.ned and added to this list if desired; implementing events \nin a virtual machine is easy to do. We found though that this list of events is suf.cient for our purpose \nof building powerful Java program analysis tools, as will be shown in the remainder of this paper. 2.2 \nDynamic binary instrumentation A dynamic binary instrumentation tool takes as input a binary and an instrumentation \nspeci.cation. The binary is the program of in\u00adterest; this is the Java application running on a virtual \nmachine in our case. The instrumentation speci.cation indicates what needs to be instrumented in the \nbinary; this is going to drive the cus\u00adtomized pro.ling. The dynamic binary instrumentation tool then \ninstruments the program of interest at run time. Upon the .rst exe\u00adcution of a given code fragment, the \ninstrumentation tool reads the original code, modi.es it according to the instrumentation speci.\u00adcation \nand stores the result as part of the instrumented binary. The instrumented version of the code is then \nexecuted and the desired pro.ling information is collected while executing the instrumented binary. The \ndata memory addresses referenced by the loads and stores in the instrumented binary are identical to \nthe uninstrumented bi\u00adnary. By keeping the original binary in memory at its original ad\u00address while generating \nthe instrumented binary elsewhere, the in\u00adstrumented binary obtains correct data values from the original \nuninstrumented binary in case data-in-code is read. The instrumen\u00adtation tool also keeps track of correspondences \nbetween instruction pointers in the original binary versus the instrumented binary. By doing so, the \ninstrumentation routines see instruction pointers and memory addresses as if they were generated during \nthe execution of the original binary. Running a dynamic binary instrumentation tool underneath a virtual \nmachine requires that the instrumentation tool can deal with self-modifying code. The reason is that \nmost virtual machines im\u00adplement a dynamic optimizer that detects and (re-)optimizes fre\u00adquently executed \ncode fragments. A similar issue occurs when garbage is collected; copying collectors may copy code from \none memory location to another. This requires that the dynamic instru\u00admentation tool invalidates the \nold code fragment and replaces it with an instrumented version of the newly generated code frag\u00adment. \nPrevious work [16] has proposed various approaches to instru\u00ad menting self-modifying code. These approaches \nvary in granular\u00adity for tracking self-modifying code: some approaches track mem\u00adory page level accesses, \nother approaches track individual memory operations. The bottom line is that all of them cause a substantial \nslowdown in execution time of the instrumented binary, in some cases to up to a factor 20. However, since \nthe virtual machine com\u00admunicates with the dynamic binary instrumentation tool through an event handling \nmechanism, we can optimize the self-modifying code support. We use the information provided by the event \nhan\u00addling to invalidate an old code fragment and to replace it with an instrumented version of the new \ncode fragment. This eliminates the slowdown for supporting self-modifying code almost completely. Note \nthat the dynamic binary instrumentation tool does not track kernel-level system calls. This limits the \nuse of Javana to user-space instrumentation. 2.3 Event handling The virtual machine triggers events \nby calling empty functions; these empty functions are native C functions. The dynamic binary instrumentation \ntool intercepts such function calls and in response calls the appropriate event handlers. Event handlers \ncan accept ar\u00adguments because the arguments placed on the stack by the virtual machine are available \nto the binary instrumentation tool as well. For example, when allocating an object, the virtual machine \ncalls the AllocateObject function with a number of arguments, namely the object type t, its address m \nand its size s. The dynamic bi\u00adnary instrumentation tool intercepts such events by inspecting the target \naddresses of the function calls. If the target address corre\u00adsponds to the AllocateObject function in \nthe above example the dynamic binary instrumentation tool knows this function by name from the symbol \ninformation of the virtual machine the dynamic binary instrumentation tool transfers control to the \nappro\u00adpriate event handler which in turn reads the arguments from the stack and adds this information \nto its internal data structures. When the event handler has .nished execution, control is transfered \nto the return address of the event s function call, i.e., the instrumented bi\u00adnary gets control again. \nEvent handling enables the dynamic instrumentation tool to build the vertical map. In the above example \nwith the Allocate-Object event, the event handler adds the following information to the vertical map: \nan object of type t is allocated in the memory address range m to m+s. Similar event handlers exist for \nall the events mentioned in section 2.1.  2.4 Vertical instrumentation The dynamic instrumentation tool \ncaptures all native instructions and memory accesses from both the application and the virtual machine \nduring the execution of a Java application within Javana. The vertical map then enables the dynamic binary \ninstrumentation tool to know for each memory access what object is being accessed and what the object \ns type is; and for every instruction pointer, the dynamic binary instrumentation tool knows to what method, \nto what line of source code and to what thread the instruction corresponds. The end result is that Javana \nallows for easily tracking all Java object accesses, which is much harder to do without a vertical map \nand dynamic binary instrumentation support. In our proof-of-concept Javana system we keep track of the \nver\u00adtical map using two AVL trees an AVL tree is a self-balancing binary search tree. The .rst AVL tree, \nthe method tree, contains mapping information between instruction pointers and method in\u00adformation. A \nnode in the method tree is identi.ed by an instruction pointer address range that corresponds to a line \nof source code. In\u00adstruction pointer ranges that are not represented in the method tree do not correspond \nto a Java source code line. The second AVL tree called the object tree contains object information. A \nnode in the object tree identi.es an object based on the object s address range, i.e., the object s address \nand size. The remaining address ranges refer to non-objects. Note that the method and object trees are \naccessed very fre\u00adquently during a pro.ling run. For example, for every memory ac\u00adcess the object tree \nneeds to be searched for the corresponding ob\u00adject. This is very time-consuming and has a big impact \non the over\u00adall pro.ling overhead. We therefore optimized the accessing of the method and object trees \nby adding a caching mechanism that tracks recently accessed object and method information. We obtain \nan av\u00aderage hit rate for the object and method tree caches of 67% and 99%, respectively. In addition, \nwe further optimize the miss case by searching the tree starting from the previous hit. This reduces \nthe tree search time thanks to spatial locality. 2.5 Perturbation An important property of any instrumentation \nframework is that the results that are obtained during pro.ling may not suffer from perturbation. The \nend user wants the instrumentation framework to be completely transparent to its user, i.e., the instrumentation \nframework should not impact the results from pro.ling. More in particular, in our Javana system, care \nneeds to be taken so that the pro.ling results are not perturbed by the event handling mechanism. Recall \nthat the virtual machine triggers events by call\u00ading an empty method using a number of arguments. Computing \nthe arguments, pushing them onto the stack, and .nally calling the empty method introduces some overhead. \nSince the dynamic binary instrumentation tool instruments all natively executed instructions, the instructions \nexecuted for triggering an event in the virtual ma\u00adchine get instrumented as well. In order to alleviate \nthis issue, and to remove any perturbation because of the event handling mecha\u00adnism, we communicate the \naddress ranges of the virtual machine code for event triggering. As such, the dynamic binary instrumen\u00adtation \ntool knows that the code executed in these address ranges needs to be disregarded. Another issue is that \nmany virtual machines use the notion of absolute time to trigger various internal events. This could \nbe the case for detecting hot code that needs to be scheduled for optimiza\u00adtion. Detecting hot code can \nbe done by sampling the call stack; when the number of samples of a given method gets above a given threshold, \nthe method is considered for optimization. The Java thread scheduling also relies on the notion of time. \nJava threads get time quanta for execution and when a time quantum has .nished, another Java thread can \nbe scheduled. Running a virtual machine within a Javana system causes the virtual machine to run slower, \nand by consequence, this affects timer-based virtual machine events such as code optimization and Java \nthread scheduling. This can be solved by using deterministic replay techniques [3]. In fact, it is common \npractice in virtual machine research to solve the code op\u00adtimization non-determinism by having the virtual \nmachine write out its recompilation strategy during an uninstrumented run, and then reuse this recompilation \nstrategy during the instrumented run. 2.6 A proof-of-concept Javana system The Javana system is a general \nframework for building a system for building customized Java program analysis tools. Any virtual machine \ncould be employed in this framework and any dynamic binary instrumentation tool could be used as well. \nIn our experi\u00admental framework, we use the Jikes RVM as our virtual machine and we use DIOTA as our dynamic \nbinary instrumentation tool. 2.6.1 Jikes RVM The Jikes Research Virtual Machine [1] is an open source \nJava virtual machine written almost entirely in Java. Jikes RVM uses a compilation-only scheme (no interpretation) \nfor translating Java bytecodes to native machine instructions. In our experiments we use the FastAdaptive \npro.le: all methods are initially compiled using a baseline compiler, and hot methods are recompiled \nusing an optimizing compiler. Making the Jikes RVM Javana-enabled was easy. We only had to insert around \ntwo hundred lines of code (including comments) into the virtual machine in order to trigger the events \nintercepted by the dynamic binary instrumentation tool. More speci.cally, we added an event to the class \nloader, to the object allocator, to all garbage collectors when an object or code is being moved or deleted, \nto all compilers and optimizers when a method is being compiled or optimized, and to the thread management \nsystem when a thread is created, switched or terminated. There is one peculiarity with instrumenting \nthe Jikes RVM itself that needs special attention this is because the Jikes RVM is written in Java. \nInstrumentation cannot be activated until the virtual machine is properly booted. This means that there \nare some virtual machine methods and objects that cannot be communicated to the binary instrumentation \ntool during virtual machine startup. This can be solved by communicating these virtual machine methods \nand objects as soon as the virtual machine is properly booted. From then on, the instrumentation tool \nintercepts all method calls and object accesses during the program execution. 2.6.2 DIOTA The dynamic \nbinary instrumentation tool that we use in our proof\u00adof-concept Javana system is DIOTA [17]. DIOTA stands \nfor Dy\u00ad namic Instrumentation, Optimization and Transformation of Ap\u00adplications and is a dynamic binary \ninstrumentation framework for use on the Linux operating system running on x86-compatible pro\u00adcessors. \nIts functionality includes intercepting memory operations, code execution, signals, system calls and \nfunctions based on their name or address, as well as the ability to instrument self-modifying code [16]. \n DIOTA is implemented as a dynamic shared library that can be hooked up to any program. The main library \nof DIOTA con\u00adtains a generic dynamic binary instrumentation infrastructure. This generic instrumentation \nframework can be used by so-called back\u00adends that specify the particular instrumentation of interest \nthat needs to be done. The backend that we currently use is a memory operation tracing backend, i.e., \nthis backend instruments all mem\u00adory operations. The general operation of DIOTA is very similar to that \nof other dynamic binary instrumentation frameworks such as PIN [15] and Valgrind [18]. All of these operate \nin a similar way as described in section 2.2.   3. The Javana language A system for building customized \nJava program analysis tools also requires an easy-to-use instrumentation framework. The instrumen\u00adtation \nframework is the environment in which the end user will build its pro.ling tools. In this paper, we introduce \nthe Javana in\u00adstrumentation language for building Java program pro.ling tools. The Javana instrumentation \nlanguage is inspired by the Aspect-Oriented Programming (AOP) paradigm because AOP matches the needs \nin instrumentation very well.     time quali.er := before | after params := location t const t* \nloc , type t const * type , void ** userdata object operation := create (params) | copy (params, params) \n| delete (params) object event := object:object operation memory operation := read (params) | write (params) \n| access (params) memory operation target := object | nonobject | any memory event := memory operation \ntarget:memory operation event := time quali.er memory event | object event {advice code} Figure 2. The \ngrammar of the Javana instrumentation language.     3.1 Aspect-Oriented Programming Aspect-oriented \nprogramming (AOP) [13] is best known in the con\u00ad text of high-level languages and software design methodologies, \nranging from UML [24] and AspectJ for Java [12] to AspectC++ for C++ [22] to TinyC2 for C [26]. The basic \nidea of aspect-oriented programming originally came from the observation that not all functionality in \na programming model can be cleanly separated into objects or modules. Some requirements crosscut entire \nclass hier\u00adarchies, multiple modules and complete programs. Aspect-oriented programming allows for specifying \na desired functionality that con\u00adcerns the whole program in a modular implementation. Logging an application \ns execution is one of the best known examples. Implementing a logging facility in a traditional manner \nwithout AOP requires that logging code is inserted all over the program. This is very time-consuming, \nerror-prone and hard to maintain from a software development point of view. AOP on the other hand allows \nfor extracting this logging facility into a separate module, that is then woven by a weaver with the \nrest of the program at compile time or even at run time. AOP thus signi.cantly improves software maintainability. \nIn general, an AOP language consists of joinpoints, pointcuts and .nally the advice. A joinpoint speci.es \nwhere and when one can interfere in the structure or execution of a program. This can range from source \ncode line numbers to syntactical constructions to even run time events. A pointcut is a collection of \njoinpoints. Typically, a symbolic name can be associated with a pointcut for later reference. Finally, \nthe advice is code that is associated with a pointcut. The advice will be executed whenever the conditions \nspeci.ed by the pointcut are ful.lled. The general idea of AOP languages of segregating crosscutting \nconcerns in separate modules is also very much applicable to the low-level instrumentation of programs \nat the machine code level. In fact, instrumenting a binary involves inserting additional code across \nthe entire program in order to measure a program metric of interest [4, 14, 15, 18, 23]. Since the instrumentation \nitself can be completely segregated from the original program, AOP is a natural way for specifying instrumentation \nroutines [19]. The Javana instrumentation language is inspired by the AOP concept. 3.2 The Javana instrumentation \nlanguage The Javana instrumentation language is a domain-speci.c language developed for the purpose of \ninstrumenting programs written in object-oriented languages such as Java. It combines support for rec\u00adognizing \nnative execution information along with high-level lan\u00adguage concepts such as objects, object types, \nmethods, lines of code, threads, etc. The grammar of the Javana instrumentation language is shown in \nFigure 2. A joinpoint that describes an event in the Javana instrumentation language consists of a time \nquali.er followed by a memory event or an object event, followed by the advice code. The time quali.er \nspeci.es when the event should be triggered. This can be before or after the event of interest. The events \nthat can be triggered are memory events or object events. For each of those, a struct mem_access_t { \n int ip; /* instruction pointer */ int addr; /* memory address being accessed*/ int size; /* number \nof bytes accessed */ int ld_st; /* load or store ? */ int thread_ID; /* thread ID */ } struct location_t \n{ struct mem_access_t *ma; /* pointer to mem_access_t structure */ int method_ID; /* method ID */ \n char* method_name; /* method s name */ int line_number; /* line number in given method */ } struct \ntype_t { int type_ID; /* object class ID */ char* type_name; /* object class name */ } Figure 3. Data \nstructures provided in the Javana instrumentation language. number of parameters are given. These parameters \ncan then be used by the advice code. The advice code is the instrumentation code in C inserted by the \nend user. Javana also comes with a translator for converting the Javana in\u00adstrumentation statements as \nspeci.ed in Figure 2 into C-statements while keeping the advice code (that is written in C) untouched. \nThe translated instrumentation speci.cation is then linked with DIOTA and the Jikes RVM for driving the \npro.ling run. We now discuss the object and memory events, the parameters that are provided with these \nevents and .nally the Javana direc\u00adtives. Example instrumentation speci.cations clarifying how to use \nthe Javana instrumentation language in practice will be given in section 5. 3.2.1 Object events An object \nevent consists of the keyword object followed by an object operation. The object operation can be the \ncreation (create), copying (copy) or deletion (delete) of an object. 3.2.2 Memory events A memory event \nconsists of memory operation target and the mem\u00adory operation itself. The memory operation target can \nbe an object, memory not belonging to an object or any of those. This allows the end user to focus the \ninstrumentation of memory accesses to objects only, non-objects only, or to both objects and non-objects. \nThe memory operation speci.es the type of memory access that should be instrumented. This allows the \nend user to focus on reads, writes or both. 3.2.3 Parameters The parameters that are provided by the \nJavana instrumentation language are shown in Figure 3. These parameters can be used in the advice code \nfor driving the instrumentation. The .rst pa\u00adrameter is a data structure that collects information concerning \nthe location of the object or memory event. This is done in the location t structure. The .rst element \nin this structure is a pointer to a mem access t structure. This latter structure con\u00adtains (i) the instruction \npointer of the native instruction performing the object or memory operation, (ii) the object s memory \nlocation or in case of a memory operation, the memory location being ac\u00adcessed, (iii) the size of the \nobject or in case of a memory operation, the number of bytes accessed in memory, (iv) whether this mem\u00adory \naccess is a load or store operation note this has no meaning in case of an object operation, and .nally \n(v) the thread ID of the thread performing the object or memory operation. The second and third element \nin the location t data structure are the method ID and the method name performing the object or memory \nopera\u00adtion, respectively. The fourth and .nal element is the source code line number in the given method \nthat corresponds to this object or memory operation. The second parameter in the parameter list is a \npointer to a data structure that speci.es information concerning the type of the object or memory operation. \nThis type t structure holds a type ID and a type name of the object or memory operation. This means that \nfor every object being created, copied, deleted or accessed, the Javana instrumentation language provides \nthe end user with information concerning the object s type. The third parameter in the parameter list \n(void **userdata) allows the end user to maintain object-speci.c information. The end user may for example \nset up a data structure for a given object; the pointer to this data structure can be stored through \nthis third parameter. The binary instrumentation tool then makes sure that this pointer is available \nfor all object and memory operations that refer to that same object. 3.2.4 Javana directives The Javana \ninstrumentation language also comes with a number of directives that can be speci.ed at the beginning \nof the instrumenta\u00adtion speci.cation .le. There are two directives in our current imple\u00admentation, namely \n#pragma requires method info and #pragma requires object info. The purpose of these directives is to \nimprove performance, i.e., to reduce the over\u00adhead of the vertical instrumentation. The #pragma requires \nmethod info directive informs the dynamic binary instrumenta\u00adtion tool that the method ID, the method \nname and source code line number should be kept track of during binary instrumentation. The #pragma requires \nobject info directive informs the dy\u00adnamic binary instrumentation tool that the object type ID and the \nobject type name should be kept track of. The user can decide not to include any of these two directives \nin the instrumentation speci.cation, to include only one of these, or to include both. This will affect \nthe amount of information that can be gathered during a pro.ling run as well as the amount of overhead \nexperienced during pro.ling. For example, if a user is in\u00adterested in measuring the cache miss rate per \nmethod and per source code line number, then there is no bene.t in collecting per-object information. \nThe user can then use the #pragma requires method info to disable tracking object-related information \ndur\u00ading the instrumentation run. This will limit the slowdown during vertical pro.ling.   4. Javana \nperformance This section quanti.es the slowdown of the Javana system. 4.1 Experimental setup In our evaluation \nof Javana s performance we use the SPECjvm98 benchmark suite, the SPECjbb2000 benchmark as well as the \nDa-Capo benchmarks, see Table 1. The SPECjvm98 benchmark suite1 is a client-side Java benchmark suite \nconsisting of seven bench\u00admarks. We run all SPECjvm98 benchmarks with the largest input set (-s100). \nSPECjbb20002 emulates the middle-tier of a three\u00adtier system; the pseudojbb variant of the SPECjbb2000 \nbench\u00admark that we use in our analysis runs for a .xed amount of work, i.e., for a .xed number of transactions, \nin contrast to SPECjbb2000 which runs for a .xed amount of time. The DaCapo benchmark suite3 is an open-source \nbenchmark suite designed for memory management research; we use release version beta050224. All of the \nSPECjvm98 benchmarks are run on the Jikes RVM using a 64MB heap and the generational mark-sweep (GenMS) \ngarbage collector; pseudojbb and the DaCapo benchmarks are run with a 500MB heap. Our measurements are \ndone on a 2.8GHz Intel Pen\u00adtium 4 system with a 512KB L2 cache and 1GB main memory. The operating system \non which we run our experiments is Gentoo Linux with a 2.6.10 kernel.       4.2 Javana overhead \nanalysis Running a Java application within Javana obviously introduces overhead. There are a number of \ncontributors to the overall over\u00adhead: First, the dynamic binary instrumentation tool that runs under\u00adneath \nthe virtual machine causes overhead.  Second, the event handling mechanism that communicates high-level \nlanguage concepts from the virtual machine to the dynamic binary instrumentation tool also causes overhead. \nIn addition, the event handler needs to process this information for updating the vertical map in the \ndynamic binary instrumenta\u00adtion tool.  Third, executing instrumented code requires that the binary in\u00adstrumentation \ntool searches the vertical map for every memory location accessed.  And .nally, executing the instrumentation \ncode itself as imple\u00admented by the end user of the Javana system also causes addi\u00adtional overhead.  \nWe will now quantify the overhead caused by each of these four overhead contributors. 4.2.1 Dynamic binary \ninstrumentation overhead We .rst quantify the overhead of the binary instrumentation (bullet one from \nabove). There are two contributors to this overhead. First, whenever a control transfer occurs to a computed \naddress, this address must be looked up in the binary instrumentation engine in order to transfer control \nto the corresponding instrumented code. The overhead that we observe for DIOTA in our Javana system ranges \nfrom 1.5X to 5.5X, see Figure 4. The second contributor is due to calling an instrumentation rou\u00adtine \nfor all natively executed memory operations. We quantify this overhead by calling a dummy (empty) function \nfor each memory operation. The overhead varies between a factor 12X and 53X de\u00adpending on the benchmark, \nsee Figure 4. This overhead is inherent to dynamic binary instrumentation. Other dynamic binary instru\u00admentation \ntools such as PIN [15] and Valgrind [18] show similar overheads.  4.2.2 Vertical instrumentation overhead \nWe now quantify the overhead caused by the event handling mech\u00adanism and by searching the vertical map \nfor every memory location 1 http://www.spec.org/jvm98/ 2 http://www.spec.org/jbb2000/ 3 http://www-ali.cs.umass.edu/DaCapo/gcbm.html \n Suite Benchmark Description SPECjvm98 jess db javac mpegaudio Solves a number of puzzles with varying \ndegrees of complexity Performs a set of database requests on a memory resident database Compiles a number \nof Java .les Decompresses MPEG I Layer 3 audio .les mtrt Renders a scene using ray tracing jack Parses \ngrammar .les and generates a parser for each SPECjbb2000 DaCapo pseudojbb hsqldb antlr fop jython ps \nxalan Emulates the middle tier of a three tier system Executes a number of transactions against a memory \nresident database Parses grammar .les and generates a parser and lexical analyzer for each of them Takes \nan XSL-FO .le, parses it and formats it, generating a PDF .le Interprets a series of Python programs \nReads and interprets a PostScript .le Transforms XML documents into HTML Figure 4. Slowdown due to dynamic \nbinary instrumentation. factor 2.8X and 4.4X, respectively. object info directives are set. The average \nvertical instrumentation overhead varies between a factor 2.8X and 5.5X depending on what information \nis to be kept track of. The third bar (searching the method and object trees) quanti.es the total overhead; \nand this causes an average slowdown of a factor 5.5X. However, using the Javana directives, see two leftmost \nbars searching method tree and searching object tree , signi.cant reductions in overhead are obtained. \nThe average slowdown for the vertical method and object instrumentation is a a very small part of the \ntotal vertical instrumentation overhead. Table 1. The benchmarks used in this paper. accessed (bullets \ntwo and three from above). We collectively refer to this overhead as vertical instrumentation overhead, \ni.e.,this is the overhead that enables cross-layer instrumentation. In our ex\u00ad periments we observed \nthat the event handling mechanism is only 50 40 30 20 10 0 9 8 7 6 5 4 3 2 1 0  4.2.3 Overall overhead \nFrom the above enumeration, it follows that the total slowdown of a Java program analysis tool built \nwithin Javana equals the product of the dynamic binary instrumentation slowdown, the vertical in\u00adstrumentation \nslowdown and the slowdown due to the user-de.ned instrumentation routines, i.e., the advice code included \nin the in\u00adstrumentation speci.cation. The total slowdown for the dynamic binary instrumentation and the \nvertical instrumentation varies between a factor 90X and 345X. This is the overhead caused by using Javana. \nThe additional overhead due to the instrumentation routines, increases the overall overhead to the 125X-850X \nrange; this is for the vertical cache simulation which is the most demanding vertical pro.ling tool that \nwe built with Javana. Figure 5 quanti.es the overhead from vertical instrumentation.  The .rst bar for \neach benchmark shows the overhead for the Ja\u00advana system during a vertical pro.ling run that only considers \nmethod-related information, i.e., the Javana directive #pragma requires method info was set in the instrumentation \nspeci.cation. This causes the method tree to be searched for every memory access; the object tree is \nnot searched.  The second bar measures the overhead when enabling vertical pro.ling for measuring object-related \ninformation. The Javana directive #pragma requires object info was set. In other words, the vertical \nobject tree is searched, but not the method tree.  The third bar quanti.es the overhead when both the \nmethod tree and the object tree are searched. Both the #pragma requires method info and #pragma requires \n overhead overhead compresscompress javacjavacjackjackdbdbmtrtmtrtjessjessmpegaudiompegaudiohsqldbhsqldbantlrantlrjythonjythonxalanxalanfopfopps \nps   Figure 5. Slowdown due to vertical instrumentation. According to our experience, this is an acceptable \nslowdown. Compared to simulation, Javana is fast; simulation typically causes a slowdown by at least \na factor 10,000X [2]. In cases where a 90X to 345X slowdown is undesirable, sampling can be employed \n1: before any:access (location_t const *loc, type_t const *type, void **userdata) { 2: printf (\"access \nby insn @ %p to memory location %p of size %d\\n\", loc->ma->ip, loc->ma->addr, loc->ma->size); 3: } \n Figure 6. Memory address tracing tool in Javana. to reduce this slowdown. However, this comes at the \nprice of lost accuracy; our measurements were done without applying any sampling.   5. Applications \nWe now discuss three example applications of the Javana system: memory address trace generation, vertical \ncache simulation and ob\u00adject lifetime computation. These applications demonstrate the real power of Javana: \nJavana provides an easy-to-use instrumentation environment that allows for quickly building customized \n(vertical) Java program analysis tools. The key bene.t is that easy-to-build program analysis tools increase \na software designer s productivity. And in addition, the results from pro.ling runs could yield invalu\u00adable \ninformation for optimizing the application. 5.1 Memory address trace generation Our .rst application \nis memory access tracing; the instrumentation speci.cation for building this pro.ling tool is shown in \nFigure 6. This pro.ling tool captures all memory accesses during program execution and writes to a .le \neach access instruction pointer, memory address and size. As can be seen from Figure 6, the Javana instrumentation \nlanguage only requires three lines of code for building this pro.ling tool. In other words, the expressiveness \nof the Javana language is high while the code itself is very intuitive. 60% 32KB 32-byte line L1 cache \nand an 8-way set-associative 1MB 128-byte line L2 cache. Both are write-back, write-allocate caches. \nThe cache simulation routines were taken from the SimpleScalar Tool Set [2]. We observe that only considering \nheap accesses re\u00ad sults in a severe overestimation of the actual cache miss rates. The difference in \nmiss rates varies by a factor 1.8 and 2.9 between track\u00ading heap accesses versus tracking all memory \naccesses. Therefore, we conclude that a methodology that analyzes heap accesses only in a memory performance \nstudy, is questionable.  5.2 Vertical cache simulation The second application relates cache miss rates \nto high-level con\u00adcepts such as methods, source code lines, objects and object types. This is invaluable \ninformation for software developers that are in the process of optimizing their code for memory performance. \nAs is well known, the memory-processor speed gap is an important issue in current computer systems. Poor \nmemory behavior can severely affect overall performance. As such, it is very important to opti\u00admize memory \nperformance as much as possible. Vertical pro.ling is a very valuable tool for hinting the software developer \nwhat to focus on when optimizing the application s memory behavior. Vertical cache simulation requires \nthat an instrumentation spec\u00adi.cation be written as shown in Figure 9. Lines 0 and 1 specify that the \ninstrumentation needs to keep track of both per-object and per\u00admethod information. Upon a memory access \nto an object (lines 2\u00ad6), the memory address is used by the cache simulator to update the cache s state. \nThe type-speci.c and method-speci.c data structures fraction heap accesses 50% maintained by the instrumentation \ntool are updated to keep track of the per-type and per-method miss rates. Other memory accesses, i.e., \nto non-objects (lines 7-10), update the cache s state and update 40% 30% the per-method miss rate information. \nThe per-type miss rate in\u00ad 20% formation is not updated because these memory references do not originate \nfrom object accesses. The instrumentation speci.cation for this pro.ling tool was no 10% compressjessdbjavac \nmpegaudiomtrtjackpseudojbbhsqldbantlrfopjythonpsxalan Figure 7. The fraction of all memory accesses that \nare heap ac\u00ad more than 200 lines of code, including comments. The output of the pro.ling run is a table \ndescribing cache miss rates per method, per line of code, per object and per object type. Selecting the \nper-method and per-object type cache miss rates and sorting them by decreasing number of L2 misses results \nin Tables 2 and 3. In both tables we limit the number of methods and object types to the top .ve per \nbenchmark in order not to cesses. Recent work done by Shuf et al. [21] analyzed the memory be\u00ad havior \nof Java applications. For doing so, Shuf et al. modi.ed the virtual machine to trace all accesses to \nthe heap, however, they did not trace accesses to the stack presumably because it is very dif.cult to \ntrack all memory accesses including stack accesses by instrumenting the virtual machine. Using Javana \nwe built a pro.l\u00ading tool that traces all heap memory accesses and all stack memory accesses. We found \nthat on average only 42% of all memory ac\u00adcesses are heap accesses, see Figure 7 which shows the fraction \nheap accesses compared to the total number of data memory ac\u00adcesses. In other words, Shuf et al. captured \nonly 42% of the total number of memory accesses on average. Consequently, not captur\u00ading the large fraction \nof non-heap accesses has a signi.cant impact on the overall memory system behavior. Figure 8 shows the \nfrac\u00ad tion L1 and L2 misses as a ratio to the total number of memory accesses. These results are for \na simulated 4-way set-associative overload the tables. The .rst column in each table mentions the method \nor object type, respectively. The second column shows the percentage of memory references of the given \nmethod or object type as a percentage of the total number of memory references. The two rightmost columns \nshow the number of L1 and L2 misses, respectively, along with the percentage local miss rates, i.e.,the \nnumber of misses divided by the number of accesses to the given cache level. Software developers can \nuse these tables to better understand the memory behavior of their software for guiding memory opti\u00admizations \nat the source code level. For example, from Table 2 it is apparent that the shell sort method in db is \na method that suf\u00adfers heavily from poor cache behavior. About 60% of the memory references in db occur \nwithin the shell sort method. Of these memory references, 10.5% result in an L1 cache miss, and 31.7% \nof the L2 cache accesses are cache misses. As such, this method is de.nitely a method of concern to a \nsoftware developer when opti\u00admizing the memory performance of db.  8% 3.0% 7% 6% 2.5%  L1 cache miss \nrate 5% 4% 3% 2% 2.0% 1.5% 1.0% 1% 0% compressjessdbjavac mpegaudiomtrtjackpseudojbbhsqldbantlrfopjythonpsxalan \ncompressjessdbjavac mpegaudiomtrtjackpseudojbbhsqldbantlrfopjythonpsxalan Figure 8. Cache miss rates \nusing Javana versus Shuf et al. s methodology: L1 data cache miss rates (number of L1 data cache misses \ndivided by the number of L1 data accesses) on the left and global L2 data cache miss rates (number of \nL2 data misses divided by the number of L1 data accesses) on the right. 0: #pragma requires object_info \n 1: #pragma requires method_info  2: before object:access (location_t const *loc, type_t const *type, \nvoid **userdata) { /* compute whether this object reference is a cache miss or not */ 3: hit = simulate_memory_access \n(loc->ma->addr, type->type_ID); /* update the per-type hit/miss information */ 4: update_per_type_miss_rate \n(type->type_ID, hit); 5: update_per_method_miss_rate (loc->method_name, loc->line_number); 6: }  7: \nbefore nonobject:access (location_t const *loc, type_t const *type, void **userdata) { /* update the \nsimulated cache content */ 8: simulate_memory_access (loc->ma->addr, -1);  9: update_per_method_miss_rate \n(loc->method_name, loc->line_number); 10: }  Figure 9. Vertical cache simulation tool in Javana. 0: \n#pragma requires object_info 1: typedef { 2: unsigned long long creation_time; 3: unsigned long long \nlast_access; 4: } object_info_t; 5: static unsigned long long timestamp = 0;  6: after object:create \n(location_t const *loc, type_t const *type, void **userdata) { 7: object_info_t ** const objectinfo \n= (object_info_t**)userdata; 8: (*objectinfo) = diota_malloc(sizeof(object_info_t)); 9: (*objectinfo)->creation_time \n= timestamp; 10: (*objectinfo)->last_access = 0; 11: }  12: before object:access (location_t const \n*loc, type_t const *type, void **userdata) { 13: object_info_t ** const objectinfo = (object_info_t**)userdata; \n 14: timestamp++; 15: (*objectinfo)->last_access = timestamp; 16: }  17: before nonobject:access (location_t \nconst *loc, type_t const *type, void **userdata) { 18: timestamp++; 19: }  Figure 10. Object lifetime \ncomputation tool in Javana. Method Accesses DL1 misses DL2 misses 201 compress  Compressor.compress()V \n42.7% 130906173 (7.8%) 533099 (0.4%) Decompressor.decompress()V 42.7% 21390490 (1.3%) 485995 (2%) Input \nBuffer.readbytes([BI)I 1.8% 247545 (0.3%) 55151 (18.4%) Compressor.output(I)V 4.5% 207706 (0.1%) 35700 \n(14%) Output Buffer.putbyte(B)V 0.9% 125551 (0.3%) 25169 (17.2%)     0.3% 188725 (3.2%) 46040 (16.9%) \n CompoundStatement.check(LEnvironment;LContext;JLjava/util/Hashtable;)J 0.1% 184186 (12%) 32186 (13.2%) \nExpression.<init>(IILType;)V 0.2% 138495 (2.8%) 29645 (15.1%) Instruction.<init>(IILjava/lang/Object;)V \n 0.1% 115000 (4.6%) 27981 (16.8%) CompoundStatement.code(LEnvironment;LContext;LAssembler;)V 0.1% 107313 \n(7.3%) 27416 (17.7%)   228 jack  TokenEngine.getNextTokenFromStream()LToken; 4% 214496 (0.5%) 8757 \n(3.3%) Token.<init>()V 0.1% 31771 (2.6%) 7689 (14.1%) JackConstants.printToken(LToken;Ljava/io/PrintStream;)V \n 0.2% 18382 (1%) 4564 (14.1%) TokenProcessor.action(LExpansion;)V 0% 5299 (2.5%) 2568 (32.7%) RunTimeNfaState.Move(CLjava/util/Vector;)I \n 4.5% 369592 (0.7%) 2168 (0.4%)    59.8% 132442434 (10.5%) 50720398 (31.6%) 3.5% 3413385 (4.6%) 1720280 \n(36%) Database.set index()V 6% 3924453 (3.1%) 1345881 (28.7%) Database.read db(Ljava/lang/String;)V \n 0.8% 36682 (0.2%) 9152 (13%) spec.io.FileInputStream.read()I 0% 5078 (0.7%) 3927 (60%)     227 \nmtrt  OctNode.FindTreeNode(LPoint;)LOctNode; 11.8% 27446406 (12.1%) 463179 (1.5%) PolyTypeObj.Intersect(LRay;LIntersectPt;)Z \n 3.9% 1718595 (2.3%) 184134 (9.9%) Vector.<init>(FFF)V 0.3% 715338 (13.7%) 177453 (22%) OctNode.Intersect(LRay;LPoint;F)LOctNode; \n 16.4% 1463021 (0.5%) 145254 (8.9%) Face.GetVert(I)LPoint; 14.3% 9920823 (3.6%) 113315 (1%)  jess.Node2.appendToken(Ljess/Token;Ljess/Token;)Ljess/Token; \n5.4% 6482818 (7.5%) 490280 (5.7%) jess.Value.<init>(DI)V 0.9% 786943 (5.3%) 176391 (16.5%) jess.RU.getAtom(I)Ljava/lang/String; \n2.1% 724295 (2.1%) 115008 (12%) jess.Node2.findInMemory(Ljess/TokenVector;Ljess/Token;)Ljess/Token; 1.7% \n3197035 (11.5%) 26021 (0.6%) jess.Value.<init>(II)V 0.1% 120645 (8.2%) 20881 (13.1%) hsqldb Column.createSQLString(Ljava/lang/Object;I)Ljava/lang/String; \n0.6% 490464 (3%) 353687 (44.4%) Table.getInsertStatement([Ljava/lang/Object;)Ljava/lang/String; 0.8% \n325886 (1.4%) 145450 (27.7%) Index.next(LNode;)LNode; 0.2% 152695 (3.3%) 141248 (53.8%) Expression.<init>(ILjava/lang/Object;)V \n0.2% 545316 (9.6%) 135686 (14.3%) Result.<init>()V 0% 142437 (10%) 35338 (14.3%) antlr collections.impl.BitSet.toArray()[I \n2.8% 678978 (1.2%) 168854 (13.6%) collections.impl.BitSet.orInPlace(Lcollections/impl/BitSet;)V 1.1% \n440776 (2%) 92577 (13%) Lookahead.<init>()V 0.1% 48837 (4.7%) 10240 (13.5%) AlternativeBlock.getAlternativeAt(I)LAlternative; \n0.3% 73447 (1.2%) 8135 (7.5%) LLkAnalyzer.look(ILAlternativeBlock;)LLookahead; 0.1% 76247 (4.4%) 7967 \n(7%) jython core.Py.newInteger(I)Lcore/PyInteger; 2.3% 3046300 (2.1%) 677551 (13.5%) pycode. pyx2.mmult$2(Lcore/PyFrame;)Lcore/PyObject; \n7.2% 2688617 (0.6%) 367581 (8.6%) core.PyObject. iadd (Lcore/PyObject;)Lcore/PyObject; 1.3% 1414629 (1.8%) \n348087 (16%) core.PyObject. add(Lcore/PyObject;)Lcore/PyObject; 1% 568570 (0.9%) 139698 (15.9%) core.PySequence. \nfinditem (I)Lcore/PyObject; 3.4% 470246 (0.2%) 114780 (14.1%) xalan utils.SuballocatedIntVector.addElement(I)V \n6.1% 1178740 (0.7%) 230876 (11.8%) utils.SuballocatedIntVector.elementAt(I)I 1.4% 648314 (1.7%) 79537 \n(10.2%) dtm.ref.DTMDefaultBase.indexNode(II)V 0.4% 77218 (0.7%) 11836 (9.3%) dtm.ref.DTMDefaultBase.findGTE([IIII)I \n1.4% 96575 (0.2%) 8676 (7.2%) serializer.WriterToUTF8Buffered.write([CII)V 0.1% 23178 (1.2%) 1307 (4.5%) \nfop  fo.flow.Block.layout(Llayout/Area;)I 0.1% 116716 (18.9%) 3900 (2.7%) layout.inline.InlineSpace.<init>(I)V \n0% 12918 (8.1%) 3297 (20.6%) fo.FOText.layout(Llayout/Area;)I 0% 60908 (18.3%) 3297 (4.4%) fo.expr.PropertyTokenizer.<init>(Ljava/lang/String;)V \n0% 14369 (6.5%) 3085 (15.4%) fo.PropertyList.get(Ljava/lang/String;ZZ)Lfo/Property; 0.6% 108845 (2.4%) \n2437 (1.8%) ps PSObject.DictionaryObject.getValueOf(LPSObject/PSObject;)LPSObject/PSObject; 10.4% 6274191 \n(1.5%) 247961 (2.8%) State.DictStack.getValueOf(LPSObject/PSObject;)LPSObject/PSObject; 1.2% 585068 (1.3%) \n78663 (9.7%) PSObject.PSObject.<init>()V 0.1% 126756 (5.1%) 12993 (7.9%) PSObject.ProcedureObject.execute()V \n0.5% 867436 (4%) 3130 (0.2%) State.PathPoint.<init>(DD)V 0% 22820 (6.4%) 3124 (9.9%)  202 jess   \n     Table 2. The top 5 methods for each of the benchmarks sorted by the number of L2 cache misses. \nType Accesses DL1 misses DL2 misses 201 compress  [B 20.6% 13001417 (1.6%) 1038857 (7.1%) [I 9.2% 100254792 \n(27.8%) 56465 (0%) [S 4.7% 41699357 (22.6%) 54699 (0.1%) [Ljava/lang/Object; 0.4% 4010 (0%) 406 (8.8%) \n[[I 0.1% 1632 (0%) 368 (19.6%)    213 javac  LInstruction;  1809398 (7.8%) 95228 (3.6%) LFieldExpression; \n 297830 (4.2%) 54787 (13.1%) LIdentifierExpression;  376774 (5.1%) 51935 (9.8%) LExpressionStatement; \n 0.1% 179932 (7.2%) 34840 (13.9%) LMethodExpression;  0.2% 195649 (3.8%) 30122 (11%)   228 jack \n LToken;  0.2% 96473 (3.6%) 19971 (12.3%) [I  4.1% 297878 (0.6%) 3900 (0.8%) [J  0.7% 18526 (0.2%) \n2600 (8.7%) Ljava/util/Hashtable;  1.2% 130877 (0.9%) 2389 (1.1%) Ljava/lang/String;  2.5% 23519 (0.1%) \n2384 (7%)   209 db  Ljava/util/Vector;  15.3% 36375367 (11.2%) 17288803 (38.8%) [Ljava/lang/Object; \n 7.2% 24118101 (15.7%) 11838596 (41.3%) [C  11.7% 22697725 (9.1%) 11598229 (42.4%) LEntry;  4.1% 28511936 \n(32.6%) 7941652 (22.7%) Ljava/lang/String;  13% 22717143 (8.3%) 4348649 (15.6%)   227 mtrt  LVector; \n 5.5% 3968361 (3.7%) 554763 (12.7%) LPoint;  10.6% 15020935 (7.4%) 358453 (2.1%) [LPoint;  3.5% 10720458 \n(16%) 114210 (1%) [I  4.7% 1055491 (1.2%) 97335 (8.4%) LFace;  3.3% 6796479 (10.7%) 82116 (1.1%)  \n[Ljess/ValueVector; 6.7% 5644607 (5.3%) 370383 (5%) Ljess/Value; 4.5% 3643209 (5.1%) 216290 (4.6%) Ljava/lang/Integer; \n0.5% 374152 (4.4%) 80287 (15.8%) Ljess/Token; 4.5% 5324507 (7.4%) 43438 (0.6%) [Ljess/Value; 6.2% 3964254 \n(4%) 13348 (0.3%) hsqldb Ljava/lang/Integer; 0.6% 443743 (2.5%) 353576 (47.9%) LMemoryNode; 0.8% 1098884 \n(5%) 174004 (10.8%) [Ljava/lang/Object; 2.5% 2085372 (2.9%) 147628 (5.1%) LExpression; 0.3% 685749 (9.3%) \n135919 (11.4%) LResult; 0% 142438 (23.7%) 35359 (14.3%) antlr [I 6.7% 2250997 (1.7%) 201101 (6.3%) [J \n3.7% 677296 (0.9%) 114003 (10.7%) [C 5.5% 95725 (0.1%) 13275 (9%) LLookahead; 0.2% 143657 (4.6%) 12755 \n(6%) LAlternative; 0.1% 137362 (6.3%) 10652 (5.2%) jython Lcore/PyInteger; 4.4% 8793859 (3.3%) 1424117 \n(9.9%) Lcore/PyList; 5.8% 254839 (0.1%) 22977 (6.4%) [Lcore/PyObject; 5% 3302410 (1.1%) 13465 (0.2%) \n[I 2.8% 81657 (0%) 7148 (6.1%) [Ljava/lang/Object; 8% 71723 (0%) 5139 (4.8%) xalan [I 22.3% 3588258 (0.6%) \n332505 (5.9%) [B 4.2% 506966 (0.4%) 2158 (0.3%) [[I 1.9% 350386 (0.7%) 1375 (0.3%) [Ljava/lang/Object; \n2.7% 447896 (0.6%) 1062 (0.1%) [[C 0.1% 36942 (1.2%) 1055 (1.7%) fop  [I 7.8% 902018 (1.5%) 9785 (0.9%) \nLfo/PropertyList; 1.2% 68644 (0.7%) 5392 (6.3%) [C 4.1% 88207 (0.3%) 5361 (4.4%) [Ljava/lang/Object; \n2.5% 752290 (3.7%) 5205 (0.6%) Llayout/inline/InlineSpace; 0% 25860 (11.2%) 3592 (9.9%) ps LExceptions/PSObjectException; \n0.1% 350039 (6.7%) 86914 (15.5%) LPSObject/realObject; 0.1% 150678 (7%) 9650 (4.2%) LState/PathPoint; \n0% 26141 (5%) 3162 (8.2%) Ljava/lang/String; 1.9% 2434633 (3.2%) 2492 (0.1%) LPSObject/NullObject; 0% \n7604 (12.4%) 1919 (18%)  202 jess        Table 3. The top 5 objects types for each of the benchmarks \nsorted by the number of L2 cache misses. Source code DL1 accesses DL1 misses DL2 accesses DL2 misses \n1 void shell sort(int fn) {2 int i, j, n, gap; 3 String s1, s2; 4 Entry e; 5 6 if (index == null) set \nindex(); 67 0(0%) 0 0(0%) 7 n = index.length; 134 1(0%) 1 0(0%) 8 9 for (gap = n/2; gap > 0; gap/=2) \n938 0(0%) 0 (0%) 10 for (i = gap; i < n; i++) 12276499 910 (0%) 1083 3(0%) 11 for (j = i-gap; j >=0; \nj-=gap) {12 s1 = (String)index[j].items.elementAt(fn); 23064743 157553557 8179 (0%) 29772665 (19%) 9615 \n36551726 33 (0%) 6095594 (17%) 13 s2 = (String)index[j+gap].items.elementAt(fn); 157553557 24036992 (15%) \n29456752 15581062 (53%) 14 15 if (s1.compareTo(s2) <= 0) break; 45015302 128 (0%) 153 1(0%) 16 17 e = \nindex[j]; 32322537 219 (0%) 228 0(0%) 18 index[j] = index[j+gap]; 75419253 2654 (0%) 3228 811 (25%) 19 \nindex[j+gap] = e; 43096716 0(0%) 0 0(0%) 20 }21 fnum = fn; 67 61 (91%) 73 61 (84%) 22 } Table 4. The \nshell sort method from db annotated with cache miss information. The number of L1 and L2 misses differ \nfrom the numbers given Table 2; the reason is that the numbers in this table were obtained using the \nbaseline compiler whereas the numbers in Table 2 were obtained using the adaptive compiler; the line \nnumbers returned by the adaptive compiler in Jikes are inaccurate. Table 3 shows per-object type miss \nrates for the various bench\u00ad 100% marks. The poor cache behavior for db seems to be apparent across 90% \na number of object types. For example, this table shows that the 80%  to tracking down miss rates to \nindividual objects. This would allow the software developer to isolate the source of the poor memory \nbe\u00ad havior. We do not include an example of per-object miss rates here in this paper, however, this could \nbe easily done in Javana. cumulative percentage 70% 60% 50% 40% 30% 20%  Because the shell sort method \nin db seems to suffer the 10% most from poor cache behavior, we focus on that method now. Table 4 shows \nthe shell sort method annotated with cache miss information, i.e., L1 and L2 cache miss rates are annotated \nto each line of source code. Line 13 seems to be the primary source for the high cache miss rate in the \nshell sort method. The reason is that the j+gap index results in a fairly random access pattern into \nthe 61KB index array. It s interesting to note that Hauswirth et al. [11] also identi.ed the shell sort \nmethod as a critical method for db.  5.3 Object lifetime Our third example application computes object \nlifetimes. In this application we de.ne the object lifetime as the number of memory accesses between \nthe creation and the last use of an object. Know\u00ading the allocation site and knowing where the object \nwas last used can help a programmer to rewrite the code in order to reduce the memory consumption of \nthe application or even improve overall performance [20]. Computing object lifetimes without Javana \nis fairly compli\u00adcated. First, the virtual machine needs to be extended in order to store the per-object \nlifetime information. Second, special care needs to be taken so that the computed lifetimes do not get \nper\u00adturbed by the instrumentation code. Finally, all object references need to be traced. This is far \nfrom trivial to implement. For ex\u00adample, referencing the object s header is required for accessing the \nType Information Block (TIB) or vertical lookup table (vtable) on a method call, for knowing the object \ns type, for knowing the ar\u00adray s length, etc. Also, accesses to objects in native methods need to be \ninstrumented manually. Implementing all of this in a virtual  0% 0 1 2 34 5 67 8 910 log2 (object lifetime) \nFigure 11. Cumulative object lifetime distribution for the SPECjvm98 benchmarks. machine is time consuming, \nerror-prone and will likely be incom\u00adplete. Measuring the object lifetime within Javana on the other \nhand is easy to do and in addition, it is accurate because it allows for tracking all references to a \ngiven object. In a Javana instrumenta\u00adtion speci.cation, an object s lifetime can be computed and stored \nusing the per-object void **userdata parameter that is avail\u00adable in Javana language, see section 3.2. \nAs such, computing object lifetimes is straightforward to do in Javana no more than 50 lines of code. \nThe skeleton of the instrumentation speci.cation is shown in Figure 10. Figure 11 shows the lifetime \ndistribution for the SPECjvm98 benchmarks computed using the Javana system. The horizontal axis on these \ngraphs is given on a log2 scale; the vertical axis shows the cumulative percentage objects in the given \nlifetime bucket. We observe that the object lifetimes are fairly small in general, i.e., most objects \nare short-lived objects. For most benchmarks, the object lifetime typically is smaller than 16 memory \naccesses between the creation of an object and its last use. Some benchmark have a relatively larger \nobject lifetime, see for example javac, compress and mpegaudio, however the object lifetime is still \n incorrect lifetime compressjavacjackdbmtrtjessmpegaudiohsqldbantlrjythonxalanfopps ties. However, Cachegrind \nis unable to vertically pro.le Java appli\u00adcations, nor is it capable of mapping cache miss rates to objects \nor object types. 6.2 Bytecode-level pro.ling A number of Java bytecode-level pro.ling tools have been \npre\u00adsented in the recent literature. These bytecode-level pro.ling tools differ from the Javana system \nin that Javana allows for building ver\u00adtical pro.ling tools, whereas bytecode-level pro.ling tools instru\u00adment \nthe intermediate bytecode level. We discuss two bytecode\u00adlevel pro.ling tools now. Dufour et al. [7] \nstudied the dynamic behavior of Java applica\u00ad tions in an architecture-independent way. To do so, they \nbuilt a tool called *J [8] that uses the Java Virtual Machine Pro.ling Interface (JVMPI) to collect a \nwide set of bytecode-level Java program char\u00adacteristics. The Java metrics that they collect are related \nto program size and structure, the occurrence of various data structures (such as arrays, pointers, etc.), \npolymorphism, memory usage, concurrency and synchronization. Figure 12. Evaluating the accuracy of object \nlifetime computa\u00ad tions without Javana: the percentage objects for which a non-Javana Dmitriev [5] presents \na Java bytecode-level pro.ling tool called instrumentation results in incorrect lifetime computations. \nvery small in absolute terms, i.e., the object lifetime is rarely more than 64 memory accesses. In order \nto evaluate the accuracy of object lifetime computa\u00adtions without Javana, we have set up the following \nexperiment. We JFluid. JFluid can be attached to a running Java application. The at\u00ad tached JFluid then \ninjects instrumentation bytecodes into the meth\u00adods of the running Java program. The instrumentation \nbytecodes collect pro.ling information online. When desired, JFluid can be detached from the running \napplication. 6.3 Vertically pro.ling Java applications Some very recent work focused on vertical pro.ling \nof Java appli\u00ad compute the object lifetimes under two scenarios. The .rst scenario computes the object \nlifetime when taking into account all memory accesses as done using out-of-the-box Javana. The second \nscenario computes the object lifetime while excluding all object accesses from non-Java code; this excludes \nall the object accesses from na\u00adtive JNI functions. This second scenario emulates current practice of \nbuilding an object lifetime measurement tool within the virtual machine, without Javana. The results \nare shown in Figure 12. The graph shows the percentage of objects for which an incorrect life\u00adtime is \ncomputed in current practice, i.e., when not including ac\u00adcesses to objects through JNI functions. We \nobserve large error percentages for a couple of benchmarks, namely fop (4%), antlr (6.5%) and ps (19%). \nAs such, we conclude that current practice of computing object lifetime without Javana can yield incorrect \nre\u00adsults, and this could be misleading when optimizing the code based on these measurements.  6. Related \nwork We now discuss related work. We .rst discuss binary instrumenta\u00adtion tools followed by bytecode-level \ninstrumentation approaches. Finally, we detail on existing vertical pro.ling approaches using hardware \nperformance counters. 6.1 Binary instrumentation tools A large body of work exists on instrumentation. \nA number of static instrumentation tools have been proposed such as ATOM [23], EEL [14] and FIT [4]. \nStatic instrumentation tools take a binary and store an instrumented version of the binary on disk. Executing \nthe instrumented binary then generates the desired pro.le information. Static instrumentation cannot \nbe used for analyzing Java applica\u00adtions because it cannot deal with dynamically generated code. Dynamic \ninstrumentation on the other hand does not have that limitation. Well known examples of dynamic binary \ninstrumenta\u00adtion frameworks are Valgrind [18], PIN [15] and DIOTA [16, 17]. One speci.c tool within \nValgrind s tool set is Cachegrind which is a cache pro.ler that provides limited vertical pro.ling capabili\u00adcations. \nThe purpose of these approaches is to link microprocessor performance to the Java application and the \nvirtual machine. How\u00adever, they do not allow for building customized vertical pro.ling tools. Hauswirth \net al. [11] and the earlier work by Sweeney et al. [25] presented a vertical pro.ling approach that correlates \nhardware per\u00adformance counter values to manually inserted software monitors in order to keep track of \nthe program s execution across all layers. The low-level and high-level information is collected at a \nfairly coarse granularity, i.e., hardware performance counter values and software monitor values are \nmeasured at every thread switch. Hauswirth et al. measure various hardware performance metrics during \nmulti\u00adple runs yielding multiple traces. And because of non-determinism during the execution, these traces \nsubsequently need to be aligned. Although being much faster than Javana, there are two important limitations \nwith this approach. First, aligning traces is challenging and caution is required in order not to get \nout of sync [10]. Second, the granularity is very coarse-grained one performance number per thread switch. \nThis allows for analyzing coarse-grained perfor\u00admance variations but does not allow for analyzing the \n.ne-grained performance issues we target. Georges et al. [9] also provided a limited form of vertical \npro\u00ad .ling by linking microprocessor-level metrics obtained from hard\u00adware performance counters to method-level \nphases in Java. This al\u00adlows for analyzing Java applications at a .ner granularity than the vertical \npro.ling approach by Hauswirth et al. [10, 11], however, the granularity is still much more coarse-grained \nthan the granular\u00adity that we can achieve using Javana. The commercially available tool VTune [6] from \nIntel also allows for pro.ling Java applications. The VTune tool samples hardware performance counters \nto pro.le an application and to annotate source code with cache miss rate information. However, given \nthe fact that VTune relies on sampling it is questionable whether this allows for .ne-grained pro.ling \ninformation with little overhead and perturbation of the results. All of these vertical pro.ling approaches \nrely on a micropro\u00adcessor s performance counters. This limits the scope of these tech\u00adniques to evaluating \nJava system performance on existing micro\u00adprocessors. These approaches do not allow for building customized \nvertical Java program analysis tools as the Javana system does.  7. Summary Understanding the behavior \nof Java application is non-trivial be\u00adcause of the tight entanglement of the application and the virtual \nmachine at the lowest machine-code level. This paper proposed Ja\u00advana, a system for quickly building \nJava program analysis tools. Ja\u00advana is publicly available at http://www.elis.ugent.be/ javana/. Javana \nruns a dynamic binary instrumentation tool un\u00adderneath a virtual machine. The virtual machine communicates \nwith the dynamic binary instrumentation tool using an event han\u00addling mechanism. This event handling \nmechanism enables the dy\u00adnamic binary instrumentation layer to build a so called vertical map. A vertical \nmap keeps track of correspondences between high\u00adlevel language concepts such as objects, methods, threads, \netc.,and low-level native instruction pointers and memory addresses. This vertical map provides the Javana \nend user with high-level informa\u00adtion concerning every memory access the dynamic binary instru\u00admentation \ntool intercepts. As a result, Javana is capable of tracking all memory references and all natively executed \ninstructions and to provide high-level information for each of those. Javana also comes with an easy-to-use \nJavana instrumentation language. The Javana language provides the Javana user with low\u00adlevel and high-level \ninformation that enables the Javana user to quickly build powerful Java program analysis tools that crosscut \nthe Java application, the VM and the native execution layer. The .rst key property of Javana is that \nJava program analysis tools can be built very quickly. To demonstrate the real power of Javana we presented \nthree example applications: memory address tracing, vertical cache simulation and object lifetime computation. \nFor each of these applications, the core instrumentation speci.ca\u00adtion was only a few lines of code. \nThe second key property of Javana is that the pro.ling results are guaranteed to be highly accurate (by \nconstruction) because the dynamic binary instrumentation layer tracks every single natively executed \ninstruction. Current practice is typically one of manually instrumenting the virtual machine which is \nboth time-consuming and error-prone. In addition, the accuracy of the pro.ling results might be questionable \nbecause it is hard to instrument a virtual machine in such a way that all memory accesses are tracked, \nas we have shown through our example applications. 8. Acknowledgments The authors would like to thank \nthe anonymous reviewers for their valuable comments, as well as Hans Vandierendonck for integrat\u00ading \nthe SimpleScalar cache simulator into our Javana instrumenta\u00adtion speci.cation. Jonas Maebe and Dries \nBuytaert are supported by a grant from the Institute for the Promotion of Innovation by Science and Technology \nin Flanders (IWT). Lieven Eeckhout is a Postdoctoral Fellow of the Fund for Scienti.c Research Flanders \n(Belgium) (FWO Vlaanderen). This research is also supported in part by Ghent University, the HiPEAC Network \nof Excellence and the European SARC project No. 27648.  References [1] B. Alpern, C. R. Attanasio, \nJ. J. Barton, M. G. Burke, P. Cheng, J.-D. Choi, A. Cocchi, S. J. Fink, D. Grove, M. Hind, S. F. Hummel, \nD. Lieber, V. Litvinov, M. F. Mergen, T. Ngo, J. R. Russell, V. Sarkar, M.J.Serrano, J. C. Shepherd, \nS.E.Smith,V. C.Sreedhar, H. Srinivasan, and J. Whaley. The Jalape no Virtual Machine. IBM Systems Journal, \n39(1):211 238, 2000. [2] D. C. Burger and T. M. Austin. The SimpleScalar Tool Set. Computer Architecture \nNews, 1997. See also http://www.simplescalar .com for more information. [3] J.-D. Choi, B. Alpern, T. \nNgo, M. Sridharan, and J. Vlissides. A perturbation-free replay platform for cross-optimized multithreaded \napplications. In Proceedings of the 15th International Parallel and Distributed Processing Symposium \n(IPDPS), Apr. 2001. [4] B. De Bus, D. Chanet, B. De Sutter, L. Van Put, and K. De Bosschere. The design \nand implementation of FIT: A .exible instrumentation toolkit. In Proceedings of the ACM-SIGPLAN-SIGSOFT \nWorkshop on Program Analysis for Software Tools and Engineering (PASTE), pages 29 34, June 2004. [5] \nM. Dmitriev. Selective pro.ling of Java applications using dynamic bytecode instrumentation. In Proceedings \nof the 2004 IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS), pages \n141 150, Mar. 2004. [6] J. Donnell. Java Performance Pro.ling using the VTune Performance Analyzer. Intel, \n2004. [7] B. Dufour, K. Driesen, L. Hendren, and C. Verbrugge. Dynamic metrics for Java. In Proceedings \nof the 18th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Languages, Applica\u00adtions and \nSystems (OOPSLA), pages 149 168, Oct. 2003. [8] B. Dufour, L. Hendren, and C. Verbrugge. *J: A tool for \ndynamic analysis of Java programs. In Companion of the 18th Annual ACM SIGPLAN Conference on Object-Oriented \nProgramming, Languages, Applications and Systems (OOPSLA), pages 306 307, Oct. 2003. [9] A. Georges, \nD. Buytaert, L. Eeckhout, and K. De Bosschere. Method-level phase behavior in Java workloads. In Proceedings \nof the 19th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems and Languages (OOPSLA), \npages 270 287, Oct. 2004. [10] M. Hauswirth, A. Diwan, P. S. Sweeney, and M. C. Mozer. Automating vertical \npro.ling. In Proceedings of the 20th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems \nand Languages (OOPSLA), pages 281 296, Oct. 2005. [11] M. Hauswirth, P. S. Sweeney, A. Diwan, and M. \nHind. Vertical pro.ling: Understanding the behavior of object-oriented applications. In Proceedings of \nthe 19th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems and Languages (OOPSLA), \npages 251 269, Oct. 2004. [12] G. Kiczales, E. Hilsdale, J. Hugunin, M. Kersten, J. Palm, and W. G. Griswold. \nAn overview of AspectJ. Proceedings of the 15th European Conference on Object-Oriented Programming (ECOOP), \npages 327 355, June 2001. [13] G. Kiczales, J. Lamping, A. Menhdhekar, C. Maeda, C. Lopes, J.-M. Loingtier, \nand J. Irwin. Aspect-oriented programming. In Proceedings of the European Conference on Object-Oriented \nProgramming (ECOOP), pages 220 242, 1997. [14] J. R. Larus and E. Schnarr. EEL: Machine-independent executable \nediting. In Proceedings of the ACM SIGPLAN International Conference on Programming Language Design and \nImplementation (PLDI), pages 291 300, 1995. [15] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. \nLowney, S. Wallace, V. J. Reddi, and K. Hazelwood. Pin: building customized program analysis tools with \ndynamic instrumentation. In Proceedings of the ACM SIGPLAN International Conference on Programming Language \nDesign and Implementation (PLDI), pages 190 200, June 2005. [16] J. Maebe and K. De Bosschere. Instrumenting \nself-modifying code. In Proceedings of the Fifth International Workshop on Automated Debugging (AADEBUG), \npages 103 113, Sept. 2003. [17] J. Maebe, M. Ronsse, and K. De Bosschere. DIOTA: Dynamic instrumentation, \noptimization and transformation of applications. In Proceedings of the 2002 Workshop on Binary Translation \n(WBT) held in conjunction with the International Conference on Parallel Architectures and Compilation \nTechniques (PACT), Sept. 2002. [18] N. Nethercote and J. Seward. Valgrind: A program supervision framework. \nIn Electronic Notes in Theoretical Computer Science, volume 89. Elsevier, 2003. [19] S. Reiss and M. \nRenieris. Languages for dynamic instrumentation. In Proceedings of the Workshop on Dynamic Analysis (WODA),May \n2003. [20] R. Shaham, E. K. Kolodner, and M. Sagiv. Heap pro.ling for space\u00adef.cient Java. In Proceedings \nof the ACM SIGPLAN International Conference on Programming Language Design and Implementation (PLDI), \npages 104 113, 2001. [21] Y. Shuf, M. J. Serrano, M. Gupta, and J. P. Singh. Characterizing the memory \nbehavior of Java workloads: a structured view and opportunities for optimizations. In Proceedings of \nthe 2001 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems, pages \n194 205, June 2001. [22] O. Spinczyk, A. Gal, and W. Schr\u00a8oder-Preikschat. AspectC++: an aspect-oriented \nextension to the C++ programming language. In CRPITS 02: Proceedings of the Fortieth International Conference \non Tools Paci.c, pages 53 60, 2002. [23] A. Srivastava and A. Eustace. ATOM: A system for building customized \nprogram analysis tools. Technical Report 94/2, Western Research Lab, Compaq, Mar. 1994. [24] J. Suzuki \nand Y. Yamamoto. Extending UML with aspects: Aspect support in the design phase. In Proceedings of the \nWorkshop on Object-Oriented Technology, pages 299 300, 1999. [25] P. Sweeney, M. Hauswirth, B. Cahoon, \nP. Cheng, A. Diwan, D. Grove, and M. H. d. Using hardware performance monitors to understand the behavior \nof Java applications. In Proceedings of the 3rd Virtual Machine Research and Technology Symposium (VM), \npages 57 72, May 2004. [26] C. Zhang and H.-A. Jacobsen. TinyC2: Towards building a dynamic weaving aspect \nlanguage for C. In Proceedings of the Foundations of Aspect-Oriented Languages Workshop at AOSD 2003, \nMar. 2003. \n\t\t\t", "proc_id": "1167473", "abstract": "Understanding the behavior of applications running on high-level language virtual machines, as is the case in Java, is non-trivial because of the tight entanglement at the lowest execution level between the application and the virtual machine. This paper proposes Javana, a system for building Java program analysis tools. Javana provides an easy-to-use instrumentation infrastructure that allows for building customized profiling tools very quickly.Javana runs a dynamic binary instrumentation tool underneath the virtual machine. The virtual machine communicates with the instrumentation layer through an event handling mechanism for building a vertical map that links low-level native instruction pointers and memory addresses to high-level language concepts such as objects, methods, threads, lines of code, <i>etc.</i> The dynamic binary instrumentation tool then intercepts all memory accesses and instructions executed and provides the Javana end user with high-level language information for all memory accesses and natively executed instructions.We demonstrate the power of Javana through a number of applications: memory address tracing, vertical cache simulation and object lifetime computation. For each of these applications, the instrumentation specification requires only a small number of lines of code. Developing similarly powerful profiling tools within a virtual machine (as done in current practice) is both time-consuming and error-prone; in addition, the accuracy of the obtained profiling results might be questionable as we show in this paper.", "authors": [{"name": "Jonas Maebe", "author_profile_id": "81319496603", "affiliation": "ELIS, Ghent University, Belgium", "person_id": "P813672", "email_address": "", "orcid_id": ""}, {"name": "Dries Buytaert", "author_profile_id": "81100468396", "affiliation": "ELIS, Ghent University, Belgium", "person_id": "P698113", "email_address": "", "orcid_id": ""}, {"name": "Lieven Eeckhout", "author_profile_id": "81330490198", "affiliation": "ELIS, Ghent University, Belgium", "person_id": "PP45025842", "email_address": "", "orcid_id": ""}, {"name": "Koen De Bosschere", "author_profile_id": "81100123309", "affiliation": "ELIS, Ghent University, Belgium", "person_id": "PP14054039", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167487", "year": "2006", "article_id": "1167487", "conference": "OOPSLA", "title": "Javana: a system for building customized Java program analysis tools", "url": "http://dl.acm.org/citation.cfm?id=1167487"}