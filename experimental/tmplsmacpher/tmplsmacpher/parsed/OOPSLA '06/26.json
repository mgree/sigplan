{"article_publication_date": "10-16-2006", "fulltext": "\n Conscientious Software Richard P. Gabriel Sun Microsystems Laboratories Menlo Park, California, USA \nrpg@dreamsongs.com Abstract Software needs to grow up and become responsible for itself and its own future \nby participating in its own installation and customization, maintaining its own health, and adapting \nitself to new circumstances, new users, and new uses. To create such software will require us to change \nsome of our underlying as\u00adsumptions about how we write programs. A promising approach seems to be to \nseparate software that does the work (allopoietic) from software that keeps the system alive (autopoietic). \nCategories and Subject Descriptors D.2.5. [Software Engineer\u00ading] Testing and Debugging Error handling \nand recovery; D.2.11. [Software Engineering] Software Architectures; D.3.0. [Program\u00adming Languages] \nGeneral; H.1.2. [Models and Principles] User/ Machine Systems Human factors General Terms Design, Human \nFactors, Languages, Reliability Keywords Robustness, software, self-sustaining systems, emer\u00adgence, autopoiesis, \nstigmergy, continuous (re)design, self-testing, feedback, software complexity, repair 1. Introduction \nS oftware systems today are produced according to a manufac\u00adturing model: A .nished product is constructed \nat the factory and shipped to its .nal destination where it is expected to act like any other machine \nreliable but oblivious to its surround\u00adings and its own welfare. Responsibility for testing and devising \nhow to install the software rests with the development team. Once deployed, software is on its own, along \nwith the people who must use it. The result of this way of doing development has been brittle, buggy \nsoftware where the only recourse for end-users is to hope the next release will .x the problems (and \nnot add too many new ones). We believe that software needs to grow up and become re\u00adsponsible for itself \nand its own future. Moreover, the people us\u00ading the software every day must be able to shape and customize \nit without reliance on the software s original developers. In this paper we will argue that future innovations \nin software will need to produce systems that actively monitor their own activity and their environment, \nthat continually perform self-testing, that catch errors and automatically recover from them, that automati\u00adcally \ncon.gure themselves during installation, that participate in their own development and customization, \nand that protect Copyright is held by Sun Microsystems, Inc. OOPSLA 06 October 22 26, 2006, Portland, \nOregon, USA. ACM 1-59593-348-4/06/0010. Ron Goldman Sun Microsystems Laboratories Menlo Park, California, \nUSA ron.goldman@sun.com themselves from damage when patches and updates are installed. Such software \nsystems will be self-contained, including within themselves their entire source code, code for testing, \nand any\u00adthing else needed for their evolution. Furthermore, we need to make the state of each component \nmore visible and make our components interact more richly &#38; more fully. We need to use softer, more \ndynamic architectures that support adding or replacing modules after deployment (e.g. plug-ins, dynamic \nloading of classes) and architectures where objects can be repaired in situ, methods changed / added, \ninter\u00adnal state restructured, and object hierarchies rewired). We also need new types of languages to \ndescribe the architecture of our systems. We will not program in these new languages they probably won \nt have arithmetic operators, data structures, or low\u00adlevel control statements but instead express things \nlike when to create and kill components, where components are run, when to run tests, and which components \ninteract with each other. As our software becomes ever more interdependent, with appli\u00adcations relying \non (remote) services developed by other organiza\u00adtions, it also must paradoxically become more independent, \nable to maintain its integrity in a changing environment. Interfaces between components need to become \nless brittle and more ac\u00adcommodating not requiring an exact match like a key in a lock, but based more \non pattern recognition such as phenotropics [20]. We also need to better isolate components from each \nother in biology this is referred to as spatial compartmentalization [19], for computing it may translate \ninto components not sharing common memory or other resources. Recent applications are beginning to exhibit \nthese proper\u00adties and this trend will increase, re.ecting the need for software systems to change continuously \nover their lifetimes. Many of the ideas we present in this paper are based on the changes we see occurring \nin current software. We use the term conscientious software to describe code that takes responsibility \nfor itself and its future. The following is our vision for the future. 2. Software Complexity Over the \nlast forty years we have attempted to create ever more ambitious systems, but their complexity often \nexceeds our abili\u00adties as witnessed by how brittle most software is and how many software projects fail. \nWhile our current methods have many good characteristics they do not successfully address the complexity \nof modern software systems. We need to adopt new principles and approaches if we are to progress. Software \ncomplexity arises in large part from the inherent complexity of the problems we are trying to solve. \nWe lack good models to describe the organization of complex systems. We know how to decompose large \nproblems into smaller ones, but we are not so good at describing the interactions among subcomponents. \nFor example, we do not have a good vocabulary to discuss multiple feedback loops and the emergent behavior \nthey can generate. We also have trouble when different aspects of a problem re\u00ad quire fundamentally different \ndecompositions. For example, when designing a spacecraft control system there is a natural decom\u00ad position \ninto subsystems and devices. However when dealing with the limited power budget or the attitude control \nsystem, there are a tangle of special-case subsystem-to-subsystem couplings behind a fa\u00e7ade of modular \ndecomposition [7] consider that spinning up a disk drive consumes power, generates heat, and acts as \na gyroscope. This interaction of concerns goes beyond the idea of separation of concerns that aspect-oriented \nprogramming (AOP) tries to address. The sheer complexity of the problem and its solution makes it practically \nimpossible to capture such interactions in a static speci.cation. The experience at Tandem Computers \nof trying to create reliable systems found that many failures were due to faults in the speci.cations. \nSpeci.cations are always incomplete and often just plain wrong moreover requirements are always changing. \nMethodologies with an incremental approach of con\u00ad tinuous (re)design are a better match to changing \nspeci.cations. Related to this is the realization that errors are unavoidable, due to bugs in the implementation \nand also from unexpected inputs from the environment, so we must design our systems to continu\u00ad ally \nrun tests and repair errors. Going from problem requirements to system design creates an explosion of \nderived requirements (the requirements for a particular design solution); the list of implicit requirements \ncan be 50 times greater than the original problem-focused require\u00ad ments. [11] Lots of details need \nto be .lled in when translating what to do (describing the problem to be solved) into how to do (describing \nhow the problem is to be solved). This includes translating the problem into computer terms, specifying \nrequired components, and even mapping the work to the organization of the people developing the solution. \nAgain we lack good models and higher-level abstractions to talk about complex, interacting processes. \nAnother major source of complexity is unplanned interactions between components cross-talk where bugs \nor changes in one piece of code affect quite distant, seemingly unrelated pieces of code. These implementation \ncombinatorics make it impossible to thoroughly test software: Even 100% test coverage cannot ac\u00ad count \nfor code interactions, e.g. an error manifests only when a particular combination of logic paths is executed. \nAnd beyond the lowest level of unplanned direct interactions there are the unplanned indirect ones. Examples \nwould be feedback loops cre\u00ad ated which cause new and complex behavior to emerge. Another would be system-wide \ninteractions which could cause oscilla\u00ad tions (again this involves feedback) sometimes via unplanned \nand unthought-of shared paths like indirectly shared resources. Lastly would be emergent behavior resulting \nfrom new interac\u00ad tion patterns. Hardware is generally more robust because it is more modular (and less \nstate dependent). Where it relies on history / state information hardware too is subject to bugs (e.g. \nthe Pentium math bug [28] in which the results of the division algorithm depend on intermediate partial \nresults and the path taken through a faulty lookup table). As if our problems with current systems were \nnot enough, even bigger systems are on the drawing board. Plans for ultra-large\u00adscale (ULS) systems consisting \nof billions of lines of code spread over thousands of widely distributed multi-cpu computers are now \nbeing proposed. These systems must run continuously, even as individual components / computers come and \ngo. In order to create such systems we need new approaches to how we design software. [35] 3. Continuous \n(Re)Design The practice of continuous (re)design will move from the factory to the .eld and large lump \ndevelopment will fade away. Develop\u00adment strategies have changed over time as it s become clear that \nit s not possible to get static requirements right the .rst time around. From heavy design-before-coding \nmethodologies to agile, people have tried to capture via processes the elusive nature of getting things \nright. The trend has been toward entangled inter\u00adactions with end-users and customers in order to .nd \nout what the software needs to do and how it is most congenially used. However, the watchword is still \ngetting things right. But because requirements are static doesn t mean that soft\u00adware viewed over time \nstands still. Programs evolve and change, but only through a development process back at the factory. \nBug reports, comments, suggestions and requirements determined by a marketing group, bright ideas, and \nnew technology combined with a development group produce the next version of the soft\u00adware. Static requirements \nchange over time, and in this narrow sense, it s possible to view software as a living entity adaptable, \n.exible, malleable, resistant to failure. But not self-sustaining. Design is less a result of pre hoc \nplanning than of slowly dawn\u00ading insights insights derived from seeing how the thing turns out and is \nused. Continuous (re)design will move out into the .eld because the .eld is where the observations are \nimmediate and changes can be tested rapidly in situ. Already some programs offer personalization and \ncustomiza\u00adtion allowing users to participate in the design of the software. Some basic looks, feels, \nand behaviors can be changed by tailor\u00ading menus, adding keyboard shortcuts, and de.ning macros and scripts \nthat add behavior and provide workarounds. Many of the options are available through a mechanism called \npreferences, which is a set of attributes whose values can be set, such as colors, .eld placement, and \nthe like. Preferences are like wall coverings and color, window treatments, artwork, and, to a degree, \nfurnish\u00adings. (Furnishings are perhaps more like plug-ins.) 4. Soft/Dynamic Architectures With the advent \nof softer / more dynamic architectures, change to programs will be welcome, even encouraged. Today, software \ndevelopment is a process of building static artifacts static mean\u00ading the program will not change once \ndelivered, remaining in.ex\u00adible or subject only to foreseen adaptations. A good metaphor is a highway. \nConstructing a highway takes a lot of effort including expensive and disruptive land purchases. Once \nthe dimensions and course of a highway are set, they are stable and static until a major change is made. \nWord processors are near the extreme of such static programs: useful for writing and revising documents \nwith a wide variety of styles both visual and artistic, but its own future on a writer s computer is \nrigid nothing changes.  Figure 1: Soft Architecture Not all software is totally static, and such programs \nbegin to point the way to change. Plug-in architectures and web-ser\u00ad vice-based applications can be changed \nonce installed by add\u00ad ing modules that provide services based on de.ned protocols and interfaces. Adobe \nPhotoshop is the classic example; and browsers, integrated development environments, and operating systems \nare built this way. Here the good metaphor is a house, which is also (usually) carefully planned (by \nan architect), but which can be and frequently is customized by its occupants in both small and large \nways. Stewart Brand looks at buildings as having six layers: the physi\u00ad cal site, the load-bearing structure, \nthe exterior surfaces, the guts of services like wiring and plumbing, the interior layout, and the stuff \nin the building like desks and phones. The timescale and effort needed to make a change varies across \nthese layers; site is eternal, while stuff can easily be changed daily. [3] Our com\u00ad puter systems also \nconsist of layers: programming languages are at the bottom,1 then hardware, operating system, libraries, \nand applications. Applications generally consist of one or more levels of compiled code (e.g. a framework \nand application logic) with a few preference settings so that the user can modify the look and feel. \nOn top of that is the layer of the user data, corresponding to Brand s stuff in the building though \nin many applications the desks are bolted to the .oor. When thinking of software architecture, you probably \nare imagining an architecture diagram made of bubbles with lines between them perhaps a framework (a \nbig bubble maybe) with components (the little ones) where the lines mean communica\u00ad tion through a small \npipe, like an interface. This is what we have today. But what would it be like to imagine a diagram like \nthis where two components (red star and blue ellipse) have melded with the framework (orange blob)? [Figure \n1] Some applications, such as spreadsheets, enable their users to collaborate by adding new macros and \nsharing templates. Not everyone can write macros, but one or two tinkerers in a company can make extensions \nto the spreadsheet primitives that others 1 Brand s layers correspond to permanence. For software, changing \nto a programming language with semantics not like Fortran, C, or Java would (rationally) require a new \nhardware platform. In fact, hardware (even in\u00adstruction sets) has changed more than the basic semantic \nstructures of our programming languages, and so the languages form the most basic layer for us. Sometimes \nthe stack is drawn as an hourglass with hardware at the bottom, programming languages at the narrow waist, \nand applica\u00adtions at the top. This emphasizes how applications are decoupled from the hardware through \nthe use of a standardized programming language. can then easily use in their formulas. [26] An architecture \nthat supports scripting or a macro language adds another layer that enables users to modify an application \ns behavior without needing to send it back to the factory for the professional programmers to rework. \nIf such an architecture also supports adding plug-in modules then that opens the door for the do-it-yourself \nuser to really customize the application to his or her local needs. Beyond such softnesses are software \narchitectures that make changes to themselves over time: dynamic adjustments to both state and behavior \nas the stuff (components / architecture) adapts to the environment in which it .nds itself. We can imagine \nob\u00adjects augmenting themselves, changing their algorithms, evolv\u00ading through competition,2 and rewiring \ntheir relationships as they evolve. 5. In(ter)dependent Software Software will be constructed from components \nthat want to form a community. Systems will be components either within the same address space or not \nthat interact as needed, even suppos\u00adedly / originally monolithic systems. This will enable us to treat \nevery system as if it were a distributed system, which might mean that systems can be more robust to \nsingle-point failures. Components will be constructed to minimize or ameliorate version differences and \ncalling convention mismatches. Today, strange as it seems, components are written such as dynamic link \nlibraries (DLLs) with in.exible interfaces so that slight mismatches halt reasonable operation of a system. \nThe result is almost as if the designers of the components (or more properly, the overall OS-level system \narchitecture) were more interested in their code and designs punishing simple mistakes rather than trying \nto make that code work around those mistakes to get something running. An approach like Lanier s phenotropics \ncould help. Phenotropic computing uses surfaces for interfaces rather than direct argu\u00adment-based / protocol-based \ninterfaces. Each component has a surface on which is displayed information about what it is doing and \nthat it would like to communicate to another component (or other components). Two components interacting \nobserve each other s surfaces and react to what they see or sample. Approximation replaces perfection, \nand the result can be more accommodating but perhaps less optimized behavior. This is in contrast to \nour current use of rigid, minimalistic APIs where one 2 Digital software evolution agent essentially \nreaches inside another and commands it to do some function (i.e. a remote procedure call). Instead the \n.rst agent would present a request that the second could interpret and deal with as best it can. Other \nagents might also choose to participate by transforming / translating the original request, forwarding \nthe request to an appropriate agent, or working on it themselves. The agent making the request need not \neven know which agent(s) will eventually handle it. 6. Self-Installation Software in the future will \ntake an active role in its own instal\u00adlation. At present, many programs are considered properly in\u00adstalled \nonce the correct bits are in the right locations. And even this problem is not as well addressed as it \ncould be: There are numerous interdependencies that go into proper installation. In recent years with \nsoftware updates the installation scripts have become more sophisticated, but when more permanent layers \n(in the Brand sense) are installed, the process can require extensive human in(ter)vention. In fact, \nthe outermost (appli\u00adcationmost) layers are the places where installation has become easier for the installer. \nIgnored as part of installation are the sometimes dozens of ad\u00adjustments people make to the entire set \nof installed programs to make the computing / digital nest comfortable (again).3 First are the obvious, \nsuch as: Although there are a handful of commands for moving through text, the gestures a person likes \nfor various of them though knowable are never addressed. If it s even possible to make a program that \nmanipulates text use Emacs4 command gestures, why should a person have to .gure out how to program / \ncustomize / personalize the software? Gestures are just part of it. The look and feel should be adaptable \ntoo. As stylesheets for application look and feel become more prevalent, these can form the basis for \nadapting to a preferred use scheme. Each program should endeavor to discover such customiza\u00adtions. Further, \nit should be possible for one person to transfer his or her customizations to someone else who could \nthen apply some or all of them either temporarily or permanently. In the same vein, other aspects of \nthe preferred use of software can be deduced and accommodated. For example, when installing a web browser, \nthe browser can notice that one of its potential users is also an ardent user of Adobe products and to \ncon.gure the browser to use Acrobat s PDF browser plug-in instead of some other one. The overall user \ncolor scheme can be intelligently guessed at and compatible colors can be chosen. A program that manipulates \ntext can try to determine how spellchecking is done around here.5 For example, I (one of the authors), \nlike many in my generation, like to use Emacs for manipulating text. Many programs manipulate text. I \nam not particularly interested in the next person s bright idea of how to do it (unless it is a fabulous \nidea), so why can t I use not only the style I like (Emacs commands as mentioned before), but the very \nsame Emacs in every situation, which I may have customized beyond recognition? 3 And this is the problem \nof (re)installing inner, permanent layers. 4 Emacs is a text editor widely used by programmers. It is \nhighly custom\u00adizable but has a distinct set of default key bindings. 5 At one extreme this can be taken \nas an example of the idea of common modules, typically selected by the user for some speci.c advantage. \nAnother approach, of course, is a systemwide preference mech\u00adanism where speci.c preferences would be \nlooked up in a hierar\u00adchical structure. This is the standardization approach. Although this would work \n.ne were it to happen, the realistic likelihood of that is low. To get the majority of operating system \n/ application writers to use such a system would require a mandated standard, which is unlikely for user \nexperience. Moreover, for a long time there will be a signi.cant population of legacy code that will \nnot use the standard. And then there are the renegades. Moreover, there is a real question about whether \nand when standardization is the right solution to a problem. Standardiza\u00adtion requires universal adoption, \nand, when achieved, tends to promote in.exibility. And once standardization is taken as the key, it is \ntypically taken too far, so that we end up, for example, with a monoculture. Better, we think, is ad \nhoc and independent .exibility, recog\u00adnizing that multiple standards / dialects will always exist, each \nof which will change over time. 7. Continual Installation In our vision, the installation process never \nends: As new software and hardware are installed, already installed software should continue the installation \nprocess, learning how the interests and habits of its users are changing over time. What it learns not \nthe personal things like where its users surf and the kinds of books and videos he or she prefers can \nbe sent back to the sleepy de\u00advelopers back at the plant who can move their agile .ngers into gear to \nkeep progress happening. Later or someday, this knowl\u00adedge can be used to self-adapt the software. Related \nto installation is the massive upgrade: buying that new heavy-lifting desktop machine or the spry and \nminiscule portable laptop / palmtop / .ngertop / pintop. When a new computer sys\u00adtem is acquired, all \nthat should need be done is to point the old system at the new and have them sync. Sync in the sense \nof compatibly installing everything and readjusting to the new sur\u00adroundings. Most software manufacturers \ntreat the upgrade as an opportunity (provided for free) for the users to clean house to reinstall everything \nthat was previously installed.6 However, the massive upgrade is not a fresh start: It s an increment \nover the old environment because people expect the continuity of their lives to dominate the stutter \nof technological progress. And a new system should consider itself (anthropomorphically) to be installing \nitself in an old, established environment. Both the old and new must adapt. Of course, none of this should \nbe irrevocable. Any customiza\u00adtions and installations should be trivial to back out of or alter. It should \nalways be the case that any installation can be completely and accurately undone. 8. Beyond Installation \nSomeday the manufacturing model may become pass\u00e9. Con\u00adsider the notion of no installation or certainly \nno re-installation at all. In such a world, perhaps the only starting point would be a single object \nwhich would, like a seed, begin to use resources 6 Apple s OS X has a Migration Assistant which performs \nthe easier half of this when a new version of the operating system is installed it copies .les from the \nold system, ignoring .les supplied by the new version. It doesn t do any readjustments. available to \nit to compose the application, if it even makes sense to use that word. The seed would assemble components, \ndownload clones, etc. to custom build and wire itself into the world in which it lives. When an update \nwas desired, the objects themselves might morph, according to instructions received from the original \nauthors, while retaining customizations they had adaptively designed. In this way, objects change in \nsitu and the system / application never really restarts nor does it lose the bene.t it has had from living \nin the world with its users. 9. Buildable Packaging We imagine that software will be more completely \npackaged. In\u00adstead of just binaries and some support .les, each piece of soft\u00adware will contain everything \nit needs to be further developed by local software developers.7 Today, if any sort of local development \nis possible, it s because the source code and required supporting material can be loaded onto a local \nmachine or such a machine is accessible over the internet. In general, only open source and other source-available \nsystems present this option and even when the source code is available, the right compiler might not \nbe, etc. A system delivered completely packaged like this would be easy to modify for those capable of \nit; those whose knowledge and skills are limited will still be able to make stylesheet-based and other \ncon.guration-.le based changes. Some of the expected customizations include the ability to adapt the \ncode more pre\u00adcisely to the local environment, perhaps by the encapsulated de\u00advelopment system being \nable to sense its environment and shape the code a little better. How to implement this is problematic \nat the moment because there are many sorts and levels of dependencies software can have on its build \nand execution environments. For example, how can the dependence on a particular version of a library \nor of the oper\u00adating system for that matter be captured? These sorts of dif.cul\u00adties can be handled by \npackaging up all the dependencies (and perhaps storing them in a central location for all instances that \nshare dependencies), but such an approach doesn t handle the executables, like the compilers. The problem \nis that a compiler needs to execute on a machine that exists, and it needs to pro\u00adduce code for the target \nmachine. This is probably a case where standardization can help: A given platform is very likely to have \na compiler for a popular or mandated standard programming language. Another possibility for executables \nis a virtual machine that executes the compiler; porting the virtual machine should be relatively easy \nand possibly standardly done. There can be other advantages that derive from complete packaging. For \nexample, the existence of slightly different ver\u00adsions of some software which could very well end up \ninteracting with each other raises such questions as what constitutes the essence of a program and what \nkinds of variations are permitted while retaining its identity. With such a self-enclosed mechanism comes \nthe reality of a population of individuals8 individual instances of the same program, software, component, \nor sys\u00adtem and with this it becomes possible to think about advanc\u00ading the species by selective crossbreeding \nand other means typi\u00ad 7 Such a packaging has numerous copyright and intellectual property is\u00adsues, similar \nto those found in open source software. 8 This already is true but not widely recognized. Any real running \nsystem runs a variety of release and patch levels. cally used in husbandry. Whereas today a monoculture \nis highly valued, in the future not only will it have lesser or no value but it may become obsolete. \nIn such a world, the value of common, nonprogram-speci.c standards for data, control, and behavior exchange \nwill increase. Another good result is the possibility of eliminating the prob\u00adlem of lost source code, \nwhich is a surprisingly pervasive problem with legacy software. The company that created the software \nyou run goes out of business and no one cares about the source code or thinks it s important; an outside \ngroup wrote the soft\u00adware for your company and it s backed up on a tape that s then lost. This would \nnever happen were software always packaged with everything you need. And there would be fewer problems \nre-establishing the work environment. 10. Software as an Active Collaborator / Participant Software should \ntake responsibility for its own future not mean\u00ading software broadly construed but meaning each recognizable \nprogram, package, and application. After all, software can act, it can sense some part of its environment, \nand it can react to changes, so why should software remain passive once it s been unleashed to the world? \nThe attitude that a program s actions should be limited to what was planned at the factory reminds us \nof what Marvin Minsky wrote in Why Programming Is a Good Medium for Expressing Poorly-Understood and \nSloppily Formulated Ideas : There is a popular, widespread belief that computers can do only what they \nare programmed to do. This false belief is based on a confusion between form and content. A rigid grammar \nneed not make for precision in describ\u00ading processes. The programmer must be very precise in following \nthe computer grammar, but the content he wants to be expressed remains free. The grammar is rigid because \nof the programmer who uses it, not because of the computer. The programmer does not even have to be exact \nin his own ideas he may have a range of ac\u00adceptable computer answers in mind and may be content if the \ncomputer s answers do not step out of this range. The programmer does not have to .xate the computer \nwith particular processes. In a range of uncertainty he may ask the computer to generate new procedures, \nor he may recommend rules of selection and give the com\u00adputer advice about which choices to make. Thus, \ncom\u00adputers do not have to be programmed with extremely clear and precise formulations of what is to be \nexecuted, or how to do it. Marvin Minksy [25] Software should be able to examine its environment prior \nto installation, monitor changes to its operating conditions and adapt to them as best it can, observe \nthe state of its own health and attend to it, pay attention to how its human users use it and become \neasier to use, provide for its own improvement at the hands of local developers (perhaps by noticing \nand remarking on places where users had dif.culties such as frequent requests in one spot to undo an \noperation), accept extensions and cus\u00adtomizations, and, .nally accept and provide for its own death and \nreplacement. In short, software should act like a living collaborator in its own future and not like \na manufactured machine waiting for ob\u00adsolescence to overtake it there isn t even any minimally valuable \nscrap metal or plastics to salvage. Just about everything else we buy as consumers is subject to being \nrepaired or tinkered with given enough knowledge and/or bravery this is the legacy of the physical world: \nIt s just not possible to wall off easily the business end of most macroscopic physical machines the \nway it s possible to wall off from reasonable intrusion the parts of software (and microscopic machines \nlike CPUs) that make it readily malleable. That is, the source code for a corporeal machine is not behind \na .rewall on its makers server. Some languages Lisp [23, 24, 36], Smalltalk [12], Self [37], and others \nprovided some steps in this direction by being re\u00adactive. Terms used in those times to describe such \nsystems / environments / languages include exploratory programming, rapid application development, and \ninterpreted. In a reactive environment changes are immediate the response to a change is instantaneous \nso not as much bravery is needed to dive in and see what happens. Such systems increase the possibility \nof salvaging an old bit of software. How often has it been just one thing you d like to change about \nan application s behavior? In a reactive world you could just make that change and see what happens. \n11. FailureisCommon We will assume it. This has been substantiated by numerous studies of software failures \nand famously long bug lists for most software systems. David Hovemeyer and William Pugh have reported: \nwe have found that even well tested code written by ex\u00adperts contains a surprising number of obvious \nbugs. David Hovemeyer [14] To write a program or system assuming that nothing will go wrong even in the \nparts being written at that very moment is foolish, and software written this way in a few years will \nnot be tolerated and people who design and program that way will be barred from practicing the art. Here \nJoseph Weizenbaum s point of view is illuminating: The psychological situation the compulsive program\u00admer \n.nd himself in while [.xing a bug in his code] is strongly determined by two apparently opposing facts: \n.rst, he knows that he can make the computer do any\u00adthing he wants it to do; and second, the computer \ncon\u00adstantly displays undeniable evidence of his failures to him. It reproaches him. There is no escaping \nthis bind. The engineer can resign himself to the truth that there are some things he doesn t know. But \nthe programmer moves in a world entirely of his own making. The com\u00adputer challenges his power, not his \nknowledge. Indeed, the compulsive programmer s excitement rises to a fevered pitch when he is on the \ntrail of a most re\u00adcalcitrant error, when everything ought to work but the computer nevertheless reproaches \nhim by misbehaving in a number of mysterious, apparently unrelated ways. It is then that the system the \nprogrammer has created gives every evidence of having taken on a life of its own, and certainly, of having \nslipped from his control. This too is the point where the idea that the computer can be made to do anything \nbecomes most relevant and most sound\u00ad ly based in reality. For, under such circumstances, the misbehaving \nartifact is, in fact, the programmer s own creation. Its very misbehavior can, as we have already said, \nbe the consequence only of what he has done. Joseph Weizenbaum [40] To understand the source of invasive \nand pervasive failure consider that no apple failed to fall because someone forgot to tell it to. 12. \nSeek Out and Repair Errors We expect software will become like living organisms. We are talking about \nself-sustaining and self-repairing programs run\u00adning code that is buggy but coping with those bugs and \nperhaps repairing some of them9 or repairing the damage done. Moreover, we are talking about software \nthat continually adapts to its en\u00advironment, both at installation time and afterward. In most software \nthere are data structures which are used by the processes the software embodies. Typically these data \nstruc\u00adtures are by-products of the computation but sometimes they are used to direct parts of it. Such \ndata can be tested for integrity, consistency, and, sometimes, correctness repairing data can be a potent \nform of self-repair. Self-sustaining and self-repairing programs are possible and necessary. Today, safety-critical \nsystems are deployed for which stopping and awaiting human intervention after a failure has occurred \nis simply out of the question. Even a system for which shutdown is reasonable needs to shutdown safely. \nSome research\u00aders (Rinard: [31], [32]; Patterson &#38; Fox: [5], [6], [27]; Evans: [10]) have been exploring \nideas for self-repair, rapid recovery from er\u00adrors, and failure tolerance. To many practitioners today, \nthe idea of recovering from an error goes against the grain: the error should never have happened it \ns the result of bad design or bad coding. Or bad requirements or speci.cations, or because the software \nends up in an unexpected environment, perhaps because the environment is being updated / upgraded. The \nchanges we foresee have as much to do with vocabulary and metaphors as with new techniques and technologies. \nLet s look at one of the .rst instances of a program that used self-re\u00adpair rather than absolute correctness. \n<story> In 1958, John McCarthy was thinking about a symbolic dif\u00adferentiation program in a programming \nlanguage that was later to become Lisp. He was concerned about the erasure problem : no-longer-needed \nlist structure needs to be recycled for future use. In subsequent languages, such problems were handled \neither by the structure of the program being restricted to trees (stack al\u00adlocation of data and its trivially \nautomatic deallocation through stack popping) or by explicit allocation and deallocation (mal\u00adloc/free). \nHis comment on erasure / explicit deallocation: 9 Self-repair of code can be approached variously. One \npromising vein is to think about building software through generation from some model or speci.cation \nor by some process whose initial conditions can be varied and the code regenerated. The recursive de.nition \nof differentiation made no provi\u00adsion for erasure of abandoned list structure. No solution was apparent \nat the time, but the idea of complicating the elegant de.nition of differentiation with explicit erasure \nwas unattractive. John McCarthy [24] It s worth a pause to notice the style of research described. Mc-Carthy \nand his colleagues were trying to design a programming language. Part of their methodology was to write \nthe program they thought should be able to do the job and not the program that a compiler or execution \nsystem would require to make the program run well. In fact, the beauty of the program was foremost in \ntheir minds, not correctness down to the last detail. Beauty. Remember that word. Eventually the .rst \nLisp implementers decided to ignore the bug the fault of not explicitly erasing abandoned list cells, \ncaus\u00ading the error of unreachable cells accumulating in memory, lead\u00ading to a failure to locate a free \ncell when one is expected until the failure occurred and to repair it then. This avoided the problem \nof entangling a common set of functionality (keeping available all the memory that should be) with a \npure and clear program (symbolic differentiation). The failure the fault eventually caused was repaired, \nalong with a lot of other similar errors in a process named at the time and still called garbage collection. \n</story> The entanglement of erasure code with the symbolic differen\u00adtiation code reminds us of the problem \naspects address: We have found many programming problems for which neither procedural nor object-oriented \nprogramming techniques are suf.cient to clearly capture some of the important design decisions the program \nmust imple\u00adment. This forces the implementation of those design decisions to be scattered throughout \nthe code, resulting in tangled code that is excessively dif.cult to develop and maintain. Gregor Kiczales \net al [16] The combination of inelegance and the foolishness of pursu\u00ading perfection seem to combine: \nThe Goal of Perfection is Counterproductive: The aspiration to eliminate as many programming errors as \npossible creates a development process that diffuses the focus of the project, wastes engineering resources, \nand produces brittle software that is helpless in the presence of the inevitable errors or faults. A \nmore productive as\u00adpiration is to develop systems that contain errors and sometimes behave imperfectly, \nbut remain within their acceptable operating envelope. Flawed Software Has Enormous Value: The most productive \npath to better software systems will involve the combination of partially faulty software with tech\u00adniques \nthat monitor the execution and, when necessary, respond to faults or errors by taking action to appropri\u00adately \nadjust the state or behavior. Martin Rinard [31] The moral is not that Lisp researchers scooped the aspects \nand recovery-oriented programming guys by about 40 years but to note that the metaphor of conscientious \ncomputing can be effective if thoroughly adopted. The people who wrote the .rst garbage collectors weren \nt bogged down by the belief that a pro\u00adgram is manufactured in one place for use in another, but believed \nthat a programming language was based at least in part on a runtime environment in which the software \nwould continually evolve possibly in response to changing requirements or the changing nature of interdependent \nsoftware. In this case, the simplicity and elegance of the program (sym\u00adbolic differentiation was the \nexample that drove the thinking) was not to be compromised by the intrusion of an unrelated as\u00adpect of \nthe program (its memory management needs). Instead the program was allowed to fail (to run out of storage \nbecause the programmer forgot to deallocate used memory cells), and by a process of observing its environment \n(noticing it was out of memory), it was able to avert disaster and initiate a process of repair to .x \nthe mess the programmer s faults created. Impor\u00adtantly, the memory management concern has become isolated \nin a separate module separate from the program the programmer is interested in, and in fact, separate \nfrom every other program.10 This is the sort of thought process we believe will become prevalent in the \nfuture, but executed with more gusto (and let s face it more guts, too). Garbage collection is not the \nonly example of the sort of pro\u00adgramming practices we are talking about. We include as exam\u00adples utilities \nthat repair and defragment disks, that rotate log .les and otherwise cleanup from the normal (and abnormal) \nactivities of a complex system, and that are used as preventa\u00adtives. Virus-protection software similarly \nlooks from the outside at messages and other downloaded or created .les for signs of errors or pathology. \nSome of these utilities are triggered by events (like a .le being downloaded) and others are scheduled \n(like log .le rotation). But in all cases the problem-detection and repair code are indepen\u00addent of the \ncode that experiences the problem. The code repaired and the repair code are decoupled, which is central \nin the same way that by being decoupled from the design and implementa\u00adtion of the tested code, testing \ncode is effective. Such a decou\u00adpling, though, is not effective when there are similar or common design \n/ implementation points. If both the repair and repaired code need to (correctly) implement the same \ndif.cult-to-imple\u00adment algorithm, then perhaps the same errors will appear in both pieces of code, and \nthe repair will not be effective. Moreover, some of the preventatives, such as anti-virus soft\u00adware, \nperform automatic self-updates over the internet. This is in concert with our belief that software is \ncontinually installing itself and actively improving. Such updates are provided by peo\u00ad 10 A related \nidea is leasing: A resource is allocated to a particular process or program, but only for a speci.ed \ntime. If the process or program de\u00adsires to retain the resource beyond its lease duration, it must renew \nthe lease before it runs out. If the process or program fails crashes, goes into a loop the lease will \nnot be renewed and the resource will be returned to the system. This is like the garbage collection scenario \nexcept it is not the failure of a particular component within a system that is at stake but the failure \nof the entire system. And in the garbage collection case, a program notices that it has allowed its memory \nto fall into disrepair, while in the leasing situation, the overall system notices the failure only through \na form of insurance policy or one might view it as a form of emergence: nothing is speci.cally looking \nfor the failure of a component, but the effects of such a thing happening are handled by a mechanism \nthat assumes failure. ple, but they need not be: They might be from a design farm that is continually \nimproving software through a process of digital software evolution or other automatic mechanisms. Errors \nare typically handled by exception handlers code that is activated when a failure occurs. But the ultimate \ncause of the failure the fault might not be apparent. Therefore, errors must be sought out, through aggressive \nmeans like continual testing and other bad smell detection. And as some researchers are now discovering \n(and the inventors of garbage collection discovered a long time ago), repairing damage and the results \nof erroneous execution can be an effective way to keep a program or system operating properly. 12.1 \nDon tSeekOutandRepairErrors Some errors don t need to be .xed, and in fact, the very act of .xing them \ncan cause more harm than good. [32] Sometimes it makes more sense to observe and note problems, perhaps \ntrying to keep track of coincidental events, .les open, etc., with the idea that perhaps with this information \nif the error turns out to be serious enough to .x repairs can be made. As noted by Rinard and his colleagues, \ncode can be parti\u00adtioned into forgiving and unforgiving regions. Errors in unfor\u00adgiving regions lead \nto fatal errors or unacceptable results. Errors in forgiving regions may result in bad or marginal results, \nbut typically useful results. The example they give is of software that decodes and plays mpeg .les. \nThe part of the code that locates important metadata in the input stream which enables the rest of the \ncode to properly display the video stream is unforgiving; an error here causes an in.nite loop, early \ntermination, or no video to be displayed. The code that displays video information from the input stream \nonce that information is found is for\u00adgiving because generally errors there cause only degraded video \n/ audio quality. Ideally, the system would be able to determine for itself which errors are bad enough \nto be .xed and which not, perhaps by ob\u00adserving the amount of pain the error causes in users of the soft\u00adware \nor in other parts of the system. 13. Write Tests and Continually Run Them Components of a system will \nbe continually running tests self tests, environment tests, communications tests, etc. This will form \na matrix within which various feedback loops will keep the overall system running well. At the moment, \nmost programs and software operate like bulls in a china shop: They blast ahead assuming everything will \ngo their way. Instead, well-designed software in the future will constantly be adjusting to circum\u00adstances, \nrighting itself, keeping clear of bad situations. Such feedback loops will exist within the software \nand also between the software and the software s environment, correcting small errors and making incremental \nimprovements to the organiza\u00adtion and performance of the system. Self-tests and other sorts of tests \nwill help a system discover problems early, so that their correction or amelioration is effec\u00adtive;11 \nsuch tests can be useful to determine whether the envi\u00ad 11 Coupling tests with repair means that the \neffect of a software bug can be corrected or mitigated (possibly through rebooting, reinitializing a \ndata structure, or returning an acceptable value), but the actual bug remains in the code until .xed \nby developers. ronment is changing or degrading. In such a regime, tests should look outward as well \nas inward out toward the environment as well as measuring the effects of the environment on the software. \nWhen an update is downloaded along with its new tests all tests will be (eventually) run and the results \nsent back to wherever the changes re.ected in the update were made. This way, the soft\u00adware developers \nwill have the bene.t of the testing environments of all instances of the code, and there won t be as \nmuch need for an extensive and varied testing farm. Almost every installation is different, because the \nexact needs of users depends on the com\u00adplete local computing environment: different hardware, differ\u00adent \ndrivers, different optional or custom packages and libraries, different patches and patch levels, and \non and on. Perhaps even the order of installation makes a difference, particularly when software is customized \nbased on what is already in the system. We don t need to imagine some complicated learning environ\u00adment \nthe person or people using a system can customize it, and how they do so depends on what they know, the \nexperiences they have, and the work they do, which are all in.uenced by what is already installed on \nthe computer. Many software developers don t like to write tests, although those in the agile software \ndevelopment movement put writ\u00ading tests at the center of design and implementation. For them, the tests \nare executable requirements. Their fervor over testing doesn t go far enough: Tests should be designed \nto run all the time after the software is installed. If the tests are also continually sampling and testing \nthe environment, they can help a program avoid disasters and alert the users of the host computer of \nprob\u00adlems. Such testing is part of the concept of feedback, a principle on which life depends. When testing \nis part of the culture of programs, and once software is shipped with everything needed to modify it, \nthe pos\u00adsibility arises of users creating tests that re.ect their usage pat\u00adterns. Such tests would be \nuseful to the original programmers.12 14. Exercise Many of the behaviors we expect to see in future software \ncome from the idea of exercise. When we currently think about ex\u00adercising software, we imagine simply \nusing it or testing it or perhaps it s closer to the details of walking the dog. But for people, exercise \nis a way to strengthen, and when we exercise our minds our mental faculties can be improved. Many of \nour expectations for the future involve the idea of experience changing software. We have known for decades \nthat one of the deep dif.culties of producing software is that discovering requirements is hard and trying \nto do so before some working version of the software is available is impossible. So why should the discovery \nof require\u00adments stop once the software is installed when the requirements that depend on the local context \nare all around? 12 To the .rst order, unit testing does its job: Components are veri.ed to work according \nto the designer s notion of what the component is intended to do. Problems occur when the component is \nused in an unanticipated way and/or the component becomes a piece of a larger complex system. The system \ndynamics can cause unexpected behavior resulting from a combination of unanticipated use of components \nand interactions be\u00adtween components. State and behavior are stored in unlikely places in the system \n(like the communication pathways between the components); our hope is that a new paradigm of testing \ncould .nd ways to exercise / test such system dynamics. attractants &#38; repellents This requires \nwriting software differently in a way that per\u00admits changes in situ, something that is dif.cult but not \nimpos\u00adsible. [12, 23, 24, 36, 37] 15. Use Feedback Software should adapt to its surroundings and prevailing \ncondi\u00adtions. Feedback is a mechanism found in nature and in numerous mechanical designs to provide stability \nand adaptation in the face of changing conditions. In biological systems, feedback plays a decisive role \nin main\u00adtaining cellular functions. Chemotaxis [Figure 2] is an excellent example of nested feedback \nbeing used by bacteria such as E. coli to bias their swimming motion toward food sources and away from \ntoxins. The outmost feedback loop involves sensors that con\u00adtrol when the bacteria changes its direction. \nAn inner feedback loop causes the sensors to adapt so they stay sensitive to small differences over a \nvery wide range of concentrations. Together the two loops enable E. coli to robustly follow a gradient. \n[1] Some algorithms and software that control physical devices use feedback, but otherwise it is a rare \ncomponent of software. That is, no programming language incorporates feedback as an essential mechanism, \nbut it is, instead, relegated to the program\u00admer to explicitly construct out of low-level language features.13 \nBuilding feedback requires variables, numbers, comparisons, and loops. Therefore, software developers \nespecially junior ones don t think in terms of feedback. Even though feedback is essential to living \nsystems. 16. Make Things Visible System components will be able to see out into their environ\u00adments and \ninto other components. When software has just in\u00adstalled itself, it doesn t have enough experience (or \nenough time) to scope out how the system is being used, so it needs to come up in a default mode with \ntext editing, spellchecking, etc., ex\u00adactly as some developer imagined them back at the factory. By observing \nother software in action or by looking at the recorded histories of other software running on the system, \nthe newly 13 Constraint languages which are not widely used for application pro\u00adgramming may be exceptions, \nthough feedback is typically buried in control algorithms.  installed software can learn about the usage \npatterns and pre\u00addilections of its users. Visibility into the environment is restricted today not be\u00adcause \nof privacy concerns or inadequate design, but because the concept is not in play. Encapsulation inadvertently \nis in ef\u00adfect in both directions. It is not desirable to look into a software component by design and \nit is not possible to look outside of a component (from within it) because it s not a concept in contem\u00adporary \ncomputing. Communication across a software cell barrier is through an interface sometimes through arguments \nas in procedural code or through method calls (or message-passing) in object-oriented code. But as any \nsoftware developer knows, once inside the conceptual boundary between inside and outside, the programmer \n(and one might also say, the code) has a speci.c vocabulary and set of concepts and ontologies, as does \nthe envi\u00adronment outside the component. The bridge that is normally / exclusively built between the two \nis the signature (the name and shape of the communication) and the types of the pieces of infor\u00admation \nthat go back and forth. This is a very information-poor medium. The very narrowness of the communication \nchannel is the source of many advances in conventional computing. When correctness and optimality is \nforemost, the narrower the chan\u00adnels of communication the better. Visibility requires descriptions that \nare continually updat\u00aded14 for example, descriptions of what s inside a system s soft\u00adware components, \nhow a running system is currently con.gured and what it s working on, which users use which software \nand in what ways, etc. And visibility bene.ts from abundance a rich interface where perhaps pattern matching \nand some degree of understanding is possible. This sort of visibility is partly what Lanier is aiming \nat with phenotropic computing. Lanier thinks of surfaces that can be pattern-recognized or sampled. We \nare not particular how this is 14 A description is not a representation. A representation can sometimes \nbe thought of as a model of something else, usually in the real world. Ma\u00adnipulations of the representation \ntypically mean something regarding that model. A description cannot be manipulated to create a change \nin the thing described. A description can be understood, compared to other descriptions, and actions \ncan be taken based upon them. A representa\u00adtion is typically ef.cient in some way representing just what \nis neces\u00adsary while a description can be extravagant and mention a number of apparently inessential things. \n accomplished perhaps only (translatable) blackboards can suf\u00ad.ce with simple textual pattern matching. \nOr even extensions of something like Common Lisp s keyword / optional argument lists and calling conventions. \nOr even just posting XML documents. Making continual testing effective is another reason for vis\u00adibility: \nSuch things as the overall state of the system, what user\u00advisible windows and processes are available, \nand what the user s physical environment is like should be visible and, in some cases, alterable. For \nexample, as I (one of the authors) type this sentence, I am also digitizing some old band tapes (the \nauthors were in a rock band together). It would nice if the program I m writing this paper with knew \nabout the recording software and that it was running, so that it wouldn t interfere with the program \ncaptur\u00ading all the data in the bitstream from the digitizing hardware, which can happen because the operating \nsystem, OS X, doesn t know, aside from some heuristics, how I differentially value the operation of the \ntwo programs, nor, more importantly, how dis\u00adruptions affect the .ow of the document-preparation program \n(typically, not at all) and my perception of my interaction with it (minimal or not at all). The document \npreparation program could easily surmise that the real-time like recording is likely to be a lot happier \nif the program responding to typing were to get a little less priority such a diminishment would be unnoticeable \nto me but degradation of the data stream would be noticeable on the recording to everyone who listens \nto it. And the record\u00ading software could likewise look out for itself, noticing I have a multi-CPU machine \nand conversing with the operating system about how to handle the situation. 17. Continual Noticing Systems \nwill be aware. For a system to maintain itself, it needs to see itself, it needs some level of self-awareness.15 \n[33, 34] It must be possible for a programmer who wishes to write software that operates on behalf of \nits own well-being to write that code. A current trend is telemetry. A system sends a stream of data \nto another which is monitoring its health. A model like this is part of the solution, but only part. \nTelemetry represents a time\u00advarying look at one or a few aspects of a system. The visibility required \nfor continual noticing includes the entire status of the system hardware and software as well as some \ninformation about each component: exceptions thrown, errors trapped, popu\u00ad lation of inputs handled (for \nexample). This principle also enables the use of stigmergy as a self-or\u00adganizing mechanism. According \nto the Wikipedia: Stigmergy is a method of communication in decen\u00ad tralised systems in which the individual \nparts of the system communicate with one another by modifying their local environment. [http://en.wikipedia.org/wiki/Stigmergy] \nStigmergy is a concept proposed by Pierre-Paul Grass\u00e9 in the 1950 s to describe the indirect communication \ntaking place among individuals in social insect societies. [13] A termite will pick up some mud (for \ninstance) and invest it with her phero\u00admones. This mudball will tend to attract other termites carry\u00ading \ntheir own mudballs, and the local effect will be to concen\u00adtrate the mudballs in a single place, and \nthe global effect will be 15 Self-aware does not require AI or consciousness. A thermostat has awareness. \nA car s electronic ignition system is self-aware. to create towers and arches which are then made into \ntermite palaces. See also Prigogine [29] and Camazine [4]. In comput\u00ading an example of this would be \na process that writes data into a JavaSpace that other processes can then read, do some compu\u00adtation \nbased on what they ve read, and then possibly write new data into the JavaSpace. An explicit description \nof the state and history of the software system would enable the construction of self-organizing software \nsystems not necessarily systems that would self-organize to ac\u00adcomplish their designed functions16 but \nthat would self-organize to stay alive and healthy. 18. Autopoiesis / Allopoiesis Programmed systems \nwill become as living. One way that biologi\u00adcal systems use feedback, visibility, and continual noticing \nis as part of their self-generating nature: Many of the feedback loops in a living system are involved \nwith the regulation of production of components, proteins, and other biochemical material that regulates \nthe production of other things including the regulators just mentioned. This is essentially the concept \nof autopoiesis. Autopoietic systems are systems that are de.ned as unities, as networks of pro\u00ad ductions \nof components, that recursively through their interactions, generate and realize the network that pro\u00ad \nduces them and constitute, in the space in which they exist, the boundaries of the network as components \nthat participate in the realization of the network. Humberto Maturana [21] (see also [22]) (Simply:) \nAn autopoietic system is one that is continually (re)creating itself. It is an interrelated network of \ncomponents that build that interrelated network of components that is, itself. And even though there \nmight be deep connections to an outer environment, the boundaries of the system are distinct. In living \nsystems, living is the ultimate goal. And so the pro\u00adduction of more living stuff and its adaptation \nof that living stuff to the surrounding conditions is in many ways more important than the nature of \nthe living stuff itself as long as it can self-per\u00adpetuate (more or less). Our programmed systems are \nnot thought of this way. What is important about a programmed system is what it does. In this sense the \nsoftware systems we produce are allopoietic: Allopoiesis is the process whereby a system produces something \nother than the system itself. We are interested in this other stuff and don t care about the mechanism \nthat creates it beyond the fact that it creates it. The health and stability of the mechanism is beside \nthe point as long as the desired production happens. Allopoiesis is the manufacturing process abstracted. \nThis explains a lot about our currently fairly fragile systems but to see it requires examining longevity. \nUntil recently, not many programs needed to run for extensive periods of time op\u00aderating systems, certain \nequipment- and human-health monitor\u00ading software, and some embedded systems and therefore our educational \nsystem has become geared toward teaching how to design and code programs that are used once or for short \nperiods of time. With the advent of the Web we ve seen more systems that need to run for long periods. \nFor example, web servers. These op\u00ad 16 Most programs have requirements that prevent them from naturally \nbeing written as self-organizing systems, but this shouldn t stop us from trying to look for ways to \nwrite such systems. erate on essentially a regenerative basis: Each server request is handled as if \nit were the .rst and only request, and the context for the execution is created afresh. That is, no state \nis carried over from request to request, and it s as if the server were being created each time it is \nneeded.17 When a complex, programmed system needs to live for a long time, living becomes the ultimate \ngoal. Coupling this with the need to produce the right answers, we face the following daunt\u00ading problem: \nHow can we structure a system which needs to recursively generate, realize, and produce itself as well \nas cor\u00adrectly produce something other than itself? That is, how do we combine the correct and ef.cient \nfunction of an allopoietic system with the urge to live of an autopoietic one that is continu\u00adally recreating \nitself? If we try to make a system more robust by adding lots of ex\u00adplicit exception handlers and error \ndetection code the program becomes hard to understand and very dif.cult to maintain. It goes beyond what \npeople can really write. An obvious alternative answer one that was pursued a bit during the late 1970s \nand early 1980s, mostly in the arti.cial in\u00adtelligence community is to create autopoietic systems instead \nof the allopoietic ones that are too fragile and don t know about living, and for that autopoietic system \nto also produce the al\u00adlopoietic result. One way of doing this requires the process that produces ulti\u00admate \nresults (the allopoietic stuff) also to be aware of itself, the state its in, and how well it is producing \nboth itself and its results. The simple garbage collection example demonstrates this. The allocation \nof fresh storage is part of the correct functioning of the program, while the details of the garbage \ncollection algorithm are concerned with properly and reasonably locating unreach\u00adable storage for reclamation. \nSome garbage collection algorithms don t locate all such storage, leading to memory leaks18 or use less\u00adthan-perfectly \ntimely reclamation. That is, some collectors do a good job, but not a perfect job. Most importantly, \nthe operation of the code that does symbolic differentiation (for example) is separate from that which \ndoes the memory management / era\u00adsure / garbage collection. Even this simple example demonstrates the \nfundamental prob\u00adlem with this approach: Techniques and languages suitable to create an autopoietic system \nsuch as the less-than-perfect gar\u00adbage collectors are (probably) not suitable for writing correct, predictable, \nand deterministic code; code that correctly does banking, for example. Moreover it is instructive to \nnote that the concept of garbage collection was resisted by mainstream language designers until the mid-1990s \non the grounds that it was too slow or that the in\u00adterruptions were too unpleasant or intolerable. Today \nalmost 50 years after the .rst garbage collector was written research papers on how to improve or ameliorate \nthese bad effects of sepa\u00adrate garbage collection .ood peer-reviewed venues, signaling the growing acceptance \nof the idea. Nevertheless, software develop\u00aders today will sometimes still prefer to write a program \nthat will leak memory until the program halts from memory exhaustion over using an automatic system. \n17 To some approximation. 18 A memory leak occurs when a program allocates a data structure us\u00ading storage \nthat is never re-used (i.e. deallocated or reclaimed) once the structure is no longer needed. The lesson \nfrom this is that there will be resistance to the creation of an autopoietic mechanism if it is slow \nor, worse, bug\u00adgy.19 The .aw in the earlier research programme was to attempt to de.ne a single programming \nlanguage or programming system to serve both purposes to operate both at the level of arithmetic and \nlogic, procedure calls and method invocations, and also at the level of feedback, visibility, noticing, \nand living. Any program\u00adming language that can operate at the allopoietic level is neces\u00adsarily fragile, \nand so injecting those elements in the autopoietic system will break it as well. Moreover, the principles \nof the two sorts of systems are incon\u00adgruous. For example, think about visibility. There is an elegance, \nor perhaps it s just a symmetry, that the principle of visibility would apply to the autopoietic part \nof a system while the principle of information hiding would apply to the allopoietic part: In computer \nscience, the principle of information hid\u00ad ing is the hiding of design decisions in a computer pro\u00ad gram \nthat are most likely to change, thus protecting other parts of the program from change if the design \ndecision is changed. [http://en.wikipedia.org/wiki/Information_hiding] The purpose of information hiding \nplays no role in the execu\u00adtion of a program no role whatsoever. Only a role during the development of \nthe software.20 Therefore, information hiding is part of the process of software creation, which takes \nplace within something called the programming environment (in the old days) or the integrated development \nenvironment (nowadays). There is no reason that the software cannot be visible (not necessarily alterable) \nduring execution or even while the software is idle. Here s an example of why. When a new piece of software \nis installed, it might wonder as mentioned earlier how spellchecking is done in these parts. One way \nwould be to inspect programs that are used a lot and have been used frequently to see whether they provide \nspellchecking and whether there is a common module or at least a dictionary that the user has augmented. \nThen the new software could adopt (/ adapt to) the existing preferred method. That is, visibility / invisibility \nshould be valued differently when viewed vis-\u00e0-vis the two different aspects of a program: au\u00adtopoietic \nand allopoietic. Invisibility (ignorance of what s really inside a module, a function, an object, etc.) \nis valuable when a soft\u00adware development team is working to produce a system that will then, while executing, \ngo on to produce something else there are two allopoietic processes in play: the design / implementa\u00adtion \nteam producing the system, and the system producing its results.21 Limited visibility of the module interfaces \nat system construction time and at execution time is valuable because it reduces the possibility of change \nto known interfaces, and the use of an interface enables the ability of the potentially changed 19 Even \nif there is a simpli.cation in the expression of the mechanism. Note that it takes less effort to write \ncode in a garbage collected language, but programmers didn t / don t accept it because of performance \nworries. 20 There are, however, execution-time repercussions. 21 But note: During the design process, \nthe insides of a module are visible to some people: Design decisions made within a module are visible \nto the local decision- and software makers.  Figure 3: Autopoietic Software System module to supplant \nthe old one. When interfaces are visible, it is readily noticeable when they change compile-time, link-time, \nand execution-time errors are timely. Visibility is valuable to the operation of the autopoietic part \nof a software system, though it may be a hazard to the allopoi\u00adetic creation of the initial autopoietic \nsystem. Perhaps it would make sense to separate the allopoietic part of a system from the autopoietic \npart; schematically [Figure 3]. The encompassing autopoietic system needs to observe itself and its environment \nto know how to change and recreate itself. It must also have some ability to observe and affect the operation \nof components of the allopoietic system. Other principles are similarly in opposition [Table 1]. Because \nof this, the requirements of the two types of systems don t line up, and so designing an autopoietic \nlanguage / environ\u00adment for allopoietic purposes is unlikely to succeed. The .gure [Figure 3] contains \nthe answer. The allopoietic part of the sys\u00adtem must remain in an allopoietic language (and runtime when \nthat s appropriate) while the autopoietic part can be in a separate language designed to do different \nthings and with radically dif\u00adferent characteristics. The autopoietic language must (perhaps) have no \ningredients that can cause errors of a nature as to crash a program written in it. A way to think of \nthis is that it must be impossible to write a program with a certain class of bugs in it. Naturally, \nit s not possible for a person to write a program with no bugs, so what we mean by this must be elaborated. \nSome bugs are about the ultimate problem, such as getting differential equations wrong, updating cells \nin the wrong order, or forgetting parts of a speci.ca\u00adtion, while others seem centered around the business \nof program\u00adming per se, such as typos, fencepost errors, failing to initialize variables, etc. These \ntwo classes of errors feel very different. One is when we are surprised or discouraged that the program \ndoesn t do what we want and the other is when we are upset the program falls over, perhaps after getting \nnowhere. One is a failure to write the right program and the other is a failure to rightly write the \nprogram (we intended). In a lithe language, it must not be possible to write a program that falls over. \nAs an example, consider the game of life [9]. It has 3 simple rules for the birth, death and survival \nof counters on an in.nite checkerboard: Autopoietic Systems Allopoietic Systems visibility / transparency \ninformation hiding dynamic / .exible interfaces static / rigid interfaces self-generating / command &#38; \ncontrol / decentralized hierarchical diversity uniformity reactive manufactured abundance / redundancy \nparsimony / ef.ciency emergent (no rei.cation) rei.cation of properties loosely coupled interaction tightly \ncoupled interaction pattern-based signal-based local rules global reasoning lithe languages Java , C++, \nC#, usual suspects Table 1: Autopoietic and Allopoietic Principles Survivals. Every counter with two \nor three neighboring coun\u00adters survives for the next generation.  Deaths. Each counter with four or \nmore neighbors dies (is re\u00admoved) from overpopulation. Every counter with one neigh\u00adbor or none dies \nfrom isolation.  Births. Each empty cell adjacent to exactly three neigh\u00adbors no more, no fewer is a \nbirth cell. A counter is placed on it at the next move.  We have all seen animations of life con.gurations. \nA program in the game of life is just any initial con.guration of counters on an in.nite 2-d plane. Some \ncon.gurations don t do anything in\u00adteresting at all: They grow forever or die off or fall into a cyclic \nstate. Others are quite interesting in fact, the mathematician John Conway proved life is universal: \nThat is, it can simulate a Turing machine. But, consider that no initial con.guration can have a fatal \nbug in it in the sense that the game of life will halt or experience some failure. The con.guration might \nnot do what you want (due to a fault in placing an initial counter), but any initial con.guration will \nrun. This is not true in a general-pur\u00adpose programming language. Of course, this is what the type theorists \naim at with (allopoi\u00adetic) type theory, but they will fail in the sense that fatal bugs will always be \npossible in the languages they work on because, after all, those languages deal with numbers and arrays \nand other in.exible and insensible data structures data structures that don t, for example, enforce application \nand domain-speci.c semantics.22 And if they were to succeed, well, we would simply use what they produce. \nBut we see autopoietic languages being lithe. Lithe: Readily bent; supple. Marked by effortless grace.23 \nThe structure of a system made this way would be of the allo\u00adpoietic part of it the part that does what \nthe designers intended, such as banking or web serving embedded in the autopoietic 22 This is true of \nessentially all programming languages both statically and dynamically typed. 23 This de.nition is adapted \nfrom The American Heritage\u00ae Dictionary of the English Language, Fourth Edition.  Figure 4: Epimodules \npart, which would be responsible, in a sense, for keeping the overall system alive. In one possible metaphor, \nit would be like Einstein s body keeping his brain / mind working properly. <digression> We imagine a \npossible structure for this by the attachment (we favor this way of thinking of it rather than as a traditional \ninterface, for reasons described later) of a monitor or autopoietic interface we will call it an epimodule \nto each or some allo\u00adpoietic components in an allopoietic system. The purpose of the epimodule is to \nmonitor the behavior of the component and to alter it when needed. For example, in a conscientious allopoietic \nsystem, the component would include all its test code. The epi\u00admodule would be able to pause the component, \nexecute its tests, and examine the results. If a new version of a subcomponent becomes available say \na new text processing component the epimodule can direct the component to unload / unpatch / ig\u00adnore \nthe old version, install the new one, run tests, and then either proceed or undo the whole operation. \nOne of the more important sets of capabilities of epimodules would be to be able to clone and then kill \na module. Imagine a scenario in which a component / module has a memory leak or other error whose bad \neffects accumulate. The autopoietic sys\u00adtem through the intermediation of the epimodule can observe and \ntrack this problem and at some point decide to clone the component. If the component has no persistent \nstate, the traf.c to the old component can be shunted to the new one. If the com\u00adponent has persistent \nstate, the old instance of the component can be directed to clone itself, copying over the persistent \nstate. In some cases in fact, in most cases this will have the effect of doing a stop-and-copy garbage \ncollection of the internal state of the component, thereby cleaning up / leaving behind the ac\u00adcumulated \ndamage to the component.24 Instead of killing the module, it could be instructed to self\u00addestruct. This \nmechanism could have similar advantages as apoptosis, or programmed cell death, does in living systems. \nIn apoptosis, the destruction of a cell is triggered by an internal or external signal, and the way the \napoptotic process is execut\u00aded how the cell commits suicide facilitates the safe disposal of cell corpses \nand fragments. Likewise, a system module asked 24 Maybe . If the problem is in a persistent part, other \ntechniques will be needed. Figure 5: Autopoiesis / Allopoiesis to kill itself can cleanly stop (if possible) \nby explicitly releasing any system resources it has acquired, thereby working toward the health of the \nsystem. Epimodules, taken in the aggregate, should be able to rewire and hence recreate an entire allopoietic \nsystem, and by continu\u00adally regenerating it, keep it healthy and alive. The requirement, though, is to \nkeep the allopoietic system operating properly: It is performing some precisely speci.ed task, and that \nmust con\u00adtinue. Perhaps some degree of tolerance for uneven performance exists, but even that might not \nbe permitted. The autopoietic sys\u00adtem is there to make the overall system more robust, less fragile, \nmore accommodating to users, and its own correct functioning should not become a factor in the correct \nfunctioning of the al\u00adlopoietic system. Schematically [Figure 4]. A more radical and interesting example \nsuggested by Armando Fox [6] is for an epimodule to observe a module s mutterings. A module can be instrumented \nwith a series of mutter statements which when captured as telemetry provides the module s inner dialog. \nWhen punctuated by input and output boundaries, the mutterings can be considered messages, and a Bayesian \nlearn\u00ading process can be applied to a testing corpus to learn what are good and bad messages. Then the \nepimodule can run the Bayes\u00adian network over the messages of a live module to get a sense of whether \nthe module is acting normally, regardless of whether its behavior is correct. These judgments can lead \nperhaps to a clon\u00ading and subsequent death of the original component. Another possible way to envision \nthe allopoietic / autopoietic structure is to look at a speculative, different, more detailed pic\u00adture \n[Figure 5]. The blue boxes represent allopoietic code the code that does the real work and red blobs \nindicate autopoietic code. The main big blue box is a component in a larger (allopoietic) system. The \nbump and string on top represent its normal inter\u00adface and connections think of it as the method signature \nand call graph. The darker (lower) bluish box inside can be thought of as the epimodule interface. Its \njob is to implement health- and repair-related operations within the component. We see things like the \nability to run tests this includes packaging up the tests themselves and some way of characterizing the \nresults to clone the component, to safely kill the component, or to repair data structures. There could \nbe others as well, such as a tap into the local exception handling and event environments. The red shapes \noutside the box, including the encompassing reddish rectangle with the rounded corners, represent autopoi\u00adetic \ncode. The odd shapes that change shapes and shades from the outside to the inside of the component (from \noval to square and from red to blue or from a darker grey to a lighter one) rep\u00adresent the epimodules \nthat assist that component by keeping it healthy and keeping healthy the entire system within which that \ncomponent exists. Epimodules can either be developed by the original developers of the allopoietic code25 \nor be developed / supplied by the devel\u00adopers or users of the installation site. There might be a standard \necology of health maintenance code at the local site that appli\u00adcation systems tie into. Further, there \nis no need for epimodules to execute on the same computer systems as the allopoietic code it oversees. \nEpi\u00admodules can execute on another computer system or systems onsite or offsite, perhaps where the developers \nof the allopoietic system are located. This will reduce the performance impact of the architecture on \nthe implementation. Epimodule execution can also be asynchronous with respect to allopoietic execution. \nFor example, the epimodules (the auto\u00adpoietic system) can include extensive simulations to set param\u00adeters \n(e.g. recompiling an allopoietic component with different compiler switches to better tune it for actual \nuse), determine the best con.guration, design and implement more appropriate glue, monitoring, or protection \ncode.26 The red, blobby, autopoietic components communicate with each other through the reddish background \nsubstrate and perhaps by the action of autopoietic entities that operate in the substrate but which are \nnot attached to speci.c allopoietic components. We don t know much about what the autopoietic parts should \nbe like. And in particular we have not much of an idea what lithe languages will be like. There is probably \na continuum of likely possibilities. But our intuition says that nudging, tendencies, pressure, and in.uence \nwill be more important than exchanging control and data or traditional control structures and composi\u00adtion \ntechniques. At the conservative end, lithe languages could be declarative, mostly descriptive perhaps \na set of wiring diagrams for putting together the system from its components, and speci.cations of the \nconditions under which to run tests, to clone components, to do internal repair, etc. These descriptions \nand speci.cations would be interpreted much as a constraint system is to maintain the functioning of \nthe system and its components. As such, the descriptions might be ineffective but never broken. At the \nmore speculative (and intriguing) end, the lithe lan\u00adguage might be able to express only programs that \nare dimly aware of themselves and their surroundings, but aware never\u00adtheless. The red, blobby epimodules \ncould be like living cells or other living organisms that are attracted to components either generally \nor speci.cally that is, some epimodules might be tai\u00adlored for certain components while others could \nbe general. The epimodules would attach themselves to components and sense conditions, both inside and \noutside the component, and exert pressure on the component to run tests, etc. Not interact through 25 \nPerhaps as a paid service. a traditional interface, but sense as if sensing the density of chemi\u00adcals \nand exert pressure as if by a suggestion or a push. The substrate could be thought of as a medium for \nsmells that would in.uence the activities of the epimodules. So, per\u00adformance monitoring of a component \ncould exude a hotspot smell, which when sensed by other epimodules would cause a migration of a set of \ncomponents to a stronger cluster or a faster machine. Perhaps it would be useful for the substrate to \nhave a geometry so that concepts of distance and expanding signals could be used to model accumulating \nevidence or disregard ir\u00adrelevant, anomalous spikes. At this end of the spectrum, concepts like population \nand crossbreeding could make sense so that the epimodules could learn or evolve to be more effective. \nPerhaps epimodules would live from nourishment provided by a healthy system and its com\u00adponents. Perhaps \nepimodules would effect the initial installation using surrogates27 to optimize placement and connectivity, \nthe real installation taking place after some initial experimenta\u00adtion or perhaps the surrogates would \nassemble components or grow them from found / sought parts and pieces in a sort of in\u00adplace development \n/ growth process. And so on. </digression> The concept of autopoiesis .ows, in a way, from Immanuel Kant \ns analysis, where he compares living organisms to mechani\u00adcal devices. Living organisms: In such a natural \nproduct as this every part is thought as owing its presence to the agency of all the remaining parts \nand also as existing for the sake of the others and of the whole the part must be an organ producing \nthe other parts, each consequently reciprocally producing the others. Immanuel Kant [15] Mechanical devices: \nIn a watch, one part is the instrument by which the move\u00adment of the others is affected, but one wheel \nis not the ef.cient cause of the production of the other. One part is certainly present for the sake \nof another, but it does not owe its presence to the agency of that other. For this rea\u00adson also the producing \ncause of the watch and its form is not contained in the nature of this material. Hence one wheel in the \nwatch does not produce the other and still less does one watch produce other watches by utilizing or \norganizing foreign material. Hence it does not of itself replace parts of which it has been deprived. \nImmanuel Kant [15] Allopoietic systems are like watches: The components are there for each other, but \nnot by each other. In other words, each component does not create the others. Order, perhaps, requires \ncontinual remaking because the nature of the universe is to unmake order. The digital world is thought \nto be immune from such effects, being timeless, but what is sometimes forgotten is the fallibility of \nthe makers the software designers, developers, and programmers who continually create .aws or fail to \ngrasp the fullness of the requirements. And these .aws accumulate and 26 Modulo bandwidth constraints. \nNote that a multicore CPU could mini\u00admize even this problem. 27 We imagine a sort of digital stem cell. \n operate on the whole and each other rendering errors over time. proper order, for the much more important \npurpose of This is why rebooting is a common resort. constructing the formula itself 19. More Principles \nAlthough people have talked about dynamic languages, re.ec\u00ad tion, meta-models, and the like, conscientious \nsoftware written as an embedded allopoietic system within an autopoietic system has never really been \nattempted before. The trip-up has been that while the initial impulse for a programming model might be \nto\u00ad ward an autopoietic system, the needs of the allopoietic require\u00ad ments eventually come to the fore \nand any attempts at a radical design fold back into a traditional mold. The autopoietic should not harm \nthe allopoietic system. This might mean that the epimodules should not be enabled to actu\u00ad ally kill \na module. One approach to this is to create a design lan\u00ad guage for autopoietic systems that is not Turing \ncomplete, and in fact quite dramatically limited in its abilities. The autopoietic system might be programmed \nin terms of .ows, where informa\u00ad tion seeps through the system rather than being instantaneously transmitted \nfrom point to point. Markets work because currency .ows, because goods .ow. The immune system works because \nblood and other .uids .ow. eBay works because reputation (re\u00ad lating to buyers and sellers) .ows. In \nmany cases, .ow is slow / through diffusion. A web server component can emit a slowly dispersing overload \nor hotspot smell perhaps its input queues are over.owing. If the overload persists, the smell around \nthe component will grow stronger and as it disperses it transmits its distress to autopoietic components \nthat, when triggered by a suitable threshold, might replicate the stressed component to relieve the overload. \nOn the other hand, if the overload diminishes, the smell diminishes and doesn t trig\u00ad ger the replication. \nThen gradients. This is related to locality. A .ow can follow a gradient, perhaps from some region where \nself-recognizers / non\u00ad self killers are created to an area where non-self has appeared. Another example \nis in a network: The autopoietic system can send out two .ows that disperse at different rates from a \npersistent store. One .ow is to enable a copy of the store to create a replicated site and the other \n.ow disables copying. A copy is made at a site with a probability proportional to the ratio of the concentration \nof enabler to disabler. In effect, replicants are made not too close, not too far, and not in a predictable \nmanner. [10] Think in terms of layers. A system doesn t have to be mono\u00ad lithic or based on interacting \ncomponents. A system based on stigmergy reacting to elements of the environment can react to events, \nto reactions, to reactions to reactions, etc. A different concern can be handled by a separate layer. \nIt can be useful to think in terms of layers rather than components, because a com\u00ad ponent is an allopoietic \nconcept. Diversity creates innovation and safety. We learned this from biology and from any creative \nactivity. We ve seen many instances in ordinary life of the fact that a diverse base creates fewer points \nof catastrophic failure. Even Charles Babbage recognized this in the realm of computation: if care is \ndemanded from the attendants for the inser\u00adtion of the numbers which are changed at every new calculation \nof a formula, any neglect would be abso\u00adlutely unpardonable in combining the proper cards in When the \nformula is very complicated, it may be algebra\u00ad ically arranged for computation in two or more distinct \nways, and two or more sets of cards may be made. If the same constants are now employed with each set, \nand if under these circumstances the results agree, we may then be quite secure of the accuracy of them \nall. Charles Babbage [2] This is not about fault tolerance of the allopoietic part of the system, though \nthere may be some lessons of value there too. An approach to fault tolerance that has been explored and \nseems like it is an application of diversity is the use of n-version program\u00adming and voting ([17], for \nexample). Such an approach might be an example were the diversity in the versions to be true diversity.28 \nWhat we are concerned about is keeping the autopoietic part of the overall system working. Therefore, \nit is not correctness of result that is important but survivability. When survivability is essential, \nredundancy may help. Re\u00addundancy achieves two things: tolerance of single fatal errors and the possibility \nof randomness. When there are numerous members of a population that in the aggregate are achieving some \npurpose, the loss of a fraction of that population due to error is not important this is obvious; randomness \nis less so. For an anthill to forage for food, a number of individuals search each using a random path \nbut leaving a pheromone trail. If one .nds a food source, she returns with some food by following her \ntrail back and adding pheromones to the trail. When other ants sense the trail they follow it, further \nreinforcing it with phero\u00admones. In this way, the redundancy enables a form of creativity or problem \nsolving. 20. Pandora Hope sole remain d within, nor took her .ight, Beneath the vessel s verge conceal \nd from light. Works and Days, Hesiod [8] Aside from parts of some operating systems including virus protection \nand some of the other examples we ve given we in\u00ad habit a world with no autopoietic software. The fear \nis that with software that is more like a living system including software that exploits digital software \nevolution we (people) will lose control of our software, both as individuals and as a society we might \nbecome frustrated that our software takes our require\u00adments more as suggestions than commands. In the \nworst case, software that is obeying its own imperatives could run amok. This is reminiscent of Pandora \ns problem. 28 Knight and Leveson report on an experiment where a group of students from two universities \nare given the same speci.cation, have the nature of the experiment (to study n-version programming) explained \nto them, and are required to use the same programming language, compiler, and platform but any methodology \nthey wished to implement the speci.\u00adcation. True diversity would require (vastly) different languages, \ndifferent language implementations, relatively independent or even poorly related speci.cations, and \ndesign and implementation groups that not only don t know of each other, but are oblivious to the situation. \nAnd even then, whether by voting or some other means the correct answer could more reliably be gotten \nis not certain. Pandora was created by the gods and given as a gift along with a jar to Epimetheus, \nPrometheus s brother. The gods were upset that the brothers had brought .re to humankind, and they placed \ndisease, death, and sorrow in the jar, and told Pandora never to open it. But they had created her with \nan unconquerable curiosity. Eventually Pandora could not hold back any more and she opened the lid, letting \nloose the evils inside. Shocked, she closed the lid but not before the evils had escaped. Fear of control \nloss has always been the issue for robots and other intelligent software from the sci-. point of view. \nWe feel we are in control of our current software applications because they are the result of a conscious \ndesign process based on explicit speci.cations and they undergo rigorous testing. But we know that those \napplications contain many bugs, some of which may be quite destructive. We have learned to live with \nthis, establish\u00ading a certain level of comfort based on the effort put in to testing and debugging the \nsoftware. Self-sustaining systems because of their more active nature will require us to get comfortable \nwith a new set of criteria to de\u00adtermine that a program will do what we expect it to. In addition to \nexplicit testing, we will need to rely on the various feedback loops and constraints de.ned to keep the \nsystem in check. Moving forward with any technology that has the potential of being independent of human \ncontrol is a touchy affair. One con\u00adsolation comes from the ending of Pandora s story The gods, in an \nunusual .t of compassion, had placed Elpis Hope in the box. The evils had escaped but Elpis was still \nin the jar. Seeing Elpis, Pandora let her out and from then on there was the possibility / hint / (false?) \nhope of cure, of life, and of happiness. We should start slowly and constantly build systems that self \nsustain. Feedback loops at all levels of scale can help. 21. Getting There Getting to conscientious software \ncan be done only in steps, though some of them require breakthroughs and new thinking. Already some steps \nare being taken: some software automatically updates itself; S.M.A.R.T. hard drive technology monitors \ndisks and predicts errors; some systems support global preferences; and some operating systems engage \nin a small degree of self-re\u00adpair, using telemetry or events; web servers spawn small server processes \nwith .xed lifetimes. These are just examples. Several researchers have been working in this area for \na while, and research is getting more daring. A couple of prominent re\u00adsearchers in the area have already \nbeen referred to: Martin Rinard, David Evans, Armando Fox, and David Patterson. Others include Tom Knight \nand Gerry Sussman [18, 38, 39]. Several companies, notably IBM, have had projects in this area whose \npurpose has been to create near-term mechanisms and products. More importantly, as we continue to make \nlarger and larger software distributed over a variety of computers in a network, producing more and more \nvariability of co-existing versions, the results based on our current old-fashioned approaches will only \nget worse. This is not pessimism speaking but an observation of the ways in which the need for accelerated \nwork in this area will become apparent. We can start on the ideas in this paper by designing systems \nwith epimodules based on software services that are like plug-ins or that operate remotely (like telemetry) \nto provide some self-re\u00adpair capabilities. Another simple step would be to make more of the insides of \nmodules visible from the outside in order to observe normal and anomalous behaviors and take corrective \naction. 22. Conclusions We are starting to make progress; and once progress is being made, perhaps it \nwill accelerate. We are still in the infancy of computing. It is foolish to think that we have already \nfound all the central concepts. For years we have been struggling to come up with the best metaphor for \ndeveloping software: is it like writ\u00ading, or engineering, or like architecture, like horticulture, like \nvoodoo? Few people are ready to realize that programming is not like other things, but other things are \nlike it. Programming is unlike anything people have done before, so the ways are lim\u00adited in which it \nis like other things. It is therefore still ok to pull ideas from lots of disciplines and areas of interest. \nWe have been pulling from a variety of sources to come up with our vision for future software directions. \n Our software is like children. For a time parents must provide everything and be prepared to step in \nto prevent the next disaster. It s not uncommon for a waking child to never be out of one of its parents \nsight for years on end. We expect that after a time the child will mature, will grow up, will be able \nto take care of itself, to solve problems, to cope, and perhaps to contribute something new. Initially \nsel.sh for what other options are there? the child becomes responsible. With luck or persistence or as \nthe result of good upbringing, the child may become conscientious. Shall we hope similarly for our software? \nAcknowledgements Thanks: Gary T. Leavens, Kristen McIntyre, Meg Withgott. 23. References [1] Alon, U., \nSurette, M. G., Barkai, N., Leibler, S., Robustness in Bacterial Chemotaxis, Nature, Vol. 397, pp. 168 \n171, January 14, 1999. [2] Babbage, C., On the Mathematical Powers of the Calculat\u00ading Engine, in The \nOrigins of Digital Computers: Selected Papers (3rd ed.), Brian Randell (Ed.), Heidelberg, Springer-Verlag, \n1982. [3] Brand, S., How Buildings Learn: What Happens After They re Built, Penguin, 1994. [4] Camazine, \nS., Deneubourg, J., Franks, N., Sneyd, J., The\u00adraula, G., Bonabeau, E., Self-Organization in Biological \nSystems (Princeton Studies in Complexity), Princeton Uni\u00adversity Press, 2003. [5] Candea, G., Brown, \nA., Fox, A., Patterson, D., Recovery Oriented Computing: Building Multi-Tier Dependability, IEEE Computer, \nVol. 37, No. 11, November 2004. [6] Candea, G., Fox, A., Recursive Restartability: Turning the Reboot \nSledgehammer into a Scalpel, Proceedings of the 8th Workshop on Hot Topics in Operating Systems (HotOS-VIII), \nSchloss Elmau, Germany, May 2001. [7] Dvorak, D., Challenging Encapsulation in the Design of High-Risk \nControl Systems, Proceedings of Onward! at OOPSLA 2002, November 2002. [8] Elton, C., The Remains of \nHesiod translated from the Greek into English Verse, in The Works of Hesiod, Calli\u00admachus, and Theognis, \nLondon, G. Bell, 1879. [9] Gardner, M., The Fantastic Combinations of John Con\u00adway s New Solitaire Game \nLife , Mathematical Games, Scienti.c American, 223, pp. 120 123, October 1970, http://ddi.cs.uni-potsdam.de/ \nHyFISCH/Produzieren/lis_projekt/ proj_gamelife/ConwayScienti.cAmerican.htm. [10] George, S., Evans, D., \nMarchette, S., A Biological Program\u00adming Model for Self-Healing, First ACM Workshop on Survivable and \nSelf-Regenerative Systems, 2003. [11] Glass, R., Practical Programmer: Sorting Out Software Complexity, \nCommunications of the ACM, Vol. 45, No. 11, pp 19 21, 2002. [12] Goldberg, A., Robson, D., Smalltalk-80: \nThe Language and Its Implementation, Addison-Wesley, 1983. [13] Grass\u00e9, P., La Reconstruction du nid \net les Coordina\u00adtions Inter-Individuelles chez Bellicositermes Natalen\u00adsis et Cubitermes sp. La theorie \nde la Stigmergie: Essai d interpretation du Comportement des Termites Con\u00adstructeurs, Insectes Sociaux, \n6:41 81, 1959. [14] Hovemeyer, D., Pugh, W., Finding Bugs is Easy, SIGPLAN Notices (Proceedings of Onward! \nat OOPSLA 2004), De\u00adcember 2004. [15] Kant, I., The Critique of Judgment, 1790; Prometheus Books, 2000. \n[16] Kiczales, G., Lamping, J., Mendhekar, A., Maeda, C., Lopes, C., Loingtier, J., Irwin, J., Aspect-Oriented \nProgramming, 11th European Conference on Object-Oriented Program\u00adming, LNCS 1241, pp. 220 242, 1997. \n[17] Knight, J., Leveson, N., An Experimental Evaluation of the Assumption of Independence in Multi-Version \nPro\u00adgramming, IEEE Transactions on Software Engineering, Vol. SE-12, No. 1, pp. 96 109, January 1986. \n[18] Knight, T., Sussman, G., Cellular Gate Technology, Pro\u00adceedings of UMC98, First International Conference \non Unconventional Models of Computation, Auckland, NZ, January 1998. [19] Krakauer, D., Robustness in \nBiological Systems: A Provi\u00adsional Taxonomy, Santa Fe Institute Working Paper #03\u00ad02-008, 2003. [20] \nLanier, J., Why Gordian Software has Convinced Me to Believe in the Reality of Cats and Apples, in Edge \n128, November 20, 2003, http://www.edge.org/documents/archive/ edge128.html. [21] Maturana, H., Autopoiesis, \nin Autopoiesis: A Theory of Living Organization, Milan Zeleny (ed.), pp. 21 30, New York, North Holland, \n1981. [22] Maturana, H., Varela, F., Autopoiesis: The Organization of the Living, in Autopoiesis and \nCognition: The Realiza\u00adtion of the Living, (1980), pp. 59 138, 1973. [23] McCarthy, J., Abrahams, P., \nEdwards, D., Hart, T., Levin, M., LISP 1.5 Programmer s Manual, MIT Press, Cambridge, Massachusetts, \n1962. [24] McCarthy, J., History of Programming Languages, The First ACM SIGPLAN Conference on the History \nof Pro\u00adgramming Languages, pp. 217 223, Los Angeles, 1978. [25] Minsky, M., Why Programming Is a Good \nMedium for Expressing Poorly-Understood and Sloppily Formulated Ideas, a slight revision of a chapter \nin Design and Plan\u00adning II Computers in Design and Communication, Mar\u00adtin Krampen and Peter Seitz (Eds.), \nVisual Committee Books, Hastings House Publishers, New York, 1967, http://rafael_es_son.typepad.com/ \nmetainformaciones/.les/ minsky_essay_1967.pdf. [26] Nardi, B., A Small Matter of Programming: Perspectives \non End User Computing, MIT Press, 1993. [27] Patterson, D., Brown, A., Broadwell, P., Candea, G., Chen, \nM., Cutler, J., Enriquez, P., Fox, A., Kiciman, E., Merzbach\u00ader, M., Oppenheimer, D., Sastry, N., Tetzlaff, \nW., Traupman, J., Treuhaft, N., Recovery-Oriented Computing (ROC): Motivation, De.nition, Techniques, \nand Case Studies, UC Berkeley Computer Science Technical Report UCB CSD-02\u00ad1175, March 15, 2002. [28] \nA good summary of the Pentium math bug by Ivars Peter\u00adson can be found at http://www.maa.org/mathland/ \nmathland_5_12.html. [29] Prigogine, I., Stengers, I., Order Out of Chaos: Man s Dia\u00adlogue with Nature, \nBantam Books, New York, 1984. [30] Randell, D., Facing Up to Faults, Department of Comput\u00ading Science, \nUniversity of Newcastle upon Tyne, January 2000. [31] Rinard, M., Automatic Detection and Repair of Errors \nin Data Structures, Companion to the 18th Annual ACM SIGPLAN Conference on Object-Oriented Programming \nSystems, Languages and Applications, Anaheim, CA, pp. 221 239, 2003. [32] Rinard, M., Cadar, C., Nguyen, \nH., Exploring the Accept\u00adability Envelope, Companion to the 20th Annual ACM SIGPLAN Conference on Object-Oriented \nProgramming, Systems, Languages, and Applications, San Diego, Califor\u00adnia, 2005. [33] des Rivi\u00e8res J., \nSmith, B., The Implementation of Proce\u00addurally Re.ective Languages, Proceedings of the ACM Symposium \non LISP and Functional Programming, 1984. [34] Smith, B., On the Origin of Objects, A Bradford Book, \nThe MIT Press, Cambridge, 1996. [35] The Software Engineering Institute (SEI), The Software Challenge \nof the Future: Ultra-Large-Scale Systems, June 2006, http://www.sei.cmu.edu/uls/. [36] Steele Jr, G., \nGabriel, R., The Evolution of Lisp, ACM Conference on the History of Programming Languages, II, published \nin ACM SIGPLAN Notices, Vol. 28, No. 3, March 1993,http://dreamsongs.com/NewFiles/HOPL2-Uncut.pdf. [37] \nUngar, D., Smith, R., Self: The Power of Simplicity, Pro\u00adceedings of the ACM Conference on Object-Oriented \nProgramming, Systems, Languages and Applications, Or\u00adlando, Florida, 1987. [38] Weiss, R., Knight, T., \nSussman, G., Genetic Process Engi\u00adneering, in Cellular Computing, Martyn Amos (Ed.), pp. 43 73, Oxford \nUniversity Press, 2004. [39] Weiss, R., Knight, T., Sussman, G., Cellular Computation and Communication \nUsing Engineered Genetic Regulato\u00adry Networks, in Cellular Computing, Martyn Amos (Ed.), pp. 120 147, \nOxford University Press, 2004. [40] Weizenbaum, J., Computer Power and Human Reason: From Judgement to \nCalculation, W.H. Freeman &#38; Compa\u00adny, 1976.  \n\t\t\t", "proc_id": "1167473", "abstract": "Software needs to grow up and become responsible for itself and its own future by participating in its own installation and customization, maintaining its own health, and adapting itself to new circumstances, new users, and new uses. To create such software will require us to change some of our underlying assumptions about how we write programs. A promising approach seems to be to separate software that does the work (allopoietic)from software that keeps the system alive (autopoietic).", "authors": [{"name": "Richard P. Gabriel", "author_profile_id": "81100654724", "affiliation": "Sun Microsystems Laboratories, Menlo Park, California", "person_id": "PP14224316", "email_address": "", "orcid_id": ""}, {"name": "Ron Goldman", "author_profile_id": "81100027165", "affiliation": "Sun Microsystems Laboratories, Menlo Park, California", "person_id": "PP18006002", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167510", "year": "2006", "article_id": "1167510", "conference": "OOPSLA", "title": "Conscientious software", "url": "http://dl.acm.org/citation.cfm?id=1167510"}