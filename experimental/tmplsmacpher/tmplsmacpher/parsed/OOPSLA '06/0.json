{"article_publication_date": "10-16-2006", "fulltext": "\n Eliminating Distinctions of Class: Using Prototypes to Model Virtual Classes DeLesley Hutchins LFCS, \nUniversity of Edinburgh D.S.Hutchins@sms.ed.ac.uk Abstract In mainstream OO languages, inheritance can \nbe used to add new methods, or to override existing methods. Virtual classes and fea\u00adture oriented programming \nare techniques which extend the mech\u00adanism of inheritance so that it is possible to re.ne nested classes \nas well. These techniques are attractive for programming in the large, because inheritance becomes a \ntool for manipulating whole class hierarchies rather than individual classes. Nevertheless, it has proved \ndif.cult to design static type systems for virtual classes, be\u00adcause virtual classes introduce dependent \ntypes. The compile-time type of an expression may depend on the run-time values of objects in that expression. \nWe present a formal object calculus which implements vir\u00adtual classes in a type-safe manner. Our type \nsystem uses a novel technique based on prototypes, which blur the distinction between compile-time and \nrun-time. At run-time, prototypes act as objects, and they can be used in ordinary computations. At compile-time, \nthey act as types. Prototypes are similar in power to dependent types, and subtyping is shown to be a \nform of partial evaluation. We prove that prototypes are type-safe but undecidable, and brie.y outline \na decidable semi-algorithm for dealing with them. Categories and Subject Descriptors D.3.1 [Software]: \nFormal De.nitions and Theory; F.3.2 [Theory of Computation]: Seman\u00adtics of Programming Languages General \nTerms Languages, Theory Keywords Abstract Interpretation, Features, Dependent Types, Mixins, Partial \nEvaluation, Prototypes, Singleton Types, Virtual Classes, Virtual Types 1. Introduction To a large degree, \nclasses and inheritance are the essence of OO programming. A class encapsulates a group of interacting \nmethods. Inheritance can be used to re.ne a class by adding new methods, or by overriding and extending \nexisting ones. Late binding ensures that whenever a method is overridden, all references automatically \npoint to the new version. In a similar fashion, a module encapsulates a group of interact\u00ading classes. \nHowever, mainstream OO languages do not provide a Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA 06 October 22 26, 2006, Portland, Oregon, USA. Copyright \nc . 2006 ACM 1-59593-348-4/06/0010. . . $5.00 mechanism for re.ning modules. C++ namespaces and Java \npack\u00adages are modules, and nested or inner classes can also be used to emulate modules to some degree. \nHowever, none of these mecha\u00adnisms support late binding. It is possible to add new classes to a module, \nbut it is not possible to re.ne or replace an existing class de.nition with something else. As has been \nextensively argued elsewhere [14] [48] [26], it is not possible to re.ne a group of mutually recursive \nclasses by deriving a new, parallel set with different names. The act of renaming the classes breaks \nthe type dependencies between them, thus requiring downcasts and run-time type checks. The situation \nis somewhat analogous to the Java collection classes before generics were introduced; downcasts are necessary \nbecause there is no way to express the appropriate type relationships. This issue is illustrated by the \nexpression problem , which has been discussed extensively in the literature [44] [27] [50] [37] [55]. \nThe expression problem concerns the design of an extensible inter\u00adpreter or compiler. A compiler manipulates \nabstract syntax trees, which consist of several different kinds of node e.g. literals, op\u00aderators, declarations, \netc. A compiler also de.nes several opera\u00adtions over such trees e.g. evaluation, pretty-printing, typing, \netc. A compiler extension must add a new kind of node, or a new oper\u00adation, without altering any de.nitions \nin the original source code. In a functional programming language it is easy to extend the compiler with \nnew operations, but hard to add new kinds of node. In a OO language it is easy to add new kinds of node, \nbut hard to add new operations, as is illustrated by the following example in Java: // core definitions \nabstract class Expr {}; class Literal extends Expr {int value ; }; class Plus extends Expr {Expr left \n; Expr right ; }; // extensions interface ExprEval {int eval (); }; class LitEval extends Literal implements \nExprEval {int eval () { return value ; }}; class PlusEval extends Plus implements ExprEval { int eval \n() { return ((ExprEval) left).eval() + ((ExprEval) right).eval(); }}; This example follows the interpreter \ndesign pattern, where each kind of node has a different class, and each operation is a method that must \nbe implemented by all the classes. Since the original classes cannot be modi.ed, this code de.nes a new \noperation within an interface. It then extends each of the node classes to implement the interface. The \ntrouble with this approach is that left and right have type Expr, not ExprEval. Whenever we wish to call \none of the new operations, we must insert a downcast to the appropriate type. The situation is somewhat \nanalogous to the Java collection classes before generics were introduced; downcasts are necessary because \nthere is no way to express the appropriate type relationships. One way to solve the expression problem \nin an elegant fashion is to use virtual classes [26]. The following example is pseudo\u00adcode for a Java-like \nlanguage. It encapsulates the entire group of classes as a module, and then re.nes them simultaneously \nby re.ning the module as a whole [28]. This mechanism allows us to add a method to each class in the \ngroup, without altering the the original module. Type dependencies within the module are preserved because \nclasses keep the same name. module EBase {abstract class Expr {}; class Literal extends Expr { int value \n; }; class Plus extends Expr { Expr left ; Expr right ; }; }; module EvalMod extends EBase {refine \nclass Expr {int eval (); }; refine class Literal { int eval () { return value ; } }; refine class Plus \n{ int eval () { return left.eval() + right.eval(); }}; }; Virtual classes are de.ned by analogy with \nvirtual methods. Just as it is possible for a derived class to override a virtual method, it is possible \nfor a derived module to re.ne a virtual class. Class re.nement obeys the same rules as ordinary inheritance; \nthe new classes inherit de.nitions from the old ones. Class names in Java are global identi.ers. As a \nresult, the re\u00adlationships between classes are hard-coded, and class hierarchies become brittle and dif.cult \nto extend. With virtual classes, class names are local references within the current module, and inheri\u00adtance \nbetween modules preserves the relationships between classes. EvalMod.Literal extends EvalMod.Expr, even \nthough it is not ex\u00adplicitly declared, because EBase.Literal extends EBase.Expr,and EvalMod inherits \nfrom EBase. In a fully general implementation of this concept, modules can also contain virtual nested \nmodules. Module inheritance thus has the potential to be truly scalable, since it can be used to manipulate \nstructures of arbitrary size. If a class library is encapsulated in a module, then it is possible not \njust to link against the library, but to customize and re.ne it to the needs of a particular application. \n1.1 History Virtual classes were .rst introduced in the Beta language, and were initially presented as \nan alternative to parameterized classes a.k.a. generics [39]. However, Beta was unable to do static typing \nfor virtual classes, and was forced to insert run-time checks. The Beta language also had a major restriction, \nwhich is that it was not possible to inherit from a virtual class. This rules out solutions like the \none above, which is an example of a higher-order hierarchy [27]. The gbeta language removed this restriction, \nand provided a static type system [24]. However, the type system for gbeta is complex, and has only recently \nbeen formalized [28]. Feature-oriented programming [8] [7], and multi-dimensional separation of concerns \n[44] are a different approach to the same problem. These solutions provide a mechanism for module re.ne\u00adment \nsimilar to the one shown above, but they do so by transform\u00ading code. Source code transformation happens \noutside the type sys\u00adtem of the target language, so features cannot be type-checked sep\u00adarately. 1.1.1 \nRecent work Interest in virtual classes has resurged in the past few years, and a number of formal models \nhave recently been published in the literature; see section 8 for more details. The biggest difference \nbetween them lies in the way they treat modules. There are three main approaches: 1. Modules are distinct \nentities, often called class groups . 2. Modules are classes. Virtual classes are static nested classes. \n 3. Modules are objects. Virtual classes are inner classes.  Using a distinct notion of class group \nmakes static typing eas\u00adier, but is somewhat unsatisfying because it ignores the similar\u00adity between \nmodule inheritance and class inheritance. The second two approaches present a uni.ed model of inheritance, \nbut differ in whether they regard virtual classes as attributes of classes, or attributes of objects. \nTreating virtual classes as attributes of objects is the most pow\u00aderful approach, because it allows an \narbitrary number of distinct class families to be created at run-time. However, treating virtual classes \nas attributes of classes is often more convenient, because there is no need to pass around instances \nof the enclosing classes. We treat virtual classes as attributes of objects, which is the most dif.cult \ncase to model formally. However, our solution uses a prototype model in which classes are objects, so \nit encompasses both of the latter approaches.  1.2 Challenges Formal models of virtual classes have \nproved dif.cult to build because classes are complex entities, which serve three distinct roles in OO \nprograms: 1. A class C is a generator for instances of the class. e.g. new C(...)  2. A class C is a \ngenerator for subclasses. e.g. class D extends C {... } 3. Classes denote types.  The .rst role presents \nno dif.culties; virtual classes behave much like virtual methods. The expression new myobj.C will lo\u00adcate \nthe constructor for C at run-time, by looking it up in the virtual method table of myobj. To ensure that \nthis operation is safe, re.ne\u00adments of a virtual class must share the same constructor signatures.  \nThe second role is harder, because re.nements to a virtual base class will affect any derived classes. \nSome re.nements may even invalidate derived classes. For example, assume that we have two virtual classes, \nC and D,where C declares a virtual method m, and D overrides m.If C is later re.ned such that m becomes \n.nal, then that re.nement will invalidate D. The solution we present in this paper detects such errors \nby re-checking the interface of all inherited de.nitions. The third role is the most dif.cult. In a method \ncall to myobj.m(), the code for m() is not determined until run-time, because it de\u00adpends on the dynamic \nvalue of myobj. Virtual classes behave simi\u00adlarly; the class denoted by the expression myobj.C depends \non the dynamic value of myobj. If virtual classes are attributes of objects, then the type system must \nnecessarily involve some form of dependent types types that depend on objects [38]. Dependent types \nare tricky because static safety requires that type judgments be performed at compile\u00adtime, even though \nthe precise value of myobj may not be known until run-time. 1.2.1 Recursive Modules The situation is \nfurther complicated by the pervasive presence of recursion. Each class in a module can potentially refer \nto all the others. The interface of a module is thus a set of mutually recursive type equations. Similarly, \nall of the methods and constructors in a module can potentially call each other. The implementation of \na module is thus a set of mutually recursive de.nitions. Inheritance relationships add an additional \ntwist, because inher\u00aditance is not recursive. The inheritance graph cannot have any cy\u00adcles, as would \noccur if classes A and B tried to inherit from each other. Nor should there be any in.nite descending \nchains, as might occur if a nested class tried to inherit from its enclosing class. Type theories for \nrecursive modules are not simple. The tradi\u00adtional approach is to untangle recursive types from recursive \nimple\u00admentations [22], but such untangling does not seem possible in the presence of dependent types. \nThe alternative is to permit general recursion at the type level, but that yields a theory that is undecid\u00adable. \nOur approach is to accept undecidability as a necessary evil, but to develop a practical and decidable \nsemi-algorithm for type checking.  1.3 Summary of Paper We present the DEEP calculus, which provides \ntype-safe support for virtual classes. Its semantics is based on a model of inheritance much like that \nin gbeta, which Ernst refers to as propagating combi\u00adnation [25]. We prefer the term used by Odersky \nand Zenger: deep mixin composition [55]. The most technically innovative aspect of DEEP is the fact that \nthe type system is based on prototypes rather than types. Prototypes are .rst-class objects; they exist \nat run-time, and they can be used in ordinary expressions. Prototypes are also types, however, and there \nis a subtype relation de.ned between them. Static type safety relies on subtyping, rather than typing. \nPrototypes allow us to treat modules, classes, methods, and ob\u00adjects in a uniform manner, as entities \nwhich exist at both compile\u00adtime and run-time. As such, they provide a natural mechanism for dealing \nwith dependent types. In a dependent type system, typing may involve the evaluation of object expressions. \nIn our prototype model, this is re.ected in the fact that the subtype relation has a copy of evaluation \nembedded in it. In fact, subtyping can be seen as a mixture of partial evaluation and abstract interpretation. \nSubtyping in DEEP is both nominal and structural. It is de.ned as a structural relation over terms, but \nterms can be paths of the form object name.class name, which means that nominal subtyp\u00ading is included \nas a special case. We show how standard approaches to type soundness can be adapted to prototypes, and \nwe prove that the type system for DEEP is sound. We also show that the type system is undecidable, and \nprovide an informal discussion of techniques to overcome this limitation. Despite the theoretical nature \nof the topic, our goal for this paper is not to be overly technical. Rather, we hope to present enough \ntheory to satisfy critics that there is some basis to our claims, while providing a discussion that is \nreadable by a wider audience. The organization of this paper is as follows. Section 2 provides an informal \ndiscussion of issues that motivated the design of DEEP. Section 3 introduces the DEEP calculus. Section \n4 gives some example code. Section 5 describes subtyping, and section 6 covers type safety and decidability. \nSection 7 describes extensions to the calculus. Section 8 covers related work, and section 9 concludes. \n 2. Informal Discussion Inheritance hierarchies are usually presented as a directed graph, where the \nnodes are classes and the arcs are inheritance relation\u00adships. In keeping with this idea, method lookup \nis frequently de\u00ad.ned as a graph traversal. Unfortunately, this metaphor becomes unwieldy when there \nare inheritance relationships between the modules themselves as well as the classes within those modules. \nFeature-oriented programming provides a compositional ap\u00adproach to modeling inheritance [8]. Features \nare essentially partial de.nitions of modules, and complex features are created by com\u00adposing simpler \nones. A compositional approach is convenient for a formal calculus, so DEEP is based on feature composition \nrather than inheritance. A deep mixin composition of modules is one which descends into the module hierarchy, \nand recursively composes classes, meth\u00adods, and nested modules which have the same name. It is de.ned \nas follows, where . is the composition operator: X a :: ax b :: bx Y a :: ay c :: cy Z a :: ax . ay \n. = b :: bx c :: cy In this example, X and Y are two modules, while a, b,and c are named de.nitions, \nwhich may be modules, classes, methods, or constants. X and Y each declare a partial de.nition, or frag\u00adment \nof a.When X and Y are composed together, the composition operator is recursively applied to compose the \ntwo fragments. Def\u00adinitions which exist in one module but not the other are copied over unchanged. Class \ncomposition is the same as module composition; the re\u00adsulting class inherits methods from both sources, \nand recursively composes methods with the same name. The composition of two methods or constants must \nmerge their implementations in some way, as will be discussed below. The :: syntax is DEEP notation for \nan open or virtual binding. It means that a must contain at least the de.nitions in ax,and at least those \nin ay.If a is a class, then it must be a subclass of both ax and ay. 2.1 Symmetric Composition DEEP provides \ntwo distinct operators for performing deep mixin composition. The .rst operator, written &#38; , stands \nfor symmetric composition, which is similar to the way traits are composed [45]. Symmetric composition \nobeys the following algebraic identities: t &#38;t = t Idempotence t &#38;u = u &#38;t Commutativity \n(t &#38;u)&#38;s = t &#38;(u &#38;s) Associativity These three identities constitute the algebraic de.nition \nof a semi-lattice, which means that there is a partial order de.ned over modules as follows: t<:u if \nand only if t &#38;u =t (De.nition of Subtyping) Subtyping is de.ned directly over modules, rather than \ntypes. The intuition is that every module provides a set of capabilities. A module t is a subtype of \nu if t provides all of the capabilities that u provides. Due to its relationship with subtyping, the \n&#38; operator can be viewed as a form of type intersection. Unlike traditional type systems, the capabilities \nof a module encompass not only its interface, but also its implementation. Two modules which have the \nsame interface, but provide different im\u00adplementations, are regarded as distinct entities; neither of \ntwo is a subtype of the other. Unfortunately, type intersection is not powerful enough to model OO inheritance. \nCommutativity and idempotence are strong requirements, and while it is easy to compose interfaces in \nthis manner, it does not seem possible to compose method implemen\u00adtations. If two classes in an intersection \nboth de.ne a method with the same name, then one de.nition must be abstract it cannot have a body. \n 2.2 Asymmetric Composition The &#38;* operator is used for asymmetric composition, which can be used \nto model features, mixin layers[46], and OO inheritance. Asymmetric composition is identical to type \nintersection, except that it also merges implementations. When two classes both im\u00adplement a method with \nthe same name, then the bodies of the two methods will be glued together in some way. The dif.culty of \nmerging implementations from two sources is well-known in OO programming as the multiple inheritance \nprob\u00adlem . The simplest way to resolve con.icts is by automatic overrid\u00ading de.nitions on the right-hand \nside of the composition over\u00adride those on the left. This does not merge two implementations, it simply \nreplaces one with the other. A more sophisticated approach is to use mixin composition [11] [10] [29]. \nDe.nitions on the right-hand side are functions which transform de.nitions on the left. Mixin composition \nis a generalization of the way overriding works in OO inheritance, where a subclass may refer to de.nitions \nin the superclass with the super keyword. Mixins are a powerful technique, but that power comes at a \ncost: Ordering Problems: Since mixin composition is not commuta\u00adtive, the order in which modules are \ncomposed is signi.cant. Re\u00adarranging the order will generate different behaviors, with effects that may \nrange from subtle to catastrophic. Duplicates: Since mixin composition is not idempotent, it is possible \nto apply the same transformation twice, as illustrated in the following example: let t =a &#38;*b let \nu =a &#38;*c let s =t &#38;*u (=a &#38;*b &#38;*a &#38;*c) This is merely a restatement of the classic \ndiamond problem with multiple inheritance. The implementation of a occurs twice within s, which may or \nmay not be what was intended. A number of OO languages, including CLOS, Dylan, and Python, linearize \nthe multiple inheritance hierarchy [6]. Lineariza\u00adtion eliminates duplicates, which is perceived as the \ngreater of the two evils, but it does not solve the ordering problem. The DEEP calculus does not perform \neither mixin composition or linearization by default. The core calculus is de.ned with simple overriding \nsemantics. However, this mechanism can be extended to more sophisticated kinds of composition without \naltering any of the type judgments presented in this paper. 2.3 Interfaces Asymmetric composition differs \nfrom type intersection only where implementations are concerned, which means that the two opera\u00adtors \nare identical with respect to interfaces. Every module t has a unique interface .t, such that t<: .t. \nLike interfaces in Java, the interface of a module only contains type signatures for methods and .elds; \nall implementations are stripped away. Interfaces obey the following identity: .(f &#38;*g) =.f &#38;.g \n Interfaces in DEEP serve much the same role as types in other languages 2.4 Virtual Types and Dependent \nTypes A type which is an attribute of an object is known as a virtual type. Static type safety for virtual \ntypes is illustrated by the following example, which is adapted from [49]. Consider a program which must \ndeal with several different kinds of animal, each of which eats a different kind of food. We model this \nby using a virtual type which holds the kind of food that the animal eats, as illustrated by the following \npsuedo-code: class Food { ... } ; class Meat extends Food { ... } ; abstract class Animal {type FoodType \n<: Food; // virtual type abstract FoodType favoriteFood (); abstract void eat (FoodType food ); } ; \nstatic void feed1(Animal aml) {aml.eat(new Meat()); // error! } static void feed2(Animal aml) { aml.eat(aml.favoriteFood()); \n// OK } A simplistic and unsound approach is to assume that since aml is an animal, and animals eat \nfood, then it is possible to feed any kind of food to aml. This is incorrect because it would allow us \nto feed meat to cows, or grass to people. Nevertheless, it is hard to come up with a good alternative, \nbecause if aml is some arbitrary animal, then there is no way of knowing at compile-time what kind of \nfood it eats! The code above circumvents this problem by endowing ev\u00adery animal with a favoriteFood which \nis guaranteed to be edible, even though its exact type is not statically known. The expres\u00adsion aml.favoriteFood() \nhas type aml.FoodType. The argument to aml.eat must also have type aml.FoodType, so function feed2 is \nwell-typed. The type aml.FoodType is a dependent type, because the object aml appears within the type \nexpression. Two types a.T and b.T are the same only if a and b refer to the same object. In this case, \nobject identity follows because the object aml is referred to by name. 2.5 Object equality and evaluation \nIn a dependent type system, proving that two types are equivalent may involve proving that two object \nexpressions are equivalent, and there is no way prove such equivalence in general. Every dependent type \nsystem must make a design decision about how to deal with object equality. Array types in C are a primitive \nform of dependent type, be\u00adcause the size of the array is an integer expression. Most modern compilers \ncan show that the type int [256] is the same as int [4* 64], because they evaluate constant integer expressions \nat compile-time. However, array sizes in C must be constant expressions involving built-in operators, \nwhich places a limit on what the type system is expected to prove. Like C, the DEEP calculus uses an \nintensional notion of equality which is based on evaluation. Two expressions are equal if they can be \nreduced to a common term. Unlike C, the type-checker may reduce arbitrary expressions at compile-time, \nnot just constant ones. The type system for DEEP can prove that (.x.x)(y)= y, because the left-hand side \nreduces to the right, even if y is not statically known. However, it cannot prove that x + y = y + x, \nwhere x and y are unknown variables; DEEP does not handle arithmetic identities. Because it may evaluate \narbitrary expressions at compile-time, the type system for DEEP is structured much like an online partial \nevaluation engine [35]. In fact, we use a technique similar to partial evaluation not only to prove type \nequivalence, but also to derive the types themselves. This technique is based on the idea of prototypes. \n 2.6 Prototypes Prototypes were proposed in the Self language as an alternative to classes [51]. In \na prototype-based system, objects are self\u00addescriptive. A prototypical object is one which implements \nsome default behavior. New objects are created by re.ning existing pro\u00adtotypes. Prototype re.nement differs \nfrom inheritance mainly be\u00adcause it is an operation over objects rather than classes, so it can occur \nat run-time. The DEEP calculus is a prototype-based system in this sense. Classes and modules are treated \nas ordinary objects which exist at run-time, and new classes are created by re.ning or composing existing \nones. The DEEP calculus is also prototype-based in a different sense: prototypes in DEEP can act as both \ntypes and objects. Unlike Self, DEEP is statically typed. There is a subtype relation de.ned over all \nobjects, and composition creates subtypes. Objects in DEEP may be only partially de.ned. An interface \nis an object which is fully abstract; it contains only type signatures for methods and .elds. An instance \nis an object which is fully concrete; every method has an implementation, and every .eld has a value. \nA class is somewhere in between it de.nes implementations for methods, but it may not de.ne values for \n.elds. Throughout the rest of this paper, we will refer to interface prototypes as types , and concrete \nprototypes as objects , but the calculus itself does not distinguish between the two. Composition in \nDEEP is used to create both subtypes and in\u00adstances. An instance of a type is a subtype of that type, \nwhich means that instances are leaves at the bottom of the inheritance hierarchy. For example: 3 <: Int \n<: Number <: Object true <: Bool <: Object In DEEP, all objects can act as types. A concrete value, like \nthe number 3,is a singleton type [47]; it represents the type of all integers which are equal to 3. In \naddition to treating objects as .rst-class types, DEEP treats types as .rst-class objects. The result \nof performing an operation on a type is just another type, e.g. 1+2 = 3 true &#38;&#38; Bool = Bool Int \n+2 = Int false &#38;&#38; Bool = false The intuition behind this mechanism is that interface types such \nas Int represent objects which are only partially de.ned. It is possible to perform computations with \nsuch objects, but the result may also be partially de.ned. The ability to perform computations with prototypes \nprovides a link between evaluation and typing. The bounding type of an ex\u00adpression can be calculated \nby substituting types for any unknown variables, and then evaluating the expression. In other words, \ntyp\u00ading is a form of abstract interpretation [21].  3. Syntax and Semantics The syntax and operational \nsemantics of DEEP are given in .gure 1. There are two basic constructs: functions and records. Functions \nare de.ned much the same as in other languages. Objects, classes, and modules are all encoded as records. \nFor the sake of clarity, the following discussion assumes that the core calculus has been extended with \ntypes Int and Bool,integer and boolean literals such as 0 and true, as well as the standard logical and \narithmetic operators. These objects are not built-in; they can be encoded using more primitive constructs. \n3.1 Functions A function is de.ned by the syntax .(x : t).u.The variable x is the argument, t is the \nargument type, and u is the body. As is standard practice, functions with multiple arguments are encoded \nby Currying: .(x, y, z).u is short for .(x)..(y)..(z).u  3.2 Records A record is de.ned by the syntax \n\u00b5x{d},where d is a (possibly empty) sequence d1 .. dn of labeled declarations, called slots.A record \nmay not have more than one slot with the same label. The self-variable x is an identi.er which refers \nto the enclosing record; it is equivalent to the this keyword in C++ or Java [1]. (Using an explicit \nname for this is helpful when dealing with nested records.) A slot is projected from a record using standard \nOO dot nota\u00adtion, as shown below. One slot can refer to other slots within the same record by means of \nthe self-variable x. let r= \u00b5x { a: Int =1; b: Int =2; c= x .a + x .b; } r.c -. r.a + r.b -. 1+2 -. 3 \n Slots use late binding. In the example above, x is not assigned a value until the slot c is actually \nprojected from the record. The de.nition of c thus acts like a simple method, rather than a constant. \nIf the values of a and b were overridden by composition, then the value of c would be affected accordingly. \nEvery record denotes a .xpoint. This .xpoint can be used to de\u00adclare recursive objects, including mutually \nrecursive functions and circular data structures, just like the letrec construct in functional languages. \nLate binding for slots has the same semantics as lazy evaluation in a letrec . The slots of a record \nhold prototypes, which can be either types or objects. This means that records can also be used to declare \nrecursive types, such as lists and trees. 3.3 Declarations Declarations serve two distinct roles. First, \na declaration de.nes an object, which is stored in the slot of a record. Second, a declaration establishes \na constraint which must hold in subtypes of that record. This dual role object + constraint is what \nallows records x, y, z ., l, m s, t, u ::= x .(x : t).t \u00b5x{ d}t(t) t.l t . t . t c, d, e ::= l :: t l \n= t l : t = u l : t = Variable Slot label Terms: variable function record application projection composition \ninterface Declarations: open/virtual binding .nal binding concrete .eld abstract .eld . ::= &#38; &#38;* \nv, w ::= .(x : t).t \u00b5x{ d} G ::= \u00d8 G,x . t . ::= <: . = Composition: type intersection asymmetric composition \nNormal Forms function record Contexts empty context variable declaration Type relations subtype exact \nsubtype type equivalence Notation: , where each declaration is terminated by a semicolon. [x . . t] \nu denotes the capture-avoiding substitution of the term t for the variable x within u. c . d -. e and \nc . d . e will compose declarations using -. and . , respectively. (See .gure 2) d is a permutation of \ne Term Equality: a-renaming of bound variables x,plus \u00b5x{ d} = \u00b5x{ e} Evaluation Context: E ::= [] \n| E.l | E(t) | v(E) | E . t | v . E    Reduction: t -. t t -. t. E[t] -. E[t] (E-CONGRUENCE) (.(x \n: t).u)(v) -. [x .. v] u (E-APPLY) declVal(d,t) \u00b5x{ d} .. -. [x .. \u00b5x{ d} ] t (E-PROJECT) declVal(l :: \nt, t) declVal(l = t, t) declVal(l : t = , t) declVal(l : t = u, u) .(x : t).u . .(x : t).s -. .(x : t). \n(u . s) (E-COMPOSEFUN) c . d -. e \u00b5x{ c}. \u00b5x{ d}-. \u00b5x{ e} (E-COMPOSEREC) . .(x : t).u -. .(x : t). . \nu (E-INTERFACEFUN) . \u00b5x{ d}-. \u00b5x{. d} (E-INTERFACEREC) Composition of sequences: c . d c . d def = e, \nwhere: dom(e)= dom(c) . dom(d) e. = 8 > < > : c. . d. if . . dom(c) n dom(d) c. if . . dom(c) and . .. \ndom(d) d. if . . dom(d) and . .. dom(c) Composition of declarations: c . d -. e (l :: t) . (l :: u) -. \nl :: t . u (DE-COMPOSE) e replaces d d . e -. e d overrides e d . e -. d (DE-REPLACE) (l = t) replaces \n(l = t) (l : t = ) replaces (l : t. = ) (l : t = u) replaces (l : t. = u ) (l = t) overrides (l :: u) \n(l : t = u) overrides (l : t. = ) d overrides e d replaces e Interface of declarations: . d def = e . \n(l :: t) def = l :: . t . (l = t) def = l = t . (l : t = ) def = l : t = . (l : t = u) def = l : t = \n(DE-INTERFACE1-4) Figure 1. Syntax and Operational Semantics and functions to serve as prototypes. There \nare three main kinds of declaration, which establish three different constraints: l :: t is an open \nor virtual declaration, which has an upper bound given by t. An open declaration can be specialized to \nany subtype of t. Virtual methods and virtual classes are de.ned using open declarations.  l= t is a \n.nal binding. A .nal binding cannot be specialized; all subtypes must have equivalent de.nitions.  l \n: t= u is a .eld. The term tis the range of the .eld, while uis the (optional) implementation, which \nmust be a subtype of the range. The implementation may be left unspeci.ed using the syntax l : t = , \nin which case the .eld is abstract. Fields with implementations are concrete.  The range of a .eld is \ninvariant; all subtypes must have the same range. The implementation of a .eld can be overridden in a \ncomposition, as will be discussed below.  3.4 Composition Composition is de.ned over both terms and \ndeclarations. The com\u00adposition of two records will compose declarations with the same label. Declarations \nare composed as follows. (The . symbol is a meta-variable which ranges over both &#38; and &#38;* .) \nIf both declarations have open bindings, then composition is recursively applied to terms: (l:: t) . \n(l:: u) -. (l:: t. u) If one declaration is more speci.c than the other, then the spe\u00adci.c one overrides \nthe general one. Final bindings override open bindings, and concrete .elds override abstract .elds. If \ntwo dec\u00adlarations are equivalent, then the one on the right replaces the one on the left.  When two \n.elds are composed with &#38;* ,  (e.g. (l: t= u)&#38;* (l: t= u )) then the implementation on the right \nreplaces the implementation on the left. The composition of two functions composes their bodies: .(x: \nt).u . .(x: t).s -. .(x: t).u. s Note: in the operational semantics, &#38; and &#38;* are treated identically. \nThe difference between the two only appears in the type system. The expression t&#38; uis not well-formed \nunless there is a valid intersection of the two terms. 3.5 Interfaces The main purpose of a .eld is \nto separate the interface of a record from its implementation. The expression . twill erase the imple\u00admentation \nof all .elds. Like . , . is recursively de.ned over both terms and declarations. It will erase the implementation \nof ev\u00adery .eld that could potentially be overridden by &#38;* . For example: .\u00b5x{ m:: \u00b5y{ \u00b5x{ m:: \u00b5y{ \na: Int =1; a: Int = ; }; -. }; ; b: Int =2; b: Int = } }  3.6 Function types In keeping with the prototype \nmodel, functions can act as types. Subtyping between functions is de.ned pointwise: given two func\u00adtions \nf and g, f<: g implies that f(a) <: g(a),for all a.For example: .(x: Int).x+ x<: .(x: Int).Int Two functions \nare compared by comparing their bodies, treating the variable xas a free variable with the given upper \nbound. The example above holds because x+ xis a subtype of Int if xis a subtype of Int. The prototype \n.(x : Int).Int serves the same role as the conventional arrow-type Int . Int. The argument type of a \nfunction is invariant (rather than con\u00adtravariant) in subtypes. This is because the composition of two \nfunctions will mix their bodies together. Since the body of a func\u00adtion may refer to its argument, relaxing \nthe type constraint would not be type-safe. 3.7 Record types Subtyping between records is done by comparing \nindividual slots. Final bindings and .elds specialize open bindings, and concrete .elds specialize abstract \n.elds. E.g. \u00b5x {\u00b5x { a:: Int; a :: Object ; b=0; b:: Int ; c=1; <: c=1; d: Int =2; d: Int = ; e= false \n; } } When comparing two records, (i.e. R<: S), the self-variable xis treated as a free variable which \nhas an upper bound given by R. A variable is equivalent to itself, so two expressions involving xare \nequivalent if xoccurs in the same place in both expressions. For example: \u00b5x {\u00b5x { a:: Int; a:: Object; \n <: b:: .(y: x.a). x.a; b:: .(y: x.a). x.a; } } This result may seem somewhat surprising. In the .rst \nrecord, b represents the arrow type Int . Int, whereas in the second record, it is Object . Object. The \n.rst de.nition of bis not a subtype of the second when projected from its enclosing record. Because of \nthis, the rules for subtyping state that if Rand Sare records, then R.l <: S.l only if R = S. The more \nusual assumption that R.l <: S.lif R<: S, is not type-safe if self-references occur in covariant positions. \n 4. Additional Examples This section contains some larger examples which illustrate how the DEEP calculus \ncan be used to emulate standard OO constructs, such as classes, methods, and generics. Along the way, \nwe will point out ways in which the DEEP calculus resolves some tricky typing issues. For these larger \nexamples, we use the following syntax sugar. The syntax method1(x: argType , ...) = body; method2(y: \nargType , ...): resultType = body;  is short-hand for: method1 = .(x: argType , ...). body; method2 \n: .(y : argType , ...). resultType = .(y: argType , ...). body; The examples in this section also follow \nthe convention that the variable gstands for the enclosing global scope. 4.1 Classes and inheritance \nClasses and methods are de.ned much as one might expect: \u00b5g{Point :: \u00b5 this{ x: Int = ; y: Int = ; rSquare \n: Int = this .x * this .x + this .y * this .y; equals(that : . this ): Bool = this.x == that.x &#38;&#38; \nthis.y == that.y; }; // inheritance Point3 :: g.Point &#38;* \u00b5 this{ z: Int = ; rSquare : Int = this \n.x * this .x + this .y * this .y + this .z * this .z; equals(that : . this ): Bool = this.x == that.x \n&#38;&#38; this.y == that.y &#38;&#38; this.z == that.z; }; // instantiation -- in Java this would be \n// Point origin = new Point3(0,0,0); origin : .g.Point = g.Point3 &#38;* \u00b5 this { x: Int =0; y: Int =0; \nz: Int =0; }; p1 : .g.Point = g.Point3 &#38;* \u00b5 this{ x: Int =1; y: Int =1; z: Int =1; }; // using \norigin as a prototypical object p2 = g. origin &#38;* \u00b5 this { y: Int =1; }; // self -types cp err = \norigin.equals(p1); // type error! cp ok = origin.equals(p2); // ok } This example de.nes a simple Point \nclass. It has three data members: x, y, z, and two methods: rSquare and equals. The mem\u00adbers of a class \nare immutable, so there is no difference between a data member and a method that takes no arguments. \nPoint3 is a class which inherits from Point. It adds a new .eld named z, and it overrides rSquare and \nequals with new de.nitions. There are two ways to create a point object. First, it is possible to instantiate \na class directly by using composition to assign values to data members. This is how origin and p1 are \nde.ned. Second, a new point can also be created by using an existing value as a pro\u00adtotypical object, \nand then overriding data members (or methods!) with new de.nitions. In the example above, p2 uses origin \nas a prototypical object. Notice that inheritance and instantiation are both performed with the same \noperation: &#38;*. This mechanism highlights the pro\u00adtotype model, in which instances are subtypes of \nclasses. 4.1.1 Interface Types Unlike typical OO languages, Point3 is not a subtype of Point,be\u00adcause \nit overrides the de.nitions of rSquare and equals. Subtyping between records includes the complete de.nition \nof all slots. In or\u00adder for one record to be a subtype of another, it must have the exact same implementation \nfor all methods. Instead, Point3 and origin are subtypes of .Point the inter\u00adface type of Point. This \nrelationship results from the identity intro\u00adduced earlier: t&#38;* u<: .t&#38; .u The distinction between \nclass objects and interfaces highlights the dual role that classes play in OO programs. Point is a generator \nfor both instances and subclasses, while .Point is the bounding type for objects that it generates. 4.1.2 \nSelf Types Another point of interest (pun intended) is the use of . this as a bounding type for the argument \nof equals. The expression . this is a self-type, which means the type of this . It is an upper bound \nfor all records which have the same interface as this. The expression . this emulates the MyType construct \nproposed by Bruce [13]. The expression cp err is not well-typed, because origin and p1 have an upper \nbound of .Point. There is thus no guarantee that they have the same interface. They both happen to be \n3D points in this example, but one could easily be overridden with a 2D point instead. However, it is \nsafe to compare origin and p2, because the type of p2 is . origin rather than .Point, and it is thus \nguaranteed to have the same interface. 4.2 Generics A generic class is a function that takes a type as \nan input, and produces a class as an output. Since functions in DEEP operate over prototypes, generics \ncan be implemented as ordinary functions. \u00b5g{ List (T: Object ) = \u00b5 this { isEmpty : : Bool ; head: T \n= ; tail: g.List(T) = ; }; nil (T: Object) = g. List (T) &#38; \u00b5 this { isEmpty = true ; tail: g.List(T) \n= g.nil(T); }; cons(T: Object, hd: T, tl: g.List(T)) = g. List (T) &#38; \u00b5 this { isEmpty = false ; \nhead: T = hd; tail: g.List(T) = tl;  }; } This is a fairly standard implementation of parametric polymor\u00adphism, \nin the informal sense of the word. The List class is parame\u00adterized by a type T. Every function which \noperates on lists (i.e. nil and cons) must also be parameterized by T. Some form of pattern matching \nwhich infers the appropriate Twould obviously be desir\u00adable in a practical implementation, but we do \nnot consider pattern matching in the core calculus. The only thing about these de.nitions which is peculiar \nto DEEP is the fact the type parameter Tis passed as an ordinary function argument. Traditional type \nsystems distinguish between functions over types, and functions over objects. The former are evaluated \nat compile-time, while the latter are evaluated at run-time. The DEEPcalculusonlyhasonekindoffunction:functionsover \nprototypes. In order to type-check the above code, the compiler will partially evaluate expressions of \nthe form List(T) at compile-time. Partial evaluation is an integral part of the type system. 4.3 Virtual \nTypes Virtual types have been proposed as an alternative to parametric polymorphism [48]. The following \nexample shows how an abstract array class can be de.ned and used. This example plugs the infa\u00admous type \nsafety problem with Java arrays. The following de.nition of arrays differs from the earlier list example \nbecause arrays have a covariant type parameter. An array of Int is a subtype of an array of Object. The \nsame is not true of lists: List(t) <: List(t ) only if t= t. \u00b5g{ Array = \u00b5 this { length :: Int; ElemType \n:: Object ; get(i: Int): this.ElemType = ; set(i: Int, e: this.ElemType): .this = ; } copyElem(a: g.Array, \nn: Int, m: Int): .a= a.set(m, a.get(n)); setElem(a: g.Array &#38; \u00b5x{ElemType = Float ; }, n: Int , f: \nFloat): .a= a.set(n, f); } An array holds a certain number of elements, all of which have an upper bound \ngiven by ElemType. The methods get(i) and set(i ,e) will get and set the ith element of the array. Since \nDEEP does not have a mutable heap, set returns a new array which has the same interface as the original. \n(Additional trickery, such as monads [52] or uniqueness types [5], can be used to avoid allocating a \nnew array.) The copyElem function will copy the value index n to index m. This routine is well-typed \nbecause get and set are both acting on thesamearray. Theexpression a.set requires an argument of type \na.ElemType a dependent type. The expression a.get(m) has type a.ElemType, so the types match up. There \nis practical problem with using covariant array types. Although it is safe to copy elements within the \nsame array, it is not safe to put elements from any other source into the array. The de.nition of setElem \ncircumvents this problem by giving ElemType a .nal bound of Float.Since a.ElemType is equivalent to Float,it \nis safe to put any .oating-point number into the array. 4.4 The Expression Problem: Our .nal example \npresents a solution to the expression problem in DEEP. This solution closely mimics the pseudo-code given \nin the introduction, but includes a bit more detail. We demonstrate that it is possible to add a new \nclass, add a new operation, and to mix the two extensions together. \u00b5g{// core definitions EBase = \u00b5m \n{ // empty class declaration Expr :: \u00b5 this {}; Literal :: m.Expr &#38;*\u00b5 this { value: Int = ; }; \nPlus :: m.Expr &#38;*\u00b5 this { e1 : .m. Expr =  ; e2 : .m. Expr = ; }; }; // add a new operation EvalMod \n= g . EBase &#38;*\u00b5m{ Expr :: \u00b5 this { eval: Int = ; }; Literal :: \u00b5 this { eval: Int = this.value; \n}; Plus :: \u00b5 this {eval: Int = this.e1.eval + this.e2.eval; }; }; // add a new type MultMod = g . EBase \n&#38;*\u00b5m{ Times :: m.Expr &#38;*\u00b5 this { e1 : .m. Expr =  ; e2 : .m. Expr = ; }; }; // combine the \ntwo extensions EvalMult = g.MultMod &#38;*g. EvalMod &#38;*\u00b5m{Times : : \u00b5 this {eval: Int = this.e1.eval \n* this .e2. eval ; }; }; }; EBase is a module with three nested classes Expr, Literal , and Plus, that \ntogether de.ne a simple syntax tree. Literal and Plus inherit from Expr. EvalMod is a module which extends \nEBase and adds a new method eval to all three classes. MultMod also extends EBase, and adds a new class \n Times which inherits from Expr. The EvalMult module combines these two extensions by com\u00adposing EvalMod \nwith MultMod. However, the pure composition (EvalMod &#38;*MultMod) has a gap in functionality because \nthe Times class does not implement the eval method. The de.nition of EvalMult .lls in this gap. 4.5 Limitation \n no indexed data types DEEP does have a major limitation. One of the main applications of dependent types \nto date has been reasoning about the sizes of data structures. Instead of ordinary lists, dependent type \nsystem can encode lists of length n,where nis natural number. Using this type, is is possible to prove \nthat operations such as map and reverse preserve the length of lists, that concatenating two lists will \nadd their lengths, etc. In contrast with other dependent type systems, such as DML [54] and Epigram \n[40], DEEP does not provide good support for types of this nature. It is certainly possible to extend \nthe de.nition of List given earlier with an integer parameter. However, in order to reason about sizes, \nthe type system must have knowledge of basic arithmetic identities, such as the commutativity and associativity \nof addition. List(n + m) should be the same type as List(m + n). DEEPdoes not handle suchidentities.This \nlimitationmeans that although the core of DEEP supports dependent types, in practice it is not able take \nfull advantage of it. 5. Subtyping Subtyping is the least relation between terms which is closed under \nthe de.nitions in .gure 2. Figure 2 de.nes three relations over terms; where . is a meta-variable that \nranges over all three. t<: umeans that tis a subtype of u. Subtyping (congruence): G . t. t G . t. uu. \nsuwf G . u=t (S-TRANS), G . t. s G . t=u (S-SYMM) G . t=u G . t. u (S-WEAKEN1-2) G . t. u G . t<: u \nG . t. t. ,u=u . (S-VAR), G . x=x G . t(u) . t(u) (S-APPLY) G . t=t. (S-PROJECT), G . t. .t G . t.l = \nt.l (S-IFACEINTRO) G . t. u G . t<: u (S-INTERFACE1-2) G ..t =.u G ..t<: .u G . t=t. u=u .  (S-COMPOSE) \nG . t.u = t. .u. G . t=t. G,x <: t. u. s  (S-FUNCTION) G . .(x: t).u . .(x: t).s dom(d)[.] dom(e) ...dom(e).G,x \n<: \u00b5x{.d}. d. . e  . (S-RECORD) G . \u00b5x{d} . \u00b5x{e} def def def [<:] = . [.]== [=]== Declaration subtyping: \nG . d. d G . d=e G . d. e (DS-WEAKEN1-2) G . d. e G . d<: e (DS-DECL1-6) G . t. u G . t=t. G . (l:: \nt) . (l:: u)G . (l: t=) =(l: t. =) G . t=u G . t=t. ,u=u . G . (l= t) =(l= u)G . (l: t= u) =(l: t. = \nu) G . t<: u G . t=t. G . (l= t) <:(l:: u)G . (l: t= u) . (l: t. =) Subtyping (reduction): G . t. t x. \nt.G (SE-VAR) G . x. t G . t. .(x: u ).s (SE-APPLY) G . t(u) . [x..u] s t.. \u00b5x{d}declType(.,d,.,u) (SE-PROJECT) \nG . t.. . [x..t] u declType(.,l:: t, .,t) declType(.,l= t, =,t) declType(.,l: t= ,<:,t) declType(.,l: \nt= u, <:,t) declType(.,l: t= u, =,u) G . t=t. G . .(x: t).u ..(x: t).s = .(x: t).(u.s) (SE-COMPOSEFUN) \nG,x <: \u00b5x{.e}. c.d. e (SE-COMPOSEREC) G . \u00b5x{c}.\u00b5x{d}= \u00b5x{e} .v-.w (SE-INTERFACE) G ..v=w G . (t&#38; \nu) = (u&#38; t) (SE-ISECTCOMM), G . (t&#38; u)&#38; s = t&#38;(u&#38; s) (SE-ISECTASSOC) G . t<: u t&#38; \nu<: t (SE-ISECTELIM1-2) G . t&#38; u=t G ..(t&#38;*u) =.t&#38; .u (SE-IFCOMPOSE) Checked composition: \nG . c.d. e G . (l:: t) .(l:: u) . (l:: t.u) G . e<: d G . d<: e ereplaces ddoverrides e G . d&#38; e. \ne G . d&#38; e. d G . e<: .d G . d<: .e ereplaces ddoverrides e G . d&#38;*e. e G . d&#38;*e. d  Figure \n2. Subtyping. (Note that . is a metavariable which ranges over <:, .,and =.) t=umeans that tis type \nequivalent to u. t=uif and only if t<: uand u<: t.  t. umeans that tis an exact subtype of u. t. uonly \nif t<: uand .t=.u.  Exact subtypes are used to prove that a class which inherits from a virtual class \nis well-formed. It is discussed in more detail in section 6.1. 5.1 Subtyping as Partial Evaluation Since \nterms in DEEP range over both types and objects, the = re\u00adlation not only de.nes equivalence between \ntypes, but also equality between objects. Moreover, equivalence is de.ned over arbitrary expressions, \nnot just values. Two expressions are equivalent if they can be reduced to a common term. The subtyping \nrules are split into two groups. The congruence rules, labeled S-*, compare terms which have the same \nshape. The reduction rules, labeled SE-*, mirror the de.nition of untyped reduction in the operational \nsemantics. As we will discuss shortly, the reduction rules mean that subtyping can be seen as a form \nof partial evaluation. Subtyping differs from untyped reduction in three main ways. First, composition \nis restricted in order to eliminate invalid compo\u00adsitions. The restrictions are: Functions cannot be \ncomposed unless they have equivalent ar\u00adgument types.  Records cannot be composed unless their slots \nhave compati\u00adble types. For example, the composition of \u00b5x{l =3;} and \u00b5x{l =4;} is illegal, because 3=.4. \n Second, subtyping includes some additional algebraic identities. Type intersection is commutative, \nassociative, and obeys the ab\u00adsorption law for semi-lattices. Third, subtyping can discard information. \nThe judgment t = u is similar to ordinary evaluation. It means that t can be reduced to an equivalent \nterm u (or vice versa). The judgment t<: u is similar to typing. It means that t can be simpli.ed to \nu,where u is an upper bound for t. Free variables can be simpli.ed to their upper bounds using rule SE-VAR. \nAny expressions that involve free variables can also be simpli.ed to an upper bound by applying the reduction \nrules. Although we refer to this mechanism as partial evaluation , it can also be regarded as a primitive \nform of abstract interpretation. To see how this works, consider the rule SE-PROJECT: If t<: \u00b5x{ l ::Int;}, \nthen t.l <:Int.  If t = \u00b5x{ l ::Int;}, then t.l = Int.  If t<: \u00b5x{ l =Int;}, then t.l = Int.  If t<: \n\u00b5x{ l :Int =3;} then t.l <:Int, and t.l = 3.  This de.nition serves as both a reduction rule, and a \ntyping rule. If we know the type of t, then we can .nd the type of t.l.If we know the exact value of \nt, then we can .nd the exact value of t.l. Most interestingly, we can also .nd the exact value of t.l \nif l is .nal bound, even if the only thing we know about t is its type. 5.2 True Partial Evaluation This \nability to derive exact values as well as upper bounds is the reason why we refer to this mechanism as \npartial evaluation rather than typing . Consider the following two de.nitions of a power function, which \ncomputes x n . \u00b5g{ powerT(n: Int , x: Int): Int = if (n == 0) then 1 else x * g. powerT (n-1,x ); powerE(n: \nInt , x: Int) = if (n == 0) then 1 else x * g. powerE (n-1,x ); pt = g.powerT(3,x); // has type Int \npe = g.powerE(3,x); // has type x*x* x*1 } Recall that the de.nition of powerT is syntax sugar for: powerT \n: .(n: Int ). .(x: Int). Int = ... This de.nition is a .eld, which means that powerT has an explicit \nbounding type: a function which ignores its arguments and returns Int. When the compiler type-checks \nthe expression powerT(3,x), it will apply this bounding type using rule SE-APPLY. The result of the application \nis Int, which is the type of the expres\u00adsion. In this case the process is very similar to what happens \nin an ordinary type system. The de.nition of powerE, on the other hand, is a .nal binding rather than \na .eld, so it has no bounding type other than itself. The compiler has no choice but to expand the body \nof powerE, and simplify the result to a value. In the process of doing so, it will reduce the if expressions, \nand expand further recursive calls. Assuming that x is a free variable of type Int, the .nal derivation \nis: g.powerE(3 ,x) = x* x* x*1 <: Int This derivation yields the same upper bound as the one for powerT, \nbut it has partially evaluated the power function in the process. Since g.powerE(3,x) is provably equivalent \nto x*x*x*1,the latter can be substituted for the former in compiled code. Limitations The price that \nmust be paid for integrating a partial evaluator into the type system is loss of decidability. If the \ntype checker is allowed to expand recursive function calls, then there is no guarantee that type checking \nwill terminate. In section 6.9, we sketch an algorithm that ensures termination by preventing the compiler \nfrom entering recursive calls. However, this restriction would make the de.nition of powerE illegal. \nAs with dependent types, DEEP possesses the machinery to per\u00adform partial evaluation, but is currently \nunable to take full advan\u00adtage of it. 5.3 Nominal Subtyping The subtype relation is de.ned over all terms, \nnot just normal forms. One bene.t of de.ning subtypes in this way is that the nominal typings used in \nmost OO languages can be seen as a special case of structural comparisons between terms. Featherweight \nJava [32] is a good example of how nominal sub\u00adtyping is typically implemented in mainstream OO languages. \nA program in featherweight Java consists of a pair (CT,e),where CT is a global class table, and e is \nan expression. Types in feather\u00adweight Java are the names of classes in the table. Subclass relation\u00adships \nare read directly from the table, which is .xed. The DEEP calculus does not use a global class table. \nInstead, subtype relationships are inferred from the local typing context. To see how nominal subtyping \nworks in practice, consider the following code, which is an excerpt from the Point example given earlier: \n\u00b5g{Point :: \u00b5 this { ... } ; // inheritance Point3 :: g.Point &#38;* \u00b5 this { ... } ; } The name of a \nclass is a path of the form x.l1.l2...ln.Inthe code above, g.Point and g.Point3 are class names. Both \nof them are declared as virtual classes, so their exact de.nitions are not statically known. However, \nit is possible to infer a subtype relation between the two by comparing paths. We prove that .g.Point3 \n<: .g.Point as follows: .g.Point3 <: .(g.Point &#38;*{...}) SE-PROJECT,SE-VAR =.g.Point &#38;.{...} SE-IFCOMPOSE \n<: .g.Point S-ISECTELIM2 This derivation expands g.Point3 to its de.nition by .nding the type of g in \nthe local context. The remaining steps exploit the relationship between interfaces and compositions. \nThe derivation is nominal because it only compares paths; at no point is there any need to compare records. \n5.4 Match Subtyping Subtyping between records in DEEP is slightly different from that traditionally used \nin the literature [19]. A record \u00b5x{d} is a re\u00adcursive structure. As such, every record has an in.nite \nexpansion denoted by the .xpoint of the record. In a traditional type system, subtyping between recursive \nstructures is coinductively de.ned as a comparison between in.nite expansions. In DEEP, however, a comparison \nbetween \u00b5x{d} and \u00b5x{e}, does not compare the in.nite expansions of the two records. In\u00adstead, it compares \ntheir de.nitions, where x is taken to be a free variable with an upper bound of \u00b5x{.d}. If two records \nare in a subtype relation, then they have the same recursive structure [19]. Bruce calls this mechanism \nmatch subtyping [13]. Match subtyping is not ordinarily a sound basis for a static type system unless \nthat type system supports some form of dependent types. In a non-dependent type system, the type of a \nterm can depend only on the static types of its subterms. This restriction leads to the following typing \nrule for projecting slots from records. (The syntax here assumes that T and U range over types, X is \na type variable, and D is a sequence of declarations of the form l : U). G . t : T, T = \u00b5X{D; l : U; \n}G . t.l : [X .. T ] U (non-dependent typing) This de.nition unfolds the recursive type T by replacing \nall occurrences of the self-type X with T . The type T is the static type of the term t. The static type \nis only an upper bound for the exact type [13] of t, which is not necessarily known at compile\u00adtime. \nWith this rule, the use of match subtyping would lead to a type error if X occurs in a contravariant \nor invariant position, such as the argument type of a method. To see why this creates a problem, consider \nthe following Java\u00adlike pseudo-code. class Point \u00b5X {... Bool equals (X that ) {... } } class Point3 \nextends Point \u00b5X { ... } Point origin = new Point3(0,0,0); // error Point p1 = new Point (1 ,1); ... \norigin.equals(p1); ... // unsafe call In this example, the origin variable has a static type of Point. \nThe static type of origin .equals is a function from Point . Bool, and the compiler would therefor judge \nthat origin .equals(p1) is well-typed. At run-time, however, origin has an actual type of Point3, which \ncannot be compared with a 2D point. The only way to avoid this situation in a traditional type system \nis to ensure that Point3 is not a subtype of Point, which would make the de.nition of origin ill-typed. \n5.5 Dependent Types Compare the non-dependent type rule above with the dependently\u00adtyped de.nition used \nin DEEP: G . t<: \u00b5x{d; l :: u; } SE-PROJECT G . t.l <:[x . . t]u This de.nition replaces all occurrences \nof the self-variable x with the term t. This replacement is safe for use with match sub\u00adtyping, because \nit does not discard any information about the exact run-time type of t. Referring back to the earlier \nPoint example, we have: \u00b5g{Point :: \u00b5 this{equals(that : .this ): Bool = ...; }; Point3 :: g.Point &#38;*\u00b5 \nthis { ... }; origin : .g. Point = ... p1 : .g. Point = ... ... g.origin.equals(p1) ... // type error \n } In this example, the static type of g. origin .equals is a function: .(that: .g.origin). Bool. Passing \np1 as an argument to this call will result in a type error unless p1 is a subtype of .g. origin,which \nit is not. As a side bene.t, the type error now occurs at the site of the unsafe call, rather than at \nthe declaration of origin. Inadditiontodependentrecordtypes, DEEPsupportsdependent function types. A \ndependent function type is one in which the value of the argument appears in the type of the result. \nThe Arrayexample shown earlier illustrates the use of such functions. 6. Type Safety In an ordinary type \nsystem, a term is considered well-typed if a type can be assigned to it. In DEEP every term is already \na type, so the notion of being well-typed does not make much sense. Instead, terms are judged to be well-formed. \nTerms which are well-formed cannot go wrong ; that is, they cannot generate type errors at run\u00adtime. \nA type error is one of the following events: A program attempts to call a function with a value of the \nwrong type.  A program attempts to project a slot that does not exist.  A program attempts to compose \ntwo functions with different argument types.  A program attempts to compose two records, but the slots \nhave incompatible de.nitions.  Ensuring that function calls are well-typed, and that slots exist is \nstraightforward. However, verifying composition turns out to be much more dif.cult. Loosely speaking, \na record is considered to be well-formed if the logical constraints established by its declara\u00adtions \nare satis.able. Given this de.nition, composition has a most unfortunate property: The composition of \ntwo well-formed terms is not necessarily well-formed. There are several ways in which a composition may \nbe ill\u00adformed. Two records may de.ne different .nal bindings for the same slot, or they may de.ne different \nranges for the same .eld. A record is also ill-formed if there are cycles of dependencies between its \nslots that prevent the proof of well-formedness from terminating, and such cycles can be introduced by \ncomposition. All these cases are illustrated in the following example: \u00b5x{a=3; \u00b5x{a=4; b: Bool= ; b: \nInt = ; c:: \u00b5y{}; . c:: x.d; d:: x.c; d:: \u00b5z{}; }} 6.1 Well-formedness The rules for well-formedness \nare given in .gure 3. A function application t(u) is well formed if t is a well-formed function, and \nu is a well-formed term of the appropriate type. A record projection t.l is well-formed if t is a well-formed \nrecord and the slot l exists. The rules for composition and intersection are more subtle. A composition \nt &#38;* u is well formed if .t &#38; .u is well-formed. Intuitively, this follows from the fact that \nthe &#38;* operator will override .eld implementations. It is not possible for there to be a type clash \nbetween the implementations of two .elds, because one simply overrides the other. All type clashes must \noccur in the Well-formed terms: twf x. t.G (W-VAR)G . xwf G . twf,uwf G . t<: .(x: u ).s, u<: u . (W-APPLY) \nG . t(u) wf G . twf,t<: \u00b5x{d},l.dom(d) (W-PROJECT) G . t.lwf G . twf,uwf G . t&#38; u=s, swf (W-ISECT) \nG . t&#38; uwf G .twf G ..t&#38; .uwf (W-INTERFACE) G ..twf G . t&#38;*uwf (W-COMPOSE) G . twf, .t&#38;*v=s, \nswf (W-INHERIT) G . t&#38;*vwf G . twf G,x <: t. uwf (W-FUNCTION) G . .(x: t).u wf ...dom(d). G,x. \u00b5x{.d}. \nd. wf (W-RECORD) G . \u00b5x{d}wf Well-formed declarations: dwf G . twf G . twf (W-DECL1-2) G . (l:: t) \nwf G . (l= t) wf wk(G) . twf (W-FIELD1) G . (l: t= ) wf wk(G) . twf,uwf,u<: t (W-FIELD2) G . (l: t= \nu) wf wk(\u00d8)= \u00d8 wk(G,x. t)= wk(G),x <: t Figure 3. Well-formedness interface, so if the interface of \nthe composition is well-formed, then the composition as a whole is well-formed. The rule for intersection \nstates that a term t&#38; uis only well\u00adformed if it is equivalent to some other well-formed term. That \nother term cannot be an intersection, or the proof will fail to terminate. Referring back to the rules \nfor subtyping, there are only two ways in which an intersection can be eliminated: G . t<: u (Absorption) \nG . t&#38; u=t G . t=vt,u=vu,vt &#38; vu =w (Reduction) G . t&#38; u=w 6.2 Instantiation Absorption handles \nthe case of pure specialization, where one term is a direct subtype of the other. When used with &#38;* \n, it also handles class instantiation. A class is instantiated by overriding existing .elds with new \nimplementations. Consider the following composition: g. Point3 &#38;*{ x: Int=0; y: Int=0; z: Int=0; \n}; In this case, x, y,and z are already de.ned within g.Point3,soit is possible to prove that: .g.Point3 \n<: .{x: Int =0;y: Int =0;z: Int =0; } and the composition is therefore well-formed. In other words, in\u00adstantiating \na virtual class is an operation which can be safely per\u00adformed at run-time. 6.3 Inheritance Reduction \nis used to handle inheritance. A composition is t.uis well-formed if it can be partially-evaluated to \na well-formed record. Since both partial evaluation and the proof of well-formedness are done at compile-time, \nthis means that inheritance is a compile\u00adtime operation. DEEP is no different from other statically-typed \nOO languages in this regard. DEEP also provides a faithful model of feature composition, which is likewise \nperformed by generating code at compile-time. The rule W-INHERIT handles the common syntax for inheri\u00adtance \nwhich is used throughout the examples in this paper. The right-hand side of the composition is a literal \nrecord which re\u00ad.nes some superclass. The declarations in this record can only be understood within the \ncontext of the superclass, so the composi\u00adtion should be performed before the record is checked for well\u00adformedness. \nThis rule could be removed without changing the fun\u00addamental expressiveness of the system, but it makes \ncode less ver\u00adbose by eliminating redundant declarations. 6.4 Exact Types Unfortunately, the use of partial \nevaluation places a strong limit on inheritance. In order to verify that t&#38;*uis well-formed, both \n.t and .umust be known up to equivalence. Without some additional extension, it would only be possible \nto inherit from a class which is statically known i.e. one which is .nal bound. That would rule out \nthe possibility of inheriting from a virtual class. In order to overcome this problem, DEEP introduces \nan exact type relation between terms, which is written . . The judgment t. uimplies that t<: uand .t=.u. \nIf a term has an exact type which is statically known, then the interface of that term is known up to \nequivalence, and it is possible to prove that compositions involving that term are well-formed. Furthermore, \nrule W-RECORD states that a record \u00b5x{d} is well-formed if its declarations are well-formed under the \nassump\u00adtion that x . \u00b5x{.d}. In other words, when verifying a class C, instead of assuming that this \nis a subtype of C, we assume that this has exact type C. Since the enclosing record has an exact type, \nany nested virtual classes also have exact types. It is safe to inherit from a virtual class. Verifying \na class Cunder the assumption that this . Censures that all instances of C are valid. It is thus safe \nto create instances of C at run-time. Unfortunately, subclasses of C may invalidate certain declarations. \nConsider the following example: \u00b5g{ Mod1 = \u00b5 thi s { A: : { a: : Int ; } ; B: : th is .A &#38;*{ a = \n4; }; } ; Mod2 = g.Mod1 &#38;* \u00b5 this { A:: { a=3; }; // error -- B is now invalid }; } In this example, \nMod1 contains two classes A and B,where B inherits from A. Inheriting from a virtual class is a potentially \ndangerous operation, because the interface of Ais not .xed. Nev\u00adertheless, exact types allow us to prove \nthat Mod1 is well-formed. However, when Mod2 extends Mod1 we have a problem. Mod2 changes the de.nition \nof A.a from a virtual binding to a .nal binding. The de.nition of A is still okay, but the inherited \ncopy of Bis now invalid. This error will be detected at compile-time because inheritance is a compile-time \noperation. The only way to verify Mod2 is to generate the complete record, and check all declarations, \nincluding declarations which are inherited from Mod1. We check the de.ni\u00adtion of B when it is .rst declared \nwithin Mod1, and then re-check the interface of B again within Mod2. 6.5 Separate Compilation At .rst \nglance, this might seem like a bad idea, since appears to rule out the possibility of separate compilation. \nHowever, the type sys\u00adtem only needs to re-check the interface of inherited declarations. Field implementations \nare checked once at the point where they are initially declared. Consequently, well-formedness for .elds \nis performed within a weaker context in which this <: C, rather than this . C. Using a weaker context \nensures that the im\u00adplementation of .elds can be safely inherited by subclasses without re-checking them. \n6.6 Summary It is safe to inherit from a virtual class. However, it is not safe to inherit from a class \nwhich is stored in a .eld, or passed as the argument to a function, because the exact type of such a \nclass is unknown. It is always safe to instantiate a virtual class, regardless of whether it has an exact \ntype. The use of exact types means that every subclass has to re-check all of the declarations that it \ninherits from super-classes. However, it does not need to re-check any implementations that it inherits. \nDEEP thus supports separate compilation of modules. 6.7 Transitivity Elimination Before moving on to \nthe formal proof of type safety, there is one more technical issue regarding subtyping that needs to \nbe addressed. Figure 2 de.nes the subtype relation in a declarative manner. This presentation is more \nconcise, but it does not specify an algo\u00adrithm for determining whether one term is a subtype of another. \nAs it turns out, the subtype relation must be split into two different al\u00adgorithms, because a proof of \nwell-formedness uses the relation in two distinct ways. First, there is the obvious use: subtyping compares \nterms. Given two terms tand u, we wish to know whether t. u.( . is a meta\u00advariable that ranges over <:, \n.,and =.) Second, subtyping is used as a replacement for typing. Given a single term t, we wish to .nd \nthe type of t a minimal upper bound vsuch that t<: v. This judgment is used in rules W-APPLY and W-PROJECT. \nDue to lack of space, we do not present a full de.nition of both algorithms here. The full de.nition \nis available as an appendix in the electronic version of this paper; what follows is a brief sketch. \nThe algorithmic de.nition splits subtyping into two relations: . . and . . The judgment G .A t . u is \nan algorithmic com\u00adparison between two terms, and it contains the subtype congruence rules (S-*). As \nusual, the main challenge of de.ning the algorithm is eliminating the rules for symmetry and transitivity: \n G . u= t G . t. u, u. s, uwf (S-SYMM), G . t= u G . t. s (S-TRANS) Transitivity involves guessing a \nsuitable u.Even worse, it involves guessing a u which is well-formed. The proof of well\u00adformedness involves \nsubtyping, and that leads to a circular de.ni\u00adtion. To overcome this problem, we replace the rules for \nsymmetry and transitivity with the following de.nitions: .. G .A t. u, u. s G .A t. u, s= u G .A t. s \nG .A t. s . The judgment G .A t . u contains the subtype reduction rules (SE-*). These rules have the \nadvantage that they can be read from left to right, just like untyped reduction, so there is no need \nto guess u. The only reduction rule that is not included is SE-ISECTELIM2, because it discards information \nand introduces a non-determinism. . The judgment G .A t . u provides a concrete algorithm for performing \ntyping and partial evaluation. It also has the following desirable properties: 1. It is con.uent. .. \n2. If t. ... . v,then vis the minimal upper bound of t. . 3. If twf and t. t,then t. wf. The third property \nis especially important, since it allows us to eliminate the circular dependency between the judgments \nfor subtyping and well-formedness. We do not have space for a formal proof here, but it is essentially \nthe same as the proof of type safety below. 6.8 Progress and Preservation We give a full proof of type \nsafety using the standard techniques of progress and preservation. [53]. The canonical small-step preservation \nproof states that if t: T and t -. t. then t. : T.In DEEP there is no typing judgment, so we prove instead \nthat if twf and t-. t,then t= t. and t. wf. This de.nition is a faithful interpretation of the traditional \nmeaning of type-safety. If t= t,then t<: vimplies that t. <: v, for any v. Thus, no matter what bounding \ntype we assign to a program, that bounding type will be preserved under evaluation. LEMMA 1 (Weakening). \nIf G . uwf,u. sand x.. G,then G,x <: t. uwf,u. s Proof: straightforward induction on the derivations \nfor subtyp\u00ading and well-formedness. LEMMA 2 (Narrowing). If G,x <: t. uwf,u. s and G . t. wf,t. <: t \nthen G,x <: t. . uwf,u. s This lemma states that judgments about subtyping and well\u00adformedness which \nare made in a general context still hold in a more speci.c context. Proof: by induction on the derivations \nof subtyping and well\u00adformedness. By lemma 1 and S-TRANS, every judgment of the form x<: tcan replaced \nwith a judgment of the form x<: t. <: t. LEMMA 3 (Substitution). If G,x <: t. uwf,u. s and G . t. wf,t. \n<: t, then G . [x.. t]uwf, [x.. t]u. [x.]s. . t Proof: by induction on the derivations for subtyping \nand well\u00adformedness. Every judgment of the form x = x can be replaced with t. = t, every judgment of \nthe form x<: t can be replaced with t. <: t, and every judgment of the form x wf can be replaced with \nt. wf. LEMMA 4 (Inversion of subtyping). If G . v<: \u00b5x{d} then there is a proof of that fact which ends \nin S-RECORD (i.e. v is a record). If G . v<: .(x : t).u, then there is a proof that fact which ends in \nS-FUNCTION (i.e v is a function). Proof: This critical result is dif.cult to prove in the declarative \nsystem, but follows immediately in the algorithmic system from elimination of transitivity. See section \n6.7. LEMMA 5 (Subterms are well-formed). If G . E[u] wf and u .u wf = v,then G . Proof: by inspection \nof well-formedness, and induction on the structure of E[u]. LEMMA 6 (Replacement). If G . E[t] wf,t = \nu, and u wf, then G . E[t] = E[u], and E[u] wf. Proof: E[t] = E[u] by inspection of the subtype relation, \nand induction on the structure of E[t]. E[u] wf by induction on the derivation for E[t] wf. LEMMA 7 (Composition). \nIf G . \u00b5x{c} <: \u00b5x{d} then \u00b5x{c} &#38; \u00b5x{d}-. \u00b5x{e} such that \u00b5x{e}= \u00b5x{c}. If G . \u00b5x{.c} <: \u00b5x{.d} \nthen \u00b5x{c} &#38;* \u00b5x{d}-. \u00b5x{e} such that \u00b5x{.e}= \u00b5x{.c}. Proof: This lemma holds for records if it \nholds between dec\u00adlarations. If c. &#38; d. -. e. by DE-COMPOSE,then e. = c. by SE-ISECTELIM1. If c. \noverrides d,then e. = c.If d. replaces c, then we see by inspection that c. <: d. implies c. = d.The \nproof for &#38;* is similar, since &#38;* and &#38; are identical with respect to interfaces. THEOREM \n1 (Progress). If \u00d8. t wf then either t is a value, or t -. t. for some t. . Proof: By induction on the \nderivation of t wf. Case t = E[u],and u . = v. By lemma 5, u wf. By the induction hypothesis, u -. \nu ,and t reduces by E-CONGRUENCE.  Case W-APPLY t = v(w). By lemma 4, v is a function, and t reduces \nby E-APPLY.  Case W-PROJECT t = v... By lemma 4, v is a record with a slot .,and t reduces by E-PROJECT. \n Case W-ISECT t = v &#38; w. An intersection is well-formed only if it can be eliminated, and that \ncan happen in one of two ways:  (1) v &#38; w = v by SE-ISECTELIM1, given that v<: w.By lemma 4, v and \nw must either both be records, or must both be functions. If they are both records, then t reduces by \nlemma 7. If they are both functions, then t reduces by E-COMPOSEFUN. (2) If v &#38; w = w . by SE-COMPOSEFUN/REC,then \nv &#38; w -. w . by E-COMPOSEFUN/REC.   Case W-COMPOSE and W-INHERIT Similar to W-ISECT; the same lemmas \napply.  Case W-INTERFACE t = .v. .v can always be reduced by E-INTERFACEFUN/REC.  THEOREM 2 (Preservation). \nIf G . t wf,t -. t. then G . t. wf,t = t. Proof: By induction on the derivation of t wf. Case t = E[u],and \nu -. u . . By lemma 5, u wf. By the induction hypothesis, u = u . and u . wf. E[u] = E[u ],and E[u ] \nwf by lemma 6.  Case W-APPLY t = v(w). We know v must be a well\u00adformed function. v(w) = t. by SE-APPLY. \nt. wf by lemma  3. Case W-PROJECT t = v... We know v must beawell\u00adformed record. v.l = t. by SE-PROJECT. \nt. wf by lemma 3.  Case W-ISECT t = v &#38; w. The intersection can be elimi\u00adnated in one of two ways: \n (1) v &#38; w = v by SE-ISECTELIM1, given that v<: w.By lemma 4, v and w must either both be well-formed \nrecords, or must both be well-formed functions. If they are both records, then by lemma 7, v &#38; w \n-. t, such that t. = v.Since v wf, it follows that t. wf. If v and w are functions, then v&#38;w = t. \nby SE-COMPOSEFUN. Moreover, the body of v must be a subtype of the body of w,so the intersection of the \ntwo bodies is well-formed.  (2) v &#38; w = t. by SE-COMPOSEFUN/REC.Wealreadyhavea proof that t. wf. \n  Case W-COMPOSE and W-INHERIT Similar to W-ISECT. In the case of record composition how\u00adever, the \nprevious line of reasoning shows that \u00b5x{c} &#38;* \u00b5x{d}-. \u00b5x{e}, such that \u00b5x{.e} wf (it only veri.es \nthe interface). Every .eld implementation in e is well-formed in the context of either \u00b5x{c} or \u00b5x{d}, \nand is thus well-formed in the context of \u00b5x{e} by lemma 2.  Case W-INTERFACE t = .v. .v = t. by SE-INTERFACE. \nIf v is a record, then d. wf implies .d. wf for all .. If v is .(x : u).s,then s wf implies .s wf by \nW-INTERFACE.  6.9 Decidability and Recursion THEOREM 3 (Decidability). The type system of DEEP is unde\u00adcidable. \nProof: Evaluation of a term may not terminate because records allow general recursion. Subtyping is undecidable \nbecause sub\u00adtyping includes evaluation. (By theorem 2, t -. t. implies that t = t.) Well-formedness depends \non subtyping, so all judgments are undecidable. . The fact that the type system is undecidable is not \nnecessarily a problem, so long as a decidable semi-algorithm exists which captures the cases that we \nwish to model namely systems of mutually recursive virtual classes. We present an informal outline of \nsuch an algorithm, but do not provide any proofs. Our strategy uses .elds to ascribe types to recursive \nimplemen\u00adtations. Consider the following non-terminating de.nition: \u00b5g{ inf = g.inf + 1; } This record \nis not well-formed because g. inf has no bounding type there is no value v for which g. inf <: v and \nit can therefor not be used as an argument to + . When the compiler attempts to .nd such a bounding type, \nit will fail to terminate. This is an example of a dependency cycle the bounding type for g. inf depends \non g. inf. Cycles can be broken by hiding recursive de.nitions within .elds. The following de.nition \nis well-formed because inf is given an explicit upper bound of Int. \u00b5g{ inf: Int = g.inf + 1; } ; Surprisingly \nenough, regular recursive types such as lists and trees do not create cycles: \u00b5g{ IntList = { head :: \nInt ; tail :: g. IntList ; }; }; The above de.nition is well-formed because IntList is already de.ned \nas a value, and therefore does not need to be reduced. (The slots of a record use lazy evaluation). Nevertheless, \nit is possible to create an in.nite chain of dependencies using a list-like structure: \u00b5x{ n: Int =0; \nsucc =x &#38;*{n: Int =x.n +1; }; last = x.succ.last; } It is the de.nition of last, not the de.nition \nof succ,which fails to terminate. The de.nition of succ has an upper bound of . x, which can be simpli.ed \nto a value. Once again, we break the chain by hiding the recursive de.nition behind a .eld: ... last: \nInt = x.succ.last; ... 6.9.1 Eliminating unsafe recursion The above examples demonstrate that many programs \nfor which type-checking fails to terminate can be transformed into well\u00adformed programs by adding type \nannotations. A practical compiler should detect places where annotations are required (or might be required) \nand issue errors rather than stepping into an in.nite loop. A practical compiler can be constructed with \ntwo restrictions: Recursive calls are not allowed in the interface of functions and records.  It is \nnot possible to project the implementation of a .eld during type-checking.  A close look at rule SE-PROJECT \nreveals that whenever a .eld is projected from a record, the type-checker has a choice. It can choose \nto project the range of the .eld, or it can choose to project the implementation. We force it to always \nproject the range. Detecting recursive calls is not unduly dif.cult. A cycle is created by a path x.l1...ln \nwhich points to the slot that is cur\u00adrently being type-checked. To eliminate such cycles, we use an old \ntrick from lazy languages. A slot is temporarily overwritten with a black hole value while it is being \ntype-checked, and any term which partially evaluates to black hole is an error. Detecting in.nite chains \nrequires a bit more subtlety, because recursive types (e.g. lists and trees) should remain legal. A recur\u00adsive \npath is one which points to an enclosing record or function. Such paths are well-formed, and it is legal \nto use them as bounding types. This makes it possible to perform nominal subtyping within a set of mutually \nrecursive classes. However, it is not possible to expand a recursive path to a value, which makes it \nillegal to call an enclosing function, or to inherit from an enclosing record. By eliminating recursive \ncalls in the interface, we guarantee that the partial evaluation of any term t will terminate to yield \na value v, such that t<: v. Partial evaluation proceeds as normal, but only the ranges of .elds are accessible, \nso a non-recursive bounding type is substituted for every potentially recursive call. This restricts \nthe precision of the partial evaluation engine (see section 5.2), but it yields a terminating algorithm. \nThis technique also ensures that the subtyping and well-formed\u00adness judgments terminate. If recursive \npaths are not expanded, then recursive applications of . or wf are always invoked ona smaller term. 7. \nExtensions The most obvious limitation of DEEP is that the core calculus only supports simple overriding. \nIt is not possible for a method m(...) in a subclass to call super.m(...), which is obviously a crippling \nrestriction. We eliminate this restriction as follows. Instead of de.ning .elds with the syntax l : t \n= u,we use the syntax l : t = s u.The term s is a programmer-de.ned operator of type .(x : t, y : t).t, \nwhich mixes implementations together. Composition of .elds then changes to the following: (l : t = s \nu)&#38;* (l : t = s u ) -. (l : t = s s(u)(u )) This version of composition no longer replaces one implemen\u00adtation \nwith the other. Instead, it mixes the two implementations to\u00adgether in some arbitrary manner which is \nde.ned by the operator s. As far as the type system is concerned, it doesn t matter what the .eld implementation \nis, so long as the implementation is a subtype of the range. There are several possible uses of this \nextension. To implement the super keyword as de.ned in Java and C++, each method of type M is encoded \nas a .eld of type .(x : M).M. This type represents a function which takes the super-class de.ni\u00adtion \nas its .rst argument. The mixin-operator s is the .ip of function composition. A composition of classes \nC1 &#38;* ... &#38;* Cn will pro\u00adduce a composition of methods mn . ... . m1. The composition of methods \nis then applied to some base de.nition, usually a no-op, to yield a single method of type M which chains \ncalls back from subclass to superclass. To implement mixin composition with linearization, each method \nof type M is encoded as a .eld which holds a list of functions of type .(x : M).M. The mixin-operator \ns merges two lists together, maintaining relative order, but eliminating duplicates. Calling the method \ninvolves folding the list with the .ip of function composi\u00adtion, and then applying the result to some \nbase de.nition as before. Other mixin schemes are possible. The exact details the schemes above don t \nmatter so much as the idea that mixins do not need to be part of the core language, but can be of.oaded \nto a library. 8. Related Work The idea of unifying types and objects comes from the the Ohmu programming \nlanguage [30], which was a predecessor to DEEP. The vc calculus [28] is a formalization of the gbeta \nand Caesar languages, and was the .rst calculus to provide full support for vir\u00adtual classes as attributes \nof objects. The de.nition of vc includes several complications that don t arise in DEEP. Vc is an imperative \nlanguage with a mutable heap, and it performs linearization of mix\u00adins within the calculus. As explained \nin section 7, DEEP of.oads linearization to a library. DEEP also follows a purely functional ap\u00adproach: \nany imperative constructs would have to be emulated in some way e.g. with monads [52] or uniqueness \ntypes [5]. Unlike DEEP,the vc calculus is provably decidable, but it gains decidability at the cost of \nseveral restrictions. The type system of vc is purely nominal; it only handles dependent path types.Itis \nunclear how structural types such as generics could be added to vc.DEEP supports full dependent types, \nwith both structural and nominal typing. Second, vc does not support .nal bindings. Final bindings are \nan important tool in many situations arrays as de.ned in section 4 are a good example. However, there \ndoes not seem to be any way to add them to vc.The vc calculus avoids name clashes during inheritance \nby requiring that all slot names be unique. In real implementations this requirement is enforced by automatic \nname\u00admangling. This technique doesn t work with .nal bindings, because .nalizing a slot when re.ning \na virtual superclass will break any subclasses which attempt to override the same slot (see section 6.4). \nDEEP avoids this problem by using exact types, and by re-checking inherited declarations. Third, vc restricts \ninheritance to classes within the same family i.e. it is not possible to inherit from a class in a different \nobject. DEEP has no such restriction. The Tribe calculus is both simpler and somewhat more pow\u00aderful \nthan vc, although its decidability has not been proven [17]. Like DEEP, Tribe uses singleton types to \nenrich the subtype rela\u00adtion. Tribe also includes an intuitive notion of subtyping between families that \nDEEP lacks. In Tribe, t.l <: u.l if t<: u, whereas in DEEP, t.l <: u.l only if t = u. This more .exible \nsubtype rule is possible because every class in Tribe has a unique enclosing record, so there is a relative \npath from this to enclosing records. The tradeoff is that like vc, classes in Tribe can only inherit \nfrom other classes in the same object. Inheritance in DEEP can cross module boundaries, but subtyping \nis less .exible as a result. Nystrom and Myer s Jx language is an extension of Java which supports the \nre.nement of static nested classes [41]. Although Jx does not currently support virtual inner classes, \nit does use a dependent type system, so this restriction does not appear to be into these two systems; \nsubtyping provides a good model for inher\u00aditance. System F. is not quite powerful enough to handle self-types, \n<: but it can be extended with recursive types and F-bounded poly\u00admorphism [15]. This extension essentially \nforms the basis for Java generics, which have been explored as an existing language mecha\u00adnism for class \nre.nement [50]. Generics with F-bounded polymor\u00adphism can capture patterns of mutual recursion, but the \nnumber of parameters per class scales with the number of classes involved, which makes them unwieldy \nfor complex collaborations. 8.1.1 Intersection Types Intersection types have been used in a number of \ncalculi. System OO languages with multiple inheritance [18]. It is important to note .F. is an extension \nof System F. which has been used to model <: intrinsic. The most unusual aspect of Jx is the use of pre.x \ntypes .thatintersectiontypesinF. instead of path types. The J&#38; language extends Jx with a form of \n in DEEP. deep mixin composition much like the one proposed in this paper, are actually much stronger \nthan those In DEEP, an intersection is only well-formed if it can be re\u00adexcept that name clashes must \nbe disambiguated by hand [42]. duced to some other term that is not an intersection. As a result, Bruce, \nOdersky, and Wadler have proposed a statically safe mechanism for re.ning groups of classes, but their \nmechanism does not scale further there is no way to de.ne groups of groups, and it is not possible to \ninherit from a virtual class. [14] The .FJ calculus developed by Igarashi and Saito is an extension of \nfeatherweight Java which allows the re.nement of static nested classes. .FJ has a similar set of restrictions: \nit is not possible to inherit from a virtual class. [33] The Concord language developed by Jolley et. \nal. uses the idea of class groups, but it lifts the restriction on inheritance. the type (.(x: Int). \nInt) &#38; (.(x: Float). Float) is ill-formed. Sys\u00ad .temF. has no such restriction the analogous type \nInt .Int . Float .Float is perfectly valid. As a result, intersections in DEEP do not actually allow \nmore terms to be typed; they are merely a convenient way to reuse code by merging declarations. This \nweaker form of intersection is suf.\u00ad cient to handle multiple inheritance, but it is provably less power\u00ad \nful. The restriction is a result of the fact that type intersections in DEEP can be applied to objects, \nand type safety requires that such [34] intersections be reducible. Odersky s .Obj calculus [43] provides \na formal treatment of virtual types, and is the basis for the Scala programming language. However, although \nScala supports virtual types, it does not support virtual classes. Instead, scala supports explicit self-types, \nwhich can be used to emulate virtual classes to some degree. Like Beta, however, it is not possible in \nScala to inherit from a virtual class. Moreover, Scala does not perform deep mixin composition auto\u00admatically; \nnested classes must be mixed by hand [55]. Duggan and Sourelis have proposed mixin modules as an exten\u00adsion \nto ML [23]. Mixin modules have the same .xpoint semantics as records in DEEP, and use a similar form \nof composition. How\u00adever, there is no subtype relation between mixin modules, so it is a form of implementation \ninheritance only. Bruce has done a great deal of work on match subtyping, and introduced the concept \nof exact types [13] [12]. Exact types provide many of the bene.ts of dependent types with a great deal \nless hassle, but they have not yet been used to support full virtual classes. Mixin layers implement \ndeep mixin composition using C++ templates [46]. Like features, this is essentially a generative ap\u00adproach, \nsince templates are not type-checked prior to instantiation. The expression problem has been discussed \nat length in many papers. Solutions can be found for gbeta [27], Java generics [50], Scala [55], and \nHyper/J [44]. Lopez-Herrejon provides a compari\u00adson of generative approaches in [37]. Although most prototype \nlanguages are untyped, the Omega language by Gunther Blaschek is an exception [9]. The type system in \nOmega is nominal, and like Java, it uses a global class table, which makes it unsuitable for virtual \nclasses. 8.1 Relation to typed .-calculi Subtyping, dependent types, singleton types, and intersection \ntypes have all been extensively studied in the literature. Subtyping has been added to Girard s System \nF and F. to yield System F<: and F. <:, respectively. Many object-oriented concepts can be translated \n 8.1.2 Dependently typed .-calculi The systems described above cannot be used to model classes which \nare attributes of objects. A further extension is necessary: dependent types. Igarashi and Pierce show \nthat virtual types can be encoded in a variant of System F. which has been extended with <: dependently \ntyped records [31]. However, their extension does not handle mutually recursive classes, and its safety \nand decidability has not been shown. Dependent types are powerful medicine, and it has proved dif\u00ad.cult \nto combine them with other language mechanisms. Adding general recursion to the extended calculus of \nconstructions in\u00adstantly renders the entire system undecidable. Type equality de\u00adpends on object equality, \nand object equality involves evaluation, so the proof of decidability in CC relies on strong normalization \n[20]. Recursive types are equally problematic because they can be used to write a .x-point operator, \nthus causing the same problem. The Cayenne language [4], which adds dependent types to Haskell, runs \nafoul of this problem, as does DEEP. Combining dependent types and subtyping is also surprisingly tricky. \nA naive combination of the two in the style of System F. in\u00ad <: troduces mutual dependencies between \nthe typing, subtyping, and kinding judgments which makes the meta-theory very dif.cult. In System .P<: \nAspinall and Compagnoni circumvent this issue by carefully controlling the order in which proofs are \ndone [3]. In Sys\u00adtem .C<:, Gang Chen avoids circularity by careful restructuring of the subtype rules \n[16]. Neither system supports bounded quan\u00adti.cation (as found in System F<:) because of meta-theoretic \ndif\u00ad.culties. Jan Zwanenburg has successfully added subtyping with bounded quanti.cation to Pure Type \nSystems; he avoids the circu\u00adlarity by de.ning subtypes over pre-terms, rather than well-typed terms \n[56]. Singleton types and singleton kinds are closely related to de\u00adpendent types [47]. Aspinall makes \nthe crucial observation that in a system with singleton types, type judgments can be expressed as subtype \njudgments, and vice versa [2]. The DEEP calculus exploits this relationship to con.ate typing and subtyping, \nwhich results in a signi.cantly simpler meta-theory. 8.2 Relation to partial evaluation Partial evaluation \nis a promising technique, and there is a vast literature on the subject. The classic text by Neil Jones \ngives a broad overview of the .eld [35]. A more recent survey of current progress and unsolved problems \ncan be found in [36]. The purpose of partial evaluation is to specialize a program with respect to some \nstatic input, in the hope that this will yield faster code. Specialization is done by shifting computations \nfrom run\u00adtime to compile-time. The Achilles heel of partial evaluation is the fact that the evaluator \nmay not terminate see [36] for details. For every function call, the evaluator must decide whether to \nexpand (i.e. inline or evaluate) the call, or residualize the call, in which case the computation is \ndeferred until run-time. Partial evaluators can be broadly classi.ed into two groups with regard to how \nthey make this decision. Online evaluators make decisions on the .y , based on internal heuristics. Of.ine \nevaluators perform a global binding-time analy\u00adsis phase before performing any evaluation. This phase \nadds anno\u00adtations to source code that describe which computations are static (compile-time), and which \nare dynamic (run-time). The DEEP calculus employs a primitive form of online evalu\u00adation. It evaluates \nexpressions on the .y, but does not employ the sophisticated heuristics found in successful real-world \nevaluators. In order to ensure termination, DEEP requires the programmer to annotate the source code \nby hand, adding bounding types that force the type system to generalize at speci.c points. (DEEP generalizes \nwhere an ordinary partial evaluator would residualize.) The use of bounding types in DEEP bears a close \nresemblance to abstract interpretation, which is a general technique used for a wide variety of static \nanalysis [21]. Like partial evaluators, abstract interpreters may fail to terminate. Abstract interpreters \nuse a tech\u00adnique called widening, which discards enough information to en\u00adsure that the analysis terminates. \nThere is an obvious parallel be\u00adtween widening and the use of bounding types in DEEP,but we have not \npursued this issue further. 9. Conclusion The DEEP calculus provides type-safe support for virtual classes. \nObjects, classes, and modules are all modeled as records, and records may be nested to any arbitrary \ndepth. This means that objects may contain classes as attributes. OO inheritance is emulated by composing \nrecords together; the composition of two records will merge de.nitions from both par\u00adents. Unlike ordinary \ninheritance, such merging performs a deep mixin composition, in which de.nitions with the same name are \nre\u00adcursively composed. This is the same mechanism found in feature\u00adoriented programming, and it supports \nthe incremental re.nement of large-scale class hierarchies. The most innovative aspect of the DEEP calculus \nis the fact that it combines types and objects into a single construct, which we call a prototype. Every \nobject denotes a type, and every type is a .rst\u00adclass object. Type safety relies on subtyping between \nprototypes, rather than typing. Prototypes have two main advantages. First, prototypes com\u00adbine three \nbig ideas dependent types, singleton types, and sub\u00adtyping into a uni.ed whole. This mechanism supports \na smooth spectrum of type information, from the very abstract (e.g. Object) down to the very detailed \n(e.g. singletons). Because types are uni\u00ad.ed with objects, types which depend on objects become a natural \npart of the language, rather than a strange and dif.cult construct. Second, the subtype relation in DEEP \nincorporates ideas from the partial evaluation and abstract interpretation communities. The static type \nof a term may just be an upper bound. However, it may also be an exact value which represents the result \nof evaluating the term. The type system includes an interpreter which is capa\u00adble of evaluating arbitrary \nexpressions at compile-time. Types thus become a tool not just for catching errors, but also for code \ngener\u00adation and optimization. 9.1 Limitations and Future Work The design of DEEP is an attempt to unify \nideas from several different branches of computer science. Currently, this uni.cation represents the \nlowest common denominator of more advanced systems. It is thus important to note some of the limitations \nof DEEP. 9.1.1 Dependent types Sophisticated dependent type systems, such as Luo s UTT [38], and Connor \nMcBride s Epigram [40], support inductive data types. These data types are a limited form of recursive \ntypes which only allow structures of .nite size. Primitive recursion over such data types yields total \nfunctions that are guaranteed to terminate, thus allowing dependent types and recursion to be combined \nin a decid\u00adable system. Interestingly enough, such functions can be used to write type cast operators \nthat prove algebraic identities such as the commutativity and associativity of addition. Thismechanismaddressesthemajorweaknessof \nDEEPwithre\u00adgard to dependent types, as described in section 4.5. Unfortunately, the current de.nition \nof DEEP relies on general recursion, so there is no way to construct proofs of this form. 9.1.2 Partial \nEvaluation As mentioned earlier, real-world partial evaluators either perform binding-time analysis, \nor use sophisticated heuristics to guide the evaluation process. DEEP does neither, which cripples its \nability to apply partial evaluation to any real-world problems. However, it might be possible to apply \ninductive data types here as well. Dependent type systems with indexed data types provide exactly the \nsort of information that a partial evaluator needs proofs of termination. In some respects, DEEP represents \na .rst attempt at combining these ideas, but there is a great deal of work to be done. Acknowlegements \nWe would like to acknowledge the help of Phil Wadler and Don Batory, who provided comments and discussion \non earlier drafts of this paper. We would also like to acknowledge the support of MZA Associates Corporation, \nwhich funded this research. References [1] M. Abadi and L. Cardelli. A Theory of Objects. Springer, 1996. \n[2] D. Aspinall. Subtyping with singleton types. Eighth International Workshop on Computer Science Logic, \n1994. [3] D. Aspinall and A. Compagnoni. Subtyping dependent types. Proceedings of 11th Annual Symposium \non Logic in Computer Science, 1996. [4] L. Augustsson. Cayenne -a language with dependent types. International \nConference on Functional Programming, pages 239 250, 1998. [5] E. Barendsen and S. Smetsers. Uniqueness \ntyping for functional languages with graph rewriting semantics. Mathematical Structures in Computer Science, \n1996. [6] K. Barrett et al. A monotonic superclass linearization for dylan. Proceedings of OOPSLA, 1996. \n[7] D. Batory, J. Liu, and J. Sarvela. Re.nements and multi-dimensional separation of concerns. ACM SIGSOFT, \n2003. [8] D. Batory, J. Sarvela, and A. Rauschmayer. Scaling step-wise re.nement. Proceedings of ICSE, \n2003. [9] G. Blaschek. Type-safe OOP with prototypes: the concepts of Omega. Structured Programming, \n12(12):1 9, 1991. [10] G. Bracha. The Programming Language Jigsaw: Mixins, Modularity and Multiple Inheritance. \nPh.D. thesis, University of Utah, 1992. [11] G. Bracha and W. Cook. Mixin-based inheritance. OOPSLA, \n1990. [12] K. Bruce. Some challenging typing issues in object-oriented languages. Electronic Notes in \nTheoretical Computer Science 82 No. 8, 2003. [13] K. Bruce, A. Fiech, and L. Petersen. Subtyping is not \na good match for object-oriented languages. Proceedings of ECOOP, 1997. [14] K. B. Bruce, M. Odersky, \nand P. Wadler. A statically safe alternative to virtual types. Proceedings of ECOOP, 1998. [15] P. Canning, \nW. Cook, W. Hill, and W. Olthoff. F-bounded polymorphism for object-oriented programming. Proceedings \nof FPLCA, 1989. [16] G. Chen. Subtyping calculus of constructions (extended abstract). Proceedings of \nthe International Symposium on Mathematical Foundations of Computer Science, 1997. [17] D. Clarke, S. \nDrossopoulou, J. Noble, and T. Wrigstad. Tribe: More types for virtual classes. In submission, 2005. \n[18] A. Compagnoni and B. Pierce. Higher-order intersection types and multiple inheritance. Mathematical \nStructures in Computer Science, 6(5):469 501, 1996. [19] W. Cook, W. Hill, and P. Canning. Inheritance \nis not subtyping. Proceedings of POPL, 1990. [20] T. Coquand and G. Huet. The calculus of constructions. \nInformation and Computation, 1(2/3), 1988. [21] P. Cousot and R. Cousot. Abstract interpretation: A uni.ed \nlattice model for static analysis of programs by construction or approximation of .xpoints. Proceedings \nof the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming languages, pages 238 252, 1977. \n[22] D. Dreyer, R. Harper, and K. Crary. Toward a practical type theory for recursive modules. Technical \nReport CMU-CS-01-112, 2001. [23] D. Duggan and C. Sourelis. Mixin modules. Proceedings of the International \nConference on Functional Programming, 1996. [24] E. Ernst. gbeta a Language with Virtual Attributes, \nBlock Structure, and Propagating, Dynamic Inheritance. Ph.D. thesis. Department of Computer Science, \nUniversity of Aarhus, Denmark, 1999. [25] E. Ernst. Propagating class and method combination. Proceedings \nof ECOOP, 1999. [26] E. Ernst. Family polymorphism. Proceedings of ECOOP, 2001. [27] E. Ernst. Higher \norder hierarchies. Proceedings of ECOOP, 2003. [28] E. Ernst, K. Ostermann, and W. Cook. A virtual class \ncalculus. Proceedings of POPL, 2006. [29] M. Flatt, S. Krishnamurthi, and M. Felleisen. Classes and mixins. \nACM Symposium on Principles of Programming Languages, 1998. [30] D. Hutchins. The power of symmetry: \nUnifying inheritance and generative programming. OOPSLA Companion, DDD Track, 2003. [31] A. Igarashi \nand B. Pierce. Foundations for virtual types. Proceedings of ECOOP, 1999. [32] A. Igarashi, B. Pierce, \nand P. Wadler. Featherweight java, a minimal core calculus for java and gj. Proceedings of OOPSLA, 1999. \n[33] A. Igarashi, C. Saito, and M. Viroli. Lightweight family polymor\u00adphism. Proceedings of the 3rd Asian \nSymposium on Programming Languages and Systems, 2005. [34] P. Jolly, S. Drossopoulou, C. Anderson, and \nK. Ostermann. Simple dependent types: Concord. Proceedings of FTfJP, 2005. [35] N. Jones, C. Gomard, \nand P. Sestoft. Partial Evaluation and Automatic Program Generation. Prentice-Hall, Inc. Upper Saddle \nRiver, NJ, USA, 1993. [36] N. D. Jones and A. J. Glenstrup. Program generation, termination, and binding-time \nanalysis. Proceedings of GPCE, 2002. [37] R. Lopez-Herrejon, D. Batory, and W. Cook. Evaluating support \nfor features in advanced modularization technologies. Proceedings of ECOOP, 2005. [38] Z. Luo. Computation \nand reasoning: a type theory for computer science. Oxford University Press, Inc., New York, NY, USA, \n1994. [39] O. Madsen and B. M\u00f8ller-Pedersen. Virtual classes: A powerful mechanism in object-oriented \nprogramming. Proceedings of OOPSLA, 1989. [40] C. McBride and J. McKinna. The view from the left. Journal \nof Functional Programming, 14(1):69 111, 2004. [41] N. Nystrom, S. Chong, and A. Myers. Scalable extensibility \nvia nested inheritance. Proceedings of OOPSLA, 2005. [42] N. Nystrom, X. Qi, and A. Myers. J&#38;: Nested \nintersection for scalable software composition. Proceedings of OOPSLA, 2006. [43] M. Odersky, V. Cremet, \nC. Roeckl, and M. Zenger. A nominal theory of objects with dependent types. Proceedings of ECOOP, 2003. \n[44] W. H. Peri Tarr, H. Ossher. N degrees of separation: Multi\u00addimensional separation of concerns. Proceedings \nof ICSE, 1999. [45] N. Sch\u00a8arli, S. Ducasse, O. Nierstrasz, and A. Black. Traits: Composable units of \nbehavior. Proceedings of ECOOP, 2002. [46] Y. Smaragdakis and D. Batory. Implementing layered designs \nwith mixin layers. Proceedings of ECOOP, 1998. [47] C. Stone. Singleton Kinds and Singleton Types. PhD \nthesis, Carnegie Mellon University, 2000. [48] K. K. Thorup and M. Torgersen. Unifying genericity combining \nthe bene.ts of virtual types and parameterized classes. Proceedings of ECOOP, 1999. [49] M. Torgersen. \nVirtual types are statically safe. 5th Workshop on Foundations of Object-Oriented Languages, 1998. [50] \nM. Torgersen. The expression problem revisited. four new solutions using generics. Proceedings of ECOOP, \n2004. [51] D. Ungar and R. Smith. Self, the power of simplicity. Proceedings of OOPSLA, 1987. [52] P. \nWadler. The essence of functional programming. Proceedings POPL, 1992. [53] A. Wright and M. Felleisen. \nA syntactic approach to type soundness. Information and Computation, 2004. [54] H. Xi. Dependent Types \nin Practical Programming. PhD thesis, Carnegie Mellon University, 1998. [55] M. Zenger and M. Odersky. \nIndependently extensible solutions to the expression problem. Workshop on Foundations of Object-Oriented \nLanguages, 2005. [56] J. Zwanenburg. Pure type systems with subtyping. International Conference on Typed \nLambda Calculi and Applications, 1999.   \n\t\t\t", "proc_id": "1167473", "abstract": "In mainstream OO languages, inheritance can be used to add new methods, or to override existing methods. Virtual classes and feature oriented programming are techniques which extend the mechanism of inheritance so that it is possible to refine nested classes as well. These techniques are attractive for programming in the large, because inheritance becomes a tool for manipulating whole class hierarchies rather than individual classes. Nevertheless, it has proved difficult to design static type systems for virtual classes, because virtual classes introduce dependent types. The compile-time type of an expression may depend on the run-time values of objects in that expression.We present a formal object calculus which implements virtual classes in a type-safe manner. Our type system uses a novel technique based on prototypes, which blur the distinction between compile-time and run-time. At run-time, prototypes act as objects, and they can be used in ordinary computations. At compile-time, they act as types. Prototypes are similar in power to dependent types, and subtyping is shown to be a form of partial evaluation. We prove that prototypes are type-safe but undecidable, and briefly outline a decidable semi-algorithm for dealing with them.", "authors": [{"name": "DeLesley Hutchins", "author_profile_id": "81100209382", "affiliation": "University of Edinburgh", "person_id": "P643437", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167475", "year": "2006", "article_id": "1167475", "conference": "OOPSLA", "title": "Eliminating distinctions of class: using prototypes to model virtual classes", "url": "http://dl.acm.org/citation.cfm?id=1167475"}