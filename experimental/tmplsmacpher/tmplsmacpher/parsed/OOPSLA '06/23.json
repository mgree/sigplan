{"article_publication_date": "10-16-2006", "fulltext": "\n Isolating and Relating Concerns in Requirements using Latent Semantic Analysis Lo Kwun Kit Chan Kwun \nMan Elisa Baniassad Department of Computer Science and Engineering The Chinese University of Hong Kong \n {kklo, kmchan3, elisa}@cse.cuhk.edu.hk Abstract Aspect-oriented requirements analysis involves the identi.cation \nof concerns that behaviorally in.uence other concerns. Such concerns are described in requirements called \naspectual requirements: re\u00adquirements that detail the in.uence of one concern over another. The current \nstate of the art for aspect-oriented requirements anal\u00adysis is Theme/Doc, which allows lexical analysis \nof requirements based on a set of developer-chosen keywords. It provides a graph\u00adical depiction of how \nconcerns relate to requirements, and affords identi.cation of potential aspectual requirements. In addition, \nclus\u00adters of requirements and concerns are identi.ed to arrive at a more useful set of concerns than \nthose initially identi.ed. Because of the lexical nature of the Theme/Doc approach, as\u00adpectual requirements \nare missed, or wrongly identi.ed. Addition\u00adally, requirements may be wrongly clustered if they contain \nam\u00adbiguous terms. In this work we explored whether the use of a statistical ap\u00adproach for textual analysis, \nLatent Semantic Analysis (LSA), would improve upon the lexical approach used by Theme/Doc. We found that \nLSA helps identify useful concern clusters, and helps reduce the number of falsely identi.ed aspectual \nrequirements. Categories and Subject Descriptors D.2.1 [Software Engineer\u00ading]: Requirements/Speci.cations \nGeneral Terms Veri.cation, Documentation Keywords Aspect-Oriented REquirements Analysis, Early as\u00adpects, \nLatent Semantic Analysis, Theme/Doc, Visualisation 1. Introduction Aspect-orientation is an approach \nfor separating concerns that do not align well with a particular program decomposition. Research into \naspects began at the programming language level, and is pro\u00adgressing earlier in the lifecycle. Currently, \nthe .eld of aspects in requirements, design and domain analysis (called early aspects)is thriving. Aspects, \noutside the context of code, take on a more general, two-part meaning: First, they are concerns that \ndo not align with a particular artifact decomposition, regardless of what the artifacts at Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA 06 October \n22 26, 2006, Portland, Oregon, USA. Copyright c &#38;#169; 2006 ACM 1-59593-348-4/06/0010. . . $5.00 \na given phase of the lifecycle might be. For instance, in require\u00adments, it may be dif.cult to choose \na document sectioning that cleanly captures an auditing concern and a transaction management concern: \none of which may have to refer to one another to be com\u00adplete. These aspects are generally referred to \nas early aspects, since they are aspects of early-lifecycle artifacts. Such aspects require early-aspect \nlanguages to properly capture. Second, aspects in the early-lifecycle are concerns that are identi.ed \nin early-lifecycle ar\u00adtifacts, but which will not align well in later artifacts [2]. In other words, \nthese are concerns that might be easily modularized in, per\u00adhaps, requirements, but which will not be \nstraightforward to imple\u00adment in code in a cleanly modularized way. These concerns can be referred to \nas early-identi.ed aspects. Early-aspects and early-identi.ed aspects often overlap. This is most often \ntrue if requirements are structured along component or object-oriented lines. Aspect-Oriented Requirements \nAnalysis (AORA) involves anal\u00adysis of requirements for the sake of identifying both kinds of con\u00adcerns \nin two phases: .rst, the dominant concern decomposition of a set of requirements is determined, and second, \naspectual re\u00adquirements [2, 12, 1] are identi.ed. An aspectual requirement is a requirement that describes \nthe impact of one concern over another. For instance, the requirement that describes how auditing affects \ntransaction management in a banking system would be considered an aspectual requirement. Determining \nthe dominant concern decomposition of a set of requirements involves clustering requirements that refer \nto similar concepts. This means that requirements will be restructured out of their original dominant \ndecomposition, and will instead, be isolated by concern. The result of this process is a set of mostly \nisolated concern clusters, with some clusters linked by requirements that could belong in more than one \ncluster. Identifying aspectual requirements involves looking at the re\u00adquirements that relate concern \nclusters, to determine whether the requirement that describes the two clusters does so by necessity. \nFor instance, transaction management and auditing would likely be found as two concern clusters. However, \nthe requirement that de\u00adscribes that auditing must be applied to transactions would not .t cleanly into \neither of these clusters. Instead, it describes the in.u\u00adence of one cluster (auditing) over the other \ncluster (transaction management). It is impossible to re-write such a requirement so that the the two \nconcerns are described separately of one another. If it were possible to split the requirement, the requirement \nwould not be aspectual. Clustering and aspectual-requirement analysis can be done manually, but is time \nconsuming and prone to error. Alterna\u00adtively, lexical approaches for visualized keyword-searching, such \nas Theme/Doc, have been shown to be helpful [1]. Theme/Doc is a lightweight tool that can be quickly \napplied to any set of re\u00adquirements regardless of the language in which the text is written. Theme/Doc \ndoes not require a knowledge base or corpus to operate. By providing the text of the requirements and \na set of keywords, a user can iteratively arrive at a set of concern clusters, and get a clear view of \npotentially aspectual requirements. However, because of its pure lexical nature, Theme/Doc in\u00advolves \nsigni.cant user intervention to obtain a set of concern clus\u00adters, and to identify aspectual requirements. \nTheme/Doc provides helpful visualization, but still requires the user to examine most of the requirements \nto determine whether they are correctly clus\u00adtered. It is also necessary, when using Theme/Doc, that \nthe devel\u00adoper must examine every potentially aspectual requirement to de\u00adtermine whether each one is \nactually aspectual. This can be time consuming, especially in the face of a large set of requirements. \nIn this paper we investigate augmenting the lexical functionality in Theme/Doc with Latent Semantic Analysis \n[6]. Latent Semantic Analysis (LSA) is an approach for determining the similarity of terms or portions \nof text based on statistical analysis of a large text corpora [6]. Like Theme/Doc, the approach does \nnot require a knowledge base to operate, and it is language independent. For instance, in addition to \nusing LSA for analysis of natural language documents, LSA has been used for analysis of programs for \nthe sake of semi-automated clustering [11], and analysis[10]. We investigate using LSA for assisting \nin .nding concern clus\u00adters, and for identi.cation of aspectual requirements. We applied three case studies \nof different sizes, the largest of which was taken from a current industrial project, and analyze how \nTheme/Doc style visualizations used for clustering and aspectual requirement identi.cation compare in \naccuracy when formed using LSA and Theme/Doc. 2. Background In this section we describe the background \nfor our work on LSA for Theme/Doc. First, we describe Theme/Doc in detail, and out\u00adline how problems \nare introduced due to its lexical nature. Then, we describe LSA, the technique we used to augment Theme/Doc \nanalysis. 2.1 Aspect-Oriented Requirement Analysis with Theme/Doc Theme/Doc [1] is a requirements analysis \napproach for identifying concerns and their aspectual relationships. A developer provides the Theme/Doc \ntool with a set of keywords indicating possible con\u00adcerns or aspects, and a set of requirements. The \nrequirements can be any granularity: word, sentence, paragraph, document section, or entire document. \nLexical analysis is then used to identify which concern terms are found in which requirements. A graphical \ndepic\u00adtion is produced by the tool, linking requirements with the concern terms they contain. Consider, \nfor instance, a very small example involving a simple banking system. The system has three requirements: \n1. Transactions include depositing and withdrawal. 2. All transactions should be audited 3. When a \nuser withdraws money, it should be tracked for...  The developers for the system also identi.ed four \nconcerns they felt of key interest : Transaction  Withdraw  Deposit  Audit  Figure 1. Theme/Doc \nView for Banking System Feeding these two lists into the Theme/Doc tool would result in a graph that \nlooks like the one shown in Figure 1. When identifying aspectual requirements, the developer looks at \nrequirements that are shared between more than one concern. In this example, two requirements (R1 and \nR2) are potentially aspectual, since they are shared by more than one concern, which indicates that they \nmay describe the behavioral in.uence of one concern over another. One requirement, R3, is not considered \na potentially aspectual requirement since it is linked to only one concern. R2 is, in fact, an aspectual \nrequirement: it describes the in.u\u00adence of auditing behavior over transactions, meaning that Audit is \nan aspect of Transaction. R1, however, is a false-positive: it de\u00adscribes ownership by one concern (Transactions) \nof other concerns (Withdraw and Deposit). While this is useful information, R1 is not describing a behavioral \nin.uence, and so is not aspectual. R3 is a false negative: It is an aspectual requirement, but be\u00adcause \nTracked was not included in the list of concerns, it is not identi.ed as such. Tracked, in this case, \nis a synonym of Audit, and should have been indicated as such by the developers providing the keyword \nlist. However, we have found that developers working on any set of requirements will not only miss synonyms, \nbut will miss entire concerns of interest, causing many false negatives. In this case, because this is \njust a small snippet of a much larger set of re\u00adquirements, they were not likely to manually identify \nall concerns of interest, including all of their synonyms. To describe cluster identi.cation, a slightly \nlarger example is needed, so we will add two more requirements (R7 and R8) that resemble R1, and three \nmore requirements that describe auditing (R4, 5 and 6). We will also group auditing and tracking so that \nthey both appear under the Audit concern. This results in the graphs shown in Figure 2. The top image \nis the usual Theme/Doc view, which shows how concerns and requirements relate. The bottom image is an \ninversion of this view, where requirements are shown as linked by concerns they share. Clusters are identi.ed \nvisually by the developer. In a set of re\u00adquirements this size, clusters of requirements in the Theme/Doc \nview (Transactions on the left, and Audit on the right) are easy to spot. However, in a large set of \nrequirements, layout issues can con\u00ad  Figure 2. Banking System Clusters (Theme/Doc and Inverted Views) \nfuse clustering. The inverted view shown on the bottom is more typ\u00adically used for cluster identi.cation, \nbecause related requirements are highly connected, and clusters are easier to distinguish. In this example \nwe have clustered requirements R1, R7 and R8 together under Transaction and R2-6 together under Audit. \nR2 and R3 could have been clustered under either Transaction or Audit, but because Audit is an aspect \nof Transaction, and R2 and R3 are the aspectual requirements that describe the relationship between Transaction \nand Audit, they are clustered under the aspect concern, Audit. Problems can occur when using Theme/Doc \nfor forming clus\u00adters. If all concerns have not been identi.ed, then entire clusters will be missing. \nAdditionally, lexical similarities between unrelated terms can lead to requirements being wrongly included \nin a cluster. When applying Theme/Doc, a developer alternates between clustering and aspectual-requirement \nidenti.cation. Clusters are used to identify groups of concern terms, which are then used to help identify \naspectual requirements. Aspectual requirements can then be placed in the correct cluster during the next \nclustering ac\u00adtivity. The .nal product of the Theme/Doc approach is a set of concerns, and aspectual \nrequirements that link them. For instance, Figure 3 shows the .nal product of analysis of the banking \nsystem: Transaction and Audit are the only two concerns shown. Grey is used to indicate aspectual relationships: \nAudit is shown to have two requirements (R2 and R3) that crosscut Transaction.  2.2 Latent Semantic \nAnalysis Latent semantic analysis (LSA) [6, 9] is a vector-space statistical information retrieval method. \nIt uses statistical reasoning to deter\u00admine the similarity between bodies of text. In this section, we \nin\u00adtroduce LSA, as it is described in [6, 9]. LSA operates on a body of text known as the corpus.Inthe \ncase of requirements analysis, the corpus is the set of requirements of interest to the developer. The \nLSA approach then divides the corpus into smaller units of text, called Documents. Additionally, terms \nare extracted from the corpus. These terms are essentially any word that appears in the document, minus \na list of generic stop-words. The stop words we used for the studies presented here are given in Appendix \nA. Described simplistically, LSA allows the identi.cation of term and document similarity. The similarity \nof two terms is determined by how often they appear together in the entire corpus. Terms can also be \nsimilar due to indirect co-location, where two terms are linked transitively by terms with which they \neach appear. The similarity of two documents is determined by how often the document s constituent terms \nappear together in the corpus. Using the documents and set of terms, LSA builds a semantic matrix X where \neach row represents a term and each column represents a document. A cell in the matrix states the frequency \nof the corresponding term appearing in the corresponding document. The m\u00d7 nsemantic matrix Xwhere m>n(meaning, \nit has more rows than columns) is then decomposed using Singular Value Decomposition (SVD) [7]. Three \nmatrices will be computed: m\u00d7 morthogonal term matrix U  n\u00d7 northogonal document matrix V  m\u00d7ndiagonal \nmatrix S containing singular values of semantic matrix X  such that X= USVT . It is possible to .nd \na rank-kapproximation to matrix X [4] with minimal change to the matrix for a given value of k[3, 4, \n7]. ' That is, SVD produces the approximation m\u00d7 nmatrix Xof X ' such that X= UkSkVkT which is the least \nsquare best .t, where Uk is m\u00d7 k, Sk is k\u00d7 kand Vk is n\u00d7 k. ' Using LSA, we exploit this rank-kapproximation \nmatrix X, rather than the original term-document matrix X: The derived ma\u00ad ' trix Xcaptures most of the \nimportant underlying structure in the term-document association, and yet removes the noise, variability \nor unimportant details in word usage [4, 6]. As kis much smaller than the number of unique terms, small \ndifferences in terminology will be ignored [4]. Therefore, similar documents will be near to each other \nin the k-dimensional semantic space even through they may not share exactly the same term. The choice \nof dimensionality kis critical to the performance of LSA. However, the choice of the value of kthat provides \nthe optimal result is still an open question and is normally done by empirical testing [3, 4]. After \nthe rank-kapproximation, we can analyse the term-term, ' term-document and document-document relationships \nusing X[6]. There are several correlation measurement methods, but below are what we use -cosine angle \nof vectors. To compare two terms, take the cosine angle of the term vectors multiplied by the singular \nvalue. The cosine angle between two row ' vectors of Xre.ect the similarity between two terms. That is, \n''T XX M = 2 IX'I Similarly, two documents can be compared by the angle be\u00ad ' tween the column vectors \nof X. 'T X' M = X IX' I2 To compare a term and a document, we have to convert the terms and documents \nvectors into an intermediate space .rst [6] and then compare the angles between the vectors in the intermediate \nspace. 1/2)T (UkSk 1/2)(VkSk M = 1/2 1/2 (UkSk VkSk With these three matrices, we can compare similarities \nbetween different terms and documents by extracting similarity values from relevant cells. 3. Approach \nIn this work we applied LSA to requirements documentation in an effort to improve upon the lexical results \nobtained by Theme/Doc. We adopted an implementation of the LSA approach described in the previous section. \nThe application of our LSA implementation for the sake of requirements analysis has three phases. First, \nLSA is applied to the requirements document. This produces graphs iden\u00adtical to those produced by Theme/Doc, \nexcept that rather than link\u00ading concerns to terms by lexical analysis, the LSA results are used. Then, \na manual visual approach is used to cluster the requirements. Finally, we applied a semi-automated technique \nusing LSA s results to narrow the set of possible aspectual requirements. This section describes both \nour approach for applying LSA and also our approach for evaluating LSA in the case studies described \nin the next section. 3.1 Implementation of LSA Because of patents on LSA, we were unable to obtain a \nworking copy of an LSA implementation. There is a generic suite of LSA tools on the web 1, however because \nthey use their own corpus for analysis, we were unable to obtain domain speci.c analysis of the requirements \ndocumentation. Therefore, we built our own tools for our analysis. 3.2 Application and Evaluation of \nLSA Initially, we preprocess the requirement text before the actual LSA process. The preprocessing consisted \nof three steps: punctuation removal This step involves removing irrelevant sym\u00adbols and punctuation from \nthe requirements so that the LSA routines will not introduce errors, such as counting a word with period \nnext to it as a new term. A notable exception is dash, which may be used to join two words to form a \nnew word. stopword removal A stopword is any word that has low seman\u00adtic value such as is, are, the, \netc. These words may introduce noise into the results since some of the stopwords are very com\u00admon in \nnatural languages. For the whole stopword list, please refer to Appendix A. stemming A word may appear \nin the requirement in different forms, which will hurt the statistical analysis of LSA. To make all forms \nof each word the same, we employ Porter Stemmer 2 to stem the requirements. After preprocessing, we use \nthe entire requirements document as the text corpus and build the semantic space. We then per\u00adform LSA \nto yield the three correlation matrices, in which ev\u00adery cell is adjusted to the absolute value of the \noriginal values. Mi,j = ||Mi,j || 3.3 Cluster Identi.cation and Evaluation Process The result of the \nprevious step is a similarity matrix, describing the similarities between terms and requirements. We \nconvert the matrices into a graphical format so that they can be viewed in the same way as the Theme/Doc \ngraphs described earlier. We then use the same cluster identi.cation process described for Theme/Doc: \nTerms and requirements that refer to similar concepts will form vi\u00adsual clusters. Dominant concerns can \nbe found through identifying the clusters in the term-requirement graph. 1 LSA tools are available on-line \nusing a variety existing corpuses: http://lsa.colorado.edu/ 2 Porter stemmer and its information is available \nat: http://www.tartarus.org/martin/PorterStemmer/ To reduce clutter in the graphs, we remove edges that \nindicate too low a similarity. If all similarity edges are left in the graph, the graph will appear nearly \ncompletely connected, making it impossi\u00adble to identify clusters of similar requirements. The thresholds \nwe applied depended upon the size of the documents and the number of concern terms using the approach \ndescribed in [15]. Clusters are then identi.ed manually by visual inspection of the graphs3. 3.3.1 Evaluation \nApproach for Case Studies To compare the LSA approach to Theme/Doc we visually clustered graphs produced \nby each technique. We then compared them using the following method. For each graph, we assessed the \nthe overall effectiveness of clusters by calculating their average cluster cohesion, their average cohesion \ntaking cluster size into account (meaning that tiny clusters will be less in.uential on the average than \nlarge clusters), the number of requirements located usefully within a cluster, and those not located \nin any cluster. Let cluster cohesion Ci and weighted cluster cohesion Wi be: number of requirements belonging \nto cluster i Ci = number of requirements in cluster i (size of cluster i Wi =0.5Ci +) max. size for all \ncluster Average Cluster Cohesion is calculated by: n 1 Ci n i=1 Average cluster cohesion considering \ncluster size is calculated by: n 1 Wi n i=1 The number of requirements usefully located is derived by \nman\u00adual inspection of each requirement and each cluster. It should be stressed that this is not the approach \nwe would recommend to some\u00adone simply applying the LSA approach. This manual inspection was necessary \nto obtain data for the case study analysis. Require\u00adments located usefully in clusters is calculated \nby: number of requirements placed correctly in cluster number of clustered requirements Requirements \nnot located in any clusters is calculated by: number of requirements not clustered total number of requirements \n  3.4 Aspectual Requirements Identi.cation Process As described earlier, aspectual requirements are \nrequirements that describe one concern s behavioral in.uence another concern. In Theme/Doc, potential \naspectual requirements are identi.ed by looking for requirements that refer to more than one concern \nterm. 3 It would likely be practical to use automatic clustering approaches to automate this phase. However, \nto date we have not applied these techniques, and leave that instead to future work. Similarly, in LSA, \nrequirements that share more than two non\u00adtrivial terms are potential aspectual requirements. As we did \nfor the cluster identi.cation process, we remove edges with low similarities to reduce clutter and ease \nidenti.cation of prominent edges in the graph. Because aspectual requirements are typically requirements \nthat describe the in.uence of one action over another [1], we automati\u00adcally produced a new LSA graph \nthat contained only verb terms. This reduces the number of potentially aspectual requirements. This reduction \nis helpful since developers must manually inspect all potentially aspectual requirements to see if they \nare truly de\u00adscribing an aspectual relationship. 3.4.1 Evaluation Approach for Case Studies To compare \nthe LSA approach to Theme/Doc, we produced three graphs: one using the LSA approach described above, \none using the Theme/Doc approach with keywords supplied by a domain expert, and another using the Theme/Doc \napproach with the same set of verbs as the LSA approach. The use of two Theme/Doc graphs allowed us to \ncompare the LSA approach against both an expert and a naive user of Theme/Doc. We then compared the shared \nrequirements from all three graphs to a manually produced list of all the aspectual requirements in the \nrequirements. In the case studies, we evaluated the results base on the follow\u00ading metrics: Positive \nPredictive Value  False Positive Rate  False Negative Rate Denote:  P is a set of candidate aspectual \nrequirements  A is a set of actual aspectual requirements  The positive predictive value is the measure \nof prediction. It is the probability of .nding an aspectual requirement in the potential aspectual requirement. \nPositive Predictive Value: |P nA| |P | False positive rate measure proportion of non-aspectual require\u00adments \nthat are considered as potential aspectual requirements. False Positive Rate: |P nAc| |Ac| False negative \nrate measure proportion of aspectual require\u00adments that are not considered as potential aspectual requirements. \nFalse Negative Rate: |P cnA| |A| 4. Validation In this paper we present three case studies in which we \napplied the approach described in the previous sections. 4.1 Small Case study: Pet Shop The Pet Shop \nsystem is described by a set of requirements speci\u00adfying the operation of a online pet shop 4. The shop \ncontains two major components: a frontend and a backend. The frontend is a website that allows customers \nto look at a product, search the prod\u00aduct catalog and place an order. The backend is the order ful.ll\u00adment \ncenter which processes the orders sent from the frontend via the massage module. It contains two sub-components: \nan order ful\u00ad.llment component which handles orders and packs and ships the products to the customers, \nand a supplier component which man\u00adages the shop suppliers. 4 The requirements and additional materials \ncan be found at http://www\u00ad106.ibm.com/developerworks/rational/library/1072.html The requirements are \nreprinted in Appendix B. The require\u00adments contain 500 words and spans 2 pages. Each sentence in the \nrequirements is considered one separate requirement. 4.1.1 Clustering Analysis We performed a visual \nclustering of the LSA-produced graph with k = 10, lower threshold = 0.65, and the Theme/Doc graph. Table \n1 lists the result for this case study. The list of clusters is shown in the .rst row of the table. If \na cluster in one approach has a corresponding cluster in the other ap\u00adproach, they are placed adjacent \nto one another in the row. The size of each cluster is placed in parentheses. LSA and Theme/Doc dif\u00adfer \nin the granularity of clusters shown. For instance, LSA s results depict placing orders and ful.lling \norders as a single concept, so it combines them into a single cluster. Theme/Doc, however, depicts them \nas different concepts and two so clusters appear. The same is true for the concepts of shipping and order \nful.llment. It is clear from the table that LSA identi.es more clusters than Theme/Doc. These clusters \nappear useful as concerns for the design and implementation of the system. For instance, Administration \nis identi.ed as a cluster, as is the Shopping Cart functionality. Theme/Doc does not depict clusters \nrelated to these concerns. We can consider cluster overlap by examining Figure 4. LSA clusters are depicted \nas grey ovals, and Theme/Doc clusters are shown outlined in black. The requirements included for each \ncluster are linked to the cluster. Requirements are shown as grey-outlined boxes. In this case, Theme/Doc \nonly clustered requirements that were also clustered by LSA. LSA also produced three clusters that Theme/Doc \ndid not: SignOn, Control and Banking. The overlap graph, however, suggests that the clusters identi.ed \nusing the two approaches complement one another. The large td PlaceOrder clus\u00adter is re.ned by the LSA \nclusters into smaller more speci.c com\u00adponents. the Theme/Doc Ship and Ful.ll clusters are linked by \nthe LSA clusters for Ordering and Administration. The td Ful.ll cluster is augmented by the lsa Supplier \nComponent cluster. In this case, Theme/Doc is more successful in terms of all clustering measures except \nthe number of requirements that are not located in any clusters. 4.1.2 Aspectual Requirements Identi.cation \nWe manually identi.ed R2, R10, R22 and R24 as aspectual require\u00adments. The results of the comparison \nof the .ndings from the three graphs is shown in Table 2. LSA s numbers are more encouraging in this \ncase than they should be: We found that while LSA did identify a good set of aspectual requirements, \nthe terms to which those aspectual require\u00adments were linked were incorrect. For example, R9 (The customer \nselects items from a catalog, places them in a shopping cart, and, when ready, purchases the shopping \ncart contents. ) is connected to let , review and modify which actually appear in R20 (A shopping cart \nview that lets customers review and modify the con\u00adtents of their shopping cart ). We attribute these \nfailings to the small size of this requirement set. Since LSA is a statistical approach, a small data \nset could hurt the analysis process. The results for the naive Theme/Doc(All terms) approach is similar \nto the LSA approach, however in this case, the terms are correctly linked to the requirements. The expert \nTheme/Doc(Selected terms) graph identi.ed 15 po\u00adtential aspectual requirements. The results for the expert \napproach were better than the naive approach in terms of false positives, but missed one requirement, \nleading to a false negative. For this small set of requirements, the lexical approach and the statistical \nLSA approach give similiar results.  4.2 Medium Case Study: Crystal Game Crystal game is a context-aware \ngame where players explore a physical location equipped with sensors, and .nd as many crystals as possible \nusing hand-held devices similar to PDAs. The players explore the game play area until the game time-limit \nruns out. They can obtain crystals by .nding unclaimed crystals, by dueling with other players, or by \ncarrying out tasks set to them by virtual char\u00adacters that communicate with them through their PDAs. \nGenerally these tasks will also involve some time limit. The winner of the game is the player who makes \nit back to the start location with the most crystals before the time limit runs out. The requirements \ncan be found in [5]. The requirements cover 10 pages, and 1500 words. Each sentence of text is considered \none requirement. 4.2.1 Clustering Analysis Table 3 shows the result for Crystal Game clustering analysis \nwith Theme/Doc and LSA (withk=70and lower threshold = 0.55). Looking at the clusters, we can observe \nthat LSA gives 3 more clusters than Theme/Doc. Once again, we see that the clusters derived by the two \napproaches differ both in number, nature, and granularity. Granularity differences in corresponding clusters \nare evident when comparing the LSA-derived display cluster, which describes the user interface of the \nportable device, to the Theme/Doc-derived show cluster, which also refers to user interface in the portable \ndevice. The display cluster contains fewer requirements than show cluster. In this case study, lexical \nerrors introduced by Theme/Doc ap\u00adpear. The mis-clustering of Enter is one such example. Enter means \ntwo things in the requirements: entering a location and entering some information to the device. Unless \nthe developer has specif\u00adically noted the synonym (by using enter+location versus en\u00adter+information \n), Theme/Doc will treat all instances of enter as the same term. LSA did not suffer from this problem, \nand distin\u00adguished the difference between the two cases of enter. In this case, LSA provides a slightly \nhigher cluster cohesion on average, but degrades the cohesion when size is considered. Small clusters \nare highly cohesive using the LSA approach, but larger clusters are not as cohesive. LSA improves on \nthe number of usefully located requirements, but also increases the number of requirements that were \ncompletely unclustered. In this case, the clusters produced by LSA were, once again, more useful than \nthose produced by Theme/Doc, even though their quality was not quite as good. This points to the possibility \nthat clusters identi.ed using LSA could then be used to enhance lexi\u00adcal analysis. Theme/Doc and LSA \napproaches once again identify clusters in complement with one another. In this case, we found that the \ncombination of the approaches both identi.es larger, more complete clusters, and also helps identify \nclusters that represent as\u00adpectual behavior. The overlap between the Theme/Doc and LSA\u00adformed clusters \nis depicted in Figure 5. Theme/Doc identi.es a Duel cluster (td Duel), and LSA identi.es a somewhat overlap\u00adping \nWager cluster (lsa Wager). Upon inspection we can see that these two clusters together form a larger, \nmore complete, Duel cluster. Improved aspect-identi.cation is also possible with this graph: The LSA \ncluster lsa Gain Energy overlaps both td Enter and td Challenge via R42 and R80 respectively, which were \nboth iden\u00adti.ed as aspectual requirements. Because of this overlap, combina\u00adtion of the two graphs can \nhelp reveal the LSA derived lsa Gain En\u00adergy as an aspect of both td Enter and td Challenge, while the \nsep\u00adarate graphs could not.  Figure 4. Clusters derived by LSA and Theme/Doc for the Petshop Theme/Doc \nLSA concern clusters 4 clusters: Ship (4) Ful.ll Order (5) Place Order (6) Catalog (4) 10 clusters: Order \n(6) Product Catalog and Search (6) Shopping Cart (2) Supplier Component (3) Message Module (1) Control \nModule (1) Interface (1) Administration (3) Signon Module (2) Banking (1) useless clusters 0 0 average \ncluster cohesion 100% 92% (8% degraded) average cluster cohesion con\u00adsidering cluster size 90% 68% (22% \ndegraded) requirements usefully located in a cluster 100% 92% (8% degraded) requirements not located \nin any cluster 29% 4% (25% improved) Table 1. Comparison of Clustering by Theme/Doc versus LSA (with \nk = 10, lower threshold = 0.65) for Pet Shop Requirements Table 2. Result of Aspectual Requirements Identi.cation \nin Pet Store Requriements (k = 10 and lower threshold = 0.7) LSA Theme/Doc(Selected Terms) Theme/Doc(All \nTerms) Positive Predictive Value 4/19 = 21% 3/15 = 20% 4/19 = 21% False Positive Rate 15/23 = 65% 12/23 \n= 52% 15/23 = 65% False Negative Rate 0/4=0% 1/4 = 25% 0/4=0%  Figure 5. Overlap of Clusters found using \nLSA and Theme/Doc for the Crystal Game 4.2.2 Aspectual Requirements Analysis The Positive Predictive \nValue in both the lexical and LSA ap\u00adproaches is high. We attribute that to the consistent use of terms \nFor this case, we manually identi.ed 34 aspectual requirements. in the requirements: the author uses \nthe same term to describe the The results comparing the three approaches (LSA, Expert Theme/Doc same \nconcepts. using selected terms, and Naive Theme/Doc using LSA-produced The Theme/Doc (All terms) approach \nobtained the lowest false terms) is depicted in Table 4. The performance of the 2 lexical negative rate \n(i.e. highest coverage), but the false positive rate is the approaches are near equivalent while LSA \nyeilds a slightly better highest. This translates into much less work for the developer as\u00adresult. sessing \nmissed aspectual requirements, but more work for checking for erroneous requirements. The Theme/Doc expert \napproach using Theme/Doc LSA concern clusters 8 clusters: Show (17) Create (5) Join (5) Enter (10) Challenge \n(9) Duel (18) Send (11) Distribute (2) 11 clusters: Display (19) Create Game (6) Join Game (3) Send to \nRandom Location (5) Give Crystals (5) Gain Energy (3) Lose Energy (2) Wager (3)5 Gameplay Area (8) Time \nLimit (11) Reach Initial Location (3) useless clusters 0 0 average cluster cohesion 70% 76% (6% improved) \naverage cluster cohesion con\u00adsidering cluster size 62% 54% (8% degraded) requirements usefully located \nin a cluster 64% 69% (5% improved) requirements not located in any cluster 15% 28% (13% degraded) Table \n3. Comparison of Clustering by Theme/Doc versus LSA (withk=70and lower threshold = 0.55) for Crystal \nGame LSA Theme/Doc(Selected Terms) Theme/Doc(All Terms) Positive Predictive Value 26/45 = 58% 28/62 = \n45% 31/68 = 46% False Positive Rate 19/60 = 32% 34/60 = 57% 37/60 = 62% False Negative Rate 8/34 = 24% \n6/34 = 18% 3/34 = 9% Table 4. Result of Aspectual Requirements Identi.cation in Crystal Game Requriements \n(k = 70 and lower threshold = 0.5) selected terms did not improve signi.cantly over the false positive \nrate of the naive approach.  4.3 Large Case Study: Toll System Our largest case study was of a set \nof Toll system requirements from Siemens AG. The toll system involves technology to operate toll roads \nthroughout the European Union. Because of the propri\u00adetary nature of these requirements, we are unable \nto provide details of their contents. The requirements cover 15 pages, and 3000 words. While this is \nan excerpt from a larger document, this segment is, in itself, a typ\u00adical size for a set of requirements \nin the Siemens industrial setting. Each requirement covered a paragraph of text. This is in contrast \nto the sentence-granularity of the other case study requirements. The keywords used in the Theme/Doc \napproach for analysis of these requirements were supplied by the Siemens developers, and took possible \nsynonyms for complex or domain speci.c terms into ac\u00adcount. The requirements were written by multiple \nauthors, from dif\u00adferent perspectives. Siemens motivation for providing us with the requirements was \nto ascertain a set of features, and their aspectual relationships. They had determined that because of \nthe size of the requirements, it was not effective for them to perform this analysis by hand. The table \nshows that four corresponding clusters were found. Three clusters were found only by the Theme/Doc approach, \nand eight clusters were found only by the LSA approach. A comparison of the quality of the clusters favors \nTheme/Doc. The average cluster cohesion was slightly better for LSA than for Theme/Doc, but when taking \ncluster size equally into account, Theme/Doc performs slightly better. More requirements were use\u00adfully \nclustered in Theme/Doc than in LSA. Slightly fewer require\u00adments were left unclustered in Theme/Doc than \nusing LSA. Once again, the granularity difference between the clusters should be noted. Theme/Doc formed \nseven large clusters, whereas LSA formed smaller, more speci.c clusters. The concern clusters are listed \nin the .rst row of the table. When two clusters corre\u00adsponded, they were placed next to one another in \nthe row. Clusters from one approach that had no corresponding cluster in the other approach appear alone \non a line in the row. The relationships between these clusters is depicted in Figure 6. Clusters found \nby Theme/Doc are in black-outlined ovals and are pre.xed by td ; the LSA-identi.ed clusters are shown \nshaded grey, and pre.xed by lsa . The requirements contained in the clusters are shown in light-grey \nboxes, and are linked to the cluster in which they are contained. The graph shows three small clusters \nthat were unidenti.ed using the Theme/Doc approach: the Demonstrator Functional\u00adity concern cluster (shown \nin the bottom-right of the .gure as lsa Demonstrator ), Enforcement (shown in the top left of the 4.3.1 \nClustering Analysis .gure as lsa enforcement ), and Language (shown in the top right Table 5 displays \nthe results of cluster analysis using the LSA and of the .gure as lsa language ). From analysis of the \nrequirements, Theme/Doc approaches. and also consultation with the developers at Siemens AG, we were \nable to ascertain that these were important concepts in the require\u00adments. While LSA did not locate all \nthe requirements that could have been linked to each of these concern clusters (if enforce had been included \nas a Theme/Doc keyword, .ve requirements would have been identi.ed, as opposed to two), even the careful \nconsideration of the developers did not include all of the concerns that were of interest. Hence, we \n.nd that LSA could be used in this case to enhance and guide the Theme/Doc approach, by identifying unanticipated \nclusters. We once again .nd that LSA clusters help place Theme/Doc clusters in greater context, and may \nenhance appropriate re\u00adquirement clustering with Theme/Doc. For instance, it can be seen that the Theme/Doc \ncluster Charge Calculation (shown as td Calculation ) has three related concepts that were identi.ed \nusing LSA: Security, Scalability and Billing. Two of the three re\u00adquirements linking those four concern \nclusters were found to be aspectual in nature: R31 and R10. This implies that Scalability and Security \nare both aspects of Charge Calculation, which makes intuitive sense. R6 was not found to be aspectual, \nwhich implies that Billing is actually part of Charge Calculation. By including the requirements in LSA \ns Billing cluster into Theme/Doc s Calculation cluster, that cluster becomes more complete. 4.3.2 Aspectual \nRequirement Analysis The results of the aspectual requirements analysis for the Toll system are shown \nin Table 6. All three approaches fare worse on this set of requirements than on the crystal game requirements. \nWe attribute this to the fact that the toll system requirements were written by multiple authors, using \nmany terms inconsistently. This inconsistency hurts both the lexical and statistical approaches, but \nseems to hurt the lexical approach more than the LSA approach. LSA missed far fewer aspectual requirements \nthan the expert Theme/Doc, and missed just one more than the naive (all terms) Theme/Doc approach. The \nLSA approach misses one more requirement than the naive (all terms) Theme/Doc approach, while the expert \nTheme/Doc ap\u00adproach misses many more requirements than the other two ap\u00adproaches.  4.4 Findings From \nthe case studies, we have several .ndings to present here. 4.4.1 Clustering Analysis The book on the \nTheme Approach recommends two ways to start looking for concern terms [5]: use all verbs from the requirements \n(Start-with-Everything approach) and read the requirements care\u00adfully to choose some useful key terms \n(Choose-Carefully-Upfront approach). The .rst approach saves time in the choosing initial con\u00adcerns but \nit will require more iterations in later stages to arrive at a useful set of concerns. The second approach \nresults in fewer initial concerns, but it takes a long time to choose them. The results from LSA clustering \nanalysis may help choosing initial themes by ruling out improbable words and proposing words that may \ncapture con\u00adcerns in the requirement that are otherwise ignored in the former approaches. Comparing the \nresults of the three case studies, we assess that LSA generally produces more .ne-grained concern clusters \nthan Theme/Doc approach. We also found that the LSA approach helps identify clusters that were not anticipated \nby the developers. An example of this is the time limit concern in Crystal Game. This concern is an important \nconcept in the game, but was not consid\u00adered explicitly by the developers deciding upon the keywords. \nLSA provides the developers an alternative view of a requirements doc\u00adument that is complementary to \nexpert analysis, and involves no human analysis of the requirements prior to cluster identi.cation. In \nall cases, we saw that the clusters identi.ed using the two approaches were complementary. The combined \napproaches iden\u00adti.ed more complete clusters, and also identi.ed aspectual relation\u00adships between clusters. \n 4.4.2 Aspectual Identi.cation In all three case studies, we found that the LSA approach in general \nobtained a higher positive predictive value than the Theme/Doc ap\u00adproach with an acceptable false negative \nrate. It reduced the search space for aspectual requirements by about 30% when comparing all three case \nstudy results. We noted that the larger the set of requirements, the better the comparative performance \nof LSA became. This suggests that LSA is a good approach for working with very large requirements sets. \n5. Related Work In this section we compare against two bodies of work: Aspect\u00adoriented requirements analysis \napproaches that involve language processing, and software engineering techniques that use latent semantic \nanalysis. 5.1 Aspect-Oriented Requirements Analysis There are many aspect-oriented requirements engineering \nand anal\u00adysis techniques, including [12, 8]. These differ in intent from this LSA augmentation of Theme/Doc \nbecause they are related to cap\u00adturing already identi.ed aspectual requirements and concerns. Preliminary \nwork, however, has been undertaken to augment Theme/Doc with natural language processing. Sampaio et \nal [13] provide an approach for identifying stakeholders and crosscutting concerns in unstructured documentation. \nIn their approach, they identify stakeholders by looking for certain linguistic features, such as er \n, et or man in the documentation. In addition, they identify aspectual requirements based on semantically-enhanced \nkeyword analysis. Keywords might include all verbs, or a list of known crosscutting concerns. This approach \nis complementary to the requirement-requirement LSA approach, since it is primarily concerned with identifying \nkeyword-requirement pairs rather than requirement clusters. The use of this approach is not as lightweight \nas the LSA approach described here, because it requires a previ\u00adously trained knowledge base to operate. \nEarlier work on Theme/Doc and LSA [15] explored the use of on-line tools for the sake of clustering and \naspectual requirement identi.cation. That work showed preliminary promise that LSA could be helpful in \nidentifying clusters and keyword-requirement pairs. However, due to the small size of the case study \nconsidered, it did not report conclusive .ndings on either cluster identi.cation or aspectual requirement \nidenti.cation. Indications showed that while LSA looked promising in theory, the use of the generic on-line \ntools would not be suf.cient to augment Theme/Doc s lexical approach. This is because the tools have \na pre-existing semantic knowledge space based on analysis of existing texts such as encyclopedias and \ntextbooks. This helps amass statistical information about very gen\u00aderal concepts, but does not assist \nin domain speci.c contexts such as those encountered when analyzing requirements documentation. The approach \npresented in this work bases all statistical analysis on the requirements document provided by the developer, \nso does not make general or domain-generic assumptions about the rela\u00adtionships between terms.  5.2 \nSoftware Engineering Techniques using LSA Marcus and Maletic [10] used Latent Semantic Indexing (LSI) \nto obtain traceability links from documentation to source code. Their Theme/Doc LSA concern clusters \n7 clusters: Transmission (15) Communication initiation (2) Road Identi.cation (8) Charge Calculation \n(15) Processing (5) Deployment (9) SMS (2) 12 clusters: Transmit Data (3) Transmission (incl. Initiation \nand Con.rmation) (5) Road Identi.cation (4) Billing (3) Demonstrator functionality (2) Language (5) Normal \noperation Mode (2) Security (4) Scalability (5) On-board Unit (OBU) functionality (3) Enforcement (2) \nRequirements Gathering (5) useless clusters 0 2 average cluster cohesion 84% 87% (3% improved) average \ncluster cohesion con\u00adsidering cluster size 67% 64% (3% degraded) requirements usefully located in a cluster \n90% 70% (20% degraded) requirements not located in any cluster 40% 44% (4% degraded) Table 5. Comparison \nof Clustering by Theme/Doc versus LSA for the Siemens Toll System (k = 70 and lower threshold = 0.5) \nLSA Theme/Doc(Selected Terms) Theme/Doc(All Terms) Positive Predictive Value 19/58 = 33% 7/29 = 24% 20/73 \n= 27% False Positive Rate 39/69 = 57% 22/69 = 32% 53/69 = 77% False Negative Rate 4/23 = 17% 16/23 = \n70% 3/23 = 13% Table 6. Result of Aspectual Requirements Identi.cation in Toll System Requriements (k \n= 70 and lower threshold = 0.5) approach involved indexing of the documentation on a document\u00adlevel granularity, \nand indexing of the code and comments on a .le\u00adlevel granularity. They found that LSI was an effective \nmeasure to associate documentation to source code. Stone and Sawyer[14] present a technique for identifying \nin\u00adstances of tacit and poorly sourced knowledge in requirements. They propose an application of LSA \nto .nd similarities between requirements and source materials, to identify points of correspon\u00addence, \nand highlight portions of requirements that had no motivat\u00ading documentation. Both Maletic and Marcus \nwork, and Stone and Sawyer s work are different in nature from the LSA approach for Theme/Doc en\u00adhancement. \nTheme/Doc is, however, intended to assist in trace\u00adability from requirements to design. It is possible \nthat Stone and Sawyer s technique could be used to further enhance Theme/Doc to include source to requirements \ntraceability. Maletic and Marcus technique might be integrated into Theme/Doc+LSA to provide an aspect-oriented \nview of source code. 6. Conclusions In this work we performed three case studies of different sizes to \ncompare the use of LSA to the use of lexical analysis for the sake of Aspect-Oriented Requirements Analysis \n(AORA). We compared the approaches in terms of the two main AORA tasks: the identi.\u00adcation of clusters \nof concerns and requirements, and the identi.ca\u00adtion of aspectual requirements. We found that the LSA \napproach complements Theme/Doc for cluster identi.cation. Clusters in Theme/Doc are larger than those \nidenti.ed using LSA, but may miss concepts not initially spotted by the developers. LSA on the other \nhand, produces a larger set of clusters that are not as internally cohesive, but that make up for missed \nconcerns. We conclude that the LSA approach and the lexical approach could be combined to enhance the \nperformance of Theme/Doc. We found that the LSA approach falsely identi.es fewer aspec\u00adtual requirements \nthan the Theme/Doc approach. This reduction helps the developer by narrowing the search space for erroneous \naspectual requirements. The lexical approach misses fewer aspec\u00adtual requirements than the LSA approach. \nAs for cluster identi.ca\u00adtion, we can see that the approaches complement one another: The lexical approach \ncould be enhanced using LSA to .lter out falsely identi.ed aspectual requirements. References [1] E. \nBaniassad and S. Clarke. Theme: An approach for aspect\u00adoriented analysis and design. In ICSE 04: Proceedings \nof the 26th International Conference on Software Engineering, pages 158 167, Washington, DC, USA, 2004. \nIEEE Computer Society. [2] E. Baniassad, P. Clements, J. Araujo, A. Moreira, A. Rashid, and B. Tekinerdogan. \nDiscovering early aspects. IEEE Software, Jan/Feb 2006. [3] M. Berry, X. Drmac, and E. Jessup. Matrices, \nvector spaces, and information retrieval. SIAM Review, 41(2):335 362. [4] M. Berry, S. Dumais, and G. \nO Brien. Using linear algebra for intelligent information retrieval. SIAM review, 37(4):573 595, 1995. \n Figure 6. Overlap of Clusters found using LSA and Theme/Doc for the Toll System [6] S. C. Deerwester, \nS. T. Dumais, T. K. Landauer, G. W. Furnas, and R. A. Harshman. Indexing by latent semantic analysis. \nJournal of the American Society of Information Science, 41(6):391 407, 1990. [7] G. H. Golub and C. F. \nV. Loan. Matrix Computations. John Hopkins University Press, third edition, 1996. [8] J. Grundy. Aspect-oriented \nrequirements engineering for component based software systems. In 4th IEEE International Symposium on \nRequirements Engineering, pages 84 91. [9] T. K. Landauer, P. W. Foltz, and D. Laham. Introduction to \nlatent semantic analysis. Discourse Processes, 25:259 284, 1998. [10] J. Maletic and A. Marcus. Supporting \nprogram comprehension using semantic and structural information. In ICSE 01: Proceedings of the 23rd \nInternational Conference on Software Engineering, pages 103 112, Washington, DC, USA, 2001. IEEE Computer \nSociety. [11] J. Maletic and A. Marcus. Recovering documentation-to-source\u00adcode traceability links using \nlatent semantic indexing. In ICSE 03: Proceedings of the 25rd International Conference on Software Engineering, \n2003. [12] A. Rashid, A. Moreira, and J. Araujo. pages 11 20, 2003. [13] A. Sampaio, N. Loughran, A. \nRashid, and P. Rayson. Mining aspects in requiements. In AOSD 2005 Aspect-Oriented Requirements Engineering \nand Architecture Design Workshop, Chicago, Illinois, USA, 2005. [14] A. Stone and P. Sawyer. Finding \ntacit knowledge by solving the pre-requirements tracing problem. In Workshop on Requirements Engineering: \nFoundation for Software Quality, 2005. [15] R. Suen and E. Baniassad. Isolating concerns in requirements \nusing latent semantic analysis. In OOPSLA 2005 Workshop on Early Aspects, San Diego, California, USA, \nOctober 2005. A. Appendix A: A small example of LSA Here is a small example to demonstrate the technique \nof Latent Semantic Analysis. The corpus we used is obtained from [3]. The corpus in this example consists \nof the following documents: D1. Complete Triathlon Endurance Training Manual: Swim, Bike, Run  D2. \nLake, River and Sea-Run Fishes of Canada  D3. Middle Distance Running: Training and Competition  D4. \nMusic Law: How to Run Your Band s Business  D5. Running: Learning, Training, Competing  In practice, \nterms are selected according to their respective fre\u00adquency in the corpus, says, appear more than once. \nFor simplicity, the following terms are selected manually. Here, we regard Sea-Run as a single word. \nT1: run(ning) T2: bike  T3: endurance  T4: training  T5: band  T6: music  T7: .shes  The .rst \nstep of LSA is to construct a semantic matrix X where each row represents a term and each column represents \na document. A cell in the matrix is the frequency of the corresponding term appears in the corresponding \ndocument. .. 10111 10000 .. . 10000 . .. X = . 10101 . .. 00010 .. 00010 01000 The next step is the singular \nvalue decomposition, the semantic matrix X is decomposed into three matrix such that X = USV T . Followed \nis the rank-k approximation of X. Here we choose k =2. The resultant matrices are: .. -0.72 0.24 -0.24 \n-0.26 .. . -0.24 -0.26 . .. U = . -0.58 -0.35 . .. -0.13 0.59 .. -0.13 0.59 00 2.74 0 S=01.55 .. -0.65 \n-0.40 00 V = -0.48 -0.07 .. .. .. -0.36 0.91 -0.48 -0.07 After obtained all these matrices, we can use \nthe formulae in Section 2.2 to calculate the similarities between terms and docu\u00adments. Since the approximation \nmatrix X ' = USV T .Wehave .. 1.12 00.90 1.04 0.90 0.58 00.34 -0.13 0.34 .. . 0.58 00.34 -0.13 0.34 . \n' .. X = . 1.25 00.80 0.08 0.80 . .. -0.1300.11 0.96 0.11 .. -0.1300.11 0.96 0.11 000 0 0 And the term-term \nsimilarity matrix M, ' T X ' X M = IX ' I2 . 1 0.74 0.74 0.87 0.53 0.53 0.31 . 0.74 1 1 0.97 0.18 0.18 \n0.42 . . . 0.74 1 1 0.97 0.18 0.18 0.42 . = . 0.87 0.97 0.97 1 0.05 0.05 0.20 . . . . 0.53 0.20 0.18 \n0.05 1 1 0.97 . . . 0.53 0.20 0.18 0.05 1 1 0.97 0.31 0.42 0.42 0.20 0.97 0.97 1 From the matrix M , \nwe can see that some similarities make in\u00adtuitive sense: The similarity between endurance and training \nis 0.97; the similarity between .shes and training is .2. However, due to the small sample size, some \nsimilarities are erroneous: The similarity between .shes and music is .97. B. Appendix B: Pet Shop Requirements \nHere is the listing of the pet shop requirements. R1: The Web site present an online pet store interface \nto the cus\u00adtomer; The customer shop and place order through this interface. R2: When a customer complete \nan order, the interface send the order to the order ful.llment center. R3: Because the Web site functional \nunit drive further business processing when it send a purchase order to the ful.llment center, it can \nbe thought of as the front end. R4: The ful.llment center ful.ll customer order. R5: It has an order \nful.llment component and a supplier com\u00adponent. R6: The ful.llment center processes order based on the \nenter\u00adprise s business rule, manage .nancial transaction, and arrange for product to ship to customer; \nBecause not all product are in stock at any given moment, order processing may occur over a period of \ntime. R7: Administrator and other supplier may interact with the ful.llment center; This portion of the \nbusiness is refer to as the back end, because its processing is triggered by placing an order, an action \nthat occur in the Web site portion. R8: Although the supplier component is part of the sample application, \nit could just as easily be a service external to the application. R9: The customer select item from a \ncatalog, place them in a shopping cart, and, when ready, purchase the shopping cart content. R10: Prior \nto a purchase, the sample application display the order: the selected item, quantity and price for each \nitem, and the total cost; The customer can revise or update the order; To complete the purchase, the \ncustomer provide a shipping address and a credit card number. R11: A customer shop, place order, manage \nher user account, and receive e-mail. R12: An administration manager review enterprise .nancial data. \nR13: A bank system process credit card. R14: A warehouse worker pack and ship order. R15: Link or navigation \nbar to common navigational task R16: A catalog providing an organized view of the site s content R17: \nA search mechanism R18: A master view of catalog item R19: A detail view that describe the details of \na particular item R20: A shopping cart view that lets customer review and modify the contents of their \nshopping cart R21: A checkout view that display the total order cost and allow the customer to enter \nbilling and shipping information R22: A receipt view to provide con.rmation of the purchase. R23: A control \nmodule to create and maintain user account information, which includes a user identi.er, billing, and \ncontact information; This information is maintained in a database; The control module also create and \nmanage the user s shopping cart and control the interaction with the user. R24: A sign-on module to handle \nthe user log-in process and security, such as verifying a user identi.er and password. R25: A product \ncatalog module that return product information from the catalog based on a user s search criteria. R26: \nA customer module that manage a user s purchasing pro\u00adcess and maintains account records for a customer. \nR27: A messaging module that enable the application to send and receive asynchronous messages containing \npurchase order C. Appendix C: Stopword List used This is the stopword list we use in this research. It \ncontains 383 words. a about above according across actually adj after afterwards again against all almost \nalone along already also although always among amongst an and another any anyhow anyone anything any\u00adwhere \nare aren aren t around as at b be because been before before\u00adhand behind being below beside besides between \nbeyond billion both but by c can can t cannot caption co co. could couldn couldn t d did didn didn t \ndo does doesn doesn t don t down during e each eg eight eighty either else elsewhere enough etc even \never every ev\u00aderyone everything everywhere except f few .fty .rst .ve for former formerly forty four \nfrom further g h had has hasn hasn t have haven haven t he he d he ll he s hence her here here s hereafter \nhereby herein hereupon hers herself him himself his how however hundred i i d i ll i m i ve ie if in \ninc. indeed instead into is isn t it it s its itself j k l last later latter latterly least less let \nlet s like likely ltd m many maybe me meantime meanwhile might million miss more more\u00adover most mostly \nmr mrs much must my myself n namely neither never nevertheless next nine ninety no nobody none nonetheless \nnor not nothing now nowhere o of off often on once one one s only onto or other others otherwise our \nours ourselves out over over\u00adall p per perhaps q r rather recent recently s same seem seemed seeming \nseems seven seventy several she she d she ll she s should shouldn shouldn t since six sixty so some somehow \nsomeone some\u00adthing sometime sometimes somewhere still stop such t ten than that that ll that s that ve \nthe their them themselves then thence there there d there ll there re there s there ve thereafter thereby \ntherefore therein thereupon these they they d they ll they re they ve thirty this those though thousand \nthree through throughout thru thus to together too toward towards trillion twenty two u under unless \nunlike unlikely until up upon us used using v very w was wasn wasn t we we d we ll we re we ve well were \nweren weren t what what ll what s what ve whatever when whence whenever where where s whereafter whereas \nwhereby wherein whereupon wherever whether which while whither who who d who ll who s whoever whole whom \nwhomever whose why will with within without won t would wouldn wouldn t x y yes yet you you d you ll \nyou re you ve your yours yourself yourselves z     \n\t\t\t", "proc_id": "1167473", "abstract": "Aspect-oriented requirements analysis involves the identification of concerns that behaviorally influence other concerns. Such concerns are described in requirements called emphaspectual requirements: requirements that detail the influence of one concern over another. The current state of the art for aspect-oriented requirements analysis is Theme/Doc, which allows lexical analysis of requirements based on a set of developer-chosen keywords. It provides a graphical depiction of how concerns relate to requirements, and affords identification of potential aspectual requirements. In addition, clusters of requirements and concerns are identified to arrive at a more useful set of concerns than those initially identified.Because of the lexical nature of the Theme/Doc approach, aspectual requirements are missed, or wrongly identified. Additionally, requirements may be wrongly clustered if they contain ambiguous terms.In this work we explored whether the use of a statistical approach for textual analysis, Latent Semantic Analysis (LSA), would improve upon the lexical approach used by Theme/Doc. We found that LSA helps identify useful concern clusters, and helps reduce the number of falsely identified aspectual requirements.", "authors": [{"name": "Lo Kwun Kit", "author_profile_id": "81319494851", "affiliation": "The Chinese University of Hong Kong", "person_id": "P813673", "email_address": "", "orcid_id": ""}, {"name": "Chan Kwun Man", "author_profile_id": "81319496572", "affiliation": "The Chinese University of Hong Kong", "person_id": "P813666", "email_address": "", "orcid_id": ""}, {"name": "Elisa Baniassad", "author_profile_id": "81414615851", "affiliation": "The Chinese University of Hong Kong", "person_id": "PP18004001", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167506", "year": "2006", "article_id": "1167506", "conference": "OOPSLA", "title": "Isolating and relating concerns in requirements using latent semantic analysis", "url": "http://dl.acm.org/citation.cfm?id=1167506"}