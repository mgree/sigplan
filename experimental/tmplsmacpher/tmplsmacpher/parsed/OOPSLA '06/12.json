{"article_publication_date": "10-16-2006", "fulltext": "\n Declarative,Formal, and Extensible Syntax De.nitionfor AspectJ ACasefor Scannerless Generalized-LRParsing \n\u00b4 Martin Bravenboer Eric Tanter Eelco Visser Department of Information and Center for Web Research, \nDCC, Department of Information and Computing Sciences, Utrecht University University of Chile Computing \nSciences, Utrecht University The Netherlands etanter@dcc.uchile.cl The Netherlands martin@cs.uu.nl visser@acm.org \n Abstract Aspect-Oriented Programming (AOP) is attracting attention from both research and industry, \nas illustrated by the ever-growing pop\u00adularity of AspectJ, the de facto standard AOP extension of Java. \nFrom a compiler construction perspective, AspectJ is interesting as it is a typical example of a compositional \nlanguage, i.e. a language composedofa numberof separate languageswithdifferent syntac\u00adtical styles: in \naddition to plain Java, AspectJ includes a language for de.ning pointcuts and one for de.ning advices. \nLanguage com\u00adposition represents a non-trivial challenge for conventional parsing techniques. First, \ncombining several languages with different lexi\u00adcal syntax leads to considerable complexity in the lexical \nstates to be processed. Second, as new language features forAOP are being explored, manyresearch proposals \nare concerned with further ex\u00adtending the AspectJ language, resulting in a need for an extensible syntax \nde.nition. This paper shows how scannerless parsing elegantly addresses the issues encountered by conventional \ntechniques when parsing AspectJ.We present the designofa modular,extensible, and for\u00admal de.nition of \nthe lexical and context-free aspects of the AspectJ syntax in the Syntax De.nitionFormalism SDF, which \nis imple\u00admented by a scannerless, generalized-LR parser (SGLR). We in\u00adtroduce grammar mixins as a novel \napplication of SDF s modu\u00adlarity features, which allows the declarative de.nition of different keyword \npoliciesand combinationofextensions.We illustratethe modularextensibilityofour de.nitionwithsyntaxextensionstaken \nfrom current research on aspect languages. Finally, benchmarks show the reasonable performance of scannerless \ngeneralized-LR parsing for this grammar. Categories and Subject Descriptors D.3.1[Programming Lan\u00adguages]: \nFormal De.nitions and Theory; D.3.4 [Programming Languages]: Processors GeneralTerms Languages, Design, \nStandardization Keywords AspectJ, syntax de.nition, syntax extension, grammar mixins, scannerless parsing, \ngeneralized-LR parsing, lexical syntax Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage.To copyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. OOPSLA 06 October 22 26, 2006, Portland, Oregon, USA. Copyright c . 2006ACM \n1-59593-348-4/06/0010... $5.00. 1. Introduction A language thatis used willbechanged to paraphrase Lehman \ns .rstlawof softwareevolution[25]. Lehman slawsof softwareevo\u00adlution apply to programming languages as \ntheyapply to other soft\u00adware systems. While the rate of change is high in the early years of alanguage,even \nstandardized languages are subjectto change.The Java language alone provides good examples of a variety \nof lan\u00adguage evolution scenarios. Language designers do not get it right the .rst time around(e.g. enumerations \nand generics). Program\u00adming patterns emerge that are so common that they can be sup\u00adported directlyby \nthe language(foreach, crosscutting concerns). The environment in which the language is used changes and \nposes new requirements(e.g. JSP for programming dynamic webpages). Finally, modern languages tend to \nbecome conglomerates of lan\u00adguages with different styles(e.g. the embedding of XML in XJ). The risks \nof software evolution, such as reduced maintainabil\u00adity,understandability,andextensibility,applyto languageevolution \nas well. Whileexperiments are conducted with the implementation, the actual language de.nition diverges \nfrom the documented spec\u00adi.cation, and it becomes harder to understand what the language is. With the \ngrowing complexity of a language, further improve\u00adments and extensions become harder and harder to make. \nThese risks especially apply to language conglomerates, where interac\u00adtions between language components \nwith different styles become very complex. AspectJ [24], the de facto standard aspect-oriented program\u00adming \nlanguage, provides a good case in point. While the of.cial ajc compiler for AspectJextends the mainstream \nEclipse compiler for Java and has a large user base, the aspect-oriented paradigm is still actively being \nresearched; there are manyproposals for further improvements andextensions(e.g. [26, 32, 11, 36, 4, 29, \n19]). The AspectBenchCompiler abc [5] provides an alternative implemen\u00adtation that is geared to experimentation \nwith and development of new aspect-oriented language features. AspectJ adds supporttoJava for modularizationof \ncrosscutting concerns, which are speci.ed as separate aspects. Aspects contain advice to modify the program \n.ow at certain points, called join points. AspectJ extends Java with a sublanguage for expressing pointcuts, \ni.e. predicatesovertheexecutionofa programthat deter\u00admine when the aspect should apply, and advices, \ni.e. method bod\u00adies implementing the action that the aspect should undertake. The pointcut language has \na syntax that is quite different from the base language. This complicates the parsing of AspectJ, since \nits lexical syntax is context-sensitive. This is a problem for scanners, which are oblivious to context. \nThe parsers of the ajc and abc compil\u00aders choose different solutions for these problems. The abc parser \nuses a stateful scanner [21], while the ajc compiler uses a hand\u00adwritten parser for parsing pointcutexpressions.For \nboth parsers the result is an operational, rather than declarative, implementation of the AspectJ syntax, \nin particular the lexical syntax, for which the correctnessand completenessarehardtoverify,andthatisdif.cult \nto modify and extend. In this paper, we present a declarative, formal, and extensible syntax de.nition \nof AspectJ. The syntax de.nition is formal and declarative in the sense that all aspects of the language \nare de.ned by means of grammar rules. The syntax de.nition is modular and extensibleinthe sensethatthe \nde.nition consistsofaseriesofmod\u00adulesthat de.nethesyntaxofthe component languages separately. AspectJ \nis de.ned as an extension to a syntax de.nition of Java 5, which can and has been further extended with \nexperimental aspect features. We proceed as follows. First wegive brief introductions to con\u00adceptsofparsing(Section2)and \naspect-orientedprogramming(Sec\u00adtion3).Toexplainthe contributionof our approachweexaminein Section4the \nissues that mustbe addressedina parser for AspectJ and discuss how the parser implementations of ajc \nand abc, two state-of-the-art compilers for AspectJ, solve these issues. In Sec\u00adtion5 we present the \ndesignofa syntax de.nition for AspectJ that de.nes its lexical as well as context-free syntax, overcoming \nthese issues. Our AspectJ syntax de.nition is based on the syntax de.\u00adnition formalism SDF2 [40] and \nits implementation with scanner\u00adless generalized-LR parsing (SGLR) [39, 14]. The combination of scannerless \n[33, 34] and generalized-LR [38] parsing supports the full class of context-free grammars and integrates \nthe scanner and parser. Due to these foundations, the de.nition elegantly deals with the extension and \nembedding of the Java language, the problems of context-sensitivelexical syntax, and the differentkeyword \npoli\u00adcies of ajc and abc.For the latter we introduce grammar mixins,a novel application of SDF s modularity \nfeatures. In Section6 weexamine theextensibilityof ajc and abc and we show how grammar mixins can be \nused to create and combine extensionsof the declarative syntax de.nition.In Section7we dis\u00adcuss the performance \nof our implementation. While LALR parsing with a separate scanner is guaranteed to be linear in the length \nof the input, the theoretical complexity ofGLR parsing depends on the grammar [31]. However, obtaining \na LALR grammar is often a non-trivial task and context-sensitive lexical syntax further com\u00adplicates \nmatters. The benchmark compares the performance of our parser to ajc, abc, and ANTLR.We conclude witha \ndiscussionof previous, related, and future work. In particular, we analyze why SGLR is not yet in widespread \nuse, and discuss research issues to be addressed to change this. The contributions of this paper are: \n An in-depth analysis of the intricacies of parsing AspectJ and how this is achieved in mainstream compilers, \ncompromising extensibility;  A declarative and formal de.nition of the context-free and lexical syntax \nof AspectJ;  Amodular formalizationofkeyword policies as appliedby the ajc and abc AspectJ compilers; \n An account of the application of scannerless parsing to ele\u00adgantly deal with context-sensitive lexical \nsyntax;  A demonstration of the extensibility of our AspectJ syntax de.nition;  A mixin-like mechanism \nfor combining syntactic extensions and instantiating sub-languages for use in different contexts;  \nAcase study showing the applicability of scannerless generalized-LR parsing to complex programming languages. \n Availability The AspectJ syntax de.nition and parser are avail\u00adable as part of AspectJ-front, which \nis open source (LGPL) and available at http://aspectj.syntax-definition.org. 2. Scanning andParsing \nIn this section we review the basic concepts of the conventional parser architecture using a separate \nscanner for tokenization and compare it to scannerless parsing, in which the parser reads char\u00adacters \ndirectly. A parser transforms a list of characters (the pro\u00adgramtext) intoa structured representation(a \nparse tree).Forexam\u00adple, Figure1showsa (simpli.ed) parse tree for theJava statement if (chars[count] \n== \\n ) line++;.Parse trees areabetter representation for language processing tools such as compilers \nthan plain text strings. 2.1 Tokenization or Scanning Conventional parsers divide the work between the \nproper parser, which recognizes the tree structure in a text, and a tokenizer or scanner, which divides \nthe list of characters that make up the program text into a list of tokens.For example, the Java statement \nif (chars[count] == \\n ) line++; is divided into tokens as follows if. (chars [count ] .==. \\n ) .line \n++ ; Figure2 illustrates the collaboration between scanner and parser. The parserbuildingaparse tree \nrequeststokensfromthe scanner, which reads characters from the input string. The reason for the division \nis the use of different techniques for the implementation of tokenization and parsing. Tokens can be \nrecognized using a deterministic .nite automaton (DFA), while parsers for recursive structures need a \npushdown automaton, i.e. a stack. Furthermore, tokenization reduces the number of items the parser has \nto consider; long sequences of characters are reduced to a single token, and whitespaces and comments \nare usually ignored by the parser. 2.2 Scanner andParser Generators Scanners and parsers can be generated \nfrom formal de.nitions of the lexical and context-free syntax of a language. Scanners are generated from \nregular expressions describing the tokens of the language and parsers are generated from context-free \ngrammars (BNF). Conventional parser generators such asYACC, Bison, and CUPacceptonlyarestrictedclassofcontext-free \ngrammarssuchas LL, LR, or LALR. The advantage is that the complexity of parsers for such grammars is \nlinear in the size of the input. Furthermore, grammarsin these classes are not ambiguous; only one interpre\u00adtationforanystringis \npossible.Thefact thata grammar does not belong in a certain class shows up as con.icts in the parse table. \nFor example, in the case of LR parsing, shift-reduce and reduce\u00adreduce con.icts indicate that the parser \ncannot make a decision Figure 1. Simpli.ed parse tree for a Java statement  Figure 2. A scanner-based \nparser uses a scanner to partition the input string into tokens, which become the leafs of parse trees. \nabout how to proceed based on the provided lookahead informa\u00adtion. Solving such con.icts requires rewriting \nthe grammar and sometimes changing the syntax of the language. Also, restricted classes of context-free \ngrammars are not closed under composition.  2.3 Lexical Context The uniform tokenization of the input \nstring by means of regular expressions can be problematic, since the scanner does not con\u00adsider the context \nin which a token occurs. This means that a partic\u00adular sequence of characters is interpreted as the same \ntoken every\u00adwhereinthe programtext.For syntactically simple languagesthat have been designed with this \nrestriction in mind this is not a prob\u00adlem. However, modern languages tend to become combinations of \ndomain-speci.c languages, each providing syntax appropriate for its domain. Because of the limitations \nof the ASCII character set, the same characters may play different roles in these languages. One solution \nthat is employed is the use of lexical state; the scanner operates in different modes depending on the \ncontext. This requires state switching when entering and leaving a context, and may require interaction \nbetween the scanner and the parser. 2.4 ProgrammaticParsers Another solution to bypass the restrictions \nposed by scanner and parser generators is the use of programmatic handwritten parsers, usually according \nto the recursive descent (topdown parsing) ap\u00adproach. The advantage is that it is easy to escape the \nrigor of the parsing algorithm and customize it where necessary. Possible cus\u00adtomizations are to drive \ntokenization from the parser to deal with lexical context or to provide customized error handling.A disad\u00advantage \nof programmatic parsers is that a parser does not provide a declarative speci.cation of the language; \nconversely, a formal grammar can serve as both documentation and implementation. Also, parser implementations \nare usually much larger in terms of lines of code, with all the implications for maintainability.  2.5 \nScannerless GeneralizedLRParsing A scannerless parser does not make use of a separate scanner to tokenize \nthe input [34]; the parser directly reads the characters of the input string. Instead of a separate speci.cation \nof lexical and context-free syntaxasis customaryin scanner-based parsing,asin\u00adgle grammar is used that \nde.nes all aspects of the language. Al\u00adthough there is no conceptual difference with scanner-based pars\u00ading, \nscannerless parsing is not in common use because it does notwork with conventional parser generators.Agrammar \nthat de\u00adscribes the lexical as well as the context-free syntax of a language does not usually .t in the \ngrammar classes supported by parser generators. The problem is that these algorithms need to make a decision \non the .rst (few) token(s) in the input. In the case of scan\u00adnerless parsing a decision may only be made \nafter reading an un\u00adbounded number of characters. This problem is solved by the use of Generalized-LR \n(GLR) parsing. GLR parsers use a parse table generated by a normal LR parser table generator, e.g. LALR(1) \nor SLR(0). At points in the input where the parser encounters a shift-reduce or reduce-reduce con.ict, \nthere are multiple possible continuations.In that casea GLR parser simulatestheexecutionof all possible \nLR parses in parallel. Scannerless GLR (SGLR) pars\u00ading adds a few disambiguation techniques to GLR parsing \nto make it suitable for scannerless parsing [39, 40, 14].Follow restrictions de.ne longest match disambiguation \nand reject productionsexpress reserved word policies. An advantage of SGLR parsing is that it deals \nnaturally with the problem of lexical context. Rather than parsing a lexical entity in isolation,asisdonewithregularexpressions,theparsing \ncontext acts naturallyaslexical state.Thus,the same sequenceof characters can be interpreted differently \nin different parts of a program. In the following sections we closely examine the differences between \nscanner-based and scannerless parsing, by studying state\u00adof-the-art implementationsof parsersfor AspectJ.In \nSection4 we analyze the properties of the parsers of the ajc and abc compilers for AspectJ.In Section5we \ndiscussa syntax de.nitionfor AspectJ using the declarative syntax de.nition formalism SDF2. 3. AQuick \nIntroduction to AspectJ To understand the examples and issues we discuss in this paper, it is importanttobe \nsomewhatfamiliarwiththe syntactical structure of an AspectJ program. This section brie.y discusses the \nvarious constructs of AspectJ. (In this paper we focus on the pointcut\u00adadvice mechanism of AspectJ.) \nKnowledge of their semantics is not necessary for this paper.Fora moreextensive accountof the AspectJ \nlanguage we refer to [1]. Figure3shows an AspectJ aspect for cachingexecutionsof the calc method of Fibonacci \nobjects. It shows the concise syntax for de.ning pointcuts, an around advice, and how this is mixed with \nnormalJava code (AspectJkeywords arein emphasized bold). Aspect Declarations Aspects can be declared, \nsimilar to Java classes, either as top-level entities or nested in Java classes 1. An aspect declaration \nconsistsofanumberof pointcut declarationsand advices, as well as standardJava members(e.g. the cache \n.eld 2). Pointcuts Apointcutisthe speci.cationofapatternofjoin points of interest to a given aspect. \nJoin points here are events in the dynamic execution of a program, e.g. a method call or an access to \nan object .eld. As such, the pointcut language of AspectJ is really a separate domain-speci.c language \nfor identifying join points. Apointcut is speci.ed using a number of pointcut designators. Primitive \npointcut designators refer to different kinds of operations in theexecutionofa program.For instance, \nexecution refers to the execution of a method 4 which method(s) is speci.ed by giving a method pattern \nas explained below. Furthermore, some pointcut designators are used either to further restrict a pointcut, \nor to bind some values to pointcut formal parameters. In Figure 3, the pointcut is given a name (a named \npointcut)and exposes one parameter of type int 3, which is bound via the args pointcut des\u00adignator to \nthe value of the argument to calc method executions 4 . 1 public aspect Caching { 2 private Map<Integer, \nInteger> cache = new HashMap<Integer, Integer>(); 3 pointcut cached(int value): 4 execution(* Fib.calc(int)) \n&#38;&#38; args(value); 5 int around(int value): cached(value) { if(cache.containsKey(value)) { return \ncache.get(value); } else { 6 int result = proceed(value); cache.put(value, result); return result; \n} } } Figure 3. Asample caching aspect in AspectJ. Advice Advice are pieces of code to execute when an \nassociated pointcut matches. This piece of code, which is similar to a Java method body, can be executed \nbefore, after, or around the inter\u00adcepted join point based on the advice kind. Since the caching aspect \nmay actually replace the execution of calc, it is declared to be of the around kind 5.Asa consequence, \nits return type(int)must be speci.ed. The caching advice is associated to the cached named pointcut, \nand it is parameterized by the value of the argument to calc. Within an around advice body, calling proceed \nresults in the intercepted join point to be executed 6. Patterns Fundamental to the pointcut language \nof AspectJ are patterns.A name pattern is used to denote names (method names, .eld names,type names)ina \ndeclarativefashion,using wildcards such as * and ?.A type pattern is used to denote types, e.g. int matches \nthe primitivetype int,whileA+ matches object type A and all its subtypes(+).A method pattern as in the \nexecution pointcut designator in 4 identi.es matching method signatures:areturn type pattern(* in 4),a \ndeclaring type pattern(Fib in 4), a name pattern (calc in 4), and then type patterns for the parameters(int \nin 4). 4. IssuesinParsing AspectJ In this section we give an overview of some of the challenges of parsing \nAspectJ. The overview is based on an analysis of the AspectJ language and a review of the source of the \nscanner and parser of the two major AspectJimplementations: the of.cial As\u00adpectJ compiler ajc, and the \nabc compiler from the AspectBench Compiler project [5]. The scanner and the parser of abc have par\u00adtiallybeen \ndocumentedin[21].The purposeofthisoverviewisto show that the parsers of the major implementations of \nAspectJ are not based on a declarative and complete de.nition of the language, which leads to minor differences \nbetween the two compilers and a lack of clarity about the exact language that each recognizes, as well \nas parsers that are not easy to maintain and extend. 4.1 Introduction The main source of the issues \nin parsing AspectJ is the difference between the lexical syntax of different parts of an AspectJ source \n.le. Conventionally, parsers use a separate scanner (or lexer)for lexical analysis that breaks up the \ninput character stream into a list of tokens, such as identi.ers, literals, layout, and speci.ckeywords \nsuch as class, public, and try. Usually this tokenization is applied uniformly to the text of a program, \nso at every offset in the input, all the same tokens of the language can be recognized by the scanner. \nHowever, this does not apply to AspectJ, which is infact morelikeamixtureof three languages.RegularJava \ncode, aspect declarations, and pointcut expressions each have a different lexical syntax. For example, \nin Java,get* is an identi.er followed by a mul\u00adtiplication operator, while in a pointcut expression it \nrepresents an identi.er pattern that matches anyidenti.er with pre.x get. In the .rst case, the scanner \nshould produce the tokens get *, while in the second case a single token get* would be expected. Similarly, \nthe + in the pointcut call(Foo+.new()) is not an addition oper\u00adator, but a subtype pattern that matches \nany subclass of Foo. To complicate matters, Java code can also occur within a pointcut def\u00adinition.For \ninstance, the if(...) pointcut designator takes as an argument a plain Java expression. The languages \ninvolved in AspectJ also havedifferent keywords. Depending on the AspectJ implementation, thesekeywords \nmight be reserved or not.For ajc, mostkeywords are not reserved, since atmostplacestheyareexplicitlyallowedas \nidenti.ersinthegram-mar.For example, aspect is a keyword, but it is allowed as the name of a local variable. \nSimilarly, around is not allowed as the nameofa methodin an aspect declaration,butitisin regularJava \ncode. On the other hand, around is allowed as the name of a local variable in regular Java as well as \nin aspect declarations. The abc compiler usesadifferentkeyword policy.Forexample, before isa keywordin \nthe contextof an aspect declaration,butis an identi.er in Java code and in pointcut expressions. In both \ncompilers, point\u00adcutexpressionkeywords, such as execution and get, are allowed as elements of a pointcut \nname pattern, e.g. Foo.execution is a valid name pattern, and so is get*. Hence, an AspectJ compiler \nneeds to consider the context of a sequence of characters to to decide what kind of token theyrepre\u00adsent. \nNext, we discuss in detail how abc and ajc parse AspectJ. 4.2 The ajc Scanner andParser The of.cial \nAspectJ compiler1, ajc,extendsthe Eclipse compiler for Java, which is developed as part of theEclipse \nJava Develop\u00admentTools (JDT) [17]. The parserof ajc roughly consists of three components: Scanner The \nscanner of ajc is a small extension of the regular Java scanner of the JDT. The JDT scanner and the extension \nin ajc are both written by hand. The scanner extension does nothing more than adding somekeywords to \nthe scanner. Parser The parser of ajc is generated from a grammar using the Jikes parser generator. The \ngrammar is a modi.ed version of the JDT grammar for regular Java. It does not actually de.ne the syntax \nof pointcut expressions: these are only scanned and parsed separately. The handwritten part of the JDT \nparser for constructing ASTs is extended as well. The original Java code has to be modi.ed at some places, \nmostly for making the parser more .exible and extensible by introducing factory methods. Presumably, \nthis could be merged with the JDT parser itself. PatternParser Ahandwritten recursive descent parser \nis invoked to parse the pointcut expressions of AspectJ after the source .le has been scanned and parsed \nby the previous components. Except for the if pointcut designator, the pattern parser works directly \non the result of the ajc scanner, since the parser parses pointcuts as a list of tokens. 4.2.1 Pointcuts \nThe most interesting part of the ajc parser is the handling of pointcuts. 1Our study is based on ajc \nversion 1.5.0. Scanner The ajc scanner is applied uniformly to the input pro\u00adgram, which means that the \nsame set of tokens is allowed at all offsets in the input. Note that the ajc scanner does not add tokens \nto the JDT scanner, except for some keywords, so the pointcuts are tokenized as anyother partof the source \n.le.Forexample, the pointcutofthe caching aspectin Figure3is scannedtothe follow\u00ading list of tokens: \nexecution ( * Fib . calc ( int ) ) &#38;&#38; args ( value ) This sequence of tokens is a correct tokenization \nof this pointcut, but our previous example of the simple name patternget* is ac\u00adtually not scanned as \nthe single token get*,but as the tokeniza\u00adtion you would expect in the context of a regular Java expression: \nan identi.er followed by a multiplication operator, i.e. the scanner produces the tokenization get *. \nStill, this does not look very harmful, but actually scanning pointcuts and Java code uniformly can lead \nto very strange tok-enizations.Forexample, consider the (somewhat arti.cial) pointcut call(* *1.Function+.apply(..)).For \nthis pointcut the cor\u00adrect tokenization according to the lexical syntax of pointcuts is: call ( **1. \nFunction + .apply ( ..)) However, the ajc scanner produces the following list of tokens for this pointcut: \ncall ( ** 1.F unction + .apply ( .. )) Perhaps surprisingly, Function has beensplitup and theFis now \npart of the token 1.F, which is a .oating-point literal where the F is a .oating-point suf.x. Of course, \na .oating-point literal is not allowed at all in this context in the source .le. As we will show later, \nthe pattern parser needs to work around this incorrect tokenization. Unfortunately, things can get even \nworse. Although rather un\u00adcommon, the .rst alpha-numerical character after the * in a simple name pattern \ncanbea number(infact, thisis also the casein the previous .oating-point example). The token that starts \nafter the * will always be scanned as a number by the JDT scanner, and the same will happen in the ajc \nscanner. The JDT scanner checks the structureof integer and .oating-point literalsby hand and immedi\u00adately \nstops parsing if it .nds a token that should be a .oating-point or integer literal accordingto theJavalexical \nsyntax,butisinvalid because certain parts of the literal are missing. This can result in error messages \nabout invalid literals, while in this context there can never actually be a literal. For example, scanning \nthe pointcutcall(void *0.Ef()) re\u00adports an Invalid .oat literal number because the scanner wants to recognize \n0.E as .oating-point literal,but the actualexponent numberis missing aftertheexponent indicator E.As \nanotherexam\u00adple, scanning the pointcut call(void Foo.*0X()) fails with the error message Invalid hex \nliteral number , since 0X indicates the startofahexadecimal .oating-pointorinteger literal,butthe actual \nnumeral is missing. Parser The ajc parser operates on the sequence of tokens pro\u00advided by the scanner. \nUnfortunately, for pointcuts the parser can\u00adnot do anything useful with this tokenization, since it is \nnot even close to the real lexical syntax of pointcuts in many cases. In a handwritten parser it might \nbe possible to workaround the incor\u00adrect tokenization,but the ajc parser is generated from a grammar \nusing the Jikes parser generator. In a grammar workarounds for in\u00adcorrect tokenizations are possible \nas well (as we will see later for parameterizedtypes)butfor pointcutsthiswouldbeextraordinarily dif.cult, \nif not impossible. For these reasons, the parser processes pointcuts just as a list of tokens called \npseudo tokens that are parsed separately by the handwritten pattern parser. In this way, the main parser \nbasically PointcutDeclaration ::= PcHeader FormalParamListopt ) : PseudoTokens ; DeclareDeclaration \n::= DeclareAnnoHeader PseudoTokensNoColon : Anno ; PseudoToken ::= ( | ) | . | * | Literal | new | JavaIdentifier \n| if ( Expression ) | ... ColonPseudoToken ::= : PseudoTokens ::= one or more PseudoToken or ColonPseudoToken \n PseudoTokensNoColon ::= one or more PseudoToken Figure 4. Pseudo tokens in the ajc grammar for AspectJ \n just skips pointcuts and forwards the output of the scanner (with a twist for the if pointcut) to the \npattern parser. It is essential that the parser can .nd the end of the pointcut without parsing the pointcut. \nFortunately, this is more or less the case in AspectJ, since pointcuts cannot contain semicolons, colons, \nand curly braces, except for the expression argument of the if pointcut designator, which we will discuss \nlater. The handling of pointcuts using pseudo tokens is illustrated in Figure 4: the .rst production \nde.nes pointcut declarations, where the pointcut, recognized as pseudo tokens, starts after the colon \nand is terminated by the semicolon. The second production for inter\u00adtype annotation declarations usesa \nsomewhat smaller setof pseudo tokens, since it is terminated by a colon instead of a semicolon. Most \nof the Java tokens, except for curly braces, semicolons, and colons, but including keywords, literals, \netc., are de.ned to be pseudo tokens. The if pointcut designator is a special case, since it takes a \nJava expression as an argument. Of course, the pattern parser should not reimplement the parsing of Java \nexpressions. Also, Java expressions could break the assumption that pointcuts do not contain colons, \nsemicolons, and curly braces.For these reasons, the if pointcut designator is parsed by ajc parser as \na special kind of pseudotoken, wheretheexpressionargumentisnotalistoftokens, but a real expression node \n(see Figure 4). Interestingly, this special pseudo token for the if pointcut des\u00adignator reserves the \nif keyword in pointcuts, while all other Java keywords are allowed in name patterns. Hence, the method \npattern boolean *.if*(..) is not allowed in ajc 2. PatternParser Finally, the handwritten pattern parser \nis applied to pointcuts, which have been parsed as pseudo tokens by the parser. The pattern parser takes \na fair amount of code, since the pointcut language of AspectJ is quite rich. Most of the code for parsing \npointcuts is rather straightforward, though cumbersome to implementbyhand.Themostcomplexcode handlestheparsingof \nname patterns. Since the tokenization performed by the ajc scan\u00adner is not correct, the pattern parser \ncannot just consume the tokens. Instead, it needs to consider all the possible cases of incorrect tok-enizations.Forexample, \nthe pointcuts call(* *1.foo(..)) and call(* *1.f oo(..)) arebothtokenizedinthe samewaybythe ajc scanner: \ncall (**1.f oo( .. )); However, the token sequences for these two pointcuts cannot be handled in the \nsame way, since the second one is incorrect, so 2This turnedouttobeaknown problem,seebug61535in ajc s \nBugzilla: https://bugs.eclipse.org/bugs/show bug.cgi?id=61535, which has been opened in May 2004. a parse \nerror needs to be reported. Therefore, the pattern parser checks if tokens are adjacent or not: while(true) \n{ tok = tokenSource.peek(); if(previous != null) { if(!isAdjacent(previous, tok)) break; } ... } The \nneed for this adjacencycheck follows naturally from thefact that the pattern parser has to redo the scanning \nat some parts of the pointcutandasingleAspectJ pointcuttokencanspan multipleJava tokens, in particular \nin name patterns. The special if pseudo tokens do not haveto be parsed anymore. For this purpose, theIToken \ninterface, of which PseudoToken and IfPseudoToken are implementations, is extended with a method maybeGetParsedPointcut \nthat immediately returns the pointcut ob\u00adject. This method is invoked from the pattern parser: public \nPointcut parseSinglePointcut() { IToken t = tokenSource.peek(); Pointcut p = t.maybeGetParsedPointcut(); \nif(p != null) { tokenSource.next(); return p; } String kind = parseIdentifier(); ... // continue parsing \nthe pointcut }  4.2.2 AjcParameterizedTypes Incorrect tokenization problems are not unique to AspectJ. \nEven in regular Java 5, a parser that applies a scanner uniformly to an input program has to deal with \nincorrect tokenizations, namely of parameterized types. For example, the parameterized type List<List<List<String>>> \nis tokenized by the ajc scanner as: List < List < List < String >>> where >>> is the unsigned right shift \noperator 3. Because of this, the grammar cannot just de.ne type arguments as a list of comma\u00adseparated \ntypes between < and > , since in some cases the .nal > will not actually be a separate token. This tokenization \nproblem has to be dealt with in two places: in the ajc grammarandinthe handwritten pattern parser.Forthe \najc grammar, Figure5shows the production rules for type arguments. Clearly, this is much more involved \nthan it should be 4. For the pattern parser, incorrect tokenizations of >> and >>> are .xed by splitting \nthe tokens during parsing when the expected token is a single >. Figure 6 show the code for this. The \neat method is used in the pattern parser to check if the next token is equal to a speci.ed, expected \ntoken.Ifa shift operatoris encountered,but a > is expected, then the token is split and the remainder \nof the token is stored in the variable pendingRightArrows, since the remainder is now the next token. \n 4.2.3 Ajc PseudoKeywords For compatibility with existing Java code,ajc does not reserve all thekeywords \nintroducedby AspectJ.Yet,the scannerof ajc does addkeywords to the lexical syntax of Java(aspect, pointcut, \nprivileged, before, after, around, and declare), which usu\u00adally implies thatthesekeywords cannotbe used \nas identi.ers since the scanner will reportthese tokens as beingkeywords.However, 3InC++thisisnotallowed:aspaceisrequired \nbetweentheanglebrackets. 4This workaround is documented in the GJ speci.cation [13]. TypeArgs ::= < \nTypeArgList1 TypeArgList -> TypeArg TypeArgList ::= TypeArgList , TypeArg TypeArgList1 -> TypeArg1 TypeArgList1 \n::= TypeArgList , TypeArg1 TypeArgList2 -> TypeArg2 TypeArgList2 ::= TypeArgList , TypeArg2 TypeArgList3 \n-> TypeArg3 TypeArgList3 ::= TypeArgList , TypeArg3 TypeArg ::= RefType TypeArg1 -> RefType1 TypeArg2 \n-> RefType2 TypeArg3 -> RefType3 RefType1 ::= RefType > RefType1 ::= ClassOrInterface < TypeArgList2 \nRefType2 ::= RefType >> RefType2 ::= ClassOrInterface < TypeArgList3 RefType3 ::= RefType >>> Figure \n5. Parameterized types in theajc grammar private void eat(String expected) { IToken next = nextToken(); \nif(next.getString() != expectedValue) { if(expected.equals(\">\") &#38;&#38; next.getString().startsWith(\">\")) \n{ pendingRightArrows = substring from 1 of next; return; } throw parse error }} private IToken pendingRightArrows; \nprivate IToken nextToken() { if(pendingRightArrows != null) IToken ret = pendingRightArrows; pendingRightArrows \n= null; return ret; else { return tokenSource.next(); } } Figure 6. Splitting shift operators in the \najc pattern parser in its grammar, ajc introduces JavaIdentifier, a new non\u00adterminal for identi.ers, \nfor which thesekeywords areexplicitly al\u00adlowed: JavaIdentifier -> Identifier JavaIdentifier -> AjSimpleName \nAjSimpleName -> around AjSimpleName -> AjSimpleNameNoAround AjSimpleNameNoAround -> aspect or privileged \nor pointcut or before or after or declare This extended identi.er replaces the original Identifier, \nwhich can no longer be one of the AspectJkeywords, at most places in the grammar. For example, the following \nproductions allow the AspectJkeywords as the nameofa class, method, localvariable, and .eld. ClassHeaderName1 \n::= Modifiersopt class JavaIdentifier MethodHeaderName ::= Modifiersopt Type JavaIdentifier ( VariableDeclaratorId \n::= JavaIdentifier Dimsopt However, the extended identi.er is not allowed everywhere. In particular, \nit cannot be the .rst identi.er of a type name, which means that it is not allowed as a simple type name, \nand cannot be the .rst identi.er of a quali.ed type name, which could refer to a top-level package or \nan enclosing class. For example, the .rst import declarationis not allowed,but the second oneis 5: import \nprivileged.*; import org.privileged.*; Ifkeywordswouldbeallowedassimpletype names,the grammar would no \nlonger be LALR(1). Thekeywords as type names intro\u00adduce shift-reduce and reduce-reduce con.icts. Hence, \na quali.ed name is de.ned to be an Identifier, followed by one or more JavaIdentifiers: ClassOrInterface \n::= Name SingleTypeImportDeclarationName ::= import Name Name -> SimpleName or QualifiedName SimpleName \n-> Identifier QualifiedName ::= Name . JavaIdentifier Pointcuts The names of the primitive AspectJ pointcut \ndesigna\u00adtors, such as get, set, call, etc., are not declared askeywords. The scanner does not have anyknowledge \nabout pointcuts, so the names are parsed as identi.ers, unless the pointcut designator was alreadyakeyword, \nsuch as if. As we have seen earlier, the name if is still accidentally a reserved keyword, but the names \nof the other pointcut designators are not, so they can be used in point\u00adcut expressions, for example \nin name patterns. However, a named pointcut with the same name as a primitive pointcut designator can \nnot be used (though surprisingly, it can be declared without warn\u00adings). Around Advice Declarations Around \nadvice declarations intro\u00adduce another complication. Whereas after and before advice dec\u00adlarations immediately \nstart with thekeywords after or before, around advice declarations start with a declaration of the return \ntype. This introduces a shift-reduce con.ict between an around ad\u00advice declaration and a method declaration. \nFor this reason, ajc does not allow methods named around in aspect declarations. Of course, it would \nnot be acceptable to disallow the name around for all methods, including the ones in regular Java classes, \nso this restriction should only apply to aspect declarations (advice cannot occur in class declarations). \nTherefore, the ajc grammar needs to duplicate all the productions (19) from an aspect declaration down \nto a method declaration, where .nally the name of a method is re\u00adstricted to a JavaIdNoAround: JavaIdNoAround \n-> Identifier JavaIdNoAround -> AjSimpleNameNoAround MethodHeaderNameNoAround ::= Modifiersopt TypeParameters \nType JavaIdNoAround (  4.3 The abc Scanner andParser The parser of abc6 is based on Polyglot [28], \nwhich provides PPG, a parser generator for extensible grammars based on the LALR CUP parser generator. \nPPG acts as a front-end for CUP, by adding some extensibility and modularity features, which we will \ndiscuss later in Section 6. Polyglot s scanner for Java is implemented using the JFlexscanner generator. \nPolyglot does not feature anextensible scanner, so the abc compiler implements its own scanner for As\u00adpectJ, \nwhich takes an approach radically different from ajc. The abc scanner and parser can parse the entire \nsource .le in a single continuous parse. So, the Java, aspect, and pointcut language are de.ned in a \nsingle JFlex speci.cation and CUP grammar. The abc 5This is related to ajc bug 37069 at https://bugs.eclipse.org/ \nbugs/show bug.cgi?id=37069 6Our study is based on abc version 1.1.0, which supports ajc 1.2.1 with some \nminor differences  Figure 7. Lexical state transitions in the abc scanner scanner is designed to immediately \nproduce the correct tokeniza\u00adtion, so there is no need to .x incorrect tokenizations later. Also, the \nscanner does not interact with the parser. 4.3.1 Managing Lexical State The abc scannerperformsa rudimentaryformof \ncontext-freepars\u00ading to recognize the global structure of the source .le while scan\u00adning. The scannerkeeps \ntrack of the current state (or context), by using a set of state transition rules that have been determined \nby a detailed analysis of the possible state switches in AspectJ. The lexical states and the transitions \nbetween them are illustrated in Figure 7. Some transitions have additional conditions, which we will \nexplain later. Maintaining lexical state is not uncommon. It is widely used for scanning string literals \nand it is a standard feature of JFlex. Every lexical state has its own set of lexical rules, which means \nthat a sequence of characters can be scanned as a different token in different states. Pointcut Declarations \nA simple example of such a state transi\u00adtion rule, is that a pointcut state is entered after the pointcut \nkey\u00adword and exited after a \";\" in pointcut context.For thisexample, the pointcut keyword and the semicolon \nindicates the start and end of a pointcut declaration, respectively. The exit of the pointcut state after \na pointcut declaration is implemented in the .ex speci.\u00adcation by returning to the previous state (which \nis maintained on a stack) whenever the \";\" token is encountered in the pointcut state (POINTCUT): <POINTCUT> \n{ \";\" { returnToPrevState(); return op(sym.SEMICOLON); }} For reasons of extensibility, keywords and \ntheir corresponding actions for entering lexical states are not speci.ed in the .ex speci.cation, but \nare initialized from the Java code by means of a Java interface LexerAction whose instances can be reg\u00adistered \nwith the scanner. LexerActions are always attached to keywords and can change the lexical state when \nthekeyword has been scanned.Forexample,the followingJava statement addsthe keyword pointcut, which starts \nthe pointcut declaration, to the scanner and speci.es that the new lexical state after thiskeyword is \npointcut. lexer.addAspectJKeyword(\"pointcut\", new LexerAction_c(new Integer(sym.POINTCUT), new Integer(lexer.pointcut_state()))); \n In thisway,keywords are registered per lexical state in a HashMap. Initially,keywords arealways scannedas \nidenti.ersand depending on the currentlexical state, the identi.eris turned intoakeyword by a lexer action. \nAs a side effect, the lexer action can modify thelexical stateof the scanner. Figure8showsa fragmentof \nthe Java class LexerAction c and the invocation of the lexer actions from the .ex speci.cation after \nan Identifier has been scanned. <YYINITIAL,ASPECTJ,POINTCUTIFEXPR,POINTCUT> { {Identifier} { LexerAction \nla; switch(yystate()) { case YYINITIAL: la = javaKeywords.get(yytext()); break; case ASPECTJ: la = aspectJKeywords.get(yytext()); \nbreak; ... } if(la != null) return key(la.getToken(this)); return id(); }} class LexerAction_c implements \nLexerAction { public Integer token; public Integer nextState; public int getToken(AbcLexer lexer) { if(nextState \n!= null) lexer.enterLexerState(nextState.intValue()); return token.intValue(); }} Figure 8. Lexer actions \nin the abc scanner Note that keywords are automatically reserved in this way, since the identi.erisalwaysbe \nturnedinakeywordif thereisalexer action for it. Note that this design choice for reseveredkeywordsis \ndifferent from the pseudokeyword policyusedby ajc. IfPointcut Designator The pointcut lexer action and \nthe lexi\u00adcal rule for ; look rather concise,but unfortunately, most rules are more complexthan this.For \ninstance, the if(..) pointcut designa\u00adtortakesaJavaexpressionasargument, whichhasthe samelexical syntax \nas Java code in Java context, so the lexical state should be changed for the argument of the if(..). \nEntering the lexical state is not very dif.cult: a lexer action for the if keyword can perform this state \ntransition.The followingJava statementaddsthe pointcut keywordif to the scanner and speci.es that the \nnew lexical state after thiskeywordis the special POINTCUTIFEXPR state: lexer.addPointcutKeyword(\"if\", \nnew LexerAction_c(new Integer(sym.PC_IF), new Integer(lexer.pointcutifexpr_state()))); However, for \nrecognizing the end of the if(..) pointcut designa\u00adtor, the scanner needs to .nd the closing parenthesis. \nOf course, a Java expression can contain parentheses as well. It would be in\u00adcorrect to leave the special \nlexical state at the .rst closing paren\u00adthesis. Thus, the scanner needs to .nd the closing parenthesis \nthat corresponds to the opening parenthesis after the if.For this purpose, the abc scanner maintains \na variable parenLevel that is used to balance the parentheses. If a \")\" is encountered, the parenLevel \nis decremented and the new parenLevel is com\u00adpared to the parenLevel of the if pointcut, for which the \ninitial parenLevel has been saved in the entry on the nestingStack: <YYINITIAL,ASPECTJ,POINTCUTIFEXPR> \n{ \"(\" { parenLevel++; return op(sym.LPAREN); } \")\" { parenLevel--; if((yystate() == POINTCUTIFEXPR) &#38;&#38; \n(parenLevel == nestingStack.peek().parenLevel)) returnToPrevState(); return op(sym.RPAREN); }} Per-clause \nThere are more places where pointcuts can occur in an AspectJ program: aspect declarations optionally \ntake a per-clause, whichis usedto controlthe instantiationof aspects.Forexample, declaring: aspect Foo \nperthis(pc ) { ... } entails that a new aspect instance of Foo is created for every this where the pointcut \npc matches. Finding out the end of the pointcut ofaper-clauseisabit moredif.cultthanfor normal pointcuts.The \nscanneragainneedsto.ndthe matchingclosing parenthesis,butit also needs to know if it is actually scanning \nthe pointcut of a per\u00adclauseor not. Insteadofanewlexical stateforper-clause pointcuts, the abc scanner \nuses a global boolean variable inPerPointcut. This variable is set to true by a lexer action for all \nper-clause keywords(perthis, percflow, etc.): class PerClauseLexerAction_c extends LexerAction_c { ... \npublic int getToken(AbcLexer lexer) { lexer.setInPerPointcut(true); return super.getToken(lexer); }} \n For a closing parenthesis in the pointcut lexical state, the scanner now needs to check if it is currently \nscanning a per-clause pointcut and if the closing parenthesis occurs at the same parenthesis level as \nthe opening parenthesis that preceded the pointcut: <POINTCUT> { \")\" { parenLevel--; if(inPerPointcut \n&#38;&#38; parenLevel == nestingStack.peek().parenLevel) { returnToPrevState(); inPerPointcut = false; \n} return op(sym.RPAREN); }} ClassKeyword While the end of a lexical state is detected in the .ex speci.cation \nby a lexical rule for a token, the start of a context is declaredin thelexer actionofakeyword.In most \ncases, the start ofanewlexical stateis clearly indicatedbyakeyword.However, the class keyword does not \nunambiguously indicate the start of the Javalexicalstateforaclass declaration,sinceitmayalsobeusedin \nclass literals(e.g. Foo.class).To distinguish a class literalfrom a class declaration, the abc scanner \nmaintains a special variable lastTokenWasDot. All tokens, except for the dot, set this variable tofalse. \nThe rule for the class token can now determine whether it appears in a class literal or a class declaration \nand change the scanner state accordingly. lexer.addGlobalKeyword(\"class\", new LexerAction_c(new Integer(sym.CLASS)) \n{ public int getToken(AbcLexer lexer) { if(!lexer.getLastTokenWasDot()) lexer.enterLexerState(aspectj \nor java ); return token.intValue(); }});  It is interesting to observe the consequences for the scanner \nif a keyword no longer unambiguously indicates the next lexical state. In this case, the scanner needs \nto be updated for all tokens to maintain the lastTokenWasDot variable. 4.3.2 Parser Thanks to the rudimentary \ncontext-free parsing in the scanner, the AspectJ grammar of abc is a clean modular extension of the basic \nJava grammar, implemented in PPG and based on the existing Polyglot grammar for Java. The grammar de.nes \nthe entire AspectJ language, including pointcuts and name patterns, which is not the case in ajc. reference_type_1 \n::= reference_type GT | class_or_interface LT type_argument_list_2; reference_type_2 ::= reference_type \nRSHIFT | class_or_interface LT type_argument_list_3; reference_type_3 ::= reference_type:a URSHIFT; wildcard \n::= QUESTION; wildcard_1 ::= QUESTION GT; wildcard_2 ::= QUESTION RSHIFT; wildcard_3 ::= QUESTION URSHIFT; \nFigure 9. Production Rules forParameterizedTypesin abc. Name Patterns There is one interesting language \nconstruct for which some undesirable production rules have to be de.ned: name patterns. The grammarexplicitly \nallows the reservedkeywordsof the pointcut lexical state as simple name pattern to allow name pat\u00adterns \nsuch as Foo.get.Withoutexplicitly allowingkeywords, this would be forbidden, since get isa reservedkeyword \nfor pointcuts in abc and will therefore not be parsed as an identi.er. The CUP production rules for this \nare: simple_name_pattern ::= PC_MULT | IDENTIFIERPATTERN | IDENTIFIER | aspectj_reserved_identifier ; \n aspectj_reserved_identifier ::= ASPECT | ... | PC_GET | ... | PC_SET ... ; This is somewhat unfortunate, \nbecause thekeywords for pointcuts are hence de.ned in the grammar, as well as in the Java code, namely \nfor adding lexer actions to the scanner. Extensions of As\u00adpectJ implemented in abc that introduce new \npointcut keywords have to extend the aspectj reserved identifier production as well. Extensions may easily \nforget to do this and thereby reserve their keywords in name patterns. This extensibility issue will \nbe discussed in more detail in Section 6. Ideally, the abc scanner should enter a new lexical state for \nname patterns, since the lexical syntax of name patterns differs from pointcuts(i.e. the setofkeywordsis \ndifferent).However, this will be more dif.cult to implement than the existing lexical states, since name \npatterns are not very explictly delimited by certain tokens 7. ParameterizedTypes Although abc does not \nsupport AspectJ 5.0 and parameterized types, it is interesting to take a look at how the scanning problems \nfor parameterized types would be solved in a similar setup of the scanner and parser. Currently, an extension \nof Polyglot for Java 5.0is under development at McGill. In contrast to the approach of the abc compiler, \nthe scanner of this extension does not always produce the correct tokenization for regularJava. Instead, \nthe grammar works around the incorrect tokenization of parameterized types by encoding this in the de.nition \nof type arguments and reference types. To illustrate this workaround for incorrect tokenization, some \nproduction rules of this grammar are shownin Figure9(lotsof detailshave been eluded).Toresolve this issue \na different lexical state should be used for types, since their lexical syntax is different from expressions. \nHowever, types will be very dif.cult to identify by a scanner in the input .le, so this approach is rather \nunlikely to work. Unfortunately, this grammar is now dif.cult to extend for ref\u00aderence types, since there \nare a large number of production rules involved, which encode the syntax of reference types in a rather \ntricky way. 7Indeed,very recentlybug72has been createdinthe abc bugzilla, which proposes to introduce \na lexer state for name patterns. See: http://abc. comlab.ox.ac.uk/cgi-bin/bugzilla/show bug.cgi?id=72 \n  4.4 Summary and Discussion We have discussed two approaches to parsing AspectJ. The ajc compiler usesa \nsingle scanner,but separate parsers (for regular code and for pointcut expressions). The abc compiler \nuses a single parser with a stateful scanner. Based on our analysis we can make the following observations. \nMany rules on the syntax of AspectJ are only operationally de.ned in the implementation of the scanner \nand parser. As a consequence neither implementation provides a declarative formalization of the syntax \nof AspectJ, although the LALR grammar of abc [21] is a step in the right direction. The ajc parser has \nundocumented implementation quirks because of the scanner implemented in and for plain Java. The abc \nparser improves over this by using a scanner with lexical states. The abc parser is also more predictable,but \nmanaging the lexical state in the parser is trickyand duplicates code and development effort. It is dif.cult \nto reason about the correctness and completeness of the context switching rules of the abc scanner.Forexample, \nthe useof the global variable inPerPointcut happens to work correctly in case an anonymous class is used \nwith aspect members in a per\u00adpointcut, but a slight change or extension of the language may render this \nimplementation invalid. Choices for introducing lexical states are guided by the complexity of determining \nthis lexical stateinthe scanner.Forexample,a separatelexical statefor name patterns might be more appropriate. \nIn conclusion, although the implementation techniques used in the parsers of ajc and abc are effective \nfor parsing AspectJ, their implementations have several drawbacks. 5. ADeclarative Syntax De.nitionfor \nAspectJ In the previous section, we have presented a range of implemen\u00adtation issues in parsing AspectJ, \nand the solutions for these in the two major AspectJ compilers, i.e. ajc and abc. As a consequence oftheseissues,thesyntaxofthelanguagethatis \nsupportedbythese compilersisnotclearly de.ned.Weconcludethatthe grammarfor\u00admalisms and parsing techniques \nthat are used are not suitable for the speci.cation of the AspectJ language.Acomplete and declarative \nde.nition of the syntax of the AspectJ language is lacking. Inthis section, we presenta de.nitionof the \nsyntaxof AspectJ that is declarative, modular, and extensible. Our AspectJ syntax de.nition is based \non the syntax de.nition formalism SDF and its implementation with scannerless generalized-LR parsing. \nThanks to these foundations, the de.nition elegantly deals with the exten\u00adsion and embedding of the Java \nlanguage, the problems of context\u00adsensitive lexical syntax, and the differentkeyword policies of the \najc and abc compilers. Indeed, the modularity of SDF allows us to de.ne three variations of the AspectJ \nlanguage: AJF, which is the most liberal de.nition, where only real ambi\u00adguities are resolved, forexamplebyreservingkeywordsatvery \nspeci.c locations.  AJC, which adds restrictions to the language to be more com\u00adpatible with the of.cial \nAspectJ compiler. The additional re\u00adstrictions are mostly related to shift-reduce problems in the LALR \nparser of ajc.  ABC, which reserveskeywordsina context-sensitiveway, thus de.ning the language supported \nby the abc compiler.  The AspectJ syntax de.nition modularly extends our syntax def\u00adinition for Java \n5 8. Also, the AJF, AJC, and ABC variations are all modular extensions of the basic AspectJ de.nition. \nMoreover, in Section6 we will show that our syntax de.nition can be easily extended with new aspect features.In \nSection7 we present bench\u00admark results, which show that these techniques yield a parser that 8Available \nathttp://java.syntax-definition.org module Java 7 8 imports Statements Expressions Identifiers exports \ncontext-free syntax PackageDec? ImportDec* TypeDec+ -> CompilationUnit 9 module Statements exports context-free \nsyntax \"for\" \"(\" FormalParam \":\" Expr \")\" Stm -> Stm \"while\" \"(\" Expr \")\" Stm -> Stm module Expressions \nexports context-free syntax ExprName -> Expr 10 Expr \"+\" Expr -> Expr {left} 11 MethodSpec \"(\" {Expr \n\",\"}* \")\" -> Expr 12 MethodName -> MethodSpec Expr \".\" TypeArgs? Id -> MethodSpec Figure 11. Fragment \nof syntax de.nition for aspects and advice.  module Identifiers exports lexical syntax [A-Za-z\\_\\$][A-Za-z0-9\\_\\$]* \n-> Id 13 lexicalrestrictions Id -/-[a-zA-Z0-9\\_\\$] 14 Figure 10. Fragment of syntax de.nition for Java \nperforms linear in the size of the input with an acceptable constant factor, at least for speci.cation, \nresearch and prototyping purposes. The core observation underlying the syntax de.nition is that AspectJ \nis a combination of languages, namely Java, aspects, and pointcuts. From this viewpoint, this work applies \nand extends pre\u00advious work on combining languages for the purpose of domain\u00adspeci.c language embedding \n[16] and meta-programming with concrete object syntax [15] (see Section 8.1). 5.1 Integrating Lexical \nand Context-Free Syntax SDF integrates the de.nition of lexical and context-free syntax in a single formalism, \nthus supporting the complete description of the syntax of a language in a single de.nition. In this way, \nthe lexical syntax of AspectJ can be integrated in the context-free syntax of AspectJ, which automatically \nleads to context-sensitive lexical syntax. Parsing of languages de.ned in SDF is implemented by the scannerless \ngeneralized-LR parser SGLR [39], which operates on individual characters instead of tokens. Thus, recognizing \nthe lexical constructs in a source .le is actually the same thing as parsing. This solves most of the \nissues in parsing AspectJ. Lexical syntax can be disambiguated in a declarative, explicit way, as opposedtothe \nimplicit,built-in heuristicsoflexical analy\u00adsistools, such asa longest-match policyanda preference forkey\u00adwords. \nWithout explicit speci.cation, keywords are not reserved and, for example, are perfectly valid as identi.ers. \nInstead, key\u00adwords can be reserved explicitly by de.ning reject productions. Java Figure 10 illustrates \nthe basic ideas of SDF with sam\u00adple modules and productions from the Java syntax de.nition. Of course, \nthe real syntax de.nition is much larger and spread over more modules. Note that the arguments of an \nSDF production are at the left and the resulting symbol is at the right, so an SDF pro\u00adduction s1 ... \nsn -> s0 de.nes that an element of non-terminal s0 can be produced by concatenating elements from non-terminals \ns1 ... sn, in that order. The modules of Figure 10 illustrate that mod\u00adules have names 7 and can import \nother modules 8. The module Java de.nes the composition of compilation units 9 from package declarations, \nimport declarations, and type declarations. Note the use of optional(?)and iterated(*,+)non-terminals. \nThe module Expressions de.nes expression names 10 (local variables, .elds, etc), addition of expressions \n11, which is declared to be left asso\u00adciative, and method invocation 12. The production rule for method \ninvocations uses {s lit}*, which is concise notation for a list of module AspectDeclaration exports \ncontext-free syntax AspectDecHead AspectBody -> AspectDec 15 AspectMod* \"aspect\" Id TypeParams? Super? \nInterfaces? PerClause? -> AspectDecHead 16 \"perthis\" \"(\" PointcutExpr \")\" -> PerClause 17 \"pertypewithin\" \n\"(\" TypePattern \")\" -> PerClause 18 AdviceMod* AdvSpec Throws? \":\" PointcutExpr MethodBody -> AdviceDec \n19 \"before\" \"(\" {Param \",\"}* \")\" -> AdvSpec 20 \"after\" \"(\" {Param \",\"}* \")\" ExitStatus? -> AdvSpec 21 \nResultType \"around\" \"(\" {Param \",\"}* \")\" -> AdvSpec 22 \"returning\" \"(\" Param \")\" -> ExitStatus 23 module \nPointcutExpression exports context-free syntax \"call \"(\" MethodConstrPattern \")\" -> PointcutExpr 24 \"get\" \n\"(\" FieldPattern \")\" -> PointcutExpr 25 \"this\" \"(\" TypeIdStar \")\" -> PointcutExpr 26 \"cflow\" \"(\" PointcutExpr \n\")\" -> PointcutExpr 27 \"if\" \"(\" Expr \")\" -> PointcutExpr 28 PointcutName \"(\" {TypeIdStar \",\"}* \")\" -> \nPointcutExpr 29 Id -> PointcutName Figure 12. Fragment of syntax de.nition for AspectJ pointcut expressions. \ns separated by lit. The module Identifiers shows how lexical syntax is de.ned in the same syntax de.nition \nas the context-free syntax. To de.ne lexical non-terminals such as identi.ers SDF provides character \nclasses to indicate sets of characters 13. The Identifiers module also de.nesalongest-match policyfor \niden\u00adti.ers, by declaring that identi.ers cannot directly be followed by one of the identi.er characters \n14. Another difference with respect to other formalisms is that there may be multiple productions for \nthe same non-terminal. This naturally leads to modular syntax def\u00adinitions in which syntax can be composed \nby importing modules. Aspects Similartothesyntax de.nitionofJava,SDF canbeused to de.ne modules for the \nlanguages of aspects, pointcut expres\u00adsions,and patterns. Figure11 presentsafew productionsfor aspect \ndeclarations in AspectJ. The .rst two productions de.ne aspect declarations 15 and aspect declaration \nheaders 16. Both produc\u00adtions use non-terminals from Java, for example Id, TypeParams (generics), and \nInterfaces. The aspect header may have a per\u00adclause, which can be used to control the instantiation scheme \nof an aspect.For instance,a perthis clause 17 speci.es that one aspect instanceis createdforeach currentlyexecutingobject(this)in \nthe join points matched by the pointcut expression given as a param\u00adeter. The per-clause pertypewithin \n18, which has been added to the language in AspectJ 5, is used to create a new aspect instance for each \ntype that matches the given type pattern. This is the only per-clause that does not take a pointcut expression \nas an argument. Advice declarations 19 are mainly based on an advice speci\u00ad.er and a pointcut expression, \nwhere an advice speci.er can be a before 20, after 21, or around 22 advice. Note that most of the pro\u00adductions \nagain refer to Java constructs, for example ResultType and Param (an abbreviation of FormalParam). Pointcuts \nThe AspectJ pointcut language is a language for con\u00adcisely describing a set of join points. Pointcut \nexpressions con\u00adsist of applications of pointcut designators, which can be primi\u00adtive or user-de.ned. \nAlso, pointcut expressions can be composed using boolean operators. Figure 12 shows some of the primitive \npointcuts of AspectJ. The call 24 and get 25 pointcut designators take patterns of methods, constructors, \nor .elds as arguments. The module Pattern exports context-free syntax IdPattern -> NamePattern NamePattern \n\".\" IdPattern -> NamePattern 30 NamePattern \"..\" IdPattern -> NamePattern PrimType -> TypePattern 31 \nTypeDecSpecPattern -> TypePattern TypeDecSpecPattern TypeParamsPattern -> TypePattern 32 NamePattern \n-> TypeDecSpecPattern 33 NamePattern \"+\" -> TypeDecSpecPattern 34 FieldModPat TypePat ClassMemberNamePat \n-> FieldPat 35 MethodModPat TypePat ClassMemberNamePat \"(\" {FormalPat \",\"}* \")\" ThrowsPat? -> MethodPat \n36 lexical syntax [a-zA-Z\\_\\$\\*][a-zA-Z0-9\\_\\$\\*]* -> IdPattern 37 Figure 13. Fragment of syntax de.nition \nfor AspectJ patterns. this 26 pointcut designator cannot be usedwith arbitrary type pat\u00adterns. Instead, \nthe argument must be a Type, an Id or a wildcard. The if 28 pointcut designator, which we have discussed \nbefore, takesa booleanJavaexpression as an argument. Finally, Figure12 de.nes the syntax for user-de.ned \npointcuts 29 in pointcut expres\u00adsions, whichhave been declared somewhere in the program using a pointcut \ndeclaration. Patterns The AspectJ pattern language plays an important role: as we have already seen, \nmost of the pointcut designators operate on patterns. Figure 13 shows some productions for the syntax \nof the pattern language. Name patterns are used to pick out names in aprogram.Aname patternisacompositionof \nidenti.er patterns37, which are used for matching identi.ers(i.e. names without a dot) by adding a * \nwildcard to the set of identi.er characters. The .. wildcard 30 can be used to include names from inner \ntypes, subpackages, etc. Almost every pointcut uses type patterns, which are used for selecting types. \nAny name pattern is a type pattern 33, but type patterns can also be used to match subtypes34, primitive \ntypes 31, parameterized types 32, etc. 36 35 Method and .eld patterns combine name patterns, type patterns, \nmodi.er patterns, throw patterns and patterns for formal parameter into complete signature patterns that \nare used to match methods and .elds by their signatures.  5.2 Composing AspectJ We have now illustrated \nhow the syntax of the sublanguages of AspectJ (Java, aspects, pointcuts, and patterns) can be de.ned \nas separate SDF modules. Next, we need to compose these modules into a syntax de.nition for AspectJ itself. \nIn SDF, we can combine two syntax de.nitions by creating a new module that imports the main modules of \nthe languages that need to be combined. The ease with which syntax de.nitions can be composed, is due \nto the two main features of the underlying parser: scannerless parsing and the use of the generalized-LRalgorithm. \nFirst, in a setting with a separate scanner such a combination would cause con.icts as has extensively \nbeen discussed in Sec\u00adtion4.However,inthescannerlessSDF settingthisdoesnotposea problem. Since lexical \nanalysis is integrated with parsing, context\u00adsensitivelexical analysis comesfor free.Forexample, when \npars\u00ading 1+1 as a Java expression the + will be seen as an addition oper\u00adator 11,but when parsing Foo+ \nin the context of a pointcut expres\u00adsion, then the + will be interpreted as a subtype pattern 34 . Second, \nif LL, LR, or LALR grammars are used, then the com\u00adbination of one or more languages is not guaranteed \nto be in the same subset, since these subsets of the context-free languages are not closed under composition. \nIndeed, if we combine method dec\u00adlarations from Java and advice declarations from aspects, then 38 module \nAspectJ imports Java AspectDeclaration PointcutExpression Pattern 39 exports context-free syntax AspectDec \n-> TypeDec ClassBodyDec -> AspectBodyDec 41 AspectDec -> ClassMemberDec 42 PointcutDec -> ClassMemberDec \n43 Figure 14. SDF module combining Java, pointcut, and aspect dec\u00adlarations. shift-reduce con.icts pop \nup since this combination is no longer LALR, as has been discussed in Section 4.2.3. Since SDF is im\u00adplemented \nusing generalized-LR parsing, SDF supports the full class of context-free grammars, which is closed under \ncomposi\u00adtion. Hence, new combinations of languages will stay inside the same class of context-free grammars. \nNevertheless, in some cases there will be ambiguities in the new combination of languages where there \nare actually two or more possible derivations for the same input. These ambiguities can be solved in \na declarative way using one of the SDF disambiguation .lters [14], such as reject, priorities, prefer, \nand associativity. Sec\u00adtion6 presentsexamplesof thisin AspectJextensions.However, this is not the case \nfor AspectJ. For example, the around advice problem is not a real ambiguity: the syntax of around advice \nand method declarations are similar for the .rst arguments, but the colon and the pointcut expression \ndistinguishes the around advice syntactically from method declarations. AspectJ Figure 14 illustrates \nhow the languages can be combined by importing 39 the modules of Java, aspects, pointcuts, and pat\u00adterns \n9. In this way, most of the integration happens automatically: the productions for pointcut expressions \nalready refer to patterns and aspect declarations already refer to pointcut expressions and patterns. \nBy importing all modules, the symbols and productions of these modules will be combined, and as a result \nthe pointcut ex\u00adpressions will automatically be available to the aspect declarations. Theintegrationofthe \nlanguagescanbeextendedandre.nedby adding more productions that connect the different sublanguages to \neach other.For instance, aspect declarations(AspectDec)are Java type declarations, since they can be \nused at the top-level of a source .le 40 (see also the production rule for compilation units 9). Furthermore, \naspect declarations 42 and pointcut declarations 43 can occur inside a class,i.e. as membersofaJava class \ndeclaration. Just as aspects and pointcuts can be de.ned in regular Java code, the declarations of aspects \ncan contain Java members such as constructors, initializers, .elds, and method declarations. Thus, Java \nclass body declarations(ClassBodyDec, i.e. elements of a Java class body) are allowed as aspect body \ndeclarations 41 . 5.3 Disambiguation and Restrictions We have not yet de.ned any reserved keywords or \nother restric\u00adtions for the syntax that we have presented. Next, we explain how the syntax de.nition \ncan be extended in a modular way toimpose additional restrictions on the language, such as different \nreserved keyword policies and requirements for being compatible with the language accepted by an LALR \ngrammar. First, we discuss how keywords can be reserved in SDF. Next, we discuss the real ambi\u00adguitiesof \nthe language that wehave presented sofar. The resulting syntax de.nition, which is the most liberal AspectJ \nsyntax de.ni\u00adtion without ambiguities, is called AJF. After that, we extend the restriction to achieve \nthe A JC and ABC variations, which are de\u00ad 9The actual composition in the full de.nition is somewhat \ndifferent, to make the de.nition more customizable.We will discuss this later. signedtobe compatible \nwiththe AspectJ languageas supportedby the ajc and abc compilers, respectively. ReservingKeywords Scannerless \nparsing does not require a syn\u00adtax de.nition to reservekeywords. Depending on the context, the same token \ncan forexamplebe interpreted asakeyword or as an identi.er.However,in some casesakeywordis inherently \nambigu\u00adousifitisnot reserved.Forexample,theJavaexpressions this and null would be ambiguous with the \nidenti.ers this and null if they would notbe reserved.In SDF reservedkeywords are de.ned using reject \nproductions[39], which are productions annotated with the reject keyword. The following twoSDF productions \nillustrate this mechanism: \"abstract\" | \"assert\" | ... | \"while\" -> Keyword Keyword -> Id {reject} The \n.rst production de.neskeywords and the second rejects these keywords as identi.ers. Reject productions \nemploy the capability of generalized-LR parsers to produce all possible derivations. In case of a keyword, \nthere will be two possible derivations: one using the real production for identi.ers and one using the \nreject production. If the reject production is applicable, then all possible parses that produce the \nsame non-terminal (in this case Id)are eliminated. In this way, the parse that uses the production for \nthe real identi.er is disallowed. Thus, in SDF reservedkeywords are de.ned per non-terminal:in theexample \nabove, thekeywords are only reserved for the Id non-terminal. If other identi.er-like non\u00adterminalswouldexistinJava(whichisnotthe \ncase),thenkeywords wouldnotbe reservedforthat non-terminal. Becausethereisjusta single identi.er non-terminalfor \nregularJava, this feature does not add muchovera mechanism for globalkeywords,but the feature is most \nuseful if languages are being combined: it can be used for de.ning context-sensitivekeywords. 5.3.1 \nAJF One of the few ambiguities in the syntax de.nition are the appli\u00adcations of user-de.ned 29 and primitive \npointcut designators.For example, the pointcut expression this(Foo) can be parsed as the primitive pointcut \nthis, but it can also parsed as a user-de.ned pointcut with the same name. To resolve this ambiguity, \nAJF re\u00adjectsthe namesof primitive pointcutsasthe nameofa user-de.ned pointcut, which is similar to the \nbehaviour of ajc and abc. To make the names of primitive pointcuts available to extensions and the other \nvariations of AspectJ, we introduce a new non-terminal: PrimPointcutName. These names are rejected as \nthe name of a used-de.ned pointcut. \"adviceexecution\" | \"args\" | \"call\" | ... | \"within\" | \"withincode\" \n-> PrimPointcutName PrimPointcutName -> PointcutName {reject} Another ambiguity that needstobe resolvedbyreservingkeywords \noccurs in type patterns.Type patterns are composed of name and identi.er patterns, but we have not imposed \nany restrictions on these name patterns, which implies that a name pattern can just as well be one of \nthebuilt-in types int, float, void, etc.We do not want to reject these types as identi.er patterns in \ngeneral, since thereis actuallyno ambiguity there.Toresolvethis ambiguity more precisely,we can disallowkeywords \nonly for the name patterns that are used as type patterns, i.e. TypeDecSpecPatterns 33. Keyword -> TypeDecSpecPattern \n{reject} The .nal ambiguity is a bit more surprising. The ajc compiler does not reserve keywords in patterns, \nnot even the regular Java keywords(except for thebug with the if pseudo token).Forex\u00adample, the method \npattern * try(String) is acceptedby ajc. Of course, this is not very useful since there can never be \na method with this name, but for now we follow this decision. As a re\u00adsult of this, the identi.er pattern \nnew is allowed for the name of a method in a method pattern. Surprisingly, the constructor pat\u00adtern *Handler+.new() \ncan now also be parsed as a method pat\u00adtern by splitting the *Handler identi.er pattern after any of \nits characters. The part before the split then serves as a type pattern for the return type of the method. \nFor example, one of the re\u00adsults of parsing are the method patterns * Handler+.new() and *H andler+.new(). \nThe reason for this is that SDF does not by default apply a longest-match policy. Of course, this split \nis not de\u00adsirable,sotodisallowthis,we de.nealongest-matchpolicy speci.\u00adcally for identi.er patterns usingafollowrestriction, \nwhich forbids derivations where an identi.er pattern is followed by a character that can occur in a pattern. \n IdPattern -/-[a-zA-Z0-9\\_\\$\\*]  5.3.2 AJC Compatibility In Section 4.2.3 we have discussed the pseudo \nkeyword policy of ajc in detail. Basically, the pseudo keywords of AspectJ are only reserved for a few \nspeci.c language constructs. This can concisely be expressed using reject productions, which allow the \nde.nition of reserved keywords per non-terminal. Similar to the PrimPointcutName we introduced earlier, \na new non-terminal for pseudokeywords can be used.For all the language constructs that cannot be pseudo \nkeywords, a reject production is de.ned. For example: \"aspect\" | \"pointcut\" | \"privileged\" | \"before\" \n| \"after\" | \"around\" | \"declare\" -> PseudoKeyword PseudoKeyword -> TypeName {reject} PseudoKeyword -> \nPackageOrTypeName {reject} The .rst production handles the case where a typename is a single identi.er(e.g. \naspect). The second case rejects pseudokeywords asthe .rst identi.erofthe quali.erofa typename(i.e. a \npackage\u00ador typename), which corresponds to the behavior of ajc, where pseudokeywords are not allowed \nas the .rst identi.erofa type\u00adname. Finally, to be more compatible with ajc,AJCcould produce parse errors \nfor incorrect .oating-point literals in name patterns by de.ning the syntax of incorrect .oating-point \nliterals and the name patterns that contain them. These patterns can then be rejected as name patterns. \nIf this behaviour were required, then this might be useful,but for now we leave this as an incompatibility \n. 5.3.3 ABC Compatibility While extending the syntax de.nition for compatibility with ajc was relatively \neasy, extending the de.nition (as we have presented it until now) to become compatible with abc is substantially \nmore dif.cult, if undertaken without the appropriate solutions. First, we discuss how a relatively easy \nrestriction of abc can be enforced. This leads to the explanation whyother restrictions are impossible \nto solve concisely in the current setup.For this, and for the de.ni\u00adtion of AspectJ extensions, we present \na novel method of combin\u00ading languages using grammar mixins. Grammar mixins then arise asthekeymechanismfor \ncomposingthe languagesinvolvedinAs\u00adpectJ. After discussing grammar mixins,we returntotheABCcom\u00adpatibility. \nKeywords and NamePatterns In Section 4.3 we have discussed that the abc compiler reservesadifferentsetofkeywordsperlex\u00adical \nstate.Forexample,in thelexical stateofa pointcut, abc re\u00adserves all the names of primitive pointcut designators.To \nsupport thesekeywords (such as the rather common get and set)in iden\u00adti.er patterns, they are explicitly \nallowed by the grammar of abc (Section 4.3.2).In SDF, thisis not an issue:keywords are reserved per non-terminal, \nsokeywords that have been reserved for identi\u00ad.ers are still allowed as identi.er patterns. As opposed \nto ajc, abc does not allow regular Javakeywords as identi.er patterns, so the previous example of the \nmethod pattern * try(String) results in a syntax error.In ourABC compatiblevariation, thisis handledby \nrejecting plainJavakeywords as identi.er patterns: Keyword -> IdPattern {reject} However, it is not obvious \nhow the context-sensitivekeywords of abc couldbe de.ned.Forexample, consider the following candi\u00addate \nfor making primitive pointcut nameskeywords: PrimPointcutName -> Keyword Unfortunately, adding this production \nreserveskeywordsinevery context, not just in pointcuts. The previous reject production for IdPattern \nillustrates whythis is the case: we only have a single keyword non-terminal and in this way we cannot \nhave context\u00adspeci.c setsofkeywords. Moreover,wehavejustasingle identi.er non-terminal(Id),but an identi.er \ncan occurinevery context, and forevery contextweneedto reserveadifferentsetofkeywords. Since we cannot \nrefer to an identi.er in a speci.c context, it is impossible to de.ne reserved keywords for it. Grammar \nmixins area solution for this,but are more generally useful than just for de.ning reservedkeywords. \n 5.4 Grammar Mixins In the context of object-oriented programming, mixins are abstract subclasses that \ncan be applied to different superclasses(i.e. are parameterizedintheir superclass)andinthiswaycanformafamily \nof related classes [12]. In the context of grammars, grammar mixins are syntax de.nitions that are parameterized \nwith the context in which they should be used. The key observation that leads to the use of mixins for \nde.ning AspectJ is that the language uses multiple instances of Java, which are mixed with the new language \nconstructsof AspectJ.Forexample,aJavaexpressioninthe context of an if pointcut is different from a Java \nexpression in an advice declaration or in a regular Java class. Similarly, an identi.er in the context \nof a pointcut is different from an identi.er in an aspect body declaration. Therefore, it should be possible \nto handle them as separate units, which would make it possible to customize them separately. Therefore, \nthe Javalanguage should be reusable in the de.nition of a new language, where the Java syntax effectively \nbecomes part of the new syntax de.nition, i.e. if syntax de.nition A1 imports B and C using mixin composition, \nthenthe syntaxof B and C should effectively become part of A1.Adifferent language A2 should be able to \ncompose itself with B or C and modify this newcomposition without affecting the other combination of \nA1, B, and C. Grammar mixins provide a more .exible way of composing languages compared to the plain \nimport mechanisms of SDF that we have been using until now. Using grammar mixins, Java can be mixed with \npointcuts, name patterns, and aspects and each of these combinations is again a unit for composition. \nAlso, it is possible to extend, customize, or restrict the Java language only for some speci.c combination. \nIn particular, SDF grammar mixins .ourish because the syntax de.nitions that are subject to mixin compositions \nare complete: the lexical as well as the context-free syntax is being composed and can both be customized \nforaspeci.c composition. In the next section we will showhowgrammar mixins can be used to their full \npotential to combine AspectJ language extensions by unifying mixin compositions. SDF Implementation For \nthe implementation of grammar mix\u00adins we make use of a combination of existing SDF features whose applicability \nto syntax de.nition had not been fully explored pre\u00adviously: parameterized modules and parameterized \nsymbols. Fig\u00adure 15 shows the SDF implementation of the mixin module for Java. An SDF grammar mixin is \nan SDF module that has a for\u00ad 44 module JavaMix[Ctx] 45 imports Java [ CompilationUnit => CompilationUnit[[Ctx]] \n46 TypeDec => TypeDec[[Ctx] ... FieldAccess => FieldAccess[[Ctx]] MethodSpec => MethodSpec[[Ctx] Expr \n=> Expr[[Ctx]] ] Figure 15. SDF grammar mixin for Java. module AspectJ[JavaCtx AspectCtx PointcutCtx \nPatternCtx] imports JavaMix[JavaCtx] 47 JavaMix[AspectCtx] JavaMix[PointcutCtx] JavaMix[PatternCtx] aspect/Declaration[AspectCtx \nJavaCtx] 48 pattern/Main[PatternCtx] 49 pointcut/Expression[PointcutCtx JavaCtx] 50 Figure 16. Main \nmodule of grammar mixin-based AspectJ AspectDec -> TypeDec[[JavaCtx]] 40 ClassBodyDec[[AspectCtx] -> \nAspectBodyDec 41 AspectDec -> ClassMemberDec[[JavaCtx]] 42 PointcutDec -> ClassMemberDec[[JavaCtx]] 43 \n\"before\" \"(\" {Param[[AspectCtx]] \",\"}* \")\" -> AdvSpec 20 \"if\" \"(\" Expr[[JavaCtx]] \")\" -> PointcutExpr \n28 PrimType[[PatternCtx]] -> TypePattern 31 Figure 17. AspectJ productions updated to grammar mixins. \nThe numbers refer to the productions mentioned earlier. mal parameter 44 that identi.esa particular mixin \ncomposition.By convention this parameter is called Ctx (for context) and the mod\u00adule name has the suf.x \nMix. This grammar mixin module imports the real syntax de.nition 45 and applies a renaming 46 to all \nthe non-terminals of the grammar, which places these non-terminals in the given Ctx by using a parameterized \nnon-terminal. The list of renamings covers all the non-terminals of the language, which can beaverylonglistthatis \ntediousto maintain. Therefore,weprovide a tool gen-sdf-mix that generatesa grammar mixin modulegiven \nanSDF syntax de.nition.The grammar mixinisnever modi.edby hand, so it can be regenerated automatically. \nAll grammar mixins that are imported using the same symbol for Ctx are subjected to mixin composition. \nIn a way, the import statement of SDF and Ctx symbol are the mixin composition oper\u00adatorsof grammar mixins.For \ngrammar mixins, composition means that the grammars of the syntax de.nitions involved in a compo\u00adsition \nare fully automatically combined, based on the normal SDF grammar composition semantics (which are also \napplied to plain imports). 5.5 AspectJ in the Mix Now we have revealed the actual design of the syntax \nde.nition, we need to revise the presentation of the AspectJ syntax. Figure 16 shows the imports of the \nmain module of the syntax de.nition. The AJF, AJC, and ABC variations import this module and the varia\u00adtion \nspeci.c modules. The AspectJ module itself has four con\u00adtexts parameters, to make the mixin composition \ncon.gurable for AspectJextensions. AspectJ imports the grammar mixin JavaMix four times, once forevery \ncontext. This makes all the non-terminals of Java available to AspectJ in these four contexts. The choice \nof the four contextsis somewhat arbitrary.Forexample,it mightbe a good idea to introduce an additional \ncontext for advice. Fortu\u00adnately, this is very easy to do by just importing another instance of the Java \ngrammar mixin with a symbol for that context. Our syntax de.nition has one context more than the abc \nscanner has lexical states: abc does not place patterns in a separate context. Next, the modules for \nthe sublanguages are imported, passing the required contexts as parameters to the modules.Forexample, \npointcut expressions 50 need to know theirown context,but also the context of regular Java expressions. \nThe imports of JavaMix and the sublanguage modules automat\u00adically compose all mixin compositions,but \nwe still need to make some interactions explicit, like we did earlier in Figure 14. How\u00adever,this time \nthe productions also connect non-terminalsfrom dif\u00adferent contexts (mixin compositions). Figure 17 shows \nsome of the production rules that we have discussed earlier,but this time us\u00ading the context parameters. \nFor example, aspect declarations are type declarations in the JavaCtx 40,but all the arguments of the \naspect declaration will be in the context of aspects, so an aspect declaration changes the context from \nJavaCtx to AspectCtx in this case. The second production 41 de.nes that regular Java class body declarations \nfrom the aspect context can be used as aspect body declarations. The productions for aspect 42 and pointcut \ndec\u00adlarations 43 makethese constructsavailableas class membersinthe regular Java context. Advice speci.ers \n20 use Java s formal param\u00adeters from the aspect context. The if pointcut expression takes an expression \nfrom the regularJava context as an argument.ForABC compatibility, we will later de.ne reservedkeywords \nper context. ByusingtheexpressionfromtheJava context, aspectand pointcut\u00adspeci.ckeywords willbe allowedin \nthisJavaexpression. Finally, the type pattern for primitive types 31 now uses a primitive type from the \npattern context. Note that the choice of the context of a symbol is completely up to the language designer: \nfor every production argument we can choose the most appropriate context. The choice of the context switches(lexicalstatetransitions)isnot \nin.uencedbythecomplex\u00adity of recognizing the context during lexical analysis. In the next section we \nshow that this enables language designers to improve their language designs.  5.6 ABC Compatibility \nRevised Thanks to the grammar mixins, we can now declare a different set of reserved keywords for each \ncontext. The AspectJ gram\u00admar now has four non-terminals for identi.ers: Id[[JavaCtx]], Id[[AspectCtx]], \nId[[PointcutCtx]], and Id[[PatternCtx]]. Similarly,there are four non-terminals forkeywords. Thus, the \nsyn\u00adtax de.nition can now rejecta different setof reservedkeywords for each speci.c context. The reject \nproduction is infact already de.ned in the Java modules imported by the AspectJ de.nition, so weonly \nneedtoextendtheexistingsetofkeywords.FortheJava context, abc introduces three newkeywords: \"privileged\" \n| \"aspect\" | \"pointcut\" -> Keyword[[JavaCtx]] For the aspect context, abc introducesa seriesof newkeywords. \nAlso,everykeyword fromtheJava contextisakeywordin aspect context. \"after\" | ... |\"proceed\" -> Keyword[[AspectCtx] \nKeyword[[JavaCtx]] -> Keyword[[AspectCtx] However, proceed is nowa reservedkeywordin aspect declara\u00adtions,soitisnolongerallowedasthe \nnameofamethodinvocation, which now rejects the special proceed call for invoking the orig\u00adinal operation \nin an around advice.To reintroduce the proceed call, we need to allow it explicitly as a method speci.er \nin the aspect context (note that an advice context would be useful here, though that would not be compatible \nwith abc, which is the whole point of this exercise). \"proceed\" -> MethodSpec[[AspectCtx]  In the context \nof pointcuts, abc reserves the Javakeywords, prim\u00aditive pointcut names, and some additionalkeywords from \nthe con\u00adtext of aspects. Keyword[[JavaCtx]] -> Keyword[[PointcutCtx]] PrimPointcutName -> Keyword[[PointcutCtx]] \n\"error\" | ... | \"warning\" -> Keyword[[PointcutCtx]] Finally,we stillneedto de.nekeywordsforthe contextof \npatterns, since our syntax de.nition uses a separate context for that. In abc, thesetwo statesaremerged,so \nde.ning patternkeywordsiseasy: Keyword[[PointcutCtx]] -> Keyword[[PatternCtx]] Keyword[[PatternCtx] -> \nIdPattern {reject}  We have now de.ned thekeyword policy of abc in a declarative way as a modular extension \nof the basic syntax de.nition. 6. AspectJ Syntax Extensions In the last few years, there has been a lot \nof research on extensions of AspectJ.Forexperimenting with aspect-oriented language fea\u00adtures, an extensible \ncompiler for AspectJ is most useful. One of the goals of the abc projectistofacilitatethis researchbyprovid\u00ading \nsuch an extensible compiler. The previous sections have high\u00adlighted a few challenges for the de.nition \nof the syntax of AspectJ and the implementation of an AspectJ parser. The result of this complexity is \nthat the parsers of ajc and abc are more complex than usual, since the requirements imposed on the parserbythe \nlan\u00adguage do not match the conventional parsing techniques too well. This section demonstrates these \nlimitations through several ex\u00adistingextensions and their issues.We compare the implementation of the \nsyntax of the extensions in abc to the de.nition of the syn\u00adtax in SDF, based on the syntax de.nition \nfor AspectJ that we pre\u00adsentedintheprevious section.Wewouldliketo emphasizethatthis discussion is all \nabout the syntax of the extensions, and not about the other compiler phases. Our modular and declarative \napproach for the de.nition of the syntax of AspectJ does not suddenly make the complete implementation \nof AspectJ extensions trivial, since a lot of work is going on in later compiler phases. Issues in Extensibility \nThe abc compiler is based on Poly\u00adglot [28], which provides PPG, a parser generator for extensible grammars \nbased on CUP, a LALR parser generator. The exten\u00adsibility features of PPG are based on manipulation of \ngrammars, with features such as drop a symbol, override productions of a symbol, and extend the productions \nof a symbol. This way of extending a grammar works in practice for most of the language extensions that \nhave been implemented for abc until now. Un\u00adfortunately this is not a truly modular mechanism, since \nLALR grammars do not compose, which means that the user of PPG has to make sure that the composed grammar \nstays in the LALR sub\u00adclass of context-free grammars. For example, we have discussed the problem of around \nadvice and method declarations with the name around. The abc compiler overcomes some of these issues \nby reservingkeywords. PPG does not feature anextensible scanner,so the abc compiler implementsitsown, \nstateful scanneraswehave discussedin detail. Thisworks .ne for the basic AspectJ language,butitis inherently \nnot modular. The rules for switching from context are based on knowledge of the entire language that \nis being scanned, which breaksdownifthe languageisextendedinan unexpectedway.The abc scannerallowsextensionstoaddkeywordsto \nspeci.c statesof the scanner.Inthisway,itis relativelyeasytoaddkeywords,butit is dif.cult to add operators \nand it is much more dif.cult to add new scanner states. For example, suppose that AspectJ did not de.ne \nan if(...) pointcut. It would have been non-trivial to extend the module HelloWorld[JavaCtx AspectCtx \nPointcutCtx] exports context-free syntax \"cast\" \"(\" TypePattern \")\" -> PointcutExpr 51 \"global\"\":\" ClassNamePattern \n\":\" PointcutExpr \";\" -> PointcutDec 52 \"cflowlevel\" \"(\" IntLiteral[[JavaCtx]] \",\" PointcutExpr \")\" -> \nPointcutExpr 53 lexical syntax \"cast\" -> Keyword[[PointcutCtx]] \"cflowlevel\" -> Keyword[[PointcutCtx]] \n\"global\" -> Keyword[[JavaCtx]] \"global\" -> Keyword[[AspectCtx] Figure 18. Syntax of some abc extensions \nimplemented in SDF scanner to handle this pointcut, since it requires the introduction of a new lexical \nstate that affects several aspects of the scanner. In these situations, the scanner has to be copied \nand modi.ed, which is undesirable for maintenance and composition of extensions. The modular syntax de.nition \nwe have presented solves many of these issues, since the de.nition itself can be extended in a modular \nway as well. Context or lexical state management is not based on rudimentary context-free parsingin the \nscanner,but fully integratedintheparserbytheuseof scannerlessparsing.Moreover, contexts can be uni.ed \nby mixin composition and ambiguities can be resolved in a modular way. 6.1 Simple Extensions First, we \ndiscuss some small AspectJ extensions that are part of the EAJ (Extended AspectJ) extension of abc. The \nSDF implementa\u00adtionoftheextensionsisshownin Figure18. SimilartothewayJava is extended, the AspectJ syntax \nde.nition can be extended by cre\u00adating a new module that imports AspectJ and adds new constructs. Cast \nand GlobalPointcuts The cast pointcut designator 51 can beusedtoselectpointsinthe programwhereanimplicitorexplicit \ncastis performed. Thisisavery simple pointcut designator,yet this simpleexample alreadyintroduces a problem \nthe implementerof theextension shouldbeaware of. Thekeyword cast is reserved in the contextofa pointcut,which \nmeansthatitisnolongerallowed as partofa name pattern (see Section 4.3.2).To resolve this, the keyword \nshould be added to the simple name patterns explicitly, which has not been done for this extension in \nthe abc implemen\u00adtation. The same problem occurs in the implementation of global pointcuts 52 (a mechanism \nfor globally restricting some aspects by extending their pointcut de.nitions). In our syntax de.nition \nthis is not an issue, since thekeywords are reserved per non-terminal. CFlowLevel The cflowlevel 10 pointcut \ndesignatorisanexten\u00adsion used to select join points based on the level of recursion. The cflowlevel pointcut \ndesignator takes two arguments: a number forthe recursionlevelanda pointcut.However,thelexical statefor \npointcuts in abc does not allow integer literals.Toavoid the need for a new lexical state or other complex \nsolutions, the syntax of the cflowlevel construct was changed to a string literal, which is supported \nin the pointcut lexical state 11. Unfortunately, in this case the syntax of the extension was designed \nto .t the existing lexical states of the scanner. In the SDF implementation of this extension referring \nto an integer literal is not a problem.  6.2 Open Modules Open modules were proposed by Aldrich [3] \nto solve the coupling issues that arise between aspects and the code theyadvise. It pro\u00ad 10Available \nat http://www.cs.manchester.ac.uk/cnc/projects/ loopsaj/cflowlevel/ 11 See http://abc.comlab.ox.ac.uk/archives/dev/2005-Aug/0003.html \n module AspectJMix[Ctx] imports AspectJ [ AspectDec => AspectDec[[Ctx]] AspectBodyDec => AspectBodyDec[[Ctx]] \n... TypePattern => TypePattern[[Ctx]] PointcutExpr => PointcutExpr[[Ctx] ] Figure 19. Grammar Mixin for \nAspectJ module OpenModule[JavaCtx] exports context-free syntax ModDec+ -> CompilationUnit[[JavaCtx]] \nRoot? \"module\" Id \"{\" ModMember* \"}\" -> ModDec \"class\" ClassNamePattern \";\" -> ModMember \"friend\" {AspectName \n\",\"}+ \";\" -> ModMember \"open\" {Module \",\"}+ \";\" -> ModMember \"constrain\" {Module \",\"}+ \";\" -> ModMember \nPrivate? \"expose\" ToClause? \":\" PointcutExpr \";\" -> ModMember Private? \"advertise\" ToClause? \":\" PointcutExpr \n\";\" -> ModMember \"to\" ClassNamePattern -> ToClause lexical syntax \"root\" | \"module\" -> Keyword[[JavaCtx]] \n\"module\" | ... | \"advertise\" -> Keyword Figure 20. SDF module extending AspectJ with open modules. vides \nan encapsulation construct that allows an implementation to limit the set of points to which external \nadvice applies. Recently, an abc extension was proposed that extends open modules to full AspectJ ([3] \nis in the context of a small functional language) and de.nes appropriate notions of module composition \n[29]. The nor\u00admal form of open modules as proposed in [29] is as follows: module ModuleName { class class \nname pattern friend list of friendly aspects expose : pointcut de.ning exposed join points } A module \ndeclaration applies to a set of classes as speci.ed in the class part. It states that aspects can only \nadvise join points matched by the pointcut speci.ed in the expose part. Friendly aspects, listed in the \nfriend part, have unrestricted access to the joinpoints occurringwithin classesofthe module.Theexactsyntax \nis more elaborate for notational convenience, and also includes constructs for restricting or opening \nmodules upon composition. The parsing of open modules requires a new lexical state. This needfallsoutofthe \ndesignedextensibilityof abc, as highlighted in Section4.3.Asa consequencethefull scannerhastobecopiedand \nmodi.ed. Although just 15 lines of code had to be modi.ed in the copy, this introduces a maintenance \nproblem: copying the scanner implies thatthedeveloperoftheextensionhastokeeptheextension in sync with \nthe main scanner of abc, which is bound evolve, for example to introduce support for AspectJ 5. SDF Conversely, \nSDF allows the syntax of open modules to be concisely and modularlyexpressed, as illustratedin Figure \n20.A new context can be introduced in a modular way. The implementa\u00adtion is based on the AspectJ grammar \nmixin module of Figure 19. 6.3 Context-Aware Aspects We now consider the AspectJ syntax extensions for \nthe pointcut restrictors proposed in [36] for context-aware aspects. Context\u00adaware aspects are aspects \nwhose pointcuts can depend on external context de.nitions, and whose advices may be parameterized with \ncontext information. Contexts are stateful, parameterized objects: theyare speci.ed by implementing a \ncontext class with a method that determines whetherthe contextisactiveornotatagivenpoint in time; context \nactivation can be based on any criteria, like the current control .ow of the application, some application-speci.c \ncondition, or input from environment sensors. A context is an object that may hold relevant state information \n(such as the value obtained from a given sensor). [36] proposes a number of general-purpose and domain-or \napplication-speci.c pointcut restrictors for restricting the applica\u00adbility of an aspect based on some \ncontext-related condition. These pointcut restrictors are explained using an AspectJ extended syn\u00adtax, \nalthough only a framework-based implementation is provided, based on the Re.exAOPkernel [37]. Syntax \nof Context-Aware Aspects From a syntactical viewpoint, context-aware aspects have the following requirements: \ni) Context restriction. The inContext pointcut restrictor is sim\u00adilar to an if pointcut designator, restricting \nthe applicability of an aspect(e.g. Discount)to the application currently being in a cer\u00adtain context(e.g. \nPromotionCtx): pointcut amount(): execution(double Item.getPrice()) &#38;&#38; inContext(PromotionCtx); \nii) Context state exposure. A mechanism is proposed to expose state associated to the context(e.g. discount \nrate) as a pointcut parameter, subsequently used in the advice: aspect Discount { pointcut amount(double \nrate): execution(* ShoppingCart.getAmount()) &#38;&#38; inContext(PromotionCtx(rate)); double around(double \nrate): amount(rate) { return proceed() * (1 -rate); }} Here the rate property of the PromotionCtx is \nexposed in the pointcut and subsequently used in the advice to compute the asso\u00adciated discount. iii) \nContext parameterization. Context activation can be param\u00adeterizedin orderto foster reuseof contexts.For \ninstance,a stock overload context can be parameterized with the ratio of stock over\u00ad.ow required to be \nconsidered active: pointcut amount(): execution(* ShoppingCart.getAmount()) &#38;&#38; inContext(StockOverloadCtx[.80]); \n In the above, the amount pointcutmatches onlyifthe stockover\u00adloadfactorissuperiorto80%whentherestofthepointcut \nmatches. iv) Extensible constructs. An important characteristic of the ap\u00adproach presentedin[36]isthe \npossibilitytoextendthesetofpoint\u00adcut restrictors, either general purpose or domain/application spe\u00adci.c. \nHence the set of context restrictors is open-ended. An example of general-purpose restrictor is one that \nmakes it possible to refer to past contexts, such as the context at creation timeofan object.For instance,the \ncreatedInCtx restrictor refers to the context in which the currently-executing object was created: pointcut \namount(): execution(* ShoppingCart.getAmount()) &#38;&#38; createdInCtx(PromotionCtx); In the above, \nthe amount pointcut matches if the current shop\u00adping cart was created in a promotional context, independently \nof whether the promotion context is still active at check-out time. An example of application-speci.c \nrestrictor for the EShop application is putInCartInCtx, which refers to the context at the time an item \nwas put in the shopping cart: pointcut amount(): execution(* Item.getPrice()) &#38;&#38; putInCartInCtx(PromotionCtx); \n module CtxAspect exports context-free syntax \"inContext\" \"(\" ActualCtx \")\" -> PointcutExpr \"createdInCtx\" \n\"(\" ActualCtx \")\" -> PointcutExpr TypeName[[JavaCtx]] ACParams? ACValues? -> ActualCtx \"[\" {Expr[[JavaCtx]] \n\",\"}+ \"]\" -> ACParams \"(\" {CtxId[[JavaCtx] \",\"}+ \")\" -> ACValues lexical syntax \"inContext\" | \"createdInCtx\" \n-> Keyword[[PointcutCtx]] module EShopCtxAspect imports CtxAspect exports context-free syntax \"putInCartInCtx\" \n\"(\" ActualCtx \")\" -> PointcutExpr lexical syntax \"putInCartInCtx\" -> Keyword[[PointcutCtx]] Figure \n21. Two SDF modules for context-aware aspects: (top) general-purpose pointcut restrictors; (bottom) application-speci.c \nextension for the EShop. Parsing Context-Aware Aspects Extending AspectJ with the two general-purpose \ncontext restrictors inContext and createdInCtx canbe de.nedina CtxAspect SDF module (Figure21(top)).The \ncontext-free syntax section de.nes the new syntax: a context re\u00adstrictor followed by the actual context \nde.nition; a context is a Java type name, with optional parameters and values (for state ex\u00adposure). \nThe lexical syntax section speci.es that the new pointcut restrictorshavetobe consideredaskeywordsina \npointcut context. Figure 21 (bottom) shows a modular syntactic extension for context-aware aspects with \nthe de.nition of the putInCartInCtx application-speci.c restrictor. Interestingly, it is not necessary \nto rede.nethe syntaxfor parametersandvaluesinthenew syntaxex\u00adtension de.nition(ActualCtx is visible from \nEShopCtxAspect). 7. Performance Deriving a production quality(i.e. ef.cient and with language\u00adspeci.c \nerror reporting) parser fromadeclarative, possibly ambigu\u00adous, syntax de.nition is one of the open problems \nin research on parsing techniques. In particular, the area of scannerless parsing is relatively new and \nthe number of implementations is very limited (i.e. about 2). This paper does not improve the performance, \nerror reporting or error recovery of these parsers in anyway: besides the arguments for a declarative \nspeci.cation of AspectJ, it only pro\u00advidesa strong motivation for continued research on unconventional \nparsing techniques. Although our current objectives are not to re\u00adplaceevery single parserina production \ncompilerbya scannerless generalized-LR parser,it is good to get an impression of the current state of \na scannerless generalized-LR parser compared to parsers used in existing compilers. In order to evaluate \nthe applicability of our approach beyond speci.cation purposes, we have performed some benchmarks to \nestimate the ef.ciency of scannerless generalized-LR parsing. It has been shown that although O(n 3) \nin the worst case (with n the length of the input), generalized-LR performs much better on gram\u00admars \nthat are near-LR [31], and that the cost of scannerless parsing is linear in the length of the input, \nalthough with an important con\u00adstantfactor [33]. There is little knowledge of how the integration of \nscannerless and generalized-LR parsing performs. We hereby compare the cost of the SGLR parser with that \nof abc, ajc, and ANTLR[30](anLL(k) parser generator)whenparsingbothamas\u00adsive amount of Java code and \nthe AspectJ testsuite of abc. 7.1 Benchmark Setup The test machine is an Intel Pentium 4 3.2GHz CPU with \n1GB memory, running SUSE 9.0. The abc, ajc, and ANTLR parsers use the Sun JDK 5.0. SGLR 3.15 isinvoked \nwith heuristic .lters andcycle detection disabled.For all parsers, we only measure the actual parse time: \nthis includes the construction of the parse tree, but no semantic analysis and I/O costs. In all benchmarks, \nthe same source .le is parsed 15 times and the .rst 10 parses are ignored to avoid start-upoverhead (class \nloadingandJIT compilationforJava, parse table loading for SGLR).For ANTLR we useversion 3.0b3 anda recentJava \n1.5 grammar writtenbyTerenceParr.  7.2 Benchmark Results Figure 22 shows the results of the Java benchmark: \nparsing of the source.lesoftheAzureus BittorrentclientandTomcat5.5.12.This .gure shows that parsing with \nall parsers is linear in the size of the input, illustratedby the trend lines (calculated using least-squares). \nSGLR parsing with the AspectJ grammar is about 4% slower than parsing with theJava grammar. The constantfactorof \nparsing with abc is about 40%of thefactorof SGLR. Clearly, the performance of ajc is superior to all \nthe other parsers. The performance of the ANTLR Java parseris more or less between the abc and ajc parsers, \nbut this is a plain Java parser. The creation of ANTLR parsers has been heavily optimized in this benchmark \nafter noticing the substantial setup cost of ANTLR3 parsers. The absolute times areall fractionsof second, \nwhichisonlyavery small portionofthe total amount of time required for compiling an AspectJ program, since \nthe most expensive tasks are in semantic analysis and actual weaving of aspects. Figure 23 shows the \nresults for parsing aspect code from the testsuite of abc. Note that the scales are different, since \naspect sources are typically smaller. Again, the parse time is linear in the size of the input, but the \nconstant factor of abc is about 60% of thefactor of SGLR. The performance of SGLR compared to ajc has \nimproved as well.For both Java parsers, parsing source .les closeto0bytesis relativelyexpensive.The reasonforthisisJIT \ncompilation, which still introduces start-up overhead after parsing the same .le 10 times before the \nactual benchmark. At .rst, we ignored just the .rst two parses, which had a dramatic impact on the performance. \nOverall, the parse time is always smaller than 0.06 second, so the absolute differences are extraordinarily \nsmall for these tiny source .les. We would have to benchmark larger aspect sources (which do not exist \nyet) to get more insight in the performance of parsing aspects and pointcuts. As a matter of fact, a \ntypical project consists of a lot of Java code with a few AspectJ aspects, so the Java benchmark is partic\u00adularly \nrelevant.To conclude, the absolute and relative performance of scannerless generalized-LR parsing is \npromising for the consid\u00aderedgrammars(Javaand AspectJ).Thefactthatthe parsersareim\u00adplementedinJavaversusCisnotrelevant,sincethemost \nimportant question is whether SGLR isfast enough in absolute time. Never\u00adtheless, since there is virtually \nno competition in the area of scan\u00adnerless parsing at present, there is ample opportunity for research \non making the performanceof scannerless parsingeven more com\u00adpetitive. 7.3 Testing The compatibility \nof the AJC syntax de.nition is tested heavily by applyingthe generated parsertoallthevalid source .lesofthe \ntest\u00adsuite of ajc 1.5.0.Testinginvalid sources requirestheexamination of the full ajc testsuiteto.ndoutif \ntests shouldfail becauseofse\u00admantic or syntactic problems. Thisisa considerableeffort,but will bevery \nuseful futurework.The resultsofthe testsuiteareavailable from the web page mentioned in the introduction. \n8. Discussion 8.1 PreviousWork Although SDF has a long history [20], a more recent redesign and reimplementation \nas SDF2 [40, 14] has made the language available for use outside of the algebraic speci.cation formalism \nASF+SDF. This redesign introduced the combination of scanner\u00adless and generalized-LR parsing [39]. In \n[16] we motivated the use of SGLR for parsing embedded domain-speci.c languages. This method, called \nM ETABORG, fo\u00adcuses on creating newlanguage combinations, where it is important to support combinations \nof languages with a different lexical syn\u00adtax. In [15] we presentedthe introduction of concrete object \nsyntax for AspectJ in Java as a reimplementation of the code generation tool Meta-AspectJ [41]. In that \nproject, we used the AspectJ syntax de.nitionof this paper,butthe design and bene.tsof the grammar were \nnot discussed. Compared to this earlier work, we have discussed the design of the syntax de.nition of \nAspectJ, which poses a challenge to parser generators.We discussedin detailhow complex differencesinlex\u00adical \nsyntax of the involved languages can concisely be de.ned in SDF, and how this is related to a stateful \nlexer. The syntax de.\u00adnition for AspectJ provides a compelling example of the applica\u00adtion of scannerless \nparsing to an existing language, where all of the following features of SDF prove their value: modular \nsyntax de.nition, rejects forkeywords, scannerless parsing, generalized-LR parsing, parameterized symbols, \nand parameterized modules. Grammar mixins are a surprisingly useful application of parame\u00adterized modules \nand non-terminals. Also, we presented a solution for implementing context-sensitivekeywordsin SDF.  \n8.2 RelatedWork Using a scannerless parser for AspectJ has not been proposed or even mentioned before \nin the literature. Concerning AspectJ implementations, we have discussed the abc and ajc scanners and \nparsers at length. The advantage of separate scanners is their foundation on .nite automata, which allowsfast \nimplementations. However, this char\u00adacteristic also implies obliviousness to context, while processing \nlanguages such as AspectJ requires introducing context-sensitivity into scanners. There are essentially \ntwo options to make scanners context-sensitive. First, the scanner may interact with the parser to retrieve \nthe context of a token. This is not very dif.cult to imple\u00admentinahandwrittenparser,butparser generatorsbasedonthisap\u00adproachare \nrare,andasfarasweknownonehavebeenusedtoparse AspectJ. Blender [9] uses GLR parsing with an incremental \nlexical analyzer that is forked together with the LR parsers in the GLR al\u00adgorithm.Asimilar approachwas \nalso usedby the implementation of SDF before the introduction of scannerless parsing [20]. Sec\u00adond, lexical \nanalysis may be extended with a rudimentary form of context-free parsing to recognize the global structure \nof the source .le while scanning by means of lexical states, without interaction with the parser. This \napproach is used in the abc scanner and parser for AspectJ. DURA-LexYt [10] supports lexical analysis \nwith multiple in\u00adterpretationsoftheinput.Asopposedto scannerlessparsing,asep\u00adarate scanner with support \nfor backtracking is used. In this way, choosing the correct lexical interpretation can be controlled \nby the parser without the need for managing lexical states in the scanner. DURA provides several levels \nof lexical backtracking tofacilitate typical scenarios of tokenization(e.g. a single or multiple divisions \ninto tokens), whereas scannerless parsing requires this to de.ned explicitly. Lexical backtracking can \nbe used for context-sensitive lexical analysis, but does not facilitate context-speci.c reserved keywords. \nDURA-LexYt does not support inherent ambiguities: the parser always returns a single parse tree, which \nmight also not be the one desired. More experience with lexical backtracking is required to getinsight \nin the performance compared to scannerless parsing. JTS Bali [8] is a tool for generating parsers for \nextensions of Java. It supports composition of lexical syntax based on heuristics such that the best \nresults are produced in the common cases.For example,keyword rules are put before the more general rules, \nsuch as for identi.ers. This means that it cannot handle lexical state and it not suitable for de.ning \nAspectJ-like extensions of Java. Parsing techniques with higher-order (parameterization) fea\u00adtures, such \nas parser combinators in higher-order functional lan\u00adguages[22],allow reuseand abstractionover grammars,butdonot \nsupport unanticipated reuse of a grammar. Grammar mixins, on the other hand, are modules based on unparameterized \ngrammars (e.g.Java)that makethis grammar reusable and allowunanticipated modi.cation of the grammar in \nevery context. 8.3 FutureWork 8.3.1 Grammar Mixins In this paper we have applied grammar mixins and \nexplained their functionality only in an informal way. In future work, we plan to make the notion of \ngrammar mixins more formal. In particular, the semantics of mixin composition of grammars that already \nuse mix\u00adins itself needs to be de.ned more precisely. Also, grammar mixins should be integrated in a \nsyntax de.nition formalism. Currently, an external tool is used to generate grammar mixin modules, which \nis not desirable. Furthermore,anotionof interfacesfor grammarmix\u00adinswouldbe usefulto separate the implementationofa \nmixin from its interface. Finally,multiple instantiationsofagrammar mixinfor a relativelylarge language,suchasJavaor \nAspectJhasamajorim\u00adpact on the performance of the parser generator, which could again besolvedbyintegrationof \ngrammar mixinsinthesyntax de.nition formalism. 8.3.2 Improvements to SDF and SGLR As we have shown in \nthis paper, SDF provides a declarative ap\u00adproach to solving complex parsing problems. Yet, the formalism \nand tools are not in widespread use. What may be the reason for this (other than publicity) and what \nimprovements can be made? Rule Syntax SDF s reverse grammar production rules may make developers accustomed \nto BNF style rules uncomfortable. It might make sense to provide a version of SDF using such a conventional \nstyle. Performance The benchmarks showed that the performance of the SGLR parser is a constantfactor \nslower than the abc parser, which should be acceptable for use at least in research projects. However, \nthere is good hope that the performance of SGLR can be much improved. There are alternative GLR implementa\u00adtions(e.g. \n[7, 27]) and alternative algorithms such as right-nulled GLR [35] with better performance than SGLR. \nHowever, these techniqueshavenotyet beenextendedto scannerless parsing, while scannerlessness is essential \nin our syntax de.nition for AspectJ. Even after these techniques are adopted, there remainsatheoretical \nperformancegap between GLR and LALR, since the complexity of GLR depends on the grammar. Therefore, it \nwould be useful to develop pro.ling tools that help grammar developers to detect performance bottlenecks \nin grammars. Error Reporting The current error reporting of SGLR is rather Spartan;itgivesthe lineand \ncolumn numbers where parsingfails. ThismaybeimprovedusingatechniquealongthelinesoftheMerr tool that generates \nerror reporting for LR parsers from examples [23]. This requires an adaption of the techniques where \nthe set of parsing statesatthefailurepointis interpreted. Analyzing Ambiguities The disadvantage of LR-like \nparser gen\u00aderators is that the grammar developer is confronted with shift\u00adreduce and reduce-reduce con.icts. \nHowever, this is also their ad\u00advantage; the developer is forced to develop an unambiguous gram\u00admar. When \nusing GLR there is no need to confront the developer, however, the con.icts are still there to inspect. \nIt would be useful to develop heuristics that can be used to inspect the con.icts in the parse table \nand use these to point the developer to problematic parts in the grammar. Platform A more mundane, not \nso scienti.c reason for lack of adoption may be the platform. The SDF parser generator and the SGLR parser \nare implemented in C and the distribution is Unix/Linux style. Furthermore, parse trees and abstract \nsyntax trees are represented using ATerms, which requires linking with theATerm library. Retargeting \nthe SDF/SGLR implementation to other platforms, such as Java, may help adoption.  8.3.3 Applications \nof the AspectJ Syntax De.nition With respect to the AspectJ syntax de.nition itself, there are a number \nof applications to consider. AspectJ Speci.cation For widespread acceptance of aspect\u00adoriented languages, \na complete speci.cation of the syntax and se\u00admantics of the language is important. In particular, concerns \nabout modifying the semantics of the host language could be reduced by at least having a complete speci.cation \nof the syntax of the lan\u00adguage. If there is enough interest in the speci.cation of the syntax and semanticsoftheAspectJ \nlanguage,thenwewouldliketowork with the AspectJ developers to make the current syntax de.nition even \nmore compatible with ajc and make it the basis of such a speci.cation. As one of the .rst applications, \nthe abc team has already used our syntax de.nition of AspectJ in a de.nition of the semantics of static \npointcuts, de.ned as a set of rewrite rules from AspectJ pointcuts to Datalog [6]. Connecting to the \nAspectBench Compiler Considering the ex\u00adtensibility goals of abc, our modular and extensible de.nition \nof AspectJwouldbe most usefulaspartofthefront-endof abc. Also, wehave shown that pseudokeywordsdo not \nrequirea handwritten parser, so the abc compiler could be made more compatible with syntax accepted by \najc. Multi-language AOP We are currently working on integrating the MetaBorgapproach[16]andthe Re.exAOPkernel \nproject[37] for multi-languageAOP. The current AspectJ syntax de.nition can be used to support AspectJ \nin Re.ex, allowing AspectJ extensions to be prototyped conveniently. 9. Conclusion We have presented \nthe design of a modular syntax de.nition for the complete syntax of AspectJ, i.e. integrating the formalization \nof the lexical and the context-free syntax of the language. In addition, we have shown that scannerless \nparsing in combination with an expressive module system can elegantly deal with the context\u00adsensitivelexicalsyntaxof \nAspectJ.The resultisa syntax de.nition that achieves a new level of extensibility for AspectJ, which \nis useful for research on aspect-oriented programming extensions. The performance of the scannerless \ngeneralized-LR parser for this grammar turns out to be linear with an acceptable constantfactor, which \nopens up possibilities for the integration of our solution in extensible compilers for AspectJ. Furthermore, \nour work on syntax de.nition for AspectJ pro\u00advides guidelines for approaching the current trend to design \npro\u00adgramming languages that are in fact mixtures of various sublan\u00adguages, for example for the integration \nof search capabilities or concrete object syntax (e.g. LINQ, E4X, XQuery,C.). The con\u00adventionofseparatingtheparsingprocessintoascannerandaparser \ndoes not apply to such languages, requiring language designers and implementers to reconsider the parsing \ntechniques to use. With the syntax de.nition for AspectJ, we haveshown that scan\u00adnerless generalized-LR \nparsing is not just useful for reverse en\u00adgineering, meta programming, interactive environments, language \nprototyping, and natural language processing,but that scannerless generalized-LR may at some point be \nused in compilers for mod\u00adern general-purpose languages. AspectJ makesastrong case for the use of scannerless \nparsing to provide concise, declarative speci.\u00adcation and implementation of the next-generation of programming \nlanguages. This result provides a strong motivation for addressing the bar\u00adrierstoawider adoptionof scannerless \ngeneralized-LR parsing that we observed in the previous section. Acknowledgments At UtrechtUniversitythis \nresearchwas supportedbytheNWO/Jac\u00adquard projectTraCE (638.001.201). E.Tanter is partially.nanced \u00b4by \nthe Millenium Nucleus Center for Web Research, Grant P04\u00ad067-F, Mideplan, Chile. We thank the abc team \nfor the report on the abc scanner and parser. The description of lexical states wasvery usefulinthedevelopmentof \nour syntax de.nition.Pavel Avgustinov of the abc team provided extensive feedback on the syntax de.nition. \nWe thank Arthur van Dam for his help with Gnuplot, and JurgenVinju for his advice on benchmarking SGLR. \nWe thank Mark van den Brand, Jurgen Vinju and the rest of the SDF/SGLR team at CWI for their work on \nthe maintenance and evolution of the SDF toolset.We thank RobVermaas for his help with the implementation \nof the syntax de.nition and benchmarking the generated parser. Finally, we would like to thank Eelco \nDolstra and the anonymous reviewers of OOPSLA for providing useful feedback on an earlier version of \nthis paper. References [1] AspectJ documentation. http://www.eclipse.org/aspectj/ docs.php. With links \nto the AspectJ Programming Guide and the AspectJ5Developer s Notebook. [2] Proc. of the 5th Intl. Conference \non Aspect-Oriented Software Development(AOSD 2006), Bonn, Germany, Mar. 2006.ACM Press. [3] J. Aldrich. \nOpen modules: Modular reasoning about advice. In Proc. of the European Conference on Object-Oriented \nProgramming (ECOOP 05), volume 3586 of LNCS, pages 144 168. Springer-Verlag, July 2005. [4] C. Allan,P.Avgustinov, \nA. S. Christensen, L. Hendren, S.Kuzins, O. Lhot\u00b4ak, O. de Moor, D. Sereni, G. Sittampalam, and J.Tibble. \nAdding trace matching with free variables to AspectJ. In Proc. of the 20thACM SIGPLAN Conference on Object-Oriented \nProgramming Systems, Languages and Applications (OOPSLA 2005), pages 345 364, San Diego, California, \nUSA, Oct. 2005. ACM Press. ACM SIGPLAN Notices, 40(11). [5]P.Avgustinov,A.S. Christensen,L. Hendren,S.Kuzins,J. \nLhot\u00b4ak, O.Lhot\u00b4ak,O.deMoor,D. Sereni,G. Sittampalam,andJ.Tibble. abc: an extensible AspectJ compiler. \nIn Proc. of the 4th Intl. Conference on Aspect-Oriented Software Development (AOSD 04), pages 87 98, \nNewYork,NY, USA, 2005.ACM Press. [6]P.Avgustinov,E. Hajiyev,N. Ongkingco,O.de Moor,D. Sereni, J.Tibble,andM.Verbaere. \nSemanticsof static pointcutsin AspectJ. Technical Report abc-2006-3, ProgrammingTools Group, Oxford University, \nOxford, United Kingdom, 2006. [7]J.AycockandR.N. Horspool.Faster generalizedlr parsing.In Proc. of 8th \nIntl. Conference on Compiler Construction (CC 99), volume 1575, pages 32 46, Amsterdam, March 1999. Springer-Verlag. \n[8] D. Batory,B. Lofaso, andY. Smaragdakis. JTS: tools for implement\u00ading domain-speci.c languages. In \nProc.Fifth Intl. Conference on Software Reuse (ICSR 98), pages 143 153. IEEE Computer Society, June 1998. \n[9] A. Begel and S. L. Graham. Language analysis and tools for input stream ambiguities. In FourthWorkshop \non Language Descriptions, Tools and Applications (LDTA 04), Electronic Notes in Theoretical Computer \nScience, Barcelona, Spain, April 2004. Elsevier. [10] D. Blasband. Parsing in a hostile world. In Proc. \nof the Eighth Working Conference on Reverse Engineering (WCRE 01), page 291, Washington, DC, USA, 2001. \nIEEE Computer Society. [11] E. Bodden andV. Stolz. J-LO, the Java Logical Observer. http: //www-i2.informatik.rwth-aachen.de/Research/RV/JLO/. \n[12] G. Bracha and W. Cook. Mixin-based inheritance. In OOP\u00adSLA/ECOOP 90, pages 303 311.ACM Press, 1990. \n[13] G. Bracha, M. Odersky, D. Stoutamire, andP.Wadler. GJ speci.ca\u00adtion, May 1998. [14] M.van den Brand,J. \nScheerder,J.J.Vinju, andE.Visser. Disam\u00adbiguation .lters for scannerless generalized LR parsers. In N. \nHor\u00adspool, editor, Compiler Construction (CC 02),volume 2304 ofLNCS, pages 143 158. Springer-Verlag, \nApril 2002. [15] M. Bravenboer, R.Vermaas, J. J.Vinju, and E.Visser. Generalized type-based disambiguation \nof meta programs with concrete object syntax. InGl \u00a8uck and Lowry [18], pages 157 172. [16] M. Bravenboer \nand E.Visser. Concrete syntax for objects. Domain\u00adspeci.c language embedding and assimilation without \nrestrictions. In D. C. Schmidt, editor, Proc.ofthe19thACM SIGPLAN Conferenceon Object-Oriented Programing, \nSystems, Languages, and Applications (OOPSLA 04), pages 365 383.ACM Press, October 2004. [17] Eclipse \nJava Development Tools (JDT) website. http://www. eclipse.org/jdt/. [18] R. Gl\u00a8uck and M. Lowry, editors. \nProc. of the 4th ACM SIG-PLAN/SIGSOFT Conference on Generative Programming and Com\u00adponent Engineering \n(GPCE 2005), volume 3676 of LNCS,Tallinn, Estonia, Sept./Oct. 2005. Springer-Verlag. [19] B. Harbulot \nand J. Gurd. Ajoin point for loops in AspectJ. In Proc. of the 5th Intl. Conference on Aspect-Oriented \nSoftware Development (AOSD 2006) [2]. [20] J. Heering,P. R. H. Hendriks,P. Klint, and J. Rekers. The \nsyntax de.nition formalism SDF reference manual. SIGPLAN Notices, 24(11):43 75, 1989. [21] L. Hendren, \nO. de Moor, A. S. Christensen, and the abc team. The abc scanner and parser, including an LALR(1) grammar \nfor AspectJ. Techrep, ProgrammingTools Group,Oxford University and the Sable research group, McGill University, \nSeptember 2004. [22] G. Hutton. Higher-order functions for parsing. Journal of Functional Programming, \n(2(3)):323 343, July 1992. [23] C. L. Jeffery. Generating LR syntax error messages from examples. ACM \nTransactions on Programming Languages and Systems (TOPLAS), 25(5):631 640, September 2003. [24] G. Kiczales, \nE. Hilsdale, J. Hugunin, M. Kersten, J. Palm, and W. G. Griswold. An overview of AspectJ. In J. Lindskov \nKnudsen, editor, ECOOP 2001: Object-Oriented Programming: 15th European Conference, volume 2072 of LNCS, \npages 327 353. Springer-Verlag, June 2001. [25] M. M. Lehman. On understanding laws, evolution, and \nconservation in the large-program life cycle. Journal of Systems and Software, 1(3):213 231, 1980. [26] \nH. Masuhara and K. Kawauchi. Data.ow pointcut in aspect\u00adoriented programming. In Proc. of theFirst Asian \nSymposium on Programming Languages and Systems (APLAS 03), volume 2895 of LNCS, pages 105 121. Springer-Verlag, \nNov. 2003. [27] S. McPeak andG.C. Necula. Elkhound:Afast, practical GLR parser generator. In E. Duesterwald, \neditor, Proc. of 13th Intl. Conference on Compiler Construction (CC 04), volume 2985 of LNCS, pages 73 \n88, Berlin, April 2004. Springer-Verlag. [28] N. Nystrom, M. R. Clarkson, and A. C. Myers. Polyglot: \nAn extensible compiler framework for Java. In Proc. of the 12th Intl. Conference on Compiler Construction, \nvolume 2622 of LNCS, pages 138 152. Springer-Verlag, April 2003. [29] N. Ongkingco,P.Avgustinov,J.Tibble,L. \nHendren,O.de Moor, and G. Sittampalam. Adding open modules to AspectJ. In Proc. of the 5th Intl. Conference \non Aspect-Oriented Software Development (AOSD 2006) [2]. [30]T.Parr. ANTLRParser Generator. http://www.antlr.org. \n[31] J. Rekers. Parser Generation for Interactive Environments. PhD thesis, University of Amsterdam, \n1992. [32] K. Sakurai,H. Masuhara,N. Ubayashi,S. Matsuura, andS.Komiya. Association aspects. In K. Lieberherr, \neditor, Proc. of the 3rdIntl. Conferenceon Aspect-Oriented SoftwareDevelopment(AOSD2004), pages 16 25, \nLancaster, UK, Mar. 2004.ACM Press. [33] D. J. Salomon and G.V. Cormack. Scannerless NSLR(1) parsing \nof programming languages. ACM SIGPLAN Notices, 24(7):170 178, 1989. Proc.oftheACM SIGPLAN 1989 ConferenceonProgramming \nLanguage Design and Implementation (PLDI 89). [34] D. J. Salomon and G. V. Cormack. The disambiguation \nand scannerless parsing of complete character-level grammars for programming languages. Technical Report \n95/06, Department of Computer Science,Universityof Manitoba,Winnipeg, Canada, 1995. [35] E. Scott and \nA. Johnstone. Right nulled GLR parsers. ACM Transactions on Programming Languages and Systems (TOPLAS), \n28(4):577 618, 2006. \u00b4 aspects. In Proc. of the 5th Intl. Symposium on Software Composition (SC 2006), \nLNCS, pages 227 249, Vienna, Austria, Mar. 2006. Springer-Verlag.  [36] E. Tanter, K. Gybels, M. Denker, \nand A. Bergel. Context-aware \u00b4 Gl\u00a8uck andLowry [18], pages 173 188.  [37] E.Tanter andJ.Noy\u00b4e.A versatilekernel \nfor multi-languageAOP. In [38] M.Tomita. Ef.cient Parsing for Natural Languages.AFast Algorithm for Practical \nSystems. Kluwer Academic Publishers, 1985. [39] E.Visser. Scannerless generalized-LR parsing. Technical \nReport P9707, Programming Research Group, University of Amsterdam, July 1997. [40] E.Visser. Syntax De.nition \nfor Language Prototyping. PhD thesis, University of Amsterdam, September 1997. [41] D. Zook, S. S. Huang, \nand Y. Smaragdakis. Generating AspectJ programs with Meta-AspectJ. In G. Karsai and E.Visser, editors, \nGenerative Programming and Component Engineering (GPCE 04), volume 3286 of LNCS, pages 1 19. Springer, \nOctober 2004.     \n\t\t\t", "proc_id": "1167473", "abstract": "Aspect-Oriented Programming (AOP) is attracting attention from both research and industry, as illustrated by the ever-growing popularity of AspectJ, the <i>de facto</i> standard AOP extension of Java. From a compiler construction perspective AspectJ is interesting as it is a typical example of <i>compositional language, ie</i> a language composed of a number of separate languages with different syntactical styles: in addition to plain Java, AspectJ includes a language for defining pointcuts and one for defining advices. Language composition represents a non-trivial challenge for conventional parsing techniques. First, combining several languages with different lexical syntax leads to considerable complexity in the lexical states to processed. Second, as new language features for AOP are being explored, many research proposals are concerned with <i>further extending</i> the AspectJ language, resulting in a need for an extensible syntax definition.This paper shows how <i>scannerless parsing</i> elegantly addresses the issues encountered by conventional techniques when parsing AspectJ . We present the design of a modular, extensible, and formal definition of the lexical and context-free aspects of the AspectJ syntax in the Syntax Definition Formalism SDF, which is implemented by a scannerless, generalized-LR parser (SGLR). We introduce <i>grammar mixins</i> as a novel application of SDF's modularity features, which allows the declarative definition of different keyword policies and combination of extensions. We illustrate the modular extensibility of our definition with syntax extensions taken from current research on aspect languages. Finally, benchmarks show the reasonable performance of scannerless generalized-LR parsing for this grammar.", "authors": [{"name": "Martin Bravenboer", "author_profile_id": "81100378172", "affiliation": "Utrecht University, The Netherlands", "person_id": "PP18001442", "email_address": "", "orcid_id": ""}, {"name": "&#201;ric Tanter", "author_profile_id": "81100346970", "affiliation": "University of Chile", "person_id": "PP18011123", "email_address": "", "orcid_id": ""}, {"name": "Eelco Visser", "author_profile_id": "81100561215", "affiliation": "Utrecht University, The Netherlands", "person_id": "PP43121329", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167491", "year": "2006", "article_id": "1167491", "conference": "OOPSLA", "title": "Declarative, formal, and extensible syntax definition for aspectJ", "url": "http://dl.acm.org/citation.cfm?id=1167491"}