{"article_publication_date": "10-16-2006", "fulltext": "\n Ef.cient Control Flow Quanti.cation Christoph Bockisch* Sebastian Kanthak* Michael Haupt*, Matthew \nArnold Mira Mezini* *Software Technology Group Darmstadt University of Technology, Germany Software Architecture \nResearch Group Hasso Plattner Institute for Software Systems Engineering, Potsdam, Germany IBM T. J. \nWatson Research Center Yorktown Heights, NY, USA {bockisch,mezini}@informatik.tu-darmstadt.de kanthak@st.informatik.tu-darmstadt.de \nmichael.haupt@hpi.uni-potsdam.de, marnold@us.ibm.com Abstract Aspect-oriented programming (AOP) is increasingly \ngaining in popularity. However, the focus of aspect-oriented language re\u00adsearch has been mostly on language \ndesign issues; ef.cient im\u00adplementation techniques have been less popular. As a result, the performance \nof certain AOP constructs is still poor. This is in par\u00adticular true for constructs that rely on dynamic \nproperties of the execution (e. g., the cflow construct). In this paper, we present ef.cient implementation \ntechniques for cflow that exploit direct access to internal structures of the virtual machine running \nan application, such as the call stack, as well as the integration of these techniques into the just-in-time \ncompiler code generation process. Our results show that AOP has the potential to make programs that need \nto de.ne control .ow-dependent behavior not only more modular but also more ef.cient. By making means \nfor control .ow\u00addependent behavior part of the language, AOP opens the possibility of applying sophisticated \ncompiler optimizations that are out of reach for application programmers. Categories and Subject Descriptors \nD.3.4 [Programming Lan\u00adguages]: Processors run-time environments General Terms Languages, Measurement, \nPerformance Keywords Aspect-oriented programming, virtual machine sup\u00adport, control .ow 1. Introduction \nThe aspect-oriented programming (AOP) paradigm [23, 14] intro\u00adduces a new kind of modules called aspects \nthat allow for cap\u00adturing crosscutting concerns in a localized way and with explicit interfaces to the \nrest of the system. Aspect-oriented programming languages introduce the following notions [22]. Crosscutting \nbehavior encapsulated in aspects is seen as func\u00adtionality that is to be executed whenever the application \nit cuts Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA \n06 October 22 26, 2006, Portland, Oregon, USA. Copyright c &#38;#169; 2006 ACM 1-59593-348-4/06/0010. \n. . $5.00 across reaches certain points in its execution. These points in the execution graph of an \napplication are called join points (e. g., method calls, .eld accesses, etc.). They are quanti.ed over \nby means of so-called pointcuts, which are queries over the execution of a program. Whenever a pointcut \nmatches, an advice associated with the matching pointcut is executed. Advice are method-like constructs. \nThe technique used to implement such a model is called weav\u00ading, denoting that an application s and its \ncrosscutting concerns control .ows are interwoven. Several approaches to implement weaving have been \ndevised [12]. The most common approach to\u00adday is bytecode weaving, where advice invocations are inserted \ninto application bytecode at locations called join point shadows [27]. Join point shadows are code structures \n(expressions, statements or blocks) that possibly yield join points during execution, e. g., the shadow \nof a method call is a call instruction. Join point shadows are determined by statically evaluating pointcuts. \nPointcuts that quantify over dynamic properties of join points cannot de.nitely be mapped to code locations. \nFor example, in AspectJ1 [22, 5], pointcuts exist that select join points depending on the current control \n.ow. The control .ow can be quanti.ed over by means of the cflow dynamic pointcut. The ef.ciency of implementations \nsupporting this pointcut is in the focus of this paper. Researchers and programmers have already identi.ed \nseveral useful usage scenarios for cflow pointcuts. It can be used to only execute advice the .rst time \nsome code section is entered, but not when it is entered recursively, e. g., to implement authentication. \nAnother use case is to restrict advice execution so that it does not (or does only) take effect if some \nsub-system of the application is currently acting. For example, the Law of Demeter (LoD) aspect [25] \nadvises, among others, all base application method executions. In the ad\u00advice, it stores objects captured \nfrom the application into a hash map, which causes their hashcode() method to be executed. Normally, \nthis would recursively trigger another advice execution. To avoid an endless recursion, the LoD aspect \ndoes not advise all method executions, but only all executions for which no advice from the LoD aspect \nis currently executing on the call stack. Note that the hashcode() method is called indirectly through \nJava s collection library. Thus, it would not be suf.cient to skip advice execution if the direct caller \nof a method is the LoD aspect. Instead, if a method 1 An aspect-oriented extension to Java. 1 class A{ \n2 Bb= new B(); 3 void m() { b.x(); } 4 void n() { b.y(); } 5 void o() { b.x(); b.y(); } 6 } 7 8 class \nB{ 9 void x() { ... this.k(); ... } 10 void y() { ... this.k(); ... } 11 void k() { ... } 12 } Listing \n1. Sample classes for cflow. execution is in the control .ow of some LoD method directly or indirectly, \nadvice must not be executed. Laddad [24] gives an extensive discussion of the cflow point\u00adcut. He presents \ntransaction management, policy enforcement and controlling tracing as examples. cflow is also used in \nindustrial projects that are implemented in AspectJ. The Glassbox Corpora\u00adtion s Glassbox Inspector [15] \n(a trouble-shooting tool for enter\u00adprise applications), employs cflow to, among others, restrict ad\u00advice \nto the top-level call of methods, excluding recursive calls. For illustration of the possible implementations \nof the cflow pointcut, consider the classes in Lst. 1. All three methods in A invoke methods on an instance \nof B, and both these methods in turn invoke, at some time during their execution, B.k(). Next, assume \nthat the call to k() is to be advised by some aspect, but only if k() is called in the course of an execution \nof A.m(). The corresponding pointcut, matching all calls to B.k() that occur in the control .ow of the \nexecution of A.m(), looks as follows: call(void B.k()) &#38;&#38; cflow(execution(void A.m ())) It cannot \nbe determined statically whether a particular call to k() is inside a certain control .ow. Hence, the \nweaver generates pieces of conditional logic called residues that are woven into application code at \njoin point shadows for calls to B.k(). A residue queries meta data to ensure that the advice is only \ninvoked when the dynamic condition is satis.ed. Different AOP implementations have different ways of \nimple\u00admenting these residues (details will be given in Sec. 2). The ma\u00adjority of existing AOP systems \nimplement them as calls to the par\u00adticular system s AOP infrastructure, and these calls are woven into \nthe application at join point shadows. This has the effect that the residues are executed by the virtual \nmachine as part of the run\u00adning application, which induces performance penalties due to the overhead \nassociated with maintaining, updating, and querying data structures connected with residues [13]. There \nare several ways to reduce the overhead introduced by these residues. The abc compiler [28, 8, 1] of \nthe AspectJ language employs static intra-and interprocedural analyses to reduce the number of required \nresidues. The abc compiler also optimizes code that ensures thread-safety for cflow pointcuts. The code \nproduced by abc is considerably faster [8] than that of ajc, the standard AspectJ compiler. The abc compiler \nperforms an interprocedural analysis only at its highest optimization level as it is very time-and memory-intensive. \nIt depends on a whole-program analysis that needs to know all possible entry points and the class .les \nfor all classes reachable from there. This places Java applications under a closed-world assumption that \ncontradicts Java s dynamic class loading capabilities. The closed world assumption is particularly hard \nto bear in the area of middleware containers, for which AOP has been recognized as a great tool to reduce \nthe complexity of transparent service injection; such containers heavily rely on dynamic deployment of \nbusiness applications. Our work on improving the ef.ciency of aspect-oriented pro\u00adgrams has followed \nanother path: integrating support for aspect\u00adoriented mechanisms directly at the execution layer, i. \ne., in the vir\u00adtual machine. The underlying rationale is as follows: The VM maintains some dynamic model \nof the execution as it executes the code, over which we can potentially directly quantify.  When required \ninformation is not directly accessible and we need to construct and maintain it, the supporting infrastructure \ncan be implemented more ef.ciently within the VM.  For the validation of our hypothesis, we have been \nworking on Steamloom [17, 9], a Java virtual machine with dedicated support for AOP mechanisms, which \nis based on IBM s Jikes Research Virtual Machine (RVM) [3, 2, 21]. With Steamloom, we have already shown \nthat supporting dy\u00adnamic aspect weaving within the virtual machine is bene.cial [17]. However, our previous \nwork was limited with regard to its depth of integrating aspect-oriented concepts into the virtual machine. \nThis is especially obvious regarding the treatment of residues for quan\u00adtifying over dynamic properties \nof join points. So far, Steamloom s treatment of residues is by weaving them as bytecodes into appli\u00adcation \nbytecodes; hence, it does not signi.cantly differ from other aspect-oriented implementations, except \nfor the fact that the VM weaves directly, rather than relying on a third-party bytecode ma\u00adnipulation \ntool. This paper goes a signi.cant step forward in deeper integration of support for aspect-oriented \nmechanisms within the virtual ma\u00adchine. Speci.cally, this paper focuses on the ef.cient implemen\u00adtation \nof quanti.cation over control .ows by means of the cflow pointcut. The contributions of the paper are \nas follows: 1. We show how existing implementation strategies for cflow can be made more ef.cient by \nexploiting direct access to internal structures of the VM, such as the call stack. Speci.cally, we consider \ntwo existing implementation strate\u00adgies for cflow: (a) the counter-based approach used by the AspectJ \ncompilers [22, 5, 28, 1], and (b) the stack walking approach used by some other aspect-oriented languages \nand frameworks, e. g., JAsCo [32, 19] and JBoss AOP [20]. 2. We present a new approach to implement \ncflow, which inte\u00adgrates support for it directly into the just-in-time (JIT) compil\u00aders of the Jikes \nRVM that dynamically translate Java bytecodes into ef.cient native machine code. This way, we offer the \nvirtual machine a better opportunity for optimizations. 3. Finally, we would like to draw the attention \nto another more conceptual contribution of the paper. The ef.ciency improve\u00adments that result from the \nintegration of support for cflow into the JIT compilers emphasize an advantage of aspect-oriented quanti.cation \nmechanisms that has been overlooked so far.  Hitherto, increased modularity has been the main argument \nfor AOP. While this is certainly the key bene.t of AOP, this pa\u00adper shows that AOP also has the potential \nto make programs that need to de.ne control .ow-dependent behavior more ef.\u00adcient. The idea is that by \nmaking means for such control .ow\u00addependent behavior part of the language, AOP opens the possi\u00adbility \nof applying sophisticated compiler optimizations that are out of reach for application programmers. Positive \neffects of AOP adoption on performance have previously also been ob\u00adserved in the setting of parallel \napplications [16]. The structure of this paper is as follows. In Sec. 2, we will .rst abstractly outline \ncommon implementation strategies for cflow. For each strategy, we will brie.y present current AOP implementa\u00adtions \nadopting it, and show how it has been realized in Steamloom. Sec. 3 covers our main contribution, a novel \nimplementation strat\u00adegy for cflow. The performance of all approaches presented in this paper is evaluated \nin Sec. 4. This section is also where the differ\u00adent approaches are discussed. Sec. 5 presents a discussion \nof future work and Sec. 6 concludes the paper. 2. C.ow Implementations We start this discussion by a \nshort introduction to the terminology used in the remainder of the paper. The following subsections each \npresent a particular approach to addressing control .ow matching. Each of the approaches is described \nin generalized form, fol\u00adlowed by a brief description of concrete AOP implementations em\u00adploying it. \nWe do not claim to provide a complete overview of ex\u00adisting AOP implementations; the systems described \nare typical rep\u00adresentatives. The approaches will also not be described in depth; for more detailed descriptions, \nwe refer to particular literature, or to a survey of AOP languages and their implementations [11]. For \neach of the particular approaches, we also give a description of its implementation in Steamloom. 2.1 \nC.ow Terminology When cflow is used, the idiom cflow(pc1) &#38;&#38; pc2 is frequently met, denoting \nthat the pointcut shall match join points pertaining to pc2 only if they occur in the control .ow of \nsome join point matched by pc1. In the following, join points matched by pc1 will be called control .ow \nconstituents. A control .ow constituent s shadows mark entries and exits of control .ows. Shadows pertain\u00ading \nto join points matched by pc2 will be called dependent shad\u00ad 2 ows. In general, an implementation of \ncflow needs to address the following two issues: 1. At constituent shadows, action needs to be taken \nto monitor the state of the control .ow, i. e., whether it is active or not. 2. At dependent shadows, \nit must be checked whether the control .ow is currently active. This is to determine whether the advice \nattached to the join point shadow needs to be invoked.  It is usually possible in AOP implementations \nto access the con\u00adtexts of constituent join points, and to use such context information in advice attached \nto dependent join points, e. g., the object that was active when the control .ow was constituted. We \ndo not provide an implementation of this feature, but discuss a possible implementa\u00adtion in Sec. 5.1. \nAlthough some of the approaches we compare our implementation with provide support for such context passing, \nthey all provide a more ef.cient infrastructure for cflow when no use is made of context passing.  2.2 \nCounters When this approach is adopted, residues that update counters are attached to control .ow entries \nand exits. When a control .ow is entered, the counter is incremented; it is decremented when the control \n.ow is left. At dependent shadows, residues check whether the counter is greater than zero. If so, the \ncontrol .ow is active and appendant advice can be executed. Control .ow counters exist once per control \n.ow. Furthermore, they must exist once per thread for this approach to work; other\u00ad 2 In [8], a terminology \nusing the corresponding terms update and query shadows has been introduced. wise, different threads \nentering and leaving the same control .ow could easily corrupt control .ow counter state. Using counters \nimposes a constant overhead at control .ow entries and exits as well as at dependent shadows. 2.2.1 Adoption \nAOP implementations employing the counter approach described above are AspectJ [22, 5] and AspectWerkz \n[10, 7]. Both avail\u00adable AspectJ compilers (ajc and abc) compile AspectJ pro\u00adgrams to Java bytecode, \ngenerating infrastructural code that uses ThreadLocal instances to encapsulate cflow counters. In princi\u00adple, \nAspectWerkz also follows the counters approach, but it always uses a stack to monitor control .ows. The \nstack is used by default to allow for accessing state from the constituent join points. Control .ow checks \nare implemented by querying the stack s size. The abc compiler [28, 8, 1] largely adopts the counter-based \napproach similar to ajc. However, it adds several optimizations. Thread-local counters are optimized \nfor the .rst application thread, so that accessing the counter via a ThreadLocal instance is avoided \nfor this thread. This facilitates a very quick retrieval of a counter object for single-threaded applications. \nMulti-threaded applications still have to use a ThreadLocal instance for counter management. Code generated \nby ajc always relies on ThreadLocal instances. Moreover, the abc compiler provides intra-and interprocedural \noptimizations to improve the performance of code conjoined with cflow pointcuts. Both optimization types \nare achieved using static analysis [31]. The abc compiler performs the time-and memory\u00adintensive interprocedural \nanalysis only at its highest optimization level. Of the intraprocedural optimizations abc applies, only \none is of further interest with regard to this paper. Others either deal with binding parameters from \nconstituent pointcuts, which is out of the focus of this paper, or have been described above. In fact, \nthe counter approach used in recent versions of ajc was .rst intro\u00adduced in abc. The remaining intraprocedural \noptimization employed in abc is the reuse of counters in methods [8]. From the observation that retrieving \na counter from thread-local storage can be expensive, the implementors of abc have derived the following \noptimization. Whenever a control .ow counter is required several times in a method (e. g., in a loop \nor at constituent shadows for control .ow entry and exit) the counter is shared in a local variable and \nhas to be retrieved only once. Since local variables are implicitly thread\u00adlocal, this optimization is \nobviously correct. As a result of interprocedural analysis, abc can completely avoid weaving cflow infrastructure \nat some join point shadows: in\u00adterprocedural analysis [8] exploits a call graph of the entire applica\u00adtion, \nwhich is why all classes reachable from the application s entry points must be known at compile-time. \nIn particular, if the virtual machine dynamically loads classes that are not known at compile\u00adtime, new \nexecution paths may be possible due to late binding of method calls in Java. If this happens, interprocedural \nanalysis be\u00adcomes unsound. In the following, we will give a brief overview of how abc s interprocedural \nanalysis works. For each pointcut expression containing a cflow designator, analysis yields three sets \nof join point shadows that are then further processed by the weaver. For the example cflow(pc1) &#38;&#38; \npc2, the three computed sets are as follows (in the following, residues and advice invocations mean those \npertaining to the sample pointcut only). The .rst set contains those shadows of pc2 that may occur in \na control .ow constituted by a shadow of pc1. At the shadows contained in this set, advice invocations \nmust be guarded by residues. At those shadows of pc2 that are not contained in the .rst set, neither \nresidues nor advice invocations need to be woven because they are guaranteed to never be executed inside \na control .ow pertaining to pc1. The second set contains those shadows of pc2 that are guar\u00adanteed to \noccur only in a control .ow constituted by a shadow of pc1. At these shadows, the advice invocation can \nbe woven without being guarded by a residue. At those shadows of pc2 that are not contained in the second \nset, residues are required. In the third set, those shadows of pc1 are contained that may in.uence the \nevaluation of residues at shadows of pc2. At these shadows, residues for counter or stack maintenance \nmust be woven.  2.2.2 Realization in Steamloom Steamloom s approach differs from other counter-based \nimplemen\u00adtations in how residues are implemented, and how thread-local counters are maintained. Residues \nwoven at both constituent and dependent shadows are calls to methods that are part of the virtual machine \nrather than other application methods. Thus, Steamloom s cflow residues are not subject to execution \nby the VM, but they are executed as a part of the VM s inherent functionality. Control .ow counters are \nalso not maintained at application level. They are stored directly in arrays that are themselves stored \nin the VM s internal representation of Java threads. Storing con\u00adtrol .ow counters in an array allows \nfor very fast access to them. The array indices for a given cflow s counters are .xed at the time the \ncorresponding aspect is woven into the application code and do not change while the aspect is active. \nThe arrays are resized dy\u00adnamically and the handles are recycled so that the maximum array size is bounded \nby the maximum number of control .ow point\u00adcuts that are deployed at a given moment in time. Since a \nparticular thread s array is only accessed by that thread, no synchronization is needed, enabling a lock-free \nimplementation of counter updating and checking residues. To reduce the cost of retrieving a counter \neven more, we have implemented the counter sharing proposed by abc [8] in Steam\u00adloom as well.  2.3 Stack \nWalking The stack walking approach does not require any residues at control .ow entries and exits. Instead, \nit gets hold of the current call stack at dependent shadows and iterates over the methods on the stack \nto check whether the control .ow in question is currently active. This approach does not need to regard \nthread locality, because the call stack that a residue accesses is always the one of the currently executing \nthread. There is no cost at control .ow entries and exits connected with stack walking. However, the \ncost imposed on dependent shadows directly depends on the depth of the call stack. In the most inauspi\u00adcious \ncase, the entire stack must be parsed only to determine that a particular control .ow is currently inactive. \n2.3.1 Adoption Depending on the language used, there are different approaches to access the call stack. \nIn Java, the call stack can be accessed by creating an instance of Throwable, which can be queried for \nthe stack frames via its getStackTrace() method. JAsCo [32, 19], an extension to Java, and JBoss AOP \n[20] follow this approach. In Smalltalk, the call stack is immediately accessible due to the re.ective \nnature of the language. AspectS [18, 6], implemented in Smalltalk, accesses the call stack by means of \nthe thisContext pseudo variable.  2.3.2 Realization in Steamloom The residues employed by Steamloom \nfor the stack walking ap\u00adproach are, as seen above with the counter approach, direct calls into the virtual \nmachine. A so-called stack frame matcher is cre\u00adated for a cflow designator when the aspect containing \na pointcut with that designator is woven into the application. From the point\u00adcut designator, the matcher \nbuilds, internally, a stack pattern rep\u00adresenting the stack layout (in terms of methods on the call stack) \nthat must be met in order for the constituent pointcut to match. In case of nested control .ows3, the \npattern contains the methods con\u00adstituting the nested control .ow in the given order. Each entry of the \npattern can, if the corresponding constituent pointcut contains wildcards, match multiple methods. The \nmatching process accesses VM-internal stack frames to extract the signature of the method executed in \neach frame. The method signatures retrieved from the stack frames are subsequently matched against the \nelements of the stack pattern to check. As soon as the pattern is safely identi.ed, the process stops, \nand the advice can be invoked. As this algorithm operates directly on the call stack maintained by the \nvirtual machine, no additional memory has to be allocated while traversing the stack. This reduces the \noverhead compared to the standard Java solution, which has to construct its own represen\u00adtation of the \ncall stack .rst by creating an instance of Throwable. 3. Control Flow Guards This section presents a \nnovel approach to implementing control .ow pointcuts in a virtual machine. Developing our solution inside \na VM has the advantage that dynamic optimization technology used in today s just-in-time (JIT) compilers \ncan be adapted and applied to dynamic aspect constructs. Our technique for optimizing cflow is based \non the concept of guards that protect the execution of code via lightweight tests. Our guarding approach \nis similar to that of thin guards [4], which uses lightweight guards to reduce the performance penalty \nof dynamic class loading in Java. This section begins with background information on thin guards. Sec. \n3.2 presents a high-level overview of our approach, and Sec. 3.3 describes our implementation in the \nJikes RVM. 3.1 Background: Thin Guards Thin guards [4] are a virtual machine optimization techique to \nenable ef.cient speculative optimizations, i. e., optimizations that rely on certain conditions being \ntrue. The primary application of thin guards was to reduce the performance penalty of dynamic class loading \nin Java. The VM would speculate that dynamic class loading will not occur, and optimize accordingly. \nAll speculative optimizations are guarded by a lightweight check to ensure that correct execution will \noccur if the assumptions change in the future. The application of thin guards involved three primary \nsteps. 1. Identify the optimistic assumptions. Optimistic assumptions are facts about the currently executing \nprogram that, when true, enable improved optimization. 2. Map the optimistic assumptions condition bits4, \nwhich are used to record whether the assumption is currently true. 3. Insert guards, lightweight tests \nthat check a condition bit, into the compiled code. Any region of code with speculative opti\u00admization \napplied is prepended with a guard; if the guard is false, an unoptimized (but correct) region of code \nis executed.  3 E. g., method m() only constitutes a control .ow if it is executed in the control .ow \nof o(). 4 Although referred to throughout the paper as a condition bit, the notion of a bit is abstract. \nThe implementation of the condition could be any representation that is convenient and ef.cient. 1 class \nFib { 2 public int test() { 3 return fib (5); 4 } 5 public int fib(int n) { 6 if (n <= 1) return 1; 7 \nreturn fib(n-1)+ fib(n -2); 8 } 9 } 10 aspect Aspect { 11 before() : call(int Fib.fib(int)) &#38;&#38; \n12 cflow(execution(int Fib.fib(int))) { 13 // ... 14 } 15 } Listing 2. Pointcut matching recursive calls \nto fib(). In the context of dynamic class loading, the optimistic assump\u00adtion is, no class loading has \noccured since the given method has been optimized. If class loading does occur, the condition bit is \nset to false to ensure that all speculative optimizations are disabled. The performance advantage of \nthin guards relies on two key observations. On the one hand, the overhead of a guard (checking a bit) \nis cheap, and on the other, optimization can be performed within a compiled method to remove redundant \nguards, thus creat\u00ading large regions of highly optimized, guard-free code.  3.2 Introduction to Control \nFlow Guards Our approach to optimizing conditional control .ow is similar to that of thin guards. Advice \ndepending on cflow pointcuts must execute only when certain conditions are met, i. e., when executed \nin the calling context of a control .ow constituent. Condition bits are used to monitor whether a thread \nis currently executing in the context of a cflow constituent. It is optimistically assumed that cflow-dependent \nadvice do not need to be executed, and such advice are protected by guards to verify that assumption. \nWhen the thread is executing in a context such that the advice need to be executed, the guard will ensure \nthey are executed. In our approach, the VM maintains a guard bit for every relevant control .ow, and \nthis bit is updated on entry/exit to that control .ow. Just like one distinct counter is used per control \n.ow selected by a pointcut in the counter based approaches (see Sec. 2.2), we use one distinct bit per \ncontrol .ow in the guards approach. As a result, there are as many control .ow guard bits per thread \nas there are different pointcuts using the cflow construct in the application. At shadows dependent on \ncontrol .ow i, advice execution is guarded by testing whether bit i is set. When the control .ow is left, \nthe bit cannot simply be reset: this would yield incorrect behavior for recursive control .ows. To cope \nwith recursive control .ows, each method activation record stores its own copy of the word containing \nthe control .ow guard bits: before setting the cflow bit at constituent shadows, the current value is \nstored into local storage of the current method activation. When leaving the control .ow, the bit s value \nis restored from local storage. This ensures correct behavior in the presence of recursive control .ows. \nFor illustration, consider the code in Lst. 2, which recursively computes the n th Fibonacci number, \nand includes a cflow aspect that advises recursive calls to the fib() method, save the initial call from \ninside the test() method. Lst. 3 shows the code for the two methods test() and fib() where the control \n.ow-dependent pointcut has been mapped to a bit that is stored as the 0th bit in a guard word. The execution \nof the fib() method constitutes the control .ow in question. Hence, at the beginning of this method, \n 1 int test () { 2 int result; 3 if((thread.cflowState &#38; 1) != 0) 4 advice (); 5 result = fib (5); \n6 return result; 7 } 8 9 int fib(int n) { 10 int oldState = thread.cflowState; 11 thread.cflowState |= \n1; 12 int result; 13 if (n <= 1) { 14 result = 1; 15 } else { 16 result = 0; 17 if ((thread.cflowState \n&#38; 1) != 0) 18 advice (); 19 result += fib(n -1); 20 if ((thread.cflowState &#38; 1) != 0) 21 advice \n(); 22 result += fib(n -2); 23 } 24 thread.cflowState = oldState; 25 return result; 26 } Listing 3. \nCompiled pseudo-code Fibonacci. the cflow state is saved in a local variable and the pointcut s cflow \nbit is set. At dependent shadows both in test() and fib(), the same bit is tested to see whether advice \nshould be executed. Finally, before returning from the method, the value saved in the local variable \nis restored into the thread s cflow state. As a result, only the outermost execution of fib() resets \nthe cflow bit and all recursive calls are correctly advised. When test() .rst invokes fib(), the cflow \nbit has not yet been set, hence this call does not lead to an execution of the advice. Please note that \nthe code shown is only pseudo-code: cflow guard bits have no representation at bytecode level. Rather, \nour implementation is integrated directly into the compilers of the virtual machine. This allows for \nadditional optimizations, as we will show in Sec. 3.3.3. The mapping of control .ow-dependent pointcuts \nto bit posi\u00adtions is done as soon as the pointcut is deployed. Thus, when\u00adever Java bytecode is translated \ninto machine code, the bit position needed at a particular join point shadow is constant and the required \nbit masks can be computed at compile-time. 3.3 Implementation We have implemented the approach in Steamloom \n[17, 9], an ex\u00adtension of the Jikes RVM that contains VM support for ef.cient aspect execution. The Jikes \nRVM has an adaptive optimization system that con\u00adtinuously monitors execution characteristics of the \nrunning appli\u00adcation. Initially, code is compiled by the baseline compiler. Since Jikes does not contain \na bytecode interpreter, it is important that the baseline compiler is executed quickly to avoid delays \nwhen a method is executed for the .rst time. To ensure ef.ciency, the base\u00adline compiler does not perform \nany optimizations, and the native code it emits very closely emulates the stack-machine model used by \nJava bytecode. If certain methods are observed to be executed frequently, based on pro.le data, they \nwill be recompiled by the optimizing compiler. The optimizing compiler applies state-of-the-art optimization \ntech\u00adniques to produce ef.cient code, including pro.le-directed inlining. Jikes RVM uses a mixture of \npreemptive and cooperative multi\u00adthreading. A small number of operating system-level threads can execute \na large number of Java threads. Jikes RVM s compilers generate machine code containing yield points, \nwhich transfer con\u00adtrol to another Java thread if the current thread s time slot has elapsed. Every operating \nsystem-level thread is represented by an in\u00adstance of the VM_Processor class5, which holds a reference \nto the object representing the thread that is currently executed on this processor. A reference to the \ncurrent processor object is always held in a special register, the processor register. The remainder \nof this section describes our storage of the cflow condition bits, as well as our changes to Jikes RVM \ns baseline and optimizing compilers. 3.3.1 Condition Bits One word of storage is allocated per thread \nto accommodate cflow guard bits. This allows for monitoring 32 different control .ow pointcuts, which \nshould be enough for most applications. The sys\u00adtem can fall back to a more conventional counter-based \nstrategy if more than 32 different control .ow pointcuts are used6. To store cflow state information \nthread-locally, the virtual ma\u00adchine s multi-threading design is exploited. One word is added to every \nthread object, and this word is used to store the thread s cflow state. To improve the performance of \naccessing this .eld, it is added to the processor object as well. Upon every thread switch, the value \nin the processor object is synchronized with the value in the thread object. Since the address of the \nprocessor object is always held in a register and the position of the cflow state .eld in the processor \nobject is a constant offset known at compile-time, the cflow state .eld can be accessed with as little \noverhead as a single memory load or write operation.  3.3.2 Guards in the Baseline Compiler For the \nbaseline compiler, the operations described in 3.2 are im\u00adplemented in a straightforward way. For accessing \nthe cflow state word, a memory load or write operation is used. To test or modify a single bit, standard \nbit operations (like bitwise and or or) are used. At constituent shadows, an additional word is used \nin the method s stack frame. Before setting the cflow bit, the old value is copied into this guard word. \nWhen the method is left, the guard word is copied back into the processor object s .eld to restore the \ncflow state. Machine code (for the x86 architecture) generated by the base\u00adline compiler for all control \n.ow state related operations is shown in Lst. 4. The esi register holds a reference to the processor \nob\u00adject, which contains the cflow state .eld at the offset given by field_offset. A reference to the \ncurrent method s stack frame is stored in the esp register by the baseline compiler. Jikes stack frame \nlayout for baseline-compiled methods can be seen in Fig. 1. The old control .ow state is stored in a \nspecial slot of the stack frame, which is located at offset stack_offset. Note that the code is fairly \ninef.cient, particularly the part that tests whether control .ow 0 is active. First, the index of the \ncontrol .ow to test (0) is pushed on the stack and then popped into a register to produce a bit mask \nthat can be AND-ed with the processor .eld. 5 Operating system-level threads are internally called virtual \nprocessors in Jikes. 6 Guards can be used for the 32 most-used control .ows, and the fallback strategy \nfor additional pointcuts. Furthermore, the number of bits used as control .ow guards could easily be \nincreased if applications using a large number of control .ow pointcuts become common; of course, at \nthe cost of additional space per thread. current frame pointer stack_offset  next method frame Figure \n1. Stack frame layout for baseline-compiled methods. 1 ;; save cflow state in stack frame 2 MOV ecx [esi]<field_offset \n> 3 MOV [esp]<stack_offset > ecx 4 ;; enter control flow 0 5 PUSH 0 6 POP ecx 7 MOV eax 1 8 SHL eax ecx \n9 OR [esi]<field_offset > eax 10 ;; test whether control flow 0 is active 11 PUSH 0 12 POP ecx 13 MOV \neax 1 14 SHL eax ecx 15 MOV ecx <field_offset >[esi] 16 AND ecx eax 17 PUSH ecx 18 ;; restore cflow state \nfrom stack frame 19 MOV ecx [esp]<stack_offset > 20 MOV [esi]<stack_offset > ecx Listing 4. Machine \ncode generated by the baseline compiler. As the control .ow index is already known at compile-time, \nthese instructions could be replaced by a single AND instruction. The code is generated like this because \nof the way the weaver passes the control .ow index to the compiler (by pushing it on the Java stack) \nand the stack-machine based model used by the baseline compiler. We did not bother to optimize this further, \nas the baseline compiler already produces fairly inef.cient code. 3.3.3 Guards in the Optimizing Compiler \nThe implementation of the approach with the optimizing compiler is different. Internally, Jikes optimizing \ncompiler proceeds in sev\u00aderal phases that operate on decreasing levels of abstraction. In the .rst phase, \nbytecode is translated into a high-level intermediate rep\u00adresentation; the last phase produces optimized \nmachine code for the target architecture. Support for cflow guards is implemented us\u00ading the high-level \nintermediate representation generated in the .rst phase. At this stage, an unlimited number of virtual \nregisters is avail\u00adable. In later phases, these registers are mapped to the (limited) set of physical \nregisters provided by the target architecture. If the num\u00adber of physical registers is not suf.cient \nto hold all virtual registers used in the previous phase, they will automatically be stored to and loaded \nfrom the method s stack frame. During method calls, regis\u00adters are stored in the stack frame as well, \nso that they can be used in the called method s native code. We have modi.ed the optimizing compiler \nto load control .ow state information into a virtual register, called the c.ow register, at the beginning \nof a method. When a control .ow is entered at a constituent shadow, three steps are performed: (a) the \ncurrent value of the cflow state is stored in a separate virtual register called backup register, (b) \nthe control .ow state in the cflow register is modi.ed, and (c) the processor object .eld is updated \nwith the new value of the cflow register. On leaving the constituent join point, the virtual register \nand the processor object .eld are restored from the backup register. When control .ow state has to be \ntested at dependent shadows, it can be accessed directly from the virtual register it has been stored \ninto at method entry. If the compiler decides to inline a method into another method, the inlined method \ns high-level intermediate representation is gen\u00aderated independently and then inserted into the outer \nmethod. This implies that it uses separate cflow and backup registers for storing control .ow state. \nThis is indeed necessary for correct behavior, e. g., if the inlined method constitutes the control .ow. \nIn this case, the cflow and backup registers of the outer and inlined methods hold different values. \nAt .rst sight, this compilation strategy does not seem to differ signi.cantly from the one described \nfor the baseline compiler. It might even look less ef.cient, because control .ow state is read at the \nbeginning of every method, although it is probably required only in a small fraction of the methods executed. \nHowever, since the approach operates on the high-level representation, the optimiz\u00ading compiler will \napply all its standard optimization techniques in later phases. Some of the applying optimizations are \nlisted below: If the virtual register holding control .ow state is never read, the compiler will detect \nthis and eliminate the memory load operation that initialized the register. Thus, methods that do not \naccess control .ow state do not exhibit any overhead.  If control .ow state information is frequently \nrequired (e. g., when a dependent shadow appears in a tight loop), it has to be loaded only once from \nmain memory and can be kept in a physical register. Basically, by using a virtual register for storing \ncontrol .ow state, the decision on whether to keep the value in a physical register or in the stack frame \nis left to the optimizing compiler s advanced algorithms.  The same applies to the old control .ow state \nvalue, which is saved at constituent shadows. Again, the compiler can decide whether to keep it in a \nphysical register or to store it in the method s stack frame, based on how many registers are needed \nby the method.  The intermediate representation generated by the optimizing compiler is shown in Lst. \n5. Here, PR denotes the processor register. The old cflow state is loaded from the processor object and \nstored into the backup register named t2psi. When entering the control .ow, bit 0 is set by an OR operation \nand the new value is stored in register t28si, as well as in the processor object. At dependent shadows, \nthe control .ow state is accessed directly from a virtual register. Note how the bit mask is included \nas a constant and does not have to be computed via a shift instruction anymore. Finally, when the control \n.ow is left, the processor object is updated from the value stored in the backup register. In addition \nto the optimizations performed by the compiler, our implementation employs two custom optimizations: \nIf a method is inlined, the virtual register holding the control .ow state is not initialized by loading \nit from the processor Listing 5. Intermediate Representation generated by the optimiz\u00ading compiler. \n1 ;; save cflow state in virtual register 2 int load t2psi(I) = PR, <field_offset > 3 ;; enter control \nflow 0 4 int or t28si(I) = t2psi(I), 1 5 int store t28si(I), PR, <field_offset > 6 ;; test whether control \nflow 0 is active 7 int and t7si(I) = t28si(I), 1 8 int ifcmp t7si(I), 0, ==, SKIP_ADVICE 9 ;; restore \ncflow state 10 int store t2psi(I), PR, <field_offset > object (which would result in a memory load). \nInstead, the value is copied from the outer method s virtual register. In addition to saving a memory \nload operation, this optimization allows the compiler to eliminate some virtual registers if one of the \nmethods does not modify control .ow state. In this case, subsequent phases of the compiler can infer \nthat both virtual registers hold the same value and thus map them to the same physical register. The \ntest checking cflow state at dependent shadows is removed if it is guaranteed to always succeed. This \nis determined by checking whether the control .ow is entered unconditionally at the beginning of the \nmethod containing the test. If the code is generated to be inlined into another method, the outer method \nis checked for an unconditional control .ow entry, too as well as its outer method if several levels \nof inlining are performed. For the Fibonacci example from Lst. 3, this optimization would remove the \nguards for advice executions inside the fib() method, since they will always succeed. This optimization \ncan be seen as a somewhat weaker form of abc s interprocedural analysis. It does not perform a whole\u00adprogram \nanalysis, which is not feasible in a virtual machine due to time and memory requirements. Instead, it \nis restricted to the set of methods inlined into the method currently being compiled. This set will always \nbe reasonably small, as the compiler avoids creating large method bodies. Both optimizations are particularly \neffective in the presence of inlining. This complements nicely with the fact that Jikes performs pro.le-directed \ninlining: inlining is focused on the most frequently used methods (and trivial methods, like setters \nand getters). Thus, the above optimizations apply to hot parts of the application, where they matter \nmost. Less frequently executed methods will be compiled only by the baseline compiler, which quickly \ngenerates less ef.cient code. 4. Evaluation This section evaluates the cflow implementations presented \nin Secs. 2 and 3. Three kinds of measurements were performed: A micro-measurement benchmark measures \nand compares the overhead of two parts of the cflow implementations: (a) the overhead for constituting \na control .ow, and (b) the overhead for checking whether a dependent join point actually occurs within \na control .ow.  A modi.ed version of the SPECjvm98 benchmarks measures and compares the impact of the \ncflow infrastructures on differ\u00adent approaches in real programs.  Benchmarks collected by the abc group \nto measure the perfor\u00admance of aspect-oriented programs.  Results of these benchmarks will be presented \nin Secs. 4.2, 4.3, and 4.4, after a short introduction to the overall setting for the evaluation in Sec. \n4.1. 4.1 Evaluation Setting When a VM begins executing an application, there is a number of sources of \noverhead, such as class loading, veri.cation, and dynamic compilation. Once these activities have subsided, \nthe VM is often referred to be executing in steady state. To ensure that different start-up behaviors \nof the presented envi\u00adronments do not in.uence the measurements, the presented results are steady-state \nresults. For each benchmark, 30 iterations were ex\u00adecuted and the median of the last 10 runs results \nconstituted the benchmark s performance. In all cases, the last 10 runs were clearly executed at steady \nstate. All measurements were made on a Dual Xeon workstation (2x3 GHz) with 2 GB RAM running Linux 2.4.23. \nHotSpot 1.5.0 (Sun s standard JVM) was used to run the bench\u00admarks compiled with ajc 1.5.0 and abc 1.1.0, \nas well as to exe\u00adcute the benchmarks in the JAsCo 0.8.7 environment. For JAsCo, the recommended HotSwap \n2 implementation was used, with the inlinecompiler switch enabled for improved performance. For AspectWerkz \n2.0, the benchmarks were executed on JRockit 1.4.2 08; Steamloom is an extension to Jikes RVM 2.3.1. \nThe programs compiled with ajc or abc compilers were not run on the Jikes RVM, which would have given \na direct comparison to our implementations in Steamloom. This is because both AspectJ compilers produce \ncode which exploits special optimizations of production Java virtual machines; such code is bound to \nexecute untypically slow on other VMs like Jikes RVM. AspectWerkz and JAsCo even rely on features which \nare not provided by Jikes RVM. Nevertheless, to produce comparable results, our measurements were conducted \nrelative to reference performances: as such, the performances of running the benchmarks without deployed \naspects on a Java virtual machine without support for AOP were consid\u00adered. For ajc, abc, and JAsCo, \nthe reference system was HotSpot, for AspectWerkz it was JRockit, and for Steamloom it was the Jikes \nRVM, each in the previously mentioned versions. Benchmark results will be presented as overheads of the \nbench\u00admarks with deployed aspects as compared to the performances of the corresponding reference JVMs. \nAdditionally, the absolute per\u00adformance numbers for each benchmark and each approach are pro\u00advided. However, \nwhen comparing the absolute numbers, one should keep in mind that underlying virtual machines exhibit \nsigni.cant differences in their respective performance characteristics.  4.2 Simple Micro-Measurements \nThe cflow infrastructure consists of two parts: on the one hand, bookkeeping which control .ows are currently \nactive and, on the other, checking whether a join point occurs in a speci.c control .ow. The performances \nof these two parts are measured indepen\u00addently of each other. As we will explain, the benchmark was con\u00adstructed \nsuch that only the cflow infrastructure is executed, but no advice. 4.2.1 Benchmark Setup The micro-benchmarks, \na small program presented in AspectJ syn\u00adtax in Lst. 6 was used. For the other environments, the example \nwas implemented in their respective syntax, or by using appropriate API calls. The example makes use \nof method execution pointcut desig\u00adnators because they are supported by all AOP implementations in focus. \nThe actual implementation of the benchmark harness is not shown in the listing and would have to be inserted \nat line 16. For a single run of the benchmark, the total time used to perform 100,000 iterations of \neach of the constituent() and dependent() operations was measured: To measure the overhead of the control \n.ow constitution in\u00adfrastructure the method constituent() (line 9 of Lst. 6) was called. This method \nconstitutes the control .ow and immedi\u00adately returns. Hence, by executing it, only the bookkeeping in\u00adfrastructure \nis executed.  To measure the overhead of the infrastructure for checking whether a join point occurs \nin a speci.c control .ow, the method dependent() (line 5) was called. A pointcut (lines 24 to 25) conditionally \nbinds an advice to the execution of this method; the pointcut only matches when dependent() is ex\u00adecuted \nin the control .ow of constituent(). This is not the case in our benchmark harness, which is implemented \ncom\u00adpletely in the method main(); hence, the advice will never be executed during our measurement.  \n Under certain circumstances, abc can determine that, e. g., a certain control .ow will always or never \nbe active when a given join point shadow is executed; in such cases, the infrastructure for constituting \nor checking a control .ow can be omitted. The goal of the micro-benchmark is to measure the impact of \nthis checking mechansim, thus the example program was written such as to prevent the optimizations mentioned \nabove; their effect on ef.ciency will be measured by the macro-benchmarks. If it was not possible to \ncall dependent() from within the con\u00adtrol .ow of constituent(), the abc compiler would realize that the \npointcut has no join points and would not weave any infrastruc\u00adture. Similarly, if dependent() was not \ncalled from outside the control .ow of constituent(), the abc compiler would realize that the check would \nnever fail at run-time and weave an uncon\u00additional call to the advice in dependent(). To prevent these \nopti\u00admization, a call to dependent() was inserted outside the control .ow in line 15. The executing virtual \nmachine can also apply optimizations. For example, when it can determine that a called method is empty, \nit can optimize the call away. To prevent this from happening, the method constituent() and the advice \nincrement a counter (lines 7 and 27). For measuring the overhead of each implementation relative to the \nversion of the benchmark without the aspect, the class Base was compiled with the standard javac compiler \nand executed on the reference system as speci.ed in this section s introduction. 4.2.2 Results Results \nfor the micro-measurements are shown in Tab. 1. The columns with the title constitution show the performance \nfor the cflow infrastructure inserted at constituent join point shadows; the columns with the title check \nshow the performance for the cflow infrastructure at dependent shadows. In each case, the .rst sub-column \nshows the absolute number of milliseconds needed for 100,000 runs. The second sub-column shows the factor \nby which execution time was increased in the presence of the aspect as com\u00adpared to the reference system, \ni.e., lower numbers indicate better performance. The results for each approach are presented in one row. \nFor abc, the benchmark was executed with different settings. First, the op\u00adtimizations of levels one \nand three were used, denoted by O1 and O3 in the table. Second, a single-and a multi-threaded environment \nwere simulated, denoted by st and mt, respectively. As explained in Sec. 2.2, abc applies a special optimization \nfor single-threaded applications. Single-and multi-threaded environments were simu\u00adlated by measuring \nthe performance in the .rst and in the second 1 class Base { 2 static int counter; 3 static boolean callDependent \n= false; 4 5 void dependent () 6 { 7 counter ++; 8 } 9 void constituent () 10 { 11 if (callDependent) \ndependent (); 12 } 13 public static void main(String [] args) 14 { 15 new Base(). dependent (); 16 /* \nexecute benchmark */ 17 } 18 } 19 20 aspect Aspect { 21 static int counter; 22 23 before() : 24 execution(void \nBase.dependent ()) &#38;&#38; 25 cflow(execution(void Base.constituent ())) 26 { 27 counter ++; 28 } \n29 } Listing 6. Code for the .rst micro-measurement. constitution check ms overhead ms overhead HotSpot \n(ref) 262 1.000 197 1.000 AspectJ 10321 39.393 2,915 14.797 abc-O1-st 1,586 6.053 1,550 7.868 abc-O3-st \n1,566 5.977 1,583 8.036 abc-O1-mt 5,142 19.557 4,350 22.081 abc-O3-mt 5,196 19.832 4,436 22.518 JAsCo \n613 2.340 1.1\u00b7107 56,751.269 JRockit (ref) 198 1.000 204 1.000 AspectWerkz 14783 74.700 8859 43.400 Jikes \n(ref) 197 1.000 197 1.000 SL-Stackw. 328 1.665 67967 345.010 SL-Counter 1049 5.325 721 3.660 SL-Guards \n524 2.660 328 1.665  Table 1. Results of the micromeasurements thread. It was ensured that only one \nthread was actually executing and the other one was sleeping during the measurement. The results of the \nSteamloom implementations are shown in the lines SL-Stackw. for the stack walking-based implementation, \nSL-Counter for the counter-based implementation, and SL-Guards for the guards-based implementation. Rows \nthat contain the perfor\u00admance of the reference system are denoted by the suf.x (ref). The following observations \nfollow from interpreting the num\u00adbers in the table: The stack walking approach, used by JAsCo and Steamloom \nStackwalking, does not produce overhead at points constitut\u00ading a control .ow. The small overhead observed \nis due to the support of these approaches for run-time deployment of as\u00adpects. This support also contributes \nto the observed overhead in JAsCo, AspectWerkz, and all Steamloom implementations. Conversely, the check \nat dependent join points is extremely ex\u00adpensive. Integrating stackwalking directly into the virtual \nma\u00adchine is several orders of magnitude faster than JAsCo s ap\u00adproach of accessing the call stack. This \nwas to be expected, since Steamloom s VM integration allows for a direct access to the virtual machine \ns call stack. However, even Steamloom s stackwalking implementation is signi.cantly slower than the counter-based \napproaches at dependent shadows. The abc compiler produces less overhead than ajc in the single-threaded \ncase. In the multi-threaded case, the code pro\u00adduced by both compilers performs badly. Since we imple\u00admented \nthe benchmark in a way that abc cannot apply opti\u00admizations, the results for both optimization levels \nare about the same.  The numbers clearly show that Steamloom s counter (SL-Counter) and guards (SL-guards) \nimplementations both outper\u00adform the abc compiler even in the single-threaded case, while already ensuring \nthread-safety.  Last but not least, the numbers show that constituting a control .ow and performing \nthe corresponding check at dependent join points with the guards-based approach is even absolutely faster \nthan respective operations with both the ajc and abc compilers, although the latter execute on a production \nJVM.   4.3 Macro-Measurements The benchmark presented in the previous section measures only the overhead \nintroduced by infrastructure needed by cflow imple\u00admentations. Although the results revealed big differences \nbetween the implementations, the overhead may be less signi.cant in large\u00adscale applications where it \nis possible to optimize residues away. To compare our approach against abc in a more realistic environment \nthat enables abc s interprocedural analysis as well as Steamloom s optimizations, we present a more complex \nbenchmark in this sec\u00adtion. 4.3.1 Benchmark Setup The SPECjvm98 benchmarks were modi.ed by adding 15 \npointcut\u00adand-advice pairs to each benchmark. The pointcuts all have the following form: execution(pc1) \n&#38;&#38; cflow(execution(pc2)) They have been picked to cover a wide range of different charac\u00adteristics. \nProperties of the pointcuts vary with respect to the rate of control .ow constitutions,  the ratio \nof dependent join point shadow executions inside to outside of the control .ow,  and the ratio of dependent \njoin point shadow occurrences di\u00adrectly in vs. outside the constituent method.  The advice attached \nto each pointcut only increments a counter, so that the overhead introduced by additional functionality \nis mini\u00admal. The benchmarks were compiled including the corresponding aspect with ajc and with abc at \noptimization levels O1 and O3. The resulting code was executed on HotSpot. abc s optimization level O3 \nincludes interprocedural optimizations and increases abc s compilation time to well over ten minutes. \nCompilation with ajc or abc at optimization level O1 only took a few seconds at most. For AspectWerkz, \nan aspect de.nition .le was provided and passed to the execution environment when starting the benchmark. \nFor Steamloom, the benchmark harness was extended to deploy the aspect before starting the iterations. \nIt was veri.ed that the advice are executed correctly in the vari\u00adous environments by counting the advice \nexecutions and comparing them to each other. We do not present results for JAsCo in this section, since \nits weak performance in the presence of cflow pointcuts prohibits the execution of the macro-benchmark. \nThe mpegaudio benchmark is not included because it was only available as obfuscated class .les that could \nnot be processed by most AOP implementations. abc could not successfully compile the javac benchmark; \nhence, this benchmark is also omitted7.  4.3.2 Results The results of running this benchmark are presented \nin Tab. 2. Each row shows the result of one implementation. For each benchmark, two numbers are shown: \nthe absolute running time in milliseconds (ms) and the overhead compared to the respective reference \nimple\u00admentation (ovhd), i. e., the reference virtual machine without sup\u00adport for aspect-oriented features \nas speci.ed in section 4.1 execut\u00ading the benchmark without any aspects deployed. Although the primary \ngoal is to measure the impact of the cflow infrastructure, the presented numbers also include some ad\u00additional \noverhead. For each approach, not only the additional time for executing the infrastructure, but also \nthe time needed to execute the advice added by the aspect is included in the presented mea\u00adsurement times. \nFor AspectWerkz and Steamloom, the overhead of the dynamic deployment facility is also included in the \npresented measurement times. From the numbers presented in Tab. 2, we draw the following conclusions. \n Our novel implementation based on control .ow guards ex\u00adhibits the least overhead for all benchmarks, \neven if abc s inter\u00adprocedural analysis is used. Our counter-based implementation is usually at the same \nlevel with abc-O1. The only exception to both rules is the jack benchmark.  For the mtrt benchmark, \nour Steamloom-Guards implementa\u00adtion is considerably faster than abc and all other approaches. We would \nalso like to draw the reader s attention to the fact that, with the exception of mtrt , all benchmarks \nare single\u00adthreaded; hence, abc can bene.t from its optimization for this case. But, our implementation \nwould exhibit the same perfor\u00admance in multi-threaded environments, i. e., in contrast to num\u00adbers for \nabc compiled single-threaded benchmarks, the num\u00adbers for our approach characterize the most general, \nthread-safe implementation.  ajc and AspectWerkz provide cflow at a very unsatisfactory performance. \nWhile ajc is faster than AspectWerkz, it still inhibits a signi.cant overhead (e. g., 14.7 % for jess \nor 31.4 % for mtrt).  An implementation based on stack inspection is not bene.cial. This becomes especially \nvisible in the jess benchmark. It in\u00adcludes a recursive interpreter for a logic programming language \nthat yields particularly deep call stacks. Accordingly, the over\u00adhead for Steamloom s stack walking implementation \nis very high for this benchmark.  abc exhibits a considerably less overhead than ajc already at the \nlower optimization level. The impact of the interprocedural optimization introduced in O3 is large for \nthe compress bench\u00admark, which abc can analyze very effectively due to its small size. For all other \nbenchmarks, the higher optimization level performs only slightly faster than O1.  7 We are in contact \nwith abc s implementors; but they could not .x the bug prior to submission deadline of this paper. 1 \npointcut move(): 2 call(void FigureElement +. moveBy (...)) || 3 call(void Point.setX(int)) || 4 call(void \nPoint.setY(int)) || 5 call(void Line.setP1(Point )) || 6 call(void Line.setP2(Point )); 7 8 after() returning: \n9 move () &#38;&#38; !cflowbelow(move ()) { 10 Display.needsRepaint (); 11 } Listing 7. Aspect and advice \nfor the .gure benchmark. The overhead of abc is very close to that of ajc for the mtrt benchmark, while \nit is signi.cantly below that of ajc for all other benchmarks. This benchmark is the only multi-threaded \nbenchmark of the SpecJVM98 suite. Thus, abc s optimization for single-threaded applications, explained \nin Sec. 2.2, does not apply here.  4.4 Benchmarks from abc Group While the benchmarks presented in \nSec. 4.3 used real applications from the SPECjvm98 benchmark suite it was synthetic in the sense that \nit used cflow pointcuts introduced only for the purpose of the benchmark. These pointcuts did not add \nany useful functionality to the application. The abc team has gathered various benchmarks by collecting \nAspectJ programs from public sources on the web [13, 8] some of which also use c.ow pointcuts. We were \nable to run the figure and the quicksort benchmarks. However, both benchmarks are fairly short, each \nbenchmark consiting of approx. 150 lines of code. Un\u00adfortunately, we were not able to run the more complex \nbenchmarks Law of Demeter, Cona, and ants because they are using more advanced constructs not currently \nsupported by Steamloom8. 4.4.1 Benchmark Setup The measurements in this section were performed against \na refer\u00adence version without deployed aspects. We only performed mea\u00adsurements for ajc, abc and Steamloom \ns control .ow guards im\u00adplementation. The previous benchmarks have already shown that the other implementations \nyield a considerably worse performance so that an additional measurement would not add any value to the \nresults of this paper. The cflow-dependent pointcuts used in both benchmarks are very similar, having \nthe form pc &#38;&#38; !cflowbelow(pc) to cap\u00adture non-recursive entry-points into certain parts of the \nprogram. For the figure benchmark which simulates a simple .gure editor the pointcut shown in Lst. 7 \nis used. It causes a noti.\u00adcation to the display object whenever a .gure element is changed. However, \ncalling a point s moveBy method during the execution of a line s moveBy method does not result in a duplicate \nnoti.ca\u00adtion because of the employment of the !cflowbelow(move()) pointcut. The quicksort benchmark collects \nvarious statistics on the sorting algorithm. It uses a similar c.ow pointcut to select the top-level \ncall to the recursive quicksort method to initialize and display the statistics (Lst. 8). 4.4.2 Results \nThe results for both benchmarks are presented in Tab. 3. Again, our novel implementation using control \n.ow guards performs very 8 Please note, that these unsupported constructs are independent from the implementation \nof the cflow pointcut. compress jess db javac mtrt jack ms ovhd ms ovhd ms ovhd ms ovhd ms ovhd ms \novhd HotSpot (ref) 5266 1.000 2045 1.000 13760 1.000 4131 1.000 1865 1.000 2679 1.000 AspectJ 35548 \n6.750 2346 1.147 13863 1.007 4289 1.038 2450 1.314 2698 1.007 abc-O1 14047 2.667 2079 1.017 13741 0.999 \nN/A N/A 2384 1.278 2691 1.004 abc-O3 6852 1.301 2075 1.015 13754 1.000 N/A N/A 2289 1.227 2702 1.009 \nJRockit (ref) 4345 1.000 1315 1.000 8812 1.000 3084 1.000 1748 1.000 2006 1.000 AspectWerkz 83340 19.181 \n2153 1.637 8868 1.006 3418 1.108 3007 1.720 2061 1.027 Jikes (ref) 4769 1.000 1790 1.000 10442 1.000 \n5900 1.000 2944 1.000 2982 1.000 SL-SW N/A N/A 28970 16.184 10444 1.000 12651 2.144 15520 5.272 3081 \n1.033 SL-Ctr 10623 2.228 1884 1.053 10451 1.001 5993 1.016 3366 1.143 3077 1.032 SL-Guards 6039 1.266 \n1779 0.994 10445 1.000 5939 1.007 3287 1.117 3044 1.021 Table 2. Results from running the spec benchmarks. \n1 pointcut sort(): 2 call(void QuickSort.quicksort (...)); 3 pointcut entry (): 4 sort() &#38;&#38; !cflowbelow(sort \n()); 5 before() : entry() { 6 Stats.before_entry (); 7 } 8 9 after() returning: entry () { 10 Stats.after_entry \n(); 11 } Listing 8. Aspect and advice for the quicksort benchmark. .gure  quicksort ms ovhd ms ovhd \nHotSpot (ref) 10 1.000 9062 1.000 AspectJ 672 67.200 10303 1.137 abc-O1 102 10.200 9854 1.087 abc-O3 \n10 1.000 9984 1.102 abc-exec-O3 43 4.300  Jikes (ref) 25 1.000 7895 1.000 SL-Guards 43 1.720 8291 1.038 \n Table 3. Results from running the .gure and quicksort bench\u00admarks. well. In fact, it exhibits the least \noverhead except for the .gure example when abc is run with the highest optimization level. A closer inspection \nshows that abc is able to completely optimize away all control .ow-related residues in this benchmark. \nSince the overhead for notifying the display is negligible, abc does not show any overhead compared to \nthe reference measurement in this case. We argue that this was possible mainly due to the small size \nof the benchmark and the particular pointcut. As we have shown in Sec. 4.3, this does not happen as frequently, \nwhen applying a larger variety of pointcuts on bigger programs. Although the .gure benchmark s essentially \nbeing a micro\u00adbenchmark, an interesting difference between the optimizations performed by abc and Steamloom \ncan be seen by modifying the pointcut only slightly. When all call(...) expressions are changed to execution(...) \nexpressions, the semantics of the as\u00adpect does not change: the display is still noti.ed everytime a .gure \nelement is modi.ed and duplicate noti.cations are avoided. However, this slight modi.cation already prevents \nsome of abc s intra-procedural optimizations, as can be seen in the row abc-exec-O3, displaying a highly \nincreased overhead. The reason for this behaviour is that when using call pointcuts, the whole pointcut \nhas more shadows in the program (at every call) com\u00adpared to the execution-based pointcut. With more \nshadows, abc can reason about each shadow separately and in the case of this benchmark determine statically \nwhether it occurs inside or out\u00adside the control .ow. If execution is used in the pointcut, how\u00adever, \nthere are less shadows in the program (only the method bod\u00adies) and these shadows may be executed both \ninside and outside the control .ow, so that a dynamic check is necessary. Steamloom s control .ow guard \noptimizations are not vulnera\u00adble to such modi.cations. Jikes inlining optimization will generate a separate \n(inlined) version of a method body at every hot call site, so that our interprocedural optimizations \ncan reason about these join points in the same differentiated way as if call pointcuts had been used. \nThis shows an advantage of delaying program optimizations until run-time. They can exploit the VM s dynamic \noptimizations, e. g., inlining, to obtain additional information, for example about the calling context, \nthat enable more ef.cient optimizations. On the other hand, of.ine optimizations allow more time-consuming \nand memory-consuming optimizations which in some cases can completely optimize away the overhead induced \nby cflow pointcuts. 5. Future Work There are three areas of future work. First, as further discussed \nin the next subsection, we will provide support for context extraction from the control .ow. Next, we \nwill investigate the usefulness of our implementation to facilitate other program language features, \nlike context-oriented programming (see section 5.2). Finally, we will include further optimization techniques \nto be applied by our cflow implementation. Our current implementation does not per\u00adform sophisticated \nredundant guard elimination. A next step in re\u00adducing guard overhead would be to perform more advanced \npath splitting and redundant guard removal analysis, similar to that per\u00adformed in previous work [4]. \n5.1 Context Extraction In Sec. 2.1, we have mentioned that our approach does not support the extraction \nof context information from constituent join points. Implementing such support is a subject of future \nwork, and we expect that context extraction can be implemented at excellent performance when VM structures \nare exploited, as with control .ow guards. As mentioned in Sec. 2.2, approaches adopting counters to \nim\u00adplement cflow matching usually use a stack when context infor\u00admation from constituent join points \nneeds to be made available to advice. Our planned implementation of context extraction does not require \na stack, but will instead rely on extracting the required val\u00adues from the corresponding stack frames \ndirectly. We are con.dent that this is feasible, given that values from frames further up in the call \nstack are always stored in a way that allows for ef.cient access to them. The required values are, in \nall cases, local state of the method containing the constituent shadow. Depending on whether the method \nthat has to access them is inlined in the former method or not, they can be accessed as follows: In \nthe case of inlining, local state of the calling method is available in the form of operands at high-level \nintermediate representation, which makes their access obviously feasible.  In all other cases, local \nstate of the method containing the con\u00adstituent shadow is stored in its stack frame. Baseline-compiled \nmethods keep their state in stack frame slots anyway, and for optimised methods, values stored in registers \nduring execution are saved to the stack frame in case another method is called. From these locations, \nthe respective values can be retrieved.  This approach requires that, for elements extracted from con\u00adstituent \njoin point context, a set of references to their storage loca\u00adtions is maintained. In case of recursive \ncontrol .ow entries, the set needs to be updated accordingly; otherwise, it can be passed on in the same \nway as our approach does for control .ow guards. Adopting this solution will come at some cost, since \nmaintain\u00ading context references is an additional task that compiled applica\u00adtion code will have to ful.l. \nYet, the cost of maintaining a complex data structure e. g., a stack, as used by current implementations \n is most likely much higher.  5.2 Context-Oriented Programming Another subject of future work is to \nextend the guards-based cflow implementation to programming approaches that allow for con\u00adtrol .ow-dependent \nbehaviour but do not apply explicit quanti.\u00adcation over join points in terms of pointcuts. An example \nof such an approach is context-oriented programming (COP), existing in the form of the Lisp-based ContextL \nprogramming language [29]. COP allows for dynamically (de)activating layers that augment the running \napplication with additional behaviour. An important dif\u00adference to the pointcut-and-advice .avour of \nAOP [26] is that in COP, points where crosscutting behaviour applies are not de.ned in terms of pointcuts, \nbut implicitly in terms of the interfaces of application classes. Hence, COP s join point model is more \ncoarse\u00adgrained than that of, e. g., AspectJ, but no less powerful in the re\u00adspect of possible interaction \nwith the base application. Given that layers can be dynamically (de)activated, the possibil\u00adity of applying \ncontrol .ow-dependent behaviour is given in COP: in the control .ow of a method that activates a layer, \nbehaviour applies that would not outside the so-de.ned context. The current implementation of ContextL \n[30] relies on the dynamic de.nition of classes representing layer combinations and on multiple dis\u00adpatch \nto realise context-dependent behaviour. The implementation utilises caching mechanisms to improve performance. \nThe authors plan to port COP to the Java platform [30]. We believe that the still-remaining overhead \ndue to caching costs could be eliminated in such an implementation by exploiting guards-based control \n.ow matching. 6. Conclusion The most important result of the work presented in this paper is that our \nnovel implementation based on control .ow guards dis\u00adplays the best performance among all approaches. \nIt performs even better than abc at its highest optimization level, which provides one of the most ef.cient \nimplementations available today. However, a whole-program analysis as performed by abc comes at the cost \nof (a) a signi.cant increase of the compilation time and (b) placing Java applications under a closed-world \nassumption that contradicts Java s dynamic class loading capabilities. Our approach has neither of these \ndisadvantages. If abc is used without the whole-program analysis, benchmark results are even more favorable \nfor our ap\u00adproach. The same is true for multi-threaded applications, as our strategy is thread-safe by \ndefault and does not need any special op\u00adtimizations for the single-threaded case. If there are more \ncontrol .ow-based pointcuts deployed in a sys\u00adtem than the number of control .ow guards we have reserved9,we \nhave to use the counter strategy for the additional pointcuts. Even though this strategy is slower than \nour counter-based implemen\u00adtation, it is still at the same level with abc. Thus, we expect all applications \nthat are making use of cflow pointcuts to bene.t from our approach, even if they are using a large number \nof pointcuts. By implementing several approaches to the best of our knowl\u00adedge within the same environment, \nwe have been able to directly compare their relative performance. Stack walking, although hav\u00ading no \noverhead at constituent shadows, does not seem to be an alternative since its complexity depends on the \nstack depth met at dependent shadows. Counter-based strategies, exhibiting constant cost at control .ow \nentries and exits as well as at dependent shad\u00adows, perform signi.cantly better in all real-word benchmarks. \nThis performance is topped only by our novel guards-based strategy. From the results presented in Sec. \n4.3, it is obvious that interpro\u00adcedural optimizations can lead to considerable performance gains. However, \ndue to time and memory constraints, a whole-program analysis is infeasible inside a virtual machine. \nWe believe that, by applying these optimizations on a smaller scale, e. g., to the code that is produced \nfrom a method and all methods that are inlined into it, they could become feasible. As described in Sec. \n3.3.3, we have already successfully applied some of abc s interprocedural optimizations to remove redundant \ncontrol .ow checks. Since this analysis works across method boundaries only in the presence of inlining, \nit is guaranteed to execute quickly and is always focused on the hot parts of the application. It seems \nvery promising to in\u00adclude more static analyses for predicting the control .ow into Jikes RVM s optimizing \ncompiler. Acknowledgements This work was supported by the AOSD-Europe Network of Excel\u00adlence, European \nUnion grant no. FP6-2003-IST-2-004349. References [1] abc (AspectBench Compiler) Home Page. http://aspectbench. \norg/. [2] B. Alpern, D. Attanasio, J. J. Barton, A. Cocchi, S. F. Hummel, D. Lieber, M. Mergen, T. Ngo, \nJ. Shepherd, and S. Smith. Imple\u00admenting Jalape no in Java. In 1999 ACM SIGPLAN Conference on Object-Oriented \nProgramming Systems, Languages, and Applications (OOPSLA 99). ACM Press, 1999. [3] B. Alpern et al. The \nJalape no Virtual Machine. IBM Systems Journal, 39(1):211 238, February 2000. [4] Matthew Arnold and \nBarbara G. Ryder. Thin guards: A simple and effective technique for reducing the penalty of dynamic class \nloading. In ECOOP 02: Proceedings of the 16th European Conference on Object-Oriented Programming, pages \n498 524, London, UK, 2002. Springer-Verlag. [5] AspectJ Home Page. http://www.eclipse.org/aspectj/. [6] \nAspectS Home Page. http://www-ia.tu-ilmenau.de/ ~hirsch/Projects/Squeak/AspectS/.  9 Although the number \nof guard bits cannot be increased at runtime, an arbitratry number of bits can be reserved. [7] AspectWerkz \nHome Page. http://aspectwerkz.codehaus. org/. [8] P. Avgustinov et al. Optimising AspectJ. In PLDI 05: \nProceedings of the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation, pages \n117 128. ACM Press, 2005. [9] C. Bockisch, M. Haupt, M. Mezini, and K. Ostermann. Virtual Machine Support \nfor Dynamic Join Points. In Proc. AOSD 2004. ACM Press, 2004. [10] J. Bon\u00b4What Are the Key Issues for \nCommercial AOP Use: how er. Does AspectWerkz Address Them? In Proc. AOSD 2004, pages 5 6. ACM Press, \n2004. [11] J. Brichau, M. Haupt, N. Leidenfrost, A. Rashid, L. Bergmans, T. Staijen, A. Char., C. Bockisch, \nI. Aracic, V. Gasiunas, K. Os\u00adtermann, L. Seinturier, R. Pawlak, M. S\u00a8e, D. Suv\u00b4 udholt, J. Noy\u00b4ee, M. \nD Hondt, P. Ebraert, W. Vanderperren, M. Pinto, L. Fuentes, E. Truyen, A. Moors, M. Bynens, W. Joosen, \nS. Katz, A. Coyler, H. Hawkins, A. Clement, and O. Spinczyk. Report describing survey of aspect languages \nand models. Technical Report AOSD-Europe Deliverable D12, AOSD-Europe-VUB-01, Vrije Universiteit Brussel, \n17 May 2005 2005. [12] T. Dinkelaker, M. Haupt, R. Pawlak, L. D. Benavides Navarro, and V. Gasiunas. \nInventory of aspect-oriented execution models. Technical Report AOSD-Europe Deliverable D40, AOSD-Europe-TUD-4, \nDarmstadt University of Technology, 28 February 2006 2006. [13] B. Dufour, C. Goard, L. Hendren, C. Verbrugge, \nO. de Moor, and G. Sittampalam. Measuring the Dynamic Behaviour of AspectJ Programs. In Proc. OOPSLA \n2004, 2004. [14] R. E. Filman, T. Elrad, S. Clarke, and M. Aks\u00b8it, editors. Aspect-Oriented Software \nDevelopment. Addison-Wesley, 2005. [15] Glassbox-Inspector Home Page. https://glassbox-inspector. dev.java.net/. \n[16] B. Harbulot and J. R. Gurd. Using aspectj to separate concerns in parallel scienti.c java code. \nIn AOSD 04: Proceedings of the 3rd international conference on Aspect-oriented software development, \npages 122 131. ACM Press, 2004. [17] M. Haupt, M. Mezini, C. Bockisch, T. Dinkelaker, M. Eichberg, and \nM. Krebs. An Execution Layer for Aspect-Oriented Programming Languages. In Proc. VEE 2005. ACM Press, \nJune 2005. [18] R. Hirschfeld. AspectS -Aspect-Oriented Programming with Squeak. In M. Aksit, M. Mezini, \nand R. Unland, editors, Objects, Components, Architectures, Services, and Applications for a Networked \nWorld, volume 2591 of LNCS, pages 216 232. Springer, 2003. [19] JAsCo Home Page. http://ssel.vub.ac.be/jasco/. \n[20] JBoss AOP Home Page. http://www.jboss.com/products/aop. [21] The Jikes Research Virtual Machine. \nhttp://jikesrvm. sourceforge.net/. [22] G. Kiczales, E. Hilsdale, J. Hugunin, M. Kersten, J. Palm, and \nW. G. Griswold. An Overview of AspectJ. In J. Lindskov Knudsen, editor, Proc. ECOOP 2001, volume 2072 \nof LNCS, pages 327 353. Springer, 2001. [23] G. Kiczales, J. Lamping, A. Mendhekar, C. Maeda, C. Videira \nLopes, J.-M. Loingtier, and J. Irwin. Aspect-Oriented Programming. In M. Aksit and S. Matsuoka, editors, \nECOOP 97: Object-Oriented Programming, volume 1241 of Lecture Notes in Computer Science, pages 220 242. \nSpringer, 1997. [24] Ramnivas Laddad. AspectJ in Action: Practical Aspect-Oriented Programming. Manning \nPublications Co., Greenwich, CT, USA, 2003. [25] Karl Lieberherr, David H. Lorenz, and Pengcheng Wu. \nA case for statically executable advice: checking the law of demeter with aspectj. In AOSD 03: Proceedings \nof the 2nd international conference on Aspect-oriented software development, pages 40 49, New York, NY, \nUSA, 2003. ACM Press. [26] H. Masuhara and G. Kiczales. Modeling Crosscutting in Aspect-Oriented Mechanisms. \nIn Proc. ECOOP 2003, 2003. [27] H. Masuhara, G. Kiczales, and C. Dutchyn. A Compilation and Optimization \nModel for Aspect-Oriented Programs. In G. Hedin, editor, Proc. CC 2003, volume 2622 of LNCS, pages 46 \n60. Springer, 2003. [28] P. Avgustinov and others. abc: an Extensible AspectJ Compiler. In Proc. AOSD \n05, pages 87 98. ACM Press, 2005. [29] P. Costanza and R. Hirschfeld. Language Constructs for Context-Oriented \nProgramming: an Overview of ContextL. In Dynamic Languages Symposium (DLS) 05, co-organized with OOPSLA \n05. ACM Press, 2005. [30] P. Costanza and R. Hirschfeld and W. de Meuter. Ef.cient Layer Activation for \nSwitching Context-Dependent Behavior. In Joint Modular Languages Conference 2006 (JMLC2006). Springer, \n2006. [31] D. Sereni and O. de Moor. Static analysis of aspects. In AOSD 03: Proceedings of the 2nd international \nconference on Aspect-oriented software development, pages 30 39. ACM Press, 2003. [32] D. Suv\u00b4ee, W. \nVanderperren, and V. Jonckers. JAsCo: an Aspect-Oriented Approach Tailored for Component Based Software \nDevel\u00adopment. In Proc. AOSD 2003, pages 21 29, 2003.     \n\t\t\t", "proc_id": "1167473", "abstract": "Aspect-oriented programming (AOP) is increasingly gaining in popularity. However, the focus of aspect-oriented language research has been mostly on language design issues; efficient implementation techniques have been less popular. As a result, the performance of certain AOP constructs is still poor. This is in particular true for constructs that rely on dynamic properties of the execution (e.g., the <i>cflow</i> construct).In this paper, we present efficient implementation techniques for <i>cflow</i> that exploit direct access to internal structures of the virtual machine running an application, such as the call stack, as well as the integration of these techniques into the just-in-time compiler code generation process.Our results show that AOP has the potential to make programs that need to define control flow-dependent behavior not only more modular but also more efficient. By making means for control flow-dependent behavior part of the language, AOP opens the possibility of applying sophisticated compiler optimizations that are out of reach for application programmers.", "authors": [{"name": "Christoph Bockisch", "author_profile_id": "81100623891", "affiliation": "Darmstadt University of Technology, Germany", "person_id": "PP14214980", "email_address": "", "orcid_id": ""}, {"name": "Sebastian Kanthak", "author_profile_id": "81100473014", "affiliation": "Darmstadt University of Technology, Germany", "person_id": "PP18007289", "email_address": "", "orcid_id": ""}, {"name": "Michael Haupt", "author_profile_id": "81100288845", "affiliation": "Darmstadt University of Technology, Germany and Hasso Plattner Institute for Software Systems Engineering, Potsdam, Germany", "person_id": "PP18001091", "email_address": "", "orcid_id": ""}, {"name": "Matthew Arnold", "author_profile_id": "81100021720", "affiliation": "IBM TJ Watson Research Center, Yorktown Heights, NY", "person_id": "PP14020675", "email_address": "", "orcid_id": ""}, {"name": "Mira Mezini", "author_profile_id": "81100583946", "affiliation": "Darmstadt University of Technology, Germany", "person_id": "P201627", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167484", "year": "2006", "article_id": "1167484", "conference": "OOPSLA", "title": "Efficient control flow quantification", "url": "http://dl.acm.org/citation.cfm?id=1167484"}