{"article_publication_date": "10-16-2006", "fulltext": "\n On System Design Jim Waldo Sun Microsystems, Inc 1 Network Drive Burlington, MA 01803 1 781 442 0497 \n Jim.waldo@sun.com Abstract In this essay, I consider some of the factors that are making it more and \nmore difficult to expend the effort necessary to do system design. Because of changes in the economics \nof the field in both industry and research, we have become less able to take the time needed to do real \nsystem design, and to train the next generation of designers. Because of the intellectual property landscape, \nwe are less able to discuss system design. The end result is that we do less good system design than \nwe used to, at least in those environments where system design used to be most common. But there are \nreasons to be optimistic about the future of system design, which appears to be happening in non-traditional \nways and in non\u00adtraditional venues. Categories and Subject Descriptors D.2.2 [Design Tools and Techniques], \nD.2.11 [Software Architecture] General Terms Design, management, standardization. Keywords System Design, \nEducation, Training.  1. Introduction I am beginning to believe that the art and craft of system design \nis in danger of being lost. Carefully designed systems, in which the right abstractions are combined \nin just the right way to produce a system that is easy to learn, easy to change, and pleasing to use \nand work with, are unlikely to happen using the kind of design techniques that are popular today. It \nisn t just the techniques that we use that impede our ability to design systems. We are unable to train \nengineers and scientists adequately in system design. The economics of the industry push us in directions \nthat don t favor design. The realities of funding in research make it unlikely that much time will be \nspent on system design. The end result is that less careful design work is being done, and we as an industry, \na profession, and an intellectual discipline don t seem to care or be able to do much about it. In what \nfollows, I will try to describe and explain some of these factors, and try to make clear the price that \nthe industry and the discipline are likely to pay because of these factors. I will begin by trying to \ncharacterize what we mean by system design. On the characterization I will give, all but the most trivial \nof software artifacts have a design, but only some of them were given that design consciously. I will \nthen turn to how system design is learned, and given that as a base will look at the changes in both \nindustry and academia that have made it harder for system design to be taught or even done in a reasonable \nway. The inability to do or to learn system design in these traditional venues has led to the emergence \nof new areas where engineers and scientists can practice and perfect their skills in the area. I will \nend the essay by discussing some of those areas, as they provide the hope that good system design will \ncontinue to be part of what we teach, learn, and practice.  2. What Is System Design? One of the most \ninteresting, and most difficult, of the tasks that we may undertake in our careers as engineers or computer \nscientists is the design of an entire system. A system is a set of interacting parts, generally too large \nto be built by a single person, designed for some particular purpose. We work with systems all the time. \nThe operating systems that control our machines are systems. The layers of hardware and software that \nallow the programs on these machines to interact with each other over a network are systems. Even most \napplications that we use are systems, whether we know it or not. As engineers, we know that the way to \nsolve a large problem is to break it into a set of interacting smaller problems. Each of these smaller \nproblems can then be decomposed into even smaller problems, until (after enough iterations) we have a \nproblem that can be solved on its own. System design is a similar task, taking a large system and breaking \nit down into a set of smaller systems. The additional step in system design is to specify the interactions \nof the smaller systems so that they fit together to create the larger system; after breaking the problem \ninto smaller problems the system designer will say how it is that the solutions to those smaller problems \nwill fit back together to solve the larger problem. All (reasonable1) software is a system that has a \ndesign on this characterization. The software will be organized around methods (or procedures, or functions, \nor whatever abstraction for this sort of thing is supported by the language being used) and each of these \nmethods will represent a decomposition and abstraction of a problem that must be solved for the software \nto run. The larger the piece of software, the more layers there are in the design, and the more complex \nthe system. 1 We have all seen BASIC programs that have no such design. However, after the first week \nor so of writing code, anyone who Copyright is held by Sun Mi crosystems, Inc. OOPSLA 06 October 22 \n26, 2006, Portland, Oregon, USA. does not avoid that sort of non-structure should be quietly, but ACM \n1-59593-348-4/06/0010. firmly, convinced to spend his or her time doing something, anything, else. But \nto say that all software has a design does not entail that all software is designed. For a program to \nbe designed requires that there be some (perhaps considerable) thinking about the right way to decompose \nthe functionality, and how to create a small set of abstractions that can be re-used and re-combined \nto provide that functionality. The notion that anything that shows some kind of design was therefore \nthe result of some conscious activity of design is a confusion that is the result of an ambiguity in \nthe term design. On one sense of the word, it is a property of some object (such as a program, a system, \nor the like) that merely indicates that there are parts that interact. On another sense of the word, \nit indicates the activity of determining what the parts of some larger whole should be, and how those \nparts will fit together. While anything that is the result of the activity of design will itself have \na design, it does not follow that anything that can be described as a group of parts interacting to form \na more complex whole (that is, anything that has the property of a design) is therefore the result of \nthe activity of design.2 One of the best indications that a program is the result of the activity of \ndesign is the existence of a document that describes that design. But all too often software has a design \nthat must be discovered from the code by inspection. Sometimes the design that is discovered shows all \nthe hallmarks of a thoughtful design activity, but there are other times that the discovered design shows \na haphazard combination of various abstractions, duplication of functionality in slightly different forms, \nand inconsistencies in the way in which abstractions were selected, implemented, and used. Such discovered \ndesigns show either the absence of any design activity prior to the construction of the program, or that \nwhat design activity did occur prior to the writing of the program was, to speak plainly, not very good. \nCollections of programs that are meant to form a system exhibit the same sort of design, but at a larger \nscale and in a more public fashion. A collection of software meant to form a system will present the \nuser of the system with a set of abstractions that can be combined in various ways. The abstractions \nmay show symmetry, simplicity, and an aptness to the task that are characteristics of what we consider \ngood design; the design may also seem random in its choice of abstractions, be repetitive, or show little \nconsistency from one part of the system to another; these are systems that we consider examples of poor \ndesign. I know of no adequate set of necessary and sufficient conditions for determining whether a design \nis good or not, but like so many things having to do with taste and aesthetics we generally know good \n(and bad) design when we see it. The Unix operating system has a simplicity and symmetry that is indicative \nof a good design; the companion C programming language has a combination of power and simplicity that \nboth reflects and compliments the PDP-11 architecture for which it was originally intended. There is \nno necessary connection between a system or program exhibiting good design and that system or program \nhaving been consciously designed by someone. While I personally know of no 2 The assumption that anything \nthat exhibits the property of having a design is, therefore, the result of the activity of design is \nthe base of arguments that go far beyond computer science, engineering, or programming. Space limitations \nand good sense keep me from addressing the wider issues of this debate. systems that were not actively \ndesigned that are examples of good design, there is no logical impossibility of such a system existing. \nFurther, it is not all that hard to find systems that were consciously designed that are not examples \nof what any of us (other than, perhaps, the original designers) would consider examples of good design; \nI m sure we can all come up with many examples of this sort of system. In spite of this, there does seem \nto be some connection between the activity of system design and the production of elegant, well crafted \nsystems, in at least that all of the actual examples of the latter are also examples of the former. System \ndesign can change and evolve over time. The original Javatm programming language and associated libraries \nhad a simple and consistent design. Some of the additions to the libraries associated with the environment \nsince it was first introduced reflect the original design, but others have introduced other notions of \ndesign. The overall system has evolved into something that, at a certain scope, has a coherent design \nbut which, taken as a whole, is far less coherent than it once was. A more radical example of design \nchange over time is seen in the sets of protocols and languages that define the World Wide Web; when \nfirst introduced these were simple and had a coherent design. Designs that have been proposed (or that \nhave become accepted standards) in the past decade, however, show no such coherence and simplicity; individual \ncollections of these may be said to form a designed system, but the amalgam that forms the overall platform \ndoes not. Some of these examples of good design were thought out in fairly complete detail before the \nsystems were produced. Others evolved with the implementation of the system itself. But in all of the \ncases of good design, there is a fairly simple set of principles that can be seen to underlie the design. \nIn the case of Unix, the idea of a file and the ability of any program to take an ASCII stream as input \nand produce such a stream as output allowed those learning the system to know what to expect as they \nencountered new parts of the system. There are times that the design of a system, even when it is an \nexample of good design, will need to be pushed and prodded in unnatural ways to gain something that the \noriginal design did not take into account. It was a great simplification in Unix to treat all files as \nASCII streams, but the introduction of magic numbers, various kinds of headers, and conventions having \nto do with the filename extension show the desire for a typed file system being overlaid on such a system. \nWhile the original design of untyped files was simple and sufficient, the complexity that has grown up \naround the various ways of indicating the type of a file can make one wish that the original design had \nbeen somewhat more complex. But one should be careful about one s wishes; the number of bad designs that \nhave been justified by quoting Einstein s maxim everything should be made as simple as possible, but \nno simpler makes one wish that he had actually said everything should be made as simple as possible, \nand then made simpler. Given my characterization of system design, I should really restate my concern \non the subject. Since any system will have a design, saying that system design is dying out would be \nthe same as saying that software development is dying out. That is demonstrably not the case. More and \nmore software is being produced, so there are more and more system designs. What I am worried about is \nthe demise of systems that are designed, in the sense that there is some coherent plan for the system \nthat is arrived at by the people working on the system in a way that is separate from simply observing \nhow the code falls out. Maybe a better characterization of my worry is that the act of designing a system \nis happening less and less, and as a result the design of the systems that we are producing is becoming \nmore and more haphazard and the resulting designs are less and less coherent, simple, and aesthetically \npleasing. Certainly all of our software has some structure to it and some set of abstractions that can \nbe identified as underlying the structure of the code, but I find that it is less and less common that \nthe structure and the abstractions are thought about (and cared about) as entities in themselves. Instead, \nwe seem to be producing software where the overall design can only be determined after the fact, by looking \nat the code that is produced Whether the perceived lack of designing systems is good or bad, it is something \nthat we as an industry and as an intellectual discipline should understand. The change in the design \nof systems is, I think, being caused by a number of factors. Individually, they might not be a problem; \ntaken together they are changing the way we build systems. Part of it has to do with education; part \nif it has to do with economics; part of it has to do with the current fads or fashions in the way we \nwrite software. In what follows, I will look at each of these factors in turn. Let s start with some \nthoughts on education.  3. TRAINING IN SYSTEM DESIGN Like most other industrial research laboratories, \nSun Labs brings in groups of interns over the summer to work on various projects. This is about as classic \na win-win situation as can be found in business. The interns (most of whom are graduate students, but \nalso undergraduates and the occasional high-school student) find a summer job in their field of interest, \nand the lab gets an injection of enthusiasm that is hard to replicate. The students think they are being \noverpaid, while we get what we consider cheap labor. The students don t know what things can t be done, \nand therefore often do the seemingly impossible. Best of all, they get to see what the real world is \nlike (although the thought of an industrial research lab being a part of the real world is more an indication \nof how artificial the world of academia is than how real our world is). This past summer, while walking \nback from lunch about a week into his tenure, the intern working in my group turned to me and asked, \nSo, how do you go about learning to design a system? Like most great questions, it showed a level of \nnaivety that was breathtaking. The only short answer I could give was, essentially, that you learned \nhow to design a system by designing systems and finding out what works and what doesn t work. I ve been \nthinking about the long answer ever since; I m not sure that the long answer differs from the short answer \nin much more than length, but nonetheless here is what I ve come up with. 3.1 The Origin of Good Design \nBefore knowing how to train someone in system design, it is useful to have some idea concerning the origin \nof good design. If we can know what leads to good design, we can try to teach people to do those sorts \nof things in the hope (although not the guarantee) that good design will result. There is no shortage \nof books, seminars, and other training guides that claim to help in this quest. There are techniques \n(such as Six Sigma) that profess to aid in the development of good design. There are languages (such \nas UML) that claim to help in the development of good design. And there are no end to the methodologies \nand processes that claim to enable any team to create a good design that will meet the needs of the customer \nby the mere repeated application of the rules that make up the methodology. I have no doubt that the \nsuccess stories that each of these design approaches and aids cite are true. In some sense, that is just \nthe problem; completely incompatible and contradictory approaches to the design problem have been shown \nto be wildly successful (by their proponents) and wildly unsuccessful (by the proponents of competing \napproaches). Bottom-up or top-down, waterfall or extreme; all seem to work for some and not for others. \nThe only generally applicable rule that doesn t have obvious counterexamples is one I first heard enunciated \nby Fred Brooks more than a dozen years ago. In a talk given in a Sun-internal seminar (an expanded version \nof which became the basis for his Turing Award lecture in 2000[3]), Brooks talked of the work he had \nbeen doing to try to find the underlying common feature of good design, not just in computer hardware \nand software but also in such endeavors as architecture, graphics, and the fine arts. The only thing \nthat he could find that good designs had in common was that they were produced by good designers.3 There \nis one reading of this insight on which it is true but uninteresting, a mere tautological statement that \nreflects giving in to the unpredictable and inscrutable mystery of design. On this reading, the only \nway to determine what produces a good design is to wait until you have one, and then attribute it to \nthe designer. Good design, on this view, happens by chance. You can hope for it, but you can t do anything \nto improve your chances of getting a good design. This is not the reading that I believe Brooks intended, \nnor the one that I found persuasive when I first heard the talk. My reading of this principal is that \nthose who have been able to produce a good design in the past are far more likely (although not guaranteed) \nto be able to produce a good design in the future. But there is no magic process by which such designers \nproduce their designs; each may go about the design problem in a different way, and a designer may approach \none problem in a particular way and another in a completely different fashion. The point, I believe, \nis that good design is a capability that some people have, and others simply do not. Whether this is \nan innate skill that people are born with, or one that is cultivated over time in ways that we don t \nunderstand, is a question far too deep for me to address here. I neither know nor care. But by the time \nsomeone is designing a computer system, whatever it takes to be a good designer is either there or it \nis not. When it is there, it can be developed and honed (or, unfortunately, degraded and warped). But \nwhen it is not there, there is no technique or process that can make up the deficit. There are a number \nof people who are uncomfortable with this concept. Many of them are managers; I will discuss their discomfort \nlater. Others are uncomfortable with this view on more philosophical grounds; they feel that saying that \nthere are those who can produce good designs and those who cannot is contrary to some egalitarian notion \n(which it is) and somehow elitist or undemocratic (which I think it is not). 3 As a somewhat depressing \nside-note, the first question asked at the end of the talk (by a senior engineer) was what process those \ngood designers used to produce the good designs. Sometimes hearing is not the same as understanding. \nWhy should we be surprised to find that there are some people who are just not capable of doing first-rate \nsystem design? Such designs are difficult, complex, and require a great deal of taste to get right. Further, \nthey require the ability to deal with a great deal of ambiguity while forming the design, an ability \nto deal with whole sets of questions that can t be solved but which the system designer knows (or has \nthe faith to believe) will be solved at the appropriate time. Given the difficulty of all of these tasks, \nit is no more surprising that not everyone can be a great designer than it is that not everyone can be \na great composer, or a great artist, or a great architect (all fields that also require design). This \nis not to say that designers are better people than those who are not great designers; indeed, designers \nare good or bad people in roughly the same proportion as any other group. But it is to say that some \npeople are better designers than others, and ignoring that is one of the many things that leads to bad \nsystem design. 3.2 Teaching by Doing Having said all that, the question of how to teach system design \nis still open. The fact that good designs come from good designers does not tell us where the good designers \ncome from. While it may be true that not everyone can be a good designer, it is also true that there \nis some learning that goes on. I am reminded of posters I saw years ago at the Rhode Island School of \nDesign, posters with the headline Talent without technique is a waste. The school did not claim to be \nable to make anyone an artist. But they did (and do) claim to be able to take someone with the talent \nto be an artist and give them the technique that will let them exploit and channel that talent. The same \nis true in system design; it may be that you have to have some talent to do the design task well, but \nit is also true that you need to learn the technique that allows you to channel and amplify that talent. \nIn my own case, the instruction that I received in system design came in the form of an apprenticeship \nwith a master designer. This was not a formal arrangement, and it could well be that the person I considered \nmyself apprenticed to did not see our relationship in anything like those terms. But looking back on \nit, I clearly see it that way. The more structured and corporate relationship was that of an overall \nsoftware architect for a major component of a system and an individual contributor for that system. The \ngroup I was in was responsible for the user environment component (basically, the windowing system and \nall user-visible tools) for Apollo Computer, an early workstation company. The architect of the group \nhad implemented the first version of these components on his own, but grander plans had been hatched \nfor the second system (as is always the case) and a small group had been assembled to do the design and \nimplementation. I had been hired to design and implement the component library that would deal with text; \nthere were others who were dealing with the windowing system, input mechanisms, the shell interpreter, \nand even a scripting language. The overall design process for the group required the owner of each component \nto write a series of specifications for his or her component, starting with a straw man (a quick sketch \nof the various pieces and the overall component model) and ending with an iron man (which would be a \ndetailed specification of all of the entry points and their functionality). Once a month, the entire \ngroup would go off site (usually to the apartment of the manager of the group) for a morning and review \none of the specifications for some component. The overall architect of the group was not one of the more \nactive participants in these discussions. But when he talked, everyone else listened. His most damning \ncriticism was a simple That s too hard. When said of a specification, it indicated that you had not done \nthe work to sufficiently understand the problem and boil it down to some simple core. The assumption \nwas that there was always some simple core, and by making the assumption such a core was generally found. \nThese design reviews, and the constant interaction with both the architect and the other members of the \ngroup over a multi-year period of time, were the places where my system design skills were honed. It \nwas here I learned about simplicity and symmetry, about interfaces and designing for change, and a host \nof other rules and techniques that I still use. More important, I learned what worked for me and what \ndid not, and that what worked for me might not work for others. Rather than learning a process of design, \nI learned how I could best design. I had originally thought that this way of learning design was unusual, \nand caused (in my case) because my academic background was in a field unrelated to computer science. \nBut as I learned more and began talking to others who I considered to be good at system design, I found \nthat this experience was more than just common; it was nearly universal. Everyone I talked to had a similar \nstory of the master designer who had, either consciously or by example (and correction) taught him or \nher what they considered to be the important lessons in design. There was a period when I would ask, \nwho did you do your design apprenticeship with? without supplying any other context. I expected some \nto be confused by the question, but I found that everyone to whom I asked the question not only understood \nit, but was able to answer without thinking. Even more interesting, the names that were given were often \nthe same. Whether they knew it or not, a relatively small number of master craftsmen were credited with \ntraining a much larger number of system designers. This was hardly a scientific survey, and as scientists \nwe should take care in drawing strong conclusions from anecdotal data. But I think it is indicative of \nsomething that no one that I have talked to about how they design and how they learned to design has \npointed to a class that they took which trained them in any important ways. Design, if my experience \nis any indication, is best learned by a long and varied process of trying, failing, and trying again \nunder the guidance of someone who is an expert at the task. 3.3 Design and Curriculum That no one seems \nto learn system design from some course can be troubling. If designing of systems is really the hard \npart of what we as engineers and computer scientists do, aren t we in need of some systematized way of \nteaching what is needed to do that kind of design? Looking around the web, there are some courses in \nsystem design that are taught at various universities, and lots of courses offered by consulting companies. \nI have more than just a passing interest in a course in system design for a variety of reasons, not the \nleast of which is that I have been contemplating teaching such a course. It is the sort of course that \nstudents ask for; it would be valuable if students coming into industry actually had some skill in system \ndesign; and it would be interesting to design the curriculum and readings for such a course. I had great \ndifficulty in getting anything like a set of readings or a coherent plan for such a class. There are \nsome obvious readings (such as Lampson[6], and Brooks[2], and lots of things by Parnas[4]), but deciding \non the concepts that needed to be taught and the sequence in which those concepts are to be presented \nkeep eluding me. After enough time of trying and failing to come to some plan, I realized that I was \nthinking about this problem in the wrong way. More than half a century ago, the philosopher Gilbert Ryle \nmade a distinction between knowing how and knowing that[8]. Knowing that is a relation between a person \nand a proposition; it is a piece of factual knowledge that can be discovered, can be justified, and can \nbe taught by the usual mechanisms of pedagogy. Knowing how is a different kind of thing; it is the kind \nof knowledge we have when we know how to walk, or run, or sing. It is not a factual sort of knowledge, \nbut an ability that we exhibit in our actions. We can know how to do something reasonably well or expertly \n(while we can t know that the world is round reasonably well or expertly). Most important, while we can \nbe taught to know how to do something, the kind of teaching that takes place is very different from the \nkind of teaching required to know that. Academic disciplines require a combination of knowing how and \nknowing that. To be fully educated in any of these disciplines, one certainly needs to understand the \nfactual backgrounds of that discipline. But to be truly educated in the field also requires that one \nlearn how to think in a particular way. Each field has its own technique (or set of techniques) that \nmust be learned just as well as the subject matter of the field if you really want to be an expert in \nthat field. Different fields have different combinations of subject matter (knowing that) and technique \n(knowing how). The vast majority of my formal (academic) training was in the field of philosophy; as \npracticed in the United States and England (the so-called Anglo-American or analytic approach to philosophy) \nthe field is almost entirely technique. Certainly there is plenty of content (the history of philosophy \nand the great philosophical questions) but what really matters is the way in which one thinks (conceptual \nanalysis, the building of logical models, approaches to argumentation). While very little of the subject \nmatter of philosophy was useful to me when I became a software engineer, I found that the techniques \nI learned were just as relevant in computer science as they were in the field in which I learned them. \nI m told by those who have attended that law school is very much the same, in that gaining a technique \n(learning to think like a lawyer) is far more important than the actual subject matter of the law (which, \nafter all, varies widely from locale to locale). After one has learned the technique, one can take the \nbar exam for a particular state (which tests knowledge of the subject matter of the law for that state) \nbefore one can practice law. But knowing the law without knowing the technique does not make one a lawyer. \nThere are other subjects (the sciences come to mind) where there is far more subject matter to master \nalong with the technique. When studying geology you still need to learn to think like a geologist, but \nthere is also a lot of subject matter that must be mastered. In these subjects, learning the technique \nis often a byproduct of learning the subject matter, or at least a byproduct of the pedagogy used in \nteaching the subject. Courses are organized around parts of the subject matter rather than around technique. \nA well-designed program will use the technique of the field in all of the courses for that field, and \nwill use the learning of the subject matter as an excuse to train students in the technique. Courses \nthat try to teach only technique tend to be somewhat unsuccessful; at best they can provide a forum for \nstudents to demonstrate their technique rather than acquire it. The academic discipline of computer science \nhas not, I believe, done a particularly good job of recognizing the distinction between the technique \nand the subject matter of computer science. While there are some examples in which the technique is reasonably \nwell described (a recent piece by Jeannette Wing[10] does a great job of describing what it is to think \nlike a computer scientist), the seemingly non-terminating discussion of what the curriculum of a computer \nscience major (see, for example, [1]) appears to confuse the techniques that we need to instill with \nthe subject matter that we need to teach. My own conclusion is that system design is really a matter \nof technique, a way of thinking rather than a subject that can be taught in a particular course. It might \nbe possible to build a program that teaches system design by putting students through a series of courses \nthat hone their system design skills as they move through the subject matter of the courses. Such a series \nof courses would, in effect, be a formalized version of the apprenticeship that is now the way people \nacquire their system design technique. There may even be departments of computer science that have just \nsuch a series of courses. If so, I am not aware of them. They would certainly not be found by looking \nfor schools that teach a course in system design; all of their courses would have as a subtext system \ndesign. I think it far more likely that computer science departments teach system design in much the \nsame way that I learned system design that there are some professors who act as master craftsmen in the \nfield for a group of students, who apprentice with such professors by taking courses with them (often \nnot caring about the subject matter) and learning by doing. But such training is accidental at best; \noften students are advised against taking too many courses from a single faculty member, which has the \neffect of lessening the possibility of such technique training occurring. What would be best is a situation \nwhere an entire department was cognizant of the need to teach the design technique, and all of the courses \nfrom any of the instructors had as an admitted goal the training in such technique. Such curricula are \npossible in other design fields, but they are difficult to design and even more difficult to evaluate. \nUntil we as a discipline find a way to do this kind of curricula design and evaluation, system design \nwill continue to be learned as a craft, through an apprenticeship, and outside of the normal academic \nchannels. Perhaps this is all that we can expect, but in times of optimism I think that we as a field \ncould do better. It might be that we should look not at engineering but at the studio arts for direction \non such a curriculum. The approach taken there is that the students do lots of design projects, of varying \nlevels of complexity and size, and are constantly undergoing criticism of their work, both from their \npeers and their instructors (and seeing the work of their peers being criticized as well). This is a \nlot more work, both for the students and the teachers, but seems to have some positive impact on the \ndevelopment of technique in an area where elegance and taste are being taught. I doubt that we could \ndo worse than we do currently if we as a discipline were to give such an approach a try. 3.4 The Intellectual \nGene Pool Before moving on to other topics, there is one side trip that I feel must be taken while on \nthe subject of learning system design. It has to do with what I think is an unfortunate narrowing of \nthe intellectual gene pool in our field. When I first started writing software, the industry was expanding \nso rapidly and the academic field was so new that there were far more jobs for software engineers than \nthere were candidates with degrees in the field. As a result, lots of different backgrounds were represented \nin nearly every software engineering group. For example, in the group in which I served my apprenticeship, \nthe academic backgrounds included a Ph.D. in physics, a Ph.D. in philosophy (me), an engineer who had \ndone graduate work in psychology, another whose background was in anthropology, and two musicians (along \nwith two engineers who had degrees in computer science and one who had no degree at all). As a result \nof all of this diversity of background, there were lots of different viewpoints on any given problem, \nand lots of ways of looking at any task. The end result was one of the most interesting and innovative \ngroups that I ve ever been a part of. What I find distressing is that I doubt very much if any of the \nmembers of that group who had studied something other than computer science could have gotten their first \njob as a software engineer today. While academia has always insisted on the proper credentials in the \nproper field (not surprising, given that they exist to issue such credentials), industry now requires \nthat those who fill the job of software engineer be trained in that field. The result is that the candidates \nentering the profession are far more homogeneous in the way they think and the way that they approach \nproblems. Many times they have been told what the proper way to solve a problem is, and so they simply \nsolve it that way. If we actually knew how to teach the way to think like a computer scientist or software \nengineer, and knew how to teach people to think that way, this might not be a problem. If we actually \nknew the answers to most of the questions that come up when producing software, getting people who already \nknow those answers would be a way of making the industry more efficient. But, as I argued in the previous \nsection, I don t think that we are very good at teaching how to think like a computer scientist (or at \nleast like a system designer). Nor do I think that we have adequate solutions to many of the problems \nthat have to do with system design in particular and software engineering in general. We can certainly \nget more immediate returns on our investments by hiring only those students who have a degree in computer \nscience or a related field. But I fear that we are limiting our genetic stock of ideas prematurely, and \nas a result the discipline is the poorer for it. 3.5 Education and System Design If the above observations \nare correct, then it is not all that surprising that system design is uncommon, and good system design \neven more so. Good system design requires not only talent but the training that supplies the needed technique \nto go along with that talent. System design is not something that can be covered in a class, but is learned \nthrough a much longer process that is more like an apprenticeship than anything else. Such apprenticeships \nare not the sort of thing that our educational system is set up to provide (at least at the undergraduate \nlevel), and is not going to be provided by some change in the set of courses that make up the curriculum. \nIn fact, most who do system design learned their craft after they completed their formal classroom education, \neither on the job or while doing thesis research. But changes in the economics of both research funding \nand the software industry have conspired against the kinds of training that lead to good system design. \n 4. WHERE SYSTEM DESIGN HAPPENS If system design is in fact learned as part of an apprenticeship, there \nare two places that we should expect such learning to take place. The first is in graduate school, where \na student can work with a single faculty member (an advisor) who acts as a master. The other is on-the-job, \nlearning the arts of system design by doing such design. But various forms of pressure have made this \nkind of training harder and harder to obtain, because less and less real design goes on either in academic \nresearch or in industry. Instead, academic research has become much more of an evolutionary task, a change \nthat has been an unintended consequence of decisions by funding agencies designed to reduce risk. At \nthe same time, industrial system design has become more constrained, more expensive, and less adventurous. \nThe result of both has been not just a reduction in the ability to teach system design, but an environment \nin which many of the wrong things are being taught about how to accomplish that task. 4.1 Industrial \nSystem Design Perhaps we should not be surprised that there is less opportunity to learn system design \nin industry, if for no other reason than that there are fewer systems that need to be designed than there \nwere ten or twenty years ago. Industry consolidation and maturity have changed the need for system design, \nand therefore the opportunity for learning such design. Twenty years ago there were far more companies \ncreating computer systems than there are today. Further, these companies competed not merely on price \nbut on the functionality, stability, and sophistication of the overall system, which was proprietary \nto the company. Every computer company had their own chips, their own hardware, their own operating system \nand their own programming language (indeed, IBM had three or four of each). In addition, customers buying \nthese systems would then need custom software that went beyond the basic computer system, so there was \na thriving industry in building that custom software. All of these projects required system design, so \nthere were lots of chances to try designing a system, and lots of chances to learn either by getting \nit right or (often better) getting it wrong. There was also a thriving interchange of design ideas in \nconferences like USENIX, OOPSLA, HotOS and the like. Current industry trends are very different. Where \nthere used to be many computer companies, there are now far fewer. The number of operating systems has \nbeen reduced to two, with the choices being Windows or one of the Unix variants. Customers almost never \npurchase custom software systems, built from the ground up from specifications hammered out in discussions \nbetween the software engineers and the customers themselves. Instead, most custom software is written \nto allow the connection of existing systems, or the continuation of those systems on new hardware or \nin new environments. The production of this kind of software comes not from small companies that specialize \nin doing system design but rather from either the consulting services of existing companies or specialized \nconsultancies, and is generally constrained to the existing environments in such a way that the design \nfreedom of the creator of the software is tightly constrained. A lot of effort has been put into finding \nways of building these custom systems in ways that are more efficient and responsive to the customer. \nTechniques such as extreme programming, in which small changes are made to a system with constant feedback \nfrom the customer have been developed and are widely used. These techniques emphasize doing quick prototypes \nand then enhancing those step-by-step until what the customer wants is produced. Such techniques are \nexcellent ways of making sure that the system produced is the one that the customer actually wants. But \nthey are not good techniques if one wants to insure some form of up-front system design. Rather than \ntrying to think out the system ahead of time by decomposing it into its constituent parts, these sorts \nof iterative techniques emphasize adding features by aggregation on to a first-approximation core. System \ndesign may be enhanced by refactoring as the project progresses, and there may be times when it is possible \nto review the entire system and change the design. But neither of these activities helps to get the project \ndone, and often the result of such work is not visible to the customer. It is far more usual that problems \nin the design are coded around rather than fixed. The end result is a system in which the design emerges \nrather than one in which the design is thought-out. Even worse than not being visible to the customer, \nwork done on designing the system is not visible to the management of the company that is developing \nthe system. Even though managers will pay lip service to the teaching of The Mythical Man Month[2], there \nis still the worry that engineers who aren t producing code are not doing anything useful. While there \nare few companies that explicitly measure productivity in lines-of-code per week, there is still pressure \nto produce something that can be seen. The notion that design can take weeks or months and that during \nthat time little or no code will be written (or that which does get written will be thrown away, which \noften appears to be regression rather than progress) is hard to sell to managers. The fact is that good \nsystem design takes time; it is the sort of thing that requires hard solo thinking along with long discussions \nwith other engineers. There are days when no real progress seems to be made, and other days when the \nonly progress is to realize that what you thought was progress over the previous few days (or weeks) \nwas in fact a wrong turn that won t really work. Such a realization is progress (in fact, perhaps the \nmost important progress, as it can save huge problems later in the project), but to a manager it may \nnot seem to be moving forward. Grady Booch once told me that he believed that the greatest contribution \nthe tools he and others had produced to support the design process was that they made it appear to managers \nthat the designer was doing something. He may have been exaggerating, but not by much. Anything that \ngives the designer time to think about the system before committing those thoughts to code helps the \ngoal of well-designed systems. What is really needed is an act of faith by management. The difference \nbetween someone who is making progress in coming to grips with a system and someone who is taking an \nin-office vacation may not be visible from the outside. Most managers are not able to do the design task \nthemselves (those that can are rarer than those who can make the needed leap of faith), and so have to \ntrust the system designer. Having an engineer as the designer who has been successful in the past may \nhelp a manager to be patient. But if you find a manager who is actually willing to give you time to do \nthe design task, stick with him or her. He or she is a treasure much rarer than gold. 4.2 Design and \nIntellectual Property A subtler change that has had an impact on system design is the change in the way \ncorporations (and, to some extent, universities) view intellectual property. One of the reasons that \nthere were conferences and mailing lists that documented and discussed system design was that the companies \nin which those systems were developed did not want the ideas underlying the systems to be kept secret. \nIndeed, the developers of the system were generally encouraged to publish their designs. Such publications \nwere seen as ways to market the products shipped by the company, and were seen by the designers as ways \nof getting feedback and new ideas about the design. It also meant that there were forums where system \ndesigners could look at the work of other designers, discuss that work with them, and find solutions \nthat could be incorporated into their own designs. But over the past decade, the companies that funded \nthe design work decided that they wanted to be paid when others used the results of the design. On the \nface of it, this is not a bad thing. If companies invested and obtained a result, it is reasonable that \nthey be rewarded for the investment. If these companies can see that there is a reward, they are more \nlikely to continue the investment. This is the premise behind the patent system in particular and intellectual \nproperty rights in general, so perhaps we should be surprised that there was a period when this kind \nof thinking was not applied to system design. There has been much debate about whether or not software \nin general and system designs in particular are proper artifacts for the patent process. I m not sure \nwhere I stand on such issues; discussions on the reification of ideas in software and the comparison \nof that to the reification of other inventions in a form that can be touched and manipulated, and discussions \nof whether software system designs are more properly covered by patent laws or copyright, are interesting \nas ways to fuel conversations over drinks. But like many discussions that are essentially philosophical, \nI m not at all sure that they will terminate with a real conclusion. Less debatable is the fact that \nthe current system is not serving either the companies that fund design or the field in which the design \ntakes place. Whether this is an inherent aspect of the system or an accident of the way in which the \nsystem has evolved is an issue that is beyond my skills to decide. But the effects are harmful in ways \nthat I see every day. The first problem has to do with the way that the negotiation over the value of \npatents occurs between the companies that hold those patents. Such negotiations, I am told by those who \nhave been party to them, are generally done by count rather than by value. That is, company A will count \nup the number of patents it holds in some broad area (such as computer hardware and software). Company \nB will do the same. Whichever company holds the larger number of patents is the one that will be paid \nby the other, and the size of the payment is determined by the size of the difference. The end result \nis that each company cross-licenses all of their relevant patents to the other, and some amount of money \nchanges hands. The problem with such a scheme is that it does not take into account the quality of the \nideas that have been patented. A fundamental patent is a major part of the field is no more valuable \nin such a negotiation than some minor tweak that is no longer relevant because the industry has passed \nit by. The assumption is that, on average, any patented idea is just as valuable as any other. This is \nan assumption that makes such negotiations possible (since any negotiation based on the value of an idea \nwould take forever), but it also encourages the companies involved to attempt to patent any idea, no \nmatter how large or small, since the value of any patent is considered equal to the value of any other. \nThis in itself would not be a problem if the quality of patents were itself more uniform. However, the \nsoftware world is still somewhat mysterious to the patent office, and was even more so when software \npatents first started to be issued. We can all think of patents that have been obtained for techniques \nthat have been in common use for years, or patents for techniques that appear to most members of the \nprofession as obvious extensions to known techniques. I have toured the patent office, and know a number \nof the people who work there. They are trying hard to do the best they can, but are working with a number \nof handicaps. While the fees that are charged for patents are supposed to be returned to the office to \nfund the work that they do, in fact a considerable portion is taken and used elsewhere; the patent office \nis one of the few places in the U.S. government that could be considered a revenue generator. The pay \nthat can be offered to examiners is far less than what they can make in the private law firms that deal \nwith intellectual property law. One director in the patent office admitted to me that when examiners \ncould only make 50% more in private industry it was still possible (because of government pensions and \nbenefits) to attract good people, but when the differential became 100% or more it got much harder. The \nnumber of patents that are being filed has grown far faster than the number of examiners; I was told \nthat the current wait between a filing and the time that an examiner is even assigned to a case is close \nto three years. Until then, applications are stored in a room filled with shelves that looks like something \nout of the last scene of Raiders of the Lost Ark. The end result is that patents are examined in a somewhat \ncursory fashion by examiners whose expertise varies widely. The patent office, to its credit, has taken \nsteps to try to make things better, but there is a 10-year history of software patents of questionable \nquality. Once again, this would not be a problem in itself, for the issuing of a patent does not mean \nthat the patent is good. That, as any patent attorney will tell you, can only be decided in court when \nthe patent is contested. But here we get to the third problem with the patent system. Patent litigation, \nfor those who have been through it, is the closest thing I ve found to living in the world envisioned \nby Kafka. The theory is that a jury of ones peers can be presented with the facts of the case, and can \ndecide if the patent in question is an embodiment of a true innovation and if the technology in question \nin fact infringes on the patented invention. But a jury of one s peers does not mean a jury of one s \ntechnical peers. Instead, it means a jury made up of people registered to vote in the district in which \nthe trial is held. Indeed, having a technical background may well disqualify a person from serving on \nthe jury in a patent case, since such a juror may be coming into the trial with a pre-conceived notion \nof what is novel and what is not in the field. The result is that twelve non-technical citizens are asked \nto decide if something really is a novel invention, and if some other piece of technology infringes on \nthat invention. To make this decision, the holder of the patent will introduce an expert witness, who \nwill present his or her credentials and then testify that the invention is both novel and infringed. \nThe defending lawyers will present their own expert witness, who will present his or her credentials \nand then point out how the invention in question was well known prior to the filing of the patent, embodied \nin a number of pre-existing technologies, and not part of the technology that is claimed to be infringed. \nThe jury then has to decide which witness to believe. The presumption is that the patent is indeed valid \n(otherwise, why would the patent examiners have awarded a patent?). The end result is probably not as \nrandom as flipping a coin, but if you have gone through the proceedings it is hard to convince yourself \nthat the results of the process actually turn on the originality of the patent and the similarity of \nthe technology claimed to infringe on that patent. Worse still for the subject of this work, if you have \nbeen found to infringe, there is then the question of whether or not you have infringed knowingly. If \nit is found that you have (rather than just infringing by accident, by re-inventing the technology contained \nin the patent) the damages awarded to the holder of the patent are tripled. The impact on all of this \non the discipline of system design is that companies now encourage their designers to patent any part \nof their design that seems novel, rather than publishing that design in a journal or talking about it \nat a conference. The more of this work that can be patented, the larger the patent portfolio for the \ncompany, and the less likely it is that there will be a need to pay large amounts of money to other firms \nwhen cross-licensing agreements are made. Part of patenting is that you can t talk about the item being \npatented until the patent is filed4, which can be a long and involved process. At the same time, companies \nare actively discouraging designers from looking at the work of their colleagues in other companies. \nLooking at such work can lead to future claims of knowingly infringing on a patent, which triples any \ndamages that might be awarded. This combination of the desire to patent and the fear of knowing infringement \ncan lead to situations that verge on the absurd. I have been asked, as part of patent filings for work \nthat I have done, to provide exhaustive lists of any pre-existing work that might have influenced the \ndesign (known in the I.P. biz as prior art) while at the same time being warned not to actually search \nthe literature for anything that I might not have known about previously. While the general situation \naround software and systems patents is troubling, the impact that situation has had on the discipline \nof system design is not often acknowledged but is nonetheless large. The co-demands of keeping our own \ninnovations secret (at least until the patent is filed) and not studying the work of others (to keep \nfrom being charged with knowing infringement) is responsible, at least in part, for stifling the discussion \nabout systems design in the communities of software engineering and computer science. We now talk about \nthe process of system design, or the tools that we can use to support system design, but we rarely talk \nabout actual system designs. It is as though artists were told they could no longer talk 4 More precisely, \nyou can t talk about the invention before it is filed if you want to get a European patent. In the U.S., \nthe patent must be filed within a year of the invention first being disclosed. In practice, it is hard \nto get approval from the legal department of a company to talk about anything patentable prior to the \nfiling, and even after it might be difficult. about art, but could only talk about brushes, pigments, \nand the way in which they prepare a canvass. It is very hard to learn about good system design unless \nyou can see and study other system designs, both good and bad. The intellectual property atmosphere in \nindustry has limited the number of designs that are actually talked about, and has convinced many system \ndesigners that they should not even look at the designs that are available. Whatever you think of the \npatent system, this effect has been bad for the overall quality of systems. Before moving on to other \ntopics, it should be noted that open source is often touted as one answer to the problems of the intellectual \nproperty system. Open source, it is argued, has as a major advantage that anyone can look at and study \nthe code for a system, and hence can learn the design of that system. Good designs can be seen, as well \nas bad designs, and the discussion (generally on mailing lists) can take the place of the conferences \nthat we used to have on system design. There is a sense in which this is true, and for that I am a great \nproponent of open source. However, open source generally allows the discovery of system design from the \nartifact of the code, rather than supplying some kind of documentation that explains why the system is \ndesigned the way it is. Further, many of the well-known open source projects (such as Linux and the Apache \nWeb Server) are implementations of existing designs. Open source projects often show us the implementation \nof a system design, and reading the code can teach one a lot about such implementations. But they are \nless useful as ways of learning about the system design itself. 4.3 Systems and Standards The one circumstance \nin which most managers will allocate time for the design of a system is when that design takes place \nin the context of a standards body. This is also the one time that most companies will allow the designers \nto talk with other designers about that design. So it would seem that standards bodies would be the best \nplace for the activity of system design. Unfortunately, for a number of reasons, standards bodies are \namong the worst places to do real system design. The interaction between system design and standards \nbodies is complex and takes a number of different forms. At its best, standards bodies simply codify \nan existing technology that is so widely used that it is already a de facto standard. The intention is \nnot to solve a technical problem with the standard, but to clarify and specify existing practice. This \nis the sort of role that the groups that standardized the C programming language or the IP protocol had. \nThere were some technical contributions made by each of these standardization efforts, but those contributions \nwere to clarify edge cases where the existing implementations of the de facto standard differed. This \nis a very different role than that taken on by standards bodies that attempt to create a standard technology \nout of whole cloth or from an as yet unproven idea. Classic examples of such attempts are the groups \nthat defined the Ada programming language or the OSI networking standard. The OSI networking standard \ngave us the seven layer model that we all know and love, but also attempted to define a standard for \ninterconnect based on that model. Only the seven-layer model remains today. The Ada language specification \ndefined a language that is still in use, but most of the users are required to use the language contractually, \nnot out of free choice. In both cases, the standard was an attempt to invent and guide technology rather \nthan codify existing technology, and in both cases the results were somewhere between partial and total \nfailure. One of the differentiators of standards that succeed and those that fail is where the system \ndesign takes place. If the system is designed outside of the standards process (generally by a small \ngroup or an individual) and has been implemented and used, the chances of the standard being widely accepted \nand useful (like the C or TCP/IP standard) are high. If the system design is done by the standards group \nitself, the chance of producing a coherent and useful design is much lower. This should be no surprise. \nGood system design requires at least a unified vision of the overall system, and the ability to push \nthat vision to all parts of the system. This can best be accomplished when the design is the responsibility \nof a single person, and can sometimes be maintained when a small group undertakes the design. However, \na standards group is rarely small and unified in its vision. Indeed, the standards process is an inherently \npolitical one, where the addition of one feature is often bargained for by accepting the addition of \na different feature. This political aspect of standards groups is exaggerated by the commercial importance \nof standards. There was a time when technology companies differentiated themselves by the features that \nthey were able to design and build into their systems. However, over the last decade adherence to standards \nhas become more and more important. This is not surprising, as it allows customers of these technologies \nto simplify their acquisition of products. They begin with a checklist of standards, and find the vendor \nwho can supply all of those standards at the best price. More important, by adhering to standards, a \ncustomer is not tied to a particular vendor, since essentially the same system can be bought from the \ncompetitors of that vendor. Because of this change in the buying strategies of their customers, influence \nover standards groups has become very important for technology vendors. If a standard can be written \nin such a way as to advantage a particular vendor, the competitors of that vendor will be forced into \nplaying catch-up for some period of time. Thus participation in and control over standards groups has \nbecome a way for technology vendors to differentiate their offerings. The recent history of attempts \nto standardize various parts of the Extensible Markup Language (XML) takes this trend to something close \nto absurdity. In the early years of this decade, it seemed that a new standards body was being formed \nevery month to promulgate an as-yet-undesigned XML standard. Each of these standards bodies was made \nup of some subset of the overall set of computer vendors, and determining which company was controlling \nthe standards group and which was being frozen out took skills that used to be reserved for determining \nthe meaning of which commissar was standing by which politburo member during the May Day parade. All \nof this may make for good business. It may give customers more choice and more control. My only point \nis that it does not produce good system design. It is hard enough to do good system design when it is \ndone by a single person or a small group whose only design considerations are technical. When that same \ntask is attempted by large groups of people each of who has a different agenda and whose technical judgment \nis at least influenced by, if not subordinate to, commercial or political considerations, we should not \nbe surprised if the resulting designs are not those that we hope others will learn to produce. 4.4 Academic \nSystem Design If system design is best learned by apprenticeship, we could expect that system design \ncould be learned in graduate school, where the student/advisor relationship closely models the apprentice/master \ncraftsman relationship. This may be true for some graduate programs, but just as the changing economics \nof industry have made it harder and harder to teach (or do) system design in companies, changes in the \neconomics of academic research have made it more and more difficult to do real system design there. There \nis an idealized view of academic research in which that research takes greater risks than industry, plans \nfor the longer term, and is less concerned with the commercial success of a research effort than in the \nintellectual content of the research. On this view, academic research can take a longer view than industrial \nresearch and development, and can take on higher-risk questions since even negative results can add to \nthe base of knowledge that is the goal of academia. When a research program does pan out, the results \ncan be transferred to industry for further development, and the academic researcher can turn to the next \nbig question. Along the way, graduate students are trained in methods of research and techniques of system \ndesign, and when they are done they can either join the industrial world or return to academia to continue \nlong-term research and the training of the next generation of graduate students. Those who believe this \nwill also clap for Tinkerbell. The reality of academic research is much different than this. Professors \nspend much of their time writing grant proposals in an attempt to get funds for the support of graduate \nstudents. Once they get such grants, they need to target their research to produce the papers that will \nbe accepted to the appropriate conferences and journals in their field, and be able to show the granting \nagencies enough progress that they will be able to get another round of grants. The cycle is actually \nquite short, with most grants requiring either yearly or semi-yearly reviews (and some requiring much \nmore frequent updates). The received wisdom is that a grant needs to have enough detail to prove that \nthe work the grant will support will in fact be successful; to do this it is in turn often necessary \nto have done the work already. Thus there is a tradition in some departments of using the results of \nthe work done on one grant to get the money for the next grant. As in most systems, the hard part is \nbootstrapping (in this case, getting the first grant), but there is an increasingly common practice at \nuniversities to offer junior faculty seed grants for this bootstrapping mechanism. This may not have \nalways been the case, but the realities of funding agencies have dictated this form of risk-averse funding. \nThe funding agencies, many of which are governmental, have been pressured to show more relevance in the \nresearch they fund, and have sometimes been embarrassed by research that has not given positive results \n(some of us are old enough to remember Senator William Proxmire s Golden Fleece awards, given to government-funded \nresearch projects that appeared to be meaningless or otherwise ill\u00adadvised). As the funding agencies \nfaced more and more pressure to show that the work they were funding lead to actual results, those agencies \nin turn placed more emphasis on insuring that the research they funded would be successful. One way of \ndoing this is to require occasional bake offs between research projects competing for money. This funding \ntechnique uses a simple recipe. Give a number of projects seed funding for a first phase of a project. \nAt the end of the first (fairly short) phase, have the different projects demonstrate their results. \nAs a result of this demonstration, either re-allocate the funding favoring the most promising of the \nalternatives, or simply cut the funding to all but the most promising project. Repeat. A number of government \nand private agencies that have been known for funding long-term research now use this model. While the \nmodel seems to make sense and certainly cuts the risk of making a major research investment in something \nthat takes years and produces nothing but negative results, it also means that many academic research \ngroups are in a constant short-term effort to produce the next bake-off demo. As a result, academic research \nis of a shorter duration and is more risk-averse than industrial research and development. Industry is \noften able to invest in high-risk development based on the possibility of large returns (although this \nis often tied to making the results of the development into a standard, which was discussed in the last \nsection). Academics are increasing unable to convince granting agencies to fund for the same long duration. \nNor are academic institutions much more open to sharing the results of their research than is industry. \nThe lesson of intellectual property has not been lost on many of these institutions that now seem to \nhope that the developments of their research can be used to add to the endowment of the university. I \ndo considerable collaborative research with various academic institutions, and have noticed over the \npast five or so years an increase in the difficulty of negotiating agreements on the intellectual property \ngenerated by such collaborations. Indeed, one collaboration that I tried to fund a couple of years ago \nbecame impossible when the academic institution s lawyers insisted on terms that gave the institution \nall rights to anything that was done by anyone in the collaboration (including any work done entirely \nby my group inside of Sun). Even when the conditions are not so irrational, the desire by these institutions \nto patent the result of the work of their faculty and graduate students has had the same squelching of \nopen discussion as has been caused by the protection of intellectual property in industry. Whether such \npolicies will lead to more money for universities is yet to be seen, but these changes in funding and \nsharing do mean that it is less likely that full system design will occur at these academic institutions. \nAcademia is subject to the same pressures as industry (although the pressures may come from slightly \ndifferent sources), with the same results with respect to system design.  5. WHAT DOES IT ALL MEAN? \nThe previous sections paint a rather grim picture concerning the practice of system design. A combination \nof impatience, economic pressures, and a lack of trust by those who don t understand what is required \nfor system design seem to be creating a perfect storm, where we don t have the time or support to do \nreal design in either academia or industry, and where we can t train the next generation of system designers \nin the craft. Perhaps this is just a sign of the age of the author, and all of the trends that I have \nidentified are simply changes that have made the world different and to which I should simply adapt. \nI could be convinced of this if I didn t see a real desire in the next generation of engineers and computer \nscientists to learn something about system design. It isn t that they have gotten beyond the need to \ndesign systems; when they see a good system design they are appreciative, excited, and want to know how \nto create designs that have the same quality. They may not be able to verbalize what they are missing, \nbut they know it when they see it, and they would like to learn. Another possibility is that the lack \nof system design at this time is just part of a natural cycle of development in the field of computer \nscience. On this view, we are in the analogue of what Thomas Kuhn[5] called a period of normal science, \nin which the existing theory (or system designs) were being confirmed, tested, and slightly altered. \nPerhaps the systems that we have are good enough for what we need to do, so there is little or no need \nto do major design work on new systems. That will change in the future when we find tasks for which the \ncurrent systems are inadequate, but until we do we should expect little support for system design. Indeed, \nsystems like those being developed by Google are just the kind of radical departures that we would expect \nin a time of revolution, and they are indicators that we are about to enter into a new system design \ncycle. I have some sympathy for this view, in that it gives me hope that things will change. But I also \nrealize that this view is based on the false assumption that there are fewer systems being produced now \nthan there were in the past. In fact, I observe all kinds of systems being produced, from the service-oriented \narchitectures of web services to the ontologies of the semantic web. What I find missing in these systems \nis a notion of design other than the designs that are done in standards committees or other large groups, \nor designs that emerge from the code that is thrown together to implement the system. I think one explanation \ncan be seen if we re-read Ivan Sutherland s Technology and Courage[9]. System design, like any other \nform of research, is hard work that entails taking great risks and therefore requires the constant application \nof what can only be called courage. It takes courage for an engineer to design a system without constantly \nasking the customer if it is what the customer wants. It takes courage for a manager to trust an engineer \nto take the time to design a system. It takes courage for a funding agency to underwrite an academic \nresearch project that might well fail. It takes courage for a company to back a design that has not been \nblessed by a standards body. What we are lacking today in our industry is the courage that is needed \nto take the kinds of risks that are inherent in doing system design. Whether this lack is caused by the \nscarcity of funding, or the bursting of the technology stock bubble, or the consolidation of the industry \nis hard to tell. But the reason that we are no longer designing interesting systems is, I believe, simply \na lack of the courage needed to do so. If this is true, then one possible approach would be to solve \nthis problem ourselves, at both the individually and collective level, by simply insisting that we be \ngiven the time and resources to do good system design. Finding courage is difficult, and instilling it \nin others more difficult still. But either is less difficult than changing the economy, or the legal \nsystem, or the attitude of the funding agencies, or the ways in which our field is taught. Indeed, we \ncould make the change starting with ourselves, by taking the time and making the effort to do good system \ndesign, and to demand of our colleagues (and managers) that they both give us the opportunity to do such \ndesign and do such designs themselves. But given the realities of our industry and the wider economy, \nI hold little hope that simply making such demands will solve the problem. But this doesn t mean that \nthe situation is hopeless. Instead, it means that those who wish to continue in the craft of system design \nneed to find other, less direct, ways of allowing such design to be practiced and taught. I am actually \nencouraged by some signs that this is already happening, although perhaps not in the way (or in the places) \nthat any of us might have expected. These signs are not coming from industry, where the relative power \nof the engineer and the manager has changed to the advantage of the latter, and where managers are under \nincreasing pressure to cut costs and therefore have become more and more cautious. Nor do I see much \nchange in academia, where short funding cycles and publications by the pound are still driving out good \nsystem design. Where I see encouraging signs are in two areas that are generally not thought of as central \nto system design, the areas of agile methods and open source software. Agile methods mean lots of different \nthings to lots of different people, so I should begin by saying what I take them to be. This is not because \nI think that my characterization is any better than any of the others, but simply because it will help \nin the discussion that follows. Like patterns or open source (a discussion that will follow) here is \nconsiderable theology in the characterizations of agile methods, and I don t wish to get caught up in \nsuch theological debates. I m happy to admit that my characterization is not really what is meant by \nagile methods; what I am describing is a trend I have seen in development that is at least sometimes \ngiven that label. What I am using the term agile methods to label is an approach to writing code (and, \nultimately, systems) that is based on small groups of programmers working closely together; in the most \nextreme form of this the small group is a pair of programmers working together with a single keyboard \nand screen. No matter what the size of the group, the system is built by iteratively constructing small \npieces, and then enhancing that working system in small, manageable chunks to build the ultimate large \nand complex system. In addition, I include the practice of test driven development in which the tests \nfor some piece of functionality are written before the code that provides that functionality. There are, \nof course, many other techniques that get included under the term agile methods, but for the purposes \nof this discussion these are the features that are most important. Earlier I noted that such an approach \nto the production of a system seems to be an invitation to plunge into the code before thinking things \nthrough and then to make incremental changes to the undersigned system until things are good enough. \nSuch an approach seems to actively discourage thoughtful system design. And, indeed, I have sometimes \nseen these methods produce systems that were badly designed, overly complex, and not well thought out. \nWhat has surprised me is the number of well-thought-out systems whose designs show taste and elegance \nthat have been produced using these techniques. The reason, I believe, has to do with two of the aspects \nof such agile methods. The first is the combination of breaking the overall system down into small pieces \nand the requirements of test-driven development. Each of these techniques requires that some thought \nbe given to the abstractions that form the system. Breaking the system down into smaller pieces requires \nsome thought into what those pieces are going to be and how they fit together, which is exactly the art \nof system design. In order to write the tests before the code that is to be tested, an abstract notion \nof what the code is supposed to do must be thought through. In deciding what to test, a programmer needs \nto think about the general functionality of the system, and how that functionality is going to be accessed. \nBoth activities require thinking about the interfaces for the various components of the system in a fashion \nthat is one removed from the implementation of those interfaces. By deciding what small thing can be \ndone and by writing the tests first, agile methods impose a requirement of thinking about the abstract \nsystem that is a way of expressing the overall design of the system. The second, and more important aspect \nthat favors system design when using agile methods is that those methods require that the work be done \nin small groups, each member of which needs to understand the entire artifact. This in turn encourages \ndiscussion of the overall system, not just as the level of the code that is being produced but at the \nlevel of the system itself. Each member of such a team has to explain to the others how the system fits \ntogether, and just that act of explanation requires thinking about the design. Even better, the others \ncan then help to make the overall design better; the give-and-take of a small-group programming session \nis much the same as that found in a good design session because it is, in fact, a design session. What \nis important here is the required communication between the participants. Having to express a design \nwill often uncover problems with the design, and can certainly show areas where the design (and, therefore, \nthe communication of the design) is unclear or inconsistent. While it is true that writing down the design \nof a system is a form of documentation that can help people who want to learn or understand the system, \nthe greatest benefit of such a written design is to the designer who must do the writing. The very act \nof writing the design document helps to clarify the design itself. In the same way, having to communicate \nthe design during group programming helps to clarify and simplify the design. The process of small group \ndevelopment also provides a opportunity for the members of the group to serve their design apprenticeship. \nWhile the group may not consist of an acknowledged master and a set of apprentices (although it could), \nthe constant discussion of the design even with a peer group can help in the development of taste and \ncraftsmanship. While there is always the possibility that bad taste will be reinforced and bad habits \nencouraged, the process of peer-mentoring is better than no form of design feedback at all. Whether it \nbe to a group of peers or a master, the real point is that the design needs to be expressed to someone \nelse. It is very difficult to mask the weaknesses of a design when you are communicating that design \nto someone else who is intimately involved in the implementation of the design. Simple designs can be \ncommunicated easily; complex designs are hard to explain. Just as writing down a design will often show \nflaws or weaknesses in the design, explaining a design to a peer will often improve the design. Working \non an open-source project also provides engineers both a forum for the discussion of design and a mechanism \nfor learning through an apprenticeship. The first of these is supplied by the mailing lists that are \ncentral to many open source projects. On these lists there is constant discussion of the design alternatives, \nphilosophies, and trade-offs that are faced by the overall project. Newer or less experienced engineers \ncan ask questions that will be answered (and discussed) by the overall community. Like the discussion \nthat goes on between the members of a pair\u00adprogramming team, such electronic discussions allow the engineers \nto try out ideas, have those ideas criticized or amplified, and generally participate in the design process \nof a large project. The discussions tend to be at a different time-scale than those held face\u00adto-face \nwith a pair-programming partner, and often involve a much larger group of participants. But they are \nstill forums that require discussion of the design. Better still, they are forums that require that the \nparticipants communicate the design in a clear and persuasive way. Just as the act of communication between \ntwo programmers can help to clarify and simplify the design of a system, the act of communicating a design \nto the other members of an open source project will help to clarify and simplify the design of the open \nsource system. These discussions often replicate, at least electronically, the master/apprentice relationship \nthat is so central to becoming an accomplished designer. Such relationships are established in spite \nof the mythology that has grown up around the way open source projects are run. The establishment of \nthis sort of mentoring happens because of the reality of the way that open source projects work, a reality \nthat is very different from the folk wisdom that has grown up around such projects. The folk wisdom of \nopen source, best exemplified by the writings of Eric Raymond [7], holds that open source projects are \nchaotic, highly democratic undertakings in which the marketplace of ideas sorts out the good ideas from \nthe bad, the code is written by anyone, and there is no hierarchy. In actual fact, most of the successful \nopen source projects are run as semi-benign dictatorships in which a very small group of people controls \nall of the code that is put into the project. These people are the committers of the project, and no \ncode is allowed into the source repository until it meets their standards. It is true that anyone can \noffer code to the committers to see if it can be included into the project. But most of the code will \ngo through a very detailed reading by the committers, and only be accepted when it is found to be good \nby the standards set by this group. Not surprisingly, most of these committers are just the kinds of \nmaster craftsmen of code that you would want supervising the apprenticeship of those learning system \ndesign. The apprenticeship is not as direct, with little or no face-to-face discussion, but the overall \nprocess is the same. The apprentice will try to solve problems, offer his or her solution, and be told \nto try again (generally with some discussion as to the reasons for needing to try again) until the code \nand the design is right. The communication may be electronic rather than face-to-face, but the process \nis the same as it was 20 years ago; one of trial-and-error, of frustration and trying again, and of failure \nand (hopefully) enlightenment (or at least increased mastery). This is a process that benefits both the \napprentice and the master. The apprentice benefits in obvious ways, learning how to be a better craftsman \nand gaining a better understanding of how to build and design a system. The master benefits by using \nthe apprentice as an idea magnifier. By having others doing some of the work, the master is freed to \nconcentrate on those parts of the design or the code that only he or she can do. The end result is that \nthe kinds of systems that can be built are more significant, and the ways of approaching design are conveyed. \nThis ability to learn, to teach, and to tackle hard technical problems without the oversight or interference \nof management is also, I believe, one of the prime reasons for the popularity of open source projects \namong engineers. Such projects are places where technical decisions can be made on technical grounds, \nand where the decision making powers are given to those who have shown technical ability in the past. \nThe fact that the end result of such developments is innovative software that is often superior to that \nproduced by the projects that are the day jobs of the very people who write the open source software \nmay be ironic, but it should not be surprising. In an important sense, both agile methods and open source \ncan be seen as reactions to the difficulty of doing system design in either the academic or the industrial \nworld. One solution to this could have been confronting the managers, professors, and funding agencies \nthat have made it increasingly more difficult to do system design in the traditional environments. But \nthis other solution is both more indirect and, in many ways, more in keeping with the ethos of software \ndesign. Rather than trying to change the set of constraints that frame the problem, designers and those \nwho wish to learn design have simply designed around the problem. By adopting agile methods, we have \nfound a mechanism that allows us to discuss and learn design without having to tell our management that \nthis is what we are doing. By working in open source, we have created an environment in which we can \ncontinue to do technical work framed in purely technical way. The fact that open source needs to be done \non our own time is a minor inconvenience; most good software designers would prefer doing technical work \nto most other forms of recreation. In a meta-sense, the new venues for learning and teaching system design \nare themselves excellent examples of system design, in which a problem is solved in a fashion that is \nelegant, subtle, and pleases both the practitioner of the art and the consumer of the code. The end result \nis that the craft survives, thrives, and continues to evolve. 6. ACKNOWLEDGMENTS I would like to thank \nBob Sproull, Ivan Sutherland, Margo Seltzer and Ann Wollrath, all of whom have been generous with their \ntime and ideas during discussions of much that is contained in this paper. Special thanks go to Brian \nMarick, whose care and comments during the shepherding of this paper have greatly improved the result. \n 7. REFERENCES [1] ACM Curricula Recommendations, http://www.acm.org/education/curricula.html, 2005. \n[2] Brooks, F.P., The Mythical Man Month: Essays in Software Engineering, 20th Anniversary Edition, Addison-Wesley, \nBoston, MA, 1995 [3] Brooks, F.P., The Design of Design, Turing Award Lecture, http://terra.cs.nps.navy.mil/DistanceEducation/online.siggraph. \norg/2001/SpecialSessions/2000TuringLecture\u00adDesignOfDesign/session.html, 2000 [4] Hoffman, Daniel M. and \nDavid M. Weiss (ed), Software Fundamentals: Collected Papers by David L. Parnas, Addison-Wesley, Boston, \nMA, 2001. [5] Kuhn, Thomas, The Structure of Scientific Revolutions, University of Chicago Press, Chicago, \nIL, 1962. [6] Lampson, Butler, Hints for Computer System Design. ACM Operating Systems Rev. 15, 5 (Oct. \n1983), pp 33-48 [7] Raymond, Eric, The Cathedral and the Bazaar: Musings on Linux and Open Source by \nan Accidental Revolutionary, O Reilly Media (2001). [8] Ryle, Glibert The Concept of Mind, University \nof Chicago Press, Chicago, IL, 1949. [9] Sutherland, Ivan, Technology and Courage, Sun Microsystems Laboratories \nEssay Series, Mt. View, CA, 1996 [10] Wing, Jeannette M., Computational Thinking, Communications of the \nACM, Vol. 49, Issue 2, March, 2006.  \n\t\t\t", "proc_id": "1167473", "abstract": "In this essay, I consider some of the factors that are making it more and more difficult to expend the effort necessary to do system design. Because of changes in the economics of the field in both industry and research, we have become less able to take the time needed to do real system design, and to train the next generation of designers. Because of the intellectual property landscape, we are less able to discuss system design. The end result is that we do less good system design than we used to, at least in those environments where system design used to be most common. But there are reasons to be optimistic about the future of system design, which appears to be happening in non-traditional ways and in non-traditional venues.", "authors": [{"name": "Jim Waldo", "author_profile_id": "81319503639", "affiliation": "Sun Microsystems, Inc, Burlington, MA", "person_id": "PP18012393", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1167473.1167513", "year": "2006", "article_id": "1167513", "conference": "OOPSLA", "title": "On system design", "url": "http://dl.acm.org/citation.cfm?id=1167513"}