{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Symposium on Principles of Programming \nLanguages A PARTIAL EVALUATOR, AND ITS USE FOR COMPILING ITERATIVE STATEMENTS IN LISP by Anders Haraldsson \nInformatics Laboratory, Linkoeping University, Sweden ABSTRACT A partial evaluation program for LISP \nis described, and an application where it has been used. The partial evaluator performs a number of other, \nrelated operations such as opening of functions and certain optimizations on programs. The application \nis based on the fact that we can generate from an interpreter and a partial evaluator the same object \ncode as a corresponding compiler should do. The paper will first formally describe the relationship between \nan interpreter and a compiler through partial evaluation. The partial evaluator system is then briefly \ndescribed and finally an experiment is shown where an interpreter for the iterative statement in INTERLISP \nis partially evaluated. 1. INTRODUCTION This paper describes partial evaluation program for LI;P, and \nan application where it has been used. The partial evaluator performs a number of other, related operations \nsuch as opening of functions and certain Optimizations on programs. It operates on almost full LISP in \nthe INTERLISP dialect [1], and unlike previously reported partial evaluators it is not restricted to \na small subset or a toy language. The application is based on the fact that we can generate from an interpreter \nand a partial evaluator the same object code as a corresponding compiler should do, a correspondence \nfirst mentioned by Futamura [2]. This research was sponsered by the Swedish Natural Science Research \nCouncil (NFR) under contract Dnr F 2654-018. Partial evaluation has long been known as a promising method \nto implement programing languages, language extensions, and special purpose languages and has been used \nby several researchers [3,4,51 . A discussion and a survey of the use of partial evaluators are found \nin Beckman et al. [6], in which it is claimed that this technique if properly developed and utilized \ncan be a very useful tool in practical program development. An improved program manipulation system, \ncalled the REDFUN-2 system, is described in Haraldsson [7]. It uses partial evaluation as its central \noperation. The experiment reported here has been carried out in that system, and the work demonstrates \nthat the technique is approaching practical usability. In section 2 we will formally describe the relationship \nbetween an interpreter and a compiler through partial evaluation. In section 3 we will describe our system \nand in section report an experiment with an interpreter, used for the iterative statement feature found \nin CLISP [1]. In section 5 we will draw some conclusions of the practical use of this technique and propose \nsome directions for further work. 2. PARTIAL EVALUATION Partial evaluation is a technique which in simplified \nform can be described as: Suppose S is a procedure of n arguments <xl, x2, . . . . xn> and the values \nof the first m arguments are known as <vi, V2, . . . . vm>. A new procedure S can be generated by partial \nevaluation such that S (xm+l, .... xn) = (1) S(vl, .... vm, xm+l, .... xn) for all xi, i=m+l,n. relationsIf \nP is the partial evaluation algorithm we have the relations P(P,P) (I) (exp) (env) = (7) S(xl, x2r . \n. . . xn) = (2) = P(P,I) (exp) (env) = P(S,{<xl,vl> . . . <xm,vm>]) (xm+lr P(I,exp) (env) = C(exp) (env) \n.... xn) = S (xm+l, .... xn) i.e. P(P,P) (I) generates C and P(P,P) is the interpreter-to-compiler We \ncall the variables xi, i=l,m the conversion program. partial evaluation variables and the remaining \nvariables the runtime variables . If this theoretical reasoning can be realized as a computer program, \nsuch Suppose we have an interpreter I. We program is unquestionably useful. It is assume that it takes \ntwo arguments, an easier to write an interpreter than the expression expr to interpret and an corresponding \ncompiler. An interpreter environment env, for example the often tends to be more well-structured association \nii-in LISP 1.5. If we and therefore easier to understand and suppose expr is known we can derive the \nmaintain. An interpreter however is not following relation as efficient to use as a compiler and therefore \nin most applications a (expr,env) = P(I,expr) (env) = (3) compiler had to be written. = I (env) The question \nis: Can we construct a The program I is accordingly a partial evaluation algorithm and specialized version \nof the interpreter I implement it, so it could be used in which only can interpret expr in practice? \ndifferent environments env. The program I is an object program for expr. If we In the ideal case such \na partial on the other hand have a comer C and evaluator should be able to handle an compile expr we \nobtain interpreter wr itten without any restrictions on the choosen programming C(expr) (env) = I (env) \n(4) language, although it is probably a moderate restriction if some of the most If we assume that the \ninterpreter I and awkward constructs in the language were the compiler C are absolutely compatible not \nused or used in a restricted way. A holds call to the function eval in LISP can be devastating if the \npa-l evaluator has P(I,expr) no information at all about what can be then it that = C(expr) (5) evaluated \nthrough that function call. When the partial evaluator is applied toif P is good enough. In practice \nif itself it must naturally also be writtenthere exist both an interpreter and a with these restrictions \nin mind. It iscompiler they are usual ly not ~ fully today ever will able compatible with each other, \nsuch as the not clear if we be interpreter and the compiler in LISP to produce a practical which do not \nalways agree. interpreter-to compiler conversion program through running The next step is to partially \nevaluate P ( the partial evaluator itself) with P(P,P) respect to the interpreter I. We will then obtain \nAnother way to go ahead is to write that program directly. We have written a P P,I) (expr) (env) = : \nsimple such program which only handles (6) . P(Irexpr) (env) rather simple code and is described in [6]. \nFrom (3),(4) and (6) we can conclude that P(P,I) is a compiler C. Here we Further demands are that the \npartial have succeeded in generating a compiler evaluator must be written efficiently from an interpreter. \nenough so it can be use:d in practice and the partial evalutor must be powerful If we go on further and \nwant to generate enough so the resulting object code is compilers for different interpreters as good \nas the compiler generated code. then we want to partially evaluate P with respect to P itself! We would \nthen Futamura gives in his paper [2] a recieve an interpreter-to-compiler description of a partial evaluation \nconversion program. We have the algorithm but he had only run rather small examples through it. Partial \nevaluation in itself is not so useful unless it is combined with other operations, such as opening of \nfunctions and various types of optimizationsr and it is important to consider how such operations are \nincorporated with the partial evaluation algorithm. 3. THE PARTIAL EVALUATOR IN THE REDFUN-2 SYSTEM We \nwill first describe in principle how a Partial evaluation algorithm works and then briefly describe the \nREDFUN-2 system. In principle a partial evaluation algorithm P works as follows: P takes two arguments, \na program S and the set of partial evaluation variables PV. P will be recursively applied to all expressions \nand sub-expressions in S. Variables in PV are replaced by their values. Whenever this operation yields \nany expression which contains only known values that expression will be evaluated. This assumes that \nwe have no side-effects involved; otherwise the expression normally must remain as it is and its evaluation \nis postponed until runtime. In conditionals if the predicate is known either its true or false branch \nand the predicate as well can be eliminated. Assignments found in the processed program must be taken \ncare of and PV must be updated according to them. The partial evaluation algorithm in REDFUN-2, denoted \nPRF, works as above. It can however also handle cases when, although we do not know the value a variable \nwill have, we know the set of possible values of the variable, or know some values a variable can not \nhave, or know the dakatype of the values a variable can be bound to. Such variables must be treated as \nruntime variables and must remain in the code. We denote such variables RV. For an expression which contains \nsuch variables the system tries to calculate its value range and these values can be useful in order \nto discard parts of the processed program. Such ranges are determined by the system either through repeated \ncalculations of the expression with different combinations of argument values, or by invoking so called \nsemantic procedures, associated with a function, by which calculations of the value range can be performed. \nAll functions used in S must be classifed depending on which operations are allowed to be performed on \nthem. There are functions which are pure in the sense that they can be evaluated at partial evaluation \ntime if all arguments are known, functions which either perform or depend on side-effects and functions \nwhich evaluate their arguments in a nonstandard fashion (FEXPR S) which must be treated specially. The \nREDFUN-2 system also performs other transformations and optimization. It provides a facility to open \nprocedures in various fashions such as beta-expansion, insertion of lambda-expression etc. and perform: \n~-transformations in the code from rules given by the user. For ~-expressions there are analyzers for \n~-structure and for the assignments made in the various branches. After partial evaluation has been carried \nout in a ~-expression there are a number of transformations of a more clean-up nature, such as removing \nlocal variables not used any longer, removing unnecessary assignments, eliminating dead code and rearranging \nthe goto-structure. The full REDFUN-2 system is a quite large LISP program. It takes about 120 pages \nto print in prettyprinted format and occupies 60000 words in the INTERLISP-system on our DEC-2(1 computer. \n4. AN EXPERIMENT In order to test the power of our REDFUN-2 system we performed the following experiment \nwith succesful results. An interpreter, denoted 11S, which previously had been written at our lab was \ntaken as test example. The interpreter had been written expert LISP programmer (Jim G~~dwi~~ without \nknowing anything about our ideas about partial evaluation of interpreters or that the program would be \nused as a test case for our REDFUN-2 system. The program 11S interprets the iterative statement feature \nfound in CLISP[lI. This feature allows for example following constructs (FOR I FROM 1 TO 10 DO (PRINT \nI)) (IN AL COLLECT CAR) (FOR X IN L JOIN (CDR X) WHEN (LISTP X)) The CLISP implementation uses the compiler \napproach and compiler, denoted CIS, translates th~ iterative statement to efficient prog expression which \nt;;n is executed. . We have here the cases (3) and (4) from section 2. Our expectation was that from \nan expression of the form PRF(IIS,expr) where PRF is the REDUN-2 system, 11S is Goodwin s interpreter \nand expr is an iterative statement, we would be able to produce object code as good as the compiler in \nCLISP would do through CIS(expr) We could naturally not expect to generate the same code, because the \ninterpreter and the compiler are written by different persons and with different assumptions. Notice \nthat both the CLISP implementation and Goodwin s interpreter are language extensions in LISP, in the \nsense that they are transformed to conventional LISP code which can be interpret by the LISP interpreter, \nor compiled to machine code using the LISP compiler. The interpreter 11S is implemented in such a way \nthat it first parses the iterative statement. During that step a number of variables are bound to values \nwhich fully describe the statement. In a second step an executor is called which exec utes the statement \ndepending on these variables. In our experiment the parsing step can remain as it is and is called at \npartial evaluation time. The main task is then to partially evaluate the executor with respect to these \nvariables with known values produced in the parser step. The executor is a program with a size of about \n100 prettyprinted lines and its code is shown in appendix 1 to give an idea of the complexity of code \nour REDFUN-2 system can handle. In appendix 2 some other examples are given. We will here give the code \nfor the simple statement (FOR I FROM 1 TO 10 DO (PRINT I)) (8) Our method gives (PROG (RANGE:LEFT I) \n(9) (SETQ RANGE:LEFT 1) (SETQ I 1) $$LP (SELECTQ (GREATERP RANGE:LEFT 10) (T (GO $$OUT)) NIL) (PRINT \nI) (SETQ I (SETQ RANGE:LEFT (PLUS RANGE:LEFT 1))) (GO $$LP) $ $OUT (RETURN NIL)) and the compiler in \nCLISP produces (PROG ($$VAL I) (lo) (SETQ I 1) $$LP (COND ((IGREATERp I 10) (RETURN $$VAL))) (PRINT I) \n$$ITERATE (SETQ I (IPLUS I 1)) (GO $$LP)) Both expressions can of course be compiled to machine code \nusing the LISP compiler. In comparison there is no real difference between these t Wo prog-expressions. \nThe prog-variable . range:left in (9) depends on the design in the implementation of the interpreter \nversion. It uses a local variable as an internal loop variable and a change of the external loop variable \nwill not change the internal one. In the compiler implementation the loop variable i can be affected \nin the loop body. Some problems. Actually there was one change in the original 11S program in order to \nproduce this code. The function segmap (see appendix 1) was first written iteratively as a prog with \na simple loop. The calls to that function were of such nature that one wants to unroll the loop in order \nto get good code out of it. Unrolling of loops has not yet been incorporated in the system. This problem \nwas solved s imply by redefining the function to a recursive one. By opening the function recursively \nthe desired code was achieved. Another problem is partial evaluation of loops . Futamura points out this \nproblem in [2] and mentions that his partial evaluation algorithm may not terminate if the loop is not \ngood enough. For us the problem is that when variables in PV and RV are assigned ins ide the loop, such \nassignments must be considered before the partial evaluation of the loop takes place. It can then happen \nthat an assignment affects PV or RV but that the assignment will later disappear because the code containing \nit is eliminated. A simple example . (11) ~SETQ A 1) (SETQ B 5) LOP (COND ((EQ B 1) (SETQ A 2))) (COND \n((EQ A 2) (FOO X Y))) ;GO LOP) . . We assume there are no other assignments of a and b inside the loop. \nThe analy~is of a~signment: in the loop will report that a may be assigned there to the value 2. PRF \nwill therefore conclude that after the label LOP the variable a may have either 1 or 2 as value, aiid \nb can only be 5. This means that PRF c =m eliminate the first cond-expression, but must leave the second \none. However if we simply perform another complete iteration of assignment analysis and partial evaluation \nthe second cond-expression will also be eliminated. The other question how the However even more iterations \nmay not always help, s ince there may be an assignment to a variable which depends on a condition which \nincludes that same variable. Actually there was such a case in this experiment. Simplified it appeared \nas (PROG (A) (12) (SETQ A GREATERP) LOP (AND (NUMBERP A) (SETQ A 1)) . (60 LOP) :) In this case PRF failed \nto eliminate the and-expression, but khe problem was solved by manually giving the help to the analyzer \nprogram that in this case no assignment of a can be performed inside the loop. - Figures. In the example \n(8) it took the REDFUN-2 system about 20 seconds CPU time to to produce the code (9). The REDFUN-2 system \nwas straightforwardly compiled. Some more efficiency could be obtained through block-compilation and \ncompilation of all procedures stored on property lists. As comparison the INTERLISP compiler takes 8 \nseconds CPU time to compile the executor functions (those shown in appendix 1). 5. CONCLUSIONS By our \npartial evaluator and the experiment we have shown that this method is useful in practice. To compile \nexpressions from the interpreter has obviously its merits and is useful in applications when the compilation \nis not performed too often and there is no point in spending resources to build a real compiler. We will \nextend our work to experiment with other interpreters. A greater break-through would be to generate the \ncompiler from the interpreter. In order to achieve this goal there are at least two major questions. \nThe first question is how powerful the partial evaluation algorithm has to be in order to handle itself, \nor if the partial evaluator can be written in such a way that it is possible. If it is not possible one \nway to go ahead is to write another partial evaluator PRF which is simpler but still powerful enough \nto handle interpreters written with some restrictions. The goal is then that ACKNOWLEDGEMENTS optimizations \nperform~~ by conventional compiler can b: incorporated in the generated compiler. Normally such optimizations \nare not included in the interpreter. Thanks to Professor Erik Sandewall for reading this paper and for \ngiving valuable comments and to Jim Goodwin who wrote the interpreter for the iterative statement which \nwere an excellent test case for our system. REFERENCES [1] Teitelman, W. INTERLISP Reference Manual, \nXerox, Palo Alto Research Center, Calif (1975). [2] Futamura, Y. Partial evalution of computer programs: \nAn approach to a compiler-compiler. J. Inst. Electronics and Communication Engineers (1971) . [3] Deutch, \nP. The interactive program verifier. Ph.D. Thesis, Xerox Research Center, Palo Alto, CA (1973). [4] Wegbreit, \nB. Goal-directed program transformation, Third ACM Symposium on Principles of Programming Languagest \nAtlanta, Georgia, (1976). [5] Ershov, A.P. On the essence of compilation, Computing Center, Siberian \nDivisionr USSR Academy of Sciences, Novosibirsk 630090, USSR, (1977). [6] Beckman L., Haraldson, A., \nOskarson, o Sandewall, E. A Partial Evaluator a;~ its Use as a Programming Tool , Artificial Intelligence \nJournal 7, (1976) 319-357. [7] Haraldsson, A. A Program Manipulation System Based On Partial Evaluation, \nPh.D. Thesis, Informatics Laboratory , Linkoeping University, Sweden (1977). PRF(PRF ,1) generates a \nuseful compiler. APPENDIX 1 ( ITENJPDATE) (GO $$LP) $$OUT We will here show the LISP code for (sEGEvAL \nFINALLY :LEFTFINALLY:RIGHT) those functions in the iterative (RETURN (SELECTQMAIN:OP statement package \nthat was partially (JOIN (CAR evaluated by the REDFUN-2 system in the ITER:VALUE)) experiment described \nin section 4. The (COLLEcT code is shown here to give the reader ~n (DREVERSE idea of the complexity \nof code our ITER:VALUE)) system can manage. ITER:VALUE]) [ITERINIT (ITERxcT [LAMBDA NIL [LAMBDA NIL (SETQRANGE:LEFT \n(sEGEvALRANGE:LEFT (PROG (ITERTMP ITER:VALUE) RANGE:RIGHT)) (ITERINIT) [ANE FOR:LEFT $$LP(SEGEVAL EACHTIME:LEFT \nEACHTIME:RIGHT) (SET FoR:LwT (COND (SELECTQ (ITERXT) ((EQRANGE:Op (worn IN)) (T (GO $$OUT)) (CAR RANGE: \nLEFT)) (SKIP (Go $$ITERATE)) (T RANGE:LEFT] NIL ) (SETQTO:LEFT (SEGEVALTO:LEFT TO:RIGHT)) (sETQ ITERTMp \n(SEGEvALMAIN:LEFT (SEGEVALFIRST:LEFT FIRST:RIGHT) MAIN:RIGHT)) (SELECTQMAIN:OP (SELECTQ ((SUM ITERcoUNT) \nMAIN:OP (SETQITER:VALUE o)) (DO NIL) ((ALwAYs NEVER) (COLLECT (sETQ ITER:VALUE (SETQ ITER:VALUE T)) (CONS \nITERTMP ITER:VALUE) NIL]) )) [JOIN (ITERXT ( COND [LAMBDA NIL [(NLISTP ITER:VALUE) (oR [SELECTQBY:TEST \n(SETQ ITER:VALUE ((NEVER DYNAMIC) (CONS ITERTMP (LAST ITERTMP] (* NEVFR Is wHERE To wAs NoT (T (RpLAcD \n(CDR ITER:vALuE) ITERTMP) GIVEN ; (RpLAcD ITER:VALUE DYNAMIC CZCURS ONLY FIRST (LAsT (CDR TIME THROUGH \nAND THEREAFTER BY:TEST IS NUMERIC; (sm (SETQITER:vALUE SEE ITERDBY AND ITERUPDATE) (PLUS ITER:VALUE ITERTMp))) \n[ITERCOUNT (AND ITERTMP ITER:VALUEI NIL) (ADDI ITER:vALuE] (NLISTP (NLISTP RANGE:LEFT)) [ALWAYS (coND \n(GREATERP (GREATERP RANGE:LEFT ((NULL ITERTMP) TO:LEFT)) (LESSP (LESSP RANGE:LEFT TO:LEFT)) [NEVER (CON~:7;$W~:vALuE \nIL) ( COND (ITERTMp (sETQ ITER:VALUE ((NOT (NUMBERPBY:TEST)) NIL ) (ITERROR ITERXT)) (GO $$OUT] ((ZEROP \nBY:TEST) [THEREIS (* THE D~AMIc cAsEs. sEE ITERupDATE-) (SETQITER:VALUE ( COND (ITERTMP ((~k5sp BY:TEsT \no) (SETTN;TER:VALUE (LESSP RANGE:LEFT TO: LEFT)) (T (GREATERP RANGE:LEFT ((EQ RANGE:oP TO:LEFT] (QUOTE \nIN)) (AND wHILE:LEFT (cAR RANGE: LEFT)) (NEQ (EQWHILE:OP (QuOTE wHILE)) (T RANGE: LEFT))) (AND (SEGEvALwHILE:LEFT \n(GO $$OUT1 WHILE:RIGHT) (ITERROR ITERXC~)) T))) $$ITERATE (AND WHEN:LEFT (AND RPTWHILE:LEFT (NEN:OP (QuOTE \nWHEN)) (NECJ (EQRPTwHILE:oP (AND (sEGEvALwHEN:LEFT WHEN:RIGHT) (QUOTE RPTWHILE)) (AND (SEGEVAL RpTWHILE:LEFT \nT)) RPTWHILE:RIGHT) (QUOTE SKIP]) T)) (GO $$OUT) ) (ITERupDATE [LAMBDA NIL (SELECTQ RANGE:OP [IN (sETFOR:LEFT \n(CAR (sETQRANGE:LEFT (ITERUPDATEII [(ON GENERATOR) (SET FoR:LEFT (sETQRANGE:LEFT (ITERUPDATEII rFROM \n(pRoG (TMP) [SET FOR:LEFT (SETQRANGE:LEFT (PLUS RANGE:LEFT (SETQTMP ( ITERUPDATEI] (* BY:TEST=NUMBER: \nTHE DYNAMIC!! CASE (SEE ITERDBY)) (Am (OR (NuMBERPBY:TEsT) (EQBy:TEsT (QUOTE DYNAMIC))) (SETQBY:TESTTMP] \n(ITERROR ITERUPDATE)) (AND RANGE:OLD (SET RANGE:OLD RANGE:LEFT]) (ITERupDATEI [LAMBDA NIL (ANC (EQRANGE:OP \n(QUOTE IN)) (SET FOR:LEFT RANGE:LEFT)) (SEGEVALBy:LEFT By:RIGHT]) (SEGEVAL [LAMBDA (**L* **R*) (SELECTQ \n**R* ((CONSTANT NUMBER) **L*) (FuNcTIoN (AppLy* **L* (EVALFOR:LEFT))) (sEGMAP **L* **R* (FuNcTIoN EVAL]) \n(SEGMAP [LAMBDA (**L **R FN **V) (COND (~~;)**L **R) ((NLkTP **L) (ITERROR SEGMAP)) (T (s,E~AP (CDR **L) \n*%R FN (AppLY* FN (cAR **L]) The last function segmap has here been redefined compared with the original \none in Goodwin s package. Co mpare discussion in section 4 in the report. Let us follow the example \n(FOR I FROM 1 TO 10 DO (PRINT I)) When all the free variables from the parsing step have been bound to \nvalues the following ~-expression was set up and given to the partial evaluator [PROG [(FOR:LEFT (QuoTE \nI)) [FOR:RIGHT (QuoTE (FROM 1 TO 10 DO (PRINT I] (RANGE:OP (QUOTE FROM)) (RANGE:LEFT 1) (RANGE:RIGHT \n(QUOTE NUMBER)) (RANGE:OLD NIL) (BY:LEFT 1) (BY:RIGHT (QUOTE NUMBER)) (BY:TEST (QUOTE GREATERP)) (TO:LEFT \n10) (TO:RIGHT (QUOTE NUMBER)) (BIND:LEFT NIL) (BIND:RIGHT NIL) (MAIN:OP (QUOTE DO)) [MAIN:LEFT (QUOTE \n((PRINT I] (MAIN:RIGHT NIL) (WHILE:OP NIL) (WHILE:LEFT NIL) (WHILE:RIGHT NIL) (RpTWHILE:OP NIL) (RPTWHILE:LEFT \nNIL) (RPTWHILE:RIGHT NIL) (WHEN:OP NIL) (WHEN:LEFT NIL) (WHEN:RIGHT NIL) (FIRST:LEFT NIL) (FIRST:RIGHT \nNIL) (EACHTIME:LEFT NIL) (EACHTIME:RIGHT NIL) (FINALLY:LEFT NIL) (FINALLY:RIGHT NIL) (ITER:BINDINGS (QUOTE \n(I] (RETURN (PROG (I) (RETURN (ITERXCT] All the functions from the iterative statement package shown \nhere are functions which are opened through beta-expansion, i.e. the procedure body replaces the procedure \ncall with appropriate substitutions. After partial evaluation and other optimizations in this code we \nobtain the final code as (PROG (RANGE:LEFT I) (SETQ RANGE:LEFT 1) (SETQ I 1) $$LP (SELECTQ (GREATERP \nRANGE:LEFT 10) (T (GO $$OUT)) NIL) (PRINT 1) (sETQ I (SETQ RANGE:LEFT (PLUS RANGE:LEFT l))) (GO $$LP) \n$$ouT (RETuRN NIL)) APPENDIX 2 The CLISP statement (FOR X IN L JOIN (CDR X) WHEN Some further examples \nfrom the experiment reported in section 4. These (AND (LISTP x) examples will only show the code (EQ \n(CAR X) (QUOTE A)))) produced from the partial evaluation step with REDFUN-2. which concatenates cdr \nof those sublists in L, in which the first element is the atom A, will cause the following code to The \nCLISP statement be produced (FOR I FROM 1TONBY 2SUM I) (PROG (RANGE:LEFT X ITERTMP ITER:VALUE) will \ncause the following code to be (SETQ RANGE:LEFT L) produced (SETQ X (CAR RANGE:LEFT)) $$LP (PROG (RANGE:LEFT \nTO:LEFT I ITERTMP (SELECTQ ITER:VALUE) (OR (NLISTP RANGE:LEFT) (SETQ RANGE:LEFT 1) (AND (NEQ T (SETQ \nI 1) (AND (LISTP X) (SETQ TO:LEFT N) (EQ (CAR X) (SETQ ITER:VALUE O) (QUOTE A)) $$LP (sELEcTQ (GREATERP \nRANGE:LEFT T)) TO:LEFT) (QUOTE SKIP))) (T (GO $$OUT)) (T (GO $$OUT)) NIL) (sKIp (Go $$ITERATE)) (SETQ \nITERTMP I) NIL) (SETQ ITER:VALUE (SETQ ITERTMP (CDR X)) (PLUS ITER:VALUE [coND [(NLISTP ITER:vALuE) ITERTMP)) \n(SETQ ITER:VALUE (SETQ I (SETQ RANGE:LEFT (CONS ITERTMP (PLUS RANGE:LEFT (LAST ITERTMP] 2))) (T (RPLACD \n(CDR ITER:VALUE) (GO $$LP) ITERTMP) $$OUT (RETURN ITER:VALUE)) (RPLACD ITER:VALUE (LAST (CDR ITER:VALUE] \n$$ITERATE The CLISP statement [SETQ x (CAR (SETQ RANGE:LEFT (IN AL COLLECT cAR) (PROGN (SETQ X RANGE:LEFT) \nwhich in LISP corresponds to (CDR X] (GO $$LP) (MAPCAR AL (FUNCTION CAR)) $ $OUT (RETURN (CAR ITER:VALUE] \nwill cause the following code to be produced (PROG (RANGE:LEFT DUMMYIV ITERTMP ITER:VALUE) (SETQ RANGE:LEFT \nAL) (SETQ DUMMYIV (CAR RANGE:LEFT)) $$LP (SELECTQ (NLISTP RANGE:LEFT) (T (GO $$OUT)) NIL) (SETQ I JTIRTMP \n(CAR DUMMYIV)) (SET Q ITER:VALUE (CONS ITERTMP ITER:VALUE)) [SETQ DUMMYIV (CAR (SETQ RANGE:LEFT (PROGN \n(sETQ DUMMYIV RANGE:LEFT) (CDR DUMMYIV] (GO $$LP) $$OUT (RETURN (DREVERSE ITER:VALUE]\n\t\t\t", "proc_id": "512760", "abstract": "A partial evaluation program for LISP is described, and an application where it has been used. The partial evaluator performs a number of other, related operations such as opening of functions and certain optimizations on programs. The application is based on the fact that we can generate from an interpreter and a partial evaluator the same object code as a corresponding compiler should do. The paper will first formally describe the relationship between an interpreter and a compiler through partial evaluation. The partial evaluator system is then briefly described and finally an experiment is shown where an interpreter for the iterative statement in INTERLISP is partially evaluated.", "authors": [{"name": "Anders Haraldsson", "author_profile_id": "81100272539", "affiliation": "Linkoeping University, Sweden", "person_id": "P328987", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512781", "year": "1978", "article_id": "512781", "conference": "POPL", "title": "A partial evaluator, and its use for compiling iterative statements in LISP", "url": "http://dl.acm.org/citation.cfm?id=512781"}