{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Sym~sium on Principles of Programming \nLanguages A Metalanguage for Interactive Prcof in ICE * M. Gordon, R. Milner University of Fdinburgh \n L. Morris Syracuse University M. Newey Australian National University C. Wadsworth University of Edinburgh \nIntroduction LCF (Icqic for Caqmtable Functions) is a prcof generating system mnsisting of an inter\u00adactive \nprograming language MG (MetaLmguage) for mnducting prcofs in PPA (Polynmrphic Predicate A-calculus) , \na deductive calculus suitable for the formalisation of reasoning almut recursively defined functions, \nin particular about the syntax, semantics and iq?lementations of many prqrcmming languages. PPI is an \nenrichment (in respect of type structure and expressive pcwer) of an extended a-calculus due to Dana \nScott and is fully discussed elsewhere [ 22 I . The puxposes of this paper are (a) to illustrate the \nfeatures of ML which me it of general interest in language design quite independently of its use for \nmachine assistd formal pxcof, (b) to illustrate ML applied to PPA, in encoding interesting prcof -finding-and\u00adperfonning \nprocedures, and (c) to convey a methodology for controlled semi\u00adautomatic proof.  We avoid formal descrj \nption; we hope that our qles and discussion will achieve these purposes mme clearly. A qlete description \nof ML, and its use with PPA, exists as a techriical reprt [91. The in@enemtation (using LISP on a DEC \n10 .\u00adW his work was supprted by the Science I@search Council of Great Britain under grant n\u00adB/RG/48175. \ncqmting system) of ML and PPI began over three years ago at Edinburgh; for abut two years the system \nhas keen usable, and its development is now virtually ccmplete. Recently it has been used in various \nstudies concerning formal semantics: theorems about data structures, recursion remval, direct versus \ncontinuation semantics, and Other topics. The need for and design of ML is based on experience with an \nearlier system at Stanford [17, 181 . In that system, beyond the ability to direct it to execute a basic \ninference (e.g. beta conversion, or transitivity of equivalence) , the user could (a) invoke .s@lif ication \nwith respect to a set of equivalences specified by him, (b) adopt a goal-directed pr~f style, gener\u00adating \nsubgoals by built-in tactics based qn the inference rules and simplification, and (c) use theorems previously \nproved.  These facilities were enough to enable several non-trivial case studies to be tackled [1,23,24,34] \nbut further use of the systein hecam increasingly limited by the fixed, and rather primitive, nature \nof its repertoire of ccmnands (rather like using an interactive assenbly language -and one without a \nprow stirou~e feature at mat: -in whim one is working all the t-at top-level) . Prcnfs oft.em contained \nmany instances of a few patterns of inference which one would like to express as derived inference rules \nor -in the goal-directed style -as derived tactics or strategies. Our present point of view is that \nneither a straightforward prcof -checker ( lalmrious and re@t\u00aditive to use) nor an autcmatic theorem-prover \n (inefficient because of general search) is satis\u00adfactory. What is required is a framswork in which a \nuser can both design his own partial prmf strategies (where he can find them) and execute single steps \nof proof (where he needs to) . We believe also that, although formal proofs are @?\u00adortant and should \nbe retrievable, it is pragmatic\u00ad ally more convincing to achieve clear expression of p~f strategy; the \nlatter entails that the way in which the strategy is built from sub-stratqies should be evident in its \nexpressicm. In other words, we re not so concerned with checking or generating prcofs as with per forming \nprocf s . RnJs, we don t normally store or display proofs but only the results of them -i.e. theorems. \nThese form an abstract type on which the only allowed operations are the inference rules of PPI ; this \nensures that a well-typed pnqcam carmot perform faulty proofs (it may not prove the theorem expected \nbut the result ~ be a theorem!) . If extra security or formal prcof -checking is desired, full proofs \nare easily generated -only minor changes in the implementation of the abstract t~ for theorems wmld be \nrequired. The principal aims then in designing ML were to make it impossible to prove non-theorems yet \neasy to prcgram strategies for performing pnmfs. A strategy -or recipe for proof -cm.dd be scane\u00adthing \nlike induction on f and g , f ollad by assuning antecedents and doing case analysis, all interleaved \nwith sinplif ication . This is inprecise -analysis of what cases? -what kind of induction, etc, etc. \n-but these in turn may well be given by further recipes, still in the sam style. The point is that such \nstrategies appear to be built frcm sinpler ones (which we call tactics rather than strategies) by a number \nof general operations in fairly regular ways; we call these operations tacticals by analcgy w ith functional. \nFor progr arming tactics and tacticals, and mre generally for manipulation of PP1 in f ind.ing prcofs, \nthe following ingredients in ML were soon found to be expedkmt (almost necessary) : the ability to handle \nhigher order functions, a rigorous but flexible type structure, a mechanism for gen\u00aderating and trapping \nfailures, and an abstract synta~ic rePres-tation of the object language PPa . Acknowledgments We are \nindebted to Dana Scmtt for providing a large part of the theoretical basis for oux vmrk: to John McCarthy \nfor encmrcaging the forerunner of this project at Stanford: to Richard Weyhrauch who contributed greatly \nto that project: to Tony Hoare and Jexry Schwarz for help with the notion of abstract -s in ML : to Avra \nCohn for help in the final design stages through her experiments: to Rod Burstall and many colleagues \nin ~inburgh for ilhnnina ting discussions. Outline of ML. ML is a higher-crder functional programing \nlanguage in the tradition of ISWIM [15], PAL [8], POP2 [6] and @DANKEN [26 1, but differs princip\u00adally \nin its handling of failure and, more so, of typ2s . It is an expression-based language, though expressions \nmay have side-effects because of the presence of assignment (the expression X: =e has as value the value \nof e , and also gives x this value) . An @mrtant expression construct is let x = e in e , which binds \nx to the value of e throughout e ; alternative forms of declaration are let f (x,y,. ..) = e for def \nirdng functions, letrec f (x,y,.. . ) = e for defining functions recursively, letref x = e for declaring \nand initializing assignable variables, and generalizations of these forms for s~taneous declarations. \nAnother imprtant expression construct is Ie ? evtp (read e or else e ), whose value is the value of e \nunless e generates a failure, in which case it is the value of e . The systen generates certain failures \nautcnnatically, and the user may generate his own with the expression fail , or the expression failwith \ne where the value of e is a token which identifies the kind of failure; a generalization of the form \ne ? e can be used to trap only certain failure tokens (kinds of failure) . The type token is one of \nML s basic types; tokens are just synbol strings. In our current application of ML, the use of failure \nas a dynamic escqe and escape-trapping mechanism facil\u00aditates a natural programing style for caqosing \ntactics and strategies which are usually inapplic\u00adable to certain goals. AS hinted above, if d is a declamation \nand: e an expression, then d in e is an expression. In interactive prcgramning (which is how prcofs are \nconducted) , one evaluates a mixed sequence of declarations and expressions, separated by ;; . ML is \na static binding language, like ISWIM, PAL and GEDWWEN (but unlike LISP and FOP2) ; a free variable z \nin the declaration let f(x) = . .. refers to the textually enclosing declaration of z , not to any subsequat \ndeclaration. An example which illustrates most of the features of MT is a generalised scalar product \n(sum the prcducts of two vectors) which is param\u00adeterised on its prcduct and sunnnation functions and \non a zero (for null vectors) . Two ways -the first recursive and the second iterative -of writing this \nin ML, with vectors represented as lists and failure for vectors of unequal length, are as follows: letrec \nscalarprod ($*, $+, zero) (.U,~2) = (1,2) ( let xl. il = L1 and x2. L2 = ~2 (.3) in (x1*x2) +5Cakqwcd($*, \n$+rzero) (!1 ,X2 ) ); (4) (if. null,(kl) &#38; null (12) then zero else. fail) let itscalaqxod ($*, \n$+, zero) (U, i2) = (1) letref ace, 11, i2 = zero, 11, P2 in ( Q ace, 11, Q2 := (5) ( (~*X2)+acc, ilr, \n~2J where x1.%1 = !/1 and X2. !?,2 = 12) )? (if null(!l) &#38; null(i2) thenacc else fail) Notes: (1) \n letrec f(x,y, z)(urv) = --- is equivalent to letrec f = l(x,y, z).l(u,v). --- . (Similarly, let . ..). \nThat is, scala.r\u00adprod and itscalarprod are defined here as (partially) curried functions, as is the style \nin functional progrann.ing. The separation of argments into two groups allows scalarprcxi to be partially \napplied to three argummts to obtain particular scalar prcduct functions; it also suggests a more efficient \nrecursive definition in which we replace letrec scalarprcx3($*, $+, zero) (kl,12) = ---scalaqrod ($*, \n$+, zero) (11 , ~2 )-\u00ad by a form which recurses on only &#38; arguments, nawly let scalarprcd($*., $+, \nzero) = scalp whererec scalp (!l, t2) = scalp (n ,12 ) --\u00ad (2) Prefixing $ to a token enables its use \nas a binaq infix without the $. (3) Infixed . is the cons function. Use on the left of a declaration, \nas here, binds xl and kl to the head and tail, respectively, of !1, with failure when U is null. (4) \nThe failure trappd by ? here is that of the declaration when one of R1, L2 is null. (5) q e repeats \ne until failure.  The functions scalaxprod and itscalarprcd make s-e on a wide variety of objects. Applications \nof either are well-typed provided their arguments have types which are instances of $* : (clxB)+y $+ \n: (yx6)+ 6 Zero:a where a,~, y,c$ are t ype variables, and then the result is a function which has the \ncorresponding instance of (a list x 6 list)+ 6 as its type. We say that the type ((aX&#38;Y)X(yX6-M)X6) \n+ (a list x f3 list + 6) is generic for scalarprod (or itscalarprcd); this means that these functions \nmay be used at any type which is a substitution instance of the generic type, in which a,$ , y,d are \ntype variables. Thus, since $*,$+ : ~ x ~+ ~ are arithmetic functions predeclared in MG, and using the \nML notation Eel; . . . ;enl for lists, we have scakrprcd($*,$+,O) ([1;2;31, [4;5;61) = 1x4 + 2x5 + 3x6 \n using Scahrprcd at the instance 0.= B-~=6= tit Of its generic t=. TO define a function which, given \ntwo vectors [bl; . . ..bnl , [cl; ...; cm] of truth values, will count the number of times that Wzh bi \nand ci are true, we may define let botlltinecount = scalarprcd (bothtrue, $+, O) where bothtrue (bl ,b2) \n= if bl &#38; b2 then 1 else O ~.~.~1 and y=6= int. We may even define a function of type a list x (a \nlist) list + a list such that using scalarprod at its t~ instance . [xl; . . ..xnl. [lisl; . . . lisn]w(xl.lisl) \n@. ..@ (m. lisn) using the predeclared amend function $(? ; the definition is let mapconsappend = scalarprod \n($. ,$@,nil) using scalarprod at its type instance B=y=d=a =. Notice then that lxk.h scalarprd and mapconsappmd \npossess a type which contains type variables; they are plynn rphic functions. The polynmrphism of MG \nshould not be confused with the plyrmrphism present in the object language PPl ; we will allude briefly \nto the latter in a later section. such plyllm rphim with respect to program types is possible, to a greater \nor lesser extent, in several languages (e.g. PASQUAL [301) which allow procedures to have explicit type \nparameters. ML relies instead on a type-checker which not only checks that plynmrphic functions are used \nconsist\u00adently at instances of their generic type but can, in nearly all practical cases, infer the types \nof all variables without these being supplied explicitly (e.g. it will infer the type giva above for \nscalarprcd and itscalarprcd). Thus we cane close to the discipline which a gccd program\u00admer will impose \nupn himself in using a typeless language such as LISP. It is remarkably conven\u00adient in interactive prcgr \namring to be relieved of the need to specify types, with assurance that badly-typed phrases will be caught, \nre~rted, and not evaluated. Of course, for off-line program\u00adming it is oftw advisable to specify the \ntypes in declarations -ticluding the types of formal param\u00adeters, and we are aware that many prefer to \nadopt such a discipline for intelligibility and for docmnentation purpses. TO this end, ML always allcws \nthe user to speci~ his types explicitly. If he cares to write letrec scalarprcd ($*: (.xf3 .+ y), $+: \n(yxa + 6), 2=0: 6) (U: a=, !,2: ~list) : 6= .... he can do so, and the typechecker will check these types \nfor him. It tuxns out that, in the presence of @ymorphism, essentially the same typechecking algorit.lm \nis necessary even if type specification is made compulsory (unless indeed the type of every expression \nwere required, which would be intoler\u00adable) . The typechecking method may be illustrated by a sinple \nexanple. Consider the following function for mapping a function over a list: letrec map(frlis) = if null(lis) \nthen nil else f(hd(lis)). map(f,tl(lis); The generic type of map should be (Y+8) x y list + 8 list. \nHow may we infer this type frcm the bare declaration? First, the generic types of the identifiers occurring \nfree in the declaration are null : a list + bool . nil :alist hd :ctlist*a tl :alist +alist . $. :axctlist+ \n. alist and we require that every occurrence of such an identifier is given, as type, a substitution \ninstance of its generic type (different occurren~s may be assigned different type instances) . Secmnd, \nevery occurrence of a formal parameter must be givem the same type, and every occurrence (in its declaration) \nof a recursively defined iden\u00adtifier must be given the same type. Third, if we denote by Uid the type \nto be given to each iden\u00adtifier in the declaration, then besides the above\u00ad msntioned constraints on \nondl etc, the follcwing equations must hold for some types T1JT2J. . . : T+ T map = f x lis + 1 f 24 \n+ -1 X-r+ r null = lis map = f 35 T xT+T hd = lis + 2 $. 4 5 6 = Glis + -C3 tl 1 = nil = 6 Each of \nthese equations except the last arises fmn sane sub-expression which is a function application; the last \narises because a conditional expression is given the sane type as its two arm, and because the definiens \nand definiendm of a declaration are given the same type. NON if we chcose distinct type variables ~ l...t~ \nand set u =allist+~, 1 5 null = a2 list , etc , the equations may be solved nil for the variables Ul,...a5, \nT1,...,T6 and using Robinsons unification algor\u00ad map f lis ithm [271 . It turns out, as the reader \nmay like to heck, that for sane distinct pair of variables yr8 we obtain G =(y+&#38;)xylist+81ist . map \nas expected. This then is the generic type of map, which may be instantiated (differently) for each later \noccurrence of the identifier. T MS exanple does not illustrate all the typing constraints. There are \nfurther rules concerning the instantiation of generic types of variables declared within a function My \n(for example, the type of the variable xl in the declaration of scalarprod is fully determined by the \ntype of the formal parameter .L1, and the rules will demand in this case that xl is given the same type \nat each occurrence), and con\u00adcerning the types of variables declared by letref (in particular, like formal \nparameters, they must be given the same type at each occurrence). For the ccnplete algorithm, and a prcof \nof its smantic correctness for a siqler language, see [211 ; the algorithn is in fact rather straight\u00adforward. \nML also includes a facility for defining abstract types, including simultaneous and\\or recursive and/or \nparmnetric ones. In ML these are not really abstract in the sense of the algebraic abstract types of, \ne.g., Guttag [101 or Zilles [361 but rather are analogous to SIMUIA classes [71, CLU clusters [16], and \nALPHARD forms [35]. As the latter are by now well-known, it will be enough to describe briefly our syntax \nfor abstract type declarations and give a simple example. The declaration form is - ty-s id = ty m...=d \ntY==9- id = +=Y with ... where the identifiers <id> are the new (parametri\u00adzed) t~s being declared, each \n<tyargs> is a sequence (possibly empty) of type variables -the formal parameters -and each <ty> is a \ntype express\u00adion. The Part with . .. has the syntax of a normal declaration (but with let replaced by \nwith) , and defines the operations or other objects availa\u00adble at the new types; the essence of ~ abstraction \nis that one may get at the represent\u00adation of the new types only in the with-part, and this representation \nis provided by two halves of the iscmmrphism (denotedby absid and repid for each type identifier id ) \nbetween each type and its representation. For (mutually) recursive types one must use absrectype in place \nof abstype. We give, as an exanq?le, the redefinition of the ML type operator list for lists; note that \nthe iscmmrphism functions are plynmrphic -they are abslist : (. +(axalist))+a~ replist : a~+(. +(ax a \nlist) ) where the basic type . is that with just one elemsnt denotsd by the expression () , and + between \n-s is disjoint smn. The declaration is: absrectype a list = . + (a x a list) with nil = abslist(tilo) \nand$.(x,f,) =abslist(inr(x,i) and null(l) = isl(replist(i)) . andhd(f,) = fst(outr(replist(i )) and \ntl(~) = snd(outr(replist(i))) The polynn~hic functions inl and m, outl ~d outr, and isl and isr are left \nand right injections, projections (with failure for arguments in wrong sumnands) and predicates for disjoint \nsm types. (~: we have underlined types and reserved words in this paper, for clarity, but our implementation \nrequires no underlining; we have ncw abandoned it for newly declared types) . Functional types are allowed \nin abstract type declarations, and this yields sane interesting possibilities. A simple exan@e is streams \n-a notion of infinite implicit lists due to ~. Here is a definition which provides two stream operations; \none for splitting a strean into its first merber and reminder, and one for building a stream frcm a function \nof the natmal numbers: absrectype a stream = . + (a x a stream) with next(s : a strean) = repstrem(s) \n() andStreamof = Str : (@ + a) + a stream whererec str (f ) = absstream(~ () . (f(1) ,str(lx. f(x+l) \n)_))  w an aside, we can shcw that the recursiveness of types also gives us the pcwer of non.nal recursion, \nso that in the presence of absrect ype, the letrec construct is theoretically redundant! In fact, a fixed-point \nfunction FIX : (( B+y)+(D+y))+(B+y) can be defined so that let f = FIX(.lf .e) is exact ly equivalent \nto letiec f = e ; the reader may like to puzzle out how the f olluwing does the trick: absrectype cl \nfixty=afixty+a with FIX (f) = F (absf ixty F) where F y = f(lx. repfixty(y) (Y) (x)) PPX in ML PPA is \ndiscussed in ML via pre-def ined abstract types, one for each of its principal syntactic classes. ~s \n~thod could be adopted for the discussion of any syntactic system within ~, but we have also built in \nthe special ability to discuss PPA h terms of a concrete representation of its syntax . This is a necessary \nconvenience; to provide concrete syntax for other syntactic systems the user would need to write, in \n~, a parser and an unpamer to map f rcm concrete to abstract syntax and vice-versa. The fomulae of PPl \nare those of a f irst-ord~ predicate calculus built by conjunction, implication and universal quantification \nfrcxn atomic ones; atcanic formulae are equivalences and inequivalences (i.e. partial ordering~) betwe= \nterms of a typed A-calculus with a f ixed-pdnt operator, a conditional operator and other constants. \nMany of these constants -including the two mentioned \u00adare plymxphic; as with ML the plynmrphism involves \nthe use of type variables, and t~ instantiation is one of the inference rules of PPA . Thus PPI is repres=ted \nin ML by the three abstract types form, term and ~ (objects of type ~ are syntactic -they are PPI type \nexpress\u00adions) ; primitive operations provided at these (ML) types are constructors and destructors. Exa@es \nof instructors are: rfkvar : token X ~ + term (a variable consists of a token with a type) mkcomb : term \nxterm+texnl . (a combination, or function application) mkinequiv : term x teml + form . (tobuild an atcmic \nformula) mkquant : tem x fom + form . (the term must be a variable) and to each constructor corresponds \na destructor (destvar, destd etc) of inverse functional type. Destructors fail if their argument is not \na tenm or form of the right sort -e.g. destvar (ink@ (..)) will fail. Concrete syntax is provided via \nquotation . ..3 ; this syntax is what one would expect, and allows t~s to be mentioned explicitly, although \nthe system will often deduce types using a methcd sinilax to that in ML. Here then are two equivalent \nML expressions of type form , assuming that the user has introduced integer as a PPA type (see the later \nsection on Thearies) : %x: integer. x ~ x let x = mkvar ( X ,mkconsttyp integer )  in mkquant (x,nkinequiv \n(x,x) ) . ~er, a device which we call antiquotation L . . . j allows ~ expressions (of appropriate ~ \ntype!) to amu Witi quotations, so that the following is also equivalent to the above: let x = X:integer7 \nin V~xJ. ~n_kinequiv(x,x)J1 Now a sequmt of PPA is an object (rrw) of ~ form list x form. PPA is a sequent \ncalculus, so a PPl theorem is a sequmt which follows frcm the axians by the inference rules. A theorem \nis represented as on output; theorems of l!r + wnf ccmxse may not be input, but only deduced, and for \nthis puqose the axicans and inference rules are provided as primitive objects at the abstract type thin. \nWe give part of the definition of this type; the types of the inference rules mentioned are ASSUME:form \n+ ~, GEN:tenn+(thm+thn) , . TRANS:th XtbI+ t.@, BETACDW:term+thm : . m thm = form list x form with \nASSUME w = absthm( [w] ,w) (Infer w +-w) and ~Xth=  let r,w = repthm th in (Frclnr l-w if 1 isvar x \n~ x E freevaxs (r) infer r I-VX. w . then f ailwith GEN when X is not else absthm (r ,mkquant (x,w) ) \nfree in r) and TRANS(thl, th2) = . . . (transitivity of qaivalence and inequival\u00adence) and BETACCXfV \nt=... ( 6 reduction) and .... .... and destthn = repthm Notice that repthm is provided to the user \n(under the nane destthm) to allw him to analyse his theorems syntactically, but he is deprived of alEthm \n-and thus assured that all objects of ~ tkm are indeed theorems, since he can only make (prove! ) them \nwith the inference rules. The PPl calculus was discussed in detail in [221; our present iqlenxmtation \nprovides essentially that calculus, but for convenience -and sane efficiency \u00admany of the axicms are \npresented tistead as infer\u00adence rules, of ihich there are about thirty (mre than strictly necessary, \nagain for ocnvenience) . Goals tactics and tacticals As a simple example to illustrate our method\u00adology, \nconsider an obvious fact abut conditionals (for T => XIY read if T then X else Y ) , namsly I-VTl T2 \nX Y Z W.(Tl => (T2 => XIY) I(T2 => Z/W)~ T2 => (Tl => X/Z)] (Tl => YIW)) The natural way one would prove \nthis informally is: strip off tie quantifiers ( Consider any T1, T2,. .,W ) , then do case analysis on \nany truth-valued term in sight -and do any sirtrplif ications that are possible. So su~ficially, as a \ntactic for this (and many other similar goals) we muld like to write (REPFAT GENTAC) THEN REPFAT(ANYCASESTAC \nTFIHi SIMF IW) . AS a first approximation, a tactic should take as argument a goal and produce as result \na list of subgoals . We shall here assume that a goal is a sequent, that is gO@ = form list x form . \nthough we in fact use a slight ramification of this type. The idea is that, by repeated sukqoaling (i. \ne. tactic application) we shall reach subgoals which may be achieved by theorems, until no sub\u00adgoals \nare left; a theorem r I-W is said to achieve the goal (r ,w) if (up to a-conversion) w =w and r Sr -the \nformulae of r in the goal are to be thought of as assumptions, sane or all of which may be used in proving \nw. But now we can see a deficiency in our first a~roximation to a tactic. Suppse that a tactic T, applied \nto goal g , has generated the subgoal list [gl; . . . ;gn 1 and that scanehow theorems thi achieving \ngi (1 s i s n) have been found. who is to deduce frcan [thl; . . ..thnl a theorem th achieving g ? Our \nanswer is that it is the job of T to provide a way of performing this deduction; to this end we define \n= thmlist+thm QZQ . tactic = go&#38; + (goal list X prcef) and we call the proaf oaqmnent of a tactic \ns result a validation. We!! a ccmpsite tactic has scxnehow generated an eqty goal list, the valid\u00ad ations \nof the ccqonmts can be ccanpsed to yield a theorem, and this cq?osite validation (a function) can be \ngenerated autcanatically as part of the business of -sing tactics. Hcxvever, not all tactics will be \nvery useful. lie shall call the useful ones valid (related but not identical with lqicians use of the \nword) : T is a valid tactic if, whenever T(g) = ([gI; . . .;gnl,p) and whenever thi achieves 9i (1 s \ni s n) , then P[thl; . . ..thnl evaluates successfully to a th~rem which achieves g . In particular, \nwhen n = O -i.e. T reduces g to an qty subgoal list -then p[ 1 achieves g and we say that T solves g \n(e.g. the s~lification tactic manages this when tie gcal simplifies to an obvious tautology) . TO illustrate, \nhere is a tactic for quantifier stripping (yielding one s~oal) which is inverse to the basic inference \nrule W, where we write in sane types explicitly as an aid to the reader: let GENTAC ( (r,w): go@ = let \nx,wl = destquant w ? failwith G3fTAC  in  let x = variant (x, freevars (w. r ) )  -u 1 . [ (r, substinform(x \n,x)w1) ]: goal ~ , (~ X ohd) :s where o is ftmction ccmpsition, and variant (x, vars) primes x, if necessary, \nto obtain a variable not in the list vars. The call of variant in GENT!AC is needed to ensure that it \nis a valid tactic, in this case to prevent possible variable clashes causing the validation function \nto fail unexpectedly (when applied to a singleton theorem list [thl where th achieves the one subgoal \nproduced by GENTAC) . Note that at worst an invalid tactic can fail or prove the wrong theorem; it can \nnever produce a false theorem ! Other elementary tactics are also easily defined, e.g. for case analysis \non a truth-valued term (prcducing three subgoals -the true, false and undefined cases) , and for ccxrputation \ninduction (prcaucing two subgoals the induction basis and the induction step) . We are mainly interested \nin valid tactics, though one may demmd eva mre of a tactic. We say that a (valid) tactic is strongly \nvalid if, whenever the argmnent goal is achievable (by sane theorem) so is each of the gaerated subgoals. \nOne may not always be able to use strongly valid tactics. Consider for exa@e the heuristic tac\u00adtic for \nproving Vn. f (n) < g(n) by finding SClne function h for which W. f (n) < h(n) s g(n); in particular, \nwe find that Vh. n <2n+ lis true (and achievable ! ) over the non-negative integers, but Vn. n<2n<2n+l \nis false (not achievable) . Nbre relevant is that various induction rules, Ussd in reverse, yield tactics \nwhich are not strongly valid. It is good practice to use strongly valid tactics when pxssible, and always \nto use valid tactics. Tacticals are fmctions on tactics, building simple tactics into ccnpsite ones. \nWee obvious exanples are: binary tacticals THEN (apply a secnnd tactic to all subgoals produced by a \nfirst) and ORELSE (try one tactic, or if it fails try another) , and a unary one REPEAT (iterate a tactic \nuntil faihrce) . Defining these, and many others, in PIG is a straightforward exercise in functional \nprcgramnin g with lists. 143reover, it is easy to shcw that THEN, ORELSE and REPEAT preserve the validity \n-even strong validity -of tactics. (It is worth noting that this tactics-and tacticals style could be \nadopted in general for problem solving; all that is involved is a type goal , a type for proposed solutions \n-which might be called shot -and an achievement relation between shots and goals . ) Isolating useful \ntactics and tacticals, and enccding them in ML, is a sbj ect of ongoing study in the various applications \nto do with formal senmntics which we mentioned in the introduction. Theories In our discussion of PP1 \nwe did not suggest the variety of its application; in fact, just as first-order predicate calculus (or \nany pure CACUIUS) may be extended to an applied calculus by the introduction of non-lcgical constants \nand non\u00adlogical axicms, so may PPA be extended. An imprt\u00adant part of this extension is the introduction \nof new types (the only non-trivial primitive type available is that of txuth-values) . New types may \nbe either introduced independently or defined \u00adperhaps recursively -in terms of existing typss . A set \nof types, tcgetier with sane new constants and axicms, is called a tkory, and all work with ICF consists \nin setting up theories, extending them or joining them to form larger theories, or (nm.t inportant) adding \nnew useful theomne to the list of those proved in an existing theory. Theories are preserved permanently \non files, to allow incremen tal working; for each theay T there is a fixed file T. THY with the types, \nccmstants and axicxns, and a 9row@l file T. FCC of useful theorems (facts). Suppse for example one wishes \nto prove the correctness of a compiling algoritlm f ran AI.lX)L to sane target language L . One will \ndevelop first a theory of AKDL and a theory of L (we give the theories these names) , then join them \nand extend the result by adding a constant ALoanPile of type ALprcg + Lprcg say, and an axicnn defining \nthis ccmpiling function. The resulting theory might be called ALGQLCDMPILE ; its parent theories are \nALCX3L and L , and one of its theor~ will assert the cxnnpiler s correctness. But AIGOL itself will be \na ccmpsite theory. One of its parent theories will be AISYN -the theory of ALCDL syntax; the types in \nthis th~ry will be such as ALprcg, ALblock, ALstatmt, ALexpn etc, the constants will be the abstract \nsyntactic operations such as mkassignment : ALVar ~ ALexpn + ALstatmt, and the axiars will characterise \nthese operations. Further mnstants and axicms will be concerned with auxiliary syntactic operations -e.g. \na predicate for determ\u00adining whether an identifier occurs free (i.e. non\u00adlocal) in a block -arxl the \ntheorems of ALSYN will be about these purely syntactic matters. ALSYN may have a parent IiVT. -the theory \nof integers \u00adif for example one of the syntactic operations counts the nunber of free occurrences of \nan identifiers in a block. Another parent theory of ALGOL will be AiSEM; this is the theory of d canains \nused to specify the semantics of AIGOL, and may in turn have parent theories INT, REAL, etc cmrrespnding \nto various data types. ALGOL itself will be the join of ALSYN and ALSEM extended by the definition of \nthe semantic function -call it ADneaning -whose type will be perhaps AJLprcg + (ALstate + ALstate) where \nALstate is the type of AI.LX3L machine states introduced in ALSm. Thmmns of ALGDL will have nothing to \ndo with amnpilation; for exanple, there are many interesting results to be proved concerning meantig-preserving \ntransformations of programs. So far, we have outlined an ancestry g raph for the theory ALGOLCCMPILE; \nbearing in mind that the basic thecmy PPA is an ancestor of every theory, the graph lcoks like this AIC33LCOMPILE \nAL&#38;42L ALSYN Iwr and of course the subgraph for L (in particular) has not been discussed. We refer \nto [9] for the details of ICF theories; here we will ~nclh by remarkimg that it appears @mssible to exploit \nthe full power of an interactive proof system with\u00adout sane discipltied f rmework, such as theories provide, \nwithin which to work incranentally. Relations with other systems There are several dimensions along which \nLCF can be crqared with other proof systems; Checking vs. Proving At one extreme a system just accepts \nccmplete proofs and then simply checks their correctness; a sophisticated example of this is the AU IOMATH \nsystem of de Bruijn et al [ 5 I . At the other extrem goals are sukmitted and an attenpt is rnac3.s to \naut.anatically achieve them; exzqles are early resolution theorem proving [27 ] and the wwk on wchanising \nstructural induction [2,31 . Between these is a continuun. Gne can reduce the tedium of ustig a pure \nchecker by increasing the gap between proof steps (these gaps being bridged by e.g. a simple theorem \nprover) ; for example the Stanford LCF system [18] did scane simplifications autcunatically but otherwise \nthe proof had to be provided by the user. Conversely a pure theorem prover can be made rore flexible \nby allcwing a user to provide information (perhaps interactively) theories. Note however that PPi itself \nis orientedto guide the search for a prmf (e.g. this is one Our aim tcwm.rds reasming about universes \nof recursivelyof the aims of the GOLUX project [11]) . defined objects of various t~s (viz. -ins ofis \nto construct a system which can be used at any Scotts TFEOry of Computation [281) and so reasoningpoint \non this continuum -for S-problem areas about other obj etis may be indirect. The Stanfordthere already \nexists useful prcof strategies (e.g. ML system of Wehyrauch [331 is based on a mreAubin [21, Eoyer &#38; \nMoore [3 I for induction on Lists, Brown [41 for integer arithmetic) and we would like general lcgic, \nand it r amains to be established to be able to cede them up straightforwardly. In whether this extra \ngenerality is needed (e.g. for other less explored areas we want to experiment with reasoning about applications \nof programs to the manual prcofs to isolate ccnmmn patterns of inf ex- real world ) ; there is a delicate \ntrade off ence. Once these are fomd they can be prqranmed between g&#38;nerality and specialization -PPA \nis as ML tactics. just general enough to handle reasoning aknut the syntax, s~tics and implementations \nof programs,Security but is fairly specialized to these. w systems based on general problem solving languages \nlike MICFOPLANNER [291 or QLISP [251 there is a danger that in Prforming a prcof wrong inferences may \nbe done. This danger is greatest for systems which are not based on any explicit [ 11 Aiello, L. , Aiello, \nM. &#38; Wehyrauchr R. ,logic (e.g. [3,321) ; for these it is not even The semantics of PASCAL in ILIF, \nAI Memo 221always clear what the valid inferences are. Hcw-Cmputer Science Dept., Stanford, 1974. ever \neven when an explicit logic is used (e.g. Von Henke and Luckhan [121 which is based on Hoare s [ 2] Aubin, \nR., Mechanizing structural induction, inference system [14 1) there may still be a risk Ph.D. thesis, \nUniversity of Fdinburgh, 1976. that invalid manipulations of theorems might [3] Boyer, R.S. &#38; More, \nJ. S., Proving theorems accidently occu -this is espcially so if about LISP function, JACM 22,1 (Jan. \n1975) , inexperienced users are allowed to prcgram strategies. 129-144. In KF we give the user the freedcm \nto write his own [41 Bm, F. M., A deductive System for Elementarytactics (in ML) but the type-checker \nensures that Arithn@cic. AISB Sumner Conference, these cannot perfom faulty proofs -at wrst a Edinburgh, \n1976. tactic can lead to an unwanted theorem (for exanple which does not achieve the desired goal) . \n[53 de Bruijn, N. G., AU IWATH, a language for math-tics, T. H.-Report 68-WSK-05 , Ept . ~ of Mathenntics, \nTechnological University, A nuker of prcgram-proving systems are tailored Eindhoven, Netherlands 1968. \nto particular programing languages thereby enabling [6] Burstall, R.M. &#38; Pop@estone, R., POP2 refer\u00adefficient \nspecial puxpse heuristics to be used ence manual, in Machine Intelligence 2, eds. (e.g. [12,311). Such \nsystems are gmd for reason-E. Dale &#38; D. Michie, American Elsevier,ing about algorithms encoded in \ntheir particular New York, 1968, 205-246. language but cannot perform proofs of theorems comnec+ing diffwer+ \nlanguages e.g. proofs of [72 oanl, O.-J. et al, The SIMULA 67 Ccrmnon base . corcrpil=s. We have tried \nto get the best of both language, Norwegian Ccrq@ing Centre, Oslo, vmrlds -spscial puqnse heuristics \nand generality 1968. -by specializing our system not to any programing [83 EvallS, A., PAL: a language \ndesigned for langua ge (e.g. -L, PASCAL etc. ) but to the teaching prcgrartnning linguistics, Proc. ACM \ndeductive system PPa , and then pruviding facilities 23rd Nat. Conf. , 1968, Brandin Systems Press, to \nenable various particular languages to be axicxn-Princeton, N. J., 395-403. atized as PPA theories; efficient \nspecial puqose tactics can then be prcgrann@i in ML for these [91 Ckmdon, M., Milner, R. &#38; Wadsworth, \nC. Edinburgh B, Department of Caqmter Science Internal Reprt CSR-11-77, University of Fdinburgh, 1977. \n [ 111 Hayes, P.J., The language G3LUX. University of Essex, 1974. [ 121 von Henke, F.N.&#38; Luckhan, \nD.C., Amethcdobgy for verifying prcqramsr Proceedings of the International Conference on Reliable Soft\u00adware, \nIOs Angeles, California 1975. [ 131 Hewitt, C., PLANNER: a language for manipul\u00adating ndels and proving \ntheorems in a rolxt, AI i%mo 168, Project MAC, M.I.T., 1970. [ 141 Hoare, C.A.R., An Axiomatic Basis \nfor Ccmputer Programing, CACM VO1.12, No.1O, 1969. 151 Landin, P.J., The next 7CX3 programing languages, \nCcmn. ACM9,3 (Ech 1966), 157-166. 161 Liskov, B.H. &#38; Zilles, S., Programing with abstract data types, \nProc. of a Sympsium on Very High-Level Languages, SIGPIAN Notices 9,4 (April 1974), 50-59. [ 171 &#38;lilner, \nR., Implementation and application of Scott s logic for omputable functions, Proc. ACM Conf. on Proving \nAssertions about Programs, SIGPI.AN Notices 7,1 (Jan.1972), 1-6. [ 181 Milner, R.r ~ic for computable \nfunctions: description of a machine inplementa~ion, AI Memo 169, Cc.q?uter Science Department, Stanford, \n1972. [191 Miner, R., Prcgram semantics andmechanised proof, Proc. 2ndAdvanced Course in Found\u00adations \nof Ccnputer Science, Mathematical Centre, .Nnsterdam, 1976. [ 201 Milner, R., ICF: a methodology for \nperform\u00ading rigorous prcofs abut prugramsr Proc. 1st IBM Sympsiun on Mathematical Fomd\u00ad [ 101 Guttag, \nJ.V., The specification and applic\u00adation to prcgrarmning of abstract data types, Ph.D. thesis, University \nof Toronto, 1975. ations 1976. of Ccmpter Science, Amagi, Japan, [ 211 Milner, R., A Theory of Programnin \ng, Department Science Internal Reprk University of Fdinburgh, Type Polynmrphism of Ccmputer CSR-9-77, \n1977. in [221 Milner, R., Mxcis, F.L. &#38; Newey, A lcgic for computable functions reflexive and polymorphic \ntypes, Conf. on Proving and Improving Arc-et-Senams, 1975. M., with Proc. Prcgrams, [231 Milner, R. &#38; \nWeyhrauch, R., Proving ccmpiler correctness in a mechanised logic, in Machine Intelligence 7, ed. D. \nMichie, Edinburgh University Press, 1972. [241 Newey. M., Formal applications to thesis, Stanford, semantics \nprcgram 1975. of LISP correctness, with Ph.D. [25] Rekoh, R., Sacerdoti, E.r QLISP Manual, Technical \nArtificial Intelligence Mento Park, California A Preliminaq note 81, Centre, SRI., 1973. [261 Reynolds, \nJ.C., GERMWIN: a s~le typeless language based on the principle of completeness and the reference concept, \nCcmn. ACM 13,5 (May 1970), X)8-319. [271 Robinson, based 12.1 J.A., A machine-oriented on the resolution \nprinciple, (Jan. 1965) 23-41. logic JACM [281 Scott, D.S. &#38; Strachey, C., Tbward a Math\u00adematical \nSemantics for Ccq?uter Languages, Proceedings of the SyKpOsiun on Cquters and Automata, Microwave Research \nInstitute Smsia Series, Vol.21r Polytechnic Institute of Brcoklyn, 1972. [29] SUSman, G., Winogradr T. \n&#38; Charniak, llhmplanner Refercmce llanual, AI Project MAC, M.I.T. 1970. E. Nkmm 203, [ 301 Tennent, \nisation Queas R.D., PASQUAL: a propsed general\u00adof PASCAL, Tech. Report 75-32, University, Kingston, Ontario, \n1975. [311 Topr, R. Interactive Progran Verification using Virtual Prograns., Ph.D. Thesis, Edinburgh, \n1975. [321 Waldinger, R.J. &#38; Levittr C.r Reasoning about VO1.5 PrOcjrams, No.3. Artificial Intelligmcer \n[331 Weyhrauch, R.W. A Stanford Artificial AIM 235.1, 1977. User s P@nual Intelligence for FOL, menm \n[341 Weyhrauch, R. &#38; Milner, R., Program semntics and correctness in a mechanised lqic, Proc. usA \n-Japan Canputer Conference, Tokyo, 1972. [351 Wulf, R.A., Abstraction I.ondon, and R.L. &#38; verification \nShawr M., in ALPHARD: introduction Carnegie-Mellon to language University, and methodology, 1976. [361 \nZilles, types, 119, S., Algebraic Computation M.I.T., 1974. specification Structures of data Group - \n\t\t\t", "proc_id": "512760", "abstract": "", "authors": [{"name": "M. Gordon", "author_profile_id": "81344491086", "affiliation": "University of Edinburgh", "person_id": "PP45022815", "email_address": "", "orcid_id": ""}, {"name": "R. Milner", "author_profile_id": "81332515695", "affiliation": "University of Edinburgh", "person_id": "PP48028746", "email_address": "", "orcid_id": ""}, {"name": "L. Morris", "author_profile_id": "81344495227", "affiliation": "Syracuse University", "person_id": "PP39029178", "email_address": "", "orcid_id": ""}, {"name": "M. Newey", "author_profile_id": "81339519399", "affiliation": "Australian National University", "person_id": "P348410", "email_address": "", "orcid_id": ""}, {"name": "C. Wadsworth", "author_profile_id": "81100153141", "affiliation": "University of Edinburgh", "person_id": "P348404", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512773", "year": "1978", "article_id": "512773", "conference": "POPL", "title": "A Metalanguage for interactive proof in LCF", "url": "http://dl.acm.org/citation.cfm?id=512773"}