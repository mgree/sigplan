{"article_publication_date": "01-01-1978", "fulltext": "\n of Programming Languages Permission to make digital or hard copies of part or all of this work or personal \nor classroom use is granted without fee provided that copies are not made or distributed for profit or \ncommercial advantage and that copies bear this notice and the full citation on the first page. To copy \notherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission \nand/or a fee.&#38;#169; 1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Symposium \non Principles Nondeterminism in Logics of Programs (Preliminary Report) by David Harel and Vaughan R. \nPratt Laboratory for Coinputer Science Massachusetts Institute of Technology Cambrid~e, Mass. 02139 -,Abstract. \nWe investigate the principles underlying reasoning about nondeterministic programs, and present a logic \nto support this kind of reasoning. Our logic, an extension of dynamic logic ([221 and [121), subsumes \nmost existing first-order Iogics of nondeterministic programs, including that developed by Dijkstra based \non the concept of weakest precondition. A significant feature is the strict separation between the two \nkinds of nonterminating computations: infinite computations and failures. The logic has a Tarskian truth-value \nsemantics, an essential prerequisite to establishing completeness of axiomatizations of the logic. We \ngive an axiomatization for flowchart (regular) programs that is complete relative to arithmetic in the \nsense of Cook. Having a satisfactory tool at hand, we turn to the clarification. of the concept of the \ntotal correctness of nondeterministic programs, providing in passing, a critical evaluation of the widely \nused predicate transformer approach to the definition of programming constructs, initiated by Dijkstra \n[51. Our axiom system supplies a complete axiomatization of ro/J. 1. Introduction 1.1. Tire Interest \nin Nondeterminism: Nondeterministic programs have attracted considerable attenllon lately. [his interest \ncould be attributed to a concern for generality: anything we have to say about nondeterministic programs \ncovers deterministic pr~grams as a special case. However there are also deeper reasons for this interest: \nFirst, nondeterministic programs have been proposed [211 as a model of parallel processes. Such parallelism \narises in timeshared computers, where nondeterminism expresses the apparent capriciousness of the scheduler. \nIt als~ arises in the management of external physical devices, where the nondeterminism captures the \nunpredictable behavior of physical devices. Second, nondeterminism is gaining credence asa component \nof a programming style that imposes the fewest constraints on the processor executing the program. For \nexample a certain program may run correctly provided that initially x is even. If the programmer requires \nthe processor to set x to an even number of the programmer s choosing, the processor may be unduly constrained. \nOna byte oriented machine where integers are represented as four-byte quantities, setting x to a particular \nnumber requires four operations, but if the programmer has merely requested setting it to an arbitrary \neven number the processor can satisfy the request with one operation, by setting the low-order byte to, \nsay, zero. This report was prepared with the support of the National Science Foundation under NSF-grant \nno. MCS76-18461. Third, nondeterminism supplies one methodology for interfacing two procedures that, \nthough written .independently, are intended to cooperate on solving a single problem, The approach is \nto make one procedure an intelligent interpreter for the other. Woods Augmented Transition Networks [271 \nsupply an instance of the style. The user of this system writes a grammar for a specific natural language \nwhich amounts to a nondeterministic program to be run on Woods interpreter, which though ignorant of \nthe details of specific languages nevertheless contributes much domain-independent parsing knowledge \nto the problem of making choices le[t unspecified by the user s program. This technique is in wide use \nin other areas of Artificial Intelligence, and supplies a way of viewing such Al programming languages \nas QA-3/QA-4/STRllN [81, PLANNER [141, etc. Fourth, from a strictly mathematical viewpoint, there is \nsomething dissatisfying about taking such constructs as if fhvr e/.\\e and w/ri/e do as primitive constructs. \nIj then else involves the two concepts of testing and choosing, and w~ile do involves the two concepts \nof testing and iterating, A more basic approach is to develop these concepts separately. However, in \nisolating the concept of testing from the concepts of choosing and iterating, we have removed the parts \nof the if tken e15e and while do constructs responsible for their determinism, Fifth, from a practical \npoint of view, when reasoning about deterministic programs it can sometimes be convenient to make what \namounts to claims about nondeterministic programs. When we argue ~hat c~x>O then x+x-1 else x+x+1 cannot \naffect y, a part of our argument might be that, whether we execute x+-x-l or w-x+1, y will not change, \nThe fact that the whole programis deterministic played no role in this argument, which amounts to the \nobservation that the nonde(erministic program (x+x-l u x+x+1) cannot change y (au/l is a program calling \nforexecution ofeitherprogram a or program fl, the choice being made arbitrarily, i.e. nondeterministically,) \nBy the same token the observation that ruAi/e x<O do x+x+2 leaves the parity of x unchanged depends \nprincipally on the fact that executing x+x+2 arbitrarily often, i.e. executing (x+x+2)*, leaves the parity \nof x unchanged. (a* is a program calling for a number of executions of program a, the choice of number \nbeing made nondeterministically.) This illustrates the appropriateness or applying nondeterministic reasoning \nto deterministic programs. 1.2. The Interest trr Abstract Programs: Concretely a program is jusLits \nlisting, unless we consider its intentional aspects such as its rai~on d efre, its proof of correctness, \nor the actual cost of writing it. At any event we shall consider in this paper that its listing supplies \neverything we know about the program. To facilitate reasoning about a program we shall often find it \nconvenient to discard information about that program. The amount of information discarded depends critically \non the nature or the 203 reasoning. When ~he reasoning involves only these-called input-output behavior \nof a program, as it does in discussing partial correctness, the appropriate degree of abstraction treats \nprograms as functions on states, or binary relations in the case O( nondeterministic programs, However \nthis degree of abstraction is inappropriate when one wants to distinguish between different kinds of \nnontermination such as diverging versus [ailing, or when one wants to deal with running time, or space \nutilization, or the program s interaction with its environment as it runs, or any other aspect of a program \nnot covered by simple initial -state -[inal-state relationships. In.this paper we shall find inconvenient \nto talk about three kinds of programs, namely concrete programs (listings, or elements of a word-algebra), \ncomputation trees, and binary relations on states. The interest in computation trees is that they exhibit \nin a natural way just those details relevant to the main problems we address in this paper, namely how \nto talk about the behavior of nondeterministic programs taking into. account pathological behavior such \nas diverging and failing, A computation tree is a tree whose vertices are states. Each path of the tree \nrepresents a possible state trajectory or computation sequence for the program. The root of the tree \nidentifies the starting state of the program. The interest in binary relations may be attributed to the \nfact that much reasoning about programs centers on their external behavior7 the question of which state \n(or states, in the presence of nondeterminism) the program will ultimately drive the processor into from \na given starting state. Such reasoning can often be confined solely to the external b~havior of the program \nand its constit~ent subprograms, in which case it is convenient to take as the objects under discussion \nnot the programs themselves but merely their behaviors. The appropriate abstract object that associates \nwith each ini(ial state of the world a final state, is a junctton frornstates to states. When nondeterminismis \npossible the appropriate choice of object is.a binary relation on sta[es. The three levels of abstraction, \nconcrete prqgrams, computation trees, and binary relations, form a hierarqhy of levels of increasing \nabstraction, or equivalently decreasing information. If one were to embed our treatment in a more algebraic \nframework than we shall do in this paper one would treat the concrete programs as an initial algebra \nof a category of abstractions, with a chain of arrows (homomorphisms) from the initial algebra to computation \ntrees and thence to binary relations.. In [act we shall explicitly exhibit these homomorphisms, but we \nshall not explicitly adopt a category-theoretic approach in so doing. i. 5 . Upper and lower bounds: \n Much discussion about programs takes the form of bounds on their behavior. For example we may claim \nthat if and when program a terminates, x=3. This is an ujper bound on the behavior of u in that tY may \nnot terminate in slates not satisfying x=3. It ~orbids transitions having a final state not satisfying \nx=3, but says nothing about the exisrence or transitions. Conversely we may claim that it is always possible \nfor u)hi{e x>O do x+x-1 to terminate with x=O. This is a /oruer bound; it promises the existence of transitions \nwith final state satisfying x=O, one such transition for every possible starting state (because of the \nalways ). However it says nothing in. itself forbidding the possibility of other transitions, though \nin this instance the knowledge that the program is deterministic allows us to infer (as an upper bound) \nthe absence of any other transitions. More generally, asserting that a program is deterministic is by \nitself an upper bound. Asserting that it is total (there always exists a halting computation) amounts \nto a lower bound. A substantial difference between our approach to bounds and that implicit in Dijkstra \ns weakest precondition (w~) operator [51 is that we shall at all times keep the upper and lower bounds \nseparate. It will become evident when we come to prove our completeness results that such a separation \nis essential to the success of an approach such as ours to getting completeness results in this area. \nin contrast Dijkstra lets the single zup operator impose both upper bounds (partial correctness) and \nlower bounds (proper termination) simultaneously, and we do not see how to deal with the combination \nin any way that is not equivalent to the decomposition made explicit in our approach.  1.4, Contents \nElsewhere (see [221 and [121) we describe a language for reasoning about bounds on abstract programs, \nwhich we haw called dynamic io~ic; a language sufficiently general that it encompasses the expressive \npower of most existing first-order languages proposed for this purpose, yet so simple in its conception \nthat it would appear to be suitable as a standard tool supplying convenient terminology for defining \nthe concepts and constructs arising in other languages. In Section 2 we first recall the basic concepts \nof dynamic logic (DL) as given in [221 and [121. We then describe the ~-computation-tree and the ~-computation \nsequences of a program u in state $, emphasizing the importance of the notions of diverging and faiting, \ncorresponding respectively to executing an. infinite .cornputation, and reaching a false test, Having \nthe trees of Section 2 in mind, Section 3 (which is the main section of the paper) deals with the ex~ension \nof DL to DL+, by adding a divergence ~tate to the universe U of states, and adding to the [al and <rY> \nmodalities of DL, a [al+ modality with its dual <a>+, constructed for facilitating reasoning about the \npresence and absence of divergences. Various important properties of the new system are proved. The axiom \nsystem P which was proved relatively complete for DL in [121, is augmented with two rules, and the resulting \nP+ is proved complete for DL+. Thus one can now sa and prove e.g. <a>true A [al+P of a program a and \nformula P, meaning a can terminate, and whenever it does P holds; moreover, ~here is no way of entering \nan infinite loop . Section 4 contains a clarification of the concept of total correctness when applied \nto nondeterministic programs, advancing the argument that this becomes an ill-defined concept unless \na strict method of executing the programs is adopted. We then carry out a critical investigation of Dijkstra \ns notion .of the weake$t precondition (zup), which is considered to be a basic tool for proving the correctness \nof nondeterministic programs. The notion of ZUP has been described in [S1 and [61 in three different \nways, none of which is constructive, and none of which is completely consistent with the others. Observations \nin this direction have been made in [11, [231 and [151, but we still feel that a mist covers this widely \nused notion, which seems to have been introduced to the program-proving community with the same strong \nmotivation, but with the same lack of underlying semantics as was Hoare s partial correctness notion \nP{a.)Q. W~ hope to have achieved a clarification of this concept. Finally, in Section S we refer to other \nimportant work related to the topic of our paper, 2. Dynamic Logic, Computation Trees, Diverging and \nFailing. First we, recall the basics of regular DL, described in greater detail in f.121. We assume we \nare given some universe of states U, the elements of which we denote by $Jf etc. Firs order formulae \nare assigned truth values in the states of U by the standard methods, writing ~kP when P evaluates to \ntrue in 204 .f. Furthermore, every regular program a over assignments (simple, in this paper) and tests, \nis regarded as a binary relation over U in the following manner: x+E = {( Y,$ )1 every symbol has the \nsame value in Y and j except x which in has the value that dthe expression E has in , p? , {(9,f)l ff=P}, \n a ;/3 , UU19 and a* are the composition, union and reflexive. transi~ive closure of their components \nrespectively. We will write j a$ [or (f,j )fa. A new formation rule is added 10 those of predicate calculus \nby admitting <a>P (read diamond-a P ) as a formula for any program a and formula P, wi(h the semantics \n~b<a>p iil 3$(ga$ A $*P), or equivalently v $U=P. 3aJ Thus for the dual =<a>=P denoted by [alP ( box-a \nP ), ~l=[alP iff Vj(~aj ~ &#38;P), or equivalently A PP. la ~ With this language many of the properties \nof programs which relate initial and final states, can be stated and roved, like bR~[alQ (partial correctness), \nFR2<a>Q ! total correctness if a is deterministic) as well as more sophisticated statements such as the \nvalid [(a;a)*lP ~[a; (a;a)*l.P = p A [U*](P3[U].P A -Pn[a]p).  Iwo approaches to the axiomatizationof \nDL can be pursued, namely constructing infinitary axiom systems with the goal of achieving (absolute) \ncompleteness (this can be done for DL as work we are doing jointly with A.R. Meyer shows), and a variation \nof Cook s method, namely constructing finitary axiom systems which are complete relative to arithmetic; \ni.e. taking as axioms all the valid formulae O( first order arithmetic. We would like to reserve for \nthe latter the term Arithmetical Cmnp/tterr~ss. We reproduce here a variant of the axiom system P first \nappearing in,[221, which was proved to be arithmetically complete in [121. (A) All valid sentences of \nfirst order arithmetic, (B) All tautologies of Propositional Calculus, (c) [X+ EIP=PE where P is modality-free, \n (D) [P?lQ=P~Q, (E) [au#lP~[alPA[~lP, {F) [a; fllP~[al[flJP, (c) F oQ [a]P ~ [rx]Q  (H) Invariance \npa[a]p P=Xa*lP  (I) Convergence P(n+l)~<a>P(n)  P(n)=Ka*>P(0) where P(1) for some arithmetical term \nt stands for P:, x does not appear in a, and n does not appear in P(x) or a. 205 We make a sirJe remark \nhere and note that rule (H) can be re laced by the equivalent induction axiom (P A [a*] ( P= IalP)) ~ \n[a*lP, and that we have changed the rule of necessitation so as to make possible the elimination of the \naxiom [al(P2Q) ~ ([alP ~ [aIQ) of [221 and [121. Neither cha,nge falsifies our completeness result of \n[121. Were our programs restricted to be deterministic (say by ,replacing u and * by some deterministic \nconditional and iteration programming constructs), DL would suffice. in this case <a>P states that everything \nwill be ok ; the program (via its one and only possible path of execution) will terminate satisfying \nP. [alP states that if a terminates then P will be satisfied. whereas canturine the fact that something \ngoes &#38;ong can b; done with [aljulw, etc. Hence, theories of total correctness of deterministic programs \nare quite easy to construct and understand; they are based in most cases on one basic construct corresponding \nto <a>P ( $ometimes...at... [191 and [41,. PISIQ [31, [P{S}QI [261, <PISIQ> [181, ~om [161 etc.). In \n[101 we describe a deterministic version of DL, and survey a large number of known methods for reasoning \nabout deterministic programs, arguing that t he underlying principles in this case are few and relatively \nsimple. For the more complex case of nondeterministic programs we will formalize the notion of executing \na program eu in a given state jcl.1, by first defining lhe j-tomflutatiorr tree of a, t(tz, ~). Given \n~ and a, da, ~) is a possibly infinite tree, each node of which can have only finitely many descendants, \nand is labeled with either a state (element of U) or the symbol ~ together with an indication of whether \nthe node is a halt node (which we denote with a square; a circle indicates a non-halt node). t(x+E, j) \nis j where # is the unique state a such that (j,#)fx+E, 8 r(aud, j) is g <---identification of roots \n(root is square iff one of component roots is) t(a Y) t(d,~) A t(a ;fl,~) is the tree resulting from \nthe attachment, for any state $ , of t(~,$)to every halt node of c(a, f) which is labeled with the state \nj, except for the case where t(~,$) is a single non-halt node and the node to which it is being attached \nhas no descendants, i which case the tree d is used insteaY of c(13,$). The halt nodes of the resulting \ntree are taken to be just the halt nodes of ~ (i.e. square nodes of c(a, f) are rounded unless they are \nalso square nodes of c(#,~)). c(a*, f) is the (possibly infinite) tree defined recursively as t(true? \nu a ; a*, j) where a is u with its root rounded (made non-halting). The reader may verify that computation \ntrees have finite out-degree at every node. In proving this it is helpful to note that if a tree has \na leaf that is not a halt node then that leaf is the root. (This would not be the case if we did not \n round the root of a in t(a*, ~).) From the point of view of our definition we are regarding a* as the \nfinitely-wide / infinitely-deep program [ U CX;([ U a; (1 U CK; (...))), and not as the infinitely-wide/ \nfinitely-deep Program f u a u tY;rl U a;a;a u ... (where I abbreviates true?). The reason [or not associating \nan ~-node with a false test directly, and instead introducing ~-nodes only via ; , is so that failure \nto satisfy a test does not count as failure if an immediate alternative is provided (necessarily via \nunion). l-his permits us to retain the definition of if P (h~n a else # as P?; a u =P?; @. In view of \nthe convenience of reasoning about tests and union independently, it seems to us well worth while to \narrange the slippery notion of failure so that it does not make this definition unusable later on. The \nset of paths of t(a,~) from the root ~ will be called the set of computation ~eguences of a and ~, c(a, \n~). We will call the infinite elements of c(a,j) divergences, and the finite elements of c(a, j) terminating \nin nodes labeled ~, failures. A divergence corresponds to the presence of a possible infinite computation \nof a, while a failure corresponds to coming across a test evaluating to false and having no immediate \nalternatives to pursue that do not entail backtracking. These concepts supply the setting and motivation \nfor the following sections, 3. Dynamic Lo@c+. In this section we define an extended DL which we will \ndenote by DL+, it will have the ability to express the absence of divergences in c(a, ~), by employing \nthe modality [czl+ (and its dual <a>+), taking [al+P to mean that there are no divergences and that every \npossible final state satisfies P. In Section 4 it will also become evident that DL+ is powerful enough \nto express the absence (and hence the presence) of failures too. Thus, a wide range of properties of \nnondeterministic programs can be expressed in DL , including, as we will see in Section 4, all the di[ferent \nversions of the notion of total correctness. The central theorems of this section are an inductive characterization \nof the fact that a* can (cannot) diverge, and the arithmetical completeness of an axiom system for DL+, \nwhich provides for the first time a complete formal proof method for formulae including assertions about \ninrinite loops and failures, A remark seems to be in place before we proceed. We are about to add a divergence \n$tate to the universe U, which for lack of a better symbol we denote by J-, This state should not be \nconfused with the similar undefined state of say [1], [23] or [171, the difference being that the 1 symbol \nin these papers stands for a divergence and failure state. The pros and cons of this different approach \nwill be analyzed, and arguments for adopting ours will be presented, in Section 4. Define therefore, \nfor a given universe u, u+ =df Uu{ 1}. Truth in A is given by defining &#38;wP for every formula P (i.e. \nthe set {P1.LkP} is empty). Validity in U+ is, however, defined to be validity in U, to avoid losing \nsuch familiar theorems as P=P. New denotations for programs are obtained in DL+ by adding ( L, L ) to \nevery test and assignment. The definitions of union and composition remain unchanged. However, we take \na* to be the re(lexive transitive closure of a Iogether with transitions (~0, J.) when there exist states \njl,.Y2, .... such that Vi) O(jiaji+l). (An alternative definition of the binary relation on U+ represented \nby a is that it is the set of all pairs (~,$) such that $f labels some halt node of t(a,Y) not Iabelled \n~, together with (~, J.) whenever t(a, ~) is infinite, or equivalently has an infinite path, by Koenig \ns Lemma and the finite outdegree of the nodes of the tree. This approach simplifies the definition by \nmaking the description of computation trees do all the work.) Now let us reexamine the definitions of \n<a>P and [alP, 1 IW fact that for &#38;[alP we could write V$(~Uf ~ &#38;F ) although [al was defined \nas =<a>~, depends on the fact that j Y=P is the same as #P for all j. We note that J.lfP and J.V-P, and \nconsequently &#38;.<a>~P is no longer the same as Vj( jcxjf = &#38;P) for all states j. Rather, we now \ndefine ~FEal+P iff Vj(ja$ ~ &#38;P), or A #P, Yal $k[alP iff Vj($aj = $~-P), or A jl#=P, lag Jk<a>P iff \n~~(ja$ A ~~P), or v gf=P, 3a$ jk<a>+p iff ~~(~a~A~y.P), or v $V P, Jaj and we clearly have [1=<>= and \n[l+=-I<>+=. (The new modalities are read box-plus a , and diamond-plus a .) Inspection shows that these \nfour concepts assert about c(a,~) that (respectively) there are no divergences and every jlnal state \nsatisfies P, every final state satisfies P, there exists a jlnal state satisfying P, and ihereexists \neither a divergence, oraf2nal state satisfying P,  Note that ~l%ul+true states the absence of divergences \nin c(a, $), and fl=<a>+fa/se the existence of (at least) one. Various properties of a nondeterministic \nprograma resembling correctness can now be expressed, namely If R, the~=~~~Qexists a terminating path \nsatisfying Q: If R, then there exists a terminating path and any such path satisfies Q: Ro(Ea]Q A <U>true), \nor equivalently Rn([a]Q A <a>Q) which we can abbreviate R~([a] A <a>)Q. If R, then there are no infinite \npaths, and there exists a terminating path satisfying Q: R~([a]+true A <a>Q) if R, then there are no \ninfinite Daths, and any terminating path satisfies Q: R~[a]+O If R, then there-are no infinite paths, \nthere exists a terminating path and any such path satisfies Q: Ro([a]+Q ~ <a>true), or as above R=([a]+ \nA <~>)Q. We now gather some of the basic properties of our new modalities: Lemma 1. For all programs \na and 19, DL+-formula P, assignment x*E and test Q?, the following are valid: (a) [rx]+p ~ [cY]p A [a]+trw. \n (b) <a>+P s <a>P v <a>+fu~se, (c) [x-El+true, (d) [Q?l+true,  (e) [cl ;191+P ~ [al+CfJl+P = [al+true \nA [a][@]+tr~g A [a][~]p, (f) <u ;@>+P ~ <a>+<~>+p ~ <a>~~se V <a><@ >+fu/se V <a><d>P,,  (g) [autf]+p \n= [al P A f31+P, (h) <au13> P = <a>+P v <fl>+P, (i) [al+(PAQ) ~ [a]+p A [a]Q,  206 (j) <a>+(PvQ) \n= <a>+P v <a>Q, (allowing the formula (f%)P for any program a and formula P, (k) [a*l(P=<a>P) ~ (P~<a*>+jdje), \nwith the above semantics) ~ and call the resulting logic ADL.  Pm+ All follow quite easily from the \ndefinitions. We omit the proofs, n Note the (seemingly paradoxical) equivalent assertions: [a]+~atse \n~ [a]+? rue A [a]~ahe. Define U -df (i.e. identity -true? the relation), ntl and a d[ ;an. Thtorem I. \nfk<ax>+false ilT Vrr)O jb<an>+true. A rigorous proof. of this theorem is given in the Appendix (Section \n6). Intuitively, the right hand side implies that arbitrarily long computation sequences can be found \nin r(a*, j), which must therefore be infinite, implying the left hand side. Conversely, if t(a*,~) contains \nan infinite path then t(an, f) must either contain an infinite path or a halt node. Corollary I. jf=[a*3+true \niff 3n>0 such that j~[anl+false. At this point we will start talking about the specific universe of arithmetic \nN (see [121), remarking that for the universe A of arithmetic with uninterpreted function and predicate \nsymbols (augmented arithmetic), all results of this paper would also hold. We can now rephrase the results \nof the previous Theorem and Corollary as FN [a*3+true ~ an[un]+falw, EN <a*> false ~ Vn<an>+irue. An \nequivalent but more comprehensible description of the behavior of the plus-modalities on a* is given \nby the following Theorem and Corollary, the proofs of which we omi~ Theorem 2. FN [ax]+true = ~n[csn]~a[se \nA [U*][Cd+tWI Corollary 2. k~ <ax>+ false ~ Vn<an>true v <ax>< a>+fahe. Corollary 2 states that a divergence \nin a* is due either to being able to run a for as many times as you wish (which by Koenig s Lemma is \nequivalent to being able to run a for ever), and this we might term diverging for global reasons, or \nto being able to run a for a certain number of times and then have a itself diverge, terming this diverging \nfor local reasons. Theorem 2 states that a* is divergence-free if there is a limit on the depth we can \ngo to by doing a, and that furthermore a itself does not diverge in the process. We recall the fact (mentioned \nin [121) that (augmented) first order arithmetic is expressive for (augmented) DL. We extend that result \nto: Theorem 3. First order arithmetic is expressive for DL+; i.e. for every DL+ formula P, there exists \na formula F of first order arithmetic such that bN FsP. Proof. Use induction on the structure of formulae \nand programs via the result in [121 and Theorem 2. n We make a remark here which concerns the Algorithmic \nLogic of the group of Polish researchers initiated by Salwicki [243. They employ an operator (fkx), \n(or which (nu)P is to be equivalent to Vn<an>P. Although [241 allows only programs which are deterministic, \nwe can admit this operator into DL We then have: T/ieorem 4. ADL is expressive for DL+, Proof. Again \ninduction is employed. This time the key fact is Corollary 2 which is rephrased as ~b<a*>+fdse (in DL+) \niff ~ F (nct)true A <a*> <a>+fahe (in ADL; where <a>+fahe stands for the ADL formula equivalent to <a>+fahe, \nwhich exists by the inductive hypothesis). ~ In [91 an arithmetically complete axiomatization of ADL \nhas been exhibited, We would like to pause here and pose an important open problem (pointed out to us \nby M.J, Fischer), concerning the expressive power of DL+: Is it the case that for every DL+-wff P there \nexists a LJL-wff Q such that b P~Q? We strongly conjecture that the answer to this question is no, i.e. \nthat DL+ is strictly stronger than DL in expressive power. Meyer [201 has shown that if array assignments \nof the form F (x) + y are allowed, then the answer is ye~, i.e. DL+ is no more expressive than DL. However, \nthe proof in [201, and the manner in which it uses array assignments in DL to make possible expressing \nthe presence of a divergence, further convinces us that with simple assignments the answer is nevertheless \nno. Another version of this question, is in the case of propositional DL (PDL, see Fischer and Ladner \n[71), where we can similarly define PDL+. It can be shown that PDL+ ~ strictly more expressive than PDL, \nOther related questions and observations can be found in [201. We now augment P to P+, by adding the \nfollowing axioms and rules: (J) [x* El+rrue, (K) [Q?]+ true,  . (L) Ca;131+rrue [al+[~l+true, ~ (M) \nIldJ1 true [a]+true A [#]+true, (N) f-al+P ~ [al*true A [alPj (0) Finiteness P(n+l)&#38;xl+P(n) , -P(O) \n P(n) =[axl+rrue where n does not appear in a. pn<u>+p(P) Divergence P~<a*>+false The soundness of \nthe axioms follows from the above discussion, and the soundness of rules (P) and (0) can be shown to \nfollow from Theorems 1 and 2 respectively. We proceed to show what we might call the completeness of \neach of the last two rules, followed by box and diamond completeness theorems for DL+, and then present \nour main result. For these purposes denote P+ without rules (1) and (P) by P*Cl, and without rules (H) \nand (0) by fJ+<>. As in C121, we will concern ourselves with the proofs of the completeness directions \nof the theorems only. Lemma 2. If, l=R~[a*l+true, then there exists a formula of arithmetic P(n) with \nfree variable n, such that the premises of rule (0) and R~ZrrP(n) are all valid. 207 Proof BY expressiveness \nof arithmetic, [an]+ alse is expressible as such a P(n). By Theorem 2, { R~~np(n), Noting (hat P(0)~~alse, \nwe observe the trivial validity of the premises of (0). H Theorem 4 (DL+ Box Completeness Theorem). For \nany formufae of arithmetic R and Q and program ts FN Rn[@]+Q iff I-P+[l R=r[al+Q. Proof Assume FN R=Ial+Q, \nwhich really asserts that both PN R=talQ and EN R~[al+~rue hold. By the DL Box Completeness Theorem of \n[121 we have f-P+C1 RdcsIQ. We shall show that FF+[3 R~[al+[rue, and axiom (N) will serve to combine \nthe results. This follows, however, by induction on the structure of u (using Lemma 2 for justifying \nthe application of rule (0) when a is fi*), from which we obtain F(n) Ma*l+true, and then R4a*l+true. \nB Lemma 3. If bR~<a*>+fd5e, then there exists a formula P of arithmetic such that the premise of rule \n(P) and R~P are both valid. Proof Assume kR~<a*>+falje. We will exhibit here a situation similar to that \noccurring with the rule of Invariance; in [221 it was implicitly shown that both [a*lP and <(a-)x>R could \nbe taken as invariant, satisfying those conditions which guaranteed that the rule could be applied. Here \ntoo, both a strongest <>+ consequent and a weakest <>+ antecedent will be shown to satisfy the requirements \nof the Lemma. The latter is simply <a*>+Ja/~e which trivially satisfies the requirements. The former \nis a little more subtle. Intuitively what we will construct is the predicate P which is true exactly \nin those states which lie on an infinite path of computation which started in a state satisfying R (by \nassumption there is at least one such path for every such starting state). Take P to be an arithmetical \nequivalent of <( CI-)*>R A <a*>+fahe (recall that f(a-)$ iff jfaj). As first order arithmetic can be \nshown to be expressive for DL+ augmented with the conuer~e ( ) operator on programs, this equivalent \nexists. <(a-)*>R states that the present state is on a path from R via ~*, and <a*>+yalse makes sure \nthat we are on a path with a possible infinite computation. First we observe that R~<(a-)*>R, and b.y \nthe assumption also R><u*>+Jizlse. Thus R~P is valid. We are left with having 10 show Pa<a>+P. This can \nbe seen to follow directly from the easily checked validities 1. <(a-)*>R ~ [al<(a-)*>R, 2. <a*>+ false \nF <a>+<a*>+ alse, and [ 3. ([U]U A <a>+V) = <a> (UAV)  (taking U to be <(a-)*>R and V to be <a*>+jalse) \n (To check 1, use the validities W4al<a->W and <IIJ><13*>R 3 <~*>R, taking W to be <(es-)*>R and @ to \nbea-.) E Theorem 5 (DL+ Dlamon~ Completeness TAeorem). For any formulae of arithmetic R and Q, and program \nu, FN R=<a>+Q iff I-P+<> R~<a>+Q. Proof. Analogous to the previous theorem, using Lemma 3. ~ Lemma 4. \nFor any DL+ wffs P and Q, and for any program U, if f-P+ P=Q, then (a) f-P+ EalP ~ [aIQ, (b) FP+ <a>P \n3 <a>Q, (c) I-P. [al+P ~ [al+Q, (d) f-P+ <a>+P ~ <a>+Q.  Pro~fi (a) is obtained by rule (C), as is \n(b) (with -IQnlP); (c) and (d) are obtained similarly with help of axiom (N). B Theorem 6 (DL+ Completeness \nTheorem). For any DL+-wff P, KNP iff FP+P ProoJ rhe framework of the proof follows in the footsteps \nof our proof of the DL-Completeness Theorem of [121, which employs induction on the number n of modalities \nin P, and works with a conjunctive normal form. Rather than reproduce it here, we refer the reader to \n[121, pointing out that Theorem 3 (above) gives us the expressiveness we need, I heorems 4 and S provide \nfor the justification of the additional parts of the case n=l, and Lemma 4 is needed for the last stage \nin which f-P+ m(a) L(P2) .3 m(a)P2 is established. a A subsequent paper [91 provides insight as to the \npattern by which we obtain arithmetically complete rules for various modalities applied to a*, and in \nthe process clarifies the analogy between the aforementioned rules for [a*l+ and <cy*>+, and the [a*] \nand <a*> rules of P. Thus, e.g. the invariant assertion method of Floyd/Hoare, which is captured concisely \nby the rule of Invariance (H), is seen to fall out easily as a special case of a much broader observation, \nIn [111, the work of this section and, of [121 is considerably extended, by adding a recursion operator \npXr(X) to ; , u and *, together with inference rules for [PX7(X)I, <pX~(X)>, [PXr(X)l+ and <pXT(X)>+. \nThe resulting axiom system is shown to be sound and arithmetically complete: The interesting part occurs \nwhen the analogue of e.g. Corollary 2 is attempted for pXr(X). 4. Total Correctness and Weakest Preconditions. \nLet us try to clarify the notion of total correctness of a nondeterministic program u. in the sequel \nwe ~ill argue that this is a concept which is Necessarily dependent on the particular notion of execution \nof a one has in mind. We will consider t(a,f) and c(a,$) of Section 2. Since da,f) might be an infinite \nset, a feasible execution of a in J cannot in general be carried out on a machine by calculating c(a,l), \nchoosing one or some of its elements, and proceeding to execute them. Rather what we need is to choose \nSome method of traversing f(a, ~) which will either eventually lead to a halt node (either anj-node or \ngood node), Qr will go on for ever. We envisage four possible such methods: (1) Depth first. At each \nnode choose arbitrarily between possibilities and proceed; stop when a halt node is reached, (2) Depth \nfirst with backtracking. Same as (1); backtrack if an ~-node is encountered.  (3) BreadtA first. At \neach node pursue all possibilities simultaneously; stop when a halt node is reached; if more than one \nis reached together, choose one arbitrarily. (4) Breadth first with imzorin.r. Same as (3); ignore all \n-/-leaves-(in s~opping and in choosing).  208 We now observe that assuming the existence of at least \none final state (.jk<a>truc), if the machine executing a program a in state ~ using these various methods \nis to reach a final state upon completion, without having diverged or failed, then t(a,~) should adhere \nto the following table, where no means that c(a, j) should be free of (ailure/divergence elements (f-nodes/infinite \npaths): failure divergence (1) no (2) Ks no (3) yes (4) {s yes  Thus for example, if we choose method \n(2), we do not mind having j-leaves in the tree, but do not want any infinite. paths to be present. The \nimportance of the above table is that it illustrates the fact that the notion of total correctness of \nnondeterministic programs is indeed strongly dependent upon the particular method used. Saying that a \nis totally correct with respect to R and Q amounts to saying that for any ~ such that ~bR, application \nof the chosen method of execution is guaranteed to lead to a final state j such that $PQ. Thus, whenever \njER, we always want both a final state to exist, and every final state to satisfy Q. Furthermore, whether \nwe require the absence of divergences and/or failures depends upon the execution method used. We arrive, \ntherefore, at the following description of the notion of total correctness of nondeterministic programs, \nthe variants of this concept for the four methods being respectively: (1) R ~ (<d>lrwe A [alQ A fl(a) \nA dv(a) ), (2) R ~ (<rx>true A [a3Q A dv(a) ), (3) R = (<a>true A [alQ A ff(es) ), (4) R = (<u>true \nA [tdQ ),  where jRf/(a) iff c(a, j) has no failures, and jkdrr(a) iff C(cr,.~) has no divergences, \nAdopting DL+, dv(u) is simply [al+true, thus total correctness for method (2) can be expressed in DL+ \nas R =1 ([tsl+Q A <a>/rue). We would like to point out at this stage, that we are quite satisfied with \nthe adequacy of DL+ for capturing the notion of total correctness for methods (2) and (4) (for the latter \nit is expressible even in DL). One cannot imagine an impl~mentation using breadth first search without \nignoring the railure nodes, as in (3). Also, backtracking has become an integral part of depth first \nsearch, to the point of people having difficulty in envisioning it without. As we shall see, however, \nDijkstra s notion of weakest precondition is really addressed to method (1), and it is, therefore, at \nthis concept that we now direct our attention, showing, quite surprisingly, that DL+ is powerful enough \nto capture the conc~pt of Jailing too, and hence the notion of total correctness for all four methods. \nIn [S1 and [61 Dijkstra introduced the concept of weakest prec9rrdition: (*) The condition that characterizes \nthe set of all initial states such that activation will certainly result in a properly terminating happening, \nleaving the system in a final state satisfying a given post-condition ([61, p. 16). This condition was \ndefined to be the value of a function wp(a, P), which we will write as {rx}P, satisfying the five conditions: \n Dijkstra then introduces a syntax for a programming language, and defines its semantics by specifying \n{IZ)P for each allowed program a. Specifically, the programs and his definitions are: empty program \nf@je?}P df fat$ej identity prog. {true?}p df p, assignment {x+E}p df P:, composition {a;#)p df {U}{6)P, \n IF { ~ (Q/iai))f df (~ Qi) A : (Qi~{ai}f ) i=l i=l i=l DO {( ~ (Qi?;ui))*;(~ -Qk)?}p =df 3jHj(P), \ni=l k=l n where HO(P) df P A (A Qk), and i=l Hj+l(P) df HO(P) v { ~ (Q~;di)}Hj(P). i=l At this point \nwe should assume that (a)-(e) are to characterize the notion of ru~, and that they ought to give rise \nto a unique predicate transformer {a}P. This, as we shall see (and as observed independently in e.g. \n[231 and [1.51), is not the case. Moreover, there seems to be no further definition to fall back on, \nif what we want is to understand what rufl(a ,P) is really saying (i.e. which states ~ satisfy wp(a,p)). \nl he English description (*) is vague! and uses the word activation , so leaving unspecified which method \nof activation is being used. The definition of Dijkstra s programming language uses rut, and certainly \ndoes not define it, and thus cannot b? of much help. We first set out to find something which satisfies \n (a) -(e) for regular a s. Inspection shows that (c) fails for <a>P and (e) for [alP. (Example of latter: \ntake a to be ~eo;(xer+l)* and pi to be x(i,) This, however should not cause alarm, because (a)-(e) are \nrequired to hold for the final product satisfying (*), which is to have the always ( will certainty ) \nand the somotimes ( will certainly ) properties. An attempt to take {a]P to be [alP A <a>P (equivalently \nCalP A <a>true) will result in (c) holding, but (e) still failing (same example). This observation explains \nour remark in [121 in which we incorrectly claimed ruj(a,P) te be CalP A <u > true, which was made solely \non the basis that this construct satisfies the axioms which appeared in [S1 ((a)-(d)), without re[erring \nto the later addition (e) of [61. [ he reason (e) fails for [al (and for that matter fails for CalP A \n<a>mi.e) is rooted in what [61 calls unbounded nondeterminism ,. which in this case is a misleading term: \na* can, as remarked, be viewed as a tree with jlrsite outdegree, but can have infinitely many final states, \nby virtue of being able to apply a infinitely often. Outlawing this situation is brought about by further \nasserting the absence of divergences! I_hus we propose to add to our suggestion [al+true, arriving at \n{U}p df [al+p A <a>~rue. 209 Lemma. Conditions (a)-(e) are satisfied by {u}P. Proof Omitted. Thus it \nwould seem that our task is completed, as would indeed be the case if ZUPwas defined to be any predicate \ntransformer satisfying (a)-(e), We might note here that the resul~ of Wand [251 strengthens our argument. \nWand has shown that if a program is de~raed to have the property of allowing only a finite number of \npossible out-states for every initial state (which in our case amounts to asserting [al+mue), then a \nfunctional F:2U + 2U is equivalent to [a]P A <a>true for some such a ijf (a)-(e) hold for F (that is \nsubstitute F for a in (a) -(e)). This result is essentially showing that our []a = [al+P A <a>true is \nindeed the greatest predicate transformer satisfying these axioms. However, the fact is that there is \nmore, in Dijkstra s description, than just the axioms. Let us take a look at the definition of his language. \nWe notice, that {a; f3}P={a]{fJ]P does not hold for our definition of {a}P, and neither do the equalities \nfor IF and DO. (Paren~hetically, we might note that, contrary to what is irnpljed in [151, the importance \nof having e.g. the property w~(a; /3,P) = wfi(a, w/41?, P)) hold, should not at all be overestimated. \nThis property is important for easing the construction of the weakest precondition of a given P with \nrespect to a given a, only if the w/I construct is the only thing you have! In our case the fact that \n{a}.P does not enjoy the property is irrelevant, because {a}P is defined as the. conjunction of two constructs \nwhich do (namely <a>/rue and [aI+P). Constructing {a}P in a concrete situation would proceed, therefore, \nby constructing the two components in the natural way using this property for both!) These observations \ncall for extra analysis. Su~~ose we were to attemirt to carrture the third class ,,. of members of c(a, \nj), namely the failures, by adding a jrriture-ftate (say L ) to U+. Despite the fact that Dijkstra s \naxioms do not ,require this,, his informal discussion of failure (referred to as abortion) tndicates \nthat failure is considered not to be proper termination, whence if we are to capture what Dijkstra had \nin mind by wp (as opposed to what he axiomatized) we will need to include 1 in our reckoning of what \nconstitutes a binary relation abstraction of a program. We can do this as we did for J-: (.!f,l ) is \nin the binary relation for a when t(a, j) contair rs a failure node. We now give a way of expressing, \nin DL+, the formula ~l(a) whose truth in s~ate j asserts that t(a, j) contains no failure node. ~l(x+E) \n~ true, ~l(P?) ~ true, fl(aw!?) ~ fi(a) A jl(~), ~/(a;@) = jl(a) A tr(a,(l) A Cal~i(r9), J/(a*) = Ca*li/(a). \n [n turn we need to define the transition predicate tr(a,fi), which expresses the hoire that if a leads \nto a state from which 19 has no chance of eventual success or divergence then a may be resumed. (Such \nresumption is possible with programs such as 7*,, where one might execute ~ some number of times, try \nto execute /3, fail immediately, and so execute ~ again. This is precisely the behavior one would expect \nin the interpretation of the DL translation of while P do a as (P?; a)*; -P?.) tr(a,d) ~ [al<~>+true \nfora an assignment or test tr(~;d,~) =C.Tltr($,fS) tr(-fur$,fi) = tr( /9) A tr(8,1J) 1 tr(~x,~) ~ [T \nl<(lwy>+true Let us define now {{a}}P df Cal+P A <a>true A J(a). Lemma. Conditions (a)-(e) are satisfied \nby {{a}} P,. Proo$ Omitted. It can be shown that the equalities in Dijkstra s definition of the guarded \ncommand language above also hold for {{r.x]}P. Thus {{a)}P exactly expresses w~(a, P), namely the weakest \nconditi6n guaranteeing correct termination when execution method (1) is adopted. Now, given that fl can \nbe expressed using DL+, and given that we have completely axiomatized DL+, we infer that we have also \ncompletely axiomatized {{a}}P. So we have given an arithmetically complete axiomatization of Dijkstra \ns notion of weakest precondition. These remarks, combined with the elegance of the logic developed in \nSection 3, seem, even without any additional backing up, to point to the. unavoidable conclusion that \nreasoning about programs should be carried out using well defined primitive basic concepts (such as [alP, \n<a>P, [al+true} yl(a) etc.) as the building blocks, from which other more complex notions can be constructed. \nWe are strongly against the approach implicit in Dijkstra s work, in which the basic construct (ru#) \nand the properties required of it, appear to obscure the simple parts of which it consists. We are further \nagainst the attempt to define the ~emantic~ of a language using a complex (execution-method dependent \nin this case) notion. Recently deBakker [21, deRoever and Plotkin (unpublished) have gone to great efforts \nin trying to find the appropriate denotational semantics which would correspond to what essentially is \nDijkstra s definition, using predicate transformers, of the semantics of a recursive programming language \n(with the explicit ad~ition of an if then e15e construct). In our opinion, not only have they not fully \nsolved the problem of tying up a denotational semantics to a total-correctness-based semantics (the same \nprocess remains to be carried out for the other three execution methods, for their solution implicitly \nassumes the need for outlawing both divergences and failures), but also the top down viewpoint of having \nto apologize for defining a language with the aid of UJP, by conjuring up a suitable ordering on the \ndomain ,which gives rise to an equivalent denotational definition, is inferior to the much healthier \nbottom up approach. The latter consists of first defining the semantical objects (states and binary relations), \nand only then introducing the logical !anguage and assigning meaning in the manner of Tarski. At this \npoint the truth of the formulae of the logical language has already been determined (and in a plausible \nwav~), and the axioms of Dijkstra s definition can then be verlfmd as mere theorems. This formalizes \nwhat happens when a semanticist is confronted with those axioms; he attempts to verify their agreement \nwith his intuition about the behavior of programs. ln contrast, deBakker, deRoever and Plotkin (in this \ncase) start from the axioms and assign semantics that are faithful to those axioms. 5. t2ther Work Some \nof the points made in the previous section appear also (either explicitly or implicitly) in Hoare [151, \nHe wri(es a a P and a e P (allows and ensures) for <a>P and [alP respectively and notes theduaiityof \n<> and [1. (The notation was interestingly confusing for us, since <> and [1 correspond to 3 and V, or \ne and u respectively, not to u and e!) More significant is his definition of b(a), which in state ~ \nasserts the finiteness of the members of c(rx j), and * which, if we take the liberty of rewriting for \nour a , is vnyo(an ejctse), or as we would write, 3n[anlfat~e, which should now be viewed in the light \nof Section 3. Hoare observes that {a]P = [al+ PA<a>/rue does not satisfy the basic axiom for program \ncomposition , and proceeds to describe explicitly in his logic of traces, that condition flex) (similar \nto our fl(a)) which. guarantees the non-existence of failures ({ blind alleys ), and shows that rop(a,P) \ndefined as {a}pAfla), satisfies that too. 210 Manna [171 uses essentially quantification over states \nto spell out a variety of properties of deterministic and nonrfeterministic programs. His pro rams are \nmany-valued functions of states, i.e. a(j) CU. f F<cs>Pis termed a totally Z-correct wrt P in ~ , and \nis written 3$($6a(j) A P(~,j)) (note thesimilarity to3$($a~A j bP)), and jf%alP termed a artia.@ V-correct \nwrt P in ~ and written Vj (jca(f) ~ P( ? ,$)). Totaleguivalence of a and d instate ~ is written a(~) \nand 19(.Y) are not empty, and a(~)=#(~) , the last conjunct being inexpressible in DL without the use \nof state quantifiers. [1 71 then proceeds to express the above and other properties using (here we translate \nfor clarity into our own t~rminology) the primitive [alP and second order quantifiers; in particular \nit is noted (perhaps the earliest men~ion of this fact) that <a> P~4al=P, and that totally ? -correct \nis l[a]ja/$e A [a]t or <U>MM A [a]f. Manna [171 then augments U with an undefined state rXJ, and requires \nthat the programs map any state into a norr-trnpty subset of Uu{mJ}, thus as is the case with [11 and \n[231 (see below), ( ~,wI) is added to the program not only in the presence of a divergence, but also \nin the case of failure, and hence differs from DL+, However, [171 has four concepts of correctness analogous \n(and not identical, due to the above difference) to our modalities: parria//y 3-correct (written Llj($ffa(f) \nA (j #~~P(.l,j)))) tofa//y I-correct (~j(jfa(f) A ~#rxJ A P(~,$))) fwrtial/y V-correct (V$(($Ca(!) Aj#~) \n~ P(j,~))) totally V-correct (Vj (j 6a(f) ZJ ($#MJ A P(j,$)))) analogous to <a>+P, <a>P, [aIP, and [al+P \nrespec~ively. The double duality of these concepts is proved, and other properties are expressed in a \nsecond order language using these four as basics. The aforementioned difference in the use of (I), comes \nto the surface in the remark 0[ ~17J that <U>+true is valid for every a, a fact which is nol true in \nDL+. However, this clean description of the four basic concepts of nondeterministic programs, formulated \nalready in 1970 (and brought to our attention by N. Dershowitz), strengthens our confidence in the manner \nin which we have constructed DL+. In deRoever [231, who uses explicit quantification over states, we \nfind in essence the remark that CalPA<a,>true satisfiqs (a) -(d). Also t233 proceeds to describe the \nZUP which satisfies (e) as well as Dijkstra s definitions of (what boils down to) ; , u and *. This is \ndone, as we have remarked, by using L to express both divergences and failures (respectively in the words \nof [231 with notation adjusted: if {$l(~,$)fu} is infinite then (J ,l)@ and 1 feel free to switch from \na relation or as a subset of values of some cartesian product UXU, to a function rx from UU{ 1} to nonempty \nsubsets of Uu{ 1 , made total by using { 1} as the value for a(j) in case .... / jl(f,j )fa} is empty \n). As remarked, this approach eliminates the possibility of using u to branch conditionally, so an if \nt/ten else is added explicitly to the Ianrwage! Of course, in this setting rup(aud,p) = wp(a,p) A w)(L9,P) \nbecause 7u/J enables one to be able to choose either, and no { have to backtrack, but on the other hand \nZIJ/J(L~ R then a f/se 13,P) = w~(R?; a,P) v ru/r(=R?; @,P). [231 also proves that the Egii-Milner ordering \non programs over U+ results in w~(a, P) being continuous in a, a result which it is possible 10 show \nholds for {u}P too. Turning to deBakker [11, the part of this work relevant to weakest preconditions, \ndiffers in an important respect from that of [231. deBakker uses u and if then dj~ as two independent \nconstructs, and does not have our notion of tests. This eliminates all possibility of failure, making \ndeBakker s task simpler than Dijkstra s or ours. In another important respect his work parallels ours; \nhe states explicitly ... with the convention that ja L holds iff some computation sequence specified \nby a does not terminate properly .... either the computation sequence is infinite, or that one of the \nelementary actions .... is undefined at some intermediate state . Interestingly, ,[11 reaches the conclusion \n(as did we independently) that it is very helpful to define -1 such that .t.~P for all P. What he really \ndoes is to restrict his predicates to those that are false in 1. Another noteworthy remark about [11 \nis his e(a), which is defined to be true in f iff (Y,l) is not in a, and thus in this light, the observation \nin [11 that e.g. e(a;ff) = e(a) A [cxle(@) amounts to our easily checked equivalence [a; #l+rrue ~ [a]+true \nA ka][/?]+frue (see Lemma l(e)). Another paper describing a logic which allows nondeterministic programs, \nand which is supplied with a complpte axiom system, is Harel, Pnueli and Stavi E131, in which the nondeterministic \nassignment x+@ P(x,x ) can be used to simulate generaI u and . However, although [al P and <a>P can essentially \nbe expressed (and by the completeness theorem proved), as well as certain combinations. of them, no mechanism \nis provided for reasoning about divergencies, and hence only total correctness for method (4) can be \ncaptured. 6. Appendix We give here a rigorous proof of Theorem 1. An interesting aspect of the proof \nis the way in which it makes use of a DL version of Koenig s lemma. While the reader may have been convinced \nby our informal justification of Theorem 1, the apparent difficulty of proving it carefully suggests \nthat the intuitively obvious in this case needs to be approached with caution unless one is willing to \naccept it as axiomatic. The theorem asserts that a* can reach 1 if and only if for any number of iterations \nor a either a terminating state is reached or a divergence is encountered along the way, The only if \npart should be obvious, but the if part appears to depend on Koenig s lemma and the fact [al+true ~ [aim \nuhe (i.e. if a doesn t diverge, then a can reach only finitely many states, which is true of our particular \nnondeterministic programming language but not true of such assignments as n:=?). Since we can state an \nextended version of Koenig s lemma in dynamic logic, we can increase the rigor of the proof of ThForem \n1 by using this extended version. First we need a notion of independent programs. We say that a and B \n(treated as binary relations) are independent when (i) a;8 = @;a (order independence), and (ii) ~afbf \nA fa$ll~ ~ $=$ , and Sirnilarh with a,fl interchanged (information independence).  i-he first condition \nimplies that for every computation ~~Yr9~ there is a computation ~#j uY , and similarly with %# interchanged. \nThe second condition asserts that if we know what state a;@ went to then we know what state a went to \nin the process, i.e. the trajectory information can be recovered from the transition information, so \nthat @ cannot destroy information supplied by a. Second, we need a generalization of the notion of there \nexist infinitely many. We use CaliP to mean that p holds in all but less than i of the states reachable \nby a. Hence [a3m)P means that only finitely many of the states accessible via a can fail to satisfy P. \nSo if [almfahe holds in stat~ ~ then there are only finitely many statm $ satisfying jaj, i.e. a has \nonly finitely many transitions possible from this state. Extended Koenig ~ Lernrna ( EKL). Let a, #l \nbe independent programs. Then [~lm~atse ~ (<a>m<f?>P ~ <P><a>WP). Proof. Itsuffices to show that the \nformula holds in an arbitrarily chosen state ~. Suppose then that %[@lm&#38;lse and jk<a>m<fl>P. Let \nV = {Ylja$ A j P<#>P}. Then since jf=<a>(x <#>P, V must be infinite. Now let fiV+U (U is the universe \nof states) be a function assigning to each element of V an element ~ such that j f?j and g bP. The construction \nof V ensures that such an j exists for every f . Since ~a~ for each ~ fV, property (ii) of independent \nprograms ensures (hat f is 1-1. Finally let W = {(j ,f(~ ))1~ (v A ~p$ af(j ) ]. Property (i) of independent \nprograms ensures that a # can be fQund for every f( j )? and so the l-1-ness of f ensures IWI)IVI, so \nthat W must be infinite too. But only finitely many distinct states may appear in the first coordinate \nof W since Yf%fll(x)fahe. Hence some value # of the first coordinate must appear infinitely often in \nW. Hence ~ ~<u>(mp. But j~~ , so $=<~><a>mP. E (It is possible to strengthen the second ~ of EKL to Z, \nbut we do not us? this fact here. There is also a more general statement of the I.emma that caters for \nother cardinals besides co, but we do not need this either.) In addition to the validities of Lemma 1 \nwe need: Ttieorem 1. jb<a*>+fa/~e iff Vn>O jb<a,n>+true. proof, (=>) We prove <a*>+fa/~e 2 <an>+true \nby induction on n. When n=O the result follows trivially. if we now take as our induction hypothesis \nthe result to be proved we get <ab+false ~ <a >false v <a>+< ax>+false ~ <u>+< an>+true ~ <an+~>+true. \n(<=) For this part of the proof we express for all n20 Jk<an>+tru.e as j,b[n:=?l<an>+ true so that we \ncan conduct the whole argument within dynamic logic. We take n:=? to be a program setting n to a nondeterministically \nchosen natural number, so that [n:=?] expresses Vn. Clearly we have [n:=?jP~<n:=?>mP. The argument assumes \nthat a does not itself use n in any way. [n:=? l<an>+rrue = -71< an+1>+true [n. -. ~ [n:=? l<a>+<an>+true \n= [n:=?l(<a>+fal$e v <a><an>+true) 3 (~>+felse V [n:=?.l<u><an>+ trrw) Now if <a>+fat~e holds then so \ndoes <a*>+fa15e, and we are done. Otherwise if <a>+fulse does not hold (i.e. [al+true holds) then we \nmust have [al+true A [n:=? l<a><an>+true = [a]m~atje A [n:=?l<a><an>+true (Lemma l(i)) ~ [a] mfiZ&#38; \nA <n:=?> w<a><an>+true (1 infinitely many natural numbers) ~ <a><n:=?>m<an>+ true (EKL) n <a>[n:=?l<an>+trwe. \n(m<n 2 (<an> +/rue ~ <am> rrue)) Thus we have [n:=? l<an>+true a <a>[n:=?l<an>+true. But this is of the \nform P~<a>P, so applying Lemma l(k) we get [n:=?l<an>+lrue = <ax>+fahe. 6 7. Acknowledgments. The early \nstages of our thinking about nondeterminism, which finally led to the formulation of DL+, were strongly \ninfluenced by numerous discussions with Nachum Dershowitz, who has also helpfully coinmented on various \nparts of the paper. Adi Shamir supplied the idea behind the rule of Finiteness. Edsger W. Dijkstra pointed \nout an error in a previous version of Section 4. We have received valuable feedback from Albert R. Meyer. \n8. References [11 deBakker, J.W, Semantics and Termination of Nondeterministic Recursive Programs, [n \nAutomata, Languages and Programming, Edinburgh. 43S-477, 1976. [23 deBakker, J.W. Recursive Programs \nas Predicate Transformers, Proc. lFIP conf. on Formal Specifications of Programming Constructs, St, Andrews, \nCanada. Aug. 1977. [31 Basu, S. K. and R. T. Yeh. Strong Verification of Programs. IEEE Trans. Software \nEngineering, SE-1, 3, 339 T345, Sept. 1975. r41 BurstaH, R.M. Program Proving as Hand Simulation with \na Liltle Induction. IFIP 1974, Stockholm. [s1 Dijkstra, E, W. Guarded Commands, Nondeterminacy and Formal \nDerivation of Programs, CACM VOI 18, no.8. 197S [61 Dijkstra, E, W. A Discipline of Proffamming. Prentice-Hall. \n1976 [71 Fischer, M.J. and R.L Ladner. Propositional Modal Logic of programs. Proc. 9th Ann. ACM Symp. \non Theory of Computing, Boulder, CoI., May 1977. [81 Green, C. Cordell. The Application of Theorem Proving \nto Question-Answering Systems. Stanford University Computer Science Department Report CS-138. 1969. [91 \nHarel, D. Arithmetical Completeness in Logics of Programs, Submitted for publication. [101 Harel, D. \nOn the Correc~ness of Regular Deterministic Programs; A Unified Survey. Submitted for publication. [111 \nHarel, D. Complete Axiomatization of Properties of Recursi~e Programs. Submitted for publication. C121 \nHarel, D., A.R. Meyer and V.R. Pr,att. Computability and Completeness in Logics of Programs. Proc. 9th \nAnn. ACM Symp. on Theory of Computing, 261-268, Boulder, CoI., May 1977. [131 Harel, D.,. A. Pnueli and \nJ. Stavi. A Complete Axiomatic System for Proving Deductions about Recursive Programs. Proc. 9th Ann. \nACM Symp. on Theory of Computing, 249-260, Boulder, CoI,, May 1977, [141 Hewitt, C.E. Description and \nTheoretical Analysis (Using Schemata) of PLANNER: A Language for Proving Theorems and Manipulating Models \nin a Robot, MIT Al Lab TR-258. 1972. [151 Hoare, C.A.R. Some Properties of Nondeterministic Computations. \nThe Queen s Univ., Belfast. 1976 [161 Kroeger, F. Logical Rules of Natural Reasoning about Programs. \nIn Automata, Languages and Progammin~ 3 (cd. Michelson, S. and R. Milrrer), 87-98. Edinburgh University \nPress, 1976. [171 Manna, Z. Second Order Mathematical Theory of Computation. Proc. 2nd Ann. ACM Symp. \non Theory of Computing, 1S8-168, 1970. [181 Manna, Z. and A. Pnueli. Axiomatic Approach to Total Correctness \nof Programs. Acts Informatica, 3, 2S3-263, 1974. [193 Manna, Z and R. Waldinger. Is sometime sometimes \nbetter than always ? intermittent assertions in proving program correctness. Proc. 2nd Int. Conf. on \nSoftware Engineering, Oct. 1976. [201 Meyer, A.R. Equivalence of DL, DL+ and ADL for Regular Programs \nwith Array Assignments. Unpublished report, Ml l. August 1977. [~1] Milrwr, R.C. An Approach to the Semantics \nof Parallel Programs. Computer Science Dept., University of Edinburgh, U.K. 1973. [221 Pratt, V.R. Semantical \nConsiderations wr Floyd -Hoare Logic. 17th IEEE Symposium on Foundations of Computer Science, 109-121, \nOct. 1976. [~3-J dcRoever, W.P, Dijkstra s Predicate Transformer, Nondeterminissm, Recursion, and Termination. \nI. R. I.S.A., Publication Interne N0,37. 1976, [241 Salwicki, A. Formalized Algorithmic Languages. BraIl. \nAcad. Pol. Sci., Ser. Sci. Math. Astr. Phys. Vol. 18. No. s. 1970. [251 Wand, M. A Characterization or \nWeakest Preconditions. .ICSS 1~, 2. 209-212. 1977. [261 Wang, A. An Axiomatic Basis for Proving Total \nCorrectness of Coto Programs. BIT 16, 88-102. 1976. [271 Woods, W.A. Augmented Transition Networks for \nNatural Language Analysis,. Report No CS-1 to the NSF, Aiken Computation Laboratory, Harvard University, \nCambridge. 1969: \n\t\t\t", "proc_id": "512760", "abstract": "We investigate the principles underlying reasoning about nondeterministic programs, and present a logic to support this kind of reasoning. Our logic, an extension of dynamic logic ([22] and [12]), subsumes most existing first-order logics of nondeterministic programs, including that developed by Dijkstra based on the concept of weakest precondition. A significant feature is the strict separation between the two kinds of nonterminating computations: infinite computations and failures. The logic has a Tarskian truth-value semantics, an essential prerequisite to establishing completeness of axiomatizations of the logic. We give an axiomatization for flowchart (regular) programs that is complete relative to arithmetic in the sense of Cook. Having a satisfactory tool at hand, we turn to the clarification of the concept of the total correctness of nondeterministic programs, providing in passing, a critical evaluation of the widely used \"predicate transformer\" approach to the definition of programming constructs, initiated by Dijkstra [5]. Our axiom system supplies a complete axiomatization of <i>wp.</i>", "authors": [{"name": "David Harel", "author_profile_id": "81100197485", "affiliation": "Massachusetts Institute of Technology, Cambridge, Mass.", "person_id": "PP14078578", "email_address": "", "orcid_id": ""}, {"name": "Vaughan R. Pratt", "author_profile_id": "81100298352", "affiliation": "Massachusetts Institute of Technology, Cambridge, Mass.", "person_id": "PP39036582", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512782", "year": "1978", "article_id": "512782", "conference": "POPL", "title": "Nondeterminism in logics of programs", "url": "http://dl.acm.org/citation.cfm?id=512782"}