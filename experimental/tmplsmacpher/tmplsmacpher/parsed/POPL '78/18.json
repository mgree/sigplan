{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Symposium on Principles of Programming \nLanguage! ALMOST cONTROL-FREE (INDETEWINISTIC) PARALLEL CO~UTATION ON pERMIT SCHEMS Karel &#38;14k The \nPennsylvania State University, University Park, Pennsylvania 16802 1. Motivation and introduction The \nparallelity means simultaneous perfor mance or execution and .it may concern either computer units of \ndifferent sorts (e.g. a rnernory and a processor), or computer units of the same sort (e.g. several processors). \n The computers Illiac 4 and Burroughs Scientific Processor (BSP) (announced recently) have several arithmetic \nprocessors. They are designed for large-scale computations with a special sort of numeric data structures, \ni.e. with large matrices (arrays). Their parallelity concerns naturally and essentially the definitions \nof matrix operations. According to [Br] the software techniques for exploiting the parallelism of the \nBSP con\u00adsists of a vectorization of an usual serial program. There are 16 processors in the BSP which \nare heavily dependent each on the other, because at each instant by each of these pro\u00adcessors just one \nand the same operation may be performed. Therefore a synchronization of all processors is assumed, which \nis the most ir~lpor\u00adtant difference from the concept of p arallel program scheme of [KM], which allows \nto speak about a sequence of particular steps, each of which is represented by execution of particular \nstatements in parallel. In this paper a p arallel computer with mkl processors is assumed, which is \nalso synchronized [Cu 1], but the processors are fully independent each on the other, i.e. on different \nprocessors different operations may be performed at each instant. Further, the parallelity con\u00ad cerns \narbitrary simple data and arbitrary opera\u00ad tions in all generality (and not only matrices). Thus the \ninherent parallelity of any serial pro\u00ad gram should be discovered and used for speeding up the duration \nof computation at most m times, while, the memory space requirements remain unchanged. In [Cu 2] parallel \nflow diagrams were intro duced and further the following ~arallelization (i.e. a computation of a parallel \nexecution sequence of steps) of a serial program, was dis\u00adcussed in two parts: 1) newly permitted state\u00adments \nare determined by a permitter, and then 2) a subset of m (or less) statements is selected from the set \nof all permitted (and not yet selected) statements by a selector. The selected statements are executed \nin parallel on m processors, etc. until all permitted statements are selected (and executed), and the \ncomputation terminates. The permitter and the selector should replace the statement counter of serial \nprograms or flow diagrams, by which is determined which statement should be executed as the next one. \nIt is nuclear whether a suitable hardware tech\u00adnology can be designed to perform as a permitter and selector \nrequire. The linearity of programs is connected with serial computers (having just one processor, thus \nm=l) essentially, and therefore in the following flow diagrams (or yrogrsm schemes) will be used instead, \nbecause they allow a natural and trans parent modification to permit diaw and schemes, which represent \na new sort of computing prescription (not necessarily deterministic algorithms) being a generalization \nof well known binary trees, by which usual arithmetic expres\u00ad sions are represented. It is well known \nthat there is no inherent reason for performing an operation from the numerator of a fraction sooner \nthan an operation from the denominator. This arbitrariness of the order conceals an intrinsic parallelism \nof any expression which contains an n-ary operation with nzz (which corresponds to the fact that the \nvalue of such operation does not depend on the order in which the values of its n arguments were achieved). \nThis obvious fact is less clear when algorithms instead of operations are considered. 2. Permit scheme \nwithout branching and computing process A permit scheme (without branching) PS=W>r,pd,(j,II> is a finite \ndirected graph <V,m~ , where Tcvxv is the set of its permit edges (arrows), provided with Iabellings \npd,$,II of vertices and edges, such that the following requirements are satisfied: (2.1) (i) there exists \nar least one initial vertex (i.e. a vertex in which no edge terminates) ; (ii) there exists at least \none result vertex (i.e. no edge leaves it); (iii) each vertex and each edge belongs to a simple path \nfrom an initial vertex. Let Vinit, Vres be the set of all initial, result vertices, respectively. (2.2) \n(i) pd: V + set of integers; pal(v) is called the permit degree of v ; (ii) pal(v) =0 iff VEVinit and \nif vEV then pal(v) =1 ; res (2.3) (i) $: V+ SymbOpru{INP,OUTP] where SymbOpr is a set of operation symbols \nprovided with an arity of the form f(n) where n>l ; (ii) @(v) =INP iff VEVinit and $(v) =OUTP iff v&#38;V \n; (iii) pd(v)>O + pd(v)=n ~~f $(v) =f(n) (2.4) (i) II:m + set of integers ; (ii) lsU(V, W) spd(w) for \neach (v,w)En (iii) pal(v) JO and l<rspd(v) + there exists WCV such that (w,v)c ir and II(w,v)=r ; (iv) \nVEV + there exists exactly one res w&#38;v such that (W,V)ET , and further II(w,v)=l . An interpretation \nof PS is a mapping int, : {O(v); pd(v)>O and VSV} +Opr , where <Obj,Opr> is a set of (partial) operations \ndefined in a set Obj , such that (Mt f(n)) &#38;Opr is an n-ary operation when f(n)=+(v) (and pd(v)=n>O) \n. Let PSint be the permit scheme PS interpreted under int . A initialization of an interpreted PS is \na mapping init: V. . +Obj ,where .O@~Opr> is the underly?~(pa~~?~l) algebra in which PS is interpreted. \nOne speaks about an initialized Ps int A set IJ*c_v is said admissible (with respect to parallel performance) \nif (2.5) there does not exist a vertex w&#38;V and vertices v, V*EV* , VZV* such that (V,W)EIT , (v*,w)&#38;lT \nand II(v,w)=lI(v*,w) The activity , or computinp process (in time) determined by a permit scheme PS is \ndefined inductively by its computing prescription. A vertex course VC= (VO,V1, . . ..V2). ..) is a finite \nor infinite sequence of sets of selected vertices, which is defined together with sets Wi of~ ermitted \nvertices and sets of yermit i -s as follows: (2.6) (a) To=~o*=df I+, Wo=df Vinit , and V. is selected \nsuch that ~ ZVOCWO ; (b) (i) ml=df{(v,w)&#38;m ; VEVO} and l*=df i ; (ii) I=df (WO-VO) UW1* where W1*=df{VEV; \npd(v)>O and for each r, l<rspd(v) there exists WCV such that (W,V)ET1 and H(w,v) =r] ; (iii) is selected \nsuch that 1 @zvlcwl ; (c) if i>l and mj , W.j and Vj have been defined for j =0,1,. ,.i 1, then (i) i=df(mi-l \n-{(v w) n; Evi-l})umfl where ~i*=df{(v,w)Em ; V&#38;Vi_ll ; i-1 (ii) Wi = (Wj-Vj) uWi* where df .U J=o \nWi*=df{v&#38;V; pd(v)>O and for each r, l~r~pd(v) there exists wEV such that (W,v) emi and II(w,v) =r} \n; (iii) v: is selected such that $*V<CW< ; L 1.1. ; (d) if there does not exist an integer i>l such \nthat Wi=$ then an integer i* must ; be chosen such that Vi=Wi for each i>i* . A vertex course VC= (V \n,V o 1  V2 ) s called main if each set Vi was selected from Wi as large as possible, i.e. if =Wi for \ni i= O,l,... . If each selected set V< of a vertex course Vc= (v ,V . ..) is admissible and if the o \nl  v2 permit scheme under the consideration PS is interpreted and initialized then the computation Comp(vcintyinit) \n= (Valo,Vall, . . ..Vali). ..) is a finite or infinite sequence of sets Vali of values assigned to vertices \nof the form of couples (v,val(v)) where VEV. , which is defined inductively and uses valu~s assigned \nto - Of the form (v,w)>val(v)) as follows: (2.7) (a) Valo=df{(v,init(v)); VEVO} ; ValT*=@ ; o (b) (i) \nVain *= df{((v,w), init(v)); VEVO} ; 1 (ii) {(v,val(v)); VEV1} where  ail = df for pal(v)= n val(v) \n= df(init $(v)) (val(vl)~. . . , . val(vn)) and vrsVo is such that (vr,v)&#38;lT1* and i I(vr,v) =r \nfor each r=l,2,. ..,n ; (c) of i>l and Valj, Valm * have been j defined for j= 0,1,2,. ..,i-l, then (i) \nValT *= df{((v,w), val(v)); Vcv. :_l} ; (ii) Vali = df(, { v val(v)); V&#38;Vi] where for pd(v)=n val(v) \n=d#nt $(v)) (val(vl)}. ..$ val(vn)) and VrEV. such that Jr jp<i is the maximal index such (vr,v)E?Ti \nand II(vr,v) =r for each r=l,2,... ,n . (d) if the computation is finite then the values assigned to \nvertices from Vres (after termination) are considered as result values and a resultation can be defined \nas a mapping res: V +Obj , . res where res(v), vEV is the value res after termination; otherwise an infinite \nsequence of values assigned to result vertices is accepted as the result of evaluation of the vertex \ncourse Vc= (Vo,vl, . . ..vi). ..) of Ps when int initialized by init . In Fig. 2.1 a permit scheme (without \nbranching) PS is represented, the main course of whic~ is finite and its subsets are differentiated by \ndotted lines. PSI evaluates (computes) three arithmetic express~ons: - - -.. , ( [\\ 1 ,- / I \\ f I \n\\ . 1 . k. / o 1 v OUTP \\ /4 \\ ., Fig. 2.1 512 5/2 A ((a+b)*(a-b))/(b**c), e2=(a+b)*(a-b) and 1 = \ne. = (b**c) , respecting fully their common sdbexpressions. Having in mind the usual arithmetic interpretation \nand initializing the verices from V as indicated in Fig. 2.2 (thus putt!?ng a=3, b=2, c=l) the computation \nwith the main course is presented in Fig. 2.2 when reading properly from up to bottom (the assigned values \nof vertices and edges are actually assigned to them in Fig. 2.2). The result values el=5/2, e2=5 and \ne3=2 are obtained as soon as possible, because the main course evaluates PS on the basis execute everything \nthat is permitted. A vertex VEV of a PS is called ~ if (2.8) (i) either VEVinit ; (ii) or VEV-Vinit \nand for each r, l<rspd(v) there exists exactly one vertex WEV such that (W,V)ET and II(w,v)=r . Lemma \n2.1, If each vertex of permit scheme PS=<V,?T,pd,@,II> is good and if T is an acyclic relation then each \nvertex course is J= :s::g;:l:;; vi,... ) is finite, each Vi i=O,l. . . and VinVj=@ when izj for i,J=O,l,. \n. . . Proof. From the goodness follows the admis sibility and from the acyclicity follows the f~,nitness \nand mutual disjointness. Another permit scheme PS2=<V,m,pd,@,II> is represented in Fig. 2.3 and is designed \nin order to characterize Dijketra s 2-semaphor mechanism [Di] . Its main vertex course Vc= (Vo,vl,. ... \nv .,...) is infinite, but periodic with the J period V for i=O,l,. . . (the 2+i v3+i v4+i v5+i particular \nsets V. are differentiated by dotted lines in Fig. 2.3)2 .    - -\\ v /,0 INP INP , , . . Q. ---\u00ad \n.Q I , yf - ), 2 I 1 i v 3+i 5+i Fig. 2.2 Fig. 2.3 178 Using the operation symbols as vertex names \n in PS one sees that f(l), g(i) and h(l) are on f y vertices which are not good in PS2 , and further, \nthere are three cycles (f(2), ~(l) (1)), ~f(l), f (2)), (h(l), ~ (2)) > &#38;3(2), g in PS2 . Thus Lemma \n2.1 is not applicable. Let us consider a PS=<V,~,pd,@,Ii> such that the following requirement is satisfied: \n(2.9) (i) All the vertices of F S which are not good belong to the set of the 1 main vertex course of \nPS ; (ii) If VSV is a vertex which is not goodwit?i respect to r, where l~r~pd(v) , then there exist \nno more than two vertices wl#w* such that (w,v~n , (w*,v)cn, II(w,v)=lT(w*,v)=r and one of them belong \nto V. = V. mit and the other belongs to a cycle. Lemma 2.2. If a permit scheme Ps = <V,m,pd,@,II> satisfies \n(2.9) then each set of selected vertices Vi occuring in a vertex course Vc= (v ,V ) is admissible. O \nl  vi -.. Proof. If v is a vertex which is not good with respect to r , lsrspd(v) and W,W* are the \ncorresponding vertices from (2.9) (ii) then one immediately sees that w and W* never can belong to the \nsame set of permitted vertices. The permit scheme PS2 in Fig. 2.3 satisfies (2.9) and therefore, if \ninterpreted azd initial\u00adized, the computation is defined, which is an infinite sequence (similarly)as \nall vertex courses of PS2 ). Obviously, in this case the resulta\u00adtion is a mapping res: v + Obj (a detailed \npresentation is further).res In Lemmas 2.1 and 2.2 some sufficient con\u00additions were used for the requirement \nthat each set of selected vertices of a vertex course is admissible (and therefore computation may be \ndefined). A necessary condition for the same purpose is as follows: (2.10) Let <V*,n*Y be the subgraph \nof <V,fP such that it contains all vertices and edges which belong to a path (V ,Vl, . . . , 0 Vk) such \nthat v &#38;v. and v does o xnit i not belong to any cycle in <V,n> for :=0,1 ,..., k. If VEV* then v \nis a good vertex. It is clear that the sufficient condition from Lemma 2.2 may be generalized, but it \nis not clear what a necessary and sufficient condition will be for having all selected sets Vi of all \nvertex courses admissible. 3. Determinacy of permit schemes without branching Let us assume a permit \nscheme PS = <V,n,pd,@,ID such that all sets of selected vertices Vi of any vertex course v= . (Vo,vl, \n. . ..vi. . ..) are admissible. If VC*=(VO*,V * ,...) is another 1 .. vi* vertex course and we interpreted \nand initialized PS (thus also vc and VC* ), then computations Comp(vcint ,init) and Comp(vc~nt ,init) \nwill be different (if VC#VC*) but it can happen that their resultations res and res* are the same. If \nthis is true for any possible initiali\u00adzation init one writes Vc . VC* and says int that Vcint and VCY \nare function equivalentlnt under interpretation int . Further it can happen that any two vertex courses \nvc and VC* of a permit scheme int int Ps are function equivalent under int . If int it is true PS is \ncalled deterministic under int . Theorem 3.1. If a permit scheme PS= <V,~,pd,@,Il> (without branching) \nsatisfies one of the following conditions: 1) each vertex v&#38;V is good and m is acyclic, or 2) PS \nsatisfies (2.9), then PS is deterministic under each interpretation. Proof (sketch). Let mvc=(Wo,W1, \n. . ..Wi.. ).) be the main vertex course of PS . Let us assume that a vertex course Vc= (v ,V O l . \n.. vi ...) differs from mvc . In virtue of (2.6)(d) there exists an integer such that WO=V i~(J o Wl=v \n1 .. i-l =vi-l but izvi hich cans (by virtue of (2.6) (c)(iii)) that there exists a vertex Vsw.-v. \nand an index k>i (because by (2.6) each pe;mitted vertex must be also selected sooner or later) such \nthat VEV ~ but Vivh for each h=i, i+l,. ..,l-l . Let us define a new vertex course VC*= (Vo*,V1*,. ..,Vi*). \n..) as follows: if lVkljl for j= O,l,. ..,l,i,l-1,l, hen let i*=dfvi ii-2, . . ..l.k+l,l,. ... v U{v}, \n and i*=df i vk*=vk_ {v} ; if lVkl=l then let Vi*= dfvi for j= 0,1, . . ..l.i+l,i+2,2,. . .,k-l , aid \n-V*= dfViu {v] and Vj*= j=k,k+l,. . . . i dfvji-l According to the assumption that vc and mvc are vertex \ncourses of PS and according to (2.6) it follows that VC* is a vertex course of PS too, because the vertex \nv is permitted in Wi and therefore can be also selected there, thus Vi*CWi . Having in mind such reduction \nof vc to VC* it is possible to reduce (in this way)to the main vertex course mvc in finite number of \nsteps, and therefore it is a base for induction. It is sufficient to prove that Vc=int VC* holds in any \ninterpretation int of PS . There is no difficulty in the case when vc is finite, but the additional condition \n(2.6)(d) is needed if vc is infinite. Thus, let int be an interpretation and init an initialization of \nPS . Then using the assumption that any set of selected vertices of a vertex course is admissible,the \ndefinition (2.7) of computation may be applied. There are two cases: 1) If any vertex of PS is good then \nby (iv) v,v EVinit and V#V1 + a(v,w) # (2.7)(c) on its that placing val(v) in any does set of not depend \nselected a(v ,w ) for any (v,w)sm, (v ,w ) sm. vertices, course on the vertices. and at all, values therefore \nbecause of all on any vertex it depends only previous Fig. such further An 4.1 that addressing of a \nPS need not exist, In is a subgraph of a pemit scheme PS a(k,g) za(h,g) in virtue of (4.1) (i), a(k,f)=ct(k,g) \nby (4.1) (iii) and 2) If PS argument vertex satisfies as in v . If 1) (2.9) then the same is valid for \na good v is not good then finally a(h,f) (4.1) a(k,f) za(h,g) (ii). =a(h,f) which is by (4.l)(ii), a \ncontradiction thus with either VEV is its first occurrence k in vc and therefore v&#38;v.$~ is the \nf~r$t VC* , which ;eans that occurrence in val(v) =val*(v) , because in both courses the same previous \nvertices are used in (2.7)(c). And if VEVk is not the first occurrence in vc then the same is true about \nv&#38;V,* in VC* (which follows from the fact=that v belongs to a cycle), and therefore (2.7)(c) must \nbe applied to the same previous vertices. A vertex VEVi (or the occurrence of v in Vi ) is called g ood \nwith respect to a vertex course Vc= (Vo,vl, . . ..vi>. -. ) of a permit scheme PS if (3.1) (i) either \nv is an initial vertex of PS ; (ii) or pd(v)yO and l$r<pd(v) + there exists at most one vertex wEV such \nthat (W,V)ET , II(w,v)=r and WEV. r where ir<i is the maximal integer with this property. A vertex course \nVc= (v ,V O l . .. v) ..) f a PS is called gc@ if each vertex v with respect to each Vi (such that v&#38;Vi) \nis good with respect to Vc . Obviously, each set Vi of selected vertices from a good vertex course Vc \n. (Vo,vl, . . ..vi . . . . ) must be admissible, and even more: Lemma 3.2, All vertex courses of a permit \ns theme PS (without branching)are good iff PS is deterministic. Proof. The same sort of argumentation \nis used as in the parts 1) and 2) of the proof of Theorem 3.1. 4. Addressing and permit diagrams without \nbranching An addressing of a permit scheme (without branching) PS=<V,r,pd,@,II> is a new label\u00adling of \nits edges U: T + Var , where Var is a set of individual variables (or locations, addresses, registers). \nThe addressing a satisfies the following requirements: (4.1) (i) (v,w)cm , (V ,W)CT and II(v,w)z II(v \n,w) + a(v,w) xa(v ,w) ; (ii) (v,w) s rr, (v ,w)&#38;?r and II(v,w)= II(v ,w) + U(v,w) =CY.(v ,w) ; (iii) \n(v,w)sn, (v,w )cm a ct(v,w)=a(v,w ) ; k h 12 11 f(l) g(2)  !?4 ,,, \\ /\\ / \\ Fig. 4.1 Lemma 4.1. If each \nvertex of a permit scheme PS is good then there existsan addressing of Ps . An addressing a efPS may \nbe defined as follows: let a : V+Var be a one-to.one mapping and let a(v,w) =df a (v) for each (v,w)&#38; \nTr . Lemma 4.2, If a permit scheme PS satisfies (2.9) then there exists an addressing of PS . An addressing \nof PS may be defined as follows: let a : (V-V. =nit)+-Var be a one to-one mapping and let a(v,w) =df \na (v) for each (v,w)E?r such that viVinit ; further if v&#38;V and init there exists WEV-V. which is \nnot good and ~nit such that (v,w) ET, then there exists v*&#38;V. lnit (by (2.)) such that (V*,W)ST , \nII(v*,w)= II(v,w) , and one defines ~(v,w) =df a(v*>w) ~ and finally if each vertex WEV-V such init that \n(v,w)c ir is good then one chooses a new variable xsVar and defines (V,W)=df x and uses (4.1) (iii). \nThe proofs of these lemmas follow directly from the corresponding definitions. In Fig. 4.2 an addressing \nof PSI from Fig. 2.1 is introduced according to Lemma 4.1. In Fig. 4.3 an addressing of PS2 from Fig. \n2.3 is introduced in accordwce with Lemma 4.2. If a permit scheme PS=<V,n,pd,$,lIY is provided with some \naddressing a: n + Var , then Var may be understood as a memory unit of a computer, the arithmetic unit \nof which is the algebra <Obj,Opr> in which PS is interpreted, and a new labelling @ of all vertices by \nusual instructions (statements) of a lower level pro\u00adgramming langu-~ge is defined as follows: (4.2) \n(i) (ii) (iii) VEV init + v(v) = ~f INP a(v,w) where (V,w)cn ; w&#38;v re~ + +(w)= df OUTR a(v,w) where \nwhere (V, w) E Tr ; VEV\u00ad(Vinit Uvres ) and pd(v)=nzl~ + $(v) =df[(o(v)) (a(v1,v),u(v2,v) ,..., a(vn,v)) \n: CX(V,W)] where (Vh,V)en ~(vh,v)=h for h=l,2,, ..,n , and (V,w)s-ir . wINP INP 1 a lb 2 + ( L \\ ( b \nc)INP ) b , The graph structure Perd=<V,n,$> is called permit diagram (derived from the permit scheme \nPS , provided with addressing a ) over the following set of instructions: 1) (input instruction) INPx \nwhere x&#38;Var , 2) (output instruction) OuTpY where y c Var , and 3) (assignment) f@) (x1,x2, ..., \nXn) =: X. where f(n) eSymbOpr , ~>1 and Xj cVar for each j= O,l,. ..,n . In Fig. 4.4 there is represented \nthe permit diagram Perd, (derived from Fig. 4.2) and in Fig. 4.5 is represented the permit diagram Perd2 \n(derived from Fig, 4.3). Il{Pa INPb INPc .. a+b=: d a-b=: e b**c =: y 1 x Y p(~ d*e=: ~ OUTPy Fig. /)lz \nOUTP 4.2 f PEL.-l Fig. zXly=: z OUTPZ 4.4 x i Y / m T1 f(l)(x) =: a ~(l) m 2A (y)=:b \\ h(l)(y) =:C \n1 OUTPX ~(1) (X) : d OUTPy Fig. 4.3 metics (int (int Fig. If one interprets as follows: (int f 2))(a,b)=df \na*b Y(2) )(d,c)=df d*c, 4.5 Perd2 In usual f(1))(x)=A4 2*x , (int g (r~j(y)=df (int h %(y)=df arith\u00ad; \n3*y 5*y , 181 6. Permit diagrams with cycles but without and (intk(l))(x) =df7*x, thenthecorres\u00adpending \npermit diagram Perd3 (over an extended branching set of instructions, because constants 2, 3, 5, 7 Let \nus consider permit diagrams Perd = are allowed also) is represented in Fig. 4.6. <V,n,pd,@,II> which \nsatisfy the following require\u00adments for an arbitrary integer kk2 , and which are represented in Fig, \n6..1 (6.1) (i) there are k vertices Vi,. ..,vk such that pd(vi) 2 for i=l,2,.. .,k , and each other vertex \nv satisfies pal(v) S1 ; (ii) all the vertices l  vk and also further vertices Wl,. ..,wk belong to the \nsame cycle in the order as follows: CYO= (Vl, w1 v2  w2  vk  W~,Vl) , thus, there exists at least \none vertex w. on cY~ between vi and aid (Wi,Vi+l)En for i+l 7 i=l,2 ,.. .,k(mod k) ; (iii) there exist \nk mutally disjoint cyclesOUTPy cY1,. ..,cYk ; each cycle Cyi has IEEI ka-.--l exactly one vertex vi \nin common with CYO and at least one vertex more Fig. 4.6 i belongs to Cyi in the ordering as followings: \nCyi= (vi, . . ..w~.vi) , thus 5. Permit diagrams with acyclic permit relation (W;,vi)cn ; and without \nbranching . - (iv) all the initial vertices are O vl There are two areas of problems which are . and \n(v~,vi)cn, II(v~,vi)= 1 for strongly connected with the concept of permit k diagram with acyclic permit \nrelation. The first i=l,2,. ..,k , and (v;>~l)cm > concerns finding an optimal code for an arith\u00ad rI(v;,v1)=2 \n; metic expression [SU,A.J,AU,AHU, where further literature is presented], and the second area (v) all \nthe result vertices are v: v ,.. ., concern computational complexity of arithmetic and (wi,v~)~n for \nJ % expressions [MP, where further literature is i=l,2,. ..,k . presented]. In any case the approach \nhere (and also in [Cu 3, Cu 4]) is more general and not Theorem 6.1. If Perd satisfies (6.1) thenrestricted \nto very special types of arithmetic each vertex course VC=(V ,.. .,Vi). ..) of Perdexpressions interpreted \nin the usual arithmetics 1 only. % Fig. 6.1 182 is infinite and satisfies the following require\u00ad ments: \n(6.2) (i) if 1 is the smallest integer such that vl&#38;V. then there exist in\u00ad dices i 11<i <... <i.<... \nsuch that Vhcv. /12 iff h=j(mo~ k) for each h=l,2 lj ,...,k and each j=l,2,. . . ; (ii) if IJh* is the \nset of all vertices which belong to Cy. and are between h and v h+l then Vh*CV ij +1 Uv ij+2 u ,.. Uv. \n-1= -l-l where h~j(mod k) and h=l,2,?. .,k ; (iii) if W.* is the set of all vertices whichL1belong to \nCyh and are different from Vh then Wh*CV i.-!-l Uv i.+2 u J J v. +1 ~j +1 U...uv. -1~j +h where h:j(modk) \nfor each h=l,2,. .,,k . Proof (sketch). By (6.1) one sees immedi\u00ad ately (see Fig. 6.1) that in the first \nperiod of vc (to which belong all the first occurrences of vertices) are contained all the initial vertices, \nwhich are not contained in any other period. In each period the ordering of vertices vc is the same as \ntheir 1 v2  vk n ordering on CYO , which proves (6.2)(i). The remaining two assertions (6.2) (ii) and \n(iii) are immediate consequences of (6.1) and of the definition of vertex course (1.6). Permit diagrams \n(or schemes) satisfying the requirement (6.1) for an integer k} 2, and represented in Fig. 6.1, describe \nIk semaphor mechanism as a special sort of periodicity in Theorem 6.1. In the same way as Theorem 3.1 \ncan be proved: Theorem 6.2 If Perd satisfies (6.1) then Perd is a deterministic permit diagram. Among \npermit schemes without branching all the vertices are good it is possible to find many other types with \nperiodic vertex courses, which allow higher permit degrees than 2. Theorem 6.1 can be considered as proof \nof correctness of concurrent process systems presented in [Ha] or ~LS], where Petri nets [Pe, BS~ are \nused. Permit diagrams are more powerful tools than Petri nets, because they allow to differentiate several \nsorts of edges (some further possibilities of this sort are discussed in [Cu 1]). 7. Permit diagrams \nwith branching In fact all permit edges in permit diagrams (or schemes) are data edges [De,DFL where \nfurther .- __ references are presented] concerning the data = values, with which operations should be \nperformed and no ~ow edges, which are only edges occurring in flow diagrams, and which are used for the \n~ontrol (which instruction should .- be executed as the next one) [Cu 5, Grj. From this point of view \ncomputation with permit diagrams without branching is fully control-free, because there are no flow edges \nat all, In virtue of determinacy it is possible to admit a comple\u00adtely indeterministic selection of some \nof permi~ted instructions without changing the resultation of the permit diagram under the consideration. \nEach flow diagram may be easily provided by all its data edges also, when the concept of the scope of \na defining occurrence of a variable in a n a%~igii-rnen? or input s tatern ent is intro-\u00ad~uced [Cu 3, \nAU, Cu 6, Cu 7]. In such a mixed diagram almost all flow edges may be omi~ted, because theyare not needed \nfor the control, but flow edges leaving relation statements (where conditions are checked)jwhich are \nlabelled by truth values,must be kept for differentiating the branching. Thus, these labelled flow edges \nin flow diagrams are used as permit edges, and they,in fact,determine some sort of periodi.city with \nrespect to loops, i.e. flow cycles, which, obviously, require some data cycles too. A complete clarification \nof situation in these mixed diagrams is not achieved yet, REFERENCES AHU] A.V.Aho -J.E. Hopkroft -J.D. \nUnman: The Design and Analysis of Computer Algorithms, Addison-Wesley, Reading, Mass.,1974 &#38; [AJI \nA.V.Aho -S.C.Johnson: Optimal code generation for expression trees, JACM 23, 3 (JuIY 1976), 488-501 iAu: \nA.V.Aho -J.D.Ullman: Optimization of straight line programs, SIAM J. Comput. 1, l(March 1972), 1-19 [Ba] \nJ.W.de Baker: Axiom system for simple Assignment Statements, 1-22, Lecture Notes in Math., No. 188, Springer \n1971 [Br ] W.B.Brainerd: The Burroughs Scientific Processor, a colloquium at Comp.Science Dept. of PENN \nSTATE, Nov. 10,1977 ~BSl E.Best, H.A.Schmid: System of open paths in Petri nets. Proc. Symposium on Math. \nFound. of Computer Science 1975, Lecture Notes in Comp. Science 32. Springer 1975, p. 186-193 ~Cul~ K.;ulfk: \nEquivalence of parallel courses of algorithmic nets and precedence flow diagrams, Proceedings of Symp. \non Math. Found. of Comp. Sciencek High Tatras, Bratislava, September 1973, 27-38 ~Cu2] K.~ulfk: Towards \na mathematical theory of parallel computers (submitted in Acts Informatica))28 p. [Cu3~ K.:ulik: Combinatorial \nproblems in theory of complexity of algorithmic nets cycles for simple computers, IFIP Bulletin, No. \n6 (1970), see also mat. 16 (1971) Prague, 188-202 without -WG Aplikace 2.2 [SUj R.Sethi timal Jour. -code \nACM J.D.Ullman: The for arithmetic 17, 4(Oct. 1970), generation expressions, 715-728 of op\u00ad [Cu4] K,~ul<k: \nmic nets 16 (1971), A note on complexity of without cycles, Aplikace Prague, 297-301 algorith\u00admat. [CU5] \nK.~ul<k: and 18 (1973), Syntactical definitions flow diagram, Aplikace Prague, 280-301 of program matematiky \n[cu6~ K.~ul~k: Algorithmic algebras Proceedings of Symp. on Math. of Comp.Sc. in Warsaw-Jablonna also \nCzech. Math. Jour. 28, Prague 1973, 670-689 of computers, Foundations 1972, see Academia, [CU7] K.~ul<k: \nComputers, Springer Mathematical Informatik 1976, 203-234 Theory of Serial -Fachberichte 1, [De] J.B.Dennis: \nProgramming generality, lelism and computer architecture, ion Processing 68, North Holland, Amsterdam, \n484-492 paral-Informat\u00ad [DFL] J.B.Dennis Data flow Comp.Sc. -J.B.Fossen -J.P.Linderman: schemas, 187 \n216, Lecture 5(1974), Springer Notes in [Di] E.W.Dijkstra: processes. In: ming languages. Press 1968 \nCo-operating Genuys,F. London sequential (cd.): Program\u00ad New York, Academic S.Greibach: Schemes, Notes \nin Theory Semantics, Comp.Sc. of Program Verification, 36(1975), Structures: Lecture Springer A.N.Habermann: \ning processes. Synchronization Corn. ACM 15, of 171-176 communicat\u00ad(1972) J.Ho$ej~: A general programmed \nprocessors the 2nd conference model of \\Czech). of CWT, parallel Abstract Prague 1973 of R.M.Karp -R.E.Miller: \nmata, J.Computer and 147-195 (1969) Parallel System program Sciences 3, schema\u00ad K.Lautenbach, H.A.Schmid: \nproving correctness of systems. In: Information Amsterdam, North Holland Petri nets for concurrent process \nProcessing 74. 1974, 187-191 D.E.Muller of Arithmetic Evaluation, July 1976 and F.P.Preparata: Expressions \n534-543, JACM, for Vol. Restructuring Parallel 23, No. 3, C.A.Petri: Concepts of Symposium on Mathematical \nComp. Sc.,High Tatras, p. 137-146 net theory, Proc. Foundations of September 1973, A.Pnueli: 46-57, Comp.Sc. \n1977 The temporal Proceedings of , Providence, logic 18th R.I. of programs, Annual Symp. October November \nof 184  \n\t\t\t", "proc_id": "512760", "abstract": "The parallelity means \"simultaneous performance or execution\" and it may concern either computer units of different sorts (e.g. a memory and a processor), or computer units of the same sort (e.g. several processors).The computers Illiac 4 and Burroughs Scientific Processor (BSP) (announced recently) have several arithmetic processors. They are designed for large-scale computations with a special sort of numeric data structures, i.e. with large matrices (arrays). Their parallelity concerns naturally and essentially the definitions of matrix operations.According to [Br] the software techniques for exploiting the parallelism of the BSP consists of a \"vectorization\" of an usual serial program. There are 16 processors in the BSP which are heavily dependent each on the other, because at each instant by each of these processors just one and the same operation may be performed. Therefore a synchronization of all processors is assumed, which is the most important difference from the concept of parallel program scheme of [KM], which allows to speak about a sequence of particular steps, each of which is represented by execution of particular statements in parallel.In this paper a parallel computer with m &#8805; 1 processors is assumed, which is also synchronized [Cu 1], but the processors are fully independent each on the other, i.e. on different processors different operations may be performed at each instant. Further, the parallelity concerns arbitrary simple data and arbitrary operations in all generality (and not only matrices). Thus the inherent parallelity of any serial program should be discovered and used for speeding up the duration of computation at most m times, while the memory space requirements remain unchanged.In [Cu 2] parallel flow diagrams were introduced and further the following \"parallelization \" (i.e. a \"computation\" of a parallel execution sequence of steps) of a serial program, was discussed in two parts: 1) newly permitted statements are determined by a permitter, and then 2) a subset of m (or less) statements is selected from the set of all permitted (and not yet selected) statements by a selector. The selected statements are executed in parallel on m processors, etc. until all permitted statements are selected (and executed), and the computation terminates. The permitter and the selector should replace the statement counter of serial programs or flow diagrams, by which is determined which statement should be executed as the next one. It is nuclear whether a suitable hardware technology can be designed to perform as a permitter and selector require.The linearity of programs is connected with serial computers (having just one processor, thus m = 1) essentially, and therefore in the following flow diagrams (or program schemes) will be used instead, because they allow a natural and transparent modification to permit diagrams and schemes, which represent a new sort of computing prescription (not necessarily deterministic algorithms) being a generalization of well-known binary trees, by which usual arithmetic expressions are represented.It is well known that there is no inherent reason for performing an operation from the numerator of a fraction sooner than an operation from the denominator. This arbitrariness of the order conceals an intrinsic parallelism of any expression which contains an n-ary operation with n &#8805; 2 (which corresponds to the fact that the value of such operation does not depend on the order in which the values of its n arguments were achieved). This obvious fact is less clear when algorithms instead of operations are considered.", "authors": [{"name": "Karel &#268;ul&#237;k", "author_profile_id": "81100332723", "affiliation": "The Pennsylvania State University, University Park, Pennsylvania", "person_id": "P348408", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512779", "year": "1978", "article_id": "512779", "conference": "POPL", "title": "Almost control-free (indeterministic) parallel computation on permit schemes", "url": "http://dl.acm.org/citation.cfm?id=512779"}