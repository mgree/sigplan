{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Symposium on Principles of Programming \nLanguages Data Types as Valuee: Polymorphism, Type-checking, Encapsulation? Alan Demers James Donahue \nGlenn Skinner Computer Science Department Cornell University Ithaca, N.Y. 14853 Abstract This paper describes \na novel approach to the treatment of data types in programming languages, which allows a simple interpretation \nof polymor phic or generic procedures, makes a simple set of type-checking rules semantically justifiable \nand provides a straightforward treatment of encapsulation. 1. Introduction One of the goals of research \nIn programming languages is the isolatio~ of the underlying con\u00adcepts of languages, i.e., those basic \nideas that allow us to understand the relations among various language features. This paper presents \na novel aPproach to the treatment of data types (inspired by the work of Scott) that allows us to clarify \nseveral aspects of the design of data type defin\u00ad ition and manipulation facilities in programming languages. \nIn the next section, we show how data types may be treated as second-class values in a lan\u00adguage. While \nnot considering the possibility of data type variables, we treat data types as semantically meaningful \narguments to procedures, functions, and data types. We then show in succeeding sections: 1. how this \nview of data types allows a simple treatment of generic or poly\u00admorphic procedures, preserving full static \ntype checking and having no difficulties with recursion, 2. how a simple rule for type-checking can \nbe justified by our treatment of types and polymorphism, and 3. how a general encapsulation mechanism \ncan be developed as a natural consequence of the basic ideas inherent in a poly\u00admorphic language.  In \nthis we achieve a pleasing economy of concept: from a basic view of data types and some funda\u00admental \nprinciples of language design, we show how t. Th~s work was partially supported by National Science Foundation \ngrant MCS76-14293 and RADC grant #AF 30602-75-C-0121. some rather powerful language constructs can be \nadded to a language like Pascal. Because of this, we argue that the approach captures well the underlying \nconcept of data type . The examples used in this paper are written in the programming language Russell. \nRussell ie syntactically eimilar to CLU [Liskov et al. 1977], Alphard [Wulf et al. 19761 and Euclid [LamPson \net al. 1977]; indeed, many of our design goals were identical with those of these efforts. What is new \nwith Russellr however, is the seman\u00adtic treatment of data types. The thesis of this paper is that the \nnew semantics has served us well. 2. Data Types A central question of language design, especially for \nlanguages like Russell, is What is a data type? That a generally accepted answer has not been reached \ncan be seen by looking at the recent ACM Conference on Data [SIGPLAN 1976], where several varying definitions \nare given. (The paper by Parnas, Shore, and Weiss [1976] is particularly enlightening in this regard.) \nBelow we present an approach, which may be most simply characterized as types are sets of operations, \nand contrast it with the . more common approach: types are sets of values. . . Succinctly, our view \nof data types is the follow\u00ading: A data type is a set of operations specifying an interpretation of values \nof a universal value space. To define what we mean by this, we draw from the work of Scottr whose models \nof the untyped lambda calculus provided the inspiration for this approach. In [1976, 1977] Scott describes \nseveral un\u00adiversal domains (continuous lattices) or value spaces, i.e., domains that contain their own \n(continuous) function spaces. The immediate importance of such domains is that they allow a simple definition \nof languages that allow self application, like the untyped lambda calculus. For example, in the lambda \nexpression Ax.x(x) , the identifier x simultaneously stands for a function and its argument, which makes \nsense only for values in a universal domain. These domains exhibit another interesting characteristic: \nas .SCott shows, they may be viewed both as typeless --i.e. , consisting of only a single type and as \ninfinitely typed --i.e. , as being com\u00adposed of elements of an infinite hierarchy of more and more complicated \ntypes. Thus, we may neatly side-step the question of whether each value belongs to only one type (as \nhypothesized in [Hoare 1972]). In one sense, the question is tautologous, since there is only one type; \non the other hand, we may say without contradiction that a value belongs to infinitely many types. It \nall depends on how we wish to view the domain. Even more surprisingly, Scott shows how data types themselves \nmay be regarded as elements of a universal domain, using the notion of a retract . A retract is a continuous \nfunction f:D+D such that f=+f. Retracts have the property that their ranges are proper subspaces of a \ndomain. Thus , we may consider as the data types of a universal domain either the proper subspaces (subdomains) \nor the retracts of the space with these subdomains as their ranges. But, the retracts of a univer\u00adsal \ndomain are elements of the domain (since the domain contains its function space); thus, the data types \nof a universal domain are themselves values of the domain. The retracts of a universal domain D may be \nviewed as defining how each element of the space may be interpreted (in the sense of bringing out the \nmeaning of ) as a value in the subspace given by the range of the retract. Remember that a retract is \na function f such that f=f f. Thus , a retract f of D collapses D onto the range of f and is the identity \nfunction on each value in its ranger i.e. , f maps each element of D into its image in the subspace given \nby the range of the retract. As was shown in [Donahue 1977, Scott 1976] this use of re tracts as the \nsingle operation interpreting values of a universal space is precisely the notion of data type needed \nto give the semantics of typed lambda calculus variants. But what has this to do with data types in more \ncommon programming languages? A good deal, we argue. We can find natural analogues of universal domains \non von Neumann machines and can treat type definitions in Algol-like languages as sets of operations \ngiving the interpretations of such domains. First, the elegant and attractive universal domains constructed \nby Scott have a homely sister in the memory of most machines. One of Che most obvious characteristics \nof the underlying hard\u00adware of most machines is its typelessness; the same sequence of bits may be used \nto represent logical values, integers, floating point values, and pieces of program that manipulate any \nof the preceding. Moreover, this domain of bit sequences is universal, because of the indistinguishability \nof program and data. More importantly, data types in Algol-like languages can be understood as sets of \noperations giving the interpretation of values of this space. Consider, for example, a language like \nAlgol 60 which has only primitive (non-structured) types (more complicated examples will be seen later \nin the paper) . In such a language, we may store values in variables, extract values from variables, \nand compose values by application of certain primi\u00adtive functions. Our approach to data types takes the \nuniversal domain of bit strings as the value space and the meaning of this set of primitive operations \nover this space as the meaning of a data type. For example, consider the following Algol program fragment: \ninteger x,y; ~ := 0; :=x Y We take as the meaning (or denotation) of integer : 1. The meaning of value \nextraction (so we know which bits of the value of the variable x to use on the right hand side of the \nassignment y := x) , 2. the meaning of assignment (so we know how many bits of the result to store in \ny), and 3. the meaning of the nullary function O  (i.e., which bit sequence represents o) . TWO points \nneed to be raised here. First, although we discuss a particular universal domain in this paper, our approach \nis not limited to any particular domain of values; Scott s l% model would do just as well. (Sequences \nof bits do have an intuitive appeal, however.) Second, what set of operations provides an interpretation \nis obviously a language-dependent matter. Retracts are sufficient for the lambda calculus, while a more \ncomplicated set is required for Pascal. But the basic approach works in both cases. This approach to \ndata types is obviously similar to the idea of algebraic specification described by Guttag [1975, 1977] \nin its focus on the set of operations provided by a type. It differs from the algebraic view of types \nin two important aspects: 1. The use of a universal domain does not appear in the algebraic approach. \nThis makes our approach somewhat more concrete, but it is necessary to the rreatment of data types aa \nvalues. 2. The algebraic approach seems most useful in considering properties of user-de\u00adfined data types. \nOur approach is motivated from a more general interest in understanding data types in a wide variety \nof languages, including those like Algol 60 or typed lambda calculi that have no type definition mechanisms. \nThus , the set of operations comprising a type using our approach includes pri\u00admitive operations like \nvalue extraction that would not appear in algebraic specifications. is affected by our view of data types. \nThis approach has a less obvious connection with the more common types are sets of values approach, but \nwe can find a way to treat our set of operations as defining set of values through the use of another \nretract. If we use the standard mathematical semantics (cf. , [Milne and Strachy 1976]) meaning for the \nvalue ex\u00adtraction and assignment operations, e.g., value extraction is defined by a function Hold(l) \n(S) for seS=L+V and !?,EL and assignment is defined by a function Update(L) (v) (s) for VEV (where V \nis the domain {0,1}*), then we must have that for all !, and s, ~v.Hold(i) (Update(L)(v) (s)) (of type \nV+V) must be a retract. And the range of this retract has a natural interpretation; it is the set of \nvalues which may be legally assigned to variables of the type (i.e., the definition of data type given \nin [Jensen and Wirth 1975]). For example, if we decide to represent integers by 32-bit values, then the \nrange of this retract for the type integer would be {0,1}32. We have now described what is meant by universal \nspace and set of operations providing an interpretation, i.e. , we have said what we mean by data type \n. But have we gained anything by adopting this approach? Yes, we now have a means of handling types as \nparameters to proce\u00addures, function, or types independently of any particular type argument. Consider \nthe Pascal\u00adlike definition function Identity (type t; val x:t) :t; Identity := x end where we have parameterized \nIdentity with res pect to a type t. The meaning of the parameters can now be understood as follows: 1. \nThe value parameter x is simply seen as standing for some value from the universal domain of bit strings, \nwhich will be interpreted in the body of the function as an element of a particular subspace, and 2. \nthe type parameter t stands for an in terpretation of the elements of univer\u00adsal space, i.e., the set \nof operations used within the body of Identity. And this set of operations can be treated as just the \nnatural extension of procedure and function parameters already allowed in many existing languages.  \nSo, we can now give a meaning to type-parameterized constructs independent of any particular arguments \napplied to these constructs. In the next section, we consider this point in more detail, giving the syntax \nand semantics of polymorphic constructs in Russell. As we show in Section 4, this view of data types \nalso allows us to adopt a simple rule for determining type compatibility. And in the final section of \nthe paper, we show how the Russell treatment of encapsulated data types 3. Polymorphism In this section \nwe continue the discussion of polymorphism begun in Section 2 by giving specific details of the syntax \nand semantics of polymorphic constructs in Russell. We begin by discussing procedures only, then show \nhow the extension to polymorphic type definitions can be made in a straightforward way. The syntax of \npolymorphic procedures in Russell is similar to that used in CLU or Alphard. Details important to our \ndiscussion are illustrated by the following procedure: proc Update( type Ta with(  function f (Ta) : \ninteger; var field Cnt : integer; ); var A : array 1..n of Ta  ); for i : l..n loop A[i].Cnt := A[i].Cnt \n+ f(A[i]) end end Update The syntax of the body of a polymorphic procedure is no different from that \nof a nonpolymorphic procedure body, and should present few problems. The only new elements are the type \nparameter and its associated with -clause. The type parameter, naturally enough, specifies that the corresponding \nargument must be a data type value. The with clause lists those operations which must be provided by \nthe type argument in any legal call. In particular, the with clause for Ta in Update requires that any \ntype argument supplied for Ta include a function f map\u00ad ping values of the type to integers, as well \nas an integer field Cnt. Other operations which can be specified in a with list include declaration (Q) \n, assignment (:=) , and equality (=) . A field is treated as a selector function returning left\u00adhand \nside values; thus, the inclusion of a field in a type parameter specification is not inconsis\u00adtent with \nour basic view of a type as a set of operations that interpret values in a universal domain. Constructs \nsimilar to the with specification appear in other languages: for example, the <> notation in Alphard \n[Wulf et al. 1976] and the where -has . .. specification in CLU [Liskov et al. 1977]. The most obvious \npurpose for these constructs is to allow the body of a polymorphic procedure to be type checked only \nonce, independent of any arguments which may be supplied in calls of it. The procedure body is type-checked \nin the usual way, under the assumption that the only operations supplied by the type parameter are those \nlisted in its with specification. (For now, we rely on the reade~intuitive understanding of the usual \nway of type-checking. This point is discussed in Section 4.) Procedure calls are checked to ensure that \neach type argument includes at least those operations listed in the corres\u00ad 25 pending with clause. our \ngoal of economy demands, however, that with should have a semantic purpose as well; other\u00adwise we should \nsurely be charged with overburden\u00ading the user with purposeless syntax. And our treatment of data types \ngives with an obvious meaning in the terms of the transmission of data type arguments to procedures. \nWithin the body of a polymorphic procedure, a type parameter denotes a type value --that is, a set comprising \nthose operations specified in its with clause. An acceptable argument provides those operations and perhaps \nothers as well. The semantics of argument transmission in Russell re\u00adquires that the type argument be \ntransformed to match the parameter specification. Of course this transformation is straightforward: it \nmerely in\u00advolves selecting from the type argument just those operations listed in the with-clause. Thusr \nthe with clause has both syntactic and semantic im\u00adportance: syntactically, it allows static type\u00adchecking \nof polymorphic procedures; semantically, it specifies the transformation to be performed on a type argument \nwhen it is passed. Except for this transformation, which can be viewed as a very simple form of coercion, \npassing a type argument is not essentially different from passing any other kind of value. The treatment \nof polymorphism in Russell, which follows directly from our approach to data types, has several advantages \nover the more obvious approach of treating a polymorphic proce dure as a macro or procedure scheme and \nex panding it for each call. Most obviously, we are permitted to type-check the body of the procedure \njust once, not for each call. More important, however, is the gain in conceptual economy. Since data \ntypes are values, parameterization of a pro\u00adcedure with respect to a data type is no different from parameterization \nof a procedure with respect to any other value. We do not macro-expand or\u00addinary procedures (except as \nan optimization measure)andr given the right interpretation of data type, there is no need to macro-expand \npolymorphic ones. This symmetry of polymorphic and non\u00adpolymorphic procedures also allows us to know \nthat recursive polymorphic procedures present no special difficulties, either in type-checking or implemen\u00adtation. \n(As Gries and Gehani [19771 show, this is not true using the macro expansion approach.) And, just as \nwe may pass nonpolymorphic procedures as arguments to other procedures, we may pass polymorphic procedures \nas arguments (something we at first were surprised to discover) . We close this section with a brief \ndiscussion of polymorphic type definitions. How easily can we extend our polymorphic procedure mechanism \nto allow definitions like the ubiquitous polymorphic stack: type Stack (type t with (dcl, :=)) . . . \nend The answer can be seen in our definition of a type as a set of operations . . . . Since we already \nhave the ability to define polymorphic operations, no semantic extension is required at all! A polymorphic \ntype definition is simply a general\u00adization of a polymorphic operation (i.e. , proce\u00addure or function) \ndefinition, in that it defines a set of operations rather than a just single one. The only minor technical \ndifference is that a type definition must also provide meanings for opera\u00adtions like declaration and \nvalue extraction, which the programmer cannot define explicitly. But the basic idea remains unchanged, \nagain advancing our goal of economy. 4. Type-checking In the preceding sections, we have assumed the \nreader was willing to tolerate an informal treat ment of type-checking. In this section, we show how \nthe need for syntactic type-checking can be motivated from our approach to data types and how a particular \nrule of type-equivalence follows from the treatment of polymorphism in the language. Type-checking refers \nto the common context\u00adsensitive restrictions placed on programs based on the compatibility of the type \nattributes of identifiers and expressions. For example, the Russell program fragment var x : integer; \nvar y : Boolean; Y := true; ~:=y is said to be illegal because of the incompatibility of the type attributes \n(integer and Boolean) of and y. In [1977], Gannon shows that such type\u00adchecking rules serve as an effective \nmeans of re\u00adducing the frequency of errors in programs. How\u00adever, viewing type checking as a redundancy \nmechansim leaves open the question of how much type-checking should be performed. Belowr we give an answer \nto this question based on our approach to data types. Remember our earlier description of data types \nas providing interpretations of values of a univer\u00adsal space. Because of the typeless nature of such \na spacer any operation may be applied to any value in the space. However, were we to ignore type in\u00adcompatibilities \nin Russell programs, our language would allow programs with representation depen dent semantics. For \nexample, the value printed by following program fragment would depend on which value in the universal \nspace was used to represent the Boolean true: var x : integer; var y : Boolean; Y := true; x := Y; print \nx (Exactly this effect may be achieved using EXTERNAL procedures in some PL/I implementations.) Certainly \nwe wish our semantics to be free of such dependencies if only to allow the implemen\u00adtor as much freedom \nas possible. In [Donahue 1977] we were able to show that type-checking is suffi\u00adcient to guarantee representation \nindependence. 26 And the forthcoming thesis of Skinner contains a proof that checking syntactic type \ncompatibility (along with a careful treatment of union types) is sufficient to guarantee representation \nindepen\u00addence of Russell semantics. The question of when the type attributes of two variables compatible \nis somewhat confused by the introduction of type declarations. Considerr for example, the following Pascal \nfragment: type t = integer; var x : integer; var y :t; := x o; :=x Y Is this program well-formed, i.e., \nshould the assignment y := x be allowed? Various answers to this question have been presented in the \nlitera\u00adture: 1. The Pascal Report, interestingly, says nothing about this question one way or the other. \n 2. The Euclid Report [Lampson et al. 1977] states that the program is correct (a type name is regarded \nas a synonym for its definition) . 3. The designer of Alphard regard the Alphard equivalent of the preceding \nprogram as type-incorrect [Wulf 1977].  In Russellr we have adopted the Alphard approach; each type \ndefinition specifies a distinct type. Thus, we regard two type attributes as compatible iff they are \nthe same type identifier (or, for para\u00admetrized types, the same type identifier applied to compatible \narguments). As we argue below, this choice is not at all arbitrary; in fact, it is demanded by our view \nof data types and polymorphism. The justification of our particular appxoach to type-compatibility follows \nfrom the principle of correspondence suggested by Tennent [1977]. This principle is that declarative \nand parametric forms should be semantically equivalent. Thus, in the context of the question at hand, \nthe program fragment: ~ t = integer; var x : integer; var y :t; := x o; :=x Y should be semantically \nequivalent to procedure p(type t with (Q, :=)); var x : integer; var y :t; x. .= o; .= Y-x end p; ~(integer) \n where we have simply replaced the declaration of t with the parameterization of the following block \nwith respect to t. (Note that in doing the transformation we also must make explicit those operations \nprovided by t.) The reasons for adopt\u00ading this principle is economy. There is no over\u00adriding reason to \nregard the two mechanisms as dis tinct, so we are well advised to make sure that we keep them identical. \nThe ramifications are twofold. First, we must regard a type declaration of the form type t =t as having \nthe following semantics: the meaning of t(i.e., the set of operations it provides) is taken from the \nmeaning of t . Also, a progr~ must have a meaning independent of what type appears on the right-hand \nside of a type declaration, as long as the type provides the operations necessarY to Per\u00adform the evaluation \nof the body of the program. This means that for the program fragment given above where the only operaticmsused \nare variable declara\u00adtion and assignment, there should be no fundamental difference between the program \nfragment beginning with type t = integer and the same fragment beginning with ~ t = Boolean since both \nprovide the necessary operations used in the body of the fragment. Put another way, if we look at the \npolymorphic procedure procedure P(= t with(dcl, :=)); . var x : integer; var y :t; x :=o; y:=x end p, \n the types integer or Boolean (or any other type providing the operations of declaration and assign\u00adment) \nwill be acceptable arguments to p. The second point is that the program frag\u00adment given above must then \nbe type-incorrect. The program only seems correct because of the declaration of t as the same as integer; \nshould t be declared as anything else the program must be invalid if we are to hope to achieve a repre\u00adsentation \n independent semantics. Otherwiser we would allow implicit coercions between integers and whatever t \ns were. But, because of our treatment of type declarations, we may not depend on the identity of t and \ninteger any type other than integer providing the same operations must be treated similarly. So, the \nprogram must be incorrect. Note that were we to adopt the macro expansion view of polymorphism discussed \nin the previous section, the Euclid rule of a type name is a synonym for its definition would become \nthe more natural interpretation of type\u00adcompatibility. Using this rule just as type t = integer; var \nx : integer; gy!t! x o; := :=xY is type-correct, while type t = Boolean; var x : integer; var y :t; X.o;.= \n:=x Y is type-incorrect, so one call of a polymorphic procedure could be considered type correct, while \nanother call might be type-incorrect. This suggests one reason to prefer our view of types and polymor\u00adphism \nto the macro expansion approach. It allows a more abstract treatment of type checking and polymorphism. \nAny call of a polymorphic procedure for which the argument and parameters match is correct, independent \nof the identity of the argument. Furthermore, the rule that type attributes of two variables are compatible \niff they are identical is a particularly elegant and simple rule. The alternative requires much more \nspace to state precisely, cf. [Lampson et al. 1977, pp. 31-321). 5. Encapsulation A type encapsulation \nfacility allows the separation of a concrete realization of an ab\u00adstract type from its use in a program \n[Wulf et al. 1976, p. 7]. Thus, the facility s primary function is one of access control - it enables \nthe programmer to specify which operations are avail\u00adable to the abstract program and which are known \nonly within the type definition itself. Then the significant question to answer in language design is \nwhat rights shQuld w should not be hidden from the user of a type to make data types truly abstract. \nFor example, both CLU and Alphard include the notion of the representation of an encapsulated type. Specification \nof a type s representation is separated syntactically from the specification of its operations, and all \ndetails of the repre\u00adsentation are automatically hidden from the ab\u00adstract program. As a consequence, \na degree of repre sentation independence is encouraged: the abstract program has no access to details \nof representation, and so cannot depend on them directly. The intent is that representations for distinct \nabstract types defined in a correct program can be chosen arbitrarily and independently. Type encapsulation \nin Russell is closer in spirit to [Koster 1976] or Euclid [Lampson et al. 1977] : anything declared within \na type definition can be exported or hidden and there is no explicit representation component of a type \ndefinition. An encapsulated type definition has the basic form: ~ <id> capsule exports (<export-list>) \n<declaration list> end The exports-list is syntactically and, as we shall see, semantically identical \nto the with list occurring in a type parameter specification. Thus , fields (i.e., components of the \ntype s representa\u00adtion) as well as operations can be exported. A fundamental advantage of our export \nmechanism is that it can be defined without intro\u00adducing any new semantic ideas. Given our view of types \nand polymorphism, we can treat the exports clause in a capsule declaration as semantically equivalent \nto a type parameter specification in a Polymorphic procedure. The details are given below. By doing this \nwe gain conceptual economy and maintain a pleasing symmetry between declaration and parameterization. \nWe illustrate with an example taken from [Jones and Liskov 1977]. The example involves an abstract type \nBank Account providing a nat ural set of operations for deposits, withdrawals, account number determination, \netc. The problem is to write a procedure which sorts an array of Bank Account values by account number, \nbut is prevented from reading or altering any account balance.+ Consider first a Russell implementation \nof the Bank Account type itself. In skeletal form, the implementation would appear as follows: type Bank \nAccount capsule exports (dcl; := ; proc Deposit (...); proc Withdraw (...); readonly Field AcctNo : int) \nend Just as in Alphard or CLU, this declaration separates the program into an inner region, in which \nall details of the type s representation are known, and an outer region, in which the type is viewed \nabstractly and only those operations listed in the exports clause are available. As declared above, the \nabstract type Bank Account provides operations such as With\u00addraw which can read and modify an account \nbalance. Our task is to write a procedure AcctSort which can manipulate Bank Account values (in order \nto sort them) but is prevented from accessing their balances in any way. This requires that offending \noperations like Withdraw be hidden from AcctSort in much the same way that details of representation \nare hidden from the abstract pro\u00adgram. The solution in Russell is to make AcctSort a polymorphic procedure \nand supply the BankAccount type as an argument. The AcctSort procedure itself looks like: proc AcctSort \n(type Acct with (:=; readonly field AcctNo :\u00advar A : array [l_..n] of Acct) <body of AcctSort> end t \n[Jones and Liskov-1977] is a discussion of pro\u00adtection rather than encapsulation. Evidently, many of \nthe me issues arise, especially given our view of encapsulation as selective hiding. The interested reader \nis invited to compare their solution with ours. The essential difference lies in their treatment of access \nrights as separate entities. Their AcctSort procedure can sort an array of BankAccount values, provided \nthe right to access the AcctNo function is preSeIIt; ours can sort an array of any type, provided the \ntype supplies an AcctNo field. 28 The calling program contains: for the design of Russell. In conclusion, \nwe re\u00ad turn to the main thesis of this paper -\u00ad that this var B : array [1.. n] of BankAccount; approach \n1S a useful tool in language design. We strongly believe in the exhortation that [the language designer \ns] task is consolidation, AcctSat (BankAccount, B) not innovation. [Hoare 1973]. For us, this has meant \ntrying to find a small set of basic ideas that would allow us to understand existing languages and to \njustify or validate our design decisions in Russell. These we recapi\u00adtulate below: Just as with the original \ndefinition of BankAccount, we can identify two distinct views 1. Our treatment of data types allows a \nof the type: simple means of handling polymorphism. Types are values and thus legal arguments in the \ncallinq procedure, all properties of to procedures, functions, or types. the (abstract) type BankAccount \nare known Moreover, as we argued in section 2, our view of types incorporates that of in the body of \nAcctSoct., the only available types as sets of values; it just depends operations, namely := and AcctNor \nare on whether you look at the retract or those explicitly listed in the with clause its range. of the \nparameter specification. 2. The idea of a representation independent These two views of the type correspond \nexactly to semantics, discussed in section 4, is the inner and outer views provided by a cap-the justification \nfor the requirement sule definition. Thus , the definition of en-of type-checking (thus leading to a \ncapsulated types requires no new semantic notions -theorem to show the correctness of our the necessary \nmachinery is already provided by type-checking rules). our view of polymorphism. We can treat an en\u00adcapsulated \ntype definition as syntactic shorthand 3. The principle of correspondence is the for an equivalent type-parameterized \nconstruct justification of our rule for type obtained using exactly the same program trans-compatibility \nand a touchstone for formation discussed in Section 4 in connection validating the treatment of type \nwith type equivalence. The program: declarations. type T capsule exports (<export-list>)) It is in the \ndesign of capsules that most <capsule body> of this work payed significant dividends. First, end we were \nassured that: <program body> 1. Type parameters to capsule definitions is exactly equivalent to the program \nwhich re-could be allowed. As both CLU and sults when the <program body> is parameterized Alphard indicate, \ntype parameters are a with respect to T and then the definition of T necessary aspect of a truly general \ntype is supplied as an argument: definition facility. We knew in advance that these could be handled, \ngiving us proc P (type T with (<export list>) one less ball to juggle. <program body> end 2. Capsule \ndefinitions would not affect the type T capsule exports (all)type-checking rules of the language. By \n<capsule body> our appeal to the principle of corres\u00adend pondence, the rule for type-compatibility G \n) is formulated independently of what may appear to the right of the equal sign in We believe this approach \nyields greater a definition of the form elegance and simplicity than could otherwise be achieved. There \nis a single set of rules type t=... (and a single syntax) for describing and limiting the set of operations \nprovided by a type. In Thus, whatever form capsules eventually addition, we maintain an exact correspondence \ntook we knew that their introduction between our declarative and parametric mechan-should not cause us \nto alter the type\u00adsims: the access control available at capsule checking rules. In fact, had we been \nboundaries is in no way different from that forced to make capsules a special case, available for type \nparameter specification. we should have known immediately that our design had gone awry. 6. Conclusions \nSecond, OUK success in achievin9 con\u00adsolidation is reflected in the degree to which We have described \na new approach to the we may explain capsules in terms of types and treatment of data types in programming \nlanguages polymorphism. Data types are sets of operations; and discussed the implications of this approach \n29 capsules merely provide a means to collect opera\u00adtions together to form a set, i.e., to declare user-defined \ndata types. Type-matching in polymorphic operations allows us to forget some operations included in the \nargument type; exports lists in capsules simply provide a syntactic shorthand for a comnon use of this \ngeneral mechanism. Thus , we claim capsules are not innovative in two senses: 1. They are similar to \nCLU clusters, Alphard forms and Euclid modules. Reveling in one s similarity with one s competitors may \nseem curious, but part of our goal was to develop ideas to simplify and generalize the work of others. \nThus, we would be most uncomfortable had capsules been completely innovative. 2. They may be understood \nwithout the in\u00adtroduction of major intellectual baggage; all of the ideas needed are present in other \nparts of the language. Thus, a valid test of the correctness of our de sign becomes how little additional \nwe need to explain capsules (or indeed any other particular feature of the language).  We are presently \nwriting an informal Russell Report and a formal semantics for the language, which will appear in Skinner \ns thesis. Our goal is to guarantee that the entire language shows the same adherence to first principles \nas that part of it described above. REFERENCES: [Donahue, 1977] James Donahuer On the Semantics of Data \nTypes, Cornell Department Computer Sciencer TR-77-311, June 1977. [Gannon, 1977] J.D. Gannonr An Experimental \nEvaluation of Data Type Conventions , CACM 20:8r Augustr 1977f 1?. 584. [Gries and Gehani, 1977] David \nGries and Naraj.n Gehanj. ~~Some Ideas on Data Types in High-Level Languages , CACll 20:6, June 1977, \np. 414. [Guttag, 1975] John W. Guttag, The Specification and Applica\u00adtion to Progrming of Abstract Data \nTypes, University of Toronto Technical Report C~RGI-59, Septemberr 1975. [Guttag, 1977] John Guttag, \nAbStraCt Data Types and the Development of Data Structures , CACM 20:6, June 1977, p. 396. [Hoare, 1972] \nC.A.R. Hearer Notes on Data structuring , in Dahl, Dijkstra, and Hoare, Structured Programming, Academic \nPres6, 1972. [Hoare, 1973] C.A.R. Hoare, Hints on Programming Language Design , Conference Record of \nSIGACTISIGPLAN Symposium on Principles of Programming Languages October, 1973. [Jensen and Wirth, 19751 \nKathleen Jensen and Niklaus Wirth, PASCAL User Manual and Report, Second Edition, Springer-Verlag, 1975, \n[Jones and Liskov, 1977] Anita K. Jones and Barbara H. Liskovr A Langu\u00adage Extension for Expressing Constraints \non Data Access , C.M.U. Technical Report, April, 1977. [Koster, 1976] Cornelis H. A. Koster, Visibility \nand Types , in [SIGPLAN, 19761, P. 179. [Lampson, et al, 1977] B.W. Lampson, J.J. Horning, R.L. London, \nJ.G. Mitchell, and G.L. Popek, Report on the Programming Language Euclid, SIGPLAN Notices 12:2, February \n1977. [Liskov, et al, 19771 Barbara Liskovr Alan Snyderr Russel Atkinson, and Craig Schaffert, Abstraction \nMechanisms in CLU , CACM 20:8, Augustr 1977, p. 564. [Milne and Strachey, 1976] R. Milne and C. Stracheyr \nA Theory of Program\u00adming Language Semantics, Halstead Press, 1976 . [Parnas, Shore, and Weiss, 1976] \nD,L. Parnas, John E. Shore, and David Weiss, Abstract Types Defined as Classes of Variables in [SIGPLAN, \n1976], p. 149. [Scott, 1976] D. Scott, Data Types as Lattices , SIAM J. Computing 5:3, September, 1976. \n[Scottr 1977] !,Logic and programming Lan9ua9es , D. Scottr CACM 20:9, September, 1977. [SIGPLAN, 19761 \nProceedings of CONFERENCE on DATA: Abstractionr Definition and Structure,SIGPLAN Noticesr Volume 21, \n1976 Special Issue. [Tennent, 1977] R.D. Tennent, Language Design Methods Based on Semantic Principles \n, Acts Informatica 8:2, 1977, pp 97-112. [Wulf et al, 1976] William Wulf, Ralph London, and Mary Shaw, \nAbstraction and Verification in Alphard: Introduction to Language and Mqthodologyr USC\\TSI Research Report \n76-46, June 1976. [Wulf, 19771 William Wulf, private cormnunication. 30\n\t\t\t", "proc_id": "512760", "abstract": "This paper describes a novel approach to the treatment of data types in programming languages, which allows a simple interpretation of \"polymorphic\" or \"generic\" procedures, makes a simple set of type-checking rules semantically justifiable and provides a straightforward treatment of encapsulation.", "authors": [{"name": "Alan Demers", "author_profile_id": "81100529925", "affiliation": "Cornell University, Ithaca, N.Y.", "person_id": "P12363", "email_address": "", "orcid_id": ""}, {"name": "James Donahue", "author_profile_id": "81100145919", "affiliation": "Cornell University, Ithaca, N.Y.", "person_id": "PP43116770", "email_address": "", "orcid_id": ""}, {"name": "Glenn Skinner", "author_profile_id": "81100245851", "affiliation": "Cornell University, Ithaca, N.Y.", "person_id": "PP14094381", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512764", "year": "1978", "article_id": "512764", "conference": "POPL", "title": "Data types as values: polymorphism, type-checking, encapsulation", "url": "http://dl.acm.org/citation.cfm?id=512764"}