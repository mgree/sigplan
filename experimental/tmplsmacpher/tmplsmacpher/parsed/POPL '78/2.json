{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 COnfc3reIICe Record of the Fifth Annual ACM Symposium on Principles of Programming \nLanguages Clauses: Scope structures and defined functions in Lucid E.A. Ashcroft Computer Science Department \nUniversity of Waterloo and W.W. Wadge Computer Science Department University of Warwick ABSTRACT In this \npaper we describe how Lucid can be extended to allow user defined functions and scope conventions, i.e. \nconventions for limiting the range or scope of the validity of definitions. This is done using new constructs \ncalled clauses which are similar in form to the blocks and procedure declarations of Algol-like languages, \nbut are nevertheless strictly non imperative, because a clause is actually a compound assertion, i.e. \nan assertion formed, as a program is, by combining a collection of assertions. Each type of clause (there \nare four) has a straightforward mathematical semantics together with its own characteristic manipulation \nrules for general program massage. In addition, the informal operational view of (some) Lucid programs \n(described in a previous paper) can be extended to give an (incomplete) operational understanding of \nthe effect of the clauses. In this framework a compute clause defines a block; a mapping clause defines \na conventional (pointwise) function; a produce clause defines a block with persistent memory (or an anonymous \nprocess or actor ); anda function clause defines a sort of procedure with own variables (or a general \nkind of coroutine). INTRODUCTION Lucid is a nonprocedural or denotative language; a Lucid program is \nan assertion or set of assertions defining its output, rather than a set of commands which some machine \nmust obey in order to produce the output. Lucid is by no , means the first such language; the distinction \nbetween imperative and denotative languages, and the advantages of the latter, have been well understood \nfor at least a dozen years (see Landin [51). Up until now, however, denotative languages have been almost \nuniversally regarded as elegant curiosities, the playthings of academics unfit for real programming. \nThe Lucid project is an attempt to demonstrate that this view is unwarranted, that denotative programming \ncan be practical, and that in some respects it need not be so radically different from conventional well \nstructured programming. Objections to denotative languages are all based on the supposedly obvious fact \nthat denotative programs cannot be executed, and that they give rise to no activity (other than function \ncalling); in other words, that they have no operational meaning. Thus iteration, for example, is supposedly \nimpossible because it is an operational concept: assignment is necessary (to update loop variables) and \ntransfer is needed (to go back and start another iteration, and to exit on completion) . Furthermore, \ndenotative languages must (so goes the reasoning) be inherently inefficient, because their implementations \ncannot take advantage of various operational shortcuts such as the moving of constant expressions outside \nloops or sharing of variables; and finally, it is argued, denotative languages must always be cumbersome \nbecause they lack the rich variety of constructs found in imperative languages: the for\u00adloops, case statements, \nmultilevel exits, own variables and so on, all of course invented to bring about a desired operational \neffect . The denotative programmer, on the other hand, is supposedly restricted to recursive function \ndefinitions, so that his languages can never be anything more than syntactically sugared variants of \nthe A-calculus. The first version of the Lucid language, (as described in [1], henceforth referred to \nas Basic Lucid ) refuted some of these objections by showing that a well-structured form of iteration \ncan be expressed very naturally in a denotative framework. But even more, we showed that it is indeed \npossible for denotative programs to have operational interpretations. The operational semantics for Basic \nLucid (actually for a subset thereof) can be used informally as a guide to the programmer, but it can \nalso be made precise, and used as the basic of an implementation, for example a compiler. Of course, \na Programming language needs much more than a facility for iteration if it is to be practical, and in \nparticular it needs facilities which allow programmers to restrict the scope of variables, and to define \ntheir own functions. In this paper we present an extension of Basic Lucid which has these features. We \ndefine the new constructs , their mathematical semantics and the class of programs, and give the (derived) \nmani\u00adpulation rules for verification and transformation of programs. 17 CLAUSES nested. Lucid has constructs \nfor structuring programs analogous to the blocks, while-loops and procedure declarations of Algol-like \nimperative languages. These constructs are called clauses. Clauses are used in programs to define data, \nfunction or mapping variables, but, in the more general framework of the formal theory, a clause is a \ncompound assertion, i.e. an assertion built up by combining a collection of assertions. Produce clauses \nThe simplest type of clause is the produce clause. A produce clause is used to limit the scope of certain \nvariables so that the same variable can be used in different places with different meanings. A produce \nclause has the form produce <data term> using <variable list> <set of assertions> end The <data te~> \nat the head of the clause is the subject of the clause, the <variable list> is the global list, and the \n<set of assertions> is the body of the clause. The variables occurring in the global list are the global \nvariables of the clause. The special variable output (which must not appear on the global list) and any \nother variable not on the global list, but occurring free in an assertion in the body of the clause, \nis called a local variable. Here is a simple example produceDroot _ ~,~z~., output = ( B + fi)/(2 A) \nend Here, A , B and C are the global variables and output and D are the local variables. If this clause \nis in a program, the definition of D in the clause is not valid outside it, although the definitions \nof A , B and C are available inside the clause. This is because semantically a produce clause is an assertion \nabout the subject and the globals of the clause, Inside the clause the special local data variable output \nrefers to the subject. The clause, considered as an assertion, is true iff there exist values for the \nlocal variables which make all the assertions in the body true when output has the value of the subject \nterm. Thus the meaning of a produce clause is independent of the choice of local variables. For example, \nwe could have used E instead of D is the clause above. A produce clause is used in a program as a pseudo-equation \ndefining its subject. When used this way, the body of the clause must (as in the example) be a subprogram, \ni.e. a set of equations and clauses defining output and other local variables in terms of each other \nand the globals (for more details see the next section). In particular, local variables can in turn be \ndefined by other produces, i.e. produce clauses can be The definition of the meaning of a pro\u00adduce clause \ngiven above works (makes sense) even when the body is not a subprogram. This is very important because \nit allows us to continue the Lucid practice of freely mixing program text with assertions in the course \nof verifying a program. Function clauses Function clauses are compound assertions about function variables, \nand are used in programs to define functions. A function clause is of the form function <function term> \n(<data variable list>) using <variable list> <set of assertions> end The function term is called the \nsubject of the clause, and the data variables in the parentheses are called the formal parameters. As \nbefore the global variables are those in the global list but now the locals are those occurring free \nin the body which are neither globals nor formal parameters . Formal parameters must all be distinct, \nand may not occur in the global list. Here is a typical function clause taken from a program: function \nRoot A,B,C) $ D =B -4 A-C output = (-B + fi)/(2 A) end In this case the global list is empty and the \nword is deopped. * A function clause is an assertion about the subject and the globals. It asserts that, \nfor all values of the formal parameters, there exist values of the local variables which make every assertion \nin the body of the clause true when output has the value of the subject applied to the formal parameters \nvalues. When used in a program, a function clause is a definition of its subject, which must simply be \na function variable, and the body of the clause must be a subprogram consisting of definitions of the \nlocals. Both these constructs are quite general and do not involve any of the functions in Lucid. They \ncould be added to any assertional language to give facilities for restricting the scope of variables, \nand for defining functions. Lucid has, in addition, two special versions of produce and function clauses, \nwhich allow the definition of subcomputations. They achieve this by implicitly applying -to the global \nvariables and formal parameters, and -1 latest to the result (see [2]). These analogs of the produce \nand function clauses are the com\u00adpute and mapping clauses respectively. In form they are identical to \ntheir analogs, except that 18 the word compute replaces the word produce , the word mapping replaces \nthe word function and the subject of a mapping clause is a mapping expression. The terms subject , global \n, local , formal parameter etc. are defined as for produce and function clauses. These clauses are used \nin programs to define their subjects, which in the case of a mapping clause must simply be a mapping \nvariable. When used in a program, the body of compute or mapping clause must be a subprogram defining \nnot the variable output but the specizl variable result , which is synonymous with = output . Since the \nlatest value of anything is quiescent (see [2]), result must be defined to be quiescent e.g., by an expression \nof the form x~P.t Semantically, these clauses, like their analogs, are assertions about their subjects \nand their globals. A compute clause is true iff there exist values for the local variables which make \nall the assertions in the body true when each global has its latest value and result has the latest value \nof the subject. A mapping clause is true iff for all values for the formal parameters there exist values \nfor the local variables which make every assertion in the body true when every global and formal parameter \nhas its latest value and result has the latest value of the subject applied to the latest values of the \nformal parameters. AN OPERATIONAL VIEW The mathematical semantics of clauses is given rigorously in [3]. \nIt is simple and precise, even when stated formally, and is used to justify the rules of inference for \nreasoning about programs and to prove implementations correct. However, it is not the best guide for \nwriting and understanding programs, because there is no notion of computations taking place or of anything \nhappening at all. We therefore present an alternative, operational view of the semantics of clauses in \nprogram?, which extends the operational view of Basic Lucid pro\u00adgrams in terms of loops, described in \n[1]. This operational view is informal and is derived from the more basic mathematical semantics. Of \nthe four types of Lucid clauses, the simplest operationally (or at least the most conventional) is the \ncompute clause. In a program, it is like an Algol block in that its subject is defined to be the result \nof a subcomputation carried out in a single step of the enclosing iteration, during which time the globals \nare considered to be frozen . If the body of the clause has inductively defined variables, the subcomputation \ncan be thought of as an inner loop. For example, the following program statement t In this paper we will \nabbreviate ~m~ by ~and~~by~ . compute loglOX using X I =0~1+1 P l~P.lo first(A,B,logA,logB) = (P,= P,I,= \nI) asa next P> X compute C using A,B first R= A*B/2 =next R = (R+AoB/R)/2 result = R~ IA*B -R21 < .00001 \nend loge = (logA+logB)/2 next(A,B,logA,logB) = if X < C then (A,C,logA,logC) else (C,B,logC,logB) result \nlogc~ IA-BI < .00001 . end has an inner compute clause which defines each value of C to be (an~proximation \nto) the cor\u00adresponding value of 4A*B . This inner compute clause can be considered to be a nested loop \nwhich is run through completely on each step of the enclosing iteration, The compute clause replaces \nthe Basic Lucid begin-end construct. The other clause with a fairly conven\u00adtional operational interpretation \nis the mapping clause. In a program, a mapping clause defines a function guaranteed to be pointwise in \nits argu\u00adments and globals, i.e. a function whose value at a given point in time depends only on the \nvalues of its arguments and globals at that time. It does this because it freezes its parameters as well \nas its globals. Here, for example, is a definition of a mapping variable trans mapping trans(L) using \ntrans,dict result = if null(L) then NIL else m atom(L) then cons(trans(car(L)) ,trans(cdr(L))) else \nL D = diet ~ cdr(D) E = car(D) entry = E ~ car(E) eq L V null(E) L = if null(entry) then L else cdr(entry) \nend which, when applied to the S expression L returns the S expression formed by replacing each atom \nby a corresponding S-expression, the correspondence being given by the pairlist diet. Because we want \nthe definition of trans to be recursive the function variable trans must appear on the global list. Terms \ninvolving mappings can be thought of as giving rise to Algol-like mapping calls , as will be shown when \nwe consider the manipulation rules for clauses. The two types of clauses defined give the programmer \nroughly the facilities of Algol s blocks and procedures, with certain restrictions on side effects. One \nof the reasons that these two clauses have a fairly conventional operational interpretation is that that \nin addition to restricting the scope of definition, they also freeze their globals and parameters so \nthat they can be thought of as describing self-contained subcomputations. The produce and function clauses \n19 do not use this freezing effect and therefore their operational interpretation is completely different, \nbecause inner computations can interact with those of the enclosing iteration. Operationally, the difference \nbetween a compute and a produce is that a produce clause must be considered either as an anonymous ongoing \nprocess which continuously produces values of its subject; or, alternatively, as a block of code which \nis repeatedly executed but with persistent internal memory in the form of inductively defined local variables. \nFor example, the following clause produce Y !x?A?43X N =l&#38;N+l T =first X~T+*X output = TIN end defines \nthe values of Y to be the running averages of the values of X up to that time, e.g. the third value of \nY is the average of the first three values of X . The local variable T , for example, keeps a running \ntotal of the values of X . We must imagine either that the iterations of the body of the clause are running \nin parallel but in step with those of the enclosing iteration, or, alternatively, that the clause body \nis executed once on each step of the enclosing iteration, but the values of the local variables ,1 II \nI and T are remembered between executions of the clause body. Function clauses can be thought of as templates \nfor processes, with each textual occurrence of a function call corresponding to the process which ia \nthe appropriate instance of the template. These processes must, like those defined by produce clauses, \nbe thought of as operating in parallel, but synchronized with the enclosing iteration, and as updating \ninternal variables even if, on some steps of the enclosing iteration, the output values are not required. \nAlternatively, the function body can be thought of as a conventional Algol-like procedure body which \nis called and returns a result, provided in addition that (i) the inductively defined local variables \nare thought of as own variables whose values are remembered between one call and the next; (ii) different \ntextual occurrences have separate copies of these variables; and (iii) the procedure is called on each \nstep of the iteration containing the function call, even when the value is not needed, for housekeeping \npurposes , namely to keep the own variables up to date. For example, the following piece of program N=l,&#38;Qj \nN+l function Avg(X) I =1~1+1 T .QA%GXM.XT+2%LX output = T/I end Y = Avg(N) Avg(N2) ~ N eq 5 defines \nY to be 33, the average of the first five positive integers times the average of the first five squares. \nWhether we interpret this program in terms of processes or in terms of procedures with own variables \nthe formal semantics requires first of all that the two occurrences of Avg make use of separate copies \nof I and T , and secondly that the values of these variables be kept up to date even though no actual \naverages need be computed until the fifth step of the main iteration. The operational view just described \ncan be extended to cover recursive functions, but we must imagine that each recursive call sets up a \nnew process, or generates new copies of the own variables. Some existing coroutine languages are capable \nof this, for example that of Kahn and McQueen [4]. In fact, languages already exist which exhibit similar \nfeatures to most of those found in this operational interpretation of produce and function clauses, but \nthe difference is that the designers started with the operational view, selecting those features which \nconformed to a personal and preconceived view of what processes and coroutines are. In Lucidon the other \nhand, any operational interpretations must conform with the mathematical semantics of clauses, and this \nin turn is simply the result of combining the Lucid view of iteration with the ability to define functions \nand limit the scopes of variables. We can therefore claim, with 11coroutine some and justification, \nprocess are that our the true notions ones. of PROGRAM PROOFS BY PROGRAM MANIPULATION We have rules \nfor transforming programs which can be rigorously justified using the formal semantics. Using such transformations \nit is poaaible to reason about programs in a very natural way. The first two rules allow us to carry \non normal reasoning within clause boundaries. The first says that we can add to any subclause any assertion \nthat follows logically from the assertions in the subclause. Conversely, the second rule says that we \ncan throw away any assertion from any subclause. There is also a set of movement rules which allow us \nto move across clause boundaries assertions whose free variables are all globals of the clause. Any such \nassertion can be moved in or out of a produce or function clause, and any such i assertion which is pointwise \ncan be moved in or out of a compute or mapping clause. Furthermore in the case of a produce clause, assertions \nwhich refer to output can be moved out of the clause provided output is replaced by the subject of the \nclause, and conversely, assertion which refer to the subject can be moved in provided the subject is \nreplaced by output . Similarly, the same is true of compute clauses, if we consider result rather than \noutput . ? An assertion is pointwise if it is a pointwise term or a compute or mapping clause whose sub\u00ad \nject is a pointwise term or a function clause with no global variables.  20 These are the most important \nrules  E?w!w2~ because they allow both small and large changes to an assertion in a single step -the \nassertions being moved can themselves be clauses. In order to prepare the stage for the application of \nthese rules we also need rules for adding global variables to a clause and for renaming its local variables. \nWe also need a rule which allows any function or mapping clause to be transformed to a produce or compute \nclause (respectively) by adding the formal parameters to the global list and by making any consistent \nsubstitution of terms for the formal parameters. While these rules are natural and easy to use, we know \nof no small well-structured symmetric subset of them which are inmme sense complete. Computational Behavior \nof Functions and Mappings The formal definitions of clauses and the manipulation rules above are sufficient \nto answer questions of an operational nature about functions and mappings. We will first illustrate how \nthe rules can be used to perform symbolic execution of a function call. Consider produce M function \nMin(X) moutPut mx = output = if output < next X then output . *-X end z =3$&#38;l&#38;2 output = Min(Z2) \nend We first use the function transformation rule, with the formal parameter X being replaced by 22 , \nyielding produce M roz:~;;:: * z =WJut % output< =22 then output else = 22 end 7-=3 ~l&#38;2 output \n= Min(Z ) end Then we use our movement rule to move the definition of Z inside the produce clause yielding \nproduce M produce Min(Z2) * 2 first output = first Z next output = if output < _ 22 then output else \n* 22 z =3~l,f&#38;2 end output = Min(Z2) end Then inside the produce we substitute 3 &#38; 1-2 for every \noccurrence of Z , perform some simple calculations and, after discarding unnecessary statements, we have \nproduce Min(Z2) using Z output =9,@J l&#38;l end output = Min(Z2) end . The assertion output = 9 ~ 1 \n~ 1 can be moved out of the inner produce, yielding Min(Z2) = 9 ~ 1~ l . Then substitution of equals \nfor equals yields output = 9 &#38; 1 ~ 1 in the body of the outer produce and this can be brought out, \ngiving M=9~lf&#38;l . Any mechanism to implement functions and mapPings must produce effects that are \nconsistent with all properties that can be proved using the manipulation rules. In particular, one such \nparameter-passing mechanism is the call by name rule as considered in Vuillemin [6]. To see that call \nby value does not work, consider produce V mapping f(x, Y) = f result = if X eq O then O else f(X-l,f(X,Y)) \n. end output = f(l,o) end We can duplicate the mapping clause, and then transform one of the copies \ninto the corresponding compute clause (setting up the actuallformal parameter correspondence) giving \nproduce V mappin~ f(X,Y) using f result = if X eq O then O else f(X-l,f(X,Y)) end compute f(l,O) using \nf result = if 1 eq O ~ O else f(l-l,f(l,O))  end output = f(l,o) end Inside the compute clause we obtain \nresult = f(o, f(l,o)) which can be moved out , and the compute clause discarded, giving produce V m~ \nf(x,Y) * f result = if X eq O then O else f(X-l,f(X,Y)) end f(l,o) = f(o,f(l,o)) output = f(l,o) end \nWe repeat the process with formal parameter X being replaced by O and Y being replaced by f(l,o) . Inside \nthe resulting compute clause we get result = if O eq O then O else f(O-l,f(l,O))) .  This simplifies \nto result = O 21 and when we move this out and discard the compute clause we get produce V f(o,f(l,o)) \n= o f(l,o) = f(o,f(l,o)) output = f(l,o) end. From this we clearly get output = o which we can move out \ngiving V=o. In a call by value implementation of this function, the program would diverge, which is inconsistent \nwith the fact that v = o . A more efficient mechanism than call by name is the delay rule or call by \nneed of Vuillemin [6], and Lucid may be first programming language that can actually use it. Finally, \nwe will show that the manipula tion rules can be used to settle the question of dynamic versus static \nbinding of global variables of functions and mappings. Consider compute U mapping f(X) using Y result \n=X+Y end Y=l compute result * f Y =2 result = f(3) end end . The question is whether the value of U \nis 5 or 4, which depends on whether the inner or outer definition of Y is used in the evaluation of f(3) \n. In a language like LISP which has dynamic binding, the inner value would be used, in Algol the outer. \nIt is easy to see that the manipulation rules imply that Lucid uses static binding. We cannot move the \nmapping inside the inner compute clause until we have renamed the inner local variable Y . The variable \nY can then be added to the global list of the inner compute, and the mapping can be moved giving compute \nV Y=l compute result using Y map ping f(X) using Y result =X+Y end z2 . result = f(3) end end . The \ndefinition of Y can now be brought down into the mapping, and it is then straightforward to finally obtain \nV = 4 . [1] Ashcroft E.A. and Wadge W.w., Lucid, a non-procedural language with iteration , CACM 20, \nNO. 7, pp. 519-526. [2] Ashcroft E.A. and Wadge W.w. , Lucid -a formal system for wriiing and proving \nprograms , SIAM J. Comput. 5, No. 3, pp. 336-354. [31 Ashcroft E.A. and Wadge W.W., Lucid: Scope structures \nand defined functions , CS-78-01, Computer Science Department, University of Waterloo. (Revised version \nof CS-76-22.) [4] Kahn G. and MacQueen D.B., Coroutines and networks of parallel processes , Proc. IFIP77 \npp. 993-998, North Holland. [51 Landin P.J., The next 700programming languages , CACM 9, pp. 157-166. \n[6] Vuillemin J., Correct and optimal implemen\u00adtations of recursion in a simple programming language \n, 5th Annual ACM Symposium on Theory of Computing, Austin, 1973. 22 \n\t\t\t", "proc_id": "512760", "abstract": "In this paper we describe how Lucid can be extended to allow user-defined functions and scope conventions, i.e. conventions for limiting the range or scope of the validity of definitions. This is done using new constructs called clauses which are similar in form to the blocks and procedure declarations of Algol-like languages, but are nevertheless strictly non-imperative, because a clause is actually a compound assertion, i.e. an assertion formed, as a program is, by combining a collection of assertions.Each type of clause (there are four) has a straightforward mathematical semantics together with its own characteristic \"manipulation rules\" for general program massage. In addition, the informal operational view of (some) Lucid programs (described in a previous paper) can be extended to give an (incomplete) operational understanding of the effect of the clauses. In this framework a \"compute\" clause defines a block; a \"mapping\" clause defines a conventional (pointwise) function; a \"produce\" clause defines a block with persistent memory (or an anonymous 'process' or 'actor'); and a \"function\" clause defines a sort of procedure with own variables (or a general kind of coroutine).", "authors": [{"name": "E. A. Ashcroft", "author_profile_id": "81100071527", "affiliation": "University of Waterloo", "person_id": "PP43126086", "email_address": "", "orcid_id": ""}, {"name": "W. W. Wadge", "author_profile_id": "81100211818", "affiliation": "University of Warwick", "person_id": "PP43124898", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512763", "year": "1978", "article_id": "512763", "conference": "POPL", "title": "Clauses: scope structures and defined functions in Lucid", "url": "http://dl.acm.org/citation.cfm?id=512763"}