{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 COIIference Record of the Fifth Annual ACM Symposium on Principles of Programming \nLanguages SYNTACTIC CONTROL OF INTERFERENCE John C. Reynolds School of Computer and Information Science \nSyracuse University ABSTRACT In programming languages which permit both assignment and procedures, distinct \nidentifiers can represent data structures which share storage or procedures with interfering side effects. \nIn addition to being a direct source of programming errors, this phenomenon , which we call interference \ncan impact type structure and parallelism. We show how to eliminate these difficulties by imposing syntactic \nrestrictions, without prohibiting the kind of constructive interference which occurs with higher-order \nprocedures or SIMULA classes. The basic idea is to prohibit interference between identifiers, but to \npermit interference among components of collections named by single identifiers. The Problem tantamount \nto calling n by value. But while this solution is adequate for simple variables, it can It has long \nbeen known that a variety of become impractical for arrays. For example, the anomalies can arise when \na programming language procedure combines assignment with a sufficiently powerful procedure transpose(X, \nY); real array X, Y; procedure mechanism. The simplest and best\u00adunderstood case is aliasing or sharing \nbetween for i := 1 until 50 do . variables, but there are also subtler phenomena of for j := 1until 50 \ndo the kind known vaguely as interfering side  effects . Y(i, j) := X(j, i) In this paper we will show \nthat these anomalies are instances of a general phenomenon which we call will malfunction for a call \nsuch as transpose(Z, Z) interference. We will argue that it is vital to which causes X and Y to be aliases. \nBut changing constrain a language so that interference is X to a local variable only solves this problem \nat syntactically detectable, and we will suggest the expense of gross inefficiency in both time and principles \nfor this constraint. space. Certainly, this inefficiency should not be Between simple variables, the \nonly form of imposed upon calls which do not produce interfer\u00adinterference is ~ or sharing. Consider, \nfor ence, On the other hand, in-place transposition is example, the factorial-computing program: best \ndone by a completely different algorithm. This suggests that it is reasonable to permit procedure fact(n, \nf); integer n, f; procedures such as transpose, but to prohibit calls !?%&#38; integer k; of such procedures \nwith interfering parameters. Although these difficulties date back to Algolk:=O; f:=l; and FORTRAN, more \nrecent languages have introduced while k # n donew features which exacerbate the problem of interference. \nOne such feature is the union of:=k+l; f:=kxfendl?_!%@k data types. Suppose x is a variable whose value \nend . can range over the union of the disjoint data types integer and character. Then the language mustSuppose \nn and f are called by name as in Algo 1, or provide some construct for branching on whetherby reference \nas in FORTRAN, and consider the effect the current value of x is an integer or a charac\u00adof a call such \nas fact(z, z), in which both actual ter, and thereafter treating x as one type or theparameters are the \nsame. Then the formal parameters other. For example, one might write n and f will be aliases, i.e., they \nwill interfere in the sense that assigning to either one will unioncase x of (integer S; character: S \n) , the assignment f := 1 will obliterate the value of affect the value of the other. As a consequence, \nwhere x may be used as an identifier of typen so that fact(z, z) will not behave correctly. integer in \nS and as an identifier of type characterIn this case the problem can be solved by in S . However, consider \nchanging n to a local variable which is initialized to the value of the input parameter; this is unioncase \nx of (integer: (y := A ; n := X+ Work supported by National Science Foundation Grant 1); MCS 75-22002, \nand by the Science Research Council character: noaction) . of Great Britain. It is evident that aliasing \nbetween x and y can nodelist item link cause a type error in the expression x + 1. Thus , in the presence \nof a union mechanism, interference can destroy type security. This problem occurs with variant records \nin PASCAL [1], and is only avoided in Algol 68 [2] at the expense of copying union values. The introduction \nof parallelism also causes serious difficulties. Hoare [3,4] and Brinch-Hansen [5] have argued convincingly \nthat intelli\u00adgible programming requires all interactions between parallel processes to be mediated by \nsome mechanism such as a critical region or monitor. As a consequence, in the absence of any critical \nregions or monitor calls, the arallel execution of two statements, written S s can only be 71 permitted \nwhen S1 and S2 do &#38;ot in?~rfere with one another. For example, x:=X+l ]/ y:=y x2 would not be permissible \nwhen x and y were aliases. In this paper, we will not consider interacting parallel processes, but we \nwill permit the parallel construct SII S2 when it is syntactically evident 1 that S1 and S2 do not interfere. \nAlthough this kind of determinate parallelism is inadequate for practi cal concurrent programming, iH \nia sufficient to make the consequences of interference especially vivid. For example, when x and y are \naliases, the above statement becomes equivalent to whose meaning, if any, is indeterminate, machine\u00addependent, \nand useless. These examples demonstrate the desirability of constraining a language so that variable \naliasing is syntactically detectable, Indeed, several authors have suggested constraints which would \neliminate aliasing completely [6,7]. However, aliasing is only the simplest case of the more general \nphenomenon of interference, which can occur between a variety of program phrases. We have already spoken \nof two statements interfering when one can perform any action which affects the other. Similarly, two \nprocedures interfere when one can perform a global action which has a global effect upon the other. Interference \nraises the same problems as variable aliasing. For example, P(3) II Q(4) is only meaningful if the procedures \nP and Q do not interfere. Thus the case for syntactic detection extends from aliasing to interference \nin general. However, the complete prohibition of interference would be untenably restrictive since, unlike \nvariables, interfering expressions, statements, and procedures can have usefully different meanings. \nBoth the usefulness and the dangers of inter\u00adference between procedures arise when procedures are used \nto encapsulate data representations. As an example, consider a finite directed graph whose nodes are \nlabelled by small integers. Such a graph might be represented by giving, for each node n, a linked list \nof its immediate successors nl,. . ., nk: 1 2 k B This representation is used by the procedure procedure \nitersucc(n,p) ; integer n; procedure P; begin integer k; k := novelist; while k # Odo . !2!?&#38;?lP(item(k)); \nk = link(k) @ end whic n causes the procedure p to be applied to each immediate successor of the node \nn. If the graph is ever to change, then something probably a procedure such as addedge or deleteedge \n-must interfere with itersucc by assigning to the global arrays nodelist, item, and link. On the other \nhand, the correct operation of itersucc requires that the procedure parameter p must not assign to these \narrays, i.e. , that p must not interfere with itersucc. Indeed, if itersucc involved parallelism, e.g. \nif the body of the while statement were m integer m; m := item(k); k := link(k) end Q5@JlF (m) II ~> \nthen noninterference between p and itersucc would be required for meaningfulness rather than just correctness \n. Of course, the need for interfering procedures would vanish if the graph representation were a parameter \nto the procedures which use it. But this would preclude an important style of programming -epitomized \nby SIMULA 67 [8] -in which data abstraction is realized by using collections of procedures which interfere \nvia hidden global variables. In summary, these examples motivate the basic goal of this paper: to design \na programming lan\u00adguage in which interference is possible yet syntactically detectable. To the author \ns know\u00adledge, the only current language which tries to meet this goal is Euclid [7]. The approach used \nin Euclid is quite different than that given here, and apparently precludes procedural parameters and \ncall-by-name. The Basic Approach (III) Certain types of phrases, such as expressions, and procedures \nwhich do not Before proceeding further, we must delineate assign to global variables, are said to be \nthe idea of interference more precisely. By a passive. When P and Q are both passive, ewe mean a variab~ey \nexpression, statement, P # Q. or procedure denotation. In the first three cases, we speak of exercising \nthe phrase P, meaning: either assigning or evaluating P if it is a variable, evaluating P if it is an \nexpression, or executing P if it is a statement. For phrases F and Q, we write P # Q to indicate that \nit is syntactically detectable that P and Q do not interfere. More precisely, # is a syntactically decidable \nsymmetric relation between phrases such that: (1) If neither P nor Q denotes a procedure, then P # Q \ninplies that, for all ways of exercising P and Q, the exercise of P will have no effect on the exercise \nof Q (and vice-versa) . Thus the meaning of exercising P and Q in parallel is well-defined and determinate. \n (2) If P denotes a procedure, A , . . . , An are syntactically appropriate ac t ual para\u00admeters, P#Q, \nandA1 #Q, ... ,~ #Q, then P(Al, ... ,A)#Q. (Thus P#Q captures the idea ?hat P cannot interfere with Q \nvia global variables.)  It should be emphasized that these rules have a fail-safe character: P # Q \nimplies that P and Q cannot interfere, but not the converse. Indeed, the rules are vacuously satisfied \nby defining # to be universally false, and there is a prubablyy endless sequence of satisfactory definitions \nwhich come ever closer to the semantic relation of non interference at the expense of increasing complexity. \nWhere to stop is ultimately a question of taste: P {) Q should mean that P and Q obviously do not interfere. \n Our own approach is based upon three principles: (I) If I # J for all identifiers I occur\u00ad ring free \nin P and J occurring free in Q, then P#Q. In effect, all channels of interference must be named by identifiers. \nFor the language discussed in this paper, this principle is trivial, since the only such channels are \nvariables. In a richer language, the principle would imply, for example, that all 1/0 devices must be \nnamed by identifiers. (II) If I and J are distinct identifiers, then I #J. This is the most controversial \nof our principles, since it enforces a particular convention for distinguishing between interfering and \nnoninter\u00adfering phrases. Interfering procedures (and other entities) are still permissible, but they \nmust occur within a collection which is named by a single identifier. (An example of such a collection \nis a typical element in a SIMULA [8] class. Indeed, the idea of using such collections was suggested \nby the SIMULA class mechanism, although we will permit collections which do not belong Co any cla5.s.) \nPassive phrases perform no assignments or other actions which could cause interference. Thus they cannot \ninterfere with one another or even with themselves, although an active phrase and a passive phrase can \ninterfere. An Illustrative Language To illustrate the above principles we will first introduce an Algol-based \nlanguage which, although it satisfies Principle (I), permits uncontrolled interference. We will then \nimpose Principle (11) to make interference syntactically detectable. Finally, we will explore the consequences \nof Principle (111). Unlike Algol, the illustrative language is completely typed, so that reduction (i.e. \nappli cation of the copy rule) cannot introduce syntax errors. It provides lambda expressions and fixed\u00adpoint \noperators for all program types, and a named Cartesian product, which is needed for the collections discussed \nunder Principle II. Procedure declarations, multiple-parameter procedures, and classes are treated as \nsyntactic sugar, i.e. , as abbreviations which are defined in terms of more basic linguistic constructs. \nArrays, call-by-valuey jumps and labelsy unions of types, references, input output, and critical regions \nare not considered. We distinguish between data types, which are the types of values of simple variables, \nand program types, which are the types which can be declared for identifiers and specified for parameters. \nThe only data types are integer, real, and Boolean, as in Algol, but there are an infinite number of \nprogram types. Specifically, the set of program types is the smallest set such that: (Tl) If 6 is a data \ntype, then 6 var (meaning variable) and 6 exp (meaning expression) are program types. (T2) sta (meaning \nstatement) is a program type. (T3) If u and u are program types, then ~+~f is a program type. (T4) If \n~ is a function from a finite~et of identifiers into program types, then II(o) is a program type. A formal \nparameter specified to have type 6 var can be used on either side of assignment statements, while a formal \nparameter specified to have type 6 exp can only be used as an expression. The program type u + m describes \nprocedures whose single parameter has type w and whose call has type u . For example, the Algol procedures \nyrocedure pi(n); integer n; n := 3; real procedure p2(x); real x; p2 := x X x; would have types integer \nvar + sta and real exp + real exp respectively. The program type II(;) is a Cartesian product in which \ncomponents are indexed by identifiers ra~her than by consecutive integers. Specifically, II(W) descr~bes \ncollections in which each_i in the domain of_w indexes a component of type ~(i). The function u will \nalways be written as a list of pairs of the form argument:value. Thus, for example, II(inc: sta, val: \ninteger exp) describes collections in which inc indexes a statement and val indexes an integer expression. \nA typical phrase of this type might be (inc: n := n+ 1; val: n Xn). To simplify the description of syntax \nwe will ignore aspects of concrete representation such as parenthezation, and we will adopt the fiction \nthat each identifier has a fixed program type (except when used as a component index), when in fact the \nprogram type of an identifier will be specified in the format I:u when the identifier is bound. We write \n<u id> and <(I)> to denote the sets of identifiers and phrases with program type LO. Then the syntax \nof the illustrative language is given by the following production schemata, in which 6 ranges over all \ndata types, LO, o , WI, . . . Un range over program types, and il, . . . , in, range over identifiers: \n<integer exp> ::= O I .integer exp>+<integerexp> <Boolean exp> ::= true I integer exp>=<integerexp> I \n.Boolean exp>&#38;<Booleanexp> (and similarly for other constants and operations on data types) <sta> \n::= <6 var> := <6 exp> <sta> ::= noaction I <sta>; <sta> I while .Boolean exp> ~ <sta> <sta> : := new \n<6 var id> in <sta> <w> ::= <U id> <W + w > ::= a <~ id>. <w > <~t> ::= <~ + OJ> (<u>) <II(i :U , ... \n, i :On)> ::= 11 (iI:<ml>, ..: , i :<U > ) nn <wk> ::= <II(i :U , in:wn)> . i 1 1  k <~> : := if <Boolean \nexp> then <~> else <~> <~> ::= Z(<W + 0.)>) Although a formal semantic specification is beyond the \nscope of this paper, the meaning of our language can be explicated by various reduction rules. For lambda \nexpressions, we have the usual rule of beta-reduction: (XI. P) (Q) -++Q where the right side denotes \nthe result of substituting Q for the free occurrences of I in P, after changing bound identifiers in \nP to avoid conflicts with free identifiers in Q. Note that this rule implies call by name: If P does \nnot contain a free occurrence of I then (AI. P)(Q) reduces to P even if Q is nonterminating or causes \nside effects. For collection expressions, we have (il:P1, . . . ,in:P ).ik -Pk . n For example, (i.nc: \nn := n+l, val: nxn ). inc * n := n+l . Again, there is a flavor of call by-name, since the above reduction \nwould still hold if nxn were replaced by a nonterminating expression. The fixed-point operator ~ can \nalso be elucidated by a reduction rule: In addition to lambda expressions, the only other binding mechanism \nin our language is the declaration of new variables. The statement -[1 integer new I: real in S has the \nsame meaning as the Boolean integer Algol statement begin real I; S end. Boolean [\u00ad 1 By themselves, \nlambda exp~essions and new variable declarations are an austere vocabulary for variable binding. But \nthey are sufficient to permit other binding mechanisms to be defined as abbreviations. This approach \nis vital for the language constraints which will be given below, since it insures that all binding mechanisms \nwill be affected uniformly. Multiple-parameter procedures are treated following Curry [9]: P(A1, ... \n, An) ; P(A1) ... (An) A(I1, .... In). B E AI1. ... AI B n and definitional forms, including procedure \ndeclarations are treated following Landin [10]: let I=QinP (ii. P)(Q) letrecI=QinP (AI. P)(~(AI. Q)) \n. (However, unlike Landin, we are using call-by-name.) We will omit type specifications from let and \nlet rec expressions when the type of I is apparent from Q. As shown in the Appendix, classes (in a slightly \nmore limited sense than in SIMULA) can also be defined as abbreviations. As an example, the declaration \nof the procedure fact shown at the beginning of this paper, along with a statement S in the scope of \nthis declaration, would be written as: let fact = l(n :integer exp, f: integer var). new k: integer in \n(k :=0; f :=1; while k#ndo (k := k+l; f := kxf)) inS.  After eliminating abbreviations, this becomes \n (Afact: integer exp + (integer var+ sta). S) (In: integer exp. Af: integer var. new k: integer in (k \n:=O;f :=1; while k#ndo (k :=k+l; f :=kxf))) . Controlling Interference For example, consider the following \nprocedure The illustrative language already satisfies Principle I. If we can constrain it to satisfy \nPrinciple II as well, then P # Q will hold when P and Q have no free identifiers in common. By assuming \ncompatible consequences section), the with we most pessimistic this result of Principle get III (and \ndefinition postuntil poning the of next # the P # Q iffF(P) ~F(Q) = {}, where F(P) denotes the set of \nidentifiers which occur free in P. To establish Principle II, we must consider each way of binding an \nidentifier. A new variable declaration causes no problems, since new variables are guaranteed to be independent \nof all previously declared entities. But a lambda expression can cause trouble, since its formal parameter \nwill interfere with its global identifiers if it is ever applied to an actual parameter which interferes \nwith the global identifiers, or equivalently, with the procedure itself. To avoid this interference, \nwe will restrict the call P(A) of a procedure by imposing the requirement P # A. The following informal \nargument shows why this restriction works. Consider a beta-reduction (AI. P)(Q) +PII@. Within P there \nmay be a pair of identifiers which are syntactically required to satisfy the #-relationship, and therefore \nmust be distinct. If so, it is essential that the subs\u00ad titution I + Q preserve the.{1-relationship. \nNo problem occurs if neither identifier is the formal parameter I. On the other hand, if one identifier \nis I, then the other distinct identifier must be global. Thus the #-relation will be preserved if K # \nQ holds for all global identifiers K, i.e., for all identifiers occurring free in AI. P. This is equivalent \nto (AI. P) # Q. More formally, one can show that, with the restriction on procedure calls: syntactic \ncorrectness is preserved by beta reduction (and also by reduction of collection expressions), and continues \nto be preserved when other productions restricted by # are added, e.g., <Sta> : := <sta > l! <sta > when \n<sta > # <sta2> . 12 1 The restriction P # A on P(A) also affects the language constructs which are defined \nas abb~evia\u00ad tions. For let I = Q in P z (AI. P)(Q), and for let rec I = Q in P = (n. P)(Y(AI. Q)), we \nsee that, . except for I, no free identif~er of Q can occur free in P. Thus , although one can declare \na procedure or a collection of procedures which use global identifiers (the free identifiers of Q), these \nglobals are masked from occurring in the scope P of the declaration, where they would interfere with \nthe identifier I. For multi-parameter procedures, P(A1, ,.. , An) = P(A1) . . . (An) implies the restrictions \nP # Al, p(A1) # A2, ... , P(A1) ... (~-1) # ~, which are equivalent to requiring P # Ai for each parameher \nand Ai # Aj for each pair of distinct parameters. for a repeat statement: let repeat = A(s: sta, b: Boolean \nexp). (s; whilelb do s) . . In any useful call repeat(A1, A2), the statement Al will interfere with the \nBoolean expression A2. Although this is permitted in the unconstrained illustrative language, as in Algol, \nit is prohibited by the restriction A1 #A2. Instead, one must group the interfering parameters into a \ncollection: let repeat = Ax: II(s: sta, b: Boolean exp). (x.s; whilel x.b do X.S) , and use calls of \nthe form repeat( (S:A1, b:A2 ) ). This example is characteristic of Principle II. Although interfering \nparameters are permitted, they require a somewhat cumbersome notation. In compen\u00adsation, it is immediately \nclear to the reader of a procedure body when interference between parameters is possible. Passive Phrases \nIn making interference syntactically detect\u00adable, we have been unnecessarily restrictive. For example, \nwe have forbidden parallel constructs such as x:=nlly:=n or let twice = As: sta. (s; s) in (twice(x \n:= x+1) II twice(y := yx2)) . Moreover, the right side of the reduction rule Y(f) * f(~(f)) violates \nthe requirement f # Y(f), ~iving a clear sign that there is a problem ~ith recursion. In the first two \ncases, we have failed to take into account that the expression n and the procedure twice are passive: \nThey do no assignment (to global variables in the case of procedures), and therefore do not interfere \nwith themselves. Similarly, when f is passive, f # ~(f) holds, and the reduction rule for ~(f) becomes \nvalid. This legitimizes the recursive definition of procedures which do not assign to global variables. \n(Recursive procedures which assign to global variables are a more difficult problem. Within the body \nof such a procedure, the global variables and the procedure itself are interfering entities, and must \ntherefore be represented by components of a collection named by a single identifier. This situation probably \ndoesn t pose any fundamental difficulties, but we have not pursued it.) The following treatment of passivity \nis more tentative than the previous development. Expressions in our language are always passive, since \nthey never cause assignment to free variables. Procedures may be active or passive, independently of \ntheir argument and result types. Thus we must distinguish the program type u +P U describing passive \nprocedures from the program type m * u describing (possibly) active procedures. More formally, we augment \nthe definition of program types with (T5) If o and u are program types, then ~+~t is a program type. \n P and we define passive program types to be the smallest set of program types such that (PI) 6 exp is \npassive. (P2) w~ u is passive. (P3) If fi(i) is passive for all i in the domain of =, then II@) is passive. \n Next, for any phrase r, we define A(r) to be the set of identifiers which have at least one free occurrence \nin r which is outside of any subphrase of passive type. Note that, since identifier occurrences are themselves \nsubphrases, A(r) never contains identifiers of passive type, and since r is a subphrase of itself, A(r) \nis empty when r has passive type. Then we relax the definition of P // Q to permit P and Q to contain \nfree occurrences of the same identifier, providing every such occurrence is within a passive subphrase. \nWe define: P # Q zA(P) nF(Q) = {}&#38;F(P) nA(Q) = {} . Finally, we modify the abstract syntax. We define \na passive procedure to be one in which no global identifier has an active occurrence: <~ + ~q> ::= i \n<U id>. <ut> P when A(<u >) -{<u id>} = {} . Passive procedures can occur in any context which permits \nactive procedures: <~ + ~t> ::=<~+ Uf> , P but only passive procedures can be operands of the fixed-point \noperator: <u> ::= Y(<u +P 0>) . Some Unresolved Questions Our abstract syntax is ambiguous, in the sense \nthat specifying the type of a phrase does not always specify a unique type for each subphrase. For example, \nin the original illustrative language, the subphrase if p then x else y might be either . a variable \nor ~ expression in contexts such as z:= if pthen xelse y . (a: if p then x else y, b: 3).b Similarly, \nthe introduction of passive procedures permits the subphrase As: sta. (s; s) to have either type sta \n+-ata or eta + sta in the context P (As: sta. (s; S))(X := X+l) . Although these ambiguities could probably \nbe eliminated, our intuition is to retain them, while insisting that they must not lead to ambiguous \nmeanings. Indeed, it may be fruitful to extend this attitude to a wider variety of implicit conversions. \nIn normal usage, a procedure call will be active if and only if either the procedure itself or its parameter \nare active. Although other cases are syntactically permissible they seem to have only trivial instances. \nThus it might be desirable to limit the program types of procedures to the cases: O+pe ~+pa e+a a+af \nwhere EI and 0 are passive types and a and a are nonpassive types. The most serious problem with our \ntreatment of passivity is our inability to retain the basic property that beta-reduction preserves syntactic \ncorrectness. Consider, for example, the reduction (Ap: mixed. (x :=p.a II y :=p.a)) (( a:n+l, b:n:= O)) \n* x:= (a: n+l, b:n:=O}.a Ily:= (a:n+l, b:n:=O). a * x:=n+llly:=n+l !Imixedl! where stands for the program \ntype II(a: integer exp, b: sta). Although the first and last lines are perfectly reasonable, the inter\u00admediate \nline is rather dubious, since it contains assignments to the same variable n within two statements to \nbe executed in parallel. Neverthe less, our definition of # still permits the inter\u00admediate line, on \nthe grounds that assignments within passive phrases cannot be executed. However, if we accept x:= (a: \nn+l, b:n:=O).a # y := (a: n+l, b:n:=O).a, then it is hard to deny is: sta. x := {a: n+l, b: (n:= O\\ls)).a \n# y := (a: n+l, b:n:=O).a . But this permits the reduction (1s: sta. x := (a: n+l, b: (n:=Oll s)). a) \n(y:= (a: n+l, b:n:=O). a) * x := (a: n+l, b: (n:= Oily:= (a: n+l, b:n:=O).a) ) .a) * x := n+l Here the \nintermediate step, in which the under\u00adlined statement is clearly illegal, is prohibited by our syntax. \nThis kind of problem is compounded by the possibility of collection-returning procedures. For instance, \nin the above examples, one might have silly(n+l, n := O), where silly has type integer exp + (sta + mixed), \nin place of the collection (a: n+l, b: n := O ) . A possible though unesthetic solution to these problems \nmight be to permit illegal phrases in contexts where passivity guarantees nonexecution. A more hopeful \npossibility would be to alter the definition of substitution to avoid the creation of illegal phrases \nin such contexts. Directions for Further Work Beyond dealing with the above questions, it is obviously \nessential to extend these ideas to other language mechanisms, particularly arrays, In addition, the interaction \nbetween these ideas and the axiomatization of program correctness needs to be explored. We suspect that \nmany rules of inference might be simplified by using a logic which imposes #-preservation upon substitutions. \nA somewhat tangential aspect of this work is the distinction between data and program types, which obviously \nhas implications for user-defined types. (Note the absence of this distinction in Algol 68 [2].) In less \nAlgol-like languages, data types might have as much structure as program types, and user definitions \nmight be needed for both types of type. Indeed, there may be grounds for introducing more than two types \nof type. Finally, these ideas may have implications for the optimization of call-by-name, perhaps to \nan extent which will overcome the aura of hopeless inefficiency which surrounds this concept. For example, \nwhen an expression is a single parameter to a procedure, as opposed to a component of a collection which \nis a parameter, then its repeated evaluation within the procedure must yield the same value (although \nnontermination is still possible). This suggests a possible application of the idea of lazy evaluation \n[11, 12]. APPENDIX Classes as Syntactic Sugar In a previous paper, we have argued that classes are a \nless powerful data abstraction mechanism than either higher-order procedures or user-defined types [14]. \nThe greater generality of higher-order procedures permits the definition of classes (in the reference-free \nsense of Hoare [13] rather than SIMULA itself) as abbreviationa in our illustrative language. In fact, \nthe basic idea works in Algol 60, although the absence there of lambda expressions and named collections \nof procedures makes its application cumbersome. We consider a class declaration with scope S of the form: \nclass C(DECL; INIT; I1:P1, . . . , In:Pn) ~ S (1) which defines C to be a class with component names \nI Here DECL is a list of declarations o$ v~~~~b;% and procedures which will be private to a class element, \nINIT is an initialization statement to be executed when each class element is created, and each Pk is \nthe procedure named by Ik, in which the private variables may occur as globals. Within the scope S, one \nmay declare X to be a new element of class C by writing the statement newelement X: C in S . (2) Then \nwithin the statement S one may write X.Ik to denote the component pk of the class element X. To express \nthese notations in terms of procedures, suppose P , . . . , Pn have types UJl, . . . . tin respectively. \nThe+ we define (1) to be an abbreviation for: let C = Ab: II(I1:u1, . . . , In:on) + sta, (DECL; INIT; \nb((I1:P1, . . . , In:Pn ))) inS, where b is an identifier not occurring in the original class declaration, \nand where DECL must be expressed in terms of new and let declarations. Then we define (2) to ~an ab~viation \nfor: C(AX: II(I1:w1, . . . , In:wn). S ) . As an example, where for simplicity PI and P2 are parameterless \nprocedures: class counter(integer n; n := O; inc: n := n+l, val: n) in . . . newelement k: counter in \n. . . (k.inc; x := k.val) is an abbreviation for let counter = Ab: II(inc: sta, val: integer exp) + \nsta. new n: integer in (n := O; b((inc: n := n+l, val: n))) &#38; .,. counter(ik: II(inc: sta, val: \ninteger exp). . . . (k.inc; x := k.val)) , which eventually reduces to new n: integer ~ (n := O; . . \n. (n:= n+l; x :=n)) . In the process of reduction, identifiers will be renamed to protect the privacy \nof n. The only effect of our interference-controlling constraints is that C must be a passive procedure, \ni.e., INIT and PI, . . . , Pn cannot assign to any variables which are more global than those declared \nby DECL. This insures that distinct class elements will not interfere with one another. Otherwise, if \nC is not passive, then S in the definition of (2) cannot contain calls of C, so that multiple class elements \ncannot coexist. ACXNOWLEDGEMENTS Most of this research was done during a delightful and stimulating sabbatical \nat the University of Edinburgh. Special thanks are due to Rod Burstall and Robin Milner for their encouragement \nand helpful suggestions, and to the members of IFIP working group 2.3, especially Tony Hoare, for establishing \nthe viewpoint about programming which underlies this work. REFERENCES [1] Wirth, N. The Programming Language \nPASCAL. Acts Informatica~, (1971), pp. 35-63. [2] van Wijngaarden, A. (cd.), Mailloux, B. J., Peck, J. \nE. L,, and Koster, C. H. A. Report on the Algorithmic Language ALGOL 68. MR 101, Mathematisch Centrum, \nAmsterdam, February 1969. [3] Hoare, C. A. R. Towards a Theory of Parallel Programming. In Operating \nSystems Techniques, Academic Press, New York, 1972. [4] Hoare, C. A. R. Monitors: An Operating System \nStructuring Concept. Comm. ACM 17 (October 1974), pp. 549-557. [5] Brinch-Hansen, P, Structured Multiprogramming, \nComm. ACM~ (July 1972), pp. 574-577. [6] Hoare, C. A. R. Procedures and Parameters: An Axiomatic Approach. \nIn Symposium on the Semantics of Algorithmic Languages (cd. E. Engeler). Springer, Berlin-Heidelberg-New \nYork, 1971, [7] Popek, G. J., Horning, J. J., Lampson, B. W., Mitchell, J. G., and London, R. L. Notes \non the Design of Euclid. In Proceedings of an ACM Conference on Language Design for Reliable Software, \nSIGPLAN Notices ~, no. 3 (March 1977)2 pp. 11-18. [8] Dahl, O. -J. Hierarchical Program Structures. In \nStructured Programming, Academic Press, New York 1972. [9] Curry, H. B., and Feys, R. Combinatory Logic, \nVolume I. North-Holland, Amsterdam 1958. [10] Landin, P. J. A Correspondence Between ALGOL 60 and ChurchFs \nLambda Notation. comm ACM ~ (February and March 1965), pp. 89-101 and 158-165. [11] Henderson, P., and \nMorris, J. H., Jr. A Lazy Evaluator. Third ACM Symposium on Principles of Progranuning Languages (1976), \npp. 95-103. [12] Friedman, D. P., and Wise, D. S. CONS Should Not Evaluate its Arguments. Third Int 1 \nColloquium on Automata, Languages, and Programming, Edinburgh University Press 1976, pp. 257-284. [13] \nHoare, C. A. R. Proof of Correctness of Data Representations. Acts Informatica ~, pp. 271-281 (1972). \n[14] Reynolds, J. C. User Defined Types and Procedural Data Structures as Complementary Approaches to \nData Abstraction. In New Directions in Algorithmic Languages 1975, ed. S. A. Schuman, I.R.I.A. 1975, \npp. 157-168.\n\t\t\t", "proc_id": "512760", "abstract": "In programming languages which permit both assignment and procedures, distinct identifiers can represent data structures which share storage or procedures with interfering side effects. In addition to being a direct source of programming errors, this phenomenon, which we call interference can impact type structure and parallelism. We show how to eliminate these difficulties by imposing syntactic restrictions, without prohibiting the kind of constructive interference which occurs with higher-order procedures or SIMULA classes. The basic idea is to prohibit interference between identifiers, but to permit interference among components of collections named by single identifiers.", "authors": [{"name": "John C. Reynolds", "author_profile_id": "81100470240", "affiliation": "Syracuse University", "person_id": "PP39044240", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512766", "year": "1978", "article_id": "512766", "conference": "POPL", "title": "Syntactic control of interference", "url": "http://dl.acm.org/citation.cfm?id=512766"}