{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Symposium on Principles of Programming \nLanguages A General Scheme for the Automatic Inference of variable Typest Extended Abstract by Marc A. \nKaplan &#38; Jeffrey D. Unman Princeton University S.um[n.acy Se present tfie bes2 known algoi ~thm f_or \nt~e d~t~prn:natj.on or run-time types Ln type dsclarat:ons. demonstrate tnat it 5s ~ programming language \nrequiring no ~$ super%or to DtQer published algorithms and that it is the best possible algorithm ~rom \namong all toose that use trle same set o? ~rimit~ve ~perators+ of In th%s pape~ we pr~sent a ,model computation \nthat is an abstraction o? typeless programming languages Sucfi 3s APL, Si TL and SIJOBOL. Based on this \nmodel we present a general scheme ror autofnati\u00ad cally inPerring tne types o? the variables in a given \nprogram, ~ur type %n?erence system is prfivably more powsr?ul than tne systetms OP Jones and Mucnnick \nLJ] and Tenenbaum [T]. .In S+3ctlon II. W% ?ntroduce a model ?or tne treatment 0? type in er-znce. A \nsysten OP relationships that enables us to in?er types is discussed in Sect?o~ 111, Then SectTon IV gives \na ?ormula trlat we believe is tfie best acn~evable without intraductng wnolly new concepts ;nto the o? \nt~p~ determ%rlat~on. praDiem 5ection V justi?ies our view by s!?owin: how LO gst tne best poss;ble result \n?rom a given set of primitive operators and starting solu\u00adtions. In .5ectlon VI wd show that our solution \nis at least as good as other pro\u00adpossd methods, and Sect:on VII is an extend%d example that demonst.?at5s \nour solution can be better than Other Known Solutlofls . ---------------------------------_--,----\u00ad ?work \npartially supported by NSF grant McS-76-15255. II A Model of Computation in a Programming Language The \nbasic buildina block of our pro\u00ad gramming language is the parallel assign\u00ad ment statement, whose most \ngeneral form IS Q: (x1, x2.x3, ,.. ,xk)+(@, (Y,1,Y12. ..,11d ), @:1 (12, ,i22!. ..+Y2d1), 2 2 e, <fK1,YK2 \n. . . ..f kdk) k wfi+r+ are dist;nct variable 1 L2  XK names , @, e, ,,..,@ are operators C)f ~ -1-2 \nK degrees d1,d2, . . ,dk, respect~v~;y, and tfle Y. s are variable names JM To? simple assignment X+1 \nis included oy writing it as X+id(i). where :6 $s trle ldent:ty operator. Operztors may be O: (iegree \n0; tflat is they may cake nO arguments and yield constant values. The tntent is that varLaD3.e names \nare bound to (associated wit~) values ?rom (members Or) a universe 0? values V. liach operator aj with \ndegree dj corresponds to d. a function @j:V +V. Now tfie ,meanin,g of an assignment statement should \nbe clear. Let tne varL\u00adables Y De bound to values b~fore Jm jm assignment .J is execllted. ?fien a~ter \nQ :s executed. var~ables Xl, . ,XK become bound to tfle values W. (vll, . . ..vld)o. .o. J1 1 @j (v ), \nr?spect:vely. Jach A ~kl  vkdK K loses any vaius Lt may have been bounti to be?ore tne ~execut~on 0? \nd. All other pro\u00ad gram varia~lzs I .reta:n t!l~~r values. Jm A p~ograrri is a d%rected grav~ eacfi ~~ \n whose nodes is labeled by an instance 0? an ass:~nment statement, subject to the ?oiloiiLng restrict~ons: \n1. There :s a spec%al node wh~c!? we cali tne start/~inisn (Si?) node. 2. &#38;ivery ntide is reachable \n?ron the SF node. 3. Tne S? node is reachable ?rom every md.e . 4. T! Ie J? node is labeled bv an asshn\u00ad \n ,ment statement in ~nlch every pro,qram ~ef~ variaale appears on the Oand s?dti and no Var~~b~i[;S \nappear on tne r:g~t nand side. ~ Rrograu CXCCU.L1?.Q :s a path t~rough the program gr~ph tnat beg:ns \nat Lfie Sr node and ends at the SF nods but does not conta;n any otner ? n.stances 0? tfie S2 node. correspondence \nof the model ~rogrammin~ language to real Programming lanquages ~xecuting tbe sir n~de corresponds to \nirlitiaiizing all varia~ies. deachirrg tne SF node corresponds to program termina\u00ad tion If we like, we \nmay postulate the existence 0? spec%al value , undec:.g$g ~ V, and ~ constant f unct.:on, u w~ich yields \ntnis value. Then a typ:cal program m~gbt fiava :ts Sk node labeled wit.1 ths statenent ( L1,Z2, . . .,zt)<-(p \np, ,.,p). , J* can [~odel tne %nput and output statements 0? a real profzramz;ng lanyuaqe dith spec~al \noperators. tiects:.on state\u00ad ments can be modeled as ? 01.Lows: real language: J P(X1:X2 . ..lXk) dL \nTiidd ?ALSti new_ var$able<-p(A1 i2, . . ,Xv) . db AdmiGtEtii~. we Only lmoael t~e T-act that t~le \npr~d-cate, p, :s evaluated In a nlodel progr~m either sdge may bti ta~en a?ttir p :s evaluated, reqardiess \no? p s outcome. TBUS $here may Cx:st execution patns %n tne model o? a real program which are not execution \npatfis in the real pro\u00adgrac. But it is true that every possible real execut:on path is a possible path \nthrough tne model program Tnere?ore, any statement tnat holds true f or all execu\u00adt~ons o? a model program \nP, must also hold Lrue for every poss:ble execut.i.on or the program tnat d models. if we take any reasonable \nsemant;cs for pre~icates. ttie of set prOgrain executions is not e?~ ec\u00adtively computable, so our over-est:rnate \nor the set of execut;~n paths is a reasonable approach, and corr~sponds to the assump\u00adt~ons usually made \nin code optim:zat~on 1A, G, H, La, Ki, SC]. iie sriall assume that all programs that we analyze are correct, \n~n the sense that Cos resuit of every operat~on will be de~~ned W?ll or all input values occur\u00adr~ng dur:ng \nany execution. and tnat all executions reach the SF nods a?ter passin~ tnrough a Finite number o? statements. \nlLL ? rI* Type Determination Pro!J15rn 1? a compiler could pr%dict toe range Op values that variables \nmay take on dur\u00ading tne execution 0? a prograin, it could utilize tne ~n?ormatiorl to produce simpler, \nmore e??LcLent code to carry out the operations tndicated by the program. For example. :? t~e statement \n1%-J+K occurr +d som* wh2re Ln t~e text o-an APL program. and tne compiler could determ~ne that bot~ \nJ and K would always be bound to scalar <ntef.er values for every +xecution 0? t~is statement, ttien \ntae compiler could generat~ code tfla.t would use a simple machine instruction to add the values or J \nand K (rather than cal!~i.ng a generalized addition routine) , and could al.Locate a .sLng:ie word f \nor I in which to place the result (ratfier than bindtng 1 tO tne storage t!-la,t the generalized addtti.on \nroutinti would allocate dynam~cally) . i.loreover, :f a global check showed tfiat 1 never takes on any \nValu*s other than tnose or scalar _Lnt5gers, tnen tbe compiler could allocate I at compile time (assuming \nno recursive uses 0? 1). bauer [B] snows that sven a simple type determination scneme can result tn substantial \nsav;ngs. More generally, we would ~iKt? tO partition tfle universe or computable values, V, into ttypes. \nFor tne purposes of this paper, a LY.QC :s any subset o? V. r or instance, types may correspond to diP\u00ad \n?erent storage represent,ati.OnS. Each of lnte~3r.,re~~ aLIQayLl:l~], rga~ s~t, ~etg~~gggeog~ Srray, \nc~ac, cgar stKA2E, an@&#38;D.g (a data structure capable OP storing any value in the universe V) mifzht \nDe tyoes it Ls peP?e@tly p~~m%eaible for one type to contain values tfiat are also contained in another \ntype. It is also possible to incorporate tne constant propagation problem into our scheme by . .4----\u00ad \nhaving types such as constant 3, constant , string abc , an$d so on. In general, the comp~ler writer \n.mus t decide on tbe set 0? types he is willing to consider. Here we shall only make tfie assumptions \nthat: 1. The set of types, wbie.h we shall dsna%e by T, forms a latt:ce. + ? ne meet (greatest lower \nbound) OS two elements s,t ~ T is denoted by s~t. The join (least upper bound) o? s and t :s denoted \nby .sVt. A partial ordering < on T is giv%n by tne rule y~x w x<.y e+ XAY=X w yvx=y. Ne shall uss < for \n< but not =. There eXiStS a 19ast element Q and a qreatest element 1 such tnat ?or all s&#38;T, o< s \n<.j. The partial or.deriny .< should be f-ol~ows. interpreted as Iq s<t then variable X saying tnat a \nprogram is bound to a value o? type s is more pre\u00adC:se than merely say~ng that X 4.s bound to a value \n0? type t. 2. A symbol or exprsss~on tha~ represents an element of T will usually appear surrounded by \nbrackets whtin :t %s important tnat the reader b~ink o? t~at expr+ss:on as a subset or V as well as a \nmember of T. Bearing this in flind, we a.ssu,ne that the lattice join and meet are related to set un~on \nand intersection as ?O11OWS: l.tVs] 5 [t]U[s] and [tAs] ~ [t]~l_s]. Th;s snould be ~nterpreted as ?ol\u00ad10WS \n, IT program variable X is eithzr bound to a value o? type t or a value o? type S, then ~t is surely \nbound to a value of type tvs, wh~ch must conta~n the set Lt]dLs]. On the other hand, %? we know that \nX is bound to a value whose type %s describsd by bQ&#38;.D. t and s, then X is surely bound to a valu~ \nWkose type iS tAs, wbicn must conta~n tne set I_tlnisl. 3. (Finite Chain Condition) All chatns (sequences \nor elements related by <) tn T are of Ti.nite length. Note that this is not so strong a condition as \nassum-Zng tnat all cnalns have Lfielr Lengtn bounded by some constant. i-iowever, the f infte chain condttion \ndoes tnply that T is a complete lattice. + . . ...-.. =_ -._-_ T + An :ntroductlon to lattice theOrY \nand found ~n its bas~c de?~nitions may be re~erenc~ [J]. _.. _- __... -:..-.-- o? $ A lattice LS QOQL4.Q \nif every cha~n elementS has both a least upper bound and a greatest lower bound, To s+j~ that these assunpt~ons \nare reasonable, let us consider how such a lattice of typss may be constructed First, we cnoose some \nbasZc subsets of V, such as the example types mentioned above. may also include some alter\u00ad ~~ nated \ntypss LTj such as reaL_Qc_characLer or i~k~gsc_9.r2gLz.gz.r._gC~~.~ in this ini\u00adtial col12cti.on Or types, \nA natural par\u00adtial ordering oF tness subsets CS given by tne subset relat~on, ~. To insure tbe exist~nce \nof gr~ates~ and least types w% add V and the empty set to our collection or types. Next , we must extend \nour col-IectLon so that f or sach pair s and t 0? Subsets or V that appear Ln our collec\u00adtion, tnerz \nalso appea?s botn a unique largest subset that conta~ns the i.nt~rsec\u00adt~on o? s and t and a un<que smallest \nsub\u00adset that contains tfle union o? s and t. Tfiis assurbs tne ex~stsnce o? a greatest lower bound and \na ?L~ast tipper bound or each pa:r Ln our collection. Our collec\u00adtion is now a lattice sat~s?ying assump\u00adt~ons \n1 and 2. If we were care~ul i.n all or our selections , then we should als,> satisfy assumption 3, In \npzrt~cular, 5P He started wltn only ~nitely many basic: subsets, tnen our extens~on to a complete iatt~ce \nwi~~ also be finite Ano cfier way to tfllnx about the con\u00adstruction O? a lattice O? types, T, is to view \nthe process as th~ jUdiCiOUS selec\u00adtion or a subpartial ord+r o? toe powerset c)? v that is Coincidentally \na lattice sati.sfy~n~ assumptions 1,2 and 3. T enf3n\u00adbaum L? ] gives a very detailed example o? such \na lattice of types ?or the program\u00adming langua~e .5dTL. T~p,.e h:ey.e~~g 9ur goal i.s to automatically \nLnFer of tile type values each variable may bs bound to at eacfi po~nt in tfle program. ~~:s %n?ormatLon \nwill aid tfie compiler in deciding what code to generate ?or each statement tie begin the task by exam~n:ng \nthe operators 0? our programinin~ language . Suppose we know that at some point in a program, X, is bound \nto a value of type . t., or I<i<k. How cons%der the expres\u00ad 1 ,sLon $(X1 ,X2,. .,XK). tie Woulo liKe \nto speak about ;ts type. e names a function, cons aer tcle set ::{e(vl, . ..!vk) vi~Lt:]} , ti n+esssarily \n. includes all of tne values t~at e(X1.X2, . . ..xkj may have. Iiow let s be an element o: T sucn th..t \n[s] ~R. Then it ~s clear that the value Oe @(xl, x*....., x)k must be of type s. bus or +ac~ operator \ne, we may dep:ne a function T ~:Tk->T SUCh ~~ that ~ is t~e least type s such that [s] . . . rk). ~ and \nd = aQ. teen de tnterpret tne .monat<oni.city 0? our type in?erence ?unctLons as being tne con\u00addition \ntna% toe more precise tne in?orma\u00adt:on we have concerning tne type Oe an operator s inputs, the more \nprecise we can be :n va~ing a statement about Me operator s output. ~~ de have considered tne case where \nthe ty,oes OP an operator s inputs are Known , and tie fiave seen how we can d~duce a valid assertion \nabout the operator s r~sult . NOW suppose ttiat we have some a prior? inf ormat$on concerning the tyPe \nof an operator s result and tfle types or some of tts input.s. We may be able to capital\u00adize on tfi:s \nLnPormatLon by Us%ng M to deduce sometn:ng more about a particular input . For example cons;iier the \nAPL statement: A+-B+? Suppose w2 have krloi{ledge that A will be an integer af ter the statement has \nbeen executed, Then by the nature or the + operator. it must be teat 5 is bound to an i ntegtir value \nbepo~e t~]e +4 operator is applied -= + ltiOt12 t~~t fk LS a iatt~c~ xzr,fi partial order < Civen by \n(X1 . . . ..Xk) < (Yl, . . ..yk)  A. only  e and ~? x:.<y4 , ?or 7<i<K., where x<,y2dT. ~ and v are \nslxllarly +:xt%nfl\u00ad . ..A ~ d; ; x,y6TK, t~en XAY is the Freatsst elt?ment w~TK and x~v is the l~:l~t \nelement K ueT , such t.nat W<X<U and W$y<,u , Moreo\u00advgr, l? T sat~s~~~s the ~n~te cfla~n COn\u00ad d~c~on, \nthen so does TR. 0 yor As ,ie constructed a runct~on Te eacn operator e, so we now construct addi\u00ad tional \nfunctions M - % or ach operator as oliows. (k is the degr?e OF operator #. ) $or each j=l,2.. .,k con\u00ad \nK+lTj.T struct a monotonic function ~. ->T Suc.n trlat TJ(t ,t1,t2, .,tk) ZS tne least element Ore{ ~sT \nI Ls] ~{vjlvj~[tj] and 3 v.SLt<j. iij Sucrl that 1* V =o(vl . . ..vk)} }. de may prove each T: co be \nnonoton:c; toe proof ~S similar to +tnat of ~emrna 1 and is omi.t~ed. ;iow we would like to constder \nwhat typs inferences can be made by examintng a such as single assignment statement, Q, the ons sfiown \nin Stact. 2. ype determina\u00adtion is unusual among data plow problems in that information may b+ propagated \nbotti ?Or ward and backward. Let t be a map rem the j ~rward h?e.re.n.x: set z 0~ program variables \nto the elements oftypEsO? T givtng knowledpe about the the values ass<gned to the program s vari\u00ad~f~ \nables .DeP.ore stattilment d is sxecuted, W:SQ to construct rrom t and Q a new nap ?Q(t) tnat. descr:bes \nwhat we know about the typss of t~e va;ues assigned to the at-t$?r statement Q iS program variables executed. \n ln Constructing d e ake se the o? our knowled~e or the operators and semant~cs of tne assignment 9 \nr,atement def ~nt? {or eacn variable Z. C z we l~d(t)l(z) to De (1) L(z), t? L does not occur in statement \ni). trl occurs in Lhe m pos~t:on of tfie Ye?t fiazd side o-d. $iie expect that Lt wL1l not always be \nvracticabie to construct these best type Tj in~erence !unctiOnS . in such cases anyal monotonic ?unct~ons \nT~, whlefi approximate the f unct~ons Tj.0 may be used in tne tneory w.h:ckl ?Ollows. de say g appro.x$.~nat.es \nf f-or all x O? P, i?, . :rl tfls domain .dx)>f(x), (3) such that m otherwise. Z=Y mj l?lacKHar.d ~n~eCS.,ncg: \nLet t be a map rem the set 0? program variables z to tae elements of T g%v%ng knowledge about tbe types \n0 t!-le values ass%gned to t! le program s variables aster statement d :s executed. de CW:sh to construct \na new map bu(t) which will describe what we can deduce about what the types 0? the values o? ~e:oq~ tne \nprogram variables were statement Q was executed. In ~onstr~~~ting bti de again make use of our Knowledge \nof tfie operators and the semantics of the assignment statement. (1) t(z), if Z does not occur in statement \n~.  (2) 1< :F L occurs only on ttie le~t band side 06 d.  (3) T: (t(xm),t (yml) ,  A i_ all pairs \n(mjj) t (Y ),..., such that m2 Z.y t (Ymd )), mj m otherwise. where ~, if W appears on the left t (w) \n= [ side of Q Lt(w) , otherwise Notice tnat both ?&#38;(t) and bti(t) can be regarded as functions o? \nt t or a f ixe.d statement d. indsed. ? and b are mono-QQ ton:c functions that map LZ+TJ -into Lz+-T]*, \nsince they are just compositior]s of tna monotonic functions {Ta, J } and ~,+ : ... .. ... .-.-.--- --.- \n-Y Lz4TI denotes the set OF all map!lings Trom the set z to tne lattice T. Note that [zaTl is a lattice. \nIf r,q e [z-T] tnen we de?int? fsg wnenever ~(Z)<g(Z), fOr all Zez. Further, i? z %s a f ~n%te set 0? \n$ elements then [z-+TI is isomorphic to 1, T wnence the f~nite cnain cond%tion holds for [z4T] whenever \nit holds for T. olow consider a progralll P in our xodel o? a d~rected graph Op language consisting n \nnodes. for convenience let the S$ no(ie ~~ nade 1 , and designate tne other nodes 2,3, . . ..n. Let \nt~e program var<ables be z = {+L2,.. ..ZJ. At any gi.v!?n po;nt Ln t~e or prograin we descr~be the types \ntne values Wnich may be ass~gned to each of the variables by a mapptng t:zqT. A mapping t 3acelY dcscrz.Des \nthe types of values of z ;P, ~or each t, [t(z,)] ~ . {Vev ! v is possibly tiounti to Z: during any program \nexecut~on]. it is easy to see that ip s describes z, then all mappings x su~~~~l~t x(Zi)>s(Zi) ~or 311 \nZ,GZ safely describe Z. A mapping t is . rn~.rs. pcecise. (bet,ter) than a sa~e mapping s <f t Is saf \ne and t<s. o? pwe For each node j construct forward and backtiard %n?5renCe functions P ..andb. from \n[z~T] to [z4TI. as out\u00ad l~ned ab~ve for example node Q. By construction we have: 1. I? t:z-jT sa?t?ly \ndescribes the types of th3 values ass~gnsd to the program variables be~ore node j is executed, thzn ~j(t) \nsarelY descr~bss ttie types or tne values ass~gntid to the program a~ter var~ables node j has been exe\u00ad \ncut,ed. 2. If s:z4T sa?ely descr~bes the tYPes of the values ass:gned af ter node J has b~en executed, \nthen bj(s) sa~ely dt?scriDes the types o? the values tihlcb were assigned to the program var~ables before \nnode j was executed. itiow, couching our type ~n~erenc~ problem in tne notation we have developed above, \nour problem :s to TInd zapp:ngs x1,x2,x3, . ..xn ?rom z to T so that For eacn x and ?or all executions \nor our pro-J gram P and ?or all times in a given execu\u00adtion o? P at whic~ control reachzs node j, saf \nely descr:bes tns program variat)les j on ent~y to node j. de call such a set ofl mapp~ngs a s~~.g soluJ~Qn \nto the type Y5nd\u00ading prOb;LSIM or program P under the lat\u00adof\u00ad tice types T. lt will opr.en be con\u00advenient \nto write a proposed solution as one vector -n x = xl x2 x3 - xn)e~z+TJ + ~ and V are monotonic fknct~ons \n0? two arguments , meani ng that ir WLX and Y5U, tnen WAY ~ -XAU and WVY 5 XVU. X. s, J code 1P we can \nthen our to accomoda%~ YLnd very prec:s+ compiler can La:lor only tfiose types Sucti its of S%milarly \nB:Lz~T]n~Lz~T]n by, we def lne values which the xi s irrd:cate might arise during an actual p~ograrn \nsxeeut:on. LB(xl, x2, . . ..xn)]m = V .jf5SUCc(m) bm(xj), k~e know how to make type LnTerences when \npasstng through the nodes, in t~e Scrrse that our CunctLons C and b . 2.ndT\u00ad jJ cate how the variables \nof our program cake on new types as each statement :3 exe\u00adcuted. Miaking use Oy che in~ormatiorl con-. \ntainsd ;n the f low .gr aph 0? d, we now de?ine ~uncti.ons E and ij wh:c~ character\u00adize forward and backward \npropagation , Q? respectively, type information throu~hout the program ~,, j\u00ad s ,3 : unctLon f rom LZ~T]n \nto Lf (xl, x<, . . ..xn)]. = v ,n(xm). J mtipr cd(j) t~pes 0? tn3 values 0? tne variables at node j given \nthe types 0? tne varia~les at trl~ nodzs tnat fl(-)~ into j. cl? described Dy vector x = (xl . . . ..xnj. \n+ and O(t):O, for all t5[z~T] or O? so F(x)=F x is the inner !~roduct an nXn matrix unctions From lz-+Tj \nto L.z~T] and an n-vector OF mapp~ngs in LzATJ, Witrl unction ,applicatiorl corr~spond~ng to scalar mult~plicati~on \nand trle lattice ?unctLon V:[z+T]XLz+T1-> Lz+Tj corresponding to scalar addit$on. where succ(m) . { j \nI m~j iS an edgs i.n the ?1OW graph o? P ] In%uitive~y, TP Ym=W(xl, ..o,xn)] then m Ym expresses what \ncan be deduced about the types o! the values of the variables at node m, ,gLven the typ~s o? tfie variables \nat tne successors or node m. fLgain, we can dr%te d(x) in !matrLx notation as d x, wfier~i f-b ip ln~j \ni.s an edge O? p m D= mj 0, otoerwise \\. uotice tnat ootn F and B are monoton:c funct;ons , s~nce cQ%y \nars each compos~\u00ad tions of monotonic unctions. F and B r~pr+sent two di?f srent, but related, type in~ersnee \nsystems. The ?ol\u00adiow~ng two iemmas show ho w c~t~sr ? or B nay b? used to demonstrate tfie sa?encss Of \na proposed solution, ~eqryl~ ~: Let vectors x and s in Lz+T]n be such tfiat x ~ sAF(x), and let s be \nsafe. ~~en x Ls sa~e. p-roof : ~!~e proo? :s carried out by a strai~htTorward induct~on on executiog \npath Length. I A similar lemma holds ~or B tflat X~SAB(x),LeImJ~ 3: Let x be such where s is Sa-e, x,sGLz~T]n. \nThen x is safe. o? hop: : The proof is similar to that Lemma 2. 0 Fortunately, the two preceedin~ lem\u00admas \nnot only give a means of testing tbe sa~ene~s OF ~ solution; but they also Sug\u00ad de gest a Way to compute \na sa?~ so~LUtiOrl. shall demonstrate tfiis Yor the case of the forward type propagation system, F. All \nof tne Tollowing may also b% carried out in the El system. safe Assume we have a solution, s~[z+T]n, \nand we hope to ?.irrd a better solutlon. x. The ?act thab any x ki!lictl sat~s~ies x > s~~(x) is sa?~ \nsuggests define L~at we look ?-or t~e smallest Sucti x, namely that we Y%nd tfie s mallest x Sucti t!~a.t \nx=sAF (x). Considering s as ~ixed, r :LZ~T]n-+ LZ~T]n by s is(x) = SAF(X) (Notice tnat Fs is a monotonic \n$un~t~on because A and F are monotonic. ) Now let v=F~(Q) be ttie least ~;xedpoint Oe Fs. That is, v \nis tne least elemtint OF ~Z-~Tjn Such that v . E s(v) . s/l?(v). by Lemma 2, v is provably sa~e. Notice \ntfiat the monotonic~ty 0? P implies that s F:(g). F:(Q) i=l,2)(...,m Thus tie can write v explicitly \nas, v = 7:(0) = v ~~(oj i=l ,2,3,... many steps as long as the lattice T bas no in~~n~te cha~ns. dow \nconsidering s as the var;able, de~ine tne Function t:[Z~T]na[ZeT]n by de summarize what appears aDove \nby: The Tollowing lemma expresses some %nterest:ng acts about t he Cunct%on ~. L~.nTl@ 5: (a) $(X)<x. \nt is decreasing i.e., ~or all x, (b) f is monotonic. (c) lT2(x)=~(x), L.c., a f ;xedpoint or $. (d) d(~[(0))=7[(Q),f \nor For all all x, x, P(x) and is fop all k>O. tg.oa: (a) I(x)=F~(0) =x~2 ($(x)) < x (b) Let X<y. Vie \nclaim  !Iave r ~(Q)=Q=r~(0). IJOW assume induct\u00ad ively . h ~(uj<~~(o). T.nis , along with tne ,monotonicity \nor F g2ves us (D1) F(V~(!Jjj < r (F}(L!)) Our nypotfies~s ~s that x~y. so by (bl) and the monotonici.ty \nof A: (b2) Lx i+l(g)=x~F(F~(Qj) <. Y~F(F~(M)=F~+l(Q) which completes tne %nduct:on. tie c~a~,n (c) Let \ny=d (x)=F~(0). (cl) Y? for all i  F~(!2). and (c~) F~(.Q) = F:(O), For all i, As in part (b), we proceed \nby induction on :. At 2=0 botn (cl) and (c2) ars trivi\u00adally true . Now assume t~e induction nypotnes%s \nor (cl). That and the rnono\u00ad tonlclty of Fx imply that F X(Y)M:+T(Q). But since y LS a YixedpoLnt of \nr we flav~ x Whi.c!-l completes the y=fx(y)2F~+ (Q), Lnduction step f or (cl). To prove (c2), assume \nthe induction Qypotflesis and apply i- v to get ., hj+l(Q)= Fy(F~(Q)) =YAF(F~(tI) ), But si.nc~ Y is \na fixedpoint of we also have ~ x y=r x(y)=xAl:(y). So we can write (c2.1) r-~+ (~j = XAr(y)A~(~~(~j) \nCombining tne ?act tflat F is monoton:c witfi (cl), we see F(y)>F(P ~(Q)). By the de~inttion 0? 1.> tnis \nmeans F(~l~(~))=i~(y)Af(F~(~) ). ? nus we can sub\u00ad stitute ?or F(y)/lF(F~(L))) In (c2.1) and get fiy \ni+l(Q) =x~F(F~(gj )=r ~+l(g), Wh:cti completes tne LnductTon. F Lnally. notice that (c2j implies that \n ii &#38; Typ,e ~e.tp~.rninat:o~ A.Jgori.L.Du A consequence o? Lemma 5 LS that g;ven any saf e solut~on \ns. we can apply $ to it to get a (possibly) batter solution. f(s). But no furthf:r apglicat%ons or ~ \ncan y~eld any ~mprovernents over f(s). of course all OF tne above ar,qunents Horx equaily tie~l or t!?e \nbackwards 5nYer\u00adence system -tie can construct a $ f une\u00ad ti.on from a by de~ining B(s) = B~(Q), ~w.herv \nb s(x) = sAS(X). And we can state Lemmas 4 and 5 by just substituting the symbol $ Ln place 0? 1? everywhere \nt~a.t t appears in Lemmas J-1 and 5. .S0 g?ven .2 sa~e solut:on s we can computs a (possi\u00adbly) better \nsolution L@(s). l~otice t~at the fact taat a given sa?e SolUtLon s cannot be improved by further applications \n0? f or i% does not %mply that :t may not be improved by an appl~catiorr of $ or $, rsspt?ct:vely. It \n:s easy to demonstrate programs tihere $ T(s) gives a better solut:on than either d(s) or X(s).+ Given \nan <nikLal safe solution s, (eg. j, which $s always saf e) we can compute $ = (j~j*(s) = i) r . ..$ $(s). \n In tfie next sect;on we snail present some gene~~l results about monoton% funct\u00adions on lattices that \nshow 5 is, Xn some sense, an optimal solution to tne type determinat~on problem. v vp~j.ma~i$.y fiesuits \no? Given 3 set monotone unctions, d=t!11,h2, . ..,hn] ~ lL-~L], Whos e members ~ac,h map a complete \nlattice L into CtselF, L s meet and join functions, ~~ ~~~e~v} c lLXL->L], and ,given a set in~tial \np;ints , S={S1,S2, . . .,sM}s L, We or would like to study the set po~nts, C(ti,),l,s), which can b+ \ncomputed by arbi\u00ad t~ar:ly applyins arbitrary compos~ttons o? t~e functions or l-l anti V to tfle points \nOP a. Just what we mean by computed and arbitrary W:l.1 necorne clear as we proceed in our investigation. \n~~ Our motivation :s as ?Ollows. eacn or the points in S represents a saf e solution to t~e type deterin:nat~on \nproblen and each of trle unctLons in i-l and M preserve saf ety , tnen every po;nt in c(ii,4,s) w511 \nalso represent a sa?s solu\u00ad t~on. vie shall use the tneory tie develop to prove that ($ f)*(S) LS the \nbest solu\u00ad t:on tie can ind, g%ven operators ~, ~, 8, F , A. V, compos~tion anfi aPPl:cat:oQ o? functions, \nand an initial saf e Solut:on s $ tie shall prssent such a program at tne end or t~ls paper. Since each \npoint :n C(d,M,S) is be computable (in $initely many oper~~ tions) ~or each point c in C(H,M,S) triers \nshould be some orrnula e tnat expresses ho w to compute c rem ths sets d, [Y , and s. so, turn~ng tile \nproblem arout?d, we s~a~~ ~~rst look at a ratner larg~ class of forrnu~as, (tud), defined by: P, = U{E:: \ni=l.c?, ...} ~= d{~J k \\ J,k=l,i?, ,..} Gjlkrs where the iii s and the are g~vsn recurs%vt?ly by the \nrules which ?o11ow. intuitively, the ii s are vectors of L expressions witn values in L, and the ~j,k, \ns are Cunctions ~rom L j to Lk. (ti.i) (variable introduction) If x is a 1 variable name, then x iS \nin ~ . (jv~j) (f unotion application) If ~j.KGGj k ~JeEj and then j,k(ej)6Ek. ~ (E.iv) (?unction closure) \nIf ~k k~tik k and k ,k K,k.* eta, tnen both L,g J-(ek)e# and Srt!atest lower bound (gID) and Z ~or tfie \nleast upper bound (lub) O? an iterated application or g k to ek.) (b.:) (abstraction) If eK~13 k and \nare variable naimes, YlYY~9.+.~yj tnen k( /~,y~,...,Ye).e K e dJ k. j,x . (G.i.i) (function introduction) \nif g 1 .s the name or a f uncti.on from LJ~Lk, j,keGj,K. teen g ,k our intent is that eac~ formula in \nL K may be interpreted as an element of L e prov~d.+d we interpret each free variable as an ~~ement \n0~ L. Simi\u00ad in a Formula ~j,klarly the ?ormulas in may each be K interpreted as !hnctions mapping LJ \nto L . Since ,We are only given tnti functions Tn H %nlt:al latttce po~nts tn 3and PI and tne to start \nwith, let us cons%der how to OF toe set rormulasLnterpret Q~H,i4,sl(E?U8)LH,,q,~]. Tne notatton stands \n?or the set o? exprsss~ons e such that (1) e is a ~oymula in tne set Q, (2) ~f x ig a f ree variable \nname :n e, tnen XG {1511, 1S21, .,., Sm 1, i.e., x names an element of S, and (3) :r g 5s a ?unctton \nname occur:ng Ln e  then e~tner geti and gnamesan 2,1 element of n, or g~ti and g names an element \nof iq. TO ~QLRrpEiic.. a formula, e~(~b&#38;)~Hjf~yS~t we first iief :ne a YunctLon 1, wnich maps variable \nnames S,...,sLnto t!-le 1m or corr~spondinp lattice points S, and wbi.ch maps fhnction names 1 and hrl \nA,V LO tne corresponding functions of H and M. idext , we extend 1 to ?, a f unction drloss doma;n is \n(JUJ)L3,4,S], by recur\u00adsively ds?ini.ng: (Ii.ij l(x) . i(x) , i? x is a variable nam~ . kj]i(~(eK)j I \ni=O,l ,2,.. }~ut)~L~(g i) l(k(yl.yZ, . ,yJ)eKj is tne ?unc\u00ad ., tion f GLLJ~LKJ, given by: r(t T,t2, . \n. . ,tj) = ~(ek), where $ is trls extens<on of an interpretat~on J that is giV&#38;O by: fti, ife= the \nvariable Yi> for some i J(e) =< ~I(e), ife  some other variable or function name Note tnat trl:s de~in;tlon \n5s not circular, since Ke nas f ewer i nstances of abstraction than k(Y1, . . ..yjeKeK. (lG.ii) l(g) \n= i(g) , if g is a function name The correspondence between these rules For interpreting f ormulas, and \ntne rules given above ?or building f ormula~ should be obvious -we are just sayin~ that a ?ormula is \ninterpreted by Lnter\u00adprst:ng each of the parts of wh~ch it was built . In the case 0? rules (IE.iv.a) \nand (~1~.iv.b), it SklOU~d be nOted that the existence of greatest lower and least upper bounds is guaranteed \nby our assump\u00adtion that i, is a. complets lattice (and Qence so is each Lk). Thus I maps each o? formula \nin (EdG)[H,M,S] into a member the set (U{Li I i=l ,2,...}) U (U{LLj~Lk] \\ j,k=~ ,2,...}). def :ne C(ti,ll!s) \n {I(e)ti; e;7;dG)!~~M,Sl 1. Ubserv$ that (~,~~),(~.~:~) because of rules and (E.iv), C(H,M,S) is necessar~ly \nclosed under ?in%te Cartes:an products, funct~on applicat~on, and fWnction closures. It is also true \nthat C(H,FI,S) conta~ns tne pro\u00ad ject~on functions , 2~:Lk4L, since rule (G.i) allows us to write ormulas \no? the ~orm k(xl, . . ..xkx.x. . Also not~ce that i~ 1 ., ~:LJ~LK g:Li~L J ~C(H,M,S) and ec(ii,l~,s) \ntfien there extst formulas eg~Gi J and eeeGj,k sucn tnat g=T.(eg), t=l(er), and is a For\u00adk(xl . . . \n..xef(eg(xl.xl. . . .,Xi)) ,,l,k mula in u whose interpretation is just Thus c(H,M,S) is closed untier \n~unc\u00adtion composition. ~ g. The reader should now be convinced that C(H,M,S) % the set of all points \nand functions which can be computed rem H, M, and S by arbitrary unction composition and appl~cation. \n Two points should b? made here . First, we have Introduced the concatena\u00adtion construction (E.ii) (wfiicb \nleads to closure under ~ini te Cartesian products) to capture the notion that during a compu\u00adtation ire \nmay separately compute and store several di??ersnt values which may be recombined later by a Further \ncomputation Second, we kave introduced tfie two forms of-function closure (E.iv) to capture the notion \ntfiat we may apply a particular function arbitrarily many times, in a iterat~ve fashion. accumulating \nIntermedi\u00adate results in a meet or join, fialting only w~tin tflat meet or join reacties a minimum or \nmaximum value, respectively iQOtiCe that if Lbe underlying lattic~ satis?ies tne ?inite chatn condition, \nthen ef~ectZvely ~unction closure can be com\u00adputed. ~de would now ~~ke to Yurther investi\u00adgate t,he properties \nof C(H,(4,S). Our that ?irst result says (rough~Y speaking) all ?unct,ions in c(Ii,Iq,S) are monotonic \n C(ti,M,S) monotoni\u00adand ttiat everything i.n cally depends on t~e values %n tne sets d, M, and S. of \nan Iiecall tnat t!ls domain v = ic-w~se join ir3terpretatlon 1 ?Or the single symbol ~ormulas in (f2UG)[rI,M,S] \nis tne set 0? names for the elements o? H, M, and S. We shall say that 1 fs an glter.ngtiie l.nterpretation \nfor tne sin~ie symbol or\u00admulas in (2UG)[fi,i*l,S] i? 1 nas the same domain as 1, but 1 maps the names \nOS ele\u00adments of s Lnto (possibly) dlPperent values Zn L, maps t!le names of elernants 0? H into (possibly) \ndlr~erent monotonic ?unctions in lL-+L], and maps t9e names o? elements of ( I into (possibly) different \nmonotonic ?unctioris in LLXL~L]. A par\u00adt:al ordering on altsrnat~ve Interpreta\u00adtions :s defined by sayLng \nI fI i? and only i+ or all e in t~~ domain of 1, l (c)<I(e). itiOW we can state: T!33Qr.s~.n 1,: Let \n1 and I be alt~rnat;ve interpretations or the s~ngle symbol ! or\u00ad m;;s in (dUG)[tI,I l,Sl, such that \n1 <1. (1) ?or all e~(EUG)[i3,M,S], ? (e)<I(e). (2) ?or all g~c[li,M,S], I(!g) is a ,nono\u00adtonic f unction, \n Pcoor: The proof 5s a strai,?htpor~ard induction on tne structural complex~ty o? (number applications \nrules (E.i)-(li.iv), (G.i) and (G.it) ~~6~d in the construction) of the ?ormula e. For a g<v~n tnt?rpretation \n1, we say that Yormulas e and e ar~ egukvaign~. 2P 12 l(el)=f(e2) it is easy to see that (EUG)Lfi,M,S] \nis part~t~oned into equivalence classes by t~:s and relation tflat tile set of these equivalence classes \nSince eacn:s isomorphic to c(li,:~,s). n~mber 0\u00b0 c(ti,,4,S) has (at least) one f or\u00ad represents :t , \n mula in (EbC)lH,lt,S.1 tnat <n the text that ?O11OWS we shall Find Lt convenient to blur the dfstlnct:on \nbetween of c(fl,Ff,S) and tn%~r representa\u00ad members tive Formulas . All ormulas will be understood to \nbe interpreted by I, unless Je ~fld~catc otherwise. luot~ce that tflere is a natural par\u00adtial ordering \non toe elements Of C(H,M,S); ?or cl,c2Gc(~l,M,sj, CI<C2 ie and only ip k eit,ner (c1,c2~L !or some k \nand cl<c2 ) or Our n$xt(C1,C2GLLk+Ljl and CI<C2 ). result snows tfiat minimal and maximal ele\u00adments \no? c(H,r4,s) Sxi St and can be represented oy s;mple formulas. First , ?or notational convenience, we \ndefine: Ak = k(Y1,Y2, ..., :~Y?~~Ay2j\\rn?ehYk S = vector of S . (S 1 s2  srn) ~(Yl>Y2, .!., Yk).Y,vY2y. \n..vYk D = k-duplicator ky. (y,y, . . . ,Y) ~[L+Lk] MQX(H,N,S] (:)z(~%)) rn.axk[H,M,s] s DK(rn2ELH,Jl,s]) \n~in~J KLii,,!,S] k(x) .iF((&#38;Am+J(s,x))). where x=(x ,.,.,x  1 j) IL@l.f kM,rI,S] = k(x).~k((;~i(vm+j(s,x))), \nwhere x=(x ,.. .,x.) 1 J To prOV2 t!ld next theorem we WL1l n~ed: Pr oo?-: First notice tnat Dax ? Si \nor eac~ ., .. ----Sies, because Also tJaX=(Fi)=(Vm(S)) 2 Vm(s.] 2 S, . . notice tnat h is monotons s%nce \nit is in C(H,M,S), and that by construction ~ is ~ncreasing, i.e. , rl(x)?x, for all x. So t~i(x) I \n~=u,l,~,...} rorm a cnain And since L 5s assumed tc sati.sf y t.ne ?inLte Chain condttion all monotonic \n.?unct~ofls are continuous Li] . T!lerc~~re f or all X, - A similar ar.gu\u00ad Dk((h)$(\\/m(s))) = LTRXK. \nment shows the result f or K&#38;q k . B NOX we can state: (b) Let c ~ C(H,M.S)RILj~Lkl, for some j,k. \nTtien KI&#38;n.CJ k[H,M,S] S, c S rn~XSJ K[H,Lq,S]. Proof : Since each CGC(H,M,S) has a representative \n?ormula we can carry out a proof by induction on the structure of these formulas. tne case 09 t~e previo;:rtheorem, \nt~~re%;ill be an --.. ..\u00ad argu\u00adment each 0? tne rules (E.i)-(E.i.v) and (G:i)-(G.i.i). For the saKe of \nbrevity de only prtis~nt t~e argument for rule (E.iii). After seeing this, the manner in which the rest \nof the proof could be car\u00adried out will becoine obvious. !issurne c ~ C(H,M,S)nLk can be written as g(e), \nwhere g ~ C(H,M, S)fil.LjaLk] and e ~ C(H,N,S)nLJ and both g and e have smaller minimal f ormulas than \ndoes c, By the induction hypothesis e S rnaxJ[H,M,S], Hence by th$ monotonicity o? ~, g(e) < g(maJ). \nThe i.nductio~ hypothesis also guarantees that g ~ N~K~J klH,M,S]. so g(gaxj) < ma.~:j k(rnaxj), Wkli.co \nequals ~ax:[d,iq,S] by the preceding lemma. A similar argument shows that QLn.KIH,l~,sl < c. II Now, \nlet us apply Theorem 2 to the solution Let d={$,@,F,B}, or Sect+on Iv. PI={A,v}, and S = {s} for some \nsafe solu\u00ad tion se ~Z->Tln, where Z={Z1,Z2, . . ..ZI} is the set OF variables o? an n-node ?1OW graph \n. de can now show tnat safe ~~eor~m ~: The best solut~on in .- .. C(H,M,S) over the lattice [z+T]n is?= \n(4 r)%s) = ($ fi)f(s). Proof : By previous theorem ul!.t9 .. the L=[z+T]n, we know that the smallest \nele\u00ad ment in C(H,M,S)~lz+T]n is Q3(s). But notice that because $ is decreasing, and Bx is monotonic, \n?or any x we have $(x) = B;(Q) ~x($(X)) <. BX(X) = xAB(x). Sim~\u00ad larly, $(x) s xAF(x). Moreover , because \n~ is decreasing, $($(x))<!(x), and because $ is decreasing, and is monotonic, F($(x)) <1(x). Combining \nthese ?acts with a little lattice al!?ebra, we get SLnce ($ T) is a decreasing f unct%on, no confusion \nii:ll result frOm writing ($ tl )x(s) as (@ t)X(s). A similar remark appl%es ?or $ $. QQtimaA.i.i Q: \nt and-B Observe that $ :s not directly expressible in terms or ~~n~ G, in the sense that, unless Q is \n~n S, the ?ormula ~or T, whicfi is kS. ((iy. SAF(y))*(Q)), is not in C(tF,B},{/\\,//},Sj. A similar statement \napplies to ~. Because O is gen\u00aderally not a saf e solu~,ion, we do not wish to introducz Q into S. To \nexplore tne propert~es of ~ormulas ltke those ~or $ and $ we shall def lne a new class of com\u00adputable \nobjects A(El,,ti,S). A(H,M,S) iS much like C(li,Lq,S), except tnat in detin\u00ad~ng the set O? underlying \nformu~~s and their Interpretations , we add rule (E.v) and its interpreting rule (IE.v): (E.v) (least \nf ixedpoint formation) 1~ ~lj ~J,keGj,K, (2) ~j,k bas no f ree occurrences 0? variables y ,,... 7Yk7 \n(3) el, . . ..ej~El. and (4) n names a ?unction in Ii, then let P= ~(Yl!. ..,Yk ). gJ K(n(el ),. .,n(ej)). \n(Note that F is a member o? Gk K). Z4 kk Tnen ~ (J2K)~E , where Q = (0.,...,0) k represents the least \nelement of L . (IE.V) I(r%f)) z lub{L~(?)]i(Ok) ! i=o,172, . . . }, which is the least ~ix\u00adsdpoint o? \nt~e ~unct~on 1(? ). w% are very carefui :n spec:?ylnp tne form Qf FUnec:on F tn rule (iv) Decause WG \ndo not want unsa~e solut$ons to sncsr i nto ~(H,L4.sj. In part~cular, tne applZ\u00adcat:on 0? a ~unction \nin H to eac~ argument J,K . or g iS one way to assure saf ety Ln tne presence 0? a least f i.xedpo:nt \noperator, altnough it %s not the only conceivable way . Formally, we let, i be tfle set o? all ormulas \nt.Dat can be built by recursively rules (i.i)-(E.v), (G.i) and ~g:;~~;~ ~et I be the natural Lnterprsta\u00adtton \n?or the names 0? tne elements of 3, ,4, and 5; and let f be tqe extsnsion of I given b,y rules (IE.i)-(Ii.v), \n(IIJ.1) and we (lG,li), Tnen define A(tl,M,s) = { l(e) ; eGdL13,M,S] }. A s w% did wh~le discussing toe \nelements o? C(ti,kl,s), we shali usually denote tne members of A(H,tl,S) by tkeir representative ?orinulas, \nunderstood to be interpreted by I. In part~cula~, not+ that c = iy.sl\\rl(y) e A({F],M, {s}) s and tnat \n~ = ks.F~(0) can be written as d-= ks. ([ky. lkx. sAxl(F(Y))li(Q) ), which ls Ln a form adm~ttsd by rules \n(E.~)-(E.v), (G.}.) and (G.:.:), So$e A({F},M,S), f or any S, since there are no fr~+j variables tn the \n?ormula f or if. similar Oriflu.las can be g~ven to demon\u00adstrate tnat 8 and $ are in A({B},M,{s }). s \nT!1e Yellowing lemma expresses the obs~rvation t.nzt all ~unct~ons in A(H,M,S) are monotonic and that \nall objects <n A(H,A,S) depend monotonically on 1, Lema j : Let 1 and I be alternative LnterpretatLons \n?or tne single symbol ?or\u00ad mulas in ll[H,i4,S], sucn that I ~1. Then (1) for all e~RIH,M,S], I (e)<I,(e). \n (2) for all @RLti,M,S] sucn that g is in a ?or.m given by either rule (G.i) or (G.i.i), l(g) is a monotonic \n~unction.  <200:: The proof ;s essentially tfie sams as tna c oe T!2eorem 1, u An %mnediate consequence \nof Lemma 7 is tnat $ and @ are monotonic unct~ons; thus we have an alternative way of demon\u00adstrating \na fact ttiat ~e stated ezrlt$r as Dart (0) 0? Lemma 5 tie shall now show that, tn the case where Ii={F}, \ni l={~,v}, S=iS~, . . ..Sm} ~ lattice L, and F ~lL~L], then A(ti;lti,s) has minimal elements. As usual. \nail Lnat f o~lOws WILl~ still Qold i? B and 1) are uniformly .suDstituted ?or i and ~. respec\u00adtively \n. Just as w+ defined rni~ and .mjnf . we no d de! ine: l~~LF,i4,S] = t(~m(s))+ jQWK[F,iY,S] = LJk(lMJLF,:4,S]) \n= ~Qw~J kLj ,i4,SJ t~le context makes ouris conven~ent and meaning clear. Also, s hsrs stands For a vector \n0 the m elements of S. :~t~. D%(Am+J(S,X))). where ,..., Xj) 1 Corresponding to Lemma 6, we hzve: l k(lOWjLF,M,S]) \n LSMYQ ~.: For all j,k, ~Qwf . . = JQJ./[F,l4,sl. PCOOE: ? he proof is much like that of Lemma 6, the \nkey pOfntS being that $ LS decreasing and monoton;c and that $ $=$. dut tnese acts ars g:vsn by parts \n(a), (b), and (c) of Lemma 5. 0 TQe,o~eN 4: (a) Let a ~ A(F,i l,S)fiLk, f or some k. Then a ?. @N.kLl~,: \nl,S]. Then  (b) Let a ~ A(F,@fIILj->Lk]. a ~ Joyr kLF,,vl,S].  f COAC : Tn~ proof c~ose~y ?o~~OWS \nthat ~f ~i~eorefn 2, excegt that we must present a new argument corresponding to tfie new YUle (E.v). \nK Assume a ~ A(,F,/4,S)~L has a -.. representative ?ormula of the form ?*(Q.k), where P = (!f(yl, .!. \nJYk). !3j k(F(el)4. ,t .F(ej))) ~j,k 6 A(F,&#38;l,S)nLLk~Lk], and , I  ej are each of a ~orrn ad.nltted \nby rule (t,v). By trle ~nduction hypothesis. ~~~ref or~ u-{Y1, . . ..YK}. , Decause all functions belonging \nto A(F,,.],S) are nono\u00adton~,~, (1) f lk(Y). [UJ k[F,M,S]] (F(lQxIF,M,S ]), . . ..F(U[F ,M,S 1)), where \ny = (yl ... ..Yk). T!Ie rignt hand side o? (1) can easily be S!loh n to t) e ?qual to k(y ). ok f F~ \nr(Al+k(s,y)), s=where Am(s). we claim ?:(OK) 2 Dk F~(Q), ?or all :~o. T!lis :s shown by induct:on on \ni. For :=0 the claim %s triv%ally true. 140W t)y the :nduct~on hypothesis and the mono\u00ad f~+l(Qk) > ?(DW(Q)). \nton;c:ty 0? f , ~KI~S and tnequal~ty (1) yield (2) ! i+ (QK) Uk6$oh-s -t(A +L:(s.uk F;(Q) )). T!~e right \nhand side of (2) may be Peducsd to uK ~ Fs !$ F ~((l), which is seen to eciual o? bk F:+~ \\O), by twice \ninvoKing part (d) a LeMM; b. This completes the %nductLon step. ; Sowenave a =? I  lub{DK F@} = Dk(lub \nJowk[F.M,sl. 0 Theorem ~ SayS that giVen some saee soiution s~[z~Tln, tns best sa?e solution tn A({F}, \n{~,V}, {s}) :s El (s). or, trr other words, gi.v~n typ~ i.nf zrence ?unct~~n F, computing if(s) is an \noptimal way to use F to improve a safe solution s. We rem~nd the reader tfiat similar remarks can ~)~ \n made about ~. Other researchers hav3 proposed alternative methods ?or computing ffood Sape solutions \nto thti typs ?inding prob\u00adlem. In t~lis section we express some 0? these metnods ~n the notat~on Wn:cn \nw% have d%veloped above. de tfien prove the insqualt%es whicti Indicate that our msthod y:elds better \nsolutions. Jones and Hucnnick [J] construct sys\u00adt+ms of equations which correspond to f or\u00adward and bacK.4ard \n~nfertince 0? types. in our notation their bac~%ard system 1. corresponds very closely tot y = B(Y) \nand tfielr ~or ward system is just X=F y(x). ?ri~y suggsst solving the backward system for its maximal \nixpoint , subst~tusi~!z this into tfie ?orward system and solvink~ ?or the minimal eixpoint. That is, \nthey set and ~. = LJ* (0) = t(yo) L1 Y, ) our kechni.que 5s somewhat morti ,~en\u00aderal 5.n that we can \neas;ly incorporate any additional information provided by a given sa~e solution s which might, For example, \nbe derived from user declarations wltfiln ~ In tineir paper, Jonss and duchrr;c< also suggest the possibility \nOP eo,nputi.ng B as iB(x)]m = ~ bm(xj), rattier than US\u00ad j~succ(m) ing the join xe proposed Ln Ssction \n11.L. de do not c~ns%der this v+rs%on o? the~r algorithm; as pointed out in LJ], it can lead to ~ncorrect \ndetermination or types tixcept under vtiry strict assumptions about program behavior. tne program. \nAlso notice that ii j)(~.) = which :s Jones and So our techn~aue LS at ieast as power?ul as tnat of \nLJ]. ?enenbaum s L ?. <dea is to compute a safe Solutian Ln two ~:r.a~-ss ~ ir.~t an transla.$%an 0? \ny to lower case i? y is a character string. e(x,y) returns tne sum 0? x and y ip DotCl x and y ars numbers, \nreturns tfie c~flc~teq~t~on o? x and y ~~ both x and y a?e charact~r str~ngs, and is oto?rwise unde?:ned. \n TO orm our latt,:.ce o~ types, we T~(rQal,y1,y2)[>QoQ.3~ tQe bas~c types: -1 rgai : n.&#38; Qklac o \n.-.. ---. -..... ----- __________. . yc?al = tae sst of reai nunb$rs . . 1Psal real. (1 o. .r~~ i.g; \n= trl+ set 0? integers EeaL ~gal real Q .-oCgal = the set o? all character int :nt. 0.. c! str!.ngs g \nQ o c1 -.. !2 ._ and extend to a lattice, T, which 5s shown 0o 0 Q di.agramat~cail.y hy: ~~(~nt1y1,y2) \nYl\\Y2 i 1 gtia~ int GQ.3r Q ---_, .-..__ -.-_,_______ . ._ __ . ,. ,.___ _ f 1 real resl i.n$ Q o ~~al \n{ rea~ r9aL int. o o int t:rlt :Jlc o g I ~9.. Qrlar!!2 o Q o .. 0 0! Qo0o0 ... -. TRe typs ?unctLo5s, \n{ IJ ] are de+ ined op. by: Also. ?:(0 Y,.Y2) = JJf for .ali y, , Y2 and x. T$(x,jI ~7y2) T:(x,Y2,y1), \n?or ~~1 pro\u00ad 1: 2: 3: 1 Forward Q.1,?2,F3:T are given infer?nce 2->T2 ?or statements by: [rl(tA,tB)lA \nT:n unctions 1 , 2, and 3 So we nave the ollow%ng relatzons: Lf2(~A,tB)]A = &#38;l(tA) ($ f/)*(l) \n< @ N(jj < G*(f(j.)) < f(l) = ff$(~j = ~ B*(Jj %s str:ctly TQUS our proposed solut:on better than e:t,ner \n?enenbaum s so?Lution or [f3(tA,~B)]A = T:(tA,t3) + Jones and Muchn5cK s solution on tfl:s example. = \nl :(MA,tB) fi~fer~nc~sL~3% tBjlB The subscripts A and B reference t.~e com\u00adof a 2 LA] AnO, A. V.. and \nJ. ~. Unman, l!DQ ponents vector ~ T wQlc.Q descriDe ?Q.ory O: ~ars~ng. Trgn~l,at.iOQ, aQd L . . variables \nA and d, respect~ve~y. . .0DQ2L:M:vol. H, .QQrnpiLing, Prentice-Hall , Englewood Cl;.P+ s, No Tne matrix \n0= c , the ! orward propaga\u00adtion ?unct,~on 5s : J ., 1973 Q g? 3 {110!ss LB] Bauer, A. ?!. and d. J. \nSaal, r =f APL rsally need run-time checKi.ng? ,  1 < o SQ~twa.re. -trzict.zc.e a~d. gxper~enGg, vol. \n4, 1974, Pp. 12Y-130  gf.gL Backward Inperence funct~ons -- .< :-lgory22 Lo] l)onnellan, T.. Latt4ce,,. \n.<+. , Per\u00ad gamon Press bl b2 b3:T T are ~~ven J : LGI Graham, S. L. and #l, iiegman, 1A cast [bl(tA,tB)]A \n= 1 and usually l~near algorithm or global ?1OW analys~s JACM, vol. Lb1(tA,tB)]5 I 23, NO. 1, January \n1~ ?b. pp. 1?2-202 Lb2(tA.tB)lA = T~l(tA, l) . Lb2(tA,tB)lB = td Lb3(tA.tB)]A = ~(tA,. LtB) Lb3(tA,tB)]B \n= TjtA,l.tti) ?he .natrlx o? t:ne backward propaga-Li{a] Kam, J. B. and J. 1) Unman , Mono\u00adt~on funct~on \n~s: tone Data F~o-w Analys%s Frameworks !, o Qta Inf~grn~t:ca, vol. ?, January bl \u00ad197 7. pp. 305-31 \n7d= g b2 b2 (o LKi] iildall, G. A., A unif-ied aPProach b3 Q to global program opti.mt.zat2.on , of \nPcQcg.gd_irlgs _... AM! 5Y.mPQ?.2u3 Qn ide can now compute: ?c2nQ:.IzLQs 0: &#38;oglalNrEiQg L..aIW&#38;LEs>. \n1973, pp. 194-2(JO + Muchnick LPI] points out tnat for ! UAP(J, tie can also $(1)=1 compute tnat: the \nwas language developed, ?or which constraints tne on LJ] algorithm tne semant\u00ad ($-tl)*(fl) = ff $ ~(l) \nics 0? operators guarantee that ($ F)*(lI is tne same as fd*(.1). 74 [S] Scott, l)., QatQ XJQ$?S ?+s, \nLatL;c.gs, unpublished lectur e nat~s, Matnemat\u00ad ica~ Centre, Amsterdam, Juns 1972, see also a paper \n0? toe same Qame in SIAI JQMrnaL or Computing,, vol. 5, I!o. 3. September 197b, pp. 522-567 [ ~j Tenenbaun, \nA. , TyJ.XJ Qetc.paQIZU&#38;oQ :Qc Ugry tiig~ LevQQ. ~ag&#38;u3.ge9. HePort liso-3, Courant Institute \nof Mathematical Sc5ences, New York University. 1974 \n\t\t\t", "proc_id": "512760", "abstract": "We present the best known algorithm for the determination of run-time types in a programming language requiring no type declarations. We demonstrate that it is superior to other published algorithms and that it is the best possible algorithm from among all those that use the same set of primitive operators.", "authors": [{"name": "Marc A. Kaplan", "author_profile_id": "81537254356", "affiliation": "Princeton University", "person_id": "P187424", "email_address": "", "orcid_id": ""}, {"name": "Jeffrey D. Ullman", "author_profile_id": "81100314798", "affiliation": "Princeton University", "person_id": "PP39037330", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512768", "year": "1978", "article_id": "512768", "conference": "POPL", "title": "A general scheme for the automatic inference of variable types", "url": "http://dl.acm.org/citation.cfm?id=512768"}