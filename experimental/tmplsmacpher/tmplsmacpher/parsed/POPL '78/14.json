{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Symposium on Primci.pies of Programming \nLanguages A SIMPLIFIER BASED ON EFFICIENT DECISION ALGORITHMS Greg Nelson and Derek C.Oppen Artificial \nintelligence Laboratory Computer Science Department Stanford University Stanford, California Abstract \nWe describe a simplifier for use in program manipulation and verification. The simplifier finds a normal \nform for any expression over the language consisting of individual variables, the usual boolean connective, \nthe conditional function cond (denoting if-then-else), the integers (numerals), the arithmetic functiotls \nand predicates +,-and <, the LISP constants, funcliom and predicates nil, car, crfr, cons and atom, the \nfunctions store and select for storing into and selecting from arrays, and uninterpreted function symbols. \nIndividual variables range over the union of the rationals, the set of arrays, the LISP s-expressions \nand the booleans true and false. The constant, function and predicate symb,~ls take their natural interpretations. \nThe simphfier is coraplete; that is, it simplifies every valid formula to true. Thus it % also a decision \nprocedure for the quantifier-free theory of rationals, arrays and s-expression sunder the above functions \nand predicates. The organization of the simplifier is based on a method for coinbinin~-ciecisiun algcuitnrns \nfor several theories into :. single decision algorithm for a larger theory containing the original theories. \nMore precisely, given a set S of functions and predicates over a fixed domain, a satisjiability program \nfor S is a program which determines the satisfiability of conjunctions of literals (signed atomic formulas) \nwhose predicates and function signs are in S. We give a general procedure for combining satisfiabiiity \nprograms for sets S and T into asingle satisfiability program for S uT, given certain conditions on S \nand T. We show how a satisfiability program for a set S can be used to write a complete simplifier for \nexpressions containing functions and predicates of S as well as uninterpreted function symbols. The simplifier \ndescribed in this paper is currently used in the Stanford Pascal Verifier. This researcf~ was supported \nby the Advanced Research Projects Agency of lhe Department of Defense under Contract MDA903-76-C-0206 \nand by the National Science Foundation under contract MIX 76-000327. 1. Introduction In this section \nwewilldefine thesyntax andsemantics of the language accepted by our simplifier, and give some examples \nof simplifications. We will also define awtisfiubility )rogram for a set S of functions, predicates, \nand constants. Essentially, such a progralm determines the satisfiability of conjunctions of hterals \n(signed atomic formulas) whose predicates and function signs are in S. The formal definition specifies \nthe interpretations of the elements of S in such a way that it makes sense to merge satisfiability procedures \nfor two sets S and T into one for S uT. Section 2 gives our method for doing this, based on Craig s interpolation \niemma ([Craig 19.571). S@Orr 3 shows how a satisfiability procedure can be used to implement a simplifier \nfor arbitrary expressions. Section 4 contains some concluding remarks. 1.1 Language Accepted by the simplifier \nThe simplifier accepts the usual boolean connective and also the three-argument function cond (cond(p,a,b) \nmeans if p then a eke b). The other functions, predicates, and constants to which the simplifier currently \ngives an interpretation are those of the following theories: the theory of rationals under addition, \nthe theory of list structure with car, cdr, cons, atom and nil, and the theory of arrays under storing \n(store) and selecting (select), The foHowing a.%iolms are assumed for these functions. Arithmetic: 2 \nVx VyVz [X+o=x Ax+-x=o A(X+Y)+Z=X+(Y+Z) AX+ Y=Y+X Ax5x A(XSYVYSX) A(X<y A~<X~X=y) A(XSy Ay<Z~X <Z) A(X<J \n=X+Z<Y+Z) Ar)#l A051] We also allow the other arithmetic relations c, >, and ?, mukiphcallon by a scalwi, \nand the numerals 2, 3, ... The&#38;e can be defined in terms of O, +,-and sin the usual way. The above \naxiom is the axiom for a commutative group with a translation-invariant totai order. A model for the \ntheory with this axiom is the theory of rationals under addition and s.(Z is called Z instead of ~ for \nhistorical reasons.) Arrays: V QvVeVi Vj select(store(v, i, e), j) = cond(i=j, e, select(v, j)) The \nsimplifier accepts store and select, functions which operate on arrays or vectors. seIect(V,I) denotes \nthe Ith component of the vector V. We may write VIII for select(V,I). store(V,I,E) is the vector whose \nIth component is equal to E and whose Jth component, for J # I, is the Jth component of V. List Structure: \nd Vx Vy [car(cons(X, Y)) = X A cdr(cons(X, Y)) = Y A -atom(X) ~ cons(car(X), cclr(X)) = X A + aLom(cons(X, \nY)) A atom(nil)l Note that acycbcity is not assumed; for instance, car(X) = X is regarded as satisfiable. \nLet # be the conjunction of the above axioms. Given a quantifier-free expression F, the simplifier tries \nto find the simplest F such that ~ entails F = F and returns F . In particular, if ~ entails F, the simplest \nF such that ~ entails F = F is the boolean constant true, which the simplifier will return. Thus the \nsimplifier is a decision procedure for the quantifier-free theory axiomatized by ~. The results in this \npaper apply to many logical theories, but we will illustrate them with the theories which our simplifier \ncurrently handles. We use z, V, and ~ as names for the theories of rationals, arrays and list structure. \nWe also use these letters for the axioms for these theories (note that each theory has exactly one axiom) \nand for their satisfiability programs. Besides the satisfiability programs Z, ~, and ~, our simplifier \ncontains a program, called ~, which determines the satisfiability of conjunctions of equalities and diseq \nualities between terms containing uninterpreted functions and predicates. For instance, ~ will return \nunsatisfiable given the formula x = y A f(x) # f(y). ~ is therefore a satisfiability program for the \nquantifier-free theory of equality with uninterpreted function symbols. 1.2 Examples of the Use of the \nSimplifier Here are some examples of simplifications. X = F(X) ~ F(F(F(X))) = X; true; cons(X,Y) = Z \no car(Z) + cdr(Z) -X -Y = O; true xsYAY+D<x A3*D22*D 3V[2*X-YI=VIX+DI; true; v = store(store(V, I, VIJI), \nJ, VII]) =JVIII = V[JJ true; This formula expresses the theorem that if the Ith and Jth elements of a \nvector V are swapped, and if the resulting vector is identical to the original vector, then the Ith and \nJth elements were the same. 1.3 Satisfiability .Programs The logical Jymboh are A, v, -, ~, =, cond, \nV and 3. A panztneter of a forlmula is any non-logical atomic symbol which occurs free in the formula. \nThus the parameters of the formula Qv Vx P(x, f(x)) = a are Q, P, f, and a. The parameters of the axiom \nfor a theory are the primitive constants, functions, and predicates of the theory. For instance, the \nparameters of ~ are car, cdr, cons, atom ?nd nil. If ~ is an axiom, then a term is an _.J?-term if and \nonly if each of its parameters is a parameter of ~ or an individual variable. We define ~-ljteral and \nfl-formula analogously. For example, x = y and x s y + 3 are Z-literals but x s car(y) is not. We call \na term an L -term if none of its parameters are parameters of any axiom, that is, if all its parameters \nare uninterpreted. We similarly define &#38;-/iteru/ and &#38;-formula. (Note that this definition only \nmakes sense if we have already fixed the other theories we are interested in; we will assume we have \nfixed ,?, ~ and V.) A Satisfiabi[ity program for ~ is a program which determines whether a conjunction \nL1 A ,.. A Lk of ~-li[erals k satisfiable in the theory axiomatized by ~, that is, whether ~ A LI A ... \nA Lk is satisfiable. # specifies a set of functions and predicates and also their interpretation; \\his \nmakes precise the definition given in the introduction. There are efficient satisfiability programs for \nz, V and ~. For z, the simplex algorithm is very fast in practice ([Nelson 19?6]). [Nelson and Oppen \n1977] describe satisfiabiiity algorithms for ~ and &#38; which determine the satisfiability of conjunctions \nof length n in time 0(n2). [Johnson and Tarjan 19?7] have ilmproved the underlying algorithm to O(n log2 \nn). [Oppen 1978] describes an algorithm which runs in linear time if list structure is assumed to be \nacyclic. The satisfiability problem for /) is NP-complete [Dowrmy and Sethi 1976], but the expensive \ncases do not seem to arise in practice. 2. Merging Satisfiabiiity Programs In this section, we show \nhow to write a satisfiability program for, say, Z A d, given one for z and one for ~ . It is not obvious \nhow to do this since there may be mixed terms in the conjunction like car(x) < cdr(x) + 1. Our method \nfor merging satisfiability programs for two theories will work whenever their sets of parameters are \ndisjoint. This is the case for z, V and ~. We will also show how a satisfiability program for a theory \ncan be used in conjunction with &#38; to decide the satisfiabiiity of conjunctions of Iiterals which \ncontain uninterpreted function symbols as well as parameters of the theory. We will first illustrate \nhow we merge satisfiability programs.  2.1 Example Let F be the following unsatisfiable conjunction: \nx s Y A Y s X + car(cons(O,X)) A P(F(X)-F(Y)) A ~ p(o) The first step is to make each atomic formula \n/rrrmogeneous, that is, contain only parameters of one theory. We do this by introducing new variables \nto replace terms of the wrong type and adding equalities defining these new variables. For instance, \nthe second conjunct would be a z-literal except that it contains a term car(cons(O,X)), which is not \na z-term. We replace car(cons(O,X)) by a new variable G 1, say, and add to the conjunction the equality \nG 1 = car(cons(O,X)) defining G 1. By continuing in this fashion we eventually obtain a formula F which \nis satisfiable if and only if F is, such that each literal of F is homogeneous. In our example, F is \nX< YAY<X+Gl AP(G2)A-p(G5) A G 1 = car(cons(G5,X)) A ~~ = ~?I -G i AG3=F(X) AG4=F(Y)AG5=Q  We next divide \nF up into three conjunctions FE, FZ and FL. F contains all the ~-literals, FZ all the ~-literals and \nFL all the ~-literals. Here is F divided up into homogeneous parts: Fz E L X<y P(G2) = true G 1 = car(cons(G5,X)) \nY< X+G1 P(G5) = fake G2=G3-G4 G3 = F(X) G5=0 G4 = F(Y) These three conjunctions are given to the three \nsatisfiability programs z, ~, and ~ . Since each conjunction is satisfiable by itself, there must be \ninteraction between the programs to detect the unsatisfiability. The interaction takes a particular, \nrestricted form. We require that each satisfiability program deduce and propagate to the other satisfiability \nprograms all (new) equalities between variables entailed by the conjunction it K considering. For example, \nif X s Y and Y s X are asserted to z, it must deduce and propagate to the other satisfiability programs \nthe fact that X = Y. The other satisfiability programs add X = Y to their conjunctions and the process \ncontinues. Eventually, either some satisfiability program will find that the conjunction it has received \nis Unsatisfiable (in which case the original formula WaS unsatisfiable) or else the propagations will \nstop with each conjunction satisfiable. In this case, one more test, described in the next sectlorr, \nmust be made to guarmi tee that the origiri ai formu!a is satisfiable. (In our example, this test is \nnot needed.) Let us illustrate this by continuing with our example. The satisfiability programs z, &#38; \nand ~ have just received, respectively, Fz, FE and FL. (V is not needed since there are no V-terms.) \nAt first, only ~ can deduce an equality between variables: the equality G 1 = G5. It propagates this \nequality. z can make use of this fact and propagates X . Y. / now propagates G3 = G4. When z receives \nthis new equality, it propagates G2 = G5. &#38; now has an inconsistent conjunction, and signals unsatisfiable. \nThe following shows the Iiterals. received by the satisfiability programs, together with the propagated \nequalities listed in the order in which they were propagated. z &#38;J x~y P(G2) . true G 1 = car(cons(G5,X)) \nY<x+G1 P(G5) = false G2=G3-G4 G3 = F(X) G5=0 G4 = F(Y) G1=G5 X=Y G3 =G4 G2 =G5 unsatisfiable There are \nseveral important observations to make First, the only interactions that take place between satisfiability \nprograms is by propagations of equalities between variables. We prove in section 2.3 that this is sufficient \nfor completeness (it is sometimes necessary to do a case-split as described in section 2.2). It is \nimportant to realize that it is never necessary to propagate disequalities, nor equalities other than \nthose between variables. This is intuitively plausible. For instance, after receiving G 1 = G5, there \nwas no need for z to propagate that Y s X or that X = Y + G 5, even though these were deducible facts, \nsince none of the other satisfiability programs could make use of this information -none of them knows \nanything about < or +. Further, it is plausible that no disequality, such as x # Y, need be propagated, \neven though every theory shares = and =: the disequality x # y is needed to prove inconsistency only \nif x = y is deduced. But if some program deduces that x = y, it will propagate this fact to the other \nprograms, in particular the one that has deduced x # y; the latter will deduce the inconsistency. Finally, \nthe only satisfiability programs that made use of a new equality, such as x = y, were those programs \nwhose conjunctions contained occurrences of both x and y. For instance, when .# propagated G 1 = G5, \nonly Z ever made direct use of this equality. It is in fact the case that when equalities are propagated, \nthe only satisfiability programs that need to receive the equality are those which already know about \nboth variables in the equality. 2.2 Joint Satisfiability Procedure In this section we present a joint \nsatisfiability procedure which combines satisfiability algorithms for several theories. We assume that \nwe have just two theories ~ and ~f with no common parameters (the general case follows easily) and that \nwe have satisfiability procedures for determining if ~-literals, ~)-literals and ~-literals are satisfiable. \nGiven a conjunction F of Iiterals, the joint satisfiability procedure determines whether ~ A (f A F \nis satisfiable. FA, FB and FE are program variables containing conjunctions of literals. 1. [Make F homogeneous] \nAssign conjunctions to Fp FA, and FB by the method described in section 2.1, so that FE contains an E-formula, \nan J-formula, a e?-formula, and A B FEAFA AFBA ~ AL??issatisfiable iff FA ~ A# is. 2. [Unsatisfiable?] \nIf any of FP ~ A FA, ~ A FB are unsatisfiable, return unsatisfiable, 3. [Propagate equalities] If any \nof the formulas F,_, ~ A FA,  # A FB entail some equality between variables which is not entailed by \nboth of the other formulas, then add the equality as a new conjunct to whichever of FA, FB and FE do \nnot entail it. Go to 2. 4. [Case split necessary] If any of the formulas F~ ~ A FA, 8 A FB entail a disjunction \nU1 = VI v ... v Uk = Vk of equalities between variables, without entailing any of the equalities alone, \nthen apply the joint satisfiability procedure recursively to the k formulas FA A FBA FEA U1 = VI, .... \nFAA FBAFEAUk = Vk. If any of these formulas are satisfiable, return satisfiable. Otherwise return unsatisfiable. \n 5. (If this step M reached, there are no equalities to propagate and  no case splits to be done, and \nFE, F&#38; FB are each satisfiable.) Return satisfiable. Clearly if the procedure returns unsatisfiable, \nthen F is unsatisfiable. We will prove in the next section that the procedure is also correct if it returns \nsatisfiable. The joint satisfiability procedure we have described here IS too crude to be implemented; \nit will be subsumed by the simplification algorithm described in section 3.1. We conclude this section \nwith an example, involving V and Z, which illustrates case splitting. Suppose that after step 1, the \nformulas are: Fv: store(v,i,e)[j] = x A V[j] = y FZ: x>e Ax>y true E: Each formula is satisfiable and \nthe whole conjunction is unsatisfiable, but there are no equalities to propagate in step 3. In step 4, \nV propagates the disjunction x E e v x M y; each case leads to a contradiction in Z. As this example \nshows, case splitting is essential to the completeness of the method. It is potentially very expensive, \nbut we have found that it does not occur frequently. In fact, V is the only satisfiability procedure \nin our system which can cause a split. Z cannot, since a conjunction of linear inequalities in rationals \ncan never entail a disjunction of equalities, unless it entails one of the disjuncts. (Otherwise we would \nhave a convex set contained in the union of two hyperplanes but not in either of them alone, which is \nimpossible.) We can also prove that < and ~ never produce splits. We call theories which never produce \nsplits convex. When Z is extended to be a satisfiability program for the integers, it will no longer \nbe convex, since for example x=l Ay=2Alsz Azs2 entails thedisjunctionx=zv y=z without entailing either \ndisjunct alone. However, since we need propagate only equalities between variables, not between variables \nand constants, Iiterals such as 1 < z < 100 will not cause splits (unless there are 100 variables equal \nto 1, 2, .... 100 respectively!). The theory of sets, which we intend to add to the simplifier, is another \nexample of a non-convex theory; for example, x e {y, z} causes a case split.  2.3 Correctness of the \nJoint Satisfiability Procedure The proof of correctness requires several lemmas. Our first goal is to \ndefine the rtsidue of a forimula. Essentially the residue is the strongest boolean combination of equalities \nbetween variables which the formula entails. For example the residue of the formula x =f(a) Ay =f(b) \nis a=b~x=y, and the residue of x5y Ay<xisx=y. We make the following assumptions about the underlying \nformal system: (1) Individual variables are distinguishable from function variables, and propositional \nvariables are di$tmguishable from other individual variables, and (2) There is no quantification over \nfunctions or predicates. The results of this section hold without these restrictions, but the proofs \nare easier using (2) and less tedious using (l). We define a simple formula to be one whose only parameters \nare individual variables. For instance, x * y v z = y is silmple, but x<y is not. Thus an unquantified \nsimple formula is a propositional formula whose atomic formulas are either propositional variables or \nequalities between individual variables. Because of the next lemma, this also characterizes arbitrary \nsimple formulas. Lemma 1: Every quantified simple formula F is equivalent to some unquantified simple \nformula G. G can be chosen so that its individual variables are all free individual variables of F. Proof: \nSuppose F is of the form 3X ~(x). If x is a propositional variable, we can take ~(true) v ~(false) as \nG, Otherwise, let ~0 be the formula resulting from ?! by first replacing any occurrences of x = x and \nx * x by true and false respectively, and then replacing any remaining equality involving x by false. \nThen, if VI, .... vk are the parameters of ~, F is equivalent to *O v W(v ~) v .. v V(vk), since, in \nany interpretation, x will either equal one of the vi or else be different from all of them. By repeatedly \neliminating quantifiers in this manner, we will eventually obtain an equivalent quantifier-free formula \nwhose only variables are free variables of F. (If restriction (2) above is lifted, Lemma 1 holds only \nif we allow simple formulas to contain equalities between function variables. For example, Vx f(x) = \ng(x) is a quantified simple formula equivalent to the simple formula f = g.) Lemma 2: (Craig s interpolation \nlemma) If F entails G, then there exists a formula H such that F entails H and H entails G, and each \nparameter of H is a parameter of both F and G. Proofi see [Craig, 19571. Lemma 3: If F is any formula, \nthen there exists a simple formula F.es(F), the re$idue of F, which is the strongest simple formula that \nF entails; that is, if H is any simple formula entailed by F, then Res(F) entails H. Res(F) can be written \nso that its only variables are free individual variables of F. Proof Let {Gk} be the set of all simple \nformulas which F entails. For each Gx, choose Hx so that F o Hx o G ~, the only parameters of HX are \nparameters of both F and GA, and Hk is unquantified. The existence of Hx is guaranteed by lemmas 1 and \n2. Now, each Hk is a propositional formula whose atomic formulas are propositional variables which are \nparameters of F or else equalities between individual parameters of F. An infinite conjunction of propositional \nformulas over a finite set of atomic formulas is always equivalent to some finite propositional ~ormula \nover these atomic forimulas, so there is a finite formula H which is equivalent to the conjunction of \nall the HA, whose only parameters are free individual parameters of F. But any simple formula Gk entailed \nby F is entailed by some HA, and so by H. We can therefore take H to be the residue of F. If ~ is an \naxiom, the ~-residue of F is the residue of ~ AF. Thus the Z-residue ofXsYAY sX isX =Y.When no confusion \ncan result, we will not specify the axiom. Here are some examples of residues. Res(x=f(a) A y= f(b)) \n= a=b =1x=y Res(x=store(v, i, e)[j]) = i=j =1X=e Res(x=store(v, i, e)[j] A y=v[j]) = cond(i=j, X=e, x=y). \n(Note that the addition of an individual variable as a label affects the residue.) Res(x +y -a-b>O) \n\" --(x=a A y=b) A T (x=b A y=a) As a final example to relate the notion of residue to that of joint satifiability, \nhere are the residues of the formulas which appeared in the example of sectio n Z.I: z L J X<y P(G2) \nG 1 = car(cons(G5,X)) Y< X+G1 -P(G5) G2=G3-G4 G3 = F(X) G5=0 G4 = F(Y) G5=G1 . X=Y A G3=C4 = G2=G5 G2e \nG5AX=Y~G3=G4 G1=G5 As we found in section 2.1, the residues are inconsistent. An essential fact needed \nfor proving the correctness of the joint satisfiability procedure is that these residues are always inconsistent \nif the original formula is. This is a consequence of the following lemma. Lemma 4: If A and B are formulas \nwhose only common parameters are individual variables, then Res(A A B) s Res(A) A Res(B). ProoE Obviously \nthe left side of the equivalence entails the right side, so we need only show the converse. From AAB \n~Res(AAB) wegetA =1(B ~Res(AAB)) and so, by CNaig s interpolation lemma, there IS a formula H entaiied \nby A which entails B =1Res(A A B) and whose only parameters are parameters of A and B. But these must \nbe individual variables, so H is simple and therefore Res(A) ~ (B =1Res(A A B)). Writing this as B o \n(Res(A) a Res(A A B)), and observing that the right hand side of this is simple, we have Res(B) ~ (Res(A) \n~ Res(A A B)), or Res(A) A Res(B) ~ Res(A A B), which proves the lemma. Now we are ready to prove the \ncorrectness of the Joint Satisfiability Procedure. We will prove that if step 5 is reached, F is satisfiable. \nIt follows, by induction on the depth of recursion, that the procedure is also correct whenever step \n4 returns satisfiable. To show that F is satisfiable, it suffices to show that Res(FE A A A FA A B A \nFB) is not false. But by lemma 4, this is equivalent to Res(FE) A Res(A A FA) A Res(B A FB). Thus it \nsuffices to show that when step 5 is reached, the conjunction of the residues of the three formulas \nis satisfiable. If step 5 is reached, F~ FN and Fall entail the same set of B equalities between variables. \nLet S be this set of equalities, and let T be the set of all other equalities between variables of F. \nWe claim that the interpretation which makes every equality in S true and every equality in T fake will \nsatisfy Res(FE), Res(A A FA), and Res(B A FB). For if it does not satisfy, say, Res(FE), then Res(FE) \nwould entail the disjunction of all equalities in T. But if this were the case, step 4 would have caused \na case split and step 5 would never have been reached. 3. Simplification based on %tisfiability Programs. \nIn section 3.1 we define what we mean by an incremental, resettabie satisfiability program. In section \n3,2, we describe how such programs can be used to implement a simplification procedure, which is a generalization \nof a joint satisflability procedure. In section 3.3 we discuss some aspects of the efficiency of our \nsimplification procedure. In section 3.4 we discuss some of its deficiencies. 3.1 Incremental, Resettable \nSatisfiability Programs An inc? etrtentat satisfiability procedure is one which accepts literals one \nby one and which can determine at any tilme whether their conjunction is satisfiable. If in addition \nit can mark its state, accept more literals, and later return to the marked state by undoing the Iiterals \nwhich were asserted after the mark, it is called resettable. Frolm now on we will assume that all the \nsatisfiability programs we use are incremental and resettable, and that they propagate the equalities \nand disjunctions of equalities which are errtailed by the conjunctions they have received, More precisely, \na satisfiability program for a theory ~ consists of a global data structure, CONTEXTA, for representing \nconjunctions of #-literals, together with the following functions for manipulating it. If Q is the conjunction \ncurrently represented by CONTEXTN then: A SSERTA(P) where P is a literal, changes CONTEXTA to represent \nQ A P. If Q A P is unsatisfiable, ASSERTA(P) returns false. Otherwise, if there are any equalities between \nvariables which are entailed by QA P but not by Q then ASSERTA(P) returns the conjllnction of all silch \nequalities. Otherwice, if there are any disjunctions of equalities between variables which are entailed \nby QA P, then ASSERTA(P) returns one of these disjunctions. Otherwise, ASSERTA(P) returns true. PUSHA() \nsaves the current state of CONTEXTA without changing the conjunction that it represents. POPA() restores \nCONTEXTA to the state it was in just before the last call to PUSHA(). boolean constant, returns an expression \nF equivalent to F in this CONTEXTA F is the normal form for F in this context. For example, SIMPATOMZ(X \n+ O) returns x and SIMPATOMZ(X -y) returns O if x = y is entailed by CL (SIMPATOMA will only be called \nwhen Qis consistent). Any decision algorithm can theoretically be used to implement a satisfiability \nprogram with these properties. However, it generally requires considerable effort to construct an efficient \nsatisfiability program from an efficient decision algorithm. We have implemented satisfiability procedures \nfor z, V, ~, and ~. The program for ,? is described m detail in [Nelson 1976]. [Nelson and Oppen 1977] \ndescribe the data structure used by all programs except Z, and describes the programs for ~ and ~. The \nsatisfiabihty program for V is trivial: it signafi splits whenever it finds a term of the form select(store(... \n);.); that is, it does the obvious split required by its axiom. Before giving the simplification algorithm, \nwe define the auxiliary function ASSERT*, which accepts an arbitrary literal, splits it into homogeneous \npieces, and calls the appropriate assertion functions. We define it for the case where there are satisfiability \nprograms for two theories ~ and Lo. In this program, PE, PA, PB ~, ~, ~ are variables containing formulas. \nASSERTx(~: 1. Divide Q into homogeneous pieces ~, ~, and ~ as described in section 2. 2. Set PE + ASSERTE(~k \nPA+ ASSERTA(~); PB + ASSERTB(~) 3. If any of P A, PB PE are false, return false. 4. If any of PA, PB, \nPE are disjunctions, return one of these disjunctions. 5. If all of PA, PB PE are true, return true \n 6. (One or more of the formulas are conjunctions of equalities, and the others are true. This step will \npropagate the equalities.) Set each of the variables ~, ~, and ~ to be the formula PEAPA APB, and goto2. \n We define the functions PUSH* and POP*; they call the push and pop functions for each of the satisfiability \nalgorithms. We also assume the existence of a function SIMPATOM* which takes an arbitrary term and simplifies \nit using the information in CONTEXTA, CONTEXTE, and CONTEXTB. It does this by calling the SIMPATOM functions \nfor these three theories. We omit the details. ASSERT*, PUSH*, POP*, and SIMPATOM* are used by the simplifier \nas a satisflability program accepting arbitrary Iiterals of the language. SIMPA TO MA(F), where F is \na non-boolean expression or a We have four observations to make about these functions. First, a term \nt in an inhomogeneous literal which has been replaced by a new variable v in step 1 of some call to ASSERT* \nmay in a subsequent call be replaced by another new variable w. This is all right, since both t = v and \nt = w are sent to the relevant satisfiability program. Second, a record is kept of the individual variables \n generated as labels for terms in step 1, so that SIMPATOM* can put the hterals back together, repl$ccing \ngenerated labels by the terms rhey represent. Thircl, it is not necessary to send all the equalities \nto all the satisfiability programs in step 6. As mentioned in section 2.2, an equality need only be sent \nto a satisfiabihty program if both variables in the equality are parameters of the conjunction represented \nin the program. Fourth, it is important to note that ASSERT*, PUSH*, POP*, and SIMPATOM* do not form \na satisfiability program, since ASSERT* may return a disjunction without doing a case split to determine \nif any of the disjoncts are satisfiable. It would be possible to change ASSERT* to investigate each branch \nof the disjunction, but this is not delicate enough to be of use in a simplifier. When a case split occurs \nfor which some, but not all, of the cases are satisfiable, the simplifier needs to ktlow whit/L branches \nof the split are satisfiable. For example, consider the problem of simplifying x e {4, -6] A x >0 to \nx = 4. The simplifier must discover that the satisfiable branch of the split is the one in which x = \n4. This is why ASSERT* returns the disjunction to the simplifier; the latter does the case split as described \nin the next section. 3.2 Cond-style simplification In this section we will use LISP list notation for \nexpressions. Our simplifier first puts expressions into cond normal jhm. (This is similar, but not identical, \nto the cond normal form in [McCarthy 1963].) An expression is defined to be in cond normal form if the \nfollowing holds. (1) The expression does not contain any boolean connective other than cond. Thus A A \nB is replaced by the equivalent (cond A B false), and -A try (cond A false true). (2) No first argument \nto a cond is a cond, Thus (cond (cond P A B) C D) is replaced by (cond P (cond A CD) (cond B C D)), \n(3) No expression of the form (cond P ,4 B) is the argument to any function other than cond; thus (F \n(cond P A B)) is replaced by (cond P (F A) (F B)). (4) Every boolean subexpression (other than constant \nsubexpressions true and false) is the first argument to a cond. For instance, a single atomic formula \nP which is not the first argument to a cond is replaced by (cond P true false). F(X=Y) is successively \nreplaced by (F (cond (= X Y) true false)) and (cond  (= X Y) (F true) (F false)). (In practice, the \ntransformation required by clause 4 is not carried out if the subexpression is a second or third argument \nto cond, since this would waste space, The cond normal form of (cond P A B), if A and B are boolean, \nis (cond P (cond A true false) (cond B true false)) but we store it as (cond P A B). In the discussion \nbelow, we assume that the transformation has been made. We will not consider here ho-w to determine whether \na subexpression is boolean.) Cond norlmal form is not a canonical form, since two syntactically different \nexpressions, each in cond normal form, may be logically equivalent. An expression in cond normal form \ncorresponds naturally to a binary tree whose nodes are labelled with atomic formulas. We call this tree \nthe corral tree for the expression. To the expression (cond P A B) corresponds the tree whose root is \nIabeiled with P, whose left son is the tree for the expression A, and whose right son is the tree for \nthe expression B. The tree for any non-cond expression E is a node with outdegree zero Iabelled with \nE. Thus every node in a cond tree is either an internal node with two sons and a boolean expression as \nlabel, or a leaf node whose label is either non-boolean or one of the constants true or false. The maximum \nnumber of nodes in the cond tree for an expression of length n may be exponential in n. But, by sharing \nstructure, the tree can be represented as a directed graph, and the amount of storage required is linear \nin n. Let N be a node of the tree. Then <Nl N2 .,. Nk> is the branch to N if N, is th~ root of the tree, \nNk = N, and, for each l<i<k, Ni+l is a son of Ni. The context at N is defined to be the conjunction L1 \nA ,.. A Lk-l, where each Li is the label of Ni if Ni+l is the left son of Ni, and the negation of the \nlabel of Ni otherwise. The context of a node is exactly the condition that must hold for an evaluator \nto reach the node during evaluation of the expression. That is, if the conditional expression is regarded \nas a program fragment, the context of a node is the strongest invariant assertion on the arc leading \nto the node. For example, consider the following expression in cond normal form: (cond P (cond QA B) \n(cond R C D)). The context of the node for B, that is, P A -Q IS the condition that B would be evaluated \nif the whole expression were evaluated. It follows that the disjunctive normal form of a formula is the \ndisjunction of the contexts of the leaves labelled with true in the cond tree for the formula. Cond normal \nform is much more compact than (traditional) disjunctive normal form because, in the former, disjuncts \nare represented as branches in a tree (or paths in a directed graph) and thus may share structure. To \nsimplify an expression, the simplifier traverses its cond tree, maintaining as it does so a representation \nfor the context of the node it is visiting. It ignores nodes whose contexts are inconsistent. Besides \npruning away the branches which are inconsistent, the simplifier collapses together branches to leaves \nwith equivalent labels. lf the expression is a valid formula, every leaf which IS reached will be labelled \ntrue; all these branches will be collapsed, and true will be returned. Similarly an unsatisfiable formula \nsimplifies to false. The following algorithm simplifies a formula F, which we assume is in cond normal \nform. NORMALIZE is a function which returns the cond normal form of its argument. SIMPLIFY(F): 1. If \nF is not of the form (cond P A B), return SIMPATOM(F). 2. F is of the form (cbnd P A B). Call PUSH* \n(). Set Q+ ASSERT*(P). If Q,= false, then POP*() and return SIMPLIFY(B). (P cannot be true, so F is equivalent \nto B in the context in which it appears. Furthermore, the context of B is  equivalent to the context \nof F) If Q = true then set AA + SIMPLIFY(A). Otherwise, set AA + SIMPLIFY(NORMALIZE(( cond Q A NIL))). \n(In this case, Q is a disjunction. The third argument to the cond is irrelevant, as explained below.) \nCall POP*(), and go on to step 3. 3. Call PUSH* (). Set Q+ ASSERT. If Q= false, then POP*() and return \nAA. (P cannot be false, so F is equivalent to A in the context in which it appears, and the context of \nA is equivalent to the context of F.) If Q= true then set BB c SIMPLIFY(B). Otherwise, set BB + SIMPLIFY(NORMALIZE((cond \nQ B NIL))). Call POPX(), and go on to step 3. 4. If AA = BB, return AA. Otherwise, let P = SIMPATOM(P). \nIf AA = true and BB = false, return P. Otherwise return the expression (cond P AA BB),  Note how plopagatlons \naue spliced into the fo~niula. ~oi instance, suppose that ASSERT*(P) returns a disjunction D v E in step \n2. We simplify the normalized form of (cond (D v E) A NIL), which is (cond D A (cond E A NIL)), In simplifying \nthis expressicm, A is simplified twice, once assuming D and once assuming E. The NIL is never reached, \nsince its context, -D A -E, is inconsistent with the context of F. We will now sketch the proof of the \ncompleteness of the algorithm. We say that the context of a node is convex if it does not entail any \ndisjunction of simple equalities without entailing one of the disjuncts. Whenever the context of its \nargument is non-convex, SIMPLIFY calls itself recursively on some cond expression. Thus whenever its \nargument is not a cond expression, its context is convex. The proof of correctness of the joint sa.tisfiability \nalgorlthm shows that if a context is convex, and no satisfiability algorithm has propagated false, then \nit is consistent. Therefore whenever SIMPLIFY returns from step 1, the context is consistent. If F is \nvalid, every leaf of its cond tree with a consistent context is Iabelled with true, so every term returned \nin step 1 is true. Itfollows by induction that AA and BB are always true, and therefore that the algorithm \nis complete.  3.3 Comparison with DNF-style Theorem Proving We do not know how to give an adequate \nanalysis of our simplifier; since its behavlour in practice is much better than its worst case behaviour. \nIr.steacl, wc wdl con,pare our app;oach, using co,Id r,orma~ form, with an obvious alternative approach, \nusing disjunctive normal form, which we call a DNF-style approach. We assume that we are only interested \nin proving validity of formulas and are not interested in simplifications of arbitrary expressions, We \nassume that the formula is represented as a cond tree with n internal nodes. The most obvious algorithm \nto prove the formula is to put its negation into disjunctive normal form and to test each disjunct for \nunsatisfiability. This corresponds to testing that the context of each leaf Iabelled with false is unsatisfiable. \nThe standard DNF-style approach builds up the context for each leaf from scratch, that is, from the root \nof the cond tree. The number of call! to ASSERT equals the sum, taken over all leaf nodes Iabelled with \nfalse, of the length of the branch to the leaf. This sum varies frorr O(n) to 0(n2), and has an average \nvalue of O(n 1 5), if om considers all binary trees with n internal nodes and all externa node Iabellings \nwith true or false to be equally likely. There ar< no calls to PUSH or POP. A non-resettable satisfiability \nprogram can be used. Our algorithm makes n calls to PUSH, n calls to POP, am 2n calls to ASSERT, Therefore, \nDNF-style algorithms minimiu (to zero) the number of calls to PUSH and POP, while ou a]gorithim minimizes \nthe number of calls to ASSERT, TI determine which method is better, we would need to know th expected \nnumber of calls to ASSERT which each algorithm make on realistic input distributions and the relative \ncosts of resettabl satisfiability algorithms and non-resettable ones. The fonmulas which arise in the \nStanford Verifier are oftei implications between conjunctions of Iiterals. (Formulas with thi structure \narise in program verification whenever the invarian assertion on a simple loop is a conjunction of Iiterals.) \nIf there ar n conjuncts in the antecedent of such a formula and m conjunct in tlw consequent, then the \ndisjunctive normal forml of th negation of the formula has length m(n + 1), while the cond tre has only \nm + n internal nodes. A DNF-style algorlthm ca therefore make as many as m(n+ 1) calls to ASSERT, while \nou algorithm will make at most m + n calls t~ ASSERT, PUSH an POP. On this sort of example, our approach \nseems superior. 3.4 Finding the Simplest Form problem actually arises frequently and is more troublesome \nin In this section, we will note some problems with our present simplification algorithm. These problems \ndo not arise when our simplifier is used as a theorem prover, but only when it is being used to simplify \nexpressions which do not simplify to an atomic symbol such as true. These problems arise in the design \nof any simplification algorithm. First, a problem common to all normal forms is that they may lose some \nof the structure of the original expression. It 1shard to recover this structure if the expression does \nnot significantly simplify. For instance, using cond normal form, the formula (A vBvC)A(D vEv F)is simplified \n to (cond A (cond E true (cond D true F)) (cond B (cond E true (cond D true F)) (cond C (cond E true \n(cond D true F)) false))) and (cond E true (cond D true F)) is duplicated in three places. Our simplifier \nactually converts this formula back to a formula involving the usual boolean connective, but the present \nversion of the simplifier does not find the original (and simplest) form of the expression. This has \nnot been a serious problem in our system; it only becomes a problem when the original formula is not \nsimplifiable and is in a form close to conjunctive normal form. Another problem occurs when simplifying \nconjunctions like x < y A y s x A x = y. The simplifier discovers that the last equahty is redundant \nand simplifies the conjunction to x s y A y s x instead of to x = y. (Had the equality appeared first, \nboth inequalities would have been removed as redundant.) There does not seem to be any way to handle \nthis problem without extending the set of primitives for manipulating contexts. For example, if a call \nto ASSERT made earlier conjuncts in the context redundant, this might be detected and exploited. It probably \nwould not be too difficult to modify ASSERT in this manner, but it might create unacceptable complications \nin the simplification algorithm. A significant problem concerns implementing the test AA = BB in step \n[41 of our simplification algorithm. This is intended to collapse branches of the cond tree which lead \nto identical resultq for example (cond P 1 1) should simplify to 1. If AA or BB are atomic symbols, there \nis no problem. If they contain conds, testing for logical equivalence is possible but probably impractical. \nIf they contain no conds, then testing them for equality (using the lisp EQUAL) will usually be sufficient, \nif SIMPATOM puts expressions into a canonical form. However there is a difficulty: consider (cond (= \nX 1) (F 1) (F X)), which we would like to simplify to (F X). Our SIMPATOM chooses (F 1), not (F X), as \nthe canonical form when X = 1 is known, so in step 4 AA is (F 1) and BB is (F X). A completely adequate \ntest for collapsing the two branches would require testing whether QA P entailed AA = BB, in which case \nBB should be returned, otherwise whether QA -P entailed AA = BB, in which case AA should be returned. \n(Q is the context of F, which is of the form (cond P A B).) Again the overhead may be prohibitive This \npractice than any of the other problems we have mentioned in this section. 4. Notes The language accepted \nby the simplifier is richer than that described in section 1, All predicates (including =) and boolean \nconnective are considered boolean-valued functions (that is, functions which evaluate to the booleans \ntrue and false). Terins are allowed to contain arbitrary boolean-valued expressions, Expressions are \nallowed as functions. The following simplifications illustrate this generality. F(true) 2 F(X v -X} true; \ncond(true, F, G)(X) F(X); The axio[ms assumed by our simplifier do not enforce strict typing. For instance, \ncons(X, Y) + store(V, 1, E) is an acceptable expression (that the simplifier will simplify to itself) \nWe plan to add type predicates (or type corlstants and a type fund,oil) to tl?c next version of our simplifier. \nThe simplifer does not store conjunctions of atomic formulas as strings or LISP s-expressions, but in \na graph with one vertex for each term and subterm in the conjunction. Another data structure is used \nto represent an equivalence relation on the vertices. Two vertices are equivalent if the terms they represent \nare known to be equal in this context. To propagate an equality, a satisfiability procedure merges two \nequivalence classes this can be done very efficiently. The details of this representation are given in \n[Nelson and Oppen 19771. Using this representation, it is not necessary to generate labels for terms \nwhich appear in inhomogeneous Iiterals. This representation also allows the efficient implementation \nof other routines in our simplifier more efficient, such as PUSH and POP. Obviously, one way to implement \nPUSH would be to have it make a physical copy of the existing context equally obviously this is not very \nsatisfactory. The approach we take is to keep a history of all changes we make to our global data structur~ \npopping then involves undoing these changes until we reach the context of the last call to PUSH. The \nsimplifier includes a decision procedure for the theory of the rationals, but not for the theory of the \nintegers, In this respect, our simplifier does not differ from most theorem provers. A satisfiability \nprogram for the integers would have to be able to determine whether a conjunction of linear inequalities \nis satisfiable over the integers. This ]s commonly called the integer programming problem; it is much \nmore difficult in practice than the rational linear programming problem. Luckily, most formulas that \ntend to arise in practice (at least in program verification and program manipulation) do not depend on \nsubtle properties of the integers, Further, there are some easily-implemented heuristics (such as converting \nx < y into x + 1 s y) which treat integer variables as rationals and work well in practice. We also \nwish to handle multiplication in our simplifier (multiplication of two variables muttiphcation by a constant \nis correctly handled). One approach would be to include some heuristics to handle the cases that arise \nin practice. Another approach, which we prefer, would be to implement a decision procedure for the reals \nunder addition and multiplication. Our simplifier is not a general purpose theorem prover; it cannot \nprove quantified theorems of the predicate calculus. However, in the Stanford Verifier, it is used in \nconjunction with a program called the ru.khunder which accepts user-supplied lemmas. During a simplification, \nthe rulehandler instantiates the free variables of the lemmas and sends the instantiated lemmas to the \nsimplifier, In our system, the rule handler stands in the same relation to the simplifier as the satisfiability \nprograms. The rule handler can be viewed as a satisfiability program driven by user-supplied axioms. \n Acknowledgment We thank the Stanford Verification group for their patience in waiting two years for \nthis simplifier. References [Craig 19571 W. Craig, Three Uses of the Herbrand-Gentzen Theorem in Relating \nModel Theory and Proof Theory , Journal of Symbolic Logic, volume 22, [Downey and Sethi 1976] P. Downey \nand R. Sethi, Assignment Commands and Array Structures , manuscript. [Johnson and Tarjan 1977] D. S. \nJohnson and R. E. Tarjan, Finding Equivalent Expressions , manuscript. [McGarth y 1963] J. McCarthy, \nA Basis for a Mathematical Theory of Computation , in Computing Programming and Formal Systems, edited \nby P. Braffort and D. Hirshberg, North-Holland Amsterdam. [Nelson 19761 C. G. Nelson, Documentation for \nZ , unpublished memorandum. [Nelson and Oppen 1977] C. G. Nelson and D. C. Oppen, Fast Decision Algorithms \nbased on Un]on and Find , Proceedings of the 18th Annual IEEE Symposium on Foundations of Computer Science, \nOctober 1977. [Oppen 19781D. C, C)ppen, Reasoning about Recursively Defined Data Structures , Proceedings \nof the Fifth ACM Symposium on Principles of Programming Languages, January 1978.  \n\t\t\t", "proc_id": "512760", "abstract": "We describe a simplifier for use in program manipulation and verification. The simplifier finds a normal form for any expression over the language consisting of individual variables, the usual boolean connectives, the conditional function cond (denoting if-then-else), the integers (numerals), the arithmetic functions and predicates +, - and &#8804;, the LISP constants, functions and predicates nil, car, cdr, cons and atom, the functions store and select for storing into and selecting from arrays, and uninterpreted function symbols. Individual variables range over the union of the rationals, the set of arrays, the LISP s-expressions and the booleans true and false. The constant, function and predicate symbols take their natural interpretations.The simplifier is <i>complete;</i> that is, it simplifies every valid formula to true. Thus it is also a decision procedure for the quantifier-free theory of rationals, arrays and s-expressions under the above functions and predicates.The organization of the simplifier is based on a method for combining decision algorithms for several theories into a single decision algorithm for a larger theory containing the original theories. More precisely, given a set S of functions and predicates over a fixed domain, a <i>satisfiability program</i> for S is a program which determines the satisfiability of conjunctions of literals (signed atomic formulas) whose predicates and function signs are in S. We give a general procedure for combining satisfiability programs for sets S and T into a single satisfiability program for S &#8746; T, given certain conditions on S and T. We show how a satisfiability program for a set S can be used to write a complete simplifier for expressions containing functions and predicates of S as well as uninterpreted function symbols.The simplifier described in this paper is currently used in the Stanford Pascal Verifier.", "authors": [{"name": "Greg Nelson", "author_profile_id": "81100407919", "affiliation": "Stanford University, Stanford, California", "person_id": "PP31040964", "email_address": "", "orcid_id": ""}, {"name": "Derek C. Oppen", "author_profile_id": "81332519577", "affiliation": "Stanford University, Stanford, California", "person_id": "PP42050081", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512775", "year": "1978", "article_id": "512775", "conference": "POPL", "title": "A simplifier based on efficient decision algorithms", "url": "http://dl.acm.org/citation.cfm?id=512775"}