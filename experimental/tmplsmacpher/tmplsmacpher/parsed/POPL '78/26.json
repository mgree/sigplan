{"article_publication_date": "01-01-1978", "fulltext": "\n Permission to make digital or hard copies of part or all of this work or personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, \nto post on servers, or to redistribute to lists, requires prior specific permission and/or a fee.&#38;#169; \n1978 ACM 0-12345-678-9 $5.00 Conference Record of the Fifth Annual ACM Symposium on Principles of Programing \nLanguages summary LOCAL CONSTRAINTS IN THE SYNTAXANE OF PROGRAMMING IANGUAGES~t Aravind K. Joshi, Leon \nS. Levy+ and Department of Computer and Information R. 268 Moore School University of Pennsylvania Philadelphia, \nPA 19104 The method of local constraints attempts to describe context-free languages in an apparently \ncontext sensitive form which helps to retain the intuitive insights about the grammatical structure. \nThis form of description? while apparently context\u00ad sensitive program a tree for the form of syntax is, \nin fact, context-free and allows a derivation structure to be represented as with additional constraints, \nthus allowing possibility of a correctness proof in the Knuthian semantics. A part ofAWOL 60 has been \nrestated as a granunar with local constraints. w anunars with by a suitable Finally, the the semantics \n4 by considering 1. Introduction It is also shown that parsing of local constraints can be carried out \nextension of Early s algorithm. relationship of local constraints to of progrems is discussed in Section \nsome program transformations. The method of local constraints attempts to describe context-free languages \nin an appar&#38;tly context-sensitive form which helps to retain the intuitive insights about the grammatical \nstructure. This form of description, while apparently context-sensitive allows a program represented \nas a thus allowing for ness proof in the as described in In Section is, in fact, context free and derivation \nstructure to be tree with additional constraints, the possibility of a correct\u00ad form of Knuthian semantics, \n[1]. 2, some kmown definitions and results about local constraints are reviewed. In Section 3, some examples \nof portions of ALGOL 60 syntax are restated as gramar s with local constraints, to support our claim \nthat this style of grammar corresponds to the intuitive under\u00adstanding of the derivation structure. A \nparsing algorithm for gramnar s with local constraints is breifly described in this section also. It \nis an extension of Earley salgorithm. The relationship of local constraints to the semantics of programs \nis discussed of program approaches are constraints in Section 4 by giving some examples transformations. \nIn Section 5, several to the discovery of local constraints presented. A grammar with local for a part \nof ALGOL 60 is presented in This work MCS76-19466 was and partially NSF Grant supported by MCS77-04834. \nNSF Grant + On leave Delawme from University of Delawewe, Newark, Appendix 1 and some details of the \nparser are described in Appexdix 2, 2. Background 2a. Definition of Local Constraints Context-sensitive \ngrarrunars , in general, are more powerful (with respect to weak generative capacity) than conteti-free \n~amnars. A fascinating isthat if a for analysis is context-free. First, SEMANTICS Kang Yueh Science result \nof Peters and Ritchie [31 context sensitive than the language we describe what we sensitive grammar, \na tree t, we define Roughly speaking, slice across the following recursive Definition 2.1. tree t, denoted \nG, used for gramnar G is used analyzed by G mean by a context\u00ad analysi~ . a set of proper analyses a \nproper analysis of a tree tree. More precisely, the definition applies: The set of proper analyses P(t), \nis defined as follows: (i) Ift . 0 (the empty tree) then P(t) = 0. Given of t. is a of a ii) ft=ki7-Tzh \nthen P(t)={A} UP(t_).P(t, )!. ..-P(t_) u1 11 where t o, tl, . . . tn are trees, and t denotes concatenation \n(of sets). Example 2.1 t. AAB dE ffi c P(t) = {S, AB, cde } . AE, Ae, CdB, 1 The method has linguistic \nto as local transfonnations. a better term in our present the term local transformations justified (see \nSection 4 for ; e Cd-E, Cole, cdB, c=, \u00ad origins Local context; can further and is referred constraints \nis although, also be comnents). Let G be a context-sensitive grammr , i.e. its rules are of the form2 \nA+u/c$I Y  where A s V ~ (V is the alphabet and X is the set of terminal symbols), u s V+ (set of non-null \nstrings on V) and ~, Y c @ (set of all strings on v). If @ and Y are both null then the rule is a context-free \nrule. A tree t is said to be analyzable with respect to G if for each node of t, some rule of G holds \n. It is obvious how to check whether a context free rule holds of node or not. A context-sensitive rule \nA+ u/~ Y holds of a node labeled A, if the string corresp~nding to the descendants of that node is u, \nand there is a proper analysis of t of the form p1@AYp2 which Dasses through the nodes (0.,0. s V; ). \nWe call tie contextua~ condition @ ~i,za proper analysis predicate. Similar to these context-sensitive \nrules, which allow us to specify context on the right and left , we often need rules to specify context \non the top or bottom . Given a node labeled A in a tree t, we say that 6(A, @ Y), ~, Y E V: :,holds of \na node labeled A if there ~s a path fmm the root of the tree to the frontier, which passes through the \nnode labeled A, and is of the form P1@4YP2 pl,pfw. The contextual condition associated with such a vertical \nproper analysis is called a domination predicate. The gemeral form of local constraint combines the proper \nanalysis and domination predicates as follows: Definition 2.2. A local constraint is a rule of the form \nA+ ~/cA where VA is a Boolean combination of proper analysls and domination predicates. In transformational \nlinguistics the context sensitive and domination predicates are used to describe conditions on transformations, \nhence we have referred to these local constraints elsewhere as local transformations [21. 2b. Results \non Local Constraints Theorem 2.1 [21. Let G be a finite set of local constraints and T (G) the set of \ntrees analyzable by G. Then the string language L( T(G))= [xl x is the yield of t ~dt e T (G)} is context-free. \nExample 2.2. Let V = {S,T,a,b,c,e} and x . {a,b,c,e}, and G be a finite set of local constraints: 1. \nS+e 2. s+aT 3. T+as 4. S+bTc / (a ) A &#38;(S,T_) T+bSc / (a )A 6(T, S )  5. .  In rules 1, 2, \nand 3 the context is null, and these rules are context-free. In rule 4 (and in rule 5) A+u/(j Y is just \nanothev way of writing $AY+ $W Y. the constraint requires an a on the left, and the node dominated (immediately) \nby a T (and by a S in rule 5). The language generated by G can be derived by G1 : S+e S+ aTl S+aT T+ \nasl T+aS Tl+ bSc S1+ bTc In G1 there are additional variables S1 and T which enable the context checking \nof the local cons +raints gramnar, G, in the generation process. It is easy to see that under the homomorphism \nwhich remves subscripts on the variables T1.and S , each tree generable in G1 is analyzable n G. ~so, \neach tree analyzable in G has a hommnorphic pre-image in G1. # The methods used in the proof of the theorem \nuse tree automata to check the local constraints predicates, since tree automata used as recognizes accept \nonly tree sets whose yield languages are context-fre,?. In [21 some other generalizations of the local \nconstraints are also shown to yield context\u00adfree languages, as in: Theorem 2.2. The yield of the set \nof trees analyzed by productions of the form A + f3/a A is context free where A e V z, Bcv+, a, A E \nR, where R is a regular subset of V;C. Theorem 2.3 The yield of trees analyzed by productions of the \nformA + $/a. k is context free where A e V -Z, B is a recognizable set, and a, h are expressions denoting \nsequences of recognizable sets. Again, the argument is by construction of a composite tree automaton \nto achieve the combined effect of several tree automata. In particulm, the proper analysis predicates \nof the Peters Ritchie result are computable by finite tree automata, and Boolean combinations of these \nproper analysis predicates are also finite-tree automta computable including the computation required \nfor domination predicates.. 3. Local Constraints in Syrrtax 3a. Examples 3.1 Local constraints can be \nused to simplify the syntax of context-free gramnars, for example, the most comnonly used granunar for \nthe class of simple arithmetic expressions is E+E+TIT 1: T+T$~FIF F+a\\ (E) G; below is an equivalent \ngramnar with local constraints. Note that G; gives unambiguous structural descriptions, m accordance \nwith the precedence relationships, for the arithmetic expressions. G;: E~E+E/(1 + _) A(l$ )A(T . $:) \nE+~;,E/ ( 1 :: _) E+(E) E+a Another example is a grammar for a class of binary numDers. G2 : Wo\\l L+LB \nIB N+L. LIL By using local constraints, it becomes G;: N+o 11 N+J)JN/_T N N+N.N/ ( 1 N )A(l N)A(l. ) \nA(--i 1) We will also show some more extended examples from AJXOL 60 syntax in Appendix 1. 3b. Parsing \nof Gramnar s with Local Constraints In the following, we will give brief sketch of the parsing algorithn \nfor parsing of gr annnars with local constraints. We are able to extend Earley s algorithm [4] so that \nit also checks for local constraints. In Earley salgorithm, for a given context\u00adfree grammar G (V,Z,P,S) \nand an input string w=aa . . ..a , the dotted rule [Aw.~,iI is in list I. lo? O ~? ~ j if and only if \nA+a@ is a production ~ P, and ther~ exists y and &#38; in ~~ such that S% yA ~, y % a1a2 . . ..aiand \na %ai+lai+2 . . ..aj. The abave statement can be better understood by the pictorial representation: If \n[Aw,.6,il is in I., then we are working on a potentially valid parse3.@ that there is a sen\u00adtential form \nyA6 where y > ala . . ..a.. and the dotted rule [A%. i3,il indicates&#38;t We know nothing yet about \n@ or 6. aqai+lai+2  aj To extend Earley s algoritkm to check for local constraints, it can be seen \nthat the left portion of constraints can be checked with the parsed portion y, but the right portion \nof constraints have to be carried along with the dotted rule in order to be checked later with the unknown \nportion of 6. For the domination predicates, both the top and bottom portions can be checked with the \nparsed tree when [A+a. ,il is generated. So in the first step, we have to separate the proper analysis \npredicates into left and right poritions by the following rules: (1) A~u/7(cx B) is changed to A+a/(l~ \n-)V( 7 (3)  _  (2) A+u/(~_f3)A(Y_&#38;) is changed to A-+u/(aAy) (8 A 15)   (3) A+u/(~_f3) v (y_&#38;) \nis changed to A+w/(a . B) andA~u/(y 6)  The domination predicates will be left unchanged. After this \nsimplification, the proper analysis predicates will be of the form where a and B are strings over V>t \nor negation of them. For a given context-free grammar G=(V,Z,P,S) with local constraints and an input \nstring in x$ , the parser scans the input ala2 -an strng fmm left to right. As each symbol a. is scanned, \na list of items I. is constructed w~ich represents the condition of the recognition process at that point \nin the scan. Each item in the list represents: (1) a production such that we are currently scanning an \ninstance of its right side. (2) a dot in the production which indicates how much of the production we \nhave scanned. (3) a pinter back to the pxsition in the input string at which we began to look for that \ninstance of the production.  (4) a forest representation which shows how the scanned petion in the production \nderives the terminal string. (5) a set of string which shows the constraints remaining to be checked \nwith the unscanned portion of the production.  The item [A+.(x).6(y),il is in list I. for o<i~ if and \nOnly if A+ ~ B/C is a<pmduc$i$n in P~and foy some y and 6, we &#38;ve &#38;yA6, y ~a+a2 ~~a . . ..a. \n. . . ..a.. x is a forest representa ion of a: and y ~~la set]of strings which remain to be checked with \nthe set of proper analyses of B. Definition 3.1 A tree is represented by its bracket representation, \nfor example, A is represented as S(A(C(c),d),B(E(e))). A forest is a set of trees and is represented \nas the concatenation of their tree representations. However, in the actual implementation, we do not \nneed to carry the forest representation of a in [A+a.f3,il. We can just attach an integer to each nonterminal \nin a to indicate where that non\u00adterminal derives final string. By final string we mean a dotted rule \n[A+y.il with dot at the end. We adopt the forest representation in the explana\u00adtion of parsing algorithn \nfor the clarity of constraints checking. The central part of the parsing algorithn is to generate the \nsequence of list I ,1 ,...In, which will be shown in the Appendix 2. 1 S%Ping is in L(G) if and only \nif after con\u00ad :~~:$;;;.:: for O~j~n, there exist some items of the form [S]+a(X). (Y),Ol ti In, where \nf is either an empty string or some negative constraints. The parse for w is S(x). 4. Local Constraints \nin Semantics In this section, we will develop a number of additional considerations which motivate the \nuse of local constraints in the description of programming languages. First, the use of local constraints \ncan be justified by the fact (as shown below) that, in general, a granunar with local constraints is \narbi\u00adtrarily more efficient, in terms of the storage required for the gramnar, than any context-free \nw~ for the same language. Second, local con\u00adstraints seem a natural way of describing the ratching of \ntypes between operator and operands. Third, a number of optimizing transformations can be incorporated \nin symtax by the use of local restrictions. It is clear that since grarrnnar s with local constraints \ncan only describe recognizable sets, that claims abut the descriptive power of such w ammars will, in \ngeneral, appeal to their natural ness or understandability. While such consider ations are quite important, \nthey are also partly subjective. However, the following objectives claim can be made: Local constraints \nallow more efficient representations of the grammar s of context free languages. Since every context-free \ngrammar is, by defi\u00adnition, also a local constraints grammar -with vacuous constraints, it is clear that \nthe local constraints grammar s are at least as efficient in representing context free languages. TO \nshow that local constraints are more efficient, it suffices to show that for any specified constraint, \nthere is a context-free language, L , such that the context-free grammar for L req$ires at least log \nq times the storage of theqlocal constraints s~ for L . We define L z.{w} where w i~a word of len&#38;hq. \nThen Lqis aala2. .:a q-definlteqevent. The local constraints grammar for Lq is Gl : (1) x+ ox iJEx (2)X+a/aa \nq 1 2.. .al-l There are IZI productions of the first kind, and one production of the second kind. Hence, \nthe storage required for G1 is kllZ\\+k2q. Assuming that l~I<<q, G1requires O(q) storage. Since L is q \ndefinite, it requires a q-state minimal mach!ne with IzI productions of the form X, + oX. for each state, \nplus one production of the f&#38;m Xq~l + a Since there are q-states, the cl. representation of each \nstate will require O(log q) and the regular grammar, G2 for L requires O(q log q) storage. Hence we hav~ \nshown: Theorem 4.1. For any constant k, there are languages whose local constraint grammar requires less \nthan l/kth the storage of a context-free P~ generating the same structural descriptions. Examples of \nthe use of local constraints are found in the base grammar compnents of natural language transfomnational \ngranmars , in applying selectional restrictions to the lexical items. An obvious parallel to the syntactic \nsituation is the matching of operand/operator types. In addition to this selectional restriction type \nof local constraints, there are kinds of program transformation rules which are used to modify a program, \nusually for purposes of effici enecy. It turns out that many of these trans\u00adformational rules can be \nstated as local con\u00adstraints (transfomnations) on a context-free granunar. These rules are often stated \nin the literature as equivalence preserving transforma\u00adtions of the form $(x,y) <~ Y(x,y). The point \nof view of local constraints is to prefer one of the two forms , and to use selectional restrictions \nto exclude the other form. This is why the term local transformations is appropriate. The following examples \nare based on the Irvine catalog of program transformations [51. Examples 4.1 a) x+O; y+O; z+o~x+v+z+o \nWith local constraints we can ~xclude constructions such as those on the left hand side of this transform@ional \nrule: <Stm-b + war> + 0/ l(war> + 0; ) <Stint> + <Var> + <Stint> (Note that a more detailed discussion \nof the syntax will actually use domination predicates; i.e. a syntactic rule of the form <stint> + war> \n+ <expr> will be constrained to rule out the case that the left context is, as shown, <var> + O; and \nthat <expr> derives O.) b) As noted in [21, if variables names are of finite size, then equality of names \ncan be incorporated in context free local constraints. Thus a rule eliminate @ chains can be in\u00adcorporated \nin the syntax via a local constraint: <label> + .Q/ 1 (gOto A ~~<; ~:gOtO) V1 (~ Ai:gOtO ~$: ) In this \ncase, the constraint says that t cannot appear immediately after goto, if L is the label of a goto statement. \nc) D~ibute unary operators over conditionals: a(B + E1;E2) = (Ew E1;aE2) In this case, we can restrict \nthe productions whose left hand side is <cond expr> by the constraint that they be not immediately preceded \nby a unary operator. Although local constraints can capture many of the transformational restrictions \nand therefore can be incorporated in an essentially context-free description, we do not rule out the \npossibility of nrre general constraints which may lead to noncontext-freeness. In other words, context-freeness \nshould not be used as a justification for poor style. 5. Discovery of Local Constraints 5a. From Direct \nTransfomtions In the following, we will present a set of transformation rules which can be used to transform \nB+$lBell . . . I $SBO a given context-free grammar to its equivalent D+ III BE1l. ..l ~tBsCt w~ with \nlocal constraints. They are transformed to (1) Forward Substitution A+all. ..lam /( p (l(yi_6i))) .A \nA+ yB6 B+~ A+ Y1A611 . ..l YpA~p ~ j~(~(o 1 j _ ej))) j1 They are transformed to A((~( l(nk_ck))) A \n+ YD6 kzl More rigorously, it should be stated as V 16(D ))  A+ yB6/CA A+ fi/CB A+~ll . ..I.o /( ; \n(yi_ 6i))11 They are transformed to i.1 A+ YWCA, A+ $lAell ,..lc$sAesv(~ I (+. 6.)) j .1 1 3 if there \nis no conflict in the constraints CandC such as CB does not have the kind of c&#38;stpa$; 7P 7v, where \np e Suffix(y) and v(; ((ilk_ Ck)A6(D ))) k=lis the resulting constraintsv e Prefix(d). T., from CA \nand CBfo&#38;ed as: D + ~lA~ll . ..lnkA~k (i) If CA has a domination predicate of the form 6(P _v) such \nthat v = Bu, then this predicate is changed to IS(P CI), otherwise, all predicates in CA i~included in \nCA,. This transformation rule is the rmst cormnonly used one to eliminate nonterminal symbol B. (ii) \nIf C. has a domination predicate of the form 6(U u v) such that P oA, then this (4) Merging pred~ate \nis changed to 6(u v), or if CB has a proper analysis predic=e of the form A+B v such that v . 6y and \nv 6E, then this A+ yiA6i/Xi_Yi, 1 ~i~n &#38;edicate is changed to 6 c, otherwise, the predicates in \nCB are not ti~luded in CA,. A+ yiBdi/v i_vi, 1 < i < n  A+all ..ola The production B + $/CB can be deleted \nif no B+~ll ...l~~ other production has nonterminal B on the right hand side. They are transformed to \nHowever, we will not state such complicated A+B rules in the following transformation rules for A+ ~iA6i/((xi \n_Yi) V (Pi_vi))A( ~ clarity reason. j.1 (2) Backward Substitution 7(LIjYj _6jvj)), 1 < i:n A+all...lam \n6L ai A+CL1l...lCXm/ ~ (lJ.y. Is. v.) A+Y16 611 . . . IYP66P j.1 11 11 A+6 B+611...IBP They are transformed \nto We will show the use of these transformation A+B rules to simplify the ALGOL 60 syntax (Appendix 1). \n P A+all . . . lam/ (l(y i_6i)) However, the main idea is to come out a grammar with local constraints \ndirectly rather thanA i. 1 modify it afterward. A+y1A61 1... fi(7(yi_ di)) The constraints can also be \nmerged by the YpA8p/ following rules: i.1 (1) A+u/(x Y) v (!.IX Yy )  (3) Elimination is equivalent \nto A+all... lam, B#a. A+W/(x y)  A+Y1B611 ... I YPB=6 A Yy) (2) A+o/(x Y) (uX P B+811...l~n,Bi~. \nis equivalent to1 A + u/(~X Yy ) (3) A+ o/h X lY) v (-lllx 1 Yy) is equivalent to A+u/(mPx_lYY) (4) \nA+u/(~x -Y) A (luX lYy) is equivalent to A+IJ/(_Ix lY) (5) A+u/(x Y) v (1x 1 Y) is equivalent to \n A+u (6) A+u/(x Y) A (1X IY) this production can be deleted.  573. From Skeletons One notion of the \nphrase structure of a sentence is that it captures and formalizes our intuitive grasp of the organization \nof the elements in a sentence. This is developed in meater detail in [6] where it is formalized as a \nskeletal rewriting systems. Definition (informal) A skeleton of a derivation tree is the derivation tree \nw~th non-terminal labels removed. Example 5.1 t. s a Tub Al c sb I I a s is the skeleton of t. A skeletal \nrewriting system, G = (I,P) consists of a finite set of skeletons and a finite set of replacanent rules \nS + S2 where S1 and S2 are skeletons. The ske i etal rewrittig systems are a direct analog of Brainerd \ns tree w~s. The following theorems are given in [6]: Theorem 5.1 Let G be a skeletal rewriting system. \nThe set of skeletons generated by G is the set of skeletons of a local set. (A local set, as defined \nby Thatcher, is the set of derivation trees of a context-free grarmnar. ) Theorem 5.2 For every local \nset, L, there is a skeletal rewriting system which generates the set of skeletons of L. Also shown in \n[6] is the fact that a finite set of skeletons of a language uniquely determines a minimal context-free \ngrarmnar for that language with the same phrase structuring. Further, one can define skeletal automata \nanalogous to httom\u00ad up tree automata, and the class of skeletal automata characterizes the skeletal set \nof local sets. Example 5.2 In the phrase structuring of arithmetic expressions, if we agree that the \noperators associate to the left, that parentheses dominate, and use the accepted precedence of operators, \nthen the phrase structuring of each arithmetic expression is uniquely determined --although, as noted \nin [6] the syntactic category names are arbitrary. Thu~ the phrase structure of the ex\u00ad pression a + \na $: a + a is given by the skeleton: a a lleuniqueminimal (wide-sense [7]) gramnarof arithmetic expressions \nover {+,$ } with parentheses is summarized by the schemes (the set of initial symkols, S {E O,E+,E:,}) \nEo+a 1. 2. E. +[Vll 3. E++Vl+V2  V2 c {Eo, E,:] Rule scheme 2 stands for 3 rules, rule scheme 4 \nstands for 2 rules, and rule scheme 3 stands for 6 rules. The minimal grammar is derived, in general, \n by finding the unique minimal (deterministic) skeletal automaton, assigning a different variable to \neach distinct state, and having the rules in the gramnar, G, invert the rules of the automaton, A. Thus \n, ~+x . . . . ..X nEGe +ucA. 1 A 1 xn Having developed a minimal context-free P ammar, G, yielding \nthe skeletal set, one can systematically develop all of the contexts in which to rassage the grammar. \nBut when one uses other each variable can occur, and generate a local heuristics, which only guarantee \na covering constqints grammar. Sup~se V is a non-terminal, relation among the gramnar s but do not maintain \nandX%alVa2, for some X E V-Z, al, a2 E VY , in strong equivalence, one cannot apply Theorem 5.2. is \nan allowable context for V in G. then al a2 In other words, there is a proper analysis of some derivation \ntree in G of the fo~ Y a Va Y2 Yl> Y E V: . Since the set of proper ana +1yses 21s just t i e set of \nsentential forms, it is a context-free langu\u00adage and one can effectively compute the set of allowable \ncontents up to any fixed length k. The possible left and right contents of length 1 for the gramar of \nExample 5.2 are: left contexts right contexts E~< +, ~,] +, [ E+[ +,1 E. ~ ~,+, [ $~, +, ] Note that \nthese contexts are exactly those specified by the local constraints grammar of simple arithmetic expressions \ngiven in Section 3. Example 5.3 Let G be the grammar for binary numbers in Section 3a. G: {%0, Bl, L+LB, \nL+B, N+L.L,ML}. By finding the wide sense minimal grammar, S {N, L, B] N+L.L I L.B I B.L \\ B.B L+LB\\BB \nB+OI1  the following allowable contexts of length 1 are computed. left contexts right contexts . ,B,O,l \nN B .,l,O,B,L L,B,l,O,. Incorporating these constratits into a gramnar , we obtain Gl: {x+O,X+l, x+xx/c, \nx+x.x/c A cl} )Al((l ) and x)AI( l)A=( O) where c= -(x _)A 1(1 ~1= 1( A-(. )Al( .)  In general, when \nGl and G2 are grammar s with local constraints they are equivalent to conteti\u00adfree grarrunars. Thus, \nThe quesiton of whether Gl and G2 generate the same skeletal set directly reduces to the question of \nstrong equivalence of context-free granmar s, in this casep the grammars corresponding to the minimal \ntree automata for G1 and G2. Hence, we have Theorem 5.2 Let G and G2 be grammars with local constrauts. \nIt i~ decidable whether or not the skeletal set generated by Gl equals the skeletal set generated by \nG2. Providing one chooses the set of local constratits in such a way as to maintain the s~ng equivalence. \nTheorem 5.2 is applicable, and one may rather freely use one s intuition [11 Gerhart, S.L., Correctness \npreserving program transformations , Proc. ACM-SIGACT POPL Symposium, Jan. 1976. [2] Joshi, A.K. and \nLevy, L.S., Constraints on structural descriptions: local trans\u00adformations , SIM Journal of Com.putinR, \nJune 1977. 3] Peters, S. and Ritchie, R.W., Context\u00adsensitive irmnediate constituent analysis \u00adcontext-free \nlanguages revisited~~, Proc. ACM Symp. on Theory of Computing, 1969. 4] Earley, J., lr~ efficient context-free \nparsing algorithm , CACM, 13, 1970. [5] Standish, T.A., et al., The Irvine Program Transformation Catalog \n, Tech. Rep., Dept. of Information and Computer Science, University of California, Irvine, Jan. 1976. \n[6] Levy, L.S. and Joshi, A.K., Skeletal structural descriptions, submitted for publication, 1977. [7] \nSalomaa, A., Formal Languages, Academic Press, New York, 1973. Appendix 1 In the following, we will \npresent the mdified syntax for ALGOL 60 using local con straints. Both the original and modified syntax \nare shown. The numbers (e.g. 2.5.) refer to the numbers in the Revised Report on the Algorithmic Language \nALGOL 60 (IFIP 1962). Also we will show the sequence of transformation rules which are used to simplify \neach syntactic category. Each item in the sequence is a triplet (I,A,B), where I is the number of transfomtion \nrule used, A and B are the non-terminal symbls A and B in the transfomtion rules. (see Section 5a). 2.5, \nNumbers Original: <unsigned integer> : :=<digit> \\<unsigned integer> <digit> <integer> : :=<unsigned \ninteger>l +<Unsigned integer> l-<unsigned integer> <decimal fraction>: :=.<Unsigned integer> <exponent \npart>: :=lO<integer> <decimal number>: := <unsinged integer>l <decimal fraction~l <unsigned integer> \n<decimal fraction> <unsigned number> ::=:decimal number>l <exponent part>l<decimal number><exponent \npart> <number>: := <unsigned number> l+<unsigned ntnnber>l -<unsigned number> Modified: <unsigned integer> \n: :=<digit> l<unsigned integer> <digit> <number>: , <Unsigned integer>l .<Unsigned integer>/ 1 (10,10+,10-) \n(3 ,< factor> ,<primary> ) 1 <unsigned integer> .mnsigned integer>/ l(lO,lO+,lO )llO<number>/ 7(10,10+,10-)_~101 \n<number>lO<number>/ 1(10,10+,10-)_=lOl +wm.mber>/( 1 (+,-) _~io)l \u00ad-<number>/( 1(+,-)_~10 Here we simplify \nthe writing of constraints of the form (1X Ty)A(TP_~v) to  l(kll_ 1 (Y>v) The sequence of transformation \nrules applied are : (1, <decimal number>, <decimal fraction>) (1, <unsigned number>, <exponent part>) \n(3, <unsigned number>, <decimal number>) (3, <number>, <unsigned number>) (3, <number>, <integer>) (4, \n<number>, wnsigned integer>) 3.3 Arithmetic Expressions Original: +1\u00ad <adding operator>: := <multiplying \noperator> ::=xI/l + <primary> ::=~unsigned number> l<variable>l <function designator>l (<arithmetic expression>) \n <factor> : :=<pr*> l<factor>+<primary> <term > : :=<factor> l<term><multiplying operator> <factor> \n<simple arithmetic expression>: := <term> I <adding operator><term>l <simple arithmetic expressiom<adding \noperator > <term> <if clause>: := if <mleem expression> then <arithmetic exp=ssion>: :=<simple arithmetic \nexpression>l<if claus.e><simple a.rithm.etic expression> else <arlthmetlc expression> Modified: <addingoperator>: \n:.+l\u00ad <multiplying operator> ::=xj/1 + <if clause>: := if<%oleem expression>then <arithmetic expression> \n: :=<number>l<vZZle> I <function designator>l (<arithmetic expression>)l <arithmetic expression>+erithmetic \nexpression>/ 1+ I <= ~thmetic expression><multiplying operator> <arithmetic expression>/ l(<multiplying \noperator>,+) -1+1 <a~hmetic expression><adding operator> <arithmetic expression>/ 1 (<adding operator>, \n<multiplying operator>,+)_l(<multiplying operator>,+)l <adding operator><arithmetic expression>/ ~(<addin \ngoperator>~<multiplying Qperator>p+)_ n(<multiplying operator>,+)l <if clause><arithmetic expression>else \n<arithmetic expression>/ 1 (<adding operator>, <multiplying operator>, +) ~(<adding operator>, <multiplying \noperator>, +,=lse) The sequence of transfommetion rules applied are : C3,<term>,<factor> ) (3,<simple \narithmetic expression>,<term>) (3,<arithnetic expression>,<simple arithmetic expression> ) 5.2 Array \nDeclarations Original: <lower bound>: := <arithmetic expression> <upper bound>: := <arithmetic expression> \n<knund pair>: :=<lower Ixmnd>:<upper kxmnd> <bmnd pair list>: := <bwnd pair> I <Lnund pair list>,dxmnd \npair> <array segment>: := <array identifier> [bound pair list>] l<array identifier>, <array segment> \n<array list>: :=<array segnent>l <array list>,erray segment> <array declaration>: := array <array list>l \n<local or own type>array<amay list> Modified: <bound pair list>::= *ithmetic expressio&#38; : %rithmetic \nexpression> I <bound pair list>,dxmnd pair list>/ l<hund pair list>._ <array list> ::=<identifier> [<bound \npair list>]l <identifier> .<arrav list>l <array list>,<amay list>/~<amay list>,_ <array declaration>: \n:= array<array list>l <local or own type>array<mray list> The sequence of transformation rules applied \nare : (l,<bound pair>,<lower hund>) (l,<bound pair>,<upper kound>) (3,@ound pair list>,dmnd pair>) (l,<array \nsepent>,<~ay identifier>) (3,<array list>,<array segyent>) Appendix 2 Parsing Algorithm First, we construct \n10 as follows, (1) If S + a/(u_v) is a production in p, then add [S+.a,O] to 10 if u=l or some negative \nconstraints. (2) Perform predictor and completer operations on 10 until no new items can be added to \n    I 0 ITmconstruct Ij for O~<n as follows, (3) Perform scanner operation on Ii_l. (4) Perform predictor \nand complet~r operations on Ij until no new items can be added to I..  This algorithm is to construct. \nfor o~sn]. A string w = ala2 . . ..a is in L(G) i~ and only if after constructing ?. for O~jjn, there \nexists some items of the form 3[Sti(X). (Y),0] in In, where Y is either an empty string or some negative \nconstraints. The parse forw is S(X). For the productions in P with the constraints simplified, which \nare of the form A+~/((CY.lA~2~... Aak)_(~l A ~2A. .. AF3m))AD, where a, B are strings over V* or negation \nof them, D (3) Completer operation is applicable to an is a l?oolean combination of domination predicates \nof item if the dot is at the end of its production. the form 8(u v) where p~vsV*. There are three Suppose \nthat [B+ y(x). (Y),i] is an itemin I. operations w~ch work on the item in a list I. :1 and B + Y/(P v) \nA D is a production in P.3 Examine the lfit I. for items of the form (1) Predictor operation is applicable \nto an ~tem when there M a nontermmal to the right of the dot. Suppose that [A+ a (X).B6(Y),i] is an itemin \nI., 1 then for all productions in P of the form B + y/(~ V) A D, if the left constraint u is satisfie~such \nthat LEFT(p, [A+a(X).B6(Y),i] ) is TRUE, then we add [%.y,j] to I.. 3 The checking of left constraints \nis a recursive call as Procedure LEFT(H, [A+a(X).B6(Y),i]) Comment: p may be of the form~l A ~P2 A .... \n x. is the forest rewesentation of a. [A+a(x).BB(Y),il) A LEFT(u., [A+a(~).B6(Y).il) else if p=-Ipl \nthenl(LEFT(~ ,[A~~(X).B~(Y),i])j \u00adelse if v c Suffix(PA(X);, where PA(x) is the set o~proper analyses \nof X, then TRUE else if p = on such that ~cPA~ and there =t~an item [E+a ( 6).Af3 (C),k] in Ij, then \nLEFT(a, [E+a ((3) .AS (~),k] ) W=D UI A U2 then EFT(~ ~, else FALSE end (2) Scanner operation is applicable \nto an item when there E a terminal to the right of *he dot. Suppose that [A-m(X).a6(Y),i]is an item in \n1.-1. If a = a. and INIT(a,Y) is TRUE, then we addg [A+aa(X,~). 6(cr),i] to I., where o = DEL(a,Y) is \nthe remainder after dele~ing a from the prefix of Y. The checking of a against the prefix of Y is defined \nas Procedure INIT(a,Y) Corment: Y maybe of the form Yl A lY A . . . beginifY=YAY then INIT(IY.,Y )AIi?IT(a,Y2) \n -if ~=~2Y~~ l(IN~T(a,Yl)) ~se if Y lwhere A is an empty - string, or Y = au for some IJCV$ then TRUE \nelse FALSE end The deleting of a flmm the prefix of Y is defined as procedure DEL(u,Y) Comnent: Ymaybeof \nthe form Y. AIY. A . . . begin if Y . Y-A Y2 then DEL(a,Y~) A DEfi(a, Y2) . else if Y1= lYI then lDEL(a,Yl) \n~se if Y = au for some UEV$: then o Note here thd we mix the interpretation of ! A r ad ~ . Sometimes \nwe want to evaluate the E?ooleem .A and 1 operations to yield a TRUE/I ALSE value, somet~es we use \nT A 1 and r ~ to form the Ebolean combination of strings. But it should be clear to the reader which \nway we use them. [A+ a(cr).Bf3(t),k]+ For each one found, if DOM(D, [E+y(X) .(Y),i])IIFT(M, [A+a(o).B6(c),k]) \nand MATCH(X,C) are all TRUE, then we add [A +uB(o,B(x)).~(v A Y A ~),k] toIj, where &#38;PADEL(x,E). \nThe checking of parsed pwtion x against the unmatched constraints Y is defined as Procedure MATCH(X,Y) \nComment: Y may be of the form Y, A.-IYO A . . . x is a forest representation. lx!gin if Y YI A Y2 then \nMATCH(X, Yl) A MATCH (x, Y.) e~se if Y ~Ylthen l(MATCH(X, Y )) els~if Y c Pr~(PA(x)) then T~UE ~se if \nY cr~ and OEPA(X) then TRUE ~se FALSE end The deleting of strings in the set of proper analysis of x \nfrom the prefix of Y is defined as Procedure PADEL(x,Y) Conunent: Y may beofthe fo?mY A 1Y2 A . . x is \na forest represen + ation. begin if Y Y1 ,A Y2 then PADEL(x, Yl)A PADEL(x, Y2) else if Y =-IY then 7 \nPADEL(x, Yl) e~e if Y ~ Prefix(PA(X)) then 1 . else if Y UrI and os PA(x) therm end The procedure DOM(D, \n[B+y(X). (Y),i]) for checking the domination predicates is omitted here because it is quite straightforward. \nExarrde A.1 G:E+E+E/(1+ )A(l$: _)A(-1 +) E+E *E/(l->+ ) E+a After constraints simplification, the w~ \nbecomes For an input string w a + a 5 a, the parse lists are generated as [E+.E+E, O] 10: [E+ .E tE, \nO] [E+ .a, O] 11: [E+ a(a)., O] [E+ E(E(a)).+E, 01 [E +E(E(a)).$ E, O] 12: [E +E+(E(a),+).E, O] Since \nthe time used to check the constraints X[E+.E+E,2] is constant, this algorithm will have the same [E+ \n.EJ~E, 2] time bmnd as Earleyls algo~ithm, that is, it [E+ .a, 2] takes at most n3 tim~ fop any context-free \ngrarmar and will reduce to n for unambiguous grammars. The item [E + .E + E, 2] is deleted because Note \nthat all ALGOL 60 syntax and gramnars the left constraint is not satisfied in the modified by the set \nof transformation rules p~edictor operation. satisfy the simple form of constraints, [E =-a(a)., 2]13: \n[E + E + E (E(a),+,E(a)). ,0] [E + E(E(a)).~ E, 2] [E + E(E(E(a),+,E(a))).+ E ( 1 ~ ), O] [E + E(E(E(a),+,E(a))) \n.: E (1 :), O] [E + E (E(a), ).E, 2] 14: X[E+ .E +E, 4] X[E+ .E ~: E, 4] [E+ .a, 4] The last item \nin I does not satisfy the constraint in the scann $r operation, so it is not carried on to I . Also, \nthe middle two items in 14 are deleted Because they do not satisfy the left constraint in the predictor \noperation. [E+ a(a), 4]15: [E+E t E (E(a),~ ,E(a)), 2] [E+E +E (E(a),+,E(E(a), :,E(a))), O] [E +E(E(E(a),$ \n,E(a))).$ E, 2] [E +E(E(E(a),+,E(E(a) ,*,E(a)))).+ E (l f ),O] [E +E(E(E(a),+,E(E(a),: ,E(a))) ).; :E \n(1$ ),0]  The string w a + a : a is accepted because the item [E +E + E(E(a),+,E(E(a),$:,E(a))). ,0] \nis in I . The parse tree for a + a $~5a is E(E(a),+,E(E(a),$:,E(a)) ). However, it is not practical to \nhave the parsing algorithm to check the most general form of local constraints. If we restrict the local \nconstraints to be of the form such that either they consist of terminal symbols only or it is sufficient \nto check the constraints at the same level where the production is used, then we do not need to carry \nthe unmatched constraints and the checking of constraints is quite easy to perform with Earley s algorithm. \nThe dotted rule is of the form [A+a.fi,il, which has the same meaning as Earley s algoritlmn. The three \noperations which work on the items in a list Ii are (1) Predictor operation: Suppose that [A%.BB,i] is \nan item in I-, then for all productions of the form Wy?U v, if Me Suffix (ctvaa . . ..a.) and vc Pref&#38;~6), \nthen we add [% .Y~j~ to I;. 3 (2) Scanner operation: Suppose that [A%.a ~,i] is an item in I. [A+aa.6,i] \nto 1~~1 ~f a aj hen e add  (3) Completer operation: Suppose that [*y.,i] is ~ ita ~ I. and 9y/D_v \nis a pzmduction in  P. Examine the]list Ii for ~tems of the form  [A%.Bf3,k]. For each one found, \nif PC Suffix ..a.) and VE prefiX(13 V a. an,, ~+laj+2 \u00ad a v ala~ thenwe a d [A+&#38;B.6,k] to I.. 3 \n \n\t\t\t", "proc_id": "512760", "abstract": "The method of local constraints attempts to describe context-free languages in an apparently context-sensitive form which helps to retain the intuitive insights about the grammatical structure. This form of description, while apparently context-sensitive is, in fact, context-free and allows a program derivation structure to be represented as a tree with additional constraints, thus allowing for the possibility of a correctness proof in the form of Knuthian semantics. A part of ALGOL 60 syntax has been restated as a grammar with local constraints. It is also shown that parsing of grammars with local constraints can be carried out by a suitable extension of Early's algorithm. Finally, the relationship of local constraints to the semantics of programs is discussed in Section 4 by considering some program transformations.", "authors": [{"name": "Aravind K. Joshi", "author_profile_id": "81100643205", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "PP14220565", "email_address": "", "orcid_id": ""}, {"name": "Leon S. Levy", "author_profile_id": "81100154637", "affiliation": "University of Pennsylvania, Philadelphia, PA and University of Delaware, Newark, Delaware", "person_id": "PP14063847", "email_address": "", "orcid_id": ""}, {"name": "Kang Yueh", "author_profile_id": "81100238014", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "PP39033948", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512760.512787", "year": "1978", "article_id": "512787", "conference": "POPL", "title": "Local constraints in the syntax and semantics of programming languages", "url": "http://dl.acm.org/citation.cfm?id=512787"}