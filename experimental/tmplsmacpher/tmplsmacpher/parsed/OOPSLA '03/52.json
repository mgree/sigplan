{"article_publication_date": "10-26-2003", "fulltext": "\n Acceptability-Oriented Computing Martin Rinard MIT Laboratory for Computer Science Cambridge, MA 021139 \n ABSTRACT We discuss a new approach to the construction of software systems. Instead of attempting to \nbuild a system that is as free of errors as possible, the designer instead identi.es key properties that \nthe execution must satisfy to be accept\u00adable to its users. Together, these properties de.ne the ac\u00adceptability \nenvelope of the system: the region that it must stay within to remain acceptable. The developer then \naug\u00adments the system with a layered set of components, each of which enforces one of the acceptability \nproperties. The potential advantages of this approach include more .exible, resilient systems that recover \nfrom errors and behave accept\u00adably across a wide range of operating environments, an ap\u00adpropriately prioritized \ninvestment of engineering resources, and the ability to productively incorporate unreliable com\u00adponents \ninto the .nal software system.  Categories and Subject Descriptors D.2.1 [Software Engineering]: Requirements/Speci.cations; \nD.2.3 [Software Engineering]: Coding Tools and Tech\u00adniques; D.2.3 [Software Engineering]: Software/Program \nVeri.\u00adcation;  D.2.3 [Software Engineering]: Testing and Debugging; D.3.3 [Programming Languages]: Language \nConstructs and Features  General Terms Design, Languages, Reliability, Security  Keywords Acceptability \nProperties, Repair, Monitoring, Recti.cation * This research was supported in part by DARPA Con\u00adtract \nF33615-00-C-1692, NSF Grant CCR00-86154, and NSF Grant CCR00-63513, NSF Grant CCR02-09075, an IBM Eclipse \nAward, and the MIT-Singapore Alliance. Copyright is held by the author/owner. OOPSLA 03, October 26 30, \n2003, Anaheim, California, USA. ACM 1-58113-751-6/03/0010. 1. INTRODUCTION Software developers face \nincreasing demands to improve both the functionality and the reliability of the software that they produce. \nThis combination is challenging because of the inherent tension between these two properties: increas\u00ading \nthe functionality increases the complexity, which in turn increases the di.culty of ensuring that the \nsoftware executes reliably without errors. We believe that current software engineering practices may \nbe approaching the limit of the combination of func\u00adtionality and reliability that they can deliver. \nThis is of some concern because of the compelling need for improve\u00admentsinbothof these twoproperties: \nFunctionality: Functionality pressure has tradition\u00adally come from the dynamics of the desktop software \nmarket. In this context, increased functionality has been seen as a way to obtain a marketing advantage \nover competitors, to motivate customers to purchase upgrades, and to satisfy customer demands for more \nuseful or usable computer software. In the future, several trends will increase the pres\u00adsure for additional \nsoftware functionality (and there\u00adfore additional software complexity). First, increasing interconnectivity \nplaces demands on the software to interoperate with a wider range of systems and data sources. Each new \nsystem and data source typically requires the development of new functionality to sup\u00adport the interoperation. \nSecond, embedded systems are the next large software growth area. As the scope and sophistication of \nthe phenomena that these systems monitor and control in\u00adcreases, so must the functionality and complexity \nof the software. Reliability: Because many embedded systems control physical phenomena, failures can \nhave immediate and disastrous consequences that threaten human safety. Reliability has therefore always \nbeen a primary con\u00adcern for embedded systems; its importance will only increase as embedded systems continue \nto expand the scope of the phenomena that they monitor and control. Reliability has also been a central \nconcern for tra\u00additional corporate information management systems: down time translates directly into \nimpaired operations, lost pro.ts, and frustrated customers may look to com\u00adpetitors to satisfy their \nneeds. The increased depen\u00addence on highly interconnected information systems only magni.es the importance \nof reliability. As inter\u00adconnectivity increases, more of the business becomes unable to function in the \nabsence of a working system, and the system as a whole becomes increasingly vul\u00adnerable to cascading \nfailures triggered by the failure of a single component. Both of these phenomena in\u00adcrease the consequences \nof failures, in some cases dra\u00admatically. Finally, after many years in which features were the primary \nconcern, consumers of desktop productivity software are tiring of dealing with software that fails. Reliability \nis therefore becoming an important issue for this kind of software, even though the consequences of failure \nare usually small in comparison with em\u00adbedded systems or corporate information management systems. The \nstandard approach for achieving reliability has been simplicity, or to state it more pejoratively, lack \nof ambition: keep the program simple enough so that it can be made to work with standard techniques. \nAs legitimate function\u00adality demands increase, this approach will become increas\u00adingly infeasible. The \nmore ambitious alternative, namely the deployment of increasingly less reliable systems, seems unattractive \nand potentially disastrous. And the fact that these issues play out against a backdrop of ruthless com\u00adpetition, \never-increasing time and market pressures, accel\u00aderated development schedules, and continuously changing \nrequirements and computing environments only exacerbates the need for better solutions. If we step back \nand examine the situation, it becomes clear that there is almost never just a single acceptable execution \nthat the program must deliver. Instead, there is usually a range of acceptable executions, with some \nexecutions more acceptable than others. This fact suggests the concept of an acceptability envelope: \na region of the execution that the program must stay within to remain acceptable. This con\u00adcept, in turn, \nsuggests the following development approach: instead of trying to develop a perfect program, instead \nde\u00advelop a program that may contain errors, but that always stays within its acceptability envelope in \nspite of those er\u00adrors. Several activities characterize this approach: Acceptability Property Identi.cation: \nThe de\u00adsigner identi.es properties that the state and behavior must preserve for the program s execution \nto be ac\u00adceptable. The result is a set of (potentially) partially redundant and prioritized acceptability \nproperties.Un\u00adlike traditional speci.cations, which completely char\u00adacterize the desired behavior, acceptability \nproperties are partial: they identify minimum acceptability re\u00adquirements for speci.c aspects of the \nexecution.  Monitoring: The developer produces components that monitor relevant aspects of the program \ns execution to detect impending acceptability violations.  Enforcement: Once the component detects an \nim\u00adpending acceptability violation, it takes actions de\u00adsigned to bring the program s execution back \nwithin its acceptability envelope.  Logging: The component logs important events such as the detection \nof impending acceptability violations and the actions that the system takes to avert such violations. \n 1.1 Perspective Change Acceptability-oriented computing promotes a perspective change on the part of \nthe developers and users of software. In particular, the following notions are implicit but central to \nthis approach: The Goal of Perfection is Counterproductive: The aspiration to eliminate as many programming \ner\u00adrors as possible creates a development process that dif\u00adfuses the focus of the project, wastes engineering \nre\u00adsources, and produces brittle software that is helpless in the presence of the inevitable errors or \nfaults. A more productive aspiration is to develop systems that contain errors and sometimes behave imperfectly, \nbut remain within their acceptable operating envelope. Flawed Software Has Enormous Value: The most productive \npath to better software systems will involve the combination of partially faulty software with tech\u00adniques \nthat monitor the execution and, when neces\u00adsary, respond to faults or errors by taking action to appropriately \nadjust the state or behavior. If successful, this approach will enable the construction of computer systems \nthat can sustain (potentially self-in.icted) damage, process unexpected or illegal inputs, and take in\u00adcorrect \nactions, yet nevertheless continue to execute produc\u00adtively. 1.2 Architecture Acceptability-oriented \nsystems have an architecture that di.ers substantially from that of traditional systems. Specif\u00adically, \nacceptability-oriented systems contain multiple par\u00adtial, redundant, and layered components that enforce \nac\u00adceptable system behavior and structure properties. Outer layers take priority over inner layers, with \nthe layers be\u00adcoming progressively simpler, more partial, and more likely to accurately capture the intended \nproperty as they move towards the periphery of the layered structure. The core innermost layer will typically \nconsist of the source code of the system, usually written in a standard program\u00adming language. Conceptually, \nthe core is intended to com\u00adpletely specify both the behavior of the system and the structure required \nto completely implement this behavior. The possibility of errors within the core or unanticipated actions \non the part of the environment in which the compu\u00adtation exists is the only reason that the core does \nnot, by itself, comprise a completely acceptable system. The outer layers identify increasingly minimal \nrequire\u00adments for acceptable system behavior and structure. Con\u00adceptually, the information in these layers \nmay be redundant with the information in the innermost layer. The partial nature of these outer layers \nmeans that many of the lay\u00aders address orthogonal aspects of the system and are there\u00adfore largely independent. \nOthers provide information that is partially or completely redundant with other layers. The outermost \nlayers focus on only those most basic properties required for minimal system acceptability while layers \ncloser to the core focus on more elaborate properties that, when satis.ed, enhance the value of the program. \nThe outer layers of the program monitor the execution of the program to identify impending violations \nof the de\u00adsired acceptability properties. Potential responses to such violations include repair actions \nthat are designed to de\u00adliver an acceptable state for continued execution, exit ac\u00adtions that are designed \nto safely shut down the system and await external intervention, and logging actions that record the impending \nacceptability violations and the resulting ac\u00adceptability enforcement actions. The monitoring, repair, \nand safe exit algorithms will vary depending on the kinds of requirements they are designed to enforce. \nIn many cases, it may be productive to express some of the layers using a variety of high-level speci.cation \nlan\u00adguages. Tools will translate the resulting speci.cations into code that implements the monitoring, \nlogging, repair, and safe exit actions. In other cases, it may be more productive to code the acceptability \nenforcement operations directly in standard programming languages. 1.3 Acceptability Enforcement Approaches \nWe identify two approaches that a system can use to re\u00adspond to impending acceptability violations and \nenforce its acceptability envelope: Resilient Computing Approaches: A resilient com\u00adputing approach \nresponds to impending acceptability violations by taking actions that are designed to bring the system \nback into an acceptable state from which it can continue to execute inde.nitely.  Safe Exit Approaches: \nA safe exit approach re\u00adsponds to impending acceptability violations by ex\u00adecuting a safe exit strategy: \na sequence of actions de\u00adsigned to extricate the system safely from the problem\u00adatic situation in which \nit .nds itself. This sequence is designed to leave the system and any parts of the phys\u00adical world with \nwhich it interacts in a stable state,or a state in which it is acceptable for the system to take no action \nat all until it is repaired by some external intervention.  We expect safe exit approaches to be used \nprimarily when waiting for external intervention to repair the system is a reasonable response to failures \nor the perceived negative consequences of continuing to execute a potentially incom\u00adpletely repaired \nsystem outweigh the bene.ts. Many exist\u00ading systems already contain a very conservative, limited ver\u00adsion \nof a safe-exit strategy: standard error checking mecha\u00adnisms (such as assertions) can be viewed as enforcing \nvery basic acceptability properties (the locally checkable condi\u00adtions that appear in the assertions) \nwith a simple safe exit strategy (halt the computation at the .rst sign of an accept\u00adability violation). \nWe expect that most such systems would bene.t from a more comprehensive and purposeful applica\u00adtion of \nacceptability-oriented computing, in particular, an increased awareness and understanding of explicit \naccept\u00adability properties, a more organized approach to detecting impending acceptability violations, \nand a larger e.ort de\u00advoted to identifying more appropriate safe exit strategies. We expect resilient \ncomputing approaches to be most ap\u00adpropriate in several situations: when the repair is expected to deliver \na completely acceptable system, when the e.ect of the repaired damage will be .ushed out of the system \nwithin an acceptable amount of time provided that it contin\u00adues to execute, when external intervention \nis not practical, or when there is a strong incentive for continued execution over outright system failure, \neven if the continued execu\u00adtion may be somewhat compromised. In many embedded systems that control unstable \nphysical phenomena, for ex\u00adample, compromised execution is far preferable to outright failure. Resilient \ncomputing may be especially useful for systems that are composed of several largely independent components \nthat share a fate repairing one component may enable the other components to continue with their normal \nexecution, while allowing the component to fail may disable the remaining components. It may also be \nuseful when the software is known to execute incorrectly in certain situations, but the developers are \nunwilling to risk the sys\u00adtem disruption or damage that might result from changing the code, preferring \ninstead to repair any damage after it occurs. We note that it is possible to apply resilient computing \nand safe exit responses in the same system, with some unac\u00adceptabilities repaired via the resilient computing \ntechniques and others triggering a safe exit strategy. 1.4 Acceptability Enforcement Mechanisms It is \npossible to apply acceptability-oriented computing to all aspects of a system s structure and behavior. \nWe have explored mechanisms that interpose acceptability .lters on input and output streams, that dynamically \ntraverse data structures to .nd and repair violations of key data structure consistency properties, and \nthat enforce properties that re\u00adlate the content of the data structures to the input and out\u00adput values. \nOther likely candidates include enforcing pro\u00adcess structure properties (such as the presence of processes \nthat implement a crucial part of the system s functionality), system con.guration properties (these constrain \nthe values of various system con.guration setting), and library usage properties (that involve the order \nin which clients may in\u00advoke library operations and the values that they may pass to the library). We \ndistinguish several distinct classes of mechanisms that can be used to apply acceptability-oriented computing: \n Black-Box Mechanisms: A black-box mechanism treats the core as a unit. It does not modify the core at \nall and a.ects it only through well-de.ned aspects of its interface such as its input and output streams. \n Gray-Box Mechanisms: A gray-box mechanism does not modify the code of the core, but may use more in\u00advasive \ntechniques (such as procedure call interception and data structure modi.cation) that a.ect conceptu\u00adally \ninternal aspects of the core.  White-Box Mechanisms: Awhite-box mechanism augments the core directly \nwith new acceptability en\u00adforcement code.  The basic trade-o. is that less invasive techniques require \nless knowledge of the core system and are less likely to in\u00adtroduce new errors, but typically require \nmore involved im\u00adplementation mechanisms and may be limited in the amount of control they can exert over \nthe core. More invasive tech\u00adniques o.er more control and typically use simpler imple\u00admentation mechanisms, \nbut require the developer to operate within a more complex implementation environment and of\u00adfer greater \nopportunities for collateral damage in the form of inadvertently introduced errors. 1.5 Structure of \nthe Paper The remainder of the paper is structured as follows. In Section 2 we use a running example \nto present several di.er\u00adent resilient computing techniques. We discuss issues associ\u00adated with these \ntechniques as they arise. In Section 3 we dis\u00adcuss several other techniques that we expect acceptability\u00adoriented \ndevelopers to use. In Section 4 we discuss several broader technical and social issues associated with \nthe po\u00adtential use of acceptability-oriented computing. In Section 5 we present several more aggressive \nextensions that may in\u00adterfere more deeply with the core system in an attempt to generate more reliable \nexecution. We discuss related work in Section 6, unrelated work in the area of reliability in Sec\u00adtion \n7, and conclude in Section 8.  2. EXAMPLE We next present a simple example that illustrates how to \napply the basic concepts of acceptability-oriented com\u00adputing. The core component in our example implements \na simple map from names to numbers. We assume that this component will be used to translate names to \nnumeri\u00adcal identi.ers, as in, for example, a name server that maps a bank of printer names to printer \nnetwork addresses. Like many Unix components, the core component in our example accepts its inputs as \na sequence of commands on the standard input stream (stdin) and writes its outputs to the standard output \nstream (stdout). It accepts three commands: put name num, which creates a mapping from name to num; get \nname, which retrieves the num that name maps to; and rem name, which removes the mapping asso\u00adciated \nwith name. In response to each command, it writes the appropriate num onto the standard output: for put \ncom\u00admands it writes out the number from the new mapping, for get commands it writes out the retrieved \nnumber, and for rem commands it writes out the number from the removed mapping. Figure 1 presents the \ncode for the main procedure, which parses the input stream of commands, invokes the appro\u00adpriate procedure \n(put for put commands, get for get com\u00admands, and rem for rem commands), then writes the re\u00adturn value \nof the procedure to the output stream. Figure 2 presents the code for these procedures. We have omitted \nthe de.nitions of several constants (LEN, N,and M) and auxiliary procedures. The complete code for all \nof the examples in this paper is available at www.cag.lcs.mit.edu/~rinard/paper/oopsla03/code. The core \nmaintains a hash table that stores the mappings. Each bin in the table contains a list of entries; each \nentry contains a mapping from one name to one num.The bin procedure uses a hash code for the name (computed \nby the hash function) to associate names to bins. The procedures alloc and free manage the pool of entries \nin the table, while the find procedure .nds the entry in the table that holds the mapping for a given \nname. 2.1 Acceptability Properties We identify several acceptability properties that the core should \nsatisfy: Continued Execution: Our .rst acceptability prop\u00aderty is that the core continues to execute \nso that as many of its mappings as possible remain accessible to its client. The rationale for this property \nmight be, int main(int argc, char *argv[]) { char cmd[LEN], name[LEN]; int val; initialize(); while (scanf(\"%s\", \ncmd) != EOF) { val=0; if (strcmp(cmd, \"put\") == 0) { if (scanf(\"%s %d\", name, &#38;val) == 2) { put(name, \nval); } } else if (strcmp(cmd, \"get\") == 0) { if (scanf(\"%s\", name) == 1) { val = get(name); } } else \nif (strcmp(cmd, \"rem\") == 0) { if (scanf(\"%s\", name) == 1) { val = rem(name); } } printf(\"%d\\n\", val); \nfflush(stdout); } } Figure 1: Implementation of main Procedure of Core for example, that the client \n(and potentially the rest of the system) will hang unless it receives a response for each request. Our \nacceptability enforcement tech\u00adniques must therefore protect the core against prob\u00adlematic inputs and \ninternal data structure inconsisten\u00adcies that could cause it to fail. Output Sanity: Ideally, the core \nwould always return the correct number for each get command. We may, however, be willing to relax this \nconstraint to allow it to return 0 (indicating no mapping) even if a past put command established a mapping. \nWe may also be will\u00ading to accept (or even require) the core to return any number within the minimum \nand maximum numbers to which mappings have been established. The ratio\u00adnale for these properties might \nbe, for example, that the bank of printers has been allocated a contiguous range of addresses, and while \nit might be acceptable to deliver a job to any printer within the range, it might not be acceptable to \nroute the job to some other arbi\u00adtrary printer. Note that both of these acceptability properties fall \nwell short of requiring the core to execute correctly. They also depend, to some extent, on the needs \nof the client in the context of the larger system. In general, we expect the ac\u00adceptability properties \nfor the di.erent components to vary depending on the context in which they are deployed. Fi\u00adnally, we \nnote that the client can reasonably hope for more than just acceptability property satisfaction instead \nof returning 0 for every get query, it is reasonable to expect the core to return the correct value much \nof the time. 2.2 Data Structure Repair The alloc procedure in Figure 2 assumes that there is always \na free entry to return to the caller; the put procedure assumes that it always gets a valid entry back \nfrom the alloc procedure. If these assumptions are violated (presumably because the client has attempted \nto put too many mappings into the table), there is a memory corruption error and the core may fail. The \nstandard way to .x this problem is to struct { int _value; int _next; char _name[LEN]; } entries[N]; \n#define next(e) entries[e]._next #define name(e) entries[e]._name #define value(e) entries[e]._value \n#define NOENTRY 0x00ffffff #define NOVALUE 0 int end(int e) { return (e == NOENTRY); } int table[M], \nfreelist; int alloc() { int e = freelist; freelist = value(e); return e; } void free(e) { value(e) = \nfreelist; freelist = e; } int hash(char name[]) { int i, h; for (i = 0, h = 0; name[i] != \\0 ; i++) { \nh*=997;h+=name[i]; h= h%4231; } return h; } int bin(char name[]) { return hash(name) % M; } int find(char \nname[]) { int b = bin(name), e = table[b]; while (!end(e) &#38;&#38; strcmp(name, name(e)) != 0) e = \nnext(e); return e; } int rem(char name[]) { int e = find(name); if (!end(e)) { int val = value(e), b \n= bin(name); table[b] = next(e); name(e)[0] = \\0 ; free(e); return val; } else return NOVALUE; } int \nput(char name[], int val) { int e = alloc(); value(e) = val; strcpy(name(e), name); int p = find(name); \nif (!end(p)) free(p); int b = bin(name); next(e) = table[b]; table[b] = e; return val; } int get(char \nname[]) { int e = find(name); if (end(e)) return NOVALUE; else return value(e); } Figure 2: Implementation \nof Map Core Procedures modify the core software to recognize when it is out of entries and augment it \nwith code to handle this case. This approach, of course, requires the developer to oper\u00adate directly \nwithin the core software. Two potential pitfalls include the need for the developer to understand the \ncore software and collateral damage in the form of introduced errors. Moreover, the standard approach \nto running out of memory is to have the allocation routine return a value in\u00addicating that the allocation \nfailed, leaving the application to deal with the problem. The application usually has no idea how to \nrecover and exits (if it checks the return code at all). The alternative, distributing infrequently executed \nrecovery code throughout the application, may be unattractive not only because of the increased complexity \nand damage to the structure of the code but also because of the di.culty of delivering recovery code \nthat executes acceptably. Modi.cation also requires access to compilable source code, which may be problematic \neither because the core was de\u00adlivered in executable form only, because the original source code has \nbeen lost, because legal considerations preclude modi.cation, because recerti.cation costs make modi.ca\u00adtions \nimpractical, because another organization maintains the code and any local modi.cations will be wiped \nout in future releases, or because the core is coded in an archaic language for which a compiler is no \nlonger available. An alternate view is that the core is failing because its data structures do not satisfy \nthe data structure consistency property that the freelist must point to a valid entry when the alloc \nprocedure executes, and the way to eliminate the failure is to enhance the core with a component that \ndetects, then repairs, any data structure consistency violations. Further investigation reveals another \nconsistency prob\u00adlem. The following input causes the core to in.nite loop while processing the get g \ncommand: put a1 put c2 put a3 put e4 get g The cause of the in.nite loop is a circularity in one of the \nlists of entries. This circularity violates the data structure consistency property that there is exactly \none reference to each element of the entries array (these references are im\u00adplemented as indices stored \nin the freelist, table array, and next and value .elds of the entries). It may be worth\u00adwhile to ensure \nthat this property holds as well. Figure 3 presents a procedure, repair, that detects and repairs any \ndata structure consistency violations in our ex\u00adample program from Figure 2. The repair procedure .rst \ninvokes repairValid to replace all invalid references with NOENTRY. The procedure then invokes repairTable,which \nensures that all entries in lists in the table have at most one incoming reference from either an element \nof the table array or the next .eld of some entry reachable from the table array. This property ensures \nthat each element of table refers to a distinct NOENTRY-terminated list and that di.erent lists contain \ndisjoint sets of entries. Finally, repair invokes repairFree to collect all of the entries with reference \ncount 0 (and that are therefore not in the table) into the free list. If the free list remains empty \n(because all entries are already in the table), the procedure chooseFree chooses an arbitrary entry and \ninserts it into the free list, ensuring that int valid(int e) { return (e >= 0) &#38;&#38; (e < N); } \nvoid repairValid() { int i; if (!valid(freelist)) freelist = NOENTRY; for (i =0; i <M; i++) if (!valid(table[i])) \ntable[i] = NOENTRY; for (i =0; i <N; i++) if (!valid(next(i))) next(i) = NOENTRY; } static int refs[N]; \nvoid repairTable() { static int last = 0; int i, e, n, p; for (i =0; i <N; i++) refs[i] = 0; for (i =0; \ni <M; i++) { p = table[i]; if (end(p)) continue; if (refs[p] == 1) { fprintf(stderr, \"t[%d] null (%d)\\n\", \ni, p); table[i] = NOENTRY; continue; } refs[p] = 1; n = next(p); while (!end(n)) { if (refs[n] == 1) \n{ fprintf(stderr, \"n(%d) null (%d)\\n\", p, n); next(p) = NOENTRY; break; } refs[n] = 1; p = n; n = next(n); \n} } } void chooseFree() { static int last = 0; int i, n, p; fprintf(stderr, \"freelist = %d\\n\", last); \nn = last; last = (last + 1) % N; name(n)[0] = \\0 ; value(n) = NOENTRY; freelist = n; for (i =0; i <M; \ni++) { p = table[i]; if (end(p)) continue; if (p == freelist) { fprintf(stderr, \"t[%d]=%d (%d)\\n\", i, \nnext(p), p); table[i] = next(p); return; } n = next(p); while (!end(n)) { if (n == freelist) { fprintf(stderr, \n\"n(%d)=%d (%d)\\n\", p, next(n), n); next(p) = next(n); return; } p= n;n= next(n); } } } void repairFree() \n{ int i, f = NOENTRY; for (i =0; i <N; i++) if (refs[i] == 0) { next(i) = value(i); value(i) = f; f = \ni; } if (end(f)) chooseFree(); else freelist = f; } void repair() { repairValid(); repairTable(); repairFree(); \n} Figure 3: Data Structure Repair Implementation freelist refers to a valid entry. It then removes this \nentry from the table. The repair algorithm maintains a reference count ref[e] for each entry e and uses \nthis count to guide its repair ac\u00adtions. It also logs each repair action to stderr.The result\u00ading log \nmay make it easier to become aware of and investi\u00adgate any errors in the core and to understand the behavior \nof the repaired system should it become desirable to do so. The repair algorithm has several properties: \n Heuristic Structure Preservation: When possi\u00adble, the algorithm attempts to preserve the structure it \nis given. In particular, it has no e.ect on a con\u00adsistent data structure and attempts to preserve, when \npossible, the starting linking structure of inconsistent data structures. The repaired data structure \nis there\u00adfore heuristically close to the original inconsistent data structure.  Continued Execution: \nWhen the free list is empty, the repair algorithm removes an arbitrary entry from the table and puts \nthat entry into the free list. This action removes the entry s mapping; the overall e.ect is to eject \nexisting mappings to make way for new map\u00adpings. In this case the repair algorithm converts failure into \nsomewhat compromised but ongoing execution. Because the repair algorithm also eliminates any cy\u00adcles \nin the table data structure, it may also eliminate in.nite loops in the find procedure.  This example \nillustrates several issues one must consider when building components that detect impending accept\u00adability \nviolations and enforce acceptability properties: Acceptability Property: The developer must .rst determine \nthe acceptability property that the compo\u00adnent should enforce. In our example, the acceptability property \ncaptures aspects of the internal data struc\u00adtures that are directly related to the ability of the core \nto continue to execute. Note that the acceptability property in our example is partial in that it does \nnot completely characterize data structure consistency in particular, it does not attempt to enforce \nany re\u00adlationship between the values in the entries and the structure of the lists in the table data \nstructure. In a fully correct implementation, of course, the hash code of each active entry s name would \ndetermine the list in which it is a member.  Monitoring: The monitoring component in our ex\u00adample simply \naccesses the data structures directly in the address space of the core to .nd acceptability vio\u00adlations. \nIn general, we expect the speci.c monitoring mechanism to depend on the acceptability property and on \nthe facilities of the underlying system. We an\u00adticipate the use of a variety of mechanisms that allow \nthe monitor to access the address space of the core pro\u00adcesses (examples include the Unix mmap and ptrace \nin\u00adterfaces), to trace the actions that the program takes, or to monitor its inputs, outputs, procedure \ncalls, and system calls.  Enforcement: A white-box application of data struc\u00adture repair would insert \ncalls to the repair procedure at critical places in the core program, for example just  before the put, \nget,and rem procedures in our ex\u00adample. It is also possible to wait for the core to fail, catch the resulting \nexception, apply data structure re\u00adpair in the exception handler, then restart the appli\u00adcation from \nan appropriate place. A gray-box implementation might use the Unix ptrace interface (see Section 2.5) \nor mmap to get access to the address space(s) of the core process(es). All of these mechanisms update \nthe data structures directly in the address space of the core, heuristically attempting to preserve the \ninformation present in the original incon\u00adsistent data structure. In general, we expect that enforcement \nstrategies will attempt to perturb the state and behavior as little as possible. We anticipate the use \nof a variety of mecha\u00adnisms that update the internal state of the core, cancel impending core actions \nor generate incorrectly omitted actions, or change the inputs or outputs of the core, components within \nthe core, or the underlying system. Logging Mechanism: Our example simply prints out to stderr a trace \nof the instructions that it exe\u00adcutes to eliminate inconsistencies. In general, we antic\u00adipate that the \nlogging mechanism will vary depending on the needs of the application and that some devel\u00adopers may .nd \nit desirable to provide more organized logging support. Note also that logging is useful pri\u00admarily for \nhelping to provide insight into the behavior of the system. The log may therefore be super.uous in situations \nwhere it is undesirable to obtain this insight or it is impractical to investigate the behavior of the \nsystem. We note one other aspect that this example illustrates. The problem in our example arose because \nthe core (like many other software systems) handled a resource limitation poorly. Data structure repair \nenables continued execution with compromised functionality. But because no system can support unlimited \nresource allocation, even the best possi\u00adble implementation must compromise at some point on the functionality \nthat it o.ers to its clients if it is to continue executing. Finally, there is another way to prevent \nput from failing because the free list is empty change the implementation so that it checks if the free \nlist is empty and, if so, skips the call to put. This mechanism is an instance of condi\u00adtional code excision \nas discussed below in Section 5.4. Al\u00adthough this technique does not protect the core against the full \nrange of potential data structure corruption problems, it does avoid a speci.c execution that is known \nto cause corruption. 2.3 Input Monitoring and Recti.cation Our example program uses .xed-size character \narrays to hold the name in each entry, but does not check for input names that are too large to .t in \nthese arrays. It may there\u00adfore fail when presented with input names that exceed the array size. A standard \nway to .x this problem is to modify the core so that it either checks for and rejects excessively long \nnames or uses dynamic memory allocation to correctly handle names of arbitrary length. An acceptability-oriented \napproach might instead inter\u00adpose a .lter on the input. This .lter would monitor the in\u00adput stream to \ndetect and eliminate inputs that would cause int main(int argc, char *argv[]) { int count = 0, c = getchar(); \nwhile (c != EOF) { if (isspace(c)) count = -1; if (count < LEN-1) { putchar(c); count++; } else fprintf(stderr, \n\"character %c discarded\\n\", (char) c); if (c == \\n ) fflush(stdout); c = getchar(); } } Figure 4: Token \nLength Filter Implementation array over.ow. Figure 4 presents the code for just such a .lter. The .lter \ntruncates any token (where a token is a contiguous sequence of non-space characters) too long to .t in \nthe name arrays from Figure 2. Using the Unix pipe mechanism to pass the input through this .lter prior \nto its presentation to the core ensures that no token long enough to over.ow these arrays makes it through \nto the core. There are several issues that arise when building these kinds of input .lters: Acceptability \nProperty: The developer must .rst determine the acceptability property that the .lter should enforce. \nIn our example, the property is sim\u00adple: no token longer than LEN characters. For systems with real-time \nconstraints, one twist is that the prop\u00aderty may involve timing characteristics such as the fre\u00adquency \nat which the inputs arrive. Note that the acceptability property in our example is partial in that it \ndoes not completely characterize the legal inputs. It instead captures a simple property that every input \nmust satisfy to be acceptable. This simplicity enables the .lter to avoid the complexity of performing \na complete legality check on the input. The result is a simpler .lter that requires less development \ne.ort and is less likely to have acceptability problems of its own.  Interposition: The input .lter \nmust use some mech\u00adanism that allows it to observe and potentially process the input before passing it \nalong to the core. In our example we use the standard Unix pipe mechanism to pass the input through the \n.lter before it reaches the core. This black-box approach requires no modi.ca\u00adtions to the core at all. \n If the core uses procedure calls to obtain its input, a gray-box interposition mechanism may redirect \nthe calls to invoke the .lter s procedures, which then ob\u00adtain and process the input before returning \nit back to the core. Ways to implement this redirection in\u00adclude providing a new implementation of the \ninvoked procedure, using binary rewriting techniques [16] to change the invoked procedure, using operating \nsystems mechanisms to redirect an invoked system call [2], or using aspect-oriented programming mechanisms \nto in\u00adtercept method calls [15]. If the core uses memory\u00admapped I/O, it may be possible to use memory \npro\u00adtection mechanisms to have the attempted I/O oper\u00adations generate a memory protection fault. The \npro\u00advided fault handler would then implement the inter\u00adposition. Other mechanisms may be appropriate \nfor other input strategies. Monitoring: The monitor processes the input to de\u00adtect inputs that do not \nsatisfy the acceptability prop\u00aderty. In our example, the monitor keeps a running count of the number \nof contiguous non-space charac\u00adters. When it encounters a character that would cause this count to exceed \nLEN, it has detected an impend\u00ading violation of the acceptability property. We expect input monitoring \nimplementations to vary depending on the property that they are designed to check. Note that the monitor \nmay maintain state to help it check the acceptability of the input. In our example, the count variable \nis an example of this kind of state.  Enforcement: In addition to enforcing the accept\u00adability property, \nthe .lter will typically attempt to keep the recti.ed input (heuristically) close to the orig\u00adinal input. \nIn our example, the .lter truncates overly long tokens but otherwise leaves the input stream un\u00adchanged. \nAlternative .lters might split overly long to\u00adkens by inserting spaces into the middle of long non\u00adspace \ncharacter sequences or remove overly long to\u00adkens altogether. We rejected these alternatives be\u00adcause \nsplitting or removing tokens appears to be more likely to confuse the core s input stream processing \nthan truncation. In general, we expect that enforcement strategies will tend to be application dependent \nand heuristic. Error\u00adcorrecting parsers insert keywords to make an input program parse [1]; spell-checkers \nuse a dictionary of known words to correct misspellings. For systems whose acceptability properties involve \nreal-time constraints, the enforcement mechanism may delay inputs that ar\u00adrive too early and/or spontaneously \ngenerate replace\u00adments for inputs that arrive too late.  Logging: In this example the .lter simply logs \nthe discarded characters. A more elaborate logging imple\u00admentation might provide more information about \nthe truncated tokens and the position in the input where the truncation occurred.  Note that in our \nexample we applied input .ltering at a well-de.ned interface consisting of input and output streams. \nIt is possible, of course, to apply input .ltering at arbitrary granularities throughout the software. \nMany implementa\u00adtions of standard libraries, for example, have extensive error checking that is designed \nto catch incorrect usage patterns (although the usual response is to signal an error, not to rectify \nthe input and continue the execution). 2.4 Output Monitoring and Recti.cation The core in our example, \nlike many software systems, may produce unacceptable results under certain inputs. For ex\u00adample, the \nfollowing input: putx10 puty11 rem y putx12 rem x get x causes the core to generate the output 10 11 \n1112 12 2 instead of 10 11 1112 12 0 (a 0 returned from a get com\u00admand indicates that there is no mapping \nassociated with the name). The problem is that the free procedure, when invoked by the put procedure \nto remove the entry that im\u00adplements the map from x to 10, does not actually remove the entry. It instead \nputs the entry on the free list (which uses the value .eld to link together the free entries), leaving \nit also linked into the table of active entries. One way to .x this problem is to change the implemen\u00adtation \nof the core. But (especially for larger, more complex components with sophisticated internal state and \nbehavior) developing the understanding required to safely change this implementation may take an enormous \namount of time and e.ort. And changing the core always raises the possibility of introducing new errors. \nFigure 5 presents a component that enforces the accept\u00adability property that any output must either 1) \nbe between the minimum and maximum values inserted into the map\u00adping, or 2) be 0. It enforces this property \nby creating two .lters. The .rst .lter (the extract procedure) processes the input to determine whether \nor not the next command is a get, put,or rem. The other .lter (the rectify procedure) processes the output \nto record the minimum and maximum values put into the table. It uses these values to ensure that all \noutputs for get and rem commands are either between the minimum and maximum or 0; we call this activity \nrec\u00adti.cation. The .rst .lter uses the channel stream to pass the command information to the second .lter. \nThe main procedure sets up the channels, creates the two .lters, and starts the core. Figure 6 graphically \npresents the resulting process structure. When confronted with an out of bounds result from the core, \nthe output .lter replaces the result with 0. An alter\u00adnative approach would be to simply replace the \nresult with the minimum or maximum value. This approach might be preferable when any value in the table \nis acceptable. Con\u00adsider our motivating usage context of a client that uses the core to map a bank of \nprinter names to network addresses. Assuming the minimum and maximum values remain valid, the .lter would \nensure the delivery of the print job to some printer. If all of the printers are acceptable to the client, \nthe result would be a system that could deliver acceptable results even in the face of unreliable behavior \non the part of the core. The code in Figure 5 uses a black-box approach: the im\u00adplementation of the core \nremains unchanged. As may often be the case with such solutions, the management code re\u00adquired to implement \nthe communication between the .lters and the interpositions on the input and output streams dom\u00adinates \nthe code required to enforce the acceptability prop\u00aderty. A white-box approach may require less code \nbecause the state and communication may be more easily accessi\u00adble. The drawback, of course, is that \nthe white-box code must execute in a more complex and presumably less well understood context. Figure \n7 presents a white-box reimplementation of the core main procedure from Figure 1. We have augmented this \nprocedure to maintain the minimum and maximum values put into the mapping and to coerce out of bounds \nvalues to 0. The code is substantially smaller than the black-box code in Figure 5, but is embedded within \nthe input and output processing code in the main procedure. As should be the case, the .lter code is \nadded around the edges of the core it does not appear within the procedures (put, get, rem) that implement \nthe primary functionality of the core. void extract(int fd) { char cmd[LEN], name[LEN]; int val; while \n(scanf(\"%s\", cmd) != EOF) { if (strcmp(cmd, \"put\") == 0) { if (scanf(\"%s %d\", name, &#38;val) == 2) { \nprintf(\"%s %s %d\\n\", cmd, name, val); fflush(stdout); write(fd, \"p\", 1); fsync(fd); } } else if (scanf(\"%s\", \nname) == 1) { printf(\"%s %s\\n\", cmd, name); fflush(stdout); write(fd, cmd, 1); fsync(fd); } } } void \nrectify(int fd) { int val; char c; static int min = MAXINT; static int max = 0; while (scanf(\"%d\", &#38;val) \n!= EOF) { read(fd, &#38;c, 1); if (c == p ) { if (val < min) min = val; if (max < val) max = val; } \nelse { if (val < min) val = 0; if (val > max) val = 0; } printf(\"%d\\n\", val); fflush(stdout); } } int \nmain(int argc, int *argv[]) { int input[2], output[2], channel[2]; pipe(input); pipe(channel); pipe(output); \n if (fork() == 0) { dup2(input[1], 1); extract(channel[1]); } else if (fork() == 0) { dup2(input[0], \n0); dup2(output[1], 1); execv(argv[1], argv+1); fprintf(stderr, \"io: execv(%s) failed\\n\", argv[1]); }else \n{ dup2(output[0], 0); rectify(channel[0]); } } Figure 5: Black-Box Implementation of Min/Max Output \nMonitoring and Recti.cation input  input command channel output filtered output  Figure 6: Process \nStructure for Black-Box Imple\u00admentation of Min/Max Output Monitoring and Rec\u00adti.cation int main(int argc, \nchar *argv[]) { char cmd[LEN], name[LEN]; unsigned val; static int min = MAXINT; static int max = 0; \ninitialize(); while (scanf(\"%s\", cmd) != EOF) { val=0; if (strcmp(cmd, \"put\") == 0) { if (scanf(\"%s \n%u\", name, &#38;val) == 2) { put(name, val); /* record min and max */ if (val < min) min = val; if (max \n< val) max = val; } } else if (strcmp(cmd, \"get\") == 0) { if (scanf(\"%s\", name) == 1) { val = get(name); \n} } else if (strcmp(cmd, \"rem\") == 0) { if (scanf(\"%s\", name) == 1) { val = rem(name); } } /* enforce \nacceptability property */ if (val < min) val = 0; if (val > max) val = 0; printf(\"%u\\n\", val); fflush(stdout); \n } } Figure 7: White-Box Implementation of Min/Max Output Monitoring and Recti.cation int scan(char name[], \nint val) { int i; for (i =0; i <N; i++) if (strcmp(name, name(i)) == 0) return(value(i)); return val; \n} Figure 8: Code to Scan entries Array The primary new consideration when implementing com\u00adbined input \nand output .lters is the mechanism that the .lters use to communicate. The black-box implementation in \nFigure 5 uses a Unix pipe to carry the extracted command information to the output .lter. The white-box \nimplementa\u00adtion in Figure 7 uses variables. Other potential mechanisms include network connections and \nshared memory segments. Other issues (such as interposition mechanisms, monitoring, and acceptability \nproperty enforcement) are similar to those discussed in Section 2.3.  2.5 Structure and Behavior Further \ntesting may reveal another anomaly the fol\u00adlowing input: puta5 putc6 rem a get c produces the output \n5650 instead of the output 5656. One hypothesis may be that the core is dropping mappings because it \nhas exceeded its mapping capacity, but this hardly seems likely with only three mappings. It turns out \nthat there is a di.erent problem. When the rem procedure in Figure 2 removes a mapping, it removes (in \naddition to the removed entry) all entries in the list before the removed entry. As with the previous \ndeletion example from Section 2.4, it is possible to recode parts of the core so that the rem procedure \ndoes not delete the preceding list entries. The same disadvantages (the need to understand the core code, \nthe potential to introduce new errors) apply. An alternative is to apply an acceptability property that \nrelates the data structures that the core builds to the out\u00adputs that it generates. Speci.cally, the \nentries array con\u00adtains the mappings that the get procedure makes available to the client. An appropriate \nacceptability property is there\u00adfore that get should never return 0 if there is a mapping present in \nthe entries array for the name passed as an ar\u00adgument to the put command. One can therefore view the \ntable data structure as (like a cache) providing quick access to a set of mappings that may provide an \nacceptable answer. But if this data structure fails to provide an answer, the im\u00adplementation should \nexamine the entries array directly to .nd the mapping. Figure 8 presents code that scans the entries \narray to .nd the mapping for a given name. A white-box implemen\u00adtation of the acceptability property \ndiscussed above would simply invoke the the scan procedure whenever the get pro\u00adcedure (from Figure 2) \nreturns 0. With this change, the im\u00adplementation correctly returns 6 as the result of the get c command \nfor the input discussed above. void extract(int fd) { char cmd[LEN]; char name[LEN]; int val; while (scanf(\"%s\", \ncmd) != EOF) { if (strcmp(cmd, \"put\") == 0) { if (scanf(\"%s %d\", name, &#38;val) == 2) { printf(\"%s %s \n%d\\n\", cmd, name, val); fflush(stdout); write(fd, name, strlen(name)); write(fd, \"\\n\", 1); fsync(fd); \n} } else if (scanf(\"%s\", name) == 1) { printf(\"%s %s\\n\", cmd, name); fflush(stdout); write(fd, name, \nstrlen(name)); write(fd, \"\\n\", 1); fsync(fd); } } } int main(int argc, int *argv[]) { int input[2], output[2], \nchannel[2], pid; pipe(input); pipe(channel); pipe(output); if (fork() == 0) { dup2(input[1], 1); extract(channel[1]); \n} else if ((pid = fork()) == 0) { dup2(input[0], 0); dup2(output[1], 1); execv(argv[1], argv+1); fprintf(stderr, \n\"st: execv(%s) failed\\n\", argv[1]); }else { dup2(output[0], 0); rectify(pid, channel[0]); } } Figure \n9: Implementation of name Extractor for entries Filter It is also possible to develop a gray-box implementation. \nOne approach interposes an output .lter and scans for 0 outputs. It then uses the Unix ptrace package \nto gain ac\u00adcess to the address space of the core process and examine the contents of the entries array \nto determine if it should replace 0 with some other value. As in the example in Sec\u00adtion 2.4, the output \n.lter needs some information from the input stream. It is possible to use the same solution: an input \n.lter that extracts the information and uses a sepa\u00adrate channel to pass it along to the output .lter. \nFigure 9 presents the code for this input .lter. The extract proce\u00addure implements this .lter it extracts \nthe names from the input stream and passes them to the output .lter. The main procedure creates the input \n.lter, the core, and the output .lter and sets up the connections between them. Figure 10 presents the \ncode for the output .lter. The addr procedure uses the readelf command to extract the symbol table information \nfor the core process and .nd the address of the entries array within this process. It uses the getLine \nprocedure to parse the symbol table information. The rectify procedure implements the output .lter. It \ninput  int getLine(FILE *f, char buf[], int len) { int i =0, c; while (((c = fgetc(f)) != EOF) &#38;&#38; \n(i < len-1)) { buf[i++] = c; if (c == \\n ) break; } buf[i] = \\0 ; return(i); } #define SIZE 256 int \ngetAddr(int pid, char sym[]) { char cmd[SIZE], buf[SIZE]; int addr = 0; sprintf(cmd, \"readelf -s /proc/%d/exe\", \npid); FILE *f = popen(cmd, \"r\"); while (getLine(f, buf, SIZE) != 0) { if (strstr(buf, sym) != NULL) { \ninti= 0,j= 0; while ((buf[i] != : ) &#38;&#38; (buf[i] != \\0 )) i++; i++; sscanf(buf + i, \"%x\", &#38;addr); \n} } return addr; } int getEntries(int pid, int offset) { int i; for (i = 0; i < sizeof(entries) / sizeof(int); \ni++) { ((int *) entries)[i] = ptrace(PTRACE_PEEKDATA, pid, offset+i*sizeof(int)); if (((((int *) entries)[i]) \n== -1) &#38;&#38; (errno != 0)) return -1; } return i; } void rectify(int pid, int fd) { int val; int \noffset = getAddr(pid, \"entries\"); char name[LEN]; int i; int stat; while (scanf(\"%d\", &#38;val) != EOF) \n{ for (i = 0; i< LEN; i++) { read(fd, &#38;name[i], 1); if (name[i] == \\n ) break; } name[i] = \\0 ; \nif (val == 0) if (ptrace(PTRACE_ATTACH, pid, 1, 0) != -1) { if ((waitpid(pid, &#38;stat, 0) != -1) &#38;&#38; \n(getEntries(pid, offset) != -1)) val = scan(name, val); ptrace(PTRACE_DETACH, pid, 0, 0); } printf(\"%d\\n\", \nval); fflush(stdout); } } Figure 10: Implementation of entries Filter input input   command name \n channel channel ptrace output interface filtered output filtered output  Figure 11: Process Structure \nfor entries Filter examines the output stream and, when it .nds a 0 output, uses the ptrace package to \nattach to the core process. It then invokes the load procedure to copy the contents of the entries array \nfrom the core into its own local version and invokes the scan procedure to .nd an appropriate entry (if \none exists) and return the value from this entry. Figure 11 graphically presents the process structure \nthat the entries .lter generates when combined with the min/max .lter from Section 2.4. There are two \ninput .lters: the .rst extracts the command information from the input stream to pass it to the min/max \noutput .lter; the next extracts the name information to pass it to the entries .lter. The entries .lter \nuses the ptrace interface to access the data structures in the core. This example illustrates how to \nuse the structures that the core builds as a foundation for stating and enforcing acceptability properties. \nInstead of specifying output prop\u00aderties as a function of the inputs, it is instead possible use properties \nthat capture the relationship between the out\u00adputs and the structures that the core builds as it processes \nthe inputs. Leveraging the core data structures may sub\u00adstantially reduce the complexity and implementation \ne.ort required to enforce some acceptability properties without these data structures, the enforcement \ncomponent may be forced to reimplement much of the data structure function\u00adality to store the input information \nthat it needs to enforce its acceptability property. It may also be useful to enforce acceptability properties \ninvolving the inputs and the resulting core data structures. Many of these properties can be viewed as \ncapturing accept\u00adability properties of the core state as a function of the core s interaction history \nwith the environment. There is a conceptual connection between some transac\u00adtion processing failure recovery \nalgorithms and resilient com\u00adputing mechanisms that enforce acceptability relationships between the input \nand the state. Transaction processing systems typically maintain a log of all operations performed against \nthe database. Conceptually, the database is sim\u00adply a data structure (like the table in our example) \nthat the transaction processing system uses to accelerate access to the data (whose primary representation \nis in the log). When the database fails, the recovery system may rebuild the database by replaying part \nor all of the log. One can therefore view the recovery algorithm as enforcing a correct\u00adness relation \nbetween the input history in the log and the structure of the database.  3. MORE TECHNIQUES In Section \n2 we presented a range of acceptability-oriented computing techniques in the context of an example program. \nWe next discuss other potential techniques and applications. 3.1 Data Structure Consistency The data \nstructure repair implementation discussed in Section 2.2 consists of a set of hand-coded procedures that \ndynamically detect and repair violations of key data struc\u00adture consistency properties. While this code \nsatis.es its re\u00adpair goals, hand-coded data structure repair code can be di.cult to develop (because \nthe developer cannot assume that the data structures satisfy their normal invariants and because the \n.nal code can be quite complex). And it can be di.cult to examine the code to determine which properties \nit does and does not enforce. We have therefore developed a new speci.cation-based approach to enforcing \ndata structure consistency proper\u00adties [10]. The goal is to reduce development e.ort and place the .eld \non a .rmer foundation by making the enforced con\u00adsistency properties explicit. Our system accepts as \ninput a speci.cation of the desired data structure consistency prop\u00aderties. During the execution of the \nprogram, it traverses the data structures in the heap to .nd speci.c objects that vio\u00adlate the consistency \nproperties. When it .nds a violation, it applies repair actions that coerce the data structures back \ninto a consistent state. It is also possible to apply the in\u00adconsistency detection and repair process \nto a persistent data structure (such as an application data .le) just before a pro\u00adgram attempts to access \nthe data structure. One complication is that correct programs may temporar\u00adily violate the consistency \nconstraints during data structure updates. We address this complication by enabling the pro\u00adgrammer to \nidentify the points in the program where he or she expects the data structures to be consistent. The \ntool enforces data structure consistency at only those points. A potential concern is that repair followed \nby continued execution may lead to the silent generation of unexpected results. Our approach generalizes \nto support the tagging of all values computed using repaired data. These tags would support user interfaces \nthat suitably distinguish results pro\u00adduced from repaired data, alerting the user to potentially questionable \nresults. We have applied our system to several applications an air-tra.c control system, a multi-player \ngame, a sim\u00adpli.ed version of the Linux ext2 .le system, and Microsoft Word documents. We found that \nthe speci.cations had ac\u00adceptable development overhead and that the resulting re\u00adpair algorithms enabled \nthe systems to e.ectively recover from otherwise fatal errors. We found the air-tra.c con\u00adtrol system \nto be a particularly interesting application. It tracks hundreds of aircraft and implements features \nthat provide di.erent kinds of functionality (.ow visualization, route planning, con.ict detection, trajectory \nprojection, and scheduling). Without data structure repair, an error in any one of the aircraft or any \none of the features can cause the entire system to fail, denying the controller access to any of its \nfunctionality. Data structure repair enables the system to continue to execute and provide normal functionality \nfor almost all of the aircraft and features. 3.2 Process Structure Consistency Many distributed systems \nare structured as collections of communicating processes. Like data structures, these process structures \noften come with consistency properties. These properties typically become violated because processes \n(or the machines that host them) fail, hang, or become in\u00adaccessible. It is possible to augment these \nprograms with additional components that monitor the process structure for inconsistencies caused by \nthe presence of failed, inacces\u00adsible, or duplicated processes. Like most other monitoring components, \nthese components could be manually coded or automated generated from a speci.cation of relevant consis\u00adtency \nproperties. Resilient computing techniques might repair inconsistent process structures by regenerating \nfailed or inaccessible pro\u00adcesses and shutting down duplicate processes (after rerout\u00ading connections \nto a chosen primary process). In our map example from Section 2, one might isolate the core behind an \ninput and output .lter. If the core fails, the .lters would cooperate to restart it. An extension might \nrecord put com\u00admands, then replay these commands to reinitialize the new core. Safe exit techniques might \nshut down the remaining processes after taking appropriate actions to move to a sta\u00adble state. 3.3 Con.guration \nConsistency Many programs and operating systems must be con.g\u00adured to operate correctly. System administrators \nare typ\u00adically responsible for (more or less manually) con.guring systems and maintaining the con.gurations \nto ensure that they support the needs of the user and are consistent with the surrounding computing infrastructure. \nA con.guration can become inconsistent in a variety of ways: updates to the computing infrastructure \nin which the system is embedded, botched, incompatible, or undesirable software installations, or attacks \nsuch as software viruses. Di.erent applications may also require di.erent con.gurations. It is possible \nto augment these systems with components that monitor the con.guration to detect inconsistent or suboptimal \ncon.gu\u00adrations. Resilient computing approaches might recon.gure the system automatically; safe exit approaches \nmight notify a system administrator and block any actions a.ected by the inconsistent or suboptimal part \nof the con.guration. 3.4 Library Usage Consistency Many libraries come with implicit consistency require\u00adments \non the sequence in which the operations must be invoked. Standard examples include requiring .les to \nbe opened before reading or writing and ordering constraints (such as two phase locking) on lock and \nunlock operations. It is possible to monitor the execution of the program to detect violations of these \nordering requirements. When a violation is detected, resilient computing techniques could automatically \ninsert or remove library calls to move a pro\u00adgram from inconsistent to consistent execution sequences. \nFor example, if a client passes an invalid .le descriptor to a read or write operation, the operation \ncan simply open a default .le and perform the operation on that .le.  4. ISSUES Acceptability-oriented \ncomputing as presented in this pa\u00adper is largely untested and it is unclear to what extent it will succeed. \nIt has the potential to signi.cantly change many of the engineering and social trade-o.s associated with \nsoft\u00adware development, in both obvious and quite subtle ways. The overall success of the technique will \ndepend, in large part, on the interaction between these changes. 4.1 Continued Execution After Repair \nResilient computing systems are strongly biased towards continued execution even after the con.rmed detection \nof an incorrect or unexpected execution in part of the system. In many situations it may be far from \nclear when this contin\u00adued execution is more desirable than the more traditional approach of terminating \nthe computation, then relying on human intervention to restore the system to an acceptable operating \nstate, or on the slightly more powerful concept of monitoring for unacceptable states or behavior, then \nexe\u00adcuting a safe exit strategy. Resilient computing should therefore be most easily ac\u00adcepted in situations \nwhere continued execution, even if com\u00adpromised, has clear advantages over outright failure. Ex\u00adamples \nof such situations include autonomous systems that must execute largely without human intervention, systems \nwith long recovery times and stringent availability expecta\u00adtions, and when (such as in image processing \nsoftware) the basic acceptability of a pro.ered result is immediately ob\u00advious upon inspection. Resilient \ncomputing may be useful when the software is known to execute incorrectly in cer\u00adtain situations, but \nthe developers are unwilling to risk the system disruption that might result from .xing the incorrect \ncode, preferring instead to repair any damage after it occurs. It may also be useful for systems with \nmultiple largely inde\u00adpendent components repairing an otherwise fatal .aw in one component may enable \nthe system as a whole to continue its execution, with the remaining components continuing to provide \ntheir normal functionality. Resilient computing may be less acceptable when (as is the case for many \nnumeric calculations) the acceptability of the result is di.cult to determine by simple inspection, especially \nwhen a repaired error may cause the produced result to satisfy stated consistency properties but still \ndevi\u00adate from a correct or acceptable result. Ways to attack this problem include the use of credible \ncomputation (computa\u00adtions that produce a checkable proof of the correctness or acceptability of their \nresults) [20, 21] or explicit tagging of results that depend on repaired state or computation. 4.2 Easy \nAdoption Path Technologies that require wholesale changes to current practice typically have a di.cult \nadoption path, even when it is clear that they o.er substantial advantages. Technolo\u00adgies that require \nfew changes typically have a much easier time. This dichotomy is especially acute for technologies that \ninvolve a large, stable installed base. The installed base of C and C++ programmers, for example, has \nin the past comprised a substantial (and in many cases unsur\u00admountable) obstacle to the adoption of new \nprogramming languages, even when these languages were clearly superior. Acceptability-oriented computing \nhas a very easy adop\u00adtion path. It can be incrementally added to preexisting core software written in \nstandard legacy languages such as Fortran, C, or C++. There are no serious obstacles that signi.cantly \ncomplicate its use in multilingual software sys\u00adtems. Only those developers actively producing the accept\u00adability \nmonitoring and enforcement components or speci.\u00adcations need even be aware of its presence in the system; \nother developers can continue to obliviously use the same practices they have always used. In fact, resilient \ncomput\u00ading techniques may even reinforce current software develop\u00adment practices by increasing the reliability \nof software produced using these practices, they may postpone or elim\u00adinate the need to move to new practices. \nEven if organi\u00adzations wind up never using its failure recovery features in deployed systems, the inconsistency \ndetection features may facilitate the detection and localization of errors during the development phase. \nAnd the exercise of identifying the key acceptability properties may help the organization to under\u00adstand \nthe properties that the system should preserve and to focus their development e.ort. Acceptability-oriented \ncom\u00adputing therefore has the pro.le of technology that can pro\u00adliferate very rapidly throughout the software \ndevelopment ecosystem once its advantages become apparent. 4.3 Poorly Understood Software Components \nWith current development practices, the use of potentially unreliable or poorly understood components \nintroduces a substantial amount of uncertainty about the behavior of the system. In particular, it can \nbe di.cult or impossible to rea\u00adson about what circumstances might cause unacceptable be\u00adhavior to occur, \nwhat form the unacceptable behavior might take, and the ultimate consequences of the unacceptable be\u00adhavior. \nThis situation is unfortunate, because these kinds of components may, in many circumstances, provide \nsubstan\u00adtial functionality and development advantages. For exam\u00adple, machine learning, neural networks, \nand software evolu\u00adtion (all of which produce software that may be di.cult or impossible to understand) \ncan e.ciently deliver function\u00adality that is di.cult to obtain at any cost using standard development \ntechniques. And many incompletely developed or debugged software packages also implement (albeit par\u00adtially) \nvaluable functionality. Acceptability-oriented computing may be able to elim\u00adinate much of the uncertainty \nassociated with the use of such potentially unreliable or poorly understood compo\u00adnents. The acceptability \nenforcement mechanisms bound the range of potential system behaviors, making it possi\u00adble to reason concretely \nand precisely about the potential impact of these components. Acceptability-oriented tech\u00adniques therefore \npromise to enable a much more aggres\u00adsive approach to software reuse and to the incorporation of poorly-understood \nsoftware into the system. The end re\u00adsult may be a dramatic reduction in the di.culty of building acceptable \nsoftware systems and corresponding increase in the amount of functionality that we can incorporate into \nan acceptable system. 4.4 Appropriate Engineering Investment In almost every software development project, \nsome parts of the system are, in practice, more important than others. An e.cient development process \nwould clearly devote more care to the engineering of these parts of the system. But tra\u00additional requirements \nanalysis processes fail to prioritize the requirements, leaving the developers without any guidance as \nto how they should most e.ciently invest their engineer\u00ading resources to deliver the most acceptable \nsystem within their means. Because acceptability-oriented computing provides such a prioritization, it \nmay trigger the development of new soft\u00adware engineering processes that direct di.erent amounts of engineering \nresources to di.erent tasks based on the per\u00adceived importance of each task to the overall acceptability \nof the .nal system. 4.5 Impact on Software Quality If acceptability-oriented computing delivers on its \npromise to make systems execute acceptably in spite of errors, it will also reduce the incentive to produce \nreliable software in the core. One potential outcome would be a substantial reduction in the amount of \nengineering required to produce an acceptable piece of software. Instead of sinking a large amount of \nengineering resources into .nding and eliminating programming errors in the core software system, the \norgani\u00adzation would simply accept a larger number of core software errors, then rely on the outer layers \nto compensate for their presence. The success of this particular scenario depends on the as\u00adsumption \nthat the production of close to perfect software is more expensive than the production of software that \nis, in the presence of a su.ciently sophisticated acceptability enforcement mechanisms, just acceptably \n.awed. But note that even in a resilient system, the core software must reach a certain level of reliability \nbefore the system as a whole can function acceptably. And it is also clear that, in a variety of settings \nthat range from manufacturing [8] to personal relationships [17, 7], the mere presence of mechanisms \nthat are designed to detect and compensate for human error has the e.ect of reducing the e.ectiveness \nof the participants in the setting and, in the end, the overall quality of the sys\u00adtem as a whole. A \npotential explanation is the bystander e.ect that the participants start to rely psychologically on \nthe error detection and compensation mechanisms, which reduces their motivation to reduce errors in their \nown work. In fact, the most successful manufacturing process in the world today (lean production) can \nbe viewed as designed to magnify the negative impact of each error on the process and to therefore increase \nthe vulnerability of the system as a whole to these errors [23]. The rationale is that this ap\u00adproach \nmakes each error immediately obvious and serious and therefore immediately addressed. The goal is also \nto increase the motivation of the human participants to reduce their individual errors to the lowest \npossible level and to ap\u00adply their e.orts to eliminating errors within the system as a whole. The knowledge \nthat they are developing software for an acceptability-oriented system with error detection and com\u00adpensation \nmechanisms may therefore reduce the motivation and ability of the developers to produce quality software. \nThey may even be incapable of delivering software that sat\u00adis.es even the reduced requirements for successful \ninclusion in a resilient system. It may turn out to be the case that, in the end, the best way to build \nreliable software is to place each developer in a position where 1) each error that he or she makes will \nhave serious consequences, and 2) he or she is solely responsible for ensuring the absence of errors \nin the parts of the system that he or she develops. The error monitoring and compensation mechanisms \nat the heart of acceptability-oriented computing are obviously counterpro\u00adductive in such a scenario. \nA related problem is that developers may subconsciously adjust their activities and work habits so that, \nacross a very broad range of development processes, the same amount of e.ort is required to deliver a \nminimally acceptable software system regardless of the development methodology or sys\u00adtem structure. \nIn this case acceptability-oriented computing would not produce a better system, and its more sophisti\u00adcated \nstructure could be seen only as a disadvantage. 4.6 Automatic Property Generation Acceptability-oriented \ncomputing requires the presence of identi.cation of acceptability properties. We expect that, compared \nto the speci.cation for the core software system, these speci.cations will be quite small and relatively \neasy for developers to produce. However, it may be desirable to produce these speci.cations automatically \nto reduce the development burden. One approach is to statically analyze the program to ex\u00adtract likely \nacceptability properties. This analysis would ob\u00adviously need to be unsound (if not, the core program \nwould never violate the properties). Of course, the trade-o. is that an unsound analysis has the freedom \nto generate more am\u00adbitious and potentially more useful properties. Another approach is to monitor the \nexecution of the code to learn key input, output, and data structure properties [9, 11]. The system would \nthen enforce these properties for all executions. Potential issues include ensuring that the sys\u00adtem \nobserves enough behaviors so that it does not in.exibly enforce a overly narrow set of properties and \neliminating un\u00addesirable properties generated by unacceptable executions. 4.7 Monitoring and Repair \nOverhead Acceptability-oriented computing may introduce additional overhead in the form of the monitoring \nand repair software. The potentially most serious form of this overhead occurs when the system su.ers \nfrom a recurrent error that is re\u00adpeatedly repaired, and therefore masked, by the error com\u00adpensation \nsoftware. In this scenario, the system might spend most of its time executing the error recovery software, \nwith the human users oblivious to the true source of the com\u00adpromised performance and therefore unable \nor unmotivated to solve the problem. In the worst case, the problem could become progressively more serious \nuntil the recovery mech\u00adanisms were .nally unable to compensate. In the absence of such monitoring and \nrepair, of course, the error would become immediately obvious and problematic to its users, who would \nthen repair the system and eliminate the error. Logging mechanisms are designed to attack this problem \nthey produce information about repaired errors in part to alert the human users or administrators to \nthe potential problem. It is unclear how e.ective such warnings would be in practice, given the discipline \nrequired to take action in response to warnings of errors that do not immediately interfere with the \noperation and use of the system. An example of this kind of problem arises in intermittently faulty hard \ndisks, which may require multiple reads of the same disk block to successfully retrieve the data. The \nsystem may spend much of its time repeatedly attempting to read the same disk block, but this fact is \nhidden because the retries are transparent to the client of the low-level disk hardware. Despite the \nfact that such intermittent errors are typically logged and often indicate an impending total disk failure, \nmany users do not regularly monitor the log to preemptively replace faulty disks before they fail. 4.8 \nAcceptability Requirements Identi.cation One of the prerequisites for applying resilient computing is \nidentifying key acceptability properties, which typically take the form of structural consistency properties \nor basic behavioral requirements. Many software engineers believe that explicitly identifying and documenting \nthese kinds of properties improves the software development process, even if they are never explicitly \nused once they have been identi\u00ad.ed and documented. Potential bene.ts include obtaining a better understanding \nof the system under development and facilitating the communication of this understanding within the development \nteam. What is now understood as a key advantage of acceptability-oriented computing (a more reli\u00adable \nsystem through automated compensation for errors and faults) may prove, over time, to be most important \nas an in\u00adcentive that convinces organizations to explicitly document key system acceptability requirements. \n 4.9 Error Tracking It is often desirable to be able to understand why a system behaves the way it does. \nIn general, we expect that resilient computing techniques may complicate this analysis the additional \nlayers may obscure or even completely mask the original sources of errors. One way to attack this problem \nis to ensure that the monitoring mechanisms adequately log all of the impending acceptability violations \nthat they detect. The log entries should help the developer trace interesting events in the system and \nreconstruct potential reasons for its behavior. The logs may even make a system augmented with acceptability-oriented \nmechanisms easier to understand than the original, unaugmented system. 4.10 Close to Perfect Software \nThe recent proliferation and success of bug-.nding soft\u00adware development tools and safe programming languages \nsuch as Java raises the possibility that developers may be able, in the near future, to dramatically \nincrease the quality of the software that they produce. It is possible that this increase may be large \nenough to render the additional ben\u00ade.t of the resilient approach small enough to be not worth the additional \ncost and complexity. 4.11 More Creative Software Acceptability-oriented programming may free developers \nfrom the tyranny of perfection, enabling the creative devel\u00adopment and deployment of code with only a \nhazy, intuitive idea of what the code will do in some or even most situa\u00adtions. Instead of engaging in \ndetailed reasoning about what will happen, programmers may simply adopt a more empiri\u00adcal approach in \nwhich they quickly throw together some code that they feel is close to what they might want, try it in \nthe system to see how it works out, then incrementally modify it until it exhibits approximately the \ndesired behavior most of the time, relying on the acceptability enforcement mech\u00adanisms to avoid the \nintroduction of unacceptable behavior. The potential advantages of this approach include faster exploration \nof the implementation space and a reduced need for developers to understand the software system. It may \nalso reduce the cognitive capabilities required to function e.ectively in the system, enabling less competent \ndevelopers to make meaningful contributions.  5. EXTENSIONS As described so far, resilient computing \ncan be seen as a way to inject redundancy into a system to increase ac\u00adceptability. Its focus on in.uencing \nthe execution via data structure updates and input and output .lters often leaves the core software untouched. \nBut resilient computing tech\u00adniques may make some dramatically di.erent approaches to developing and \nmanipulating the core practical. 5.1 Failure-Oblivious Computing Consider a safe language with null pointer \nchecks and ar\u00adray bounds checks. If the program fails one of these checks, the run-time system throws \nan exception. Because program\u00admers usually can t be bothered or don t know how to handle these exceptions \nin a more intelligent fashion, the program usually terminates. Instead of terminating, the system can \ninstead replace the execution of the o.ending statement with a simple de\u00adfault action that enables the \nsystem to continue to execute without throwing an exception. So, for example, if the pro\u00adgram attempts \nto load a value from a null reference, the system might return a default, previously observed, or ran\u00addom \nvalue as the result of the load and continue to execute without throwing an exception. The system could \nalso sim\u00adply discard values stored to illegal addresses. One can view this approach as applying resilient \ncomputing at a low level with simple automatically generated recovery actions and no speci.cation required \nfrom the developer. One justi.cation for this approach is that the program may produce many results, \nonly some of which may be af\u00adfected by any given error. But all of the results need the .ow of control \nto pass through the computation that gener\u00adates them. One artifact of the standard sequential comput\u00ading \nparadigm is that the .ow of control is arti.cially mul\u00adtiplexed between independent computations, with \na failure in any one of the computations causing the .ow of control to be unavailable to the others. \nA similar arti.cial resource constraint occurs in token ring networks and may be one of the reasons that \nthese networks have proved to be less popular than other kinds of networks. An alternate approach would \napply techniques from lazy programming languages to view the computation as a (lazily generated) dependence \ngraph containing computations that lead to the results. If the dependence graph for a given result contains \nan error, the program simply does not produce that result. Independent computations, of course, would \nstill pro\u00adduce their results. Given this insight, it is possible to trans\u00adlate the basic philosophy of \nthe approach back to sequential languages. This approach would use the sequential .ow of control only \nto order interfering accesses (two accesses inter\u00adfere if they access the same location and one of the \naccesses is a write). The failure of one computation would not pre\u00advent independent computations from \nsuccessfully producing their results. It is, of course, possible to generalize this idea to allow independent \ncomputations to produce results even if one of the computations does not terminate. One gener\u00adalization \nwould reason statically about the complete set of e.ects performed by potentially nonterminating loops \nto ex\u00adecute independent computations following the loop even in the absence of loop termination. An alternative \ngeneraliza\u00adtion would simply forcibly exit loops that fail to terminate either within some predetermined \nnumber of iterations or after substantially exceeding previously observed numbers of executions. 5.2 \nCode and Input Variation A traditional approach to surviving faults is to periodi\u00adcally checkpoint, then \nreact to failure by rolling back to a previously checkpointed state, then restart. The disadvan\u00adtage, \nof course, is that the system will simply fail again if presented with the same input. One way to avoid \nthis problem is to perturb the input in some way to elicit di.erent behavior from the system. The speci.c \nperturbation will depend on the context, but examples could include varying the timing and order of in\u00adputs \nfrom independent sources, removing parts of the input, or transforming the values in the inputs in some \nway. Of course, this input transformation may cause the program to generate di.erent results but then, \nthis is the whole point: to change the behavior of the program to move it away from failure. Another \nalternative is to use fault injection to perturb the execution of the program for some time after failure. \nPotential targets of fault injection include modifying the data structures and changing the direction \nof conditional branches. The data structure modi.cation could be guided by consistency property speci.cations \nif they are available. This approach would reduce the chance of the recovery mech\u00adanism causing new failures. \n 5.3 Code Omission Much of the code in the core typically falls into one of two categories: common case \ncode that implements the basic functionality and executes on almost all inputs, and uncom\u00admon case code \nthat is there to correctly handle very rare combinations of events. It is well known that uncommon case \ncode complicates the structure of the program and can make the program substantially larger and more \ndi.cult to understand. Resilient computing opens up the possibility of simply omitting the uncommon case \ncode. In most cases the omis\u00adsion would have no e.ect because the omitted code would not have executed. \nIf the code would have executed, the ac\u00adceptability enforcement mechanisms may produce a result that \n(while potentially di.erent from the correct result that the omitted code would theoretically have produced) \nthe user can live with. The potential bene.ts of this approach include smaller, simpler code that is \neasier and cheaper to develop and mod\u00adify. These advantages may enable the developers to pro\u00adduce common-case \ncode with fewer errors, in which case the system as a whole may be more reliable than a system which \ncontains code for the uncommon cases. The mere elimination of the uncommon case code may also, by itself, \nincrease the reliability of the system. Because complex, in\u00adfrequently executed code is notoriously di.cult \nto develop without errors, its elimination (even with no replacement) may increase the overall reliability \nof the system. As discussed below in Section 6.5 the use of garbage col\u00adlection can be seen as an instance \nof code omission (an appli\u00adcation that uses garbage collection omits all of the code used to support \nexplicit memory management). The bene.ts of that garbage collection delivers (elimination of references \nand memory leaks; increased reliability) provide an indica\u00adtion of the potential advantages that code \nomission may o.er when applied to other aspects of the computation. 5.4 Code Excision In some cases \nthe mechanism that detects acceptability violations may be able to identify the code that caused the \nviolation. If a given piece of code is responsible for many violations, it may be bene.cial for the acceptability \nenforce\u00adment mechanism to excise the code from the system so that it will not continue to cause problems. \nThe excised code may be replaced by alternate code or simply removed from the system with no replacement \nof the functionality that it was intended to provide. The potential bene.ts may in\u00adclude reduced repair \noverhead and fewer faults propagated to otherwise acceptable parts of the system. A generalization of \ncode excision identi.es properties whose satisfaction causes the code to fail, then uses if statements \nto skip the code in question when these properties are sat\u00adis.ed. We call this generalization conditional \ncode excision; the conditional skipping of put invocations when the free list is empty as discussed in \nSection 2.2 is an example of this technique. 5.5 Code as an Inconsistency Generator A correct data structure \nupdate can often be viewed as creating intermediate inconsistent data structures, then re\u00adpairing the \ninconsistency. Given an automated consistency restoration mechanism, it may be possible to simply omit \nthe explicit consistency restoration code, relying on the auto\u00admated consistency restoration algorithm \nto restore the con\u00adsistency properties and complete the update. Once again, the potential advantages \ninclude smaller and simpler code. This approach may turn out to be especially useful for data structure \ninitialization. The standard approach is to functionally decompose the initialization to match the de\u00adcomposition \nof the data structure. Unfortunately, there are often complex interdependences between these di.erent \nini\u00adtialization components, which complicates the staging of the initialization. In the worst case, the \nneed to eliminate cyclic initialization dependences can force counter-intuitive code refactorings, with \nthe initialization code remaining brittle in the face of incremental data structure changes. An alternative \napproach is to declaratively specify the consistency properties for initialized data structures, elimi\u00adnate \nthe explicit data structure initialization code, then in\u00advoke the data structure consistency enforcer \nafter an alloca\u00adtion of the initial item in the data structure. The consistency enforcer will automatically \ngenerate a legal initialization se\u00adquence, eliminating the need for the developer to produce code that \ncorrectly orders the initialization steps. 5.6 Core Elision All of the techniques discussed so far eliminate \npart of the system but leave other parts intact. The extreme logical endpoint is to simply eliminate \nall of core code so that the system consists of nothing more than a set of acceptability speci.cations \nwritten in a variety of languages. We expect this approach to work best for relatively simple systems, \nand in fact some work in model-based computing and domain\u00adspeci.c languages can be seen as an instance \nof this core elision technique.  6. RELATED WORK We next discuss several existing techniques that can \nbe seen as instances of acceptability-oriented computing. We focus on resilient computing techniques. \nMost deployed sys\u00adtems contain embryonic safe exit techniques in the form of assertions or input safety \nchecks, although as mentioned above in Section 1.3, we expect that these systems would bene.t from an \nincreased awareness and understanding of explicit acceptability properties, a more organized approach \nto detecting impending acceptability violations, a larger ef\u00adfort devoted to identifying more appropriate \nsafe exit strate\u00adgies, and, when appropriate, the application of resilient com\u00adputing techniques. We \nnote that monitoring for impending acceptability violations is a key component of acceptability\u00adoriented \ncomputing. Monitoring is a well-established .eld of computer science; monitoring techniques have been \ndevelop\u00ading in a wide range of .elds and deployed to accomplish a variety of goals. 6.1 Hand-Coded Data \nStructure Repair Data structure repair has been a key part of two of the most reliable software systems \never built: the IBM MVS operating system [18] and the software for the Lucent 5ESS switch [13]. Both \nof these systems contain a set of manually coded procedures that periodically inspect their data struc\u00adtures \nto .nd and repair inconsistencies. The reported results indicate an order of magnitude increase in the \nreliability of the system [12]. These successful, widely used systems illustrate the util\u00adity of performing \ndata structure inconsistency detection and repair. We view the use of declarative speci.cations for data \nstructure repair (see Section 3.1) as providing a signi.cant advance over current practice, which relies \non the manual de\u00advelopment of the detection and repair code. The declarative approach enables the developer \nto focus on the important data structure consistency constraints rather than on the operational details \nof developing algorithms that detect and correct violations of these constraints. The expected result \nis a substantial reduction in the amount of e.ort required to develop reliable inconsistency detection \nand repair software. 6.2 Persistent Data Structures Persistent structures are an obvious target for \nmany in\u00adconsistency elimination algorithms. An inconsistency in a small part of the system can prevent \nthe system from ac\u00adcessing any of the data at all. And the standard default error recovery technique, \nrebooting, does not eliminate the problem since the inconsistencies persist across reboots. File systems, \nfor example, have many characteristics that moti\u00advate the development of automatic repair programs (they \nare persistent, store important data, and acquire disabling inconsistencies in practice). Developers \nhave responded with utilities such as Unix fsck and the Norton Utilities that at\u00adtempt to .x inconsistent \n.le systems. Databases also have many characteristics that justify inconsistency detection and repair, \nand database researchers have investigated a vari\u00adety of integrity management techniques [6, 5, 22]. \nThese techniques update the relations in the database to enforce database consistency constraints. 6.3 \nPartial Reboots Researchers have developed a technique that exploits the structure in component-based \nsystems to avoid complete system reboots [4]. When the system starts to exhibit anoma\u00adlous behavior, \nthey apply techniques that attempt to reboot a minimal set of components required to restore the system \nto normal operation. The goal is to minimize recovery time by leaving as much of the system as possible \nintact. 6.4 Application-Speci.c Techniques The utility of the acceptability-oriented approach can be \nseen in several cases in which developers have opportunisti\u00adcally applied such techniques to improve \ntheir systems. We are aware, for example, of avionics software with two .ight control systems: one is \na venerable, fairly conservative, and well-tested version, while the other is a newly developed, more \nsophisticated and aggressive version. The acceptabil\u00adity property is that the aggressive version must \nkeep the aircraft within the same .ight envelope as the conservative version. This strategy enables the \ndevelopers to apply more sophisticated .ight control algorithms without compromis\u00ading the safety of the \naircraft. We are also aware of a graph\u00adics rendering package that simply discards problematic tri\u00adangles \ninstead of including complex special-case code that attempts to render the triangle into the scene [14]. \nEmbed\u00added systems developers have used layered approaches that apply safe exit strategies to increase \nthe probability that the system behaves acceptably even when confronted with unan\u00adticipated situations \n[19]. Given the utility of acceptability\u00adoriented techniques, we expect that they have been applied in \nan application-speci.c manner in many other systems. 6.5 Garbage Collection One reasonable acceptability \nproperty is that all mem\u00adory in a system is either reachable via the application s data structures or \npresent in the free list and available for allocation. Garbage collection can be seen as a resilient \ncomputing technique that enforces this property. From this perspective, developers who use standard garbage-collected \nlanguages such as Java can be seen as adopting a deliberate code omission strategy as discussed in Section \n5.3. Speci.\u00adcally, the developers omit all of the code that is designed to support, enable, and perform \nexplicit memory management. This perspective highlights some of the potential advantages of code omission. \nExplicit memory management code is no\u00adtoriously di.cult to get correct and is a serious source of problems \nin many deployed software systems. Removing this code and replacing it with a single uniform implemen\u00adtation \nthat enforces a well-de.ned acceptability property can produce a substantially more reliable system. \n 7. UNRELATED WORK Reliability has been a central issue in computer science ever since the very .rst \ncomputers were built. Early research in the area tended to focus on ways to enable the system to continue \nto operate after sustaining various kinds of physi\u00adcal damage. The standard approach is to apply some \nform of redundancy to enable the system to recognize or even reconstruct damaged data. This redundancy \nis sometimes connected to mechanisms that allow the system to recom\u00adpute any results lost or incorrectly \ncomputed because of the damage. We identify this research as unrelated research because its primary goal \nis to simply preserve the correct execution of the program in the face of damage or errors, not to actively \nmonitor and change the execution to ensure that it satis.es acceptability properties. 7.1 Physical Redundancy \nPhysical redundancy provides the system with multiple copies of its basic components, enabling the system \nto con\u00adtinue to operate even if some of the components become inoperable. This basic idea can be applied \nat all levels of the system design, from the basic logic gates in the com\u00adputer system to larger components \nsuch as processors and memories. Since broken hardware components may not be able to recognize that they \nare no longer functioning cor\u00adrectly, there is often some way to compare results from all components \nand choose the result that is perceived to be most likely to be correct. The standard mechanism is to \nuse majority voting, which obviously works best with at least three versions of each potentially faulty \ncomponent. 7.2 Information Redundancy The basic idea behind information redundancy is to repli\u00adcate \ninformation to enable the system to reconstruct missing or damaged data. The standard approach is to \nuse parity or more sophisticated versions of error correcting code. This approach can be applied in space \n(redundancy in the bits in memory) or in time (redundancy in bits transmitted). The primary downside \nis the extra physical resources (memory or bandwidth) required to apply the technique. If the tech\u00adnique \nsupports detection but not correction, another poten\u00adtial downside is decreased reliability. The standard \nresponse to the detection of an uncorrectable error is to terminate the computation. Because many of \nthese errors may have a min\u00adimal e.ect on the overall system, it may be better for the system to simply \ncontinue to execute through the error. 7.3 Computation Redundancy The basic idea behind computation \nredundancy is to repli\u00adcate computation to enable the system to recognize and dis\u00adcard any incorrect \nresults. One .avor basically boils down to physical redundancy in that the same computation is repli\u00adcated \non multiple hardware platforms. If one of the plat\u00adforms sustains damage and produces an incorrect result, \na comparison with the other results will reveal the discrep\u00adancy. The standard response is to discard \nthe incorrect re\u00adsult and, in some circumstances, initiate a repair action. Another way to replicate \ncomputation is to produce multi\u00adple di.erent implementations of the same speci.cation. The idea is that \nif one implementation is incorrect and produces an incorrect output, the other implementations will most \nlikely not su.er from the same error and will produce cor\u00adrect output. As in hardware computation replication, \na com\u00adparison of the results enables the system to recognize and discard the incorrect result. Note that \nthe success of this approach relies on developers producing independent errors. In practice, even independent \ndevelopments have an annoy\u00ading tendency to produce implementations that often fail on the same inputs \n[3]. Another potential problem is that the speci.cation may be incorrect. 7.4 Checkpoint and Reboot \nA standard approach to corrupted or damaged state is to rebuild the state from scratch by simply rebooting \nthe system. This approach works extremely well provided the corrupted state is discarded during the reboot \nprocess, it is acceptable to lose of the discarded state, and it is acceptable to disable the system \nduring the period of time when it is rebooting. This approach can be augmented with periodic check\u00adpointing, \nenabling the reboot to lose less information by starting from recent state. One can view actions that \nsave state to disk as periodically checkpointing parts of the state to ensure that it persists across \nfailures. One potential prob\u00adlem with checkpointing is that the checkpoint may silently contain corrupted \nor inconsistent state. At .rst glance, rebooting may seem to be pointless after all, won t the system \njust fail again once it is rebooted and asked to retry the task that elicited the error? It turns out \nthat, in practice, many software errors occur only under unusual combinations of circumstances, and that \nrebooting the system and retrying the task often changes the state and various aspects of the inputs \n(such as their timing) enough to avoid the speci.c combination of circumstances that caused the error. \n 7.5 Transactions Transactions are a standard way to avoid corrupting data structures in the presence \nof errors in updates [12]. The transaction processing system implements a semantics in which the entire \nset of updates performed during the trans\u00adaction become visible to the rest of the system atomically. \nIf the transaction fails for any reason none of its updates become visible. It is possible to dynamically \ncheck for con\u00adsistency at the end of each transaction just before it commits and abort the transaction \nif it leaves any of the updated data in an inconsistent state. 7.6 Comparison All of the mechanisms \ndiscussed in this section either attempt to protect the computation and its state against physical damage, \nor to protect the system against errors that corrupt its data structures by eliminating the e.ect of \nany computation that leaves the state inconsistent or at\u00adtempts to perform an illegal action. A fundamental \ndi.er\u00adence with acceptability-oriented computing in general and resilient computing in particular is \nthat these last two ap\u00adproaches accept the need to incorporate at least some of the e.ects of erroneous \ncomputations into the system and its state. Reasons why it might make sense to do this include the need \nto make forward progress in the computation and eliminating recovery time.  8. CONCLUSION Software engineering \nhas been dominated by the aspira\u00adtion to produce software that is as close to perfect as pos\u00adsible, with \nlittle or no provision for automated error recov\u00adery. We discuss an alternate approach that explicitly \nrejects the aspiration of attempting to produce perfect software as counterproductive. Software built \nusing this alternate ap\u00adproach instead consists of layers of partial and potentially redundant acceptability \nspeci.cations, with the layers be\u00adcoming progressively simpler, more partial, and more likely to accurately \ncapture the intended acceptability property as they move towards the periphery of the layered structure. \nThis approach may make it possible to build resilient sys\u00adtems that continue to execute productively \neven after they take an incorrect action or sustain damage. It may also en\u00adable organizations to prioritize \ntheir development processes to focus their e.orts on the most important aspects of the system, reducing \nthe amount of engineering resources re\u00adquired to build the system and enabling a broader range of individuals \nto contribute productively to its development. Acknowledgements I would like to thank Daniel Jackson, \nButler Lampson, and the members of my research group, in particular Brian Dem\u00adsky and Karen Zee, for \nmany interesting and useful discus\u00adsions on the subject of this paper. Also, some of the ideas in this \npaper were honed in collaboration with Daniel Jackson when we worked together to prepare a grant proposal; \nin particular, the discussion of the trade-o. between function\u00adality and reliability emerged as part \nof that process. Butler Lampson brought the software con.guration problem to my attention in a discussion \nwe had some time ago; I would like to thank Tim Kay for the idea that parity checks de\u00adcrease reliability; \nTim also developed the graphics package that discards problematic triangles. Jim Larus and Daniel Jackson \nbrought the example of dual aircraft .ight control software to my attention. Patrick Lam helped me .gure \nout how to use the Unix ptrace interface from Section 2.5. 9. REFERENCES [1] A.V. Aho,R. Sethi,and J. \nUllman. Compilers: Principles, Techniques, and Tools. Addison-Wesley, Reading, MA, second edition, 1986. \n [2] A. Alexandrov, M. Ibel, K. Schauser, and C. Scheiman. UFO: A personal global .le system based on \nuser-level extensions to the operating system. ACM Transactions on Computer Systems, 16(3):207 233, August \n1998. [3] Susan Brilliant, John Knight, and Nancy Leveson. Analysis of faults in an n-version software \nexperiment. IEEE Transactions on Software Engineering, SE-16(2), February 1990. [4] George Candea and \nArmando Fox. Recursive restartability: Turning the reboot sledgehammer into ascalpel. In Proceedings \nof the 8th Workshop on Hot Topics in Operating Systems (HotOS-VIII), pages 110 115, Schloss Elmau, Germany, \nMay 2001. [5] Stefano Ceri, Piero Fraternali, Stefano Paraboschi, and Letizia Tanca. Automatic generation \nof production rules for integrity maintenance. ACM Transactions on Database Systems, 19(3), September \n1994. [6] Stefano Ceri and Jennifer Widom. Deriving production rules for constraint maintenance. In Proceedings \nof 1990 VLDB Conference, pages 566 577, Brisbane, Queensland, Australia, August 1990. [7] J. Darley and \nB. Latane. Bystander intervention in emergencies: Di.usion of responsibility. Journal of Personality \nand Social Psychology, pages 377 383, August 1968. [8] W. Edwards Deming. Out of the Crisis. MIT Press, \n2000. [9] B. Demsky and M. Rinard. Role-based exploration of object-oriented programs. In Proceedings \nof the 2002 International Conference on Software Engineering, Orlando, Florida, May 2002. [10] Brian \nDemsky and Martin Rinard. Automatic detection and repair of errors in data structures. In Proceedings \nof the 2003 ACM SIGPLAN Conference on Object-Ori ented Programming Systems, Languages, and Applications \n(OOPSLA 03), Anaheim, California, November 2003. [11] Michael D. Ernst, Adam Czeisler, William G. Griswold, \nand David Notkin. Quickly detecting relevant program invariants. In International Conference on Software \nEngineering, pages 449 458, 2000. [12] Jim Gray and Andreas Reuter. Transaction Processing: Concepts \nand Techniques. Morgan Kaufmann, 1993. [13] G. Haugk, F.M. Lax, R.D. Royer, and J.R. Williams. The 5ESS(TM) \nswitching system: Maintenance capabilities. AT&#38;T Technical Journal, 64(6 part 2):1385 1416, July-August \n1985. [14] T. Kay and J. Kajiya. Ray tracing complex scenes. Computer Graphics (Proceedings of SIGGRAPH \n86), 20(4):269 78, August 1986. [15] G. Kiczales, J. Lamping, A. Mendhekar, C. Maeda, C. Lopes, J. Longtier, \nand J. Irwin. Aspect-oriented programming. In Proceedings of the 11th European Conference on Object-Oriented \nProgramming, Jyvaskyla, Finland, June 1997. [16] J. Larus and E. Schnarr. EEL: Machine-independent executable \nediting. In Proceedings of the ACM SIGPLAN 95 Conference on Programming Language Design and Implementation \n(PLDI), San Diego, California, June 1995. [17] B. Latane and J. Darley. Group inhibition of bystander \nintervention in emergencies. Journal of Personality and Social Psychology, pages 215 221, October 1968. \n[18] Samiha Mourad and Dorothy Andrews. On the reliability of the IBM MVS/XA operating system. IEEE Transactions \non Software Engineering, September 1987. [19] P. Plauger. Chocolate. Embedded Systems Programming, 7(3):81 \n84, March 1994. [20] M. Rinard and D. Marinov. Credible compilation with pointers. In Proceedings of \nthe Workshop on Run-Time Result Veri.cation, Trento, Italy, July 1999. [21] Martin Rinard. Credible compilation. \nTechnical Report MIT-LCS-TR-776, Laboratory for Computer Science, Massachusetts Institute of Technology, \nMarch 1999. [22] Susan D. Urban and Louis M.L. Delcambre. Constraint analysis: A design process for specifying \noperations on objects. IEEE Transactions on Knowledge and Data Engineering, 2(4), December 1990. [23] \nJames Womack, Daniel Jones, and Daniel Roos. The Machine that Changed the World: the Story of Lean Production. \nHarper Collins, 1991.  \n\t\t\t", "proc_id": "949344", "abstract": "We discuss a new approach to the construction of software systems. Instead of attempting to build a system that is as free of errors as possible, the designer instead identifies key properties that the execution must satisfy to be acceptable to its users. Together, these properties define the <i>acceptability envelope</i> of the system: the region that it must stay within to remain acceptable. The developer then augments the system with a layered set of components, each of which enforces one of the acceptability properties. The potential advantages of this approach include more flexible, resilient systems that recover from errors and behave acceptably across a wide range of operating environments, an appropriately prioritized investment of engineering resources, and the ability to productively incorporate unreliable components into the final software system.", "authors": [{"name": "Martin Rinard", "author_profile_id": "81100087275", "affiliation": "MIT, Cambridge, MA", "person_id": "P192534", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/949344.949402", "year": "2003", "article_id": "949402", "conference": "OOPSLA", "title": "Acceptability-oriented computing", "url": "http://dl.acm.org/citation.cfm?id=949402"}