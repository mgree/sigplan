{"article_publication_date": "10-26-2003", "fulltext": "\n Hardware/Software Codesign in Neo Smalltalk Jecel Mattos de Assumpc\u00b8ao Jr. Merlintec Computers Rua \nConde do Pinhal 2185, s64 S ao Carlos, SP, Brazil  jecel@merlintec.com ABSTRACT The processors normally \nused for low cost or embedded ap\u00adplications are not well suited for running Smalltalk, so we created \nour own using programmable circuits (FPGAs). By creating the software and hardware speci.cally to work \nwith each other it was possible to simplify both to such a de\u00adgree that the resulting system is competitive \nin terms of price/performance compared to solutions with traditional processors, despite the ine.ciency \nof FPGAs relative to cus\u00adtom designs. Both a 16 bit and a 32 bit hardware implementation of Neo Smalltalk \nwere created and illustrate the cost and per\u00adformance tradeo.s possible in this kind of development. \nThe hardware is de.ned in terms of objects exchanging mes\u00adsages down to the lowest level, which is an \ninteresting con\u00adtrast to the traditional bytecoded virtual machines used for Smalltalk, Java and similar \nlanguages.  Categories and Subject Descriptors B.1.5 [Register Transfer-Level Implementation]: De\u00adsign; \nC.1.2 [Processor Architectures]: Multiple Data Stream Architectures; C.5.3 [Computer System Implementa\u00adtion]: \nMicrocomputers microprocessors, portable devices; D.3.2 [Programming Languages]: Language Classi.ca\u00adtions \nSmalltalk  General Terms Design, Languages  Keywords Codesign, Object-Oriented Hardware 1. INTRODUCTION \nIt has been argued[1] that special hardware doesn t re\u00adally help object oriented languages. Indeed, the \nsad fate of the various Lisp Machines, the Lynn Rekursiv[2] and several Copyright is held by the author/owner. \nOOPSLA 03, October 26 30, 2003, Anaheim, California, USA. ACM 1-58113-751-6/03/0010. Table 1: Basic \nInstruction Set Tag Instruction 0 execute primitives 1 push object 2 send message 3 send self message \n great academic projects (like the Mushroom[3]) are hardly encouraging for new language speci.c processor \nprojects, though there have been some recent e.orts to create hard\u00adware for Java. A major problem is \nthat such projects are created by small groups that can t keep up with Moore s Law like the mainstream \nprocessors do. On top of that there is always some new software trick or other being developed that makes \nthings much faster on stock hardware. So any design ex\u00adpected to be 30% faster here and there is doomed \nfrom the start. An interesting option is the use of Field Programmable Gate Arrays (FPGAs). Even though \nthey are slower and more expensive than the corresponding custom chip solu\u00adtion, for special architectures \nthey can be used to create a competitive product. FPGAs are often the .rst circuits to work on new semiconductor \nprocesses, making it easy for a design based on them to keep pace with Moore s Law. And these designs \ncan be changed at any time, even in the .eld, so it is possible to stay ahead of new developments in \nsoftware implementations.  2. OBJECTS AND MESSAGES, ALL THE WAY DOWN Neo Smalltalk1 was designed to \nenable the development of low cost computers for students. The goal is to make it sim\u00adple for them to \ncreate their own content and programs (spe\u00adcially simulations), but the machine itself should be learn\u00adable \nby anyone interested in computer technology. So a single organizational style was used for the graphical \nuser interface, the high level language, the system level program\u00adming and even the lowest hardware implementation \nlevel: objects exchanging messages. Table 1 shows the four basic instructions which are gen\u00aderated by \nthe compiler from the Neo Smalltalk source code. Each takes up a 32 bit (or 16 bit, as explained in the \nnext section) word with the lowest two bits indicating the instruc\u00adtion and the rest the operand. This \nallows a single stream of 1previously called Self/R and Merlin OS Table 2: Primitive Instruction Set \nReceiver Object Message 0 Message 1 Message 2 Message 3 0 Stack dup pop over swap 1 Memory atInc:Put: \natInc: auxAtInc:Put: auxAtInc: 2 Math add sub shiftLeft shiftRight 3 Logic and or not xor 4 State write5: \nwrite32: read5: read32 5 Registers pop5: pop32: push5: push32 6 Indirect literal5: literal32: perform5: \nperform32: 7 Branch jump5: jump32: skipOnZero return information to be fed into the microprocessor, \nin contrast to normal bytecode virtual machines which separate the byte\u00adcodes themselves from the literal \nreferences they need to operate. For large methods (which use the same literals and message selectors \nmany times) the traditional approach is far more compact, but most methods are very small so this simpli.cation \nis worth it. The most important thing to no\u00adtice about the basic instruction is how they are exclusively \nabout objects and messages. The execute primitives basic instruction2 encodes six (3, in 16 bit words) \n5 bit instructions that are described in Ta\u00adble 2. These can also be described in terms of objects and \nmessages. The top three bits select one of eight hardware objects and the bottom two bits indicate a \nmessage to be sent to it. The result is a mostly conventional stack ma\u00adchine with most instructions dealing \nexclusively with the stack, though some require a 5 bit (next slot ) or 32 bit (next word) extra operand. \nThe performX: instructions are particularly interesting since they treat their operand as another primitive \ninstruc\u00adtion to be executed, allowing many more hardware objects than the basic 8. An application might \nrequire a fast multi\u00adplier or a graphics BitBLT operation, for example. Moving what was previously a \nsoftware object to hardware is rela\u00adtively simple due to the uniform organization at all levels. High \nperformance is only possible with a massive memory bandwidth and this is achieved by having many tiny \ninternal memories that can be accessed in parallel: the data stack cache, the return stack cache, two \nframe caches, the instruc\u00adtion cache and the object cache. Each one is optimized for a di.erent access \npattern and so can achieve far better results than a generic hardware would. The object cache, for example, \nis indexed by the object number and the .eld o.set. This virtual address would nor\u00admally require one \ntable lookup followed by an addition to get the physical address to be read or written to on every single \naccess. By not using physical addresses for the cache, this costly process is only needed on a cache \nmiss[3] taking it out of the critical path. In the same way, the instruction cache is designed to make \nmessage sends, normally a very slow operation, take only a single clock cycle in the most common case. \n 3. TRADEOFFS Being able to modify both the hardware and software to obtain the best overall solution \nresults in a vast design 2It looks just like a small integer to the garbage collector, while the push \nobject instruction is encoded like a regular object pointer. This allows code vectors to be treated ex\u00adactly \nlike any other object space with many interesting options to explore. For one low cost application, with \na 15 thousand gate FPGA, a 16 bit implementation was chosen. This required some obvious space saving \nmodi.cations, like combining the instruction and data caches and eliminating the frame caches. These \na.ect performance, but not the software organization. Having at most 30 thousand objects available does \na.ect quite drastically the software, however. For any obvious Smalltalk object there are many less obvious \nones just to support it: the class, method dictionary, method objects, source strings and others. The \n16 bit implementation sac\u00adri.ces the re.ective capabilities that these provide by com\u00adbining them all \ninto a single code object. Since the machine has plenty of RAM (making it with less than 8 MB would actually \nbe more expensive) and the number of possible message selectors is small, the code ob\u00adjects implement \nthe rows of a full table lookup scheme (not normally used since 95% of the entries are empty) wasting \nabout 2 MB but gaining a higher performance. On the 32 bit version this would not be practical as the \ntable would require many gigabytes. On a more expensive machine with a 300 thousand gate FPGA it is possible \nto .t up to six 32 bit processors, each with its own local caches. This is a simple way to obtain high \nperformance if the software has been created with a large number of threads. An alternative is to have \nfewer, but more sophisticated processors. What has been described so far is the hardware equivalent of \nsimple interpreted virtual machines like those used in early versions of Smalltalk or Java. Far more \nadvanced software technologies have been developed and it would be interesting to render these in hardware. \n 4. CONCLUSION Special hardware for object-oriented languages can work very well when they are designed \ntogether. 5. REFERENCES [1] U. H\u00a8olzle and D. Ungar. Do object-oriented languages need special hardware \nsupport? In W. Oltho., editor, Proceedings ECOOP 95, LNCS 952, pages 293 302, Aarhus, Denmark, August \n1995. Springer-Verlag. [2] D. Pountain. Rekursiv: an object-oriented CPU. Byte Magazine, 13(12):340 349, \nNov. 1988. [3] I. Williams and M. Wolczko. An object-based memory architecture. In G. M. S. Alan Dearle \nand S. B. Zdonik, editors, Implementing Persistent Object Bases: Proceedings of the Fourth International \nWorkshop on Persistent Object Systems, pages 114 130. Morgan Kaufmann Publishers, Inc., 1991.  \n\t\t\t", "proc_id": "949344", "abstract": "The processors normally used for low cost or embedded applications are not well suited for running Smalltalk, so we created our own using programmable circuits (FPGAs). By creating the software and hardware specifically to work with each other it was possible to simplify both to such a degree that the resulting system is competitive in terms of price/performance compared to solutions with traditional processors, despite the inefficiency of FPGAs relative to custom designs.Both a 16 bit and a 32 bit hardware implementation of Neo Smalltalk were created and illustrate the cost and performance tradeoffs possible in this kind of development. The hardware is defined in terms of objects exchanging messages down to the lowest level, which is an interesting contrast to the traditional bytecoded virtual machines used for Smalltalk, Java and similar languages.", "authors": [{"name": "Jecel Mattos de Assumpccao", "author_profile_id": "81100497185", "affiliation": "Merlintec Computers, Sao Carlos, SP, Brazil", "person_id": "P643455", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/949344.949357", "year": "2003", "article_id": "949357", "conference": "OOPSLA", "title": "Hardware/software codesign in neo smalltalk", "url": "http://dl.acm.org/citation.cfm?id=949357"}