{"article_publication_date": "10-26-2003", "fulltext": "\n Five Years of Framework Building Lessons Learned Kurt Madsen MetaTech, Inc. 18311 Sturbridge, Court \nTampa, Florida, U.S.A. 1 813 991 0177 madsen@metatech.us ABSTRACT When developing large software systems, \nit is often difficult to foresee exactly which trade-offs are important, and which quality parameters \nwill be of importance down the road. This paper reports experiences from a project in which a large application \nframework for B2B integration has been continuously developed and used over a five-year period. The framework \nhas been the foundation for a variety of different concrete applications. Here we will report on our \nexperiences from this endeavor.  Categories and Subject Descriptors D.2.13 [Reusable Software]: Reuse \nModels, Reusable libraries D.2.11 [Software Architectures]: Domain-specific architectures General Terms \nDesign. Keywords Application Frameworks, Object-Oriented Programming, C++, Architecture, Enterprise \nApplication Integration. 1. INTRODUCTION On long-term, software development projects, it is not possible \nto anticipate all future requirements. Therefore, it is necessary to design for change. One approach \nis to define a generic solution to a set of related problems, and then iteratively extend that solution \nto solve the next problem. As the problems change, the solution can be refined and adapted. An application \nframework provides such a solution by defining a template, which can be reused to build many related \napplications. As new requirements emerge, new applications can be constructed that build upon the efforts \nand understanding of prior deliverables. This paper examines an object-oriented, application framework \ncalled EXPRESS. In particular, it explores the experiences of the project team presented as 13 lessons \nlearned in the context of software engineering. Software engineering involves analyzing trade-offs and \nmaking decisions to optimize value given scarce resources. It also involves measuring the quality parameters \nthat Copyright is held by the author/owner(s). OOPSLA 03, October 26-30, 2003, Anaheim, California, USA. \nACM 1-58113-751-6/03/0010. describe the product. One of the challenges of long-term software projects \nis that these trade-offs and quality parameters are not always clear at project inception. 1.1 Problem \nDomain EXPRESS was originally developed within the financial services industry to integrate middle and \nback office applications at banks. While the architecture and project experiences can be applied to other \ndomains and industries, this paper focuses on banking applications that can be created with EXPRESS. \nWhen investment banks trade securities (e.g., stocks, bonds), messages that contain the trade details \nmust pass through many applications at multiple institutions in the Bank-To-Bank (B2B)1 supply chain. \nExamples of institutions include other banks, depositories, settlement networks, and government agencies. \nProcessing and delivering these messages involves integrating across a wide range of communications protocols, \ndata formats, and application-level processing. Figure 1 illustrates the flow of messages among applications. \nThe front office is where traders enter trade details. The middle office is where both banks one for \neach counter-party to the trade agree electronically to the details of the trade. The back office is \nwhere securities and funds are actually exchanged between banks. In between the trading banks are many \napplications at intermediary institutions (e.g., settlement networks). Application integration is complicated \nby a dynamic industry and requirements that change frequently. For example, prior to the introduction \nof the Euro currency, many banks in Europe routed messages by currency code; once the European Union \nmoved to a single currency, the currency code attribute was no longer useful for message routing. Other \nexamples include the re-regulation of the banking industry in America [1] and on-going bank mergers. \nThe EXPRESS project grew from the need to insulate middle and back office applications from these changes. \n1 Traditionally, the acronym B2B implies Business To Business e-commerce, in which two or more businesses \ntrade in a digital community. The problem domain for this paper, Bank To Bank, can be described as systems \nintegration for supply chains. Both interpretations of B2B involve similar technical challenges. Fr ont \nOf f i ce B ank s  Tr ad e C apt ur e Ex p r es s Mi ddl e Of f i ce  Tr ad e C onf i r m Se t l \nem en t Ba c k Of f i ce Ne t wo r ks  Se t l em e n t I nt r an et Ex t r an et  Figure 1. Typical \nB2B Integration Environment  2. APPROACH EXPRESS is an object-oriented, application framework written \nin C++[2]. An application framework provides most of the structure for a generic application, which can \nbe reused to build a familyof related applications. This framework portion is developed once and contains \nelements common to all applications, typically in the form of collaborating, abstract base classes. Implementing \nderived classes then createsspecific applications. In EXPRESS, derived classes are grouped into components \ncalled Plug-ins. Plug-ins can also be reused from one application to the next. One of the benefits of \napplication frameworks is a reduction in the development time required to build each new application \ndue the fact that much of the code in the common framework isreused. Another benefit is that maintenance \neffort is reduced since code common to all applications is in one place. The EXPRESS framework builds \non the Broker Pattern[3],in which applications at remote banks are inter-connected with EXPRESS in the \nmiddle providing integration services. The services are broken down into the following subsystems: Communications \nLayer. Provides adapters to send and receive messages to and from other applications. This layer provides \nadapters to all of the middleware and session layer protocols used by the various institutions. Messages \nare exchanged through protocol-specific channels called message queues, which are implemented as Plug-ins. \n Format Layer. Interprets and translatesincoming message streams from one format to another. Formats \ncan be proprietary messaging standards or de-facto industry standards such as SWIFT[4]. Translators for \ndifferent formats are implemented as Plug-ins.  Application Layer. Routes messages among a pool of proxies, \nwhich represent remote applications at other banks. Proxies provide hooks for application-level (bank-specific) \nprocessing. Proxies are implemented as Plug-ins.  Foundation Libraries. Contains classes and functions \nfor message routing, control, scheduling, exception handling, and various shared technical servicessuch \nasfile processing  utilities (banks often exchange batch files as well as on-line message traffic). \nTo create an EXPRESSapplication, one must write Plug-ins (if they do not already exist) for each of the \nthree layersand, optionally, a derived controller that inherits from the default Controller in the Foundation \nLibraries. Additionally, one must add reference data in the EXPRESS control database. The generic controller \nprovides for subsystem initialization when EXPRESS starts up, event dispatching during run-time[5], and \nsubsystem termination when EXPRESS shuts down. It is possible to write application-specific controller \ninstead of using the generic controller. Examples of Plug-ins for the Communications Layer include sockets, \nflat files, in-memory tables, PrintQs,MQSeries, and proprietary bank protocols.  Examples of Plug-ins \nat the Format Layer include support for fixed-length fields, tag-value formats, and file formats with \ndifferent header/body/trailer options.  Examples of Plug-ins at the Application Layer include IIOP\u00adenabled \nproxies that stand in for applications at other banks.  Our initial thinking at the beginning of the \nproject was that within a layer, only one Plug-in would handle a given message stream. After experimentation, \nwe discovered that it can be useful to pass a stream of messages through several Plug-ins in the same \nlayer. The inspiration for this idea came from the Pipes and Filters architectural pattern[3].For example, \nthe Format Layer needs to parse incoming messages into an intermediate token list and then applytranslation. \nAs another example, the Application Layer might need to implement duplicate message checking. This could \nbe done by inserting a filter Plug-in into the streamto catch and remove duplicate messages (based on \nsome bank-specific information). Figure 2 shows how EXPRESS can scale to larger deployments. A ppl i \nca t i on Ms g Q C han nel s Lo c a l Fo r ma t i ng R egi on al Na t i ona l SW I FT Fe d Wi \nr e Ba n k 2 Ba n k 1  Figure 2 EXPRESS Switching Network As the project evolved, the scope of deployments \nexpanded to include different business units and locations. We realized that the output of one EXPRESS \napplication could feed the input of another to form a switching fabric across the enterprise. In this \nway, EXPRESS supports a wide-range of deployment scenarios from large data centers supporting global \nclearance and settlement traffic to one-process adapters for translating a message stream to a different \nformat. Lesson #1: When building application frameworks, always maintain a clear separation between application \nindependent elements, which belong in the framework and application dependent elements, which belong \nin derived classes (in components called Plug-ins). 3. DECISIONS An important aspect of software engineering \ninvolves selecting the best solution for a given problem. Project experience comes from living through \nthe consequences of long-term architecture decisions. It is only after the consequences have been realized \nthat a team can go back and assess the original decisions. Over time, these post-mortem reviews add to \nthe collective wisdom of the team. It is important for a team to clearly document important decisions \nsince, years later, it can be difficult to remember exactly how the team got into a particular situation. \nSeveral project decisions are presented below. 3.1 Determining the Right Level of Abstraction Software \nengineers are notorious for creating unnecessary layers of abstraction in the name of software reuse. \nWrappers for Application Programming Interfaces (APIs) are a common example. When we designed the Communications \nLayer, we considered writing an abstraction layer to hide middleware APIs such as MQ Series. The argument \nagainst this approach was that it would add complexity and limit access to MQ Series rich features. The \nargument in favor of this approach was that we needed a consistent abstraction layer across a wide variety \nof communications protocols including proprietary message distribution systems that used databases. Ultimately, \nwe decided to introduce our own abstraction layer, which is illustrated in figure 3. The framework portion \nconsists of four abstract base classes: MsgBase specifies methods common to all MsgQs such as connect() \nand disconnect(); MsgInQ is for receiving messages; MsgOutQ is for sending messages; and MsgQ combines \nall methods into one class. MsgInQ and MsgOutQ use virtual inheritance to specialize MsgBase. There are \nmore methods than illustrated such as the ability to use non-blocked I/O. Additionally, the MsgBase class \nuses a finite state machine to enforce proper execution of the MsgQ class hierarchy methods. For example, \nit is not possible to call send() without first calling open(). The application-specific portion of the \nclass hierarchy contains the derived classes of strongly-typed MsgQs. So far, we have implemented MsgQs \nusing MQ Series, SWIFT, Sockets, files, in\u00admemory queues, and proprietary middleware (which uses a relational \ndatabase). And, we have experimented with FAXQs. We discovered many uses for MsgQs: Point-to-point messaging \nbetween banks  Network access points for settlement and clearance networks  Routing duplicate message \nstreams to contingency sites  Load balancing across different EXPRESS nodes  Message capture and replay \nfor regression testing and bank emulation  Creating audit trails and message logs  The most valuable \nproperty of MsgQs is the ability to route message traffic from one type of communications infrastructure \nto another. In one case, we had a network failure that shut down a critical link to the American central \nbanking system (i.e., Fed Wire). A construction crew accidentally cut a cable while digging up a New \nYork City street, which disrupted our primary leased line. Routers re-routed traffic over an alternate \nline. But, this uncovered another, pre-existing problem with a faulty firewall access list at another \nbank. That led to an IP loop between routers. The cascade of failures ultimately prevented completion \nof the middle leg of the TCP three-way hand shake, which disrupted all MQ Series traffic between both \nbanks. Fortunately, we were able use MsgQs to switch production traffic to an alternate communications \nplatform that still worked. Had we not decided to wrap the MQ Series API, we would not have had this \nrecovery option. Lesson #2: When designing abstract base classes, distinguish between specifying behavior \n(i.e., class protocol) vs. factoring out common implementation shared by derived classes. It is generally \nbetter to do one or the other, not both. Lesson #3: Resist the temptation to create unnecessary abstraction \nlayers (e.g., API wrappers) unless absolutely necessary. Lesson #4: Systems built with redundant components \nof different types are generally more reliable than systems built with redundant components of the same \ntype. The space shuttle, for example, has different types of computers whose outputs are compared with \nvoting logic. Such an approach increases reliability and availability. 3.2 Compromise in Layer Positioning \nOne aspect of software engineering is compromise. We experienced this when deciding whether to put the \nEXPRESS MsgFactory in the Communications Layer or the Format Layer. To appreciate this dilemma, it is \nfirst necessary to understand how EXPRESS uses the MsgFactory to create messages. In EXPRESS, the MsgFactory \ninterprets data on an input buffer and instantiate the correct, strongly typed ExMsg object. Type safety \nis necessary to ensure proper translation of messages from one message to the next. Note that languages \nsuch as Java provide class loaders: C++ has no built-in function to do this. The two aspects of EXPRESS \nthat make class loading challenging are that (a) no assumptions can be made about the format or protocol \nof an input stream since its specification is generally defined by another bank; and (b) extensibility \nis essential: new types have to be introduced without touching existing code As an example, introducing \nnew code for mortgage message processing could not put bond message processing at risk. One good approach \nto this problem is the Exemplar idiom[6]. An Exemplar is an object that represents a class, which can \nbe used for class loading in C++. At system startup, one exemplar for each type of message is instantiated \nand added to a linked list of static objects. Then, at run-time, the MsgFactory iterates over the exemplar \npool passing each one a reference to the input buffer. Exemplar examine the input buffer to determine \nif they are the same type of message as the data in the buffer. Most exemplars return null and the iteration \ncontinues until the pool of exemplars is exhausted or one of them finds a match (i.e., it recognizes \nits own type in the input stream). If there is a match, the exemplar clones a new message object of the \nsame type, un-flattens itself from the input buffer, and discards the correct number of bytes from the \ninput buffer. The main advantage of the Exemplar idiom for EXPRESS is that existing code, including the \nfactory code, does not depend upon newly introduced classes. Figure 4 illustrates an example. The Exemplar \nidiom generally worked well, although we experienced some unexpected results during unit and system testing \nwhich led to minor design changes. Each exemplar was declared with file scope and defined in its own \n*.o module. Since they were defined outside of main and linked into the final executable, the order in \nwhich exemplars were added to the message Factory s linked list was unpredictable (at least across compilers). \nThus, we had to be careful to ensure that class loading did not depend on the order of exemplars. In \nother words, one input byte stream could never match two or more message types. This turned out to be \nnon-trivial since EXPRESS had to support a wide variety of message formats defined by different institutions. \ntemplate <class B> class Exemplar { public: Exemplar( Base&#38; ); ~Exemplar( ) static Base* MakeObj( \nistream&#38; ); private: Exemplar(); Exemplar( Exemplar&#38; ); Exemplar&#38; operator=( Exemplar&#38; \n); static Exemplar* _list; Exemplar* _next; Base&#38; _obj; }; #define ADD_EXEMPLAR( Base, D ) \\ static \nDerived Derived ## _dummy; \\ static Exemplar<Base>Derived ## \\ _Exemplar_ ## Base( Derived ## _dummy \n); Figure 4. MsgFactory using the Exemplar Idiom Now, let us return to the issue of whether the MsgFactory \nbelongs in the Communications Layer or the Format Layer. Regardless of the layer chosen, the MsgFactory \nwas part of the EXPRESS framework, while the exemplars were part of Plug-ins depending upon the application \nto be built. One option was to put the MsgFactory in the Communications Layer. This had appeal since \nEXPRESS applications often associated a particular MsgQ with a particular bank (hence format). This information \nhelps the MsgFactory find the right reference message set from which new messages can be created. The \nother option was to put the MsgFactory in the Format Layer. From a modeling perspective, this is where \nthe MsgFactory in particular, the exemplars belonged. But the problem with this approach is that the \nCommunications Layer would then depend upon the Format Layer, which would introduce a circular dependency \nbetween subsystems. We ultimately decided to put this into a common library, which was not a great solution, \nbut solved the dependency problem. Lesson #5: Partitioning functionality across different components \noften involves compromise. Constraints such as eliminating circular dependencies across libraries or \ncomponents take precedence over other partitioning issues.  4. TRADE-OFFS Another aspect of software \nengineering is optimizing trade-offs, particularly with respect to limited resources and competing goals. \n4.1 Entropy vs. Change Sometimes software teams do the wrong things for the right reasons. Two and a \nhalf years into the EXPRESS project, our bank initiated a global IT reengineering program. An external \nconsulting firm was hired to audit all IT projects, including EXPRESS, to ensure alignment with the corporate \nstrategy. Production releases were suspended while employees and consultants worked together for nine \nmonths on a major redesign of the EXRESS framework. Conflicting views soon emerged on the combined team: \nthe employees represented entropy; the consultants represented change. Over time, we learned that each \nside held an essential perspective the other lacked. In the end, many things were changed in EXPRESS: \nsome things were improved, some were worse, and some were just different. This section gives an example \nof how competing ideas can lead to unforseen trade-offs in design. In the first generation of EXPRESS, \nprior to the redesign, the process of translating messages and their fields from one format to another \nwas done in code. The thinking behind the original EXPRESS design, and the rationale for code-based translation, \nwas that the strong type-safety of C++ would prevent software defects. Type safety is a feature of a \nprogramming language in which the compiler ensures that the actual arguments passed to a function match \nthe formal arguments declared in the function s signature. If they do not match, the code does not compile, \nthereby preventing this class of software defects. Our faith in strong type-safety was confirmed by an \nearly bug. Some of the early message translation routines were written in C using functions like sprintf(). \nUnfortunately, sprintf() does not enforce type safety. So, if a pointer to a integer is passed to sprintf() \ninstead of a pointer to a string, a general protection fault will likely occur. While this is a well-known \nproblem in C, programmers compensate by being careful with types. The problem is that people make mistakes. \nWe discovered this bug during user acceptance testing for the first release of EXPRESS. This confirmed \nour selection of C++, and justified our subsequent expanded use of type-safety. As illustrated in Figure \n5, an ExMsg is a strongly-typed container for all data related to a message. The clone(), Unflatten(), \nand Flatten() methods are used by the MsgFactory described above. The srcMsg is a Unicode String buffer \nthat contains the original message as received by an EXPRESS application. The tokenList contains the \ninternal representation of the message. The destMsg is a Unicode String buffer that contains the destination \nmessage. (Note that EXPRESS does support the ability to translate one input message to multiple output \nmessages.) Message format translation within the Format Layer of EXPRESS occurs in two stages: first, \nthe input source message is parsed into an in-memory list of tokens; second, that list of tokens is translated \ninto the destination message format. By doing message translation in two steps, we reduced the number \nof possible translations from n(n-1)/2 to n+1. The trade-off for this reduction in complexity is that \neach message takes twice as long to process. An example of a source message, in-memory token list, and \ndestination message are presented in figures 6, 7, and 8, respectively. Figure 5 ExMsg Class Hierarchy \nstruct { char id[9]; float price; double qty; } Security; struct { char bank_name[15]; char acct_num[12]; \n} Counter_party; struct { char msg_type_code[4]; Security security; Counter_party cpty; } Deliver_vs_payment; \nFigure 6 A Source Message using a Fixed-Structure Trade  Figure 7 In-Memory Token List <Trade> <Type>DeliverVsPayment</Type> \n<Security> <ID>ISIN123</ID> <Price>87 3/8</Price> <Qty>100,000</Qty> </Security> <Counter-Party> <Name>Other \nBank</Name> <Account>ABA123</Account> </Counter-Party> </Trade> Figure 8 A Destination Message using \nXML Structure Initially, we added map() as a pure, virtual method to the ExMsg base class. The idea was \nthat any one type of ExMsg could be translated into another type using polymorphism. But, we found a \nchallenge in that one of the formats (i.e., message sets) was an internal API, which we exported to client \napplications. The application-specific implementation (i.e., derived classes) was linked in at build \ntime by make files and packaging scripts. Since we needed to load different destination formats (depending \nupon the destination bank), we had difficulties with separating member declarations from member definitions \nacross two (or more libraries). In hindsight, this was a learning experience as there are several patterns \n(e.g., Visitor) that solve this problem[7]. Later, we used dynamically linked libraries and overloaded, \nstatic functions with two strongly typed formal arguments, one for the srcMsg buffer and one for the \ndestMsg buffer. This worked well to prevent illegal mappings between message types, but didn t provide \nrecursive mapping into composite messages[7]. Once again, we discovered what we already knew: the software \ndevelopment process involves compromise. The strength of the code-based approach used in the first generation \nwas that both messages and their translation methods were strongly typed. In fact, the compiler and link \neditor ensured that illegal mappings (i.e., the translation from an input message to an output message \nin a different format) were not possible for incompatible message types. This significantly reduced opportunities \nfor software defects allowing us to focus on other issues during testing. We combined this type safety \nwith rigorous regression testing. The result was that the first generation of EXPRESS never had a production \nsoftware defect with business impact that was due to an invalid mapping. The trade-off for this quality \nwas time: new requirements had to be implemented as code changes, which meant releasing EXPRESS through \nour Software Development Life Cycle (SDLC). As a result, we did many software releases into production, \nbut each release took considerable effort. In the second generation of EXPRESS, after the redesign with \nthe consultants, the process of translating messages and their fields from one format to another was \nimplemented using reference tables stored in a database. The rationale for this change was that the corporate \nstrategy favored rapid application development, and databases could be changed rapidly. Note, that this \napproach does not take advantage of strong type\u00adsafety. Message translation in the second generation \nof EXPRESS uses data-driven translation by storing a set of translation rules in reference data in static \ntables in a database. This includes rules that specify data formats, state machine reference tables, \nwhich can be changed on the fly. This has the advantage of more flexibility, and the disadvantage that \nmore defects occur in quality assurance testing. With sufficient testing, the second generation has yielded \nflexible results and is currently used by EXPRESS. Lesson #6: The risk of failure during production releases \nis inversely proportional to the frequency of releases. Lesson #7: A big advantage of strongly-typed \nlanguages such as C++ is type safety. The compiler and link-editor prevent incompatible types from being \nused in unintended ways. Leverage this feature to reduce opportunities for software defects. Lesson #8: \nAfter two or three years into a project, it can be valuable to introduce new team members with different \nperspectives provided they do not introduce change for the sake of change. Properly introduced, such \nchange ultimately encourages developers to put aside the not-invented-here prejudice and to be open to \nnew ideas. Lesson #9: Software development teams sometimes respond to pressure for aggressive development \nschedules by putting programming logic and static, reference tables into databases. Unless it is controlled \ncarefully, this approach is bad practice for two reasons: it bypasses strict, corporate deployment lifecycles \nby encouraging developers to maintain production control logic; and it introduces the possibility that \nhuman error could lead to integrity problems, which could lead to unpredictable program execution. 4.2 \nAccuracy vs. Time This is an example of a run-time trade-off. EXPRESS supports validation methods in \nobject constructors that can be turned on or off recursively at run-time to balance current traffic volume \nand throughput. (The latter is adversely affected by validation processing.) In the Securities Industry, \nstraight through processing (STP) the automation of back-office functions with minimal human intervention \n can take considerable processing resources. This is particularly true for exception transactions which \nrequire off-line research to resolve. We initially planned to support a variety of STP scenarios. After \na while, we realized that the 80:20 rule applied since we were spending too much effort on features that \nwere ultimately did not use. This is because we found other approaches to address performance issues \nthrough a combination of process configuration (described below) and load balancing across processes. \nThus, controlling accuracy as a quality parameter became less important as we had other ways to address \nperformance. Lesson #10: Always seek to solve the most important problem first, followed by the hardest \nproblem second. (Generally, the hardest problem is also the most important problem.) Drop everything \nelse and repeat this cycle. Tackling the hardest problems early helps define the scope of the project. \n 4.3 Flexibility vs. Complexity This is an example of a build-time trade-off. At start-up, express can \nbe configured for either horizontal or vertical scaling. With horizontal scaling, each protocol layer \nwithin EXPRESS (e.g., the Communications Layer) is configured as a cluster of processes load-balanced \nacross loosely coupled server hardware on the same LAN segment. This model is appropriate for deployments \nin data centers that need to support high On-Line Transaction Processing (OLTP) volumes. Conversely, \nwith vertical scaling, a single process boundary encapsulates the entire protocol stack. Multiple processes \nare configured on shared hardware with each process handling a limited number of information channels. \nThese channels, in turn, map to specific business functions (e.g., stocks vs. mortgage-backed securities). \nFigure 9 Horizontal Scaling Our initial thinking was that most deployments would use horizontal scaling \nas depicted in figure 9. It turns out that we made more use of vertical scaling, shown in figure 10, \nbecause it addressed an important customer requirement: each new product line had to be released independently \nof the rest. For example, high volume from mortgage-related products (e.g., pool allocation day) could \nunder no circumstances adversely affect the processing of government securities (e.g., treasury bonds) \nwhich had tight processing deadlines. We found that this requirement outweighed the performance penalties \nof vertical scaling. Thus, we bundled product-related feature sets into vertical process groups. The \nkey point is that this engineering trade-off was implemented as a configuration option, not a design \nlimitation. Lesson #11: Enforce architectural constraints early; defer configuration changes as long \nas possible. This maximizes opportunities for discovering unforeseen applications while maintaining the \nquality controls and structure of a well-defined architecture. Figure 10 Vertical Scaling 4.4 Reuse \nConsidered Harmful Two aspects of designing for reuse are particularly challenging: not knowing how software \nbeing developed today could potentially be reused tomorrow; and determining the right balance of granularity \namong development units (i.e., lightweight objects, big components, entire systems). While reuse is generally \ndesirable, there is a point beyond which reuse yields diminishing returns. Six months into the beginning \nof the project, we made a controversial decision which later became important for survival. EXPRESS was \noriginally part of a larger project to build a next\u00adgeneration clearance and settlement system. There \nwere many arguments made for both projects to share a common code base. The EXPRESS team unilaterally \ndecided to eliminate all dependencies on shared code. The basis for this decision was that B2B application \nintegration was functionally distinct from a clearance and settlement system. This decision was not without \ncriticism. But, the intent was clear: EXPRESS would evolve independently of other projects. During the \ntwo years that followed, several EXPRESS applications were put into production with a new release approximately \neach quarter. The clearance and settlement system, however, had not been rolled out into production. \nAlthough its scope was larger and its design was brilliant, the clearance and settlement project was \nultimately cancelled. While we did not know it at the time, the decision to eliminate dependencies on \nlibraries shared by both projects spared EXPRESS from sharing the same fate. It also positioned EXPRESS \nto become an enterprise service. Lesson #12: Reuse for the sake of reuse can be counterproductive. Instead, \nfocus on good architecture, understanding the cost of reuse, and applying it appropriately.  5. MEASURING \nGROWTH One of the quality parameters of applications frameworks is the rate at which they grow. This \ndrives the velocity of the project. We defined a growth index as z = yield / effort, where yield and \neffort can be measured in several ways such as function points and actual resources expenditures, respectively. \nThis is analogous to return on investment. This metric measures the change in yield over time after considering \nthe up-front investment in developing the application framework. The growth index describes a framework \ns ability to leverage previous work (via software reuse) when building new deliverables. After five years \nof production releases, we concluded that application frameworks tend to go through three stages of growth. \n1. During the first stage, the growth index is less than one. Most of the time and resources are spent \nbuilding the framework itself. For EXPRESS, we developed a few Plug\u00adins with the first release to create \na useful, production deployment (allocating collateral for the finance desk). This first product release \nwas important for our project sponsors. 2. During the second stage of the framework growth lifecycle, \nthe growth index is approximately one. Most, if not all of the framework development has been completed, \nbut the original team is still in the critical path of enhancements. Thus, yield and effort are linearly \nrelated. Stated in a more meaningful way, yield is constrained by resources, time, and budget. 3. During \nthe third stage, the growth index exceeds one. As an application framework matures, the development team \ncan leverage its customers resources by helping them tailor the framework to the their specific needs. \nAt this stage, customers can perform self-provisioning and self-service, which frees up the original \ndevelopment team to pursue other activities such as enhance the framework. Customers generally favor \napplications that are customizable and have mature administration facilities, especially when it decreases \ntheir time to market.  As the EXPRESS project grew, we had some success in realigning our team into \nan internal consulting role. This did accelerate delivery by leveraging resources in other departments. \nUnfortunately, we did not consistently track the growth index and other metrics across releases. As a \nresult, we had some difficulty making the case for additional hardware and software. Lesson 13: One of \nthe challenges of building application frameworks that span different departments is that no one group \nwants to subsidize the development costs of a framework that benefits a competing department. Therefore, \nit is especially important to track the growth index and tie the results back to the long-term business \ncase for the project. The case for proper use of metrics in software engineering is well-established. \n 6. CONCLUSION EXPRESS was implemented using object-oriented technology because this was the best approach \nto satisfy the business requirements. Having an application framework as the basis for our architecture \nhelped us to meet short-term deliverables and adapt to longer term needs as they emerged. Over the course \nof five years, EXPRESS changed considerably. As EXPRESS matured, we discovered unforeseen applications, \nboth big and small, such as the following: Daisy-chaining the output of one EXPRESS application into \nthe input of another helped us scale to larger deployments.  Batch jobs for file extracts, conversion, \nand transfer (typically among banks).  Bank emulators EXPRESS can be configured to read archived data \nfrom files or databases and then send the traffic to another bank. This process can work both ways creating \na source or sink for message traffic. Regression tests can be built using production logs of previous \nruns.  Miscellaneous utilities used in shell scripts such as filters, file pre- and post-processors, \nand message routing among internal applications While this paper has focused on using application frameworks \nfor application integration, there are many other uses for application frameworks. These include both \ndomain-specific and domain\u00adindependent frameworks. One theme that emerged from our work is that as integration \nstandards evolve up the protocol stack, services at lower levels become commodities. New opportunities \nexist for commercial products that can address the challenging problems at the application layer, in \nparticular, business semantics integration. Examples of industry efforts in this area include ebXML[8] \nand RosettaNet[9]. Finally, the following references provided valuable insight: [10], [11], [12], and \n[13]. In summary, object-oriented, application frameworks can add great value to long-term projects that \ninvolve many releases of a set of related applications. For further information on application frameworks, \nvisit www.metatech.us. 7. REFERENCES [1] Securities Industry Association. Gramm Leach Bliley Act. http://www.sia.com/gramm_leach_bliley/. \n[2] Linthicum, D. B2B Application Integration. Addison-Wesley, 2001, pages 82 88. [3] Buschmann, F., \nMeunier, R., Rohnert, H., Sommerlad, P., Stal, M. Pattern-Oriented Software Architecture: A System of \nPatterns. John Wiley &#38; Sons, 1996, pages 99 122 and 53 70. [4] Society for Worldwide Interbank Financial \nTelecommunication. http://www.swift.com/. [5] Schmidt, D. Reactor: An Object-Oriented Interface for Event-Driven \nUNIX I/O Multiplexing. C++ Report, SIGS, Vol. 5, No. 2, February, 1993, pages 1 12. [6] Coplien, J. Advanced \nC++ Programming Styles and Idioms. Addison-Wesley, 1992, pages 279 306. [7] Gamma, E., Helm, R., Johnson, \nR., and Vlissides, J. Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley, \n1995, pages 331 344. [8] ebXML: Enabling a Global, Electronic Market. http://www.ebxml.org/. [9] RosettaNet, \nLingua Franca for eBusiness. http://www.rosettanet.org/. [10] Bucka-Lassen, D., Fraleigh, S., Omorogbe, \nN., and Riehle, D. The Architecture of a UML Virtual Machine. Association of Computing Machinery, Conference \non Object-Oriented, Programming, Languages, and Systems, Fall 2001, pages 327 341. [11] Meyers, S. Effective \nC++. Addison-Wesley, 1992. [12] McConnell, S., Rapid Development: Taming Wild Software Schedules. Microsoft \nPress, 1996. [13] Royce, W. Software Project Management. Addison-Wesley Object Technology Series, 1998. \n  \n\t\t\t", "proc_id": "949344", "abstract": "When developing large software systems, it is often difficult to foresee exactly which trade-offs are important, and which quality parameters will be of importance down the road. This paper reports experiences from a project in which a large application framework for B2B integration has been continuously developed and used over a five-year period. The framework has been the foundation for a variety of different concrete applications. Here we will report on our experiences from this endeavor.", "authors": [{"name": "Kurt Madsen", "author_profile_id": "81100505957", "affiliation": "MetaTech, Inc., Tampa, FL", "person_id": "P643466", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/949344.949441", "year": "2003", "article_id": "949441", "conference": "OOPSLA", "title": "Five years of framework building: lessons learned", "url": "http://dl.acm.org/citation.cfm?id=949441"}