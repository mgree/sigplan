{"article_publication_date": "10-17-2010", "fulltext": "\n To Upgrade or Not to Upgrade Impact of Online Upgrades across Multiple Administrative Domains Tudor \nDumitras\u00b8 Priya Narasimhan Eli Tilevich Carnegie Mellon University Carnegie Mellon University Virginia \nTech tudor@cmu.edu priya@cs.cmu.edu tilevich@cs.vt.edu Abstract Online software upgrades are often plagued \nby runtime be\u00adhaviors that are poorly understood and dif.cult to ascertain. For example, the interactions \namong multiple versions of the software expose the system to race conditions that can introduce latent \nerrors or data corruption. Moreover, indus\u00adtry trends suggest that online upgrades are currently needed \nin large-scale enterprise systems, which often span multi\u00adple administrative domains (e.g., Web 2.0 applications \nthat rely on AJAX client-side code or systems that lease cloud\u00adcomputing resources). In such systems, \nthe enterprise does not control all the tiers of the system and cannot coordinate the upgrade process, \nmaking existing techniques inadequate to prevent mixed-version races. In this paper, we present an analytical \nframework for impact assessment, which allows system administrators to directly compare the risk of follow\u00ading \nan online-upgrade plan with the risk of delaying or can\u00adceling the upgrade. We also describe an executable \nmodel that implements our formal impact assessment and enables a systematic approach for deciding whether \nan online up\u00adgrade is appropriate. Our model provides a method of last resort for avoiding undesirable \nprogram behaviors, in situa\u00adtions where mixed-version races cannot be avoided through other technical \nmeans. Categories and Subject Descriptors D.2.7 [Software Engineering]: Distribution, Maintenance, and \nEnhance\u00adment; K.6.3 [Management of Computing and Informa\u00adtion Systems]: Software Management; C.2.4 [Computer-Communication \nNetworks]: Distributed Systems General Terms Management, Reliability Keywords Mixed-version race, Online \nupgrade, Multiple administrative domains, Risk assessment Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to \nlists, requires prior speci.c permission and/or a fee. Onward! 2010, October 17 21, 2010, Reno/Tahoe, \nNevada, USA. Copyright c . 2010 ACM 978-1-4503-0236-4/10/10. . . $10.00 1. Introduction Actively used \nsoftware must be modi.ed continuously to en\u00adsure its utility and safety. Fixing bugs, adding new features, \nremoving obsolete features, optimizing performance all involve upgrading existing software systems. Moreover, \ncur\u00adrent industry trends suggest that upgrade-related downtime is unacceptable for many large-scale distributed \nsystems, such as electrical utilities, assembly-line manufacturing, customer support, e-commerce or online \nbanking [6]. These systems must employ online-upgrade techniques. During an online upgrade, the system \nenters states that emerge at runtime and that may not have been validated in advance. Multi-tier enterprise \nsystems often employ rolling upgrades, which upgrade-and-reboot each node at a time, in a wave rolling \nthrough the distributed system. Rolling upgrades place the system in a state with mixed versions, where \nrequests might be processed by either the old or the new version during the upgrade. In general, the \nbehavior of a system with mixed versions is not guaranteed to conform to the speci.cation of either version \nof the software and is hard to validate in advance [25]. For example, while the new version can be backward\u00adcompatible, \nthe old version can not handle invocations that require the new version s semantics. Previous research \nad\u00advocates coordinating the upgrade operations [14, 26, 29], to prevent the new version from calling \ninto the old ver\u00adsion, simulating the interfaces of past and future versions during the upgrade [1] or \nperforming upgrades atomically, end-to-end [10], to avoid mixed versions altogether. These approaches \nare infeasible in large-scale distributed systems that span multiple administrative domains (e.g., by \nrelying on client-side code or on cloud-computing resources), where an online upgrade s administrator \ndoes not control all the tiers and cannot coordinate their upgrades. We show that, in systems that communicate \nacross administrative domains us\u00ading asynchronous messaging, a rolling upgrade exposes such a system \nto a new kind of race condition, involving multiple software versions. Such mixed-version races might \nbe benign, but they might also have a critical impact (in 1994, a similar condi\u00adtion in a banking system \ncaused a $15M loss for the bank s customers in a single day [12]). Conversely, delaying the up\u00adgrade \nof a system with known software defects might also have a negative impact. The trade-offs between upgrading \nand not upgrading are not easy to ascertain.  We are aware of two real-world upgrade failures that can \nbe traced to mixed-version races [12, 23]. However, to the best of our knowledge, this race condition \nhas not been described before in the research literature. Instead of preventing mixed-version races, \nor other un\u00adexpected behaviors that can result from an online upgrade, we propose assessing the risk \nthey pose to the system. Our model helps answer the following question: Is it worth suf\u00adfering a potential \ninconsistency during an online upgrade in order to introduce a change that addresses a known issue in \nthe running system? Addressing an issue encompasses cor\u00adrective and perfective maintenance [28], i.e., \n.xing software defects and adding new features, respectively. While bugs and upgrade inconsistencies \nare both undesirable, answering this question allows developers and administrators to choose the lesser \nevil. We have devised a comprehensive model taking into con\u00adsideration all the parameters that in.uence \nthe risks of bugs and mixed-version races. These parameters include the time needed to upgrade a single \nhost, the number of hosts to up\u00adgrade in a certain tier of the system, and the number of mes\u00adsages exchanged \nbetween tiers. We believe that, for a risk-assessment method to be use\u00adful, it must not require testing \nthe entire mixed-version state space, which exhibits combinatorial explosion. Therefore, by understanding \nthe sequence of events that exposes the race conditions, we assess their impact in a limited number of \nsystem con.gurations, and we derive the overall risk of upgrading analytically. Through three case studies \nof upgrades performed in both mission-critical systems (online banking) and in Inter\u00adnet services with \nrelaxed consistency requirements (social networking) we emphasize that our model makes it pos\u00adsible to \nconcretely quantify these risks. In fact, our model commonly recommends counter-intuitive, but correct, \ndeci\u00adsions. We have also created an executable model, in the form of a Web application, to reify our \nrisk-assessment approach and to demonstrate that it can bene.t real users. Risk assess\u00adment represents \na method of last resort, for the situations where mixed-version races cannot be avoided through other \ntechnical means. This paper makes three contributions: We describe mixed-version races, which can occur \nduring upgrades across multiple administrative domains, and we identify the system interactions that \nlead to such race conditions;  We develop an analytical framework for reasoning about the trade-off \nbetween upgrading in the presence of mixed-version races and delaying an upgrade that cor\u00adrects known \nsoftware defects;  We present an online tool that implements our analytical model and we demonstrate \nits use, on three case studies, to decide whether to upgrade or not to upgrade. We note that, in practice, \nthe risk of upgrading can be in.u\u00adenced by additional factors, such as known bugs in the new version. \nIn this paper, we focus on assessing the impact of mixed-version races. A comparison between the risks \nintro\u00adduced by bugs in the old and new versions can be achieved through known testing methods and is \noutside the scope of this paper. The rest of this paper is structured as follows. In Sec\u00adtion 2, we review \nthe state of the art in benchmarking the dependability of systems that undergo online upgrades. In Section \n3, we introduce mixed-version races. In Section 4, we formally present our analytical risk model. In \nSection 5, we describe three case studies of online upgrades, and in Section 6 we discuss the implications \nof our contribution.  2. Background Historically developed in the telecommunications industry for the \nmaintenance of telephone switches, dynamic soft\u00adware updating techniques [13] focus on upgrading single\u00adnode \nsystems on the .y. However, industry trends sug\u00adgest that online-upgrade techniques are currently needed \nin a wide range of distributed systems (e.g., electrical util\u00adities, assembly-line manufacturing, customer \nsupport, e\u00adcommerce, online banking) [6]. The characteristics of dis\u00adtributed systems simplify some aspects \nof the upgrade prob\u00adlem, while complicating others. Speci.cally, while dis\u00adtributed systems include redundancy \nand fault-tolerance mechanisms, allowing components to be temporarily inac\u00adcessible, they also require \nmore complex interactions among the heterogeneous system components (e.g., asynchronous messaging, long-running \ntransactions, reads/writes to shared storage). Moreover, in distributed systems spanning multiple administrative \ndomains, it may be dif.cult to coordinate the operations performed during an online upgrade. Online upgrades \nin distributed systems. The earliest work on distributed-system upgrades relies on the crash recov\u00adery \nand state transfer mechanisms from the Argus sys\u00adtem [3], which were originally developed for coping \nwith crash faults and network partitions. Similarly, the Eternal system, which provides fault tolerance \nto legacy CORBA ap\u00adplications by redirecting the message exchanges to a group\u00adcommunication protocol, \nleverages this mechanism to co\u00adordinate the distributed upgrade [29]. The authors observe, however, that \ncertain communication patterns used in prac\u00adtice, such as one-way or asynchronous messages, prevent Eternal \nfrom enforcing the quiescence needed for upgrading the CORBA objects that receive these messages. The \nConic system [14] upgrades component-based sys\u00adtems through architectural recon.gurations (i.e., changing \ncomponents and connectors) and can achieve quiescence if each component provides a minimal control API: \npassi\u00advate, assert(active/passive), activate, link, unlink. Conic de\u00adtermines the correct sequence of \ncontrol API calls required when upgrading a component (e.g., passivating all its in\u00adbound nodes). These \nprinciples are re.ected in modern com\u00adponent frameworks such as R-OSGi, which upgrade a com\u00adponent along \nwith the transitive closure of its inbound de\u00adpendencies [24].  In the absence of fault-tolerance mechanisms \nor control APIs, the PODUS system establishes simple rules for co\u00adordinating a distributed-system upgrade, \nsuch as upgrad\u00ading servers before their clients [26]. This approach can be extended to systems that communicate \nacross multiple ad\u00administrative domains using remote procedure calls (RPC), which consist of synchronous \nrequest-and-reply message ex\u00adchanges. Instead of strictly enforcing the order of local up\u00adgrades, the \nUpstart system [1] enables a mixed-version op\u00aderating mode by providing simulation objects, which im\u00adplement \nthe interfaces of past and future versions. This ap\u00adproach requires disallowing some incompatible invocations \nduring the distributed-system upgrade. We previously developed the Imago system [10], which upgrades \ndistributed systems atomically end-to-end, and we showed that this approach improves the dependability \nof on\u00adline upgrades. In particular, atomicity prevents the mixed\u00adversion races introduced in this paper. \nIn large-scale dis\u00adtributed systems, which often span multiple administrative domains, we must reason \nabout the impact of relaxing the atomicity guarantees on system dependability. Industry best-practices \nfor online upgrade. Prior research suggests that there is a tension between between the up\u00adgrade atomicity \nand the system availability during the up\u00adgrade. System administrators sometimes favor the atomicity, \nby upgrading inter-dependent components together, during windows of planned downtime [9], or by placing \nthe old ver\u00adsion in a read-only mode during the upgrade. However, many enterprises can no longer afford \nthe high cost of downtime and must upgrade their systems online, without constraining the live workload \n[6, 22]. Industry best-practices recommend rolling upgrades, which upgrade-and-reboot each node in a \nwave rolling through the cluster [5, 18]. A rolling upgrade avoids downtime and imposes very little capacity \nloss, but it requires the old and new versions to interact with each other in a compatible manner. Moreover, \nnew features intro\u00adduced by an upgrade sometimes require the system operators to undergo a lengthy re-training \nprocess, which mandates a gradual deployment of the new version at different sites [9]. In such cases, \nthe enterprise application will include a mix of versions that operate concurrently at different installation \nsites, without placing any site in a read-only mode and with\u00adout allowing state divergence. These requirements \nhave motivated the introduction of several commercial products for synchronizing the persis\u00adtent state \nof two versions [6] and for performing rolling up\u00adgrades [16, 21]. However, these commercial products \npro\u00advide no way of determining if the interactions between mixed versions are safe and leave these concerns \nto the ap\u00adplication developers. Moreover, rolling upgrades can lead to mixed-version races [23]. Dependability \nof online-upgrade techniques. Evaluations of the previous upgrade mechanisms typically focus on the range \nof updates (i.e., the types of changes supported) and on the overhead imposed, rather than on the upgrade \nde\u00adpendability. Field studies [2, 20], surveys [7, 19], fault injec\u00adtion [10, 19] and direct experimentation \n[7, 31], have been used to assess the effectiveness of previous approaches in reducing the number of \nupgrade failures. Beattie et al. [2] analyze the security patches released between 1999 2001 and recorded \nin a vendor-independent database, and they .nd that software defects were dis\u00adcovered in 18% of these \npatches. Oppenheimer et al. [20] study the failures recorded by three large-scale Inter\u00adnet services, \nand they report that 4.6 10 component fail\u00adures and 0.7 6 system-wide failures occur each month, mostly \nduring regular maintenance activities. Oliveira et al. [19] present a survey of 51 database administrators, \nwho report eight classes of faults: deployment, performance, general-structure, DBMS, access-privilege, \nspace, general\u00admaintenance, and hardware. Crameri et al. [7] present a sim\u00adilar survey, of 50 system \nadministrators, who report that the average and maximum failure rates for upgrades, in their infrastructures, \nare 8.6% and 50%, respectively. We previ\u00adously developed Ecotopia [11], a framework for scheduling change-management \noperations in complex service-oriented architectures (SOA) by asking what-if questions about the impact \nof operations that span multiple administrative do\u00admains. Zheng et al. [31] propose running experiments \nwith different con.gurations, in a virtualized data center, in or\u00adder to reduce the cost of answering \nwhat-if questions. We introduced an upgrade-centric fault model [10], with four fault types, and proposed \nbenchmarking the dependability of online-upgrade techniques through fault-injection experi\u00adments driven \nby our fault model. To the best of our knowledge, ours is the .rst descrip\u00adtion of mixed-version races, \na new kind of race condition that a rolling upgrade can expose in a large-scale distributed system spanning \nmultiple administrative domains. We there\u00adfore take a different approach than the prior work. Instead \nof preventing mixed-version races through a new technique which might be infeasible under the realistic \nassumptions of the systems that we target we present the best possible al\u00adternative, risk assessment. \nUnlike the previous approaches for evaluating the dependability of online upgrades, our risk model does \nnot rely on .eld or experimental data. We make use of system parameters and testing results that are \nread\u00adily available to the developers and administrators. By quan\u00adtifying the trade-off between upgrading \nin the presence of mixed-version races and delaying an upgrade that corrects known software defects, \nthis work can help upgrade admin\u00adistrators make informed decisions regarding whether to up\u00adgrade or not \nto upgrade.  3. Mixed-version races Rolling upgrades, which gradually upgrade each node in the cluster, \nare widely believed to reduce the risks of upgrading because failures are localized and might not affect \nthe entire distributed system [9, 21]. However, they also create states with mixed versions, which expose \nthe system to a new type of race condition, which we call mixed-version race. Mixed-version races occur \nin systems that span multiple administrative domains, where a consistent upgrade sched\u00adule cannot be \nenforced. Asynchronous message exchanges across domain boundaries potentially lead to a situation where \na callback from the new version is processed by the old version on a different tier of the application. \nWe illustrate mixed-version races with an online banking example. Banks are starting to employ online \nupgrades [6], in spite of the inherent risks of data inconsistency associated with current upgrading \napproaches. We consider an online banking application that uses the AJAX style of web pro\u00adgramming, where \npart of the application code is executed at client-side, in multiple web browsers. The following sequence \nof events leads to a mixed\u00adversion race (see also Figure 1): 1. The bank initiates a rolling upgrade \nof its infrastructure. The rolling upgrade places the system in a state where two versions (old and new) \nco-exist in the front-end. Both versions handle client requests, during the upgrade. 2. The bank customer \nstarts an online banking session. Her browser sends an initial request to load the front page of the \nbanking application. 3. The request arrives at a front-end server that was al\u00adready upgraded and that \nruns the new version. The user s browser loads the new version of the web page, which includes both static \nHTML markup and Javascript code. This code implements the client side functionality of the application. \n 4. The user initiates an operation that requires additional communication with the server. Rather than \nreload\u00ading an entire page, the client-side code issues an XMLHttpRequest callback into the server, to \nreload part of the banking page that is currently displayed. 5. The asynchronous callback, which was \nissued by the new version of the client-side code, arrives at a server that was not yet upgraded.The \nold version of the server-side code does not know how to handle the request and throws an exception (in \nthe best case) or handles the request incorrectly (in the worst case). 6. When the user receives the \nreply, she may or may not notice that an error has occurred.  Client (browser) Web 2.0 front-end Start \nrolling upgrade Initial request New version AJAX callback Old version Exception / ?? Error Inconsistency \nFigure 1. Mixed-version race. If the web front-end includes only a few servers, which can be upgraded \nquickly, the window of vulnerability to mixed-version races is small. However, these race conditions \noccur frequently during rolling upgrades of large Internet systems, such as Facebook [23]. For banking \napplications, the inconsistencies that may result can have severe consequences, including .nancial losses. \nFor example, if the code that checks whether to allow a cash transfer is moved from the server-side to \nthe client\u00adside (e.g., in order to push some computational load to the clients), a mixed-version race \ncan lead to this code executing twice. In this situation, a request to debit $100 from a bank account \nwould subtract $200 from the user s account balance because of the double invocation of the debit operation: \nonce from the browser and once from the server. In 1994, a similar upgrade of Chemical Bank s data center \naffected more than 100,000 customers over the course of a single day. Each ATM withdrawal was deducted \ntwice from the customer s account, adding up to a $15M loss. More\u00adover, some checks bounced, which made \nChemical Bank customers incur additional fees at other .nancial institutions. The upgrade changed a single \nline of code in the server-side software [12]. 3.1 Key technical challenges The mixed-version race described \nabove could have been avoided by extending the load balancer, which dispatches client requests to the \nfront-end servers, to track the progress of the rolling upgrade and to determine the appropriate server-side \nversion for each request. This approach would require adding signi.cant complexity and processing delays \nto a key component of the enterprise infrastructure, which is essential for avoiding performance bottlenecks. \nAlterna\u00adtively, the servers could wait until the end of the rolling up\u00adgrade before starting to send \nthe new version of the client\u00adside Javascript code. In a large enterprise infrastructure, where some \nservers are likely to become unresponsive dur\u00ading the upgrade either because they have failed or because \nthey are slow to upgrade it is dif.cult to determine reli\u00adably when the rolling upgrade has completed. \nPrior anec\u00addotal evidence, from the recorded occurrences of mixed\u00adversion races [12, 23], con.rms that \nthese conditions cannot be avoided easily.  There are three technical challenges that render mixed\u00adversion \nraces hard to address using existing techniques: Non-atomic upgrades. A rolling upgrade is not an atomic \noperation, and it places the system in a state with mixed versions. In large-scale infrastructures, some \nnodes crash during the upgrade and other nodes need a long time to complete the upgrade. Moreover, some \nup\u00adgrades fail silently. In such an environment, the end of the rolling upgrade is not always easy to \ndetect because it is hard to distinguish a node that has crashed from a node that is slow. Because the \nupgrade is a long-running pro\u00adcedure, often enterprises cannot delay exposing the new functionality to \nthe other tiers of the application.  Asynchronous messaging. Asynchronous communica\u00adtion is used, for \nperformance reasons, in all the tiers of modern enterprise systems. For instance, in the front\u00adend AJAX \napplications receive asynchronous callbacks from the client-side code, in the middle tier appli\u00adcation \nservers use message-oriented middleware (e.g., Amazon s Simple Queue Service, XMPP), and in the back-end \nstorage systems use asynchronous I/O. Asyn\u00adchronous communication is considered by some experts a better \nparadigm for building distributed systems than synchronous RPC [30].  Versions determined dynamically. \nWhen asynchronous message exchanges occur concurrently with long\u00adrunning rolling upgrades, the code versions \ninvolved in the exchange are determined dynamically (e.g., at the time of the .rst invocation). Upgrades \nperformed in the middle of the message exchange expose the system to mixed-version races.  As online-upgrade \ntechniques are increasingly adopted by contemporary enterprise application, similar problems will become \nwidespread. Distributed enterprise systems have been using heterogeneous, off-the-shelf components for \na long time. With the advent of cloud computing, these third-party components are also provisioned and \nmanaged by third parties, such as public cloud infrastructures (e.g., the Amazon Web Services). These \nenterprise systems span multiple administrative domains and no longer control the upgrading schedule \nfor all their tiers. Cloud-based resources (e.g., storage objects, message queues) are upgraded on schedules \nset by the service providers, and upgrades may occur during an asynchronous message exchange between \ntiers. In other words, third-party provisioning, despite all its bene.ts, will likely introduce the risk \nof mixed-version races for a wide range of applications.  4. Upgrade-risk model Our model answers the \nquestion is it riskier to upgrade or not to upgrade? By combining the likelihood of mixed\u00adversion races \nwith the severity of the resulting errors and inconsistencies which characterizes the impact of potential \nupgrade failures we estimate the risk of upgrading.We then compare this result with the risk of not upgrading, \nobtained from the severity of the original bugs or feature requests that are addressed by the upgrade. \nIn other words, we estimate the expected impacts of the two alternative decisions to upgrade or not to \nupgrade over the typical time frame of a rolling upgrade. 4.1 Assumptions Our approach is predicated \nby four assumptions: We assume that the software developers and system ad\u00administrators use a uniform \nlabeling system, which covers the severity of known bugs, the criticality of feature ad\u00addition/change/removal \nrequests, as well as the severity of the inconsistencies that might occur during an upgrade.  We assume \nthat a thorough integration-testing procedure is in place, and that it can be extended to the system \nstates with mixed versions.  We assume that the atomic unit of upgrade is the host, i.e. that all the \ncollocated components that are upgraded con\u00adcurrently are exposed to the users after the host reboots. \n We assume that, in most cases, developers and admin\u00adistrators cannot estimate accurately the likelihood \nof ex\u00adposing known bugs or of invoking new callbacks or the variability of upgrade durations for each \nhost.  Mixed-version testing is done using only two hosts, one run\u00adning the new version and the other \nrunning the old version, and triggers the worst case scenario leading to a mixed\u00adversion race: a callback \nfrom the new version arriving at the old version, as described in Section 3. The inconsistencies discovered \nin this manner are assigned their own severity levels, and the uniform labeling system ensures that they \nare comparable with the impact of known bugs. The complexity and duration of this testing procedure de\u00adpends \non the differences between the old and new versions, but not on the number of potential mixed-version \nstates cre\u00adated at runtime. For example, out of the 352 servers sup\u00adporting Wikipedia, one of the ten \nmost popular sites on the Internet, 120 hosts are located on the front end and can be accessed by the \nusers.1 This could lead to 2120 1E36 (one undecillion) possible version combinations during a rolling \nupgrade similar to the one described in Section 3. Instead, we test only one combination. We can extend \nthis testing approach to upgrade scenarios where n mixed versions must coexist (with n> 2)or where m \ntiers of the distributed system are affected by the upgrade. In the .rst case, we have to consider all \nthe cases where a version can invoke an older version, and we must test n 1 = n(n-1) mixed-version combinations. \nIn the second 22 1 The information on Wikipedia dates from April 2009.  case, we must consider all the \ncases where the new version invokes the old version in the next tier, and we must test (m - 1)2m-2 combinations. \nIn practice, however, integration testing is not likely to be affected by combinatorial explosion because \nit is uncom\u00admon to support a large number of mixed versions and be\u00adcause distributed systems have only \na few tiers that span multiple administrative domains (e.g., for m =4 we have to test only 12 combinations). \nMoreover, because during a rolling upgrade each individual host is upgraded in an atomic fashion by disconnecting, \nupgrading, rebooting and reinte\u00adgrating the host into the distributed system the number of collocated \ncomponents that must be upgraded does not af\u00adfect the complexity of the testing procedure. In this paper, \nwe focus on the most common situation, where the system spans two administrative domains and includes \nonly two ver\u00adsions during the rolling upgrade: the old version and the new version. To enhance the usability \nof our analytical model, we do not use continuous probability values for expressing the like\u00adlihood of \nexposing bugs or mixed-version inconsistencies, because these values are dif.cult to estimate accurately. \nIn\u00adstead, we use a discrete probability measure, with three pos\u00adsible values: low, medium, and high. \nSimilarly, we require system administrators to specify the duration of single-host upgrades in the form \nof a triangular distribution, with an ex\u00adpected value and lower/upper bounds. In consequence, the outputs \nfrom our model are discrete values as well, which simpli.es the comparison between the impacts of upgrading \nand of not upgrading. Working with discrete values allows administrators to capture the partial information \navailable about the system and to use it for deciding when and how to execute an upgrade.  4.2 Analytical \nrisk model Table 1 describes the input and output parameters of our risk model. Ncall, Nbug, c, S(Ik) \nand S(Bk),are deter\u00admined through integration testing. Pcall(k) and Pbug(k) are workload-dependent metrics, \nwhich are estimated from test\u00ading results and from system monitoring logs. U, t , tlo and thi are provided \nby the system administrators. We assess: Nbug . Pr[Bk] \u00b7 S(Bk) Riskno upgrade = k=1 Nbug \u00b7 max S Ncall \n. Pr[Ik] \u00b7 S(Ik) Riskupgrade = k=1 Ncall \u00b7 max S , which combine the likelihoods of inconsistencies \nand bug manifestations with the corresponding severity levels. We normalize the risk values with respect \nto max S in order to keep them comparable across different severity scales. The inputs Pcall(k) and Pbug \n(k) can take one of the val\u00adues plo, pmed or phi, which correspond to low, medium and Model inputs U \nNumber of servers upgraded. t Mean upgrade duration for a single host. tlo, thi Lower and upper bounds \nfor the upgrade duration. Average number of callbacks per request issued by c the new version of the \nclient-side code. Number of callbacks that can trigger a mixed-Ncall version race, because they do not \nexist in the old version or because they have different semantics. Nbug Number of bugs addressed by the \nupgrade. Severity of event E (e.g., manifestation of bugs S(E) B1, B2 ... BNbug or of mixed-version inconsisten\u00adcies \nI1, I2 ... INcall ). Probability of issuing the callback that leads to Pcall(k) mixed-version inconsistency \nIk. Pbug(k) Probability that a request will expose bug Bk. Model outputs The risk associated with decision \nD . RiskD {upgrade, no upgrade}. Because the risk of inconsistency varies during the upgrade, we estimate \nthe average risk, Riskupgrade, and the maximum risk, max(Riskupgrade). Other notations Pr[E] Probability \nof event E. plo/med/hi Discrete probability values: plo <pmed <phi. ti Time needed to upgrade server \ni. ti Time when the .rst i servers have been upgraded. Prace(i) Probability of mixed-version races at \nti. Table 1. Summary of notations. high probabilities. These discrete levels are easier to spec\u00adify \nthan precise probability values. In our analysis, we do not attempt to assign placeholder values to these \nprobabil\u00adity levels, and instead we derive the risk symbolically. To avoid counter-intuitive artifacts \nin the computation, we con\u00adsider that plo, pmed or phi correspond to a linear scale, i.e., pmed =2plo \nand phi =3plo. The probability of exposing a bug during normal opera\u00adtion is unaffected by the upgrade \nprocess and remains con\u00adstant: Pr[Bk]= Pbug (k) .{plo,pmed,phi}.The sever\u00adity levels S(Bk) and S(Ik) \nalso remain constant during the rolling upgrade. The probability of exposing an inconsistency depends \non both the workload and the progress of the rolling upgrade. An inconsistency will occur only if the \nclient issues a new callback, which does not exist or has different semantics in the old version (event \nE1) and if this callback arrives at a server that has not yet been upgraded and continues to run the \nold version (event E2, which corresponds to a mixed\u00adversion race). After upgrading the ith server: Pr[Ik]= \nPr[Ik|E1] \u00b7 Pr[E1]= Pr[E2] \u00b7 Pr[E1]= = Prace(i) \u00b7 Pcall(k)  0 20 40 60 80 100 0 20 40 60 80 100 Time \nTime (a) Progression of the rolling upgrade. (b) The likelihood of triggering an inconsistency, Prace(i) \n\u00b7 Pcall, varies during the rolling upgrade. The likelihood of exposing a known bug, Pbug, remains constant. \n Figure 2. Parameters of the risk model. The probability of mixed-version races Prace varies dur\u00ading \nthe upgrade. We note t1,t2 ...tU the upgrade durations for servers 1, 2 ...U. The upgrade of the ith \nserver will then .i be completed at time ti = tk, as shown in Figure 2a. k=1 We do not assume that durations \nti are known precisely when planning the upgrade. However, we consider that sys\u00adtem administrators are \nable to estimate empirically the ex\u00adpected value of the time needed to upgrade a single host (t), as \nwell as the upper and lower limits (thi and tlo). We use a triangular distribution, characterized by \nthese parameters, to estimate the upgrade timings. Prace depends on two events: sending the initial request \nto a server running the new version (event E2.1, analogous to step 2 in Figure 1), and sending any of \nthe subsequent callbacks to the old version (event E2.2, analogous to step 4 in Figure 1): Prace(i)= \nPr[E2.1 at ti] \u00b7 Pr[E2.2 at ti] i Pr[E2.1 at ti]= U Pr[E2.2 at ti]=1 - Pr[\u00acE2.2 at ti] Event \u00acE2.2 corresponds \nto the scenario where all c call\u00adbacks are handled by the new version: c Pr[E2.2 at ti]=1 - i U cPrace(i)= \ni \u00b7 1 - i (1) UU We compute the likelihood of exposing bugs or mixed\u00adversion inconsistencies by combining \nthe probabilities of the independent events that lead to these circumstances, as shown in Figure 3. After \nthe upgrade of the ith server, the risks of upgrading and of not upgrading are: = Riskno upgrade Riskupgrade(i)= \nNbug Pbug (k) \u00b7 S(Bk) k=1 (2) Nbug \u00b7 max S c ii \u00b7 1 -\u00b7 UU Ncall Pcall(k) \u00b7 S(Ik) k=1 \u00b7 Ncall \u00b7 max S \nThe risks of upgrading and of not upgrading are functions of the discrete probability values plo, pmed,and \nphi.The range of possible risk values is RiskD . [0, 3plo].We consider that the risk is high when RiskD \n> 2plo,medium when RiskD . (plo, 2plo], and low when RiskD = plo (see Figure 4). The average risk of \nupgrading is: U ti \u00b7 Riskupgrade(i) i=1 = (3)Riskupgrade tU New callback 1: Prace =0 at times t0 and \ntU , because the .rst and second terms of the equation are null, respectively. In other words, before \nand after the rolling upgrade the probability of expos\u00ading an inconsistency is 0, because all servers \nare executing the same version of the software. Figure 2b illustrates the  evolution of Prace during \nthe rolling upgrade. Figure 3. Events leading to a mixed-version inconsistency. Figure 4. Discrete risk \nvalues. Low risk Medium risk High risk Risk  0 plo 2plo 3plo This formula does not have a closed-form \nexpression in terms of t, tlo and thi. Instead, we can estimate this risk through a Monte Carlo simulation, \nby randomly generating multiple sets of ti input terms and by computing the mean of the resulting risks. \nUsing this approach, we can also compute the 95% con.dence interval for the average risk of upgrading, \nwhich indicates the precision of our estimation. The maximum risk of upgrading, however, can be com\u00adputed \nusing a simple, closed-form expression. We compute this maximum by approximating the probability of sending \na new callback to the old version, from Equation 1, with a continuous function P race(x) and by differentiating \nthis function: c xx Prace(x)= \u00b7 1 - UU dP race(x) =0 . dx c 1(c +1) \u00b7 x - 0 =0 . Uc+1 U 1 x0 = U c c \n+1 The maximum probability of sending new callbacks to the old version is:2 11 c max(Prace)= \u00b7 1 - (4) \nc +1 c +1 max(Prace) depends only on c, and its asymptotic bound is 1. However, for typical values of \nc, its value is much lower. If the new version issues up to 12 callbacks into the server, the maximum \nvalues of this probability are: c 123456 max(Prace) 0.25 0.38 0.47 0.53 0.58 0.62 c 7 8 9 10 11 12 max(Prace) \n0.65 0.68 0.70 0.72 0.73 0.75 The maximum risk of upgrading is: max(Riskupgrade)= max(Prace) \u00b7 Pcall \n\u00b7 Ncall Pcall(k) \u00b7 S(Ik) k=1 \u00b7 (5) Ncall \u00b7 max S We have created an online tool that automates these \ncal\u00adculations, available at http://orchestrate.cs.vt.edu: 8080/examples/servlets/update.html. 2 This \nformula computes an upper bound, because the stair function Prace(x) = P race(x). However, the exact \nmaximum could be computed by determining the time interval when the risk is maximized, i = x0,and introducing \nit in Equation 1.  4.3 Interpretation Our risk model compares the expected impacts of executing an upgrade \nand of putting it on hold. This assessment takes into account the impacts of known bugs in the old version \nand of mixed-version inconsistencies that can arise during the upgrade. We do not consider the impact \nof potential bugs in the new version, which cannot be accurately estimated. The conditional probability \nof producing an inconsis\u00adtency, Prace, varies as the rolling upgrade progresses. Intu\u00aditively, a request \nthat arrives after half of the servers have been upgraded incurs a higher risk of inconsistency than \nre\u00adquests arriving at the beginning or at the end of the upgrade. Therefore, the decision whether to \nupgrade or not can take into account either the maximum or the average risk over the duration of the \nrolling upgrade. Most system adminis\u00adtrator will base this decision on the average risk, which cor\u00adresponds \nto the intuitive notion of expected impact of the upgrade. However, mission-critical systems, where each \nre\u00adquest can have a severe impact (e.g., physical injury or .\u00adnancial loss), will consider the maximum \nrisk of upgrading. While we consider that Pbug and Pcall remain constant for the duration of the upgrade, \nthese parameters are likely to be dependent on the system s workload. For example, on different days \nof the week the load might shift between dif\u00adferent features provided by the system, exercising different \ncode paths in the old and new software versions. This will change the probabilities of exposing bugs \nand inconsisten\u00adcies. If the system administrators can estimate the values for Pbug and Pcall during \ndifferent time windows, based on test\u00ading results and knowledge of past workloads, our model will help \nthem determine the best time for performing the up\u00adgrade. Alternatively, the risk assessment may suggest \nthat an of.ine upgrade, executed during a planned maintenance window, is more appropriate for the system. \n 5. Model validation Complete data on real-world upgrade failures is scarce and hard to obtain, due \nto the sensitivity of this subject. We are aware of two real-world examples of upgrade failures that \ncan be traced to mixed-version races [12, 23]. Because, to the best of our knowledge, this race condition \nhas not been characterized before, we currently lack suf.cient data to de\u00adsign statistically-signi.cant \nexperiments for evaluating the risk of upgrading in the presence of mixed-version races. Moreover, our \nanalytical model assesses the perceived im\u00adpact of upgrades, which cannot be measured directly. In par\u00adticular, \nthe severity of a bug or of a mixed-version incon\u00adsistency is a qualitative measure that re.ects the \ndevelopers or administrators perception of the impact resulting from the manifestation of these bugs/inconsistencies. \nThis apri\u00adori perception of impact is dif.cult to correlate with a mea\u00adsurable quantity. We conduct a \nqualitative evaluation of our risk model, seeking to answer the question: Is this risk model use\u00adful? \nBy walking through three hypothetical but realistic scenarios of online upgrades, we focus on the time \nwhen a system administrator must decide whether to upgrade or not and on the information available for \nmaking this deci\u00adsion. Two scenarios focus on mission-critical systems (on\u00adline banking, in Section 5.1, \nand foreign exchange, in Sec\u00adtion 5.3) and one focuses on a large-scale system that is not mission critical \n(a social networking site, in Section 5.2). We show that using our analytical model leads to better de\u00adcisions \nthan those suggested by intuition alone. These sce\u00adnarios demonstrate that the model provides additional \ninfor\u00admation, not available through other means, for making the upgrade-or-not decision. Our risk model \ncan systematically inform an upgrade administrator, or any other stakeholders in these applications, \nwhether an online upgrade is appropri\u00adate in their environment.  \u00a75.1 \u00a75.2 \u00a75.3 U 10 100 100 t 1 min \n1 min 2 min tlo 0 min 0 min 0 min thi 6 min 2 min 7 min Pcall phi phi pmed c 6 2 1 S(I) 3 5 3 Pbug plo \npmed phi S(B) 5 5 2 In this paper, we do not seek to answer the question: How accurate is the additional \ninformation provided by the risk model? In the future, we plan to use the model in a produc\u00adtion system, \nfor an extended period of time, and to report on this experience after observing real upgrade failures. \nWe be\u00adlieve that such practical experience is essential for providing a complete validation of our proposed \napproach. 5.1 Upgrade #1: Online banking Imagine that a bug in the Web interface of an online banking \napplication (such as the one described in Section 3) was reported and corrected. Speci.cally, in the \nold version, an edit box for entering fund transfer information accepts all alpha-numeric characters \nrather than restricting user input to numbers only. The alphanumeric characters are needed in order to \nenter a currency speci.cation. However, this can expose the site to a SQL injection attack, which is \none of the top 25 programming errors that lead to security vulnerabilities [8]. The new version of the \nWeb interface uses a radio box to specify the currency and a numbers\u00adonly text box. Because this bug \naf.icts those users that use online brokerage services, who tend to constitute an important segment of \nthe customers, the bug is assigned the severity level 5 (highest). Through integration testing, it has \nbeen determined that replacing the upgrade can lead to an inconsistency resulting from a mixed-version \nrace. Because the old version of the server-side code expects a single parameter, it will disregard the \ncurrency speci.cation and will assume that the sum is speci.ed in US dollars. This can cause signi.cant \nproblems when the site is used by customers with accounts in foreign currencies. This potential inconsistency \nis assigned severity level 3. Because the impact of SQL injection attacks outweighs the severity of mixed-version \ninconsistencies, intuition sug\u00adgests that the upgrade should be deployed as soon as pos\u00adsible. However, \nthe most likely impacts of these two events depend on other parameters as well. Imagine that the prob\u00adability \nof being the target of an attack is Pbug = plo, while Low Medium Medium Riskno upgrade Medium Medium \nLow max(Riskupgrade) Low Low Riskupgrade Table 2. Risk parameters in the three upgrade scenarios. most \nof the callbacks issued by the new version use the new radio box parameter (Pcall = phi), because the \nmajority of the bank s customers have accounts in a foreign currency (the remaining parameters are summarized \nin Table 2). Using our online tool, we compute that the risk of not upgrading is low, while the maximum \nrisk of upgrading is medium. Because online banking is a mission-critical ap\u00adplication, we do not take \nthe mean risk of upgrading into consideration. Contrary to our intuition, the analytical model predicts \nthat it is better to upgrade during a planned mainte\u00adnance window than online. Alternatively, an online \nupgrade may be appropriate during a time window when most of the customers who access the system have \naccounts in dollars.  5.2 Upgrade #2: Social networking site The Web interface of a social-networking \nsite is not rendered correctly when accessed using an old version of some Web browser. Speci.cally, a \npush button that allows users to log in appears disabled. This happens because the browser in question \nuses an obsolete version of the DOM tree. The usage monitoring service in place indicates that a user \nwill try to access the Web site using this particular version of the browser with probability Pbug = \npmed. However, the bug is assigned severity level 5 because it causes the site to be unavailable whenever \nit occurs, and high availability is a top priority for the social networking site. After log-in, the \nold version of the server sends (via AJAX callbacks) more information than the user needs. The client-side \ncode, running in the user s browser, .lters this information. The new version, which .xes the DOM bug, \nchanges the way elements are displayed and moves the .l\u00adtering to the server side. Whenever a new-version \ncallback is processed by an old-version server, some other user s private information is leaked and displayed \nin the browser (Pcall = phi). This potential privacy breach is also assigned severity level 5.  Our \nintuition suggests that an online upgrade should be avoided, because, while the bug and the mixed-version \nin\u00adconsistency are equally severe, the bug does not manifest frequently. However, as social networking \nis not a mission critical application, we compare the risk of not upgrading (medium) with the average \nrisk of upgrading (low). In this case, the analytical risk model predicts that an online up\u00adgrade represents \nthe best course of action.  5.3 Upgrade #3: Foreign exchange system Multiple online banking applications \nrely on a cloud-based service that provides foreign-currency exchange rates. This cloud-based service \nis provisioned and upgraded by a third party. The cloud service can support multiple versions of the \ncommunication protocol, and the version in use is es\u00adtablished at the start of the message exchange. \nThe service uses a publish-subscribe infrastructure. When banking appli\u00adcations subscribe to the service, \nthey receive asynchronous messages that encapsulate Java objects. The new version of the service is provided \nas an extension of the old service; the corresponding objects instantiate a subclass of the old version \ns data type. A certain bank requires the new version of the service in order to provide a new feature. \nSpeci.cally, in addition to the current exchange rate, the new version also speci.es the time when this \nrate was valid. This information is useful for customers who engage in money market speculation. This \nmissing feature is assigned severity level 2. A sizable subsegment of the system s users, are estimated \nto wish the feature added (Pbug = phi). However, an online upgrade can expose a mixed-version race. If \nthe bank starts a rolling upgrade, to add the new fea\u00adture in its application code, the service publisher \nwill begin broadcasting messages belonging to the new version. Some messages will be received by servers \nstill running the old version (Pcall = pmed). When these servers unmarshall the message and determine \nthat the object s class de.nition is unknown, they will throw an exception. This renders the ser\u00advice \nunavailable for servers that have not yet been upgraded. This partial outage is assigned severity level \n3. The missing feature and the partial outage have different likelihoods and different severity levels. \nIt is, therefore, dif\u00ad.cult to make a decision based only on intuition. Our online tool shows that the \nrisk of upgrading is always lower than the risk of not upgrading, and recommends an online up\u00adgrade. \nOur analytical model provides a systematic approach for deciding whether to upgrade or not to upgrade. \n 6. Discussion Our risk model can determine, analytically, the best time window for performing an upgrade. \nAnecdotal evidence, and recent empirical studies, indeed suggest that some days might be better than \nothers for implementing changes and \u00b4 upgrades. For example, Sliwerski et al. [27] study the ver\u00adsion \nhistory of several open-source systems and discover a temporal correlation between the code changes that \nrequire subsequent .xes and the weekday when these changes are implemented. According to this study, \nthe best days for .x\u00ading software bugs are Tuesdays (with Fridays and Satur\u00addays being the riskiest days). \nInterestingly, Windows [17] and Facebook [23] also deploy their upgrades on Tuesdays. Recent advances \nin low-overhead dynamic analysis [4, 15] have made it possible to monitor systems in their de\u00adployment \nenvironments in order to assess the probability that certain bugs will be exposed. These techniques provide \nthe tools for evaluating the risk of not upgrading a system that includes known software defects (Riskno \nupgrade). However, the leading cause of failure for enterprise up\u00adgrades are errors in the upgrade procedure \n(e.g., specify\u00ading wrong service locations, introducing shared-library con\u00ad.icts, creating database-schema \nmismatches), rather than software defects (e.g., bugs in the new version) [7, 10]. Moreover, these failures \nare often hard to replicate outside of the deployment environment, because they correspond to broken \ndependencies and their manifestation is workload\u00addependent. Unlike for software defects, we currently \nlack a comprehensive corpus of realistic faults that commonly occur during online upgrades and the conditions \nthat trig\u00adger them. This makes it challenging to assess the terms of the risk of upgrading (Riskupgrade), \nsuch as the severity of mixed-version inconsistencies. In the future, we plan to es\u00adtablish a collaborative \nrepository of data on upgrade failures, collected from multiple industry sources. Similar reposito\u00adries, \nsuch as the common programming errors that lead to security vulnerabilities [8], have had a great impact \non the practice of programming, and our paper emphasizes the util\u00adity of an upgrade-centric fault repository. \nDuring enterprise-system upgrades, the mixed-version states are usually an artifact of the upgrade approach \n(e.g., rolling upgrades). However, sometimes mixed versions rep\u00adresent a user requirement. For example, \nwhen the opera\u00adtors of an enterprise system must undergo an extensive re\u00adtraining to use the new version \nof system, the upgrade must be deployed gradually [9]. These user requirements add to the complexity \nof impact assessment for online upgrades, by extending the time when the system is vulnerable to mixed \nversion races and by increasing the number of program ver\u00adsions that co-exist in the system. Mixed-version \nraces are an example of behavior that emerges at runtime and that cannot be tested, exhaustively, before \nthe system is deployed. Large-scale systems that un\u00addergo runtime evolution (e.g., online software-upgrades, \nar\u00adchitectural recon.gurations) must cope with changes imple\u00admented during the system execution. These \nchanges inter\u00adact with the workload in ways that may be unpredictable at design-time. Reasoning about \nsuch emerging behavior is dif.cult because previously-established system invariants do not hold, changes \nare implemented by both human and soft\u00adware agents, hidden dependencies in the environment can induce \nupgrade failures, and externally-imposed deadlines might affect the outcome. This paper represents a \n.rst step toward a systematic approach for validating such runtime\u00ademerging behaviors.  7. Conclusion \nWe describe a new type of race condition that may occur during online upgrades in systems spanning multiple \nad\u00administrative domains and communicating via asynchronous messaging across domain boundaries. The recorded \noccur\u00adrences of such mixed-version races suggest that they can pro\u00adduce severe effects, including .nancial \nloss. Mixed-version races will become widespread in systems relying on cloud\u00adcomputing resources, which \nare provisioned and operated by third-party service providers. We introduce an analytical model and an \nonline tool for comparing the risks of upgrad\u00ading and of not upgrading. This model compares the expected \nimpact of mixed version races with the effects of known bugs in the deployed software. Our model represents \na .rst step toward reasoning about the behavior of system states that emerge in the deployment environment \nand that may be un\u00adpredictable at design-time.  References [1] S. Ajmani, B. Liskov, and L. Shrira. \nModular software upgrades for distributed systems. In European Conference on Object-Oriented Programming, \npages 452 476, Nantes, France, Jul 2006. [2] S. Beattie, S. Arnold, C. Cowan, P. Wagle, and C. Wright. \nTiming the application of security patches for optimal up\u00adtime. In Large Installation System Administration \nConference, pages 233 242, Philadelphia, PA, Nov 2002. [3] T. Bloom. Dynamic Module Replacement in a \nDistributed Programming System. PhD thesis, MIT, 1983. [4] M. Bond, K. Coons, and K. McKinley. Pacer: \nProportional detection of data races. In ACM Conference on Program\u00adming Language Design and Implementation, \nToronto, CA, Jun 2010. [5] E. A. Brewer. Lessons from giant-scale services. IEEE Internet Computing, \n5(4):46 55, Jul/Aug 2001. [6] A. Choi. Online application upgrade using edition-based rede.nition. In \nACM Workshop on Hot Topics in Software Upgrades, Orlando, FL, Oct 2009. [7] O. Crameri, N. Kne.zevi\u00b4c, \nD. Kosti\u00b4c, R. Bianchini, and W. Zwaenepoel. Staged deployment in Mirage, an inte\u00adgrated software upgrade \ntesting and distribution system. In Symposium on Operating Systems Principles, pages 221 236, Stevenson, \nWA, Oct 2007. [8] CWE/SANS. Top 25 most dangerous programming errors. Feb 2010. [9] A. Downing, Oracle \nCorporation. Personal communication, 2008. [10] T. Dumitras\u00b8 and P. Narasimhan. Why do upgrades fail \nand what can we do about it? Toward dependable, online upgrades in enterprise systems. In ACM/IEEE/IFIP \nMiddleware Con\u00adference, pages 349 372, Urbana-Champaign, IL, Nov/Dec 2009. [11] T. Dumitras\u00b8, D. Ros\u00b8u, \nA. Dan, and P. Narasimhan. Eco\u00adtopia: An ecological framework for change management in distributed systems. \nIn C. Gacek, A. Romanovsky, and R. de Lemos, editors, Architecting Dependable Systems IV, pages 262 286. \nSpringer-Verlag, LNCS 4615, 2007. [12] S. Hansell. Glitch makes teller machines take twice what they \ngive. The New York Times, Feb 18 1994. [13] M. Hicks. Dynamic Software Updating. PhD thesis, De\u00adpartment \nof Computer and Information Science, University of Pennsylvania, August 2001. [14] J. Kramer and J. Magee. \nDynamic con.guration for dis\u00adtributed systems. IEEE Transactions on Software Engineer\u00ading, 11(4):424 \n436, 1985. [15] B. Liblit, A. Aiken, A. X. Zheng, and M. I. Jordan. Bug isolation via remote program \nsampling. In ACM Conference on Programming Language Design and Implementation,San Diego, CA, Jun 2003. \n[16] Microsoft Corporation. Perform a rolling upgrade from Windows 2000. TechNet Library, Jan 2005. http://technet.microsoft.com/en-us/library/ \ncc738005(WS.10).aspx. [17] Microsoft Developer Network. Windows Update Agent. http://msdn2.microsoft.com/en-us/library/ \naa387099.aspx. Retrieved on 18 Feb 2008. [18] Of.ce of Government Commerce. Service Transition. Infor\u00admation \nTechnology Infrastructure Library (ITIL). 2007. [19] F. Oliveira, K. Nagaraja, R. Bachwani, R. Bianchini, \nR. P. Martin, and T. D. Nguyen. Understanding and validating database system administration. USENIX Annual \nTechnical Conference, Jun 2006. [20] D. Oppenheimer, A. Ganapathi, and D. A. Patterson. Why do Internet \nservices fail, and what can be done about it? In USENIX Symposium on Internet Technologies and Systems, \nSeattle, WA, Mar 2003. [21] Oracle Corporation. Database rolling upgrade using Data Guard SQL Apply. \nMaximum Availability Architecture White Paper, Dec 2008. http://www.oracle.com/ technology/deploy/availability/pdf/maa_wp_ \n10gr2_rollingupgradebestpractices.pdf. [22] D. Patterson. A simple way to estimate the cost of down\u00adtime. \nIn Large Installation System Administration Conference, pages 185 188, Philadelphia, PA, Nov 2002. [23] \nD. Reiss, Facebook. Personal communication, 2009. [24] J. S. Rellermeyer, M. Duller, and G. Alonso. Consistently \napplying updates to compositions of distributed OSGi mod\u00adules. In ACM Workshop on Hot Topics in Software \nUpgrades, Nashville, Tennessee, Oct 2008. [25] M. Segal. Online software upgrading: new research directions \nand practical considerations. In Computer Software and Ap\u00adplications Conference, pages 977 981, Oxford, \nEngland, Aug 2002.  [26] M. E. Segal and O. Frieder. Dynamically updating distributed software: supporting \nchange in uncertain and mistrustful en\u00advironments. In IEEE Conference on Software Maintenance, pages \n254 261, Oct 1989. [27] J. \u00b4 Sliwerski, T. Zimmermann, and A. Zeller. When do changes induce .xes? On \nFridays. In International Workshop on Min\u00ading Software Repositories (MSR), Saint Louis, Missouri, May \n2005. [28] E. B. Swanson. The dimensions of maintenance. In Interna\u00adtional Conference on Software Engineering, \npages 492 497, San Francisco, CA, 1976. [29] L. Tewksbury, L. Moser, and M. Melliar-Smith. Live upgrades \nof CORBA applications using object replication. In Interna\u00adtional Conference on Software Maintenance, \npages 488 497, Florence, Italy, Nov 2001. [30] S. Vinoski. Convenience over correctness. IEEE Internet \nComputing, 12(4):89 92, 2008. [31] W. Zheng, R. Bianchini, G. J. Janakiraman, J. R. Santos, and Y. Turner. \nJustrunit: Experiment-based management of virtu\u00adalized data centers. In USENIX Annual Technical Conference, \nSan Diego, CA, Jun 2009.   \n\t\t\t", "proc_id": "1869459", "abstract": "<p>Online software upgrades are often plagued by runtime behaviors that are poorly understood and difficult to ascertain. For example, the interactions among multiple versions of the software expose the system to race conditions that can introduce latent errors or data corruption. Moreover, industry trends suggest that online upgrades are currently needed in large-scale enterprise systems, which often span multiple administrative domains (e.g., Web 2.0 applications that rely on AJAX client-side code or systems that lease cloud-computing resources). In such systems, the enterprise does not control all the tiers of the system and cannot coordinate the upgrade process, making existing techniques inadequate to prevent mixed-version races. In this paper, we present an analytical framework for impact assessment, which allows system administrators to directly compare the risk of following an online-upgrade plan with the risk of delaying or canceling the upgrade. We also describe an executable model that implements our formal impact assessment and enables a systematic approach for deciding whether an online upgrade is appropriate. Our model provides a method of last resort for avoiding undesirable program behaviors, in situations where mixed-version races cannot be avoided through other technical means.</p>", "authors": [{"name": "Tudor Dumitras", "author_profile_id": "81310501860", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2354176", "email_address": "", "orcid_id": ""}, {"name": "Priya Narasimhan", "author_profile_id": "81100599670", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P2354177", "email_address": "", "orcid_id": ""}, {"name": "Eli Tilevich", "author_profile_id": "81100650102", "affiliation": "Virginia Tech, Blacksburg, VA, USA", "person_id": "P2354178", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869530", "year": "2010", "article_id": "1869530", "conference": "OOPSLA", "title": "To upgrade or not to upgrade: impact of online upgrades across multiple administrative domains", "url": "http://dl.acm.org/citation.cfm?id=1869530"}