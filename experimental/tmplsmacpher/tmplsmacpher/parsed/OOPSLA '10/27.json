{"article_publication_date": "10-17-2010", "fulltext": "\n Dynamic Parallelization of Recursive Code Part I: Managing Control Flow Interactions with the Continuator \nCharlotte Herzeel Pascal Costanza Software Languages Lab, Vrije Universiteit Brussel, Belgium charlotte.herzeel/pascal.costanza@vub.ac.be \nAbstract While most approaches to automatic parallelization focus on compilation approaches for parallelizing \nloop iterations, we advocate the need for new virtual machines that can paral\u00adlelize the execution of \nrecursive programs. In this paper, we show that recursive programs can be effectively parallelized when \narguments to procedures are evaluated concurrently and branches of conditional statements are speculatively \nex\u00adecuted in parallel. We introduce the continuator concept, a runtime structure that tracks and manages \nthe control depen\u00addences between such concurrently spawned tasks, ensuring adherence to the sequential \nsemantics of the parallelized pro\u00adgram. As a proof of concept, we discuss the details of a par\u00adallel \ninterpreter for Scheme (implemented in Common Lisp) based on these ideas, and show the results from executing \nthe Clinger benchmark suite for Scheme. Categories and Subject Descriptors D.1.3 [Software]: Programming \nTechniques Parallel Programming; D.3.4 [Software]: Programming Languages Interpreters General Terms Languages, \nPerformance Keywords Recursion, automatic parallelization, software speculation, virtual machines, continuator \n1. Introduction Multicore processors are sneaking into our everyday life: Desktops and laptops have been \nequipped with multicore processors for several years now. In general, if we want our programs to take \nadvantage of such processors, we can choose to adopt parallel programming, which is, however, known to \nbe very dif.cult and was until recently only con\u00adsidered to meet .rm performance requirements. Most expe\u00adrience \nwith parallel programming stems from highly speci.c Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA/SPLASH 10, October 17 21, 2010, Reno/Tahoe, Nevada, USA. \napplications in the domains of scienti.c computing and mul\u00adtimedia, which run on specialized hardware \nor clusters [18]. It is not clear whether these experiences can be easily trans\u00adferred to a desktop setting \nwith multicores. It is in this light that a new family of multiprocessing languages is emerging, examples \nof which include Sun s Fortress, IBM s X10, and Cray s Chapel. These languages are in turn based on experiences \nwith academic multipro\u00adcessing languages such as Cilk, Multilisp, Qlisp, and so on. In such languages, \nthe programmer merely exposes the po\u00adtential parallelism in the program. It is the language s run\u00adtime \nsystem that is then responsible for generating threads and scheduling them ef.ciently on the hardware. \nThe results are promising, but it may still take years for languages like Fortress, X10, and Chapel to \nbe fully developed, and even if we get them, there is the problem that we need to rewrite all existing \napplications from scratch if we want them to take advantage of multicores. In contrast, with automatic \nparallelization, the compiler is fully responsible for mapping programs onto threads [37]. An important \nobservation is that most work on automatic parallelization focuses on loops [4, 9, 10, 12, 13, 37, 52, \n54], but this is insuf.cient when considering recursive code, be\u00adcause there is an important class of \nalgorithms that cannot be easily and ef.ciently expressed as loops [1, 44]. Such re\u00adcursive code is abundant \nin programs written in functional languages, where recursion is a favorite coding pattern. Con\u00adsequently, \nthere is an important class of programs that are not automatically parallelized using existing techniques. \nOur position is that we should also come up with new vir\u00adtual machines that can parallelize the execution \nof existing sequential languages. In this paper, we investigate one as\u00adpect of such a virtual machine, \nnamely how to automatically extract and manage the parallelism in recursive code. More concretely, we \ninvestigate a virtual machine to automatically extract parallelism by combining parallel argument evalu\u00adation \nand speculative branching, which were introduced as language constructs in earlier languages [21, 28, \n47]. We dis\u00adcovered that building parallel argument evaluation and spec\u00adulative branching into a virtual \nmachine requires a runtime mechanism for managing the control .ow of the different c Copyright . 2010 \nACM 978-1-4503-0203-6/10/10. . . $10.00  tasks that are spawned to execute a program. For this, we developed \nthe continuator concept, a structure that tracks the dependences between the spawned tasks. The continua\u00adtor \nmanages the interactions between parallel argument eval\u00aduation, speculative branching, and side effects. \nThe contin\u00aduator also solves one of the long-standing problems in im\u00adplementing speculative computation: \nIt makes it possible to squash wrongly speculated computations without freezing all interpreter execution \nand guarantees that wrongly spec\u00adulated computations do not keep spawning new tasks. As we explain in \nthe rest of the paper, the idea is to represent the execution trace of a computation as a tree, where \nwe use continuators to represent its nodes. As a proof of concept implementation, we present a par\u00adallel \ninterpreter for Scheme that implements our approach. We choose Scheme because it is a minimal language \nwith all the basic ingredients for expressing different program\u00adming paradigms [1]: In Scheme one can \nwrite anywhere on the spectrum from very functional code (which is easier to parallelize) to very imperative \ncode (which in general cannot be done in parallel). As a validation, we present the results of our interpreter \nrunning the Clinger benchmark suite for Scheme [14]. For functional code, the numbers show good speedups \ncompared to a sequential implementation, despite the fact that our parallel interpreter uses a very straightfor\u00adward \ntask scheduler. This proves that the overhead of the continuator infrastructure can be suf.ciently minimized \nand is in an acceptable range. In order to ensure adherence to the sequential semantics of the interpreted \nlanguage, the contin\u00aduator currently guarantees the absence of data races by syn\u00adchronizing the computation \nat each assignment. As a conse\u00adquence, code with many side effects currently runs in con\u00adstant time with \nrespect to the number of processors, but we present suggestions for improving this in future work. The \ncontributions of this paper are: a dynamic approach for automatically parallelizing recur\u00adsive code, \nwhich combines parallel argument evaluation and speculative branching  the continuator concept, which \nmanages the control .ow interactions between parallel argument evaluation, spec\u00adulative branching, and \nside effects  a squashing mechanism that guarantees that wrongly speculated computations are fully discarded, \nwithout freezing the program execution  a parallel Scheme interpreter as a proof of concept imple\u00admentation \nof our approach  benchmarks showing that the overhead of our continuator infrastructure is in an acceptable \nrange  2. Toward dynamic parallelization Over the past years, several new parallel programming lan\u00adguages \nwere developed that attempt to hide some of the com\u00adplexity of parallel programming. These programming \nlan\u00adguages provide language constructs that enable the program\u00admer to expose the parallelism in an application, \nbut it is the responsibility of the language s runtime system to generate threads and schedule them ef.ciently \non the hardware. We next discuss how parallelism is typically extracted from re\u00adcursive programs in these \nlanguages, namely by calling the recursive subcalls in parallel, and by parallelizing the execu\u00adtion \nof conditionals. 2.1 Extracting parallelism from recursive code As an example of a recursive program, \nconsider Fig. 1, which shows the de.nition of a procedure for counting the leaves of a tree structure \n(in Scheme). It is a tree-recursive program, given the two recursive calls in the else branch. If we \ncan execute the recursive subcalls in parallel, we are likely to gain a speedup. (define (count-leaves \nx) (cond ((null? x) 0) ((not (pair? x)) 1) (else (+ (count-leaves (car x)) (count-leaves (cdr x)))))) \nFigure 1. Recursively counting the leaves of a tree Multiprocessing languages like Multilisp, Qlisp, \nand Cilk use such examples to motivate the need for a future, fork\u00adjoin, or parallel call construct, \nwhich makes it possible to call a procedure so that its arguments are processed in par\u00adallel instead \nof sequentially. In our example, the + should be called thusly to make sure that the two recursive calls \nto count-leaves execute in parallel. Another approach for further increasing the available parallelism \nin a recursive program is speculative computa\u00adtion [45, 47, 50]. The idea behind speculative computation \nis to start executing computations before they are known to be required. For example, speculative computation \ncan speed up execution of a search algorithm when all of the branches in the search space are explored \nin parallel, even though only one of them yields the correct result [46]. To support speculative computation, \nlanguages like Multilisp and Qlisp introduce parallel variants of constructs like and, or, and if. QLisp \nadditionally suggests the concept of heavyweight futures as a means to express speculative computation \n[25]. As an example, consider Fig. 2. We adapted this exam\u00adple from Russell and Norvig s textbook on \nArti.cial Intelli\u00adgence (AI) (see p. 73 [55]). It illustrates the general pattern of AI search algorithms. \nThe idea is that the search space is represented as a tree of nodes to be explored. The code implements \na loop that traverses the nodes in the search space (here stored in a queue). During each iteration, \nthe code checks whether a particular node satis.es the goal of the search, see goal-test? in the second \nif expression. If the node satis.es the test, the loop returns it as a result. Oth\u00aderwise, new nodes \nare generated (expand) and the search loop continues. Goal testing and search space expansion are typically \nvery costly operations, and it is reasonable to as\u00adsume that parallelizing their execution yields a performance \nimprovement. In Multilisp, for example, this can be achieved by marking the if as speculative.  (define \n(general-search problem queuing-fn) (define (loop node nodes) (if (empty-queue? nodes) node (let ((fnode \n(remove-front nodes))) (if (goal-test? problem (node-stage fnode)) fnode (loop fnode (queing-fn nodes \n(expand fnode problem) )))))) (loop () (make-initial-queue problem queuing-fn))) Figure 2. Recursively \nsearching a problem space  2.2 Dif.culties and open issues The proposed constructs for parallelizing \nrecursive programs are quite straightforward, but implementing and using them ef.ciently is not trivial. \nOne potential problem with language constructs for par\u00adallel procedure calling and speculative computation \nis that they lead to programs that produce a lot of .ne-grained par\u00adallelism. It is in general more dif.cult \nto schedule .ne\u00adgrained parallelism than coarse-grained parallelism ef.\u00adciently on multicores because \neach parallel computation needs to be represented in memory, needs scheduling time, and so on [30]. Over \nthe years, several runtime architec\u00adtures and scheduling strategies were developed to properly handle \nthis. The literature argues that a runtime architecture based on work-stealing scheduling provides the \nmost ef.\u00adcient solution to the granularity problem. It is, for example, used in Multilisp [28], Qlisp \n[49], Cilk [8], Fortress [11], and X10 [3]. We discuss work stealing in more detail in Section 3.1. A \nrelated problem is that the effectiveness of paralleliz\u00ading parts of a program depends on that program \ns input. For example, it is interesting to parallelize the execution of (fib 35), which computes the \nFibonacci of 35, but it is less inter\u00adesting to parallelize the execution of (fib 2). The program\u00admer \nmust take this into account. The Cilk programming en\u00advironment, for example, comes with a tool that monitors \nex\u00adecutions and reports programmers how much potential par\u00adallelism exists in a particular computation \n(see Chapter 15 of [35]). Similar experiments were done with Qlisp where the programmer estimates the \nthreshold for switching to par\u00adallel execution [24], but .nding the right threshold is a matter of trial \nand error. Another issue is that in all parallel programming lan\u00adguages we are aware of interactions \nbetween side effects and parallel language constructs must be handled explicitly by the programmer. That \nis, side effects must be explicitly synchronized using locks or atomic blocks, and in case of errors, \nit is the programmer s responsibility to properly re\u00adstore state. This is particularly dif.cult in combination \nwith speculative computation: When a speculative computation performs side effects, and it turns out \nthat the speculative computation is wrong, the side effects that were already per\u00adformed must be undone \nby the programmer [45, 47]. Using speculation can also severely slow down appli\u00adcations when the program \nconsistently speculates on the wrong computations. In Multilisp, programmers can in.u\u00adence which computations \nare favored for speculation by set\u00adting task priorities, but this considerably complicates the code [47]. \nAnother issue is that wrongly speculated com\u00adputations may never be deleted and as such swamp the pro\u00adcessor \nwith unnecessary work [45 47, 50]. See Section 7.4 for a more detailed discussion on this.  2.3 A virtual \nmachine approach We think that most of the above issues should be handled im\u00adplicitly by the virtual \nmachine. Our long-term goal is to build a virtual machine that automatically parallelizes sequential \ncode, steered by advanced runtime analysis [31]. Such a virtual machine would perform hot-spot analysis \nto detect which parts of the program are interesting to parallelize and decide where to insert parallel \nprocedure calls or specula\u00adtive computations. It could furthermore monitor the inputs of programs and \ndecide to switch to sequential execution for short computations. In case of parallel conditionals, a \nvirtual machine could keep track of which branches are most often taken and perform branch prediction \nto avoid speculating on the wrong branches. The interactions between side effects and parallel constructs \nwould also be handled automatically. For this, dependence analysis [37] could be included as part of \nthe dynamic compilation phase to detect and remove po\u00adtential data races. And so on. This paper is the \n.rst step to such a parallelizing virtual machine and investigates how we can automatically extract and \ncoordinate parallelism in recursive programs. As an experiment, we build an interpreter for Scheme that \nexecutes procedure calls and conditionals by default in parallel. Our contribution is the continuator \nconcept, a mechanism that automatically manages the control .ow interactions between parallel procedure \ncalling, speculative computation, and side effects. It also solves the problems that are present in existing \nimplementations of speculative computation: Our system automatically deletes wrongly speculated computations \nand makes sure that they cannot loop forever. Adding hot-spot analysis and dynamic compilation is part \nof future work and is discussed in Section 6. 3. Parallel execution by default Our research approach \nhas been to test our ideas in a straight\u00adforward language implementation in the form of an inter\u00adpreter. \nThis approach is in line with the Lisp tradition for using interpreters to understand execution semantics \nand us\u00ading them as a starting point to develop new program analysis techniques that can be used in compiler \nand virtual machine implementations [19, 51, 62]. The most well-known exam\u00adple where this approach is \nused are the lambda papers [22, 57 59, 61 64], a series of papers by Sussman and Steele that use interpreters \nto explore advanced programming concepts and implementation techniques, and led to the discovery of techniques \nfor optimizing tail recursion [59], discussed solu\u00adtions to the funarg problem [62], and showed that \nprocedure calls do not necessarily impose an overhead compared to go\u00adtos [58]. Similarly, aspect weavers \n[39, 43], Haskell [34], Java [27], JavaScript [33], and Smalltalk [36] to name just a few were all .rst \nimplemented as interpreters.  Our interpreter is an AST-based interpreter, rather than one based on \nbyte codes. The advantages and disadvan\u00adtages of ASTs compared to byte codes are subject to con\u00adtroversy \n[17, 40]. We believe that AST-based interpretation is more amenable to parallelization, because it gives \nrise to a tree-recursive process [1], which potentially yields expo\u00adnential amounts of parallelism [28], \nwhereas the .at repre\u00adsentation of byte codes gives rise to an iterative, sequential interpretation process. \nOur interpreter implements a non-trivial subset of Scheme, close to the R3RS speci.cation of Scheme1, \nbut does not support call/cc nor I/O operations. I/O operations are not particularly relevant for our \nexperiments, and call/cc is not supported because it is not clear what a construct for reifying the program \nstack should return in a parallel in\u00adterpreter, where the stack is spread over multiple threads. Nonetheless, \nour interpreter is suf.ciently mature to support a broad class of Scheme programs for benchmarking pur\u00adposes \nin Section 5. The interpreter itself is written in Com\u00admon Lisp, using the Common Lisp Object System \n(CLOS)2, and the LispWorks3 development environment. Our code re\u00adlies on a LispWorks package for multiprocessing \nand in par\u00adticular its support for mailbox synchronization. 3.1 A parallel interpreter based on work-stealing \nThe execution model we assume is based on work-stealing scheduling, in the tradition of multiprocessing \nlanguages like Qlisp [21], Multilisp [28], and Cilk [8], with the dif\u00adference that our interpreter automatically \ngenerates paral\u00adlel tasks instead of requiring the programmer to introduce parallelism. We opt for a \nwork-stealing architecture because this appears to be the most ef.cient solution to scheduling .ne-grained \nparallelism on multicores [3, 7, 11, 28, 49]. The idea is that we start from a sequential interpreter \nthat we du\u00adplicate over as many threads as there are processor cores. Each of these interpreter threads \nis equipped with a mail\u00adbox queue, serving as a parallel stack: Interpreter calls are encoded as messages \nput onto the thread s mailbox queue, which the thread continuously polls. We implement a sim\u00adple work-stealing \nalgorithm so that the different interpreter 1 See http://people.csail.mit.edu/jaffer/r3rs_toc.html 2 \nThe Common Lisp Object System (CLOS) is an extension for object\u00adoriented programming in Common Lisp, \nsee [16] for an overview. 3 For LispWorks R ., see http://www.lispworks.com/ threads can steal messages \nfrom one another to balance the workload. The code for creating such an interpreter thread is shown in \nFig. 3.4 A Lisp process is initialized through the library function mp:process-run-function. The important \npart of the code is the lambda expression: It encodes what the created process does. As we see, the .rst \nthing an interpreter thread does is set up a mailbox queue (mbox) and register itself in a global variable \nthat keeps track of all of the inter\u00adpreter threads (*interpreters*). Then an endless loop fol\u00adlows, \nwhere the interpreter thread polls its mailbox queue for a message. If a message is found, the message \nis processed, calling the appropriate interpreter function. If after a par\u00adticular timeout (here 0.00001s), \nno message is found in the thread s own mailbox queue, the thread will attempt to steal a message from \none of the other threads (steal-msg). The code for stealing a message is omitted. It is just a loop that \ntraverses the list of interpreter threads, polling each mailbox queue until a message is found that can \nbe stolen. This works assuming that a computation is initialized externally by the read-eval-print loop \n(or REPL), which randomly selects a mailbox queue and assigns it the (.rst) input expression. (defmethod \nmake-interpreter-thread (name) (mp:process-run-function ; create a process name () (lambda () (let ((mbox \n(mp:make-mailbox))) (setf (mp:process-mailbox mp:*current-process*) mbox) (push mp:*current-process* \n*interpreters*) (do ((msg (mp:mailbox-read mbox :timeout 0.000001) (mp:mailbox-read mbox :timeout 0.000001))) \n(nil) (if (not (null msg)) (funcall (get-function msg) (args msg)) (let ((msg (steal-msg))) (funcall \n(get-function msg) (args msg))))))))) Figure 3. Code for creating an interpreter thread Our interpreter \nis structured as a continuation-passing\u00adstyle (cps) interpreter [19], i.e. an interpreter where control \n.ow is made explicit using function objects, which makes it easier to distribute computations over different \nthreads. A code excerpt of the evaluator is shown in Fig. 4. An impor\u00adtant difference with a regular \ncps interpreter is that evaluator functions are not directly called, but through the operator call, for \nwhich the code is also shown in Fig. 4. The op\u00aderator call wraps interpreter calls into message objects \nand pushes them onto the interpreter thread s mailbox queue. The interpreter we discussed so far does \nnot give rise to a parallel execution of programs each interpreter call produces at most one message. \nWe introduce parallelism by revising the interpreter to perform parallel procedure calling and speculative \nbranching.  3.2 Parallel argument evaluation In our interpreter, all procedures are by default executed \nin parallel. This includes all user-de.ned procedures, but also 4 Note that we color Common Lisp code \nblue and Scheme code green.  (defmethod eval (exp env cont) (cond ((variable-p exp) (funcall cont (binding \nexp env))) ((atom exp) (funcall cont exp)) ((if-p exp) (call # eval-if exp env cont)) ((set-p exp) (call \n# eval-set exp env cont)) ...)) (defmethod eval-if (exp env cont) ...) (defmethod eval-set (exp env cont) \n...) ... (defmethod call (func &#38;rest args) (mp:process-send mp:*current-process* (cons func args))) \nFigure 4. Calling the evaluator primitive procedures and expressions such as begin. To ex\u00adecute a procedure \nin parallel, we evaluate its arguments in parallel. Here we sketch the requirements for going from sequential \nargument evaluation to parallel argument evalu\u00adation. The code for performing sequential argument evalua\u00adtion \nis shown in Fig. 5. The function eval-args implements a loop that iterates over the list of unevaluated \nargument ex\u00adpressions (exps). The variable results is used for accumu\u00adlating the results from evaluating \nthe arguments. The loop exits when the list of arguments to evaluate is empty, which then triggers the \ncontinuation of evaluating the arguments (i.e. calling cont, which encodes applying the procedure to \nthe evaluated arguments, which for brevity is omitted from Fig. 5). When there is still an argument to \nevaluate, the loop calls the top-level evaluator function (eval), which it passes as a continuation a \nlambda that continues the eval-args loop with the updated list of evaluated arguments. (defmethod eval-args \n(exps results env cont) (if (null exps) (cont results) (call # eval (car exps) env (lambda (arg!) (call \n# eval-args (cdr exps) (cons arg! results) env cont))))) Figure 5. Sequential argument evaluation Mockup \ncode for evaluating the arguments in parallel is shown in Fig. 6. It illustrates what we would like the \ncode to do. The code implements a loop similar to the loop for evaluating arguments sequentially. The \nbig difference is that the loop for parallel evaluation does not wait for the result of evaluating an \nargument to proceed with the loop: After requesting the evaluator to evaluate an argument, the loop immediately \ncontinues to request evaluation of the rest of the arguments (see the two successive calls). As a reminder: \ncall transforms an interpreter call into a message object which is pushed onto the local interpreter \nthread s message queue, from which other interpreter threads can steal messages. It is because of this \nthat the successive calls in Fig. 6 are potentially executed in parallel. The tricky part is that, somehow, \ncalling the continuation of evaluating the arguments (cont), which encodes the pro\u00adcedure application, \nmust be delayed until all the arguments (defmethod eval-args (exps results env cont) (if (null exps) \n(cont (wait-and-collect-results results)) (progn (call # eval (car exps) env (lambda (arg!) (store! arg! \nresults)) ) (call # eval-args (cdr exps) env results cont)))) Figure 6. Mockup parallel argument evaluation \nare .nished evaluating and accumulated from the parallel calls (store!) in the right order the order \nthat matches the procedure s formal parameter list. We conclude that we need two elements to support \npar\u00adallel argument evaluation: 1) a mechanism for accumulating the results of the different arguments, \nrespecting the order of the procedure s formal parameter list and 2) a way of de\u00adlaying the continuation \nthat encodes the procedure applica\u00adtion until the results of all of the argument expressions are known. \n 3.3 Speculative branching Here we discuss the requirements for supporting specula\u00adtive evaluation of \nconditional expressions. Mockup code is shown in Fig. 7. Under parallel evaluation of a condi\u00adtional \nexpression, we understand that the test and one of the branches are executed in parallel. The code for \neval-if shows a call to launch the evaluation of the test expression. Then we speculate which branch \nwe are going to execute in parallel (speculate-alternate-p), and launch execution of either the then \nor else expression. We suppose that the results of the different parallel tasks are accumulated in the \nvariables test, then and else. Then, eval-if needs to wait for the result of the test expression before \nit can call the continuation of evaluating the if expression (i.e. cont). (defmethod eval-if (exp env \ncont) (let ((test nil) (then nil) (else nil) (test-task nil) (else-task nil) (then-task nil)) (setf test-task \n(call # eval (car exp) env (lambda (test!) (setf test test!)))) (if (speculate-alternate-p) (setf then-task \n(call # eval (cadr exp) env (lambda (then!) (setf then then!)))) (setf else-task (call # eval (caddr \nexp) env (lambda (else!) (setf else else!))))) (wait-until-done test-task) (if (true-p test) (if (not \n(null then-task)) (progn (wait-until-done then-task) (cont then)) (progn (squash else-task) (setf then-task \n(call # eval (cadr exp) env (lambda (then!) (setf then then!)))) (wait-until-done then-task) (cont then))) \n...))) Figure 7. Mockup speculative branching  If the test turns out to be true, we verify that we speculated \non executing the then branch (by checking that then-task is not bound to nil). If this is the case, we \ncall the contin\u00aduation with the result of the then expression, as soon as that result is known. If instead \nwe speculated on evaluating the else branch, which, in this case, is the wrong branch to con\u00adtinue from, \nwe call squash to interrupt and discard the else task, and subsequently we start execution of the then \ntask. The code for when the test expression turns out to be false works equivalently and is omitted from \nFig. 7. From this mockup code, we can conclude that what we need to support speculative branching is \n1) a mechanism for accumulating the results of the test, then, and else expres\u00adsions; 2) a way to delay \nthe continuation of the if expression; 3) a mechanism for discarding evaluation of the branch ex\u00adpression \nthat turns out to be the wrong one; 4) a mechanism to .gure out which branch to speculate on. Interactions \nwith side effects are discussed in the next subsection. Note that with speculative branching, stop conditions \nare bypassed. To illustrate what we mean, consider the de.nition of a procedure first: (define (first \nl) (if (null? l) () (car l))) The procedure first returns the .rst element of a list, but if that list \nis empty, it returns the empty list. When the if expression is evaluated in parallel, and the list happens \nto be the empty list, it may happen that the evaluator tries to execute (car l), i.e. the else branch. \nBut taking the car of the empty list yields an error in Scheme [56]. It is important to note that this \nerror is the result of our parallel evaluation strategy, and we must make sure that such errors are discarded \nand that they are certainly not reported as programming errors. Another case where bypassing stop conditions \nseems paradoxical is that it may cause recursive procedures to re\u00adcurse beyond the base case. Picture \nthe recursive de.nition of the factorial function: (define (fac n) (if (<= n 2) n (* n (fac (-n 1))))) \nImagine we want to compute the factorial of 2, and that the evaluator has already launched evaluation \nof the factorial of 1, although the result is just 2. It seems that this execution will loop forever, \nevaluating the factorial of 1, 0, -1, and so on. We need to make sure that the squashing mechanism of \nthe underlying evaluator is capable of stopping this kind of looping.  3.4 Side effects One of the key \ndif.culties in parallel programming is han\u00addling side effects. This is because side effects impose an \nexplicit ordering in a program s execution, and maintain\u00ading this ordering reduces the potential parallelism \ninherently. To illustrate the problem, consider the following (contrived) procedure for .lling a list \nwith numbers from 1 to n:5 5 Recall from Section 3.2 that we parallelize subexpressions of begin. (define \n(make-list n) (let ((res ())) (define (loop c) (if (= c 0) res (begin (set! res (cons c res)) (loop (-c \n1))))) (loop n))) Without care, the parallel execution of make-list may not produce a list containing \nnumbers from 1 to n: It may pro\u00adduce a list where the numbers are randomly ordered, or even just a subset. \nThis is because it is not .xed when the set! ex\u00adpression is evaluated. When such a situation arises, \nit is said that a data race occurs. Multiprocessing languages provide synchronization constructs for \navoiding data races, typically locks or software transactions [29]. Our interpreter should handle synchronization \nof side effects automatically without the programmer having to mention locks or atomic blocks in the \nsource code. Mockup code for handling variable assignment automat\u00adically is shown in Fig. 8. Before evaluating \nan assignment, we make sure that all computations that come logically be\u00adfore the assignment have .nished \nexecuting. That way we can assure that none of those computations uses the (prema\u00adturely) updated variable \nvalue. For our example above, this means that the assignment waits for the execution of (= c 0) and more \nimportantly the execution of the iterations 1 to c - 1. Then, after performing the side effect, we roll \nback the computations that logically come after the assignment and that (might) read the variable before \nit was updated. In our example we thus roll back (loop n). (defmethod eval-set! (exp env cont) (call \n# eval (cadr exp) env (lambda (val!) (wait-until-all-previous-expressions-done exp) (bind! env (car exp) \nval!) (roll-back-all-later-expressions exp) (cont ok)))) Figure 8. Mockup variable assignment Vector \nassignment (vector-set!) and list assignment (set-car! and set-cdr!) after variable assignment the only \nother primitive side effecting operations in R3RS Scheme can be handled similarly. Note that our approach \nfor handling side effects is very conservative we turn every side effect into a synchroniza\u00adtion point. \nInstead, we could opt for speculative evaluation of side effects and rely on a runtime mechanism to detect \nand undo data race con.icts. We choose to implement a con\u00adservative approach to side effects because \nwe .rst want to focus on the basic control .ow interactions from combining side effects with parallel \nargument evaluation and specula\u00adtive branching in a virtual machine. In Section 6, we discuss how alternative \napproaches to handling side effects could be built on top of our basic support for side effects.  3.5 \nSummary of requirements We can generalize and summarize the requirements for adopting parallel argument \nevaluation and speculative branching as follows: 1. We need a mechanism that accumulates the results \nof the subcomputations of a computation and then triggers the next continuation. 2. We need a way of \ndelaying the continuation of a compu\u00adtation until all of its subcomputations have .nished. (E.g. we can \nonly apply a procedure once we have evaluated all of its arguments.) 3. For implementing speculative \nbranching, we need to make sure that it is possible to discard computations that turn out to be part \nof the wrong branch. 4. The discard mechanism should avoid the looping that is (seemingly) introduced \nwhen parallelizing conditionals bypasses stop conditions in recursive code. 5. We must make sure that \nthe errors produced by bypassing stop conditions are not reported as programming errors. 6. For making \nsure that side effects happen in the correct or\u00adder, we need to be able to check whether the expressions \nthat logically come before the side effect have .nished computing. 7. We also need a mechanism to roll \nback computations of expressions that logically come after a side effect.  We argue that all of these \nrequirements are related to managing the control .ow, which becomes complicated by dividing the computation \nover different parallel tasks. In the next section, we discuss the continuator concept for implementing \nan interpreter that satis.es these requirements. 4. Managing control .ow with continuators We introduce \nthe continuator concept as a basis for a run\u00adtime mechanism that coordinates the various parallel tasks \nthat are spawned to implement parallel procedure calling and speculative branching. 4.1 Representing \nthe execution trace as a tree Fig. 9 shows a tree representation of the execution trace of the factorial \nfunction. It shows all the subexpressions nec\u00adessary to evaluate a factorial call. Our interpreter builds \nthis tree as the program runs for tracking the control dependences between computations. We exploit the \ntree structure as a ba\u00adsis for a runtime mechanism that manages control .ow and satis.es the requirements \nwe discussed in Section 3.5.  4.2 Implementing the tree with the continuator We de.ne the continuator \nstructure for implementing the nodes of the execution tree. For each expression the evalua\u00adtor processes, \nthere is a corresponding continuator, which is used for accumulating and reducing the results of (sub)ex- \n Figure 9. Execution trace of factorial as a tree pressions. We implement the continuator as a CLOS class, \nshown in Fig. 10. (defclass continuator () ((arguments :initform (make-array 1)) (children :initform \n(make-array 1)) (parent :initform nil) (idx :initform 0) (env :initform nil) (cont :initform nil) (lock \n:initform (mp:make-lock)) (msg-handler :initform # handle-msg) (children-exps :initform (make-array 1)))) \n (defclass procedure-call-continuator (continuator) ((fobj :initform nil)) (defclass if-continuator (continuator) \n((issued-consequent :initform nil) (issued-alternate :initform nil))) (defclass set-continuator (continuator) \n((var-to-set :initform nil))) ... Figure 10. The continuator structure The class continuator de.nes a \nslot arguments for storing the results of a continuator s children. The slots children, parent, and idx \nare there for tracking the par\u00adent/child relations of the tree. A continuator also stores interpreter \nstate, in the slots env and cont. The latter encodes what happens when all of a continuator s chil\u00addren/subexpressions \nare .nished computing. Each contin\u00aduator has a lock associated with it for synchronization pur\u00adposes. \nThe slot children-exps stores the subexpressions of the continuator, whereas the slot msg-handler holds \na function. The exact purposes of these different slots becomes clear when we discuss the implementation \nof parallel argu\u00adment evaluation, speculative branching, and side effects in the next subsections. Fig. \n10 reveals there are different types of continua\u00adtors (see the various continuator subclasses). There \nis a continuator class for each of Scheme s primitive expres\u00adsion types, namely procedure call expressions, \nconditional expressions (if), and side effecting expressions (set!, vector-set!, set-car!, and set-cdr!). \nThe interpreter dispatches differently on the types of continuators, and some of the specialized continuator \nclasses de.ne slots that hold additional data, such as a procedure object for the case of the procedure \ncall continuator, slots for checking which branch is executed speculatively for the case of an if continuator, \nand a slot for storing the name of the variable to assign for the set! continuator.  4.3 Implementing \nparallel argument evaluation We extend each evaluator function with a continuator ar\u00adgument. The REPL \ncreates the initial continuator, the root, and subsequent evaluator calls grow the execution tree from \nthere by creating new continuators at well-de.ned points in the interpreter, namely the interpreter functions \nthat initialize evaluation of a procedure call, or if, set!, vector-set!, set-car!, and set-cdr! expressions. \nFig. 11 shows the code for parallel argument evalua\u00adtion, albeit simpli.ed the synchronization code is \nomit\u00adted (synchronization is discussed in Section 4.6). The func\u00adtion eval-args makes a new procedure \ncall continuator (fcall-ctor), initializing it using the arguments passed to eval-args. There is a check \nto see whether the list of argu\u00adments to evaluate (args) is empty: If this is the case, we im\u00admediately \nproceed with the next continuation (cont). Other\u00adwise, there is a loop which processes the unevaluated \nargu\u00adments. There are two iteration variables: One for going over the list of unevaluated arguments (unevaluated-args) \nand a counter that gives the index for each of these unevaluated arguments (ctr). (defmethod eval-args \n((ctor continuator) fobj args env cont) (if (null args) (funcall cont ()) (let ((fcall-ctor (make-fcall-continuator \nctor cont fobj env args))) (do ((ctr 0 (+ 1 ctr)) (unevaluated-args args (cdr unevaluated-args))) ((null \nunevaluated-args)) (let* ((arg (car unevaluated-args)) (ctr* ctr) ; rebind ctr for closure (arg-node \n(svref (children fcall-ctor) ctr))) (call # eval arg-node arg env (lambda (arg!) (call # fcall-accumulate \narg-node arg! ctr*)))))))) Figure 11. Parallel argument evaluation (simpli.ed) For each unevaluated argument, \nwe request its evalu\u00adation (see the call to eval). Note the arguments passed to the latter eval call, \nin particular the continuator and continuation arguments. The continuator is the nth child of the procedure \ncall continuator, with n = ctr. The con\u00adtinuation calls fcall-accumulate with as arguments that node \n(arg-node), the evaluated argument (arg!), and the index of the unevaluated argument (ctr*). The function \nfcall-accumulate (in Fig. 12) stores the result of evaluat\u00ading an argument in the procedure call continuator \nand checks whether all procedure call arguments are evaluated. If so, it calls the continuation that \nwas stored in the procedure call continuator. We see that the loop in eval-args spreads the evalu\u00adation \nof the arguments over different tasks and that their (defmethod fcall-accumulate ((ctor continuator) \narg! pos) (setf (aref (arguments (parent ctor)) pos) arg!) (when (all-arguments-evaluated-p (parent ctor)) \n(funcall (cont (parent ctor)) (array->list (parent ctor))))) Figure 12. Accumulating a procedure call \nargument (sim\u00adpli.ed) results are collected and stored in the procedure call con\u00adtinuator (via fcall-accumulate). \nHence the continuator provides a means to collect the results of parallel com\u00adputations and satis.es \nRequirement 1 in Section 3.5 for implementing parallel argument evaluation. Also, we see that the continuation \nof eval-args is delayed using the continuator it is stored there upon entry of eval-args and called only \nwhen all of the arguments are .nished eval\u00aduating (via fcall-accumulate). As such, the continuator provides \na way of delaying computations and satis.es Re\u00adquirement 2 in Section 3.5.  4.4 Implementing speculative \nbranching Fig. 13 shows the code for speculative branching, omitting the synchronization code for conciseness. \nThe code shows that eval-if evaluates an if expression by telling the inter\u00adpreter to evaluate the test \n(via issue-test) and, at the same time, it chooses to evaluate either the else or the then expres\u00adsion \n(via issue-alternate or issue-consequent). In our current implementation we always speculate on the else \nbranch, but better speculation strategies, that make guesses based on the test s outcomes in previous \nexecutions, are likely more accurate (we come back to this in Section 7.2). (defmethod eval-if ((ctor \ncontinuator) exp env cont) (let ((if-ctor (make-if-continuator ctor exp env cont)))) (issue-test if-ctor \n(cadr exp)) (if (speculate-alternate-p) (progn (setf (issued-alternate-p if-ctor) T) (issue-alternate \nif-ctor (cadddr exp))) (progn (setf (issued-consequent-p if-ctor) T) (issue-consequent if-ctor (cadddr \nexp))))) (defmethod issue-test ((if-ctor if-continuator) exp) (let ((child (svref (children if-ctor) \n0))) (call # eval child exp (env if-ctor) (lambda (test!) (call # accumulate-test child test!))))) (defmethod \naccumulate-test ((ctor continuator) val-for-test) (let ((if-ctor (parent ctor))) (setf (value-for-test \nif-ctor) val-for-test) (if val-for-test (progn (inline-msg-handler if-ctor 1) ; see squashing (when (issued-alternate-p \nif-ctor) (squash-alternate if-ctor) (issue-consequent if-ctor)) (when (not (eql *unknown* (val-for-conseq \nif-ctor))) (funcall (cont if-ctor) (val-for-conseq if-ctor)))) ...))) ... Figure 13. Speculative branching \n(simpli.ed) The code for issuing evaluation of the test expression is also shown in Fig. 13. The function \nissue-test calls eval to evaluate the test expression, and the continuation calls accumulate-test (also \nde.ned in Fig. 13). This function is responsible for storing the result of the test in the continuator \ncreated for evaluating the if expression (if-ctor). It then checks if the test result is true or false. \nIf it is true, it calls inline-msg-handler, which opti\u00admizes squashing, and which we discuss in the next \nsec\u00adtion where we cover the details of squashing computa\u00adtions. After the inline-msg-handler call, the \ncode checks if we speculatively started executing the else expression (issued-alternate-p), in which \ncase we discard that computation (squash-alternate) and issue evaluation of the then expression. Then \nthe function checks if the result of the then expression is already computed and if so, it calls the \ncontinuation of the if expression (stored in if-ctor). The code for when the test turns out to be false \nis very similar and omitted from Fig. 13.  The code for issuing evaluation of the then and else ex\u00adpressions \n(issue-consequent and issue-alternate) is similar to the de.nition of issue-test and omitted from Fig. \n13. The code calls eval to evaluate the then (or else) expression, and as a continuation, the function \naccumulate-consequent (or accumulate-alternate) is called. This function stores the result of the then \n(or else) expression in the continuator and if the test result is known and true (or false), the function \nmay call the continuation of the if expression (stored in the continuator if-ctor). There is no need \nfor this function to squash the wrong branch, as this is handled by accumulate-test. 4.4.1 Squashing \nwithout stopping the world Here we discuss the details of discarding (or squashing) computations. In \nSection 3.5, we discussed that speculative branching may bypass stop conditions and cause evaluation \nto loop for recursive code; we require that the squashing mechanism avoids that (see Requirements 3 and \n4). To re\u00adfresh our discussion about the looping problem, we discuss Fig. 14, which displays the execution \ntrace of the factorial function. Imagine we want to compute the factorial of 2. Un\u00adder speculative evaluation, \nwe may speculatively issue eval\u00aduation of the else branch of the if in the factorial s de.ni\u00adtion. However, \nthe result of the factorial is just 2 (i.e the then branch) and the computation of the else branch needs \nto be discarded. Fig. 14 shows the execution trace growing to the right, assuming we speculated on the \nelse branch of the if expres\u00adsion. To squash the computation for the else branch, we need to squash its \nsubcomputations, and their subcomputations, and so on. The squashing is illustrated using the red crosses \nthat cut off branches in the execution tree. What may happen is that while we squash a task, e.g. for \nthe expression (* n (fac (-n 1))), one of its parallel subtasks, e.g. for the expression (fac (-n 1)), \nspawns a new subtask. When we come to squashing the task for the expression (fac (\u00adn 1)), one of that \ntask s subexpressions (down the tree) may again spawn a new subtask. This may go on forever, given the \nrecursive structure of the factorial function, so that the squashing is continuously behind the spawning \nof new tasks. This situation may seem exceptional at a .rst glance, but it is not. We indeed repeatedly \nencountered the problem in our .rst attempts to implement speculative branching. One strategy to avoid \nthe looping would be to have our squashing mechanism freeze the interpreter to squash all of the tasks \nthat are generated so far and then restart the interpreter. We call this a stopping the world approach. \nIt obviously greatly reduces the available parallelism in the execution of a program. Our continuator \nconcept supports a squashing mechanism that does not require stopping the world and still avoids the \nlooping. Our strategy for implementing the squashing mechanism is to allow the continuators to in.uence \nhow messages are handled by the interpreter. Recall that interpreter functions are called through an \noperator call, which turns an in\u00adterpreter call into a message object that is put onto an in\u00adterpreter \nthread s mailbox queue, as we explained in Sec\u00adtion 3.1 (also see Fig. 4). Such a message consists of \nthe in\u00adterpreter function to call and its arguments, which for most interpreter functions consists of \na continuator, an expression, an environment, and a continuation. We equip each contin\u00aduator with a message \nhandler (a function), and we change the interpreter so that it calls this message handler for pro\u00adcessing \na message. The idea is that a continuator s message handler can be updated, which allows us to implement \nthe squashing mechanism. Fig. 15 shows the updated code for creating an interpreter thread the original \ncode is shown in Fig. 3. The bottom of Fig. 15 also shows the new code for the call operator, which now \nadds a continuator to the message objects it cre\u00adates. The code for make-interpreter-thread shows that \ninterpreter threads no longer (fun)call interpreter functions directly to process a message. Instead, \nan interpreter thread defers this to the message s message handler (cf. the call to get-msg-handler). \n (defmethod make-interpreter-thread (name) (mp:process-run-function ; create a process name () (lambda \n() (let ((mbox (mp:make-mailbox))) (setf (mp:process-mailbox mp:*current-process*) mbox) (push mp:*current-process* \n*interpreters*) (do ((msg (mp:mailbox-read mbox :timeout 0.000001) (mp:mailbox-read mbox :timeout 0.000001))) \n(nil) (if (not (null msg)) (funcall (get-msg-handler msg) msg) (let ((msg (steal-msg))) (funcall (get-msg-handler \nmsg) msg)))))))) (defmethod call (f (c continuator) &#38;rest args) (mp:process-send mp:*current-process* \n(cons f (cons c args)))) Figure 15. Indirect handling of messages We de.ne two kinds of message handlers. \nTheir code is shown in Fig. 16. The default message handler (handle-msg) just calls the interpreter function \nstored in the message ob\u00adject. There is also a message handler de.ned that is used for squashed continuators \n(ignore-msg), which does not do anything with a message but just immediately returns. (defmethod handle-msg \n(msg) (apply (car msg) (cdr msg))) (defmethod ignore-msg (msg) t) Figure 16. Two kinds of message handlers \nThe root continuator has the default message handler. Any other continuator inherits the message handler \nof its parent, unless it is an if continuator. For if continuators, a new mes\u00adsage handler is created \nthat calls the message handler of its parent, as shown in Fig. 17. This allows us to squash children \nof an if continuator which can execute speculatively by replacing their message handlers. (defmethod \nmake-continuator ((pa continuator) idx) (let ((node (make-instance continuator :parent pa ...))) (setf \n(msg-handler node) (msg-handler pa)) node)) (defmethod make-continuator ((pa if-continuator) idx) (let \n((node (make-instance continuator :parent pa ...))) (setf (msg-handler node) (lambda (msg) (funcall (msg-handler \n(parent node)) msg))) node)) Figure 17. Initializing a continuator s message handler To squash a continuator, \nwe assign to its parent a dummy continuator that has ignore-msg as its message handler, cf. Fig. 18, \nand we clean up any results that the parent may have stored for the squashed child. Since children tasks \nthat execute speculatively rely on calling their parent s message handler, they are automatically squashed \nas well. Note that squashing a continuator does not mean that all of the mes\u00adsages produced for its children \nare discarded at exactly the same time. These messages are only discarded as soon as an interpreter thread \ntries to process them. However, this way of squashing does not require us to freeze the interpreter and \nstop the world! (defmethod squash-continuator ((ctor continuator)) (let ((old-pa (parent ctor))) (setf \n(parent ctor) (make-instance continuator :msg-handler # ignore-msg)) (setf (svref (children old-pa) (idx \nctor)) (make-instance continuator :pa old-pa :idx (idx ctor))) (setf (svref (arguments old-pa) (idx ctor)) \n*unknown*))) Figure 18. Squashing a continuator At this point, one may wonder about the performance impact \nof redirecting message handing through message handlers. Fig. 17 suggests we create a new indirection \nfor each child of an if continuator. When executing recursive code, this can lead to very deep chains \nof indirections in the message handlers. For example, consider we want to evaluate the factorial of 35: \neach time we get to evaluating the if expression, we create an indirected message handler. This means \nthat each recursive call of which there are a lot for computing (fac 35) takes place through an in\u00addirected \nmessage handler. We can however undo the indi\u00adrections for the children of an if continuator as soon \nas we know the outcome of the test. It is then safe to undo the indirection for the correct branch since \nthat branch cannot be squashed anymore. Hence we replace that continuator s message handler with the \none of the if continuator. This is what inline-msg-handler does in the code for eval-if (in Fig. 13). \n 4.4.2 Discarding errors caused by speculation With speculative branching, stop conditions may be by\u00adpassed. \nIn Section 3.3, we discussed an example where this causes the execution of a program to generate unexpected \nerrors. We discussed the procedure first which takes as ar\u00adgument a list and returns the car of that \nlist, unless that list is empty, in which case it returns the empty list. Under spec\u00adulative execution, \nwe may try to take the car of the empty list which in Scheme is an error. Such errors are created by \nour parallel evaluation strategy and we do not want them to propagate as programming errors (see Requirement \n5 in Section 3.5). Normally, when an error occurs, execution is halted and the error is spit out to the \nprogrammer. In our parallel in\u00adterpreter, we change this so that errors are propagated as re\u00adsults of \nan execution. Fig. 19 shows the code for resolving a procedure call. The case for applying a primitive \nproce\u00addure, i.e. a procedure that is de.ned in Common Lisp such as +, is wrapped with a handler-case6. \nWe see that when a primitive procedure application causes an error, we just call the continuation anyway, \nwith the error object as result. This way, errors that are generated by speculation do not interrupt \nthe execution, but are propagated as results of the wrongly speculated branches. Since those branches \nare never returned 6 handler-case is the equivalent to try-catch in other languages.  as the result \nof the computation as a whole, these errors re\u00admain hidden from the programmer. (defmethod procedure-apply \n((ctor continuator) fobj args env cont) (let ((fcall-ctor (parent ctor))) (if (primitivep fobj) (handler-case \n(funcall cont (apply (primitive-f fobj) args)) (error (condition) (funcall cont condition) )) (call # \neval fcall-ctor (body fobj) (bind (func-env fobj) (params fobj) args) cont)))) Figure 19. Applying a \nprocedure (simpli.ed)  4.5 Implementing side effects We now discuss the implementation of side effects \nin our parallel interpreter. We discuss only the implementation of variable assignment (set!), because \nthe implementations for vector and list assignment are practically the same. To refresh our discussion \non side effects, consider the (contrived) loop example in Fig. 20.7 This loop iterates n times, and during \neach iteration, it increases the value of the variable x by 1, as long as the value of x is smaller than \nmax. There is one side effect in the loop, the assignment to x. The (sequential) semantics of the loop \ndictate that this assign\u00adment occurs after the check to see if x is bigger than max and before iteration \nn - 1. However, the implementation of variable assignment in our parallel evaluation strategy must explicitly \nmake sure this is the case. Our implementation exploits the continuator tree to .nd out when it is safe \nto perform a side effect and also to .g\u00adure out which computations were started prematurely and need \nto roll back. Consider the continuator tree drawn for our running example in Fig. 20. We know we can \nperform the assignment when the computations/continuators to the left of the set! continuator completed. \nWe can check this by following the parent pointers of the continuator for the set! and verifying that \nall of their children to the left have al\u00adready reported their results (Requirement 6 for implement\u00ading \nside effects in Section 3.5). Similarly, we know what computations potentially need to roll back: It \nis the compu\u00adtations/continuators to the right of the set! continuator that 7 Recall from Section 3.2 \nthat we parallelize subexpressions of begin. potentially read the old value of x and need to be retried \n(Requirement 7 in Section 3.5). (defmethod eval-set ((ctor continuator) exp env cont) (let ((set-ctor \n(make-set-continuator ctor exp env cont))) (let ((child (svref (children set-ctor) 0))) (call # eval \nchild (caddr exp) env (lambda (exp!) (call # accumulate-set child exp!)))))) (defmethod accumulate-set \n((ctor continuator) val) (if (expressions-issued-before-done-p ctor) (let ((set-ctor (parent ctor))) \n(set-binding (env set-ctor) (var-to-set set-ctor) val) (rollback-expressions-issued-after set-ctor) (update-argument \nset-ctor val 0) (funcall (cont set-ctor) ok)) (call # accumulate-set ctor val))) Figure 21. Variable \nassignment (simpli.ed) Fig. 21 shows the implementation of variable assignment. The method eval-set creates \na set! continuator and calls eval for computing the variable s new value. The interesting part is the \ncontinuation which calls accumulate-set. This function loops until it .nds out that all expressions that \nwere issued for evaluation before the set! expression .nished (via the function expressions-issued-before-done-p). \nThe code for expressions-issued-before-done-p is omit\u00adted, but it is a loop that follows the parent pointers \nstart\u00ading from the set! continuator (set-ctor) and checks the results these continuators have accumulated \nso far. The function expressions-issued-before-done-p has two cases, depending on whether it checks an \nif continuator or another type of continuator. By default, the children to the left of a particular continuator \nare all of its parent s children that have a smaller index. In case of an if continuator, how\u00adever, the \nonly child that is considered to be to the left of the continuator for the else branch is the continuator \nfor the test, excluding the continuator for the then branch. This is because either the then or the else \nbranch is selected in the end, and there is no point for an else computation to wait for a (squashed) \nthen computation! When all of the expressions issued before the assignment are done, accumulate-set performs \nthe actual assignment by overriding the value of the variable (set-binding). Then the expressions issued \nafter the set! expression are rolled back (via rollback-expressions-issued-after). The code for that \nis omitted: It is just a loop that follows the set! continuator s parent pointers, squashes those con\u00adtinuator \ns children to the right, and reissues them, by call\u00ading eval with the expressions that they stored in \nthe slot children-exps (see the de.nition of the continuator class in Fig. 10). Note that these rollbacks \ndo not need to undo any assignments because each assignment is a syn\u00adchronization point that waits for \nall of the expressions that are issued before. The squashing mechanism used to perform rollbacks is similar \nto what we de.ned in the previous sub\u00adsection for if expressions. The latter means that code with side \neffects requires all continuators to have an indirected message handler by default.  4.6 Summary and \nimplementation pitfalls In this section, we have introduced the continuator concept and have shown how \nit helps coordinating parallel argument evaluation, speculative branching, and side effects. All the \nrequirements listed in Section 3.5 are ful.lled: Requirements 1 and 2 (accumulating arguments that are \nevaluated in parallel, and delaying the continuation of a procedure call) are ful.lled by the procedure \ncall contin\u00aduator, as described in Section 4.3.  Requirements 3 and 4 (the ability to discard wrongly \nspeculated branches, without looping) are ful.lled by the message handler architecture, as described \nin Sec\u00adtion 4.4.1.  Requirement 5 (avoiding reports of errors that are thrown in wrongly speculated \nbranches) is ful.lled by wrapping errors and returning them as results that will eventually be discarded, \nas described in Section 4.4.2.  Requirements 6 and 7 (ensuring correct order of side ef\u00adfects, and rolling \nback computations that depend on side effects) are ful.lled by the set! continuator, as described in \nSection 4.5.  The code we presented is simpli.ed for explanation pur\u00adposes. There are, however, a number \nof implementation dif\u00ad.culties that we want to make the reader aware of: Continuator access must be \nsynchronized, and we follow a strict locking protocol to avoid deadlocks (.rst we lock the parent, then \nthe continuator itself), which pollutes our implementation with checks that the continuator we locked \nwas not squashed after we locked its parent and that its parent is really the same as the one we locked. \n When rolling back expressions for implementing side effects, we must .rst squash all expressions issued \nafter the side effect, and only then restart them. Otherwise we might squash and restart a continuator \nbefore those other expressions are squashed. Those may have remaining (but incorrect) results, and the \nrestarted continuator may trigger these continuators to complete.  We need to create the children of \na continuator right away when we create the continuator itself, even though we do not know what type \nof continuators these children should be. This is because they can be squashed before they are used for \nevaluation. Because of this, there are certain places in the interpreter that cast continuators to the \nright type (eval-fcall, eval-if, eval-set! and the interpreter functions for the other side effects). \n For interpreting the application of a non-primitive proce\u00addure, the interpreter reuses the continuator \nthat was gen\u00aderated for evaluating the expression that calls the proce\u00ad  dure. E.g. the procedure call \ncontinuator for (fac (-n 1))) is reused as continuator for evaluating its expansion into (if(<= n 2)2 \n(*n ...)). Otherwise there would be a hole in the continuator tree. 5. Validation We ran our parallel \ninterpreter on the Clinger benchmark suite for Scheme [14]. Although our interpreter is a proof of concept \nrather than an industrial-strength implementation of the ideas presented in this paper, the benchmarks \nalready show that the overhead of the continuator infrastructure is in an acceptable range and good speedups \nare possible. The Clinger benchmark suite for Scheme is a collection of different benchmark suites, including \nthe Gabriel bench\u00admarks [20], the Kernighan and Van Wyck benchmarks [38], and a set of numerical and \nother programs. The applications include simple programs like the Fibonnaci and Ackermann functions, \nbut also AI algorithms for solving puzzles, nu\u00admerical programs for computing fast Fourier transformations \nand Mandelbrot sets, a type checker, and so on. Our imple\u00admentation runs all of the programs, except \nfor the ones that rely on call/cc, which we do not support, as it is not clear what a continuation represents \nin our parallel interpreter. We also do not support the benchmarks for testing .le I/O. We ran our experiments \nusing 32-bit LispWorks 6.0 for Mac OS X, on an 8-core Mac Pro, equipped with two Quad-Core Intel Xeon \nNehalem processors (each 2.26GHz) and 8GB of 1066MHz DDR3 ECC SDRAM. In our benchmarks, we compare two \ninterpreters, namely our parallel interpreter and a sequential cps interpreter. These two interpreters \nonly differ in the implementation of the evaluation process. They share all of the code that im\u00adplements \nthe interpreter infrastructure, such as the code for representing environments, parser code, code for \nrepresent\u00ading Scheme values, and so on. Our benchmarks measure two things: 1) the memory overhead generated \nby the continuator infrastructure and 2) the speedups of the different programs. Fig. 22 shows the benchmark \nresults when a straightfor\u00adward implementation of a Scheme interpreter and continu\u00adators is used. It \nshows the speedup per benchmark using 2, 4, 6, and 8 threads. The graph maps the number of threads (X \naxis) onto the speedup factor (Y axis), which is com\u00adputed as Tseq , where Tseq is the runtime of a benchmark \nus- Tpar ing the sequential interpreter, and Tpar is the runtime using the parallel interpreter. Fig. \n22 reveals there are benchmarks that show speedups, but also benchmarks that show slow\u00addowns, as their \nspeedup factor is below 1. Using 8 threads, nqueens is about 1.6x faster, tak 1.8x, takl 3.5x, and .b \n1.3x. Additionally, these speedups scale with the number of cores. Programs that contain side effects \n(see paraf.ns!, fft!, and mbrot!, i.e. all benchmarks with a ! in their name) run 2 - 90x slower, but \nroughly in constant time, independent of the number of interpreter threads. That is not so surprising, \nas our implementation insists on sequentializing side effects, and consequently there is little parallelism \nto be exploited in programs with many side effects. There are some opportu\u00adnities to improve the way \nside effects are handled and we discuss them in Section 6.  Oddly enough, there are also some benchmark \nprograms without side effects that run slower, namely ack, an im\u00adplementation of the Ackermann function, \nand cps tak,a continuation-passing-style implementation of the Takeuchi function (see [20]). If we look \nat the execution traces of these programs, we observe that they do not produce bal\u00adanced trees, but rather \nunbalanced trees with linear structure. The nodes of these trees accumulate their results one by one, \nand consequently there is not much parallelism in the com\u00adputations. This is, for example, also the case \nfor the factorial function, for which we display the execution trace in Fig. 9 in Section 4.1. Computing \na factorial yields a chain of nested factorial calls which grows until the base case is reached and then \nthe actual result is computed by returning from the recursive calls and multiplying their results, one \nby one. The latter is inherently a sequential process, and such code can\u00adnot bene.t much from parallelization. \nIn contrast, if we look at the execution traces of the programs in Fig. 22 that yield a good speedup, \nwe observe that these programs produce more balanced execution trees, and this is because they have (some) \nimportant parts written in a tree-recursive style. In other words, programs written in a tree-recursive \nstyle are more likely to produce good speedups. However, program\u00adming in a tree-recursive style is not \nenforced by Scheme, which makes it dif.cult to parallelize existing programs.8 We can greatly improve \nthe benchmark results we just discussed by applying an optimization that targets functional 8 It is interesting \nto compare this to Fortress, which is a new multiprocessing language that is currently being developed \nat Sun Labs, and is designed to encourage programming in a tree-recursive style. We discuss Fortress \nin Section 7.5. Figure 23. Speedups (when optimized for functional code) code. A simple static analysis \nof the code can reveal the ab\u00adsence of side effects which allows us to remove a great deal of indirections \nin the continuator s message handlers. Fig. 23 shows the speedups that we get by using this optimization. \nWe see that the speedups are improved by at least a factor 2 compared to Fig. 22. Using 8 threads, nqueens \nis now 3.1x faster, tak 3.9x, takl 7.8x, and .b 3.6x. Note that for takl we even get a super linear speedup \nwhen using 2, 4, or 6 threads. The optimization does not remove the overall slowdowns for ack, and cps \ntak, nor does it help for code with lots of side effects (not shown). Fig. 24 shows the impact of the \ncontinuator infrastructure on memory usage. It shows the memory overhead per bench\u00admark using 2, 4, 6, \nand 8 threads. The graph maps the num\u00adber of threads (X axis) onto the overhead factor (Y axis), which \nis computed as Mpar where Mseq is the total amount Mseq of memory consumed using the sequential interpreter, \nand Mpar is the total amount of memory consumed using the parallel interpreter. The .gure reveals for \nnqueens, tak, takl, and .b, that parallel execution consumes 2 to 3 times more memory than sequential \nexecution. The .gure also shows that for these cases, the memory overhead grows very slowly and is almost \nindependent from the number of interpreter threads. The small increase of memory usage is because when \nthere are more interpreter threads, more of the wrongly speculated computations can execute, which creates \nunnec\u00adessary continuator and message objects. However, since the speedup for nqueens, tak, takl, and \n.b also increases with the number of threads (i.e. the results are computed faster), this effect is negligible. \nIn contrast, the memory overhead for ack and cps tak grows more steeply with the number of threads (see \nFig. 24). When discussing the speedups, we said that these programs currently do not give a speedup because \ntheir linear structure forces part of the computation to proceed se\u00adquentially. Because of this, the \neffect on memory overhead for speculating wrongly is more noticeable for ack and cps tak. In future work, \nwe plan to investigate better branch pre\u00addiction techniques: This should reduce the number of wrong speculations, \nand consequently also the extra memory over\u00adhead that it generates.  Memory usage is very different \nfor the benchmarks with side effects (fft!, paraf.ns!, mbrot!), where memory usage grows fast with the \nnumber of threads. This is because our interpreter synchronizes on every side effect and restarts all \ncomputations that come logically after the side effect, and these restarted computations need to create \nnew continua\u00adtor objects. Also, the more threads there are available, the further the computations that \nneed to restart may have pro\u00adgressed, which may have created plenty of continuator ob\u00adjects that are \nthen discarded. Note that the memory overhead for fft! grows spectacularly, and its graph is even cut \noff to keep Fig. 24 readable. This is because the fft! program con\u00adtains exceptionally many side effects, \nas it de.nes a huge number of variables which it initializes using assignments. To summarize: 1) There \nare some programs for which we get (linear) speedups, 2) the memory overhead of the contin\u00aduator infrastructure \nis a constant factor for these programs, and 3) programs with side effects run substantially slower using \nour approach, but this is due to our naive implementa\u00adtion for handling side effects and not because \nof the overhead of the continuator infrastructure. Given these observations, we conclude that the overhead \nof the continuator infrastruc\u00adture can be minimized and is in an acceptable range, but also that there \nis plenty of room for optimizations to realize a proper implementation of our approach. 6. Outlook: Integration \ninto virtual machines Apart from the fact that our interpreter automatically paral\u00adlelizes Scheme programs, \nit is otherwise a very traditional interpreter that does not use any of the known techniques to speed \nup programs by way of just-in-time or dynamic com\u00adpilation. The reason is mainly because our goal was \nto focus our attention on understanding how automatic paralleliza\u00adtion of recursive code could work, \nand studying a parallel interpreter helped us discover the continuator concept. Parallelizing an interpreter \nalone is, of course, not enough. One approach to reusing our ideas would be in a compiler that generates \ncode to spawn concurrent tasks for argument expressions in procedure calls, and speculative branching \nin conditional statements. Continuators can then be introduced by the compiler as well to track and manage \nthe runtime de\u00adpendences, just as described in this paper. We are convinced that reusing the continuator \nconcept in a compilation set\u00adting should be straightforward, since we were already able to reuse the \ncontinuator concept unchanged in a non-trivial variation of our interpreter that is organized as a pipeline \n(not discussed in this paper). Integration with a compiler can have the advantage that static analysis \ntechniques could be used to determine which side effects are strictly local (such as local assignments \nto initialize freshly allocated data structures, or local assignments to iteration variables that are \notherwise not accessed). See [4, 37] for an overview of such analysis techniques. However, we actually \nbelieve that the ideas of this pa\u00adper could more effectively be used in a dynamic compila\u00adtion setting: \nVirtual machine implementations like HotSpot for Java [41], V8 [26] and TraceMonkey [23] for JavaScript, \nand LuaJIT for Lua [48], to name just a few, actually ini\u00adtially execute code in interpreted mode, but \nmonitor the in\u00adterpretation to discover hot regions of commonly executed code or code paths, which can \nthen be compiled at runtime to speed up overall execution of a program. The idea is that most of the \ntime, only small parts of a program are executed, and that dynamic compilation can then spend its resources \non optimizing the identi.ed hot regions. For such optimiza\u00adtions, the dynamic compiler can then take \nruntime informa\u00adtion into account that was gathered by the virtual machine and that would otherwise not \nbe available to a purely static compiler. (See also [6] for a historical overview of just-in\u00adtime compilation.) \nOur hypothesis is that automatic parallelization of recur\u00adsive code and continuators, as presented in \nthis paper, could be integrated into such a virtual machine architecture. On the one hand, the static \nanalysis techniques for distinguishing between local and global side effects could be reused when compiling \nthe hot code regions to reduce the observed neg\u00adative impact of assignments by forcing such code to execute \nsequentially. On the other hand, the virtual machine could perform fur\u00adther analyses at runtime: For \nexample, it could measure both sequential and parallel execution of the same code regions, and subsequently \nrun only those regions in parallel that ac\u00adtually bene.t from such parallelization. The virtual machine \ncould also attempt to limit the amount of parallelism that is generated, by parallelizing argument expressions \nand condi\u00adtional statements only to a certain depth in the computation tree, again steered by previously \nmonitored runtime informa\u00adtion (as already done in Qlisp [25, 49, 65]). In other words, the virtual machine \ncould perform a variant of auto-tuning at runtime. To summarize, we believe that the notion of au\u00adtomatically \nparallelizing recursive code using continuators opens up a number of exciting avenues for future virtual \nma\u00adchine research.  7. Related work and further discussion 7.1 Parallelizing compilers Automatic parallelization \nhas been a major research topic since the 1960 s [37]. The focus of that research is .nding new compilation \ntechniques, mostly in the context of For\u00adtran. Note that the term automatic parallelization is used for \ntwo different kinds of compiler research (see Chapter 1 of [37]). It is used for referring to compilers \nthat optimize code so that it better exploits the parallel design of pipelined pro\u00adcessors, but the term \nis also used for referring to compilation techniques that parallelize programs at a coarser grain by \nmapping code onto threads to run on multicore processors. Our own work is similar to the latter kind \nof research as we want to parallelize sequential programs so that they can bet\u00adter bene.t from multicore \nprocessors. We observe that the main sources of parallelism that is considered in the literature are \nloops, as it is in principle pos\u00adsible to map the different iterations of a loop onto different threads. \nThe major dif.culty is that, in order to preserve the sequential semantics, the execution of these threads \nmust re\u00adspect the data dependences between the iterations. That is, the execution must respect the order \nof the side effects. Some approaches allow parallelizing only loops for which it can be statically determined \nthat there are no dependences between the iterations that may cause a faulty parallel execution. The \nfocus of these approaches is .nding better static analysis techniques to improve discovery of dependences \n[37], tech\u00adniques for rearranging code to improve data locality [9], and .nding ways for transforming \nloops so there are less de\u00adpendences between iterations [4, 10]. In contrast, software speculation approaches \nallow parallelizing arbitrary loops, but they foresee runtime mechanisms for detecting and un\u00addoing dependence \nviolations. Current research on software speculation focuses on .nding ways to reduce the memory overhead \nassociated with runtime dependence checking, ei\u00adther by .nding better dependence checking algorithms \nand implementations [54], or by reducing the number of threads that are generated or activated at the \nsame time [12, 52]. In our work, we focus on automatically parallelizing re\u00adcursive code, rather than \nloops. For parallelizing loops, the iterations are mapped onto threads, but recursive code re\u00adquires \na different way of extracting parallelism. Work on parallel programming languages suggests constructs \nfor par\u00adallel procedure calling and speculative computation. We pro\u00adpose a virtual machine that combines \nparallel procedure call\u00ading and speculative branching as default execution strategies. Our contribution \nis the continuator concept for managing the control .ow interactions between parallel argument evalua\u00adtion, \nspeculative branching and side effects. However, similar to the case of loops, we also require a mechanism \nfor handling data dependences between the parallel tasks. Our continuator infrastructure allows hooking \nin such a mechanism, but as we discussed, we have only tried a conservative way of handling data dependences \n(every side effect is a synchronization point). It would be interesting to reuse the ideas for managing \ndata dependences in loop parallelization. We could for example add a preprocessing step to our virtual \nmachine that performs a static analysis of the code to detect data dependences, e.g. to mark (local) \nvariables that can be safely updated in parallel. Perhaps one obstacle is that most of the existing depen\u00addence \nanalyses focus on statically allocated arrays, but recur\u00adsive code often operates on more complex data \nstructures. There is more advanced work by Rugina and Rinard [53] on dependence analysis in the context \nof divide and conquer algorithms where the focus is on dynamically allocated ar\u00adrays. An alternative \nstrategy for handling side effects would be to opt for a runtime mechanism for handling dependence violations \nas used in loop parallelization based on software speculation [12], or reuse previous work on software \ntrans\u00adactions [15, 32, 42].  7.2 Processor parallelism Exploiting parallelism has always been a key \noptimization strategy in processor design. In fact, it is the key idea be\u00adhind pipelined and multiple \nissue processors, which, before multicores came along, dominated the desktop market [30]. Pipelined processors \nparallelize the execution of a program as it runs, as their components (or stages) are organized in such \na way that subsequent instructions are executed in an overlapping manner. Various updates of the basic \npipelined design is what steadily improved the performance of unipro\u00adcessors for the past twenty years. \nHowever, due to various technical limitations, involving heat production and power consumption, hardware \nmanufacturers can no longer im\u00adprove upon the current pipelined designs in a cost-effective way [30], \nand instead focus shifted to multicores. The big difference with previous designs is that multicores \ndo not automatically make use of the available parallelism. That is, the hardware is not responsible \nfor automatically distribut\u00ading program execution over the different cores. In multicore designs, that \nis the software s responsibility. Our idea is to transfer the notion of runtime paralleliza\u00adtion in hardware \nto the virtual machine. The difference is that our virtual machine operates on a coarser tree-based program \nrepresentation than the pipelined hardware, which operates on .at machine code. This tree-based program \nrep\u00adresentation is the basis for spreading execution over different processors, but it also introduces \nnew complexity.  The major idea from hardware parallelization that we ex\u00adplore in this paper is speculative \nbranching. A branch in\u00adstruction in machine code consists of a test instruction and a jump instruction \nthat tells the processor what to execute next when the test instruction is true. This means the processor \nhas to execute the test instruction before it can select the next instruction to execute. Because of \nthis, the pipeline s use is suboptimal, as the test instruction needs to be completely done before the \nnext instruction can start executing. A pro\u00adcessor with speculative branching speculates on the next \nin\u00adstruction, e.g. the one from the branch, to keep the pipeline busy. When the test is known and it \nturns out the processor speculated wrongly, the speculated instruction is squashed by clearing everything \nin the pipeline that is behind the test instruction. The hardware often implements branch predic\u00adtion \nto speculate on the instruction that most likely comes next, e.g. by making guesses based on the outcomes \nof the test for previous executions. In this paper, we propose to execute high-level condi\u00adtional constructs \nspeculatively. The major dif.culty is that the squashing mechanism becomes more complicated. In the case \nof the pipelined processor, it is easier to .nd the compu\u00adtations that need to be squashed, as it is \njust whatever is in the pipeline right after the test instruction. Also, machine code is .at, and it \nis known for each instruction what registers it accesses and hence what data dependences exist between \nin\u00adstructions. In contrast, in our system, the execution of condi\u00adtionals is scattered over different \nconcurrent processors and it is not known what variables, arrays, etc. an expression is going to access. \nOur contribution is that we explore specu\u00adlative branching in the context of high-level language con\u00adstructs \nand that we show how squashing can be supported using the continuator concept. We are aware of a couple \nof other software systems that support speculative branching for high-level conditionals [45, 47], but \nnone of these ap\u00adproaches correctly handles squashing of wrongly speculated computations (see Section \n7.4). We have not yet explored branch prediction in our system and leave this as a topic for future work. \n 7.3 Multiprocessing languages An alternative to automatic parallelization is explicit paral\u00adlel programming, \nas supported by multiprocessing languages such as Qlisp [21], Multilisp [28], and Cilk [8]. Qlisp and \nMultilisp are Lisp dialects, whereas Cilk is an extension of C. Cilk introduces a spawn construct for \nlaunching paral\u00adlel tasks and a construct called sync for marking where the code needs to wait for those \ntasks to .nish. Qlisp introduces the qlambda construct for creating functions whose bodies are evaluated \nas parallel tasks, a construct pcall for call\u00ading a function whose argument expressions are processed \nin parallel, and a synchronization construct called wait. Multi\u00adlisp also has the pcall construct and \nintroduces the future construct for evaluating an expression in a new thread. The return value of such \na future call is a special future object to which the spawned thread (eventually) writes back its result. \nThe idea is that the execution can proceed from a future call, using the future object as the future \ncall s return value. When the Multilisp implementation tries to apply a primitive function with such \na future object, it is supposed to use the result that is written back to the future object, and the \nimple\u00admentation blocks the primitive application until this is the case. Hence in Multilisp, no explicit \ntask synchronization is necessary. In our approach, the virtual machine is responsible for choosing where \nto spawn parallel tasks. It performs parallel argument evaluation and speculative branching by default, \nand the continuator infrastructure is responsible for synchro\u00adnizing the spawned tasks. In other words, \nthe language con\u00adstructs from Qlisp, Multilisp, and Cilk are absorbed by the virtual machine. There seems \nto be a strong relation between futures and continuators. Future objects collect the result of a parallel \ntask, and they force function applications to block until the result is known. Similarly, continuators \naccumulate the re\u00adsults of different parallel tasks and delay their continuation. The difference between \nfuture objects and continuators is that the future object introduces a single point of synchro\u00adnization \nin the implementation, namely for primitive func\u00adtion application, whereas the continuator infrastructure \nin\u00adtroduces multiple synchronization points, namely for evalua\u00adtion of procedure calls, if, set!, vector-set!, \nset-car! and set-cdr! expressions. The continuator is designed for implementing automatic parallel argument \nevaluation and speculative branching, and it is not clear if this can be done using future objects alone. \nA major contribution of multiprocessing languages like Qlisp, Multilisp, and Cilk is that they introduced \nand devel\u00adoped very advanced work-stealing schedulers [7, 8, 21, 28, 49], which are being picked up by \nmodern multiprocessing languages such as Fortress [11] and X10 [3]. Our interpreter similarly implements \na runtime architecture based on work\u00adstealing. The implementation itself is, however, a straight\u00adforward \none. It would be interesting to run our benchmarks with one of these more advanced work-stealing schedulers, \nwhere data structures, synchronization points, and schedul\u00ading strategies are heavily optimized [2, 3, \n7, 8, 11].  7.4 Speculative computation Speculative computation is a parallelization strategy where \ncomputations are executed before they are known to be re\u00adquired [45, 47, 50]. It has been implemented \nin Multilisp and Qlisp, where it appears in the form of parallel variants of constructs like funcall, \nand, or, and if. Experiments with speculative computation are promising: For example, for certain Multilisp \napplications, a speedup factor of 26 was reported [47]. However, speculative computation is very dif\u00ad.cult \nto implement, and it is currently not supported by any production language.  There are a couple of problems \nwith the implementation of speculative computation in Multilisp. In particular, a cor\u00adrect implementation \nof discarding threads does not seem re\u00adalized (see Chapter 10 of [46]), and discarding of threads may \nlag behind new threads being spawned. In [46], the author argues that this should not occur in concrete \nexecu\u00adtions because, in the existing implementation of Multilisp, the concrete time to spawn a new thread \nis much higher than the time for aborting a thread. As such, the problem should not occur. This is a \nshaky reasoning at best, and not a solu\u00adtion for implementing speculative computation correctly. A similar \nstory can be found in a paper that reports on the parallel implementation of a rule-based production \nsystem in Qlisp [45]. The authors claim that speculative evaluation is bene.cial for this application, \nand propose to add a specu\u00adlative construct sfcall to Qlisp for speculatively executing a function. However, \nthey acknowledge they were unable to implement a mechanism to correctly discard wrongly spec\u00adulated computations. \nIt seems that a correct implementation for correctly discarding wrongly speculative computations is lacking \nin existing systems [45, 47, 50]. In the virtual machine we propose, conditional expres\u00adsions are by \ndefault executed speculatively. We did not in\u00advestigate speculative execution of other types of expres\u00adsions, \nbut we are con.dent that they can be supported by the continuator infrastructure as well (since or and \nand can be macroexpanded into if [56]). Also, our implementation based on continuators and message handlers \nmakes it pos\u00adsible to squash wrongly speculated computations without freezing the execution and guarantees \nthat wrongly spec\u00adulated computations do not keep spawning new tasks. We think this a fundamental contribution. \n 7.5 Fortress, an implicit parallel language Fortress [5] is a new programming language that is designed \nfor high-performance computing and is currently being de\u00adveloped at Sun Labs. What sets Fortress apart \nfrom other multiprocessing languages is that it is an implicit parallel language in which the programmer \ndoes not need to intro\u00adduce parallelism explicitly. Instead, the semantics of Fortress are de.ned so \nthat the arguments of an operator may execute in parallel [60]. The programmer must take these parallel \nsemantics into account when writing programs, e.g. side ef\u00adfects must be synchronized explicitly using \natomic blocks. One of the key ideas behind Fortress is to replace the ba\u00adsic linear data structures (i.e. \nvectors and lists) with the conc data structure, which organizes data as a tree. Iteration code for the \nconc is written in a tree-recursive style, and the claim is that such code bene.ts more from parallelization \nthan it\u00aderation code that operates on linear data structures [60]. Our own experiments con.rm this observation, \nas our bench\u00admarks show the best results for programs where important parts are written in a tree-recursive \nstyle. There is obviously an overlap between Fortress and our own work, albeit our starting points are \ndifferent. Whereas Fortress s goal is to develop a new multiprocessing language in which it is easy to \nwrite code that is optimal for par\u00adallel execution, our goal is to .nd out how we can auto\u00admatically \nparallelize existing recursive programs. Similar to our approach, Fortress uses parallel argument evaluation \nas one means to introduce parallelism in a program s execution. However, on top of that, we provide speculative \nevaluation of conditional expressions, and we sequentialize the behav\u00adior of side effects. 8. Summary \nand conclusions In this paper we explore the idea of a work-stealing virtual machine that automatically \nparallelizes recursive code by combining parallel procedure calling and speculative execu\u00adtion of conditionals \nas default execution strategies. Our con\u00adtribution is the continuator concept for managing the control \n.ow interactions between parallel procedure calling, specu\u00adlative branching, and side effects. The idea \nis to represent the execution trace as a tree where we use continuators to rep\u00adresent its nodes. The \ncontinuators are used for accumulating and reducing the results of parallel computations. Also, they \nguarantee discarding computations issued by wrong specu\u00adlation without having to freeze the interpreter, \nand they make rollbacks possible for handling side effects. As a proof of concept implementation, we \npresent a par\u00adallel Scheme interpreter that implements our approach. We choose Scheme because it is a \nminimal language in which it is possible to write anywhere on the spectrum of very functional code to \nvery imperative code. As a validation, we show the results of our interpreter running the Clinger benchmark \nsuite for Scheme. The numbers show (linear) speedups for functional code where important parts are writ\u00adten \nin a tree-recursive style. Programs with side effects in general run slower, but in a constant execution \ntime inde\u00adpendent from the number of available processor cores. Our hypothesis is that automatic parallelization \nof recur\u00adsive code and continuators, as presented in this paper, could be integrated into a full-.edged \nvirtual machine architecture. In future work, we plan to move our implementation to a vir\u00adtual machine \nthat performs just-in-time and dynamic compi\u00adlation. In such an architecture, we could reuse existing \ncom\u00adpilation techniques for improving the way side effects are handled, e.g. by adding a static analysis \nstep to detect side effects that can execute in parallel, or by deciding to exe\u00adcute highly imperative \ncode sequentially. Also, the virtual machine could perform further analyses at runtime, and it could \nmeasure both sequential and parallel execution of the same code regions, and subsequently only run those \nregions in parallel that actually bene.t from such parallelization.  Acknowledgments We thank our shepherd \nRichard P. Gabriel for his support and advice to improve this paper. A very big thank you goes to Dave \nFox, Usha Millar, and Martin Simmons from LispWorks R . for letting us use an alpha version of Lisp-Work \n6.0 since early 2008. Our work would not have been possible without LispWorks 6.0 and its support for \nmulti\u00adprocessing. It is truly an amazing piece of technology that sets a very high standard for multiprocessing \nsupport in Lisp and other dynamic languages. We thank the partici\u00adpants of the POOSC 08 workshop (at \nECOOP 08) where our initially vague ideas were warmly received and dis\u00adcussed. We also thank Theo D Hondt, \nWolfgang De Meuter, Guy L. Steele Jr., Luc Steels, and Stijn Verhaegen for their comments on earlier \ndrafts of this paper and other discus\u00adsions on this work. Charlotte Herzeel s research is funded by a \ndoctoral scholarship of the Institute for the Promotion of Innovation through Science and Technology \nin Flanders (IWT-Vlaanderen). References [1] H. Abelson and G. J. Sussman. Structure and Interpretation \nof Computer Programs. MIT Press, Cambridge, MA, USA, 1996. ISBN 0262011530. [2] U. A. Acar, G. E. Blelloch, \nand R. D. Blumofe. The data locality of work stealing. In SPAA 00: Proceedings of the twelfth annual \nACM symposium on Parallel algorithms and architectures, pages 1 12, New York, NY, USA, 2000. ACM. ISBN \n1-58113-185-2. doi: http://doi.acm.org/10.1145/ 341800.341801. [3] S. Agarwal, R. Barik, D. Bonachea, \nV. Sarkar, R. K. Shya\u00admasundar, and K. Yelick. Deadlock-free scheduling of X10 computations with bounded \nresources. In SPAA 07: Pro\u00adceedings of the nineteenth annual ACM symposium on Paral\u00adlel algorithms and \narchitectures, pages 229 240, New York, NY, USA, 2007. ACM. ISBN 978-1-59593-667-7. doi: http://doi.acm.org/10.1145/1248377.1248416. \n[4] A. V. Aho, M. S. Lam, R. Sethi, and J. D. Ullman. Compilers: Principles, Techniques, &#38; Tools \nwith Gradiance. Addison-Wesley Publishing Company, USA, 2007. ISBN 0321547985, 9780321547989. [5] E. \nAllen, D. Chase, J. Hallett, V. Luchangco, J.-W. Maessen, S. Ryu, G. L. Steele, Jr., and S. Tobin-Hochstadt. \nThe Fortress Language Speci.cation, version 1.0, March 2008. [6] J. Aycock. A brief history of just-in-time. \nACM Comput. Surv., 35(2):97 113, 2003. ISSN 0360-0300. doi: http://doi. acm.org/10.1145/857076.857077. \n[7] R. D. Blumofe and C. E. Leiserson. Scheduling multithreaded computations by work stealing. J. ACM, \n46(5):720 748, 1999. ISSN 0004-5411. doi: http://doi.acm.org/10.1145/324133. 324234. [8] R. D. Blumofe, \nC. F. Joerg, B. C. Kuszmaul, C. E. Leiserson, K. H. Randall, and Y. Zhou. Cilk: an ef.cient multithreaded \nruntime system. SIGPLAN Not., 30(8):207 216, 1995. ISSN 0362-1340. doi: http://doi.acm.org/10.1145/209937.209958. \n[9] U. Bondhugula, A. Hartono, J. Ramanujam, and P. Sadayap\u00adpan. A practical automatic polyhedral parallelizer \nand locality optimizer. SIGPLAN Not., 43(6):101 113, 2008. ISSN 0362\u00ad1340. doi: http://doi.acm.org/10.1145/1379022.1375595. \n[10] P. Boulet, A. Darte, G.-A. Silber, and F. Vivien. Loop par\u00adallelization algorithms: from parallelism \nextraction to code generation. Parallel Comput., 24(3-4):421 444, 1998. ISSN 0167-8191. doi: http://dx.doi.org/10.1016/S0167-8191(98) \n00020-9. [11] D. Chase and Y. Lev. Dynamic circular work-stealing deque. In SPAA 05: Proceedings of the \nseventeenth annual ACM symposium on Parallelism in algorithms and architectures, pages 21 28, New York, \nNY, USA, 2005. ACM. ISBN 1-58113-986-1. doi: http://doi.acm.org/10.1145/1073970. 1073974. [12] M. Cintra \nand D. R. Llanos. Toward ef.cient and robust soft\u00adware speculative parallelization on multiprocessors. \nIn PPoPP 03: Proceedings of the ninth ACM SIGPLAN symposium on Principles and practice of parallel programming, \npages 13 24, New York, NY, USA, 2003. ACM. ISBN 1-58113-588-2. doi: http://doi.acm.org/10.1145/781498.781501. \n[13] M. Cintra and D. R. Llanos. Design space exploration of a software speculative parallelization scheme. \nIEEE Trans. Parallel Distrib. Syst., 16(6):562 576, 2005. ISSN 1045\u00ad9219. doi: http://dx.doi.org/10.1109/TPDS.2005.69. \n[14] W. Clinger. Twobit and Larceny benchmark suite. http://www.ccs.neu.edu/home/will/Twobit/. [15] P. \nCostanza, C. Herzeel, and T. D Hondt. Context-oriented Software Transactional Memory in Common Lisp. \nIn DLS 09: Proceedings of the 5th symposium on Dynamic lan\u00adguages, pages 59 68, New York, NY, USA, 2009. \nACM. ISBN 978-1-60558-769-1. doi: http://doi.acm.org/10.1145/ 1640134.1640144. [16] L. G. DeMichiel and \nR. P. Gabriel. The Common Lisp Ob\u00adject System: an overview. In European conference on object\u00adoriented \nprogramming on ECOOP 87, pages 151 170, Lon\u00addon, UK, 1987. Springer-Verlag. ISBN 0-387-18353-1. [17] \nT. D Hondt. Are Bytecodes an Atavism? In Self-Sustaining Systems: First Workshop, S3 2008 Potsdam, Germany, \nMay 15-16, 2008 Revised Selected Papers, pages 140 155, Berlin, Heidelberg, 2008. Springer-Verlag. ISBN \n978-3-540-89274\u00ad 8. doi: http://dx.doi.org/10.1007/978-3-540-89275-5 8. [18] J. Dongarra, I. Foster, \nG. Fox, W. Gropp, K. Kennedy, L. Torc\u00adzon, and A. White, editors. Sourcebook of parallel computing. Morgan \nKaufmann Publishers Inc., San Francisco, CA, USA, 2003. ISBN 1-55860-871-0. [19] D. P. Friedman and M. \nWand. Essentials of Programming Languages, 3rd Edition. The MIT Press, 2008. ISBN 0262062798, 9780262062794. \n[20] R. P. Gabriel. Performance and evaluation of LISP sys\u00adtems. Massachusetts Institute of Technology, \nCambridge, MA, USA, 1985. ISBN 0-262-07093-6. [21] R. P. Gabriel and J. McCarthy. Queue-based multi-processing \nLISP. In LFP 84: Proceedings of the 1984 ACM Sympo\u00adsium on LISP and functional programming, pages 25 \n44, New York, NY, USA, 1984. ACM. ISBN 0-89791-142-3. doi: http://doi.acm.org/10.1145/800055.802019. \n [22] R. P. Gabriel and G. L. Steele, Jr. A pattern of language evolution. In C. Herzeel, editor, LISP50: \nCelebrating the 50th Anniversary of Lisp, pages 1 10, New York, NY, USA, 2008. ACM. ISBN 978-1-60558-383-9. \ndoi: http://doi.acm.org/10. 1145/1529966.1529967. [23] A. Gal, B. Eich, M. Shaver, D. Anderson, D. Mandelin, \nM. R. Haghighat, B. Kaplan, G. Hoare, B. Zbarsky, J. Oren\u00addorff, J. Ruderman, E. W. Smith, R. Reitmaier, \nM. Bebenita, M. Chang, and M. Franz. Trace-based just-in-time type spe\u00adcialization for dynamic languages. \npages 465 478, 2009. doi: http://doi.acm.org/10.1145/1542476.1542528. [24] R. Goldman and R. P. Gabriel. \nPreliminary results with the ini\u00adtial implementation of Qlisp. In LFP 88: Proceedings of the 1988 ACM \nconference on LISP and functional programming, pages 143 152, New York, NY, USA, 1988. ACM. ISBN 0\u00ad89791-273-X. \ndoi: http://doi.acm.org/10.1145/62678.62696. [25] R. Goldman and R. P. Gabriel. Qlisp: Parallel Processing \nin Lisp. IEEE Software, 6(4):51 59, 1989. doi: doi:10.1109/52. 31652. [26] Google. V8 JavaScript Engine. \nhttp://code.google.com/p/v8/. [27] J. Gosling and H. McGilton. The Java Language Environment: A White \nPaper. Technical report, Sun Microsystems, Menlo Park, CA, USA, May 1996. [28] R. H. Halstead. Multilisp: \nA language for concurrent symbolic computing. ACM transactions on languages and systems,7 (4):501 538, \n1985. [29] T. Harris and K. Fraser. Language Support for Lightweight Transactions. OOPSLA 03, Proceedings, \n2003. ISSN 0362\u00ad1340. doi: http://doi.acm.org/10.1145/949343.949340. [30] J. L. Hennessy and D. A. Patterson. \nComputer Architecture: a quantitative approach. Morgan Kaufmann Publishers, San Francisco, CA, USA, fourth \nedition, 2007. [31] C. Herzeel, P. Costanza, and T. D Hondt. Controlling dynamic parallelization through \nlayered re.ection. In 7th Work\u00adshop on Parallel/High-Performance Object-Oriented Scien\u00adti.c Computing \n(POOSC 08) , 2008. [32] C. Herzeel, P. Costanza, and T. D Hondt. An Extensible Inter\u00adpreter Framework \nfor Software Transactional Memory. Jour\u00adnal of Universal Computer Science, 16(2):221 245, 2010. [33] \nW. Horwat. Mozilla Javascript repository. http://mxr.mozilla.org/mozilla/source/js2/semantics/, 11 1999. \n[34] P. Hudak. Yale Haskell 91 implementation. http://www.haskell.org/haskellwiki/Implementations, 10 \n1991. [35] Intel. Intel Cilk SDK Programmer s Guide. http://software.intel.com/en-us/articles/intel-cilk/. \n[36] A. C. Kay. The early history of Smalltalk. SIGPLAN Not., 28(3):69 95, 1993. ISSN 0362-1340. doi: \nhttp://doi.acm.org/ 10.1145/155360.155364. [37] K. Kennedy and J. R. Allen. Optimizing compilers for \nmodern architectures: a dependence-based approach. Morgan Kauf\u00ad mann Publishers Inc., San Francisco, \nCA, USA, 2002. ISBN 1-55860-286-0. [38] B. W. Kernighan and C. J. Van Wyk. Timing trials, or the trials \nof timing: experiments with scripting and user-interface lan\u00adguages. Software: Practice and Experience, \n28(8):819 843, 1998. ISSN 0038-0644. doi: http://dx.doi.org/10.1002/(SICI) 1097-024X(19980710)28:8.819::AID-SPE184.3.3.CO;2-F. \n[39] G. Kiczales, J. Lamping, A. Menhdhekar, C. Maeda, C. Lopes, J.-M. Loingtier, and J. Irwin. Aspect-oriented \nprogramming. In M. Aks\u00b8it and S. Matsuoka, editors, Proceedings European Conference on Object-Oriented \nProgramming, volume 1241, pages 220 242, Berlin, Heidelberg, and New York, 1997. Springer-Verlag. [40] \nT. Kistler and M. Franz. A Tree-Based Alternative to Java Byte-Codes. Int. J. Parallel Program., 27(1):21 \n33, 1999. ISSN 0885-7458. doi: http://dx.doi.org/10.1023/A: 1018740018601. [41] T. Kotzmann, C. Wimmer, \nH. M\u00a8ossenb\u00a8ock, T. Rodriguez, K. Russell, and D. Cox. Design of the Java HotSpotTMclient compiler for \nJava 6. ACM Trans. Archit. Code Optim., 5(1):1 32, 2008. ISSN 1544-3566. doi: http://doi.acm.org/10.1145/ \n1369396.1370017. [42] J. R. Larus and R. Rajwar. Transactional Memory. Morgan Claypool Publishers, USA, \n2007. ISBN 1-59829-124-6. [43] H. Masuhara, G. Kiczales, and C. Dutchyn. A compilation and optimization \nmodel for aspect-oriented programs. In CC 03: Proceedings of the 12th international conference on Com\u00adpiler \nconstruction, pages 46 60, Berlin, Heidelberg, 2003. Springer-Verlag. ISBN 3-540-00904-3. [44] J. McCarthy. \nHistory of LISP. In History of programming languages I, pages 173 185, New York, NY, USA, 1981. ACM. \nISBN 0-12-745040-8. doi: http://doi.acm.org/10.1145/ 800025.1198360. [45] H. G. Okuna and A. Gupta. Parallel \nExecution of OPSS in QLISP. Technical report, Stanford University, Stanford, CA, USA, 1987. [46] R. B. \nOsborne. Speculative Computation in Multilisp. PhD thesis, Massachusetts Institute of Technology, December \n1989. [47] R. B. Osborne. Speculative Computation in Multilisp. In LFP 90: Proceedings of the 1990 ACM \nconference on LISP and functional programming, pages 198 208, New York, NY, USA, 1990. ACM. ISBN 0-89791-368-X. \ndoi: http://doi.acm. org/10.1145/91556.91644. [48] M. Pall. The LuaJIT Project. http://luajit.org/. [49] \nJ. D. Pehoushek and J. S. Weening. Low-cost process cre\u00adation and dynamic partitioning in Qlisp. In Proceedings \nof the US/Japan workshop on Parallel Lisp on Parallel Lisp: lan\u00adguages and systems, pages 182 199, New \nYork, NY, USA, 1990. Springer-Verlag New York, Inc. ISBN 0-387-52782-6. [50] S. L. Peyton Jones. Parallel \nimplementations of functional programming languages. Comput. J., 32(2):175 186, 1989. ISSN 0010-4620. \ndoi: http://dx.doi.org/10.1093/comjnl/32.2. 175. [51] C. Queinnec. Lisp in small pieces. Cambridge University \nPress, New York, NY, USA, 1996. ISBN 0-521-56247-3.  [52] C. Quinones, C. Madriles, J. S\u00b4anchez, P. \nMarcuello, A. Gonz\u00b4 alez, and D. M. Tullsen. Mitosis compiler: an infras\u00adtructure for speculative threading \nbased on pre-computation slices. SIGPLAN Not., 40(6):269 279, 2005. ISSN 0362\u00ad1340. doi: http://doi.acm.org/10.1145/1064978.1065043. \n[53] R. Rugina and M. Rinard. Automatic parallelization of di\u00advide and conquer algorithms. In PPoPP 99: \nProceedings of the seventh ACM SIGPLAN symposium on Principles and practice of parallel programming, \npages 72 83, New York, NY, USA, 1999. ACM. ISBN 1-58113-100-3. doi: http: //doi.acm.org/10.1145/301104.301111. \n[54] P. Rundberg and P. Stenstr\u00a8Low-cost thread-level data om. dependence speculation on multiprocessors. \nIn Proc. of the workshop on Multithreading Execution and Compilation at MICRO-33, 2000. [55] S. J. Russell \nand P. Norvig. Arti.cial Intelligence: A Modern Approach. Pearson Education, 2003. ISBN 0137903952. [56] \nM. Sperber, R. K. Dybvig, M. Flatt, A. van Straaten, R. Kelsey, W. Clinger, J. Reese, R. B. Findler, \nand J. Matthews. Revised6 Report on the Algorithmic Language Scheme, September 2007. [57] G. L. Steele, \nJr. LAMBDA: The Ultimate Declarative. Techni\u00adcal report, Massachusetts Institute of Technology, Cambridge, \nMA, USA, 1976. [58] G. L. Steele, Jr. Debunking the Expensive Procedure Call Myth or, Procedure Call \nImplementations Considered Harm\u00adful or, LAMDBA: The Ultimate GOTO. Technical report, Massachusetts Institute \nof Technology, Cambridge, MA, USA, 1977. [59] G. L. Steele, Jr. Rabbit: A Compiler for Scheme. Technical \nre\u00adport, Massachusetts Institute of Technology, Cambridge, MA, USA, 1978. [60] G. L. Steele, Jr. Organizing \nFunctional Code for Par\u00adallel Execution; or, foldl and foldr Considered Slightly Harmful. Keynote at \nthe 14th ACM SIGPLAN Interna\u00adtional Conference on Functional Programming (ICFP 2009), http://www.vimeo.com/6624203, \n2009. [61] G. L. Steele, Jr. and G. J. Sussman. Lambda: The Ultimate Imperative. Technical report, Massachusetts \nInstitute of Tech\u00adnology, Cambridge, MA, USA, 1976. [62] G. L. Steele, Jr. and G. J. Sussman. The Art \nof the Inter\u00adpreter or, The Modularity Complex (Parts Zero, One, and Two). Technical report, Massachusetts \nInstitute of Technol\u00adogy, Cambridge, MA, USA, 1978. [63] G. L. Steele, Jr and G. J. Sussman. Design of \nLISP-based processors, or SCHEME: A Dielectric LISP, or Finite Mem\u00adories Considered Harmful, or LAMBDA: \nThe Ultimate Op\u00adcode. Technical report, Massachusetts Institute of Technol\u00adogy, Cambridge, MA, USA, 1979. \n[64] G. J. Sussman and G. L. Steele, Jr. An Interpreter for Extended Lambda Calculus. Technical report, \nMassachusetts Institute of Technology, Cambridge, MA, USA, 1975. [65] J. Weening. Parallel execution \nof Lisp programs. PhD thesis, Stanford Comput. Sci. Rep. STANCS-89-1265, June 1989.    \n\t\t\t", "proc_id": "1869459", "abstract": "<p>While most approaches to automatic parallelization focus on compilation approaches for parallelizing loop iterations, we advocate the need for new virtual machines that can parallelize the execution of recursive programs. In this paper, we show that recursive programs can be effectively parallelized when arguments to procedures are evaluated concurrently and branches of conditional statements are speculatively executed in parallel. We introduce the <i>continuator</i> concept, a runtime structure that tracks and manages the control dependences between such concurrently spawned tasks, ensuring adherence to the sequential semantics of the parallelized program. As a proof of concept, we discuss the details of a parallel interpreter for Scheme (implemented in Common Lisp) based on these ideas, and show the results from executing the Clinger benchmark suite for Scheme.</p>", "authors": [{"name": "Charlotte Herzeel", "author_profile_id": "81350595801", "affiliation": "Vrije Universiteit Brussel, Brussels, Belgium", "person_id": "P2354078", "email_address": "", "orcid_id": ""}, {"name": "Pascal Costanza", "author_profile_id": "81329488208", "affiliation": "Vrije Universiteit Brussel, Brussels, Belgium", "person_id": "P2354079", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869491", "year": "2010", "article_id": "1869491", "conference": "OOPSLA", "title": "Dynamic parallelization of recursive code: part 1: managing control flow interactions with the continuator", "url": "http://dl.acm.org/citation.cfm?id=1869491"}