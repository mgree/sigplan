{"article_publication_date": "10-17-2010", "fulltext": "\n Refactoring References for Library Migration Puneet Kapur Brad Cossette Robert J. Walker Department \nof Computer Science University of Calgary Calgary, AB, Canada {pkapur, bcossett, walker}@ucalgary.ca \nAbstract Automated refactoring is a key feature of modern IDEs. Ex\u00adisting refactorings rely on the transformation \nof source code declarations, in which references may also be transformed as a side effect. However, there \nexist situations in which a dec\u00adlaration is not available for refactoring or would be inappro\u00adpriate \nto transform, for example, in the presence of dangling references or where a set of references should \nbe retargeted to a different declaration. We investigate the problem of dangling references through a \ndetailed study of three open source libraries. We .nd that the introduction of dangling references during \nli\u00adbrary migration is a signi.cant real problem, and character\u00adize the speci.c issues that arise. Based \non these .ndings we provide and test a prototype tool, called Trident, that allows programmers to refactor \nreferences. Our results suggest that supporting the direct refactoring of references is a signi.cant \nimprovement over the state-of-the-art. Categories and Subject Descriptors D.2.7 [Software En\u00adgineering]: \nDistribution, Maintenance, and Enhancement; D.2.6 [Software Engineering]: Programming Environments General \nTerms Human Factors, Languages. Keywords Dangling references, library migration, refac\u00adtoring, .exible \nsearch, .exible transformation, Trident. 1. Introduction Automated refactoring is a key feature of modern \nintegrated development environments (IDEs). Existing refactorings in\u00advolve the transformation of source \ncode declarations, such as class or method declarations, where any references (e.g., method calls, the \nuse of a type name within a variable dec\u00adlaration) can optionally be updated to re.ect changes to the \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA/SPLASH \n10, October 17 21, 2010, Reno/Tahoe, Nevada, USA. Copyright &#38;#169; 2010 ACM 978-1-4503-0203-6/10/10. \n. . $10.00 underlying declaration. However, there exist practical situa\u00adtions in which a declaration \nis not available for refactoring or would be inappropriate to transform, but instead, only the references \nshould be changed. The direct refactoring of ref\u00aderences is not available at present, reducing support \nto the level of text editing; thus, greater effort is required of devel\u00adopers, with the greater likelihood \nthat they introduce errors. We see four situations in which the refactoring of ref\u00aderences is of potential \nbene.t. (1) In library migration in practice, the developer is likely to remove an old version and insert \na new one; if the library s application program\u00adming interface (API) has changed, dangling references \nwill now be present in the developer s code. (2) In test-driven de\u00advelopment, test cases are written \nbefore their corresponding declarations. As development proceeds, revised design ideas can necessitate \nthe refactoring of the tests even if the dec\u00adlarations have not yet been written. (3) In pragmatic reuse \nscenarios, developers opportunistically locate useful func\u00adtionality from another system that they copy \nand modify to operate in their own system. This process of integration often involves the refactoring \nof references to utilize declarations in the developer s target system. (4) Practical software de\u00advelopment \ninvolves the ability to revise design ideas in the midst of implementation. This can involve the presence \nof dangling references, or different ideas about how to use ex\u00adternal APIs requiring references to be \nrefactored. In all these situations, the transformations (a) must oper\u00adate in the presence of broken \nsemantics and possibly broken syntax, (b) where the details of transformation can vary be\u00adtween locations, \nand (c) where the developer is the ultimate arbiter of what makes sense. Existing work does not suf.ce \nto support the refactor\u00ading of references. Standard transformation approaches can demand excessive precision \nfrom the developer in terms of the search query [26], can be excessively rigid about syn\u00ad tactic details \n[7], or can fail in the presence of broken se\u00ad mantics [5]. Previous work to support library migration \nhas focused on: strong notions of type correctness [2, 20], lead\u00ad ing to poor performance or dif.culty \nin specifying trans\u00adformations; adding adaptor layers [12, 21, 22], with run\u00ad time overhead and limited \napplicability; or solely on recom\u00admending alternative calls [9, 27], rather than actually per\u00ad forming \ntransformations. Even in the few cases where tech\u00adniques attempt to actually migrate between library \nversions (e.g., [1, 11]), they demand access to the source code and/or a repository of example usage \ncode, and are incapable of providing transformations in all cases after all, inferring library migration \nis reducible to functional equivalence, an undecidable problem in general.  We focus here speci.cally \non the library migration sce\u00adnario. We begin by presenting an empirical study on a large number of versions \nof three industrially relevant software li\u00adbraries, to illustrate that their APIs do indeed break between \nversions and characterize how. We also present a prototype tool, called Trident, to sup\u00adport the refactoring \nof references that is intended to handle a subset of the API breakages that we have observed. Tri\u00addent \nprovides .exible search-and-replace functionality that uses an exemplar supplied by the developer; it \nleverages a blend of lexical, syntactic, and semantic clues according to the developer s needs. Trident \nmakes use of partial program analysis [8] to estimate whether two references refer to the same entity. \nIt allows the developer to preview the set of lo\u00adcations that a query would transform, and how these \nwould be transformed. The developer can either proceed or revise the search criteria or transformation \nspeci.cation. We performed case studies with two industrial develop\u00aders, who were tasked with a realistic \nlibrary migration prob\u00adlem. Both developers attempted the task .rst with our tool support and then with \nonly standard IDE support. Qualita\u00adtive observations about the relative strengths and weaknesses of the \ntreatments are reported along with the developers thoughts and opinions. The remainder of the paper is \nstructured as follows. Sec\u00adtion 2 describes an actual industrial scenario of library mi\u00ad gration. Section \n3 presents our empirical study into API breakages in a set of industrial software libraries. Section \n4 describes our approach to supporting some of these transi\u00adtions, as embodied in the Trident tool, which \nis evaluated through two in-depth case studies with industrial develop\u00aders in Section 5. Section 6 discusses \nremaining issues and future work. Section 7 considers how our approach differs from existing work for \nthis practical problem. This paper contributes an empirical study into the nature of API change in a \nset of industrial systems, and an approach that allows references to be refactored, independent from \ndeclarations, and even when the references dangle. 2. Motivation Consider an actual scenario of class \nlibrary migration that unfolded at Chartwell Technology, our industrial research partner. At the time, \nChartwell employed approximately 40 software engineers working on over 1 MLOC of Java code. The code \nmade extensive use of the XML parsing facilities provided by the JDOM library, version b9.1 As Chartwell \ns product line matured, the XML processing de\u00admands increased, prompting a search for a newer XML class \nlibrary. The then-new release of JDOM (version b10) seemed like the most appropriate replacement candidate. \nFollowing the most direct upgrade path, one developer was assigned to replace JDOM-b9 with JDOM-b10 on \nhis class\u00adpath, to ensure that the revised code compiled and passed all unit tests and then commit the \nchanges. This class library migration was not so simple in practice. A comparison of the library versions \nreveals that there are 120 binary incompatibilities [14] between the two JDOM versions. Some of these \nchanges are unlikely to have any implications for JDOM users, such as the visi\u00adbility change of the .eld \norg.jdom.input.SAXHandler. currentElement from protected to private. While other, seemingly trivial, \nchanges had a considerable im\u00adpact on the compilation of the Chartwell codebase. For in\u00adstance, the method \nElement.getParent() was removed and replaced with Element.getParentElement(). This method was invoked \nthroughout the code base and its absence alone resulted in 140 compilation errors. Simi\u00adlarly the pretty \nprinting of XML documents was previ\u00adously accomplished by instantiating XMLOutputter thus: new XMLOutputter(\"\", \ntrue). In the new version this task was accomplished with a new Format class and all the previous method \ninvocations needed to be replaced with new XMLOutputter(Format.getPrettyFormat()). This change resulted \nin 86 compilation errors. The full set of changes and resulting errors in the Chartwell codebase are \navailable elsewhere [16]. In total there arose 467 compilation errors during this li\u00adbrary migration, \nresulting from just 7 of the 120 binary in\u00adcompatibilities between the JDOM versions. Thus, the po\u00adtential \nimpact of the library upgrade would have been far worse if Chartwell had made more extensive use of the \nJDOM API. To complete the JDOM library migration ulti\u00admately took almost 2 full days of effort and involved \nmanual modi.cations of 274 Java .les. The dif.culty of this solution stands in stark contrast to the \napparent simplicity of the underlying API change. Given this discrepancy, it is worth asking: Why was \nthe task at\u00adtempted manually when there are a host of code modi.ca\u00adtion tools inside of Eclipse? Consider \nthe alternatives that the developer could have pursued. The .rst tool that comes to mind for this task \nis grep. A search for the regular expression \\.getParent() and replacement with \\.getParentElement() \nseems like the most obvious choice for the .rst API change. Unfor\u00adtunately this initial impulse is wrong \nas there are innu\u00admerable invocations of methods named getParent() in the Chartwell code base that correspond \nto method decla\u00ad 1 Although a beta-version, JDOM was the cutting edge technology of the day; alternative \nlibraries were not considered viable by Chartwell.  rations on different types unrelated to JDOM. The \npreva\u00adlence of duplicate method names can be seen in a lex\u00adical search of the Eclipse 3.5.1 libraries \n1,233 classes with 3,024 getParent() references to a range of different method declarations. For the \nmoment, let us assume that duplication of method names is a rare event and the only references in the \ncode base to getParent() correspond to the pertinent ones in JDOM. Even so, grep would still not be up \nto the task. A closer examination of the API change reveals that originally 6 JDOM classes declared getParent() \nmethods. Of those, 5 now share a common parent, the new Content class, from which they inherit getParentElement(). \nThe 6th class is Attribute and it remains outside the new supertype hier\u00adarchy. As such getParent() invocations \non variables of type Attribute should not be refactored. Making the neces\u00adsary syntactic distinctions \nbetween such cases is outside the ability of lexical tools such as grep. Conveniently Eclipse provides \nsyntactic search sup\u00adport through Java Search (we distinguish Java Search from Eclipse File Search, which \nis purely lexical) which might prove useful. Initial attempts at specify\u00ading Attribute.getParent() in \nour Java Search query appear to work. None of the getParent() references unrelated to JDOM appear in \nthe search results. How\u00adever all the getParent() references to JDOM are re\u00adturned whether they are invoked \non Attribute vari\u00adables or on any of the 5 other classes. Refusing to become discouraged we try applying \nthe same strat\u00adegy to the next API change. Occurrences of new XMLOutputter(\"\") need to be replaced with \nnew XMLOutputter(Format.getRawFormat()) while those of new XMLOutputter(\"\", true) need to be replaced \nwith XMLOutputter(Format.getPrettyFormat()). Un\u00adfortunately Java Search is still not up to the task as \nit is un\u00adable to distinguish between overloaded versions of the same dangling method reference. An optimist \nmight argue that despite its shortcom\u00adings, Java Search has done enough by returning a list of method \nreferences and associated .lenames that we can perform a replace operation on. We are stymied yet again \nas Java Search offers no replace option. Re\u00adgardless, what we need is not replace functionality but refactoring \nfunctionality. Eclipse refactorings pro\u00advide numerous error checking and convenience features that potentially \nsimplify the user experience. For in\u00adstance when refactoring new XMLOutputter(\"\") to new XMLOuputter(Format.getRawFormat()) \nthe appropri\u00adate import needs to be added to the affected classes. Sim\u00adilarly when changing method names, \nrefactoring tools en\u00adsure the proposed name does not con.ict with another name in the same scope. While \nsuch points may seem trivial and straightforward, we will see the great pain that they can cause in practice. \n3. API Change in the Wild Various authors have mentioned the existence of API changes in practice. In \nparticular, Dig and Johnson s study on API evolution [10] is prominent. Unfortunately, their study has \nthree shortcomings from our perspective: (1) the number of migrations that they considered consist of \na sin\u00adgle version transition for each of 5 systems; (2) they con\u00adsidered only public entities and not \nall entities that a de\u00adveloper could depend on, and furthermore, only those en\u00adtities with publicly available \ndocumentation and intended for reuse (i.e., internal packages in Eclipse would be ig\u00adnored); and (3) \nhaving decided previously that library migra\u00adtion paths can be described via automated refactorings in \nthe majority of cases, they do not look for changes that would contradict this notion. Instead, we present \nan in-depth investigation of API changes in practice, without any presupposition about the nature of \nsuch changes. We sampled the growing body of open-source software available on the Internet, to select \nthree systems that are heavily used in industry and gener\u00adally regarded as of reasonable quality; we \nchose HTML-Unit, JDOM, and log4j. (As an example, HTMLUnit has been downloaded 69,343 times for the versions \nthat we have investigated.) For each of these systems, we sought out as many versions as we could, in \norder to examine the API changes between successive versions. To detect and analyze API changes, we performed \na three-step process: (1) we used the Eclipse API Tooling to determine the binary incompatibilities between \nsuccessive versions; (2) we then used JDiff in an attempt to automati\u00ad cally classify the API changes; \nand .nally (3) we manually inspected and revised each of the reported changes (includ\u00ading looking through \nthe associated documentation) to over\u00adcome shortcomings of these tools. We concerned ourselves only with \nchanges that could potentially break an existing client, discarding all other events. Changes considered \nper\u00adtinent include visibility reduction of entities (types, meth\u00adods, constructors, or .elds), deletion \nof entities, movement of entities (including formal parameters), and the insertion of entities that would \nbreak existing references (e.g., new formal parameters, new declared exception). The detailed re\u00adsults \nare tallied in the appendix. Table 1 summarizes the results over all transitions be\u00ad tween successive \nversions; detailed results are available else\u00adwhere [16]. We found that APIs in these systems change \nun\u00ad predictably and sometimes severely, and that API change is far from uncommon. In addition to the \ndata, we also qual\u00aditatively found that the @deprecated tag is an unreliable guide: deprecated entities \nof course do not always get elim\u00adinated, but entities can be deleted or otherwise transformed without \never having been labelled as deprecated and with\u00adout any explicit indication as to how a developer ought \nto migrate their library usage to a newer version.  System Version All Types Methods Constructors Fields \ntransitions \u00b5 s\u00b5s\u00b5 s\u00b5s\u00b5s HTMLUnit 31 26.19 54.30 4.61 4.40 20.06 52.96 1.29 2.56 0.23 0.67 JDOM 8 27.88 \n42.80 1.25 1.28 18.50 28.75 2.75 6.98 5.38 7.10 log4j 15 13.87 39.84 1.53 3.54 7.40 23.10 0.53 1.25 4.40 \n12.48 Table 1. API breakages in the studied systems. Mean and standard deviation are presented for the \ninter-version binary incompatibilities both with respect to all changes and broken down by entity kind. \nAs the average number of changes for each transition be\u00adtween versions is between 13 and 28, the burden \non the de\u00adveloper to determine how to remap each dangling reference is potentially high especially since \na single API breakage could result in multiple dangling references. We note that the majority of change \nevents (~62%) involve the deletion of entities, and approximately half of the change events are speci.cally \nmethod deletions. (We do not count as method deletions any likely signature changes that would be eas\u00adily \nlocated by the developer.) Deletions are potentially the greatest burden to the developer, as no immediate \nclues ex\u00adist about what the deleted entity should be replaced with. We found that most of these changes \nwere not accompanied with documentation about the recommended migration path. If the library providers \ndo not even point out how to cope with version transitions, they are unlikely to create heavy\u00adweight \nspeci.cations that could be used to correctly trans\u00adform client code, as required by a variety of API \nmigration research [2, 6, 20, 24]. A developer is left with little choice but to manually transition \ntheir code, a notably painful pro\u00adcess [3]. More pragmatic support would be a boon. 4. Refactoring References: \nPrototype Tooling As a .rst step in determining whether tool support for refac\u00adtoring references would \nbe of practical bene.t, we present our prototype tool, Trident. Trident is implemented as a plugin for \nthe Eclipse IDE, which aims to provide .exible search-and-replace functionality for refactoring references. \nTrident does not currently aim to address every detail of the process of refactoring references: by investing \nin partial sup\u00adport, we intended to collect enough empirical evidence to inform whether stronger tooling \nis worth developing. We wished to mimic the capabilities of existing Eclipse tools (such as Java Search, \nand Eclipse s refactoring sup\u00adport), but allowing for intelligent replacements in contexts where existing \nsupport could not operate: incomplete code bases with dangling references. 4.1 Goals To enable Trident \nto provide refactoring support for refer\u00adences, we aimed to address two key issues. First, we wanted \nto provide refactoring support equivalent in capability to ex\u00adisting refactoring tools, and not simply \nextend lexical/Java Search to include a replace feature. After spending some time observing Eclipse users \ninvoke the Rename and the Introduce Local Variable refactorings that Eclipse pro\u00advides, we made several \nobservations about the nature of refactoring which we sought to emulate: Exemplar Based. To activate \nmost refactorings the devel\u00adoper must provide an example of the code to be refac\u00adtored. For instance, \nrenaming a method requires that the cursor is currently placed on a method name. Context Sensitive. The \ntypes of standard refactorings avail\u00adable depend on the broader context in which the example resides. \nSelecting a variable declaration inside a method body makes available the extract method refactoring \nwhile selecting a similar statement in the class body does not. Completion Assistance. Once you have \nselected the type of refactoring to apply, a specialized UI provides com\u00adpletion assistance. Explicit \nassistance in the change method signature refactoring comes in the form of type\u00adcompletion widgets beside \nthe method arguments that al\u00adlow you to quickly select from other types currently visi\u00adble in the project. \nImplicit assistance comes in the form of checking for other methods in the same scope that might share \nyour proposed method name/signature and cause naming con.icts. Escape Clause. A refactoring can be aborted \nat various stages and for various reasons. Most refactorings provide an inline preview of the proposed \nchange so the user has immediate visual feedback on whether or not he should proceed. Following which, \na preview is provided that lists all affected .les and shows a side-by-side comparison (with syntax highlighting). \nAgain at this stage the devel\u00adoper can cancel the refactoring altogether or selectively override the \nrefactoring and exclude some .les from the change. Even once the code has been modi.ed it is pos\u00adsible \nto undo all the changes on a project wide basis.  4.2 Application and Features Trident is applied in \na 5-stage process. (1) The devel\u00adoper highlights code to refactor and activates Trident (selection). \n(2) A wizard is displayed allowing for spe\u00adci.c details about the search criteria to be con.gured (search \ncon.guration). (3) A checkbox list is presented with each location described that matched the criteria; \nby default, the entire set of results is selected, but this can be restricted to any individual locations \n(restriction).  (4) Another wizard is displayed allowing for speci.c details about the refactoring criteria \nto be speci.ed (refactoring con.guration). (5) A comparison editor allows for before and after shots \nof the changes to be previewed. At any step, the process can be aborted, or the developer can return \nto the previous step. We describe each stage of the process, below, via a running example: the statement \nCategory.getInstance(ResourceBundleTest.class), in which Category and ResourceBundleTest are types. Selection. \nThe Selection stage begins with the developer highlighting a section of code containing a reference in \nthe editor; he activates Trident using a toolbar button. Trident then obtains the node (as de.ned by \nthe Eclipse Java Development Tools) from the abstract syntax tree (AST) corresponding to the current \nselection; to deter\u00admine likely resolution information in the presence of dan\u00adgling references, the partial \nprogram analysis (PPA) tool of Dagenais and Hendren [8] is applied. Currently only 6 types of AST node \nselections are supported: SimpleName, SimpleType, Quali.edName, Quali.edType, MethodInvo\u00adcation, and \nClassInstanceCreation. Search Con.guration. The developer speci.es how the exemplar should be used to \nsearch for other dangling ref\u00aderences. The developer is asked to identify which portions of the exemplar \nshould be included in the search and how they should be interpreted. Developers are provided with (a \nmaximum of) three search options to guide the search. Figure 1 illustrates this with our running example. \nThe method invocation is broke into its three constituent com\u00adponents: method expression (Category), \nmethod name (getInstance), and a variable length argument list (ResourceBundleTest.class). Beside each \ncomponent is a drop down box with search options. For the method expres\u00adsion three search options are \navailable: verbatim , mean\u00ading search for method expressions that are lexically iden\u00adtical to Category; \ntype , meaning search for method ex\u00adpressions that evaluate to the same type, which in this case is org.apache.log4j.Category; \nand ignore , meaning remove that portion of the exemplar from search considera\u00adtion. Method names have \nonly two search options: verba\u00adtim and ignore . As previously, choosing verbatim in our example means \na search will be conducted for other method invocations where the name portion is getInstance. Arguments \nhave the same three search options available with one small difference. If there are = 2 arguments, choos\u00ading \nignore for any one of them still requires the search condition that is applied to the others to hold \nand the num\u00adber of arguments must still equal n. Choosing to ignore all the arguments means any type \nand any number of arguments is considered valid in the ensuing search. Figure 1. Trident search con.guration. \n Figure 2. Trident search results. Figure 3. Trident refactoring con.guration. Figure 4. Trident reference \nrefactoring preview.  The search criteria are translated into lexical search cri\u00adteria via regular expressions \nas well as additional semantic checks when appropriate. Restriction. Locations that match the search \ncriteria are presented in a checkbox list. The developer can review the individual matches, select/deselect \nthese individually or as a group, or back up to revise their search crite\u00adria. In Figure 2, we see that \nmultiple instances of calls to Category.getInstance(...) have been found, where the details of the argument \nvary between a variety of class lit\u00aderals and invocations of getName() on class literals (which returns \na String). The developer has selected two of the locations as being of interest. Refactoring Con.guration. \nThe developer can then spec\u00adify how the components should be altered, as illustrated in Figure 3. This \nstep is relatively simplistic in our current pro\u00ad totype. The wizard is initially populated with details \nfrom the exemplar. If a given component is unaltered by the devel\u00adoper, the corresponding component in \nall locations is left un\u00adtransformed. Otherwise, the corresponding component in all locations is transformed \nas speci.ed: (1) the method name can be replaced if replaced via the Browse for method button, the speci.c \nmethod to be invoked will be identi.ed and hence import statements can and will be modi.ed auto\u00admatically \nas well; (2) the method expression can be replaced; (3) the existing method arguments can be replaced; \n(4) any existing argument can be deleted; (5) new arguments can be inserted; and (6) arguments can be \nmoved, which does not transform the contents of corresponding arguments, only their positions in the \nlist. To be clear, this set of possible transformations is pur\u00adposefully limited to simplify the process \nof using it. Through the Restriction stage and iterative invocations of Trident, we feel that the completion \nof a large task is more practicable than with complex speci.cations. Preview. As a .nal stage, the developer \ncan preview the change that will result at each selected location, in a com\u00adparison editor that is standard \nfor automated refactorings in Eclipse (as in Figure 4). If the previewed transformation is unacceptable \nat any point, the developer can unselect that lo\u00adcation, or he can back up to an earlier stage of the \nprocess to revise his criteria. Finally, the transformations are applied in a single, undoable step, \nso the developer can globally undo the transformation if desired. 5. Case Studies To determine whether \neven partial tool support for refactor\u00ading references is likely to be bene.cial in practice, we con\u00adducted \ntwo case studies with industrial participants, in which they were asked to migrate a software system \nfrom depen\u00addence on an out-of-date library version to a more recent ver\u00adsion. Each participant was asked \nto undertake the code mi\u00adgration .rst using the Trident tool, and then attempt the same migration again \nwithout the bene.t of our tool support. Our research questions were: (RQ1) How painful is it to refactor \ndangling references in source code using existing tool sup\u00adport? and (RQ2) Does Trident help developers \nreduce the dif.culty of refactoring in these cases? Section 5.1 describes the methodology we used to \ncon\u00ad duct our case studies. Section 5.2 describes our qualitative observations of the participants undertaking \ntheir refactor\u00ading tasks using Trident to assist them, and subsequently per\u00adforming the same refactoring \nmanually. Section 5.3 com\u00ad pares the approaches quantitatively and qualitatively, dis\u00adcussing the implications \nof the study. 5.1 Case Study Methodology We recruited two industrial software developers to partici\u00adpate \nin our case study, and asked them to refactor references in a software system which was currently in \nan uncompi\u00adlable state due to changes within a depended-upon library. The goal of the refactorings was \nto restore the system to a compilable state. 5.1.1 Participants Participant 1 described himself as having \n9 years of ex\u00adperience in developing Java software, and having used the Eclipse IDE for the past .ve \nyears. Participant 2 described himself as having 7 years of experience developing Java soft\u00adware, and \nhaving used the Eclipse IDE for two years.  5.1.2 Systems We chose to have the developers migrate the \nJaxMe project (version 1.63), an open source implementation of the Java Architecture for XML Binding \n(JAXB) speci.cation, which de.nes how an XML schema can be transformed into a set of Java classes and \ninterfaces for programmatic manipula\u00adtion. The JaxMe v1.63 contains 213 classes and 18928 LOC. JaxMe \nwas a strong candidate for our study as it relied heav\u00adily on a library which had evolved signi.cantly, \nwith func\u00adtionality deprecated and removed: the Apache log4j library. Log4j provides application logging \nfunctionality to de\u00advelopers. In place of using System.out or System.err method calls to write logging \nand error messages to the con\u00adsole, log4j provides a runtime con.gurable logging frame\u00adwork which can \nselectively disable speci.ed levels of log\u00adging during execution, and can provide output in multiple \nformats. As log4j has increased in both popularity and matu\u00adrity, its API has undergone signi.cant changes. \nFor example, in previous versions of the library, developers would use the Category class to access the \ncategory of functionality that they wished to log. However, in the transition from v1.2.8 to v1.3, the \nfunctionality provided by the Category class was largely supplanted by the Logger class, because using \na logger for logging made more sense than using a cat\u00adegory (according to the manual). Similarly, the \nPriority class was originally used by developers to de.ne the impor\u00adtance of a logging message being \nsent to the Category ob\u00adjects used for logging. In the new version, the type was re\u00adplaced with a new \nLevel class which allowed developers to set the error level of logging messages sent.  5.1.3 Task For \nthe case study, each developer was asked to migrate the JaxMe project from v1.2.8 to v1.3 of the log4j \nlibrary. Only a subset of the real transition was allowed to cause compilation problems: the change of \nCategory instances to Logger; and the change of Priority instances to Level. There are several other \ndifferences between log4j v1.2.8 and v1.3, but we elected to restrict our study to the above subset for \nthree reasons: (1) the time required of partic\u00adipants to perform the case study had to be restricted \nfor practicality; (2) these classes, and their associated methods and/or .elds, constitute the majority \nof the differences be\u00adtween the two versions; and (3) the classes that have been removed and their intended \nreplacements are clearly indi\u00adcated in the library s documentation, through the use of the @deprecated \nand @see tags, thereby eliminating any am\u00adbiguity about what modi.cations are needed. We simulated the \npartial transition to v1.3 by providing stubs for missing entities that were not in the limited subset. \n 5.1.4 Setup Participants were provided with the Eclipse IDE v3.5, con\u00ad .gured with the Trident tool \nas a plugin. At the start of the case study, each participant was provided with a short tuto\u00adrial introducing \nthem to the purpose and usage of the Trident tool. The tutorial showed a dozen unique sample scenarios \nin which the Trident tool was used to .nd and refactor code containing dangling references, to illustrate \nto the participant how the tool can be used. At the completion of their training, the JaxMe v1.63 source \ncode was loaded in their project workspace, with log4j v1.3 (adjusted as described above) in the JaxMe \nproject s classpath. Participants were then asked to modify the source code to eliminate the dangling \nreferences left by the log4j library transition, reducing the compilation error count to 0. To alleviate \nthe developers need to familiarize themselves with the log4j documentation, participants were provided \nwith a concise list of the source entities that had been removed between versions, and the names of the \nen\u00adtities that should be used to replace them replacements, ex\u00adtracted and condensed from the log4j documentation. \nParticipants undertook this task twice. On their .rst at\u00adtempt (the tool treatment), they used the Trident \ntool, and on their second attempt (the manual treatment) they were to attempt the change manually using \nany functionality within Eclipse they desired, but without the assistance of Tri\u00addent. In both treatments, \nwe asked the study participants to think aloud as each went through the task to help us under\u00adstand their \nthinking process, action rationales, and reactions to the results. While each treatment was conducted \non the same system and problem, the treatments were conducted 24 72 hours apart: our goal in doing this \nwas to partially re\u00adduce the learning effect caused by having to repeat the same tasks, since we expected \nthat this would prevent develop\u00aders from remembering every detail of the task, thus poten\u00adtially obscuring \nour attempt to measure differences between Trident and existing techniques. We did expect though that \nthis would not eliminate the learning effect, and thus give a small advantage to developer performance \nin the manual treatment. For the tool treatments, participants were asked to only use Trident for any \nautomated/semi-automated refactorings to the code: they were allowed to make manual modi.ca\u00adtions to \nthe source code as they desired (i.e., via the source code editor). They were also allowed to ask the \nstudy inves\u00adtigator about any details of Trident s usage, but not details of how the code could or should \nbe modi.ed to successfully complete the task. For the manual treatments, each participant was allowed \nto use only those tools provided within the Eclipse IDE (e.g., refactorings, lexical search/replace tools) \nand manual modi.cation to alter the JaxMe source. Participants were again free to ask for assistance \nin using any of the tools provided by the Eclipse IDE.  5.2 Observations We focus here on a few high-level \nobservations of the partic\u00adipants actions and comments. A more detailed and complete set of observations \ncan be located elsewhere [16]. 5.2.1 Participant 1 Tool treatment. The participant s approach can be \ncharac\u00adterized as heavily iterative, cycling between selecting dif\u00adferent exemplars as input to Trident, \nre.ning his search cri\u00adteria, and investigating the search results. For a particular transformation, \nhe discovered that providing Trident with different variations on the same input (e.g., searching on \nthe ERROR .eld name vs. searching on the fully quali.ed type and .eld name org.apache.log4j.Priority.ERROR) \nal\u00adlowed him to re.ne and discriminate the search results of the tool to re.ect his original intention. \nIn most cases, the participant would try several different exemplars as the in\u00adput for Trident, before \n.nding the example which captured precisely those locations he wished to transform. Later in the task, \nthe participant chose exemplars in a deliberately exploratory fashion; he would select an example, activate \nTrident, then alter how Trident restricted its search on that example (e.g., ignoring the type or presence \nof a parameter in a method invocation to use Trident to .nd the different kinds of arguments being passed \nin, before I decide on what changes to make. ). The participant used the preview screens to ensure that \nhis intended modi.cations were carried out correctly, but also to quickly locate unusual cases where \nhe wanted to see if Trident performed as he expected. For example, the participant had to perform a transformation \non a static method invocation (i.e., from Category.getRoot() to Logger.getRootLogger()), but noticed \nthat in the JaxMe source code, static methods were more often accessed on an instance (e.g., cat.getRoot()) \nthan in a static manner. The participant chose as his exemplar cat.getRoot() be\u00adcause it described the \nmore frequently occurring situation, but used the preview screens to see that Trident (1) cap\u00adtured the \ncases in which the method was accessed statically through the class type, and (2) correctly transformed \nthose cases as well.  Towards the end of the task, the participant preferred to use Trident to enact \nlarge sets of changes, while using manual modi.cation to .x one-off changes. In one case, he aimed to \ntransform a method invocation which accepted a parameter whose value was almost always passed in as a \nstatic .eld reference on a type, but in a few cases was a reference to a local object. Rather than restrict \nTrident to deal with those cases separately, he reasoned instead that the side-effects of the transformation \nfor those special cases were easily dealt with manually afterwards. Manual treatment. After realizing \nthat Eclipse s Java Search tool does not support search and replace operations, the participant resorted \nto using the File Search and Replace tool, which also allowed him to use regular expressions for the \ntransformations. The participant found he needed to iterate through sev\u00aderal versions of a regular expression \nbefore he could get it to match examples he knew about in the source code despite Eclipse providing inline \nregular expression assis\u00adtance. These examples also proved to be problematic; in tai\u00adloring his patterns \nto these examples (which exempli.ed the majority of cases), he would often capture cases that were (1) \nsuf.ciently lexically similar that imprecision in the pat\u00adtern caused an unintended match (e.g., forgetting \nto escape the dot ( . ) operator because the mistake in the pattern still worked on his example), or \n(2) syntactically similar yet se\u00admantically different, such as patterns written to capture static .eld \naccesses on types that also captured static method invo\u00adcations on the same. These consequences prompted \nhim to comment, The big problem with grep and regular expres\u00adsions is that you capture things that you \ndon t expect . A frequent point of frustration for him was that the com\u00adpilation error count in the project \nwould barely decrease af\u00adter enacting a particular transformation; the participant often found that a \nsingle transformation was not enough to resolve a single problem. Instead, he needed to apply a sequence \nof patterns before the transformation was complete. For example, after a transformation was enacted, \nthe compiler often could not recognize the new types or meth\u00adods involved as their containing class had \nnot been im\u00adported. In most cases, he was able to .x this automati\u00adcally using Eclipse s Organize Imports \ntool. In one partic\u00adular case though, this didn t work: two classes with the same name, but different \nenclosing packages, resided on the class path (org.apache.log4j.Logger and java.util. Logger), and the \nOrganize Imports tool gave the error Am\u00adbiguous references, user interaction is required. It was not \nable to decide which Logger class was being referenced by the newly transformed source code. In this \nparticular case, the transformation had affected 44 .les, requiring the man\u00adual addition of 44 import \nstatements. To .x this, the partic\u00adipant chose to write a regular expression to insert the ap\u00adpropriate \nimport statement after the package declaration in a Java class; because there was no way to restrict \nthe inser\u00adtion of this pattern to only those 44 .les which needed it, he applied the pattern to every \nclass in the JaxMe system, and then used Eclipse s Organize Imports to remove the unnec\u00adessary import \nstatements from those classes in which they did not belong; he evaluated this solution as an ugly hack. \nEven then, he also unintentionally transformed a string lit\u00aderal in the source code which happened to \nmatch his regular expression. He only caught this mistake because the trans\u00adformation at that point caused \na compilation error. Regarding his experiences using regular expressions for this task, the participant \nnoted that he never got the [regular expressions] right the .rst time, despite knowing the change that \nhad to be made, and he encountered signi.cant frus\u00adtration from all the unintended side effects .  5.2.2 \nParticipant 2 Tool treatment. The participant initially was confused about how to select exemplars, but \nthis was resolved quickly by the experimenter providing a tutorial on the matter. He also failed to realize \ninitially that multiple classes with the name Level existed on the classpath; this is an issue that arose \nfrom Eclipse and not speci.cally from Trident. This participant can be characterized as more cautious \nand less willing, initially, to experiment with Trident in un\u00adexpected situations. When searches returned \na broader set of hits than he had anticipated, he was tempted to restrict the locations to only those \nthat he had anticipated and deal with the others manually. Two features of Trident led him to overcome \nthis hesitancy: (1) global undo caused such unexpected changes to be low risk to try out; and (2) the \nintroduction of comments by Trident that explained what it had changed and why helped him to understand \nthe rationale for the broader set of results. Earlier presentation of rationale (i.e., during Restriction) \nwould likely have helped him. The participant asked if it was possible to restrict the search to only \ncertain kinds of entities (i.e., type declarations within variable declaration statements, as opposed \nto within catch clauses, method declarations, etc.). Trident does not currently provide such a restriction \ncapability, and he was able to complete all but 5 remaining errors with Trident. Thus, it is not clear \nwhether this capability is needed. Manual treatment. The participant attempted to reason about some of \nthe API changes as though they consti\u00adtuted refactorings (e.g., moving .elds between types). He at\u00adtempted \nto utilize the Eclipse automated refactorings, to be confronted with the error message, Destination type \ndoes not exist , since these operate on declarations and not dan\u00adgling references.  His second attempt \ninvolved Eclipse s Java Search tool\u00ading, but this did not allow him to search-and-replace. Thor\u00adough \nbrowsing of the menus led him to a lexical replacement option under Eclipse s File Search tool. For the \nAPI change from Category.getIns tance(...) to Logger.getLogger(...), this tooling caused the participant \n2 key problems: (1) the large number of hits led him to exhaustively review each before he was willing \nto change each; and (2) the import statements in each .le had to be manually adjusted before the references \nstopped dangling. I am beginning to realize what a pain this really is. Initially I had thought Eclipse \nsearch and replace would do this for me. For the API change from Category.getRoot() to Logger.getRootLogger(), \na lexical search-and-replace was again used; this was a viable option despite the fact that the getRoot() \nmethod is sometimes invoked on static .elds, and sometimes invoked directly on the class. In all the \ncases involving static .elds, the name of the .eld is con\u00adsistently cat , making lexical search-and-replace \nrelatively straightforward. He encountered a key usability problem in the process, however: a copy-and-paste \nerror in the replace\u00adment text .eld caused an extra, empty pair of parentheses to be attached to the \nend of the new method invocation. As the Eclipse File Search tooling does not provide a global undo capability, \nthe participant attempted a second round of search-and-replace to .x his previous mistake. For the API \nchange from static Category cat = ... to static Logger cat = ..., his previous refactor\u00adings had altered \nthe target statements to public static Category cat = Logger.getLogger(...). He speci\u00ad.ed the regular \nexpression Category\\s+cat\\s*=\\s* Logger.getLogger to search for matches, and Logger cat = Logger.getRootLogger() \nas the pattern to re\u00adplace it with. The replacement ought to have been Logger cat = Logger.getLogger() \n. A series of erroneous keystrokes and button presses while attempting further reg\u00adular expression-based \nsearch-and-replaces compounded the problems. This is a nightmare. Is it okay if I quit this task? After \nadditional attempts, he eventually fell back to man\u00adually correcting these and all remaining errors, \nnoting the task seemed easy but the [manual change process] was really messy and I am not con.dent in \nthe solution .  5.3 Results and Analysis The quantitative results are given in Table 2. For both partic\u00ad \nipants, Trident clearly outperformed the manual treatment, despite the study being biased in favour of \nthe latter. Overall time for performance was reduced by 23% in using Trident; note that this time includes \nthe signi.cant delays incurred waiting for (the completely unoptimized) Trident tooling to complete its \nsearches. Manual .le modi.cations were re\u00adduced by 82 95% through the use of Trident. Interestingly, \nonly about half of the attempted invocations of Trident were carried through to completion. This may \nindicate that the de\u00advelopers did not understand well enough the consequences of their selections before \nreviewing the preview results, or it may indicate dif.culties with the tool interface; the qualita\u00adtive \nobservations discount the latter possibility. We analyze our observations in terms of our research questions, \nbelow. How painful is it to refactor dangling references in source code using existing tool support? \nBoth participants strug\u00adgled at times to refactor source code with dangling ref\u00aderences, but their dif.culties \nvaried dramatically between them. Participant 1 had a solid grasp of regular expressions, using them \nto great effect, perhaps providing the best possi\u00adble example of state-of-the-practice tool support. \nHe seemed to require very few operations to complete the task, and in the end elected to manually .x \na few compilation errors di\u00adrectly. However, he still was not able to write patterns that were completely \nerror free; in most operations, participant 1 had one or more unanticipated side effects occur that needed \nto be addressed manually. It was also necessary for him to do what he described as an ugly hack in which \nimport state\u00adments were inserted globally across the system to address a class resolution problem affecting \nonly a portion of the sys\u00adtem. This participant s breadth of experience with Eclipse (as both a user \nand plugin developer), combined with his depth of knowledge about regular expressions made him an excellent \ncandidate to test our approach. His dif.culty in completing the assigned task despite these advantages \nspeaks to the limitations of Eclipse and regular expression\u00adbased support in addressing this problem. \nBy contrast, Participant 2 had signi.cant dif.culty in the refactoring task, to the point where he contemplated \naban\u00addoning the migration of the JaxMe system between log4j versions. His dif.culties re.ect many of \nthe problems in\u00adherent with such tooling. He was not able to use the Eclipse refactoring tools with which \nhe was comfortable, because they were not designed with refactoring dangling references in mind. He wanted \nto use Eclipse s Java Search functional\u00adity to .nd and replace Java types and .elds, but the search inexplicably \nhas no replace option. He had dif.culty .nding the .le-based search-and-replace tool he wanted, and when \nusing it, ran into numerous problems caused by typos or copy-and-paste bugs that were further complicated \nby be\u00ading unable to undo his mistakes and start over. In the end, Participant 2 spent a considerable \nportion of time manually enacting changes to the code. Participant 2 also noted that his experience could \nhave been worse; JaxMe appeared to consistently use a naming convention when declaring Category variables \nin the code, which allowed him to leverage that pattern (speci.cally, Category cat) to make the task \nof .nd correct pattern  Participant Time (min.) File modi.cations Trident invocations manual Trident \nmanual Trident started completed 1 74 57 40 7 28 14 2 130 100 104 5 21 10 Table 2. Quantitative results \nfrom the case studies. matches easier. Had this convention not been in use (e.g., each variable declaration \nused a different name), he felt his task would have grown in dif.culty. Both participants had common \nproblems which we feel are worth noting: both expressed frustration when refactor\u00adings attempted with \nstandard Eclipse tooling had no effect on reducing the compilation error count, or caused increases in \nthe error count. In many cases, refactorings required mul\u00adtiple steps before an error reduction would \noccur, causing them to wonder if their actions were having any effect. Does Trident help developers reduce \nthe dif.culty of refac\u00adtoring in these cases? Both participants strongly stated that the task was far \neasier with the assistance of Trident. Participant 1 found that Trident s preview window, com\u00adbined with \nits undo functionality, allowed him to attempt refactorings in an exploratory manner. He would often \nuse the preview window to look for speci.c cases in which he wanted to ensure that his search criteria \nworked, and gain early feedback as to what problems could exist. In cases where he was not sure if he \nhad captured all the dangling references of interest, or had captured too much, he would often proceed \nwith the refactoring, since he was con.dent that Trident s undo functionality would allow him to revert \neasily back if he was wrong. Participant 2 was far more deliberate about enacting changes, and as such \nheavily relied on Trident s preview window to understand how his searches were working, and to ensure \nthat his expectations as to the tool s refactoring would match reality. In cases where he was confused \nor un\u00adsure about how a particular refactoring might affect code, the comments shown in the code previews \nprovided suf.cient feedback to encourage him that he was on the right track. Both participants seemed \nto make steady progress with the Trident tool. Neither participant saw an increase in the number of compilation \nerrors after performing a particular refactoring, and both made steady, consistent progress in reducing \nthe number of compilation errors in the JaxMe system with every Trident invocation. 6. Discussion 6.1 \nThreats to Validity Having each participant repeat the same migration task ob\u00adviously calls into question \nthe validity of the results from the second treatment, since learning effects would accrue. How\u00adever, \nwe wished to put our approach up against the toughest comparison: industrial-strength tooling when the \nparticipant was already familiar with the speci.c task. Both qualitatively and quantitatively, Trident \noutperformed the standard tool\u00ading, despite biasing the study strongly in favour of the stan\u00addard tooling. \nIt is possible that participants exposure to the Trident tool shaped their approach in the manual treatment \nsuch that the nature of the refactorings they attempted were not appro\u00adpriate for their context; however, \nour observations show that the participants clearly understood what they were trying to achieve, and \nthe problems they encountered stemmed largely from the inadequacies inherent in existing tool support. \nOur case study demonstrates selection bias in two ways: .rst, in the nature of the systems examined, \nand second in the skill sets of the participants. The evolution of the log4j system between versions \nappears to be, in many respects, trivial. In most cases, a single class in the old version of the API \nneeds to be replaced by a functionally equivalent class in the new version, and all this entails is a \ntype change in the code: existing method invocations and .eld access on these types are syntactically \nidentical across both versions. In fact, documentation describing how code using version 1.2 of the log4j \nlibrary should transition to version 1.3 indicates that: For 99.99% of users, [this transition] translates \nto the following string .nd-and-replace operations: 1. Replace the string Category.getInstance with the \nstring Logger.getLogger . 2. Replace the string Category.getRoot with the string Logger.getRootLogger \n. 3. Replace the string Category with the string Logger . 4. Replace the string Priority with the string \nLevel .  However, our case study participants demonstrated in their manual refactorings that this advice \nis simplistic. The JaxMe system does not always access static methods through their associated class, \nbut may instead access them through an object instantiation of that class, which would not be caught \nby such search and replaces. Further, we note that a string replace on words such as Category and Priority \nindis\u00adcriminately across a system can also have serious side effects should those words accidentally \nbe used in source code doc\u00adumentation, variable, parameter, or method names, or even in a string literal \nas Participant 1 discovered. Consequently, we argue that while the evolution of log4j in this case may \nseem trivial, its usage within the JaxMe system makes mi\u00adgration between library versions a non trivial \nmatter for de\u00advelopers to resolve. In larger systems, using more compli\u00adcated libraries than those simply \nproviding logging function\u00adality, we would expect this problem to be even worse, and the need for effective \ntool support greater.  We do note that there seemed to be a disparity in how each participant used the \ntools available in the Eclipse IDE, stemming from their differing skill-levels with respect to regular \nexpressions. Participant 2 bene.ted the most from the Trident tool support as opposed to manual approaches \nin accomplishing their task. This could suggest that our choice of participants may unfairly paint Trident \nin a more .attering light. However, despite Participant 1 s skill at the manual treatment, he still ran \ninto a number of serious issues which required hacks to address. Regardless of the skill-level of a developer, \nmany aspects of refactoring references are not addressable by current tool support. In considering how \nour results generalize, we are care\u00adful to note that we have conducted only two case studies with two \nparticipants, and both of these case studies were undertaken on the same system. The nature of how APIs \nevolve may vary wildly, and log4j should not be considered as being archetypical of such evolution. Similarly, \nthe man\u00adner in which JaxMe is affected by changes in one of its li\u00adbraries evolution is likely different \nfrom many other soft\u00adware systems; JaxMe particularly has certain common pat\u00adterns in how the log4j library \nwas used which made refac\u00adtoring dangling references easier in some cases, and harder in others, than \nit might have otherwise been. Many of the speci.c observations we made during the case study would likely \nchange had any of these speci.cs changed. However, while the kinds and nature of dangling refer\u00adences \ncaused by library evolution may vary dramatically across speci.c systems, our case study demonstrates \nthat they do occur, and that existing tool support does little to help developers to address the problems \ninherent in trying to refactor references. Trident has shown that it can help in some of these cases, \nand has the potential to be improved upon to handle cases that it currently cannot. As we explore how \nlibraries evolve, and the kinds of tool support needed to support library migration in these cases, Trident \ns potential usefulness should grow.  6.2 Tool Limitations API changes may exhibit a 1:1 correspondence \nbetween re\u00adplacee and replacer source entities (e.g., A.x() becomes A.y()) or API changes can be n:1, \n1:n (e.g., a facade class replaces many individual classes or vice versa) or even n:n correspondence. \nFrom the outset we have restricted the de\u00advelopment of Trident to address just 1:1 API changes. We limit \nourselves to this scenario because Trident is intended as a prototype tool to investigate the potential \nof our ap\u00adproach. Accounting for more complex refactoring scenarios is an area for future work. 6.3 \nUsability Both participants had dif.culty at times in selecting an ex\u00ademplar from the source code that \nwas appropriate for con.g\u00aduring Trident. For example, participants would often select the single word \nforming an identi.er, which suggested to Trident that the participant was intending to invoke a search \non a simple name, when the participant was in fact interested in operating on the type associated with \nthat name, but had not selected enough of the identi.er s context. A straightfor\u00adward solution to this \nusability issue is to prompt participants when the simple name selected is within a larger context that \nmight be of greater interest. It should be noted that providing users with assistance in selecting the \nright code with which initiate a refactoring is also an issue within Eclipse [19]. By default Trident \nscans the entire code base during the search query sub-stage which introduces a perceptible time delay \nin the use of the tool; Trident is not optimized in the least, at present. Providing developers with \nthe option of limiting the number of .les by name or by package included in the search could help alleviate \nthis problem. Investigating the usefulness of the approach took priority over improving its performance. \n 6.4 Future Work The second participant made the interesting suggestion that Trident should be integrated \nwith the Eclipse Quick .x fea\u00adture: When a method cannot be resolved, Eclipse already offers an option \nto create the method and Participant 2 ad\u00advocated for a new option such that if a method was missing \nyou could repoint it somewhere else . He noted that inte\u00adgrating Trident with Quick Fix would enhance \ntool usability since the developer would be presented with a solution right alongside the problem . Enlarging \nour case study to include more class libraries and more target systems would provide greater support \nfor the external validity of this work, as would an increase in the number of participants. As a next \nstep we intend to perform a formal experiment into the effectiveness of the approach. 7. Related Work \nPrevious work that aims to address the problems of li\u00adbrary migration can be classi.ed as helping with \ndiscovering refactorings, automatic generation of adaptor code, or assist\u00ading with source code transformation. \nDiscovering Transformations. Some approaches provide tools to discover what kinds of transformations \nhave been made in the library between versions, which a developer can then use to consider how to update \ntheir source code [17, 25]. Such approaches have three large drawbacks: (1) they can\u00adnot correctly handle \nall situations, thus requiring developer intervention; (2) they do not actually transform the devel\u00adoper \ns source code; and (3) they cannot operate in the ab\u00adsence of the library versions source code.  Automatic \nGeneration of Adaptors. Other researchers have looked into providing backwards compatibility be\u00adtween \nsuccessive library versions by generating adaptor lay\u00aders to mimic the interface and behaviour of previous \nver\u00adsions [12, 21, 22]. Such tools are aimed at library developers, who have access to the repositories \ncontaining the history of their library s changes, but cannot modify clients who rely on functionality \nthey provide. These techniques are aimed at legacy systems, however, where adapting the source code using \nthe library is impractical or undesirable. Furthermore, (1) some kinds of library changes cannot be hidden \nbehind an adaptive layer but need to be addressed in the client code; and (2) the performance overhead \nfrom the adaptors is unac\u00adceptable in some situations. Assisting with Source Code Transformation. Source \ncode transformation techniques can be classi.ed as lexically\u00adbased, syntactically-based, and semantically-based. \nLexically-based approaches consist of standard search-and\u00adreplace features present in IDEs and in traditional \nsearch tools such as the grep family of Unix tools (e.g., [26]). Such tools can (a) fail to help with \nthe transformation of located references and/or (b) demand precision from the developer in specifying \nminor lexical details, resulting in either false positives or false negatives. As we have seen in our \ncase studies, lexical tools fall short of our approach. Syntactically-based approaches add knowledge \nof syn\u00adtactic structures into the mix, thus enabling discrimination of references from declarations. \nFor example, TXL [7] is a syntactic transformation language that one could conceiv\u00adably use to locate \nreferences and refactor them; however, we have seen in our case studies the utility of also leveraging \nsemantics to locate only references of certain types. Traditional approaches to semantically-aware program \ntransformation (e.g., [13]) demand the presence of formal speci.cations of the source code, which tend \nto be absent in industrial settings. Semantic grep [5] suffers from being burdensome on the developer \njust as with grep. Chow and Notkin [6] require that a library maintainer an\u00ad notate changed functions \nwith rules used to generate trans\u00adformation tools. Tip et al. [24], Balaban et al. [2], and Nita and \nNotkin [20] require that the developer using the library write a speci.cation of the transformation to \napply in mi\u00adgrating from one library to another. There are 3 problems with such approaches: (1) they \nare not extensible to gen\u00aderal many-to-many transformations, yet are intended to be automated; (2) they \ntend to focus on correctness and preci\u00adsion rather than getting the worst of the job done for the de\u00adveloper; \nand (3) writing out transformation speci.cations is not how developers think about performing library \nmigra\u00adtions [4] As Murphy-Hill says [18], programmers some\u00ad times want to break code [temporarily] ... \nand ... program\u00admers already know how to .x compilation errors, so having them .x compilation errors \nshould be easier than .xing un\u00adfamiliar refactoring tool errors. CatchUp! [15] provides a means to record \nautomated refactorings and replaying these so that library migration be\u00adcomes automatic; this idea has \nbeen incorporated as refactor\u00ading scripts in industrial IDEs. Unfortunately, it requires that the library \nchanges be performed with automated refactor\u00adings, which is not always possible. Dig et al. [11] take \nthe CatchUp! notion of recording and replaying refactorings one step further by .rst inferring the refactorings \nbetween two library versions, rather than de\u00admanding that the library developer record them. The key \ndrawbacks to the technique is that not all transformations are expressible as combinations of the standard \nautomated refactorings, and it applies heuristics to estimate refactor\u00adings in many cases, which can \nbe incorrect. Thus, developer intervention is still necessary. Tansey and Tilevich [23] focus on the \nmore limited prob\u00ad lem of refactoring annotations. Their machine learning tech\u00adnique requires the provision \nof examples, which could be a more costly technique overall than manual intervention, and it still does \nnot provide complete coverage. Andersen and Lawall [1] describe an approach that mines a patch repository \nfor common transformations that respond to interface changes. Their approach is geared towards op\u00aderating \nsystems and device drivers; a repository of patches is unlikely to exist in the case of libraries which \nare often simply released as successive versions due to their smaller size. Also, they give an example \nin which a function call has had an argument eliminated, and for which their technique is incapable of \ndetermining a complete transformation from the original call to the new one. This is exactly the kind \nof case where manual intervention is most needed, and which we aim to address. Diff-CatchUp [27] and \nSemDiff [9] both recommend re\u00ad placements for dangling references due to library migration. Both approaches \nmine a source code repository (such as the library s own implementation) to determine how calls in other \nsystems have been migrated. Aside from the fact that these approaches will operate only when a reliable \nreposi\u00adtory exists, these approaches only make recommendations, failing to aid in the actual transformation \nprocess itself. In our case study, the problem was not what the dangling ref\u00aderences should be replaced \nwith, but how to replace them: such recommenders are complementary to our work. 8. Conclusion We have \nexamined the problem of refactoring references, particularly with respect to the library migration problem, \nand demonstrated that it is not well solved with state-of-the practice approaches. We examined many versions \nof a few industrially-relevant software systems and found that API changes can be frequent, without warning, \nand severe. We have created a lightweight approach for exemplar\u00adbased search-and-replace combining lexical, \nsyntactic, and semantic criteria for selection and refactoring as a developer engaged in a library migration \ntask sees .t.  Our case studies involved two industrial developers who undertook a restricted library \nmigration task both with and without our approach, as embodied in the Trident tool. De\u00adspite signi.cant \nbiases towards the status quo, Trident was seen as being of signi.cant bene.t in terms of time to com\u00adplete \nthe task and in aiding the developer s comprehension. We will continue our work to expand the range of \nscenar\u00adios in which our approach applies, to improve the usability of our tool support, and to evaluate \nit with increasing for\u00admality. The results presented herein are an indication of the value of continued \ninvestment in this line of research. Acknowledgments We wish to thank Rylan Cottrell and the anonymous \nreview\u00aders for useful feedback on this manuscript. This work has been supported by graduate scholarships \nfrom the Alberta Informatics Circle of Research Excellence, and by postgrad\u00aduate scholarships and a Discovery \nGrant from the Natural Sciences and Engineering Research Council of Canada. References [1] J. Andersen \nand J. L. Lawall. Generic patch inference. Au\u00adtomat. Softw. Eng., 17(2):119 148, 2010. [2] I. Balaban, \nF. Tip, and R. Fuhrer. Refactoring support for class library migration. In Proc. ACM SIGPLAN Conf. Obj.-Oriented \nProgr. Syst. Lang. Appl., pages 265 279, 2005. [3] M. Boshernitsan and S. L. Graham. iXj: Interactive \nsource\u00adto-source transformations for Java. In Companion ACM SIG-PLAN Conf. Obj.-Oriented Progr. Syst. \nLang. Appl., pages 212 213, 2004. [4] M. Boshernitsan, S. L. Graham, and M. A. Hearst. Aligning development \ntools with the way programmers think about code changes. In Proc. ACM SIGCHI Conf. Human Factors Comput. \nSyst., pages 567 576, 2007. [5] R. I. Bull, A. Trevors, A. J. Malton, and M. W. Godfrey. Semantic grep: \nRegular expressions + relational abstraction. In Proc. Working Conf. Reverse Eng., pages 267 276, 2002. \n[6] K. Chow and D. Notkin. Semi-automatic update of applica\u00adtions in response to library changes. In \nProc. IEEE Int. Conf. Softw. Maintenance, pages 359 368, 1994. [7] J. R. Cordy. The TXL source transformation \nlanguage. Sci\u00adence of Computer Programming, 61(3):190 210, 2006. [8] B. Dagenais and L. Hendren. Enabling \nstatic analysis for partial Java programs. In Proc. ACM SIGPLAN Conf. Obj.-Oriented Progr. Syst. Lang. \nAppl., pages 313 328, 2008. [9] B. Dagenais and M. P. Robillard. Recommending adaptive changes for framework \nevolution. In Proc. Int. Conf. Softw. Eng., pages 481 490, 2008. [10] D. Dig and R. E. Johnson. How do \nAPIs evolve? A story of refactoring. J. Softw. Maint. Res. Pract., 18(2):83 107, 2006. [11] D. Dig, C. \nComertoglu, D. Marinov, and R. E. Johnson. Au\u00adtomated detection of refactorings in evolving components. \nIn Proc. Europ. Conf. Obj.-Oriented Progr., volume 4067 of Lec\u00adture Notes in Computer Science, pages \n404 428, 2006. [12] D. Dig, S. Negara, V. Mohindra, and R. Johnson. ReBA: Refactoring-aware binary adaptation \nof evolving libraries. In Proc. Int. Conf. Softw. Eng., pages 441 450, 2008. [13] M. S. Feather. Reuse \nin the context of a transformation-based methodology. In T. J. Biggerstaff and A. J. Perlis, editors, \nSoftware Reusability, volume 1: Concepts and Models, chap\u00adter 14, pages 337 359. Addison-Wesley, 1989. \n[14] J. Gosling, B. Joy, G. Steele, and G. Bracha. Java Language Speci.cation, chapter 13: Binary Compatibility. \nAddison-Wesley, 3rd edition, 2005. [15] J. Henkel and A. Diwan. CatchUp!: Capturing and replaying refactorings \nto support API evolution. In Proc. Int. Conf. Softw. Eng., pages 274 283, 2005. [16] P. Kapur, B. Cossette, \nand R. J. Walker. Refactoring ref\u00aderences for library migration Appendix. Technical Report 2010-960-09, \nDepartment of Computer Science, University of Calgary, 2010. [17] M. Kim, D. Notkin, and D. Grossman. \nAutomatic inference of structural changes for matching across program versions. In Proc. Int. Conf. Softw. \nEng., pages 333 343, 2007. [18] E. Murphy-Hill. A model of refactoring tool use. In Proc. Wkshp. Refactoring \nTools, 2009. [19] E. Murphy-Hill and A. P. Black. Breaking the barriers to successful refactoring: Observations \nand tools for Extract Method. In Proc. Int. Conf. Softw. Eng., pages 421 430, 2008. [20] M. Nita and \nD. Notkin. Using twinning to adapt programs to alternative APIs. In Proc. Int. Conf. Softw. Eng., 2010. \nIn press. [21] I. S\u00b8avga and M. Rudolf. Refactoring-based support for binary compatibility in evolving \nframeworks. In Proc. Int. Conf. Generative Progr. Component Eng., pages 175 184, 2007. [22] I. Savga, \nM. Rudolf, S. Goetz, and U. A\u00dfmann. Practical refactoring-based framework upgrade. In Proc. Int. Conf. \nGenerative Progr. Component Eng., pages 171 180, 2008. [23] W. Tansey and E. Tilevich. Annotation refactoring: \nInferring upgrade transformations for legacy applications. In Proc. ACM SIGPLAN Conf. Obj.-Oriented Progr. \nSyst. Lang. Appl., pages 295 312, 2008. [24] F. Tip, A. Kiezun, and D. B\u00a8Refactoring for general\u00ad aumer. \nization using type constraints. In Proc. ACM SIGPLAN Conf. Obj.-Oriented Progr. Syst. Lang. Appl., pages \n13 26, 2003. [25] P. Weissgerber and S. Diehl. Identifying refactorings from source-code changes. In \nProc. IEEE/ACM Int. Conf. Automat. Softw. Eng., pages 231 240, 2006. [26] S. Wu and U. Manber. Agrep \nA fast approximate pattern\u00admatching tool. In Proc. USENIX Winter Technical Conf., pages 153 162, 1992. \n[27] Z. Xing and E. Stroulia. API-evolution support with Diff-CatchUp. IEEE Trans. Softw. Eng., 33(12):818 \n836, 2007.    \n\t\t\t", "proc_id": "1869459", "abstract": "<p>Automated refactoring is a key feature of modern IDEs. Existing refactorings rely on the transformation of source code declarations, in which references may also be transformed as a side effect. However, there exist situations in which a declaration is not available for refactoring or would be inappropriate to transform, for example, in the presence of dangling references or where a set of references should be retargeted to a different declaration.</p> <p>We investigate the problem of dangling references through a detailed study of three open source libraries. We find that the introduction of dangling references during library migration is a significant real problem, and characterize the specific issues that arise. Based on these findings we provide and test a prototype tool, called Trident, that allows programmers to refactor references. Our results suggest that supporting the direct refactoring of references is a significant improvement over the state-of-the-art.</p>", "authors": [{"name": "Puneet Kapur", "author_profile_id": "81375598044", "affiliation": "University of Calgary, Calgary, AB, Canada", "person_id": "P2354135", "email_address": "", "orcid_id": ""}, {"name": "Brad Cossette", "author_profile_id": "81470655677", "affiliation": "University of Calgary, Calgary, AB, Canada", "person_id": "P2354136", "email_address": "", "orcid_id": ""}, {"name": "Robert J. Walker", "author_profile_id": "81350587870", "affiliation": "University of Calgary, Calgary, AB, Canada", "person_id": "P2354137", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869518", "year": "2010", "article_id": "1869518", "conference": "OOPSLA", "title": "Refactoring references for library migration", "url": "http://dl.acm.org/citation.cfm?id=1869518"}