{"article_publication_date": "10-17-2010", "fulltext": "\n Programming With Time Cyber-physical programming with Impromptu Andrew Sorensen Henry Gardner Australian \nNational University Australian National University andrew@moso.com.au Henry.Gardner@anu.edu.au Abstract \nThe act of computer programming is generally considered to be temporally removed from a computer program \ns exe\u00adcution. In this paper we discuss the idea of programming as an activity that takes place within \nthe temporal bounds of a real-time computational process and its interactions with the physical world. \nWe ground these ideas within the con\u00adtext of livecoding a live audiovisual performance practice. We \nthen describe how the development of the programming environment Impromptu has addressed our ideas of \npro\u00adgramming with time and the notion of the programmer as an agent in a cyber-physical system. Categories \nand Subject Descriptors D.1.0 [Programming Techniques]: General With-Time Programming General Terms Design, \nExperimentation, Languages, Hu\u00adman Factors Keywords Time, Concurrency, Cyber-physical Systems, Livecoding, \nImpromptu 1. Introduction An act of programming is usually considered to sit .rmly within the context \nof software development , with the latter being the active process behind the production of software \nproducts . In this view, causal actions made by the program\u00admer target the design and notation of a formal \nspeci.cation for future action by a computing system. One signi.cant rami.cation of this traditional \nview is to promote a strong separation between the program, process and task domains [43]; a program \nbeing a static speci.cation of intention (i.e. code), a process being the rei.cation of the program on \na given computing machine, and the task domain being a target for real-world affect. This view is so \npervasive Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. Onward! \n2010, October 17 21, 2010, Reno/Tahoe, Nevada, USA. Copyright &#38;#169; 2010 ACM 978-1-4503-0236-4/10/10. \n. . $10.00 as to have dominated the historical practice of computer programming. In this paper we discuss \nan alternative view, where pro\u00adgramming is a causal and ephemeral practice whose action directly targets \na physical task domain. This view gives priv\u00adilege to causal action by projecting the programmer s human \nagency into the world. The traditional, temporal separation between program, process and task domains, \nis elided as programmer action is made directly affective in the task do\u00admain. The programmer becomes \nan active agent operating within a cyber-physical feedback system, orchestrating the real-time evolution \nof computational processes which affect the physical environment. In turn the environmental, task do\u00admain \nprovides the programmer with real-time feedback to inform her future actions. This realignment of programming, \nfrom a static to a dy\u00adnamic activity, requires a suitable realignment to the sub\u00adstrate of programming \ninfrastructure. In particular when shifting programming from an act of speci.cation to an act of action \nit is not only the runtime system that is sub\u00adject to the temporal bounds of the task domain but the \npro\u00adgramming tools themselves. By placing the programmer as an active agent in a cyber-physical feedback \nsystem we are opening the programming task up to a broad range of time and concurrency demands. Compilers, \nlinkers, analysers and the like are all tradi\u00adtionally considered to be out of time processes. However, \nwhen integrated into a dynamic, real-time, causal develop\u00adment process, such tools must be reactive, \ncomplying to task-domain time and concurrency constraints as well as be\u00ading amenable to reactive updates \nfrom the environment. In this paper we explore the idea of programming as an act of human agency bounded \nin temporal alignment with a real-world task domain. We consider the implications of this model for programming \nlanguage systems and provide concrete illustrations using the programming environment Impromptu . In \nthe next section we start by considering a reference scenario from a digital-arts practice known as livecoding \n[10] and we show that the key concerns which emerge are those of temporality, scheduling, concurrency \nand the human computer interface. In Section 3, we then introduce a paradigm which we call With Time \nProgram\u00adming (WTP). The main technical section of this paper, Sec\u00adtion 4, describes the Impromptu WTP \nenvironment which has been used for livecoding and live audiovisual perfor\u00admances around the world over \nthe past .ve years. Finally, Section 5 makes a connection between WTP and program\u00adming support for human \nagency in cyber-physical systems.  2. A Reference Scenario As discussed above, the realignment of programming \nas a dynamic activity transforms it from a static speci.cation of intention into a vehicle for direct \ncausal affect. This tran\u00adsition elevates the human programmer s role in the compu\u00adtational process to \none of active agency. In this section, a traditional example and a modern scenario from music and multimedia \npractice are introduced to provide an orientation for the rest of this paper. Consider the analogy of \na traditional musical score. The score provides a static speci.cation of intention a static program \ndomain. Musicians, representing the process do\u00admain, perform the actions required to realise or reify \nthe score. Finally, the actions in the process domain result in sound waves which are perceived by a \nhuman audience as music. This .nal stage is our real-world task domain. Now consider a dynamic program \ndomain in which a composer conceives of and describes a musical score in real-time. We commonly call \nthis type of composition improvisation. In it, the improvising musician is involved in a feedback loop \nin\u00advolving forethought, moving to causal action and .nally to reaction, re.nement and re.ection. Livecoding \n[10, 50] is a computational arts practice that involves the real-time creation of generative audiovi\u00adsual \nsoftware for interactive multimedia performance. Com\u00admonly the programmers actions are exposed to the \naudience by projection of the editing environment. Livecoding perfor\u00admances often involve more than one \nparticipant, and are often commenced from a conceptual blank slate [48]. Be\u00ad cause of the highly temporal \nnature of linear media, sound and visual animation, livecoding provides a strong example of what we call \nwith-time programming . We now present a short story describing a possible livecoding performance: Two \nperformers are present on stage. One, a violinist, stands paused, bow at the ready. Another sits behind \nthe glow of a laptop screen. A projection of the laptop screen is cast above the stage showing a blank \npage with a single blinking cursor. The laptop musician begins to type ... ( play-sound (now) synth c3 \nsoft minute ) ... the expression is evaluated and blinks on the overhead projection to display the performer \ns action. An ethereal syn\u00adthetic sound immediately enters the space and the violinist begins to improvise \nin sympathy with the newly evolving syn\u00adthetic texture. The laptop performer, listens to the thematic \nmaterial provided by the violinist and begins to outline a generative Markov process to accompany the \nviolin ... Figure 1. Livecoding Duet (Bencina &#38; Sorensen 2009) ( define chords (lambda ( beat chord \nduration ) (for-each (lambda (pitch) ( play synth pitch soft duration )) chord ) (schedule (*metro* (+ \nbeat duration )) chords (+ beat duration ) (random (assoc chord ((Cmin7 Dmin7) ( Dmin7 Cmin7 )))) duration \n))) (chords (*metro* get -beat 4) Cmin7 4) ... the chords function is called on the .rst beat of a new \ncommon time bar and a simple recursive chord pro\u00adgression begins supporting the melodic performance of \nthe violin. The chord function loops through time, creating an endless generative sequence of four beat \nchords. After a few moments of re.ection the laptop performer begins to modify the chords function to \nsupport a more varied chord pro\u00adgression with a randomised rate of temporal recursion ... ( define chords \n(lambda ( beat chord duration ) (for-each (lambda (pitch) ( play dls (+ 60 pitch ) soft duration )) chord \n) (schedule (*metro* (+ beat duration )) chords (+ beat duration ) (random (assoc chord ((Cmin7 Dmin7 \nBbmaj) (Bbmaj Cmin7) ( Dmin7 Cmin7 )))) (random (3 6)))))  ... the laptop performer .nishes editing \nthe desired changes and pauses to listen to the violinist, waiting for a musically sensitive moment to \nintroduce the new code changes. The code is evaluated and hot-swapped on-the-.y. The chord progression \ncontinues on without any noticeable interrup\u00adtion. The violinist responds in kind by improvising over \nthe new progression inspiring the laptop performer to introduce a basso profundo voice ... ( define basso \n(lambda ( beat pitch duration ) ( play bass pitch soft duration ) (schedule (*metro* (+ beat duration \n)) basso (+ beat duration ) (if (< pitch 37) 48 (pc:relative pitch -1 (pc: scale 10 ionian ))) duration \n))) (basso (*metro* get -beat 4) 48 8) ... the basso profundo voice enters on the .rst beat of the next \nbar, perfectly synchronising to the ongoing chord progression with a slowly falling Ionian scale. In \nthis way a performance unfolds over time, with both performers acting in the world executing and modifying \nplans in response to reactive feedback from the environment. This story illustrates a number of key concerns. \nThe lap\u00adtop performer is affecting change in-the-world in real-time which is only possible when the program, \nthe process and the task domains are temporally aligned. The livecoding per\u00adformer must be able to realise \nupdates to the process domain, through the program domain within the temporal bounds of the task domain. \nIn practical terms this means that the sys\u00adtem needs to support direct manipulation by the programmer \nwithin the bounds of human audio perception fractions of milliseconds for some audio tasks. The system \nalso needs to support the temporal alignment and scheduling of con\u00adcurrent processes: both the chords \nand the basso profundo voices needed to be synchronised temporally and the basso profundo was scheduled \nfor introduction at a time which made sense musically. Finally, the system needs to support multiple \nhuman cognitive cycles of attention, planning and action. In particular, there were times when the programmer \nwas planning future action, by building processes that infer future temporal agency. These planning phases \noccur at the same time that a programmer is also attending to the on\u00adgoing performance and they may need \nto be interrupted to adjust other aspects of the music or visual display. Although planning phases involve \nlimited temporal association be\u00adtween the program and process domains, there is a need for temporal reasoning \nthat is tied to the task domain through real-world, clock-time semantics. Although this scenario is arti.cial, \nthe .rst author of this paper is an active composer and livecoding performer. His work has been performed \naround the world and is viewable online as recorded video screen-casts [? ].  3. With-Time Programming \nWith-Time programming (WTP) extends ideas of just in time programming [37], experimental programming \n[42] and live programming [1, 15, 31, 44], to include timing constraints based on real-world clock-time. \nWe claim that a focus on time driven semantics provides programmers with a strong causal connection to \nthe real-time world. Aligning time in the program, process and task domains helps to sup\u00adport human action \ncycles including planning, execution and feedback. In this section we position With-Time program\u00adming \nwith respect to its comparitors. 3.1 Just In Time and Experimental Programming Just in Time (JIT) programming \nprescribes that algorithmic description and evaluation occur within a temporal quantum that is appropriate \nto a given task domain. Richard Potter offers the following description: ... the goal of just in time \nprogramming is to allow users to pro.t from their task-time algorith\u00admic insights by programming. Instead \nof automating with software what was carefully designed and imple\u00admented much earlier, the user recognises \nan algorithm and then creates the software to take advantage of it just before it is needed, hence implementing \nit just in time.[37] Potter s emphasis that the user as a spontaneous algo\u00adrithm creator is fundamental \nto JIT programming and this distinguishes it from other design-centred, engineering prac\u00adtices. JIT programming \naligns with an iterative and incremen\u00adtal development cycle common to Agile software develop\u00adment methodologies. \nLike Agile methods, JIT programming advocates a style of negotiated development between pro\u00adgrammers \nand their work. Agile methods acknowledge the limitations of formal speci.cation in the development of \nreal-world commercial projects and attempt to systematise the development cycle to accommodate unknown, \nor poorly known, requirements [4]. Where JIT programming diverges from Agile thinking is that it is fundamentally \nmore transient in nature. Not only is development a negotiation, it is also ephemeral. Indeed, during \nthe course of a JIT session, source code which was valid at the start may be re-appropriated for a different \npurpose at the end. In other words, source code will expand, contract and morph during a given session \nand, signi.cantly, the source code at any point in time will only provide a partial view of the active \nruntime system. Today there are many, widely-used JIT programming environments we mention the R statistical \nenvironment as one successful example[39]. For the JIT programmer, there is often no intention to cre\u00adate \na .nal software product and JIT programming is about experiment rather than manufacturing. The term Experi\u00admental \nProgramming has sometimes been used in the same sense as JIT programming and it has also been used to \nde\u00adnote some speci.c JIT programming projects. It has a long history in the Lisp community as re.ected \nin the following quote by Erik Sandewall:  The average Lisp user writes a program as a pro\u00adgramming \nexperiment, i.e.., in order to develop the understanding of some task, rather than in expectation of \nproduction use of the program.[42]. Seymour Papert attempted to start an education revolu\u00adtion around \nthe idea of experimental programming which resonates to this day in the work of the Lifelong Kinder\u00adgarten \nProject at MIT including projects such as Logo [36], Flogo I &#38; II [19] and Scratch [28]. These projects \nall share an interactive and experiential view of programming, which sees the programmer as an active \nlearner engaged in a com\u00adputational experiment.  3.2 Live Programming Live Programming (LP) is a term \nwhich has been used to denote systems which support the direct intervention of the programmer in a program \ns runtime state. It can be thought of as an extreme version of JIT programming where there is a direct \ncorrelation between a program s representation and its execution. For example: In [SubText] the representation \nof a program is the same thing as its execution. Aligning syntax and semantics narrows the conceptual \ngulfs of program\u00adming. The experience of programming becomes more akin to using a spreadsheet than a \nkeypunch [15]. Live Programming often shares an interest in real-world experiential and experimental \nprogramming practice and of\u00adten seeks to provide the programmer with a direct connection to the physical \nworld: In our vision, the Self programmer lives and acts in a consistent and malleable world, from the \nconcrete motor-sensory, to the abstract, intellectual levels. At the lowest, motor-sensory level of experience, \nobjects provide the foundation for natural interaction. Conse\u00adquently, every visual element in Self, \nfrom the largest window to the smallest triangle is a directly manipu\u00adlable object. [44] Examples of \nLP interfaces maybe text-driven systems where each character that is inserted by a programmer is im\u00admediately \ninterpreted and acted upon even before a com\u00admand termination character has been received. Some visual\u00adpatching \nenvironments also support a notion of live program\u00adming where on-the-.y changes to a data-.ow graph are \nim\u00admediately interpreted. For example, environments such as Max/MSP and PureData, support immediate updates \nto a signal processing graph in response to changes in the visual programming interface[38]. 3.3 Features \nof WTP WTP is an extension of JIT programming which emphasises clock-time and interaction with real-world \nartefacts. WTP is an experimental and experiential practice that focuses on the dynamic negotiation of \nartefacts that exist in-the-world. It at\u00adtempts to be incremental and interactive and it supports hot \nupdates to the runtime system. It is reactive to the environ\u00adment, providing feedback to the programmer \nboth through the user interface and also through the programming lan\u00adguage infrastructure. WTP s emphasis \non real-world interac\u00adtion mandates that time and concurrency be .rst-class con\u00adcerns of, not only the \nruntime system, but of the whole pro\u00adgramming infrastructure. As shown in the reference scenario, WTP \ncan support direct and immediate updates to the environment. However, WTP code is a transient interface \nfor intervention rather than being either a static speci.cation, or a live representation. Ultimately, \nWTP attempts to provide the programmer with a strong causal connection to the world by correlating time \nand concurrency across the program, process and task domains. There is at least one reference in the \nliterature where the term Just In Time programming has been used to apply to our conception of WTP: Rohrhuber \net al. describe their JITlib extension to the SuperCollider environment, which is also in the domain \nof livecoding of audiovisual media. We will consider this system in Section 4.5 (Related Work).  4. \nImpromptu In this section we describe Impromptu, a WTP system which has been progressively developed \nand applied in the livecod\u00ading context over the past .ve years [45]. As discussed above, a WTP system \nmust address a num\u00adber of key concerns: It needs to support .rst-class tempo\u00adral semantics and a natural \nstyle of concurrent programming; it needs to provide an integrated, reactive, development envi\u00adronment; \nand it needs to include adequate real-time systems support for the particular task domain. In the following \nsec\u00adtions we outline how Impromptu addresses these issues. Figure 2. The Impromptu IDE  4.1 Dynamic \nand reactive infrastructure The programming language infrastructure of a WTP system must support dynamic \nupdates to the underlying runtime system in a timely manner in other words, the program domain must \nbe able to dynamically in.uence the process domain. A WTP system must also be reactive in nature, in \nthat it provides suitable real-time feedback to the program\u00admer and, ideally, supports various automated \nmechanisms for reactively updating the underlying runtime system. Be\u00adcause programming and execution \nare temporally aligned, these observations imply that WTP development tools must, themselves, be dynamic \nand reactive: they must comply with time and concurrency constraints from the task domain and need to \nbe amenable to reactive updates from the environ\u00adment. Impromptu provides an Integrated Development Environ\u00adment \n(IDE) based around a Scheme language implementa\u00adtion and an audiovisual runtime system. The environment \nincludes, a source code editor, a Scheme interpreter 1,an experimental Scheme-to-x86 compiler (via LLVM), \na con\u00adcurrent (incremental) garbage collector, a debugger, an au\u00addio DSP architecture and a substantial \ngraphics subsystem. Additionally, Impromptu supports a number of options for extension, including a foreign-function \ninterface, a bidirec\u00adtional Objective-C bridge and audio and visual plug-in ar\u00adchitectures. Impromptu \nsupports multi-core and distributed process\u00ading possibly from multiple, collaborating programmers. Its \nuser-interface (UI) allows programmers to select an ac\u00adtive process and then its editing window is used \nto plan and enter functions for scheduling and evaluation. By automated selection and highlighting, the \neditor allows programmers to send arbitrary expressions to an Impromptu process for evaluation either \nvia interpretation or JIT compilation. Im\u00adpromptu strives to make this process as timely as possible. \nIn the context of multimedia performance this means being able to, for example, perform through the interface, \nevalu\u00adating expressions in time to the rhythms of a live ensemble. This is a task that requires co-ordination \nbetween the editor, evaluation engine and underlying runtime system. The Impromptu IDE provides an array \nof standard text\u00adediting tools such as keyword-completion, syntax highlight\u00ading, keyboard shortcuts, \nexpression matching, error high\u00adlighting, text macros, undo/redo, search-and-replace, and so on. The \neditor is also programmable, providing both pro\u00adgrammers and the Impromptu system itself with the ability \nto modify text procedurally. This provides for programmer feedback directly through the text interface. \nAn example of this textual feedback in action is the case of autonomous debugging. Autonomous debugging \nis an im\u00adportant consideration for WTP as the programmer is often involved in other real-time activities \nwhen an error occurs 1 Impromptu s original interpreter was forked from the TinyScheme project [49]. \nIt has been substantially modi.ed since the original fork. a debugging task interrupts human activities \nsuch as lis\u00adtening, musical planning and orchestration and too much time spent attending to debugging \ncan seriously detract from an overall performance. Ideally we would like the debug\u00adger to intercede to \nautomatically solve simple problems and to provide noti.cation and to update the source code to re\u00ad.ect \nthe actions taken. One example where this occurs is in the case of unbound variables in situations where \nIm\u00adpromptu s analyser can discern that the unbound variable can be safely represented with a suitable \ntype and value ( safely in a program/process-domain sense rather than a task-domain sense). The debugger \ncan then automatically substitute the value into the abstract syntax tree and update the source code \nto re.ect the change. There is no doubt that this style of autonomous debugging has a number of task \ndomain rami.cations but it is arguably less invasive than automatically interrupting the programmer from \nher current task to engage in a debugging activity. Maintaining execution of the concurrent process until \nthe programmer .nds time to address the error can be a useful tool. By updating the code, and highlighting \nthe change, the programmer is made aware of the modi.cation and can take action when time permits. Impromptu \ns programmable editing environment also al\u00adlows programmers to build autonomous agents that can gen\u00aderate \nand/or modify the source code at runtime. This style of autonomous editing was a feature of Alex McLean \ns Perl environment [32] and has recently become a central feature of Thor Magnusons ixi language [27]. \nThe Impromptu UI is responsible for displaying informa\u00adtion about the state of the runtime system. Sometimes \nthis information is presented discretely, as with the debugging example above, but there are many situations \nwhere it is con\u00adtinuous. This is the case for load information such as mem\u00adory usage, CPU performance, \nand, more speci.cally, the sys\u00adtem s ability to meet real-time deadlines. The Impromptu UI provides real-time \nfeedback about the system s ability to meet timing constraints using a graphical, heads-up-display that \n.oats above the source code. Timing of temporal recur\u00adsions and other system resource information is \ngraphically displayed to the programmer over the text interface. Additionally, the Impromptu UI provides \ncanvas and plug-in support to the underlying audio and graphics sub\u00adsystems. Plug-in UIs such as those \nin Apple s AudioUnit speci.cation, provide real-time gestural control over plug-in parameters and supplement \nImpromptu s procedural access to these same parameters. (This combination of direct ma\u00adnipulation and \nprocedural control is another example of the coupling of program and process domains.) The Impromptu \ngraphics canvas provides any number of either OpenGL or Quartz graphics contexts for display on any connected \ndis\u00adplays, at any given resolution. Impromptu s canvases pro\u00advide a number of useful abilities such as \nthe ability to cap\u00adture as an image (PDF or bitmap) or as a quicktime movie, to write or read directly \nto or from another canvas (be that OpenGL or Quartz), to capture images directly from the un\u00adderlying \nwindow system, and so on. Finally, the Impromptu Objective-C bridge allows for custom OSX Cocoa UIs to \nbe built on-the-.y and manipulated either procedurally or directly. Impromptu can, and has been, used \nto develop stan\u00addalone OSX desktop applications [46].  4.2 Concurrency In order to support the high \ndegree of parallelism inherent in many real-world task domains, a WTP system should have a concurrency \nmodel which is lightweight [2]. It should attempt to be syntactically and semantically simple. It should \nbe suf.ciently ef.cient to support the domain activity and it should be .exible to allow for easy integration \nwith third\u00adparty libraries and remote systems. Impromptu responds to the .rst three requirements by adopting \na concurrency design pattern which we have dubbed temporal recursion (linguistically rather than mathemat\u00adically \nrecursive). Temporal recursion is a style of time\u00addriven, discrete-event concurrency [6, 24] similar \nto Engines [20, 21] with real-time interrupt scheduling. By scheduling future events in a self referential \nmanner, a temporal loop is formed. Temporal recursion provides an asynchronous, deterministic concurrency \nframework with a simple semantics for both time and concurrency. It is the primary concurrency paradigm \nin Impromptu and in the simplest case, of non-distributed, single-core operation, it is the only model \nwhich programmers need to reason about. The fourth requirement, of .exibility, is implemented using a \nmulti-layer concurrency model as described below. The temporal recursion model is an extension of Im\u00adpromptu \ns support for the real-time execution of arbitrary code blocks such as procedures, closures and continuations. \nA real-time scheduler is responsible for scheduling the exe\u00adcution of code blocks with chronological \nordering. This en\u00adgine is based on a priority queue containing a dynamic num\u00adber of event structures \n tuples containing an execution start\u00adtime, a maximum execution run-time, a process identi.er, a function \n(procedure, continuation or closure), and a vector of one or more argument values as required by the \ngiven func\u00adtion. Events can then be applied using standard procedure\u00adcall semantics by applying the supplied \narguments to the given function. (The scheduler protects message tuples from garbage collection). More \ndetails on temporal recursion are given in the next subsection. Impromptu s temporal recursion model \nand Scheme s top-level interaction work together to support a natural and .exible style of hot-swappable \ncode. The Scheme language makes code updates natural in that modi.cations to the source code are re.ected \nin the next function call so that dynamic updates from the program domain are re.ected in the process \ndomain. Impromptu supports multi-core and distributed compu\u00adtation by supporting a notion of processes. \nProcesses are pre-emptive and each provides an isolated execution stack, heap memory and real-time garbage \ncollector 2. Interac\u00adtion with other Impromptu processes is strictly via message passing through Impromptu \ns inter-process communication (IPC) mechanism. Impromptu s temporal recursion events specify a pro\u00adcess \nID and may be directed to execute on any available Impromptu process. The temporal-recursion discrete-event \nmodel mandates the sequential execution of functions and each Impromptu process is responsible for executing \nthese functions as fast as possible. Impromptu supports standard Scheme semantics particularly with regard \nto state seman\u00adtics. As in standard Scheme, it is possible to program in both functional and imperative \nstyles using the temporal re\u00adcursion model and this provides a straight-forward progres\u00adsion from standard \nScheme programming to Impromptu pro\u00adgramming. A multi-layered approach to concurrency such as this places \nadditional cognitive load on the programmer because he must be able to reason about programs with suitable \nre\u00adgard to all layers. However, a multi-layered approach is the most practical solution for any system \nattempting to provide a deterministic concurrency model while supporting non\u00addeterministic distributed \ncomputation and external library integration. Impromptu attempts to balance these needs with a desire \nto provide a simple, deterministic concurrency model and makes this model explicit. Keeping concurrency \nand time as explicit concerns is, as we have previously men\u00adtioned, an issue that we think is of intrinsic \nimportance to WTP. 4.2.1 Temporal-recursion In this subsection, we provide concrete examples of Im\u00adpromptu \ns temporal-recursion model and describe how the programmer needs to reason about this model. Impromptu \nsupports temporal recursion through a single function -the schedule call. Schedule is an asynchronous \ncall that is responsible for registering an event tuple with the schedul\u00ading engine. In its simplest \nform schedule takes a deadline time and a closure as its only two arguments. If the closure requires \narguments then this variable number of arguments must also be supplied to the schedule call. ;; perodic \ncycle called every 1000 ticks ; ; with incrementing integer counter ( define periodic ( lambda ( time \ncount ) ( print count:> count ) ( schedule (+ time 1000) periodic (+ time 1000) (+ count 1)))) ; ; start \ncycle ( periodic (now)0) Listing 1. Temporal Recursion 2 Actually the garbage collector, which is a concurrent \nvariant of Baker s treadmill [3], runs on its own kernel thread. Therefore each Impromptu process actually \nrequires two kernel threads.  Listing 1 shows the de.nition of a temporal recursion. It is worth noting \nthat the temporal recursion semantics are structured around the notion of scheduled function execu\u00adtion \nas opposed to the more abstract concept of a sched\u00aduled event. We believe that this provides a very minimal \nex\u00adtension to existing Lisp programming practice (in particu\u00adlar, the tail-recursive programming style \nfamiliar to Scheme programmers). In listing 1 a single temporal recursion is started when (periodic (now) \n0) is called. As its .nal action the perodic function schedules its own execution in 1000 clock-ticks \nfrom time and increments both time and count.The count and time arguments are the only observ\u00adable state \nand are isolated to this particular temporal recur\u00adsion. A second, or third etc., concurrent temporal \nrecursion can be started at any time by re-evaluating periodic.Note that any state (i.e. count) is isolated, \nbeing discrete for each temporal recursion. Temporal recursion can also support shared-state. By scheduling \na function closed over count, it is possible to share this state between multiple temporal recursions. \nListing 2 demonstrates the combination of shared state (count) and isolated state (name) between each \ntemporal recursion. The log output of listing 2 will look like this A0,B1,C2,A3,B4,C5,A6... . ; ; shared \nmemory count ( define shared -count ( letrec (( count 0) (proc (lambda (time name) ( print name count \n) ( set ! count (+ count 1)) (schedule (+ time *second*)proc (+ time *second*)name)))) proc )) ; ; start \nthree temporal recursions which share count (let ((time (now))) ( shared -count time A ) ( shared -count \ntime B ) ( shared -count time C )) Listing 2. Temporal Recursions sharing memory Impromptu s temporal \nrecursion is a co-operative con\u00adcurrency model and the programmer is responsible for en\u00adsuring that temporal \nrecursions meet their real-time dead\u00adlines. Functions must either run to completion or explicitly yield \ncontrol. In the simplest case of a single temporal re\u00adcursion this requirement forces the programmer \nto ensure that a queued function is capable of completing its execu\u00adtion before the time of its future \ninvocation. This situation becomes more complex once a second temporal recursion is introduced and the \nprogrammer must ensure that each of two temporal recursions must not only meet their own deadlines, but \nensure that they do not interfere with each others dead\u00adlines. This potentially presents a very dif.cult \nproblem for programmers to reason about but, in practice, the problem is less problematic as the common \npattern of use for temporal recursion is to create functions with extremely short execu\u00adtion times. We \nargue that this convention would not only be characteristic of real-time multimedia, but would be the \ncase with any type of successful, real-time, reactive programming but it is an issue that the programmer \nneeds to be aware of and a consequence of making Impromptu s concurrency model explicit.  4.3 Time \nImpromptu has been designed to provide a reactive system with timing accuracy and precision based on \nthe constraints of human perception. Human auditory perception has a sig\u00adni.cantly higher precision than \nvisual perception and re\u00adquires accuracy in the microsecond range[40]. Although this is signi.cantly \nlonger than the nanosecond clock of most current operating systems, the accuracy required to maintain \na suitable quality-of-service for audiovisual tasks remains a challenge[25]. WTP makes this challenge \neven more dif.\u00adcult by demanding that the real-time system be dynamic. It is not only the dynamic number \nand type of reactive events that can effect real-time performance but also dynamic changes to the execution \nof the reactive system itself. The real-time demands of WTP systems are relaxed by recognising that, \n.rstly, human agency combines perception with cycles of cognition and action with combined timings measured \nin fractions of seconds and, secondly, that timing constraints in the task domain may also be greater \nthan mere perception. For example, in the multimedia performance domain an audience would forgive, or \nnot even perceive, the loss of a single musical note, however the loss of every .fth note might cause \nsome consternation. Thus the quality-of\u00adservice demands on the system are .rm rather than being hard \nreal time. Impromptu includes a .rm real-time scheduling engine based on an earliest-deadline-.rst (EDF) \napproach[8]. The scheduler supports two clock types, an audio-rate clock, measured in audio samples (or \nticks ) since Impromptu was initialised, and a real-world wall clock , represented as an NTP timestamp[33] \n3. Earlier, we claimed that a WTP programming environ\u00adment should support a .rst class semantics for \ntime in order to help programmers reason about the temporal state of a program. Lee et al.[26] proposed \nsix features that should be present in order to provide a programming environment with a .rst class semantics \nfor time: 3 Why does Impromptu have two clocks? An audio-rate clock makes sense for two reasons. Firstly \nas one of Impromptu s primary task domains is temporally bound to human audio perception a clock referencing \nthe audio\u00adrate is useful and appropriate. Secondly, professional audio devices are usually built with \nhigher quality quartz crystals than commodity computing hardware. However, there are two primary problems \nwith an audio-rate clock. Firstly, an audio-rate clock has no notion of real-world time, making it unsuitable \nfor distributed timing tasks. Secondly, it is often convenient for users to operate in terms of wall-clock \ntime - please start this video at 3:00pm . The scheduling engine does not discriminate between these \ntwo time references and programmers are free to use either and to convert freely between the two.  \nThe ability to express timing constraints  Timed communication  Enforcement of timing constraints \n Tolerance to violations and constraints  Maintaining consistency in distributed real-time systems \n Static timing veri.cation  We present these six features in the following sub\u00adsections and outline \nhow Impromptu performs in meeting each requirement. 4.3.1 Ability to express timing constraints Impromptu \nprovides the ability to express both start-time and execution-time constraints in either clock-time or \nsample\u00adtime. Start-time provides the earliest deadline by which a function must begin executing. Execution-time \nexpresses the maximum time available for the execution of the given function. ; ; video player temporal \nrecursion looping ; ; at a rate of 1/24 th of one second . ; ; maximum-execution time of 1/32nd of one \nsecond ( define video -player (lambda ( time mov position ) (let ((frame (gfx:get-movie-frame mov position \n))) ( gfx : draw-image time *canvas* frame 1) (schedule (cons (+ (now)(/ *second* 24)) (/ *second* 32)) \nvideo -player (+ time (/ *second* 24)) mov (+ position 1/24))))) ; ; this call starts the temporal recursion \n;; the execution deadline for this first call ; ; is the default execution duration of the process ( \nvideo -player (now) (gfx:load-movie /tmp/myfilm.mp4 ) 0.0) Listing 3. MPEG Video Playback Listing 3 demonstrates \na straight forward MPEG video player written in Impromptu. The video-player plays back video at a rate \nof 24 frames per second. It has a temporal constraint on its execution-time mandating that each frame \ncomplete its rendering in less than 1/32nd of a second. 4.3.2 Timed Communication Impromptu s primary \ncommunication mechanism is via remote-procedure calls. Impromptu s RPCs can be either synchronous or \nasynchronous. Synchronous RPCs are de\u00adsigned to work within the context of Impromptu s tempo\u00adral recursion \nmodel. A synchronous RPC is responsible for capturing a continuation before sending an asynchronous message \nto the remote process. It then immediately breaks to the top-level. This effectively stalls any active \ntemporal recursion. The result of executing the procedure call on the remote process is returned to the \nsending process, at which point the sending process executes the stored continuation with the returned \nresult. A time-out can be applied to the RPC in which case any stored continuation will lapse after the \ntime-out period has expired. The time-out is also used as the maximum-execution duration for the remote \nprocedure call. Asynchronous calls can also specify a time-out although this value is for the remote \nmaximum-execution duration value only as asynchronous RPC calls do not directly return values. Impromptu \ns internal NTP support includes clock syn\u00adchronisation that has been designed to .ne-tune the local NTP \nhost-time across a LAN. This additional level of clock synchronisation provides temporal accuracy in \nthe microsec\u00adond range for communication between distributed processes [47]. As previously discussed \nthe microsecond range is pre\u00adcise enough to support the synchronisation of audiovisual activities. 4.3.3 \nSystem enforcement of timing constraints Impromptu supports deadline enforcement through both the start-time \nand execution-time of functions. The Impromptu EDF scheduler is responsible for ensuring that events \nare dis\u00adpatched to their requested process, and each process is then responsible for ensuring that each \nevents execution meets its execution-time deadline. Events that the EDF fails to dis\u00adpatch on time are \nsubject to a global reaper. Events which fail to execute within their stated execution-time deadline \nraise an exception or call an optionally supplied closure/continu\u00adation. One problem with Impromptu s \nexecution duration time\u00adout is the time spent in foreign function calls. Impromptu does not have the \nability to abort computation until the completion of a foreign function call. This can effect the systems \nability to respond in a timely manner to calls which exceed their maximum execution duration. However, \nthis excess will be immediately reported on completion of the foreign function call, and the computational \nwill abort. 4.3.4 Tolerance to violations and constraints Impromptu s temporal constraint violations \ncurrently fall into one of two categories. Either an event is late in starting execution, or it is late \nin completing execution. In the .rst case there is some limited programmer discretion in setting a reaper \ntime-out. The scheduler incorporates a global reaper which is re\u00adsponsible for culling events whose start \ntimes are late by an amount greater than a user-de.ned default value (usually in the order of 1ms). Culled \nevents register an error message to the users log view, but are otherwise ignored. There is no similar \ntolerance for missed execution completion times.  4.3.5 Maintaing consistency in distributed real-time \nsystems Impromptu provides co-ordination of distributed processes by incorporating a Linda style Tuple \nSpace model[47] known as Spaces . Spaces provides Impromptu with inter\u00adprocess co-ordination both locally \nand remotely. It is imple\u00admented on top of Impromptu s RPC mechanism and sup\u00adports the same time-out \nsemantics. Spaces implementation is based on the original Linda model [17] and supports the primitives \npost, read and remove -or, in Impromptu, write, read and take. Support for regular expression matches \nand numeric conditionals are supported as tuple parameter matches. Parameter matches can be bound in-place \nas per the original Linda model.  ; ; no timeout - wait indefinitely for new messages to arrive ; ; \nand then repeat ( define mail -reader ( lambda ( username ) (let loop ((mailbox (append mailbox/ username))) \n(spaces:take mailbox subject from message) ( printf from:%s\\nsubject :%s\\n%s from subject message) ( \nloop mailbox ) ) ) ) ; ; read andrew s mailbox (mail -reader andrew ) Listing 4. Linda Co-ordination \non Model  4.3.6 Static timing veri.cation Given the nature of WTP, it is dif.cult to see how a for\u00admal \ntemporal veri.cation of Impromptu programs could pro\u00adceed. There appear to be two signi.cant impediments \nto pro\u00adviding such an analysis. Firstly, as an environment designed for WTP, Impromptu programs are extremely \ndynamic. Not only is it impossible to say with certainty how many, and what type of events the system \nmay be required to process, but it also impossible to know exactly how those events are to be processed \nbefore runtime. Secondly, the system is distributed and highly reliant on integration with external libraries. \nThe culmination of these issues, makes it extremely unlikely that any reasonably\u00adbroad static analysis \nis possible. Instead, Impromptu at\u00adtempts to compensate by providing programmers with run\u00adtime feedback \nabout the temporal state of the executing sys\u00adtem and provides programmers with the ability to control \noverdue tasks through the use of programmer-supplied tim\u00ading constraints.  4.4 AudioVisual Subsystems \nImpromptu provides a substantial runtime system with a particular focus on audio and visual subsystems. \nHere we very brie.y present features of these two major subsystems. 4.4.1 Audio Architecture Impromptu \ns audio subsystem implements the Apple Au\u00addioUnit speci.cation, a set of design requirements for imple\u00admenting \nAudioUnit plugins and the protocols used to con\u00adnect these nodes into arbitrary data-.ow graphs. Addition\u00adally, \nthe speci.cation outlines various protocols for commu\u00adnicating between applications which host these \nDSP graphs and the individual AudioUnit plugins which they instantiate and communicate with. The speci.cation \nalso outlines var\u00adious user interface guidelines4 and various conventions for 4 AudioUnit plugins may \nprovide their own custom GUI. supporting interoperability. The AudioUnit speci.cation is a well-established \nindustry standard supported by the majority of high-end digital audio companies. The AudioUnit/CoreAudio \nspeci.cation prescribes a syn\u00adchronous, data-.ow system, with an adjustable block size and a pull architecture. \nIn its standard form the AudioUnit speci.cation does not explicitly support multi-threaded op\u00aderation. \nHowever, Impromptu supports the parallel process\u00ading of upstream subgraphs. Impromptu also allows on-the-.y \ncompilation of cus\u00adtom AudioUnits at runtime. These custom AudioUnits can be integrated anywhere into \nthe DSP graph. This pro\u00advides Impromptu programmers with the ability to mix and match commercial audio \nplugins with their own on-the-.y custom DSP code. Listing 5 shows the code used to com\u00ad pile and load \na simple low pass .lter. This code can be hot\u00adswapped at anytime without adversely effecting the audio \nsignal chain. Listing 5 shows a custom low-pass .lter. ;; DSP kernel for low pass filter ( define lp \n-filter (lambda (sample time channel data) (let ((frequency (f64g data 0)) (p0 (f64g data 1)) (p1 (f64g \ndata 2))) ( set !p0 (+ p0 (* frequency (- sample p0)))) ( set !p1 (+ p1 (* frequency (- p0 p1)))) (f64s \ndata 1 p0) (f64s data 2 p1) p1 ))) ( define filter -dat (objc:data:make (* 83))) ( f64s filter -dat 0 \n0.5) (au:code: load au-code-node filter lp -filter filter -dat ) Listing 5. Simple LowPass Filter  \n4.4.2 Graphics Architecture Impromptu provides access to the OSX graphics system through a custom canvas \nclass. Canvases can be constructed with any dimension and can optionally be run fullscreen on any available \nvisual display. Any number of canvases can be instantiated for either Quartz vector/bitmap drawing or \nOpenGL rendering. ; ; create canvas 640x480 (define canvas (gfx:make-canvas 640 480)) ; ; start live \nvideo camera (gfx : start -live -video ) ;; create a gaussian blur image filter (define *blur* (gfx:make \n-filter CIGaussianBlur )) ;; playback live camera images at 24 frames per second ( define draw-camera \n( lambda ( time ) (let* ((image (gfx:get-live-frame )) ( filtered -image (gfx:apply -filter *blur* image))) \n( gfx : draw-image time canvas filtered -image 1) (callback (+ time (/ *samplerate* 24)) draw-camera \n(+ time (/ *samplerate* 24)))))) ; ; start drawing to canvas ( draw-camera (now)) Listing 6. Apply gaussian \n.lter to live image stream and render to canvas  The Impromptu graphics subsystem supports OpenGL, GLSL, \nvector drawing, Bitmap drawing, video decoding and encoding and image processing. Figure 3. A snapshot \nof an Impromptu graphics canvas Graphics animation is handled using Impromptu s tempo\u00adral recursion paradigm \nfor concurrency. Listing 6 illustrates the application of a gaussian .lter to a live video stream at \n24 frames per second. A second temporal recursion can be run at a completely separate frame-rate, or \nindeed at a variable frame-rate, with both rendering to a single, or multiple canvases. Audiovisual synchronisation \nis trivial as the same temporal structures are used for both audio and visual change-over-time.  4.5 \nRelated Work There are far too many areas of related work to cover in this small section. Instead, we \nwill brie.y outline a few major in.uences and related projects. Languages such as Lisp [29] and Smalltalk \n[23] have in.uenced Impromptu s interactive nature. Self [44], Boxer [1], SubText [15] and SuperGlue \n[31] have explored the idea of direct manipulation of the process domain through the program domain. \nSimula [13], Erlang [2] and Linda [17] have all in.uenced Impromptu s concurrency model. A precursor \nto this paper s central theme of WTP comes from Rohrhuber et al.[41] in their presentation of JITLib, \na programming extension for the SuperCollider language (and where Just In Time is used in the same way \nthat we refer to WTP). They discuss WTP in relation to real-time audio signal processing and examine \nsome of the concerns raised by dynamic, temporal programming. The .rst explicit reference to a real-time, \ntemporal re\u00adcursion, appears to come from the music programming lan\u00adguage Moxie [9]. Moxie de.nes a cause \noperation which can be used to schedule temporal recursions. Dannenburg s CMU MIDI Toolkit borrowed cause \nfrom Moxie [14]. En\u00adgines [20, 21] and coroutines [13, 34] both support similar concurrency styles to \ntemporal recursion although they are commonly used in implicit abstractions and are generally not implemented \nwith real-time interrupt scheduling. There is a long history of research into real-time tempo\u00adral semantics \nin the embedded systems community. Ada, RT-Java [8] and the synchronous languages Lustre, Esterel and \nSignal [5] are a few of the many languages for embedded programming which support a temporal semantics. \nHow\u00adever, these languages have different design goals to WTP environments. They are primarily designed \nfor product de\u00advelopment, rather than experimentation, and as a result they commonly lack the dynamic \nand interactive nature required for WTP. They are often designed for demanding real-time applications, \nwhere static analysis is applied to tightly spec\u00adi.ed behaviour in order to provide hard real-time temporal \nguarantees. There has been a substantial body of research into Func\u00adtional Reactive Programming (FRP) \nas a paradigm for mod\u00adelling continuous behaviours and discrete events [12, 16, 35, 51]. In many respects \nFRP is similar to synchronous systems, including ChucK which is discussed below. FRP shares many of the \nsame advantages as the synchronous lan\u00adguages (such as formal reasoning) and some of the same disadvantages \n(such as performance and interfacing to non\u00adsynchronous systems). FatherTime (FrTime) has attempted to \naddress some of these concerns by implementing FRP using asynchronous and impure methods [11]. It is \nimple\u00ad mented in Scheme and has had some limited exposure to livecoding practice through the Fluxus [18] \nproject. SuperCollider [30] and ChucK [52] are two of the few programming environments that have directly \naddressed the notion of WTP. Both environments are heavily oriented to\u00adwards audio signal-processing \nand algorithmic music com\u00adposition and are commonly used for livecoding. Both envi\u00adronments share many \nof the same motivations as Impromptu although they are less focused on visual applications. SuperCollider \nwritten by James McCartney shares many architectural features with Impromptu. It is a dynamic, byte\u00adcode \ninterpreted language with a deterministic co-operative concurrency model, real-time garbage collection \nand real\u00adtime EDF scheduling. SuperCollider s concurrency model is asynchronous. ChucK, developed by \nGe Wang and Perry Cook follows in the synchronous languages genre (Signal, Lustre, Esterel [5]) in implementing \na concurrency model with temporal se\u00admantics based around the synchrony hypothesis. ChucK s data-.ow \n[22] shreds , are explicit, user space and deter\u00ad ministic. ChucK s synchronous approach provides one \nof the ma\u00adjor distinctions between the environments. ChucK attempts to provide a similar (synchronous) \nsemantics for program\u00adming tasks at both low-level continuous and higher level dis\u00adcrete temporal levels \n5. This provides for an elegant, uni.ed semantics for programmers. However, a purely synchronous 5 Continuous \nin this context meaning changing every tick of some clock  implementation strategy makes distributed \nand integration programming dif.cult as synchronous code does not nat\u00adurally co-ordinate with non-synchronous \nexternal libraries and non-deterministic distributed computation. SuperCol\u00adlider and Impromptu s choice \nof asynchronous concurrency trades ChucK s clean semantics for a more .exible architec\u00adture. // define \nrunner function runner = {|msg, k, inc | {|time | // lambda closing over msg k inc // print integer \nmessage (msg ++ k).postln; // increment k k=k+ inc; // loop in 1 second SystemClock.schedAbs( time+1.0,thisFunction \n); }. value ( thisThread . seconds ); // call anonymous lambda }; // start first temporal recursion runner \n. value ( TR-1 ,0 ,1); // start second temporal recursion runner . value ( TR-2 ,0 ,2); Listing 7. Spawning \ntwo SuperCollider Timed Loops An example of this dual semantics in Impromptu is the code in Listing 5 \nwhich includes on-the-.y compilation of DSP code in Impromptu. That example is implicit with re\u00adgards \nto both time and concurrency because it is compiled into a node in a synchronous data-.ow graph. It is \ndynamic, but is semantically removed from the generally explicit and asynchronous temporal recursion \nmodel used for other Im\u00adpromptu programming 6. // define shred function fun void shred runner (string \nmsg, int k, int inc) { while ( true ) { // print integer with message <<< msg, k >>>; // increment integer \nk+ inc=> k; // loop in 1 second 1.0:: second => now ; }} // start first shred spork shred runner( shred \n-1 ,0 ,1); // start second shred spork shred runner( shred -2 ,0 ,2); Listing 8. Spawning two ChucK \nshreds Code Listings 7, 8 and 9 compare similar behaviour in Su\u00ad perCollider, ChucK and Impromptu. All \nthree support an ex\u00adplicit temporal semantics. They all share concurrency mod\u00adels that are deterministic \nand lightweight supporting hun\u00addreds or thousands of concurrent activities. Neither Super-Collider or \nChucK directly support multi-core processing, although they are capable of communicating between mul\u00adtiple \nseparate instances of their runtimes. Both SuperCol\u00ad 6 It is worth mentioning that Impromptu s temporal \nrecursion framework could be used for signal processing (i.e. low-level continuous processing), but this \nwould .t less comfortably with the AudioUnit speci.cation and is less ef.cient. lider and ChucK provide \nstrong start-time constraints al\u00adthough neither environment currently includes support for execution-duration \nconstraints. ; ; define temporal recursion function ( define runner (lambda ( time msg k inc ) ; ; print \ninteger message ( print msg k) ; ; loop in 1 second and increment integer (schedule (+ time *second*) \nrunner (+ time *second*) msg (+ k inc) inc))) ;; start first TR ( runner (now) tr-1 0 1) ; ; start second \nTR ( runner (now) tr-2 0 2)) Listing 9. Spawning two Impromptu temporal recursions  5. Discussion \n5.1 Cyber-physical systems Drawing temporal and concurrency concerns into the pro\u00adgram domain brings \nthe activity of programming into the do\u00admain of cyber-physical systems where programmers become agents \nwith a cyber-physical relationship with the world. As computing becomes increasingly dominated by cyber\u00adphysical \nsystems, the traditional, data-transformational view of computing passed down from Church and Turing \n[25] [7] becomes increasingly incommensurate with computational demands[43]. As expressed by Edward Lee: \n... why is the latency of audio signals in modern PCs a large fraction of a second? Audio processes are \nquite slow by physical standards, and a large frac\u00adtion of a second is an enormous amount of time. To \nachieve good audio performance in a computer (e.g. in a set-top box, which is required to have good audio \nperformance), engineers are forced to discard many of the innovations of the last 30 years of computing. \nThey often work without an operating system, with\u00adout virtual memory, without high-level programming \nlanguages, without memory management, and with\u00adout reusable component libraries, which do not expose \ntemporal properties on their interfaces. Those innova\u00adtions are built on a key premise: that time is \nirrelevant to correctness; it is at most a measure of quality. Faster is better, if you are willing to \npay the price. By con\u00adtrast, what these systems need is not faster computing, but physical actions taken \nat the right time. It needs to be a semantic property, not a quality factor. [25] It is not that computer \nscience has not attempted to rec\u00adoncile a physical time with a computational time but, rather, the level \nof abstraction at which this reconciliation usually occurs. Modern operating systems, routinely provide \nhigh\u00adprecision clocks and operate successfully in highly concur\u00adrent and media-rich environments. Nevertheless, \ntemporality is lost when moving to higher-level languages and runtime environments because real-world \ntime is not of primary con\u00adcern to the computational process for many programming tasks.  With Time \nProgramming is a paradigm which meets many of Lee s key concerns. With Time Programmers are active participants \nin the world and have a fundamental inter\u00adest in time and concurrency. Their role, as human agents in \na cyber-physical relationship with the world, is not only re\u00adactive but also intentional. They become \nan integral part of a cyber-physical system by providing stimulus for the system and reacting responsively \nto its perturbations in the world. Signi.cantly, their role is not merely gestural (or direct) but also \nprocedural, and procedural control provides the ability to plan for future states and to adapt to changing \nrequire\u00adments computationally. Providing WTP programmers with the ability to act procedurally in a reactive \nfeedback loop with the physical world requires suitable time and concur\u00adrency semantics. In particular, \nwe see the need for a .rst\u00adclass semantics for time and a deterministic concurrency paradigm. For WTP, \none of the primary rami.cations of such .rst-class semantics for time is the possibility of align\u00ading \ndevelopment time, computational time and real-world clock-time.  5.2 Conclusion We have discussed a \nprogramming paradigm which we have called With Time Programming and we have claimed that WTP is an extension \nof just-in-time programming where the programmer s real-world causal agency is supported by real\u00adtime \nprogramming infrastructure. WTP is directed towards experimental and experiential practices where an \nenviron\u00admental artefact is the primary goal. We have described a WTP programming environment, Impromptu, \nand we have discussed how Impromptu s sup\u00adport for accurate start-time and execution-time constraints, \nin combination with a simple, lightweight concurrency pat\u00adtern, helps a programmer to reason about, to \ncontrol and to react within a multimedia cyber-physical system. In the fu\u00adture, we are interested in \napplying Impromptu to other do\u00admains, such as robotics and command-and-control, in situa\u00adtions where \nhuman agency is of central concern. We are entering an age in which many computing activ\u00adities will no \nlonger be primarily algebraic and transforma\u00adtional. Instead, computing devices will increasingly interact \nwith each other and the world around them in cyber-physical systems. The work described here is part \nof a continuing ex\u00adploration into the act of programming as a real-time causal activity where the human \nprogrammer is an active agent in a cyber-physical world.  References [1] A. A diSessa and H. Abelson. \nBoxer: a reconstructible com\u00adputational medium. Communications of the ACM, 29(9):859 868, 1986. [2] J. \nArmstrong. Making reliable distributed systems in the presence of sodware errors. PhD thesis, Royal Institute \nof Technology, Stockholm, Sweden, 2003. [3] H. G. Baker. The treadmill: Real-time garbage collection \nwithout motion sickness. ACM SIGPLAN Notices, 27:66 70, 1992. [4] K. Beck, M. Beedle, A. van Bennekum, \nA. Cockburn, W. Cun\u00adningham, M. Fowler, J. Grenning, J. Highsmith, A. Hunt, R. Jeffries, et al. Manifesto \nfor agile software development, 2001. Online: http://www.agilemanifesto.org, 2001. [5] A. Benveniste, \nP. Caspi, S. Edwards, N. Halbwachs, P. Le Guernic, and R. De Simone. The synchronous languages 12 years \nlater. Proceedings of the IEEE, 91(1):64 83, 2003. [6] R. Beraldi and L. Nigro. Distributed simulation \nof timed petri nets. IEEE CONCURRENCY, 7(4):52 62, 1999. [7] W. Beynon, R. Boyatt, and S. Russ. Rethinking \nprogram\u00adming. In Information Technology: New Generations, 2006. ITNG 2006. Third International Conference \non, pages 149 154, 2006. [8] A. Burns and A. Wellings. Real-Time Systems and Program\u00adming Languages: \nADA 95, Real-Time Java, and Real-Time POSIX. Addison Wesley, 2001. [9] D. Collinge. Moxie: A language \nfor computer music perfor\u00admance. pages 217 220. International Computer Music Con\u00adference, ICMC, 1984. \n[10] N. Collins, A. McLean, J. Rohrhuber, and A. Ward. Live coding in laptop performance. Organised Sound, \n8(03):321 330, 2004. [11] G. Cooper and S. Krishnamurthi. Frtime: Functional reactive programming in \nplt scheme. Computer science technical report. Brown University. CS-03-20, 2004. [12] A. Courtney, H. \nNilsson, and J. Peterson. The yampa arcade. In Proceedings of the 2003 ACM SIGPLAN workshop on Haskell, \npage 18. ACM, 2003. [13] O. Dahl and K. Nygaard. Simula: an algol-based simulation language. Communications \nof the ACM, 9(9):678, 1966. [14] R. Dannenberg. The cmu midi toolkit. In Proceedings of the 1986 International \nComputer Music Conference, pages 53 56, 1986. [15] J. Edwards. Subtext: Uncovering the simplicity of \nprogram\u00adming. In In OOPSLA 05: Proceedings of the 20th annual ACM SIGPLAN conference on Object oriented \nprogramming, systems, languages, and applications, pages 505 518. ACM, 2005. [16] C. Elliott and P. Hudak. \nFunctional reactive animation. In Proceedings of the second ACM SIGPLAN international con\u00adference on \nFunctional programming, pages 263 273. ACM, 1997. [17] D. Gelernter. Generative communication in linda. \nACM Transactions on Programming Languages and Systems (TOPLAS), 7(1):80 112, 1985. [18] D. Grif.ths. \nFluxus, 2010. URL http://www.pawfal.org/fluxus/. [19] C. Hancock. Real-time programming and the big ideas \nof computational literacy. PhD thesis, Citeseer, 2003.  [20] C. Haynes and D. Friedman. Abstracting \ntimed preemption with engines* 1. Computer Languages, 12(2):109 121, 1987. [21] R. Hieb and R. Dybvig. \nContinuations and concurrency. In Proceedings of the second ACM SIGPLAN symposium on Principles &#38; \npractice of parallel programming, pages 128 136. ACM, 1990. [22] R. Karp and R. Miller. Properties of \na model for parallel computations: Determinancy, termination, queueing. SIAM Journal on Applied Mathematics, \npages 1390 1411, 1966. [23] A. Kay. Smalltalk, a communication medium for children of all ages. Xerox \nPalo Alto Research Center, Palo Alto, CA, 1974. [24] E. Lee. Concurrent models of computation for embedded \nsoftware. System-on-chip: next generation electronics,page 223, 2006. [25] E. Lee. Computing needs time. \nCommunications of the ACM, 52(5):70 79, 2009. [26] I. Lee, S. Davidson, and V. Wolfe. Motivating time \nas a .rst class entity. Technical Reports (CIS), page 288, 1987. [27] T. Magnusson. Ixilang. URL http://www.ixi-audio.net/ixilang/. \n[28] J. Maloney, L. Burd, Y. Kafai, N. Rusk, B. Silverman, and M. Resnick. Scratch: a sneak preview [education]. \nIn Creat\u00ading, Connecting and Collaborating through Computing, 2004. Proceedings. Second International \nConference on, pages 104 109, 2004. [29] J. McCarthy. Recursive functions of symbolic expressions and \ntheir computation by machine, part i. Communications of the ACM, 3(4):195, 1960. [30] J. McCartney. Rethinking \nthe computer music language: Su\u00adpercollider. Computer Music Journal, 26(4):61 68, 2002. [31] S. McDirmid. \nLiving it up with a live programming language. In Proceedings of the 2007 OOPSLA conference, volume 42, \npages 623 638. ACM New York, NY, USA, 2007. [32] A. McLean. Hacking perl in nightclubs. at http://www. \nperl. com/pub/a/2004/08/31/livecode. html, 2004. [33] D. Mills. Rfc 1305-network time protocol (version \n3) speci.\u00adcation. Implementation and Analysis, 1992. [34] A. Moura and R. Ierusalimschy. Revisiting coroutines. \nACM Transactions on Programming Languages and Systems (TOPLAS), 31(2):6, 2009. [35] H. Nilsson, A. Courtney, \nand J. Peterson. Functional reactive programming, continued. In Proceedings of the 2002 ACM SIGPLAN workshop \non Haskell, page 64. ACM, 2002. [36] S. Papert. Mindstorms: Children, computers, and powerful ideas. \nBasic Books New York, 1980. [37] R. Potter. Just-in-time programming. Watch What I Do: Programming by \nDemonstration, MIT Press, Cambridge, MA, pages 513 526, 1993. [38] M. Puckette. Max at seventeen. Computer \nMusic Journal,26 (4):31 43, 2002. [39] R Project for Statistical Computing. http://www.r-project.org/. \n[40] C. Roads. Microsound. The MIT Press, 2004. [41] J. Rohrhuber, A. de Campo, and R. Wieser. Algorithms \ntoday notes on language design for just in time programming. In International Computer Music Conference, \npage 291. ICMA, 2005. [42] E. Sandewall. Programming in an interactive environment: the lisp experience. \nACM Computing Surveys (CSUR), 10(1): 35 71, 1978. [43] B. C. Smith. On the origin of objects / Brian \nCantwell Smith. MIT Press, Cambridge, Mass. :, 1996. ISBN 0262193639 0262692090. [44] R. Smith and D. \nUngar. Programming as an experience: The inspiration for self. Object-Oriented Programming, pages 303 \n330. [45] A. Sorensen. Impromptu: an interactive programming envi\u00adronment for composition and performance. \nProceedings of the Australasian Computer Music Conference, 2005. [46] A. Sorensen. Oscillating rhythms, \n2008. URL http://www.acid.net.au [] A. Sorensen. Livecoding screencasts, 2010. URL http://vimeo.com/impromptu/videos/sort:plays. \n[47] A. Sorensen. A distributed memory for networked livecoding performance. In International Computer \nMusic Conference. ICMA, ICMA, June 2010. [48] A. Sorensen and A. Brown. aa-cell in practice: An approach \nto musical live coding . In Proceedings of the International Computer Music Conference, pages 292 299, \n2007. [49] D. Sou.is and J. Shapiro. Tinyscheme. URL http://tinyscheme.sourceforge.net. [50] TOPLAP. \nToplap website. URL http://www.toplap.org. [51] Z. Wan and P. Hudak. Functional reactive programming \nfrom .rst principles. In Proceedings of the ACM SIGPLAN 2000 conference on Programming language design \nand implemen\u00adtation, pages 242 252. ACM, 2000. [52] G. Wang, P. Cook, et al. Chuck: A concurrent, on-the-.y \naudio programming language. In Proceedings of International Computer Music Conference, pages 219 226. \nCiteseer, 2003.   \n\t\t\t", "proc_id": "1869459", "abstract": "<p>The act of computer programming is generally considered to be temporally removed from a computer program's execution. In this paper we discuss the idea of programming as an activity that takes place within the temporal bounds of a real-time computational process and its interactions with the physical world. We ground these ideas within the con- text of livecoding -- a live audiovisual performance practice. We then describe how the development of the programming environment \"Impromptu\" has addressed our ideas of programming with time and the notion of the programmer as an agent in a cyber-physical system.</p>", "authors": [{"name": "Andrew Sorensen", "author_profile_id": "81331504369", "affiliation": "Australian National University, Canberra, Australia", "person_id": "P2354156", "email_address": "", "orcid_id": ""}, {"name": "Henry Gardner", "author_profile_id": "81100521514", "affiliation": "Australian National University, Canberra, Australia", "person_id": "P2354157", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869526", "year": "2010", "article_id": "1869526", "conference": "OOPSLA", "title": "Programming with time: cyber-physical programming with impromptu", "url": "http://dl.acm.org/citation.cfm?id=1869526"}