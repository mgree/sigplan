{"article_publication_date": "10-17-2010", "fulltext": "\n Symbolic Heap Abstraction with Demand- Driven Axiomatization of Memory Invariants * Isil Dillig Thomas \nDillig Alex Aiken Department of Computer Science Department of Computer Science Department of Computer \nScience Stanford University Stanford University Stanford University isil@cs.stanford.edu tdillig@cs.stanford.edu \naiken@cs.stanford.edu Abstract Many relational static analysis techniques for precise rea\u00adsoning about \nheap contents perform an explicit case analy\u00adsis of all possible heaps that can arise. We argue that \nsuch precise relational reasoning can be obtained in a more scal\u00adable and economical way by enforcing \nthe memory invari\u00adant that every concrete memory location stores one unique value directly on the heap \nabstraction. Our technique com\u00adbines the strengths of analyses for precise reasoning about heap contents \nwith approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Further\u00admore, \nby avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world \npro\u00adgrams with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, \nincorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after .xing 4 previously \nundiscovered bugs found by our system. Our experiments also show that the combina\u00adtion of reasoning about \nheap contents and enforcing exis\u00adtence and uniqueness invariants is crucial for this level of precision. \nCategories and Subject Descriptors D.2.4 [Software En\u00adgineering]: Software/Program Verication General \nTerms Languages, Veri.cation, Experimentation Keywords Heap Analysis, Relational Static Analysis, Ar\u00adray \nAnalysis, Memory Invariants * This work was supported by grants from NSF (CNS-050955, CCF\u00ad0430378) with \nadditional support from DARPA. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. OOPSLA/SPLASH 10, October 17 21, 2010, Reno/Tahoe, Nevada, USA. Copyright \nc &#38;#169; 2010 ACM 978-1-4503-0203-6/10/10. . . $10.00 1. Introduction In the past decade, there has \nbeen considerable progress in reasoning statically about the heap and contents of un\u00adbounded data structures. \nIn particular, for reasoning about array contents, techniques such as [1 5], have focused on in\u00adferring \nand expressing interesting invariants that are shared between different elements of arrays. For example, \nconsider the following code: for(i=0;i< n;i++){ if (*) a[i] = b[i] else a[i] = NULL; } Here we assume \nthat the condition (*) is suf.ciently com\u00adplicated that whatever static analysis we are using cannot \nun\u00adderstand it. Even in the presence of such uncertainty, tech\u00adniques for reasoning about the contents \nof arrays can still represent that for all i in the domain of arrays a and b, ei\u00adther a[i] is equal to \nb[i] or a[i] is NULL. While having an accurate understanding of the contents of arrays is often necessary \nfor proving non-trivial proper\u00adties about real programs, this information alone is also often not suf.cient. \nIn the speci.c case of reasoning about arrays, one coarse but accurate intuition is that while these \ntech\u00adniques are good at characterizing array writes, they can still lose information about array reads. \nConsider again the code fragment above. On exit from the loop, we know that a[i] is equal to either NULL \nor b[i]. While we do not which of the two values each a[i] holds, the information about the array contents \nis quite precise. In fact, it is the most pre\u00adcise information possible about what is written into array \na given that we know nothing about the conditional s predi\u00adcate. Now, consider the following code snippet, \nwhich im\u00admediately follows the loop above:  x = a[k]; y = a[k]; if(x != NULL) assert(y==b[k]); What \nis needed to prove the assertion in this example? We need to know that (i) x is either NULL or b[k], \n(ii) y is also either NULL or b[k], (iii) the two successive reads from a[k] yield the same value regardless \nof a s contents. Precise heap analysis techniques such as [1, 3, 6 8] can naturally reason about (i) \nand (ii), but something more is needed to reason about (iii). The dif.culty is the uncertainty involving \nthe actual value of a[k]. If we proceed naively, the .rst read of a[k] can be NULL or b[k], and so x \ncan be either value. Similarly, the second read of a[k] can be NULL or b[k], and so y can also be either \nvalue. Then, in reasoning about the assertion, it appears that x != NULL can hold (since one possibility \nis that x is b[k]) at the same time that y == NULL also holds (since one possibility is that y is NULL), \nand the assertion cannot be discharged. We have lost the relationship between x and y, namely that in \nall executions x == y. Establishing property (iii) is very important because it allows relational reasoning \nin the presence of uncertainty by establishing correlations between values stored in different heap locations \n(e.g., the relationship between x and y above). A standard way to deal with this dif.culty is to perform \nan explicit case split: Construct one heap abstraction H where a[k] s value is NULL and another heap \nabstraction H' where a[k] s value is b[k]. Since x and y both have the value NULL in heap H and both \nhave the value b[k] in H', the equality of x and y can be established and the assertion is discharged \n[1, 6, 9]. Put another way, a case split on the possible values of a[k] allows us to know that both reads \nof a[k] in the example return the same value. This paper is about avoiding case splits on the heap ab\u00adstraction, \nwhich we consider problematic for both practical and philosophical reasons: Case splits on the heap \nare generally eager operations: as illustrated above, .rst the heap is split into the various possibilities \nand only then is the subsequent code ana\u00adlyzed. Thus, we pay the full price of the case analysis up front, \nwithout knowing whether the split is eventually needed to prove some property of interest.  Case splits \ncan (and do) result in an exponential blow-up: Every time an abstract location may point to n distinct \nmemory locations, then n distinct copies of the heap must be created and separately analyzed, quickly \nresulting in an infeasible number of heap con.gurations. Even if the preceding point can be addressed \nand the case analysis is somehow performed lazily, the state space explosion problem from duplicating \nthe abstract heaps still persists.  The case splits are really just a form of disjunction (i.e., the \ndisjunction of n possible worlds). Given that disjunc\u00adtion is already required to represent multiple \npossible  contents of individual locations (e.g., a[k] may be either NULL or b[k]), it would be conceptually \nsimpler and pre\u00adsumably easier to implement a system with only a single way of performing disjunctions. \nIn this paper, we address the problem of establishing rela\u00adtional reasoning without creating explicit \ncopies of abstract heaps. We argue that the need for constructing duplicates of the heap arises from \nthe lack of one very important and primitive invariant that real computer memories satisfy but that is \nnot enforced directly by standard heap abstractions: .rst, every memory location has at least one value \n(exis\u00adtence) and second, every memory location has at most one value (uniqueness). Consider the original \nheap abstraction described above, where a[k] may be either b[k] or NULL. As the informal reasoning we \ncarried out suggests, this abstraction does not prevent a[k] from simultaneously being equal to both \nb[k] and NULL, and so even adjacent reads from a[k] cannot be proven to yield the same value. The case \nanalysis, in essence, enforces the existence and uniqueness invariant by creating multiple disjoint heaps \nwhere the abstract memory location of interest has exactly one value. The key insight underlying our \ntechnique is to create a single heap abstraction that enforces the existence and uniqueness invariants \nwithout requiring an explicit case analysis of heap values. To be concrete, consider a heap abstraction \nin which the possible points-to targets of a loca\u00adtion a are x and y. Our technique quali.es points-to \nedges from a to x with a formula fx and the edge to y with a formula fy such that by construction, fx \nand fy are con\u00adtradictory (guaranteeing that a cannot simultaneously point to both x and y, enforcing \nuniqueness) and their disjunction is valid (guaranteeing that a points to at least one of x or y in every \npossible world, enforcing existence). These for\u00admulas add no new mechanism, using the same language of \nformulas already needed just to describe the contents of the heap. The method is also inherently lazy; \nthe formulas are small and all the work is deferred until constraint solving is performed. The main advantage \nof this symbolic approach is that, while a case analysis may eventually be needed in solving the constraints, \nconstraint solvers often avoid the full case analysis because satis.ability or validity can often be \neasily established without examining the entire formula in detail, and furthermore several disjoint heaps \ndo not need to be separately analyzed. Enforcing existence and uniqueness of memory contents directly \nleads to precise relational reasoning. For instance, in the code example, suppose that the heap abstraction \nencodes a[k] is NULL under some constraint f1 and b[k] under some constraint f2 such that f1 and f2 are \ncontradictory. Then, it is easy to see that x and y are equal to NULL under constraint f1 and equal to \nb[k] under constraint f2. Since f1 and f2 are contradictory, the heap abstraction directly encodes x \n  Figure 1. An exact symbolic heap and y must have the same value, allowing the assertion to be discharged. \nTo summarize, in this paper, we propose a technique that uni.es reasoning about heap contents with enforcing \nthe fundamental memory invariant that every concrete memory location has a unique value until its next \nwrite. Speci.cally, we extend the symbolic heap abstraction described in [4] for reasoning about heap \ncontents to enforce existence and uniqueness of values stored in memory locations. Our ap\u00adproach combines \nthe strengths of techniques for reasoning about heap contents, such as [1, 6, 9] with techniques that \nfocus on the axiomatization of memory invariants, such as decision procedures like the theory of arrays \n[10]. 1.1 A Quick Overview In this subsection we give a high-level overview of the tech\u00adnical sections \nthat follow. A symbolic heap abstraction [4] represents points-to relations in the heap as directed edges \nin a graph where nodes correspond to abstract memory loca\u00adtions. In general, abstract locations represent \na non-empty set of concrete locations; for example, an array is repre\u00adsented by a single abstract location \nthat represents all of the concrete elements of the array. Each points-to edge in the symbolic heap is \nlabeled with a bracketing constraint, (fmay,fmust), identifying which concrete elements within a given \nabstract location may and must point to which con\u00adcrete elements in the target location. Therefore, the \nsymbolic heap abstraction simultaneously encodes both an over-and an underapproximation of the concrete \nheap. The simultane\u00adous use of over-and underapproximations is useful in multi\u00adple ways, which are relevant \nto but not the topic of this paper. For example, bracketing constraints are needed in sound and precise \npath-sensitive analysis (and, in particular, in comput\u00ading complements of path conditions) [11] and in \nde.ning a precise location update mechanism, called a .uid update [4]. The key soundness invariant of \nthis symbolic heap abstrac\u00adtion is that the disjunction of all may conditions on edges outgoing from \nan abstract location A is valid, while the pair\u00adwise conjunction of any two must constraints on outgoing \nedges from A is unsatis.able. We say that a heap abstraction is exact if the over-and underapproximations \nare identical. An exact abstract heap describes precisely one concrete heap. Therefore, when the over-and \nunderapproximations encoded by the symbolic heap are identical, the symbolic heap already encodes exis\u00adtence \nand uniqueness of values stored in memory locations. For example, the symbolic heap shown in Figure 1 \nis exact Figure 2. An inexact symbolic heap since the may and must conditions on points-to edges are \nidentical. In particular, this abstract heap encodes a concrete heap where the .fth element of an array \na points to X and all other elements point to Y . Observe that this symbolic heap encodes that no concrete \nelement in array a can simultane\u00adously point to both X and Y because the may conditions on the edges \nto X and Y are disjoint, thereby encoding unique\u00adness of the value stored in any concrete element in \na. Simi\u00adlarly, this symbolic heap also encodes that every element in a has some value (i.e., existence) \nsince the disjunction of the must conditions is true. In practice, except for the simplest heaps, symbolic \nheaps are rarely exact. Consider the imprecise symbolic heap in Figure 2. This abstraction encodes that \nany element of array a in the range [0, 4] may point to X, but no element must point to X. On the other \nhand, any element in the array may point to Y , but elements whose indices are not in the range [0, 4] \nare guaranteed to point to Y . Such a symbolic heap no longer encodes existence and uniqueness of concrete \nelements; for example, elements in the range [0, 4] may point to X or Y or neither. More technically, \nwe can see that the conjunction of the may constraints is now satis.able (allowing a memory location \nto point to two different places simultaneously), and the disjunction of the must constraints is not \nvalid (allowing a memory location to possibly have no value at all). Hence, as illustrated by these examples, \nwhile an exact symbolic heap, such as the one from Figure 1, encodes ex\u00adistence and uniqueness, the normal \nsituation of an imprecise symbolic heap such as the one from Figure 2 does not. Ob\u00adserve that the use \nof bracketing constraints is not the source of this dif.culty; any heap abstraction that encodes only \nan over-or an underapproximation is imprecise and will suffer from the same problem. In fact, bracketing \nconstraints only improve the situation by making it explicit whether the ab\u00adstraction enforces existence \nand uniqueness of memory con\u00adtents. To be able to reason about existence and uniqueness in\u00advariants in \nthe presence of uncertainty without performing case splits, our approach augments the symbolic heap ab\u00adstraction \nwith a technique we call demand-driven axiomati\u00adzation of memory invariants. Speci.cally, whenever a \nbrack\u00adeting constraint on a points-to edge becomes imprecise (e.g., due to imprecise loop invariants \nor branches on values that are not statically known), our technique replaces this impre\u00ad  Figure 3. \nA symbolic heap abstraction cise bracketing constraint with a special formula of the form .=.d . .t such \nthat, by construction, the introduction of these . con\u00adstraints enforces the existence and uniqueness \nof the value stored in each memory location. The demand-driven aspect of our method is again that we \nonly introduce these extra constraints for edges in the points-to graph where the brack\u00adeting constraint \nis not exact. Of course, we do not want to discard the information en\u00adcoded by the original bracketing \nconstraints because they might still provide useful information despite being impre\u00adcise. Hence, to combine \nreasoning about memory invariants and heap contents, our technique introduces a quanti.ed ax\u00adiom of the \nform .i1,...im.fmust . .d . fmay which preserves the partial information present in the impre\u00adcise heap. \nThe introduction of these axioms enforces that any fact that can be proven under the original, but imprecise \nheap abstraction can still be proven to hold under the modi.ed heap abstraction that enforces the existence \nand uniqueness of memory contents. Furthermore, this axiomatization strat\u00adegy guarantees that the number \nof valid assertions that can be proven correct is monotonic with respect to the precision of the heap \nabstraction, a property that does not hold without enforcing existence and uniqueness of memory contents. \n 1.2 Organization and Contributions The rest of this paper is organized as follows: Section 2 reviews \nthe basic symbolic heap abstraction described in [4], and Section 3 describes how to evaluate assertions \non this heap abstraction. Section 4 shows how to combine this heap abstraction with enforcing existence \nand uniqueness in\u00advariants. Section 5 describes our implementation; Section 6 presents experimental results. \nFinally, Section 7 surveys re\u00adlated work, and Section 8 concludes. To summarize, this paper makes the \nfollowing contribu\u00adtions: We argue that enforcing existence and uniqueness of memory contents allows \nfor precise relational reasoning without performing an explicit case split on the possible concrete heaps \nthat can arise.  We propose demand-driven axiomatization of memory invariants as a way to combine the \nstrength of symbolic  Figure 4. A precise heap abstraction heap abstraction with the ability to reason \nprecisely in the presence of partial information. We de.ne what it means for a heap abstraction to be \nmore precise than another heap abstraction, and we show that the set of valid assertions that can be \nproven correct by our analysis is monotonic with the respect to the precision of the heap abstraction, \na property that does not hold without enforcing existence and uniqueness of memory contents.  We demonstrate \nthat the combination of symbolic heap abstraction and demand-driven axiomatization is power\u00adful and scalable \nenough to verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH \n(over 26,000 lines) after .xing 4 unknown bugs discovered by our technique.  We show experimentally \nthat enforcing memory invari\u00adants is as important as reasoning about heap contents and that a substantial \nnumber of assertions requires combined reasoning about both heap contents and memory invari\u00adants.  2. \nSymbolic Heap Abstraction In this section, we review the basic symbolic heap abstrac\u00adtion introduced \nin [4]. 2.1 An Informal Overview In a symbolic heap abstraction, each array is represented by a single \nabstract location quali.ed by an index variable rang\u00ading over the possible indices of the array. Invariants \non ar\u00adray elements are expressed symbolically through constraints qualifying these index variables. A \nkey feature of this tech\u00adnique is that it does not require constructing explicit parti\u00adtions of the heap \nto perform strong updates and does not .x the shape of the invariants that are expressible by a given \npartitioning scheme a priori. As an example, consider the symbolic heap abstraction in Figure 3, which \nrepresents an array a whose elements a[i] in the range [0, size) may be equal to either b[i] or NULL. \nIn this graph, nodes represent abstract memory locations, and directed edges represent points-to relations \nwhere the source of the edge points to the target of the edge. The abstract location (a)i1 represents \nall elements of some array a, and its corresponding index variable i1 ranges over the possible indices \nof this array. The abstract location *(b)i2 represents the points-to targets of the elements of another \narray b, and *NULL represents the abstract location pointed to by NULL.  Constraint pairs (fmay,fmust) \ncalled bracketing constraints on the edges qualify the source and the target locations index variables, \nselecting which concrete elements of the source may and must point to which concrete elements of the \ntarget. By convention, the target location s index vari\u00adables are always primed in the constraints. If \nfmay and fmust are the same, we write a single constraint instead of a pair. The constraint (0 = i1 < \nsize . i ' = i1, false) 2 on the edge from (a)i1 to *(b)i2 indicates that all elements of array a in \nthe range [0, size) may point to the same locations as the corresponding elements of array b (indicated \nby i ' = 2 i1), but since fmust is false, no element must point to the corresponding element in b[i]. \nSimilarly, the constraint (0 = i1 < size, false) on the edge between (a)i1 and *NULL indicates that any \nelement in the range [0, size) may be, but does not have to be, NULL. A main motivation for using bracketing \nconstraints in the points-to graph is to allow a more precise and general update mechanism, called .uid \nupdate, than techniques that iden\u00adtify all updates as either strong or weak. A strong update to an abstract \nlocation l removes all existing points-to edges from l, whereas a weak update preserves all existing \nedges. However, since an abstract location may correspond to many concrete locations, some points-to \nedges from l are removed by an update whereas others are not. To express the range of possibilities between \nthese two extremes without case\u00adsplitting on an abstract location, a .uid update computes a constraint \n. describing which elements of l are affected by the update, and adds a new edge under constraint . while \npreserving existing outgoing edges of l under \u00ac.. However, since it is, in general, impossible to obtain \nan exact descrip\u00adtion of the set of elements updated in loops, . is often an overapproximation; thus, \n\u00ac. is an underapproximation of the elements not affected by the update. For this reason, .uid updates \nrequire that constraints used in the heap abstraction are bracketing constraints. Now, if (fmay,fmust) \nrepresents the concrete elements that may and must be updated, \u00ac(fmay,fmust) . (\u00acfmust, \u00acfmay) soundly \nidenti.es the elements that may and must be un\u00adchanged after the update. In addition to allowing a precise \nand general update mechanism, bracketing constraints also make it explicit when the heap abstraction \nis exact. For example, in Figure 4, since fmay and fmust are the same (indicated by a single con\u00adstraint \ninstead of a pair), this heap encodes that every even element (indicated by i1%2 = 0) in the range [0, \nsize) must be equal to b[i] whereas every odd element must be NULL. This heap might be a re.nement of \nthe symbolic heap from Figure 3, obtained, for example, using a more precise loop invariant.  2.2 Formal \nDe.nition of Symbolic Heaps In a symbolic heap, access paths [12] name abstract loca\u00adtions and are de.ned \nby: Access Path p := l |(p)i |* p | s Here, l names an abstract location corresponding to a vari\u00adable \nor fresh allocation. Any array location is represented by an access path (p)i, where p represents the \narray and i is an index variable ranging over p s indices. The access path *p represents the dereference \nof p. Finally, s denotes a scalar value, such as NULL. Access paths may contain multiple index variables, \nsuch as when modeling nested ar\u00adrays. For example, if x is an array of pointer arrays, then (*(x)i1 )i2 \nnames the abstract location associated with each of the nested arrays. Access paths may be converted \nto terms in the constraint language when they are used in constraints. Base locations l are represented \nby variables of the same name; the access path (p)i is represented by the function term arr(p, i) where \narr is an uninterpreted function. The access path *p is rep\u00adresented as the uninterpreted function term \nderef(p), and .\u00adnally s is represented by a constant of the same value. When access paths appear in constraints, \nwe assume they are im\u00adplicitly converted to terms. DEFINITION 1. (Bracketing Constraints) A bracketing \nconstraint (fmay,fmust) is a pair of constraints with the prop\u00aderty fmust . fmay. In general, fmay and \nfmust may be over any theory; in this paper, we only consider formulas in the combined theory of uninterpreted \nfunctions and linear integer arithmetic ex\u00adtended with divisibility (mod) predicates. In the remainder \nof this paper, any constraint is implicitly understood to be a bracketing constraint. DEFINITION 2. (Boolean \noperations) \u00ac(fmay,fmust) = (\u00acfmust, \u00acfmay) (fmay1,fmust1).(fmay2,fmust2) = (fmay1 . fmay2,fmust1 . fmust2) \n(fmay1,fmust1).(fmay2,fmust2) = (fmay1 . fmay2,fmust1 . fmust2) Satis.ability and validity of bracketing \nconstraints is de\u00ad.ned as follows: DEFINITION 3. (Satis.ability and Validity) SAT((fmay,fmust))= SAT(fmay) \nVALID((fmay,fmust))= VALID(fmust) DEFINITION 4. (Symbolic Heap Abstraction) A symbolic heap abstraction \nis a directed graph where nodes labeled with access paths denote abstract memory locations, and an edge \nfrom abstract location p to p ' indicates that some concrete location in p may point to another concrete \nlo\u00adcation in p '. Edges are labeled with bracketing constraints (fmay,fmust), where fmay and fmust respectively \nconstrain which concrete elements of the abstract source location may and must point to which concrete \nelements of the target lo\u00ad cation.  3. Proving Assertions on the Symbolic Heap In this section, we show \nhow to prove assertions using the information encoded by the symbolic heap abstraction. To be able to \nprove assertions, we .rst need a way to retrieve the possible values stored in a location. 3.1 Determining \nPoints-to Targets First, as mentioned earlier and illustrated in the examples, the formulas on edges \nallow us to talk about properties of subsets of abstract memory locations. For example, in the formula \nin Figure 4, we can see that odd elements of the array point to NULL. Second, as is standard, we can \nuse substitution to interpret which concrete source location may (or must) point to which concrete target. \nSo, in the constraint on the edge from (a)i1 to *(b)i2 , if we substitute 2 for index variable i1, we \nobtain: 2%2 = 0 . i ' 2 =2 . 0 = 2 < size Hence, assuming size is at least 3, this is equivalent to i \n' = 2 2, which tells us that a[2] is equal to b[2]. However, substitution is not powerful enough. In \ngeneral, we may be reading from different indices of the array under different program conditions or \nwe may be unsure about the value of the program variable that is used as an index into the array. For \nthis reason, the index that is read from the array is described by an arbitrary constraint rather than \na simple equality. For example, the constraint (i =2 . .ag) . (i = 5 .\u00ac.ag) describes reading the second \nelement of an array under program condition flag, but the .fth element under \u00acflag. Similarly, for the \narray read a[v], we might know that v has some value less than 4, but we might not know its exact value; \nhence, the array indices that are read are described by the imprecise constraint (i< 4, false). The right \ntool, then, for deducing possible values stored in a memory location is existential quanti.er elimination, \nwhich generalizes substitution to arbitary constraints. For example, if we want to determine the result \nof reading an index whose exact value we do not know but that is de.nitely greater than 2, we can conjoin \nthe constraint (i1 > 2, false)with the appropriate edge constraint and then eliminate the existentially \nquanti.ed variable i1. For example, for the edge from (a)i1 to *(b)i2 in Figure 4, this would yield: \n.i1.((i1 > 2, false). (i1%2 = 0 .i ' = i1 . 0 = i1 < size)) 2 After eliminating i1, we obtain: (i ' 2%2 \n= 0 . 2 <i ' 2 < size, false) which tells us that the result of the read could be any even\u00adindexed element \nof array b. To be precise, we de.ne a read operation on the heap abstraction, read(p, .), which given \nan abstract location p and a constraint . on the index variables of p, yields a set of (access path, \nbracketing constraint) pairs representing the possible results of the read. DEFINITION 5. (read(p, .)) \nLet p be an abstract memory location, and let . = (fmay,fmust) be a constraint such that fmay selects \nat least one concrete element and fmust selects at most one concrete element of p. Let e be an edge from \np to pi quali.ed by constraint fi in the symbolic heap, and let l I be the vector of index variables \nin p. Then, let f ' = Eliminate(.l I.. . fi) i where Eliminate performs existential quanti.er elimina\u00adtion1. \nFinally, let f '' be obtained by renaming primed (i.e., i target s) index variables in f ' to their unprimed \ncounterparts. i Then: (pi,f '' i ) . read(p, .) EXAMPLE 1. Consider the heap from Figure 3. Here, we \nhave: read((a)i1 ,i1 =2) = {(*(b)i2 , (i2 =2 . 2 < size, false)), (*NULL, (2 < size, false)))}  3.2 \nProving Assertions Now, using this read operation, we describe how to evaluate simple assertions on a \ngiven symbolic heap con.guration. We de.ne an assertion primitive assert(S = S ' ) where S = read(p, \n.) and S ' = read(p ' ,. ' ) for some arbitrary abstract locations p, p ' and some index constraints \n., . '. Intuitively, such an assertion is valid if the heap abstraction encodes that the values stored \nin the concrete locations identi.ed by p, . and p ' ,. ' must be equal. DEFINITION 6. (Validity of Assertion) \nConsider the asser\u00adtion: assert(read(p, .)= read(p ' ,. ' )) Let (pi,fi) . read(p, .) and (pj' ,f ' j \n) . read(p ' ,. ' ). Let l' Ii and Ilbe the index variables used in each pi and pj ' , j let Fli, Fl' \ndenote fresh vectors of index variables, and let j Fl= Fli, Fl' = Fl'. The assertion is valid if: i \njj  '' pi[Fli/Ili]= pj ' [Fl/Il] . l' jj VALIDF, Fl. i,j'' . fi[Fli/Ili] . fj ' [Fl/Il] jj Intuitively, \nthis de.nition .rst computes the constraint under which the two sets obtained from read(p, .) and read(p \n' ,. ' ) are equal. As expected, this is a disjunction of all pairwise equalities of the elements in \nthe two sets, i.e., a case analysis of their possible values. Now, for the assertion to be valid, this \nconstraint must be valid. Observe that the constraints in this de.nition are all bracketing constraints, \nand the validity of bracketing constraints from De.nition 2 uses the under\u00adapproximations fimust ,f ' \nsuch that jmust fimust . (p = pi) and fj' must . (p ' = pj' ) 1 Existential quanti.er elimination in \nthe combined theory of uninterpreted functions and linear integer arithmetic may not always be exact; \nhowever, since our technique uses bracketing constraints, we compute quanti.er-free over-and underapproxima\u00adtions \n[13].  Hence, the validity of the above formula guarantees that the values of p and p ' must be equal. \nAlso, note that the renam\u00ad ' ing of index variables to fresh variables F , lFlis necessary to avoid naming \ncollisions when pi and pj ' share index vari\u00adables. This can arise, for example, when pi and pj ' refer \nto distinct concrete elements in the same abstract location. We conclude this section with an example \nillustrating that the symbolic heap does not allow discharging a simple asser\u00adtion because it does not \nenforce existence and uniqueness of memory contents in the presence of imprecision: EXAMPLE 2. Consider \nevaluating the following assertion on the heap from Figure 3: x=a[2]; y=a[2]; assert(x==y) The possible \nvalues V (x) and V (y) of x and y are obtained from V (x)= V (y)= read((a)i1 ,i1 = 2). Hence, assuming \nsize > 2, we have: (*(b)i2 , (i2 =2, false)), V (x)= V (y)= (*NULL, (true, false))) Now, to evaluate \nthe assertion, we query: . . be the constraints qualifying outgoing edges from p. Let Ii denote the primed \nindex variables used in each constraint fi. Then, VALID(.I.lfmayi ) i and UNSAT(.l. fmustj ) for i= \nj I. fmusti However, observe that the soundness of the symbolic heap does not require the following invariants: \nUNSAT(.I. flmayi . fmayj ) VALID(.I.lfmusti ) i Thus, if the heap abstraction is not exact, as is often \nthe case in any heap analysis, the overapproximation does not enforce that each concrete source has at \nmost one concrete target, and the underapproximation does not enforce that each con\u00adcrete source has \nat least one concrete target. Unfortunately, as we saw in Example 2, the lack of these invariants often \nprevents proving even simple assertions in the presence of imprecision. In this section, we describe \nhow to combine symbolic heap abstraction with enforcing existence and uniqueness of ((*(b)f1 = *(b)f2 \n) .(f1 =2, false). memory contents. The key idea underlying demand-driven axiomatization is to replace \nany imprecise bracketing con\u00ad straint (i.e., fmay . fmust) with a constraint . serving two ....... (f2 \n=2, false)). ((*(b)f3 = *NULL) .(f3 =2, false).(true, false)). ....... VALID .f1,f2,f3. ((*NULL = *NULL) \n.(true, false).(true, false)) The result is false because the suf.cient conditions (i.e., fmust) of all \nthe bracketing constraints are false. As this ex\u00adample illustrates, we cannot prove the validity of this \nsim\u00adple assertion using the information encoded by the heap ab\u00adstraction because the heap abstraction \ndescribed so far does not enforce the memory invariant that every concrete loca\u00adtion must have exactly \none value. 4. Demand-Driven Axiomatization of Memory Invariants The overapproximation encoded in the \nsymbolic heap en\u00adforces that every abstract location must have at least one tar\u00adget for any possible \nindex, while the underapproximation en\u00adforces that a speci.c concrete location cannot point to mul\u00adtiple \nconcrete elements. Thus, if the heap abstraction is ex\u00adact (i.e., the over-and underapproximations are \nthe same, as in Figure 4), it follows immediately that the symbolic heap enforces the existence and uniqueness \nof memory contents. More formally, a key soundness requirement for the sym\u00adbolic heap abstraction can \nbe stated as follows: DEFINITION 7. (Soundness Requirement) Let p be a source location in the heap abstraction, \nand let {(fmay1 ,fmust1 ),... (fmayk ,fmustk )} purposes: (i) it enforces that for each concrete source \nloca\u00ad tion, there is exactly one target location it can point to, and (ii) it allows us to retain all \nthe information encoded in the original over-and underapproximations. We .rst develop (i), then (ii). \n 4.1 Enforcing Existence and Uniqueness To enforce that concrete locations have exactly one target lo\u00adcation \n(i.e., (i)), these . constraints must have the following properties: 1. They should enforce that the \nconstraints on any pair of edges outgoing from the same abstract source are dis\u00adjoint (required for uniqueness) \nand that there is at least one feasible abstract target location under any satis.able index constraint \n(required for existence). 2. If there is an edge from ps to pt, the . s should enforce that any concrete \nelement in ps can point to at most one concrete target in pt (also required for uniqueness). 3. The \nintroduction of . s should not prevent different con\u00adcrete elements in the same abstract location from \npointing to the same target.  Of these, (1) and (2) are necessary to enforce the desired existence and \nuniqueness invariant, while (3) is necessary for soundness. By construction, these . s are of the form: \n.=.d . .t  where .d enforces (1) and .t enforces (2), both while respecting (3). We .rst describe the \nconstruction of .d and then .t . Given a source location ps with index variables Ils, let pt0 ,...,ptk \nbe the set of targets of all outgoing edges from ps. For the j th edge from ps to ptj , we construct \n.j as d follows: . . dps (i1,...,im) = 0 if j =0 .j = dps (i1,...,im)= j if 0 <j<k d . (1) dps (i1,...,im) \n= k if j = k where i1,...,im . Ils By construction, each set of .d s for a location ps en\u00adforces that \nthe outgoing edge constraints are pairwise con\u00adtradictory and their disjunction is valid. Here, dps is \nan un\u00adinterpreted function symbol unique to location ps. For an abstract location containing m index \nvariables, it is neces\u00adsary to introduce an m-ary uninterpreted function symbol in order to enforce the \nsoundness requirement (3). Observe that, for concrete assignments lv, vl' to index variables Ils of ps, \ndps (lv) must be equal to dps (vl' ) only if lv = vl'. Hence, while the .d constraints prevent the same \nconcrete source from having different targets, they do not force two distinct concrete locations in the \nsame abstract source to have the same target. We now consider how to construct .t . Recall that .t must \nenforce that a given concrete source location cannot have multiple concrete targets in the same abstract \ntarget location (i.e., (2)), a property that is not enforced by the .d constraints. Hence, to satisfy \n(2), we construct .t as follows. Let i ' ,...,i ' be the index variables used in the j1 jn j th target \nptj . Then, .jt =i ' jk = tk(i1,...,im) (2) 1=k=n Here, tk is an uninterpreted function symbol unique \nto the k th index variable of the target. .j stipulates that each t index variable used in the target \nis a function of the source s index variables, thereby enforcing that each concrete source can have at \nmost one concrete target in the same abstract target location. Finally, to enforce both requirements \n(1) and (2), we modify the constraint on the j th outgoing edge from ps to be: .j =.jd . .jt LEMMA 1. \nLet e1,...ek be the set of outgoing edges from an abstract location ps. Let .1 ,..., .k be the new set \nof constraints constructed as above qualifying e1,...,ek. Then, the symbolic heap abstraction enforces \nthat each con\u00adcrete source location must point to exactly one concrete tar\u00adget location, or alternatively, \nthat each concrete location has exactly one value. Figure 5. The modi.ed version of the heap from Figure \n3 enforcing existence and uniqueness invariants First, we argue that the same concrete source cannot \npoint to two different concrete targets. Let ps[ls/li] denote a con\u00adcrete source, obtained by a variable \nassignment ls to the in\u00addex variables li of ps. Let pt1 [tl1/il t1 ] and pt2 [tl2/il t2 ] be two concrete \ntargets, obtained by variable assignments tl1, tl2 to index variables il t1 , il t2 of abstract locations \npt1 and pt2 . If pt1 [tl1/il t1 ] and pt2 [tl2/il t2 ] are different, then either (i) pt1 and pt2 are \ndifferent abstract locations, or (ii) tl1 = tl2. For (i), observe that this is not possible since UNSAT(.j \n[ls/li] . d .k[ls/li] . j = k) for two edges ej and ek. For (ii), observe d that: t1( s) t1( s) .j =tl1 \n=... and .j =tl2 =... tt tn( s)tn( s) contradicting tl1 = tl2. Now, we argue why each concrete location \nps[ls/li] must have at least one concrete target. Let li' denote the primed index variables used in the \ncon\u00adstraints on outgoing edges from ps. Observe that the formula .li ' . .j[ls/li] is valid; thus each \nconcrete source must 0=j=k have at least one concrete target. The following example shows that, using \nthe modi.ed symbolic heap, we can now prove assertions that could not be discharged using the basic symbolic \nheap. EXAMPLE 3. Consider the heap from Figure 3. For the edge from (a)i1 to *(b)i2 , we construct .1 \n=(d(i1) = 0 . i ' = t(i1)) 2 and for the edge from (a)i1 to *NULL, we construct .2 = d(i1) = 1 This modi.ed \nheap is shown in Figure 5. Now, consider eval\u00aduating the assertion: x = a[2]; y = a[2]; assert(x == y); \non this modi.ed heap as described in Section 3. As be\u00adfore, the values V (x) and V (y) of x and y are \ngiven by read((a)i1 ,i1 = 2): {(*(b)i2 ,d(2) = 0 . i2 = t (2)),V (x)= V (y)= (*NULL,d(2) = 1))}  Now, \nto evaluate the assertion, we query: i ' = i1. Since .j stipulates that each index variable used 2 t \n. . in the target is a function tk(i1,...,im) of the source s in\u00ad (*(b)f1 = *(b)f2 ) . d(2) = 0 .f1 = \nt(2) . d(2) = 0 . f2 dex variables, we apply the substitution st to both fj and may VALID ....... .f1,f2,f3. \n((*(b)f3 = *NULL) . d(2) = 0 .f3 = t(2) . d(2) = 1). ((*NULL = *NULL) . d(2) = 1 ....... fmustj . These \naxioms therefore restrict which set of concrete elements may and must be selected by each .j as stipulated \nd by fj may and fj must as well as restricting the relationship be\u00ad .d(2) = 1) In the .rst disjunct, \nf1 = f2, hence (*(b)f1 = *(b)f2 )= true. Simplifying this formula, we obtain: .f1,f2. ((d(2) = 0 . f1 \n= t(2) . f2 = t (2)) . ... . d(2) = 1) This formula is indeed valid, and we can now prove the assertion. \n 4.2 Preserving Existing Partial Information We now consider the second part of demand-driven axioma\u00adtization: \nRecall that while replacing the imprecise edge con\u00adstraints with the new . constraints ensures that every \ncon\u00adcrete source location points to exactly one concrete target, we would still like to retain the partial \ninformation present in the original, but imprecise heap abstraction. As an exam\u00adple, consider the following \nassertion: if(a[2] != NULL) assert(a[2] == b[2]); Clearly, the heap abstraction from Figure 3 encodes \nenough information to prove this assertion, however, the modi.ed heap from Figure 5 no longer retains \nsuf.cient information to reason that a[2] must be either b[2] or NULL. In particular, the constraint \non the edge to *(b)i2 does not stipulate that i ' = i1; hence, we do not know which element in *(b)i2 \n2 a[2] points to; we only know that it points to some unique element if d(2) = 0 is satis.ed. Hence, \nto preserve the information encoded by the orig\u00adinal imprecise bracketing constraints, we introduce axioms \nfor each .j that encode the additional partial information d j present in the original symbolic heap. \nLet (fj ,fmust) be mayan imprecise bracketing constraint (i.e., fj . fmustj ) on may the j th outgoing \nedge from source location ps, and let .j d be a constraint obtained as described above. As before, Ils \ndenotes the index variables in ps. Let st be a substitution replacing each target index variable with \nits corresponding tk(i1,...,im) from Equation 2. Then, to preserve the in\u00adformation present in the original \nheap abstraction, our tech\u00adnique introduces the axioms: jj j .l.st (fand .l. st (fj ) Ismust) . .d Is. \n.d may First, observe that .j ,fmustj , and fj all qualify the source dmay location s index variables. \nSince the heap abstraction states properties about any concrete location that satis.es the in\u00addex constraint \non edges, the source s index variables are all universally quanti.ed in these axioms. Additionally, ob\u00adserve \nthat fj and fj may also constrain the relation\u00ad may must ship between the source and the target s index \nvariables, e.g., tween the source and the target s index variables. As the following example shows, symbolic \nheap abstrac\u00adtion with demand-driven axiomatization allows combined reasoning about memory contents and \ninvariants. EXAMPLE 4. Consider again the heap from Figure 3 and the modi.ed heap from Figure 5. Our \ntechnique now intro\u00adduces the following axioms: .i1.d(i1) = 0 . (0 = i1 < size . i1 = t (i1)) .i1. false \n. d(i1) = 0 .i1.d(i1) = 1 . 0 = i1 < size .i1. false . d(i1) = 1 Now, consider the assertion: if(a[2]! \n= NULL) assert(a[2] == b[2]) As before: read((a)i1 ,i1 = 2) = {(*(b)i2 ,d(2) = 0 . i2 = t (2)), (*NULL,d(2) \n= 1))} and read((b)i2 ,i2 = 2) = {(*(b)i2 ,i2 = 2)}} Since the conditional requires that a[2] is non-null, \nthe as\u00adsertion is guarded by the predicate: \u00ac(d(2) = 1) Now, we need to show the validity of the formula \n *(b)f1 = *(b)f2 . d(2) = 0 . f1 = t (2) . f2 =2 .f1,f2. . (*NULL = *(b)f2 . d(2) = 1 . f2 = 2) under \nthe assumption \u00ac(d(2) = 1). Simplifying the formula with respect to the assumption \u00ac(d(2) = 1), we obtain: \n.f1,f2. *(b)f1 = *(b)f2 . f1 = t(2) . f2 =2 Hence, it remains to show that under our axioms, t(2) must \nbe equal to 2. Since one of the axioms is .i1.d(i1) = 0 . (0 = i1 < size . i1 = t (i1)) it follows that: \nd(2) = 0 . (0 = 2 < size . 2= t(2)) Since d(2) = 0 is implied by the assertion guard, we have t(2) = \n2; hence f1 = f2, establishing the validity of the asssertion.  While deciding quanti.ed formulas in \nthe combined the\u00adory of uninterpreted functions and linear integer arithmetic is, in general, undecidable, \nthe axioms introduced by our technique belong to a decidable fragment, sometimes re\u00adferred to as the \nmacro fragment [14]. In particular, a syn\u00adtactic instantiation of the axioms for each occurrence of the \nfunction term d(lt) is suf.cient for completeness.  4.3 Monotonicity of Provable Assertions If a heap \nabstraction does not enforce existence and unique\u00adness of memory contents, it turns out that it is possible \nto learn more about the contents of the heap while being able to prove strictly fewer assertions about \nthe program! In other words, for such a heap abstraction, the number of provable assertions is not monotonic \nwith respect to the precision of the heap abstraction. For instance, in Example 2, if we use a less precise \nheap abstraction that maps each element of a to an unknown location, we can prove the assertion assert(x \n== y), which we cannot prove using the more precise heap from Figure 3. We now describe what it means \nfor a symbolic heap to be more precise than another heap abstraction of the same program, and we show \nthat our technique never proves fewer assertions about the program using a more precise heap abstraction. \nFor a heap H and a concrete location l, we use the notation aH (l) to denote the abstract location that \nincludes l in H. We write .(p) to denote the set of concrete locations that are represented by some abstract \nlocation p. ' DEFINITION 8. We say a symbolic heap H splits an ab\u00adstract location p in H into locations \np1,...,pk (where .(p)= .(p1) . ... . .(pk)) under constraints f1,...,fk if for every edge from ps to \npt under constraint f in H: ' 1. If pt = p, then H contains an edge from ps to pj under constraint f \n. fj. ' 2. If ps = p, then H contains an edge from pj to pt under constraint f. ' 3. If ps = p . pt = \np, then H also contains an edge from ps to pt under f. ' Intuitively, if H is obtained from H by splitting \nlocation p to more precise abstract locations p1,...,pk under con\u00adstraints f1,...,fk, then any edge to \np in H is replaced by a set of edges to any abstract location pj under its respective constraint fj . \nDEFINITION 9. We say a heap H is at least as precise as ' another heap H if either of the following two \nconditions are satis.ed: 1. For all concrete locations lc that can arise during the execution of a program, \naH (lc)= aH), and for every w (lcedge from ps to pt quali.ed by constraint (fmay,fmust) ' in H, there \nis an edge in H from ps to pt quali.ed by (f ' ,f ' must) such that: may fmay . f ' . f ' may must . \nfmust ' Figure 6. Heap H and H from the proof. 2. Otherwise, there must exist a concrete location lc \nwith aHw (lc)= p ' and aH (lc)= p0 such that .(p0) . .(p ' ), and there exists a set of abstract locations \np1,...pk in H such that .(p ' )= .(p0) . .(p1) ... . .(pk). ' Furthermore, H must be at least as precise \nas H split '' where Hsplit splits p ' in H into {p0,p1,...pk} under constraints {f1,...,fk} such that \nfor every edge e to p ' under constraint f ' in H ', there is an edge to pj in H under constraint fj \n. f ' . According to the .rst criterion in this de.nition, a heap H ' is at least as precise as H if \nthe abstract locations in the two heaps are the same and the over-and underapproximations encoded by \nthe constraints in H are at least as tight as those in H '. The second condition in the de.nition states \nthat ' if H and H differ in at least one abstract location p, then ' H re.nes H by replacing p with a \nset of abstract locations p1,...,pk, each of which represent a portion of the concrete locations represented \nby p. ' LEMMA 2. Let H and H be two sound symbolic heaps obtained from the same program such that H is \nat least as precise as H '. If H and H ' enforce existence and uniqueness ' invariants, then any assertion \nprovable under H is also provable under H. (Sketch) If H is at least as precise as H ', and for all lc, \naH (lc)= aHw (lc), this lemma is easy to show. We consider the case where there exists some lc such that \n.(aH (lc)) . .(aH)). For simplicity, we assume that there is exactly w (lc ' one abstract location p \nin H that is now represented by two abstract locations p1 and p2 in H (if this is not the case, we can \neasily construct a sequence of more precise heaps from ' H to H that have this property at each step). \nConsider an assertion of the form assert(read(ps,.)= read(p ' ,. ' )) that s is provable in H '. Let \nread(ps,fs)= {..., (pi,fi),...}and read(p ' ,f ' )= {..., (pi' ,f i' ),...} in heap H. Clearly, if ss \nthere does not exist some pi, p ' such that p = pi or p = pi' , i then the assertion is also trivially \nprovable in H. There are two cases to consider: (i) Only one of the read value sets ' contains p in H \nor (ii) both of them contain p in H '. The .rst case is uninteresting since if p is in only one of the \nread sets, p does not play a role in the validity of the assertion. Again, since p1,p2 are not in R or \nR ' and p1 and p2 are Hence, we consider (ii). distinct, this is equivalent to checking:  .. .I. . . \n.'. (f . f1 . f' .. ). .. (**) abstract locations, and fR and f ' represent the disjunction R VALID \n(f . f2 . f'). of the constraints on the edges from ps (resp. p ' ) to each s location in R (resp. R \n'). (The constraints from ps to R are (R = R' . fR . f' R) ' the same in H and H because all existing \ninformation is preserved, i.e., these constraints must be equivalent under the axioms from Section 4.2.) \nTo keep the proof understandable, we only consider the case where p does not contain index variables. \nSince both ' H and H enforce existence and uniqueness of memory contents, we know: fR . f = false f ' \n. f ' = false R fR . f = true f ' . f ' = true R fR . f . f1 = false f ' . f ' . f1 = false R fR . f \n. f2 = false f ' . f ' . f2 = false R f . f1 . f . f2 = false f ' . f1 . f ' . f2 = false fR . (f . f1) \n. (f . f2)= true f ' . (f ' . f1) . (f ' . f2)= true R These constraints imply f . ((f . f1) . (f . \nf2)) and f ' . ((f ' . f1) . (f ' . f2)). Observe that this implies f1 . f2 = true (1) Let Is denote \nthe index variables used in the source lo\u00ad ' cations ps and p ' . For the assertion to be valid in H \n, we s have: .. Now, observe that (f . f1 . f ' ) . (f . f2 . f ' ) . f.f ' .(f1.f2) . f.f ', where the \nlast equivalence follows from (1). Hence, the validity of (*) implies the validity of (**). 5. Implementation \nWe have implemented the ideas presented in this paper in our Compass veri.cation framework for analyzing \nC pro\u00adgrams. Compass supports most features of the C language, including structs, unions, multi-dimensional \narrays, dynamic memory allocation, and pointer arithmetic. Compass does not assume type safety and handles \ncasts soundly using a technique based on physical subtyping [15]. To check for buffer overruns, Compass \ntracks buffer and allocation sizes. Compass can be used for checking both user-provided as\u00adsertions as \nwell as many memory safety properties, such as null dereferences, buffer overruns and underruns, uninitial\u00adized \nreads, leaked stack allocations, and invalid casts. How\u00adever, Compass currently does not check for integer \nover\u00ad.ows; hence, the safety of buffer accesses is predicated on the absence of integer over.ows. Compass \nperforms .ow-, path-, and context-sensitive program analysis. To achieve path-sensitivity, the constraints \nqualifying the edges in the symbolic heap abstraction not only qualify the source and the target s index \nvariables, but can also mention constraints arising from path conditions. .I. . . .'. (p = p . f . f' \nFor interprocedural analysis, Compass performs a summary\u00ad based, context-sensitive analysis. For solving \nconstraints, Compass utilizes a custom SMT solver called Mistral [16], VALID .... .... ). (p = R' . f \n. f' R). (p = R . f' . fR). (R = R' . fR . f' R) Since we know that p is not in R or R ', this formula \nis only valid if the following formula is also valid: .I. . . .'. VALID (*) (f . f') . (R = R' . fR . \nf' R . . . .') Now, the validity of the assertion in H is checked using the formula: .. which also provides \nsupport for on-line simpli.cation of constraints [17]. 6. Experimental Evaluation To evaluate the precision \nand scalability of symbolic heap abstraction combined with axiomatization of memory invari\u00adants, we use \nCompass to check for memory safety properties (speci.cally, null dereferences, buffer overruns and under\u00adruns, \nand safety of casts) in OpenSSH 5.3p1 [18], totaling .I. . . .'. 26,615 lines of code. We believe OpenSSH \nto be a challeng\u00ad (p1 = p1 . f . f1 . f' . f1). (p2 = p2 . f . f2 . f' . f2). (p1 = p2 . f . f1 . f' \n. f2). (p2 = p1 . f . f2 . f' . f1). VALID ............. ............. ing and interesting target because \nit contains many complex array and pointer usage patterns, is heavily optimized for performance, is believed \nto be well-tested, and it is widely deployed. = R' . f . f1 . f' (p1 R). = R' . f . f2 . f' (p2 R). (R \n= p1 . fR . f' . f1). (R = p2 . fR . f' . f2). The results of this experiment are presented in Figure \n7. To quantify the relative importance of reasoning about heap contents and reasoning about memory invariants, \nwe run our (R = R' . fR . f'analysis in four different con.gurations: The .rst con.gura- R)  Combined \nContent Only Mem-Inv Only Smash Time (s) 261 788 103 115 Max memory used (MB) 208 763 144 105 # reported \nbuffer errors 2 77 117 371 # reported null errors 3 53 71 180 # reported cast errors 0 28 11 421 Total \n# of errors 5 158 199 972 Total # of false positives 1 154 195 968 Figure 7. Experimental results obtained \non a single core of a 2.66 GHz Xeon CPU tion, called Combined , employs the technique described in this \npaper, combining symbolic heap abstraction with demand-driven axiomatization of memory invariants. The \nsecond con.guration, called Content Only , tracks contents of memory locations, but it does not enforce \nexistence and uniqueness of memory contents. The third con.guration is Mem-Inv Only , which enforces \nexistence and uniqueness of concrete memory locations (i.e., introduces the . con\u00adstraints from Section \n4), but does not introduce the axioms described in Section 4. The fourth con.guration is Smash , which \neffectively smashes array contents by neither intro\u00adducing memory invariants nor tracking the relationship \nbe\u00adtween indices and contents. As described in Section 5, all con.gurations of the analysis are .ow-, \npath-and context\u00adsensitive. As shown in the .rst column of Figure 7, using the tech\u00adnique proposed in \nthis paper, Compass analyzes OpenSSH in ~ 4.4 minutes using no more than 208 MB of memory, .nding one \nbuffer overrun, one buffer underrun (unrelated to the .rst one), and three null dereference errors, one \nof which is a false positive. The only false positive reported by the analysis is due to an imprecise \nloop invariant, where the in\u00advariant generation aspect of our analysis cannot determine that an array \nelement must be updated exactly once, rather than in multiple iterations, of a loop. In these experiments, \nwe only annotated the relationship between argv and argc in main and provided suitable stubs for functions \nwe did not analyze (e.g., system calls, OpenSSL functions called by OpenSSH). In addition, we had to \nannotate an invariant that relates two .elds of a global data structure. We belive the statistics shown \nin the .rst (Combined) column of Fig\u00adure 7 demonstrate that symbolic heap abstraction combined with demand-driven \naxiomatization is precise and scalable enough to verify memory safety properties in a real applica\u00adtion \nwith suf.ciently useful precision. In contrast, the analysis con.guration (Content Only) that reasons \nabout contents of arrays but that does not enforce memory invariants reports 154 false positives. It \nis inter\u00adesting to observe that in addition to reporting signi.cantly more false positives, the analysis \nalso takes about three times as long as the .rst analysis con.guration (Combined). This longer running \ntime is explained by the fact that many con\u00adstraints can be proven unsatis.able by only taking mem\u00adory \ninvariants into account without needing extra informa\u00adtion about the contents of memory locations. We \nbelieve the striking difference in precision between the .rst and second analysis con.gurations corroborates \nthe hypothesis that rea\u00adsoning about memory invariants is as important as reasoning about contents of \nmemory locations. We next consider the analysis con.guration from Figure 7 that only enforces memory \ninvariants but that does not track the relationship between indices and values. This con.gu\u00adration reports \n195 false positives, con.rming that precise reasoning about array contents is vital for successful veri\u00ad.cation \nof real-world applications. From the 154 and 195 false positives reported by the Content Only and Mem-Inv \nOnly con.gurations, 56 error reports are shared. This observation indicates that at least 56 errors require \ncombined reasoning about array contents as well as memory invariants and cannot be discharged by two \nseparate analyses. The .\u00adnal con.guration, which performs array smashing, reports 968 false positives, \ndemonstrating that this level of precision is unlikely to be useful for veri.cation of real-world appli\u00adcations. \nWe believe the reason that our analysis can scale to a program like OpenSSH with a few ten thousand lines \nof code while performing a very precise analysis of array and heap contents is that it avoids performing \nexplicit case analyses in two important ways: First, by employing the axiomatization strategy described \nin this paper, our analysis can achieve precise relational reasoning without explicitly considering different \nheap con.gurations. Second, by using the .uid update operation [4] for array updates, our technique avoids \ncreating explicit partitions of arrays.  To demonstrate that other C programs also require rea\u00adsoning \nabout memory invariants in addition to heap con\u00adtents, we also applied all four analysis con.gurations \nto .ve Unix Coreutils programs, ranging from 304 to 1151 lines of C code. While symbolic heap abstraction \ncombined with axiomatization of memory invariants is powerful enough to prove the absence of buffer overruns, \nnull dereferences, and casting errors with zero false positives in these programs, neither the Content-Only \nnor the Mem-Inv Only set\u00adting is able to prove all accesses are safe. As shown in Fig\u00adure 8, the relative \nimpact of reasoning about heap contents and memory invariants is roughly comparable, underscoring that \nreasoning about existence and uniqueness invariants is crucial for successful veri.cation of real programs. \n7. Related Work There has been much interest in reasoning about the contents of arrays in the past decade; \nmany of these techniques fo\u00adcus on generating invariants about array elements. Gopan et al. propose a \n3-valued logic-based framework for reasoning about the contents of arrays [1]. In this work, array elements \nthat share a common invariant are placed into a partition, and operations such as focus and blur are \nrequired to iso\u00adlate and coalesce array elements. Jhala and McMillan adopt an approach similar to [1] \nusing counterexample-guided ab\u00adstraction re.nement [2]. The approach presented in [5] also uses abstraction \nre.nement for reasoning about array con\u00adtents. Halbwachs and Peron propose an array content anal\u00adysis \nbased on abstract interpretation for a restricted class of so-called simple programs [3]. In this paper, \nin addition to precisely reasoning about array contents, we present a scal\u00adable technique that enforces \nexistence and uniqueness invari\u00adants and achieves precise relational reasoning without per\u00adforming explicit \ncase splits. Manevitch [19] proposes a heuristic to make TVLA\u00adbased analyses more scalable. To mitigate \nthe state-space explosion that arises from analyzing the set of all possi\u00adble heaps, he proposes partial \nisomorphic heap abstrac\u00adtion, which is a heuristic to merge two abstract heaps if they are universe congruent. \nWhile this technique consider\u00adably speeds up analysis on many benchmarks, it may lose information and \nis not as precise as analyzing all abstract heaps separately. Our technique reasons about only one ab\u00adstract \nheap per program point, and achieves the same level of precision as creating multiple heaps by enforcing \nexistence and uniqueness through constraints on points-to edges. This strategy effectively delays any \ndisjunctive reasoning until constraint solving, and since a constraint solver typically does not need \nto analyze all cases to prove a constraint sat\u00adis.able or unsatis.able, our approach appears to be more \nscalable without losing precision due to heuristic merging of abstract heaps. An alternative to the graph-based \nheap representations considered in this paper is veri.cation-condition generation based approaches for \nreasoning about heap contents (e.g., [20]). These approaches use combinations of various logics, such \nas the theory of arrays [10, 21 23] and pointer logic [24], to generate one large veri.cation condition \nencoding all writes to and reads from the heap. Since these approaches encode the entire history of heap \nwrites and reads in one formula (i.e., the veri.cation condition), these techniques are able to establish \nrelations and correlations between vari\u00adables without requiring any extra machinery. In contrast, ap\u00adproaches \nbased on per program-point heap representations such as [1, 4, 6], track the contents of the heap only \nat a given point in the program, and as a result, do not record a history of how this heap was established. \nFor this reason, the latter approaches need extra tools to achieve precise re\u00adlational reasoning but \ntend to be more scalable because they only encode the current state of the heap. The technique pre\u00adsented \nin this paper combines aspects of both approaches by allowing relational reasoning in a practical and \nscalable way and without requiring the history of updates to the heap. Ef\u00adfectively, our approach separates \nthe task of reasoning about heap contents from answering queries about the heap, and we believe this \nseparation is key to scaling our approach to a program as large as OpenSSH. Work on array analysis from \nthe parallel compiler work of the 80 s and 90 s also infers some aspects of the memory invariant in the \nform of may-dependences and dependence distances [25]. These techniques are targeted at a very dif\u00adferent \nclass of applications and are not as expressive as our approach. We do not address the problem of reasoning \nabout recur\u00adsive pointer data structures. Techniques for reasoning about contents of recursive pointer \ndata structures, such as lists and trees, include (but are not limited to) techniques based on canonical \nabstraction [6] and separation logic [8, 26]. We believe the techniques described in this paper can be \nextended to some recursive pointer data structures, such as lists; we leave this as future work. 8. Conclusion \nWe have presented a new and conceptually simple technique for enforcing correlations between abstract \nread operations on aggregate data structures: rather than splitting the abstract heap into multiple heaps \nso that the memory location of in\u00adterest has a unique value in each individual heap, we enforce via constraints \nthe existence and uniqueness of the value of every memory location. As a result, we are able to delay \nthe cost of analyzing the possible values in the heap from the time when the heap representation corresponding \nto some program statement is .rst constructed to when we need to answer satis.ability and validity queries \nabout a property of the program. By delaying the cost we often avoid having to pay it at all, as in many \ncases queries can be answered by a solver without a full enumeration of all possibilities. We have also \nshown that this improved trade-off in theory actually pays off in practice: our implementation is able \nto analyze medium-sized program such as OpenSSH precisely enough to fully verify memory safety, even \nin the presence of intricate array and pointer operations.  9. Acknowledgments We would like to thank \nMooly Sagiv for several very useful discussions and comments on an earlier draft of this paper. References \n[1] Gopan, D., Reps, T., Sagiv, M.: A Framework for Numeric Analysis of Array Operations. In: POPL, NY, \nUSA, ACM (2005) 338 350 [2] Jhala, R., Mcmillan, K.L.: Array Abstractions from Proofs. In: CAV. (2007) \n[3] Halbwachs, N., P\u00b4 eron, M.: Discovering Properties about Ar\u00adrays in Simple Programs. In: PLDI, NY, \nUSA, ACM (2008) 339 348 [4] Dillig, I., Dillig, T., Aiken, A.: Fluid Updates: Beyond Strong vs. Weak \nUpdates. In: ESOP. (2010) 246 266 [5] Seghir, M., Podelski, A., Wies, T.: Abstraction Re.nement for Quanti.ed \nArray Assertions. In: SAS, Springer-Verlag (2009) [6] Reps, T.W., Sagiv, S., Wilhelm, R.: Static Program \nAnalysis via 3-valued Logic. In: CAV. Volume 3114 of Lecture Notes in Comp. Sc., Springer (2004) 15 30 \n[7] Distefano, D., O Hearn, P., Yang, H.: A Local Shape Analysis Based on Separation Logic. Lecture Notes \nin Comp. Sc. 3920 (2006) 287 [8] Yang, H., Lee, O., Berdine, J., Calcagno, C., Cook, B., Diste\u00adfano, \nD., O Hearn, P.: Scalable Shape Analysis for Systems Code. CAV (2008) 385 398 [9] Bogudlov, I., Lev-Ami, \nT., Reps, T., Sagiv, M.: Revamping TVLA: Making Parametric Shape Analysis Competitive. Lec\u00adture Notes \nin Computer Science 4590 (2007) 221 [10] McCarthy, J.: Towards a Mathematical Science of Computa\u00adtion. \nIn: IFIP. (1962) [11] Dillig, I., Dillig, T., Aiken, A.: Sound, Complete and Scalable Path-sensitive \nAnalysis. In: PLDI, ACM (2008) 270 280 [12] Landi, W., Ryder, B.G.: A Safe Approximate Algorithm for \nInterprocedural Aliasing. SIGPLAN Not. 27(7) (1992) 235 248 [13] Gulwani, S., Musuvathi, M.: Cover Algorithms \nand Their Combination. In: ESOP. (2008) 193 207 [14] Ge, Y., de Moura, L.: Complete Instantiation for \nQuanti\u00ad.ed Formulas in Satis.abiliby Modulo Theories. In: CAV, Springer (2009) 320 [15] Chandra, S., \nReps, T.: Physical Type Checking for C. In: PASTE 24(5) (1999) 66 75 [16] Dillig, I., Dillig, T., Aiken, \nA.: Cuts from proofs: A complete and practical technique for solving linear inequalities over integers. \nIn: In CAV, Springer (2009) [17] Dillig, I., Dillig, T., Aiken, A.: Small Formulas for Large Programs: \nOn-line Constraint Simpli.cation in Scalable Static Analysis. In: SAS. (2010) [18] http://www.openssh.com/: \nOpenssh 5.3p1 [19] Manevich, R.: Partially Disjunctive Shape Analysis. PhD thesis, Tel Aviv University \n(2009) [20] Lahiri, S., Qadeer, S.: Verifying Properties of Well-founded Linked Lists. In: Proceedings \nof the Symposium on Principles of Programming Languages. (2006) 115 126 [21] Bradley, A., Manna, Z., \nSipma, H.: What s Decidable About Arrays? Lecture notes in computer science 3855 (2006) 427 [22] Stump, \nA., Barrett, C., Dill, D., Levitt, J.: A Decision Proce\u00addure for an Extensional Theory of Arrays. In: \nIEEE Sympo\u00adsium on Logic in Computer Science. (2001) 29 37 [23] Habermehl, P., Iosif, R., Vojnar, T.: \nWhat Else is Decidable about Integer Arrays? Lecture Notes in Computer Science 4962 (2008) 474 [24] Kroening, \nD., Strichman, O.: Decision Procedures: An Algo\u00adrithmic Point of View. Springer-Verlag New York Inc (2008) \n[25] Pugh, W.: The Omega Test: A Fast and Practical Integer Programming Algorithm for Dependence Analysis. \nIn: ACM Conference on Supercomputing. (1991) 4 13 [26] Reynolds, J.: Separation logic: A Logic for Shared \nMutable Data Structures. In: 17th Annual IEEE Symposium on Logic in Computer Science. (2002) 55 74  \n  \n\t\t\t", "proc_id": "1869459", "abstract": "<p>Many relational static analysis techniques for precise reasoning about heap contents perform an explicit case analysis of all possible heaps that can arise. We argue that such precise relational reasoning can be obtained in a more scalable and economical way by enforcing the memory invariant that every concrete memory location stores one unique value directly on the heap abstraction. Our technique combines the strengths of analyses for precise reasoning about heap contents with approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Furthermore, by avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world programs with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after fixing 4 previously undiscovered bugs found by our system. Our experiments also show that the combination of reasoning about heap contents and enforcing existence and uniqueness invariants is crucial for this level of precision.</p>", "authors": [{"name": "Isil Dillig", "author_profile_id": "81331491247", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P2354080", "email_address": "", "orcid_id": ""}, {"name": "Thomas Dillig", "author_profile_id": "81331491149", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P2354081", "email_address": "", "orcid_id": ""}, {"name": "Alex Aiken", "author_profile_id": "81100399954", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P2354082", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869493", "year": "2010", "article_id": "1869493", "conference": "OOPSLA", "title": "Symbolic heap abstraction with demand-driven axiomatization of memory invariants", "url": "http://dl.acm.org/citation.cfm?id=1869493"}