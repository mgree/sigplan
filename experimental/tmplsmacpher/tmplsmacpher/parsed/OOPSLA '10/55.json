{"article_publication_date": "10-17-2010", "fulltext": "\n Flexible Modeling Tools for Pre-Requirements Analysis: Conceptual Architecture and Research Challenges \n Harold Ossher1, Rachel Bellamy1, Ian Simmonds1, David Amid2, Ateret Anaby-Tavor2, Matthew Callery1, \nMichael Desmond1, Jacqueline de Vries1, Amit Fisher2, Sophia Krasikov1 1IBM T.J. Watson Research Center \nHawthorne, New York, USA ossher,rachel,simmonds,mcallery,mdesmond,devries,kras@us.ibm.com Abstract A \nserious tool gap exists at the start of the software lifecy\u00adcle, before requirements formulation. Pre-requirements \nanalysts gather information, organize it to gain insight, en\u00advision possible futures, and present insights \nand recom\u00admendations to stakeholders. They typically use office tools, which give great freedom, but \nno help with consistency management, change propagation, or information migration to downstream tools. \nDespite these downsides, office tools are still favored over modeling tools, which are constrain\u00ading \nand difficult to use. We introduce the notion of flexible modeling tools, which blend the advantages \nof office and modeling tools. We propose a conceptual architecture for such tools, and outline research \nchallenges to be met in realizing them. We briefly describe the Business Insight Toolkit, a prototype \ntool embodying this architecture. Categories and Subject Descriptors: D.2.1 [Software En\u00adgineering]: \nRequirements/Specifications Tools. General Terms: Design, Human Factors. Keywords: Flexible modeling, \nmodeling tools, pre\u00adrequirements analysis, business analysis. 1. Introduction Few business software \nprojects begin with requirements engineering. Before requirements some form of business analysis is conducted \nto determine whether new develop\u00adment is needed. At this stage, before requirements are for\u00admulated, \nactivities include gathering information, organiz\u00ading it to gain insight, envisioning alternative futures, \nand presenting insights and recommendations to stakeholders. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for profit or commercial advantage and that copies bear this notice and the \nfull citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute \nto lists, requires prior specific permission and/or a fee. Onward! 2010 October 17 21, 2010, Reno/Tahoe, \nNevada, USA. Copyright &#38;#169; 2010 ACM 978-1-4503-0236-4/10/10 $10.00. 2IBM Haifa Research Center \nHaifa, Israel davida,atereta,amitf@il.ibm.com Currently available tooling for this early stage of the \nsoft\u00adware lifecycle is inadequate. For good reasons, discussed below, users prefer office tools. However, \nthese tools are limited in organizing infor\u00admation, with no underlying content models; while represen\u00adtations \nof visual elements are persisted, there is no notion that those elements represent content in the user \ns domain. Consequently, consistency must be maintained manually; users spend valuable time propagating \neven small changes. Practitioners reported spending entire days on manually maintaining consistency, \nwhich not only consumes time but disrupts flow. Migrating results to downstream modeling tools, which \nare founded on domain-specific content mod\u00adels, is inevitably manual; traceability is usually lost. Modeling \ntools, such as for Business Process Models (BPM)1, may be used at this early stage. They have the opposite \nproblem to office tools, however. They have un\u00adderlying content models depicted by visual elements. Metamodels \nconstrain the structure of the content, thereby restricting the usage of visual elements, typically with \na level of precision premature at this stage. A pre-sales con\u00adsultant reported spending as much time \ninventing details to dismiss irrelevant error messages as in mapping the proc\u00adess, and with no actual \nquality improvements. We argue that pre-requirements analysts need flexible modeling tools: tools blending \nthe advantages of office and modeling tools. Such a tool would allow users to work freely and easily \nwith visual elements, attributing meaning to visual characteristics by associating them with elements \nof the underlying content model, thereby enabling consis\u00adtency management. Given suitable domain-specific \ndefini\u00adtions, the tool would provide guidance and checking, with\u00adout requiring strict conformance to \na rigid metamodel. Us\u00aders can thereby move smoothly between informal explora\u00adtion and modeling with varying \ndegrees of formality. We propose a conceptual architecture for such tools, and out\u00adline research challenges \nfor them to be realized. 1 See, for example, http://www.bpmn.org/  This architecture arose from our \nwork on Business In\u00adsight Toolkit (BITKit) [19], a prototype tool supporting pre-requirements analysis. \nWe designed and evolved it by observing its target users and from their feedback. How\u00adever, we believe \nthat flexible modeling tools have broader applicability, since similar considerations apply in other \ndomains, especially those involving exploration. We see value in incorporating many of the features we \ndescribe into standard modeling tools, including tools for UML\u00adbased design, allowing users to work at \nvarying levels of formality. Less formality is desirable for example, during the early, exploratory phase \nof design. The contributions of this paper are: (a) identification of a new, open area for tool research, \n(b) identification of re\u00adquirements, derived from user studies, for tools supporting pre-requirements \nanalysis, (c) a conceptual tool architecture integrating key benefits of office and modeling tools, ena\u00adbling \nusers to move smoothly between exploration and modeling (primarily a novel combination of known archi\u00adtectural \nelements brought together to address specific re\u00adquirements), and (d) identification of related research \nchal\u00adlenges. Section 2 introduces the tooling challenges of pre\u00adrequire-ments analysts, before assessing \nthe adequacy of office and modeling tools, respectively. We highlight fea\u00adtures of office tools missing \nfrom modeling tools that would give them the requisite flexibility. Section 3 de\u00adscribes our conceptual \narchitecture for flexible modeling tools, showing how the advantages of office and modeling tools can \nbe blended. Section 4 describes the BitKit proto\u00adtype and our experience with it. Section 5 discusses \nrelated work.  2. Pre-Requirements Analysis To understand the work of pre-requirements analysts we held \na three-day workshop for twelve IBM Business Archi\u00adtects. This was supplemented by an email shadowing \nof a three month consulting project, in which a Senior Business Analyst established data governance practices2 \nwithin a customer organization, and with on-site observation of a one month project. Each workshop attendee \ndescribed three pre-requirements projects: one that successfully resulted in insights for the customer, \none that failed, and one that was a near-miss or last-minute save. Through these real stories from actual \nprojects, workshop participants focused on their life in the field rather than by the book versions. \nWe found that pre-requirements analysts typically work alone or in small teams, at the site of the business \nbeing analyzed. In the case of teams, members work closely to\u00adgether to reach shared understandings of \nthe situation. Ana\u00adlysts often use ad hoc concepts, diagrams and notations that 2 Data governance includes \nthe establishment of standard data definitions to promote integration of and consistency between the \nmany systems, organizations and processes of a company, together with processes for both maintaining \nand ensuring adherence to those standards. they explain to one another, and that are defined, polished \nor changed before presentation to broader audiences. Ana\u00adlysts themselves are typically business people \nwith deep understanding of business issues and varying degrees of technical expertise. They are usually \nnot the same people who elicit detailed requirements, or architect or design IT systems, and hence are \nnot used to using modeling and de\u00advelopment tools designed to support the software lifecycle. A central \nfinding of this study is that pre-requirements analysts work with a holistic perspective including ideas \nfrom business and, to a lesser extent, from IT. They gather information relevant to a business or pre-identified \nbusiness problem, and organize and make sense of it to identify business issues and potential solutions. \nA presentation is created to communicate proposed solutions and their value to the client s business. \nThus, pre-requirements analysts help their clients frame business problems and explore a variety of feasible \nsolutions. Their role is one of envision\u00ading, which often results in business transformation. The process \nis exploratory. Narratives play a central role in structuring the work of pre-requirements analysts. \nTheir final output is a presenta\u00adtion or report, containing a variety of tables, business proc\u00adess diagrams, \norganizational diagrams, as-is system dia\u00adgrams, etc. While the creation of this narrative is an ex\u00adploratory \nprocess, consultants like to be presentation-ready almost immediately, even if that presentation is a \nrough draft of a final version. Template reuse is a common work\u00ading style, especially for consultants \napplying their accumu\u00adlated experience and expertise to similar issues for several clients. Templates \nhelp organize findings into pre-defined categories and representations that were helpful in past projects; \nand also as a way of reusing narrative structure in presentations. Often the template is adapted to fit \nthe needs of a particular project, including changing styles and vo\u00adcabulary for the storyline, taste \nand culture of the client. Invariably, analysts prefer to work in office tools than modeling tools. To \nunderstand why, we conducted an addi- Office tools Modeling Tools Have broad applicability Support multiple \nviews on the same model Are easy to learn Facilitate consistency man- Presentation tools provide agement \nnarrative structuring in the same medium as final presen-Provide domain-specific guid\u00adtation ance Don \nt constrain development Provide syntax, semantic order model and semantic mapping Provide multiple stylistic \ncues Provide just syntax Table 1: Advantages of office vs. modeling tools  tional study focusing on \nthe users experience of these tools. Using a customized version of the Cognitive Dimen\u00adsions questionnaire \n[5], and follow-up phone interviews, we interviewed five business consultants who use these tools for \ntheir day-to-day work. All but one reported on more than one tool. Two reported on a modeling tool, two \nreported on a diagramming tool (an office tool supporting structured graphics) and four reported on a \npresentation tool. Table 1 summarizes advantages of each type of tool. Given the small number of participants, \nthese results are suggestive rather than conclusive. All interviewees prefer to use office tools where \npossi\u00adble, even for technical diagrams. One interviewee com\u00admented, their immediate need was communication, \nnot de\u00adtailed modeling: you got lots of details in the modeler model, and you just got the pictorial \npresentation with [a diagramming tool], but that was sufficient for communicat\u00ading the business process. \nYou didn't need all the details that were in the [modeling tool] model. Two interviewees commented that \nit would take too long to learn the model\u00ading tool s features. In comparison, the learning curve was \nminimal for getting to the ability to diagram using the diagramming tool. Equally importantly, modeling \ntools cause premature commitment by imposing inappropriate work order and levels of detail: [it] makes \nme be too rig\u00adorous, when I want to be sloppy. Metamodel enforcement forces users to provide details \nbefore they are ready: It tends to force compliance with standards, driving you into the detail before \nthe bigger picture is sorted out. With no underlying content model, office tools are free of constraints \nimposed by metamodels: [the diagramming tool] is really agnostic about what terms 'mean'. They are just \nelements on a page and carry no metadata apart from style. This makes them easy to learn, and ensures \nbroad applicability. Work order is unconstrained, as is level of detail. The user can evolve the diagram \nor presentation as their understanding of what they need to represent evolves: [in office tools] you \nhave to put something in 'a' format or place, it has to go somewhere to begin with. I've never found \nthat much of a problem because I can always move it or format it how I want when I have decided what \nthe over\u00adall structure or content is going to be. Working in the medium used to present is important, \nand is one reason interviewees like to do even preliminary work using presentation tools. Being in the \npresentation medium helps them think through the final form as they create the story: There is an element \nof rehearsal ... as you are selecting the elements and the sequence [I ask myself] what level of detail \ndo I need to go into, am I conveying the message? Am I teaching, or persuading? However, analysts also \nmentioned downsides to office tools. One interviewee recounted how the lack of a detailed model led to \na disconnect between the pre-requirements business case and the detailed models that defined the sys\u00adtem \ndownstream. Changes downstream need to be propa\u00adgated back upstream, but there is no easy way to update \nthe presentations, reports and diagrams produced using office tools. They are not updated, and get out-of-date: \n at that point you are beyond the [diagramming tool] and you don't go back and change the model. Then \nthe docs get out of sync Office tools are viscous: a single consistent change in style or terminology \nof an element may require many ac\u00adtions throughout a document. All interviewees complained of managing \nconsistency across documents and within large documents: Difficult to maintain continuity of thought \nand to ensure that if an element occurs many times in the document they are all kept in sync. A lot of \ntime was wasted making and propagating low-level changes: Time-consuming to arrange all the different \nelements and ensuring consistent styles are used throughout. Consistency issues are typically handled \nwell in model\u00ading tools. Visual elements in both an office tool and a mod\u00adeling tool are syntactic, and \ncombine to form a visual lan\u00adguage supported by the tool. However, modeling tools map syntactic elements \nto elements of an underlying content model (or abstract syntax) [12]. With office tools, the tool supports \nno such mapping; the user might have one in mind, promoting disciplined, consistent usage, but might \ndeviate from it or change it at will. Modeling tools can leverage the content model to provide domain-specific \nguidance and multiple views of the model, and structure\u00adaware operations like query and refactoring. \nNeither office nor modeling tools alone are ideal for the exploration, sense-making and communication \ntasks of pre\u00adrequirements analysts. These user studies show clear trade\u00adoffs between the added power \nand functionality enabled by an underlying content model, and the increased burden it brings to the user \nexperience. For the studied pre\u00adrequirements analysts, the office user experience has clear advantages. \nOffice tools have broad applicability, are easy to learn, and allow the user to choose the order of develop\u00adment, \nwith meaning evolving as content is created. How\u00adever, if such a user experience could be maintained, \npre\u00adrequirements analysts would clearly welcome the advan\u00adtages of an underlying content model.  3. \nConceptual Architecture As introduced above, flexible modeling tools blend the advantages of office and \nmodeling tools, thereby more ef\u00adfectively supporting pre-requirements analysts work. In particular, they \nprovide the free-form, relatively\u00adunconstrained user experience of office tools blended with the support \nfor structure provided by modeling tools, which facilitates multiple views, consistency management and \ndomain-specific support. This structural support is often loosely termed semantics, to reflect the fact \nthat the vis\u00adual elements are not just drawings, as they are in office tools, but have underlying meaning \nthat is represented in the tool (in the underlying content model or abstract syn\u00adtax) and used by the \ntool to help the user. We avoid the term semantics in this paper, however, because some respected authorities \ndeem it to be incorrect in this context [12].  A flexible modeling tool might be built as a modeling \ntool with added flexibility. There are many possible forms of flexibility that would be beneficial, but \nthe primary focus of our work is freedom from the rigid metamodel that typically underlies a modeling \ntool: the flexibility to do, and to save, free-form work that does not conform to the metamodel, to be \nshown violations with customizable degrees of intrusive\u00adness, and to evolve the metamodel while modeling, \nif appro\u00adpriate. A flexible modeling tool might also be built as an office tool with added support for \nrepresenting meaning as\u00adsociated with visual elements a smart office tool. A third possibility is for \na flexible modeling tool to be a new kind of tool entirely, built afresh to realize the desired blend \nof capa\u00adbilities. We present a conceptual architecture that, we argue, is key to accomplishing the blend \nof office- and modeling-tool capabilities whichever of the above paths is followed. It is illustrated \nin Figure 1, and consists of the following ele\u00adments: A visual layer providing multiple views, giving \nthe user much of the freedom of office tools.  An underlying model comprising related visual and con\u00adtent \nsub-models, mapping visual cues to content items. It represents arbitrary, unconstrained information; \nan entity\u00adrelationship model is suitable.  A forgiving approach to domain-specific guidance, with structure \ndefinitions. These specify structural constraints, e.g., restricting the entities that can be related \nby a particu\u00adlar kind of relationship.3 Structure definitions are used to identify structural violations \nand provide assistance. Mod\u00adels violating structure definitions can, however, be created, manipulated \nand saved, as the underlying model is uncon\u00adstrained.  Refactoring support allowing convenient reorganization. \n A presentation layer supporting synthesis of presentations from working views.  These architectural \nelements provide the considerable flexi\u00adbility required by our users. Individuals or small groups with \nshared understanding engaged in exploratory activities do not need precision. Their work is better facilitated \nby auto\u00admatically mapping visual entities to generic content enti\u00adties untyped entities and relationships \nthat can be refined and constrained as work progresses. Multiple views can be coordinated without demanding \npremature commitment or constraining which structures can be expressed. Structure definitions might not \nbe used; or predefined packages de\u00adsigned for a domain can be reused; or generic entities can be refined \nand structure definitions introduced incremen\u00adtally as understanding evolves. Violations might be ignored. \n3 We do not consider behavioral constraints, since models produced dur\u00ading pre-requirements analysis \nare typically not executable. If and when greater precision is required, such as for com\u00admunication with \nother tools, predefined structure defini\u00adtions can be introduced and violations dealt with. Figure 1: \nTop-level conceptual architecture for flexible modeling tools Packages of structure definitions together \nwith addi\u00adtional material to be discussed, such as classification hier\u00adarchies, effectively constitute \nmetamodels. This is key to providing domain-specific assistance. However, the forgiv\u00ading approach to \nguidance ensures that the metamodel acts as an aid rather than a straitjacket, allowing the user to de\u00adviate \nfrom it when appropriate. It is also possible to evolve the metamodel along with the model when appropriate, \nsuch as during early exploration of new domains. These issues, including the desirability and safety \nof this degree of freedom, are discussed further in section 3.8. The architectural elements presented \ndo not constitute a complete tool architecture. A full tool requires many other elements, such as persistence, \nversioning, atomic model updates, undo, and collaboration. These are not specific to flexible modeling \ntools and, therefore, are beyond the scope of this paper. However, unique elements of this architecture \ncan have profound implications elsewhere. For example, our flexible support for visual cues with underlying \nmean\u00ading might be used to visualize collaboration, highlighting entities that others are working on [13]. \nWe aim to support organization and communication of information during pre-requirements analysis in a \nbusiness context. The content of this information is greatly variable, depending on the project, but \ntypically concerns entities (people, organizations, etc.) and their interactions and rela\u00adtionships, \nrather than large quantities of numeric data. The entity-relationship approach is therefore a natural \nfit. We henceforth assume that information consists of entities with properties, and relations between \nentities. Example. Throughout this section, we will illustrate con\u00adcepts using a running example, based \non issue based con\u00adsulting. This approach is used by many business analysts. They conduct interviews \nand examine material to deter\u00admine key issues affecting a business, then make recom\u00admendations for improvement. \nIn our running example, we follow a business analyst exploring issues at the Useless-Gadget manufacturing \ncompany.  3.1 Visual Layer This layer is responsible for displaying visual elements and allowing users \nto manipulate them. Analysts told us that this layer should allow a great deal of flexibility in visually \nexploring, creating and manipulating visual elements as they focus on the content of their analysis. \nOffice tools provide such flexibility, contributing to their popularity in this domain. Modeling tools \ntypically have a visual layer separate from the model, as in the view and controller of the MVC pattern \n[9]. If, as usual, the model constrains the information and its structure, constraints show through in \nthe visual layer, limiting freedom: the visual layer is limited to what the underlying model can represent. \nFlexible mod\u00adeling tools therefore require particularly rich underlying models, as described in section \n3.4. Visual flexibility depends upon the ability to select from and improvise a variety of views. Analysts \noften combine diagrams, tables and text into presentations or other docu\u00adments, and a flexible modeling \ntool can offer an even richer variety. Multiple views allow users to work with their in\u00adformation in \nmany different ways, facilitating exploration and presentation. Office tools do offer a variety of document \nand diagram types, but maintain no relationship between them. Consis\u00adtency management is, therefore, \nmanual. To reduce this burden, flexible modeling tools must use the same underly\u00ading model for multiple \nviews. Furthermore, unlike typical visualizations, all views must allow editing and manipula\u00adtion of \nthe information they show, with changes propagated accordingly. This has been common practice in program\u00adming \nenvironments and modeling tools for decades [21], but here applies to a wider and open-ended variety \nof views over more diverse information. Some views, such as hierarchy charts and process dia\u00adgrams, are \ndesigned for information with specific structure. Because of flexibility inherent in the underlying model, \nand the fact that the model can be changed through other views, the user might try to apply such a specialized \nview to inap\u00adpropriate information. An important special case occurs where some of the expected structure \nis missing because the user has not provided it yet. Flexible modeling tools must be tolerant: rather \nthan refusing to show the informa\u00adtion at all, the view should show as much as possible and use the guidance \nmechanism (section 3.5) to indicate what is incomplete or incorrect and how the user might fix it.  \n3.2 Visual Organization Analysts frequently work with information visually, both exploring it to gain \nunderstanding and again when commu\u00adnicating that understanding. They make use of a variety of visual \ncues, including: D epa r t m e n t s Is s u e s  Sa l e s H i g h e m pl oy ee t u r n o v er  Ma \nn u f a c t u r i n g H i gh pe ak s i n pa r t s i n v e nt or y  Hu m a n R e s o u r c e s Lo w \ns um m er t hr o u g hpu t  H i r i n g s k il le d s e as on al w o r k e r s  S e as on al qu a l \ni t y pr o bl em s  R e l a t i v el y f ew r ep e at c us t om er s  L a te fu l f i l l m e n t d \nu e t o m i s s i n g p a r t s  Figure 2. Two lists that were assembled from inputs gathered in a \nseries of interviews Style. Different shapes, colors, line styles, etc, used to high\u00adlight distinctions \nand commonalities. Entities are often drawn as shapes, and relationships as lines or arrows con\u00adnecting \nthem. Position. Related entities are often positioned to indicate relationships: nearby, side-by-side, \nstacked or layered, or arranged in a list or table. A common case is visual con\u00adtainment, typically used \nto indicate a containment or sub\u00adsumption relationship. Other dimensions, such as time and animation \nremain re\u00adsearch challenges from a flexible modeling perspective. Example. Figure 2 shows lists of departments \nand issues mentioned during interviews with employees in those de\u00adpartments. Simple lists are typical \nin very early stages of projects, as information is gathered. Some of the issues are shown with red text, \nbecause they were stated as being im\u00adportant. These sorts of cues provide what we call visual organi\u00adzation. \nThey aid cognitive processes involved in organizing and understanding information [6]. They also facilitate \nef\u00adfective communication. When used in a consistent and evocative manner, they make, communicate and \nsubtly reinforce important points. When used haphazardly or in\u00adconsistently, they can create confusion \n[15]. As our user studies emphasized, good presenters put a good deal of effort into visual cues. Office \ntools offer a wide variety of visual cues, and free\u00addom to make good (or bad) use of them. Users can \nmove things around freely and experiment with different organi\u00adzations during the exploratory phase, \nand can craft beauti\u00adful presentations to communicate key points once they have been conceptualized. \nUnfortunately, the relationship be\u00adtween visual cues and what they mean is not understood by the tool, \nsince office tools have no notion of underlying meaning. For example, one cannot pose a query asking \nfor all issues, and expect it to use the list shown in Figure 2 to find them. One cannot even query on \nstyle, e.g., find all entities colored red. Flexible modeling must enable such queries, without limiting \ncapabilities for visual organiza\u00adtion.  Is s u e s  H i g h e m pl oy e e t u r n ov e r  H i gh \npe ak s in pa r t s i n ve n t or y  L o w s u m m er t hr ou g hp u t  H i r i ng s k il le d s \ne as on a l w o r k er s  S e a s on al qu a l i t y pr o bl em s  R e l a ti v e l y fe w r e p \ne a t c u s t o m e r s  L a te fu l fi l l m e n t d u e to m i s s i n g p a r ts   Figure 3. A \nlegend which shows how background colors, used in a list, map to various named categories.  3.3 Content \nOrganization To create a coherent analysis and presentation of business issues and potential solutions, \nusers need to organize not merely the visual elements but underlying concepts and data. We call this \ncontent organization. Typical elements of content organization include relationships, grouping, dis\u00adtinctions \nand classification. We observed great variability in the kinds of content organization used across, and \neven within, projects. We discovered that users evolve the concepts that go into the final presentation \nby organizing snippets of infor\u00admation from interviews, prior projects and client docu\u00adments. Sets provide \na well-understood means of dealing uniformly with diverse content organization. In office tools, these \ntypically start as lists. Flexible modeling tools treat lists as enumerated (extensional) sets. During \nexploration, users reorganize the content within and between lists as they attempt to seek appropriate \nstructure. Once a user has organized many snippets, regrouping them using query\u00adbased (intensional) sets \noffers the user further flexibility, reducing the viscosity inherent in manual re-categorization. Example. \nUnderlying the lists shown in Figure 2 are three sets: Departments, consisting of 3 departments.  Issues, \nconsisting of 7 issues.  An anonymous set, consisting of the 3 issues shown with red text.  These sets \nare conceptually distinct from the lists or styles that depict them in Figure 2. Each set could be depicted \nin many other ways, such as nodes in a diagram or rows or columns in a table. The names of the first \ntwo sets can be derived from the list titles. Naming the third set sensibly, e.g., Important, requires \nuser intervention to specify the intended meaning of the red text style. The user should be able to name \nit when ready, but leave it anonymous until then. Another key form of organization is making distinctions \nbetween information snippets, leading to classification. After creating lists, our users notice distinct \nsets within the lists. They then create lists within lists subsets capturing the distinctions. When \ndone recursively this leads to a hier\u00adarchy. Classification can be done by first defining catego\u00adries \nand then categorizing entities. However, in exploratory activities it is often done the other way around: \nusers often group entities together based on intuitions before they can articulate them, then define \nthe categories as their under\u00adstanding deepens. Example. The analyst categorizes issues into Personnel \nIssues, Manufacturing Issues and Sales Issues. Figure 3 shows these categories in a legend, associating \na unique style to each one. These styles overlay the issues list, show\u00ading the categorization visually. \nAny sets, like Departments and Issues, can be used as categories too; given these sets, users naturally \ntalk about an issue or say that Human Resources is a Department. Grouping is insufficient for allowing \nusers to make sense of all information and must be complemented by re\u00adlationships. These too can be captured \nby query-based sets, such as all entities related to entity e by relationship r, where r denotes a particular \nkind of relationship. Example. The user captures which department(s) reported each of the issues. Figure \n4 shows this as a diagram with each reported relation shown as an arrow. The underlying relationships \nsupport queries, such as What issues did the Manufacturing Department report?, Which depart\u00adment(s) \nreported the High Employee Turn over issue? and What issues were reported by more than one depart\u00adment? \nOur users often viewed the same set of information snip\u00adpets from different perspectives. The same entities \nare often organized simultaneously along multiple organizational dimensions, to reflect different relationships \nnoticed by the Figure 4. A simple diagram in which reported relations between departments and issues \nare shown as arrows. Note that departments and issues are only distinguished here by their role in these \nrelations  Presentation  Visual Model Mapping Content Model  specializes  refers to determines \ndepicts (*-1) contains (1-*) Figure 5. The various types of entity comprising the visual model, content \nmodel and mapping. users. For example, employees might be organized by de\u00adpartment, by job description, \nby experience level, by the customers they interact with, etc. An organizational dimen\u00adsion is a pair \n(s, {s1, s2, , sn}), where s is the set of enti\u00adties organized according to this dimension, and each \nsi is a subset of s. For example, s might be the set of all employ\u00adees in a company, and each si might \nbe the set of all em\u00adployees in departmenti or interacting with customeri, etc. During exploration, users \ntry various organizational di\u00admensions before settling on a few that prove valuable. This is difficult \nin office tools. Many users do this using stickies and a large wall, and then face the tedious task of \ngetting their work into electronic form for sharing with colleagues. Some users curtail exploration due \nto the insurmountable difficulty of reorganizing the snippets. Flexible modeling tools must support multiple \norganizational dimensions. Multiple, simultaneous classifications must be supported, allowing the same \nentity to be classified in multiple differ\u00adent ways. A flexible modeling tool must allow users to capture \nor\u00adganizations that emerge rather than force-fit content into limited predefined organizations. While \nthe tool may pro\u00advide a starter collection of useful sets and organizational dimensions, it must also \nallow the user to define custom sets and organizational dimensions. Given that our target users are not \nusually computer scientists, providing a suit\u00adable user experience remains a significant research chal\u00adlenge. \n 3.4 Related Visual and Content Models As in many modeling tools, our architecture s underlying model \nis split into two related sub-models: the visual model and the content model (Figure 5). The model is \nan entity\u00adrelationship model, suitable for representing the kind and variety of information described \nabove. Both entities and relationships can be organized. For example, relationships can be classified \naccording to their kind, such as reported or interacts with. To allow uniform treatment of entities and \nrelationships when appropriate, relationships are them\u00adselves considered to be entities. In fact, everything \nin Fig\u00adure 5 specializes Entity, but this is not shown, to simplify the figure. The visual model captures \nvisual cues and their proper\u00adties, including style and position. Presentations are explic\u00aditly represented \nas collections of views and visual ele\u00adments. The content model captures underlying information, with \nsets representing its organization; structure definitions and violation sets are described below. Entities \nin the visual model depict entities or relationships in the content model, shown as dotted arrows in \nFigure 5. Example. Figure 6 shows the visual and content models underlying the view of the two lists \nin Figure 2. As reported above, users experiment visually during ex\u00adploratory activities as a way to \ngain understanding, thinking more about visual elements than their underlying meaning. During this phase, \nmodel elements being depicted are ge\u00adneric: entities or relationships with little or nothing known about \nthem. As user understanding is gained and distinc\u00adtions emerge, the needs to express them, with the underly\u00ading \nmodel evolving accordingly. This is an important rea\u00adson to avoid rigid typing, where it is hard or impossible \nto change the type of an entity once created. Conventional typing has two elements: classification of \nentities according to type, and structural properties, specifying properties that entities of a particular \ntype must have. The flexible ap\u00adproach to content organization deals with classification in a less restrictive \nway: entities and relationships can be classi\u00adfied in multiple ways simultaneously, and be reclassified \nat  cont ai ns dep i c ts re fe rs t o item li s t vi ew vi s u al e l em ent set st y l e st \ny l e ma p p in g ru l e  Figure 6. Visual and content models underlying the lists shown in Figure 2. \nwill. Structural properties are specified using structure definitions (Figure 5, right), perhaps in terms \nof categories, using the guidance component described in section 3.5. Reclassifying an entity or relationship \nmight result in guid\u00adance violations, since its structure might be suitable for the old category but \nnot the new one. It remains valid content, however, and the guidance component will guide the user through \nthe process of fixing the structure. Example. Initially, the entities in the issue list were just generic \nentities. After some categorization, they became Personnel Issues, Manufacturing Issues and Sales Issues. \nLater, a category-specific guidance rule was added stating that any Sales Issue should have an affected \nregion rela\u00adtionship to an item classified as Sales Region. Sales Issue then behaves rather like a type, \nin that it describes expected structure. However, the analyst can still work with a model that violates \nsuch rules, and can later decide that Sales Is\u00adsue is not a useful category after all and should be dropped. \n Figure 7. A simple diagram in which the styling of a visual element as a red stick figure indicates \nthat it is an important personnel issue. The relationship between content and visual models is deeper \nthan just depictions, however: it also provides a mapping between content and visual organization. This \nallows users to specify visual cues to be used uniformly in manifesting aspects of content organization \n a capability missing from many modeling tools. This reduces interface viscosity at a whole different \nlevel. For example, correcting a classification error, such as all Sales employees should be located \nin AL not NY, when all NY employees are colored blue, can be done with a single action and color will \nbe propagated automatically. 3.4.1 Style Mapping Style is a key part of visual organization. Analysts \nreported using office tools styling to capture various content dimen\u00adsions of their information. However, \nmanually setting and maintaining correct styles was time-consuming and error\u00adprone. Flexible modeling \nexplicitly maps style to underly-ing content organization (Figure 5, center). This mapping enables tool \nsupport that reduces user errors and effort, while enabling visual exploration to uncover the dimen\u00adsions \nalong which content is organized. Such support also reduces the effort required to visually represent \ndistinctions users have noticed but not recorded. A style, following common practice such as CSS4, is \na set of attribute:value pairs. We interpret style attributes liberally, complementing typical ones like \nfill color with shape, decorations and any other visual cues provided by a view. Example. Figure 7 shows \nissues of various kinds. Impor\u00adtant personnel issues are depicted using the red stick figure style: redFigureStyle \n= { shape:stickFigure, fillColor:red } 4 For example, see http://www.w3.org/TR/CSS2/   H i g h pe \nak s in parts inv e nto r i e s    cont ain s d epi ct s re f e rs to it em v isual ele m ent set \n l e gen d vi e w sty le sty le map pin g m a ppi n g rule  Figure 8. The style mappings that were \nimplicit in figure 7 are revealed in the form of a legend,both visually (above) and as represented in \nthe underlying model (below). A style mapping rule is an ordered pair s . y, where s is a set and y a \nstyle, specifying that depictions of members of s should be styled according to y. For example, both \nstyle mapping rules r1: all issues classified as personnel . { shape:stickFigure } r2: all entities classified \nas important . {fillColor:red} apply to issues that are classified as both personnel and important, \ncausing their depictions to have redFigure-Style (i.e., to have at least the style attributes specified \nby redFigureStyle). In our architecture, each view has a style mapping made up of style mapping rules. \nStyles used in these rules must be ones that the view can render; for example, list or table views might \nnot support shape variations. The style map\u00adping could be manifested to the user, as a legend. This al\u00adlows \nusers to see what the styles mean, and can be a place for editing style mappings. Changes immediately \naffect the styling of all appropriate visual elements in the view. Example. Figure 8 shows the diagram \nin Figure 7 along with an accompanying legend and some of the underlying model items, including the style \nmapping. Note that the legend is a depiction of the style mapping, with each legend entry depicting a \nsingle style mapping rule. Many style attributes, such as fill color, shape and a va\u00adriety of decorators, \nare independent: any visual element can have arbitrary combinations of values for them. We call a set \nof such style attributes a style space, and each inde\u00adpendent attribute a style dimension. An appealing \nstructure for the style mapping is to associate each style dimension in a style space with an organizational \ndimension, mapping each subset in the organizational dimension to a different value in the style dimension. \nThis allows the user to see the organizational dimensions visually and to control which to show, and \nclearly separates distinctions being made by the different dimensions. Example. The diagram in figures \n7 and 8 was based on mapping the organizational dimensions issue kind (with values personnel, sales, \netc.) and importance (with values important and insignificant ) to certain shapes and fill colors, respectively, \nso that different issue kind values are displayed as different shapes and different im\u00adportance values \nare shown as different colors. This use of styles is typical in diagrams created everyday by our users. \n Our users reported sophisticated style coordination across sets of views. For example, consistent styling \nis of\u00adten desired across a presentation, as it aids understanding. However, subsections may purposely \nchange a style to em\u00adphasize some point. One user included diagrams done by another team that had shared \nmeanings with the rest of the presentation. To remain true to the originals, she used original styles \nfor these diagrams only. Several views should therefore be able to share a base style mapping, with each \nview specializing or overriding it if desired. If the user changes an inherited style mapping rule, the \nquestion arises whether the user intends to change the local view only, or the base. User experience \nremains a research challenge. Multiple style mapping rules within a style mapping may apply to a single \nentity, as for r1 and r2 above. A style clash occurs if these mappings specify different values for the \nsame style attributes. Style ambiguity occurs when the same style attribute is mapped to different sets, \nleaving the user to guess what each occurrence means. Implementa\u00adtions based on this architecture must \ncope with clashes and ambiguity in a non-intrusive manner, ideally using the guidance mechanism (section \n3.5). If style spaces are used, with different style dimensions being associated with different organizational \ndimensions, as described above, style ambiguity cannot occur. If the subsets of the organizational dimensions \nare disjoint, style clashes cannot occur either.  3.4.2 Position Mapping Position mapping is conceptually \nsimilar to style mapping, with mapping rules specifying position (e.g., placement or containment) instead \nof style. This requires a model of po\u00adsition instead of simple attribute:value pairs. Some views offer \ncontinuous positioning, such as diagrams allowing arbitrary placement, whereas others offer discrete \nalterna\u00adtives, such as tables allowing placement in specific rows and columns. Such models do exist, \ne.g. [10], but their in\u00adtegration into the flexible modeling architecture requires further research. \n 3.5 Guidance Thus far we have focused on flexibility, and on providing consistent appearance in the \nface of flexibility, contrasting this to tools that restrict user interactions to those that re\u00adspect \na metamodel, a form of enforcement that puts users in a straitjacket. In contrast, we aim to provide \nguidance with\u00adout confinement. During early exploration, and in unfamiliar domains, there might be no \nknown guidance to give. However, once a structure has emerged or is known up-front, as when ana\u00adlysts \nwork within an analysis framework developed on pre\u00advious projects, guidance can help the user work within \nit and conform to it. Our architecture therefore contains a guidance component for which we identify \nand justify some properties, leaving many options for specific designs and implementations. Some concrete \ndetails of guidance in the BITKit prototype are given in section 4. 3.5.1 Structure definitions Guidance \nis specified in structure definitions, which spec\u00adify a variety of structural constraints on the model. \nFor ex\u00adample, every item classified as an issue should be classified along the importance dimension. \nStructure definitions about content entities and relationships, like this, are speci\u00adfied in terms of \nthe content model, not the visual model. However, structure definitions can also cover the mapping between \ncontent and visual models, such as specifying that style mappings should be structured according to style \nspaces; e.g., items in subsets of Issue should be styled using a color set. Our architecture does not \nsupport typing of entities as such. Typing usually brings a degree of viscosity: changing an entity s \ntype is difficult or impossible in some models. Abstraction can also be compromised, because an entity \ncan usually have just a single type. Structure definitions in combination with content organization, \nhowever, provide key benefits of typing, as noted above. Structure definitions effectively cause referenced \ncategories to be like types, but with greater flexibility. Example. Figure 4 showed reported relations \nbetween departments and issues. Quite early on in the project, the analyst registered this structure \nas a structure definition: reporting: Every issue should be the target of a reported relation from a \ndepartment. The specific nature of structure definitions and the lan\u00adguage used to express them are not \nlaid down by this archi\u00adtecture. A flexible modeling tool might use an existing, general approach, such \nas xlinkit [16] or Crocopat [4], or implement specific kinds of high-level, parameterized structure definitions \nthat provide convenient abstractions embodying many low-level rules [14].  3.5.2 Positive and negative \nguidance The obvious use of structure definitions is to detect and report violations. Architects Workbench \n(AWB) did this in a non-intrusive way with reminders shown in a separate view [1]. This negative guidance \nalerts users when their model violates specified structures. Example. Given the reporting structure definition \nabove, a reminder is shown for any issue with no incoming re\u00adported relation, reminding the user to provide \none in due course. A reminder is also shown for any reported relation between the wrong kinds of items, \ni.e., not from a depart\u00adment to an issue.  However, as AWB users confirmed, it is equally helpful to \nprovide positive guidance by doing things automatically for the user whenever possible, or leading the \nuser to a cor\u00adrect result by presenting a restricted set of choices. For ex\u00adample, if the user draws \na line in a diagram between the boxes depicting two entities, a relation is created between those entities. \nIn the absence of guidance, the relation might be given a generic kind like related to. The user would \nthen have to edit the relation to change its kind once it becomes clear. This avoids premature commitment: \nthe user can draw a line without first deciding what relation it depicts. It is cumbersome, however, \nwhen the kind of rela\u00adtion is clear it is more helpful for the tool to create the right kind automatically. \nThe user might still change it, if desired, but that is expected to be an exception. Example. Given \nthe reporting structure definition above, the tool automatically creates reported relations whenever \nan arrow is drawn from a department to an issue. If the ana\u00adlyst decides that a particular arrow depicts \na different rela\u00adtion, e.g., addresses , s/he can change it to that. This will cause a temporary violation, \nwhich might be ignored or might lead to another structure definition. If, as our users reported, the \nanalyst uses a framework defined by a senior analyst, useful structure definitions might already have \nbeen specified, and can be imported. These would provide useful guidance based on past experi\u00adence. An \nintermediate form of positive guidance is where structure definitions cannot determine a unique correct \nre\u00adsult, but instead can offer a restricted set of alternatives. This facilitates autocompletion a restricted \nmenu of valid possibilities based on context and user input. Example. If the reporting structure definition \nis comple\u00admented with an addresses relation, the analyst can be of\u00adfered a choice between these two when \ncreating a relation between a department and an issue. The manner in which guidance is actually given \nto the user through the user interface can significantly affect the user experience. In the case of pure \npositive guidance, the tool can just do the single, right thing, but in all the other cases some guidance-specific \ninteraction is required. Given our users desire for flexibility, we avoid more stringent approaches, \nsuch as forcing the user to correct each viola\u00adtion immediately. The flexible modeling architecture uses \nan approach to guidance with low invasiveness and inte\u00adgrated with other architectural elements: visual \ncues con\u00adtrolled by the style mapping. The sets used in style map\u00adping rules can include violation sets \n(Figure 5, bottom\u00adright) of items or relationships involved in guidance viola\u00adtions, resulting in visual \ncues indicating the violations. Like all style mapping rules, these are manifested in the legend, making \nthe meaning of the cues clear, and allowing the user to change them, to control their obtrusiveness, \nand even their presence. Different degrees of flexibility are appropriate at differ\u00adent times and in \ndifferent settings. For example, when jun\u00adior people are collaborating within a structure defined by \nmore experienced people, they may extend, but not change, the structure. The level of freedom allowed \nby this architec\u00adture might seem undesirable, or even dangerous, in such contexts. It is certainly possible \nto provide levels of guid\u00adance enforcement, with policies based on attributes such as user role. However, \nit is an open question whether such measures are necessary or desirable. Material developed during pre-requirements \nanalysis is critical to downstream activities, such as requirements en\u00adgineering and project planning \nand management. Structure definitions provide the key to integration between flexible modeling tools \nand other, traditional modeling tools used in a project. When exporting a model fragment from a flexible \nmodeling tool to a standard modeling tool, it must conform to the target metamodel. Structure definitions \neffectively defining that metamodel can be loaded, allowing the guid\u00adance component to check for conformance \nand helping the user to achieve it. Once all violations have been removed, the model is suitably structured \nfor direct export to the standard modeling tool.  3.5.3 Guidance checker The guidance checker is responsible \nfor evaluating (rele\u00advant) structure definitions when changes occur or are un\u00adderway, to determine both \nviolations and what positive guidance to give. Positive guidance places greater demands on a checker \nthan is typical. Both it and the language used to express structure definitions, should be designed with \nthe goal of providing user-friendly positive guidance. Nentwich, Emmerich and Finkelstein show how to \ncompute repair actions for first-order logic constraints [17]. Remain\u00ading research challenges include \nuser experience issues for positive guidance and for end-user manipulation of struc\u00adture definitions, \nand interaction protocols between the guidance checker and views to allow timely computation and display \nof positive guidance in response to user ges\u00adtures.  3.6 Refactoring During exploratory work, users \nmust be able to try things without worrying about whether they are exactly right, and then change them \nlater. This reduces premature commit\u00adment by making change, and thus iteration, easy. Rich views with \nan underlying flexible model support many kinds of changes, but some structural changes require refactoring \nsupport. For example, when extracting impor\u00adtant statements from interview transcripts, one might quickly \ncategorize them based on who made the statements. Later on, however, it might be preferable to use said \nby relationships between statements and interviewees instead, or even reported relationships. This makes \nthe nature of the relationships explicit, allowing other relationships be\u00adtween statements and stakeholders. \nThis refactoring would be tedious and error-prone to do by hand: explicit refactor\u00ading support is preferable. \n Some refactorings involve just the primitives in the un\u00adderlying model, such as categories and relations \nin the ex\u00adample above. The tool can include built-in support for these. In other cases, however, refactoring \nwill involve transforming to or from structures defined by structure definitions. Though refactoring \nhas been offered by tools for some time now, many research challenges remain in the area of extensible \nsupport for new refactorings, as well as determining appropriate refactorings for the domain of flexible \nmodeling (e.g., refactorings that both transform data and create structure definitions). It is particularly \nchal\u00adlenging to enable stakeholders with domain understanding who are not expert software engineers to \ndefine new refac\u00adtorings.  3.7 Presentation layer A key focus of pre-requirements work is the creation \nof presentations: coherent expositions of understanding of the business situation together with implications \nand recom\u00admendations. User challenges are to determine a good narra\u00adtive structure and ensure that each \nkey point is backed by appropriate supporting material. The presentation layer provides presentation \nviews for working with presentations. All views are candidates for incorporation into presentations. \nEach presentation unit (e.g., slide) is an assembly of one or more views together with titles and other \nsupporting visual elements. The incor\u00adporation of large exploratory views into presentations may require \nuser-guided pagination or refactoring to ensure legibility, conformance to form factors, and that material \nis revealed in appropriate and useful chunks. In general, con\u00adsiderable work may be needed to polish \npresentations, in addition to assembly of the narrative. As noted in section 2, pre-requirements analysts \n(in common with many other users) often use templates when constructing presentations. A template in \nthis context is a guide or pattern that enables the creation of presentation elements of some specific \nform. They range from the sim\u00adple, such as slides containing bullet lists, to the complex, such as organization \ncharts. Such templates often derive from prior projects. Though sophisticated users might en\u00adgage in \ntemplate definition using whatever means their presentation tools offer, it is more common to pick up \nan example, remove the old (and probably confidential) data, and use the resulting skeleton as a template. \nThe presentation layer of a flexible modeling tool should therefore provide a means to create templates \nfrom existing presentation fragments, and to use them conveniently in new presentations. The templates \nare primarily artifacts in the visual layer, represented and stored in the visual model. However, it \nis also important that a template record what is to be done in the content model as it is filled in. \nFor exam\u00adple, an organization chart template would typically be tied to an underlying model of the organization \nand its employ\u00adees, and this model would be updated as the template is filled in. Constructing a presentation \nbrings a fresh perspective to the exploratory and envisioning role of the user, causing them to revise \nand enrich their understanding. The presen\u00adtation layer therefore allows full manipulation of viewed \ncontent. This further justifies presentations being assem\u00adblies of views, as well as our overall goal \nof blending mod\u00adeling and presentation features into a single tool. User in\u00adteraction techniques enabling \ngradual yet fluid transitions between modeling, preparation and presentation require further research. \nExplicit style mappings play additional roles within presentations. Legends may accompany each view, \nand in interactive presentations, may present the reader with con\u00adtrols to enable or disable specific \nmappings, or select one or more entries to highlight from a style dimension. Decisions about what to \nplace under reader control are made by the author. Suitable presentation views could be used for actual \npresentation, but in many contexts it is necessary to export presentations in standard forms, such as \nslide decks or web sites. This is the task of presentation exporters.  3.8 Metamodel Analogs and Evolution \nNow that all the elements of our flexible modeling conceptual architecture have been presented, it is \nworth revisiting the issue of metamodels. The function of a metamodel in a traditional modeling tool \nis to define the permissible structure of models, which is then enforced by the tool. The metamodel embodies \nmuch domain-specific understanding, allowing the tool to provide domain-specific assistance and functionality. \nThe metamodel often ensures conformance to industry standards, and facilitates interoperation with other \ntools. In the case of flexible modeling tools, we clearly want the enforcement to be replaced by forgiving \nguidance. It is still useful in many situations, however, to help the user build models that have expected, \nand perhaps standard, model structures in a particular domain. Several of the architectural elements \ndescribed above work together to enable this: Classifications specify domain concepts and (some of) \ntheir relationships. They serve the role of types.  Structure definitions specify expectations and constraints \nabout model structure.  Sets and organizational dimensions embody useful ways of organizing content \nin the domain.  Templates specify useful ways of organizing and present\u00ading content visually.  Style \nmappings manifested as legends specify useful vis\u00adual conventions for displaying content.   We call \na package made up of a coherent collection of these items a thought framework, because it supports work \nfollowing a particular way of thinking (such as issue based consulting, used in the running example earlier). \nA thought framework effectively constitutes a metamodel. When loaded into a flexible modeling tool, it \nenables the tool to help the user work in the supported fashion. It allows the tool to present tailored \ndiagramming views, with appropri\u00adate palettes and visual conventions. It allows the tool to show the \nuser where expectations are violated, and often to help the user avoid or remove violations. It allows \nthe tool to export models that conform to the metamodels of stan\u00addard modeling tools. Users working in \na new domain can start from scratch and just do free-form modeling. An initial thought frame\u00adwork will \nnaturally evolve as they proceed, for example as they create classifications and sets, and structure \ndefinitions aimed at helping them with their work. They might import (fragments of) existing thought \nframeworks along the way, as they see fit. As their understanding of the domain ma\u00adtures, or at the point \nthat it would be useful to another pro\u00adject, they can do some explicit work to harden the thought framework \nand make it suitable for sharing. The process of supporting non-expert users in creating thought frame\u00adworks, \nboth by deducing as much as possible from their regular modeling activities and by providing convenient \nmeans for them to explicitly examine and manipulate the thought framework, remain research challenges. \nUsers working in an established domain would generally be expected to start out by loading domain-specific \nthought frameworks. These might have been produced as just de\u00adscribed, or be provided together with a \nflexible modeling tool, providing a good out-of-the-box experience for the domain, or be obtained from \ndomain experts, or developed within an organization for use in multiple projects, etc. Users working \nwithin an existing thought framework might still need to deviate from it at times, for example to introduce \nnew relationships that capture connections not foreseen by the thought framework authors. Thanks to the \nforgiving guidance, they can do this, resolving violations later or not at all. If they determine that \nthe thought frame\u00adwork is deficient, they can enhance it, and potentially share the enhancements. This \nability to evolve the metamodel during and as part of modeling is an important property of flexible modeling \ntools. In contrast, changing the meta\u00admodel of a standard modeling tool generally requires an expert \nworking in a different language and environment, and requires the tool to be regenerated, or at least \nrestarted, and data to be migrated. This ability to violate, and especially to change, a metamodel is \nvaluable in some contexts and detrimental in others. It tends to be valuable during exploratory activities, \nespecially in new domains, where supporting free-wheeling thinking and exploration is especially important. \nIt tends to be detrimental in cases where work is being done on a shared, established model, such as \nan enterprise architec\u00adture. Changing the metamodel on the fly could lead to lack of understanding or \nmisunderstanding by other stakeholders and failure of other tools that rely on the model structure. Even \nin such cases, however, some free-form exploration is often valuable, such as when considering possible \nfutures based on an enterprise architecture; it is only if and when it comes time to change the architecture \nitself that rigid con\u00adformance is needed. Discretion is thus needed in the use of flexibility. Such discretion \ncould be put in the hands of individual users, with purely cultural pressure to do the right thing. In \nmore controlled environments, the discretion could be put in the hands of senior stakeholders, projects \nleaders or managers, who would specify role-based restrictions to be enforced by the tool. The important \nthing is that a flexible modeling tool provide a range of possibilities to suit different scenar\u00adios. \n  4. The BITKit Prototype BITKit is a prototype tool for business stakeholders in\u00advolved in pre-requirements \nanalysis [19]. We started by building minimal capabilities, adding enhancements only when necessary, \nincluding based on observations of and feedback from senior business analysts who test-drove early versions. \nOur work on BITKit inspired the architec\u00adture described above, but we extended and generalized be\u00adyond \nBITKit s current capabilities. This section briefly describes BITKit as a concrete yet limited instance \nof the architecture. BITKit, shown in figure 9, is built as a Rich Internet Application using Adobe Flex5. \nPersistence is provided by streaming XML to a REST server, or storing it on the local disk (when running \nunder Adobe AIRTM). The underlying model is founded on entities, called items, and directed, binary relationships, \nwhich are themselves items. Sets are items, and both enumerated and query-based sets are supported. BITKit \ndoes not include a general-purpose query language, however, but rather specific kinds of pa\u00adrameterized \nsets supporting a standard set interface. For example, an AllTargetsSet is the set of all target items \nreachable by following a specified relationship from a specified source item. These various sets, along \nwith stan\u00addard set operations like intersection and union, provide an open, extensible means of expressing \nqueries. This ap\u00adproach enabled us to start quickly and fill holes as needed. We chose tagging as our \nmeans of classification. Tag\u00adging is a flexible, informal approach to organization and popular on the \nInternet (e.g., Delicious6, flikr7). It is light\u00adweight, allowing users to attach tags to any entities. \nIt ap\u00adpears to be particularly effective during early exploration. 5 http://www.adobe.com/products/flex/. \nAdobe, Flex and AIR are trade\u00admarks of Adobe Systems Incorporated. 6 http://delicious.com/ 7 http://www.flickr.com/ \n  Figure 9. A screenshot of the BITKit prototype, showing a simple project based upon the running example \nof this paper. The screen consists of a simple workbook (left) and presentation (bottom left), containing \ntwo worksheets and two slides respec\u00adtively. Of the various model views shown on the right, the items \nview is currently open. At center is a presentation slide dis\u00adplaying several issues and departments \nand their relationships, all styled by the style mappings shown in the slide s legend. Seasonal quality \nproblems is currently selected and its tags are being viewed in the inspector. Multiple classification \nis supported by attaching multiple tags to entities. Although tags might be used with little thought \ninitially, they can be defined and organized as un\u00adderstanding increases [20]. The business analysts \nwe worked with were mostly not used to tagging, and their understanding and appreciation increased when \nwe re\u00adexplained them as lightweight classifications. Early feedback led to tag groups: collections of \nrelated tags, such as tags representing degrees of importance or kinds of issues. Tag groups serve as \norganizational dimen\u00adsions in multi-dimensional classifications, allowing simul\u00adtaneous classification \nby such criteria as importance and issue kind. Not surprisingly, feedback revealed the need for implication \nrelationships among tags, which would support classification hierarchies. BITKit provides three kinds \nof view: diagrams, lists and tables [20]. Diagrams depict items as shapes and relation\u00adships as lines; \nitems are manually placed on diagrams. A list is founded on a set, displaying all items in that set. \nLike all BITKit views, lists can be changed by the user, causing the underlying set to be updated. In \nsome cases there is not a unique way to do this, such as when an item is removed from an intersection, \nand the user needs to be consulted. Determining an optimal user experience remains a research challenge. \nTables are also set-based. The user selects row and col\u00adumn sets, determining the headers. The contents \nof a cell, at the intersection of a row and column, is computed based on the headers of that row and \ncolumn. For example, if the rows are all tags in group Issues and the columns are all tags in group Importance, \nthen each cell will contain en\u00adtries tagged with a particular kind of issue and degree of importance. \nChanges the user makes in the table cause ap\u00adpropriate changes to the underlying tagging.  All BITKit \nviews have legends, showing their style mappings. Diagrams currently support the richest variety of styles: \nshape, background color, line color and line thick\u00adness. Lists and tables do not naturally support shape \nvaria\u00adtion. Experience revealed the need for mapping organiza\u00adtional dimensions to style dimensions, \nas described in sec\u00adtion 3.4, so that the user can comprehend organizational dimensions at a glance. \nWe plan to add support for such mapping, and additional style attributes including decora\u00adtors. As with \nsets, BITKit offers a small but extensible set of structure definitions. Currently, it supports implications \ninvolving sets (every item in s1 must also be in s2), and con\u00adstraints on the endpoints of relations \n(e.g., both the source and target of a sub-issue relation must be tagged with Issue ). We have given \npriority to supporting positive guidance. For example, if the user creates a sub-issue relation, the \nsource and target are automatically given Is\u00adsue tags, if they do not have them already. Violations are \ncurrently shown as decorators on shapes and lines in dia\u00adgrams only. We plan to introduce violation sets, \nas de\u00adscribed in section 3.5.2, which would allow violations to be depicted via style mappings. Violation \ndecorators can be opened to see details, including a list of possible repairs. BITKit s presentation \nlayer is still primitive. Based on user feedback, views are aggregated into both workbooks and presentations. \nUsers explore using workbooks, and then copy views into presentations. As practice areas ma\u00adture, we \nexpect workbooks to become fairly stable tem\u00adplates, guiding analysts in their work, but presentations \nto be tailored differently for different audiences. Supporting smooth transitions between them remains \nan area for future work. The need for refactoring soon emerged as analysts used BITKit. Because tagging \nis so lightweight, it is used early on where relationships are more appropriate. Also, it is not always \nclear whether something should be an item, a tag or a tag group. Wand and Weber discuss another situation \nwhere it is hard for users to make correct choices up front [22]. Avoidance of premature commitment requires \nthat the user can pick quickly, and easily change decisions later. Earlier preparations for pilot use \nin a real industrial con\u00adtext to support consultants in evaluating software devel\u00adopment organizations \nand recommend improved practices (e.g., requirements management or change management) led to the need \nto support collateral material: standard ma\u00adterial, perhaps from prior projects, largely visual but per\u00adhaps \nalso with underlying content, that can be adapted and reused. Users want to copy parts of it into their \nmodels and make local changes, and to parameterize it, effectively cre\u00adating templates. We have begun \nexperimenting with ap\u00adproaches to abstracting and parameterizing existing models.  5. Related Work Requirements \nmodeling tools, such as GRAIL/KAOS [3] and Rational Requirements Composer8, embody specific metamodels. \nExtensible modeling tools, such as RSM9, also embody specific metamodels, but allow some degree of flexibility, \nthrough user-defined stereotypes and profiles. The need to conform with the metamodels, however, pre\u00advents \nthe degree of flexibility needed in our domain. Model Integrated Program Synthesis [18], and other en\u00advironments \nsupporting metamodeling, allow domain ex\u00adperts to define metamodels from which domain-specific modeling \ntools can be generated. Each such tool supports manipulation of models that conform to its metamodel. \nThese systems provide valuable time savings and flexibility to tool builders, but the tools produced \ndo not reflect it: each supports the metamodel from which it was generated, and changes require regeneration. \nFlexible modeling tools, in contrast, allow tool users to evolve metamodels and to manipulate models \nthat do not conform to specific meta\u00admodels. Architects Workbench (AWB) [1] served as an inspira\u00adtion \nfor our work, though it was developed for IT architects rather than business stakeholders. It also provides \na flexible underlying model with guidance, but is configured with specific metamodels. The underlying \nmodel allows change\u00adtype refactorings and graceful handling of incompleteness and metamodel evolution, \nwhich result in reminders indi\u00adcating what is incomplete or incorrect. AWB s metamodels include catch-all \ntypes (RawNode, Basic-Relation and Note), which allow free-form, untyped capture of data, but with no \nway of introducing new categories or kinds of rela\u00adtions except by changing the metamodel and reconfiguring. \nAWB also does not support general style mapping. Telelogic Systems Architect10 is a modeling tool for \nen\u00adterprise architecture, and hence closer to the domain of business analysis. It supports a large corpus \nof diagrams, methods and notations, based on underlying metamodels that can be tailored by expert administrators. \nThe user thus has a wide choice of metamodels, but not the flexibility to deviate from or extend the \none chosen. Our approach to guidance relates to Balzer s landmark work on tolerating inconsistency [2]. \nHis approach intro\u00adduced pollution markers to indicate the violation of specific constraints: instead \nof requiring a constraint to hold always, one instead requires a pollution marker to be present if and \nonly if the constraint does not hold. The presence of the marker thus indicates the violation of a specific \nconstraint, and, as he noted, can be used to provide a visual cue to the user, such as coloring inconsistent \nspreadsheet cells. The markers can also be used as guards, preventing the execu\u00adtion of code that depends \non the constraints being satisfied. 8 http://www-01.ibm.com/software/rational/announce/rrc/ 9 www.ibm.com/developerworks/rational/products/rsm/ \n10 http://www.telelogic.com/Products/systemarchitect  Balzer s motivation was facilitating complex updates \nin\u00advolving multiple parties, where consistency would only be restored once all parties had completed \ntheir parts of the updates. The inconsistencies were thus expected to be tem\u00adporary. Our motivation is \nto guide users with domain\u00adspecific structure definitions, but with the freedom to devi\u00adate from them. \nViolations thus represent cases where the content model violates whatever structure definitions are in \nuse, and not necessarily inherent inconsistencies within the models. These violations might be repaired \nas work pro\u00adceeds, especially if the models are to be passed to down\u00adstream tools. Sometimes, however, \nviolations are deemed acceptable; they then persist as such, or the structure defini\u00adtions themselves \nare modified to reflect new understanding or a difference in domain. Another area of inconsistency handling \nin requirements tools is to represent and work with mutually-inconsistent information from multiple stakeholders. \nThis requires a model that reifies multiple perspectives, allowing them to be inconsistent and their \nrelationships explored, such as the Viewpoints model [7]. Support for multiple stakeholder perspectives, \nand for alternative possible futures, which might also be mutually inconsistent, are important in our \ndomain also. They are, however, largely independent of the focus of this paper, and not addressed here. \nAnother largely-independent area not addressed in this paper is sketch-based user interfaces. Grundy \nand Hosking describe generic support for adding sketch-based input to modeling tools [11]: drawn shapes \nare recognized as dia\u00adgram elements, at times that are customizable by the user. They argue that this \napproach improves tools along several cognitive dimensions [5]: premature commitment, viscos\u00adity, progressive \nevaluation, secondary notation, closeness of mapping and error proneness. Although it is unclear how \nthese sketch-based interfaces would be received by busi\u00adness stakeholders, and how much they would help, \nwe pos\u00adtulate that would be a valuable addition to pre-requirements tools and to flexible modeling tools \nin general.  6. Conclusion This paper introduced the notion of flexible modeling tools, and described \nkey architectural elements needed to blend the advantages of office tools and modeling tools. Pre\u00adrequirements \nanalysts, and others engaged in exploratory work, currently find themselves forced to use either office \ntools or modeling tools. Input we received from many prac\u00adtitioners clearly indicated that neither is \nideal. Through a visual layer allowing the user great freedom, an underlying model able to represent \nany information, mapping from model characteristics to visual cues, forgiving guidance and refactoring \nand presentation support, flexible modeling tools bring together many of the key advantages of office \ntools and modeling tools, allowing users to move smoothly between informal exploration and modeling with \nvarying degrees of formality and precision. They therefore have the potential to fill a gap in the current \ntool spectrum. We also identified a number of research challenges re\u00admaining in the area of flexible \nmodeling tools. Several in\u00advolve infrastructure, but many involve the user experience: providing an experience \nthat gives power and flexibility to business users without being too complex, confusing or intrusive \nis particularly challenging. We hope that this pa\u00adper will spark research on these challenges, and provide \na framework within which it can be positioned.  Acknowledgements We thank Barth\u00e9l\u00e9my Dagenais and the \nanonymous reviewers for many helpful comments.  References [1] S. Abrams et al, Architectural thinking \nand modeling with the Architects' Workbench. IBM Systems Journal 45(3), July, 2006. [2] R. Balzer, Tolerating \ninconsistency. In Proceedings of the 13th International Conference on Software Engi\u00adneering (ICSE 1991), \nIEEE, pp. 158 165, 1991. [3] P. Bertrand et al, GRAIL/KAOS: An Environment for Goal-Driven Requirements \nEngineering. In Proceed\u00adings of the 19th International Conference on Software Engineering (ICSE 1997), \npp. 612 613, 1997. [4] D. Beyer, Relational programming with CrocoPat. In Proceedings of the 28th International \nConference on Software Engineering (ICSE 2006), pp. 807-810, 2006. [5] A. F. Blackwell and T.R.G. Green, \nA Cognitive Di\u00admensions questionnaire optimised for users. In A.F. Blackwell &#38; E. Bilotta (Eds.), \nIn Proceedings of the Twelfth Annual Meeting of the Psychology of Pro\u00adgramming Interest Group, pp. 137-152, \n2000. [6] S.K. Card, J.D. Mackinlay and B. Shneiderman (Eds.), Readings in information visualization: \nUsing vision to think. Morgan Kaufmann, 1999. [7] A. Finkelstein et al, Viewpoints: A framework for inte\u00adgrating \nmultiple perspectives in system development. International Journal of Software Engineering and Knowledge \nEngineering 2(1), pp. 31-58, 1992. [8] A. C. W. Finkelstein, D. Gabbay, A. Hunter, J. Kramer, and B. \nNuseibeh, Inconsistency Handling in Multi-perspective Specifications, IEEE TSE 20(8), pp. 569-578, 1994. \n[9] E. Gamma, R. Helm, R. Johnson and J. Vlissides, De\u00adsign Patterns: Elements of Reusable Object-Oriented \nSoftware. Addison-Wesley, April 2005. [10] E. R. Gansner and S. C. North, An Open Graph Visu\u00adalization \nSystem and its Applications to Software En\u00adgineering. Software Practice and Experience, 30(11), pp. 1203-1233, \n2000. [11] J. Grundy and J. Hosking, Supporting generic sketch\u00ading-based input of diagrams in a domain-specific \nvis\u00ad  ual language meta-tool. In Proceedings of the 29th In\u00adternational Conference on Software Engineering \n(ICSE 2007), pp. 282-291, 2007. [12] D. Harel, and B. Rumpe, Meaningful Modeling: What's the Semantics \nof Semantics ? IEEE Computer 37(10), pp. 64-71, 2004. [13] S. Hupfer, L-T. Cheng, S. Ross and J. F. Patterson, \nIntroducing collaboration into an application devel\u00adopment environment. In Proceedings of the 2004 ACM \nConference on Computer Supported Cooperative Work, pp. 21-24, 2004. [14] H. Kilov and J. Ross, Information \nModeling: an Ob\u00adject-Oriented Approach. Prentice Hall, 1994. [15] J.H. Larkin and H.A. Simon, Why a Diagram \nis (Some\u00adtimes) Worth Ten Thousand Words. Cognitive Science 11(1), pp. 65-99, 1987. [16] C. Nentwich, \nL. Capra, W. Emmerich and A. Finkel\u00adstein, xlinkit: a consistency checking and smart link generation \nservice. ACM Transactions on Internet Technology 2(2), pp. 151-185, 2002. [17] C. Nentwich, W. Emmerich \nand A. Finkelstein, Con\u00adsistency management with repair actions. In Proceed\u00adings of the 25th International \nConference on Software Engineering (ICSE 2003), pp. 455-464, 2003. [18] G. Nordstrom, J. Sztipanovits, \nG. Karsai, and A. Le\u00addeczi, Metamodeling rapid design and evolution of domain-specific modeling environments. \nIn Proceed\u00adings of the IEEE ECBS 99 Conference, Nashville, Tennessee, pp. 68 74, April, 1999. [19] H. \nOssher et al, Business Insight Toolkit: Flexible pre\u00adrequirements modeling. Informal demonstration paper \nin ICSE 2009 Proceedings Companion, May 2009. [20] H. Ossher et al, Using tagging to identify and organize \nconcerns during pre-requirements analysis. Workshop paper in ICSE 2009 Proceedings Companion, May 2009. \n[21] S. P. Reiss, PECAN: Program Development Systems that Support Multiple Views. IEEE TSE 11(3), pp. \n276\u00ad285, 1985. [22] Y. Wand and R.A. Weber, Research commentary: information systems and conceptual modelling \na research agenda. Information Systems Research 13(4), pp. 363 376, 2002  \n\t\t\t", "proc_id": "1869459", "abstract": "<p>A serious tool gap exists at the start of the software lifecy-cle, before requirements formulation. Pre-requirements analysts gather information, organize it to gain insight, en-vision possible futures, and present insights and recom-mendations to stakeholders. They typically use office tools, which give great freedom, but no help with consistency management, change propagation, or information migration to downstream tools. Despite these downsides, office tools are still favored over modeling tools, which are constrain-ing and difficult to use. We introduce the notion of flexible modeling tools, which blend the advantages of office and modeling tools. We propose a conceptual architecture for such tools, and outline research challenges to be met in realizing them. We briefly describe the Business Insight Toolkit, a prototype tool embodying this architecture.</p>", "authors": [{"name": "Harold Ossher", "author_profile_id": "81100333974", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2354166", "email_address": "", "orcid_id": ""}, {"name": "Rachel Bellamy", "author_profile_id": "81100257325", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2354168", "email_address": "", "orcid_id": ""}, {"name": "Ian Simmonds", "author_profile_id": "81100052980", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2354169", "email_address": "", "orcid_id": ""}, {"name": "David Amid", "author_profile_id": "81375618664", "affiliation": "IBM Haifa Research Center, Haifa, Israel", "person_id": "P2354170", "email_address": "", "orcid_id": ""}, {"name": "Ateret Anaby-Tavor", "author_profile_id": "81375609066", "affiliation": "IBM Haifa Research Center, Haifa, Israel", "person_id": "P2354171", "email_address": "", "orcid_id": ""}, {"name": "Matthew Callery", "author_profile_id": "81443594954", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2354172", "email_address": "", "orcid_id": ""}, {"name": "Michael Desmond", "author_profile_id": "81330490079", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2354173", "email_address": "", "orcid_id": ""}, {"name": "Jacqueline de Vries", "author_profile_id": "81318493741", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2354174", "email_address": "", "orcid_id": ""}, {"name": "Amit Fisher", "author_profile_id": "81309509178", "affiliation": "IBM Haifa Research Center, Haifa, Israel", "person_id": "P2354175", "email_address": "", "orcid_id": ""}, {"name": "Sophia Krasikov", "author_profile_id": "81317495850", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY, USA", "person_id": "P2354167", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869529", "year": "2010", "article_id": "1869529", "conference": "OOPSLA", "title": "Flexible modeling tools for pre-requirements analysis: conceptual architecture and research challenges", "url": "http://dl.acm.org/citation.cfm?id=1869529"}