{"article_publication_date": "10-17-2010", "fulltext": "\n Modular Logic Metaprogramming Karl Klose Aarhus University Denmark Abstract In logic metaprogramming, \nprograms are not stored as plain text.les but rather derived from a deductive database. While the bene.ts \nof this approach for metaprogramming are obvi\u00adous, its incompatibility with separate checking limits \nits ap\u00adplicability to large-scale projects. We analyze the problems inhibiting separate checking and \npropose a class of logics that reconcile logic metaprogramming and separate check\u00ading. We have formalized \nthe resulting module system and have proven the soundness of separate checking. We validate its feasibility \nby presenting the design and implementation of a speci.c logic that is able to express many metaprogram\u00adming \nexamples from the literature. Categories and Subject Descriptors D.1.6 [Programming Techniques]: Logic \nProgramming; D.3.1 [Programming Languages]: Formal De.nitions and Theory; D.3.4 [Pro\u00adgramming Languages]: \nProcessors: Code generation General Terms Design, Languages, Theory Keywords Modularity, Separate Checking, \nLogic Metapro\u00adgramming 1. Introduction The need to divide large-scale software into manageable building \nblocks became apparent in the 1960s and 1970s. It was soon recognized, however, that not every partition \nof the source code into blocks constitutes a good modulariza\u00adtion; rather, a good module should be self-contained \nin that it describes its requirements on the context and clearly spec\u00adi.es the service it provides to \nthe external world in a form that is separately checkable by a compiler while still hiding implementation \ndetails [35]. Dedicated module constructs that help to enforce such abstraction boundaries quickly fol\u00adlowed \nand have been realized in the module constructs of Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA/SPLASH 10, October 17 21, Reno/Tahoe, Nevada, USA. Copyright \nc . 2010 ACM 978-1-4503-0203-6/10/10. . . $10.00 Klaus Ostermann University of Marburg Germany languages \nsuch as Ada, Pascal, C, Modula-2, or ML. Indeed, Cardelli (and others) have argued that separate checking \nis such a fundamental property of a module system that a mod\u00adule system without separate checking is \n(arguably) not really a modularization mechanism [8]. Separate checking is traditionally achieved by \nspecify\u00ading a set of names or signatures of functions, procedures, or data-structures that the module \nrequires (or imports) and provides (or exports), respectively. A module can be checked separately by \nchecking that the module provides well-formed de.nitions of all exported names under the as\u00adsumption \nthat de.nitions for all imported names will be pro\u00advided by other modules. However, this simple notion \nof import/export interfaces as lists of names or signatures breaks down once some form of (static) metaprogramming \nis involved. Static metapro\u00adgramming means that (parts of) the program are computed at compile-time. \nTypical examples of static metaprogramming are templates in C++, various forms of macro programming, \nor compile-time metaobject protocols such as OpenC++ [11] or Javassist [12]. If such program computations \nare involved in the compilation process, it is neither clear how these program computations can be checked \nseparately (meaning that they will only compute well-formed programs for ev\u00adery well-formed input), nor \nhow the functionality of these computations can be described as an interface that does not reveal the \nimplementation details, such that clients that use the computed programs can be checked against this \ninter\u00adface. As a consequence, programs involving static metapro\u00adgrams can usually only be understood, \nanalyzed and veri\u00ad.ed as a whole, because the dependencies between parts of such programs cannot be speci.ed \nin terms of module in\u00adterfaces. This problem is well-known, and various solutions have been proposed \nfor speci.c restricted forms of metapro\u00adgramming, such as conditional declarations [26] or certain computations \nover the structure of classes [19, 25, 27, 28]. This work has a more general focus: We investigate and \ncharacterize the relation between separate checking and metaprogramming, independent of speci.c metaprogram\u00adming \nconstructs or host languages. We identify minimal conditions on the interface and implementation language \nunder which separate checking is sound.  We have chosen logic metaprogramming [14, 30, 39] as the basis \nfor our studies, because it is one of the most gen\u00aderal and declarative forms of metaprogramming, and \nbe\u00adcause the strong semantic foundations of logic programming make it particularly well-suited for a \nformal treatment. In logic metaprogramming, programs are described as a deduc\u00adtive database in a logic \nlanguage such as Prolog, and thus the shape of the .nal program may depend on arbitrarily com\u00adplex deduction \nrules. Although we use logic metaprogramming as the motiva\u00adtion of our approach, we believe that our \nresults are also ap\u00adplicable to other forms of metaprogramming, or, more gen\u00aderally, to any form of programming \nthat requires modules whose interfaces require some form of computation or de\u00adduction. The contributions \nof this work are as follows: We analyze the tension between logic metaprogramming and separate checking \nand, more generally, between pro\u00adgram generators, information hiding, and separate check\u00ading of well-formedness \nconstraints.  We propose a generic model of modules that describes the implementation and interface \nof modules in terms of formulas from a logic language, such that compatibility and consistency checks \ncan be expressed in terms of logic validity and consistency. This model does not depend on a .xed logic \nor object language; rather, it axiomatizes the requirements on the logic and the object language under \nwhich separate checking is sound. Module con\u00adstructs ranging from traditional modules which import/\u00adexport \nlists of names to sophisticated modules that can give interfaces to program generators can be uniformly \ndescribed as instances of this model, via logics that sat\u00adisfy the axioms. The structure of our formalization \nhas been inspired by (and can be seen as a generalization of) Cardelli s seminal work on separate checking \n[8].  We present a design and implementation of an actual module description logic, FP +, that .ts to \nthe axioms described in our formalization and is suf.ciently power\u00adful for many typical use cases from \nlogic metaprogram\u00adming. The logic is the pure part of Prolog (no negation\u00adas-failure, cuts etc.) plus \na few simple, well-known ex\u00adtensions from .Prolog [33]. We demonstrate by means of examples how a small, \nJava-like object-oriented pro\u00adgramming language can be modeled in our system and be equipped with metaprogramming \nconstructs.  We explore the design space of instantiations of our model by presenting other possible \nlogic languages and discussing their respective expressiveness to model ob\u00adject languages and metaprogramming \nconstructs. We also discuss applications of modular logic metaprogramming for generating design pattern \nimplementations, cross\u00adlanguage type systems, and pluggable type systems.  The remainder of this paper \nis structured as follows. First, we introduce logic metaprogramming and discuss its mod\u00adularity problems \n(Sec. 2). Then we show informally what steps need to be taken to make logic metaprogramming mod\u00adular \n(Sec. 3). In Sec. 4, we present our formalization of mod\u00adule description logics. We describe an implementation \nof a module system based on the formalization and the imple\u00admentation of the FP + logic in Sec. 5. We \ndiscuss advan\u00adtages and limitations of our approach in Sec. 6. Section 7 compares to related work. Section \n8 concludes. Appendix A contains the proofs of all theorems presented in the paper. 2. Logic Metaprogramming \nIn (static) logic metaprogramming (LMP) [14, 39], a logic language (the meta language) is used to specify \nprograms in another language (the object language). In the following we give a brief introduction to \nLMP by encoding a typical metaprogramming example using Prolog as meta-language and a functional toy \nobject language which we call FP. We will discuss both the expressiveness and the problems of LMP in \nterms of this example. Although the main implementation of our framework is for the Java programming \nlanguage, we will use FP as an example object language in this section. Since it is much simpler, it \nallows us to show every aspect of modeling a language in our framework for modular logic metaprogram\u00adming \n(MLMP) in full detail. Although Java is a much more powerful and complex language, it does not add many \nin\u00adteresting issues for our purposes that do not already arise in FP. We will discuss our Java incarnation \nof our model in Sec. 5.3. 2.1 Logic Metaprogramming Systems An LMP system consists of three parts: A \nfront-end, a de\u00adductive database, and a back-end. The front-end reads object language terms from data \nstreams, and converts these terms to a form understood by the meta language. For example, the front-end \ncould translate a function fun f = arg+11 into the Prolog term funimpl(f,add(arg,1)). For our further \ntreatment we ig\u00adnore the front-end, since it is not interesting, and concentrate on the part where the \ninput is already transformed into logic formulas. The deductive database contains the representation \nof the object language program generated by the front-end and a set of program computation rules. The \nprogram computation rules are either in some form encoded in the object language programs, or the programmer \nmay directly access the deduc\u00adtive database, or there could be just a .xed set of prede.ned computation \nrules. The origin of the program computation rules is irrelevant for the purpose of this paper. The database \n1 FP is a .rst-order functional language with integers and addition as only available primitive type \nand operation, respectively. Each function has ex\u00adactly one implicit parameter which is called arg. \n funimpl(f1, add(5, arg)). funimpl(f2, add(7, call(f1, arg))). funimpl(compose(A, B), add(call(A, arg), \ncall(B, arg))) . funimpl(A, _), funimpl(B, _). funimpl(f3, add(arg, call(compose(f1,f2), 13))). Figure \n1. LMP Example may also contain auxiliary (library) rules that help in writing program computation rules, \nsuch as rules to look up things in the program. Furthermore, the deductive database contains a deduction \nmechanism, which can be used to derive all pos\u00adsible variable substitutions under which a query can be \nde\u00adduced from the database. The back-end of the system uses the deductive database to generate the program \nin object language syntax. To this end, the back-end typically generates all solutions to queries that \nrepresent object language entities of interest for the cur\u00adrent program, and generates code for these \nsolutions. For example, the query funimpl(Name, Body) generates all function de.nitions that can be deduced \nfrom the current database. For each successful substitution found for these queries code is generated. \nIf the database contains recur\u00adsively applicable program computation rules, the na\u00a8ive strat\u00adegy of iterating \nover all possible program entities will not terminate. To solve the problem of such in.nitely large code \nbases, a strategy to select only those parts of the deductive closure of the database that are relevant \nto the program at hand is required. This could be just a list of function names, or a computation of \nevery program entity transitively refer\u00adenced from the main function. The choice of this strategy is \nirrelevant for this work; we just assume that some termi\u00adnating program generation strategy is available. \n 2.2 Example: A Generic Function Composer The example in Fig. 1 shows a typical use case for metapro\u00adgramming. \nThe code de.nes two ordinary functions f1 and f2, and a function de.ned by a proper metaprogram: compose \ncomposes two functions A and B by calling each with the given argument and adding their results. 2 The \nlast function f3 uses the metaprogram by calling a composed function compose(f1, f2). Using a straight-forward \nse\u00admantics for FP, we expect f3 to be equivalent to the function add(arg, 43) at runtime. This small \nmetaprogram is a typical example of the use of metaprogramming to solve a programming problem that requires \nabstraction over elements of the language that are not .rst class : In our example language FP it is \nnot possible 2 We adopt the Prolog convention to use upper-case letters for variables and for anonymous \nvariables. to write abstractions involving functions, but we can provide such abstractions using metaprogramming. \nAlthough metaprogramming would not be necessary to implement this example in a higher-order functional \nlan\u00adguage, every programming language has some structures that are not .rst class , so metaprograms are \nneeded to implement abstractions over these structures. For example, classes in object-oriented programming \nlanguages like Java or C# or data type de.nitions in Haskell are not .rst class . The lack of abstractions \nover classes, in particular, is a com\u00admonly encountered problem and metaprogramming tech\u00adniques like \ncode generation and language extensions are often used to deal with it. For example, the de.nition of \ngeneric proxy classes or pair classes is a typical metapro\u00adgramming example in OO languages [25]. Our \nexample can be seen as a small-scale version of these more sophisticated applications of metaprogramming. \nWe have implemented examples for the aforementioned more re\u00adalistic usages of metaprogramming, but they \nare more com\u00adplicated and do not add anything to the discussion that can\u00adnot also be illustrated in terms \nthe simplistic function gener\u00adator example. Since metaprograms cannot be understood by the com\u00adpiler \nor interpreter for the object language, the system needs to generate code for the instance of compose \nthat is used in f3. How the resulting names for composite functions such as compose(f1, f2) are represented \nin object code is a re\u00adsponsibility of the back-end. For example, it could generate a new function name \nsuch as compose f1 f2.  2.3 Representation Choices There are several design choices in the representation \nof object programs. For our purposes, the granularity and the openness of the representation are signi.cant. \nRegarding granularity, function bodies could also be treated and pro\u00adcessed as opaque constants rather \nthan being decomposed into term representations of their abstract syntax trees as in our example. Only \nin the latter case can the deductive database also be used to perform interesting computations on the \nexpression level, but if such kinds of computations are not required, then an opaque constant representation \nis suf.cient. Representations also differ in their openness, which boils down to the decision whether \na constructor in the object language is represented as a term constructor (closed) or predicate constructor \n(open) in its encoding. We have repre\u00adsented function de.nitions via a predicate, which means that new \nfunctions can be added to the database without chang\u00ading any existing code. Function bodies, on the other \nhand, are represented as terms, which makes it impossible to add something to a function body without \nactually modifying the term. This difference becomes interesting when one consid\u00aders, for example, whether \nthe methods of an object-oriented class should be represented in an open or a closed way. These choices \nhave implications for extensibility as well as separate checking and will be discussed later on in detail \n(Sec. 6.3.2).  2.4 Lack of Modularity Logic metaprogramming like most other metaprogram\u00adming constructs \n does not provide any modular checks making sure that computed programs or their clients are well-formed. \nIf we look at the metaprogram and at f3 in Fig. 1, then it is obvious that neither of them can be checked \nin a modular way, using only the interfaces of other refer\u00adenced entities. The code for a composed function \nin Fig. 1 is only avail\u00adable after instantiation with two concrete functions, and it is not obvious how \nto make sure that the program gen\u00aderator will only generate well-formed functions. On the other hand, \nthe function generator does not have an inter\u00adface that could hide its implementation details, hence \nthe call to compose(f1,f2) in f3 can only be type-checked by considering the full implementation (and \ncomputing the speci.c instance) of the function generator. Consequently, errors are only detected after \nthe generated programs are rejected by the object language compiler or in\u00adterpreter. At this point, however, \nit becomes very dif.cult to understand the origin of the error, since the error occurs in generated code \nwhose form depends on possibly com\u00adplex computations. It is obviously desirable to check meta\u00adprograms \nand their clients once and for all in a modular way instead. 3. Modular LMP The main reason why separate \nchecking is not possible in LMP is that there is no interface mechanism which can de\u00adscribe the behavior \nof program generators in a way that en\u00adables information hiding, yet contains suf.cient information to \ncheck each module separately. In the following, we will hence revisit our example and discuss what kind \nof informa\u00adtion must be available in the interface and what properties the checking algorithm must have \nsuch that separate check\u00ading is possible. After this informal discussion, we will gener\u00adalize our .ndings \nin the form of a formal de.nition in Sec. 4, which can also be read in parallel with this section. We \nwill also identify various requirements on the logic solver that do not hold for standard Prolog-like \nsolvers, but we will defer the discussion of how we addressed these requirements until Sec. 5. A variant \nof Fig. 1 as a set of modules is shown in Fig. 2. Each module starts with the keyword MODULE and consists \nof up to four sections: REQUIRES, IMPLEMENTATION, PRO-VIDES, and IMPLEMENTATIONPROVIDES. The REQUIRES \npart describes the constraints on the context under which the module can be used. The IMPLEMENTATION \npart gives the implementation, and the PROVIDES part states what is ex\u00adported to the external world. \nThe IMPLEMENTATIONPRO- Module % We call this module m1 in the text Implementation funimpl(f1, add(5, \narg)). Provides fun(f1). Module % We call this module m2 Requires fun(f1). Implementation funimpl(f2, \nadd(7, call(f1, arg))). Provides fun(f2). Module % We call this module m3 Requires fun(compose(f1,f2)). \nImplementation funimpl(f3, add(arg, call(compose(f1, f2), 13))). Provides fun(f3). Module % We call this \nmodule compose Implementation funimpl(compose(A, B), add(call(A, arg), call(B, arg))) . fun(A), fun(B). \nProvides fun(compose(A,B)) . fun(A), fun(B). Module % We call this the system module ImplementationProvides \nfun(F) . funimpl(P, Body),bodyok(Body). bodyok(arg). bodyok(N) . number(N). % number is a built-in bodyok(add(E1, \nE2)) . bodyok(E1), bodyok(E2). bodyok(call(F, A)) . fun(F), bodyok(A). Figure 2. Modular version of \nFig. 1 VIDES section is just a shorthand for copying de.nitions into both the IMPLEMENTATION and the \nPROVIDES part. In our module system, every imported feature of another module must be described explicitly \nin the module s RE-QUIRES part. This enables completely separate checking; no other module is referenced \n(our modules do not have names anyway); rather, required and provided features are matched during module \ncomposition. While the enumeration of every feature expected of an\u00adother module may seem a bit cumbersome, \nit is the only way in which a module can be checked completely indepen\u00addent of its context. However, \nthere could be different ways to arrive at this speci.cation. For example, the requirements could be \ninferred from the implementation by an appropriate algorithm, or a lightweight device (such as a preprocessor) \nthat allows one to import everything that is exported by an\u00adother module (such as header .les in C or \nimports in Java) could be implemented. Which (if any) of these mechanisms is used is not relevant for \nthis work. Our modules could be viewed as a kind of intermediate layer, where conventional import statements \nare transformed into the required form by copying the referenced module s PROVIDES to the module s REQUIRES \npart. However, for this work we just assume that all requirements are explicitly speci.ed.  The code \nin Fig. 2 contains one module that was not present in Fig. 1: the system module. The system module is \nspecial in that its PROVIDES part is implicitly part of the REQUIRES part of each other module; apart \nfrom this special role it is just another module. It is hence similar to, say, the java.lang package \nin Java or the Prelude in Haskell. In our system, however, we can use this module to de.ne the static \nsemantics and well-formedness of our language. We can see that the system module in Fig. 2 de.nes a simple \ntype checker for FP3. 3.1 Validity of Modules Let us now discuss the meaning of the different parts of \nour modules. In traditional module systems, the PROVIDES and REQUIRES parts of a module consists of a \nlist of names or type signatures, and a module is valid if, under the assump\u00adtion that if all required \nidenti.ers are bound to implemen\u00adtations of the correct type, the implementation part of the module gives \ncorrect de.nitions of all identi.ers/types in the PROVIDES part. Furthermore, two such modules are com\u00adpatible, \nif they do not require an identi.er to be bound to contradicting types and they do not export the same \nname [8]. In the case of our modules, a module is valid if each for\u00admula in the PROVIDES part is a logical \nconsequence of the declarations in the REQUIRES part and the declarations from the implementation. In \nthe example, the modules provide formulas of the form fun(F). It is easy to see that both mod\u00adule m1 \nand module m2 are valid, and that validity coincides with type safety as de.ned by the system module. \nNote that both modules can be checked completely separately, using only the PROVIDES part of the system \nmodule as external input. Module m3 can now also be checked separately, due to the explicit requirement \nfun(compose(f1, f2)) in its RE-QUIRES part. In particular, it can be checked independently of the metaprogram \nfor composing the functions. This solves the .rst problem identi.ed in the previous section: The lack \nof separate checking of clients of the code generator. The more interesting challenge is the well-formedness \ncheck of the compose function generator, because it in\u00advolves proving formulas containing universal quanti.cation \n(variables are implicitly universally quanti.ed) and impli\u00ad 3 For simplicity we have shown a type checker \nthat cannot deal with recur\u00adsive functions. One way to support recursive functions is to exchange the \ngoal bodyok(Body) in the de.nition of fun(F) by bodyok(Body) . fun(F). This is not standard Prolog code \nbut supported by our solver. cation. To this end, let us analyze the derivation of the fun(compose(A, \nB)) . ... property at the end of the compose module. The property is universally quanti.ed over A and \nB. In proof theory (and in our solver), the deduc\u00ad G.P (c) tion rule for universal quanti.cation is , \nwhere c G..X.P (X) is a fresh constant, hence let a and b be fresh constants for these variables. This \nleaves us with the task of proving R . I . fun(compose(a,b)) . fun(a), fun(b), where R and I are the \nformulas from the requirement and implementation part of the module, respectively. The deduc\u00ad G,A.B tion \nrule for implication is , hence we must prove G.A.B fun(compose(a, b)) in the context R . I .{fun(a), \nfun(b)}. Now type-checking the function calls in the func\u00adtion generator will succeed, because when the \ntype-checker queries fun(a) and fun(b), respectively, in the last clause of the bodyok predicate, this \nquery succeeds because they are in the context. Hence the interface of the function gener\u00adator is now \nalso suf.cient to check, once and for all, that all functions generated by this computation will be well-formed \n-which solves the second problem identi.ed in the previ\u00adous section: The lack of separate checking of \ncode genera\u00adtors/meta programs.  3.2 Consistency and Compatibility So far, we have only looked at the \nproblem of checking a single module separately. However, the purpose of a module is to be composed with \nother modules, which raises the issue of module compatibility. A trivial solution would be to regard \nall modules as mutually compatible, but this would mean that many common compatibility requirements in \nreal languages could not be modeled within our system, like forbidding two modules to export the same \nname or to create a cycle in an inheritance hierarchy. Such constraints arise frequently in conjunction \nwith metaprogramming. For example, a typical pattern for vari\u00adability management in C++ is to use #ifdef \npreprocessor directives to switch between different variants of a class or method. Some con.gurations \nof the switches of #ifdef directives are often contradictory because, say, the same method would be de.ned \ntwice. To enable separate check\u00ading, it is hence important that one can state these dependen\u00adcies in \nthe module s interface. In our setting, we model incompatibility between mod\u00adules as interfaces that \nare contradictory that is, the union of the interfaces of the modules is inconsistent. Inconsis\u00adtency \ncannot be directly expressed using Prolog, because sets of Horn clauses are always consistent by construction. \nA common way [31] to deal with this problem in a resolution\u00adcompatible way is to introduce a distinguished \nconstant . to act as a symbol for inconsistency. This constant can be used in heads of clauses and a \nproof of . from a given set of formulas marks this set as inconsistent. For example, a module may de.ne \ntwo variants of a func\u00adtion f1, one of which calls a conditionally included function f2. The switches \nfor these functions are a, b, and c. The dependencies can be expressed as follows:  Module Requires \n .. a,b. c . b. Implementation funimpl(f1, add(5, arg)) . a. funimpl(f1, add(7, call(f2,arg))) . b. funimpl(f2, \nadd(9, arg)) . c. Provides fun(f1). a. fun(f1). b. fun(f2). c. The check for module validity will take \ncare that this module is well-formed for every combination of the switches that satisfy the requirements \n(notice that the call to f2 in the second variant of f1 will only type-check due to the c . b constraint \nin the REQUIRES part). Module compatibility makes sure that this module will never be composed with a \nmodule or a set of modules that make it possible to derive both the a and the b switch; in this case, \nthe system would be able to prove . and would mark this set of modules as incompatible. With this notion \nof inconsistency, we can now de.ne what it means for modules to be consistent and compatible with other \nmodules. First, a module is consistent if it is valid, and ifitsinterface(i.e., REQUIRES .PROVIDES) is \nconsistent as a logic theory, that is, it is impossible to deduce .. Further\u00admore, a set of modules is \ncompatible, if the union of their interfaces is consistent. It is important that module compat\u00adibility \ndepends only on the interface but not the implemen\u00adtation because module compatibility should not depend \non implementation details. Later we will formulate a theorem that module composition cannot go wrong \nif only consis\u00adtent and compatible modules are composed, and that module compatibility is preserved by \nmodule composition. A weaker notion of compatibility checking of a set of modules would be to check compatibility \nonly pairwise. However, this would not be sound. For example, module 1 may provide a, module 2 may provide \nb, and module 3 may require .. a, b. These modules are pairwise compatible, yet their composition would \nlead to an inconsistent module.  3.3 Information Hiding Information hiding in our system is formalized \nby the re\u00adquirement that the union of requirements and implementa\u00adtion must logically imply (but not \nbe logically equivalent to) the PROVIDES part. However, since sets of logic (implemen\u00adtation) formulas \nmay be inconsistent, we have to be careful that the implementations of two modules are not incompat\u00adible \n(meaning: their union is inconsistent) although their in\u00adterfaces are compatible. For example, if we \nwould not re\u00adstrict the kinds of formulas in the implementation part, the following module would be consistent \nand compatible with every other module (since its interface is empty), yet its im\u00adplementation is incompatible \nwith any module that provides a function foo: Module Implementation .. funimpl(foo, arg). This example \nillustrates that we need more .ne-grained control over the kind of information that can be hidden in \nmodule implementations. It must not be possible to put formulas into the implementation that may silently \ncon.ict with implementations and interfaces of other modules. Just forbidding the use of . in the implementation \npart does not solve the problem, since one module may hide a function foo in its implementation part, \nand another module may contain a ..funimpl(foo, arg) rule in its REQUIRES part. To deal with this problem, \nwe make a distinction between formulas that can be used to describe hidden implementa\u00adtion details (implementation \nformulas) and formulas that are used to describe module interfaces. Implementation formu\u00adlas have the \nproperty that they are always consistent with ar\u00adbitrary sets of other implementation formulas, and thus \ncan be used in the implementation without further restrictions. If we want to use interface formulas \nin the implementation, there would be the possibility of an inconsistency. To pre\u00advent a module from \nhiding this possible source of inconsis\u00adtencies, we require that all interface formulas that appear in \nthe implementation must also appear in its PROVIDES part. The details of this mechanism will be discussed \nin the formal model presented in the next section. The choice of implementation formulas and how the \naforementioned properties of implementation formulas can be ensured depends on the logic. In our sample \nlogic, we de\u00adnote this distinction by a separation of the term constructors into two classes: the name \nof implementation constructors ends with impl (such as funimpl), and interface construc\u00adtors are all \nother constructors. We then de.ne a formula to be an implementation formula, if it uses an implementation \nconstructor in its head. The consistency check for a module will then determine whether the module is \nconsistent under any possible assignment of truth values to implementation literals -more about that \nlater.  3.4 Composition, Finalization, and Code Generation Consistent modules that are compatible can \nbe composed to form a new module, whose PROVIDES and implementation parts contain the union of the PROVIDES \nand implementa\u00adtion parts of the constituents, respectively. The REQUIRES part contains the union of \nthe REQUIRES parts of the con\u00adstituents except those formulas that follow logically from the PROVIDES \nparts of the constituents. In the formalization, we will see that the computation of the new REQUIRES \ninterface is actually a bit more complicated due to the fact that there may be circular dependencies \nand that the minimal set of re\u00adquirements that leave the module in a consistent state is not unique. \nHowever, we later will show that the composition of two valid, consistent and compatible modules is again \ncon\u00adsistent and valid, and that the .nal result of composing a set of modules, which together constitute \na complete program, is unique again.  At some point, all modules of the system have been com\u00adposed and \nit is time for the backend to generate source code. We could de.ne a (composed) module to be complete \nif its REQUIRES part is empty. However, this would be too strict, because a module may have formulas \nin the REQUIRES part that are not provable, yet are true if we consider the program to be complete. For \nexample, the constraint .. a,b from above cannot be proven in a monotonic logic: While it may hold in \nsome con.guration of modules that not both a and b are true, the addition of a new module could always \ninvali\u00addate that property. The source of this problem is that we expect our deduc\u00adtion relation to be \nmonotonic, which means that whenever we can prove f from a set F , then we can also prove f from any \nset F . . F . Some well-formedness constraints such as the one described above are inherently closed-world, \nhowever. Other typical closed-world constraints use univer\u00adsal quanti.cation, whereby the quanti.cation \nis supposed to quantify over all entities in a system, hence the proof\u00adtheoretic rule for universal quanti.cation \nis not applicable. To deal with such closed-world constraints, it is necessary to mark the point when \na program is complete, i.e., no more modules will be added to the program. When a program is sealed in \nthis way, it is safe to switch to an extended closed\u00adworld version of the prover, which is no longer \nrequired to be monotonic. To this end, we introduce a .nalization operation on a (composed) module, which \nattempts to prove all open requirements but this time using a closed-world version of the inference relation, \nwhere, say, .. a, b is considered proved if not both a and b can be deduced. If .nalization is successful \n(all requirements have been proved), the interfaces of the modules are discarded and the backend can \ngenerate code from the implementation of the .nalized module. In modular logic metaprogramming, code \ngeneration always operates on the set of all implementation formulas. There is no separate compilation \nof modules, be\u00adcause the structure of the code that would result from a mod\u00adule s implementation may \ndepend on the implementation of other modules and thus we cannot generate any meaningful code before \nwe seal the composition of all modules.  3.5 Soundness We have seen how various kinds of well-formedness \ncondi\u00adtions can be modeled in our modular LMP approach. How\u00adever, our approach itself is not speci.c \nto any object lan\u00adguage or set of well-formedness conditions, and hence our system can only detect well-formedness \nviolations that have been modeled correctly. Therefore we can only guarantee relative soundness, that \nis, soundness with respect to the part of the static semantics that has been modeled, e.g., in the form \nof well-formed rules in the system module. A point which makes the correct formulation of well\u00adformedness \nconstraints subtle is its interplay with the notion of information hiding embodied by our module system. \nA module can contain utter garbage in its implementation part if nothing is promised in its PROVIDES \npart. If a module contains, say, a function de.nition which is not exported and not called (directly \nor indirectly) by any other function which is exported, then a type error in this function cannot be \ndetected. However, the well-formedness constraints can be speci.ed in such a way that the type-check \nof an exported function requires all transitively called functions within the module (including those \nthat are not exported) to be well\u00adtyped, too. Our type checker in Fig. 2 has this property. For this \nreason it is important that the code generator will generate object language code only for those parts \nof the database that are used in the the proof trees required to prove the PROVIDES part of the module. \nWe believe that this is suf.cient to model the well\u00adformedness constraints of object languages in such \na way that all well-formedness errors are detected within the mod\u00adule system but only if the logic is \nexpressive enough, e.g., computationally complete. For simple logics, such as propositional logic or \nvariants thereof, complex type-checking rules cannot be modeled within the logic. This does not mean, \nhowever, that our framework cannot be used. The key idea is to model those program entities which are \ntoo complicated (or undesired) to check within the logic as atomic constants. Then these entities can \nbe checked by an external tool before the MLMP checking process takes place. Due to their representations \nas constants, the entities cannot be manipulated within the logic and will hence still be well-formed \nwhen they are later again rei.ed as object-language code in the backend. In general, the level of detail \nin the program represen\u00adtation hence has to .t to the expressive power of the logic and the complexity \nof the well-formedness constraints at that level of detail. 4. Formalization In this section, we generalize \nfrom the discussion in the previous sections and present an axiomatization of a class of logics together \nwith a formal de.nition of modules on top of the logic under which separate checking will be sound. We \ncall a logic that .ts to the axioms a module description logic (MDL). The logic FP +, which was informally \nused in the previ\u00adous section, is just one particular MDL, and we will give a more detailed description \nof FP + and other possible logic languages later. The proofs for all theorems presented in this section \nare contained in the appendix.  4.1 Module Description Logic We assume that the formulas in an MDL are \ngiven by a set F. In the examples in the previous section, this set of formulas was the set of FP + facts \nand rules. In the following, we use upper-case letters F, G to denote subsets of F, and lower\u00adcase letters \nf, g to denote single formulas. We also assume a deduction relation, .. P(F) \u00d7F, which de.nes what logically \nfollows from a given set of formulas. We use the notation F . F . to denote that for all f . F . we have \nF . f. The choice of this deduction relation is not completely arbitrary, because we need to have some \nimportant properties in the logic language to make the module system well-de.ned, in particular to prove \nanything about the result of combining modules. The following de.nition sums up the properties of an \nMDL. DEFINITION 1 (Module Description Logic). A module de\u00ad F , ., .CW scription logic is a tuple (F,, \n.F ) satisfying the following conditions: .F . F (1.1) If F . F . and (F . F .) . F .. then F . F .. \n(1.2) If F . F . and F . G then F . . G (1.3) For all F . F we have F . F (1.4) F . F (1.5) F .. . (1.6) \nIf F . f then F .CW f (1.7) The .rst requirement (1.1) de.nes the notion of incon\u00adsistency. An important \npoint we have stressed in the last section was the possibility and identi.cation of inconsisten\u00adcies \nbetween module interfaces. To make minimal assump\u00adtions about the structure of formulas, we only require \nthat ., standing for inconsistency, is a logic formula. The next three requirements are that . is transitive \n(1.2), monotonic (1.3) and re.exive (1.4). Transitivity means that if a set F . of formulas follows from \nanother set F by de\u00adduction, and F .. follows from F ., then F .. already follows from F . This is important \nto make sure that what follows from an interface also follows from an implementation of the interface. \nMonotonicity means that if a formula can be proved from a set F of formulas, then it can also be proved \nfrom every larger set that contains F . This property is essen\u00adtial for modularity, because it guarantees \nthat requirements that are checked against interfaces of one module also hold when checked against a \nlarger interface, for example the in\u00adterface of a composition of modules. Re.exivity means that everything \nthat is in the context can be deduced. As we argued in the previous section, we have to distin\u00adguish \na subset of formulas that is always consistent, which we call implementation formulas. We denote this \nset of for\u00admulas F (1.5, 1.6). Finally, we need a closed-world version .CW of the deduction relation \nwhich must be an extension of the ordinary deduction relation that is no longer required to be monotonic \n(1.7).  4.2 Modules, Validity, and Consistency F , ., .CW Based on an arbitrary but .xed MDL (F,, .F \n) we can now de.ne what a module is: DEFINITION 2 (Module). A module is a triple (R, I, P ) of .nite \nsubsets of F. In correspondence with the previous section, we call R the REQUIRES part, I the implementation \npart (the formulas between BEGIN and END), and P the PROVIDES part. We call the set R . P the interface \nof the module. We do not model the IMPLEMENTATIONPROVIDES part that was used in the motivation, since \nit is just syntactic sugar for putting copies of formulas in both I and P . Not every combination of \nrequirements, implementation, and provided interface forms a valid module. To formalize the requirements \nfor valid and consistent modules, we gen\u00aderalize the requirements formulated in Sec. 3.1 and 3.2. First \nwe de.ne what it means that a module is valid: DEFINITION 3 (Valid Module). A module M =(R, I, P ) is \nvalid, if R . I . P . Valid modules have correct speci.cations in the sense that their PROVIDES part \nis really a logical consequence of the implementation and the requirements. In other words, the system \ncan trust the promises in the interface of the module without referring to its implementation. However, \na module may still create inconsistencies, either by inconsistent for\u00admulas in the interface or by containing \ninterface formulas in the implementation. For example, a module may require ., or hide .. x in its implementation. \nWe deal with these problems by de.ning a stronger prop\u00aderty of modules, namely consistency. To do so, \nwe .rst for\u00admalize the idea of a legal interface, which represents inter\u00adfaces that are consistent and \nwill never create inconsistencies with hidden parts of other modules: DEFINITION 4 (Legal interfaces). \nFor a set F .F of for\u00admulas, we say that F is a legal interface, written ifc(F ), iff .F . .F .F . F \n. .. .. A valid module is consistent if it has a legal interface and all implementation formulas are \neither part of the informa\u00adtion hiding space F or announced in the PROVIDES part. DEFINITION 5 (Consistent \nModule). A module M given by the three sets (R, I, P ) is consistent, written module-ok(M), iff M is \nvalid ifc(R . P ) .f . I.(f . F) . (f . P ). (5.8) (5.9) (5.10)  By 5.10, consistency guarantees that \nwe can reason about the possible effects or inconsistencies caused by a module by looking at its interface \nonly. Together with validity, con\u00adsistency de.nes the separate check that can be made on each module \nin isolation. Any further checks will only concern the interface of the modules. Hence, module-ok(M ) \ncan be seen as our formalization of the requirements that enable separate checking.  4.3 Composing Modules \nThe composition of two or more modules requires two ac\u00adtivities: A check whether the modules are compatible, \nand a process which discharges those requirements of the modules that are exported by the other module \nand merges the de.ni\u00adtions of the modules. Compatibility is de.ned as follows: DEFINITION 6 (Module compatibility). \nA set of modules M = {(R1,I1,P1),..., (Rn,In,Pn)} is compatible, writ\u00adten \u00f7(M), iff ifc( Ri . Pi). i.{1,...,n} \nIf only two modules are involved, we write M \u00f7 M. to stand for \u00f7({M, M.}). It is crucial that the compatibility \nbetween modules does not depend on their respective implementation. Hence it would in principle be possible \nthat the implementations are contradictory. But if all modules are consistent, then the fact that these \nmodules are compatible also means that their implementations are compatible: THEOREM 7. If a set {(R1,I1,P1) \n..., (Rn,In,Pn)} of modules is compatible and every module Mi is consistent, then .i.{1,...,n}Ii .. .. \nAs a consequence, we can merge these implementations without the danger of inconsistencies, and we can \nthen cre\u00adate a new module for the merged implementation by creating a new interface. This interface contains \nonly those formulas of the original modules interfaces that are not proved by the combined provided parts. \nModule reduction is a formaliza\u00adtion of this process as a transition system on modules: DEFINITION 8 \n(Module Reduction). A module (R, I, P ) is reducible by f . R, if P . f and (R \\{f},I,P ) is valid. The \nreduction relation on modules is de.ned as (R, I, P ) . (R \\{f},I,P ) if (R, I, P ) is reducible by f. \nThe re.exive and transitive closure of . is .* . M. is a minimal reduction of a module M, written M .min \nM., if M .* M. and (\u00ac.M..) M. . M.. (M. is a normal form of M). The validity check of (R\\{f},I,P ) can \nfail in the case of non-wellfounded circular de.nitions. For example, a module may require fun(f) and \nprovide fun(f). Such situations can, in the general case, not be detected in a modular way, which explains \nwhy we have to look into the implementation part. Rather than throwing an error, we have decided to just \nnot allow the reduction of this requirement, since the situation may still be resolved by adding another \nmodule later on which adds the missing feature. Module reduction preserves consistency. LEMMA 9 (Preservation \nof consistency under reduction). If module-ok(M) and M . M., then module-ok(M.). The composition of two \nmodules M1 =(R1,I1,P1) and M2 =(R2,I2,P2) is de.ned as the set of all possible minimal reductions of \ncomposing the parts of both modules: DEFINITION 10 (Module composition). M1 + M2 = {M | (R1 . R2,I1 . \nI2,P1 . P2) .min M}. This de.nition of module reduction will correctly dis\u00adcharge circular dependencies \nbetween modules. For exam\u00adple, if M1 =({fun(a)}, {funimpl(b, call(a,arg))}, {fun(b)}) and M2 =({fun(b)}, \n{funimpl(a, call(b,arg))}, {fun(a)}) and M . M1 + M2 then M .min (\u00d8, {funimpl(a, ... ), funimpl(b, ... \n)}, {fun(a),fun(b)}) Module composition produces a unique new module, un\u00adless the module contains non-wellfounded \ncircular depen\u00addencies. For example, if M1 =({a}, {b . a}, {b}) and M2 =({b}, {a . b}, {a}) are combined, \nthe resulting re\u00adquirements can be reduced to {a} or {b}, but no further, since the module would become \ninvalid otherwise. However, we will later show that all of the modules in M1 + M2 are equivalent with \nregard to the .nal program at the end of the composition process. DEFINITION 11 (.-Equivalence). We say \nthat two mod\u00adules M1 =(R1,I1,P1) and M2 =(R2,I2,P2) are .\u00adequivalent, written M1 . M2, if I1 = I2 and \nP1 = P2 = P, P . R1 . R2 and P . R2 . R1 THEOREM 12 (Composition and .-Equivalence). If both M. and M.. \nare minimal reductions, i.e., M.,M.. . M1 + M2, then M. . M.. . We can pick any of the minimal reductions \nwithout losing information and thus can choose an arbitrary deterministic module composition. DEFINITION \n13 (Deterministic Composition). We de.ne the deterministic composition of two modules M1 and M2 as M1 \n.s M2 = s(M1 + M2), for some selection function s : S .. m . S.  The .s composition operation has the \nproperty that it pre\u00adserves consistency and validity of modules: THEOREM 14 (Composition). Let M1 and \nM2 be two mod\u00adules with module-ok(M1) and module-ok(M2) and M1 \u00f7 M2. Then module-ok(M1 .s M2). Let us \nnow come to the composition of sets of arbitrary many modules. For this we must .rst establish that compo\u00adsition \npreserves compatibility: THEOREM 15 (Preservation of Compatibility). If \u00f7 ({M1,M2,M3}), then (M1 .s M2) \n\u00f7 M3 The order in which modules are composed is not signi.\u00adcant: THEOREM 16. The operation .s is associative \nwith respect to .-equivalence: (M1 .s M2) .s M3 . M1 .s (M2 .s M3). .s Thus we can write Mi for the result \nof iteratively 1=i=n combining adjacent modules from the list (Mi)1=i=n in arbitrary order. This means \nthat we can generalize Thm. 14 to sets: THEOREM 17 (Composition of module sets). Consider a set M = {M1,...,Mn} \nof modules with module-ok(Mi) .s for all i and \u00f7(M). Then module-ok( Mi). 1=i=n  4.4 Finalization and \nCode Generation Using the composition operator de.ned in the previous para\u00adgraph on all modules of a \nprogram, we obtain a single mod\u00adule representing our program, but this resulting module may still contain \nformulas in its REQUIRES part even if all de\u00adpendencies are satis.ed. As discussed in Sec. 3.4, these \nfor\u00admulas are closed-world requirements that cannot be proved with the monotonic deduction system. To \ngenerate code for a program represented by a mod\u00adule we have to ensure that the module s REQUIRES part \nis empty, because otherwise required information could be missing in the .nal program or there could \nbe unsatis.ed constraints. As discussed before, this cannot be achieved us\u00ading ., because composition \nuses the . deduction relation, which is monotonic by de.nition. Monotonicity is neces\u00adsary for composition, \nbecause the resulting module may be composed with other modules later, but as soon as we want to generate \ncode we know that there will be no more com\u00adpositions. What we need is an operator that turns the .nal \nmodule into a program or indicates an error, if one of the closed-world requirements is not satis.ed. \nWe call this oper\u00adation .nalization. For .nalization we use the (typically) non-monotonic ex\u00adtension \n.CW of the deduction relation .. There are different ways to de.ne non-monotonic extensions such as negation\u00adas-failure \n[36], and the choice of the non-monotonic ex\u00adtensions determines which kinds of non-monotonic well\u00adformedness \nrequirements can be declared. Usually, the closed-world extension will contain additional deduction F \n..CWf rules such as F .{f}.CW. . For the purpose of our formalism, the exact kinds of non-monotonic extensions \nare not signif\u00adicant; the only role of .CW is to discharge nonmonotonic requirements, hence it only matters \nthat the deduction rela\u00adtion is an extension of the monotonic one that is no longer required to be monotonic, \nas required by Def. 1.7. The result of .nalization is what we call a program, namely the database of \nall implementation formulas which forms the input to the code generator backend. If .nalization succeeds, \nneither the REQUIRES nor the PROVIDES part are needed anymore. For the de.nition of .nalization we use \n.CW, a variant of . that is de.ned by using .CW instead of DEFINITION 18 (Closed-World Module Reduction). \nA mod\u00adule (R, I, P ) is closed-world reducible by f . R, if P .CW f and (R \\{f},I,P ) is valid. The reduction \nre\u00adlation on modules is de.ned as (R, I, P ) .CW (R \\{f},I,P ) if (R, I, P ) is closed-world reducible \nby f. The re.exive and transitive closure and minimal reductions of .CW are de.ned like in Def. 8. It \nis obvious that .CW preserves validity and consistency. With this de.nition, .nalization is de.ned as \nfollows: DEFINITION 19 (Finalization). I if (R, I, P ) .CW min (\u00d8,I,P )Final(R, I, P )= failure otherwise \nThe following theorem sums up the main properties of our approach. By this theorem we know that in whatever \norder we compose our modules, the result is well-de.ned if the comprising modules are. THEOREM 20. Given \na set {M1,...,Mn} of consistent and compatible modules, a selection strategy s, and the com\u00ad .s posed \nmodule M =(R, I, P )= Mi, the following 1=i=n statements hold: M can be computed in a .nite number of \nreduction steps.  M is consistent, i.e., module-ok(M).  If s and s. are two selection functions (Def. \n13) and .s and .s. are their associated composition operators, then  .s .s. Final( Mi)= Final( Mi). \n1=i=n 1=i=n The implementation part of M is consistent, i.e., I .. ..  If Final(M)= I .F then I . P \n.   5. Implementation We have implemented a system for MLMP which is built according to the formal \nmodel described in the last section. As in the formal model, our MLMP implementation can be parameterized \nwith an MDL and a corresponding solver, and is independent of any particular object language. We have \nalso developed a prototypical system module for the Java programming language. In the following, we describe \nboth the MLMP system and our solver for the FP + module description logic. The system and the solver \nare available for download at http://daimi.au.dk/~klose/mlmp. 5.1 The MLMP System We have implemented \nour MLMP system in SWI-Prolog4. It comprises a central module, the module composer, which is de.ned in \nterms of the three variation points of the system: the frontend interface, the MDL interface with correspond\u00ading \nsystem module, and the backend interface. The frontend, which is responsible for reading mod\u00adule descriptions, \ncan support multiple input formats. There is a raw input format, namely input terms of the form mod(R, \nI, P ) which describe the three parts of a module. To ease writing modules, the frontend can be equipped \nwith functions to accept quoted object language code and trans\u00adform it into formulas accepted by the \nsystem, or to convert .les written directly in the object language. The module composer is the central \ncomponent of our implementation, which provides the top level interface to the user and coordinates the \nuse of the frontend, the MDL imple\u00admentation, the system module, and the backend. The mod\u00adule composer \ntakes a list of modules as input, checks each module for consistency using the MDL interface, and pro\u00adduces \na composed module according to our formalization. If required by the user, the module composer will also \ntry to .nalize the module and, if successful, produce code using the backend. We have developed a sample \ncode generator component that produces Java code from FP + modules. Whenever module checks or reduction \nare necessary, the system invokes the deduction relation through the MDL in\u00adterface. The system module \nis another parameter, and the module composer will take care of adding the system mod\u00adule constraints \nto all consistency and compatibility checks, as described in Sec. 3.1. All in all, the system is a straightforward \nand direct im\u00adplementation of our formalization. 5.2 The FP + Module Description Logic The logic we use \nin our examples, FP +, consists of the pure and monotonic core of Prolog [37] (which means: no negation-as-failure \nor other closed-world reasoning, no cuts, no side effects), and a few simple extensions well-known from \n.Prolog [32, 33] and its extensions. Hence we do not 4 http://www.swi-prolog.org/ claim any originality \nof our solver from the perspective of logic programming and theorem proving. We have implemented a solver \nfor this logic in Prolog, as an extension of the standard meta-circular Prolog interpreter [37]. Although \nthe Prolog extensions we need are available in .Prolog, we have not used .Prolog itself for two reasons: \nFirst, it is not clear whether the higher-order extensions of .Prolog interfere with our de.nition of \nF and the require\u00adments of Def. 1. Rather, for this work we were looking for the simplest logic that \nful.lls our formal requirements and is suf.cient for the examples we are interested in. Second, we need \ncontrol over the deduction mechanism such that we can perform the consistency check (see next subsection) \nand switch to closed-world deduction for .nalization, and this turned out to be much easier if we have \nour own solver im\u00adplementation. Programs in FP + consist of standard Prolog Horn\u00adclauses, the term ., \nwhich is used to denote inconsis\u00adtency, and the following features from .Prolog: implications as goals, \nexplicit quanti.cation, and universally quanti.ed goals. The set FP + of formulas in our language is \nde.ned over a set L of (positive) literals. There is a subset L . L which contains all implementation \nliterals and for which ../L . Syntactically, we use the notation from Sec. 3.3 and distinguish implementation \nliterals from other literals by the functor suf.x impl. The set of implementation formulas is de.ned \ninductively as follows: FP + = L .{ l . l1 . ... . ln, (.v)f, (.v)f } where li . L, l . f .F P +. L, \nSince . cannot be used in the head and there is no negation, this de.nition satis.es (1.5) and (1.6) \nof Def. 1. Formulas in F P + can be used both as clauses in the logic program and as goals, which makes \nit necessary to give an interpretation of implication and universal quanti.cation. Formally, the set \nof F P + formulas is a subset of the .rst\u00adorder hereditary Harrop formulas (fohh) [32], and the proof \nmethod (which was sketched in the motivation in Sec. 3) for fohh agrees with the classical proof-theoretical \nsemantics in predicate logic [32]. A detailed discussion of how a solver for such formulas works is not \nrelevant for this paper. The basic structure of the solver is that of a standard resolution\u00adbased Prolog \nsolver, and the additional features (quanti.ca\u00adtion, implications as goals) are handled as described \nin [32]. For the interface formulas in FP +, . is allowed as the head of a clause. Operationally we treat \n. like a literal and we interpret the meaning of . as minimal-logic nega\u00adtion [31, Sec. 7], that is, \nwe are only interested in detecting inconsistencies but we do not allow deducting arbitrary for\u00admulas \nfrom a proof of .. The full set of formulas is given by the following inductive de.nition:  FP + = L \n.{l . l1 . ... . ln, (.v)f, (.v)f}where f .FP +,l . L . {.},li . L. Regarding the remaining properties \nof Def. 1, (1.1) and (1.4) hold trivially, and (1.3) holds because we use only the monotonic core of \nProlog and monotonic extensions. (1.2) holds modulo the depth bound of the solver, see discussion in \nthe next section. 5.2.1 Checking Module Consistency The de.nition of legal interfaces (Def. 4) involves \nchecking the public interface of the module together for consistency with arbitrary sets of implementation \nformulas, and is hence instrumental to make information hiding sound. However, in FP + it is not obvious \nhow to implement this check, since it quanti.es over an in.nite set. Fortunately the solution is simple: \nDuring the consistency check, the solver assumes that every implementation literal is true. This check \nis sound because implications in FP + can only contain positive liter\u00adals. It is also complete, since \nthere could always be an addi\u00adtional module which contains the respective implementation literal. Formally \nwe can describe this strategy by a mapping T : FP + .FP + which removes all implementation literals from \na given formula. If the resulting body of the clause is empty, the head literal is returned and if the \nhead literal is an implementation literal, it is replaced by true. This strategy for consistency checks \nis both sound and complete, as guaranteed by the following theorem: THEOREM 21. (.F .F P +) {fi}i.I . \nF ...{T (fi)i.I }... 5.2.2 Closed-World Reasoning As discussed in Sec. 4.4, the .nalization phase of \nthe module composition process requires a closed-world version of the deduction relation, which is no \nlonger required to be mono\u00adtonic. Our FP + solver introduces the following two non\u00admonotonic proof rules \nduring .nalization: First, a formula .. l1 .....ln is considered proved if any of the li cannot be proved \n(this is essentially negation-as-failure). Second, a universally quanti.ed implication can be proved \nby iterating over all possible instantiations of the premise (in the SWI Prolog system this non-monotonic \nrule is available as the forall primitive). 5.2.3 Termination and Incompleteness of the Solver Since \nFP + is an extension of (pure) Prolog, the solver is incomplete, just like any Prolog solver. This means \nthat the proof search is either not guaranteed to terminate, or the solver will sometimes answer unknown \ninstead of yes or no. We have chosen the latter approach by limiting the search depth of the prover. \nIf the limit is exceeded, the Module Requires x: Nat Implementation z : Nat =3,f : Nat . Nat = .y.y +x+z \nProvides f : Nat . Nat Figure 3. Module in F1 prover answers unknown. For our purposes, it is suf.cient \nto make sure that the solver only errs on the safe side . This means that whenever unknown occurs during \na check (module validity, consistency, or compatibility), the check fails. The practical signi.cance \nof incompleteness will be discussed in the next section.  5.3 The Java binding We have also implemented \na prototypical system module and a code generator for the Java programming language. Obviously the static \nsemantics of the Java programming lan\u00adguage is much more complex than FP (our example from the introduction), \nbut conceptually the system module for Java has the same shape as the one for FP in Fig. 2. We have choosen \nopen representations for both classes and methods (cf. Sec. 2.3), which enables more .exibility from \nthe per\u00adspective of metaprogramming -for example, methods can be added to a class externally . Our code \ngenerator just iterates over the database and computes, starting from a set of start classes transitively \nthe code of all classes that are referenced from this set. A Java compiler is then used to compile the \ncode to Java byte code. 6. Discussion In this section we demonstrate the versatility of MLMP and discuss \nalternative MDLs, other applications, and limitations of the approach. 6.1 Alternative MDLs In the previous \nsection we introduced the MDL instance FP + as a very expressive and undecidable language. How\u00adever, \nFP + is just one data point in a wide spectrum of pos\u00adsible MDLs, which also includes simpler, decidable \nlogics. In the following we discuss other MDLs and their potential applications. 6.1.1 Simple Signature \nMatching Our .rst example demonstrates how our module system is connected to traditional module systems \nthat use simple lists of signatures in their export/import interfaces. For illustra\u00adtion, we choose Cardelli \ns module system for F1 [8] as an example. An example for an F1 module is given in Fig. 3. The module \nsystem for this language has the following responsibilities: a) It must check that the modules are well\u00adtyped \ngiven the speci.ed imports, b) it must check that what is promised in the PROVIDES part is available \nin the imple\u00ad  Module Requires bound(x,Nat) Implementation def(l1,Nat,3), def(l2,Nat .Nat,.y.y + x + \nl1), export(l2,f) Provides export(l2,f), bound(f,Nat.Nat) Figure 4. Encoding of Fig. 3 in FF1 mentation, \nc) two modules must be deemed incompatible if they have con.icting expectations regarding the type of \nan imported term, d) two modules that export the same name must be deemed incompatible. Furthermore, \nthe composi\u00adtion of two compatible modules should not produce acciden\u00adtal name clashes of hidden names, \ni.e., lexical scoping must be preserved. In the following we present the Module Description Logic for \nF1. In particular, we show how the problem with the lack of name spaces and scoping can be solved in \nthe context of our framework. Lexical scoping is a subtle issue if modules are repre\u00adsented as .at sets \nof formulas. Module composition (Def. 10) combines modules by merging their implementation parts, and \ncare must be taken to preserve scoping during this oper\u00adation. We deal with this problem by a de.nition \nof F F1 which takes care that every name has a globally unique label l; tech\u00adnically, this could be realized \nby assigning, say, suf.ciently large random numbers to every internal name. Formally, we de.ne the set \nof formulas in the logic as follows (x, t, and e range over all names, types, and terms, respectively): \n FF1 = {def(l, t, e) | l is unique in F F1} FF1 = FF1 .{export(l, x), bound(x, t)} . {.} The corresponding \nencoding of the example is given in Fig. 4. We represent the de.nition of names by def terms. Internal \nlabels can be exported as name x via export. The bound predicate is used in the interface parts to specify \nim\u00adported and exported names. The deduction relation . over these formulas is given by the following \nfour inference rules: F . def(l, t, e) F . export(l, x) welltyped(F, l, t, e) f . F F . bound(x, t) F \n. f F . bound(x, t) F . export(l, x) F . bound(x, t.) F . export(l.,x) t .l = l. = t. .F .. F .. The \n.rst rule takes care of points a) and b) discussed above: If a module declares that it provides a de.nition \nof x with type t, then it will be de.ned and well-typed. We assume that a type checking algorithm is \ngiven in the form of a welltyped predicate, which builds a typing context out of the F param\u00adeter and \nthen checks that e has type t under this context. The welltyped predicate must type-check exactly the \nterm t and any other term in F that is (transitively) referenced by t if it checks less, then hidden \nterms that are needed in the .nal program may not be well-typed. If it checks more, then the deduction \nrule would not be monotonic (1.3). The next rule is just set membership and guarantees (1.4) of Def. \n1. In par\u00adticular, this rule is responsible for matching signatures, i.e., required and provided bound \nformulas. The last two rules declare a set of formulas inconsistent if it has contradict\u00ading expectations \nwith regard to the type of an identi.er, or the same name is provided twice, respectively (see c) and \nd) above). The last rule also explains why the internal label l2 is also published in the PROVIDES part \nof Fig. 4: It denotes that there is an actual hidden implementation associated to that label. Without \nthis information, it would be impossible to detect whether another module has a de.nition of the same \nname. In fact, Def. (5.10) forces any consistent module to publish all its exports in its PROVIDES part. \nIt is not hard to see that this deduction system has the properties demanded by Def. 1. (1.1) and (1.5) \nare trivial, and we have already discussed (1.4). (1.2) is trivial since the logic has no implication \nor the like. (1.3) was already dis\u00adcussed for the .rst rule above, and the other rules are triv\u00adially \nmonotonic. (1.6) is more interesting: If it were possible to deduce more bound formulas by adding more \ndef formu\u00adlas, then (1.6) would not hold due to the last two deduction rules. But due to the incorporation \nof the export formu\u00adlas, which are not part of F F1, this cannot happen and (1.6) holds. Closed-world \nreasoning is not required for F1, hence .CW =., which trivially ful.lls 1.7. In a more expressive logic, \nsuch as FP +, FF1 can be encoded within the logic, that is, the deduction rules given above are encoded \nas formulas within the system module of the logic. Hence the above encoding of the F1 module system could \nalso be performed in FP +.  6.1.2 Propositional Logic Propositional logic also trivially ful.lls Def. \n1 by taking F = \u00d8. This logic is too simple to represent programs, but it can still be useful to express \ncon.guration well-formedness constraints, such as constraints on the valid con.gurations of a product \nline or feature model [4]. For example, in a feature model it is typical to have constraints of the form \nfeature X requires feature Y or feature X and feature Y cannot be used together , and such constraints \ncan easily be formulated in propositional logic [4]. A nice property of our approach is that the compatibility \nand consistency checks are by construction again modular, as with every instance of our model. In contrast, \ncon.guration checkers for feature models are typically global checkers that need the complete con.guration \nof a feature model in one place. In our model, this would correspond to checking all constraints not \nuntil .nalization.  If necessary, the idea can easily be generalized to more powerful constraint systems \nfor con.guration checking, such as the one investigated by [5]. It is only necessary to make sure that \nDef. 1 holds.  6.1.3 Datalog Datalog [9] is a subset of Prolog that is decidable and can be implemented \nvery ef.ciently, as compared to full Prolog. These properties come at the price of restricted arithmetic, \nrestricted negation, and the prohibition of complex terms as arguments. This restricted logic is not \nexpressive enough to model complex constraints, such as a type systems, but it is suf.cient to reason \nabout simpler properties of software sys\u00adtems, for example source code querying, detection of design \nguideline violations, and enforcement of architectural con\u00adstraints [18, 23]. We could combine these \napproaches with our module system to provide modular checks for architec\u00adtural constraints on arbitrary \ncollections of source code arti\u00adfacts.  6.2 Other Applications In the previous presentation of alternative \nMDLs we also discussed a set of applications of these logics. Since our FP + logic can encode all these \nlogics, these applications would work equally well in FP +. In this section, we want to discuss three \nmore application areas that make full use of the expressiveness of FP +. 6.2.1 Design Pattern Generators \nIt is known that logic metaprogramming can be used to gen\u00aderate parts of the implementation of design \npatterns that de\u00adpend on the structure of the rest of the system [15]. Typi\u00adcal examples are visitors \nfor class hierarchies, proxy/wrap\u00adper/decorator classes, and .yweight objects [21]. The im\u00adplementation \nof such design pattern consists of one or more class computations and a set of predicates through which \nthe user can control the application of the class computations. For example, a visitor generator for \na class hierarchy with root X is realized by the module in Fig. 5, which uses the pro\u00adgram representation \nfrom Sec. 3. This generator creates the visitor class visitor(X) and visit methods for all possi\u00adble \nsubtypes of X. It also takes care of creating all the nec\u00adessary accept methods in the elements of the \nclass hier\u00adarchy. The generation of a visitor can be triggered by an\u00adother module by putting make visitor( \nMyClass ) into its PROVIDES interface (and the implementation). Just as in our function generator example, \nthe code generator can be type-checked once and for all, and clients using visitors can be type-checked \nin terms of the visitor interface only. 6.2.2 Cross-Language Typing A particular strength of our approach \nis that it is indepen\u00addent of a speci.c object language, which makes it partic- Module Implementation \nclassimpl(visitor(X), Object ) . make_visitor(X), class(X). methodimpl(visitor(X), visit(Y), [y], [Y], \n void, return ) . make_visitor(X), class(Y, S), subtypeeq(Y, X). methodimpl(Y, accept, [visitor], [visitor(X)], \nvoid, Body ) . make_visitor(X), class(Y, S), subtypeeq(Y, X), Body = call(visitor, visit(Y), [this]). \nProvides class(visitor(X), Object ) . make_visitor(X), class(X). method(visitor(X), visit(Y), [Y], void) \n. make_visitor(X), class(Y, _), subtypeeq(Y, X). method(Y, accept, [visitor(X)], void) . make_visitor(X), \nclass(Y, S), subtypeeq(Y, X). Figure 5. Visitor generator ularly simple to integrate different object \nlanguages. There are often complex constraints between different code arte\u00adfacts written in different \nlanguages. For example, classes for database access may be generated from speci.cations in an XML format. \nOne would like to typecheck clients of these classes against the XML speci.cation rather than against \ngenerated code. Similarly, there are often complex well-formedness constraints between con.guration .les \nand ordinary source code. For example, a class name occuring in a con.guration .le for a component container \nmay be re\u00adquired to be the name of an existing class which must be a subclass of a container class. Finally, \nit would also be de\u00adsirable to have a .ne-grained modular typing discipline for calls between program \nparts written in different languages. The lack of modular cross-language checks typically leads to subtle \nerrors that occur late in the build process or some\u00adtimes not until deployment-or runtime. All such cross-language \nwell-formedness constraints can easily be modeled and hence checked in our framework. All a user of our \nframework has to do to integrate several lan\u00adguages is to provide a frontend for each of these languages, \nand then add the cross-language well-formedness constraints either to the system module or to an ordinary \nmodule that is imported by the modules to be checked.  6.2.3 Pluggable Type Systems Another interesting \napplication is to provide support for pluggable type systems [3, 6]. Pluggable type systems check optional \nor domain-speci.c well-formedness constraints that are not part of the type system of the object language. \nTypi\u00adcal examples include non-null type checkers or type systems for alias control.  In our setting, \npluggable type systems can be de.ned in the PROVIDES part of a module, just like the normal base type \nsystem is de.ned in the system module, and other mod\u00adules could then use the type system by importing \nit and ex\u00adporting, say, method nonnull ok well-formedness certi.\u00adcates in their PROVIDES part, whereby \nmethod nonnull ok is de.ned by the type system module and holds if the respec\u00adtive method is well-formed \nwith regard to the non-null type system. In fact, the type system discussed in Sec. 3 can al\u00adready be \nconsidered a pluggable type system if the rules are moved from the system module into an ordinary module. \nAnother conceivable application of pluggable type sys\u00adtems would be to retroactively check an existing \nmodule ac\u00adcording to a new type system (or, more generally, static anal\u00adysis). However, there is one \nmajor problem with this idea: typically, the actual code to be type-checked is hidden in the implements \npart of the module, and hence another module that is not explicitly imported has no access to these hidden \nparts. The implementation details would have to be exposed in the PROVIDES part of a module to make this \nwork, but this would be in con.ict with information hiding. A possible solution to this problem would \nbe a more .ne-grained notion of information hiding, where, say, some modules are allowed to see more \nimplementation details than other modules. The exact design of such a mechanism is part of our future \nwork.  6.3 Limitations We conclude the discussion with a consideration of the lim\u00aditations of our approach. \n6.3.1 Incompleteness of the Solver Although we have seen that our formal framework is also ap\u00adplicable \nand useful if it is instantiated with simple, decidable logics, many interesting applications in particular \nthose re\u00adlated to type checking require undecidable logics such as FP +. In Sec. 5.2.3 we have already \ndiscussed how incom\u00adpleteness is being dealt with technically. Here we want to discuss the implications \non the programming model. The consequence of the incompleteness of a solver is that sometimes modules \nare unfairly rejected. The situations in which this can happen depend on the deduction algorithm of the \nsolver. Our resolution-based FP + solver, for example, is suspectible to the same programming patterns \nthat lead to non-termination in Prolog programs, such as left-recursion. For example, if the transitive \nhull of the subtyping relation in our Java binding would be speci.ed via a rule such as subtypeeq(A,C) \n. subtypeeq(A,B), subtypeeq(B,C). subtypeeq(A,B) . class(A,B). then the solver will return unknown whenever \nthis rule is used. Similarly, the backtracking algorithm may always backtrack to the wrong choice points, \nalthough another choice point would quickly lead to a successful answer. There are techniques to reduce \nthe number of situations where the solver loops (such as tabling, or left-recursion elimination), but \nthis does not change the fact that a user of our system has to encode his formulas in a way that is compatible \nwith the solver algorithm, if the solver is incom\u00adplete, for example by rewriting the two rules to remove \nthe left-recursion: subtypeeq(A, A) . class(A, S). subtypeeq(A, C) . class(A, B), subtypeeq(B, C). Our \nFP + implementation uses a depth-limit approach to avoid in.nite loops in the prover, which means that \nprograms of a certain complexity (i.e., requiring a proof of large depth) will be rejected even if they \nare correct. Our experience shows, however, that this is not a problem in practice, since most proofs \nhave small depth.  6.3.2 In.uence of the Representation Under a closed-world assumption, such as in \ntraditional LMP, the form of program representation is not very im\u00adportant, because different representations \ncan easily be com\u00adputed from each other. In our modular setting, however, the choice of representation \ndirectly in.uences which kinds of properties can be proven modularly, and which kinds of pro\u00adgram computations \ncan be expressed. We have already hinted at the question of open versus closed representation in Sec. \n2.3. In the program representa\u00adtion chosen in this paper, classes, methods, .elds, and con\u00adstructors \nwere represented openly in the form of predicates, whereas we chose a closed representation of method-and \nconstructor bodies as terms nested inside their respective method and constructor declaration. Open representations \nare extensible: It is possible to add new classes/methods/.elds/constructors without modifying any existing \nmodule code. Closed representations are not: It is not possible to add, say, another statement to a method \nbody without changing the method body representation. On the other hand, all properties that quantify \nover all entities of a kind (such as: all classes, all methods etc.) can\u00adnot be established modularly \nif these entities have an open representation. For example, with our open representation of methods it \nis not possible to check modularly that there is no ambiguous overloading of two methods. It is possi\u00adble \nto specify such constraints, and violations against these constraints are detected early (as soon as \ntwo modules are composed that violate the property), but these constraints will stay in the REQUIRES \npart of the composed module and they will only be proved during .nalization, when the solver switches \nto closed-world reasoning. This is not a problem when entities have a closed repre\u00adsentation. For instance, \nit can be established modularly, once and for all, that a method body is well-typed. Hence, the choice \nof the program representation is a tradeoff between extensibility and modularity. In Sec. 6.1.1 we have \nseen that dealing with names, name clashes, and lexical scoping properly also requires a care\u00adfully chosen \nprogram representation. The fact that formulas in a logic do not have an identity (e.g., if two modules \nprovide the same property then they are indistinguishable) has to be taken into account when encoding \nwell-formedness constraints related to name clashes or double de.nitions.  Finally, the design of the \ninformation hiding discipline (the F set) in.uences what kinds of well-formedness con\u00adstraints can be \nretroactively imposed on a module, since retroactive constraints (that are not anticipated by import\u00ading \nthe module containing the checks) can only operate on the interface of the module. We have seen that \nthis can be a limitation in the context of pluggable type systems.  6.3.3 Alignment with the Object \nLanguage As discussed in Sec. 3.5, it is the responsibility of the pro\u00adgrammer to make sure that the \nconstraints modeled into the system module are suf.cient to make sure that no well\u00adformedness errors \narise after code generation. If the well\u00adformedness constraints of an object language were available \nas a machine-readable speci.cation (rather than being bur\u00adried in a compiler or an informal language \nspeci.cation), then it might be possible to design a frontend for the lan\u00adguage the speci.cation is written \nin, such that the checks agree by construction with the speci.cation.  6.3.4 No Silver Bullet The fact \nthat program generators can seemingly be checked so easily once and for all may seem to be a bit suspicious. \nHowever, logic solvers are no silver bullet to the problem, and the fact that program generators can \nbe checked is not due to some black magic but due to a careful declaration of the requirements on the \ninput of the program generators. To illustrate this point, consider a method generator, which takes a \nmethod body B (or other statement) and pro\u00adduces a method that is equivalent to void execNtimes(int n) \n{ for (int i=0; i<n; i++) {B} } How could this generator be proved safe, once and for all? B might have \nopen variables that must be available in the context. B may declare itself a variable i or n which clash \nwith the loop variable or the method argument, respectively. B may itself not even be a well-typed statement. \nThe answer to this question is that the REQUIRES inter\u00adface of this code generator must be derived from \nthe de.ni\u00adtion of the typing rule of the for statement. For better read\u00adability, we will not use Prolog \nsyntax in the following, but standard type system notation. The (simpli.ed) typing rule for for loops \nwill typically be something like G . e : int G .{i : int}. c : bool G .{i : int}. b : void G . for (int \ni = e; c; i++) {b} : void and in FP + this typing rule would be encoded as a univer\u00adsally quanti.ed implication. \nObviously, in the speci.c ex\u00adample above, the body has to ful.ll the constraint C = {i : int,n : int}. \nB : void, hence the program generator will only be accepted by the system if C is demanded as a constraint \non the input of the program generator. Hence, in general, to prove program generators correct, one has \nto look at the proof tree that the solver will attempt to generate, check what the solver will try to \nprove about the input parameters, and add these properties to the REQUIRES interface of the program generator. \n7. Related Work Our work is related to three different areas of work: program generation, module systems \nand separate compilation, and logic programming. 7.1 Program Generation There is a wide spectrum of program \ngeneration and meta\u00adprogramming approaches, such as macros, C++ templates, meta-object protocols, open \ncompilers, or logic metapro\u00adgramming, the latter being the starting point of this work. Typically, these \napproaches are not modular, and checking only takes place on generated programs. Logic metapro\u00adgramming \nwas investigated in detail in the PhD theses of [14] and [39]. Despite its generality and expressiveness, \nthere have not been many follow-up works, although more recently several forms of logic metaprogramming \nhave be\u00adcome popular again as program query languages [18, 23, 34]. There are various approaches to make \ncertain forms of static metaprogramming safe [17, 19, 25 27]. CJ [26] offers statically safe conditional \ndeclarations. CTR [19] as well as safegen, MJ and MorphJ [25, 27, 28] offer forms of statically safe \niteration over, say, the methods of a class, which can then be used to generate various forms of wrappers. \nThese works are tailored towards a speci.c object language and a speci.c form of metaprogramming. Hence \nour work is not a competitor ; rather, our formal model provides a common foundation for these works \nin that it characterizes the relation between modular checking and expressiveness of the metalanguage. \nWe believe that each of these languages corresponds to a particular program representation, system module, \nand logic in our model. Our logic FP + is more expressive than any of these approaches, albeit at the \nprice of an undecidable solver. Staging [38], such as in MetaML or MetaOCaml, can also be seen as a form \nof statically safe program generation, but staging does not increase the expressiveness of the language; \nit is mainly a technique for program specialization.  7.2 Module Systems and Separate Compilation There \nis a large body of literature on module systems in both functional and object-oriented programming, but \nfew of these works deal with the problem of incorporating metapro\u00adgramming into the module system. The \nwork of Cardelli [8] was the .rst to formally inves\u00adtigate the issue of separate checking, and his formal \nmodel was an important inspiration for this work. In fact, this whole work started with the idea of what \nhappens if one revisits Cardelli s de.nitions and generalizes name-based imports/\u00adexports to arbitrary \nformulas in a logic. Sec. 6.1.1 makes this connection explicit.  Ancona et al. [1, 2] discuss the problems \nof modular checking, separate compilation and linking in the context of the Java programming language. \nIn order to cope with inter-module dependencies, they introduce a special kind of bytecode, called polymorphic \nbytecode, which can be used to infer constraints on possible linking contexts. This can be seen as an \ninterface which consists of formulas described in a non-trivial logic. Their approach is tailored to \nseparate checking of Java and hence complementary to our work. However, the idea to infer the requirements \nfrom the code rather than writing them down explicitly would also be in\u00adteresting in our setting. Many \nmodule or type systems allow some form of inter\u00adface parameterization, such as generics in Java, SML \nfunc\u00adtors, or typed .-calculi where types can be parameterized by types (higher-order types) or values \n(dependent types). In such languages, the matching process between required and provided interfaces also \ninvolves some form of infer\u00adence or, more generally, computation. However, these forms of parameterization \ndo typically not involve computations over rei.cations of programs, which is the main source of the expressive \npower of metaprogramming. The idea to express module consistency and compatibility by means of logic \nvalidity and consistency can also be found in other works on interface languages such as [10, 13, 20], \nbut none of these works deal with the problem of modular metaprogramming.  7.3 Logic and Logic Programming \nThere is a large amount of work on module systems for logic programming, such as the module system for \nProlog from [7], but all these approaches use predicate names and properties (such as arity, argument \ntypes, modes) as the basic building blocks of interface speci.cations, but not the logic itself as in \nour approach. Although module systems have been proposed for metaprogramming in logic [24, 29], these \napproaches are either based on names of language symbols (or declarations) and relations are usually \nexpressed as parametrization of declarations over names or signatures, or use features that modularize \nthe de.nition of predicates, but not of arbitrary logic formulas. In the context of logic meta programming, \nDe Volder et al. [16] propose a generic component model which is syntactically similar to our modules \nin that a component consists of a REQUIRES and PROVIDES interface together with an implementation, which \nis a list of clauses. In contrast to our framework, De Volder et al. s component model lacks support \nfor static checking of well-formedness and instead focuses on composition. Therefore, the approach can \nnot be compared to the framework developed in this paper. As described earlier, our logic FP + is a straightforward \nextension of (pure) Prolog with universally quanti.ed goals and implications as goals -techniques well-known \nfrom .Prolog [33]. Our treatment of inconsistency via a desig\u00adnated . constant is also standard [31]. \nIn our future work, we would like to explore the use of other logics, such as full .Prolog, as MDL in \nmore detail. For this work, our main goal in the design of FP + was to keep it as simple as possible, \nsuch that the description of this speci.c logic does not distract from our general module framework, \nwhich we consider the main contribution of this work. Institutions [22] are similar to our axiomatization \nof mod\u00adule description logics in that both are abstractions over a range of concrete logics. However, \nthe results in the liter\u00adature on institutions are mainly about the problem of com\u00adposing different logics, \nwhereas our work is about the com\u00adposition of modules that are formulated in the same logic. 8. Conclusions \nand Future Work We have shown that it is possible to tame the tiger: Ex\u00adpressive static metaprogramming \nvia LMP can be reconciled with separate checking. We have presented a formal frame\u00adwork which identi.es \nvery general conditions under which separate checking is sound, and have described the imple\u00admentation \nof a powerful metaprogramming system which has been designed according to the formal framework. Our future \nwork will concentrate on four areas: First, we want to explore the trade-off between openness and separate \nchecking in more detail. Second, we want to model existing safe metaprogramming systems such as those \ndescribed in the previous section in our work. We believe that the design of an MDL and program representation \nfor these approaches will give new insights into their expressiveness and makes it easier to compare \nsafe metaprogramming approaches. Third, we want to investigate a larger space of possible logics and \ntheir utility for metaprogramming, such as full .rst or higher-order logic. Fourth, we want to study \nthe relation between the expressiveness of type systems viewed as a logic (Curry-Howard isomorphism) \nand MDLs. References [1] D. Ancona, F. Damiani, S. Drossopoulou, and E. Zucca. Poly\u00admorphic bytecode: \nCompositional compilation for Java-like languages. In Proceedings of the 32th Symposium on Princi\u00adples \nof Programming Languages (POPL 05), New York, NY, USA, 2005. ACM Press. [2] D. Ancona, G. Lagorio, and \nE. Zucca. Flexible type-safe link\u00ading of components for Java-like languages. In Proceedings of the 7th \nJoint Modular Languages Conference (JMLC 06), volume 4228 of Lecture Notes in Computer Science, pages \n136 154, Berlin, Heidelberg, 2006. Springer Verlag. [3] Chris Andreae, James Noble, Shane Markstrum, \nand Todd Millstein. A framework for implementing pluggable type systems. In Proceedings of the 21st conference \non Object\u00ad  Oriented Programing, Systems, Languages, and Applications (OOPSLA 06), pages 57 74, New \nYork, NY, USA, 2006. ACM Press. [4] Don Batory. Feature models, grammars, and propositional formulas. \nIn Proceedings of the 9th International Software Product Line Conference (SPLC 05), volume 3714 of Lec\u00adture \nNotes in Computer Science, Berlin, Heidelberg, 2005. Springer Verlag. [5] David Benavides, Pablo Trinidad, \nand Antonio Ruiz-cort\u00b4es. Automated reasoning on feature models. In Proceedings of the 17th Conference \non Advanced Information Systems Engineer\u00ading (CAiSE 05), volume 3520 of Lecture Notes in Computer Science, \npages 491 503, Berlin, Heidelberg, 2005. Springer Verlag. [6] Gilad Bracha. Pluggable type systems, 2004. \nOOPSLA Workshop on Revival of Dynamic Languages. [7] Daniel Cabeza and Manuel Hermenegildo. A new module \nsys\u00adtem for Prolog. In Computational Logic (CL 2000), volume 1861 of Lecture Notes in Computer Science, \npages 131 148, Berlin, Heidelberg, 2000. Springer Verlag. [8] Luca Cardelli. Program fragments, linking, \nand modulariza\u00adtion. In Proceedings of the 24th ACM SIGPLAN-SIGACT symposium on Principles of Programming \nLanguages (POPL 97), pages 266 277, New York, 1997. ACM Press. [9] S. Ceri, G. Gottlob, and L. Tanca. \nWhat you always wanted to know about datalog (and never dared to ask). IEEE Trans\u00adactions on Knowledge \nand Data Engineering, 01(1):146 166, 1989. [10] Arindam Chakrabarti, Luca de Alfaro, Thomas A. Henzinger, \nMarcin Jurdzinski, and Freddy Y. C. Mang. Interface com\u00adpatibility checking for software modules. In \nProceedings of the 14th International Conference on Computer Aided Veri.\u00adcation (CAV 02), pages 428 441, \nBerlin, Heidelberg, 2002. Springer Verlag. [11] Shigeru Chiba. A metaobject protocol for C++. In Proceed\u00adings \nof the 10th conference on Object-Oriented Programing, Systems, Languages, and Applications (OOPSLA 95), \npages 285 299, New York, 1995. ACM Press. [12] Shigeru Chiba. Load-time structural re.ection in Java. \nIn Proceedings of the 14th European Conference on Object-Oriented Programming (ECOOP 00), volume 1850 \nof Lec\u00adture Notes in Computer Science, pages 313 336, Berlin, Hei\u00addelberg, 2000. Springer Verlag. [13] \nLuca de Alfaro and Thomas A. Henzinger. Interface au\u00adtomata. In Proceedings of the 8th European software \nengi\u00adneering conference held jointly with 9th ACM SIGSOFT inter\u00adnational symposium on Foundations of \nsoftware engineering (ESEC/FSE-9), pages 109 120, New York, USA, 2001. ACM Press. [14] Kris De Volder. \nType-Oriented Logic Meta Programming. PhD thesis, Vrije Universiteit Brussel, 1998. [15] Kris De Volder. \nImplementing design patterns as declarative code generators. http://www.cs.ubc.ca/~kdvolder/ publications/design_patterns-abstract.htm, \n2001. [16] Kris De Volder, Johan Fabry, and Roel Wuyts. Logic meta components as a generic component \nmodel. In Fifth In\u00ad ternational Workshop on Component-Oriented Programming, Workshop reader of ECOOP \n00, 2000. [17] Dirk Draheim, Christof Lutteroth, and Gerald Weber. A type system for re.ective program \ngenerators. In Proceedings of the 4th international conference on Generative programming and component \nengineering (GPCE 05), Lecture Notes in Computer Science, pages 327 341, Berlin, Heidelberg, 2005. Springer \nVerlag. [18] Michael Eichberg, Sven Kloppenburg, Karl Klose, and Mira Mezini. De.ning and continuous \nchecking of structural pro\u00adgram dependencies. In Proceedings of the 30th international conference on \nSoftware engineering (ICSE 08), pages 391 400, New York, NY, USA, 2008. ACM Press. [19] Manuel F\u00a8ahndrich, \nMichael Carbin, and James R. Larus. Re\u00ad.ective program generation with patterns. In Proceedings of the \n5th international conference on Generative program\u00adming and component engineering (GPCE 06), pages 275 \n284, New York, NY, USA, 2006. ACM Press. [20] Robert Bruce Findler, Mario Latendresse, and Matthias Felleisen. \nBehavioral contracts and behavioral subtyping. In Proceedings of the 8th European software engineering \nconfer\u00adence held jointly with 9th ACM SIGSOFT international sym\u00adposium on Foundations of software engineering \n(ESEC/FSE\u00ad9), pages 229 236, New York, NY, USA, 2001. ACM Press. [21] Erich Gamma, Richard Helm, Ralph \nJohnson, and John Vlis\u00adsides. Design Patterns. Addison-Wesley Professional, Indi\u00adanapolis, USA, January \n1995. [22] J.A. Goguen and R.M. Burstall. Introduction to institutions. In Logic of Programs, Workshop, \nCarnegie Mellon University, volume 164 of Lecture Notes in Computer Science, pages 221 256. Springer \nVerlag, 1983. [23] Elnar Hajiyev, Mathieu Verbaere, and Oege de Moor. Cod\u00adequest: Scalable source code \nqueries with datalog. In Pro\u00adceedings of the 20th European conference on Object oriented programming \n(ECOOP 06), volume 4067 of Lecture Notes in Computer Science, pages 2 27, Berlin, Heidelberg, 2006. Springer \nVerlag. [24] P. Hill. A module system for meta-programming. Logic Program Synthesis and Transformation \n Meta-Programming in Logic, 883:395 409, 1994. [25] Shan S. Huang and Yannis Smaragdakis. Expressive \nand safe static re.ection with MorphJ. In Proceedings of the 2008 ACM SIGPLAN conference on Programming \nlanguage design and implementation (PLDI 08), pages 79 89, New York, NY, USA, 2008. ACM Press. [26] Shan \nS. Huang, David Zook, and Yannis Smaragdakis. cJ: enhancing Java with safe type conditions. In Proceedings \nof the 6th international conference on Aspect-oriented software development (AOSD 07), pages 185 198, \nNew York, NY, USA, 2007. ACM Press. [27] Shan S. Huang, David Zook, and Yannis Smaragdakis. Mor\u00adphing: \nSafely Shaping a Class in the Image of Others. In Proceedings of the 21st European Conference on Object-Oriented \nProgramming (ECOOP 07), Berlin, Heidelberg, 2007. Springer Verlag.  [28] Shan Shan Huang, David Zook, \nand Yannis Smaragdakis. Statically safe program generation with safegen. In Proceed\u00adings of the 4th international \nconference on Generative pro\u00adgramming and component engineering (GPCE 05), Lecture Notes in Computer \nScience, pages 309 326. Springer Verlag, 2005. [29] Evelina Lamma and Paola Mello. Modularity in logic \npro\u00adgramming. In Proceedings of the eleventh international con\u00adference on Logic programming, pages 15 \n17, Cambridge, MA, USA, 1994. MIT Press. [30] Kim Mens, Isabel Michiels, and Roel Wuyts. Supporting soft\u00adware \ndevelopment through declaratively codi.ed program\u00adming patterns. In Journal on Expert Systems with Applica\u00adtions, \npages 236 243, New York, NY, USA, 2001. Elsevier Science Inc. [31] Dale Miller. A logical analysis of \nmodules in logic program\u00adming. J. Log. Program., 6(1-2):79 108, 1989. [32] Gopalan Nadathur, Bharat Jayaraman, \nand Keehang Kwon. Scoping constructs in logic programming: Implementation problems and their solutions. \nJ. Log. Program., 25(2):119 161, 1995. [33] Gopalan Nadathur and Dale Miller. An overview of .Prolog. \nIn Proceedings of the Fifth International Logic Programming Conference, pages 810 827, Cambridge, MA, \nUSA, 1988. MIT Press. [34] Klaus Ostermann, Mira Mezini, and Christoph Bockisch. Ex\u00adpressive pointcuts \nfor increased modularity. In Proceedings of the 19th European Conference on Object-Oriented Pro\u00adgramming \n(ECOOP 05), volume 3586 of Lecture Notes in Computer Science, pages 214 240, Berlin, Heidelberg, 2005. \nSpringer Verlag. [35] D. L. Parnas. On the criteria to be used in decompos\u00ading systems into modules. \nCommunications of the ACM, 15(12):1053 1058, December 1972. [36] Raymond Reiter. On closed world databases. \nIn Logic and Databases, pages 55 76, New York, NY, USA, 1978. Plenum Press. [37] Ehud Shapiro and Leon \nSterling. The Art of PROLOG: Ad\u00advanced Programming Techniques. The MIT Press, Cam\u00adbridge, MA, USA, April \n1994. [38] Walid Taha and Tim Sheard. Multi-stage programming with explicit annotations. In Proceedings \nof the 1997 symposium on Partial Evaluation and semantics-based Program Manip\u00adulation (PEPM 97), pages \n203 217, New York, USA, 1997. ACM Press. [39] Roel Wuyts. A Logic Meta Programming Approach to Support \nthe Co-Evolution of Object-Oriented Design and Implementa\u00adtion. PhD thesis, Vrije Universiteit Brussel, \n2001. APPENDIX A. Proofs We will need the following lemmas for the proofs: LEMMA 22 (Monotonicity of \nifc). If ifc(F ) and F . . F , then ifc(F .). Proof. Assume that ifc(F ) and \u00acifc(F .), i.e., (.I .F \n) F .. I ... By monotonicity of . it follows that F . I .. and therefore \u00acifc(F ), which is a contradiction. \nLEMMA 23. . is an equivalence relation. Proof. We have to show: Re.exivity Since R1 = R2, we have to \nshow that P . R . R, which follows from the monotonicity of .. Symmetry The de.nition of . is symmetric. \nTransitivity Both = and . are transitive. LEMMA 24. .k . N, M, M. (M .k M. . M . M.) Proof. The case \nk =0 is trivial. To prove k =1 we assume that (R, I, P ) . (R \\{f},I,P ). Now we have to prove that R \n. P . R \\{f}, which follows from 1.4 and 1.3, and R\\{f}.P . R, which is true, because R \\{f}. R \\{f} \nand P .{f}. The case k> 1 follows from Lemma 23 (transitivity of .).     A.1 Theorem 7 Proof. Let \nI = .i.{1,...,n}Ii be the implementation and P = .i.{1,...,n}Pi the PROVIDES part of the composed module. \nBy 5.10, we can split I into two disjunct sets I = I. .P ., where I. .F and P . . P . Because all modules \nare compatible, we have ifc(P ) and by Lem. 22 we get ifc(P .), which means that P . is consistent together \nwith arbitrary implementation formulas, and in particular it is consistent with I.. From this follows \nthat I .. .. A.2 Lemma 9 Proof. By de.nition of ., M. is valid. If M. were inconsis\u00adtent, then M would \nhave been inconsistent, too, by Lemma 22. But M is consistent by assumption, hence M. must be consistent. \n A.3 Theorem 12 Proof. Let M =(R1 . R2,I1 . I2,P1 . P2). Since M. and M.. are minimal reductions of M, \nwe have M .k M. and M .l M... By Lemma 24 it follows that M . M. and M . M.. and by transitivity and \nsymmetry of . we have M. . M.. .  A.4 Theorem 14 Proof. Let Mi =(Ri,Ii,Pi) for i =1, 2. Let M = (R1 \n. R2,I1 . I2,P1 . P2) as in the .rst step in Def. 10. Then M is valid because for each f . P1 . P2 we \nhave R1 . R2 . I1 . I2 . f by the validity of M1 and M2 and the monotonicity of . (Def.1.3). (R.,I.,P \n.)=(R.,I1 . I2,P1 . P2)= M1 .s M2. M is also consistent because ifc(R1.R2.P1.P2) by M1\u00f7M2. By Lemma 9 \nconsistency is preserved in every reduction step, hence M1 .s M2 must also be consistent.  A.5 Theorem \n15 Proof. Let Mi =(Ri,Ii,Pi) for i .{1, 2, 3} and M1 .s M2 =(R, I, P ). By Def. 8 and 10, P = P1 . P2 \nand R . R1 . R2. The theorem now follows by Def. 6 and Lemma 22. A.6 Theorem 16 Proof. Let (Mi)1=i=3 \n=(Ri,Ii,Pi), then (M1.sM2) .s M3 . (I1 . I2,R1 . R2,P1 . P2) .s M3 . (I1 . I2 . I3,R1 . R2 . R3,P1 . \nP2 . P3) . M1 . (I2 . I3,R2 . R3,P2 . P3) . M1 .s (M2 .s M3)  A.7 Theorem 17 Proof. By induction on \nn. The base case n =1 is trivial, the case n =2 is covered by Thm. 14. For the inductive case .s n = \n3, let M = Mi. By induction hypothesis we 1=i=n-1 know module-ok(M). By applying Thm. 15 n - 2 times, \nwe get M \u00f7Mn. Now the theorem follows by applying Thm. 14 to M and Mn. A.8 Theorem 20 Proof. We prove \nthe parts of the theorem in the order as stated. A reduction step removes exactly one formula from the \nREQUIRES set of the module, and the REQUIRES set is .nite.  Follows by Thm. 17.  .s From Thm. 12 we \nknow that M. = Mi . 1=i=n .s. Mi = M... By transitivity of . we know that 1=i=n M . . M.. and by the \nde.nition of ., their implemen\u00adtation and PROVIDES part are equal. Thus, the only way it could happen \nthat Final(M.) . = Final(M..) is when one .nalization fails while the other succeeds. But be\u00adcause M. \n. M.., there is no requirement formula, that can be proved for one module but not for the other. The \nimplementation part of M is the union of the im\u00adplementation parts of the modules M1,...,Mn and thus \nconsistent by Thm. 7. .CW If M is valid, and MM. then M. is valid by min de.nition of .min, that is, \nR . I . P . By the de.nition of Final, M. has the form (\u00d8,I,P ), thus I . P .  A.9 Theorem 21 Before \nproving the theorem, we have to de.ne T . DEFINITION 25. ll . L T (l)= true l . L T ((.v) f)=(.v)T (f) \nT ((.v) f)=(.v)T (f) T (l . l1,...,ln)= T (l) . T (l1),...,T (ln) T ({l1,...,ln})= {T (l1),...,T (ln)} \nProof. Let G be arbitrary but .xed. . Assume that .F .F P + such that G.F ... We observe that a proof \nof . does not include proofs of implications. Thus, the proof tree contains only substitutions of literals \nby bodies of matching clauses, eliminations of existential quanti.cation and substitution of constants \nfor universally quanti.ed variables. By replacing every node of the tree that contains implementation \nliteral with true and removing their subtrees, we end up with another valid proof tree. All the substitutions \nof clause bodies that are in the tree can be done using formulas from T (G), which means that the modi.ed \ntree is a proof tree for . in T (G), and thus T (G) ... . Assume that T (G) ... We can choose F = L \n, for which G . F .., because all implementation literals that can be used in the proof are true.  \n \n\t\t\t", "proc_id": "1869459", "abstract": "<p>In logic metaprogramming, programs are not stored as plain textfiles but rather derived from a deductive database. While the benefits of this approach for metaprogramming are obvious, its incompatibility with separate checking limits its applicability to large-scale projects. We analyze the problems inhibiting separate checking and propose a class of logics that reconcile logic metaprogramming and separate checking. We have formalized the resulting module system and have proven the soundness of separate checking. We validate its feasibility by presenting the design and implementation of a specific logic that is able to express many metaprogramming examples from the literature.</p>", "authors": [{"name": "Karl Klose", "author_profile_id": "81418595356", "affiliation": "Aarhus University, Aarhus, Denmark", "person_id": "P2354094", "email_address": "", "orcid_id": ""}, {"name": "Klaus Ostermann", "author_profile_id": "81100028971", "affiliation": "University of Marburg, Marburg, Germany", "person_id": "P2354095", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869499", "year": "2010", "article_id": "1869499", "conference": "OOPSLA", "title": "Modular logic metaprogramming", "url": "http://dl.acm.org/citation.cfm?id=1869499"}