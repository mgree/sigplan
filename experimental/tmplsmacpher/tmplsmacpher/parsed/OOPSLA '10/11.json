{"article_publication_date": "10-17-2010", "fulltext": "\n From OO to FPGA: Fitting Round Objects into Square Hardware? Stephen Kou Jens Palsberg UCLA Computer \nScience Department University of California, Los Angeles Abstract Consumer electronics today such as \ncell phones often have one or more low-power FPGAs to assist with energy\u00adintensive operations in order \nto reduce overall energy con\u00adsumption and increase battery life. However, current tech\u00adniques for programming \nFPGAs require people to be spe\u00adcially trained to do so. Ideally, software engineers can more readily \ntake advantage of the bene.ts FPGAs offer by be\u00ading able to program them using their existing skills, \na com\u00admon one being object-oriented programming. However, tra\u00additional techniques for compiling object-oriented \nlanguages are at odds with today s FPGA tools, which support nei\u00adther pointers nor complex data structures. \nOpen until now is the problem of compiling an object-oriented language to an FPGA in a way that harnesses \nthis potential for huge en\u00adergy savings. In this paper, we present a new compilation technique that feeds \ninto an existing FPGA tool chain and produces FPGAs with up to almost an order of magnitude in energy \nsavings compared to a low-power microproces\u00adsor while still retaining comparable performance and area \nusage. Categories and Subject Descriptors D.3 Programming Languages [Processors]: Compilers General Terms \nDesign, Experimentation, Languages, Mea\u00adsurement, Performance Keywords Objects, FGPAs 1. Introduction \nField-programmable gate arrays (FPGAs) offer a middle point between application-speci.c integrated circuits \n(ASICs) and central processing units (CPUs). ASICs have the lowest power consumption but also the lowest \n.exibility: they can Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. OOPSLA/SPLASH 10, October 17 21, 2010, Reno/Tahoe, Nevada, USA. Copyright c &#38;#169; \n2010 ACM 978-1-4503-0203-6/10/10. . . $10.00 be used for only one purpose. FPGAs, on the other hand, \ntypically exhibit at least an order of magnitude more power consumption than ASICs [10], but they also \nprovide greater .exibility: they can be programmed and reprogrammed. Tra\u00additionally, mobile consumer \nelectronics such as cell phones have used ASICs to help increase battery life time by of\u00ad.oading the \nmore energy or computationally-intensive oper\u00adations from the CPU to the ASIC/FPGA. However, during the \npast decade, consumer electronics have increasingly used FPGAs to allow, for example, easy adaptation \nto the many cell phone standards worldwide [1]. Furthermore, the repro\u00adgrammability of the FPGA also \nmakes it an ideal choice for hardware that needs to be upgraded or modi.ed often. Currently, the bene.ts \nthat FPGAs offer come at a price. While CPUs are simple to program and languages made to program CPUs \nare generally high-level and easy to learn, ASICs and FPGAs can only be programmed by those spe\u00adcially \ntrained to use the tools and languages developed speci.cally for designing digital circuits. FPGA designers \ntypically use a hardware description language (HDL) such as VHDL [13] or Verilog [2] to de.ne the behavior \nof the FPGA. Although recent developments have raised the level of abstraction by allowing HDL designs \nto be constructed from programs written in C, the barrier of entry can be re\u00adduced even more by enabling \nsoftware engineers to start at an even higher level of abstraction and program FPGAs in a paradigm familiar \nto many object-oriented programming. The nascent boom in FPGA use further presses the question of how \nthis can be accomplished. Some work has been done to approach this problem. For example, Huang, Hormati, \nBacon, and Rabbah [7] have de\u00adsigned a new object-oriented language aimed to target both CPUs and FPGAs. \nA DES encryption benchmark, when written in this language, generated an FPGA design that exe\u00adcuted fourteen \ntimes slower than the same code running on a CPU. However, their project did not consider energy usage; \nbut we note that since energy = (power \u00d7 time), longer run\u00adning times decrease the energy advantage that \nFPGAs offer. Schoeberl [15] presented an implementation of a Java vir\u00adtual machine in which bytecode \nwas executed by an FPGA; however, he did not compare the performance between the FPGAs and CPUs.  Let \nus note that compiling an object-oriented language to an FPGA is different from specifying a hardware \ndesign in C++ using an embedded domain-speci.c language, as is done by Mencer, Platner, Morf, Flynn [12]. \nOur approach is different from previous attempts; we wish to take an existing object-oriented language \nthat was designed without FPGAs in mind and compile programs written in this language to C programs, \nwhich can be passed through an existing tool that converts C programs to HDL designs, which can then \nbe synthesized on an FPGA. In par\u00adticular, we want to compile bare object-oriented programs; that is, \nobject-oriented programs that are written in the usual syntax without any form of special annotations \nor pragmas to help the compiler. We want to do this in a way that real\u00adizes a large part of the energy \nsavings that is possible on an FPGA compared to a CPU, while still attaining comparable performance and \narea usage. At .rst, it seems straightforward to approach our goal: .rst compile an object-oriented language \nto C, and then let the tool chain from C to FPGAs take over. However, tra\u00additional techniques for compiling \nobject-oriented languages are at odds with today s FPGA tools that don t support point\u00aders and complex \ndata structures. Open until now is the prob\u00adlem of compiling an object-oriented language to an FPGA in \na way that realizes some of the huge potential for energy savings. Challenge: compile a bare object-oriented \nprogram to an FPGA with signi.cant energy savings compared to a CPU, while still maintaining acceptable \nperfor\u00admance and space usage. As the starting point for our investigation, we chose the Virgil programming \nlanguage and the AutoPilot tool for mapping from C to FPGAs. In this paper, we present a new compilation \ntechnique that compiles unmodi.ed, bare Virgil programs in a way that AutoPilot can successfully produce \nHDL designs meant for synthesis on FPGAs. Titzer [16] designed Virgil with the purpose of program\u00adming \nembedded systems and device drivers within small memory. Virgil is a strongly-typed, object-oriented \nlanguage akin to Java and C#. Virgil has several features that makes it an ideal language for our project. \nIn particular, Virgil di\u00advides computation into two phases initialization and ex\u00adecution; the initialization \nphase involves the compiler inter\u00adpreting, starting with the components which contain entry point methods, \nthe constructors in the program. Each con\u00adstructor may allocate additional memory via the new expres\u00adsion, \nwhich results in an additional constructor call. Memory allocation and the use of new expressions to \ncreate objects and arrays are complementarily limited to constructors only. The compiler, upon completion \nof the initialization phase, has a view of the entire heap of the program and can then rep\u00adresent the \ngenerated objects and arrays in an ef.cient man\u00adner. Titzer, Auerbach, Bacon, and Palsberg [17] have \nalso explored the possibility of doing this on a full-.edged Java virtual machine. The .nal execution \nof the program, whether on an FPGA or a CPU, constitutes the execution phase. The company AutoESL, Inc. \n(http://www.autoesl.com) created the AutoPilot tool for converting a subset of C into various hardware \ndescription languages for synthesis onto an FPGA chip. AutoPilot is a commercialization of the ex\u00adperimental \nxPilot system developed by Cong et al. [5, 19], and is more robust, stable, and reliable than xPilot. \nAutoPilot uses LLVM [11] as its frontend and then outputs a hardware design in several hardware description \nlanguages, namely VHDL, Verilog, and SystemC [3]. After further optimiza\u00adtion for a speci.c FPGA brand \nand model, the output can be directly imported into the FPGA manufacturer s own synthe\u00adsis and layout \ntool, which will do the .nal HDL compilation, synthesis, routing, and other FPGA-speci.c layout tasks, \naf\u00adter which the design can be downloaded into the FPGA and executed. AutoPilot s subset of C excludes \nfunction pointers, and places severe limitations on regular pointers, struct casting, and the contents \nof structs. These limitations rule out the traditional way of representing objects as virtual method \ntables cannot be used (as there are no function pointers), and structs cannot be used (as there is no \nsupport for casting). Our compilation technique successfully translates bare, recursion-free Virgil programs \nto the subset of C that Au\u00adtoPilot accepts. We build on Titzer and Palsberg s notion of vertical object \nlayout [18], and we use the idea of using type case to compile virtual method dispatch without use of \nfunc\u00adtion pointers [4]. On top of that, we introduce two new tech\u00adniques: grouped arrays that overcome \nthe other limitations of AutoPilot, and the hybrid object layout scheme for com\u00adpression of object tables. \nOur implementation, essentially, is: OO to FPGA = typecase for method dispatch + grouped arrays + hybrid \nobject layout. Our approach produces HDL designs that, when executed on an FPGA, exhibit up to almost \nan order of magnitude in energy savings over a low-power microprocessor, and with decent performance \nand competitive area usage compared with HDL designs written directly in C. The structure of the rest \nthis paper is as follows: in the next section, we take a closer look at AutoPilot s subset of C and the \nmotivation behind our approach. Sections 3 5 detail how we compile objects, arrays, and methods, respectively. \nIn Section 6 we discuss further optimizations, and in Section 7 we give our experimental results. 2. \nAn FPGA-oriented subset of C AutoPilot places several limitations on the extent of C s fea\u00adtures that \nare supported that dramatically change the way ob\u00adject references and array references are compiled, \nas well as requiring a completely different approach to handling virtual method dispatch. The way that \nwe implement these three form the core of our compilation technique. Traditionally, all three areas have \nbeen solved by using scalar and function pointers. We will show that usage of pointers in AutoPilot is \nsigni.cantly hampered and, as a result, we cannot use them at all. Thus, the driving force behind our \napproach is to rep\u00adresent references and virtual methods without using pointers of any kind.  This section \nreviews the traditional methods of compiling objects, arrays, and references to the C programming lan\u00adguage, \nand how the restrictions imposed by AutoPilot make these approaches infeasible. 2.1 Memory Model The \ncrux of the problem lies in the fundamental difference of the memory architecture of an FPGA versus that \nfound on CPUs. The hallmark of the FPGA memory model which separates it from that of the CPU is that \nthe memory require\u00adments must be known beforehand; the amount of memory al\u00adlotted to a design is precisely \nthe amount of memory that the design requires; no more is given than requested. Further\u00admore, this memory \nis fragmented into many subunits, into which data is distributed and stored. This is in stark contrast \nto that of CPU-based computers, where memory is a single vast, allocatable, and addressable area that \ncan be managed by the application itself; additional memory can be requested during execution. Because \nof this difference in design philosophies, a pro\u00adgram fed through AutoPilot cannot utilize dynamic mem\u00adory \nallocation; i.e. calls to malloc and free. The reason behind this is twofold: primarily, as stated before, \nFPGAs themselves limit the amount of memory available to the syn\u00adthesized design. ROMs and RAMs are allocated \non an as\u00adneeded basis during the design and synthesis phase; addi\u00adtional memory blocks cannot be requested \nduring runtime. Also, dynamic memory allocation and other managed mem\u00adory models generally have a negative \nimpact on performance and therefore are not ideal for hardware programming. As a result, AutoPilot is \nstrongly suited for programs that have statically known memory requirements. Virgil is an ideal programming \nlanguage to target AutoPilot because all Virgil programs have this exact property. The initialization \nphase explained earlier allows the Virgil compiler to know the memory footprint of the program in its \nentirety. We encode this memory footprint in an way that works with AutoPilot, and emit C code for the \nrest of the program.  2.2 C Pointers A language construct in C that is inseparably linked to the memory \nmodel of the underlying platform is the pointer. Au\u00adtoPilot performs a series of transformations on the \nprogram itself that eventually removes all pointers from the program. It relies heavily on various static \nanalysis techniques in order to accomplish the illusion of pointers that it offers the pro\u00adgrammer. However, \ndynamic pointers, or pointers that are re-assigned to point to different data during runtime, have always \nrepresented a challenging static analysis task; it is very dif.cult to determine to which data various \npointers will point to at various points during execution if they are passed around and re-assigned. \nBecause of this dif.culty, there are several quite hefty restrictions placed on pointers by AutoPi\u00adlot. \nThe transformation away of pointers is a necessary step taken by AutoPilot because pointers, in their \ntraditional sense, cannot be easily implemented on FPGAs for architec\u00adtural reasons. On-chip FPGA memory \nis not a single, large, addressable memory space like those on computers. Instead, the memory space is \nfragmented into many small blocks . These blocks, called BRAMs in standard FPGA terminol\u00adogy, each have \ntheir own input/output pins, which allow for parallel reads and writes over multiple blocks. This memory \narchitecture, while good for performance, is the reason why pointers are so hard to emulate on FPGAs. \nThis is compounded by the fact that each memory block has its own address space; when a pointer pointing \nto data residing on one block is re-assigned to data residing on an\u00adother block, AutoPilot must be able \nto determine the correct block that holds the new data. The hardware design explic\u00aditly re.ects this, \nas there must be a connection made in the form of a bus between the entity and the memory blocks to which \nit accesses. It is AutoPilot s job, then, to deter\u00admine statically to which data each pointer points \nand route the electrical signals to the correct block when dereferenced. Pointer arithmetic, too, must \nalso be transformed away and converted to direct data accesses as well. Therefore, pointers that are \ndynamically re-assigned or those whose data cannot be determined statically are not supported in AutoPilot. \nThe end product of this operation is a program that is left without pointers at all. Any use of pointers \nthat cannot produce this end state cannot be handled by AutoPilot. structs are also limited in this fashion; \nthey cannot contain pointers. 2.2.1 Function pointers The standard execution model on a computer involves \nexe\u00adcution of instructions stored in the main memory. Each in\u00adstruction has a corresponding address; \nmoving between ar\u00adeas of code is accomplished using jumps to different ad\u00addresses. Calling a function \ninvolves .rst copying arguments onto the stack then transferring execution to the address of the .rst \ninstruction of the function. AutoPilot takes a completely different approach to con\u00adverting functions \nonto an FPGA. Each C function in the pro\u00adgram is converted into a design entity, a language construct \npresent in all HDLs that provides a level of abstraction. Like functions, which group together code and \nprovide a black\u00adbox interface, entities also group together circuitry and logic and provide a black-box \ninterface in the form of input and output pins. Copies of the entity, called instances, can be  class \nA { class B extends A { class C { field child : A; field other: C; field a : int; field value : int; \nfield b : int; method bar() : void method foo() : void { } method f() : void { } { } method arg() : void \n} method bar() : void { } { } } } Figure 1. A set of classes written in Virgil. placed onto the chip, \neach occupying a certain amount of area. An HDL design consists of an interconnected network of entity \ninstances. Unlike functions on a computer, any function call ren\u00addered in this scheme requires a direct, \nphysical connection of wires between the caller instance and the callee instance. If AutoPilot cannot \ndetermine the entity instance to which a call is made, it cannot handle that function call. This is apparent \nin the case of function pointers. If a AutoPilot can\u00adnot determine during compilation which function \na function pointer is pointing to, it is unable to create the necessary connections that implement the \ncall. In fact, AutoPilot at this time has no support for function pointers, even those that can be statically \nreasoned about. This limitation creates substantial problems for the way the semantics of virtual methods \nare implemented. The tra\u00additional technique of handling virtual dispatch is the use of virtual method \ntables. Virtual method tables are lists of func\u00adtion pointers that point to the correct function to be \ncalled when a virtual method is invoked. The cell representing the virtual method is read, and the address \nstored within is then jumped to and executed. Because of the dependence of this approach upon the function \npointer, we are forced to use a different mechanism to accomplish similar functionality and semantics. \n  2.3 Functions and Recursion As stated earlier, each function is converted into design entities, of \nwhich instances are created; wires linking in\u00adstances together re.ect calls between different entities. \nThis paradigm for representing functions precludes the need for stack frames to be set up in memory; \nhere, the closest con\u00adcept of a stack is the area available on the FPGA chip. FPGA tools are able to \nminimize the number of instances needed of each entity by allowing reuse of instances. As long as the \ninstance is used only by one call at a time, the instance may be used over and over again. However, there \nare scenarios where the instance cannot be reused, such as parallel calls to the same entity. The general \nsolution for these scenarios is to place another copy of the entity on the chip, thereby resulting in \ntwo instances of the same entity allowing for two simultaneous calls. Of course, this then leaves less \nremaining free area on the FPGA chip for other logic. One signi.cant case where this approach fails, \nhowever, is in the case of general recursion. Because the entity then needs to call itself, the existing \ninstance is not reusable. This creates an irreconcilable case for AutoPilot: because it cannot conclude \nhow many times the recursive call will be performed, it then assumes an in.nite number of instances would \nbe needed. However; the area on a chip is far from in.nite, and thus AutoPilot rejects the input program. \nThe design of Virgil, however, allows recursion; we do not at\u00adtempt to resolve this problem in this paper. \nWhile it is pos\u00adsible in some cases to eliminate recursion through program transformations, it is beyond \nthe scope of this paper and thus is relegated to future work. Other than recursion, however, functions \nare fully supported in AutoPilot s subset of C. 3. Objects We now turn to presenting our approach to \ncompiling Vir\u00adgil. Our chief concern is the representation of objects and object references. The representation \nmethod is particularly important in the case of Virgil because, like Java, program\u00admers must use the \nobject-oriented paradigm. Objects are in\u00adstances of classes declared in Virgil and are allocated and \nin\u00adstantiated in the constructors. Object references are pointer\u00adlike constructs that provide a level \nof indirection to objects; like Java, all manipulations done with objects in Virgil are through the use \nof references. Object references are passed, by value, to methods; object references are used in all \nlo\u00adcal variables, arrays, and .elds which are typed as being an object instance. Virgil classes are relatively \nsimple compared to their counterparts in Java, C#, or C++. Fields and methods can only be marked as public \nor private, while all classes can only be public. Static .elds and methods are not supported, but the \nfunctionality is present via the use of singleton components. All classes are single-inheritance with \nmeth\u00adods being virtual by default; interfaces and abstract methods are not supported. Another important \ndistinction between Java s and Virgil s class semantics is that not all of the classes in Virgil ultimately \ninherit from a common Object class as they do in Java. Instead, a program can consist of a set of disjoint \nclass hierarchies, each with its own unique root class. To illustrate this, a small set of classes have \nbeen declared in Virgil syntax in Figure 1. We have described two distinct class families: that of A \nand B, and a single-member family C. Because the two do not ultimately inherit from a common type, they \nare wholly independent of each other.  The next few sections will build examples off of this sample \nclass hierarchy. To give a quick summary of the way these classes are structured: both the .elds child \nin A and other in B are references to other objects. Polymorphism rules allow the recursive child .eld \nin A to refer to either an instance A or an instance of B. Two methods are de.ned in A: foo and bar. \nB provides an overridden implementation for bar, but not foo; it also adds another method arg. With this \nin mind, in the following sections we discuss and review various object layout strategies, culminating \nwith the representation we use in our compiler that tries to mini\u00admize space while at the same time attempting \nto incur a min\u00adimal amount of performance overhead on an FPGA. 3.1 Horizontal Object Layout We term the \ntraditional method of compiling objects to C as the horizontal object layout . It is the most straightfor\u00adward \napproach to representing objects using C language con\u00adstructs, and is considered well-known; thus, we \nwill simply provide a cursory review of this approach. The horizontal ob\u00adject model converts each class \ninto a struct; the struct is composed of, in this order: (1) a pointer to a virtual method table, (2) \nthe .elds of the parent class, and (3) the .elds de\u00ad.ned in the class itself. As a result, each class \nstruct in\u00adclude its parent class struct as a pre.x. In this scheme, references to objects are rendered \nas pointers which point to instances of the struct. Polymor\u00adphism is accomplished by exploiting the property \nstated ear\u00adlier that the in-memory layout of a child class is compatible with that of its parent; a pointer \ntyped as the struct of the child class can be casted to a pointer typed as pointing to an instance of \nthe parent class struct; all accesses to the .elds and entries in the virtual method table would be compatible. \nA type cast is implemented in a similar fash\u00adion: a pointer typed as pointing to an instance of the parent \nstruct may in reality be pointing to an instance of the child struct; thus, a cast can be performed in \nthe C code on the pointer itself to cast it back to a reference of the child class. Figure 2 illustrates \nhow one instance of A, one instance of B, and one instance of C from our example class hierarchy would \nbe laid out in memory using the horizontal object model. The .eld called vmt is a pointer to the virtual \nmethod table, which contains the collection of function pointers that refer to the virtual methods. A \n.eld access is easily translated using the horizontal object model. We show a translation of a small \nVirgil method to C in the following code snippet. It Figure 2. Memory layout of A, B, and C in the Horizontal \nObject Model. is a simple dereference of the object pointer, coupled with a .eld access: method f(obj \n: A) : int { return obj.value; } int f(struct A* obj) { return obj->value; } Although this is the most \nstraightforward way to repre\u00adsent objects on a computer, it uses pointers profusely to ac\u00adcomplish the \nvarious traits required for inheritance and poly\u00admorphism. This object representation breaks down when \nAutoPilot is involved in a number of ways: function pointers like the ones used in virtual method tables \nare not allowed, structs containing pointers are prohibited, and the casting of structs, done here to \naccomplish subtype polymorphism and type casting, cannot be used. It is therefore clear that we cannot \nuse this form of object representation when targeting AutoPilot.  3.2 Vertical Object Layout The .rst \nstep forward is to .rst remove the necessity of the pointer in the representation of an object reference. \nA strategy that accomplishes this goal, and the basis for our approach, is the vertical object layout \n[18]. We work here with the concept of the uncompressed vertical object model, which omits the compression \nscheme performed in Titzer s work. The vertical object layout re-organizes all of the objects in a program \ninto a large table, where the rows are the class .elds, and the columns are the individual objects. There \nis thus one row for every .eld de.ned in the program. The virtual method table is also encoded as rows; \none row for every virtual method de.ned. Therefore, an object in this model is a single column across \nall the rows. References to objects, then, do not use pointers a reference is an integer that refers \nto the column index in the table where the values reside. Instead of pointers, this integer is used anywhere \nthat an object reference is expected. A .eld lookup using the uncompressed vertical object is shown in \nthe code snippet below. We show a translation of a small method into C:  method f(obj : A) : int { return \nobj.value; } int f(int obj) { return Row_A_Value[obj]; } The emitted C code is achieved from the following \nsteps: 1. Given the .eld, the compiler determines the correct row to access in the object table: Row \nA Value. 2. The row is accessed given the object identi.er: obj. 3. The .eld is accessed by indexing \ninto the .eld array.  Fields are no longer grouped into structs to re.ect how they were declared in \nclasses; instead, the vertical object model .attens the structure of the program from a set of classes \nto instead a set of .elds. Field accesses and encapsu\u00adlation are instead guaranteed by the Virgil type-checker, \nand such traits of the program are not re.ected in the C code. Because of this property of the vertical \nobject model, both polymorphism and casting are trivial and require no special treatment. No type information \nis retained in the C code, as all object references are now an int. Figure 3 illustrates how the vertical \nobject model would lay out 2 instances of A, two instances of B, and one instance of C from our example \nclass hierarchy shown earlier. The virtual method table s entries are also rendered as rows in the object \ntable; they are typed as arrays of function pointers. An obvious drawback of the uncompressed vertical \nobject model is the amount of wasted memory incurred when ren\u00addering the object table. All the crossed \nboxes in the .gure are cells present in the table, but are unused. For example, an instance of A gets \nallocated all the memory needed for the .elds of B and C as well. Therefore, as larger programs are created \nwith more complex object hierarchies, the amount of wasted memory will grow. This design choice allows \nfaster lookups and simpler object reference representation, at the expense of an increased memory footprint. \nNevertheless, the vertical object model solves one of the major obstacles presented in the previous section \nto repre\u00adsenting objects in FPGAs and AutoPilot: it allows us to cre\u00adate references to objects without \npointers. However, the ver-Figure 3. A visualization of the in-memory layout of the uncompressed vertical \nobject model. tical object model alone is not enough to satisfy all the limits of AutoPilot: it still \nemploys function pointers to implement virtual dispatch, and the amount of wasted memory is not ideal \nfor hardware, where increased area directly translates to increased costs. In the next sections, we address \nboth of these issues by modifying the uncompressed vertical object model.  3.3 Space minimization The \nvertical object model employs a compression scheme which we do not explore in this paper. Instead, we \npresent a compression scheme which .ts well with the unique archi\u00adtectural properties of FPGAs. Our aim \nis to compress the object table while still .nding a way to represent an object reference that retains \nthe sim\u00adplicity of the vertical object model. To accomplish this, we totally restructure both the object \ntable and the object refer\u00adence. The section describes this approach. 3.3.1 The object table While we \nretain the concept of the object table from the vertical object model, we restructure it in such a way \nthe leaves no wasted space. Originally, every object in the object table shown in Figure 3 was the same \nsize in memory each object occupied an entire column. By compressing the object table and removing the \nunused cells, as shown in .gure 4, the unused space is gone, but objects are now no longer at a single \nindex. For example, the third column in the table, an instance of B, occupies the third cell in the row \nfor A, but occupies the .rst cell in the row for B. Such an  Figure 4. The hybrid object layout s object \ntable format. object table requires us to store offset information for the different rows. One approach \nis to introduce another table, which maps single integers to a collection of offsets. This scheme would \npreserve the single-integer property of the vertical object model, while allowing us to remove the wasted \nspace. How\u00adever, this would have adverse effects on performance. A .eld lookup in this scheme would entail \nthe following steps: method f(obj : A) : int { return obj.value; } int f(int obj) { return Row_A_value[Objects[obj][1]]; \n} 1. Given an index obj, a lookup is done into the second table to retrieve the correct offsets corresponding \nto the given object instance index: Objects[obj]. 2. Given the .eld being accessed, the compiler determines \nwhich row is the correct row that corresponds to the .eld: Row A Value. 3. The compiler determines which \noffset is the correct one that corresponds to the row. Here, we assume the offset at index 1 refers to \nthe A row. 4. The row is then accessed, being given the correct offset retrieved from the .rst step. \nSince it is a .eld array, the access is simply an array access.  Two new steps are introduced: .rst, \nan additional lookup to retrieve the set of offsets; second, a determination must be made as to which \noffset corresponds to which row. While the latter is accomplished within the compiler, the former must \noccur at runtime. For traditional computer programming, such a design would be a tradeoff of performance \nin favor of memory. The memory minimization comes at the cost of the additional lookup for every .eld \naccess. Surprisingly, we .nd that this extra lookup can actually be eliminated when targeting FPGAs because \nof a unique opti\u00admization that can be performed. If we eliminate the second table altogether, but pass \nalong the set of offsets directly in\u00adstead of an integer to the second table, no additional lookup is \nneeded. An object reference then would not a single inte\u00adger, but instead would be the tuple of offsets \nthat point into the object table directly. Thus, .eld accesses in our model consist only of steps 2-4. \nTo see why this is discouraged on microprocessor-based systems but a perfectly valid design choice when \nprogram\u00adming FPGAs, one must re-examine the implications of the differences in the way function calls \nare implemented on the FPGA by AutoPilot and the way they are traditionally done on a microprocessor. \nNormally, passing large data structures (larger than the register size of the platform) as arguments \nfor function calls is discouraged. Calls such as these will both require a larger stack frame to hold \nthe data, as well as additional copy operations to copy the data structure into into the stack frame \nbefore the function can be called. Fur\u00adthermore, this is compounded by the fact that when dealing with \ndata larger than the multiprocessor s register size, mul\u00adtiple loads and stores are required to move \nthe data. Because of this, functions with complex parameters have traditionally been represented indirectly \nby pointers to mitigate this prob\u00adlem; a pointer always .ts into the register and can be copied in one \noperation. In the hardware world, however, no such dif.culty exists in function calling. A large data \nstructure being passed by value is just synthesized as a wider bus between the caller and the callee. \nData is passed along this bus in a single parallel write operation regardless of bit width. Because of \nthis unique property of an FPGA, widening the bitwidth of an object reference from a single integer to \nmultiple integers incurs nearly no performance overhead. In fact, we .nd that for larger programs with \nbig class hierarchies, this actually offers increased performance over the uncompressed model, as will \nbe discussed in our benchmarks section. The next subsections discuss in more detail our usage of tuples \nas pointers, as well as outline the other difference in our object table format versus that of the vertical \nobject model.  3.3.2 Table layout and Inheritance We call our object model the hybrid object model because \nwe retain the struct concept from the horizontal scheme, but apply it to the design philosophy of the \nvertical scheme. Like the horizontal object model, we take each class and convert it to a struct. However, \ninstead of pre.xing the struct with that of its parent, we omit the parent s layout altogether, and just \ninclude the .elds immediately declared in the class itself. Thus, unlike the horizontal object model, \ninheritance is not encoded within the struct itself. Each class struct forms a row in our object table. \nBe\u00adcause we group by structs instead of .elds, our object ta\u00adble has a fewer number of rows than that \nof the vertical ob\u00adject model. Virtual method information is also omitted from  struct Ptr { char null; \nint comp1; int comp2; } Figure 5. The general structure of the pseudopointer. the table. Objects are \nplaced into the rows that correspond to their inheritance chain as illustrated in .gure 4: the table \nlayout consists of two instances of A, two instances of B, and one instance of C. An instance of A only \nhas an entry in the row that corresponds to A, whereas an instance of B, because its parent class is \nA, consists of an entry the A row as well as an entry in the B row. Finally, an instance of C has only \none entry in the row for C. Boxes represent actual elements in the row; empty spaces do not use any memory \nand are present to make the diagram easier to understand. Each column in a diagram represents one object \ninstance; the text underneath shows the tuple of offsets required to accurately reference the object. \nAnother thing to note is that while in the horizontal object model, inheritance is apparent in the layout \nof the struct itself: the parent class .elds pre.x those of the class itself, resulting in a memory layout \nthat is compatible with that of the parent. The vertical object model, similarly, makes the class hierarchy \nvisible in the table itself. A class instance contains .elds for itself as well as its parent (and all \nthe other classes in the hierarchy, too). For our hybrid object model, however, inheritance is shown \nneither in the structs nor the object table. Instead, inheritance is handled in the object references; \nthe tuple contains offsets for each node in the chain from the root class to leaf class. The root class \nof any object will always be at the .rst element in the reference tuple, and child classes follow, forming \nthe complete chain from root to leaf.  3.3.3 Structs as Pointers These tuples of offsets which are used \nas references to ob\u00adjects we call pseudopointers. Though they perform the func\u00adtion of pointers and provide \na means of indirection to objects similar to pointers, the semantics are very different. The pseudopointer \nis rendered as a struct in C. The general structure of the pseudopointer is shown in .gure 5. It consists \nof a null .ag to indicate a reference to null. If nonzero, it is understood to be a null reference. Following \nthe null .ag are a series of integer .elds comp1 ... compN, which we call component offsets. These component \noffsets point to various cells in the object table. The set of cells that these component offsets point \nto comprise the object instance. Each component points to an element in a unique row in the table. All \nobjects in our program use this struct de.nition as the canonical object reference; it is used wherever \nan object struct A { struct Ptr child; int value; }; struct B { struct Ptr other; } struct C { int a, \nb; } Figure 6. Our class hierarchy in this class encoding scheme. reference is expected local variables, \n.elds in classes and components, elements in arrays of objects, and parameters to functions. The struct \nis passed by value into any functions that take object references as parameters. One example of this \nis shown in .gure 6, which in particular demonstrates how the references to other classes (.elds child \nand other) are rendered in C. The interpretation of the component offsets is dependent on the static \ntype of the object reference during compila\u00adtion. Each class is broken down into multiple components;a \ncomponent is a node in the class inheritance chain. These components are then ordered from root class \nto leaf class. The number of component offsets stored in the pseudo\u00adpointer struct is determined by class \nwith the greatest num\u00adber of components that is, the class with the longest path to the root class of \nits family. All objects which have a shorter path to the root node will use the same pseudopointer struct, \nbut some of the component offsets will be unused. This scheme results in an absolute ordering of compo\u00adnents \nfor every class: each class ordering is pre.xed by that of its parent. This property is exploited in \norder to accom\u00adplish polymorphism. When a reference of type B is assigned to a reference for A, it still \nresults in a compatible pseudo\u00adpointer, because the component ordering for A is a subset of that of B; \nall the component offsets still correspond to the correct rows. With our sample class hierarchy, B has \nthe longest chain with a length of two the chain from B to the root is {A, B}. Thus, the program written \nusing our sample hierarchy will require a pseudopointer with two component offsets, as shown in .gure \n5. All pseudopointers for references to B will have its two component offsets pointing to the rows for \n{A, B}, respectively. References to C will use one component out of the two {C, -1}, where -1 is used \nto indicate an unused component in the pseudopointer. Figure 7 illustrates how the pseudopointer is interpreted \nfor a reference to a B. A .eld access in this scheme is translated into C as shown in the code snippet \nbelow. We convert the same mini-method Figure 7. An illustration of the pseudopointer, pointing to an \ninstance of B.  that we have been using throughout this paper to show how a .eld is accessed: method \nf(obj : A) : int { return obj.value; } int f(struct Ptr obj) { return Row_A[obj.comp1].value; } The generation \nof this code involves several steps: 1. Given the .eld that is being accessed, the compiler deter\u00admines \nthe class that de.nes this .eld: A. 2. The compiler gets the position of the class within the class \nhierarchy. This ordering determines which offset to use in the pseudopointer: obj.comp1. 3. Code is \nemitted accessing the row that corresponds to the class using the correct offset from the pseudopointer: \nRow A. 4. The .eld can then be accessed: value.  A component ordering for every class is created during \ncompilation. We use this ordering also to implement poly\u00admorphism. The horizontal object model implements \npoly\u00admorphism through a form of structural subtyping a child class struct contains all the methods and \n.elds, in the same order, of its parent. This allows pointers to the structs to be casted and still compatible. \nWe use the class ordering itself to implement polymorphism. A child class offset or\u00addering is a superset \nof that of its parent. As stated earlier, the compiler must create a mapping from offset position within \nthe pseudostruct to a certain row. This mapping differs for each class family; the .rst offset in the \npseudopointer for a reference to an instance of B would refer to the row for A; however, for a reference \nto an instance of C, the .rst offset refers to an element in the row for C. We order these components \nin such a way that the orderings for a subclass is always compatible with the ordering of the parent \nclass; this way, subtype polymorphism is allowed. A reference to a B can be passed to method expecting \na reference of type A as a parameter. Compatibility between parent and child class is accomplished by \nensuring that the order of the parent class is a subset of that of the child. This way, when code expecting \na reference to A received instead a reference to B, the offsets still correspond to the same rows. By \nthis same design choice, casting is possible and requires no additional code.  3.4 Runtime type information \nAugmenting this object layout model is the runtime type information .eld TYPEID that is placed into each \nroot class struct in order to supply Virgil s type query operator, instanceof, with the needed information. \nThis .eld also allows us to check for incompatible type casts. The TYPEID .eld is an unique integer that \nis assigned during compile time to each class. The way in which these values are ordered allow us to \noptimize the work needed for comparing two types for com\u00adpatibility: each class knows both the minimum \nvalue of its subtree (itself) and the maximum value assigned to its chil\u00addren. The implementation of \ninstanceof is straightforward given an object type id, checking to see that it is greater than the id \nof the target class and less than the maximum value for that class will yield the correct result. In \nour example, the compiler would assign a class identi\u00ad.er of 1 for A, 2 for B, and 3 for C. The instanceof \noperator querying whether an instance of C is compatible with A, then, would be rendered as follows: \nreturn Row_C[obj.f0].TYPEID >= 1 &#38;&#38; Row_C[obj.f0].TYPEID <= 2; Similarly, a type cast can be \nvalidated by checking the class identi.er of the target object to make sure it falls into the target \nclass interval. 4. Arrays Virgil s notions of arrays is similar to that of Java. The programmer can always \ncheck the length of an array by accessing the length .eld, and reads and writes are checked at runtime \nfor being outside of the bounds of the array. What the programmer actually deals with are references \nto the arrays themselves; like objects, all .elds, variables, and parameters which are typed in Virgil \nas an array are actually treated as references to arrays. These references are then passed by value in \nmethods. Array references normally would be implemented in C, again, via the use of pointers. Arrays \nwould be converted to global variables, and pointers would in turn point to these global variables. Virgil \ntakes an additional step by also in\u00adcluding with the pointer a .eld indicating the length of the array. \nThese two items would be wrapped into a struct, which would then be passed around. Of course, because \nof the same reasons why the traditional object representation doesn t work, this strategy does not work \neither. Aside from  Figure 8. Array model. the fact that we cannot use pointers, they cannot be included \nas members of structs either. 4.1 Array grouping Arrays in Virgil also fall under the rules for object \nalloca\u00adtion: arrays can only be created using the new operator with a constant-sized length inside constructors \nfor classes or com\u00adponents. Once the initialization phase is complete, the com\u00adpiler will know the total \nnumber of arrays in the program and their lengths. This information allows us to perform our array grouping \ntechnique. In order to successfully represent references to arrays without pointers, we approach the \nproblem in much the same way as with objects. We use the type information known dur\u00ading compilation to \ncreate canonical global variables for each type of an array, demarcated by the element type. All arrays \nwhich have the same element type are then grouped together and concatenated to form one long array. The \noriginal arrays as de.ned in the Virgil program are now subsets of this one canonical array. This approach \nis illustrated in .gure 8. The heap shown here consists of two arrays typed as char[], two int arrays, \nand two arrays holding objects of different types, A[] and C[]. Although the classes A and C are incompatible, \ni.e. they do not intersect at all in the class hierarchy, we consider them both to be the same array \ntype, as all objects are represented by one struct in C. The arrays are grouped and concatenated, forming \none canonical array for each array type. Array grouping accomplishes the prerequisites needed to successfully \nencode references to arrays without the need for pointers.  4.2 Array referencing With the array groups \ncreated, an array can be uniquely iden\u00adti.ed by its start offset, and its length. We solve this problem \nin much the same way as the object references; we create a single struct which holds the necessary information \nto identify an array. This array reference struct s basic struc\u00adture is shown in .gure 9. Because an \narray reference can be null like object references, we reserve a special .ag for struct Array { char \nnull; int start; int length; } Figure 9. Array reference struct. null. The other two .elds indicate \nthe start of the array within the canonical array, as well as the length of the array, respec\u00adtively. \nThe length information is used on all element accesses during runtime to ensure that accesses are valid \nand in the bounds of the array, similar to array accesses in Java or C#. These array references are, \nlike our object pseudopointer, passed by value into functions. Given an array reference and a expression \nevaluating to an index within the array, an element access would entail the following steps: method f(arr \n: int[], x : int) : int { return arr[x]; } int f(struct Array arr, int x) { return int_array[arr.start \n+ x]; } 1. Determine the overall index by summing the result of the index expression together with the \nstart .eld of the array reference : arr.start + x. 2. The compiler determines the correct global array \nto ac\u00adcess based on the static type of the array. All objects are considered to be one array type: int \narray. 3. Perform the array access.  Although all array accesses are checked to ensure they are within \nbounds, because currently Virgil has no exception handling mechanism, the case where an invalid array \naccess occurs will result in unde.ned behavior. Array grouping allows us to determine the correct array \nto access during compile time based solely on the known  void Foo_dispatch(struct Pointer __this) { \nswitch(Row_A[__this.f0]) { case1: //B B_bar(__this); return; default: // A A_bar(__this); return; } \n} Figure 10. Dispatcher function in C. type information of the array being accessed. Grouping all arrays \nof the same time to one canonical array eliminates the need for pointers, and allows us to represent \nreferences to arrays in a straightforward way with minimal performance overhead. 5. Methods The .nal \narea of major concern is virtual method dispatch without the use of tables or function pointers. The \ngeneral approach for this is the use of typecase to examine the run\u00adtime type of an object in order to \ndetermine the correct func\u00adtion to invoke. To accomplish this, we create intermediate dispatcher functions. \nIn general, each method call will be re-routed to a dispatcher function, which switches on the object \ns type identi.er and then calls the correct function directly. This section will provide an overview \nof this ap\u00adproach. 5.1 Type Case for Method Dispatch Our dispatcher method relies on several features \nof our ob\u00adject representation to successfully dispatch a call to the cor\u00adrect function: the runtime type \ninformation .eld, TYPEID, in the root class struct; the fact that the pointer offsets are ordered in \nsuch a way that the root class component index will always be the .rst .eld in the pointer; and the fact \nthat all classes are known during compile time in order to create a complete class hierarchy. The dispatcher \nconsists primarily of a switch statement on the TYPEID of the object, and calls the appropriate function \nfor the class. If the method has a non-void return type, the dispatcher will return the result of the \ncalled function. One case statement will be placed for every class in the class hi\u00aderarchy. We employ \nfall-through cases for classes that share a common method. An example of the dispatcher method for foo \nas de.ned in class A of our example hierarchy is shown in .gure 10. The dispatcher strategy incurs the \nhighest performance penalty in our object representation model, since each method call will have to go \nthrough an intermediate dis\u00adpatcher function before the correct code is executed. How\u00adever, through static \nanalysis and optimizations described later, we can skip the dispatcher for many method calls to which \nthe destination method is de.nitely known during compile-time.  5.2 Delegates Virgil supports the notion \nof delegates, which behave sim\u00adilarly to function pointers. Normally, they are compiled in C as function \npointers, which then are passed around in the place of delegates. However, because AutoPilot does not \nsupport function pointers, we do not allow delegates in the Virgil programs at this time. It is possible \nto extend the concept of dispatchers and create a large dispatcher that switches between all functions \nthat have the same signa\u00adture, however we have not implemented this at this time. We therefore relegate \nthe implementation of delegates to future work. 6. Optimizations The approaches we have just demonstrated \nrepresents the generalized model of how we implement the various lan\u00adguage constructs of Virgil targeted \nfor hardware compila\u00adtion. However, we perform several additional optimizations to further reduce area \nneeded and improve performance. Our optimizations fall into several categories, which will be dis\u00adcussed \nin this section. 6.1 Method Call Optimizations Although all methods are virtual in Virgil, we again take \nad\u00advantage of the fact that all classes are known at compile time in order to replace some dispatcher \ncalls with direct method calls. Some virtual methods may never be overridden by other classes in the \nclass hierarchy; calls to these methods do not need a dispatcher, as it is known in complete certainty \nwhich method is being called. We are able to then remove the call to the dispatcher, instead replacing \nit with a direct call the function. This minimizes the impact to performance of using dispatchers. In \nour example, the arg method in B and the foo method in A both exhibit the property of never being overridden \nby a child class. Calls to these functions elsewhere in the pro\u00adgram, then, are replaced with direct \ncalls to the C functions that represent the methods.  6.2 Bitwidth Optimization Our compiler generates \na variety of data structures and spe\u00adcial integer values throughout the model presented. Special values \nsuch as the array lengths, object identi.ers, array off\u00adsets, object table offsets, all are constant \nvalues generated during compilation time whose minimum and maximum val\u00adues are known. Because of this \nfact, our compiler can op\u00adtimize the sizes of the integer types needed to store these values. AutoPilot \nallows for arbitrary bit-width integer types in C. It accomplishes this through various typedefs that \nhook into AutoPilot s own libraries. This feature is exposed in C via types such as int6, which represents \na 6-bit signed integer. AutoPilot supports arbitrary bit integers from 1 bit to 1,024 bits. We take advantage \nof this feature to minimize the bit widths of all of the compiler-generated data structures.  To illustrate \nthis approach, let us use the heap layout as shown in .gure 4. The pseudopointer consists of two components. \nClasses that use the .rst component are A, B, and C; the second component is used only by B. The widest \nrow that is pointed to by the .rst component is the row for A, which consists of four elements. The row \nfor B, on the other hand, only has two cells. Our compressed pseudopointer is then: struct Ptr { uint1 \nnull; uint2 comp1; uint1 comp2; } Our pseudopointer, as a result, is only 4 bits wide. One bit is required \nfor the null .ag, while 2 bits are needed to represent the last index in row A, 3, and one bit to encode1, \nthe last index in row B. This optimization, although minor, serves two purposes: it saves area to a small \nextent by re\u00adducing the bus widths; it also increases performance by a small amount by reducing the probability \nof wires of uneven lengths (due to routing). Variables, .elds, and parameters de.ned as type int within \nthe Virgil program itself by the programmer are not modi.ed. Because the compiler cannot determine the \nrange of values that will be stored within these, their size will al\u00adways be 32 bits. However, Virgil \nhas another feature that allows the programmer to take advantage of this bitwidth optimization feature \nby using the raw types within Virgil. Raw types are unsigned types which can be de.ned as any number \nof bits between 1 and 64. Normally, we map these to one of the primitive unsigned integer types in C; \nhowever, when compiling with AutoPilot as the target, we can con\u00advert them into the exact number of bits \nthat the programmer de.ned them to be.  6.3 Array and Object Initialization One .nal required step that \nwe must do is assign all the ini\u00adtialization data the initial values of all arrays and objects into \na separate variables in C which are marked with const. AutoPilot recognizes this property and puts the \ndata in a spe\u00adcial ROM. Upon startup, this ROM data is copied into the RAM slots. This step comprises \nthe runtime initialization phase when the hardware is executed. The overhead intro\u00adduced by this operation \nis measured in the benchmarks sec\u00adtion; it depends primarily on the amount of data that needs to be copied \nfrom ROM to RAM. 7. Experimental Results 7.1 Benchmarks We wrote four Virgil benchmark applications to \nmeasure and compare the performance of our compiler. Three were trans\u00adlations of cryptographic benchmark \nprograms authored in C found in the CHStone benchmark suite [6], a well-known suite benchmark programs \nwritten in C designed to be syn\u00adthesized to FPGAs. These benchmarks, because they are translated from \nC, a non-object oriented language, lack the use of most of the object-oriented features that are available \nin Virgil. They primarily showcase the raw computational veracity of the compiler. To make up for this \nde.ciency, a fourth benchmark, the Richards benchmark, was also trans\u00adlated into Virgil [14]. The Richards \nbenchmark simulates the task dispatcher in the kernel of an operating system, and was translated from \nan object-oriented Java/C++ imple\u00admentation. The Richards benchmark does little in the way of raw computation, \nbut exercises many features of the lan\u00adguage that were not covered by our cryptographic bench\u00admarks. \nRichards uses many Virtual methods which require dispatchers, and there is a nontrivial amount of objects \nallo\u00adcated during the initialization phase. We chose Richards to enable comparison of Virgil and C++. \nThe following list describes in more detail the various benchmarks that we have chosen to use. They have \nbeen speci.cally chosen because they do not use any .oating point arithmetic, as Virgil does not have \n.oating-point prim\u00aditive types. The .rst three in the list are our cryptographic benchmarks from the \nCHStone suite. The last one is the object-oriented Richards benchmark. AES An implementation of the \nAdvanced Encryption Standard, a popular and modern encryption cipher.  Blow.sh An implementation of \nthe Blow.sh block cipher algorithm.  SHA An implementation of the cryptographic hash function, SHA-1. \n Richards Simulation of a task-dispatcher component of an operating system kernel.  Figure 11 shows \nthe various sizes of each benchmark program in line numbers for both the original source code and our \nVirgil translation.  7.2 Platform The performance of our compiler was compared with that of two different \nCPUs: an Intel Xeon CPU, which is Intel s high-performance CPU offering, and an Intel Atom CPU, which \nis the low-power mobile offering. The Xeon s hefti\u00adness offers speed at a cost of power consumption, \nwhile the Atom s leanness ensures that its power consumption will be very low compared to the Xeon, sacri.cing \ncomputational performance. The Xeon processor gives us an idea of the computational veracity of our benchmark \napplications that  Benchmark CPU (xeon) Time Energy (us) (mJ) CPU (atom) Time Energy (us) (mJ) FPGA \nTime Energy Slices FlipFlops BRAM (us) (mJ) AES C 23 1.9 92 0.37 34 0.04 4,803 6,641 54 Virgil/wide 83 \n6.7 317 1.27 103 0.14 6,199 8,198 51 Virgil/hybrid 85 6.8 317 1.27 106 0.14 6,575 8,253 51 Blow.sh C \n222 17.7 834 3.34 1,144 1.52 6,795 8,962 63 Virgil/wide 877 70.2 1,786 7.15 2,092 2.74 4,689 6,031 69 \nVirgil/hybrid 889 71.1 2,587 10.35 2,040 2.65 4,700 6,029 69 SHA1 C 319 25.4 1,093 4.37 1,565 2.07 5,715 \n8,409 65 Virgil/wide 1,070 85.6 2,131 8.52 1,525 1.98 4,858 6,595 64 Virgil/hybrid 1,074 85.9 2,630 10.52 \n1,525 2.04 4,890 6,598 64 Richards C++ 10,065 805.2 39,900 159.60 N/A N/A N/A N/A N/A Virgil/wide 11,164 \n893.1 36,331 145.32 16,065 21.21 4,330 5,519 68 Virgil/hybrid 29,135 2,330.8 61,622 246.49 14,433 18.91 \n4,317 5,355 67 Figure 12. Experimental results.  Lines of code Original Virgil Originally in C: AES \n791 669 Blow.sh 1320 1548 SHA 1349 1187 Originally in C++: Richards 705 437 Figure 11. Benchmark code \nlength.  can be achieved on ordinary, off-the-shelf server and work\u00adstation machines, while the Atom \ngives us a better idea of how the lowest-power x86 CPUs compare to the FPGA in terms of both performance \nand power consumption. The Xeon E5430, upon which our Xeon platform is based, has a TDP (Thermal design \npower) of 80 Watts [9]. On the other hand, our Atom 230 CPU boasts a TDP of only 4 Watts [8]. Because \nthe Atom s target market overlaps signi.cantly with that of FPGAs, we believe that the Atom will be a \nmore in\u00adteresting comparison than the Xeon. The TDP of a processor indicates its maximum designed power \nconsumption. We use these .gures in our estimates of the power consumed when our benchmark applications \nare executed on the respective CPUs. While additional power is consumed by the support devices needed \nto facilitate a CPU memory, storage drives, and other peripheral devices we are only interested in \nthe power directly consumed by the CPU in this paper. FPGA power consumption can be mea\u00adsured in a more \naccurate way; each FPGA vendor usually provides a tool that can precisely estimate the amount of power \nconsumed by a particular design when it is turned on. Both of these .gures, the TDP of a CPU and the \nestimated power consumption of an FPGA in watts, which can be mul\u00adtiplied by the execution time to give \na estimated .gure of the power consumed by the program in joules. CPU benchmarks were performed via an \nx86 64 gcc compiler running on Ubuntu Linux, kernel 2.6.32. The benchmarks were run 200,000 times, with \nthe overall run time being divided by 200,000 to obtain the average per\u00adexecution time. FPGA measurement \nwas done via the GHDL VHDL compiler, which converts FGPAs designs into an x86 program, which can be run \nfrom within Linux. This gave us the ability to have a better view of the internal timings and signal \ndata. The simulation results were con.rmed by re-executing the design on an Xilinx Virtex-II FPGA chip. \nThe FPGA vendor (Xilinx) tools were used for synthesis and layout. The Intel Xeon E5430 processor contains \n4 cores, each running at 2.66 GHz. It has a 6 MB shared cache. The system was further equipped with 32 \nGB of DDR2 RAM, although the benchmark programs never used more than 500MB of memory. The benchmarks \nwere compiled using GCC 4.4.3 on Ubuntu Lucid Lynx 10.04. The Intel Atom 230 is a single-core, hyper-threaded \nCPU running at 1.6 GHz with 512KB of cache. 1 GB of DDR2 memory is also installed on the system. Again, \nthe bench\u00admarks were compiled using GCC 4.4.3 on Ubuntu Lucid Lynx 10.04. The FPGA simulation platform \nis primarily the GHDL VHDL compiler version 0.28dev running, again, on Ubuntu Linux 10.04. The hardware \nspeci.cations of the simulation system are not important, as the simulator executes the de\u00ad  Benchmark \nInitialization (us) AES 23us Blow.sh 231us SHA1 330us Richards 2us Figure 13. Runtime initialization \nperiods. sign at a speci.ed clock speed (100MHz in our case) regard\u00adless of the underlying hardware. \n 7.3 Measurements Figure 12 show our measurements. On each execution plat\u00adform, the original C benchmark \nwas .rst compiled and exe\u00adcuted to establish original performance. Our compiler then compiles the benchmark \nprograms in two speci.c modes for comparison: .rst, the notion of the uncompressed verti\u00adcal object model, \nwhich contains wasted space, and our hy\u00adbrid object model which was described in this paper. The uncompressed \nmodel is measured in order to show that our table compression and object reference representation does \nnot have an adverse effect on the overall performance when run on an FPGA, although it may result in \nslower run times on the CPU. Finally, area measurements were gathered from the synthesis reports generated \nby the Xilinx synthesis tool. We report three numbers for area usage: 1. Slices a quantitative measurement \nwhich represents the size of the logic of the design. 2. Flip-.ops Flip-.ops are the on-chip ROM, which \nre\u00ad.ects the amount of read-only memory needed by the de\u00adsign. 3. BRAM units On-chip RAM is split into \nsubunits called BRAMS.  7.3.1 Runtime Initialization As discussed in the optimization section, an additional \nstep that must be taken is the runtime initialization phase. This step is a one-time operation that occurs \nat the beginning of execution that copies all the initialization data stored in the ROM into the RAM \nthat takes up a nontrivial amount of time. The table in .gure 13 shows the time taken for this required \ninitialization phase for the different benchmarks. This number was gathered during simulation of the \nFPGA design. These numbers are already included in the performance numbers included in .gure 12. However, \nthe amount of time spent purely on the logic of the Virgil benchmarks can be obtained by subtracting \nthis number from the total execution time.  7.4 Microbenchmarks The scalability factor of our object \nmodel was also tested in order to ensure that it supports large programs with many objects and/or deep \nclass hierarchies. Two benchmarks were written: one to test the effect of the dispatcher on large class \nhierarchies, and the other to test the the impact of large amounts of objects upon method calls. For \nthe former, class hierarchies of three, six, and twelve were benchmarked, and for the latter, programs \nconsisting of one class and ten, one hundred, and one thousand objects were measured. In all cases, one \nmillion method calls were issued. We found that there was no signi.cant difference in per\u00adformance between \nthe various benchmarks; all performed within 3-5% of each other. This strongly indicates that there should \nbe minimal scalability issues with large programs and our object model.  7.5 Assessment We approached \nthe performance assessment from three dif\u00adferent perspectives: energy, run time, and physical size. Pri\u00admarily, \nwe were interested in the amount of energy con\u00adsumed by the various designs during execution. Admittedly, \nenergy savings may be less attractive if the run time were to degrade signi.cantly when switched to an \nFPGA. Thus, secondly, we performed overall measurements of run time across platforms. Thirdly, we also \nanalyzed the physical size of the hardware designs created by our compiler, as fabrica\u00adtion cost for \nan FPGA chip is primarily driven by the physi\u00adcal size of the design. Time and Energy. As can be expected, \nthe Xeon plat\u00adform is the fastest and uses the most energy. The Xeon pro\u00adcessor executed the benchmarks \n2 to 4 times faster than the Atom processor, but consumed 5 to 10 times more energy doing it. For the \nthree cryptographic benchmarks, C on the Atom processor executed 1.2 to 2.4 times faster than Virgil \non the FPGA, but consumed 1.3 to 2.6 times more the energy do\u00ading it. In contrast, for the object-oriented \nRichards bench\u00admark, the FPGA is better in both dimensions: C++ on the Atom processor executed 2.8 times \nslower than Virgil on the FPGA, and consumed 8.4 times more energy doing it. Thus, for the object-oriented \nbenchmark we can get the best of both worlds by switching from C++ on Atom to Virgil on the FPGA: faster \nexecution and almost an order of magni\u00adtude energy savings. Remarkably, Richards in C++ on Xeon executes \nwithin 2x faster than Virgil on the FPGA, but consumes more than 42x more energy doing it. For the Richards \nbenchmark, when we compare Vir\u00adgil/wide to Virgil/hybrid, we see a big jump in run time and energy consumption \nfor both Xeon and Atom, but a signi.cant drop for the FPGA. The reason is that the hybrid object model \nis a better .t for the FPGA than the wide object model, but is wasteful on a CPU. For SHA1, the execution \ntime and energy consumption of Virgil on the FPGA is even lower than of C on the FPGA. If initialization \ntime is omitted from the result, then the AES benchmark executes slightly faster in Virgil on the FPGA \nthan in C on the Xeon! For an informal comparison, Huang et al. reported that DES on an FPGA ran 14 times \nslower than DES on a Core 2 Duo processor with a fre\u00adquency of 2.66 GHz. We believe that our Virgil compiler \nis a signi.cant improvement over the previous work on marry\u00ading object-oriented programming paradigms \nwith hardware synthesis toolchains.  Physical Size. For each of the three cryptographic bench\u00admarks, \nwe can compare the slices, FlipFlops, and BRAM in C and in Virgil. We .nd that our area usage numbers \nare comparable. We have managed to occupy less area than that of even the original C program s design \nin two out of three cases. In both of these cases, our version of the benchmark occupied signi.cantly \nless area. The AES benchmark, how\u00adever, occupied a similar margin more area. The interpretation of the \nRichards benchmark results must be approached differently. Because the original pro\u00adgram cannot be synthesized \nthrough AutoPilot as it uses many of the language constructs, especially pointers, in such a way that \nis disallowed by AutoPilot, we do not have a comparison on the FPGA for the equivalent non-Virgil version. \nFurthermore, Virgil provides a way to write the Richards benchmark that would be impossible otherwise \nto do (short of replicating our model by hand in C). There\u00adfore, our sole comparison available is the \nexecution time of the C++ version running on the CPUs. It is also the only benchmark in which we have \na signi.cant number of ob\u00adjects and classes; the computational CHStone benchmarks are not implemented \nin a object-oriented fashion. Here, we see the advantages of our object compression scheme. We used a \nsmaller number of both .ip-.ops and BRAMs, as well as gain a signi.cant performance boost over the non\u00adcompressed \nversion. The Virgil Compiler. The measurements show signi.\u00adcant variation across the cryptographic benchmarks. \nFor ex\u00adample, AES in C on the Atom is 1.2 times faster than in Virgil on the FPGA, while Blow.sh in C \non the Atom is 2.4 times faster than in Virgil on the FPGA. It is dif.cult to pinpoint the exact causes \nof the performance difference be\u00adcause optimizations are done at multiple points through the compilation \nprocess: our Virgil compiler attempts to produce optimized C code, the AutoPilot tool itself aims to \nemit opti\u00admized HDL design code, and the .nal FPGA vendor-speci.c synthesis tool aims to produce an optimal \nphysical layout of the design on the FPGA chip, so In future work we will in\u00advestigate further how to \noptimize C code for AutoPilot. 8. Conclusion The compiler that we have introduced, which enables a full \ntool chain that leads from high-level object-oriented Virgil code to low-level VHDL designs, allows software \nengineers to easily reap the enormous energy consumption bene.ts that FPGAs have to offer while still \nexhibiting reasonable performance and competitive area. This system is still a preliminary investigation, \nand much work can be done to further improve the experience of the programmer. In particular, work can \nbe done to better ex\u00adtend Virgil to some domains of hardware programming is currently out of reach. Examples \nof such domains are that of streaming data models, .oating-point arithmetic, and de\u00adsigns that interact \nwith external hardware. All three of these can be achieved elegantly with well-designed extensions to \nVirgil. Further static analysis, or an explicit modi.er to make certain arrays and objects read-only, \nwould help to shorten runtime initialization by reducing the amount of data that must be copied from \nROM to RAM. Furthermore, improvements can be made to overall pro\u00adgrammer experience in terms of designing \nprograms with the paradigms which already exist. A big notion that Virgil is currently lacking is support \nfor user exceptions; currently, any attempts at dereferencing a null reference or accessing an array \nout of bounds leads to unde.ned behavior. By im\u00adplementing an exception system as well as a way in hardware \nto handle these exceptions would greatly ease the task of de\u00adsigning hardware that gracefully exits when \nerror conditions are encountered. Finally, several features currently allowed in Virgil are not supported \nin our representation. These include: Recursion  Delegates (function pointers)  Generics  The support \nfor these features, along with the various im\u00adprovements that could be made listed above, would make \nVirgil a truly powerful platform on which to program FG-PAs. Acknowledgments. We thank Jason Cong, Karthik \nGu\u00adruraj, Guoling Han, Zhiru Zhang, and Yi Zou for many discussions and help with AutoPilot. We also \nthank Kan\u00adnan Goundan, Ben Titzer, and the anonymous referees for helpful comments on drafts of the paper. \nWe were sup\u00adported in part by the National Science Foundation Center for Domain-Speci.c Computing (award \nnumber 0926127), and by National Science Foundation award number 0725354. The second author thanks David \nBacon for many conversa\u00adtions about compiling OO to FPGA. References [1] David Baldwin. Structured ASIC \nchallenges FPGA. Nikkei Electronics Asia, September 2003. [2] Jayaram Bhasker. A Verilog HDL Primer. \nStar Galaxy Pub\u00adlishing, 2005. [3] David C. Black, Jack Donovan, Bill Bunton, and Anna Keist. SystemC: \nFrom the Ground Up. Springer, 2004. [4] Craig Chambers. The Design and Implementation of the SELF Compiler, \nan Optimizing Compiler for Object-Oriented Programming Languages. PhD thesis, Stanford University, 1992. \n [5] J. Cong and Y. Zou. Lithographic aerial image simulation with FPGA-based hardware acceleration. \nIn In FPGA 08, Proceedings of 16th ACM/SIGDA International Symposium on Field Programmable Gate Arrays, \npages 20 29, 2008. [6] Yuko Hara, Hiroyuki Tomiyama, Shinya Honda, and Hiroaki Takada. Proposal and quantitative \nanalysis of the CHStone benchmark program suite for practical C-based high-level synthesis. Journal of \nInformation Processing, 17:242 254, 2009. [7] Shan Shan Huang, Amir Hormati, David F. Bacon, and Ro\u00addric \nM. Rabbah. Liquid metal: Object-oriented programming across the hardware/software boundary. In Proceedings \nof ECOOP 08, European Conference on Object-Oriented Pro\u00adgramming, pages 76 103, 2008. [8] Intel. Atom \nprocessor 230. Information available from http://ark.intel.com/Product.aspx?id=35635. [9] Intel. Xeon \nprocessor E5430. Information available from http://processor.nder.intel.com/details.aspx?sSpec=SLANU. \n[10] Ian Kuon and Jonathan Rose. Measuring the gap be\u00adtween FPGAs and ASICs. In In FPGA 06, Proceedings \nof 14th ACM/SIGDA International Symposium on Field Pro\u00adgrammable Gate Arrays, pages 21 30, 2006. [11] \nChris Lattner. LLVM: An infrastructure for multi-stage op\u00adtimization. Master s thesis, University of \nIllinois at Urbana-Champaign, 2004. [12] Oskar Mencer, Marco Platzner, Martin Morf, and Michael J. Flynn. \nObject-oriented domain speci.c compilers for pro\u00adgramming FPGAs. IEEE Transactions on VLSI Systems, 9(1):205 \n210, 2001. [13] Volnei A. Pedroni. Circuit Design with VHDL. MIT Press, 2004. [14] Martin Richards. Benchmarking \nwith the Richards benchmark. http://research.sun.com/people/mario/ java benchmarking/richards/richards.html. \n[15] Martin Schoeberl. Java technology in an FPGA. In In FPL 04, Proceedings of the International Conference \non Field-Programmable Logic and its Applications, 2004. [16] Ben L. Titzer. Virgil: Objects on the head \nof a pin. In Proceedings of OOPSLA 06, ACM SIGPLAN Conference on Object-Oriented Programming Systems, \nLanguages and Ap\u00adplications, 2006. [17] Ben L. Titzer, Joshua Auerbach, David F. Bacon, and Jens Palsberg. \nThe ExoVM system for automatic VM and applica\u00adtion reduction. In Proceedings of PLDI 07, ACM SIGPLAN \nConference on Programming Language Design and Imple\u00admentation, pages 352 362, San Diego, California, \nJune 2007. [18] Ben L. Titzer and Jens Palsberg. Vertical object layout and compression for .xed heaps. \nIn Proceedings of CASES 07, In\u00adternational Conference on Compilers, Architecture, and Syn\u00adthesis for \nEmbedded Systems, pages 170 178, Salzburg, Aus\u00adtria, September 2007. A revised version of the paper appeared \nin Semantics and Algebraic Speci.cation, Essays Dedicated to Peter D. Mosses on the Occasion of His 60th \nBirthday, Springer, LNCS 5700, 2009. [19] Z. Zhang, Y. Fan, W. Jiang, G. Han, C. Yang, and J. Cong. Au\u00adtopilot: \nA platform-based ESL synthesis system. In P. Coussy and A. Morawiec, editors, High-Level Synthesis: From \nAlgo\u00adrithm to Digital Circuit. Springer Publishers, 2008.     \n\t\t\t", "proc_id": "1869459", "abstract": "<p>Consumer electronics today such as cell phones often have one or more low-power FPGAs to assist with energyintensive operations in order to reduce overall energy consumption and increase battery life. However, current techniques for programming FPGAs require people to be specially trained to do so. Ideally, software engineers can more readily take advantage of the benefits FPGAs offer by being able to program them using their existing skills, a common one being object-oriented programming. However, traditional techniques for compiling object-oriented languages are at odds with today's FPGA tools, which support neither pointers nor complex data structures. Open until now is the problem of compiling an object-oriented language to an FPGA in a way that harnesses this potential for huge energy savings. In this paper, we present a new compilation technique that feeds into an existing FPGA tool chain and produces FPGAs with up to almost an order of magnitude in energy savings compared to a low-power microprocessor while still retaining comparable performance and area usage.</p>", "authors": [{"name": "Stephen Kou", "author_profile_id": "81470642476", "affiliation": "UCLA Computer Science Department, Los Angeles, CA, USA", "person_id": "P2354020", "email_address": "", "orcid_id": ""}, {"name": "Jens Palsberg", "author_profile_id": "81100375570", "affiliation": "UCLA Computer Science Department, Los Angeles, CA, USA", "person_id": "P2354021", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869470", "year": "2010", "article_id": "1869470", "conference": "OOPSLA", "title": "From OO to FPGA: fitting round objects into square hardware?", "url": "http://dl.acm.org/citation.cfm?id=1869470"}