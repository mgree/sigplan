{"article_publication_date": "10-17-2010", "fulltext": "\n A Dynamic Evaluation of the Precision of Static Heap Abstractions Percy Liang UC Berkeley pliang@cs.berkeley.edu \nOmer Tripp Tel-Aviv University omertrip@post.tau.ac.il Mayur Naik Intel Labs Berkeley mayur.naik@intel.com \nMooly Sagiv Tel-Aviv University msagiv@post.tau.ac.il Abstract The quality of a static analysis of heap-manipulating \npro\u00adgrams is largely determined by its heap abstraction. Object allocation sites are a commonly-used \nabstraction, but are too coarse for some clients. The goal of this paper is to investi\u00adgate how various \nre.nements of allocation sites can improve precision. In particular, we consider abstractions that use \ncall stack, object recency, and heap connectivity information. We measure the precision of these abstractions \ndynamically for four different clients motivated by concurrency and on nine Java programs chosen from \nthe DaCapo benchmark suite. Our dynamic results shed new light on aspects of heap ab\u00adstractions that \nmatter for precision, which allows us to more effectively navigate the large space of possible heap abstrac\u00adtions. \nCategories and Subject Descriptors D.2.4 [Software En\u00adgineering]: Software/Program Veri.cation General \nTerms Measurement, Experimentation, Veri.ca\u00adtion Keywords heap abstractions, static analysis, dynamic \nanal\u00adysis, concurrency 1. Introduction Many static analyses of heap-manipulating programs require reasoning \nabout the heap. This reasoning is driven by a heap abstraction, a systematic way to partition the typically \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. OOPSLA/SPLASH \n10, October 17 21, 2010, Reno/Tahoe, Nevada, USA. Copyright c &#38;#169; 2010 ACM 978-1-4503-0203-6/10/10. \n. . $10.00 unbounded number of concrete objects at run-time into a .nite set of abstract objects. The \nchoice of heap abstraction impacts the precision and scalability and ultimately the usability of a static \nanalysis. Object allocation sites are perhaps the most popular kind of heap abstraction. Analyses based \non this abstraction place all objects allocated at the same site in the program into the same partition. \nThough useful in some cases, allocation sites are too coarse to prove many properties of interest. Consequently, \na plethora of re.nements have been proposed in the literature (e.g., [4, 20, 24, 27, 31]). The goal of \nthis paper is to understand which types of re.nement are most useful for various clients. Abstractions \nWe focus on a family of heap abstractions that re.ne object allocation sites by augmenting the abstrac\u00adtion \nof an object with information of the following kind: Call stack We add the chain of the k most recent \ncall sites on the stack of the thread creating the object. The result\u00ading heap abstraction, known as \nk-CFA [31] with heap cloning or heap specialization, is popular in points-to analyses for both procedural \nand object-oriented lan\u00adguages (e.g. C and Java). Object recency If an object is the i-th to last allocated \nat its allocation site, the recency index of that object is min{i-1,r}, where r is a .xed maximum depth. \nAdding the recency index allows us to distinguish the last r ob\u00adjects created at an allocation site and \nfrom all other ob\u00adjects created earlier at that site.1 This heap abstraction, called the recency abstraction \n[4, 24], is particularly use\u00adful for .ne-grained reasoning about loops, as it allows distinctions between \nobjects created in different itera\u00adtions of the same loop. 1 Note that in this paper, we use the term \nrecency to refer to recency of allocation, not recency of access.  Heap connectivity We distinguish \nobjects by their connec\u00adtivity properties in the heap, e.g., by associating an ob\u00adject o with the allocation \nsites of other objects that can reach o through the heap graph. These heap connectivity predicates are \ncommon in shape analysis [27], and allow reasoning about complex data structures. Clients As we will \nsee, the precision of a heap abstraction depends heavily on the client. In this study, we study four \nclients for Java which are motivated by concurrency static race and deadlock detection, in particular. \nThe THREADESCAPE client asks whether a particular heap-accessing statement in the program (that is, an \naccess to an instance .eld or array element) ever accesses objects which are reachable from a static \n.eld (and thus potentially accessible by more than one thread). The SHAREDACCESS client asks a stronger \nquestion: whether that object is actu\u00adally accessed by multiple threads. These two clients are use\u00adful \nfor static race detection: a statement is race-free if it only accesses thread-local data. The SHAREDLOCK \nclient is related, asking whether a lock acquisition statement in the program ever holds a lock that \nis ever held by more than one thread. This client is similarly useful for static deadlock detection: \na statement cannot be involved in a deadlock if it holds a lock that is only ever held by one thread. \nFinally, the NONSTATIONARYFIELD client asks whether a given instance .eld f in the program is stationary \n[32], that is, whether for every object o, all writes to o.f precede all reads of o.f. This client is \nagain useful for race detection: a pair of read-write statements accessing f cannot race if f is stationary. \nMethodology We evaluated our heap abstractions on the clients described above on nine concurrent Java \nprograms from the DaCapo benchmarks suite [5]. While our motiva\u00adtion is ultimately static analysis, our \nmethodology for evalu\u00adating our family of abstractions and clients is based on a dy\u00adnamic analysis. Speci.cally, \na program is run concretely, and abstractions are computed on the .y, against which queries are answered. \nWorking in this setting allows us to focus only on heap abstractions, since we assume that all other \naspects static analyses must contend with (e.g., primitive data, de\u00adstructive updates, merge points, \nand method summarization) are handled optimally. This dynamic setting therefore provides an upper bound \non the precision of the best possible static analysis that uses a given heap abstraction. While we cannot \nsay de.nitively that an abstraction will work well within a static analysis due to other compounding \nfactors, we can certainly show that a heap abstraction is ineffective for some client. For example, for \nthe THREADESCAPE client on the luindex benchmark, only 6.3% of the queries reported to be escaping by \nusing the allocation site abstraction are actually escaping. In this case, the heap abstraction is clearly \na bottleneck: no amount of work on the other aspects of static analysis can help. Summary of Main Results \n1. We show that the precision of an abstraction on a client is in part driven by whether the abstraction \nis in line with the properties of the client. For example, for the NONSTATIONARYFIELD client, RECENCY \n(de.ned in Section 4.2) works quite well because both the client and the abstraction involve temporal \nproperties. On the other hand, increasing k has virtually no impact. 2. We evaluated the effect of varying \nthe call site depth k for abstractions based on k-CFA. For THREADESCAPE, we showed that as k increases, \nthe precision undergoes a sharp phase transition, with the critical k value occurring between k =3 and \nk =6. 3. We found that RECENCY is an important dimension over\u00adall, leading to the highest precision \non three of the four clients. We also show that increasing the recency depth r improves precision past \nr =1, which has been the only case studied in past work. 4. We show that adding re.nements along multiple \ndi\u00admensions simultaneously can be important. In one case, REACHFROM does not improve precision over ALLOC \nuntil we use k-CFA with k = 5. In another case, increas\u00ading the recency depth from r =1 to r =2 is useless \nunless k is large enough. 5. We use the number of abstract objects (which we call abstraction size) \nto measure the potential scalability of an abstraction. We found that RECENCY offers the best tradeoff \nbetween precision and size.  The rest of the paper is organized as follows. Section 2 formalizes our \nmethodology. Section 3 describes our four clients and Section 4 describes our family of heap abstrac\u00adtions. \nSections 5 and 6 describe the benchmarks and exper\u00adimental setup, respectively. Section 7 presents our \nresults. Section 8 surveys related work, and Section 9 concludes. 2. Methodology We present the general \nframework for our empirical study. The basic idea is this: We run a dynamic analysis that main\u00adtains \nthe concrete environment, heap, and various other in\u00adstrumentation. At various points along the execution \ntrace, the abstraction is applied to the concrete state to produce an abstract state, which is used to \nanswer client queries. 2.1 Program Syntax and Semantics We now present our dynamic analysis. Figure \n1 provides the relevant notation. A program is described by a set of program points P, where each program \npoint p . P has a statement stmt(p) . S. Figure 1 provides the full list of statements; For example, \nan instance .eld read takes the form v1 = v2.f for local variables v1,v2 . V and instance .eld f . F.2 \nThe statement spawn v creates a new thread by 2 We use f to denote both instance .elds and array indices. \n Syntactic domains: (program point) p . P (static .eld) g . G (local variable) v . V (instance .eld \nor array index) f . F (primitive stmt.) s . S s ::= v = null | v = new | v1 = v2 | v = g | g = v | v1 \n= v2.f | v1.f = v2 | spawn v | lock v (stmt. at point) stmt . P . S Semantic domains: (object) o . O \n(environment) . . .= V . (O.{null}) (thread ID) t . T (threads) . . T= T . (P\u00d7 .) (heap) s . S=(O\u00d7 F) \n. (O.{null}) (auxiliary instr.) u . U (state) . . O= T\u00d7 T \u00d7 S \u00d7 U (trace) r ::= [.1, ..., .n] (query) \nq . Q . (O . bool) Figure 1. Program trace syntax and semantic domains. Let ..t, ..., ..s, and ..u correspond \nto the components of a state .. For convenience, also de.ne ..p = ...(..t).p to be the program point \nof the current thread ..t, and let ... = ...(..t).. be the environment of thread ..t. calling java.lang.Thread.start() \nwith this set to the object pointed to by v. The statement lock v acquires a lock on the object pointed \nto by v. We are not concerned with the control-.ow graph of the program as our analysis is dynamic and \ndepends only on the execution trace (de.ned below). Having established the syntax, we now describe the \nse\u00admantics of program execution. When the program executes, there are a set of threads indexed by a set \nof thread IDs T. For each thread ID t . T, .(t) speci.es two pieces of informa\u00adtion about that thread: \n(1) a current program point .(t).p . P and (2) an environment .(t).. . ., which maps each local variable \nv . V to the concrete object .(t)..(v) . O that v points to. All threads share a heap s . S, which is \na di\u00adrected graph whose nodes are concrete objects and edges are pointers labeled with an instance .eld \nor array index. In par\u00adticular, s(o, f)= o' means object o . O points to o' . O via .eld f . F. At any \ntime during program execution, there is a state . . O, which contains the following information: (1) \nthe ID ..t . T of the thread that is about the execute, (2) the threads ... . T, (3) the heap ..s . S, \nand (4) any auxiliary instrumentation ..u . U which is needed either For abstractions: (allocation site) \nh . H (allocation site of object) as . O . H (objects in order of creation) os . O* (method call site) \ni . I (method call stack of object) cs . O . I* For clients: (thread-escaping objects) esc .P(O) (threads \naccessing an object) accs . O .P(T) (threads locking an object) lcks . O .P(T) (object-.eld pairs read) \nrds .P(O\u00d7 F) Figure 2. Auxiliary instrumentation u . U needed by vari\u00adous abstractions and clients. Let \n..esc, ..accs, ..lcks, and ..rds denote the instrumentation collected for state .. Sec\u00adtions 3 and 4 \nprovide the semantics of these quantities. (abstract object) a . A (abstraction function) a . (O \u00d7 O) \n. A (abstract env.) .a . .a = V . A (abstract threads) .a . Ta = T . (P\u00d7 .a) (abstract heap) sa . Sa \n=(A\u00d7 F) .P(A) a (abstract aux. instr.) u. Ua (abstract state) .a . Oa = T\u00d7 Ta \u00d7 Sa \u00d7 Ua a (abstract query) \nq. Q . (O . bool) Figure 3. Abstract versions of our semantic domains. by the abstraction or client. \nThis instrumentation (detailed in Figure 2) includes information such as object allocation sites and \ncall stack information. A full program execution is represented by a trace r, which is a sequence of \nstates [.1,...,.n]. We omit the concrete semantics for the various statements as it is stan\u00addard. The \nauxiliary instrumentation warrants more discus\u00adsion, which we defer to Section 3.  2.2 Abstractions \nAn abstraction function a, the central object of interest in this paper, maps a concrete object o . O, \nin the context of a concrete state . . O, to an abstract object a = a(., o) in some abstract domain A \n(see Figure 3).3 Intuitively, a de.nes an equivalence relation over objects such that objects in the \nsame equivalence class are not distinguished. For example, the classical object allocation site abstraction \nmaps o . O to the site h . H where o was allocated. However, the abstraction function can in general \ndepend on any aspect 3 For convenience, de.ne a(., null)= null.  of the current state ., which will \nbe crucial for de.ning the reachability and recency abstractions (Section 4). The abstraction function \na can be used to map concrete objects to abstract objects, but in order to answer queries, we will use \na to map a concrete state . to an abstract state .a. We construct .a by applying a to the various parts \nof . =(t, ., s, u) as follows: 1. For the current thread ID t, no abstraction is performed. 2. For the \nthread .(t)=(p, .) with program point p and environment ., we de.ne .a(t)=(p, .a), where the abstract \nenvironment .a is computed by applying the abstraction a to the object .(v) to which a variable v . V \npoints:  .a(v)= a(., .(v)). (1) 3. For the heap s, we de.ne the abstract heap sa by col\u00adlapsing objects \nin the heap graph that map to the same abstract object: '' ' sa(a, f)= {a . A : .o, o . O,s(o, f)= o, \n' a = a(., o),a = a(., o ')}. (2) Note that in the abstract graph, there might be more than one edge \nleaving a node with the same .eld label. 4. For a given auxiliary instrumentation u, the abstract in\u00adstrumentation \nua consists of abstracted versions of the information needed for clients (the concrete versions are described \nin Section 3): The abstract escaping set esca consists of the set of abstract values taken on by some \nconcrete object in the concrete escaping set esc: a esc = {a(., o): o . esc}. (3) Whereas accs maps a \nconcrete object to the set of threads that have accessed it, accsa maps an abstract object a to the set \nof threads that have accessed any concrete object with abstraction a:  accs a(a)= accs(o). (4) o:a(.,o)=a \nSimilarly, lcksa maps an abstract object a to all the threads that have locked any concrete object with \nab\u00adstraction a:  lcksa(a)= lcks(o). (5) o:a(.,o)=a Finally, rdsa is the set of all pairs (a, f) such \nthat some object with abstraction a had its .eld f read: rdsa = {(a(., o),f):(o, f) . rds}. (6) From \nthese four cases, we can observe the general recipe for constructing abstract instrumentations: for sets \nwhose elements involve objects (e.g., esc and rds), project these objects onto their abstractions; for \nfunctions mapping objects to sets (e.g., accs and lcks), construct a mapping from abstract values to \na union of those sets.  2.3 Answering Queries A client is speci.ed by a set of queries which each operate \non a trace. An example of a query for THREADESCAPE is: at program point p, does variable v ever point \nto an object which is reachable from a static .eld or was the argument of spawn? It will be useful to \nformulate a query q on a trace r = [.1,...,.n] in terms of a disjunction over individual queries on each \nstate .i in the trace: n q(r)= q(.i). (7) i=1 For example, the THREADESCAPE query speci.ed by (p, v) \nis true if at any point in the trace where the current statement is p, v points to thread escaping data \n(see Section 3.1 for more details). Henceforth, we will consider the client to be de.ned by a set of \nqueries Q, where each query q . Q maps a concrete state . to a boolean indicating whether a given property \nholds on that state. These queries induce the quantity of interest via a disjunction over the states \nin the dynamic trace (7). Note that a static answer to the query would involve a further disjunction \nover all possible traces of a program. To evaluate an abstraction with respect to a client, we must be \nable to answer queries against the abstraction. For a query q . Q and an abstraction a, we let qa . Oa \n. bool denote an abstract query. The optimal abstract query, based on supervaluational se\u00admantics, would \nreturn true for an abstract state if the concrete query is true for any state . with that abstract state: \n a qopt(x)=q(.). (8) .:.a=x This query is both sound and complete, but is in general a dif.cult quantity \nto compute, so we will present sound approximations that is, qa for which the following condi\u00adtion holds: \nq(.)=1 . q a(.a)=1. (9) We measure the quality of an abstraction a by precision, the fraction of queries \nanswered true under the abstraction which are actually true concretely: |{q . Q : q(r)}| precision(a, \nr)= . (10) |{q . Q : qa(ra)}| Note that queries are based on static code artifacts (for example, for \nTHREADESCAPE, queries correspond to all variables at all heap-accessing program points), not on dy\u00adnamic \nobjects. Therefore, a small change in a single ob\u00adject which is pointed to by many variables can affect \nmany queries, and thus have a large impact on precision. Some of this sensitivity is intrinsic to the \nclients. For example, in THREADESCAPE, adding a single link in the heap can cause an arbitrary large \nset of objects to escape.  3. Clients We study four clients motivated by concurrency. In partic\u00adular, \nthese clients can be used by higher-level analyses for .ndings concurrency defects such as races and \ndeadlocks. Some have additional applications which we will discuss later. We chose the clients to satisfy \nthree requirements: (1) the client should be useful for solving a real-world problem; (2) the client \nshould have a clear evaluation metric based on precision; and (3) the client should require reasoning \nabout the heap and thus depend on the quality of the heap abstraction. For low-level clients with no \nclear application, it would be hard to appreciate the effect of the abstraction. On the other hand, high-level \nclients are more problematic from a methodological perspective, as they often require more than a good \nheap abstraction and might be harder to evaluate. For each client, we formulate the property of interest \nin terms of queries of the form q . O . bool. We show how these queries can be computed form the auxiliary \ninstrumen\u00ad a tation. We also de.ne the abstract query q. 3.1 THREADESCAPE A key problem in the analysis \nof concurrent programs is identifying which data in a program is thread-local, i.e., reachable from at \nmost one thread. Information about thread\u00adlocality is useful for reducing false positives in static race \nand deadlock analyses [25], as well as reducing the run\u00adtime overhead of software-transactional memory \n[35] and dynamic analyses for .nding concurrency defects [10]. More ef.cient memory allocators and garbage \ncollectors for multi-threaded programs, as well as optimizations in multi\u00adthreaded programs under sequentially-consistent \nmemory models, can also bene.t from thread-locality [15]. One way to obtain this information is by asking \nthread\u00adescape queries: At a program point p . P, can a given variable v . V ever point to an object which \nis reachable from more than one thread (e.g., by following a series of .eld pointers from a static .eld)? \nThis question can be expressed as a disjunction over the states . in the trace (7) of the following query: \nTHREADESCAPE(p, v)(.) \u00a3 (11) ..p = p . ...(v) . ..esc. We now de.ne the escaping set esc. The set esc \nof the initial state .1 is empty. Given the set esc of a state ., the ' set esc of the next state . ' \nis de.ned to be the set of objects ' o which are reachable via the heap graph ..s (denoted ..s o : o \n') from an object o satisfying any of the following three conditions: 1. o . esc, 2. the current statement \nsets some static .eld g . Gto point to o (that is, stmt(..p) = g = v and ...(v)= o), or 3. the current \nstatement executed is spawn v and v points to  o (that is, stmt(..p) = spawn v and ...(v)= o). This \ncondition captures the fact that objects o which are passed into newly created threads (via spawn) also \nescape. Now, we need to de.ne the set of queries Q. Motivated by race detection, we include query THREADESCAPE(p, \nv) if p is an instance .eld or array element read/write statement and v is the variable whose .eld is \nbeing accessed, namely v.f = y or y = v.f for some variable y. Given an abstraction a, the natural abstract \nquery would be as follows: THREADESCAPEa(p, v)(.a) \u00a3 (12) a .a .p = p . .a..a(v) . .a .esc . However, \nthis abstract query is costly to evaluate, because we would need to compute graph reachability to ascertain \na(., o) . .a.esca for each state . in the trace. We therefore de.ne a new set ..esc, which is a relaxation \nof the escaping set ..esc (that is, ..esc . ..esc): The transfer function for esc is analogous to that \nof esc, with the exception that reachability is de.ned with respect to the abstract heap .sa ' that is, \no reaches o iff a(., o) .a: a(., o '). Intuitively, we are using the abstraction to update the escaping \ninformation directly, instead of only using it to answer queries. The resulting query under the relaxation \nis the same as (12), only with esca replaced with esc a \u00a3 {a(., o): o . ..esc}. (13) Note that ..esca \n. ..esca, so the resulting relaxed abstract query is still sound. 3.2 SHAREDACCESS Another property that \ncaptures the notion of thread non\u00adlocalityis SHAREDACCESS.Unlike THREADESCAPE,which deems an object to \nbe non-local simply when it is reachable from more than one thread, SHAREDACCESS deems an ob\u00adject to \nbe non-local when it is actually accessed from more than one thread a stronger property. We de.ne an \naccess to be an instance .eld or array ele\u00adment read/write. Intuitively, an object o is considered thread \nshared if there are two states along the execution trace .1 and .2, such that the two statements stmt(.1.p) \nand stmt(.2.p) access some .eld of the same object but are executing under different threads (.1.t .2.t). \nThis prop\u00ad = erty is easy to answer given the the auxiliary instrumentation ..accs, which provides for \neach object the set of threads that have accessed it:  SHAREDACCESS(p, v)(.) \u00a3 (14) ..p = p .|..accs(...(v))| \n> 1. The set of queries Qcorresponds to all .eld accessing state\u00adments, as in THREADESCAPE (Section 3.1). \nWe now de.ne the access sets accs. For the initial state, accs(o) is empty for each object o. Given the \nset accs(o) of state ., the set accs '(o) of the next state . ' includes threads t which satisfy any \nof the following: 1. t . accs(o), or 2. t is the current thread (..t = t) and a .eld of o is accessed \n(that is, stmt(..p) .{x.f = y, y = x.f} for any y and ...(x)= o).  The abstract query SHAREDACCESSa(p, \nv) is answered by seeing if v points to an object with an abstraction ...a(v) that has been accessed \nby more than one thread: SHAREDACCESSa(p, v)(.a) \u00a3 (15) .a .p = p .|.a .accs a(.a..a(v))| > 1. Recall \nthat .a.accsa(a) is the union of ..accs(o) over objects o with abstraction a. 3.3 SHAREDLOCK A thread-shared \nlock is an object used by a lock acquisition statement that is executed by more than one thread. The \nstatement lock v captures the three cases of lock acquisition in Java: (1) synchronized static methods, \nin which the lock object is the class object; (2) synchronized instance methods, in which the lock object \nis the this object; and (3) blocks of the form synchronized(v) { ... }, in which the lock object is v. \nOne natural application of the SHAREDLOCK client is synchronization removal [2, 3, 6 8, 26]. However, \nin re\u00adcent years this problem has been obviated by advances in hardware and JVMs. Static deadlock detection, \non the other hand, remains an important problem, which can ben\u00ade.t greatly from knowing which synchronization \noperations can safely be ignored. Byanalogyto SHAREDACCESS,wede.ne SHAREDLOCK by replacing accs with \nlcks: SHAREDLOCK(p, v)(.) \u00a3 (16) ..p = p .|..lcks(...(v))| > 1. The de.nition of lock sets lcks is similar \nto that of accs. Initially, lcks(o) is empty. Given the set lcks(o) of state ., the set lcks '(o) of \nthe next state . ' includes threads t which satisfy any of the following: 1. t . lcks(o), or 2. t is \nthe current thread (..t = t) and a lock is placed on o (stmt(..p)= lock v and ...(v)= o). The abstract \nquery SHAREDLOCKa(p, v) is de.ned accord\u00ading to SHAREDLOCK(p, v), but replacing . with .a , . with .a, \nand lcks with lcksa in (17). 3.4 NONSTATIONARYFIELD Stationary .elds were .rst introduced by Unkel and \nLam [32] as a generalization of the final keyword in Java. A .eld is considered stationary if all instances \nof the class declaring the .eld satisfy the property that all writes to the .eld occur before all reads. \nAs noted in [32], knowing which .elds are stationary pro\u00advides an object-oriented basis for reasoning \nabout aliasing relations across time; such information can be used, e.g., by a deadlock analysis when \nreasoning about aliasing between locks stored as object .elds. A more immediate application is in race \ndetection, where a pair of read/write statements on the same .eld f is race-free if f is stationary. \nWe de.ne the query on the negation of the stationary-.eld property. A .eld is non-stationary if there \nexists a state . in the trace such that NONSTATIONARYFIELD(f)(.) returns true, where NONSTATIONARYFIELD(f)(.) \nreturns true if the current statement (stmt(..p)) writes to .eld f of an object o which has been previously \nread ((o, f) . ..rds). Formally: NONSTATIONARYFIELD(f)(.) \u00a3 (17) (stmt(..p) = x.f = y) . (...(x),f) . \n..rds. We need to de.ne rds. Given the set rds of state ., the set rds ' of the next state . ' includes \neach (o, f) satisfying any of the following: 1. (o, f) . rds, or 2. the current statement reads from \n.eld f of object o (that is, stmt(..p) = y = x.f for any y and ...(x)= o).  The abstract query NONSTATIONARYFIELDa(f) \nis an\u00adswered analogously to NONSTATIONARYFIELD(f), but re\u00adplacing . with .a , . with .a, and rds with \nrdsa . 4. Abstractions In this section, we present a family of heap abstractions that we will study. \nAbstractions in this family re.ne the classic allocation site abstraction along three dimensions: call \nstack, object recency, and heap connectivity. Recall that an abstraction function a maps an object o \n. O in a state . . O to an abstract object a(., o) . A, where this mapping is computed using the appropriate \nauxiliary instrumentation ..u . U (see Figure 2). The allocation site abstraction, denoted ALLOC, maps \nan object to the site where it was allocated: ALLOC(., o)= ..as(o). (18)  Although very popular, the \nplain allocation site abstrac\u00adtion can be too coarse to prove many properties [17]. In the subsequent \nthree sections, we will walk through the three di\u00admensions of re.nement, using a THREADESCAPE example \nas motivation (Figure 4). 4.1 Call Stack Consider Example 1 in Figure 4. Variables x and y point to distinct \nobjects, but because they are allocated at the same allocation site (h1), the allocation site abstraction \ncannot distinguish between the two objects, and thus x cannot be proven thread-local at p1. The most \ncommon way to re.ne this abstraction is to use k-CFA with heap cloning; let {ALLOCk : k =0, 1, 2,... \n}denote these abstractions. Speci.cally, ALLOCk maps an object o to the allocation site of o (..as(o)) \nand the k most recent call sites on the stack of the thread at the point at which o was allocated (..cs(o)[1..k]): \nALLOCk(., o)= (..as(o), ..cs(o)[1..k]). (19) When k =0, we recover the original allocation site abstrac\u00adtion. \nWith call stack information, we can see that ALLOCk=1 can make the relevant distinctions in Example 1 \nto prove x thread-local at p1. The calling context is especially important in code where factory methods \nare frequently used, since in this case, many different objects are allocated at only one site and cannot \nbe distinguished by ALLOC. Large k values might be especially important when such methods exist deep \nin heavily-reused code such as the JDK standard library. One of the goals of this paper is to study how \nlarge k must be in order to prove various queries. We can also implement k-object sensitivity [20] in \nour framework by simply replacing the call sites in (19) with the appropriate allocation sites, but we \ndid not pursue this empirically. 4.2 Object Recency In some cases, no amount of call stack information \n(even k = 8) can help distinguish enough objects to prove a query. Consider Example 2 in Figure 4. The \nprogram repeat\u00adedly creates an object and renders it thread escaping. There\u00adfore, at p1, all objects \nexcept for the most recent one are escaping. But since all objects have the same allocation site and \ncall stack, even ALLOCk=8 cannot prove x thread-local at p1. This example therefore motivates re.ning \nallocation site abstractions to distinguish objects by their creation time. This is object recency idea, \nproposed by [4], which allows .ne-grained reasoning about loops. Recall that ..os is the sequence of \nobjects which have been allocated so far (in that order). For an object o (whose abstraction we re trying \nto compute), de.ne the subsequence of ..os which contains only objects with the same ALLOCk abstraction \nas o: relosk(., o)= (20) '' [o : o . ..os, ALLOCk(., o)= ALLOCk(., o ')]. Now de.ne the recency index \nof object o to be the position of o relative to the end of list relosk(., o), truncated at r: recidxk(., \no)= (21) min{indexof(reverse(relosk(., o)),o),r}. We have recidxk(., o)=0 if o is the last element of \nrelosk(., o), 1 if it is next to last, etc. Finally, de.ne abstraction RECENCYr to map an object o k \nto its ALLOCk abstraction along with its recency index: RECENCYr (., o)= (ALLOCk(., o), recidxk(., o)). \n(22) k Note that when r =0, we recover ALLOCk. For r> 0, we can distinguish between r +1 objects with \nthe same allocation site abstraction. The only setting consid\u00adered in past work is r =1, so for convenience, \nwe sim\u00adply write RECENCYk for RECENCYr=1 , RECENCYr for k RECENCYr , and RECENCY for RECENCYr=1 k=0k=0. \nReturning to Example 2, we see that RECENCY distin\u00adguishes between the last allocated object (which x \npoints to) and the others, allowing us to prove the query thread-local. The form of Example 2 is a common \nparadigm in server\u00adlike programs, where new objects are repeatedly constructed and subsequently released \nto other threads. The point is that during the construction phase, the objects are thread-local, but \nin order to prove this, one needs to distinguish the objects in the current loop iteration from the ones \nin previous loop iterations.  4.3 Heap Connectivity Note that the RECENCYr abstraction is heavily tied \nto single allocation sites; objects allocated at a site eventually collapse to the same abstraction after \nr objects are created. For pro\u00adgrams that maintain complex data structures, objects allo\u00adcated at one \nsite might enter into a diverse set of relationships and have different properties over time. For these \nprograms, more sophisticated shape analysis might be important. We consider two kinds of abstractions, \nPOINTEDTOBYk [33] and REACHFROMk [27], which combine shape pred\u00adicates with k-CFA. Standard shape analysis \npredicates are based on local variable names [16, 27], which offer more distinctions than allocation \nsites. However, we use allocation sites instead of variable names in order to focus on the effect of \nadding shape information without con.ating the contribu\u00adtion of variable names (which are another orthogonal \ndimen\u00adsion of re.nement which warrants further investigation). Speci.cally, POINTEDTOBYk maps an object \no to the set of allocation sites of objects which can reach o in at most one step: POINTEDTOBYk(., o)= \n(23) ' {ALLOCk(., o '): o = o . o ' .f = o}.  Figure 4. Three examples that show the strengths and \nweaknesses of various abstractions. In each example, the goal is to prove that x is thread-local at p1, \ncorresponding to the query at the .eld-accessing statement ... x.f .... The heap graphs at query time \nfor two abstractions are shown below each code snippet. In Example 1, x is local but y escapes. Since \nboth are allocated at h1, the allocation site abstraction (ALLOC) cannot prove x local, but ALLOCk=1, \nwhich augments h1 with the call site (p2 and p3) can. In Example 2, no k value suf.ces to distinguish \nx from the rest, but object recency does differentiate the last object allocated from the rest. In Example \n3, RECENCY is insuf.cient to distinguish x from the other elements of the linked-list, but REACHFROM \ncan because the other elements are reachable from an additional allocation site h1. Note this is a re.exive \nversion of the pointed-to-by relation (the allocation site of o is always included in the set), which \nis non-standard. Similarly, REACHFROMk maps an object o to the set of allocation sites of objects which \ncan reach o in a .nite number of steps: ..s ' REACHFROMk(., o)= {ALLOCk(., o '): o : o}. (24) Consider \nExample 3 in Figure 4. Here, a linked-list is cre\u00adated whose third node is rendered escaping. RECENCY \ncan\u00adnot distinguish between the second node and any following node except the last. One could increase \nr to let RECENCY make more distinctions, but r would have to grow linearly with the list s length, rendering \nthe approach impractical. Turning to REACHFROM, note that the second node is reachable from allocation \nsites h2 (the .rst node) and h3 (the second node), while the third node onwards are in addi\u00adtion reachable \nfrom h1. Therefore, REACHFROM is able to separate the second node and deem it thread-local. RECENCY and \nREACHFROM really capture different as\u00adpects of the heap one does not strictly dominates the other. Which \none works better depends on the benchmark and client involved, and thus for the remainder of the paper, \nwe turn to an empirical study to provide more insight. An implementation note: computing the REACHFROM \nabstraction is expensive since the abstraction of an object o depends on other objects in the heap, and \nthus each lo\u00adcal heap update requires computing reachability information and updating the abstraction \nfor a potentially large set of nodes. We use a dynamic data structure which maintains, for each object \no, the set of objects that can reach o. We ef.\u00adciently handle cases where a node is not on a cycle with \nany of its immediate predecessors; various other optimizations are also employed.  A.nal remark: Note \nthat POINTEDTOBY, REACHFROM, and RECENCY are state-dependent in that a(., o) depends on .. This dependence \ngives these abstractions more power, but also at some computational expense. In contrast, ALLOCk for \nany k value is state-independent. 5. Benchmarks We experimented with nine Java programs from the DaCapo \nbenchmark suite (version 9.12) [5]: antlr A parser generator and translator generator avrora A simulation \nand analysis framework for AVR microcontrollers batik A Scalable Vector Graphics (SVG) toolkit fop An \noutput-independent print formatter hsqldb An SQL relational-database engine luindex A text indexing tool \nlusearch A text search tool pmd A source-code analyzer xalan An XSLT processor for transforming XML \nThe suite provides three progressively larger inputs for each benchmark, via the -s [small|default|large] \noptions, hence\u00adforth called SMALL, MEDIUM, and LARGE inputs, respec\u00adtively. Due to computational constraints, \nwe used SMALL inputs for our experiments. In Section 6, we show that the effect of the larger inputs \non our conclusions is likely to be insigni.cant. Table 1 provides various statistics of the benchmarks. \nThe numbers refer only to classes, methods, and bytecodes that were visited during execution under SMALL \ninputs. The app. columns provide numbers for application code (i.e., excluding the JDK standard library) \nwhile the total columns provide numbers for the entire code. 6. Experimental Setup Our experiments were \nperformed using IBM J9VM 1.6.0 on 32-bit Linux machines. We implemented all our abstrac\u00adtions and clients \nusing Chord [1], an extensible static and dynamic program analysis framework for Java bytecode, built \non top of the Joeq compiler infrastructure [34] and the Javassist bytecode instrumentation library [9]. \nChord takes as input the class .les, main entry point, and input data for each benchmark. Chord .rst \nruns the uninstrumented bench\u00admark on the provided input data, and uses a lightweight JVM agent to observe \nall classes that are loaded, includ\u00ading both application and JDK library classes. It then in\u00adstruments \neach class that was loaded (with the exception of java.lang.J9VMInternals) to generate an event when\u00adever \none of the following types of actions is executed in a method of that class: an object allocation (each \nnew and newarray),  a write to a static .eld of reference type (each putstatic),  a read or write to \nan instance .eld or an array element of primitive or reference type (each getfield, putfield, aload, \nand astore),  an explicit thread creation site (each call to the start() method of class java.lang.Thread), \n a lock acquisition site (each monitorenter as well as the entry point of each synchronized method), \nand  the points immediately before and after method calls (each invokevirtual, invokestatic, etc.). \n Each of these events is required by some abstraction (e.g., the pre-and post-method call events are \nrequired by k-CFA) or by some client (e.g., the putstatic event is required by the THREADESCAPE client \nto detect when objects become reachable from a static .eld). Chord then runs the instrumented benchmark \non the input data. Chord allows for the option of processing the generated events on-the-.y in a separate \nJVM with an uninstrumented JDK that communicates with the event-generating JVM via a POSIX pipe.4 We \ndid not employ this on-the-.y option as it produced non-deterministic traces for highly concurrent benchmarks. \nInstead, we ran the program once and wrote the trace of generated events to a binary .le on disk. This \nallowed us to perform our analysis across different abstrac\u00adtions and clients on the same trace, yielding \nresults which are meaningful to compare. However, saving to disk forced us to use the SMALL inputs for \nthe DaCapo benchmarks be\u00adcause the MEDIUM and LARGE inputs resulted in enormous traces. The # events \ngenerated column in Table 2 shows the number of events generated on various input sizes; en\u00adtries marked \n? denote that the experiment either ran for too long or ran out of memory. While the number of reachable \nqueries did generally in\u00adcrease for larger inputs as more application code became reachable, there was \nnot much variation in the answers for the queries that were reachable under both SMALL and LARGE inputs. \nThis observation is quanti.ed in Table 2 for the THREADESCAPE client. The column % change in reachable \nqueries has entries of the form (-n, +m) mean\u00ading that the number of queries reachable under the indicated \nlarger input but not under the SMALL input was m% of the queries reachable under the SMALL input; likewise, \nthe number of queries reachable under the SMALL input but not 4 Using separate JVMs circumvents performance \nand correctness issues that would arise when event-processing code itself calls instrumented JDK libraries \nif one JVM were used.  benchmark version # classes # methods # bytecodes # threads app. total app. total \napp. total app. total antlr 2.7.2 89 290 845 1,663 102,426 147,774 1 5 avrora cvs-20090612 399 678 1,726 \n2,882 89,397 161,925 4 8 batik 1.7 613 1,300 2,308 5,676 157,575 388,601 2 8 fop 0.95 868 1,357 4,467 \n6,764 373,657 511,713 1 5 hsqldb 1.8.0.4 111 465 1,013 2,597 103,879 212,472 42 46 luindex 2.4.1 170 \n495 1,019 2,453 73,527 161,152 1 5 lusearch 2.4.1 126 448 734 2,142 55,053 132,677 9 13 pmd 4.2.5 420 \n817 2,394 4,086 173,045 268,497 2 7 xalan 2.7.1 400 720 2,529 3,879 184,390 261,396 9 12 Table 1. Statistics \nof the DaCapo benchmarks used in this study. benchmark # events generated (in millions) % change in re \nachable queries % change in true queries SMALL MEDIUM LARGE MEDIUM LARGE MEDIUM LARGE antlr avrora batik \nfop hsqldb luindex lusearch pmd xalan 45.7 18.3 59.4 44.1 50.1 6.0 16.6 13.2 29.6 772 3,193 572 235 849 \n? 2,184 940 2,219 1,926 18,468 731 -2,035 ? 4,662 ? ? -0.4, +90.1 -0.0, +0.2 -0.0, +21.5 -5.9, +5.2 -0.0, \n+0.3 ? -0.0, +1.8 -0.4, +11.1 -0.0, +0.0 -0.4, +90.1 -0.3, +5.8 -0.0, +38.2 --0.0, +0.3 ? -0.0, +1.8 \n? ? -0.0, +0.0 -0.0, +0.0 -0.0, +6.0 -0.3, +0.2 -0.0, +0.0 ? -0.0, +0.0 -0.0, +4.2 -0.0, +0.0 -0.0, +0.0 \n-0.0, +0.5 -0.0, +6.0 --0.0, +0.0 ? -0.0, +0.0 ? ? Table 2. Trace lengths and variation in results for \nTHREADESCAPE on different input data sets. A - means that the input size does not exist, and ? means \nthe experiment ran out of resources. abstraction sub-family re.nements {ALLOCk}k.N k-CFA {RECENCYrk}k.N,r.N \n k-CFA, object recency to depth r {POINTEDTOBYk}k.N k-CFA, heap connectivity {REACHFROMk}k.N k-CFA, \nheap connectivity Table 3. Abstractions we consider in this study. under the indicated larger input was \nn%. The most signi.\u00adcant increases are for antlr (90%) and batik (38%). The column % change in true queries \nis de.ned analo\u00adgously with true queries instead of reachable queries. By this metric, even the most \nsigni.cant changes are quite small: 6% for batik and 4% for pmd. 7. Results This section presents our \nempirical results on the family of abstractions considered in Section 4. Recall that we consider re.nements \nof the basic allocation site abstraction (ALLOC) along three dimensions: k-CFA, object recency, and heap \nconnectivity. Table 3 describes the abstractions we studied empirically. For each abstraction, we obtain \nprecision numbers for four clients and nine benchmarks. To navigate this large result space, we structure \nthis section around the following questions: Independent of abstraction, what is the fraction of true \nqueries (queries for which the answer is true) for a given client? (Section 7.1)  Which abstraction \nworks best for a given client? (Sec\u00adtion 7.2)  What is the effect of the k in k-CFA? (Section 7.3) \n What is the effect of the recency depth r? (Section 7.4)  How scalable are the high-precision abstractions? \n(Sec\u00adtion 7.5)  7.1 Client Statistics Table 4 shows the queries which were true in the concrete execution \nfor each benchmark and client (without abstrac\u00adtion). For the NONSTATIONARYFIELD client, the fraction \nof true queries is stable across benchmarks, but for the other three clients, this fraction varies considerably. \nIn particular, variation in THREADESCAPE and SHAREDACCESS corre\u00adlate with the amount and nature of concurrency \nin the bench\u00admark program (Table 1). Recall that THREADESCAPE measures reachability while SHAREDACCESS \nmeasures actual accesses. Indeed, we see the latter client has strictly fewer true queries, and moreover, \nTable 4. For each benchmark (row) and client (column), we report the number of total queries issued (|Q|), \nthe number of queries for which the answer is true, and the corresponding percentage. For all clients \nexcept for SHAREDLOCK, only queries from application code are reported; for SHAREDLOCK, queries from \nthe JDK standard library are also included because there are few locks in application code.  benchmark \nTH# true READESCAPE # total percent SH# true AREDACCESS # total percent S# true HAREDLOCK # total percent \nNONS# true T# total ATIONAR percent YFIELD antlr avrora batik fop hsqldb luindex lusearch pmd xalan 17 \n1983 312 3791 1674 139 144 513 3702 3490 5169 5028 13734 3817 3616 2490 6345 7717 0.5 38.4 6.2 27.6 43.9 \n3.8 5.8 8.1 48.0 0 1755 0 0 1095 0 51 45 496 3490 5169 5028 13734 3817 3616 2490 6345 7717 0.0 34.0 0.0 \n0.0 28.7 0.0 2.0 0.7 6.4 0 17 13 5 41 5 20 16 43 78 76 165 123 135 160 105 94 116 0.0 22.4 7.9 4.1 30.4 \n3.1 19.0 17.0 37.1 101 132 215 391 157 202 109 161 291 377 1037 988 2114 576 637 459 928 1306 26.8 12.7 \n21.8 18.5 27.3 31.7 23.7 17.3 22.3 the gap between the two clients is quite substantial for some benchmarks \n(notably fop and xalan), suggesting generally a higher use of static .elds.  7.2 Effect of Abstraction \non Clients In this section, we focus on four abstractions (ALLOC, ALLOCk=5, RECENCY, and REACHFROM), \nwhich allows us to explore the three dimensions of re.nement independently. Tables 5 8 provide the precision \nresults for the four clients on all nine benchmarks. Benchmark-client pairs where all queries are false \nare marked with - as a placeholder. A bold number indicates that it is within 1% of the precision of \nthe best abstraction on that benchmark-client pair. Let us start with the THREADESCAPE client. From Ta\u00adble \n5, we see that the plain allocation site abstraction is quite imprecise (average precision of 34.8%). \nALLOCk=5 improves the precision signi.cantly for the majority of the benchmarks (e.g., fop), but has \nlittle impact on oth\u00aders (e.g., batik). RECENCY is on average less effective than ALLOCk=5, though there \nare exceptions (e.g., hsqldb). REACHFROM performs slightly better than RECENCY. The SHAREDACCESS and \nSHAREDLOCK clients have similar behavior, as seen in Tables 6 and 7. In contrast to THREADESCAPE, these \ntwo clients receive little improve\u00adment from ALLOCk=5. On the other hand, RECENCY is quite effective, \noutperforming or tying the other three ab\u00adstractions uniformly across all benchmarks. REACHFROM seems \nto perform similarly to ALLOC and ALLOCk=5, sug\u00adgesting that these clients and benchmarks do not need \nso\u00adphisticated reasoning about the shape of the heap. Instead, the simple temporal notion captured by \nRECENCY seems to suf.ce. For NONSTATIONARYFIELD, the case for RECENCY is stronger. From Table 8, we see \nthat there is a huge gap between the precision of RECENCY (90.7%) and the other abstractions. Both ALLOC \nand ALLOCk=5 perform equally poorly (40 50%). REACHFROM sits approximately half way in between. It is \nintuitive that RECENCY performs well on NONSTATIONARYFIELD, as this client is intrinsically built around \na temporal property (writes must precede reads), and RECENCY focuses on making temporal distinctions. \nbenchmark ALLOC ALLOCk=5 RECENCY REACHFROM antlr 48.6 85.0 81.0 100.0 avrora 54.7 62.3 69.2 77.8 batik \n13.5 15.1 20.9 20.6 fop 36.3 99.3 42.8 41.3 hsqldb 62.6 69.0 94.3 ? luindex 6.3 97.2 6.8 6.8 lusearch \n14.3 90.0 19.0 19.6 pmd 12.4 87.1 14.9 14.6 xalan 64.0 78.9 78.7 76.6 average 34.8 76.0 47.5 ? Table \n5. Precision results for the THREADESCAPE client. benchmark ALLOC ALLOCk=5 RECENCY REACHFROM antlr - \n- - - avrora 96.2 96.2 98.6 ? batik - - - - fop - - - - hsqldb 51.3 56.8 87.0 ? luindex - - - - lusearch \n3.5 3.5 3.6 3.5 pmd 1.9 2.0 18.4 3.1 xalan 11.2 11.2 15.0 13.3 average 32.8 34.0 44.5 ? Table 6. Precision \nresults for the SHAREDACCESS client. To conclude this section, there is a fair amount of vari\u00adation in \nthe precision of abstractions. However, two trends stand out: (1) RECENCY is a clear winner in three \nof the four clients, and in the exceptional THREADESCAPE, k-CFA pro\u00advides the most utility. So far, we \nhave not seen REACHFROM to be very helpful, but we will see a case for REACHFROM  benchmark ALLOC ALLOCk=5 \nRECENCY REACHFROM antlr - - - - avrora 70.8 70.8 85.0 ? batik 100.0 100.0 100.0 81.2 fop 50.0 100.0 100.0 \n? hsqldb 77.4 78.8 91.1 ? luindex 50.0 100.0 100.0 100.0 lusearch 29.9 32.8 33.9 32.3 pmd 40.0 43.2 72.7 \n40.0 xalan 55.1 55.1 59.7 58.1 average 59.1 72.6 80.3 ? Table 7. Precision results for the SHAREDLOCK \nclient. benchmark ALLOC ALLOCk=5 RECENCY REACHFROM antlr 59.1 60.1 91.0 78.3 avrora 33.2 33.6 93.6 77.2 \nbatik 35.8 36.1 99.5 65.3 fop 42.0 44.9 90.9 68.2 hsqldb 45.4 49.5 94.6 ? luindex 78.0 84.2 94.8 94.8 \nlusearch 38.2 38.2 64.9 56.5 pmd 37.8 39.9 96.4 69.4 xalan 44.0 44.5 90.4 74.2 average 45.9 47.9 90.7 \n? Table 8. Precision results for the NONSTATIONARYFIELD client. in Section 7.3. As mentioned in Section \n4, shape analysis typically considers reachability from local variables rather than from allocation sites \n[16]. Since local variables gener\u00adally offer .ner distinctions than allocation sites, we expect a variable-based \nvariant of REACHFROM to perform better. However, the use of variables is an orthogonal dimension (we \ncould imagine RECENCY based on variables as well), which is outside the scope of this study.  7.3 Effect \nof k-CFA In the previous section, we saw that ALLOCk=5 was very useful for THREADESCAPE but not for the \nother clients. Is it because k needed to be higher? Could we have done just as well with k< 5 for THREADESCAPE? \nThis section answers these questions. Figure 5 plots the precision as a function of k for the four sub-families \nof abstractions in Table 3 (taking r =1). First, consider the THREADESCAPE client (.rst row). We see \nthat all abstractions work extremely poorly (precision around 20%) for small values of k, but there is \na phase tran\u00adsition where the precision shoots up to nearly 100%. The critical value varies across abstractions \nand benchmarks, but is around k =3 to k =6. A partial explanation to the phase transition is as follows: \nRecall that THREADESCAPE is de\u00ad.ned in terms of reachability, which is a sensitive property: a localized \nover-abstraction can render the entire subgraph downstream to be escaping. Note that on the batik benchmark, \neven for k = 8, both ALLOCk and RECENCYk fail to undergo the positive transi\u00adtion, but the heap connectivity \nabstractions (POINTEDTOBY and REACHFROM) do. On the remaining benchmarks, POINTEDTOBY and REACHFROM compare \nfavorably with the other abstractions. After all, the THREADESCAPE client is de.ned in terms of reachability. \nIn fact, we can rede.ne REACHFROM (24) to include a special label for static .elds. This change actually \nhas extremely positive consequences: the modi.ed REACHFROM abstraction would always have 100% precision \nas it will never con.ate objects reachable from static .elds from those which are not. On the other clients, \nwe see that increasing k does not help in general (even with k = 8). A notable exception is the pmd benchmark, \nwhere extremely large values of k make a signi.cant difference. In a separate experiment on SHAREDACCESS, \nwe saw that the precision did not reach its limit until k = 18. Further investigation is required to \nunderstand what properties of pmd make it an outlier, and in particular, which of its objects actually \nrequire a large k value. In summary, the utility of k depends heavily on the client (THREADESCAPE versus \nothers), and to a lesser ex\u00adtent on the benchmark (with the exception of pmd). Fur\u00adthermore, we .nd that \nREACHFROM performs well on THREADESCAPE it just takes larger k values to realize its potential, an instance \nof the synergy between two dimen\u00adsions of re.nement.  7.4 Effect of Recency Depth r In Section 7.2, \nwe saw that RECENCYr=1 performed well. In this section, we investigate whether increasing the recency \ndepth r adds any additional value. We study two sub-families of abstractions, RECENCYrk=0 and RECENCYr \n, for 0 = r = 6.5 The results are given k=8 in Table 9. We see that for most benchmark-client pairs, \nthe precision increases by a fair amount as r increases until some point, larger values of r cease to \nbe useful. An exception is lusearch, whose precision increases steadily up to r =6 across all clients. \nIn general, there seems to be a greater consistency across clients than for benchmarks, whereas for k-CFA, \nthe effect was the opposite. Finally, the gains from increasing k and increasing r are in general subadditive. \nHowever, one notable exception is THREADESCAPE on batik, where going from r =1 to r =2 when k =0 increases \nprecision by only 0.5% whereas going from r =1 to r =2 when k = 8 increases precision by 75.6%. We saw \na similar superadditive effect on the same benchmark-client pair in Section 7.3, where going 5 Note that \nunlike k = 8, r = 8 trivially allows us to distinguish all objects and thus always achieve 100% precision. \n  Figure 5. Effect of varying k for various abstractions. For THREADESCAPE, there is a sharp increase \nin precision around a critical value of k, but the precision does not depend much on k for the other \nclients (except on the pmd benchmark). from ALLOC to REACHFROM is useless if k< 5 but very useful if \nk = 5.  7.5 Tradeoff between Abstraction Precision and Size Thus far, we have focused on evaluating \nthe precision of ab\u00adstractions. However, another important property of abstrac\u00adtions is how well they \ncan scale inside a static analysis. To get at the notion of scalability in our dynamic analysis framework, \nwe introduce the size of an abstraction a, which we de.ne to be the number of abstract objects |A|. Figure \n6 plots the precision versus size of various ab\u00adstractions. Good abstractions live in the lower right-hand \ncorner of the plot (exhibiting high precision with low com\u00adplexity). As a baseline, we created a RANDOM \nabstrac\u00adtion. To construct this abstraction, we .x a .nite set of abstract values, A = {1,...,n}, and \nassign each ob\u00adject o independently to a random element of A. We tried n .{1000, 10000, 100000, 8}, where \nn = 8 corresponds exactly to the concrete result. RANDOM performs quite poorly on THREADESCAPE. As mentioned \nearlier, THREADESCAPE requires global rea\u00adsoning about the heap, which is sensitive to arbitrary col\u00adlapsing \nof concrete objects. On the other hand, for the NONSTATIONARYFIELD client, RANDOM actually per\u00adforms \nmuch better than the ALLOC, POINTEDTOBY and REACHFROM abstractions. This is an artifact of the client: \nwhen random objects of different types are collapsed, no in\u00adformation is actually lost with respect to \nstationarity because the two objects do not even have any .elds in common. Note that as k increases, \nthe size of the abstraction increases substantially, while the precision does not in\u00adcrease appreciably \napart from the phase transitions. (Note Table 9. Effect of increasing the recency depth r. Each cell \nshows the precision for the given RECENCY abstraction with a particular benchmark and client. Bold entries \nindicate precision within 1% of r =6.  r = 0 r = 1 RECENCYr = 2 r kr = 3 =0 r = 4 r = 5 r = 6 r = 0 \nr = 1 RECENCYr = 2 r kr = 3 =8 r = 4 r = 5 r = 6 THRESC batik luindex lusearch pmd 13.5 6.3 14.3 12.4 \n20.9 6.8 19.0 14.9 21.4 7.1 22.4 14.9 22.1 7.1 22.7 14.9 22.5 7.1 23.0 15.0 22.6 7.2 23.2 15.0 22.7 7.2 \n23.5 15.0 15.1 97.2 90.0 87.4 23.4 100.0 100.0 93.6 99.0 100.0 100.0 93.6 99.0 100.0 100.0 93.6 99.0 \n100.0 100.0 93.6 99.0 100.0 100.0 93.6 99.0 100.0 100.0 93.6 SHRDACC batik luindex lusearch pmd --3.5 \n1.9 --3.6 18.4 --3.9 20.5 --5.3 22.1 --5.6 25.0 --6.7 29.6 --10.6 29.6 --3.5 100.0 --3.6 100.0 --4.0 \n100.0 --5.5 100.0 --6.0 100.0 --7.6 100.0 --14.6 100.0 SHRDLCK batik luindex lusearch pmd 100.0 50.0 \n29.9 40.0 100.0 100.0 33.9 72.7 100.0 100.0 35.7 80.0 100.0 100.0 40.0 80.0 100.0 100.0 40.8 80.0 100.0 \n100.0 46.5 80.0 100.0 100.0 74.1 80.0 100.0 100.0 32.8 100.0 100.0 100.0 33.9 100.0 100.0 100.0 35.7 \n100.0 100.0 100.0 40.8 100.0 100.0 100.0 41.7 100.0 100.0 100.0 47.6 100.0 100.0 100.0 76.9 100.0 NONSTFLD \nbatik luindex lusearch pmd 35.8 78.0 38.2 37.8 99.5 94.8 64.9 96.4 99.5 99.0 73.6 97.0 99.5 99.0 87.9 \n97.6 99.5 99.0 88.6 97.6 99.5 99.0 90.1 98.2 99.5 99.0 90.8 98.2 36.1 84.2 38.2 65.2 99.5 98.1 65.3 98.2 \n99.5 99.0 79.0 98.8 99.5 99.0 93.2 98.8 99.5 99.0 95.6 98.8 99.5 99.0 95.6 99.4 99.5 99.0 95.6 99.4 \nthat the Y-axis is on a log scale.) Shape-based abstractions (POINTEDTOBY and REACHFROM), though sometimes \nef\u00adfective for THREADESCAPE, are quite costly because the abstract values are sets of allocation sites, \nwhich suffer from a combinatorial explosion. The number of abstract values may even exceed the number \nof concrete objects, since a single object may take on many abstractions during its life\u00adtime as its \nconnected heap changes. Summary Although there is a fair amount of variation in precision across benchmarks \nand clients, this variation can be explained in terms of two main trends: First, the best abstractions \nfor a client tend to correlate with the proper\u00adties of the client: NONSTATIONARYFIELD involves tempo\u00adral \nproperties and thus bene.ts from RECENCY, which offers temporal distinctions; THREADESCAPE involves heap \ncon\u00adnectivity properties and thus bene.ts from REACHFROM. Second, there are non-trivial interactions \nbetween the vari\u00adous re.nement dimensions (in one example, the potential of REACHFROM is only realized \nwith k-CFA for large enough k). Overall, we showed that ALLOC is clearly insuf.cient, and RECENCY is \na important dimension worthy of further exploration. 8. Related Work A comprehensive presentation and \nevaluation of the k-CFA heap abstraction, as well as other k-limited abstractions like k-object-sensitivity, \nis presented in [17]. The recency ab\u00adstraction was introduced in [4]. Shape analysis, which is a static \ntechnique for verifying properties of dynamically\u00adallocated data structures, is presented in [27]. Here, \nwe sur\u00advey work on evaluating the impact of k-limited heap abstrac\u00adtions on points-to and call-graph \nalgorithms (Section 8.1) and work on using connectivity-based heap abstractions to improve garbage collectors \n(Section 8.2) and detect memory bloat (Section 8.3). 8.1 Points-to and Call Graph Algorithms Liang et \nal. [19] present a set of empirical studies inves\u00adtigating the effect of calling contexts on the precision \nof Andersen s algorithm. In particular, the effect of context\u00adsensitive naming schemes on precision is \nevaluated, and the traditional calling context sensitivity is compared to object context sensitivity. \nThe precision of the points-to informa\u00adtion computed by each of the algorithms is evaluated vis\u00ada-vis \ndynamically-collected data. In an earlier and closely related study [18], the authors perform a similar \nset of exper\u00adiments (again, using reference information collected at run\u00adtime as an approximation of \nprecise reference information), concluding that hybrid approaches for identifying instances and computing \npoints-to information are needed. Lhot\u00b4ak and Hendren [17] follow a similar approach. They conduct an \nempirical study on a set of large Java benchmarks to evaluate the precision of subset-based points-to \nanalysis under three variations of context sensitivity: call string, ob\u00adject sensitivity, and the BDD-based \ncontext-sensitive algo\u00adrithm proposed by Zhu and Calman, and by Whaley and Lam. They evaluate the effects \nof these variations on the number of contexts generated, the number of distinct points\u00adto sets constructed, \nand the precision of call-graph construc\u00adtion, virtual-call resolution, and cast-safety analysis. Our \nstudy is complementary to theirs: we measure the effect of k-CFA on the precision of clients for much \nhigher values of k, but for a single execution, whereas they measure the same for smaller values of k \nbut over all executions. Some abstractions we consider are different from theirs (e.g., they do not evaluate \nheap connectivity and we do not evaluate k\u00adFigure 6. Tradeoff between abstraction precision and size \nratio for two clients and four benchmarks. (Note the logarithmic scale.) The size ratio is size of the \nabstraction |A| divided by the size of the ALLOC abstraction. Multiple points for a given abstraction \nindicate increasing values of k which monotonically increases both precision and size. Note that the \nupper-rightmost RANDOM point corresponds to the concrete execution.  object sensitivity). Finally, \nall our clients are motivated by concurrency and are different from theirs.  8.2 Garbage Collection \nHirzel and Hind [13] explore whether the connectivity of objects can yield useful partitions or improve \nexisting par\u00adtitioning schemes. They consider direct points-to relations, as well as transitive reachability \nrelations, and conclude that connectivity correlates strongly with object lifetimes, and is therefore \nuseful for partitioning objects. Shaham et al. [30] study the potential impact of different kinds of \nliveness information on the space consumption of a program in a garbage-collected environment. They mea\u00adsure \nthe time difference between the actual time an object is reclaimed by the garbage collector and the earliest \ntime in which this could have been done assuming the availability of liveness information. Four kinds \nof liveness information are considered: stack reference, global reference, heap refer\u00adence, and any combination \nof the above. Inoue et al. [14] introduce a precise method for predicting object lifetimes, where the \ngranularity of predictions is equal to the smallest unit of allocation. They construct predictors based \non execution traces including accurate records of each object s allocation and death, and rely on a (.xed-length) \npre.x of the stack at the time of allocation to disambiguate allocation contexts and thus improve the \nprecision of the pre\u00addictor. Their empirical results suggest that for some applica\u00adtions, object lifetimes \ncan be predicted to the byte using the allocation-context heuristic. This .nding resonates well with \nour empirical results, which show that the THREADESCAPE client bene.ts greatly from high k values.  \nThe approach taken in [14] is inspired by the work of Seidl and Zorn [28, 29], which attempts to predict \nthe refer\u00adence and lifetime behavior of heap objects according to four categories: highly referenced, \nshort lived, low referenced, and other. Similar to [14], prediction relies on a training trace containing \nextensive information, including the number of loads and stores to each object, the call stack at the \ntime of each allocation, and the size of the allocated object. Seidl and Zorn use a stack-based prediction \nscheme, and conclude that it is important to choose the right depth for the stack predictor. Their experiments \nsuggest that a depth of 3 yields an effective predictor. While all four of these studies provide insightful \nobser\u00advations that may be leveraged by a static analysis, their goal differs from ours. Our goal is to \nevaluate static abstractions explicitly, so as to provide insight to static-analysis devel\u00adopers, whereas \nthese studies focus on (concrete) empirical results, and establish heuristics that may bene.t a garbage \ncollector.  8.3 Memory Bloat Mitchell [21] investigates ways to summarize the memory footprint of object-oriented \napplications in order to discover cases where high-overhead collections, bulky data models and large \ncaches are used. As part of the analysis, he devel\u00adops a catalog of ownership structures, which are shown \nto be prevalent in large-scale applications, and are therefore pow\u00aderful units of aggregation and .ltering. \nIn a related study, Mitchell and Sevitsky [22] study applications posing large runtime memory requirements. \nThey introduce health sig\u00adnatures to distinguish cases where a large memory footprint enables an important \nrequirement (e.g., the use of a cache to ameliorate a performance problem) from instances where memory \nis used excessively. Also closely related is Yeti [23], a tool for summarizing memory usage to uncover \nthe costs of design decisions. This is accomplished through a series of progressive abstractions and \ncorresponding visualizations. The goal behind Yeti is to assist developers in discovering instances where \nlarge-scale Java applications suffer from memory problems due to an inef.cient design, or lifetime bugs \nsuch as leaks. Similar to our study, these works are concerned with ab\u00adstracting the concrete heap. However, \nthe abstractions ad\u00advocated by these studies are not inspired by static analysis; rather, they are more \nheuristic in nature, and are tuned to\u00adward an interactive process wherein simpli.cation of the concrete \nheap is bene.cial (indeed mandated) as part of a reasoning process leading to the identi.cation of evasive \nbugs and design .aws. Dufour et al. [11] introduce blended analysis, an algo\u00adrithm combining a dynamic \nrepresentation of the program s calling structure with a static analysis applied to a region of that \ncalling structure with observed performance problems. In a case study they perform, they show that blended \nescape analysis is highly effective at localizing a performance prob\u00adlem due to overuse of temporary \nstructures. In a subsequent study [12], new metrics are added to quantify key properties of temporary \ndata structures and their uses, and an empir\u00adical evaluation is conducted to characterize temporaries \nin framework-intensive applications. Dufour s studies are similar to our work in that a static representation \nof the program is computed on top of a dy\u00adnamic trace. However, whereas Dufour s focus is on localiz\u00ading \na particular problem or behavior (which is present during the concrete execution), our goal is to understand \nwhich heap abstractions are likely to be good for static analysis. 9. Conclusion With the goal of .nding \ngood heap abstractions for static analysis, we have investigated a family heap abstractions on four clients \nand nine benchmarks. Our evaluation of these abstractions revealed many interesting properties about \nthe role and utility of k-CFA, object recency and heap connec\u00adtivity. We believe these results can serve \nas a useful guide for developing static analyses. References [1] Chord: A static and dynamic program \nanalysis framework for Java. http://code.google.com/p/jchord/. [2] J. Aldrich, C. Chambers, E. G. Sirer, \nand S. J. Eggers. Static analyses for eliminating unnecessary synchronization from Java programs. In \nProceedings of the 6th Intl. Static Analysis Symp. (SAS), pages 19 38, 1999. [3] J. Aldrich, E. Sirer, \nC. Chambers, and S. J. Eggers. Com\u00adprehensive synchronization elimination for Java. Science of Computer \nProgramming, 47(2-3):91 120, 2003. [4] G. Balakrishnan and T. W. Reps. Recency-abstraction for heap-allocated \nstorage. In Proceedings of the 13th Intl. Static Analysis Symp. (SAS), pages 221 239, 2006. [5] S. M. \nBlackburn, R. Garner, C. Hoffman, A. M. Khan, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Frampton, \nS. Z. Guyer, M. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4c, T. \nVanDrunen, D. von Dincklage, and B. Wiedermann. The DaCapo benchmarks: Java benchmarking development \nand analysis. In Proceedings of the 21st ACM SIGPLAN Conf. on Object-Oriented Pro\u00adgraming Systems, Languages \nand Applications (OOPSLA), pages 169 190, 2006. [6] B. Blanchet. Escape analysis for Java: Theory and \npractice. ACM Transactions on Programming Languages and Systems, 25(6):713 775, 2003. [7] B. Blanchet. \nEscape analysis for object-oriented languages: Application to Java. In Proceedings of the 14th ACM SIG-PLAN \nConf. on Object-Oriented Programming Systems, Lan\u00adguages and Applications (OOPSLA), pages 20 34, 1999. \n[8] J. Bogda and U. H\u00a8olzle. Removing unnecessary synchro\u00adnization in Java. In Proceedings of the 14th \nACM SIGPLAN  Conf. on Object-Oriented Programming Systems, Languages and Applications (OOPSLA), pages \n35 46, 1999. [9] S. Chiba and M. Nishizawa. An easy-to-use toolkit for ef.\u00adcient Java bytecode translators. \nIn Proceedings of the 2nd Intl. Conf. on Generative Programming and Component Engineer\u00ading (GPCE), pages \n364 376, 2003. [10] J.-D. Choi, K. Lee, A. Loginov, R. O Callahan, V. Sarkar, and M. Sridharan. Ef.cient \nand precise datarace detection for multithreaded object-oriented programs. In Proceedings of the ACM \nSIGPLAN Conf. on Programming Language Design and Implementation (PLDI), pages 258 269, 2002. [11] B. \nDufour, B. G. Ryder, and G. Sevitsky. Blended analysis for performance understanding of framework-based \napplications. In Proceedings of the ACM SIGSOFT Intl. Symp. on Software Testing and Analysis (ISSTA), \npages 118 128, 2007. [12] B. Dufour, B. G. Ryder, and G. Sevitsky. A scalable technique for characterizing \nthe usage of temporaries in framework\u00adintensive Java applications. In Proceedings of the 16th ACM SIGSOFT \nIntl. Symp. on Foundations of Software Engineering (FSE), pages 59 70, 2008. [13] M. Hirzel, J. Henkel, \nA. Diwan, and M. Hind. Understand\u00ading the connectivity of heap objects. In Proceedings of the Workshop \non Memory Systems Performance (MSP) and the Intl. Symp. on Memory Management (ISMM), pages 143 156, 2003. \n[14] H. Inoue, D. Stefanovic, and S. Forrest. On the prediction of java object lifetimes. IEEE Transactions \non Computers, 55: 880 892, 2006. [15] K. Lee and S. P. Midkiff. A two-phase escape analysis for par\u00adallel \nJava programs. In Proceedings of the 15th Intl. Conf. on Parallel Architectures and Compilation Techniques \n(PACT), pages 53 62, 2006. [16] T. Lev-Ami, T. Reps, M. Sagiv, and R. Wilhelm. Putting static analysis \nto work for veri.cation: A case study. In In Intl. Symp. on Software Testing and Analysis, pages 26 38, \n2000. [17] O. Lhot\u00b4ak and L. Hendren. Context-sensitive points-to anal\u00adysis: is it worth it? In Proceedings \nof the 15th Intl. Conf. on Compiler Construction, pages 47 64, 2006. [18] D. Liang, M. Pennings, and \nM. J. Harrold. Evaluating the pre\u00adcision of static reference analysis using pro.ling. In Proceed\u00adings \nof the ACM SIGSOFT Intl. Symp. on Software Testing and Analysis (ISSTA), pages 22 32, 2002. [19] D. Liang, \nM. Pennings, and M. J. Harrold. Evaluating the impact of context-sensitivity on andersen s algorithm \nfor java programs. In Proceedings of the ACM SIGPLAN-SIGSOFT Workshop on Program Analysis For Software \nTools and Engi\u00adneering (PASTE), pages 6 12, 2006. [20] A. Milanova, A. Rountev, and B. Ryder. Parameterized \nobject sensitivity for points-to and side-effect analyses for Java. In Proceedings of the ACM SIGSOFT \nIntl. Symp. on Software Testing and Analysis (ISSTA), pages 1 11, 2002. [21] N. Mitchell. The runtime \nstructure of object ownership. In Proceedings of the 20th European Conf. on Object-Oriented Programming \n(ECOOP), pages 74 98, 2006. [22] N. Mitchell and G. Sevitsky. The causes of bloat, the limits of health. \nIn Proceedings of the 22nd ACM SIGPLAN Conf. on Object-Oriented Programming Systems, Languages and Applications \n(OOPSLA), pages 245 260, 2007. [23] N. Mitchell, E. Schonberg, and G. Sevitsky. Making sense of large \nheaps. In Proceedings of the 23rd European Conf. on Object-Oriented Programming (ECOOP), pages 77 97, \n2009. [24] M. Naik and A. Aiken. Conditional must not aliasing for static race detection. In Proceedings \nof the 34th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages (POPL), pages 327 338, 2007. \n[25] M. Naik, A. Aiken, and J. Whaley. Effective static race detection for Java. In Proceedings of the \nACM SIGPLAN Conf. on Programming Language Design and Implementation (PLDI), pages 308 319, 2006. [26] \nE. Ruf. Effective synchronization removal for Java. In Pro\u00adceedings of the ACM SIGPLAN Conf. on Programming \nLan\u00adguage Design and Implementation (PLDI), pages 208 218, 2000. [27] M. Sagiv, T. W. Reps, and R. Wilhelm. \nParametric shape anal\u00adysis via 3-valued logic. ACM Transactions on Programming Languages and Systems, \n24(3):217 298, 2002. [28] M. L. Seidl and B. G. Zorn. Segregating heap objects by reference behavior \nand lifetime. SIGOPS Oper. Syst. Rev., 32 (5):12 23, 1998. [29] M. L. Seidl, M. L. Seidl, M. L. Seidl, \nB. G. Zorn, B. G. Zorn, and B. G. Zorn. Predicting references to dynamically allocated objects. Technical \nreport, 1997. [30] R. Shaham, E. K. Kolodner, and M. Sagiv. Estimating the impact of heap liveness information \non space consumption in Java. In Proceedings of the Workshop on Memory Systems Performance (MSP) and \nthe Intl. Symp. on Memory Manage\u00adment (ISMM), pages 171 182, 2002. [31] O. Shivers. Control-.ow analysis \nin Scheme. In Proceed\u00adings of the ACM SIGPLAN Conf. on Programming Language Design and Implementation \n(PLDI), pages 164 174, 1988. [32] C. Unkel and M. S. Lam. Automatic inference of stationary .elds: a \ngeneralization of Java s .nal .elds. In Proceedings of the 35th ACM SIGPLAN-SIGACT Symp. on Principles \nof Programming Languages (POPL), pages 183 195, 2008. [33] E. Y.-B. Wang. Analysis of Recursive Types \nin an Imperative Language. PhD thesis, Univ. of Calif., Berkeley, CA, 1994. [34] J. Whaley. Joeq: A virtual \nmachine and compiler infras\u00adtructure. Science of Computer Programming, 57(3):339 356, 2005. [35] R. M. \nYoo, Y. Ni, A. Welc, B. Saha, A.-R. Adl-Tabatabai, and H.-H. S. Lee. Kicking the tires of software transactional \nmemory: why the going gets tough. In Proceedings of the 20th ACM Symp. on Parallelism in Algorithms and \nArchitectures (SPAA), pages 265 274, 2008.    \n\t\t\t", "proc_id": "1869459", "abstract": "<p>The quality of a static analysis of heap-manipulating programs is largely determined by its <i>heap abstraction</i>. Object allocation sites are a commonly-used abstraction, but are too coarse for some clients. The goal of this paper is to investigate how various refinements of allocation sites can improve precision. In particular, we consider abstractions that use call stack, object recency, and heap connectivity information. We measure the precision of these abstractions dynamically for four different clients motivated by concurrency and on nine Java programs chosen from the DaCapo benchmark suite. Our dynamic results shed new light on aspects of heap abstractions that matter for precision, which allows us to more effectively navigate the large space of possible heap abstractions</p>", "authors": [{"name": "Percy Liang", "author_profile_id": "81323492904", "affiliation": "UC Berkeley, Berkeley, CA, USA", "person_id": "P2354083", "email_address": "", "orcid_id": ""}, {"name": "Omer Tripp", "author_profile_id": "81435610768", "affiliation": "Tel-Aviv University, Tel-Aviv, Israel", "person_id": "P2354084", "email_address": "", "orcid_id": ""}, {"name": "Mayur Naik", "author_profile_id": "81100223912", "affiliation": "Intel Labs Berkeley, Berkeley, CA, USA", "person_id": "P2354085", "email_address": "", "orcid_id": ""}, {"name": "Mooly Sagiv", "author_profile_id": "81100150928", "affiliation": "Tel-Aviv University, Tel-Aviv, Israel", "person_id": "P2354086", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869494", "year": "2010", "article_id": "1869494", "conference": "OOPSLA", "title": "A dynamic evaluation of the precision of static heap abstractions", "url": "http://dl.acm.org/citation.cfm?id=1869494"}