{"article_publication_date": "10-17-2010", "fulltext": "\n The Spoofax Language Workbench Rules for Declarative Speci.cation of Languages and IDEs Lennart C. L. \nKats Delft University of Technology l.c.l.kats@tudelft.nl Abstract Spoofax is a language workbench for \nef.cient, agile devel\u00adopment of textual domain-speci.c languages with state-of\u00adthe-art IDE support. Spoofax \nintegrates language processing techniques for parser generation, meta-programming, and IDE development \ninto a single environment. It uses concise, declarative speci.cations for languages and IDE services. \nIn this paper we describe the architecture of Spoofax and in\u00adtroduce idioms for high-level speci.cations \nof language se\u00admantics using rewrite rules, showing how analyses can be reused for transformations, code \ngeneration, and editor ser\u00advices such as error marking, reference resolving, and content completion. \nThe implementation of these services is sup\u00adported by language-parametric editor service classes that \ncan be dynamically loaded by the Eclipse IDE, allowing new languages to be developed and used side-by-side \nin the same Eclipse environment. Categories and Subject Descriptors D.2.3 [Software En\u00adgineering]: Coding \nTools and Techniques; D.2.6 [Software Engineering]: Programming Environments General Terms Languages \n1. Introduction Domain-speci.c languages (DSLs) provide high expressive power focused on a particular \nproblem domain [38, 47]. They provide linguistic abstractions over common tasks within a domain, so that \ndevelopers can concentrate on ap\u00adplication logic rather than the accidental complexity of low\u00adlevel implementation \ndetails. DSLs have a concise, domain\u00adspeci.c notation for common tasks in a domain, and al\u00adlow reasoning \nat the level of these constructs. This allows them to be used for automated, domain-speci.c analysis, \nveri.cation, optimization, parallelization, and transforma\u00adtion (AVOPT) [38]. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA/SPLASH 10, October 17 21, 2010, Reno/Tahoe, \nNevada, USA. Copyright c &#38;#169; 2010 ACM 978-1-4503-0203-6/10/10. . . $10.00 Eelco Visser Delft University \nof Technology visser@acm.org For developers to be productive with DSLs, good in\u00adtegrated development \nenvironments (IDEs) for these lan\u00adguages are essential. Over the past four decades, IDEs have slowly \nrisen from novelty tool status to becoming a funda\u00admental part of software engineering. In early 2001, \nIntelliJ IDEA [42] revolutionized the IDE landscape [17] with an IDE for the Java language that parsed \n.les as they were typed (with error recovery in case of syntax errors), performed se\u00admantic analysis \nin the background, and provided code nav\u00adigation with a live view of the program outline, references \nto declarations of identi.ers, content completion proposals as programmers were typing, and the ability \nto transform the program based on the abstract representation (refactor\u00adings). The now prominent Eclipse \nplatform, and soon af\u00adter, Visual Studio, quickly adopted these same features. No longer would programmers \nbe satis.ed with code editors that provided basic syntax highlighting and a build button. For new languages \nto become a success, state-of-the-art IDE support is now mandatory. For the production of DSLs this requirement \nis a particular problem, since these languages are often developed with much fewer resources than general \npurpose languages. There are .ve key ingredients for the construction of a new domain-speci.c language. \n(1) A parser for the syntax of the language. (2) Semantic analysis to validate DSL pro\u00adgrams according \nto some set of constraints. (3) Transfor\u00admations manipulate DSL programs and can convert a high\u00adlevel, \ntechnology-independent DSL speci.cation to a lower\u00adlevel program. (4) A code generator that emits executable \ncode. (5) Integration of the language into an IDE. Traditionally, a lot of effort was required for each \nof these ingredients. However, there are now many tools that support the various aspects of DSL development. \nParser generators can automatically create a parsers from a grammar. Mod\u00adern parser generators can construct \nef.cient parsers that can be used in an interactive environment, supporting error re\u00adcovery in case of \nsyntax-incorrect or incomplete programs. Meta-programming languages [3, 10, 12, 20, 35] and frame\u00ad works \n[39, 57] make it much easier to specify the semantics of a language. Tools and frameworks for IDE development \nsuch as IMP [7, 8] and TMF [56], simplify the implemen\u00ad tation of IDE services. Other tools, such as \nthe Synthesizer Generator [41], Centaur [2], and Lrc [37] can even generate a complete IDE from a syntactic \n(and sometimes semantic) speci.cation of a language. Language workbenches With a wealth of language \ncon\u00adstruction tools, a need arose for comprehensive tools that integrated these different solutions and \nguided the develop\u00adment of languages. Fowler described the trend of integrating the development and use \nof DSLs into a single IDE envi\u00adronment, and introduced the term language workbenches for these tools \n[16]. In [18] he described this development as follows: Whereas external and internal DSLs have been \naround for longer than I ve been programming, language workbenches are a much newer animal. These tools \nsupport DSL creation not just in terms of parsing and code generation but also in providing a better \nediting experience for DSL users. Fowler studied a number of practical, modern examples of language workbenches \nthat allow developers to de.ne and use text-based DSLs, including the Meta Programming Sys\u00adtem (MPS)[15, \n25] and Intentional Programming [43]. In his article he also spoke of visual editor environments such \nas MetaEdit+ [33] and DSL Tools [9], but as these have a very different programming model and do not \nsupport text\u00adbased languages, we will not discuss them here. Fowler de\u00adscribed that language workbenches \ngreatly increase the cost\u00adeffectiveness of developing a new language, perhaps even to the point that \nthey can be developed for a single appli\u00adcation as sometimes strived for in language-oriented pro\u00adgramming \n[16, 54]. Rather than using a pure text represen\u00ad tation, the workbenches Fowler described store the \nabstract representation of a DSL program, and use syntax-directed (or projectional) editing to manipulate \nthis representation directly. Based on an abstract representation of a program, these workbenches can \nanalyze a DSL program, perform transformations on it, and may show different views. While it is very \nimportant to maintain an abstract repre\u00adsentation of a program to enable IDE features such as those made \npopular by IntelliJ, this does not imply that it should be the principal storage representation of programs, \ncertainly given the disadvantages of that approach. Fowler noted the need to be able to store incomplete \nand contradictory in\u00adformation in the abstract representation, which is not trivial in this model. Other \ndisadvantages include the lack of free text editing; incompatibility with standard, text-based ver\u00adsion \ncontrol systems and issue trackers; and having no way to import artifacts from other (possibly legacy) \ntools or to edit programs with other tools (leading to vendor lock-in). A free text editing approach, \nbased on modern parser gen\u00aderators, seems much more attractive, since it avoids these problems without \nprecluding the advantages of a language workbench. Requirements For a language workbench based on freely \neditable, textual languages, we identify the following re\u00adquirements: (1) It must provide an integrated \nenvironment for both de.n\u00ading languages and using generated editors. (2) Conversely, it must be possible \nto deploy generated edi\u00adtors separately from the workbench for use by end de\u00advelopers, who may not be \ninterested to work in a meta\u00adprogramming environment. (3) The environment must provide state-of-the-art \nIDE fa\u00adcilities. It should provide a substantial number of mod\u00adern, language-speci.c editor services \nsuch as automatic indentation and bracket insertion, on-the-.y error mark\u00aders, reference resolving, and \ncontent completion. Many of these services require an abstract representation of a DSL program; the editor \nshould schedule parsing and se\u00admantic analysis in the background. (4) The environment should support \nef.cient, agile language de.nition, through incremental and selective develop\u00adment of IDE services, which \nrequires separation of con\u00adcerns between language speci.cations and pure IDE logic.  Related work The \nMeta-Environment [34, 44] was one of the .rst tools that could be described as a language work\u00adbench \n(avant la lettre), combining language speci.cation us\u00ading ASF+SDF [12] and generated editors for using \nthese lan\u00ad guages (1). While it supported the construction of editors for end developers, these could \nnever really escape the meta\u00adenvironment (2). Conceived in the early nineties, it did not yet support \nmodern IDE features (3) based on real-time pars\u00ading and semantic analysis as programs are edited; error \nre\u00adcovery was unavailable for the generated GLR parser at the time. Rather, it required developers to \nsave a .le and wait for a list of errors in a separate view. While it allowed the ASF+SDF language to \nspecify language syntax and seman\u00adtics, the meta-environment offered little opportunity to cus\u00adtomize \ngenerated editor services (4). More recent endeavors, which fuse language speci.ca\u00adtion and the construction \nof modern, interactive IDE compo\u00adnents (3), are EMFText [22], MontiCore [36] TEF [55], and Xtext [14]. \nThese approaches all follow the same general architec\u00adture. They de.ne their own language for the description \nof grammars. They may allow annotations in the grammar for the description of syntactic editor services \n[36], or, by an\u00ad notating lexical use-def relations, basic semantic editor ser\u00advices [14, 22]. From this \ngrammar they generate a new, sep\u00ad arate Eclipse plugin project (2). However, rather than pro\u00adviding a \ntruly integrated environment, they require a second Eclipse instance to load this plugin (1). For IDE \nsupport be\u00adyond the basic services that can be derived from the gram\u00admar, the workbenches allow developers \nto write fragments of Java code to customize the generated plugin (4). The work\u00adbenches either use generated \nJava classes or an Eclipse Mod\u00adeling Framework (EMF) metamodel [6] for the abstract syn\u00ad tax. Transformations \nare carried out using Java visitors or external, EMF-based tooling (4). The tools include string template \nengines for code generation. Spoofax In this paper we present Spoofax, a language workbench that enables \nef.cient, agile development of soft\u00adware languages with state-of-the-art IDE support based on concise, \ndeclarative speci.cations. Spoofax is an integrated environment for the speci.ca\u00adtion of languages and \naccompanying IDE support in Eclipse. Generated editors can be dynamically loaded into the meta Eclipse \ninstance enabling smooth switching between devel\u00adopment of the language and development with the language \nunder construction. Spoofax also supports the generation of a stand-alone plugin for the language under \nconstruction that can be deployed to end developers without exposing the meta-programming facilities. \nSpoofax supports a wide range of editor services based on tightly integrated, real-time application of \nsyntactic and semantic analyses. Analyses are based on the structured ab\u00adstract representation provided \nby a live parse of the text in the editor, which uses a parser scheduled in a background thread. Error \nrecovery [11, 29] ensures that editor services function even in the presence of (multiple) syntactic \nerrors. Origin tracking [46] techniques are used to relate the re\u00ad sults of analysis back to the text \nin the editor without requir\u00ading preservation of layout information in the speci.cation of analyses and \ntransformations. These and other techniques for the implementation of editor services have been fac\u00adtored \ninto language-parametric components, allowing lan\u00adguage developers to focus purely on the language-speci.c \nparts of a compiler and IDE. Spoofax supports language de.nition with declarative domain-speci.c languages. \nThe modular, declarative syntax de.nition formalism SDF [21, 49] is closed under compo\u00ad sition, ensuring \nsupport for language extensions and em\u00adbeddings [5]. The Stratego transformation language pro\u00ad vides \na uni.ed formalism for concise speci.cation of anal\u00adysis, transformation, and code generation, enabling \nreuse of analysis rules for multiple purposes, including dynamic rules [3] for context-sensitive analysis \nand transformation. We have developed idioms for language speci.cation based on rewrite rules that can \nbe used in batch compilation as well as in interactive editor services. Editor descriptor DSLs pro\u00advide \nthe bridge between speci.cation of syntax and seman\u00adtics and the language parametric editor service components, \nproviding a pluggable interface supporting the language en\u00adgineer in adding new operations to the editor. \nTo show that our approach is practical, we describe the speci.cation of a web language and report on \npractical ex\u00adperience with the implementation of other languages and in\u00adtegration with external tools. \nThe Spoofax language workbench is available from http://spoofax.org. Previous work The Spoofax project \nstarted in 2007 with the development of Eclipse editors dedicated to Stratego and SDF [27]. In order \nto provide IDE support for languages built with Stratego and SDF, we developed a prototype of a new Spoofax \nenvironment built from scratch, described in [30], where we showed how DSLs can be used to de.ne presentational \neditor services, and how such de.nitions can be derived from a grammar. We also sketched an interface \nfor error markers and reference resolving. The present paper shows how a single semantic description \nbased on rewrite rules can be used for both compilation and interactive edi\u00adtor services such as error \nmarkers, reference resolving, and content completion. The new Spoofax environment comes with full-featured, \nbootstrapped IDE support for the meta\u00adlanguages used for language speci.cation, as well as meta\u00adprogramming \nfeatures such as the ability to apply transfor\u00admations directly from the environment. Outline We proceed \nas follows. We .rst describe the ar\u00adchitecture of Spoofax and the general anatomy of Spoofax language \nde.nitions in Section 2. In Section 3 we discuss syntax de.nition and the speci.cation of syntactic editor \nser\u00advices. In Section 4 we discuss the de.nition of language se\u00ad mantics: analysis, transformations, \ncode generation, and ed\u00aditor services based on these techniques. We report on experi\u00adence with language \ndevelopment using Spoofax in Section 5. In Section 6 we elaborate on the implementation of the lan\u00ad guage \nworkbench. Finally, we discuss related work and di\u00adrections for future work in Sections 7 and 8, and \nconclude in Section 9. 2. An Overview of Spoofax In this section we give an overview of Spoofax from \nthe point of view of three categories of software developers. End developers of a Spoofax IDE work with \nthe edi\u00adtor services specialized to the their (domain-speci.c) lan\u00adguage. The developers of Spoofax itself \nmaintain its archi\u00adtecture and language-parametric components. Language en\u00adgineers use Spoofax to develop \na language de.nition, i.e. the language-speci.c elements of an IDE. 2.1 Editor Services Modern IDEs provide \na wide variety of language-speci.c editor services, which are based on tightly integrated, real\u00adtime \napplication of syntactic and semantic analysis. Figure 1 shows a selection. The editor checks the syntax \nof the program text, marks syntactic errors inline, and highlights text elements based on the syntactic \nstructure as the developer types. The syntac\u00adtic state of the parser at the cursor is used for editor \nser\u00advices such as syntax completion, automatic bracket inser\u00adtion, bracket highlighting, automatic indentation, \nand com\u00adment insertion. The abstract representation provided by the parser enables code folding, the \noutline view, and navigation using the quick outline feature.  Figure 1. Editor services for a web language. \nBased on live semantic analysis of the abstract represen\u00adtation produced by the parser, the editor displays \nerror and warning markers in the code. Program navigation and un\u00adderstanding is supported by reference \nresolving, occurrence highlighting, and hover help, which use semantic analysis to reveal relations between \nelements of a program. Content completion shows the developers the valid ways to complete the current \nconstruct. Transformation and code generation, using the results of semantic analysis, can be triggered \neach time the editor is saved, or on demand through the Trans\u00adform drop down menu or using context menus. \nIn addition to the language-speci.c editor services pro\u00advided by a Spoofax plugin, Eclipse is an extensible \nenviron\u00adment that offers many language-generic development facili\u00adties such as plugins for version control, \nbuild management, and issue tracking, and the package explorer view (left of Figure 1) that gives an \noverview of all projects and is used for resource management.  2.2 Component Architecture Traditionally \nsoftware languages are developed .rst as stand-alone compilers and IDEs are later added, typically requiring \na signi.cant reimplementation of many of the in\u00adgredients of the compiler to realize the implementation \nof editor services. The components of a compiler parser, semantic analysis, transformations, and code \ngeneration also play a central role in editor services based on the ab\u00adstract syntax and semantic analysis \nof a program. Spoofax has been designed to factor out language independent im\u00adplementation knowledge \ninto the generic Spoofax libraries. Furthermore, language-speci.c de.nitions are de.ned such that they \ncan be reused in several IDE components. Figure 2 gives an overview of basic compiler components (marked \nwith an asterisk) and editor services in an IDE. The depen\u00addencies between these components can be characterized \nas generative dependencies a component can be automati\u00adcally derived from another and usage dependencies \na component calls another. The grammar and parser are at the root of the depen\u00addency graph in Figure \n2 (A), since the syntactic structure of programs is the basis for the implementation of all other services. \nIn particular, the services for presentation in Fig\u00adure 2 (B) and editing in Figure 2 (C) are automatically \nde\u00ad rived from the grammar. These services can then be cus\u00adtomized, or re-written from scratch, as desired. \nKey for the derivation of functionality from a grammar is the use of a declarative syntax formalism. \nSemantic actions or escapes to external functions, which are sometimes used with parser generators, make \nit hard to reason about the structure of a grammar for other purposes. In the implementation of Spoofax \nwe use SDF [21, 49]. Another essential compo\u00ad nent for an editor is error recovery, to ensure that editor \nser\u00advices based on the structure of the program keep working in the presence of syntax errors. In [11, \n29] we showed how a permissive grammar, a grammar with error recovery rules, can be derived from a declarative \nSDF grammar, ensuring good error recovery even for complex grammars composed of multiple embedded languages \nor extensions. In Section 3 we describe how SDF grammars are de.ned and how cus\u00adtomizable editor services \ncan be derived from them. The semantic services cannot be derived from the gram\u00admar, since they depend \non an interpretation of the syntactic structure of programs. Name analysis is a central compo\u00adnent, which \nis reused in all other semantic editor services. Name analysis resolves the declaration of names in a \npro\u00adgram according to the scope rules of the language.  Figure 2. Relations between IDE components. \nDependency .ow is indicated with arrows; generative dependencies are indicated with a solid line. Components \nwith an asterisk are generally also part of traditional batch compiler implementations. Custom Generated \nSyntax de.nition Lang.sdf Common.sdf Editor service descriptors Lang.main.esv Lang-Builders.esv Lang-Colorer.esv \nLang-Completions.esv Lang-Folding.esv Lang-Outliner.esv Lang-References.esv Lang-Syntax.esv Lang-Builders.generated.esv \nLang-Colorer.generated.esv Lang-Completions.gen...esv Lang-Folding.generated.esv Lang-Outliner.generated.esv \nLang-References.gen....esv Lang-Syntax.generated.esv Semantic de.nition lang.str check.str generate.str \n Figure 3. Language de.nition components.  2.3 Structure of a Language De.nition A Spoofax language \nde.nition is an Eclipse project that de\u00ad.nes the language-speci.c elements of an IDE, reusing the language-parametric \ncomponents from the Spoofax infras\u00adtructure. Figure 3 gives an overview of the default structure of a \nlanguage de.nition project. Each of the three main compo\u00adnents syntax, service descriptors, and semantics \n is de\u00ad.ned in a number of modules. Developers are free to orga\u00adnize these how they wish, but the default \nlayout separates the different concerns into different .les, allowing develop\u00aders to quickly familiarize \nthemselves with the components and interfaces of a language de.nition. An important design principle \nin the combination of de\u00adrived and handwritten .les has been to clearly indicate in the .le name which \n.les are generated. These .les are re\u00adgenerated every time the project is rebuilt and should not be edited \nby the language developer. To ignore speci.c rules in the generated .le, they can be disabled or rede.ned \nin the ac\u00adcompanying handwritten .le. If the generated .le is not used at all, it can simply be removed \nfrom the list of imported de\u00adscriptor .les. The syntax is de.ned using SDF [21, 49]. The default project \ncomes with a skeletal language with four produc\u00adtion rules (shown in Figure 4), and a module Common.sdf \nwith default rules for comments and lexical patterns such as strings and identi.ers. Editor services \nare de.ned using declarative, rule-based editor descriptor languages. These can be used to de.ne pre\u00adsentation \nor editing services, and can describe the interface of semantic editor services (describing what transformations \nto use for which service, and which views can be shown for a language). Derived services are maintained \nin separate .generated.esv .les, and provide basic functionality (or, at the very least, examples) for \nthese services based on the grammar. Not all services can be derived, but these .les are also a source \nof documentation and examples. Semantic de.nitions are speci.ed using Stratego [3], which provides an \nintegrated solution for analysis, trans\u00adformation, and code generation rules. Spoofax separates editor \nservice speci.cations and the transformations that implement them. Editor service descriptors specify \nwhich transformations to apply, while the Stratego speci.cations specify what these should do. This design \nensures .exibility in the implementation of services and allows for possible future integration with \nother meta-programming languages and frameworks. We discuss the three categories of de.nitions and their \nrelations in more detail in the following sections. 2.4 Agile Language Development The architecture \nof the Eclipse platform is based on the OSGi component model, in which each plugin is (usually) a JAR \ncontaining Java classes, a plugin manifest, optional de\u00adscriptor .les, and auxiliary resources, such \nas images. The descriptors specify which parts of the Eclipse framework a given plugin extends, and which \nparts of the plugin may be extended by other plugins. The OSGi model implies dis\u00adtributing plugins as \nstatic JARs. The normal work.ow cy\u00adFigure 4. Multiple editors, side by side, in the same Eclipse IDE \ninstance: the de.nition of an entity language (left), an editor for the entity language itself (upper \nright), and the abstract syntax of the selected entity (lower right).  cle for plugin developers is \nto declare new extensions in the plugin.xml descriptor .le, implement these in Java, and test the plugin \nin a second instance of Eclipse, which is detri\u00admental to a rapid development process. One IDE instance \nLanguage de.nitions in Spoofax are based on the Eclipse plugin project model: each language de.nition \nincludes a plugin manifest and descriptor .les that allow it to be distributed to end developers as a \nnormal Eclipse plugin. However, to enable agile language develop\u00adment we use a very different work.ow \nmodel than that of standard Eclipse plugin development. By using language\u00adparametric editor services \nthat dynamically load and update language-speci.c service speci.cations (described in more detail in \nSection 6), we can use generated editors for a lan\u00ad guage in the same environment (Eclipse instance) \nin which we edit the language de.nition itself. Figure 4 illustrates how a grammar (left) and a generated \neditor (upper right) can be used side by side. The editor is fully functional and includes semantic services \nalso de.ned in the same environment. The lower right editor illustrates an abstract syntax view for the \nselection in the generated editor that is updated in real-time as the selection is edited.1 The same \nview can be used to inspect (intermediate) results of transformations. Inductive design Rather than designing \na complete DSL on paper, before its implementation, it is good practice to incrementally introduce new \nfeatures and abstractions through a process of evolutionary, inductive design [16, 51]. In the context \nof a language workbench, this means that DSL programs and the DSL itself evolve together. This enables \nquick turn-around time for the development of the DSL and the subsequent gradual extension as new applications \nare developed, and new insights into the domain are acquired. 1 While a graphical abstract syntax view \ncan be visually appealing, we opt for an automatically formatted textual view instead, as it is much \nmore concise, conveys the same information, and bene.ts from standard, textual editor services. Moreover, \nthe same textual representation is also used in (and can be copy-pasted to) speci.cations of analyses \nand transformations. The Spoofax environment assists in the initial creation of a new language using \na wizard that simply takes the name of the language, the .le extension it uses, and a package name. The \nwizard then creates a new Eclipse project with a skeletal language de.nition. From this point, new language \nfeatures can be added through an iterative development process. New language constructs can be added \nto the grammar. These features can be directly used in the editor for the language. A new language project \ncreated by the wizard includes standard Eclipse plugin con.guration .les (these are typi\u00adcally not changed \nby language developers), as well as spec\u00adi.cation .les native to the Spoofax environment. Develop\u00aders \ncan then de.ne editor services and de.ne semantics for these features. Some editor services are automatically \nde\u00adrived from the grammar; their speci.cation can be adapted as desired. An important aspect of the Spoofax \narchitecture is that it allows for selective development of editor services. Develop\u00aders can freely select \nwhat services to implement: the editor can also be used with a subset of all features. For exam\u00adple, \ndevelopers may forgo sophisticated semantic analyses and transformations, and simply de.ne code generation \nby a very direct mapping of abstract syntax to target code using string templates. Reuse is key for ef.cient \nlanguage devel\u00adopment, which means there are some dependencies between services (as seen in Figure 2), \nbut most can be completed individually, allowing the language and IDE to be evaluated and used at every \nstage of development. Language understanding with views The speci.cations of most editor services, in \nparticular those for semantic services based on analyses and transformations, are de.ned in terms of \na textual abstract representation of programs. Using the abstract syntax view (Figure 4), developers \ncan inspect the abstract syntax of a text selection or .le. The abstract syntax view of Figure 4 is not \na built-in Spoofax feature, but it is a view that is de.ned with the de\u00adfault, skeletal language de.nition. \nViews show the results of transformations (as indicated by the relation in Figure 2). When a view is \nopened, it is automatically placed to the side of its source .le, allowing developers to view both at \na glance. Views are implemented using standard, textual ed\u00aditors (either for DSLs or languages such as \nJava that live in the Eclipse environment). They show either the abstract syn\u00adtax of a transformation \nor the concrete syntax (e.g., standard Java code). The default view for showing the abstract syntax is \nde.ned by showing the result of the identity transforma\u00adtion, i.e., code is only parsed, not transformed. \n Views are an important aspect of our architecture and a requirement for agile language development: \nthey are essen\u00adtial for awareness of the abstract representation of a lan\u00adguage, and can be used to show \n(intermediate) results of analyses and transformations independent of other editor services.  2.5 Example \nDomain-Speci.c Language In the following sections we use the NWL language2, a sub\u00ad set of WebDSL [51], \nto illustrate key points of language def\u00ad inition. NWL covers several aspects of web programming i.e. \nentity declarations (data modeling), properties with in\u00adverse relations, parameters and variables, expressions, \ntem\u00adplate de.nitions, page navigation, and several types of tem\u00adplate elements. However, in this paper \nwe focus only on def\u00adinitions of entities and actions (which are analogous to data type de.nitions and \nfunctions in other languages). 3. Syntax The central implementation artifact for any textual language \nis the parser, which can be generated from a grammar. In Spoofax, the grammar has the following roles: \n1. it speci.es the concrete syntax (keywords etc.) 2. it speci.es the abstract syntax (the data structure \nused for analysis and transformation of programs written in the language) 3. it is used to derive editor \nservices for presentation and editing that can be customized by the developer  We use SDF [21, 49] to \nde.ne grammars. SDF grammars are declarative, highly modular, combine lexical and context\u00adfree syntax \ninto one formalism, and can de.ne concrete and abstract syntax together in production rules [32]. SDF \nproductions take the form p1...pn -> s and spec\u00adify that a sequence of strings matching symbols p1 to \npn matches the symbol s. Productions can be annotated with a constructor name n to uniquely identify \nthem in the abstract syntax using the {cons(n)} annotation. Other annotations include {left} and {right} \nto specify the associativity of operators, and {deprecated(e)} to mark deprecated syn\u00adtax with optional \nexplanation e. 2 The complete de.nition of NWL is available at http://strategoxt. org/Spoofax/NWL. module \nNWL imports Common exports context-free start-symbols Start context-free syntax \"module\" ID Def* -> Start \n{cons(\"Module\")} \"import\" ID -> Def {cons(\"Import\")} \"entity\" ID \"{\" Prop* \"}\" -> Def {cons(\"Entity\")} \n\"action\" ID \"(\" {Param \",\"}* \")\" \"{\" Stat* \"}\" -> Def {cons(\"Action\")} ID \":\" Type -> Param {cons(\"Param\")} \nID \":\" Type -> Prop {cons(\"Property\")} ID -> Type {cons(\"SimpleType\")} \"Set\" \"<\" Type \">\" -> Type {cons(\"SetType\")} \n Exp \":=\" Exp \";\" -> Stat {cons(\"Assign\")} \"for\" \"(\" ID \":\" Type \")\" \"{\" Stat* \"}\" -> Stat {cons(\"ForAllEntity\")} \n\"for\" \"(\" ID \":\" Type \"in\" Exp \")\" \"{\" Stat* \"}\" -> Stat {cons(\"ForAll\")} \"all\" \"(\" Type \")\" -> Exp \n{cons(\"ForAllExp\")} STRING -> Exp {cons(\"StringLit\")} ID -> Exp {cons(\"Var\")} Exp \".\" ID -> Exp {cons(\"PropAccess\")} \n Figure 5. A grammar for entities and actions in NWL. Figure 5 shows an abbreviated SDF grammar for \nthe NWL language. The grammar extends the basic entity lan\u00adguage of Figure 4 with additional features. \nNWL modules consist of a module name and a list of Def de.nitions. Def\u00adinitions can be entity declarations, \nimport declarations, or actions. Actions have a comma-separated list of Param pa\u00adrameters and a list \nof Stat statements. Mapping between abstract and concrete syntax The ab\u00adstract syntax, used in the speci.cation \nof editor services, can be represented as .rst-order terms of the form t ::= \"...\" // string literals \n| c(t1,...,tn) // constructor applications |[t1,...,tn] // lists of terms As an example, consider the \n.rst production of the NWL grammar: \"module\" ID Def* -> Start {cons(\"Module\")} This production has three \nelements: the literal module , an identi.er name, and a list of de.nitions. For analyses and transformations \nwe re usually not interested in literals and layout, so only the name and list of de.nitions are included \nin the abstract representation: Module(\"example\", [Entity(\"User\", [...])]) which corresponds to the \nabstract syntax of the module at the upper right of Figure 4. Spoofax generates a parser from the grammar, \nwhich pro\u00adduces the abstract representation of a .le every time the user presses key and a short delay \npasses. After the parser com\u00adpletes, all editor services that depend on the abstract repre\u00adsentation \nare updated automatically. Internally, the abstract representation is stored ef.ciently in memory as \nJava ob\u00adjects, and maintains full layout and position information for use in services that need it. \n3.1 Syntactic Editor Services Editor services related to presentation and editing can be based directly \non the syntax de.nition (as indicated by the relation in Figure 2). These services can be fully speci.ed \nusing declarative editor service descriptor speci.cations. Rather than give an exhaustive overview of \nthese descrip\u00adtors and their features (available online at [1]), we show some examples in this section \nto give an impression of how a declarative descriptor DSL can concisely describe these services. Syntax \nhighlighting Default syntax highlighting behavior is derived based on the literals and lexical syntax \nin the grammar. The colors used for this derived behavior are spec\u00adi.ed in the generated colorer descriptor, \nshown in the lower half of Figure 6. It speci.es a color for keywords (alphanu\u00ad meric literals in the \ngrammar), operators (non-alphanumeric literals), strings (lexicals that allow spaces), numbers (lex\u00adical \nnumeric patterns), and identi.ers (other lexicals). The default colorization works well, but can be customized \nin the NWL-Colorer.esv .le. The top half of Figure 6 illustrates custom coloring rules for the Type symbol, \nwith speci.c col\u00adors for the SimpleType and the SetType constructor. Other coloring rules can override \nthe colors for literals and lexi\u00adcals, and can specify background colors, colors for regions of code \nrather than single productions, and more. Code folding and outline view Code folding and the out\u00adline \nview are speci.ed by selecting grammar productions that should be made foldable or shown in the outline \nview. Figure 7 illustrates some folding rules for the NWL lan\u00ad guage. Spoofax uses heuristics to automatically \nderive a gen\u00aderated folding descriptor, based on the logical nesting struc\u00adture of the language. Currently, \nproductions rules that have an identi.er lexical and a list of child elements are included in this descriptor. \nWhile not perfect, the heuristic provides a good starting point for a new folding de.nition. Any un\u00addesired \nde.nitions in the generated .le can be disabled by using the (disabled) annotation in the custom speci.ca\u00adtion. \nThe (folded) annotation can be used for constructs that should be folded automatically. Bracket highlighting \nand insertion By describing pairs of matching brackets and the comment constructs of a lan\u00adguage, the \nbracket highlighting, bracket insertion, and com\u00adment insertion features can be enabled for an editor \n(Fig\u00adure 8). Bracket pairs are also used to supplement the au\u00ad tomatic indentation speci.cation (not \nshown): the cursor is automatically indented one level if a newline is entered after an opening bracket. \nSyntax completion We distinguish syntactic and semantic content completion (the latter is discussed in \nthe next sec\u00ad module NWL-Colorer imports NWL-Colorer.generated colorer Type.SimpleType : cyan Type.SetType \n: gray  module NWL-Colorer.generated colorer keyword : magenta bold identifier : default string : blue \n... Figure 6. Syntax highlighting rules for NWL. module NWL-Folding imports NWL-Folding.generated folding \nStart.Module Definition.Entity Definition.Action Figure 7. Folding rules for NWL. module NWL-Syntax \nlanguage line comment : \"//\" block comment : \"/*\" * \"*/\" fences :(){} Figure 8. Comment and bracket de.nition \nrules for NWL. tion). Syntactic content completion provides users with com\u00adpletion suggestions based \npurely on static, syntactic tem\u00adplates. For example completion template: \"entity \" <e> \" {\\n\\t\\n}\"  \nis a syntactic completion rule for entity de.nitions. Comple\u00adtion rules are composed of static strings \nand placeholder ex\u00adpressions. Static strings allow for precise control of the pre\u00adsentation of completions \nand are enclosed by double quotes. They can use \\n for newlines or \\t for one indentation level (following \nthe user s tab/space con.guration). Placeholder expressions are indicated by angular brackets. The editor \nau\u00adtomatically moves the cursor to these expressions once the user selects a completion proposal, allowing \nthe expressions to be .lled in as the user continues typing. 4. Analysis and Transformation Semantic \nanalysis has two key roles in the implementation of programming languages. First, the analysis checks \nif pro\u00adgrams program are (type) consistent, reporting errors if they are not. Second, it provides semantic \ninformation for use by compilers, IDEs, and other language-speci.c tools. In IDEs, semantic analysis \nforms the basis for all seman\u00adtic editor services. There are two forms of semantic anal\u00adysis that are \nparticularly important for IDEs: name analysis and type analysis. Name analysis binds each identi.er \noccur\u00adrence to its declaration. Name analysis is exposed directly in the IDE in the form of reference \nresolving: press and hold Control and hover the mouse cursor over an identi.er to re\u00adveal a blue hyperlink \nthat leads to its declaration. Type anal\u00adysis determines the type of expressions and is important for \nreporting errors and for context-dependent code generation.  Other analyses such as .ow and pointer \nanalysis may also have a role in marking errors and warnings or for optimiza\u00adtion of the generated code, \nbut in this paper we focus on name and type analysis because of their central and crucial role in both \ncompilation of languages and for editor services. Like many traditional compilers, we employ a staged \narchitecture of analyses and transformations, as illustrated in Figure 9. First programs are parsed, \nthen syntactic sugar is eliminated, and then they are analyzed, creating abstract syntax trees decorated \nwith semantic information. Semantic editor services such as reference resolving and error marking operate \non these decorated trees. After the analysis, the tree can be further normalized to a core form, and \n.nally code generation rules can generate resulting code. In the remainder of this section, we .rst introduce \nthe Stratego transformation language, and then show idioms for using Stratego rewrite rules to concisely \nand declaratively specify analyses and transformations for use by editor ser\u00advices and for code generation. \n 4.1 Stratego We use the Stratego program transformation language [3] to describe the semantics of a \nlanguage. The Stratego lan\u00adguage is based on the paradigm of term rewriting with pro\u00adgrammable rewriting \nstrategies introduced by [52]. Basic transformations are de.ned by means of conditional term rewrite \nrules of the form r: t1->t2 wheres with r the name of the rule, t1 and t2 .rst-order terms, and s a strategy \nexpression. A rule applies to a term when its left\u00adhand side t1 matches the term, and the condition s \nsucceeds, resulting in the instantiation of the right-hand side pattern t2. Otherwise the application \nfails. Unconditional rules have no where clause, others may have multiple that must all be satis.ed. \nIn addition to checking applicability constraints, the where clause of a rule can perform computations \nthat may be used in the right-hand side of the rule. For example, in the rule schema r : t1 -> t2 where \nt3 := <s> t4 the term t4 is transformed by application of a strategy or rule s, matching against and \nbinding variables in the pattern t3. Term t4 may use variables from the left-hand side t1, and right-hand \nside t2 may use t3. Rewrite rules can concisely express small transforma\u00adtions based on the abstract \nrepresentation of a program. Us\u00ading content completion of terms, based on the syntax of a language, and \nby providing views of the abstract syntax and the results of transformations, the Spoofax environment \nas\u00adsists in writing these rules. More complex transformations can be created by com\u00adposing rules using \nstrategies. Many strategies can be com\u00adpared to visitors in object-oriented programming in that they \nguide the application of rules in a tree. A strategy is essen\u00adtially a partial function from terms to \nterms. If a strategy is not de.ned on a term it is said to fail. Failure arises from the failure of rewrite \nrules to apply to terms. Strategies are com\u00adposed from basic combinators such as the identity transfor\u00admation \nid, sequential composition s1; s2 and determinis\u00adtic choice s1 <+ s2. The Stratego standard library provides \na number of strategies for general use, such as map(s) that applies a strategy expression s to each element \nof a list, and alltd(s) that descends down the branches of a term up to the points where s can be successfully \napplied, returning the complete term after transformation. Context-sensitive transformations can be expressed \nby means of dynamic rewrite rules [4], which are instantiated at run-time, as illustrated by the following \nschema: r:t1-> t2 where rules(dr : t3 -> t4)  The dynamic rule dr is de.ned when r is applied to a term \nmatching t1. Any variables that t3 and t4 share with t1 are then inherited by the instantiation of dr \n(concrete examples follow below). 4.2 Desugaring Desugaring rules can simplify the abstract representation, \ntransforming higher-level constructs to more general, lower\u00adlevel constructs, or mapping constructs with \nmultiple forms to a single, canonical form. They can also be used to migrate deprecated language constructs \nto newer alternatives. This way, later analysis and transformation stages only need to focus on a subset \nof all language constructs. The full WebDSL language supports various different iteration expressions \nand statements with optional .lters and ordering clauses [51]. In our NWL subset we provide three basic \niteration constructs without .ltering or order\u00ading, shown in the grammar of Figure 5. The ForAllExp expression \nand the ForAllEntity statement iterate over all instances of a given entity type. The ForAll statement \nis more general and iterates over a given expression. To avoid having to write typing, transformation, \nand code generation rules for each of these variations, we use desugaring rules to transform similar \nconstructs to the most general form. desugar-top = innermost(desugar) desugar: ForAllEntity(x, t, s*) \n-> ForAll(x, t, ForAllExp(t), s*) desugar: Call(x) -> CallArgs(x, []) Figure 10. Simple desugaring rules. \nFigure 10 shows a desugar rule that transforms the ForAllEntity statement to the more general form. An\u00adother \nde.nition of the rule transforms action calls with\u00adout arguments to action calls with an empty list of \nargu\u00adments (omitted in the syntax de.nition). More sophisticated, context-sensitive transformations, \nsuch as type inference for the ForAll loop, can be applied after semantic analysis of the program. The \ndesugar rules are exhaustively applied in an innermost fashion by the desugar-top strategy.  4.3 Reporting \nErrors and Warnings There are a number of concerns in checking a program for errors and reporting them \nto the user: Context: identifying points in the code to check  Assumptions: only report an error if \ncertain assumptions hold (validating the context and avoiding spurious errors)  Constraints: checking \nfor constraints at the context  Formulating an error message  Attribution of the error to a particular \ncharacter range in the source text (usually, only part of the context is marked, such as the name of \nan erroneous method)  In Spoofax, error checking is a transformational process: it transforms an abstract \nsyntax tree to a list of errors (also a tree, containing messages and attributed tree nodes). We use \nregular Stratego rewrite rules to transform parts of the tree to errors. These check rules encapsulate \nall of the above concerns, and adhere to the following idiom: check: context -> (target, $[error message]) \nwhere assumption where require(constraint) The rule checks whether for the given context (the term under \nscrutiny) the constraint is satis.ed, given that the assumption holds. The require(s) operator is sugar \nde\u00ad.ned as follows: require(s) = not(s) That is, the check rule succeeds (producing the speci.ed error \nmessage), if the assumption succeeds but the constraint fails. The right-hand side is a pair consisting \nof target term and an error message. The target is (typically) a subterm of the context and denotes the \nterm to which the error message should be attributed. The error message should explain that the constraint \ndoes not hold. The error message is a string typically composed using string interpolation, i.e. $[...] \nis a string consisting of all literal characters between the check-top = collect-all(check) check: Var(x) \n-> (x, $[Variable [x] is not declared]) where require(type-of) check: SimpleType(x) -> (x, $[Undefined \ntype [x]]) where require(is-simple-type) check: PropAccess(e2, p) -> (p, $[[t] has no property [p]]) \nwhere t := <type-of> e2 where require(type-of) check: ForAllExp(t) -> (t, $[For loop requires entity \ntype argument]) where <is-simple-type> t where require(<is-entity-type> t)  check: SetType(t) -> (t, \n$[Set requires entity type argument]) where <is-simple-type> t where require(<is-entity-type> t) Figure \n11. Consistency checking rules. quotes, except for escapes between [...]. For example, if t is bound \nto \"Blog\" and p to \"size\" then $[[t] has no property [p]] evaluates to the string \"Blog has no property \nsize\". Figure 11 gives a selection of check rules for the NWL language. The check-top strategy controls \nthe application of these rules: it collects a list of all tuples resulting from successful applications \nof the check rules. For the speci.ca\u00adtion of assumptions and constraints, these rules use a number of \nhelper rules that are de.ned by the name and type analy\u00adsis (which we describe in the next subsection). \nThe type-of helper is a rule that returns the type of an expression. If the type cannot be resolved (indicating \nan error in the program), type-of fails. For example, the .rst check rule of Figure 11 requires that \ntype-of succeeds for the context. If it does not, an error is reported. Another helper is is-simple-type, \nused in the second check rule: it only succeeds if the given type is a declared entity type (as opposed \nto a set type). This helper is also used to distinguish the case where constructors are unde.ned or just \nnon-entity types. 4.4 Binding Transformations to Editor Services Transformation with origin information \nFor the check rules it is important to maintain the relation between the original source location and \nthe term an error is attributed to. Figure 12 illustrates the different steps of the error checking strategy. \nFirst, the source code is parsed, desugared, and an\u00adalyzed, producing the abstract syntax tree to the \nleft. Then the check-top strategy is applied, producing the tree to the right, with pairs for all attributed \nterms and error mes\u00adsages. Throughout the desugaring, analysis, and error check\u00ading process, the relations \nbetween the original source posi\u00adtions and the terms are maintained, as shown by the dashed lines. Using \nthese relations, all errors can be reported in the source code locations that correspond to the attributed \nterms. The origin relations are maintained automatically by the Spoofax environment, allowing language \ndevelopers to write concise, position information-agnostic transformations  editor-analyze: (ast, path, \nproject-path) -> (ast , errors, warnings, notes) where editor-init; ast := <desugar-top> ast; ast := \n<declare-top> ast ; errors := <check-top> ast ; warnings := <check-warning-top> ast ; notes := <check-note-top> \nast Figure 13. Control rule for semantic analysis. rather than keeping track of the original position \nmanually. Position information is implicitly passed along with trans\u00adformations through a form of origin \ntracking [46]. Origin tracking is a general technique that can be applied in term rewriting systems to \nimplicitly maintain a link to the origi\u00adnating term after it has been rewritten to a new term. Origin \ntracking as introduced by Van Deursen et al [46] has originally been used to trace back errors to their \noriginal source, much like we do in our error checking transforma\u00adtion. However, as we show in the remainder \nof this section, the technique can also be used to for high-level speci.cations of analyses and transformations \nused by editor services. Control rules The transformation of an abstract syntax tree to a list of errors \nis controlled by the analysis control rule. Control rules are regular Stratego rewrite rules with a .xed \nsignature that form the interface between the IDE and the Stratego transformation speci.cation. The control \nrule for semantic analysis and error report\u00ading is shown in Figure 13. The rule is given information \nabout the .le that is being analyzed, in the form of a tu\u00adple with the abstract syntax tree of the .le \nto be checked, its project-relative path, and the .le system path of the project itself. The rule transforms \nthis input to a new abstract syntax tree, decorated with semantic information, and lists of er\u00adrors, \nwarnings, and informational notes to be marked in the program. In the where clause, the rule .rst resets \nthe cur\u00adrent analysis environment using the built-in editor-init strategy. Corresponding to Figure 9, \nthe rule then desug\u00ad ars the input abstract syntax tree and analyzes it, by calling the declare-top strategy \n(given below). It then collects all markers for the resulting (decorated) abstract syntax tree us\u00ading \nthe check strategies. Semantic editor descriptors Editor descriptor .les deter\u00admine which control rule \nis used for which service. For ex\u00adample, the NWL-Builders.esv .le speci.es: observer: editor-analyze \n which means that editor-analyze is used as the observer control rule for the semantic analysis and error \nreporting. Control rules can also be speci.ed for when .les are saved (on save), for when a view is opened \n(builder), for reference resolving (reference), and for each of the other semantic services of Figure \n2. 4.5 Name and Type Analysis Name analysis binds each identi.er occurrence to its decla\u00adration. Based \non name analysis, type analysis identi.es the types of expressions. Name analysis is also used for seman\u00adtic \neditor services and code generation, as illustrated in Fig\u00adure 2. Together, name and type analysis form \nthe basis for consistency checking rules as those seen in Section 4.3. As name analysis and type analysis \nare generally used together, it is common practice for compilers to combine the two analyses. Rather \nthan locating the de.nition site for identi.er occurrence, the name analysis then directly collects a \nmapping of names to types, and the type analysis determines the types of surrounding expressions. In \nSpoofax we use the name analysis independently from the type analysis in semantic editor services. For \nthis reason it is important to separate it from the type analysis. In this section we present an idiom \nfor separate speci.cation of name and type analysis using rewrite rules and dynamic rules. For simplicity, \nwe divide the name analysis in two stages: .rst we collect all globally visible names, and then we analyze \nscoped names. Unscoped name analysis Globally visible names can be stored directly as dynamic rules that \nmap an identi.er to its declaration site. For NWL, we use the EntityDef and ActionDef dynamic rules for \nglobal names (Figure 14). The declare-top strategy controls the stages of the name analysis. It .rst \ndeclares all primitive types, then applies the declare rule to the outermost de.nitions, and .nally calls \nrename-top to analyze scoped names (shown below). declare-top = declare-primitive-types; alltd(declare); \nrename-top declare-primitive-types = rules( PrimitiveDef: \"String\" -> \"String\" PrimitiveDef: \"Int\" -> \n\"Int\" ... ) declare: d@Entity(x, p*) -> d where rules(EntityDef : x -> d) declare: d@Action(x, param*, \nstat*) -> d where rules(ActionDef : x -> d) declare: Import(x) -> Import(x) where open-import( resolve-import \n, parse-file , declare-top ) resolve-import: Import(x) -> $[[<project-dir>]/[x].nwl] Figure 14. Name \nanalysis for globally visible names. The declare rules match entities and actions, and de.ne dynamic \nrules that map each name x to its de.nition site d. For import declarations, Spoofax provides a generic \nopen-import strategy (used in Figure 14, bottom). This strategy ensures that .les are cached after they \nare parsed and avoids cycles in the dependency graph. The open\u00adimport strategy takes three strategy expressions \nas its ar\u00adguments, that respectively resolve the .lename of an import (resolve-import), parse the .le \n(parse-file), and ana\u00adlyze the .le (declare-top). Scoped name analysis For scoped names, we base our \nanalysis on the notion of consistent renaming [53], which is the task of renaming all names in a program \nsuch that they are unequal to all other names that do not correspond to the same declaration site. However, \nrather than directly chang\u00ading the names in the tree, we add annotations that satisfy this uniqueness \nrequirement. This way, the abstract syntax tree remains the same modulo annotations, aiding in debugging \nand traceability of analysis and code generation. As an ex\u00adample, Figure 15 shows how an action de.nition \nin concrete syntax (top), abstract syntax (middle), and as abstract syntax with renaming annotations \n(bottom). After renaming, each local name combined with its annotation is globally unique: for instance, \nwe can distinguish \"s\"{\"a_0\"} from any other identi.er s de.ned elsewhere. Figure 16 shows renaming rules \nthat add consistent nam\u00ading annotations to local variables. The .rst de.nition of rename (Figure 16 (A)) \noperates on action parameters. It replaces the name x of a parameter with the annotated name x{<new>}, \nwhere <new> generates a fresh, globally unique name. The VarDef dynamic rule is de.ned to map the an\u00adnotated \nname to the de.nition site. The RenameId dynamic rule records the renaming for the current scope: for \neach fol\u00adlowing occurrence of x, it should given the name y (Fig\u00ad action add(s : Set<User>) { for(u:User \nins){ ... } } Action(\"add\", [Param(\"s\", SetType(SimpleType(\"User\")))], [ForAll(\"u\", SimpleType(\"User\"), \nVar(\"s\"), ...)] ) Action(\"add\", [Param(\"s\"{\"a_0\"}, SetType(SimpleType(\"User\")))], [ForAll(\"u\"{\"b_0\"}, \nSimpleType(\"User\"), Var(\"s\"{\"a_0\"}), ...)] ) Figure 15. Consistent renaming of an action de.nition. \nrename-top = alltd(rename) rename: d@Param(x, t) -> Param(y, t) (A) where y := x{<new>}; rules( VarDef \n:y->d RenameId : x -> y ) rename: Var(x) -> Var(y) (B) where y := <RenameId> x rename: Action(f, p1*, \ns1*) -> Action(f, p2*, s2*) (C) where {| RenameId: p2* := <rename-top> p1*; s2* := <rename-top> s1* \n|} rename: d@ForAll(x, t, e, s1*) -> ForAll(y, t, s2*) where {| RenameId: y := x{<new>}; rules( VarDef \n:y->d RenameId : x -> y ); s2* := <rename-top> s1* |} Figure 16. Name analysis using renaming rules. \n ure 16 (B)). Any names that are not declared will not be renamed, and are reported as errors in the \ncheck stage as VarDef is never de.ned for them. To respect the scopes of the language, we use dynamic \nrule scopes [4] to re.ect scoping construct of the language. This Stratego feature takes the form {| \nr: ... |} and en\u00adsures that any de.nition of the dynamic rule r made directly or indirectly within the \nscope is no longer visible after the scope is exited. The rename rule for actions (Figure 16 (C)) uses \nthis feature to scope variables declared within an ac\u00adtion. As the RenameId for these variables is unde.ned \nat the end of the scope, the variables are no longer visible in any following actions. The last de.nition \nof rename combines local renaming and scoping for the for statement. Type analysis Type analysis can \nbe speci.ed using rules that project a language construct to its type. The type-of rule maps language \nconstructs to their type (Figure 17). Typ\u00ad ing rules for literals generally specify a constant type (e.g., \nfor StringLit). Typing rules for declarations can fetch the type from one of the subterms (e.g., for \nentities or proper\u00adties). Other typing rules use name analysis rules to fetch a de.nition and then apply \nthe basic type-of rules (e.g., for type-of: StringLit(x) -> SimpleType(\"String\") type-of: Entity(x, \nprop*) -> SimpleType(x) type-of: Property(_, t, _) -> t type-of: Param(x, t) -> t type-of: ForAll(x, \nt, _, _) -> t type-of: ForAllExp(t) -> SetType(t) type-of: Var(x) -> <type-of> (<VarDef> x) type-of: \nPropAccess(e, f) -> t where p := <lookup-property(|f)> (<type-of> e); t := <type-of> p Figure 17. Typing \nrules. lookup-property(|f): Entity(y, p*) -> <fetch-elem(?Property(f,_,_))> p* lookup-property(|f): SimpleType(y) \n-> <lookup-property(|f)> (<EntityDef> y) is-simple-type = is-primitive-type <+ is-entity-type is-primitive-type: \nSimpleType(x) -> <PrimitiveDef> x is-entity-type: SimpleType(x) -> <EntityDef> x Figure 18. Helper rules \nfor error checking. Var). For compound expressions such as PropAccess, we fetch the property de.nition \ncorresponding to the expression and return its type. To fetch the property f of a given type we use the \nlookup-property(|f) helper rule, where the pipe (|) indicates that it receives a term argument f (as \nop\u00adposed to a strategy argument). Other projection rules can test for various properties based on the \nname analysis. Figure 18 illustrates additional projection rules that are used in the check rules. Of \nthese, the lookup-property rule is of particular interest. It uses the Stratego standard library strategy \nfetch-elem to try and fetch the property f from an entity de.nition. A second def\u00adinition fetches the \nproperty given a type instead of an entity.  4.6 Reference Resolving and Occurrence Highlighting Reference \nresolving and occurrence highlighting are speci\u00ad.ed using a control rule that given an identi.er, respectively \nlooks up its declaration or all occurrences of that identi.er. For reference resolving, this rule is \nshown in Figure 19. The rule is given the selected node in the tree, its position (spec\u00adi.ed as a list \nof child offsets), the decorated abstract syntax tree, and the .le system paths. The same tuple is given \nto the control rules of all other semantic editor services (with the exception of the analysis and error \nchecking control rule). Reference resolving is implemented by simply applying the dynamic rules from \nthe name analysis stage to the selected identi.er, using a decl-of helper rule to fetch the appropri\u00adate \ndeclaration. Occurrence highlighting can be speci.ed in a similar fashion, but is omitted here for reasons \nof brevity. Both services rely fully on the name analysis speci.cation and only require a small addition \nto implement the editor service.  4.7 Content Completion Semantic content completion (sometimes called \ncontent as\u00adsist) provides completion proposals based on the syntactic editor-resolve: (selected, pos, \nast, path, project-path) -> target where target := <decl-of> selected decl-of: Var(x) -> <VarDef> x \ndecl-of: SimpleType(x) -> <EntityDef> x decl-of: Submit(x) -> <ActionDef> x Figure 19. Rules for reference \nresolving. and semantic context of the expression that is being edited. Content completion can provide \nsuggestions for globally visible names as well as locally scoped names. For this rea\u00adson, we integrate \ncontent completion into the name analysis of Section 4.5. An important aspect of our design for the content \ncom\u00adpletion service is its interface to the semantic analysis. Con\u00adtent completion suggestions must be \nprovided regardless of the syntactic state of a program: an incomplete expression blog. does not conform \nto the syntax, but for content com\u00adpletion it must still have an abstract representation. One ap\u00adproach \n(as taken by IMP [8], for example) is to require the language developer to add special productions to \nthe gram\u00admar that map these incomplete expressions to an abstract representation. Unfortunately, this \nmeans the developer has to do extra work and has to account for all cases where con\u00adtent completion may \nbe expected in the grammar. In our approach, we opt for a generic representation of incomplete syntactic \nexpressions: we introduce an arti.cial COMPLETION term to the abstract representation at the point of \nthe cursor. For example, if a variable is expected at the cursor, a Var(COMPLETION(\"p\")) is placed at \nthe corre\u00adsponding point in the abstract representation, with p the (possibly empty) identi.er pre.x \nthat was already typed in. Similarly, compound expressions can take a form like PropAccess(\"blog\",COMPLETION(\"p\")). \nIn Figure 20 we de.ne content completion for vari\u00adables and property access expressions by extending \nthe name analysis from Figure 16. We replace the de.nition of rename-top with one that applies propose-completion \nbefore it applies rename. The .rst de.nition of propose\u00adcompletion provides completion suggestions for \nvariables, by taking all keys of the RenameId dynamic rule. Strat\u00adego provides the derived function all-keys-RenameId \nto do this. As the rule is evaluated within the context of the analysis, this results in a list of all \nvariables in the current scope, and thus all valid suggestions if a variable is expected at the cursor \nlocation. The ContentProposals dynamic rule stores the list. The second propose-completion rule provides \ncompletion suggestions for property access expres\u00adsions, by fetching all property names and recording \nthem in the dynamic rule. The control rule for content completion is called editor-complete. It .rst \nperforms name analysis (extended with content completion support) and then fetches the value of the ContentProposals \nrule. The editor descriptor speci.es which control rule to use for content completion, and may specify \na character se\u00ad rename-top = alltd(propose-completion <+ rename) propose-completion: Var(COMPLETION(p)) \n-> all-vars where all-vars := <all-keys-RenameId>; rules(ContentProposals: () -> all-vars) propose-completion: \nPropAccess(e, COMPLETION(p)) -> p2* where Entity(x, p*) := <EntityDef>; p2* := <map(property-name)> p*; \nrules(ContentProposals: () -> p2*) editor-complete: (selected, position, ast, path, project-path) -> \np* where editor-init; ast := <declare-top> (<desugar-top> ast); p* := <ContentProposals> () Figure 20. \nContent completion rules. quence that automatically triggers content completion. For example, for NWL, \ncontent completion should be automati\u00adcally triggered when the user types . or : .  4.8 Transformations, \nCode Generation, and Views Based on the Stratego language, Spoofax supports trans\u00adformations and code \ngeneration using concrete object syn\u00adtax [50], allowing rules to be written using the concrete syn\u00ad tax \nof the language that is transformed as patterns. These patterns can be syntactically checked against \nthe syntax of the language. The Stratego compiler converts the patterns to abstract syntax. Concrete \nsyntax can be very effective for writing modular transformations that are divided into a series of small, \nseparate transformation steps [23]. After transfor\u00ad mation using concrete syntax, a pretty printer can \nproduce text output from the result. Concrete object syntax can be contrasted to template en\u00adgines, where \nno further transformation steps are possible af\u00adter code is rewritten (unless the resulting text is reparsed). \nStratego also offers language support for template engine\u00adlike transformations, by providing indentation-safe \nstring in\u00adterpolation as a quick and dirty code generation solution. For the small NWL language we opted \nfor this approach to code generation: after some desugaring and normalization, NWL is printed to Java, \nand no subsequent transformations are applied. Figure 21 shows code generation rules using string interpolation \nand the control rule for generating Java. Transformations and code generation can be used as a ba\u00adsis \nfor views. Views can be described using descriptors, and can have a title, a rule name, and a number \nof annotations: builder: \"Generate Java code\" = generate-java (openeditor) (realtime) builder: \"Show \nabstract syntax\" = generate-aterm (openeditor) (realtime) (meta) This speci.cation de.nes views to show \nJava code and the abstract syntax of a selection. The (openeditor) annota\u00adtion speci.es that an editor \nshould be opened for the view (rather than just generating code and saving it a .le). The (realtime) \nannotation speci.es that the view should be updated in real-time as the source .le is changed. Finally, \ngenerate-java: (selected, position, ast, path, project-path) -> ($[[path].java], <to-java> selected) \nto-java: Entity(x, p*) -> $[ class [x] { [p2*] } ] where p2* := <to-java> p* to-java: Property(x, Type(t)) \n-> $[ private [t] [x]; public [t] get_[x] { return [x]; } public void set_[x] ([t] [x]) { this.[x] = \n[x]; } ] Figure 21. Code generation rules. the (meta) annotation speci.es that the view should only \nbe available to language engineers, not to end developers. 5. Experience We have substantial experience \nin using Spoofax and lan\u00adguages created with Spoofax. Several languages are part of the standard distribution, \nand are used in the development of new languages: The SDF language. Developed before the Spoofax work\u00adbench, \nwe described the static semantics of SDF using the idioms in this paper to support editor services such \nas views on syntax productions and content completion.  The ESV editor descriptor language.  The Stratego \nlanguage. We described the static semantics to provide full-featured Stratego IDE support.  The ATerm \nlanguage [45], used for abstract syntax. In addition to the Spoofax speci.cation, we added special support \nfor views based on the source .le of an ATerm .le (e.g., allowing generate Java code to be applied to \nan ATerm created from an NWL .le).  Spoofax has also been used, by ourselves and others, to de\u00advelop \na variety of new languages covering different domains. Some have been developed independently of our \nenviron\u00adment before Spoofax was available, and have used Spoofax to describe the syntax and static semantics \nfor IDE integra\u00adtion. A selection: Acoda [48] is a tool set that uses DSLs to aid in data mi\u00ad grations \nas data models evolve. Given different versions of a data model, it can automatically derive textual, \ned\u00aditable evolution traces that can be executed to perform data migration. The data model editor uses \nviews to gen\u00aderate these traces and supports the full range of editor features for editing them.  Aster \n[31], an attribute grammar language based on strategies for description of attribute propagation pat\u00adterns. \n PIL [24], a Java-like, object-oriented programming lan\u00ad guage that targets multiple software platforms. \n   Mobl, a DSL for web-based mobile phone applications. It generates HTML/Javascript code when .les \nare saved, allowing them to be directly tested in a browser.  NWL (shown in this paper) and WebDSL [51], \na DSL for the Web. While WebDSL was developed using Stratego, it did not follow the idioms we presented \nin this paper that would allow it to fully integrate into and IDE. We are currently working on describing \nthe full static semantics of the language and its extensions using this new style.  An assembly language \nfor Java bytecode, used mainly as a pedagogical tool for inspecting and creating Java class .les, or \nto directly generate bytecode from other Spoofax languages. With over 200 instruction keywords it cur\u00adrently \nbene.ts greatly from syntactic content completion; semantic content completion could even improve the \npro\u00adgramming experience more based on the stack state at a given point in a program.  Observations To \ngive a few observations about our expe\u00adrience, Spoofax allows for a much more agile development model \nthan was previously possible with separate tools for syntax de.nition, meta-programming, and especially \nIDE development. As languages are developed they are directly usable in the IDE from the point that a \nsyntax is de.ned. From there, developers can incrementally add additional functionality, from presentational \neditor services to semantic analyses and code generation. Not all languages listed above have yet reached \nthe level of maturity where they incorporate the full set of services from Figure 2, but they still provide \nan improved user experience compared to a standard text ed\u00aditor. Using Spoofax also changed the deployment \nmodel of the languages: they can now be distributed as Eclipse plugins instead of separate command-line \ncompilers, which tends to be much more appealing to end developers. In our experience the Spoofax workbench \nsigni.cantly lowers the bar for creating a new language by providing an interactive environment for development \nand playing with it as it evolves. We have developed a number of experimen\u00adtal languages to try out new \nlanguage concepts, and are now using it with great success in a course on model-driven soft\u00adware engineering. \nIt allows students to experiment with lan\u00adguage features and experience all aspects of language devel\u00adopment \nin a uni.ed environment. For a course on compiler construction, we will use the bytecode language to \nallow stu\u00addents to experiment with stack architectures and abstractions over a low-level language. Customization \nBased on the Eclipse platform, Spoofax language plugins are open to various forms of extensions and integration \nwith other plugins. In the WebDSL plugin we particularly made use of that, and integrated the plu\u00adgin \nwith the Eclipse Web Tools Platform for testing and deploying web applications. The plugin also provides \nits own wizard that con.gures database and deployment con\u00ad.guration. These customizations have been implemented \nas custom Java code, directly embedded in the plugin itself. The WebDSL plugin also integrates with the \nAcoda plugin: Acoda can extract data models from web applications, show these in a view, and then derive \nevolution traces by compar\u00ading data models. Evolution As languages evolve with new insights, new constructs \nmay be added and others removed, which can lead to incompatibilities with older programs. One way Spoofax \nassists in migrating older DSL programs to newer revisions of a language is through the notion of deprecated \nsyntax. Syntactic constructs marked deprecated are displayed with a warning in the editor, and may be \ntransformed to updated constructs using desugaring rules (Section 4.2) or by a mi\u00ad gration transformation \nthat processes these constructs and produces a migrated program. An area of future work is to provide \ntool support to assist in these migrations, much like Acoda can do for data models. 6. Implementation \nThe implementation of Spoofax is based on the Eclipse plat\u00adform, allowing it to be used together with \nother, language\u00adindependent Eclipse plugins such as build management tools and other language-speci.c \nplugins. For the de.nition of generic IDE components we make use of the IMP framework [7, 8], which greatly \nsimpli.ed the construction of these components by abstracting over the Eclipse API and guiding us through \nthe development process using wizards. Languages developed in our environ\u00adment maintain compatibility \nwith IMP. In addition to the ser\u00advice descriptor DSLs, it is also possible to use Java-based implementations \nusing the IMP framework to implement components of a language. The language workbench integrates the \nlanguage para\u00admetric editor service components based on IMP with the Spoofax libraries for parsing (JSGLR) \nand running Strat\u00adego (Stratego/J) [1]. As Spoofax/IMP the of.cial name of the workbench integrates \nnearly all of the libraries of the Spoofax project, the workbench is also simply called the Spoofax language \nworkbench. 6.1 Language-Parametric Editor Services From an implementation point of view, only a small \npor\u00adtion of an IDE or IDE plugin implementation is actually language-speci.c. A great part of the implementation \nof IDE components deals with accidental complexity that has little or no relevance to a particular language. \nIDE development frameworks such as IMP [7, 8] and TMF [56] simplify the implementation of these components \nby abstracting away from many of these details. In Spoofax we implemented IDE components in a lan\u00adguage-parametric \nfashion. Each component is written in Java, and interacts with the APIs for abstract syntax trees, tokens, \ntext editor widgets, the .le system, the parser and error recovery, etc. However, it does not include \nany speci.c knowledge of the language it is used for. Instead, the com\u00adponents interpret an editor descriptor \nthat con.gures these language-speci.c parts. For each editor service, a factory class that reads the \neditor descriptor for that service, and in\u00adstantiates the language-parametric implementation class for \nit. These classes use the standard Java collection classes such as hash tables to ef.ciently store and \naccess the language con.guration. For example, for the syntax highlighting ser\u00advice, we maintain hash \ntables that specify which format\u00adting style to apply to which kind of character sequence. For parsing, \nwe use a generated parse table that is dynamically loaded into the environment. We use proxy classes \nto implement the Eclipse and IMP extension points for editor services, satisfying the static Eclipse/OSGi \ncomponent model for loading plugins. These proxy classes invoke the corresponding factory class as ser\u00advices \nare .rst used, loading the parametrized implementation classes. When a language de.nition is changed, \nthe proxy classes seamlessly load new services from the descriptors. Parser technology and IDE components \nKey for rapid feedback in interactive environments is a parser that supports error recovery in order \nto parse .les with syntax errors and incomplete programs as a programmer edits the text. As an example, \nconsider the .le at the left of our screenshot in Figure 4. This .le is not syntactically correct, since \nthe last production does not have a symbol it matches to. To still provide content completion, the parser \nstill has to produce a sensible abstract representation for the editor services to operate on. In [11, \n29] we described language-generic error recovery techniques that we use in the Spoofax language workbench \nto address this issue. A number of editor services directly interact with the syn\u00adtactic state of the \nparser. For instance, the bracket insertion service needs to determine if the cursor is not inside a \nstring or comment terminal. If that is the case, and the user types an opening bracket {, the service \nshould not automatically insert the closing bracket }. One way to determine whether the cursor is inside \na string or comment is simply having a language-speci.c blacklist of syntactic constructs were bracket \ninsertion should be disabled. However, to do this in a language-agnostic way, we had to take a different \nap\u00adproach. Instead, we analyze the active production at the se\u00adlected character, which can be determined \nfrom the parse tree. If it is a lexical production, we can examine the lexical character class that can \nbe parsed by it. If the character class includes the bracket that would be inserted (e.g., }), then that \nindicates that the bracket would become part of the lexical. For these cases, closing bracket insertion \nis disabled. Another editor service that interacts directly with the parser is content completion. As \nwe discussed in Section 4.7, programs are often in a syntactically incorrect state when a completion \nproposal is demanded. For example, an expres\u00adsion e. may be a property access expression in the mak\u00ading. \nIf content completion is triggered at that point, we insert a placeholder identi.er at the point of the \ncursor, forming an expression e.placeholder, and parse the .le again. This ensures that the expression \nis still parsed as a compound expression. Any missing semicolons, parenthe\u00adses, etc. can be picked up \nby the regular error recovery rules. The placeholder also allows us to easily add an arti.cial COMPLETION \nconstructor at the point where the placeholder appears, which is used for the content completion analysis \nof Section 4.7. Interpretation versus compilation Using language-para\u00admetric editor services does not \nenforce an interpretative model. It is also possible to use language-parametric edi\u00adtor services with \ncompiled Java classes that are dynamically loaded using classloaders. In fact, we use classloaders to \nload compiled Stratego speci.cations for semantic services. Using a compiled model can lead to improved \nruntime per\u00adformance, but comes at the cost of compilation speed. For Stratego, developers can choose \nwhether to interpret or com\u00adpile speci.cations, depending on whether they want more agile development \nor if they want to distribute the plugin to end developers. A similar approach could also be used for \nsyntactic editor services, but we feel that the trade-off of compilation time versus performance for \nthose services may be unacceptable: we have never seen performance problems for those services based \non an interpretative model. 6.2 Semantic Services and Rewrite Rules The Stratego language was originally \ncompiled to C, but we developed a more .exible backend that compiles it to Java and interoperates with \nEclipse. Where the C-based Strat\u00adego operates only on the ATerm data type of the ATerm li\u00adbrary [45], \nthe Java implementation is more .exible and can transform any tree structure that implements the IStratego-Term \ninterface. Using adapter classes, any Java data type can be made to implement it. This approach is called \nthe program object model adapter (POM) approach. Previous experience with a Stratego interpreter on Java \nshowed that this approach allows rule-based transformations to interoperate with Java\u00adbased frameworks \nsuch as a compiler frontends [28]. We use the POM adapter approach to transform trees that maintain position \nand layout information. By using a custom factory class used to construct new IStrategoTerm instances, \nwe implemented a form of origin tracking [46] for Stratego. Origin tracking is key to concise, position-agnostic \nspeci.cation of transformations and analyses in Spoofax. The term factory class is used to construct \nnew terms by compiled and interpreted Stratego programs. Term fac\u00adtories have methods to create new terms \ngiven a construc\u00adtor name/and or children or by parsing them from .les [28]. We added methods to replace \nsubterms of a term. Terms are functional, immutable data types, so by default these meth\u00adods simply return \na new term with the given subterms. In Spoofax, we return a new term that maintains a link to the original \nterm and its children. We changed the implementa\u00adtion of the Stratego traversal operators all, some, \nand one to use the new replace methods. This way, all strategies that use these combinators (such as \nalltd and collect-all, shown in this paper) support origin tracking.  6.3 Editor Extensibility and Customization \nLanguage workbenches provide an integrated development environment for building a language and IDE support, \nab\u00adstracting over low-level IDE implementation details. Still, it can be useful to have a backdoor to \nescape the environ\u00adment and add features that (we) the developers of the work\u00adbench had not anticipated. \nSpoofax language de.nitions can be extended using the standard Eclipse extension model. New components \ncan be added to plugins simply by declaring them in the plugin.xml descriptor .le and implementing them \nin Java. Since we base our implementation on IMP, helpful IMP wizards can even generate skeletal Java \nimplementation for common editor services. Once declared, Java implementa\u00adtions of services can even \noverride the Spoofax implemen\u00adtations. Drawbacks of adding services this way are that they do not provide \nthe same abstractions as DSLs would, and that they tie developers to the standard Eclipse way of plu\u00adgin \ndevelopment: custom, Java-based services can only be used in a secondary Eclipse instance. 7. Discussion \nand Related Work Spoofax is a language workbench for textual domain-speci.c languages. Textual languages \nbene.t from integration with standard, text-based version control systems and issue track\u00aders, easy importing \nand exporting of .les from other tools (avoiding vendor lock-in), .les that are editable with other tools, \nand free text editing. Notable other tools for creating and using textual DSLs are the Meta-Environment \n[34, 44], EMFText [22], MontiCore [36], TCS [26], TEF [55], and Xtext [14]. A thorough comparison of \na number of these tools has recently been provided by Goldschmidt et al [19] and by Pfeiffer and Pichler \n[40]. In our discussion we con\u00ad trast these tools to Spoofax. The Meta-Environment is a platform for \nlanguage devel\u00adopment, source code analysis, and source code transforma\u00adtion [34, 44]. It includes SDF, \nthe ASF term rewriting lan\u00ad guage, and provides an IDE framework written in Java. The Meta-Environment \nderives basic syntax highlighting from SDF grammars. ASF tree-traversal may also be used to an\u00adnotate \nthe AST with coloring directives. ASF is also used to specify the typing rules of the language, and may \ninclude custom error messages, presented in a separate view. The IDE framework provides outlining but \nnone of the other pre\u00adsentation, editing, or semantic services provided by Spoofax. Compared to the Stratego \nlanguage, ASF has limited expressive power. ASF is a pure term rewriting language, whereas Stratego adds \nstrategies [52] and dynamic rules [4], which have been key for concise, reusable analyses in Spoofax. \nIn Spoofax we use origin tracking for position\u00adagnostic speci.cation of editor services. Origin tracking \nwas originally implemented as a prototype for ASF [46], but is no longer used in the current version. \n EMFText [22], TEF [55], and TCS [26] take a differ\u00ad ent approach to syntax development than we do in \nSpoofax. Rather than combining the speci.cation of concrete and ab\u00adstract syntax into a single grammar, \nthey start with the con\u00adstruction of a metamodel. TCS and EMFText have a generic concrete syntax that \ncan be derived from a metamodel, at the cost of domain-speci.c notation. In EMFText, develop\u00aders also \nhave the option to write their own grammar with pro\u00adductions that map to elements of the metamodel. On \nthe one hand, this approach allows the use of existing EMF meta\u00admodels for building new languages, which \ncan be useful in certain cases. On the other hand, the approach is also less agile than using a syntax \nformalism that integrates abstract and concrete syntax: it introduces redundancies in the gram\u00admar, and \nrequires the syntax to be maintained in two places. The three workbenches provide error markers, reference \nre\u00adsolving, and content completion that can be customized us\u00ading Java, but none of the presentation and \nediting services of Figure 2. Xtext [14] is also based on EMF metamodels, but inte\u00ad grates the speci.cation \nof concrete syntax and metamodel into a single grammar speci.cation. Xtext was originally part of openArchitectureWare \n[13], and used the OCL-like Xtend language for model transformations and for the spec\u00adi.cation of problem \nmarkers using constraints and for ref\u00aderence resolving. Recently, Xtext has been reimplemented using \nTMF [56]. It now relies on grammar annotations and uses Java code to describe the static semantics of \nlanguages and all but the most basic editor services. The abstract representation of programs in Spoofax \nis based on trees, where dynamic rules superimpose graph structures. In contrast, EMF is based on graphs. \nEMFText and Xtext allow annotations in grammar productions to spec\u00adify simple use-def relations between \nproductions that intro\u00adduce back-edges to the abstract syntax tree, effectively pro\u00adducing graphs. This \napproach of syntactic name resolution only works for names with a global scope (or lexical scopes in \nthe case of EMFText). It is inadequate for compound ex\u00adpressions (e.g., blog.author). EMFText and Xtext \nresort to Java code to specify these relations. In Spoofax, the name analysis is fully speci.ed in a \nrule-based Stratego speci.ca\u00adtion. An interesting future step for Spoofax could be to map abstract syntax \ntrees and dynamic rules to EMF models, and express constraints over such models with Stratego. MontiCore \n[36] generates custom Java classes to rep\u00ad resent the abstract syntax. It supports basic presentational \nservices, which are speci.ed as grammar properties. Syn\u00adtax coloring is speci.ed as lists of keywords \nto highlight. Pre-de.ned (Java-style) comments are supported. Folding is speci.ed by a list of non-terminals. \nFor semantic editor ser\u00advices, MontiCore grammars specify events, which may be specialized with user-de.ned \nJava classes. Interestingly, with the exception of the Meta-Environment and TEF, all tools that we described \ngenerate ANTLR parsers. TEF uses a the RunCC parser generator. ANTLR s LL(k) or LL(*) parsers cannot \ncope with left recursion in grammars. Likewise, RunCC s LR(k) parsers are limited to a subset of the \ncontext-free grammars. This means that they are not closed under composition, which means that adding \nextensions to a grammar or reusing grammars can intro\u00adduce con.icts in the parser [32]. These parsers \nalso rely on using a single, separate scanner, which means that adding extensions with a different lexical \nsyntax is not possible. In contrast, Spoofax and the Meta-Environment use SDF to specify grammars and \ngenerate scannerless generalized LR (SGLR) parsers. Based on SGLR parsing, SDF grammars can be freely \ncomposed, allowing for embedded languages and language extensions. One area in which Spoofax excels compared \nto other tools is in supporting agile language design and development. Languages can be incrementally \ndeveloped and changes can be dynamically loaded into the environment. Spoofax au\u00adtomatically derives \nsyntactic editor services from the syn\u00adtax de.nition. Editor services can then be selectively cus\u00adtomized \nas desired. In contrast, the other tools often provide generic syntax highlighting for keywords and hardcoded \nde\u00adfault symbols such as strings, but do not derive highlight\u00ading or other services based on analysis \nof the grammar. Of the other tools, only the Meta-Environment and TCS have the ability to dynamically \nreload language de.nitions with\u00adout requiring the editor environment to be relaunched. In the case of \nthe Meta-Environment, this comes at the cost of the idiosyncrasies of a custom IDE environment rather \nthan in\u00adtegration into a common language platform such as Eclipse. TCS integrates into Eclipse, but is \nprimarily designed for adding a textual syntax to languages that have a model-based principal representation. \nWhile it allows free text editing, it does not allow the same .exibility in language design as other \nworkbenches where language engineers can write their own grammar. We use the Stratego language for analyses, \ntransforma\u00adtions, and code generation. Other workbenches use Java classes for analysis, sometimes combined \nwith grammar an\u00adnotations, Java visitors for transformations, and template en\u00adgines for code generation. \nBased on strategies and rewrite rules, Stratego concisely specify analyses and transforma\u00adtions. Providing \na choice of concrete object syntax (ensuring syntactic correctness) [50] and string interpolation, Stratego \nalso provides a .exible solution for code generation. Other notable meta-programming languages include \nASF+SDF [12], JastAdd [20], Rascal [35], and TXL [10]. They provide limited IDE support at this point, \nalthough the developers of JastAdd and Rascal are actively working on IDE support dedicated to their \nmeta-programming lan\u00adguages. However, much like the original Spoofax Stratego editor [27], they do not \nprovide a language workbench so\u00ad lution for languages developed with them. Like Stratego, ASF+SDF and \nTXL support a form of concrete object syn\u00adtax, but they do not support string interpolation. Only Rascal \nsupports both forms of code generation. JastAdd relies on Java visitors on the abstract syntax tree to \ngenerate code. 8. Open Issues and Future Work In this paper we showed that the Stratego language can \nbe used for concise speci.cations of analysis, transformations, and code generation. Still, many other \nmeta-programming languages exist that each have their own merits and uses. We believe that Spoofax has \nthe potential to become a common, open platform for hosting multiple meta-programming lan\u00adguages. Spoofax \nde.nes a lightweight, technology-agnostic interface between editor services and semantic analyses. Analysis \nspeci.cations in other meta-programming lan\u00adguages could follow the same interface, and to some de\u00adgree \nmay follow the same idioms for reuse, allowing them to implement the same set of editor services. One \nconstraint is the representation of the abstract syntax, which may re\u00adquire marshalling to another form. \nAnother is our use of ori\u00adgin tracking in the speci.cation of analyses. Without origin tracking, semantic \nspeci.cations would have to explicitly ensure that analysis results contain position information. In \nprevious work, we applied strategic programming in the .eld of attribute grammars, enabling high-level, \ndeclar\u00adative speci.cations of semantic analyses in the Aster lan\u00adguage [31]. Based on Aster s reusable \nattribute propagation patterns for name, type, and .ow analysis, we would like to investigate how Aster \nspeci.cations can be integrated into Spoofax and used to specify IDE services. Another area of future \nwork is in providing tool support for .rst-class language components. Based on the modu\u00adlar SDF syntax \nformalism and SGLR parsing, it is possi\u00adble to decompose languages into separate, reusable compo\u00adnents \n[5]. As an example, WebDSL [51] reuses the syntax de.nition of HQL for queries. Such compositions still \nre\u00adquire much manual work, as Spoofax provides only limited tool support for these forms of reuse. One \nideal scenario may be that users of a language could just pick and match the language features they need, \nand that the environment com\u00adposes them. Composition at the semantic level poses addi\u00adtional challenges. \nBased on a uniform type system and a sin\u00adgle host language, it is possible to combine language compo\u00adnents. \n(Notably, MPS [25] relies on these properties.) How\u00ad ever, if a different host language or type system \nis used, reuse is currently limited to the syntactic level. Spoofax provides support for a signi.cant \nnumber of ed\u00aditor services found in modern IDEs, and provides a solid foundation for implementing new \nservices, based on back\u00adground parsing and reuse of semantic analyses. Users can currently add additional \ncomponents using Java, but we would like to support more services using DSLs in the fu\u00adture. Services \nthat we would particularly like to support are refactoring and debugging. In current IDE implementations, \nthese services are especially demanding to implement, re\u00adquiring sophisticated analyses for refactoring, \nand interac\u00adtion with the runtime state of applications for debugging. Refactorings are highly language-speci.c \ntransforma\u00adtions, but they often take common forms: rename some\u00adthing, extract something, etc. We expect \nthat it would be possible to describe preconditions, postconditions, and invariants of these forms of \nrefactorings in a uniform way based on our idioms for name and type analysis. Based on the Stratego language, \nand using origin tracking for layout\u00adagnostic transformations, we hope to .nd ways to ef.ciently and \nsuccinctly express refactorings. For debugging, the runtime state of domain-speci.c lan\u00adguages can take \nmany different forms. The IMP platform only provides rudimentary support for of languages that gen\u00aderate \nJava code [8]. While we could also add support for de\u00ad bugging of DSLs that generate Java, we are also \ninterested in making it easier to describe debuggers in a more technology\u00adagnostic way, and in .nding \ngeneral patterns to ef.ciently construct debuggers for arbitrary DSLs. 9. Conclusion Modern IDEs increase \ndeveloper productivity by incorpo\u00adrating many different kinds of editor services speci.c to the syntax \nand semantics of a language. They assist developers in understanding and navigating through the code, \nthey di\u00adrect developers to inconsistent or incomplete areas of code, and they even help with editing \ncode by providing automatic indentation, bracket insertion, and content completion. As a consequence, \ndevelopers that have grown accustomed to these services are growing less accepting of languages that \ndo not have solid IDE support. To ef.ciently develop languages with IDE support, Spoo\u00adfax supports selective, \nincremental development of editor services that can be dynamically loaded, evaluated, and tuned in the \nsame environment. Using high-level languages to specify the syntax and semantics of a language, it pro\u00advides \na language development solution that greatly increases productivity of language engineers in building \nlanguage and IDE components compared to using handwritten compo\u00adnents or separate language engineering \ntools. Acknowledgements This research was supported by NWO/JACQUARD projects 612.063.512, TFA: Transforma\u00adtions \nfor Abstractions, and 638.001.610, MoDSE: Model-Driven Software Evolution. We would like to thank Karl \nTrygve Kalleberg for his many contributions to the Spoofax project; the development teams of IMP, SDF, \n(J)SGLR, and Stratego/XT for their valuable efforts; Maartje de Jonge and Emma S\u00a8oderberg for their contributions \nto error recov\u00adery with JSGLR; Rob Vermaas, Bernhard Merkle, and the anonymous reviewers for suggestions \nfor this paper; and .\u00adnally our users for providing continuous feedback and com\u00ading up with interesting \nnew ideas. References [1] The Spoofax project. http://www.spoofax.org/. [2] P. Borras, D. Clement, T. \nDespeyroux, J. Incerpi, G. Kahn, B. Lang, and V. Pascual. Centaur: the system. SIGPLAN Not., 24(2):14 \n24, 1989. [3] M. Bravenboer, K. T. Kalleberg, R. Vermaas, and E. Visser. Stratego/XT 0.17. A language \nand toolset for program trans\u00adformation. Sci. of Comp. Programming, 72(1-2):52 70, June 2008. Special \nissue on experimental software and toolkits. [4] M. Bravenboer, A. van Dam, K. Olmos, and E. Visser. \nPro\u00adgram transformation with scoped dynamic rewrite rules. Fun\u00addamenta Informaticae, 69(1 2):123 178, \n2006. [5] M. Bravenboer and E. Visser. Concrete syntax for objects: domain-speci.c language embedding \nand assimilation with\u00adout restrictions. In OOPSLA, pages 365 383, 2004. [6] F. Budinsky, D. Steinberg, \nE. Merks, R. Ellersick, and T. J. Grose. Eclipse Modeling Framework. Addison-Wesley, 2004. [7] P. Charles, \nR. M. Fuhrer, and S. M. Sutton, Jr. IMP: a meta-tooling platform for creating language-speci.c IDEs in \nEclipse. In ASE 2007, pages 485 488, 2007. [8] P. Charles, R. M. Fuhrer, S. M. Sutton, Jr., E. Duesterwald, \nand J. Vinju. Accelerating the creation of customized, language\u00adspeci.c IDEs in Eclipse. In OOPSLA 2009. \nACM, 2009. [9] S. Cook, G. Jones, S. Kent, and A. C. Wills. Domain-Speci.c Development with Visual Studio \nDSL Tools. Addison Wesley, 2007. [10] J. R. Cordy, C. D. Halpern-Hamu, and E. Promislow. TXL: a rapid \nprototyping system for programming language dialects. In Conf. on Comp. Languages, pages 280 285. IEEE, \n1988. [11] M. de Jonge, E. Nilsson-Nyman, L. C. L. Kats, and E. Visser. Natural and .exible error recovery \nfor generated parsers. In SLE, 2010. [12] A. v. Deursen, J. Heering, and P. Klint, editors. Language \nPrototyping: An Algebraic Speci.cation Approach, volume 5 of AMAST Series in Computing. World Sci. Publ. \nCo., 1996. [13] S. Efftinge et al. openArchitectureWare User Guide. Version 4.3. Available from http://www.eclipse.org/gmt/oaw/ \ndoc/4.3/html/contents/, April 2008. [14] S. Efftinge and M. Voelter. oAW xText: A framework for tex\u00adtual \nDSLs. In Workshop on Modeling Symposium at Eclipse Summit, 2006. [15] M. Fowler. A language workbench \nin action -MPS. http: //martinfowler.com/articles/mpsAgree.html, 2005. [16] M. Fowler. Language workbenches: \nThe killer-app for do\u00admain speci.c languages? http://martinfowler.com/ articles/languageWorkbench.html, \n2005. [17] M. Fowler. PostIntelliJ. http://martinfowler.com/ bliki/PostIntelliJ.html, 2005. [18] M. Fowler. \nA pedagogical framework for domain-speci.c languages. IEEE Software, 26:13 14, 2009. [19] T. Goldschmidt, \nS. Becker, and A. Uhl. Classi.cation of concrete textual syntax mapping approaches. In ECMDA-FA 2008, \nvolume 5095 of LNCS, pages 169 184. Springer, 2008. [20] G. Hedin and E. Magnusson. JastAdd: an aspect-oriented \ncompiler construction system. Sci. Comput. Program., 47(1):37 58, 2003. [21] J. Heering, P. R. H. Hendriks, \nP. Klint, and J. Rekers. The syn\u00adtax de.nition formalism SDF: Reference manual. SIGPLAN Not., 24(11):43 \n75, 1989. [22] F. Heidenreich, J. Johannes, S. Karol, M. Seifert, and C. Wende. Derivation and re.nement \nof textual syntax for models. In ECMDA-FA, pages 114 129, 2009. [23] Z. Hemel, L. C. L. Kats, D. M. Groenewegen, \nand E. Visser. Code generation by model transformation. A case study in transformation modularity. Softw. \nand Syst. Modeling, 2009. [24] Z. Hemel and E. Visser. PIL: A platform independent lan\u00adguage for retargetable \nDSLs. In SLE, 2010. [25] JetBrains. Meta programming system. https://www. jetbrains.com/mps. [26] F. \nJouault, J. B\u00b4ezivin, and I. Kurtev. TCS: a DSL for the spec\u00adi.cation of textual concrete syntaxes in \nmodel engineering. In Generative and Component Engineering (GPCE 06), pages 249 254. ACM, 2006. [27] \nK. T. Kalleberg and E. Visser. Spoofax: An interactive devel\u00adopment environment for program transformation \nwith Strate-go/XT. In Workshop on Language Descriptions, Tools, and Applications (LDTA 2007), pages 47 \n50, 2007. [28] K. T. Kalleberg and E. Visser. Fusing a transformation lan\u00adguage with an open compiler. \nIn Workshop on Language De\u00adscriptions, Tools, and Applications (LDTA 2007), volume 203 of ENTCS, pages \n21 36. Elsevier, April 2008. [29] L. C. L. Kats, M. de Jonge, E. Nilsson-Nyman, and E. Visser. Providing \nrapid feedback in generated modular language en\u00advironments. Adding error recovery to scannerless generalized-LR \nparsing. In OOPSLA, pages 445 464, 2009. [30] L. C. L. Kats, K. T. Kalleberg, and E. Visser. Domain\u00adspeci.c \nlanguages for composable editor plugins. In Work\u00adshop on Language Descriptions, Tools, and Applications \n(LDTA 2009). Elsevier, April 2009. [31] L. C. L. Kats, A. M. Sloane, and E. Visser. Decorated attribute \ngrammars. Attribute evaluation meets strategic programming. In Conference on Compiler Construction (CC \n2009), volume 5501 of LNCS, pages 142 157. Springer, March 2009. [32] L. C. L. Kats, E. Visser, and G. \nWachsmuth. Pure and declara\u00adtive syntax de.nition: Paradise lost and regained. In Onward!, 2010. [33] \nS. Kelly and J.-P. Tolvanen. Domain-Speci.c Modeling. En\u00adabling Full Code Generation. John Wiley &#38; \nSons, Inc., 2008. [34] P. Klint. A meta-environment for generating programming environments. ACM Transactions \non Software Engineering Methodology, 2(2):176 201, 1993. [35] P. Klint, T. van der Storm, and J. Vinju. \nRascal: a domain speci.c language for source code analysis and manipulation. In SCAM, pages 168 177, \n2009. [36] H. Krahn, B. Rumpe, and S. V\u00a8olkel. Monticore: Modular development of textual domain speci.c \nlanguages. In TOOLS, pages 297 315, 2008. [37] M. F. Kuiper and J. Saraiva. Lrc -a generator for incremental \nlanguage-oriented tools. In Compiler Construction (CC 98), pages 298 301, London, UK, 1998. Springer-Verlag. \n[38] M. Mernik, J. Heering, and A. Sloane. When and how to develop domain-speci.c languages. ACM Computing \nSurveys (CSUR), 37(4):344, 2005. [39] N. Nystrom, M. Clarkson, and A. Myers. Polyglot: An Exten\u00adsible \nCompiler Framework for Java. Compiler Construction (CC 03), 2622:138 152, Apr. 2003. [40] M. Pfeiffer \nand J. Pichler. A comparison of tool support for textual domain-speci.c languages. In Workshop on Domain-Speci.c \nModeling, pages 1 7, 2008. [41] T. Reps and T. Teitelbaum. The synthesizer generator. SIG-SOFT Softw. \nEng. Notes, 9(3):42 48, 1984. [42] S. Saunders, D. K. Fields, and E. Belayev. IntelliJ IDEA in Action. \nManning, 2006. [43] C. Simonyi. The death of computer languages, the birth of Intentional Programming. \nTech. report, MS Research, 1995. [44] M. Van den Brand, A. Van Deursen, J. Heering, H. De Jong, et al. \nThe Asf+Sdf Meta-Environment A Component-Based Language Development Environment. In Compiler Construc\u00adtion, \nvolume 44 of LNCS, pages 365 370. Springer, 2001. [45] M. G. J. van den Brand, H. de Jong, P. Klint, \nand P. Olivier. Ef.cient annotated terms. Software, Practice &#38; Experience, 30(3):259 291, 2000. [46] \nA. van Deursen, P. Klint, and F. Tip. Origin tracking. Journal of Symbolic Computation, 15(5/6):523 545, \n1993. [47] A. van Deursen, P. Klint, and J. Visser. Domain-speci.c lan\u00adguages: an annotated bibliography. \nSIGPLAN Not., 35(6):26 36, 2000. [48] S. Vermolen and E. Visser. Heterogeneous coupled evolution of software \nlanguages. In MoDELS, pages 630 644, 2008. [49] E. Visser. A family of syntax de.nition formalisms. Technical \nReport P9706, Programming Research Group, University of Amsterdam, July 1997. [50] E. Visser. Meta-programming \nwith concrete object syntax. In GPCE, pages 299 315, 2002. [51] E. Visser. WebDSL: A case study in domain-speci.c \nlanguage engineering. In GTTSE, pages 291 373, 2007. [52] E. Visser, Z.-E.-A. Benaissa, and A. P. Tolmach. \nBuilding program optimizers with rewriting strategies. In ICFP, pages 13 26, 1998. [53] W. Waite and \nG. Goss. Compiler construction. 1984. [54] M. P. Ward. Language-oriented programming. Software Concepts \nand Tools, 15(4):147 161, 1994. [55] Textual Editing Framework (TEF). http://www. informatik.hu-berlin.de/sam/meta-tools/tef. \n[56] Textual modeling framework (TMF). http://www. eclipse.org/modeling/tmf/. [57] The WAtson Libraries \nfor Analysis. http://wala. sourceforge.net/.    \n\t\t\t", "proc_id": "1869459", "abstract": "<p>Spoofax is a language workbench for efficient, agile development of textual domain-specific languages with state-of-the-art IDE support. Spoofax integrates language processing techniques for parser generation, meta-programming, and IDE development into a single environment. It uses concise, declarative specifications for languages and IDE services. In this paper we describe the architecture of Spoofax and introduce idioms for high-level specifications of language semantics using rewrite rules, showing how analyses can be reused for transformations, code generation, and editor services such as error marking, reference resolving, and content completion. The implementation of these services is supported by language-parametric editor service classes that can be dynamically loaded by the Eclipse IDE, allowing new languages to be developed and used side-by-side in the same Eclipse environment.</p>", "authors": [{"name": "Lennart C.L. Kats", "author_profile_id": "81381609357", "affiliation": "Delft University of Technology, Delft, Netherlands", "person_id": "P2354090", "email_address": "", "orcid_id": ""}, {"name": "Eelco Visser", "author_profile_id": "81100561215", "affiliation": "Delft University of Technology, Delft, Netherlands", "person_id": "P2354091", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1869459.1869497", "year": "2010", "article_id": "1869497", "conference": "OOPSLA", "title": "The spoofax language workbench: rules for declarative specification of languages and IDEs", "url": "http://dl.acm.org/citation.cfm?id=1869497"}