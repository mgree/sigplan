{"article_publication_date": "03-01-1993", "fulltext": "\n Compositional Analysis of Modular Logic Programs Michael Codish* Saumya K, Debray$ Roberto Giacobazzi~ \nAbstract This paper describes a semantic basis for a composi\u00adtional approach to the analysis of logic \nprograms. A logic program is viewed aa consisting of a set of mod\u00adules, each module defining a subset \nof the program s predicates. Analyses are constructed by considering abstract interpretations of a compositional \nsemantics. The abstract meaning of a module corresponds to its analysis and composition of abstract meanings \ncorre\u00adsponds to composition of analyses. Such an approach is essential for large program development \nso that al\u00adtering one module does not require re-analysis of the entire program. We claim that for a \nsubstantial class of programs, compositional analyses which are based on a notion of abstract unfolding \nprovide the same pre\u00adcision as non-compositional analysis. A compositional analysis for ground dependencies \nis included to illus\u00adtrate the approach. To the beat of our knowledge this is the first account of a \ncompositional framework for the analysis of logic programs. Introduction It is widely acknowledged \nthat as the size of a pro\u00adgram increases, it becomes impractical to maintain it as a single monolithic \nstructure. Instead, the program *Department of Computer Science, KU Leuven, Belgium. codish@cs .kuleuven \n.ac. be. i Department of Computer Science, The University of Ari\u00adzona, Tucson, AZ 85721, USA. debray@cs. \narizona. edu. Sup\u00adported in part by the National Science Foundation under grant number CCR-8901 283. \n$Djpwtimento di Informatica, Universit&#38; di Piss, CO~O Italia 40, 56125 Piss, Italy. giaco@di. unipi. \nit. Supported in part by the Esprit Basic Research Action 3012-Compulog. Permission to copy without fee \nall or part of this material ie granted provided that the copies are not made or distributed for direct \ncommercial advantage, the ACM copyright notice and tha title of tha publication and ite date appear, \nand notice is given that copying is by permission of the Association for Computing Machinery. To copy \notherwise, or to republish, requires a fee and/or specifio permission. ACM-20th PoPL-l/93-S.C., USA @ \n1993 ACM 0.89791.561.5/93/0001 /0451 . ..$1.50 has to be broken up into a number of smaller units called \nmodules that provide the desired functionality when combined. Modularity helps reduce the com\u00adplexity \nof designing and proving correctness of pro\u00adgrams. Modularity helps also in developing adaptable software. \nSince the program specifications can change while the program itself is being constructed, a modu\u00adlar \nstructure of programs and a corresponding modu\u00adlar analysis can reduce the updating complexity both in \nprogram development and in program analysis. In contrast to this situation, however, current works on \ndataflow analysis of logic programs typically assume that the entire program is available for inspection \nat the time of analysis. Consequently, it is often not pos\u00adsible to apply existing dataflow analyses \nto large pro\u00adgrams, either because the resource requirements are prohibitively high, or because not all \nprogram compo\u00adnents are available when we wish to carry out the anal\u00adysis. This is especially unfortunate \nbecause large pro\u00adgrams are typically those that stand to benefit most from the results of good dataflow \nanalysis. In this paper, we give a formal account of how mod\u00adular logic programs may be analyzed. The \nbasic idea is more or less standard: we consider a semantics to modular programs, then study how such \na semantics may be safely approximated and how the results of such approximations may be composed to \nyield flow analysia results for the entire program. We demon\u00adstrate this approach by giving a compositional \nground dependencies analysis for modular logic programs. Se\u00admantic treatments of modules in logic programs \nhave been given by a number of authors (see, for exam\u00adple, [7, 22]), typically based on nontrivial extensions \nto Horn clause logic that lead to complex semantics; it appears to us that the development of abstract \nin\u00adterpretations based on such semantics is not entirely straightforward. The semantics we consider here \nas a basis for abstract interpretations is a simplification of that proposed in [4]. The essential idea \nis to treat modules as programs in which undefined predicates are considered open. The meaning of a module \nis given in terms of iterated unfoldings of the procedures de\u00adfined in it, except that the open (i.e., \nimported) pred\u00adicates are not unfolded the result is to specify the meaning of a module in terms of structures \nthat de\u00adpend only on the meaning of the open predicates. It turns out that composition of modules is \ndescribed using the same semantic function namely, iterated unfolding as that used for describing the \nmeaning of a module, leading to a conceptually and mathemati\u00adcally simple and elegant treatment. This \nsemantics is attractive as a basis for abstrac\u00adtion as it resembles the semantics of [14] which pro\u00advides \nthe basis for abstract interpretation as described in [2] and [8]. The use of clauses aa semantic ob\u00adjects \nleads to interesting technical complications for abstract interpret ation, in that there are two indepen\u00addent \ndimensions along which we need finite descrip\u00adtions in the abstract domain, namely, finite descrip\u00adtions \nof sets of substitutions (the usual dimension), and also finite descriptions of unbounded sequences of \natoms. This is not a matter of purely theoretical inter\u00adest: in most Prolog systems currently available, \ne.g., BIM and Sicstus Prologs [3, 6], there are no a pm ori restrictions on the dependencies between \nthe differ\u00adent modules in a program (a module A depends on a module B if a procedure defined in A calls \na procedure defined in B), and it is entirely possible to have a set of modules mutually dependent on \neach other. As a prac\u00adtical matter, therefore, it is important to be able to deal with modules with arbitrary \ninter-module depen\u00addencies. Our general treatment which we call sym\u00admet ric composition--shows how these \nproblems may be addressed. However, it may incur a loss in pre\u00adcision because of the need to approximate \nobjects of unbounded size using descriptions of bounded size in a way that is not usually encountered \nin abstract in\u00adterpretations. We identify a special case, where the dependencies between modules is hierarchical, \nwhere it can be guaranteed that there will be no need to sac\u00adrifice additional precision when dealing \nwith what we call the directed composition of modules. The rest of the paper is organized as follows: \nSection 2 presents briefly some preliminary definitions and no\u00adtations. Section 3 describes the concrete \nsemantics which is the basis for abstraction. Section 4 intro\u00adduces the general compositional abstract \nsemantics, while Section 5 describes a special case where abstrac\u00adtions are defined in terms of abstract \nunfolding and presents an example for ground dependencies analysis. Section 6 illustrates how our approach \ncan be used for compositional analysis. Section 7 discusses how some restrictions on modules, assumed \nin earlier sections, can be relaxed. Section 8 discusses related work, and Section 9 concludes. 2 Preliminaries \nIn the following we assume familiarity with the stan\u00addard definitions and notation for logic programs \n[20] and abstract interpretation [11, 12]. Throughout, we will assume a fixed set of function symbols \nX, a fixed set of predicate symbols II and a fixed denumerable set of variables Var. With each function \nsymbol ~ G E and predicate symbol p E II is associated a unique nat\u00adural number called its arity a (predicate \nor function) symbol f with arit y n is written f/n. The non-ground term algebra over Z and Var is denoted \nZ erm(X, Var) or Term for short. The set of atoms constructed from predicate symbols in II and terms \nfrom Term is de\u00adnoted Atom(ll, X, Var) or Atom for short. The pow\u00aderset of a set X is denoted by P(X). \nA goal z is a se\u00adquence of atoms, and is typically written (al, . . . . an) or simply as al, . . .. an. \nWe sometimes view ii as a set and write b G ii. The empty sequence is denoted by ( ). The concatenation \nof goals &#38; and ~2 is de\u00adnoted $1:: bz. A Horn clause is an object of the form h + $ where h is an \natom, called the head, and ~ is a goal, called the body. The set of clauses constructed from elements \nof Atom is denoted C/ause(II, S, Var) or Clause for short. The set of variables occurring in a syntactic \nobject tis denoted by vars(t). A substitution is a mapping from Var to Term which acts as the identity \nalmost everywhere: it extends to apply to any syntactic object in the usual way. The identity substitution \nis denoted c. The set of idempc\u00adtent substitutions is denoted Sub. Following tradition, the application \nof a substitution O to an object t will be written tO rather than t9(tfix a partial function ).We mgu \nwhich maps a pair of syntactic objects to an idem\u00adpotent most general unifier of the objects. A state\u00adment \nd = mgu(s, t) implies that s and t are unifiable. The notation for mgu is extended aa usual for sets \nof equations. We write mgu((al, . . . . an), (bl, . . . . b~)) to denote the most general unifier of \nthe set of equations {al= tq,..., an = b~}. Note that mgu(( ), ( )) = c. A variable renaming is a substitution \nthat is a bi\u00adjection on Var. Two syntactic objects tland t2are equivalent up to renaming, written tl-tz,iftlp \n= tz for some variable renaming p. The equivalence class of tunder w is denoted by [t]~.Given an equivalence \nclass ~ of syntactic objects and a finite set of variables V, it is always possible to find a representative \nt of ~ (i.e. an object t such that [t]-= ;) that contains no variables from V. For a syntactic object \ns and a set of equivalence classes of objects 1, we denote by (cl,.. ., c~) <, 1 that c1,..., c~ are \nrepresentatives of elements of 1 renamed apart from s and from each other, namely, that 1. [Ci]w E 1; \n 2. vars(c$) n vars(s) = 0, 1< i < n; and  3. i + j implies vars(ci)nvars(cj) = 0, 1 S i,j < n. Note \nthat the empty tuple is trivially renamed apart from any object s and (possibly empty) set 1, i.e., () \n<,1. In the discussion that follows, we will be concerned with sets of clauses modulo renaming, i.e., \nsubsets of [Clause]-. For simplicity of exposition, we will abuse notation and assume that a clause represents \nits equiv\u00adalence class and write Clause rather than [Clause]-. We focus on logic programs which are constructed \nfrom predicate disjoint modules (considered also in [15, 17]). If PI,..., P. are logic program modules, \n=%~1then P U Pi is a modular logic program. A mod\u00ad ular logic program is predicate disjoint if the predi\u00adcates \ndefined in each module are disjoint from those defined in the others. For logic program (or mod\u00adule) \nP, open(P) denotes the set of predicates that occur in the body of a clause in P but are not de\u00adfined \nin P. For any program P, we denote by @p the set { [p(~) 4-p(E)]W I p C open(P) }: as we will see, these \ntautologies play an important role in defining the semantics of P. 3 Bottom-up semantics for composition \nThis section presents the semantic basis for composi\u00adtional abstract interpretations. The semantics is \nan instance of the compositional bottom-up semantics of Bossi et al. [4], specialized for the case of \npredicate disjoint modules. We propose two notions of com\u00adposition which provide the basis for composition \nof analyses. The first, symmetric composition , is that introduced in [4]. It is more general and applicable \nto the analysis of arbitrary modular logic programs. However the second, directed composition , provides \nfor potentially more precise analyses when programs have a hierarchical structure. It allows us to analyze \na module while plugging in analyses for predicates defined in other modules that are lower in the hierar\u00adchy. \nDefinition 3.1 An interpretation is any element in Int = p( C Jause). The concrete semantics is formalized \nin terms of un\u00adfolding of clauses. The unfolding operator unf speci\u00adfies the result of unfolding clauses \nfrom an interpreta\u00adtion PI with clauses from an interpretation P2. Definition 3.2 [unfolding] : The unfolding \noperator unf : Int x Int * Int is dejined as unf(Pl , P2) = ?=[(h *J, :: . . . :: Jn)c7]z, ~ ~flw: ~:,+ \ng~,.. .,~n]-CR, (n 20), ... ,hn + L4.} <c P2, u = mgu((gl, . . ..gn). (hi, hn))hn)) [ 1 Intuitively, \nthe unfolding operator yields every pos\u00adsible way to unfold each literal in each clause of PI once using \nclauses in Pz. This operator is of inter\u00adest ss it can be applied to formalize both top-down and bottom-up \nsemantics for logic programs [19], The following formalizes a bottom-up semantics for open logic programs \nin terms of iterated unfolding that is, repeatedly unfolding the clauses in a program until further \nunfolding prod~ces no change: - Definition 3.3 ~xpoint semantics [4]]: The jixpoint semantics of a program \nP is given by the function F : Int * Int, dejined as 7(P) = lfp( T$), where T$ : Int * Int is defined \nas T$(I) = unf(P, I U @p). Several aspects of this definition demand explana\u00adtion. First, compare with \nthe standard TP fixpoint semantics for Horn logic programs. The Tp opera\u00adtor infers (ground) facts from \nthe clauses in the pro\u00adgram given facts in an interpretation for the body goals. This process can also \nbe viewed as a kind of unfolding where facts (i.e, unit clauses) are used to unfold program clauses, \nOnce we consider modular programs, however, this approach is too simplistic be\u00adcause if we wish to give \na compositional semantics then open predicates, i.e., those imported from other mod\u00adules, have no definition \navailable. The solution to this problem proposed in [4] is to unfold only those predi\u00adcates which have \na definition, so that the meaning of a program becomes dependent (as intuitively it should) on the meaning \nof its open predicates. Technically, this is accomplished by letting @p to add tautologi\u00adcal clauses \nfor the open predicates and to unfold all predicates in the body of a clause. Notice that the unfolding \nof an undefined predicate with a tautologi\u00adcal clause is basically a no-op . Moreover, note that: If \nopen(P) = 0 then @p = 0 and T~(l) = tinf(P, 1). When I consists of unit clauses (facts), the fixpoint \noperator in this case gives precisely the generalized (non-ground) fixpoint semantics of [14]. Proposition \n3.4 [symmetric composition [4]] : Let PI and P2 be modules, then F(P1 U P2) = F(F(P1) U 3( P2)). Example \n1 Consider the logic program P (a portion of a quicksort program), consisting of the following two modules: \nPSP. SPM(X,[I,[I>[l). Splat(x, [YIL], [YIL1], L2) + gt(x, Y), Sp/it(x, L, Ll, L2)< Sphf(x, [YIL], Ll, \n[YIL2]) + /e(X, Y), sp12t(X, L, Ll, L2). P/g: gi(s(o), o). gt(s(x), s(Y)) -gt(x, Y). /e(O, O). /e(O, \ns(0)). /e(s(X), s(Y)) t /e(X, Y). The unfoldings of PSP specify the possible ways of split\u00adting a list \nof values into two lists of values; those larger than a given X and those smaller than X. In the module \nP,P the domain of values and the in\u00adterpretation of larger and smaller are open, since the predicates \nle/2 and gt/2 are open. Evaluation of F(P~P) proceeds as follows:~ 1. Spht(x, [],[1,[ l). 2. Split(x, \n[YJ, [Yl], [ ]) + gt(x, YJ. spiit(X, [Yl], [], [YI]) +-Wx, YI).  3. spiit(X, [Yl, Y2], [l 1, Y21, [I) \n+ gt(x, Y~), gt(x, Y~). Spht(x, [Yl, Y2], [yI],[Y2]) + gt(X, YI), /e(X, Yz). sp~it(x, [Yl, Y2], [Y2], \n[YI]) +\u00adgt(X, Yz), /e(X, Yl).  split(X, [Yl, Y2], [], [l 1, Y2]) +\u00ad/e(X, Y~), /e(X, Yz). etc. The unfoldings \nof P19 specify the relations less or equal and greater than on integers. Since open(Plg) = 0, the result \ncorresponds to the se\u00admantics of [14]: {gt(s( 0), O), le(O, O), le(O,s(0)), gt(s(s(o)),s(o)), . . . }. \nThe meaning of P,, U P,, can be evaluated directly or by applying Proposition 3.4. In either case the \nresult corresponds to the standard meaning as provided by the semantics of [14].  4 Abstract semantics \nand com\u00adposition We assume the standard framework of abstract inter\u00adpretation as defined in [11] in terms \nof Galois inser\u00adtions. We let (AInt, U, n, Q denote a complete lat\u00adtice of abstract models, where each \nabstract model de\u00adscribes a set of clauses. (Int, a, Alnt, -y) is a Galois 1we i~u~trate the &#38;USeS \nadded by successive iterations of unfolding. insertion, i.e., a : Int * AInt and -y : AInt * Int are \nmonotonic mappings, and additionally, a(~(l)) = 1 and I ~ 7(41 )) for each 1 G Jni and 1 c Alnt. The \nabstract semantics is a function ~ * : AInt -AInt which assigns an abstract model to abstractions of \nprograms. The abstract meaning of a program P is FA(cr(P)). For now, we assume only that 7A is safe with \nrespect to the concrete semantics, namely, that for every 16 Int, Q(F(I)) ~ 7A(@(I)). Abstract (symmetric) \ncomposition is analogous to concrete composition. The following theorem states the correctness of applying \nabstract composition for program analyses based on any safe abstract seman\u00adtics. Theorem 4.1 [correctness \nof abstract composition] Let (Int, cr, AInt, ~) be a Galois insertion and let FA : AInt +-AInt be a monotonic \nand safe approxi\u00admation of F. Then, for any program modules PI, P2 E Int, cr(F(P~ U Pz)) ~ FA(FA(a(P~)) \nU FA(a(Pz))). PROOF. Assume the premise of the theorem and let P1, P2 E lnt. Recall that a is continuous \nin any Galois insertion [11]. a(F(P~ u P2)) = cY(F(F(P~) u F(P2))) [ Proposition 3.4 1 ~ @(a(F(P~) u \nY(P2))) [ safety 1 = FA(a(F(Pl)) u a(7(P2))) [ a continuity [ safety and monotonicity ] 0  5 Compositional \nAnalysis In this section, we illustrate the ideas sketched in the previous section in a concrete way. \nWe focus on abstract interpretations induced from a set of ab\u00adstract substitutions A Sub, and illustrate \ntwo exam\u00adples of compositional analyses for detecting ground dependencies which describe the manner \nin which the groundless of a variable in a clause depends on the groundless of other variables induced \nfrom an appropriate e domain of abstract substitutions. In the first example we introduce the set VClause \nof clauses in which all the terms are distinct variables, Abstract substitutions describe instances of \nthese clauses pro\u00adviding a domain of abstract interpretations. This do\u00admain illustrates the technical \nproblems that can arise in the analysis of general programs. In the second ex\u00adample, we apply an additional \nlevel of abstraction to handle this problem. In the following let (A Sub, lz) be a complete lattice of \nabstract substitutions, let (p(Sub), ~S, Asub,-ys) be a Galois insertion and let VClause = V(v, w) c \nK. y~(tc) = e vars( VO) = vars( WO) { 1 c } Each element of VC lause is an equivalence class of clauses \nmodulo renaming, and is syntactically rep\u00adresented as a clause. The idea is to associate each representative \nof VClause with an abstract substitu\u00adtion that describes a set of its instances. This is ac\u00adcomplished \nin Definitions 5.2 and 5.3 (below) by for\u00admalizing abstract interpretations as mappings from VClause \nto ASub. The ordering (likewise the join and the meet) on VClause -+ A Sub is determined by the ordering \non A Sub. Namely, for Ila, 120 G VClause * ASub, l? ~ l; a Vc. If(c) ~ l;(c). In the follow\u00ading it is \nconvenient to view an abstract interpretation Ia : VClause -A Sub as an equivalent binary rela\u00adtion: \n{ (c,~) I c C VClause, K = l (c) }. Example 2 If ASub = p(Sub) then the relation gt from Ezarnpie 1 \nis described by (9i(zl, Z2); {21 + s(o), X2 l-+ 0}), (gt(z,, z,) + gt(zs, z,); {z, = S(z,), 22 = z.}) \n {1 As an example of a domain of abstract substitutions, consider the domain Dep adopted from [9]: Definition \n5.1 [dependency relation] : A relation R over a lattice X is additive ifl (x R x A y R y ) ~ (z u y) \nR (z u y ). A dependency relation R is an ad\u00additive equivalence relation (rejlexive, symmetric and transitive) \nover P( Var). We let Dep denote the com\u00adplete lattice of dependency relations ordered by impli\u00adcation \n(containment). For notational convenience, we let an arbitrary rela\u00adtion represent the smallest dependency \nrelation im\u00adplying (i.e., containing) it. Furthermore, we let WI +-+ w{,..., Wn ++ WJ denote the rela\u00adtion \n{( WI, W{),. . . . ( W., W;)} and drop set brackets when sets are singleton. A dependency relation K \ndescribes those substi\u00adtutions d satisfying the condition that for every (V, W) G K, the terms in VO \nare ground iff the terms in WO are ground. A particular case is when V = 0 (or respectively W = 0); in \nthis case it means that the terms in We (or respectively Vd) are defi\u00adnitely ground. The corresponding \nabstract interpre\u00adtation is defined by the following: Let ~ E p(Stib) and K c Dep. Define CYD : p(Sub) \n-Dep and yD : Dep + @(Sub) by: Example 3LetO= {z I+ O,y++O}andd = {z #O, y w s(0)}. Then ~D({d, O }) \nis the small\u00adest dependency relation which contains {x, Y} w 0. Note that in our notation this is written \nsimply as a~({e, e }) = {z, y} -0. It is straightforward to prove that (p(Sub), CYD, Dep, YD) k a Galois \ninsertion. We now describe how a domain of abstract interpretations is induced from (p(Sub), a,s, ASub, \n7s). Definition 5.2 [abstract interpretations I] : Define ~ : (VClause + ASub) -Int and &#38; : Int \u00ad \n( VClause + ASub) by: (C,lc) c la, d ~(1 ) = [4-e E -fs(~) ,. an { 1 c G VClause, a(l) = (c, /c) K = \nas{mgu(c, c ) I c <c 1} {} Example 4 Let ASub = Dep and /e(O, O), I= le(O, s(0)), ie(s(X), s(Y)) -le(X, \nY) {} Then, (le(z, y); {z, y} ~ 0), (~) = (/e(z, y) + /e(z , y ); 2 + z , y ++ y ) {1 In the following \nwe denote AIntD the domain of abstract interpretations where A Sub = Dep. Unfortunately ii and ~ as defined \nabove do not pro\u00advide a Galois insertion as ~ is not injective. This means that several distinct elements \nin ( VClause + A Sub) describe the same set of clauses. However this is easily fixed, as suggested in \n[12], by letting ~ induce an equivalence relation s on ( VClause + A Sub): Example 5 If ASub = Dep, If \n= {(le(z, y); {z, y} s 0)} and 1; = {(le(z, y); {z, y, z} -0)}. Then, ~(1~) = ~(1~) and consists of all \nground instances of /e(z, y). Definition !5.3 [abstract interpretations II] : Let AInt = ( VClause * \nASub)/= where = is the equiv\u00adalence relation induced by Y on ( VClause h ASub); i.e., I? ~ 1: ifl~(l~) \n= ~(1~). Define 7: Alnt + Int and a : Int + AInt by lifting ~ and G respectively: i.e., Y([l ]=) = ~(Ia) \nand a(l) = [ti(l)]~. Notice that the equivalence relation = also provides variable hiding. Given a \nclause description (c, K), where c c VC1ause and s G A Sub, the relevant vari\u00adables for the analysis \nare only those in vars( c). The in\u00ad ve c e. tuition is that if {(c, K)} s {(c, K )}, and K # K then K \n@D(~) = (V, W) vars( VO) = vars( WO) ; and tc describe the same set of abstract substitutions, 1 { when \nrestricted to the variables in vars( c). We do not require ASub to be a finite height lattice (in fact \nDep is not of finite height). However, we require that for every c c VClause, the set {[(c, K)]= I K \nc ASub} is finite. It is not difficult to show that (Int, a, Alnt, 7) is a Galois insertion. A safe abstract \nsemantics can now be defined in terms of abstract unfolding which is in turn defined in terms of an abstract \nunification function mguA : (Atom x ASub) x (Atom x ASub)* + ASub which is assumed to satisfy the (safety) \ncondition that if mgv~((ii; ~o), (( bl; ~1), . . ..(b~. Kn))) = K, 6, ~ 7s(Kt) (0 S i S n), and mgu(iit%, \n{bldl, . . ., bnf)n)) = L9,then O c 7(K). Example 6 The following is a safe abstract unifica\u00adtion function \nfor Dep similar to that introduced in [9]. mgu~((~; ~o), (( bl; ~l),. ... (b~; ~n))) = ,QoK, U{ ({z}, \nvars(t)) I z ~ t Gmgu(ii, i) } . where ~ = (bl, . . . . bn). For instance: mgq$((gt(z , /); 0), (gt(x \n, y ); X + 0, / + 0)) = X ++x t+g, y wy +-+@ indicating that X1, y , X1l, and y t are all ground. Definition \n5A [abstract unfolding]2 : The abstract unfolding operator unfA : AInt x AInt + AInt is defined as: \nunfA(Pl, Pz) = ~=(h+tl:: . . . ::tn; k), c=(h+gl ,.. .,9n; ~) E~l, ((hi +II; KI),..., u (h~ + ?.;%)) \n<c P2, ((91,...,9n), K),k = mguA ((hi; m), . . . . (hn;~n)) () The abstract fixpoint semantics is now \ndefined in terms of abstract unfolding by: Definition 5.5 [abstract jixpoint semantics]: Define 3A : \nAInt + AInt as FA(Pa) = ljp(T#~) where T$a : AInt + A1nt is defined by T$~(Ia) = unfA(Pa, Ia u O>.) and \n@~~ is the natural extension of @p for abstract programs and has the property that @\\a = CY(@P). 2Elements \nof A Sub are, in general, in%ite objects. To for\u00admally rename apart objects of A Int it is necessary \nto assume that every element of A Sub can be represented by a finite object, which is not unreasonable. \nProposition 5.6 If mguA is a safe abstract unifica\u00adtion function, then unfA is a safe abstract unfolding \nand 3A is a safe abstract semantics, namely, for every 11, Iz E Int, (i) ~(unf(Il, Iz)) G unfA(~(Il), \n412)); and (ii) a(F(Il)) ~ FA(a(.fl)). Theorem 4.1 can now be applied to justify compo\u00adsitional analyses. \nHowever, it is interesting to note that when AInt is induced from ASub we can prove a stronger result \nwhich implies that composition does not introduce additional loss of precision, i.e., that ~A(l~ U If) \n= FA(FA(I~) U FA(Ij)) The proof is similar to that of Proposition 3.4. It relies on the ob\u00adservation \nthat (abstract) unfolding is an associative binary operator that is left-distributive over the com\u00adposition \nof programs, and that 3A is idempotent. Symmetric Composition: Analysis of General Modules As mentioned \nearlier, existing Prolog implementations allow arbitrary inter-module dependencies. An inter\u00adesting technical \nproblem arises in this case: abstract unfolding may introduce arbitrarily large clauses so that analyses \ncan no longer be guaranteed to termi\u00adnate. This necessitates a second (and orthogonal) ab\u00adstraction to \ndeal with unbounded clause bodies in the abstract semantics. One proposal to deal with ab\u00adstract domains \ncontaining infinite chains is to use some kind of widening/narrowing approach to restrict the analysis \nto a finite subspace of the entire domain [13]. Here we consider a somewhat simpler solution that can \nbe formalized in the standard framework of abstract interpretations by restricting AInt to be a finite \nheight lattice. We apply a further level of abstraction to pro\u00advide finitary descriptions of (sets of) \narbitrarily large abstract clauses. A domain VClaus Q c VClaus e in which clauses are restricted to have \nbodies containing at most one occurrence of a predicate symbol is in\u00adtroduced. In this case, since II \nmay be assumed to be finite, the new abstract domain, denoted AInt*, becomes finite. This abstraction, \ncalled star abstrac\u00adtion and originally introduced in [9], provides an ap\u00adpropriate framework to develop \ncompositional analy\u00adses. We demonstrate this for the case of ground de\u00adpendencies analysis. The basic \nidea is to collapse all occurrences of the same predicate in a body to one canonical atom, representing \nany possible sequence of atoms with that predicate symbol. The collaps\u00ading of a sequence p(il), . . . \n. p(i&#38;) of atoms is a pair (P(i); K) where K G Dep captures the intuition that each argument x~ of \np (it) represents the set of the j ~ arguments in p(il ), . . . . p(im). The following defini\u00adtion formalizes \nthis as an abstraction function: Definition 5.7 [star abstraction] : a% : AIntD + AInt~ is defined bg: \ncr*(l ) = ?=(h+bl::..,:: bm; i&#38;c,), u? (h t-T,/c,) E 1 , { ((bl; ICI), .... (b~; K~)) <~ ccdiapse(h \n+ ~) } where collapse : VClause + [p(Atom x Dep)]~ is de\u00adjined by: collapse(h + ~) = 2= [(p(z); zl ~ \nxl,..., % -xn)]N, ~ pln En, 2 =_{xl, . . ..zn}. ii(lvam(h +b)=O, l~i <n, Xi={~;lp(~l,...,~~)E~}#O { \nNotice that as a result of star abstraction, multiple occurrences of gt(. . .) goals have been collapsed \ninto a single occurrence. We do not fully formalize here the star abstrac\u00adtion as a Galois insertion \n(and hence as an abstract interpret ation in our framework). However, we ob\u00adserve that ak is a complete \njoin-morphism which im\u00adplies that an adjoint concretization mapping -y* : AInt~ + AIntD does exist and \nis determined by Y*(I) = U { 1 [ CY*(I ) = I } . Since the composi\u00ad tion of Galois insertions is also \na Galois insertion [12], (ht, a*ocr, AM5, YOM) provides a suitable basis for abstract interpretation. \nIt is the second level of (star) abstraction which guarantees termination of composi\u00adtional ground dependencies \nanalysis for arbitrary logic program (modules) by taking for unfA in Definition 5.5 the function unf* \n: AInt~ x AInt~ + AInt&#38; defined by The corresponding function 3A : AInt~ + AInt~ is denoted by P. \nThe resulting abstract semantics can also be thought of as being produced by an ab\u00adstract unfolding operator \nunfA that never produces multiple literals with the same predicate symbol in an unfolded clause body, \ninstead collapsing them into a single canonical literal that is, where all the action takes place during \nabstract unfolding rather than in a separate abstraction step. We illustrate (the result of) a compositional \nground dependency analysis for the split relation defined in Example 1. The modules P,P and Prg are analyzed \nindependently and then the results are composed. Example 8 Recall the program P.P U Pig from Exam\u00adple \n1. The abstract meanings of the two modules P8P and P/$ are given by P(P.P) and P(Plg) respectively: \nP(P$P) = (gt(z, y); z -0, y -0), (p~9) = (/e(z, y); z +0, y *0) {}  The abstract meaning of the composition \nof the two modules is then obtained as P(F(P,p) u P(plg)) = (split(z~,zz,zs,zq);zz w 23 ++ 24-0), (9qz, \nY); z -O,Y -0), (/e(z, y); z *O, y ~0) { } Intuitively, this is what we ezpect: using the abstract semantics \nof the module P19, we have inferred that the second, third, and fourth arguments of the predicate split \nmust be ground. This is in fact the best we can do the first argument of split may in fact not be ground, \ngiven the jirst clause defining this predicate (see Ezample 1). Directed Composition: Analysis of Hi\u00ad \nerarchical Programs As discussed above, a compositional analysis that first analyzes different modules \nin isolation, then composes the resulting analyses, may have to deal with the pos sibilit y of unbounded \nclause bodies during analysis, typically by sacrificing some precision to gain termi\u00adnation. However, \na common program design technique is to structure different modules in a hierarchical way, so that components \nof a program are defined and un\u00adderstood in terms of previously defined components. If the modules in \na program are structured hierarchi\u00adcally, it is possible to take advantage of this fact and obtain a \ncompositional evaluation of the program that does not involve clause structures of unbounded size. The \nunderlying idea is quite straightforward. Con\u00adsider the program of Example 1, where P~g is lower in the \nhierarchy of modules than PSP. We can use the (abstract) meaning of Plg to evaluate the (ab\u00adstract) meaning \nof P, i.e., considering unfoldings of P = P,p U F(Plg ). While P is an infinite pro\u00adgram, it will have \na finite abstraction. Furthermore, as open(P ) = 0, unfoldings will produce only unit clauses, i.e., \nclauses with empty bodies. When viewed as a program analysis, this corresponds to plugging the analysis \nof Plg into the analysis of P,P instead of composing the respective analyses. While a pure composition \nis preferable, the latter may provide more precise results as it requires less abstraction, and sim\u00adpler \nabstract models for the program. Proposition 5.8 [directed composition] For any two (predicate disjoint) \nmodules P1 and P2, F(PI u P2) = F(P1 U7(P2))? PROOF. Consider any two modules PI and Pz. We have F(PI \nu 7(P2)) = X(F(PI) UF(Y(P2))) [ by Proposition 3.4 ] = F(F(PI) u F(P2)) [ 7 is idempotent ] = F(PI U \nP2) [ by Proposition 3.4 ] o The following result shows that a bottom-up com\u00adposition of modules is \nsound: Theorem 5.9 Let (lnt, a, Altit, -y) be a Galois inser\u00adtion and let FA : AInt + AInt be a monotonic \nand safe approximation of F. Then, for any pro\u00adgram modules PI, Pz ~ Int, we have @(F(Pl U P2)) ~ FA(a(Pl) \nu @(a(P2))). The following example illustrates a hierarchical de\u00adpendency analysis (i.e. taking A Sub \n= Dep). Example 9 Consider the logic program dejining the qs relation for a quicksort program, where \nsplit is de\u00adfined in Example 1: Pq, : qs([ ],[ ]). qs([xlxs], Ys) + split(X, Xs, Ll, L2), qs(Ll, h), \nqs(L2, Bs), append(Ls, [X IBS], Ys). P am. append([ ], X,X). .. append([Xl w], Y, [X12]) + append(W, \nY, Z). The analysis starts from the module PaPp. The ab\u00adstract meaning of append is obtained as: (fP( \nT$P.PP) ) = (append(xl, 22, X3); { [z, -0,22 = x,] u [{x,, X2} ~ x3]) } Notice that the intersection \n(the lub on Dep) of (the smallest dependency relation containing) {xl, X2} * X3 and (the smallest dependency \nrelation containing) xl -0, Zz -X3 is (the smallest dependency rela\u00adtion containing) {xl, x2} + X3. so \nFA(cr(Papp)) = {(append(zl, Z2, 23); {xl, 32} -Z3)}. The abstract meaning of Plg (from Example 1) is \na(P/g) = (gt(z, y); z +0, y -0), (gt(z, y) + gt(z , y ); z -z , y -y ), (le(z, y); z ~ O,y ~0), (Ie(z, \ny) + le(z , y ); r * z , y w y ) {1 To approximate the meaning of P,p U Pig we apply (abstract) directed \ncomposition: @(cr(Psp) u 3A(a(plg))) = (split(xl, x2, x3, x4); x2 * x3 + x4 +-+ 0), (gt(z, y); z eo,y \n++0), (le(z, y);x++0,y++0) {} Observe that the result is the same as evaluation of F %(PSP u P/g). An \nadditional application of (a~\u00adstract) directed composition provides the following ap\u00adproximation of the \nmeaning of Pq8 U PaPp U P,P U Pig: (qs(zl, q?); z~ ~ q), (append(xl, 22, z3); {zl, 22} ++ z3), (gi(z, \ny); z -0, y ~ 0), (Ie(z, y);z+ 0,y * 0), { (spiit(zl, $2, x3, x4); X2 +X3 -X4 -0) 1 Abstract Composition: \nPrecision vs. Termination The first part of this section demonstrates that, in gen\u00aderal, the (symmetric) \ncomposition of program analy\u00adses may require an additional layer of abstraction im\u00adplying a potential \nloss of precision. The second part illustrates that a weaker form of (directed) composi\u00adtion can be applied \nto analyze programs with a hierar\u00adchical structure. In this case analyses are potentially more precise. \nHowever, this approach is limited to programs with a hierarchical structure and in partic\u00adular to closed \nprograms (i.e., programs in which ev\u00adery predicate is defined in some module); moreover, the composition \nis weaker and in particular, a mod\u00adule cannot be analyzed until all lower modules are available and have \nbeen analyzed. In the following we provide some syntactic char\u00adacterizations which strengthen both of \nthe above ap\u00adproaches to compositional program analysis. The first characterization identifies a CISSSof \nbounded program modules. Unfolding clauses in such modules does not create clauses of unbound length. \nConsequently, if a program consists of bounded modules then a single layer of abstraction is sufficient \nfor symmetric com\u00adposition of analyses. The basic idea is to detect the absence of loops in the program \ns call graph which might cause a problem. Note that not all loops create unbounded unfoldings. A convenient \nway to express this criterion is by way of a context free grammar. The second characterization identifies \na class of semi-hierarchical programs which can be analyzed us\u00ading one layer of abstraction with directed \ncomposition. This class is richer than the class of hierarchical pro\u00adgrams assumed above. To be more \ngeneral, and in particular to allow predicates which are undefined in all modules, it is necessary to \ndisallow certain combi\u00adnations of recursion and calls to open predicates. Our approach draws on the notion \nof stratification (intro\u00adduced in [1] to support a safe use of negation), iden\u00adtifying those programs \nwhere only negated relations whose meaning is fixed beforehand are allowed. The basic idea is that modules \nwhich call open predicates may be allowed in the hierarchy as long as there exists a bound on the number \nof their occurrences in unfold\u00adings. A syntactic condition is defined in terms of the condition for checking \nbounded modules. The following formalizes the call graph of a program in terms of a context free grammar. \nDefinition 5.10 [call grammarJ : Let P be a mod\u00adule. Let atoms(P) and open_ atoms(P) denote the atoms \nand, respectively, the open atoms (i. e., any atom whose predicate symbol is in open(P)), occur\u00adring \nin P. The call grammar of P is the context\u00ad free grammar Gp = (N, T, Q, S) defined as follows: the set \nof nonterminals is given by N = (atoms(P) \\ open-atoms(P) )U{S}, where S is a distinguished non\u00ad terminal \nthat is the start symbol of GP; the set of ter\u00ad minal symbols is given by T = open. atoms(P); and the \nset of productions Q is given by the following: -For each A e atoms(P)\\ open. atoms(P) there is a production \nS-A. -For each clause h : b~,....b~ in P there is a production h---+ bbn.. bn. -For each pair of atoms \n(b, h) e atoms(P) x atoms(P) such that b occurs in the body of a clause, h is the head of a clause and \nb unifies with (a renaming of) h there is a production b-h. Example 10 Consider the following program, \nwhich computes the transitive closure of a binary relation b: tc(x , Y) + b(X, Y). tc(U, V) + b(U, W), \ntc(W, V).  Assume that the only open predicate in this program is b. The call grammar for this program \nis G = (N, T, Q, S), where: N = {S, tc(x, Y), tc(u, v), tc(w, v)}; T = {b(X, Y), b(U, W)}; and whose \nproductions are given by s -ic(x, Y) [ tc(u, v) I tc(w, v) tc(X, Y) + b(X, Y) tc<U, V) -b(U, W) tC(~, \nV) tc(w, v) + tc(x, Y) \\ tc(u, v)  The structure of this grammar becomes more obvious if we rename the \ngrammar symbols as follows: tc(X, Y) + A,ic(U, V) = l?, tc(W, V) + C b(X, Y)+a, b(U, JV)+b The productions \nof the grammar then become: S-AIBIC A-a B+bC C-+A[B  Observe that L(G) = { b a I n >0 } is not fnite. \nTheorem 5.11 Let P be a module with call grammar Gp. If the language L(GP) of GP is finite, then the \nnumber of atoms occurring in the clauses in 7(P) is bounded. PROOF. (outline) Given a program P, let \nthe rank of a clause c in X(P) be the smallest number of unfolding steps necessary to obtain c from P. \nIt can be shown that for any program P, for every clause c 6 F(P) there is a string w in L( GP) such \nthat the number of atoms in the body of c is equal to the length of w: the proof is by induction on the \nrank of c. Now suppose that L( Gp ) is finite. Let N be the length of the longest string in L( Gp), then \nno clause in %(P) can have more than IV atoms in its body. The theorem follows. 1 Note that it is decidable \nwhether the language of an arbitrary context-free grammar is finite [18]. The\u00adorem 5.11 therefore gives \na decidable sufficient con\u00addition for determining whether, for any given module P, the clauses in F(P) \nare bounded. The following example illustrates the application of this approach. Example 11 Consider \nthe following program, which generates the list of prime numbers up to N for any given natural number \nN: primes(N, L) + N<2, L= []. primes(N, L) + N ~ 2, intlist(N, Ll), primes.l(Ll, [2], L). primes_l([ \n], LO, Ll) + rever.se(LO, Ll). primes.l([HIL], LO, Ll) + divisibie(LO, H), primes-1 (~, LO, .L1). primes-1 \n([.HIL], LO, Ll) + not_divisible(LO, H), primes.l(L, [.HILO], Ll). We omit the definitions of intlist/2, \ndivisible/2, noi. divisible/2. The idea of this program is to exam\u00ad ine a list of numbers, checking each \nnumber to see if it is divisible by any of the primes found up to that point if it is not, it is added \nto the list of primes found, and the process continues with the remaining numbers. However, because of \nthe way primes are added to the list as they are found, the list is generated backwards , an d has to \nbe reversed at the end. Now suppose that the only open predicate in this program is reverse/2, which \nis imported from a li\u00adbrary. The corresponding context-free grammar has a jinite language, since the \nonly nonterminals that de\u00adrive a nonempty string are primes and primesS, each of which derive only the \nsymbol reverse(LO, Ll) . It follows from this that unfolding this program does not produce clauses of \nunbounded size. Before introducing the class of semi-hierarchical programs we need the following notation: \nDefinition 5.12 [leveling, closure] : Let P =a~l P% be a modular logic program. A leveling of P is a \npartial order < on the modules of P. The closure of a module Pa E P (with respect to a leveling ~) is \nthe program : closure< (Pi) = U Pj. Pj 5p% Definition 5.13 [semi-hierarchical programs] : Let P =,~1 \nPa be a modular logic program. We say that P is s~mi-hierarchical if there exists a leveling s of P such \nthat closure< is bounded for i = l.. n. In particular, note that a program consisting of bounded modules \nis semi-hierarchical, since the empty partial order serves as an appropriate leveling for such a program. \nThe following example considers the pub\u00adlic domain tokenizer for Prolog written by Richard O Keefe. Example \n12 Consider a program consisting of the following modules: p~ok : Defines a tokenizer for Prolog. The \nopen pred\u00adicates of this module are append, defined in Put,l, and I/o primitives defined in P*Y$. Putil \n: Defines a set of user defined utilities, including the append program from Example 9. It contains no \nopen predicates. P ,Y, : Dejines a set of system defined I/O primitives. It contains no open predicates. \nWe include here part of P@: read. tokens( TokenList, Dictionary) + read-tokens(32, Diet, List OfTokens), \nappend(Dict, [ ], Diet), Dictionary = Diet, TokenList = List OfTokens. read-tokens([atom( end_of@e)], \n[ ]). read-tokens( 1, _, _) + fail. read-tokens( Ch, Diet, Tokens) + Ch =< 32, getO(NeztCh), read_tokens(Next \nCh, Diet, Tokens). read-tokens(40, Diet, ~( I Tokens]) + getO(NeztCh), read_tokens(Next Ch, Diet, Tokens). \nread-tokens(41, Diet, ~) I Tokens]) + getO(NeztCh), read_tokens(Next Ch, Diet, Tokens). The program Ptok \nU Put,t U P,Ys is hierarchical: pt~k is above the modules PUt~l and PSYS. While the pro\u00adgram P = PtOk \nU P.Y, is not hierarchical, it is semi\u00adhierarchical. Hence P can be analyzed wtthout consid\u00adering the \nmeaning of append.  6 Reusing Analyses The goal of this work has been to develop a formal technique \nfor the compositional abstract interpreta\u00adtion of modular logic programs. With such an ap\u00adproach, if \nsome modules in a program change during development, it is necessary to reanalyze only those modules \nthat have changed: the abstract semantics computed for the other modules can be reused without any problems, \nand the new abstract semantics for the program computed simply by composing them with the (new) abstract \nsemantics computed for the mod\u00adules that have changed. (Contrast this to the work of [10, 24], where \nit is necessary to reanalyze not only the modules that have changed, but (potentially) also any module \nthat depends on a changed module.) In this section, we illustrate this reuse of abstract semantics with \nan example. Example 13 Consider again the program of Example 1: suppose the module Plg is changed to \nuse a diflerent formulation of the predicates gt and Ie: gt(s(x), x). 4 gt(s(x), Y) + gt(x, Y). gt(s(x), \ns(Y)) -gt(x, Y). le(X, X). /e(X, Y)+ gt(Y, X). Let the changed module be denoted by Pig. Its ab\u00adstract \nsemantics, using the same abstract domain as in the previous examples, is given by P(P&#38;) = The new \nabstract semantics for split can now be ob\u00adtained without reanalysis, by simply composing the (previously \ncomputed) abstract semantics of split with the (new) abstract semantics for gt and le: P(P(P$P) u P(P(g)) \n= It can be seen from this that the change to the defini\u00adtions of the predicates gt and le leads to a \nslightly dif\u00adferent abstract meaning for the predicate split: whereas in Example 8 it was inferred that \neach of the sec\u00adond, third and fourth arguments of split was definitely ground, we now infer that these \nthree arguments are either all ground, or are all nonground. On examin\u00ading the program Pig, it is apparent \nthat this is, in fact, what should be inferred.  More General Composition The main focus of this paper \nhas been on the compo\u00adsitional analysis of predicate disjoint modules. This choice is motivated by the \nfact that module based im\u00adplementations of logic programming languages typi\u00adcally provide this functionality. \nMoreover from a tech\u00adnical point of view, the assumption that modules are predicate disjoint simplifies \nsomewhat our presenta\u00ad tion. For example, we do not need to introduce im\u00ad port declarations to the syntax \nsince only predicates which are not defined in a module may be open. However, it is worth noting that \nfrom the analy\u00adsis point of view there is no real obstacle in provid\u00ading for compositional analysis of \nprograms which are not predicate disjoint. Moreover, although most im\u00adplementations do not support such \nmodules, the pos\u00adsibility of spreading the definitions of a predicate in different modules is useful, \nfor example, in distributed deductive databases. This allows different modules to represent different \nviews of the knowledge about a predicate. To substantiate our claim, we note that the com\u00adpositional \nsemantics defined in [4] (which is the basis for our framework) is not restricted to predicate dis\u00adjoint \nmodules. Instead, each module is conceptually accompanied by a declaration of its open predicates. The \nconcrete fixpoint semantics is defined as before, by allowing tautological clauses in @p for each open \npredicate. Moreover, Proposition 3.4 holds for arbi\u00adtrary modules while Theorem 4.1 and Proposition 5.8 \nextend with no difficulty. The following example illustrates the feasibility of applying compositional \nanalysis to programs which contain modules which are not predicate disjoint. Example 14 Consider a program \nconsisting of the following modules: P%at : Dejining the evaluation of arithmetic expres\u00adsions over the \nintegers and including definitions for predicates integeril, plus/3, times/3, and eval/2. The clauses \nfor eval/2 include: eval(A + B, Y) + eval(A, A ), eval(l?, l? ), PIus(A , B , Y). eval(A * B, Y) + eval(A, \nA ), evai(l?, B ), times(A , B , Y). eval(X, X) t-integer(X). PTea{ : Defining the evaluation of arithmetic \nexpres\u00adsions over the reals and including de~nitions for predicates real/1, sinus/2 and eval/2. The clauses \nfor eval/2 include: evai(sin(A), Y) + eval(A, A ), sinus(A , Y). evai(X, X) + real(X).  The predicate \neval/2 is assumed to be partially defined and hence open in both P;~t and PT~~l. Consider a ground dependency \nanalysis of these modules. For l ,~t we could expect the following result of an analysis: P(P*nt) = (integer(x); \nz -0), (Plu$(z, y, 2); {$, Y} * z), (times(z, y, z); {z, y} -z), (evd(z, y); {z, y} -0), (eval(z, y) \nt evd(z , y ); z ~ z , y e y ) [ } The last tuple derives from the fact that eval/2 is open and hence \nhas an added tautological clause. Likewise, the anticipated result of an analysis for P,eal is: P(Pre.() \n= (reai(z); z * 0), (sinus(z, y); z + y), (eval(z, y); {3, y} + 0), (eval(z, y) + eval(z , y ); z ~ z \n, y ~ y ) { 1 Now consider the analysis for P = Pint U P,~al. There are two possible views: 1. If eval/2 \nis assumed closed in P then we should consider unfoldings of P(Pint) and P(P~~ol) giving (integer(z); \nz -0), (pius(z, y,z); {~, v} -z), (times(z, y,z); {z, y} ~ .%), (real(z); x w 0), (sinus(z, y); z e y), \n(evai(z, y); {r, Y}+O) 1 2. On the other hand if eval/2 is assumed open then we should consider unfoldings \nof P(P,nt) and F(P~~~r) together with the tautological clause eval(z, y) + eval(z, y) giving: (integer(z); \nz + 0), (p/us(z, y, z); {z, y} -z), (times(z, y, z); {2, y} ~ z), (real(z); z + 0), (sinus(z, y); z * \ny), (eval(z, y); {z, y} ~ 0), (eval(x, y) + eval(z , y ); z ~ z , y -y )  Related Work Several compositional \nsemantics for logic programs have been proposed in the literature. These include Mancarella et al. [21], \nGaifmann et al. [16] and Bossi et al. [4]. In [21] the compositional semantics is pre\u00advided by composing \nthe Tp functions associated with program modules. Gaifmann et al. propose to adopt clauses as semantic \nobjects in order to characterize partial computations (from the head to the body) and to enable different \nnotions of composition. Bossi et al. also consider clauses as semantic objects. They pro\u00adpose a bottom-up \napproach providing a semantics that resembles the non-ground Tp operator of [14]. Logi\u00adcal semantics \nfor modules in logic programs have been proposed by a number of authors [7, 22]. These are typically \nbased on various extensions to Horn logic: for example, Chen s treatment of modules [7] is based on second-order \nlogic, while Miller s [22] uses implica\u00adtion goals in clause bodies. In either case, the seman\u00adtics appears \nto be somewhat more complicated than that considered in [4], and we conjecture that a formal treatment \nof abstract interpretation based on such se\u00admantics would require considerably more machinery than that \ngiven here. The problem of program analysis across module boundaries for imperative langua$es has been \nconsid\u00adered by a number of researchers: Cooper et al. [10] and Tichy et al. [24] are concerned primarily \nwith low-level details of maintaining information to allow a compiler to determine whether a change to \none program unit necessitates the recompilation of another, separately\u00adcompiled, unit, while Santhanam \nand Odnert [23] consider register allocation across module boundaries. While the motivation for their \nwork is related to ours, the treatment is significantly different in that no at\u00adtempt is made to give \na formal semantic account of the problem or the proposed solutions. These authors have no notion of composition \nof abstract seman\u00adtics analogous to ours; because of this, if the dataflow characteristics of a module \nin a program changes, it is necessary to reanalyze other modules that depend on it in the worst case, \nthis can lead to reanalysis of everv module in the momam. By contrast, in our .. approach it is necessary \nto reanalyze only the mod\u00adules that have actually changed: the effects of these changes are propagated \nby composition of abstract se\u00admantics. 9 Conclusions We have described a compositional approach to the \nabstract interpretation of modular logic programs. In the proposed framework the analysis of a program \ncan be derived by composing the analyses of its constituent modules. For a substantial class of hierarchical \npro\u00adgrams, composition does not entail a sacrifice of pre\u00adcision. In addition to reducing the conceptual \ncomplexity of large programs and enabling the analysis of pro\u00adgrams developed by teams, we expect that \nour frame\u00adwork will prove useful in developing new applications which focus on the analysis of the interaction \nbetween modules. Finally, this paper has focused on the abstraction of a bottom-up compositional semantics. \nHowever the approach taken is of general interest. In particular the ideas of considering hierarchical \nprograms and star abstraction are applicable also for the development of top-down frameworks for compositional \nanalysis. Acknowledgements: The stimulating discussions with Maurizio Gabbrielli and Giorgio Levi and \nthe comments of Gerda Janssens are gratefully acknowl\u00adedged.  References [1] K. R. Apt, H. Blair, and \nA. Walker. Towards a Theory of Declarative Knowledge. In J. Minker, editor, Foundations of Deductive \nDatabases and Logic Programming, pp. 89-148. Morgan Kauf\u00admann, Los Altos, Ca., 1988. [2] R. Barbuti, \nR. Giacobazzi, and G. Levi. A Gen\u00aderal Framework for Semantics-based Bottom-up Abstract Interpretation \nof Logic Programs, Tech\u00adnical Report TR 12/91, Dipartimento di Infor\u00admatica, University di Piss, 1991. \nTo appear in ACM l%ansactions on Programming Languages and Systems. [3] BIM_Prolog reference manual. \nB.I.M. B -3078, Everberg, Belgium. [4] A. Bossi, M. Gabbrielli, G. Levi, and M. C. Meo. Contributions \nto the Semantics of Open Logic Programs. In Proceedings of the International Conference on Fifth Generation \nComputer Sys\u00adtems 1992, pp. 570-580, 1992. [5] M. Bruynooghe, G. Janssens, B. Demoen, and A. Callebaut. \nAbstract Interpretation: Towards the Global Optimization of Prolog Programs. In Pvoc. Fourth IEEE Int \n1Symp. on Logic Program\u00adming, pp. 192 204. IEEE Comp. Sot. Press, 1987. [6] M. Carlsson and J. Widen. \nSIC Stus Prolog Users Manual. SICS, Sweden, 1988. [7] W. Chen. A Theory of Modules Based on Second-Order \nLogic. In Proc. Fourth IEEE Int 1 Symp. on Logic Programming, pp. 24 33. IEEE Comp. Sot. Press, 1987. \n[8] M. Codish, D. Dams, and E. Yardeni. Bottom\u00adup Abstract Interpretation of Logic Programs. Technical \nreport, Dept. of Computer Science, The Weizmann Institute, Rehovot, 1990. To appear in Theoretical Computer \nScience. [9] M. Codish, M. Falzschi, and K. Marriott. Sus\u00adpension Analysis for Concurrent Logic Programs. \nIn K. Furukawa, editor, Proc. Eighth lnt 1 Conf on Logic Programming, pp. 331 345. The MIT Press, Cambridge, \nMass., 1991. [10] K.D. Cooper, K. Kennedy, and L. Torczon. In\u00adterprocedural Optimization: Eliminating \nUnne\u00adcessary Recompilation. In Proc. SIGPLAN 86 Symp. on Compiler Construction, pp. 58-67, 1986. [11] \nP. Cousot and R. Cousot. Abstract Interpreta\u00adtion: A Unified Lattice Model for Static Analysis of Programs \nby Construction or Approximation of Fixpoints. In Proc. Fourth ACM Symp, Prin\u00adciples of Programming Languages, \npp. 238 252, 1977. [12] P. Cousot and R. Cousot. Systematic Design of Program Analysis Frameworks. In \nProc. Sizth ACM Symp. Principles of Programming Lan\u00adguages, pp. 269-282, 1979. [13] P. Cousot and R. \nCousot. Comparing the Galois Connection and Widening/Narrowing Approaches to Abstract Interpretation. \nIn M. Bruynooghe and M. Wirsing, editors, Proc. of PLILP 92, volume 631 of Lecture Notes in Com\u00adputer \nScience, pages 269 295. Springer-Verlag, Berlin, 1992. [14] M. Falaschi, G. Levi, M. Martelli, and C. \nPalamidessi. Declarative Modeling of the Op\u00aderational Behavior of Logic Languages. Theoret\u00adical Computer \nScience, 69(3):289 318, 1989. [15] H. Gaifman, M. J. Maher, and E. Y. Shapiro. Re\u00adactive Behavior Semantics \nfor Concurrent Con\u00adstraint Logic Programs. In E. Lusk and R. Over\u00adbeck, editors, Proc. North American \nConf. on Logic Programming 89, pp. 553-572. The MIT Press, Cambridge, Mass., 1989. [16] H. Gaifman and \nE. Shapiro. Fully abstract compositional semantics for logic programs. In Proc. Sixteenth Annual ACM \nSymp. on Prin\u00adciples of Programming Languages, pp. 134-142. ACM, 1989. [17] R. Gerth, M. Codish, Y. Liechtenstein, \nand E. Shapiro. Fully abstract denotational seman\u00adtics for Concurrent Prolog. In Proc. Third IEEE Symp. \non Logic In Computer Science, pp. 320\u00ad 335. IEEE Computer Society Press, 1988. [18] J. E. Hopcroft and \nJ. D. Unman, Introduction to Automata Theory, Languages, and Computation, Addison-Wesley, 1979. [19] \nG. Levi. Models, Unfolding Rules and Fixpoint Semantics. In R. A. Kowalski and K. A. Bowen, editors, \nProc. Fifth Int 1 Conf. on Logic Program\u00adming, pp. 1649 1665. The MIT Press, Cambridge, Msss., 1988. \n[20] J. W. Lloyd. Foundations of Logic Programming. Springer-Verlag, Berlin, 1987. Second edition. [21] \nP. Mancarella and D. Pedreschi. An Algebra of Logic Programs. In R. A. Kowalski and K. A. Bowen, editors, \nProc. Fifth Int 1 Conf. on Logic Programming, pp. 1006 1023. The MIT Press, Cambridge, Mass., 1988. [22] \nD. Miller. A Theory of Modules for Logic Pro\u00adgramming. In Proceedings IEEE symposium on Logic Programming, \npp. 106-114, 1986. [23] V. Santhanam and D. Odnert, Register Alloca\u00adtion across Procedure and Module \nBoundaries , Proc. ACM SIGPLAN-90 Conference on Pro\u00adgramming Language Design and Implementation, White \nPlains, NY, June 1990, pp. 28-39. [24] W.F. Tichy and M.C. Baker. Smart Recompila\u00adtion. In Proc. Twelfth \nACM Symp. on Principles of Programming Languages, pp. 236 244. ACM, 1985.  \n\t\t\t", "proc_id": "158511", "abstract": "<p>This paper describes a semantic basis for a compositional approach to the analysis of logic programs. A logic program is viewed as consisting of a set of modules, each module defining a subset of the program's predicates. Analyses are constructed by considering abstract interpretations of a compositional semantics. The abstract meaning of a module corresponds to its analysis and composition of abstract meanings corresponds to composition of analyses. Such an approach is essential for large program development so that altering one module does not require re-analysis of the entire program. We claim that for a substantial class of programs, compositional analyses which are based on a notion of <italic>abstract unfolding</italic> provide the same precision as non-compositional analysis. A compositional analysis for ground dependencies is included to illustrate the approach. To the best of our knowledge this is the first account of a compositional framework for the analysis of logic programs.</p>", "authors": [{"name": "Michael Codish", "author_profile_id": "81100633343", "affiliation": "", "person_id": "P196640", "email_address": "", "orcid_id": ""}, {"name": "Saumya K. Debray", "author_profile_id": "81100148240", "affiliation": "", "person_id": "P260625", "email_address": "", "orcid_id": ""}, {"name": "Roberto Giacobazzi", "author_profile_id": "81100572239", "affiliation": "", "person_id": "PP14198144", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158703", "year": "1993", "article_id": "158703", "conference": "POPL", "title": "Compositional analysis of modular logic programs", "url": "http://dl.acm.org/citation.cfm?id=158703"}