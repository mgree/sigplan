{"article_publication_date": "03-01-1993", "fulltext": "\n A concurrent, generational garbage collector for a multithreaded implementation of ML Damien Doligez \nXavier Leroy Ecole Normale Sup&#38;-ieure and INRIA Rocquencourt* Abstract This paper presents the design \nand implementation of a quasi real-time garbage collector for Concurrent Carol Light, an implementation \nof ML with threads. This two-generation system combines a fast, asyn\u00adchronous copying collector on the \nyoung generation with a non-disruptive concurrent marking collector on the old generation. This design \ncrucially relies on the ML compile-time distinction between mutable and im\u00admutable objects. Introduction \n This paper presents the design and implementation of a garbage collector for Concurrent Carol Light, \nan imple\u00admentation of the ML language that provides multiple threads of control executing concurrently \nin a shared address space. Garbage collection the automatic reclamation of unused memory space is one \nof the most problematic components of run-time systems for multi-threaded lan\u00adguages. The naive stop-the-world \napproach, where all threads synchronously stop executing the user s pro\u00adgram to perform garbage collection, \nis clearly inade\u00adquate, since it introduces synchronization between oth\u00ader wise independent t breads. \nFor inst ante, this can re\u00adsult in all threads being blocked for some time if one thread is in the middle \nof a lengthy, uninterruptible operation when garbage collection starts. This contra\u00advenes one of the \nmain motivations for having multi\u00adple threads: to reduce the response time of interactive applications. \nTo achieve this goal, a promising direc\u00adtion is to run the garbage collector concurrently with *Authors \naddress: INRIA Rocquencourt, B. P. 105, 78153 Le Chesrmy, France. E-mail: Dsmien. Doligez@inria. fr, \nXavier .Leroy@inria. fr. Permission to copy without fee all or part of this material is granted provided \nthat the copies are not made or distributed for direct commercial advantage, the ACM copyright notice \nand the title of the publication and ita date appear, and notice is given that copying is by permission \nof the Association for Computing Machinery. To copy otherwise, or to republish, requires a fee andlor \nspecific permission. ACM-20th PoPL-1 /93-S. C., USA @ 1993 ACM 0-89791-561-5/93/0001/01 13,..$1.50 the \nthreads that execute the user s program, with as little synchronization as possible between the collector \nand the mutators (the threads executing the user s pro\u00adgram). A number of concurrent collectors have \nbeen de\u00adscribed in the literature, such as the concurrent mark\u00adand-sweep algorithm [11, 14, 5], which \nrequires no syn\u00adchronization with the mutators, at the price of a moder\u00adate overhead on the mut ators. \nHowever, these designs seem unable to meet the memory demands of typical ML programs. ML programs tend \nto have high allo\u00adcation rates, but many allocated objects have a short life span. This is due in part \nto the ML language it\u00adself, which encourages a programming style where many intermediate structures are \nbuilt; and in part to some compilation techniques [1, 10] that result in heap allo\u00adcation for large amounts \nof environments and control structures. The garbage collection technique most adapted to this allocation \nprofile is generation scavenging [24], that concentrates reclamation effort on recently allocated objects. \nHowever, the efficient implementation of gen\u00aderation scavenging requires the ability to relocate ob\u00adjects \nby copying between the memory areas that hold the various (generations of objects. Performing relo\u00adcation \nwhile the mutators are running is problematic: we must ensure that the mutators are aware of the re\u00adlocation, \nand do not try to access a relocated object at its old, invalid address. Some designs rely on tests when \ndereferencing a heap pointer [23, 4]; others, on an extra indirection word for each heap object [8, 20]; \nothers, on virtual memory page protections [2]. All three approaches entail a significant run-time penalty \non the mutators, unless special hardware or special sys\u00adtem software is used. The memory management system \npresented in this paper is an attempt to circumvent this weakness of concurrent copying collectors by \nrelying on specific fea\u00adtures of the ML language. This system has two gen\u00aderations, with a fast, asynchronous \ncopying collector on the young generation, and a non-disruptive con\u00adcurrent marking collector on the \nold generation. The aforementioned difficulties with copying are avoided by splitting the young generation \ninto areas attached to the mutators, each area being accessed byonemutator only. The performance issue \nwith concurrent mark-and\u00adsweep pointed out above is avoided by the fact that the allocation rate in the \nold generation is low, since most short-lived objects are reclaimed by the copying collectors. This combination \nresults in quasi real-time performance for memory allocation, while keeping the overhead on the mutators \nlow. This design relies crucially on two features of ML. First, the ML type system distinguishes at \ncompile-time between mutable objects (that can be physically mod\u00adified) and immutable objects. Second, \nduplicating im\u00admutable objects is semantically transparent. The first point makes it possible to have \ndifferent allocation poli\u00adcies for mutable and immutable objects. The second point allows copying the \nobject residing in the private area of a mutator at arbitrary times. The remainder of this paper is organized \nas follows. Section 2 briefly describes the Concurrent Carol Light system. Section 3 presents the memory \norganization; the concurrent aspects of the system (the mark-and\u00adsweep major collector) are detailed \nin section 4. Sec\u00adtion 5 comments on some experimental results. Sec\u00ad tion 6 discusses some directions \nfor further work. Fi\u00ad nally, section 7 compares our design with some other concurrent collectors. 2 \nConcurrent Carol Light Concurrent Carol Light is an extension of Carol Light [16, 15], the authors implementation \nof the ML lan\u00adguage, with concurrency primitives. The concurrency model is lightweight processes (threads) \nwith shared memory. The synchronization tools are locks and con\u00additions. (Figure 1 shows the Carol Light \ninterface to the module providing the concurrency primitives. ) This is the model provided by the C Threads \nlibrary under the Mach operating system [9]. On top of these con\u00adcurrency primitives, we can to implement \nhigher-level concurrency abstractions such as channels and events [22, 6]. The ML language is a conventional \nimperative lan\u00adguage vvith functions as first-class values and strong static typing [21, 17]. From the \nstandpoint of mem\u00adory management, the ML language has two distinctive features that are crucial to the \ndesign described here. The first feature is that not all ML data structures can be modified in-place. \nThat is, the updating primitives provided by the language operate only on specific data types, either \nbuilt-in (such as references and arrays) or specially declared (such as the Carol record types with mutable \n) fields). This fact, combined with strong static typing, ensures a clear separation at compile-time \ntype process; ; value fork : (unit -> a) -> process and exit : unit -> a and join : process -> unit and \ndetach : process -> unit and yield : unit -> unit and self : unit -> process; ; type iuutex; ; type \ncondition; ; value neW_nwtex : unit -> nnltex and nev_condition : unit -> condition and lock : nmtex \n-> unit and unlock : nmtex -> unit and try_lock : nmtex -> bool and signal : condition -> unit and broadcast \n: condition -> unit and wait : condition -> rnutex -> unit; ; Fig~rel: Theinterface tothemodule thread \nproviding the concurrency primitives between mutable objects (that can be physically up\u00ad dated) and immutable \nobjects (that can only be read once constructed). This permits different allocation policies for mutable \nand immutable objects; our design takes advantage of this fact. Another important feature of ML is that \nit does not specify any generic physical equality primitive similar to eq in Lisp. The provided equality \nprimitive implements structural equality on immutable objects, and physical equality on mutable objects. \nConsequently, there is no way to test two immutable objects for physical equality, Combined with the \nfact that immutable objects cannot be modified in-place, this means that it is always seman\u00adtically correct \nto duplicate an immutable structure: the original structure and its copy cannot be distinguished by any \nprogram. Our collector does indeed duplicate immutable structures and keeps the two copies alive for \nsome time strange as it may sound for a system that is supposed to reclaim memory space. 3 Overview \nof the memory or\u00adganization The memory heap is organized as follows. (See figure 2.) First, there is \na large, common heap shared between all threads. All threads can allocate, read, and update ob\u00adjects \nin the shared heap. Then, each thread possesses its own, small, private heap (typically 32 K). On a mod\u00ad \nern shared-memory architecture with large, write-back caches, we expect the private heap to remain in \none and only one cache most of the time, thereby causing very little bus traffic when it is accessed. \nThis asssumes that result in a live object being reclaimed. Threads , I 1 s, I Stacks , , , I # t , \nIMinor heaps , 1 I1 Major heap II Figure 2: Memory organization the system scheduler is clever enough \nto tie each thread to a single processor whenever possible. 3.1 Two generations Each thread treats the \ntwo heaps it can access (the shared heap and its own private heap) as two gener\u00adations: the private heap \ncontains the young genera\u00adtion; the shared heap contains the old generation. Each thread allocates immutable \nobjects in its own private heap. Mutable objects are handled differently, as we shall see below. This \nallocation does not require any synchronization with the other threads. When the private heap becomes \nfull, the correspond\u00ading thread stops and performs a minor collection: it copies all live objects in \nthe private heap to the shared heap. Live objects are those that arepointedto by the memory roots of \nthe thread (the registers and the stacks of the machine), as well as their descendants. This copy\u00ading \nmakes the whole private heap available again for private allocation. Consequently, allocation in the \npri\u00advate heap is performed linearly, and requires only one pointer comparison and one pointer increment. \nA mi\u00adnor collection can be performed at any time, regardless of the status of the other mutator threads. \nThe only synchronization required is when allocating the copied objects in the shared heap. Major collection \non the shared heap is performed by a dedicated thread, which runs concurrently with the mut ator (and \nminor collection) threads. It uses the concurrent mark and sweep algorithm described by Di\u00adjkstra et \nal. [11]. We postpone a complete discussion of the algorithm and the cooperation between the major collector \nthread and the other threads to the next sec\u00adtion. Since the major collector does not move objects, no \nsynchronization is required when accessing or modi\u00adfying an object in the shared heap, either for the \nmajor collector thread or for the mut ator t breads. Race con\u00ad ditions can result in a dead object not \nbeing collected by the current major collection cycle; but they cannot If the available space in the \nshared heap drops to zero before the major collection cycle is over, then the muta\u00adtor threads attempt \nto enlarge the shared heap, by ex\u00adtending the process address space, instead of waiting for the major \ncollection to finish. We want to avoid block\u00ading the mutator threads as much as possible. Blocking is \nonly required in the unlikely case where the virtual memory is exhausted.  3.2 Copy on update The design \noutlined above assumes that there are no pointers from the shared heap to a private heap, nor from one \nprivate heap to another private heap. Oth\u00aderwise, a private heap could contain objects that are live, \nbut not directly reachable from the roots of the corresponding threads. Without special treatment, a \npointer from the shared heap to a private heap can be created by updating an old mutable object, residing \nin the shared heap, with a pointer to a newly created structure} that still resides in a private heap; \nand a pointer between two private heaps can then be created by reading the mutable object from another \nthread. This situation is avoided by copying the transmitted private object to the main shared heap and \nstoring in the old mutable object a pointer to the copy, instead of a pointer to the original private \nobject. The de\u00adscendants of the transmitted object that reside in the private heap are recursively copied, \ntoo. This copying is very similar to a minor collection with only one root, the transmitted object. Indeed, \nit stores forwarding pointers from the copied objects to their copies, just as the minor collector does, \nso that the next minor collec\u00adtion will not copy these objects again, but reuse their copies. 1 Therefore, \nthis copy on update strategy does not waste time: we just do some of the next minor col\u00adlection right \naway. Also, it avoids the complexity of maintaining a remembered set of old objects that con\u00adtain pointers \nto the young generation [24]. 3.3 Allocation of mutable objects Until the next minor collection, the \nthread that created the transmitted object can access both the original, pri\u00advate object and its copy \nin shared memory: the original object can still be reached through the memory roots of the thread, since \nwe haven t updated the roots of the thread; the copy can be accessed by dereferencing the mutable object \nin which it was stored. Therefore, we must *nsure that the two objects are semantically equivalent. This \nis the case if both objects cent ain only 1To implement this, the objects in the private heaps have one \nextra header word, to store a forwarding pointer without destroy\u00ading the object. This extra word is stripped \nwhen the object is copied to the major heap. immutable structures; then, as pointed out in the pre\u00advious \nsection, no constructions in the ML language can distinguish one from the other. This is no longer true \nif the original object contains a mutable structure, be\u00adcause it would be duplicated during the copying \nprocess. This could lead to an update of the two mutable struc\u00adtures by two different objects, breaking \nthe equivalence between the transmitted object and its copy. To avoid this situation, it suffices to \nallocate mutable objects directly in the main, shared heap. Then, they will never be copied, since they \nalready reside in the shared heap. This makes copying semantically trans\u00adparent. Of course, a performance \npenalty is incurred: allocation in the shared heap is more expensive than allocation in the private heap, \nbecause of the required synchronization and free-list searching. However, most ML programs allocate relatively \nfew mutable objects, and they tend to have a longer life span than average. This keeps the overhead reasonable. \n  4 The concurrent collector The major collector implements the concurrent mark and sweep algorithm \ndescribed by Dijkstra et al. [11]. In this section, we recall the basics of the algorithm, adapt it to \nour situation (Dijkstra et al. made some sim\u00adplifying assumptions to keep correctness proofs man\u00adageable), \nand show how the mutator threads cooperate with the concurrent collector. In this section, each thread \nalong with its minor col\u00adlector is considered a mutator thread by the major col\u00adlector. The major collector \nwill be called the collec\u00adtor , and the mutator threads (and their minor collec\u00adtors) will be called \nthe mutators . The major collector does not essentially depend on the existence of the minor collectors. \nIt only needs some way of asking a given mutator to mark the objects pointed to by its roots. In our \ndesign, this marking is performed by the minor collectors. 4.1 Four-color marking Each olbject in the \nshared heap has one of four colors: white, gray, black, or blue. White denotes objects that have not \nyet been visited by the marking phase. Gray denotes objects that have been visited, but whose sons have \nnot yet been visited. Black denotes objects that have been visited, and whose sons have been visited \ntoo. Blue is used for the free list objects: blue objects are always ignored by the collector. z 2 ~ \ntheory, the color blue is not needed: it suffices to consider the free-list head as a memory root, and \nthe free-list blocks as regular reachable blocks. However, the blue color avoids the extra cost of tracing \nand coloring the free-list blocks. allocate sweep mark update Figure 3: Color transitions The color \nof a block evolves as summarized in figure 3. The marking phase sets to black all reachable objects. \nTo do so, it sets the roots to gray and repeatedly finds a gray object and marks it. Marking an object \nmeans setting it to black, and shading its sons. Shading means setting the object to gray if it is white. \nThe sweeping phase reclaims all white objects, setting them to blue and adding them to the free list. \nIt also resets all black objects to white. Allocation in the heap turns blue objects back to white, gray \nor black, depending on the relative states of the collector and mutator, as detailed below. 4.2 The \ncollection phases The collector proceeds in three phases: root enumer\u00adation, end of marking, and sweeping. \nThe root enu\u00admeration and end of marking together constitute the marking phase. At the beginning of the \nroot enumeration phase, the collector sets a global flag to signal the beginning of the marking phase. \nIt then shades the global variables, and asks each mutator to shade its roots. During this phase, the \ncollector also begins to find gray objects and mark them as described above.3 The root enumeration ends \nwhen the collector has obtained the roots of the last mutator. The collector then completes the marking \nphase by repeatedly marking gray objects until no more remain. When the marking phase is finished, the \ncollector ex\u00adamines each heap object in turn. All black objects are set to white. All white objects are \nfree; they are set to blue and inserted into the free list (or collapsed with the preceding free object, \nif adj scent). Some objects might have been set to gray by the mutators since the end of the marking \nphase. These objects are also set to white. The marking phase aasumes that no object is black when it \nstarts, and it ensures that all reachable objects 3 To quickly find the next gray object, a cache of \nrecently shaded objects is maintained, avoiding the cost of an actual scan\u00adning of the heap in most cases. \n  b [114 !5 start update POP shade the roots marking of this thread Figure 4: What happens if we do \nnot shade the new value are black or gray when it stops. More precisely: . all objects that are reachable \nfrom the roots of a mut ator at the time the mut ator shades its roots, or that become reachable after \nthat time, are black at the end of the marking phase. Objects can become reachable by allocation and \nby in\u00adplace modification, which are performed by the muta\u00adtors concurrently with the collection. These \noperations therefore require some cooperation with the collector, as described below. The sweeping phase \nassumes that all reachable objects are black or gray when it starts, and it ensures that only unreachable \nobjects are inserted into the free list, and that no black objects remain when it stops. Again, allocation \nand in-place modification re\u00adquire some cooperation with the collector, in order to avoid setting objects \nto black. These preconditions and postconditions ensure the correctness of the collector: only unreachable \nobjects are ever inserted into the free list. The completeness (all unreachable objects are eventually \ninserted into the free list) stems from the following facts: no unreachable object ever becomes reachable \nagain  there are no blue objects outside of the free list  all white objects unreachable at the start \nof the marking phase remain white  all white objects are inserted into the free list by the sweeping \nphase  gray objects that are unreachable at the beginning of the mark phase become black during marking, \nthen white during sweeping, and are reclaimed by the next collection cycle.  4.3 Concurrent allocation \nand modifi\u00adcation As explained in [11], the mutators have to take the collector state into account when \nperforming in-place modification on heap objects. Otherwise, updating an already black object could result \nin a reachable object that remains white at the end of marking. This prob\u00adlem is further complicated \nby the fact that the set of roots is not fixed during the collection: mut ators can push and pop pointers \non their local stacks without any cooperation with the collector. To avoid this kind of situations, the \nmodification op\u00ad eration must shade both the old and the new value of the modified field. Shading the \nnew value ensures that it will be recognized as reachable by the collector, even if all other pointers \nto the new value disappear (e.g., by popping the last pointer from a stack). Shading the old value ensures \nthat it will be recognized as reachable by the collector, in case some pointers to the old value are \nstill kept on some stack. In the simplified setting described in [11] (a fixed set of roots), shading \neither the old or the new value is sufficient. This is not true in our case. Assume we do not shade the \nnew value. Since the collector starts marking objects before having obtained all roots, a mu\u00adtator can \nmodify a black object by storing a pointer to a white object which is only reachable from the local stack, \nthen pop all pointers to this white object before shading its roots. This results in a reachable object \nthat remains white. This kind of pointer smuggling is illustrated in figure 4. Now, assume we do not \nshade the old value. The mutator could give its roots, then push a white field of a white object onto \nits stack, then overwrite that field. This results in a white object that is reachable from the stack. \n(See figure 5.) This coloring at modification time is only necessary during the marking phase. For the \nsake of efficiency, we do not perform it during the sweeping phase, avoid\u00ading the creation of gray objects \nthat would survive a complete collection cycle before being reclaimed. Concurrent allocation raises similar \nissues: the newly allocated objects must be assigned the right color, de\u00adpending on the collector status. \nDuring the marking phase, objects are allocated black. This is justified by the fact that the allocated \nobjects become reachable, 3b b b+ shade the roots push update finish sweep of this thread marking Figure \n5: What happens if we do not shade the old value and their sons were already reachable, hence will even-to \ncomplete before the next marking cycle. The other tually be set to black. Setting the allocated objects \nrace condition is that the sweep pointer can change af\u00adto gray would also be correct, but the marking \nphase ter the test in line 6. However, the sweep pointer is might not terminate. monotonically increasing, \nhence the race condition can During the sweeping phase, objects are allocated only result in executing \nline 9 instead of line 7, i.e. in white if they have already been swept, and gray oth-setting the object \nto gray instead of white, which is safe. erwise, to avoid immediate deallocation. 4..5 Interface with \nthe minor collector 4.4 Synchronization issues The shading of roots is performed by a variant of the \nThe coloring scheme described above has one inter\u00adminor collector that sets to gray all objects copied \nto esting property: it is always safe to set an object to the major heap, as well as all root objects \nthat are gray. Of course, setting many objects to gray is in\u00adalready in the major heap. This requires \nlittle extra efficient, since an unreachable gray object will not be work compared with a normal minor \ncollection. reclaimed at the end of the current collection cycle, but Hence, the least disruptive technique \nfor getting the only at the end of the next cycle. However, this fact roots is to set a flag telling \nthe minor collectors to shade allows us to avoid synchronization whenever the result\u00ad the roots, and \nwait for all the mutators to complete a ing race condition can only end up in making an object minor \ncollection. However, a mutator can execute a gray instead of the intended color. program that does not \nallocate; it can also be blocked This trick is used in the modification and allocation on a lock, or \nwaiting for input or output. In the former procedures, to test the collector status without locking. \ncase (looping mutator), the major collector interrupts For instance, the coloring of newly allocated \nblocks is the mutator and forces a premature minor collection. In implemented as follows: the latter \ncase (blocked mutator), the major collector performs the copying and shading itsel~ this is similar 1. \nif phase = marking then to a minor collection, except that the minor heap is not 2. set the object to \nblack; emptied. The major collector also has to make sure the 3. if phase = sweeping then mutator does \nnot resume execution before the copying 4. set the object to gray; and shading is complete. This is the \nmost disruptive 5. else interaction between the collector and a mutator, but it 6. if address(object) \n< sweep.pointer then is infrequent. 7. set the object to white; 8. else 9. set the object to gray; \n 5 Experimental results There are two race conditions between this code and the collector. First of \nall, the collector may enter the We have implemented the collector described above in sweeping phase \nbetween lines 1 and 2. Then, the object a prototype ML system derived from Carnl Light re\u00adcould incorrectly \nbe set to black after being swept. In lease 0.4. It runs on an Encore Multimax with fourteen this case, \nlines 3 and 4 set the object back to gray, which NS32532 processors, under the Mach operating system. \nmeets the preconditions of the next marking phase. The Each processor is rated at about 6 MIPS, and has \na collector must synchronize with all mutators before en-256 K write-back cache. The Carol Light system \nis a tering the marking phase, hence line 4 is guaranteed fast bytecode interpreter; it runs 4 to 8 times \nslower Test program Knuth-Pipelined Parallel SIMPLE Bendix compiler compiler (30 x 30) Number of threads \n15 3 12 6,4 (avg) Proportion of updates requiring copying 96 % 43 % 36 % 96 % Major GC load 32 % 16 % \n39 % 10 % Minor GC, average 2.9 ms 2.3 ms 6.3 ms 2.1 ms Minor GC, worst-case 64 ms 180 ms 110 ms 360 \nms Copy-on-update, average 260 /M3 37 ps 55 ps 70 ps Copy-on-update, worst-case 70 ms 6.9 ms 31 ms 20 \nms Free-list locking, average 60 /4S 19 ps 1.6 ms 54 ps Free-list locking, worst-case 17 ms 220 ps 110 \nms 25 ms Figure 6: Average performance than the SML of New Jersey native-code compiler. To put the timings \nbelow in perspective, an application of the identity function takes about 15 ps. The measure\u00adments used \n32 K private heaps, that easily fit into the caches, along with the run-time system and the byte\u00adcode \nprogram. In this section, we comment on some measurements performed on this implementation. We have used \nthe following test programs: A parallel implementation of the Knuth-Bendix completion algorithm. The \nprogram comprises fif\u00adteen threads, and performs lots of interprocess communication via shared mutable \ndata struc\u00adtures.  A pipelined version of the Carol Light compiler, with one thread for the lexical \nanalyzer, one for the parser, and one for the remainder of the compiler. This program is a typical example \nof the producer\u00adconsumer model. The amount of communicant ion is respectable, though less important than \nin the parallel Knuth-Bendix program.  A parallel version of the Carol Light compiler, that simultaneously \ncompiles several files, each file be\u00ading compiled sequentially by one thread. There is very little communication \nbetween the threads. Our test runs twelve compilers in parallel.  e The SIMPLE numerical benchmark from \nAppel s book [1], parallelized by Morriset and Tolmach [19]. This program is typical Fortran code translated \nto ML, and makes very heavy use of mutable arrays. The parallel version relies on futures , that is, \nlazy structures with speculative evaluation. The measurements have two goals: first, estimate the latency \nof memory operations such as allocation and in\u00adplace modification; second, determine whether the ma\u00adjor \ncollector keeps up with a high number of active mu\u00adtators. For the first point, we have measured how \nlong the mut ators are interrupted by (1) minor collections, (2) copy on update operations, and (3) direct \nallocation in the major heap, which requires synchronization. For the second point, we take advantage \nof the fact that the major collector does not run continuously, but only when the amount of free space \nin the shared heap drops below a certain threshold (15% of the total heap size, in the experiments). \nHence, the running time of the major collector compared with the execution time of the whole program \ngives an estimate of the load of the major collector. The results are given in figure 6. The load of \nthe major collector appears to be below 5% per mutator. This suggests that our design should scale to \nabout 20 mut ators. These results hold for the four realistic pro\u00adgrams considered here. However, on \nartificial examples that do nothing but allocate mutable objects, the major collector cannot keep up \nwith as few as four mutators. This is an experimental confirmation of the initial as\u00adsumption that real \nML programs do not allocate much mutable data. The average latency times are remarkably low. Most minor \ncollections complete in less than 10 ms. The copy-on-update strategy makes the cost of an assign\u00adment \nproportional to the size of the assigned value (with the size of the private heap as upper bound) in \nthe worst case; in practice, assignment remains reasonably efficient, even in programs such as the Knuth-Bendix \nbenchmark, that transmit large structures through mu\u00adtable objects. Finally, the last case where a mutator \ncan be delayed on a memory operation is when it accesses the free list to allocate objects directly in \nthe shared heap: free list accesses must be mutually exclusive. To lower contention, each thread maintains \nits own small, private free list. The private free lists are replenished from the main free list when \na request cannot be satis\u00ad Minor colktions 60, I 50\u00ad ,,f / ,, Knuth-Bendix Pipelined compiler -----\u00ad \n40- Parallel compiler SIMPLE -----\u00ad-~~~ 30\u00ad 2 20\u00ad 10\u00ad 0 1 , ......-------......... 1 0.1 1 10 100 1000 \nTime (ins) Copy on update 90, 80 Knuth-Bendix 70 Pi&#38;lined compiler -----\u00ad 60 Parallel compiler SIMPLE \n------\u00ad-\u00ad 50 40 30 20 10 0 1 0.01 0.1 1 10 100 Time (ins) Contention for free-list access 100 iF 90 80 \nKnuth-Bendix Pipelined compiler -----\u00ad 70 Pamllel compiler -----\u00ad 60 SIMPLE \u00ad 50 g 40 Z&#38;i 30 -d \n20 Pi 10 0 ........................... ............ 0.01 0.1 1 10 1 10 Time (ins) Figure 7: Latency distribution \n 120 fied. Transfers from the main free list to a private free list are performed a large chunk at a \ntime, to keep their frequency, low. This strategy works well on three of our test programs, but does \nnot avoid a certain amount of contention for the parallel compiler. From these results, we conclude that \nour design achieves good response time, and is adequate for in\u00adteractive applications. However, it does \nnot achieve true real-time performance: there is no guaranteed up\u00adper bound on the time taken by memory \noperations. A small number of these operations take much longer than the average time. This can be seen \non figure 7, which plots the distribution of execution times for the three memory operations. For instance, \na minor collection can take as much as 360 ms, in the worst-case where all objects in the minor heap \nare alive. Similarly, some copy-on-update operations may need to copy (almost) all objects from the minor \nheap. There is a trade-off between maximal latency and garbage collection over\u00adhead: the worst-case latency \ncan be lowered by reducing the size of the private heaps, but this results in more time spent in minor \ncollections, and an increased load on the major collector. Extensions The memory management system \ndescribed above can be extended in several ways. The first direction is to parallelize the major collection, \nin order to keep up with more active mutators. The sweeping phase can straightforwardly be parallelized, \nsince the heap is al\u00adready divided in medium-sized chunks (256 K), which can be swept by independent \nthreads. The marking phase can also be performed concurrently by several threads, though achieving good \nbalance is more deli\u00adcate. Another area of improvement is the (weight of threads. Since each thread has \nits own stack and its own private heap, thread creation is a rel at ively ex\u00adpensive operation: starting \na Concurrent Carol Light thread takes about 3 ms, which is commensurate with the time it takes to start \na Mach thread (about 1 ms), but still too important for applications that spawn a large number of short-lived \nthreads. For these appli\u00adcations, a promising direction is to adopt the two-level scheme outlined in \n[19], where the user-level threads are multiplexed on top of a small number of kernel threads. Each kernel \nthread has its own private heap, and time\u00adshares between a number of user-level threads. User\u00adlevel threads \ncan freely share a private heap, provided that the memory operations on the private heap are mutually \nexclusive, which the user-level scheduler can easily guarantee. Finally, the concurrent collector described \nabove can be simplified into an incremental, generational collec\u00adtor for uniprocessors. The idea is to \nperform a small part of the major collection at each minor collection. Since there is only one private \nheap, copy-on-update is no longer mandatory, and we can maintain a remem\u00adbered set instead. We have integrated \nthis incremental collector in the release 0.5 of the Carol Light system. 7 Related work The system described \nin this paper is related to two trends in research on garbage collection. The first trend deals with \nconcurrent variants of the classical mark\u00adsweep algorithm, with as little synchronization as pos\u00adsible \nbetween the mutator and the collector [14, 11, 5]. The emphasis here is on proving the correctness of \nthe proposed algorithms, rather than on practicality and efficiency. To our knowledge, none of these \ndesigns has made its way into an actual run-time system. There are good reasons to believe that collectors \nbased on these designs would not be able to keep up with typical ML programs. Hickey and Cohen [13] provide \nsome theoret\u00adical evidence of this problem. This problem is avoided in our system by the use of generation \nscavenging, that greatly reduces the allocation rate as viewed by the con\u00adcurrent mark-and-sweep collector. \nA different approach to the parallelization of the mark-sweep algorithm is described by Boehm et al. \n[7]. Their algorithm requires no cooperation from the rrnu\u00adtators; instead they rely on virtual memory \nprotections to keep track of modifications performed by the mu\u00adtators. Their collector overlaps most \nof its work with the mutator activity but it has to stop the mutators to finish the marking phase. The \nresulting pauses are short (about 100 ms) but still one order of magnitude longer than in our system \non average. Moreover, their technique must stop all mutators simultaneously, intro\u00adducing a spurious \nglobal synchronization point between all threads. Avoiding this phenomenon was one of our main goals. \nThe second trend is the practical implementation of concurrent or incremental copying collectors. The \nfirst such collectors were described by Steele [23] and Baker [4], and later extended to generations \n[18] and to mul\u00adtiple mut ators [12]. This algorithm requires a test on each heap pointer dereferencing} \nwhich imposes consid\u00aderable overhead on the mutator, unless special hardware is used. A variant proposed \nby Brooks [8] replaces this test by a systematic indirection. On stock hardware, this technique slightly \nreduces the overhead, at the ex\u00adpense of one extra word per heap object. North and Reppy [20] have extended \nthis technique with genera\u00adtions. Appel, Ellis and Li [2] propose to use virtual\u00admemory protections to \nimplement Baker s algorithm without tests on stock hardware. Their technique relies on sophisticated \nvirtual memory primitives, which most widespread operating systems do not provide in an effi\u00adcient way \n[3]. Thus, concurrent purely copying garbage collection has not yet been implemented on stock hard\u00adware \nand standard operating systems without major overhead on the mut ators. Our mixed design avoids this \ndifficulty by restricting the copying to unshared objects, which cannot be accessed concurrent y.  Conclusions \n We have described a memory management system for a multithreaded implementation of ML that achieves \nquasi real-time performance with low overhead on the mut ators. This system relies crucially on the compile\u00adtime \nseparation of mutable and immutable objects. In the case of ML-like languages, this separation is en\u00adsured \nby the type system, therefore demonstrating an unexpected spin-off of strong, static typing in the area \nof garbage collection. This technique can also be ap\u00adplied to dynamically-typed languages such as Scheme, \nas long as separate allocation primitives are provided for mutable cons cells and immutable cons cells, \nand similarly for other data types. Acknowledgments We would like to thank Ian Jacobs for his careful \nproof\u00adreading, and Greg Morriset for sending us the SIMPLE benchmark. References [1] A. W. Appel. Compiling \nwith continuations. Cam\u00adbridge University Press, 1992. [2] A. W. Appel, J. R. Ellis, and K. Li. Real-time \ncon\u00adcurrent collection on stock multiprocessors. SIG-PLAN Notices, 23(7):11-23, 1988. [3] A. W. Appel \nand K. Li. Virtual memory primitives for user programs. Technical Report CS-TR-276\u00ad90, Princeton University, \n1990. [4] H. G. Baker. List processing in real time on a serial computer. Commun. ACM, 21(4):280 294, \n1978. [5] M. Ben-Ari. Algorithms for on-the-fly garbage col\u00adlection. ACM Trans. Prog. Lang. Syst., 6(3):333\u00ad344, \n1984. [6] B. Berthomieu. Implementing CCS: the LCS ex\u00adperiment. Technical report 89425, LAAS, Dec. 1989. \n[7] H. J. Boehm, A. J. Demers, and S. Shenker. Mostly parallel garbage collection. SIGPLAN No\u00adtices, \n26(6):157-164, 1991. [8] R. A. Brooks. Trading data space for reduced time and code space in real-time \ngarbage collection on stock hardware. In Lisp and Functional Program\u00adming 1984, pages 256 262. ACM Press, \n1984. [9] E. C. Cooper and R. P. Draves. C threads. Techni\u00adcal report CMU-CS-88-154, Carnegie Mellon \nUni\u00adversit y, 1988. [10] G. Cousineau, P.-L. Curien, and M. Mauny. The categorical abstract machine. \nSctence of C omputer Programming, 8(2):173-202, 1987. [11] E. W. Dijkstra, L. Lamport, A. J. Martin, \nC. S. Sholten, and E. F. M. Steffens. On-the-fly garbage collection: an exercice in cooperation. Commun. \nACM, 21(11):966-975, 1978. [12] R. H. Halstead. Implementation of Multilisp: Lisp on a multiprocessor. \nIn Lisp and Functional Pro\u00adgramming 1984, pages 9-17. ACM Press, 1984. [13] T. Hickey and J. Cohen. Performance \nanalysis of on-the-fly garbage collection. Commun. ACM, 27(11):1143-1154, 1984. [14] H. T. Kung and S. \nW. Song. An efficient parallel garbage collection system and its correctness proof. In Foundations of \nComputer Science 1977, pages 120 131. IEEE Computer Society Press, 1977. [15] X. Leroy. The ZINC experiment: \nan economical implementation of the ML language. Technical re\u00adport 117, INRIA, 1990. [16] X. Leroy and \nM. Mauny. The Carol Light system, version O.5 documentation and user s guide. Technical report L-5, \nINRIA, 1992. [17] R. Milner, M. Tofte, and R. Harper. The definition oj Standar-d ML. The MIT Press, \n1990. [18] D.A. Moon. Garbage collection in a large Lisp sys\u00adtem. In Lisp and Functional Programming \n198.J, pages 235-246. ACM Press, 1984. [19] J. G. Morriset and A. Tolmach. A portable mul\u00adtiprocessor \ninterface for Standard ML of New Jer\u00adsey. Technical report CM U-CS-92-155, Carnegie Mellon University, \n1992. [20] S. C. North and J. H. Reppy. Concurrent garbage collection on stock hardware. In Functional \nPro\u00adgramming Languages and Computer Architecture 1987, volume 242 of Lecture Notes in Computer Science, \npages 113-133. Springer-Verlag, 1987. [21] L. C. Paulson. ML for the working programmer. Cambridge University \nPress, 1991. [22] J. H. Reppy. CML: a higher-order concurrent lan\u00adguage. SIGPLAN Notices, 6(26):294-305, \n1991. [23] G. L. Steele Jr. Multiprocessing compactifying garbage collection. Commtin. ACM, 18(9):495\u00ad \n508, 1975. [24] D. Ungar. Generation scavenging: a non\u00addisruptive high performance storage reclamation \nalgorithm. In Sofiware Engineering Symposium on Practical Software Development Environments, pages 157 \n167. ACM Press, 1984. \n\t\t\t", "proc_id": "158511", "abstract": "<p>This paper presents the design and implementation of a &#8220;quasi real-time&#8221; garbage collector for Concurrent Caml Light, an implementation of ML with threads. This two-generation system combines a fast, asynchronous copying collector on the young generation with a non-disruptive concurrent marking collector on the old generation. This design crucially relies on the ML compile-time distinction between mutable and immutable objects.</p>", "authors": [{"name": "Damien Doligez", "author_profile_id": "81100592225", "affiliation": "", "person_id": "P57895", "email_address": "", "orcid_id": ""}, {"name": "Xavier Leroy", "author_profile_id": "81100078576", "affiliation": "", "person_id": "PP39026141", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158611", "year": "1993", "article_id": "158611", "conference": "POPL", "title": "A concurrent, generational garbage collector for a multithreaded implementation of ML", "url": "http://dl.acm.org/citation.cfm?id=158611"}