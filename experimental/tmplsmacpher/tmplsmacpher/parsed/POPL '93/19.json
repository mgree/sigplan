{"article_publication_date": "03-01-1993", "fulltext": "\n Polymorphism by name for references and continuations Xavier Leroy Ecole Normale Sup&#38;ieure and INRIA \nRocquencourt Abstract This article investigates an ML-like language with by\u00adname semantics for polymorphism: \npolymorphic ob\u00adjects are not evaluated once for all at generalization time, but re-evaluated at each \nspecialization. Unlike the standard ML semantics, the by-name semantics works well with polymorphic references \nand polymorphic con\u00adtinuations: the naive typing rules for references and for continuations are sound \nwith respect to this semantics. Polymorphism by name leads to a better integration of these imperative \nfeatures into the ML type discipline. Practical experience shows that it retains most of the efficiency \nand predict ability of polymorphism by value. Introduction Polymorphic type disciplines like that of \nML fit well within purely applicative languages. However, poly\u00admorphism becomes problematic when imperative \nfea\u00adtures are added to a purely applicative kernel. In this paper, we consider two important imperative \nfeatures: references (data structures that can be modified in\u00adplace); and first-class continuations (objects \nthat cap\u00adture the control state of the evaluator). In the ML community, it has long been known that the \nnaive poly\u00admorphic typing for references is unsound; strong typing restrictions must be put on polymorphic \nreferences to ensure soundness [19]. Recently, it has been shown that the natural polymorphic typing \nfor continuations [4] is unsound for similar reasons [7, 8]. In this paper, we show that these difficulties \nare not inherent to the polymorphic typing of references and continuations, but specific to the ML semantics \nfor generalization and specialization (the two constructs that introduce polymorphism): when generalization \nand specialization are given alternate semantics, the *Author s address: INRIA Rocquencourt, projet Formel, \nB. P. 1os, ?s1 S3 L. Ch.-na=, Framce. E-mail: Xavier Ler. Y@inria fr. Permission to copy without fee \nall or part of this material is granted provided that the copies are not made or distributed for direct \ncommarciel advantage, the ACM copyright notice and the title of the publication and its date appear, \nand notice is given that copying is by permission of the Association for Computing Machinery. To copy \notherwise, or to republish, raquires a fee and/or specific permission. ACM-20th PoPL-I /93-S. C., USA \n@ 1993 ACM 0-89791 -561 -5/93 /0001 /0220 . ..$1 .50 simple polymorphic typings for references and continu\u00adations \nbecomes sound. We call the ML semantics poZy\u00adrnorphism by value, and the alternate semantics studied \nhere polymorphism by name. Generalization is the operation that transforms a term of type r[a], where \na is a type variable stand\u00ading for an unknown type, into a term oft ype VCY. T[CX]. Specialization is \nthe operation that transforms a term of type Va. T[a] into a term oft ype r[u], for some given type expression \nu. With ML s polymorphism by value, generalization has strict semantics: it evaluates its ar\u00adgument once \nand for all, and the resulting value is shared between all specializations of the polymorphic term produced. \nWith polymorphism by name, general\u00adization has lazy semantics: it suspends the evaluation of its argument, \nand each specialization re-evaluates this suspension in the current context. Polymorphism by name is \nused in Quest [2]; viewed as a restricted form of polymorphism, the generics of Clu or Ada also fol\u00adlows \nthis semantics. Drawing the parallel with function application, polymorphism by value is analogous to \ncall by value, and polymorphism by name is analogous to call by name. These two semantics for polymorphism \ncannot be dis\u00adtinguished in a purely applicative language without re\u00adcursion: lambda-calculus with polymorphic \ntyping is strongly normalizing. This is no longer true when we add imperative features to the core language. \nIn partic\u00adular, polymorphism by value makes it possible to access the same reference object or continuation \nobject with two different types, which can compromise type safety; while this cannot happen with polymorphism \nby name, since specializations to the two types return two differ\u00adent references or continuations. This \nsemantic difference has major consequences on the polymorphic typing discipline. With polymorphism by \nvalue, some typing restrictions must be put on gener\u00adalization and/or on the constructs that build references \nand continuations to avoid the inconsistent use of one reference or continuation object with different \ntypes. Several polymorphic type systems have been proposed that achieve this goal [3, 19, 15, 13, 20, \n18], but they are either overly restrictive (many useful polymorphic func\u00adtions that use references or \ncontinuations are rejected), or complicated and hard to understand from the pro\u00ad Semantics Implicit \nsyntax Explicit syntax Naive polymorphic typing Polymorphism by value ML FX-87 [6] unsound Polymorphism \nby name This work Quest, Clu, Ada sound Figure 1: Four approaches to polymorphism grammer s standpoint. \nIn contrast, with polymorphism by name, the simple, intuitive polymorphic type disci\u00ad plines can be extended \nstraightforwardly to references and continuations, and provide excellent support for the imperative programming \nstyle. This fact is folk lore, and the author does not claim originality for noticing it. It is briefly \nmentioned in sev\u00aderal discussions of imperative languages with polymor\u00adphic type systems [6, 2]. This \nfact is also apparent in Harper and Lillibridge s recent work on CPS conversion for polymorphic languages \n[8, 9], which shows that an ML-like language (i.e. one with call by value and poly\u00admorphism by value) \ndoes not admit any type-preserving CPS transform, in contrast to languages with call by name or polymorphism \nby name. The first aim of the present paper is to formally state this folklore result, by giving a soundness \nproof for Mil\u00adner s type system with respect to the by-name seman\u00adtics, including references and first-class \ncontinuations. This proof improves over previous soundness proofs for references in the setting of structural \noperational se\u00admantics [19] by using only elementary techniques in\u00adstead of more involving techniques \nsuch as co-induction. The second aim is to clarify a confusion that appears in some of the works mentioned \nabove: the confusion between the fact that polymorphism is given by-name semantics and the fact that \npolymorphism is explicit in the syntax. The explicit presentation of polymor\u00adphism consists in providing \nspecial syntactic constructs for generalization and specialization: for instance, ab\u00adstraction over a \ntype variable (As. e) and application of a term to a type (e(~)) in Girard s and Reynold s second-order \nlambda-calculus. Ada, Clu, Quest follow this approach. The alternate present ation consists in leaving \nthese operations implicit in the source program, and to perform them silently at conventional program \npoints. In the ML language, generalization is performed by the let construct, and specialization by referenc\u00ading \na variable. All existing languages with polymor\u00adphism by name have polymorphism explicit in the syn\u00adtax. \nThis leads Cardelli to write [2]: Mutability [in Quest] interacts very nicely with all the quantifiers, \nincluding polymor\u00adphism [. ..] The problems encountered in ML are avoided by the use of explicit polymor\u00adphism. \n This is misleading: mutable objects cause no difficulties in Quest because polymorphism follows the \nby-name se\u00admantics, not because it is explicit in the syntax. Indeed, the two semantics and the two syntactic \npresentations for polymorphism can be combined independently (see figure 1); but the fact that the simple \npolymorphic typ\u00ading is sound is specific to the by-name semantics. To clearly make this point, this paper \ninvestigates a calcu\u00adlus with implicit polymorphism and by-name semantics for generalization and specialization. \nThis calculus re\u00admains very close to the ML language, much closer than languages with explicit polymorphism, \nyet it safely sup\u00adports the polymorphic typing of references and contin\u00aduations without putting complicated \nrestrictions over typing. Our final aim is to discuss the practicality of polymor\u00adphism by name. Polymorphism \nby name is sometimes rejected a priori on the grounds of inefficiency [6], and also on the grounds that \nan imperative language with non-strict constructs is error-prone. The author s ex\u00adperience with a prototype \nimplementation of ML with polymorphism by name suggests that these problems are minor in practice: polymorphism \nby name can be compiled just as efficiently as polymorphism by value in the most frequent cases; and \nprograms that behave differently under the two semantics are quite rare, The remainder of this paper \nis organized as follows. Section 2 informally introduces polymorphism by name, and shows how it interacts \nwith references and contin\u00aduations. Section 3 gives an operational semantics for this calculus, and shows \nthe soundness of Milner s type system with respect to this semantics. Section 4 reports on the practicality \nof polymorphism by name.  2 Informal development 2.1 The let name binding The let binding plays two \nroles in ML: type generaliza\u00adtion and sharing of sub computations. On the one hand, the expression let \nz = a in b generalizes the type of a, allowing x to be used in b with different inst antes of the type \nof a. On the other hand, this expression evaluates a once and for all, and shares the resulting value \nbetween all occurrences of z in b. The other ML binding construct, function abstraction, also performs \nsharing on the value of the function argument, but does not generalize its type (for reasons relevant \nto the type inference problem). MLN, the variant of ML with polymorphism by name proposed in this paper, \nseparates type generalization from value sharing. The let construct is replaced by the let name construct: \nlet name x=ain b. This construct generalizes the type of a, giving a poly\u00admorphic type to x in b. In \ncontrast with the usual let binding, the let name binding does not evaluate a im\u00admediately. Instead, \nthe evaluation of a is suspended and is restarted each time z is referenced in b. In other terms, the \nMLN expression let name z = a in b be\u00adhaves exactly like the ML expression let z=~(). a in b{x+~()}, \nor equivalently like the textual substitution b{z + a}. Hence, in MLN, the two roles of the ML let are \nprovided by separate constructs: the let name binding performs type generalization but does not share \nthe cor\u00adresponding value, while function abstraction performs value sharing, but does not generalize \nthe correspond\u00ad ing type. The parallel is more apparent if we introduce the derived form let val z=a \nin b, which is syntactic sugar for (h. b)(a). The let val binding shares the value of a between all occurrences \nof z in b, but does not generalize the type of a; hence, all occurrences of x in b are given the same \ntype. The semantics for let name are consistent with a well-known property of the ML type system [16]: \nthat the expression let x = a in b has type T if and only if the substitution b{o + a} has type r, provided \nz occurs in b. The let name construct carries this equiv\u00adalence one step further: let name x = a in b \nnot only typechecks but also behaves like the textual substitu\u00adtion b{z + a}. What have we gained by \nseparating type general\u00adization and value sharing into distinct constructs? In a purely applicative setting, \nnothing. Worse, we lose the ability to define polymorphic objects that are com\u00adputed only once and shared \namong all their invocations. We shall discuss later how serious this restriction is for purely applicative \nprograms. However, when we add imperative features such as references and continua\u00adtions, the restriction \nhas important benefits, as we shall see.  2.2 References References are indirection cells whose contents \ncan be physically updated. They model data structures that can be modified in-place. References are presented \nthrough the primitive operations ref (a), to create a fresh reference to a; and !a to access the contents \nof reference a; and a := b to update the contents of refer\u00adence a by b. For t ypechecking, we introduce \nthe type r ref of references cent aining an object oft ype T. The obvious t ypings for the operations \nover references are: T4Tref for creation Tref+r for access rrefxr+r for update. for all types T. It \nis well known that these typings are not sound in a language with polymorphism by value. Here is a classical \nexample: let r = ref(/Jx. x) in r:= (~x. x+ 1); i.f (!r)(true) then . . else . . . With the typings above, \nthe reference r is given type da. (a ~ a) ref. Hence, we can use r with type (int a int) ref and assign \nit the successor function. We can then consider r with type (bool ~ bool) ref; hence (!r)(true) has type \nbool, and the if statement is well-typed. However, evaluating (!r)(true) causes to be added to true, \nwhich is a run-time type violation. With polymorphism by value, type safety can be compromised when a \nreference is given a non-trivial polymorphic type. Several restrictions of the ML type system have been \nproposed that rule out this situation [3, 19, 13, 20, 18]. However, finding the right type system for \nML with references is still an active research topic. The main difficulty is to give a type system that \nis correct but not overly restrictive. On the one hand, it is not easy to statically con\u00adtrol the propagation \nof references in a program. Since references are first-class values, they can be returned as function \nresults, stored into data structures, passed through polymorphic functions, and even hidden inside function \nclosures as in the following example. let functional-ref = Ax. let r=ref x in ((A(). !r), (Ay. r := y)) \nThe function functional~ef creates a reference and disguises it as two functions, one for access, the \nother for update. The two functions returned seem totally unrelated, and there is not even a ref in their \ntypes. It is difficult to keep track of the reference hidden in these two functions. On the other hand, \nthe type system should not put overly strong restrictions over references whose types contain type variables. \nOtherwise, many useful poly\u00admorphic functions that use references are rejected, and the imperative programming \nstyle is poorly supported. Consider the following function, which reverses a list iteratively: let reverse \n= N. let arg =ref 1 in let res =ref [] in while not null(arg) do res := head(!arg) :: !res; arg := tail(!arg) \ndone; !res Because of the two local references that hold interme\u00addiate results, most extensions of the \nML type system give a more restrictive type to this function than to its purely applicative counterpart, \neven though the two functions compute exactly the same result. The most advanced extensions [13, 18] \nsucceed in giving the same type to the two functions, but they require complex type algebras, where types \nreflect many operational properties of the functions. This conflicts with the use of types as partial \nspecifications in module interfaces. Polymorphism by name provides an indirect way to resolve this tension. \nWith polymorphism by name, it is semantically impossible to create a reference and con\u00adsider it with \ntwo different types. Consider again the first example above, with let replaced by let name: let name \nr = ref (Ax. x) in r := (~x. x+ 1); if (!r)(true) then . . . else . .  The test if (!r)(true) re-evaluates \nref (Ax. x), result\u00ading in a new reference to the identity function, differ\u00adent from the reference that \nwas assigned the successor function in the previous line. Hence !r evaluates to the identity function, \nand no run-time type violation oc\u00adcurs. With let val instead of let name, the reference r would be given \ntype (a a a) ref, where a is not generalized, Hence a is instantiated to int when typ\u00ading the assignment, \nand typing the test leads to a static type error. The functionalxef example proceeds similarly: the only \nway to do something harmful with functional-ref is to apply it to a polymorphic ob\u00adject (e.g. the identity \nfunction), bind the two returned functions to variables, and use them with two different instantiations \nof their types: let (read, write) = functaonal~ef (Ax. x) in Either the let is a let val, and identifiers \nread and write remain monomorphic; or the let is a let name, and functionalxef(~x. x) is re-evaluated \neach time read or write are referenced, creating fresh, non\u00adaliased references to the identity function \neach time. These examples show that polymorphism by name avoids type violations when polymorphic references \nare inconsistently used. However, it perfectly supports the consistent sharing of references inside polymorphic \nfunctions, even if these references have statically un\u00adknown types. For instance, in the case of the \nfunction reverse, the desired behavior is obtained by: let name reverse = M. let val arg =ref 1 in let \nval res = ref [j in while not null(arg) do res := head(!arg) :: !res; arg := tail(!arg) done; !res \nThe let val bindings for arg and res ensure that these identifiers are bound to the same references throughout \nthe while loop. This causes no typing difficulties be\u00adcause arg and res are consistently used with the \nsame type inside the loop. The outermost let name binding ensures that reverse is polymorphic. The fact \nthat the closure representing this function will be rebuilt each time reverse is used, instead of being \nshared between all uses, is semantically transparent. 2.3 First-class continuations We now consider \nthe addition of continuations as first\u00adclass values to the core ML language. We closely follow the presentation \nadopted in the Standard ML of New Jersey implementation. This presentation and some al\u00adternatives are \nthoroughly discussed by Dubs, Harper and MacQ~een [4], to which the reader is referred for a more gentle \nintroduction to continuations in ML. In SML-NJ, continuations are presented through the type r cent of \ncontinuations expecting a value of type ~, and the two operations callcc(a), to capture the current continuation \nand pass it to the function a, and throw(al, az), to restart the continuation al on the value az. The \ntypings for these operations are, for all types T and T : (r cent +7) + ~ for callcc rcontxrer for throw \n These typings are sound in a simply-typed language [4]. It had long been believed that they were also \nsound in the polymorphic type system of ML, until Harper and Lillibridge came up with a counterexample \n[7]: let later= callcc(~k. (~x. x, ~f. throw(k, (f, Ag. ())))) in print (first(later)( Hello world )); \nsecond(later)(~x. x + 1)  Everything typechecks with the typings above: later is given type Ya,p.(a \n-+ a) x (a ~ a) ~ /?, and therefore can be used with a instantiated to string in the first part of the \nsequence and with a instantiated to int in the second part. At run\u00adtime, the callcc construct binds k \nto the continu\u00adation later + print(first(later). . .). Execution proceeds by applying the identity function \nto the string Hello world , thenby restarting the continuation k on the value v = (Ax. x+ l), (~g. ()). \nA run-time type violation follows when trying to apply the first compo\u00adnent of v to the string Hello \nworld . The reason is that the type of value v is less general than the type statically assumed for later \nin the body of the let. This situation is quite similar to the first example with references above: in \nboth cases, static typing as\u00adsumptions about identifiers bound to polymorphic ob\u00adjects are violated after \nthe binding has changed, either because a reference was updated, or because a contin\u00aduation was restarted. \nThis problem with polymorphic continuations can be avoided by typing restrictions similar to those for \npoly\u00admorphic references [21, 11] with the same drawbacks: the corresponding type systems are either \ntoo restrictive or too complicated. Again, polymorphism by name pro\u00advides an alternate solution. With \nby-name semantics for generalization, it is impossible to capture a continu\u00adation that generalizes the \ntype of the value received by the continuation, as in Harper and Lillibridge s exam\u00adple, because polymorphism \nby name does not generalize the type of values, but only of suspended expressions. In the setting of \npolymorphism by name, Harper and Lillibridge s example becomes: let name later = callcc(~k. (Ax. x, ~f. \nthrow(k, (f, ~g. ())))) in print (flrst(later)( Hello world )); second(later)(~x. x + 1)  (Binding \nlater with a lambda abstraction would re\u00adsult in a static type error. ) The callcc expression defining \nlater is evaluated twice, once for each ref\u00aderence to later, capturing different continuations than in \nthe case of by-value semantics. In particular, the application second(later) binds k to the continuation \nlater + second(later)(~x. x + 1), and the throw k restarts the program at that point, with second(lat \ner) bound to the harmless function Jg. (). No run-time type violation occurs,  3 Formalization In this \nsection, we formalize the calculus presented above, give its operational semantics, and show the soundness \nof Milner s typing rules with respect to the semantics.  3.1 Syntax The language we consider is the \ncore ML language en\u00adriched with references and continuations. We assume given a countable set of variable \nidentifiers, ranged over by z. The terms of the calculus, ranged over by a, are described by the grammar \nbelow. Expressions: .. a .. i integer constant lx variable identifier [ Ax. a function abstraction / \na~(a~) function application I let name x= al in a~ suspended binding I Op(a) unary operator application \nI op(al, az) binary operator application Operators: Op ::= ref creation of a reference I deref access \nto a reference I assign modification of a reference ] callcc capture the current continuation I throw \ninvocation of a continuation For the sake of simplicity, we have omitted conditional constructs and fixpoint \noperators in the calculus above. It is straightforward to add typing and evaluation rules for conditionals. \nAs for recursive functions, there is no need to introduce a built-in fixpoint operator, since recursive \nfunctions can be defined (albeit painfully) in terms of references and continuations. For inst ante, \nthe expression below computes the fixpoint Y (~j. Jz. a): let val r = ref (Ax. throw(k, 1)) in r := Ax. \na{f +--!r}; !r (Here, k is assumed to be some dummy integer continu\u00adation previously captured. The function \nJx. throw(k, 1) has type r -+ # for all types ~ and #, and therefore provides an initial value with the \nright type for the ref\u00aderence. ) 3.2 Operational semantics We now give a continuation semantics to the \nlanguage above, in structured operational style. The rules in fig\u00adure 3 define the evaluation predicate \ne/s t-a; k + r, meaning in evaluation environment e and initial store .. . Values: v .. integer constant \nI ~x, a,e) function closure 11 store location Ik cent inuat ion Answers: r ::= I v/s wrong normal run-time \nanswer type error Environments: e ::= [Zltvl,..., znvn]n] finite mapping from variables to values Continuations: \nk ::= I I I I I stop apply l(a, apply2(z, Unop(op, k) binopl(op, binop2(op, e, k) a, e, k) a, e, k) v, \nk) end of the program function part of an argument part of an argument of a unary first argument of a \nsecond argument of application application operation binary opea binary ration operation Stores: s ::= \n[ll+vl,...,ln+vn] finite mapping from locations to values Figure 2: The semantic objects Ski bk+r x \nG Dom(e) ske(x)bk~r Sk?) bstOp+ V/s e/ski; k~r e/stx; k3r Sk(Z, U)e)Dk9r e/sl-a2{x+-al}; k*r e/sk Az. \na;k+r e/s i-let name x=al ina2; k~r e/s 1-al; apply l(az, e, k) z+-r e/s t-a2; apply 2(z, al, el, k) \n~ r e[s+-v]/sl-a; k~r e/s h a1(a2); k + r s h (x, al, el) bapplyl(az, e,k) + r s F vbapply2(x, a,e, k) \n+ r e/s t-a;unop(op, k) + r e/s F al; binopl(op, az, e, k) + r e/s 1-az; binop2(op, VI, k) + r e/s E \nop(a); k + r e/s h op(al, a2); k + r s h VI Bbinopl(op, az, e,k) ~ r / @ Dom(s) s[~+v]t-~pk+r 1 E Dom(s) \nhs(~)bk+r s &#38; v b unop(ref, k) + r s ~ /bunop(deref, k) ~ r / G Dom(s) s[l?i--v]bvbk+r s ~ v b binop2(assign, \n~, k) ~ r e[x+k]/s+a; k+r skvbkl+r s t-(c, a, e) bunop(callcc, k) * r s ~ v b binop2(throw, kl, k) ~ \nr If none of the conclusions of the rules above match: eis 1-a; k + wrong skvbk+ wrong Figure 3: The \nevaluation rules .E(x)=val. ..crn.7\u00adElni:int EFz:~{al +rl, . ..)am+rn} E[z:#]t-a:r Et-al: r +r Ekaz:r \nEt-Ax. a:r +r Et-a1(a2):r E1-al:r IV(T ) \\ IV(E) = {Cq .%} E[z : Vcrl . . .crn. #] Ea2:r E1-letname z=alinaz:r \nEka:r Eta: rref Etal:rref El-az:r E F ref(a) : T ref E 1-deref(a) : T E t-assign(al, az) : r Eka:rcont-+r \nEFal:r E t-az : r cent E F callcc(a) : T E + throw(al, az) : T Figure 4: The typing rules s, the evaluation \nof the term a followed by the contin-3.3 Type system uation k terminates on the answer r)). The rules \nalso We now apply Milner s polymorphic type discipline to define the auxiliary predicate s 1-v ~ k ~ \nr, meaning the language above. The typing rules are well known; in the initial store s, the value w passed \nto the contin\u00adwe recall them in figure 4. The rules define the pred\u00aduation k produces the answer r . \nAn answer is either a icate E F a : T, meaning under the assumptions E,value and a modified store, or \nthe constant wrong de\u00adthe expression a has type T . Type expressions, typenoting a run-time type error. \nEvaluation environments schemes and typing environments are defined by the map variables to values. These \nsemantic objects are grammar: represented as terms from the algebra defined by the grammar in figure \n2. Store locations, ranged over by /, Type expressions: .. are taken from a given infinite set of locations. \nT .. int the type of integers [a type variable I 71 + r~ function type I T ref reference type The evaluation \nrules can almost be read as the transi-I T cent continuation type tions of an abstract machine such \nas the CEK-machine [17, 5] enriched with a store: the terms a represent Type schemes: the code component \nof the machine, the environments u ::= b ~l...~T.T e represent the environment component, and the con- \nTyping environments:tinuation terms k represent the stack. The judgement E ::= [xl: al, . . ..z~. an] \n e/s F a; k + r can be read as initiate the computa\u00adtion of a, pushing the current state of the computation \n 3.4 Type soundness on k if necessary . The judgement s E v b k a r can similarly be read as (resume \nthe saved computation on We are now in a position to show a Milner s style sound\u00ad top of k over the value \nW . ness result for the proposed calculus: no closed, well\u00adtyped term can evaluate to wrong. That is, \na well\u00adtyped term either diverges or terminates with a normal The only rule that does not correspond \nclosely to response, but does not terminate on a run-time type a transition of a CEK-like machine is \nthe rule for violation. let name. For the sake of simplicity, we have expressed Proposition 1 If [] 1-a \n: T and []/[] 1-a; stop > r, the evaluation of let name x = al in az as the evalu\u00adthen r # wrong. ation \nof the textual substitution az {z +-al}. An alter\u00adnate present ation, closer to an actual execution model, \nA simple, indirect proof of this claim is as follows. is to bind z to the suspension (al, e) during the \nevalua- By rewriting all let name nodes in a by the rule tion of az, and to evaluate this suspension \neach time z let name x= al in az is referenced; this presentation is detailed in [11, chap\u00adter 6]. * \nlet z= A(). al in az{zt-zo} we transform a into a term a of ML with polymor\u00adphism by value that evaluates \nto wrong if and only if a evaluates to wrong, Moreover, the translation a is well\u00adtyped in Tofte s type \nsystem [19], with all type variables taken to be imperative t ype variables. The main reason is that \nall let expressions bind non-expansive expres\u00adsions. Then, proposition 1 follows from the well-known \nfact that Tofte s type system is sound for the core ML language extended with references and continuations. \nUnfortunately, while the soundness of Tofte s system haa been shown for ML plus references [19, 21] and \nseparately for ML plus continuations [21], no formal soundness proof has been given for the combination \nof references and continuations. Hence this indirect argu\u00adment is not satisfactory. A direct proof of \nthe soundness claim is given in appendix. The proof is a considerable simplification over previous proofs \nof type soundness in the presence of a store, which rely either on complicated domain constructions [3], \nor on definitions by greatest fixpoints and proofs by co-induction [19]. The key idea, due to Tofte, \nis to appeal to the typ\u00ading relation to define what it semantically means for a functional value to belong \nto a function type: in\u00adstead of the usual condition closure (z, a, e) belongs to type rl ~ TZ iff it \nmaps values of type rl to values of type 7-2 , we take that closure (r, a, e) belongs to type ~1 + r2 \niff we can derive the typing judgement E t Ax. a : rl + TZ for some typing environment E that agrees \nwith the evaluation environment e . We have extended this idea to the semantic typing of cent inuat ions: \ninstead of the usual condition cent in\u00aduation k belongs to type ~ cent iff it never produces wrong when \napplied to a value of type r , we use struc\u00adtural induction over k and appeal to the typing rules. The \nresulting proof is elementary: it proceeds only by structural induction over the terms representing values \nand evaluation derivations. In particular, there is no need for proofs by co-induction [19, 14]. The \nproofs also easily extend to other polymorphic type systems for references and continuations [11].  \n Assessment Polymorphism by name supports references and contin\u00aduations in a type-safe way, while retaining \nthe ML type algebra and typing rules, that are familiar and easy to understand, This is a strong advantage \nover the re\u00adstricted type systems proposed for references and con\u00adtinuations in the setting of by-value \nsemantics, which generally use richer type algebras and more complex typing rules. MLN, the variant of \nML with polymor\u00adphism by name proposed in this paper, is therefore an interesting alternative to ML when \nimperative features are considered. However, MLN is not semantically equivalent to ML: since value sharing \nand type generalization are per\u00adformed by distinct constructs in MLN, it is not possible to share the \nvalue of a polymorphic object. In this sec\u00adtion, we discuss the practical consequences of this fact. \n4.1 Differences in semantics First of all, programs where polymorphic objects are computed by expressions \nwith observable side-effects do not behave the same in ML and in MLN: the side-effects are performed \nonce at creation-time in ML, but several times in MLN once for each specialization. Example: let name \nf = print( Hi! ); ~x. x in f(f(f)) Evaluating this MLN phrase prints (H1 ! three times; the corresponding \nML phrase prints Ei ! only once. Here is another example, which assumes defined a stamp generator gensym: \nlet stamper = let stamp = gensyrno in Ax. (x, stamp) in ... In ML, the stamper function takes arguments \nof arbi\u00adtrary types and pairs them with the stamp obtained the same stamp for all applications of stamper. \nThe straightforward translation to MLN behaves differently: let name stamper = let val stamp = gensymo \nin Ax. (x, stamp) in ... Each application of st amper re-evaluates the expression defining stamper, and \ntherefore calls gens ym each time; hence, a different stamp is paired with each argument. To preserve \nthe original behavior, the program must be rewritten as follows: let val stamp= gensym( ) in let name \nstamper = Ax. (x, stamp) in ... For more complex examples, deeper transformations might be required. \nHowever, these examples are rather artificial. In practice, polymorphic objects are most often defined \nby expressions that are side-effect free and that do not depend on the state, such as lambda\u00adabstractions. \nIn this case, the translation from ML to MLN is straightforward: it suffices to replace the let bindings \nby let name for polymorphic objects and let val otherwise, and the behavior of the program is preserved. \nFor the experiments described below, the author translated about 10000 lines of ML programs to MLN this \nway, without encountering a single case where non-trivial transformations (as in the stamper example) \nwere required. 4.2 Differences in efficiency let f = weirdsort (<) (lots .ofintegers) in Even in the \ncases where it is safe to re-evaluate the expressions defining polymorphic objects, we may fear that \nthis recomputation is a major source of inefficiency. In practice, this is not the case, because in most \npro\u00adgrams the vast majority of polymorphic objects are de\u00adfined as functions Ax. a. The evaluation of \nthese objects reduces to the construction of a closure, which is cheap. Moreover, the standard uncurrying \ntechniques [1, sec\u00adtion 6.2] can be used to avoid re-building the function closure when a polymorphic \nfunction is immediately ap\u00adplied. Consider the typical code fragment: let name f=Jx.a in ... f(1) ... \nf(true) ...  This MLN program is compiled exactly as the following ML program: let f=~(). ~x. a in ... \nfo(l) ... fo(true) That is, f is compiled as a curried function with two arguments, ( ) and x. After \nuncurrying, the two cur\u00adried applications are transformed into simple calls to a function with two arguments, \nwhich is as efficient as the direct application f(1) or f (true). (The extra cost of passing the unit \nargument can easily be avoided.) However, there are some situations where a polymor\u00adphic object is expensive \nto compute. These situations correspond to the partial application of a curried func\u00adtion that performs \na significant amount of computation between the passing of its first and second arguments. Binding the \nfunction returned by the partial applica\u00adtion allows the sharing of this computation between all subsequent \napplications of the function. With polymor\u00adphism by name, this sharing is impossible if the result of \nthe partial application must remain polymorphic. Here is an example of this situation. Consider a func\u00adtion \nthat sorts key-data pairs in increasing order for the keys. Assume that the keys and the associated data \nare not provided together, as a list of pairs, but sepa\u00adrately, as a list of keys and a list of associated \nitems. The function result is the permuted list of items. To take advantage of partial applications, \nthe clever way to write this function is to compute the sorting permu\u00adtation (e.g. a list of integers) \nas soon as the list of keys is given, and to return a function that simply applies the sorting permutation \nto the given list of items: let weirdxort = ~order. ~keys. let permut = . . in A items. apply .permut(permut, \nitems) This is more efficient if several lists of items are to be ordered on the same list of keys: \n. . . f(lots.of-strings) . . . . . . f(lots_of_booleans) . . . Here, the intermediate function f is \npolymorphic (with type da. a list + a list), and therefore can be ap\u00adplied to item lists of different \ntypes without sorting again the list of keys each time. This last point holds in ML, but not in MLN. \nIf f is to remain polymorphic, it must be bound by a let name construct; then, each application f(1) \nevaluates as weird=ort (<) (lots_of_integers) (1) Hence, the benefits of partial application are lost. \n 4.3 Experimental results To evaluate more precisely the impact of polymor\u00adphism by name on real programs, \nthe author has im\u00adplemented a prototype compiler for ML with polymor\u00adphism by name, derived from his \nCarol Light system [12], which implements polymorphism by value. Deriv\u00ading an MLN compiler from an ML \ncompiler is straight\u00adforward: it suffices to transform the MLN expressions letnamez=ainb into ML expressions \nlet z=~(). a in 15{z+z()} early in the compilation process; the remainder of the compiler need not be \nmodified. Good performance cru\u00adcially depend on the efficiency of the subsequent uncur\u00adrying phase, however. \nIn the case of the Carol Light execution model [10, chap. 3], the very same code is generated for the \nMLN expression let name f= Ax. a in ... f(a ) ... f(a ) ... and for the corresponding ML expression \nlet f= Ax. a in ... f(a ) ... f(a ) ... which is about the best we can expect. Figure 5 gives some preliminary \nbenchmark results for the Carol Light-based ML and MLN compilers. The test programs comprise, in addition \nto the usual toy programs, two medium-sized programs perform\u00ading mostly symbolic processing, Boyer s \nsimplified the\u00adorem prover and an implementation of the Knuth-Bendix completion algorithm, and two pieces \nof the Carol Light environment, adapted to polymorphism by name and bootstrapped, the lexical analyzer \ngenera\u00adtor (1000 lines) and the compiler itself (8000 lines). Some of these programs are completely monomorphic \n(Fibonacci, word count). Others use polymorphic func\u00adtions intensively (Church integers). The more realistic \nTest ML MLN Slowdown Amount of MLN/ML polymorphism ! Fibonacci 5.9 s Church integers 2.5 S Sieve 3.2 \ns Word count 6.4 S Boyer 16.0 S Knuth-Bendix 7.9 s Lexer generator 2.1 s The Carol Light compiler 7.1 \ns Figure 5: Experimental comparison between programs operate mostly on monomorphic data struc\u00ad tures, \nbut make frequent use of generic functions over lists, hash tables, etc. The experimental results show \nthat all programs, even the purely monomorphic ones that do not use let name at all, are slowed down \nby about 5% in MLN. The reason is that a minor optimization in the Carol Light execution model, which \nrelies on the fact that curried functions are always applied to at least one ar\u00adgument, applies to ML, \nbut not to MLN. This slow\u00addown is specific to the Carol Light execution model; it should not occur with \nmore conventional uncurrying techniques. In addition to this general slowdown, the tests exhibit a slowdown \nby 170 to 10~0, which repre\u00adsents the actual cost of polymorphism by name with respect to polymorphism \nby value. Adapting such an ML compiler to MLN is straight\u00adforward: it suffices to transform let name \nz = a in b expressions into let val z = A(). a in b{x + z()} early in the compilation process, and let \nthe uncurrying mechanisms work on this intermediate form. These experimental results are encouraging: \nthey show that an ML compiler with uncurrying mechanisms can easily be adapted to polymorphism by name, \nwith\u00adout major efficiency loss. The author believes that these results are not specific to the Carol \nLight implementa\u00adtion, but should apply to any ML compiler equipped with uncurrying mechanisms. Polymorphism \nby name cannot be dismissed easily on the grounds of ineffi\u00adciency.  Conclusions We have shown that \nby-name semantics for polymor\u00adphism can be integrated with an ML-like language, re\u00adsulting in a simple \nsolution to the problems raised by the polymorphic typing of references and continuations. This solution \nhas two major advantages over the tra\u00additional restricted polymorphism by value approach, which consists \nin keeping polymorphism-by-value se\u00ad 6.3 S 6% none 2.9 S 16% high 3.4 s 6% moderate  6.7 S 4% none \n18.0 S 12% low 8.3 S 5% moderate 2.3S 9% low 8.3 S 16% low ML and MLN, in the Carol Light system mantics \nand putting suitable typing restrictions over references and continuations. First of all, the type system \nassigns the same types to applicative and im\u00adperative implementations of the same function, which is \ncrucial in the context of modular programming (in Standard ML, for instance, most polymorphic func\u00adtions \nspecified with an applicative type cannot be im\u00adplemented in an imperative style). Moreover, this result \nis achieved while keeping the simple, familiar ML type algebra, in contrast with the most recent type \nsystems for restricted polymorphism-by-value, such as effect sys\u00adtems [18] and closure typing [13, 11], \nwhich achieve the same results at the cost of complicated type algebras where type expressions are so \ninformative that their use as specifications in module interfaces becomes problem\u00adatic. It is true that \nthe polymorphism-by-name approach has some unfortunate drawbacks, such as its inability to express the \nsharing of some sub computations of poly\u00admorphic values, but these drawbacks seem relatively minor in \npractice, compared with the drawbacks of the restricted polymorphism-by-value approach. We have presented \nsome experimental evidence of this fact; more experience with polymorphism by name is needed to confirm \nthe practicality of this approach.   A Proof of soundness In this appendix, we sketch the proof of \nsoundness of Milner s type system with respect to the semantics given in section 3.2. We first formalize \nwhat it means for a value to se\u00admantically belong to some type, and for a continuation to semantically \naccept values of some type. We write these conditions S 1= v : r and S 1= k :: r, respectively. The hypothesis \nS is a store typing, that is, a partial mapping from locations to type expressions. The store typing \nis needed to take into account the sharing of values introduced by the store. The semantic typing relations \nare defined by structural induction over the 229 terms representing values, continuations and evaluation \n2. IfS+v :rand S&#38;k:: ~and+ s: Sand environments, as follows: sl-vbk%-r,thenr #wrong. S>i:int  S \n~ (z, a,e) : T1 ~ T2 if there exists a typing environment E such that E 1-Ax. a : T1 + T2 and S1-e:E. \n S~ 4: ~ ref if 1E Dom(S) and S(l) = ~.  S+k:7contif S~k::T.  s + stop :: ~ for all types ~.  S # \napplyl(a, e, k) :: rl ~ 72 if there exists a typing environment E such that E 1-a : T1 and S~e:Eand S~k::rz. \n e S &#38; apply2(z, a, e, k) :: r if there exists a typing environment E and a type r such that E 1-Ax. \na : T+r and S~e:E and S~k::#. e S ~unop(ref)k) ::~if S l=k :: r ref. e S ~ unop(deref, k) ::r ref if \nS ~ k ::r. S 1= binopl(assign, a, e, k) :: T ref if there exists a typing environment E such that E \ni-a : T and S~e:Eand S~k::r.  S ~ binop2(assign, v,k) :: ~ if S ~ v : r ref and s~k::r.  S + unop(callcc, \nk) :: ~ cent ~ r if S ~ k :r.  e S 1= binopl(throw, a, e, k) :: T cent if there exists a typing environment \nE such that E 1-a : T and S~e:E. S ~ binop2(throw, v, k) :: ~ if S ~ v : r cont.  S ~ e : E if for \nall x c Dom(e), E(z) is a simple type r such that S ~ e(~) : ~.  \\ s : S if Dom(s) = Dom(S), and for \nall 1 c Dom(s), we have S ~ s(l) : S(4).  A store typing S extends a store typing S if Dom(S ) z Dorn(S), \nand S (l) = S(l) for all 1 6 Dom(S). The semantic typing relations defined above are obviously stable \nunder store extension; that is, if S*W: T and S extends S, then S 1= v : r, and similarly for the other \nsemantic typing relations. Proposition 2 Let a be a term, E a typing environ\u00adment, r a type expression, \nS a store typing, k a contin\u00aduation, s a store, and r an answer. l. If Eka:rand S~e:E and S+k::r and \n1=s :S and e/s+ a; k 3 r, then r # wrong. Proof. The proof is a simple, but tedious induction on the \nheight of the evaluation derivation (the derivation of e/s 1-a;k + rfor (l); the derivationofs 1-Vbk \n~ r for (2)), and case analysis on a and k, respectively. We give the main cases; the remaining cases \nare similar. Case (1) when a is let name z = al in az. From the typing derivation of E h a : T, we can \ncon\u00adstruct a typing derivation of E 1-az {x + al} : T [16, section 4.7. 2]. The result follows from induction \nhy\u00adpothesis (1) applied to the evaluation of az {z +-al}. Case (1) when a is al(az). Let r ~ ~ be the \ntype of al. By definition of ~ over applyl con\u00adtinuations, we have S > apply l(az, e, k) :: T + r, taking \nE for the required typing environment. Ap\u00adplying the induction hypothesis (1) to the evaluation e/s 1-al; \napply l(az, e, k) + r, we get r # wrong as expected. Case (2) when k is apply l(az, ez, k). By hy\u00adpothesis \nS~ k::T,wehave T= rl + r2and E2Fa:~1and S&#38;e2:E2and S ~k::~z,forsome~l, rz, E2. By hypothesis S \\ \nv : ~, the value v is a closure (z, ao, eo), and (3) E. 1-Az.ao : T1 --+ T2 and (4) S F e. : E. for some \nEO. Since v is a closure, the elimination rule for applyi closures matches. From (3) and (4), we get \nS ~ apply2(z, ao, eo, k) :: I-1. The expected re\u00adsult follows from induction hypothesis (1) applied to \nthe evaluation e/s 1-az; apply2(z, ao, eo, k) + r. Case (2) when k is apply2(z, a, e, k). By hy\u00adpothesis \nS~k::r,wehave (5)EFAx.a:r--+r and(6) S~e:Eand S~k:: #forsome Eand some #. Consider the environments el \n= e[~ +-v] and El = E[z +-T]. By (6) and the hypothesis S ~ v : ~, we have S ~ el : El. Moreover, El \nt-a : T since this is the premise of the only typing rule that concludes (5). Hence we can apply induction \nhypothesis (1) to the evaluation el/s k a; k + r. Case (2) when k is unop(ref, k ). Let 1 be the new \nlocation chosen by the evaluation rule. Consider the store typing S = S[1 ~ ~]. We have ~ s[l +-V] : \nS . Since 1 @ Dom(s) = Dom(S), the store typing S extends S. Hence S ~ k :: ~ implies S 1= k :: T, which \nmeans S &#38; k :: r ref. The result follows by induction hypothesis (2) applied to the evaluation s[l \ne v] 1= 1 D k %-r and to the store typing S . Case (2) when k is binop2(assign, v, k ). By hypothesis \nS ~ k :: T, we have S ~ k :: T, and the value v is a location 1 such that S(l) = ~. Since 1= s : S, it \nfollows that / G Dom(s). By hypothesis S ~ v : r, we have ~ s[l? -v] : S. Hence we can apply the induction \nhypothesis (2) to the evaluation s[l +-v] 1-v D k ~ r. [7] It follows that r # wrong, as desired. Case \n(2) when k is unop(callcc, k ). By hy\u00adpothesis S + k ::r, we have r = T cent + T and [8] s + k :: T . \nBy hypothesis S &#38; v : r, we have v = (x,a,e), with E i-~x.a :r cent + r and S 1-e : E for some typing \nenvironment E. Consider the [9]environments ei = e[z + k] and E = E[z + r cent]. We have S ~ e : E and, \ngiven the typing rule for function abstraction, E 1-a : r . The result follows by induction hypothesis \n(1) applied to the evaluation [10] of e /s Fa;k a r. Case (2) when k is binop2(throw, k , k ). By hypothesis \nS ~ k :: r, it follows that S + k :: r. [11] Applying the induction hypothesis (2) to the evaluation \nS ~ v D k ~ r, we get the expected result. o [12] Proposition 1 in section 3.4 immediately follows from \nproperty (1) in proposition 2, taking the empty map for e,E, sand S. [13] Acknowledgments The author \nis indebted to Didier R4my for many dis\u00adcussions of the ideas in this paper. Many thanks to [14] Benjamin \nPierce for his editorial help. [15] References [1] A. W. Appel. Compiling with continuations. Cam\u00ad[16] \nbridge University Press, 1992. [2] L. CardeUi. Typeful programming. In E. J. Neuhold and M. Paul, editors, \nFormal Descrip\u00adtion of Programming Concepts, pages 431-507. [17] Springer-Verlag, 1989. [3] L. Damas. \nType assignment in programming lan\u00adguages. PhD thesis, University of Edinburgh, 1985. [18] [4] B. F. \nDuba, R. Harper, and D. MacQueen. Typ\u00ading first-class continuations in ML. In Principles of Programming \nLanguages J99J, pages 163 173. [19]ACM Press, 1991. [5] M. Felleisen and D. P. Friedman. Control oper\u00ad[20] \nators, the SECD machine and the J-calculus. In Formal Description of Programming Concepts III, pages \n131-141. North-Holland, 1986.  [6] D. K, Gifford and J. M. Lucassen. Integrating [21] functional and \nimperative programming. In Prin\u00adciples of Programming Languages 1986, pages 28 38. ACM Press, 1986. \nR. Harper and M. Lillibridge. ML with callcc is unsound. Message sent to the snd mailing list, July 1991. \nR. Harper and M. Lillibridge. Polymorphic type assignment and CPS conversion. In 1992 SIG-PLAN Continuations \nWorkshop, 1992. R. Harper and M. Lillibridge. Explicit polymor\u00adphism and CPS conversion. In Principles \nof Pro\u00adgramming Languages 1993. ACM Press, 1993. X. Leroy. The ZINC experiment: an economical implementation \nof the ML language. Technical re\u00adport 117, INRIA, 1990. X. Leroy. Typage polymorphe d un langage algo\u00adrithmigue. \nDoctoral dissertation (in French), Uni\u00adversii% Paris 7, 1992. X. Leroy and M. Mauny. The Carol Light \nsystem, version O.5 documentation and user s guide. Technical report L-5, INRIA, 1992. X. Leroy and \nP. Weis. Polymorphic type infer\u00adence and assignment. In Principles of Program\u00adming Languages 1991, pages \n291 302. ACM Press, 1991. R. Milner and M. Tofte. Co-induction in relational semantics. Theoretical Comput. \nSci., 87:209 220, 1991. R. Milner, M. Tofte, and R. Harper. The definition of Standard ML. The MIT Press, \n1990. J. C. Mitchell. Type systems for programming languages. In J. van Leeuwen, editor, Handbook of \nTheoretical Computer Science, volume B, pages 367 458. The MIT Press/Elsevier, 1990. J. Reynolds. Definitional \ninterpreters for higher\u00adorder programming languages. In Proceedings of the 25th ACM National Conference, \npages 717 740. ACM Press, 1972. J.-P. Talpin and P. Jouvelot. The type and ef\u00adfect discipline. In Logic \nin Computer Science 1992. IEEE Computer Society Press, 1992. M. Tofte. Type inference for polymorphic \nrefer\u00adences. Information and Computation, 89(l), 1990. A. K. Wright. Typing references by effect infer\u00adence. \nIn European Symposium on Programming, volume 582 of Lecture Notes in Computer Science. Springer-Verlag, \n1992. A. K. Wright and M. Felleisen. A syntactic ap\u00adproach to type soundness. Technical report TR91\u00ad160, \nRice University, 1991.  \n\t\t\t", "proc_id": "158511", "abstract": "<p>This article investigates an ML-like language with byname semantics for polymorphism: polymorphic objects are not evaluated once for all at generalization time, but re-evaluated at each specialization. Unlike the standard ML semantics, the by-name semantics works well with polymorphic references and polymorphic continuations: the naive typing rules for references and for continuations are sound with respect to this semantics. Polymorphism by name leads to a better integration of these imperative features into the ML type discipline. Practical experience shows that it retains most of the efficiency and predictability of polymorphism by value.</p>", "authors": [{"name": "Xavier Leroy", "author_profile_id": "81100078576", "affiliation": "", "person_id": "PP39079472", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158632", "year": "1993", "article_id": "158632", "conference": "POPL", "title": "Polymorphism by name for references and continuations", "url": "http://dl.acm.org/citation.cfm?id=158632"}