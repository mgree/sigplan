{"article_publication_date": "03-01-1993", "fulltext": "\n Differential Logic Programming * A. Bossi M. Bugliesi Dipartimento di Matematica P&#38;A University \ndi Padova Via Belzoni 7, 35131 Padova, Italy {micheleQblues,bossiQpdmat 1}.unipd.it Abstract In this \npaper we define a compositional semantics for a generalized composition operator on logic programs. Static \nand dynamic inheritance as well as composition by union of clauses can all be obtained by specializing \nthe general operator. The semantics is based on the notion of difieren tial programs, logic programs \nanno\u00ad tated with declarations that establish the programs external interfaces.  1 Introduction The power \nof Horn clause logic as a programming lan\u00adguage waa pointed out for the first time in [16] and since \nthen it has gained the interest of a still growing research community. The most appealing features of \nlogic programming a8 a programming language are to be found both in the elegance of its semantic char\u00adacterization \nand in the declarativity of its computa\u00adtional model. As best summarized by Zaniolo in [31], the rule \nbased reasoning of logic, combined with ade\u00adquate tools for efficiently storing and retrieving large \namounts of information could provide a realistic basis for the development of efficient knowledge base \nsys\u00adtems. As a matter of fact, its use in the development of knowledge base applications has promptly \ndisclosed one major weakness of Horn clause logic as a program\u00adming language. In fact, in spite of its \ndeclarativity, logic programming turns out not to scale very well when it comes to designing practical \napplications. Its *ThhJ work has been supported by Progetto Finalizzato Sis\u00adtemi Infonuatici e Calcolo \nParallelo of C.N.R. under grant n. 91 OO88O.PF69 and by the Esprit Bazic Research Action 3012-Compulog \nPermission to copy without fee all or part of this material is granted provided that the copies are not \nmsde or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission of the Association for Computing \nMachinery. To copy otherwise, or to republish, requires a fee and/or specific permission. ACM-20th PoPL-1/93-S.C., \nUSA 01993 ACM 0-89791 -561 - 519310001 /0359 . ..$1.50 M. Gabbrielli G. Levi M. C. Meo Dipartimento di \nInformatica Universit~ di Piss, Corso Italia 40, 56100 Piss, Italy {gabbri,levi,meo} @di.unipi.it unit \nof abstraction relations appears to be too fine grained to support the development and the mainte\u00adnance \nof large programs. This need for a more structured approach to soft\u00adware development has motivated a \nwide research ef\u00adfort in the logic programming community during the last decade. Inspired to the experience \ngained in re\u00adlated fields, several approaches have been taken and different solutions have been proposed \nin the recent literature. One of the currently moat promising direc\u00adtions in this area, is based on the \nidea of integrating into a logical framework some of the distinguishing no\u00adtions of the Object-Oriented \nprogramming paradigm: abstraction and inheritance (late binding). From a logical point of view, an object \n the O\u00ad0 unit of abstraction has a natural interpretation as a logic theory: an object is simply a collection \nof axioms which describe what is true about the object itself. Under this assumption, the design of a \ncoherent semantic model for a logic language extended to incor\u00adporate the notion of inheritance can be \nattempted at different levels. At the operational level, it amounts to defining a new inference system \nwhich combines this mechanism with the deductive process of resolution. At the declarative level, it \nrises two interesting is\u00adsues: firstly the problem of characterizing inheritance in terms of the standard \nnotions of satisfiability and truth found in classical logic; secondly, the problem of capturing the \ncompositional properties inherent in the incremental approach to software development en\u00adtailed by inheritance. \nInheritance. Our view of inheritance conforms with the one nowadays widely accepted in the Object-Oriented \ncommunity. An intuitive justification for such interpretation is contained in [7]. Inheritance ia viewed \naa a mechanism for differential programming, i.e. a mechanism for constructing new program com\u00adponents \nby specifying how they differ from the ex\u00adisting ones. Differential programming is achieved by using \nfilters to modify the external behaviour of exist\u00ading components. Accordingly, a modified veraion of \na component is obtained by defining a new component that performs some special operations and possibly \ncalls the original one. This idea is illustrated by the following example. Example 1.1 Consider the \nfollowing dejinations:   oA ey- CLASS student whoAmI = print( (aStudent ) whoAreYou = SELF : whoAml \nCLASS es-student INHERIT student whoAml = print( aCsStudent ) aSt udent := NEW student anotherStudent \n:= NEW es-student We have two classes, student and es-student, imd two corresponding instances. Class \nes-student is a subclass of student and redefines one of ii?s superclass methods. The invocation NEW \nclass returns an instance of class whereas the expression object : message denotes the request for object \nto execute the method associated wdh message. We are interested in the answers to the two following message-sents. \n(a) aStudent : WhoAreYou. (b) anotherStudent : WhoAreYou.  The result of evaluating (a) is straightforward. \nThe message is sent to aStudent and the answer is: a Student . Case (b) is more interesting. Now the \nresult de\u00adpends on what the self-reference SELF refers to. We have two choices and two corresponding \nanswers. The first as to interpret SELF as the object in which the self-reference occurs: aStudent. The \ncorresponding answer, exemplified in figure 11 shows that the modzji\u00adcation csStudent only partially \naffects the external be\u00adhaviour of the the original component students. Whai ho re ~. aStudent Figure \n1: Naive interpretation of Self we actually expect here is that SELF refers to the con)\u00adposite object \nobtained by applying the modzjication to the original component. This is achieved through the interpretation \nillustrated an figure 2. Figure 2 also provides a justification for inheritance as a mechanism for deriving \nmodified versions of recur\u00adsive structures. This characterization constitutes the main motiva\u00adtion to \nCook s approach in [7]. In an independent aCsStudent Figure 2: Correct Interpretation of Self study [27], \nReddy adopts a similar approach and de\u00advelops an incremental study of different forms of in\u00adheritance \nwhere the interpretation given by figure 2 is classified as dynamic inheritance a la Smalltalk [15] \n-as opposed to the static mechanism exhibited by languages like Simula-67 and depicted in figure 1. The \napproach we take in this paper follows Reddy s classification. Compositionality. The adequacy of a semantic \ncharacterization for a language is typically measured on the account of how effective the semantics is \nfor defining the meaning for programs written in the lan\u00adguage. More generally though, in view of a modular \napproach to program development, the semantics of a language should actually aim at characterizing the \nmeaning of program fragments rather than of simple programs. This is in fact crucial to be able to define \nthe meaning of a composite program on the account of the meaning of its components. A semantics with \nthese properties is said to be homomorphic or compo\u00adsitional. More precisely, we say that the semantics \n[.] is compositional with respect to a composition oper\u00adation o if, given two program components C and \nD, the relation [Co D] = [Cl a(o) [D] holds for a suit\u00adable choice of the homomorphism a which maps the \nsyntactic operator o onto the corresponding semantic operator a(o). In the context of a hierarchical \ncompo\u00adsition of program based on inheritance, a natural in\u00adterpretation of the above relation is that \nD is a given hierarchy, C is a new component and o is the special\u00adization operator. Therefore, the hierarchical \ncompo\u00adsition Cn o C2 o Cl should be understood as the sequence of compositions Cn o (. . . (C2 o Cl) \n. . .), or equivalently, o is to be thought of as right-associative. Outline of the paper. The purpose \nof this paper is to make a contribution towards the integration of Object-Orientation and logic programming. \nThe ap\u00adproach we follow enables results in two major out\u00adcomes. The first is generality: we introduce \na gener\u00adalized composition operator on logic programs which captures the semantics of several specialized \nmecha\u00adnisms such as static and dynamic inheritance as well as composition by union of clauses. The second \nis compositionality: programs are looked at as indepen\u00addent fragments to be combined to form larger pro\u00adgrams \nand, dually, the semantics of a composite pro\u00adgram is obtained by combining the semantics of its components. \n The approach is based on the notion of cfifferen\u00adtial programs, logic programs annotated in order to \nmake their external interfaces explicit. The seman\u00adtic characterization is defined following the general \napproach described in [11]. In that paper, the idea is to accommodate in the programs interpretations \nmore syntactic objects in order to achieve an accurate declarative characterization of the programs opera\u00adtional \nbehaviour. Along the same guidelines, here we introduce the notion of context-sensitive interpret a\u00adtions \n(es-interpretations) which enables us to achieve the compositional property we are looking for. The rest \nof the paper is organized as follows. In sec\u00adtion 2 we introduce the idea of differential programs and \nthe associated composition operator. In section 3, we define the declarative semantics for differential \npro\u00adgrams and show its compositional properties. Finally in section 4 we discuss the relation of our \napproach with the existing literature in the field. 2 Differential Logic Programs A differential program \nis a program P annotated by three sets of exported predicate symbols: X: statically inherited predicates \n(E-predicates); A: dynamically inherited predicates (A-predicates); ~: extensible predicates (~-predicates). \nWe assume the three sets are mutually disjoint, and their union is contained in the set 7(P) of the pred\u00ad \nicate symbols occurring in P. The remaining predi\u00adcates, ~(~) \\ (E U A U @) will be henceforth referred \nto as internal predicates and denoted with L(P). We assume that the symbols for internal predicates range \nover an alphabet 3 which is disjoint from the alpha\u00adbets used for E, A and @ predicates. For any pro\u00adgram \nwe also define the set K(P) of the predicates defined in P (p is defined in P if there exists a clause \nin P whose head s predicate symbol is p) and the set Open(P) = (Z\\ K(P)) UAUE1. The qualification Open \nis used here to emphasize that the definition for these predicates can be modified by composing P with \nother programs. This is not the case for internal predicates and, as explained below, for static predicates \ndefined in P. Statically and dynamically inherited predicates are evaluated according to an overriding \nsemantics. The distinction between the two sets S and A reflects the distinction between two different \nforms of inheritance we would like to coexist. The idea is that a program P is to be understood as part \nof a structured context of the form C isa P isa D and that the evaluation of a goal depends on the annotation \nof its predicate symbol. A ~-predicate is evaluated in P using P s local definition or any definition \ninherited from the context D. The local definition, if there is any, overrides the inherited one. Hence, \nany occurrence in P of a goal for a static predicate which is also defined in P, is bound to the local \ndefinition independently of the context in which P occurs. Conversely, the evaluation of A-predicate \nin P uses the local definition or the inherited one, only if no definition for the same predicate name \nis provided by the context C. If C does provide a definition, than this definition overrides in P the \nlocal or inherited one. The annotation @ models an orthogonal composi\u00adtion mechanism defined with an \nextension semantics whereby local definitions are extended with inherited ones. Therefore, the definition \nof a ~-predicate in P can be extended (not overridden) with the definition ofCand ofD. 2.1 Isa-hierarchies \nof Programs \\Ve can make this informal description precise by for\u00admally defining the rules for evaluating \na goal in a generic isa-hierarchy of differential programs. Let HP be the hierarchy Pn isa Pn -1 isa \n. . . isa PI. It follows from the previous discussion that the evaluation of a goal in HP is well defined \nif and only if every predicate symbol occurring in the Pis has a unique identity in terms of membership \nto the corresponding annotations Y~s, A;s and ~~s. The following condition ensures this property. Definition \n2.1 (compatibility) Let (Ep, AP, @P)-P and (EQ, AQ, @Q)-Q be two differ\u00ad ential programs. P and Q are \nsaid to be compatible provided that the following condttion holds: ~(p) fi T(Q) = (ZP o ~Q) U(~P n @Q) \nU(AP n AQ) u (L(P) n L(Q)). We will henceforth consider only hierarchies of com\u00adpatible programs and \ndefine the evaluation of goals whose predicate symbols are exported by at least one of the component \nprograms. Internal predicates are thus thought of as encapsulated within the compo\u00adnents and hence their \ndefinition not is exported by the hierarchies. The evaluation rules are given below in Natural Deduction \nstyle extending those reported in [5]. If G is a conjunctive goal, then evaluating G in HP amounts to \nevaluating in HP each of the conjuncts. Namely: HP FeG1 HP t. G# HP too Gl, G2 If G is an atomic goal, \nsay p(t), then the first step con\u00adsists of selecting in the hierarchy a component which provides a clause \nfor p. Formally: Pk, HP t-. p(t) HP l-o p(t)  The annotation for the predicate p determines differ\u00adent \nways of selecting the compone-nt pk. Namely: (1) p c U,(EP, UAP,) + k = max{j I p E K(Pj)} (2) p e Ui(ep,) \nak~{jlpGx(Pj)}  The relation Pj, HP !-8 G is defined similarly, the main difference being that, together \nwith the choice of the component pk, it entails the selection of a match\u00ading clause for the selected \natom in the goal. The case for conjunctive goals again splits the evaluation on each of the conjuncts: \npj, HP keGI PjJHP koGzg Pj, HP keo G1, G2 The case for atomic goals defines the main step: Pk, HP i-a \nGO (6 = rngu(p(t), p(~)) &#38; C c P~) Pj, HP t-e. ~(t)  Here C = I@: -G, 6 = rngu(p(t), p(~)) and pk \nis cho\u00adsen according to one of the following conditions (l ) pE 2P, &#38; k= max {i < j IPi defines p} \n(2 ) Pc AP, &#38; k= maz {i < n IPi defines p} (3 ) pe@pj &#38; kE{i IPi defines p} (4 ) PE ~(Pj) &#38; \nk=~ Remarks. (l ) and (2 ) (and similarly (1) and (2)) formalize the overriding semantics of X-and A\u00adpredicates. \nFor A-predicates, the search for a match\u00ading clause for p(t) stops at pk, the first compo\u00adnent in a left-to-right \nscan of HP which defines p. For Z-predicates the search ignores the components Pj~~..P~. The operational \nsemantics of the isa-composition can be finally defined in terms of the above rules as fol\u00adlows. Call \nisa-proof for G in HP a proof-tree rooted at HP l-. G whose internal nodes are instances of one of the \nabove inference rules and whose leaf nodes are labelled by HP !-, D or by Pj, HP I-C 0 (n denotes the \nempty goal and ~ the empty substitution). Then, the evaluation of G in HP yields the substitution 9 iff \nthere exists an isa-proof for HP Fe G.  2.2 Syntactic Program Composition The operational semantics \nof isa-hierarchies of dif\u00adferential programs has an alternative and equivalent characterization in terms \nof the semantics of a gen\u00aderalized composition operator d whose definition can be given in a purely \nsyntactic fashion. The defini\u00adtion of ~-composition provides the link between the compositional semantics \nfor differential programs in\u00adtroduced in section 3 and the operational semantics defined in terms of \nisa-proofs. As discussed in the in\u00adtroduction, the syntactic operator q is right associa\u00adtive and thus \nthe hierarchical composition P. 4 P.-1~ ... ~ PI is interpreted as P~ a (P~ 1 d ~.. ~ PI). Let s first \nintroduce a little notation and terminol\u00adogy. For any (non atomic) goal G, Pred(G) stands for the set \nof predicate symbols of the atoms occur\u00adring in G, W! also denote with B a conjunction of atoms, with \nX tuple of variables and and with dlv the restriction of the substitution U to the set of vari\u00adables \nV. Finally, we assume the reader familiar with the standard notions of logic programming reported in \n[20] and [1]. The definition of ~ -composition is based on the fol\u00adlowing notion of renaming. Definition \n2.2 (renaming) Let II and 17, r ~ II, be two sets of predicate symbols. We denote with @p,n a faintly \nof functions which rename any predicate symbol ~n 17 wath a new internal predicate symbol which does \nnot belong to II. If~ E @,H, then Now let ~ G @r,n and P be a program such that n(P) ~ II. We abuse the \nnotation and write @r(P) to denote the program obtained by applying the renam\u00ad ing ~ c @r,n to all the \npredicate symbols occurring in P. Definition 2.3 (syntactic composition) Let (~P, AP, ~~)-p and (~Q, \nAQ, @Q)-Q be two differ\u00adential programs. The composition P d Q is defined provtded that the two programs \nare compatible in the sense of definition 2.1. P d Q is the differential pro\u00adgram (E, A, @)-(P U 4r(Q \n)) where P{, Q and ~r are defined respectively as Pred(fl) n ~Q G k(Q) &#38; }Q ={h:-~EQ Precl(h) @ AQ \nn K(P) h E Qr,n r = (8Q n K(P)) U (L(P) n L(Q)) II = T(P) u T(Q) and the annotation (E, A, ~)-is computed \naccording to the foilowing definitions: Some explanations are needed at this point. P d Q is ferenta \nai programs: obtained by taking the union of a subset of P and of a renamed subset of Q. Let s first \nconcentrate on the subsetting operations. Recall that our basic assump\u00adtion on the isa-and ~-compositions \nis that they are right associative. Then, we may safely assume that (P d Q) is not going to be furtherly \ncomposed into a hierarchy of the form (P a Q) d H, Now consider a predicate symbol p c 2P. If p is not \ndefined ei\u00adther in P or Q, then the clauses of P whose bodies contain a goal G with Pred(G) = p will \nnever be se\u00adlected by any successful isa-proof for the hierarchy P isa Q. Correspondingly, all such clauses \nare deleted from the composition P to obtain P . The same ar\u00adgument motivates the corresponding condition \non Q . From Q, we also remove the clauses which define predi\u00adcate symbols in AQ which are also defined \nby P. This provides the syntactic counterpart of the overriding semantics which we assume for A-predicates \nin the isa-composit ion. As for the renaming, it is performed in order to avoid name clashes for static \nand internal predicates. Internal predicates are assumed to be not visible from the context, hence the \nrenaming for predicates in L(P) n L(Q). Consider then the static predicates of Q. We rename the occurrences \nof a predicate p in Q whenever p ~ ~Q rl K(P). There are two reasons for this choice. On one side, since \np is static in Q, any predicate call for p in Q should refer to the orig\u00adinal definition of p local to \nQ also in the composition P ~ Q. On the other side, the clauses which define p in Q must be distinguished \nfrom the definition of p already existing in P (since we assume an overriding semantics). All the renamed \npredicates in Q become internal predicates for the composition P a Q, and if the composition is defined, \nno other clash can arise between two predicate names of P and Q. Further\u00admore, since the internal predicate \nsymbols generated via renaming range over S, any new program R com\u00adpatible with P and Q, will be also \ncompatible with P d Q. Hence, the composition operators a and isa are defined in the exact same cases. \nA final remark concerns the annotations X, A and @ for the composition. The subsetting operations on \nthe component programs, might modify the set of predicate symbols occurring in P and Q. Hence, the new \nannotation is obtained taking the union of EP, AP and ~P respectively with EQ, AQ and t3Q and then intersecting \nthe resulting components with the set T(P U Q1). This is in fact equivalent to taking the intersection \nwith n(P CI Q). s(z) : -q(z) q(a) P= r(c) t(b) { s(z): -r(z) h(x) : -t(x) Q. r(a): -q(x) s(a) { h(a)q($) \n: -h(~) R= r(b) s(z) : -t(z) { where 2P ={q,t}, ZQ=XR={h,q,t}, AP =AQ = AR = {r} and @p = @Q= @R= {s}. \nWe compute the composition P ~ Q < R in two steps (recall that d is right-associative). s(x) : -?-(z) \n9(Z) :+% ($)Q4R= r(a): -q(z) h+, (a)s(a) { The two clauses h(z): -t(z) c Q and s(z): -t(z)have been \ndeleted because t @ K(Q U R); the clause r(b) G R because r E AR n K(Q). The renaming CJ!J1G The new \nannotation for Q d R is given ~~h! ! ~~~~t~ = {r} and 63 = {.s}. Composing P on the Q d R yields the \nnew program ( s(z): -q(z) s(z): -r(x) r(c) Pd(Qd R) = q(a) t(b)[ where the renaming dz E @iq],~q,$,,,t,h~l} \nand the final annotation is Z = {q, t}, A = {r} and @ = {s}. We mentioned earlier in this section that \n~ provides an alternative and equivalent characterization for the isa-composition. This equivalence follows \nfrom the tight correspondence existing between isa-proofs and successful SLD-derivations. We can in fact \nestablish a one-to-one mapping between the steps of a successful SLD derivation in any d-composition \nand of a corre\u00adsponding isa-proof for the associate isa-hierarchy by exploiting the properties of the \nrenamings. Let #l, . . . on be the renamings applied in the con\u00ad struction of the hierarchy HPd = Pn \n4 . . .4 PI (dj is applied when the hierarchy Pj d . . . ~ PI is extended with Pj+l). Let now ~j be defined \nas the composition where (@l o @z)(p) = q52(I#1(p)). It can be verified that the following properties \nhold true: ifp c 12Pj andp~ T(Pj 4 ...4 PI), then for any i >j, ifp~AP, U@p, andpc~(Pj4. ..4 Pi), Example \n2.4 Let P, Q and R be the following dtf-then @j (p) = p. The following property for the composition i7P4 \nfol\u00adlows from the above properties of the renamings and from the definition of a-composition. Notice, \nthat, if c is a clause of one of the components, say Pj and it contains an occurrence of a predicate \np such that p$zm(Pj 4... ~ PI), then neither c nor +j (c) be\u00adlong to HP.. Let then c = h: -B, be a clause \nin Pj. The renamed clause ~j (c) belongs to HP. iff the two following conditions hold: if b is a conjunct \nof ~ such that Pred(b) E Z~,, then Pred(b) belongs to K(Pj~ . ..4 PI). if Pred(h) 6 AP, then Pred(h) \nin not de\u00ad fined in any P1 with 1> j; Let now HP = Pn isa Pn _1 isa ... isa P1 denote the isa-hierarchy \ncorresponding to HP4 = P. ~ . . . d PI. Let also G Lp fi denote an SLD-derivation of &#38; from G in \nP (under any selection rule) with answer substi\u00ad tution L9. Lemma 2.5 Let G be a (non atomic) goal with \nPred(G) ~ ~(Pj) . Pj, HP Fe G = @j(G) HP. 0 and ~ = dlv~r(G). Proof. The proof follows by induction \non the number of inference steps in the isa-proof and the length of the SLD-derivation using the above \nproperties of renan~\u00adings and deletion and noting that if a clause c E PJ is selected in a successful \nisa-proof than +j (c) E HP.. 0 Theorem 2.6 Let HP be an isa-hterarchy and HP. = P. ~ . . . d P1 be the \ncorresponding (2, A, @)-differential program. Then for any goal G such that Pred(G) ~ (X UAU@): HP EOG \n~ G -?+Hpq 0 and 7 = d]var(G), Proof. For G atomic: HPt-OA 6 Pk,HPk@ A (lemma 2.5) ~ @~(A) ~Hpa 0 Now \nA ~Hp~ 0 follows by the properties of the re\u00adnaming ok since Pred(A) e K(Pk) and for any / > k, Pred(A) \n# K(Pk) and hence @k(A) = A. In the general case of conjunctive goals the proof follows immediately by \ninduction. 0 The proof highlights one important property of the renamings used in the ~-composition, \nnamely that the renamings preserve the predicates exported by the corresponding isa-composition. Hence, \nthe (Z, A, @)-differential program HP. and the corre\u00adsponding isa-hierarchy HP prove exactly the same \ngoals G provided that Pred(G) ~ (Z U A U ~). Note that this condition is equivalent to assume that Pred(G) \ndoes not contain internal predicates. In fact if p E Pred(G) is not internal and p @ (2I U A U ~), then \nG fails both in the hierarchy HP and in the cor\u00adresponding program HP<.  3 A semantics compositional \nwrt 4 The approach we follow towards a compositional se\u00admantics for the composition operator ~ is based \non an extension of the semantics for open logic programs de\u00adfined in [3] and [2]. The extension had been \nmotivated by the fact that the standard approach to the seman\u00adtics of logic programming provides an elegant \nway of defining the meaning of programs but lacks an impor\u00adtant compositionality property. The minimal \nmodel semantics ([29]) is in fact concerned only with AND\u00adcomposition (of atoms in a goal or in a clause \nbody) but is not compositional with respect to one of the most primitive composition operations the \nunion of clauses which is at the basis of the very same idea of modularity in logic programming. Let \ns consider an example. M(P) denotes the standard least Herbrand model semantics of P. Example 3.1 Let \nPI = {r(a)} and Pz = {P(X) :-r(X), r(b)}be two programs. The semantics of the unzon M(P1 U P2) = {p(a), \np(b), r(a), r(b)} can\u00adnot be obtained from the semantics of PI and P2, since .lf(Pl) = {r(a)} and M(PZ) \n= {p(b), r(b)}. Obviously the minimal-model semantics is also non\u00adcompositional with respect to more \ncomplex operators like our inheritance mechanisms. The same argument applies to also other semantics, \nsuch as those reported in [9] and [10], which are defined on sets of (possibly non ground) atoms. As \na matter of fact, in order for a semantics to be compositional, it is crucial that its definition embeds \na mapping from sets of atoms to sets of atoms. This is the case for the semantics based on the closure \noperator of [17] and on the TP operator ( [22]). If we want a semantics expressed within pro\u00ad gram syntax, \ncompositionality with respect to union of programs can be equivalently achieved by choosing sets of clauses \nas the semantic objects used to interpret our programs. This idea is at the basis of the open semantics \npro\u00adposed in [3] and [2] and similarly of the semantics de\u00ad fined in [12]. Roughly, the open semantics \nS(P) of a program P, is given by the set ~f resultants [21] ob\u00adt ained from goals of the form p(X) in \nP. Namely S(P) = {p(l)o:-s I 329 St. p(x) &#38;p B} Under this definition, the semantics of program \nP2 of example 3.1, is given by the set S(PZ) = {P(x) :-~(x), r(b), p(b)}. The above characterization \nof the semantic domain induces the following compositional definition of the semantics of the union of \ntwo programs ([2]): S(PI u PJ = $(S(PI) u i$(PJ) However, this definition is not adequate to model the \ntype of program composition we are considering. Let s consider an example. Example 3.2 Let (Xl, Al, @l)-PI \nand (~z, Az, @z)-Pz be the programs dejined in example 3.1, assuming Al = {r}, AZ = {r, p} and%=@ = 0 \nfor i = 1,2. The composition PI 4 Pz corresponds to the program {r(a), p(X): -r(X) }where the clause \nr(b) E P2 has been overriden by the clause r(a) G PI. NOW, if we apply the previous definition, we obtain \nS(P1 U Pz) = {r(b), p(b), r(a), p(a), p(X): -r(X)}. Notice that to obtain the semantics of PI a P2, from \nS(P1 U P2) we should delete from S(PI U Pa), not only r(b), which is an obvious consequence of the overriding \nsemantics of ~, but also everything derived from r(b) (p(b) in this case). This is because r is defined \nin P,. Thus, when defining the semantics of P2, we need a mechanism for recording that p(b) haa been \nobtained by using the definition of the A-predicate r, local to P2, which could be overridden by the \ncontext. This is achieved by introducing the following notion of context sensitive clause as element \nof the semantic domain. Definition 3.3 A context sensitive clause (cS-clause) is an object of the form \n(1) A:-{917... )9n}n~l, ~k., ~k where ql, ..., qn are predicate symbols. The intuitive meaning of (1) \nis that the logical impli\u00adcation A+ B1, ..., Bk is true in any context which does not override the definitions \nof ql, . . . . qn. A context sensitive interpretation is defined in terms of equivalence classes of es-clauses \nas follows. Say that two es-clauses c1 = HI : sO~l and C2 = H2 : su&#38; are equivalent (cl % C2) iff, \nconsidering the ~i s as multisets, c1 and C2 are equal up to renaming. Definition 3.4 (es-interpretation) \nLet CA be the set of all the =-equivalence classes of es-clauses A: -s 0 B such that s ~ A, An interpretation \nI for a (~, A, @)-program P a s any ~ ~ Cd. In the following we denote the ~-equivalence class of a es-clause \nc by c itself and we also consider any program clause H: -B1, . . . . Bh as the es-clause H:-{} 0B1, \n. . . . B~. Therefore any program is viewed equivalently as a es-interpretation. Abusing the nota\u00ad tion, \nwe will also identify synt attic operators on cs\u00ad clauses with (semantic) operators on CA. The repre\u00ad \nsentatives of the equivalence classes contained in CA will be assumed be renamed apart. This is consistent \nwith the definition of the semantic operators which are given independently of choice of representative \nel\u00ad ements of equivalence classes. The previous definitions for programs (such as Open(P), L(P) etc.) \nare finally implicitly extended to apply to es-interpretations. We now introduce an unfolding operator \nfor (X, A, El)-programs. The operator preserves the op\u00aderational behavior of programs with respect to \ncom\u00adputed answers. Therefore it can be used as the basic transformation on programs to define a fixpoint \nse\u00admantics compositional with respect to d and correct with respect to computed answers. The same operator \nprovides also the basis for directly defining an equiva\u00adlent unjolding semantics which is obtained as \nthe limit oft he top-down infinite unfolding process. As we show below, the unfolding semantics can be \nused as an in\u00adtermediate step to prove the equivalence between the operational semantics of an isa hierarchy \nHP and the fixpoint semantics of the corresponding HP. program. To simplify the notation, in the following \nwe will omit the prefix (Z, A, ~) when no ambiguity arises. Given a set of predicate symbols ~, by Idv \nwe denote the set of es-clauses: {p(i~): -{} 0 p(~) I p c W and ~ distinct variables} Definition 3.5 \n(unfolding,) Let P, I be cs-mierpretations for (E, A, @)-programs. The es-unfolding unfP(I) of P with \nrespect to I is the set of es-clauses defined as: unfp (1) = {AO:-SU C{... UC~O(il, ~~)O~~)O I A:-s \nUBl,. ... B~CP, cli=B~:_CiU~i~I, i=l, . . ..k. O=rngu((Bl,. ... B~), (B{, B\\)),\\)), C( _ Ci if C!i 6 \nIdOPen(P) or Pred(Bi) @ A % Ci U {Pred(Bi)} otherwise } The intuition is that whenever we unfold an \natom Bi, we add Pred(Bi) to the constraints of the unfolded cs\u00adclause if and only if Pred(Bi ) is a A-predicate \n(and the clause used to unfold is not in Id. pen(~)). Therefore the set of es-clauses returned by the \nes-unfolding of P with respect to 1 is a es-interpretation for (Z, A, @)\u00adprograrns. The fixpoint semantics \nof differential programs is given terms of an immediate-consequence operator for es-interpretations, \nand this, in turn, can be simply defined in terms of unfolding as follows. Recall that for a (Z, A, @)-program \nP, Open(P) = (Z\\ K(P)) U ~ U ~. The set ~dop..(p) is used in the following definition to ensure that \nthe es-clauses whose bodies contain only open predicates are not excluded from T;(1) (and thus from the \nfixpoint semantics). As we will show in subsection 3.2, this allows us to achieve compositionality with \nrespect to 4. Definition 3.6 Let P be a (Z, A, @)-progmm and let I be a es-interpretation for P. Then \nwe define T (l) = unfp(l U ldOP.n(PJ). Proposition 3.7 T; is monotonic and continuous on the complete \nlattice (CA, ~). The notion of ordinal powers for T? is defined as usual, namely T~ TO = 0, T~ Tn+l = \nTj?( TjY tn ) and T~ tw = (Jn>o ( T~ tn ). Since T~ is continuous on (CA, <), well Known results of lattice \ntheory allow to prove proposition 3.9 and then to define the fixpoint semantics as follows. Proposition \n3.8 T~ Tw is the least jixpoint of on the complete lattice (CA, ~). Definition 3.9 Let P be a (Z, A, \n@)-program. jixpoint semantics [P] of P is defined as follows: [P] = T~ ~w \\ {H :-sUfi IPred(H) c L(P)} \nNote that the [P] semantics can be considered as a differential program. As such, according to the definition \nof differential programs, the (E , A , @ a\u00adnnotation of [P] is obtained by intersecting the orig\u00adinal \n(Z, A, @)-annotation of program P with the set T( [P]) of predicates occurring in the semantics. More\u00adover, \nsince the predicates L(P) (i.e. the predicates not in 2 U A U @) are considered internal to the pro\u00adgram, \nthe clauses which define such predicates are not included in the semantics. Note also that if H: -s 0 \nBody E [P] then Pred(l?ody) ~ Open(P). This is coherent with the fact that clauses in the se\u00admantics \nare needed to capture other possible defini\u00adtions only for open predicates. Example 3.10 The semantics \nof programs intro\u00ad duced in example 2 .4 are the following [P] = { s(a): -{}U 7 (C) :-{}0 q(a): t(b): \n-{}lZ -{}o s(x) :-{} CL7 (Z) h(z): -{}clt(z) s(a) :-{r}Oq(z) s(a) :-{}0 r(a) :-{} Clg(z) [Q] = { q(a):-{}U \nr(b):-{}0 [R] ={ h(cl):-{}o S(z): -{}nt(z) According to the es-clause s(a): -{r} tlq(z), the im\u00adplication \ns(a) a g(z) holds true aa long as the con\u00adtext in which Q occurs does not override the def\u00adinition for \nr local to Q. Assume now that Q oc\u00adcurs in the context P ~ Q where P s definition of r is the unit clause \nr(c). Then obviously the new definition overrides clause r(a): -{} 0q(x) thus inval\u00adidating the constrained \nimplication entailed by clause S(a) :-{r}nq(z). 3.1 Unfolding semantics and equiva\u00ad lence results The \nequivalence between the operational semantics of an isa hierarchy HP and the fixpoint semantics of the \ncorresponding HPq can be proved in a concise and el\u00adegant way by introducing the intermediate notion \nof unfoidmg semantics U(P) [18,19,8]. The unfolding se\u00admantics is obtained as the limit of the top-down \nun\u00adfolding process. Definition 3.11 Let P be a (E, A, @)-program. Then we define the collection of es-interpretations \nPI=P Pn+l = unf~m (P U IdOPen(PJ) The unfoldzng semantics U(P] of the program P is defined as u(p) = \nu / Jopen(P)(p7z) n=l)2, (L,herej for any T and Q, Pred(B) ~ n, Pred(h) @ L(P) } Pz(Q) = {h:-s@ c Q I \nThe equivalence between the unfolding and the fLx\u00adpoint semantics follows by first noticing that they \nare based on the same operator (applied respectively bottom-up and top-down). Then by observing also \nthat the unfolding operator is associative, i.e for any three es-interpretations P, Q and R} unfP(unfQ(R)) \n= unfp(unfQ(R)), we can prove the equality T~ ~ n ~Ope.(P) (p.) and hence the next theorem. Theorem 3.12 \nLet P be a program. Then [P] = U(P). We now prove the adequacy of the [P] fixpoint seman\u00ad tics with respect \nto the operational semantics defined in terms of isa-proofs. This is accomplished in two steps. We first \nshow (see theorem 3.13 below), that the U(P) semantics correctly models the answer\u00adsubstitution semantics \nof the ~-syntactic composi\u00adtion. In view of theorem 3.12, the same property holds for [P]. Theorem 3.13 \nLet P be a (Z, A, @)-program and let G= Al,..., A~ be a goal with Pred(G) ~ (XUAUO). Then  G%pa ~ 3 \nHi: Si OG U(P), i=l, . . ..k. 3-y = rngu((Al,..., Ak)(Hl, Hk))Hk)) ~lvar(G) = ~lv.r(G) The proof of \nthe above result can be carried out by us\u00ading a straightforward inductive argoment, since U(P) is based \non a top-down definition which mimics a par\u00adallel SLD derivation (the proof is essentially the same of \nthose given in [19,8] for the case of standard pro\u00adgrams). Then, the desired equivalence can be stated \nin terms of the following Theorem 3.14 Let HP be an isa-hierarchy, HPq be the corresponding (Z, A, @l)-program \nand G = Al, ..., Ab be a goal with Pred(G) ~ (E U A U ~). Then: HPFOG ~ 3Hi: si 0~[HPd], i=l,..., k, \n3-/ = rngu((Al,..., Ak)(Hl, Hk)),k)), ? 1.ar(G) = ~lva,(G). Proof Immediate from theorems 2.6, 3.13 \nand 3.12. 1 As a further corollary, we can prove that semantic equality between ~-hierarchies implies \nsameness of answer substitutions on isa-hierarchies. Call wi~a the observational equivalence, based on \nanswer substitu\u00adtions, for isa-hierarchies: HP 1-$ G iff HP t-o, G HP mi~a HP u where ~luar(G) = ~o~~(G) \nCorollary 3.15 Let HP and HP1 be isa-hierarchies and let HP. and HP: be the corresponding (Z, A, @)\u00adprogranw. \nThen: 3.2 Compositionality We show now the compositionality of the [P] wrt a. As a consequence, using \nprevious theorems we can ob\u00adtain the main result of the paper which shows that the operational semantics \nof an hierarchy F n isa Pn _ 1 ka ... isa PI can be obtained compositionally from the semantics [Pi] \nof the components of the hierarchy. We first introduce a semantic operation + on cs\u00adinterpretations which \ncorresponds to the syntactic composition ~ of differential programs. Also in this case, the operator \n+ is considered to be right\u00adassociative. Definition 3.16 Let (Ep, Ap, @p)-P and (ZQ, A~, @~)-Q be compatible \ndifferential programs and let Ip = [Pj, IQ = [Q]. We define the semantic composition Ip + IQ = [1$ U \n1~] where SnK(p) = 0,p?d(~) n~Q = f) Pred(A) g K(P) fl (ZQ U AQ)} The definition of IP + IQ is given \nalong the same guidelines of the corresponding definition for the syn\u00adtactic q-composition. The intuition \nis the following. First recall that all the es-clauses in 1P and IQ are the result of the unfolding process \non P and Q. Now, take a es-clause c in 1P which contains an atom b such that Pred(b) belongs to 21P. \nFrom the definition of the fixpoint semantics, it follows that Pred(b) is not clefined by P. Then, if \nIQ does not cent ain any defi\u00adnition for Pred(b), c can be deleted from Ip + IQ. As for the syntactic \ncomposition, the deletetion is safe in this case being a, and hence +, assumed to be right\u00adassociative. \nThe same argument motivates the corresponding condition on 1~. The remaining condition on 1~ pro\u00advide \nthe semantic counterpart of the overriding which occurs at the syntactic level between P and Q. Recall \nthe two programs of example 3.2. We said that to com\u00adpute the semantics of P d Q in a compositional way, \nwe should have deleted from the semantics of Q, not only the definition of the A-predicate r, but also \nev\u00aderything derived in Q using redefinition. The two con\u00additions given above on lb model precisely this \nmech\u00adanism. Note also that [lb U 1~] can be considered a (Z, A, @)-program, where the (E, A, ~) annotation \nis obtained according to the usual restrictions for differ\u00adential programs. Namely, Z = (ZP U ~Q) (l \nx(l&#38; U ~~) and analogously for A and @. The proof of the compositionality theorem can be obtained \nby using the tight relation existing between the syntactic ~-composition of programs and the se\u00admantic \noperation < on es-interpretations. In fact, [P] < [Q]= [1$ U 16] where 1$ and 1~ are obtained respectively \nas subsets of [P] and [Q] according to the conditions given in definition 3.16. Correspondingly, P d \nQ = P U Q where P and Q are obtained re\u00adspectively as a subset of P and as a renamed subset of Q (definition \n2.3). Due to the correspondence between the conditions which define the sets I;, 1~ and P , Q we can \nshow that taking the semantics of 1$ U 1~ is equivalent to taking the semantics of P U Q . Theorem 3.17 \n(compositionality) Let (~~, AP, ~P)-P and (EQ, AQ, @~)-Q be differential programs. Then 4 Related Work \nNote that in the definition of II + IQ we have use also a piece of syntactic information (~(Pi )). This \ncould have been avoided by embedding this information into the semantics ~. Let us show an example of \nthe compositional con\u00adstruction of the semantics. Example 3.18 Let s constder programs Q and R in\u00adtroduced \nin example 2.4 and their respective semantics (example 3.10). From definition 9.16, IQ] < [R] = [l&#38;Ul&#38;] \nwhere l&#38;U1~ is given by the cs-interpretation s(z) :-{} Clr(z) s(a): -{}Ci s(a) :-{r}13q(x) 9(a):-{}D \nr(a) :-{}tlq(z) { Note that, according to definition 316, the clause h(a): -{}0 E [R] does not appear \nin 1~ because the predicate h c ~R is defined in Q. The clause s(z) :-{} et(z) E [R] does not appear-in \nI&#38; because the predicate t c ~R is not dejined in R. Also the clause r(b) :-{}0 E [R] ZS deleted \nsince t E AR and t is defined in Q. Correspondly, [Q 4 R] is the es-interpretation: S(z) :-{}nr(z) s(a) \n:-{}Cl s(a) :-{r}U q(a):-{}0 r(a): -{}0 { Note that, since q is static and defined in Q d R, tn the semantics \nof Q4 R there are no es-clause wzfh q ?n the body. It s easy to verify that the equality [Qd R] = [Q] \n< [R] holds. As the final result, we now show the adequacy of the [P] fixpoint semantics to model compositionally \nthe operational behavior of isa-hierarchies defined in terms of isa-proofs. Theorem 3.19 Let HP= P. isa \n. ~. isa PI be an isa-hierarchy, let HP. be the corresponding (Z, A, @)\u00adprogram and G = A~, . . ..Ak \nbe a goal wdh Pred(G) Q (Z U A U ~). Then HPto Gu fori=l,... jk, 3Hj: Si DE IPl]<... <[P,,], Zly = rngu((Al,..., \nA~)(Hl,. ... H~)) ~lvar(G) = il. ar(G) Proof Immediate from theorem 3.17 and corollary 3.14. 0 Corollary \n3.20 Let HPl and HP2 be two isa\u00adhierarchies and let HP~, HP? be the corresponding (Z, A, @)-programs. \nThen [HP:] = [HP:] a V P, (P isa HPl) $si,a (P isa HP2) The use of the deduction theorem to provide a \nlogical foundation to the theory of modular logic program\u00ad ming was the main motivation behind Miller \ns semi\u00ad nal paper on this subject [23]. His idea was to extend the expressive power of positive horn \nclauses by allow\u00ad ing implications to occur in the bodies of clauses and by interpreting them as follows. \nAn implication goal D 3 G is provable in a program P if G is provable in the extended program P U {D}. \nThe idea of modular\u00adity derives then by observing that, if D is a conjunc\u00adtion of clauses, we can interpret \nthe goal D o G as a scoping construct which requires that the clauses in D be loaded before evaluating \nG and then unloaded after G succeeds or fails. Implication goals as structuring tools are also used in \n[14] following a more static ap\u00adproach. Indeed, the language defined in [14] has static scope rules for \nclause definitions. A semantics based on modal logic for such a language is proprosed in [13]. A modular \nextension to logic programming was also proposed in [28], based on the theory of modular\u00adity developed \nby the Standard ML module system. Abstraction and the ability to define structured com\u00adponents are also \nat the basis of that approach but cross-references between predicate definitions in dif\u00adferent modules \nare achieved only through the explicit use of qualified names. Thus, there is no support for the implicit \ninteraction between different components which is entailed by the composition mechanisms we have considered \nin this paper. An extensive study on the semantics of various forms of composition mechanisms for logic \nprogram\u00adming has also been developed in [4]. In that paper, inheritance systems are viewed as a special \ncase of more general forms of composition mechanisms which are derived as extensions or variations of \nContextual Logic Programming. The approach is rather differ\u00adent, than the one presented in this paper, \nin at least two respects. The first is our use of extended inter\u00adpretations as opposed to the use of \nstandard Herbrand mterpretations in [4]. The second is that the definition of inheritance assumed in \nthat paper is based only on the idea of extension rather than overriding between inherited definitions. \nThis assumption is crucial for the framework presented in [4] to prove the existence of a fixpoint for \nthe immediate consequence operator they define. The same assumption provides also the basis for the compositional \napproach developed by the same authors in a related and more recent paper [5]. Monteiro and Porto s approach \nto the declarative se\u00admantics of Contextual Logic Programming, [24], is also related to our characterization \nof inheritance. One major difference is in the language. In fact, Contex\u00adtual Logic Programming (CXLP) \nhas essentially the same semantic connotation as static inheritance, with the difference that CXLP s \nmechanism for unit com-ture Notes an Computer Science, pages 265-289, position is inherently dynamic. \nIn effect, CXLP S con-Sendai, Japan, 1991. text extension, by providing a mechanism for dynam\u00ad [2] A. \nBossi, M. Gabbrielli, G. Levi, and M. C. Meo. ically specifying (and modifying) a unit s hierarchical \nContributions to the Semantics of Open Logiclinks with its ancestors, captures a more general no-Programs. \nIn Proceedings of the Internationaltion which is known as delegation [30]. In a related Conference on \nFifth Generation Computer Sys\u00adpaper [25] they take a more direct approach to the tems 1992, pages 570-580, \n1992. study of inheritance systems. The notion of inheri\u00adtance they consider in (the bulk of) that paper \nis es\u00ad [3] A. Bossi and M. Menegus. Una Semantica Com\u00ad sentially the same we have assumed here. The \nseman-posizionale per Programmi Logici Aperti. In tic problem is instead approached from a completely \nP. Asirelli, editor, Proc. Sixth Italian Conference different perspective. Their view is strictly transfor\u00ad \non Logic Programming, pages 95 109, 1991. mational. The methodology to capture the meaning [4] A. Brogi, \nE. Lamma, and P. Mello. Structuring of an inheritance system is to transform it into a logic Logic Programs: \nA Unifying Framework and its program to then show the equivalence between the Declarative and Operational \nSemantics. Techni\u00ad respect ive operational semantics. A declarative inter\u00adcal Report 4/1, Progetto Finalizzato \nC.N.R. Sis\u00ad pretation is then derived indirectly on the account of temi Informatici e Calcolo Parallelo, \n1990. the well-known equivalence between the operational and declarative semantics in logic programming. \nA [5] A. Brogi, E. Lamma, and P. Mello. Objects in a refined result is described in [26] where they \nintroduce Logic Programming Framework. In Second Rus\u00ada direct declarative characterization for a composite \nstan Conference on Logic Programming, 1991. language which combines the static and dynamic in\u00adterpretations \nof inheritance as well as the overriding [6] M. Bugliesi. A Declarative View of Inheritance and extension \nmodes between inherited definition we in Logic Programming. In K. Apt, editor, Proc. have considered \nin this paper. There is a fundamental Joznt Int ! Conf. and Symposium on Logic Pro\u00addifference from the \napproach we have presented here: grammmg. The MIT Press, Cambridge, Mass., the semantic construction \nof [26] applies to complete 1992. hierarchies and it is given under the assumption that [7] 1~. Cook \nand J. Palsberg. A Denotational Seman\u00ad the components of the hierarchy are known in advance. tics of \nInheritance and its Correctness. In Pro- As such, the issue of compositionality is not even taken ceedings \nof 00PSLA 89, pages 433-443, ACM, into account. Compositionality is instead one of the 1989. key issues \nin our approach: each differential program is looked at as an independent fragment to be arbitrarily \n[8] F. Denis and J.-P. Delahaye. Unfolding, Proce\u00adcomposed onto any hierarchy. Then the compositional \ndural and Fixpoint Semantics of Logic Programs. properties of our semantics ensure that the meaning In \nC. Choffrut and M. Jantzen, editors, STACS of the resulting hierarchy can be determined from the 91, \nvolume 480 of Lecture Notes in Computer meaning of the components. Science, pages 51 1 522. Springer-Verlag, \nBerlin, A compositional semantics of inheritance is also 1991. given in [6], but different semantic objects \n(the least [9] M. Falaschi, G. Levi, M. Martelli, andHerbrand model and the immediate-consequence op- \n C. Palamidessi. A new Declarative Semantics for erator respectively) are required to coexist there, \nin Logic Languages. In R. A. Kowalski and K. A. order to capture the meaning of static and dynamic Bowen, \neditors, Proc. Fzflh Int 1 Conf. on Logicinheritance. In contrast to that case, the choice of Programmmg, \npages 993 1005. The MIT Press,context-sensitive interpretations, allows us to have a Cambridge, Mass., \n1988. uniform treatment of the two mechanisms. Finally, our approach represents the first attempt to \n[10] M. Falaschi, G. Levi, M. Martelli, and capture, in a compositional fashion, a computational C. Palamidessi. \nDeclarative Modeling of the Op\u00adsemantics of inheritance systems stated in terms of erational Behavior \nof Logic Languages. Theoret\u00adcomputed-answer-substitutions. ical Computer Science, 69(3):289 318, 1989. \n [11] M. Gabbrielli and G. Levi. On the Seman\u00ad tics of Logic Programs. In J. Leach Albert,  References \nB. Monien, and M. Rodriguez-Artalejo, editors, [1] K. R. Apt and D. Pedreschi. Proving Termination Automata, \nLanguages and Prograrnrnmg, l$~h in\u00adof General Prolog Programs. In T. Ito and A .R. ternational Colloquium, \nvolume 510 of Lecture Meyer, editors, Proc. of Int. Conf. on Theoretical Notes tn Computer Science, pages \n1 19. Springer-Aspects of Computer Software, volume 526 of Lec-Verlag, Berlin, 1991. [12] H. Gaifman \nand E. Shapiro. Fully Abstract Com\u00adpositional Semantics for Logic Programs. In Proc. of ACM Conf. on \nPrinciple of Programming Lan\u00ad [25] L. Monteiro and A. Porto. A Transformational View of Inheritance in \nLogic Programming. In Proc. 7th Int. Conf. on Logic Programming, 1990. [26] L. Monteiro and A. Porto. \nSyntactic and Seman\u00adtic Inheritance in Logic Programming, In J. Dar\u00adlington and R. Dietrich, editors, \nProc. PHOENIX Seminar and Workshop on Declarative Program\u00admmg, 1991. [27] U. Reddy. Objects as Closures: \nAbstarct Seman\u00adtics of Object Oriented Languages. In Proc. of the Int, Conf on Lwp and Functional Programming, \npages 289-297. ACM, 1988. [28] D. T. Sannella and L. A. Wallen. A Calcu\u00adlus for the Construction of Modular \nPolog Pro\u00adgrams. Journal of Logic Programming, 6(12):144\u00ad177, 1992. [ 29] h~. H. van Emden and R. A. \nKowalski. The se\u00admantics of predicate logic as a programming lan\u00adguage. Journal of the ACM, 23(4):733-742, \n1976. [30] P. Wegner. Dimensions of Object-Based Lan\u00adguage Design. In Proc. of the 00PSLA 87, 1987. [31] \nC. Zaniolo. Deductive Databases -Theory meets Practice. In Proc. Znd Int. Conf. on Extended Database \nTechnotogyl 1990. guages, 1989. [13] L. Giordano and A. Martelli. A struction of Blocks and Modules gramming. \nIn V. Saraswat and K. Proc. 1991 Int 1 Symposium on ming, pages 239 253, 1991. [14] L. Giordano, A. Martelli, \nand F. Rossi. Local definitions with static scope rules in Logic Lan\u00adguages. In Proc. of the FGCS Int. \nConf., 1988. [15] A. Goldberg and D. Robson. Smalltalk-80: The Language and its Implementation. Addison-Wesley, \n1983. [16] R. Kowalsky. Logic for Problem S. Elsevier North-Holland, 1979. [17] J.-L. Lassez and M. J. \nMaher. Closures and Modal Recon\u00ad in Logic Pro- Ueda, editors, Logic Program- Fairness in the Semantics \nof Programming Theoretical Computer Science, 29:167-184, [18] G. Levi. Models, Unfolding Rules and Semantics. \nIn R. A. Kowalski and K. A. Logic. 1984. Fixpoint Bowen, editors, Proc. Fifth Int 1 Conf. on Logzc Program\u00ad \nming, pages 1649 1665. The MIT Press, Canl\u00ad bridge, Mass., 1988. [19] G. Levi and P. Mancarella. The \nUnfolding Se\u00admantics of Logic Programs. Technical Report TR\u00ad13/88, Dipartimento di Informatica, Universit5 \ndi Piss, 1988. [20] J. W. Lloyd. Foundations of Logic Programming. Springer-Verlag, Berlin, 1987. Second \nedition. [21] J. W. Lloyd and J. C. Shepherdson. Partial Eval\u00aduation in Logic Programming. Journal of \nLogtc Programming, 11:217-242, 1991. [22] P. Mancarella and D. Pedreschi. An Algebra of Logic Programs. \nIn R. A. Kowalski and K. A. Bowen, editors, Proc. Fifth Int 1 Conf. on Logzc Programming, pages 1006 \n1023. The MIT Press, Cambridge, Mass., 1988. [23] D. Miller. A Logical Analysis of Modules in Logic Programming. \nJournal of Logic Programming, 6(2):79-108, 1989. [24] L. Monteiro and A. Porto. Contextual logic pro\u00ad \ngramming. In G. Levi and M. Martelli, edi\u00adtors, Proc. Sixth Int 1 Conf. on Logic Progrant\u00adming, pages \n284 302. The MIT Press, Cambridge, Mass., 1989. 370  \n\t\t\t", "proc_id": "158511", "abstract": "<p>In this paper we define a compositional semantics for a generalized composition operator on logic programs. Static and dynamic inheritance as well as composition by union of clauses can all be obtained by specializing the general operator. The semantics is based on the notion of <italic>differential</italic> programs, logic programs annotated with declarations that establish the programs' external interfaces.</p>", "authors": [{"name": "A. Bossi", "author_profile_id": "81100294137", "affiliation": "", "person_id": "PP31070672", "email_address": "", "orcid_id": ""}, {"name": "M. Bugliesi", "author_profile_id": "81100363070", "affiliation": "", "person_id": "PP31073402", "email_address": "", "orcid_id": ""}, {"name": "M. Gabbrielli", "author_profile_id": "81100230344", "affiliation": "", "person_id": "PP39072083", "email_address": "", "orcid_id": ""}, {"name": "G. Levi", "author_profile_id": "81341493216", "affiliation": "", "person_id": "PP39075128", "email_address": "", "orcid_id": ""}, {"name": "M. C. Meo", "author_profile_id": "81100122202", "affiliation": "", "person_id": "PP33035378", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158689", "year": "1993", "article_id": "158689", "conference": "POPL", "title": "Differential logic programming", "url": "http://dl.acm.org/citation.cfm?id=158689"}