{"article_publication_date": "03-01-1993", "fulltext": "\n Call by Name, Assignment, and the Lambda Calculus Martin Odersky Dan Rabin Paul Hudak Department of \nComputer Science Yale University* Abstract We define an extension of the call-by-name lambda cal\u00adculus \nwith additional constructs and reduction rules that represent mutable variables and assignments. The \nex\u00adtended calculus has neither a concept of an explicit store nor a concept of evaluation order; nevertheless, \nwe show that programs in the calculus can be implemented us\u00ading a singlethreaded store. We also show \nthat the new calculus has the Church-Rozser property and that it is a conservative extension of classical \nlambda calculus with respect to operational equivalence; that is, all algebraic laws of the functional \nsubset are preserved. 1 Introduction Are assignments harmful? Common wisdom in the func\u00adtional programming \ncommunity has it that they are: seemingly, they destroy referential transparency, they require a determinate \nevaluation order, and they weaken otherwise powerful type systems such as ML s. Con\u00adsequently, programming \nlanguages with a strong func\u00adtional orientation often forbid or at least discourage the use of assignments. \nOn the other hand, assignments are useful. With them, one can implement mutable, implicit, distributed \nstate\u00ada powerful abstraction, even if it is essily misused. The traditional alternative offered by functional \nprogram\u00adming is to make state explicit. The resulting plumb\u00ading problems can be ameliorated by hiding \nthe state parameter using monads [20] or by using continuation\u00ad passing style [10]. Wadler, for example, \nuses the monad *Authora ac~:~l. Box 2158 Yale Station, New Haven, CT 06520. . {odersky-martin, rubin-dan, \nhudak\u00adpau~ Ocs.yale.edu Permission to copy without fee all or part of this materisl is granted provided \nthat the copies are not made or distributed for direct commercial advantage, the ACM copyright notice \nand the title of the publication and its date appear, and notice is given that copying is by permission \nof the Association for Computing Mschinery. To copy otherwise, or to republish, requires a fae and/or \nspecific permission. ACM-20th PoPL-1 /93-S. C., USA a 1993 ACM 0.8979J-56J.~/93/QOOJ /0043 . ..$J .50 \ntechnique in [22] to present pure functional program\u00adming as an alternative to impure programming with \nassignments. Monads are indeed successful in eliminat\u00ading explicit mention of state arguments, but they \nstill require a centralized definition of state. We show here that one Deed not choose between purity \nand convenience. We develop a framework that com\u00adbines the worlds of functions and state in a way that \ncan naturally express advanced imperative constructs with\u00adout destroying the algebraic properties of \nthe functional subset. The combinations are referentially transparent: names can be freely exchanged \nwith their definitions. More generally, we show that every meaningful opera\u00adtional equivalence of the \nfunctional subset carries over to the augmented language. Since we would like to abstract away from the \nissues of a particular programming language, we will concen\u00adtrate in this paper on a calculus for reasoning \nabout functions and assignments. The calculus is notable in that it has neither a concept of an explicit \nstore nor a concept of evaluation order. Instead, expanding on an idea of Boehm [2], we represent state \nby the collection of assignment statements in a term. A Church-Rosser property guarantees that every \nreduction sequence to normal form yields the same result. Following Plotkin [15] and Felleisen [3], we \nderive from the reduction rules both a theory and an evaluator and study the relation\u00adship between them. \nThe main contributions of this paper are: We define (in Section 2) syntax and reduction rules of &#38;,, \na calculus for functions and state. We show (in Section 3) that ~v=, is Church-Rosser and that it admits \na deterministic evaluation func\u00adtion which acts as a semi-decision procedure for equations between terms \nand answers. Even though the syntax of Avar is storeless, we show (in Section 4) that Avar-programs can \nstill be efficiently implemented using a single-threaded store. x ~ Vars immutable variables G Tags mutable \nvariables (tags) ~ e FConsts primitive functions ~n e C onstrs constructors of arity n (n > O) Al G Avar \nterms M ::= flcn[z[z.Ml M1M2 [ v[wv.Ml M?l M1=:M21M1pz.M2 I return M I pure M Figure 1: Syntax of Ava. \n . We show (in Section 5) a strong conservative ex\u00ad tension theorem: every operational equivalence be\u00ad \ntween terms in classical applied A-calculus also holds in Avar provided the domain of basic constants \n( and constructors is sufficiently rich). This is to our knowledge the first time such a result has been \nestablished for an imperative extension of the A\u00adcalculus. These properties make Ava, suitable as a basis \nfor the design of wide-spectrum languages which combine func\u00adtional and imperative elements. On the functional \nside, we generally assume call-by-name, but call-by-value can also be expressed, since strictness can \nbe defined by a J-rule. On the imperative side, first class variables and procedures can be used as building \nblocks for muta\u00adble objects (Section 6 presents an example making use of these constructs), We do not \nimpose any particular restrictions on either functions or side-effecting proce\u00addures, except for requiring \nthat their difference is made explicit. Building on Au., is attractive because it gives us an equational \nsemantics that makes reasoning about pro\u00adgrams quite straightforward. In contrast, the traditional store-baaed \ndenotational or operational semantics of im\u00adperative languages impose a much heavier burden on program \nderivations and proofs: at every step, one has to consider the global layout of the store, including \na map from names to locations and a map from locations to values. Other semantic approaches, such as \nHoare logic or weakest predicate transformers might accomm~ date simpler reasoning methods, but they \nare not easily extended to structure sharing or higher-order functions. 2 Term Syntax and Reduction Rules \nof &#38;o, The term-forming productions of Au., fall into three group adds the constructs for modeling \nassignment; the third introduces constructs for mediating between the world of assignments and the world \nof functions. groups, each presented on one line in Figure 1. The first group consists of clauses defining \nA-calculus with primi\u00ad tive function symbols and data constructors. We refer to this basic calculus as \nthe applied ~-calculus. The second Basic applied A-terms. We denote functional abstrac\u00adtion (z.M) without \nthe customary leading A; this modi\u00adfication makes some of our reduction rules more legible. The presence \nof primitive function symbols f and fixed\u00adarity constructors c shows the applied nature of the calculus. \nBasic constants are included as constructors of arity O. We assume that every calculus we consider has \nat least the unit value () as basic constant. Store tags and primitive state transformers. The scope \nof a mutable variable v is delimited by the construct war v .M. Mutable variables, also called tags, \nare syn\u00adtactically distinct from the immutable variables intro\u00adduced by abstractions x.M. We denote tags \nby the let\u00adters u, U, w, and immutable variables by Z, U, z. Tag readers M? and assignments Ml =: M2 \nare the primitive state transformers. If M computes a tag, M? is the state transformer that produces \nthe value associ\u00adated with that tag without altering the store. Dually, if Ma computes a tag, MI =: Ma \nis the state trans\u00adformer that sets that tag to Ml and produces an ignor\u00adable value. Composition of state \ntransformers. State transform\u00aders are composed into sequences using the monad-bind expression Ml D x \n.M2. This construct connects a state transformer Ml with a functional abstraction X.M2. It denotes the \nstate transformer that passes the value pro\u00ad 44 Avar Modula ~? b ~0~ [r)/x]M N E x.kf N(x) ; M var v.M \nVARU:T; M M=:u u:=M N;M N;M return M RETURN M pure M M Figure 2: Correspondence duced by Ml to X.M2 \nin the state resulting from the computation of Ml. We take (D) to be right-associative and often employ \nthe following abbreviation: N;M Gf NDx.M (x ~fv M). Coercion of state transformers. The &#38;--expresaion \nreturn M allows a pure expression M to be used as a state transformer; the expression pure M permits \n(under certain conditions) the coercion of a state trans\u00adformer to a pure expression. Correspondence \nwith programming languages. Fig\u00adure 2 relates terms of Aver with constructs of traditional imperative \nprogramming languages. We use Modula as a representative of such a language. The ~var-calculus deviates \nfrom common imperative pro\u00adgramming languages in its notation for assignments, which goes from left to \nright, and in its variable-readers, which are explicit state transformers rather than expres\u00adsions. These \nnotational conventions make tag-matching in the reduction rules easier to follow. In particular, be\u00ad \ncause of the m-orientation of assignments, information and computation in a state transformer flows uniformly \nfrom left to right. In each case, the conventional nota\u00adtion can be obtained by syntactic sugaring, if \ndesired. We would expect that such sugaring is introduced for any programming languages based on Avar. \nNotational conventions for reduction. We use bu M (fv M) to denote the bound (free) variables and tags \nin a term M. A term is closed if @ M = 0. Closed terms are also called progrums. We use M s N for syntactic \nequality of terms (modulo a-renaming) and reserve M = N for convertibility. If R is a notion of reduction, \nwe use M ~ N to express that M reduces in one R reduction step to N, and M ~ N to express that M reduces \nin zero or more R-steps to N. The subscript is dropped variable lookup (implicit in Modula) procedure \ncall, c is result parameter variable definition assignment sequential composition return statement effect \nmasking, implicit in Modula between &#38;. and Modula if the notion of reduction is clear from the context. \nA value V is a A-abstraction, a primitive function, or a (pomibly applied) constructor. An observable \nvalue (or answer) A is an element of some nonempty subset of the basic constantsl. v ::= z. Ml flcn Ml... \nM~(O<m <n) Acc A context C is a term with a hole [ ] in it. A state pr+ S is a special context that is \nof one of the forms s ::= [] I varv.S I M=:v; S and that satisfies in addition the requirement that wr \nS G bv S. The set of variables wrdten in S, wr S, is defined as follows: wr[] =0 wr (VW v.S) = wrS wr(M \n=: u;S) = {v} Uwr S. Following Barendregt [1], we take terms that differ only in the names of bound variables \nto be equal, Hence all terms we write are representatives of equivalence classes of a-convertible terms. \nWe follow the hygiene rule that bound and free variables in a representative are distinct, and we use \nthe same conventions for tags. Figure 3 gives the reduction rules of &#38;r. Rule (8) is the usual ,&#38;rule \nof applied A-calculus, It is the only rule whose reduction involves substitution. Rule (d) expresses \nrewriting of applied basic functions. To abstract from particular constants an~ their rewrite rules, \nwe only require the existence of a partial func\u00adtion d from primitive functions2 ~ and values to terms. \n10ther ~bse~tions SUCh as convergence to an arbltr~Y v~ue can be encoded using suitable J-rules. Zptimitive \nfunctions of more than one arwnent =e obtained by currying. /3 d (@.M) fv N + + [N/x] M (5(f, v) (J(f, \nV) defined) bD rp Ub =:P (kf~ b X.ikfZ) b y.h f~ (return N) P x.M (W v.kf) D X.~ (Ml =: M2) b Z.M3 + \n+ + j MI b z.(M2 P y.M3) (a.M) N var u.(Mbr.N) MI =: M2 ; (X.M3) () (XC jV M3) f bl b2 N=:v; N=:v; varv. \nv? bx. tv?Dx. w? bx. M M kl ~ + ~ N=:v; w? bz. w? bx. (c.M)N N=:v; varv. M kf (v (v # # w) w) Pc PA Pf \npure pure pure (S[return (S[return (S[return cn Ml z. M]) ~]) kfk]) -+ + +f c $. (pure pure (S[return \n(S[return MJ) Ikf]) (pure (S[return A&#38;])) (k< n) Figure 3: Reduction rules for &#38;. We restrict \n6 not to look inside the structure of its argument term, except when the term is a fully ap\u00adplied constructor \nat toplevel. That is, we postulate that for every primitive function $ there exist terms Nj and N$,CYI \n(cn e Constrs) such that for all values V for which J(f, V) is defined: N=. Ml ... M. if V = c MI ...M. \nC$(f,v) = N v otherwise. { State transformers obey two of the three laws of a Kleisli monad: (b) is associative \nand return is a left unit. The third law, stating that return is a right unit, fails. A counter-example \nis 1 b (x.return x) # 1. Note, however, that this example would be typically regarded as a type error \nin a statically typed language, since the number 1 is not a state transformer. In fact, every reasonable \ntype system should establish the third monad law as an operational equivalence for well-typed terms. \nRule (up) extends the scope of a tag over a (b) to the right. Variable capture is prevented by the hygiene \nccm\u00addition (bound and free variables are always different). Rule (=: b) passes (), the result value of \nan assignment, to the term that follows the assignment. Rules (f), (bl), and (&#38;) deal with assignments. \nThe fusion rule (f) reduces a pair of an assignment and a dereference with the same tag. The bubble rules \n(bl) and (h) allow variabl~readers to bubble to the left past assignments and introductions involving \nother tags. 46 Note that bubble and fusion reductions are defined only on tags v whereas the corresponding \nproductions Mu? and Ml =: Mu in the context-free syntax (Figure 1) admit arbitrary terms in place of \n,MV. This is a conse\u00adquence of tags being first class, folr even if M is not a tag it might still be \nreducible to one. The final three rules implement effect masking , by which local state manipulation \ncan be isolated for use in a purely functional context. These three rules can be applied only if the \nargument to pure is of form S[return V] where V is a value and S is a state pre\u00adfix. The context-condition \n( wr S ~ h S) for state prefixes S ensures that evaluation of the argument to pure neither affects nor \nobserves global storage. Effect mzwking pushes state inwards , and thus exposes the outermost structure \noft he result oft he pure expression. In the special cases where the resullt is a basic constant or primitive \nfunction the state disappears altogether.3 Example 2.1 (Counters) To illustrate the syntax and reduction \nsemantics of Am., we construct a function to generate counter objects. The generated counters en\u00adcapsulate \nan accumulator cnt. They export a function that takes an increment ( inc) and yields the state trans\u00adformer \nthat adds inc to the current value of cnt while returning cni? s old value. This is expressed in Auor \nas s~iti~]y, we ~tU&#38;,~d~ CSJCUIUSthat htsd only one effect m*k\u00ading rule: A context pure (S[return \n[ ]]) can be dropped if global storage is unaffected and none of the variables bound in S appear in the \nterm in the hole. This approach looks simpler at first glance, but it is not clear how a standard evaluation \nfunction for the resulting calculus ean be constructed. rnkcounter O@dr . ctr 1 ; dr O (var cnt .0 =: \ncd ; return CZ R) D ctr . ctr 1 ; ctr O var cnt . (0 =: cnt : return CTRJ p ctr . ctr 1 : ctr O var cnt \n.0 =: cnt ; return CTR ~ ctr , ctr 1 ; ctr O var cnt .0 =: cnt ; (ctr . ctr 1 ; ctr O) CTR varcnt. O=:cnt; \nCTRl; CTR O var cnt .0 =: cnt ; (inc . cnt? b c . c + znc =: cnt ; return c) 1 ; CTR O -? varcnt. O =:cnt; \ncnt?bc. c+l=:cnt; return c; CTRO -? var cnt .0 =: cnt; (c. c+ l=: cd ; return c) O ; CTR O -? varcnt. \nO=:cnt; O+l=:cnt ;return O; CTRO varcnt. cnt;O-. O+l=:cnt; CTRO varcnt. O =:cnt; O+l=:cnt; O+l+O =:cnt; \nreturnl Figure 4: A sample reduction. follows (with layout indicating grouping): mkcounter = initial \n. var cnt . initial =: cnt ; return inc . cnt? D c. c+ inc=: cnt ; ret urn c The reduction rules define \na reduction relation between terms in the usual way: we take ~ to be the smallest relation on Avar x \nAVar that contains the rules in Fig\u00adure 3 and that, for any context C, is closed under the implication \nM+ N * C[M]+ C[N]. The sample reduction given in Figure 4 illustrates the use of mkcounter in a program \nthat defines a counter ctr, increments it, and then inspects the final value. We use the abbreviation \nCTR s inc . cnt? b c . c + inc =: cnt ; return c. For each step in the reduction, the redex for the next \nreduction is underlined. Other reduction sequences are possible as well, but they all yield the same \nnormal form, since ~.., is Church-Rosser (Section 3). Fundamental Theorems In this section, we establish \nthat our calculus has the fundamental properties that make it suitable as a basis for reasoning about \nprograms. We first show that re\u00adduction is confluent; we then derive from the reduction relation a theory \n&#38;. for equational reasoning about A var terms. We also derive from the reduction relation an evaluation \nfunction that takes programs to answers. We conclude by showing that the evaluation function is a semi-decision \nprocedure for equations between pro\u00adgrams and answers. Due to space limitations, most proofs are sketched \nor omitted; full proofs can be found in [14]. In the sequel, let + be the union of all reductions in \nFigure 3 except (@) and (d). Proposition 3.1 + is strongly normalizing: every se\u00adquence of ~-reductions \nterminates. Proof: A standard termination measure argument. Proposition 3.2 + is Church-Rosser: if M \n+ Ml and M + M2 then there exists M3 such that Ml ~ M3 and M2~ M3. Proof: A case analysis on the relative \npositions of re\u00addexes coupled with a case analysis on reduction rules shows that + is weakly Church-Rosser. \nThe proposi\u00ad tion then follows by Newman s lemma ([1], Proposition 3.1.25) and Proposition 3.1. This \nleads us to the confluence result of the full reduc\u00ad tion relation: Theorem 3.3 ~ is Church-Rosser. pmf: \nThepurely functional reduction relation -@ is easily shown to be Church-Rosser (using Mitschke s the\u00adorem \n([1], Theorem 15.3.3), for instance). By Proposi\u00adtion 3.2, + is Church-Rosser. A straightforward case \n analysis on the relative positions of redexes establishes that ~ commutes with ~. By the lemma of Hindley \nand Rosen ([1], Proposition 3.3 .5), the combined notion of reduction -+ is Church-Rosser. R Reduction \ngives rise in the standard way to an equa\u00adtional theory. As usual, we define equality (=) to be the smallest \nequivalence relation that cent ains reduction. Definition. The theory Au=. has as formulas equations \nM = N between terms M, N ~ AV... Equality (=) is the smallest equivalence relation between terms that \ncontains reduction (~), We now define a computable procedure, or evaluation function, that maps a program \nto an answer if it re\u00adduces to one. We define our evaluation function via a context machine. At every \nstep, a context machine sep arates its argument term into a head redex that occupies a uniquely-determined \nevaluation context and then per\u00adforms a reduction on the redex. Evaluation stotxs once the argument is \nan answer. Evaluation contexts for Au=, are defined as follows: E ::= [] I EM IfE I var v.E I E? I M=:E \nI Epx.M I M=:vpx.E I pure E I pure S[return E] The productions on the first line generate evaluation \ncontexts in classical A-calculus with constants; the other productions deal with the evaluation of state \ntransform\u00ad ers. Given a Au.. -term, a step of the evaluation function starts at the root of the term. \nIf it is a redex, it is reduced; otherwise, the term s abstract syntax tree is matched against the E-productions, \nand the subterm occupying the position of the E is recursive y checked. If no redex is found, evaluation \nstops; otherwise the process is repeated. Definition. A redex A is a left redex of a Avar term M if M \ns E[A], for some evaluation context E. A left redex A of M is the head redez of M if, for all left redexes \nA of M, A g A. Definition. The evaluation function evalvar on A... programs is defined as follows: eval \nE[M] = eval E[N] if M is head redex inE[M] and M+ N, evalA = A. What is the relation between Avar and \nevaluar? we can show (by adapting a proof of the Cmrry-Feys stan\u00addardization theorem in [1], Section \n11.4) that evaiuar is a semi-decision procedure for equations in Avar of the form M = A where M is a \nprogram and A is an answer (a constant c ): Theorem 3.4 (Correspondence) For every closed term M ~ Auar \nand answer A, A.av 1-M=A @ eval.a. MsA. 4 Simulation by a Single-Threaded Store We now show that assignments \nin Avar can be imple\u00admented using a single sequentially-accessed store. In order to do this, we define \na translation from Avar into another calculus, AC, that represents stores explicitly. This calculus has \nreduction rules that closely resem\u00adble the usual meanings of store-operations in imperative models of \ncomputation; furthermore, we can define an evaluation function on the language AO that evaluates sequences \nof such operations in the expected temporal order. We establish that the evaluation functions for ~c \nand ~var-agree on those terms that are present in both languages. This simulation result shows both that \n~war possesses a reasonable implementation as a pro\u00adgramming language and also that ~Var indeed reasons \nabout assignment as claimed. To form the new term language A., we make stores ex\u00adplicit by extending \nthe defining grammar of Avar (Fig\u00adure 1) with the additional production M ::= u . M. Here, a = {vI:Ml, \n..., v.: Mn } is a state, represented by a set of pairs v :M of tags v and terms M. dom u = {v,,..., \nVn} is called the domain of u. Tags in dom m are considered to be bound by u. Reduction rules for states \nare derived from the reduction rules of ~v~~, with the following modifications: We keep (@ and (d) reduction \nas well as the flattening rules (Db), (rb), (Vb), (=: b). We replace the remaining bubble, fu\u00adsion, and \neffect masking rules by rules that construct, access, update, and destroy states, as shown in Figure \n5. The new basic constant undef is used to flag an initial\u00adized variable. The rules in Figure 5 define \na reduction relation AC between terms in A6. This relation can be shown to be confluent: Theorem 4.1 \naa is Church-Rosser. Note that, even though a state u can be duplicated in rule apc, the resulting states \nare all read-only. Therefore it suffices to copy a pointer to the state instead of the state itself: \nstate in &#38; is single-threaded [17]. 48 u~~~ u. Var V.lvf j cU{u:undef} . M u=: uU{U:N } . ZV=:U; \nM ~ uU{U:N} .M u? mU{v:N} . u? D$.~ + UU{U:N} . (x.M)N (N ~ undef). Upure pure M -+@.M UPC u. return \n[cn Ml ... J&#38;] A Cn (u. return [Ml]) ... (~. return [Mk]) (k < n) flPA m. return [z.M] + z . a. return \n[M] upf a . return ~] +f Figure 5: Modified reduction rules for &#38;. The evaluation contexts in&#38; \nare given by the grammar: E ::= [] [ EM [fE 1 E? IM=:E . ] EDX.M I I pure E I pure S[return E] I u*E \n Based on this definition of evaluation context, we define the notion of head redex and the standard \nevaluation function eualo for programs in A. as was done for AVar in Section 3. evalq closely corresponds \nto usual notions of store-based computations with store access and up date as single reduction steps. \nAnalogously to the sit\u00aduation in AVar, evalq is a semi-decision procedure for equations between terms \nand answers in AO. Theorem 4.2 (Correspondence) For every closed term M G AO and answer A, &#38;tM=A \n~ evalOM~A. Since A.ar c A., it makes sense to apply eval~ to a term in AV=r. Moreover, both evaluation \nfunctions are equivalent if we consider only observable results: Theorem 4.3 (Simulation) For every closed \nterm M in A ., and answer A, A.arl-M=A u &#38;l-M=A. Proof: There is a close correspondence between states \nin &#38; and state prefixes in &#38;.r. Every state prefix S corresponds to a state us, defined by dom \nus = bvS s=s [N=: w;c[]], w$iwT c +-(U:N) GC7S vebv S,v~wr S ~ (v:undef)cus Define S[pure (S[M])] = us \n. M and extend S canon\u00adically to all of Avo~. S is subjective but not injective: every non-empty state \ncorresponds to an infinite num\u00adber of state prefixes. We define a right inverse S-1 of S by picking for \neach state u one of the state prefixes that corresponds to n. Assume that tag identifiers are totally \nordered, and that the identifiers VI, ..., v~ in a state fl = {VI : Ml, .... v. : Mn } form an ascending \nse\u00adquence. Define S-l[a. M] s pure (var VI. . . . varun. Ml=: vl; . . .. Mn=. vn; M). and extend S-1 \ncanonically to a mapping from AQ to A var. It is straightforward to verify that (i) M # S[M], (ii) &#38; \n1-SIS-l[u]J = a,  (ii:) ~var ~ S-l [S[M]] S M (operational equivalence s is defined in the next section). \nUsing these laws, one shows by a case analysis over the respective notions of reduction in AvaT and Jo \nthat (iv) If M + N by contracting a head redex A in M, and N ~ A then &#38; 1-S[it.f] = S[N], (v) If \nM # IV then &#38; t-S- [M] S S- [N].  The theorem then follows from laws (i-V) by an induc\u00adtion on \nthe length of the reduction sequence from M to A. m 5 Operational Equivalence Operational equivalence \nis intended to reflect the notion of interchangeability y of program fragments. It equates strictly more \nterms than does convertibility. We will define operational equivalence for arbitrary extensions of the \n~-calculus. Definition. An equational theory Ax over terms in A* is an extension of A (wrt conversion), \nif A G A+, and, for any terms M, I? in A, Ath4=N~A*l-kl=N An extension is conservative if the implication \nin the last statement can be strengthened to an equivalence. Definition. Let A* be some extension of \nthe A-calculus. Two terms N and M are opemtionally equivalent in A., written Ax ~ N !2 M, if for all \ncontexts C in A* such that C[M] and C [N] are closed, and for all answers A, A. EC[N]=A e &#38;t-C[M]=A. \nLemma 5.1 For any terms M, N, and context C, J* I-M%NsA* 1-C[M]=C[N]. Proposition 5.2 The following are \noperational equiv\u00adalences in &#38;~r: (1) v? Dx. vJ?c-y, M ~ W? Py. V? PZ, kf (2) N=:v; N =:w; M % ~ \n=, tv; N=, v;kf  (v# w) (3) varv. N=:w; M G N=:w; varv. M (v# W,V@fvN) (4) varv. varw. M E varw. varv. \nM (5) N=:v; N =:v; M E N =:v; M (6) S[S [M]] s S [M] (S ~ [],  h snjv S [Al] =0) Proofi One uses \nthe correspondence and simulation IW\u00adsults of Sections 3 and 4, together with an induction on the definition \nof evalg. Equation (1) says that variable lookups commute. Equations (2), (3) and (4) say that assignments \nand variable introductions commute with themselves and with each other. Equation (5) says that if a variable \nis written twice in a row, the second assigned value is the one that counts. Equation (6) implements \ngarbage collection : it says that a state prefix S of an expression S[S [M]] can be dropped if every \nvariable written in S is unused in S [M]. The reason for the second state prefix S is to prevent false \noperational equivalences involving non\u00adsense terms, aa in var v. 1 # 1. Note that, using the bubble conversion \nlaws and the commutative laws (2), (3) and (4), garbage can always be moved to a state pre\u00adfix. Relationship \nbetween .,4.., and classical k-calculus. Clearly, convertibility in ~ implies convertibility in AU.,, \nsince (~) and (J) are reduction rules in Atiar. However, this goes only part of the way. For instance, \nthe equa\u00adtion tail o cons x ~ id between list lprocessing functions is not an equality in the sense of \n,&#38;Lconvertibility, but it is an operational equivalence. Other operational equiv\u00adalences are those \nthat identify some diverging terms or terms that involve fixpoints. Since equivalences like these are \nroutinely used when reason ing about programs, we would hke them to be preserved m &#38;r. We estab\u00adlish \nnow the result that AvGr indeed preserves the op\u00ad erational equivalences of Al and, furthermore, that \nA~~~ does not introduce any new operational equivalences be\u00adtween A-terms. The only provision on this \nresult is that the underlying set of constructors and basic function symbols needs to be (sufficiently \nrich (meaning that we can always find enough constructors that are not used in the reduction of some \ngiven program). Definition. An (extension of) applied A calculus &#38; has a sufficiently muchset of \nconstants if (a) The constructor alphabet includes for every arity n an infinite number of constructors \nthat do not form part of any of the terms Nf ,Cn, Nf used to define the 6 function. (b) For every type \nconstructor c one can define in ~. a projection function proj.cn such that (c) One can define in&#38; \na function projector proj.f such that  proj.cn (cn Ml ... M.) P Q = P MI ... Mn proj-cn V P Q ,= QV \nfor any other value V. proj-f(cn Ml ... M.) P Q = Q (c Ml ... M.) for any data value c Ml ... Mn proj.f \nV P Q =Pv for any non-data value V (i.e. for any function). Clearly, these projection functions can \nbe defined by suit able &#38;rules. The functions proj.c represent a stripped down version of pattern \nmatching on data types, as it k found in many functional programming languages. Function proj.f can be \nthought to be a dy\u00adnamic type test, similar to procedure? in Scheme. Theorem 5.3 (Conservative Extension) \nAssume that A and Auar have the same, sufficiently rich set of con\u00adst ants. Then for any two terms M, \nN c A, Proof: The proof ia based on finding a syntactic enabed\u00add:ng F from the stor~based calculus Ad \nto terms in A. Definition. Let A. be an extension of A Let 7? be an unspecified domain of environments. \nA mapping &#38; : A, + 7?,-+ A is a syntactic embedding from A* to A if &#38; is compoaitiona14, i.e. \nVCe A.[]Vp~l? 3p e RVMe A* J 1-g[C[M]]p = (g[C]p)[$[M]p~, 8 is the identity on A programs, i.e. for all \nclosed M E A, pc ??, J 1-$[M]p= M, and &#38; is semantics preserving, i.e. A*l-M=A ~Jt-~[M]p=A. For technical \nreasons, we use a variant of&#38;, in which statea are represented aa sequences of bindings v : M, rather \nthan as sets of such bindings. The reduction rules in Figure 5 carry over, except that the first three \nrules are now defined on sequences rather than sets: u .varv.M + a+ [v:undefl . M uil-[v:N ] +a o ZV=:v; \nM + a+[u:N]+u . M u-H-[ v: N]-IFu . V? PZ.M -+ a + [v :iV] -H-u . (z.M) N (N ~ undef). where -H-is the \nappend operator on lists. Clearly, The\u00adorem 4,3 holds for the new just as for the original ~0 calculus. \nAssuming for the moment that we have found a syntactic embedding ~ from the new &#38; to A, we can then \nprove Theorem 5.3 as follows: % : Assume that A + M 2 N and let A be an answer. Then, for all A-contexts \nCA such that C~[M J and C~[N] are closed; At-C~[M]=A*AF C@]=A. Assume first that both M and N are closed. \nLet C be an arbitrary closed Ava,-context and let p be in the environment domain of 7. Since r is compositional, \nthere exists an environment p with F[C[M]]p = (%[C]p)[~[M]p 1. 4we ~ume that ~YntMtic embedding are exhmkl \n~oni\u00adcally to contexts, e.g. &#38;[[ ]] = []. Furthermore, AVlzr 1-C[M] = A + (Theorem 4.3) JoFC[M] =A \n * (7 is semantics preserving) J 1-F[C[M]]p= A  * (F is compositional) A 1-(7[C]p)[F[M]p 1 = A  + (Y \nis the identity on A programs) A + ($[C]p)[M] = A + (premise: A + M ~ N)  ~ 1-(F[C]p)[N] = A s (reverse \nthe argument) Avor 1-C[N] = A. Now let M and N be arbitary A terms, with fv M U fu N = {Zl,..., Zn}. \nThen, AI-MSN (Lemma 5.1) A+ Xl. ... MSXl S~n . ...~n.N (first part of proof) Avar l-xl . . ..xM2z12zn \n. . ..zn.N (Lemma 5.1) A ar~M~N,  += . Assume Avar ~ M s N. Then we have Avat-1-C[M] = A+ Avar 1-C[N] \n= A for all contexts C in A.=. such that C[M] and C [N] are closed and therefore also for all such contexts \nC in A. Since terms M E A have only /3 and d redexes, and since A is closed under @ reduction, this implies \nA+ M&#38;N. E The remainder of this section is devoted to the defini\u00adtion of the syntactic embedding \n~ from ~. to A This construction is actually of a broader importance than just as a technique for the \nproof of conservative exten\u00adsion, for it also gives us a way to construct models for Auar 9 by composing \nany denotational semantics of ap plied A calculus with 7. We aaeume from now on that Auar has a sufficiently \nrich set of constants. F is defined in Figure 6. It takes as environment a stack of symbol tables. Each \nsymbol table contains bindings for mutable and immutable variables local to some pure scope. (A pure \nscope extends over a subterm with outermost constructor pure, but excludes any nested purt+terms). Symbol \ntables are represented as sets of bindings z + M and v + M. The stack is implemented f c if3kf.{z-+M} \n~tthen M else outer (7[2] .ts) y.r[ll!f](({z i+ ~} u t) : h) where y + fv(t: ts) (r[M,] ts) (qq ts) if \nMcf. {vI-+ M} ~ t then M else outer (F[u] ts) Var (Y.FW](({V * Y} u t) : ts)) where y ~fv(t: k) Deref \n(7[M] ts) Assign (%[Ml] ts) (F[M2] ts) Return (F[M] b) bind (Z[itll] ts) (Y[x.M2] ts) ezec E (y[M] ts) \nezec s (YIJI] (t: h)) [q:iwl,..., wn:ifn]n] = 0 s = [F[iwl] (t: ts), .... qkq (t : ts)] t = {VI+ Tag \nO,..., Vn# Tag (n l)} Figure 6: Syntactic embedding F as a list, using ~ for the empty list and (:) as \nconstructor symbol. The translation scheme mentions constructors Var, Deref, Assign, Bind, Return, Tag \nin Figure 6, as well as In, Out, Undef, which are defined later. We call these constructors F-interns/, \nand assume that they do not occur in the terms ~ is applied to. This can always be achieved by a suitable \nrenaming since Avar is sufficiently rich. F maps state transformers in A.ar to data structures in A that \nare then passed to one of two interpreter functions bind or exec. To define these functions and others \nused in the definition of F, we use a functional notation similar to Haskell, rather than a formulation \nin terms of projection functions in order to aid legibd\u00adity. Functional abstractions are still expressed \nas x .M iristead of Haakell s \\z + M. bind (Bind s f) g = Bind x (y.bind (f y) g) bind (Return x) g = \ngx bind ( Var f) g = Var (y.bind (f y) g) Intuitively, bind simulates AO reductions (DD), (rD), and (UP). \nThe remaining non-functional A. reductions, which all reference state, are simulated by function exec. \netec s(Var f) = exec (s -H-[ Vndef]) (f (Tag (length s))) exec s (Bind (Assign x (Tag i)) g) = exec (take \ni s it [x] + (drop (i+l) s)) (g ()) exec s (Bind (Deref (Tag i)) g) I s!!i # Undef = exec s (g (s!!i)) \nexec s (Return (c xl ... Xn)) = c (exec s (Return X1)) ... (exec s (Return z.)) exec s (Return f) I f \nnot a data value z . exec s (Return (f x)) In the second-t~last clause Cn ranges over all data con\u00adstructors \nexcept those that are F-internal. In the last clause f ranges over all non-data values (i.e. values that \ndo not consist of a fully applied constructor at top\u00adlevel). The syntax of values ensures that non-data \nval\u00adues are always functions. The translation scheme represents states ss lists of terms, and tags as \nvalues Tag i where i acts as an index into the state list5. This scheme poses one rather diffi\u00adcult problem: \nAO uses globally unique tag names, but the representation of a tag as an index is unique only among all \ntags bound in the same state prefix. How\u00adever, it is mandatory to be able to distinguish between tags \nbound in a given state prefix and tags that are free in it. Otherwise, global variable accesses and updates \nin a pure go undetected. There is no hope of finding a syntactic embedding F that assigns globally unique \nnames to tags; every such mapping would have to pass a name supply between pure terms. This would violate \nthe condition that 7 maps purely functional A-terms to themselves, and hence 7 would not be a syntactic \nembedding. We overcome this problem by introducing the mutually recursive functions outer and inner. \nFunction outer marks occurrences of (mutable and immutable) vari\u00adables in pure scopes other than the \none in which the variables are defined. The number of outer operators applied to such variables equals \nthe difference in nest\u00ading level of the pure scope that defines the variable and the pure scope in which \nit is used. Function inner can\u00adcels out the effect of outer. The definition of these two sThj~ ** of \nthe embedding is similar to the px esfmkdkm of monadic state transformers in [22] 52 data QEntry a = \ncons a ( Var (QEntry a)) type Queue a = { put : a+l%co, get : Pmca, isempty : Pmc Bmd J mkqueue Pmc \n(Queue a) mkqueue = Varv. =front . v =: front ; WU rear. v=:nxv; return { put x = rear? by. varw. f30nsx \nw=: y; w=: mar, get = f?wlt?b ~ . y?b cons z z . z=: front ; return x, isempty = jhllt?by. TSW?bz. returny+z \n} Figure 7: A queue implementation mkqueue Dq.g.$put x ;q$get oM S mkqueue Pq.M x q-lPut x ; q-$puty \n;q.$get E q_l-Putx ; q$9etbz . q$ptd y ;returnz mkqueue bq.q~isempty bM 2 mkqueue ~q.M tie 9 $Put x ; \nq~ isemPtY ~ q $put x ; return False Figure 8: Axioms for an imperative queue abdract data type functions \nis as follows: Proposition 5.4 gives us a way to treat AVar programs as syntactic sugar for functional \nprograms. In the ter\u00ad outer (Tag M) = Out ( Tag M) minology of [4], A can express Jvd,. One might ask \nwhy outer (Out M) = out (out M) one should bother with J vat-at all, if all its terms can outer (ln M) \n=M be mapped via ~ to functional values. We believe that the main reason for studying JVar independently \nlies in inner (Tag M) = h (M) its simplicity, compared to the translated image under inner (Out M) = \nM 3. In the next section, we give an example showing inner (h M) = h (Zn M) how the laws of AVdr CaU \nhelp reasoning about imper\u00ad ative programs that previously required very complex For every other data \nv~ue Cn Ml ,.. Mn, including Val. proofs. uea formed from ~-internal constructors: outer(cn Ml ,.. Mn) \n= c (outer Ml) ...(outer M.) 6 Example: Queue A13T inner(cn Ml ... Mn) = c (inner Ml) ...(inner M ) \nFigure 7 presents an imperative implementation of an abstract data type Queue . A queue is represented \nouter f = c.outer (f (inner z)) as a record whose fields are closures implementing the inner f = x.inner \n(f (outer z)) operations put (i.e. append to end), get (remove from front) and isempty. Proposition 5.4 \nF is a syntactic embedding. For every non-data value f: Internally, a queue is implemented by two references \nto a linked list of entries. Each entry has a data field andPmofi It is straightforward to verify that \n3 is compoai\u00ad a link field. The link field is a mutable variable pointing tionai and that it maps A-programs \nto themselves. That to the next entry in the list. The last link field in the list ~ also preserves semantics \nis shown using a technique is always uninitialized. front always refers to a variable similar to the \nproof of Theorem 4.3. that in turn either refers to the first entry in the queue, or is uninitialized, \nif the queue is empty. rear always refers to the last link field of the queue. For conciseness we augment \nthe basic calculus with pat\u00adtern matching and records. Field selection is expressed by infix ($), of \nhigher precedence than function ap\u00adplication. Also, even though Au.. is untyped, we still write type \ndeclarations and function signatures in order to help understanding. Var Q designates the type of mutable \nvariables that contain values of type cr. Pmc CY designates the type of state transformers that return \nresults of type a. One feature of Avat-not discussed so far concerns vari\u00adable identity: In the last \nline of the example, y + z is intended to be true iff y and z designate the same tag. (=) carmot be defined \nvia (d) since tags are not values. We define (+) instead by adding reduction rules v~vdtrueandv=w~ false \nifv#w. Itis straightforward to show that this addition does not in\u00advalidate any of the results presented \nin earlier sections. The implementation in Figure 7 satisfies the axioms for queues shown in Figure 8. \nThis cau be shown using Av=r s conversion rules and the operational equivalences of Proposition 5.2. \nFor the second axiom, a structural induction on terms is needed. As an example, we show in Figure 9 the \nproof that our implementation satis\u00ad fies the first queue axiom. Even though this proof is far from short, \nall its steps are simple and amenable to machine-assisted proof-checking. Also, some of the proof s size \nis due to the detailed level of presentation. 13y contrast, the traditional approach to verifying pro\u00ad \ngrams with pointers treats pointer-threaded structures ss graphs. This requires complex arguments when \niso\u00ad morphism between graphs needs to be shown. Related Work Hoare et. al. [9] present a normalizing \nset of equations for an imperative language with assignment, conditional and nondeterministic choice. \nFunctional abstraction is not considered. Field [7] extends the deterministic part of their theory with \nshared variables. Boehm [2] gives an equational semantics for a first-order Algol-like lan\u00ad guage. ID \nhis setting, expressions have both values and effects, which are defined by different fragments of his \ncalculus. Felleiaen, Friedman, and Hieb [5, 6] have developed a succession of calculi for reasoning \nabout Scheme pro\u00ad grams. Since their target programming language is call\u00ad by-value, they have based their \nwork on the A v-calculus of Plotkin[15] instead of the pure A-calculus. It is inher\u00ad ent in their goal \nof reasoning about Scheme that their theories are not a conservative extension with respect to operational \nequivalence of either the classical A-calculus or of A v. hlason and Talcott [1 1, 12] have also de\u00adveloped \nequational calculi with motivations similar to those of Felleisen et. al. and with comparable results. \nOur work was influenced in part by the Imperative Lamb da Calculus (ILC) of Swarup, Reddy and Ireland \n[18]. Like .AVa,, ILC assumes call-by-name and models as\u00adsignment by rewriting variable uses to approach \nand merge with their definitions. Unlike ~ ~~, ILC is de\u00adfined in terms of a three-level type system \nof values, ref\u00aderences and observers. This somewhat restricts expres\u00adsiveness on the imperative side: \nreferences to objects that encapsulate state cannot be expressed, and all pro\u00adcedures have to be formulated \nin continuation-passing style. Also, unlike ~.ar, ILC is strongly normalizing, and, as a consequence, \nnot Turing-equivalent (e.g. re\u00adcursion is prohibited). A programming language with motivation similar \nto that of ~w~~ is Forsythe [16]. The language distinguishes between mutable and immutable variables, \nand also be\u00adtween value expressions and commands; however, it does so by means of a refined type system \nthat is based on in\u00adtersection types. Forsythe essentially uses a two-phase semantics, in which a term \nis first expanded to some potentially infinite program which is then executed in a second phase. Some \ncommon programming idioms such as procedure variables do not fit in this framework and therefore cannot \nbe expressed. 8 Conclusions and Future Work We have extended the applied A-calculus with assign\u00adment. \nWe have shown that the resulting calculus is confluent, preserves all operational equivalences of the \noriginal calculus, and permits implement at ion by a con\u00adventional, sequentially updated, store. We hope \nthat AV.. will prove useful as a framework for extending lazy functional programming languages with imperative \ncon\u00adstructs. An important step to that goal will be the study of type systems for Au... We have intentionally \nkept the present treatment untyped in order that many of our results may be applied immediately to versions \nof ~va~ with ar\u00adbitrary descriptive type systems. Had we started out with a typed calculus instead, all \nour results would hold only for the lparticular type system used. This would re\u00adsult in a loss in generality, \nsince there are many possible candidates for such a type system. In particular, there are several widely \ndiffering approaches to implementing the effect checking required by the pure rule (examples are [8, \n13, 18, 19, 21]). By keeping Auar untyped we mkqueue~q . q$put x ; q$get DM (expand mkqueue) var v.var \nfront .v=: front ;var rear .v=: rear ;return QDq . q-lput x ; q.J.getb M where Q ~ {put = ,,., get = \n.... isempty = ...}. as in Figure 7 (rb on return Q, followed by ~) varv. varfront .v=:front; var rear. \nv=: rear; Q$Put $ ; Q$get D [Q/q] M (expand Q$put, Q$get) Varv. varfront .v=:front; var rear. v=: rear; \nrear? Dy. varw. Cons xw=:y; w =: rear; front? by . y ? b Cons x z . z =: front ; return x b [Q/q] M (fuse \non rear) varv. varfront .v=:frant; var rear. v=: rear; varw. Consxw=:v; w=: rear; front? b yt . y ? b \nCons x z , z =: front ; returns+ D [Q/q] M (bubble and fuse on front) varv. varfront .v=:front; var rear \n.v=: rear; varw. Cons xw=:v; w=: rear; v? b Cons X1 z . z =: front ;return x ~ [Q/q] M (bubble and fuse \non v) var v .var front . v =: front ;var rear . v =: rear ; varw. Cons xw=:v; w=: rear; w=: front ; return \nz b [Q/q] M (rearrange, using Proposition 5.2 (2), (3), (4)) varw. varv. Consxw=:v; var front . v =: \nfront ; w =: front ; varrear .v=:rear; w=: rear ; return z D [Q/q] M (Proposition 5.2 (5), twice) varw. \nvarv. Con8x w=: v; var front . w =: front ; var rear .w=: rear ; returns D [Q/q] M (Proposition 5.2 (6), \neliminating var v . Cons z w=: v ; []) varw. varfmnt. w=: front ;vnrrear. w=: rear; return z b [Q/q] \nM (rb, z not free in Q) varw. varfrant .w=:front; var rear w=: rear ; [Q/q] (M z) (~,rD in reverse) varw. \nvarfront. w=: front ;var rear. w =: rear ; return Q b (M 22) (collapse definition of mkqueue, using that \nv and w not free in Q, M) mkqueue bq .M x Figure 9: Proof of a law on queues. avoid being overly specific. \nAlso left to future research is the investigation of vari\u00adants of Jva.. A call-by-value variant promises \nto be a useful tool for reasoning about programs in existing im\u00adperative or impurely functional languages. \nA variant with control-operators could provide an equational the\u00adory for a language with call/cc or exceptions. \nAcknowledgements This work was supported in part by DARPA grant num\u00adber PJOO01491-J-4043. The second \nauthor was sup\u00adported by an IBM Graduate Fellowship during the final preparation of this paper. We thank \nManfred Broy, Kung Chen, Matthiw Felleisen, John Field, Uday Reddy, Vipin Swarup and Philip Wadler for \ndiscussions and comments on earlier versions of this paper. References [1] H. Barendregt. The Lambda \nCalculus: Its Sgntax and Semantics, volume 103 of Studies in Logic and the Foun\u00addations of Mathematics. \nNorth-Holland, 1984. [2] H.-J. Boehm. Side effects and aliasing can have sim\u00adple axiomatic descriptions. \nACM Transactions on Pro\u00adgramming Languages and Systems, 7(4):637-655, Octo\u00adber 1985. [3] E. Crank and \nM. Felleisen. Parameter-passing and the lambda-calculus. In Proc. 18th ACM Symposium on Principles of \nProgmmming Language$, pages 233-244, January 1991. [4] M. Felleisen. On the expressive power of programming \nkmguages. In N. D. Jones, editor, ESOP 9o, Eu\u00adropean Symposium on Programming, Lecture Notes in Computer \nScience 432, pages 134 151. Springer-Verlag, 1990. [5] M. Felleisen and D. P. Fkiedman. A calculus for \nassign\u00adments in higher-order languages. In Proc. lJth ACM Symposium on Principles of Programming Languages, \npages 314-325, January 1987. [6] M. Felleisen and R. Hieb. The revised report on the syntactic theones \nof sequential control and state. Tech\u00adnical Report Rice COMP TR89-1oO, Rice University, June 1989. To \nAppear in Theoretical Computer Sci\u00adence. [7] J. Field. A simple rewriting semantics for realistic im\u00adperative \nprograms and its application to program anal\u00adysis. In PEPM 92: ACM SIGPLAN Workshop on Par\u00adtial Evaluation \nand Semantics-Based Program Manipu\u00adlation, pages 98-107, June 1992. Yale University Re\u00adsearch Report \nYALEU/DCS/RR-909. [8] J. Guzm&#38;n and P. Hudak. Single-threaded polymor\u00adphic lambda calculus. In IEEE \nSymposium on Logic in Computer Science, pages 333-343, June 1990. [9] C. A. R. Hoare, I. J. Hayes, He \nJifeng, C. C. Morgan, A. W. Roscoe, J. W. Sanders, I. H. Sorensen, J. M. Spivey, arnd B. A. Sufrin. Laws \nof programming. Com\u00admunications of the ACM, 30(8):672 686, August 1987. [10] P. Hudak and D. Rabin. Mutable \nabstract datatypes -or how to have your state and muuge it too. Re\u00adsearch Report YALEU/DCS/RR-914, Yale \nUniversity, Department of Computer Science, July 1992. [111 L Mason and C. Talcott. Programming, transforming, \nand proving with function abstractions and memories. In Automata, Languages, and Programming: 16th In\u00adternational \nColloquium, Lecture Notes in Computer Sci\u00ad ence 372, pages 574 588. Spnnger-Verlag, 1989. [12] I. Mason \nand C. Taicott. Equivalence in functional lan\u00adguages with side effects. Journal of Functional Program\u00adming, \n1(3):287-327, July 1991. [13] M. Odersky. Observers for linear types. In B. Krieg-Briickner, editor, \nESOP 92: 4th European Symposium on Programming, Rennes, France, Proceedings, Lec\u00adture Notes in Computer \nScience 582, pages 390-407. Springer-Verlag, February 1992. [14] M. Odersky and D. Rabin. The unexpurgated \ncall\u00adby-name, assignment, and the lambda-calculus. Re\u00adsearch Report YALEU/DCS/RR-930, Department of Computer \nScience, Yale University, New Haven, Con\u00adnecticut, October 1992. [15] G. D. Plotkin. Call-by-name, call-by-value, \nand the ~-calcuhm Theoretical Computer Science, 1:125-159, 1975. [16] .J. C. ReynoMs. Preliminary design \nof the programming lan~age Forsythe. Technical Report CMU-CS-88-159, Carnegie Mellon University, June \n1988. [17] D. Schmidt. Detecting global variables in denota\u00adtional specifications. ACM Trarwactions on \nProgram\u00adming Languages and Systems, 5(2):299 310, 1985. [18] V. Swarup, U. S. Reddy, and E. Ireland. \nAssignments for applicative languages. In J. Hughes, editor, Proc. 5th ACM Conf. on Functional Programming \nLanguages and Computer Architecture, Lecture Notes in Computer Sci\u00adence 523, pages 192-214. Springer-Verlag, \nAugust 1991. [19] J.-P. Talpin and P. Jouvelot. Type, effect and region reconstruction in polymorphic \nfunctional languages. In Workshop on Static Analysis of Equational, Functional, and Logic Programs, Bordeaux, \nOct. 1991. [20] P. Wadler. Comprehending monads. In Proc. ACM Conf. on Lisp and Functional Programming, \npages 61\u00ad78, June 1990. [21] P. Wadler. Is there a use for linear logic? In Proc. Symposium on Partial \nEvaluation and Semantics-Based Program Manipulation, pages 255-273, June 1991. SIG-PLAN Notices, Volume \n26, Number 9. [22] P. Wadler. The essence of functional programming. In Proc. 19th ACM Symposium on \nPrinciples of Program\u00adming Languages, pages 1 14, January 1992. \n\t\t\t", "proc_id": "158511", "abstract": "<p>We define an extension of the call-by-name lambda calculus with additional constructs and reduction rules that represent mutable variables and assignments. The extended calculus has neither a concept of an explicit store nor a concept of evaluation order; nevertheless, we show that programs in the calculus can be implemented using a single-threaded store. We also show that the new calculus has the Church-Rosser property and that it is a conservative extension of classical lambda calculus with respect to operational equivalence; that is, all algebraic laws of the functional subset are preserved.</p>", "authors": [{"name": "Martin Odersky", "author_profile_id": "81100056476", "affiliation": "", "person_id": "PP14030830", "email_address": "", "orcid_id": ""}, {"name": "Dan Rabin", "author_profile_id": "81332522261", "affiliation": "", "person_id": "P58206", "email_address": "", "orcid_id": ""}, {"name": "Paul Hudak", "author_profile_id": "81100539650", "affiliation": "", "person_id": "PP40028396", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158521", "year": "1993", "article_id": "158521", "conference": "POPL", "title": "Call by name, assignment, and the lambda calculus", "url": "http://dl.acm.org/citation.cfm?id=158521"}