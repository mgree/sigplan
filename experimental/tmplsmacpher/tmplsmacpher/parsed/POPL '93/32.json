{"article_publication_date": "03-01-1993", "fulltext": "\n Incremental Program Testing Using Program Dependence Graphs SAMUEL BATES SUSAN HORWITZ samuel@cs.wise.edu \nhorwit.@cs.wise.edu Computer Sciences Department University of Wisconsin-Madison 1210 West Dayton Street \nMadison, Wisconsin 53706 ABSTRACT program dependence graphs have been proposed for use in optimizing, \nvectorizing, and parallelizing compilers, and for program integration. This paper proposes their use \nas the basis for incremental program testing when using test data adequacy criteria. Test data adequacy \nis commonly used to provide some confidence that a particular test suite does a reasonable job of testing \na program. Incremental program testing using test data adequacy criteria addresses the prob\u00adlem of testing \na modified program given an adequate test suite for the migimd program. Ideally, one would like to create \nan adequate test suite for the modified program that reuses as many files from the old test suite as \npossible. Furthermore, one would like to know, for every file that is in both the old and the new test \nsuites, whether the program components exercised by that file have been affected by the program moditicatiow \nif no components have been affected, then it is not necessary to rerun the program using that file. In \nthis paper we define adequacy criteria based on the program dependence graph, and propose techniques \nbased on program slicing to identify components of the modified program that can be tested using files \nfrom the old test suite, and components that have been affected by the modification. This information \ncan be used to reduce the time required to create new test fiIes, and to avoid unpro\u00adductive retesting \nof unaffected components. Although exact identification of the components listed above is, in general, \nundecidable, we demonstrate that our techniques provide safe approximations. This work was supported \nin part by NSFunder grant CCR-8958530, by DARPA, monitored by ONR under contrsct NOO014-88-K-0590, as \nwell as by grants from 3M and Xerox. Permission to copy without fee all or part of this material is granted \nprovided that the copies are not made or distributed for direct commercial advantage, the ACM copyright \nnotice and the title of the publication and its date appear, and notice is given that copying is by permission \nof the Assoclatlon for Computing Machinery. To copy otherwise, or to republish, requires a fee and/or \nspecific permission. ACM-20th PoPL-1/93-S.C., USA Q 1993 ACM 0.89791 .561.5/93/0001 /0384 .,.$1 ,5(3 \n1. INTRODUCTION Program dependence graphs have previously been proposed for use in optimizing, vectorizing, \nand parallelizing com\u00adpilers [10], and for program integration [15]. This paper proposes a new use: as \nthe basis for incremental program testing when using test data adequacy criteria. Test data adequacy \nis a widely accepted concept for pro\u00adviding some confidence that a particular test suite (set of input \nfiles) does a reasonable job of testing a program [18, 24, 29]. For example, a test suite is adequate \nunder the all-statements criterion if for every statement in the pro\u00adgram there is at least one input \nfile in the suite such that when the program is run using that input file, the statement is executed. \nIncremental program testing using test data adequacy cri\u00adteria addresses the following problem: given \na program and a test suite that is adequate under criterion C, what should be done after the program \nis modified? Ideally, one would like to create a test suite for the modified program that is adequate \nunder criterion C, and that reuses as many files from the old test suite as possible. Furthermore, one \nwould like to know, for every file that is in both the old and the new test suites, whether the program \ncomponents exercised by that file have been affected by the program modification; if no components have \nbeen affected, then it is not neces\u00adsary to rerun the program using that file. Example. Figure 1 shows \na program before and after a modification. Version 1 is intended to compute the product of the odd numbers \nin the range 1..N (where N is an input that is supposed to be positive); however, the variable oak!P \nis incorrectly initialized to zero. This error is corrected in Version 2, which also adds the computation \nof the product of the even numbers. The statements of Version 2 that are affected by these modifications \n(i.e., the statements where new values are computed or used) are shown enclosed in boxes. There are many \nstatement adequate test suites for Ver\u00adsion 1. One such suite consists of two tiles, containing the values \nO and 2, respectivelfi this test suite is also statement adequate for Version 2. Since the statements \nof Version 2 that are exercised by the first test file (the statements at lines [1], [2], and [3]) arc \nnot affected by the changes to the pro\u00adgram, it is not necessary to run Version 2 using the ftrst test \nfile in order to test the modified program. 0 In this paper we propose techniques to address the prob\u00adlems \nof incremental testing. In particular, we discuss how to identify which components of the modified program \ncan be tested using files from the old test suite, and @ which components have b&#38;m affected by the \nmodification. Given this information, retesting can prcaed more quickly: the potentially time consuming \ntask of creating new test files can be reduced or eliminated, and unproductive retest\u00ading of unaffected \ncomponents can be avoided. Although precise answers to the two questions listed above are, in general, \nundecidable, we propose the use of program dependence graphs and program slicing to pro\u00advide safe approximations. \nThis approach leads to more pre\u00adcise results than have been achieved by previous work in the area of \nincremental testing [12,27,33]. In particular, previous work has suffered from two shortcoming (1) previous \ntechniques for matching components of the modified program with test files from the old test suite may \nnot correctly handle multiple program modifications. In the presence of multiple modifications, those \ntechniques may match a com\u00adponent of the modified program with an old test file that fails to test the \ncomponent. (2) By using a syntactic rather than a semantic definition of affected component, previous \ntechniques may fail to identify components that have been transitively affected by modifications elsewhere \nin the program.  The work presented here avoids these shortcomings. The remainder of the paper is organized \nas follows: Sec\u00adtion 2 provides background material, including the definitions of program dependence \ngraphs, program slicing, and adequacy criteria based on program dependence graphs. Section 3 addresses \nthe two issues listed above Section 3.1 describes how to determine which com\u00adponents of the modified \nprogram can be tested using files from the original test suite (and which com\u00adponents might need new \ntest files);  Section 3.2 defines what it means for a program com\u00adponent to be affected by a mo&#38;ftcation \nand discusses how to identify affected components.  The techniques described in Section 3 assume that \nall state\u00adments is the criterion of interes~ Section 4 discusses how to apply these techniques to other \nadequacy criteria, and applies them to the all-flow-edges criterion. Section 5 com\u00ad pares our approach \nto previous work; Section 6 summarizes our results. 2. BACKGROUND 2.1. The Program Dependence Graph To \nsimplify our presentation, we restrict our attention to programs written in a language with the following \ncharac- Version 1 Version 2 program main@le) program mairt(@le) begin begin [1] read~, N) [1] read~, \nN) [2] ifNc1 then [2] ifNcl then [3] write( erro~ input< l ) [3] Write( errm input<l ) [4] else [4] else \n[5] i:=l [5] i:=l [6] oddP := o [7] while i <N do H Esa [8] if odd(i) then [8] while i < N do [9] oaiiP:= \noaliP*i [9] if odd(i) then . [10] a [10] Oddp . Oddw 1 [11] := i+l [11] else [12] od [12] r131 write(oddP) \n[13] 6 ~14j fi [14] i :=i+l end Figure 1. Two versions of a program. Version 1 is supposed to compute \nthe product of the odd numbers from 1 to N, but in\u00adcorrectly initializes oddP to zero. Version 2 fixes \nthat error and adds the computation of the product of the even numbers. The af\u00adfected statements of Version \n2 with respect to Version 1 are shown in boxes. teristicsl: A program consists of a sequence of one or \nmore statements of the following kinds assignment, read, write, if-then-else, or while-loop. o Expressions \ninclude constants and scalar variables. A program reads from a single input tile, which is named in the \nprogram header. The program dependence graph (PDG) for a program P is a directed graph whose vertices \nare connected by several kinds of edges. The PDG includes a special ENTRY vertex, a vertex for every \nstatement and predicate in P, a vertex that represents the initial opening of P s input file, and, for \nevery read statement, a vertex for each variable into which a value is read. The edges of the PDG represent \nthe program s control and &#38;ta dependence. The source of a control edge can be a predicate vertex, \nthe ENTRY vertex, or a vertex that represents a read statemen~ control edges are labeled either true \nor false. The presence of a control edge from vertex v 1 Techniques have hem proposed to permit program \ndependence graphs to be used to represent programs written in more reatistic tanguages [14, 16, 22]. \nWe use dte simple language descrihcd shove because it per\u00ad mits us to present our ideas on incrcmentat \nprogram testing without having to discuss detsits that are indepertdent of testing. to vertex w means \nthat the program component represented by v controls the execution of the component represented by w \nin the following sensex whenever the component represented by v is evaluated and its value matches the \nlabel on the edge, the component represented by w will eventu\u00adally execute (barring the presence of an \ninfinite loop or an exception such as division by zero); however, if the value does not match the label \non the edge, the component represented by w may never execute (the ENTRY vertex and the read vertices \nare considered to represent pseudo\u00adpredicates that always evahtate to lrue). Control dependence can be \ndetermined for programs with arbitrary control flow [10]; however, for the language under consideration \nhere, these dependence represent the nesting structure of the program: There is a control edge labeled \ntrue from the vertex that represents the predicate of an if-then-else state\u00adment to every vertex that \nrepresents a statement in the then branch of the if, and there is a control edge labeled false to every \nvertex that represents a state\u00adment in the else branch of the if. e There is a control edge labeled truefrom \nthe vertex that represents the predicate of a while-loop to every vertex that represents a statement \ninside the loop. * There is a control edge labeled true from the vertex that represents the predicate \nof a while-loop to itself. There is a control edge labeled truefrom the ENTRY vertex to every vertex \nthat represents a statement that is not inside any if-then-else or while-loop.  There is a control edge \nlabeled true from the vertex that represents a statement of the form read(idl, id2, .... idJ to the vertices \nthat represent idl, id2, .... idn.  We denote a control edge from vertex x to vertex y with labelL byx \n~~ y. There are three kinds of data dependence in a PDG: flow dependence, def-or&#38;r dependence, and \nread dependence. Flow dependence are essentially de~-usechains [1]; that is, there is a flow edge from \nvertex v to vertex w iff all of the following hold: (1) v defines a variable x (2) wusesx (3) there \nis an x-definition-free path in the program s  control flow graph from v to w. We denote a flow edge \nfrom vertex v to vertex w by v +f w. Def-order dependence are included in PDGs to ensure that semantically \ndifferent programs cannot have identical PDGs2. There is a clef-order edge from vertex v to vertex w \n2 Other definitimts of progmnr dependence graphs have included atrfi and oufpuf dependence in place of \n&#38;f-order dependenees [ 10]. with witness vertex u iff all of the following hold3: (1) v and w define \nthe same variabky (2) there is a vertex u that is the target of flow edges from both v and W, (3) there \nis a path in the program s control flow graph from vtow.  We denote a clef-order edge from vertex v \nto vertex w with witness vertex u by v ~a (u,w. Read dependence represent the sequential nature of input \nread from a file. There is a read edge from vertex v to vertex w iff either of the following holds: (1) \nv is the vertex that represents the initial opening of the program s input file, w represents a read \nstttte\u00adment, and there is a read-free path in the program s control flow graph from v to W,or (2) both \nv and w represent read statements, and there is a read-free path in the program s control flow graph \nfrom vtow.  We denote a read edge from vertex v to vertex w by v +, w. Example. The PDGs for the programs \nof Figure 1 are given in Figure 2(a). 2.2. Program Slicing The goal of program slicing (defined by Mark \nWeiser [34]) is to take a program P, a component c, and a set of variables V, and to produce a projection \nof P (by removing some of P s statements) such that both P and the projection compute the same values \nfor all variables in Vat component c when they are run on the same inputs. A slicing algorithm that uses \nPDGs was given by Karl and Linda Ottenstein [28]. This algorithm is slightly more restricted than the \nalgorithm defined by WeiseC programs are sliced with respect to component c and the variables defined \nor used at c rather than an arbitrary set of variables. The Ottensteins algorithm has two steps: Step \n1 takes as input the program s PDG and the vertex v that represents component c. The output of Step 1 \nis the set of PDG ver\u00adtices from which there is a path to v along control artd/or flow edges. Step 2 \ncreates the program projection by removing all components that do not correspond to a vertex identified \nby Step 1. Tom Reps and Wuu Yang defined the PDG slice with respect to a vertex v to be the PDG induced \nby the vertex set identified in Step 1 of the Ottensteins slicing algorithm [31]. They showed that isomorphism \nof PDG slices gttaran\u00adtees equivalent behavior as defined below: 3 This definition of clef-order edges \ndiffers stightly from the cme originally given [13]; however, we have shown that the two definiticms \nare equivalent [3].  lkin Gwoddirl (%iRl4 (a) The PDGs of the progrw of Figure 1. T (b) The slices \nof the two PDCs with respect to Write( ... ) F~ure 2. The PDGs of the two programs of Figure 1 and their \nPDG slices with re.qwet to write ... ). The components that are in the slices have equivalent behaviors \nin the two programs. DEFINITION (statement and predicate behavior). When a program is executed, the behuvwr \nof a statement or predi\u00adcate in the program is the sequence of values that arise at that point during \nthe execution. In particulw for an assign\u00adment statement, the sequence of values assigned to the left\u00adhand-side \nvariable for a read statement, the sequence of values read from the input fil~ for a write statemen~ \nthe sequence of values written to the output for a predicate, the sequence of boolean values to which \nit evaluates. The sequence of values that arise at statement or predicates when program P is executed \nusing input file f is denoted by Pm(s). DEmON (equivalent behavior), Two statements or predicates, s \n~ and S2, in programs P ~ and P2, respectively, have equivalent behuvior iff all of the following hold \n For any input file ~ on which both P ~ and P2 ter\u00adminate normally4, P ~(f)(sl ) = P2~(s2).  For any \ninput file ~ on which neither P ~ nor P2 ter\u00adminates normally, either P 1(f)(s 1) is a prefix of P2(f)(s2), \nor vice versa.  For any input file f on which P ~ terminates normally but P2 does not, P2(f)(s2) is \na prefix of P ~(f)(sl).  4A program fails to ternrina te normally if it executes an infinite luup, or \nan exception such as division by zero. For any input file ~on which P2 terminates normally but P ~ does \nnot, P ~(f)(sl) is a prefix of P2(fl(sJ. THEOREM 2.1 (PDG slice isomorphism guarantees equivalent behavior) \n[31]. Ifs 1 and S2 are statements or predicates (possibly in different programs) such that the PIN slices \nwith respect to the vertices that correspond tos 1 and S2 are isomorphic (where edge type and vertex \nand edge labels as well as graph shape must be preserved by the isomorphism), then s ~ and S2 have equivalent \nbehaviors. Example. Figure 2(a) shows the PDOS of the two pro\u00adgrams from Figure 1; shading is used to \nindicate the vertices that are identified by Step 1 of the Ottensteins slicing algo\u00adrithm when slicing \nwith respect to write( erro~ input<l ), Figure 2(b) shows the PDG slices (the graphs induced by the shaded \nvertices in Figure 2(a)). The two PDG slices tzre isomorphic, and it is clear that the behaviors of the \ncom\u00adponents write( erroc input< l ) are equivalent in the two programs. l 2.3. Defining Adequacy Criteria \nUsing Program Depen\u00addence Graphs As discussed in the Intnxluction, test data adequacy criteria provide \na way to measure how thoroughly a program is tested by a given test suite. An adequacy criterion C is \ndefined by specifying a set of program components, and by defining what it means for a component to be \nexercised when the program is run. A test suite is deemed adequate under criterion C if for every component \nc of the progmm, there is a test f such that when the program is run on r, com\u00adponent c is exercised. \nSome previous work has defined adequacy criteria in terms of a program s control flow graph [19,21]. \nFor example, for the all-statements criterion, a component is a control flow graph node, and a node is \nexercised if the corresponding program statement or prrxlkate is executed. Thus, test suite T meets the \nall-statements criterion if every statement and predicate in the program can be mapped to a test in T \nthat causes it to execute. For the all-branches cri\u00adterion, a component is a control flow graph edge \nwhose source is a predicate node (i.e., an edge labeled either true orfalse), and a component is exercised \nif the corresponding predicate is evaluated and the value matches the edge label. Thus, test suite T \nmeets the all-branches criterion if every predicate in the program can be mapped to two (not neces\u00adsarily \ndifferent) tests in ~ one that causes it to evaluate to true, and one that causes it to evaluate @false. \nMore recently, adequacy criteria have been defined in terms of the program s data flow (clef-use chains), \nwhere uses are divided into two cktww p-uses, uses that occur in predicates, and c-uses (computation \nuses) [23, 26, 29]. For example, for the all-c-uses criterion, a component is a def\u00aduse chain d--w where \nu is a computation use, and a com\u00adponent is exercised if u uses a value that was defined at d, Thus, \ntest suite T meets the all-c-uses criterion if every def\u00adto-c-use chain d+u in the program can be mapped \nto a test in T that causes u to use a value defined at d. The program dependence graph, which includes \nrepresentations of both control and data dependence, can be used to provide a single, unifying framework \nin which to define adequacy criteri~ the vertices and edges of the PDG are the components used in the \ncriteria definitions [4]. For example, for the all-vertices criterion, a component is a PDG vertex, and \na component is exercised if the corresponding program statement or predicate is executed. For the all-jiow-edges \ncriterion, a component is a flow edge v +f w, and a component is exercised if the program state\u00adment \nor predicate that corresponds to w uses a value defined at the program statement that corresponds to \nv. Two adequacy criteria cart be compared by considering the sets of test suites that are adequate under \neach criterion [29]. A test suite that is adequate under one criterion C may also be adequate under another \ncriterion D. If this is true for all C-adequate test suites, then we say that C subsumes D. Two criteria \nare equivalent if each subsumes the other. Subsumption can be used to create hiermhies of criteria. Figure \n3 shows some examples of these hierarchies and afso shows the relationships between criteria defined \nin terms of control flow graphs, data flow, and PDGs. As illustrated in Figure 3, some of the PDG adequacy \ncri\u00adteria are equivalent to criteria previously defined in terms of control or data flow (for example, \nthe all-vertices and all\u00adstatements criteria are equivalent); however, there are some previous criteria \n(for example, the all-c-uses criterion) that have no obvious analog in the PDG. This means that the techniques \ndescribed in this paper may not apply when cri\u00ad kfi M c-uses/ d p-uses/ au ths ftow edger some p-uses \nSom c-uses AI loops branches J1 - ps statements vertieea Control Flow Criteria PDG Criteria Data Flow \nCriteria Figure 3. The relationships between PM eritena and criteria defined in terms of a program s \ncontrol or data flow. teria are used that have no PDG analog. However, we believe that the set of PDG \ncriteria is rich enough to be of practical use in program testing, and that the advantages of being able \nto use the techniques proposed here will outweigh arty disadvantages of using PDG criteria. 3. TESTING \nA MODIFIED PROGRAM We now turn to the problem of testing a program after it has been changed. In this \nsection, we assume that the adequacy criterion of interest is all-vertices (equivalently, all\u00adstatements). \nSection 4 discusses how to extend our tech\u00adniques to the PDG edge adequacy criteria. Ideally, after modfying \na program, one would like to create an adequate test suite for the modified program (reus\u00ading as many \nold tests as possible), and to run the program on all of the tests in this suite. However, it may be \ntoo expensive to run all the tests, Therefore, a reasomble goal is to run enough tests to guarantee that \nevery affected state\u00adment of the modified program is exercised (by definition, a statement is affected \neither if it is a new statement or if its behavior differs from the corresponding statement of the original \nprogram5). In this case, if a reused test is only known to test unaffected statements, that test should \nnot be rerun. Given the goal discussed above, the following process can be used to test a modified program: \n(1) A subset of the original test suite is identified for use in exercising statements of the modified \npro\u00ad %is definition of an sffected statement requires being able to map a stste\u00ad ment of the modified \nprogram to the corresponding statement of the origi\u00ad naf program. In practice, this map could he defined \nby applying a syntac\u00ad tic matching algorithm to the two programs, such as that of [35], or by us\u00ad ing \na special editor that keeps track of statement eorrwspondenee as the program is modified. Such an editor \ncan be created using systems such as MENTGR [9], GANDALF [25], and the Synthesizer Generator [30]. Wtm \n(Mk is discussed in StxXion 3.1). (2) A subset of the tests selected in Step 1 is identified for use \nin exercising @ected statements (thk is dis\u00adcussed in Section 3.2). (3) The programmer runs the modified \nprogram on the tests selected in Step % when the program is run, a record is kept of the statements that \nactually were exercised. (4) The programmer creates new tests for the affected statements of the moditied \nprogram that were not exercised by the reused tests (for example by using the techniques for test data \ngeneration proposed in [7,8,20]).  3.1. Selecting Tests that Exercise Components of New LetOld be a \nprogram and New be a variant created by modifying Old. Assume that T is a statement-adequate test suite \nfor Old. For each test t of T, we assume that Old has been run on t,and that the statements exercised \nby thave been gathered in a set s,; since T is statement-adequate, every statement of Old is in at least \none of these sets. To identify the tests in T that will exercise the statements of New, we group the \nstatements of Old and New into equivalence classes called executwn clu.wes such that all statements in \nthe same class have equivalent execution pat\u00adterns, defined as follows: DEFINITION (equivalent execution \npatterns). If s 1 and S2 are statements of P 1 and P2, respectively, s 1 and S2 have equivalent execution \npatterns iff all of the following hold (i) For any input file on which P ~ and P2 both terminate normally, \ns 1 and S2 are exercised the same number of times (ii) For any input file on which P ~ terminates normally \nbut P z does not, S2 is exercised at most as many times ass 1 is exercisd,  (iii) For any input file \non which P2 terminates normally but P ~ does not, s, is exercised at most as many times as sz is exercised. \nConsider statements S1 and S2 in programs Old and New, respectively, such thats 1 and S2 are in the same \nexecution class. There is a test t that exercisess 1, since T is statement adequa~, thrthermore, sinces \n1 and S2 are in the same exe\u00adcution class, S2 is also exercised by t(provided that New terminates normally \non t). Any class that contains state\u00adments of both Old and New will thus provide tests for the statements \nof New in the class. To provide an algorithm for partitioning the statements of Old and New into execution \nclasses, we define a new kind of slice called a control slice: DEFINITION (control slice). A control \nslice of a PDG G with respect to a vertex v is the PDG slice of a PDG G with respect to v , where (i) \nG contains all the vertices of G, plus a new unlabeled vertex v ; (ii) G contains all the edges of G, \nplus new edges (p+gv lp+gv): That is, to take a control slice with respect to vertex v, create anew vertex \nv with the same control predecessors as v but with no flow predecessors, and take the PDG slice with \nrespect to v . The following lemma demonstrates that control slice iso\u00admorphism provides a safe criterion \nfor partitioning state\u00adments into execution classes. LEMMA 3.1. If the statements of programs P 1 and \nP2 are partitioned into classes based on control slice isomo~hism, then all the statements in each class \nhave equivalent execu\u00adtion patterns. PROOF. Let G1 and G2 be the PDGs of P1 and P2, respec\u00adtively, and \nlet v 1 and V2 be vertices in G 1 and G2, respec\u00adtively, whose control slices are isomorphic. There are \ntwo cases to conside~ v 1 and V2 am while-loop predicates, and v 1 and V2 are any other type of vertex \n(it is impossible for v 1 to be a while-loop predicate if v z is not, or vice versa, because in that \ncase they would have non-isomorphic con\u00adtrol slices). If V1 is a while-loop predicate, G 1 contains a \ncontrol edge v 1 +$ v 1; hence G contains a control edge v* +: v . Therefore the control slice of G ~ \nwith respect to v 1 contains the PDG slice of G 1 with respect to v 1, and similarly for v z. Furthermore, \nthe PDG slice of G 1 with respect to v 1 is isomorphic to the PDG slice of G2 with respect to v z. Hence \nv 1 and v z have equivalent behavior. It is clear horn the definitions that vertices with equivalent \nbehavior have equivalent execution patterns, so we are done. Now suppose v ~ and V2 are not while-loop \npredicates. Let w 1 and w z be the control predecessors of v 1 and V2 with labels L 1 and L2, respectively; \nthen L l=L z and the PDG slice of G ~ with respect to w ~ is isomorphic to the PDG slice of G2 with respect \nto W2. By Theorem 2.1, the predicates w 1 and W2 have equivalent behavior. We Figure 4. Control slice \nof Version 1 with respect to oddp := O snd of Version 2 with respect to evenp := l . %s set can containzero, \none, or two edgw, the EWRY vertex has no cmtrol predeeeasors, a venex that represents a while-loop predicatehas \ntwo eootrol predwessors, and slt other vertiees have exactly one amtml predecessor. VERSION 1 VERSION \n2 Figure 5. The statements in the programs of Figure 1 partitioned into is the set of tests that exercise \nthe statements in that class. demonstrate that parts (i) and (ii) of the definition of equivalent execution \npatterns are satisfied; part (iii) follows by symmetry from part (ii). (i) Let tbe a test on which Imth \nP ~ and P2 haI~ then P ~(t)(w ~) = Z 2(t)(w2). The vertex v 1 is exercised exactly once for every occurrence \nof L 1 in the sequence P 1(r)(w 1), since P 1 halts (and similarly for vertex V2 in P2). Since P 1(t)(w \n1) = P2(t)(w2), t exercises v 1 and v z the same number of times.  (ii) Let f be a test on which P \n~ hrdts but P2 does no~ then P2(t)(wJ is a prefix of PI (t)(wl). LetL2 occur n times in P 2(t)(w2); v \nz is exercised at most n times. Since P ~(t)(wz) is a prefix of P ~(t)(wl ), L ~ occurs at least n times \nin P ~(t)(w ~); P ~ halts, so v 1 is exer\u00adcised at least n times. Thus v z is exercised by r at most \nas many times as v 1 is exercised by t. l  Example. Figure 4 shows the PDG that is the control slice \nof Version 1 with respect to the statement oddp :=Q this PDG is also the control slice of Version 2 with \nrespect to the statement evenp :=1 . Because the two statements have the same control slice, they are \nin the same execution fi classes based on control slice isomorphism. Lkted above each class class (and \nare exercised by the same set of tests). Figure 5 shows all of the statements of Version 1 and Version \n2 par\u00ad titioned into classes based on control slice isomorphism. For each class, the tests that exercise \nthe statements of Ver\u00ad sion 1 that are in the class are tisted, these tests will atso exercise the statements \nof Version 2 that are in the same class. Notice that the class containing evenp :=evenP*i contains no \nstatement of Version 1; hence the technique finds no test in T to exercise evenP :=evenP*i . (In fact, \nthe test 2 will exercise the statement evenP :=evenP*i. This will be discovered if the programmer uses \nthe retesting process given at the beginning of Se&#38;on 3.) l An algorithm for determining which tests \nin T can be used to exercise statements in New is given in Figure 6. The first step, partitioning the \nstatements according to con\u00ad trol slice isomorphism, can be done in (expected) time pro\u00ad portional m \nthe sum of the sizes of the statements control slices [17]. One of the inputs to the algorithm is a function \n foti mapping each statement of Old to the set of tests in T thatexercise ic this function can be constructed \nfrom the sets St mentioned above. The output of the algorithm is a function f~W mapping each statement \nof New to a set of function IdentifyReusableTeats( Old, New : progrm, f..: map of statements of Old \nto sets of tests in T) returns map of statements of New to sets of testa in 2 beght partition the statements \nof Old and New into classesbased on control slice isomorphiam for each statements of New do f~ew(s) \n:= 0 for each statement s of Old in the same class ass do add the tests in fou(i) to fNew(s) endfor \nendfor return fNew end Figure 6. Algorithm for determining which tests can be reused. tests in T that \nwill exercise it (provided New halts on the test). The algorithm also identifies statements that may \nrequire new tests to be create@ namely, those statements that are mapped to the empty Set by fNw. 3.2. \nDeciding Which Tests to Rerun The techniques of the previous section will match some statements of New \nwith each reused test. In this section we describe how to select a subset of the teused tests to be rerun; \na testis selected only if it is identified as exercising a potentially affected statement of New. DEFtNITION \n(affected statements). A statement $ of New is aflected iff one of the following holds: (1) there is \nno corresponding statement in 014 or (2) the behavior of s in Old is not equivalent to the behavior \nofs in New.  As discussed in Section 2.2, if the PDG slices with respect to statements s 1 and S2, in \nprograms Old and New respec\u00adtively, are isomorphic, then S1 and S2 have equivalent behavio~ therefore, \nwe can use isomorphism of PDG slices to identify unaffected statements of New. The reused tests that \nare selected to be rerun are those that are matched with statements of New that have no corresponding \nstatement in Old or whose PDO-slice is not isomorphic to the PDG-slice of the corresponding statement \nof Old. Figure 7 gives an algorithm for selecting tests to rerun. Using the techniques of [17], isomorphism \nof two PDG\u00adslices can be determined in worst-case time proportional to the size of the smaller of the \ntwo slices. Thus, in the worst case, the time required for the algorithm of Figure 7 is pro\u00adportional \nto the number of statements in New, plus the sum of the sizes of the slices with respect to statements \nof New that have a corresponding statement in Old. Examt)le. Fimre 1 shows the statements of Version \n2 that are id&#38;tified-as affected with respect to Version 1. State\u00ad ments evenP :=1 , 6evenP :=evenP*i \n, and function IdentifyTestsToRerun( Old, New : ~Ogr=, fN.w: map of statements of New to sets of tests \nin T) retuma setof testato rerun declare aflited setof statements of New begin /*Step 1:Identify (asuperaetof) \ntheaffected statementsofNew*/ Rerun:= 0 for each statements of New do ifs has no corresponding statement \nin Old then adds to c#ected etse lets be the statement of Old that corresponds tos in if the PDG slice \nof New with respect tos is not isomorphic to the PDG slice of Old with respect to s then adds to affected \nendif endlet endlf end for /*Step 2 Identify reused tests that are known to test a statement of New \nin @ectefl/ Rerun:= 0 for every statements of New do ifs is in affected then add the tests in fNew(s) \nto Rerun end if endfor return Rerun end Ftgure 7. Algorithm for determining which reused tests should \nbe remn. write(evenP) are identified as affected because they have no corresponding statements in Old \nstatements oddP :=1 , oddP :=o(MPW, and write(oddP) are identified as affected because their PDG slices \nare not iso\u00admorphic to the PDO slices of the corresponding statements of Old (in particular, the PDG \nslices in Old include the ver\u00adtex oddP :=0 , while the PDG slices in New include the vertex oddP:= l \n). (h this example, PDO-slice isomor\u00adphism can be used to identify the affected statements of New exuctly; \nin general, this technique may identify as affected some statements whose behaviors are in fact equivalent \nto the corresponding statements of Old.) Figure 5 shows that affected statements oddP :=1 , evenP :=1 \n, oddP z=oddP*Y, write(oddP) and write(evenP) are exercised by the test 2 , so this test should be rerun. \nThe test O exercises only unaffected statements, so it need not be rerun. l 4. APPLICATION TO PDG EDGE \nADEQUACY CRI- TERIA The techniques described in Section 3 can be applied to the PDG edge criteria as \nwell as the all-vertices criterion. As an example, we describe how to define the all-flow-edges criterion \nand how to apply the techniques to incremental testing with respect to i~ the application of the techniques \nto the all-control-edges criterion is discussed in [2]. First, we must we define several fundamental \nconcepts about the execution and behavior of a flow edge; in what follows, we explain each concept and \ngive its definition for the all\u00adflow-edges criterion. The first concept that is rt@red is the definition \nof what it means to exercise a flow edge. A vertex is exercised by a test if the program execution on \nthe test includes an instance of the statement corresponding to the vertex. A flow edge x +fy comsponds \nto one or more paths in the control-flow graph beginning with x defining a variable v, ending with y \nusing v, and containing no other definition of v along the path. The edge is exercised by a test if the \npro\u00adgram execution includes an instance of at least one of the paths corresponding to the flow edge. \nThe program execu\u00adtion may include several instances of v-definition-free paths from x to y; the flow \nedge is exercised once for each such instance. In addition, the algorithm IdentifyReusableTests relies \non a method for identifying classes of components that have equivalent execution patterns. Section 3.1 \nshowed that comparison of control slices can be used to group ver\u00adtices into the appropriate classes. \nAlthough the definition of equivalent execution patterns was given in Section 3.1 in terms of statements, \nthe definition extends to any program component for which a definition of the component s being exercised \ncan be given. We now define the control slice of a PDG with respect to a flow edge so that comparison \nof control slices can also be used to group flow edges that have equivalent execution patterns. The definition \nis motivated by the following observation: the edge x +f y is not exercised if x or y is not exercised, \nor if at least one instance of a definition of v is exercised after every instance of x and before every \ninstance of y. G G DEmoN (control slice with respect to a flow edge). The controf slice of a PDG G with \nrespect to a flow edge e =x +fy is the PDG slice of a PDG G with respect to y , where (i) G contains \nall the vertices of G, plus unlabeled ver\u00adtices x ,y and, for every vertex z such that x -j&#38;~, z, \nan unlabeled vertex Z ;7 (ii) G contains all the edges of G, plus the edges +Lx) u {q-+: y iq+gy] u \n [; :[; ;;+fz ) u {X +fy lx+fy ) u {Z +fy lz+;y) u {x +* fy)z ). That is, to take the control slice \nwith respect to edge e=x +f y: (1) create new vertices x , y , and z (where z is the target of a clef-order \nedge from x with witness y) that have the same control predecessors as their counterparts but no flow \npredecessors; (2) create edges among x , y and z that parallel the edges among their counterparts; and \n(3) take the PDG slice with respect to y . Figure 8 shows the construction of G . Isomorphism of control \nslices provides the partitioning method required, as the following theorem shows. THEOREM 4.1. If the \nflow edges of P ~ and P2 are parti\u00adtioned into classes based on control slice isomorphism, then all the \nflow edges in each class have equivalent execu\u00adtion patterns. Proof sketch. Let e ~=xl +f y, and e2=x2 \n+f y z be flow edges on a variable v with isomorphic control slices. The following conditions are sufficient \nto conclude that e ~ and e z have equivalent execution patterns: (i) corresponding endpoints of the edges \nhave equivalent execution patterns; (ii) corresponding definitions of v that cccur on control flow graph \npaths from xl toy ~ (from X2 toy z) have  g .....y.$3-&#38;&#38;3  Figure 9. Control slice of Versions \n1 and 2 with respect to the Figure 8. Graph tnnsformation used in defining the control slice flow edge \nodd :=oaiff i -+fwrite(odd). with respect to the edge x -+fy. Each clef-order edge is labeled with its \nwitness vertex. 7S0meof theseverticesmaybethe samq for instance,if x=y, theni+. equivalent execution \npattemv (iii) if both programs halt on a test, then there is an occurrence of the pattern x 1...y 1 \nin P 1 s execution mace iff there is a corresponding occurrence of the pattern x2...y2 in P2 s execution \ntrace, and corresponding instances of the patterns occur in the same order in the two trace.y (iv) corresponding \ninstances of the patterns xl ...y 1 and x2...y z both contain an instance of a definition of v or neither \ndoes; (v) if one of the programs does not terminate on a test, the sequence of instances of the pattern \nin the nonter\u00adminating program s execution trace is a prefix of the sequence of instances of the corresponding \npattern in the terminating program s execution trace.  The proof involves showing that if e 1 and e \nz have iso\u00admorphic control slices, then conditions (i)-(v) hold. The full proof appears in [2]. Example. \nFigure 9 shows the control slice of Version 1 with respect to the flow edge from oddp :=oddP*i to write(oddP); \nit is also the control slice of Version 2 with respect to the same flow edge. Hence these edges have \nequivalent execution patterns and are both tested by the test 2 . 1 The algorithm IdentifyTestsToRerun \nrelies on the identification of affected components in the modified pro\u00adgram. The definition of affected \ngiven in Section 3.2 depends on the concept of equivalent behavior. Thus we need to define the behavior \nof an edge. In Section 2.2, the behavior of a vertex is defined to be the sequence of values computed \nat the vertex. We define the behavior of a flow edge similarly as the sequence of values that flow along \nthe edge. A value V flows along an edge if the variable defined at the source of the edge gets value \nV, and a definition-free path is traversed during execution to the target of the edge. The definition \nof equivalent behavior given in Section 2.2 then applies to flow edges as well as to statements and predicates. \nWe also need a safe way to identify components with equivalent behavio~ this allows us to identify (a \nsuperset of) the components that are affected. Section 3.2 showed that comparison of PDG slices can be \nused to identify ver\u00adtices whose corresponding statements have equivalent behavior. We now define a PDG \nslice with respect to a flow edge in order to get a similar result. DEmoN (PDG slice with respect to \na flow edge). The PDG slice of a PDG G with respect to a flow edge e =x +fy is the PDG slice of a PDG \nG with respect toy , where (i) G contains all the vertices of G, plus an unlabeled vertex y and, for \nevery vertex z such that x +a ~) Z, an unlabeled vertex z ; (ii) G contains all the edges of G, plus \nthe edges  {q+~y lq+~y) u {r+~z lr+~z) u u {Z +fy lz+fy) u (x+fY lx+fY 1 {x+&#38;~~z ).  Figure 10 \nshows the construction of G . Isomorphism of PDG slices provides a safe way to identifj flow edges with \nequivalent behavior, as the following theorem shows. THEOREM 4.2. If P 1 and P z are programs and e 1 \nand ez are flow edges in the PDGs Gp, and GP2, respectively, such that the PDG slices with respect to \ne 1 and e z are iso\u00admorphic, then e 1 and e2 have equivalent behavior. Proof skefch. There are two parts \nto the proof (i) Show that e ~ and e ~ have equivalent execution pat\u00adtem~ and (ii) Show that identical \nvalues flow along the edges in corresponding instances.  Let el=xl +f y I and ez=xz +f Y2. The PDG slice \nwith respect to a flow edge contains the control slice with respect to the edge; hence the control slices \nwith respect to G G  qy...&#38;3.&#38;3 u Figure 10. Graph transformation used in defining the PDG \nslice Figure 11. PDG slice of Version 2 with respect to the flow edge with respect to x+, y. Each &#38;f-order \nedge k labeled with its * :-#*i +fwrite(oddP). witness vertex. e 1 and e2 are isomorphic. By Theorem \n4.1, e 1 and e2 have equivalent execution patterns. Furthermore, proper\u00adties (iii)-(v) in the proof of \nTheorem 4.1 hold. Hence corresponding instances of the patterns x 1...y 1 and x2...y z contain corresponding \ninstances of x 1 and X2. The PDG slice with respect to a flow edge also contains the PDG slice with respect \nto the source of the edg~ the isomorphism of the flow-edge PDG slices implies that x 1 and X2 have isomo~hic \nPDG slices. By Theorem 2.1, x 1 and X2 have equivalent behavior. Hence corresponding instances of x 1 \nand X2 compute the same value. Since the value that flows along e 1 (respectively, e z) is defined by \nx 1 (respectively, X2), identical values flow along the edges in corresponding instances. 0 Example. \nFigure 11 shows the PDG slice of Version 1 with respect to the flow edge from oddP :=oddP*i to write(oddP); \nit differs from the PDG slice of Version 2 with respect to the same flow edge in the initial definition \nof oddP. Hence the edge is identified as affected. It does in fact have different behavior from the corresponding \nedge in Version 1; on the test 2 , the value O flows along the edge in Version 1, but the value 1 flows \nalong the edge in Version 2. l To summarize Recall that an adequacy criterion is defined by specifying \na set of program components and defining what it means for a component to be exercised, To permit the \nretesting techniques presented in Section 3 to apply to a new adequacy criterion, one must also define \n(1) a method for grouping components with equivalent execution patterns (2) the behavior of a componen~ \nand (3) a method for identifying components with equivalent behavior.  We have given these definitions \nfor the all-flow-edges cri\u00ad terion, and have demonstrated that the definitions satisfy the required properties. \n5. RELATED WORK The work presented here makes contributions in two areas by addressing the problems of \nincremental program testing with respect to an adequacy criterion, and by defining three new kinds of \nPDG slice (the control slice with respect to a vertex and a flow edge, and the PDG slice with respect \nto a flow edge). Accordingly, there are two kinds of related work. In the area of incremental testing, \nprevious work has used the idea of identifying affected clef-use pairs as an aid to selecting tests for \nregression test\u00ading. Taha, Thebaut, and Liu [33] describe a method using incremental data flow analysis \nto partition a test suite for a program into three sets that are relevant for a modification of the program: \nthe retestable test cases, which exercise changed paths in the program; the reusable fesf cases, which \nexercise unchanged paths in the program; and the obsolete test cases, which are not valid for the modified \nprogram. Ostrand and Weyuker [27] present a similar method of determining the clef-we associations that \nare affected by a program change, and use the results to decide which tests of an adequate test suite \nneed to be rerun and which clef-use associations require new tests. Harrold and Soffa [12] use incremental \ndata flow analysis to identify affected clef-use pairs and to select tests for retesting these pairs. \nNone of the three techniques precisely defines what it means for a flow dependence to be affected. AU \nthree tech\u00adniques identify as affected only those flow dependence for which either the definition or \nthe use has undergone an editing chang~ they fail to take into account changes that transitively affect \na flow dependence. Furthermore, multi\u00adple editing changes to the program can cause the tech\u00adniques to \nselect tests for retesting that do not exercise the flow dependence that they are intended to test. In \ncon\u00adtrast, our techniques for incremental testing, when applied to the all-flow-edges criterion, take \ninto account the transi\u00adtive effects of a modification, and identify a superset of the affected flow \ndependence identified by the three tech\u00adniques. Also, our techniques guarantee that a test selected to \nexercise a component does in fact exercise it, provided that the program terminates. A by-product of \nour work on incremental program test\u00ading is a technique that groups program components for cov\u00aderage \nby a single tes~ there has been other work on developing such techniques. Gupta and Soffa [11] order \nprogram statements and clef-use pairs using the postdomi\u00adnance relation on the control-flow graph; the \nordering is used to guide the generation of tests for a test suite ade\u00adquate under the all-statements \nor alldef-use-pairs criterion. Chusho [5,6] defines an ordering of control flow graph edges based on \nexecution bchavio~ a primitive edge is one for which no other edge s execution guarantees its execu\u00adtion. \nHe then presents an algorithm for reducing the con\u00adtrol flow graph by combining each non-primitive edge \nwith the primitive edge that guarantees its execution. A test that exercises a primitive edge e is guaranteed \nto exercise the non-primitive edges associated with e. In both Chusho s and Gupta and Soffa s work, program \ncomponents are ordered rather than partitioned into equivalence classes; a component that precedes another \nin the ordering will be exercised if the latter component is exercised but not necessarily vice versa. \nFurthermore, these techniques will only permit the ordering of components within a single program; our \ntechnique, testing isomorphism of control slices, applies across programs. In the area of PDG slicing, \nSchatz and Ryder [32] define a PDG slice called the condition-preserving slice that is similar to the \ncontrol slice defined here (condition\u00adpreserving slices are used to identify race conditions in a parallel \nprogram). The control slice defined in this paper yields a subgraph of the condition-preserving slicq \nthe latter graph can include flow edges that are not in the con\u00adtnd slice. As a consequence, testing \ncondition-preserving slice isomorphism is a less precise method of partitioning statements into execution \nclasses than testing control slice isomorphism. 6. SUMMARY We have presented techniques that use the \nprogram depen\u00addence graph and PDG slicing to address the problems of incremental testing. We have also \ndefined three new PDG slices, and shown a semantic property for each one the control slice with respect \nto a vertex or a flow edge has the property that two components with iso\u00admorphic control slices have \nequivalent execution pat\u00adterns;  the PDG slice with respect to a flow edge has the property that two \nflow edges with isomorphic PDG slices have equivalent behaviors.  The algorithms of Figures 6 and 7 \ncan be used to auto\u00admate the selection of tests for a modified program from an adequate test suite for \nthe originrd program, The first alg~ rithm identities tests that can be reused to test statements of \nthe modified program; the second algorithm identifies a safe approximation to the set of affeeted statements \nof the modified program, and identifies the tests that are guaranteed to exercise those statements. Our \napproach represents an important improvement over previous approaches to incremental testing. The algo\u00adrithms \nused in previous work to match components of the modified program with existing test files can match \na com\u00adponent with a test file that fails to exercise it. Furthermore, because previous algorithms for \nidentifying affected com\u00adponents are based on a syntactic rather than a semantic definition of affected; \nthey may fail to take into account the transitive effects of a modification. ACKNOWLEDGEMENTS We would \nlike to thank Thomas Ball and Paul Adams for their many helpful comments. REFERENCES 1. A. V. Aho, R. \nSethi, and J. D. Unman, Compilers: Princi\u00adples, Techniques, and Tools, Addison-Wesley, Reading, MA (1986). \n 2. S. Bates and S. Horwitz, Incremental Program Testing Using Program Dependence Graphs, technical report \nin preparation, Computer Sciences Department, University of Wiscons~ Madkon, WI (1992). 3. S. Bates \nand S. Horwitz, On Integrating Programs with Inpug in prcparatio~ Computer Sciences Departmen~ University \nof Wisconsin, Mad~on, WI (1992). 4. S. Bates and S. Horwi@ Test Data Adequacy Criteria Based on Program \nDependence Graphs; in preparation, Computer Sciences Departrnen~ University of Wisconsi~ Madwo~ WI (1992). \n 5. T. Chusho, Coverage Measure for Path Testing Based on the Concept of Essential Brancheq Journal of \nInformation Processing 6(4) pp. 199-205 (1983). 6. T. Chusho, Test Data Selection and Quality Estimation \nBased on the Concept of Essential Branches for Path Test\u00ading: IEEE Transactwns on So@are Engineering \nSE\u00ad13(5) pp. 509-517 (May 1987).  7. L. A. Clarke, A System to Generate Test Data and Symbol\u00adically \nExecute Programs, IEEE Transaction on Soj%vare Engineering SE-2(3) pp. 215-222 (September 1976). 8. \nR. A. Dehfillo and A. J. Offit~ Constraint-Based Automatic Test Data Generation IEEE Transactions on \nSojlware Engineering 17(9) pp. 900-910 (September 1991). 9. V. Dottzeau-Gouge, G. Hue~ G. KahtL and \nB. Laug, Pro\u00adgramming environments baaed on structured editors: The MENTOR experience, pp. 128-140 in \nInteractive Progrwn\u00adming Environments, ed. D. Barstow, E. Sandewall, and H. ShrobeJvfcGraw-Hfll, New \nYork, NY (1984). 10. J. Ferrante, K. Ottenstcin, and J. Warren, The program dependence graph and its \nuse in optimizatio~ ACM Tran\u00adsactio~ on Programming Languages and Systems 9(3) pp. 319-349 (kdy 1987). \n 11. R. Gupta and M. L. Soff% Automatic Generation of a Com\u00adpact Test Suite, Technical Repor~ University \nof Pitta\u00adburgk Pittsbur~ PA (1991). 12. M. J. Harrold and M. L. Soff% An Incremental Approach to Unit \nTesting during Maintenartce, Proceedings of the Conference on So@vare Maintenance (Phoenix, Arizona), \n pp. 362-367 (October 24-27, 1988).  13. S. Horwit.z, J. Prim, and T. Reps, On the adequacy of pro\u00adgram \ndependence graphs for representing programs, pp. 146-157 in Conference Record of the Fifteenth ACM Sympo\u00adsium \non Principles of Programvu ng Languages, (San Diego, CA, January 13-15, 1988), ACM, New York, NY (1988). \n 14. S. Horwi@ P. Pfeiffer, and T. Reps, Dependence analysis for pointer variables, Proceedings of the \nSIGPLAN 89 Conference on Programming Language Design and Imple\u00admentation, (Portland, OR, June 21-23, \n1989), ACM SIG-PLAN Notices 24(7) pp. 28-40 (July 1989). 15. S. Horwitz, J. Prins, and T. Reps, Integrating \nNoninterfer\u00ading Versions of Prograsns, ACM Transactions on Program\u00adming Languages and Systems 11(3) pp. \n345-387 (July 1989). 16. S. Horwit~ T. Reps, and D. Bintdey, Interprocedural slic\u00ading using dependence \ngraphs, ACM Transactions on Pro\u00adgramming Languages and Systems 12(1) pp. 26-60 (January 1990). 17. S. \nHorwitz and T. Reps, Efficient comparison of program slices, Acts Informatica 28 pp. 713-732 (1991). \n 18. W. E. HowderL Reliabtiity of the Path Analysis Testing Strategy, IEEE Transactions on Software Engineering \nSE\u00ad2(3) pp. 208-215 (September 1976). 19. J. C. Huang, An Approach to Program Testing, ACM Computing \nSurveys 7(3) pp. 113-127 (September 1975). 20. B. Korel, Automated Softw~e Test Data Generation: IEEE \nTrarwactions on Sofiare Engineering 16(8) pp. 870-879 (August 1990). 21. K. W. Krause, R. W. Smith, \nand M. A. Goodwin, Optimal Software Test Planning Through Automated Network Anatysis/ Record of the 1973 \nIEEE Symposium on Com\u00adputer So~are Reliability (New York New York), pp. 18-22 (April 30-May 2, 1973). \n 22, J. Lams and P. Hilfinger, Detecting confticts between struc\u00adture accesses? Proceedings of the ACM \nSIGPLAN 88 Cor$erence on Programming Language Design and Imple\u00admentation, (Atlant% GA, June 22-24, 1988), \nACM SIGPLAN Notices 23(7) pp. 21-34 (June 1988). 23. J. W. Laski and B. KoreL A Data Flow Oriented Promam \nTesting StrategyV IEEE Transactions on So~are Engineering SE-9(3) pp. 347-354 (May 1983). 24. B. Marick, \nA Survey of Test Effectiveness and Cost Stu\u00addies, Report No. UIUCDCS-R-90-1652, Department of Computer \nScience, University of Illinois at Urbana-Champaign, Urbana IL (December 1990). 25. D. Nod@ R. EllisotL \nB. Stand~ G. Kaiser, E. KanL A. Haberrnarm, V. Ambriol% and C. Montangero, Special issue on the GANDALF \nprojec~ Jourtud of Systems and Sojiware 5(2)(May 1985). 26. S. C. Ntafos, On Required Element Testing: \nIEEE Tran\u00adsaction on SoJiware Engineering SE-10(6) pp. 795-803 (November 1984). 27. T. J. Ostrand and \nE. J. Weyuker, Using Data Flow Analysis for Regression Testing: Proceedings of the Sixth Annual Pactj \nic Northwest Software Quality Co@erence (Portland Oregon), (September 19-20, 1988). 28. K. Ottenstein \nand L. Ottenstek The program dependence graph in a softswmedevelopment enviromnent~ Proceedings of theACM \nSIGSOFTISIGPLAN So@are Engineering Symp\u00adosium on Practical So~are Development Environments, (Pittsburgh, \nPA, Apr. 23-25, 1984), ACM SIGPLAN Notices 19(5) pp. 177-184 (May 1984). 29. S. Rapps and E. J. Weyuker, \nSelecting Software Test Data Using Data Flow l.nformatio~ IEEE Trarwactions on Sojhvare Engineering SE-11(4) \npp. 367-375 (April 1985). 30. T. Reps and T. Teitelbaum, The Synthesizer Generator: A system for constructing \nlanguage-based editors, Springer-Verlag, New York, NY (1988). 31. T. Reps and W. Yang, The semantics \nof program slicing and program integration, pp. 360-374 in Proceedings of the Colloquium on Current Issues \nin Programnu ng Languages, (Barcelon% Spain, March 13-17, 1989), Lecture Notes in Computer Science Vol. \n352, Springer-Verlag, New York NY (March 1989). 32. E. Schatz and B. G. Ryder, Directed Tracing to Detect \nRace CondkionsV LCSR-TR-176, Laboratory for Computer Science Researc~ Rutgers University, New Bmnswick, \nNJ (February 1992). 33. A. Tah~ S. M. Thebau~ and S. Liu, An Approach to Software Fault Localization \nand Revalidation Based on Incremental Data Flow Analysis, Proceedings of the Thir\u00adteenth Annual Internatwnal \nComputer Software &#38; Applica\u00adtions Co~erence (Orlando, Florida), pp. 552-558 (Sep\u00adtember 20-22, 1989). \n 34. M. Weiser, Program Slicing, IEEE Transactions on So@are Engineering SE-10(4) pp. 352-357 (July 1984). \n 35. W. Yang, Identifying syntactic dtiferences between two programs, So#ware Practice &#38; Experience \n21(7) pp. 739-755 (July 1991).  \n\t\t\t", "proc_id": "158511", "abstract": "<p>Program dependence graphs have been proposed for use in optimizing, vectorizing, and parallelizing compilers, and for program integration. This paper proposes their use as the basis for <italic>incremental program testing</italic> when using <italic>test data adequacy criteria</italic>. Test data adequacy is commonly used to provide some confidence that a particular test suite does a reasonable job of testing a program. Incremental program testing using test data adequacy criteria addresses the problem of testing a modified program given an adequate test suite for the original program. Ideally, one would like to create an adequate test suite for the modified program that reuses as many files from the old test suite as possible. Furthermore, one would like to know, for every file that is in both the old and the new test suites, whether the program components exercised by that file have been affected by the program modification; if no components have been affected, then it is not necessary to rerun the program using that file.</p><p>In this paper we define adequacy criteria based on the program dependence graph, and propose techniques based on program slicing to identify components of the modified program that can be tested using files from the old test suite, and components that have been affected by the modification. This information can be used to reduce the time required to create new test files, and to avoid unproductive retesting of unaffected components. Although exact identification of the components listed above is, in general, undecidable, we demonstrate that our techniques provide safe approximations.</p>", "authors": [{"name": "Samuel Bates", "author_profile_id": "81100271048", "affiliation": "", "person_id": "P259150", "email_address": "", "orcid_id": ""}, {"name": "Susan Horwitz", "author_profile_id": "81100357689", "affiliation": "", "person_id": "PP39039239", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158694", "year": "1993", "article_id": "158694", "conference": "POPL", "title": "Incremental program testing using program dependence graphs", "url": "http://dl.acm.org/citation.cfm?id=158694"}