{"article_publication_date": "03-01-1993", "fulltext": "\n COMPLEXITY OF BIDIRECTIONAL DATA FLOW ANALYSIS Dhananjay M. Dhamdhere Uday P. Khedker dmd(llcse.iitb.ernet.in \nuday@cse.iitb.ernet.in Department of Computer Science and Engineering Indian Institute of Technology, \nBombay, 400076. Abstract The concept of an information j70w path arising from the generalized theory \nof data flow analy\u00adsis [21] is used to analyze the complexity of data flow analysis. The width (w) of \na program flow graph with respect to a class of data flow prob\u00adlems is introduced as a measure of the \ncomplexity of round-robin iterative analysis. This provides the first known complexity result for round \nrobin iterative analysis of bidirectional data flows com\u00admonly used in algorithms based on the suppression \nof partial redundancies [6, 7, 8, 9, 17, 18, 25]. We alao show that width provides a better bound on \nthe complexity of unidirectional data flows than the classical notion of depth. The paper presents ways \nto reduce the width, and thereby the complexity of flow analysis, for several interesting problems. Complexity \nanalysis using the notion of width is also shown to motivate ef\u00adficient solution methods for various \nbidirectional problems, viz. the alternating iterations method, and an interval analysis based elimination \nmethod for the partirJ redundancy elimination problems. The paper also presents a condition for the de\u00adcomp \nosabiM y of a bidirectional problem into a se\u00adquence of unidirectional problems. Introduction The data \nflows used in classical code optimization mostly involve unidirectional dependencies, i.e. the data flow \ninformation at a node of the program flow graph is influenced either by its predecessors, or its successors. \nSuch data flows can be readily classified into forward and backward data flows [1]. Bidirectional problems, \nwherein the information at a node depends on its predecessors as well as its successors, arise in several \nPermission to copy without fee all or part of this material is granted provided that the oopies are not \nmade or distributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission of the Association for Computing \nMaohinery. To copy otherwise, or to republish, requires a fee and/or specific permission. ACM-20th PoPL-1 \n/93-S. C., USA @1993 ACM 0-89791 -561 -5/93 /0001 /0397 ...$1 .50 unifications of optimizing transformations. \nThe Morel and Renvoise Algorithm (MRA) for suppression of par\u00adtial redundancies [25], which unifies the \ntraditional op\u00adtimization of code movement, common sub expression elimination and loop optimization; \nand the Composite Hoisting and Strength reduction Algorithm (CHSA) [8, 17, 18], are examples of such \nunifications. Their ap\u00adpeal lies in the reductions in optimizer sizes and running times offered by them. \nClassical work in complexity analysis of data flow problems uses the characteristics of control flow \ngraphs, viz. the number of nodes, edges or back edges in a flow graph, as the basis of the complexity \nstudy. Though bidirectional data flow problems have been known for over a decade, it has not been possible \nto explain their intricacies, or determine their complexities, using the traditional theory of data flow \nanalysis. A generalized theory offering a uniform treatment of the unidirectional and bidirectional problems \nhas shown that the bidirec\u00adtional problems are no more complex than the unidirec\u00adtional problems as far \nas the order of the work involved is concerned [21]. However certain complexity issues, viz. the bound \non the number of iterations in round robin iterative data flow analysis of bidirectional flows, have \nremained un-addressed. In this paper, we use the key concept from the gen\u00aderalized theory of data flow \nanalysis [21], namely the concept of an information flow path, to analyze the com\u00adplexity of data flow \nanalysis. TVe use the nature of an information flow path as the basis for a classification of data flow \nproblems. We then combine the concept of an information flow path with the properties of graph traversals \nto evolve the notion of the width (w) of a pro\u00adgram flow graph with respect to a class of data flow problems. \nThe width is shown to be a measure of the complexity of round robin iterative data flow analysis for \na class of problems. This is the first time a complex\u00adity result has been provided for the round robin \niterative solution of bidirectional data flows. Another significant outcome is the demonstration that \nthe classical bound of d + 1 iterations for the solution of unidirectional prob\u00adlems, where d is the \ndepth of the flow graph, is a loose bound. A tighter bound using the notion of width is provided in section \n3. VVe present ways to reduce the width, and thereby the complexity of flow analysis, for a set of interest\u00ading \nproblems. The study of information flow paths also yields valuable insight into the behaviour of data \nflows, which motivates more efficient techniques for the solu\u00adtion of data flow problems, including bidirectional \nprob\u00adlems. We use this insight to devise efficient methods for the solution of several bidirectional \ndata flow problems, viz. the method of alternating iterations, which is appli\u00adcable to useful variants \nof the partial redundancy elim\u00adination algorithm, and an interval analysis based elim\u00adination method \napplicable to the Morel Renvoise Algo\u00adrithm [25], and the Composite Hoisting and Strength reduction Algorithm \n[8, 17, 18]. The feasibility of decomposing a bidirectional data flow problem into a sequence of cascaded \nunidirectional problems has been the subject of some discussion in the literature [6]. We show that the \nnature of information flow paths is useful in this context as well. We prove a general condition for \nthe feasibility of decomposition and demonstrate its applicability to some interesting bidirectional \nproblems. A brief description of the bidirectional data flow problems referred in this paper is contained \nin the ap\u00adpendix. Section 2 defines the concept of an information flow path, based on which section 3 \ndefines the notion of width. Section 4 relates width to the efficiency of data flow analysis and presents \nseveral methods for efficient data flow analysis of bidirectional data flow problems. Section 5 discusses \nthe feasibility of decomposing a bidi\u00adrectional data flow problem into cascaded unidirectional problems. \nThe concluding section presents experimen\u00adtal results and analyzes their implications. 2 Information \nflow paths 2.1 Traversals Given a depth first spanning tree, we differentiate be\u00adtween back edges and \nnon-back edges; we term the latter as forward edges in this paper.l Thus the term forward edges, as used \nin this paper, includes the conventional notions of forward as well as cross edges [1]. Information flow \nis realized during a traversal. We define the notions of traversal as follows : (i) Edge Traversals : \nForward traversal along an edge is a tail-to-head traversal of the edge, while the backward traversal \nis a head-to-tail traver\u00adsal. 1 We use the terms forward edges and back edge8 as synonyms of advancing \nedges and retreating edges respectively, We prefer the former because it expresses the intuitive. notion \nof direction more clearly. For non-reducible flow graphs, a back edge in this paper means a retreating \nedge. Fe : Forward traversal along an edge B= : Backward traversal along an edge Ff Forward traversal \nalong a forward edge Bf : Backward traversal along a forward edge Fb : Forward traversal along a back \nedge Bb : Backward traversal along a back edge FG : Forward traversal over the graph BG : Backward traversal \nover the graph Figure 1: Notations for traversals (ii) Graph !lkaversals : A forward traversal over \na graph visits the nodes of the graph in a depth first order. A backward traversal visits the nodes in \na reverse depth first order.2 A graph traversal depends on the ordering imposed by a DFS tree while \nan edge traversal does not. Figure 1 summarizes the notations used in this paper. The direc\u00adtion of traversal \nis indicated by B or F with subscript e for the edge traversal and G for the graph traversal. For edge \ntraversal, subscripts f and b are used instead of e if forward and back edges need to be distinguished. \nAn iteration in a round robin iterative analysis re\u00adalizes one graph traversal. 2.2 The notion of information \nflow [21] We restrict our discussion to bit vector problems [15] wherein each bit can be treated independently, \ni.e. the value of a bit i in a bit vector is influenced only by the corresponding bits in other bit vectors \nof the program flow graph. Let TOP and BOT refer to the values of a bit in T and J-bit vectors, respectively. \nA BOT value for a data flow property implies a useful item of information from the viewpoint of data \nflow analysis (viz. a reaching definition), whereas a TOP value implies that such in\u00adformation can not \nbe concluded. For iterative data flow analysis, the data flow properties are initialized to TOP for all \nnodes (except for the graph entry/exit nodes, which may have other values). Some properties change to \nBOT due to the local effect of computations in a node, viz, when a definition is generated, or an expres\u00ad \nsion is killed. In turn, these change the properties of the neighboring nodes to BOT. Definition 1 : \nInformation Flow Information is said to flow from node i to some neighboring node j when a property of \ni, on becoming BOT, causes the corresponding property of j to become BOT. Note that the information flow \nis transitive. Incor\u00adporation of the information flows due to all BOT prop\u00ad 2We assume that a visit to \na node leaves the IN and OUT properties of the node in mutually consistent states. Figure 2: Edge flow \nfunctions erties in the program flow graph leads to a fixed point of the data flow equations [21]. 2.3 \nFlow functions There are two fundamental kinds of flows in a data flow problem : (i) Information flows \nwithin a node, i.e. between the entry and exit of node i : Represented by node jiow functions f(i). \n(ii) Information flows along edge (i, j) : Repre\u00adsented by edge flow functions g(i, j). (Figure 2)  \ngl (i, j) : Information and the entry of j. flow between the exit of i gz(i, j) : Information and the \nexit of j. flow between the exit of i gs(i,,j) i and : Information the entry of j. flow between the entry \nof gA(i, j) : Information i and the exit of j. flow between the entry of The flow functions are superscripted \nby f or b to indicate whether the flow is in the forward or the back\u00adward direction. The flow functions \nare determined di\u00adrectly from the data flow equations governing a problem. If a flow is not present, \nthe corresponding flow function is T. We refer to the functions by their type names f, gl, gz, gs and \ngA respectively with an appropriate su\u00adperscript ~ or b. Table 1 lists the function types for the data \nflow problems defined in the appendix. The edge flow functions of the type gf (g~) are said to be clustered \nif the information flow is identical for all out-edges (in-edges) of a node. 2.4 Information flow paths \nDefinition 2 : Information flow path An information j30w path (ifp) is an allowable se\u00adquence of edge \ntraversals I%, Z2, ...,.% along which in\u00adformation can jlow during data flow analysis. Note that a traversal \nover an edge Si could be a forward or a backward traversal over the graph edge ei. Thus an information \nflow path may not be a graph theoretic path. We represent an ifp p from program point p to a program \npoint q by < p,q,p > where a program point refers to the entry/exit of a basic block. Where convenient, \nwe will represent an ifp simply as a sequence of nodes, leaving the traversal of the edges connecting \nthese nodes implicit. Example 1 : Consider an ~G traversal over the graph Some of the possible ifi s \nare : (i) (1,2,4,5,6) = I ~ F* Ft Ff (ii) (1,2,5, 6)= Fj B~ Ft  (iii) (6,5,3,2, 1) = I?f l?~ Bt B~ \n(iv) (6, 5,2, 1) = Bf F~ B, (V) (3,2,4) = Bj Fj (vi) (3, 5,4) = F~ Bj  c1 Sequences of edge traversals \nalong which informa\u00adtion may not flow can be determined by syntactic cri\u00adteria, i.e. knowing which node \nand edge functions are absent (i.e. = T), as well as semantic criteria, i.e. know\u00ad ing the nature of \nthe actual data flow. Example 2 : Syntactic criteria indicate that the ifp s for the problem of available \nexpressions cannot contain a backward edge traversal (since all the backward edge flow functions are \nT) and the ifp s for MRA cannot con\u00adtain two successive forward edge traversals (since ~f = T). Thus \nifp (i) of example 1 cannot be an ifp for MRA. Example 4 shows how the ifp s of EPA cannot contain two \nbackward edge traversals following a forward edge traversal due to the semantic criteria. 0 For monotone \ndata flows, an ifp is necessarily acyclic. Note, however, that the underlying graph theo\u00adretic path may \nbe cyclic since a node may appear in the path once for its entry point and once for its exit point. Problem \nFunction types Class C Reaching Def. f , 9[ < {OUT}, {f~, gj (1000)} > Live Variables fb> 9; < {IN}, \n{fb, gb(lOOO)} > MRA fb}919{ < {IN}, {~b, gf(lOOO), gb(lOOO)} > LSIA ff,9{,9! < {OUT}, {ff, gb(lOOO), \ngf(lOOO)} > MMRA fb>9L9{,9; < {IN}, {fb, g~(lOOO), g~(OOIO), g&#38;(lOOO)} > EPA fb$9L9! < {IN}, {fb, \ng~(oolo),g~(looo)} > CHSA ff, f*,9!,9{ <{ OUT},{ff, f~, gf(lOOO), gb(lWIO)} > Table 1: Classification \nof data flow problems considered in this paper Example 3 : An ifp (2,5,3,2) = ~b~f~f in the graph of \nexample 1 is a valid information flow path for MRA as PPINz may affect PPOUTZ along such a path. 0 For \nbit vector problems, the most general form of the flow functions is : h(X) = A + -d? c X. The function \nh is called a pre$erve function if h(BOT) = BOT. A preserve function guarantees the propa\u00adgation of information \nunder all conditions. Preserve functions have the form h(X) = X and h(X)= A + X for the union problems \n(here, BOT = 1) and the form h(X) = X and h(X) = -IB . X for the intersection problems (BOT = O). Definition \n3 : Information preserving path An ifp is an information preserving path (ipp) if all jlow functions \nin the ifp are preserve functions. 2.5 Classification of data flow problems A data flow problem is said \nto be non-singular if it in\u00advolves more than one distinct confluence operator. Thus the EPA and MMRA \ndata flow problems of the ap\u00adpendix are non-singular, while all other problems are singular (refer to \nthe appendix for the data flow equa\u00adtions). Data flow problems are classified according to the nature \nof the information flow paths. A class C is a tuple <{path origin}, {flow function types}> where : (i) \nPath origin is a program point represented as IN/OUT.  (ii) The node flow function types are represented \nby f f / f b. Edge flow functions are represented by g(b1b2b3b4) where bi is 1 if the corresponding flow \nfunction is # T. For non-singular data flows, the function name is subscripted by the operator.  Table \n1 contains the classification of the problems referred in the paper. Note the dualism among the classes \nwith respect to the path origin and the func\u00adtion types. For simplicity, we will name the classes by \ntheir representative data flow problems. Hence we will use the names appearing in the first column of \nTable 1 as the class names. The significance of classes lies in the fact that for a given graph, all \nproblems in a class possess similar ifp s and hence obey the same complexity bound. However, using the \nknowledge of a data flow problem it may be possible to develop a more specific definition of its ifp \ns, and hence a more specific bound for it. We define the information flow paths for a data flow problem \n(or a class of data flow problems) by a regular expression over the set of edge traversals. Table 2 con\u00adtains \nthe regular expressions for the data flow problems defined in the appendix. Example 4 below shows how \na more specific regular expression for the ifp s of the EPA data flow problem is obtained from that for \nthe EPA class of data flow problems. Example 4 : Consider the MMRA and EPA prob\u00adlems. MMRA, and other \nmembers of its class, have ifp s which can be represented by the regular expres\u00adsion (Be / Fe)+. The \nifp s of the EPA class of problems are represented by the same regular expression. How\u00adever, the ifi \ns of the EPA data flow problem can be more precisely represented by (Be+ I Fe)(F. *B. I F.*). This is \ndue to the nature of the EPA data flow (eqs. 7, 8 of figure 6), which restricts the backward flow resulting \nfrom the PPIN property turning BOT due to the g! function merely to the OUT property of the predeces\u00adsors \n(since the IN property of the predecessors is already BOT). 0  3 The width of a graph To simplify the \npresentation, we represent the forward and backward directions generically by 6. For example, if 6 is \nthe forward direction, then an F is replaced by 6 while a B is replaced by 6-. Figure 3 summarizes the \ngeneric notation. Thus 6G = FG if the graph traversal visits the nodes of a graph in a depth first order. \nDefinition 4 : Conforming and Non-conforming edge traversals Problem Function types Information flow \npaths pe~Reaching Def. ff $9{ B,+ Live Variables fb, g: MRA  fb19L9{ (Be+(Fe I ~))+ Be* LSIA ff}9{,9i \nF.+((13el e+)* I Be) MMRA fb*9;,9{>9; (Be I F.)+ EPA fb,9L9i (Be+ / F,) I ,*(B, I e) CHSA ff, fb,9!,9{ \nIL(BC I Fe) Table 2: Information flow paths of the data flow problems referred in this paper C$j : Traversal \nalong a forward edge in direction 6 6b : Traversal along a back edge in direction 6 6; : Traversal along \na forward edge in direction 6\u00ad (5; : Traversal along a back edge in direction 6\u00ad 6G : Traversal over \nthe graph in direction 6 6; : Traversal over the graph in direction 6- Figure 3: Generic notation for \nvarious traversals, For a da traversal, d~ and 6; edge traversals are conforming edge traversals while \n6? and 6b are non\u00adconforming edge traversals. It is readily seen that the Jf and 6; traversals are compatible \nwith 6G traversal whereas the 6; and 6b traversals are in the opposite direction. Definition 5 : Span \nA span is a maximal sequence of conforming edge traversals in an ifp. Spans are separated by a non-conforming \nedge traversal and vice-versa. Thus, two successive non\u00adconforming edge traversals have a null span between \nthem. Further, an information flow path may begin and/or end with a null span. The information along \na span can be propagated in one 6G traversal; the same graph traversal also re\u00adalizes the information \nflow along the preceding non\u00adconforming edge traversal. Definition 6 : Segment A segment is a maximal \nsequence of successive edge traversals in the same direction. Successive Fe s constitute a forward segment \nwhile successive Be s constitute a backward segment. A seg\u00adment may be bounded or unbounded. Example \n5 : Consider an FG graph traversal and an ifp ~AA~ Ft F1Ff Fb B/j Ft Bf Bt ~ ~ The underbraces denote \nthe (non-null) spans; over\u00adbraces, segments; and underscores denote the non\u00adconforming edge traversals. \nNote that there is a null span between two successive B~ s. 0 Example 6 : The ifp s of unidirectional \ndata flow problems consist of a single unbounded segment. From table 2, MRA, MMRA, EPA and CHSA have \nunbounded backward segments. MMRA, EPA and CHSA have unbounded forward segments too, while MRA has a \nbounded forward segment. U For an ifi < p, q, p >, let length(p) and width(p) denote the total number \nof edge flow functions and the number of edge flow functions along non-conforming edge traversals, respectively. \nDefinition 7 : Bypassed information flow path An ifp < p, q, pl > is said to be bypassed by <p, q, PZ \n> if the edge functions of p are clustered, and (i) either p, is an ipp or length(p2) =1, and (ii) wid-th(pz) \n< width(pl).  Intuitively, < p, q, PI > is bypassed by < p, q, PZ > if the same information is guaranteed \nto flow along PZ and length(pz ) < length. Such a guarantee can be given only if pz is an ipp or length(p2) \n= 1 and the edge functions are clustered. In practical data flow problems, bypassing usually occurs due \nto lengi!h(pz) = 1. Definition 8 : Width The width w of a graph G for a class of data jiow problems with \nrespect to a traversal 6G is the maximum number of non-conforming edge traversals along an ifpi no part \nof which is bypassed. If we represent the number of spans by s then s = w + 1 for the width determining \npath. Theorem 1 : w + 1 iterations are suficient for the round robin algorithm to converge on a jized \npoint. Proof : The information flow can be initiated only af\u00adter the IN rmd OUT properties of all nodes \nare com\u00adputed to determine the information originating within the nodes. This can be achieved in the \nfirst iteration. The same iteration also realizes the propagation of infor\u00admation along a non-null span \n(if any) at the beginning of an ifp. However, every non-conforming edge traversal, and the span that \nfollows it, requires a separate itera\u00adtion. Thus, w+ 1 iterations are sufficient for information propagation \nalong the width determining path. Now consider an ifp < p, q, pl > such that Width(pl) > w. This is possible \nonly if a section p of pl is bypassed by another ifp p) . Let width(p ) be w , width(fl) be w and width(pl) \nbe WI, Then (wl w ) + w ~ w. Again w + 1 iterations suffice for information to propagate from p to q. \nl Note that the bound w+l is a static prediction. For a particular instance of a data flow problem, the \nnumber of iterations could be less as the behaviour of the non\u00adpreserving ifp s (i.e. ifp% containing \nfunctions of the form h(X) = A + 7.B .X) is governed by the constants A and B for that instance. Example \n7 : Consider the following graph 12 c-l If we choose 6G = BG, Bb and Ff become the non-conforming edge \ntraversals. The width determin\u00ading paths for MRA, EPA and MMRA are : (6, 1,2,5, 11, 10,9,7,8) = BjF~l?bF~l?jB~BjFj \n (1,6,7,8, 10, 11, 12) = FfI fl fFfFJFf e (1,6,7,8, 10, 11, 12) = FjFjFj.F~F~Fj  The widths for the \nthree problems are 4, 6, and 6, re\u00adspectively. 0 3.1 The width and the depth Depth (d) is defined as \nthe maximum number of back edges along any acyclic path [1]. To use the notion of width for unidirectional \nflows, choose 6 as the natural direction of the flow in the problem. Now there are no flows along 6; \nand c5~ edge traversals, and the only non-conforming edge traversal is bb. Since the width considers \nonly those paths which do not have bypaesed fragments, w ~ d. Thus, width provides a tighter bound on \nthe number of iterations. Example 8 : Consider a spiral graph [3] whose depth increases linearly with \nthe nesting depth.3 t Here d = 3, while w = 1 for a unidirectional prob\u00adlem since every part of an ijp \nbeginning on a back edge is bypassed, viz. path (5, 2, 6) is bypassed by the path (5, 6). This explains \nthe observation that the number of iterations remains constant even as the size of the spiral graph grows. \n! Further, the notion of depth assumes a fixed pat\u00adtern for information flow governed by the directed \npaths in the flow graph, hence it is only applicable to unidi\u00adrectional data flow problems,  4 Efficiency \nof data flow analysis This section discusses the issues raised by the presence of unbounded segments \nin information flow paths, and the importance of bounded segments in reducing the complexity of data \nflow analysis. 4.1 Choice of direction in graph traver\u00ads al Consider a data flow problem whose ifi s \nhave un\u00adbounded segments in one direction. Recall that w = #6h + #6~, i.e. width has contributions from \nthe 3 SPird ~tmctwe~ ~e~~t from repeat . . . u ntil 100PSwith prC\u00ad mature exits. back edges in the 6 \nsegments and forward edges in the &#38; segments. #6: is likely to be smaller when the un\u00adbounded segments \nare in the 6 direction, rather than the 6-direction. Hence the appropriate direction for graph traversal \nis the one that makes the unbounded segments lie in the 6 direction. For example, MRA has unbounded backward \nseg\u00adments but bounded forward segments, hence backward graph traversal would require fewer iterations \nthan forward traversal. For unidirectional problems, the favoured direction of traversal is trivially \nthe direction of the data flow. Alternating iterations For problems with unbounded segments in both \ndi\u00adrections, alternating the direction of graph traversal be\u00adtween successive iterations can effectively \nreduce the so\u00adlution complexity. This can be explained as follows : A segment in the 6 direction may \nconsist of a number of spans separated by non-conforming edges, which may themselves form sizable spans \nin the 6-direction. Since the effect of a span in the 6 direction is incorporated by a single iteration \nin the 6 direction, alternating the di\u00adrection of graph traversal between successive iterations would \nyield better results. Thus, the alternating itera\u00adtions approach is clearly warranted in the case of \nEPA and MMRA. Let SPbe the number of non-null spans along an ifi p. The width of p for alternating iterations \nis defined as follows : width=(p) = 2SP + c, where c = 1 if p ends with a non-null span, else c = 0. \nThe number of iterations for the method of alternating iterations is then Wa + 1 where w~ is defined \nanalogous to w, viz. w= = max(widtha(p)) Vp, where p is an ifp, no part of which is bypassed. 4.2 Handling \nbounded segments When a data flow problem has bounded segments in one direction, and unbounded segments \nin the other direc\u00adtion, complexity of the data flow analysis can be reduced by attempting to truncate \nthe information flow paths. Consider an ifp p = (Os., zi, Ei+l, t?~+z), where edge i%+l constitutes a \nbounded segment of length 1, i.e. t% and @i+2 belong to the segments in the opposite direction. Truncation \ncan be effected by transforming the program %OWgraph or the data flow equations so as to terminate each \nifp analogous to p before it reaches the edge Zi+2. Effectively, p is split into two ifp s PI and Pz. \nSince width(pl), width(pz) s width(p), this could reduce the width. In this section, we present three \ntransformations based on this approach. 4.2.1 Edge splitting An edge which runs from a branch node (i.e. \na node with more than one successor) to a join node (i.e. a node with more than one predecessor) is called \na critical Figure 4: Edge splitting edge. It has been reported [11] that when such an edge is split \nby inserting a new node, the solution complexity of MRA is reduced. The following lemma captures the \ninfluence of the edge splitting graph transformation on the solution complexity of MRA. Lemma 1 : Following \nedge splitting, MRA can be solved with the complexity of a unidirectional problem. Proof : Following \nsection 4.1, we choose &#38; 6G = BG for MRA. Consider figure 4. Before edge split\u00adting, the information \nflow path from node i to node m (p= (i,j, k, l,m) = Bf Ft B~ l ~ ) would have contained two 6; (i.e. \nFj ) edge traversals. With the inser\u00adtion of j , p is split into two ifp s pl = (i, j, j ) and PZ = (k, \nl , L m), which contain a single 6; traversal each. (This is because a p = (i, j, j , k, 1 , 1,m) is \nnot an ifp for MRA due to two successive 6; traversals (j, j ) and (j , k)). In general, edge splitting \nrestricts the num\u00adber of 6; edge traversals along any information path to ~ 1 in the transformed graph.4 \nThus w ~ w + 1, where w is the width of the graph for a unidirectional data flow problem. 0 As a result \nof edge splitting the MRA ifp s become B.+(F. [ e) for the transformed graph, instead of the original \n(Be+(F~ I c))+Be*. 4.2.2 Edge placement The technique of edge placement eliminates a partial redundancy \nof an expression e in node i, which cannot be safely hoisted into a predecessor j, by creating a synthetic \nnode along the edge (j, i) and hoisting e into it [6]. Unlike edge splitting, however, a synthetic node \nis conceptual; it does not participate in data flow analysis. It becomes real only when a computation \nis inserted in it during optimization phase following the data flow anal ysis. Use of edge placement \nin MRA results in elimina\u00adtion of the II term from the PPINi equation (eq. 1 of figure 6). It thus transforms \nthe data flow, rather than the flow graph, to achieve the same effect as edge split\u00adting, viz, restricting \nthe number of 6; traversals along any ifi to < 1. Solution efficiency vis-a-vis MRA is guaranteed by \nthe fact that the resulting data flow is simply (backwards) unidirectional in nature. 4<1 in the original \nWFWh. Figure 5: Interval based solution for MRA 4.2.3 Interval pre-headers [10] mentions that an interval \nbased elimination method can not be extended to MRA. The notion of width can be used to justify this, \nand to motivate an edge splitting graph transformation which enables an elimination ap\u00adproach to MRA \nsolution. Consider a forward edge (j, k) terminating on the interval header (figure 5). The infor\u00admation \nflowing forward along this edge can flow (back\u00adwards) along the latching edge (k, /) of the interval \nto reach the exit edge (1, m) of the interval. Thus, infor\u00admation can flow forward through an interval, \nas well as back through it due to the mostly backward nature of MRA. However, if we introduce an interval \npre-header by splitting every inter-interval edge (i.e. every edge in a reduced graph), we will effectively \ntruncate an informa\u00adtion flow path before it reaches an interval-header along a forward edge, viz. the \npath p = (i, j, k, 1,m) would be truncated to pl = (i, j, j ). This restricts the infor\u00admation flow between \ntwo intervals to a unidirectional flow. Thus the bidirectional problem is partitioned into smaller sub-problems \nrelated to each other by a unidi\u00adrectional data flow. This makes the classical interval analysis approach \nfeasible for MRA. A detailed discussion of elimination algorithms for bidirectional data flow problems \ncan be found in [20].  5 Decomposing bidirectional flows into unidirectional flows Decomposition of \na bidirectional data flow problem into a sequence of unidirectional problems (i.e. solving a bidirectional \nproblem as a sequence of cascaded unidi\u00adrectional problems) is motivated by the desire to reduce the \namount of work or to improve the understandability of the data flow involved. Prior work on decomposition \nhas been ad hoc and/or directed at specific bidirectional data flow problems [6, 11, 23]. In this section \nwe provide a condition for the decomposability of a bidirectional data flow problem. Lemma 2 : It is \nfeasible to decompose a bidirectional data flow problem into a sequence of unidirectional data jlow problems \nif and only if the number of segments in every information jlow path for the data jlow problem is bounded \nby a constant. Proof : Let 6 be the direction of the first segment in an information flow path. Information \npropagation along the segment can be realized by a unidirectional data flow problem which has $ as its \nnatural direction of flow. Information flow along the following segment would require a unidirectional \nproblem in the opposite direction, etc. Thus, the number of unidirectional prob\u00adlems required will equal \nthe number of segments, which should be bounded by a constant for the decomposition to be feasible. Further, \nthe order of solving the unidi\u00adrectional problems will have to be the same as the order of segments in \nthe information flow paths. 0 Corollary 2.1 : MRA cannot be solved by cascaded unidiTectionai pro blems.5 \nThe ifp s of MRA have the form (l?,+(F , [ e))+Be*, thus they can have an unbounded number of forward \nand backward segments. Similar statements hold for the LSIA and CHSA problems. D In the following, we \nexplain two decompositions re\u00adported in literature, and motivate a third one. Corollary 2.2 : It is possible \nto decompose MRA if edge splitting is performed. Following section 4.2.1, the information flow paths \nin the resulting program flow graph can be characterized by the regular expression B,+ (l e I c). Since \nthe number of segments can at most be 2, it is possible to solve MRA by cascaded unidirectional problems. \nFurther, since the second (i.e. the forward) segment has a length < 1, it is possible to solve MRA on \na graph in which critical edges have been split as a backward problem followed by a forward comection \n[11].(I Corollary 2.3 : EPA can be decomposed into cascaded unidirectional problems. The decomposition \nof the Edge Placement Algo\u00adrit hm( EPA) [6] is feasible since its information flow paths are characterized \nby (13.+ I F e)l e (B, [ c) (refer table 2). The number of segments in an ifp can at most be 3, hence \ndecomposition the condition of lemma for EPA is presented 2 is satisfied. in [6, 10].KI A Corollary 2.4 \n: It is possible to deedge splitting is perfoTmed. The ifp s of MMRA incorporate fects : compose two \nMMRA distinct if ef\u00ad unless edge splitting is performed. (i) The mostly backward propagation of MRA \nwhich leads to ifp sections described by the reg\u00adular expression (Bc+ (I . I e))+ B. , and (ii) The \nforward propagation of EPA which leads to ifi sections described by the regular expression Fe*(B. [ c). \n Edge splitting truncates the ifp sections of the first kind to simply Be+(I . I c) in the transformed \nflow graph, and Be+ in the original graph, respectively (refer lemma 1). The resulting ifp s are described \nby the reg\u00adular expression (Be+ ] I ~)1 .* (Be I c) in both the trans\u00adformed as well as the original \ngraphs. Since this is the same as the regular expression for EPA in corollary 2.3, the decomposability \nof MMRA follows. The resulting decomposition is described in [12].cI This result in not surprising since \nEPA differs from MMRA only in the use of the edge placement tech\u00adnique (refer appendix) which has already \nbeen shown to achieve an effect equivalent to edge splitting in the original program flow graph (refer \nsection 4.2. 1). 6 Results and Conclusions The results of analyzing a suit of scientific programs written \nin Fortran-77 are presented in table 3. The fol\u00adlowing observations can be made concerning these re\u00adsults \n: (i) Very good correlation is seen between the width and the number of iterations for the problems which \nhave bounded segments in the c$-direc\u00adtion (viz. MRA). (ii) For EPA and MMRA, the predicted and ob\u00adserved \nwidths for backward iterations differed by very large margins. This can be attributed to the following \n: (a) Width is a static prediction. Many of the long ifp s traced during width computation may not be \nrealized dur\u00ading data flow analysis. This fact is well accepted by practitioners of data flow anal ysis. \n (b) The ifp s of EPA and MMRA have un\u00adbounded 6-segments. Hence, the com\u00adputed widths are very large. \nThis ac\u00adcentuates the effect mentioned in (a) above. A similar effect is observed in the case of unidirectional \nproblems having unbounded 6-segments. For example, the problem of available ex\u00adpressions has unbounded \n6-segments when solved using backward iterations. Its width is therefore the number of   edges along \nthe longest acyclic forward path in the program. In practice, in\u00adformation does not propagate so much. \n (iii) For problems with unbounded segments in both directions (viz. EPA and MMRA), the method of alternating \niterations scored over the backward direction of graph traversal by a large margin in a total of 11 cases. \nIn 10 cases, it performed only marginally worse than back\u00adward traversal. On the whole, alternating iter\u00adations \nshould be the favoured solution method for EPA and MMRA. When compared to MRA, the additional complexities \nof data flow in EPA and MMRA do not appear to make them very expensive in practice. (Note that MRA is \nalso known to take upto 5 iterations in practice [25]). (iv) Despite observation (ii), observation (iii) \nabove demonstrates the applicability of the con\u00adcept of an information flow path to non-singular data \nflows as well, thereby vindicating the use of ib s as the basis of a stud y of the complexity of data \nflow analysis. Acknowledgements The authors wish to thank the referees for their critical comments. Thanks \nare also due to Amitabha Sanyal, Ajit Diwan and Vikram Dhaneshwar for useful feedback from time to time, \nand to Viral Acharya and Moses Charikar for the implementation support. References [1] A. V. Aho, R. \nSethi, and J. D. Unman. Compil\u00adevs -Principles, Techniques, and Tools. Addison-Wesley, 1986. [2] F. E. \nAllen and J. Cocke. A program data flow analysis procedure. Communications of ACM, 19(3):137-147, 1977. \n[3] S. Biswas, G. P. Bhattacharjee, and P. Dhar. A comparison of some algorithms for live variable analysis. \nInternational Journal of Computer Math\u00adematics, 8:121-134, 1980. [4] F. C. Chow. Minimizing register \nusage penalty at procedure calls. In Proceedings of SIGPLAN 88 Symposium. on Compiler Construction, pages \n85\u00ad94, 1988. Also Published as SIGPLAN Notices, 23(7). [5] D, M. Dhamdhere. An elimination algorithm \nfor hi-directional data flow analysis. Technical report CSE-TR-88-31, Department of Computer Science \nand Engineering, The University of Connecticut, Storrs, 1988. MRA EPA II M MRA program [Nl IEI 1X1 w \nBackward Backward Alternate Backward Alternate w #i w #i Wa#i w #i Wa#i pgml 366216812 4 13 4 55 26 6 \n205 pgm2 361641 63-[,-13 4 12 3 54 27 5 225 11IIfI II III I I mzm3 48 6811111111131 3 1123110 I7I5II39I1OI \n3115 .. H pgm4 6084143133 279 75501839 5 mzm5 455024112 2 37 3 53 41 2 9 3 ,L p~m6 304716012 4 13 4 \n55 23 4 17 5 pgm7 344614014 3 22 5 75 27 4 15 5 pgm8 375220412 4 18 7 55 28 7 19 5 pgm9 618422413 4 29 \n3 54 47 4 29 4 pgm10 405334323 4 24 6 85 37 4 25 6 pgmll 467820712 4 14 5 55 26 7 20 6 pgm12 3348305124 \n143 43287 235 pgm13 3448 5412 4 24 3 33 33 4 114 pgm14 374398124 353 33367 33 pgm15 628336512 4 30 3 \n54 41 4 215 Number of nodes Number of edges Number of expressions Width for unidirectional problems Width \nfor bidirectional problems Width for alternating iterations Number of iterations aFor a width w, though \nw + 1 iterations are sufficient for converging on a fixed point, an additional iteration is required \nto ascertain that the fixed point is reached. Thus, the actual bound on the number iterations for a round \nrobin algoritlun is w + 2, Table 3: Experimental results [6] D. M. Dhamdhere. A fast algorithm for code \nformatively. In ACM SIGPLAN 92 Conference movement optimization. ACM SIGPLAN Notices, on Programming \nLanguage Design and Implemen\u00ad23(10):172-180, 1988. tation, 1992. [7] D. M. Dhamdhere. Register assignment \nusing [12] Vikram Dhaneshwar. M. Tech. dissertation (stage code placement techniques. Computer Languages, \n1). Department of Computer Science and Engi\u00ad 13(2):75-93, 1988. neering, Indian Institute of Technology, \nBombay, 1992. [8] D. M. Dhamdhere. A new algorithm for compos\u00adite hoisting and strength reduction optimization. \n[13] A. C. Fong, J. B. Kam, and J. D. Unman. Appli-International Journal of Computer Mathematics, cations \nof lattice algebra to loop optimization. In 27(1):1 14, 1989. Proceedings of the ACM Symposium on Principles \nof Programming Languages, pages 1 9, 1975. [9] D. M. Dhamdhere. Comments on practical adapta\u00adtion of \nthe global optimization algorithm by morel [14] S, Graham and M. Wegman. A fast and usually lin\u00ad and \nrenvoise. ACM 7kansactions on Programming ear algorithm for global data flow analysis. Journal Languages \nand Systems, 13(2), 1991, of ACM, 23(1):172-202, 1976. [15] M. S. Hecht. Flow Analysis of Computer Programs. \n[10] D. M. Dhamdhere and Harish Patil. An elimina\u00ad tion algorithm for hi-directional data flow analy-Elsevier \nNorth-Holland Inc., 1977. sis using edge placement technique. ACM !&#38;ans-[16] M. S. Hecht and J. D. \nUnman. A simple algorithm actions on Programming Languages and Systems, for global data flow analysis \nproblems. SIAM Jour\u00ad 1992. (To appear). nal of Cornpuiing, 4(4):519 532, 1977. [11] D. M. Dhamdhere, \nB. K. Rosen, and F. K, Zadeck. [17] S. M. Joshi and D. M. Dhamdhere. A composite How to analyze large \nprograms efficiently and in-algorithm for strength reduction and code move\u00adment : part I. International \nJournal of Computer Jkfaihematicq 11(1):21-44, 1982. [18] S. M. Joshi and D. M. Dhamdhere. A composite \nalgorithm for strength reduction and code move\u00adment : part II. International Journal of Computer Mathematics, \n11(2):111-126, 1982. [19] J. B. Kam and J. D. Unman. Monotone data flow analysis frameworks. Acts ln~ormatica, \n7(3):305\u00ad318, 1977. [20] Uday P. Khedker and D. M. Dhamdhere. Elimina\u00adtion algorithms for hi-directional \ndata flow prob\u00adlems. Department of Computer Science and En\u00adgineering, Indian Institute of Technology, \nBombay, 1992. (In preparation). [21] Uday P. Khedker and D. M. Dhamdhere. A gen\u00aderalized theory of data \nflow analysis. Technical re\u00adport TR-070-92, Department of Computer Science and Engineering, Indian Institute \nof Technology, Bombay, 1992. [22] G. Kildall. A unified approach to global program optimization. In Proceedings \nof the ACM Sym\u00adposium on Principles of Programming Languages, pages 194-206, 1973. [23] J, Knoop, O. \nRuthing, and B. Steffen. Lazy code mot ion. In ACM SIGPLAN 92 Conference on Programming Language Design \nand Implementa\u00adtion, 1992. [24] T. J. Marlowe and B. G. Ryder. Properties of data flow framewo~ks. Acts \nInforrnatica, 28:121\u00ad163, 1990. [25] E. Morel and C. Renvoise. Global optimization by suppression of \npartial redundancies. Communica\u00adtions of ACM, 22(2):96-103, 1979. [26] R. E. Tarjan. Fast algorithms \nfor solving path problems. Journal of ACM, 28(3):594-614, 1981.  Appendix Bidirectional Data Flow Algorithms \nThe Morel and Renvoise algorithm (MRA) [25] per\u00ad forms global program optimization by the suppression \nof partial redundancies. The basic approach is one of fre\u00adquency reduction by code hoisting. Partial \nredundancy of an expression is used to motivate its hoisting. Since common subexpression elimination \nand loop invariant movement are special cases of redundancy elimination, the algorithm unifies several \ntraditional optimizations within a single framework. Equations 1 and 2 represent the data flows of MRA. \nLocal property ANTLOCi represents information concerning upwards exposed occurrence(s) of an expres\u00adsion \ne in node i of the program flow graph, while TRANSP~ reflects the absence of definition(s) of e s operands \nin the node. Partial redundancy is repre\u00adsented by the data flow property of partial availabil\u00adity PAVINi \n/PAVOUTi defined using the classical for\u00adward data flow problem of available expressions [1] with the \nconfluence operator changed to X. Safety of hoist\u00ading is incorporated by considering only those expres\u00adsions \nwhich are very busy at the entry/exit of a node. This is incorporated by the II term of the PPOUT~ equation \n(eq. 2). A property INSERTi identifies nodes where occurrences of expression e should be inserted. PPINi. \nlANTLOCi identifies occurrences which are re\u00ad dundant following the insertion. In the Load-Store Insertion \nAlgorithm [7], the prob\u00adlem of placing Load and Store instructions of a variable to characterize its \nlive range for register assignment is modelled as redundancy elimination of the Load and Store instructions. \nHere, we consider the problem of the placement of Store instructions, which is a dual of MRA (eqs. 3 \nand 4). The local and global properties used in the equations are self-explanatory. In the Modified MRA \nalgorithm (MMRA) [9], cer\u00adtain simplifications are introduced in the MRA equa\u00adtions. An additional term, \nwith 2 as the confluence, is added to the PPIN~ equation (eq. 5) to suppress re\u00addundant hoisting of an \nexpression. Other terms in the equations are the same as in MRA. The technique of edge placement [6] \naims at total elimination of partial redundancies by placing an ex\u00adpression which is partially redundant \nin node i, but can not be safely placed in a predecessor node j, into a synthetic node placed along edge \n(j, i). This simpli\u00adfies the data flow dependencies by eliminating the II term of MRA s PPINi equation. \nThe Edge Placement Algorithm (EPA) [6] uses the technique of edge place\u00adment, and also incorporates the \nsuppression of redun\u00addant hoisting by adding a X term in the PPINi equation (eq. 7). As mentioned in \nsection 2.5, MMRA and EPA are non-singular data flows since they involve two distinct confluence operators. \nThe Composite Hoisting and Strength reduction Algorithm (CHSA) [17, 18] unifies strength reduction and \nredundancy elimination into the same framework. Additive computations are used to update the value of \na high strength expression following an update of the induction variable s value. Recomputations of the \nhigh strength expression are placed at other strategic places in the program. The NO COMINi /N OCOMOUTi \nprob\u00ad lem is used to limit the number of additive compu\u00ad tations along a path following a recomputation \nof the high strength expression. CHSA is the only known sin\u00ad gular data flow problem to possess the node \nand edge flow functions in both directions forwards as well aa backwards. 1. Morel Renvoise Algorithm \n(MRA) [25] : PPIN; = CONSTi . ( ANTLOCi + TRANSPi . PPOUTi) c ~ (AVOUTP + PPOUTP) (1) p 6 pred(i) PPOUTi \n= fl (PPIN,) (2) s E SUcc(i) 2. Load Store Insertion Algorithm (LSIA) [7] : SPPIN~ = ~ (SPPOUTP) (3) \np 6 pred(i) SPPOUTi = DPANTOUTi . ( DCOMPi + DTRANSPi . SPPIN~) . ~ (DANTIN, + SPPIN.) (4) s E Succ(i) \n 3. Modified MRA (NIMRA) [9] : PPINi = PAVINi . ( ANTLOCi + TRANSPi . PPOUTi) . ~ (AVOUTP + PPOUTP) (5) \ne pred(i) ~ (PPINPIANTLOCP + AVOUT; p E peal(i) PPOUTi = ~ (PPINs) (6) s c Succ(i) 4. Edge Placement \nAlgorithm (EPA) [6] : PPINi = PAVINi . ( ANTLOCi + TRANSPi PPOUTi) (7) ~ ( PPINP ~-IANTLOCP + AVOUTP) \np E peal(i) PPOUTi = ~ (PPIN$) (8) s c $Ucc(i) 5. Composite Hoisting and Strength reduction Algorithm \n(CHSA) [17, 18] : NOCOMINi = CONSTAi . ( z NOCOMOUTp + CONSTBi . NOCOMOUTi) (9) p @ pred(i) NOCOMOUTi \n= CONSTCi + CONSTDi . ( E NOCOMIN. + CONSTEi . NOCOMINi) (lo) s < Succ(i) Figure 6: Data flow equations \nof the problems referred in this paper \n\t\t\t", "proc_id": "158511", "abstract": "<p>The concept of an <italic>information flow path</italic> arising from the generalized theory of data flow analysis [21] is used to analyze the complexity of data flow analysis. The <italic>width (w)</italic> of a program flow graph with respect to a class of data flow problems is introduced as a measure of the complexity of round-robin iterative analysis. This provides the first known complexity result for round robin iterative analysis of bidirectional data flows commonly used in algorithms based on the suppression of partial redundancies [6, 7, 8, 9, 17, 18, 25]. We also show that width provides a better bound on the complexity of unidirectional data flows than the classical notion of <italic>depth</italic>.</p><p>The paper presents ways to reduce the width, and thereby the  complexity of flow analysis, for several interesting problems. Complexity analysis using the notion of width is also shown to motivate efficient solution methods for various bidirectional problems, <italic>viz</italic>. The <italic>alternating iterations</italic> method, and an interval analysis based elimination method for the partial redundancy elimination problems. The paper also presents a condition for the decomposability of a bidirectional problem into a sequence of unidirectional problems.</p>", "authors": [{"name": "Dhananjay M. Dhamdhere", "author_profile_id": "81100471827", "affiliation": "", "person_id": "P66375", "email_address": "", "orcid_id": ""}, {"name": "Uday P. Khedker", "author_profile_id": "81100376987", "affiliation": "", "person_id": "PP39040090", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158696", "year": "1993", "article_id": "158696", "conference": "POPL", "title": "Complexity of bi-directional data flow analysis", "url": "http://dl.acm.org/citation.cfm?id=158696"}