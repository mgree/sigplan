{"article_publication_date": "03-01-1993", "fulltext": "\n Graph Types Nils Klarlund &#38; Michael I. Schwartzbacht {klarlund,mis}@daimi. aau .dk Aarhus University, \nDepartment of Computer Science, Ny Munkegade, DK-8000 ~rhus, Denmark Abstract Recursive data structures \nare abstractions of simple records and pointers. They impose a shape invam ant, which is verijied at \ncompile-time and exploited to auto\u00admatically generate code for building, copying, compar\u00ading, and traversing \nvalues wiihout loss of ejiciency. However, such values are always tree shaped, which is a major obstacle \nto practical use. We propose a notion of graph types, which allow com\u00admon shapes, such as doubly-linked \nlists or threaded trees, to be expressed concisely and efficiently. We de\u00adjine regular languages of routing \nexpressions to spec\u00adify relative addresses of extra pointers in a canonical spanning tree. An eficient \nalgorithm for computing such addresses is developed. We employ a second\u00ad order monadic logic to decide \nwell-formedness of graph type specifications. This logic can also be used for au\u00ad tomated reasoning about \npointer structures. Introduction Recursive data types are abstractions of structures bllilt from simple \nrecords and pointers. The values of a recursive data type form a set of pointer struc\u00adtures that all \nobey a common shape invariant. The advantage of this approach is twofold: validity of the invariant can \nbe statically verified at compile-time, which contributes to the correct\u00adness of programs; and *The author \nis supported by a fellowship from the Danish Resemch Counsil. t The author is partially supported by \nthe Danish Research Council, DART Project (5.21.08.03). Permission to copy without fee all or part of \nthis material is granted provided that the copies are not made or distributed for direct commercial advantage, \nthe ACM copyright notice and the title of the publication and its date appear, and notice is given that \ncopying is by permission of the Association for Computing Machinery. To copy otherwise, or to republish, \nrequires a fee and/or specific permission. ACM-20th PoPL-1/93-S.C., USA @ 1993 ACM 0-89791 -561 -5/93 \n/0001 /0196 . ..$1 .50 0 the invariant can be exploited to automatically generate code for such tasks \nas copying, compar\u00ading, and traversing values. Recursive data types originate from the seventies [7] \nand have become ubiquitous in modern typed func\u00adtional languages such as ML [8] and MIRANDA [10], but \nthey may also be employed in PASCAL-like imper\u00adat ive languages. Their benefits are substantial, but \nthey also impose limitations; in particular, the values of recursive data types will always be tree shaped. \nIn this paper we present a natural generalization, graph types, which allows a large variety of graph \nshaped values, including (doubly-chained) cyclic lists, leaf-to\u00adroot-linked trees, leaf-linked trees, \nand threaded trees. The key idea is to allow only graphs with a backbone, which is a canonical spanning \ntree. All extra edges must depend functionally on this backbone. The ex\u00adtra edges are specified by a \nlanguage of regular routing expressions, which give relative addresses within the backbone. We show that \nconstruction of such graph values along with all relevant manipulations can happen efficiently in linear \ntime. We introduce a de\u00adcidable monadic logic of graph types, which allows au\u00adtomatic derivation of some \nconstant time operations such as concatenation of doubly-linked lists. There have been other attempts \nto describe graph-shaped values. Our proposal, however, allows exact descrip\u00adtions of a more general \nclass of types, and it does so using an intuitive notation that is very close to exist\u00ading concepts in \nprogramming languages. This summary is kept in an informal, explanatory style. Formal definitions and \nalgorithms are included in the appendix. 2 Data Types For this presentation, a (recursive) data type \nD is a special kind of tree grammar. The non-terminals are called types. There is a distinguished main \ntype, which in examples is always the one mentioned first; the oth\u00aders are merely auxiliary. A production \n z 4v(al: Tl,..., an:Tn) of D, where T and the T~ s are types, declares a variant v of type T containing \ndata jields named al, ..., an; we say that the production declares a type-variant (T: v). For each type, \nthe possible variants must be mutually distinct; thus (T: v) uniquely determines the produc\u00adtion, Moreover, \nfor each type-variant, the data fields must be mutually distinct. The values of a data type are essentially \nthe derivation trees of the underlying context-free grammar, starting with the main type. They are implemented \nas pointer trees, but the programmer will never directly manip\u00adulate these pointers. Each node of such \na pointer tree is an instance of a variant of a type. A formal detlni\u00adtion of the values of a data type \nis given in section Al of the appendix. As a simple example, consider the following data type, which \nspecifies a type of simple integer lists L + nonempty(head: Int, tail: L) -+ emptyo We can think of \nthe type Int as being a data type specified w Int+Oollo1201.. . We allow implicit variants as a form \nof syntactic sugar. If the sets of data fields are distinct for all variants, then the explicit variants \nare not needed; we may think of the variant names ss being a concatenation of the field names. Thus, \nwe may instead write L + (head: Int, tail: L) 4() Programming with Data Types When a data type has been \nspecified, it gives rise to a number of operations in the programming language. First of all, there is \na language for denoting constant values. For the above lists, one may write down L(head: 11, tail: (head: \n12, tail: (head: 13, tail: ()))) for the list of type L with elements 11, 12, and 13. If x is a variable \ncontaining a value of type L, then x.tail.tail.head specifies the address of a subtree, in this case \nof type Int. In a functional language this would always denote the corresponding value; in an imperative \nlanguage there is the usual distinction be\u00adtween 1-and r~values. The comparison x = y is al\u00adways defined \nfor two values of type L. If x is a value of type L, then the boolean expression is(x,v) yields true \nexactly when x is of variant v, In an impera\u00adtive language, the value assignment x := y is present, possibly \naccompanied by the swap x :=: y which ex\u00adchanges two subtrees without copying. Values of data types are \ntraversed by recursive functions or proce\u00addures. Thus, explicit pointers are never used. There is no \nintrinsic loss of efficiency in this approach. Constants can be built, copied, compared, and tra\u00adversed \nin optimal linear time, and addresses are ac\u00adcessed in constant time. Thus, if one really wants tree \nshaped values, then only advantages are to be seen. Shortcomings of Data Types The main draw-back of \ndata types is the limited shapes of values that they allow. For the above simple lists, values always \nlook as follows (an empty record is pictured as a ground symbol) However, it is a common optimization \nto want an extra pointer to gain constant time access to the last element of the list. Thus, the values \nshould instead have the following shape These are not trees and, hence, cannot be specified by data types. \nUntil now, there has been no solution to this problem. The only possibility has been to revert to the \noften perilous use of explicit pointers. 3 Graph Types ,0 We introduce the notion of graph types, which \nform a conceptually simple extension of data types. They al\u00ad low graph shaped values while retaining \nthe efficiency and ease of use. There are two key insights to our solution: while being graphs, the values \nall have a backbone, which is a canonical spanning tree; and the remaining edges are all functionally \ndeter\u00admined by this backbone. Many, but not all, sets of graphs fit this mold; we give examples of both \nkinds. A graph type extends a data type by having routing fields aa well as data jields. Productions \nnow look like T~v(. ..ai ?)...) :~... flj:!lj[l Here ai is a normal data field but aj is a routing field. \nIt is distinguished by having an associated routing ex\u00adpression R. A graph type has an underlying data \ntype, which is obtained by removing the routing fields. The backbones of the graph type values are simply \nthe val\u00adues of this data type. Routing expressions describe relative addresses within the backbone. The \ncomplete graph type value is obtained by using the routing ex\u00adpressions to evaluate the destinations \nof the routing fields. Routing expressions are regular expressions over a lan\u00adguage of directives, which \ndescribe navigation within a backbone. Directives include move up to the parent (from a specific child) \n(t or T a) , move down to a specific child (J a), and verify a property of the cur\u00adrent node , where \nproperties include this is the root ( A), this is a leaf ($), and this is (a specific variant of) a specific \ntype (T or (T: v)). A routing expression defines the destination indicated by the correspond\u00ading routing \nfield if its regular language contains pre\u00adcisely one sequence of successful directives leading to a \nnode in the tree. A graph type is well-formed if every routing expression always defines a unique destination. \nSection A2 of the appendix gives formal definitions of these concepts. To make a convincing case for \nthis new mechanism, we need to demonstrate the following facts: . many useful families of structures \ncan be easily specified; . values can be manipulated at run-time similarly to values of data types, and \nwithout loss of effi\u00adciency; and well-formedness of graph type specifications can be decided at compile-time. \nExamples We now show that many common pointer structures have simple specifications as graph types. The \nexam\u00adples are all well-formed, which can be easily seen in each case. In pictures of values, we use the \nconvention that pointers from data fields are solid, whereas those from routing fields are dashed. The \nroot of the un\u00adderlying spanning tree, or backbone, is indicated by a solid pointer with no origin. The \nlist with a pointer to the last element looks like H a (first: L, last: L[Jfirst Jtail $ t]) L A (head: \nInt, tail: L) + () A typical value is first i.. . . . . . . . . . . H-------------f The routing expression \nJfirst Jtail $ T for the last field contains the following directives: move down along the first pointer \n(Jfirst); follow the tail pointers until a leaf is reached (Jtail $); then back up once (t). This is \nthe destination of the last pointer. A cyclic list looks like C -+ (next: C!) -+ (next: C[~* A]) A typical \nvalue is next ~ I next M The routing expressions contain the following simple directives: move up to \nthe root. A doubly-linked cyclic list looks like D ~ (next: D, prev: D[t +A Jnext $]) ~ (next: D[t A], \nprev: D[t +A]) A typical value is prev r 1 jrII next II 1 $-R prev I Ilnext next I, prev Ii Ii L -;---..p::v\u00ad \n1 I L -..  IM!3 next Directives are more complicated here; they use the nondeterministic union operator \non regular expres\u00adsions (+) to express context-dependent choices. For example, consider the (prev field \nof the first variant. According to the routing expression T + A $next $ of this field, we must either \nmove up, or, if we are at the root, follow next pointers to the leaf. A binary tree in which all leaves \nare linked to the root looks like R ~(left, right: R) -(root: R[f A]) A typical value is !, r 1 /\\ \n1 1 AI1 I left I II I1 II root~ J I /\\ Ii I ~ left I root I L --6b~ -J A binary tree in which all \nthe leaves are joined in a cyclic list looks like J a(left, right: J) +(next: J[sTEP$]) where STEP abbreviates \nTright* (tleft lright+ A) Jleft*. A typical value is !? /\\ left \\ left AI L------------..... J next \nA binary tree with red or black leaves, in which those of the same color are joined in a cyclic list, \nlooks like K +(left, right: K) ared(next: K[BLACK* RED]) ~black(next: K[RED* BLACK]) where RED abbreviates \nSTEP (K:red) and BLACK ab\u00adbreviates STEP (K: black). We shall abstain from show\u00ading a typical value of \nthis type. Finally, a binary tree in which all nodes are threaded cyclically in post-order looks like \nT +(left, right: T, post: TIPOST]) a(post: TIPOST]) where POST abbreviates ~right+tleft \\rightJleft*$+ \nA Jleft . A typical value is ------------. -----\u00adr 1 I I I I left 1 post :-\u00ad 1 1 1 I left t I 1 \n At a first glance such specifications may seem daunt-exactly the same as for the underlying two data \nvalues; ing, but at least to the authors they quickly became the routing fields are just ignored. familiar. \nThe use of abbreviations, such as STEP and POST above, may improve legibility and promote reuse of routing \nexpressions. Complicated pointer struc\u00adtures may give rise to complicated graph type specifi\u00adcations. \nHowever, it is fair to say that the complexity of the graph type specification correlates well with this \ninherent complexity, in the same way that a verbal or pictorial description would. Not all families of \ngraph shaped values can by specified by graph types. First of all, they must be determin\u00adistic, in the \nsense that all edges must be functions of some underlying spanning tree. This precludes such things as \na pointer from the root to some node in the tree. But even all deterministic situations cannot be specified. \nConsider a generalized tableau structure on a grid, in which there must be an edge from a point to the \none immediately below, if they are both present. A graph type cannot represent such graphs, since the \nvariant at a given node is dependent on whether there is a downward pointing edge. Thus the variant is \nde\u00adpendent on the rest of the graph something we can\u00adnot specify in a context-free grammar. Programming \nSo far, we have seen that many families of pointer structures can be captured ss the values of graph \ntypes. We must also demonstrate that they can be used for programming in a manner similar to that for \ndata types. An obvious problem with having graph shaped values is that the recursive traversal may be \nproblematic; how can we avoid cycles? However, for graph types we have the canonical spanning tree of \nthe underlying data value. Thus, many of the simple techniques can be inherited in a straightforward \nmanner. For exam\u00adple, the algorithm for comparing two graph values is The syntax for constants are also \nthe same as for the underlying data type. The values of the routing fields are then computed automatically. \nThe example values of the previous section are specified as constants as follows: H(first: (head: 11, \ntail: (head: 12, tail: (head: 13, tail: ())))) C(next: (next: (next: ()))) D(next: (next: (next: ()))) \nR(left: (left: (), right: ()), right: ()) J(left: (left: (), right: ()), right: ()) T(left: (left: (), \nright: ()), right: ()) Note that the expressions for the C-and D-values are identical, as are those for \nthe R-, J-, and T-values. Copying (sub) values happens in two steps. First, the underlying spanning tree \nis copied; second, the values of the routing fields must be reevaluated. Consider for example the leaf-to-root-linked \ntree. If a subtree is copied, then the leaves must now point to the new root of that tree. If a data \nfield in a graph value is assigned, then several routing fields in the both the surrounding spanning \ntree and the new graft may have to change. Consider for example the red-black leaf-linked trees. If a \nleaf is changed from red to black, then it must be removed from one cyclic list and inserted in another. \nA simple way of handling this is to reevaluate all routing fields, but that is undesirable since the \nsurrounding tree may be large and the graft maybe small. A similar problem exists for the swapping of \nsubtrees. We must develop an algorithm for detecting the routing fields that are required to be updated. \nRouting fields can be read just like data fields; they also point to subtrees of the canonical spanning \ntree. It is, of course, not possible to assign directly to a routing field. In summary, many of the required \nalgorithms are in\u00adherited from the underlying data structure. However, we must be able to evaluate all \nrouting fields in only combined linear time, and for assignment we need to detect those routing fields \nthat must be updated. Evaluating Routing Fields Backbones can clearly be constructed in linear time. \nGiven a backbone, it is possible to evaluate all routing fields in combined linear time. First, each \nrouting expression in the graph type is translated into an equivalent nondeterministic au\u00adtomaton. This \ntranslation is linear. Next, a table is constructed that for each node a and for each automaton state \nq of each automaton A con\u00adtains a pointer. Intuitively, if this pointer is not nil, it indicates a node \n/3 reachable by a sequence w of di\u00adrectives from a such that upon reading w, automaton A may end up in \na final state at node ~. This table is calculated in linear time by an algorithm described in the appendix. \nWhen the table has been constructed, the destination of a routing field at CYis given as the pointer \nfound in an entry (cr, go) of the table, where go is an initial state of the automaton representing the \nrouting expression. Detecting Required Updates Sometimes when a change occurs, it is sufficient to up\u00addate \nrouting fields for only a small part of the value. For example, this happens when swapping subtrees of \nvalues of type J, the type of leaf-linked binary trees. Consider the situation after the subtrees rooted \nat ad\u00ad dresses a and /3 have been swapped: 1 1 I I L ----------------\u00ad -----------------\u00ad ---. .-. ..-a \nnext Here only the next pointers at a , a , @, and P need to be updated. If we assume that J is made \ndoubly-linked by adding a field prev: J[t + A] \u00adit would often be less costly to locate the four nodes \n{a , a , @, ~ } after the change and reevaluate their next fields than evaluating all routing expressions \nin the backbone from scratch. In fact, with this approach we can guarantee that the time to locate fields \nin need of updating is proportional to the total length of the paths that lead to these fields, in this \ncsse of the paths from a to a , from a to a , from ~ to /? , and from /3 to p . To generate these paths, \nwe consider each node inci\u00addent on a backbone edge that changes (above, it would be a, ~, and their parents). \nEach automaton state at such a node can be followed backwards towards pos\u00adsible origins, routing fields \nwhose routes go through the node-and forwards towards a possible destina\u00adtion. Above, this involves finding \nfour destinations and four origins. For example, when considering a, we obtain two origins, the next \nfields of a) and a {, and their corresponding destinations. We shall shortly see how further optimizations \nare po5 sible. Note, however, that for some graph types the number of paths to follow may be proportional \nto n. This happens for example for the root linked trees of type R described earlier when a new root \nis added to an existing tree. In this case there is no gain in using the techniques described in this \nsection compared to the algorithm for updating all routing fields. Monadic Logic and Well-Formedness \nThe monadic second-order logic on graph types is a logical formalism that allows several important prop\u00aderties \nabout graph types to be expressed. In section A4 of the appendix, we define the logic formally and show \nthat it is decidable. Our logic permits quantifi\u00adcation over values of graph types, addresses, and sets \nof addresses. In this logic we can formulate questions such as What is the type-variant of a node a in \na value z? or Is there a walk in a value z from node a to node ~ according to a routing expression R? \nThe question of whether a graph type is well-formed can also be expressed in the logic as it is shown \nin section A4 of the appendix. Thus this question is decidable. Similarly, questions about comparing \nvalues, such as Val G1 G Val G2, where GI and G2 are graph types, are decidable. Although much can be \nexpressed in the monadic second-order logic on graph types, there are simple operations that cannot. \nFor example, one cannot rep\u00ad resent the result of replacing a subtree with another subtree (although \ncertain properties of the result may be expressible). Access Optimization In the example of updating \nrouting fields in leaf-linked trees, we saw that only four fields needed to be up\u00addated. It is not hard \nto see that calculating the desti\u00adnation of each such routing field is not necessary. For example, the \nnew value of the next field at a is the old value of the next field at ~ . Thus, when the four routing \nfields have been located, the updates can take place in constant time by properly permuting the values \nof known next pointers. Such use of the values of routing fields is called access optimization. The formal \nreasoning behind access optimization can be formulated in monadic logic. For example the ques\u00adtion Is \nthe value of the next field at cd in the new graph the same aa the value of the next field at /3 in the \nold graph? can be expressed, and the answer yes can be computed. In general, a strategy for access optimization \nis to compare values contained in nodes already located to the destination of paths that arise in the \ndetection of required updates. This involves trying out different combinations of paths that are followed \nexplicitly and testing whether other needed destinations or origins can be found in constant time. Thus \none can for\u00admulate a minimization problem for finding the least number of paths that need to be followed \nin order to carry out an update, and this problem is decidable. For doubly-linked lists of type D, such \nreasoning al\u00adlows the automatic generation of optimal, constant\u00adtime code for concatenating lists without \nthe pro\u00adgrammer having to specify any pointer operations. Related Work Decidability of Iogics of graphs \nhave been studied ex\u00adtensively; see [4] for references to the classical re\u00adsults that the monadic second \norder logic on finite trees is decidable and for extensions to more gen\u00aderal graphs. The hyperedge-replacement \ngrammars of [4] and similar context-free graph rewriting for\u00admalisms describe much larger classes of \ngraphs than our graph types. An important result of [4] is that any property expressed in second-order \nmonadic logic on graphs is decidable on hyperedge-replacement gram\u00admars. We could have used this result \nto derive our de\u00adcidability result; but the translation into context-free graph grammars appears to be \nmore complex than our approach. Although mathematically interesting, context-free graph grammars tend \nto be hard to un\u00adderstand; this is likely the reason why, to our knowl\u00adedge, they have not been used \nfor describing types in programming languages. Closer in spirit to our approach are the feature gram\u00admars \nand algebras; see [5] for references. These for\u00admalisms are built on the view that features (corre\u00adsponding \nto our record fields) are partial functions that identify attributes. Not being based on tree struc\u00adtures, \nfeatures allow the description of self-referential data structures. As opposed to our approach, the val\u00adues \ndesignated are not guided by any expressions. The programming languages in [1, 2] and [3] use sim\u00adilar \nideas and permits circular data structures. A re\u00adstriction of this work is that such circular references \nmay only point to nodes labeled syntactically with a marker. Since the number of markers is finite, this \nlanguage precludes the modeling of e.g. doubly-linked lists or leaf-linked trees, but allows root-linked \ntrees. The ADDS notation in [6] allows the description of abstract properties of pointer structures through \nthe concepts of dimensions and directions. The main motivation is to make static analysis more feasible \nthrough (non-invasive) program annotations. With the ADDS notation one cannot specify the exact shape \nof values, and manipulations still rely on explicit pointer operations. The techniques for evaluating \nrouting fields are sim\u00adilar to algorithms for reevaluating attributed gram\u00admars [9], but to our knowledge \nthe algorithms for up\u00addating a tree of a grammar whose attributes are nodes in the tree has not been \ndescribed before. Acknowledgments Thanks to the anonymous referees for their helpful comments. References \n[1] H. Ait-Kaci and R. Nasr. Logic and inheritance, In Proc. 19th ACM Symp. on Print. of Program\u00adming \nLanguagesj pages 219 228, 1986. [2] H. Kit-Kaci and R. Nasr. Login: A logic programming language with \nbuilt-in inheritance. Journal of Logic Programming, 3:185-215, 1986. Journal version of [1]. [3] H. Ait-Kaci \nand A. Podelski. Towards a meaning of life. In Jan Maluszyfiski and Martin Wirsing, editors, Proceedings \nof the %-d International Sym\u00adposium on Programming Language Implementa\u00adtion and Logic Programming (Passau, \nGermany), pages 255 274. Springer-Verlag, LNCS 528, Au\u00adgust 1991. [4] B. Courcelle. The monadic second-order \nlogic of graphs I. Recognizable sets of finite graphs: In\u00adformation and computation, 85:12-75, 1990. \n[5] J. Dorre and W.C Rounds. On subsumption and semiunification in feature algebras. In Proc. IEEE Symp. \non Logics in Computer Science, pages 300 310, 1990. [6] L. Hendren, J. Hummel, and A. Nicolau. Ab\u00adstractions \nfor recursive pointer data structures: Improving the analysis and transformation of im\u00adperative programs. \nIn Proc. SIGPLAN 92 Con\u00adference on Programming Language Design and Implementation, pages 249-260. ACM, \n1992. [7] C.A.R, Hoare. Recursive data structures. hter\u00adnational Journal of Computer and Information \nSciences, 4:2:105-132, 1975. [8] Robin Milner, Mads Tofte, and Robert Harper. The Definition of Standard \nML. MIT Press, 1990. [9] T. Reps. Incremental evaluation for attribute grammars with unrestricted movement \nbetween tree modifications. Acts Infornaatica, 25, 1986. [10] D.A. Turner. Miranda: A non-strict functional \nlanguage with polymorphic types. In Proc. Conf\u00aderence on Functional Programming Languages and Computer \nArchitecture, pages 1 16. Springer-Verlag (LNCS 201), 1985. Appendix: Formal Definitions This appendix \ncontains the formal definitions of the concepts introduced. They may be used to elucidate and substantiate \nthe contents of the preceding sum\u00admary. Al: Data Types Associated with a data type D we have some notation. \nThe main type is denoted Main D. By TV we denote the set of types. By TV(T: v)a we denote the type of \nthe data field a in variant v of type T, i.e., for the type\u00advariant above, Tv(T : v)ai = Ti. By VD we \ndenote the set of all variants in D; by VDT we denote the set of variants of type T. By Fv we denote \nthe set of all data fields in D; by FD (T: v) we denote the set of data fields of type T and variant \nv, i.e., for the type\u00advariant declaration above, FO(T : v) = {al, , . . . an}. An address a is an element \nof F;. The values of D is the set Val D of functions z : F% 4 Tv x VD such that dom x is finite and \nprefix closed;  c(e) = (Main P: v), for some v; and  forallacdom z,ifx(a) =(T:v)then  -vEVPT and -era \nEdomx ~ aCFD(T:v) A Tv(T: v)a = T where z(cra) = (T : v ) for some v . Intuitively, the addresses in \ndom % serve as pointer values. A2: Graph Types and Routing Expressions While F~ still denotea all fields, \nwe use F: to denote the data fields, and F; to denote the routing jields. We use the notation ~ (T: v) \na to denote the rout\u00ading expression associated with the routing field a in variant v of type T. The graph \ntype has an underlying data type Data Q which is obtained by removing all the routing fields. The routing \nexpressions must all be defined on Data G, as described below. Given a data type D, define the alphabet \nA that con\u00adsists of directives (letters) A; $; T; Ta and la, where aEFv; T and (T:v), where TETD and \nVEVVT. Given x E Val D we define the step relation -= on dom z x A x dom z by the following transitions: \n 6:=6 . 3 Cr -=cl if a is a leaf in z t a,a+= CY T4 cr. a+= a cr~= ffoa @ S=a if z(a) = (T : v) for some \nv ~ (~)= ~ if x(a) = (T :v) When Q ~= ~, we say that ~ is reached from CYby directive d. Note that @ \nsuch that a ~= ~ is uniquely defined, if it exists, by the values of a and d. Aroutep=dl.. . dn is a \nword over A. A walk in x from ac domx to ~Gdom x along p is the unique sequence, if it exists, cxo, . \n. . an = fl, such that ~i-1~= ~i for all i, 1 < i < n. The walk is denoted Q z= p. A routing expression \nR on D is a regular expression over A. We construct regular expressions using oper\u00adators + (union), . \n(concatenation), and * (iteration). The regular language defined by R is denoted L(R). Given x, R and \nan origin tYE dom x, a destination is a @c dorn x such that a ~= p for some route p E L(R). The set of \nall destinations is denoted Dest =(R, a). If this set is a singleton we say that R at a in z has the \nunique destination property. Intuitively, the routing expressions specify where the pointers in he routing \nfields should lead to. A graph type is only well-formed when all such expressions al\u00adways have the unique \ndestination property and always lead to subtrees of the specified types. The values of a well-formed \ngraph type G form the set Val G of finite graphs. There is a graph for every value in the underlying \ndata type. Given x E Val Data G we construct a graph whose nodes are dom x, the set of addresses in x. \nThe edges, which are labeled by field names, come in two flavors: data edges and routing edges. The data \nedges provide the canonical spanning tree-the backbone---and are defined as {a ~ aa Iaa G domz}. The \nrouting edges are defined as {a4pl a c F~z(a), Rgz(a)a = R, Dest .(R, cr) = {/3} } In this graph, addresses \nin F; (both data and routing fields) are defined. A3: Evaluating Routing Fields Here we give the details \nof the algorithm mentioned in Section 5. We are given a backbone z and a collection of nondeterministic \nfinite-state automata representing all routing expressions in the graph grammar. For an automaton A with \ntransition relation 4A and a word w=do . . . dn 6 A*, we write q _%A q to denote that there exists go, \n.d.., qn+l such that go = q, qn+l = i, and go ~ ql . ..-3 qn+~. Our goal is to build a table Tbl such \nthat for each node a in z and for each automaton A and each state q of A, the value of Tbl(cr, q) is \na node ~, if it exists, such that for some w GA*, a %= ~ and q ~.4 qF, where qF is a final state of A; \nif no such node exists then Tbl(a, q) = nil. The algorithm below employs a queue Q to calculate Tbl: \n1. Tbl(cr, q) := nil, for all nodes a in z and all au\u00adtomata states q 2. make Q empty 3. for all (a, \nq), where q is a final state: (a) Tb/(cx, q) := et (b) insert (a, q) in Q  4. while Q is non-empty: \n (a) delete an element (cr, q) from Q (b) for all (~, q ) such that Tb/(~, q ) = nil and   for some \nd,q 5A qand ~~= a: i. Tbl(fl, q ) := Tb/(~, q) ii. insert (~, q ) in Q Note that each entry (a, q) is \nconsidered at most once and that Step 4.(b) involves only the node a and its immediate neighbors thus \na number of nodes that depends on the grammar only. We conclude that the algorithm runs in linear time \nas a function of the size Ofz. With the well-formedness criterion it is not hard to see that the destination \nof a routing field at a is the node ~ if and only if there exists an initial state q of the corresponding \nautomaton such that Tbl(a, q) = ~. A4: Monadic Logic The monadic second-order logic of graph types, de\u00adnoted \nM2L GT, is used to express certain proper\u00adties of graph types. We first introduce a simpler logic, monadic \nsecond-order logic of data types, de\u00adnoted M2LDT. Fix a data type D. We define the M2LDT on D as follows. \nThere are two kinds of second-order variables, value variables and address set variables. A value variable \nx denotes a value of D. An address set variable M denotes a set of addresses of D. Such variables can \nbe combined with U, fl and 0 to form address set expressions. The set of addresses of z is denoted dom \nz, which is also a set expression. A first-order variable a, also called an address vam \u00adable, denotes \nan address of D. That a is an address in M is expressed as the formula a E M. A value variable z of type \nD is introduced by an existential quantifica\u00adtion 3DX or a universal quantification lfvx. Variables that \ndenote addresses or sets of addresses are intro\u00adduced by usual existential (3) or universal (V) quan\u00adtification. \nThe formulas of the logic are obtained by combining quantification, A (and), V (or), = (nega\u00ad .,. ?.. \n\u00adtion) with the following basic formulas: is A(cJ) ac = isc$(a) z(a) is a leaf variant isz (T: v)(a) \nz(a) = (T : v) is=T(a) z(a) = (T : v) for some v is=walk(a, ~, R) ~p c L(R) : cz~= ~ a=p El = E2 t~ ~82 \nfa E&#38; ~ = @.a a=/?ka aGFDz(@ and a = ~.a where &#38; and the &#38;i s are address set expressions. \nThe formulas have the obvious meanings, e.g. is=(T: v)(~) is true iff the type-variant at address a in \nz is (T: v). The formulaa = /3; aistrue if a = ~.a and aisa field of the type variant at a in z. Expressing \nwell-formedness The following formula in M2LDT expresses that a graph type G is well-formed: where D \n= Data ~ is the underlying data type; 3 ! is an abbreviation for there exists a unique ; and AND is an \nabbreviation expressing the conjunction obtained by expanding over the corresponding indices. Decidability \nof M2LDT Theorem 1 M2LDT is decidable. Proof M2LDT is decidable by an easy reduction to M2LkSFT, the \nmonadic second-order logic of k suc\u00adcessors on finite trees. The latter logic hss set vari\u00adables, such \nas X, denoting subsets of {1, . . . . k}* and jirst-order variables, such as a, denoting elements of \n{1,... , k}*. In addition there is a successor function .kforeachj E{l,..., k} and connective and quan\u00ad \ntifiers as above. We will indicate how formulas of M2LDT involving a data type D can be translated into \nM2LkSFT. We let k be [Fm[, the number of different fields in D, and we rename field names as 1,..., k. \nAn x in D introduced by a quantified for\u00admula 3ZJX : t is translated into 3Xd, X;,..., X~T, IX; ,..., \nxp : g A ~, where xd expresses dom z; x;,... X;= expresses the type at position a by the bit pattern \n(ac XJ,..., acX~T) (here nl = loglT~l); x;, . . . X~w expresses the variant at position a by the bit \npattern (a c X;,..., a c X~ ) (here n = log lV~ l); ~ is the translation of ~; and g is a formula expressing \nthat z is a value of D according to the con\u00additions on derivation trees given in Section 1. Address set \nvariables are just translated into set variables and address variables into first-order variables. Most \nof the basic formulas are now easy to express. For ex\u00adample, a = ~ i a is translated into a = f?.a A \na Ex; this formula is equivalent a = ~. a A a c F~z(~) since z c Val V. The basic formula iszwalk(a, \n,8, R) is more difficult, Here we encode the working of AR, the automaton equivalent to R, on z by a \nformula that guesses the subsets of states at each a that are accessi\u00adble from a partial ron (which is \nlike a run except that the last state need not be final) starting at cr. This collection of subsets can \nbe coded using IARI set vari\u00adables. We must then write a M2LkSFT formula ex\u00adpressing that all states \nin a subset have a predecessor for some directive under the transition relation (unless the state is \ninitial and in the subset at a). This alone is not sufficient. We must also write down a condition that \nensures that the collection of subsets is minimal with respect to the previous condition; technically, \nwe are calculating a least fixed-point in order to ensure that all states are reachable from initial \nstates at cr. The details of this translation are omitted. c1 Logic of graph types The monadic second-order \nlogic of graph types, M2LGT, has the same syntax as M2LDT. Theorem 2 M2LGT is decidable. Proof The translation \ninto M2LkSFT only differs for the formula a = /3 ; a. If a c F~z(@, then the translation must expresses \nthat is=walk(~, a, R), where R = R~z(~)a. We omit the details. c1  \n\t\t\t", "proc_id": "158511", "abstract": "<p>Recursive data structures are abstractions of simple records and pointers. They impose a shape invariant, which is verified at compile-time and exploited to automatically generate code for building, copying, comparing, and traversing values without loss of efficiency. However, such values are always tree shaped, which is a major obstacle to practical use.</p><p>We propose a notion of graph types, which allow common shapes, such as doubly-linked lists or threaded trees, to be expressed concisely and efficiently. We define regular languages of routing expressions to specify relative addresses of extra pointers in a canonical spanning tree. An efficient algorithm for computing such addresses is developed. We employ a second-order monadic logic to decide well-formedness of graph type specifications. This logic can also be used for automated reasoning about pointer structures.</p>", "authors": [{"name": "Nils Klarlund", "author_profile_id": "81100072411", "affiliation": "", "person_id": "PP39025867", "email_address": "", "orcid_id": ""}, {"name": "Michael I. Schwartzbach", "author_profile_id": "81392609511", "affiliation": "", "person_id": "P198767", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/158511.158628", "year": "1993", "article_id": "158628", "conference": "POPL", "title": "Graph types", "url": "http://dl.acm.org/citation.cfm?id=158628"}