{"article_publication_date": "01-26-2011", "fulltext": "\n Mathematizing C++ Concurrency Mark Batty Scott Owens Susmit Sarkar Peter Sewell Tjark Weber University \nof Cambridge Abstract Shared-memory concurrency in C and C++ is pervasive in systems programming, but \nhas long been poorly de.ned. This motivated an ongoing shared effort by the standards committees to specify \nconcurrent behaviour in the next versions of both languages. They aim to provide strong guarantees for \nrace-free programs, together with new (but subtle) relaxed-memory atomic primitives for high\u00adperformance \nconcurrent code. However, the current draft standards, while the result of careful deliberation, are \nnot yet clear and rigor\u00adous de.nitions, and harbour substantial problems in their details. In this paper \nwe establish a mathematical (yet readable) seman\u00adtics for C++ concurrency. We aim to capture the intent \nof the cur\u00adrent ( Final Committee ) Draft as closely as possible, but discuss changes that .x many of \nits problems. We prove that a proposed x86 implementation of the concurrency primitives is correct with \nrespect to the x86-TSO model, and describe our CPPMEM tool for exploring the semantics of examples, using \ncode generated from our Isabelle/HOL de.nitions. Having already motivated changes to the draft standard, \nthis work will aid discussion of any further changes, provide a cor\u00adrectness condition for compilers, \nand give a much-needed basis for analysis and veri.cation of concurrent C and C++ programs. Categories \nand Subject Descriptors C.1.2 [Multiple Data Stream Architectures (Multiprocessors)]: Parallel processors; \nD.1.3 [Con\u00adcurrent Programming]: Parallel programming; F.3.1 [Specifying and Verifying and Reasoning \nabout Programs] General Terms Documentation, Languages, Reliability, Stan\u00addardization, Theory, Veri.cation \nKeywords Relaxed Memory Models, Semantics 1. Introduction Context Systems programming, of OS kernels, \nlanguage run\u00adtimes, etc., commonly rests on shared-memory concurrency in C or C++. These languages are \nde.ned by informal-prose standards, but those standards have historically not covered the behaviour of \nconcurrent programs, motivating an ongoing effort to specify con\u00adcurrent behaviour in a forthcoming revision \nof C++ (unof.cially, C++0x) [AB10, BA08, Bec10]. The next C standard (unof.cially, C1X) is expected to \nfollow suit [C1X]. The key issue here is the multiprocessor relaxed-memory be\u00adhaviour induced by hardware \nand compiler optimisations. The de\u00adsign of such a language involves a tension between usability and performance: \nchoosing a very strong memory model, such as se- Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 11, January 26 28, 2011, Austin, Texas, USA. Copyright c \n&#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 quential consistency (SC) [Lam79], simpli.es \nreasoning about pro\u00adgrams but at the cost of invalidating many compiler optimisa\u00adtions, and of requiring \nexpensive hardware synchronisation instruc\u00adtions (e.g. fences). The C++0x design resolves this by providing \na relatively strong guarantee for typical application code together with various atomic primitives, with \nweaker semantics, for high\u00adperformance concurrent algorithms. Application code that does not use atomics \nand which is race-free (with shared state properly pro\u00adtected by locks) can rely on sequentially consistent \nbehaviour; in an intermediate regime where one needs concurrent accesses but performance is not critical \none can use SC atomics; and where performance is critical there are low-level atomics. It is expected \nthat only a small fraction of code (and of programmers) will use the latter, but that code concurrent \ndata structures, OS kernel code, language runtimes, GC algorithms, etc. may have a large effect on system \nperformance. Low-level atomics provide a com\u00admon abstraction above widely varying underlying hardware: \nx86 and Sparc provide relatively strong TSO memory [SSO+10, Spa]; Power and ARM provide a weak model \nwith cumulative barri\u00aders [Pow09, ARM08, AMSS10]; and Itanium provides a weak model with release/acquire \nprimitives [Int02]. Low-level atomics should be ef.ciently implementable above all of these, and proto\u00adtype \nimplementations have been proposed, e.g. [Ter08]. The current draft standard covers all of C++ and is \nrather large (1357 pages), but the concurrency speci.cation is mostly contained within three chapters \n[Bec10, Chs.1, 29, 30]. As is usual for indus\u00adtrial speci.cations, it is a prose document. Mathematical \nspeci.\u00adcations of relaxed memory models are usually either operational (in terms of an abstract machine \nor operational semantics, typically involving explicit buffers etc.) or axiomatic, de.ning constraints \non the relationships between the memory accesses in a complete candidate execution, e.g. with a happens-before \nrelation over them. The draft concurrency standard is in the style of a prose description of an axiomatic \nmodel: it introduces various relationships, identify\u00ading when one thread synchronizes with another, what \na visible side effect is, and so on (we explain these in \u00a72), and uses them to de.ne a happens-before \nrelation. It is obviously the result of extensive and careful deliberation. However, when one looks more \nclosely, it is still rather far from a clear and rigorous de.nition: there are points where the text \nis unclear, places where it does not capture the in\u00adtent of its authors, points where a literal reading \nof the text gives a broken semantics, several substantial omissions, and some open questions. Moreover, \nthe draft is very subtle. For example, driven by the complexities of the intended hardware targets, the \nhappens\u00adbefore relation it de.nes is intentionally non-transitive. The bottom line is that, given just \nthe draft standard text, the basic question for a language de.nition, of what behaviour is allowed for \na speci.c program, can be a matter for debate. Given previous experience with language and hardware mem\u00adory \nmodels, e.g. for the Java Memory Model [Pug00, MPA05, CKS07, SA08, TVD10] and for x86 multiprocessors \n[SSZN+09, OSS09, SSO+10], this should be no surprise. Prose language de.\u00adnitions leave much to be desired \neven for sequential languages; for relaxed-memory concurrency, they almost inevitably lead to ambi\u00adguity, \nerror and confusion. Instead, we need rigorous (but readable) mathematical semantics, with tool support \nto explore the conse\u00adquences of the de.nitions on examples, proofs of theoretical re\u00adsults, and support \nfor testing implementations. Interestingly, the style of semantics needed is quite different from that \nfor conven\u00adtional sequential languages, as are the tools and theorems.  Contributions In this paper \nwe establish a mathematically rig\u00adorous semantics for C++ concurrency, described in Section 2 and with \nfurther examples in Section 3. It is precise, formalised in Isabelle/HOL [Isa], and is complete, covering \nessentially all the concurrency-related semantics from the draft standard, without signi.cant idealisation \nor abstraction. It includes the data-race\u00adfreedom (DRF) guarantee of SC behaviour for race-free code, \nlocks, SC atomics, the various .avours of low-level atomics, and fences. It covers initialisation but \nnot allocation, and does not ad\u00address the non-concurrent aspects of C++. Our model builds on the informal-mathematics \ntreatment of the DRF guarantee by Boehm and Adve [BA08]. We have tried to make it as readable as possi\u00adble, \nusing only minimal mathematical machinery (mostly just sets, relations and .rst-order logic with transitive \nclosure) and introduc\u00ading it with a series of examples. Finally, wherever possible it is a faithful representation \nof the draft standard and of the intentions of its authors, as far as we understand them. In developing \nour semantics, we identi.ed a number of issues in several drafts of the C++0x standard, discussed these \nwith members of the concurrency subgroup, and made suggestions for changes. These are of various kinds, \nincluding editorial clari.cations, sub\u00adstantive changes, and some open questions. We discuss a selection \nof these in Section 4. The standards process for C++0x is ongoing: the current version is at the time \nof writing the .nal committee draft , leaving a small window for further improvements. That for C1X is \nat an earlier stage, though the two should be compatible. As a theoretical test of our semantics, we \nprove a correctness result (\u00a75) for the proposed prototype x86 implementation of the C++ concurrency \nprimitives [Ter08] with respect to our x86-TSO memory model [SSO+10, OSS09]. We show that any x86-TSO \nexecution of a translated C++ candidate execution gives behaviour that the C++ semantics would admit, \nwhich involves delicate issues about initialisation. This result establishes some con.dence in the model \nand is a key step towards a veri.ed compilation result about translation of programs. Experience shows \nthat tool support is needed to work with an axiomatic relaxed memory model, to develop an intuition for \nwhat behaviour it admits and forbids, and to explore the consequences of proposed changes to the de.nitions. \nAt the least, such a tool should take an example program, perhaps annotated with constraints on the .nal \nstate or on the values read from memory, and .nd and display all the executions allowed by the model. \nThis can be com\u00adbinatorially challenging, but for C++ it turns out to be feasible, for typical test examples, \nto enumerate the possible witnesses. We have therefore built a CPPMEM tool (\u00a76) that exhaustively considers \nall the possible witnesses, checking each one with code automatically generated from the Isabelle/HOL \naxiomatic model (\u00a76). The front\u00adend of the tool takes a program in a fragment of C++ and runs a symbolic \noperational semantics to calculate possible memory ac\u00adcesses and constraints. We have also explored the \nuse of a model generator (the SAT-solver-based Kodkod [TJ07], via the Isabelle Nitpick interface [BN10]) \nto .nd executions more ef.ciently, al\u00adbeit with less assurance. All of the examples in this paper have \nbeen checked (and their executions drawn) using CPPMEM. Our work provides a basis for improving both \nstandards, both by the speci.c points we raise and by giving a precisely de.ned check\u00adpoint, together \nwith our CPPMEM tool for exploring the behaviour of examples in our model and in variants thereof. The \nC and C++ language standards are a central interface in today s computational infrastructure, between \nwhat a compiler (and hardware) should im\u00adplement, on the one hand, and what programmers can rely on, \non the other. Clarity is essential for both sides, and a mathematically precise semantics is a necessary \nfoundation for any reasoning about concurrent C and C++ programs, whether it be by dynamic analy\u00adsis, \nmodel-checking, static analysis and abstract interpretation, pro\u00adgram logics, or interactive proof. It \nis also a necessary precondition for work on compositional semantics of such programs.  2. C++0x Concurrency, \nas Formalised Here we describe C++ concurrency incrementally, starting with single-threaded programs \nand then adding threads and locks, SC atomics, and low-level atomics (release/acquire, relaxed, and re\u00adlease/consume). \nOur model also covers fences, but we omit the de\u00adtails here. In this section we do not distinguish between \nthe C++ draft standard, which is the work of the Concurrency subcommit\u00adtee of WG21, and our formal model, \nbut in fact there are substantial differences between them. We highlight some of these (and our ra\u00adtionale \nfor various choices) in Section 4. Our memory model is ex\u00adpressed as a standalone Isabelle/HOL .le and \nthe complete model is available online [BOS]; here we give the main de.nitions, auto\u00admatically typeset \n(and lightly hand-edited in a few cases) from the Isabelle/HOL source. The semantics of a program p will \nbe a set of allowed execu\u00adtions X. Some C++ programs are deemed to have unde.ned be\u00adhaviour, meaning \nthat an implementation is unconstrained, e.g. if any execution contains a data race. Accordingly, we \nde.ne the se\u00admantics in two phases: .rst we calculate a set of pre-executions which are admitted by the \noperational semantics and are consis\u00adtent (de.ned in the course of this section). Then, if there is a \npre\u00adexecution in that set with a race of some kind, the semantics indi\u00adcates unde.ned behaviour by giving \nNONE, otherwise it gives all the pre-executions. In more detail, a candidate execution X is a pair (Xopsem,Xwitness), \nwhere the .rst component is given by the op\u00aderational semantics and the second is an existential witness \nof some further data; we introduce the components of both as we go along. The top-level de.nition of \nthe memory model, then, is: cpp memory model opsem (p : program)= let pre executions = {(Xopsem,Xwitness). \nopsem p Xopsem . consistent execution (Xopsem,Xwitness)} in if .X . pre executions . (indeterminate reads \nX = {}) . (unsequenced races X = {}) . (data races X= {}) then NONE else SOME pre executions  2.1 \nSingle-threaded programs We begin with the fragment of the model that deals with single\u00adthreaded programs, \nwhich serves to introduce the basic concepts and notation we use later. As usual for a relaxed memory \nmodel, different threads can have quite different views of memory, so the semantics cannot be expressed \nin terms of changes to a monolithic memory (e.g. a function from locations to values). Instead, an execution \nconsists of a set of memory actions and various relations over them, and the memory model axiomatises \nconstraints on those. For example, consider the program on the left below. This has only one execution, \nshown on the right. There are .ve actions, labelled (a) (e), all by the same thread (their thread ids \nare elided). These are all non-atomic memory reads (Rna)orwrites(Wna), with their address (x or y) and \nvalue (0,1, or 2). Actions (a) and (b) are the initialisation writes, (c) and (d) are the reads of the \noperands of the == operator, and (e) is a write of the result of ==. The evaluations of the arguments \nto == are unsequenced in C++ (as are arguments to functions), meaning that they could be in either order, \nor even overlapping. Evaluation order is expressed by the sequenced-before (sb) relation, a strict preorder \nover the actions, that here does not order (c) and (d). The two reads both read from the same write (a), \nindicated by the rf relation.  a:Wna x=2 sb int main() { int x=2; rf b:Wna y=0 rf int y=0; sb sb y \n= (x==x); return 0; } c:Rna x=2 d:Rna x=2 sb sb e:Wna y=1 The set of actions and the sequenced-before \nrelation are given by the operational semantics (so are part of the Xopsem); the rf re\u00adlation is existentially \nquanti.ed (part of the Xwitness), as in general there may be many writes that each read might read from. \nIn a non-SC semantics, the constraint on reads cannot be sim\u00adply that they read from the most recent \nwrite, as there is no global linear time. Instead, they are constrained here using a happens-before relation, \nwhich in the single-threaded case coin\u00adcides with sequenced-before. Non-atomic reads have to read from \na visible side effect, a write to the same location that happens-before the read but is not happens-before-hidden, \ni.e., one for which there is no intervening write to the location in happens-before. We de\u00ad.ne the visible-side-effect \nrelation below, writing it with an arrow. The auxiliary functions is write and is read pick out all actions \n(including atomic actions and read-modify-writes but not lock or unlock actions) that write or read memory. \nvisible-side-effect a ---------. b = happens-before a --------. b . is write a . is read b . same location \nab . \u00ac(.c. (c = a) . (c = b) . is write c . same location cb . happens-beforehappens-before a --------. \nc --------. b) The constraint on the values read by nonatomic reads is in two parts: the reads-from map \nmust satisfy a well-formedness condition (not shown here), saying that reads cannot read from multiple \nwrites, that they must be at the same location and have the same value as the write they read from, and \nso on. More interestingly, it must respect the visible side effects, in the following sense. consistent \nreads from mapping = (.b. (is read b . is at non atomic location b)=. visible-side-effect (if (.avse \n.avse ---------. b) visible-side-effect rf then (.avse .avse ---------. b . avse -. b) rf else \u00ac(.a. \na -. b))) . [...] If a read has no visible side effects (e.g. reading an uninitialised variable), there \ncan be no rf edge. This is an indeterminate read, and the program is deemed to have unde.ned behaviour. \nrf indeterminate reads = {b. is read b .\u00ac(.a. a -. b)} A pre-execution has an unsequenced-race if there \nis a write and another access to the same location, on the same thread that are unsequenced. unsequenced \nraces = {(a, b). (a = b) . same location ab . (is write a . is write b) . same thread ab . sequenced-beforesequenced-before \n\u00ac(a ---------. b . b ---------. a)} Programs with an execution that contains an unsequenced race (ur), \nlike the one below, have unde.ned behaviour. a:Wna x=2 int main() { sb int x = 2; rf int y = 0; b:Wna \ny=0 y = (x == (x=3)); sb ur sb return 0; } d:Rna x=2 c:Wna x=3 sb sb e:Wna y=0  2.2 Threads, Data Races, \nand Locks We now integrate C++-0x threads into the model. The following program spawns a thread that \nwrites 3 to x and concurrently writes 3 into y in the original thread. a:Wna x=2 sb asw void foo(int* \np) {*p = 3;} int main() { b:Wna t1=thrd1 e:Wna p=x int x= 2; sb sb,rf int y; thread t1(foo, &#38;x); \nc:Wna y=3 rf f:Rna p=x y=3; t1.join(); sb sb return 0; } d:Rna t1=thrd1 g:Wna x=3 The thread creation \ngives rise to additional-synchronizes-with asw (asw) edges (here a - . e) from sequenced-before-maximal \nac\u00adtions of the parent thread before the thread creation to sequenced\u00adbefore-minimal edges of the child. \nAs we shall see, these edges are also incorporated, indirectly, into happens-before. They are gener\u00adated \nby the operational semantics, so are another component of an Xopsem. Thread creation gives rise to many \nmemory actions (for passing function arguments and writing and reading the thread id) which clutter examples, \nso for this paper we usually use a more concise parallel composition, written {{{ ... ||| ... }}}: a:Wna \nx=2 int main() { asw,rf int x= 2; asw int y; {{{ x=3; b:Wna x=3 c:Rna x=2 dr ||| y = (x==3); }}}; sb \nreturn 0; } d:Wna y=0 This example exhibits a data race (dr): two actions at the same location, on different \nthreads, not related by happens-before, at least one of which is a write. data races = {(a, b). (a = \nb) . same location ab . (is write a . is write b) . \u00ac same thread ab . \u00ac(is atomic action a . is atomic \naction b) . happens-beforehappens-before \u00ac(a --------. b . b --------. a)} If there is a pre-execution \nof a program that has a data-race, then, as with unsequenced-races, that program has unde.ned be\u00adhaviour. \nData races can be prevented by using mutexes, as usual. These give rise to lock and unlock memory actions \non the mutex location, and a pre-execution has a relation, sc,aspartof Xwitness that totally orders such \nactions. A consistent locks predicate checks that lock and unlock actions are appropriately alternating. \nMoreover, these actions on each mutex create synchronizes-with edges from every unlock to every lock \nthat is ordered after it in sc. The synchronizes\u00adwith relation is a derived relation, calculated from \na candidate ex\u00adecution, which contains mutex edges, the additional-synchronizes\u00adwith edges (e.g. from \nthread creation), and other edges that we will come to.  synchronizes-with a ---------. b = (* additional \nsynchronisation, from thread create etc. *) additional-synchronizes-with a ---------------. b . (same \nlocation ab . a . actions . b . actions . ( (* mutex synchronization *) sc (is unlock a . is lock b \n. a -. b) . [...])) For multi-threaded programs with locks but without atom\u00adics, happens-before is the \ntransitive closure of the union of the sequenced-before and synchronizes-with relations. The de.nition \nof a visible side effect and the conditions on the reads-from rela\u00adtion are unchanged from the single-threaded \ncase.  2.3 SC Atomics For simple concurrent accesses to shared memory that are not pro\u00adtected by locks, \nC++0x provides sequentially consistent atomics. Altering the racy example from above to use an atomic \nobject x and SC atomic operations, we have the following, in which the concur\u00adrent access to x is not \nconsidered a data race, and so the program does not have unde.ned behaviour. a:WSC x=2 int main() { sb \natomic_int x;  rf,sc b:Wna x.store(2); int y=0; {{{ x.store(3); asw asw ||| y = ((x.load())==3); c:WSC \nx=3 d:RSC x=2 }}}; sc return 0; } sb e:Wna y=0 Semantically, this is because SC atomic operations are \ntotally or\u00addered by sc, and so can be thought of as interleaving with each other in a global time-line. \nTheir semantics are covered in de\u00adtail in [BA08] and we will describe their precise integration into \nhappens-before in the following section. Initialisation of an atomic object is by non-atomic stores (to \navoid the need for a hardware fence for every such initialisa\u00adtion), and those non-atomic stores can \nrace with other actions at the location unless the program has some synchronisation. Non\u00adinitialisation \nSC-atomic accesses are made with atomic read, write and read-modify-write actions that do not race with \neach other. 2.4 Low-level Atomics SC atomics are expensive to implement on most multiprocessors, e.g. \nwith the suggested implementations for an SC atomic load be\u00ading LOCK XADD(0) on x86 [Ter08] and hwsync; \nld; cmp; bc; isync on Power [MS10]; the LOCK d instruction and the hwsync may take 100s of cycles. They \nalso provide more synchronisation than needed for many concurrent idioms. Accordingly, C++0x in\u00adcludes \nseveral weaker variants: atomic actions are parametrised by a memory order, mo, that speci.es how much \nsynchronisa\u00adtion and ordering is required. The strongest ordering is required for MO SEQ CST actions \n(which is the default, as used above), and the weakest for MO RELAXED actions. In between there are MO \nRELEASE/MO ACQUIRE and MO RELEASE/MO CONSUME pairs, and MO ACQ REL with both acquire and release semantics. \n 2.5 Types and Relations Before giving the semantics of low-level atomics, we summarise the types and \nrelations of the model. There are base types of action ids aid, thread ids tid, locations l,andvalues \nv.Aswehaveseen already, actions can be non-atomic reads or writes, or mutex locks or unlocks. Additionally, \nthere are atomic reads, writes, and read\u00admodify-writes (with a memory order parameter mo) and fences \n(also with an mo parameter). We often elide the thread ids. action = aid, tid:Rnal = v non-atomic read \n| aid, tid:Wnal = v non-atomic write | aid, tid:Rmo l = v atomic read | aid, tid:Wmol = v atomic write \n| aid, tid:RMWmol = v1/v2 atomic read-modify-write | aid, tid:L l lock | aid, tid:U l unlock | aid, tid:Fmo \nfence The is read predicate picks out non-atomic and atomic reads and atomic read-modify-writes; the \nis write predicate picks out non\u00adatomic and atomic writes and atomic read-modify-writes. Locations are \nsubject to a very weak type system: each location stores a particular kind of object, as determined by \na location-kind map. The atomic actions can only be performed on ATOMIC lo\u00adcations. The non-atomic reads \nand writes can be performed on either ATOMIC or NON ATOMIC locations. Locks and unlocks are mutex actions \nand can only be performed on MUTEX loca\u00adtions. These are enforced (among other sanity properties) by \na well formed threads predicate; we elide the details here. The Xopsem part of a candidate execution \nX consists of a set of thread ids, a set of actions, a location typing, and three binary relations over \nits actions: sequenced-before (sb), additional-synchronized-with (asw), and data-dependency (dd). We \nhave already seen the .rst two: sequenced-before contains the intra-thread edges imposed by the C++ evaluation \norder, and additional-synchronized-with contains additional edges from thread creation and thread join \n(among others). Data dependence will be used for release/consume atomics (in \u00a72.8). These are all re\u00adlations \nthat are decided by the syntactic structure of the source code and the path of control .ow, and so the \nset of possible choices for an Xopsem can be calculated by the operational semantics without reference \nto the memory model (with reads taking unconstrained values). The Xwitness part of a candidate execution \nX consists of a fur\u00adther three binary relations over its actions: rf, sc,and modi.cation order (mo). \nThe rf reads-from map is a relation containing edges to read actions from the write actions whose values \nthey take, and edges to each lock action from the last unlock of its mutex. The sequentially consistent \norder sc is a total order over all actions that are MO SEQ CST and all mutex actions. The modi.cation \norder (mo) is a total order over all writes at each atomic location (leaving writes at different locations \nunrelated), and will be used to express coherence conditions. These relations are existentially quanti.ed \nin the de.nition of cpp memory model, and for each Xopsem ad\u00admitted by the operational semantics there \nmay be many choices of an Xwitness that give a consistent execution (each of which may or may not have \na data race, unsequenced race, or indeterminate read). The happens-before relation, along with several \nothers, are de\u00adrived from those in Xopsem and Xwitness.  2.6 Release/Acquire Synchronization An atomic \nwrite or fence is a release if it has the memory order MO RELEASE,MO ACQ REL or MO SEQ CST. Atomic reads \nor fences with order MO ACQUIRE,MO ACQ REL or MO SEQ CST, and fences with order MO CONSUME,are acquire \nactions.  Pairs of a write-release and a read-acquire support the following programming idiom. Here \none thread writes some data x (perhaps spanning multiple words) and then sets a .ag y while the other \nspins until the .ag is set and then reads the data. // sender // receiver x = ... while (0 == y); y=1; \n r=x; The desired guarantee here is that the receiver must see the data writes of the sender (in more \ndetail, that the receiver cannot see any values of data that precede those writes in modi.cation or\u00adder). \nThis can be achieved with an atomic store of y, annotated MO RELEASE, and an atomic load of y annotated \nMO ACQUIRE. The reads and writes of x can be nonatomic. In the model, any instance of a read-acquire \nthat reads from a write-release gives rise to a synchronizes-with edge, e.g. as on the left below (where \nthe rf edges are suppressed). a:Wna x=1 a:Wna x=1 sb sb b:WREL y=1 b:WREL y=1 sb,mo,rs sw sw c:WRLX \ny=2 c:RACQ y=1 rf d:RACQ y=2 sb sb d:Rna x=1 e:Rna x=1 For such programs (in fact for any program without \nre\u00adlease/consume atomics), happens-before is still the transitive clo\u00adsure of the union of the sequenced-before \nand synchronizes-with happens-before relations, so here a -------. d and (d) is obliged to read from \n(a). In this case, the read-acquire synchronizes with the write\u00adrelease that it reads from. More generally, \nthe read-acquire can syn\u00adchronize with a write-release (to the same location) that is before the write \nthat it reads from. To de.ne this precisely, we need to use the modi.cation order of a candidate execution \nand to introduce the derived notion of a release sequence, of writes that follow (in some sense) a write-acquire. \nFor example, in the fragment of an execution on the right above, the read-acquire (d) synchronizes with \nthe write-release (b) by virtue of the fact that (d) reads from another write to the same location, (c), \nand (b) precedes (c) in the modi.cation order (mo) for that location. The modi.cation order of a candidate \nexecution (here modi.cation-order b ---------. c) totally orders all of the write actions on each atomic \nlocation, in this case y. It must also be consistent with happens-before, in the sense below. consistent \nmodi.cation order = modi.cation-order (.a. .b. a ----------. b =. same location ab) . (.l . locations \nof actions. case location-kind l of ATOMIC . ( let actions at l = {a. (location a = SOME l)} in let \nwrites at l = {a . actions at l. (is store a . is atomic store a . is atomic rmw a)} in strict total \norder over writes at l modi.cation-order (----------.|actions at l ) . (* happens-before at the writes \nof l is a subset of mo for l *) happens-beforemodi.cation-order --------.|writes at l . ----------.. \n[...]) .. ( let actions at l = {a. (location a = SOME l)} in modi.cation-order (----------.|actions at \nl )= {})) In the example, the release action (b) has a release sequence [(b),(c)], a contiguous sub-sequence \nof modi.cation order on the location of the write-release. The release sequence is headed by the release \nand can be followed by writes from the same thread or read-modify-writes from any thread; other writes \nby other threads break the sequence. We represent a release sequence not by the list of actions but by \na relation from the head to all the elements, as the order is given by modi.cation order. In .gures we \nusually suppress the re.exive edge from the head to itself. rs element rs head a = same thread ars head \n. is atomic rmw a release-sequence ---------. b = is at atomic location b . is release arel . ( (b = \narel ) . arel modi.cation-order (rs element arel b . arel ----------. b . modi.cation-order modi.cation-order \n(.c.arel ----------. c ----------. b =. rs element arel c))) A write-release synchronizes-with a read-acquire \nif both act on the same location and the release sequence of the release contains release-sequence the \nwrite that the acquire reads from. In the example b --------. rf synchronizes-with c -- . d,sowehave \nb -------. d. The de.nition below covers mutexes and thread creation (in additional-synchronizes-with) \nbut elides the effects of fences. synchronizes-with a ---------. b = (* additional synchronization, \nfrom thread create etc. *) additional-synchronizes-with a ---------------. b . (same location ab . a \n. actions . b . actions . ( (* mutex synchronization *) sc (is unlock a . is lock b . a -. b) . (* \n release/acquire synchronization *) (is release a . is acquire b .\u00ac same thread ab . release-sequencerf \n(.c. a ---------. c -. b)) . [...])) The modi.cation order and the sc order we saw earlier must also \nbe consistent, in the following sense: consistent sc order = happens-before let sc happens before = --------.|all \nsc actions in modi.cation-order let sc mod order = ----------.|all sc actions in sc strict total order \nover all sc actions ( -.) . sc happens before sc ------------.. -.. sc mod order sc ---------.. -.  \n2.7 Constraining Atomic Read Values The values that can be read by an atomic action depend on happens\u00adbefore, \nderived from sequenced-before and synchronizes-with. We return to the execution fragment shown on the \nright in the previous subsection, showing a transitive reduction of happens-before that coincides with \nits constituent orderings. a:Wna x=1 d:RACQ y=2 hb hb hbb:WREL y=1 e:Rna x=1 hb c:WRLX y=2 An atomic \naction must read a write that is in one of its visible sequences of side effects; in this case (d) either \nreads (b) or (c).  A visible sequence of side effects of a read is a contiguous sub\u00adsequence of modi.cation \norder, headed by a visible side effect of the read, where the read does not happen before any member \nof the sequence. We represent a visible sequence of side effects not as a list but as a set of actions \nin the tail of the sequence (we are not concerned with their order). visible sequence of side e.ects \ntail vsse head b = modi.cation-order {c. vsse head ----------. c . happens-before \u00ac(b --------. c) . \nmodi.cation-order modi.cation-order (.a. vsse head ----------. a ----------. c happens-before =.\u00ac(b --------. \na))} We de.ne visible-sequences-of-side-effects to be the binary re\u00adlation relating atomic reads to their \nvisible-side-effect sets (now in\u00adcluding the visible side effects themselves). The atomic read must read \nfrom a write in one of these sets. We can now extend the previous de.nition of the consistent reads-from \npredicate to be the conjunction of the read-restrictions on nonatomic and atomic actions, and a constraint \nensuring read\u00admodify-write atomicity. consistent reads from mapping = (.b. (is read b . is at non atomic \nlocation b)=. visible-side-effect (if (.avse .avse ---------. b) visible-side-effect rf then (.avse .avse \n---------. b . avse -. b) rf else \u00ac(.a. a -. b))) . (.b. (is read b . is at atomic location b)=. (if \n(.(b', vsse) . visible-sequences-of-side-effects. (b' = b)) then (.(b', vsse) . visible-sequences-of-side-effects. \nrf (b' = b) . (.c . vsse. c -. b)) rf else \u00ac(.a. a -. b))) . rf (.(a, b) . -.. is atomic rmw b modi.cation-order \n=.-. b) . a |--------- [...] A candidate execution is also required to be free of the following four \nexecution fragments. This property is called coherence.  c:Wx=1 a:W x=1 c:R x=1 b:Wx=2 morf  rf hbmo \nhb b:W x=2 d:R x=2 d:R x=2 rf CoWR CoRR a:W x=1 a:W x=1 c:R x=1 rf hb mo hb mo b:W x=2 d:W x=2 CoWW \nCoRW CoRR Two reads ordered by happens-before may not read two writes that are modi.cation ordered in \nthe other direction. CoWR It is forbidden to read from a write that is happens-before\u00adhidden by a later \nwrite in modi.cation order. CoWW Happens-before and modi.cation-order may not disagree. CoRW The union \nof the reads-from map, happens-before and modi.cation-order must be acyclic. Finally, we restrict SC \nreads: If there is no preceding write in sc order, then there is no extra restriction. Otherwise, they \nmust read from the last prior write in sc order, from a non-atomic write that follows it in modi.cation \norder, or from any non-SC atomic write.  2.8 Release/Consume Atomics On multiprocessors with weak memory \norders, notably Power, release/acquire pairs are cheaper to implement than sequentially consistent atomics \nbut still signi.cantly more expensive than plain stores and loads. For example, the proposed Power im\u00adplementation \nof load-acquire, ld; cmp; bc; isync,involvesan isync [MS10]. However, Power (and also ARM) does guarantee \nthat certain dependencies in an assembly program are respected, and in many cases those suf.ce, making \nthe isync sequence un\u00adnecessary. As we understand it, this is the motivation for introduc\u00ading a read-consume \nvariant of read-acquire atomics. On a stronger processor (e.g. a TSO x86 or Sparc), or one where those \ndependen\u00adcies are not respected, read-consume would be implemented just as read-acquire. Read-consume \nenables ef.cient implementations of algorithms that use pointer reassignment for commits of their data, \ne.g. read\u00adcopy-update [MW]. For example, suppose one thread writes some data (perhaps spanning multiple \nwords) then writes the address of that data to a shared atomic pointer, while the other thread reads \nthe shared pointer, dereferences it and reads the data. // sender // receiver data = ... r1=p p = &#38;data; \n r2 = *r1; // data Here there is a dependency at the receiver from the read of p to the read of data. \nThis can be expressed using a write-release and an atomic load of p annotated MO CONSUME: int main() \n{ int data; atomic_address p; {{{ { data=1; p.store(&#38;data, mo_release); } ||| printf(\"%d\\n\", *(p.load(mo_consume)) \n); }}}; return 0; } As we saw in \u00a72.6, the semantics of release/acquire pairs intro\u00adduced synchronizes-with \nedges, and happens-before includes the transitive closure of synchronizes-with and sequenced-before \nfor a release/acquire version of this example, we would have the happens-before edges on the left below, \nand hence a -------. d. a:WSC data=1 a:WSC data=1 sb sb b:WREL p=data b:WREL p=data dob sw c:RACQ p=data \ndob c:RCON p=data sb,dd sb,dd,cad d:RSC data=1 d:RSC data=1 For release/consume, the key fact is that \nthere is a data dependency (dd) from (c) to (d), as shown on the right. The (dd) edge is provided by \nthe operational semantics and gives rise to a carries\u00ada-dependency-to (cad) edge, which extends data \ndependency with thread-local reads-from relationships: carries-a-dependency-to a ------------. b = rf \nsequenced-beforedata-dependency a ((-.n ---------.) . ---------.)+ b In turn, this gives rise to a dependency-ordered-before \n(dob) edge, which is the release/consume analogue of the release/acquire synchronizes-with edge. This \ninvolves release sequences as before (in the example just the singleton [(b)]): dependency-ordered-before \na --------------. d = a . actions . d . actions . (.b. is release a . is consume b . release-sequencerf \n(.e. a ---------. e -. b) . carries-a-dependency-to (b ------------. d . (b = d)))  2.9 Happens-before \nFinally, we can de.ne the complete happens-before relation. To accommodate MO CONSUME, and speci.cally \nthe fact that re\u00adlease/consume pairs only introduce happens-before relations to dependency-successors \nof the consume, not to all actions that are sequenced-after it, the de.nition is in two steps. First, \nwe de\u00ad.ne inter-thread-happens-before, which combines synchronizes\u00adwith and dependency-ordered-before, \nallowing transitivity with sequenced-before on the left for both and on the right only for synchronizes-with: \ninter-thread-happens-before --------------. = synchronizes-with let r = ---------.. dependency-ordered-before \n--------------.. synchronizes-withsequenced-before (---------.. ---------.) in rsequenced-beforer (-.. \n(---------.. -.))+ In any execution, this must be acyclic: consistent inter thread happens before = inter-thread-happens-before \nirre.exive ( --------------.) Happens-before (which is thereby also acyclic) is then just the union with \nsequenced-before: happens-before --------. = sequenced-beforeinter-thread-happens-before ---------.. \n--------------. 2.10 Putting it together Given a candidate execution X =(Xopsem,Xwitness), we can now \ncalculate the derived relations: release-sequence (\u00a72.6), hypothetical-release-sequence (a variant of \nrelease-sequence used in the fence semantics), synchronizes-with (\u00a72.2, \u00a72.6), carries-a-dependency-to \n(\u00a72.8), dependency-ordered-before (\u00a72.8), inter-thread-happens-before (\u00a72.8), happens-before (\u00a72.1, \u00a72.2, \n\u00a72.3, \u00a72.8), visible-side-effect (\u00a72.1), and visible-sequences-of-side-effects (\u00a72.7). The de.nition \nof consistent execution used at the start of Sec\u00adtion 2 is then simply the conjunction of the predicates \nwe have de\u00ad.ned: consistent execution = well formed threads . (\u00a72.5, defn. elided) consistent locks . \n(\u00a72.2, defn. elided) consistent inter thread happens before . (\u00a72.8) consistent sc order . (\u00a72.6) consistent \nmodi.cation order . (\u00a72.6) well formed reads from mapping . (\u00a72.1, defn. elided) consistent reads from \nmapping (\u00a72.1, \u00a72.7) The acyclicity check on inter-thread-happens-before, and the subtlety of the non-transitive \nhappens-before relation, are needed only for release/consume pairs: Theorem 1. For an execution with \nno consume opera\u00adtions, the consistent inter thread happens before condition of consistent execution \nis redundant. Theorem 2. If a consistent execution has no consume operations, happens-before is transitive. \nThe proofs are by case analysis and induction on the size of possible cycles.  3. Examples We now illustrate \nthe varying strength of the different memory orders by showing the semantics of some classic examples. \nIn all cases, variants of the examples with SC atomics do not have the weak-memory behaviour. As in our \nother diagrams, to avoid clutter we only show selected edges, and we omit the C++ sources for these examples, \nwhich are available on-line [BOS]. Store Buffering (SB) Here two threads write to separate loca\u00adtions \nand then each reads from the other location. In Total Store Order (TSO) models both can read from before \n(w.r.t. coherence) the other write in the same execution. In C++0x this behaviour is allowed if those \nfour actions are relaxed, for release/consume pairs and for release/acquire pairs. This behaviour is \nnot allowed for the same program using sequentially consistent consistent atomics (with non-atomic initialisation). \nMessage Passing (MP) Here one thread (non-atomically) writes data and then an atomic .ag while a second \nthread waits for the .ag and then (non-atomically) reads data; the question is whether it is guaranteed \nto see the data written by the .rst. As we saw in \u00a72.6, with a release/acquire pair it is. A release/consume \npair gives the same guarantee iff there is a dependency between the reads, otherwise there is a consistent \nexecution (on the left) in which there is a data race (here the second thread sees the initial value \nof x; the candidate execution in which the second thread sees the write x=1 is ruled out as that does \nnot happen-before the read and so is not a visible side effect). b:Wna x=1 d:RCON y=1 c:WRLX x=1 e:RRLX \nx=1 g:RRLX y=1 rf drsb sb sb sbrf sb c:WREL y=1 e:Rna x=0 d:WRLX y=1 f:RRLX y=0 h:RRLX x=0 The same holds \nwith relaxed .ag operations. In a variant in which all writes and reads are release/consumes or relaxed \natomics, eliminating the race, and there are two copies of the reading thread, the two reading threads \ncan see the two writes of the writing thread in opposite orders (as on the right above) consistent with \nwhat one might see on Power, for example. Load Buffering (LB) In this dual of the SB example the ques\u00adtion \nis whether the two reads can both see the (sequenced-before) later write of the other thread in the same \nexecution. With relaxed atomics this is allowed, as on the left: hb c:RRLX x=1 e:RRLX y=1 c:R x=1 e:RCON \ny=1 rf sb,hb dob dob sb,hbsb sb rf d:WRLX y=1 f:WRLX x=1 d:WREL y=1 f:WREL x=1 but with release/consumes \n(with dependencies) it is not (as on the right above), because inter-thread-happens-before would be cyclic. \nIt is not allowed for release/acquire and sequentially con\u00adsistent atomics (which are stronger than release/consumes \nwith de\u00adpendencies), because of the cyclic inter-thread-happens-before and stronger inter-thread ordering. \nWrite-to-Read Causality (WRC) Here the .rst thread writes to x; the second reads from that and then (w.r.t. \nsequenced-before) writes to y; the third reads from that and then (w.r.t. sequenced\u00adbefore) reads x. \nThe question is whether it is guaranteed to see the .rst thread s write. c:WRLX x=1 d:RRLX x=1 f:RRLX \ny=1rf sb sb rf e:WRLX y=1 g:RRLX x=0 With relaxed atomics, this is not guaranteed, as shown above, while \nwith release/acquires it is, as the synchronizes-with edges in the inter-thread-happens-before relation \ninterfere with the required read-from map.  Independent Reads of Independent Writes (IRIW) Here the \n.rst two threads write to different locations; the question is whether the second two threads can see \nthose writes in different orders. With relaxed, release/acquire, or release/consume atomics, they can. \nrf rf c:WREL x=1 d:WREL y=1 e:RACQ x=1 g:RACQ y=1 sb sb f:RACQ y=0 h:RACQ x=0  4. From standard to formalisation \nand back We developed the model presented in Section 2 by a lengthy iter\u00adative process: building formalisations \nof various drafts of the stan\u00addard, and of Boehm and Adve s model without low-level atom\u00adics [BA08]; \nconsidering the behaviour of examples, both by hand and with our tool; trying to prove properties of \nthe formalisations; and discussing issues with members of the Concurrency subcom\u00admittee of the C++ Standards \nCommittee (TC1/SC22/WG21). To give a .avour of this process, and to explain how our formalisation differs \nfrom the current draft (the .nal committee draft, N3092) of the standard, we describe a selection of \ndebatable issues. This also serves to bring out the delicacy of the standard, and the pitfalls of prose \nspeci.cation, even when carried out with great care. We have made suggestions for technical or editorial \nchanges to the draft for many of these points and it seems likely that they will be incorpo\u00adrated. We \nbegin with two straightforward drafting issues, easily .xed. Then there are three substantial semantic \nproblems in N3092 where we have proposed solutions. Finally, there is an outstanding ques\u00adtion that warrants \nfurther investigation. Subsequent in visible sequences of side effects N3092 de\u00ad.nes: The visible sequence \nof side effects on an atomic object M, with respect to a value computation B of M, is a maximal contigu\u00adous \nsub-sequence of side effects in the modi.cation order of M, where the .rst side effect is visible with \nrespect to B, and for ev\u00adery subsequent side effect, it is not the case that B happens before it. However, \nif every element in a vsse happens-before a read, the read should not take the value of the visible side \neffect. Following discussion, we formalise this without the subsequent. Additional happens-before edges \nThere are 6 places where N3092 adds happens-before relationships explicitly (in addition to those from \nsequenced-before and inter-thread-happens-before), e.g. between the invocation of a thread constructor \nand the function that the thread runs. As happens-before is carefully not transitively closed, such edges \nwould not be transitive with (e.g.) sequenced\u00adbefore. Accordingly, we instead add them to the synchronizes\u00adwith \nrelation; for those within our C++ fragment, our operational semantics introduces them into additional-synchronizes-with. \nAcyclicity of happens-before N3092 de.nes happens-before, making plain that it is not necessarily transitive, \nbut does not state whether it is required to be acyclic (or whether, perhaps, a pro\u00adgram with a cyclic \nexecution is deemed to have unde.ned be\u00adhaviour). The release/consume LB example of \u00a73 has a cyclic inter\u00adthread-happens-before, \nas shown there, but is otherwise a con\u00adsistent execution. After discussion, it seems clear that executions \nwith cyclic inter-thread-happens-before (or, equivalently, cyclic happens-before) should not be considered, \nso we impose that ex\u00adplicitly. Coherence requirements The draft standard enforced only two of the four \ncoherence requirements presented in \u00a72.7, CoRR and CoWW. In the absence of CoRW and CoWR, the following \nexecu\u00adtions were allowed. b:WREL x=1 c:RCON x=1 a:RMWREL x=0/1 d:WREL x=0 rf,dob mo,rs sb,mo sb rf mo \nb:WSC x=2 sw,vse sb,vse d:WREL x=2 c:RSC x=1 The execution on the left violates CoRW by containing a \ncycle of happens-before and modi.cation order edges, allowed only due to the lack of transitivity of \nhappens-before. The execution on the right violates CoWR by having a read from a write (the read\u00admodify-write \n(a)) that is sequenced-before-hidden by (c). Actions (b) and (c) are shown as SC atomics for emphasis. \nFurthermore, the draft standard refers to the visible sequence of side-effects, suggesting uniqueness. \nNevertheless, it allows valid executions that have more than one, relying on the lack of transitiv\u00adity \nof happens-before as in the CoRW execution above. These behaviours are surprising and were not intended \nby the designers. Sequential consistency for SC atomics The promise of sequen\u00adtial consistency to the \nnon-expert programmer is a central design choice of C++0x and is stated directly by N3092: memory order \nseq cst ensures sequential consistency [...] for a program that is free of data races and uses exclusively \nmemory order seq cst operations. Unfortunately N3092 allows the following non\u00adsequentially consistent \nexecution of the SB example with SC atom\u00adics (initialisation writes, such as (a) and (b), are non-atomic \nso that they need not be compiled with memory fences): a:Wna x=0 sb b:Wna d:RSC x=0 f:RSC y=0   We \ndevised a stronger restriction on the values that may be read by SC atomics, stated in \u00a72.7, that does \nprovide sequential consistency here. Overlapping executions and thin-air reads In a C++0x pro\u00adgram that \ngives rise to the relaxed LB example in \u00a73, the written value 1 might have been concrete in the program \nsource. Alterna\u00adtively, one might imagine a thin-air read: the program below has the same execution, \nand here there is no occurrence of 1 in the pro\u00adgram source. int main() { int r1, r2; atomic_int x = \n0; atomic_int y = 0; c:RRLX x=1 e:RRLX y=1 {{{ { r1 = x.load(mo_relaxed)); rf y.store(r1,mo_relaxed); \n} sb sb rf ||| { r2 = y.load(mo_relaxed)); d:WRLX y=1 f:WRLX x=1 x.store(r2,mo_relaxed); } }}} return \n0; } This would be surprising, and in fact would not happen with typical hardware and compilers. In \nthe Java Memory Model [MPA05], much of the complexity of the model arises from the desire to outlaw thin-air \nreads, which there is essential to prevent forging of pointers. N3092 also attempts to forbid thin air \nreads, with: An atomic store shall only store a value that has been computed from constants and program \ninput values by a .nite sequence of program evaluations, such that each evaluation observes the values \nof variables as computed by the last prior assignment in the sequence. This seems to be overly constraining. \nFor example, two subexpression evaluations (in separate threads) can overlap (e.g. if they are the arguments \nof a function call) and can contain multiple actions. With relaxed atomics there can be consistent executions \nin which it is impossible to disentangle the two into any sequence, for example as below, where the SC-write \nof x must be between the two reads of x. In our formalisation we currently do not impose any thin-air \ncondition.  a:Wna x=0 int main() { atomic_int x = 0; int y; {{{ x.store(1); ||| { y = (x.load()==x.load()); \n}}}; return 0; } e:Wna y=0  5. Correctness of a Proposed x86 Implementation The C++0x memory model has \nbeen designed with compilation to the various target architectures in mind, and prototype implemen\u00adtations \nof the atomic primitives have been proposed. For example, the following table presents an x86 prototype \nby Terekhov [Ter08]: Operation x86 Implementation Load non-SC Load Seq cst mov lock xadd(0) OR: mfence, \nmov Store non-SC mov Store Seq cst lock xchg OR: mov , mfence Fence non-SC Fence Seq cst no-op mfence \n This is a simple mapping from individual source-level atomic op\u00aderations to small fragments of assembly \ncode, abstracting from the vast and unrelated complexities of compilation of a full C++ lan\u00adguage (argument \nevaluation order, object layout, control .ow, etc.). Proposals for the Power [MS10] and other architectures \nfollow the same structure, although, as they have more complex memory mod\u00adels than the x86, the assembly \ncode for some of the operations is more intricate. Verifying that these prototypes are indeed correct \nimplementa\u00adtions of the model is a crucial part of validating the design. Further\u00admore, as they represent \nthe atomic-operation parts of ef.cient com\u00adpilers (albeit without fence optimisations), they can directly \nform an important part of a veri.ed C++ compiler, or inform the design and veri.cation of a compiler \nwith memory-model-aware optimi\u00adsations. Here, we prove a version of the above prototype x86 imple\u00admentation \n[Ter08] correct with respect to our x86-TSO seman\u00adtics [SSZN+09, OSS09, SSO+10]. Following the prototype, \nwe ignore lock and unlock operations, as well as forks and joins, all of which require signi.cant runtime \nor operating system support in addition to the x86 hardware. We also ignore sequentially consis\u00adtent \nfences, but cover all other fences. We do consider read-modify\u00adwrite actions, implementing them with \nx86 LOCK d read-modify\u00adwrites; and we include non-atomic loads and stores, which can map to multiple \nx86 loads and stores, respectively. The prototype map\u00adping is simple, and x86-TSO is reasonably well-understood, \nso this should be seen as a test of the C++ memory model. In x86-TSO, an operational semantics gives \nmeaning to an as\u00adsembly program by creating an x86 event structure Ex86 (analo\u00adgous to Xopsem) comprising \na set of events and an intra-thread program-order relation (analogous to sequenced-before) that or\u00adders \nevents according to the program text. Events can be reads, writes, or fences, and certain instructions \n(e.g. CMPXCHG) cre\u00adate locked sets of events that execute atomically. Corresponding to Xwitness,thereare \nx86 execution witnesses Xx86 which comprise a reads-from mapping and a memory order, which is a partial \norder over reads and writes that is total on the writes. The remainder of the axiomatisations are very \ndifferent: x86-TSO has no concept of release, acquire, visible side effect, etc. Abstracting out the \nrest of the compiler To discuss the correct\u00adness of the proposed mapping in isolation, without embarking \non a veri.cation of some particular full compiler, we work solely in First, we lift the mapping between \ninstructions to a nondeter\u00administic translation action comp from C++ actions to small x86 event structures, \ne.g. relating an atomic read-modify-write action to the events of the corresponding x86 LOCK d instruction. \nTo de.ne what it means for the mapping to be correct, suppose we have a C++ program p with no unde.ned \nbehaviour and an which is allowed by its operational semantics. We regard comp as taking such an Xopsem \nand giving an x86 event structure Ex86, respecting the action comp mapping but with some freedom in the \nresulting x86 program order. We say the mapping is correct if given such an abstract com\u00adpiler, the existence \nof a valid x86-TSO execution witness for Ex86 implies the existence of a consistent C++ execution witness \nXwitness for the original actions Xopsem. We prove this by lifting such an x86 execution witness to a \nC++ consistent execution, as illustrated below. consistent execution Xopsem  Xwitness -1 evt comp evt \ncomp Ex86 Xx86 valid execution Belowweshowan Xopsem and Ex86 that could be related by evt comp. The \ndotted lines indicate some of the x86 program or\u00addering decisions that the compiler must make, but which \nevt comp does not constrain. In more detail, we use two existentially quanti.ed helper func\u00adtions locn \ncomp and tid comp to encapsulate the details of a C++ compiler s data layout, its mapping of C++ locations \nto x86 ad\u00addresses, and the mapping of C++ threads to x86 threads. Given a C++ location and value, locn \ncomp produces a .nite mapping from x86 addresses to x86 values. The domain of the .nite map is the set \nof x86 addresses that corresponds to the C++ location, and the mapping itself indicates how a C++ value \nis laid out across the x86 addresses. A well-formed locn comp has the following properties: it is injective; \nthe address calculation cannot depend on the value; each C++ location has an x86 address; different C++ \nlocations have non-overlapping x86 address sets; and an atomic C++ location has a single x86 address, \nalthough a non\u00adatomic location can have several addresses (e.g. for a multi-word object).  Finally, \nthe evt comp relation speci.es valid translations, ap\u00adplying action comp with a well-formed locn comp \nandalsocon\u00adstraining how events from different actions relate: no single x86 instruction instance can \nbe used by multiple C++ actions, and the x86 program-order relation must respect C++ s sequenced-before. \nThe detailed de.nitions, and the proof of the following theorem, are available online [BOS]. Theorem \n3. Let p be a C++ program that has no unde.ned behaviour. Suppose also that p contains no SC fences, \nforks, joins, locks, or unlocks. Then the x86 mapping is correct in the sense above. That is, if actions, \nsequenced-before, and location-kind are members of the Xopsem part of a candidate execution resulting \nfrom the operational semantics of p, then the following holds: .comp locn comp tid comp Xx86. evt comp \ncomp locn comp tid comp actions sequenced-before location-kind . valid execution (.a.actions (comp a)) \nXx86 . .Xwitness. consistent execution (Xopsem,Xwitness) Proof outline. Xx86 includes a reads-from map \nand a memory ordering relation that is total on all memory writes. To build Xwitness, we lift a C++ reads-from \nmap and modi.cation order from these through comp (e.g., a -rf . b iff .(e1 . comp a)(e2 . x86-rf comp \nb). e1 ---. e2). We create an sc ordering by restricting the Xx86 memory ordering to the events that \noriginate in sequen\u00adtially consistent atomics, and linearising it using the proof tech\u00adnique from our \nprevious triangular-race freedom work for x86-TSO [Owe10]. We then lift that through comp. The proof \nnow pro\u00adceeds in three steps: happens-before 1) We .rst show that if a -------. b and there are x86 events \ne1 and e2 such that e1 . comp a and e2 . comp b,then e1 precedes e2 in either Xx86 s memory order or \nprogram order. We have machine-checked this step in HOL-4 [HOL].1 This property establishes that, in \nsome sense, x86-TSO has a stronger memory model than C++, and so any behaviour allowed by the former \nshould be allowed by the latter. However, things are not quite so straightforward. 2) Check that Xwitness \nis a consistent execution. Most cases are machine checked in HOL; some are only pencil-and-paper. Many \nrely upon the property from 1. For example, in showing that rf visible-side-effect (at a non-atomic location) \nif a --. b,we . b then a -------note that if there were a write c to the same location such that happens-beforehappens-before \na -------. c -------. b, then using the property from 1, there is an x86 write event in comp c that would \ncome between the events of comp a and comp b in Xx86, thus meaning that they would not be in Xx86 s reads-from \nmap, contradicting the construction of Xwitness s reads from map. 3) In some cases, some of the properties \nrequired for 2 might be rf visible-side-effect false. For example, in showing that a --. . b implies \na ------- happens-before b, we need to show that a -------. b. Even though there is such a relationship \nat the x86 level, it does not necessarily exist in C++. In general, x86 executions can establish reads-from \nrelations 1 The C++ model is in Isabelle/HOL, but x86-TSO is in HOL-4. We support the proof with a semi-automated \ntranslation from Isabelle/HOL to HOL-4. that are prohibited in C++. Similarly, for non-atomic accesses \nthat span multiple x86 addresses, the lifted reads from-map might not be well-formed. We show that if \none of these violations of 2 arises, then the original C++ program has a data race. We .nd a minimum \nviolation in Xx86, again using techniques from our previous work [Owe10]. Next we can remove the violation, \nresulting in a consistent Xwitness for a pre.x of the execution, then we add the bad action, note that \nit creates a data race, and allow the program to complete in any way. The details of this part are by \npencil-and-paper proof. Sequentially consistent atomics The proposal above includes two implementations \nof sequentially consistent atomic reads and writes; one with the x86 locked instructions, and the other \nwith fence instructions on both the reads and writes. However, we can prove that it suf.ces either to \nplace an mfence before every sc read, or after every sc write, but that it is not necessary to do both. \nIn practice, placing the fence after the sc writes is expected to yield higher performance. This optimisation \nis a direct result of using triangular-race free\u00addom (TRF) [Owe10] to construct the sc ordering in proving \nThe\u00adorem 3. Roughly, our TRF theorem characterises when x86-TSO executions are not sequentially consistent; \nit uses a pattern, called a triangular race, involving an x86-level data race combined with a write followed, \non the same thread, by a read without a fence (or locked instruction) in between. If no such pattern \nexists, then an execution Xx86 can be linearised such that each read reads from the most recent preceding \nwrite. Although the entirety of an execution witness Xx86 might con\u00adtain triangular races and therefore \nnot be linearisable, by restricting attention to only sc reads and writes we get a subset of the execu\u00adtion \nthat is TRF, as long as there is a fence between each sc read and write on the same thread. Linearising \nthis subset guarantees the relevant property of Xwitness s sc ordering: that if a and b are sequentially \nconsistent atomics and a -rf . b,then a immediately precedes b in sc restricted to that address. Compiler \ncorrectness Although we translate executions instead of source code, Theorem 3 could be applied to full \nsource-to\u00adassembly compilers that follow the prototype implementation. The following diagram presents \nthe overall correctness property. w.f. threads consistent execution p Xopsem Xwitness g compiler f  \n' p Ex86 Xx86 w.f. events valid execution If, onceweuse f , we can then apply evt comp to get the same \nevent set back, i.e., informally, evt comp(f(E)) = E, then The\u00adorem 3 ensures that the compiler respects \nthe memory model, and so we only need to verify that it respects the operational semantics. Thus, our \nresult applies to compilers that do not optimise away any instructions that evt comp will produce. These \nrestrictions apply to the code generation phase; the compiler can perform any valid source-to-source \noptimisations before generating x86 code.  6. Tool support for exploring the model Given a relatively \ncomplex axiomatic memory model, as we pre\u00adsented in Section 2, it is often hard to immediately see the \ncon\u00adsequences of the axioms, or what behaviour they allow for partic\u00adular programs. Our CPPMEM tool takes \na program in a fragment of C++0x and calculates the set of its executions allowed by the memory model, \ndisplaying them graphically.  The tool has three main components: an executable symbolic operational \nsemantics to build the Xopsem parts of the candidate executions X of a program; a search procedure to \nenumerate the possible Xwitness for each of those; and a checking procedure to calculate the derived \nrelations and predicates of the model for each (Xopsem,Xwitness) pair, to check whether it is consistent \nand whether it has data races, unsequenced races or indeterminate reads. Of these, the checker is the \nmost subtle, since the only way to intuitively understand it is to understand the model itself (which \nis what the tool is intended to aid with), and thus bugs are hard to catch. It also has to be adapted \noften as the model is developed. We therefore use Isabelle/HOL code generation [Haf09] to build the checker \ndirectly from our Isabelle/HOL axiomatisation, to keep the checker and our model in exact correspondence \nand reduce the possibility for error. The operational semantics Our overall semantics is strati.ed: the \nmemory model is expressed as a predicate on the actions and rela\u00adtions of a candidate execution. This \nmeans we need an operational semantics of an unusual form to generate all such candidates. In a setting \nwith a global SC memory, the values read by loads can be determined immediately, but here, for example \nfor a program with a single load, in principle we have to generate a large set of exe\u00adcutions, each with \na load event with one of the possible values. We make this executable by building a symbolic semantics \nin which the values in actions can be either concrete values or uni.cation vari\u00adables (shown as ?v). \nControl .ow can depend on the values read, so the semantics builds a set of these actions (and the associated \nrelations), together with constraints on the values, for each control\u00ad.ow path of the program. For each \npath, the associated constraint is solved at the end; those with unsatis.able constraints (indicating \nunreachable execution paths) are discarded. The tool is designed to support litmus test examples of the \nkind we have seen, not arbitrary C++ code. These do not usually involve many C++ features, and the constraints \nrequired are propositional formulae over equality and inequality constraints over symbolic and concrete \nvalues. It is not usually important in litmus tests to do more arithmetic reasoning; one could imagine \nusing an SMT solver if that were needed, but for the current constraint language, a standard union-.nd \nuni.er suf.ces. The input program is processed by the CIL parser [NMRW02], extended with support for \natomics. We use Graphviz [GN00] to generate output. We also allow the user to add explicit constraints \non the value read by a memory load in a C++ source program, to pick out candidate executions of interest; \nto selectively disable some of the checks of the model; and to de\u00adclutter the output by suppressing actions \nand edges. As an example, consider the .rst program we saw, in \u00a72.1. There are two possibilities: the \nreads of x either read the same value or different values, and hence the operational semantics gives \nthe two candidate executions and constraints below: c:Rna sb,dd Later, the memory model will rule out \nthe left execution, since there is no way to read anything but 2 at x. The semantics maintains an environment \nmapping identi.ers to locations. For loads, the relevant location is found in that, and a fresh variable \n?v is generated to represent the value read. Other constructs typically combine the actions of their \nsubterms and also build the relations (sequenced-before, data-dependency, etc.) of Xopsem as appropriate. \nFor example, for the if statement, the execution path splits and two execution candidates will be generated. \nThe one for the true branch has an additional constraint, that the value returned by the condition expression \nis true (in the C/C++ sense , i.e. different from 0), and the candidate for the false branch constrains \nthe value to be false. There are also additional sequenced-before and control-dependency edges from the \nactions in the condition expression to actions in the branch. Choosing instantiations of existential \nquanti.ers Given the Xopsem part of a .nite candidate execution, the Xwitness part is existentially quanti.ed \nover a .nite but potentially large set. In the worst case, with m reads and n writes, all sequentially \nconsis\u00adtent (atomic), to the same location, and with the same value, there (n+1) might be O(m\u00b7 m! \u00b7 (m \n+ n)!) possible choices of an rf, modi.cation-order and sc relation. In practice, though, litmus tests \nare much simpler: there are typically no more than 2 or 3 writes to any one location, so we avoid coding \nup a sophisticated memory\u00admodel-aware search procedure in favour of keeping this part of the code simple. \nFor the examples shown here, the tool has to check at most a few thousand alternatives, and takes less \nthan 0.2 sec\u00adonds. The most complex example we tested (IRIW with all SC) had 162,000 cases to try, and \nthe overall time taken was about 5 minutes. Checking code extracted from Isabelle We use Isabelle/HOL \ncode generation to produce a checker as an OCaml module, which can be linked in with the rest of the \nCPPSEM tool. Our model is stated in higher-order logic with sets and relations. Restricted to .nite sets, \nthe predicates and de.nitions are almost all directly ex\u00adecutable, within the domain of the code generation \ntool (which im\u00adplements .nite sets by OCaml lists). For a few cases (e.g impor\u00adtantly transitive closure), \nwe had to write a more ef.cient function and an Isabelle/HOL proof of equivalence. The overall checking \ntime per example is on the order of 10-3 seconds, for examples with around 10 actions. 6.1 Finite model \ngeneration with Nitpick/Kodkod Given the Xopsem part of a candidate execution, the space of pos\u00adsible \nXwitness parts which will lead to valid executions can be ex\u00adplored by tools for model generation. We \nreused the operational semantics above to produce a Xopsem from a program, and then posed problems to \nNitpick, a .nite model generator built into Is\u00adabelle [BN10]. Nitpick is a frontend to Kodkod, a model \ngenerator for .rst order logic extended with relations and transitive closure based on a state-of-the-art \nSAT solver. Nitpick translates higher\u00adorder logic formulae to .rst-order formulae within Kodkod syntax. \nFor small programs, Nitpick can easily .nd some consistent execu\u00adtion, or report that none such exists, \nin a few seconds. In particular, for the IRIW-SC example mentioned above, Nitpick takes 130 sec\u00adonds \nto report that no execution exists, while other examples take around 5 seconds. Of course, Nitpick can \nalso validate an execu\u00adtion X with both parts Xopsem and Xwitness concretely speci.ed, but this is signi.cantly \nslower than running the Isabelle-extracted validator. The bottleneck here is the translation process, \nwhich is quite involved.  7. Related work The starting points for this paper were the draft standard \nitself and the work of Boehm and Adve [BA08], who introduced the ratio\u00adnale for the C++0x overall design \nand gave a model for non-atomic, lock, and SC atomic operations, without going into low-level atom\u00adics \nor fences in any detail. It was expressed in informal mathemat\u00adics, an intermediate point between the \nprose of the standard and the mechanised de.nitions of our model. The most closely related other work \nis the extensive line of research on the Java Memory Model (JMM) [Pug00, MPA05, CKS07, SA08, TVD10]. \nJava im\u00adposes very different constraints to C++ as there it is essential to prohibit thin-air reads, \nto prevent forging of pointers and hence se\u00adcurity violations.  Turning to the sequential semantics \nof C++, Norrish has re\u00adcently produced an extensive HOL4 model [Nor08], and Za\u00adlewski [Zal08] formalised \nthe proposed extension of C++ concepts. There is also a body of research on tool support for memory models, \nnotably including (among others) the MEMSAT of Tor\u00adlak et al. [TVD10], which uses Kodkod for formalisations \nof the JMM, and NEMOSFINDER of Yang et al. [YGLS04], which is based on Prolog encodings of memory models \nand included an Ita\u00adnium speci.cation. Building on our previous experience with the MEMEVENTS tool for \nhardware (x86 and Power) memory mod\u00adels [SSZN+09, OSS09, SSO+10, AMSS10], we designed CPP-MEM to eliminate \nthe need for hand-coding of the tool to re.ect changes in the model, by automatically generating the \nchecker code from the Isabelle/HOL de.nition. We made it practically usable for exploring our non-idealised \n(and hence rather complex) C++0x model by a variety of user-interface features, letting us explore the \nexecutions of a program in various ways.  8. Conclusion We have put the semantics of C++ and C concurrency \non a mathe\u00admatically sound footing, following the current .nal committee draft standard as far as possible, \nexcept as we describe in \u00a74. This should support future improvements to the standard and the development \nof semantics, analysis, and reasoning tools for concurrent systems code. Having done so, the obvious \nquestion is the extent to which the formal model could be incorporated as a normative part of a fu\u00adture \nstandard. The memory model is subtle but it uses only simple mathematical machinery, of various binary \nrelations over a .xed set of concrete actions, that can be visualised graphically. There is a notational \nproblem: one would probably have to translate (au\u00adtomatically or by hand) the syntax of .rst-order logic \ninto natural language, to make it suf.ciently widely accessible. But given that, we suspect that the \nformal model would be clearer than the current standardsese for all purposes, not only for semantics \nand analysis. Acknowledgements This work would not have been possible without discussions with members \nof the C++ Concurrency sub\u00adcommittee and the cpp-threads mailing list, including Hans Boehm, Lawrence \nCrowl, Peter Dimov, Doug Lea, Nick Maclaren, Paul McKenney, Clark Nelson, and Anthony Williams. Jasmin \nBlanchette assisted us with the Nitpick tool. We acknowledge fund\u00ading from EPSRC grants EP/F036345, EP/H005633, \nEP/H027351, and EP/F067909.  References [AB10] S. V. Adve and H.-J. Boehm. Memory models: A case for \nrethinking parallel languages and hardware. C. ACM, 2010. [AMSS10] J. Alglave, L. Maranget, S. Sarkar, \nand P. Sewell. Fences in weak memory models. In Proc. CAV, 2010. [ARM08] ARM. ARM Architecture Reference \nManual (ARMv7-A and ARMv7-R edition). April 2008. [BA08] H.-J. Boehm and S.V. Adve. Foundations of the \nC++ concur\u00ad rency memory model. In Proc. PLDI, 2008. [Bec10] P. Becker, editor. Programming Languages \n C++. Final Committee Draft. 2010. ISO/IEC JTC1 SC22 WG21 N3092. [BN10] Jasmin Christian Blanchette and \nTobias Nipkow. Nitpick: A counterexample generator for higher-order logic based on a relational model \n.nder. In Proc. ITP, 2010. [BOS] www.cl.cam.ac.uk/users/pes20/cpp. [C1X] JTC1/SC22/WG14 C. http://www.open-std.org/ \njtc1/sc22/wg14/. [CKS07] P. Cenciarelli, A. Knapp, and E. Sibilio. The Java mem\u00adory model: Operationally, \ndenotationally, axiomatically. In Proc. ESOP, 2007. [GN00] E. R. Gansner and S. C. North. An open graph \nvisualization system and its applications to software engineering. Softw. Pract. Exper., 30(11):1203 \n1233, 2000. [Haf09] Florian Haftmann. Code Generation from Speci.cations in Higher-Order Logic. PhD thesis, \nTU M\u00a8 unchen, 2009. [HOL] The HOL 4 system. http://hol.sourceforge.net/. [Int02] Intel. A formal speci.cation \nof Intel Itanium processor fam\u00adily memory ordering. http://www.intel.com/design/ itanium/downloads/251429.htm, \nOctober 2002. [Isa] Isabelle 2009-2. http://isabelle.in.tum.de/. [Lam79] L. Lamport. How to make a multiprocessor \ncomputer that cor\u00adrectly executes multiprocess programs. IEEE Trans. Comput., C-28(9):690 691, 1979. \n[MPA05] J. Manson, W. Pugh, and S.V. Adve. The Java memory model. In Proc. POPL, 2005. [MS10] P. E. McKenney \nand R. Silvera. Example POWER implementation for C/C++ memory model. http: //www.rdrop.com/users/paulmck/scalability/ \npaper/N2745r.2010.02.19a.html, 2010. [MW] P. E. McKenney and J. Walpole. What is RCU, fundamen\u00adtally? \nLinux Weekly News, http://lwn.net/Articles/ 262464/. [NMRW02] George C. Necula, Scott McPeak, Shree Prakash \nRahul, and Westley Weimer. Cil: Intermediate language and tools for analysis and transformation of c \nprograms. In Proc. CC, 2002. [Nor08] M. Norrish. A formal semantics for C++. Technical report, NICTA, \n2008. [OSS09] S. Owens, S. Sarkar, and P. Sewell. A better x86 memory model: x86-TSO. In Proc. TPHOLs, \n2009. [Owe10] S. Owens. Reasoning about the implementation of concur\u00adrency abstractions on x86-TSO. In \nProc. ECOOP, 2010. [Pow09] Power ISA Version 2.06. IBM, 2009. [Pug00] W. Pugh. The Java memory model \nis fatally .awed. Concur\u00adrency -Practice and Experience, 12(6), 2000. [SA08] J. .c\u00b4ik and D. Aspinall. \nOn validity of program transforma\u00ad Sev.tions in the Java memory model. In ECOOP, 2008. [Spa] The SPARC \narchitecture manual, v. 9. http://dev elopers.sun.com/solaris/articles/sparcv9.pdf. [SSO+10] P. Sewell, \nS. Sarkar, S. Owens, F. Zappa Nardelli, and M. O. Myreen. x86-TSO: A rigorous and usable programmer s \nmodel for x86 multiprocessors. C. ACM, 53(7):89 97, 2010. [SSZN+09] S. Sarkar, P. Sewell, F. Zappa Nardelli, \nS. Owens, T. Ridge, T. Braibant, M. Myreen, and J. Alglave. The semantics of x86-CC multiprocessor machine \ncode. In Proc. POPL, 2009. [Ter08] A. Terekhov. Brief tentative example x86 imple\u00admentation for C/C++ \nmemory model. cpp-threads mailing list, http://www.decadent.org.uk/pipermail/ cpp-threads/2008-December/001933.html, \nDec. 2008. [TJ07] E. Torlak and D. Jackson. Kodkod: a relational model .nder. In Proc. TACAS, 2007. [TVD10] \nE. Torlak, M. Vaziri, and J. Dolby. MemSAT: checking ax\u00adiomatic speci.cations of memory models. In PLDI, \n2010. [YGLS04] Y. Yang, G. Gopalakrishnan, G. Lindstrom, and K. Slind. Nemos: A framework for axiomatic \nand executable speci.ca\u00adtions of memory consistency models. In IPDPS, 2004. [Zal08] M. Zalewski. Generic \nProgramming with Concepts.PhD thesis, Chalmers University, November 2008.  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>Shared-memory concurrency in C and C++ is pervasive in systems programming, but has long been poorly defined. This motivated an ongoing shared effort by the standards committees to specify concurrent behaviour in the next versions of both languages. They aim to provide strong guarantees for race-free programs, together with new (but subtle) relaxed-memory atomic primitives for high-performance concurrent code. However, the current draft standards, while the result of careful deliberation, are not yet clear and rigorous definitions, and harbour substantial problems in their details.</p> <p>In this paper we establish a mathematical (yet readable) semantics for C++ concurrency. We aim to capture the intent of the current (`Final Committee') Draft as closely as possible, but discuss changes that fix many of its problems. We prove that a proposed x86 implementation of the concurrency primitives is correct with respect to the x86-TSO model, and describe our Cppmem tool for exploring the semantics of examples, using code generated from our Isabelle/HOL definitions.</p> <p>Having already motivated changes to the draft standard, this work will aid discussion of any further changes, provide a correctness condition for compilers, and give a much-needed basis for analysis and verification of concurrent C and C++ programs.</p>", "authors": [{"name": "Mark Batty", "author_profile_id": "81479651209", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509557", "email_address": "Mark.Batty@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Scott Owens", "author_profile_id": "81337492133", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509558", "email_address": "Scott.Owens@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Susmit Sarkar", "author_profile_id": "81392603911", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509559", "email_address": "Susmit.Sarkar@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Peter Sewell", "author_profile_id": "81100511814", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509560", "email_address": "Peter.Sewell@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Tjark Weber", "author_profile_id": "81430630683", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509561", "email_address": "Tjark.Weber@cl.cam.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926394", "year": "2011", "article_id": "1926394", "conference": "POPL", "title": "Mathematizing C++ concurrency", "url": "http://dl.acm.org/citation.cfm?id=1926394"}