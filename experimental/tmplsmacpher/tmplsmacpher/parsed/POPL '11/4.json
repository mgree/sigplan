{"article_publication_date": "01-26-2011", "fulltext": "\n Relaxed-Memory Concurrency and Veri.ed Compilation Jaroslav .c\u00b4ik1 Viktor Vafeiadis1,2 Francesco Zappa \nNardelli3 Suresh Jagannathan4 Peter Sewell1 Sev. 1University of Cambridge 2MPI-SWS 3INRIA 4Purdue University \n(work done while on sabbatical at Cambridge) Dedicated to the memory of Robin Milner Abstract In this \npaper, we consider the semantic design and veri.ed compi\u00adlation of a C-like programming language for \nconcurrent shared\u00admemory computation above x86 multiprocessors. The design of such a language is made \nsurprisingly subtle by several factors: the relaxed-memory behaviour of the hardware, the effects of \ncom\u00adpiler optimisation on concurrent code, the need to support high\u00adperformance concurrent algorithms, \nand the desire for a reasonably simple programming model. In turn, this complexity makes veri.ed (or \nverifying) compilation both essential and challenging. We de.ne a concurrent relaxed-memory semantics \nfor ClightTSO, an extension of CompCert s Clight in which the pro\u00adcessor s memory model is exposed for \nhigh-performance code. We discuss a strategy for verifying compilation from ClightTSO to x86, which we \nvalidate with correctness proofs (building on CompCert) for the most interesting compiler phases. Categories \nand Subject Descriptors C.1.2 [Multiple Data Stream Architectures (Multiprocessors)]: Parallel processors; \nD.1.3 [Con\u00adcurrent Programming]: Parallel programming; F.3.1 [Specifying and Verifying and Reasoning \nabout Programs] General Terms Reliability, Theory, Veri.cation Keywords Relaxed Memory Models, Verifying \nCompilation, Se\u00admantics 1. Introduction Context Multiprocessors are now ubiquitous, with hardware support \nfor concurrent computation over shared-memory data structures. But building programming languages with \nwell-de.ned semantics to exploit them is challenging, for several inter-linked reasons. At the hardware \nlevel, most multiprocessor families (e.g., x86, Sparc, Power, Itanium, and ARM) provide only relaxed \nshared\u00admemory abstractions, substantially weaker than sequentially con\u00adsistent (SC) memory [Lam79]: some \nof the hardware optimisations they rely on, while unobservable to sequential code, can observably affect \nthe behaviour of concurrent programs. Moreover, while for some multiprocessors it has long been clear \nwhat the programmer can rely on, e.g. the Sparc Total Store Ordering (TSO) model [Spa], for others it \nhas been hard to interpret the vendor s informal-prose architecture speci.cations [SSZN+09]. For x86, \nwe recently pro\u00adposed x86-TSO [SSO+10, OSS09] as a rigorous and usable seman\u00adtics; we review this in \n\u00a72. Permission to make digital or hard copies of all or part of this work for personal or classroom use \nis granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation Compilers also rely on optimisations for performance, \nand again many common optimisations (e.g., common subexpression elimi\u00adnation, and so on) preserve the \nbehaviour of sequential code but can radically change the behaviour of concurrent programs. Hence, when \ndesigning a concurrent shared-memory program\u00adming language, where one must choose what memory semantics \nto provide, there is a dif.cult tension to resolve. A strong model (such as sequential consistency) will \nbe relatively easy for pro\u00adgrammers to understand but hard to implement ef.ciently, because compiler \noptimisations will not always be sound and because ex\u00adpensive processor-speci.c memory fences (or other \nsynchronisa\u00adtion instructions) will be needed to enforce ordering in the tar\u00adget hardware. Another alternative \nis to forbid programs contain\u00ading races and give SC semantics to the rest [AG96], relying on synchronisation \nfrom the implementations of lock and unlock. Pre\u00adcisely de.ning a non-SC programming language model is \na tech\u00adnical challenge in itself, as witnessed by the complexities in estab\u00adlishing a Java memory model \nthat admits all the intended optimi\u00adsations [Pug00, MPA05, CKS07, SA08, TVD10], and the ongoing work \non C++0x [BOS+11]. However, when it comes to concurrent systems code and con\u00adcurrent data structure libraries, \nfor example as used in an OS ker\u00adnel and in java.util.concurrent [Lea99], it seems that a weak model \nis essential. Compiler optimisations are not the main issue here: these low-level algorithms often have \nlittle scope for optimi\u00adsation, and their shared-memory accesses should be implemented exactly as expressed \nby the programmer. But for good performance it is essential that no unnecessary memory fences are introduced, \nand for understanding and reasoning about these subtle algorithms it is essential that the language has \na clear semantics. Moreover, such algorithms are intrinsically racy. Such code is a small fraction of \nthat in a large system, but may have a disproportionate effect on performance [Boe05]. This is illustrated \nby an improvement to a Linux spinlock, where a one-instruction change to a non-SC prim\u00aditive gave a 4% \nperformance gain [Lin99]. Recognising this, both Java and C++0x aim to provide a strong model for most \nprogram\u00adming but with low-level primitives for expert use. In the face of all this intertwined semantic \nsubtlety, of source language, target language, compilation between them, and the soundness of optimisations, \nit is essential to take a mathematically rigorous and principled approach to relaxed-memory concurrency: \nto give mechanised semantics for source and target languages and to consider veri.ed (or verifying) compilation \nbetween them. In the sequential setting, verifying compilation has recently been shown to be feasible \nby Leroy et al. s CompCert, a verifying compiler from a sequential C-like language, Clight, to PowerPC \nassembly language [Com09, Ler09a, Ler09b, BL09]. In this paper, we con\u00adsider verifying compilation in \nthe setting of concurrent programs with a realistic relaxed memory model. Contributions Our .rst contribution \nis the design and de.ni\u00ad on the .rst page. To copy otherwise, to republish, to post on servers or to \nredistribute tion of ClightTSO (\u00a73). ClightTSO is not intended to be a general\u00ad to lists, requires prior \nspeci.c permission and/or a fee. purpose programming language, but rather a language in which POPL 11, \nJanuary 26 28, 2011, Austin, Texas, USA. concurrent algorithms can be expressed precisely, and, more \nimpor\u00ad c Copyright &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00  tantly, as a test case for \nreasoning about relaxed-memory computa\u00adtion. It essentially exposes the x86 or Sparc hardware load and \nstore operations (and synchronisation primitives) to the programmer, so ClightTSO loads and stores inherit \nthe hardware relaxed-memory TSO behaviour, but can be implemented without memory fences or atomic instructions. \n(As we discuss in \u00a76, in a full language one would expect to augment these with thread-local accesses \nthat the compiler is permitted to optimise away, for high-performance se\u00adquential code, but that is not \nour focus here.) The semantic design of ClightTSO turns out to involve a surprisingly delicate interplay \nbetween the relaxed memory model, the behaviour of block alloca\u00adtion and free, and the behaviour of pointer \nequality. Our second contribution is one of semantic engineering (\u00a74). Relaxed memory models are complex \nin themselves, and a veri\u00adfying compiler such as CompCert is complex even in the sequen\u00adtial case; to \nmake verifying compilation for a concurrent relaxed\u00admemory language feasible we have to pay great attention \nto struc\u00adturing the semantics of the source and target languages, and the compiler and any correctness \nproof, to separate concerns and re\u00aduse as much as possible. We factor out the TSO memory from each language \nand build small-step labellised semantics, allowing most of the proof to be done by threadwise simulation \narguments. A key question for each compiler phase is the extent to which it changes the memory accesses \nof the program. For most of our phases (8 of 15) the memory accesses of source and target are in exact \n1:1 cor\u00adrespondence. Moreover, for four phases the memory accesses are identical except that some values \nthat are unde.ned in the source take particular values in the target; and one phase (register allo\u00adcation) \nhas no effect on memory accesses except that it removes memory loads to dead variables. For all these, \nthe correctness of the phase is unrelated to the TSO nature of our memory. That leaves two phases that \nchange memory accesses substantially, and whose proofs must really involve the whole system, of all threads \nand the TSO memory. Thirdly, we present evidence that our approach is effective (\u00a75). We have implemented \na compiler from ClightTSO to x86 multipro\u00adcessors, taking CompCert as a starting point, and have proved \ncor\u00adrectness (in Coq [Coq]) for key phases thereof. In addition, we have successfully run the compiler \non a number of sequential and con\u00adcurrent benchmarks, including an implementation of a non-trivial lock-free \nalgorithm by Fraser [Fra03]. Finally, we re.ect on the formalisation process and on the tools we used \n(\u00a76), discuss related work, and conclude. The proof effort for each compiler phase was broadly commensurate \nwith its conceptual dif.culty: some have es\u00adsentially no effect on memory behaviour, and needed only \ndays of work; a few were much more substantial, really changing the in\u00adtensional behaviour of the source \nand with proofs that involve the TSO semantics in essential ways.  Figure 1. x86-TSO block diagram \n 2. Background: x86-TSO We begin by recalling the relaxed-memory behaviour of our tar\u00adget language, x86 \nmultiprocessor assembly programs, as captured by our x86-TSO model [SSO+10, OSS09]. The classic example \nshowing non-SC behaviour in a TSO model is the store buffer (SB) assembly language program below: given \ntwo distinct memory lo\u00adcations x and y (initially holding 0), if two hardware threads (or processors) \nrespectively write 1 to x and y and then read from y and x (into register EAX on thread 0 and EBX on \nthread 1), it is possible for both to read 0 in the same execution. It is easy to check that this result \ncannot arise from any SC interleaving of the reads and writes of the two threads, but it is observable \non modern Intel or AMD x86 multiprocessors. SB Thread 0 Thread 1 MOV [x].1 MOV EAX.[y] MOV [y].1 MOV \nEBX.[x] Allowed Final State: Thread 0:EAX=0 . Thread 1:EBX=0 Microarchitecturally, one can view this \nbehaviour as a visible con\u00adsequence of store buffering: each hardware thread effectively has a FIFO buffer \nof pending memory writes (avoiding the need to block while a write completes), so the reads from y and \nx can occur before the writes have propagated from the buffers to main memory. In addition, it is important \nto note that many x86 instructions involve multiple memory accesses, e.g. an increment INC [x].By default, \nthese are not guaranteed atomic (so two parallel increments of an initially 0 location might result in \nit holding 1), but there are LOCK d variants of them: LOCK INC [x] atomically performs a read, a write \nof the incremented value, and a .ush of the local write buffer. Compare-and-swap instructions (CMPXCHG) \nare atomic in the same way, and memory fences (MFENCE) simply .ush the local write buffer. The x86-TSO \nmodel makes this behaviour precise in two equiv\u00adalent ways: an abstract machine with an operational semantics, \nillustrated in Fig. 1, and an axiomatisation of legal executions, in the style of [Spa92, App. K] (the \nmodel covers the normal case of aligned accesses to write-back cacheable memory; it does not cover other \nmemory types, self-modifying code, and so on). For the relationship between the model and the vendor \ndocu\u00admentation (and with empirical testing) we refer to our previous work [SSO+10, OSS09, SSZN+09]. \n 3. ClightTSO ClightTSO is a C-like language: imperative, with pointers and pointer arithmetic, and with \nstorage that is dynamically allocated and freed, but not subject to garbage collection (GC)1. We choose \nthis level of abstraction for several reasons. First, it is what is typically used for concurrent systems \nprogramming, for example in an OS kernel (where garbage collection may be infeasible), and many concurrent \nalgorithms are expressed in C-like pseudocode. should be straightforward.  type, ty ::= void | int (intsize,signedness) \n| float (.oatsize) | pointer (ty) | array (ty,len) | function (ty * ,ty) | struct (id,f) | union (id,f) \n| comp pointer(id) | (ty) .eldlist,f ::= nil | (id,ty)::f unary operation, op1 ::= ! | ~ | \u00adbinary operation, \nop2 ::= + | -| * | / | % | &#38; | | | ^ | << | >> | == | != | < | > | <= | >= expr, e ::= aty expr descr, \na ::= n | f | id | *e | &#38;e | op1 e | e1 op2 e2 | (ty)e | e1?e2:e3 | e1&#38;&#38;e2 | e1||e2 | sizeof \n(ty) | e.id opt lhs ::= | (id:ty)= atomic statement, as ::= CAS | ATOMIC INC | MFENCE statement, s ::= \nskip | e1=e2 | opt lhs e'(e * ) | s1;s2 | if (e1) then s1 else s2 | while (e)do s | do s while (e) | \nfor (s1;e2;s3)s | break | continue | return opt e | switch (e)ls | l:s | goto l | thread create(e1,e2) \n| opt lhs as(e * ) labeled statements, ls ::= default :s | case n:s;ls fndefn internal ::= ty id(arglist){varlist \ns} program ::= dcls fndefns main =id Figure 2. ClightTSO abstract syntax (excerpts) some atomic read-modify-write \nprimitives that are directly imple\u00admentable by x86 LOCK d instructions. An excerpt of the abstract syntax \nis given in Fig. 2, where one can see that programs consist of a list of global variable declarations, \na list of function declarations, and the name of a main function. Function bodies are taken from a fairly \nrich language of statements and expressions. Semantically, though, the addition of relaxed-memory concur\u00adrency \nhas profound consequences: TSO Most obviously, the ClightTSO load and store operations must have TSO \nsemantics to make them directly implementable above x86, so we cannot model memory as (say) a function \nfrom locations to values. Instead, we use a derivative of the TSO ma\u00adchine in Fig. 1 (the abstract machine \nstyle is more intuitive and technically more convenient here than the axiomatic model). Pointer equality \nC implementations are typically not memory\u00adsafe: one can use pointer arithmetic to corrupt arbitary state \n(in\u00adcluding that introduced by compilation). But in order to specify an implementable language, C standards \nrule out many programs from consideration, giving them unde.ned behaviour. For example, the draft C1X \nstandard states If an object is referred to outside of its lifetime, the behavior is unde.ned. The value \nof a pointer becomes indeterminate when the object it points to reaches the end of its lifetime [C1X, \n6.2.4p2]. In Clight the memory state records what is allocated, with equality testing of pointers giving \nthe unde.ned value (Vundef) if they do not refer to currently allocated blocks. However, in a relaxed-memory \nsetting any appeal to global time should be treated with great caution, and the concept of currently \nallocated is no longer simple: different threads might have differ\u00adent views not only of the values in \nmemory but also of what is allo\u00adcated. For example, in x86-TSO one thread might free, re-allocate and \nuse some memory while another thread compares against a pointer to it, with the writes of the .rst thread \nremaining within its buffer until after the comparison. One could make pointer com\u00adparison effectful, \nquerying the x86-TSO abstract machine to see whether a pointer is valid w.r.t. a particular thread whenever \nit is used, but this would lead to a complex and unwieldy semantics. Moreover, comparing potentially \ndangling pointers for equality is useful in practice, e.g. in algorithms to free cyclic data structures. \nAccordingly, for ClightTSO we take pointer comparison to always be de.ned. Block reuse In turn, this \nmeans that the ClightTSO semantics must permit re-use of pointers (again contrasting with Clight, in \nwhich allocations are always fresh), otherwise it would not be sound w.r.t. the behaviour of reasonable \nimplementations. For ex\u00adample, in the program below h must be allowed to return 0 or 1,as an implementation \nmight or might not reuse the stack frame of f for g. int* f() { int a; return &#38;a; } int* g() { int \na; return &#38;a; } int h() { return (f() == g()); } Memory errors and buffering of allocations and frees \nA read or write of a pointer that is dangling w.r.t. that thread must still be a semantic error, so that \na correct compiler is not obliged to preserve the behaviour of such programs. Now, implementations of \nmem\u00adory allocation and free do not necessarily involve a memory fence or other buffer .ush: at the assembly \nlanguage level, stack allo\u00adcation and free are simply register operations, while heap malloc and free \nmight often be w.r.t. some thread-local storage. To test whether pointers are valid, therefore, we treat \nallocations and frees analogously to writes, adding them to the buffers of the TSO ma\u00adchine. This is \na convenient common abstraction of stack and heap allocation (for the former, it essentially models the \nstack pointer). An allocation must immediately return a block address to the calling thread, but they \nshould not clash when they are unbuffered (when they hit the main memory of the TSO machine), so they \nmust return blocks that are fresh taking into account pending allocations and frees from all threads. \nIt is technically convenient if frees and writes also fail immediately, when they are added to the TSO \nma\u00adchine buffer, so we also take all possible sequences of the pending allocations and frees into account \nwhen enqueuing them. Otherwise one would have latent failures, e.g. if two threads free a block and those \nfrees are both held in buffers. Finite memory A .nal novelty of ClightTSO, not directly re\u00adlated to concurrency, \nis that we support .nite memory, in which allocation can fail and in which pointer values in the running \nmachine-code implementation can be numerically equal to their values in the semantics. The latter is \nconvenient for our correctness proofs, simplifying the simulations. It also means that pointer arith\u00admetic \nworks properly (mod 232) and may be helpful in the future for a semantic understanding of out-of-memory \nerrors. The mem\u00adory usage of a compiled program and its source may be radically different, as the compiler \nmay be able to promote local variables to registers but will need extra storage for stack frames and \ntem\u00adporaries. But (analogous to verifying rather than veri.ed compila\u00adtion), it would be reasonably straightforward \nto make the compiler emit and check, for each function, bounds on those. One could then reason about \nreal space usage in terms of a source semantics anno\u00adtated with these bounds. Small-step semantics ClightTSO \nis a concurrent language, in which execution of an expression or a statement may involve mul\u00adtiple memory \nreads and hence multiple potential interaction points with other threads. We therefore need a small-step \noperational se\u00admantics for both expressions and statements. Conceptually this is routine, but it requires \nsigni.cant re-engineering (described in \u00a75.1) of de.nitions and proofs w.r.t. CompCert, where Clight \nhad a big\u00adstep semantics for expressions.  We use a frame-stack style, with thread states that can be \nan executing expression paired with an expression-holed continuation or an executing statement paired \nwith a statement-holed continua\u00adtion: expr cont,.e ::= [opt ] \u00b7 .e | [ t =e2] \u00b7 .s | [v t = ] \u00b7 .s | \n... 1 stmt cont,.s ::= stop | [ ; s2] \u00b7 .s | ... state ::= e \u00b7 .e |. | s \u00b7 .s |. | ... Here . is a thread-local \nenvironment mapping identi.ers to their lo\u00adcations in allocated blocks. The semantics is also parameterised \nby an unchanging global environment of global variables and func\u00adtions, and additional machinery is needed \nto deal with l-values, loops, and function calls, which we return to in \u00a75.1. We also .x a left-to-right \nevaluation order. Examples We give a .avour of the language with some very small examples of ClightTSO \nsource programs. SB The x86 visible-store-buffer behaviour can now be seen at the ClightTSO level, e.g. \nif the following threads are created in parallel then both could print 0 in the same execution. int x=0; \nint y=0; void *thread0(void *tid) void *thread1(void *tid) { x=1; { y=1; printf(\"T0: %d\\n\", y); printf(\"T1: \n%d\\n\", x); return(0); } return(0); } Spinlock using CAS More usefully, an ef.cient spinlock can be implemented \ndirectly in ClightTSO using CAS. Any integer variable can be used to represent the state of the spinlock, \nwith lock and unlock as follows: void lock(int *mutex) void unlock(int *mutex) { while (CAS(mutex, 0, \n1)) { *mutex = 0; } while (*mutex) ; } The generated assembler mimics the optimised implementa\u00adtion \nof Linux spinlocks mentioned in Section 1: as shown by Owens [Owe10], the memory update performed by \nunlock does not need to be synchronising on x86-TSO. A publication idiom The memory model supports the \ncommon publication idiom below: double channel; int flag = 0; // sender // receiver channel = 5.2; while \n(flag == 0); flag = 1; printf (\"%f\\n\", channel); Since the store buffers are FIFO, when the receiver \nthread sees the update to flag, the contents of the channel variable must have been propagated into main \nmemory, and as such must be visible to all other threads (that do not themselves have a pending write \nto channel). For contrast, in C++0x [Bec10, BOS+11] (which also targets non-TSO machines), flag must \nbe accessed with sequen\u00adtially consistent atomics, implemented with costly x86 LOCK d in\u00adstructions or \nfences, or with release/acquire atomics, implemented with normal stores and loads but with a much more \ninvolved se\u00admantics.  4. Verifying Compiler Strategy Having discussed our x86 target language in \u00a72, \nand the design and rationale of our ClightTSO source language in \u00a73, we now consider the semantics and \nproof structure required to make a verifying compiler for a concurrent relaxed-memory language feasible. \nCorrectness statement The .rst question is the form of the cor\u00adrectness theorems that we would like the \ncompiler to generate. We con.ne our attention to the behaviour of whole programs, leaving a compositional \nunderstanding of compiler correctness for relaxed\u00admemory concurrency (e.g. as in the work of Benton and \nHur for sequential programs [BH09]) as a problem for future work. We take the observable behaviour of \nboth ClightTSO and x86-TSO programs to be labelled transition systems (LTS) with visible ac\u00adtions for \ncall and return of external functions (e.g. OS I/O primi\u00adtives), program exit, semantic failure, and \nan out-of-memory error, together with internal t actions: event, ev ::=call id vs | return typ v | exit \nn | fail | oom | t We split external I/O into call and return transitions so that blocking OS calls can \nbe correctly modelled. Now, how should the source and target LTS be related? As usual for implementations \nof concurrent languages, we cannot ex\u00adpect them to be (in some sense) equivalent, as the implementa\u00adtion \nmay resolve some of the source-language nondeterminism (c.f. [Sew97]). For example, in our implementation, \nstack frames will be deterministically stack-allocated and the pointers in the block-reuse example above \nwill always be equal. Hence, the most we should expect is that if the compiled program has some ob\u00adservable \nbehaviour then that behaviour is admitted by the source semantics some kind of backward simulation2 \nresult. This must be re.ned further: compiled behaviour that arises from an erroneous source program \nneed not be admitted in the source semantics (e.g. if a program mutates a return address on its stack, \nor tries to apply a non-function). We have to distinguish between such semantic errors (modelled with \nfail) and out-of\u00admemory allocation errors (modelled by oom) so that we can cor\u00adrectly blame the source \nprogram in the former case. Moreover, the compiled program should only diverge, indicated by an in.\u00adnite \ntrace of t labels, if the source program can. We express all this with the following notion of backward \nsimulation between a source LTS S and a compiled target LTS T . DEFINITION 1. A family of relations Ri \n: States(S) \u00d7 States(T ), indexed by elements i of a well-founded order >,isa measured backward simulation \nif, whenever sRi t and t -ev. t ' for ev = oom, then either t* fail 1. .s ' .s -. s ' --. (s can reach \na semantic error), or t* ev ' ''' 2. .s ,j.s -. -. s . sRj t (s can do a matching step), or 3. .j. ev \n= t . i>j . sRj t ' (t stuttered, with a decreasing measure).  Given a measured backward simulation \nrelating S and T , one can easily see that if S has no semantic failures then any (.nite or in.nite) \ncompleted trace of T , that does not include an out-of\u00admemory error, is a trace of S. The CompCert 1.5 \nproof strategy ClightTSO is an extension of sequential Clight, and its compiler has to deal with everything \nthat a Clight compiler does, except for any optimisations that be\u00adcome unsound in the concurrent setting. \nWe therefore arrange our semantic de.nitions and proof structure to re-use as much as pos\u00adsible of the \nCompCert development for sequential Clight, isolating the parts where relaxed-memory concurrency plays \na key role. CompCert 1.5 is around 55K lines of Coq subdivided into 13 compiler phases, each of which \nbuilds a semantic preservation proof between semantically de.ned intermediate languages. The 2 Terminology: \nin CompCert forward and backward refer to the direc\u00adtion of the simulation with respect to the compiler \nphases, not to the di\u00adrection of transitions. Thinking of compilation as forwards , a forward simulation \nmeans that source behaviours can be matched by the target.  overall strategy is to build some kind of \nforward simulation for each phase; these can be composed together and combined with determinacy for the \ntarget language (PowerPC or ARM assembly) to give a backward simulation for a complete compilation. Forward \nsimulations are generally easier to establish than backward simula\u00adtions because compiler phases tend \nto introduce intermediate states; a forward simulation proof does not have to characterise and relate \nthese. As we shall see, this strategy cannot be used directly for compi\u00adlation of concurrent ClightTSO \nto x86, but much can be adapted. Decomposing the proof by compiler phases Ourcompileris divided into \nsimilar (but not identical) phases to CompCert. The above notion of backward simulation also serves as \nthe correctness criterion for each of our phases: THEOREM 1. The composition of two measured backward \nsimula\u00adtions is a measured backward simulation. [Coq proof] Labellisation and threadwise proof In our \nconcurrent setting the languages are not deterministic, so the CompCert approach to building backward \nsimulations is not applicable. However, for most of the phases we can re-use the CompCert proof, more-or\u00adless \nadapted, to give forward simulation results for the behaviour of a single thread in isolation and we \ncan make our semantics deterministic for such. We therefore labellise the semantics for each level (source, \ntarget, and each intermediate language). Instead of de.ning transitions (s, mSC) -. (s ' ,mSC' ) over \ncon.gurations that combine a single-threaded program state s andanSCmemory mSC (as most sequential language \nsemantics, including CompCert, do), we de.ne the semantics of a single thread (split apart from the memory) \nas a transition system: s -te. s ' (together with extra structure for thread creation) where a thread \nevent te is either an external event, as above, an interaction with memory me,aninternal t action, or \nthe start or exit of the thread: thread event, te ::= ext ev | mem me | t | start opt tidpvs | exit The \nwhole-system semantics of each level is a parallel compo\u00adsition roughly of the form s1 | ... | sn | mTSO \nof the thread states si and a TSO machine mTSO. The threads in\u00adteract with the TSO machine by synchronising \non various events: reads or writes of a pointer p with a value v of a speci.ed memory chunk size, allocations \nand frees of a memory block at a pointer p, various error cases, and thread creation. These transitions \nare in the style of the early transition system for value-passing CCS [Mil89]: a thread doing a memory \nread will have a transition for each possible value of the right type. For example, here is the ClightTSO \nrule for dereferencing a pointer: access mode ty ' =By value c typ = type of chunk c Val.has type vtyp \nLOADBYVALUE mem (read pcv) ty' |. |. p \u00b7 [* ] \u00b7 .e ---------. v \u00b7 .e External events of the threads (and \nof the TSO machine) are ex\u00adposed directly as the whole-system behaviour. This conceptually simple change \nseparates concerns: compiler phases that do not substantially affect the memory accesses of the program \ncan be proved correct per-thread, as described in \u00a75.4 (and those results lifted to the whole system \nby a general result below), leaving only the two remaining phases that require proofs that really involve \nthe TSO machine. The TSO machine Our TSO machine is based on the x86-TSO abstract machine, with a main \nmemory and per-thread buffers, but with several differences. The TSO machine must handle memory allocations \nand frees (which are buffered), and various memory errors; the main memory records allocation as in CompCert. \nWe use the TSO semantics for software threads, not hardware threads, which is sound provided that the \nscheduler .ushes the buffer during task switching. We use the same TSO machine for all the intermedi\u00adate \nlanguages, and we uniformly lift threadwise LTSs to the parallel composition with the TSO machine. Lifting \nthreadwise forward simulations to whole-system back\u00adward simulations We convert forward threadwise simulations \nto whole-system backward simulations in two steps. First, we observe that a forward simulation from a \nreceptive language to a determi\u00adnate language implies the existence of backward simulation. We say that \ntwo labels are of the same kind, written te ; te ' if they only differ in input values. In our case, \nte ; te ' if (i) te and te ' are reads from the same memory location (but not necessarily with the same \nvalue), or (ii) te and te ' are external returns, or (iii) te = te ' . ' DEFINITION 2. AthreadLTS is \nreceptive if s -te. t and te ; te ' implies .t ' .s te- . t ' . ' ' DEFINITION 3. AthreadLTSis determinate \nif s -te. t and s te- . t implies te ; te ' and, moreover, if te = te ' ,then t = t ' . DEFINITION 4. \nArelation R between the states of two thread LTSs S and T is a threadwise forward simulation if there \nis a well\u00adfounded order < on the states of S such that if given any s, s ' . S, t . T and label te, whenever \ns -te. s ' and sRt, then either t* tet ''' ' te = fail,or .t.t -. -.-. * t . s Rt ' ,or te = t . s Rt \n. s ' <s. DEFINITION 5. A relation R is a threadwise backward simulation if there is a well-founded order \n< on T such that whenever t -te. t ' t* tefail ' ''' and sRt, then either .s.s -. -. s . s Rt ' ,or .s.s \n--. s ' ,or te = t . sRt '. t ' <t. Moreover, if t - . (t is stuck) and sRt,then s -' .s fail' . . or \n.s --. s Note the subtle asymmetry in handling errors: if a source state does an error or gets stuck, \nboth the backward simulation and forward simulation hold. In contrast, the target states errors must \nbe re.ected in the source to make the backward simulation hold. This is necessary to allow compilers \nto eliminate errors, but not to introduce them. THEOREM 2. If R is a threadwise forward simulation from \nS to T , S is receptive, and T is determinate, then there is a threadwise backward simulation that contains \nR. [Coq proof] Eliding details of initialisation and assumptions on global envi\u00adronments, we have: THEOREM \n3. A threadwise backward simulation can be lifted to a whole-system measured backward simulation, for \nthe composition of the threads with the TSO machine. [Coq proof] To establish correctness of compiler \nphases that remove dead vari\u00adable loads and concretise unde.ned values, we have also proved variants \nof Theorems 2 and 3 for suitably modi.ed De.nitions 4 and 5.  The two non-threadwise proofs In ClightTSO \n(as in Clight) lo\u00adcal variables are all in allocated blocks, but an early phase of the compiler identi.es \nthe variables whose addresses are not taken (by any use of the &#38; operator) and keeps them in thread-local \nenvi\u00adronments, changing loads and stores into (t-action) environment accesses; moreover, individual stack \nallocations on function entry are merged into one large allocation of the entire stack frame. Con\u00adversely, \na later phase does activation record layout, and thread-local state manipulation (t actions) is compiled \ninto memory accesses to the thread-local part of activation records. In both cases, the thread has different \nviews of memory in source and target, and these views involve the TSO-machine buffering of loads, stores, \nallocations and frees. We return to this, which is the heart of our proof, in \u00a75.2 and \u00a75.3. Finite memory \nrevisited To be faithful to a real machine seman\u00adtics, our x86 semantics uses .nite memory and performs \nmemory allocations only when threads are initialized (the stack of the thread is allocated). In Clight, \nhowever, small memory allocations happen whenever a variable is declared; as a result, the memory should \nbe unbounded because the compiler can promote local variables to registers and thus a Clight program \ncan have a footprint that would not .t in the x86 memory. In our intermediate languages, we switch from \nin.nite to .nite memory in the Csharpminor to Cstacked phase (\u00a75.2), where we move local variables whose \nad\u00address is not taken to local environments, and perform one allo\u00adcation (for the remaining local variables) \nper function call. Since our pointer type needs to accommodate both the .nite and in.\u00adnite nature of \naddresses, our pointers are composed of two parts: an unbounded block identi.er and machine integer offset \nwithin the block. The lower-level language semantics uses only the .\u00adnite memory in block 0 the memory \nrefuses to allocate any other block. The higher level languages can allocate in any block. Note that \none memory block can contain more than one memory ob\u00adject. A later phase (MachAbs to MachConc phase, \n\u00a75.3) compiles away the allocations per function call pre-allocating a thread s stack when it is created. \nThe .nal phase: targetting x86 We target x86 because x86-TSO gives us a relatively simple and well-understood \nrelaxed mem\u00adory model for a common multiprocessor. CompCert 1.5 targets se\u00adquential PowerPC and ARM assembly \nlanguage, but these have much more intricate concurrent behaviour which is still not fully understood \n(though c.f. [AMSS10]). We therefore need an x86 backend, described in \u00a75.5, adopting parts of the new \nx86 backend of CompCert 1.8.  5. CompCertTSO Following the strategy above, we have built a working compiler \nfrom ClightTSO to x86 assembly language with x86-TSO seman\u00adtics, and have proved correctness of the most \ninteresting phases. This shows (a) how we can reason about concurrent TSO be\u00adhaviour, in the phases where \nthat plays a key role, and (b) how our overall strategy enables relatively straightforward adaptation \nof the existing sequential proof, in the phases where concurrent memory accesses do not have a big impact. \nOur development, all mecha\u00adnised in Coq, is available online3. The structure of our compiler, and of \nits proof, is shown in Fig. 3. The subdivision into phases between intermediate languages follows CompCert \n1.5 as far as possible, with our major changes being: The source and target languages are ClightTSO and \nconcurrent x86 assembly, not Clight and PowerPC or ARM assembly. 3 www.cl.cam.ac.uk/users/pes20/CompCertTSO \n ClightTSO source Parsing, type-checking, simpli.cation (CIL) ClightTSO Control-structure simpli.cation; \n\u00a75.1 type-based overloading resolution Csharpminor \u00a75.2 Stack allocation of address-taken locals Cstacked \nCompilation of switch statements (unde.ned values can become de.ned) Cminor  Instruction selection CminorSel \nConstruction of the CFG; 3-address code generation  RTL Recognition of tail calls (unde.ned values can \nbecome de.ned) RTL Constant propagation  RTL CSE (for arithmetic expressions only) RTL  Register allocation \n(unnecessary loads removed) \u00a75.4 LTL  Branch tunnelling LTL Linearisation of the CFG LTLin Spilling, \nreloading, calling conventions (unde.ned values can become de.ned) Linear Laying out the activation records \n(Part I)  MachAbs \u00a75.3 Laying out the activation records (Part II) MachConc Emission of x86 assembly \ncode \u00a75.5 (unde.ned values can become de.ned) Asm (x86) Printing of x86 AST, assembly and linking Machine \ncode (x86) Our proof structure is indicated by single arrows for threadwise forward simulations; and \nstraight double arrows for direct proofs of whole-system backward simulations. Arrows are solid if the \nproof is completed and dotted otherwise. The completed composite whole-system backward simulations (lifted \nwith Theorems 2 and 3, and composed with Theorem 1) are shown with curved double arrows. ClightTSO and \nCsharpminor perform a stack allocation for each individ\u00adual variable in the program and assume an in.nite \nmemory, whereas the languages below have only .nite memory. From Cstacked to MachAbs a stack allocation \noccurs for each non-empty stack frame (that is, almost ev\u00adery function call), whereas in MachConc and \nAsm only when a thread is created. FiniteIn.nite Stack allocationsStack allocations memory memory at \nthread creation at calls Figure 3. CompCertTSO phases  The semantics is expressed with a TSO machine, \nwhich is common to all phases.  We need a stack of memory-model-aware abstractions for the intermediate \nlanguages. While named after those of CompCert, their semantics are all adapted to labellised TSO semantics. \n The simulation from ClightTSO to the .rst intermediate lan\u00adguage, Csharpminor, is a new proof above \nour small-step se\u00admantics.  The CompCert phase that does stack allocation of some local variables (those \nwhose address is taken by &#38;), from Csharpmi\u00adnor to Cminor, is divided into two via a new intermediate \nlan\u00adguage Cstacked. Cstacked has the same syntax as Csharpminor (and compilation to it is the identity \non terms) but a memory semantics more like Cminor. The proof of the Csharpminor-to-Cstacked phase is \na new direct whole-system backward simula\u00adtion argument, dealing with the very different patterns of \nmem\u00adory accesses in the two languages and how they interact with the TSO machine.  The proofs of the \nmiddle phases of the compiler, from RTL to MachAbs with various optimisations, are relatively straightfor\u00adward \nadaptations of the CompCert proofs to our per-thread la\u00adbellised semantics and then lifted by the general \nresults of the previous section.  Our Mach-to-Asm phase generates x86 rather than PowerPC or ARM assembly. \n The rest of this section discusses these in more detail. Our main results are as follows. THEOREM 4. \nGiven a ClightTSO program, p, and its compilation to a Cminor program, p ' , there is a measured backward \nsimulation between the LTSes of p and p ' . [Coq proof] THEOREM 5. If an RTL program, p, has been successfully \ncom\u00adpiled to a Machabs program, p ' , by the following phases: tail call recognition, constant propagation, \nrestricted CSE, register allo\u00adcation, branch tunnelling, linearisation, reloading and activation record \nlayout, then there is a measured backward simulation be\u00adtween the LTSes of p and p ' . [Coq proof] Proof \noutline: First, we construct threadwise forward simulations from ClightTSO to Csharpminor, from Cstacked \nto Cminor, and between each of the eight phases from RTL to MachAbs. (More precisely, for the tail call \nrecognition and reloading phases we es\u00adtablish a threadwise forward simulation with undefs, and for the \nregister allocation phase a lock-step threadwise forward simulation with unnecessary load removal.) Then, \nwe turn these threadwise forward simulations to threadwise backward simulations by Theo\u00adrem 2 (and by \nthe analogous theorems for the threadwise forward simulation with undefs and for the lock-step threadwise \nforward simulation with unnecessary load removal). Then, by Theorem 3, we turn the threadwise backward \nsimulations into whole-system measured backward simulations. In \u00a75.2, we also establish a mea\u00adsured backward \nsimulation from Cstacked to Csharpminor. Finally, by composing these measured backward simulations according \nto Theorem 1, we get the overall measured backward simulations. At the time of writing, the remaining \nproofs required for a complete verifying compiler include our MachAbs-to-MachConc phase, which involves \nmemory manipulations very similar to those of Csharpminor-to-Cstacked, and the forward simulations for \ncom\u00adpilation from Cminor to RTL, which should be relatively straight\u00adforward adaptations from CompCert. \nThese have been sketched out in detail (in Coq), and we believe that the main intellectual chal\u00adlenges \nhave all been addressed, though of course one can never be certain until the proof is complete. ClightTSO \nCsharpminor ptr*int.ptr v2 \u00b7 [n * ] \u00b7 [v1 +ptr*int.ptr ] \u00b7 . e |. v2 \u00b7 [v1 + ] \u00b7 .e |. t t (BINOP) (BINOP) \nptr*int.ptr v \u00b7 .e |. v 2 \u00b7 [v1 + ] \u00b7 . e |. t (BINOP) v \u00b7 . e |. Here int = int (I32,Signed) and ptr \n= pointer (int). The type annotation in the multiplication (*) context is omitted. Figure 4. Part of \nthe simulation relating ClightTSO and Csharp\u00adminor evaluation for addition of an int and a pointer. ClightTSO \nCsharpminor *((&#38;(idty1 )ty 2 ))ty 3 \u00b7 .e |. t (DEREF) ty3 ] \u00b7 .e |. Somep ty3 ] \u00b7 .e |.  id \u00b7 . \ne |. (&#38;(idty1 )ty2 ) \u00b7 [* t (ADDR) lval (idty1 ) \u00b7 [* t eval var ref . id p c (VARLOCAL) mem (read \npcv) has type v ty 3 ] \u00b7 .e |. (VAR) (type of chunk c) p \u00b7 [* mem (read pcv) ... (LOADBYVALUE) v \u00b7 . \ne |. v \u00b7 .e |. Figure 5. ClightTSO compilation can sometimes eliminate source-level transitions. 5.1 \nSmall-stepping (ClightTSO to Csharpminor) ClightTSO is compiled into Csharpminor, a high-level intermedi\u00adate \nrepresentation that has a simpler form of expressions and state\u00adments. Most notably, the translation \nuni.es various looping con\u00adstructs found in the source, compiles away casts, translates union and structs \ninto primitive indexed memory accesses, and makes variable l-value and r-value distinctions explicit. \nHigh-level type information found in ClightTSO is compiled to a lower-level byte\u00adaware memory representation. \nAccounting for these differences in the simulation is complicated by the relatively large size of the \ntwo languages: ClightTSO s de.nition has 90 rules, while Csharpminor has 56. Because expression evaluation \nis de.ned by a small-step seman\u00adtics, adapting the forward simulation proofs directly from Com\u00adpCert \n(which uses a big-step expression evaluation semantics) was not feasible, and much of the proof, along \nwith the simulation change, had to be written from scratch as a result. Since the two lan\u00adguages are \nrelatively close, however, the revised simulation could sometimes simply map ClightTSO transitions directly \nto the corre\u00adsponding Csharpminor ones; evaluation of constants, unary opera\u00adtions, and certain components \nof function call and return are such examples.  However, as we mentioned earlier, compilation often \nresults in a ClightTSO term becoming translated to a sequence of lower-level simpler Csharpminor terms. \nTo illustrate, the diagram shown in Fig. 4 shows the evaluation of a binary addition of an integer and \na pointer. For ClightTSO, the multiplication of the integer operand by the representation size of the \npointer type is performed implicitly, subsumed within the intrinsic de.nition of addition. In Csharpmi\u00adnor, \nan explicit binary multiplication operation is introduced. No\u00adtice that the continuations in the subsequent \nmatching states are structurally quite different from each other as a result; the simula\u00adtion relation \nmust explicitly account for these differences. Perhaps a more surprising consequence of using a small-step \nse\u00admantics is that the simulation relation may sometimes be required to match multiple ClightTSO transitions \nto a single Csharpminor one. For example, compilation from ClightTSO to Csharpminor eliminates various \nstates de.ned in ClightTSO to deal with ad\u00addressing and dereferencing. Consider the evaluation of an \nidenti\u00ad.er that appears in an r-value context. In ClightTSO, the identi.er is .rst translated into a \npointer, and a separate step returns either the contents of the pointer (in case it references a scalar \ntype) or the pointer itself (in case of e.g., arrays or structs). Compilation to Csharpminor removes \nthis intermediate step, generating the appro\u00adpriate access instruction directly, since the pointer type \nis statically known. This simpli.cation generalizes to sequences of address\u00adof and dereferencing operations. \nWe depict the sequence of steps necessary to compute a variable s address, and then dereference it (if \nit is a scalar) in Fig. 5. The relation eval var ref states that variable id, in the context of local \nenvironment ., evaluates to pointer p that references an object with memory representation c. The value \nv read must have a type consistent with c as de.ned by relation has type. Notice that ClightTSO requires \nfour steps to perform this operation while compilation to Csharpminor requires only one. To account for \nsuch differences, the simulation relation forces Csharpminor transitions to stutter, incorporating a \nmeasure on ClightTSO expressions and continuations that allows matching of several intermediate ClightTSO \nstates to a single Csharpminor one. Indeed, such a measure, suitably adapted, must be de.ned for most \nother compiler phases. Besides memory read and write operations, the ClightTSO se\u00admantics also generates \nevents for function argument and local vari\u00adable allocation as part of the function calling sequence. \nThe small\u00adstep semantics requires these operations be performed in stages. After all argument expressions \nand the function pointer have been evaluated, memory is allocated for each formal parameter, as well \nall local variables, in turn. Each distinct allocation is represented as a separate labelled transition. \nAfter allocation, the values of the ac\u00adtuals are written to the formals. On function exit, allocated \nstorage is freed individually. The corresponding Csharpminor transitions are similar, albeit with a change \nin the underlying type representa\u00adtion used to guide memory allocation and writes.  5.2 Changing memory \naccesses (1) (Csharpminor to Cstacked) Languages and Compilation The Csharpminor to Cstacked phase bridges \nthe semantic gap to the next intermediate language, Cminor, by introducing a new semantics of the Csharpminor \nsyn\u00adtax. That is, the program transformation from Csharpminor to Cstacked is an identity function. However, \nthe Cstacked memory semantics closely follows that of Cminor, which differs radically from Csharpminor. \nTo understand the motivation for introducing Cstacked, we summarise the main features of the following \ncompilation phase (Cstacked to Cminor): 1. Local variable reads and writes are turned into explicit memory \naccesses or local state reads and updates. Note that in Csharp\u00adminor, as in C, it is legal to take the \naddress of a local vari\u00adable and even to pass it to another thread, so long as it is not accessed outside \nits lifetime. Variables whose address is never taken, however, are guaranteed to be thread-local, and \nthe com\u00adpiler lifts such variables from memory to local state. The re\u00admaining variables are kept in memory. \n 2. Individual local variable allocations are replaced with single stack-frame allocation. 3. Switch-case \nstatements are compiled to switch-table state\u00adments.  Without the intermediate Cstacked phase, the .rst \ntwo steps change memory semantics: step 1 replaces memory accesses to local variables with local state \nmanipulation that does not touch memory, and step 2 replaces the individual variable (de)allocations \nwith a single stack-frame (de)allocation in Cminor. To separate concerns, the Cstacked semantics only \ncaptures the memory effects of the transformation, i.e., its transitions simulate the compilation steps \n1 and 2. Cstacked and Csharpminor only differ in handling local variables. The change is most evident \nin the types of local environments, which are part of the local state of threads. In Csharpminor, a local \nenvironment is a map from names to pointers and type information that essentially describes the size \nof a local variable in memory: var kind, vk ::= scalar memory chunk | array size cshm env, cshe ::= nil \n| ( id :( p , vk))::cshe In Cstacked, a local environment consists of a stack frame pointer and a map \nthat assigns to each name a value or an offset within the stack-frame: st kind, sk ::= local v | stack \nscalar memory chunk ofs | stack array size ofs cst items, csti ::= nil | ( id : sk)::csti cst env, cste \n::= ( p , csti) Note that Cstacked can keep values of local variables in the local environment (when \nthe corresponding st kind is local). This contrasts with Csharpminor, which stores the values of all \nlocal variables in memory. The difference in the environment drives all the other changes from Csharpminor \nto Cstacked: we adjust the rules for assignment, the write of a function s return value, local variable \nreads, function entry, and function exit to handle local in-state variables and on\u00adstack variables separately. \nThe most signi.cant change is in func\u00adtion entry, where we scan the function body for the &#38; operator \nand compute the size of its stack frame together with offsets for on\u00adstack local variables. We illustrate \nthe radical difference between the memory seman\u00adtics of Csharpminor and Cstacked on the environment construction \nand parameter binding in function entry. Consider the following function: int f(int i) {int j, k; g(i, \n&#38;j, &#38;k); return j+k;} Fig. 6 shows the environment construction and argument binding transitions \nfollowing an invocation of f with parameter 1.The states have the following meaning: the state Call lf \nfollows the evaluation of actual parameters l in the invocation of f; Alloc lve is an intermediate state \nfor allocation of local variables v,where e is an accumulator for the environment and l is the list of \nvalues to be bound to the function s formal parameters; Bind lpe is a state for binding parameter names \np to values l in environment e.The Alloc to Bind transition retrieves the parameter names from the state \ns continuation, which we omit in this example for brevity. Note that  Csharpminor Cstacked Call [1] \nf Call [1] f t 23 i : I Alloc [1] j : I [] 45 k : I alloc ai 4 Stack \u00bb j : I Alloc [1] i :(ai, I) \nk : I alloc aj 4 Stack alloc as 8 Stack \u00bb j :(aj , I) Alloc [1] k : I i :(ai, I) alloc ak 4 Stack \n23 k :(ak, I) Alloc [1] [] j :(aj , I) 5 4 i :(ai, I) t  2 3 0231 k :(ak, I) k : SI 4 Bind [1] [i] \nj :(aj , I) 45 4 5A Bind [1] [i] @as, j : SI 0 i :(ai, I) i : LUnd write ai int32 1 t 2 3 0231 k :(ak, \nI) k : SI 4 Bind [] [] j :(aj, I) 45 4 5A Bind [] [] @as, j : SI 0 i :(ai, I) i : L 1 where I stands \nfor scalar int32, LUnd for local Vundef, SI ofs for stack scalar int32 ofs,and L 1 for local (Vint 1). \nFigure 6. Function entry transitions in Csharpminor and Cstacked. the states do not refer to memory directly. \nInstead, the transitions expose the memory interaction in the labels. In Csharpminor, the semantics of \nfunction entry allocates three different 4-byte blocks, one for parameter i, and two for variables j \nand k. In Cstacked (and in all languages between Cminor and MachAbstract), the function entry semantics \nallocates a single 8-byte stack frame for variables j and k. No memory is reserved for variable i because \ni s value is kept in the thread-local local environment. The binding transitions are also different: \nCsharpminor writes the value 1 of parameter i to memory, but Cstacked simply stores the value in the \nenvironment. Indeed, note the difference in the environment entry for i in the last Bind states at the \nbottom of the .gure: the Csharpminor entry only contains a pointer to memory, whereas the Cstacked entry \ncontains the value of the variable. Simulating Cstacked in Csharpminor Remember that the Csharpminor-Cstacked \nphase switches from in.nite memory to .\u00adnite memory. This is necessary to be able to simulate the creation \nof the Cstacked local environments by fresh memory allocation in Csharpminor so that the memory cannot \nbe allocated even by future Cstacked allocations. We call the .nite space used by Cstacked the machine \nspace. The remaining (in.nite) part of the Csharpminor memory space in other blocks is called scratch \nspace. Our rep\u00adresentation of pointers is of the form (b, ofs) where b is an inte\u00adger block identi.er \nand ofs .{0,..., 232 - 1} is an offset. In our semantics, the machine space pointers have block b =0,the \npointers with non-zero b are scratch space pointers. We simulate Cstacked transitions so that we preserve \nequality of pointer values in the states and the values in the (machine) memory: We simulate Cstacked \nstack frame allocation by allocations of individual variables at the same (machine) memory location as \nthey have in Cstacked. Moreover, we allocate space for Cstacked local environments in globally fresh \nblocks in the scratch memory.  Cstacked memory reads/writes are simulated by the same reads/writes in \nCsharpminor.  Cstacked local environment accesses (which are t events in Cstacked) are simulated by \nmemory accesses to the correspond\u00ading Csharpminor scratch memory.  We simulate Cstacked stack frame \ndeallocation by freeing the individual variables, including the ones in non-machine mem\u00adory, in Csharpminor. \n The simulation relation on the states of the parallel composition of threads and the TSO machine consists \nof three main compo\u00adnents: a thread state relation, a TSO buffer relation and a memory relation. Relating \nthread states The main source of dif.culty is relat\u00ading the local environments of Cstacked and Csharpminor \nbecause the values of the local environments in Cstacked correspond to the memory contents of Csharpminor. \nTherefore, the thread state sim\u00adulation must relate Cstacked thread state with Csharpminor thread state \nand memory. In our TSO semantics, a thread s view of memory may differ from the real contents of the \nmemory and from other threads views of memory because of possibly pending writes, allocations and frees \nin store buffers of this and other threads. We consider local environments related for thread t if the \nvalues in the local environ\u00adments in the Cstacked state are the same as the ones in the memory of Csharpminor \ns TSO machine with t s buffer applied. Moreover, we consider stack environments related if for each Cstacked \nenvi\u00adronment item of the stack kind with offset ofs, the corresponding Csharpminor item s pointer equals \nthe sum of Cstacked stack frame pointer and ofs. Since Cstacked and Csharpminor only differ in their \nenvironments, the thread state simulation relation is a natural lifting of the environment relation. \nAll thread transitions preserve such a relation because they can only affect the thread s buffer. However, \nthe simulation of applying other threads buffers to the main memory (unbuffering) requires a stronger \nrelation. In particular, the state relation does not prevent unbuffering in one thread from interfering \nwith another thread s state relation. To get non-interference for unbuffering, we keep track of memory \npartitioning among threads (this is also necessary to make sure that threads do not free each others \nstack frames) by augmenting the state relation with the partitions they own in memory. Relating buffers \nThe buffer relation requires that a Cstacked (stack-frame) allocation corresponds to individual disjoint \nCsharp\u00adminor allocations (of individual variables) that must be in the stack\u00adframe; Cstacked writes correspond \nto the same writes in Csharp\u00adminor buffer; frees in Cstacked buffer correspond to frees of sub\u00adranges \nin Csharpminor. To relate frees, we must know the sizes of objects in memory because a free label does \nnot contain a size; hence, we parametrise the buffer relation by the thread s partition. It is worth \nnoting that the Csharpminor buffer may contain extra memory labels for the local environment manipulation, \nwhich are t labels in Cstacked and thus do not appear in the Cstacked buffer. We only require the operations \nin the labels to be valid in the thread s partition.  Csharpminor Cstacked write (0, 8) int32 3  write \n(0, 8) int32 3 ... ... alloc (0, 12) 8 Stack  Figure 7. Buffer relation. Fig. 7 illustrates the buffer \nrelation. Assuming that the TSO machine inserts labels to the top of the buffer and applies the labels \nto memory from the bottom, the buffer contents might be generated by the function f from the beginning \nof this section, where the allocations correspond to the transitions from Fig. 6, the dotted part of \nthe buffer is generated by the function g, the frees correspond to local variable deallocations at function \nexit, and the write label is issued by writing the return value to the caller s stack frame. The grey \nlabels are the memory manipulation removed by the compiler, or, more precisely, they are the labels introduced \nby the backward simulation (note that they act on scratch memory). In the simulation proof, the buffer \nrelation says how to simulate Cstacked buffer application in Csharpminor while preserving the simulation \nrelation. For example, if we are to simulate Cstacked buffer application of the alloc label, we apply \nthe three corre\u00adsponding allocations followed by the write from the Csharpminor buffer. Relating TSO \nstates The whole-system simulation relation states that there are Cstacked and Csharpminor partitionings, \ni.e., maps from thread ids to partitions such that The Csharpminor (resp. Cstacked) partitioning corresponds \nto the ranges allocated in the Csharpminor (resp. Cstacked) TSO machine s memory. Moreover, the partitionings \nmust be pair\u00adwise disjoint and for each thread, the Csharpminor machine partitions must contain sub-ranges \nof Cstacked partitions. This is necessary to guarantee that any Cstacked allocation can be successfully \nsimulated in Csharpminor4.  The values in the machine memory are the same in Cstacked and in Csharpminor. \nWe need this property to establish that reads of the same address give the same value in Cstacked and \nin Csharpminor.  Each thread s Cstacked and Csharpminor buffers are related.  For each thread t, the \nstates of t in Csharpminor and Cstacked are related in the partitions and memory updated by t s buffers. \n The relation also imposes several consistency invariants: to guar\u00adantee that Cstacked writes do not \noverwrite Csharpminor scratch memory, we require scratch pointers only appear as pointers in Csharpminor \nenvironments. With these ingredients, the relation on the TSO states is a whole-system backward simulation \nrelation. 4 A simulation of successful allocation is an interesting (and lengthy) ex\u00adercise because one \nmust show that in Csharpminor, no possible partial ap\u00adplication of other threads buffers con.icts with \nthe simulated allocations. The partial buffer applications create states that do not directly correspond \nto any Cstacked state (e.g., partially allocated environments), forcing us to invent a new simulation \nrelation for this purpose.  5.3 Changing memory accesses (2) (MachAbs to MachConc) In many respects, \nthe simulation from MachAbs to MachConc is similar to the Csharpminor-Cstacked simulation. MachAbs and \nMachConc are again two different semantics for the same pro\u00adgrams. In MachAbs, the thread-local state \nconsists of the current func\u00adtion being executed, the program counter, the stack pointer, the register \n.le, the current stack frame, and a sequence of the stack frames for the function s callers. Instructions \nthat manipulate lo\u00adcal stack variables (getstack, setstack, getparam) perform a t-step, which accesses \nonly the thread-local stack frames. In con\u00adtrast, MachConc allocates the stack frames in (global) memory; \nso the three aforementioned instructions generate read or write events for communicating with the TSO \nmachine. The proof is by whole-system measured backward simulation, which keeps track of which regions \nof MachConc s memory are local for a given thread (corresponding to the thread-local parts of the stack \nframes) and which regions correspond to the possibly shared parts of each thread s stack frames. For \nthe thread-local parts, MachConc s memory is related to the corresponding thread s frames only after \nthe thread s buffered updates have been applied, whereas for the shared parts, MachConc s memory is immediately \nrelated to MachAbs s memory (i.e., before any buffers have been applied). In addition, the MachConc and \nthe MachAbs buffers for each thread are related in an element-wise manner if we ignore the thread-local \nwrites from the MachConc buffers (as they do not correspond to any memory writes in MachAbs). Of course, \ndeciding whether a buffered write is thread-local depends on its position inside the buffer, since preceding \nbuffered allocations and frees can affect whether an address is local or shared. The full simulation \nrelation also relates the states of each thread in the two semantics and contains several administrative \nproperties, such as that the various thread-local and shared stack allocation ranges are pairwise disjoint, \nand that stack frames are aligned to 16 byte boundaries. A distinguishing aspect of this simulation is \nthat we compile away stack-allocations and frees. In MachAbs, each non-empty stack frame is allocated \nwith a fresh address at function entry, and deallocated at function return. Concretely, however, no mem\u00adory \nallocation takes place; the stack pointer is simply incremented or decremented accordingly. Therefore, \nin MachConc, each thread is allocated a stack when created, and the stack pointer is simply decremented \nat function entry and incremented at function return (x86 stacks grow downwards). If decrementing the \nstack pointer exceeds the allocated stack range, the semantics raises an Out of Memory error. In concrete \nx86 executions, this would correspond to a segmentation fault due to stack over.ow. Compiling away stack-allocations \nand frees makes the simulation relation slightly more intricate as the relations between buffers and \nbetween memo\u00adries over the appropriate ranges are of equality on values; the Mach-Abs values are less \nde.ned than the corresponding MachConc ones. This is because a newly allocated stack frame in MachAbs \nwill ini\u00adtially contain Vundef everywhere, whereas in MachConc the cor\u00adresponding block, after decrementing \nthe stack pointer, will contain whatever values happened to be there.  5.4 The easy phases, including \noptimisations We have enabled all the CompCert 1.5 optimisations that are sound under the TSO semantics. \nThese are: constant propagation &#38; partial evaluation, a restricted version of CSE (common subexpression \nelimination) that eliminates only common arithmetic expressions, but does not eliminate common memory \nloads, redundant load removal (as part of register allocation), branch tunneling, and tail call optimisation. \nThe only CompCert 1.5 optimisation we do not perform is CSE for memory reads, because this is unsound \nunder the TSO memory model as demonstrated by the following example (adapted from [Pug00]):  int x; \nvoidf (int*p){int a= x, b= *p, c= x; x=1; x=0; printf(\"%d%d%d\", a, b, c);} f(&#38;x); CSE would replace \nthe assignment c=x with c=a, allowing the second thread to print 010, a behaviour that is not allowed \nby the TSO semantics. Labellising CompCert s de.nitions of RTL, LTL, LTLin, Lin\u00adear, MachAbs, and MachConc \nand establishing that they are de\u00adterminate and receptive (so that they can be composed with the TSO \nmachine) was straightforward because the CompCert 1.5 def\u00adinitions of these languages were already fully \nsmall-step. Porting CompCert s forward simulation proofs to threadwise forward sim\u00adulation proofs and \nlifting them to measured whole-system back\u00adward simulations using Theorems 2 and 3 was equally straightfor\u00adward. \n(In the early days of the project, porting one phase took ap\u00adproximately two days, but by the end 3 hours \nwere suf.cient to port constant propagation and lift it to a measured whole-system backward simulation.) \nElimination of redundant loads required a small adaptation of the forward-to-backward simulation infrastruc\u00adture. \nMoreover, the tail call optimisation and the spilling/reloading phases may change some of the unde.ned \nvalues in the source se\u00admantics to particular values in the target semantics requiring us to prove another \nslightly more general version of Theorems 2 and 3.  5.5 The x86 backend We adapted the x86 backend from \nCompCert 1.8 (CompCert 1.5 supported PowerPC and ARM only), with several notable differ\u00adences in the \nsemantics and proofs. Our x86 semantics is based on a well-tested HOL4 formalisation of part of the x86 \ninstruction set [SSZN+09, Section 3]. The structure of our instruction AST is closer to that of general \nx86 instructions, with their various com\u00adbinations of immediate, register and addressing-mode arguments, \nthan that of CompCert 1.8, which is a .atter AST supporting just the combinations used by the compiler. \nIt does entail some addi\u00adtional complexity in the proof, however. We replaced individual stackframe allocations \nwith one-off stack space allocation at the start of the thread and direct stack pointer arithmetic. We \ndetect stack over.ow by checking that the stack pointer register stays inside the thread s stack space. \nIf not, the semantics issues an explicit oom event. Using the more realistic single stack space gives \nus the added bene.t of direct access to function arguments and the return address. This contrasts with \nCompCert that accesses arguments through an indirect link to parent stackframe and models the re\u00adturn \naddress with a virtual return-address register (similarly to Pow-erPC s real link register). The direct \naccess to arguments buys us a slight performance advantage over CompCert, while the direct re\u00adturn address \naccess enables a more honest modelling of x86. Several parts of the x86 semantics are less realistic \nthan we would wish. The most notable abstraction in the semantics is mod\u00adelling register and memory contents \nby the high-level value datatype (as in CompCert), which is a discriminated union of point\u00aders, integers, \n.oats and unde.ned value, instead of the more appro\u00adpriate bit-vector representation. 5.6 Running CompCertTSO \nDespite not making any attempt at optimising the generated code results on simple sequential and concurrent \nbenchmarks (mostly drawn from [Com09]) show that our generated code runs at about 75% of the performance \nof gcc -O1. As a more representative example, we have also successfully compiled Fraser s lock-free skiplist \nalgorithm [Fra03]; we are roughly 69% of the perfor\u00admance of gcc -O1 on this benchmark. Porting required \nonly three changes, all to in-line assembly macros, two of which were replac\u00ading macros for CAS and MFENCE \nby the ClightTSO constructs.  6. Discussion We re.ect brie.y on the impact of the tool chain and proof \nstyle that we employed to ease development of our compiler. The main tool was Coq. Here we found the \nproof style advo\u00adcated by SSREFLECT [GM07] to be helpful in ensuring proof ro\u00adbustness, but to retain \nbackward compatibility with CompCert, we employed it selectively. Occasionally, we used specialised tactics \nto automate some of the more tedious proofs, such as the threadwise determinacy and receptiveness of \nall the languages. To give the reader a .avour for the effort involved in the de\u00advelopment, we list the \nnumber of lines of proof and speci.cations (de.nitions and statements of lemmas) for some of the important \n(and fully proven) phases of our compiler. Phases Specs Proofs TSO machine &#38; memory 2079 2746 Simulations \n(\u00a74) 1075 1810 ClightTSO de.nition 2010 186 ClightTSO-Csharpminor (\u00a75.1) 1452 2379 Csharpminor-Cstacked \n(\u00a75.2) 3481 8208 RTL-Linear (\u00a75.4) 7141 5098 2594 2803 MachConc-Asm (\u00a75.5) Of those the RTL-Linear phases \nare adaptations of existing code (7 phases in total), as is the compiler part of MachConc-Asm; the rest \nis largely new. For comparison, CompCert 1.5 has roughly 31K lines of speci.cations and 23K lines of \nproofs for all the phases. The project has taken approximately 36 man-months. The semantics of ClightTSO \nis given as an inductively de.ned relation, as usual and following Clight. To make it easier to check \nthe integrity of the de.nition, we also implemented a functional characterisation of the threadwise single-step \ntransition relation and proved that the two de.nitions are equivalent. By extracting the functional version \ninto an OCaml program serving as an interpreter, we were able to test the semantics on sample ClightTSO \nprograms. This revealed a number of subtle errors in our original de.nitions. It would also be worth \ntesting our x86 semantics against processor behaviour, as we did for a HOL4 x86 semantics in previous \nwork with Myreen [SSZN+09]. A mechanised theorem is only useful if its statement can be un\u00adderstood, \nand for CompCertTSO the overall correctness theorem involves the ClightTSO and x86 semantics. We de.ned \nClightTSO using Ott [SZNO+10], a tool that generates Coq and LATEXdef\u00adinitions from a single source; \nit also helped in enforcing naming conventions. The ClightTSO grammar and semantic rules, and the terms \nin examples are all parsed and automatically typeset.  7. Related Work Research on veri.ed compilation \nof sequential languages has a long history. Notable recent work includes CompCert, which we have already \ndiscussed in detail; Chlipala s compiler from a small im\u00adpure functional language to an idealised assembly \nlanguage, fo\u00adcussing on Coq proof automation [Chl10]; Myreen s JIT compiler from a bytecode to x86 [Myr10]; \nand Benton and Hur s compila\u00adtion [BH09] from a simply typed functional language to a low-level SECD \nmachine. This last differs from most other work in giving a compositional understanding of compiler correctness \nrather than just a relationship between the whole-program behaviours of source and target.  Veri.ed \ncompilation of concurrent languages has received much less attention. Perhaps the most notable example \nis the work of Lochbihler [Loc10] extending Jinja (a compiler from sequential Java to JVM, veri.ed in \nIsabelle/HOL) to concurrency. As here, shifting to a small-step semantics required non-trivial proof \neffort, but the Jinja memory accesses in source and target are very closely related, so issues of relaxed-memory \nbehaviour, memory layout, .nite memory, and so on seem to have played no role. To the best of our knowledge, \nthere is no prior work addressing veri.ed compilation for a relaxed-memory concurrent language. An alternative \napproach to extending CompCert with concur\u00adrency has been suggested by Hobor et al. [HAZN08]. They de\u00ad.ne \na concurrent version of Cminor equipped with a concurrent separation logic. The idea is to do verifying \ncompilation for pro\u00adgrams that have been proved correct in such a logic, and their ora\u00adcle semantics \nfor concurrent Cminor (factored rather differently to ours) is intended to make that possible without \nextensive refactor\u00ading of the CompCert proofs. That is in some sense complementary to our work: we focus \non intrinsically racy concurrent algorithms, whereas programs proved correct in that logic are known \nto be race free (as most application code is expected to be). However, we con\u00adjecture that an oracle \nsemantics could be de.ned directly above the labellised semantics that we use. ClightTSO is not intended \nas a proposal for a complete lan\u00adguage: its load and store operations are loosely analogous to the C++0x \natomics [Bec10, BOS+11] and Java volatiles [MPA05], and it has no distinguished class of memory operations \nwhich are supposed to be thread-local (and hence which a compiler is li\u00adcenced to optimise between synchronisation \npoints). It is closer to the pseudocode or C-with-macros that is commonly used for con\u00adcurrent shared-memory \nalgorithms, and the ClightTSO operations can be implemented ef.ciently, with simple x86 loads and stores. \nVolatiles and C++0x SC atomics need heavier implementations, though C++0x also has cheaper low-level \natomics with weaker se\u00admantics that are cheaper to implement. Java and C++0x also have more complex semantics, \nalbeit not speci.c to TSO processors (es\u00adsentially x86 and Sparc).  8. Conclusion The shift to commodity \nmulticore processors has recently made relaxed-memory concurrent computation pervasive, but semantics \nand veri.cation in this setting is a long-standing problem. As Lam\u00adport wrote in 1979 [Lam79]: For some \napplications, achieving sequential consistency may not be worth the price of slowing down the processors. \nIn this case, one must be aware that conventional methods for designing multiprocess algo\u00adrithms cannot \nbe relied upon to produce correctly executing programs. Protocols for synchronizing the processors must \nbe designed at the lowest level of the machine instruction code, and verifying their cor\u00adrectness becomes \na monumental task. This paper is a step towards putting them on a rigorous foundation, both for programming \nand veri.cation. Acknowledgements We thank Xavier Leroy for enlightening discussions and for making CompCert \navailable. We acknowledge funding from EPSRC grants EP/F036345 and EP/H005633 and ANR grant ANR-06-SETI-010-02. \n References [AG96] S. V. Adve and K. Gharachorloo. Shared memory consistency models: A tutorial. IEEE \nComputer, 29(12):66 76, 1996. [AMSS10] J. Alglave, L. Maranget, S. Sarkar, and P. Sewell. Fences in weak \nmemory models. In Proc. CAV, 2010. [Bec10] P. Becker, editor. Programming Languages C++. Final Committee \nDraft. 2010. ISO/IEC JTC1 SC22 WG21 N3092. [BH09] N. Benton and C.K Hur. Biorthogonality, step-indexing \nand compiler correctness. In Proc. ICFP, 2009. [BL09] Sandrine Blazy and Xavier Leroy. Mechanized semantics \nfor the Clight subset of the C language. Journal of Automated Reasoning, 43(3):263 288, 2009. [Boe05] \nH.-J. Boehm. Threads cannot be implemented as a library. In Proc. PLDI, pages 261 268, 2005. [BOS+11] \nM. Batty, S. Owens, S. Sarkar, P. Sewell, and T. Weber. Math\u00adematizing C++ concurrency. In Proc. POPL, \n2011. [C1X] Programming languages C (committee draft, WG14 N1494, ISO/IEC 9899:201x). http://www.open-std.org/jtc1/ \nsc22/wg14/www/docs/PostColorado.htm. [Chl10] A. Chlipala. A veri.ed compiler for an impure functional \nlanguage. In Proc. POPL, 2010. [CKS07] P. Cenciarelli, A. Knapp, and E. Sibilio. The Java mem\u00adory model: \nOperationally, denotationally, axiomatically. In Proc. ESOP, 2007. [Com09] The Compcert veri.ed compiler, \nv. 1.5. http://compcert. inria.fr/release/compcert-1.5.tgz, August 2009. [Coq] The Coq proof assistant. \nhttp://coq.inria.fr/. [Fra03] Keir Fraser. Practical Lock Freedom. PhD thesis, 2003. Also available as \nTech. Report UCAM-CL-TR-639. [GM07] G. Gonthier and A. Mahboubi. A small scale re.ection exten\u00adsion for \nthe coq system. Technical report, 2007. [HAZN08] A. Hobor, A. W. Appel, and F. Zappa Nardelli. Oracle \nseman\u00adtics for concurrent separation logic. In Proc. ESOP, 2008. [Lam79] L. Lamport. How to make a multiprocessor \ncomputer that cor\u00adrectly executes multiprocess programs. IEEE Trans. Comput., C-28(9):690 691, 1979. \n[Lea99] D. Lea. Concurrent Programming in Java. Second Edition: Design Principles and Patterns. 1999. \n[Ler09a] Xavier Leroy. Formal veri.cation of a realistic compiler. Communications of the ACM, 52(7):107 \n115, 2009. [Ler09b] Xavier Leroy. A formally veri.ed compiler back-end. Journal of Automated Reasoning, \n43(4):363 446, 2009. [Lin99] 1999. Linux Kernel mailing list, thread spin unlock optimization(i386) , \n119 messages, Nov. 20 Dec. 7th, http://www.gossamer-threads.com/lists/engine? post=105365;list=linux. \nAccessed 2009/11/18. [Loc10] A. Lochbihler. Verifying a compiler for Java threads. In Proc. ESOP 10, \n2010. [Mil89] R. Milner. Communication and Concurrency. Prentice Hall International, 1989. [MPA05] J. \nManson, W. Pugh, and S.V. Adve. The Java memory model. In Proc. POPL, 2005. [Myr10] M. O. Myreen. Veri.ed \njust-in-time compiler on x86. In Proc. POPL, 2010. [OSS09] S. Owens, S. Sarkar, and P. Sewell. A better \nx86 memory model: x86-TSO. In Proc. TPHOLs, 2009. [Owe10] S. Owens. Reasoning about the implementation \nof concur\u00adrency abstractions on x86-TSO. In Proc. ECOOP, 2010. [Pug00] W. Pugh. The Java memory model \nis fatally .awed. Concur\u00adrency -Practice and Experience, 12(6), 2000. [SA08] J. .c\u00b4ik and D. Aspinall. \nOn validity of program transfor\u00ad Sev.mations in the Java memory model. In ECOOP, 2008. [Sew97] P. Sewell. \nOn implementations and semantics of a concurrent programming language. In Proc. CONCUR, July 1997. [Spa] \nThe SPARC architecture manual, v. 9. http://dev elopers.sun.com/solaris/articles/sparcv9.pdf. [Spa92] \nThe SPARC Architecture Manual, V. 8. SPARC International, Inc., 1992. Revision SAV080SI9308. http://www.sparc. \norg/standards/V8.pdf. [SSO+10] P. Sewell, S. Sarkar, S. Owens, F. Zappa Nardelli, and M. O. Myreen. x86-TSO: \nA rigorous and usable programmer s model for x86 multiprocessors. C. ACM, 53(7):89 97, 2010. [SSZN+09] \nS. Sarkar, P. Sewell, F. Zappa Nardelli, S. Owens, T. Ridge, T. Braibant, M. Myreen, and J. Alglave. \nThe semantics of x86-CC multiprocessor machine code. In Proc. POPL, 2009. [SZNO+10] P. Sewell, F. Zappa \nNardelli, S. Owens, G. Peskine, T. Ridge, S. Sarkar, and R. Strni.Ott: Effective tool support for the \nsa. working semanticist. J. Funct. Program., 20(1):71 122, 2010. [TVD10] E. Torlak, M. Vaziri, and J. \nDolby. MemSAT: checking axiomatic speci.cations of memory models. In PLDI, 2010.  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>In this paper, we consider the semantic design and verified compilation of a C-like programming language for concurrent shared-memory computation above x86 multiprocessors. The design of such a language is made surprisingly subtle by several factors: the relaxed-memory behaviour of the hardware, the effects of compiler optimisation on concurrent code, the need to support high-performance concurrent algorithms, and the desire for a reasonably simple programming model. In turn, this complexity makes verified (or verifying) compilation both essential and challenging.</p> <p>We define a concurrent relaxed-memory semantics for <i>ClightTSO</i>, an extension of CompCert's Clight in which the processor's memory model is exposed for high-performance code. We discuss a strategy for verifying compilation from ClightTSO to x86, which we validate with correctness proofs (building on CompCert) for the most interesting compiler phases.</p>", "authors": [{"name": "Jaroslav &#348;ev&#269;ik", "author_profile_id": "81384598170", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509552", "email_address": "jaroslav.sevcik@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Viktor Vafeiadis", "author_profile_id": "81100493655", "affiliation": "MPI-SWS, Saarbruecken , Germany", "person_id": "P2509553", "email_address": "viktor@mpi-sws.org", "orcid_id": ""}, {"name": "Francesco Zappa Nardelli", "author_profile_id": "81453660213", "affiliation": "INRIA, Rocquencourt, France", "person_id": "P2509554", "email_address": "Francesco.Zappa_Nardelli@inria.fr", "orcid_id": ""}, {"name": "Suresh Jagannathan", "author_profile_id": "81100208907", "affiliation": "Purdue University, West Lafayette, USA", "person_id": "P2509555", "email_address": "suresh@cs.purdue.edu", "orcid_id": ""}, {"name": "Peter Sewell", "author_profile_id": "81100511814", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509556", "email_address": "Peter.Sewell@cl.cam.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926393", "year": "2011", "article_id": "1926393", "conference": "POPL", "title": "Relaxed-memory concurrency and verified compilation", "url": "http://dl.acm.org/citation.cfm?id=1926393"}