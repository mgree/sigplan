{"article_publication_date": "01-26-2011", "fulltext": "\n Precise Reasoning for Programs Using Containers Isil Dillig Thomas Dillig Alex Aiken Department of \nComputer Science Department of Computer Science Department of Computer Science Stanford University Stanford \nUniversity Stanford University isil@cs.stanford.edu tdillig@cs.stanford.edu aiken@cs.stanford.edu Abstract \nContainers are general-purpose data structures that provide func\u00adtionality for inserting, reading, removing, \nand iterating over ele\u00adments. Since many applications written in modern programming languages, such as \nC++ and Java, use containers as standard build\u00ading blocks, precise analysis of many programs requires \na fairly so\u00adphisticated understanding of container contents. In this paper, we present a sound, precise, \nand fully automatic technique for static reasoning about contents of containers. We show that the proposed \ntechnique adds useful precision for verifying real C++ applications and that it scales to applications \nwith over 100,000 lines of code. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program \nVerication General Terms Languages, Veri.cation, Experimentation 1. Introduction Containers are a family \nof general-purpose abstract data struc\u00adtures that provide functionality for inserting, retrieving, removing, \nand iterating over elements. Examples of containers include maps, lists, vectors, sets, multimaps, deques, \nas well as their combina\u00adtions. We classify containers as either position-dependent or value\u00addependent: \nIn position-dependent containers, each element e has a position that is used for inserting e into or \nreading e from the container. Position-dependent containers include vectors and lists, which support \ninserting and reading elements at a speci.ed po\u00adsition, as well as queues and stacks, which allow inserting \nand reading elements at the .rst or last position. In contrast, value\u00addependent containers expose no \nnotion of position, and each el\u00adement is added and retrieved using its value. Instances of value\u00addependent \ncontainers include various kinds of maps, sets, bags, and multimaps. For instance, in a map, elements \nare inserted and looked up using a key; similarly, in a set, elements are inserted and found by the value \nof their elements rather than a position in the container. Both kinds of containers are ubiquitous in \nmodern program\u00adming, and many languages, such as C++, Java, and C#, provide a standard set of containers \nthat programmers use as basic building blocks for the implementation of other more complex data struc\u00adtures \nand software. For this reason, successful veri.cation of pro\u00adgrams written in higher-level programming \nparadigms requires a fairly sophisticated understanding of how individual elements are Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 11, January \n26 28, 2011, Austin, Texas, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 \nmodi.ed as they .ow in and out of containers. In fact, even basic safety properties often require reasoning \nabout individual elements stored inside containers: To prove that the result of looking up a key k from \na map m is non-null, we need to know that an element with key k is present in m and that the value associated \nwith k is non-null.  In languages with explicit memory management (such as C++), the safety of sequentially \ndeallocating elements in a list or vec\u00adtor depends on the absence of aliasing pointers in the container. \nAs these examples illustrate, proving even simple properties  may require a richer abstraction than \ntreating container contents as sets. In the .rst example, we need to know not only which val\u00adues are \npresent in the map, but also which keys are associated with which values. Similarly, the second example \nrequires proving the uniqueness of elements stored at different positions of the con\u00adtainer. Hence, successful \nveri.cation of these properties requires a detailed, per-element understanding of container contents. \nWe are interested in verifying properties of container-using pro\u00adgrams, such as the examples above. We \nfocus on veri.cation of the client program, divorcing checking of the client from the separate problem \nof verifying the container implementation itself. We be\u00adlieve this separation is advantageous for several \nreasons: 1. Understanding the contents of a container does not require un\u00adderstanding the container s \nimplementation. For example, while a map may be implemented as a hash table or a red-black tree, they \nboth export the functionality of asso\u00adciating a key with a value. From the client s perspective, the \ndifference between a hash map and a red-black tree lies primar\u00adily in the performance trade-off between \nvarious operations. 2. Verifying container implementations requires different tech\u00adniques and degrees \nof automation then verifying their clients. Hence, separating these two tasks allows us to choose the \nveri.\u00adcation techniques best-suited for each purpose. While we might need heavy-weight, semi-automatic \napproaches for verifying container implementations, we can still develop fully automatic and more scalable \ntechniques for verifying their clients. 3. There are orders of magnitude more clients of a container \nthan there are container implementations. This fact makes it possible to annotate a handful of library \ninter\u00adfaces in order to analyze many programs using these containers. We propose a precise and fully \nautomatic technique for static reasoning about container contents. By separating the internal im\u00adplementation \nof containers from their client-side use, our technique provides a uniform representation and analysis \nmethodology for any position or value-dependent container. Rather than modeling containers as sets of \nvalues, our technique provides a per-element understanding of containers, enabling the abstraction to \ndistinguish properties that hold for different elements. Our abstraction natu\u00adrally models arbitrary \nnestings of containers, commonly used in  1: vector< map<string, int>* > exam_scores; 2: 3: for(int \nj=0; j<NUM_EXAMS; j++) 4: { 5: map<string, int>* m = new map<string, int>(); 6: exam_scores.push_back(m); \n7: } 8: 9: map<string, vector<int>*>::iterator it = 10: student_scores.begin(); 11: for(; it != student_scores.end(); \nit++) 12: { 13: string student = it->first; 14: vector<int>* scores = it->second; 15: for(int k=0; k \n<NUM_EXAMS; k++) 16: { 17: (*exam_scores[k])[student] = (*scores)[k]; 18: } 19:} Figure 1. Example illustrating \nkey features of the technique real programs. For example, our technique can reason precisely about a \nmap of lists, expressing which lists are associated with which keys, which nested lists are shared or \ndistinct, while also tracking the contents of the nested lists. 1.1 An Informal Overview To develop \na uni.ed representation for containers, we model any container as a function that converts a key to an \nabstract index (an integer), which is then mapped to a value at that index. In this abstraction, a key \ncorresponds to any term that is used for inserting an element into or reading an element from the container. \nFor example, in a vector, keys are integers identifying a position in the vector; in a set, keys are \nthe elements that are inserted into the set. For any container, keys are converted to abstract indices \nusing a key-to-index mapping, but this mapping differs between position-and value-dependent containers: \nFor position-dependent containers (such as a vector), the key-to-index mapping is the identity, as the \nkey is the position in the data structure. For value\u00addependent containers, we leave the function converting \nkeys to indices uninterpreted; clients of value-dependent containers cannot rely on elements being stored \nin any particular place, just that they are stored somewhere in the container. A key advantage of introducing \nan extra level of indirection from keys to indices is that this strategy allows us to treat position\u00adand \nvalue-dependent containers uniformly, while providing the ability to differentiate between distinct elements \nby using inte\u00adger constraints on the indices. Speci.cally, we model containers using indexed locations \nof the form (a)i where the index variable i ranges over possible abstract indices of the container. All \nele\u00adments in the container are represented by a single abstract location (a)i, but constraints on the \nindex variable i allow distinctions to be made among the different elements of the container. This approach \nhas been previously used for successful reasoning about array con\u00adtents [1], and, as we shall see, our \napproach extends these bene.ts to both position-and value-dependent containers. This combination of indexed \nlocations and constraints on index variables allows for a much more detailed understanding of con\u00adtainers \nthan representing their contents as a set. For example, if a container c s contents are modeled by the \nset of values {13, 5, 8}, this abstraction encodes that any element in c may have any of the values 13, \n5, and 8, effectively mixing values associated with dif\u00adferent elements. On the other hand, by representing \nc using an in\u00addexed abstract location (a)i, we can qualify each of the values 13, 5, and 8 by constraints \nf1, f2, and f3, restricting which indices in Figure 2. The representation of container exam scores after \nthe analysis of code from Figure 1 (a)i may have which value. The latter abstraction encodes that only \nthose values whose keys are consistent with the index constraint fi may have value vi, and thereby retains \nthe correlations between po\u00adsitions and values for position-dependent containers and key-value correlations \nfor value-dependent containers. To illustrate important features of our technique, consider the C++ code \nsnippet in Figure 1. Here, the container student scores maps each student to a vector of integers, indicating \nthe score re\u00adceived by each student on every exam. To keep the example sim\u00adple, suppose that there are \nonly two students, Tom and Isil, and Tom received scores 76 and 65, and Isil received scores 87 and 72 \non two exams. The code in Figure 1 builds a reverse mapping exam scores where the i th element in exam \nscores is a map from each student to this student s score on the i th exam. Figure 2 shows a graphical \nrepresentation of the facts estab\u00adlished about the contents of exam scores after analyzing the code from \nFigure 1. In this .gure, nodes in the graph represent abstract locations, a directed edge from node A \nto B quali.ed by constraint f indicates that B is one of the values stored in A and f constrains at which \nindex of A the value B may be stored. We highlight im\u00adportant features of the abstraction based on Figure \n2: 1. Abstract containers: Observe that the vector exam scores is quali.ed by an index variable i1 and \nthe maps nested inside exam scores are also quali.ed by an index variable i3. Both of these index variables \nallow us to select different elements in the container by constraining the values of i1 and i3. 2. Memory \nallocations: A key prerequisite for precise reasoning about nested containers is differentiating different \nallocations. In the .gure, memory locations arising from the allocation at line 5 are described by .{i2}, \nwhere i2 is also an index variable. Hence, just as we use index variables to differentiate between elements \nin a container, we also use them for distinguishing different memory allocations arising from the same \nexpression. 3. Key-to-index mapping: On the edge from (.{i2})i3 to 76, in\u00addex variable i3 is equal to \npos( tom ), where pos is an invert\u00adible, uninterpreted function representing the mapping from key tom \nto a unique, but unspeci.ed index. On the other hand, since exam scores is a position-dependent container, \nthe key\u00adto-index mapping is the identity function; hence, the outgoing edge from (exam scores)i1 is quali.ed \nby 0 = i1 < 2. 4. Nesting of data structures: On the edge from (exam scores)i1 to the nested maps modeled \nby (.{i2})i3 , i2 is equal to i1. This constraint indicates that there is a unique allocation for every \nindex of the container exam scores because there is exactly one i2 for each i1. Furthermore, together \nwith the constraints on edges outgoing from (.{i2})i3 , the abstraction encodes that the map stored at \nposition 0 of the vector exam scores asso\u00ad   ciates key tom with value 76, but the map stored at position \n1 of the vector associates tom with value 65. 5. Iterators: The indirection from keys to indices provides \na nat\u00adural way to model iterators by accessing every element in in\u00adcreasing order of their abstract indices. \nSince the key-to-index mapping is always an invertible function, the abstraction en\u00adcodes that every \nelement is visited exactly once. This abstrac\u00adtion is also consistent with the expected semantics that \niteration order over value-dependent containers is, in general, unspec\u00adi.ed (since pos is uninterpreted) \nwhile elements of position\u00addependent containers are visited according to their position. The rest of \nthis paper is organized as follows: Section 2 gives a small language in which we formalize our technique. \nSection 3 describes the analysis and states the soundness theorem. Section 4 describes some extensions \nthat are useful for modeling containers in real applications, and Section 5 discusses our implementation. \nSection 6 presents experimental results, Section 7 surveys related work, and, .nally, Section 8 concludes. \nTo summarize, this paper makes the following key contributions: We present a uni.ed, sound, and precise \ntechnique for client\u00adside reasoning about contents of an important family of data structures known as \ncontainers.  We describe a fully automatic static analysis for containers that provides a detailed, \nper-element understanding of their contents and that supports arbitrary nestings of containers.  We \nshow experimentally that our technique is scalable enough to analyze C++ programs ranging between 16,000 \nto 128,000 lines of code that make heavy use of containers.  We demonstrate experimentally that precise \nreasoning about contents of containers reduces false alarms by an order of mag\u00adnitude compared to an \nanalysis that treats containers as sets of values when verifying the absence of null dereferences, mem\u00adory \nleaks, and deleted memory accesses in C++ programs.  2. Language and Concrete Semantics We .rst introduce \na simple statically-typed language used to for\u00admalize our technique: Program P := e + Expression e := \nv | c | nil | new . t | e1; e2 | let. v : t = e in e' | v1.read(v2) | v1.write(v2,v3) .1 .2 | foreach.0 \n(v ,v ) in v do e od 12 | if v = nil then e1 else e2 fi A program consists of one or more expressions. \nExpressions include variables v, non-negative integer constants c, the special constant nil, container \nallocations (new t ), sequencing (e1; e2), and let expressions. A read operation v1.read(v2) reads the \nvalue of element with key v2 from container v1, and v1.write(v2,v3) writes value v3 with key v2 to container \nv1.A foreach construct iterates over container v, binding the current key to v1 and the value to v2. \nFinally, an if expression evaluates expression e1 or e2, depending on whether variable v is nil or not. \nThe let, new and foreach expressions are labeled with superscripts . which are globally unique expression \nidenti.ers. When irrelevant, we omit .. Types in this language are de.ned by the grammar: Type t := Int \n| Nil | pos adt(t) | val adt(t) | maybe(t) Base types in this language are Int and Nil. Position-dependent \ncontainers with elements of type t have type pos adt(t), and value-dependent containers with value type \nt have type val adt(t). To simplify the technical presentation, we require keys of value\u00ad t = adt(t') \nG(v)= t t'= Nil G f c : Int G f nil : Nil G f v : t G f new t : t G f v1 : adt(t) G f v1 : adt(t)G f \nv2 : Int G f v2 : Int G f v3 : t3,t3 <: maybe(t) G f v1.read(v2): maybe(t)G f v1.write(v2,v3): Nil G \nf v : adt(t)G f e1 : t1 G[Int/v1, t/v2] f e : te G f e2 : t2 G f foreach (v1,v2) in v do e od : Nil \nG f e1; e2 : t2 G f v : t t<: maybe(t') G[t'/v] f e1 : t'' G f e : t',t' <: t ' : t'' G[Nil/v] f e2 \n: t'' G[t/v] f e' : t'' G f if v G f let v : t = nil then e1 else e2 fi : t'' = e in e Figure 3. Type \nchecking rules dependent containers to be integers; Section 4 discusses how to ex\u00adtend our technique \nto keys with arbitrary types and custom equality operators. We also introduce a type maybe(t ) for elements \nwhose type can be either Nil or t. A subtyping relation is de.ned as: t<: t Nil <: maybe(t ) t<: maybe(t) \nWe write adt(t ) as shorthand for pos adt(t ).val adt(t). Type checking rules for this language are given \nin Figure 3. Observe that this language allows arbitrary nestings of contain\u00aders because the element \ntype of a container can be another con\u00adtainer. Also, while this language does not have explicit contains \nand remove operations that are commonly de.ned on containers, elements can be removed by writing nil \nand the presence of key k can be checked by testing whether the result of reading k is nil. 2.1 Operational \nSemantics In the operational semantics of our language, we view memory as a two-dimensional array where \neach row stores a container, and each column identi.es the index of a speci.c element in the container. \nWe model scalar values (integers) as rows where only the 0 th column is used. A concrete memory location \nis a pair (l, i), where l is the base location (i.e., the row) and i is an offset (i.e, the column). \nFigure 4 gives the operational semantics. The general structure of the rules are of the form E, S, C \nf e : l',S'. Here, environ\u00adment E maps program variables to base locations l, store S maps concrete memory \nlocations (l, i) to an integer, identifying another base location or a constant, and C is a vector of \nintegers denoting the current iteration number of each loop in scope. The judgment E, S, C f e : l',S' \nstates that under environment E, store S, and counter vector C, expression e evaluates to value l', producing \na new store S'. In Figure 4, we use the notation S\\l to denote store S with binding l removed. In the \nrules, we also assume that type environment G is available to differentiate between position-and value-dependent \ncontainers. Most of the rules in Figure 4 are straightforward; we only high\u00adlight important features \nof the language semantics. There are two key differences between position-and value-dependent contain\u00aders \nthat our language semantics tries to capture: First, position\u00addependent containers require .lled positions \nof the container to be contiguous whereas value-dependent containers do not. Second, iteration over position-dependent \ncontainers visits elements in in\u00adcreasing order of their position, but iteration over value-dependent \ncontainers visits elements in arbitrary order in general. To capture the .rst difference, observe that \nthe language se\u00admantics requires position-dependent containers to use a contigu\u00ad  E, S f e : l, S ' \nE ' = E[v . ln](ln . dom(S ' )) S '' E(v)= lln . dom(S)= S ' [(ln, 0) . l] S '' : l ' ,S ''' S(l, \n0) = l ' = S[.i.(ln,i) . NIL] E ' ,S '' ,C f e ' : l ' ,S ''' E, S, C f v : l ' ,S E,S,C f c : c,S E,S,C \nf nil : NIL,S E,S,C f new t : ln,S ' E, S, C f let v : t = e in e \\ln E(v2)= l2 S(l2, 0) = pos E(v3)= \nl3 S(l3, 0) = elem E(v2)= l2 S(l2, 0) = key E(v1)= l1 S(l1, 0) = l ' 1 E(v2)= l2 S(l2, 0) = key E(v3)= \nl3 S(l3, 0) = val S(l1' , pos - 1) = NIL if l3 = NIL . pos > 0 E(v1)= l1 S(l1, 0) = l ' E(v1)= l1 S(l1, \n0) = l ' S(l1' , pos +1) = NIL if l3 = NIL 11 S(l ' 1, key)= lres S ' = S[(l1' , key) . val] S ' = \nS[(l1' , pos) . elem] (v1val adt)(v1pos adt) E, S, C f v1.read(v2): lres,S E,S,C f v1.write(v2,v3): NIL,S \n' E, S, C f v1.write(v2,v3): NIL,S ' E(v)= lS(l, 0) = l ' [(k1,.1),..., (kn,.n)] where ki <ki+1 . .= \n((ki,.i) . . . (S(l ' ,ki)= .i . .i = NIL) E(v1)= lk E(v2)= lv . if v pos adt (ki,.i)= i th element of \n. . ' = Permutation(.) if v val adt S ' = S[lk . ki,lv . .i] E ' = E[v1 . lk,v2 . lv] lk,lv . dom(S) \nE, S ' , (i::C) f e : le,S '' e : S ''' E ' , S, (0::C) f process((v1,v2) in . ' ) do e : S ' E, S \n'' , ((i + 1)::C) f process((v1,v2) in .) do (i< Size(.)) E, S, C f foreach (v1,v2) in v do e od : nil,S \n' \\{lk,lv} E, S, (i::C) f process ((v1,v2) in .) do e : S ''' E(v)= lS(l, 0) = l ' E, S, C f e1 : l1,S1 \nE, S, C f e1 : lr,S ' if l ' = NIL i = Size(.) E, S1,C f e2 : l2,S2 E, S, C f e2 : lr,S ' if l ' = NIL \nE, S, (i::C) f process ((v1,v2) in .) do e : S E,S,C f e1; e2 : l2,S2 E, S, C f if v = nil then e1 else \ne2 fi : lr,S ' Figure 4. Operational Semantics ous region of memory whereas value-dependent containers \nmay be sparse. In particular, it is legal to use any key when writing to a value-dependent container, \nbut for position-dependent containers, the write operation is only de.ned if it does not create holes \nin the container, i.e., all elements with indices in range [0, size) are non-nil and elements with indices \nat least size are nil. To capture the second difference, observe, in the foreach rule, that . is an ordered \nlist of (key, value) pairs, but we construct an arbitrary per\u00admutation . ' of . when iterating over value-dependent \ncontainers. Also, observe that the (key, value) pairs are pre-computed; hence, any changes to the container \nduring the iteration do not affect the (key, value) pairs that are visited. 3. Abstract Semantics In \nthis section, we describe the abstract semantics that form the basis of our analysis. We .rst describe \nour abstract domain (Sec\u00adtion 3.1) and then discuss our abstract model of containers (Sec\u00adtion 3.2). \nIn Section 3.3, we present the analysis, and in Section 3.4, we state the soundness theorem. 3.1 Abstract \nDomain and Preliminaries Our abstraction differentiates between two kinds of abstract mem\u00adory locations: \nBasic locations, \u00df, represent a single concrete ele\u00adment, and indexed locations, (a)i, represent containers. \nAs men\u00adtioned in Section 1, although a single indexed location (a)i rep\u00adresents many concrete elements, \nour abstraction can reason about individual elements stored in the container by using constraints on \nthe index variable i. The abstract values used in the analysis are: Abstract value p = NIL | c | d Abstract \nlocation d = \u00df. |(a)i Allocation a = ..{ii} Abstract values are NIL, integer constants c, basic locations \n\u00df. (where . indicates the program point where the location is introduced) and indexed abstract locations \n(a)i. Allocations a are of the form ..{ii}, where . is a label for the syntactic allocation expression \nnew .t. More interestingly, allocations are also quali.ed by a (potentially empty) vector of index variables \nto distinguish allocations arising from the same syntactic expression in different loop iterations. Hence, \njust as index variables allow us to refer to distinct elements in a container, index variables also distinguish \nallocations arising from the same program expression. Since loops may be nested, the number of index \nvariables in ..{ii} is equal to the loop nesting depth of a new . t expression. Unlike the concrete store \nthat maps each concrete location to exactly one concrete value, the abstract store necessarily maps each \nabstract location to a set of possible abstract values. An abstract value set . is a set of abstract \nvalue (p), constraint (f) pairs: Abstract value set . := 2(p,f) Here, constraints f select particular \nelements from indexed loca\u00adtions. For example, if the abstract value set for a container (a)i is {(7,i \n= 0), (4,i = 1), (NIL,i = 2)}, the abstraction encodes that the values of elements at indices 0 and 1 \nare 7 and 4 respectively, but all the other elements are nil. In the rest of this paper, we assume that \nan abstract value set . does not contain two pairs of the form (p, f1) and (p, f2); instead, . contains \np only once under f1 . f2. 3.1.1 Bracketing Constraints The constraints we require are more elaborate \nthan we have indi\u00adcated so far. Since most static analyses overapproximate program behavior, the reader \nmay expect that the constraints f used in the abstraction are overapproximations. In other words, if \nf * is a con\u00adstraint describing some subset of elements in the container during a concrete execution, \nthen f * . f if f is an overapproximation. Now, our analysis relies crucially on negating constraints \nto model certain constructs well, speci.cally updates to containers and path conditions. But, unfortunately, \nif f is a strict overapproximation, then \u00acf is a strict underapproximation of \u00acf *, i.e., \u00acf * .\u00acf. Clearly, \nfor soundness, we need a negation operation that preserves overapproximations.  To solve this problem, \nall the constraints used in our abstrac\u00adtion are bracketing constraints (.may,.must), simultaneously \nrep\u00adresenting over-and underapproximations of some set of concrete elements. A bracketing constraint \nis well-formed if .must . .may. The key bene.t of bracketing constraints is that they preserve over\u00adand \nunderapproximations under negation: \u00ac(.may,.must) = (\u00ac.must, \u00ac.may) In other words, if .may and .must \nare over-and underapproxima\u00adtions for some fact F , then \u00ac.must and \u00ac.may are over-and under\u00adintuition \nbehind this choice is that if we insert an element e with key j into a position-dependent container, \nthen e is guaranteed to be the j th element when iterating over the container. On the other hand, if \nwe insert element e with key j to a value-dependent container, we have no guarantees about where e will \nappear in the iteration or\u00adder. Thus, we model the key-to-index mapping of value-dependent containers \nas an invertible uninterpreted function. Formally, we de.ne two index selection operators, . and ., for \nmapping keys to index constraints for position-and value\u00addependent containers respectively. DEFINITION \n1. (Index Selection . for Position-Dependent Con\u00adtainer) Let .key be the set of possible abstract values \nassociated with some key, and let i be an index variable. Then, approximations for \u00acF respectively. \nWe brie.y review some basic .key. i = properties of bracketing constraints [1]: (i = pj . fj ) (pj,fj)..key \n \u00ac(.may,.must) = (\u00ac.must, \u00ac.may) DEFINITION 2. (Index Selection . for Value-Dependent Con\u00ad(.may1,.must1).(.may2,.must2) \n= (.may1 . .may2,.must1 . .must2) tainer) Let .key be the set of possible abstract values associated \n(.may1,.must1).(.may2,.must2) = (.may1 . .may2,.must1 . .must2) with some key, and let i be an index \nvariable. Then, SAT((.may,.must)) = SAT(.may) VALID((.may,.must)) = VALID(.must)  .key. i =(i = pos(pj \n) . fj ) In this paper, any constraint f is assumed to be a bracketing constraint unless explicitly stated \notherwise. To make this clear, any time we do not use a bracketing constraint, we use the letter . instead \nof f. Furthermore, if the may and must conditions of a bracketing constraint are the same, we write a \nsingle constraint in\u00adstead of a pair. For example, we abbreviate the bracketing constraint (i = k, i \n= k) as i = k. The constraints .may and .must we use in\u00adside bracketing constraints in this paper belong \nto the combined theory of linear integer arithmetic and uninterpreted functions.  3.2 Abstract Model \nof Containers As discussed in Section 1, our abstraction models any position-or value-dependent container \nas a mapping from a key to an abstract index to a value stored at this index of the container. In this \nsection, we detail the key-to-index and the index-to-value mappings. 3.2.1 Index Selection: From Keys \nto Indices The most important requirement for the key-to-index mapping M for containers is that it obeys \nthe following axiom: .i1,i2. i1 = i2 . M-1(i1)= M-1(i2) This axiom states that if two abstract indices \nare equal, then the keys associated with these indices must also be equal. This re\u00adquirement is necessary \nfor soundness; otherwise, two keys may be mapped to the same index, causing a value associated with key \nk1 to be erroneously overwritten through inserts using a different key k2. Hence, M has the property \nthat its inverse mapping is a func\u00adtion. However, the question remains whether M is itself a function. \nIn this regard, there are two sensible design alternatives: (pj,fj)..key where pos is an invertible uninterpreted \nfunction. Given an abstract value set .key representing a set of possible keys, the index selectors . \nand . yield a constraint describing the possible indices associated with .key. In the de.nition of ., \nsince the mapping M is the identity function, the index variable i is set equal to each possible value \npj of the key (i.e., i = pj ). On the other hand, in the de.nition of ., the index variable i is equal \nto an invertible uninterpreted function pos of each key (i.e., i = pos(pj )). Since the abstract value \nset associated with the key may contain more than one element, we take the disjunction of the constraints \nassociated with each possible value of the key.  3.2.2 Element Selection: From Indices to Values We \nnow consider the problem of determining the value associated with a given index. More speci.cally, given \nan abstract value set . associated with a container, we want to determine which elements of . are consistent \nwith some index constraint f. We begin with a simple example: Suppose that the abstract value set . for \na container (a)i is {(8,i = 1), (5,i = 2), (NIL,i > 2))}and we want to determine the possible values \nof the element at index 2 in the container. To do this, we can substitute 2 for index variable i and \nremove all unsatis.able elements from ., which yields 5 as the only possible value for this element. \nWe formalize this concept using an element selection operation N : DEFINITION 3. (Element Selection N \n) Let I denote the set of index variables mentioned in constraint f, and let QE de.ne a  quanti.er \nelimination procedure. Then, (pj ,fj ) . . . SAT(fj . f). 1. For some containers that allow multiple \nvalues for the same key, such as multimaps, we can allow the same key to map to  .N f =(pj ,f j ' ) \nmultiple indices such that M itself is not a function. f ' j = QE(.I. (fj . f)) 2. We can require M to \nbe a function and model containers that allow multiple values per key using nested containers. Without \nloss of generality, we choose (2) because our model can express arbitrary nestings of containers. Since \nboth M and M-1 are functions, the key-to-index mapping is always a bijec\u00adtion (i.e., an invertible function). \nHowever, the key-to-index map\u00adping for value-dependent containers differs from that of position\u00addependent \ncontainers: In particular, for value-dependent contain\u00aders, M is an invertible uninterpreted function, \nwhile for position\u00addependent containers, M is the (interpreted) identity function. The First, observe \nthat the element selection operation N .lters out elements in . inconsistent with f because of the requirement \nSAT(fj . f). Second, observe that the resulting constraint f ' j is obtained by existentially quantifying \nand then subsequently elim\u00adinating all index variables used in f from the constraint fj . f because f \n' j = QE(.I. (fj .f)). Existential quanti.er elimination generalizes the simple substitution mechanism \nwe sketched out in\u00adformally in the example: Since the index constraint f is not always a simple equality, \nwe may not be able to substitute concrete values for the index variables; hence, we use existential quanti.er \nelimi\u00adnation in the general case. Furthermore, it is not required that this  . = {NIL, true} . = {c, \ntrue} (1) (2) E, S, C f nil : ., SE, S, C f c : ., S E(v)= \u00df E, S, C f e1 : .1, S1 S(\u00df)= . E, S1, C f \ne2 : .2, S2 (3) (4) E, S, C f v : ., SE, S, C f e1; e2 : .2, S2 E, S, C f e : ., S ' ' , S '' E[v . \u00df.], \nS ' [\u00df. . .], C f e : . ' (5) ' : . ' , S''\\\u00df. E, S, C f let. v : t = e in e E(v)= \u00df S(\u00df)= . = fnil \n= ((pj = NIL) . fj ) (pj,fj)..E, S, C f e1 : S1 E, S, C f e2 : S2 S ' =(S1 .\u00acfnil) U (S2 . fnil) (6) \nE, S, C f if v = nil then e1 else e2 : S' Figure 5. Transformers not Directly Related to Containers quanti.er \nelimination procedure be exact since our technique uses bracketing constraints. In particular, since \nquanti.er elimination in the theory of uninterpreted functions is not always exact, we may use quanti.er-free \nover-and underapproximations [2]. EXAMPLE 1. Consider the abstract value set (0, (0 = i = 10, false)), \n(1, (0 = i = 10, false)), . = (NIL, (i> 10,i > 10)) associated with container (a)i. To determine the \npossible values of those elements whose indices in the container are in the range [0, 2], we compute: \n.N (0 = i = 2) = {(0, (true, false)), (1, (true, false))} The resulting set encodes that the possible \nvalues of elements in the range [0, 2] are either 0 or 1, but de.nitely not NIL.  3.3 The Analysis \nWe describe the analysis as deductive rules of the form: Read from Position Dependent Container E(v1)= \n\u00df1 E(v2)= \u00df2 S(\u00df1)= .1 S(\u00df2)= .2 . = {S((a)ij ) N ((.2.ij ) . fj ) | ((a)ij ,fj ) . .1)} E, S, C f v1.read(v2): \n., S Read from Value Dependent Container E(v1)= \u00df1 E(v2)= \u00df2 S(\u00df1)= .1 S(\u00df2)= .2 . = {S((a)ij ) N ((.2.ij \n) . fj ) | ((a)ij ,fj ) . .1)} E, S, C f v1.read(v2): ., S Newval . ' w = {(pj ,fw . fj ) | (pj ,fj \n) . .w} .p = {(pk, \u00acfw . fk) | (pk,fk) . S((a)i)} S f newval((a)i,.w,fw): . ' . .p w Update .c = {((a)i1 \n,f1),..., ((a)ik ,fk)} S f newval((a)i1 ,.val, (.key . i1) . f1): .1 ... S f newval((a)ik ,.val, (.key \n. ik) . fk): .k S ' = S[(a)i1 . .1,..., (a)ik . .k] (. . {., .}) S f update(.c,.key,.val) with . : S' \nWrite to Value Dependent Container E(v1)= \u00df1 E(v2)= \u00df2 E(v3)= \u00df3 S(\u00df1)= .1 S(\u00df2)= .2 S(\u00df3)= .3 S f update(.1,.2,.3) \nwith . : S ' E, S, C f v1.write(v2,v3): {(NIL, true)}, S' Write to Position Dependent Container E(v1)= \n\u00df1 E(v2)= \u00df2 E(v3)= \u00df3 S(\u00df1)= .1 S(\u00df2)= .2 S(\u00df3)= .3 S f update(.1,.2,.3) with . : S ' 0 E, S, C f v1.write(v2,v3): \n{(NIL, true)}, S' Container Allocation a = ..{ii.}, ii. =[i.,...,i. ] where n = |C| 1n S f newval((a)i. \n, {(NIL, true)}, ii. = C): . ii. E, S, C f new. t : {((a)i. , = C)}, S[(a)i . .] . E, S, C f e : ., S \n' where E, S, and C are the abstract counterparts of the E, S, C 00 Figure 6. Abstract Semantics for \nContainer Operations environments used in the concrete semantics. In particular, the abstract environment \nE maps program variables to basic locations \u00df., the abstract store S maps abstract memory locations d \nto abstract value sets ., and, .nally, the counter vector C (a vector of integers) is used for distinguishing \ndifferent loop iterations. We present the analysis in three steps: First, we discuss the basic transformers \nnot directly related to containers (Figure 5), then we describe the abstract semantics for reading from, \nwriting to, and allocating containers (Figure 6), and, .nally, we give the abstract semantics of the \nforeach construct (Figure 7). Most of the transformers presented in Figure 5 are straightfor\u00adward; we \nonly discuss rule (6) in detail. In this rule, fnil describes under what condition v is NIL. After independently \nanalyzing the Rule (6) also uses a join operation on abstract stores de.ned as: .d . (dom(S1) . dom(S2)). \n(p, f) . (S1 U S2)(d) . (p, f1) . S1(d) . (p, f2) . S2(d) . f = f1 . f2 In this de.nition, we require \nthat every abstract value p that is present in either S1 or S2 is also present in the other; if it is \nnot explicitly there, we add it under constraint false. 3.3.1 Abstract Semantics for Container Operations \nWe now consider the abstract semantics for reading from contain\u00ad ers, presented in Figure 6. In the .rst \ntwo rules of Figure 6, .2 repre\u00adthen and else branches, we obtain the resulting abstract store S' sents \nthe abstract value set for the key v2, and each of the elements by conjoining S1 and S2 with \u00acfnil and \nfnil respectively and then (a)ij in abstract value set .1 are containers that the read operation may \nbe performed on. We perform the key-to-index mapping using the . operator for position-dependent containers \nand the . oper\u00adtaking their union. In this rule, we use the notation S . f as shorthand for the describe \nthe positions in container (a)ij from which we read the  Key, value pair at kth Iteration for pos adt \nvalue. Finally, we perform the index-to-value mapping using the N operation; the abstract value set . \ndescribes all possible elements E(v)= \u00df S(\u00df)= .c that may be obtained as a result of the read. .v ) N \n(ij = {S((a)ij .k\u00d7v = ((k, pv),fv) ( = k . fj ) | ((a)ij ,fj ) . .c}(pv,fv) . .v . pv = NIL) The now \nconsider the rules in Figure 6 that describe the abstract semantics for writing to containers. The helper \nrule Newval com\u00ad f elem.(v)@k : .k\u00d7v Key, value pair at kth Iteration for val adt putes the new abstract \nvalue set associated with container (a)i af\u00adter writing .w at those indices of (a)i described by constraint \nfw. is written to only those locations that satisfy the index Since .w constraint fw, we conjoin fw \nwith each element in .w to obtain . ' E(v)= \u00df S(\u00df)= .c w . Now, those elements in container (a)i that \ndo not satisfy the index constraint fw are not modi.ed by the write; hence the ex\u00ad = {S((a)ij .k\u00d7v . \n.. .v ) N (ij = k . fj ) | ((a)ij ,fj ) . .c}(pv,fv) . .v . pv = NIL . .. isting values S((a)i) are preserved \nunder condition \u00acfw. Thus, .p represents all values in (a)i that are not affected by the write. Fi\u00adnally, \nthe set of new values stored in container (a)i is obtained by taking the union of . ' (i.e.,the new value \nfor the updated indices) . fk = ((pos(pk)= k) ((pk,pv),fkv) = . (fkv =(fk . fv)[pos./pos]) .... . SAT(fkv) \nw and .p (i.e., values stored at all other indices). f elem.(v)@k : .k\u00d7v The second helper rule, Update, \nuses Newval to compute the new abstract store after a write. In this rule, each element (a)ij in .c represents \na container that may be written to. The value set .val describes the possible values that may be written, \nand the constraint ((.key . ij ) . fj ) (where . is either . or .) describes those indices of (a)ij that \nare modi.ed. For each container (a)ij in .c, the Newval rule is invoked to compute the new value set \n.j after the write, and a new store S ' is obtained by binding each (a)ij to its new value set .j . The \nwrite rules for position-and value-dependent containers use the Update rule to compute the new abstract \nstore after the write. As expected, the rule for position\u00addependent containers uses the . operator while \nthe rule for value\u00addependent containters uses ..1 The last rule in Figure 6 describes the abstract semantics \nfor container allocations. The abstract location arising from the allo\u00adcation is labeled with the expression \nidenti.er . to differentiate al\u00adlocation sites, and the vector of index variables ii. differentiates \nallocations arising from the same syntactic expression in different loop iterations. Since the counter \nvector C has as many entries as the loop nesting depth of the allocation expression, the number of Foreach \nf elem.0 (v)@k.0 : .kv .key = {(pkey,f) | ((pkey,pval),f) . .kv} .val = {(pval,f) | ((pkey,pval),f) . \n.kv}  E' = E[v1 . \u00df.1 ,v2 . \u00df.2 ] S' = S[\u00df.1 . .key,\u00df2 .2 . .val] E ' , S ' , (0::C) f .x (e, k.): S \n'' . = {(NIL, true)} .1 .1 E, S, C f foreach.0 (v ,v ) in v do e od : ., S''\\{\u00df.1 ,\u00df.2 } 12 Fix E, S[c/k], \n(c::C) f e : ., S' , S' . S* E, S* , ((c + 1)::C) f .x (e, k): S* E, S, (c::C) f .x (e, k): S* Figure \n7. Abstract Semantics for Iterating over Containers indices of the container. After the write at line \n2, we have:  variables in ii. is equal to the number of entries in C. Observe that, in this rule, the \nconstraint ii. = C stipulates that each index vari\u00adable in ii. is equal to the appropriate counter describing \nthe iteration number of a loop. Finally, recall that the concrete semantics initial\u00adizes the entries \nin a freshly allocated container to NIL, hence, the Newval rule is invoked to compute the new value set \nassociated with container (a)i. after initializing its elements to NIL. 0 EXAMPLE 2. Consider the simple \nprogram: b 1: leta v: val adt(Int) = new val adt(Int) in 2: v.write(4, 87), 3: let x = v.read(4) in 4: \nlet y = v.read(3) in nil Assume E(v)= \u00dfa. The abstract store after line 1 is given by: S :[\u00dfa . {(.b)i, \ntrue)}, (.b)i .{(NIL, true)}] Here, .b does not have any index variables because the allocation expression \nis not in a loop; the index variable i in (.b)i ranges over 1 Recall that the operational semantics are \nunde.ned if position-dependent containers are not used contiguously. Since checking this correct usage \ncondition is an orthogonal problem to reasoning about container contents, the abstract semantics reason \nonly about programs for which the operational semantics do not get stuck . \u00dfa . {(.b)i, true)}, S : (.b)i \n.{(87,i = pos(4)), (NIL,i = pos(4))} At line 3, the abstract value set for x is: S((.b)i) N (i.4) = S((.b)i) \nN (i = pos(4)) = {(87, true)} Similarly, at line 4 the abstract value set for y is: S((.b)i) N (i.3) \n= {(NIL, true)}  3.3.2 Abstract Semantics for Iteration The main idea behind the abstract semantics \nfor iterating over containers is that the j th iteration of the loop accesses the key and value pairs \nstored at the j th index of the container. It is easy to see that this strategy is correct for position-dependent \ncontainers because (i) the concrete semantics requires an element with key j to be accessed during the \nj th iteration and (ii) in our abstraction, the key-to-index mapping for position-dependent containers \nis the identity function. For value-dependent containers, recall that the operational semantics stipulates \nan arbitrary iteration order. Now, although the abstraction models iteration by visiting the element \nat the j th index during the j th iteration, it does not impose any restrictions on which key may be \nvisited during the j th iteration because the key-to-index mapping is an uninterpreted function (the \nconstraint j = pos(k) is satis.able for any value of j and any key k). Furthermore, since pos is an invertible \nfunction, the abstraction encodes that for each different value of j, there is a different key k, indicating \nthat no key may be visited multiple times.  Figure 7 gives the abstract semantics of the foreach construct. \nThe .rst two rules compute the set of (key, value) pairs that may be visited during an arbitrary k th \niteration of the loop for position\u00adand value-dependent containers respectively. Since the abstract se\u00admantics \nmodels iteration as visiting the k th index during the k th iteration, we retrieve the values stored \nin container (a)ij under the index constraint ij = k. Therefore, in the .rst two rules, the ab\u00adstract \nvalue set .v describes the values that may be stored at index k. For position-dependent containers, the \nkey during the k th it\u00aderation of the loop is bound to k, as required by the operational semantics. In \nthe .rst rule, we construct the set of possible key, value pairs for the k th iteration as the set of \nall (k, pv) such that pv is non-nil and in .v. Observe that the (key, value) pairs in .k\u00d7v respect the \nrelationship between keys (i.e., positions) and values, as illustrated by the following example: EXAMPLE \n3. Consider a position-dependent container (a)i such that S((a)i)= {(44,i = 0), (3,i = 1), (NIL,i = 2)}. \nWe compute the set of (key, value) pairs during the k th iteration as: .k\u00d7v = {((k, 44),k = 0), ((k, \n3),k = 1)} Observe that the abstraction respects the relationship between po\u00adsitions and values; for \nexample, the pair (1, 44) is infeasible. The second rule in Figure 7 computes the (key, value) pairs \nduring the k th iteration for value-dependent containers. In this rule, the key during the k th iteration \nis bound to all integers pk such that k = pos(pk), as stipulated by constraint fk.2 Asinthe position-dependent \ncase, the relationship between keys and values are preserved because the rule .lters out infeasible (key, \nvalue) pairs by checking the satis.ability of fkv. Finally, observe that the pos function is renamed \nto pos. because elements may be visited in a different order in each loop. The foreach rule .rst invokes \nthe appropriate helper elem rule for computing the set of (key, value) pairs during an arbitrary k.0 \nth iteration. (The variable k is superscripted with the expression iden\u00adti.er .0 for this loop in order \nto avoid naming con.icts.) The set .kv therefore describes the set of possible (key, value) pairs during \nan arbitrary iteration. The abstract value sets .key and .val are obtained by selecting the keys and \nthe values from .kv respectively. The ab\u00adstract environment E ' binds variables v1, v2 to fresh locations \n\u00df.1 and \u00df.2 , and the abstract store S ' binds \u00df.1 and \u00df.2 to .key and .val, since the operational semantics \nrequires the (key, value) pairs to be computed before executing the body of the foreach construct. The \nforeach rule uses the helper .x rule to obtain the .nal store S'' . In the .x (e, k) rule, c represents \nthe current iteration number of the loop. Since the bindings for v1 and v2 are parametric on vari\u00adable \nk, the rule replaces occurrences of k in Swith concrete value c when evaluating the loop body e. In this \nrule, S* is a sound store de\u00adscribing the cumulative effect of the loop, as S* overapproximates the store \nafter any loop iteration. Here, an abstract store S' overap\u00adproximates another abstract store S, written \nSS' according to De.nition 5: DEFINITION 4. (Domain Extension S .Si ) An abstract store S '' = S .Si \nis a domain extention of Swith respect to S ' if the fol\u00adlowing condition holds: Let d be any binding \nin S ' and let (pi,fi) be any element of S ' (d). 1. If d . S.(pi,f ' i) . S(d), then d . S .Si .(pi,f \n' i) . S .Si (d) 2. Otherwise, d . S .Si . (pi, false) . S .Si (d)  DEFINITION 5. (Abstract Store Overapproximation \nSS ') Let S1 be the domain extension S .Si , and let S2 be the domain 2 Observe that the set of all possible \npk s is .nite for any given program in our language; hence candidates for pk are drawn from a .nite set. \nextension S'S' if for all d . S1 and for all pi such .S . Then, S that (pi, (.may,.must)) . S1(d) and \n(pi, (. ' ,. ' maymust)) . S2(d): '' .may . .may . .must . .must According to this de.nition, a store \nS' overapproximates an\u00adother abstract store S if, when they are extended to the same do\u00admain, any may \nconstraint in Simplies the corresponding may con\u00adstraint in S ', and any must constraint in S is implied \nby the cor\u00adresponding must constraint in S '. In other words, the overapproxi\u00admation encoded in S ' through \nthe may constraints is more permis\u00adsive than S, and the underapproximation encoded by S ' through the \nmust constraints is less permissive than S. In the .x rule, it is easy to see that a trivial invariant \nstore S* always exists since the analysis creates a .nite number of abstract locations for any given \nprogram, and an abstract store Striv with constraint (true, false) mapping each possible abstract location \nto any other abstract location has the property .S. SStriv. To .nd a more useful invariant store than \nthe trivial Striv, it is necessary to infer numeric invariants relating index variables associated with \ndifferent containers or allocation sites. Since the focus of this paper is not invariant generation, \nwe do not go into the details of how to .nd a good invariant store; various techniques based on abstract \ninterpretation [3, 4] and quanti.er elimination [1, 5] can be used for .nding invariants. In particular, \nour previous work on array analy\u00adsis [1] presents an algorithmic way of .nding such invariants in this \ndomain, and we use the algorithm from [1] in our implementation.  3.3.3 An Example Illustrating Key \nFeatures of the Analysis In this section, we consider a small, but realistic, example illustrat\u00ading some \nimportant features of the analysis. Consider the following program fragment: 1: leta paper scores: val \nadt(pos adt(Int)) = 2: new b val adt(pos adt(Int)) in 3: foreachc (pos, cur paper) in papers 4: do e \n5: letd scores: pos adt(Int) = new pos adt(Int) in 6: paper scores.write(cur paper, scores) 7: od; 8: \nletf reviewed paper = paper scores.read(45) in 9: if(reviewed paper != nil) 10: then reviewed paper.write(0, \n5) else nil In this program fragment, papers is a position-dependent con\u00adtainer whose elements are identi.ers \nfor all submitted papers to a conference. The code above creates a new value-dependent con\u00adtainer paper \nscores that maintains a mapping from each paper identi.er to a list of scores associated with this paper. \nThe code iterates over papers and, for each paper, allocates a new position\u00addependent container, scores, \nand inserts the (key, value) pair, (cur paper, scores) into the map. For simplicity, let us assume this \nparticular conference was unpopular this year and had only 3 submissions with identi.ers 21, 45, and \n32, which are placed in papers in this order. Let us also assume that E(papers) is \u00dfp and S(\u00dfp)= {((.p)i1 \n, true)}. After the allocation at line 5 during some arbitrary k th iteration of the loop, the abstract \nenvironment and stores are: E(papers)= \u00dfp E(paper scores)= \u00dfa E(scores)= \u00dfd E(cur paper)= \u00dfc  S(\u00dfp)= \n{((.p)i1 , true)} S(\u00dfa)= {((.b)i2 , true)} S((.p)i1 )= {(21,i1 = 0), (45,i1 = 1), (32,i1 = 2), (NIL,i1 \n= 3)} S(\u00dfc)= {(21,k = 0), (45,k = 1), (32,k = 2)} S((.b)i2 )= {(NIL, true)} S(\u00dfd)= {((.e{i3})i4 ,i3 = \nk)} S((.e{i3})i4 )= {(NIL,i3 = k)} Consider the write at line 6, which uses cur paper as the key and \nthe freshly allocated container scores as the value. Here, the possible values of cur paper during the \nk th loop iteration are given by S(\u00dfc) above, which encodes that the value of cur paper is 21 during \nthe .rst iteration (k =0), 45 during the second iteration (k =1), and 32 during the third iteration (k \n=2). The abstract value set for the value scores is given by S(\u00dfd)= {((.e{i3})i4 ,i3 = k)}. Here, the \nfreshly allocated container is represented by (.e{i3})i4 , which has two index variables i3 and i4, where \ni3 distinguishes allocations from different loop iterations and i4 differentiates elements stored in \nthe container. The constraint i3 = k in S(\u00dfd) encodes that we are considering the allocation that happened \nduring the k th iteration. Hence, the set of all possible (key, value) pairs that are written at line \n6 in any k th iteration are: .. .. ((21, (.e{i3})i4 ),i3 = k . k = 0), ((45, (.e{i3})i4 ),i3 = k . k \n= 1), For the if expression at line 9, only the then branch is satis.able since (.e{i3})i4 is not NIL. \nFinally, after the write at line 11, the values for the nested containers are given by: S((.e{i3})i4 \n)= {(5,i4 =0 . i3 = 1), (NIL,i4 =0 . i3 = 1)} Hence, this abstract store encodes that only the score \nat position 0 of the scores list associated with key 45 in paper scores has been changed to 5, but the \nscore lists associated with all other keys are unchanged.  3.4 Soundness of the Abstraction In order \nto state the soundness theorem, we .rst need to de.ne an abstraction function from concrete to abstract \nmemory locations. Observe that if ii denotes a vector of index variables used in some abstract location \nd and s is a concrete assignment to each of the index variables in ii, then the pair (d, s) represents \none concrete memory location. Therefore, the abstraction function is a mapping from concrete locations \nto a pair consisting of an abstract memory location d and a full assignment s to all index variables \nused in d: Abstraction function a = Concrete loc (l, i) . (d, s) To make this abstraction function precise, \nit is necessary to aug\u00adment the operational semantics with some additional bookkeeping machinery that \nwas omitted from Figure 4 to avoid complicating . . the language semantics. First, for each concrete \nlocation (l, i) in ((32, (.e{i3})i4 ),i3 = k . k = 2) store S, we need to determine the program point \n. that results in the binding of (l, i) in S; we write id(l, i) to denote the program point . associated \nwith the introduction of (l, i). Second, to be able to give Now, if we eliminate the dependence on a \nparticular iteration k, we obtain the set of all possible (key, value) pairs that may be written during \nany iteration of the loop: a full assignment to the index variables in an abstract location, we need \nto determine the counter vector C when a concrete location was introduced. Hence, we assume an environment \nA maps each concrete location (l, i) to the counter vector C present when (l, i) was introduced in concrete \nstore S. Since it is trivial to extend the .. .. ((21, (.e{i3})i4 ),i3 = 0), ((45, (.e{i3})i4 W = ),i3 \n= 1), .. ((32, (.e{i3})i4 ),i3 = 2) operational semantics from Figure 4 to track id(l, i) and A(l, i), \nwe assume this additional bookkeeping information is available. We can now de.ne the abstraction function \nas follows: DEFINITION 6. (Abstraction Function) Let (l, k) be a concrete memory location, and let id(l, \nk)= . such that . labels expression e ., and A(l, k)= C. Then, the abstraction of (l, k), written a(l, \nk), is: . .. 1. ((..{ii.})i. , ii. = C . i= k) if e = new pos adt t 0 0 . .. 2. ((..{ii.})i. , ii. = \nC . i= pos(k)) if e = new val adt t 0 3. (\u00df. , true) 0 otherwise Observe that, while all the allocations \nat line 5 are represented by a single abstract container (.e{i3})i4 , the index constraints stipulate \nthat the allocations associated with each key are distinct from each other, since the values of i3 are \ndifferent for the keys 21, 45, and 32. Now, to process the write at line 6, we use the update rule from \nFigure 6 for each entry in W with .c = {((.b)i2 , true)}(the location associated with container paper \nscores), the key, value sets .key,.val given by each entry in W (.key = {(21, true)}, .val = {((.e{i3})i4 \n),i3 = 0)} etc.), and using the index selector . since paper scores is value-dependent. This yields: \n. . ((.e{i3})i4 , ((i3 =0 . i2 = pos(21)). We extend this abstraction function from all concrete values \nv (i3 =1 . i2 = pos(45)). . . . . to all abstract values p in the following obvious way: (i3 =2 . i2 \n= pos(32))), S((.b)i2 )= .. (NIL,i2 = pos(21). . . . . (NIL, true) if v = NIL i2 = pos(45) . i2 = pos(32)) \n(c, true) if v is integer constant c a(l, k) if v is a memory location(l, k) a(v)= . The new abstract \nvalue set S((.b)i2 ) expresses that all containers stored in paper scores are unique because the value \nof i3 is dif- We write s(f) to denote the result of substituting each of the ferent for each key. Now, \nlet us consider lines 8-10 in the program variables in f with their concrete assignment speci.ed by s. \nIn fragment. To determine the result of the read at line 8, we compute: addition, we assume the substitution \ns(f) gives an interpretation to all function symbols pos. in f by replacing pos. with the particular \n . . ((.e{i3})i4 , ((i3 =0 . i2 = pos(21)). permutation it stands for in a given execution. Since it \nis trivial to (i3 =1 . i2 = pos(45)). . . . . extend the operational semantics to track which permutation \nwas (i3 =2 . i2 = pos(32))), N (i2 = pos(45)) used for which loop, we assume this information is available. \n(NIL,i2 = pos(21). . . . . DEFINITION 7. (Value Agreement) Let v be a concrete value with i2 = pos(45) \n. i2 = pos(32)) which, when simpli.ed, yields {((.e{i3})i4 ,i3 = 1)}. Hence, if S(reviewed paper)= \u00dff \n, then: S(\u00dff )= {((.e{i3})i4 ,i3 = 1)} a(v)=(p, s), and let . be an abstract value set. We say concrete \nvalue v agrees with abstract value set ., written v ~ ., if: 1. (p, (.may,.must)) . . . VALID(s(.may)) \n 2. .(p ' , (. ' ,. ' (p ' = p) maymust)) . .. UNSAT(s(.must' ))  In this de.nition, the .rst condition \nstates the correctness of the overapproximation encoded by ., and the second condition states the correctness \nof the underapproximation. If the abstract represen\u00adtation of v is (p, s), then, for the overapproximation \nto be correct, p must be in . under some constraint (.may,.must) and the may constraint .may must evaluate \nto true under the index assignment s. (Recall that since the language from Section 2 has no inputs, the \nonly variables in constraints are index variables; thus, .may al\u00adways evaluates to a constant under s.) \nThe second condition of value agreement states the correctness of the underapproximation, requiring at \nmost the abstract representation of v to be in ., i.e., all other elements in . should be infeasible \nunder index assignment s. DEFINITION 8. (State Agreement) Let (v, E, S, C) be a con\u00adcrete state, consisting \nof a concrete value v, concrete environment E, concrete store S and counter vector C, and let (., E, \nS, C) be an abstract state with abstract value set . and abstract envi\u00adronment and store E, S and counter \nvector C. We say concrete state (v, E, S, C) agrees with abstract state (., E, S, C), written (v, E, \nS, C) ~ (., E, S, C), if the following conditions hold: 1. v ~ . (according to De.nition 7) 2. .v . \ndom(E). (v . dom(E) . E(v)= a(E(v), 0)) 3. .(l, k) . dom(S).S(l, k)= l ' . (a(l, k)=(d, s) . l ' ~ (S(d) \nNs))  4. C = C  THEOREM 1. (Soundness) Let P be any program. If (E, S, C) ~ (E, S, C), then E, S, C \nf P : l, S ' . E, S, C f P : ., S ' . (l, E, S ' ,C) ~ (., E, S ' , C) The proof is given in the appendix. \n4. Extensions The language we have used for the formal development requires keys of value-dependent containers \nto be integers, but, in real lan\u00adguages, keys may have arbitrary types. The techniques we have de\u00adscribed \nso far are directly applicable when pointer values are used as keys because pointer equality is a form \nof integer equality. How\u00adever, it is common to de.ne custom equality predicates on some types, and determining \nwhether two keys are equal may be more involved than simple integer equality. Consider the following \nC++ code snippet: class Point { int x; int y; color c; Point(int x, int y, color c){ this->x=x; this->y=y; \nthis->c=c; }; bool operator==(const Point &#38; other) { return x == other.x &#38;&#38; y == other.y; \n} } unordered_set<Point> points; Point p1 = Point(5, 34, RED); points.insert(p1); Point p2 = Point(5, \n34, BLUE); points.insert(p2); Here, the type Point de.nes a custom equality operator that only checks \nthe x and y coordinates for a point but disregards its color. In the above program, after the last insertion \noperation, there is only one element in the set even though two points with different colors are inserted. \nIf we treat p1 and p2 as variables in the constraint lan\u00adguage, our technique would conclude that the \nsize of the set is 2 un\u00adder constraint p2 = p1 and 1 under p2 = p1. To be more precise in the presence \nof custom equality predicates, we infer axioms charac\u00adterizing when two objects are equal. Speci.cally, \nby analyzing the implementations of the custom equality predicates, we infer nec\u00adessary and suf.cient \nconditions (. = must) characterizing when may, . = two objects o1 and o2 may and must be equal. (Observe \nthat treating p1 and p2 as variables in the constraint language as above is equiva\u00adlent to the trivial \nand always sound equality condition (true, false)). Now, in order to take into account what we know about \nthe custom equality predicate, we add the axioms .o1,o2.o1 = o2 may . . = and .o1,o2.. = = o2 to the \nconstraint solver. For instance, must . o1 for the simple equality predicate for Point, we could utilize \nthe ax\u00adiom .p1,p2.p1 = p2 . (p1.x = p2.x . p1.y = p2.y), allowing the technique to conclude that the \nsize of the set after the second insertion is 1. In the technical development, we also assumed that the \niteration order over value-dependent containers is arbitrary. While this is true in most cases, some \nvalue-dependent containers (such as a red\u00adblack-tree based map) may visit keys in a certain order during \nan iteration. We can encode such restrictions in the iteration order by analyzing the custom less than \noperators and inferring appropriate axioms about the pos function in a similar way as above. 5. Implementation \nWe have implemented the ideas presented in this paper in our Compass program veri.cation framework for \nanalyzing C and C++ programs. Compass utilizes a gcc and g++ based front-end called SAIL [6] which translates \nC and C++ code to a low-level represen\u00adtation, similar to 3-address code. Compass uses the Mistral SMT \nsolver [7, 8] for solving and simplifying constraints generated dur\u00ading the analysis. Compass supports \nmost features of C++, including classes, arrays, dynamic memory allocation, pointer arithmetic, ref\u00aderences, \nsingle and multiple inheritance, and virtual method calls. Compass performs path-sensitive analysis and \nachieves context\u00adsensitivity by computing polymorphic summaries of functions (and loops) and instantiates \nthem in calling contexts [9]. 6. Experimental Evaluation To demonstrate the usefulness of the ideas presented \nin this pa\u00adper, we evaluate the proposed technique in two different ways: In a .rst set of experiments, \nwe perform a case study and prove the functional correctness of a set of small, but challenging programs \nmanipulating containers. In a second set of experiments, we use this technique to prove memory safety \nproperties of real C++ ap\u00adplications that heavily use containers, and we show that a precise understanding \nof data structure contents is bene.cial in improving analysis results. For both sets of experiments, \nwe annotated the con\u00adtainers provided by the C++ standard template library [10], either directly as position-or \nvalue-dependent containers or by nesting them inside already annotated STL containers. 6.1 Case Study \nIn our case study, we analyze .fteen small, but challenging, exam\u00adple programs totaling close to 1000 \nlines of code. All benchmarks are available at http://www.stanford.edu/~tdillig/cont.txt. The results \nof the case study are presented in Figure 8; we brie.y discuss each of the programs from this table. \nThe .rst two programs copy the contents of a vector and a map into another container of the same type \nand assert their element-wise equality. Program 3 builds the reverse map r of map m by inserting each \n(k, v) pair in m as the key-value pair (v, k) of r. Program 4 is modeled after the example in Section \n1 and asserts the correctness of the entries in exam scores. Program 5 inserts all the keys in a map \nm into a set s and asserts that s contains exactly the keys in m. Programs 6-8 illustrate nested containers \nby asserting properties about the composed data structures. Program 9 inserts numbers [0, size) into \na stack and a queue and asserts that the top of the stack is the last  Program Time Memory 1 Vector \ncopy 0.22s <2 MB 2 Map copy 0.33s <2 MB 3 Reverse mapping 0.14s <2 MB 4 Example from Introduction 0.22s \n<4 MB 5 Set containing map keys 0.62s <2 MB 6 Map of lists 0.21s <2 MB 7 Vector of sets 0.11s <2 MB 8 \nMultimap 0.33s <2 MB 9 Stack-queue relationship 0.19s <2 MB 10 Singleton pattern correctness 0.23s <5 \nMB 11 Prove map values non-null 0.30s <2 MB 12 Prove non-aliasing between vector elements 0.31s <2 MB \n13 List containing key,value pairs of a map 1.14s <2 MB 14 Set containing map keys with non-null values \n0.44s <2 MB 15 Relationship between keys and values in map 0.31s <2 MB Figure 8. Experimental Results \nof the Case Study element in the queue. Program 10 emulates the singleton pattern through a get shared \nmethod that uniqui.es objects that are the same according to their custom equality predicate by using \na set, and asserts the correctness of get shared. Program 11 asserts that the values in a map are non-null, \nand Program 12 asserts that there is no aliasing between elements in a vector. Program 13 builds a list \ncontaining (key, value) pairs in a map and asserts that the list contains exactly the key, value pairs \nin the map. Program 14 builds a set containing all map keys with non-null values and asserts that the \nset contains exactly the keys with non-null values. Program 15 asserts various properties about the relationship \nbetween keys and values in a map. Compass is able to fully automatically verify all of these examples, \nwhile reporting errors in slightly modi.ed, buggy versions of these programs. As shown in Figure 8, the \nrunning times for most of these examples are under a second and maximum memory consumption is consistently \nbelow 4 MB. We believe these examples illustrate that Compass can automatically verify interest\u00ading properties \nabout the functional correctness of client programs using containers and their nestings. 6.2 Proving \nMemory Safety Properties In a second set of experiments, we investigate the added ben\u00ade.ts of precise \nreasoning about container contents when check\u00ading for memory safety properties in real C++ applications. \nUsing Compass, we analyzed three applications ranging from 16,030 to 128,318 lines of C++ code: The .rst \napplication is LiteSQL [11], which integrates C++ objects tightly with a database. The second application \nwe analyzed is the widget library of the vector graph\u00adics program, Inkscape (which was used for the drawings \nin this submission) [12]. We chose this component of Inkscape because it illustrates how more complex \nabstract data types are implemented using standard containers as building blocks. The third application \nis Digikam, a stand-alone, fairly large, open-source photo manage\u00adment program [13]. Both LiteSQL and \nthe Inkscape widget library use the C++ stan\u00addard template library (STL), while Digikam uses container \nlibraries of the QT framework [14]. Fortunately, since the containers in QT are interface-compatible \nwith the ones in the STL, we were able to use the same set of container interface annotations for all \nthree applications. As typical of many programs written in an object\u00adoriented style, all of these applications \nmake heavy use of contain\u00aders, such as vectors, lists, maps, and their combinations. To demonstrate the \nimportance of precise, per-element reason\u00ading about containers when checking for memory safety properties, \nwe analyzed these applications in two different con.gurations: In the .rst con.guration, we use the technique \ndescribed in this paper, while in the second con.guration, we track which set of elements a LiteSQL 0.3.8 \nNumber of lines 16,030 Our technique Containers as sets Running time 1 CPU 4.5 min 5.8 min Running time \n8 CPUs 1.6 min 1.6 min Maximum Memory 1.3 GB 1.5 GB Null Dereference Errors Actual errors False positives \n2 2 2 68 Memory Leak Errors Actual errors False positives 3 0 3 7 Access to Deleted Memory Actual errors \nFalse positives 0 0 0 4 Total FP to error ratio 0.75 15.8 Inkscape 0.47 Widget Library Number of lines \n37,211 Our technique Containers as sets Running time 1 CPU 7.2 min 6.1 min Running time 8 CPUs 2.3 min \n2.1 min Maximum Memory 1.9 GB 1.8 GB Null Dereference Errors Actual errors False positives 1 0 1 24 Memory \nLeak Errors Actual errors False positives 1 1 1 18 Access to Deleted Memory Actual errors False positives \n2 2 2 22 Total FP to error ratio 0.75 16 Digikam 1.2.0 Number of lines 128,318 Our technique Containers \nas sets Running time 1 CPU 45.1 min 44.3 min Running time 8 CPUs 8.7 min 10.3 min Maximum Memory 12.0 \nGB 10.6 GB Null Dereference Errors Actual errors False positives 17 8 17 220 Memory Leak Errors Actual \nerrors False positives 8 1 8 45 Access to Deleted Memory Actual errors False positives 3 0 3 6 Total \nFP to error ratio 0.32 9.68 Figure 9. Proving memory safety properties container may store, but we do \nnot reason about the relationship be\u00adtween positions and values for position-dependent containers, and \nwe do not track the key-value relationships for value-dependent containers (i.e., we smash containers \ninto a set of values). Figure 9 summarizes the results of our experiments. For each of the three applications, \nwe check the following memory safety properties: Null pointer dereferences, memory leaks (i.e., lack \nof unreachable memory), and accessing deleted memory. All of our experiments were performend on an 8-core \n2.66 GHz Xeon work\u00adstation with 24GB of memory. In Figure 9, we provide the running times of the analyses \nboth on a single core as well as on all eight cores. Since the analysis is summary-based, many functions \ncan be analyzed in parallel to yield much better running times, ranging from 1.6 to 8.7 minutes on eight \ncores. In Figure 9, observe that the technique presented in this paper improves the precision of the \nanalysis over the second con.gura\u00adtion which treats the container s contents as a set, in many cases \nby an order of magnitude. For example, the total false positive to error ratio for Digikam is 0.32 if \nthe technique presented in this pa\u00adper is used for the analysis, while this ratio increases to 9.68 with \nthe second analysis con.guration. This statistic means that there are roughly three actual error reports \nper false positive using our technique, while there is less than one actual error per nine false positives \nusing the second, less precise con.guration. We believe that this dramatic reduction in false positives \nillustrates the useful\u00adness of our technique for analyzing real-world C++ applications.  Also, observe \nin Figure 9 that there are no signi.cant differences in running time and memory consumption between the \ntwo analysis con.gurations. We believe that the statistics provided in Figure 9 illustrate that our technique \nadds useful precision without incurring signi.cant extra computational resources. 7. Related Work In \nthis work, we share the goal of separating the veri.cation of data structure implementations from the \nveri.cation of their client-side use with the Hob veri.cation framework [15 17]. Hob s main fo\u00adcus is \nto verify that the implementation of a data structure obeys its speci.cation; on the client-side, Hob \ncan be used to check that cus\u00adtom data structure invariants are obeyed by the client, such as the requirement \nthat the data structure has no content before a certain method is called. While Hob addresses a more \ngeneral class of ab\u00adstract data structures than containers, the client-side abstraction of Hobis a set \nabstraction of data structures, which is less precise than the abstraction we consider. For instance, \nHob s client-side reason\u00ading about a map does not track the relationship between keys and values in a \nmap or between positions and elements in a vector [17]. In contrast, we only consider the client-side \nuse of a special, yet fundamental, class of data structures, and our focus is a fully auto\u00admatic technique \nto improve analysis precision when analyzing real C++ programs that use containers. Another work that \naddresses the client-side use of data struc\u00adtures is [18], which focuses on verifying that the client \nof a soft\u00adware component obeys the requirements of that component, such as the requirement that a data \nstructure d is not modi.ed during an iteration over d. Another work with a similar focus is [19], which \nuses predicate abstraction to verify that clients of the C++ standard template library (STL) obey the \nrequirements for correct use of this library. Yet another work that is focused on usage of STL data struc\u00adtures \nis [20], which is an unsound bug .nding tool for discovering incorrect usage of STL primitives. None \nof these efforts consider properties which require reasoning about the contents of containers, which \nis our focus. We believe that the problem of understanding container contents and the problem of verifying \nthe correct usage of an ADT interface are orthogonal and complementary. The idea of using numeric constraints \nto specify elements of un\u00adbounded data structures goes back to [21], which uses this idea for tracking \nmay-alias pairs in lists. In our previous work on analysis of array contents, we use the combination \nof indexed locations and bracketing constraints to model arrays [1]. While this paper also uses some \nof the same underlying technical machinery as in [1], the contributions of this work include a formalization \nof the differ\u00adences and similarities between different kinds of containers, and a precise and uniform \nanalysis framework that both leverages what is the same and expresses what is different about containers. \nIn this paper, we observe that a key requirement for precise rea\u00adsoning about nested containers is to \ndifferentiate between contain\u00aders allocated in different loop iterations. The necessity to distin\u00adguish \nallocations arising from the same expression also arises in other contexts, such as static race detection \nin [22]. The technique described in [22] also uses a vector of loop counters to distinguish between distinct \nallocations. The work described in [23] addresses the typestate veri.cation problem for real-world Java \nprograms, which make heavy use of containers. This work also reports on the challenge of achieving suf.cient \nprecision as objects .ow in and out of containers; they utilize techniques such as focus and blur, developed \nby the shape analysis community based on 3-valued logic [24]. In contrast, our approach never performs \nexplicit case splits on abstract containers and instead uses constraints to both specify different elements \nin the container as well as to perform updates on individual elements. In this paper, we observe that \ndifferences among various position\u00addependent containers and different value-dependent containers are \ninsigni.cant for developing a methodology for reasoning about their contents, although these differences \nmay have signi.cant per\u00adformance implications. This paper does not address the problem of selecting ef.cient \ncontainers (which is considered in [25]) or estimating their computational complexity (addressed in [26]). \n8. Conclusion In this paper, we have presented a precise, scalable, and fully au\u00adtomatic technique for \nreasoning about contents of containers. We have demonstrated experimentally that precise client-side \nreason\u00ading about containers is important for successful veri.cation of memory safety properties in real \nC++ programs. 9. Acknowledgments We would like to thank Roy Frostig for his help with extending our front-end \nfor the C language to C++. References [1] Dillig, I., Dillig, T., Aiken, A.: Fluid Updates: Beyond Strong \nvs. Weak Updates. In: ESOP. (2010) [2] Gulwani, S., Musuvathi, M.: Cover Algorithms. In: ESOP. (2008) \n193 207 [3] Cousot, P., Halbwachs, N.: Automatic Discovery of Linear Restraints among Variables of a \nProgram. In: POPL, ACM (1978) 84 96 [4] Karr, M.: Af.ne relationships among variables of a program. A.I. \n(1976) 133 151 [5] Kovacs, L., Voronkov, A.: Finding loop invariants for programs over arrays using a \ntheorem prover. In: FASE 2009. (2009) 470 485 [6] Dillig, I., Dillig, T., Aiken, A.: SAIL: Static Analysis \nIntermediate Language. Stanford University Technical Report [7] Dillig, I., Dillig, T., Aiken, A.: Cuts \nfrom Proofs: A Complete and Practical Technique for Solving Linear Inequalities over Integers. In: CAV. \n(2009) [8] Dillig, I., Dillig, T., Aiken, A.: Small Formulas for Large Programs: On-line Constraint Simpli.cation \nin Scalable Static Analysis. In: SAS. (2010) [9] Dillig, I., Dillig, T., Aiken, A.: Sound, Complete and \nScalable Path\u00adsensitive Analysis. In: PLDI. (2008) 270 280 [10] http://www.sgi.com/tech/stl/: C++ standard \ntemplate library [11] http://sourceforge.net/apps/trac/litesql/: LiteSQL [12] http://www.inkscape.org/: \nInkscape [13] http://www.digikam.org/: Digikam [14] http://qt.nokia.com/products/: QT Framework [15] \nLam, P., Kuncak, V., Rinard, M.: Hob: A tool for verifying data structure consistency. In: Compiler Construction. \n237 241 [16] Lam, P., Kuncak, V., Rinard, M.: Generalized Typestate Checking for Data Structure Consistency. \nIn: VMCAI. (2005) 430 447 [17] Kuncak, V., Lam, P., Zee, K., Rinard, M.: Modular Pluggable Anal\u00adyses \nfor Data Structure Consistency. IEEE Transactions on Software Engineering 32(12) (2006) 988 1005  [18] \nRamalingam, G., Warshavsky, A., Field, J., Goyal, D., Sagiv, M.: Deriving Specialized Program Analyses \nfor Certifying Component\u00adclient Conformance. In: PLDI. (2002) 94 [19] Blanc, N., Groce, A., Kroening, \nD.: Verifying C++ with STL Con\u00adtainers via Predicate Abstraction. In: IEEE/ACM Conference on Au\u00adtomated \nsoftware engineering, ACM (2007) 521 524 [20] Gregor, D., Schupp, S.: STLlint: lifting static checking \nfrom languages to libraries. Software Practice and Experience 36(3) (2006) 225 [21] Deutsch, A.: Interprocedural \nmay-alias analysis for pointers: Beyond k-limiting. In: PLDI, ACM NY, USA (1994) 230 241 [22] Naik, M., \nAiken, A.: Conditional Must not Aliasing for Static Race Detection. In: POPL. (2007) 338 [23] Fink, S., \nYahav, E., Dor, N., Ramalingam, G., Geay, E.: Effective Typestate Veri.cation in the Presence of Aliasing. \nTOSEM 17(2) (2008) 1 34 [24] Reps, T.W., Sagiv, S., Wilhelm, R.: Static Program Analysis via 3-Valued \nLogic. In: CAV. (2004) 15 30 [25] Shacham, O., Vechev, M., Yahav, E.: Chameleon: Adaptive Selection of \nCollections. In: PLDI, ACM (2009) 408 418 [26] Gulwani, S., Mehra, K.K., Chilimbi, T.: Speed: Precise \nand ef.cient static estimation of program computational complexity. In: POPL. (2009) 127 139 [27] Gulwani, \nS., McCloskey, B., Tiwari, A.: Lifting abstract interpreters to quanti.ed logical domains. In: POPL, \nACM (2008) 235 246 Appendix: Proof of Soundness In this section, we sketch the proof of soundness of \nthe key rules from Section 3.3. The proof is a standard induction on the inference rules from Figures \n5, 6, and 7. We only focus on the rules that involve containers. A.1 Preliminaries We .rst introduce \nsome notation that is convenient to use in the proofs and state some assumptions. DEFINITION 9. (s(.)) \nLet . be an abstract value set, and let s be an assignment to (at least) the index variables in .. Then: \ns(.)= {(pj ,s(fj ) | (pj ,fj ) . . . SAT(s(fj )} DEFINITION 10. (Ifl, LfJ) Let f be the bracketing constraint \n(.may,.must). Then, Ifl = .may and LfJ = .must. Throughout the proof, we assume that every abstract value \np that can arise for a given program is present in every abstract value set .; for values that have not \nbeen explicitly added to ., we assume (p, false) . .. A.2 Proof of Key Rules We .rst consider the read \nrule for position-dependent containers: Let (lc,k) denote the concrete location that the read is per\u00adformed \non (i.e, the result is obtained from S(lc,k)). Let a(lc,k)= (d, sc), and let a(S(lc,k)) = (p, sp). In \nthe rule, suppose: .1 = {..., ((a)ij ,fj ),...}.2 = {..., (pk,fk),...}S((a)ij )= {..., (plj ,flj ),...} \nBy the assumption that the abstraction is correct before the read (i.e., E, S, C ~ E, S, C), we have: \n((a)ij = d) . sc(Ifj l)= true ((a)ij = d) . sc(Lfj J)= false pk = k .Ifkl = true (*)pk = k .LfkJ = false \nplj = p . sp(sc(Iflj l)) = true plj = p . sp(sc(Lflj J)) = false The resulting abstract value set . is \ncomputed by the rule as: . = S((a)ij ) N ( ((ij = pk) . fk) . fj ) Now, assume, for contradiction, that \nS(lc,k) ~ .. Then, either (i) (p, (true, *)) . sp(.), or (ii) .p ' = p. (p ' , (*, true)) . sp(.). Assume \n(i). By (*), for d = (a)ij and pk = k, we have sc(Ifj l)= true and Ifkl = true; thus, . = S((a)ij ) N \n((ij = k . fj ), *) By correctness of the abstraction before the read, we have: (p, (.may,.must)) . S((a)ij \n) Furthermore since sp(sc(.may)) = true by (*) and since sc must assign ij to k and sc(fj )= true, sp(sc(.may \n. (ij = k) . fj )) = true Hence, assumption (i) is not possible. Now, assume (ii). First, observe that \nif (a)ij = d and pk = k, then, from the last identity in (*), it follows that (ii) cannot hold. Now, \nif (a)ij = d, then sc(Lfj J)= false, and .(p ' ,f ' ). . = sc(S((a)ij ) N ( ((ij = pk).fk).fj )), we \nhave Lf 'J = false. Now, if pk = k, we know from (*) that LfkJ = false, hence (ii) is again not possible. \nAn almost identical argument also applies to value-dependent containers; the only difference is that \nsc now assigns ij to pos(k) and . is computed as: . = S((a)ij ) N ( ((ij = pos(pk) . fk) . fj ) Now, \nwe consider a write v1.write(v2,v3) to position-dependent container v1. Let (l, k) denote the concrete \nmemory location that is modi.ed, and let v denote the concrete value that is written. From the operational \nsemantics, we have: ' v if i = k S (l, i) = (1) S(l, i) otherwise Let: a(l, i)=(d, si) a(k)=(k, true) \na(v)=(pv * ,s v * ) a(S(l, i)) = (pei ,sei ) In the write rule from Figure 6, let: .1 = {..., ((a)ij \n,fj ),...}.2 = {..., (pk,fk),...}.3 = {..., (pv,fv),...}S((a)ij )= {..., (plj ,flj ),...} By the assumption \nthat the abstraction is correct before the write (i.e., E, S, C ~ E, S, C), we know: (pk = k) .Ifkl = \ntrue (pk = k) .LfkJ = false (pv = pv * ) . sv * (Ifvl)= true (pv = pv * ) . sv * (LfvJ)= false (*)(d \n= (a)ij ) . si(Ifj l)= true (d = (a)ij ) . si(Lfj J)= false plj = pei . sei (si(Ifljl)) = true plj = \npei . sei (si(Lflj J)) = false In the write rule, for each (a)ij , the new entry in new abstract store \nS ' is computed as: S' ((a)ij )= S[(a)ij . (.3 . (.2.ij ) . fj ) . S((a)ij ) . (\u00ac(.2.ij ) .\u00acfj )] (**) \n where . . f is shorthand for conjoining f with every constraint in ., as described in Section 3.3. \nAssume that the write rule is not sound. Then, using (1), either: (i) v ~ (S ' (d) Nsi[k/i]) or (ii) \nS(l, i) ~ (S ' (d) Nsi) for i = k  We .rst consider (i). Suppose v ~ (S ' (d) Nsi[k/i]). Then, there \nare two possibilities: 1a. (pv * , (true, *)) . sv * (S' (d) Nsi[k/i]) 1b. .pv ' = pv * . (pv' , (*, \ntrue)) . sv * (S ' (d) Nsi[k/i]) Now, assume 1a and consider evaluating sv * (S ' (d) Nsi[k/i]). Under \nsv *, we know from (*) that in (**), sv * (.2) contains the pair (pv * , (true, *)). Observe that si[k/i] \nmust assign ij to k. Hence, by using (*), we know that the constraint .2.ij = ((ij = pk) . fk)(***) evaluates \nto (true, *) under assignment si[k/i]. Furthermore, under assignment si[k/i], (*) implies that Ifj l \nis true; hence it follows that (pv * , (true, *)) . sv * (S ' (d) Nsi[k/i]), contradicting assump\u00adtion \n1a. Now assume 1b. Under assignment sv *, we know from (*) that for any (pv' ,f ' v) . .2 such that pv \n' = pv * , Lf ' vJ is false. Since con\u00adjoining additional constraints cannot weaken false, it follows \nthat .pv ' = pv * . (pv' , (*, false)) . sv * (S ' (d) Nsi[k/i]), contradicting assumption 1b. We know \nconsider (ii), i.e., S(l, i) ~ (S ' (d) Nsi) for some i such that i = k. This corresponds to the case \nwhere the abstract semantics for write overwrites the existing value of the wrong key. Again, there are \ntwo possibilities: 2a. (pei , (true, *)) . sei (S' (d) Nsi) 2b. .pei = pei . (pei , (*, true)) . sei \n(S ' (d) Nsi) i Now, assume 2a. From (*), we know that under assignment sei , (pei , (true, *)). Now, \nby (**), we need to show that conjoining the constraint (\u00ac(.2.ij ) .\u00acfj ) cannot strengthen true. Observe \nthat si assigns ij to i where i = k, and observe that pk = i . si(LfkJ)= false; hence the suf.cient condition \nfor .2.ij is false. Thus, I\u00ac(.2.ij )l = true, which implies (pei , (true, *)) . sei (S ' (d) Nsi), contradicting \n2a. Finally, assume 2b. Under assignment sei , we know from (*) that for any (plj ,flj ) . S((a)ij ) \nsuch that plj = pei , Lflj J is false. Since conjoining additional constraints cannot weaken false, assumption \n2b is also infeasible. The proof for value-dependent containers is almost identical. The only differences \nare that si now assigns ij to pos(i) according to the de.nition of the abstraction function, and S ' \nis computed as: S ' ((a)ij )= S[(a)ij . (.3 . (.2.ij ) . fj ) . S((a)ij ) . (\u00ac(.2.ij ) .\u00acfj )] We now \nconsider the foreach rule. Since the .x rule stipulates that S* is a correct invariant without giving \na constructive algo\u00adrithm, we only argue about the loop initialization, i.e., (key, value) pairs bound \nin the foreach rule of the abstract semantics correctly model the concrete execution. We focus on value-dependent \ncon\u00adtainers. Let keyk be the concrete key visited during the k th loop iteration such that a(keyk)=(keyk,sk) \nwhere sk gives interpre\u00adtation to function symbols pos.. In the abstract semantics, the value set .key \nduring the k th iteration is given by .key = {..., (pk,k = pos .(pk)),...} Suppose keyk ~ .key. Then, \neither (keyk, (true, *)) . sk(.key) or .pk = keyk. (pk, (*, true)) . sk(.key) But, under interpretation \nsk, we have: pk = keyk . sk(pos.)= k pk = keyk . sk(pos.)= k Hence, keyk ~ .key.    \n\t\t\t", "proc_id": "1926385", "abstract": "<p>Containers are general-purpose data structures that provide functionality for inserting, reading, removing, and iterating over elements. Since many applications written in modern programming languages, such as C++ and Java, use containers as standard building blocks, precise analysis of many programs requires a fairly sophisticated understanding of container contents. In this paper, we present a sound, precise, and fully automatic technique for static reasoning about contents of containers. We show that the proposed technique adds useful precision for verifying real C++ applications and that it scales to applications with over 100,000 lines of code.</p>", "authors": [{"name": "Isil Dillig", "author_profile_id": "81331491247", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P2509595", "email_address": "isil@cs.stanford.edu", "orcid_id": ""}, {"name": "Thomas Dillig", "author_profile_id": "81331491149", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P2509596", "email_address": "tdillig@cs.stanford.edu", "orcid_id": ""}, {"name": "Alex Aiken", "author_profile_id": "81100399954", "affiliation": "Stanford University, Stanford, CA, USA", "person_id": "P2509597", "email_address": "aiken@cs.stanford.edu", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926407", "year": "2011", "article_id": "1926407", "conference": "POPL", "title": "Precise reasoning for programs using containers", "url": "http://dl.acm.org/citation.cfm?id=1926407"}