{"article_publication_date": "01-26-2011", "fulltext": "\n On Interference Abstractions Nishant Sinha NEC Laboratories America nishants@nec-labs.com Abstract \nInterference is the bane of both concurrent programming and anal\u00adysis. To avoid considering all possible \ninterferences between con\u00adcurrent threads, most automated static analysis employ techniques to approximate \ninterference, e.g., by restricting the thread sched\u00aduler choices or by approximating the transition relations \nor reach\u00adable states of the program. However, none of these methods are able to reason about interference \ndirectly. In this paper, we intro\u00adduce the notion of interference abstractions (IAs), based on the models \nof shared memory consistency, to reason about interference ef.ciently. IAs differ from the known abstractions \nfor concurrent programs and cannot be directly modeled by these abstractions. Concurrency bugs typically \ninvolve a small number of unexpected interferences and therefore can be captured by small IAs. We show \nhow IAs, in the form of both over-and under-approximations of interference, can be obtained syntactically \nfrom the axioms of se\u00adquential consistency. Further, we present an automatic method to synthesize IAs \nsuitable for checking safety properties. Our exper\u00adimental results show that small IAs are often suf.cient \nto check properties in realistic applications, and drastically improve the scal\u00adability of concurrent \nprogram analysis in these applications. Categories, Subject Descriptors: D.2.4 [Software/Program Veri\u00ad.cation]: \nModel Checking, Formal Methods. General Terms: Algorithms, Veri.cation.  1. Introduction Analyzing shared \nmemory concurrent programs is dif.cult due to the fact that constituent program threads may interfere \nwith each other via shared variables. Multiple formalisms have been devel\u00adoped to model and reason about \ninterference, e.g., the Mazurkiewicz traces [1] model the program behaviors as a partial order over events \nwhile the context-switching model utilizes a scheduler to generate all possible thread interleavings. \nBecause analyzing all possible interferences is intractable in practice, these models em\u00adploy reduction \ntechniques to focus on a subset of interferences, e.g., partial-order reduction [2 6] or context-bounding \n[7 9]. In this paper, we develop a new formalism based on mem\u00adory consistency models [10] for analyzing \nshared memory concur\u00adrent programs ef.ciently. A memory consistency (MC) model pre\u00adscribes rules on when \na read to a shared location may observe some write to the same location, and hence determines the set \nof feasible executions of a concurrent program. Concurrent program analysis Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 11, January 26 28, 2011, Austin, Texas, \nUSA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 Chao Wang NEC Laboratories America \n chaowang@nec-labs.com based on MC models has received considerable attention recently, both for the \nrelaxed MC models which allow instruction reorder\u00adings [11, 12] by the compiler or hardware, as well \nas for high-level static analysis [13]. Using a MC model is particularly attractive be\u00adcause it allows \nus to reason about correlations between reads and writes of program threads directly, inside a reasoning \nframework for partially-ordered events, similar to Mazurkiewicz traces. In this work, we focus on the \nwell-known MC model of sequen\u00adtial consistency (SC) [10, 14], which is both intuitive as well as simpler \nto analyze. The SC model prescribes the following rules (more formally, axioms in .rst-order logic) of \ninterference for cor\u00adrect program executions: (i) each read must observe some write to the same shared \nlocation (interfering write), and (ii) a read may only observe the last such write in the causal order. \nNote, however, that enforcing these rules for all reads and corresponding interfer\u00ading writes in a program, \nagain leads to an intractable analysis. To obtain a scalable analysis, we introduce interference abstrac\u00adtion \n(IA), a new concurrency abstraction to reason about thread interference using the memory consistency \nmodels. One way to obtain an IA is by weakening the SC rules, e.g., by permitting a read to not observe \nany interfering write. In other words, we allow program executions where the read may obtain any value \nindepen\u00addent of the values of the interfering writes. This form of weaken\u00ading leads to an over-approximation \nof interference (denoted as an OIA). Alternatively, we may strengthen the SC rules, e.g., by forc\u00ading \na read to observe only a subset of all possible interfering writes. Consequently, executions where the \nread may observe writes out\u00adside the subset are ruled out. Such strengthening leads to an under\u00adapproximation \nof interference (denoted as an UIA). Employing ei\u00adther of these approximations (obtained by weakening \nor strengthen\u00ading the SC rules) makes analysis more tractable. Intuitively, an IA enforces fewer dependency \nrelationships among reads and writes than ordained by the SC rules. Many concurrent safety errors, e.g., \ndata races, deadlocks and atomicity violations, typically occur due to a small amount of unexpected interference \nbetween threads [15]. This fact is captured formally by IAs, i.e., there often exist small IAs suf.cient \nto detect these errors. We present a formal framework to characterize IAs in an uni\u00adform manner by exploiting \nthe axiomatic formulation of SC rules. More precisely, we show how to obtain a wide variety of IAs in \na syntactic manner by selectively instantiating the SC axioms. The framework models not only OIA s and \nUIA s but also mixed IAs (MIA s) containing both over-and under-approximations of inter\u00adference, in a \nseamless manner. Further, we show how several in\u00adformal notions of concurrency abstractions for checking \nproperties can be formally captured in the uniform framework of IAs. Given our uni.ed framework of IAs, \nthe key problem is to synthesize IAs suitable for checking a property. To this goal, we present an iterative \nre.nement scheme which starts from a coarse IA and gradually re.nes it in a property-driven manner. Most \ntradi\u00adtional abstraction/re.nement schemes (e.g. [4, 16 19]) work with either over-or under-approximations \nto obtain proofs or witnesses respectively. In contrast, our algorithm works directly on a mixed approximation, \ni.e., mixed IAs, and iteratively steers the mixed IA to an OIA (if a proof exists) or an UIA (if a witness \nexists). We implemented our approach in the FUSION platform, which is a collection of tools for concurrent \nprogram veri.cation (e.g. [13, 20 23]). We evaluated the effectiveness of IAs for checking embed\u00added \nassertions and data races on medium sized programs. Our re\u00adsults show that small IAs are suf.cient to \ndecide many of the prop\u00aderties, and our iterative re.nement procedure enables drastically improved analysis \nof these benchmarks. Further, we have been able to check larger benchmarks that were intractable without \nusing IAs. To sum up, this paper makes the following contributions: We introduce the notion of interference \nabstraction to rea\u00adson about interferences based on memory consistency models. These IAs may over-or \nunder-approximate the thread interfer\u00adence, or represent their combination. (Sec. 5). We show that these \nIAs formally capture common concurrency bug patterns and as well as correctness proofs (Sec. 5.3).  \nWe present a uni.ed framework for obtaining these IAs from the axioms of sequential consistency [10, \n14] (Sec. 4, 5). The framework of IAs provides a .exible mechanism for approx\u00adimating interference among \nreads and writes, guided by the memory consistency axioms.  We formalize the set of IAs as a complete \nlattice and present an iterative approach to synthesize IAs for checking proper\u00adties based on a symbiotic \ncombination of over-and under\u00adapproximate IAs (Sec. 6). A set of focusing heuristics are also presented \nto make the iterative algorithm practical.   2. Preliminaries We start with formalizing concurrent \nprograms. 2.1 Concurrent Programs A concurrent program consists of a .nite set of threads T0,...,Tk \ncommunicating via a set SV of shared variables. Each thread Ti has a set of local variables LV i and \nis represented by a control .ow graph (de.ned below). Threads are allowed to fork other threads in a \nbounded manner, i.e., the total number of threads is .nite. Let T0 denote the main thread and Vi = SV \n. LV i denote the set of variables accessible to thread Ti. We represent a concurrent program using a \nconcurrent con\u00adtrol .ow graph (CCFG), which may be viewed as an extension of control .ow graphs (CFGs) \nfor sequential programs. A CCFG C=(N, E) consists of a set of nodes N and a set of edges E.We use two \nspecial types of nodes fork and join to model thread creation and thread join respectively. A program \nthread Ti corre\u00adsponds to a sub-graph (Ni,Ei) of the CCFG, where Ni consists of nodes representing program \nlocations in thread Ti and Ei con\u00adsists of edges representing the program statements. Assume that Ni \ncontains unique entry and exit nodes of Ti. For each Ti (i =0)the entry node has a single incoming edge \nfrom a fork node and the exit node has a single outgoing edge to a join node. Each edge in Ei is labeled \nby one of the following actions: guarded assignment (assume(c),asgn),where c is a condition over Vi,and \nasgn = {w := exp} is a set of parallel assign\u00adments, where w . Vi and exp is an expression over Vi. Intu\u00aditively, \nthe assignments proceed iff condition c is true.  fork(j),where 0 <j = k and j i, starts the execution \nof  = child thread Tj . join(j),where 0 <j = k and j = i, waits for child thread Tj to terminate. \n assert(c),where c is a condition over Vi, asserts c.  Thread T0 Thread T1 Thread T2 int x = 0; foo() \n{ bar() { int y = 0; int a; int b; pthread tt1, t2; t11 a=y; t21 b=x; main() { t12 if (a==0) { t22 if \n(b==1) { t1 pthread create(&#38;t1,0,foo,0); t13 x=1; t23 y=1; t2 pthread create(&#38;t2,0,bar,0); t14 \na=x+1; t24 b=y+1; t3 pthread join(t2,0); t15 x=a; t25 y=b; t4 pthread join(t1,0); t16 }else t26 }else \nt5 assert( x != y); t17 x=0; t27 y=0; } t18 } t28 } Figure 1. A multi-threaded C program with an assertion. \n By de.ning expressions suitably and using code transformations, the above formulation can model all \nstatements in standard pro\u00adgramming languages like Java and multi-threaded C. The details on modeling \ngeneric language constructs such as pointers and struc\u00adtures are omitted since they are not directly \nrelated to concurrency. For more information on language modeling, please refer to recent efforts including \n[24 26]. The guarded assignment action (assume(c),asgn) may have the following variants: (1) when c = \ntrue, it represents normal assignments; (2) when the set asgn is empty, assume(c) itself can represent \nthe then-branch of an if(c)-then-else statement, while assume(\u00acc) can represent the else-branch; and \n(3) with both guard and assignments, it represents an atomic check-and-set, which can be used as the \nfoundation of all kinds of synchroniza\u00adtion primitives. For example, acquiring the lock lk in thread \nTi is modeled as (assume(lk = .), {lk := i}) and releasing the lock is modeled as (assume(lk = i){lk \n:= .}). Herethevalueof lk indicates the lock owner s thread index (. means the lock is free). Similarly, \nacquiring the counting semaphore se is modeled as (assume(se > 0), {se := se - 1}). 2.2 Bounded Concurrent \nPrograms Static analysis of concurrent programs with loops and/or recursion is known to be undecidable \neven with .nite data. Our goal, how\u00adever, is to analyze real-life programs where data structures are \npre\u00adcisely modeled. We, therefore, focus on analyzing bounded con\u00adcurrent programs, whose analysis is \ndecidable. Intuitively, a struc\u00adturally bounded program is obtained by .nitely unwinding the loops and \nrecursion in an arbitrary real-life concurrent program. Bounded programs are also obtained in the context \nof symbolic predictive analysis (e.g., [21, 22]), by generalizing from the se\u00adquence of program statements \nexecuted in a particular trace. This form of bounding .nitizes the number of program threads and the \nheap. Further, if the underlying program theory is decidable, then the analysis becomes decidable. A \nbounded program under\u00adapproximates the sets of paths of the original program and hence the violations \nfound by the analysis are real. However, the proofs (absence of violations) found may not generalize \nto the original program. We represent bounded programs using CCFGs. For ease of presentation, we assume \nthat all function calls in the program have been inlined. However, the presented technique can be directly \nextended to handle function calls modularly [13]. Example. Fig. 1 shows an example of a multi-threaded \nC program with two shared variables x and y. The main thread T0 creates threads T1 and T2, which in turn \nexecute functions foo and bar, respectively. Thread T0 waits for T1,T2 to terminate and join back, before \nasserting (x = y).Here pthread  create and pthread join are routines in PThreads library, directly corresponding \nto fork/join in our model. (Since this particular example does not have loops and recursion, the bounded \nand the original programs are same.) The assertion at t5 de.nes the correctness property, which holds \nin some, but not in all, execution traces of the program. In particular, the execution trace . =(t1t2)({t11 \nt15}t18)(t21t26t27t28){t3 t5} does not violate the assertion (x =2,y =0 at t5), whereas the execution \ntrace .' =(t1t2)({t11 -t14})(t21 - t25t28)(t15t18){t3 \u00adt5} violates the assertion (x =2,y =2 at t5). \n 2.3 Gated Single Static Assignment Recall that a sequential program can be encoded in a standard manner \nusing the gated single static assignment (GSA) form [27], which combines the classic single static assignment \n(SSA) form (each variable is de.ned exactly once) with conditions under which a particular de.nition \nof a variable may reach a join node. For example, consider the following C code: l1 : if (c1) { z=1; \n} // z1 l2 : elsez=2; // z2 l3 : y=z+3; // y1 The SSA form renames the writes to z at l1 and l2 in terms \nof new de.nitions of z1 and z2, respectively. The use of z in l3 is then rewritten using the f function \nas f(z1,z2), which, by de.nition, may evaluate to either z1 or z2. Consequently, l3 is rewritten as y1 \n= f(z1,z2)+3,where y1 is a fresh de.nition of y. Note that the f operator does not contain information \nabout the conditions under which de.nition z1 or z2 may be chosen, and therefore cannot be used for precise \nencoding of the bounded program. The GSA representation solves the problem by replacing f(z1,z2) with \nite(c1,z1,z2) where ite stands for the if-then-else operator. That is, y1 = z1 +3 when condition c1 is \ntrue; otherwise y1 = z2 +3.  3. Symbolic Analysis of Bounded Programs We say that two memory accesses \ni nterfere if both access the same memory location and at least one of them is a write. To avoid worrying \nabout whether the accesses are concurrent or not, we use the term interference in a generic manner, both \nfor access pairs occurring in the same thread or occurring concurrently. In order to check properties \nof a bounded CCFG C, we encode it as a .rst-order logic formula in a step-wise manner. First the pro\u00adgram \nstatements in C are encoded in an interference-modular man\u00adner by ignoring the interference between all \nreads and writes (de\u00adnoted FC ). The read-write interference in C is then encoded using sequential consistency \naxioms (denoted .), which corresponds to composing the program threads. The property, e.g., existence \nof an assertion violation, data race, or atomicity violation, is encoded as aformula FPRP . The combined \nformula F:=FC . . . FPRP is then checked for satis.ability using an off-the-shelf constraint solver, \ne.g., an SMT solver [28, 29]. The formula F is satis.able iff there exists an execution of the program \nthat violates the property. 3.1 Interference-Modular Encoding We show how to encode all the edges of \nthe CCFG C without modeling the interference between the global reads and writes. The encoding in this \nsection is similar to our previous works [13, 21]; we review the main details here. Although the GSA \nform can encode sequential programs (cf. Sec. 2.3), it cannot directly encode a program thread in a concurrent \ncontext. This is due to possibility of interference on shared variables by concurrent threads, i.e., \na read of a shared variable (a global read, in short) must take into account all possible interferences \nfrom concurrent writes. To ignore modeling such interferences, each global read of variable z is assigned \na fresh symbolic value rz (also called a placeholder). Using these fresh values, we can now encode the \nthreads in the CCFG using the standard GSA encoding 1. We say that a program edge is global if it accesses \na shared vari\u00adable; otherwise it is local. Both local and global edges participate in the data .ow inside \na thread; however, only global edges partic\u00adipate in data .ow across the threads. Hence, we encode the \nlocal and global edges separately: this enables us to only consider global edges for encoding the thread \ninterleavings, or more precisely, the interference between threads. Our encoding, denoted by FC , con\u00adsists \nof a local component FL and a global component FG: FC := FL . FG We now discuss how FL and FG are obtained. \n3.1.1 Encoding Local Edges (FL) Given the program in the GSA form together with placeholders for global \nreads, we can encode each program assignment of form w := exp on a local edge as a formula (w = exp). \nThe local encoding FL is obtained by conjoining the formula obtained from local edges. Fig. 2 (left) \nshows the GSA encoding of the running example in Fig. 1. The local variable a is de.ned in t11 and t14.At \nt18 the value of a is either a1 (de.ned in t11)or a2 (de.ned in t14), depending on the condition (a1 \n=0).  3.1.2 Encoding Global Edges(FG) We .rst compute the enabling condition for each edge. Path conditions. \nThe path condition for an edge ti in the CCFG C is denoted by g(ti): ti executes iff g(ti) is satis.able. \nLet tfirst and tlast be the unique .rst and last edge in C respectively. Start\u00ading with g(tfirst):= true, \nthe path conditions are computed iter\u00adatively for each ti via CCFG traversal as follows. We distinguish \nbetween CCFG nodes having multiple predecessors: if the prede\u00adcessors are in the same thread, the node \nis said to be an intra-thread join; otherwise it is an inter-thread join. If the source of ti is an \nintra-thread join node with incoming edges tj and tk,then g(ti)= g(tj) . g(tk).  If the source of ti \nis an inter-thread join node with incoming edges tj and tk,then g(ti)= g(tj) . g(tk).  If ti is a branching \nstatement with condition c and tj precedes ti,then g(ti)= g(tj) . c.  In all other cases, the source \nof ti has a single incoming edge tj and g(ti)= g(tj).  Fig. 2 (center) shows the path conditions in \nthe example CCFG. Global accesses. Each global edge is encoded using the notion of a global access. The \nglobal access a for an edge e is a tu\u00adple (Addr, V al, En),where Addr(a) is the memory location ac\u00adcessed, \nVal(a) is the value read or written, and En(a) is the con\u00addition under which e is enabled. For example, \nedge t11 (cf. Fig. 2) is encoded as an access r11 =(y, ry1,g(t11)). Similarly, edge t15 is encoded as \na global access w15 =(x, a1,g(t15)). The global access a captures all the information about the execution \nof the corresponding global edge e succinctly. Interference Skeleton. Observe that to model all interferences \nin the CCFG C precisely, we not only need the values of global accesses, but also their relative order \nin C.Let c denote the partial order among global accesses induced by the CCFG (called program order). \nFor accesses a1 and a2,if a1 c a2 holds, then a1 must happen before a2 in all program executions. The \nset of global accesses in C,say RW , together with their program order, denoted 1 We will later see that \nintroducing such placeholders is, in fact, an instance of interference abstraction (Sec.5). Interference \nSkeleton: GSA Form: Path Conditions of all Edges: w00 t0 : x0=0 . y0=0[w00, w01] t1 : g(t1)= true w01 \n t2 : g(t2)= g(t1)  12 r11 r 21 t11 : a1 = ry [r11] t21 : b1 = rx [r21] g(t11)= g(t1) g(t21)= g(t2) \nt12 : t22 : g(t12)= g(t11) . (a1 =0) g(t22)= g(t21 . (b1 =1) t13 : x1 =1[w13] t23 : y1 =1[w23] g(t13)= \ng(t12) g(t23)= g(t22)   w13 w23 t14 : a2 = rx 1 +1[r14] t24 : b2 = ry 2 +1[r24] g(t14)= g(t13) g(t24)= \ng(t23) t15 : x2 = a2 [w15] t25 : y2 = b2 [w25] g(t15)= g(t14) g(t25)= g(t24) r14 r24 t16 : t26 : g(t16)= \ng(t11) . (a1 =0) g(t26)= g(t21) . (b1 =1) w27w17 t17 : x3 =0[w17] t27 : y3 =0[w27] g(t17)= g(t16) g(t27)= \ng(t26) t18 : a3 = ite(a1 =0,a1,a2) t28 : b3 = ite(b1=1 ,b1,b2) g(t18)= g(t15) . g(t17) g(t28)= g(t25) \n. g(t27) w15 w25 t3 : g(t3)= g(t2) . g(t28) t4 : g(t4)= g(t3) . g(t18)  33 r50 t5 : assert(rx )[r50, \nr51] g(t5)= g(t4) = ry r51 Figure 2. The symbolic encoding of the bounded program in Fig. 1. The global \nedges are labeled by the corresponding global accesses (e.g., t11 by [r11]). Edges t0 is labeled by write \naccesses on x (w00)and y (w01) respectively. Edge t5 is labeled similarly. (RW, c), is called the interference \nskeleton (IS) of C.Fig.2 (right) shows the IS (as a graph) for the running example: each node corresponds \nto an access a =(Addr, V al, En) modeling the location, value and the enabling condition respectively, \nand the edges model the program order. Note that the IS models all the global accesses and their mutual \nordering precisely. To encode the IS (RW, c) in .rst-order logic, we introduce a new type called Acc, \nand the following operators over the type: a must-happen-before predicate HB over pairs of Acc elements \nand operators addr, val,and en which map an Acc element to its location, value and enabling condition, \nrespectively. Now IS is encoded as FG: FG =FAcc . FPO where FAcc encodes the set of accesses RW , V FAcc \n:= a.RW (addr(a)= Addr(a) . en(a)= En(a). val(a)= Val(a)) and FPO encodes c: ^ FPO := (HB(ai,aj)) (ai,aj \n). We also refer to FPO as program order constraints.  3.2 Encoding Properties Generic programming \nerrors may be modeled as embedded asser\u00adtions in the CCFG. The formula FPRP then captures the condi\u00adtion \nunder which a given assertion is violated. For an assertion assert(c) in transition t, FPRP is de.ned \nas FPRP := g(t) .\u00acc denoting that the condition c must hold if t is executed. In our run\u00ad 123123 ning \nexample in Fig. 2, fresh variables rx ,rx ,rx , ry ,ry ,ry are added to denote the values of the six \nglobal reads, and the prop\u00aderty sub-formula is de.ned as FPRP := g(t5) .\u00ac(rx 3 = ry 3) Besides assertion \nviolations, we can encode standard concur\u00adrency errors such as data races and atomicity violations directly \nas a set of happens-before constraints. Suppose we want to check the three-access atomicity violation \n[30, 31] involving global accesses c, c ' and r,where c and c ' are in the same thread and are intended \nto execute atomically, r is executed in another thread and interferes with both c and c ' . (An example \nof such violation is given later in Fig. 7.) The property formula is de.ned as follows: FPRP := en(c) \n. en(r) . en(c ' ) . HB(c, r) . HB(r, c ' )  4. Axiomatic Composition Given the skeleton IS = (RW, c) \nobtained from the interference\u00admodular encoding of the CCFG C, we can now encode the interfer\u00adence (both \nintra-and inter-thread) using the axioms for sequential consistency (SC) over the set of global accesses \nRW in C. Intu\u00aditively, the SC axioms link the read accesses in RW to appropriate write accesses in RW \nto obtain feasible program executions. The basis of axiomatic composition is the link relation. DEFINITION \n1 (Link Relation). The predicate link(r, w) denotes that the read r observes write w, i.e., the value \nretrieved by the read access r is the same as the value set by the write access w.The link relation is \nexclusive, i.e., link(r, w) ..w ' = w. \u00aclink(r, w ' ). The SC axioms [11, 13, 32], denoted as ., can \nbe modeled in typed .rst order logic using operators HB, addr, val and en and quanti.ed variables r, \nw and w ' over type Acc (cf. Sec. 3.1). The formula .:=.1 . .2 . .3,where .1 := .r. .w. en(r) . (en(w) \n. link(r, w)) .2 := .r. .w. link(r, w) . HB(w, r). (addr(r)= addr(w)) . (val(r)= val(w)) .3 := .r. .w. \n.w ' . (link(r, w) . '' ' ( en(w ) .\u00acHB(w ,w) .\u00acHB(r, w ) . addr(r)= addr(w ' )) Formula .1 models that \nif a read r is enabled, then r must be linked to some enabled write w, and vice versa. Formula .2 models \nthe data .ow and relative order between r and w when r links with w, i.e., both the value and address \nof r and w must be same and w executes before r.Formula .3 says that if r links with w then no other \nwrite w ' to the same address as r should be executed between w and r, i.e., w ' executes either before \nw or after r. Fig. 3 shows the hierarchical encoding of F. When checking properties, the . axioms interact \nsubtly with the property violation condition FPRP : the condition FPRP identi.es well-formed paths in \nthe CCFG that lead to a property violation and enables the reads and writes along those paths; the axioms \n. then make sure that reads and writes along those paths can be appropriately linked to obtain a feasible \nthread interleaving. F FC FPRP .  FL FG .1 .2 .3 Figure 3. Hierarchical Encoding of the CCFG. 4.1 \nFull instantiation of SC axioms Let R and W denote the set of all reads and writes in RW respec\u00adtively. \nGiven R and W, . can be encoded directly by instantiat\u00ading the quanti.ers for all reads in R and writes \nin W. Recall from Sec. 3.1 that the values of addr(a), val(a) and en(a) for each access a are already \nencoded in FG. Additional constraints are re\u00adquired to encode the exclusivity of link and that HB is \na strict partial order. Here, we exploit the theory of uninterpreted functions: rewrite link(r, w) as \nId(r)=Id(w),where Id is an indexing func\u00adtion which maps each access to an unique integer. All writes \nw are initialized with unique Id(w) values. Similarly, rewrite HB(a, b) as Clk(a) <Clk(b),where the Clk \nfunction assigns an integer time-stamp to each access and the operator < encodes the partial order over \ninteger time-stamps. Example. The SC constraints for the running example (with sub\u00adstituted values for \nen, val, addr and HB in .2 and .3)are .1 := (en(r14) . (en(wj ) . link(r14,wj )). WWj.{00,13,15,17} (en(r5) \n. (en(wj ) . link(r5,wj )). j.{01,23,25,27} ... .2 := link(r14,w00) . Clk(w00) <Clk(r14) . rx 1 =0). \nlink(r14,w13) . Clk(t13) <Clk(t14) . rx 1 =1). link(r14,w15) . Clk(t15) <Clk(t14) . rx 1 = a1). ... .3 \n:= link(r14,w00) . \u00ac(g(t13) . Clk(w00) <Clk(w13) <Clk(r14)). \u00ac(g(t15) . Clk(w00) <Clk(w15) <Clk(r14)). \n\u00ac(g(t17) . Clk(w00) <Clk(w17) <Clk(r14)). ... Let .bdenote the quanti.er-free formula obtained by instantiating \n. for all accesses in R and W. Note that the number of constraints in the worst case is cubic in the \nsizes of R and W. The following theorem captures the idea that the solutions of .bcorrespond to the feasible \nexecutions of the program that violate the checked property. THEOREM 1. [13] Suppose we have an encoding \nFC of a bounded CCFG C and a property encoding FPRP . The formula F:= FC . .b. FPRP is satis.able iff \nthere exists a feasible execution of C which violates the property. For convenience, if F is satis.able \nthen we say that a witness exists; otherwise we say that a (unsatis.ability) proof exists. Instead of \nalways referring to F for a given CCFG and a property, we say .bis satis.able (has a witness) or is unsatis.able \n(has a proof). We now characterize the satisfying models of . using the notion of a read-write match \nand an interference relation. DEFINITION 2 (Read-Write Match). Given setofreads R and writes W,a read-write \nmatch (match, in short) is a partial function M : R . W. DEFINITION 3 (Interference Relation (IR)). An \ninterference rela\u00adtion is a tuple (RI,WI,M, c) where RI . R, WI . W, M is a match and c is a partial \norder over the set R . W. DEFINITION 4 (IR Satisfying .b). If .bis satis.able with a model T, then there \nexists an unique IR I =(RI,WI,M, c) satisfying b . de.ned as follows: RI and WI are respectively the \nenabled reads and writes in T, i.e., (r . RI . en(r)) and (w . WI . en(w)).  M : RI . WI is well-de.ned \nfor all r . RI with co-domain WI. Moreover, M(r)= w iff link(r, w) holds in T.  c= {(a, b) |a, b . (RI \n. WI) . HB(a, b) holds in T }.  Intuitively, if .bis satis.able, then we can extract a match M by recording \nwhich of the link(r, w) predicates hold in the current solution and the partial order c induced by the \nHB predicate. Note that the exclusivity of the link constraints ensures that M is a well\u00adde.ned function. \nFor the running example in Fig. 2, .bhas a satisfying IR I =(RI ,WI,M, c)where RI = {r11,r14,r50,r51,r21,r24}, \nWI = {w00,w01,w13,w15,w23,w25}, M = {(r11,w01),(r14,w13), (r50,w15), (r21,w13), (r24,w23),(r51,w25)} \nand c consists of program order constraints (FPO in Sec. 3.1) together with (w13 c r21) and (r21 c w15). \nNote that w17 and w27 are dis\u00adabled and hence not in WI. An execution trace . = (t1t2)({t11 - t14})(t21 \n- t25 t28)(t15t18){t3 -t5} corresponds to I and violates the assertion.  4.2 Redundant Instantiation \nof SC axioms As mentioned earlier, . may give rise to a large number (cubic in the reads/writes) of constraints; \nin practice, many of these are re\u00addundant. For example, if a read r precedes write w in the program order, \ninstantiating . for link(r, w) is wasteful and can be avoided. Redundant constraints also occur in a \nmore obscure manner, e.g., suppose the given property can be violated by executing the pro\u00adgram threads \nsequentially without interleaving them. In this case, most constraints linking reads in one thread to \nconcurrent writes in another thread are unnecessary for checking the property. Pruning redundant constraints \nis the key to making our problem tractable. Interestingly, the syntactic formulation of . offers insights \non how to prune redundant constraints. Let us consider a few pruning methods. Suppose, for example, we \npick a subset of reads and writes, say R . R and W . W respectively, and instantiate .2 only for R and \nW to obtain, say, .+. Note that .+ is an over\u00ad approximation of .bbecause b .=.+ .F ,where F corresponds \nto the pruned constraints. Hence, a witness to .+ may not correspond to any feasible program execution; \nhowever, a proof for .+ implies that the property is never violated in P . On pruning constraints as \nabove, we are able to over-approximate the interference, and hence the program behaviors axiomatically. \nClearly, such an over\u00adapproximation is cheaper to check if we can discover small R and W sets, which \nare suf.cient for proving the absence of violation. Consider another form of pruning, again based on \nthe syntactic structure of the axioms. Observe that instantiating .1 leads to a disjunction of link(r, \nw) formula for each read r . R and write w . W.If W is large, we must explore a large number of choices \nto .nd an appropriate read-write match. This naturally leads to another approximation: pick a subset \nof writes W . W for each read r and instantiate .1 (similarly .2 and .3) only for pairs (r, w) where \nw . W . By pruning the disjunctions, we obtain an under-approximation of the interference (denoted by \n.-)which is cheaper to analyze. This under-approximation preserves witnesses, i.e., a witness found using \n.- corresponds to a concrete witness in the program P . Again, the usefulness of .- depends on obtaining \nasmall W suf.cient for computing a witness. Each of the approximations above relies on either weakening \nor strengthening the SC axioms by decoupling reads and writes; hence we refer to them as interference \nabstractions (IAs). The above two examples show how the syntactic structure of the SC axioms may be exploited \nto obtain approximations (under-or over-) of thread interference. In fact, the abundance of quanti.ers \nin . allows us to build a complex array of abstractions systematically, where the under-and over-approximations \nof interference are intricately combined. We now de.ne interference abstractions obtained in this manner \nformally.  5. Interference Abstractions To formally represent the interference abstractions, we .rst \nde.ne the link set for a read. DEFINITION 5(Link Set). Given a set of reads R . R,let W : R . 2W map \neach read r . R to a set of writes which r may link with. We say that W(r) is the link set of r. Let \ncW(r) contains all pos- W denote the default link set such that csible writes that r may link with statically. \nFor example, in Fig. 2, W(r14)= {w00,w13,w15,w17} because r14 reads variable x.Let . . .a . and S denote \nthe (r, w) pairs and (r, w, w ' ) triplets for which .2 and .3 are instantiated respectively. Now, we \ncan reformulate the Syntactic UIA s are more tricky to de.ne. SC axioms . as follows. DEFINITION 8 (Syntactic \nUIA). An IA a =(R, W, ., S) is an b LEMMA 1. Given a syntactic OIA a,. c W). .2 := .(r, w) . . .f2(r, \nw) Intuitively, an UIA is obtained if .1 is instantiated for all reads .3 := .(r, w, w ' ) . S .f3(r, \nw, w ' ) r . R but only for a subset W of the default link set of each read. .:=.1 . .2 . .3 Moreover, \n.2 must be instantiated for all pairs (r, w) . .(R, W) where and S consists of all triples (r, w, w ' \n) where w is drawn from W(r) ' UIA iff (i) R = R, (ii) .= .(R, W) and (iii) S= s(R, W, .1 := .r . R. \n.w .W(r) .f1(r, w) but w f1(r, w):= en(r) . (en(w) . link(r, w)) c W(r). All the above constraints \nare critical for constructing an UIA which preserves witnesses. ranges over the default set f2(r, w):= \nlink(r, w) . (HB(w, r). addr(r)= addr(w) . val(r)= val(w)) f3(r, w, w ' ):= link(r, w) . (en(w ' ) .\u00acHB(w \n' ,w) .\u00acHB(r, w ' ) . addr(r)= addr(w ' )) To model . and S, we introduce functions . and s as follows. \n LEMMA 2. Given a syntactic UIA a =(R, W, ., S), .a . .b. A subtle difference between an OIA a = (R, \nW, ., S) and an UIA \u00df = (R ' , W ' , . ' , S ' ) must be noted. Suppose for some r . R, r . R in a.In \nthe UIA \u00df, R ' = R and hence r . R ' ;however, let W ' (r) be empty. Although these two cases appear \nsimilar, they .(R, W)= {(r, w) | r . R, w .W(r)} correspond to different instantiations of ..For the \nOIA a, .1 will '' '' not be instantiated for r at all; however, for the UIA \u00df, .1 will be s(R, W, W )= \n{(r, w, w ) | r . R, w .W(r),w .W (r)} instantiated as \u00acen(r). In other words, not including a read \nr in an Given R, W and W ' the functions . and s model the set of OIA allows r to be enabled in any witness \nof .a without linking (r, w) pairs and (r, w, w ' ) triples that .2 and .3 are instantiated to any write; \nin contrast, setting W ' (r)= \u00d8 in an UIA amounts to for, respectively. The complete instantiation .bof \n. corresponds to disabling r in all witnesses of .\u00df . W) and S= s(R,W,W). c c c A full instantiation \n.bof . corresponds to both an OIA and an W, .= .(R, 5.1 Syntactic IAs c R = R, W = UIA.Also, an IA \na =(R, W, ., S) is an mixed IA (MIA), if a is An interference abstraction (IA) is characterized by an \nincomplete instantiation of . axioms. We say that the IAs thus obtained are syntactic because they are \nobtained by restricting the instantiations of SC axioms syntactically. DEFINITION 6 (Syntactic Interference \nAbstraction (IA)). Given . as above and the set of all global reads R, an interference ab\u00adstraction a \nis de.ned to be a tuple (R, W, ., S) such that: (i) R . neither an OIA nor an UIA. In particular, if \nR = R and W c W, then a is an MIA. Intuitively, in an MIA, some reads may not be linked to any writes \nwhile other reads may link to a restricted set of writes. We next discuss how to visualize the set of \nsyntactic IAs. 5.2 Visualizing Syntactic IAs As mentioned above, an IA a corresponds to instantiating \n. only for a subset of all possible reads and/or writes. Note that even = though .1 is instantiated \nfor .(R, W), .2 and .3 may be in- R, (ii) W. c c W, (iii) . . .(R,W), and (iv) S . s(R,W,W). c We say \nthat a is a proper IA if at least one of R, W, . or S is c a proper subset. We refer to R, W, . and S \nas components or dimensions of a.The size of a is de.ned to be the sum of the sizes of components of \na. Each IA a =(R, W, ., S) corresponds to an instantiation of ., denoted by .a, consisting of sub-formulas \n.a 1 , .a 2 and .a 3 . Intuitively, an IA corresponds to .rst .xing a set of reads R and the set of writes \nW(r) that each read r . R may link to, and then instantiating .1 for each (r, w) in .(R, W),and .2 and \n.3 stantiated independent of .1, for different subsets of reads and writes from R and W. The possible \nchoice of read and write sub\u00adsets gives rise to a complex space of IAs. To better visualize this space, \nconsider Fig. 4 which shows the components as four inde\u00adpendent dimensions, R, W, . and S. Intuitively, \nthe W dimension corresponds to an under-approximation, while the other dimensions correspond to over-approximations. \nMoving away from the center along any dimension corresponds to reducing the approximation corresponding \nto that dimension. Note also that the dimensions are somewhat inter-dependent, i.e., it makes sense to \nselect values for . and S only after we .nish selecting the values for R and W. The IA space shown in \nFig. 4 is, in fact, even more complex, c c c W) and s(R,W,W) respectively. Note that replacing read \nvalues by placeholders (during interference-modular for subsets of .(R,e.g., we may instantiate only \nthe order constraints HB(w, r) in .2 without instantiating the data .ow constraints val(r)=val(w). encoding, \ncf. Sec. 3.1) is the coarsest IA, where a read does not link with any write, i.e., may assume an arbitrary \nvalue. An IA a is said to be under-approximate (UIA)iff .a Consequently, we may obtain even more .ne-grained \nOIA s, cor\u00ad . .b. responding to sub-dimensions of the .-axis in the .gure. We show Similarly, a is said \nto be over-approximate (OIA)iff .b. .a . later that the space of syntactic IAs directly corresponds to \na com-Otherwise we say that a is a mixed IA (MIA). As expected, an UIA is useful for obtaining witnesses \nwhile an OIA helps obtain proofs. We now show how the OIA and UIA as de.ned above in a semantic manner \ncan be obtained syntactically. plete lattice. We now show that these syntactic IAs indeed have a practical \nsigni.cance, i.e., they correspond to some common se\u00ad mantic notions useful for reasoning about concurrent \nprograms. 5.3 Useful Semantic Interference Abstractions DEFINITION 7 (Syntactic OIA). An IA a =(R, W, \n., S) is an Many popular techniques for reasoning about concurrent programs c W. incorporate some form \nof semantic interference abstraction. Many In other words, an OIA isobtained if .1 is instantiated for \nall writes of these abstractions can be readily modeled by our syntactic IAs. OIA iff W = W(r) of each \nread r . R.However, .1 need not be instantiated for all reads and .2/.3 may not be instantiated pletely. \nNot instantiating .1 for some read r and write w disallows for all reads and writes. The following lemma \nshows that a syntactic linking r with w in any execution. Formula .2 corresponds to lo-OIA is also a \nsemantic OIA and hence preserves proofs. cal consistency: not instantiating .2 for some (r, w) implies \nthat in the default link set Let us .rst examine the meaning of instantiating . incom\u00ad  = {r1,r2, ...} \nR . S {(r, w, w .)}{(r, w)} W r . .{w1,w2,...} Figure 4. The Space of Syntactic Interference Abstractions. \nnoThread T1 Thread T2 interleaving t1 lock(A) t11 lock(B) can reach t6 t2 x=1; t12 a=y; and t16 si\u00admultaneously \nt3 lock(B) t13 lock(A) t4 t5 t6 t7 y= 1; unlock(B) z= 1; unlock(A) t14 t15 t16 t17 b= x; unlock(A) z= \n2; unlock(B) ... t6 ... ... t16 Figure 5. A control-state reachability analysis can prove the ab\u00adsence \nof data race (between t6 and t16). in any execution, r may link with w irrespective of their values, \nad\u00addresses and execution order. The formula .3 corresponds to global consistency: not instantiating .3 \nfor some (r, w, w ' ) implies that in any execution where r links with w, any other interfering w ' is \nallowed to interleave in between r and w. 5.3.1 Control-State Reachability Sometimes we can prove a \nproperty using a control-state reach\u00adability analysis [23, 31] where the control .ow structure and the \nsynchronization operations (such as lock-unlock and signal-wait) are modeled precisely, whereas the other \ndata .ow is ignored. This reasoning corresponds to a semantic IA de.ned as follows: parti\u00adtion the set \nof all reads R on shared variables SV in the program into two disjoint subsets: Rsync and (R\\Rsync). \nThe subset Rsync Thread Ti t1 lock(A) t2 if (x == 0) t3 unlock(A) t4 y= 1; t5 unlock(A) Thread Ti t1 \n. t2 assert(A = i) assume (A = .) { A:= i; } t2 . t3 assume (x = 1) t2 . t4 assume (x = 1) t3 . t4 assert(A= \ni) { A: = .; } t4 . t5 { y= 1; } t5 . t6 assert(A= i) { A: = .; }  Figure 6. The assertion failure at \nt5, caused by double unlock, can be detected in a serial execution. a feasible Thread T1 Thread T2 interleaving \nt1 : p := &#38;a; ... t1 t2 : if (p =0) { t2 t3 : * (p):=10 t4 t5 } t3 t5 : a := 0; ... t4 : p := 0; \nFigure 7. Any serial execution of block t2,t3 is non-erroneous. or interleave sporadically [7, 9]. Thread-local \nbugs fall in this category, e.g., as in Fig. 6 (left), where x =0 initially. Here lock A may be released \ntwice. Recall (cf. Sec. 2) that we encode locks using guarded assignments to shared variables as in Fig. \n6 (right). Additional assertions are added to t1 for checking double-locking errors, and to t3, t5 for \nchecking double-unlocking errors. The assertion at t5 is violated due to double unlocking. We can detect \nthis violation by only considering a serial execution of threads Ti. This form of reasoning can be captured \nby an UIA a = (R, W, ., S),where R contains reads on x which are only linked with writes inside the same \nthread or an initial write. More pre\u00adcisely, the read of x at t2 links with the initial write x =0,the \nread of A at t5 links with the write at either t1 or t3, and so on. Note that restricting the set of \nwrites to link makes W(r) . c W(r) for r . R, and hence results in an UIA. Checking this UIA for consists \nof all the variables modeling the synchronization primi\u00adsatis.ability corresponds to checking only serial \nexecutions. tives. The subset (R \\Rsync) consists of the remaining global vari-Sometimes all the serial \nexecutions are good, but an interleaved ables, which will be ignored in the IA. Given a default write \nmap execution involving only a small amount of interference may lead to a bug. Fig. 7 shows one such \nbug due to atomicity violation2. c c c W,.(Rsync,W),s(Rsync,The IA a is an OIA by de.nition (WW and Rsync \n. R)and c c W for the reads in the program, this semantic IA can be obtained syntactically as W,W)) \nc a = (Rsync, The transitions t2, t3 in thread T1 are intended to be executed atomically; however, the \nprogrammer fails to enforce it. If t4 is = hence a proof obtained with a still holds when the SC axioms \nare fully enforced. Consider Fig. 5 as an example. The two concurrent threads T1,T2 communicate through \nlocks A, B and shared variables x, y, z. The property of interest is that whether the writes to z at \nt6 and t16 cause a data race. We can show that no data race exists by using a control-state reachability \nanalysis based on locks A and B only; the rest of the variables x, y and z may be ignored because of \nthe following reason. Transitions t6 and t16 cannot be enabled at the same time, because thread T1 must \nacquire A in order to reach t6,but if A is held by T1, then thread T2 cannot reach t16 because it cannot \nacquire A at t13. We can capture this reasoning precisely by including reads on only A and B variables \nin Rsync in the IA a above and therefore can prove the absence of data race with a.  5.3.2 Serial or \nLargely Serial Execution Sometimes program bugs are insensitive to thread scheduling, i.e., they appear \neven in executions where the threads execute serially interleaved in between t2 and t3, a NULL dereference \noccurs. Again, an UIA a is suf.cient to detect such bugs. Note that if we force each global read to copy \nfrom the preceding intra-thread write, we will not be able to detect the bug. Therefore, the UIA should \nallow the read of p at t3 to link with t4 (besides t1). Inferring such reduced set of writes (W) automatically \nis, however, the prime challenge.   6. Exploring the IA Space We now focus on .nding an ef.cient exploration \nstrategy over the IA space to discover IAs of small size, which are precise enough for checking the given \nproperty. Let A denote the set containing all possible IAs. We de.ne an order relation on A as follows. \nDEFINITION 9 (Order of IAs). Given two IAs a =(R, W, ., S) and \u00df =(R ' , W ' , . ' , S ' ), we say that \na . \u00df if R . R ' , W.W ' , . . . ' , S . S ' , and at least one of R, W, . is a proper subset of the \ncorresponding R, W ' , . ' . 2 For modeling pointers/structures, please refer to our previous work [13]. \n Figure 8. Semantic Interpretation of IAs. The bold circle denotes the full instantiation of .. If a \n. \u00df, then we say that \u00df re.nes a. The poset (A, .) is a complete lattice with component-wise set union \nand intersection as the join and meet operators. The top element of the lattice cccc (R, W,.(R, W),s(R, \nW, W)) corresponds to a full instantiation (.a b =.) while the bottom element (\u00d8, \u00d8, \u00d8, \u00d8) corresponds \nto not instantiating . at all(.a = true). 6.1 Exploring the Lattice Given a property P , we say that \nan a is minimal for P if a is an OIA (UIA) which proves (falsi.es) P , and there exists no \u00df . a such \nthat \u00df proves(falsi.es) P . Since computing a minimal IA is at least as hard as checking the property \nitself, we are only interested in practically ef.cient algorithms to compute small IAs. The formulation \nof syntactic IAs suggests two naive strategies to obtain small IAs. Starting with a UIA a, one may iteratively \naugment the sets W, . and S until an actual witness is obtained. Similarly, one may start with an OIA \na and iteratively instantiate constraints until a proof is obtained. Both these re.nement strate\u00adgies \nintroduce new constraints in a lazy manner. Semantically, this form of re.nement corresponds to increasing \ncoupling or interfer\u00adence between threads and checking if a witness or a proof persists as the coupling \nincreases. The two re.nement strategies presented above have a number of issues. First, these strategies \nare suitable either for .nding proofs (using OIA s) or witnesses (using UIA s), but not both. Second, \nsince the two IAs are disjoint, the proof-directed strategy does not gain from the witness-directed strategy, \nand vice versa. Ideally, we desire of a re.nement method where both OIA s and UIA s could work in unison \nand assist each other. A natural way to combine OIA s and UIA s is via an MIA. Fig. 8 depicts and compares \nthe semantics of OIA s, UIA s and MIA s in a visual manner. Recall that the full instantiation .bmod\u00ad \nels sequential consistency precisely and hence corresponds to all feasible thread interleavings. An OIA \nremoves interference con\u00adstraints from .band therefore leads to more interleavings (infeasible ones) \nthan allowed by .b. In contrast, an UIA adds interference con\u00adstraints to .b, leading to fewer interleavings \nthan allowed by .b.An MIA contains both an OIA andanUIA, and therefore omits some interleavings from \n.bwhile allowing some infeasible ones. Although MIA s combine the advantages of both OIA s and UIA s, \nneither models nor proofs of MIA s may provide conclusive results because of combined over-and under-approximation \nin an MIA. We now examine the suf.cient conditions under which a model (proof) of an MIA may be an actual \nmodel (proof) for .b.  6.2 Models and Proofs of (Mixed) IAs Given an MIA a, we de.ne the interference \nrelation (IR) I satisfy\u00ading .a (model of the MIA) in a manner similar to Defn. 4: in the solution of \n.a , RI and WI are enabled reads and writes respec\u00adtively, M(r)= w iff link(r, w) holds and c consists \nof (r, w)\u00adpairs satisfying HB relation. Each IR I, in turn, corresponds to an induced IA de.ned as follows. \nIntuitively, if an IR I satis.es .a , then the induced IA, IA(I), models the subset of SC constraints \nrelevant to I. The hope is that IA(I) is an UIA; in that case, I is a true witness. Thread T1 Thread \nT2 r1 : assume(l = .); r2 : assume(l = .); w1 : l := 1; w2 : l := 2; ... ... w . 1 : l := .; w . 2 : \nl := .; Figure 9. Example with concurrent lock/unlock. DEFINITION 10 (IR-induced IA). Given an interference \nrelation I =(RI,WI,M, c),the IA \u00df =(R, W, ., S) induced by I, denoted by IA(I), isde.ned asfollows. \n(i) R = RI ,  (ii) W(r)= {M(r)} if M(r) is de.ned, else W(r)= \u00d8,  (iii) .= M,  (iv) S= {(r, w, w ' \n) | (r, w) . M .w ' . WI .w c w ' c r}.  However, in general, I may not correspond to a true witness \nof b . because of approximation in MIA: all the constraints IA(I) relevant to the I may not be enforced \nby (contained in) the current MIA. On enforcing the missing constraints (from the set IA(I)), if I is \nno longer a witness, then we say that I is .-inconsistent. DEFINITION 11 (.-inconsistent IR). Suppose \nan IR I induces IA \u00df =IA(I). We say that I is .-inconsistent if .\u00df is unsatis.able. An IR I =(RI,WI,M, \nc) may be .-inconsistent (invalid wit\u00adness) due to multiple reasons. For example, M may not be de.ned \nfor some enabled r . RI . Instantiating .1 for such r is unsatis\u00ad.able because antecedent en(r) is true \nbut the consequent is false. We say that I is .1-inconsistent here. Similarly, instantiating .2 for a \nsubset of r-w pairs in M may be unsatis.able. In this case, we say I is .2-inconsistent. We de.ne .3-inconsistent \nsimilarly. Note that, in general, we may need to instantiate a combination of .1, .2 and .3 constraints \nfor I to detect if I is .-inconsistent. The following lemma is crucial to .nding actual witnesses using \nIAs: it shows that to .nd an actual witness, i.e., an IR satisfying .b, it is suf.cient to compute a \n.-consistent IR. LEMMA 3. If an IR I is .-consistent, then I satis.es .b. Example. Consider the example \nin Fig. 9 with two threads T1 and T2, each containing a pair of lock/unlock statements on the lock l. \nThe lock/unlock statements are transformed into guarded statements (cf. Sec. 2) and note that each lock/unlock \npair is associated with a triple of lock accesses, e.g., (r1,w1,w1' )for T1. Here, the link set of r1 \nis W(r1)= {w2,w2' }. Similarly, W(r2)= {w1,w1' }. Consider an IR I =(RI ,WI,M, c), where RI and WI contain \nall reads and writes respectively, M = {(r1,w2' ), (r2,w1' )} and c contains program order relation, \ni.e., r1 c w1 c w1 ' and r2 c w2 c w2' . Clearly, match M vio\u00adlates lock semantics. More precisely, M \nis .2-inconsistent, i.e., on instantiating .2 for pairs in M,the IR I becomes unsatis.able be\u00adcause the \ntransitivity of HB relation is violated. Consider another ' '' IR I with ordering: r1 c w1 c w1 c r2 \nc w2 c w2. Suppose the match M ' links r2 with w1.The IR I ' is .3-inconsistent: if r2 links with w1 \nthen the interfering write w2 ' should not occur in between, and hence I ' violates .3. Dual to the notion \nof a .-consistent IR (a valid witness) is the idea of a valid proof, i.e. a subset of constraints of \n.a, which does not mention any reads whose link sets are under-approximated. DEFINITION 12 (Valid Proof). \nSuppose the instantiation .a for an IA a =(R, W, ., S) is unsatis.able and P is a proof of unsatis.ability. \nWe say that P is valid if P contains no r such that W(r) . c W(r).  We say that a read r invalidates \na proof P ,if P contains r and W(r) . c W(r). The following lemma shows that to prove absence of errors, \nit is suf.cient to .nd an IA having a valid proof P . LEMMA 4. Let the instantiation .a of an IA a =(R, \nW, ., S) have a valid proof P .Then P is also a proof for .b.  6.3 Re.nement of Mixed IA s We now present \nour re.nement procedure REF which tries to au\u00adtomatically compute an IA precise enough for either proving \nthe property or .nding a violating witness. REF works directly on an mixed IA (MIA) and iteratively re.nes \nthe MIA to obtain either a valid proof or a .-consistent IR (cf. Sec. 6.2). Fig. 10 provides an overview \nof our re.nement procedure. The procedure starts with an initial IA a =(R, W, ., S) by choosing sets \nR, W, . and S. Then, REF checks if .a conjoined with the CCFG and property encodings, FC and FPRP respectively \n(cf. Sec. 3.1), is satis.able. If .a is satis.able and the IR I obtained from the solution is .\u00adconsistent, \nthe algorithm terminates with a valid witness. If I is not .-consistent, then a must contain an over-approximation \ndue to either R, . or S (cf. Sec. 6.2). Therefore, .a is re.ned to re\u00adduce the over-approximation (using \nprocedure RED-O). Otherwise .a is unsatis.able: if .a has a valid proof P , the algorithm ter\u00adminates. \nIf P is not valid, i.e., it contains an under-approximation due to W(r) for some r,then .a is re.ned \nto reduce the under\u00adapproximation (using procedure RED-U). Note the advantage of working with an MIA: \nupon termination, the .nal IA may not be an OIA or an UIA; obtaining a .-consistent IR or a valid proof \nis suf.cient to obtain a conclusive result. We now describe the details of the RED-O and RED-U steps. \nThe pseudo code is listed as follows. =(R, W, ., S).Let the .-inconsistent IR be I = (RI ,WI,M, ).Re.ne \na by performing one of the following oper\u00adations to reduce the over-approximation in a: c Pick r . RI \n\\ R and W .W(r).Set R := R .{r} and W(r):= W . Set .:= . . M ' Set S:= S .{(r, w, w ' ) | (r, w) . M \n. ww r} Since .a is unsatis.able, obtain the set of invalidating reads R ' . R in the proof of unsatis.ability \nof .a.Re.ne a by setting W(r)= W(r) c for each r . R ' to reduce the under-approximation in a. In words, \nRED-O analyzes the IR I and then chooses to re.ne a by updating one or more of R or . or S depending \non the reason of .-inconsistency (cf. Sec. 6.2). Similarly, RED-U checks if .a is unsatis.able due to \nunder-approximation in W(r) for some r; in that case, RED-U removes the approximation by setting W(r):= \ncW(r). Checking if the IR I is .-inconsistent is done by adding constraints IA(I) related to I incrementally \nand checking if the result is satis.able. Note that both RED-O and checking .-consistency involve adding \nconstraints to reduce the over\u00adapproximation. Therefore, we combine them in practice using a layered \ninstantiation strategy (Sec. 7.2). Besides disambiguating the choices in RED-O as presented above, the \nstrategy also avoids adding irrelevant constraints. Note how REF exploits the uniform representation \nof IAs in form of MIA s to check properties using a symbiotic combination of OIA s and UIA s. Also, the \nre.nement is guided both by unsat\u00adis.ability proofs and witnesses obtained at intermediate iterations \nand hence is property-directed. The algorithm REF terminates in .nite number of steps because the height \nof the IA lattice is .nite and each iteration of REF ascends the lattice by one or more steps.  The \nre.nement procedure can be implemented ef.ciently using an incremental SMT solver [28, 29] by iteratively \nadding new constraints. Moreover, using an MIA during re.nement enables sharing the learned information \nbetween the constituent OIA s and UIA s inside the MIA, thus allowing the OIA s and UIA s to assist each \nother for computing both proofs and witnesses. For the example in Fig. 2, we initialize MIA a =(R, W, \n., S) as follows. R includes all reads r11,r14,r21,r24,r50,r51. W is initialized so that the link set \nof each read contains no concurrent writes: W(r11)= {w01}, W(r14)= {w13,w17}, W(r50)= {w15,w17} and so \non. Suppose we instantiate .= .(R, W), i.e., for all writes in the link set of each read. Let S= \u00d8.The \nIA a is an MIA because, e.g., W(r14) . c W(r14) (under-approximation) and S= \u00d8 (over-approximation). \nOn checking .a (with FC and FPRP ), the result is unsatis\u00ad.able because r11 links with w01 and r21 links \nw00. Hence, the then branch in T1 executes while the else branch in T2 executes. Therefore, r50 gets \nvalue 2 and r51 gets value 0 so that the asser\u00adtion is never violated. The proof of unsatis.ability mentions \nr11 and r21. Suppose the procedure RED-U then expands W for r21 to c W(r21)= {w00,w13,w15,w17} and . \nis updated with the cor\u00adresponding pairs. In the next iteration, suppose we obtain an IR I which links \nr21 with w13,but I has w13 c w15 c r21 in I. Here, I is not .-consistent because it violates .3. Therefore, \nREF up\u00addates S= {(r21,w15,w13)} using RED-O, which .nally results in a .-consistent IR with w13 c r21 \nc w15. Note how a combination of over-and under-approximation was exploited by REF to arrive at a .-consistent \nIR. Further, even though we check bounded programs (where paths in each thread or number of threads have \nbeen under-approximated), over\u00adapproximating interference is orthogonal and does not work against the \nprevious under-approximation. In fact, it may assist in .nding the bug quickly in many cases (cf. above \nexample) or obtaining a proof early by avoiding redundant constraints.  7. Focused Re.nement The procedure \nREF proceeds iteratively by ascending the lattice of IAs based on the current satisfying solution or \nan infeasibility proof. Since the size of the lattice is exponential in the number of reads and writes, \nthe basic re.nement strategy may not converge quickly to a desirable small IA on its own. In particular, \nit may add redundant constraints guided by the model from the solver, thus making the intermediate IA \nlarger and the subsequent itera\u00adtions more expensive. We propose a set of heuristics to focus the re.nement \non relevant constraints. 7.1 Static Focusing We .rst describe heuristics to guide REF by removing redundant \nconstraints or adding useful lemmas statically. (S0) Interference Pruning. For each read r, compute a \nsmall W(r), not containing any writes that r may never link with. For example, a r cannot link with w \nif HB(r, w) holds statically, or c gram slices obtained by run-time analysis of the FUSION tool. Our \nbenchmarks consist of Java program slices obtained from the vari\u00adous publicly available programs [33 \n35]. We check for errors such as assertion violations and data races. Many of these program slices are \ndif.cult to analyze, because they contain multiple threads (with forks and joins), each having a large \nnumber of global accesses, together with assume statements containing guards for branches taken during \nrun-time. Our goal was to investigate if the hardest subset of available benchmarks could be checked \nusing small IAs. We initialize the re.nement scheme with an IA containing all reads in the CCFG and the \nlink set of each read with only writes which are non-concurrent with the read. Lock lemmas were also \ninstantiation. We observed that for obtaining proofs, REF needed accesses to the lock variable for each \nLi .L be (ri,wi,wi' ). if HB(w, r) and there exist interfering writes w ' along each path from w to r. \nSuch writes may be detected by performing a static analysis on the interference skeleton (IS) (cf. Sec. \n3.1). (S1) Biased Initialization. To obtain IAs with lesser concurrent interference, we initialize W(r) \nfor each r with only writes in the same thread or initial writes. This ensures that if a serial or largely \nserial execution (cf. Sec. 5.3) violates the property, then few re.nement iterations will be suf.cient. \nWe also bias the initial IA to couple reads and writes on synchronization variables only. This forces \nREF to start with only those IAs where the above interference conditions must hold. (S2) Lock Lemmas. \nA number of optimizations are possible for locks. (S2a) Consider the program shown in Fig. 9 again. The \nread in the initial assume statement (r1) may link with either w2 or w2' . However note that if link(r1,w2) \nholds then val(r1)= val(w2)=2, making the guard (l = .) as false,which in turn blocks the execution of \nT1. Therefore, we reduce the link set W(r1) by removing w2 matching lock/unlock statements in the whole \nprogram and the c from it. (S2b) Let L denote the set of added to improve re.nement. We observed that \nlemma S2a had a much larger impact than lemma S2b, although S2b also helped re\u00adduce run-times in a few \ncases. Further, we used biased re.nement (7.2) strategy for reducing over-approximation. We focus on \nshow\u00ading the effectiveness of IAs and that MIA s can perform better than OIA s or UIA s. All experiments \nwere conducted on 2.33GHz Intel Xeon machine with 16GB memory. Fig. 11 compares the full instantiation \nwith the re.nement (REF) procedure on a set of properties of the hard benchmarks. In this table, Columns \n1-3 show the name of each test case, the number of threads, and whether there is a bug (T) or a proof \n(F). Columns 4-6 show the number of reads, the number of writes, and the average size of the link sets. \nThe remaining columns compare the run-times and the IA sizes obtained with and without interfer\u00adence \nabstraction. The IAs computed by REF are drastically smaller than full instantiation both for satis.able \nand unsatis.able bench\u00admarks. This con.rms the belief that only a small amount of inter\u00adference need \nbe considered for checking many properties. More\u00adover, small IAs lead to much lesser run-times than with \nthe full For each L1,L2 .L, either the statement block denoted by L1 to instantiate .2 only a few times \nfor each r-w pair in the initial executes before the block denoted by L2 or vice-versa. This fact can \nbe captured by the constraints .i..j. (HB(wi' ,rj).HB(wj' ,ri)), IA. Finding witnesses is more challenging \nthan .nding proofs: REF which are quadratic in the size of L (better than the original cubic goes through \na number of iterations for reducing both the under\u00ad and over-approximation present in the initial IA. \nsize). (S3) Although instantiating .2 eagerly for all pairs of reads/writes Fig. 12 shows the advantage \nof using combined MIA s in REF .= .(R, W) is expensive, instantiating only a portion of .2 for . incurs \nlesser cost both in terms of constraints size and solv\u00ad c vsusingonly OIA soronly UIA s.Thesearescatterplotswherethe \nx-axis is the run-time with only OIA s or only UIA s, and the y-axis is the run-time with MIA s. The \ndata points correspond to checking several data race properties in benchmark (syncBench.1119). We ing \ntimes. We can therefore instantiate only a portion of .2, e.g., link(r, w) . HB(w, r) for all (r, w) \n. . eagerly. This is espe\u00adcially useful if the ordering constraints are suf.cient for checking the property. \nFormally, this form of instantiation corresponds to fur\u00adther partitioning the components of an a and \ninstantiating some of those partitions eagerly.  7.2 Layered Instantiation Note that in RED-O, updating \nS adds far more (quadratic in num\u00adber of reads and writes) constraints than updating . (linear in size \nof reads R). We, therefore, perform a layered re.nement to\u00adwards the goal of adding fewer redundant constraints. \nGiven an IR I =(R, W, M, c) satisfying .a, we .rst check if I is .2 \u00adconsistent (cf. Sec. 6.2). If I \nis not .2-consistent, we update . and continue to the next iteration. Only when we .nd a .2-consistent \nIR, we check if I is .3-consistent. In this way, we bias the re\u00ad.nement towards .. Similarly, we update \nthe set R only when the current match M is both .2-and .3-consistent.  8. Experiments We implemented \nthe algorithm REF and evaluated it on concur\u00adrent benchmarks in the FUSION framework [20, 21]. Although \nour method can be applied to arbitrary bounded concurrent pro\u00adgrams, in these experiments, we focus on \nanalyzing concurrent pro\u00adobserve that MIA s clearly outperform OIA s implying that under\u00adapproximated \nIAs are essential for ef.ciency. In contrast, MIA s may not be always better than only UIA s: however, \nthe over\u00adapproximation in MIA s improves the performance in most cases. The procedure REF for .nding \nsmall IAs may be viewed as an automated quanti.er instantiation (AQI) technique speci.c to the domain \nof SC axioms where the variables are quanti.ed over .\u00adnite domains. Although a number of SMT solvers \nsupport asserting quanti.ed formula and include generic AQI heuristics, we found that such approach did \nnot perform well even on small bench\u00admarks (we used Yices [28] with default settings). We believe it \nis due to the following reasons: .rst, the solver must be provided with large number (at least quadratic \nin the number of reads and writes) of non-interference constraints derived from static pruning (cf. Sec. \n7.1), without which these benchmarks become intractable. Secondly, generic AQI heuristics often lead \nto eager redundant in\u00adstantiation which severely hurts performance. Most importantly, it is dif.cult \nfor generic heuristics to infer a biased initialization of the MIA s: the initialization exploits knowledge \nabout the typical be\u00adhaviors of concurrent programs, which is unavailable to the solver. We are aware \nthat a number of improved AQI heuristics have been implemented in Z3 [36]. We believe that these recent \nim\u00adprovements are complementary, and, if exploited correctly, could assist REF in converging faster. \nNote that an SMT solver also uses a combination of under-and over-approximations internally during Bm \nNSAT R W Avg. |W| T(s) barrierB.653 13 F 285 269 9 29 barrierB.653 13 T 285 269 9 30 syncBench.722 13 \nF 270 289 3 4 syncBench.722 13 T 270 289 3 4 syncBench.1119 16 F 496 457 24 902 syncBench.1119 16 T 496 \n457 24 741 Full Instantiation IA Size 2.7K / 2.7K / 91K 2.7K / 2.7K / 91K 891 / 891 / 8.5K 891 / 891 \n/ 8.5K 12K / 12K / 1M 12K / 12K / 1M syncBench.1954 19 F 1012 856 48 >1hr 49K/49K/8M syncBench.1954 \n19 T 1012 856 48 >1hr 49K/49K/8M daisy1 3 F 496 798 19 117 10K / 10K / 0.4M daisy1 3 T 496 798 19 681 \n10K / 10K / 0.4M elevator1 4 F 829 615 3 202 3K / 3K / 29K elevator1 4 T 829 615 3 82 3K/3K/29K elevator2 \n4 F 2259 1491 10 >1hr 24K / 24K / 0.7M elevator2 4 T 2259 1491 10 >1hr 24K / 24K / 0.7M With IAs (REF) \nT(s) IA Size 2 249/285/0 22 350/382/3.2K 2 259/270/0 2 254/270/55 3 477/496/0 149 533/498/12K 15 989/1012/0 \n258 1056 / 1023 / 20K 5 370/495/0 396 370/30/850 38 824/0/0 23 824/30/0 15 2204/0/0 14 2204/39/215 Figure \n11. Experimental Results. R (W) = number of reads (writes). IA size denotes the size of the IA a =(R \n' , W, ., S) when the check P terminates, in form (A/B/C) where A = |W(r)|,B= |.| and C= |S|. nK and \nnM are shorthand for n * 103 and n * 106 respectively. r Figure 12. Run-times using MIA s vs. only OIA \ns or only UIA s on benchmark syncBench.1119. constraint solving, which is unfortunately ineffective in \nhandling the full instantiation directly. In other words, the solver is unable to focus on the concurrent \nfacts relevant to the property by itself; the presented re.nement scheme, in contrast, has the concurrency\u00adspeci.c \nknowledge (e.g., to compute an initial biased IA) and is able to steer the solver towards the relevant \nfacts. 9. Related Work Automated reasoning about concurrent programs with shared memory has been traditionally \ndone by systematically restricting the thread scheduler [2, 4, 5, 37, 38] based on partially-ordered \ntraces [1] with dependency relation (Mazurkiewicz (M-) traces). In particular, the work in [4] uses iterative \nenlargements of scheduler under-approximations to .nd bugs based on proofs from a SAT solver. Automated \ncompositional methods have also employed ab\u00adstractions of both transition relations [39, 40] and state \nspaces [41] of individual threads. IAs, in contrast, build upon the axioms of memory consistency instead \nof M-traces (cf. [42]). Note that the notion of IAs is orthogonal to abstractions of transition relations: \nIAs abstract only the correlations between reads and writes without modifying the transition relations \nof individual threads. The no\u00adtion of .eld abstraction introduced in [26] for removing reads and writes \nto selected structure .elds may be viewed as a form of OIA. However, .eld re.nement links each .eld read \nwith all possible writes, thus hampering its scalability. As our experiments show, the combination of \nOIA s with UIA s is important. Iterative abstraction-re.nement methods [16, 17] for sequential software \nusing predicate abstraction [18, 19] have been investigated widely. Mixed abstractions of transition \nsystems containing both may and must transitions to preserve universal and existential prop\u00aderties respectively \nhave also been studied and applied to sequential software (cf. [43] for a nice overview). Recent work \nhas also com\u00adbined may-and must-summaries of procedures to obtain a more scalable analysis of sequential \nsoftware [44]. Decision procedures for bit-vectors [45] also employ mixed abstractions of formula. Automatic \nquanti.er instantiation (AQI) inside SMT solvers is an active research topic. The most prevalent AQI \nstrategy [28, 29], introduced in Simplify [46], employs triggers [36, 46]: to enable QI, subterms (triggers) \nof quanti.ed assertions are matched (uni.ed) with the ground terms in the partial model of the solver. \nHowever, such heuristics are in general incomplete and often cause a large number of redundant instantiations. \nLeino et al. proposed to handle quanti.ed assertions via a separate module [47] similar to a theory module \nin an SMT solver. However, lack of tight integration between the quanti.er module and the main solver \nleads to duplicate theory reasoning as well as restrained learning. 10. Conclusions We presented a new \nform of concurrency abstraction for shared memory programs called interference abstractions (IAs) based \non the axioms of sequential consistency. The framework of IAs pro\u00advides an automated and .exible mechanism \nfor approximating in\u00adterference. An iterative algorithm to synthesize IAs for checking concurrent properties \nwas presented and shown to yield small IAs for practical benchmarks. IAs may be extended in multiple \nways, e.g., we can cluster multiple reads and/or writes into a single ac\u00adcess and reason about these \naccess sets simultaneously. These ex\u00adtensions, in contrast to pure IAs, may also violate the program \nor\u00adder. Extending the notion of IAs to relaxed memory models is also an interesting direction. We also \nplan to compare with automated quanti.er instantiation inside constraint solvers, handle unbounded programs, \nand investigate rely-guarantee reasoning using interfer\u00adence abstractions. Acknowledgments. We thank \nthe anonymous reviewers for their careful reading and valuable suggestions. We are also indebted to Yeting \nGe and Cesare Tinelli for useful discussions.   References [1] Mazurkiewicz, A.W.: Trace theory. In: \nAdvances in Petri Nets. (1986) 279 324 [2] Godefroid, P.: Partial-Order Methods for the Veri.cation of \nConcur\u00adrent Systems: An Approach to the State-Explosion Problem. Springer-Verlag New York, Inc., Secaucus, \nNJ, USA (1996) [3] Peled, D.: Partial order reduction: Model-checking using representa\u00adtives. In: MFCS. \n(1996) 93 112 [4] Grumberg, O., Lerda, F., Strichman, O., Theobald, M.: Proof-guided underapproximation-widening \nfor multi-process systems. In: POPL. (2005) 122 131 [5] Musuvathi, M., Qadeer, S., Ball, T., Basler, \nG., Nainar, P.A., Neamtiu, I.: Finding and reproducing heisenbugs in concurrent programs. In: OSDI. (2008) \n267 280 [6] Kahlon, V., Wang, C., Gupta, A.: Monotonic partial order reduction: An optimal symbolic partial \norder reduction technique. In: CAV. (2009) 398 413 [7] Qadeer, S., Rehof, J.: Context-bounded model checking \nof concurrent software. In: TACAS. (2005) 93 107 [8] Musuvathi, M., Qadeer, S.: Iterative context bounding \nfor systematic testing of multithreaded programs. In: PLDI. (2007) 446 455 [9] Lal, A., Touili, T., Kidd, \nN., Reps, T.W.: Interprocedural analysis of concurrent programs under a context bound. In: TACAS. (2008) \n282 298 [10] Adve, S.V., Gharachorloo, K.: Shared memory consistency models: A tutorial. IEEE Computer \n29(12) (1996) 66 76 [11] Burckhardt, S., Alur, R., Martin, M.M.K.: Checkfence: checking consistency of \nconcurrent data types on relaxed memory models. In: PLDI. (2007) 12 21 [12] Torlak, E., Vaziri, M., Dolby, \nJ.: Memsat: checking axiomatic speci.\u00adcations of memory models. In: PLDI. (2010) 341 350 [13] Sinha, \nN., Wang, C.: Staged concurrent program analysis, FSE 2010 [14] Lamport, L.: How to make a multiprocessor \ncomputer that correctly executes multiprocess programs. IEEE Trans. Computers 28(9) (1979) 690 691 [15] \nLu, S., Park, S., Seo, E., Zhou, Y.: Learning from mistakes: a comprehensive study on real world concurrency \nbug characteristics. SIGARCH Comput. Archit. News 36(1) (2008) 329 339 [16] Kurshan, R.P.: Computer-aided \nveri.cation of coordinating processes: the automata-theoretic approach. Princeton University Press (1994) \n[17] Clarke, E.M., Grumberg, O., Jha, S., Lu, Y., Veith, H.: Counterexample-guided abstraction re.nement \nfor symbolic model checking. Journal of the ACM (JACM) 50(5) (2003) 752 794 [18] Ball, T., Majumdar, \nR., Millstein, T.D., Rajamani, S.K.: Automatic predicate abstraction of C programs. In: PLDI. Volume \n36(5)., ACM Press (June 2001) 203 213 [19] Henzinger, T.A., Jhala, R., Majumdar, R., McMillan, K.L.: \nAbstrac\u00adtions from proofs. In: POPL. (2004) 232 244 [20] Wang, C., Chaudhuri, S., Gupta, A., Yang, Y.: \nSymbolic pruning of concurrent program executions. In: FSE 2009. 23 32 [21] Wang, C., Kundu, S., Ganai, \nM.K., Gupta, A.: Symbolic predictive analysis for concurrent programs. In: FM. (2009) 256 272 [22] Wang, \nC., Limaye, R., Ganai, M., Gupta, A.: Trace-based symbolic analysis for atomicity violations. In: TACAS, \nSpringer (2010) 328 342 [23] Kahlon, V., Wang, C.: Universal Causality Graphs: A precise happens\u00adbefore \nmodel for detecting bugs in concurrent programs. In: CAV, Springer (2010) 434 445 [24] Clarke, E., Kroening, \nD., Lerda, F.: A tool for checking ANSI-C programs. In Jensen, K., Podelski, A., eds.: TACAS. Volume \n2988 of LNCS., Springer (2004) 168 176 [25] Ivancic, F., Yang, Z., Ganai, M.K., Gupta, A., Shlyakhter, \nI., Ashar, P.: F-soft: Software veri.cation platform. In: CAV. (2005) 301 306 [26] Lahiri, S.K., Qadeer, \nS., Rakamaric, Z.: Static and precise detection of concurrency errors in systems code using smt solvers. \nIn: CAV. (2009) 509 524 [27] Ballance, R.A., Maccabe, A.B., Ottenstein, K.J.: The program depen\u00addence \nweb: A representation supporting control, data, and demand\u00addriven interpretation of imperative languages. \nIn: PLDI 90. 257 271 [28] Dutertre, B., de Moura, L.: A fast linear-arithmetic solver for DPLL(T). In: \nCAV. (2006) 81 94 [29] de Moura, L., Bj\u00f8rner, N.: Z3: An ef.cient smt solver. In: TACAS. (2008) 337 340 \n[30] Lu, S., Tucek, J., Qin, F., Zhou, Y.: AVIO: detecting atomicity viola\u00adtions via access interleaving \ninvariants. In: ASPLOS. (2006) 37 48 [31] Farzan, A., Madhusudan, P., Sorrentino, F.: Meta-analysis for \natomic\u00adity violations under nested locking. In: CAV. (2009) 248 262 [32] Yang, Y., Gopalakrishnan, G., \nLindstrom, G., Slind, K.: Nemos: A framework for axiomatic and executable speci.cations of memory consistency \nmodels. In: IPDPS. (2004) [33] http://www.javagrande.org/: The Java Grande Forum Bench\u00admark Suite. [34] \nHavelund, K., Pressburger, T.: Model checking Java programs using Java PathFinder. International Journal \non Software Tools for Technol\u00adogy Transfer (STTT) 2(4) (2000) [35] von Praun, C., Gross, T.R.: Static \ndetection of atomicity violations in object-oriented programs. Object Technology 3(6) (2004) [36] de \nMoura, L.M., Bj\u00f8rner, N.: Ef.cient e-matching for smt solvers. In: CADE. (2007) 183 198 [37] Flanagan, \nC., Godefroid, P.: Dynamic partial-order reduction for model checking software. In: POPL. (2005) 110 \n121 [38] Clarke, E., Grumberg, O., Peled, D.: Model Checking. MIT Press. [39] Flanagan, C., Qadeer, S.: \nThread-modular model checking. In: SPIN. (2003) 213 224 [40] Henzinger, T.A., Jhala, R., Majumdar, R., \nQadeer, S.: Thread-modular abstraction re.nement. In: CAV. Volume 2725., Springer-Verlag (2003) 262 274 \n[41] Cohen, A., Namjoshi, K.S.: Local proofs for global safety properties. Formal Methods in System Design \n34(2) (2009) 104 125 [42] S\u00b8erb.anut\u00b8.a, T.F., Chen, F., Ros\u00b8u, G.: Maximal causal models for se\u00adquentially \nconsistent multithreaded systems. Technical report, Uni\u00adversity of Illinois (2010) [43] Wei, O., Gur.nkel, \nA., Chechik, M.: Mixed transition systems revis\u00adited. In: VMCAI. (2009) 349 365 [44] Godefroid, P., Nori, \nA.V., Rajamani, S.K., Tetali, S.: Compositional may-must program analysis: unleashing the power of alternation. \nIn: POPL. (2010) 43 56 [45] Bryant, R.E., Kroening, D., Ouaknine, J., Seshia, S.A., Strichman, O., Brady, \nB.A.: An abstraction-based decision procedure for bit-vector arithmetic. STTT 11(2) (2009) 95 104 [46] \nDetlefs, D., Nelson, G., Saxe, J.B.: Simplify: a theorem prover for program checking. J. ACM 52(3) (2005) \n365 473 [47] Leino, K.R.M., Musuvathi, M., Ou, X.: A two-tier technique for supporting quanti.ers in \na lazily proof-explicating theorem prover. In: TACAS. (2005) 334 348  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>Interference is the bane of both concurrent programming and analysis. To avoid considering all possible interferences between concurrent threads, most automated static analysis employ techniques to approximate interference, e.g., by restricting the thread scheduler choices or by approximating the transition relations or reachable states of the program. However, none of these methods are able to reason about interference directly. In this paper, we introduce the notion of <i>interference abstractions</i> (IAs), based on the models of shared memory consistency, to reason about interference efficiently. IAs differ from the known abstractions for concurrent programs and cannot be directly modeled by these abstractions. Concurrency bugs typically involve a small number of unexpected interferences and therefore can be captured by small IAs. We show how IAs, in the form of both over- and under-approximations of interference, can be obtained syntactically from the axioms of sequential consistency. Further, we present an automatic method to synthesize IAs suitable for checking safety properties. Our experimental results show that small IAs are often sufficient to check properties in realistic applications, and drastically improve the scalability of concurrent program analysis in these applications.</p>", "authors": [{"name": "Nishant Sinha", "author_profile_id": "81100335738", "affiliation": "NEC Labs America, Princeton, NJ, USA", "person_id": "P2509644", "email_address": "nishants@nec-labs.com", "orcid_id": ""}, {"name": "Chao Wang", "author_profile_id": "81100220807", "affiliation": "NEC Labs America, Princeton, NJ, USA", "person_id": "P2509645", "email_address": "chaowang@nec-labs.com", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926433", "year": "2011", "article_id": "1926433", "conference": "POPL", "title": "On interference abstractions", "url": "http://dl.acm.org/citation.cfm?id=1926433"}