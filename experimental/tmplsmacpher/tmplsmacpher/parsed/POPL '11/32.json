{"article_publication_date": "01-26-2011", "fulltext": "\n Making Prophecies with Decision Predicates Byron Cook Microsoft Research &#38; Queen Mary, University \nof London bycook@microsoft.com Abstract We describe a new algorithm for proving temporal properties \nex\u00adpressed in LTL of in.nite-state programs. Our approach takes ad\u00advantage of the fact that LTL properties \ncan often be proved more ef.ciently using techniques usually associated with the branching\u00adtime logic \nCTL than they can with native LTL algorithms. The caveat is that, in certain instances, nondeterminism \nin the sys\u00adtem s transition relation can cause CTL methods to report coun\u00adterexamples that are spurious \nwith respect to the original LTL formula. To address this problem we describe an algorithm that, as it \nattempts to apply CTL proof methods, .nds and then re\u00admoves problematic nondeterminism via an analysis \non the po\u00adtentially spurious counterexamples. Problematic nondeterminism is characterized using decision \npredicates, and removed using a partial, symbolic determinization procedure which introduces new prophecy \nvariables to predict the future outcome of these choices. We demonstrate using examples taken from the \nPostgreSQL database server, Apache web server, and Windows OS kernel that our method can yield enormous \nperformance improvements in comparison to known tools, allowing us to automatically prove properties \nof programs where we could not prove them before. Categories and Subject Descriptors D.2.4 [Software \nEngineer\u00ading]: Software/Program Veri.cation Model checking; Correct\u00adness proofs; Reliability; D.4.5 [Operating \nSystems]: Reliability Veri.cation; F.3.1 [Logics and Meanings of Programs]: Specify\u00ading and Verifying \nand Reasoning about Programs; F.3.2 [Logics and Meanings of Programs]: Semantics of Programming Languages \nProgram analysis General Terms Veri.cation, Theory, Reliability Keywords Linear temporal logic, formal \nveri.cation, termination, program analysis, model checking 1. Introduction The common wisdom amongst \nusers and developers of tools that prove temporal properties of systems is that the linear speci.ca\u00adtion \nlogic LTL [33] is more intuitive than CTL [10], but that prop\u00aderties expressed in the universal fragment \nof CTL (.CTL) with\u00adout fairness constraints are often easier to prove than their LTL Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 11, January 26 28, \n2011, Austin, Texas, USA. Copyright &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 Eric Koskinen \nUniversity of Cambridge ejk39@cam.ac.uk cousins [3, 32, 44]1. Properties expressed in CTL without fair\u00adness \ncan be proved in a purely syntax-directed manner using state\u00adbased reasoning techniques, whereas LTL \nrequires deeper reason\u00ading about whole sets of traces and the subtle relationships between families of \nthem. In this paper we aim to make an LTL prover for in.nite-state programs with performance closer to \nwhat one would expect from a CTL prover. We use the observation that .CTL without fairness can be a useful \nabstraction of LTL. The problem with this strategy is that the pieces don t always .t together: there \nare cases when, due to some instances of nondeterminism in the transition system,.CTL alone is not powerful \nenough to prove an LTL property. In these cases our LTL prover works around the problem using something \nwe call decision predicates, which are used to character\u00adize and treat such instances of nondeterminism. \nA decision predi\u00adcate is represented as a pair of .rst-order logic formulae (a, b), where the formula \na de.nes the decision predicate s presupposi\u00adtion (i.e. when the decision is made), and b characterizes \nthe binary choice made when this presupposition holds. Any transition from ' state s to state s in the \nsystem that meets the constraint a(s).b(s ') ' is distinguished by the decision predicate (a, b) from \na(s).\u00acb(s ). We use decision predicates as the basis of a partial symbolic determinization procedure: \nfor each predicate we introduce a new prophecy variable [3] to predict the future outcome of the decision. \nAfter partially determinizing with respect to these prophecy vari\u00adables, we .nd that CTL proof methods \nsucceed, thus allowing us to prove LTL properties with CTL proof techniques in cases where this strategy \nwould have previously failed. To synthesize the deci\u00adsion predicates we employ a form of symbolic execution \non spuri\u00adous .CTL counterexamples together with an application of Farkas lemma [23]. With our new approach \nwe can automatically prove properties of in.nite-state programs in minutes or seconds which were in\u00adtractable \nusing existing tools. Examples include code fragments drawn from the PostgreSQL database server, the \nApache web server, and the Windows OS kernel. Limitations. In practice, the applicability and performance \nof our technique is dependent on the heuristic used to choose new decision predicates when given an abstract \nrepresentation of a speci.c point in a spurious counterexample. The predicate synthesis mechanism implemented \nin our tool is applicable primarily to in.nite-state pro\u00adgrams over arithmetic variables with commands \nthat only contain linear arithmetic. However, no matter which predicate selection mechanism is used, \nour predicate-based determinization strategy is sound. Thus, unsound approximations to predicate synthesis \ncould potentially be used in instances where the systems considered do not meet the constraints given \nabove. Our technique is also based 1 Abadi and Lamport [3] make this point using the terminology of re.ne\u00adment \nmappings and trace equivalence instead of phrasing it in the con\u00adtext of temporal logics.  on an .CTL \nprover for in.nite-state systems, which itself cannot be complete. A further limitation is that our procedure \nis not well suited for .nite-state model checking. The problem is that introducing prophecy variables \ngreatly increases the number of state-holding elements required in usual .nite-state encodings: Each \nprophecy variable must be capable of counting up to a number larger than the system s diameter [12]. \nThe problem is further exacerbated when we introduce multiple prophecy variables, as the nth prophecy \nvari\u00adable must range over values as large as the diameter of the system which has been augmented with \nthe .rst n-1 prophecy variables. In contrast, when using proof tools for in.nite-state systems the per\u00adformance \ncost for adding additional in.nite-state variables is usu\u00adally low. Finally, our procedure critically \ndepends on the full structure of counterexamples to .CTL properties, which are in the form of trees. \nUnfortunately, with only a few exceptions [13, 17] tools do not return whole tree counterexamples. Related \nwork. Our method complements more classical automata\u00adtheoretic approaches [34, 45] in which fairness \nconstraints are used to encode linear-temporal conditions and then language emptiness a.k.a. fair termination \nis proved of the resulting sys\u00adtem. The dif.culty with language emptiness for in.nite state sys\u00adtems \n(e.g. as implemented in previous work [15]) is that the mech\u00adanisms that allow us to ignore in.nite executions \nnot accepted by the fairness constraints are effectively the same as the expensive techniques used for \nproving termination. Thus, in practice, our pre\u00advious tool [15] relies too heavily on termination proving \nmachinery. In contrast, our new approach uses syntax-directed techniques for.CTL that depend much less \non the performance of the underlying termination proving infrastructure. However, our strategy does rely \non the assumption that, on average, the subtle correlations that are tracked only on-demand in our approach \ndo not occur frequently. In cases where this assumption is not true, the cost of on-demand inference \nof decision predicates may be higher than simply us\u00ading traditional techniques. We will see an example \nof this later in Section 6. It is well known that determinization addresses the subtle se\u00admantic distinctions \nbetween linear-time and branching-time log\u00adics [39]. However, for in.nite-state systems, open questions \nstill re\u00admain if we hope to develop a practical determinization-based strat\u00adegy: a) what to determinize, \nsince complete determinization does not lead to a viable automatic tool for in.nite-state systems, and \nb) how to determinize in a way that facilitates the application of current formal veri.cation tools. \nWe address these two questions in this paper. Others have considered this trade-off between linear-time \nspec\u00adi.cations and ef.cient branching-time veri.cation procedures. For example, Cadence SMV [1] reduces \nLTL to CTL using additional fairness constraints [9, 14]. This technique still relies heavily on reasoning \nabout fairness. This is a sensible engineering choice for .nite-state systems for the reasons discussed \nabove, but not for in.nite-state systems. Schneider describes a method of translating an LTL formula \ninto a semantically equivalent CTL formula [41]. However, this leads to an exponential blowup in the \nsize of the CTL formula, and requires a modi.cation to the model checking algorithm. Maidl identi.es \nthe subset of .CTL (called .CTLdet) which is expressible in LTL. Consequentially, for such formu\u00adlae, \nan .CTL prover can be used [31]. By contrast, our decision predicate-based technique allows one to verify \nany LTL formula using branching-time proof techniques in such a way that perfor\u00admance is affected only \nin cases where tracking subtle correlations between traces is actually required. Previous work has also \nexamined different methods of repre\u00adsenting systems [4, 6, 43] in order to facilitate proving linear-time \nPROVE (M, .L) : O := \u00d8 let .C = APPROXIMATE(.L) in while true do let MO = DETERMINIZE(M, O) in match \nPROVE.CTL(MO,.C) with| Succeed -> return Succeed| Fail(.)-> let = REFINE(.) in O ' if(O ' = \u00d8) let p \n. . in return Fail(p) else O := O . O ' done Figure 1: Algorithm based on predicate determinization which \nim\u00adplements LTL model checking (i.e. M .L .L). The procedures APPROXIMATE,DETERMINIZE,REFINE and PROVE.CT \nL are de\u00ad.ned in later sections. temporal properties or proving linear-time properties of abstrac\u00adtions \n(e.g. pushdown systems [21, 42]). When model-checking is performed using explicit-state techniques [25, \n28, 29] then the con\u00adverse of our assumption is true: linear-time traces are in fact more naturally explored \nthan branching-time executions in this context. Our procedure uses several techniques found in the literature: \nnamely prophecy variables [3] and Farkas lemma [23]. We are of course not the .rst to use these techniques \nin applications related to the one addressed here. Prophecy variables have been used for many years to \nresolve nondeterminism in proofs, including some recent work [27, 38]. Our use of Farkas lemma is similar \nto its use in rank function synthesis [35] and invariant generation [40].  2. Algorithm Our LTL proof \nprocedure, PROVELT L, is given in Figure 1. The algorithm is designed to iteratively .nd a suf.cient \nset of decision predicates O such that proof tools for CTL can be used to prove an LTL property .L of \nthe system M . The algorithm is based on four procedures which are each de.ned in later sections of the \npaper: APPROXIMATE (Section 3) is a simple procedure which ap\u00adproximates an LTL formula with an analogous \n.CTL formula in which universal operators are added in (e.g. F becomes AF, and G becomes AG). Without \nloss of generality we assume that negations have been pushed to the atomic propositions of the formula. \n DETERMINIZE (Section 4) takes a transition system and a set of decision predicates O and returns a \nnew partially determinized system in which newly introduced prophecy variables are used to make predictions \nabout the valuations of the decision predi\u00adcates in O.  REFINE (Section 5) takes an .CTL counterexample \n. and, in the case that . represents multiple distinct paths through the system, returns decision predicates \nwhich characterize the non\u00addeterminism that distinguishes between the different paths. In the case that \n. represents only a single path through the system then REFINE returns \u00d8,  PROVE.CTL(Section 6) is an \n.CTL-prover.  When O =\u00d8,DETERMINIZE(M, O)= M. Thus, on the .rst iteration of the loop our procedure \nis attempting to prove .L via a simple approximation .C together with the original system M. When given \na non-empty set of decision predicates, DETERMINIZE builds MO by conjoining the original transition relation \nof M with a relation that speci.es the behavior of a prophecy variable for each decision predicate. For \nany set of decision predicates O,if .C holds, then .L also holds. Thus, whenever we .nd a suf.cient set \nof predicates to prove .C,wehaveproved .L.  REFINE is used to determine if an .CTL-counterexample found \nby PROVE.CTL represents a real LTL-counterexample or something spurious. At .rst glance there is a formidable \nse\u00admantic gap between the two types of counterexamples: .CTL\u00adcounterexamples are trees, whereas LTL-counterexamples \nare traces. However, if all of the paths through the counterexample . represent the same path or its \npre.xes, then any one of these paths is a legitimate counterexample to .L. In this case REFINE returns\u00d8. \nOtherwise, if . represents more than one path in the program, REFINE returns a non-empty set of new decision \npredicates. Example. Consider the LTL property FG(x = 1),which infor\u00admally can be read for every trace \nof the system, x = 1 will even\u00adtually become true and stay true. The meaning of the analogous.CTL property \nAFAG(x = 1) is slightly more operational: On all paths emanating from an initial state, the system eventually \nreaches a state such that along all paths starting from this state, x = 1 will be true and stay true. \nFor every transition system, if AFAG(x = 1) holds, then FG(x = 1) holds. Furthermore, our experience \nleads us to believe that proving AFAG(x = 1) is often an ef.cient method of proving FG(x = 1). However, \nconsider the following program, where * represents nondeterministic choice: 1 x:=1; 2 while (*) { 3 skip; \n4 } 5 x:=0; 6 x:=1; 7 while (true) { 8 skip; 9 } In this case FG(x = 1) is valid, but unfortunately \nAFAG(x = 1) is not. FG(x = 1) is valid because, for every individual program trace, it is valid. For \nexample, if a trace never leaves the loop at line 2, then the property is valid because x = 1 before \nentering the loop. For the traces that do leave the loop, x = 1 will become true at the command on line \n6 and then remain true. The .CTL property is valid only if we can .nd a set of states that are eventually \nreached from the program s initial states such that AG(x = 1) holds. In this case no such set of states \nexists, and tools for .CTL veri.cation will return counterexamples to AFAG(x = 1) that seemingly have \nno relation to to the original property FG(x = 1). The heart of the problem is the nondeterministic choice \nbetween the transition from line 2 to 3, and the transition from line 2 to 5: when we are in the loop \nat line 2 we cannot know if we will eventually leave the loop or not. We struggle when trying to decide \nif a state at location 2 is the point at which x = 1 will be global true, as it is only after considering \na full program trace that we would know (i.e. in this case we need to be looking at sets of traces, not \nsets of states). We now illustrate the procedure in Figure 1 on this example. Let .L = FG(x = 1) and \nM be the example program from above. Our procedure approximates .L with APPROXIMATE(.L)= .C = AFAG(x \n= 1). As we described above, the program M does not respect the property .C. The counterexample . to \n.C in M is an in.nite tree which can be represented as a .nite graph of transitions between program locations: \n x := 1 In this graph pc = 5 indicates that the execution is at a state in which the program counter \nis at line 5. Our procedure uses REFINE to simultaneously symbolically simulate all possible paths through \nthis graph and try to unify them into a single path through M. In this case it would begin its execution \nby visiting .rst pc = 1 and then pc = 2, after which it would discover that, for all paths of the graph \nto represent the same path, it must unify pc = 5 and pc = 3, which cannot be done. Thus, in this case, \nthe .CTL counterexample . will be deemed spurious to the LTL property and the decision predicate (pc \n= 2, pc = 5) will be included in the O ' re.nement2. This decision predicate (pc = 2, pc = 5) characterizes \nthe choice: when pc = 2, will pc ' = 5 or not? Notice also that, in this particular case, the predicates \nselected are over program locations, but this is not true in general (see Example 10 in Section 5). The \nprocedure then uses DETERMINIZE to generate MO,which is effectively the cross product of M and a new \ntransition relation which updates a new prophecy variable . based on the valuations of the decision predicate \n(pc = 2, pc = 5): .s(pc)= 2 . s '(pc). 5 . s(.). 0 . s '(.)= s(.)- 1 . . . ..s(pc)= 2 . s '(pc)= 5 . \ns(.)= 0 . s '(.). Z . . . . s(pc). 2 . s '(.)= s(.). We might try to express MO in textual program code \nform as . := *; x:=1; while (*) {assume(. . 0); . := . -1; skip; } assume(. = 0); . := *; x:=0; x:=1; \nwhile (true) { skip; } This new prophecy variable . predicts the outcomes of the decision predicate (pc \n= 2, pc = 5). We initialize . to be an integer. For every given trace of the system, the concrete number \nchosen at the command . := * predicts the number of instances of the transition s(pc)= 2.s '(pc). 5 before \nwe see a transition s(pc)= 2.s '(pc)= 5. The choice of a negative number (e.g. -1)represents the case \nwhere the execution will never see a s(pc)= 2.s '(pc)= 5 transition (i.e. non-termination)3. Whenever \nthe program makes a transition s(pc)= 2 . s '(pc). 5 it knows that . . 0, because the prophecy made previously \ndoes not allow it. The program also ' decrements . whenever we see a s(pc)= 2 . s (pc). 5 transition, \nfor we know that (if we are going to see it at all) we are one step closer to seeing s(pc)= 2 . s '(pc)= \n5. If and when a 2 An additional decision predicate will also be returned by our procedure, but it is \nnot important for this example. 3 In later sections we use a special element . instead of negative numbers \nto represent non-termination, but for the purpose of this illustration negative numbers are easier. \n s(pc)= 2 . s '(pc)= 5 transition .nally occurs, we know that . = 0. The program then predicts how many \ns(pc)= 2.s '(pc). 5 transitions will be visited the next time around until seeing another s(pc)= 2 . \ns '(pc)= 5 transition (which will never occur in this example). Because the old prediction is not needed \nagain, we can re-use the same variable . for the new prophecy. With the prophecy variable . in place, \nthere is now a set of states where AG(x = 1) holds: {s |(s(.)< 0 . s(pc)= 2). s(pc)= 6} Furthermore we \ncan prove that this set of states is eventually reached. So we can now use .CTL where it previously failed. \nOn the second iteration of the procedure from Figure 1, no .CTL\u00adcounterexample will be found in MO and \nthus the LTL property .L has been proved of M. Note that if we remove the second x:=1 command from the \nexample, then the property .L is false. In this case the variable . will uniquely determine the number \nof iterations through the .rst loop, and the counterexample returned will instead involve the second \nloop. From this .CTL counterexample, we can construct a valid LTL counterexample. Preliminaries In the \nlater sections of this paper we de.ne each of the sub\u00adprocedures used in Figure 1 (i.e. APPROXIMATE in \nSection 3, DETERMINIZE in Section 4, etc). However, before moving to these more detailed descriptions \nwe must develop some terminology and de.nitions that will be shared later. More details on any of our \nformalities, including a Coq proof script, can be found in our com\u00adpanion technical report [16]. States, \nsets, relations. We assume a domain D of states and, in the context of programs, will often treat it \nas a mapping from variables V to values. We will let s and t range over states, and S represent a set \nof states. We assume that no two states are indistinguishable. R will often be used to represent relations. \nWhen R is represented symbolically (i.e. expressed as a formula) it will be over the unprimed variables \nV and primed variables V ' .Fora state predicate p, the meaning [p]S, is de.ned as the set of concrete \nstates that respect p. The relational meaning of a formula p over primed and unprimed variables, [p]R \nis de.ned in the usual way. When it is clear from the context that we mean the real relation as opposed \nto the symbolic formula representation, we will drop the []R brackets. The notations .1 and .2 mean the \n.rst and second projection, respectively, of a relation. In cases where we are representing programs \nwith control-.ow graphs we will assume that states include a variable pc that represents the program \ncounter and whose value is taken from a .nite domain L={e1, ..., en}. Transition systems. We de.ne a \nmachine M =(S, R, I) where I . S is the set of initial states and R . S \u00d7 S is the transition relation. \nIn this paper we will be constructing new systems by adding variables and equating them to their original \nversions. Thus, it is convenient to build in a notion of internal and external state = Sex \u00d7 Sin elements. \nWe assume that S (i.e. states consist of an external (visible) component and an internal component). \nWe refer to an individual state as .s, s in.. S and when a machine has no internal components, we omit \nthe .. brackets. Traces and paths. We de.ne a trace to be a sequence of states in in p =(.s0,s0 ., .s1,s1 \n., ...) in inin such that .s0,s0 .. I ..i = 0.(.si,si ., .si+1,si+1.) . R We denote traces(I,R) as the \nset of all such traces. For conve\u00adnience, we do not allow .nite traces the transition relation must \nbe such that every state s has at least one successor state. This is a(p0|ext) p .L .L . p .L .L p .L \n.L p .L .L p .L ap .L .L . .L p .L .L . .L .i = 0.pi .L .L .i = 0.pi .L .L p .L G.L p .L F.L .i = 0.pi \n.L .L ..j = 0.pj .L .L ..i < j.pi .L .L p .L .L W.L Figure 2: Semantics of LTL: .L a(s|ext) s .C .C s \n.C .C s .C .C . s .C .C s .C as .C .C . .C s .C .C . .C .(s0,s1, ...). traces(I,R)..i = 0.s0 = s . si \n.C .C s .C AF.C .(s0,s1, ...). traces(I,R)..i = 0.s0 = s . si .C .C s .C AG.C .(s0,s1, ...). traces(I,R). \n.i = 0.si .C .C ..j = 0.sj .C .C ..0 = i < j. si .C .C s .C A[.C W.C] Figure 3: Semantics of .CTL: .C \nwithout a loss of generality, as .nal states can be encoded as states that loop back to themselves in \nthe transition relation. With coin\u00adductive reasoning we can show that there exists an in.nite trace from \nevery state. We use the notation p|ext to denote the projection of p where internal components are removed: \nin in . (.s0,s0 ., .s1,s1 ., ...)|ext =(s0,s1, ...) traces(I,R)|ext is similarly de.ned. We say that \ntwo systems are trace equivalent, notationally ., if their sets of projected traces are equivalent. We \nde.ne an abstract trace to be a sequence of state abstractions. A path is a special case of an abstract \ntrace in which only the pc-valuations are given. A path or an abstract trace is spurious if there does \nnot exist a concrete trace from which we can construct the path via a projection. Decision predicate \nvector. Formally we will treat O as a vector of pairs. Each element in the decision predicate vector \nO is a predicate pair denoted (a, b). We will use the vector index i to refer to a particular pair within \nO,and ai,bi denote the components of the ith pair. We use the notation ai(s) to indicate that s is in \nthe set of states where ai holds (i.e. s . [ai]) and similar for bi(s).  3. APPROXIMATE: Proving LTL \nwith .CTL In this section we describe APPROXIMATE, which de.nes a sound over-approximation of LTL formulae \nwith formulae in .CTL. 3.1 Linear Temporal Logic (LTL) We use the following LTL grammar: .L ::= a | \n.L . .L | .L . .L | G.L | F.L | .L W.L We have not included U, R, X or \u00ac. Without loss of generality \nwe assume that negations appear only in atomic propositions (i.e. instances of \u00ac have been pushed to \nthe leaves of the formula). In the context of programs X is relatively useless and is easily subsumed \n . by F. U and R can be encoded as: .L U.L = F.L .(.L W.L) and . .L R.L = .L W(.L . .L). The LTL semantics, \nnotationally .L, are given in Figure 2. The notation pi indicates a suf.x of a trace starting at the \nith state in the sequence. We use p0 to denote the .rst element in p. The superscript binds tighter than \nthe subscript, i.e. p0 i =(pi)0. An atomic proposition a is from some abstract domain D,and we assume \nthat true, false . D and that D is closed under negation (i.e. .a . D. .\u00df . D. [\u00df]S = [\u00aca]S). The operator \nG.L speci.es that .L globally holds along all traces. The operator F.L speci.es that along every trace, \neventually a suf.x will be reached where .L holds. Finally, the .L W.L operator speci.es that .L holds \nforever or .L holds until .L holds. The LTL entailment relation .L is de.ned on traces: the relation \np .L .L indicates that .L holds for a given trace p. We now lift .L to machines. De.nition 3.1 (LTL Machine \nEntailment). Assume that M = (S, R, I). We de.ne LTL-entailment, notationally M .L .L,as .p . traces(I,R) \n.p .L .L  3.2 Computation Tree Logic (.CTL) We now review existential-free computation tree logic: .C \n::= a | .C . .C | .C . .C | AG.C | AF.C | A[.C W.C] The semantics of .CTL .C are given in Figure 3. Unlike \nthe trace\u00adbased LTL semantics, .CTL s semantics are state-based. By this we mean that the temporal operators \nare state-based in structure the derivation of a given formula is per-state and depends on the derivation \nof subformulae for subsequent states. The opera\u00adtor AG.C speci.es that .C globally holds in all reachable \nfuture states. The operator AF.C speci.es that across all computation sequences from the current state, \nthat there is a reachable state in which .C holds. Finally, the A[.C W.C] operator speci.es that .C holds \nin every state where .C does not hold yet. De.nition 3.2 (.CTL Machine Entailment). As we did for .L, \nwe lift .C to machines. Assume M =(S, R, I). We de.ne .CTL\u00adentailment, notationally M .C .C,tobe .s . \nI. R,s .L .L 3.3 Over-approximating LTL with .CTL We describe a simple syntactic conversion from a formula \nin LTL to its corresponding over-approximation in .CTL. De.nition 3.3. (APPROXIMATE) For all .L, APPROXIMATE(a) \n= a APPROXIMATE(.L . .L) = APPROXIMATE(.L) . APPROXIMATE(.L) APPROXIMATE(.L . .L) = APPROXIMATE(.L) . \nAPPROXIMATE(.L) APPROXIMATE(G.L) = AG APPROXIMATE(.L) APPROXIMATE(F.L) = AF APPROXIMATE(.L) APPROXIMATE(.L \nW .L) = A[APPROXIMATE(.L) W APPROXIMATE(.L)] Lemma 3.1. (.CTL Approximation) For a machine M and LTL \nproperty .L, M .C APPROXIMATE(.L). M .L .L Proof. By corresponding structural induction on the formulae \nAPPROXIMATE(.L) and .L. We .rst unlift .C and .L .Since traces is de.ned over I, we are free to pick \na state s . I such that s .C .C. We now pick a trace p . traces({s},R) and the appropriate case from \nthe CTL semantics. For example, in the DETERMINIZE((S, R, I), O)=(SO,RO,IO) where N. O S = S \u00d7 N: denoted \n.s, .. N. O I = I \u00d7 N: O ' R={(.s, .., .s ,. '.) | (s, s '). R ..(ai,bi). O. ' [ai(s). .i =1 . bi(s '). \n.i =1] (1) ' .[ai(s). .i > 0 . bi(s '). .i = .i - 1] (2) ' .[ai(s). .i = 0 .\u00acbi(s '). .i . N:] (3) ' \n.[\u00acai(s). .i = .i]} (4) . and N: = N .{1}. Figure 4: The DETERMINIZE procedure which, when given a vector \nof predicate pairs O, constructs the corresponding predicate\u00addeterminized machine. ' s .C AF.C case the \nuniversal quanti.cation tells us that for p =(s0,s1, ...) that .n.sn .C .C ' . By the inductive hypothe\u00adsis \nfor all p . traces({sn},R),wehavethat p .L .L ' . and thus we have established the criteria for p .L \nF.L ' . For further details, see our companion technical report [16].  4. DETERMINIZE: Decision Predicate \nDeterminization In this section we describe the procedure DETERMINIZE,which uses decision predicates \nas it performs a symbolic form of partial determinization. Partially determinized machines. Figure 4 \ncontains the de.nition for DETERMINIZE, which is designed to return a partially deter\u00adminized machine \nwhen given a vector of predicates O and a ma\u00adchine: MO = DETERMINIZE(M, O) The new machine MO includes \nadditional prophecy variables de\u00adnoted .i. These correspond to the predicate pairs (ai,bi) in the vector \nO. In accordance with IO these variables are free to be a positive integer or zero or 1 in the initial \nstate. We will see that the choice of initial values (and the choice in Eqn. 3 from Figure 4) is the \ndriving force behind determinization. For simplicity we used Z instead of N: in Section 2. We also now \nde.ne the update relation differently than we did in Section 2, in the sense that in Figure 4 the unprimed \nvariables appear only to the left of . and primed variables appear only to the right. While the two formalizations \nare equivalent, the encoding in Figure 4 is conceptually more op\u00aderational and easier to implement within \na tools setting, where in practice we are modifying the existing transition relation of M. Transitions \nin RO are made in accordance with R, but con\u00adstrained by the values of . when states are reached that \nmatch a de\u00adcision predicate (ai,bi) in O. Speci.cally, when a state is reached where ai holds and the \nprophecy variable .i =1,then bi must hold in the next state and .i is unchanged (Eqn. 1 of Figure 4). \nThis rule corresponds to behaviors where a ai(s) state is visited in.nitely often. Alternatively, if \n.i > 0 (Eqn. 2) then bi must also hold in the next state, except that .i is decremented. When .i reaches \nzero, then \u00acbi must hold in the next state and .i is free to take a new value from N:, starting the process \nall over (Eqn. 3). Finally, when ai doesn t hold of a particular state, .i is unchanged (Eqn. 4). The \nprophecy variables introduced here trade nondeterminism in the transition relation R for a larger, nondeterministic \nstate space. The state space nondeterminism is either determined at ma\u00adchine initialization by the initial \nchoice of values for . given by IO , and b =(x = 1). With these predicates we can construct the corre\u00ador \nelse later in a trace (Eqn. 3) by choosing new nondeterministic sponding MO .  values for .. This lazy \nselection of nondeterministic values means O S=[ that MO needn t consist of in.nitely many prophecy variables \nfor NN ]\u00d7 N: denoted .[ xy ] ,.. =.[ 00 ] , N:. powerful forms of nondeterminism, but we intend to use \nthis tech\u00ad nique in the context of programs for which countable nondetermin\u00adism is suf.cient. Theorem \n4.1. For all O, MO . M . Proof. The theorem holds if each of the conditions P1, P2, P3 and P4 and PB \ndescribed below are met. These conditions are a varia\u00adtion of Proposition 5 from Abadi and Lamport [3]. \nConditions P1, P2, P3 and P4 directly match Abadi and Lamport s conditions. We omit Condition P5 as it \ninvolves liveness restrictions on the behav\u00adior of machines and we assume that our machines have no liveness \nrestrictions. We loosen the restriction of Abadi and Lamport s P6 with PB (detailed below), as our prophecy \nvariables do not respect the condition of .nite nondeterminism. The new condition PB is in fact a consequence \nof P6: in the second part of the proof, Abadi and Lamport show that all the behaviors of M are contained \nwithin MO (note that regardless of superscript, P = M because L = true). Part 2.1 de.nes a directed graph, \nand then introduces Claim 2.1, which is not true in our setting. However, Claim 2.1 is only used in conjunction \nwith Claim 2.2 and K\u00a8 onig s Lemma in order to prove Claim 2.3. In our setting we have simply included \nClaim 2.3 as condition PB. We now describe why each condition holds: v (P1) SO . S \u00d7 SP for some SP . \nv (P2) IO = .-p 1(I) where .-p 1 maps S \u00d7 SO onto S. ' (P3) If ((s, p), (s ,p ')) . RO then (s, s '). \nR or s = s ' . This holds v by construction of RO from R. ' (P4) If (s, s '). R and (s ,p '). SO then \nthere exists p . SO such '' that ((s, p), (s ,p )) . RO. Again, this holds by construction of RO from \nR, case splitting on the value of p ' and quantifying v over i . O. (PB) For every (s0,s1, ...). traces(I,R) \nthere exists (p0,p1, ...) such that ((s0,p0), (s1,p1), ...). traces(IO,RO). Proof: Quantifying over each \ni =|O|, consider all of the (pos\u00ad sibly in.nitely many) transitions (sj ,sj+1) such that ai(sj ) holds. \nNow for each transition bi(sj+1) may or may not hold. This can be modeled by: m )8|*(b8 (.m. bi \u00acbii \n) )8|* i.e. a head (.m = 0.bim\u00acbiconsisting of repeated in\u00adstances of .nitely many bi-states and a single \n\u00acbi-state, and a tail consisting of in.nitely many bi-states. So we can choose .i accordingly, setting \n.i = m in each (potentially zero or in\u00ad.nitely many) instances of the head, and setting .i =1 in the \nv tail. Further details are available [16]. Example 5. (Nondeterministic Choice) Consider the following \nmachine: O R={(.[ 0 ] , 1. , .[ 1 ] , 0.) , (.[ 0 ] , 0. , .[ 0 ] , N:.) , 00 01 (.[ 1 ] , 0. , .[ 1 \n] , 0.) , (.[ 0 ] , N:. , .[ 0 ] , N:.)} 00 11 The .rst two transitions have now been determinized: from \nthe initial state, depending on the initial choice of ., either (x = 1) or \u00ac(x = 1) will hold in the \nnext state. In this example, since the nondeterministic transition only happens once, the (external) \nbehaviors when . > 1 or . =1 in the initial state are all equivalent to . = 1 in the initial state so, \nfor presentation purposes, we have omitted them. The additional behaviors will be used in the next example. \nExample 6. (Termination) Consider the following in.nite-state system which we represent symbolically \nS = N denoted x I = N ' '' R R = [(x > 0 . x = x + 1).(x > 0 . x = 0).(x = 0 . x = 0)] In this transition \nrelation, when x > 0 initially, there is nondeter\u00adminism in how many times the .rst transition is chosen \nbefore the second transition is chosen. We can determinize this with the pred\u00adicates a =(x > 0) and b \n=(x > 0), constructing the corresponding MO as follows: SO = N \u00d7 N: IO = N \u00d7 N: O '' R= [(x > 0 . . \n=1. x = x + 1 . . =1). '' (x > 0 . . > 0 . x = x + 1 . . = . - 1). '' (x > 0 . . = 0 . x = 0 . . . N:). \n'' R (x = 0 . . . N: . x = 0 . . . N:)] In MO the .rst choice of how many times a transition from [x \n> ' 0 . x = x + 1]R is taken is given by the choice of an initial value for .. Any .nite number of iterations \ncorresponds to an arbitrarily chosen numeric value of .. The case where the transition is taken in.nitely \nmany times corresponds to the initial choice of 1 for .. Example 7. (Running example) For the example \ngiven in Section 2, the state space of the original program is S ={e1, ..., e9}\u00d7{0, 1} denoted pc, x.For \nO ={(pc = e2, pc = e5)}, we have one prophecy variable denoted .,so SO = S \u00d7N: and IO ={e1}\u00d7{1}\u00d7N:.The \ntransition relation (omitting some uninteresting arcs) is de.ned as follows: O ' '' R= [(x = 1 . pc = \ne2 . . =1. x = 1 . pc = e2 . . =1). ' '' (x = 1 . pc = e2 . . > 0 . x = 1 . pc = e2 . . = . - 1). ' \n'' (x = 1 . pc = e2 . . = 0 . x = 1 . pc = e5 . . . N:). ...]R 4.1 Proving LTL with .CTL and determinization \nLemma 3.1 shows that one can prove LTL properties with an .CTL veri.er and an unmodi.ed transition relation. \nWe now extend this S =[ with .CTL and a predicate-determinized machine. I =[ 00 ] R ={([ 0 ] , [ 1 \n]) , ([ 0 ] , [ 0 ]) , ([ 1 ] , [ 1 ]) , ([ 0 ] , [ 0 ])} Theorem 4.2. (.CTL Approximation with Determinization) \nFor a 00 01 00 11 machine M, LTL property .L and predicates O, In this transition relation there is nondeterminism \nin the .rst transi\u00ad tion. We can determinize this with the predicates a =(x = 0.y = 0) MO .C APPROXIMATE(.L). \nM .L .L NN ] denoted [ yx ] to show that one can prove (perhaps even more) LTL properties Proof. Lemma \n3.1 says that M .C APPROXIMATE(.L). M .L .L The process of predicate determinization constructs machine \nMO from M such that MO . M. Since the two machines are trace equivalent and it is known that trace-equivalent \nmachines have the same LTL-behavior, Lemma 3.1 applies to the new machine and hence the theorem holds. \nFurther details are available [16].   5. REFINE: Decision Predicate Re.nement We now describe REFINE, \nour procedure which examines coun\u00adterexamples from a branching-time veri.cation tool and discov\u00aders predicates \nwhich characterize the nondeterministic branching within them if any nondeterminism exists. .CTL counterexamples. \nCounterexamples in .CTL are trees [13]. The shape of the tree depends on the shape of the property which \nis violated. While most tools typically do not annotate their coun\u00adterexamples with subformula, they \ncould be made to do so. We formalize an .CTL counterexample tree as follows: De.nition 5.1. (.CTL tree \ncounterexample) . ::= CEXa of p | CEX. of . | CEX. of . \u00d7 . | CEXAG of p \u00d7 . | CEXAF of p \u00d7 p \u00d7 . | CEXW \nof p \u00d7 . \u00d7 . In the above de.nition there is a constructor for each structural ele\u00adment of an .CTL formula. \nA counterexample to an atomic propo\u00adsition CEXa is a (single state) trace where the atomic proposition \ndoes not hold of the .rst element. A counterexample to a conjunc\u00adtion CEX. is a counterexample to one \nof the conjuncts. A coun\u00adterexample to a disjunction CEX. is comprised of two counterex\u00adamples, one for \neach disjunct. A counterexample CEXAG is a path to a state in which a counterexample exists for the subformula. \nA counterexample CEXAF is a stem path to an in.nite lasso loop where a counterexample exists for the \nsubformula. A counterexam\u00adple CEXW is a path to a state where a counterexample exists for both subformulae. \nFor example, the counterexample to the property AF((AGp).(AGq)) consists of a stem and loop (for the \nAF sub\u00adformula), and from within the loop a stem for each AG subformula. Equality . between counterexamples \nis inductively de.ned, lift\u00ading equality between traces. We denote by .|ext the counterexam\u00adple which \nconsists of the external projection of paths in all com\u00adponents. Often counterexamples from model checking \ntools may contain less information than actual concrete traces (e.g. SLAM returns abstract traces that \ninclude the valuations of pc together with the valuations of the predicates used during the failed proof \nattempt). In the AF rule, the counterexample is represented as a stem with an in.nitely-repeated lasso \npath, along which every sub\u00adtree is a counterexample to the subformula. In reality, not all coun\u00adterexamples \nto termination can be represented this way. There are some rare programs that do not terminate but whose \ncounterexam\u00adples cannot be represented as a in.nitely-repeated lasso path. For example: while (x > 0) \n{ y:=x; x:=x+1; while (y > 0) { y:=y-1; }} . {(a, b), (a, \u00acb)} such that R . [a . b ' . ]R ]R PSYNTHD(R, \nR ')=. and R ' . [a .\u00acb ' . \u00d8 if no such a, b exist . Figure 5: Speci.cation of PSYNTHD which, when given \nsymbolic representations of two relations, returns predicate pairs that distin\u00adguishes them. An implementation \nof this procedure is described in Section 6. REFINE(.): S := \u00d8 N := {n0} let G = cefg(.|ext) in while \ntrue do '' let N = {n | n . N ..(n,r, n '). G} in '' let T = {r | n . N ..n .(n,r, n ). G} in ' let O \n= .r,r ' .T PSYNTHD(r, r )in if O =\u00d8 then ' if N . S = S then return \u00d8 else N := N ' ' S := S . N else \nreturn O done Figure 6: The REFINE procedure walks down a counterexample .ow-graph, at each step simultaneously \nexploring all possible next steps. If any pair of possible next steps are distinguishable via a predicate \nfrom PSYNTHD then that predicate is immediately returned. cefg(n0,.) . = match . with| CEXa s N. (n0,Id, \nn0)| CEX. .1 N. cefg(n0,.1)| CEX. .1,.2 N. cefg(n0,.1). cefg(n0,.2)| CEXAG p, .1 N. cefgp(n0, nx). cefg(nx,.1)| \nCEXAF p, N. cefgp(n0, n1). cefgp (n1, n1 p, .1 ) . cefg(n1,.1)| CEXW p, .1 N. cefgp(n0, nx). cefg(nx,.1) \nwhere nx, n1 are fresh. ) . cefgp(n0, nx= {(ni,r, ni+1)| 0 = i <|p|.(p0i ,p0 i+1). [r]R} where each ni \nis fresh and nx = n|p| Figure 7: The cefg procedure consumes a counterexample and constructs a counterexample \n.ow graph, using cefgp to convert a path p to a graph component. In this case we assume an approximation \nof the real counterexam\u00adple has been found and has been encoded using CEXAF .Insome instances this could \npotentially lead to divergence in our tool. Counterexample control-.ow graphs. From a given counterex\u00adample \n., we can construct a corresponding counterexample .ow\u00adgraph (CEFG) G which represents all paths in the \ncounterexam\u00adple. We use a standard graph-based notation, where nodes n . N correspond to states in the \ncounterexample, and edges are triples(n1,r, n2) consisting of a starting node, a transition relation \nr from the counterexample and a destination node. Even when we are working with programs, these CEFGs \nare different from pro\u00adgram CFGs because they represent possible state transitions: there may be multiple \nCEFG transitions for a single CFG transition (e.g. when the program involves nondeterministic assignment) \nand there maybe multiple CEFG nodes which have the same CFG node. A counterexample .ow graph can be constructed \nfrom a counterex\u00adample via the translation shown in Figure 7.  Predicate synthesis. The procedure PSYNTHD(r, \nr ') is speci.ed in Figure 5. It consumes two transition relations R, R ' and returns two pairs of decision \npredicates: both (a, b) and (a, \u00acb).Wereturn both pairs because it is dif.cult to know apriori which \nwill be more useful to the LTL proving procedure, as the information tracked by (a, b) differs slightly \nfrom that tracked by (a, \u00acb). Moreover, there are cases where tracking only (a, b) will result in divergence, \nwhereas (a, \u00acb) does not. The details of the implementation of PSYNTHD will differ, depending on the \ncontext (i.e. .nite-state systems expressed at the bit-level, in.nite-state systems expressed over linear \narithmetic, etc). We assume that for a given domain D (a) that D is capable of distinguishing two states \nand (b) that PSYNTHD is capable of discovering suf.cient elements in D to do so. If these assumptions \ndo not hold then in some instances our technique may be unable to suf.ciently determinize. In our implementation, \ndescribed in Section 6, we use constraint-solving techniques to .nd predicates which are monomials over \nlinear inequalities. Symbolic tree execution. The recursive procedure REFINE,given in Figure 6, consumes \nan .CTL counterexample and returns a set of predicates which distinguish nondeterministic branching. \nThis involves .rst constructing a counterexample .ow-graph, and iter\u00adatively exploring the frontier. \nREFINE simultaneously steps down each possible branch of the counterexample, ensuring that all of the \nnext states are equivalent using PSYNTHD (see the PSYNTHD speci.cation in Figure 5) to .nd distinguishing \npredicates. When distinct states are found, the corresponding predicates are returned, so that they can \nbe added to O and the main algorithm can reiterate. Progress. We now show that for a given counterexample \n.,if REFINE discovers predicates, then our algorithm produces a new machine for which .|ext is not a \ncounterexample. We also show that, if no predicates are found by REFINE, then a real counterex\u00adample \nto the original LTL property can be constructed from .|ext. Lemma 5.1. (Counterexample elimination) For \na machine MO , property .L, if . is a counterexample to MO .C APPROXIMATE(.L) then . counterexample . \n' to MO ' .C APPROXIMATE(.L) such that .|ext . . '|ext where O ' = O . REFINE(.) and REFINE(.).\u00d8. Proof. \nLet (ai,bi). REFINE(.). By de.nition of REFINE in Fig\u00adure 6 this predicate pair must have come from a \nsubcomponent of ' ''). the counterexample . .ow graph of the form (n,r, n '), (n,r , n Moreover ai(.1(r)), \nbi(.2(r)) and \u00acbi(.2(r ')).Now,inthe new machine the prophecy vector is augmented with a new element \n.i. So the set of states denoted ..1(r),.. have either .i = 0 or .i . {1, 1, 2, ...}. According to RO \n' , either (..1(r),.., ..2(r),..) is enabled or else (..1(r),.., ..2(r '),..) is enabled, but not both. \nHence, there is no valid counterexample . ' such that .|ext . . '|ext. Further details are available \n[16]. Remark on completeness. There are a few impediments to mak\u00ading a completeness claim. First, for \na given .CTL counterexample ., the routine PSYNTHD must be able to discover predicates to characterize \nnondeterminism in .. However, since we use approx\u00adimation (e.g. with linear arithmetic), it will not \nalways be able to discover suf.cient predicates when they exist. Second, even when we have a perfect \nPSYNTHD routine, some .CTL counterexamples may be spurious, as the underlying .CTL also supports only \noverapproximation in linear arithmetic. Conse\u00adquently, when REFINE(.)=\u00d8 we cannot necessarily claim that \nwe have a valid LTL counterexample. Furthermore, as mentioned pre\u00adviously, there are some non-terminating \nprograms that do not have a in.nitely-repeated lasso path. In these instances, the .CTL tool itself will \neither hang or return spurious counterexamples. Finally, it is unclear whether our re.nement loop will \ndiscover a .nite number of decision predicates. With an in.nite predicate vec\u00adtor O8, all nondeterminism \ncan be represented (given a suf.cient predicate domain), but one would hope that for each program/prop\u00aderty \nthere is a .nite predicate vector. Example 8. (Running Example) For the example in Section 2, an .CTL \nprover may generate the following counterexample: (CEXAF [ 1 ]::[ 2 ] , [ 2 ]::[ 3 ]::[ 2 ] , CEXa [ \n5 ]) 11111 0 where a state is represented as [ pc ]. From this counterexample, x we use cefg to construct \nthe counterexample .ow-graph G given in Section 2. Each arc represents a possible transition within the \ncounterexample tree. the procedure REFINE then walks all possible paths of the control-.ow graph simultaneously, \nstarting from the .rst node as follows: Iteration 1: N ={n0}, S =\u00d8 Iteration 2: N ={n1}, S ={n0,n1} Iteration \n3: N ={n2,n3}, S ={n0,n1,n2,n3} After the .rst and second iterations PSYNTHD does not discover a predicate \nto distinguish the two branches, but after the third call to REFINE, the predicate pairs (pc = e2, pc \n= e3) and (pc = e2, pc . e3) are discovered, which distinguish paths that remain in the loop or exit \nthe loop. A new machine is then constructed with prophecy variables corresponding to these decisions, \nand for this new machine an .CTL veri.er can prove that the property holds. Example 9. Consider the following \nprogram for which we would like to prove .L =(FG y = 1).(F x = t): e0:x=y=0;t=*; while(*) e1: x++; e2:t=*; \ne3: if (x<t) e4: y=1; while (true) e5: skip; The machine representing this program can be encoded as \nfollows:  .. .. Figure 8: Counterexamples for each of the three iterations of proving Example 9. The \nnotation Id indicates the identity transition (arising from the loop at line e5). ' In this iteration, \nREFINE .nds that N ={n1,n2} and that R = c.e.x. 1 (CEX. (1CEXAF (2CEXAF [0 0 56 \u00a30 ]::[0 0 56 \u00a31 ] , \n. . . . x ' =x+1 y ' =y t ' =t pc ' =pc . . . . , (1CEXAG Id, (1CEXa [ x 0 56 \u00a31 ]))), [0 0 56 \u00a30 ]::[0 \n0 56 \u00a32 ]::[0 0 56 \u00a33 ]::[0 1 56 \u00a34 ]::[0 1 56 \u00a35 ] ,Id, (2CEXa [0 1 56 pc=\u00a35 ]))) c.e.x. 2 (CEX. (1CEXAF \n(2CEXAF [0 0 56 \u00a30 ]::[0 0 56 \u00a31 ] , . . . . x ' =x+1 y ' =y t ' =t pc ' =pc . . . . , (1CEXAG Id, (1CEXa \n[ x 0 56 \u00a31 ]))), [0 0 56 \u00a30 ]::[1 0 56 \u00a31 ]::[1 0 56 \u00a32 ]::[1 0 56 \u00a33 ]::[1 1 56 \u00a34 ]::[1 1 56 \u00a35 ] \n,Id, (2CEXa [1 1 56 \u00a35 ]))) .. .. c.e.x. 3 (CEX. (1CEXAF (2CEXAF [0 0 56 \u00a30 ]::[1 0 56 \u00a31 ]::[1 0 0 \u00a32 \n]::[1 0 0 \u00a33 ]::[1 0 0 \u00a35 ] ,Id, (1CEXAG Id, (1CEXa [1 0 0 \u00a35 ]))), [0 0 56 \u00a30 ]::[1 0 56 \u00a31 ]::[1 0 \n2 \u00a32 ]::[1 0 2 \u00a33 ]::[1 1 2 \u00a34 ]::[1 1 2 \u00a35 ] ,Id, (2CEXa [1 1 2 \u00a35 ])))  {(e0,e1), (e0,e2)}. Taking \nthe (only) pair of relations from R, PSYNTHD generates the predicate pairs (pc = e0, pc = e1) and(pc \n= e0, pc . e1). Corresponding prophecy variables are created, and the .CTL veri.er is used on the newly \nconstructed machine, resulting in the next counterexample in Figure 8. We then get the second counterexample \n.ow graph in Figure 9 and the REFINE explores it as follows: Iteration 1: N ={n0}, S =\u00d8 Iteration 2: \nN ={n1,n2}, S ={n0,n1,n2} After the .rst iteration, PSYNTHD does not discover any predicates to distinguish \nthe two branches, but after the second iteration the predicate pairs (pc = e1, pc = e1) and (pc = e1, \npc . e1) are discovered, which distinguish paths that remain in the loop or exit the loop. The .CTL veri.er \nis executed once again, resulting in the third counterexample in Figure 8. The counterexample .ow-graph \nFigure 9: The counterexample .ow graphs that are constructed at is given in Figure 9 and REFINE explores \nit as follows: each iteration of proving Example 9. Iteration 1: N ={n0}, S =\u00d8 Iteration 2: N ={n1,n5}, \nS ={n0,n1,n5} Iteration 3: N ={n2,n6}, S ={n0,n1,n5,n2,n6} Iteration 4: N ={n3,n7}, S ={n0,n1,n5,n2,n6,n3,n7} \n S =[ NNN L x y ] denoted [] I =[ t 00 N ] In the .nal iteration, PSYNTHD discovers the predicate pairs \n(pc = e2,t = x) and (pc = e2, t < x). Notice that the second predicate is pc \u00a30 ' ''' R = [(pc = e0 . \npc = e1 . x = x . y = y . t = t). ' ''' (pc = e0 . pc = e2 . x = x . y = y . t = t). '' '' (pc = e1 . \npc = e1 . x = x + 1 . y = y . t = t). '' '' (pc = e1 . pc = e2 . x = x + 1 . y = y . t = t). ' ''' (pc \n= e2 . pc = e3 . x = x . y = y . t . N). ' ''' (pc = e3 . pc = e4 . x < t . x = x . y = y . t = t). ' \n''' (pc = e3 . pc = e5 . x = t . x = x . y = y . t = t). ' ''' (pc = e4 . pc = e5 . x = x . y = 1 . t \n= t). ' ''' R (pc = e5 . pc = e5 . x = x . y = y . t = t)] Using an .CTL prover, we may obtain the .rst \ncounterexample in Figure 8. From this counterexample, we use cefg to construct the .rst counterexample \n.ow graph in Figure 9. Each arc represents a possible transition within the counterexample tree. The \nprocedure REFINE then walks all possible paths of the control-.ow graph simultaneously, starting from \nn0 as follows: Iteration 1: N ={n0}, S =\u00d8 over a program variable other than pc in the next example \nwe will see that pc is not always suf.cient to distinguish paths. Running the.CTL veri.er one more time \nyields no counterexamples. Hence the original LTL property holds. Example 10. In the examples above, \nalmost all predicates were over the program counter variable pc. In many cases, the program counter serves \nas a convenient way of distinguishing paths through the program. However, this is not always the case. \nConsider proving the property (G x = 0).(F x = 20) for the following program: C0:x=0; while(x<20) C1: \nx := (x==0)*{0,1} + (x==1)*20; while(true) C2: skip The notation {0,1} represents nondeterministic choice \nbetween 0 or 1. The LTL property holds because in traces where this non\u00addeterministic choice is always \n0, the property G x = 0 holds. For any trace in which the nondeterministic choice is 1, the property \nF x = 20 holds.  x We shall represent the state as [] where x . N.An .CTL \u00a3 prover will generate the \nfollowing counterexample to (AG x = 0).(AF x = 20): (CEX. (CEXAG [ 0 ] :: [ 0 ] :: [ 1 ] , (CEX. [ 1 \n])) \u00a30 \u00a31 \u00a31 \u00a31 (CEXAF [ 0 ] :: [ 0 ] :: [ 0 ] ,Id, (CEX. [ 0 ]))) \u00a30 \u00a31 \u00a31 \u00a31 For this counterexample \nREFINE would explore the corresponding CEFG, and discover the decision predicate pairs (x = 0, x = 1) \nand (x = 0, x . 1) which distinguish the transition ([ 0 ] , [ 1 ])from \u00a31 \u00a31 ([ 0 ] , [ 0 ]). Importantly, \nthere is no predicate over the program \u00a31 \u00a31 counter variable alone which distinguishes these two transitions. \nWe can now synthesize a prophecy variable corresponding to this decision predicate and an .CTL prover \nwill discover a proof of the.CTL property, implying that the original LTL property holds.  6. Implementation \nIn this section we discuss some details of our implementation of the algorithm in Figure 1, our implementation \nof an .CTL prover, and the results of our tool when applied to example programs. Predicate synthesis. \nIn Section 5, we have assumed the existence of a predicate synthesis mechanism PSYNTHD that met the con\u00adstraints \ngiven in Figure 5: . {(a, b), (a, \u00acb)} such that R . [a . b ' ]R . PSYNTHD(R, R ')=. and R ' . [a .\u00acb \n' ]R. \u00d8 if no such a, b exist . Depending on the con.guration of the systems considered by the tool, \nPSYNTHD will need to be implemented in different ways. Here we describe a particular method of synthesizing \npredicates for counterexamples drawn from the style of programs typically ac\u00adcepted by modern model checking \ntools for in.nite-state programs. As is true in many symbolic model checking tools for software, we will \nassume that counterexamples are sequences of commands drawn from a path in the program. We will assume \nthat these commands are over a .nite set of arithmetic variables, and that the conditional checks and \nassignment statements only use linear arithmetic. Given this context, an implementation can represent \nthe relations passed to PSYNTHD as conjunctions of inequalities using variables. For example, the command \nsequence e41 : x := x - 1; e21 : assume(x > 0); e10 : y := x; which might represent a piece of a counterexample \ncan be repre\u00adsented as a relation from valuations on (x, y, pc) to valuations on '' (x , y , pc ') where \n.x1, x0, y1, y0. ' '' .{ pc = e41 . pc = e10 . x = x0 . x = x1 . y = y0 . y = y1 } x1 = x0 - 1 . x1 > \n0 . y1 = x1 We can reduce the search for predicates in this setting to the search for functions satisfying \na set of constraints. In this instance we hope to .nd families of af.ne functions f and g such that the \nfollowing conditions are true 1. (.V ' .R1 ..V ' .R2)..i.dom(f) fi(V )> 0 2. R1 ..i.dom(g) gi(V ')> \n0 3. R2 .\u00ac(.i.dom(g) .gi(V ')> 0)  The set of pre-states common to both relations R1 and R2 are given \nS =.V ' .R1 ..V ' .R2, i.e. we are existentially quantifying out the post-states by quantifying out the \nvariables that are used to represent them. We then .nd an over-approximation of S that is expressible \nas the conjunction of inequalities using f. The second and third constraints force the function g which \nis expressed only over the primed variables to distinguish between two transitions. As done elsewhere \n[35], we can apply Farkas lemma [23] and an SMT solver (e.g. Z3 [2] or Yices [20]) to .nd linear functions \nfi and gi that satisfy the above constraints. Thus, to implement PSYNTHD(R1,R2) we .nd families f and \ng satisfying the above constraints. We then return the predicate pairs (a, b) and (a, \u00acb) where a =. \nfi(V )> 0 and b =. gi(V )> 0 i.dom(f) i.dom(g) A witness to .V ' .R1 ..V ' .R2 can be computed using \na quanti.er elimination procedure, or alternatively, an additional application of Farkas lemma. In practice, \nhowever, a good guess is simply to take the valuation of pc from both R1 and R2, i.e. S = pc = e,where \nR1 . pc = e and R2 . pc = e. Proving .CTL for in.nite-state systems. We use .CTL veri.\u00adcation tool for \nin.nite-state programs, described elsewhere [17]. Our .CTL prover works by reducing the task of .CTL \nveri.ca\u00adtion, via a program transformation, to an interprocedural program analysis problem. Thus, we \ncan use known safety analysis tools [5, 11, 19, 26] combined with techniques for re.ning termination \narguments [7, 8, 18, 22, 37] to obtain an .CTL veri.cation tool whose power is limited only by the power \nof these underlying tools. The transformation uses recursion and nondeterminism in such a way that when \nthese tools are applied to the transformed pro\u00adgram, they effectively perform the necessary reasoning \n(e.g back\u00adtracking, eventuality checking, tree counterexamples, abstraction, abstraction-re.nement, etc.) \nto prove branching-time behaviors of the original program. Formally, our transformation T worksasfol\u00adlows: \nFor a program P and an .CTL property .C, .M. T(P, M,.C) cannot return false . P .C .C where M is assumed \nto be a .nite set of disjunctively well-founded relations [36]. The new program T(P, M,.C) is constructed \nby recursively walking the structure of .C. Instances of AF(p) is syntactically decomposed into proving \ntermination to a set of states in which p holds; AG(p) can be decomposed into checking that p holds at \neach line of the program, etc. M can be thought of as the argument of progress when proving .C. Once \na suitable setM has been found, proving that T(P, M,.C) cannot return false can be accomplished with \nexisting interprocedural analysis tools. Satisfying instances of M can be found using the same technique \nas is used in TERMINATOR [18]. In our implementation we use SLAM [5] as the underlying safety prover, \nand RANKFINDER [35] as the method of .nding new ranking functions f from spurious counterexamples .. \nExperiments. We have drawn out a set of LTL challenge prob\u00adlems from industrial code bases. Examples \nwere taken from code models of the I/O subsystem of the Windows kernel, the back-end infrastructure of \nthe PostgreSQL database server, and the Apache web server. We also include a few toy examples, as well \nas the ex\u00adample from Figure 8 in [15]. Further details on our benchmarks, including sources are available \nin our companion technical re\u00adport [16]. In many cases, heap-commands from the original sources have \nbeen abstracted away using the approach due to Magill et al. [30]. This abstraction introduces new arithmetic \nvariables that track the sizes of recursive predicate found as a byproduct of a successful memory safety \nanalysis using an abstract domain based on separa\u00adtion logic. This abstraction also may introduce extra \nnondetermin\u00adism into the transition relation which, in more complex cases, may force our method to synthesize \ndecision predicates.  Program LOC Property Fair termination tool [15] Time (s) |M| Result Decision predicates \ntool (Figure 1) Time (s) |M| |O| Result Example from Section 2 5 FGp 2.32 1 . 1.98 1 1 . Example from \nFig. 8 of [15] 34 G(p . Fq) 209.64 1 . 27.94 0 0 . Toy acquire/release example 14 G(p . Fq) 103.48 3 \n. 14.18 1 0 . Toy linear arith. 1 13 p . Fq 126.86 1 . 34.51 1 0 . Toy linear arith. 2 13 p . Fq T.O. \n1+ ??? 6.74 1 0 . PostgreSQL strmsrv 259 G(p . FGq) T.O. 5+ ??? 9.56 0 0 . PostgreSQL strmsrv+bug 259 \nG(p . FGq) 87.31 0 . 47.16 1 0 . PostgreSQL pgarch 61 FGp 31.50 2 . 15.20 0 0 . PostgreSQL dropbuf 152 \nGp T.O. 2+ ??? 1.14 0 0 . PostgreSQL dropbuf 152 G(p . Fq) 53.99 1 . 27.54 2 0 . Apache accept() liveness \n314 Gp . GFq T.O. 1+ ??? 197.41 1 2 . Apache progress 314 G(p .(Fq1 . Fq2)) 685.34 0 . 684.24 0 0 . Windows \nOS fragment 1 180 G(p . Fq) 901.81 2 . 539.00 2 0 . Windows OS fragment 2 158 FGp 16.47 0 . 52.10 3 3 \n. Windows OS fragment 2+bug 158 FGp 26.15 0 . 30.37 0 0 . Windows OS fragment 3 14 FGp 4.21 0 . 15.75 \n1 1 . Windows OS fragment 4 327 G(p . Fq) T.O. 7+ ??? 1,114.18 1 0 . Windows OS fragment 4 327 (Fa).(Fb) \n1,223.96 5 . 100.68 1 0 . Windows OS fragment 5 648 G(p . Fq) T.O. 1+ ??? T.O. 0 0 ??? Windows OS fragment \n6 13 FGp 149.41 2 . 59.56 1 0 . Windows OS fragment 6+bug 13 FGp 6.06 0 . 22.12 0 0 . Windows OS fragment \n7 13 GFp T.O. 1+ ??? 55.77 1 0 . Windows OS fragment 8 181 FGp T.O. 1+ ??? 5.24 1 0 . Table 1: Comparison \nof fair termination based LTL prover [15] to decision predicate based algorithm from Figure 1 . Examples \ndrawn from PostgreSQL database server, Apache web server, as well as the I/O subsystem of the Windows \nOS. The property column indicates the shape of the temporal properties, where p and q are atomic propositions \nspeci.c to the program. A . indicates that the tool has proved the property, whereas a . indicates that \na valid LTL counterexample has been found. |O| indicates the number of decision predicates needed, and \n|M| the number of progress measures required. T.O. indicates that the experiment timed out after 4 hours, \nand in such cases we specify at least how many termination arguments were needed (denoted +). The only \npreviously known tool for automatically proving LTL\u00adlike properties of in.nite-state programs is described \nin [15], which is a TERMINATOR-like [18] procedure with an extension for fair\u00adness. LTL2BA [24] is used \nto convert LTL formulae to B\u00a8uchi au\u00adtomata. As we have done in our implementation of Figure 1, the implementation \nof [15] uses SLAM as the underlying safety model checker,and RANKFINDER[35]astherankfunctionsynthesistool. \nTable 1 reports the results of our experiments. The .rst column describes the code artifact. We added \nbugs into several of the examples. The second column LOC reports the number of lines of code for each \nexample. We studied the results for properties of differing shapes (e.g. G(p . Fq), FGp, GFp, etc.). \nExperiments were run using Windows Vista and an Intel 2.66GHz processor. For both tools we report the \ntotal time, the number of ranking functions required (denoted |M|), and the result for each of the benchmarks. \nA . indicates that the tool proved the property, and . is used to denote cases where bugs were found. \nIn the case that the tool exceeded the timeout threshold of 4 hours, T.O. isused to represent the time, \nthe result is listed as ??? , and we simply report the current size of |M| at the time that the tool \nwas killed together with a + symbol. For our approach we report the number of decision predicates required \n|O|. For these examples relatively few prophecy variables are usually required. This con.rms our assumption \nthat faster CTL\u00adbased techniques usually work, so long as we have a fast method for evaluating the potential \nspuriousness of CTL counterexamples, and an effective strategy of re.nement when CTL methods fail. We \nalso observe that |M| is typically smaller when using the decision predicates based tool. We implemented \nsupport for fairness in our decision predicate based approach tool in order to support Figure 8 of [15]. \nThis is due to the fact that one of the fairness constraints actually comes from an environment assumption \nand thus must still be modeled. Our support for fairness uses essentially the same recipe as given in \n[15], combined with the source-to-source transformation. As mentioned in Section 1, a limitation to our \napproach is that there are cases when we see a minor performance penalty for our strategy of only tracking \ncorrelations on demand (e.g. in Windows OS fragment 2. ) We also see some minor overhead when comput\u00ading \nreal counterexamples (e.g. in Windows OS fragment 2+bug ). The most dramatic aspect of Table 1 is the \noverall result: our decision predicate based LTL prover was able to prove/disprove all but 1 example \nin usually a fraction of a minute, whereas the fair termination based tool fails on nearly a quarter \nof the benchmarks. This is due to our strategy of .rst trying to use .CTL proof strate\u00adgies, and only \ntracking subtle relationships between families of traces on demand using decision predicates. Without \nour approach we could not reliably use an .CTL-based proof strategy with pre\u00adcision equal to native LTL-based \napproaches. In each of these T.O. cases but one our decision predicate based tool proves all of the ex\u00adamples \nwith reasonable runtimes (resulting in a .). Furthermore, our tool reported no spurious counterexamples: \nin the cases where a purely .CTL-based approach would have been incomplete for LTL (resulting in a spurious \ncounterexample), our re.nement pro\u00adcedure quickly found and then symbolically shifted the problematic \nnondeterminism into the state-space of the system.  7. Conclusion We have described a new algorithm \nfor proving LTL properties of in.nite-state systems. Our algorithm searches for instances of nondeterminism \nthat preclude the use of CTL-based proof methods. We characterize these instances of nondeterminism using \ndecision predicates, and then symbolically shift them into the state-space using a partial-determinization \nprocedure. The advantage to this approach is that CTL proof methods can be used where they would have \npreviously failed. We .nd in practice that most instances of nondeterminism is harmless to CTL proof \nmethods. Thus, in many cases, we see performance improvements when using this strategy. Acknowledgments. \nWe thank Josh Berdine, Matko Botin.can, Axel Legay, Peter O Hearn, Matthew Parkinson, Nir Piterman, Moshe \nVardi and Hongseok Yang for their comments and thought\u00adful discussions. Stephen Magill provided several \nof the examples from Table 1. We also thank the Gates Cambridge Scholarship program for funding Eric \nKoskinen s Ph.D.  References [1] Cadence SMV. http://www.kenmcmil.com/smv.html. [2] The Z3 Theorem Prover. \nresearch.microsoft.com/projects/Z3. [3] ABADI,M., AND LAMPORT, L. The existence of re.nement map\u00adpings. \nTheoretical Computer Science 82, 2 (1991), 253 284. [4] ABDULLA, P. A., JONSSON,B., NILSSON,M., D ORSO,J., \nAND SAKSENA, M. Regular model checking for LTL(MSO). In CAV (2004). [5] BALL,T., BOUNIMOVA,E., COOK,B., \nLEVIN,V., LICHTENBERG, J., MCGARVEY,C., ONDRUSEK,B., RAJAMANI, S., AND US-TUNER, A. Thorough static analysis \nof device drivers. ACM SIGOPS Operating Systems Review 40, 4 (2006), 85. [6] BOUAJJANI, A., LEGAY, A., \nAND WOLPER, P. Handling liveness properties in (.-) regular model checking. Electronic Notes in Theo\u00adretical \nComputer Science 138, 3 (2005), 101 115. [7] BRADLEY, A., MANNA,Z., AND SIPMA, H. Termination of polyno\u00admial \nprograms. In VMCAI (2005). [8] BRADLEY,A. R., MANNA,Z., AND SIPMA, H. B. Linear ranking with reachability. \nIn CAV (2005). [9] BURCH,J., CLARKE,E., MCMILLAN, K., DILL, D., AND HWANG, L. Symbolic model checking: \n10 to the 20 states and beyond. Infor\u00admation and Computation 98, 2 (1992). [10] CLARKE,E., EMERSON,E., \nAND SISTLA, A. Automatic veri.cation of .nite-state concurrent systems using temporal logic speci.cations. \nTOPLAS 8, 2 (1986), 263. [11] CLARKE,E., GRUMBERG, O., JHA, S., LU,Y., AND VEITH,H. Counterexample-guided \nabstraction re.nement for symbolic model checking. JACM 50, 5 (2003), 794. [12] CLARKE,E., GRUMBERG, \nO., AND PELED,D. Model checking. Springer, 1999. [13] CLARKE,E., JHA, S., LU,Y., AND VEITH, H. Tree-like \ncounterex\u00adamples in model checking. In LICS (2002). [14] CLARKE,E.M., GRUMBERG, O., AND HAMAGUCHI, K. \nAnother look at LTL model checking. Form. Methods Syst. Des. 10, 1 (1997), 47 71. [15] COOK,B., GOTSMAN, \nA., PODELSKI, A., RYBALCHENKO, A., AND VARDI, M. Y. Proving that programs eventually do something good. \nIn POPL (2007). [16] COOK,B., AND KOSKINEN, E. Making prophecies with decision predicates. Tech. Rep. \nUCAM-CL-TR-789, University of Cambridge, Computer Laboratory, Jan. 2011. [17] COOK,B., KOSKINEN,E., AND \nVARDI, M. Branching-time rea\u00adsoning for programs. Tech. Rep. UCAM-CL-TR-788, University of Cambridge, \nComputer Laboratory, Jan. 2011. [18] COOK,B., PODELSKI, A., AND RYBALCHENKO, A. Termination proofs for \nsystems code. In PLDI (2006). [19] COUSOT,P., COUSOT,R., FERET,J., MAUBORGNE,L., MINE\u00b4, A., MONNIAUX, \nD., AND RIVAL, X. The ASTREE analyzer. In ESOP (2005). [20] DUTERTRE,B., AND DE MOURA, L. M. A fast linear-arithmetic \nsolver for dpll(t). In CAV (2006), T. Ball and R. B. Jones, Eds., vol. 4144 of LNCS, Springer, pp. 81 \n94. [21] ESPARZA,J., KUCERA, A., AND SCHWOON, S. Model-checking LTL with regular valuations for pushdown \nsystems. In TACS (2001). [22] FANG,Y., PITERMAN, N., PNUELI, A., AND ZUCK, L. Liveness with invisible \nranking. International Journal on Software Tools for Technology Transfer (STTT) 8, 3 (2006), 261 279. \n[23] FARKAS, J. Uber die theorie der einfachen ungleichungen. Journal fur die Reine und Angewandte Mathematik \n124 (1902), 1 27. [24] GASTIN,P., AND ODDOUX, D. Fast LTL to B\u00a8uchi automata transla\u00adtion. In CAV (July \n2001). [25] HAVELUND, K., AND PRESSBURGER, T. Model checking Java pro\u00adgrams using Java path.nder. International \nJournal on Software Tools for Technology Transfer (STTT) 2, 4 (2000), 366 381. [26] HENZINGER, T. A., \nJHALA,R., MAJUMDAR,R., NECULA,G.C., SUTRE, G., AND WEIMER, W. Temporal-safety proofs for systems code. \nIn CAV (2002). [27] HOBOR, A., APPEL,A.W., AND NARDELLI, F. Z. Oracle semantics for concurrent separation \nlogic. In ESOP (2008). [28] HOLZMANN, G. J. The model checker SPIN. IEEE Trans. Software Eng. 23, 5 (1997), \n279 295. [29] KWIATKOWSKA,M., NORMAN, G., AND PARKER,D. PRISM: Probabilistic symbolic model checker. \nLNCS 2324 (2002), 200 204. [30] MAGILL, S., BERDINE,J., CLARKE,E., AND COOK, B. Arithmetic strengthening \nfor shape analysis. LNCS 4634 (2007), 419. [31] MAIDL,M.ThecommonfragmentofCTLandLTL.In FOCS (2000). \n[32] NAIN, S., AND VARDI, M. Branching vs. linear time: Semantical perspective. In ATVA (2007). [33] \nPNUELI, A. The temporal logic of programs. In 18th Annual Sympo\u00adsium on Foundations of Computer Science \n(1977), IEEE, pp. 46 57. [34] PNUELI, A., AND ZAKS, A. PSL model checking and run-time veri.cation via \ntesters. In FM (2006), J. Misra, T. Nipkow, and E. Sekerinski, Eds., vol. 4085 of LNCS, Springer, pp. \n573 586. [35] PODELSKI, A., AND RYBALCHENKO, A. A Complete Method for the Synthesis of Linear Ranking \nFunctions. LNCS (2003), 239 251. [36] PODELSKI, A., AND RYBALCHENKO, A. Transition invariants. In LICS \n(2004), pp. 32 41. [37] PODELSKI, A., AND RYBALCHENKO, A. ARMC: the logical choice for software model \nchecking with abstraction re.nement. In PADL (2007). [38] QADEER, S., SEZGIN, A., AND TASIRAN, S. Back \nand forth: Prophecy variables for static veri.cation of concurrent programs. Tech. Rep. MSR-TR-2009-142, \nMicrosoft, 2009. [39] SAFRA, S. On the complexity of omega -automata. In SFCS (1988). [40] SANKARANARAYANAN, \nS., SIPMA, H., AND MANNA,Z. Constraint-based linear-relations analysis. In SAS (2004). [41] SCHNEIDER, \nK. Model checking on product structures. FMCAD (1998). [42] SCHUPPAN,V., AND BIERE, A. Liveness checking \nas safety checking for in.nite state spaces. In Workshop on Veri.cation of In.nite-State Systems (INFINITY) \n(2005). [43] VARDHAN, A., SEN, K., VISWANATHAN,M., AND AGHA,G. Using language inference to verify Omega-regular \nproperties. In TACAS (2005). [44] VARDI, M. Branching time vs. linear time: Final showdown. In TACAS \n(2001). [45] VARDI,M.Y., AND WOLPER, P. An automata-theoretic approach to automatic program veri.cation \n(preliminary report). In LICS (1986).  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>We describe a new algorithm for proving temporal properties expressed in LTL of infinite-state programs. Our approach takes advantage of the fact that LTL properties can often be proved more efficiently using techniques usually associated with the branching-time logic CTL than they can with native LTL algorithms. The caveat is that, in certain instances, nondeterminism in the system's transition relation can cause CTL methods to report counter examples that are spurious with respect to the original LTL formula. To address this problem we describe an algorithm that, as it attempts to apply CTL proof methods, finds and then removes problematic nondeterminism via an analysis on the potentially spurious counterexamples. Problematic nondeterminism is characterized using <i>decision predicates</i>, and removed using a partial, symbolic determinization procedure which introduces new prophecy variables to predict the future outcome of these choices. We demonstrate---using examples taken from the PostgreSQL database server, Apache web server, and Windows OS kernel---that our method can yield enormous performance improvements in comparison to known tools, allowing us to automatically prove properties of programs where we could not prove them before.</p>", "authors": [{"name": "Byron Cook", "author_profile_id": "81323489213", "affiliation": "Microsoft Research &#38; Queen Mary, University of London, Cambridge, United Kingdom", "person_id": "P2509639", "email_address": "bycook@microsoft.com", "orcid_id": ""}, {"name": "Eric Koskinen", "author_profile_id": "81350575010", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509640", "email_address": "ejk39@cam.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926431", "year": "2011", "article_id": "1926431", "conference": "POPL", "title": "Making prophecies with decision predicates", "url": "http://dl.acm.org/citation.cfm?id=1926431"}