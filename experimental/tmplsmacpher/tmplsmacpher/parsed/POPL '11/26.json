{"article_publication_date": "01-26-2011", "fulltext": "\n Automating String Processing in Spreadsheets Using Input-Output Examples Sumit Gulwani Microsoft Research, \nRedmond, WA, USA sumitg@microsoft.com Abstract We describe the design of a string programming/expression \nlan\u00adguage that supports restricted forms of regular expressions, condi\u00adtionals and loops. The language \nis expressive enough to represent a wide variety of string manipulation tasks that end-users struggle \nwith. We describe an algorithm based on several novel concepts for synthesizing a desired program in \nthis language from input-output examples. The synthesis algorithm is very ef.cient taking a fraction \nof a second for various benchmark examples. The synthesis algo\u00adrithm is interactive and has several desirable \nfeatures: it can rank multiple solutions and has fast convergence, it can detect noise in the user input, \nand it supports an active interaction model wherein the user is prompted to provide outputs on inputs \nthat may have multiple computational interpretations. The algorithm has been implemented as an interactive \nadd-in for Microsoft Excel spreadsheet system. The prototype tool has met the golden test -it has synthesized \npart of itself, and has been used to solve problems beyond author s imagination. Categories and Subject \nDescriptors D.1.2 [Programming Tech\u00adniques]: Automatic Programming; I.2.2 [Arti.cial Intelligence]: Program \nSynthesis General Terms Algorithms, Human Factors Keywords Program Synthesis, User Intent, Programming \nby Ex\u00adample (PBE), Version Space Algebra, Spreadsheet Programming, String Manipulation 1. Introduction \nMore than 500 million people worldwide use spreadsheets. These business end-users have myriad diverse \nbackgrounds and include commodity traders, graphic designers, chemists, human resource managers, .nance \npros, marketing managers, underwriters, com\u00adpliance of.cers, and even mailroom clerks they are not profes\u00adsional \nprogrammers, but they need to create small, often one-off, applications to support business functions \n[5]. Unfortunately, the state of art in spreadsheet programming is far from satisfactory. Spreadsheet \nsystems come with tons of fea\u00adtures, but end-users struggle to .nd the correct feature or succes\u00adsion \nof commands to use from a maze of features to accomplish Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to \nlists, requires prior speci.c permission and/or a fee. PoPL 11, January 26 28, 2011, Austin, Texas, USA. \nCopyright c . 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 their task [9]. More signi.cantly, programming \nis still required to perform tedious and repetitive tasks such as transforming entities like names/phone-numbers/dates \nfrom one format to another, data cleansing, extracting data from several text .les or web pages into \na single document, etc. Spreadsheet systems like Microsoft Excel allow users to write macros using a \nrich inbuilt library of string and numerical functions, or to write arbitrary scripts using a variety \nof programming languages like Visual Basic, or .Net. Since end-users are not pro.cient in programming, \nthey .nd it too dif.cult to write desired macros or scripts. We have performed an extensive case study \nof spreadsheet help forums and identi.ed that string processing is one of the most common class of programming \nproblems that end-users struggle with. This is not surprising given that languages like Perl, Awk, Python \ncame into existence to support string/text processing, and that new languages like Java/C# provide a \nrich support for string processing. During our study of help forums, we also carefully studied how these \nusers were describing the speci.cation of the desired program to the experts on the other side of the \nhelp forums. It turns out that the most common form of speci.cation was input\u00adoutput examples. Since \ninput-output examples may lead to under\u00adspeci.cation, the interaction between the user and the expert \noften involved a few rounds of communication (over multiple days). We describe a program synthesis system \nthat is capable of syn\u00adthesizing a wide range of string processing programs in spread\u00adsheets from input-output \nexamples. The synthesizer aims to replace the role of the forum expert, which not only removes a human \nfrom the loop, but also enables users to solve their problems in a few seconds as opposed to a few days. \nOur synthesis system, which is deployment ready, has the following important usability proper\u00adties. \u00b7 \nFully Automated: We do not require non-sophisticated end\u00adusers to provide annotations/hints of any form. \n \u00b7 Real Time: Our system takes less than 0.1 second on average per interactive round. \u00b7 Easy Interaction: \nProgramming by examples is an interactive process where examples are added in each round to make the \nspeci.cation more precise. Our system helps identify the inputs for which the user should provide examples. \n \u00b7 Fast Convergence: Our system typically takes 1-4 rounds of iteration for convergence in practice. \n \u00b7 Noise Handling: If the user makes a small mistake in mostly correct speci.cation, our system can still \ncompute the likely solution and report the likely mistake.  This paper makes the following contributions. \n1. We describe a string programming/expression language that is expressive enough to represent a wide \nvariety of string manipu\u00adlation tasks found during an extensive study of Excel online help forums, while \nat the same time also being restrictive enough to enable ef.cient program search over that space (Section \n3).  2. We describe an algorithm with several novel concepts that can ef.ciently synthesize a set of \nprograms in our language that are consistent with a given set of input-output examples (Section 4). \n3. We describe extensions to the above algorithm that enable sev\u00aderal usability properties (Section 5). \n 4. We discuss our experience with a ready-to-be-deployed proto\u00adtype tool (Section 6).  2. Problem De.nition \nWe start out by describing a representative case-study, picked up from an online Excel help forum, that \nillustrates a typical interac\u00adtion between a user and an expert on help forums. We then use it to motivate \nthe key technical problem that we address in this paper. EXAMPLE 1. The user intends to extract the following \nbold sub\u00adstrings from the respective strings: 1. John DOE 3 Data [TS]865-000-0000 --453442-00 06-23-2009 \n 2. A FF MARILYN 30 S 865-000-0030 4535871-00 07-07-2009 3. A GEDA-MARY 100MG 865-001-0020 --5941-00 \n06-23-2009 The user initially provides a few examples to the expert that are similar to the .rst example \nabove. The expert provides a program P1 that uses the logic of extracting 12 characters after the .rst \noccurrence of ] . The user runs program P1 on other inputs in her spreadsheet and observes that it does \nnot perform the desired extraction for the second example above and then presents that to the expert. \nThe expert then provides a program P2 that uses the logic of .nding the .rst occurrence of - and extracting \n3 characters on left of it and 8 characters on right of it. The user runs program P2 on her spreadsheet \nand observes that it does not perform the desired extraction for the third example above and then presents \nthat to the expert. The expert then provides a program P3 that uses the logic of .nding the .rst occurrence \nof a pattern of the form ???-????-??? , where ? is supposed to match any character.  The user runs program \nP3 on her spreadsheet and is satis.ed with the produced results, and the thread is closed. One might \nwonder why did the expert not suggest a program P4 which is similar to P3, but ? is supposed to match \nany digit as op\u00adposed to any character. Or why did the expert not suggest a program P5 which is similar \nto P3, but the .rst three occurrences of ? are forced to match only 865. Even though programs P3, P4 \nand P5 are semantically different, these programs may not yield different outputs on the inputs the user \nhas in her spreadsheet. Hence these programs are observationally equivalent over the format of the in\u00adputs \npresent in the spreadsheet. We draw the following conclusions from this representative case study. First, \nthe user is communicating her intent using input\u00adoutput examples. Second, the user cannot be expected \nto provide representative inputs in the .rst round. Hence, an example based synthesis system must be \ninteractive. However, in order to remain usable, the system should allow the user to interact easily \nand converge quickly (i.e., in a few rounds) to the desired intent [10]. In this paper, we describe such \na program synthesis system. We present an algorithm for synthesizing string manipulation programs that \nare consistent with input-output examples. We also describe how the algorithm can be extended to enable \neasy interaction and fast convergence. 3. Expression Language for String Manipulation We have identi.ed \na string expression language that is expressive enough to describe various string manipulation tasks \nsuccinctly, while at the same time concise enough to be amenable for ef.cient learning. There is a tradeoff \nbetween the expressiveness of a search space, and the complexity of .nding simple consistent hypotheses \nwithin that space [6, 18]. In general, the more expressive a search space, the harder the task of .nding \nconsistent hypotheses within that search space. However, it is also worth-mentioning that the expressiveness-complexity \ntradeoff is not as simple as it seems, as an expressive language can sometimes make a simple theory .t \nthe data, whereas restricting the expressiveness of the language means that any consistent theory must \nbe very complex. Our string expres\u00adsion language seems to enjoy the right tradeoff. We present a core \nversion of this language; extensions that enable easy adaptation of the underlying algorithm are mentioned \nlater in Section 4.7.1. The syntax and semantics of the string expressions P is for\u00admally described \nin Figure 1 and Figure 2 respectively. We use the notation E to denote an empty string and . to denote \nan unde.ned value. If any of the arguments to any constructor is ., then it re\u00adturns .. The notation \n8[t1 : t2] denotes the substring of 8 starting at location t1 and ending at location t2. The string expressions \nP map an input state 0, which holds values for m string variables V1, \u00b7\u00b7,Vr (denoting the multiple input \ncolumns in a spreadsheet), to a single output string 8. P :(String \u00d7 ... \u00d7 String) . String The above \nformalism can also be used for string processing tasks that require generating a tuple of n strings as \nan output by simply solving n independent problems. A trace expression refers to the Concatenate(f1, \n\u00b7\u00b7, fn) con\u00adstructor, which denotes the string obtained by concatenating the strings represented by f1, \nf2, \u00b7\u00b7, fn in that order. An atomic expres\u00adsion refers to ConstStr (denoting a constant string), SubStr \nor Loop constructors, which are explained below. 3.1 Substrings The SubStr(Vi, p1, p2) constructor makes \nuse of two position ex\u00adpressions p1 and p2, each of which evaluates to an index within the string Vi. \nSubStr(Vi, p1, p2) denotes the substring of string Vi that starts at index speci.ed by p1 and ends at \nindex speci.ed by p2 -1. If either of p1 or p2 refer to an index that is outside the range of string \nVi, then the SubStr constructor returns .. The position expression CPos(k) refers to the kth index in \na given string from the left side (or right side), if the integer constant k is non-negative (or negative). \nPos(r1, r2, c) is another position constructor, where r1 and r2 are some regular expressions and integer \nexpression c evaluates to a non-zero integer. The Pos constructor evaluates to an index t in a given \nstring 8 such that r1 matches some suf.x of 8[0 : t-1] and r2 matches some pre.x of 8[t : l-1], where \nl = Length(8). Furthermore, t is the cth such match starting from the left side (or the right side) if \nc is positive (or negative). If not enough matches exist, then . is returned. We use notation SubStr2(Vi, \nr, c) to denote the cth occurrence of regular expression r in Vi, i.e., SubStr(Vi, Pos(E, r, c), Pos(r, \nE, c)). We often denote SubStr2(Vi, CPos(0), CPos(-1)) by simply Vi. Tokens and Regular Expressions A \ntoken is either some special token or is constructed from some character class C in two ways: C+ denotes \na token that matches a sequence of one or more charac\u00adters from C. \u00acC+ denotes a token that matches a \nsequence of one or more characters that do not belong to C. We use the following collection of character \nclasses C: Numeric Digits (0-9), Alphabets (a-zA-Z), Lowercase alphabets (a-z), Uppercase alphabets (A-Z), \nAccented alphabets, Alphanumeric characters, Whitespace charac\u00adters, All characters. We use the following \nSpecialTokens. \u00b7 StartTok: Matches the beginning of a string. \u00b7 EndTok: Matches the end of a string. \n  String expr P := Switch((b1, e1), \u00b7\u00b7, (bn, en)) [ Switch((b1, e1), \u00b7\u00b7, (bn, en))]] 0 = if ([[b1] \n0) then [ e1] 0 Bool b := d1 . \u00b7 \u00b7 . dn . . Conjunct d := 11 .\u00b7\u00b7. 1n Predicate 1 := Match(Vi, r,k) |\u00ac \nMatch(Vi, r,k) Trace expr e := Concatenate(f1, \u00b7\u00b7, fn) Atomic expr f := SubStr(Vi, p1, p2) | ConstStr(8) \n| Loop(AW : e) Position p := CPos(k) | Pos(r1, r2, c) Integer expr c := k | k1W + k2 Regular Expression \nr := TokenSeq(T1, \u00b7\u00b7, Tr) Token T := C + | [\u00acC]+ | SpecialToken Figure 1. Syntax of String Expressions \nP . Vi refers to a free string variable, while W refers to a bound integer variable. k denotes an integer \nconstant and 8 denotes a string constant. \u00b7 A token for each special character, such as hyphen, dot, \nsemi\u00adcolon, colon, comma, backslash, forwardslash, left/right paren\u00adthesis/bracket etc. For better readability, \nwe reference tokens by representative names. For example, AlphTok refers to a sequence of alphabetic \ncharac\u00adters, NumTok refers to a sequence of numeric digits, NonDigitTok refers to a sequence of characters \nthat are not numeric digits, HyphenTok matches with the hyphen character. Addition of more tokens may \nmake the language more power\u00adful. (These tokens may be added either by the user or can be mined by searching \nfor frequently occurring substrings in a given spread\u00adsheet.) However, to stay true to our goal of avoiding \nany user anno\u00adtations, we aim to keep the language expressive without having to depend on addition of \nproblem-speci.c tokens. A regular expression r = TokenSeq(T1, \u00b7\u00b7, Tn) is a sequence of tokens T1, \u00b7\u00b7, \nTn. We often refer to singleton token sequences TokenSeq(T1) simply as T1. We use the notation E to denote \nan empty sequence of tokens. E matches an empty string. It is worth discussing our restricted choice \nof regular expres\u00adsions. First, we allow for only a restricted form of the Kleene star operator. The \nKleene star is restricted to one or more occurrences as opposed to zero or more occurrences (and that \ntoo at the innermost level). Second, we do not allow for the disjunction operator. These restrictions \n(together with the token partitioning optimization de\u00adscribed in Section 4.2) enable us to ef.ciently \nenumerate regular expressions that match certain parts of a string. If we allowed ar\u00adbitrary Kleene star \nand disjunction, we would lose this ability. Use of conditionals at the outer level allow us to recover \nsome of the expressiveness lost due to restricted form of regular expressions. The following two examples \nillustrate the expressive power of our substring constructor. EXAMPLE 2. The goal in this problem, taken \nfrom an Excel online help forum, is to extract the quantity of the purchase. Observe that characterizing \nthe substring that is being extracted is non-trivial, in fact, not even possible using the character-class \ntokens that our language provides. However, characterizing the (left) position before the substring and \nthe (right) position after the substring is relatively easy and also expressible in our language. . else \nif ([[bn] 0) then [ en] 0 else . [ d1 . ... . dn] 0 =[ d1] 0 . ... . [ dn] 0 [ 11 . ... . 1n] 0 =[ 11] \n0 . ... . [ 1n] 0 [ Match(Vi, r,k)]] 0 = Match(0(Vi), r,k) [ Concatenate(f1, \u00b7\u00b7, fn)]] 0 = Concatenate([[f1] \n0, \u00b7\u00b7, [ fn] 0) [ Loop(AW : e)]] 0 = LoopR(AW : e, 1,0) LoopR(AW : e, k, 0)= let t := [ e[k/W]]] 0 in \nif (t = .) then E else Concatenate(t, LoopR(AW : e,k+1,0)) [ SubStr(Vi, p1, p2)]] 0 = 8[[[p1] 8 :[ p2] \n8], where 8 = 0(Vi). [ ConstStr(8)]] 0 = 8 { k if k = 0 [ CPos(k)]] 8 = Length(8)+ k otherwise [ Pos(r1, \nr2, c)]] 8 = t such that . t1,t2 s.t. 0 = t1 <t = t2, 8[t1 : t-1] matches r1, 8[t : t2] matches r2, and \nt is the cth such position (in increasing/ decreasing order if c is positive/negative. Figure 2. Semantics \nof String Expressions P . Input V1 Output BTR KRNL WK CORN 15Z 15Z CAMP DRY DBL NDL 3.6 OZ 3.6 OZ CHORE \nBOY HD SC SPNG 1 PK 1 PK FRENCH WORCESTERSHIRE 5 Z 5 Z O F TOMATO PASTE 6 OZ 6 OZ  The following string \nprogram identi.es the left position to be the one before the occurrence of the .rst number, while the \nright posi\u00adtion to be the one at the end of the string. String Program (in our language): SubStr(V1, \nPos(E, NumTok, 1), CPos(-1)) EXAMPLE 3 (Directory Name Extraction). Consider the follow\u00ading example taken \nfrom an excel online help forum. Input V1 Output Company\\Code\\index.html Company\\Code\\ Company\\Docs\\Spec\\specs.doc \nCompany\\Docs\\Spec\\  String Program: SubStr(V1, CPos(0), Pos(SlashTok, E, -1)) 3.2 Loops The string \nexpression Loop(AW : e) refers to concatenation of e1, e2,..., en, where ei is obtained from e by replacing \nall occur\u00adrences of W by i. n is the smallest integer such that evaluation of en+1 yields .. It is also \npossible to de.ne more interesting termi\u00adnation conditions (based on position expression, or predicates), \nbut we leave out details for lack of space. EXAMPLE 4 (Generate Abbreviation). The goal here is to extract \nout all uppercase letters. This problem is taken from [21] and is presented as an example of Advanced \nText Formulas. Input V1 Output International Business Machines IBM Principles Of Programming Languages \nPOPL International Conference on Software Engineering ICSE String Program: Loop(AW : Concatenate(SubStr2(V1, \nUpperTok,W))). EXAMPLE 5 (Split Odds). The goal in this problem, taken from an Excel help forum, is to \nplace each odd in a separate cell, while ignoring any extraneous numbers or parenthesis. We reduce the \nproblem of generating multiple unbounded number of output strings to that of generating one output string \nwhere the multiple strings are separated by a unique symbol, say#. Input V1 Output (6/7)(4/5)(14/1) 6/7 \n# 4/5 # 14/1 # 49(28/11)(14/1) 28/11 # 14/1 # () (28/11)(14/1) 28/11 # 14/1 # String Program: Loop(AW \n: Concatenate(SubStr(V1, p1, p2), ConstStr( # ))) where p1 = Pos(LeftParenTok, TokenSeq(NumTok, SlashTok),W)) \nand p2 = Pos(TokenSeq(SlashTok, NumTok), RightParenTok,W). EXAMPLE 6 (Remove excess spaces). The goal \nin this problem, provided by the product team and also present in [21], is to re\u00admove all leading and \ntrailing spaces and replace internal strings of multiple spaces by a single space. Notice how the loop \nexpression prints out all but last sequence of non-whitespace characters (to not print any trailing whitespace \nin the output). Input V1 Output Oege de Moor Oege de Moor Kathleen Fisher AT&#38;T Labs Kathleen Fisher \nAT&#38;T Labs String Program: Concatenate(Loop(AW : Concatenate(SubStr(V1, p1, p2)), ConstStr( )), \nSubStr2(V1, NonSpaceTok, -1)) where p1 = Pos(E, NonSpaceTok,W), and p2 = Pos(NonSpaceTok, TokenSeq(SpaceTok, \nNonSpaceTok),W). 3.3 Conditionals The top-level string expression P is a Switch constructor whose arguments \nare pairs of (disjoint) boolean expressions b and trace expressions e. The value of P in a given input \nstate 0 is the value of the trace expression that corresponds to the boolean expression sat\u00adis.ed by \n0. Boolean expressions b are represented in DNF form and are boolean combinations of predicates of the \nform Match(Vi, r,k), where r is some regular expression and k is some integer constant. Match(Vi, r,k) \nevaluates to true iff Vi contains at least k matches of regular expression r. We often denote Match(Vi, \nr) by simply Match(Vi, r, 1). Conditionals play a very important role in our string processing language. \nThey allow us to appropriately interpret/process data that is in multiple formats. This is precisely \nthe place where most existing (data cleansing) tools that allow string processing through tons of automated \npre-canned features fail since they assume that the input is in a .xed structured format. Conditionals \nalso allow us to express transformations that are beyond the expressive power of the underlying conditional-free \npart of our language. EXAMPLE 7 (Conditional Concatenation). The goal here is to concatenate the .rst \nand the second strings V1 and V2 in the in\u00adput tuple as V1(V2), only if both V1 and V2 are non-empty \nstrings. Otherwise, the output should be empty string. This example is taken from an Excel online help \nforum. Input V1 Input V2 Output Alex Asst. Alex(Asst.) Jim Manager Jim(Manager) Ryan E E E Asst. E  \nString Program: Switch((b1, e1), (b2,E)), where b1 = Match(V1, CharTok) . Match(V2, CharTok), e1 = Concatenate(V1, \nConstStr( ( ),V2, ConstStr( ) )), b2 =\u00acMatch(V1, CharTok) .\u00acMatch(V2, CharTok). EXAMPLE 8 (Mixed Date \nParsing). The goal here is to parse dates in multiple formats into day, month, and year. This example \nis taken from an internal mailing list. We show below the program for day extraction (Month and year \nextraction are solved similarly.) Input V1 Output 01/21/2001 01 22.02.2002 02 2003-23-03 03  String \nProgram: Switch((b1, e1), (b2, e2), (b3, e3)), where b1 = Match(V1, SlashTok),b2 = Match(V1, DotTok), \nb3 = Match(V1, HyphenTok), e1 = SubStr(V1, Pos(StartTok, E, 1), Pos(E, SlashTok, 1)) e2 = SubStr(V1, \nPos(DotTok, E, 1), Pos(E, DotTok, 2)) e3 = SubStr(V1, Pos(HyphenTok, E, 2), Pos(EndTok, E, 1)) EXAMPLE \n9 (Name Parsing). The goal in this problem, provided by the product team, is to parse names that occur \nin multiple formats and transform them into a uniform format. Input V1 Output Dr. Eran Yahav Yahav, \nE. Prof. Kathleen S. Fisher Fisher, K. Bill Gates, Sr. Gates, B. George Ciprian Necula Necula, G. Ken \nMcMillan, II McMillan, K.  String Program for extracting initial of the .rst name: The logic used is \nthat of extracting the initial of the .rst word not followed by a dot: SubStr(V1, p1, p2), where p1 = \nPos(E, TokenSeq(AlphTok, NonDotTok), 1), and p2 = Pos(E, TokenSeq(LowerTok, NonDotTok), 1). String Program \nfor extracting last name: The logic used is that of extracting the word followed by a comma, or the last \nword (if no comma exists): Switch((b1, e1), (b2, e2)), where b1 = Match(V1, CommaTok),b2 =\u00acMatch(V1, \nCommaTok), e1 = SubStr2(V1, p1, p2),e2 = SubStr2(V1, AlphTok, -1), p1 = Pos(E, TokenSeq(AlphTok, CommaTok), \n1) and p2 = Pos(AlphTok, CommaTok, 1) The above two programs can be concatenated together (after dis\u00adtributing \nconditionals at the top-level) along with some constant strings to yield the desired program. EXAMPLE \n10 (Phone Numbers). The goal here is to parse phone numbers that occur in multiple formats and transform \nthem into a uniform format, adding a default area code of 425 if the area code is missing. This example \nwas provided by the product team.  Input V1 Output 323-708-7700 323-708-7700 (425)-706-7709 425-706-7709 \n510.220.5586 510-220-5586 235 7654 425-235-7654 745-8139 425-745-8139 String Program: Switch((b1, e1), \n(b2, e2)), where  P := Switch((b1, e1), \u00b7\u00b7, (bn, en)) e := Dag( 7,7/,7t ,6, W), f where W : 6 . 2 f \n:= Loop(AW : e) | SubStr(Vi, { pj }j , { ph}h) (1) | ConstStr(8) p := CPos(k) | Pos( r1, r2, c) r := \nTokenSeq(T 1, \u00b7\u00b7, T n) [ Switch((b1, e1), \u00b7\u00b7, (bn, en))]] = {Switch((b1, e1), \u00b7\u00b7, (bn, en)) | ei . [ \nei] } [ Dag( 7,7/,7t,W)]] = {Concatenate(f1, \u00b7\u00b7, fn) | fi . [ W(6i)]], 61, \u00b7\u00b7,6n . 6 form a path between \n7/ and 7t} [ { fi}i] = {f | f . [ fi] }[ Loop(AW : e)]] = {Loop(AW : e) | e . [ e] } [ SubStr(Vi, { pj \n}j , {p h'}h)]] = {SubStr(Vi, p1, p2) | p1 . [ pj ] , p2 . [ p h'] } [ ConstStr(8)]] = {ConstStr(8)}[ \nCPos(k)]] = {CPos(k)}[ Pos( r1, r2, c)]] = {Pos(r1, r2, c) | r1 . r1, r2 . r2, c . c} [ TokenSeq(T 1, \n\u00b7\u00b7, Tn)]] = {TokenSeq(T1, \u00b7\u00b7, Tn) | T1 . T 1, \u00b7\u00b7, Tn Tn} . Figure 3. Syntax and semantics of a language/data-structure \nfor succinctly describing huge sets of string expressions. / / // Intersect(Dag( 71,71,71t ,61,W1), Dag( \n72,72,72t ,62,W2)) = Dag( 71 \u00d7 7 2, (71,72), (71t ,72t ),612,W12), where ''' '  612 = {.(71,72), (71,72).|.71,71.. \n6 1, .72,72.. 6 2}, and '' '' W12(.(71,72), (71,72).)= {Intersect( f, f ' ) | f . W1(.71,71.), f ' . \nW2(.72,72.)} Intersect(SubStr(Vi, { pj }j , {p i' , {p ' p}r)) = {IntersectPos( ph, p)}h,r) h}h), SubStr(V \n}l, { lrr Intersect(ConstStr(81), ConstStr(82)) = ConstStr(81) if 81 = 82 Intersect(Loop(AW : e1), Loop(AW \n: e2)) = Loop(AW : Intersect( e1, e2)) IntersectPos(CPos(k1), CPos(k2)) = CPos(k1) if k1 = k2 (2) ''' \n''' IntersectPos(Pos( r1, r2, c), Pos( r1, r2, c )) = Pos(IntersectRegex( r1, r1), IntersectRegex( r2, \nr2), c n c ) '' '' IntersectRegex(TokenSeq(T 1, \u00b7\u00b7, T n), TokenSeq(T 1, \u00b7\u00b7, T r)) = TokenSeq(T 1 n T \n, \u00b7\u00b7, T n n T r) if n = m Figure 4. The Intersect function. The Intersect function returns \u00d8 in all other \ncases not covered above. b1 = Match(V1, NumTok, 3),b2 =\u00acMatch(V1, NumTok, 3), e1 = Concatenate(SubStr2(V1, \nNumTok, 1), ConstStr( - ), SubStr2(V1, NumTok, 2), ConstStr( - ), SubStr2(V1, NumTok, 3)) e2 = Concatenate(ConstStr( \n425- ), SubStr2(V1, NumTok, 1), ConstStr( - ), SubStr2(V1, NumTok, 2)) 4. Algorithm In this section, \nwe describe an algorithm for learning a string ex\u00adpression (in the language presented in Section 3) that \nis consis\u00adtent with the provided input-output examples. In fact, the algorithm ends up learning a set \nof string expressions all of which are con\u00adsistent with the provided input-output examples. This enables \nthe algorithm to have several desirable properties discussed later. The top-level structure of the algorithm \nis described in proce\u00addure GenerateStringProgram in Fig 7, which we explain below. Step 1: The algorithm \n.rst computes (in the loop at Line 2), for each input-output pair (0, 8), a set of all trace expressions \nthat map input 0 to output 8. We refer to this set as a trace set. This is done using the procedure GenerateStr \n(explained in Section 4.3). The set of such expressions can be huge; a key enabling technology is the \ndata-structure (described in Section 4.1) for succinctly repre\u00adsenting and manipulating such a huge set \nof expressions. Step 2: If the target program does not contain any conditionals (i.e., it is expressible \nas a trace expression, then the algorithm can simply intersect the trace sets of all input-output examples. \nHow\u00adever, since this is not a valid assumption, the algorithm .rst parti\u00adtions the examples so that inputs \nin the same partition are handled by the same conditional in the top-level Switch construct (and then \nintersect the trace sets for inputs in the same partition). Partitioning is performed (in Line 4) using \nthe procedure GeneratePartition (explained in Section 4.5.1). Inputs in the same partition have the property \nthat intersection of their trace sets is non-empty. The al\u00adgorithm uses a greedy heuristic to minimize \nthe number of such partitions by starting with singleton partitions and then iteratively merging those \npartitions that have the highest compatibility score (a notion de.ned in Sec 4.5.1). Step 3: The algorithm \nthen constructs (in the loop at Line 7) a boolean classi.cation scheme as a function of the inputs that \nwill place them in the appropriate partition. This is done using the pro\u00adcedure GenerateBoolClassifier \n(explained in Section 4.5.2). This boolean classi.cation forms the top-level switch construct for the \nstring program returned by the algorithm at Line 9. Steps 2 and 3 are explained in detail in Sec 4.5. \nThe GenerateStr procedure used in Step 1 is explained in Sec 4.3. It makes use of two key procedures \nGenerateSubstring and GenerateLoop, which are discussed in Sections 4.2 and 4.4 respectively. We start \nout by brie.y describing the key data-structure (used by these procedures) and the operations that it \nsupports. 4.1 Data-structure for Manipulating Sets of Expressions Figure 3 describes our data-structure/language \nfor succinctly rep\u00adresenting huge sets of string expressions of various kinds and also presents its formal \nsemantics. P , e, f, p, and r denote respectively a set of string programs, a set of trace expressions, \na set of atomic expressions, a set of position expressions, and a set of regular expressions. They are \nrepresented using the data-structure shown in Fig 3. c represent a set T and Size(Switch((b1, e1), \u00b7\u00b7, \n(bn, en))) = Size( e1) \u00d7\u00b7\u00b7\u00d7Size( en)  Size(Dag( 7, 7/,7t,W )) = size(7t) .. where size(7)= (size(7 ' \n) \u00d7 Size( f)) ' f. (. ' , .) and size(7/)=1 .. Size(SubStr(Vi, { pj }j , {p h' }h)) = ( Size(p j )) \u00d7 \n( Size( ph' )) jh Size(Loop(AW : e)) = Size( e) Size(ConstStr(8)) = 1 Size(CPos(k)) = 1 Size(Pos( r1, \nr2, c)) = Size( r1) \u00d7 Size( r2) \u00d7 Size( c) Size(TokenSeq(T 1, \u00b7\u00b7, T n)) = Size(T 1) \u00d7\u00b7\u00b7\u00d7Size(T n) Figure \n5. The Size function. The equations here also illustrate the huge representation savings that our data-structures \nprovide compared to explicit representation. of tokens and a set of integer expressions, and are represented \nexplicitly. The Concatenate constructor used in our string language is generalized to the Dag constructor \nDag( 7, 7/,7t , 6, W ), where 7 is a set of nodes containing two distinctly marked source and tar\u00adget \nnodes 7/ and 7t , 6 is a set of edges over nodes in 7 that in\u00adduces a DAG, and W maps each 6 . 6 to a \nset of atomic expres\u00adsions. The set of all Concatenate expressions represented by a Dag( 7, 7/,7t , \n6, W ) constructor include those whose ordered ar\u00adguments belong to the corresponding edge on any path \nfrom 7/ to 7t. The Switch, Loop, SubStr, Pos, and TokenSeq constructors have all been overloaded to accept \na set of values of the correspond\u00ading type for its arguments with the expected semantics. The data-structure \nsupports the following two interesting oper\u00adations, both of which are required for the partitioning procedure. \nIntersection Operation Given two sets of expressions of the same kind, construct a set of expressions \nthat are common to the two given sets. The intersection function is described in Fig 4. The most interesting \npart is the intersection of two DAGs, which is similar to intersection of two regular automatas. The \nchallenge, compared to regular automata case, is to intersect the labels on the edges -in case of automata, \nthe labels are simply a set of characters, while in our case, the labels are sets of string expressions. \nWe intersect sets of string expressions using the intersection operation supported by the data-structure \nused for representing those sets of string expressions. Size Operation Given a set of expressions of \nsome kind, estimate the size of the set. The size function is described in Figure 5. Observe the succinctness \nbene.ts provided by the factorization used by each set construct. 4.2 Learning Substring Extraction Logics \nIn this section, we describe how to learn the set of all SubStr ex\u00adpressions in our language that can \nbe used to extract a given sub\u00adstring from a given string. (This is an important component of the procedure \nGenerateStr.) The number of such expressions may be huge, in which case, explicit representation and \ncomputation of all these expressions would be infeasible with respect to both time and space. For example, \nfollowing is a small sample of various logics for extracting 706 from the string 425-706-7709 (call it \nV1). \u00b7 Second number: SubStr2(V1, NumTok, 2). \u00b7 Second last alphanumeric token:  SubStr2(V1, AlphNumTok, \n-2). \u00b7 Substring between the .rst hyphen and the last hyphen: SubStr(V1, Pos(HyphenTok, E, 1), Pos(E, \nHyphenTok, -1)).  \u00b7 First number that occurs between hyphen on both ends.  SubStr(V1, Pos(HyphenTok, \nTokenSeq(NumTok, HyphenTok), 1), Pos(TokenSeq(HyphenTok, NumTok), HyphenTok, 1)). \u00b7 First number that \nis preceded by a number-hyphen sequence. SubStr(V1, Pos(TokenSeq(NumTok, HyphenTok), NumTok, 1), Pos(TokenSeq(NumTok, \nHyphenTok, NumTok), E, 1)).  The GenerateSubstring procedure performs this task effec\u00adtively, and is \nbuilt around the following two key observations. Decomposition into independent sub-problems The substring\u00adextraction \nproblem can be decomposed into two independent position-identi.cation problems, each of which can be \nsolved inde\u00adpendently. Note the two independent calls to GeneratePosition procedure at Lines 3 and 4 \nin GenerateSubstring procedure in Figure 7. The solutions to the substring-extraction problem can also \nbe maintained succinctly by independently representing the solutions to the two position-identi.cation \nproblems. Note the rep\u00adresentation of the SubStr constructor in Eq. 1 in Figure 3. Partitioning of Tokens \ninto Indistinguishable Sets A given string does not often distinguish between several sets of tokens. \nHence, for any position-identi.cation problem, the choice of reg\u00adular expressions for a given string \ncan be restricted to using only one token from each set of indistinguishable tokens. We de.ne this more \nformally below. DEFINITION 1 (Indistinguishability). We say that a token T1 is indistinguishable from \ntoken T2 with respect to a string 8 if the set of matches of token T1 in 8 is same as the set of matches \nof token T2 in string 8. Note that indistinguishability is an equivalence relation. DEFINITION 2 (Indistinguishability \nPartition). Given a string 8 and a set of tokens, let IParts/ denote the partition of tokens into indistinguishable \nsets, and let Reps/ denote some set of representa\u00adtive tokens, one from each partition. We use the notation \nIParts/(T) to denote the set in which token T lies. We use this observation to restrict the choice of \ntokens used in constructing regular expressions to come from the set Reps/ at Lines 2 and 3 in procedure \nGeneratePosition. This signi.cantly reduces the number of regular expressions that get considered at \nLines 2 and 3 without affecting the completeness of the algorithm. 4.3 Learning Traces In this section, \nwe discuss how to learn the set of all trace expres\u00adsions (i.e., Concatenate constructors) that can be \nused to gener\u00adate a given output string from a given input state. The number of such expressions may \nbe huge. For example, consider the prob\u00adlem of transforming phone numbers in Example 10. Consider the \nsecond input-output example, where the input state consists of one string (425)-706-7709 and the output \nstring is 425-706-7709 . Figure 6 shows a small sampling of different ways of generating parts of the \noutput string from the input string using SubStr and ConstStr constructors. (Each substring extraction \ntask itself can be performed in a huge number of ways as explained in Sec 4.2). Following are three of \nthe trace expressions represented in the .g\u00adure, of which the second one (also shown in bold in the .gure), \nwould lead to the correct answer. 1. Extract the substring 425 . Extract the substring -706-7709 .  \n an output string from the input string. 2. Extract the substring 425 . Print constant - . Extract the \nsub\u00adstring 706 . Print constant - . Extract the substring 7709 . 3. Extract the substring 425 . Extract \nthe substring -706 . Print constant - . Extract the substring 7709 .  GenerateStr procedure performs \nthis task effectively (by us\u00ading the DAG data-structure introduced earlier to succinctly repre\u00adsent all \ntrace expressions). It uses the following crucial observa\u00adtions. Independence of (unknown) sub-problems \nFirst, observe that the logic for generating some substring of an output string is com\u00adpletely decoupled \nfrom the logic for generating another disjoint substring of the output string. Hence, the problem of \ngenerating the output string can be decoupled into independent sub-problems of generating different parts \nof the output string. In particular, assume that we have an oracle (as in a PBD system like [11]) that \nprovides us with the decomposition of a given out\u00adput string into n disjoint adjacent substrings, where \neach disjoint substring gets generated by a different argument of the enclosing concatenate operator. \nGiven such a decomposition, we can decom\u00adpose the problem of identifying the trace expression for generating \nthe output string, into n independent sub-problems of generating each of the disjoint adjacent substrings \nusing at atomic expression constructor. These problems can not only be solved independently, but their \nsolutions can also be stored independently to succinctly represent an exponential number of solutions \nin linear space. How\u00adever, unfortunately, we do not apriori know the appropriate decom\u00adposition of the \noutput string into various parts for which we can independently seek a solution. The naive strategy of \nenumerating all possible decompositions would not scale since the number of decompositions is exponential \nin the size of the output string. Number of possible sub-problems is quadratic Second, observe that the \ntotal number of different substrings/parts of a string is quadratic (and not exponential) in the size \nof the output string. This leads to a succinct representation of all possible decompositions of a string \nusing a DAG representation, and hence allows us to de\u00adcompose the problem of generating the output string \n(using a trace expression) into a quadratic number of independent sub-problems of generating different \nsubstrings of the output string (using some atomic expression). With the above two observations, we are \nnow ready to explain the effective functioning of the procedure GenerateStr. The pro\u00ad cedure GenerateStr \ngenerates a Dag( 7, 7/,7t , 6, W ) constructor that represents the set of all trace expressions that \ncan generate a given output string from a given input state. The key idea is to construct a node corresponding \nto each position within the out\u00adput string and create an edge from a node corresponding to any position \nto a node corresponding to any later position. Observe that each edge here corresponds to some substring \nof the output. Each such edge is annotated with the set of all atomic expressions that can generate the \ncorresponding substring (Lines 5 and 6 in procedure GenerateStr). The set of all such SubStr and Loop \nexpressions is generated by Procedures GenerateSubstring and GenerateLoop respectively. The following \ntheorem holds. THEOREM 1. Procedure GenerateStr(0, 8) computes the set of all trace expressions e with \nthe following properties: A1. (Soundness) e generates the output string 8 from the input state 0, i.e., \n[ e] 0 = 8. A2. (Completeness Restriction) Any loop that occurs in e is non\u00ad nested and executes at least \ntwice on 0. PROOF: The procedure GenerateSubstring(0, 8) generates the set of all SubStr expressions \nthat can generate 8 from 0. The procedure GenerateLoop(0, 8, W ) extends the map\u00adping W (k1,k4) with \nall Loop expressions that can generate 8[k1,k4] from 0 and furthermore satisfy the restrictions in A2. \nHence, the theorem follows. 4.4 Learning Loops In this section, we discuss how to infer the set of all \nLoop construc\u00adtors that can be used to generate some unknown part of a given output string 8 from a given \ninput state 0. In the process, we would also identify the unknown part of the output string that the \nLoop constructor can generate. Procedure GenerateLoop performs this task effectively, and involves the \nfollowing steps: 1. Guess three positions within the output string k1, k2, and k3. 2. Unify the set \nof trace expressions that can generate 8[k1 : k2] with the set of trace expressions that can generate \n8[k2 : k3] to obtain a new set of string expressions, say e that uses the loop iterator W. The uni.cation \nalgorithm is explained below. 3. Obtain the set of substrings obtained by running the string ex\u00adpressions \ne on input 0. If this set contains a singleton string that matches 8[k1 : k3] for some k3, then we conclude \nthat 8[k1 : k3] can be generated by Loop(AW : e). Otherwise ignore.  The uni.cation algorithm is same \nas the intersection algorithm except with the following replacement to Eq. 2 in Figure 4. IntersectPos(k1,k2)= \n/ (k2 - k1)W + k1 if k1 = k2 The key idea above is to guess a set of loop bodies by unifying the sets \nof trace expressions associated with the substrings 8[k1 : k2] and 8[k2 : k3], and then test the validity \nof the conjectured set of loops. For performance reasons, we do not recursively invoke GenerateLoop (in \nthe call that it makes to GenerateStr). This allows us to discover all single loops. Nested loops may \nbe discov\u00adered by controlling the recursion depth. 4.5 Learning Conditionals In this section, we discuss \nhow to generate the top-level Switch constructor, after having learned, for each input-output example, \nthe set of all trace expressions that can generate the output string from the input state. There are \ntwo important components that enable learning of appropriate conditionals: partitioning of input\u00adoutput \nexamples into disjoint partitions, and learning classi.ers based on inputs for those partitions. The \nclassi.ers provide the conditionals, while the intersection of the trace sets associated with various \ninputs in a partition yields the computational branch for the corresponding conditional. 4.5.1 Learning \nPartitions In this section, we discuss how to appropriately classify the input\u00adoutput examples into different \npartitions -the idea being that exam\u00ad GenerateStringProgram(S: Set of (0, 8) pairs) 1 T := \u00d8; 2 foreach \n(0, 8) . S 3 T := T . ({0}, GenerateStr(0, 8)); 4 T := GeneratePartition(T); 5 0 ' := {0 | (0, 8) . S}; \n6 foreach ( 0, e ) . T: 7 let B[ 0] := GenerateBoolClassifier( 0, 0 ' -0 ) 8 Let ( 01, e 1),..., ( 0h, \ne h) be the k elements in T in increasing order of Size( e). 9 return Switch((B[ 01], e 1),..., (B[ 0h], \ne h)); GeneratePartition(S: Set of (0, 8) pairs) 1 while exists ( 0, e ), ( 0 ' , e ' ) . T s.t. Comp( \ne, e ' ) 2 Let ( 01, e 1), ( 02, e 2) . T be s.t. CS( e1, e 2) is largest. 3 T := T -{( 01, e1), ( 02, \ne 2)}.{( 01 . 0 2, Intersect( e1, e 2))}; 4 return T; GenerateBoolClassifier(0 1,0 2: Set of inputs) \n1 1 := 01;b := false; 0 ' 2 while ( 01 ' /= \u00d8) 3 Old 1 := 1; 0 ' 0 ' 0 ' 0 ' 0 '' 4 2 := 02; 1 := 1;d \n:= true; 5 while ( 02 ' / = \u00d8) 6 Old 2 := 2; 0 ' 0 ' 7 Preds := {Match(Vi, r,c), \u00acMatch(Vi, r,c) |[ \nMatch(Vi, r,c)]]0, 0 . 00 '' 1 . 0 2}; 8 Let 1 . Preds be s.t. CSP(1, 1 , 2) 0 ' is largest. 9 d := d \n. 1; 0 '' 0 '' 0 '' 10 1 := 1 -{01 | 01 . 1 , \u00ac[ 1] 01}; 11 0 2 ' := 02 ' -{02 | 02 . 0 2' , \u00ac[ 1] 02}; \n12 if (Old 2 = 2) then FAIL. 0 ' 0 ' 0 '' 0 ' 0 ' 13 1 := 1 - 1 ;b := b . d; 0 ' 0 ' 14 if (Old 1 = \n1) then FAIL. 15 return b; GenerateStr(0: Input state, 8: Output 1 7 := {0,..., Length(8)}; 2 7/ := {0}; \n3 := {Length(8)}; 7t  4 6 := {.i, j.| 0 = i<j = Length(8)}; string) 5 Let W be the mapping that maps \nedge .i, j.. 6 to the set {ConstStr(8[i : j - 1])}. GenerateSubstring(0, 8[i : j - 1]); 6 W ' := GenerateLoop(0, \n8, W ); ' 7 return Dag( 7, 7/,7t , 6, W ); GenerateLoop(0: Input state, 8: Output string, W ) 1 W ' := \nW ; 2 foreach 0 = k1,k2,k3 < Length(8): 3 e 1 := GenerateStr(0, 8[k1 : k2]); e 2 := GenerateStr(0, 8[k2 \n: k3]); 4 e := Unify( e1, e2); 5 if ([[Loop(AW : e)]]0 = {8[k1 : k4]}) for some k4 6 W ' (.k1,k4.) := \nW ' (.k1,k4.) .{Loop(AW : e)}; 7 return W ' ; GenerateSubstring(0: Input state, 8: String) 1 result \n:= \u00d8; 2 foreach (i, k) s.t. 8 is substring of 0(Vi) at position k 3 Y1 := GeneratePosition(0(Vi),k); \n4 Y2 := GeneratePosition(0(Vi),k + Length(8)); 5 result := result .{SubStr(Vi,Y1,Y2)}; 6 return result; \n GeneratePosition(8: String, k: int) 1 result := {CPos(k), CPos(-(Length(8)-k)}; 2 foreach r1 = TokenSeq(T1, \n\u00b7\u00b7, Tn) matching 8[k1 : k-1] for 3 foreach TokenSeq(T1' , \u00b7\u00b7, T ' ) matching 8[k : k2] for r2 =r 4 \nr12 := TokenSeq(T1, \u00b7\u00b7, Tn, T ' 1, \u00b7\u00b7, T ' ); r some k1: some k2: cth 5 Let c be s.t. 8[k1 : k2] is \nthe match for r12 in 8. 6 Let be the total number of matches for r12 in 8. c ' 7 r 1 := generateRegex(r1,8); \n8 r 2 := generateRegex(r2,8); 9 result := result .{Pos( r1, r 2, {c, -(c ' -c+1)})}; 10 return result; \ngenerateRegex(r: Regular Expression, 8: let r be of the form TokenSeq(T1, \u00b7\u00b7, Tn). return TokenSeq(IParts/(T1), \n\u00b7\u00b7, IParts/(Tn String) )); Figure 7. Algorithm for learning string programs that are consistent with \na given set S of input-output examples. ples that end up in the same partition are those that require \nsimilar computational processing. We attempt to achieve this by requiring the partitioning to satisfy \nthe following two properties. \u00b7 Utility: For each partition, there is at least one trace expression e \nthat is consistent with all examples in that partition. \u00b7 Minimality: Number of partitions should be \nas small as possible. Observe that the utility requirement can be satis.ed trivially on its own by placing \neach example in its own partition, but then it would not lead to any generalization, which in turn would \nnot lead to any convergence. The minimality requirement can be satis.ed trivially on its own by placing \nall examples in the same partition, but it may lead to failure because there might not be any trace expression \nthat can express the transformation for all the examples. It is the combination of these two requirements \nthat leads to faster successful convergence. It would be computationally expensive to try out all possible \n partitioning choices and select the one that contains smallest num\u00adber of partitions. We present a \npartitioning algorithm (based on greedy algorithmic design pattern) that is not only ef.cient, but in \npractice, yields the smallest number of partitions. The algorithm for learning partitions is described \nin procedure GeneratePartition in Figure 7. We start with singleton parti\u00adtions that contain one input \neach, along with associated trace sets. We then merge two partitions only if their associated trace sets \nhave at least one trace expression in common. (This criterion leads to sat\u00adisfaction of the utility requirement). \nWe refer to such trace sets as being compatible with each other. DEFINITION 3 (Compatible). We say that \ntrace sets e1 and e2 are compatible with each other, denoted Comp( e1, e2), if Comp( e1, = e1, e2) /\u00d8 \ne2)Intersect( = Often there are multiple choices of pairs of partitions that can be merged with each \nother. We select a pair that has the highest compatibility score. The compatibility score is designed \nto facilitate partitioning decisions that, at least in practice, lead to the smallest number of partitions. \nThe compatibility score has two components CS1 and CS2. CS1 measures agreement of two partitions with \nrespect to the compatibility of their trace sets and their intersection with all other trace sets. In \nparticular, if two trace sets e1 and e2 are both com\u00adpatible with e3, and so is Intersect( e1, e2), then \nwe bump up the compatibility score of e1 and e2. Also, if two trace sets e1 and e2 are both not compatible \nwith e3, then we bump up the compatibil\u00adity score of e1 and e2. Note that in either of above-mentioned \ntwo cases, the potential of e1 or e2 to merge with e3 is unchanged as a result of the intersection of \ne1 and e2. The idea is to select those partitions for merging that keep alive merging potential with \nother partitions in a later step, resulting in a smaller number of overall partitions. CS2 is used to \nproduce a .ner score in case there are ties on the CS1 score. It gives preference to those pairs of trace \nsets whose relative size after intersection is largest. The idea is that a larger trace set is more likely \nto merge with other trace sets in a later step, resulting in a smaller number of overall partitions. \nDEFINITION 4 (Compatibility score). Let e1 and e2 be two com\u00adpatible trace sets drawn from a set T = \n{ e\"(1),..., e\"(n)} of trace sets. We de.ne the compatibility score of e1 and e2 with respect to T , \ndenoted by CS( e1, e2,T ) as: CS( e1, e2,T )=(CS1( e1, e2,T ), CS2( e1, e2)) where CS1 and CS2 are de.ned \nas follows: boolean formula b learned so far. The loop in line 2 is repeated until 0 1 ' becomes empty \n(or it does not change). The loop in line 5 identi.es a new predicate 1 in each iteration 0 '' with \nthe property that several inputs in 1 satisfy 1, but several 0 '' inputs in 0 2 ' do not satisfy 1, \nand then adds it to the conjunct d. 1 and 0 2 ' are both those monotonically decreasing subsets of 0 \n1 ' and 0 2 respectively that satisfy the conjunct d built so far. 0 2 is used to decide whether or not \nthe loop in line 5 needs to be iterated any 0 '' further, while 1 is used to update 0 1' , which is \nrequired for the loop in line 2. Hence, the following theorem holds. THEOREM 2. If GenerateBoolClassifier( \n01,0 2) does not fail and returns a boolean condition b, then all inputs in 0 1 satisfy b and none of \nthe inputs in 0 2 satisfy b. To ensure learning of small boolean formulas, we ensure that the predicate \n1 that is chosen at Line 8 is such that \u00b7 several inputs in 0 2 ' do not satisfy 1. This keeps 0 2 ' \nsmaller, which helps to terminate the inner loop at Line 5 faster, which leads to conjuncts d containing \nsmall number of predicates. 0 '' 0 '' \u00b7 several inputs in 1 satisfy 1. This keeps 1 larger, which helps \nto keep 0 1 ' smaller, which in turn helps to terminate the outer loop in Line 2 faster, which leads \nto fewer number of conjuncts. To enable a selection that satis.es above-mentioned criterion, we choose \na predicate with highest classi.cation score (as de.ned 0 '' below) with respect to the sets 1 and 0 \n2' . . CS1( e1, e2,T )= ( e1, e2, eh) DEFINITION 5 (Classi.cation Score of a Predicate). Given two sets \nof inputs 0 1 and 0 2, and a unary predicate 1 over inputs, we de.ne . .. .. the classi.cation score \nof 1, denoted by CSP(1, 0 1,0 2), as: e . ,h// =1,h=2 1 if (Comp( e1, eh)= Comp( e2, eh) CSP(1, 0 1,0 \n2)= Size({01 | 01 . 0 1, [ 1] 01}) \u00d7 = Comp(Intersect( e1, e2), eh)) Size({02 | 02 . 0 2, \u00ac[ 1] 02}) \n( e1, e2, eh) = 0 otherwise 4.6 Correctness Size(Intersect( e1, e2)) CS2( e1, e2)= Max{Size( e1), Size( \ne2)} Comparison on compatibility scores (x,y), which are pairs of numbers, is de.ned using lexicographic \nordering, i.e., ( 1, 1) > ( 2, 2)=( 1 > 2) . ( 1 = 2 . 1 > 2) We repeat the merging process one by one \nuntil no more parti\u00adtions can be merged. 4.5.2 Learning Classi.ers for Partitions In this section, we \ndiscuss how to generate classi.ers for the vari\u00adous partitions generated using the algorithm GeneratePartition \ndescribed above. A classi.er for a partition is a boolean condition (over the set of predicates in our \nlanguage) that returns true for all inputs in the partition and returns false for all inputs not in that \npartition. We attempt to learn not just any classi.er, but a simple (small-sized) one. Given a set of \npredicates, one simple approach can be to enu\u00admerate boolean formulas of increasingly large sizes and \ncheck if it can act as a classi.er for some partition. However, this approach would be computationally \nexpensive. We present a classi.er learn\u00ading algorithm (based on greedy algorithmic design pattern) that \nis not only ef.cient, but in practice, yields smallest classi.ers. The algorithm for learning classi.ers \nis described in procedure GenerateBoolClassifier in Figure 7. We learn a boolean clas\u00adsi.er in DNF form. \nThe loop in line 2 learns a new conjunct d in each iteration with the property that none of the inputs \nin 0 2 satisfy d, but several inputs in 0 1 ' do. 0 1 ' is that monotonically decreasing subset of inputs \nfrom 0 1 that are not yet covered by the disjunctive If procedure GenerateBoolClassifier does not fail, \nthe synthe\u00adsis algorithm succeeds. In that case, the following theorem holds. THEOREM 3 (Soundness). \nThe set P of string expressions re\u00adturned by GenerateStringProgram({(0i,8i)}i) are all consis\u00adtent with \neach input-output pair (0i,8i), i.e., .P . P .i : ([[P ] 0i)= 8i The proof of theorem 3 follows from \nsimilar soundness properties of the involved procedures, of which the most interesting one has been stated \nin Theorem 2. CONJECTURE 1 (Completeness). If there exists a string expres\u00adsion in our language that \nis consistent with the given set of input\u00adoutput pairs, the algorithm produces one. The above conjecture \nis true at the level of traces, i.e., if there ex\u00adists a consistent trace expression (satisfying the \nrestriction A2 in Theorem 1), then the algorithm generates it. However, the above conjecture may not \nbe true in general. In practice though, we have observed our partitioning and classi.cation procedures \nto always work, and it appears that there are some interesting theoretical properties of these procedures \nthat might pave the way for proving the above conjecture under some general conditionals. This inves\u00adtigation \nis left for future work. 4.7 Discussion 4.7.1 Adaptability to Language Extensions The algorithm can be \neasily adapted to deal with the following lan\u00adguage extensions. The choice of tokens/predicates can be \nenriched arbitrarily as long as they can be ef.ciently enumerated. The choice of regular expressions \nis inextensible for reasons mentioned earlier. The substring construct can be extended further to allow \nfor a con\u00adstant index offset into the current choice of substrings. The loop construct can be enriched \nto allow for termination conditions based on position logic or conjunctions of predicates. It may be \npossible to nest conditionals inside loops. The key algorithmic idea would be to recursively perform \npartitioning and classi.cation, as is done at the top-level, instead of a simple uni.\u00adcation. However, \nperformance may be a concern. 4.7.2 General Principles Here, we summarize some key general principles \nof our learn\u00ading algorithm. The algorithm .rst learn traces and then infer loops/conditionals. This is \nunlike recent work on more-general program synthesis techniques (e.g., [19]) that attempt to learn ev\u00aderything \nat the same time, often leading to unscalablility. For learning conditionals, the algorithm uses a greedy \nstrat\u00adegy based on scoring functions to .rst infer partitioning and then boolean classi.cation. The standard \nway to learn conditionals in recent program synthesis work is to phrase this as a combinatorial search \nproblem (using SAT/SMT solvers), which leads to solutions that may not scale in real-time settings like \nours. For learning traces, the algorithm uses DAG based data-structures that can represent and manipulate \n(intersection, evaluation, size/rank computation) huge sets of programs. This approach would work in \ngeneral for any term algebra. The DAG based data-structure can be likened to BDDs, which can succinctly \nrepresent and manipulate (conjunction, disjunction, negation) huge sets of program states, and are popular \nin the veri.cation community. 5. Usability Extensions 5.1 Active Interaction Model (for easier interaction) \nA simple interaction model can be to ask the user to investigate the results of a synthesized program \non other inputs in the spread\u00adsheet and to report any discrepancy. However, this may be cum\u00adbersome in \ncase of large spread-sheets. To enable easier interac\u00adtion, we exploit the fact that our synthesis algorithm \nreturns a set of programs P . The synthesis system can run P on every input 0 in the spreadsheet to generate \na set of corresponding outputs 8 , i.e., 8 = {[ P ] 0 | P . P }. The set 8 can be computed directly without \nexplicitly enumerating all programs in P . (This requires exploit\u00ading the structural decomposition of \nthe underlying data-structures as is done in Intersect and Size methods -we leave out details for lack \nof space.) The synthesis system can then highlight any in\u00adput (for user inspection) whose corresponding \noutput set contains at least two strings. We refer to this as the active interaction model. It is interesting \nto compare the above idea with the idea of distinguishing inputs that was introduced recently in the \ncontext of synthesis of bit-vector algorithms [8]. An application of that idea in our context would mean \npicking any two (semantically different) programs from P and then synthesizing an input on which the \ntwo programs yield different outputs. Such an approach would not be effective in our setting since, as \nis illustrated by the case-study in Example 1, convergence does not require to narrow the choice of consistent \nprograms down to a semantically unique program in the language. It is suf.cient to narrow the choice \ndown to that set of consistent programs that are equivalent with respect to the .nite number of inputs \nin the spreadsheet. 5.2 Noise Handling The algorithm declares failure when it fails to learn a boolean \nclas\u00adsi.cation scheme. In that case, it can attempt to identify any noise (inadvertent error in one input-output \nexample) as follows. The al\u00adgorithm classi.es an input-output example as a potentially-noisy if the input \nbelongs to a singleton partition, but the boolean classi.ca\u00adtion scheme fails to generate a boolean classi.er \nfor that singleton partition. For each potentially-noisy example, the algorithm ignores the corresponding \npartition, and re-learns the boolean classi.cation scheme for other partitions. If it succeeds, it classi.es \nthe example as noisy and presents that to the user for validation, and can even suggest a .x by running \nthe learned program on the input corre\u00adsponding to the noisy example. EXAMPLE 11. Consider the following \nset of examples provided to our tool in one of the scenarios, in which the user failed to spell Kimberly \ncorrectly in the output column. Input V1 Input V2 Output Otis Daniels Otis, D. Kimberly Jones Kimberley, \nJ. Mary Leslie Mary, L. The GeneratePartition algorithm groups the .rst and third ex\u00adample in one partition, \nwhile the second example belongs to a singleton partition. The GenerateBoolClassifier algorithm fails \nto generate a boolean classi.cation scheme that distin\u00adguishes the two partitions. Ignoring the singleton \npartition enables GenerateBoolClassifier algorithm to succeed trivially (since there is only one partition). \nThe algorithm declares the second example to be noisy and asks the user to investigate if she really \nmeant Kimberly, J. (which it generates by running the learned program on the noisy input). 5.3 Ranking \nof Multiple Solutions (for faster convergence) Selecting an expressive language for inductive program \nsynthesis systems raises an interesting dilemma. While it makes users who want to program sophisticated \ntasks happy, it may adversely impact users who want to program simple tasks but now may require to provide \nmore bits for disambiguation of their intent (which manifests in the need to provide more examples and \nmore rounds of interaction). The Occam s razor principle, which states that the simplest explanation \nis usually the correct one, comes to our rescue here. We de.ne a comparison scheme between different \nstring expressions by de.ning a partial order between them. Some of these choices are subjective, but \nhave been observed to work well. (There is also a fascinating prospect of personalizing this partial \norder based on the user intent observed during last few scenarios). A Concatenate constructor is simpler \nthan another one if it contains smaller number of arguments or its arguments are pair\u00adwise simpler. Similarly \nfor TokenSeq constructor. StartTok and EndTok are simpler than all other tokens (suggesting that extrac\u00adtion \nlogics based on the start/end of strings are more common). A token corresponding to a character class \nis simpler than the one cor\u00adresponding to a smaller character class. (We favor generality here.) CPos \nexpressions are simpler than Pos expressions (giving prefer\u00adence to extraction logics based on constant \noffsets). A SubStr con\u00adstructor is simpler than both ConstStr constructor (it is less likely for constant \nparts of an output string to also occur in the input) and Concatenate constructor (if there is a long \nsubstring match be\u00adtween input and output, it is more likely that the corresponding part of the output \nwas produced by a single substring extraction logic). Procedures generateRegex, GenerateLoop, GenerateStr, \nGeneratePosition, and GenerateSubstring, which generate a set of solutions, can take this ordering into \naccount to produce an ordered set of solutions. 6. Prototype Tool We have built the program synthesis \nsystem described in this pa\u00adper as an add-in, called QuickCode, for Microsoft Excel 2010. Mi\u00adcrosoft \nExcel is the most popularly used spreadsheet system in the world and is widely regarded to be the swiss \narmy knife of all busi\u00adnesses. The program synthesis system has two components: (a) the algorithm described \nin Section 4, which has been implemented in C# (it is less than 5000 lines of code), and (b) the usability \nextensions described in Section 5, which are supported using a simple, but cool, graphical user interface \ndescribed below. 6.1 User Interface The user .rst selects a rectangular region of spreadsheet containing \nboth input and output columns. We treat the mostly populated columns as input columns, and less populated \ncolumns as output columns. However, we also provide the .exibility for the user to select multiple column \nranges and identify explicitly which columns are inputs and which columns are outputs (since it may be \nthe case that most cells in an input column have null entries, while our default treatment would be to \nregard it as an output column). We treat the rows that contain entries for an output column as input\u00adoutput \nexamples for the program to be learned for that column. The user then presses the QuickCode button. The \nsystem then populates the spreadsheet as follows. It invokes the synthesis algo\u00adrithm (procedure GenerateStringProgram) \nfor each of the out\u00adput column. For each output cell Cr,c (in row r and output column c), the system \nruns the generated set of programs for output column c on the input state speci.ed in row r to generate \nan ordered set 8 of possible outputs. The system populates the cell Cr,c as follows: \u00b7 If 8 contains \none string (the most common case), the system populates the cell with that string. \u00b7 If 8 contains multiple \nstrings, the system populates the cell with the .rst string (top ranked solution), but highlights it \nto point out to the user that there are multiple computational interpretations of the few examples provided \nby the user, and that the user may want to investigate the output of the highlighted cell. \u00b7 If 8 is \nempty, the system populates the cell with ?? to draw the attention that the user should provide the output \nfor that cell.  The user may then (repeatedly) .x contents of any cell by right-clicking on it, wherein \na dialog box opens up that allows the user to choose from other strings in the corresponding sequence \n8 , or to provide a new output altogether. After any such .x, the above learning process is automatically \nrepeated with the extended set of input-output examples, and the contents of spreadsheet are automatically \nupdated to re.ect the new learned results. 6.2 Evaluation Metrics Our synthesis system can be evaluated \nagainst several metrics stated below. Algorithmic Performance: This is a measure of the effectiveness \nof the data-structures used by the algorithm. The algorithm was timed to take less than 0.1 seconds on \naverage for a varied bench\u00admark suite of more than 100 problem instances drawn from online help forums \nor obtained from Excel product team as representative examples. (The examples described in this paper \nform a representa\u00adtive part of this benchmark suite.) Each problem instance contained up to 10 input-output \npairs (more than what the user would want to provide in any scenario) and each string in any pair contained \nup to 100 characters (more than what is typical of spreadsheet cells). Experiments were performed on \na machine with Intel Core-2-Duo 2.8 GHz CPU, and 4 GB RAM. Number of Interactive Rounds: This is a measure \nof the general\u00adization power of the conditional learning part of the algorithm and the ranking scheme. \nWe observed that the tool typically requires just one round of interaction, when the user is smart enough \nto give an example for each input format (which typically range from 1 to 3) to start with. It is heartening \nto note that this was indeed the case for most scenarios in our benchmarks, even though our algorithm \ncan function robustly without this assumption. The maximum num\u00adber of interactive rounds required in \nany scenario was 4 (with 2 to 3 being a more typical number). The maximum number of examples required \nin any scenario over all possible interactions was 10. Success Ratio: We have not come across any problem \ninstance that can be expressed in our language, but our algorithm fails to converge to the correct solution. \nThis is a measure of the validity of the completeness hypothesis discussed in Section 4.6. However, we \nhave found several problem instances that cannot be expressed in our language. Most of these instances \nare related to semantic entity reasoning (such as transforming dates into day of the week). For syntactic \nstring manipulation tasks, we have been more than pleasantly surprised at the expressiveness of our lan\u00adguage. \nFew testing moments came in the middle of some internal demos to large audiences, where we were asked \nto try out modi.ed scenarios on the spot (on real spreadsheet data). The tool success\u00adfully learned the \ndesired transformations in all those cases. Following are a few examples of scenarios where QuickCode \nwas used by fellow colleagues to perform tasks beyond the imagi\u00adnation of the author. EXAMPLE 12 (Synthesis \nof part of a future extension of itself). The synthesis system is currently being extended with semantic \nknowledge of common entities that would allow the system to per\u00adform transformations that are beyond \nthe realm of syntactic com\u00adputations. One of the dictionaries that was recently added to the system was \nmapping from a country s international dialing code to the name of that country. Rishabh Singh performed \nthis task, which he originally thought would take around an hour (in absence of any scripting), in less \nthan a minute using the QuickCode add-in (after copying and pasting the data from Wikipedia into an Excel \nspreadsheet). Input V1 Input V2 Output Albania 355 case 355: return Albania ; Algeria 213 case 213: return \nAlgeria ;  String Program: Concatenate(ConstStr( ca8e ),V2, ConstStr( : return ), V1, ConstStr( ; \n)) The above examples were suf.cient for QuickCode to populate the spreadsheet with the desired output \nfor more than 200 rows, each containing data for a different country. The resultant code\u00adfragment in \nthe output column was copied and pasted in Visual Studio Development Environment as part of a switch \nstatement, and it compiled! EXAMPLE 13 (Filtering Task). Ben Zorn wanted to estimate the total number \nof page-hits to links in the pictures directory from weekly statistics consisting of pairs of links and \npage-hits. He tried to use the QuickCode add-in by giving examples where the output column was a copy \nof the input page-hit column only if the input link column contained pictures in the path. Input V1 Input \nV2 Output /um/people/sumitg/pictures/lake-tahoe/index.html 192 192 /um/people/sumitg/index.html 104 0 \n/um/people/sumitg/pubs/speed.html 16 0 /um/people/sumitg/pubs/popl10 synthesis.pdf 13 0 /um/people/sumitg/pictures/verona/index.html \n7 7 /um/people/sumitg/pictures/kerela/target21.html 3 3 Quite surprisingly for the author, the QuickCode \nadd-in worked successfully (without use of its hidden capability of being able to add new tokens -addition \nof pictures token would have done the trick). Closer investigation of the generated program revealed \nan\u00adother trick for solving the same problem: all (and only) pictures links had 6 occurrences of the backslash \ntoken -a pattern that could not have been easy for the user to discover. String Program: Switch((b1,V2), \n(b2, ConstStr(0))), where b1 = Match(V1, SlashTok, 6), and b2 =\u00acMatch(V1, SlashTok, 6). EXAMPLE 14 (Arithmetic \nTask). The synthesis engine currently does not support any arithmetic reasoning. Hence, we thought that \na few examples found on Excel help forums, asking for computing the sum of all numbers in a string, had \nto wait. However, Bill Harris showed us a cute trick that almost did it. Input V1 Output Alpha 10 Beta \n20 Charlie 30 Delta 10+20+30 POPL 9 CAV 7 PLDI 6 ESOP 4 9+7+6+4 String Program: Concatenate(Loop(AW \n: Concatenate(SubStr(V1, p1, p2), ConstStr( + ))), SubStr2(V1, NumTok, -1)) where p1 = Pos(E, NumTok,W) \nand p2 = Pos(NumTok, TokenSeq(NonDigitTok, NumTok),W). It is interesting to note above how the loop constructor \ngets used to print all, but last, numbers, each followed by a plus sign (The position expression p2 ensures \nthat there better be another number following the number to be extracted). The last integer is then concatenated \nseparately. (The desired sum can now be obtained by formatting the output column as a number inside Excel.) \n7. Related Work Work on learning concepts such as deterministic .nite state au\u00adtomata [1], or regular \ntransducers [20] from examples is not appli\u00adcable in our setting because it requires making many more \nqueries to the user, and most string processing tasks described in this paper are more expressive than \nwhat can be expressed by these concepts. The most closely related work is that of automating text-editing \nusing demonstrations or examples. These text-editor techniques may be lifted to the spreadsheet setting, \nbut they would not work well because (a) the real spreadsheet scenarios are more challeng\u00ading than what \nthese techniques can handle, (b) the PBD interface, inherent to most of these techniques, requires users \nto provide much more information that is way beyond the usability bar in spread\u00adsheets. We explain these \nissues below. Text-editing using Demonstrations SMARTedit [11] is a Pro\u00adgramming by Demonstration (PBD) \nsystem for learning text\u00adediting commands, where the primitive program statements in\u00adclude moving the \ncursor to a new position and inserting/deleting text. However, there are two signi.cant differences: \n(a) The lan\u00adguage of programs considered is not as expressive as required in the spreadsheet setting. \nIn particular, it does not provide support for conditionals, which are very important for data cleansing \ntasks in spreadsheets. Hence, it cannot be applied for the processing re\u00adquired in Examples 7, 8, 9, \n10, 13. Also, its cursor movement logic is restricted to positions either before or after the kth occurrence \nof a single token, while scanning from left side. In contrast, our position extraction logic is much \nmore powerful -it allows to iden\u00adtify positions based on kth occurrence of sequences of tokens both before \nand after the desired position, while scanning from left or right side. As a result, the SMARTedit system \ncannot be applied for processing required in Examples 1, 3, 5, and 14. (b) More sig\u00adni.cantly, as for \nany PBD system, the user is required to provide a complete demonstration or trace, where the demonstration \nconsists of a sequence of the editor state after each primitive action, really spelling out how to do \nthe transformation, but on a given exam\u00adple. The user is also required to segment each iteration of an \ninner loop. Further, PBD based systems also have the drawback of being sensitive to the order in which \nthe user chooses to perform actions. Our system is based on Programming by Example (as opposed to Demonstration) \n-it requires the user to only provide the .nal state (as opposed to also providing the intermediate states). \nThis ren\u00adders our system much more usable [10], however, at the expense of making the learning problem \nmuch more dif.cult, for which we do present an effective algorithm. TELS [22] is another PBD system \nthat records high-level ac\u00adtions similar to the actions used in SMARTedit, and implements a set of heuristics/expert \nrules for generalizing the arguments of each of the actions. However, TELS s dependence on heuristic \nrules to describe the possible generalizations makes it dif.cult to under\u00adstand the hypothesis space \nclearly, as well as to imagine applying it to the different domain of spreadsheet applications. Simultaneous \nediting [15] is another PBD-like system that al\u00adlows the user to de.ne a set of regions to edit, and \nthen allows the user to make edits in one, while the system makes equivalent edit\u00ading in all other records. \nThe inference used in simultaneous editing is much less powerful since it does not support conditional \nor loopy edits (every editing action is applied uniformly to every record). Text-editing using Examples \nNix described a text-editing system that synthesizes gap programs based on examples [17]. A gap program \nis a collection of (pattern, replacement) pairs, where each pattern is composed of constants and variables \nthat bind to the text in between the constants, and a replacement can be a constant string or a variable \nfrom the input pattern. Gap programs are not expressive enough to represent the solution of most of the \nstring processing benchmark examples described in this paper. Data Processing for Programmers The PADS \nproject has en\u00adabled simpli.cation of ad hoc data processing tasks for program\u00admers by contributing along \nseveral dimensions: development of do\u00admain speci.c languages for describing text structure or data for\u00admat \n[2, 3], learning algorithms for automatically inferring such for\u00admats [4], and a markup language to allow \nusers to add simple anno\u00adtations to enable more effective learning of text structure [23]. The learned \nformat can then be used by programmers for documenta\u00adtion or implementation of custom data analysis tools. \nIn contrast, the focus of this paper is to enable end-users (non-programmers) to perform small, often \none-off, repetitive tasks on their spread\u00adsheet data. Asking end-users to provide annotations for learning \n(relatively simple) text structure, and then develop custom tools to format/process the inferred structure \nis way above the expertise and usability bar for these users. Hence, we are interested in automating \nthe entire end-to-end process, which includes not only learning the text structure from the inputs, but \nalso learning the desired trans\u00adformation from the outputs. Algorithmic Techniques [6] provides a good \nsurvey of various program synthesis techniques: exhaustive search, logical reason\u00ading, probabilistic \ninference, and version-space algebras. Exhaus\u00adtive search based techniques would not scale for our problem \nset\u00adting since the underlying state space (even for programs of small bounded size) is huge. Logical \nreasoning techniques (such as those used in learning straight-line bit-vector programs from input-output \nexamples [8], or loopy programs from logical speci.cations [19]) are not suited for various reasons: \nthey are not as scalable (several minutes are acceptable for discovering a new bit-vector algorithm, \nbut not for an interactive spreadsheet session); they cannot deal with noise in the user input; they \ncannot easily compute all solu\u00adtions (required for providing various computational interpretations to \nthe user for an ambiguous input). The GenerateStr part of the synthesis algorithm presented in this \npaper is closest to the version-space algebra approach that in\u00advolves maintaining a set of all hypotheses \n(drawn from a hypothesis space) that are consistent with a sequence of observed examples. Mitchell originally \nused this idea for re.nement-based learning of boolean functions [16], while Lau et.al. extended the \nconcept to learning more complex functions in a PBD setting [13]. Our syn\u00adthesis algorithm shows how \nthe concepts of version-space algebra can be lifted to the PBE (Programming by Example) setting, for \na fairly expressive string expression language involving conditionals and loops. The idea of using DAGs \nas the version space for concate\u00adnate constructor is inspired by the use of a similar data-structure \nin a very different context of solving an important open problem re\u00adlated to global value numbering [7]. \nThe novel concepts introduced in this paper are quite general -we feel that they might be used to create \nPBE versions of other version-space algebra based PBD sys\u00adtems (e.g., those that learn shell scripts \n[12] or imperative Python programs [14]). 8. Conclusion General purpose computational devices, such as \ncell-phones, com\u00adputers, are becoming accessible to people at large at an impres\u00adsive rate. In the future, \nrobots will become house-hold entities. But, unfortunately, programming general purpose platforms has \nnever been easy, because we are still mostly stuck with the model of pro\u00adviding step-by-step, detailed, \nand syntactically correct instructions on how to accomplish a certain task, instead of simply describing \nwhat the task is. Program synthesis has the revolutionary potential to change this landscape, when targeted \nfor the right set of people, for the right set of problems, and using the right interaction model. In \nthis paper, we have identi.ed a killer application, that of automating string processing in spreadsheets, \nwhich hundreds of millions of end-users struggle with on a regular basis (as is evident from online help \nforums and talking to product groups). We have developed an ef.cient algorithm to help automate a variety \nof string processing tasks from input-output examples (which we found to be the most natural intent expression \nmechanism on help forums). We have paid special attention to usability issues and crossed the line from \ndeveloping an academic-only technology to one that is ready to be deployed. Acknowledgments Thanks to \nBen Zorn who had such a belief in the promise of this technology that he helped .nd connections in product \nteams even before a prototype could be built. Thanks to the Excel product team who kept engaging with \nus despite their initial skepticism whether such a magical technology can ever be possible. Thanks to \nPiali Choudhury for building a cool UI for the tool. Thanks to Bill Harris and Rishabh Singh for adding \nnew features and taking the technology to another level, details of which are beyond the scope of this \npaper. Thanks to Ras Bodik, Venkie, and David Walker for useful discussions. Finally to my Excel-literate \nparents and spouse for the best (tear-rendering) compliment after playing with the tool: For the .rst \ntime, we understand what your research is about . References [1] D. Angluin. Learning regular sets from \nqueries and counterexamples. Inf. Comput., 75(2):87 106, 1987. [2] K. Fisher and R. Gruber. PADS: a domain-speci.c \nlanguage for processing ad hoc data. In PLDI, pages 295 304, 2005. [3] K. Fisher, Y. Mandelbaum, and \nD. Walker. The next 700 data descrip\u00adtion languages. In POPL, pages 2 15, 2006. [4] K. Fisher, D. Walker, \nK. Q. Zhu, and P. White. From dirt to shovels: fully automatic tool generation from ad hoc data. In POPL, \n2008. [5] M. Gualtieri. Deputize end-user developers to deliver business agility and reduce costs. In \nForrester Report for Application Development and Program Management Professionals, April 2009. [6] S. \nGulwani. Dimensions in program synthesis. In PPDP. ACM, 2010. [7] S. Gulwani and G. C. Necula. A polynomial-time \nalgorithm for global value numbering. In SAS, pages 212 227, 2004. [8] S. Jha, S. Gulwani, S. Seshia, \nand A. Tiwari. Oracle-guided component-based program synthesis. In ICSE, 2010. [9] A. J. Ko, B. A. Myers, \nand H. H. Aung. Six learning barriers in end\u00aduser programming systems. In VL/HCC, pages 199 206, 2004. \n [10] T. Lau. Why PBD systems fail: Lessons learned for usable AI. In CHI 2008 Workshop on Usable AI, \nFlorence, Italy, 2008. [11] T. Lau, S. Wolfman, P. Domingos, and D. Weld. Programming by demonstration \nusing version space algebra. Machine Learning, 53(1\u00ad2), 2003. [12] T. Lau, L. Bergman, V. Castelli, and \nD. Oblinger. Programming shell scripts by demonstration. In Workshop on SCLAS, AAAI, 2004. [13] T. A. \nLau, P. Domingos, and D. S. Weld. Version space algebra and its application to programming by demonstration. \nIn ICML, 2000. [14] T. A. Lau, P. Domingos, and D. S. Weld. Learning programs from traces using version \nspace algebra. In K-CAP, pages 36 43, 2003. [15] R. C. Miller and B. A. Myers. Interactive simultaneous \nediting of multiple text regions. In USENIX Annual Technical Conference, 2001. [16] T. M. Mitchell. Generalization \nas search. Artif. Intell., 18(2), 1982. [17] R. P. Nix. Editing by example. TOPLAS, 7(4):600 621, 1985. \n[18] S. Russell and P. Norvig. Arti.cial Intelligence: A Modern Approach (2nd Edition). Prentice Hall, \n2 edition, December 2002. [19] S. Srivastava, S. Gulwani, and J. Foster. From program veri.cation to \nprogram synthesis. In POPL, 2010. [20] J. M. Vilar. Query learning of subsequential transducers. In Proceed\u00adings \nof the 3rd International Colloquium on Grammatical Inference, 1996. [21] J. Walkenbach. Excel 2010 Formulas. \nJohn Wiley and Sons, 2010. [22] I. H. Witten and D. Mo. TELS: learning text editing tasks from examples. \nIn Watch what I do: programming by demonstration, pages 293 307. MIT Press, Cambridge, MA, USA, 1993. \n[23] Q. Xi and D. Walker. A context-free markup language for semi\u00adstructured text. In PLDI, pages 221 \n232, 2010. \n\t\t\t", "proc_id": "1926385", "abstract": "<p>We describe the design of a string programming/expression language that supports restricted forms of regular expressions, conditionals and loops. The language is expressive enough to represent a wide variety of string manipulation tasks that end-users struggle with. We describe an algorithm based on several novel concepts for synthesizing a desired program in this language from input-output examples. The synthesis algorithm is very efficient taking a fraction of a second for various benchmark examples. The synthesis algorithm is interactive and has several desirable features: it can rank multiple solutions and has fast convergence, it can detect noise in the user input, and it supports an active interaction model wherein the user is prompted to provide outputs on inputs that may have multiple computational interpretations.</p> <p>The algorithm has been implemented as an interactive add-in for Microsoft Excel spreadsheet system. The prototype tool has met the golden test - it has synthesized part of itself, and has been used to solve problems beyond author's imagination.</p>", "authors": [{"name": "Sumit Gulwani", "author_profile_id": "81100315615", "affiliation": "Microsoft Corporation, Redmond, WA, USA", "person_id": "P2509623", "email_address": "sumitg@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926423", "year": "2011", "article_id": "1926423", "conference": "POPL", "title": "Automating string processing in spreadsheets using input-output examples", "url": "http://dl.acm.org/citation.cfm?id=1926423"}