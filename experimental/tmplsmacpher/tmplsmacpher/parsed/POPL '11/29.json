{"article_publication_date": "01-26-2011", "fulltext": "\n Multivariate Amortized Resource Analysis Jan Hoffmann Klaus Aehlig Martin Hofmann Ludwig-Maximilians-Universit\u00a8at \nM\u00a8unchen {jan.ho.mann,aehlig,martin.hofmann}@i..lmu.de Abstract We study the problem of automatically \nanalyzing the worst-case resource usage of procedures with several arguments. Existing au\u00adtomatic analyses \nbased on amortization, or sized types bound the resource usage or result size of such a procedure by \na sum of unary functions of the sizes of the arguments. In this paper we generalize this to arbitrary \nmultivariate polyno\u00admial functions thus allowing bounds of the form mn which had to be grossly overestimated \nby m 2 + n 2 before. Our framework even b encompasses bounds like mimj where the mi are the sizes i,j=n \nof the entries of a list of length n. This allows us for the .rst time to derive useful resource bounds \nfor operations on matrices that are represented as lists of lists and to considerably improve bounds \non other super-linear operations on lists such as longest common subsequence and removal of du\u00adplicates \nfrom lists of lists. Furthermore, resource bounds are now closed under composition which improves accuracy \nof the analysis of composed programs when some or all of the components exhibit super-linear resource \nor size behavior. The analysis is based on a novel multivariate amortized resource analysis. We present \nit in form of a type system for a simple .rst\u00adorder functional language with lists and trees, prove soundness, \nand describe automatic type inference based on linear programming. We have experimentally validated the \nautomatic analysis on a wide range of examples from functional programming with lists and trees. The \nobtained bounds were compared with actual resource consumption. All bounds were asymptotically tight, \nand the con\u00adstants were close or even identical to the optimal ones. Categories and Subject Descriptors \nF.3.2 [Logics And Meanings Of Programs]: Semantics of Programming Languages Program Analysis; F.3.1 [Logics \nand Meanings of Programs]: Specifying and Verifying and Reasoning about Programs General Terms Performance, \nLanguages, Theory, Reliability Keywords Functional Programming, Static Analysis, Amortized Analysis, \nResource Consumption, Quantitative Analysis 1. Introduction A primary feature of a computer program is \nits quantitative perfor\u00admance characteristics: the amount of resources like time, memory and power the \nprogram needs to perform its task. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 11, January 26 28, 2011, Austin, Texas, USA. Copyright c &#38;#169; \n2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 Ideally, it should be possible for an experienced programmer \nto extrapolate from the source code of a well-written program to its asymptotic worst-case behavior. \nBut it is often insuf.cient to determine the asymptotic behavior of program only. A conservative estimation \nof the resource consumption for a speci.c input or a comparison of two programs with the same asymptotic \nbehavior require instead concrete upper bounds for speci.c hardware. That is to say, closed functions \nin the sizes of the program s inputs that bound the number of clock cycles or memory cells used by the \nprogram for inputs of these sizes on a given system. Concrete worst-case bounds are particularly useful \nin the devel\u00adopment of embedded systems and hard real-time systems. In the former, one wants to use hardware \nthat is just good enough to ac\u00adcomplish a task in order to produce a large number of units at lowest \npossible cost. In the latter, one needs to guarantee speci.c worst\u00adcase running times to ensure the safety \nof the system. The manual determination of such bounds is very cumbersome. Cf., e.g., the careful analyses \ncarried out by Knuth in The Art of Computer Programming where he pays close attention to the con\u00adcrete \nand best possible values of constants for the MIX architecture. Not everyone commands the mathematical \nease of Knuth and even he would run out of steam if he had to do these calculations over and over again \nwhile going through the debugging loops of pro\u00adgram development. In short, derivation of precise bounds \nby hand appears to be unfeasible in practice in all but the simplest cases. As a result, automatic methods \nfor static resource analysis are highly desirable and have been the subject of extensive research. On \nthe one hand there is the large .eld of WCET (worst-case execution time) analysis [27] that is focused \non (yet not limited to) the run-time analysis of sequential code without loops taking into account low-level \nfeatures like hardware caches and instruction pipelines. On the other hand there is an active research \ncommunity that employs type systems and abstract interpretation to deal with the analysis of loops, recursion \nand data structures [15, 3, 24].1 In this paper we continue our work [16] on the resource analysis of \nprograms with recursion and inductive data structures. Our ap\u00adproach is as follows. 1. We consider Resource \nAware ML (RAML),a .rst-order fragment of OCAML that features integers, lists, binary trees, and recursion. \n2. We de.ne a big-step operational seman\u00adtics that formalizes the actual resource consumptions of programs. \nIt is parametrized with a resource metric that can be directly re\u00adlated to the compiled assembly code \nfor a speci.c system architec\u00adture [23].2 3. We describe an elaborated resource-parametric type system \nwhose type judgments establish concrete worst-case bounds in terms of closed, easily understood formulas. \nThe type system al\u00adlows for an ef.cient and completely automatic inference algorithm that is based on \nlinear programming. 4. We prove the non-trivial soundness of the derived resource bounds with respect \nto the big\u00ad 1 See \u00a78 for a detailed overview of the state of the art. 2 To obtain clock-cycle bounds \nfor atomic steps one has to employ WCET tools [23].  step operational semantics. 5. We verify the practicability \nof our approach with a publically available implementation and a repro\u00adducible experimental evaluation. \nAs pioneered by Hofmann and Jost [18] to analyze the heap\u00adspace consumption of .rst-order functional \nprograms, our type sys\u00adtem relies on the potential-method of amortized analysis to take into account \nthe interactions between different parts of a computation. This technique has been successfully applied \nto object-oriented programs [19, 20], to generic resource metrics [23, 7], to polymor\u00adphic and higher-order \nprograms [24], and to Java-like bytecode by means of separation logic [4]. The main limitation shared \nby these analysis systems is their restriction to linear resource bounds which can be ef.ciently reduced \nto solving linear constraints. A recently discovered technique [16, 17] yields an automatic amortized \nanalysis for polynomial bounds while still relying on linear constraint solving only. The resulting extension \nof the linear system [18, 23] ef.ciently computes resource bounds for .rst\u00ad b order functional programs \nthat are sums pi(ni) of univariate polynomials pi. For instance, it automatically infers evaluation-step \nbounds for the sorting algorithms quick sort and insertion sort that exactly match the measured worst-case \nbehavior of the functions [17]. The computation of these bounds takes less then a second. This analysis \nsystem for polynomial bounds has, however, two drawbacks that hamper the automatic computation of bounds \nfor larger programs. First, many functions with multiple arguments that appear in practice have multivariate \ncost characteristics like m \u00b7 n. Secondly, if data from different sources is interlinked in a program \nthen multivariate bounds like (m + n)2 arise even if all functions have a univariate resource behavior. \nIn these cases the analysis fails, or the bounds are hugely over-approximated by 3m 2 +3n 2 . To overcome \nthese drawbacks, this paper presents an auto\u00admatic type-based amortized analysis for multivariate polynomial \nresource bounds. We faced three main challenges in the develop\u00adment of the analysis. 1. The identi.cation \nof multivariate polynomials that accurately describe the resource cost of typical examples. It is necessary \nthat they are closed under natural operations to be suitable for local typing rules. Moreover, they must \nhandle an unbounded number of arguments to tightly cope with nested data structures. 2. The automatic \nrelation of sizes of data structures in function ar\u00adguments and results, even if data that is scattered \nover different locations (like n1 + n2 = n in the partitioning of quick sort). 3. The smooth integration \nof the inference of size relations and resource bounds to deal with the interactions of different func\u00adtions \nwhile keeping the analysis technically feasible in practice.  To address challenge one we de.ne multivariate \nresource polyno\u00admials that are a generalization of the resource polynomials that we used earlier [16]. \nTo address challenges two and three we introduce a multivariate potential-based amortized analysis (\u00a75 \nand \u00a76). The local type rules emit only simple linear constraints and are remark\u00adably modest considering \nthe variety of relations between different parts of the data that are taken into account. Our experiments \nwith a prototype implementation3 (see \u00a77) show that our system automatically infers tight multivariate \nbounds for complex programs that involve nested data structures such as trees of lists. Additionally, \nit can deal with the same wide range of linear and univariate programs as the previous systems. As representative \nexamples we present in \u00a77 the analyses of the dynamic programming algorithm for the length of the longest \ncom\u00admon subsequence of two lists and an implementation of insertion sort that lexicographically sorts \na list of lists. Note that the latter 3 See http://raml.tcs.ifi.lmu.de for a web interface, example pro\u00adgrams, \nand the source code. example exhibits a worst-case running time of the form O(n 2 m) where n is the length \nof the outer list and m is the maximal length of the inner lists. The reason is that each of the O(n \n2) comparisons performed by insertion sort needs time linear in m. We also implemented a more involved \ncase study on matrix op\u00aderations were matrices are lists of lists of integers. It demonstrates interesting \ncapabilities like the precise automatic tracking of data sizes when transposing matrices or the automatic \nanalyses of com\u00adplex functions like the multiplication of lists of matrices of different (.tting) dimensions. \nDetails are available on the web. The main contributions we make in this paper are as follows. 1. The \nde.nition of multivariate resource polynomials that gener\u00adalize univariate resource polynomials [16]. \n(in \u00a74) 2. The introduction of type annotation that correspond to global polynomial potential functions \nfor amortized analysis which depend on the sizes of several parts of the input. (in \u00a75) 3. The presentation \nof local type rules that modify type annota\u00adtions for global potential functions. (in \u00a76) 4. The implementation \nof an ef.cient type inference algorithm that relies on linear constraint solving only.  2. Background \nand Informal Presentation Amortized Analysis Amortized analysis with the potential method has been introduced \n[26] to manually analyze the ef.ciency of data structures. The key idea is to incorporate a non-negative \npo\u00adtential into the analysis that can be used to pay (costly) operations. To apply the potential method \nto statically analyze a program, one has to determine a mapping from machine states to potentials for \nevery program point. Then one has to show that for every pos\u00adsible evaluation, the potential at a program \npoint suf.ces to cover the cost of the next transition and the potential at the succeeding program point. \nThe initial potential is then an upper bound on the resource consumption of the program. Linear Potential \nOne way to achieve such an analysis is to use linear potential functions [18]. Inductive data structures \nare stati\u00adcally annotated with a positive rational numbers q to de.ne non\u00adnegative potentials F(n)= q \n\u00b7 n as a function of the size n of the data. Then a sound albeit incomplete type-based analysis of the \nprogram text statically veri.es that the potential is suf.cient to pay for all operations that are performed \non this data structure during any possible evaluation of the program. The analysis is best explained \nby example. Consider the func\u00adtion .lter:(int,L(int)) . L(int) that removes the multiples of a given \ninteger from a list of integers. filter(p,l) = match l with | nil -> nil | (x::xs) -> let xs = filter(p,xs) \nin if x mod p == 0 then xs else x::xs Assume that we need two memory cells to create a new list cell. \nThen the heap-space usage of an evaluation of .lter(p,,) is at most 2|,|. To infer an upper bound on \nthe heap-space usage we enrich the type of .lter with a priori unknown potential annotations4 q(0,i),pi \n. Q+0 . .lter:((int,L(int)), (q(0,0),q(0,1))) . (L(int), (p0,p1)) The intuitive meaning of the resulting \ntype is as follows: to evaluate .lter(p,,) one needs q(0,1) memory cells per element in the list , and \nq(0,0) additional memory cells. After the eval\u00aduation there are p0 memory cells and p1 cells per element \nof the returned list left. We say that the pair (p,,) has potential 4 We use the naming scheme of the \nunknowns that arises from the more general method introduced in this paper.  F((p, ,), (q(0,0),q(0,1))) \n= q(0,0) + q(0,1) \u00b7|,| and that ,' = .lter(p, ,) has potential F(,', (p0,p1)) = p0 + p1 \u00b7|,'|. A valid \npo\u00adtential annotation would be for instance q(0,0) = p0 = p1 =0 and q(0,1) =2. Another valid annotation \nwould be q(0,0) = p0 =0, p1 =2, and q(0,1) =4. It can be used to type the inner call of .lter in an expression \nlike .lter(a,.lter(b,,)). To infer the potential annotations one can use a standard type inference in \nwhich simple linear constraints are collected as each type rule is applied. For the heap-space consumption \nof .lter the constraints would state that q(0,0) = p0 and q(0,1) = 2+ p1. Univariate Polynomials An automatic \namortized analysis can be b also used to derive potential functions of the form qini i=0,...,k with qi \n= 0 while still relying on solving linear inequalities only [16]. These potential functions are attached \nto inductive data structures via type annotations of the form iq =(q0,...,qk) with qi . Q+0 . For instance, \nthe typing ,:(L(int), (4, 3, 2, 1)), de.nes |;||;| the potential F(,, (4, 3, 2, 1)) = 4+3|,| +2+1. 23 \nThe use of the binomial coef.cients rather than powers of variables has several advantages. In particular, \nthe identity b b b n+1 nn qi= qi+1+ qi i=0,...,k ii=0,...,k-1 ii=0,...,k i gives rise to a local typing \nrule for list match which allows to type naturally both, recursive calls and other calls to subordinate \nfunc\u00adtions in branches of a pattern match. This identity forms the mathematical basis of the additive \nshift < of a type annotation which is de.ned by <(q0,...,qk)= (q0 + q1,...,qk-1 + qk,qk). For example, \nit appears in the typing tail:(L(int), iq) . (L(int), <(iq)) of the function tail that removes the .rst \nelement from a list. The potential resulting from the con\u00adtraction xs:(L(int), <(iq)) of a list (x::xs):(L(int), \niq), usually in a pattern match, suf.ces to pay for three common purposes: (i) to pay the constant costs \nq1 after and before the recursive calls, (ii) to fund, by (q2,...,qn), calls to auxiliary functions, \nand (iii) to pay, by (q0,...,qn), for the recursive calls. To see how the polynomial potential annotations \nare used, con\u00adsider the function eratos:L(int).L(int) that implements the sieve of Eratosthenes. It successively \ncalls the function .lter to delete multiples of the .rst element from the input list. If eratos is called \nwith a list of the form [2, 3,...,n] then it computes the list of primes p with 2 = p = n. eratos l = \nmatch l with | nil -> nil | (x::xs) -> x::eratos(filter(x,xs)) Note that it is possible in our system \nto implement the function .lter with a destructive pattern match (just replace match with matchD). That \nwould result in a .lter function that does not consume heap\u00adcells and in a linear heap-space consumption \nof eratos. But to illus\u00adtrate the use of quadratic potential we use the .lter function with linear heap-space \nconsumption from the .rst example.5 In an eval\u00aduation of eratos(,) the function .lter is called once \nfor every sublist of the input list , in the worst case. Then the calls of .lter cause |;| a worst-case \nheap-space consumption of 22. This is for exam\u00adple the case if , is a list of pairwise distinct primes. \nAdditionally, there is the creation of a new list element for every recursive call of eratos. Thus, the \ntotal worst-case heap-space consumption of the function is 2n +2n 2if n is the size of the input list. \nTo bound the heap-space consumption of eratos, our analysis system automatically computes the following \ntype. eratos:(L(int), (0, 2, 2)) . (L(int), (0, 0, 0)) Since the typing assigns the initial potential \n2n+2n 2to a function argument of size n, the analysis computes a tight heap-space bound 5 It is just \nmore convenient to argue about heap space than to argue about evaluation steps. for eratos. In the pattern \nmatch, the additive shift assigns the type (L(int), (2, 4, 2)) to the variable xs. The constant potential \n2 is then used to pay for the cons operation (i). The non-constant potential xs:(L(int), (0, 4, 2)) is \nshared between the two occurrences of xs in the following expression by using xs:(L(int), (0, 2, 0)) \nto pay the cost of .lter(xs) (ii) and by using xs:(L(int)(0, 2, 2) to pay for the recursive call of eratos \n(iii). To infer the typing, we start with an unknown potential annota\u00adtion as in the linear case. eratos:(L(int), \n(q0,q1,q2)) . (L(int), (p0,p1,p2)) The syntax-directed type analysis then computes linear inequalities \nwhich state that q0 = p0, q1 = 2+ p1, and q2 = 2+ p2. This analysis method works for many functions that \nadmit a worst-case resource consumption that can be expressed by sums of univariate polynomials like \nn 2 + m 2. However, it often fails to compute types for functions whose resource consumption is bounded \nby a mixed term like n 2 \u00b7m. The reason is that the potential is attached to a single data structure \nand does not take into account relations between different data structures. Multivariate Bounds This \npaper extends type-based amortized m analysis to compute mixed resource bounds like 2n \u00b72. To this end, \nwe introduce a global polynomial potential annotation that can express a variety of relations between \ndifferent parts of the input. To give a .avor of the basic ideas we informally introduce this global \npotential in this section for pairs of integer lists. The potential of a single integer list can be expressed \nas a vector (q0,q1,...,qk) that de.nes a potential-function of the form bkn qi. To represent mixed terms \nof degree = k for a pair of i=0 iinteger lists we use a triangular matrix Q =(q(i,j))0=i+j=k. Then b \nQ de.nes a potential-function of the form nm 0=i+j=k q(i,j)ij where m and n are the lengths of the two \nlists. This de.nition has the same advantages as the univariate version of the system. Particularly, \nwe can still use the additive shift to as\u00adsign potential to sublists. To generalize the additive shift \nof the uni\u00ad b n+1 m variate system, we use the identity = 0=i+j=k q(i,j)ij b b nm nm + . It is re\u00ad 0=i+j=k-1 \nq(i+1,j)ij0=i+j=k q(i,j)ij.ected by two additive shifts <1(Q)=(q(i,j) + q(i+1,j))0=i+j=k and <2(Q)=(q(i,j) \n+ q(i,j+1))0=i+j=k where q(i,j) : = 0 if i + j>k. The shift operations can be used like in the univariate \ncase. For example, we derive the typing tail1: ((L(int),L(int)),Q) . ((L(int),L(int)), <1(Q)) for the \nfunction tail1(xs,ys)=(tail xs,ys). To see how the mixed potential is used, consider the function dyade \nthat computes the dyadic product of two lists. mult(x,l) = match l with | nil -> nil | (y::ys) -> x*y::mult(x,ys) \ndyade(l,ys) = match l with | nil -> nil | (x::xs) -> (mult(x,ys))::dyade(xs,ys) Similar to previous examples, \nmult consumes 2n heap cells if n is the length of input. This exact bound is represented by the typing \nmult: ((int,L(int)), (0, 2, 0)) . (L(int), (0, 0, 0)) that states that the potential is 0+2n +0n 2before \nand 0 after the evaluation of mult(x,,) if , is a list of length n. The function dyade consumes 2n +2nm \nheap cells if n is the length of .rst argument and m is the length of the second argument. This is why \nthe following typing represents a tight heap-space bound for the function. .. 000 dyade: ((L(int),L(int)), \n.22 .) . (L(int, int), 0) 0  To verify this typing of dyade, the additive shift <1 is used in the pattern \nmatching. This results in the potential .. 220 (xs,ys): ((L(int),L(int)), .22 .) 0 that is used as in \nthe function eratos: the constant potential 2 is used to pay for the cons operation (i), the linear potential \nys:(L(int), (0, 2, 0)) is used to pay the cost of mult(ys) (ii), the rest of the potential is used to \npay for the recursive call (iii). Multivariate potential is also needed to assign a super-linear po\u00adtential \nto the result of a function like append. This is, for exam\u00adple, needed to type an expression like eratos(append(,1,,2)). \nHere, append would have the type .. 022 append: ((L(int),L(int)), .42 .) . (L(int), (0, 2, 2)). 2 The \ncorrectness of the bound follows from the convolution formula n+m nm =++nm and from the fact that append \nconsumes 2 22 2n resources if n is the length of the .rst argument. The respective initial potential \n4n +2m + 2( n + m + mn) furnishes a tight 22 bound on the worst-case heap-space consumption of the evaluation \nof eratos(append(,1,,2)), where |,1| = n, |,2| = m. 3. Resource Aware ML RAML (Resource Aware ML) is \na .rst-order functional language with ML-style syntax, booleans, integers, pairs, lists, binary trees, \nrecursion and pattern match. In the implementation of RAML we already included a destructive pattern \nmatch that we could handle using the methods described here. Syntax To simplify typing rules and semantics, \nwe de.ne the following expressions of RAML to bein let normal form. In the implementation we transform \nunrestricted expressions into a let normal form with explicit sharing before the type analysis. . . e \n::= () | True | False | n | x | x1 binop x2 | f(x1,...,xn) | let x = e1 in e2 | if x then et else ef \n| (x1,x2) | nil | cons(xh,xt) | leaf | node(x0,x1,x2) . . | match x with (x1,x2) . e nil . e1 cons(xh,xt) \n. e2 | match x with| match x with .. leaf . e1 ..  node(x0,x1,x2) . e2 '' The operation (q, q ) \u00b7 (p, \np ) de.nes how to account for an eval\u00adbinop ::= + |-|*| mod | div | and | or uation consisting of evaluations \nwhose resource consumptions are e : A states that the expression e has type A under the signature S in \nthe context G. The typing rules that de.ne the typing judgment are standard and a subset of the resource-annotated \ntyping rules from \u00a75 if the resource annotations are omitted. Programs Each RAML program consists of \na signature S and a family (ef ,yf )f.dom(S) of expressions with a distinguished vari\u00adable identi.er \nsuch that yf :A fS ef :B if S(f)= A . B. We write f(y1,...,yk)= ef ' as an abbreviation to indicate that \nS(f )=(A1, (A2, (...,Ak) \u00b7\u00b7\u00b7 ) . B and y1:A1,...,yk:Ak fS ef ' :B. In this case, f is de.ned by ef = \nmatch yf with (y1,yf ' ) . ' ''' match yf with (y2,yf ) ...ef . Of course, one can use such func\u00adtion \nde.nitions also in the implementation. Operational Semantics To prove the correctness of our analysis, \nwe de.ne a big-step operational semantics that measures the quan\u00adtitative resource consumption of programs. \nIt is parametric in the resource of interest and can measure every quantity whose usage in a single evaluation \nstep can be bounded by a constant. The actual constants for a step on a speci.c system architecture can \nbe derived by analyzing the translation of the step in the compiler implemen\u00adtation for that architecture \n[23]. The semantics is formulated with respect to a stack and a heap as usual: A value v . Val is either \na location , . Loc, a boolean constant b, an integer n, a null value NULL or a pair of values (v1,v2).A \nheap is a .nite partial mapping H : Loc . Val from locations to values. A stack is a .nite partial mapping \nV : VID . Val from variables to values. The operational evaluation rules de.ne an evaluation judgment \nof the form V, Hf e . v, H ' | (q, q ' ) expressing the following. If the stack V and the initial heap \nH are given then the expression e evaluates to the value v and the new heap H '. To evaluate e one needs \nat least q . Q+ resource units and after the evaluation there are q ' . Q+ resource units available. \nThe actual resource consumption is then d = q - q '. The quantity d is negative if resources become available \nduring the execution of e. Fig. 1 shows the evaluation rules of the big-step semantics. There is at most \none pair (q, q ' ) such that V, Hf e . v, H ' |(q, q ' ) for a given expression e, a heap H and a stack \nV. The non\u00adnegative number q is the (high) watermark of resources that are used simultaneously during \nthe evaluation. It is handy to view the pairs (q, q ' ) in the evaluation judgments as elements of a \nmonoid Q =(Q+ \u00d7 Q+0 , \u00b7). The neutral element 0 is (0, 0) which means that resources are neither used \nnor restituted. We skip the standard de.nitions of integer constants n . Z and de.ned by (q, q ' ) and \n(p, p ' ), respectively. We de.ne variable identi.ers x . VID. For the resource analysis it is unim\u00adportant \nwhich ground operations are used in the de.nition of binop. In fact, one can use here every function \nthat has a constant worst\u00adcase resource consumption. Simple Types We de.ne the well-typed expressions \nof RAML by assigning a simple type, a usual ML type without resource annotations, to well-typed expressions. \nSimple types are data types and .rst-order types as given by the grammars below. A ::= unit | bool | \nint | L(A) | T (A) | (A, A) F ::= A . A To each simple type A we assign a set of semantic values [A]in \nthe obvious way. For example [T (int, int)] is the set of .nite binary trees whose nodes are labeled \nwith pairs of integers. It is convenient to identify tuples like (A1,A2,A3,A4) with the pair type (A1, \n(A2, (A3,A4))). A typing context G is a partial, .nite mapping from variable identi.ers to data types. \nA signature S is a .nite, partial mapping of function identi.ers to .rst-order types. The typing judgment \nG fS '' ' '' (q + p - q, p ) if q = p (q, q ) \u00b7 (p, p )='' (q, p + q ' - p) if q >p If resources are \nnever restituted (as with time) then we can restrict to elements of the form (q, 0) and (q, 0) \u00b7 (p, \n0) is just (q + p, 0). We identify a rational number q with an element of Q as fol\u00adlows: q = 0 denotes \n(q, 0) and q< 0 denotes (0, -q). This nota\u00adtion avoids case distinctions in the evaluation rules since \nthe con\u00adstants K that appear in the rules might be negative. A notorious dissatisfying feature of classical \nbig-step semantics is that it does not provide evaluation judgments for non-terminating evaluations. \nIn a companion paper [17] we describe a big-step oper\u00adational semantics for partial evaluations that \nagrees with the usual big-step semantics on terminating computations. It inductively de\u00ad.nes statements \nof the form V, Hf e . | q for a stack V, a heap H, q . Q+0 and an expression e. The meaning is that there \nis a par\u00adtial evaluation of e with the stack V and the heap H that consumes q resources. This allows \nfor a smooth extension of the soundness theorem (Theorem 1) to non-terminating evaluations (see [17]). \n x . dom(V) n . Z (E:VAR) (E:CONSTU) (E:CONSTI) unit int V, Hf x V(x), H| Kvar V, Hf () NULL, H| KV, \nHf n n, H| K b .{True, False}V(x)= v [yf . v], Hf ef v ' , H ' | (q, q ' ) (E:CONSTB) (E:APP) bool ' \n| Kapp ' ) \u00b7 Kapp V, Hf b b, H| KV, Hf f(x) v, H ' \u00b7 (q, q 12 x1,x2 . dom(V) v = op(V(x1), V(x2)) V(x)= \nTrue V, Hf et v, H ' | (q, q ' ) (E:CONDT) (E:BINOP) conT ' conT V, Hf x1 op x2 v, H| Kop V, Hf if x \nthen et else ef v, H ' | K\u00b7(q, q )\u00b7K 12 V(x)= False V, Hf ef v, H ' | (q, q ' ) (E:CONDF) conF ' conF \n V, Hf if x then et else ef v, H ' | K1 \u00b7(q, q )\u00b7K2 V, Hf e1 v1, H1 | (q, q ' ) V[x . v1], H1 f e2 v2, \nH2 | (p, p ' ) (E:LET) let ' let ' let V, Hf let x = e1 in e2 v2, H2 | K1 \u00b7 (q, q ) \u00b7 K2 \u00b7 (p, p ) \u00b7 \nK3 x1,x2 . dom(V) v =(V(x1), V(x2)) V(x)=(v1,v2) V[x1 . v1,x2 . v2], Hf e v, H ' | (q, q ' ) (E:PAIR) \n(E:MATP) pair matP ' matP V, Hf (x1,x2) v, H| KV, Hf match x with (x1,x2) . e v, H ' | K1 \u00b7 (q, q ) \u00b7 \nK2 xh,xt . dom(V) v =(V(xh), V(xt)) l . dom(H) nil l, H[l . v] | Kcons (E:NIL) (E:CONS) V, Hf nil NULL, \nH| KV, Hf cons(xh,xt) V(x)= NULL V, Hf e1 v, H ' | (q, q ' ) (E:MATNIL) matN ' matN V, Hf match x with \n| nil . e1 | cons(xh,xt) . e2 v, H ' | K1 \u00b7 (q, q ) \u00b7 K2 V(x)=l H(l)=(vh,vt) V[xh .vh,xt .vt], Hf e2 \nv, H ' | (q, q ' ) (E:MATCONS) matC ' matC V, Hf match x with | nil . e1 | cons(xh,xt) . e2 v, H ' | \nK1 \u00b7 (q, q ) \u00b7 K2 x0,x1,x2 . dom(V) v =(V(x0), V(x1), V(x2)) l . dom(H) (E:LEAF) (E:NODE) leaf node V, \nHf leaf NULL, H| KV, Hf node(x0,x1,x2) l, H[l . v] | K V(x)= NULL V, Hf e1 v, H ' | (q, q ' ) (E:MATLEAF) \nmatTL ' matTL V, Hf match x with | leaf . e1 | node(x0,x1,x2) . e2 v, H ' | K1 \u00b7 (q, q ) \u00b7 K2 V(x)=l \nH(l)=(v0,v1,v2) V[x0 .v0,x1 .v1,x2 .v2], Hf e2 v, H ' | (q, q ' ) (E:MATNODE) matTN ' matTN V, Hf match \nx with | leaf . e1 | node(x0,x1,x2) . e2 v, H ' | K1 \u00b7 (q, q ) \u00b7 K2 Figure 1. Evaluation rules of the \nbig-step operational semantics. The Cost-Free Resource Metric The type rules in \u00a76 make use of the cost-free \nresource metric. This is the metric in which all constants K that appear in the rules are instantiated \nto zero. It follows that if V, Hf e v, H ' | (q, q ' ) then q = q ' =0. We will use the cost-free metric \nin \u00a76 to pass on potential in the typing rule for let expressions. Well-Formed Environments If H is a \nheap, v is a value, A is a type, and a . [A] then we write H F v .a : A to mean that v de.nes the semantic \nvalue a . [A] when pointers are followed in H in the obvious way. We elide a formal de.nition of this \njudgment. Note that if H F v .a : A then v may well point to a data structure with some aliasing, but \nno circularity is allowed since this would require in.nitary values a. We do not include them because \nin our functional language there is no way of generating such values; in principle our method can encompass \ncircular data [19]. We also write H F v : A to indicate that there exists a, neces\u00adsarily unique, semantic \nvalue a . [A] so that H F v .a : A .A stack V and a heap H are well-formed with respect to a context \nG if H F V(x) : G(x) holds for every x . dom(G). We then write H F V:G. Formal de.nitions can be found \nin the literature [24]. 4. Resource Polynomials A resource polynomial maps a value of some data type \nto a non\u00adnegative rational number. Potential functions are always given by such resource polynomials. \nIn the case of an inductive tree-like data type, a resource poly\u00adnomial will only depend on the list \nof entries of the data structure in pre-order. Thus, if D(A) is such a data type with entries of type \nA, e.g., A-labelled binary trees, and v is a value of type D(A) then we write elems(v)=[a1,...,an] for \nthis list of entries. An analysis of typical polynomial computations operating on a data structure v \nwith elems(v)=[a1,...,an] shows that it con\u00adsists of operations that are executed for every k-tuple (ai1 \n,...,aik ) with 1 = i1 < \u00b7\u00b7\u00b7 <ik = n. The simplest examples are linear map operations that perform some \noperation for every ai. Another example are common sorting algorithms that perform comparisons for every \npair (ai,aj ) with 1 = i<j = n in the worst case. Base Polynomials For each data type A we now de.ne \na set P(A) of functions p : [A] . N that map values of type A to natural numbers. The resource polynomials \nfor type A are then given as nonnegative rational linear combinations of these base polynomials. We de.ne \nP(A) as follows.  P(A)= {a . 1} if A is an atomic type P(A1,A2)= {(a1,a2) . p1(a1) \u00b7 p2(a2) | pi .P(Ai)} \nk k P(D(A)) = {v .pi(aji ) | k . N,pi .P(A)} 1=j1<\u00b7\u00b7\u00b7<jk=ni=1 In the last clause [a1,...,an]= elems(v). \nEvery set P(A) con\u00adtains the constant function v . 1. In the case of D(A) this arises for k =0 (one element \nsum, empty product). |;| For example, the function , . k is in P(L(A)) for ev\u00adery k . N; simply take \np1 = ... = pk =1 in the def\u00ad |;1||;2| inition of P(D(A)). The function (,1,,2) .\u00b7 is k1 k2 in P(L(A),L(B)) \nfor every k1,k2 . N and [,1,...,,n] . b |;i||;j | \u00b7 .P(L(L(A))) for every k1,k2 . N. 1=i<j=nk1 k2 Resource \nPolynomials A resource polynomial p : [A] . Q+ 0 for a data type A is a non-negative linear combination \nof base polynomials, i.e., p =qi \u00b7 pi i=1,...,m for qi . Q+0 and pi .P(A). We write R(A) for the set \nof resource polynomials for A. An instructive, but not exhaustive, example is given by Rn = R(L(int),...,L(int)). \nThe set Rn is the set of linear combinations of products of binomial coef.cients over variables x1,...,xn, \nthat ba m nxj is, Rn = { qi | qi . Q+0 ,m . N,kij . N}. i=1 j=1 kij These expressions naturally generalize \nthe polynomials used in our univariate analysis [16] and meet two conditions that are im\u00adportant to ef.ciently \nmanipulate polynomials during the analysis. First, the polynomials are non-negative, and secondly, they \nare closed under the discrete difference operators .i for every i. The discrete derivative .i p is de.ned \nthrough .i p(x1,...,xn)= p(x1,...,xi +1,...,xn) - p(x1,...,xn). As in [16] it can be shown that Rn is \nthe largest set of polynomi\u00adals enjoying these closure properties. It would be interesting to have a \nsimilar characterisation of R(A) for arbitrary A. So far, we know that R(A) is closed under sum and product \n(see Lemma 1) and are compatible with the construction of elements of data structures in a very natural \nway (see Lemmas 2 and 3). This provides some justi.cation for their choice and canonicity. An abstract \ncharacter\u00adization would have to take into account the fact that our resource polynomials depend on an \nunbounded number of variables, e.g., sizes of inner data structures, and are not invariant under permuta\u00adtion \nof these variables. It seems that some generalization of in.nite symmetric polynomials to subgroups of \nthe symmetric group could be useful, but this would not serve our immediate goal of accurate multivariate \nresource analysis. 5. Annotated Types The resource polynomials described in \u00a74 are non-negative linear \ncombinations of base polynomials. The rational coef.cients of the linear combination are present as type \nannotations in our type sys\u00adtem. To relate type annotations to resource polynomials we sys\u00adtematically \ndescribe base polynomials and resource polynomials for data of a given type. If one considers only univariate \npolynomials then their descrip\u00adtion is straightforward. Every inductive data of size n admits a po\u00ad b \ntential of the form qin . So we can describe the potential 1=i=ki function with a vector iq =(q1,...,qk) \nin the corresponding recur\u00ad q sive type. For instance can we write Li(A) for annotated list types. Since \neach annotation refers to the size of one input part only, uni\u00advariatly annotated types can be directly \ncomposed. For example, an annotated type for a pair of lists has the form (Liq(A),Lpi(A)). See [16] for \ndetails. Here, we work with multivariate potential functions, i.e., func\u00adtions that depend on the sizes \nof different parts of the input. For a pair of lists of lengths n and m we have, for instance, a potential \nb function of the form qijn m which can be described 0=i+j=k ijby the coef.cients qij . But we also want \nto describe potential func\u00adtions that refer to the sizes of different lists inside a list of lists, etc. \nThat is why we need to describe a set of indexes I(A) that enu\u00admerate the basic resource polynomials \npi and the corresponding coef.cients qi for a data type A. These type annotations can be, in a straight \nforward way, automatically transformed into usual easily understood polynomials. This is done in our \nprototype to present the bounds to the user at the end of the analysis. Names For Base Polynomials To \nassign a unique name to each base polynomial we de.ne the index set I(A) to denote resource polynomials \nfor a given data type A. Interestingly, but as we .nd coincidentally, I(A) is essentially the meaning \nof A with every atomic type replaced by unit. I(A)= {*} if A .{int, bool, unit} I(A1,A2)= {(i1,i2) | \ni1 . I(A1) and i2 . I(A2)} I(L(B)) = I(T (B)) = {[i1,...,ik] | k = 0,ij . I(B)} The degree deg(i) of \nan index i . I(A) is de.ned as follows. deg(*)=0 deg(i1,i2) = deg(i1) + deg(i2) deg([i1,...,ik]) = k \n+ deg(i1)+ \u00b7\u00b7\u00b7 + deg(ik) De.ne Ik(A)= {i . I(A) | deg(i) = k}. The indexes i . Ik(A) are an enumeration \nof the base polyonomials pi .P(A) of degree at most k. For each i . I(A), we de.ne a base polynomial \npi .P(A) as follows: If A .{int, bool, unit} then p*(v)=1. If A =(A1,A2) is a pair type and v =(v1,v2) \nthen p(i1,i2)(v)= pi1 (v1) \u00b7 pi2 (v2) If A = D(B) (in our type system D is either lists or binary node\u00adlabelled \ntrees) is a data structure and elems(v)=[v1,...,vn] then p[i1,...,im](v)=pi1 (vj1 ) \u00b7\u00b7\u00b7 pim (vjm ) 1=j1<\u00b7\u00b7\u00b7<jm=n \nWe use the notation 0A (or just 0) for the index in I(A) such that p0A (a)=1 for all a. We have 0int \n= * and 0(A1,A2) = (0A1 , 0A2 ) and 0D(B) = []. If A = D(B) for B a data type then the index [0,..., \n0] . I(A) of length n is denoted by just n. We identify the index (i1,i2,i3,i4) with the index (i1, (i2, \n(i3,i4))). For a list i =[i1,...,ik] we write i0::i to denote the list [i0,i1,...,ik]. Furthermore, we \nwrite ii ' for the concatenation of two lists i and i ' . ' '' Lemma 1 If p, p .R(A) then p+p ,p\u00b7p .R(A), \nand deg(p+ p ' ) = max{deg(p), deg(p ' )} and deg(p\u00b7p ' ) = deg(p)+deg(p ' ). By linearity it suf.ces \nto show this lemma for base polynomials. This is done by induction on A. Corollary 1 For every p .R(A, \nA) there exists p ' .R(A) with deg(p ' ) = deg(p) and p ' (a)= p(a, a) for all a . [A]. This follows \ndirectly from Lemma 1 noticing that base polynomials p .P(A, A) take the form pi \u00b7 pi! .  Lemma 2 Let \na . [A] and , . [L(A)]. Let i0,...,ik . I(A) and k = 0. Then p[i0,i1,...,ik]([]) = 0 and p[i0,i1,...,ik](a::,)= \npi0 (a) \u00b7 p[i1,...,ik](,)+ p0(a) \u00b7 p[i0,i1,...,ik](,). To prove this, one decomposes the sum in the de.nition \nof p[i0,i1,...,ik](a::,) into two summands, one corresponding to the case where the .rst position j1 \nequals one, thus hits a and where it is greater than one, thus a is not considered. Note that p0(a)=1; \nthis factor is there to achieve the format of the resource polynomials for types like (A, L(A)). Lemma \n3 characterizes concatenations of lists (written as jux\u00adtaposition) as they will occur in the construction \nof tree-like data. Note that, e.g., elems(node(a, t1,t2)) = a::elems(t1) elems(t2). Lemma 3 Let ,1,,2 \n. [L(A)]. Then ,1,2 . [L(A)] and bk p[i1,...,ik](,1,2)= p[i1,...,it](,1) \u00b7 p[it+1,...,ik](,2). t=0 This \ncan be proved by induction on the length of ,1 using Lemma 2 or else by a decomposition of the de.ning \nsum according to which indices hit the .rst list and which ones hit the second. Annotated Types and Potential \nFunctions We use the indexes and base polynomials to de.ne type annotations and resource poly\u00adnomials. \nWe then give examples to illustrate the de.nitions. A type annotation for a data type A is de.ned to \nbe a family QA =(qi)i.I(A) with qi . Q+ 0 We say QA is of degree (at most) k if qi =0 for every i . I(A) \nwith deg(i) >k. An annotated data type is a pair (A, QA) of a data type A and a type annotation QA of \nsome degree k. Let H be a heap and let v be a value with H F v.a : A for a data type A. Then the type \nannotation QA de.nes the potential FH(v:(A, QA)) = qi \u00b7 pi(a) i.I(A) Usually we de.ne type annotations \nQA by only stating the values of the non-zero coef.cients qi. However, it is sometimes handy to write \nannotations (q0,...,qn) for a list of atomic types just as a vector. Similarly, we write annotations \n(q0,q(1,0),q(0,1),q(1,1),...) for pairs of lists of atomic types sometimes as a triangular matrix. If \na . [A] and Q is a type annotation for A then we also write b F(a :(A, Q)) for i qipi(a). Examples The \nsimplest annotated types are those for atomic data types like integers. The indexes for int are I(int)= \n{*} and thus each type annotation has the form (int,q0) for a q0 . Q+0 . It de.nes the constant potential \nfunction FH(v:(int,q0)) = q0. Similarly, tuples of atomic types feature a single index of the form (*,..., \n*) and a constant potential function de.ned by some q(*,...,*) . Q+0 . More interesting examples are \nlists of atomic types like, e.g., L(int). The set of indexes of degree k is then Ik(L(int)) = {[], [*], \n[*, *],..., [*, ..., *]} where the last list contains k unit el\u00adements. Since we identify a list of i \nunit elements with the integer i we have Ik(L(int)) = {0, 1,...,k}. Consequently, annotated types have \nthe form (L(int), (q0,...,qk)) for qi . Q+0 . The de\u00ad.ned potential function is F([a1,...,an]:(L(int), \n(q0,...,qn)) = b qin . 0=i=ki The next example is the type (L(int),L(int)) of pairs of inte\u00adger lists. \nThe set of indexes of degree k is Ik(L(int),L(int)) = {(i, j) | i + j = k} if we identify lists of units \nwith their lengths as usual. Annotated types are then of the from ((L(int),L(int)),Q) for a triangular \nk \u00d7 k matrix Q with non-negative rational en\u00adtries. If ,1 =[a1,...,an], ,2 =[b1,...,bm] are two lists \nthen the potential function is F((,1,,2), ((L(int),L(int)), (q(i,j)))) = b nm . 0=i+j=k q(i,j) ij Finally, \nconsider the type A = L(L(int)) of lists of lists of integers. The set of indexes of degree k is then \nIk(L(L(int))) = b {[i1,...,im] | m = k, ij . N,ij = k - m} = j=1,...,m {0,...,k}.{[1],..., [k - 1]}.{[0, \n1],...} . \u00b7\u00b7\u00b7 . Let , = [[a11,...,a1m1 ],..., [an1,...,anmn ]] be a list of lists and Q = (qi)i.Ik(L(L(int))) \nbe a corresponding type annotation. The de.ned potential function is then F(,, (L(L(int)),Q)) = bb mj1 \nmjl [i1,...,il].Ik(A)1=j1<\u00b7\u00b7\u00b7<jl=n q[i1,...,il] \u00b7\u00b7\u00b7 i1 il In practice the potential functions are usually \nnot very complex since most of the qi are zero. Note that the resource polynomials for binary trees are \nidentical to those for lists. The Potential of a Context For use in the type system we need to extend \nthe de.nition of resource polynomials to typing contexts. We treat a context like a tuple type. Let G= \nx1:A1,...,xn:An be a typing context and let k . N. The index set Ik(G) is de.ned through Ik(G) = {(i1,...,in) \n| ij . Imj (Aj ),mj = k}. j=1,...,n A type annotation Q of degree k for G is a family Q =(qi)i.Ik(G) \nwith qi . Q+0 . We denote a resource-annotated context with G; Q. Let H be a heap and V be a stack with \nH F V :G where H F V(xj ).axj : G(xj ) . The potential of G; Q with respect to H and V is n k FV,H(G; \nQ)= qii pij (axj ) (i1,...,in).Ik(G) j=1 In particular, if G= \u00d8 then Ik(G) = {()} and FV,H(G; q())= q(). \nWe sometimes also write q0 for q(). 6. Type Rules If f : [A] . [B] is a function computed by some program \nand K(a) is the cost of the evaluation of f (a) then our type system will essentially try to identify \nresource polynomials p .R(A) and p\u00af.R(B) such that p(a) = p\u00af(f (a)) + K(a). The key aspect of such amortized \ncost accounting is that it interacts well with composition. Proposition 1 Let p .R(A), p..R(B), p\u00af.R(C), \nf : [A] . [B], g : [B] . [C], K1 : [A] . Q, and K2 : [B] . Q. If p(a) = p.(f(a)) + K1(a) and p.(b) = \np\u00af(g(b)) + K2(b) for all a, b, c then p(a) = p\u00af(g(f(a))) + K1(a)+ K2(f(a)) for all a. Notice that if \nwe merely had p(a) = K1(a) and p.(b) = K2(b) then no bound could be directly obtained for the composition. \nInteraction with parallel composition, i.e., (a, c) . (f(a),c), is more complex due to the presence of \nmixed multiplicative terms in the resource polynomials. Proposition 2 Let p .R(A, C),p\u00af.R(B, C), f : \n[A] . [B], and K : . Q. For each j . I(C) let p(j) .R(A) [A] b (j)(j) and p\u00af.R(B) be such that p(a, c)= \nj p(a)pj (c) and b p\u00af(b, c)= j p\u00af(j)(b)pj (c). (0)(a) = (j)(a) = If pp\u00af(0)(f (a)) + K(a) and pp\u00af(j)(f(a)) \nholds for all a and j =0 then p(a, c) = p\u00af(f(a),c)+ K(a). In fact, the situation is more complicated \ndue to our accounting for high watermarks as opposed to merely additive cost, and also due to the fact \nthat functions are recursively de.ned and may be partial. Furthermore, we have to deal with contexts \nand not merely types. To gain an intuition for the development to come, the above simpli.ed view should, \nhowever, prove helpful.  Type Judgments The declarative type rules for RAML expres\u00adsions (see Fig. 2) \nde.ne a resource-annotated typing judgment of the form S; G; Q f e :(A, Q ' ) where e is a RAML expression, \nS is a resource-annotated signature (see below), G; Q is a resource\u00adannotated context and (A, Q ' ) is \na resource-annotated data type. The intended meaning of this judgment is that if there are more than \nF(G; Q) resource units available then this is suf.cient to eval\u00aduate e. In addition, there are more than \nF(v:(A, Q ' )) resource units left if e evaluates to a value v. Programs with Annotated Types Resource-annotated \n.rst-order types have the form (A, Q) . (B, Q ' ) for annotated data types (A, Q) and (B, Q ' ).A resource-annotated \nsignature S is a .nite, partial mapping of function identi.ers to sets of resource-annotated .rst-order \ntypes. A RAML program with resource-annotated types consists of a resource-annotated signature S and \na family of expressions with variables identi.ers (ef ,yf )f.dom(S) such that S; yf :A; Q f ef : (B, \nQ ' ) for every function type (A, Q) . (B, Q ' ) . S(f ). Notations Families that describe type and context \nannotations are denoted with upper case letters Q, P, R, . . . with optional super\u00adscripts. We use the \nconvention that the elements of the families are the corresponding lower case letters with corresponding \nsuper\u00adscripts, i.e., Q =(qi)i.I , Q ' =(qi' )i.I , and Qx =(qix)i.I . Let Q, Q ' be two annotations with \nthe same index set I. We write Q = Q ' if qi = qi ' for every i . I. For K . Q we write Q = Q ' + K to \nstate that qi0 = qi0 ' + K = 0 and qi = qi ' for i = i0 . I. Let G=G1, G2 be a context, let i =(i1,...,ik) \n. I(G1) and j =(j1,...,jl) . I(G2) . We write (i, j) to denote the index (i1,...,ik,j1,...,jl) . I(G). \nWe write S; G; Q cf e :(A, Q ' ) to refer to cost-free type judgments where all constants K in the rules \nfrom Fig. 2 are zero. We use it to assign potential to an extended context in the let rule. More explanations \nwill follow later. Let Q be an annotation for a context G1, G2. For j . I(G2) we de.ne the projection \npj G1 (Q) of Q to G1 to be the annotation Q ' with qi ' = q(i,j). The essential properties of the projections \nare stated by Propositions 2 and 3; they show how the analysis of jux\u00adtaposed functions can be broken \ndown to individual components. Proposition 3 Let G,x:A; Q be an annot. context, H F V :G,x:A, and H F \nV(x).a : A . Then it is true that FV,H(G,x:A; Q)= b FV,H(G; pj G(Q)) \u00b7 pj (a). j.I(A) Additive Shift \nA key notion in the type system is the additive shift that is used to assign potential to typing contexts \nthat result from a pattern match or from the application of a constructor of an inductive data type. \nWe .rst de.ne the additive shift, then illustrate the de.nition with examples and .nally state the soundness \nof the operation. Let G,y:L(A) be a context and let Q =(qi)i.I(G,y:L(A)) be a context annotation of degree \nk. The additive shift for lists <L(Q) of Q is an annotation <L(Q)=(qi' )i.I(G,x:A,xs:L(A)) of degree \nk for a context G,x:A, xs:L(A) that is de.ned through ' q(i,j::;) + q(i,;) j =0 q = (i,j,;) q(i,j::;) \nj =0 Let G,t:T (A) be a context and let Q =(qi)i.I(G,t:T (A)) be a context annotation of degree k. The \nadditive shift for binary trees <T (Q) of Q is an annotation <T (Q)=(qi' )i.I(G!) of degree k for a context \nG ' =G,x:A, xs1:T (A), xs2:T (A) that is de.ned by ' q(i,j::;1;2) + q(i,;1;2) j =0 q = (i,j,;1,;2) q(i,j::;1;2) \nj =0 The de.nition of the additive shift is short but substantial. We be\u00adgin by illustrating its effect \nin some example cases. To start with, consider a context ,:L(int) with a single integer list that features \nan annotation (q0,...,qk)=(q[],...,q[0,...,0]). The shift opera\u00adtion <L for lists produces an annotation \nfor a context of the form x:int, xs:L(int), namely <L(q0,...,qk)=(q(0,0),...,q(0,k)) such that q(0,i) \n= qi + qi+1 for all i<k and q(0,k) = qk. This is exactly the additive shift that we introduced in our \nprevious work for the univariate system [16]. We use it in a context where , points to a list of length \nn +1 and xs is the tail of ,. It re.ects the fact that bb b n+1 nn qi = qi+1 + qi . i=0,...,k i i=0,...,k-1 \nii=0,...,k i Now consider the annotated context t:T (int); (q0,...,qk) with a single variable t that \npoints to a tree with n +1 nodes. The additive shift <T produces an annotation for a context of the form \nx:int,t1:T (int),t2:T (int). We have <T (q0,...,qk)= (q(0,i,j))i+j=k where q(0,i,j) = qi+j + qi+j+1 if \ni + j<k and q(0,i,j) = qi+j if i + j = k. The intention is that t1 and t2 are the subtrees of t which \nhave n1 and n2 nodes, respectively (n1 + n2 = n). The de.nition of the additive shift for trees incorporates \nthe b n+m nm convolution = for binomials. It is true ki+j=ki j bb n+1 nn that qi =(qi + qi+1)+ qk = i=0,...,k \ni i=0,...,k-1ik bk-1 b n1 b n1 n2 n2 (qi + qi+1)+ qi . i=0 j1+j2=ij1 j2 j1+j2=kj1 j2 As a last example \nconsider the context l1:L(int),l2:L(int); Q where Q =(q(i,j))i+j=k, l1 is a list of length m, and l2 \nis a list of length n +1. The additive shift results in an annotation for a context of the form l1:L(int),x:int, \nxs:L(int) and the intention is that xs is the tail of l2, i.e., a list of length n. From the de.nition \nit follows that <L(Q)=(q(i,0,j))i+j=k where q(i,0,j) = q(i,j) + q(i,j+1) if i + j<k and q(i,0,j) = q(i,j) \nif i + j = k. The soundness follows from the fact that for every i = k it is true that bk-i mn+1 m bk-i-1 \nn j=1 q(i,j) ij = ij=0 (q(i,j) + q(i,j+1)) i + n q(i,k-i) . k Lemmas 4 and 5 state the soundness of the \nshift operations. Lemma 4 Let G,,:L(A); Q be an annotated context, H F V : G,,:L(A), H(,)=(v1,, ' ) and \nlet V ' = V[xh . v1,xt . , ' ]. Then H F V ' :G,xh:A, xt:L(A) and FV,H(G,,:L(A); Q)= FV! ,H(G,xh:A, xt:L(A); \n<L(Q)). This is a consequence of Lemma 2. One takes the linear combina\u00adtion of instances of its second \nequation and regroups the right hand side according to the base polynomials for the resulting context. \nLemma 5 Let G,t:T (A); Q be an annotated context, H F V : G,t:T (A), H(t)=(v1,t1,t2), and V ' = V[x0 \n. v1,x1 . t1,x2 . t2]. If G ' =G,x:A, x1:T (A),x2:T (A) then H F V ' :G ' and FV,H(G,t:T (A); Q)=FV! \n,H(G ' ; <T (Q)). We remember that the potential of a tree only depends on the list of nodes in pre-order. \nSo, we can think of the context splitting as done in two steps. First the head is separated, as in Lemma \n4, and then the list of remaining elements into two lists. Lemma 5 is then proved like the previous one \nby regrouping terms using Lemma 2 for the .rst separation and Lemma 3 for the second one. Sharing Let \nG,x1:A, x2:A; Q be an annotated context. The shar\u00ading operation y(Q) de.nes an annotation for a context \nof the form G,x:A. It is used when the potential is split between multiple oc\u00adcurrences of a variable. \nThe following lemma shows that sharing is a linear operation that does not lead to any loss of potential. \nLemma 6 Let A be a data type. Then there are non-negative ratio\u00ad (i,j) nal numbers ck for i, j, k . I(A) \nand deg(k) = deg(i, j) such that the following holds. For every context G,x1:A, x2:A; Q and every H, \nV with H F V :G,x:A it holds that FV,H(G,x:A; Q ' )= FV! ,H(G,x1:A, x2:A; Q) where V ' = V[x1,x2 .V(x)] \nand b ' (i,j) q = cq(;,i,j). (;,k) i,j.I(A) k  ' + Kvar unit ' int ' Q = Qq0 = Kq0 =0 n . Z q0 = Kq0 \n=0 (T:VAR) (T:CONSTU) (T:CONSTI) '' ' x:A; Q f x :(A, Q ) \u00d8; Q f () : (unit,Q ) \u00d8; Q f n :(int,Q ) bool \n' = Kop ' b .{True, False} q0 = Kq0 =0 op .{+, -, *, mod, div} q(0,0) q0 =0 (T:CONSTB) (T:OPINT) \u00d8; Q \nf b :(bool,Q ' ) x1:int,x2:int; Q f x1 op x2 :(int,Q ' ) app '' app '' ' P +K= QP = Q +K(A, P ) . (A \n,P ) . S(f) op .{or, and} q(0,0) =Kop q0=0 12 (T:APP) (T:OPBOOL) '' ' x:A; Q f f(x):(A ,Q ) x1:bool,x2:bool; \nQ f x1 op x2 :(bool,Q ) '' let G1 ' = px:A let '' let G1; P f e1 :(A, P )G2,x:A; R f e2 :(B, R ) P + \nK1 = pi(Q) P i0 (R)+ K2 R = Q + K3 0 G1, G2; Q f let x = e1 in e2 :(B, Q ' ) ' conT G '' conT ' G; P \nf et :(A, P ) P +K1 = p0 (Q) P =Q +K2 G,x1:A1,x2:A2; P f e :(B, P ) ' conF G '' conF matP '' matP G; \nR f ef :(A, R ) R+K1 = p0 (Q) R =Q +K2 P + K1 = QP = Q + K2 (T:COND) (T:MATP) G,x:bool; Q f if x then \net else ef :(A, Q ' )G,x:A; Q f match x with (x1,x2) . e :(B, Q ' ) ' pair nil ' leaf ' Q = Q + Kq0 = \nKqi0 =0 q0 = Kqi0 =0 (T:PAIR) (T:NIL) (T:LEAF) '' ' x1:A1,x2:A2; Q f (x1,x2) : ((A1,A2),Q ) \u00d8; Q f nil \n:(L(A),Q ) \u00d8; Q f leaf :(T (A),Q ) ' )+ Kcons ' node Q = <L(QQ = <T (Q )+ K (T:CONS) (T:NODE) xh:A, xt:L(A); \nQ f cons(xh,xt):(L(A),Q ' ) x0:A, x1:T (A),x2:T (A); Q f node(x0,x1,x2):(T (A),Q ' ) ' matN G G; R f \ne1 :(B, R ) R + K1 = p0 (Q) '' matN ' matC '' matC R = Q + K2 G,xh:A, xt:L(A); P f e2 :(B, P ) P + K1 \n= <L(Q) P = Q + K2 (T:MATL) G,x:L(A); Q f match x with | nil . e1 | cons(xh,xt) . e2 :(B, Q ' ) ' matTL \nG G; R f e1 :(B, R ) R + K1 = p0 (Q) '' matTL ' matTN '' matTN R = Q + K2 G,x0:A, x1:T (A),x2:T (A); \nP f e2 :(B, P ) P + K1 = <T (Q) P = Q + K2 (T:MATT) G,x:T (A); Q f match x with | leaf . e1 | node(x0,x1,x2) \n. e2 :(B, Q ' ) ' ''' G,x:A, y:A; P f e :(B, Q ) Q =(P ) G; P f e :(B, P ) Q = PQ = P y(T:SHARE) (T:WEAKEN) \nG,z:A; Q f e[z/x, z/y]:(B, Q ' ) G; Q f e :(B, Q ' ) ''' ' G; P f e :(B, P ) Q = P + cQ = P + c G; P \nf e :(B, P ) .i . I(G): pi = q(i,0) (T:OFFSET) (T:AUGMENT) G; Q f e :(B, Q ' )G,x:A; Q f e :(B, Q ' ) \nFigure 2. Type rules for annotated types. Lemma 6 is a consequence of Corollary 1. Moreover, the coef.\u00ad \n(i,j) cients ck can be computed effectively and are natural numbers. For a context G,x1:A, x2:A; Q we \nde.ne (Q) to be the Q ' from y Lemma 6. Type Rules Fig. 2 shows the annotated type rules for RAML expressions. \nWe assume a .xed global signature S that we omit from the rules. The last four rules are structural rules \nthat apply to every expression. The other rules are syntax-driven and there is one rule for every construct \nof the syntax. In the implementation we incorporated the structural rules in the syntax-driven ones. \nThe most interesting rules are explained below. T:SHARE has tobe appliedtoexpressionsthatcontaina variable \ntwice (z in the rule). The sharing operation (P ) transfers the y annotation P for the context G,x:A, \ny:A into an annotation Q for the context G,z:A without loss of potential (Lemma 6). This is crucial for \nthe accuracy of the analysis since instances of T:SHARE are quite frequent in typical examples. The remaining \nrules are af.ne linear in the sense that they assume that every variable occurs at most once. T:CONS \nassigns potential to a lengthened list. The additive shift <L(Q ' ) transforms the annotation Q ' for \na list type into an annotation for the context xh:A, xt:L(A). Lemma 4 shows that potential is neither \ngained nor lost by this operation. The potential Q of the context has to pay for both the potential Q \n' of the resulting list and the resource cost Kcons for list cons. T:MATL showshowtotreatpatternmatching \noflists.Theinitial potential de.ned by the annotation Q of the context G,x:L(A) has to be suf.cient to \npay the costs of the evaluation of e1 or e2 (depending on whether the matched list is empty or not) and \nthe potential de.ned by the annotation Q ' of the result type. To type the expression e1 of the nil case \nwe use the projection p0G(Q) that results in an annotation for the context G. Since the matched list \nis empty in this case no potential is lost by the discount of the annotations q(i,j) of Q where j =0. \nTo type the expression e2 of the cons case we rely on the shift operation <L(Q) for lists that results \nin an annotation for the context G,xh:A, xt:L(A). Again there is no loss of potential (see Lemma 4). \nThe equalities relate the potential before and after the evaluation of e1 or e2, to the potential before \nthe and after the evaluation of the match operation by incorporating the respective resource cost for \nthe matching.  T:NODE and T:MATT are similar to the corresponding rules for lists but use the shift \noperator <T for trees (see Lemma 5). T:LET comprises essentially an application of Proposition 2 (with \nf = e1 and C =G2) followed by an application of Proposi\u00adtion 1 (with f being the parallel composition \nof e1 and the identity on G2 and g being e2). Of course, the rigorous soundness proof takes into account \npartiality and additional constant costs for dis\u00adpatching a let. It is part of the inductive soundness \nproof for the entire type system (Theorem 1). The derivation of the type judgment G1, G2; Q f let x = \ne1 in e2 :(B, Q ' ) can be explained in two steps. The .rst starts with the derivation of the judgment \nG1; P f e1 :(A, P ' ) for the sub-expression e1. The annotation P corresponds to the potential that is \nexclusively attached to G1 by the annotation Q plus some resource cost for the let, namely P = piG1 (Q)+ \nK1 let. Now we 0 derive the judgment G2,x:A; R f e2 :(B, R ' ). The potential that is assigned by R to \nx:A is the potential that resulted from the judgment for e1 plus some cost that might occur when binding \nthe ' px:A(R)+ Klet variable x to the value of e1, namely P = i02 . The potential that is assigned by \nR to G2 is essentially the potential that is assigned by to G2 by Q, namely pi0G2(Q)= p0G2 (R). The second \nstep of the derivation is to relate the annotations in R that refer to mixed potential between x:A and \nG2 to the annotations in Q that refer to potential that is mixed between G1 and G2. To this end we remember \nthat we can derive from a judgment G1; S f e1 :(A, S ' ) that F(G1; S) = F(v:(A, S ' )) if e1 evaluates \nto v. This inequality remains valid if multiplied with a potential for fG2 = F(G2; T ), i.e., F(G1; S) \n\u00b7 fG2 = F(v:(A, S ' )) \u00b7 fG2 . To relate the mixed potential annotations we thus derive a cost\u00ad cf ' \nfree judgment G1; Pj e1 :(A, P j ) for every i0= j . I(G2). (We use cost-free judgments to avoid paying \nmultiple times for the evaluation of e1.) Then we equate Pj to the corresponding annotations in Q and \nequate Pj ' to the corresponding annotations pG1 ' px:A in R, i.e., Pj = j (Q) and Pj = j (R). The intuition \nis that j corresponds to fG2 . Note that we use a fresh signature S in the derivation of each cost-free \njudgment for e1. Soundness The main theorem of this paper states that type derivations establish correct \nbounds: an annotated type judgment for an expression e shows that if e evaluates to a value v in a well\u00adformed \nenvironment then the initial potential of the context is an upper bound on the watermark of the resource \nusage and the dif\u00adference between initial and .nal potential is an upper bound on the consumed resources. \nNote that it is possible to prove that the bounds also hold for non-terminating evaluations as we did \nfor the univariate sys\u00adtem [17] in a companion paper (see the discussion in \u00a73). Theorem 1 (Soundness) \nLet H F V:G and S; G; Q f e:(A, Q ' ). If V, Hf e v, H ' | (p, p ' ) then p = FV,H(G; Q) and p - p ' \n= FV,H(G; Q) - FH! (v:(A, Q ' )). Theorem 1 is proved by a nested induction on the derivation of the \nevaluation judgment V, Hf e v, H ' | (p, p ' ) and the type judgment G; Q f e:(A, Q ' ). The inner induction \non the type judgment is needed because of the structural rules. There is one proof for all possible instantiations \nof the resource constants. It is technically involved but conceptually unsurprising. Compared to earlier \nworks [16], further complexity arises from the new rich potential annotations. It is mainly dealt with \nin Lemmas 4, 5, and 6 and the concept of projections as explained in Propositions 2 and 3. 7. Type Inference \nand Experiments Type Inference The type-inference algorithm for RAML extends the algorithm that we have \ndeveloped for the univariate polynomial system [17]. It is not complete with respect to the type rules \nin \u00a76 but it works well for the example programs we tested. Its basis is a classic type inference generating \nsimple linear con\u00adstraints for the annotations that are collected during the inference, and that can \nbe solved later by linear programming. In order to ob\u00adtain a .nite set of constraints one has to provide \na maximal degree of the resource bounds. If the degree is too low then the generated linear program is \nunsolvable. The maximal degree can either be speci.ed by the user or can be incremented successively \nafter an unsuccessful analysis. A main challenge in the inference is the handling of resource\u00adpolymorphic \nrecursion which we believe to be of very high com\u00adplexity if not undecidable in general. To deal with \nit practically, we employ a heuristic that has been developed for the univariate system. In a nutshell, \na function is allowed to invoke itself recursively with a type different from the one that is being justi.ed \n(polymor\u00adphic recursion) provided that the two types differ only in lower\u00addegree terms. In this way, \none can successively derive polymorphic type schemes for higher and higher degrees; for details, see \n[17]. The generalisation of this approach to the multivariate setting poses no extra dif.culties. The \nnumber of multivariate polynomials our type system takes mm n nnm into account (e.g., nm,n ,n ,m ,m , \nfor a 23 2322 pair of integer lists if the max. degree is 4) grows exponentially in the maximal degree. \nThus the number of inequalities we collect for a .xed program grows also exponentially in the given maximal \ndegree. Moreover, one often has to analyze function applications context-sensitively with respect to \nthe call stack. Recall, e.g., the expression .lter(a,.lter(b,l)) from \u00a72 where we had to use two different \ntypes for .lter. Experimental Evaluation In our prototype implementation we collapse the cycles in the \ncall graph and analyze each function once for every path in the resulting graph. For larger programs \nthis can lead to large linear constraint systems if the maximal degree is high. Sometimes they are infeasible \nfor the LP solver6 we use. Our emphasis was on correctness of the prototype, not on per\u00adformance. There \ncertainly is room for improvement, either by tun\u00ading the con.guration of the current LP solver7 or by \nexperimenting with alternative solvers. Further improvement is possible by .nd\u00ading a suitable heuristic \nthat is in between the (maybe too) .exible method we use here and the inference for the univariate system \nthat also works ef.ciently with high maximal degree for large programs. For example, we could set certain \ncoef.cients qi to zero before even generating the constraints. Alternatively, we could limit the number \nof different types for each function. However, we are satis.ed with the performance of the prototype \non the example programs that do not require high degrees. For instance, we successfully analyzed longer \nexamples with up to degree 4 (multiplication of a list of matrices). Table 1 shows a compilation of the \ncomputation of evaluation\u00adstep bounds for several example functions. All computed bounds are asymptotically \ntight. The run-time of the analysis varies from 0.02 to 1.96 seconds on an 3.6 GHz Intel Core 2 Duo iMac \nwith 4 GB RAM depending on the needed degree and the complexity of the source program. Our experiments \nshow that the constant factors in the com\u00adputed bounds are generally quite tight and even match the measured \n6 lp solve version 5.5.0.1 7 Currently, we use the standard con.guration with no additional options. \n  Function Computed Evaluation-Step Bound Simpli.ed Computed Bound Act. Behav. Run Time isortlist:L(L(int)).L(L(int)) \nnub:L(L(int)).L(L(int)) transpose:L(L(int)).L(L(int)) mmult:(L(L(int)))2.L(L(int)) dyade:(L(int),L(int)).L(L(int)) \nlcs:(L(int),L(int)).int subtrees:T (int).L(T (int)) eratos:L(int).L(int) b 16mi+16 n +12n+3 1=i<j=n \n2 b 12mi+18 n +12n+3 1=i<j=n 2 b 32mi+2n+13 1=i=n b ( yi)(32 + 28n)+14n+2x+21 1=i=x 10nx+14n+3 39nx \n+6x + 21n + 19 8 n 2 + 23n +3 16 n +12n +3 2 8n 2 m+8n 2-8nm+4n+3 6n 2 m+9n 2-6nm+3n+3 32nm+2n+13 28xyn+32xy+2x+14n+21 \n10nx+14n+3 39nx +6x + 21n + 19 4n 2 + 19n +3 8n 2+4n+3 O(n 2 m) 0.91 s O(n 2 m) 0.97 s O(nm) 0.04 s O(nxy) \n1.96 s O(nx) 0.03 s O(nx) 0.36 s O(n 2) 0.06 s O(n 2) 0.02 s  Table 1. The computed evaluation-step \nbounds, the actual worst-case time behavior, and the run time of the analysis in seconds. All computed \nbounds are asymptotically tight and the constant factors are close to the worst-case behavior. In the \nbounds n is the size of the .rst argument, mi are the sizes of the elements of the .rst argument, x is \nthe size of the second argument, yi are the sizes of the elements of the second argument, m = max1=i=n \nmi, and y = max1=i=x yi. worst-case running times of many functions. The univariate analy\u00adsis [16, 17] \ninfers identical bounds for the functions subtrees and eratos. In contrast, it can infer bounds for the \nother functions only after manual source-code transformations. Even then, the resulting bounds are not \nasymptotically tight. We present the experimental evaluation of two functions be\u00adlow. The source code \nand the experimental validation for the other examples is available online8. It is also possible to download \nthe source code of the prototype and to analyze user generated exam\u00adples directly on the web. Example \n1: Lexicographic Sorting of Lists of Lists The fol\u00adlowing RAML code implements the well-known sorting \nalgorithm insertion sort that lexicographically sorts lists of lists. To lexico\u00adgraphically compare two \nlists one needs linear time in length of the shorter one. Since insertion sort does quadratic many comparisons \nin the worst-case it has a running time of O(n 2 m) if n is the length of the outer list and m is the \nmaximal length of the inner lists. leq (l1,l2) = match l1 with | nil -> true | (x::xs) -> match l2 with \n| nil -> false | (y::ys) -> (x<y) or ((x == y) and leq (xs,ys)); insert (x,l) = match l with | nil -> \n[x] | (y::ys) -> if leq(x,y) then x::y::ys else y::insert(x,ys); isortlist l = match l with | nil -> \nnil | (x::xs) -> insert (x,isortlist xs); Below is the analysis output for the function isortlist when \ninstan\u00adtiated to bound the number of needed evaluation steps. The compu\u00adtation needs less then a second \non typical desktop computers. isortlist: L(L(int)) --> L(L(int)) Positive annotations of the argument \n0 --> 3.0 2 --> 16.0 1 --> 12.0 [1,0] --> 16.0 The number of evaluation steps consumed by isortlist is \nat most: 8.0*n^2*m + 8.0*n^2 -8.0*n*m + 4.0*n + 3.0 where n is the length of the input m is the length \nof the elements of the input The more precise bound implicit in the positive annotations of the argument \nis presented in mathematical notation in Table 1. 8 http://raml.tcs.ifi.lmu.de We manually identi.ed \ninputs for which the worst-case behav\u00adior of isortlist emerges (namely reversely sorted lists with similar \ninner lists). Then we measured the needed evaluation steps and compared the results to our computed bound. \nFig. 3 shows a plot of this comparison. Our experiments indicate that the computed bound exactly matches \nthe actual worst-case behavior. Example 2: Longest Common Subsequence An example of dy\u00adnamic programming \nthat can be found in many textbooks is the computation of (the length of) the longest common subsequence \n(LCS) of two given lists (sequences). If the sequences a1,...,an and b1,...,bm are given then an n \u00d7 \nm matrix (here a list of lists) A is successively .lled such that A(i, j) contains the length of the \nLCS of a1,...,ai and b1,...,bj . The following recursion is used in the computation. . . 0 if i =0 or \nj =0 A(i, j)= A(i - 1,j - 1) + 1 if i, j>0 and ai =bj. max(A(i, j-1),A(i-1,j)) if i, j>0 and ai =bj The \nrun time of the algorithm is thus O(nm). Below is the RAML implementation of the algorithm. lcs(l1,l2) \n= let m = lcstable(l1,l2) in match m with | nil -> 0 | (l1::_) -> match l1 with | nil -> 0 | (len::_) \n-> len; lcstable (l1,l2) = match l1 with | nil -> [firstline l2] | (x::xs) -> let m = lcstable (xs,l2) \nin match m with | nil -> nil | (l::ls) -> (newline (x,l,l2))::l::ls; newline (y,lastline,l) = match l \nwith | nil -> nil | (x::xs) -> match lastline with | nil -> nil | (belowVal::lastline ) -> let nl = newline(y,lastline \n,xs) in let rightVal = right nl in let diagVal = right lastline in let elem = if x == y then diagVal+1 \nelse max(belowVal,rightVal) in elem::nl; firstline(l) = match l with | nil -> nil | (x::xs) -> 0::firstline \nxs; right l = match l with | nil -> 0 | (x::xs) -> x; The analysis of the program takes less then a second \non a usual desktop computer and produces the following output for the func\u00adtion lcs.  Figure 3. The \ncomputed evaluation-step bound (lines) compared to the actual worst-case number of evaluation-steps for \nsample inputs of various sizes (crosses) used by isortlist (on the left) and lcs (on the right). lcs: \n(L(int),L(int)) --> int Positive annotations of the argument (0,0) --> 19.0 (1,0) --> 21.0 (0,1) --> \n6.0 (1,1) --> 39.0 The number of evaluation steps consumed by lcs is at most: 39.0*m*n + 6.0*m + 21.0*n \n+ 19.0 where n is the length of the first component of the input m is the length of the second component \nof the input Fig. 3 shows that the computed bound is close to the measured number of evaluation steps \nneeded. In the case of lcs the run time exclusively depends on the lengths of the input lists. 8. Related \nWork Most closely related is the previous work on automatic amortized analysis [17, 16, 18, 19, 20, 23, \n24] (see \u00a71). This paper describes the .rst system that can compute multivariate polynomial bounds. Other \nresource analyses that can in principle obtain polyno\u00admial bounds are approaches based on recurrences \npioneered by Grobauer [12] and Flajolet [11]. In those systems, an a priori un\u00adknown resource bounding \nfunction is introduced for each function in the code; by a straightforward intraprocedural analysis a \nset of recurrence equations or inequalities for these functions is then de\u00adrived. Even for relatively \nsimple programs the resulting recurrences are quite complicated and dif.cult to solve with standard methods. \nIn the COSTA project [1, 2, 3] progress has been made with the solution of those recurrences. In an automatic \ncomplexity analysis for higher-order Nuprl terms Benzinger uses Mathematica to solve the generated recurrence \nequations [5]. The size measures used in these approaches (like the length of the longest path in the \ninput data) are less precise for nested data structures than our resource polynomials which comprise \nthe sizes of all inner data structures. As a result, our method can deal with compositions of functions \nmore accurately and is able to express a wider range of relations between parts of the input. We also \n.nd that amortization yields better results in cases where resource usage of intermediate functions depends \non factors other than input size, e.g., sizes of partitions in quick sort. A successful method to estimate \ntime bounds for C++ proce\u00addures with loops and recursion was recently developed by Gulwani et al. [15, \n13] in the SPEED project. They annotate programs with counters and use automatic invariant discovery \nbetween their val\u00adues using off-the-shelf program analysis tools which are based on abstract interpretation. \nA recent innovation for non-recursive pro\u00adgrams is the combination of disjunctive invariant generation \nvia ab\u00adstract interpretation with proof rules that employ SMT-solvers [14]. In contrast to our method, \nthese techniques can not fully automati\u00adcally analyze iterations over data structures. Instead, the user \nneeds to de.ne numerical quantitative functions . This seems to be less modular for nested data structures \nwhere the user needs to specify an owner predicate for inner data structures. It is also unclear if quantitative \nfunctions can represent complex mixed bounds such as b (10mi+2mj )+16 n +12n+3 for isortlist. Moreover, \n1=i<j=n2 our method infers tight bounds for functions such as insertion sort b that admit a worst-case \ntime usage of the form i. In con\u00ad 1=i=n trast, [15] indicates that a nested loop on 1 = i = n and 1 = \nj = i is over-approximated with the bound n 2 . A methodological difference to techniques based on abstract \nin\u00adterpretation is that we infer (using linear programming) an abstract potential function which indirectly \nyields a resource-bounding function. The potential-based approach may be favorable in the presence of \ncompositions and data scattered over different loca\u00adtions (partitions in quick sort). As any type system, \nour approach is naturally compositional and lends itself to the smooth integration of components whose \nimplementation is not available. Moreover, type derivations can be seen as certi.cates and can be automati\u00adcally \ntranslated into formalized proofs in program logic [6]. On the other hand, our method does not model \nthe interaction of integer arithmetic with resource usage. Other related works use type systems to validate \nresource bounds. Crary and Weirich [9] presented a (monomorphic) type system capable of specifying and \ncertifying resource consumption. Danielsson [10] provided a library, based on dependent types and manual \ncost annotations, that can be used for complexity analyses of purely functional data structures and algorithms. \nIn contrast, our focus is on the inference of bounds. Another related approach is the use of sized types \n[22, 21, 8] which provide a general framework to represent the size of the data in its type. Sized types \nare a very important concept and we also employ them indirectly. Our method adds a certain amount of \ndata dependency and dispenses with the explicit manipulation of symbolic expressions in favour of numerical \npotential annotations. Polynomial resource bounds have also been studied in [25] that addresses the derivation \nof polynomial size bounds for functions whose exact growth rate is polynomial. Besides this strong restric\u00adtion, \nthe ef.ciency of inference remains unclear. 9. Conclusion and Directions for Future Work We have introduced \na quantitative amortized analysis for .rst-order functions with multiple arguments. For the .rst time, \nwe have been able to fully automatically derive complex multivariate resource bounds for recursive functions \non nested inductive data structures such as lists and trees. Our experiments have shown that the analy\u00adsis \nis suf.ciently ef.cient for the functions we have tested, and that the resulting bounds are not only \nasymptotically tight but are also surprisingly precise in terms of constant factors.  The system we \nhave developed will be the basis of various future projects. A challenging unsolved problem we are interested \nin is the computation of precise heap-space bounds in the presence of automatic memory management. We \nhave .rst ideas for extending the type system to derive bounds that contain not only polynomial but also \ninvolve logarith\u00admic and exponential functions. The extension of linear amortized analysis to polymorphic \nand higher-order programs [24] seems to be compatible with our system and it would be interesting to \ninte\u00adgrate it. Finally, we plan to investigate to what extent our multivari\u00adate amortized analysis can \nbe used for programs with cyclic data structures (following [19, 20, 4]) and recursion (including loops) \non integers. For the latter it might be bene.cial to merge the amor\u00adtized method with successful existing \ntechniques on abstract inter\u00adpretation [15, 3]. Another very interesting and rewarding piece of future \nwork would be an adaptation of our method to imperative languages without built-in inductive types such \nas C. One could try to employ pattern-based discovery of inductive data structures as is done, e.g., \nin separation logic. References [1] E. Albert, P. Arenas, S. Genaim, G. Puebla, and D. Zanardini. Cost \nAnalysis of Java Bytecode. In 16th Euro. Symp. on Prog. (ESOP 07), pages 157 172, 2007. [2] E. Albert, \nP. Arenas, S. Genaim, and G. Puebla. Automatic Inference of Upper Bounds for Recurrence Relations in \nCost Analysis. In 15th Static Analysis Symp. (SAS 08), pages 221 237, 2008. G\u00b4 [3] E. Albert, P. Arenas, \nS. Genaim, M. omez-Zamalloa, G. Puebla, D. Ram\u00b4irez, G. Rom\u00b4an, and D. Zanardini. Termi\u00ad nation and Cost \nAnalysis with COSTA and its User Interfaces. Electr. Notes Theor. Comput. Sci., 258(1):109 121, 2009. \n[4] R. Atkey. Amortised Resource Analysis with Separation Logic. In 19th Euro. Symp. on Prog. (ESOP 10), \npages 85 103, 2010. [5] R. Benzinger. Automated Higher-Order Complexity Analysis. Theor. Comput. Sci., \n318(1-2):79 103, 2004. [6] L. Beringer, M. Hofmann, A. Momigliano, and O. Shkar\u00adavska. Automatic Certi.cation \nof Heap Consumption. In Log. f. Prog., AI, and Reas., 11th Conf. (LPAR 04), pages 347 362, 2004. [7] \nB. Campbell. Amortised Memory Analysis using the Depth of Data Structures. In 18th Euro. Symp. on Prog. \n(ESOP 09), pages 190 204, 2009. [8] W.-N. Chin and S.-C. Khoo. Calculating Sized Types. High.-Ord. and \nSymb. Comp., 14(2-3):261 300, 2001. [9] K. Crary and S. Weirich. Resource Bound Certi.cation. In 27th \nACM Symp. on Principles of Prog. Langs. (POPL 00), pages 184 198, 2000. [10] N. A. Danielsson. Lightweight \nSemiformal Time Complexity Analysis for Purely Functional Data Structures. In 35th ACM Symp. on Principles \nProg. Langs. (POPL 08), pages 133 144, 2008. [11] P. Flajolet, B. Salvy, and P. Zimmermann. Automatic \nAverage-case Analysis of Algorithms. Theoret. Comput. Sci., 79(1):37 109, 1991. [12] B. Grobauer. Cost \nRecurrences for DML Programs. In 6th Int. Conf. on Funct. Prog. (ICFP 01), pages 253 264, 2001. [13] \nB. S. Gulavani and S. Gulwani. A Numerical Abstract Domain Based on Expression Abstraction and Max Operator \nwith Ap\u00adplication in Timing Analysis. In Comp. Aid. Veri.cation, 20th Int. Conf. (CAV 08), pages 370 \n384, 2008. [14] S. Gulwani and F. Zuleger. The Reachability-Bound Problem. In Conf. on Prog. Lang. Design \nand Impl. (PLDI 10), pages 292 304, 2010. [15] S. Gulwani, K. K. Mehra, and T. M. Chilimbi. SPEED: Pre\u00adcise \nand Ef.cient Static Estimation of Program Computational Complexity. In 36th ACM Symp. on Principles of \nProg. Langs. (POPL 09), pages 127 139, 2009. [16] J. Hoffmann and M. Hofmann. Amortized Resource Analysis \nwith Polynomial Potential. In 19th Euro. Symp. on Prog. (ESOP 10), pages 287 306, 2010. [17] J. Hoffmann \nand M. Hofmann. Amortized Resource Analysis with Polymorphic Recursion and Partial Big-Step Operational \nSemantics. In 8th Asian Symp. on Prog. Langs. (APLAS 10), 2010. To appear. [18] M. Hofmann and S. Jost. \nStatic Prediction of Heap Space Usage for First-Order Functional Programs. In 30th ACM Symp. on Principles \nof Prog. Langs. (POPL 03), pages 185 197, 2003. [19] M. Hofmann and S. Jost. Type-Based Amortised Heap-Space \nAnalysis. In 15th Euro. Symp. on Prog. (ESOP 06), pages 22 37, 2006. [20] M. Hofmann and D. Rodriguez. \nEf.cient Type-Checking for Amortised Heap-Space Analysis. In 18th Conf. on Comp. Science Logic (CSL 09). \nLNCS, 2009. [21] J. Hughes and L. Pareto. Recursion and Dynamic Data\u00adstructures in Bounded Space: Towards \nEmbedded ML Pro\u00adgramming. In 4th Int. Conf. on Funct. Prog. (ICFP 99), pages 70 81, 1999. [22] J. Hughes, \nL. Pareto, and A. Sabry. Proving the Correctness of Reactive Systems Using Sized Types. In 23th ACM Symp. \non Principles of Prog. Langs. (POPL 96), pages 410 423, 1996. [23] S. Jost, H.-W. Loidl, K. Hammond, \nN. Scaife, and M. Hof\u00admann. Carbon Credits for Resource-Bounded Computations using Amortised Analysis. \nIn 16th Symp. on Form. Meth. (FM 09), pages 354 369, 2009. [24] S. Jost, K. Hammond, H.-W. Loidl, and \nM. Hofmann. Static Determination of Quantitative Resource Usage for Higher-Order Programs. In 37th ACM \nSymp. on Principles of Prog. Langs. (POPL 10), pages 223 236, 2010. [25] O. Shkaravska, R. van Kesteren, \nand M. C. van Eekelen. Polynomial Size Analysis of First-Order Functions. In Typed Lambda Calc. Apps. \n(TLCA 07), pages 351 365, 2007. [26] R. E. Tarjan. Amortized Computational Complexity. SIAM J. Algebraic \nDiscrete Methods, 6(2):306 318, 1985. [27] R. Wilhelm et al. The Worst-Case Execution-Time Problem Overview \nof Methods and Survey of Tools. ACM Trans. Embedded Comput. Syst., 7(3), 2008.  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>We study the problem of automatically analyzing the worst-case resource usage of procedures with several arguments. Existing automatic analyses based on amortization, or sized types bound the resource usage or result size of such a procedure by a sum of unary functions of the sizes of the arguments.</p> <p>In this paper we generalize this to arbitrary multivariate polynomial functions thus allowing bounds of the form <i>mn</i> which had to be grossly overestimated by <i>m<sup>2</sup>+n<sup>2</sup></i> before. Our framework even encompasses bounds like <i>&#8727;<sub>i,j&#8804;n</sub> m_i m<sub>j</sub></i> where the <i>m<sub>i</sub></i> are the sizes of the entries of a list of length <i>n</i>.</p> <p>This allows us for the first time to derive useful resource bounds for operations on matrices that are represented as lists of lists and to considerably improve bounds on other super-linear operations on lists such as longest common subsequence and removal of duplicates from lists of lists.</p> <p>Furthermore, resource bounds are now closed under composition which improves accuracy of the analysis of composed programs when some or all of the components exhibit super-linear resource or size behavior.</p> <p>The analysis is based on a novel multivariate amortized resource analysis. We present it in form of a type system for a simple first-order functional language with lists and trees, prove soundness, and describe automatic type inference based on linear programming.</p> <p>We have experimentally validated the automatic analysis on a wide range of examples from functional programming with lists and trees. The obtained bounds were compared with actual resource consumption. All bounds were asymptotically tight, and the constants were close or even identical to the optimal ones.</p>", "authors": [{"name": "Jan Hoffmann", "author_profile_id": "81100074262", "affiliation": "Ludwig-Maximilians-Universit&#228;t, M&#252;nchen, Germany", "person_id": "P2509630", "email_address": "jan.hoffmann@ifi.lmu.de", "orcid_id": ""}, {"name": "Klaus Aehlig", "author_profile_id": "81100169004", "affiliation": "Ludwig-Maximilians-Universit&#228;t, M&#252;nchen, Germany", "person_id": "P2509631", "email_address": "aehlig@ifi.lmu.de", "orcid_id": ""}, {"name": "Martin Hofmann", "author_profile_id": "81452607849", "affiliation": "Ludwig-Maximilians-Universit&#228;t, M&#252;nchen, Germany", "person_id": "P2509632", "email_address": "martin.hofmann@ifi.lmu.de", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926427", "year": "2011", "article_id": "1926427", "conference": "POPL", "title": "Multivariate amortized resource analysis", "url": "http://dl.acm.org/citation.cfm?id=1926427"}