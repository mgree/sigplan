{"article_publication_date": "01-26-2011", "fulltext": "\n A Typed Store-Passing Translation for General References Franc\u00b8ois Pottier INRIA Francois.Pottier@inria.fr \nAbstract We present a store-passing translation of System F with general references into an extension \nof System F. with certain well\u00adbehaved recursive kinds. This seems to be the .rst type-preserving store-passing \ntranslation for general references. It can be viewed as a purely syntactic account of a possible worlds \nmodel. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs and Features \nDynamic storage management; F.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs Type \nstructure General Terms Languages, Theory 1. Introduction Motivation Building a semantic model of a \nprogramming lan\u00adguage amounts to translating it into some mathematical meta\u00adlanguage. An important constraint \nin the design of such an interpre\u00adtation is that it must explain (that is, translate away) computational \neffects such as non-termination and state, which do not exist in mathematics. Non-termination is often \nhandled using the tools of domain theory, which was created for this purpose. State is usually dealt \nwith in the style of Strachey [32] by making the store explicit and interpreting commands as functions \nthat map stores to stores. Another important consideration is that the model should exploit the type \ndiscipline of the programming language. This enables it to serve as a tool in establishing type soundness \nand in proving typed contextual equivalence laws. As a result of these considerations, building a semantic \nmodel of a rich programming language can be a challenging task. It is common wisdom among compiler writers \nthat when one is faced with a complex translation task, one should decompose it into a succession of \nindependent phases, connected via suitably chosen intermediate languages. In this paper, we study one \ninstance where this wisdom might be applicable in the construction of a semantic model. We focus on a \nparticular programming language, namely a version of Sys\u00adtem F equipped with general references, and \non a particular aspect of its semantics, namely the store-passing transformation, whose purpose is to \nexplain (translate away) references. We isolate this transformation, just as if it were a phase in a \ncompiler, and present it as a translation of our typed, imperative source language into a typed, purely \nfunctional intermediate language. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 11, January 26 28, 2011, Austin, Texas, USA. Copyright c . 2011 \nACM 978-1-4503-0490-0/11/01. . . $10.00 In so doing, we move the frontier between syntax and semantics. \nWe suggest that a model of the imperative source language might be obtained through the composition of \nthe store-passing trans\u00adformation with a model of the purely functional intermediate lan\u00adguage. This \nmakes the construction of the model more modular, and may help explain it to researchers who are familiar \nwith syntactic techniques. This also extends the family of known type-preserving transformations: to \nthe best of our knowledge, until now, it was an open question how to de.ne a type-preserving store-passing \ntrans\u00adlation for general references. Which intermediate language? In this endeavor, an important part \nof the dif.culty is to .nd out what the typed intermediate lan\u00adguage should be, and to keep it minimal. \nIt would be nice if it could be a well-studied calculus, such as System F or F.. However, these calculi \nare strongly normalizing, whereas our source language is not: general references allow recursion through \nthe store. Thus, one more ingredient is needed. In order to .nd out what this ingredient should be, let \nus .rst review some of the semantic models of gen\u00aderal references. Possible worlds models A reference \nis a dynamically-allocated memory cell, whose value can be read and modi.ed at any time. We consider \ngeneral references, which means that a reference can hold a value of any type, including a function, \nor the address of some other reference. Furthermore, we are interested in weak references. That is, we \nare interested in a type discipline whereby updates are type-invariant, de-allocation is forbidden, and \naliasing is permitted. The presence of references precludes a na\u00a8ive interpretation of types as sets \nof values. A sentence such as: the address 100 is an integer reference does not make sense on its own. \nIt implicitly re\u00adlies on the assumption that the address 100 is currently allocated, that some integer \nvalue is currently stored there, and on the knowl\u00adedge that these facts will continue to hold in the \nfuture. To re.ect this, several semantic models of weak references in the literature follow the possible \nworlds approach [2, 10, 16, 34]. There, the interpretation of a type is parameterized over a world, which \nrepresents the current state of the store. Worlds are equipped with a partial ordering: w1 = w2 means \nthat w2 is a possible future world of w1, that is, every address that is allocated in w1 is also allocated \nin w2, with the same type. Bounded universal quanti.cation over worlds is used to express the idea that \na value that is valid now is also valid in every possible future world. Bounded existential quanti.cation \nis used to express the idea that a command has the effect of transforming the current world into some \npossible future world. At the heart of these possible worlds models of general refer\u00adences is a circularity. \nAs stated above, semantic types are open\u00adended: they are parameterized over a world. However, worlds \ntoo must be open-ended: they must describe the store now and in ev\u00adery possible future. One way of achieving \nthis is to de.ne a world as a map of memory addresses to semantic types. This makes the de.nitions of \nworlds and semantic types mutually recursive, and creates a need to either solve a recursive domain equation \n world ~ = world . ... [10] or work with approximate solutions .1 = .1 .2 = . 2 . = . . = . .1 . .2 \n= .  2 of it [2, 14]. An alternative is to de.ne a world as a map of mem\u00ad . = . ory addresses to syntactic \ntypes [16]. Then, the circularity appears when worlds and types must be interpreted as semantic objects, \nand again a recursive domain equation must be solved. A calculus with recursive kinds In this paper, \nwe are not in\u00adterested in solving or approximating recursive domain equations. Our purpose is to argue \nthat a certain syntactic program transfor\u00admation (namely, a store-passing translation) produces well-typed \nterms. Drawing inspiration from the possible worlds models, we wish to parameterize and to quantify types \nover worlds. Thus, we need worlds to be types (of a particular kind). That is, world should be a kind. \nBecause we need world ~world . ..., we should look = for an intermediate calculus that supports recursive \nkinds. This is the key ingredient that was alluded to above. Should we propose an extension of F. with \narbitrary recur\u00adsive kinds? Such a system would have Turing-complete compu\u00adtation at the type level. \nThat sounds rather wild. Do we need non\u00adterminating computation at the type level? Yes. We do wish to \nallow certain forms of non-terminating computation at the type level, be\u00adcause we .nd it natural to view \na recursive type as a .-term whose in.nite reduction produces, in the limit, an in.nite tree. This is \na form of non-terminating but productive computation. Is there a way of ensuring that every type-level \ncomputation is productive in such a sense? Yes. Nakano [21, 22], for instance, presents a type system \nthat controls recursion so as to guarantee productive computation. This system has recursive types but \nre\u00adquires every cycle in the type structure to cross a later modality, written . We re-use this system \noff-the-shelf, at the kind level; therefore, Nakano s terms and types become our types and kinds. By \nadopting Nakano s system, we rule out certain recursive kinds. For instance, the recursive equation world \n= world . ... is in fact invalid, because it does not involve the modality. Fortunately, the modi.ed \nequation world = world . ... is permitted, and still .ts our purposes. This equation states that a world \nis a contractive function: it is able to produce some output independently of its argument. This intuitively \nseems to correspond to the fact that if one attempts to describe the shape of the store, one will be \nable to provide a non-empty pre.x of a description before one hits a self-reference to the shape of the \nstore. For instance, one might say: the store currently contains one cell, which contains one function, \nwhose argument must be a store that is a possible future of the current store... The ultrametric-space \ntechniques of Birkedal et al. [9, 10] and of Schwinghammer et al. [30] served as inspiration for the \npresent work, so it is no surprise that there is a close analogy between these works and ours. Their \n21 scaling factor becomes the modality. Their construction of world composition as the .xed point of \na con\u00adtractive map [30, Lemma 13] becomes a recursive de.nition that happens to be permitted in Nakano \ns system. The fact that world composition is associative [30, Lemma 14] becomes an assertion about the \nequality of two B\u00a8 ohm trees and can be automatically checked (\u00a74.4). In recent work, spurred in part \nby an earlier version of the present paper, Birkedal et al. [8] construct a metric model of a version \nof Nakano s system. This gives .rm footing to the corre\u00adspondence between and 21. Birkedal et al. note \nthat their work provides the basis for a semantic model of the typed calculus that is presented here. \nWhether and how this model can be exploited in useful ways remains to be determined. Contributions The \ncontributions of this paper are: (i) the design of FORK, an extension of system F Omega with well-behaved \nRe\u00ad 1 . . (.1 . .2) .1 . .2 Figure 1. FORK: properties of the subkind relation K;a : .1 f t : .2 K f \na : K(a) K f .a.t : .1 . .2 K f t1 : .1 . .2 K f t2 : .1 K f t : .1 .1 = .2 K f t1 t2 : .2 K f t : .2 \nFigure 2. FORK: kind assignment cursive Kinds; (ii) a type-preserving encoding of general references \ninto this calculus. Paper outline We .rst recall Nakano s system (\u00a72), and build upon it in the de.nition \nof FORK (\u00a73). Then, we explain how a version of System F equipped with general references can be encoded \ninto FORK. We prove that the encoding is type-preserving and semantics-preserving1 (\u00a74). A prototype \nimplementation of a FORK type-checker, the complete source code for the encoding of references, as well \nas the machine-checked proof of semantic preservation, are available online [28]. Some proofs are omitted \nand can be found in the extended version of this paper [29].  2. Nakano s system We now recall the de.nition \nand properties of Nakano s system [21, 22]. Our version of the system is close to Nakano s S-. \u00b5 +. It \nis slightly simpli.ed in that it is restricted to .nite types (without distinction between positively \nand negatively .nite types) and (as a result) it does not have a T type. Despite this difference, we \nrefer to it as Nakano s system . There are two levels in Nakano s system, which are usually referred \nto as types and terms . Nakano s types and terms are the kinds and types of FORK, respectively, so this \nis how we refer to them. Kinds The kinds are co-inductively de.ned as follows: . ::= *| . . . | . A kind \n. is a possibly in.nite tree. In the prototype implementa\u00adtion [28], kinds are .nitely represented via \na set of mutually recur\u00ad sive de.ning equations. (Thus, only regular kinds can be de.ned.) A kind .is \nwell-formed iff every in.nite path through .crosses a constructor in.nitely often. A kind is .nite iff \nevery in.nite path through . enters the domain of an arrow in.nitely often. We restrict our attention \nto kinds that are well-formed and .nite. (The .niteness condition is used in the proof of Lemma 2.4, \nwhere it serves to rule out types that produce an in.nite stream of . s, and therefore do not have a \nhead normal form.) In the implementation, this requirement is enforced by checking that every occurrence \nof a kind name in the right-hand side of its de.ning equation(s) lies under a constructor and in the \ndomain of an arrow. 1 More precisely, we prove that the encoding preserves convergence, and sketch how \none might prove that it also preserves divergence.  Subkinding Kinds come with a subkind relation =. \nWe omit its de.nition, which is somewhat technical (the reader is referred to [27]) and is irrelevant \nas long as the following properties hold. The subkind relation is re.exive, transitive, and satis.es \nthe laws in Figure 1, where means that the relation holds in both directions. The subkind relation satis.es \nthe following inversion lemma: Lemma 2.1 If .1 . .2 = .1 . .2 holds, then, for some n . N, both .1 = \nn .1 and n .2 = .2 hold. 0 (We write n . for n applications of to ..) When kinds are .nitely represented \nas a set of mutually recursive de.ning equa\u00adtions, it is decidable whether two kinds .1 and .2 are in \nthe sub\u00adkind relation. In fact, it is possible to decide whether there exists n . N such that .1 = n \n.2 holds, and to compute the least such n when one exists [27]. The prototype implementation [28] takes \nadvantage of this fact to perform bottom-up kind synthesis. Types Types are pure .-terms: t ::= a | .a.t \n| tt We write t1 -. t2 when t1 \u00df-reduces to t2. Reduction is permit\u00adted under arbitrary contexts. A kind \nenvironment K is a sequence of bindings of the form a : .. The judgement K f t : . means that, within \nsuch an environment K, the type t has kind .. The rules that de.ne it (Figure 2) are standard. Recursion \nThe judgement f Y :( . . .) . ., where Y is Curry s .xed point combinator .f.((.x.f (xx))(.x.f (xx))), \nis derivable. (The variable x receives the recursive kind . = (. . .).) We introduce the notation \u00b5a.t \nas syntactic sugar for Y (.a.t). This gives rise to the derived reduction rule: \u00b5a.t -. [a . \u00b5a.t]t and \nto the derived kind assignment rule: K;a : . f t : . K f \u00b5a.t : . The prototype implementation [28] \nhas built-in support for recur\u00ad sive type de.nitions, based on the above rules. In fact, it supports \nmutually recursive type de.nitions. Properties The system enjoys the following degradation and sub\u00adject \nreduction properties. Lemma 2.2 K f t : .implies K f t : .. 0 Lemma 2.3 K f t1 : .and t1 -. t2 imply \nK f t2 : .. 0 A type of the form .a1 ...am.a t1 ...tn is a head normal form. Types are solvable: they \nadmit head normal forms [21, 22, 27]. Lemma 2.4 If K f t : .then t has a head normal form. 0 It is worth \nnoting that this holds under any environment K, that is, in the presence of type variables of arbitrary \nkind. Together, Lemmas 2.3 and 2.4 imply that every type admits a maximal B\u00a8ohm tree, that is, one that \ndoes not contain any occurrence of . (the unde.ned B\u00a8ohm tree). These two lemmas have been checked by \nthe author using the Coq proof assistant [27]. Type equality We take type equality, a relation between \ntypes, to be B\u00a8ohm tree equivalence up to . [7, \u00a710.2.25] [15]. Several alternative characterizations \nof this relation are known. It is the greatest consistent .-theory. It coincides with the equational \ntheory of Scott s D8 model. It is the greatest compatible semi-sensible relation, that is, it coincides \nwith the observational congruence obtained by observing solvability. We write t1 = t2 when t1 and t2 \nare in the type equality relation. In this paper, this relation is used only when both K f t1 : . and \nK f t2 : . hold for some environment K and kind .. This has the following bene.cial consequence: Lemma \n2.5 The relation =, restricted to well-kinded types, is semi-decidable. Proof. We outline a simple semi-algorithm. \nThis semi-algorithm maintains a conjunction G of goals, where a goal is an equation t1 = t2 between two \nhead normal forms. The free variables of a goal are implicitly viewed as universally quanti.ed. A goal \ng can be decomposed into a conjunction of sub-goals, written (g), as per the following equations. A case \napplies only if no prior case applies. We write t. for the principal head normal form of t. (.a.t1 = \n.a.t2) is (t1 = t2) (.a.t1 = t2 ) is (t1 = t2 a) if a # t2 ( t1 = .a.t2) is (t1 a = t2) if a # t1 ( t1 \nt1 = t2 t2 ) is (t1 = t2). t1.= t2. ( a = a ) is true ( t1 = t2 ) is false We write (G) for the conjunction \nof sub-goals obtained by applying (\u00b7) to every goal in G. Consider the problem of deciding whether t1 \n= t2 holds. Enu\u00admerate the potentially in.nite sequence de.ned by G0 =(t1.= t2.)and Gk+1 = (Gk). If some \nGk is found to be empty, report yes . If some Gk is found to be false, report no . If t1 = t2 holds, \nthen this semi-algorithm reports no . If t1 = t2 holds and t1 and t2 have a .nite B\u00a8ohm tree, then it \nreports yes . If t1 = t2 holds and t1 and t2 have an in.nite B\u00a8ohm tree, then the semi-algorithm diverges. \nD In the prototype implementation [28], this semi-algorithm is improved in two ways. First, Gk+1 is de.ned \nas (Gk)\\ j=k Gj. That is, any goal that has already appeared during an earlier step is considered valid. \nGoals are compared up to renaming of their free variables. Second, an equation of the form t1 t1 = t2 \nt2, where one of the two sides is not a head normal form, is heuristically decomposed into t1 = t2 . \nt1 = t2. (This is done in addition to the default behavior, which is to reduce both sides to head normal \nform before decomposing them.) This can have the effect of replacing a dif.cult goal, which would lead \nthe semi-algorithm into a sequence of ever\u00adgrowing goals, with a conjunction of simpler goals that the \nsemi\u00adalgorithm is able to prove. The semi-algorithm thus improved remains sound. Indeed, when it succeeds, \nthe set of goals that have been examined forms an hnf bisimulation up to . and up to context, as studied \nby Lassen [15], which implies that these goals are valid. The semi\u00ad algorithm remains incomplete, but \nis strong enough to prove all of the equations required by the encoding presented in \u00a74. Why do we require \ntypes to be well-kinded? If we were to re\u00admove this condition, every type would be permitted. Still, \nthe fact that = is a consistent .-theory would be suf.cient to prove that FORK is type-safe (\u00a73). However, \ntype equality would then become undecidable, and (as a result) type-checking would become unde\u00adcidable \nas well. This would make it pragmatically more dif.cult to build well-typed FORK terms, as we do in \u00a74. \nIf we do insist that types are well-kinded, on the other hand, then every type is solvable and (as a \nresult) type equality and type-checking are semi\u00addecidable, a pragmatically valuable property. Another \npotential reason why kinds should be well-formed and types should be well-kinded is that these conditions \nmake it pos\u00adsible to interpret kinds in a category of ultrametric spaces and to interpret types as inhabitants \nof kinds, in the style of Birkedal et al. [8].  . ::= * | . . . | . (co-inductively; see \u00a72) t ::= a \n| .a.t | tt (see \u00a72) |.| () | (,)|.. |.. (type constants) t ::= x | .x.t | tt (functions) | () (unit) \n| (t,t)| let (x,x)= t in t (pairs) | .a.t | tt (universals) | pack t,t as t (existentials) | unpack a,x \n= t in t G ::= \u00d8| G; a : . | G; x : t Figure 3. FORK: kinds, types, terms 1.K f () : * 2.K f. : * . \n* . * 3.K f (,): * . * . * 4.K f.. :(. . n *). n * 5.K f.. :(. . n *). n * Figure 4. FORK: kind assignment: \nconstants ABS VAR G f t1 : 0* G;x : t1 f t : t2G f x : G(x) G f .x.t : t1 . t2 APP UNIT G f t1 : t1 . \nt2 G f t2 : t1 G f () : () G f t1 t2 : t2 (,)-ELIM (,)-INTRO G f t1 :(t1,t2) G f t1 : t1 G f t2 : t2 \nG; x1 : t1;x2 : t2 f t2 : t G f (t1,t2):(t1,t2)G f let (x1,x2)= t1 in t2 : t .-ELIM .-INTRO G f t : .. \nt1 G; a : . f t : ta #G G f t2 : 0. G f .a.t : .. (.a.t )G f tt2 : t1 t2 .-INTRO G f t : t1 t2 G f.. \nt1 : 0* G f t2 : 0. G f pack t2,t as .. t1 : .. t1 .-ELIM CONVERSION G f t1 : .. t1 a #G,t2 G f t : t1 \nG; a : .;x :(t1 a)f t2 : t2 G f t2 : 0*t1 = t2 G f unpack a,x = t1 in t2 : t2 G f t : t2 Figure 5. FORK: \ntype assignment  3. FORK In System F., a system of simple .nite kinds is used to classify types. In \nFORK, instead, Nakano s system is used. As a result, FORK is an extension of F.. FORK retains type safety, \nbut aban\u00addons strong normalization. Kinds and types Kinds and types (Figure 3) are as presented previously \n(\u00a72), except a number of type constants are introduced, as is standard in F.. These constants are assigned \nkinds by the axioms in Figure 4. (.x.t1)t2 -. [x . t2]t1 let (x1,x2)=(t1,t2)in t -. [x1 . t1,x2 . t2]t \n(.a.t)t -. [a . t]t unpack a,x = (pack t2,t1 as t1)in t2 -. [a . t2,x . t1]t2 C[t1] -. C[t2] if t1 -. \nt2 Figure 6. FORK: reduction semantics It may come as a surprise that the function and product type constructors \nhave kind * . * . *, as opposed to * . * . * in F.. This means that these constructors are contractive \nin both arguments. An intuitive reason why they should be viewed as contractive is precisely that they \nare type constructors, as opposed to type operators: they produce syntax. For instance, an application \nof the function type constructor to two arbitrary types t1 and t2 yields a type that is well-de.ned down \nto depth 1 it has an arrow at its root regardless of how t1 and t2 might behave. The FORK axioms are \nmore liberal than their F. counterparts, and crucially so. For instance, the former allow the recursive \ntype \u00b5a.a . a to have kind *, while the latter would make this type ill-kinded. Naturally, the encoding \nof general references into FORK (\u00a74) relies on the existence of such recursive types. Because the function \nand product type constructors have kind * . * . *, one cannot expect the types that classify values \nto always have kind *, as in F.. Instead, in FORK, the types that classify values have kind n *, for \nsome n . N. We write K f t : 0.when K f t : n .holds for some n . N. The universal and existential type \nconstructors .. and .. are not considered contractive. Because the types that classify values can have \nkind n * for any n . N, it is natural for these two constants to admit every kind of the form (. . n \n*) . n *, as opposed to just (. . *). * in F.. The properties stated in the previous section (\u00a72) remain \nvalid in the presence of type constants of arbitrary kind. Type assignment The syntax of terms t and \ntype environments G is standard (Figure 3). A type environment Gcan play the role of a kind environment \nK. The type assignment judgement G f t : t is de.ned in Figure 5. The typing rules are identical to their \nF. counterparts up to a few details, which we now discuss. The type conversion rule (CONVERSION) relies \non the notion of type equality that was de.ned earlier (\u00a72). The types that classify values have kind \n0*. This is re.ected in the following de.nition and lemma: De.nition 3.1 The empty type environment is \nwell-formed. The type environment G; a : . is well-formed if G is well-formed and a #G. The type environment \nG; x : t is well-formed if G is well\u00adformed and G f t : 0*. 0 Lemma 3.2 If G is well-formed, then G f \nt : t implies G f t : 0*. 0 In the following, we restrict our attention to well-formed type environments. \nThe type application rule (.-ELIM) states that a universally quanti.ed variable of kind . can be instantiated \nwith a type of kind 0.. The rule .-INTRO is similarly relaxed. This makes sense thanks to the following \ntype substitution lemma, which is later exploited in the proof of subject reduction:  C ::= .x.[] | \n[] e | e [] |([],e)| (e, []) | pi [] S ::= [] | S[bind ([],e)] (.x.e1)e2 . [x . e2]e1 pi (e1,e2) . ei \nC[e] . C[e ] if e . e (s,S,e1) . (s,S,e2) if e1 . e2 (s,S, bind (e1,e2)) . (s,S[bind ([],e2)],e1) (s,S[bind \n([],e2)],return e1) . (s,S,e2 e1) (s,S, new e) . (s{. . e},S,return .) where . = |s|(s,S, read .) . (s,S,s(.)) \nif .< |s|(s,S, write (.,e)) . (s{. . e},S,return ()) if .< |s| Figure 7. System F: untyped reduction \nsemantics Lemma 3.3 Let G1 f t1 : 0.. If G1;a : .;G2 is well-formed, then G1;[a . t1]G2 is well-formed. \nFurthermore, G1;a : .;G2 f t : t2 implies G1;[a . t1]G2 f [a . t1]t :[a . t1]t2. 0 It is possible to \ngive a syntax-directed presentation of the type system, where the conversion rule is merged with the \nother rules. This allows type-checking to be performed in a standard bottom\u00adup fashion. That is, provided \nevery .-bound variable carries an explicit kind and every .-bound variable carries an explicit type, \nthe knowledge of Gand t is suf.cient to reconstruct a type t (if one exists) such that G f t : t holds. \nThe prototype implementation of FORK follows this scheme. Type soundness FORK is equipped with a standard \nreduction semantics (Figure 6). Reduction is permitted under an arbitrary context. Values are de.ned \nas follows: v ::= .x.t | () | (v,v)| .a.v | pack t,v as t The system enjoys the following properties: \nLemma 3.4 (Subject reduction) G f t1 : t and t1 -. t2 imply G f t2 : t. 0 De.nition 3.5 A term t is well-typed \niff G f t : t holds, where G binds only type variables (no term variables). 0 Lemma 3.6 (Progress) A \nwell-typed term either reduces or is a value. 0 Theorem 3.7 (Type soundness) A well-typed term either \ndiverges or reduces (in zero or more steps) to a value. 0  4. Encoding general references into FORK \n4.1 The source calculus The source language of the encoding is a monadic presentation of System F with \ngeneral references. It is due to Peyton Jones and Wadler [25, \u00a75.3]. The terms are the standard terms \nof System F, extended with the monadic constants return and bind; with the constants new, read, and write \nfor allocating, reading and writing references; and with memory locations ., which we take to be natural \nnumbers. e ::= x | .x.e | ee | .a.e | eT | () | (e,e)| pi e |return | bind | new | read | write | . F-ABS \nF-VAR E;x : T1 f e : T2 E1;x : T;E2 f x : T E f .x.e : T1 . T2 F-APP F-.-INTRO E f e1 : T1 . T2 E f e2 \n: T1 E;a f e : T E f e1 e2 : T2 E f .a.e : .a.T F-.-ELIM E f e : .a.T1 E f e T2 : [a . T2]T1 F-UNIT E \nf () : () F-(,)-INTRO F-(,)-ELIM E f e1 : T1 E f e2 : T2 E f e : (T1,T2) E f (e1,e2): (T1,T2) E f pi \ne : Ti F-RETURN E f return : .a.a . Ma F-BIND E f bind : .a..\u00df.(M a,a . M\u00df). M\u00df F-NEW F-READ E f new \n: .a.a . M (ref a) E f read : .a.ref a . Ma F-WRITE E f write : .a.(ref a,a). M () Figure 8. System \nF: typing rules The types are: T ::= a | () | T . T | (T,T)|.a.T | MT | ref T where M is the monad. The \nde.nition of the typing judgement E f e : T appears in Figure 8. This de.nition concerns programs whose \nexecution has not begun and (hence) that do not contain memory locations. A de.nition of the encoding \nof locations is needed only as part of the semantics preservation argument (\u00a74.10). The operational semantics \nis de.ned for type-erased terms, that is, terms where the type abstraction and type application constructs \nhave been erased. The semantics, which appears in Figure 7, is organized in two layers, following Moggi \nand Sabry [19]. First, simpli.cation of terms is de.ned: it is the compatible closure of \u00df-reduction. \nThen, reduction of con.gurations is de.ned, where a con.guration is a triple of a store s, an evaluation \nstack S, and a term e, which represents a computation (that is, it presumably has a type of the form \nMT). Because memory locations are natural numbers, a store is just a list of terms. We write nil for \nthe empty store. We write |s| for the length of the store s. We write s(.)for the term found in the store \ns at location .. We write s{. . e} for the extension or update of the store s at location . with the \nterm e. An evaluation stack is just a list of suspended applications of bind. In the following, we present \nan encoding of this calculus into FORK. We begin with a series of de.nitions of FORK kinds, types, and \nterms (\u00a74.2 \u00a74.6), whose well-formedness has been machine\u00ad checked by the prototype implementation of \nFORK [28]. Then, we de.ne the encoding (\u00a74.7 and \u00a74.8), a type-directed transformation of the source \ncalculus into FORK. Finally, we prove that the encod\u00ading is type-preserving (\u00a74.9) and semantics-preserving \n(\u00a74.10).  4.2 Fragments In order to type-check the store, which is basically a sequence of values, we \nneed sequences of base types, where a base type is a type of kind *. Because the store grows with time, \nwe often use  kind fragment = * . * type fnil : fragment = .tail. tail type @: fragment . fragment . \nfragment = .f 1 f 2 tail. f 1 (f 2 tail) type snoc : fragment . * . fragment = .f. .data. .tail. f (data, \ntail) Figure 9. Fragments type array : fragment . * type index : fragment . * . * term array empty \n: array fnil term array extend : .f data. array f . data . array (f snoc data) term array read : .f data. \narray f . index f data . data term array write : .f data. array f . index f data . data . array f term \narray end index : .f. array f ..data. index (f snoc data) data term index monotonic : .f 1 f 2 data. \nindex f 1 data . index (f 1 @ f 2) data Figure 10. Arrays such a sequence to describe only part of the \nstore, and concatenate multiple such sequences to obtain a description of the complete store. For this \nreason, we refer to such a sequence as a fragment. Because we intend to parameterize types over fragments, \nto quantify over fragments, etc., fragments must be types (of a suit\u00adable kind), and the basic operations \nover fragments must be type operators. This is done as follows (Figure 9). The kind fragment is * . *. \nThe empty fragment fnil is the identity function. Fragment concate\u00adnation @ is function composition. \nIt is easy to check, with respect to type equality =, that fnil is a left unit and right unit for @, \nand that @ is associative. The extension of a fragment f with a base type data, written snoc f data or \nmore pleasantly f snoc data, is .tail. f (data, tail). The type (data, tail) is the application of the \nproduct type constructor (,)(Figure 4) to the base types data and tail.  4.3 Arrays We wish to represent \nthe store as an array. Thus, FORK must support arrays. We need heterogeneous arrays: it must be permitted \nfor different array elements to have different types. We need safe arrays: out-of-bound array accesses \nmust be statically forbidden. (As Levy puts it, it is unnatural [...] to specify what happens when we \nread a non-existent cell, something that can never occur in reality [16].) We need extensible arrays: \nthere must be a way of creating a new array by appending a new cell at the end of an existing array, \nand any valid index into the earlier array must remain a valid index into the new array. The signature \nin Figure 10 ful.lls these requirements. It intro\u00adduces a couple of abstract type constructors for arrays \nand indices, as well as a number of operations over arrays. The type array f describes a heterogeneous \narray whose ele\u00adments are described by the fragment f. The type index f data repre\u00adsents the address \nof a cell of base type data within an array of type array f. The type operators array and index are contractive: \nas far as the user of the array abstraction is concerned, they can be thought of as type constructors. \nkind world = world . fragment type nil : world = .x. fnil type o : world . world . world = .w1 w2 x. \nw1 (w2 o x) @ w2 x Figure 11. Worlds The zero length array, array empty, is described by the frag\u00adment \nfnil. Array extension, array extend, is described using the fragment extension operation, snoc. Reading \nand writing are per\u00admitted by array read and array write. Writing is type-invariant: the old and new \narray elements both have type data. The operation ar\u00adray end index returns the end index of an array \nof type array f. It is not a valid index into this array, but becomes a valid index once the array is \nextended with a new cell: this is expressed by the type .data. index (f snoc data) data. The operation \nindex monotonic witnesses the fact that a valid index into a smaller array is also a valid index into \na larger array: this is expressed in terms of frag\u00adment concatenation. This operation is a coercion: \nits semantics is the identity. There are two ways of making the types and operations de\u00adscribed by this \nsignature available in FORK. The .rst way, which we follow, is to implement this signature. This can \nbe done by representing array data as a tagless singly\u00adlinked list (that is, as a sequence of nested \npairs) and by represent\u00ading an array index as a pair of functions for reading and writing at this index. \n(The read function, for instance, encapsulates a sequence of pair projections.) The code is about a hundred \nlines [28]. It does not use any recursion: it is in fact expressed within F.. This im\u00adplementation of \narrays shows that, in principle, it is not necessary to extend FORK with primitive arrays. It is of course \ninef.cient: reading and writing have linear time complexity. Thesecondwaywouldbetoextend FORK withprimitivearrays, \nthat is, to consider the signature of Figure 10 as a set of axioms, to extend the operational semantics \nof FORK with new reduction rules for arrays, and to extend its type soundness proof. This would allow \na more ef.cient implementation of array access, although ef.ciency seems of little concern here.  4.4 \nWorlds Our arrays are extensible in width. This helps us model dynamic allocation, that is, the fact \nthat the store grows with time. There remains to model higher-order store, that is, the fact that the \nstore can contain references and functions, whose type, in the encoding, depends on the shape of the \nstore. This dependency means that, as the store grows in width, the type of an existing store cell evolves. \nWe say that the store also grows in depth. An example may help illustrate this phenomenon. Consider the \nML program let x1 = ref (.x.x) in let x2 = ref 0 in x1 := (.x.!x2) . When the reference cell x1 is .rst \nallocated, it contains a function that has type int . int unconditionally. However, x1 is later updated \nwith a function that has type int . int only under a store where the cell x2 exists and holds an integer \nvalue. Thus, the type of the contents of the cell x1 evolves with time. In order to re.ect this, we introduce \nworlds (Figure 11). A world is an open-ended description of a store fragment. More precisely, a world \nis a fragment that is itself parameterized over a world. The kind world is recursive. It is well-formed, \nbecause the recursion goes through the later constructor . A world is a contractive function of a world: \nit produces some structure before it uses its argument. The empty world nil is the constant function \nthat returns the empty fragment. World composition, w1 o w2, can be described as  kind stype = world \n. * type box : stype . stype = .ax. .y. a (x o y) type unit : stype = .x. () type pair : stype . stype \n. stype = .abx.(ax, bx) type univ :(stype . stype) . stype = .body x. .a. body a x type arrow : stype \n. stype . stype = .abx. box a x . box b x type monad : stype . stype = .ax. store x . outcome a x type \noutcome : stype . stype = .ax. .y.(box a (x o y), store (x o y)) type store : world . * = .x. .y. array \n(xy) type ref : stype . stype = .ax. .y. index (xy)(a (x o y)) Figure 12. Semantic types the result of \nextending w1 in depth and in width with w2. Naturally, its de.nition is recursive. We invite the reader \nto check that it is well-typed in Nakano s system, using the derived kind assignment rule for recursive \ntype de.nitions. The empty world nil is a left unit and right unit for world com\u00adposition. Furthermore, \nworld composition is associative. This fact is non-obvious; fortunately, the semi-algorithm for type \nequality (\u00a72) proves it (and others like it) without assistance. In the following, by convention, the \nvariable w has kind world, while the variables x and y have kind world.  4.5 Semantic types A type \nin the source language is translated to a semantic type, that is, a contractive function of worlds to \nbase types (Figure 12). Let a be a semantic type and x be a world. A value v of type ax is valid now, \nin world x. Is it valid also in every future world? That is, is it the case that v also has type a (x \no y) for every y? In general, there is no guarantee that this is so. Where we need this to be the case, \nwe are explicit about this requirement and use a value of type box a x, where the semantic type operator \nbox builds in a universal quanti.cation over future worlds. This operator is known as the necessity modality \n[5]. A semantic type of the form box a is known as necessary [5] or hereditary [14]. Remark There are \nsemantic models (see e.g. [31]) where necessity is built into the world equation, so that (the analogue \nof) every type is hereditary. Here, this is not the case. FORK does not have a monotonic arrow at the \nkind level, so there seems to be no way of building necessity into worlds. We follow Appel et al. [5] \nand Hobor et al. [14] and explicitly use the box modality to keep track of which types are hereditary. \n0 It is worth noting that bounded quanti.cation over all future worlds z (that is, .z = x. t) is expressed \nhere in terms of ordinary quanti.cation over a world extension y (that is, .y. [z . x o y]t). In this \nencoding, the associativity of world composition expresses the transitivity of the world ordering. A \nhereditary value is valid in every future world, hence is hereditary in every future world. This is expressed \nby de.ning a coercion forward of type .a xy.box a x . box a (x o y). The encoding of unit, pairs, and \nquanti.ers is straightforward: the world parameter x is just passed down. The encoding of arrows states \nthat functions require a hereditary argument and produce a hereditary result. This is expressed by the \ntype box a x . box b x. Remark The reader might have expected instead the type box (.x. ax . b x), which \nguarantees that the function itself is hereditary. This type is more general than box a x . box b x. \nHowever, this choice would cause a dif.culty in the construction of certain functions, such as new (Figure \n15). There, we must be able to argue that the argument v is hereditary, because this value will be written \ninto the store, and the store holds hereditary values. If v has type box a x, the argument is trivial, \nwhereas if it has type ax, it is not clear that v is hereditary. Our current choice, on the other hand, \ndoes not seem to cause any dif.culty. It leads to a style where every variable in the type en\u00advironment \nhas a boxed type (see De.nition 4.2) and every expres\u00ad sion has a boxed type (see the statement of Theorem \n4.3). In short, the fact that the encoding [T] of a type T is not always hereditary does not hurt us: \nwe use explicit boxes where needed. Another route would be to set things up so that the encoding [T]of \nevery type T is a hereditary semantic type. One would then build this information into the translation \nvia coercions: wherever one abstracts over a semantic type variable a, one would also abstract over a \ncoercion of type .x. a x . box a x. It seems plausible that this would succeed; it could be investigated \nas part of future work.0 The encoding of the monad is standard [16]. A computation requires a store in \nworld x, and produces a pair of a (hereditary) result and a new store in some future world x o y. We \nuse the abbreviation outcome a x for the type of such a pair. A store in world w contains values that \nare valid in world w and in future worlds. That is, a store is an array of hereditary values. This is \nexpressed by de.ning store w as .x. array (w x). In other words, a store is of course of .xed width, \nbut is polymorphic in depth. A reference of type ref a in world x is, roughly speaking, an index that \nallows reading or writing data of type ax within an array of type store x. More precisely, universal \nquanti.cation over a world extension y is again used to guarantee that references are hereditary. By \ndirect appeal to index monotonic, it is possible to de.ne a coercion box ref of type .ax. ref a x . box \n(ref a) x. We have reviewed the encoding of every type constructor of the source language. Thus, any \nsource-level type T is translated to a semantic type [T]. (The inductive de.nition of this translation \ncannot be expressed within FORK.) De.nition 4.1 The encoding [T] of a type T is de.ned as follows: a \n[a] = [()] = unit [T1 . T2] = arrow [T1][T2] [(T1,T2)] = pair [T1][T2][.a.T] = univ (.a.[T]) [MT] = monad \n[T][ref T] = ref [T] where the combinators that appear in the right-hand sides of these equations are \nde.ned in Figure 12.  4.6 Memory allocation When a new reference is allocated, the width of the array \nthat represents the store is increased by one. If the allocation takes place in world x, and if the newly \ncreated reference is initialized with a value v of type box a x, what is the new world after allocation? \nThis new world must be the composition of x and of a world of width one, which we refer to as a cell. \nThat is, the new world must be x o cell a x, for an appropriate de.nition of cell, an operator that maps \na and x to a world.  type cell : stype . world . world = .a x y tail.(a (x o cell a x o y), tail) term \nstore extend : .xa. store x . box a x . store (x o cell a x) term store end index : .xa. store x . ref \na (x o cell a x) Figure 13. Memory allocation The de.nition of cell appears in Figure 13. As above, the \nparam\u00ad eter x represents the world before allocation, or a past world. The parameter y represents a depth \nextension, or a future world, while tail represents a width extension. The type cell a x y tail, a type \nof kind *, is a product of the types a(...) and tail. (This is consistent with our de.nition of fragment \nextension, snoc, in Figure 9.) The semantic type a is applied to the composite world x o (cell a x) o \ny, re.ecting the manner in which the .nal world is obtained: starting in world x, .rst a memory cell \nis allocated, then the world is extended with y. Thus, the de.nition of cell is recursive. It is worth \nnoting that a value v of type box a x also has every type of the form a (x o cell a x o y), simply because \nthe latter is a polymorphic instance of the former. Thus, the value that is used to initialize the cell \nis indeed a suitable value for the cell in every future world y. How do we ascertain that this de.nition \nof cell is right? The proof is in the fact that the terms store extend and store end index, which respectively \nconstruct the new store and the address of the new reference, have the types shown in Figure 13. The \nde.nitions of these terms [28] are a couple lines each. Up to a number of suitable type abstractions \nand applications, store extend is just ar\u00adray extend, while store end index is just array end index. \n 4.7 Encoding the monadic constants All of the infrastructure is now in place. We are in a position \nto encode the constants return, bind, new, read, and write. To do so, we must de.ne .ve terms that admit \nthe types shown in Figure 14 and that adequately implement the store-passing machinery. We present and \nexplain only the de.nitions of the term new (Figure 15). The de.nitions of return, bind, read, and write \nare omitted and can be found online [28]. We believe that the de.nition of new is representative, so \nthat the reader who has studied it could (if he or she so wished!) reconstruct the other de.nitions as \nan exercise. The structure of the de.nition of new is in large part imposed by its type. By de.nition \nof box, univ, arrow, and monad (Figure 12), the desired type for new: box (univ (.a. a arrow monad (ref \na))) nil is equal to: .x. .a. box a x ..y. store (x o y) . outcome (ref a) (x o y) Thus, the de.nition \nof new begins with abstractions over a world x, a semantic type a, a value v of type box a x, a world \ny, and a store s of type store xy. The type xy is de.ned on the .y as a local abbreviation for x o y. \nIt might seem strange that we must abstract over two successive world extensions, x and y. This is required \nby the monadic structure of the source language: the world x corresponds to the point in time where ref \nis applied to a value v, while the world x o y corresponds to the point in time where the computation \nref v is run. After accepting these parameters, new must produce a result of type outcome (ref a) xy. \nBy de.nition of outcome (Figure 12), this is equal to: .z. (box (ref a) (xy o z), store (xy o z)) term \nreturn : box (univ (.a. a arrow monad a)) nil term bind : box (univ (.a. univ (.b. (monad a pair (a arrow \nmonad b)) arrow monad b ))) nil term new : box (univ (.a. a arrow monad (ref a))) nil term read : box \n(univ (.a. ref a arrow monad a)) nil term write : box (univ (.a.(ref a pair a) arrow monad unit)) nil \nFigure 14. Encoding the monadic constants: declarations term new : box (univ (.a. a arrow monad (ref \na))) nil = .xa. .v : box ax. .y. type xy = x o y in .s : store xy. type c = cell a xy in pack c,( box \nref [a][xy o c](store end index [xy][a] s), store extend [xy][a] s (forward [a][x][y] v) ) as outcome \n(ref a) xy Figure 15. Encoding the monadic constants: de.nition of new This type is existentially quanti.ed \nover a world extension z, which represents the new storage allocated by the computation. Here, this new \nstorage is a single cell, which holds a value of semantic type a. So, according to our earlier discussion \n(\u00a74.6), the concrete witness for z should be cell a xy. Thus, c is de.ned as a local abbreviation for \ncell a xy, and the construct pack c, ... as outcome (ref a) xy is used in order to build an existential \npackage. Inside this package should be a pair of a newly allocated mem\u00adory location, at type box (ref \na) (xy o c), and an extended store, at type store (xy o c). The next available memory location is obtained \nby applying store end index (Figure 13) to suitable type arguments and to the current store s. This application \nhas type ref a (xy o c). This is what was required, except a leading box is missing: we must justify \nthat this memory location is valid not only now, but also in the future. This is achieved via an application \nof the coercion box ref, which was mentioned earlier (\u00a74.5). It seems that the new store should be obtained \nby applying store extend (Figure 13) to the current store s and to the initial value v of the newly allocated \ncell. However, there is a slight dif.culty: s and v do not inhabit the same world. Indeed, s has type \nstore (x o y), while v has type box a x. Thus, before store extend can be applied, the value v must be \nmoved from the world x into the world x o y. Fortunately, v is hereditary, so this is easily achieved \nby applying the coercion forward (\u00a74.5). The de.nition of new is somewhat complex due to the many type \nannotations. However, by erasing all type abstractions, appli\u00adcations, and abbreviations, as well as \nall coercion applications, one .nds that new is just .v..s.(store end index s,store extend s v). Thus, \nit is easy to informally convince oneself that the untyped translation that underlies our encoding is \nindeed a standard store\u00adpassing translation. A formal argument of semantics preservation appears further \non (\u00a74.10).  ENCODE-VAR E1;x : T;E2 f x . .y.x (wE2 o y):T ENCODE-ABS E;x : T1 f e . t : T2 E f .x.e \n. .wx..x.t : T1 . T2 ENCODE-APP E f e1 . t1 : T1 . T2 E f e2 . t2 : T1 E f e1 e2 . t1 nil t2 : T2 ENCODE-.-INTRO \nE;a f e . t : T E f .a.e . .y..(a : stype).(t y):.a.T ENCODE-.-ELIM E f e . t : .a.T1 E f eT2 . .y.(t \ny [T2]) :[a . T2]T1 ENCODE-UNIT E f () . .y.() :() ENCODE-(,)-INTRO E f e1 . t1 : T1 E f e2 . t2 : T2 \nE f (e1,e2). .y.(t1 y,t2 y) :(T1,T2) ENCODE-(,)-ELIM E f e . t :(T1,T2) E f pi e . .y.let (x1,x2)= t \ny in xi : Ti Figure 16. System F-to-FORK encoding: pure fragment  4.8 Encoding terms We have de.ned \nthe encoding of the .ve monadic constants. There remains to encode the pure fragment of the source language, \nthat is, the terms of System F. The encoding is type-directed. It takes the form of an encoding judgement \nE f e . t : T, which enriches the System F typing judgement: that is, E f e : T holds iff E f e . t : \nT holds for a certain t. The de.nition of this judgement appears in Figure 16. Over pure terms, the encoding \nis essentially the identity. It introduces type abstractions and applications in order to introduce and/or \neliminate the box modality.  4.9 Type preservation The following de.nition and theorem state precisely \nin what way the encoding is type-preserving. De.nition 4.2 With each variable x, we associate a world \nvariable wx. Then, with a System F type environment E, we associate a world wE, as follows: w\u00d8 = nil \nwE;a = wE wE;x:T = wE o wx The encoding [E] of a type environment E is given by: = \u00d8 [\u00d8 [E;a = E ;a \n: stype [E;x : T] = [ E] ;wx : world;x : box [T] wE;x:T 0 Every abstraction .x in the source program \ngives rise to a sequence of two abstractions, of the form .wx..x, in the translated program. This accounts \nfor the fact that the world at the time a function is de.ned and the world at the time this function \nis applied are distinct: the latter is in general an extension of the former. The parameter wx represents \nthis extension. Theorem 4.3 (Type preservation) E f e . t : T implies [E] f t : box [T] wE. 0 Proof. \nIn this proof, we do not consider the cases of the con\u00adstants return, bind, new, read, and write, which \nhave been machine\u00adchecked [28]. There remains one case for each of the rules in Fig\u00adure 16. . Case ENCODE-VAR. \nBy hypothesis, under the environment [E1;x : T;E2], x has type: box [T] wE1;x:T. By de.nition of box, \nthis is: .y.([T] (wE1;x:T o y)). Thus, the type application x (wE2 o y)has type: [T] (wE1;x:T o wE2 o \ny), that is, o y). Thus, the term .y.x (wE2 o y)has type: .y.([T] (wE1;x:T;E2 o y)), [T] (wE1;x:T;E2 \nthat is, box [T] wE1;x:T;E2. . Case ENCODE-ABS. By the induction hypothesis, under the environment [E;x \n: T1], the term t has type box [T2] wE;x:T1. That is, under the type environment: [E];wx : world;x : \nbox [T1] (wE o wx), the term t has type: box [T2] (wE o wx). There follows that the term .wx..x.t has \ntype: .wx.(box [T1] (wE o wx). box [T2] (wE o wx)), By de.nition of the encoding and by de.nition of \nbox, this type is: box [T1 . T2] wE. . Case ENCODE-APP. By the induction hypothesis, under the type \nenvironment [E], the term t1 has type box [T1 . T2] wE and the term t2 has type box [T1] wE. By de.nition \nof box and by de.nition of the encoding, the former of these types is: .wx.(box [T1] (wE o wx). box \n[T2] (wE o wx)). As a result, the application t1 nil has type: box [T1] wE . box [T2] wE, and the application \nt1 nil t2 has type box [T2] wE. . Case ENCODE-.-INTRO. By the induction hypothesis, un\u00adder the type \nenvironment [E];a : stype, the term t has type   box [T] wE. Thus, the term: .y..(a : stype).(t y) \nhas type .y..(a : stype).([T] (wE o y)). By de.nition of univ, this type is: .y.(univ (.a.[T])(wE o y)), \nthat is, by de.nition of box: box (univ (.a.[T])) wE, that is, by de.nition of the encoding, box [.a.T \n] wE. . Case ENCODE-.-ELIM. By the induction hypothesis, under the type environment [E], the term t has \ntype: box [.a.T1] wE. As we saw in the previous case, this type is: .y..(a : stype).([T1] (wE o y)). \nThus, the term .y.(t y [T2])has type: .y.(([a . [T2]][T1])(wE o y)). Because the encoding of types is \ncompositional (i.e., commutes with type substitution), this type is: .y.([[a . T2]T1] (wE o y)), that \nis, by de.nition of box: box [[a . T2]T1] wE. . Cases ENCODE-UNIT, ENCODE-(,)-INTRO, ENCODE-(,)-ELIM. \nLeft to the reader. D  4.10 Semantics preservation The encoding is semantics-preserving. This is true \neven in the ab\u00adsence of a well-typedness hypothesis. This is not surprising: one might be tempted to \nsay that the encoding is obviously a store\u00adpassing translation, and that a store-passing translation \nis obvi\u00adously semantics-preserving. Nevertheless, it is worth checking this fact. The results presented \nin this section have been machine\u00adchecked using Coq; the development can be found online [28]. Because \nthe rules ENCODE-.-INTRO and ENCODE-.-ELIM in Figure 16 encode type abstractions and type applications \nin terms of type abstractions and type applications, it is possible to de.ne an untyped version of the \nencoding, which transforms untyped terms into untyped terms. This untyped encoding is a function. In \nthe following, we write e for an untyped term of the source calculus, and we write [e] for its untyped \nencoding. It is easy to check, by examination of Figure 16, that the un\u00ad typed encoding function is the \nidentity over the pure fragment of System F. As an immediate corollary, every simpli.cation step in the \nsource calculus is simulated by one reduction step in the target calculus: Lemma 4.4 e1 . e2 implies \n[e1] -. [e2]. 0 We now wish to prove an analogous simulation diagram about the reduction of con.gurations. \nThis requires de.ning the encoding of a memory location [.], the encoding of a store, the encoding of \nan evaluation stack, and the encoding of a con.guration. These some\u00adwhat technical de.nitions are omitted, \nbut can be found online [28]. It is then a matter of routine to check that one step of reduction in the \nsource calculus is simulated by one or more steps of reduction in the target calculus. This is stated \nas follows. In order to allow for some slack in the administrative reductions, the encoding of con.gurations \nis a relation, rather than a function. We write (s,S,e). t to indicate that the term t is an encoding \nof the con.guration (s,S,e). Then, we have: Lemma 4.5 (Simulation) For a closed con.guration (s1,S1,e1), \nthe following diagram holds: (s1,S1,e1) t1 + (s2,S2,e2) t2 0 It is worth noting that, in order to establish \nt1 -.+ t2, we exploit the fact that reduction of FORK terms is permitted under arbitrary contexts. We \nuse this .exibility, in particular, to perform reduction inside the components of a pair. As an immediate \nconsequence, we .nd that convergence is preserved by the encoding. Lemma 4.6 (Convergence) Let e1 be \na closed term of the source calculus. If the start con.guration (nil,[],e1) reduces (in many steps) to \nsome con.guration of the form (s, [],return e2), then the term [e1][nil] reduces (in many steps) to the \npair ([e2],[s]). 0 Proving that divergence is also preserved by the encoding is more dif.cult. Of course, \nby Lemma 4.5, the existence of an in.nite reduction sequence out of the start con.guration (nil,[],e1)implies \nthe existence of an in.nite reduction sequence out of its encoding However, this is not the desired property. \nBecause [e1][nil]. reduction of FORK terms is permitted under arbitrary contexts, the relation -. is \nnon-deterministic, and the existence of an in.nite reduction sequence is not an appropriate de.nition \nof divergence. Instead, we would like to consider that the term [e1][nil] diverges if and only if it \ndoes not have a head normal form. An analogous phenomenon arises in the source calculus, where simpli.cation \nis permitted under arbitrary contexts. Here is an informal sketch of how this problem might be solved. \nIn each of the source and target calculi, de.ne notions of standard (that is, leftmost) and internal \nreduction. Prove that divergence (that is, the absence of a head normal form) is equivalent to the exis\u00adtence \nof an in.nite standard reduction sequence. In the target calcu\u00adlus, prove that standard reduction and \ninternal reduction commute. Takahashi [33] proves these facts in the pure .-calculus. Then, re.ne Lemma \n4.5, by showing that one standard reduc\u00ad tion step in the source calculus is simulated by a mixture of \nat least one standard reduction step and an arbitrary number of internal re\u00adduction steps in the target \ncalculus. Use this fact, together with the property that standard reduction and internal reduction commute, \nto conclude that, if a source con.guration admits an in.nite stan\u00addard reduction sequence, then so does \nits encoding. We have not yet attempted to machine-check this development.  5. Related work Several \nstore-passing translations have appeared in the literature. Moggi s state monad [18] relies on a .xed \nstore type: it does not support dynamic memory allocation. Parameterised monads [6] al\u00ad low the type \nof the store to vary with time and can be used to model systems of strong references with memory allocation \nand de-allocation. Similarly, Hoare Type Theory [23] extends type the\u00ad ory with a monad that is indexed \nwith pre-and post-conditions: {P}x : A{Q} is the type of computations that expect a store in state P \nand produce a value x of type A together with a new store in state Q. Hoare Type Theory is very expressive, \nyet does not support weak references. O Hearn and Reynolds [24] translate two variations of Algol 60 \ninto a purely functional calculus with polymorphic and linear types, and compose this translation with \na model of the target calculus to obtain models of the source lan\u00adguages. Chargu\u00b4eraud and Pottier [12] \ntranslate an expressive type\u00ad and-capability calculus, which supports strong references, into a purely \nfunctional calculus2. Pottier [26] extends Chargu\u00b4  eraud and Pottier s work with an anti-frame rule \nthat allows weak references to be de.ned in terms of strong references. However, it is not clear how \nChargu\u00b4 eraud and Pottier s store-passing translation could be extended to support the anti-frame rule. \nTo the best of our knowl\u00adedge, no typed store-passing translation for weak references has appeared in \nthe literature. The syntactic approach to type soundness [13, 35] deals with weak references via store \ntypes, which map memory addresses to types. The store type grows with time (this is part of the statement \nof subject reduction) and simultaneously describes the current store as well as all future stores. This \nis probably the simplest approach to type soundness for general references. However, it does not suggest \nhow to design a type-preserving store-passing translation. FORK is an ad hoc extension of System F. that \nallows non\u00adterminating yet productive computation at the type level and (as a result) is able to express \nrich recursive types, far beyond the view of recursive types as regular trees that is commonly encountered \nin simpler type systems [4, 11]. There exist other calculi that per\u00ad mit productive computation at the \ntype level: .S [3] and Mini-Agda [1] come to mind. Perhaps these calculi could serve as target languages \nfor a type-preserving store-passing translation of general references.  6. Directions for future work \nIn this paper, we have equipped the source and target calculi with pairs. Is it possible to equip both \ncalculi with sums and extend the de.nition of the encoding? We believe so, up to a technical dif.\u00adculty. \nIn the de.nition of the encoding, we have exploited the com\u00admutation of box with respect to pairs: that \nis, a polymorphic pair can be transformed into a pair whose components are polymorphic. The term that \nperforms this transformation can be de.ned in System F, and, a fortiori, in FORK; up to type erasure, \nit is the identity. If the calculi were extended with sums, then, analogously, we would need a coercion \nthat transforms a polymorphic sum into a sum whose summands are polymorphic. Unfortunately, such a coercion \ncannot be de.ned, it seems, in System F. Instead, it must be added as an axiom, and one must move to \na version of FORK equipped with subtyping, in the style of System F. [17]. The typed store-passing translation \nthat we have presented is not fully abstract: there are terms that inhabit the encoding of a source type, \nbut do not encode any source term. In particular, there is snapback: it is permitted to duplicate or \ndiscard the store. Following O Hearn and Reynolds [24], one could enrich FORK with linear types and re.ne \nthe translation so as to encode the fact that the store is treated linearly. One might then hope to prove \nthat the re.ned translation is fully abstract. M\u00f8gelberg and Staton [20] prove such a result for a store-passing \ntranslation that deals with local state. Their translation is simpler than the one considered here insofar \nas they .x the type of the store: all locations have the same 2 In the absence of group regions in the \nsource calculus, Chargu\u00b4eraud and Pottier s translation is type-preserving in a strong sense. When the \nsource calculus has group regions, however, their translation is type-preserving only in a weaker sense: \nit uses map lookup and map update operations whose success is guaranteed by the type system of the source \ncalculus but not by the type system of the target calculus. The success of these operations depends on \nthe fact that the population of a group region can only grow with time. Thus, achieving type preservation \nin a strong sense might require a possible worlds machinery, as in the present paper. type, and all locations \nare considered allocated (they initially hold a default value). In this paper, only a limited meta-theoretic \nstudy of FORK has been carried out: we have established its type soundness with respect to an operational \nsemantics. To go further, we suggest building semantic models of FORK, perhaps by following Birkedal \net al. [8], and determining whether useful models of System F with general references can in fact be \nobtained by composition with the store-passing translation presented in this paper.  Acknowledgments \nI wish to thank Lars Birkedal, Paul-Andr\u00b4e Melli`es, Bernhard Reus, Jan Schwinghammer, and Hongseok Yang \nfor pleasant and inspir\u00ading discussions.  References [1] Andreas Abel. MiniAgda: Integrating sized and \ndependent types. In Workshop on Partiality And Recursion in Interactive Theorem Provers (PAR), July 2010. \n[2] Amal Jamil Ahmed. Semantics of Types for Mutable State. PhD thesis, Princeton University, 2004. [3] \nThorsten Altenkirch, Nils Anders Danielsson, Andres L\u00a8 oh, and Nico\u00adlas Oury. .S: Dependent types without \nthe sugar. In Functional and Logic Programming, volume 6009 of Lecture Notes in Computer Sci\u00adence, pages \n40 55. Springer, April 2010. [4] Roberto M. Amadio and Luca Cardelli. Subtyping recursive types. ACM \nTransactions on Programming Languages and Systems, 15(4):575 631, September 1993. [5] Andrew W. Appel, \nPaul-Andr\u00b4es, Christopher D. Richards, and e Melli`J\u00b4er ome Vouillon. A very modal model of a modern, \nmajor, general type system. In ACM Symposium on Principles of Programming Languages (POPL), pages 109 \n122, January 2007. [6] Robert Atkey. Parameterised notions of computation. Journal of Functional Programming, \n19(3 4):355 376, 2009. [7] Henk P. Barendregt. The Lambda Calculus, Its Syntax and Semantics. Elsevier \nScience, 1984. [8] Lars Birkedal, Jan Schwinghammer, and Kristian St\u00f8vring. A metric model of lambda \ncalculus with guarded recursion. Presented at FICS 2010, July 2010. [9] Lars Birkedal, Kristian St\u00f8vring, \nand Jacob Thamsborg. The category\u00ad theoretic solution of recursive metric-space quations. Technical Report \nITU-2009-119, IT University of Copenhagen, 2009. [10] Lars Birkedal, Kristian St\u00f8vring, and Jacob Thamsborg. \nRealizability semantics of parametric polymorphism, general references, and recur\u00ad sive types. Mathematical \nStructures in Computer Science, 2010. To appear. [11] Michael Brandt and Fritz Henglein. Coinductive \naxiomatization of recursive type equality and subtyping. Fundamenta Informatic\u00e6, 33:309 338, 1998. [12] \nArthur Chargu\u00b4eraud and Franc\u00b8ois Pottier. Functional translation of a calculus of capabilities. In ACM \nInternational Conference on Func\u00adtional Programming (ICFP), pages 213 224, September 2008. [13] Robert \nHarper. A simpli.ed account of polymorphic references. In\u00adformation Processing Letters, 51(4):201 206, \n1994. [14] Aquinas Hobor, Robert Dockins, and Andrew W. Appel. A theory of indirection via approximation. \nIn ACM Symposium on Principles of Programming Languages (POPL), January 2010. [15] Soren B. Lassen. Bisimulation \nin untyped lambda calculus: B\u00a8ohm trees and bisimulation up to context. In Mathematical Foundations of \nProgramming Semantics, volume 20 of Electronic Notes in Theoreti\u00adcal Computer Science, pages 346 374. \nElsevier Science, April 1999. [16] Paul Blain Levy. Possible world semantics for general storage in call\u00ad \nby-value. In Computer Science Logic, volume 2471 of Lecture Notes in Computer Science. Springer, 2002. \n [17] John C. Mitchell. Polymorphic type inference and containment. In\u00adformation and Computation, 76(2 \n3):211 249, 1988. [18] Eugenio Moggi. Notions of computation and monads. Information and Computation, \n93(1), 1991. [19] Eugenio Moggi and Amr Sabry. An abstract monadic semantics for value recursion. Informatique \nth\u00b4eorique et applications, 38(4):377 400, 2004. [20] Rasmus Ejlers M\u00f8gelberg and Sam Staton. Full abstraction \nin a metalanguage for state. In Workshop on Syntax and Semantics of Low Level Languages, July 2010. [21] \nHiroshi Nakano. A modality for recursion. In IEEE Symposium on Logic in Computer Science (LICS), pages \n255 266, June 2000. [22] Hiroshi Nakano. Fixed-point logic with the approximation modality and its Kripke \ncompleteness. In International Symposium on Theoret\u00adical Aspects of Computer Software (TACS), volume \n2215 of Lecture Notes in Computer Science, pages 165 182. Springer, October 2001. [23] Aleksandar Nanevski, \nGreg Morrisett, and Lars Birkedal. Hoare type theory, polymorphism and separation. Journal of Functional \nProgramming, 18(5 6), 2008. [24] Peter W. O Hearn and John C. Reynolds. From Algol to polymorphic linear \nlambda-calculus. Journal of the ACM, 47(1):167 223, 2000. [25] Simon Peyton Jones and Philip Wadler. \nImperative functional pro\u00ad gramming. In ACM Symposium on Principles of Programming Lan\u00adguages (POPL), \npages 71 84, January 1993. [26] Franc\u00b8ois Pottier. Hiding local state in direct style: a higher-order \nanti\u00ad frame rule. In IEEE Symposium on Logic in Computer Science (LICS), pages 331 340, June 2008. [27] \nFranc\u00b8ois Pottier. A formalization of Nakano s type system. http: //gallium.inria.fr/ fpottier/fork/, \nOctober 2009. [28] Franc\u00b8ois Pottier. The electronic FORK, July 2010. http:// gallium.inria.fr/ fpottier/fork/. \n[29] Franc\u00b8ois Pottier. A typed store-passing translation for general refer\u00adences (extended version). \nNovember 2010. [30] Jan Schwinghammer, Lars Birkedal, Bernhard Reus, and Hongseok Yang. Nested Hoare \ntriples and frame rules for higher-order store. In Computer Science Logic, volume 5771 of Lecture Notes \nin Computer Science, pages 440 454. Springer, September 2009. [31] Jan Schwinghammer, Hongseok Yang, \nLars Birkedal, Franc\u00b8ois Pottier, and Bernhard Reus. A semantic foundation for hidden state. In International \nConference on Foundations of Software Science and Computation Structures (FOSSACS), volume 6014 of Lecture \nNotes in Computer Science, pages 2 17. Springer, March 2010. [32] Christopher Strachey. Fundamental concepts \nin programming lan\u00adguages. Higher-Order and Symbolic Computation, 13(1 2):11 49, April 2000. [33] Masako \nTakahashi. Parallel reductions in .-calculus. Information and Computation, 118(1):120 127, April 1995. \n[34] Robert D. Tennent and Dan Ghica. Abstract models of storage. Higher-Order and Symbolic Computation, \n13:119 129, 2000. [35] Andrew K. Wright and Matthias Felleisen. A syntactic approach to type soundness. \nInformation and Computation, 115(1):38 94, November 1994.   \n\t\t\t", "proc_id": "1926385", "abstract": "<p>We present a store-passing translation of System <i>F</i> with general references into an extension of System <i>F</i><sub>&#969;</sub> with certain well-behaved recursive kinds. This seems to be the first type-preserving store-passing translation for general references. It can be viewed as a purely syntactic account of a possible worlds model.</p>", "authors": [{"name": "Fran&#231;ois Pottier", "author_profile_id": "81100490085", "affiliation": "INRIA, Paris-Rocquencourt, France", "person_id": "P2509587", "email_address": "francois.pottier@inria.fr", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926403", "year": "2011", "article_id": "1926403", "conference": "POPL", "title": "A typed store-passing translation for general references", "url": "http://dl.acm.org/citation.cfm?id=1926403"}