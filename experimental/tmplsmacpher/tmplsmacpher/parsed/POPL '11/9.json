{"article_publication_date": "01-26-2011", "fulltext": "\n A Parametric Segmentation Functor for Fully Automatic and Scalable Array Content Analysis Patrick Cousot \nRadhia Cousot Francesco Logozzo \u00b4Ecole normale sup\u00b4erieure &#38; Centre National de la Recherche Scienti.que \nMicrosoft Research, Redmond New York University \u00b4Ecole normale sup\u00b4erieure &#38; z s orm co fog @z o \nt. mc o lo i Courant Institute of Mathematical Sciences Microsoft Research, Redmond t eno f@s .u rco \ns , o us uc .u edo t@ s ny .pc c fuh @ n .a soo s t. erad i r Abstract We introduce FunArray, a parametric \nsegmentation abstract do\u00admain functor for the fully automatic and scalable analysis of array content \nproperties. The functor enables a natural, painless and ef.\u00adcient lifting of existing abstract domains \nfor scalar variables to the analysis of uniform compound data-structures such as arrays and collections. \nThe analysis automatically and semantically divides arrays into consecutive non-overlapping possibly \nempty segments. Segments are delimited by sets of bound expressions and abstracted uniformly. All symbolic \nexpressions appearing in a bound set are equal in the concrete. The FunArray can be naturally combined \nvia reduced product with any existing analysis for scalar variables. The analysis is presented as a general \nframework parameterized by the choices of bound expressions, segment abstractions and the re\u00adduction \noperator. Once the functor has been instantiated with .xed parameters, the analysis is fully automatic. \nWe .rst prototyped FunArray in Arrayal to adjust and exper\u00adiment with the abstractions and the algorithms \nto obtain the appro\u00adpriate precision/ratio cost. Then we implemented it into Clousot, an abstract interpretation-based \nstatic contract checker for .NET. We empirically validated the precision and the performance of the analysis \nby running it on the main libraries of .NET and on its own code. We were able to infer thousands of non-trivial \ninvariants and verify the implementation with a modest overhead (circa 1%). To the best of our knowledge \nthis is the .rst analysis of this kind ap\u00adplied to such a large code base, and proven to scale. Categories \nand Subject Descriptors D.2.4 [Software Engineer\u00ading]: Program Veri.cation formal methods, validation, \nasser\u00adtion checkers; D.3.1 [Programming Languages]: Formal Def\u00adinitions and Theory semantics; F.3.1 [Logics \nand Meanings of Programs]: Specifying and Verifying and Reasoning about Programs Mechanical veri.cation, \nassertions, invariants; F.3.2 [Logics and Meanings of Programs]: Semantics of Programming Languages Program \nanalysis. General Terms Algorithms, Design, Languages, Performance, Reliability, Security, Theory, Veri.cation. \nKeywords Abstract interpretation, Array abstraction, Array con\u00adtent analysis, Array property inference, \nInvariant synthesis, Static analysis, Program veri.cation. Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. POPL 11, January 26 28, 2011, Austin, Texas, \nUSA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 1. Introduction Our goal is \nto augment static analyzers for very large programs with a new fully automatic static analysis determining \nproperties of array elements with good precision but at low cost so as to scale up. The approach is in \nthe context of abstract interpretation [7]. The .rst objective of the array content analysis is to reduce \nthe false alarms due to accessing array elements which analysis is of\u00adten imprecise, in particular because \ntheir proper initialization is un\u00adknown. The second objective is to allow for automatically proving user \nprovided pre/post conditions and assertions of moderate com\u00adplexity on arrays (such as the non relational \nproperty all elements are initialized but not the relational one the array is sorted as in [6]). To cope \nwith veri.cation, we want to be able to adjust the cost/precision ratio towards more or less precision, \none extreme being the classical analysis by array smashing, the other being an element by element analysis \nof maximal precision and cost. 2. Motivating Example Let us consider the example in Fig. 1, extracted \nfrom the public constructor of the Random class of the .NET framework. The con\u00adstructor initializes all \nthe elements of the private array SeedArray to be =-1. The initialization process is quite complex, relying \non some number theory properties which are out-of-the scope of the paper. The precondition requires the \nparameter Seed not to be the smallest 32-bits integer, to prevent Math.Abs from throwing an OverflowException. \nNext, an array of 56 elements is allocated and assigned to SeedArray. The last array element is set to \nthe value of Seed, whereas all the others are zero (because of .NET se\u00admantics). The .rst loop (Loop \n1), sets all the elements of indexes 1 ... 54 to be =-1 according to the non-contiguous indexing se\u00adquence: \n21, 42, 8,..., leaving the .rst and the last elements un\u00adchanged. Therefore the assertion at the end \nof Loop 1 holds. The next loop (Loop 2) shakes the values in the array, updating the last element of \nthe array but not the .rst. To prove the second assertion one should prove that (i) the last element \nof SeedArray is de.\u00adnitely updated in the inner loop to a = 1 value; and that (ii) the inner loop is \nexecuted at least once. Array expansion The .rst and most precise approach for proving the two assertions: \n(i) expands the 56 cells of the array to 56 local variables; (ii) fully unrolls the loops. The example \nwill then become intractable, even with up-to-date hardware and tools. We totally unrolled the .rst loop, \nwe sliced the second loop according to some interesting variables (manually determined), and we tried \nto prove the second postcondition using Boogie [2] and the state-of\u00ad the-art SMT solver Z3 [10]. We let \nthe veri.cation process run for a whole week-end without getting an answer. The theorem prover  public \nRandom(int Seed) { Contract.Requires(Seed != Int32.MinValue); int num2 = 161803398 -Math.Abs(Seed); this.SeedArray \n= new int[56]; this.SeedArray[55] = num2; int num3 = 1; // Loop 1 for(inti=1; i<55;i++){ int index=(21* \ni) %55; this.SeedArray[index] = num3; // (*) num3 = num2 -num3; if (num3 < 0) num3 += 2147483647; num2 \n= this.SeedArray[index]; } Contract.Assert(Contract.Forall( // (**) 0,this.SeedArray.Length -1, i => \na[i] >= -1)); // Loop 2 for(intj=1; j<5; j++){ // Loop 3 for (intk =1;k <56;k++) { this.SeedArray[k] \n-= this.SeedArray[1 + (k + 30) % 55]; if (this.SeedArray[k] < 0) this.SeedArray[k] += 2147483647; }} \nContract.Assert(Contract.Forall(0, // (***) this.SeedArray.Length, i => a[i] >= -1)); } Figure 1. A motivating \nexample taken from the core li\u00adbrary of .NET. Contract.{Requires, Assert, ForAll} is the CodeContracts \nAPI (adopted in .NET from v4.0) to express pre\u00adconditions, assertions and bounded universal quanti.cations \n[3]. was overcome by the large number of case splits it had to perform (because of conditionals in loop \nbodies and the lack of primitive support for the remainder operation which had to be axiomatized). Array \nsmashing At the opposite side of the precision spectrum there is the smashing of all the array elements \ninto one summary location. It is immediate that this is not going to work. For instance in Loop 1, the \nvalue of SeedArray[55] is smashed with the others, concluding that any value can be written anywhere \nin the array. Predicate abstraction The method of Qadeer and Flanagan [15] uses some easy syntactic heuristics \nto derive the predicates used for the abstraction, which unfortunately do not work here. For instance, \none needs to know that 1 = index < 55 to determine that the last element of SeedArray is never overwritten \nin Loop 1, or that num3 =-1. Both properties cannot be inferred with syntactic heuristics. Array Partitioning \nThe array partitioning approach of Gopan, Reps and Sagiv [17] (later improved by P\u00b4eron and Halbwachs \n[19]) separates the task of array partitioning from that of establishing ar\u00adray properties. Given a partition \nof the array into slices, the analy\u00adsis populates the slices with some abstract value. The partitioning \nis done either syntactically or by some pre-analysis. The syntac\u00adtic approach (used in the examples of \n[17, 19, 29]) simply does not work here (e.g. it cannot determine which array element is written at (*)), \nand in general it is unfeasible in the generic set\u00adting of the bytecode analysis, where high-level syntactic \nstructures are compiled away. As a consequence, at the early stages of this work, we tried to implement \nthe second pre-analysis approach in Clousot [14]. The idea was to .rst perform a preliminary analysis \nof indices to provide a restricted domain for each loop, and then to perform the array analysis (generalizing \n[19, Sect. 15]). Perfor\u00ad mance turned out to be extremely bad. The .rst pre-analysis gen\u00aderated too many \npartition slices (also noticed by Dillig et al [12, Sect. 4]). The second analysis needed to replay the \nindex analy\u00adsis (e.g. to distinguish the .rst iteration from all the others) and the partition analysis \n(e.g. to track how abstract values .owed be\u00adtween partitions). The analysis of the example induced a \n28\u00d7 slow\u00addown with respect to a run of Clousot without the array analysis. We have therefore developed \na new approach (subject of this pa\u00adper) in which: (i) the scalar analysis and the array analysis are \nper\u00adformed at the same time (which is also more precise [8]); (ii) the array segmentation is automatically \nand semantically discovered by the analysis; and (iii) the segmentation admits possibly empty seg\u00adments. \nIn particular, possibly empty segments are a winning choice because they enable a compact representation \nfor array partitions avoiding the exponential multiplication of slices of the aforemen\u00adtioned works (Sect. \n4.4). Yang et al remarked similar advantages when using possibly empty list segments for shape analysis \n[37]. Under-approximations and Templates The technique of Gul\u00adwani, McCloskey and Tiwari [18] is extremely \npowerful yet ex\u00ad pensive. It requires: (i) the user to provide templates for the ar\u00adray invariants; and \n(ii) the abstract domain to perform under\u00adapproximations for the index variable. It can infer all the \ninvariants of our example, provided some re.nement in the handling of tran\u00adsition functions for quanti.ed \nfacts and in the under-approximation algorithm. Their technique uses uninterpreted functions and a guess \n&#38; prove cycle to determine precedents for guards. Unfor\u00adtunately, the abstract domain of uninterpreted \nfunctions exposes a double-exponential complexity [18], which seriously affects the analysis cost. According \nto [18, Sect.5.2], at best the quanti.ed domain induces a 70% slowdown of their analyzer, and at most \na 1800% slowdown (w.r.t. a normal run) on small examples. As a comparison, the functor abstract domain \npresented in this paper in\u00adduces a mere 1% slowdown with respect to a normal Clousot run on huge, production \nquality libraries (cf. Sect. 12), yet presenting a high precision. Deductive methods Program veri.ers \na la ESC/Java 2 [5] or `Spec# [1] require the user to provide loop invariants. In our run\u00ad ning example, \nwe needed to provide a few extra-annotations (9 to be exact) to help both tools prove the assertions \nin the code. First we have to add the invariant on the content of SeedArray to every loop in the code. \nThen, we added the loop invariant num3 =-1 . i = 1 to Loop 1, j = 1 to Loop 2 and k = 1 to Loop 3. In \ngeneral, such program veri.ers are very powerful but the extra-annotations impose a burden that very \nfew professional programmers are will\u00ading to pay for. Furthermore, deductive veri.cation-based tools \ncan check the correctness of a program fragment (e.g. a method), but they cannot infer facts to be used \non larger pieces of code (e.g. class invariants to verify whole classes [26]). Theorem prover-based The \nmethod of Kov\u00b4acs and Voronkov [23] uses a saturation theorem prover to generate loop invariants. The \nidea is to encode the changes to an array at the i-th iteration as a quanti.ed fact and then to systematically \napply resolution to derive a closed form (one not mentioning the loop iteration i). A prob\u00adlem with such \na technique is termination, for instance to determine when the right loop invariant has been produced \nby a satura\u00adtion step. This may require a human help (stopping the saturation process when a postcondition \ndoes not work: for instance if we remove the .rst assertion in Fig. 1, then the process may go on forever). \nFurthermore, their method is based on the use of mono\u00adtonic changes to the array (which is not the case \nfor Loop 1) and it requires a pre-analysis of indexes (causing an extra slow-down). The techniques of \nJhala and McMillan [20, 30] and of Seghir, Podelski and Wies [35] make use of the loop postconditions \nto be proven in order to infer the quanti.ed loop invariants. Suppose we remove (**) and (***) from the \nexample. Then their techniques (unlike ours) cannot infer the postcondition that all the elements of \nSeedArray are initialized to a value =-1 at the end of the Random constructor. In practice, such a postcondition \nis needed, for instance to prove that it is an object invariant for the class Random [26] and hence to \nprove the safety of the public methods. Furthermore, the techniques above do not always guarantee termination. \n The .uid updates technique of Dillig, Dillig and Aiken [12] is very expressive and it can be extended \nto precisely track complex containers properties [13]. It is exposed to a potential exponential explosion \ntoo. Theoretically, their technique is the lifting to the reduced cardinal power [8] of a points-to analysis. \nPractically, every time an array is accessed or created, the points-to edges are modi.ed, new constraints \nare added and calls to an SMT solver are issued to prove the (un-)feasibility of the edge(s) and simplify \nthe constraints. This may negatively in.uence the performance of the analysis and also affect the precision \n(whenever the expressions go out of the language treated by the SMT solver, as for instance the reminder \nin Fig. 1). Our Approach Our analysis infers all the invariants for Fig. 1 without user interaction: \nno templates, no annotations nor partitions are required, no hypotheses are done on the structure of \nthe source program. The invariants are inferred even if the assertions are removed from the code. The \ncode is analyzed in (a little bit less than) 60 milliseconds (50 milliseconds for reading the bytecode, \nperforming a stack analysis, heap analysis, non-null, and numerical analysis alone). The analysis is \nan instance of FunArray, which we introduce in this paper. FunArray is a functor abstract domain which \nlifts exist\u00ading analyses for scalar values to uniform compound data structures as arrays or collections. \nIn this paper we will concentrate on arrays, but it is immediate to see how the results generalize to \ncollections as found in mainstream object-oriented languages such as C# or Java as well as matrices when \ninstantiating the functor on itself. The FunArray analysis automatically divides the array into a sequence \nof possibly empty segments delimited by a set of seg\u00adment bounds. The content of each segment is uniformly \nabstracted. The array analysis can be combined via a reduced product with an abstraction for scalar variables. \nTherefore the FunArray has three main parameters: (i) the expressions used to describe the segment bounds; \n(ii) the abstract domain used to abstract the segment val\u00adues; and (iii) the abstract domain used to \nabstract scalar variables. When the three parameters above are chosen to be: (i) simple ex\u00adpressions \nin the form k or x + k where x is a variable and k is an integer [33]; (ii) and (iii) intervals [7] then \nfor Loop 1 our analy\u00adsis infers that all the values of the arrays with indexes in the range 1 ... 54 \nare greater or equal to -1, and that the last element of the array is not overwritten. The FunArray uses \nthe information to in\u00adfer the segmentation below, which is enough to prove the assertion (**) (values \nin brackets are bounds, intervals denote the abstrac\u00adtion for the array elements in the bounds, see Sect. \n4.3). {0} [-1,+oo] {55} [+oo,-oo] {56}. (1) For Loop 3, the analysis discovers that all the array elements, \nincluding the last one, have been overwritten with a value =-1: {0} [-1,+oo] {56}. (2) The loop invariant \nfor Loop 2 is then the union of the two in\u00advariants above, that is (1) as the .rst segmentation subsumes \nthe second one. If directly propagated after the loop, this invariant is too weak to prove the assertion \n(***). The imprecision is origi\u00adnated by the fact that we are not considering that the body of Loop 2 \nis executed at least once, so that SeedArray[55] is overwritten at least once (because of (1)). Standard \nstatic analysis techniques such as loop unrolling or backwards goal propagation [14, Sect. 6] can be \nused to recover the needed precision, and hence re.ne the abstract post-state of Loop 2 to (2). This \nhighlights another advan\u00ad tage of our analysis, which bene.ts for free of precision re.nement techniques \napplied to the analyzer. 3. Our Contribution The main advantages of our analysis can be summarized as: \n1. The array segmentation is automatically and semantically in\u00adferred during the analysis. By semantically, \nwe mean that the subdivision of the array is done during the analysis using seman\u00adtic information, unlike \nthe aforementioned approaches which de\u00adrive the partition by looking at the syntactic structure of the \npro\u00adgram. The segments are consecutive, without holes (a hole being just another segment). The segments \nderive from the way array elements are modi.ed and accessed. Segments are delimited by bounds, in increasing \norder, denoted by sets of simple symbolic expressions with equal but unknown values; 2. The combinatorial \nexplosion in the handling of disjunctions is avoided by considering symbolic segment bounds as well as \npossibly empty segments; 3. The relations between array indexes and array elements can be inferred by \nabstracting pairs made of the array index and the value of the corresponding array element (vs. abstracting \narray element values only); 4. The precision/cost ratio in the abstraction of the array content can \nbe .nely tuned using a functor abstract domain: the array content analysis is parameterized by the abstract \ndomain repre\u00adsenting symbolic segment bound expressions, the abstract do\u00admain abstracting the pairs (index, \nvalue) in segments, the ab\u00adstract domain assigning values to segment bound expressions, and the reduction \nbetween those domains. 5. By instantiating the array segmentation abstract domains functor with different \nabstract domains, different static analyzers can be automatically generated with different cost/precision \nratios allowing the cost versus precision tradeoff of the analysis to be tuned depending on the target \napplication at no re-programming cost of the static analyzer.  We have .rst implemented our technique \nin a research proto\u00adtype Arrayal, to quickly experiment with the algorithms and ad\u00adjust the abstractions. \nThen we fully implemented it in Clousot, an industrial-quality static contract checker for .NET based \non ab\u00adstract interpretation. The functor abstract domain enabled a natural lifting of the abstract domains, \nalready present in Clousot, to ar\u00adray contents. To the users, this is exposed as a simple checkbox in \nthe development environment. We validated the precision of the analysis by using it to check its own \nimplementation. The analy\u00adsis is extremely fast: we estimated the cost of the array analysis on Clousot \nto be less than 1% of the total running time when running it on production code (Sect. 12). To the best \nof knowledge, this is the .rst analysis of this kind applied to such a large scale. 4. Array Initialization \nWe explain the details of our technique on the initialization exam\u00adple of Fig. 2, slightly more general \nthan Loop 3. We illustrate how we avoid the combinatorial explosion on the partial initialization example \nof Fig. 3 and on the array rearrangement example of Fig. 4. 4.1 Manual proof A manual proof of the exit \nspeci.cation would involve a loop invariant at program point 2 stating that if A.Length =0 then i =0 \nand the array A is empty or else A.Length ? 1 in which case either i =0 and the array A is not initialized \nor else i > 0  void Init(int[] A) { /*0:*/ inti=0; /* 1: */ while /* 2: */ (i < A.Length) { /*3:*/ A[i]=0; \n/*4:*/ i=i+1; /*5:*/ } /*6:*/ } Figure 2. The fully initialized example. We want to prove that .i . [0, \nA.Length): A[i]=0 at program point 6. so that A[0] = A[1] = ... = A[i - 1] =0. Formally the invariant \n(A.Length =0 . i = 0) . (A.Length ? 1 . 0 : i : A.Length ..j . [0, i): A[j] = 0) holds at point 2 (1). \nThis invariant shows that array content analyses must be able to: (i) express disjunctions of array descriptions; \n(ii) express properties of array segments (that is sequences of values of consecutive array elements); \nand (iii) relate the symbolic limits 0, i-1, A.Length-1 of these segments to the scalar program variables. \n 4.2 Automatic proof and the meaning of the abstract invariant predicates In our array segmentation \nanalysis instantiated e.g. with constant propagation [22], we automatically get the abstract invariant \npredi\u00ad cates p1 = A: {0 i} T {A.Length}? p2 = A: {0} 0 {i}? T {A.Length}? p6 = A: {0} 0 {A.Length i}? \n where pi is the abstract invariant predicate at program point i = 1,..., 6. In this example the properties \nof scalar variables need not be used. The abstract values for constant propagation can be | (i.e., bottom \n., meaning unreachable), an integer constant (mean\u00ading equal to that constant), or T (i.e., top T, meaning \nunknown). In the array environments such as A: {0i} T {A.Length}? in p1, each array of the program (such \nas A) has its content de\u00adscribed by a segmentation (such as {0i} T {A.Length}?). From the symbolic segment \nbounds such as {0i} and {A.Length}? we know that i =0 (since all expressions in a bound are equal) and \nthat 0= i : A.Length (since the segment bounds are in increas\u00ading order, strictly increasing in absence \nof ?). The segments are not empty, except if the upper bound of the segment is marked with ?. The segments \nare consecutive without holes, since a hole can al\u00adways be represented by a T segment (possibly empty \nif the hole may or may not be absent). Each segment uniformly describes the array elements within that \nsegment bounds, lower bound included, upper bound excluded. In {0i} T {A.Length}?, the array ele\u00adment \nabstract value is T, meaning in the constant propagation anal\u00adysis, that the array values are unknown \n(T). So the invariant p1 states that i =0 : A.Length ..j . [0, A.Length): A[j] . Z. In particular, when \ni = A.Length =0, the interval [0, A.Length) is empty, so the quanti.ed expression holds vacuously. The \ninvariant p2 states that 0 : i : A.Length (in ab\u00adsence of question marks ? these inequalities would be \nstrict), that A[0] = A[1] = ... = A[i - 1] =0 when i > 0 and that the values A[i], A[i +1], ..., A[A.Length \n- 1] are unknown when A.Length > i. So the array is divided into consecutive non\u00adoverlapping segments, \nwhich may be empty and are delimited by symbolic expressions in increasing order. The abstraction of \nthe ar\u00adray elements within one segment is uniform but different segments can have different abstract \nproperties. (1) This invariant can also be written 0 : i : A.Length ..j . [0, i): A[j] =0 with the convention \nthat [0, -1] = \u00d8 is the empty set in which case A[j] is not evaluated, which is made explicit by a disjunction \nof cases (marked ? in segmentation bounds). In order to avoid combinatorial explosion, disjunctions ap\u00adpear \nin restricted form only either as possible segment empti\u00adness, or symbolic bounds which may have different \nvalues, or in the segment content analysis (see Sect. 11.1). For example, the post-condition p6 expresses \nthat either the array is empty (i.e. A.Length = i =0) or else A.Length = i > 0 and all array elements \nare initialized to 0. Please note that the case A.Length < 0 is excluded. This comes from the initial \ncondition stating that A.Length ? 0 since most programming languages like C, C# and Java do not allow \narrays of negative size. We handle all such runtime errors including division by zero, index out of bounds, \n. . . by stopping execution. This is a sound treatment of their unde.ned semantics in absence of runtime \nerrors but may otherwise miss some other possible erroneous executions (following from the fact that \nexecution goes on in practice with an unde.ned semantics).  4.3 Detailed unreeling of the initialization \nexample analysis We now consider the details of the analysis of the code of Fig. 2 with constant propagation. \nThe initial condition A.Length ? 0 is recorded in the segmentation of array A. p0 = A: {0} T {A.Length}? \nThe assignment i =0; sets the value of the scalar variable i to 0. The equality i=0 is valid after the \nassignment and so is recorded in the lower bound of the array segment. Initially p2 = p3 = ... = p5 = \n. denotes unreachability of the loop so that the abstract loop invariant is initially p2 = p1 U p5 = \np1 (using the join U in the constant abstract domain for segments: x U. = .U x = x, x UT = TU x = T, \ni U i = i, and i U j = T when i= j). p2 = p1 = p0[i=0] = A: {0 i} T {A.Length}? The loop is entered when \ni < A.Length so that the array, hence its only segment, cannot be empty so ? is dropped: p3 = p2[i<A.Length] \n= A: {0 i} T {A.Length} The analysis of the array assignment A[i] = 0; splits the array segment around \nthe index i and assigns to the array element the value of expression 0 in the constant domain that is \n0: p4 = p3[A[i]=0] = A: {0 i} 0 {1 i+1} T {A.Length}? Please note that the segment i ... i+1 is de.nitely \nnot empty while the segment i+1 ... A.Length may be empty. The scalar variable assignment i =i +1; is \ninvertible since the old value of i is the new value of variable i decremented by 1. So the segment bounds \ninvolving variable i have to be modi.ed accordingly: p5 = p4[i=i+1] = A: {0 i-1} 0 {1 i} T {A.Length}? \nThe next approximation of the loop invariant is p2 = p1 U p5. This join .rst involves the uni.cation \nof the segment {0 i}T{A.Length}of p1 and that {0 i - 1}0{1 i}T{A.Length}? of p5. Keep\u00ading only the expressions \nappearing in both segmentations, we get {0 i}T{A.Length} and {0}0{i}T{A.Length}?. Split\u00adting the bound \n{0 i} we get {0}.{i}?T{A.Length} so that the union with {0}0{i}T{A.Length}? can now be performed segmentwise \nin the constant domain {0}. U 0{i}(? Y )TU T{A.Length}( Y?) = {0}0{i}?T{A.Length}? since the seg\u00adments \nmay be empty in at least one of the cases (that is Y = for non-empty segments and otherwise Y ?=? Y =? \nY ?=? for possibly empty ones). We get p2 = p1 U p5 = A: {0} 0 {i}? T {A.Length}? The next iteration \nis similar: p3 = p2[i<A.Length] = A: {0} 0 {i}? T {A.Length} p4 = p3[A[i]=0] = A: {0} 0 {i}? 0 {i+1} \nT {A.Length}? p5 = p4[i=i+1] = A: {0} 0 {i-1}? 0 {i} T {A.Length}? p2 = p1 U p5 = A: {0} 0 {i}? T {A.Length}? \n void InitPartial(int[] A, int[] C) { Contract.Requires(A.Length == C.Length); inti= 0,j=0; while (i \n< A.Length) { if (p(A[i])) // For some predicate p C[j++] = 1; i++; }} Figure 3. Partial array initialization. \nPartition-based techniques use four partitions encoding the fact that at loop exit C may be empty, partially \n.lled, almost-totally .lled or totally .lled. Our analysis: (i) compactly represents the same information \nwith only one segmentation; and (ii) infers the segmentation automatically. so that we have reached a \n.xpoint. It remains to compute p6 = p2[i>=A.Length] = A: {0} 0 {A.Length,i}? where A.Length = i since \nthe segmentation of p2 provides the information that 0 : i : A.Length. The array content analysis always \nterminates since the only two reasons for non-termination are impossible: 1. The array might have in.nitely \nmany symbolic segments as in {0} ... ... {n-3} ... {n-2} ... {n-1} ... {n} which is prevented by segmentation \nuni.cation and widening; 2. A segment might take successive strictly increasing abstract values which \nis prevented by the use of a widening/narrowing convergence acceleration for segment content analysis \n[7]. No widening was necessary for constant propagation which satis.es the ascending chain condition \n(. c i c T, i . Z).  4.4 Partial Array Initialization Full array initialization is a very well studied \nexample, and array\u00adpartitioning techniques perform reasonably well on it [17, 19]. However, partial array \ninitialization (Fig. 3) illustrates the multipli\u00ad cation of partitions which makes those techniques not-scalable. \nAt the end of the loop, our analysis (instantiated with constant propa\u00adgation) infers the following segmentation \nfor C: {0} 1 {j}? T {i,A.Length,C.Length}? which compactly captures the fact that C may be empty (when \n0= j = i), may be not initialized (when j =0), may be partially initialized (when 0 < j < i), may be \nfully initialized (when 0 < j = i). Compare it with partition-based approaches where the abstract state \nat the end of the loop contains four disjuncts: one representing the concrete state when none of the \nC elements is initialized (j = 0), two representing the partial initialization of C distinguishing when \nj+1 < C.Length or j < C.Length, and one representing the total initialization (j == C.Length) ([17, 7.2]). \nWe tried this example using our early implementation of [19] and we got a 2\u00d7 slow-down with respect to \na normal run of Clousot (it is worth noting that the experimental results reported in [17] and those \nin [18] are even worse than our .rst implementation). For this example, Clousot lifted with the functor \nabstract domain was so fast that we were unable to measure its impact on the performances: the additional \ncost is in the order of magnitude the noise of the virtual machine (JIT, garbage collector . . . ) i.e. \nfew milliseconds.  4.5 Array in-situ rearrangement example The in-situ array rearrangement algorithm \nof Fig. 4 [4, 23] maintains an invariant void Rearrangement(int[] A) { Contract.Requires(A.length > \n1); Contract.Requires(Contract.Forall(0,A.length, i => (-100 <= A[i] &#38;&#38; A[i] <= 100))); int a \n= 0, b = A.length; /*1:*/ while/*2:*/(a<b){ /*3:*/ ifA[a]>= 0then{ /*4:*/ a=a+1; /*5:*/ }else{ /*6:*/ \nb=b-1; /* 7: */ int x = A[a]; A[a] = A[b]; A[b] = x; /*8:*/ }} /*9:*/ } Figure 4. The array in-situ rearrangement \nexample. where positive numbers are on the left of a, the negative numbers are on the right, from b included, \nand in the middle, between a and b - 1 the numbers remain to be handled. If A[a] is positive, the limit \na is moved to the right. Otherwise, A[a] is exchanged with A[b-1] and b is moved to the left. The algorithm \nterminates when the central zone is empty. This invariant which is automatically inferred by the automatic \narray segmentation analysis illustrates the interest of using possibly empty segments: p1 = (A: {0 a} \n[-100,100] {b A.length} a:[0,0] b:[2,+oo] A.length:[2,+oo]) p2 = (A: {0}[0,100]{a}?[-100,100]{b}?[-100,-1]{A.length}? \na:[0,+oo] b:[0,+oo] A.length:[2,+oo]) p9 = (A: {0} [0,100] {b a}? [-100,-1] {A.length}? a:[0,+oo] b:[0,+oo] \nA.length:[2,+oo]) 5. Abstract Domains and Functors An abstract domain D includes a set D of abstract \nproperties as well as abstract functions and operations D.op for the partial order structure of abstract \nproperties (.), the join (U), the meet (n), convergence acceleration operators: widening (V) and narrowing \n(L), the abstract property transformers involved in the de.nition of the semantics of the programming \nlanguage: the abstract evaluation of program arithmetic and Boolean expressions, the assignment to scalar \nvariables . . . [7]. A monotonic concretization function . provides the meaning of abstract properties \nin terms of concrete properties. An abstract domain functor D is a function from the pa\u00adrameter abstract \ndomains D1,..., Dn to a new abstract domain D(D1,..., Dn). The term functor is mutated from OCaml ter\u00adminology. \nThe formal parameters D1,..., Dn of the abstract do\u00admain functor D can be instantiated to various actual \nabstract do\u00admains without needing to rewrite the code of the static analyzer. So various abstractions \ncan be experimented at no programming cost. The abstract domain functor D(D1,..., Dn) composes ab\u00adstract \nproperties D1,..., Dn of the parameter abstract domains D1,..., Dn to build a new class of abstract properties \nD (e.g. abstract environments mapping program numerical variables to in\u00adtervals) and operations (e.g. \nassignment of an interval to a variable). For short, we can omit the parameters writing D or op when \nthe parameters D1,..., Dn are clear from the context. 6. Concrete Semantics We describe the elements \nof the semantics of programming lan\u00adguages to which our array content analysis does apply, that is scalar \nvariables, simple expressions, and unidimensional arrays and cor\u00adresponding assignments. 6.1 Scalar Variables \nSemantics The operational semantics of scalar variables with basic types (bool, char, int, float, etc.) \nis assumed to be concrete variable environments . .Rv mapping variable names i . Xto their values .(i) \n.V so that Rv \u00a3 X .  V. In the following we let A.Length . Xbe the name denoting the length of the array \nA. 6.2 Simple Expressions Semantics The program simple ex\u00adpressions e . E containing only constant, scalar \nvariables, and mathematical unary and binary operators have a semantics [e]. in the concrete variable \nenvironment . so that [e] .Rv .V. For simplicity, the values in our examples are chosen to be inte\u00adgers \n(so V = Z). The semantics of scalar variable assignment is as usual [i := e]. \u00a3 .[i := [e].] where .[i \n:= v](i)= v and .[i := v](j)= .(j) when j = i. 6.3 Unidimensional Arrays Semantics The operational seman\u00adtics \nof array variables (such as A . A) are concrete array envi\u00adronments . .Ra mapping array names A . A to \ntheir values .(A) .A \u00a3 Rv \u00d7 E\u00d7 E\u00d7 (Z . (Z\u00d7V)) so that Ra \u00a3 A .A. In order to be able to relate array \nelement values to their indexes, we assume that the concrete value of an array A is a quadruple a =(., \nA.low, A.high,A) .A, where: . .Rv is a scalar variable environment (Sect. 6.1);  A.low . E is an expression \n(0 in our examples) which value [A.low]. evaluated in the variable environment . yields the integer lower \nbound of the array;  A.high . E(A.Length in our examples) is an expression which value [A.high]. evaluated \nin the variable environment . yields the integer upper bound of the array;  A maps an index i . [[A.low]., \n[A.high].) to a pair A(i)= (i, v) of the index i and the corresponding array element value v.  The instrumented \nsemantics of arrays makes explicit the fact that arrays relate indexes to indexed element values by considering \nar\u00adray elements to be a pair of an index and an array element value. This instrumented semantics is in \ncontrast with the classical se\u00admantics a . [e, h) .V of arrays mapping indexes in [e, h) to ar\u00adray element \nvalues in V. The explicit inclusion of the array bounds is useful to handle arrays of parametric length \nsuch as JavaScript arrays or collections in managed languages. Nevertheless, the ex\u00adamples here consider \narrays of .xed length, maybe unknown, with A.low = 0. The inclusion of the concrete variable environment \nis also necessary to explain segments (which are sub-arrays whose bounds may symbolically coincide at \ndifferent program points al\u00adthough they may take different concrete values over time, so that the length \nof the segment can vary during execution as shown e.g. in Sect. 4.3 by p1 and p5). The semantics of an \narray element access A[e] is classical. The expression e is evaluated to an index i. The array variable \nA is evaluated to its array value a =(., A.low, A.high,A) where . is the concrete variable environment. \nIt is a buffer overrun runtime error if i< [A.low]. or [A.high]. : i, in which case the value of A[i] \nis unde.ned so that program execution is assumed to stop. Otherwise the index is in-bounds so A(i)=(i, \nv) is well-de.ned and v is the value, in the classical sense, of the array element A[e]. Obviously storing \n(i, v) instead of v is useless but for the fact that the instrumented semantics can be used to make the \narray content analysis more precise. Example 1 Let us consider the initialization example of Fig. 2 with \nthe additional assumption that A.Length > 1. At program point 6 the .nal values of the scalar variables \nare given by .6 such that .6(i)= .6(A.Length)= n where n> 1 is the unknown array length. The .nal value \nof A is a6 =(.6, 0, A.Length,A6) with A6(i)=(i, 0) for all i . [0,n). Because .6, 0, and A.Length are \neasily understood from the context, we write A[i] =(i, 0) by abuse of notation where the value i of i \nis assumed to be in-bounds. nU In the analysis of the example of Fig. 2, the pair A[i] =(i, v) was .rst \nabstracted to v, which is the case for all non-relational ab\u00adstract domains such as constant propagation \nwhich cannot establish a relation between the index i and the array element value v. Array properties \nare sets of concrete array values and so belong to P(A) (relations between array values are thus abstracted \naway). We have no hypotheses on expressions but Z . E and X . E so that the expressions used in segment \nbounds can at least be integer constants or scalar variables, which is necessary in most programming \nlanguages to express bounds. 7. The Variable and Expression Abstract Domains 7.1 Scalar variable abstraction \nWe let X be an abstract domain encoding program variables includ\u00ading a special variable v0 which value \nis assumed to be always zero so X = X.{v0} where v0 . X. Operations include the equality comparison of \nvariables. Properties and property transformers of concrete variable en\u00advironments in P(Rv) are abstracted \nby the variable environment abstract domain R(X) which depends on the variable abstract do\u00admain X (so \nthat R is an abstract domain functor). The abstract properties . .R are called abstract variable environments. \nThe concretization .v(.) denotes the set of concrete variable environ\u00adments having this abstract property. \nIt follows that .v .R . P(Rv). The static analysis of scalar variables may or may not be rela\u00adtional. \nFor non-relational abstractions, P(Rv) is .rst abstracted to X . P(V) and R \u00a3 X .V where the abstract \ndomain V ab\u00adstracts properties of values in V with concretization .v .V . P(V). 7.2 Expressions in simple \nnormal form The symbolic expressions appearing in segment bounds belong to the expression abstract domain \nE(X). The abstract properties E consist in a set of symbolic expressions depending on the vari\u00adables \nin X restricted to a canonical normal form plus the bottom expression . corresponding to unreachability \nand the top expres\u00adsion T abstracting all symbolic expressions which cannot be put in the considered \nnormal form. The array bound expressions are assumed to be converted in canonical normal form (e.g. via \naux\u00adiliary variables, so that ...A[B[i]]... becomes ...{int x; x := B[i]; A[x]}...). Different canonical \nforms for expressions correspond to different expression abstract domains E(X). In our examples, and \nin the Clousot implementation, the ab\u00adstract expressions E are restricted to the normal form v + k where \nv .X is an integer variable plus an integer constant k . Z(v0 + k represents the integer constant k). \nAn alternative example of con\u00advenient normal form would be linear expressions a.v + b where v is a variable \nand a, b . Z(a =0 for constants). 7.3 Concretization Given an abstract domain for scalar variables with \nconcretization .v .R . P(X . Z), the concretization .e(e). of an expression e .E depends on the abstract \nvalue . .R of the scalar variables in X and is the set of possible concrete values of the expression. \nSo .e .E . R . P(V) such that .e(.). \u00a3 \u00d8, .e(T). \u00a3 V, .e(v0 + i). \u00a3 {i}, and otherwise .e(v + i). \u00a3 {.(v)+ \ni | . . .v(.)}.  7.4 Abstract operations on expressions in simple normal form Simple operations are \nde.ned on symbolic expressions in normal form such as the check that an expression depends or not on \na given variable, or the substitution of an expression for a variable in an expression followed by its \nreduction in normal form, returning T if impossible.  Given two expressions in normal form, we must \nbe able to an\u00adswer the question of their equality and inequality, which in the ab\u00adstract is always true, \nfalse or unknown. These abstract equality and inequality tests of expressions may be more or less sophisticated. \nWe consider below three cases of increasing complexity, which one is chosen can be a parameter of the \nanalysis. Syntactic comparisons In their simplest form the comparisons can be purely syntactic. For example \nv + i = v + j is true if and only if v = v and i = j, false if v = v and i = j and unknown otherwise. \nSimilarly v + i< v + j is true if and only if v = v and i<j, false if v = v and i ? j and unknown otherwise. \nThe comparison of i and v + j where v = v0 always has an unknown result. This is very simple, rapid, \nbut rather imprecise. Variable comparisons An immediate re.nement consists in using the abstract information \n. .R available on scalar variables. This is always possible since the corresponding abstract domains, \nwhether relational or not, do have primitives to handle program conditional expressions. For example \nassume that R(X) is an interval analysis, .(v)= ' [a, b], and .(v )=[a,b']. The comparison v + i< v + \nj is true when v = v and i<j or v = v but (using the abstract ' variable environment) b + i< a+ j, false \nwhen v = v and i ? j or v = v but (using the abstract variable environment) b' +j : a +j and unknown \notherwise. Relational domains such as DBM [11] and Octagons [32] can directly answer such questions. \nIn that case the expression abstract domain E is an abstract domain functor E(X, R(X)) depending on the \nvariable abstract domain X and the variable environment abstract domain R(X). Please note that comparison \nof expressions e, e' .E must be done for all possible variable abstract domains R which requires all \nof them to share a common abstract interface for expression comparison. A reasonable choice is to translate \nthe comparison of normal expressions in E to that of program expressions which anyway have to be evaluated \nin the abstract using R. Segmentation-based comparisons The information in the array segmentation can \nbe used to symbolically compare expressions. 11 22 In fact a segmentation {e1 ... e 1 } ... {e1 ... e \n2 }[?2] ... mm nn 1 {e1 ... emn }[?n] maintains the information that e1 = ... = 12 2 nn e m1 : e1 = ... \n= e m2 : ... : e1 = ... = emn (where the i-th inequality is strict when [?i+1] is empty and not strict \nwhen [?i+1] is ?). In its simplest form, two expressions are known to be equal if they appear in the \nsame segment bound, unequal if they appear in different segment bounds of the same array (strictly when \nseparated by at least one ), and otherwise their comparison is unknown. More sophisticated algorithms \ncan be used depending on the allowed syntactic form of normal expressions. For example, in the case of \nexpressions of the restricted form v + i, i . Zwhere constant expressions are represented by the dis\u00adtinguished \nvariable v0 which value is assumed to always be zero, we can use Pratt s algorithm [33] to compare their \nsymbolic values. A graph matrix is constructed with an edge (v, v ) labelled i - j whenever v+i : v +j \n(respectively i-j+1 when v+i< v +j) is derived from a segmentation of some array. Equalities are rep\u00adresented \nby two inverse inequalities. Arcs between incomparable variables are marked +8 (including when i - j \nor i - j +1 over\u00ad.ows so that the relation is abstracted away). The Roy-Warshall-Floyd all-pairs shortest \npaths/transitive closure algorithm [34] is used to derive all possible comparisons derived by repeated \nappli\u00adcation of the transitivity of comparisons. A cycle (v, v) for a vari\u00adable v in the transitive closure \nmatrix means impossibility, that is unreachability in the concrete. A constraint v + k : v holds when \nthe label of arc (v, v ) is less than or equal to k in the transitive closure matrix. Another similar \nexample is Shostak algorithm [36] for com\u00adparison of linear expressions of the form a.v + b.v : c where \na, b, c . Z. 8. Segment Bounds Abstract Domain Functor The segment bound abstract domain functor B takes \nany of the ex\u00adpression abstract domains E discussed in Sect. 7.2 and produces an instantiated segment \nbound abstract domain B(E) whose abstract properties are sets of expressions B \u00a3 P(E \\{., T}). The empty \nset \u00d8 denotes unreachability while non-empty sets {e1 ... em}of expressions e1,...,em .E are all equivalent \nsymbolic deno\u00adtations of some concrete value (generally unknown in the abstract except when one of the \nei is a constant). 8.1 Concretization The concretization .b .B . P(Rv) of segment bounds is the set \nof scalar variables concrete environments . making the concrete values of all expressions in the set \nto be equal [e1]. = ... = em].. So .b(\u00d8)= \u00d8 and .b(S)= {. |.e, e . S : [e]. = [ e ].} where [e]. is the \nconcrete value of expression e in the concrete environment . (for example [v0 + c]. \u00a3 c and otherwise \n[v + c]. = .(v)+ c). When normal expressions and segment bounds are simpli.ed and compared in the context \nof variable abstract environments . .R (Sect. 7.4), the concretization can be chosen as .b .B . R . P(Rv) \nsuch that .b(S). = {. . .v(.) |.e, e . S : [e]. = [e ].}. 8.2 Abstract operations on segment bounds The \nsegment bound abstract domain operations include basic set operations (such as the empty and singleton \nconstructors, test for emptiness, inclusion, strict inclusion, and equality, union, intersec\u00adtion) as \nwell as a widening (when the normal form of expressions does not enforce the .niteness of the number \nof expressions which can all have the same concrete value). A simple widening limits the number of expressions \nthat can appear to a maximum given as a parameter of the analysis. In order to handle non-invertible \nassignments to scalar vari\u00adables, the segment bounds abstract domain B(E) has an operation that eliminates \nfrom a set of expressions all the expressions that contain a given variable (using the check provided \nby the expres\u00adsion domain parameter E in Sect. 7.4). Similarly, to handle invertible assignments to scalar \nvariables, an operation is available to substitute an expression for a variable in all expressions of \na set, a resulting expression being eliminated from the set when the expression domain parameter cannot \nput it in normal form. After a side-effect free assignment i=e; or an equality test i==e, we have i = \ne so e (e) can be added to a segment bound containing the expression e (i) provided the expression domain \nparameter E can put e (e) in normal form. Based on the comparison of expressions in sections Sect. 7.4 \nthe segment bounds abstract domain functor can compare sets of equal expressions. For example s<s' is \ntrue if there exists an expression e in s and expression e' in s' such that the expression ' domain parameter \nE can determine that e<e' is true. s<sis false if the expression domain parameter E can determine that \n' there exists e . s and e. s' such that e = e'. Otherwise the comparison s<s' has an unknown result. \n 9. Array Element Abstract Domain The array element abstract domain A abstracts properties of pairs \n(index, value of indexed array element). The concretization is .a . A . P(Z\u00d7V). Properties in P(Z \u00d7V) \nmay not or may be .rst abstracted to P(V) when we do not want to relate array element values to their \nindex. In the .rst case we have a relational analysis (e.g. in Sect. 11.1), in the second a non-relational \n(e.g. in Sect. 4.3). 10. Conversion between the Variable and Array Element Abstract Domains In general \nthe variable and array elements abstractions do differ so that a conversion from one to the other is \nneeded. A variable to array element abstract property conversion is in\u00advolved in an assignment A[i] = \ne; (handled as A[i] = (i,e);), while an array element to variable property conversion is required in \nan assignment x := A[i];, and no conversion is required in A[i] := A[j]; or i = j;. This is taken care \nof by a conversion abstract domain providing the two conversion functions. There\u00adfore, the analysis must \nbe parameterized by a conversion abstract domain functor C(A, R) which contains two conversion functions \nfrom variable abstract properties in R to abstract array elements properties in A and inversely. This \ndomain can also abstract (i,e) into e to get array content analyses not relating indexes to indexed array \nelements. 11. FunArray: The Array Segmentation Abstract Domain Functor The array segmentation abstract \ndomain S(B(E), A, R) abstracts a set of possible array contents by consecutive, non-overlapping segments \ncovering all array elements. The precision/cost ratio of the array segmentation analysis can be adjusted \nto a speci.c ap\u00adplication domain by changing the abstraction R of scalar variable environments (Sect. \n7.1), the normal form E of symbolic expres\u00adsions (Sect. 7.2), hence that of the segment bounds B(E) (Sect. \n8), the abstraction A of the abstract array elements (Sect. 9), as well as the various parameters of \nthese abstract domains (such are the degree of re.nement of expression comparison in E in Sect. 7.4, \nhence of segment bounds comparison of B(E) (Sect. 8.2) and the conversions (Sect. 10). 11.1 Examples \nof array segmentation functor instantiations To illustrate the possibility of relating the value of array \nelements to their index, let us consider the static analysis of intn =10, i=0; int[] A = new int[n]; \n /*1:*/ while/*2:*/(i<n){ /*3:*/ A[i]=0; /*4:*/ i=i+1: (3) /* 5: */ A[i] = -16; /*6:*/ i=i+1: /*7:*/ \n} /*8: */ typical of data transfer protocols where even and odd numbered packets contain data of different \ntypes e.g. [16, Sec. 6.6.3], [25]. We will combine parity (where | (i.e. .) is unreachable, o is odd, \ne is even, T (i.e. T) is unknown) and intervals. Example 2 The .rst abstraction is the reduced product \n[8] of par\u00ad ity and intervals where pairs of a parity and an interval denote the conjunction of both \nproperties (with a reduction e.g. of bounds by parity (such as (e,[0,9]) . (e,[0,8])) and parity for \nconstant intervals (such as (T,[1,1]) . (o,[1,1]))). In the following analysis of (3) this abstraction \nis used both for variables and ar\u00ad ray elements (hence ignoring their relationship to indexes since [(i, \ne)]. =(parity([e].), interval([e].))). p1 = (A: {0 i} (T, [-oo,+oo]) {n 10}, i: (e, [0,0]) n: (e, [10,10])) \np2 = (A: {0} (e, [-16,0]) {i}? (T, [-oo,+oo]) {n 10}? i: (e, [0,10]) n: (e, [10,10])) p8 = (A: {0} (e, \n[-16,0]) {n 10 i}  i: (e, [10,10]) n: (e, [10,10])) The analysis of i starts with the initial value \n(e,[0,0]) and is (e,[0,2]) after one iteration which is widened to (e,[0,+oo]) hence stable. The narrowing \nphase starts with the test i<n where n in [10, 10] so i is in (e,[0,9]) hence (e,[0,8]) by re\u00adduction \nthrough evenness. After one more iteration we get back (e,[0,10]) to narrow (e,[0,+oo]) which is (e,[0,10]) \nand is a .xpoint. nU Example 3 The second abstraction is the reduced cardinal power [8] of intervals \nby parity whose abstract properties have the form (o -> io,e -> ie) meaning that the interval is io (resp. \nie) when the parity is o (resp. e). In the following non-relational analysis of (3), we use the reduced \nproduct of parity and intervals for simple variables and the power of parity by interval for array elements \n(hence ignoring their relationship to indexes since [(i, e)]. maps parity([e].) to interval([e].)). For \nexample (o-> |,e-> [-16,0]) means that the indexed array elements must be even with value included between \n-16 and 0. p1 = (A: {0 i} (o -> [-oo,+oo],e -> [-oo,+oo]) {n 10}, i: (e, [0,0]) n: (e, [10,10])) p2 = \n(A: {0} (o -> _|_,e -> [-16,0]) {i}?, (o -> [-oo,+oo],e -> [-oo,+oo]) {n 10}?, i: (e, [0,10]) n: (e, \n[10,10])) p8 = (A: {0} (o -> _|_,e -> [-16,0]) {n i 10}, i: (e, [10,10]) n: (e, [10,10])) Observe that \nthe abstraction is more powerful but the result is exactly the same as in the above analysis in Ex. 1 \nusing the re\u00adduced product since (o -> | ,e -> [-16,0]) is exactly (e, [-16,0]) on array elements. nU \nExample 4 The third abstraction also uses the reduced cardinal power of intervals by parity, but this \ntime in a relational way for arrays thus relating the parity of an index to the interval of possible \nvariation of the corresponding element (so [(i, e)]. isa map of parity([i].) to interval([e].)). We get \np1 = (A: {0 i} (o -> [-oo,+oo],e -> [-oo,+oo]) {n 10}, i: (e, [0,0]) n: (e, [10,10])) p2 = (A: {0} (o \n-> [-16,-16],e -> [0,0]) {i}? (o -> [-oo,+oo],e -> [-oo,+oo]) {n 10}?, i: (e, [0,10]) n: (e, [10,10])) \np8 = (A: {0} (o -> [-16,-16],e -> [0,0]) {n 10 i}, i: (e, [10,10]) n: (e, [10,10])) so that the array \nelements with odd index are shown to be equal to -16 while those of even index are zero. nU 11.2 Abstract \nPredicates The array segmentation abstract predicates belong to S \u00a3 {(B\u00d7 A) \u00d7 (B\u00d7 A\u00d7{ , ?})k \u00d7 (B\u00d7{ , \n?}) | k ? 0} . {.} and have the form 11 222nn mm1 {e1 ... e 1} P1 {e1 ... e 2}[?] P2 ... Pn-1 {e ... \nemn}[?n] where the segment bounds {e1 i ... e i i }. B, i . [1,n], n> 1, are .nite mnon-empty sets \nof symbolic expressions in normal form eji .E as respectively considered in Sect. 8 and Sect. 7.2;  \nthe Pi.A are abstract predicates chosen in an abstract domain A denoting possible values of pairs (index, \nindexed array ele\u00adment) in a segment of Sect. 9; and   the optional question mark [?i] follows the \nupper bound of a segment. Its presence ? means that the segment might be empty. Its absence means that \nthe segment cannot be empty. Because this information is attached to the segment upper bound (which is \nalso the lower bound of the next segment), the lower bound {e11 ... e 1 1 } of the .rst segment never \nhas a question mark. ({ , ?}, ., m , ?, Y, A) is a complete lattice with -?. The symbolic expressions \ne ki .E in a given segment bound de\u00adpend on scalar variables but not on array elements hence A[A[i]] \nshould be handled as x=A[i]; A[x] so that the auxiliary vari\u00adable x can appear in a segment bound for \narray A. The consecutive segment bounds are in strictly increasing order in the concrete ex\u00adcept when \nfollowed by a question mark meaning that the preceding block may be empty. There is no hole between segments \n(since this hole can always be viewed as another segment whose properties are unknown). The .rst block \nlimit always contains an expression in normal form denoting the array lower bound while the last block \nalways contains an expression in normal form denoting the array upper bound. Within one block the abstraction \nis uniform (but can be relational, since the array semantics of Sect. 6.3 can relate the array value \nA[i] to the index i). A possible re.nement would be to introduce relationships between segment emptiness \nmarks (so as to express that in {0} 0{i}?T {n}? both segments cannot be si\u00admultaneously empty), which \nwe do not do for the sake of ef.ciency. 11.3 Concretization Given the concretizations .v .R . P(Rv) for \nthe variable ab\u00adstract domain and .a .A . P(Z \u00d7V) for the array elements abstract domain, the concretization \n.s of an abstract array segmen\u00adtation is an array property so .s .S . R . P (A). The concretization of \na segment BPB ' [?] is the set of arrays whose elements in the segment [B, B ' ) satisfy the abstract \nproperty P (< stands for < while <? stands for :): .s' (BPB ' [?]). \u00a3 '' ' {(., e, h, A) | . . .v(.) \n..e1, e2 . B : .e1, e2 . B : [e]. = [e1]. = [e2].<[?] [e ' 1]. = [e ' 2]. = [h]. . ' .i . [ [e1]., [e1]. \n) : A(i) . .a(P )} The concretization of an array segmentation B1P1B2[?2]P2 ... Pn-1Bn[?n] is the set \nof arrays whose elements in all segments [Bi,Bi+1), i =1,...,n-1 satisfy abstract property Pi and whose \nlower and upper bounds are respectively given by B1 and Bn. .s(B1P1B2[?2]P2 ...Pn-1Bn[?n]). \u00a3 n-1 ' \n{(., e, h, A) . -. (Bi Pi Bi+1[?i+1]). | s i=1 .e1 . B1 : [e1]. = [e]. ..en . Bn : [en]. = [h].} and \n.s(.)= \u00d8. 11.4 Segmentation uni.cation Given two segmentations with compatible extremal segment bounds \n(in general for the same array), the objective of segmentation uni.\u00adcation is to modify the two segmentations \nso that they coincide. By compatible we mean that the .rst (the last) segment bounds should have a non-empty \nintersection. In practice this is always the case as the .rst segment bound always contains 0 and the \nlast segment bound always contains the symbolic name for the array length (e.g., A.Length). On the best \nuni.cation The problem of segmentation uni.cation admits a partially ordered set of solutions, in general \nnot forming a lattice. The minimal elements, hence the least precise uni.cations are those where all \nthe segments are joined, and only the extremes are preserved. Example 5 Let a and b be distinct variables. \nWhen unifying {0}...{ab} with {0}...{abc}, both segmentations {0}...{a}and {0}...{b} are minimal solutions, \nbut not comparable. nU The maximal elements, hence the most precise uni.cations are the coarsest common \nre.nements of both segmentations. Example 6 When unifying {0}...{a}...{b}...{c} with {0}...{b}...{a}...{c} \nboth segmentations {0}...{a}...{c} and {0}...{b}... {c} are maximal , but not comparable solutions. nU \nIn general, a solution is such that the bounds: (i) do appear in one or the other initial segmentation; \nand (ii) preserve the original orderings. One segment can be empty in one segmentation (like {0i}) and \nnon-empty in the other one (like {0}P {1,i}). Therefore segmentation must include the splitting of empty \nsegments (like {0i}.{0}P ' {i}?). Such an empty segment splitting is used in the comparison/join/meet/widening/narrowing \nof segments (which are not all commutative) so that the abstract value P ' of the created empty segment \nmust be chosen as the left/right neutral element of the considered operation (e.g. P ' is . for join, \nT for meet, . on the left and T on the right of the partial order ). The segmentations involved in a \nuni.cation are usually related to different program contexts: Example 7 Assume we want to unify {0 i-1}P1{i} \nand {0 i-2}P2{i} (obviously in two different contexts). The coars\u00adest common re.nement is {i-2}.{0}.{i-1}?P1{i} \nfor {0, i-1}P1{i} and {i-2}.{0}?P2{i-1}P2{i} for {0,i-2}P2{i} (which would yield the join {i-2}.{0}?P2{i-1}?P1 \n. P2{i}). However, it might be the case that i < 2 from the abstract variable environment, in which case \nthe expression i-2 in the lower bound of the .rst re.ned segmentation is unde.ned. nU Therefore, the \nwell-de.nedness of the coarsest common re.ne\u00adment, if any, depends upon the abstract variable environment, \ntoo. To sum up, we want the array segmentation analysis: (i) to have the possibility of being completely \nindependent of the variable analysis (see Sect. 11.7); (ii) to have a deterministic behavior in presence \nof several maximal common re.nements. Therefore we present a segmentation uni.cation which does not provide \nany guarantee on the maximality of the result, but instead one which: (i) is always well-de.ned in absence \nof knowledge of the contexts of the segmentations; (ii) does terminate; (iii) is deterministic. The segmentation \nuni.cation algorithm The .rst step of the al\u00adgorithm is checking the compatibility of the two input segmenta\u00adtions \nto verify that they do have common lower and upper bounds. Then, the uni.cation proceeds recursively \nfrom left to right and maintains the invariant that the left part is already uni.ed. We let .TrTl (resp. \n.) denote the left (resp. right) neutral element. 1. B[?1] P1 B1' [?1' ] ... and B[?2] P2 B2' [?2' ] \n... have same lower bounds and so keep the .rst segments as they are and go on with B1' [? ' 1] ... and \nB2' [?2' ] .... 2. In case (B .B1)[?1] P1 B1' [?1' ] ... and B[?2] P2 B2' [?2' ] ... with B1 = \u00d8 and \nB n B1 = \u00d8, let B1 be the set of expressions in B1 appearing in the second segmentation blocks B2' ,.... \n 2.1 If B1 is empty then go on with B[?1] P1 B1' [?1' ] ... and B[?2] P2 B2' [? ' 2] ... following case \n1. 2.2 Otherwise go on with B[?1] .Tl B1? P1 B1' [? ' 1] ... and B[?2] P2 B2' [? ' 2] ... as in case \n1. 3. The symmetrical case is similar. 4. In case (B.B1)[?1]P1B1' [?1' ] ... and (B.B2)[?2]P2B2' [?2' \n] ... with B1,B2 = \u00d8 and B n B1 = B n B2 = \u00d8, let B1 (resp.   B2) be the set of expressions in B1 (resp. \nB2) appearing in the second (resp. .rst) segmentation blocks B2' ,... (B1' ,...). 4.1 If B1 and B2 are \nboth empty, go on with B[?1]P1 B1' [? ' 1] ... and B[?2] P2 B2' [? ' 2] ... as in case 1. 4.2 Else if \nB1 is empty (so that B2 is not empty) then go on with B[?1] P1 B1' [? ' Tr B2? P2 B ' 2] ... 1] ... and \nB[?2] .2[? ' (where .is the right neutral element). Tr 4.3 The symmetrical case is similar. 4.4 Finally \nif B1 and B2 are both non-empty then go on with B[?1].1[? ' Tr B2?P2 B2' [?2' ] ... Tl B1?P1 B ' 1] ... \nand B[?2] . as in case 1. 5. In case B1[?1] P1 B1' [?1' ] ... and B2[?2] P2 B2' [? ' 2] ... with B1 n \nB2 = \u00d8, we cannot be on the .rst left segment block so we have on the left B0[?0] P0 B1[?1] P1 B1' [? \n' 1] ... and B '' 0[? ' 0] P0 B2[?2] P2 B2' [?2' ] ... and go on by merging these con\u00adsecutive blocks \nB0[?0] P0 U P1 B1' [?1A?1' ] ... and B0' [?0' ] P0 ' U P2 B2' [?2A? ' 2] .... 6. Finally, at the end \neither we are left with the right limits that have both been checked to be equal or else we have B1[?1] \nP1 B1' [? ' 1] and B2[?2] with B1 ' = B2. Because we have maintained the invariant that B1 is always \nequal to B2 in the concrete (so necessarily [? ' 1] =? since then B1 = B2 = B1' ), and so we end up with \n(B1 . B1 ' . B2)[?1] and (B1 . B1 ' . B2)[?2] Un Example 8 In the analysis of the example of Fig. 2, \nwe have to unify {0 i}T{n} and {0i-1} 0{1i}T{n}? which be\u00adcomes {0} . {i}? T {n} and {0}0 {1i}T{n}? by \n4.3 and we go on with {i}? T {n} and {1 i} T {n}? which, by the symmetric in 3 of 2.1 becomes {i}? T \n{n} and {i} T {n}? so we go on with {n} and {n}? which terminates the recursion by 6, thus returning \n{0}.{i}? T {n} and {0} 0 {i} T {n}?. Their array segmentation join is then {0} 0 {i}? T {n}? (taking \nthe disjunction Y of potential segment emptiness). nU The algorithm never adds any new expression to \nthe segment bounds nor increments the total number of segment bounds in splits and so does terminate. \nThe algorithm has a look-ahead of 1 (cf. case 5). It can be easily re.ned to provide a larger look\u00ad ahead \nat a price of an increased complexity. However, an advantage of the algorithm is that its behavior and \noutput are deterministic. For instance, in the Ex. 6 our algorithm returns the non-maximal segmentation \n{0}...{c}.A 2-look-ahead algorithm should make the choice between the two maximal solutions. In general, \nthe algorithm can be easily adapted and re.ned to take into account speci.c knowledge when comparing \nsegment bounds (for instance the total order induced by constants Sect. 12.2).  11.5 Partial order/join/meet/widening/narrowing \nFor an array segmentation join S.U,a (., .)-segmentation uni\u00ad.cation is performed and then the array \nelement abstract domain join A.U is applied segmentwise. For the meet S.n,a (T, T)\u00adsegmentation uni.cation \nis performed and then a segmentwise meet A.n. For the widening S.V,a (., .)-segmentation uni.cation is \nperformed and then a segmentwise widening A.V. Moreover, the widening merges consecutive segments with \nsame abstract value. Widenings could also be used to limit the size of segment bound sets and/or the \nnumber of segments given as parameters of the anal\u00adysis. For the narrowing S.L,a (T, T)-segmentation \nuni.cation is performed and then a segmentwise narrowing A.L. For the par\u00adtial order S. ,a (., T)-segmentation \nuni.cation is performed before returning the conjunction of the segmentwise comparisons A. . The potential \nsegment emptiness indications must also be taken into account, that is =  -?= ?.  11.6 Abstract Transfer \nFunctions Abstract value of an indexed array element Assume that we have to evaluate [A[e]]. for the \narray A abstracted by the segmentation B1P1B2[?2]P2 ...Pn-1Bn[?n]. The expression B1 : e : Bn is evaluated \nin the abstract and a warning is emitted if the result is unreachable (dead code), false (de.nite error) \nor unknown (poten\u00adtial error). Let Be be the largest segment bound such that Be : e is true (B1 otherwise) \nand Bh be the smallest segment bound such that e <Bh is true (Bn otherwise, assuming that execution goes \non only in absence of buffer overrun). The value of [A[e]]. is then h-1 k=e Pk where U is the join in \nthe domain A abstracting (index, value of indexed array element) pairs. A call to a conversion func\u00adtion \nof C is necessary if this abstract value in A must be converted to a variable abstract value in R. Assignment \nto an array element In an array element assignment A[e] = e with abstract variable environment . where \nthe array A is abstracted by the segmentation B1P1B2[?2]P2 ...Pn-1Bn[?n], we .rst determine the range \nof segments such that Be : e <Bh is de.nitely true. The segmentation of A can be thought of as being \nab\u00adstracted to B1P1 ...Be[?e](h-1 ]Ph ...Pn-1Bn[?n k=e Pk)Bh[? ' ] where [? ' ] is ? if all the [?e+1],..., \n[?h] are ? (so that the block Be ...Bh can then be empty) and otherwise. Of course it may happen that \nh = e +1 in which case only one segment is con\u00adcerned or e =1 and h = n in which case all segments are \nsmashed. In all cases, the assignment is de.nitely in the seg\u00adment Be ...Bh (may be at its borders). \nThis segment is split. Let P .A be the abstraction of the value of the pair (e, e ) in A. After the array \nelement assignment, the array segmen\u00adtation of A becomes B1P1 ...Be[?ek=e Pk){e}[?l]P {e ](h-1 + 1}(h-1 \nk=e Pk)Bh[?r]Ph ...Pn-1Bn[?n]. [?l] is ? unless the seg\u00adment bounds comparison discussed in Sect. 8.2 \ncan determine that Be < {e} is always true. Similarly, [?r] is when {e +1} <Bh for sure and ? otherwise. \nThere are special cases. When the index expression e or e+1 or both cannot be put in the normal form \nof E, we have to merge the corresponding segments, to get B1P1 ...Be[?e](P Uh-1 k=e Pk) Bh[? ' ]Ph ...Pn-1Bn[?n] \nin the worst case. This is the case of the assignment (*) in Fig. 1. If the segment bounds comparison \ncan determine that Be = {e} we get B1P1 ... (Be .{e})[?l]P {e + 1}(h-1 k=e Pk)Bh[?r]Ph ...Pn-1Bn[?n]. \nSimilarly if {e +1} = Bh for sure, we get B1P1 ...Be[?e](h-1 k=e Pk){e}[?l]P ({e+1}. Bh)Ph ...Pn-1Bn[?n]. \nTest of an array element A test c(A[e]) of an array element A[e] can be done by getting the abstract \nvalue of (i, v) of (e,A[e]) in A, restricting the abstract value (i, v) by restricting i to the array \nbounds (execution is assumed to stop in case of buffer overrun) and v to the test c(v), and assigning \nthe restricted value back to the array element A[e]. For a simpler uniform treatment of tests involving \nboth scalar variables and array elements, (i, v) in A can be converted to the variable abstract domain \nR and back after handling the test using C. Assumption for the content of an array For a statement in \nthe form of assume .i . [a, b).c(A[e]) (assuming a = b are within the array bounds): (i) we infer an \nabstract segment value as in the previous case (let us call it P); (ii) we abstract the bounds a, b in \nthe quanti.cation to their best possible approximation a, b in the bounds abstract domain; (iii) we materialize \nthe most generic abstract segmentation A: {0} T {a}? P {b}? T {A.Length}? and we use the scalar abstract \ndomain to get rid of some of the un\u00adcertainties. Finally the so-obtained abstract predicate is intersected \n(using the meet operation) with the abstract value in the pre-state of A. For example, using the abstract \ndomain of intervals:  /* (A: {0} T {A.Length}, k:[10,10], A.Length:[10, +oo]) */ assume forall i: [0, \nk) => A[i] >= 0; /* (A: {0} [0, +oo] {k} T {A.Length}?, ...) */ In fact, the materialized abstract segment \nis A: {0} T {0}? [0, +oo] {k}? T {A.Length}?, which can be reduced using the abstract domain of scalars \nto: A: {0} [0, +oo] {k} T {A.Length}? The constant zero is trivially equal to itself and k is positive \nbut it may be equal to the length of the array A. Finally the value in the pre-state of A is re.ned via \nthe meet operation. Invertible assignment to a scalar variable In an invertible assign\u00adment to a scalar \nvariable x = f(x,yy) where y = y1,..., ym, we have xnew = f(xold,y ), where f is the value of f, xold \ndenotes the value of the variable x before assignment, xnew denotes the value of the variable x after \nassignment, f has no side effect so the val\u00ad f-1 ues y of the variables y are not changed, and xold =(xnew,y \n). For such an invertible assignment, all occurrences of the variable x in the expressions in the segment \nbounds must be replaced by the expression f-1(x,y ) and the resulting expressions simpli.ed into canonical \nnormal form, if any, and dropped otherwise. In case a segment bound becomes empty because normalization \nis impossi\u00adble, the two adjacent segments must be joined. For the example in Fig. 2, we have: /* (A: \n{0} 0 {i}? 0 {i+1} T {n}?, ...) */ i =i +1; /* (A: {0} 0 {i-1}? 0 {i} T {n}?, ...) */ Non-invertible \nassignment to a scalar variable In a non invert\u00adible assignment x = f(x,y ), no inverse xold = f-1(xnew,y \n) is available, for example in x = f (y ). For such a non invertible as\u00adsignment x = e, all expressions \nin the segment bounds containing occurrences of the variable x must be eliminated from these seg\u00adment \nbounds. In case a segment bound becomes empty, the two adjacent segments must be joined. Then the variable \nx and expres\u00adsion e are added to the segment bound containing an expression e ' such that [e ' == e]. \nis de.nitely true in the abstract. In the simple purely syntactic case of Sect. 7.4, [e ' == e]. = true \nis under\u00adapproximated by e ' = e so that x is added to all segment bounds containing e. For the example \nof Fig. 2 we have: /* (A: {0}T{n}?,i:T n:T) */ i = 0; /* (A: {0 i} T{n}?, i: 0n:T )*/ f-1 In case of \nan assignment x = f(y ), x . y where yi = i (xnew, y1,...,yi-1,yi+1,...,ym) is available, the expression \ne(fi -1(xnew, y1, ..., yi-1, yi+1, ..., ym)) can be added to all segment bounds containing an expression \ne(yi) whenever simpli.cation in canoni\u00adcal normal form is possible. For example: /* (A: {0} 0 {i+5 j+7} \nT {10 n}, ...) */ i = j -7; /* (A: {0} 0 {i+14 j+7} T {10 n}, ...) */ Comparison of scalar variable expressions \nThe equality com\u00adparison e = e (where e and e have equivalent normal forms) to\u00adgether with the segment \nbounds comparison discussed in Sect. 8.2 that may be able to determine that e = Bi(2) is always true \nwill add e and e to Bi. Moreover, if e = Bj for sure and i<j then the segmentation B1P1B2[?2]P2 ...Pn-1Bn[?n] \nwill be reduced to B1P1B2[?2]P2 ...Pi-1(Bi . Bi+1 . ... . Bj . {e, e })[?i]Pj ...Pn-1Bn[?n] or to unreachability \nwhen one of '' (2) Recall that e = B is .e . B : e = e . InitBackwards(int[] A) { int i = A.Length; /*1:*/ \nwhile/*2: */(0<i){ /*3:*/ i=i-1; /*4:*/ A[i]=0; /*5:*/ } /*6:*/ } Figure 5. Example of a backwards initialization. \nArray segmen\u00adtation reduction is needed to prove the postcondition .j . [0, A.Length). A[j]=0. the [?i+1], \n..., [?j ] is (since then e < e ). The comparison e : e has the same effect when j<i or when e < e and \ni = j. Otherwise disequality e <> e and strict inequality e < e with e = Bi and e = Bi+1 can be used \nto remove a doubt ? on the possible emptiness of a segment BiPiBi+1? which becomes BiPiBi+1.  11.7 Array \nsegmentation reduction A program analysis is the product of a segmentation analysis for arrays and the \nanalysis of scalar variables. The two analyses can be completely independent which is an important feature \nfor the array segmentation analysis to be easily inserted in any analyzer without having to make any \nhypothesis on the static analyzer. The consequence is that the result may not be as precise as possible. \nLet us illustrate this phenomenon on the program of Fig. 5. Using the independent product of interval \nabstractions for array elements and scalar variables, the post condition derived by the static analyzer \nwith Sect. 7.4 at program point 6 is (A: {0} [-oo,+oo] {i}? [0,0] {A.Length}?, i: [0,0] A.Length: [2,+oo]) \nIt states that it is possible that i = 0 but the array segmenta\u00adtion analysis cannot prove that this \nis indeed always the case. It is in general always more precise to consider the reduced prod\u00aduct of the \narray and variable analyses [8]. This consists in iter\u00adating reduction operators that propagate information \nfor one ab\u00adstract domain to the other. For example it may be useful to prop\u00adagate the relational information \nof array segmentation (equality of expressions in a segment bounds and segment bounds in increas\u00ading \norder (strictly increasing in absence of ?)), unless a more pre\u00adcise relational domain is already used \nfor scalar variables. In the other direction, the information provided by the scalar variable analysis \ncan be propagated to segmentations. A possibly empty segment ...B[?] PB ' ? ... can be reduced to a non-empty \none ...B[?] PB ' ... if the scalar variables environment . implies .e . B : .e ' . B ' : [e].< [e ' ]. \nis always true in the ab\u00adstract (the abstract test returning either ., true, false, or unknown). Similarly, \na possibly empty segment ...B[?]PB ' ? ... may be def\u00adinitely empty and reduced to the bound ... (B . \nB ' )[?] ... when .e . B : .e ' . B ' : [e]. = [e ' ]. = true. In the reduction example of Fig. 5, the \nfact that i . [0, 0] implies that the segment {0} [-oo,+oo] {i} is empty, in which case the reduction \nautomatically yields (A: {0 i} [0,0] {A.Length}, i: [0,0] A.Length: [2,+oo]) which is exactly the expected \nresult at program point 6. 12. Implementation 12.1 CodeContracts and Clousot CodeContracts allow the \nlanguage-agnostic speci.cation of con\u00adtracts (preconditions, postconditions and object-invariants [3, \n31]).  The CodeContracts API is included in .NET starting from v4.0. Clousot is an abstract interpretation-based \nstatic analyzer devel\u00adoped at MSR Redmond used to statically check: (i) contracts; and (ii) the absence \nof common runtime errors such as non-null deref\u00aderences or buffer overruns. Clousot is used both inside \nand out\u00adside Microsoft on large production projects. When a method is an\u00adalyzed, its preconditions is \nturned into an assumption and its post\u00adcondition into an assertion. For each method call appearing in \nthe method body, its precondition is turned into an assertion and the postcondition into an assumption. \nObject-invariants are assumed at the entry of public methods and asserted at the exit point (a detailed \ndescription of the object-invariants treatment is out-of-the scope of this paper). Further assertions \nare generated from the body text: e.g. when an array is accessed the indexing expression is better being \nin bounds. Clousot analyzes the bytecode, which presents several advantages (independence from the compiler, \nthe language, the language version . . . ), but also some drawbacks (lack of pro\u00adgram structure . . . \n) [27]. After reading the bytecode, extracting the contracts, creating the control .ow graph, and simplifying \nthe program, a heap analysis is run so to resolve aliasing, and the pro\u00adgram is turned into a scalar \nform. The heap analysis makes some assumptions on parameter aliasing, we refer the interested reader \nto [14]. On the top of the program scalar form several forward value analyses are run, and their results \nare used to discharge the asser\u00adtions. Assertions are discharged using simple built-in decision pro\u00adcedures. \nIf an assertion cannot be discharged, then the analysis is re.ned by using a more precise abstract domain \nor a goal-directed backward propagation. If re.nement does not work, then a warn\u00ading is reported to the \nuser. Warnings are issued because of a lack of knowledge (e.g. missing postcondition, precondition too \nweak . . . ), incompleteness of the analysis (inevitable in all the static analyses), or because of too \ncomplex assertions (e.g. quadratic inequalities). Before this work, quanti.ed assertions over arrays \n(e.g. all the elements are non-null) were not understood by Clousot which reported warnings for assertions \nas e.g. the ones in Fig. 1. Fur\u00ad thermore, the analysis was also very imprecise in handling array loads \n(and iterations over collections), so that each time a value was loaded from an array, nothing could \nbe stated on that value, hence the worst case was assumed, degrading the analysis precision. Fix\u00ading \nthose issues were a main request from Clousot s users.  12.2 Implementation of FunArray in Clousot We \nfully implemented FunArray in Clousot. To the user (typ\u00adically a programmer with no background in formal \nmethods) FunArray is exposed as a simple check-box in Visual Studio. When the check-box is enabled, the \nFunArray is transparently instantiated with the abstract domains in Clousot. The array anal\u00adysis is orthogonal \nto the other components of Clousot, so that it can bene.t of precision improvements for free. For instance, \nif a more precise scalar variable abstract environment is used, then the FunArray analysis is likely \nto get more precise. Functor instantiation In the current implementation: (i) the ab\u00adstract domain used \nfor the segment elements is the disjoint union of intervals with non-nullness; (ii) the expressions used \nin the segment limits are the simple expressions of Sect. 7.2 augmented with ex\u00adplicit casts to model \nthe fact that a.Length and (int) a.Length both denote the length of an array a in the bytecode; and (iii) \nthe scalar numerical abstract domain is the one provided by Clousot in the particular run. Several numerical \nabstract domains are avail\u00adable in Clousot, among them: Pentagons [28] combined with Lin\u00ad ear equalities \n[21], Subpolyhedra [24]. Clousot numerical domains are composed according to a tree topology [9]. Reduction \nis achieved via pushing or pulling of in\u00ad formation. An abstract domain can push information to abstract \ndomains of lower rank, and pull information from all other do\u00admains. The segmentation abstract domain \nis at the root of the tree. It pushes: bottom (contradiction), expression equality (when the two expressions \nappears in the same bound), array values (e.g., in x = a[i], if it determines that a[i]!= null, then \nit pushes the information x != null). It pulls: comparisons (exp1 < exp2, exp1!= exp2, exp1 == exp2 . \n. . ), integer constants (all the vari\u00adables which are known to be de.nitely constants), intervals (e.g. \nin x = a[exp], which is the range for exp?), abstract values (e.g. in a[i] = z, which is the abstract \nvalue for z?). The array analysis is currently implemented as a value analysis run on the top of the \nheap analysis, when in particular array aliasing has been resolved. As a consequence, the abstract transfer \nfunctions implemented in the analyzer are very similar to those described in Sect. 11, with some adjustements \nto meet the peculiarietes of the .NET semantics and Clousot infrastructure. Array creation When an array \nis created with the instruction newarr A exp then the segmentation {0} d { A.Length, exp }? is materialized, \nwhere d denotes the abstraction in the segment value abstract domain of the default value for the type \nof the array elements (e.g., 0 is the default value for int and null is the default value for reference \ntypes). The so-materialized segmentation is then re.ned pulling some information from the scalar variables \nabstract domain. In the particular case, Clousot .rst asks the numerical abstract domain if exp > 0. \nIf the answer is true then the uncertainity ? is dropped. If the answer is false, then it means that \nexp == 0 (as if exp < 0, then a buffer overrun occurs, causing the concrete execution to stop, and having \nsome other Clousot analysis reporting the bug). Therefore the empty segmentation is returned. Otherwise, \nthe original segmentation could not be re.ned, and it is returned as it is. Assertions Clousot implements \na very simple and special\u00adized decision procedure to check whether an quanti.ed assertion over arrays \nholds at a given program point. Given the statement assert .i . [e1, e2).c(A[i]), Clousot uses the numerical \nab\u00adstract domain to provide a lower bound l for e1 and an upper bound u for e2 to be used to determine \nan upper-approximation v for the values of A[i] in the range [l, u). The expression c(v), which does \nnot contain any reference to array values, is then constructed and its truth is decided by the internal \ndecision procedures commonly used in Clousot. Example 9 Let us consider the example in Fig. 2, and let \nus suppose that at the end of the method there was the statement assert .i . [0, A.Length). A[i] == 0. \nClousot infers the limits to be 0 and A.Length, and it uses the abstract state p6 to determine that in \nsuch a range v = A[i]=0. The consequent proof obligation 0 == 0 is then trivially discharged. nU Function \ncalls Function calls are not-inlined as Clousot relies on their contract instead. So they are turned \ninto two instructions, an assert for the precondition, and an assume for the postcondi\u00adtion. Segmentation \nUni.cation In the implementation we slightly re\u00ad.ned the algorithm of Sect. 11.4 to cope with some noise \nproduced by the bytecode representation and heap analysis. In general, in a segmentation done at bytecode \nlevel one will .nd many more extra-variables than those that one may expect, in particular when reasoning \nat the equivalent source code. The .rst modi.cation is the introduction of a puri.cation step, which \npre-processes the segmentations to remove those segment bounds (and hence segments) containing variables \nappearing only in one of the two segmentations. Of course those would have disap\u00adpeared anyway with the \noriginal algorithm, but the puri.cation step  has the advantage of making the algorithm faster and more \nprecise, as shown by the next example. Example 10 Suppose we need to unify the segmentation {0} ... \n{a} ...{b}...{A.Length} with {0}... {b}... {A.Length}. The puri.cation step removes {a} from the .rst \nsegmentation, enabling the segmentation uni.cation algorithm to produce a more precise result. Without \npuri.cation, we would have needed a deeper look-ahead for the algorithm to prevent the abstraction of \nthe bound {b}. nU The second modi.cation is a re.nement of the step 5 to take into account constants: \nIf B1 and B2 contain a constant then we can use this information to materialize new bounds, as illustrated \nby the next example. Example 11 Suppose we need to unify {0}...{25}...{26} ...{A.Length} with {0}... \n{20}... {30}... {A.Length}. The result of the uni.cation is {0}...{20}...{25} ...{26} ...{30} ...{A.Length}. \nnU 13. Experimental Evaluation We validated the performances of the analysis by running on large, production \nquality libraries. We validated its precision by running it on its own implementation (Clousot is written \nin C#). 13.1 Analysis of large libraries We report the experience of running Clousot on the main libraries \nof the .NET framework. The mscorlib.dll and System.dll li\u00adbraries provide core functionalities such as \nbasic types, optimized data structures, cryptographic primitives, date manipulation, inter\u00adfaces with \nthe operating system, etc. The other libraries focus on database interfacing (System.data.dll), bitmap \nmanipulations (System.Drawings.dll), WEB contents (System.Web.dll), XML parsing and creation (System.Xml.dll). \nLibraries have been authored by several different programmers over the years, hence present all kinds \nof different programming styles and op\u00adtimizations. We randomly inspected a large set of methods con\u00adtaining \nloops with arrays. For instance, this is how we picked the example in Fig. 1. We found few cases of code \nas Fig. 2, whereas Fig. 3 is a lot more common pattern. Other common idioms include the initialization \nusing multiple loops, conditional initialization of an array pre.x (or post.x) followed (or not) by the \ninitialization of the remaining array segment (or a sub-segment). From our manual inspection we deduced \nthat simple partitions based on the assump\u00adtion that arrays are uniformly traversed from the .rst to \nthe last element (e.g. [29]) simply do not apply to existing .NET code. Other syntactic-based partitioning \nheuristics do not apply as well (roughly because at bytecode level the structure of loops has been compiled \naway). We conclude that an array analysis technique in order to be effective should handle very ef.ciently \nthe above cases. At the beginning of this project, our .rst attempt was to im\u00adplement the technique of \n[19] on the top of a semantic analysis to determine the array partitions. Performances turned out to \nbe ex\u00adtremely bad: up to 100\u00d7 slower w.r.t. a normal run of Clousot. The main reasons for the bad performance \nwere: (i) the large num\u00adber of generated slices (because of lack of possibly empty seg\u00adments, unlike \nus); (ii) the need to re-run the analysis once the par\u00adtition is discovered (e.g. to distinguish the \n.rst iteration from all the others); (iii) the cost of partition changes (detailed in [19, Sect. 5]). \nMore generally, the problem of [17, 19] is that they abstract too much the concrete environment, e.g. \nby separating the array partitioning from the discovery of array partitions (we do it at the same time \ninstead) and e.g. by forgetting the relative positioning of array slices (we have consecutive segments). \nThe information lost because of the rough abstraction must then be recovered during the array analysis. \nNext, we developed FunArray in which we made sure that: (i) the array analysis is run at the same time \nas the scalar variable analysis; and (ii) explicit partition enumeration is avoided by means of possibly \nempty segments, i.e at each program point there is at most one approximation for a given array. We .rst \nsketched the analysis in a research prototype (Arrayal), to experiment and adjust the algorithms and \nthen we validated it by integrating it in Clousot. Our analysis turned out to be extremely fast. We report \nthe ex\u00adperimental results in Tab. 1. For each library, we report the number of functions, the analysis \ntime without the array analysis, the anal\u00adysis time with the array analysis, the slowdown, and the number \nof inferred non-trivial array invariants in function postconditions. The libraries are not annotated \nwith contracts, so we cannot report on it. In the experimental setting Clousot is run in its off-the-shelf \ncon\u00ad.guration except for the iterative re.nement which is switched off (as it is not needed for the particular \nexperience). The workbench is a 2.4GHz Core 2 duo laptop running Windows 7 and .NET v3.5. The .rst observation \nis that the FunArray introduces a negligible analysis slowdown (less than 1%) whereas it discovers a \nthousands of non-trivial array invariants. More interestingly, we did not en\u00adcountered any corner case \ncausing the analysis time to blow up (unlike previous published similar techniques). This fact makes \nus comfortable to state that the analysis scales up well. We were also positively impressed by the fact \nthat the analysis was able to han\u00addle complex initialization patterns such as the one in Fig. 1, which \nwere not considered at all during its design, meaning that the anal\u00adysis is robust enough to handle unexpected \ncode (a problem that unfortunately af.icts several static analyses usually developed for few coding patterns). \ntime w. Lib # func. time arr. . # inv mscorlib.dll 21 475 4:06 4:15 0:09 2 430 System.dll 15 489 3:40 \n3:46 0:06 1 385 System.data.dll 12 408 4:49 4:55 0:06 1 325 System.Drawings.dll 3 123 0:28 0:29 0:01 \n289 System.Web.dll 23 647 4:56 5:02 0:06 840 System.Xml.dll 10 510 3:59 4:16 0:17 807 Table 1. The execution \ntime with and without the array analysis, the slow-down and the number of non-trivial array invariants. \nTime is in minutes. The incidence of array analysis is a mere 1%.  13.2 Analysis of annotated code To \nvalidate the precision of the analysis in the context of contract checking we ran it against its own \nimplementation in Clousot. Once again we run Clousot in the off-of-the-shelf con.guration (and iterative \nre.nement on). We implemented FunArray with a pair of mutable sequences, one for the bounds and the other \nfor the array elements. Each sequence should only contain non\u00adnull elements. Sequences are implemented \nas partially .lled ar\u00adrays (to optimize cache hits). The class NonNullSeq abstracts se\u00adquences, allowing \nfor in-place insertion, manipulation, update and removal of elements (13 methods in total). The object \ninvariant of NonNullSeq states that all the elements in the partially .lled ar\u00adray are non-null. The \nanalysis of NonNullSeq without the func\u00adtor analysis takes 5.36 seconds, reporting 11 warnings (out of \n210 proof obligations). The analysis of NonNullSeq with the functor analysis takes 3.85 seconds, with \n0 warnings! Therefore the more precise analysis is also faster. The reason why is that the array anal\u00adysis \ninduces a negligible slow-down and discover more facts on the program, which can be directly used to \ndischarge the proof obliga\u00adtions, without moving to more re.ned analyses. Once NonNullSeq has been veri.ed, \nthen we considered the FunArray implementa\u00adtion (78 methods), where we were able to prove 61 further \nproof obligations, out of 1800 total (FunArray analysis cost was negli\u00adgible). The remaining 8 warnings \nare issued by a possible violation of the precondition of the segment uni.cation algorithm (out-of\u00adreach \nof Clousot, and maybe of existing SMT solvers). Overall, our experience matched the feedback from our \nusers (we do not have access to their code though): FunArray reduced the number of false positives at \na negligeable cost.  14. Conclusions Our main goal was to have a non-intrusive, precise and scalable \nstatic analysis for array contents. We achieved it through these core ideas: (i) to derive the segment \nbounds through array accesses in array element tests and assignments (so that we do not rely on the end-user \nor other analyses/tools to infer the segment bounds); (ii) to exploit segment uni.cation for partial \norder, joins, meets, widen\u00adings, and narrowings; (iii) to carefully treat disjunction (via possi\u00adbly \nempty segments, symbolic bounds with different instances, and relation of array values to indexes). Although \nexpressiveness of ar\u00adray segmentation is limited, our analysis is self-contained without hidden hypotheses. \nIt has proved to be simple enough to scale up in production-quality static analysis tools (whereas a \nprevious at\u00adtempt based on [17, 19] did not). We used it to validate its own implementation, effectively \nreducing to zero the false alarms. The approach is applicable to matrices of higher dimensions by recursively \ninstantiating the functor on an array instantiation. The work can be extended to relational properties \namong segments by using an auxiliary scalar variable to denote the value of any ele\u00adment of a segment \nand relating the values of these auxiliary scalar variables for different segments by a relational abstraction \nin the scalar environment. This would handle the partitioning in Quick-Sort. Intra-segment relational \nproperties can also be considered by using several auxiliary scalar variables xi, xj , . . . to denote \nthe val\u00adues of elements indexed i : j : ... within the segment and relat\u00ading them in the scalar environment. \nThis would handle sorting al\u00adgorithms [6]. Of course inter-segments and intra-segment relational properties \ncan be combined. The extra cost makes those relational analyses probably inappropriate in a general-purpose \nand scalable static veri.er such as Clousot. Acknowledgments We would like to thank Manuel F\u00a8 ahndrich \nfor the insightful discussions and the support provided with the implementation of the decompilation \nof ForAll in Clousot. Work partly supported by the CMACS NSF Expeditions in Computing. References [1] \nM. Barnett, K. Leino, and W. Schulte. The Spec# programming system: An overview. CASSIS 04, LNCS 3362, \n49 69. Springer, 2005. [2] M. Barnett, B.-Y. Chang, R. DeLine, B. Jacobs, and K. Leino. Boogie: A modular \nreusable veri.er for object-oriented programs. FMCO 05, LNCS 4111, 364 387. Springer, 2006. [3] M. Barnett, \nM. F\u00a8ahndrich, and F. Logozzo. Embedded contract languages. SAC 10. ACM, 2010. [4] D. Beyer, T. A. Henzinger, \nR. Majumdar, and A. Rybalchenko. Path invariants. PLDI 07, 300 309. ACM, 2007. [5] P. Chalin, J. Kinirya, \nG. Leavens, and E. Poll. Beyond assertions: Advanced speci.cation and veri.cation with JML and ESC/Java2. \nFMCO 05, LNCS 4111, 77 101. Springer, 2006. [6] P. Cousot. Veri.cation by abstract interpretation. Veri.cation \n Theory &#38; Practice, LNCS 2772, 243 268. Springer, 2003. [7] P. Cousot and R. Cousot. Abstract interpretation: \na uni.ed lattice model for static analysis of programs by construction or approxima\u00adtion of .xpoints. \n4th POPL, 238 252. ACM, 1977. [8] P. Cousot and R. Cousot. Systematic design of program analysis frameworks. \n6th POPL, 269 282. ACM, 1979. [9] P. Cousot, R. Cousot, J. Feret, L. Mauborgne, A. Min\u00b4e, D. Monni\u00adaux, \nand X. Rival. Combination of abstractions in the Astr\u00b4ee static analyzer. ASIAN, LNCS 4435, 272 300. \nSpringer, 2006. [10] L. de Moura and N. Bj\u00f8rner. Z3: An ef.cient SMT solver. TACAS 08, LNCS 4963, 337 \n340. Springer, 2008. [11] D. Dill. Timing assumptions and veri.cation of .nite-state concurrent systems. \nAutomatic Veri.cation Methods for Finite State Systems, LNCS 407, 197 212. Springer, 1989. [12] I. Dillig, \nT. Dillig, and A. Aiken. Fluid updates: Beyond strong vs. weak updates. ESOP 10, LNCS 6012, 246 266. \nSpringer, 2010. [13] I. Dillig, T. Dillig, and A. Aiken. Precise reasoning for programs using containers. \n37th POPL. ACM, 2011. [14] M. F\u00a8ahndrich and F. Logozzo. Static contract checking with abstract interpretation. \nFoVeOOS 10, LNCS. Springer, 2010. [15] C. Flanagan and S. Qadeer. Predicate abstraction for software \nveri.\u00adcation. 29th POPL, 191 202. ACM, 2002. [16] Garmin Int. Garmin device interface speci.cation. Technical \nreport, Garmin Int., Inc., Olathe, 2006. www.garmin.com/support/pdf/i op_spec.pdf. [17] D. Gopan, T. \nReps, and S. Sagiv. A framework for numeric analysis of array operations. 32nd POPL, 338 350. ACM, 2005. \n[18] S. Gulwani, B. McCloskey, and A. Tiwari. Lifting abstract interpreters to quanti.ed logical domains. \n35th POPL, 235 246. ACM, 2008. [19] N. Halbwachs and M. P\u00b4eron. Discovering properties about arrays in \nsimple programs. PLDI 2008, 339 348. ACM, 2008. [20] R. Jhala and K. McMillan. Array abstractions from \nproofs. CAV 07, LNCS 4590, 193 206. Springer, 2007. [21] M. Karr. Af.ne relationships among variables \nof a program. Acta Inf., 6:133 151, 1976. [22] G. Kildall. A uni.ed approach to global program optimization. \n1st POPL, 194 206. ACM, 1973. [23] L. Kov\u00b4acs and A. Voronkov. Finding loop invariants for programs over \narrays using a theorem prover. FASE 2009, LNCS 5503, 470 485. Springer, 2009. [24] V. Laviron and F. \nLogozzo. Subpolyhedra: A (more) scalable ap\u00adproach to infer linear inequalities. VMCAI, LNCS 5403, 229 \n244. Springer, 2009. [25] S.-H. Lee and D.-H. Cho. Packet-scheduling algorithm based on pri\u00adority of \nseparate buffers for unicast and multicast services. Electronics Letters, 39(2):259 260, 2003. [26] F. \nLogozzo. Class-level modular analysis for object oriented lan\u00adguages. SAS 03, LNCS 2694, 37 54. Springer, \n2003. [27] F. Logozzo and M. F\u00a8ahndrich. On the relative completeness of bytecode analysis versus source \ncode analysis. CC 08, LNCS 4959, 197 212. Springer, 2008. [28] F. Logozzo and M. F\u00a8ahndrich. Pentagons: \na weakly relational abstract domain for the ef.cient validation of array accesses. SAC, 184 188. ACM, \n2008. [29] M. Marron, D. Stefanovic, M. Hermenegildo, and D. Kapur. Heap analysis in the presence of \ncollection libraries. PASTE 07, 31 36. ACM, 2007. [30] K. L. McMillan. Quanti.ed invariant generation \nusing an interpo\u00adlating saturation prover. TACAS 08, LNCS 4963, 197 212. Springer, 2008. [31] B. Meyer. \nEiffel: The Language. Prentice Hall, 1991. [32] A. Min\u00b4e. The octagon abstract domain. Higher-Order and \nSymbolic Computation, 19:31 100, 2006. [33] V. Pratt. Two easy theories whose combination is hard. Technical \nreport, MIT, 1977. boole.stanford.edu/pub/sefnp.pdf. [34] B. Roy. Transitivit\u00b4e et connexit\u00b4e. Comptes-Rendus \nde l Acad\u00b4emie des Sciences de Paris, S\u00b4er. A-B, 249:216 218, 1959. [35] M. Seghir, A. Podelski, and \nT. Wies. Abstraction re.nement for quanti.ed array assertions. SAS 09, LNCS 5673, 3 18. Springer, 2009. \n[36] R. Shostak. Deciding linear inequalities by computing loop residues. JACM, 28(4):769 779, 1981. \n[37] H. Yang, O. Lee, J. Berdine, C. Calcagno, B. Cook, D. Distefano, and P. W. O Hearn. Scalable shape \nanalysis for systems code. CAV 98, LNCS 5123, 385 398. Springer, 2008.     \n\t\t\t", "proc_id": "1926385", "abstract": "<p>We introduce FunArray, a parametric segmentation abstract domain functor for the fully automatic and scalable analysis of array content properties. The functor enables a natural, painless and efficient lifting of existing abstract domains for scalar variables to the analysis of uniform compound data-structures such as arrays and collections. The analysis automatically and semantically divides arrays into consecutive non-overlapping possibly empty segments. Segments are delimited by sets of bound expressions and abstracted uniformly. All symbolic expressions appearing in a bound set are equal in the concrete. The FunArray can be naturally combined via reduced product with any existing analysis for scalar variables. The analysis is presented as a general framework parameterized by the choices of bound expressions, segment abstractions and the reduction operator. Once the functor has been instantiated with fixed parameters, the analysis is fully automatic.</p> <p>We first prototyped FunArray in Arrayal to adjust and experiment with the abstractions and the algorithms to obtain the appropriate precision/ratio cost. Then we implemented it into Clousot, an abstract interpretation-based static contract checker for .NET. We empirically validated the precision and the performance of the analysis by running it on the main libraries of .NET and on its own code. We were able to infer thousands of non-trivial invariants and verify the implementation with a modest overhead (circa 1%). To the best of our knowledge this is the first analysis of this kind applied to such a large code base, and proven to scale.</p>", "authors": [{"name": "Patrick Cousot", "author_profile_id": "81100592699", "affiliation": "New York University, New York, NY, USA", "person_id": "P2509575", "email_address": "pcousot@cs.nyu.edu", "orcid_id": ""}, {"name": "Radhia Cousot", "author_profile_id": "81100592574", "affiliation": "&#201;cole normale sup&#233;rieure, Paris, France", "person_id": "P2509576", "email_address": "radhia.cousot@ens.fr", "orcid_id": ""}, {"name": "Francesco Logozzo", "author_profile_id": "81100572523", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P2509577", "email_address": "logozzo@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926399", "year": "2011", "article_id": "1926399", "conference": "POPL", "title": "A parametric segmentation functor for fully automatic and scalable array content analysis", "url": "http://dl.acm.org/citation.cfm?id=1926399"}