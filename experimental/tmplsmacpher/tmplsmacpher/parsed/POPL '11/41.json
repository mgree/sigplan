{"article_publication_date": "01-26-2011", "fulltext": "\n Complexity of Pattern-based Veri.cation for Multithreaded Programs * Javier Esparza Fakult\u00a8ur Informatik, \nTechnische Universit\u00a8 atf\u00a8at M\u00a8 unchen, Germany. esparza@model.in.tum.de Abstract Pattern-based veri.cation \nchecks the correctness of the program ex\u00adecutions that follow a given pattern, a regular expression over \nthe ** alphabet of program transitions of the form w1 ...w n. For multi\u00adthreaded programs, the alphabet \nof the pattern is given by the syn\u00adchronization operations between threads. We study the complexity of \npattern-based veri.cation for abstracted multithreaded programs in which, as usual in program analysis, \nconditions have been re\u00adplaced by nondeterminism (the technique works also for boolean programs). While \nunrestricted veri.cation is undecidable for ab\u00adstracted multithreaded programs with recursive procedures \nand PSPACE-complete for abstracted multithreaded while-programs, we show that pattern-based veri.cation \nis NP-complete for both classes. We then conduct a multiparameter analysis in which we study the complexity \nin the number of threads, the number of pro\u00adcedures per thread, the size of the procedures, and the size \nof the pattern. We .rst show that no algorithm for pattern-based veri.ca\u00adtion can be polynomial in the \nnumber of threads, procedures per thread, or the size of the pattern (unless P=NP). Then, using recent \nresults about Parikh images of regular languages and semilinear sets, we present an algorithm exponential \nin the number of threads, procedures per thread, and size of the pattern, but polynomial in the size \nof the procedures. Categories and Subject Descriptors: D.2.4 [Software Engineer\u00ading]: Software/Program \nVeri.cation. General Terms: Veri.cation, Languages, Algorithms, Reliability. Keywords: concurrent programming, \nsafety, context-free lan\u00adguages. 1. Introduction The analysis and veri.cation of multithreaded programs \nis one of the most active research areas in software model checking. This is due, on the one hand, to \nthe increasing relevance of multicore archi\u00adtectures, and, on the other hand, to the dif.culty of conceiving, \nrea\u00ad * This research was sponsored by the Comunidad de Madrid s Program PROMETIDOS-CM (S2009TIC-1465), \nby the PEOPLE-COFUND s program AMAROUT (PCOFUND-2008-229599), and by the Spanish Ministry of Science \nand Innovation (TIN2010-20639). Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. POPL 11, January 26 28, 2011, Austin, Texas, USA. Copyright c &#38;#169; \n2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 Pierre Ganty The IMDEA Software Institute, Madrid, Spain. \n pierre.ganty@imdea.org soning about, and debugging concurrent software. Automated anal\u00adysis tools must \ncope with the very untractable nature of the analysis problems. Multithreaded programs with possibly \nrecursive proce\u00addures communicating through global variables are Turing powerful even for programs having \nonly two threads and three variables, all of them boolean. If communication takes place through message \npassing, the programs are Turing powerful even after applying the usual program analysis abstraction \nthat replaces all conditions in alternative constructs and loops by nondeterminism. Context-bounding, \nproposed by Qadeer and Rehof in [25], is the most successful proposal to date for overcoming untractability. \nIt restricts the problem further by exploring only those computation with a bounded, .xed number of contexts.A \ncontext is a segment of the computation during which only one thread accesses the global variables; a \ncontext switch takes place when the identity of this thread changes. Reachability of a program point \nby a computation with at most k context switches (the context-bounded reachability problem) is NP-complete \nwhen k is given in unary, and can be checked by means of an algorithm polynomial in the size of the program \nand exponential in k [20, 21, 25] . Context-bounding has been implemented in several model checkers, \nlike CHESS, SPIN, SLAM, jMoped, and others [1, 5, 20, 28, 30], and experiments with these tools have \nprovided evidence that many concurrency errors manifest themselves in computations with few context switches. \nWhile context bounding has been very successful, it also has important limitations. In particular, it \nrestricts the number of com\u00admunications between threads. While a thread can perform arbitrar\u00adily many \nreads and writes to the global variables during a context, these writes are not observed by the other \nthreads, and so only the value of the variable immediately before the context switch amounts to a communication. \nSo in a computation with k con\u00adtext switches threads communicate at most k times. In this paper we study \na more .exible technique, introduced by Kahlon in [15], that applies the theory of bounded languages \ndeveloped in the mid\u00adsixties by Ginsburg and Spanier [11] to the veri.cation problem. Kahlon uses the \ntheory to prove decidability of safety analysis for multithreaded programs whose executions conform to \na pattern, a regular expression of the form w1 * ...w * over the alphabet of n program instructions. \nObserve that the executions of such a pro\u00adgram can be arbitrarily long. An equivalent, but in our opinion \nmore fruitful point to view is to consider a pattern as a class of executions speci.ed by the veri.er. \nThe executions of the program may conform to the pattern or not, but we can automatically ver\u00adify whether \nthose executions conforming to the pattern satisfy the property. In other words, the programmer speci.es \nby means of a pattern those executions she/he is interested in. We call this point of view pattern-based \nveri.cation. The claim of [15] is that pattern-based veri.cation provides a good compromise between expressivity \nand complexity. The ex\u00adpressivity point has been considered in some detail in [9], where it is shown \nthere that the pattern-based approach is strictly more ex\u00adpressive than context-bounding.1 In this paper \nwe study the compu\u00adtational complexity of pattern-based veri.cation, thus completing the theoretical \nanalysis. In a nutshell, we show that pattern-based veri.cation, like context-bounding, is NP-complete, \nand we iden\u00adtify an interesting (and in a certain sense unique) polynomial case. For the complexity \nanalysis we reduce the reachability problem for multithreaded programs to a language theory problem called \nnon-Disjointness Modulo a Pattern, or nDMP for short: checking non-emptiness of the intersection of a \ngiven set of context-free grammars and a given pattern. By putting together classical results by Ginsburg \nand Spanier [11] and more recent results by Verma, Seidl, and Schwentick [31] we .rst show that, like \ncontext-bounded reachability, nDMP is NP-complete. Interestingly, the algorithm we derive from the easiness \nproof relies on satis.ability checking of a Presburger formula, which contrasts with the .xed point evaluation \nused in context-bounding. In the second and main part of the paper, we conduct a multiparameter analysis \nof nDMP. The size of an instance of nDMP is a function of four parameters: the number of threads, the \nmaximal number of procedures per thread, the maximal size of a procedure, and the size of the pattern. \nFor every subset of parameters we determine the complexity of nDMP when the parameters in the subset \n(and no others) have a .xed value. While this gives 16 possible cases, the results can be easily summarized: \napart from some trivial cases, in which the problem can be solved in constant time (for instance, when \nall four parameters have .xed values), the problem remains NP-complete for all subsets except one: the \ncase in which the number of threads, procedures per thread and the size of the pattern are .xed, but \nthe size of the procedures is not. We prove that this case is polynomial. The proof uses several recent \nresults about Parikh images of regular languages and complexity of semilinear sets [19, 29]. The paper \nis organized as follows. Section 2 contains prelimi\u00adnaries. Section 3 presents our program and formal \nmodels, an anal\u00adysis of the context-bounding technique, and the reduction of the pattern-based veri.cation \nproblem to nDMP. Section 4 shows that nDMP is NP-complete. Section 5 contains our multiparameter anal\u00adysis \nof nDMP. The NP-hard cases are covered by means of reduc\u00adtions from different NP-complete problems. Our \nmain result, the polynomial case mentioned above, is contained in Section 5.3. Fi\u00adnally, Section 6 contains \nconclusions and discusses related work. 2. Preliminaries An alphabet S is a .nite non-empty set of symbols. \nWe assume the reader is familiar with the basics of language theory, including regular and context-free \nlanguages (see e.g. [13]). Context-free Languages. A context-free grammar is a tuple G =(X , S, P,S) \nwhere X is a .nite non-empty set of variables, S is an alphabet, P.X\u00d7 (S .X ) * is a .nite set of productions \n(the production (X, w) may also be noted X . w) and S .X is the axiom. Given two strings u, v . (S .X \n) * we write u . v if there exists a production (X, w) .P and some words y, z . (S .X ) * such that u \n= yXz and v = ywz. We use . * to denote the re.exive transitive closure of .. The language of a grammar \nis the set L(G)= {w . S * | S . * w}. A language L is context\u00adfree if L = L(G) for some context-free \ngrammar G. A context-free grammar is regular if each production is in X\u00d7 S * (X .{e}).A language L is \nregular if L = L(G) for some regular grammar G. 1 This is achieved by exhibiting a family of two-thread \nprograms, param\u00adeterized by a number n, such that reachability analysis for a .xed pattern proves reachability \nof a program point for all n, but such that the number of context switches needed to reach the program \npoint goes to in.nity when n grows. We sometimes use LX (G) with X .X to denote the language {w . S \n* | X . * w}. Multisets. A multiset m:S . N maps each symbol of S to a natural number. M[S] denotes the \nset of all multisets over S. We sometimes use the following notation: [q1,q1,q3] denotes the multiset \nm such that m(q1)=2, m(q3)=1 and m(x)=0 for all x . S \\{q1,q3}. The empty multiset is denoted \u00d8. The \nP size of a multiset m is |m| = m(s). Given two multisets s.S m, m' . M[S] and we de.ne m . m' . M[S] \nas the multiset satisfying (m . m')(a)= m(a)+ m'(a) for every a . S. Given m . M[S] and c . N, we de.ne \nc \u00b7 m as the multiset satisfying (c \u00b7 m)(a)= c \u00b7 m(a) for every a . S. By .xing a linear order on S, \nevery multiset m can be seen as a vector of Nk where k = |S|, and vice versa. 3. Model and decision problem \n3.1 Program model We model a sequential program by a system of .owgraphs, a tuple of .owgraphs containing \none .owgraph for each procedure. Nodes of a .owgraph correspond to control points of the program, and \nedges to sequential statements. A sequential statement is either a condition (a boolean combination of \nexpressions x = e), an assignment x := e, or a procedure call. Each .owgraph has a unique node without \nincoming edges, the initial node, and a unique node without outgoing edges, the .nal node, different \nfrom the initial node. All nodes are reachable from the initial node and co\u00adreachable from the .nal node. \nA multithreaded program is modeled by a tuple of systems of .owgraphs, one for each program thread. Each \nsystem of .ow\u00adgraphs uses a set of channels to send or receive messages; abus\u00ading language, we call a \nsystem of .owgraphs together with the set of channels it uses a thread. We denote by Chi the set of chan\u00adnels \nused by the i-th thread, and the set of all channels by Ch. The edges of the .owgraphs are labeled by \nsequential statements, by send statements a!x, indicating that the thread is willing to send the value \nof x through channel a . Ch, or by receive statements a?y, indicating that the thread is willing to receive \na value through channel a and assign it to variable y. We assume that each channel is owned by a thread: \nthe owner of channel a can only contain send statements a!x, and all other threads can only contain receive \nstate\u00adments a?y. Channels work as in CSP: they have capacity 0, i.e., a message is exchanged through \nchannel a only if its owner exe\u00adcutes a send statement, and all other threads having a in their sets \nof channels simultaneously execute a matching receive statement. So we allow multiparty synchronization. \nFigure 1 shows a model of a program with three threads. Each of the threads, contains only one .owgraph, \nwith channels {a, b, c}, {a, b}, and {b, c}, respec\u00adtively. The .rst thread owns channels a and c, the \nsecond thread owns channel b and the third owns no channel. n0 m0 l0 a!xx := 0 a?yy := y +1 c?z call \nP1 n1 n2 m1 m2 l1 b?z c!xb?x call P2 b!y n3 m3 l2 Proc P1 Proc P2 Proc P3 Figure 1. A model of a program \nwith three threads. During a program execution threads exchange values through channels. A trace of \nthe program is the sequence of channels used along some full execution. For instance, aacb is a trace \nof the program of Figure 1 corresponding to (among others) the execution (a!x, a?y) callP1 callP2 (a!x, \na?y)(c!x, c?z) callP2 y := y +1(b?x, b!y, b?z). Using standard techniques, veri.cation of safety properties \ncan be reduced to the reachability of some program point, which can be reduced to nonemptiness of the \nset of traces of a modi.ed program (notice that the set of traces is nonempty iff the program can ter\u00adminate, \ni.e, all threads can simultaneously reach their .nal node). Since this problem is undecidable even for \nsingle-thread while\u00adprograms, further restrictions are unavoidable. The classical pro\u00adgram analysis abstraction \nconsists of replacing all condition state\u00adments by non deterministic choice, which amounts to ignoring \ndata, since data do not longer in.uence control-.ow. We call the result an abstracted program. Unfortunately, \ntrace emptiness is still unde\u00adcidable for abstracted multithreaded programs [26], and PSPACE\u00adcomplete \nfor multithreaded while-programs. For this reason we re\u00adstrict the problem further. However, before doing \nso we de.ne a formal model for abstracted multithreaded programs. Remark. Context-bounding is formulated \nin [24, 25] for boolean programs, programs in which all variables are boolean. In boolean programs data \nin.uences control, and so one could think that there is a deep conceptual difference with the program \nanalysis abstrac\u00adtion. However, this is not the case. Since the number of valuations of the variables \nof a boolean program is .nite, the program can be easily transformed into a dataless program whose program \npoints are pairs consisting of a program point of the boolean program and a valuation of the variables. \nThis is in fact how the context\u00adbounding technique proceeds, since it models a boolean program as a pushdown \nsystem, a dataless formal model. In our presenta\u00adtion we stick to the program analysis abstraction for \nconvenience and clarity, but the technique can be equally well applied to predi\u00adcate abstractions and \nboolean programs.  3.2 Formal model Let P be an abstracted multithreaded program with threads t1,...,tn \ncommunicating over a set Ch of channels. We assign to P a tuple G1,...,Gn of context-free grammars over \nthe alphabet Ch, such T n that w is a trace of P iff w belongs to i=1 L(Gi). We proceed in two steps. \nFirst we assign to P grammars G ' 1,...,G ' with al\u00ad n phabets Ch1,..., Chn such that w is a trace of \nP iff for every 1 = i = n the projection of w onto Chi belongs to L(G ' i). In a second step we transform \nthese grammars into the .nal grammars G1,...,Gn. The grammar G ' i over the alphabet Chi generates the \ninterpro\u00adcedurally valid traces of ti. These are the traces that ti can generate in an environment always \nready to match its send and receive state\u00adments. G ' i has a variable for each node of ti, a production \nfor each edge, and a further production for the .nal node of ti. The produc\u00adtion corresponding to an \nedge leading from node X to node Y and labelled by e is de.ned as follows: if e is a condition or an \nassignment, the production is X . Y ;  if e = call P , the production is X . P0Y , where P0 is the initial \nnode of procedure P ;  if e = a!x or e = a?y, the production is X . aY ;  the production for the .nal \nnode Z of t is Z . e.  The three grammars for the program of Figure 1 have variables {n0,...,n3}, {m0,...,m3}, \n{l0,l1,l2}, terminals {a, b, c}, {a, b}, {b, c}, and productions: n0 . an1 | n2 m0 . am1 | m2 l0 . cl1 \nn1 . cn3 | n0n2 m1 . m0m3 l1 . bl2 n2 . bn3 m2 . bm3 l2 . e n3 . em3 . e Observe that the number of \nproper procedures (procedures that can be called, unlike P3 in our example) is equal to the number of \nvariables Z for which there is a production of the form X . ZY . We call them procedure variables. In \nour example, those variables are n0,m0. It is easy to see that the traces of P under the program analysis \nabstraction are the words w . Ch * satisfying the follow\u00ading property: for every thread ti, the projection \nof w onto Chi is a word of L(G ' i). This completes the .rst step. For the second step, we slightly modify \neach G ' i: we set its alphabet to Ch, and add new productions. For each variable X of G ' i and for \neach channel a that does not appear in G ' i, we add a new production X . aX. The grammar so obtained \nis denoted by Gi. In our example, we add productions mj . cmj to the second grammar for j .{0,..., 3}, \nand productions lj . alj to the third grammar for j .{0,..., 2}. Observe that a grammar Gi is in a particular \nprogram normal form: all productions are of the form X . aa or X . \u00df., where a is a variable and \u00df, . \nis either a variable or e. All grammars now have Ch as alphabet. Since every channel is owned by some \nthread, it is easy to see that the set of traces of an abstracted program with threads t1,...,tn is equal \nto T n i=1 L(Gi). Since reachability of a program point can be easily reduced to checking nonemptiness \nof the set of traces of a modi.ed pro\u00adgram, our formal model reduces the reachability problem for ab\u00adstracted \nprograms to the nonemptiness problem for the intersection of context-free languages. Since this problem \nis undecidable, this does not immediately provide any algorithmic advantage. For this reason we restrict \nthe problem and introduce pattern-based veri.\u00adcation. 3.3 Pattern-based veri.cation Kahlon [15] has \nrecently proposed to only explore the traces of a multithreaded program having a certain shape. Inspired \nby the work of Ginsburg and Spanier [11], he suggests to only explore traces conforming to what we call \nin this paper communication patterns (or just patterns for short). Patterns are regular expressions ** \n* of the form w1 w2 ...w n, where wi . Ch * \\{e}2. We study the problem of deciding, given an abstract \nmultithreaded program P and a pattern p, whether some word of L(p) is a trace of P . Given the formal \nmodel given above, this veri.cation problem reduces to the following language-theoretic problem: DEFINITION \n1. Non Disjointness Modulo a Pattern (nDMP) Instance: Context-free grammars G1,...,Gg in program normal \nform over an alphabet S, and a pattern p over S. T Question: Is gi=1 L(Gi) n L(p)= \u00d8? 3.4 Context bounding \nas pattern-based veri.cation Recall that in context bounding, instead of asking whether a given multithreaded \nprogram has a trace, we ask if it has a trace with at most k context switches. Before studying the complexity \nof nDMP, we sketch an argument showing that context bounding can be seen as a special case of pattern-based \nveri.cation. We do not formalize the reduction, which would be very technical and tedious, but describe \nit in enough detail in order to (we hope) convince the reader. 2 The languages of patterns are called \nbounded languages in the literature. Consider a multithreaded boolean program P communicating through \nshared variables. Without loss of generality (see [24, 25] for details) we assume that P has one single \nshared variable g which can take v different values. We .rst show how to simulate P by a multithreaded \nprogram P ' whose threads communicate through message passing. Let t1,...,tn be the threads of P . The \n''' ' program P has threads t1,...,t n. Each thread ti has a variable gi that acts as a local copy of \ng.3 At any given moment in time, every thread of P ' is either active or passive. Loosely speaking, when \nti ' is active it simulates the thread ti; when it goes passive, it suspends the simulation, until its \nnext active phase. More precisely, from its passive state a thread t ' i can either send a signal to \nall other threads through a channel ai, by which it becomes active, or receive a signal through a channel \naj for some j = i, by which it remains passive. After one of the two happens, t ' i behaves as follows: \n(1) If ti ' has become active, then it resumes its simulation of ti. Thread ti ' simulates ti using the \nmost recent value of g which is available from gi. At any point ti ' may nondeterministically decide \nto suspend the simulation. In this case, ti ' communicates to all other processes the current value of \ng (available through gi), say u, by sending a signal through a channel bi,u. After sending this signal, \nti ' becomes passive. (2) If ti ' has remained passive, then it waits for a signal through some channel \nbj,u, where j = i, and when the signal arrives it updates the value of gi to u. Observe that a context \nof P is simulated by an activity cycle of P ', i.e., a segment of the computation of P ' starting at \nthe moment a thread becomes active, and ending when it switches to the passive state. Since the trace \nof an activity cycle has length 2 (during a cycle the active thread sends exactly two signals), the traces \nof P ' simulating computations of P with at most k contexts have length at most 2k. The problem of deciding \nif P has a full computation with at most k context switches can now be reduced to an instance of nDMP. \nThe grammars of the instance are the result of applying the translation of Section 3.2 to P ' . For the \npattern, let W = {w1,...,wnv} be the set of all sequences of length 2 of the ** )k form aibi,u (there \nare nv of them), and let p =(w1 ...w nv. Clearly, L(p) contains (among others) all sequences obtained \nby concatenating at most k words of W . So all full computations of P with at most k contexts are simulated \nby computations of P ' whose traces belong to L(p). Therefore, if P has a full computation with at most \nk contexts, then the intersection of the languages of the grammars obtained from P ' and p is nonempty. \n(The converse does not hold, but this only shows that the instance of nDMP explores more computations \nof P that context bounding with k context switches.) 4. NP-completeness of nDMP The decidability of nDMP \nwas proved in [11]. We show it is NP\u00adcomplete. But we .rst de.ne the size of an instance of nDMP, since \nthis requires some care. The size |w| of a word w is its length |w|. P ** n The size of a pattern p = \nw1 ...w is |p| = |wi|. De.ning n i=1 the size of a grammar requires a bit of care. The seemingly natural \nchoice would be to de.ne the size of a grammar G =(X , S, P,S) as |X | + |P|. However, recall that the \ngrammar Gt for a thread t is constructed in two steps: in a .rst step, a grammar G ' t is constructed \nthat matches the behaviour of the thread is de.ned; in a second step, loop productions of the form X \n. aX are added for every variable X and every channel a that does not appear in t. In pathological cases \nthe number of these productions could be much larger than the number of true productions, arti.cially \nincreasing 3 Since our multithreaded programs are dataless, the local variable gi is actually encoded \ninto the nodes of the program as explained in a previous remark. the size of the grammar. For this reason, \nwhen a grammar has productions X . aX for every variable X and some terminal a, we de.ne that all those \nproductions count as one single production for determining the size. We denote the size of a grammar \nG, so de.ned, by |G|. 4.1 nDMP is NP-hard We show4 that nDMP is NP-hard even for regular grammars and \n.xed pattern p = a *. From a programming point of view, this means that the veri.cation problem is already \nNP-hard for multi\u00adthreaded procedureless programs, and the simplest pattern. THEOREM 1. The following \nproblem is NP-hard: Instance: Regular grammars G1,...,Gg in program normal form. g Question: Is T i=1 \nL(Gi) n L(p)= \u00d8for the pattern p = a * ? PROOF: The proof is by reduction from 3-CNF-SAT. Let . be a \npropositional formula with n variables and m clauses c1,...,cm. We de.ne for each clause ci a regular \ngrammar Gi over the alpha- T bet {a} such that m L(Gi)= \u00d8iff . is satis.able. i=1 We need some preliminaries. \nAssign to each variable v a prime number nv, and assign to each clause c the number nc obtained by multiplying \nthe primes of the three variables occurring in c. (This requires to construct n primes in time p(n) for \nsome polynomial p. It is well-known that the i-th prime number pi satis.es pi < i ln i + i ln ln i, and \nso one can compute n primes by applying a primality test to each number from 1 to n ln n + n ln ln n. \nNotice that the primality test can take exponential time, because the size of the number k is O(ln k).) \nGiven a clause c and a variable v, we say that a number 0 = k is a (c, v)-witness if v appears positively \nin c and k = 0 mod nv, or v appears negatively in c and k = 0 mod nv. Further, k is a c-witness if it \nis a (c, x)-witness, or a (c, y)-witness, or a (c, z)-witness where x, y and z are the three variables \noccurring in c. For instance, if c = x .\u00acy . z and nx =2,ny =3,nz =5, then k is a c-witness if k = 0 \nmod 2, or k = 0 mod 3, or k = 0 mod 5, i.e., if k =3, 9, 21, 27. Given an assignment f to the variables \nof ., let nf be the product of the numbers of the variables set to true by f. It is easy to see that \nf satis.es c iff nf is a c-witness. Now, for each clause c we de.ne a grammar Gc in program nor\u00admal form \nover the alphabet {a}. The grammar Gc has the numbers 0, 1, 2,...,nc - 1 as grammar variables, 0 as axiom, \nproductions k . a (k .c 1) for every 0 = k = nc - 1, where .c is addi\u00adtion modulo nc, and a further production \nk . E for each c-witness k = nc - 1. We have L(Gc)= {a k | k is a c-witness}, and so an T assignment \nf satis.es c iff a nf . L(Gc). So m )= \u00d8 T mi=1 L(Gci iff . is satis.able, and so ) n L(p)= \u00d8 holds \nfor i=1 L(Gci p = a * iff . is satis.able. D 4.2 nDMP is in NP We show that nDMP is in NP. The direct \napproach would be to T show that if g L(Gi) n L(p)= \u00d8, then there is a witness T i=1 w . ig =1 L(Gi) \nn L(p) of polynomial length. However, it is easy to construct instances of size k for which the shortest \nwitness is the word a 2k (see also Lemma 2). So we proceed differently, in two steps: .rst we polynomially \nreduce nDMP to a problem about Parikh images of context-free grammars, and then we show that this problem \nis in NP. The Parikh image of a word w . S * is the multiset .(w): S . Nthat assigns to each a . S the \nnumber of occurrences of a in w. The Parikh image of a language L, denoted by .(L), is the set of Parikh \nimages of its words. We consider the following problem: 4The proof is due to Mikolaj Boja\u00b4 nczyk.  DEFINITION \n2. Non Disjointness of Parikh Images (nDPK) Instance: Context-free grammars G1,...,Gg in program normal \nform. T Question: Is ig =1 .(L(Gi)) = \u00d8? The reduction from nDMP to nDPK relies on a classical re\u00adsult \nby Ginsburg and Spanier [11]: Given context-free languages ** L1,...,Lg and a pattern p = w1 ...w n over \nan alphabet S, there exist context-free languages L ' 1,...,L ' g such that T g Li n L(p)= \u00d8 iff T g \n.(L ' i)= \u00d8 . (1) i=1i=1 e The proof can be easily sketched: take a new alphabet S= eS * {a1,...,an}, \nand consider the homomorphism h :S . given by h(ai)= wi for every 1 = i = n. Since context\u00adfree languages \nare closed under intersection with regular lan\u00adguages and under inverse homomorphism, the language L \n' = `\u00b4 i h-1 ** Li n L(p) n L(a1 ...a n) is context-free and satis.es prop\u00aderty (1). Moreover, using \nthe constructions underlying these clo\u00adsure properties we can easily construct from a grammar Gi for \nLi a grammar G ' i for L ' i in polynomial time. However, for the complexity analysis in Sect. 5.3 we \nalso need to establish a relation between the number of procedure variables of Gi and G ' i. For this \nreason we provide our own direct construction. 4.2.1 A polynomial time reduction from nDMP to nDPK The \nfollowing lemma contains the main properties of our construc\u00adtion. ** e LEMMA 1. Given p = w1 ...w n \nover S, an alphabet S= {a1,...,an}, a homomorphism h :Se. S *, and a grammar G in program normal form, \nwe can compute in polynomial time a grammar Gf over Sein program normal such that: L(Gf )= h-1(L(G) \nn L(p)) n L(a1 * ...a n* );  If pr is the number of procedure variables in G, then Gf has O(pa 2 \u00b7 pr) \nprocedure variables where pa is the size of p.  PROOF: (Sketch.) Let Gp be a regular grammar with O(pa) \nvari\u00adables such that L(Gp)= L(p) (this grammar clearly exists). The variables of Gf are triples [q1Xq2], \nwhere X is a variable of G and q1,q2 are variables of Gp such that q2 is reachable from q1. The productions \nare chosen to satisfy that [q1Xq2] . * w holds in Gf iff there exists u . S * such that (1) w . h-1(u) \nn L(a1 * ...a n* ), (2) X . * u holds in G, and (3) q1 . * u \u00b7 q2 in Gp. This is achieved in two steps. \nFirst, a grammar Grx is constructed that satis.es [q1Xq2] . * u iff conditions (2) and (3) above hold. \nThe construction is similar to the triple construction used to trans\u00adform a pushdown automaton into an \nequivalent context-free gram\u00admar. In the second step we adjust the terminals in the productions of Grx: \nthe productions used to generate the letters of the words w1,...,wn are modi.ed so that they generate \nno terminal at all, with the exception of those productions generating the last letter of one the words \nw1,...,wn, say, the word wi: these that are modi\u00ad h-1 .ed so that they generate the letter ai =(wi) instead. \nFor the number of process variables, notice that by the above construction each procedure variable in \nG yields O(pa 2) procedure variables in Gf , hence if pr is the number of procedure variables in G we \n.nd that the number of procedure variables in Gf is O(pa 2 \u00b7 pr). A detailed proof of this lemma is given \nin an appendix. D  4.2.2 nDPK is in NP The proof relies on results of [11, 23, 31], showing that Parikh \nim\u00adages of context-free languages are semilinear sets, that semilinear sets are exactly the sets de.nable \nby (existential) Presburger for\u00admulas, and that satis.ability of existential Presburger formulas is NP-complete. \nWe brie.y recall these notions. Given k = 1, c . Nk, and P = {p1,...,pm}. Nk, we denote by L(c; P ) \nthe subset of Nk de.ned as follows L(c; P )= {m . Nk |..1,...,.m . N: m = c . (.1 \u00b7 p1) .\u00b7 \u00b7\u00b7. (.m \u00b7 \npm)} . A set S . Nk is linear if S = L(c; P ) for some c . Nk and some .nite P . Nk.A semilinear set \nis a .nite union of linear sets. Existential Presburger formulas f are de.ned by the following grammar \nand interpreted over natural numbers: t ::= 0 | 1 | x | t1 + t2 f ::= t1 = t2 | t1 >t2 | f1 . f2 | f1 \n. f2 |.x \u00b7 f1 . Given an existential Presburger formula f, we denote by [f] the set of valuations of \nthe free variables of f that make f true; f is sat\u00adis.able if [f] is nonempty. Satis.ability of existential \nPresburger formulas is an NP-complete problem (see e.g. [31, Lemma 5]). A set S . Nk is (existential) \nPresburger de.nable if S = [f] for some existential Presburger formula f. It is well known that a set \nis Presburger de.nable iff it is existential Presburger de.nable iff it is semilinear. We use the following \nresult of [31, Th. 4]: given a context-free grammar G over S, one can compute in linear time an existential \nPresburger formula fG such that [fG] = .(L(G)). We brie.y sketch the proof for future reference. Let \nG =(X , S, P,S). A result of [7] characterizes .(L(G)) as the set of all multisets m . M[P] that are \nsolution of a certain system of linear equations, and for which a certain derived graph is connected. \nThen, [31, Th. 4] shows that this set of multisets is Presburger de.nable by explicitly constructing \nan existential Presburger formula in linear time in the size of G. THEOREM 2. nDMP is in NP. PROOF: By \nLemma 1 it suf.ces to show that nDPK is in NP. Let G1,...,Gg be an instance of nDPK, and let fGi be the \nexis\u00adtential Presburger formula of [31, Th. 4] de.ning .(L(Gi)). Let T .= fG1 . ... . fGg . We have \n[.] = g .(L(Gi)), and T i=1 so . is satis.able iff ig =1 .(L(Gi)) = \u00d8. Since existential for\u00admulas are \nclosed under conjunction, . is an existential Presburger formula. Since satis.ability of existential \nPresburger formulas is NP-complete (see e.g. [31]), the result follows. D 5. Multiparameter analysis \nFrom a veri.cation point of view, it is important to analyze whether nDMP remains NP-complete or becomes \npolynomial for programs in which one or more of the following parameters is .xed: the number of threads, \nthe maximal size of a procedure, the maximum number of procedures per thread, and the size of the pattern. \nIn the formal model, these parameters correspond to the number of grammars g, the maximal size of a grammar \nsg, the maximal number of procedure variables in each grammar pr, and the size of the pattern pa. Since \neach parameter can be .xed or not, there are in principle 16 possible cases. We use pbto denote that \na parameter p is .xed, and p to denote that it is not .xed. So, for instance, the case in which g and \npr are .xed but sg and pa are not, is denoted by nDMP(bpr, pa). Section 5.1 consider the cases in which \ng, sg, cthe size of a grammar sg is .xed. Sections 5.2 and 5.3 deal with the more involved cases in which \nsg is not .xed, i.e., threads can have arbitrary size. 5.1 Fixed-sized grammars In this section we assume \nthat sg is .xed. Recall that the size of a grammar in program normal form is equal to the number of variables \nplus the number of productions, but when for some terminal a the grammar contains a production X . aX \nfor every variable X, then all those productions count together as one. Observe that .xing the size sg \nof a grammar immediately .xes pr (the number of procedure variables of a grammar cannot be larger than \nits size). This leaves four cases, corresponding to the four combinations for .xed/non.xed g and pa. \nWe .rst observe that if on top of sg and pr we .x at least another parameter (viz. g or pa), then each \ninstance of nDMP can be reduced to one out of a constant number of nDPK instances, and so the problem \ncan be trivially solved in polynomial time. So the only non-trivial case is nDMP(g, sgb, c pr, pa), which \ncorresponds to small but arbitrarily many threads, and an arbitrary pattern. This case remains NP-complete. \nTHEOREM 3. The following problem is NP-hard: Instance: Regular grammars G1,...,Gg in program normal form \nof .xed size, and a pattern p. T Question: Is ig =1 L(Gi) n L(p)= \u00d8? PROOF: (Sketch.) By reduction from \n3-CNF-SAT. Let . be a propositional formula with n variables x1,...,xn and m clauses c1,...,cm. We de.ne \nfor each clause ci a regular grammar Gi T m such that i=1 L(Gi) n L(p)= \u00d8 iff . is satis.able. Let ci \n= ei1 . ei2 . ei3 where 1 = i1 <i2 <i3 = n and ei . {xi,xi}. We de.ne Gi as a regular grammar for the \nlanguage S * ei1 S * ei2 S * ei3 S *, where S= {xk,xk | k .{i1,i2,i3}}. /Observe that we can easily give \na regular grammar Gi with four variables and four productions, plus productions of the form X . aX, which \nare not counted in the size of the grammar. It is now T easy to see that mi=1 L(Gi) is the set of words \ne1 ...en that correspond to a satisfying assignment of ., and so by taking p = x1* (x1) * ...x n* (xn) \n* we are done. D  5.2 Grammars of arbitrary size: NP-hard cases Since sg is not .xed, there are three \nparameters, namely g, pr, and pa, that can still be .xed or not. We show that if at least one of these \nthree parameters is not .xed, then nDMP remains NP-complete. In Section 5.3 we complete the analysis \nby proving that if all three parameters are .xed, then nDMP becomes polynomial. We have already dealt \nwith one case: Theorem 1 shows that nDMP(g, sg, cpa) is NP-complete (in the theorem the gram\u00ad pr, cmars \nare regular, and so pr =0, and the pattern is always a * , and so pa = g, sg, pr, c 1). This leaves two \ncases: nDMP(bpa), and nDMP(bpr, pa). For nDMP(bpa) we show that g, sg, cg, sg, pr, cnDMP remains NP-complete \nfor two grammars and .xed pattern a * by a reduction from the 0-1 Knapsack problem. DEFINITION 3 (0 1 \nKnapsack Problem). Instance: (1) A set of objects {o1,...,om} and their associated weights {w1,...,wm}, \nwhich are positive integer given in binary. (2) A positive integer W given in binary. Question: Is there \na subset S .{o1,...,om} such that the total weight of S is equal to W ? THEOREM 4. The following problem \nis NP-hard: Instance: Two context-free grammars G1,G2 in program normal form over the alphabet {a}. Question: \nIs L(G1) n L(G2) n L(p)= \u00d8for pattern p = a * ? PROOF: The proof is by reduction from the 0-1 Knapsack \nproblem: Let {o1,...,om}, {w1,...,wm},W be an instance of the 0-1 Knapsack problem, and let n be the \nmaximum number of bits needed to encode any of the integers {w1,...,wm,W }. De.ne G to be the grammar \nover unary alphabet {a} with productions given by the union of the sets (2) through (7) shown below. \nIntuitively, a derivation of G nondeterministically selects a subset of objects as follows. The object \noi is selected by applying the production Si . Si (n) (2), and omitted by applying Si . Si+1 (3). If \noi has been selected, then the derivation outputs a wi through the variable Si (n) using the productions \nin (4) and (5), and then comes back to Si+1 using production (6). Formally, we have Si (n) . * P wi n \n a \u00b7 Si+1. Indeed, observe that wi = j=0 jth bit of wi \u00d7 2j , and the productions of (4)-(5) follow the \nbinary encoding of wi: if the j-th bit is 0 then the derivation moves to the next bit, and if it is 1, \nthen the grammar outputs a 2j through Aj . The productions of (7) no make use of a well-known encoding \nto ensure LAk (G)= a 2k for every 0 = k = n. Finally, the axiom of G is S1. no Si . Si (n) :1 = i = m \n(2) {Si . Si+1 :1 = i = m - 1}.{Sm . e} (3) 89 < 1 = i = m = (k)(k-1) Si . Ak \u00b7 Si :1 = k = n (4) :; \nbit k of wi is 1 89 < 1 = i = m = (k)(k-1) Si . Si :1 = k = n (5) :; bit k of wi is 0 n ono (0) (0) Si \n. Si+1 :1 = i = m - 1 . Sm . e (6) {Ak . Ak-1Ak-1 :1 = k = n}.{A0 . aZ}.{Z . e} (7) We now turn to W \n, and de.ne the grammar GW by: j. (k)(k-1) 1 = k = n W . Ak \u00b7 W : (8) bit k of W is 1 j. no (k)(k-1) \n1 = k = n (0) W . W : . W . e (9) bit k of W is 0 where W (n) is the axiom. From the reasoning above \nwe .nd that .\u00af L(G)= a W . Clearly, G and GW can be computed in polynomial time, and are in program \nnormal form. Moreover, it is easily seen that L(G)n L(GW ) n L(p)= \u00d8 iff there is a subset S .{o1,...,om} \nsuch that the total weight of S is W . D For nDMP(bpr, pa), we show that nDMP remains NP\u00ad g, sg, ccomplete \nfor three grammars, each of them with at most one pro\u00adcedure variable. The proof is by reduction from \nthe bounded Post Correspondence Problem [10]. DEFINITION 4 (Bounded Post Correspondence Problem). Instance. \nTwo sequences a =(a1,...,an) and b =(b1,...,bn) of words over an alphabet S, and a positive integer K \n= n. Question: Is there a non-empty sequence i1,...,ik of k = K (not necessarily distinct) positive integers, \neach between 1 and n, such that ai1 ai2 ...aik = bi1 bi2 ...bik . THEOREM 5. The following problem is \nNP-hard: Instance: Two context-free grammars G1,G2 in program normal form, each of them with 1 procedure \nvariable, a regular grammar R in program normal form, and a pattern p. Question: Is L(G1) n L(G2) n L(R) \nn L(p)= \u00d8?  PROOF:(Sketch.) Let a, b, K be an instance of the bounded Post Correspondence Problem. De.ne \nG= {1,...,n} and assume it is disjoint from S. We construct the context-free grammars G1 =({X}, S . G, \nP1,X), where P1 = {X . ai \u00b7 X \u00b7 i | i . G}.{X . e} , G2 =({Y }, S . G, P2,Y ), where P2 = {Y . bi \u00b7 Y \n\u00b7 i | i . G}.{Y . e} , SK the regular grammar R such that L(R)=S * \u00b7 i=1 Gi, and ** * the pattern p =(a1 \n...a n)K (1 * ...n )K . Observe that, since K = n, the size of p is polynomial in the size of the instance. \nNotice that G1 and G2 can be easily put in program normal form: replace a production X . ai \u00b7 X \u00b7 i by \nproductions X . ' ' '''' ' ai \u00b7 Xi,X i . X \u00b7 Xi ,X i . i \u00b7 Z, Z . e , where Xi, Xi '' and Z are fresh \nvariables. Finally, observe that X is the only procedure variable. It follows easily from the construction \nthat L(G1) nL(G2) nL(R) nL(p)= \u00d8iff the bounded PCP instance is positive. D Notice that in this reduction, \nneither the number of words in p nor their length is .xed. By mean of a more involved reduction it is \npossible to show NP-hardness with a single word only (but arbitrarily long). This reduction is presented \nnext. 5.2.1 A .ner analysis P ** n We have de.ned the size of a pattern p = w1 ...w n as |wi|. i=1 We \ncan now zoom in and consider the size as a function of two parameters, the number n of words in the pattern, \nand the maximal length of a pattern. Since the reduction of Theorem 5 requires a pattern with a large \nnumber of words (2n in the worst case), we study whether nDMP stays NP-complete if on top of the number \nof grammars g and the number pr of procedures also the number ** of words n in the pattern p = w1 ...w \nn is .xed, but not their length. We show that nDMP remains NP-hard by reduction to the 0-1 Knapsack problem \nof Def. 3. Consider the reduction from 0-1 Knapsack shown in Th. 4. It does not yield a grammar with \na .xed number of procedure variables because of the sets (7), (4), and (8) of productions. To solve this \nproblem we .rst construct a grammar G. with a .xed number of procedure variables that can still be used \nto encode big numbers, albeit by means of a more complicated encoding. Fix a number n = 1 and an alphabet \nS= {a0,a1,...,an}. {b1,...,bn}, and let w = anbn \u00b7\u00b7\u00b7 a1b1a0. We encode the number k = 2n by the word \nw k. The grammar G. =(X ., S, P.,X) has variables X . = {X}.{A1,...,An} (X is the only procedure variable), \nand productions P. given by the union of the sets (10) to (14): {X . An} (10) {X . bkAk-1 | 1 = k = n} \n(11) {Ak . akXAk-1 | 1 = k = n} (12) {Ak . aj bj Ak | n = j, k = 0 . j>k} (13) {A0 . a0} (14) G. can \nalso be obtained as follows. We .rst apply the construc\u00adtion of Sect. 3.2 to the program shown in Figure \n2. This returns a context-free grammar in program normal form. Second, some pro\u00adductions are merged for \nbetter readability. Consider the pattern p = w *. Our .rst lemma shows that the language LAk (G.) n L(p) \nconsists of a unique word given by 2k repetitions of w. no LEMMA 2. LAk (G.) n L(p)= w 2k for every 0 \n= k = n. PROOF: The proof is by induction on k.  Figure 2. The abstracted program de.ning Gb. For every \ni . {1,...,n} we have ji .{i, . . . , n} as in (13). k = 0. The only word which can be derived from A0 \nand follows p is given by A0(.(13)) * anbn ...a1b1A0 .(14) anbn ...a1b1a0 = 0 2 w . k > 0. We distinguish \ntwo cases: k<n and k = n. For k<n, consider the following partial leftmost derivation: (.(13)) * Ak \nanbn ...ak+1bk+1Ak .(12) anbn ...ak+1bk+1akXAk-1 .(11) anbn ...ak+1bk+1akbkAk-1Ak-1 (.(12).(11)) * anbn \n\u00b7\u00b7\u00b7 a1b1A0A0A1 ...Ak-1 .(14) anbn \u00b7\u00b7\u00b7 a1b1a0A0A1 ...Ak-1 = w \u00b7 A0A1 ...Ak-1 For the case k = n, consider \n(.(12).(11)) * An anbn ...a1b1A0A0A1 ...An-1 .(14) w \u00b7 A0A1 ...An-1 . We only need these two partial \nderivations, because every left\u00admost derivation that does not start like one of the two does not generates \na word of L(p) either. To conclude, we apply the induc\u00ad . * 20 tion hypothesis on A0A1 ...Ak-1 to show \nthat Ak w \u00b7 w \u00b7 1 2k-1 2 2k Pk-1 w \u00b7\u00b7\u00b7 w , hence that Ak . * w since 1+ i=0 2i =2k . D Using this lemma \nwe can already obtain a .rst reduction from the 0-1 Knapsack problem to nDMP in polynomial time. If in \nthe reduction of Th. 4 the set (7) is replaced by the set P., we get L(G) n L(GW ) n L(p)= \u00d8 iff there \nexists S .{o1,...,om}such that S s weight is W . However, this reduction is not yet ade\u00adquate because \nthe variables {A1,...,An} are procedures variables (see the sets (4) and (8) of productions). To .x this \nproblem, we need a second lemma: no LEMMA 3. (1) L(G.) n L(p)= w 2n . no ` \u00b4 (2) {anbn ...ak+1}\u00b7 L(G.) \nn L(p)= w 2k for all 1 = k = n - 1. PROOF: (1) Any derivation of G. that generates a word of L(p) must \nuse the production (10) .rst, so that X .(10) An. Applying no Lem. 2 we get L(G.) n L(p)= LAn (G) n \nL(p)= w 2n . (2) Any derivation of G. generating a word u such that anbn ...ak+1u belongs to L(p) must \nstart with X .(11) bk+1 \u00b7 Ak. As shown in .(11) the proof of Lem. 2, the derivation must continue with \nX bk+1 \u00b7 Ak . * w \u00b7 A0A1 \u00b7\u00b7\u00b7 Ak-1, and so .nally lead to w 2k . D We the help of this lemma we can now \nproceed as follows. Recall that we have already replaced set (7) in the reduction of Th. 4 by P . Now \nwe replace the set (4) by 8 9 < 1 = i = m = S(k) i . anbn \u00b7 \u00b7 \u00b7 ak+1 \u00b7 X \u00b7 S(k-1) i : 1 = k = n :; bit \nk of W is 1 and the set (8) by j. (k)(k-1) 1 = k = n W . anbn \u00b7\u00b7\u00b7 ak+1 \u00b7 X \u00b7 W : bit k of W is 1 xx This \ngives two grammars Gr1 and Gr2 with S1 and W (n) as axioms, respectively. We have: THEOREM 6. The following \nproblem is NP-hard: Instance: Two context-free grammars G1,G2 in program normal form over alphabet S, \neach of them with 1 procedure variable, and a pattern p = w * consisting of a single word w . S * . Question: \nIs L(G1) n L(G2) n L(p)= \u00d8? PROOF: The proof is by reduction to 0-1 Knapsack. We construct Gr1 x , Grx \n2 and p as above. The proof of correctness for the reduction essentially follows the one of Th. 4 where \nthe result of Lem. 3 is 1 x)nL(Grx used when needed. We thus obtain that L(Gr2 )nL(p)= \u00d8iff a subset \nof {o1,...,om} has weight W . It is routine to check the following: given a 0-1 Knapsack instance (1) \nGrix is computable in polynomial time, (2) X is the only procedure of Grx where i .{1, 2} and (3) p = \nw * is computable in polynomial time. Note that Grix are not in program normal form, but can easily be \nbrought into it by adding new variables and productions. The transformation does not add any procedure \nvariable. D i  5.3 Grammars of arbitrary size: a polynomial case We present the most involved result \nof the paper, a polynomial algorithm for nDMP(bpr, c g, sg, cpa). Notice that the reduction of nDMP to \nsatis.ability of existential Presburger formulas of Th. 2 does not help, because it yields formulas of \narbitrary size that, to the best of our knowledge, do not fall immediately into any polynomial class \ndescribed in the literature (see e.g. [12, 22, 27]). However, using some recent results of [19, 29] we \nshow how to compute in polynomial time an equisatis.able formula that belongs to the polynomial class \nof [27]. As a .rst step we observe that, because of the reduction from nDMP to nDPK shown in Section \n4.2, it suf.ces to provide a polynomial algorithm for nDPK, and in fact only for the instances of nDPK \nwith a .xed number g of grammars over an alphabet of .xed size al, and a .xed number of procedure variables \npr ', i.e., a polynomial procedure for nDPK(balb, c'). Indeed, Lem. 1 g, sg, pr shows that (1) al, the \nsize of the alphabet in the reduced nDPK instance, is .xed, because pa is .xed in nDMP, and (2) that \npr ' , the number of procedure variables in the reduced nDPK instance, is .xed since pa and pr are .xed. \nLet G1,...,Gg be an instance of nDPK(balb, c g, sg, pr). The polynomial algorithm proceeds in two steps: \n.rst, for each i . {1,...,g} the algorithm computes a regular grammar (or non\u00addeterministic automaton) \nAi such that .(L(Ai)) = .(L(Gi)); T then, the algorithm checks if ig =1 .(L(Ai)) = \u00d8. The dif.\u00adculty \nconsists of showing that both steps can be carried out in polynomial time. For this we prove two facts. \nFirst, if Gi = (X , S, P,S), then the algorithm constructs Ai in O(|Gi|f(pr)) time and space for some \nfunction f. Second, given automata A1,...,Ag over an alphabet of size al, the algorithm performs T` \u00b4 \n the check g .(L(Ai)) = \u00d8 in O (|A1| + \u00b7\u00b7\u00b7 + |Ag|)h(g,al) i=1 time for some function h. Since g, pr, \nand al have .xed values, so do f (pr) and h(g, al). Step 1. We show that given a context-free grammar \nG in program normal form with pr variables, we can construct a regular grammar AG satisfying .(L(AG)) \n= .(L(G)) in O(|Gi|f(pr)) time and space (for some function f). For this we strengthen a recent result \nof [8], which shows that such a grammar can be constructed in O(|G|f(v)) time and space, where v is the \ntotal number of variables of G. We start by de.ning the grammar AG. DEFINITION 5. Let G =(X , S, P,S) \nbe a context-free grammar in program normal form, and let pr be the number of procedure variables of \nG. We de.ne the regular grammar AG =(Q, S, d, q) as follows: Q is the set of all multisets m . M[X ] \nof at most (pr + 2) elements, and q, the axiom, is given by [S];  d = {\u00d8 . E}.d ', where d ' contains \na production m . a \u00b7m ' iff P contains a production X . a\u00df, such that a . S * , \u00df .X *, and m ' . [X] \n= m . .(\u00df).  Observe that |Q| = O(|X |pr+2) and |d| = |Q|2 \u00b7 al. We set out to prove the following \nresult (see Theorem 7 in the next page) by means of several lemmas: Let G =(X , S, P,S) be a context-free \ngrammar in pro\u00ad gram normal form. The regular grammar AG of Def. 5 sat\u00ad is.es .(L(G)) = .(L(AG)). We \n.rst introduce some new notation. Given L1,L2 . S * , we write L1 =. L2, respectively L1 .. L2, to denote \nthat the Parikh image of L1 is equal to, respectively included in, the Parikh image of L2. Also, given \nw, w ' . S *, we abbreviate {w} =. {w ' }to w =p w '. Using this notation we can rewrite our proof goal \n.(L(G)) = .(L(AG)) as L(AG)=. L(G). The proof is a modi.cation of the one given in [8]. The in\u00adclusion \nL(AG) .. L(G) is proved in [8, Prop 2.1]. Establish\u00ading L(G) .. L(AG) is done through the chain of inclusions \nL(pr+2) L(G) .. (G) .. L(AG), where L(i)(G) is the index-i approximation of L(G), de.ned as follows. \nDEFINITION 6. A derivation S = a0 . \u00b7\u00b7\u00b7 . am of G = (X , S, P,S) has index k if for every i .{0,...,m} \nat most k symbols of ai are variables. The set of words derivable through derivations of index k is denoted \nby L(k)(G). The inclusion L(pr+2)(G) .. L(AG) is proved in [8, Lem. 2.4]. To prove L(G) .. L(pr+2)(G) \nwe need a few preliminaries. DEFINITION 7. Let G =(X , S, P,S) be a context-free grammar in program normal \nform. We inductively de.ne the set Tr of .nite labelled trees as follows: if (X, e) .P then the tree \nt labelled by production (X, e) and consisting of one single node is a tree of Tr, and its yield .(t) \nis equal to e;  if (X, a \u00b7 Y ) .P, then the tree t labelled by (X, a \u00b7 Y ) and having as only child \na tree t ' . Tr labelled by some (Y, a) .P isa tree of Tr, and .(t)= a \u00b7 .(t ' );  if (X, Y ) .P, then \nthe tree t labelled by (X, Y ) and having as only child a tree t ' . Tr labelled by some (Y, a) .P is \na tree of Tr, and .(t) = .(t ' );  if (X, Z \u00b7 Y ) .P, then the tree t labelled by (X, Z \u00b7 Y ) and having \ntwo children labelled by some (Z, a1) (left) and (Y,a2) (right) is also a tree of Tr, and .(t) = .(t1) \n\u00b7 .(t2).  A tree t . Tr is a derivation tree if it is labelled by a production (S, a) .P for some a. \nThe set of all derivation trees of G is denoted by TG. The yield .(T ) of a countable set T . Tr of \nS trees is de.ned by .(T )= t.T .(t). In the following, we mean derivation tree whenever we say tree. \nLEMMA 4 (Easy). Let G =(X , S, P,S) be a context-free gram\u00admar in program normal form. Then L(G) = .(TG). \nL(pr+2) By Lem. 4, proving L(G) .. (G) reduces to proving .(TG) .. L(pr+2)(G). We now introduce the notion \nof dimen\u00adsion of a tree. DEFINITION 8. The dimension d(t) of a tree t is inductively de\u00ad.ned as follows: \n1. If t has no children, then d(t)=0; 2. If t has exactly one child t1, then d(t)= d(t1); 3. If t has \nexactly two children t1 and t2, then  ( d(t1)+1 if d(t1)= d(t2)d(t)= max(d(t1),d(t2)) if d(t1)= d(t2). \nThe set of all derivation trees of dimension k for grammar G is denoted by T k G. The next lemma goes \nalong the lines of [8, Lem. 2.1], but with many small changes. LEMMA 5. Let G =(X , S, P,S) be a context-free \ngrammar in program normal form with pr procedure variables. Then .(TG) .. pr+1 S i=0 .(T i G). PROOF: \nIn this proof we write t = t1 \u00b7 t2 to denote that t1 is a derivation tree except that exactly one leaf \ne is labelled by a production of the form (A, a) with a = e; t2 is a derivation tree labelled (A, a ' \n) for some a '; and the tree t is obtained from t1 and t2 by replacing the leaf e =(A, a) of t1 by t2. \nWe want to prove that for every tree t . TG, there exists a tree ' '' t such that .(t)=. .(t ) and d(t \n) = pr +1. Let a tree t be compact if d(t) = L(t), where L(t) = 1+ L ' (t) and L ' (t) is the number \nof distinct procedure variables in t. We .nd that L ' (t) = pr for every t . TG, hence L(t) = pr +1. \nTo establish the above result, it suf.ces to show that for every tree t, there exists a compact tree \nt ' such that .(t)=. .(t ' ). The proof is by induction on the number of nodes of t. In the base case, \nt has just one node labelled (S, e), so d(t)=0 < 1 = L(t), hence t is compact, and we are done. In the \nfollowing, assume that t has more than one node and d(t) >L(t) holds. If t has exactly one child t1 then \nd(t)= d(t1) >L(t). Since t1 has one node less than t, induction hypothesis shows that t1 can be made \ncompact, i.e. d(t1) = L(t1). Next we conclude from the de.nition of L and the structure of t that L(t1) \n= L(t), also that d(t)= d(t1) and .nally that d(t) = L(t) and we are done. Let us turn to the case where \nt has two children t1 and t2. We assume w.l.o.g. that d(t) = d(t1) = d(t2). Finally, by the induction \nhypothesis, we can further assume that t1 and t2 are compact, i.e. d(ti) = L(ti) for i =1, 2. From the \nde.nition of dimension and L, t1 is a subtree of t, and d(t) >L(t) we .nd that: L(t)+1 = d(t) = d(t1)+1 \n= L(t1)+1 = L(t)+1. We conclude from above that d(t1)= L(t) and d(t)= d(t1)+1, hence that d(t1)= d(t2) \nby de.nition of dimension and .nally that d(t1)= d(t2)= L(t)= L(t1)= L(t2) since t1,t2 are compact subtrees \nof t. We now prove the following claim: there is a path in t2 from the root to a leaf such that two nodes \nare labelled by (Z, a) and (Z, a ' ) where Z is a procedure variable. Our proof is by contradiction. \nObserve that for derivation tree t with child t ' such that d(t) >d(t ' ), the de.nition of dimension \nand program normal form shows that t is labelled by (X, Z \u00b7Y ) for some variables X, Z and Y . If d(t)= \nk then the rooted path that goes down through the left child whenever possible has at least k nodes with \nlabel of the form (Z, a) where Z is a procedure variable. Finally since d(t2)= L(t2)= L ' (t2)+1 where \nL ' (t2) is the number of distinct procedure variables in t2, we .nd that two nodes are labelled (Z, \na) and (Z, a ' ) where Z is a procedure variable, hence a contradiction. abc bc So t2 can be factored \ninto t2 \u00b7 (t2 \u00b7 t2) such that t2 and t2 have their root labelled (Z, a) and (Z, a ' ) where Z is a procedure \nvariable. As L(t)= L(t1)= L(t2), we also .nd a node of t1 labelled (Z, a) where Z is a procedure variable \nwhich allows us to write ab b t1 = t1 \u00b7 t1 where t1 has its root labelled (Z, a) where Z is a procedure \nvariable. Now we cut out the middle part t2 b of t2, and insert it between ab ' a bb the two parts t1 \nand t1 of t1, so that we get t1 = t1 \u00b7 (t2 \u00b7 t1) and ' ac '' t2 = t2 \u00b7 t2. We then have L(t1)= L(t1)= \nL(t2) = L(t2). By '' '' induction, t1 and t2 can be made compact, so d(t1) = L(t1)= '' ' d(t1)= d(t2) \n= L(t2) = d(t2). Consider the tree t obtained from t by replacing t1 by t1 ' and t2 by t2' . Clearly, \n.(t)=. .(t ' ). If d(t1' ) <d(t1) or d(t2' ) <d(t2), then d(t ' ) = d(t)-1= L(t)= L(t ' ) by de.nition \nof dimension, and we are done because t ' is '' ' compact. Otherwise, we have d(t1)= d(t2)= L(t ' )= \nL(t1)= L(t2' ). So we can iterate the above procedure and insert a part of t2 ' into t1' . This procedure \nterminates, because the transfer of nodes from the second child to the .rst cannot proceed forever. D \nL(pr+2) By this lemma, proving .(TG) .. (G) reduces to S pr+1 G) .. L(pr+2) showing .(TG) ..S i=0 .(T \ni (G). To conclude pr+1 G) . L(pr+2) the proof we show i=0 .(T i (G). G) . L(k+1) LEMMA 6. For every \nk = 0: .(T k (G). PROOF: Let t be a derivation tree of dimension k. The proof is by induction on the \nstructure of t. Base. t consists of a node labelled (S, e), hence k =0 and S . e is of index 1. Step. \nW.l.o.g. t has two children t1 and t2 such that d(t) = d(t1) = d(t2). By the de.nition of dimension we \nhave d(t2) = k - 1. Let A, A1 and A2 be the roots of t, t1 and t2, respectively. Then A . A1A2 is a production \nof the grammar. By induction hypothesis, there are derivations A1 . * w1 of index k +1 and A2 w2 of index \nk. So there is a derivation A . A1A2 . * . * A1w2 . * w1w2 of index k +1. D Collecting the results above, \nwe get: THEOREM 7. For every context-free grammar G in program nor\u00admal form with pr procedure variables, \n.(L(AG)) = .(L(G)). PROOF: In [8, Prop 2.1], L(A) .. L(G) has been proved. For the reverse inclusion: \nL(G) = .(TG) .. S pr+1 i=0 .(T i G) Lem. 4 Lem. 5 . L(pr+2)(G) Lem. 6 .. L(AG) [8, Lem. 2.4] D COROLLARY \n1. Given a context-free grammar G with pr proce\u00addure variables, we can construct in O(|G|(pr+2)) time \na regular grammar AG such that .(L(G)) = .(L(AG)). PROOF: Follows immediately from the fact that the \nnumber of vari\u00adables of the regular grammar AG of Def.5 for a context-free gram\u00admar G with n variables \nand pr procedure variables is O(npr+2). D Step 2. Given regular grammars A1,...,Ag over an alphabet \nof T size al, we show that ig =1 .(L(Ai)) = \u00d8can be checked in time O((|A1| + \u00b7\u00b7\u00b7 + |Ag|)h(g,al)) for \na function h. It is well known that for every regular grammar A, the set .(L(A)) is semilinear. It has \nbeen recently proved that .(L(A)) is small . THEOREM 8. [29, Th. 4.1] Let A be a regular grammar with \nn variables over alphabet S of size al. There exists a representation S m of .(L(A)) . Nal as a union \nof linear sets j=1 L(cj ; Pj ), where m is polynomial in n and exponential in al, the maximum entry of \neach cj is polynomial in n and exponential in al, the number of periods in each Pj is at most al, and \nthe maximum entry of each period is at most n. Furthermore, this is computable in time polynomial in \nn and exponential in al. This theorem suggests the following procedure to check T g .(L(Ai)) = \u00d8 for \n.xed g. First, compute for each Ai a i=1 representation of .(L(Ai)) as given above. This is done in polyno\u00admial \ntime in the number of variables of Ai since S is of .xed size. Then, for each tuple (L(c1; P1),...,L(cg; \nPg)), where L(ci; Pi) is a linear set of .(L(Ai)), check if ngi=1L(ci; Pi)= \u00d8. Since g and al are .xed, \nthe number of tuples is polynomial, and so in order to obtain a polynomial procedure we just need to \nprove that ngi=1L(ci; Pi)= \u00d8 can be checked in polynomial time. For this we .rst reduce the problem to \nsolving a system of linear equations over the natural numbers. DEFINITION 9. Let t = (L(c1; P1),...,L(cg; \nPg)) be a tuple of no (1) (ji) linear sets of dimension al, where Pi = pi ,...,pi . The existential Presburger \nformula Ft is given by ^ (1) (j1) (1) (jg) .x1 ,...,x1 ,...,xg ,...,x g : f(id, id +1,e) 1=id=g-1 1=e=al \nwhere f(id, id ' ,e) denotes the formula j jidid' XX (i)(i)(i)(i) cid (ae)+ x* p(ae)= cid' (ae)+ x. idid \nid' * pid' (ae) i=1 i=1 In the above de.nition, the subformula f(id, id ' ,e) has the fol\u00adlowing interpretation: \nf(id, id ' ,e) is satis.able iff there exist v . L(cid ; PidV) and v ' . L(cid' ; Pid' ) such that v(e)= \nv ' (e). Therefore f(id, id ' ,e) is satis.able iff L(cid ; Pid ) 1=e=al and L(cid' ; Pid' ) have a common \nvector, i.e., iff L(cid ; Pid ) n VV L(cid' ; Pid' )= \u00d8. So f(id, id +1,e) is 1=id=g-11=e=al satis.able \niff ngi=1L(ci; Pi)= \u00d8. Hence the following result. LEMMA 7. Let t = (L(c1; P1),...,L(cg; Pg)) be a tuple \nof lin\u00adear sets. We have ngi=1L(ci; Pi)= \u00d8iff Ft is satis.able. Assume now that the maximum entries and \nnumber of periods of the linear sets in the tuple t of Def. 9 are as given in Th. 8. An inspection of \nthe formula Ft in Def. 9 shows that in this case the number of variables of Ft is at most g * al, and \nso that Ft is an existential Presburger formula with g * al quanti.ers and no free variables. Since g \nand al are .xed parameters, g *al is also .xed. It follows that the satis.ability of Ft can be determined \nin polynomial time by means of the Lenstra-Scarpellini s algorithm [22, 27] (see also [12]). This concludes \nthe proof that given regular grammars A1,...,Ag T over an alphabet of size al, whether gi=1 .(L(Ai)) \n= \u00d8holds or not can be determined in polynomial time. 6. Conclusions We have studied the complexity \nof pattern-based veri.cation, an approach to the veri.cation of multithreaded programs essentially introduced \nby Kahlon in [15]. The approach asks the programmer ** to supply a pattern, a regular expression of \nthe form w1 ...w n over the alphabet of channels (and possibly other program instructions). The veri.cation \ntool then analyzes whether the program has some execution that uses the channels conforming to the pattern. \nThe expressivity of pattern-based veri.cation was .rst investi\u00adgated in [9], where it was shown that \ncontext bounding, the tech\u00adnique introduced by Qadeer and Rehof in [25] and implemented in CHESS, SPIN, \nSLAM, jMoped, and other tools [1, 5, 20, 28, 30], is a special case of pattern-based veri.cation. In \nthis paper we provide a further analysis and give a explicit reduction. We have reduced the pattern-based \nveri.cation problem to nDMP, the problem of deciding whether the intersection of a given set of context-free \ngrammars and a pattern is nonempty. Putting together classical results by Ginsburg and Spanier [11] about \nbounded context-free languages; the characterization of the Parikh images of context-free languages given \nin [7]; the encoding of this characterization into existential Presburger arithmetic presented in [31]; \nand the fact that existential Presburger arithmetic reduces to solving a system of linear Diophantine \nequations (well-known to be in NP [32]) we have shown that nDMP is NP-complete. Since context bounding \nis also NP-complete, the additional expressivity of pattern-based veri.cation does not come at an extra \ncost in terms of asymptotic complexity. We have conducted a multiparameter analysis of nDMP on the number \nof threads, the maximum number of procedures per thread, the maximal size of a procedure, and the size \nof the pattern. By requiring the value of a parameter to be .xed or not, we get 16 cases. We have shown \nthat all except one are either trivially polynomial or still NP-complete. The analysis of the remaining \ncase (all parameters .xed except the maximal size of a procedure) is the main technical contribution \nof the paper. Using a novel constructive proof of Parikh s theorem and recent results about the Parikh \nimages of nondeterministic automata [19, 29], we have shown that this case is polynomial. Given the high \ncomplexity of automatic veri.cation of multithreaded procedural programs (unless strong constraints like \nabsence of communication between threads or restriction to local properties of a thread are imposed) \nwe think that this is a remarkable result. Two comments about our model are in order. First, while we \nhave only considered abstracted programs (i.e., we assume that all program paths with (1) correct nesting \nof procedure calls and re\u00adturns, and (2) correct synchronization over channels, are feasible), our approach \ncan also be applied to boolean programs at the price of an increase in the size of the procedures and \nthe number of pro\u00adcedures per thread. Notice that context bounding and other tech\u00adniques face the same \nproblem. Second, we have opted for a com\u00admunication model based on rendez-vous ` a la CSP. The reason \nis convenience: the connection between the veri.cation problem and the emptiness problem for the intersection \nof context-free gram\u00admars is easier to describe in this model. Our approach can also be applied to other \ncommunication mechanisms by suitably choosing the alphabet of the patterns. Related work. The automatic \nveri.cation of safety properties for multithreaded programs with possibly recursive procedures has been \nintensively studied in the last years. The program is usually modeled as a set of pushdown systems communicating \nby some means. Several special cases with restricted communication have been proved decidable, including \ncommunication through locks satisfying certain conditions, linearly ordered multi-pushdown sys\u00adtems, \nand systems with acyclic communication structure (also satis\u00adfying some additional conditions) [2, 3, \n14 17]. Several recent pa\u00adpers study the automatic veri.cation of parametric programs with an arbitrary \nnumber of procedures [18] and with dynamic creation of procedures [4, 6], two features that we have not \nconsidered in this paper. From a complexity point of view, pattern-based ver\u00adi.cation lies together with \ncontext-bounding and communication through locks at the lower end of the spectrum. Other approaches require \nexponential time, but do not belong to NP (or this is not known), or are superexponential. The only other \ncase we know of a problem with polynomial complexity in the size of the program is the veri.cation of \nsingle-index properties (close to local reachabil\u00adity) in systems communicating through locks [17]. \nAcknowledgement. Many thanks to Mikolaj Boja\u00b4 nczyk for pro\u00adviding the proof of Theorem 1, to Anthony \nWidjaja To for sug\u00adgesting a more direct polynomial time algorithm using [22, 27], to Michael Luttenberger \nand Andrey Rybalchenko for helpful dis\u00adcussions, and .nally to the anonymous reviewers for their helpful \ncomments and to Tomas Poch for pointing typos in the manuscript. References [1] CHESS: Find and reproduce \nheisenbugs in concurrent programs. URL http://research.microsoft.com/en-us/projects/CHESS/. [2] M. F. \nAtig, B. Bollig, and P. Habermehl. Emptiness of multi-pushdown automata is 2EXPTIME-complete. In DLT \n08: Proc. 12th Int. Conf. on Developments in Language Theory, volume 5257 of LNCS, pages 121 133. Springer, \n2008. [3] M. F. Atig, A. Bouajjani, and T. Touili. On the reachability analysis of acyclic networks of \npushdown systems. In CONCUR 08: Proc. 19th Int. Conf. on Concurrency Theory, volume 5201 of LNCS, pages \n356 371. Springer, 2008. [4] M. F. Atig, A. Bouajjani, and S. Qadeer. Context-bounded analysis for concurrent \nprograms with dynamic creation of threads. In TACAS 09: Proc. 15th Int. Conf. on Tools and Algorithms \nfor the Construction and Analysis of Systems, volume 5505 of LNCS, pages 107 123. Springer, 2009. [5] \nT. Ball and S. K. Rajamani. The SLAM project: debugging system software via static analysis. In POPL \n02: Proc. 29th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, pages 1 3. ACM Press, \n2002. [6] A. Bouajjani, M. M\u00a8uller-Olm, and T. Touili. Regular symbolic anal\u00adysis of dynamic networks \nof pushdown systems. In CONCUR 05: Proc. 16th Int. Conf. on Concurrency Theory, volume 3653 of LNCS, \npages 473 487. Springer, 2005. [7] J. Esparza. Petri nets, commutative context-free grammars, and basic \nparallel processes. Fundamenta Informaticae, 31:13 26, 1997. [8] J. Esparza, P. Ganty, S. Kiefer, and \nM. Luttenberger. Parikh s theorem: A simple and direct construction. CoRR, 1006.3825, 2010. [9] P. Ganty, \nB. Monmege, and R. Majumdar. Bounded underapproxima\u00adtions. In CAV 10: Proc. 20th Int. Conf. on Computer \nAided Veri.ca\u00adtion, volume 6174 of LNCS, pages 600 614. Springer, 2010. [10] M. R. Garey and D. S. Johnson. \nComputers and Intractability, A Guide to the Theory of NP-Completeness. New York, 1979. [11] S. Ginsburg \nand E. H. Spanier. Semigroups, presburger formulas, and languages. Paci.c Journal of Mathematics, 16(2):285 \n296, 1966. [12] E. Graedel. Subclasses of presburger arithmetic and the polynomial\u00adtime hierarchy. Theoretical \nComputer Science, 56(3):289 301, 1988. [13] J. E. Hopcroft and J. D. Ullman. Introduction to Automata \nTheory, Languages and Computation. Addison-Wesley, 1st edition, 1979. [14] V. Kahlon. Boundedness vs. \nunboundedness of lock chains: Charac\u00adterizing decidability of pairwise c.-reachability for threads communi\u00adcating \nvia locks. In LICS 09: Proc. 24th Annual IEEE Symp. on Logic in Computer Science, pages 27 36. IEEE Computer \nSociety, 2009. [15] V. Kahlon. Tractable data.ow analysis for concurrent programs via bounded languages. \nPatent WO/2009/094439, July 2009. [16] V. Kahlon and A. Gupta. On the analysis of interacting pushdown \nsystems. In POPL 03: Proc. 30th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages, pages \n303 314. ACM, 2007. [17] V. Kahlon, F. Ivancic, and A. Gupta. Reasoning about threads com\u00admunicating \nvia locks. In CAV 05: Proc. 17th Int. Conf. on Computer Aided Veri.cation, volume 3576 of LNCS, pages \n505 518. Springer, 2005. [18] A. Kaiser, D. Kroening, and T. Wahl. Dynamic cutoff detection in parameterized \nconcurrent programs. In CAV 10: Proc. 20th Int. Conf. on Computer Aided Veri.cation, volume 6174 of LNCS. \nSpringer, 2010. [19] E. Kopczy\u00b4nski and A. W. To. Parikh images of grammars: Complexity and applications. \nIn LICS 10: Proc. 25th Annual IEEE Symp. on Logic in Computer Science. IEEE, 2010. [20] A. Lal and T. \nReps. Reducing concurrent analysis under a context bound to sequential analysis. In CAV 08: Proc. 20th \nInt. Conf. on Computer Aided Veri.cation, volume 5128 of LNCS, pages 37 51. Springer, 2008. [21] A. Lal, \nT. Touili, N. Kidd, and T. W. Reps. Interprocedural analysis of concurrent programs under a context bound. \nIn TACAS 08: Proc. 14th Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems, \nvolume 4963 of LNCS, pages 282 298. Springer, 2008. [22] J. Lenstra, H. W. Integer programming with a \n.xed number of vari\u00adables. Mathematics of Operations Research, 8(4):538 548, 1983. [23] R. J. Parikh. \nOn context-free languages. Journal of the ACM, 13(4): 570 581, 1966. [24] S. Qadeer. The case for context-bounded \nveri.cation of concurrent programs. In SPIN 08: Proc. of 15th Int. Model Checking Software Workshop, \nvolume 5156 of LNCS, pages 3 6. Springer, 2008. [25] S. Qadeer and J. Rehof. Context-bounded model checking \nof concur\u00adrent software. In TACAS 05: Proc. 11th Int. Conf. on Tools and Algo\u00adrithms for the Construction \nand Analysis of Systems, volume 3440 of LNCS, pages 93 107. Springer, 2005. [26] G. Ramalingam. Context-sensitive \nsynchronization-sensitive analysis is undecidable. ACM TOPLAS, 22(2):416 430, 2000. [27] B. Scarpellini. \nComplexity of subcases of presburger arithmetic. Trans. of the American Mathematical Society, 284(1):203 \n218, 1984. [28] D. Suwimonteerabuth, J. Esparza, and S. Schwoon. Symbolic context\u00adbounded analysis of \nmultithreaded java programs. In SPIN 08: Proc. of 15th Int. Model Checking Software Workshop, volume \n5156 of LNCS, pages 270 287. Springer, 2008. [29] A. W. To. Parikh images of regular languages: Complexity \nand appli\u00adcations. CoRR, 1002.1464, 2010. [30] S. La Torre, G. Parlato, and P. Madhusudan. Reducing context\u00adbounded \nconcurrent reachability to sequential reachability. In CAV 09: Proc. 21st Int. Conf. on Computer Aided \nVeri.cation, volume 5643 of LNCS, pages 477 492. Springer, 2009. [31] K. N. Verma, H. Seidl, and T. Schwentick. \nOn the complexity of equational horn clauses. In CADE 00: 20th Int. Conf. on Automated Deduction, volume \n1831 of LNCS, pages 337 352. Springer, 2005. [32] J. von zur Gathen and M. Sieveking. A bound on solutions \nof linear in\u00adteger equalities and inequalities. Proc. of the American Mathematical Society, 72:155 158, \n1978. A. Reduction of nDMP to nDPK   A.1 Construction of the grammar Gf ** (i)(i) Let p = w1 ...w \n, and let wi = b...bfor every 1 = i = n. n1 ji Let Gp =(X p , S,dp,q1(1)) be the regular grammar where \nn o X p = qr (s) | 1 = s = n . 1 = r = js n o (s)(s)(s) dp = q. bq| 1 = s = n . 1 = i<js . i ii+1 n (s)(s)(s \n' ) ' o q. bq| 1 = s = s = n . js js 1 n o q(s) . e | 1 = s = n. 1 S n It is routine to check that i=1 \nL (i) (Gp)= L(w1 * ...w * ). n q 1 Given Gp and a grammar G =(X , S, P,S) in program normal form our \ngoal is to de.ne a grammar for the language -1 ** h(L(G) n L(p)) n L(a1 ...a n) . We .rst de.ne Grx =(X \nrx , S, Prx,X0) which, as we prove later, satis.es L(Grx)= L(G) n L(p): n o X rx (s)(x)(s)(x) = {X0}. \n[qr Xqy ] | X .X ,qr ,qy .X p,s = x Prx is the set containing for every 1 = s = x = n a production (s)(x) \nX0 . [q1 Sq1 ] and: for every production X . e .P of G and for every 1 = s = n, 1 = r = js a production \n(s)(s) [qr Xqr ] . e ; (15) for every production X . Y .P of G and for every 1 = s = u = n, 1 = r = js, \n1 = v = ju a production (s)(s) [qXq(u)] . [qYq(u)]; (16) rv rv for every production X . . \u00b7 Y .P of G \nwith . . S and for every 1 = s = u = n, 1 = r = js, 1 = v = ju productions (s)(u)(s)(u) [qr Xqv ] . . \n\u00b7 [qr+1Yqv ] if r<js and . = b(rs); and (17) (s)(u)(s ' )(u) x [qjs Xqv ] . . \u00b7 [q1 Yqv ] .Pr (s) ' if \n. = bjs and s = s = u (18) for every production X . ZY .P of G and for every 1 = s = u = x = n, 1 = r \n= js, 1 = v = ju, 1 = y = jx a production (s)(x)(s)(u)(u)(x) [qr Xqy ] . [qr Zqv ][qv Yqy ] . (19) In \nwhat follows, we use X . a to indicate that the derivation G is carried out using the productions of \nthe grammar G. (s)(u) * (s) * LEMMA 8. Let w . S *. We have [qr Xqv ] . w iff qr . GN Gp w \u00b7 qv (u) and \nX . * w. G PROOF: The proof for the only if direction is by induction on the (s)(u) length of the derivation \nof [qr Xqv ] . * w. (s)(s) i = 1. Then [qr Xqr ] . e. The de.nition of Grx shows that X . e .P, and so \nX . e. i > 1. We do a case analysis according to the de.nition of Grx . (s)(u)(s)(u) [qr Xqv ] . [qr \nYqv ] . * w. It is trivially solved using the induction hypothesis. (s)(u)(s)(u) [qr Xqv ] . . \u00b7 [qr+1Yqv \n] . * .w '. The de.nition of x (s) Grshows that . = br for some r<js. The production (s)(s)(s) qr . br \n\u00b7 qr+1 . dp and induction hypothesis show that (s)(s)(s)(s) ' (u) qr . br \u00b7 qr+1 . * br w \u00b7 qv . Also \nthe production X . . \u00b7 Y .P and induction hypothesis show that X . ' (s) . \u00b7 Y . * . \u00b7 w and we are done \nsince . = br . (s)(u)(s)(s )(u)(s) [qXqv ] . b\u00b7 [q' Yqv ] . * b\u00b7 w '. The production js js 1 js (s)(s)(s \n' ) q. b\u00b7 q. dp and induction hypothesis show that js js 1 (s)(s)(s ' )(s) ' (u) qjs . bjs \u00b7 q1 . * bjs \nw \u00b7 qv . Also the production X . . \u00b7 Y .P where . = bj(ss ) and the induction hypothesis show that X \n. . \u00b7 Y . * . \u00b7 w ' and we are done. (s)(x)(s)(u)(u)(x)(u)(x) [qr Xqy ] . [qr Zqv ][qv Yqy ] . * w1\u00b7[qv \nYqy ] . * (s) . * w1w2 = w. By induction hypothesis, we have qr (u) (u)(x) w1 \u00b7qv and Z . * w1. Also \nqv . * w2 \u00b7qy and Y . * w2. (s)(x) Hence we .nd that qr . * w1w2 \u00b7qy and X . * w1w2 since X . Z \u00b7 Y .P \nwhich concludes this case since w = w1w2.  Using a similar induction on the length of X . * w, the if \ndirection is easily proved. D We now obtain a grammar Gf by slightly modifying Grx. We change the productions \nof (17) and (18) respectively to (s)(u)(s)(u)(s)(u)(s ' )(u) [qr Xqv ] . [qr+1Yqv ] and [qjs Xqv ] . \nas \u00b7[q1 Yqv ] where as . Se. Because of this change, Gf has alphabet Se. Also, it is routine to check \nthat this change amounts to applying the inverse homomorphism h-1 and taking the intersection with L(a1 \n* ...a n* ). A.2 Proof of Lemma. 1 Given p = w1 * ...w * and a grammar G in program normal form, n we \nhave that Gf satis.es each of the following properties: L(Gf ) . Se* where e}; S= {a1,...,an L(Gf )= \nh-1(L(G) n L(p)) n L(a1 * ...a * ); n Gf is in program normal form;  Gf is computable in polynomial \ntime;  If pr is the number of procedure variables in G, then Gf has O(pa 2 \u00b7 pr) procedure variables \nwhere pa is the size of p.  PROOF: The .rst item is obvious from the de.nition of Gf . Let Gf =(X f \n, Se, Pf ,X0). If follows directly from Lem. 8 that for * (s) * (x) every w . S * , X0 . w iff q1 . \nw\u00b7q1 where 1 = s = x = N GGp n o * (s) n and S . w. The productions q. e | 1 = s = n . dp 1 G of Gp \nshows that the equivalence can be rewritten as follows: ** * X0 . w iff q1(s) . w where 1 = s = n and \nS . w. We GN Gp G S conclude from the de.nition of Gp that L(p)= ni=1 L (i) (Gp), q 1 hence that L(Grx)= \nL(G) n L(p), and .nally that L(Gf )= h-1x** (L(Gr)) n L(a1 ...a n). The second item is immediate from \nthe de.nition of Gf and that G is in program normal form. The third item is clear from the de.nition \nof Grx and Gf . For the fourth item, we have that since pa is the size of p, pa is also the size of X \np by de.nition of Gp. Also (19) shows that each procedure variable in G yields O(pa 2) procedure variables \nin G, hence if pr is the number of procedure variables in G we .nd that the number of procedure variables \nin Grx, hence Gf is O(pa 2 \u00b7 pr). D  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>Pattern-based verification checks the correctness of the program executions that follow a given <i>pattern</i>, a regular expression over the alphabet of program transitions of the form <i>w</i><sub>1</sub>* ... <i>w</i><sub>n</sub>*. For multithreaded programs, the alphabet of the pattern is given by the synchronization operations between threads. We study the complexity of pattern-based verification for <i>abstracted</i> multithreaded programs in which, as usual in program analysis, conditions have been replaced by nondeterminism (the technique works also for boolean programs). While unrestricted verification is undecidable for abstracted multithreaded programs with recursive procedures and PSPACE-complete for abstracted multithreaded while-programs, we show that pattern-based verification is NP-complete for both classes. We then conduct a multiparameter analysis in which we study the complexity in the number of threads, the number of procedures per thread, the size of the procedures, and the size of the pattern. We first show that no algorithm for pattern-based verification can be polynomial in the number of threads, procedures per thread, or the size of the pattern (unless P=NP). Then, using recent results about Parikh images of regular languages and semilinear sets, we present an algorithm exponential in the number of threads, procedures per thread, and size of the pattern, but polynomial in the size of the procedures.</p>", "authors": [{"name": "Javier Esparza", "author_profile_id": "81100206259", "affiliation": "Technische Universit&#228;t M&#252;nchen, M&#252;nchen, Germany", "person_id": "P2509670", "email_address": "esparza@model.in.tum.de", "orcid_id": ""}, {"name": "Pierre Ganty", "author_profile_id": "81392617027", "affiliation": "The IMDEA Software Institute, Madrid, Spain", "person_id": "P2509671", "email_address": "pierre.ganty@imdea.org", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926443", "year": "2011", "article_id": "1926443", "conference": "POPL", "title": "Complexity of pattern-based verification for multithreaded programs", "url": "http://dl.acm.org/citation.cfm?id=1926443"}