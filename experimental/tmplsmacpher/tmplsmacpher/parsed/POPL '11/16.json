{"article_publication_date": "01-26-2011", "fulltext": "\n Blame for All Amal Ahmed Robert Bruce Findler Jeremy G. Siek Indiana University Northwestern University \nUniversity of Colorado at Boulder amal@cs.indiana.edu robby@eecs.northwestern.edu jeremy.siek@colorado.edu \nPhilip Wadler University of Edinburgh wadler@inf.ed.ac.uk Abstract Several programming languages are \nbeginning to integrate static and dynamic typing, including Racket (formerly PLT Scheme), Perl 6, and \nC# 4.0 and the research languages Sage (Gronski, Knowles, Tomb, Freund, and Flanagan, 2006) and Thorn \n(Wrigstad, Eug\u00adster, Field, Nystrom, and Vitek, 2009). However, an important open question remains, which \nis how to add parametric polymorphism to languages that combine static and dynamic typing. We present \na system that permits a value of dynamic type to be cast to a polymor\u00adphic type and vice versa, with \nrelational parametricity enforced by a kind of dynamic sealing along the lines proposed by Matthews and \nAhmed (2008) and Neis, Dreyer, and Rossberg (2009). Our system includes a notion of blame, which allows \nus to show that when casting between a more-precise type and a less-precise type, any cast failures are \ndue to the less-precisely-typed portion of the program. We also show that a cast from a subtype to its \nsupertype cannot fail. Categories and Subject Descriptors D.3.3 [Language Constructs and Features]: Procedures, \nfunctions, and subroutines General Terms Languages, Theory Keywords casts, coercions, blame tracking, \nlambda-calculus 1. Introduction The long tradition of work that integrates static and dynamic types includes \nthe partial types of Thatte (1988), the dynamic type of Abadi et al. (1991), the coercions of Henglein \n(1994), the contracts of Findler and Felleisen (2002), the dynamic dependent types of Ou et al. (2004), \nthe hybrid types of Gronski et al. (2006), the grad\u00adual types of Siek and Taha (2006), the migratory \ntypes of Tobin-Hochstadt and Felleisen (2006), the multi-language programming of Matthews and Findler \n(2007), and the blame calculus of Wadler and Findler (2009). Integration of static and dynamic types \nis a fea\u00ad ture of .NET languages including Visual Basic and C#, is being ex\u00adplored for Javascript, Perl, \nPython, and Ruby, and is the subject of the recent STOP 2009 workshop held in conjunction with ECOOP. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL \n11, January 26 28, 2011, Austin, Texas, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. \n. . $10.00 A unifying theme in this work is to use casts to mediate between statically and dynamically \ntyped code. Casts may be introduced by compiling to an intermediate language; the blame calculus may \nbe regarded as either such an intermediate language or as a source language. The main innovation of the \nblame calculus is to assign positive and negative blame (to either the term contained in the cast or \nthe context containing the cast), with associated notions of positive and negative subtype. These support \nthe Blame Theorem, which ensures that when a program goes wrong, blame lies with the less-precisely-typed \nside of a cast (Wadler and Findler, 2009). In this paper, we extend a fragment of the blame calculus \nto incorporate polymorphism, based on a notion of dynamic sealing. For simplicity, our fragment includes \nbase types, function types, and the dynamic type, as found in gradual types, but omits subset types, \nas found in hybrid types. Our system adds the ability to cast a value of dynamic type to a polymorphic \ntype and vice versa. We name this system the polymorphic blame calculus. A fundamental semantic property \nof polymorphic types is re\u00adlational parametricity, as introduced by Reynolds (1983). Our sys\u00ad tem uses \ndynamic sealing to ensure that values of polymorphic type satisfy relational parametricity. For instance, \nevery function of type .X. X.X must either be the identity function (one which always returns its argument) \nor an unde.ned function (one which never returns a value), and this property holds true even for values \nof dy\u00adnamic type cast to a polymorphic type. Relational parametricity un\u00adderlies some program optimizations, \nnotably shortcut deforestation as employed by the Glasgow Haskell Compiler (Gill et al., 1993). Our system \nmay guarantee the validity of such optimizations even in the presence of dynamic types. Dynamic sealing \nto enforce parametricity has a long history. Sealing for data abstraction goes back at least to Morris \n(1973). Cryptographic sealing for parametricity was introduced by Pierce and Sumii (2000). Extending \ncasts to include seals, while demon\u00ad strating relational parametricity, was .rst explored in the context \nof multi-language programming by Matthews and Ahmed (2008). A practical implementation for Scheme contracts \nwas described by Guha et al. (2007). Recently, Neis et al. (2009) used dynamic seal\u00ad ing to restore parametricity \nin a non-parametric language. Our development is supported by the use of type bindings to control the \nscope of type variables, both statically and dynamically. Type bindings are closely related to constructs \nfor generating new type names (Neis et al., 2009; Rossberg, 2003); an important differ\u00ad ence is that \nour type bindings are immobile, that is, there is no scope extrusion. Our development also uses static \ncasts to conceal and re\u00adveal the representations of type variables. Together with type bind\u00adings, static \ncasts provide a syntactic means to preserve the type\u00adhiding nature of type abstractions after they are \ninstantiated. Static casts play an important role in the static semantics of our system but a lesser \nrole in the dynamic semantics. As such, static casts are implicit in our main system (as in Neis et al. \n(2009)). However, we use an explicit version of the static casts as a technical device in our proof of \nthe Subtyping Theorem. The explicit casts are closely related to the coercions of Rossberg (2003) and \nare reminiscent of the syntactic type abstractions of Grossman et al. (2000).  We present three technical \nresults in this paper. The .rst result is the Jack-of-All-Trades Principle (Sections 6.3 and 11), which \njusti.es the way we implement casts that instantiate polymorphic values. The second result is the Blame \nTheorem (Section 8), which states that when casting between a less-precise type and a more\u00adprecise type, \nany cast failures are due to the less-precisely-typed portion of the program. The .nal result is the \nSubtyping Theorem (Section 9), which states that a cast from a subtype to a supertype cannot lead to \nblame for that cast. We do not present a relational parametricity result; that result is forthcoming \nand will be an adap\u00adtation of the result by Matthews and Ahmed (2008). The paper comes with a Redex model \ncovering some of the systems in this paper, available online: http://plt.eecs.northwestern.edu/blame-for-all/ \n This paper is an improved version of a paper in STOP 2009. The current paper is completely rewritten \n(and has lost one author and gained another). Among the more signi.cant differences, we use type bindings \nas compared to a global store; and we prove the Subtyping Theorem, a conjecture in the earlier paper. \n2. From untyped to typed The blame calculus provides a framework for integrating typed and untyped programs. \nOne scenario is that we begin with a program in an untyped language and we wish to convert it to a typed \nlanguage. Here is a simple untyped program. * let pos= I.x.x > 0l in * let app= I.f..x.f xl in * Iapppos* \n1l It returns Itruel : *. We indicate untyped code by surrounding it with ceiling brackets, I\u00b7l. Untyped \ncode is really uni-typed (a slogan due to Harper (2007)); it is a special case of typed code where every \nterm has the dynamic type, *. To aid the eye, we sometimes write variables of type * with a superscript \n*. Here is the same program, rewritten with types. let pos = .x : I.x > 0 in let app =.X. .Y. .f : X.Y. \n.x : X.f x in app IB pos 1 This program returns true : B. As a matter of software engineering, when we \nadd types to our code we may not want to do so all at once. Of course, it is trivial to rewrite a three-line \nprogram. However, the technique described here is intended to apply also when each one-line de.nition \nis replaced by a thousand-line module. We manage the transition between untyped and typed code with a \nrelatively new construct (Gronski et al., 2006; Siek and Taha, 2006) with an old name, cast . Casts can \nbe between any two compatible types. Roughly speaking, type A is compatible with type B when a value \nof type A can be coerced to type B. We are particularly interested in the case where either the source \ntype is * (corresponding to importing untyped code into typed code), or where the target type is * (corresponding \nto importing typed code into untyped code). We introduce an order on types corresponding to precision, \nwhere * is the least precise type. We introduce a notion of blame associated with casts, so that we can \nprove the following result: if a cast between a less-precise type and a more\u00adprecise type fails, then \nblame falls on the less-precise side of the cast. An immediate corollary is that if a cast between untyped \nand typed code fails, blame lies with the untyped code well-typed programs can t be blamed . A cast from \na more-precise type to a less-precise type is called widening. Here is the above program rewritten to \ndemonstrate widening. It is mostly untyped, but contains one typed component cast for use in an untyped \ncontext. * let pos= I.x.x > 0l in let app =.X. .Y. .f : X.Y. .x : X.f x in * let app= app : .X. .Y. (X.Y \n).X.Y .p * in * Iapppos* 1l It returns Itruel : *. Every cast is annotated with a blame label, used to \nascribe fault if the cast fails. The cast in the above program has blame label p. Our notation is chosen \nfor clarity rather than compactness. Writ\u00ading the source type of the cast is redundant; the type of the \nsource can always be inferred. In a practical language, we would expect the source type to be elided. \nOf course, the untyped context may not satisfy the constraints required by the typed term. If in the \nabove we replace ** * Iapppos1l by Iapp1 pos*l it now returns blame p. Blaming p (rather than p) indicates \nthat the fault lies with the context containing the cast labelled p (rather than the term contained in \nthe cast). This is what we expect, because the context is untyped. Passing a polymorphically typed value \ninto an untyped context requires an appropriate instantiation for the type parameters. As you might guess, \nin this case the type parameters X and Y are instantiated to *. However you might not guess that instantiating \nto * always works, regardless of whether the target is * or something more precisely typed. One of the \ncontributions of this paper is to prove the Jack-of-All-Trades Principle: if instantiating a type parameter \nto any given type yields an answer then instantiating that type parameter to * yields the same answer. \nA cast from a less-precise type to a more-precise type is called narrowing. Here is the above program \nrewritten to demonstrate narrowing. It is mostly typed, but contains one untyped component cast for use \nin a typed context. let pos = .x : I.x > 0 in * let app= I.f..x.f xl in * let app = app: * .p .X. .Y. \n(X.Y ).X.Y in app IB pos 1 This returns true : B. Of course, the untyped term may not satisfy the constraints \nrequired by the typed context. If in the above we replace I.f..x.f xl by I.f. .x. xl it now returns blame \np. Blaming p (rather than p) indicates that the fault lies with the term contained in the cast labelled \np (rather than the context containing the cast). This is what we expect, because the term is untyped. \nTo check for this error, the implementation must seal each value. That is, casting from type X to type \n* yields a value sealed with X, and attempting to cast from type * to type Y fails because the seals \nX and Y are distinct. One of the contributions of this paper is to work out the details of sealing in \na setting with dynamic types. One consequence of sealing is that typed terms always satisfy appropriate \nparametricity properties, even when they are derived by casting from untyped terms. We now begin our \nformal development.  3. Simply-typed lambda calculus All the systems in this paper extend a vanilla \ncall-by-value simply\u00adtyped lambda calculus, shown in Figure 1. We let A, B, and C range over types. A \ntype is either a base type . or a function type A.B. The base types include integers and Booleans, written \nI and B respectively. We let s and t range over terms. Terms include constants, primitive application, \nvariables, abstractions, and application. The variables v and w range over values. A value is either \na constant or an abstraction. We write G f t : A if term t has type A in type environment G. A type environment \nmaps variables to types. The function ty maps constants and primitive operators to their types. The function \nd maps an operator and a tuple of values to a value, and must preserve types. That is, if ty(op)= A .B \nand \u00b7f Av : A then there is a w such that d(op, Av )= w and \u00b7f w : B. Suitable choices of d can specify \narithmetic, conditional, and .xpoint operators. We write s -. t to indicate that redex s reduces to t, \nand write s -. t to indicate that reducing a redex inside s yields t. We let E range over evaluation \ncontexts, which are standard. 4. Simply-typed blame calculus Before proceeding to polymorphism, we review \nthe fundamentals of the simply-typed blame calculus, shown in Figure 2. The blame calculus extends the \nsimply-typed lambda-calculus with a dynamic type, written *, and with four term forms: dynamic casts, \ngrounded terms, type tests, and blame. One can think of the dynamic type * as the sum of all the base \ntypes plus the function type. * = I + B +(*.*) Accordingly, the ground types are the base types together \nwith the type *.*. Every value of dynamic type is constructed by a cast from ground type to dynamic type, \nwritten v : G . *. These casts can never fail, so they are not decorated with blame labels. For example, \nid* =(.x: *.x): *.* . * is a value of type *.A test s is G returns true if s evaluates to a value grounded \non G. For example, (1 : I . *) is I returns true. In general, a cast s : A .p B converts the value of \nterm s from type A to type B. Casts are decorated with blame labels. We assume an involutive operation \nof negation on blame labels: if p is a blame label then p is its negation, and p is the same as p. We \nwrite s : A .p B .q C as shorthand for (s : A .p B): B .q C. A cast from A to B is permitted only if \nthe types are compatible, written A -B. Every type is compatible with itself, the dynamic type is compatible \nwith every type, and functions are compatible if their domain and range are compatible; note the contravariance \nin the function rule. For now, compatibility is symmetric, but this will change in Section 6. Finally, \nthe term blame p indicates a failure, identifying the relevant label. Blame terms may have any type. \nWe now brie.y review the reduction rules. A cast from one function type to another reduces to a wrapper \nfunction that casts the argument, applies the original function, then casts the result note the reversal \nin the argument cast, and the corresponding negating of the blame label (WRAP). A cast from a ground \ntype to itself is the identity (ID). (The side condition G *.* avoids overlap = with (WRAP). For now, \nthe only ground type other than *.* is ., but this will change in Section 6.) A cast from type A to * \nfactors into a cast from A to the unique ground type G that is compatible with A followed by a cast from \nG to * (GROUND). Here we see the reason for distinguishing between casts and ground terms: otherwise \nwhenever the (GROUND) rule is applicable, it would be applicable in.nitely many times. A cast from * \nto type A examines the ground G of the value of type *. If G is compatible with A, the two casts collapse \nto a direct cast from G to A (COLLAPSE). If G is not compatible with A, the offending cast is blamed \n(CONFLICT). A test checks the ground of the value of type *. If it matches the test returns true, else \nit returns false (ISTRUE), (ISFALSE). An occurrence of blame p in an evaluation position causes the program \nto abort (ABORT). For example, say pos = .x : I.x > 0. Then (pos : I.B .p *.*) (1 : I . *) -. * pos (1 \n: I . * .p I): B .p * -. * pos 1: B .p * -. * true : B . * The function cast factors into a pair of \ncasts. The cast on the ranges retains the order and the blame label. The cast on the domains swaps the \norder and negates the blame label. The swap is required for types to work out. Negation of the blame \nlabel is required to assign blame appropriately, as can be seen by changing the argument: (pos : I.B \n.p *.*)(false : B . *) -. * pos (false : B . * .p I): B .p * -. * blame p The inner cast fails, ascribing \nblame to the label p on the cast. Blaming p (rather than p) indicates that the fault in the original \ncast lies with the context containing the cast (rather than the term contained in the cast). That is, \nwe blame the untyped context for failing to supply an integer rather than blame the typed function for \nfailing to accept a boolean. A cast from type dynamic to itself is the identity: ' v : * .p * -. v where \nv' is observationally equivalent to v. To see this, take v = w : G . *. Then w : G . * .p * -. w : G \n.p * -. w : G .p G . * via (COLLAPSE) and (GROUND). And a cast from a ground type to itself produces \neither an equivalent value, via (ID) or (WRAP). It is straightforward to de.ne an embedding I\u00b7l from \nthe un\u00adtyped lambda calculus into the blame calculus. Icl= c : ty(c) . * q Iop(AMl : A* .q*, if ty(op)= \nA .B M )l= op(IAA ): B .r Ixl= x I.x. Ml=(.x: *. IMl): *.* .q * IMNl=(IMl : * .q *.*) INl IM is Gl= IMl \nis G For example, I.x. xl =(.x: *.x): * .* . *. 5. Explicit binding The traditional way to reduce a \ntype application is by substitution, (.X. t) A -. t[X:=A]. We begin by explaining why this cannot work \nin our case, and then introduce a variant of the polymorphic lambda calculus with an explicit binding \nconstruct. 5.1 The problem A naive integration of casts and dynamic type with type substitution cannot \nensure relational parametricity. Say we wish to cast the untyped constant function K * = I.x. .y. xl \nto a polymorphic type. We consider two casts. K * : * .p .X. .Y. X.Y .X K * : * .p .X. .Y. X.Y .Y  \nSyntax Variables x, y Constants c Base types . ::= I | B Types A, B, C ::= . | A.B Type rules ty(c)= \n. G f At : AAty(op)= AA.B G f c : . G f op(At ): B Reduction rules (.x:A. t) v -. t[x:=v] op(Av ) -. \nd(op, Av ) Terms s, t ::= c | op(At ) | x | .x:A. t | ts Environments G ::= \u00b7| G,x : A Values v, w ::= \nc | .x:A. t Contexts E ::= [\u00b7] | op(Av, E,At ) | Es | vE G,x : A f t : B G f x : A G f .x:A. t : A.B \nG f ts : B x : A . GG f t : A.B G f s : A (BETA) s -. t (STEP) E[s] -. E[t] (DELTA) Figure 1. Simply-typed \nlambda calculus. Syntax Blame labels p, q Types A, B, C ::= . | A.B | * Ground types G, H ::= . | *.* \nTerms s, t ::= c | op(At ) | x | .x:A. t | ts | s : A .p B | s : G . * | s is G | blame p Environments \nG ::= \u00b7| G,x : A Values v, w ::= c | .x:A. t | v : G . * Contexts E ::= [\u00b7] | op(Av, E,At ) | Es | vE \n| E is G | E : A .p B | E : G . * Untyped terms M, N ::= c | op(MA) | x | .x. M | MN | M is G Type rules \n G f s : AA -B G f s : G G f s : * G f blame p : A G f (s : A .p B): B G f (s : G . *): * G f s is G \n: B Compatibility A ' B -B ' -A A -AA -** -B A.B -A ' .B ' Reduction rules '' '''' ' v : A.B .p A .B \n-. .x :A. (v (x : A .p A): B .p B ) (WRAP) v : G .p G -. v if G = *. * (ID) v : A .p * -. v : A .p G \n. * if A -G and A = * (GROUND)  v : G . * .p A -. v : G .p A if G -A (COLLAPSE) v : G . * .p A -. blame \np if G -A (CONFLICT)  (v : G . *) is G -. true (ISTRUE) (v : H . *) is G -. false if G = H (ISFALSE) \nE[blame p] -. blame p if E =[\u00b7] (ABORT)  Figure 2. Simply-typed blame calculus (extends Figure 1). We \nexpect the .rst cast to succeed and the second to fail, the latter because of parametricity. The parametricity \nproperty for the type .X. .Y. X.Y .Y guarantees that a value of this type must be either the .ipped constant \nfunction (which returns its second argument) or the unde.ned function (which never returns a value). \nSo an attempt to cast the constant function (which returns its .rst argument) to this type should fail. \nThe traditional way to reduce a type application is by substitu\u00adtion. This cannot work in our case! To \nsee why, consider reducing each of the above by substituting X:=I,Y :=I. (K * : * .p .X. .Y. X.Y .X) \nII 23 -. * (K * : * .p I.I.I)23 -. * 2 (K * : * .p .X. .Y. X.Y .Y ) II 23 -. * (K * : * .p I.I.I)23 \n-. * 2 Note how, in the second line of each reduction, the substitution has erased the difference between \nthe two programs the system has forgotten that the terms were once polymorphic. Thus, we see that special \nrun-time support is needed to enforce parametricity. In the literature, such run-time support is called \ndy\u00ad  Syntax Types A, B, C ::= . | A.B | X |.X. B Terms s, t ::= c | op(At ) | x | .x:A. t | ts | .X. \nt | tA | .X:=A. t Environments G ::= \u00b7| G,x : A | G,X | G,X:=A . ::= \u00b7| G,X | G,X:=A Values v, w ::= \nc | .x:A. t | .X. v Contexts E ::= [\u00b7] | op(Av, E,At ) | Es | vE | .X. E | EA | .X:=A. E Type rules G,X \nf t : B G,X:=A f t : B G f A X/. ftv(B) G f t : .X. B G f A (TYABS) (TYAPP) (NEW) G f .X. t : .X. B G \nf tA : B[X:=A]G f .X:=A. t : B G f t : B (X:=A) . GG f t : B[X:=A](X:=A) . G (REVEAL) (CONCEAL) G f t \n: B[X:=A]G f t : B Reduction rules (.X. v) A -. .X:=A. v (TYBETA) .X:=A. c -. c (NUCONST) .X:=A. (.y:B. \nt) -. .y:B[X:=A]. (.X:=A. t) (NUWRAP) .X:=A. (.Y. v) -. .Y. (.X:=A. v) if Y = X and Y ./ftv(A) (NUTYWRAP) \nFigure 3. Polymorphic lambda calculus with type bindings (extends Figure 1). Syntax Types A, B, C ::= \n. | A.B | * | X |.X. B Ground types G, H ::= . | *.* | X Terms s, t ::= c | op(At ) | x | .x:A. t | ts \n| s : A .p B | s : G . * | s is G | blame p | .X. t | tA | .X:=A. t Values v, w ::= c | .x:A. t | v : \nG . * | .X. v Contexts E ::= [\u00b7] | op(Av, E,At ) | Es | vE | E is G | E : A .p B | E : G . * | .X. E \n| EA | .X:=A. E Compatibility A -BA[X:=*] -B X/. ftv(A) A -.X. B .X. A -B Reduction rules (v : G . \n*) is G -. true if G = X for any X (ISTRUE) (v : H . *) is G -. false if G = H and H = X for any X (ISFALSE) \n (v : X . *) is G -. blame pis (ISTAMPER) .X:=A. (v : G . *) -. (.X:=A. v): G . * if G = X (NUGROUND) \n.X:=A. (v : X . *) -. blame p. (NUTAMPER) v : A .p (.X. B) -. .X. (v : A .p B) if X/. ftvA (GENERALIZE) \n v :(.X. A) .p B -. (v*): A[X:=*] .p B if B = * and B = .X ' .B ' for any X ' ,B ' (INSTANTIATE)  Figure \n4. Polymorphic blame calculus (extends and updates Figures 1, 2 and 3). namic sealing, which we review \nin Section 12. In particular, our ap\u00ad proach is inspired by the dynamic sealing of Matthews and Ahmed \n(2008), the dynamic type generation of Neis et al. (2009), and the syntactic type abstraction of Grossman \net al. (2000). Based on these ideas, we introduce an alternate semantics for the polymor\u00adphic lambda \ncalculus as a step towards de.ning our polymorphic blame calculus.  5.2 Polymorphic lambda calculus \nwith explicit binding We avoid the problems above by introducing a polymorphic lambda calculus with explicit \nbinding, shown in Figure 3. As usual, types are augmented by adding type variables X and universal quanti.ers \n.X. B, and terms are augmented by adding type abstractions .X. t and type applications tA. The key new \nconstruct is explicit type binding, .X:=A. t. Type environments are augmented to include, as usual, type \nvariables X and, more unusually, type bindings X:=A. As usual, we assume an implicit side condition when \nwriting G,X or G,X:=A that X is not in G. The type rules for type abstraction and application are standard \n(TYABS), (TYAPP). The type rule for binding augments the type environment with the binding, and a side \ncondition ensures that free type variables do not escape the binding (NEW). Two additional type rules, \nwhich are not syntax directed, permit a type variable to be replaced by its bound type, or vice versa, \nwithin the scope of a type binding (REVEAL), (CONCEAL).  We now brie.y consider the reduction rules. \nOur rule for type applications, instead of performing substitution, introduces an ex\u00adplicit type binding \n(TYBETA). Three new rules push explicit type bindings into the three value forms: constants (NUCONST), \nvalue abstractions (NUWRAP), and type abstractions (NUTYWRAP). (Side conditions on the last rule avoid \ncapture of type variables.) For example, (.X. .x:X. (.y:X. y) x) I 2 -. (.X:=I. .x:X. (.y:X. y) x)2 -. \n(.x:I..X:=I. (.y:X. y) x)2 -. .X:=I. (.y:X. y)2 -. .X:=I. 2 -. 2 byrules(TYBETA), (NUWRAP),(BETA),(BETA)and \n(NUCONST), respectively. Note that for the term .X:=I. (.y:X. y)2 to be well\u00adtyped that 2 must be regarded \nas having type X this is why the type rules permit both replacing a type variable by its binding and \nthe converse. As is well known, allowing type abstraction over terms with ar\u00adbitrary effects can be problematic. \nAs we will see in Section 6.4, the same issue arises here, due to raising of blame as a possi\u00adble side \neffect. The usual solution is to restrict type abstraction to apply only to values, as in the value polymorphism \nrestric\u00adtion of SML (Wright, 1995). We would like to do the same here, and restrict our syntax to only \ninclude type abstractions of the form .X. v. However, this would not be consistent with the re\u00adduction \n(NUTYWRAP), which may push the non-value type bind\u00ad ing construct underneath a type abstraction. (A similar \nissue arises with the reduction (GENERALIZE), introduced in Section 6.) In\u00ad stead, therefore, we allow \nthe body of a type abstraction to be any term (hence, the term form .X. t), but only consider a type \nab\u00adstraction to be a value if its body is a value (hence, the value form .X. v). This further requires, \nunusually, that we permit reduction underneath type abstractions (hence, the context form .X. E).  5.3 \nRelation to standard calculus We relate the polymorphic lambda calculus with explicit binding to the \nstandard polymorphic lambda calculus based on type substitu\u00adtion. We omit the de.nitions of the latter \nto save space. We de.ne the erasure t. from the calculus with explicit bindings to the stan\u00addard calculus \nas follows: . ... c = c (ts)= ts .. . (op(At )) = op(At ) (.X. t)=.X. t. x . = x (tA). = t. A (.x:A. \nt). = .x:A. t. (.X:=A. t). = t.[X:=A] The only clause of interest is that for a binder, which is erased \nby performing the type substitution. We also de.ne the application of an environment to a type G(A) and \nthe erasure of environments G. . (G,x:B)(A)= G(A) (G,x:A).=G. ,x:G(A) (G,X)(A)= G(A) (G,X).=G.,X (G,X:=B)(A)= \nG(A[X:=B]) (G,X:=A).=G. We can now state that the polymorphic lambda calculus with bind\u00adings correctly \nimplements the standard calculus, that is, erasure pre\u00adserves types and reductions. Proposition 1 (Erasure). \nIf G f s : A then G. f s . : G(A), and if ' .'. '. s -. s then either s = s or s . -. s . 5.4 Type safety \nIt is straightforward to show the usual type safety results for the calculus with explicit binding. Typically \nthese results are formu\u00adlated with respect to closed terms and empty environments, but be\u00adcause we allow \nreduction under type abstractions and binding our results are formulated with regard to terms that may \ncontain free type variables and environments that may contain type variables and bindings (but not term \nvariables). We let . range over such environments. With this caveat, we have the usual results for canonical \nforms, progress, and preservation. Proposition 2 (Canonical forms). If . f v : C then either v = c and \nC = . for some c and ., or  v = .x:A. t and C = A.B for some x, t, A, and B, or  v =.X. w and C = .X. \nA for some w, X, and A.  Proposition 3 (Progress). If . f s : A then either s = v for some value v or \ns -. s ' for some term s ' . Proposition 4 (Preservation). If . f s : A and s -. s ' then . f s ' : A. \n 5.5 Relation to dynamic type generation Neis et al. (2009) present a form for generating type names: \nnew X A in t. The main difference between our bindings and new is that new adds its binding to a global \nlist of bindings, s. s; new X A in t -. s, X A; t if X/. dom(s) Earlier versions of our system also used \na global list of bindings, but two aspects of our system require the change to local bindings. First, \nevaluation proceeds under . in our system, which makes it problematic to use the global binding approach. \nLet s =(.x:X..y:Y.x): X.Y .X and consider the following program and hypothetical reduction sequence. \nE; let f = .X.(.Y.s) X in (f I, f B) -. Y X; let f = .X.s in (f I, f B) -. Y X; ((.X.s) I, (.X.s) B) \n-. Y X, X I; (s, (.X.s) B) But the next step in the sequence is problematic. We would like to a-rename \nthe X in .X. s, but that would lose the connection with Y . Also, Y should really get two different bindings. \nLocal bindings solve this problem by binding Y :=X locally, inside the .X. Second, bindings play a role \nin enforcing parametricity, which we discuss in detail in Section 6.2. An earlier system, the .N \u00adcalculus \nby Rossberg (2003), uses local type bindings, but .N performs scope extrusion, that is, the type bindings \n.oat upwards. The type bindings in this paper are immobile because they can trigger errors and we want \nthose errors to occur at predictable locations. 6. Polymorphic blame calculus Now that we have established \nthe machinery of explicit binding, we consider how to combine dynamic casts with polymorphism. The polymorphic \nblame calculus is shown in Figure 4. The syntax is simply the union of the constructs of the blame calculus \nand the polymorphic lambda calculus, and the type rules are the union of the previous type rules. Two \nnew cases for quanti.ed types are added to the de.nition of type compatibility, one each corresponding \nto casts to and from quanti.ed types. Note that these break the symmetry of compat\u00adibility enjoyed by \nthe simply-typed blame calculus. We discuss compatibility in tandem with the corresponding reductions, \nin Sec\u00adtions 6.1 and 6.3. The intuition behind parametric polymorphism is that functions must behave \nuniformly with regard to type variables. To maintain parametricity in the presence of dynamic types, \nwe arrange that dynamic values corresponding to type variables must be treated abstractly. Recall that \nvalues of dynamic type have the form v : G . *, where G is a ground type. A key difference in moving \nto polymorphism is that the ground types, in addition to including base types . and the function type \n*.*, now also include type variables X. A value of the form v : X . * is called a sealed value.  We \nnow brie.y consider the reduction rules. Tests are updated so that if the value is sealed then the test \nindicates blame rather than returning true or false (ISTRUE), (ISFALSE), (ISTAMPER); the reason for this \nchange is discussed in Section 6.2. Two rules are added to push bindings into the one new value form, \nground values (NUGROUND), (NUTAMPER); the motivation for these rules is also discussed in Section 6.2. \nFinally, the last two rules extend casts to the case where the target type or source type is a quanti.ed \ntype (GENERALIZE), (INSTANTIATE); these rules are discussed in Sections 6.1 and 6.3. A side condition \non (GENERALIZE) avoids capture of type variables, and a side condition of (INSTANTIATE) avoids overlap \nwith (GROUND) and (GENERALIZE). The rules (ISTAMPER) and (NUTAMPER) introduce two global blame labels, \npis and p. , which are presumed not to label any cast. 6.1 Generalization Perhaps the two rules of greatest \ninterest are those that cast to and from a quanti.ed type. We begin by discussing casts to a quanti.ed \ntype, postponing the reverse direction to Section 6.3. Rule (GENERALIZE) casts a value to a quanti.ed \ntype by ab\u00ad stracting over the type variable and recursively casting the value; note that the abstracted \ntype variable may appear free in the target type of the cast. Observe that the corresponding rule for \ncompat\u00adibility asserts that if the cast on the left of this rule is compatible then the cast on the right \nis also compatible. We now have enough rules in place to return to our examples from Section 5.1. Here \nis the .rst example1 (K * : * .p .X. .Y.X.Y .X) II 23 -. * (.X. .Y.K * : * .p X.Y .X) II 23 -. * (.Y \n:=I. .X:=I.K * : * .p X.Y .X)23 -. * .Y :=I..X:=I. K * (2 : X .p *) (3 : Y .p *): * .p X -. * .Y :=I..X:=I. \nK * (2 : X . *) (3 : Y . *): * .p X -. * .Y :=I..X:=I. (2 : X . *): * .p X -. * .Y :=I..X:=I. 2 -. * \n2 The .rst step applies (GENERALIZE) twice, while the penultimate step applies (COLLAPSE) and (ID). \nThis yields 2, as expected. The second example is similar, save for the last steps. (K * : * .p .X. .Y.X.Y \n.Y ) II 23 -. * .Y :=I..X:=I. (2 : X . *): * .p Y -. * .Y :=I..X:=I. blame p -. * blame p Here the penultimate \nstep applies (CONFLICT). and the .nal step applies (ABORT). This yields blame p, as expected.  6.2 Parametricity \nWe now consider some further examples, with an eye to under\u00adstanding how sealing preserves parametricity. \nThe parametricity property for the type .X. X.X guarantees that a value of this type must be either the \nidentity function or the 1 Careful readers will spot that some reductions are shown out of order, so \nas to group related reductions together. unde.ned function. Consider the following three untyped terms. \nid* = I.x. xl inc* = I.x. x +1l test * = I.x. if (x is I) then (x + 1) else xl Function id is parametric, \nbecause it acts uniformly on values of all types; while functions inc and test are not, since the former \nacts only on integers, while the latter acts on values of any type but behaves differently on integers \nthan on other arguments. However, casting all three functions to type .X. X.X yields values that satisfy \nthe corresponding parametricity property. Casting id* , as one might expect, yields the identity function, \nwhile casting inc* and test *, perhaps surprisingly, both yield the only other parametric function of \nthis type, the everywhere unde.ned function. Here is the .rst example. (id* : * .p .X. X.X) I 2 -. * \n.X:=I. id* (2 : X .p *): * .p X -. * .X:=I. 2: X . * .p X -. * 2 The last step is by rules (COLLAPSE) \nand (ID). No matter which type and value are supplied, the casts match up, so this behaves as the identity \nfunction. Here is the second example. (inc* : * .p .X. X.X) I 2 -. * .X:=I. inc* (2 : X .p *): * .p X \n-. * .X:=I. ((2 : X . * .q I)+1) : I .q * .p X -. * blame q The last step is by rules (CONFLICT) and \n(ABORT); here q labels casts in inc* introduced by embedding typed integer addition into the untyped \nlambda calculus. Regardless of what type and value are supplied the casts still don t match, so this \nbehaves as the everywhere unde.ned function. Here is the third example. (test * : * .p .X. X.X) I 2 -. \n* .X:=I. test * (2 : X .p *): * .p X -. * .X:=I. if (2 : X . *) is I then \u00b7\u00b7\u00b7 else \u00b7\u00b7\u00b7 -. * blame pis \n The last step is by rules (ISTAMPER) and (ABORT). Sealed val\u00ad ues should never be examined, so rule \n(ISTAMPER) ensures that applying a type test to a sealed value always allocates blame. Rules (ISTRUE) \nand (ISFALSE) add side-conditions to ensure they do not overlap with (ISTAMPER). The use of explicit \nbinding plays a central role: the test (2 : I . *) is I returns true, while the test (2 : X . *) is I \nallocates blame to pis , even when X is bound to type I. Regardless of what type and value are supplied, \nthe test always fails, so this behaves as the everywhere unde.ned function. An alternative choice might \nbe for (v : X . *) is G to always return false (on the grounds that a sealed value is distinct from any \nground value). This choice would still retain parametricity, because under this interpretation the result \nof casting test* would be the identity function. However, we would lose another key property; we want \nto ensure that casting can lead to blame but cannot otherwise change a value. In this case, casting converts \ntest * to the everywhere unde.ned function, which is acceptable, while converting it to the identity \nfunction would violate our criterion. Finally, consider the polymorphic type .X. X.*. The para\u00admetricity \nproperty for this function states that it must be either a constant function (ignoring its argument and \nalways returning the same value) or the everywhere unde.ned function. Let s see what happens when we \ncast id* to this type.  (id* : * .p .X. X.*) I 2 -. * .X:=I. id* (2 : X .p *): * .p * -. * .X:=I. 2: \nX . * .p * -. * .X:=I. 2: X . * -. * blame p. Here rule (NUTAMPER) plays a key role, ensuring that the \nattempt to pass a value grounded at type X through the binder for X must fail. In an earlier system we \ndevised that did not have bindings (Ahmed et al., 2009), this term would in fact reduce to a value of \ntype *, violating a strict interpretation of the parametricity re\u00adquirement. It was only a mild violation, \nbecause the value of type * was sealed, so any attempt to examine it would fail. Still, from both a theoretical \nand practical point of view the current system seems preferable, because it detects errors earlier, and \neven if the result of the offending cast is not examined.  6.3 Instantiation Having considered casts \nto a quanti.ed type, we now turn our attention to the reverse, casts from a quanti.ed type. Rule (INSTANTIATE) \ncasts a value from a quanti.ed type by instantiating the quanti.ed type variable to the dynamic type \nand recursively casting the result. Observe that the corresponding rule for compatibility asserts that \nif the cast on the left of this rule is compatible then the cast on the right is also compatible. The \nrule always instantiates with the dynamic type. Often, we are casting to the dynamic type, and in that \ncase it seems natural to instantiate with the dynamic type itself. However, is this still sensible if \nwe are casting to a type other than the dynamic type? We show that there is a strong sense in which instantiating \nto the dynamic type is always an appropriate choice. Let s look at some examples. Let K be a polymorphically \ntyped constant function. K =.X. .x:X. .y:X. x Here is an example casting to dynamic type. (K : .X. X.X.X \n.p *. * .*) I2lI3l -. * (K* : *. * .* .p *. * .*) I2lI3l -. * I2l Unsurprisingly, instantiating polymorphically \ntyped code to * works perfectly when casting typed code to untyped code. Perhaps more surprisingly, it \nalso works well when casting polymorphically typed code to a different type. Because every value embeds \ninto the type *, instantiating to * yields an answer if instantiating to any type yields an answer. Here \nis an example of casting to static type. (K : .X. X.X.X .p I . I . I)23 -. * (K* : *. * .* .p I.I.I)23 \n-. * 2 This, of course, gives us exactly the same answer as if we had instantiated K to I instead of \n*: (K I : I . I . I .p I . I . I)23 -. * 2 In this sense, we say that * is a Jack-of-All-Trades: if instantiating \nto any type yields an answer, then so does instantiating to *. However, instantiating to * is something \nof a laissez faire policy, in that it may yield an answer when a strict instantiation would fail. For \ninstance, consider a slight variant on the example above. (K : .X. X.X.X .p I . * . I)2 Itruel -. * (K* \n: *. * .* .p I. * .I)2 Itruel -. * 2 Here, instantiating to I directly is more strict, yielding blame \nrather than a value. (K I : I.I.I .p I. * .I)2 Itruel -. * blame p In other words, *, though a Jack-of-All-Trades, \nis a master of none. To formulate the relevant property precisely, we need to capture what we mean by \nsaying that one term yields an answer if another does, so we formulate a notion of contextual approximation \nc. First, we de.ne convergence and divergence. A term that neither converges nor diverges must allocate \nblame. De.nition 5. A closed term s converges, written s ., if s -. * v for some value v, and diverges, \nwritten s ., if the reduction sequence beginning with s does not terminate. Next, we de.ne a variant \nof contextual approximation, where a term that allocates blame approximates every term. De.nition 6. \nTerm s approximates term t, written s c t, if for all evaluation contexts E we have E[s] . implies E[t] \n., and  E[s] . implies E[t] ..  We can now state the principle. Theorem 7 (Jack-of-All-Trades Principle). \nIf . f v : .X. A and A[X:=C] -B (and hence A[X:=*] -B) then (vC : A[X:=C] .p B) c (v* : A[X:=*] .p B). \nWe defer the proof until Section 11.  6.4 Evaluation under type abstraction As noted in Section 5.2, \nan unusual feature of our presentation is that we evaluate underneath type abstractions. We now provide \nan example, promised there, of why such evaluation is necessary. Parametricity guarantees that a term \nof type .X. X cannot reduce to a value. One term with this type is .X. blame r. In our calculus, this \nterm is not a value, and it evaluates to blame r. However, if we did not evaluate under type abstractions \nthen this term would be a value. We want it to be the case that v : A .p * .q A is equivalent to v for \nany value v of type A. (Among other things, it is easy to show that this is a consequence of the Jack-of-All-Trades \nPrinciple.) However, if .X. blame r is a value, this is not the case. (.X. blame r): .X. X .p * .q .X. \nX -. * (.X. blame r) * : * .p * .q .X. X -. * (.X:= *. blame r): * .p * .q .X. X -. * blame r This is \nno good a cast that should leave a value unchanged has instead converted it to blame! The solution to \nthis dif.culty, as described in Section 5.2, is to permit evaluation under type abstractions, and to \nonly regard terms of the form .X. v as values. We conjecture that if we based our system on call-by-name \nrather than call-by-value that evaluation under type abstraction would not be necessary. 6.5 Type safety \nThe usual type safety properties hold for the polymorphic blame calculus. Lemma 8 (Canonical forms). \nIf . f v : C, then 1. v = c and C = . for some c and ., or 2. v = w : G . * and C = *, for some w and \nG, or 3. v = .x:A. t and C = A.B, for some x, t, A, and B, or 4. v =.X. w and C = .X. A, for some w, \nX, and A.   Compatibility A B A ' -AB -B ' A[X := *] -BA -B A -AA -** -B X/. ftv(A) A.B -A ' .B ' \n.X.A -BA -.X.B Subtype A<: B A<: GA ' <: A B<: B ' A[X:=C] <: B A<: B A<: A X/. ftv(A) A<: *A . B<: \nA ' . B ' .X.A <: B A<: .X. B Positive Subtype A<:+ B + B ' + B A ' <:- A B<:A[X:=*] <:A<:+ B A<: + \nA A<: + * X/. ftv(A) + A ' . B ' + B A . B<:.X.A <:A<:+ .X. B Negative Subtype A<:- B - + -- - A<:G \n- A ' <:A B<:B ' A[X:=*] <:- B A<:B A<: A *<: B X/. ftv(A) - -- A ' A<:BA . B<:. B ' .X.A <:B A<:- .X. \nB Naive Subtype A<:n B A<:n A ' B<:n B ' A[X:=*] <:n B A<:n B A<:n A A<:n * X/. ftv(A) A . B<:n A ' \n. B ' .X.A <:n B A<:n .X. B Figure 5. Subtyping Relations Proposition 9 (Preservation). If . f s : A \nand s -. s ', then . f s ' : A. Proposition 10 (Progress). If . f s : A, then either s = v for some \nvalue v, or  s -. s ' for some term s ' , or  s = blame p for some blame label p.  Preservation and \nprogress on their own do not guarantee a great deal because they do not rule out blame as a result. In \nsections 8 and 9 we characterize situations in which blame cannot arise. 7. Subtyping relations Figure \n5 presents the compatibility relation and four forms of subtyping ordinary, positive, negative, and naive. \nCompatibility determines when it is sensible to attempt to cast one type to another type, and the different \nforms of subtyping characterize when a cast cannot give rise to certain kinds of blame. All .ve relations \nare re.exive, and all four subtyping relations are transitive. Why do we need four different subtyping \nrelations? Each has a different purpose. We use A<: B to characterize when a cast from A to B cannot \nyield blame for that cast. One useful consequence is that casting from a quanti.ed type .X. B to any \ninstance of that type B[X:=A] never yields blame. However, while subtyping gives a strong guarantee, \nit arises relatively rarely in programs that integrate static and dynamic typing. What we wish to show \nfor such programs is not that they never fail, but that when they do fail that blame always lies on the \nless precisely typed side of the cast, and this is the purpose of the other three relations. We use A<:+ \nB and A<:- B to characterize when a cast from A to B cannot yield either positive or negative blame, \nrespectively, and we use A<:n B to characterize when A is a more precise type than B. The de.nitions \nare related, in that A<: B holds if A<:+ B and A<:- B (but not conversely), and A<:n B holds if and only \nif A<:+ B and B<:- A. We tried to massage our de.nitions so that the .rst clause, like the second, would \nbe an equivalence, but failed to do so. Compatibility is written A -B. It is re.exive, and the dy\u00adnamic \ntype is compatible with every other type. The remaining three compatibility rules can be read off directly \nfrom the reduc\u00adtions (WRAP), (INSTANTIATE), and (GENERALIZE): replacing . in the reductions yields the \n-conditions in the rules. The casts on the left-hand side of the reductions correspond to the compatibili\u00adties \nin the conclusion of the rules, and the casts on the right-hand side correspond the hypotheses. Thus, \nthe compatibility rules are designed to ensure that reducing compatible casts yield compatible casts. \nFunction compatibility is contravariant in the domain and co\u00advariant in the range, corresponding to the \nswapping in the (WRAP) rule. A polymorphic type .X. A is compatible with type B if its instance A[X:=*] \nis compatible with B, corresponding to the (INSTANTIATE) rule. A type A is compatible with polymorphic \ntype .X. B if type A is compatible with B (assuming X does not appear free in A so there is no capture \nof bound variables), corre\u00adsponding to the (GENERALIZE) rule. Ordinary subtyping is written A<: B. It \ncharacterizes when a cast cannot give rise to blame. Every subtype of a ground type is a subtype of *, \nbecause a cast from a ground type to * never allocates blame. As with all the relations, function subtyping \nis contravariant in the domain and covariant in the range. A polymorphic type .X. A is a subtype of a \ntype B if some instance A[X:=C] is a subtype of B this is the one way in which subtyping differs from \nall the other relations, which instantiate with * rather than an arbitrary type C. It is easy to see \nthat A<:+ B and A<:- B together imply A<: B, but not conversely. The next two relations are concerned \nwith positive and negative blame. If reducing a cast with label p allocates blame to p we say it yields \npositive blame, and if it allocates blame to p we say it yields negative blame. The positive and negative \nsubtyping relations characterize when positive and negative blame can arise. In the next section, we \nshow that a cast from A to B with A<:+ B cannot give rise to positive blame, and with A<:- B cannot give \nrise to negative blame. The two judgments are de.ned in terms of each other, and track the negating of \nblame labels that occurs in the contravariant  s sf p A<:+ Bs sf p A<:- Bs sf p (s : A .p B) sf p (s \n: A .p B) sf p q = pq = ps sf ps sf p (s : A .q B) sf p (s : G . *) sf p s sf pq = p (s is G) sf p (blame \nq) sf p A t sf p c sf p (op(At )) sf px sf p t sf pt sf ps sf p (.x : A. t) sf p (ts) sf p t sf pt sf \npt sf p (.X. t) sf p (tA) sf p (.X:=A. t) sf p Figure 6. Safety for <:+ and <:- position of function \ntypes. We have A<:+ * and *<:- B for every type A and B, because casting to * can never give rise to \npositive blame, and casting from * can never give rise to negative blame. We also have A<:- G implies \nA<:- B, because a cast from a ground type to * cannot allocate blame, and a cast from * to any type cannot \nallocate negative blame. We also de.ne a naive subtyping judgment, A<:n B, which corresponds to our informal \nnotion of type A being more precise than type B, and is covariant for both the domain and range of functions. \n8. The Blame Theorem The Blame Theorem asserts that a cast from a positive subtype cannot lead to positive \nblame, and a cast from a negative subtype cannot lead to negative blame. The structure of the proof is \nsimilar to a type safety proof, depending on progress and preservation lemmas. However, the invariant \nwe preserve is not well-typing, but instead a safety relation, t sf p, as de.ned in Figure 6. A term \nt is safe for blame label p with respect to <:+ and <:-, written t sf p, if every cast with label p has \na source that is a positive subtype of the target, and every cast with label p has a source that is a \nnegative subtype of the target; we assume that p = pis and p = p. . Lemma 11 (Blame progress). If s sf \np then s -. blame p. Lemma 12 (Blame preservation). If s sf p and s -. s ', then s ' sf p. Positive and \nnegative subtyping are closely related to naive subtyp\u00ading. Proposition 13 (Factoring). A<:n B iff A<:+ \nB and B<:- A. The proof of Proposition 13 requires four observations. Lemma 14. If A<:+ B and X . A, \nthen X . B. If A<:- B and X . B, then X . A. Given X . B, we have A[X:=*] <:+ B iff A<:+ B. Given X . \nA, we have A<:- B[X:=*] iff A<:- B. We may now characterize how positive, negative, and naive subtyping \nrelate to positive and negative blame. Note that, typically, each cast in a source program has a unique \nblame label. Corollary 15 (Blame Theorem). Let t be a program with a subterm s : A .p B where the cast \nis labelled by the only occurrence of p in t, and p does not appear in t. s sf<: p A<: Bs sf<: p A<: \nBs sf<: p (s : A .p B) sf<: p (s : A .p B) sf<: p q = pq = ps sf<: ps sf<: p (s : A .q B) sf<: p (s \n: G . *) sf<: p s sf<: pq = pq = p (s is G) sf<: p (blame q) sf<: p At sf<: p c sf<: p (op(At )) sf<: \npx sf<: p t sf<: pt sf<: ps sf<: p (.x : A. t) sf<: p (ts) sf<: p  t sf<: pt sf<: pt sf<: p (.X. t) \nsf<: p (tA) sf<: p (.X:=A. t) sf<: p Figure 7. Safety for <: If A<:+ B, then t -. * blame p.  If A<:- \nB, then t -. * blame p.  If A<:n B, then t -. * blame p.  If B<:n A, then t -. * blame p.  The .rst \ntwo results are an immediate consequence of blame progress and preservation (Lemmas 11 and 12) while \nthe second two results are an immediate consequence of the .rst two and factoring (Proposition 13). Because \nour notion of more and less precise types is captured by naive subtyping, the last two clauses show that \nany failure of a cast from a more-precisely-typed term to a less-precisely-typed context must be blamed \non the less-precisely-typed context, and any failure of a cast from a less-precisely-typed term to a \nmore-precisely-typed context must be blamed on the less-precisely-typed term. The Blame Theorem and Subtyping \nTheorem give no guaran\u00adtees regarding the two global blame labels pis and p. . We are in\u00advestigating \nan alternative design in which the is, ., and . forms are individually labelled and the safety relations \ncan guarantee the absence of blame going to those labels under suitable static condi\u00adtions. 9. The Subtyping \nTheorem The Subtyping Theorem asserts that a cast from a subtype to a supertype cannot lead to any blame \nwhatsoever. As with the Blame Theorem, the structure of the proof is similar to that of a type safety \nproof, depending on progress and preservation lemmas. Again, we use a safety relation, s sf<: p, as de.ned \nin Figure 7. A term t is safe for blame label p with respect to <:, written s sf<: p, if every cast with \nlabel p or p has a source that is a subtype of the target; we assume that p = pis and p = p. . Lemma \n16 (Subtyping progress). If s sf p then s -. blame p. The preservation result is a little more complex \nthan that for the Blame Theorem, because it involves approximation as introduced in Section 6.3. Lemma \n17 (Subtyping preservation). If s sf<: p and s -. s ' , ' '' ''' then either s sf<: p or there exists \ns such that s c s and s '' sf<: p. The proof is by case analysis on s -. s ' and s -. s ', where the \ncase for (INSTANTIATE) depends on the Jack-of-All-Trades Princi\u00ad ple. We may now characterize how subtyping \nrelates to blame.  Syntax Binding reference P, Q ::= X | X Terms s, t ::= c | op(At ) | x | .x:A. t \n| ts | .X. v | tA | .X:=A. t | s : A .P B Values v, w ::= c | .x:A. t | .X. v | v : A .X X Contexts E \n::= [\u00b7] | op(Av, E,At ) | Es | vE | EA | .X:=A. E | E : A .P B Type rules G f t : B (X:=A) . GG f t \n: B[X:=A](X:=A) . G (REVEAL) (CONCEAL) G f (t : B .X B[X:=A]) : B[X:=A]G f (t : B[X:=A] .X B): B Reduction \nrules (.X. v) A -. .X:=A. (v : B .X B[X:=A]) if .X. v : .X. B (TYBETA) .X:=A. (v : B .Y Y ) -. (.X:=A. \nv): B .Y Y (NUSC) v : . .P . -. v (SCBASE) '''' ' (.x : A. t): A.B .P A .B -. .x:A. (t[x:=(x : A .P A)] \n: B .P B ) (SCWRAP) (.X. v): .X. B .P .X. B ' -. .X. (v : B .P B ' ) if X = P and X = P (SCTYWRAP) v \n: X .P X -. v if X = P and X = P (SCSEAL) v : A .X X .X A -. v (SCCANCEL) Figure 8. Polymorphic lambda \ncalculus with static casts (extends and updates Figures 1 and 3). Syntax Terms s, t ::= c | op(At ) \n| x | .x:A. t | ts | s:A.p B | s:G.* | s is G | blame p | .X. t | tA | .X:=A. t | s:A .P B Values v, \nw ::= c | .x:A. t | v : G . * | .X. v | v : A .X X Contexts E ::= [\u00b7] | op(Av, E,At ) | Es | vE | E is \nG | E:A.p B | E:G.* | .X. E | EA | .X:=A. E | E:A.P B Reduction rules v : * .P * -. v (SCDYN) Figure \n9. Polymorphic blame calculus with static casts (extends and updates Figures 1, 2, 3, 4, and 8). Corollary \n18 (Subtyping Theorem). Let t be a program with a subterm s : A .p B where the cast is labelled by the \nonly occurrence of p in t, and p does not appear in t. If A<: B, then t -. * blame p and t -. * blame \np. The result is an immediate consequence of subtyping progress and preservation. 10. Static casts The \npolymorphic lambda calculus with explicit bindings (Figure 3) includes two type rules that are not syntax \ndirected, (REVEAL) and (CONCEAL). In this section, we introduce the polymorphic lambda calculus with \nstatic casts, which extends the earlier calculus by adding two new constructs so that the two type rules \nin question become syntax directed. The result is a calculus which syntactically records exactly where \ntype abstraction occurs, similar in some respects to that of Grossman et al. (2000). The more re.ned \ntype information provided by the new calculus will be of use in the proof of the Jack-of-all-Trades Principle \nprovided in the next section. 10.1 Polymorphic lambda calculus with static casts We introduce the polymorphic \nlambda calculus with static casts in Figure 8. It proves convenient for the new constructs to use a notation \nsimilar to that for dynamic casts, and hence we call them static casts. Dynamic casts may fail and are \ndecorated with a blame label. Static casts may not fail, and are decorated with a binding reference. \nStatic casts come in two forms, corresponding to the rules (RE-VEAL) and (CONCEAL) in the polymorphic \nlambda calculus with explicit binding. Assume binding X:=A appears in the environ\u00adment G. We reveal the \nbinding of a type variable with the construct s : B .X B[X:=A] and we conceal the binding with the construct \ns : B[X:=A] .X B. For convenience in the reduction rules, we use the syntax s : A .P B to range over \nboth forms, where P is a binding reference that is either X or X. We write P for the involution that \nadds an overbar when one is missing, or removes the overbar when one is present. With the addition of \nstatic casts, we have a new value form. It is now the case that a value of type X always has the form \nv : A .X X where v has type A and X is bound to A in the environment. The rule for type application is \nmodi.ed to also insert a suitable static cast (TYBETA). The static cast depends upon the type of the \ntype abstraction; it is easy to annotate terms to preserve this information.  We introduce a reduction \nrule to push explicit bindings through the one new value form (NUSC). Surprisingly, the (NUSC) re\u00ad duction \nrule requires no side conditions; the type system already ensures that X = Y and X/. ftv(B). We also \nintroduce reduction rules to perform static casts for each type constructor: base types (SCBASE), functions \n(SCWRAP), quanti.ed types (SCTYWRAP), and type variables (SCSEAL). The rules to push a static cast through \na base type (SCBASE) or a type variable (SCSEAL) both resemble the rule for dynamic casts (ID). The rule \nto apply a static cast to a function (SCWRAP) re\u00ad sembles the corresponding rule for dynamic casts (WRAP). \nJust as WRAP .ips the cast on the arguments and negates the blame label, SCWRAP also .ips the static \ncast on the arguments and negates the binding reference. One notable difference between (SCWRAP) and \n(WRAP) is that (SCWRAP) does not introduce a new wrapper func\u00ad tion to apply the cast, but instead performs \nsubstitution directly in the body of the lambda abstraction. This greatly simpli.es the sim\u00adulation relation \nused in the proof of the Jack-of-All-Trades Prin\u00adciple. The substitution-based approach is not viable \nfor (WRAP) because a dynamic cast can fail, but works here because a static cast cannot fail. Theruletoapplyastaticcasttoaquanti.edtype \n(SCTYWRAP) is simpler than the corresponding rules for applying a dynamic cast. For dynamic casts we \nrequire separate rules for universal quanti\u00ad.ersinthesource (INSTANTIATE)andinthetarget (GENERALIZE); \nwhile for static casts it suf.ces to use a single rule to handle a uni\u00adversal quanti.er in both the source \nand target (SCTYWRAP), since one will be a substitution instance of the other. Finally, if a static cast \nmeets its negation, the two casts cancel (SCCANCEL). 10.2 Relation to explicit binding We relate the \npolymorphic lambda calculus with static casts to the polymorphic lambda calculus with explicit binding. \nWe de.ne the erasure t from the calculus with static casts to the calculus with explicit binding as follows: \nc = c (.X. t) =.X. t (op(At)) = op(tA )(tA) = t A x = x (.X:=A. t) = .X:=A. t (.x:A. t) = .x:A. t \n(t : A .P B) = t (ts) = t s Proposition 19 (Erasure). If G f s : A then G f s : A, and if ' ' ' s -. \ns then either s = s or s -. s . 10.3 Type safety It is straightforward to show the usual type safety \nresults for the polymorphic lambda calculus with static casts. Notably, there is now one additional canonical \nform, for a term whose type is a type variable. Proposition 20 (Canonical forms). If . f v : C then either \n v = c and C = . for some c and ., or  v = .x:A. t and C = A.B for some x, t, A, and B, or  v =.X. \nw and C = .X. A for some w, X, and A.  v = w : A .X X and C = X for some w, X, and A.  Proposition \n21 (Progress). If . f s : A then either s = v for some value v or s -. s ' for some term s ' . Proposition \n22 (Preservation). If . f s : A and s -. s ' then . f s ' : A. 10.4 Polymorphic blame calculus with \nstatic casts Given the above development, it is straightforward to augment the polymorphic blame calculus \nto include static casts, as shown in Figure 9. The syntax is just the union of the syntaxes of the previous \ncalculi. Only one additional reduction rule is required, to apply a static cast to the dynamic type (SCDYN). \nAnalogues of the previous results to relate the calculus with static casts to the one without are straightforward, \nas are analogues of the type safety results, and we omit the details. 11. The Jack-of-All-Trades Principle \nWe now provide the proof of Theorem 7, the Jack-of-All-Trades Principle. To prove the theorem we introduce \na relation s ~ t that cis contained in c and prove that c ~ is a simulation. Examining the theorem gives \nour starting point for the relation. c vC : A[X:=C] .p B ~ v* : A[X:=*] .p B. As these terms reduce, \nthis cast can break into many casts, but they will all have the general form c.p s : A .p B ~ t : A ' \nB or the form ~ t : B .p ' s : B .p A cA where s ct, and A and A ' are the same, except some types in \nA ~ are replaced by * in A '. To make the latter speci.c, we introduce a few de.nitions. De.nition 23. \nIf S is a map from type variables to types, its erasure S * is the map that takes each X in the domain \nof S to *. De.nition 24. We say that type A simulates type A ', written A c ~ A ', if there exists a \ntype A '' and a map S such that A = S(A '' ) and A ' =S * (A '' ). For example, if A =(X.X).B and A ' \n= *.* we have A cby taking A '' = Y .Z and S= Y :=X.X, Z:=B ~ A ' (and hence S * = Y :=*, Z:=*). As a \nsecond example, consider what type A may simulate a type variable X, A c ~ X? The answer is that X is \nthe only type that simulates X, so A = X. The full de.nition of the relation cis given in Figure 10. \n~ The rules on the right-hand side make ca congruence and the ~ remaining rules help us keep terms related \nas they reduce. We add thefollowingsideconditiontotherule (LEFTSC):thetypevariable in the binding reference \ndoes not appear anywhere in the program on the right-hand side of c ~ ; this is because (LEFTSC) arises \nfrom (LEFTTYABS), in which there is a type abstraction on the left that does not appear on the right. \nNote that the simulation rules say nothing about types. But when the terms on each side of the conclusion \nare well typed then the terms in the hypothesis are as well. Furthermore, we have the following lemma. \nLemma 25. If s ~ t, G f s : A, and G ' ~ A ' cf t : A ', then A c. c The proof is a straightforward induction \non s ~ t. An important property of c ~ is that it relates values to terms that reduce to values. Lemma \n26 (Value on the left of cIf v cw and ~). ~ t, then t -. * v cw for some value w. ~ In the proof that \nc ~ is a simulation, the case for (BETA) requires the following lemma regarding substitution. c' c' Lemma \n27 (Substitution preserves cIf t and vv , ~ ). t~~ ~ t '' then t[x:=v] c[x:=v ]. The result is a consequence \nof the fact that c ~ is a congruence. We now show that c ~ simulates both the reduction relation -. and \nthe step relation -., beginning with the former.  (CONGCONST) (CONGVAR) xx ~ ~ t ~ A ' ~ .x:A ' ~ t1 \n~ t2 ~ t1 t2 c ~ t ~ A ' c ~ .Y.t ccc ccct~ ccccccccccccc ~ tA cccc ~ t c c ~ t is G ~ t ~ t : A .q \n~ ~ ~ t ~ A ' ~ B ' ~ t : A ' ~ t ~ A ' ~ .X:=A ' ~ f t : work with respect to the work of Matthews \nand Ahmed (2008) is A ~ A ' ~ t : A ' ~ A ' ~ t ~ t ~ t ~ t ~ t ~ t ~ t ~ w cccccccccc s ~ t s : A .p \nB c As (CONGABS)(POSCAST) .x:A. s.t ~ t blame q cc c .p B s1s2A s (CONGAPP)(NEGCAST) ~ t : B .p\u00afA ' s1 \ns2s : B .p\u00afAA s (BLAME) (CONGTYPEABS) .Y. s s (LEFTTYABS) (LEFTSC) (LEFTNU) s.Y.s (CONGTYPEAPP) sA sss \n: A .P B (CONGIS) s is G ss.X:=A. s (CONGCAST) s : A .p BB v (RIGHTGROUND) v w ~ ~ (.X. v) * c c w : \nG . * (CONGGROUND) v v : G . *w : G . * vw ~ c w (LEFTTYAPP) ABs (CONGSC) B ' s : A .P .P B ' At (CONGNU) \n' .X:=A. t.t Figure 10. Simulation relation p simulates -.) Suppose . f s : A and . ' cc ~ ~ t and s \n-. s ~ t associating sealing with type abstraction instead of the interface The proof relies on the presence \nof bindings and static casts to pre\u00adbetween languages, and 2) we establish the blame and subtyping serve \ntype information, especially the presence of type variables. theorems and the Jack-of-All-Trades principle. \n~ t cc Lemma 28. ( ', then t -. * t ' and s ' ' for some t ' . that 1) we tease apart the notion of \ndynamic casting and sealing, B. If sp simulates -.) Suppose . f s : A and . ' ~ c Lemma 29. ( f t : Syntactic \ntype abstraction Grossman et al. (2000) develop a gen\u00ad ', then t -. * t ' and s ' '' c ~ t and s -. \ns We then prove that~ is contained in c. c B. If sfor some t . eral theory of syntactic type abstraction \nin which multiple agents interact and have varying degrees of knowledge regarding the types at the interfaces \nbetween agents. Their general theory can be used Lemma 30. If s c ~ t, then s c t. Proof. The proof is \nby case analysis on the reduction of s. to express the type abstraction in the polymorphic lambda calcu\u00adlus, \nas well as many other kinds of syntactic abstractions. They present two systems, a simple two-agent system \nand a multi-agent Suppose E[s] .. Then E[t] . by Lemma 29. Suppose E[s] .. Then E[t] . by Lemmas 29 and \n26. The proof of the main theorem follows from this lemma. system. The two-agent system can handle a \nprogram with one type abstraction whereas the multi-agent system is needed for arbitrary programs, using \none agent per type abstraction. However, the multi\u00adagent system adds considerable complexity for generality \nthat is Proof of the Jack-of-All-Trades principle. We have unnecessary in our setting. The advantage \nof our system is that it c ~ (v* : A[X:=*] .p and we conclude by applying Lemma 30. 12. Related Work \nRun-time sealing Matthews and Ahmed (2008) present seman\u00ad tics for a multi-language system (Scheme and \nML) that enforces the parametricity of ML values with polymorphic type (with embedded Scheme values). \nTheir system places boundaries between the two languages. Their boundaries roughly correspond to a combination \nof a static and dynamic cast in our system. The contributions of our (vC : A[X:=C] .p B)B) scales up \nto handle arbitrary number of type abstractions while re\u00ad taining much of the simplicity of the two-agent \nsystem. Sulzmann et al. (2007) develop an extension of System F with type equality coercions. Their coercions \nclosely resemble the static casts of this paper, including the reduction rules. Their system does not \nhave an analogue of our type bindings and instead uses substitution to perform type application. Integrating \nstatic and dynamic Tobin-Hochstadt and Felleisen (2006) formalize the interaction between static and \ndynamic typing at the granularity of modules and develop a precursor to the Blame Theorem. Wadler and \nFindler (2009) design the blame calculus drawing on the blame tracking of higher-order contracts (Findler \nand Felleisen, 2002), and prove the Blame Theorem.  Gronski et al. (2006) explore the interaction of \ntype Dynamic with re.nement types and .rst-class types, that is, allowing types to be passed to and returned \nfrom functions. This provides a form of polymorphism, but not relational parametricity. In the language \nThorn, Wrigstad et al. (2010) show how to integrate typed and untyped code, using like types to bridge \nthe gap in a way that better enables compiler optimizations in statically typed regions of code. Their \nformal development includes classes and objects but not polymorphism. 13. Conclusion We have extended \nthe blame calculus with support for .rst-class parametric polymorphism, using explicit type binding to \nmaintain relational parametricity for values of polymorphic type. Our cal\u00adculus supports casts between \nthe dynamic type and polymorphic types. When casting from a polymorphic type, our system instanti\u00adates \nthe type variable with the dynamic type, a choice justi.ed by the Jack-of-All-Trades Principle: if instantiating \na type parameter to any given type yields an answer then instantiating that type pa\u00adrameter to the dynamic \ntype yields the same answer. We proved this principle via a simulation argument that depended on the \npresence of type bindings and static casts. We have also proved the Blame Theorem, so in the new polymorphic \nblame calculus, well-typed programs can t be blamed . Further, as a corollary of the Jack\u00adof-All-Trades \nPrinciple, we have proved the Subtyping Theorem, showing that a traditional notion of subtyping is sound \nwith respect to our operational semantics. Looking forward, there are interesting questions regarding \nhow to extend this work to subset and dependent types. Ultimately we hope to obtain a language with a \nfull spectrum type system, supporting dynamic typing all the way to total correctness. Acknowledgments \nOur thanks to Jacob Matthews for his support and participation in early discussions of this work. Siek \ns work on this paper was supported by NSF grant 0846121 and by a Distinguished Visiting Fellowship from \nthe Scottish Informatics and Computer Science Alliance. Findler s work was supported by NSF grant 0846012. \nReferences Martin Abadi, Luca Cardelli, Benjamin Pierce, and Gordon Plotkin. Dynamic typing in a statically \ntyped language. ACM Transactions on Programming Languages and Systems, 13(2): 237 268, April 1991. Amal \nAhmed, Jacob Matthews, Robert Bruce Findler, and Philip Wadler. Blame for all. In Workshop on Script-to-Program \nEvolution (STOP), pages 1 13, 2009. Robert Bruce Findler and Matthias Felleisen. Contracts for higher\u00adorder \nfunctions. In ACM International Conference on Func\u00adtional Programming (ICFP), pages 48 59, October 2002. \nAndrew Gill, John Launchbury, and Simon L. Peyton Jones. A short cut to deforestation. In ACM Conference \non Functional Programming Languages and Computer Architecture (FPCA), pages 223 232, September 1993. \nJessica Gronski, Kenneth Knowles, Aaron Tomb, Stephen N. Fre\u00adund, and Cormac Flanagan. Sage: Hybrid checking \nfor .exible speci.cations. In Scheme and Functional Programming Work\u00adshop (Scheme), pages 93 104, September \n2006. Dan Grossman, Greg Morrisett, and Steve Zdancewic. Syntac\u00adtic type abstraction. ACM Transactions \non Programming Lan\u00adguages and Systems, 22(6):1037 1080, November 2000. Arjun Guha, Jacob Matthews, Robert \nBruce Findler, and Shriram Krishnamurthi. Relationally-parametric polymorphic contracts. In Dynamic Languages \nSymposium (DLS), pages 29 40, 2007. Robert Harper. Practical Foundations for Programming Lan\u00adguages. \n2007. Working Draft. Fritz Henglein. Dynamic typing: Syntax and proof theory. Science of Computer Programming, \n22(3):197 230, 1994. Jacob Matthews and Amal Ahmed. Parametric polymorphism through run-time sealing. \nIn European Symposium on Program\u00adming (ESOP), pages 16 31, 2008. Jacob Matthews and Robert Bruce Findler. \nOperational semantics for multi-language programs. In ACM Symposium on Principles of Programming Languages \n(POPL), pages 3 10, January 2007. James H. Morris, Jr. Types are not sets. In ACM Symposium on Principles \nof Programming Languages (POPL), pages 120 124, October 1973. Georg Neis, Derek Dreyer, and Andreas Rossberg. \nNon-parametric parametricity. In ACM International Conference on Functional Programming (ICFP), pages \n135 148, September 2009. Xinming Ou, Gang Tan, Yitzhak Mandelbaum, and David Walker. Dynamic typing with \ndependent types. In IFIP International Conference on Theoretical Computer Science, pages 437 450, August \n2004. Benjamin Pierce and Eijiro Sumii. Relating cryptography and polymorphism. Manuscript, 2000. URL \nwww.cis.upenn.edu/ ~bcpierce/papers/infohide.ps. John Reynolds. Types, abstraction, and parametric polymorphism. \nIn R. E. A. Mason, editor, Information Processing, pages 513 523. North-Holland, 1983. Andreas Rossberg. \nGenerativity and dynamic opacity for abstract types. In ACM Conference on Principles and Practice of \nDeclar\u00adative Programming (PPDP), pages 241 252, 2003. Jeremy G. Siek and Walid Taha. Gradual typing for \nfunctional languages. In Scheme and Functional Programming Workshop (Scheme), pages 81 92, September \n2006. Martin Sulzmann, Manuel M. T. Chakravarty, Simon Peyton Jones, and Kevin Donnelly. System F with \ntype equality coercions. In ACM Workshop on Types in Languages Design and Implemen\u00adtation (TLDI), pages \n53 66, 2007. Satish Thatte. Type inference with partial types. In Interna\u00adtional Colloquium on Automata, \nLanguages and Programming (ICALP), volume 317 of Lecture Notes in Computer Science, pages 615 629. Springer-Verlag, \n1988. Sam Tobin-Hochstadt and Matthias Felleisen. Interlanguage mi\u00adgration: From scripts to programs. \nIn Dynamic Languages Sym\u00adposium (DLS), pages 964 974, October 2006. Philip Wadler and Robert Bruce Findler. \nWell-typed programs can t be blamed. In European Symposium on Programming (ESOP), pages 1 16, March 2009. \nAndrew K. Wright. Simple imperative polymorphism. Higher-Order and Symbolic Computation, 8(4):343 355, \nDec. 1995. Tobias Wrigstad, Francesco Zappa Nardelli, Sylvain Lebresne, Jo\u00adhan Ostlund, and Jan Vitek. \nIntegrating typed and untyped code \u00a8 in a scripting language. In ACM Symposium on Principles of Programming \nLanguages (POPL), pages 377 388, 2010.   \n\t\t\t", "proc_id": "1926385", "abstract": "<p>Several programming languages are beginning to integrate static and dynamic typing, including Racket (formerly PLT Scheme), Perl 6, and C# 4.0 and the research languages Sage (Gronski, Knowles, Tomb, Freund, and Flanagan, 2006) and Thorn (Wrigstad, Eugster, Field, Nystrom, and Vitek, 2009). However, an important open question remains, which is how to add parametric polymorphism to languages that combine static and dynamic typing. We present a system that permits a value of dynamic type to be cast to a polymorphic type and vice versa, with relational parametricity enforced by a kind of dynamic sealing along the lines proposed by Matthews and Ahmed (2008) and Neis, Dreyer, and Rossberg (2009). Our system includes a notion of blame, which allows us to show that when casting between a more-precise type and a less-precise type, any cast failures are due to the less-precisely-typed portion of the program. We also show that a cast from a subtype to its supertype cannot fail.</p>", "authors": [{"name": "Amal Ahmed", "author_profile_id": "81100287263", "affiliation": "Indiana University, Bloomington, IN, USA", "person_id": "P2509599", "email_address": "amal@cs.indiana.edu", "orcid_id": ""}, {"name": "Robert Bruce Findler", "author_profile_id": "81100028925", "affiliation": "Northwestern University, Chicago, IL, USA", "person_id": "P2509600", "email_address": "robby@eecs.northwestern.edu", "orcid_id": ""}, {"name": "Jeremy G. Siek", "author_profile_id": "81100437231", "affiliation": "University of Colorado at Boulder, Boulder, CO, USA", "person_id": "P2509601", "email_address": "jeremy_siek@colorado.edu", "orcid_id": ""}, {"name": "Philip Wadler", "author_profile_id": "81100173596", "affiliation": "University of Edinburgh, Edinburgh, United Kingdom", "person_id": "P2509602", "email_address": "wadler@inf.ed.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926409", "year": "2011", "article_id": "1926409", "conference": "POPL", "title": "Blame for all", "url": "http://dl.acm.org/citation.cfm?id=1926409"}