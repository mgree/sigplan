{"article_publication_date": "01-26-2011", "fulltext": "\n Geometry of Synthesis III Resource Management Through Type Inference Dan R. Ghica * Alex Smith University \nof Birmingham, UK {d.r.ghica,AIS523}@bham.ac.uk Abstract Geometry of Synthesis is a technique for compiling \nhigher-level programming languages into digital circuits via their game seman\u00adtic model. Ghica (2007) \n.rst presented the key idea, then Ghica and Smith (2010) gave a provably correct compiler into asynchronous \ncircuits for Syntactic Control of Interference (SCI), an af.ne-typed version of Reynolds s Idealized \nAlgol. Af.ne typing has the dual bene.ts of ruling out race conditions through the type system and having \na .nite-state game-semantic model for any term, which leads to a natural circuit representation and simpler \ncorrectness proofs. In this paper we go beyond SCI to full Idealized Algol, en\u00adhanced with shared-memory \nconcurrency and semaphores (Ghica and Murawski, 2008). Compiling ICA proceeds in three stages. First, \nan intermediate type system called Syntactic Control of Concurrency (SCC), (Ghica et al., 2006) is used \nto statically determine concurrency bounds on all identi.ers in the program. Then, a program transformation \ncalled serialization is applied to the program to translate it into an equivalent SCC program in which \nall concurrency bounds are set to the unit. Finally, the resulting program can be then compiled into \nasynchronous circuits using a slightly enhanced version of the GoS II compiler, which can handle assignable \nvariables used in non-sequential contexts. Categories and Subject Descriptors F.3.3 [Logics and Meanings \nof Programs]: Studies of Program Constructs Type structure General Terms Theory, Languages Keywords Automatic \nSynthesis, Event Logic, Syntactic Control of Interference, Game Semantics 1. Geometry of Synthesis The \nproblem of hardware compilation, synthesising digital circuits from behavioural speci.cations written \nin higher-level program\u00adming languages, turned out to be surprisingly dif.cult. Although the pioneering \nwork of van Berkel and Saeijs (1988) and Page and Luk (1991); Luk et al. (1994) yielded promising initial \nre\u00adsults, more than a decade later this technology has yet to enter the * supported by an EPSRC Advanced \nResearch Fellowship Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. POPL 11, 26 28 January 2011, Austin, Texas, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. \n. . $10.00 mainstream of digital design. Several C-to-hardware compilers are available as commercial \nproducts from companies such as MEN-TOR, ALTERA, SYNOPSYS and others, but they all share a com\u00admon weakness, \nproviding poor support for handling of functions and procedures, at least when compared with modern conventional \n( software ) compilers. The role of functions (and related concepts such as procedures, subroutines, \nmethods, etc.) in modern languages and compilers is essential in several different ways. Through the \nfunctional interface a program will structure itself into reusable components, interact with code written \nin other programming languages (foreign func\u00adtion interface), and interact with run-time services of \nthe operating systems (application binary interface). The functional subset of a modern language will \nusually be a variant of a typed lambda calcu\u00adlus and can handle functions as arguments (higher-order \nfunctions), anonymous functions (abstraction) and partial application (curry\u00ading). Starting with Algol, \nat least in the idealized form of Reynolds (1981), such features are common enough to be taken for granted \nin most contemporary languages and compilers. However, this is not the case in hardware compilation. \nThese methodological con\u00adsiderations are elaborated by Ghica (2009). The Geometry of Synthesis (GoS) \napproach is concerned with remedying this situation by compiling higher level languages into hardware \nin a way that is consistent with a modern functional in\u00adfrastructure having mature functional interface \ncapabilities. The GoS approach starts from the widely accepted premise that cir\u00adcuit diagrams that are \ngraph isomorphic should be behaviourally equal at the right level of abstraction, and builds on the work \nof Kelly and Laplaza (1980) and their seminal results regarding the representation of diagrams in the \nlanguage of compact closed cate\u00adgories. Function objects can be encoded in the language of compact closed \ncategories using just a disciplined accounting of boxes and wires, so the .rst key new insight provided \nby GoS is that function de.nition and (linear) application can be represented in hardware in a purely \nstatic way by an interconnection of circuits which is consistent with this discipline. The second insight \nis that in order to compile conventional programming languages, their imperative features and especially \ncontraction (which allows multiple occur\u00adrences of identi.ers) can be represented at the circuit level \nusing game semantics (Ghica, 2007). In fact, the hardware compilation process is tantamount to a rei.cation \nof game semantics into hard\u00adware (Ghica, 2009). Contribution. In this paper we address what we perceive \nto be a key inconvenience in the GoS approach, namely restrictions on contraction in concurrent contexts. \nIdeally, we want to allow the programmer to write programs such as .f.x.f(x); f(x) or .f.x.f(x)||f(x). \nHowever, the type system which forms the basis of the programming language allows contraction only in \nsequential contexts, hence the .rst term is typeable but the second is not. The programmer needs to serialize \nthe term by hand, writing some\u00adthing like .f1f2.x1x2.f1(x1)||f2(x2); in complicated terms this quickly \nbecomes very dif.cult to handle. This becomes even more dif.cult if we want to apply this function to \nterms which them\u00adselves require transformation. For example, if applied to .c.c||c, which needs itself \nto change to .c1c2.c1||c2, the original function should actually be .f1f2.x1x2x3x4.f1x1x2||f2x3x4. In \nthis paper we give a systematic method of obtaining such terms, which we then know how to compile into \nhardware. 2. Type systems In this section we will present a realistic shared-memory higher\u00adorder concurrent \nprogramming language with synchronisation primitives, and give several typing systems for the language. \nThe .rst type system is Idealized Concurrent Algol (ICA), the most general one, which is essentially \nthe simply-typed lambda calculus with special constants for state manipulation and con\u00adcurrency. It represents \nan extension of the idealized Algol lan\u00adguage proposed by Reynolds (1981) with parallel composition and \nsemaphores (Ghica and Murawski, 2008). The next typing system, (Basic) Syntactic Control of Interfer\u00adence \n(SCI) is an af.ne version of ICA in which contraction is dis\u00adallowed over function application and parallel \nexecution. SCI was initially proposed by Reynolds as a programming language which would facilitate Hoare-style \ncorrectness reasoning because covert interference between terms is disallowed (Reynolds, 1978, 1989). \nSCI turned out to be semantically interesting and it was studied extensively (Reddy, 1996; O Hearn et \nal., 1999; McCusker, 2007, 2010). The restriction on contraction in SCI makes it particularly well suited \nfor hardware compilation because any term in the lan\u00adguage has a .nite-state model and can therefore \nbe compiled as a static circuit (Ghica, 2007; Ghica and Smith, 2010). The third type system, Syntactic \nControl of Concurrency (SCC) is a half-way house between the unrestricted ICA and the con\u00adstrained SCI \n(Ghica et al., 2006). In SCC, contraction is allowed in all contexts, but static bounds on the number \nof contractions in non-sequential contexts are enforced through the type system. In fact, SCC with all \ncontraction bounds set to unit is equivalent to SCI. SCC has been initially proposed as a framework for \nmodel checking concurrent programs, because this language also enjoys a .nite-state model property at \nall terms (Ghica and Murawski, 2006). Evidently, this property recommends it as a more .exible alternative \nto SCI for hardware compilation. Shared memory con\u00adcurrency and semaphores cannot type in SCI because \nthey require contraction in non-sequential contexts, but can be handled by the SCC system. 2.1 Idealized \nConcurrent Algol (ICA) The primitive types of the language are commands, memory cells, semaphores and \nexpressions. For simplicity we only consider boolean expressions, but .nite-integer expressions can be \nadded in a conceptually straightforward manner. s ::= com | var | sem | exp. The type constructors are \nproduct and function: . ::= . \u00d7 . | . . . | s. Terms are described by typing judgements of the form x1 \n: .1,...,xk : .k f M : ., where we denote the set of identi.er type assignments on the left by G. By \nconvention, if we write G, G' it assumes that the two type assignments have disjoint sets of identi.ers. \nThe term formation rules of the language are those of the simply typed lambda calculus: Identity x : \n. f x : . G f M : . Weakening G,x : .' f M : . G,x : ., y : . f M : .' Contraction G,x : . f M[x/y]: \n.' G,x : .' f M : . Abstraction G f .x.M : .' . . G f M : . . .' G f N : . Application G f MN : .' G \nf Mi : .i Product G f(M1,M2) : .1 \u00d7 .2 The constants of the language are described below: 0, 1 : exp \nare the boolean constants; skip : com is the only command constant ( no-op ); asg : var \u00d7 exp . com is \nassignment to memory cell, denoted by := when used in in.x notation; der : var . exp is dereferencing \nof memory cell, also denoted by ! ; seq : com \u00d7 com . com is command sequencing, denoted by ; when used \nin in.x notation; seq : com \u00d7 exp . exp is sequencing of command with expres\u00adsion, denoted by ; when \nused in in.x notation, resulting in an expression with side effects; par : com . com . com is parallel \ncomposition of commands, denoted by || when used in in.x notation; neg : exp . exp is boolean negation; \nor : exp \u00d7 exp . exp is boolean disjunction; if : exp \u00d7 com \u00d7 com . com is branching; while : exp \u00d7 com \n. com is iteration; grab : sem . com is semaphore grab; release : sem . com is semaphore release; newvar \n:(var . com) . com is local variable declaration in block command; newvar :(var . exp) . exp is local \nvariable declaration in block expression; newsem :(sem . com) . com is semaphore declaration in block \ncommand; newsem :(sem . exp) . exp is semaphore declaration in block expression; rec. :(. . .) . . is \na .x-point operator. Local variable and semaphore binding is presented with a quanti.er\u00adstyle type in \norder to avoid introducing new variable binders in the language. Local variable declaration can be sugared \ninto a more familiar syntax as newvar(.x.M) = newvar x in M. The language ICA is a highly expressive \nprogramming language in which a large variety of algorithms and programming constructs can be coded. \nIts operational semantics, which de.nes the imper\u00adative and shared-variable concurrency primitives in \nthe usual way in the framework of a call-by-name lambda-calculus, along with a fully abstract game semantic \nmodel are given by Ghica and Mu\u00adrawski (2008).  2.2 Syntactic Control of Interference (SCI) SCI is the \naf.ne version of ICA. It has the same type structure as ICA. However, since contraction in concurrent \ncontexts is not al\u00adlowed semaphores can play no meaningful role and can be omitted from the de.nition \nof the language. The only changes as compared to ICA are the removal of explicit contraction and a new \nrule for function application: G ' G f M : . . . ' f N : . Application (new) G, G ' f MN : . ' The immediate \nconsequence of this restriction is that nested appli\u00adcation is no longer possible, i.e. terms such as \nf : com . com f f(f(skip)) are illegal. Elimination of nested application means that the usual operational \nunfolding of recursion no longer preserves typing, therefore the rec. operator must be also eliminated. \nA restricted recursion operator can be reintroduced but we will not consider it here. The second consequence \nof this restriction plays out in conjunc\u00adtion with the chosen types of sequential and parallel composition: \nseq : com \u00d7 com . com par : com . com . com. The uncurried type of seq allows the typing of normal imperative \nprograms because contraction can be achieved via product forma\u00adtion. Terms such as .c.c; c are possible, \nbut .c.c||c are not. Despite its restrictions SCI is still expressive enough to allow many interesting \nprograms. Its .nite state model makes it perfectly suited for hardware compilation (Ghica, 2007; Ghica \nand Smith, 2010).  2.3 Syntactic Control of Concurrency (SCC) The SCC type system allows contraction \nin all contexts but only when static bounds on the numbers of non-sequential contractions are respected. \nThe types of the language are given by the grammar s ::= com | exp | var | sem . ::= .n ,n . N . ::= \ns | . \u00d7 . | . . .. If a bound in .n is unit we may omit it. SCC types have the following sub-typing relation \nn1 = n2 .1 = .2 .2 = .1 .1 = .2 .n1 = .n2 12 .1 . .1 = .2 . .2 Type judgements have form x1 : .1,...,xk \n: .k f M : .. If a type assignment environment is G= {xi : .ni | 1 = i = k} i we de.ne def n \u00b7 G= {xi \n: .n\u00b7ni | 1 = i = k}. i The typing rules are like in ICA except for the management of bounds in contraction \nand function application, plus a new rule for sub-typing: G,x : .m ,y : .n f M : . ' Contraction (new) \nG,x : .m+n f M[x/y]: . ' G f M : .n . . ' G ' f N : . Application (new) G,n \u00b7 G ' f MN : . ' G f M : \n.. = . ' Subtyping G f M : . ' Note that .c.c||c is typeable in SCC, but the type is not the same as \nfor .c.c; c: c:com f c:com f par:com . com.com c:com f par c:com.com d:com f d:com c:com,d:com f par \ncd : com c:com 2 f par cc : com f .c:com 2 .par cc : com 2.com As in SCI, a general .x-point combinator \ncannot be typed. All other constants are inherited from ICA and receive, where needed, unit bound, except \nthat newvar and newsem are replaced by a family of constants which can accept a local variable (semaphore, \nrespectively) for any given bound newvar :(var n . com) . com newvar :(var n . exp) . exp newsem :(sem \nn . com) . com newsem :(sem n . exp) . exp. The SCC type system can be used to write a large variety \nof im\u00adperative, concurrent or higher order programs such as producer\u00adconsumer (Ghica and Murawski, 2006). \nIn practice the restriction is felt mainly because general recursion is ruled out and in the def\u00adinition \nof higher-order functions where concurrency bounds must be speci.ed by the programmer. Without type inference \nthe pro\u00adgrammer needs to specify guarantees as well, which is inconvenient and will be also addressed \nin this paper. Consider for example a producer-consumer program where the producer and the consumer are \ngiven as arguments. In ICA such a program would have signa\u00adture .prod : exp..cons : exp . com.M whereas \nin SCC it must be given as, for example .prod : exp..cons : exp 1 . com.M, which means that any argument \nconsumer is not allowed to use its own argument more than once in non-sequential contexts. EXAMPLE 2.1. \nnn 1. f .f..x.f(f (x)) : (com . com)n+1 . com 2 . com nn 2. f .f..x.f(x); f(x):(com . com)1 . com . com \nn 3. f .f..x.f(x)||f(x):(com . com)2 . com 2n . com n 4. f .f.f(f(skip)) : (com . com)n+1 . com n 5. \nf .g.g(.x.g(.y.x)) : ((com . com)n . com)n+1 . com. In the above, n is a positive integer constant which \nmust be pro\u00advided by the environment (the user). The term of concurrency bound is meant to encompass \ntwo kinds of run-time interleaving. The .rst is the genuine concurrency expressed in a term such as f(x)||f(x) \nand the second is that occurring in a term such as f(f(x)). We feel justi.ed in calling the latter concurrent \nbecause the computations associated with the two instances of f are interleaved during execution. In \nfact, in loc. cit. it is shown how a term of that form can be syntactically pulled apart using semaphores \nand side-effects into a term of shape \u00b7\u00b7\u00b7 f \u00b7 \u00b7 \u00b7 || \u00b7 \u00b7 \u00b7 f \u00b7 \u00b7 \u00b7 || \u00b7 \u00b7 \u00b7 x \u00b7\u00b7\u00b7 which has precisely \nthe same interleaving of effects as the original. Note that some terms are not typeable, for example \nthe applica\u00adtion of term (5) to term (4) above. Many ICA programs have SCC typing; in fact all beta-normal \nform ICA programs and all ICA pro\u00adgrams with beta-redexes of .rst order or base types are SCC ty\u00adpeable \n(Ghica et al., 2006, Lemma 10). Loc. cit. also gives a fully abstract game semantic model of SCC. 3. \nType inference for SCC SCC is an assume-guarantee type system where the assume bounds must be provided \nby the context but the guarantee can be computed via type inference, rather than being supplied by the \nprogrammer. In this section we will give a decidability result for SCC type inference. Without loss of \ngenerality we will restrict the algorithm to higher-order closed terms. ICA typing can be determined \nwith a variant Hindley-Milner-style algorithm, and we assume it. It is well known that af.ne typing plus \nexplicit contraction is as expressive as conventional typing and we will assume our ICA type inference \nalgorithm uses this strategy. The details of such an algorithm are standard and will be omitted. We further \nassume that each type . . . ' is decorated with a fresh variable n, as in .n . . ', to form a skeleton \nfor an SCC type. For instance, the type (com . com) . com will be anno\u00adtated as (com n1 . com)n2 . com. \nThe variables which occur in covariant positions in the type of the term are called assumes and those \nthat occur in contravariant positions guarantees. Once this annotated type expression is constructed \nthe next step is to obtain a set of numeric constraints on the bounds. This is done by de.ning a function \nrecursively on the derivation tree, which produces a set of constraints as a result. First we de.ne the \nconstraints at the level of the type system: |.n| = {n} |. \u00d7 . ' | = |.|.|. ' | |.n . . ' | = {n}.|. \n' | |.n1 = .n2 12 | =(n1 = n2) .|.1|=|.2| In Fig. 1 we show an example annotated derivation tree, for \nthe term .fx.f(f(x)). Given a closed term M and its derivation tree, let C(M) be the constraint system \ngenerated from the conjunction of all the annotations in the derivation tree. For the example in Fig. \n1, C(.fx.f(f(x))) is n2 = n4 + n5 . n5 = n1 \u00b7 n7 . n6 = n1 . n3 = n1 \u00b7 n8 . n8 = n6 \u00b7 n9 . n9 = 1 . n7 \n= 1 . n4 = 1 We say that a constraint system is solved for a given mapping of assumes into non-negative \ninteger constants if constant bounds for all the guarantees consistent with the constraint system can \nbe found if they exist. The mapping of guarantees into non-negative integers is the solution of the system. \nThe .rst result of this paper is: THEOREM 3.1. For any closed ICA term M it is decidable whether C(M) \ncan be solved, in which case a solution can be constructed. Proof. This theorem is proved by giving \nan algorithm for solving the constraint system then showing that the algorithm terminates. We start by \nsubstituting all assumes with the provided constants. Note that all inequations in the constraint system \nhave one of the following forms: ' '' ''' ' n = n + nn = n \u00b7 nn = nn = k, k . N. We de.ne the relation \nn > n ' if n appears on the left on a constraint ' |.1 . .1 = .2 . .2| = |.2 = .1|.|.1 = .2| '' ^ and \nn on the right. (In what follows, the order of arguments to + and \u00b7 is irrelevant for the purpose of \nworking out if a constraint is |G = G | = |. = . | of a particular form.) The algorithm is: x:..G x:.'.G' \n1. Construct the set S of solutions of the system in the abstract The notation can be extended to |G=G \n' | in the obvious way. domain of positive integers formed by quotienting Z0,+ over The required constraints \nare indicated as annotations on the derivation rules: de.ning +, \u00b7, = on this domain in the obvious way. \n)n 2. For all constraint systems in S repeat x :(. ' f x : . n = 1 .|. ' = .| the equivalence relation \na = b .. a = b.(a = 2 . b = 2), (a) Replace all variables assigned 0 (1, respectively) at (1) with V \n n = 1 0 (1, respectively). n.|.| (b) Add equations n =0 or n =1 respectively for each such \u00d8f k : . \nG ' f M : . C replacement. )n G,x :(. ' f M : . |G=G ' | (c) Delete all inequations of the form n = 0 \n\u00b7 n ', and replace G ' ,x : . f M : . C all inequations of the form n = 0+ n ' and n = 1 \u00b7 n ' with ' \n G f .x : ..M : . . . |G=G ' | n = n . (d) Construct the > relation on its set of variables. G ' f Mi \n: .i Ci G f(M1,M2) : .1 \u00d7 .2 |G=G ' | The key rules are for contraction G ' ,x : .n1 ,y : .n2 f M : . \n' C G,x : .n f M[x/y]: . ' |G=G ' |. n = n1 + n2 and application (e) Repeat until > is well founded: \ni. Pick a cycle n1 > n2 \u00b7\u00b7\u00b7 nj > n1, or a single variable n1 where n1 > n1 (treating it as a one-element \ncycle). ii. If the system contains any inequations of the form n = '''' ''' ' n + n , n = n + k, n = \nn \u00b7 n , or n = n \u00b7 k, where n, n ' , n '' are variables involved in the cycle and k is a constant discard \nthe current solution and break to (2). G f M : .1 k . .2 C . f N :(.1) ' C ' iii. Pick a fresh variable \nn. G ' , . ' f MN : .2' |. = . ' |.|G=G ' |. 0 BB@ ^ 1 iv. Replace all occurrences of ni with n, adding \nequations of the form ni = n for each such replacement. CCA ' n = k \u00b7 n v. Delete all inequations of \nthe form n = n. x:.n.. ' x:.n ..' (f) Repeat until all RHSs of all equations are constant expres\u00ad sions: \n Note that the environments G, G ' and ., . ' in each rule above differ only in the choice of variables \nused as bounds. i. Choose a >-minimal element n.  ii. Let E be the set of RHSes of inequations having \nn on the LHS, and which are all constants. iii. Replace all occurrences of n on the RHS of any equation \nor inequation with the maximum element of E. (g) Report the resulting set of equations and inequations \nas one possible solution to the constraint system. Correctness. The key point of the correctness argument \nis that at step (2e), all remaining constraints of the form n = n ' + n '' and '''' ' n = n \u00b7 n imply \nthat n>n and n>n '', and thus n > n implies that n = n '. This has two consequences: In any cycle n1 \n> n2 \u00b7\u00b7\u00b7 nk > n1 all variables are greater than or equal to each other, and so must be equal, hence step \n(2(e)iii).  Constraints as in step (2(e)ii) cannot be satis.ed, and so show that the solution to the \nconstraints in the {0, 1, = 2} number system that is currently being tried is impossible.  If the dependency \nis well founded then given the form of the inequations in the system we can proceed to variable elimination \nvia substitution in a straightforward way. Termination. The algorithm contains three loops; the outside \nloop always terminates because it iterates over a .nite set, and the inside loops always terminate because \nthey always reduce ei\u00adther the number of variables, or the number of constraints. We take the empty relation \nto be trivially well founded. D In our running example suppose we take the assume to be n1 =2, i.e. function \nf can use its argument in two concurrent contexts. Solving the system of constraints gives the following \ntyping where the guarantees n2,n3 are given the smallest possible values: 2 34 .f..x.f (f(x)) : (com \n. com). com . com. This means that the term will use f in at most 3 non-sequential contexts and x in \n4. Finally, note that a purely symbolic solution of the constraint system, which does not require the \nassumes given as constants, is not always straightforward, so types cannot always be presented as in \nEx. 2.1. The reason is that for some (pathological) terms, giving the type symbolically would require \na large number of cases. There are even terms that type in some such cases but not others; one such example \nis the term .q.(.g.g(.x.g(qx)))(.b.(.k.((k(.u.u))(.l.((kb) (.t.(l(t skip)))))))(.v..w.wv)) :(com m . \ncom n . com)n2 . com, which types only if m = 1. 4. Mapping to SCC(1): serialisation Using GoS, we know \nhow to compile into hardware terms that only use contraction in sequential contexts (Ghica and Smith, \n2010). However, contraction in concurrent contexts cannot be compiled and must be replaced by systematic \nreplication of resources. We do that by translating any SCC-typed term into another SCC-typed term in \nwhich all bounds are set to the unit value. We call this type system SCC(1). Perhaps surprisingly, this \nis actually possible provided that we introduce new, multivariate binders for assignable variables. In \nthis section we present the translation, which we call serialisation because it results in a term in \nwhich all identi.ers are used sequentially. First an informal introduction. Supposed that we want to \ncom\u00adpile the term in our running example, .f..x.f(f(x)). We know that if f : com 2 . com then the term \nhas type 2 34 (com . com). com . com, i.e. it uses 3 instances of f non-sequentially and 4 of x. In \nhardware, contraction is used to mediate access to a shared piece of circuitry from several points in \na client. When sharing is not possible then a circuit can be replicated as much as needed. We will take \nthe same approach in the programming language, by replicating identi.ers with bounds larger than the \nunit. The SCC bounds in fact tell us precisely how many instances of an identi.er must be generated, \nbecause the bounds represent the maximum number of identi.ers used in parallel at any given moment. At \nthe level of types, .n . . ' becomes . . . . \u00b7\u00b7\u00b7 . . ' ; note that the expanded type must not be . \u00d7 \n. . . ', as product allows contraction. This means that our argument f must be changed to have type com \n. com . com, and we will need three instances of it, f1,f2,f3. The type of x does not change, but we \nwill need 4 instances of it x1,...,x4. The serialised form of the term is .f1f2f3x1x2x3x4.f1(f2x1x2)(f3x3x4). \nAn obstacle in the way of a straightforward transformation is the existence of storage types (var, sem) \nwhich can be used from non-sequential contexts. For example, how can the term newvar x.x := 0 || x := \n1 : com = newvar(.x : var 2 .x := 0 || x := 1) : com be serialized when the obvious serialization of \nthe body of the loop is .x1x2.x1 := 0 || x2 := 1? We can do that simply by generalising the local variable \nbinder itself and allowing it to bind several identi.ers to the same memory location. We can now de.ne \nthe transformation in a systematic manner, inductively on the SCC type derivation inferred in the previous \nsection. We denote the transformation operation by=. and we de.ne type level translation as s = s .1 \n. .' = . . .' .n . . ' = . . .n-1 . . ' . \u00d7 .' = . \u00d7 .' . For constants we de.ne k : . = k : . except \nfor newvar :(varn . com) . com = newvarn :(varn . com) . com = newvarn :(var . \u00b7 \u00b7\u00b7 . var . com) . com. \n| {z } n times Similarly for the other binders. We need an ancillary transformation in cases when multiple \nvariables could be assigned different SCC types. A simple example is .g.g(.x.x); g(.y.y||y), because \nboth occurrences of g must be assigned the same SCC type, so its arguments have to have the same SCC \ntype as well. Because the second argument is transformed to .y1y2.y1||y2, the .rst argument must receive \na dummy variable and be rewritten to .x2x1.x1. The subtype() construction inserts dummy variables whenever \nneeded: def subtype.=.(M)= M def subtype.m (M)= .x.subtype.m+1 (M ) 1 ..3=.2 n..3 ..3=.2 n..3 1 def \n subtype.n (M)= 1 ..3=.2 n..3 `\u00b4 .x1 ...xn.M subtype.2=.1 (x1) ... subtype.2=.1 (x1) def subtype.n (M)= \n3 ..1=.3 n..2 .x1 ...xn.subtype.1=.2 (Mx1 ...xn)  n6n6 n9 g :(com. com)n7 f g : com. com . n7 = 1 x \n: comf x : com . n9 = 1 n1 n1 n6n8 f :(com. com)n4 f f :(com. com) . n4 = 1 g :(com. com)n7 ,x : comf \ng(x): com . n8 = n6 \u00b7 n9 n1 n1n3 f :(com. com)n4 ,g :(com. com)n5 ,x : comf f(g(x)) : com . n5 = n1 \n\u00b7 n7 . n6 = n1 . n3 = n1 \u00b7 n8 n1 n3 f :(com. com)n2 ,x : comf f(f(x)) : com . n2 = n4 + n5 n1 n3 f .f.x.f(f(x)) \n: (com. com)n2 . com. com) . true Figure 1. Annotated SCC derivation tree for .fx.f(f(x)) g :(com2 . \ncom) f g=. g : com . com . com f gx : com1 f x=. x : com f x  f :(com2 . com)1 f fg :(com2 . com),x \n: com2 f g(x) =. f3 : com . com . com f f3 =. g : com . com . com,x1,x2 : com f g(x1x2)  ' '' ''' f \n:(com2 . com)1,g :(com2 . com)2,x : com4 f f(fx)=. f3, g, g : com . com . com,x1,x2,x 1,x : com f f3(gx1x2)(gx1x \n) 22 '' f :(com2 . com)3,x : com4 f f(fx)=. f3,f1,f2 :(com . com . com) . com,x1,x2,x 1,x 2 : com f \nf3(f1xx)(f2xx) '' '' f .fx.f(f(x))=.f .f3f2f1x1x2x1x .f3(f1x1x2)(f2x1x ) 22  Figure 2. Serialization \nof .fx.f(f(x)) def subtype.1..2=.3..4 (M)= `\u00b4 subtype.3..2=.3..4 subtype.1..2=.3..2 (M) We de.ne the \ntransformation as follows: x : .n f x : . =. x : . f x : . f k : . =. k : . G f M : .2 =. G ' f M ' : \n.2 . G '' G,x : .1 n f M : .2 =,x1 : .1,...,xn : .1 f M : .2 G,x : .1 n f M : .2 =. G ' ,x1 : .1,...,xn \n: .1 f M ' : .2 G f .x.M : .1 n . .2 =. G ' f .x1 \u00b7\u00b7\u00b7 xn.M ' : .1 n . .2 G f Mi : .i =. G ' f Mi ' : \n.i G f(M1,M2) : .1 \u00d7 .2 =. G ' f(M1' ,M 2' ) : .1 \u00d7 .2 G f M : .1 =. G ' f M ' : .1 .1 = .2 G f M : .2 \n=. G f subtype.1=.2 (M ' ): .2 G,x : .1 n1 ,y : .1 n2 f M : .2 =. G ' ,x1 : .1,...,xn1 : .1,y1 : .1,...,yn2 \n: .1 f M ' : .2 G,x : .1 n1+n2 f M[x/y]: .2 =. G ' ,x1 : .1,...,xn1+n2 : .1 f M[xn1+1/y1] \u00b7\u00b7\u00b7 [xn1+n2 \n/yn2 ]: .2 G f M : .1 n . .2 =. G ' f M ' : .1 n . .2 . f N : .1 =. . ' f N ' : .1 G,n \u00b7 . f MN : .2 \n=. G ' , .1' ,..., . ' f M ' (N ' [.1' /. ' ]) \u00b7\u00b7\u00b7 (N ' [. ' /. ' ]) : .2 nn In the last rule given an \nidenti.er type assignment . ', by . ' k we understand an identi.er type assignment isomorphic to . ' \nwhere all the identi.ers are fresh. The substitution N ' [. ' k/. ' ] replaces all the identi.ers in \nN ' which occur in dom(. ' ) with the corresponding fresh identi.er from dom(. ' k). The correctness \nof the transformation is formulated as: THEOREM 4.1. If G f M : . is a valid SCC term and G f M : . G \n'' : . '' : . ' . =f M then G ' f M is a valid SCC(1) term. Moreover, if M is a program then M may terminate \nif and only if M ' may terminate. Proof. The proof of the .rst part of the theorem is by structural \ninduction; that of the second, by showing that any sequence of reductions in the operational semantics \nof an SCC term corresponds to a sequence of reductions in the corresponding SCC(1) term, and vice versa. \nThe small-step operational semantics of ICA is given in Ghica and Murawski (2008) and is the obvious \none. We do not include it here for lack of space. SCC and SCI have essentially the same operational semantics \nas ICA. Typing. As our induction hypothesis, we take the following (stronger) hypothesis: for G f M : \n. a valid SCC term, and G f M : . =. G ' f M ' : . ', then G ' f M ' : . ' is a valid SCC(1) term, . \n' = ., and G ' is G with all variables x : .1 n replaced with at most n copies of xi : .1. It is .rst \nnecessary to prove that for any SCC type ., . is an SCC(1) type, but this is obvious from the de.nition \nof type level translation, because it cannot produce any bounds greater than 1. The base case is trivially \ntrue by de.nition for the second rule; for the .rst rule, the knowledge that the LHS is typed correctly \nimplies that n is at least 1, and thus the typing is correct (via the identity axiom), . ' = . by de.nition, \nand the use of 1 copy of x ful.ls the requirement to have at most n copies with n = 1. In the case of \nContraction note that N ' [. ' k/. ' ] must have the same SCC type as N ' because it is a replacement \nof variables in N ' with other variables of the same type. None of the N ' [.k' /. ' ] share free variables \nwith M ' by de.nition, and because the type of ' '' M is .1 n . .2, the type of M (N [.1' /. ' ]) is \n.1 n-1 . .2 etc., until the type of M ' (N ' [. ' /. ' ]) is .2, which proves the case of n Contraction. \nThe key cases are Subtyping and Application. For Application, observe that N ' [. ' k/. ' ] must have \nthe same SCC type as N ' because it is a replacement of variables in N ' with other variables of the \nsame type. None of the N ' [. ' k/. ' ] share free variables with M ' by de.nition, and because the type \nof M ' is .1 n . .2, the type of M ' (N ' [.1' /. ' ]) is .1 n-1 . .2, and so on, until the type of M \n' (N ' [. ' /. ' ]) is .2, proving that the eighth rule n creates a correctly typed SCC(1) expression. \nCorrectness of Subtyping is proved by induction on the hypoth\u00adesis, i.e. if M ' : .1, then subtype.1=.2 \n(M ' ): .2. Note that the cases in the de.nition of subtype mirror the cases in the de.nition of = on \nSCC types (with the third and fourth cases being special cases of the .fth, needed to make the recursion \nwell-founded), and thus subtype.1=.2 is de.ned whenever .1 <.2. The base case (the .rst de.nition) is \ndegenerately true, the .fth case is true by de.nition, and the second, third, and fourth cases are obviously \ntrue 5. Compilation and correctness if the type of x is taken to be .1, .2, and .3 respectively. Here \nwe will discuss compilation into asynchronous circuits using It is important to note also that this transformation \nis composi\u00adthe Geometry of Synthesis approach. tional on the syntax, i.e. for any term G f M : . and \ncontext C[-] Consider the typical implementation of a digital half-adder: M' exist context C ' such that \n\u00d8fC[M]: com =.\u00d8fC ' [M ' ]: com. (1) Soundness. The following uses the operational semantics (OS) of \nSCC, which is essentially the same as that of ICA, the obvious combination of CBN lambda calculus, simple \nimperative language and parallel execution (Ghica and Murawski, 2008). The reduction rules are small-step \nand the semantics is non-deterministic because of possible race conditions. By termination of a program \n(closed term of com type) M. we mean may-termination, i.e. the existence of a chain of reductions leading \nto skip. We do not de.ne the OS for lack of space. The .rst step of the proof is to eliminate the multivariate \nbinders from the SCC(1) term G ' f M ' : . '; we do that simply by replacing all terms of form newn(.x1 \n...xn.M) with new(.x.M[x/xi]) where x is chosen fresh. We can do this because of the previous result \n(the correctness of typing). The resulting term is not pure SCC(1) but it must be operationally equivalent \nby the very de.ni\u00adtion of the multivariate binder. We denote this transformation by M. ff =. G ' : . \n' such that \u00d8fC[M]: com, if G f M. there f  The inputs are A and B and outputs sum S and carry C: S \n= A . B, C = A . B. Suppose that the circuit is in an initial state, where A = B = C = S =0 and we want \nto change the input values to A = B =1. In a synchronous (clocked) circuit, the system clock has a period \nlonger than the propagation delay of signals through wires and gates, and values are only considered \nmeaningful on the falling (or raising) edge of the clock, giving them time to stabilise at the correct \nvalues of S =0,C =1. However, in an asynchronous (clock-less) circuit the new input signals will propagate \nalong the wires and reach the four gate inputs at different times. Depending on the relative wire delays, \nthere are 8 different orders in which this can happen. The two gates will see a sequence of four distinct \ninputs, and produce the corresponding outputs, before settling on the correct values. As inputs change \nfrom 0 to 1 on its inputs, the outputs of the AND gate We de.ne a logical relation G f MR.M ' between \nSCC terms are the sequence 001, which corresponds to a clean transition such that there exist G ' ,. \n' such that G f M : . =. G ' f M ' ' For programs, \u00d8f MRcomM if and only if M. if and only if 0 to 1 \nthe outputs will see the sequence 010. Before settling on the correct value of 0, the circuit shows a \nspurious value of 1, a .. This is lifted to open terms in the usual manner, i.e. for all : . ' from \n0 to 1. However, on the XOR gate, as the inputs change from f . M' command contexts C which accept a \nterm of type . and trap free f so-called hazard. If this adder is connected to other circuits then \nthese circuits will consider the hazard value as a genuine value and propagate it, leading to more spurious \nvalues and ultimately a rather variables in G, C[M]. if and only if C ' [M '].. We can write this f because \nof (1) and because there is no point in using multivariate chaotic circuit behaviour. In a nutshell, \nthis is the main problem of asynchronous circuit binders in the context, so we eliminate them only in \nthe original term. design, and there exist a variety of theoretical and practical ap\u00ad proaches to mitigating \nit (Hauck, 1995). 5.1 Event logic A particularly interesting and clean solution was proposed by We induct \non the reduction rules of the operational semantics. The base cases (for identity and constants) are \ntrue by de.nition, as the transformation in those cases does not change them or their behaviour. The \nonly new construct, the multivariate binder has been syntactically eliminated. Most in-context reductions \nare also trivial. In fact this is also the reason why the rules of the OS can be omitted, because this \nproof is entirely parametric on them. The only interesting case is function application when the func\u00adtion \nhas been reduced to a normal form: (.x.M)N, s -. M[N/x],s ' . (2) The serialised term is \u00b4 ` Sutherland \n(1989) in his seminal Turing Award lecture. At the foundation of his approach lies the observation that \nboolean logic is not particularly well suited to implementing asynchronous cir\u00adcuits, suggesting instead \nan event logic: a logic of pure control, dealing not with true and false but with the more fundamental \nnotions that something happened or nothing happened . The ba\u00adsic logical functions on events can be (ef.ciently) \nimplemented as special gates or modules. At the level of physical implementation, an event is either \na high-to-low or a low-to-high transition (edge) subtype(.1)m..2=(.1' )n.. ' (.x1 \u00b7\u00b7\u00b7 xm.M ' ) 2 (N1' \n) \u00b7\u00b7\u00b7 (Nn' ), (3) where each Nk ' is a copy of the same term but with free variables changed. An argument \non the de.nition of subtype() will show imme\u00addiately that it is semantically innocuous, only introducing \ndummy variables and lambdas so that the types match. Then we notice that the only difference between \nthe two is that reduction 2 executes one reduction consisting of n substitutions, whereas reduction 3 \nexecutes n reductions consisting of one sub\u00adstitution each. D The serialization of .fx.f(f(x)) is shown \nin Fig. 2, with term types omitted for brevity. on a wire, the so-called two-phase event encoding. XOR \nprovides an OR-like function for events, producing an output event when an event arrives on any of the \ninput ports. C is the so-called Muller C-element (Miller, 1965, Chap. 10), a fundamental gate in asynchronous \ndesign. It has an AND-like functionality on events, producing an output when events arrive on both input \nports. TOGGLE steers events to its outputs alternately, starting with the dot. SELECT steers its input \nevent to the the output according to the value of input S. CALL remembers which client , R1 or R2, called \nmore recently and it steers the matching D back to D1 or D2 as is the  Figure 3. Logic modules for events \ncase. CALL can be generalised to the case where R, D, Ri,Di represent sets of ports. ARBITER grants service \nG1 or G2 to only one input request R1 or R2 at a time, delaying subsequent grants until the matching \ndone event D1 or D2. It also makes sense to consider as primitives W IRE, the simple connector, and F \nORK the forking connector with one input and two outputs. Ghica and Smith (2010) give a compositional \ntrace model for event logic. Composition of event-logic circuits is rather subtle because the interaction \nbetween two circuits can lead to unsafe traces. We illustrate this with the following example. Given \nthe obvious trace semantics for the two circuits, the compo\u00adsition F ORK; XOR might be expected to produce \ninput-output traces of the form (AZZ) *. However, if we consider traces includ\u00ading the internal channels \nX and Y , we can see that these observable traces might correspond to interactions AXY ZZ, which are \nfrom a physical point of view unsafe: if events X and Y arrive very close to each other temporally, then \nit is possible that the sequence ZZ consists of two events that happen faster than the inertial delay \nof the wire or the gate and may be suppressed (Spars\u00f8 and Furber, 2001, Sec. 6.1.3). However, composition \ndisallows such unsafe traces. The set of traces of a composite system only contains those traces that \ncan only be produced safely. Intuitively, the safe composition of two circuits involves only those traces \nin which, at the interface, each output produced by a circuit can be immediately consumed as an input \nby the other circuit. From this point of view, there are no safe traces in the composition above, i.e. \nF ORK; XOR = \u00d8. This can be shown analysing all possible interactions. The interaction between the two \nis unsafe because after input A and interface event X the next output, on Y , cannot be consumed by XOR \nbefore it outputs on Z. AY is unsafe for a similar reasons. Since all interactions are pre.xed by a sequence \nof events A \u00b7 X or A \u00b7 Y there are no safe interactions. This can be proved formally in the model of \nGhica and Smith (2010). On the other hand we can show that F ORK; C has the same behaviour as a wire \nconnecting input A and output Z, and all interactions in the composite circuit are safe.  5.2 Compiling \nSCI into event logic The game model for SCI can be represented using only the XOR, C, CALL, WIRE and \nFORK fragment of event logic. The concrete representation of types follows the game-semantic model of \nthe language so that each game-semantic move corre\u00adsponds to a distinct port of a circuit. Concretely, \nthe port structures generated during compilation is as follows: com : the type of commands corresponds \nto one input port Q and one output port A. Intuitively, Q represents a request from the environment to \nexecute the command and A and acknowledg\u00adment of termination. exp : the type of expressions corresponds \nto one input port Q and two output ports T and F . As before, Q is a request to evaluate the expression \nwhile T and F are the two possible outcomes, true or false. var : the type of variable corresponds to \ninput ports Q, W T, W F and output ports T, F, A. Q is a read request, answered by T (true) or F (false), \nwhile WT (WF ) is a request to write true (false) and is acknowledged by A. .1 \u00d7 .2 : the product type \nis the disjoint sum of the port structures corresponding to .1,.2. .1 . .2 : the product type is the \ndisjoint sum of the port structures corresponding to .1,.2 except that the input-output polarities associated \nwith .1 are reversed. The base-type constants are  Note that in both cases the request Q is immediately \npropagated to the corresponding acknowledgment. The implementation of 0:exp is analogous. The representations \nof games for the imperative language con\u00adstants are given in Fig. 4, and are simply event logic representa\u00adtions \nof the game semantic model of SCI. The ports on this circuit are decorated in the same way as the types \nin the signature in order to make the correspondence obvious. The input-output behaviour of these circuits \nis operationally intuitive. We only discuss sequen\u00adtial composition, seq : com \u00d7 com ' . com ''. The \ninitial input re\u00adquest is Q '', corresponding to the return type com ''. This request is simply propagated \nas an output request Q, corresponding to the operator requesting the evaluation of its .rst argument. \nWhen it ac\u00adknowledges termination A, it is in turn simply propagated to Q ' , re\u00adquesting the evaluation \nof the second argument. When it acknowl\u00adedges termination A ' the operator can acknowledge termination \nto the environment A '' . Here we only consider the representation of lazy sequential ' '' : operators, \nsuch as orl : exp \u00d7 exp . exp  Parallel and (eager) sequential operators raise certain technical problems \ndiscussed in Ghica and Smith (2010). Note that this way of encoding boolean values using different ports, \ncalled dual rail, is standard in asynchronous circuit design and can be extended to integers.  Figure \n4. Event-logic circuits for SCI imperative constants The CALL module is used to implement the family \nof diagonal \u00d7 . '' strategies d. : . . . ' used in contraction. The implementa\u00adtion of dcom : com . (com1 \n\u00d7 com2) is simply the CALL mod\u00adule. Higher-order contraction is implemented using more complex generalised \nCALL module as shown in loc. cit.. The local-variable binder newvar :(var . com ' ) . com '' can be also \nbe implemented by taking advantage of the stateful nature of the CALL module. SCI terms can be interpreted \ninductively on the syntax, where terms are formed from constants, contraction (described above), function \napplication, function declaration and free identi.ers. Given circuits F, M which are compilations of \nterms G fr F : . . . ' and, re\u00adspectively, . fr M : ., the circuit for G, . fr F (M): . ' is con\u00adstructed \nas a certain interconnect for the two circuits, as discussed in Sec. 1 (connectors labelled by G, D, \nT, T ' are multi-line input\u00adoutput bundles). The greyed-out circuit connecting the argument to the function \nis the evaluation morphism, the uncurrying of the identity at type . . . '. The entire construction can \nbe expressed in the language of compact closed categories in a canonical way. Function declara\u00adtion is \nthe currying relabelling of ports discussed earlier, and free identi.ers are the identity (wires). A \nsimple but useful program which illustrates the compilation of open higher-order programs is in-place \nmap, which applies a function f to all elements of a data structure, modifying them in place. Consider \nan iterator over some data structure, provided with the following interface: init : com initialise an \niterator over the data structure; curr : var get the current element in the data structure; next : com \nadvance the iterator to the next element; more : exp return false if the end of the data structure has \nbeen reached and true otherwise. Note that SCI being a call-by-name language these identi.ers rep\u00adresent \nthunks, i.e. parameter-less procedures. The program for in\u00adplace map is: init : com, curr : var, next \n: com, more : exp fr .f : exp . exp.init; while (more)(curr := f(!curr); next): com. The structure of \nthe resulting circuit is shown in Fig. 5, along with the concrete circuit, which is strikingly simple. \nPorts are annotated with the variable name for readability; top-level ports are top.q and top.a. For \nfunction f : exp ' . exp the ports corresponding to the argument are primed. Technically, variable curr \nshould go through a contraction circuit dvar : var . var \u00d7 var; however, because the .rst occurrence \nuses only the write ports and the second only the read ports, no connectors need to be actually reused \nand contraction can be omitted. In loc. cit. we show that compiled circuits are both logically and physically \ncorrect, i.e. delay-insensitive. Any term is compiled into an event logic circuit that has the same input-output \nbehaviour as the (sound) game semantic model of the language. Moreover, the circuits constructed by the \ncompiler are always safe in the sense discussed earlier in Sec. 5.1. 5.3 Contraction and local variables \nin concurrent contexts We can still use the method described above except that the local variable binder \nmust handle the binding of multiple identi.ers to the same memory cell. Moreover, the identi.ers may \noccur in concurrent contexts. It also makes sense now to use semaphores. In loc. cit. variable contraction \ncan only be done in a sequential setting; the diagonal dvar : var . var1 \u00d7 var2 is shown in Fig 6. In \nthe new setting, we do not have contraction of var-typed identi.ers in the syntax but the simultaneous \nbinding of several identi.ers to the same memory cell amounts to the same thing in the implementation, \nif the identi.ers belong to sequential contexts. This is not the case in non-sequential contexts, because \nthe CALL module cannot handle concurrent request, which amount to a race condition. The standard solution \nin asynchronous design, which we will apply, is to guard the CALL modules by using n-way ARBITERs to \nmediate all inputs. Such circuits are not basic event  Figure 5. In-place map, overall structure and \nevent-logic implementation Figure 6. Event logic implementation for sequential contraction dvar : var \n. var1 \u00d7 var2. logic gates but can be constructed from the 2-way arbiters. In Fig. 7 we show a standard \n3-way arbiter construction due to Seitz (1980). More ef.cient n-way arbiters can be designed however \ndirectly rather than compositionally from smaller arbiters (Martin, 1990). The new multivariate binding \ncircuit is represented in Fig. 8. We will not provide semantic-directed implementations for semaphores \nnoting that they can be implemented in the language using shared memory in standard ways, e.g. the Peterson \n(1981) tie-breaker algorithm. As Murawski (2010) points out, the .rst\u00adclass semaphore provided in the \noriginal ICA is needed mostly for Figure 7. A 3-way arbiter technical reasons related to de.nability \nand not algorithmic con\u00adsiderations. The correctness of the compilation is, as in Ghica and Smith (2010), \nthe correctness of representation of the game model in event logic gates. Correctness: If K receives \nan input event on its Q port it will produce an output event on its A port iff M terminates. Safety: \nCircuit K is delay-insensitive. Proof. The proof of this theorem is a corollary of Thm. 5.3 in loc. cit., \nwhich is essentially proving a logical relation between the input-output behaviour of any circuit and \nthe game semantic model of the corresponding term. Since we are still within the SCC(1) game semantic \nmodel the proof stands, but it has to be extended with a new case, the family of variable binders for \nmul\u00adtiple identi.ers. Because of the type of the multivariate binder ((var . var . com) . com) the concurrent \nusage of the vari\u00adables does not violate the seriality constraint of the game model (Def. 2.7 in loc. \ncit.). The n-way arbiter then ensures that the un\u00adderlying contraction circuit is actually used sequentially, \nbecause all read and write requests to the variable are serialized. The two XOR gates take mutually exclusive \ninput events, therefore they are always used safely. D  Figure 8. Event logic for contraction in concurrent \ncontexts. This, together with the correctness of type inference from ICA to SCC (Thm. 3.1) and program \ntransformation from SCC to SCC(1) (Thm. 4.1) lead to the main result, THEOREM 5.2. Programs in ICA which \nhave an SCC type can be effectively mapped into delay-insensitive event-logic circuits.  5.4 Example \nWe show the compilation of three terms with identical ICA types but distinct SCC and serialised versions. \nThe terms, the inferred SCC types and the SCC(1) versions are given below, assuming f : com 1 . com. \n.fx.f(fx):(com 1.com)2.com 1.com =. .f1f2x.f1(f2x) .fx.fx; fx:(com 1.com)1.com 1.com =. .fx.fx; fx .fx.fx||fx:(com \n1.com)2.com 2.com =. .f1f2x1x2.f1x1; f2x2 The compiled versions are in Fig. 9. The actual synthesised \ncir\u00adcuits are inside the grey box. The circuits marked Fi,Xi, F, X are instances of the argument that \nmust be supplied by the designer to create a working circuits or, equivalently, arguments for f, x to \nlead to programs. Note the trade-offs in the last two designs. The second circuit contains two fairly \nexpensive diagonal circuits but it only requires one instance of F and X, while the third consists only \nof connectors, but requires two instances of each of F and X; 6. Related and further work There exist \nother higher-level approaches to hardware synthesis: SYSTEMC1 or COWARE2, hardware compilers based on \nprocess calculi, such as (van Berkel et al., 1991), or higher-order structural languages such as LAVA \n(Bjesse et al., 1998); these are interesting and useful, but conceptually different ways of approaching \nVLSI design. 1 www.systemc.org 2 www.coware.com Hardware compilation in the behavioural style we are \npursuing in GoS has a substantial literature which we cannot discuss exten\u00adsively; some entry points \nto the literature are Budiu and Goldstein (2002); Buyukkurt et al. (2006). This line of work is in some \nsense parallel with ours and focuses almost exclusively on optimisation techniques such as automated \nparallelisation whereas we are con\u00adcerned with problems of a structural nature. This difference of fo\u00adcus \nis discussed extensively in Ghica (2009). Type inference for SCI has been studied before, but for a richer \nversion of the type system which we do not need (Yang and Huang, 1998). A program transformation similar \nin spirit with our seriali\u00adsation is linearisation, due to Kfoury (2000). The .rst main differ\u00adence is \nthat linearisation replicates every variable occurrence, with\u00adout permitting contraction at all. The \nsecond one is that replication of variables of higher-order type does not have to be uniform, but can \nresult in occurrences with different linearized types. The .rst difference is conceptually signi.cant \nbut technically rather minor, whereas the second one is conceptually minor but, perhaps surpris\u00adingly, \ntechnically signi.cant resulting in the existence of normal forms which can be linearized but cannot \nbe serialized. From the point of view of compiler support for separate compilation, foreign function \ncalls and run-time services we consider it crucial to offer a consistent interface between a serialized \nterm and its context, hence our decision. Also note that the soundness argument of Thm. 4.1 is simpli.ed \nby the fact that serialization is uniform across copies of identi.ers, leading to a very simple inductive \nstep in the proof. However, inside the serialised term itself perhaps a more .exi\u00adble approach which \nmixes serialisation and linearization could be used at the expense of some complication in the algorithms. \nEven so, it is worth noting that non-typeable terms are somewhat patho\u00adlogical and unlikely to be found \nin algorithmically relevant pro\u00adgrams. Combining serialization with a selective form of lineariza\u00adtion \ncan lead to interesting optimisations techniques. Various per\u00adformance parameters can be calculated at \ncompile-time, e.g. foot\u00adprint (number of gates) or latency (longest delay). Linearisation of an identi.er \nmakes a trade-off between duplicating arguments to functions and using expensive contraction circuitry, \nas can be seen in Fig. 9. In this sense, serialization is the extreme scenario in which contraction is \nalways favoured before replication. Introduc\u00ading a controlled form of linearization will be investigated \nin further optimised implementations of the compiler. Finally, the approach here can be extended to synchronous \ncir\u00adcuits using the round abstraction methodology for low-latency encoding of asynchronous speci.cations \ninto synchronous cir\u00adcuits (Ghica and Menaa, 2010). This is forthcoming work. References Per Bjesse, \nKoen Claessen, Mary Sheeran, and Satnam Singh. Lava: hardware design in Haskell. In ICFP, pages 174 184, \n1998. Mihai Budiu and Seth Copen Goldstein. Compiling application\u00adspeci.c hardware. In FPL, pages 853 \n863, 2002. Betul Buyukkurt, Zhi Guo, and Walid A. Najjar. Impact of loop unrolling on area, throughput \nand clock frequency in Roccc: C to VHDL compiler for FPGAs. In ARC, pages 401 412, 2006. Dan R. Ghica. \nGeometry of Synthesis: a structured approach to VLSI design. In POPL, pages 363 375, 2007. Dan R. Ghica. \nFunction interface models for hardware compilation: Types, signatures, protocols. CoRR, abs/0907.0749, \n2009. Dan R. Ghica and Mohamed N. Menaa. On the compositionality of round abstraction. In CONCUR, pages \n417 431, 2010.  Figure 9. Three example circuits Dan R. Ghica and Andrzej Murawski. Angelic semantics \nof .ne\u00adgrained concurrency. Annals of Pure and Applied Logic, 151 (2-3):89 114, 2008. Dan R. Ghica and \nAndrzej S. Murawski. Compositional model extraction for higher-order concurrent programs. In TACAS, pages \n303 317, 2006. Dan R. Ghica and Alex Smith. Geometry of Synthesis II: From games to delay-insensitive \ncircuits. Electr. Notes Theor. Comput. Sci., 265:301 324, 2010. Dan R. Ghica, Andrzej S. Murawski, and \nC.-H. Luke Ong. Syn\u00adtactic control of concurrency. Theor. Comput. Sci., 350(2-3): 234 251, 2006. S. Hauck. \nAsynchronous design methodologies: an overview. Pro\u00adceedings of the IEEE, 83(1):69 93, Jan 1995. G. M. \nKelly and M. L. Laplaza. Coherence for compact closed categories. Journal of Pure and Applied Algebra, \n19:193 213, 1980. A. J. Kfoury. A linearization of the lambda-calculus and conse\u00adquences. J. Log. Comput., \n10(3):411 436, 2000. Wayne Luk, David Ferguson, and Ian Page. Structured hardware compilation of parallel \nprograms. In Will Moore and Wayne Luk, editors, More FPGAs. Abingdon EE&#38;CS Books, 1994. A. J. Martin. \nDevelopments in concurrency and communication, chapter Programming in VLSI: From communicating processes \nto delay-insensitive circuits, pages 1 64. Addison-Wesley, 1990. Guy McCusker. Categorical models of \nsyntactic control of inter\u00adference revisited, revisited. LMS Journal of Computation and Mathematics, \n10:176 216, 2007. Guy McCusker. A graph model for imperative computation. Logi\u00adcal Methods in Computer \nScience, 6(1), 2010. R. E. Miller. Sequential Circuits. Wiley, NY, 1965. Andrzej S. Murawski. Full abstraction \nwithout synchronization primitives. Electr. Notes Theor. Comput. Sci., 265:423 436, 2010. Peter W. O \nHearn, John Power, Makoto Takeyama, and Robert D. Tennent. Syntactic control of interference revisited. \nTheor. Comput. Sci., 228(1-2):211 252, 1999. Ian Page and Wayne Luk. Compiling Occam into FPGAs. In \nW. Moore and W. Luk, editors, FPGAs, pages 271 283. Abing\u00addon EE&#38;CS Books, 1991. G. L. Peterson. \nMyths about the mutual exclusion problem. Infor\u00admation Processing Letters, 12:115 116, 1981. Uday S. \nReddy. Global state considered unnecessary: An introduc\u00adtion to object-based semantics. Lisp and Symbolic \nComputation, 9(1):7 76, 1996. John C. Reynolds. Syntactic control of interference. In POPL, pages 39 \n46, 1978. John C. Reynolds. The essence of Algol. In Proceedings of the 1981 International Symposium \non Algorithmic Languages, pages 345 372. North-Holland, 1981. John C. Reynolds. Syntactic control of \ninference, part 2. In ICALP, pages 704 722, 1989. C. L. Seitz. Ideas about arbiters. Lambda, 1(1):10 \n14, 1980. J. Spars\u00f8 and S. Furber, editors. Principles of Asynchronous Circuit Design: A Systems Perspective. \nEuropean Low-Power Initiative for Electronic System Design. Kluwer Academic Publishers, 2001. Ivan E. \nSutherland. Micropipelines. Commun. ACM, 32(6):720 738, 1989. Turing Award Paper. C. H. van Berkel and \nR. W. J. J. Saeijs. Compilation of communi\u00adcating processes into delay-insensitive circuits. In Proceedings \nof ICCD, 1988. Kees van Berkel, Joep Kessels, Marly Roncken, Ronald Saeijs, and Frits Schalij. The VLSI-programming \nlanguage Tangram and its translation into handshake circuits. In EURO-DAC, pages 384 389, 1991. Hongseok \nYang and Howard Huang. Type reconstruction for syn\u00adtactic control of interference, part 2. In ICCL, pages \n164 173, 1998.  \n\t\t\t", "proc_id": "1926385", "abstract": "<p><i>Geometry of Synthesis</i> is a technique for compiling higher-level programming languages into digital circuits via their game semantic model. Ghica (2007) first presented the key idea, then Ghica and Smith (2010) gave a provably correct compiler into asynchronous circuits for Syntactic Control of Interference (SCI), an affine-typed version of Reynolds's Idealized Algol. Affine typing has the dual benefits of ruling out race conditions through the type system and having a finite-state game-semantic model for any term, which leads to a natural circuit representation and simpler correctness proofs. In this paper we go beyond SCI to full Idealized Algol, enhanced with shared-memory concurrency and semaphores.</p> <p>Compiling ICA proceeds in three stages. First, an intermediate type system called Syntactic Control of Concurrency (SCC), is used to statically determine \"concurrency bounds\" on all identifiers in the program. Then, a program transformation called <i>serialization</i> is applied to the program to translate it into an equivalent SCC program in which all concurrency bounds are set to the unit. Finally, the resulting program can be then compiled into asynchronous circuits using a slightly enhanced version of the GoS II compiler, which can handle assignable variables used in non-sequential contexts.</p>", "authors": [{"name": "Dan R. Ghica", "author_profile_id": "81100060125", "affiliation": "University of Birmingham, Birmingham, United Kingdom", "person_id": "P2509627", "email_address": "d.r.ghica@cs.bham.ac.uk", "orcid_id": ""}, {"name": "Alex Smith", "author_profile_id": "81467661642", "affiliation": "University of Birmingham, Birmingham, United Kingdom", "person_id": "P2509628", "email_address": "AIS523@bham.ac.uk", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926425", "year": "2011", "article_id": "1926425", "conference": "POPL", "title": "Geometry of synthesis III: resource management through type inference", "url": "http://dl.acm.org/citation.cfm?id=1926425"}