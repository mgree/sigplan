{"article_publication_date": "01-26-2011", "fulltext": "\n Veri.ed Squared: Does Critical Software Deserve Veri.ed Tools? Xavier Leroy * INRIA Paris-Rocquencourt \n Xavier.Leroy@inria.fr Abstract The formal veri.cation of programs have progressed tremendously in the \nlast decade. Principled but once academic approaches such as Hoare logic and abstract interpretation \n.nally gave birth to quality veri.cation tools, operating over source code (and not just idealized models \nthereof) and able to verify complex real-world applications [6, 8, 15, 18]. In this talk, I review some \nof the obstacles that remain to be lifted before source-level veri.cation tools can be taken really seriously \nin the critical software industry: not just as sophisticated bug-.nders, but as elements of absolute \ncon.dence in the correctness of a critical application. Categories and Subject Descriptors D.2.4 [Software \nEngi\u00adneering]: Software/Program Veri.cation; D.3.1 [Programming Languages]: Formal De.nition and Theory; \nD.3.4 [Programming Languages]: Processors; F.3.1 [Logics and meanings of programs]: Specifying and Verifying \nand Reasoning about Programs; F.3.2 [Logics and meanings of programs]: Semantics of Programming Languages \nGeneral Terms Languages, Veri.cation Extended abstract of invited talk Critical software Software is \ncritical when human lives are at stake and there is no simple, safe failure mode. I take the paradig\u00admatic \nexample of electronic .ight control systems ( .y-by-wire ) in aircraft, which provides a fascinating \nglimpse of what software perfection may look like. Impressive reliability has been achieved so far but \nat tremendous costs by following meticulous develop\u00adment and certi.cation processes, as codi.ed in DO-178 \nregulations for instance. These processes rely on (qualitative) review, (quan\u00adtitative) analysis, and \n(black-box) testing at multiple levels of the design, complemented with strong traceability between high-level \nrequirements and actual implementation. In this domain, veri.ca\u00adtion tools have great potential to facilitate \nand strengthen the results of analysis phases, while at the same time remove the need for some costly \ntests [15]. Trust in compilers and code generators With a few notable ex\u00adceptions, most veri.cation tools \noperate over the source code: gen\u00ad * Partially supported by ANR grant Arp`ege U3CAT. Copyright is held \nby the author/owner(s). POPL 11 January 26 28, Austin, TX, USA ACM 978-1-4503-0490-0/11/01. erally C \ncode, possibly Scade/Simulink block diagrams. The guar\u00adantees provided by these tools are therefore vulnerable \nto miscom\u00adpilation: compiler bugs that cause wrong executable code to be silently generated from correct \nsources. DO-178 recognizes this is\u00adsue and mandates that either the compiler/code generator is quali\u00ad.ed \nto the same level of assurance as the code it compiles, or the generated code is certi.ed as if hand-written \n[9]. Neither require\u00adment can be fully achieved in the case of a conventional C compiler. Even when possible, \ne.g. for Scade-to-C code generators, quali.ca\u00adtion of a compiler generally comes at the cost of inef.ciencies \nin the generated code. An obvious alternative is compiler veri.cation: apply mech\u00adanized program proof \nto the compiler itself and prove semantic preservation (the generated code behaves as prescribed by the \nse\u00admantics of the source program). For example, CompCert [10, 11] is a lightly-optimizing, multi-pass \ncompiler for a large subset of C that was programmed and proved semantically preserving using Coq. From \nthe results of the CompCert experiment, the formal veri\u00ad.cation of realistic compilers appears within \nreach of today s proof technology, and generates (arguably) unprecedented con.dence in the compilation \nprocess and, indirectly, in source-level veri.cation. At the same time, much remains to be done in this \narea, such as verifying more of the .rst miles (preprocessing, parsing) and the last miles (assembing \nand linking, or even connections with micro-architecture veri.cation), and proving compilers for source \nlanguages signi.cantly different from C. Trust in veri.cation tools While unsound veri.cation tools still \nhave value as bug-.nders, veri.cation-based certi.cation of critical software demands formal evidence \nthat the results of the veri.ca\u00adtion tools are sound with respect to concrete executions. The gen\u00aderal \nprinciples for stating and proving these soundness results are well known; some approaches, such as classic \nabstract interpreta\u00adtion, even ensure soundness by construction of the analysis. Mech\u00adanization of these \nprinciples appear well within reach [2, 5, 17]. Perhaps the biggest challenge to extend these efforts \nto realistic veri.cation tools is the need to prove some of the fairly complex algorithms involved in \nthe implementation of abstract domains and theorem provers. Veri.ed vs. validated Not all parts of a \ncompiler or veri.er need to be proved: only those parts that affect soundness, but not those part that \nonly affect termination, precision of the analysis, or ef.\u00adciency of the generated code. Leveraging this \neffect, complex al\u00adgorithms can often be decomposed into an untrusted implementa\u00adtion followed by a formally-veri.ed \nvalidator that checks the com\u00adputed results for soundness and fails otherwise. (Failure is not an option \nin .ight, but is an option at compile-time and veri.cation\u00adtime.) In static analysis, for example, it \nis much easier to prove the code that checks that an abstract value X is a post-.xpoint of an operator \nF than to prove the correctness of the .xpoint iteration that computes X. Likewise, in a compiler, translation \nvalidation of the results of an untrusted compilation pass can provide soundness guarantees as strong \nas formal veri.cation of this pass, provided the validator is proved sound [12, 13, 16]. While often \neffective to reduce the overall proof effort, validation a posteriori is not a silver bullet either: \nmany compiler passes are no easier to validate than to prove correct once and for all. Between full compiler \nveri.ca\u00adtion and full translation validation lies a continuum of combined approaches that remain to be \nsystematically explored.  Mechanized semantics Formal veri.cation of compilers and pro\u00adgram veri.ers \ndoes not eliminate all sources of uncertainty, but re\u00adduces the issue of trusting these tools to (primarily) \nthe issue of trusting the formal semantics used for the source and target lan\u00adguages. Extensive manual \nreviews and testing of these semantics remains a necessity. As a further dif.culty, different tasks favor \ndif\u00adferent styles of semantics: big-step semantics or de.nitional inter\u00adpreters are perhaps the easiest \nto review by hand, while veri.cation of type-checkers, abstract interpreters, and compilers favor Wright-Felleisen \nsmall-step semantics, collecting semantics, and transition semantics with explicit contexts, respectively. \nFinally, there is also a strong tension between low-level operational semantics, easy to mechanize but \ndif.cult to work with, and higher-level approaches such as type-or step-indexed logical relations that \nprovide much nicer reasoning principles but are expensive to set up [1, 4]. Agree\u00adment on one reference \nsemantics for, say, the C language is there\u00adfore unlikely to happen. Instead, we should strive for systematic, \nmechanized proofs of equivalence or implication between these various semantics. Such proofs, as well \nas tool veri.cation in gen\u00aderal, considerably strengthen the con.dence we can have in these semantics. \nMultiple languages Many applications combine sources written in several languages, such as Scade/Simulink, \nC, and assembly for control/command systems. Also, implementations of high-level languages combine compiled \ncode with run-time systems written in a lower-level language. Verifying the correctness of the whole \nsystem requires a delicate combination of proofs, some coming from the veri.cation of the individual \nsources, others coming from the veri.cation of the compilers involved. In this situation, whole\u00adprogram \nsemantic preservation result such as those of CompCert do not directly apply, and .ner-grained approaches \nare needed: possi\u00adbly proof-preserving compilation [3, 14] combined with separation logics. Floating-point \nwoes It makes me nervous to .y an airplane since I know they are designed using .oating-point arithmetic. \nA. Householder, the author of this famous quote, should be even more nervous because modern airplanes \n.y using .oating-point arithmetic. Floating-point is, today, the biggest source of in.delities between \nthe semantics used for veri.cation and the code that actu\u00adally runs, owing to fundamental aspects of \n.oating-point arithmetic (limited precision, limited range) that are further aggravated by sloppy language \nspeci.cations (C leaves unspeci.ed the precision of intermediate .oating-point results) and dubious compiler \nopti\u00admizations (reassociation during vectorization, for instance). Good static analyzers manage to conservatively \napproximate most of these .oating-point artefacts, at signi.cant cost. Program logics and deductive program \nprovers still have some way to go in this direction: just specifying simple numerical routines in a .oating\u00adpoint \naccurate manner is already a challenge [7]. Conclusions The formal veri.cation of development and ver\u00adi.cation \ntools for critical software appears worthwhile: .rst, to strengthen the con.dence we can have in the \nresults of veri.ca\u00adtion tools, and therefore to make a stronger case for their adoption; second, because \nit raises scienti.cally-challenging issues, shedding new light on well-researched areas and exposing \nnew problems at their frontiers. The POPL community has, obviously, much to con\u00adtribute to this endeavor: \nfeel free to join! References [1] A. J. Ahmed. Step-indexed syntactic logical relations for recursive \nand quanti.ed types. In Programming Languages and Systems, 15th European Symposium on Programming, ESOP \n2006, volume 3924 of Lecture Notes in Computer Science, pages 69 83. Springer, 2006. [2] A. W. Appel \nand S. Blazy. Separation logic for small-step Cminor. In Theorem Proving in Higher Order Logics, 20th \nInt. Conf. TPHOLs 2007, volume 4732 of Lecture Notes in Computer Science, pages 5 21. Springer, 2007. \n[3] G. Barthe, B. Gr\u00b4egoire, C. Kunz, and T. Rezk. Certi.cate translation for optimizing compilers. ACM \nTransactions on Programming Lan\u00adguages and Systems, 31(5), 2009. [4] N. Benton and C.-K. Hur. Biorthogonality, \nstep-indexing and compiler correctness. In International Conference on Functional Programming 2009, pages \n97 108. ACM Press, 2009. [5] F. Besson, D. Cachera, T. P. Jensen, and D. Pichardie. Certi.ed static analysis \nby abstract interpretation. In Foundations of Security Analysis and Design, volume 5705 of Lecture Notes \nin Computer Science, pages 223 257. Springer, 2009. [6] B. Blanchet, P. Cousot, R. Cousot, J. Feret, \nL. Mauborgne, A. Mine,\u00b4 D. Monniaux, and X. Rival. A static analyzer for large safety-critical software. \nIn Programming Language Design and Implementation 2003, pages 196 207. ACM Press, 2003. [7] S. Boldo, \nJ.-C. Filli Combining Coq and atre, and G. Melquiond. Gappa for certifying .oating-point programs. In \nIntelligent Computer Mathematics, Calculemus/MKM 2009, volume 5625 of Lecture Notes in Computer Science, \npages 59 74. Springer, 2009. [8] G. Klein, J. Andronick, K. Elphinstone, G. Heiser, D. Cock, P. Derrin, \nD. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and S. Winwood. seL4: formal \nveri.cation of an operating\u00adsystem kernel. Communications of the ACM, 53(6):107 115, 2010. [9] A. J. \nKornecki and J. Zalewski. The quali.cation of software devel\u00adopment tools from the DO-178B certi.cation \nperspective. CrossTalk, Apr. 2006. [10] X. Leroy. Formal veri.cation of a realistic compiler. Communications \nof the ACM, 52(7):107 115, 2009. [11] X. Leroy. A formally veri.ed compiler back-end. Journal of Auto\u00admated \nReasoning, 43(4):363 446, 2009. [12] G. C. Necula. Translation validation for an optimizing compiler. \nIn Programming Language Design and Implementation 2000, pages 83 95. ACM Press, 2000. [13] A. Pnueli, \nM. Siegel, and E. Singerman. Translation validation. In Tools and Algorithms for Construction and Analysis \nof Systems, TACAS 98, volume 1384 of Lecture Notes in Computer Science, pages 151 166. Springer, 1998. \n[14] Z. Shao, V. Trifonov, B. Saha, and N. Papaspyrou. A type system for certi.ed binaries. ACM Transactions \non Programming Languages and Systems, 27(1):1 45, 2005. [15] J. Souyris, V. Wiels, D. Delmas, and H. \nDelseny. Formal veri.cation of avionics software products. In FM 2009: Formal Methods, volume 5850 of \nLecture Notes in Computer Science, pages 532 546. Springer, 2009. [16] J.-B. Tristan and X. Leroy. Veri.ed \nvalidation of Lazy Code Motion. In Programming Language Design and Implementation 2009, pages 316 326. \nACM Press, 2009. [17] H. Tuch, G. Klein, and M. Norrish. Types, bytes, and separation logic. In 34th \nsymposium Principles of Programming Languages, pages 97 108. ACM Press, 2007. [18] J. Yang and C. Hawblitzel. \nSafe to the last instruction: automated ver\u00adi.cation of a type-safe operating system. In Programming \nLanguage Design and Implementation 2010, pages 99 110. ACM Press, 2010.  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>The formal verification of programs has progressed tremendously in the last decade. In this talk, I review some of the obstacles that [6, 8, 15, 18] remain to be lifted before source-level verification tools can be taken really seriously in the critical software industry. A direction I advocate is the systematic formal verification of the development tools that participate in the production and verification of critical software.</p>", "authors": [{"name": "Xavier Leroy", "author_profile_id": "81100078576", "affiliation": "INRIA Paris-Rocquencourt, Le Chesnay, France", "person_id": "P2509541", "email_address": "Xavier.Leroy@inria.fr", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926387", "year": "2011", "article_id": "1926387", "conference": "POPL", "title": "Verified squared: does critical software deserve verified tools?", "url": "http://dl.acm.org/citation.cfm?id=1926387"}