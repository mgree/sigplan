{"article_publication_date": "01-26-2011", "fulltext": "\n Modular Reasoning for Deterministic Parallelism Mike Dodds Suresh Jagannathan Matthew J. Parkinson \nUniversity of Cambridge, UK Purdue University, Indiana Microsoft Research Cambridge, UK md466@cl.cam.ac.uk \n(work done while on sabbatical at Cambridge) mattpark@microsoft.com suresh@cs.purdue.edu Abstract Weaving \na concurrency control protocol into a program is dif.\u00adcult and error-prone. One way to alleviate this \nburden is determin\u00adistic parallelism. In this well-studied approach to parallelisation, a sequential \nprogram is annotated with sections that can execute concurrently, with automatically injected control \nconstructs used to ensure observable behaviour consistent with the original program. This paper examines \nthe formal speci.cation and veri.cation of these constructs. Our high-level speci.cation de.nes the conditions \nnecessary for correct execution; these conditions re.ect program dependencies necessary to ensure deterministic \nbehaviour. We con\u00adnect the high-level speci.cation used by clients of the library with the low-level \nlibrary implementation, to prove that a client s re\u00adquirements for determinism are enforced. Signi.cantly, \nwe can rea\u00adson about program and library correctness without breaking ab\u00adstraction boundaries. To achieve \nthis, we use concurrent abstract predicates, based on separation logic, to encapsulate racy behaviour \nin the library s implementation. To allow generic speci.cations of libraries that can be instantiated \nby client programs, we extend the logic with higher\u00adorder parameters and quanti.cation. We show that \nour high-level speci.cation abstracts the details of deterministic parallelism by verifying two different \nlow-level implementations of the library. Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: \nProgram Veri.cation Correctness proofs; D.3.3 [Program\u00adming Languages]: Language Constructs and Features \nConcurrent programming structures General Terms Languages, Theory, Veri.cation Keywords Separation Logic, \nConcurrent Abstract Predicates, Concurrency, Futures 1. Introduction Writing safe and ef.cient concurrent \nprograms is challenging be\u00adcause it requires programmers not only to parcel useful units of work into \nthreads that can be executed in parallel, but also to weave suitable concurrency control to coordinate \nthe access of these threads to shared data. To enable effective reasoning about concurrent programs, \nhowever, it is essential to devise modular abstractions whose implementations can be hidden behind well- \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed de.ned interfaces, allowing clients \nto reason about correctness in terms of abstract, rather than concrete, behaviour. In this paper, we \nconsider the veri.cation of one such concur\u00adrency construct: barriers. In deterministic parallelization, \ncode re\u00adgions in a sequential program are executed concurrently. While the parallelized program is internally \nnondeterministic, control con\u00adstructs are used to ensure that it exhibits the same deterministic observable \nbehaviour as its sequential counterpart. Automatic par\u00adallelization of this kind has been well-studied \nfor loop-intensive nu\u00admerical computations. However, it is also possible to extract paral\u00adlelism from \nirregularly structured sequential programs, where pro\u00adgram dependencies are not readily apparent [4, \n22, 25]. One way to achieve deterministic parallelism is through compiler\u00adinjected barriers [19]. We \ncan think of these barriers as resource management operations that enforce the original sequential order \n(aka program dependencies). A resource could be any program variable, data structure, memory region, \nlock, etc. for which own\u00adership guarantees are essential in order to enforce deterministic se\u00admantics. \nWe assume barrier implementations are provided as part of a library. While the intuition behind using \nsuch barriers is quite simple, there are many possible implementations. Verifying that an imple\u00admentation \nadheres to this intuition is challenging for several rea\u00adsons. First, the patterns of signalling in a \nbarrier implementation are highly non-local. To access a resource, a barrier must wait until all logically \npreceding threads have indicated that it is safe to do so; these logically preceding threads represent \nsources in a dependency graph. This abstract view of resource-transfer does not .t with the structure \nof a highly concurrent implementation, making it dif.cult to avoid breaking abstraction boundaries. Furthermore, \ncompiler optimizations might strive to identify the earliest point in a thread s execution path from \nwhere a resource is no longer required. In some cases, this means threads can re\u00adlease resources without \never acquiring them, so that subsequent signalling of this resource by its ancestors to its descendants \ncan bypass it altogether. An ancestor of a thread is a computation that logically precedes it under sequential \nexecution, and a descendent is a computation that logically follows it. Implementations of bar\u00adriers \nmust allow a thread to renounce the acquisition of a resource in this way. Finally, barriers may have \nto treat reads and writes differently to ensure preservation of sequential behaviour. Although many reads \ncan be performed concurrently, they must be sequentialized with respect to writes. Moreover, reads must \nbe sequentialized with respect to other reads, if there is an intervening write in the sequential order. \n for pro.t or commercial advantage and that copies bear this notice and the full citation In this paper, \nwe show how to reason in a modular way about on the .rst page. To copy otherwise, to republish, to post \non servers or to redistribute implementations of such barriers. To do this, we use concurrent to lists, \nrequires prior speci.c permission and/or a fee. abstract predicates [6], a technique based on separation \nlogic that POPL 11, January 26 28, 2011, Austin, Texas, USA. enables abstract reasoning about concurrent \nmodules. Our logic cCopyright &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00  allows us to \nreason about both high-level behavioural properties and low-level implementation details. This approach \nallows .ne\u00adgrained reasoning about behaviour, meaning that each thread can be given access to exactly \nthe behaviour it needs to run according to the abstract speci.cation. This behavioural reasoning is local, \nmeaning even non-local descriptions of the shared state can be encapsulated and abstracted. By leveraging \nconcurrent abstract predicates in this way, we take a .rst step towards the formal speci.cation and veri.cation \nof a system for deterministic parallelism. While full veri.cation of compiler analyses, transformations, \nand library implementations is our ultimate goal, we focus here on just the veri.cation problem for libraries. \nWe present a high-level speci.cation for reasoning about barriers for deterministic parallelism, independent \nof their low-level implementation. We prove that two low-level implemen\u00adtations of these barriers implement \nour high-level speci.cation. In the presence of runtime thread creation and dynamic (heap\u00adallocated) \ndata, our speci.cation must also be both generic and dy\u00adnamic, in the sense that it must be able to construct \nsignals at run\u00adtime that protect arbitrary resources. To support the transfer of arbi\u00adtrary resources \nbetween threads, we have extended the concurrent abstract predicates approach to support higher-order \npredicate pa\u00adrameters, and higher-order quanti.cation. The controlled resources are represented by propositional \narguments to abstract predicates. We make the following contributions: 1. We develop a high-level abstract \nspeci.cation for reasoning about libraries that implement barriers used to enforce deter\u00administic parallelism. \nThis speci.cation can express complex be\u00adhaviours such as the dynamic construction of new barriers and \nout-of-order signalling between threads. 2. We provide proofs that two implementations of such barriers \nsatisfy our high-level speci.cation. The .rst implementation na\u00a8ively sequentializes signalling, while \nthe second aggregates information from logically earlier threads to avoid this bottle\u00adneck. 3. We extend \nprior work on concurrent abstract predicates to sup\u00adport higher-order parameters and quanti.cations, \nfollowing higher-order separation logic [3]. By allowing propositional parameters, we can de.ne predicates \nthat take invariants as ar\u00adguments, to enable abstract reasoning about resource transfer.  An extended \nversion of this paper containing full proofs is available as a technical report [9].  2. A Speci.cation \nfor Deterministic Parallelism In this section, we describe the behaviour of a library providing barriers \nfor enforcing deterministic parallelism. We de.ne a high\u00adlevel speci.cations for these barriers, which \nallow us to prove that programs parallelised using these barriers preserve sequential behaviour. We assume \nthat code sections believed to be amenable for par\u00adallelization have been identi.ed, and the program \nsplit accordingly into threads. We assume a total logical ordering on threads, such that executing the \nthreads serially in the logical order gives the same result as the original (unparallelised) program. \nBarriers are associated with resources (e.g., program variables, data structures, etc.) that are to be \nshared between concurrently\u00adexecuting program segments. There are two sorts of barriers. A grant barrier \nnoti.es logically later threads that the current thread will no longer use the resource. A wait barrier \nblocks until all logically prior threads have signalled that they will no longer use the resource (i.e., \nhave issued grants). We assume barriers have been appropriately injected by a compiler to ensure that \nall salient data dependencies in the original program are respected. Consider the following function \nf;here * corresponds to non\u00addeterministic choice, so sleep(*) waits for an arbitrary period of time: \nf(x,y,v) { if(x<10) { y:=y+v; x:=x+v; } else { sleep(*); } } Suppose now that we run two instances of \nf in sequence: x:=0; y:=0; f(x,y,5); f(x,y,11); When this program terminates, location x and y will both \nhold 16. Here, the second call to f may have to wait for the .rst call to .nish its arbitrarily long \nsleep, even though the .rst call will do nothing more once it wakes. We parallelise this function by \ncon\u00adstructing two new functions f1 and f2. We run both concurrently, but require that f1 passes control \nof x and y to f2 before sleeping, allowing f2 to continue executing. f1(x,y,v,i) { f2(x,y,v,i) { if(x<10) \n{ wait(i); y:=y+v; x:=x+v; if(x<10) { grant(i); y:=y+v; x:=x+v; } else { } else { grant(i); sleep(*); \nsleep(*); }} }} x:=0; y:=0; i:=newchan(); f1(x,y,5,i)||f2(x,y,11,i); The barriers in f1 and f2 ensure \nthat the two threads wait exactly until the resources they require can be safely modi.ed, without violating \nsequential program dependencies. The correct ordering is enforced by barriers that communicate through \na channel; in the example, newchan creates the channel i. Assuming the barriers are correctly implemented, \nthe resulting behaviour is equivalent to that of the original sequential program. 2.1 Verifying a Client \nProgram How can we verify that our parallelised program based on f1 and f2 has the same speci.cation \nas the original sequential program? Typically, one would incorporate signalling machinery as part of \na parallelization program analysis. Clients would then reason about program behaviour using the operational \nsemantics of the barrier implementation. Validating the correctness of parallelisation with respect to \nthe sequential program semantics would therefore re\u00adquire a detailed knowledge of the barrier implementation. \nAny changes to the implementation could entail reproving the correct\u00adness of the parallelisation analysis. \nIn contrast, we reason about program behaviour in terms of ab\u00adstract speci.cations for grant, wait and \nnewchan. Suchanap\u00adproach has the following advantages: (1) Implementors can mod\u00adify their underlying \nimplementation and be sure that relevant pro\u00adgram properties are preserved by the implementation, and \n(2) client proofs (in this case, proofs involving compiler correctness) can be completed without knowledge \nof the underlying implementation. We will reason about f1 and f2 using separation logic. We write the \nfollowing assertion to denote that x points to value v and y to value v',and that x and y are distinct: \nx.v *y.v'. To reason about the parallel composition of threads, we use the PAR rule of concurrent separation \nlogic [20]: {P1}C1 {Q1}{P2}C2 {Q2} PAR {P1 *P2}C1 IC2 {Q1 *Q2} Now, to reason about f1 and f2, we must \nbe able to encode the fact that f1 can give up access to x and y by calling grant(i), while f2 can retrieve \naccess to them by calling wait(i).To use the parallel rule, we must be able to give the two threads star-separated \npreconditions.  We encode these two facts by de.ning two predicates, fut and req, corresponding to the \nfuture resource, the resource that can be acquired from logically earlier threads, and the required resource, \nthe resource that must be supplied to logically later threads. We read these as follows: fut(i, P ) \nBy calling wait on i, the thread will acquire a resource satisfying the assertion P . req(i, P ) By \ncalling grant on i when holding a resource satisfying P , the thread will lose the resource P . These \npredicates are abstract; each instantiation of the library will de.ne them differently; the client program \nknows nothing about how they are actually de.ned. The client only depends on an ab\u00adstract speci.cation \nthat captures the intuitive meaning of the predi\u00adcates: {emp}i := newchan() {req(i, P ) *fut(i, P )} \n{fut(i, P )}wait(i) {P } {req(i, P ) *P }grant(i) {emp} (Note that this is a weaker version of our full \nspeci.cation, given in Fig. 2.) The speci.cation of newchan is noteworthy. This speci.ca\u00adtion is implicitly \nuniversally quanti.ed for all assertions P , mean\u00ading that we can construct a predicate for any assertion.1 \nNew fut and req predicates can be constructed at run-time using newchan, meaning we can construct an \narbitrarily large number of channels for use in the program. Given these two predicates, we can de.ne \nthe following speci\u00ad .cations for f1 and f2. 9 >v1 < 10 .x.v1 *y.v2> < = ! x.(v1+v) * > *req i, > : ; \ny.(v2 +v) ( ) v3 < 10 . fut(i, x.v3 *y.v4) f1(x, y, v, i) {emp} () x.(v3 +v) f2(x, y, v, i) *y.(v4 +v) \nThe speci.cation for f1 says that the thread must supply the req predicate with the resources x and y \nsuch that the value in x is less than 10. The speci.cation for f2 says that the thread can receive x \nand y with the value in x less than 10. Fig. 1 gives sketch-proofs for these two speci.cations. Given \nthis speci.cation, the proof for the main program goes through as follows: on x.*y. x:=0; y:=0; i:=newchan(); \nn o x.0 *y.0 *req(i, x.5 *y.5) *fut(i, x.5 *y.5) f1(x,y,5,i) || f2(x,y,11,i) // Parallel rule. no x.16 \n*y.16 This proof establishes that the post-condition for the parallelised version of the program is identical \nto the post-condition for the original sequential version. 1 In the full speci.cation, we impose an extra \nrequirement that P is stable, meaning invariant under concurrent interference, but this holds trivially \nfor ' unshared assertions such as x . v * y . v . ( ) v1 < 10 .x.v1 *y.v2 * req (i, x.(v1+v) *y.(v2 +v)) \nif(x<10) { y:=y+v; x:=x+v; ( ) x.(v1+v) *y.(v2 +v) * req (i, x.(v1+v) *y.(v2 +v)) grant(i); // Abstract \nspec. no emp } else ... // Contradiction as v1 < 10. no emp on v3 < 10 .fut (i, x.v3 *y.v4) if(x<10) \n{ wait(i); // Abstract spec. on v1 < 10 .x.v3 *y.v4 y:=y+v; x:=x+v; n o x.(v3+v) *y.(v4 +v) } else ... \n// Contradiction as v3 < 10. n o x.(v3+v) *y.(v4 +v) Figure 1. Proofs for f1 and f2.  2.2 Generalising \nto Many Threads Suppose we want to run many copies of the function f in sequence, for example over an \narray of values vs. We might have the follow\u00ading sequential program: for(j:=0; j<max; j++){ f(x,y,vs[j]); \n} To parallelise this program, we want each call to f to run in a separate thread. To do this, f must \nbe modi.ed to contain calls to both grant and wait. Intuitively, each call to f receives the resource \nfrom logically earlier threads (those invoked in earlier loop iterations) with wait, then releases it \nto logically later threads (those invoked in later loop iterations) using grant. To allow many threads \nto access the same resource in sequence, we can construct a chain of channels. A wait barrier called \non a channel waits for grant barriers on all preceding channels. We use the ordering in chains of channels \nto model the logical ordering between a sequence of parallelised threads. A chain initially consists \nof a singleton channel constructed us\u00ading newchan. We introduce an operation split that allows us to \ninsert a new channel into the chain. The speci.cation of split takes a req predicate for an existing \nchannel and creates a new fut and req predicate representing the new channel. The new channel is inserted \ninto the chain immediately before the existing channel. We extend the req predicate with an additional \nargument identi\u00adfying the preceding channel in the chain. The split operation s speci.cation is given \nin Fig. 2. There are two more potential sources of parallelism in f.First, in the original transformation \ninvolving f1 and f2, we did not distinguish between the resources x and y. However, we need to gain access \nto y only if we take the .rst branch of the conditional. Otherwise we can release y to logically future \nthreads. To realise this parallelism in the new version of f, we use two chains of channels: one for \nx, and one for y. Second, we can exploit the ability to renounce access to a resource without acquiring \nit .rst. In the simple speci.cation given  SPECS: {fut(i, P )} 9 >req(i, i ' ,P ) *> <= ! fut(i ' ,P \n' ) >P .> : ' -; *(P *P ) req(i, i ' ,P ) wait(i) {P } grant(i) {emp} 8 9 > <req(j, j ' ,P ) > = () \nj, j ' := split(i) *fut(j ' ,Q) *stable(Q) >> :; *req(j ' ,i ' ,Q) () fut(i, P ) {stable(P )}i := newchan() \n*req(i, nil,P ) AXIOMS: ! fut(i, P ) *(P -*(P1 *P2)) =.fut(i, P1) *fut(i, P2) *stable(P1) *stable(P2) \nFigure 2. Full abstract speci.cation for deterministic parallelism. above, we can only call grant if \nwe hold the required resource. However, this is often not necessary. For example, if we take the second \nbranch of the conditional in f, we do not need the resource y. It is safe to notify future threads that \ny is available, conditional on all logically prior threads releasing it, even though the thread itself \nnever acquired access to the resource. Renunciation can be a powerful technique for parallelisation. \nSuppose a thread is logically last in a chain of threads accessing a resource. Suppose the thread takes \nan execution path rendering it unnecessary to ever access the resource. Without renunciation, a call \nto grant will block until all earlier threads have .nished with the resource. With renunciation, the \nthread can pass the barrier and continue executing, irrespective of the status of logically earlier threads. \nTo support renunciation, we modify the speci.cation for grant (see Fig. 2). This new speci.cation allows \na thread to discharge a req using the preceding fut predicate. In other words, the thread gives up the \nability to ever acquire the resource, and instead for\u00adwards this capability to future threads. When the \nresource becomes available from logically prior threads, the next thread in the logical order will receive \nit. The assertion (P ' -*P ) is used to convert the state supplied by the future to the state required \nby the next thread.2 In Fig. 2, we also add an axiom to our speci.cation. This is a fact about the library \npredicates that clients of the library can make use of. The axiom allows resource splitting. This axiom \nasserts that when a thread can receive a resource P using identi.er i, access to that resource can be \nsplit between two threads, potentially before the resource is available. The assertion (P -*(P1*P2)) \nasserts that P can be split into P1 and P2. We now de.ne fp, top of Fig. 3, a version of f which is safe \nto run in parallel with many copies of itself. This function takes arguments ix and iy representing the \nnext points in the two channel sequences, and ixp and iyp representing the immediately prior points. \nWe verify fp against the following speci.cation: ( ) no req(ix, ixp, x.) *fut(ixp, x.) *fp(...) emp req(iy, \niyp, y.) *fut(iyp, y.) A proof of this speci.cation is given in Fig. 4. Note that we only assert basic \nmemory safety in this speci.cation. We could verify 2 A resource satis.es P ' -* P iff its combination \nwith any disjoint resource satisfying P ' produces a resource satisfying P . 1 2 3 4 5 6 7 8 9 10 11 \n12 13 14 15 16 17 18 fp(x,y,v,ix,iy,ixp,iyp) { wait(ixp); if (x<10) { wait(iyp); y:=y+v; grant(iy); x:=x+v; \ngrant(ix); } else { grant(ix); grant(iy); sleep(*); }} ixf:=newchan(); iyf:=newchan(); for(j:=0; j<max; \nj++){ v:=vs[j]; ixl:=ixn; (ixf,ixn):=split(ixf); iyl:=iyn; (iyf,iyn):=split(iyf); future( fp(x,y,v,ixn,iyn,ixl,iyl) \n); } wait(ixf); wait(iyf); Figure 3. Example parallelisation of f and a client. The future annotation \nmarks the call to fp as a source of deterministic paral\u00adlelism. ( ) req(ix, ixp,x.) *fut(ixp,x.) * req(iy, \niyp,y.) *fut(iyp,y.) fp(x,y,v,ix,iy,ixp,iyp) { wait(ixp); ( ) x.*req(ix, ixp,x.) * req(iy, iyp,y.) \n*fut(iyp,y.) if (x<10) { wait(iyp); ( ) x.*y.* req(ix, ixp,x.) *req(iy, iyp,y.) y:=y+v; grant(iy); \nn o x.*req(ix, ixp,x.) x:=x+v; grant(ix); } else { grant(ix); n o req(iy, iyp,y.) *fut(iyp,y.) grant(iy); \nno emp sleep(*); }} no emp Figure 4. Proof for parallelised program fp. more complex properties by giving \nthe fut and req predicates stronger invariants. Line 14 of the proof is noteworthy. There, the precondition \ndoes not assert that the thread has access to y.; rather, it asserts it can acquire access by calling \nwait. Instead of doing this, the thread renounces access to the resource, giving it up without ever having \nit.  8 9 g(x) { gp(x,r,rp,w,wp) { ' < pp= fut(rp, x -.) *fut(wp, x -.) .p+p ' =1 if(*) { if(*) { ----. \n12 12 1 pp'p + sleep(*); grant(r); : *req(r, rp, x - .) *req(w, wp, x ) read(x); sleep(*); ; 2 if(*) \n{ } wait(rp); 12 3 // Apply the future splitting axiom to rp. ----. 1212 12 else { read(x); write(x); \ngrant(w); 8 = ' p -. p p - .) *fut(rp, x - .) *fut(wp, x fut(rp, x ) < }} }else{ 4 pp'p + : wait(rp); \nwait(wp); ; - .) *req(w, wp, x *req(r, rp, x ) write(x); 5 grant(r); grant(r); grant(w); 8 6 p' 1212 \np '9 = - .) *fut(wp, x -p.) ----. }} fut(rp, x < p + : Figure 5. Example function g and its parallelisation. \n; ) *req(w, wp, x 7 sleep(*); wait(rp); 9 read(x); grant(w); 12 n o 12 ' p 'p - .*fut(wp, x -p.) *req(w, \nwp, x ----. p + The parallelised version of the main program is given at the bot\u00ad 8 ) x tom of Fig. \n3. We give the following sketch-proof for this example. Here the predicates req(ixf, ixn, true) and req(iyf, \niyn, true) no are dummy req predicates used to represent the logically latest el\u00adement of the sequential \norder. The predicate array stands for the array of values. no array(vs, max) ixf:=newchan(); iyf:=newchan(); \n() array(vs, max) *req(ixf, nil, true) *fut(ixf,x.) *req(iyf, nil, true) *fut(iyf,y.) for(j:=0; j<max; \nj++){ ixl:=ixn; (ixf,ixn):=split(ixf); 98 >array(vs, max) *req(ixf, ixn, true) *fut(ixn,x.)> <= *req(ixn, \nixl,x.) *fut(ixl,x.) >> :; *req(iyf, iyn, true) *fut(iyn,y.) iyl:=iyn; (iyf,iyn):=split(iyf); 89 > array(vs, \nmax) *req(ixf, ixn, true) *fut(ixn,x.)> > > >> <= *req(ixn, ixl,x.) *fut(ixl,x.) > *req(iyf, iyn, true) \n*fut(iyn,y.)> >> >> :; *req(iyn, iyl,y.) *fut(iyl,y.) future( fp(x,y,vs[j],ixn,iyn,ixl,iyl) ); 10 emp \n11 } else { ... } no 12 emp Figure 6. Proof for parallelised program gp. conditional, it can use the \nread channel to signal that later threads can read. In contrast, a thread that wishes to write must wait \nfor both the read and write channels. The parallelised program is given in Fig 5. In separation logic, \nread and write access are often controlled by fractional permissions [5]. Each thread can hold either \nfull permis\u00adsion, 1, on a location x, denoted x.v, or fractional permission p p .(0..1), denoted x -.v. \nFull permission gives the thread ex\u00adclusive permission to write, while fractional permission gives non\u00adexclusive \npermission to read. Fractional permissions compose by addition, as follows: p' p+p' p' x -.v *x -.v ..x \n---.v if p+p =1. We give the function gp the following speci.cation: 8 } 12no 'p 9 p p -.) * - .) *fut(rp,x \n> wait(ixf); wait(iyf); // GC dummy req predicates. >req(r, rp,x < > > = 12 pp' gp(..) {emp} ----.) \n*fut(wp,x -.)> + array(vs, max) *x.*y. >req(w, wp,x We have shown that our parallelised version of the \nprogram is memory-safe. With a little more effort, we could verify the be\u00adhaviour of the program. Crucially, \neven though this program fea\u00adtures many threads running at once, with complex communication between threads, \neach individual thread is able to reason locally, without dealing with other threads or the implementation \nof the barriers.  2.3 Relating Reads and Writes Further parallelism is available by re.ning read and \nwrite accesses to a resource. Consider the function g giveninFig.5.It is safe for parallel threads to \nread x at the same time. However, it is important that writes to x are sequentialised, and that groups \nof reads are sequentialised with respect to writes. If two groups of reading threads are separated by \na writing thread, the logically later group must wait for the writer to .nish before reading. To exploit \nthis, we split reading and writing into two channels. We use r and rp for reads, and w and wp for writes. \nw and r are the outgoing channels, while wp and rp are the incoming channel. As soon as the thread nondeterministically \ntakes the .rst branch of the > > :; .p+p ' =1 This speci.cation says that when a thread receives a fractional \npermission from the read channel, only half of it has to be sent on to future threads using the read \nchannel. The other half can be supplied on the write channel. This allows a thread to keep the ability \nto read, while notifying future threads that they also can read. Fig. 6 shows a sketch-proof for the \nprogram. We elide the writing branch of the conditional as it is straightforward. The most notable proof \nstep is line 3, where the speci.cation s resource\u00adsplitting axiom is used to divide up access to the \nfut predicate. Half is used to discharge the req predicate r, allowing logically later threads to read, \nwhile half is used to allow the current thread to read. In this way, many threads can simultaneously \nhave fractional access to the resource.  3. Verifying a Simple Implementation So far, we have given \nan abstract speci.cation for deterministic par\u00adallelism. The speci.cation was independent of the implementation \n grant(i) { wait(i) { if(i.prev!=nil) while(i.bit!=1) wait(i.prev); skip; (i.bit:=1);} } split(i) { \nnewchan() { n:=alloc(bit); i:=alloc(bit); n.prev:=i.prev; i.prev:=nil; n.bit:=0; i.bit:=0; i.prev:=n; \nreturn i; return (i,n); } } Figure 7. Implementation of signalling library. of the barrier. In this section, \nwe show how such a speci.cation can be justi.ed by giving a simple implementation of the wait and grant \nbarriers, and verifying our abstract speci.cation against this concrete implementation. The implementation \nis given in Fig. 7. This implementation sup\u00adports resource transfer using a sequence of nodes, each of \nwhich has a bit .eld and a prev .eld. Each fut / req pair is associated with a single node, and the order \nof the sequence represents the logical ordering. The implementation requires that bits are set in sequential \norder. In \u00a75 we consider a more sophisticated implementation that allows out-of-order signalling, and \nshow that it also implements our abstract speci.cation. The wait barrier simply waits for the immediately \npreceding bit to be set. As bits are set in order, with logically earlier threads setting their bits \nbefore logically later ones, this suf.ces to show that all the earlier bits in the order have been set. \nRecall from the previous section that our speci.cation permits threads to renounce the ability to access \na resource, meaning that grant can be called before wait within the same thread. To ensure that bits \nare set in sequential order, grant must wait for the previ\u00adous bit to be set before setting its own bit. \nThe implementation uses the prev .eld of the bit to call wait, and then sets its bit when it exits. Bits \nare set atomically by grant, denoted by (-). The constructor functions newchan and split are implemented \nby allocating a new bit; split inserts a bit into the order by redirecting the prev pointer of the existing \nbit to point to the newly allocated bit. This allows computations to dynamically instantiate sub-computations \nthat have internal deterministic parallelism. 3.1 Proof Approach To prove the correctness of our module \ns functions, we use concur\u00adrent abstract predicates [6]. We extend this work with higher-order quanti.cation, \nallowing us to prove speci.cations that abstract over the particular resource held by the predicate. \nConcurrent abstract predicates extend standard separation logic with two new kinds of construct allowing \nexplicit reasoning about sharing and interference. The .rst are named shared regions,de\u00adnoted by boxed \nassertions of the form r P I This asserts that the region r contains a resource satisfying P ,and nothing \nelse. This region is shared between the current thread and an arbitrary number of other threads. The \npermitted state changes over the region are controlled by the interference environment, I. The second \nare capabilities, resources controlling the updates that a thread can perform. In order to mutate the \ncontents of a shared region, a thread requires a capability in its local state, denoted: [ACTION]r p \nThis is a permission for the operation ACTION on the region r. The exact operation denoted by the name \nACTION is determined by the interference environment for region r. Suppose that ACTION denoted the ability \nto rewrite the value in a shared address x from 0 to 1. Then we would have the following interference \nenvironment: I(x) (ACTION : x.0 x.1) A capability [ACTION]r controls both whether the operation is p \npermitted to the local thread, and whether it can be performed by the environment. Following deny-guarantee \n[8], exactly what is allowed and denied is determined by the permission level, p. We write 1 if the thread \ncan exclusively perform the action, gz if the thread and the environment can perform the action, and \ndz if neither the thread nor the environment can perform the action. The value z .(0..1) is used to track \nthe amount of permission, allowing capabilities to be split and combined. Updates performed by a thread \nmust be permitted according to the capabilities held by the thread in local state. So-called abstract \nupdates, those that do not modify the underlying heap-state, can be performed at any time by a thread. \nWe write P == Q to denote that P can be abstractly updated to give Q. As assertions describe shared states \nthat can be updated by other threads, we need to be able to describe assertions that will remain true \nno matter what the environment does. We describe these as\u00adsertions as stable. Capabilities specify exactly \nwhat behaviours the environment can perform, giving .ne-grained control of stability. For example, the \nfollowing assertion is stable, because I speci.es that the only way region r can be mutated is by the \nACTION opera\u00adtions, and the exclusive capability to perform this operation is held by the thread in local \nstate: r x.0 *[ACTION]r 1 I(x) Our logic includes an assertion stable(P ) that holds if P is stable. \nAn abstract speci.cation for a module consists of abstract pred\u00adicates, function speci.cations and axioms. \nTo show that a concrete implementation of a module corresponds to a particular abstract speci.cation, \nwe must supply concrete de.nitions for the module s abstract predicates, and then show that the following \nthree proper\u00adties hold: (1) the module implementation satis.es the abstract spec\u00adi.cations, given the \nconcrete predicate de.nitions; (2) the predicate de.nitions are stable; and (3) the axioms hold, given \nthe concrete predicate de.nitions. For simplicity, we assume that resources are garbage collected, rather \nthan being explicitly deallocated. This means that we can safely remove star-conjuncts from assertions, \nand we often use this to clean up the post-conditions for operations.  3.2 Verifying the Implementation \nNext, we prove that the implementation satis.es the abstract speci\u00ad.cation. We give de.nitions to the \nfut and req predicates in Fig. 8. (In all our predicate de.nitions, we assume unbound variables are existentially \nquanti.ed.) The de.nition of req(i, i ' ,P ) captures three pieces of informa\u00adtion: First, that there \nexists a shared bit at address i. Second, that i ' is the immediate predecessor of i, and it can be read \nby the thread. Third, that the thread must supply the resource P before setting the bit at i. In this \nde.nition, we use two auxiliary predicates: pa and box. The predecessor access predicate pa(i) asserts \nthat i is either nil, or it is a shared bit that can be read. This ensures that the thread that holds \nreq is able to access the preceding bit. The predicate box(i, P, p) asserts that the thread can exchange \nthe resource P for  r i.bit.0 *box(i, P, 1) I(i) req(i, i ' ,P ) *i.prev.i ' *pa(i ' ) r pa(i) i = nil \n.i.bit. I(i) ' [PUT]r 1 * trieve the resource P . The second cases are used in resource split\u00adting; see \nbelow for details. The .rst obligation for showing that our module implements the abstract speci.cation \nis to use our program logic to prove the module functions speci.cations. Proofs for grant, wait and split \nare given in Fig. 9. The proof of newchan is almost identical to the proof of split, and hence omitted. \nThe proof of grant operates by .rst appealing to the speci.ca\u00ad ' tion of wait to recover the full resource \nfrom a possible fut pred\u00ad icate. We also use the speci.cation {pa(i)}wait(i){emp},which can be proved \ntrivially. It then exchanges the resource and the box predicate for permission to set the shared bit. \nFinally it sets the shared bit and forgets all the remaining resource. The proof of wait spins until \nthe bit .eld is 1, which excludes stable(P ) *[GET]r 1 ' * ' the case where the resource is not present. \nAs the resource can onlyberemovedbythe wait thread, this assertion is stable under interference. The \nthread uses the GET to recover the resource, and garbage-collects all the other resources. The proof \nof split (and newchan) allocates a new piece of memory, sets the pred and bit .elds to appropriate values, \nthen Figure 8. Collected predicate de.nitions. creates the fut and req predicates by wrapping the new \nmemory in a shared region. The second obligation we must discharge is to show that the the permission \ndp on SET for the bit i. Hence, in order to acquire predicates are stable. To do this, we check each \nof the predicate the full permission to set the shared bit, the thread must supply de.nitions to make \nsure that each shared region assertion is invari\u00adthe resource P to the predicate box(i, P, 1). That is, \nthe following ant under permitted interference. abstract update holds:  3.3 Resource Splitting Using \nBoxes rr d *[SET]r I(i) I(i) i.bit.0 *box(i, P, p) *P == i.bit.0 p Our speci.cation requires that we \ncan split fut predicates according to the axiom given in Fig. 2. Below, we prove that the abstract implication \nholds. For the mo-We use the box predicate to support this splitting in our concrete ment, we just note \nthat boxes are used to control the splitting of re\u00adimplementation. Intuitively, each box initially shares \nits shared sources according to the splitting axiom. Note that, the de.nition of region with a fut predicate. \nThen, if that fut predicate is split, the box is recursive, as it mentions the box predicate inside the \nshared box instead contains a pair of boxes representing the shared state region, and in the interference \non the shared region. The .xed point for the two new fut predicates. exists by .rst .nding a solution \nignoring the interference environ-The de.nition of a predicate box(i, P, p), Fig. 8, either allows ment, \nand then restricting the interference environment by the re\u00adthe thread to access the SET permission, \nor contains two boxes with sulting solution. Finally, we give a de.nition to fut(i, P ). This assertion \nmust capture one essential piece of information: that either the shared bit at i is zero, or the resource \nP is available for collection. In these de.nitions, names surrounded with square brackets are d capabilities. \nThe semantics of such capabilities are de.ned by the interference environments. We de.ne two environments. \nThe .rst, I(i) de.nes the interference over the shared bit i. This environment includes only a single \noperation, the ability to set the shared bit: I(i)(SET : i.bit.0 i.bit.1) The interference environment \nJ(i, P, p, r) de.nes the interference over the resource-holding regions. J(i, P, p, r) 8 10 [SET]rp P \n> > < resources P1 and P2 such that P -*P1 *P2. In the proofs of the module s operations, we relied on \nthe assumption that a predicate box(i, P, 1) and resource P can be exchanged for a permission to set \nthe shared bit i.bit. We now justify this assumption with a proof. Our de.nition of box is the least \n.xed point of the recursive de.nition. We reason inductively, hence it suf.ces to prove that the entailment \nholds when box is de.ned as false, and under the as\u00adsumption that the disjunction holds. The base case \nof the induction holds trivially as box(i, P, p) is false. In the .rst inductive case, we assume that \nthe left disjunct in the shared region holds. The proof is given in Fig 10 (a). In the second case, we \nassume that the property holds for box(i, P1,p1) and box(i, P2,p2). The proof is given in Fig. 10 (b). \nThe proof given in Fig. 10 (c) shows that the future-splitting axiom holds for the concrete predicate \nde.nitions. We only show the left case for the disjunction; the right case is easy. This proof uses the \nGET action while at the same time creating new regions ! d C B BPUT : box(i, P1,p1) *box(i, P2,p2) \n*C for the two new futures. This completes the proof that our simple BC > > emp , B: C implementation \ncorresponds to our high-level speci.cation. B P -*(P1 *P2) .p1 + p2 = p C BC BC 8   BC 4. Logic and \nSemantics B> P emp C > < BC ! In this section, we present the syntax and semantics of our logic. BC \n@GET : A box(i, P1,p1) *box(i, P2,p2) *It extends the previous work on concurrent abstract predicates \n[6] p P -*(P1 *P2) .p1 + p2 = p with higher-order parameters and quanti.cation following the work of \nBiering et al. on higher-order separation logic [3]. Intuitively the .rst case for PUT allows the thread \nto push the re-Our assertion logic is a typed higher-order separation logic source P into the shared \nstate, and retrieve a fractional permission extended with predicates that denote the ability to change \nthe state to SET the shared bit. The .rst case for GET allows the thread to re-and a connective for expressing \nsharing. The syntax of the assertion r r i.bit.0 *box(i, P, p) *P i.bit.0 *box(i, P, p) *P fut(i, P \n) *(P -*P1 *P2) * I(i) I(i) == (defs &#38; assumption) == (defs and case split) stable(P1) *stable(P2) \n ' r ' == (def) *i.bit.0 *[PUT]r 1 *P *' r ' I(i) r ' stable(P1) *stable(P2) *[GET]r 1 * ' i.bit.0 r \nI(i) *P *[PUT]r 1 i.bit.0 r I(i) *[SET]r dp  box(i, P1,p1) *box(i, P2,p2) * J(i,P,p,r) P -*(P1 *P2) \n.p1 +p2 = p J(i,P,p,r) == (action PUT) == (action PUT) i.bit.0 r I(i) *[PUT]r ' 1 * i.bit.0 r I(i) *P \n *[SET]r ' d ' r == (action GET, creation of two new regions) ' r ' *[PUT]r 1 *P * p i.bit.0 emp r I(i) \nJ(i,P,p,r) r box(i, P1,p1) *box(i, P2,p2) * *P -*(P1 *P2) .p1 +p2 = p J(i,P,p,r) P -*(P1 *P2) .p1 *p2 \n= p *box(i, P1,p1) *box(i, P2,p2) == (GC) J(i,P,p,r) ' r == (assumption and GC) *[GET]1 r *fut(i, P1) \n*fut(i, P2) *[SET]r r I(i) d i.bit.0 p == (GC) *[SET]r I(i) fut(i, P1) *fut(i, P2) (a) (b) (c) d i.bit.0 \np Figure 10. Proofs of abstract updates language is as follows: t ::= Int |Frac |Region |Asn |t .t P, \nQ, L, M, . ::= false |P .Q |.x : t. P |LM |.x:t. M | E |emp |P *Q |P -*Q r | L.M |stable(P ) |[.(M )]r \np | P I I ::= .(Mx): .My : Mt(P Q) |I, I p ::= 1 |dL |gL where r ranges over region names, . over token \nnames, and v over values. We lift expressions E from the programming language to the logic. Note that \nwe use P, Q, . when the term is of type Asn. Terms are typed in the obvious way, and we will implicitly \nassume all de.nitions are well-typed. Our propositions have three important aspects they describe: (1) \nthe contents of the state, (2) the capability to change state, and (3) a partitioning of these contents \nand capabilities between local and shared regions. For completeness, the full semantics of terms is given \nin Fig. 11. Below we will only describe the salient features of the semantics. A more thorough explanation \ncan be found in [6]. Model We model propositions with Worlds that have three com\u00adponents: a local component, \nLWorld, that speci.es the current local state and local capabilities; a shared component, SWorld, that \nspec\u00adi.es the current shared state and shared capabilities; and an interfer\u00adence environment, IEnv, that \nspeci.es the possible interference (or protocol) on the shared component of the world. The shared com\u00adponent \nis split into many named regions, each of which is modelled by an LWorld. A local world, LWorld, is modelled \nby a partial heap, Heap, specifying the locally accessible state, and a capability mapping, Capab, mapping \nfrom actions in Action to permission to perform that action in DG. Each action is mapped to either a \nfull permis\u00adsion 1, an exclusive permission to perform that action, that hence prohibits the environment \nfrom performing the action; a guarantee permission gz, a non-exclusive permission to perform that action; \na deny permission dz, a non-exclusive prohibition on the action that also prevents the environment performing \nit; and an empty permis\u00adsion 0 that does not allow the action but does not prohibit the envi\u00adronment \nfrom performing it. Following Boyland [5], the z compo\u00adnents of deny and guarantee are used to track \nhow much permission is required to re-establish exclusive permission. Members of Action comprise a Region,a \nToken and a sequence of Val arguments. An action s semantic meaning as interference over a shared region \nis de.ned by an interference environment, in the set IEnv. The de.nition of an interference environment \nas a re\u00adlation over SWorld enforces the restriction that the interpretation of an action does not allow \nyou to change the interference interpre\u00adtation of any actions. Model operations As we are building a \nseparation logic we re\u00adquire a composition operator on worlds that will be used to inter\u00adpret the separating \nconjunction and separating implication. We use the standard operation from separation logic for combining \nheaps, h .h ' , by disjoint partial function combination. We use the deny-guarantee composition model \n[8] for DG. This has 0 as the unit of .. It combines two guarantee (or deny) permissions by combining \ntheir fractional components to produce a guarantee (or deny) permission with the sum of the fractions. \nIf the fractions sum to 1 then it lifts to 1. If the fractions sum to more than 1, then combination is \nunde.ned. This is then lifted to the function space in the obvious way. We de.ne the composition of LWorld \nas the combination on both components; and on World as the combination on the LWorld component, where \nthe SWorld and IEnv components are equal. We de.ne other useful operations on the model that aid in the \nde.nition of the semantics: LsJcollapses all the shared regions into a single one; lH gives the heap \ncomponent of l; lP gives the permission component of l;and .w. collapses a world into a single heap. \nFinally, we de.ne the set of well-formed worlds, WFW.A world is well-formed iff all the regions and the \nlocal component can be combined, each capability is de.ned in the interference environment, and the capabilities \nonly mention valid regions. Types The types are semantically interpreted as in Figure 11. We use i for \ninterpretations of the free variables in a term: it is a dependent product from a variable to the denotation \nof the type of that variable. We interpret propositions on the powerset of worlds. Terms The interpretation \nof false, ., ., *, -*, variables, function application, and function abstraction . are standard. The \npredicate emp speci.es that the local component of the heap is empty and makes no restriction on the \nshared part, the  no req(i,i ' ,P ) *(P .(fut(i ' ,P ' ) *P ' -*P )) grant(i) { if(i.prev!=nil) { on \nreq(i,i ' ,P ) *(P .(fut(i ' ,P ' ) *P ' -*P )) wait(i.prev); // wait() spec, or by pa. on req(i,i ' \n,P ) *P } // Unfold definition. n r o i.bit.0 *i.prev.i ' *pa(i ' ) *box(i,P, 1) *P I(i) // Push resource \ninto the box. n r o i.bit.0 *i.prev.i ' *pa(i ' ) *[SET]1 r I(i) (i.bit:=1); // Action SET. n r o i.bit.1 \n*i.prev.i ' *pa(i ' ) *[SET]1 r I(i) } // Garbage collect. no emp no fut(i,P ) wait(i){ 8 ' 9 > stable(P \n) *[GET]r *> < 1 ' = r >> ;: J(i,P,p,r) while(i.bit!=1){ skip; } .j' r stable(P ) *[GET]r 1 ' * J(i,P,p,r) \n// Abstract action GET. j' . r P *stable(P ) *[GET]r 1 ' * J(i,P,p,r) } // Garbage collect. no P on \nreq(i,i ' ,P ) *stable(Q) split(i) { n:=alloc(bit); n.prev:=i.prev; n.bit:=0; i.prev:=n; (r ) i.bit.0 \n*box(i,P, 1) *i.prev.n *pa(i ' ) I(i) *stable(Q) *n.prev.i ' *n.bit.0 // Construct region for new predicates. \n9 >> 8 < i.bit.0 r *box(i,P, 1) *i.prev.n *pa(i ' ) *= I(i) ' >> : stable(Q) *n.prev.i ' *[SET]1 r ' \n*n.bit.0 r ; I(n) // construct a new box for the future. 89 > i.bit.0 r *box(i,P, 1) *i.prev.n *pa(i \n' ) > > > > I(i) > >> > ' > < r '' = *n.prev.i ' *n.bit.0 *stable(Q) *[GET]r 1 I(n) '' > > r > > > > \n> '' > > > : *[PUT]1 r * ; ' J(n,Q,1,r ) return (i,n); } // Fold definitions. () .i1,i2. ret = (i1,i2) \n.req(i1,i2,P ) *fut(i2,Q) *req(i2,i ' ,Q) Figure 9. Proofs for grant, wait and split. interference environment, \nor the capability. The points-to predicate L.M speci.es that the location L contains the value M in the \nlocal world, and that the heap contains nothing else. The capability [.(MM)]r that says the local world \ncontains the p M p permission on region r for action . with parameters M .The as\u00adsertion stable(P ) says \nthat P will remain true given the permitted interference on the shared world. That is, if we start in \na world sat\u00adisfying P and take a step in R, then we must still satisfy P .The shared assertion P r says \nthat the shared region r satis.es the I assertion P and that region s interference is speci.ed by I. \nInterference We de.ne several relations giving the possible up\u00addates to the shared world as a result \nof the thread and the environ\u00adment. Following Jones [16], we call the interference permitted to the environment \nthe rely and the interference permitted to the local thread the guarantee. We de.ne the semantics of \nthe interference spec.cation as a relation of SWorlds. For a particular update PQ, we specify that a \npart of the pre-state must satisfy P , and replacing that part with a part satisfying Q gives the post-state. \nWe also allow the action to increase the number of regions in an unspeci.ed way. This will allow actions \nboth to repartition and to create new shared regions simultaneously. We allow the dynamic creation of \nregions. The relations Rc and Gc model this creation. The .rst, Rc, speci.es the world-change if the \nenvironment creates a region. The environment can only create a region if it does not already exist. \nIt adds a new shared region, and the relevant de.nition to the interference environment. The second, \nGc, speci.es the world-change if the current thread created a region. This differs from the rely as all \nof the permissions on actions for the new region are given to the current thread. The global rely relation, \nR, allows any action in the inference environment that is not explicitly prohibited with a deny permission \nor a full permission, as well as the creation of regions. We restrict R to well-formed worlds. The global \nguarantee, G, allows any action for which there is either a full permission or a guarantee permission. \nThe guarantee requires that the permissions and heap domain must be the same before and after the action, \nupto repartioning between regions. This ensures that permissions and heap cannot be created out of thin \nair. We also allow region creation, and restrict G to well-formed worlds. Program logic We give the proof \nrules for our program logic in Figure 12. The judgements are of the form .; G f{P }C {Q}where . is an \nassumption about the logical context, and G is an assumption about the procedures in the context of the \nform {P1}f1{Q1},..., {Pn}fn{Qn}. We use . to encode the assumptions about the abstract predicates and \ntheir axioms . We assume a standard semantics of programs [6] where (C, h) .(C ' ,h ' ) denotes a successful \nreduction in the procedure con\u00adtext . (a mapping from procedure names to commands); and . (C, h) .fault \ndenotes a memory access problem. We then de.ne the semantics of judgments as follows: DEFINITION 1 (Con.guration \nsafety). C, w, ., i, Q safe0 always holds; and C, w, ., i, Q safen+1 iff the following four conditions \nhold: 1. .w ' . if (w, w ' ) .R * then C, w ' , .,i,Q safen; . 2. \u00ac((C, w ) .fault); . '' ' 3. .C ,h \n' . if (C, w ) .(C ,h ' ),then .w ' such that (w, w ) . ' '' G * , h ' = w and C ,w ,.,i,Q safe n; and \n' '' 4. if C=skip,then .w such that w = w H , (w, w ) .G * , and w ' .[Qti.  Model p .DG {1, 0}l{tz \n|z .(0, 1) .t .{d, g}}a .Action Region \u00d7Token \u00d7Val * . .Capab Action .DG h .Heap Address .Val l{.}l .LWorld \nHeap \u00d7Capab s .SWorld Region -LWorld I.IEnv Action -P(SWorld \u00d7SWorld) w .World LWorld \u00d7SWorld \u00d7IEnv \nModel operations ..vv ..v (t, z) .(t, z ' ) 1 if z + z ' =1 h1 .h2 .v. h1(v) .h2(v) if .v. h1(v)= ..h2(v)= \n.p .00 .pp (t, z) .(t, z ' )(t, z + z ' ) if z + z ' < 1 .1 ..2 .v. .1(v) ..2(v) if .v. .1(v) ..2(v) \nde.ned (h1,.1) .(h2,.2)(h1 .h2,.1 ..2) if h1 .h2 and .1 ..2 are de.ned (h, .)H h LsJ.r.dom(s)s(r) (l1,s1, \nI1) .(l2,s2, I2)(l1 .l2,s1, I1) if l1 .l1 de.ned .s1 = s2 .I1 = I2 (h, .)P . (l, s, I)(l .LsJ)H WFW {(l, \ns, I) |(l .LsJ) de.ned .dom((l .LsJ)P ) .dom(I) .(.r. r .dom(s) ...,Mv. (r, ., Mv) .dom(I))} Types [Intt \nZ [Regiont Region [t1 .t2t[t1t .[t2t[Asnt P(World) Terms [falseti \u00d8[xti i(x) [P .Qti {w |w/.[P ti .w \n.[Qti}[LMti [Lti([Mti) [P *Qti {w .w ' |w .[P ti .w ' .[Qti} S '' [.x : t. P tiv.[t] . [P ti[x/.v] [.x \n: t. Mti .v. [Mti[x/.v] [P -*Qti {w |.w .[P ti.w .w .[Qti} [empti {((\u00d8,.),s, I)}[L.Mti {(([[Lti .[Mti],.),s, \nI)}[.(MM)]r {((\u00d8,.),s, I) |.(r, ., [MMti) =p} pi  r [stable(P )t{w |.w1 .[P ti. (w1,w2) .R .w2 .[P \nti}P {((\u00d8,.),s, I) |(s(r),s, I) .[P ti .I(r)= [Iti,r} i Interference [.(Mx): .My : M t (P Q)ti,r(r, . \n' ,M v) 8 > < s1, s2 > : [I, I ' ti,r [Iti,r .[I ' ti,r ' Rc {(l, s, I), (l, s ' , I.I' ) |r/.dom(s) \n.s Ii 9 .vM' .[Mtt, I,l0,l1,l2. (l1,s1, I) .[P t.(l2,s2, I) .[Qt> i[/x/./v,/y/.v/' ] i[/x/./v,/y/.v/' \n]= .. = . ' .s1(r)= l1 *l0 .s2(r)= l2 *l0 > ..r ' .dom(s1).r ' ' )= s2(r ' ) ;= r .s1(r = s[r.l ' ] \n.rdom(I' )= {r}} ' ''' Gc {(l, s, I), (l ' ,s , I.I' ) |r/.dom(s) .s = s[r.l1] .l .all(I)= l1 .l ' .rdom(I)= \n{r}} L where all(I' ) (\u00d8, [r, ., Mv.1]) and rdom(I)= {r |(r, , ) .dom(I)} (r,.,/v).dom(I ' ) n o '' \n'' R (l, s, I), (l, s ' , I.I) .a. (s, s .{1, dz}.dom(s ) \\dom(s)= rdom(I) .Rc nP(WFW2 ) .I(a) .(LsJ.l)P \n(a) / ) )! ( ' '' (l, s, I), .a. (s, s P )(a) .{1, (g, )}.dom(s ) \\dom(s)= rdom(I ) .I(a) .(l ' ) G \nnP(WFW2) '' '' (l ' ,s , I.I) .(LsJ.l)P .all(I)=(Ls J.l ' )P .dom((LsJ.l)H )= dom((Ls ' J.l ' )H ).Gc \n Ancillary de.nitions {p}{q} P ==Q .w .[P ti. .h .[pti. .h2 .[qti. .h ' w2.h .h ' = w .h2 .h ' = w2 \n.(w, w2) .G .w2 .[Qt i [.t {i |[.t= [Asnt} . |=. ' [.t .[. ' t i ={p}{q} Q {p}{q}{emp}{emp} . |= P =.i \n.[.t .P ==Q . |= P == Q .i .[.t .P ==Q i i Figure 11. Semantics of assertions fSL {p}C {q}.; G f{P1}C1 \n{Q1}.; G f{P2}C2 {Q2}a/.G,P,Q .; G f{P }C{Q} (PRIM) (PAR) (EXISTS) .; G f{p}C {q}.; G f{P1 *P2}C1 IC2 \n{Q1 *Q2} (.a..); G f{P }C{Q} {p}{q} {P }f {Q}.G fSL {p}C {q}. |= P ==Q .; G f{P }C {Q}. |= stable(R) \n(CALL) (ATOMIC) (FRAME) .; G f{P }f {Q}.; G f{P }(C ){Q} .; G f{P *R}C {Q *R} .; G f{P1}C1 {Q1}... .; \nG f{Pn}Cn {Qn} . ' ;G f{P ' }C {Q ' }. |=. ' .; {P1}f1 {Q1},..., {Pn}fn {Qn}, G f{P }C {Q} . |= P == \nP ' . |= Q ' == Q (LET) (CONSEQ) .; G f{P }let f1 = C1 ...fn = Cn in C {Q} .; G f{P }C {Q} Figure 12. \nSelected proof rules from [6]. All rules assume that the pre-and post-conditions of their judgements \nare stable. DEFINITION 2 (Judgement Semantics). .; G |= {P }C {Q}holds iff .n..i .[.t ... .[Gtn,i . \n|=.,i,n+1 {P }C{Q}, where [Gtn,i {. |.{P }f{Q}.G. |=.,i,n {P }.(f){Q}}and |=.,i,n {P }C{Q}.w .([P tinWFW). \nC,w,.,i, Q safe . n Differences from the CAP paper [6]. The original paper treated the meaning of interference \nsyntactically in the model, that is, the equivalent of IEnv was a map from action to syntactic de.nition \nof the actions. This was done to avoid a cyclic de.nition in World.In this paper, we have factored out \nthe semantics of interference to be a separate component. We thus impose the restriction that the inter\u00adference \nenvironment cannot update the interference environment. Note, this kind of update was not allowed before, \nbut was not ex\u00adplicitly forbidden in the model, just in the interpretation. This small refactoring of \nthe semantics allows higher-order quanti.cation. We extend the model from the original CAP paper to addition\u00adally \ncontain deny permissions [8]. This is a straightforward exten\u00adsion to the original paper. Finally, we \ntake an intuitionistic model for the permissions. This enables permissions to leak. The library we are \nconsidering in this paper requires garbage collection to collect signals when they are no longer accessible. \n  5. Verifying a More Complex Implementation The module implementation given in \u00a73 imposes a strong \nsequen\u00adtial order on calls to grant.A wait only checks its immediate predecessor, so a call to grant \nmust ensure its predecessor is set before setting its own bit. In this section, we consider an alternative \nimplementation that allows out-of-order bit setting. We prove that this implementation also implements \nour abstract speci.cation. The new implementation uses the same data-structure as the simple implementation. \nBits can be set by calls to grant in arbi\u00adtrary order, but as a consequence, each call to wait must examine \nall prior bits before exiting. As this implementation uses the same data-structure as the .rst one, the \nsplit and newchan operations are identical. The grant and wait operations are de.ned as fol\u00ad lows: grant(i) \n(i.bit } { :=1); wait(i) while whili := }} { (i!=nil) e(i.bit=0){ i.prev; { skip; } As with the .rst \nimplementation, each address has a bit .eld and a prev .eld. Calling grant sets the bit .eld for the \ncurrent address from 0 to 1, then exits immediately. When wait is called, it blocks until every bit .eld \nearlier in the order is set. To do this, it chases prev .elds, waiting for each bit .eld to go to 1 before \naccessing the preceding location. In this way, wait ensures that all previous threads have called grant. \nThe predicate de.nitions (given in Fig. 13) are similar to those for the simple implementation. The main \ndifference is in the de.\u00adnition of the fut predicate. When the shared bit is set, the resource that is \navailable to the thread may include a preceding fut predi\u00adcate. So, if the current thread expects resource \nP , it may instead get a resource satisfying (P ' -*P ) *fut(i ' ,P ' ),where i ' is the immediately \npreceding location in the logical order. The thread can then recover P ' by checking the bit for i ' \n,which may include a fut predicate for the preceding location i '' .Only when the thread has checked \nall the bits earlier in the order can it be con.dent it holds the full resource. In this way, our predicate \nde.nitions re.ect the fact that the thread does not know exactly which threads have supplied a resource, \nand which have simply renounced access to it. ' [GET]r 1 * ' r fut(i, P ) J(i,P,p,r) i.bit.0 r *i.prev.i \n' * I(i) req(i, i ' ,P ) pa(i ' ) *box(i, P, 1) r i.bit.0 . pa(i) i = nil . i.bit.1 *i.prev.i ' *pa(i \n' ) I(i) ' r ' box(i, P, p) *[PUT]r 1 J(i,P,p,r) Figure 13. Predicate de.nitions for out-of-order bit \nsetting. ' - 1 n o fut(i,P ) 2 wait(i) { 3 while n (i!=nil) { ' ' o 4 i = nil .(pa(i) *P ..P. fut(i,P \n) *(P *P )) 5 while(i.bit=0) skip; ( r ) i.bit.*i.prev.i ' *pa(i ' ) * 6 (P ..P ' . fut(i ' ,P ' ) *(P \n' -*P )) 7 i := i.prev; 8 } no 9 i = nil .((pa(i) *P ) .(.P ' . fut(i,P ' ) *(P ' -*P ))) 10 } // fut(i, \n) is false if i = nil, so... no 11 P Figure 14. Proof for wait. The req predicate is de.ned similarly \nto the .rst proof, with a recursive box predicate controlling access to bit-setting. The interference \nenvironment for the shared bit, I(i),is: SET(i ' ): i.bit.0 i.bit.1 *i.prev.i ' *pa(i ' ) The environment \nJ(i, P, p, r) for resource-holding regions is: 8 PUT : > > < > > : [SET(i ' )]r dp P .(fut(i ' ,P ' ) \n*P ' -*P ) box(i, P1,p1) *box(i, P2,p2) *P -*(P1 *P2) .p1+p2 = p ! emp 8 > > < P emp ! GET : box(i, \nP1,p1) *box(i, P2,p2) * > i ' >(.* . [SET(i ' )]r dp) : P -*(P1 *P2) .p1+p2 = p (Here the symbol .* \nis the iterated version of *.)  A proof for wait is given in Fig. 14. The most interesting step is line \n5, where the resource is recovered from the shared region. We justify this step by the following proof. \nThe other case, where a pa rather than fut is present, is trivial. on fut(i,P ' ) *(P ' -*P ) // Unfold \ndefinitions. 8 ' 9 >(P ' -*P ) *[GET]1 r * > > > > ' > > r > > > > > < = > > > > > > > > > > > > : ; \n' J(i,P ,p,r) while(i.bit = 0) { skip; } 8 ' 9 > ' -> >(P *P ) *[GET]1 r * > > > < r ' = > > > > > > \n: ; ' J(i,P ,p,r) // Pull into local state and GC GET. ( r ) i.bit.*i.prev.i ' *pa(i ' ) * I(i) '' '' \n) *(P '' (P ' ..P. fut(i ' ,P -*P ' )) *(P ' -*P ) // Transitivity of -*. ( r ) i.bit.*i.prev.i ' *pa(i \n' ) * I(i) '' '''' - (P ..P. fut(i ' ,P ) *(P *P )) The proof for grant, newchan and split are similar \nto the proofs for the single-bit case. Once again, the proof of grant depends on the fact that fut can \nbe split according to the resource held by it.   6. Related Work and Conclusions Most work on combining \nseparation logic with concurrency con\u00adstructs has considered them as primitive in the logic. This begins \nwith O Hearn s work on concurrent separation logic [20], which takes statically allocated locks as a \nprimitive. CSL has been ex\u00adtended to deal with dynamically-allocated locks [11, 14, 15] and re-entrant \nlocks [12]. Others have extended separation logic or sim\u00adilar logics with primitive channels [13, 1, \n24, 18], and event driven programs [17]. Concurrent abstract predicates [6] combine the explicit treat\u00adment \nof concurrent interference from rely-guarantee [16, 10, 23] and abstraction through abstract predicates \n[21], with a concurrent .ction of disjointness [7] supported by capabilities [8]. In this paper we have \ncombined concurrent abstract predicates with higher-order separation logic [3]. We used our higher-order \nlogic to de.ne and verify a speci.cation for barriers that enforce complex data and control dependencies \nin concurrent programs. Although we have focussed in this paper on barrier constructs used for deterministic \nparallelism [25, 2, 4, 19], our logic is in\u00adtended as a general approach to specifying concurrency constructs. \nOur syntactic approach has the advantage that concurrency con\u00adstructs of different kinds combine transparently. \nFor example, lock predicates de.ned in [6] can be transferred through our channel predicates without \nchanging the semantics or proofs of correctness for either module. In addition, we can verify that concrete \nimple\u00admentations of constructs satisfy their speci.cation. Acknowledgements Thanks to the anonymous referees, \nRichard Bornat, Matko Botin.can, Thomas Dinsdale-Young, Philippa Gard\u00adner, Neel Krishnaswami, Daiva Naud.zi\u00afunien.e, \nViktor Vafeiadis and John Wickerson.  References [1] C.J.Bell, A.Appel,and D.Walker. Concurrent separation \nlogic for pipelined parallelization. In SAS, 2009. [2] E. D. Berger, T. Yang, T. Liu, and G. Novark. \nGrace: Safe multithreaded programming for C/C++. In OOPSLA, 2010. [3] B. Biering, L. Birkedal, and N. \nTorp-Smith. BI-hyperdoctrines, higher-order separation logic, and abstraction. TOPLAS, 29(5), 2007. [4] \nR. L. Bocchino, Jr., V. S. Adve, D. Dig, S. V. Adve, S. Heumann, R. Komuravelli, J. Overbey, P. Simmons, \nH. Sung, and M. Vakilian. A type and effect system for deterministic parallel Java. In OOPSLA 09, pages \n97 116. ACM, 2009. [5] J. Boyland. Checking interference with fractional permissions. In SAS, 2003. [6] \nT. Dinsdale-Young, M. Dodds, P. Gardner, M. J. Parkinson, and V. Vafeiadis. Concurrent abstract predicates. \nIn ECOOP, 2010. [7] T. Dinsdale-Young, P. Gardner, and M. Wheelhouse. Abstraction and re.nement for local \nreasoning. In VSTTE, 2010. [8] M. Dodds, X. Feng, M. J. Parkinson, and V. Vafeiadis. Deny\u00adguarantee reasoning. \nIn ESOP, 2009. [9] M. Dodds, S. Jagannathan, and M. J. Parkinson. Modular reasoning for deterministic \nparallelism. Computer laboratory technical report, University of Cambridge, 2010. [10] X. Feng, R. Ferreira, \nand Z. Shao. On the relationship between concurrent separation logic and assume-guarantee reasoning. \nIn ESOP, 2007. [11] A. Gotsman, J. Berdine, B. Cook, N. Rinetzky, and M. Sagiv. Local reasoning for storable \nlocks and threads. In APLAS, 2007. [12] C. Haack, M. Huisman, and C. Hurlin. Reasoning about Java s Reentrant \nLocks. In APLAS, pages 171 187, 2008. [13] C. A. R. Hoare and P. W. O Hearn. Separation logic semantics \nfor communicating processes. ENTCS, 212:3 25, 2008. [14] A. Hobor, A. W. Appel, and F. Zappa Nardelli. \nOracle semantics for concurrent separation logic. In ESOP, 2008. [15] B. Jacobs and F. Piessens. Modular \nfull functional speci.cation and veri.cation of lock-free data structures. Technical Report CW 551, Katholieke \nUniversiteit Leuven, Dept. of Computer Science, 2009. [16] C. B. Jones. Tentative steps toward a development \nmethod for interfering programs. TOPLAS, 5(4):596 619, 1983. [17] N. R. Krishnaswami, L. Birkedal, and \nJ. Aldrich. Verifying event\u00addriven programs using rami.ed frame properties. In TLDI, 2010. [18] K. R. \nM. Leino, P. M\u00a8uller, and J. Smans. Deadlock-free channels and locks. In ESOP, 2010. [19] A. Navabi, \nX. Zhang, and S. Jagannathan. Quasi-static Scheduling for Safe Futures. In PPoPP, pages 23 32. ACM, 2008. \n[20] P. W. O Hearn. Resources, concurrency and local reasoning. TCS, 2007. [21] M. J. Parkinson and G. \nM. Bierman. Separation logic and abstraction. In POPL, pages 247 258, 2005. [22] M. C. Rinard and M. \nS. Lam. Semantic Foundations of Jade. In POPL, pages 105 118. ACM, 1992. [23] V. Vafeiadis. Modular Fine-Grained \nConcurrency Veri.cation.PhD thesis, University of Cambridge, July 2007. \u00b4 heap-hop. In TACAS, pages 275 \n279, 2010. [24] J. Villard, E. Lozes, and C. Calcagno. Tracking heaps that hop with [25] A. Welc, S. \nJagannathan, and A. Hosking. Safe Futures for Java. In OOPSLA, pages 439 435, 2005.  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>Weaving a concurrency control protocol into a program is difficult and error-prone. One way to alleviate this burden is <i>deterministic parallelism</i>. In this well-studied approach to parallelisation, a sequential program is annotated with sections that can execute concurrently, with automatically injected control constructs used to ensure observable behaviour consistent with the original program.</p> <p>This paper examines the formal specification and verification of these constructs. Our high-level specification defines the conditions necessary for correct execution; these conditions reflect program dependencies necessary to ensure deterministic behaviour. We connect the high-level specification used by clients of the library with the low-level library implementation, to prove that a client's requirements for determinism are enforced. Significantly, we can reason about program and library correctness without breaking abstraction boundaries.</p> <p>To achieve this, we use <i>concurrent abstract predicates</i>, based on separation logic, to encapsulate racy behaviour in the library's implementation. To allow generic specifications of libraries that can be instantiated by client programs, we extend the logic with higher-order parameters and quantification. We show that our high-level specification abstracts the details of deterministic parallelism by verifying two different low-level implementations of the library.</p>", "authors": [{"name": "Mike Dodds", "author_profile_id": "81418593776", "affiliation": "University of Cambridge, Cambridge, United Kingdom", "person_id": "P2509612", "email_address": "md466@cl.cam.ac.uk", "orcid_id": ""}, {"name": "Suresh Jagannathan", "author_profile_id": "81100208907", "affiliation": "Purdue University, West Lafayette, IN, USA", "person_id": "P2509613", "email_address": "suresh@cs.purdue.edu", "orcid_id": ""}, {"name": "Matthew J. Parkinson", "author_profile_id": "81406598777", "affiliation": "Microsoft Research Cambridge, Cambridge, United Kingdom", "person_id": "P2509614", "email_address": "mattpark@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926416", "year": "2011", "article_id": "1926416", "conference": "POPL", "title": "Modular reasoning for deterministic parallelism", "url": "http://dl.acm.org/citation.cfm?id=1926416"}