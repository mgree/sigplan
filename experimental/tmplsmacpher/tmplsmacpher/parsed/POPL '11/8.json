{"article_publication_date": "01-26-2011", "fulltext": "\n Static Analysis of Interrupt-driven Programs Synchronized via the Priority Ceiling Protocol Martin \nD. Schwarz Helmut Seidl Vesal Vojdani Technische Universit\u00a8at M\u00a8unchen Boltzmannstra\u00dfe 3, D-85748 Garching, \nGermany {schwmart, seidl,vojdanig}@in.tum.de Abstract We consider programs for embedded real-time systems \nwhich use priority-driven preemptive scheduling with task priorities adjusted dynamically according to \nthe immediate ceiling priority protocol. For these programs, we provide static analyses for detecting \ndata races between tasks running at different priorities as well as meth\u00adods to guarantee transactional \nexecution of procedures. Beyond that, we demonstrate how general techniques for value analyses can be \nadapted to this setting by developing a precise analysis of af.ne equalities. Categories and Subject \nDescriptors F.3.1 [Logics and mean\u00ading of programs]: Specifying and Verifying and Reasoning about Programs; \nF.3.2 [Logics and meaning of programs]: Semantics of Programming Languages Program analysis; D.2.4 [Software \nEngineering]: Software/Program Veri.cation General Terms Algorithms, Theory, Veri.cation Keywords inter-procedural \nanalysis, abstract domains, interrupt\u00addriven concurrency 1. Introduction There is an inherent tension \nin concurrent real-time software be\u00adtween synchronization, needed to preserve data consistency, and prioritized \nexecution, needed to meet hard deadlines. Retaining ex\u00adecution of high-priority tasks within a predictable \ntime frame, yet allowing lower-priority tasks to complete critical sections, requires sophisticated synchronization \nprimitives which limit the worst\u00adcase waiting time of high-priority tasks. Using common binary semaphores \n(mutexes) can result in a higher-priority task waiting an inde.nite amount of time for a lower-priority \ntask to complete, a situation known as unbounded priority inversion. As an example of unbounded priority \ninversion, consider a low\u00adpriority task q1 which acquires a lock needed by a high-priority task q3.When \nq3 is ready to execute, it will preempt q1, but as soon as q3 attempts to acquire the lock, it must wait \nfor q1 to complete its critical section. It is perfectly acceptable, and necessary for the Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. POPL 11 January \n26 28, 2011, Austin, Texas, USA. Copyright c &#38;#169; 2011 ACM 978-1-4503-0490-0/11/01. . . $10.00 \nPeter Lammich Markus M\u00a8uller-Olm Westf\u00a8alische Wilhelms-Universit\u00a8at M\u00a8unster Einsteinstra\u00dfe 62, D-48149 \nM\u00a8unster, Germany {peter.lammich,markus.mueller-olm}@ uni-muenster.de sake of data consistency, that \na high-priority task wait for a low\u00adpriority task to complete execution of a critical section; however, \nthe problem is that an intermediate-priority task q2 may preempt the low-priority task before it releases \nthe lock. Then, q2 is indirectly blocking the high-priority task q3 for an arbitrary amount of time. \nSince unbounded priority inversion defeats the possibility of meeting hard deadlines, operating systems \nfor embedded systems provide more sophisticated synchronization primitives than com\u00admon mutexes. Typically \nsuch primitives are based on priority in\u00adheritance: a lower-priority task which blocks a higher-priority \ntask inherits the priority of that higher-priority task for the duration of the critical section which \ncaused the blocking. This bounds the time a higher-priority task can be blocked. The original ceiling \npriority protocol [27] ensures that a higher-priority task can only be blocked for the duration of a \nsingle critical section. In safety-critical systems, a simpli.cation of this protocol, the immediate \nceiling priority protocol, is often used. This variation is also known as the priority ceiling emulation \nprotocol to distinguish it from the original inheritance-based ceiling protocol. Under this name, it \nis included in Safety Critical Java [13], a proposed subset of Real-Time Java. The immediate ceiling \npriority protocol is used by the OSEK/VDX operating system [22], which has been adopted by the automotive \nsoftware architecture Autosar [3], an emerging global standard in the automotive domain. It is also present \nin the POSIX library, where it is called the Priority Protect Protocol. In this paper, we will follow \nthe OSEK usage and simply call it the priority ceiling protocol (PCP). The PCP relies on the concept \nof resources. Each resource r obtains a ceiling priority, which is the maximal priority of tasks acquiring \nthe resource r.The scheduling of tasks then follows the dynamic priority of tasks, i.e., the maximum \nof a task s static priority and the ceiling priorities of all resources it has acquired. In this way, \na task acquiring a given resource will immediately inherit the priority of all tasks which could request \nthat resource. As this blocks intermediate-priority tasks, unbounded priority inversion is avoided. In \nthis paper, we develop static analyses for programs synchro\u00adnized via the PCP. We provide methods for \nuncovering subtle .aws due to the concurrency induced by interrupts. Speci.cally, we focus on data races \nand transactional behavior of procedures. Moreover, we explain how interprocedural value analyses can \nbe enhanced to take priorities and interrupts into account. We exemplify this with an algorithm for inferring \naf.ne equalities. The PCP was en\u00adgineered to run on uniprocessor systems, which are the de facto standard \nfor embedded real-time systems. The program in Figure 1 is used as a running example through\u00adout the \npaper. It consists of one (main) task T and two interrupts I and I' with priorities 1, 2 and 3, respectively \n(higher numbers de\u00adnote higher priorities). The program uses resources r and r'.Since   get(r) rel(r) \nz=20 3   get(r)  rel(r) y++ x-\u00ad 2     get(r) rel(r) y=0 x=10  \u00b7\u00b7\u00b7 1   get(r) rel(r) t=x+y \nx=t-x \u00b7\u00b7\u00b7 \u00b7\u00b7\u00b7  get(r)  rel(r) y=t-y z=t*2 \u00b7\u00b7\u00b7   Figure 1. Example program. r is used by T and I, \nits ceiling priority is 2, while r ' is used by T and I ' , so its ceiling priority is 3. The interrupt \nI ' of highest priority resets the variable z to the .xed value 20. The interrupt I increments the counter \ny and decrements the counter x. The main task T initializes the counters x and y; then, it attempts to \nswap their values by means of an auxiliary variable t, which receives the sum of x and y. Before completing \nthe swap, the result 2 * t is stored in the variable z. This example is designed to exhibit both a data \nrace and a nontransactional behavior. The resource r ' is held during the initialization of the main \ntask; consequently, the dynamic priority of this part is 3 (the maximal priority), ensuring that no interrupts \nmay occur. Then, the resource r with ceiling priority 2 is acquired, which will only protect against \nthe interrupt I, while I ' may still occur. Note that the interrupt I is unaware of the resource r ' \n, and yet acquiring resource r ' , protects a task from being interrupted by I because the static priority \nof I is less than the ceiling priority of r ' . This effect is typical for priority based synchronization. \nAn analysis which treats resources as locks, though, could not exclude the possibility of I interrupting \nthe initialization code, resulting in false alarms. The assignment z = t * 2 may overwrite the assignment \nin I ' if I ' occurs at T8 (or earlier). Or it might itself be overwritten if I ' occurs at T9 (or later). \nThis constitutes a data race. Moreover, at T10, variable y is overwritten with a value that might have \nbecome outdated due to an occurrence of I. In the example, this will result in failing to correctly swap \nthe variables x and y.Note that this occurs although all accesses to x and y are protected by the resource \nr. We call this nontransactional behavior. The paper is organized as follows. In Section 2, we present \na con\u00adcrete semantics of PCP programs based on execution paths. We formally de.ne the concepts of nontransactional \nbehavior and data races for interrupt-driven programs. In Section 3, we show how to analyze resource \nsets to determine priorities and consequently pos\u00adsible interleavings. In Section 4, we use the resource \nframework to detect races, and in Section 5, nontransactional behavior. Sec\u00adtion 6, shows how to extend \nthe framework to allow data-.ow anal\u00adysis and we exemplify this by computing af.ne equations for the \nexample program. Section 7 presents the experimental evaluation of our methods for race detection and \ntransactionality. Finally, we discuss related work and conclude.  2. The Core PCP Model and its Semantics \nOur model consists of one task main, with which program execu\u00adtion starts; a .nite collection of interrupt \nroutines Irpt, which we also call tasks, i.e., Task = Irpt .{main}; and auxiliary proce\u00addures Proc, which \nmay be called by all tasks. The main task as well as the interrupt routines are distinguished procedures \nwhich may not be called otherwise. For the sake of the analysis, procedures are speci.ed by means of \ncontrol-.ow graphs as in Figure 1. Every procedure f has a designated entry node fe and return node fr. \nThe collection of all control .ow graphs of procedures in Proc is denoted by (N, E) where N is the set \nof nodes and E the set of edges. Let Ne and Nr denote the set of all entry and return nodes, respectively. \nEach edge is labeled either with a basic statement s, or with a call f(),f . Proc. For simplicity, we \nconsider procedures without parameters only. Each basic statement s is either a basic command cmd, such \nas an assignment to a global variable, or a PCP statement, such as resource acquisition. Let Res denote \nthe .nite set of resources used by the program. For r . Res, the PCP statement get(r) acquires the resource \nr and rel(r) releases r. We assume that at the exit node of each task, all resources have been released. \nThis can be enforced, e.g., by successively releasing all resources potentially used by the task. Additionally, \nwe assume that we are given functions P : 2Res Task . N and U : Task . which map tasks to their static \npriorities from N and (super-)sets of the sets of resources possibly acquired during their execution. \nIn particular, we assume that P(main)=0 < P(q) for each q . Irpt. To each resource r . Res,wethenassignits \nceiling priority P(r) which equals the maximal priority of a task acquiring r, i.e., P(r)=max{P(q) | \nr .U(q)} For a subset of resources R . Res, we also write P(R) as a shorthand for max{P(r) | r . R} where \nP(\u00d8)= -8. 2.1 Execution Paths An execution path p of a PCP program is a sequence of control\u00ad.ow edges \nlabeled by basic statements into which subsequences corresponding to procedure calls or interrupts are \nnested. The nest\u00ading of a call to the procedure f is indicated by means of the start and end tags Uf \n) and U/f), respectively. Interrupts are indicated analogously. Same-level execution paths reaching a \nprogram point v (on the same level) are de.ned as follows: E is an same-level execution path reaching \nthe entry nodes qe of procedures;  p(u, cmd,v) is a same-level execution path reaching v if p is a same-level \nexecution path reaching u;  p1Uf)p2U/f) is a same-level execution path reaching v if p1 is a same-level \nexecution path reaching u, (u, f(),v) is a call edge, and p2 is a same-level execution path reaching \nthe return node fr of f ;  p1Uq)p2U/q) is a same-level execution path reaching v if p1 is a same-level \nexecution path reaching v,and p2 is a same-level execution path reaching the return node qr of an interrupt \nq.  Likewise, a (reaching) execution path reaching a program point v (not necessarily at the same level) \nis de.ned as follows. E is an execution path reaching the entry point maine of the main task;  p\u00af(u, \ncmd,v) is an execution path reaching v if p\u00afis an execu\u00adtion path reaching u;  p\u00af1Uf)p2U/f) is an execution \npaths reaching v if p\u00af1 is a exe\u00adcution path reaching u, (u, f (),v) is a call edge and p2 is an execution \npath reaching the return node fr of f;  p\u00af1Uq)p2U/q) is an execution path reaching v if p\u00af1 is an exe\u00adcution \npath reaching v,and p2 is a same-level execution path reaching the return node qr of an interrupt q; \n p\u00afUq) is an execution path reaching the entry node qe of q if p\u00afis an execution path reaching u and \neither there is a call edge (u, q(),v) or q is an interrupt.   We write .S and .R for the set of same-level \nexecution paths and reaching execution paths, respectively. For same-level execution paths, we de.ne \nthe resource set after the path in terms of the resource set R before the path: R(E, R)= R R(p(u, cmd,v),R)= \nR(p, R) R(p(u, get(r),v),R)= R(p, R) .{r} R(p(u, rel(r),v),R)= R(p, R) \\{r} R(p1Uq)p2U/q),R)= R(p1,R) \nif q . Task R(p1Uf)p2U/f),R)= R(p2, R(p1,R)) if f . Task This de.nition is extended to (reaching) execution \npaths: R(\u00afpUf)p, R)= R(p, R(\u00afp, R)) if f . Task R(\u00afpUq)p, R)= R(p, \u00d8) if q . Task where p is a same-level \nexecution path and p\u00afis a reaching execu\u00adtion path.  2.2 The Path Semantics The concrete semantics collects, \nfor each program point v,the set of execution paths reaching v taking static priorities and resource \nsets into account. Each task starts with an empty set of resources. We assume that procedures cannot \nbe interrupted at their entry points. If a task is interrupted (while executing some procedure), its \nresource set before and after the interrupt is identical, while procedure calls may change the set of \ncurrently held resources. Let p denote the maximal static priority of all tasks, and [p] the interval \n{0,...,p}. For a procedure f,let [f ] :[p] . (2Res . 2.S ) denote the function which assigns to each \nstatic priority i at which f can be called, a function which takes a resource set R before a call to \nf and returns the set of same-level execution paths of the procedure f including all execution paths \nof interrupts which possibly may have occurred. Likewise for j> 0,let [j] . .S denote the set of execution \npaths of all interrupts with static priority level j. For an edge e labeled with a basic statement, the \nconcrete semantics is a function [e] :2Res . 2.S which for each resource set R returns the singleton \nset [e](R)= {e}. In order to put up a constraint system to characterize the sets of same-level execution \npaths of procedures, we require composition operators which take resource sets and static priorities \ninto account. The composition of mappings M1,M2 :2Res . 2.S must ensure that the sets of execution paths \nare concatenated according the attained sets of resources: (M2 . M1) R = {p1p2 | p1 . M1(R),p2 . M2(R(p1,R))} \nFor interrupts, we need to .lter out execution paths which cannot be interrupted due to high dynamic \npriorities. Let Sj denote the set of execution paths of interrupts of priority j.Thenwede.ne the application \nof Sj with a mapping M :2Res . 2.S : (Sj j M) R = {p1p2 | p1 . M(R),p2 . Sj ,j > P(R(p1,R))} where the \npriority condition checks that the acquired resources allow the interrupt to occur. The functions [f] \n:[p] . 2Res . 2.S ,f . Proc, and the sets [j] then can be characterized as the least solution of the \nfollowing constraint system: [S0] S[fe,i] . I [S1] S[v, i] . [(u, s, v)] . S[u, i](u, s, v) . E [S2] \nS[v, i] . ([f] i) . S[u, i](u, f(),v) . E [f] i .Hf (S[fr,i]) [S3] [j] . ([q] j \u00d8) q . Irpt, P(q)= j \nS[u, i] . [j] j S[u, i] u/. Ne, j>i Here, the function I is given by I(R)= {E}. The auxiliary variable \nS[v, i] for a node v of some procedure f, and a static priority i describes the function which for a \ngiven resource set R at procedure start, returns the set of all same-level execution paths reaching v \nwithin f when executed within a task of static priority i.The auxiliary operator Hf takes a description \nM of the same-level execution paths of the procedure f and wraps it into the opening and closing tags \ncorresponding to f,i.e, Hf (M )(R)= {Uf)pU/f)| p . M(R)} For real-time systems, it is reasonable to assume \nthat every proce\u00addure has at least one same-level execution path, i.e., that [f ] iR is non-empty for \nevery i and R. If this is the case, the set of all pro\u00adgram points which are de.nitely unreachable can \nbe computed by standard means and then removed from the control-.ow graphs implying that property (S) \nis satis.ed: (S) Each program point v of a procedure f is same-level reachable, i.e., S[v, i](R) = \u00d8 \nfor every i and R. This property therefore will henceforth be generally assumed. In order to put up a \nconstraint system to characterize the sets of reaching execution paths, we require an operator to apply \nthe :2Res 2.S effects M . of edges or procedures to sets of reaching execution paths S, which takes attained \nsets of resources into account. We de.ne M@S = {p\u00af1p2 | p\u00af1 . S, p2 . M (R(\u00afp1, \u00d8))} Likewise, the application \nof a set of same-level execution paths S2 of interrupts of priority j to a set S1 of reaching execution \npaths is de.ned by: S2 @j S1 = {p\u00af1p2 | p\u00af1 . S1,p2 . S2, P(R(\u00afp1, \u00d8)) <j} The collecting semantics of \nsets of reaching execution paths then is given by the least solution of the following constraint system: \n[R0] R[maine, 0] .{E} [R1] R[v, i] . [(u, s, v)]@R[u, i](u, s, v) . E [R2] R[v, i] . ([f] i)@R[u, i](u, \nf (),v) . E R[fe,i] . enterf (R[u, i]) (u, f(),v) . E [R3] R[u, i] . [j]@j R[u, i] u/. Ne, j>i R[j] . \nprojj (R[u, i]) u/. Ne, j>i R[qe, P(q)] . enterq(R[j]) q . Irpt, P(q)= j Here, the operator enterf for \na procedure f . Task when applied to a set S of reaching execution paths, appends the opening tag Uf)to \neach reaching execution path in S, i.e., enterf (S)= {p\u00afUf)| p\u00af. S} The operator projj when applied to \na set S, extracts the set of all reaching execution paths p\u00affrom S where the priority of the resource \nset R(\u00afp, \u00d8) is less than j,i.e, projj (S)= {p\u00af| p\u00af. S, P(R(\u00afp, \u00d8)) <j} The constraints S0, R0 provide \nvalues for entry points of all proce\u00addures in Proc, and the entry node of procedure main, respectively. \nS1 and R1 take care of all non-call edges, by applying the seman\u00adtics of the edge, i.e., appending the \nedge to the collected sets of paths. Procedure calls are handled by the constraints S2 and R2. In S2 \nas well as the .rst part of R2, the same-level executions of the called procedure are composed with the \nexecutions before the call. Additionally, the second part of R2 describes execution paths entering procedures. \nThe constraints S3 and R3 deal with inter\u00adrupts. They correspond to implicitly introducing extra loop \nedges with interrupt calls at every node where an interrupt may occur, given that the dynamic priority \nof the executing task is suf.ciently low. Interrupts are summarized by static priority levels. Similarly \nthe entry sets of the reaching execution paths are summarized into one set for each static priority level. \nAccording to our assumption, entry nodes are excluded from constraints S3 and R3.  2.3 Data Races and \nNontransactional Behavior Let Acc(cmd) and Acc(f ) denote the set of all variables accessed by the basic \ncommand cmd and same-level executions of procedure f, respectively. For clarity of presentation, we do \nnot distinguish read and write accesses. Then a data race at some global variable x occurs if program \nexecution reaches an access to x at a dynamic priority j while x also might be accessed by some interrupt \nq of static priority exceeding j. De.nition 1. A PCP program contains a data race at variable x if there \nexists a reaching execution path p\u00af(u, cmd,v) Uq) pU/q). R[v, i] for a basic command cmd with x . Acc(cmd) \nand a same-level execution path p of the interrupt q with x . Acc(q). In the example program of Figure \n1, a data race occurs at the variable z. The interrupt I ' has static priority 3 and accesses z while \nthe main task T accesses z at a dynamic priority of 1 and can therefore be preempted by I ' at T8 or \nT9. A possi\u00adble run of the example program reaching the data race would be: (Te, get(r ' ),T1) ... (T3, \nrel(r ' ),T4) ... (T8, z = t * 2,T9) '' ''' '''' UI )(Ie, get(r ),I1)(I1, z = 20,I2)(I2, rel(r ),Ir)U/I \n' ).There are no further data races in the example program since the variables x and y are only used \nby the interrupt I which has a static priority of 2 and all accesses to these variables occur at a dynamic \npriority of at least 2. A procedure f is considered as transactional (or atomic) if during every execution \nof f, no interrupt may occur between the .rst and last access to global variables which accesses any \nof the globals accessed by f . De.nition 2. Formally, f is nontransactional at static priority j for \na resource set R, if there exists a same-level execution path Uf) p1 Uq) p U/q) p2U/f ). [f](j)(R) where \nthe following holds: p1p2 . S[fr,j](R) is a same-level execution path which contains no interrupts; \n p is a same-level execution path of the interrupt q without further interrupts;  p1 and p2 contain \nedges (u1, cmd1,v1),(u2, cmd2,v2) with Acc(cmd1)= \u00d8 = Acc(cmd2);and  p contains an edge (u, cmd,v) with \nAcc(cmd) n Acc(f)= \u00d8.  To exemplify this situation we use again the program of Figure 1. The .rst access \nof the main task T to a global occurs before program point T2 while the last access is after T10. In \nbetween, e.g., at program point T8, the dynamic priority is 1. At this node, T can be preempted by the \ninterrupt I which changes the variables x and y also used by T . Therefore T is not transactional. A \npossible run of the example program exhibiting this behavior would be: UT ) (Te, get(r ' ),T1) ... (T7, \nrel(r),T8) UI) (Ie, get(r),I1) ... (I3, rel(r),Ir) U/I) (T8, z = t * 2,T9) ... (T11, rel(r),Tr) U/T ). \n 3. Analyzing Resources In this section, we present an analysis of sets of resources possibly held at \na given program point. The results of this analysis are fun\u00addamental for determining the minimal dynamic \npriority guaranteed to hold at this program point, as well as all subsequent analyses of the program. \nThe analysis determines for each program point a set of possible resource sets. The complete lattice \nthus is given by 22Res .Setsof sets are ordered by subset inclusion. At join points we therefore take \nthe union of reaching sets. For analyzing same-level executions, we associate to each pro\u00ad :2Res cedure \nf an abstract semantics [f]. 22Res . Unlike the collecting semantics, [f] does not depend on the static \npriority in which a call to f is made. The static priority determines the inter\u00adrupts which may occur \nduring the call of f, but interrupts do not modify the sets of currently held resources. In order to \nset up the corresponding abstract constraint system, we de.ne an abstract se\u00ad . 22Res mantics from 2Res \nfor edges (u, s, v) labeled with basic statements. We de.ne: [(u, cmd,v)](R)= {R} [(u, get(r),v)](R)= \n{R .{r}} [(u, rel(r),v)](R)= {R \\{r}} Additionally, we require an abstract composition operator . :2Res \n22Res which, for abstract mappings M1,M2 . , returns the function de.ned by the following equation: \n (M2 . M1)(R)= {M2(R ' ) | R ' . M1(R)} As with the concrete semantics we compute the effect of procedures \ndepending on resource sets they are called with. The functions :2Res . 22Res [f],f . Proc, then are given \nby the least solution of the following constraint system: [S 0] S[fe] ; I f . Proc  [S 1] S[v] ; [(u, \ns, v)]. S[u] (u, s, v) . E [S 2] S[v] ; [f]. S[u] (u, f(),v) . E [S 3] [f]; S[fr] where the function \nI is given by I (R)= {R}. No constraints have been included to deal with interrupts: the reason is that \ninter\u00adrupts do not change sets of held resources. For determining the sets of reaching resource sets, \nwe require an abstract application operator @ which applies a mapping M : 2Res . 22Res to a set of resource \nsets S . 22Res as follows:  M @S = {M(R) | R . S} For approximating the sets of resource sets reaching \na node v at static priority level i, we consider the following constraint system: [R 0] R[qe,j] . {\u00d8} \nq .Task,j =P(q) [R 1] R[v, j] . [(u, s, v)]@ R[u, j] (u, s, v) . E  [R 2] R[v, j] . [f]@ R[u, j] (u, \nf(),v) . E R[fe,i] . R[u, i] (u, f(),v) . E Note that the constraints R 0 not only provides an abstract \nstart value for the entry node of main, but also for the entry nodes of all interrupts q . Irpt. This \nis because every interrupt may occur, for example at the exit node of main, and will always start with \nthe empty resource set. Note further that for reachability, we have kept the information i about the \nstatic priority at which a node is reached, in order to be able to determine its possible dynamic priorities. \nIn order to relate the concrete and abstract semantics of pro\u00adgrams, we introduce appropriate abstraction \nfunctions a :(2Res . 2.S ) . (2Res . 22Res ) and a\u00af:2.R . 22Res . These are given by a(M )(R)= {R(p, \nR) | p . M(R)}a\u00af(X)= {R(\u00afp, \u00d8) | p\u00af. X}  The following theorem states that the resource sets computed \nby the above constraint systems not only safely over-approximate the set of resources attained by the \ncollecting semantics, but the com\u00adputations are precise w.r.t. the concrete semantics. Theorem 1. 1. \nLet [f] j, S[v, j] and [f] , S[v] denote the least solutions of the constraint systems S and S , respectively. \nThen for every procedure f, static priority i, and program point v, a([f] j)= [f] a(S[v, j]) = S[v] 2. \nLet R[v, j] and R[v, j] denote the least solutions of the con\u00adstraint systems R and R , respectively. \nThen for every program point v and possible static priority j, a\u00af(R[v, j]) = R[v, j] Proof. For the proof, \nwe observe that for every edge e =(u, s, v), a([e])= [e] Also for composition of functions M1,M2 :2Res \n. 2.S ,wehave: a(M2 . M1)= a(M2) . a(M1) Since furthermore, the abstract functions [e] , as well as the \nop\u00aderation . are completely distributive, i.e., commute with arbitrary least upper bounds, the .rst assertion \nof the theorem follows by .x\u00adpoint induction. A similar argument applies to the second statement of the \ntheorem. Let n denote the sum of the number of program points and control .ow edges, and o the number \nof resources used by the program. Recall that p is the number of static priority levels. Then the number \nof constraints in the systems S and R are bounded by O(p \u00b7 n). . 22Res Since the height of the lattice \n2Res is exponential in the number of resources, the least solution of these systems can be computed by \na standard work-list algorithm in time O(p \u00b7 n \u00b7 2co) for some constant c. Typically, the number of resources \nused by embedded con\u00adtrollers are quite small. A practical implementation still may tab\u00adulate functions \n[f] only for those (i, R) of static task priorities i and resource sets R for which the procedure f may \nbe called at run\u00adtime. Also, elements in 22Res can be naturally modeled by Boolean functions which in \nturn can be ef.ciently operated on, if these are represented through ordered binary decision diagrams. \nThe example program in Figure 1 does not use any procedures, which means we have to look at the constraint \nR 0 and R 1 only. Furthermore, each node is only reached with the static priority of its task. Therefore \nwe directly obtain the following results: '' '' Node [I, 3] [I1, 3] [I2, 3] [I, 3] er Result {\u00d8} {{r \n' }} {{r ' }} {\u00d8} Node [Ie, 2] [I1, 2] [I2, 2] [I3, 2] [Ir, 2] Result {\u00d8} {{r}} {{r}} {{r}} {\u00d8} Node \n[Te, 1] [T1, 1] [T2, 1] [T3, 1] [T4, 1] '' Result {\u00d8} {{r }} {{r ' }} {{r }} {\u00d8} Node [T5, 1] [T6, 1] \n[T7, 1] [T8, 1] [T9, 1] Result {{r}} {{r}} {{r}} {\u00d8} {\u00d8} Node [T10, 1] [T11, 1] [Tr, 1] Result {{r}} \n{{r}} {\u00d8} 3.1 Flow-independent Must-resource Analysis One interesting class of PCP programs consists \nof all programs where the set of held resources at a program point v does only depend on the set of resources \nheld at the entry point of a procedure f but not on the concrete execution path reaching v. More precisely, \nwe demand that for every procedure f and set of resources R, the set S[v, j](R) is a singleton set {R \n' }. These programs are said to have .ow-independent resource sets. Such programs can be analyzed more \nef.ciently, while still being precise w.r.t our model. The analysis presented above can be further abstracted \nto com\u00adpute not all possible resource sets, but the set of de.nitely held resource. The domain is then \nsimpli.ed to 2Res ordered by superset inclusion (.) and intersection as the least upper bound. Since \nevery program point is reachable by some same-level execution path, no dedicated bottom element is required \nto denote unreachability. We :(2Res . 22Res ) . (2Res . consider the abstraction functions am 2Res:22Res \n) and a\u00afm . 2Res given by: am(M)(R)= M(R) a\u00afm(S)= S where \u00d8 is de.ned as Res. The resulting analysis \nis called must :2Res . 2Res resource analysis. The abstract functions [e]m for edges e =(u, s, v) corresponding \nto this analysis are given by: [(u, cmd,v)]m(R)= R [(u, get(r),v)](R)= R .{r} m [(u, rel(r),v)]m(R)= \nR \\{r} Note that these now are functions of the general format g(R)= R \\ K . G for suitable constant \nsets K, G.Let F denote the set of all these functions. This lattice is well known for gen-kill bit-vector \nanalyses [12]. Since also the abstract composition of functions as used by the constraint system S , \nfor must resource analysis be\u00adcomes ordinary composition of functions, must resource analysis for PCP \nprograms can be performed by means of an interprocedural gen-kill approach. Similarly the abstract function \napplication, be\u00adcomes ordinary function application. Let Sm denote the constraint system over the complete \nlattice F corresponding to S . Theorem 2. Assume that [f ] , S[v] and [f]m, S[v]m are the least solutions \nof S and Sm, respectively, where S[v](R)= \u00d8 for all program points v, and resource sets R. Then for every \nprocedure f, and program point v, ([f] )= [f]am(S[v] )= S[v]m amm The proof is analogous to the proof \nof Theorem 1. The non\u00ademptiness assumptions are required as the functions from F only commute with non-empty \nleast upper bounds (since \u00d8 = Res). In the analysis results of the example program of Figure 1 presented \nabove every set of resource sets, has only one element. This is the case because the example program \nis .ow-independent. Applying am in this case just removes the extra pair of set brackets. ' For programs \nwith .ow-independent resource sets satisfying as- For the interrupt I we obtain e.g.: Node [I , 3] ' \ne [I1, 3] ' [I2, 3] ' [I , 3] ' r Result \u00d8 {r ' } {r ' } \u00d8 sumption (S), we obtain: Corollary 1. Assume \nthat all resource sets are .ow-independent. Assume that [f], S[v, i] and [f]m, S[v]m are the least solutions \nof the constraint systems S and Sm, respectively. Then for every program point v, possible static priority \ni and resource set R, a([f] i)(R)= {[f](R)} a(S[v, i])(R)= {S[v]m(R)} m The least solution to the system \nSm can be computed in O(n \u00b7 o) if operations on resource sets (bit vectors) are counted for O(1). In \ncase a program with .ow-independent resource sets consisting solely of tasks, each program node needs \nto be analyzed for only a single context, the static priority of its task and the empty resource set. \nHowever, a node inside a procedure can be reached not only with different static priorities but also \nwith several distinct resource sets. In order to deal with this situation, we propose to combine the \n summary functions [f]m (which can be computed in polynomial time) with the constraint system R . This \nis possible since, by Corollary 1, the functions [f] can be recovered from the functions [f]by: [f] (R)= \n{[f](R)}. mm  4. Data Races In this section, we apply the results from the last section to detect data \nraces in PCP programs. One can think of a task using its dynamic priority to defend against interfering \ninterrupts. Interrupts use their static priority to attack other tasks. Note that it is the static priority \nof an interrupt q which decides whether q may interfere with the computation of another task executing \nat a given dynamic priority level. We there refer to the dynamic priority level protecting an access \nas defensive priority and the static priority level of an access as its offensive priority. De.nition \n3. Assume that R[v, i] denotes the least solution to the constraint system R .Wede.ne: V Po(x)= {P(q) \n| x . Acc(q),q . Irpt} Pd(x)={P(R) . i | (u, cmd,v) . E, x . Acc(cmd),R . R[v, i]= \u00d8} Where . and . \ndenote minimum and maximum, respectively. These functions map global variables to their offensive and \ndefensive priorities, respectively. We have: Theorem 3. If the program satis.es assumption (S), a data \nrace occurs at x if and only if Po(x) > Pd(x). Proof. First we assume that we are given an execution \npath p\u00af(u, s, v)Uq)pU/q). R[v, i] for some static priority i where p\u00afis an execution path reaching program \npoint u, p is a same-level exe\u00adcution path of the interrupt q, (u, s, v) accesses the global x and p \nalso contains an access to x.Let R = R(\u00afp, \u00d8) denote the resource set held when reaching v along p\u00af(u, \ns, v),and j = i .P(R) de\u00adnote the corresponding dynamic priority. Since the interrupt q may occur after \nthe execution of p\u00af,wehave j< P(q).ByTheorem 1, R . R[v, i] . Therefore, Pd(x) = j< P(q) =Po(x). Con\u00adversely \nassume that Po(x) > Pd(x). This means that there is an interrupt q of priority Po(x) which has a same-level \nexecution path p containing an access to the global x. Furthermore, there is an edge (u, cmd,v) accessing \nx together with a static priority i and resource set R . R[v, i] such that P(R) . i = Pd(x) < P(q). Since \nR[u, i] gathers all resource sets possibly reaching u and cmd may not change resource sets, R is also \ncontained in R[u, i] . Therefore by Theorem 1, there exists an execution path p\u00afreach\u00ading u at static \npriority i with R(\u00afp, \u00d8)= R. It follows that p\u00af(u, cmd,v)Uq)pU/q) is a reaching execution path from R[v, \ni], and we have a data race at x. If the program has .ow-independent resource sets, and all ac\u00adcesses \nare reachable, an equivalent result can be achieved using the cheaper must-resource analysis Rm. In a \ngeneral setting this would still yield a safe over-approximation of data races. For the example program \nin Figure 1, Po(x) and Pd(x) are as follows: Po(x)= Po(y)=2 Po(z)=3 Pd(x)= Pd(y)=2 Pd(z)=1 This means \nthat x and y are safe, but there is a data race at z.Which is due to I ' being possible at T9. More generally \nwe can say, that an access to x or y is safe at a defensive priority of 2 and higher, while z requires \npriority 3 or more.  5. Analyzing Transactionality Nontransactional behavior occurs when a fragment \nof a program which is meant to be executed atomically is interrupted by a task which accesses data manipulated \nby this fragment. A write access of the interrupting task may result in inconsistent data for the program \nfragment, while a read access may supply the interrupt with inconsistent data. In the example in Figure \n1 the main task switches the value of x and y and whenever accessing either one it holds the resource \nr guaranteeing exclusive access. However, it releases the resource between the two operations, which \nallows the interrupt I to modify x and y. However the old value of x is still stored in the local variable \nt which is used later to overwrite y. This is an instance of the nontransactional behavior described \nby De.nition 2. These problems are avoided if the defensive priority is suf.\u00adciently large not only for \na single access, but for the whole pro\u00adgram fragment in question. There are several subtle points to \nbe taken into account. One point is, that a procedure may have leading and trailing parts which do not \naccess globals. These parts should not in.uence the defensive priority of the procedure. Another one \npoint is, that there can be calls to other procedures which might release a held resource and then, perhaps, \nacquire it again. This in\u00ad.uences the defensive priority of the caller, no matter where in the callee \nthe temporary decrease in priority occurs. 5.1 Tasks Without Procedures Let us .rst consider PCP programs \nwith tasks, but no procedure calls. Thus, transactional behavior may refer to tasks only. Assume that \nq is such a task with static priority j. Assume further that for every program point v of q,wearegivenaset \nS[v]m(\u00d8) . Res of (de.nitely) held resources when reaching program point v.In particular, S[qe]m(\u00d8)= \n\u00d8. These sets allow to compute a (lower bound to) the dynamic priority of q when reaching program point \nv. This value is given by: P[v]= P(q) .P(S[v]m(\u00d8)) Let [p]* = {0,...,p} . {8} equipped with the reverse \nnatural or\u00addering =. For convenience, we denote the componentwise ordering on pairs from [p]2 * by = \nas well. For each program point v, we determine values S[v]t . [p]2 * where the .rst component of S[v]t \nis the minimal dynamic prior\u00adity attained on execution paths reaching v between the .rst and the last \naccess to a global. It equals 8 if and only if no global has been accessed so far. The second component \nis the minimal dynamic pri\u00adority attained after the .rst access. The pairs S[v]t are characterized as \nthe least solution (least w.r.t. to the ordering =)ofthe following constraint system: ]= (8, 8) S[v]t \n= let (a1,a2)= S[u]t in let a = P[v] . a2 in (a2,a) (u, s, v) control-.ow edge with Acc(s)= \u00d8 S[v]t = \nlet (a1,a2)= S[u]t in let a = if a2 < 8 then P[v] . a2 else 8 in (a1,a) (u, s, v) control-.ow edge with \nAcc(s)= \u00d8 S[qet Let Pd(q) be the .rst component of S[qr]t. Then the task q is transactional, if and only \nif Pd(q) =Po(x) holds for all globals x accessed by q.Where Po(x) is the offensive priority of the global \nx as de.ned in De.nition 3. In case that the PCP program has .ow-independent resource sets, also the \nreverse implication holds. We will not prove these statements here, since they follow from  y xf() \na4 a3 a2 a1  Figure 2. Priority ranges. the corresponding properties of the more general interprocedural \nsetting presented in the next subsection. Instead, we consider our introductory example. Applying the \nanalysis to the example program from Figure 1, we obtain the following results (showing only selected \nnodes): Node T2 T5 T8 Tr Ir I ' r Priorities (3, 3) (1, 1) (1, 1) (1, 1) (2, 2) (3, 3) In each task, \nthe return point is reachable from every program point of the task. Therefore, the defensive priorities \nare given by: Pd(T )=1 Pd(I)=2 Pd(I ' )=3 We conclude that I ' and I are transactional, since the sets \nof variables accessed by I and I ' are disjoint, but T is not, since the offensive priority, e.g., of \nz exceeds 1. Note that if z is removed from the program, our analysis still detects that the task T does \nnot swap x and y transactionally.  5.2 Tasks With Procedures In presence of procedure calls, the dynamic \npriority when reaching a program point v of some procedure f, may depend on the static priority j of \nthe task which executes f as well as the set R of resources held when f has been called. Let S[v]m(R) \ndenote the set of resources which are (de.nitely) held when reaching program point v. Then (a lower bound \nto) the dynamic priority of v is given by j .P(S[v]m(R)). Moreover, two values per program point do no \nlonger suf.ce for analyzing transactionality, since we cannot exclude procedure parts before the .rst \nor after the last access to a global when a procedure is called. Therefore, we determine four values \na1,a2,a3,a4.The .rst two components correspond to the two components which have been used in absence \nof procedures. Thus, the priority a1 is the lowest priority attained between the .rst and the last access \nto some global variable, and a2 is the lowest priority attained after the .rst access to a global. As \nbefore, a1 receives the value of a2 at every access to a global. At the return node of a procedure, the \nvalue of a1 denotes the procedure s defensive priority. Additionally, we compute the lowest priority \nobtained before the last access to a global variable in component a3. For that, the component a4 tracks \nthe lowest priority encountered altogether. The component a3 then receives the value of component a4 \nat every access to a global. This is illustrated in Figure 2. Let D denote the set of all quadruples \n(a1,a2,a3,a4) . [p]4 * where a1 = a2 . a3 and a4 = a2 . a3. Let the ordering on D again be the componentwise \nextension of the reverse natural ordering = on quadruples. The minimal element w.r.t. this ordering thus \nis given by (8, 8, 8, 8) which signi.es the empty set of same\u00adlevel execution paths. The abstract effect \n[(u, s, v)]t :[p] \u00d7 2R . The tuple [(u, s, v)]t(j, R) collects the defensive priorities of the execution \nof s with resource set R at static priority j. D of a control-.ow edge (u, s, v) is de.ned by: [(u, s, \nv)]t(j, R)= . . .(8,j .P(R),j .P(R),j .P(R)) Acc(s) = \u00d8 . . (8, 8, 8,j .P(R\\{r})) (8, 8, 8,j .P(R)) s \n= rel(r)) otherwise The following constraint system characterizes the defensive pri\u00adorities for triples \n(u, j, R) of nodes u, static priority level j and re\u00adsource sets R. The resource set R denotes the set \nof resources held, when the current procedure has been called. Similarly for non-task procedures, j denotes \nthe static priority of the calling task. [S0] S[qe,j, \u00d8]= (8, 8, 8,j) q . Task,j = P(q) tt S[fe,j,R]= \n(8, 8, 8,j .P(R)) f/. Task,j . [p] t [S1] S[v, j, R]= ([(u, s, v)](j, S[u]m(R))) .S[u, j, R] ttt tt (u, \ns, v) . E [S2] S[v, j, R]= ([f](j, S[u]m(R))) .S[u, j, R] ttttt (u, f(),v) . E [S3] [f]jR = S[fr,j,R] \nttt where abstract composition .t : D \u00d7 D . D is de.ned by: (b1,b2,b3,b4) .t (a1,a2,a3,a4)= . .(8, 8, \n8, 8) a4 . b4 = 8 . . . .(a1,a2,a3,a4 . b4)= 8 = b2 . a2 (b1,b2,a4 . b3,a4 . b4) a2 = 8 = b2 . . . .(a1,a2 \n. b4,a3,a4 . b4) a2 = 8 = b2 . . (a2 . b3,a2 . b4,a4 . b3,a4 . b4) a2 = 8 = b2 Note that a quadruple \nrepresents an execution path containing an access to some global if and only if the second component \nis less than 8.Let (c1,c2,c3,c4)=(b1,b2,b3,b4) .t (a1,a2,a3,a4). The abstract composition then is de.ned \nby case distinction on whether the represented execution paths contain accesses to globals or not. Assume \nfor example the fourth case, i.e., that a2 = 8 and b2 = 8. Thus, the right quadruple represents an execution \npath p containing an access, while the left quadruple represents execution paths p ' which do not access \nglobals. In this case, c1 = a1 because .rst and last accesses in pp ' both are contained in p. Furthermore, \nc2 = a2 .b4 as the dynamic priorities encountered during the entire path p ' occur after the .rst access \nto a global. The third component is c3 = a3, since the last access to a global occurs in p. Finally, \nthe fourth component is c4 = a4 . b4 since this component provides the minimal dynamic priority encountered \nduring the whole path pp ' . The other cases are analogous with the exception of the .rst case, which \ntakes care of bottom values. We have: Proposition 1. The abstract composition .t : D \u00d7 D . D is distributive \nin each argument, i.e., for all a, b, c . D, c .(a . b)=(c .a) . (c .b) t tt (a . b) .c =(a .c) . (b \n.c) t tt Proof. Let a =(a1,a2,a3,a4), b =(b1,b2,b3,b4) and c = (c1,c2,c3,c4). Consider the .rst assertion \nof the proposition If a2 = b2, then the same case of the composition applies to c.t (a.b) as well as \nto c .t a and c .t b, and the assertion follows by idempotency, commutativity and associativity of the \nminimum .. Accordingly, assume that w.l.o.g. a2 = 8 and b2 = 8.If c2 = 8, we obtain: c .(a . b)=(a1 . \nb1,a2 . b2 . c2,a3 . b3,a4 . b4 . c4) t c .a =( a1 ,a2 ,a3 ,a4 . c4 ) t c .b =( b1 ,b2 . c2 ,b3 ,b4 . \nc4 ) t By inspection of each component, the assertion can be veri.ed. If on the other hand, c2 = 8, we \nobtain: c .(a.b)=(a2 .b2 .c3,a2 .b2 .c4,a4 .b4 .c3,a4 .b4 .c4) t c .a =( c1 ,c2 ,a4 . c3 ,a4 . c4 ) \n In order to prove the assertion, it only must be proven for the .rst two columns that: a2 . b2 . c3 \n= c1 . b2 . c3 a2 . b2 . c4 = c2 . b2 . c4 Recall that a2 = 8. Since by assumption on the quadruples \nin D, c1 = c3 and c2 = c4, these equalities hold. This completes the proof of the .rst assertion. The \nproof of the second assertion is analogous. Assume that S[v, j, R]t and [f]t jR is the least solution \nof the constraint system St . Assume further that Po(x) is the offensive priority of the global x as \nde.ned in De.nition 3. Then we have: Theorem 4. Assume that assumption (S) is satis.ed, i.e., all pro\u00adgram \npoints are reachable by some same-level execution path. For a procedure f of a program with control-.ow \nindependent resource sets, a static priority j and a resource set R,let (a1,a2,a3,a4)= [f]t(j, R). Then \nthe procedure f called with resource set R at static priority level j is nontransactional, if and only \nif there ex\u00adists a global variable x . Acc(f ) with Po(x) >a1. Proof. For a given static priority level \nj and an initial resource set R, we assign to each same-level execution path p not containing interrupts, \na priority tuple (b1,b2,b3,b4)= at(p, j, R) . D where b1 is the minimal dynamic priority between the \n.rst and the last access to a global in p; b2 is the minimal dynamic priority after the .rst access to \nthe end of p; b3 is the minimal dynamic priority from the beginning of p to the last access to a global; \nand b4 is the minimal dynamic priority through p. By the de.nition of [(u, s, v)]t and .t, the tuple \nat(p, j, R) is inductively de.ned by: at(E, j, R)=(8, 8, 8,j .P(R)) at(p1(u, s, v),j,R)= [(u, s, v)]t(j, \nR(p1,R)) .t at(p1,j,R) at(p1Uf)p2U/f),j,R)= at(p2,j, R(p1,R)) .t at(p1,j,R) We extend the mapping at \nto sets S . .S of same-level execution paths by: at(S, j, R)= {at(p, j, R) | p . S} Note that according \nto this de.nition, at(S, j, R)=(8,8,8,8) if and only if S = \u00d8.Let S[v, j] ' (R) denote the set of same-level \nexecution paths at static priority j and initial resource set R reach\u00ading v which do not contain interrupts. \nThese sets can be character\u00adized by a constraint system S ' which is obtained from constraint system \nS characterizing all same-level execution paths by remov\u00ading the constraints S3. By de.nition, the operator \n.t preserves the least element. Since by Proposition 1, .t is also distributive in each argument, it \nfollows that at(S[v, j] ' (R),j,R)= S[v, j, R]t for all program points v. Now assume that the procedure \nf is nontransactional at static priority level j and initial resource set R, i.e., there is an execution \npath Uf) p1 Uq) p U/q) p2U/f ). [f](j)(R) such that p1p2 . S[fr,j](R) is a same-level execution path \ncontaining no interrupts; p is a same-level execution path of the interrupt q; both p1 and p2 contain \nan edge accessing a global; and p contains an edge which accesses a global variable x . Acc(f). Thus \nin particular, Po(x) =P(q).Let at(p1p2,j,R)=(b1,b2,b3,b4). Since the interrupt q may occur between the \ntwo global accesses in p1 and p2,wehave P(q) >b1. From the de.nition of at we obtain that: (b1,b2,b3,b4) \n= (a1,a2,a3,a4)= [f]t(j, R) Therefore, Po(x) =P(q) >b1 = a1 get(r ) rel(r ) z=20 3   get(r)  rel(r) \ny++ x-\u00ad 2    get(r )  rel(r ) y=0  f() x=10 1   get(r) t=x+y g() y=t-y x=t-x    rel(r) rel(r) \nget(r) z=t*2   Figure 3. Example program with procedures. Conversely assume that [f]t(j, R)=(a1,a2,a3,a4) \nand there is a global x . Acc(f ) such that Po(x) >a1. This means that a1 < 8, and that there is an interrupt \nq with P(q)= Po(x) > 0= P(main) which has a same-level execution path p which accesses x.Since a4 = a1 \n< 8, Recall that S[fr,j,R]t = at(S[fr,j] ' (R),j,R) = {at(p ' ,j,R) | p ' . S[fr,j] ' (R)} Therefore, \nthere exists an interrupt-free same-level execution path p ' . S[fr,j] ' (R) such that a1 equals the \n.rst component of at(p ' ,j,R).Since a1 < 8, there exist at least two accesses to globals in p ' . Moreover, \np ' can be factored into p ' = p1p2 where p1 and p2 both contain at least one access to a global and \nthe dy\u00adnamic priority after p1 equals a1.Since P(q) >a1 interrupt q may occur between p1 and p2. Thus \nby De.nition 2, f is not transac\u00adtional when called at static priority j with resource set R. For programs \nwith .ow-dependent resource acquisition, this anal\u00adysis still yields a safe over-approximation, i.e., \ntransactional proce\u00addures may be considered as possibly nontransactional, but not the other way round. \nAlternatively, the .ow-precise resource analysis S could be used to obtain more precise results. Consider \nthe example program of Figure 3 where the part of T after the initialization has been wrapped into the \nprocedure f and the nodes T9 to T10 of the original example program have into procedure g. The procedure \ng is transactional since it only contains one access to a global variable. The procedure f holds the \nresource r at all nodes between its .rst and last access to a global variable. However the call to g \ncompromises the transaction\u00adality of f since it temporarily releases r. The analysis presented above \ncaptures this behavior. For the procedure g called at static priority 1 with resource set {r} we obtain \nthe following summary: [g](j, {r})=(8, 1, 1, 1). When applied to the tuple reaching f3 t we have: (8, \n1, 1, 1) .t (2, 2, 1, 1) = (1, 1, 1, 1). Since tuple en\u00adtries may not increase, this tuple is then carried \nover to fr and with Pd(x)=2 we see that f is not transactional.  6. Linear Equalities For PCP Programs \nThe resource analysis presented in Section 3 need not explicitly deal with interrupts. The reason is \nthat interrupts neither change sets of held resources nor affect the current priorities of tasks. Values \nof globals on the other hand, can be affected by interrupts. Fortunately, summary-based interprocedural \nanalyses [28] can be adapted to resource aware value analyses of PCP programs rather easily. As a prototypic \nexample we extend the approach presented in [21] for analyzing linear equalities to take resources and \ninterrupts into account. The goal of this analysis is to compute the linear closure of extended states \nof the collecting semantics.  For simplicity, we restrict ourselves to PCP programs with .ow\u00adindependent \nresource sets. Let X = {x1,...,xk} denote the set of global variables, where k = |X| is the number of \nglobal variables. We consider af.ne assignments of the form xj := t0 +Ski=1ti \u00b7 xi with ti . Q.We write \nV for the complete lattice of linear subspaces of (k+1)\u00d7(k+ 1) matrices over the rationals Q. Each matrix \nA describes the effect of an execution onto the global state. Thereby, each global state is represented \nby a vector v =[v0,...,vk]T . Qk+1 where v0 =1 and for i> 0, vi records the value of the variable xi. \nWe write V ' for the complete lattice of linear subspaces of (k +1) vectors over the rationals Q. The \nextra component v0 allows to linearize af.ne transformations. A set S . Q(k+1)\u00d7(k+1) of transformation \nmatrices is abstracted by the linear space Span S .V of all linear combinations of matrices in S. :2Res \n. The concrete resource sensitive semantics [(u, s, v)]l Q(k+1)\u00d7(k+1) of an edge is then given by: [(u, \ns, v)] l(R)= 1 | 0 | 0 0 | Ij-1 | 0 t0 | t1 ... tk s = xj := t0 +Ski=1ti \u00b7 xi 0 | 0 | Ik-j [(u, s, v)] \notherwise l(R)= Ik+1 Where Im denotes the m-dimensional identity matrix. Note, that the resource parameter \nis not used here, but might be in another instance of the framework and is therefore given for completeness. \nThe resource sensitive semantics of an execution path p . . is de.ned as follows: [E]l = Ik+1 [ep ' ]= \n[p ' ]\u00b7 [e] l ll [Uf)p1U/f)p2]= [p2] \u00b7 [p1] ll [Uf1)p1 ... Ufs)ps]= [ps]\u00b7 ... \u00b7 [p1] l lL The concrete \nresource sensitive collecting semantics R[u, i]l : 2Res . Qk+1 of a program point u and static priority \nlevel i is then given by: R[u, i]l(R)= {[p\u00af](x) | R = R(\u00afp, \u00d8),x . Qk+1 ,p\u00af. R[u, i]} As in [21] we approximate \nthis by its span, i.e.: R[u, i]l (R)= Span(R[u, i]l(R)) :2Res We de.ne the abstract semantics [e]l . \nV by [e]l (R)= Span{[e](R)}. Since in the end we are interested in equalities l holding at a program \npoint, we can model non-af.ne assignments, xj =?, by assignments of all constant values. For the abstract \nsemantics we therefore have: 1 | 0 | 01 | 0 | 0 0 | Ij-1 | 00 | Ij-1 | 0 [xj :=?](R)= Span , l 0 | 0 \n| 01 | 0 | 0 0 | 0 | Ik-j0 | 0 | Ik-j To each procedure f , we assign an abstract function [f ]l :[p] \n. 2Res . V which summarizes the abstract effect of f. These effects are characterized by the least solution \nof the constraint system: [Sl 0] S[fe,i,R]l . I [Sl 1] S[v, i, R]l . ([(u, s, v)]l R) .l Sl [u, i, R]l \n(u, s, v) . E [S2] S[v, i, R]. ([f]i (S[u]m (R))) .S[u, i, R] l ll ll (u, f(),v) . E [Sl 3] S[u, i, R]l \n. [j]S[u, i, R]l l .l u/. Ne, j>i .P(Sm[u](R)) [S4] [f]iR .H(S[fr,i,R]) l l fl [j]l . [q]l j \u00d8 q . Irpt, \nP(q = j) For two sets of matrices M1,M2 . V , the operator .l : V \u00d7 V . V is de.ned as follows: M1 .l \nM2 = Span{A1A2 | A1 . M1,A2 . M2} By using the precomputed transformers for resource sets, we can statically \ncheck the priority condition including the resource set in\u00adformation and therefore, for this instance, \nwe do not need a ded\u00adicated l operator performing this check. Instead, we use .l for interrupts as well. \nSince we consider global variables only, the op\u00aderator Hf which transforms the abstract semantics of \na procedure into the abstract semantics of its call, is simply the identity. For tasks the resource set \nparameter R is always the empty set and the static priority i is the static priority of that task. Thus, \nif the pro\u00adgram does not contain procedures, the summaries can be simpli.ed to vector spaces of matrices. \nIn the second phase, we compute for every program point v and static priority i a mapping Rl [v, i]:2Res \n. V ' . For any given resource set R, this mapping is meant to return the linear hull of all concrete \nstates x . Qk+1 possibly reaching program point v within a task with static priority i given the current \nresource set equals R. The set of all functions 2Res . V ' forms a complete lattice w.r.t. the partial \nordering on functions induced by the partial ordering on V ' .Fromabasis B of Rl [u, i](R) for a program \npoint u with static priority i and resource set R, we obtain the set of valid equalities k t0 +i=1 ti \n\u00b7 xi =0 as the set of solutions of the system t0 \u00b7 b0 + ... + tk \u00b7 bk =0 , (b0,...,bk) . B In order to \ndescribe the effect of a procedure f for this second phase, we rely on two ingredients: the summary \n[f]m computed by same-level must resource analysis, which records how the execution of f may change the \nsets of held resources, and  the summary [f]l computed by the same-level analysis of lin\u00adear transformations \nin the .rst phase, which for each static pri\u00adority i and resource set before the call returns the vector \nspace of possible linear transformations.  This yields the following constraint system: [R0] R[maine \n, 0]; M0 l l [R1] R[v, i]; ([e]l , [e])@R[u, i] l l mll e =(u, s, v) . E [Rl 2] R[v, i]l ; (([f]i), [f])@l \nR[u, i]l lm (u, f(),v) . E R[fe,i]; enter(R[u, i]) (u, f(),v) . E l f,ll [R3] R[u, i]; [j]@R[u, i]u/. \nNe, j>i l l lj,ll R[j]l ; projj,l(Rl[u, i]) u/. Ne, j>i R[qe,j]l ; enterq,l(R[j]l ) q . Irpt, P(q)= j \nHere, M0 is the mapping which assigns the full vector space Qk+1 to the empty resource set R = \u00d8 and \nthe zero space {0} to all ) \u00d7 (2Resresource sets R = \u00d8. The operator @l : ((2Res . V ' . 2Res)) \u00d7 (2Res \n. V ' ) . (2Res . V ' ) is de.ned by: ((M, h)@l f)(R ' )= Span{Ax | R ' = h(R),A . M(R),x . f(R)} Since \nwe consider global variables only, the function enterf,l is the identity function, i.e., enterf,l f = \nf. In the constraint Rl 3, a modi.ed version of the application and the enter operator are required which \ntake into account that an interrupt q can only be enabled if the static priority of q exceeds the dynamic \npriority at a given program point. Therefore, we de.ne:  (M@j,lf) R = Span{Av | A . M (\u00d8),v . f(R),j \n> P(R)} Span{v . f(R ' ) | j> P(R ' )} if R = \u00d8 (projj,lf) R = {0} otherwise In any case we have the \nfollowing theorem: Theorem 5. Assume that the PCP program has .ow-independent resource sets and satis.es \n(S) Let furthermore S[v, i], [f] and S[v, i, R]l , [f]l , S[v]m, [f]m as well as R[v, i]l denote the \nleast solutions of the constraint systems S, Sl , Sm, and Rl , respectively. Then the following holds: \n1. For every program point v, static priority i, resource set R and procedure f, Span{[p]| p . S[v, i](R)} \n= S[v, i, R]l l Span{[p]| p . [f] iR} = [f]iR ll 2. For every program point v, static priority i and \nresource set R Span{[p\u00af](x) | p\u00af. R[v, i],x . Qk+1 , R(\u00afp, \u00d8)= R} = l R[v, i]l (R) For the constraint \nsystem Sl we have at most n \u00b7 p 2 \u00b7 2o constraints. Using the techniques from [21], this implies that \nthe least solution 2 2o can be computed in time O(n \u00b7 p \u00b7\u00b7 k8). This is a smooth gener\u00adalization of the \nresults obtained in [21] to the case of programs with interrupts and resources. Note that a practical \nimplementation may explore the given constraint systems in a demand-driven fashion such that only those \nresource sets are considered which actually are necessary for computing the reachability information \nas pro\u00advided by the least solution of Rl . For the special case of tasks only without auxiliary procedures, \nthis means that the factor 2o can be dropped completely. We exemplify our analysis for the example program \nin Figure 1. Due to their non-deterministic nature, interrupts may occur arbitrar\u00adily often, creating \nan in.nite number of program executions for a given program point, each corresponding to linear transformations \nof the state vectors. Since we are only interested in the linear hull of these transformations, it suf.ces \nto maintain a basis of the gen\u00aderated sub-space of matrices. Accordingly, we obtain the following summaries \nfor the interrupts I and I ' : 1 0000 0 1000 [I ](3, \u00d8)= Span 0 0100 ' l 200000 0 0001 10000 10000 -11000 \n-11000 [I](2, \u00d8)= Span 10100 , 10100 l 00010 20 0000 00001 00001 These transformations can be applied \nto compute the subspace of possible values for each program point of the main task. For T4,we obtain: \n1 000 10 1 00 R[T4, 1]l \u00d8 = Span 0 , -1 , 0 , 0 0 010 0 001 The second vector is due to the potential \noccurrence of the interrupt I. The interrupt I ' has no impact, since I ' is not enabled and there are \nno restrictions on the value of z,at T4. From the basis we obtain the system of equalities: 1 \u00b7 t0 +10 \n\u00b7 t1 =0 1 \u00b7 t1 +(-1) \u00b7 t2 =0 1 \u00b7 t3 =0 1 \u00b7 t4 =0 Solving this yields the equality x + y =10. Overall \nwe have the following equalities: Node Example Equalities x =10,y =0,x + y =10 T3 T4,T5 x + y =10 t = \nx + y =10 T6 x - y + t =0 T7 z =10 T8 T9,...,Tr z =20,t =10 I2' ,Ir ' z =20 This means that at the end \nof the main task T and the interrupt I ' , the equality z =20 holds. Moreover, the equality 10 = x+y \nholds although interrupts may freely occur at nodes T4 and T5. Finally, the local variable t equals 10, \nonce it has been written. Note that the equalities for z and t cannot be guaranteed in I,since I may \noccur at node T3 where both variables may still be uninitialized. Note that while this analysis directly \n.ts into the framework, it is also possible to use analyses, which for example use in.\u00adnite lattices, \nevaluate branching conditions, or even are unable to provide closed function summaries. For in.nite lattices \none would use a demand-driven local solver ([9]) and possibly widenings ([6]. The branching conditions \ncould be added to the .ow-graph and the framework semantics extended to treat them as nops while allowing \nthe concrete analysis instance to fully evaluate them. Finally sum\u00admary functions can be handled by tabulating \nthem. This technique is used in the Goblint analyzer and proved to be very useful.  7. Implementation \nThe data race and transactionality analyses from Sections 4 and 5, respectively, have been implemented \nin the analyzer Goblint for multi-threaded C [31]. This analyzer framework is based on a local .xpoint \nengine and provides basic analyses such as constant prop\u00adagation and alias analysis, which then can be \nenhanced with addi\u00adtional speci.c domains and transfer functions. The analyzer differ\u00adentiates between \nread and write accesses in order to avoid read-read warnings. Beyond the path-based approach presented \nin sections 4 and 5, Goblint takes conditions into account whenever possible. By that, the analysis may \nexclude some unrealizable execution paths and therefore may raise less false alarms. The test suite consists \nof sample programs from the nxtOSEK implementation [29] together with our own examples. Program biped \nrobot is part of the control software of a self-balancing two wheeled robot, which uses resources to \nsynchronize the bal\u00adancing with remote control commands. The programs xxx test are examples for preemptive \nscheduling (pe), resource synchro\u00adnization (res), time-triggered tasks (tt) and usb communication (usb). \nEach of these tests uses two tasks and one resource. Pro\u00adgrams example and example fun are from Figure \n1 and Figure 3, respectively. Program pingpong consists of two tasks which al\u00adternately set a variable \nto ping and pong synchronizing via a single resource. Program counter consists of an interrupt which \nincreases two .elds of a struct if an integer .ag is set and does noth\u00ading otherwise as well as a task \nwhich unsets the .ag, then prints the struct and re-sets the .ag. The integer .ag itself is protected \nby the resource. The results of running the analyzer on these examples are summarized in Table 1. We \nran these experiments on a Intel(R) Core(TM)2 Quad CPU machine with 3.00GHz under Ubuntu 10.04. The analyzer \nveri.es that the two programs pingpong and usb test are free of data races. The data races in both versions \nof the example program are discovered, as well as the unsafe ac\u00adcess to counters in pe test and tt test. \nThe race warning in biped robot occurs since re-running the initialization task is not ruled out. For \ncounter, race warnings are produced for the .elds  Program Size Time Race Trans. biped robot pe test \nres test tt test usb test example example fun pingpong counter 151 lines 97 lines 74 lines 101 lines \n140 lines 38 lines 51 lines 53 lines 58 lines 0,02 s 0,06 s 0,03 s 0,07 s 0,04 s 0,01 s 0,01 s 0,03 s \n0,02 s 1 1 0 1 0 1 1 0 2 0 1 1 1 0 1 2 0 1 Table 1. Result of analyzing example programs of the struct \nsince they are accessed both by the task and the inter\u00adrupt without protection with a resource. While \nwe verify that the integer .ag accesses are safe, the analysis presented here approxi\u00admates conditional \nbranching with non-deterministic branching and therefore does not relate the .ag value with the accesses \nto the struct. Other analyses provided by the Goblint analyzer, however, may split the execution path \nbased on the value of the .ag and thus may separately analyze the cases for a set and an un-set .ag. \nRegarding transactionality, the analyzer veri.es that the tasks of usb test and pingpong are transactional. \nIt discovers the viola\u00adtion of transactionality of the running example and also produces warnings for \npe test and tt test where the race occurs between accesses to the counter. In res test, a variable whose \naccesses are otherwise protected by a resource, is read after the release of the resource thus violating \nour de.nition of transactionality. In biped robot, on the other hand, the accesses to globals may be \ninvolved in data races, but are the only accesses to globals in their respective procedures. Accordingly, \ntransactionality is not violated. For counter, a transactionality warning is produced, since the re\u00adsource \nis released between un-setting and re-setting the .ag. All examples are small and therefore analyzed \nin negligible time. In order to get an intuition how the analyses scales, we eval\u00aduated the analyzer \non the synthetic benchmarks chain n. While the estimates for the asymptotic complexity of our analyses \ngrow exponentially with the number of resources, they depend only lin\u00adearly on the program size. Therefore, \nwe do not expect the pro\u00adgram size to be the major bottleneck for scalability but the num\u00adber of resourced \nand interrupt levels. Thus, we vary these latter parameters in the benchmarks. For n = 1, program chain \nn has globals x0,...,xn, n interrupt levels and n resources which are used to successively copy the value \nof the variable xi into the variable xi-1. The running times of the analyzer for the in\u00adstances n = 100, \n200,..., 1000 are shown in Figure 4. For each of them, the analyzer veri.ed absence of data races and \ntransac\u00adtionality of all tasks. The increase in run time for these instances is slightly worse than linear. \nEven for 1000 interrupt levels and re\u00adsources, the runtime is still quite acceptable. The source code \nof our analyses, all benchmarks, and a script to run them are available at http://goblint.in.tum.de/popl11.html. \n 8. Related Work While the ceiling and inheritance protocols [4, 27] have been for\u00admally studied [7, \n23], these papers focus on schedulability rather than data consistency; that is, one assumes the program \nis cor\u00adrectly synchronized and characterizes the impact of synchroniza\u00adtion primitives on meeting hard \ndeadlines as a function of resource usage. In contrast, we are interested in detecting erroneous use \nof these synchronization primitives. Already simple analysis problems for concurrent programs with recursion \nand synchronization are undecidable [24]. Practi\u00adcal approaches therefore either over-approximate the \ninteraction Runtime in seconds 7 6 5 4 3 2 1 Number of interrupts Figure 4. Runtimes of the analyzer \non chain n. between threads, as in thread-modular model checking [10], or ignore synchronization altogether \n[5, 8]. Some also place restric\u00adtions on concurrency. In a number of papers, Kahlon et al. [14 16] discuss \nmodel checking of pushdown systems synchronized via locks where the usage of locks must be well nested. \nThis ap\u00adproach has been generalized to pushdown systems with dynamic thread creation [19, 20]. With the \nexception, perhaps, of dynam\u00adically changing priorities, PCP programs extended with dynamic task creation \ncan also be cast within the more general model of multi-set pushdown systems. For these, Atig et al. \n[2] show that control point reachability is decidable. Their approach is based on Petri net reachability \nand does not support the inference of more complicated invariants such as linear equalities. Kidd et \nal. [18] observe that every priority preemptive system can be transformed into a pushdown system. Beyond \nthat, they ad\u00additionally represent the schedulers corresponding to synchroniza\u00adtion protocols as exponentially \nlarge pushdown systems. In case of PCP as well as for priority inheritance with well-nested resource \nusage, these two systems can be combined into one pushdown sys\u00adtem. From that, they conclude that reachability \nis decidable for PCP as well as for priority inheritance with well-nested resource usage. Our approach \ncannot be applied to priority inheritance directly, while for PCP, our analysis is exponential only in \nthe number of resources (not in the number of interrupts). Summarizing abstract effects of interrupts \nhas also been consid\u00adered by Regehr et al. [26] for analyzing stack over.ow in assembly code. Their summaries \ndescribe the stack consumption of an inter\u00adrupt together with the set of interrupts which become enabled/dis\u00adabled \nby the execution. Their model does not deal with speci.c protocols such as PCP. Additionally, Regehr \nand Cooprider [25] present a transformation technique to turn interrupt-driven embed\u00added code into thread-based \ncode and apply off-the-shelf race de\u00adtection tools to the transformed code. They introduce arti.cial \nin\u00adterrupt locks to make interrupt disabling/(re-)enabling visible to the analysis. They assume .xed \nstatic priorities and suffer from the im\u00adprecision possibly incurred by the thread analyzer. In contrast, \nour approach directly exploits the properties of the PCP protocol for interrupt-driven concurrency and \nexplicitly deals with dynamically changing priorities. This allows us to handle the set of possible in\u00adterleavings \nprecisely. Flanagan et al. [11] present a type system for atomicity in con\u00adcurrent Java programs. A transactional \nprocedure as de.ned in this paper is atomic in their sense since every execution of a transac\u00adtional \nprocedure that is possibly interrupted has an equivalent se\u00adrial execution, i.e., no interrupts occur \nduring its execution. This atomicity condition is relaxed by Vaziri et al. [30], who provide a set of \nproblematic access patterns and show that they are complete, i.e., the absence of all these patterns \nguarantee that the execution is serializable w.r.t. the critical variables and demarcated critical sections. \nOur notion of transactionality for a procedure f considers all, potentially accessed, global variables \nas critical for f where the critical section of f is the section between the .rst and last access to \nglobal variables. Kidd et al. [17] provide a static analysis for Java programs to verify the absence \nof such patterns in a given program. Artho et al. [1] give a static analysis to detect stale-value atomicity \nviolations, i.e., accesses to outdated values of globals stored in a local variable that has escaped \nthe critical section.  9. Conclusions We have provided practical methods to analyze data races and \ntransactionality in PCP programs. Moreover, our analysis of linear equalities can be considered as one \ninstance of an analysis frame\u00adwork which generalizes the functional approach of [28] from pro\u00adgrams with \nprocedures to programs with procedures, interrupts, pri\u00adorities and resources following the PCP protocol. \nOther instances of this framework can be obtained by providing speci.c domains V and V ' for summary \nfunctions and abstract states, respectively, to\u00adgether with transfer functions for the basic statements \nand speci.c versions of the operators ., j , Hf , @, enterf , @j and projj . We have implemented the \nanalyses of potential data races and transactionality within the static analyzer Goblint [31]. Preliminary \nexperiments with typical examples as well as a scalable synthetic benchmark, are encouraging. Still, \nexperiments with larger and more complicated real-world examples are desirable. We would also like to \nanalyze further kinds of concurrency .aws in PCP pro\u00adgrams and explore in how far the given approach \ncan be gener\u00adalized to more general programming models, e.g., PCP programs with task creation.  Acknowledgements \nWe thank Gordon Haak and Philipp Legrum for interesting us in PCP programs as well as providing example \nprograms and valuable insights from a user s perspective. This work is supported by the joint DFG project \nOpIAT (MU 1508/1-1 and SE 551/13-1). The third author is partially supported by EstSF grant 8421.  References \n[1] C. Artho, K. Havelund, and A. Biere. Using block-local atomicity to detect stale-value concurrency \nerrors. In ATVA 04, vol. 3299 of LNCS, pp. 150 164. Springer, 2004. [2] M. F. Atig, A. Bouajjani, and \nT. Touili. Analyzing asynchronous programs with preemption. In FSTTCS 08,vol.2of LIPIcs, pp. 37 48. Schloss \nDagstuhl, 2008. [3] Autosar consortium. Autosar Architecture Speci.cation, Release 4.0, 2009. URL http://www.autosar.org/. \n[4] T. P. Baker. Stack-based scheduling of realtime processes. Real-Time Systems, 3(1):67 99, 1991. [5] \nA. Bouajjani, M. M\u00a8uller-Olm, and T. Touili. Regular symbolic analy\u00adsis of dynamic networks of pushdown \nsystems. In CONCUR 05,vol. 3653 of LNCS, pp. 473 487. Springer, 2005. [6] P. Cousot and R. Cousot. Comparing \nthe Galois connection and widen\u00ading/narrowing approaches to abstract interpretation, invited paper. In \nPLILP 92, pp. 269 295. Springer, 1992. [7] B. Dutertre. Formal analysis of the priority ceiling protocol. \nIn RTSS 00, pp. 151 160. IEEE Press, 2000. [8] J. Esparza and A. Podelski. Ef.cient algorithms for pre* \nand post* on interprocedural parallel .ow graphs. In POPL 00, pp. 1 11. ACM Press, 2000. [9] C. Fecht \nand H. Seidl. A Faster Solver for General Systems of Equations. Sci. Comput. Programming, 35(2):137 161, \n1999. [10] C. Flanagan, S. N. Freund, S. Qadeer, and S. A. Seshia. Modular veri.cation of multithreaded \nprograms. Theoretical Comput. Sci., 338 (1-3):153 183, 2005. [11] C. Flanagan, S. N. Freund, M. Lifshin, \nand S. Qadeer. Types for atomicity: Static checking and inference for java. ACM Trans. Prog. Lang. Syst., \n30(4):1 53, 2008. [12] M. S. Hecht. Flow Analysis of Computer Programs. Elsevier, 1977. [13] T. Henties, \nJ. J. Hunt, D. Locke, K. Nilsen, M. Schoeberl, and J. Vitek. Java for safety-critical applications. In \nSafeCert 09, ENTCS. Elsevier, 2010. [14] V. Kahlon and A. Gupta. On the analysis of interacting pushdown \nsystems. In POPL 07, pp. 303 314. ACM Press, 2007. [15] V. Kahlon, F. Ivan.ci\u00b4c, and A. Gupta. Reasoning \nabout threads com\u00admunicating via locks. In CAV 05, vol. 3576 of LNCS, pp. 505 518. Springer, 2005. [16] \nV. Kahlon, Y. Yang, S. Sankaranarayanan, and A. Gupta. Fast and ac\u00adcurate static data-race detection \nfor concurrent programs. In CAV 07, vol. 4590 of LNCS, pp. 226 239. Springer, 2007. [17] N. Kidd, P. \nLammich, T. Touili, and T. Reps. A decision procedure for detecting atomicity violations for communicating \nprocesses with locks. In SPIN 09, vol. 5578 of LNCS, pp. 125 142. Springer, 2009. [18] N. Kidd, S. Jagannathan, \nand J. Vitek. One stack to run them all reducing concurrent analysis to sequential analysis under priority \nscheduling. In SPIN 10, vol. 6349 of LNCS, pp. 245 261. Springer, 2010. [19] P. Lammich and M. M\u00a8uller-Olm. \nCon.ict analysis of programs with procedures, dynamic thread creation, and monitors. In SAS 08,vol. 5079 \nof LNCS, pp. 205 220. Springer, 2008. [20] P.Lammich,M.M\u00a8uller-Olm, and A. Wenner. Predecessor sets of \ndy\u00adnamic pushdown networks with Tree-Regular constraints. In CAV 09, vol. 5643 of LNCS, pp. 525 539. \nSpringer, 2009. [21] M. M\u00a8uller-Olm and H. Seidl. Precise interprocedural analysis through linear algebra. \nIn POPL 04, pp. 330 341. ACM Press, 2004. [22] OSEK/VDX Group. OSEK/VDX Operating System Speci.cation, \nVersion 2.2.3, 2005. URL http://www.osek-vdx.org. [23] M. Pilling, A. Burns, and K. Raymond. Formal speci.cations \nand proofs of inheritance protocols for real-time scheduling. Softw. Eng. J., 5(5):263 279, 1990. [24] \nG. Ramalingam. Context-sensitive synchronization-sensitive analysis is undecidable. ACM Trans. Prog. \nLang. Syst., 22(2):416 430, 2000. [25] J. Regehr and N. Cooprider. Interrupt veri.cation via thread veri.ca\u00adtion. \nENTCS, 174(9):139 150, 2007. [26] J. Regehr, A. Reid, and K. Webb. Eliminating stack over.ow by abstract \ninterpretation. ACM Trans. Embedded Comput. Syst., 4(4): 751 778, 2005. [27] L. Sha, R. Rajkumar, and \nJ. P. Lehoczky. Priority inheritance proto\u00adcols: an approach to real-time synchronization. IEEE Trans. \nComput., 39(9):1175 1185, Sept. 1990. [28] M. Sharir and A. Pnueli. Two approaches to interprocedural \ndata .ow analysis. Program Flow Analysis: Theory and Applications, pp. 189 234, 1981. . MINDSTORMS [29] \nTakashi Chikamasa et al. OSEK platform for LEGO R R ., 2010. URL http://lejos-osek.sourceforge.net/. \n[30] M. Vaziri, F. Tip, and J. Dolby. Associating synchronization con\u00adstraints with data in an object-oriented \nlanguage. In POPL 06, pp. 334 345. ACM Press, 2006. [31] V. Vojdani and V. Vene. Goblint: Path-sensitive \ndata race analysis. Annales Univ. Sci. Budapest., Sect. Comp., 30:141 155, 2009.  \n\t\t\t", "proc_id": "1926385", "abstract": "<p>We consider programs for embedded real-time systems which use priority-driven preemptive scheduling with task priorities adjusted dynamically according to the immediate ceiling priority protocol. For these programs, we provide static analyses for detecting data races between tasks running at different priorities as well as methods to guarantee transactional execution of procedures. Beyond that, we demonstrate how general techniques for value analyses can be adapted to this setting by developing a precise analysis of affine equalities.</p>", "authors": [{"name": "Martin D. Schwarz", "author_profile_id": "81479646856", "affiliation": "Technische Universit&#228;t M&#252;nchen, M&#252;nchen, Germany", "person_id": "P2509570", "email_address": "schwmart@in.tum.de", "orcid_id": ""}, {"name": "Helmut Seidl", "author_profile_id": "81100146213", "affiliation": "Technische Universit&#228;t M&#252;nchen, M&#252;nchen, Germany", "person_id": "P2509571", "email_address": "seidl@in.tum.de", "orcid_id": ""}, {"name": "Vesal Vojdani", "author_profile_id": "81442619799", "affiliation": "Technische Universit&#228;t M&#252;nchen, M&#252;nchen, Germany", "person_id": "P2509572", "email_address": "vojdanig@in.tum.de", "orcid_id": ""}, {"name": "Peter Lammich", "author_profile_id": "81384609404", "affiliation": "Westf&#228;lische Wilhelms-Universit&#228;t M&#252;nster, M&#252;nster, Germany", "person_id": "P2509573", "email_address": "peter.lammich@uni-muenster.de", "orcid_id": ""}, {"name": "Markus M&#252;ller-Olm", "author_profile_id": "81100259808", "affiliation": "Westf&#228;lische Wilhelms-Universit&#228;t M&#252;nster, M&#252;nster, Germany", "person_id": "P2509574", "email_address": "markus.mueller-olm@uni-muenster.de", "orcid_id": ""}], "doi_number": "10.1145/1926385.1926398", "year": "2011", "article_id": "1926398", "conference": "POPL", "title": "Static analysis of interrupt-driven programs synchronized via the priority ceiling protocol", "url": "http://dl.acm.org/citation.cfm?id=1926398"}