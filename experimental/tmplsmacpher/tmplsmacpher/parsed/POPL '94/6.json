{"article_publication_date": "02-01-1994", "fulltext": "\n Portable, Unobtrusive Garbage Collection for Multiprocessor Systems Damien Doligez Georges Gonthier* \nEcole Normale Sup6rieure INRIA Rocquencourt INRIA Rocquencourt 78153 LE CHESNAY CEDEX Ecole Polytechnique \nFRANCE Damien. Doligez@inria. f r Georges. Gonthier@inria. fr Abstract Redescribe and prove the correctness \nof anew concurrent mark-and-sweep garbage collection algorithm. This algo\u00adrithm derives horn the classical \non-the-fly algorithm from Dijkstra et al. [9]. A distinguishing feature of our algo\u00adrithm is that it \nsupports multiprocessor environments where the registers of running processes are not readily accessible, \nwithout imposing any overhead on the elementary oper~ tions of loading a register or reading or initializing \na field. Furthermore our collector never blocks running mutator pro\u00adcesses except possibly on requests \nfor free memory; in par\u00adticular, updating a field or creating or marking or sweeping a heap object does \nnot involve system-dependent synchro\u00adnization primitives such as locks. We also provide support for process \ncreation and deletion, rmd for managing an ex\u00adtensible heap of variable-sized objects. Introduction Concurrent \ngarbage collection has a well-deserved reputa\u00adtion for being a tough problem. This is evidenced by the \ndiscrepancies between the state of theory and practice in this area. As we shall see below, the published \nproven al\u00adgorithms often contain simpli&#38;ing assumptions that cannot be met in practice in a multiprocessor \nsystem, because this would either impose unbearable overhead on the mut ator processes, or require a \ndegree of hardware and/or operating system support that compromises portabiMy. Implemented systems that \ndo not fall in the latter two categories often rely on incompletely formalized algorithms, which generally \nmeans buggy algorithms, given the subtleness of the correct\u00adness proofs. To our knowledge, and as we \nshall argue below, all pub\u00adlished concurrent collectors fall in one of the above cate\u00adgories, and thus \nfail to meet at least one of the basic re\u00adquirements for portable, effective garbage collection on mul\u00adtiprocessors. \nIn fact the only proposal that even attempts to meet these requirements is the Doligez-Leroy hybrid collec\u00adtor \n[10]. Unfortunately, the algorithm they proposed was in\u00ad *This work was psrtly funded by the ESPRIT \nBasic Research Ac\u00adtion No. 6454 (Project CONFER) Permission to copy without fee all or pert of this material \nis granted provided that the copies ere not made or distributed for direct commercial edvantage, the \nACM copyright notice end the title of the publication end its dete appear, and notica is givan that copying \nis by permission of the Association for Computing Machinery. To copy otherwise, or to republish, requires \na fea 8nd/or epecific permission. POPL 94-1/94, Portland Oregon, USA @ 1994 ACM 0-s9791636-9/94/001 ..$3.50 \ncompletely specified and, perhaps not unexpectedly, buggy. In this paper, we redress this state of ai%irs \nby fully describ\u00ading and proving a concurrent garbage collection algorithm that meets the requirements \nfor the Doligez-Leroy collector architecture. This turns out to be much more intricate than the simple \nadaptation of the concurrent mark-and-sweep al\u00adgorithm [9] outlined in [10]. We still expect the experimental \nresults of [10] to hold for our model, because a slightly mod\u00adified (debugged) version of their algorithm \nfits in our model. In the next section we spell out the basic portability and efficiency requirements \nfor a collector for multiprocessors. We show why previous algorithms fail at lezat one these re\u00adquirements, \nand how these requirements coincide with those of the Doligez-Leroy architecture. In section 3 we describe \nthe basic algorithm of [9], and expose a series of counterex\u00adamples to explain why a straightforward \nadaptation of this algorithm to multiple mutators would not work; we aleo ad\u00address some efficiency issues. \nIn section 4 we describe the basic procedures of our algorithm. In section 5 we describe the extensions \nto handle process and heap management. Fi\u00adnally, in section 6 we present a sketch of the correctness \nproof of the algorithm. This proof is baaed on a formzd model of the algorithm, expressed in a Unity/TLA-like \nformat; this model, listed in the appendix, also covers the extensions to the basic algorithm. 2 The \nrequirements Our basic requirements are essentially shaped by the follow\u00ading tfacts of life about multiprocessors: \n1 Registers are local. Even on a uniprocessor, it can be hard to track the machine registers of a running \nprocess. On a multiprocessor this is next to impossi\u00adble; furthermore this impossibility extends to the \nlocal memory of each processor. 2 Synchronization is expensive. Of course any mul\u00adtiprocessor system \nwill provide semaphores aud other synchronization devices, but often these will only be available through \nexpensive system calls. Thus a por\u00adtable collector should use as little synchronization as possible. \n3 Resources are not bounded. It is unreasonable to forbid system calls to grow the heap. And just as \nun\u00adreasonable to make the liveness of the collector depend on exhaustion of the system memory. 70 2.1 \nActions and overhead times: it can restrict cooperation to well-defined points in its Let us classify \nthe various actions that can be taken by a mutator thread: a) move data (including heap pointers) between \nreg\u00ad isters and/or local memory b) load a field in a register (dereference a heap pointer) c) reserve \nfree memory for future new heap objects d) create a heap object in previously reserved memory e) fill \na field in a new heap object ~) update a field in an existing heap object g) cooperate with the collector \n(see below) h) mark heap objects referenced by registers and local memory (this is a special caae of \ng) We breakup the usual allocate a heap object action into separate c (reserve), d (create), and e (fill) \nactions, The c actions are a necessary evik the c actions of all active mutator threads all contend for \nthe free memory provided either by the collector or the system. Hence c actions must call on synchronization \nprimitives, which may be expensive (fact 2). Having separate d and c actions allows us to amor\u00adtize the \nsynchronization overhead by keeping local pools for each thread, and batching operations on the free \nlist. The e (fill) and f (update) action types correspond to the same physical operation a store in the \nheap. We dis\u00adtinguish them because they have different frequencies and prewnditions. In a e action the \nmodified heap object is still private to the mutator thread, while in an f action it may shared with \nother threads. Hence f actions are haxder to implement, so it is fortunate that in practice they are \nnot very frequent: having an efficient garbage collector encour\u00adages the creation of new objects to hold \nnew results, rather than the hazardous reuse of temporaries. The g and h actions (cooperate and mark) \nare m un\u00adavoidable consequence of fact 1. Obviously, a reasonable algorithm should ensure that they do \nnot dismpt the muta\u00adtor threads signticantly. Let us say a garbage collection algorithm is unobtrusive \nif it meets the following conditions: (i) It adds no overhead to the very frequent mutator ac\u00adtions of \ntype a, b, and e. (ii) It only imposes synchronization overhead on type c mutator actions, for which \nit is unavoidable.  (iii) Mutator actions of type g and h are executed only at a mutator thread s convenience. \n(iv) For any mutator, the total overhead of g and h actions for a full collection cycle is bounded, a \nlid collection cycle being the period that ends when the collector has reclaimed all currently unused \nheap objects. (v) Full collection cycles always terminate, regardless of increases in the heap size \nor the number of processes.  Requirement (i) is a basic efficiency constraint. Any useful overhead has \nto include at least one heap reference, which would take as much time as a load or fill action, and pos\u00adsibly \ntwenty times as much as a move action. Require ment (ii) is a direct consequence of fact 2: less i%equent \nactions of type d, ~, g, or h can incur moderate overhead, but by fact 2 synchronization cannot be considered \nmod\u00aderate overhead . Requirement (iii) means a mutator does not have to be ready to cooperate with the \ncollector at all code. As a consequence, transient states are allowed in the mutators, which is required \nby efficient code. Another con\u00ad sequence is that real-time garbage collection becomes possi\u00ad ble: a mutator \nmay exclude cooperation overhead for some time-criticzl part of its code. Requirement (iv) bounds the \namount of cooperate and mark overhead a mut ator must incur before getting any significant payback from \nthe collec\u00ad tor. Requirement (v) simply takes &#38;t 3 into account. Put all together, requirements (i) \n(v) state that the per\u00ad formance of the concurrent collection cdgonthm should be roughly comparable to \nthat of a sequential collector, but without the disrupting pauses (requirements (iii) and (iv)). On the \nother hand, we limit ourselves to rather weak ef\u00adficiency requirements on the collector. The basic collector \nactions of marking, unmarking, or reclaiming a heap ob\u00adject should not require synchronization; the totaJ \namount of collector work for a full cycle should be proportional to the maximal heap size and the total \nnumber of processes, at least in absence of the (presumed infrequent) update actions. Stronger requirements \n(e.g., removing the provi\u00adsion for update actions) would imply additional mut ator overhead that is not \njustified in practim, as the collector is rarely the bottleneck, especially in the setting of [10] (which \nwe outline in subsection 2.3.) Also, allocating more mem\u00adory will compensate for a slower algorithm, \nup to a certain point [13]. As a hat resort, parallelizing the collector is also an option [15, 19]. \n 2.2 Where all else fails As elementary as constraints (i v) seem to be, they all but rule out copying \ngarbage collection algorithms that relocate objects in order to eventually reclaim entire areas at once. \nBy fact 1, the collector cannot update the local memory of running processes to reflect the relocation, \nso it must arrange for the processes to do this updating on their own. The known schemes for doing this \ninvariably break at Iezst one of (i) (iii). Doing a test [3] or a second indirection [6, 20] for each \nheap awoess obviously breaks (i) for load actions. Using virtual memory page protections to bypaas the \ntest [2] breaks (ii) and (iii): mutators incur the possibly high page fault overhead at rrmdom times. \nSome promising systems were recently proposed for in\u00adcremental and concurrent copying collection [5, \n18]; however they require a global rendez-vous of all the mutators in each collection cycle, breaking \neither (ii) or (iii), So it seems we must give up relocation to get an un\u00adobtrusive concurrent collector, \nwhich leaves us with mark\u00adand-sweep algorithms. Unfortunately, the baaic on-th~fly mark-and-sweep algorithm \n[9] does not account for fact l it assumes that the local pointers of a thread only point to otherwise \naccessible objects. This could only be enforced by imposing overhead on move actions [12], and thus break\u00ading \n(i). All the derivatives of [9] sufler this fatal flaw [4, 14]. Ftmthermore these algorithms only support \na single mutatoq the multiple mutator version [15] explicitly requires synchro\u00adnization overhead, breaking \n(ii).  2.3 The Doligez-Leroy design It may seem a pity that we had to rule out the copying al\u00adgorithms, \nas only they can deal with the large amount of short-term garbage generated by functional languages such \nss ML [1]. As was shown in [10], this dilemma can be solved ,  Stds , Minor heaps , Major heap Figure \n1: The Doligez-Leroy architecture by organizing the local memory of each processor into a stack and \nheap (Figure 1), and running a stop-and-copy collector locally to do generation scavenging. This stop-and-copy \ncol-Iector does not break requirement (ii) because it only stops the local thread. Copying is especially \nadapted to the young generation because most of the young objects are garbage, and a copying collector \nworks best in that case. Thus most of the garbage is reclaimed by the mutator threads themselves and \nthe major collector is only concerned with long-lived and mutable objects. With this architecture the \npreviously overlooked fact 1 becomes glaringly obvious: clearly the global collector can\u00adnot trace the \nlocal heap without the cooperation of the mu\u00adtator thread. In a highly portable system such as Caml-Light \n[17], fact 2 is a matter of course. So [10] had implic\u00aditly laid out requirements (i) (iv) for their \nglobal collector. They only missed on requirement (v) and, as we will see below, on some subtle implications \nof requirements (i)-(iv). 3 The basic algorithm and its shortcomings In this section, we expose the Dijkstra \net al. algorithm [9] (hereafter called the basic algorithm ) ad a series of coun\u00adterexamples that show \nwhy a straightforward adaptation to multiple mut ators cannot work, and we describe some effi\u00adciency \nproblems of this algorithm. 3.1 The basic algorithm First we describe the heap data structure, then \nthe operw tions of the collector and mutators. The heap fixed number is a fixed of fields. array of \nobjects, each of which has a const type ~ End, MaxIndex E NAT ADDR z {O,..., End 1} INDEX e {O,..., \nMaxIndex} hmp ~ array [ADDR, INDEX~ of OBJECT There is a fixed set of globally accessible locations. \nOne of them is the head of the free list, which uses the usual linked list implementation. const Globals \nE set of ADDR The tracing status of heap objects is modeled by a separate W1OT array. Mark: foreach \nx E Globals do MarkGray(x) Scan: repeat dirty + false foreach x E ADDR do if wlor [z] = Gray then dirty \n+ true foreach i E INDEX do MarkGmy(heap[x, i]) wlor [z] + Black until -I dirty SwesptYOlear: foreach \nx E ADDR do if wlor[x] = White then append x to the free list else if wlor[z] = Black then color[z] + \nWhite Figure 2: The basic collector type COLOR R { White, Gmy, Black} Var w lor ~ array [ADDR] of COLOR \ninit Vx c ADDR, wlor[z] = White White objects are unmarked. Their reachability status is un\u00adknown. Black \nobjects are traced. They are marked (reach\u00adable) and their sons are marked. Gmy objects are marked but \ntheir sons have not been marked yet. Because the free list head is one of the globally accessi\u00adble values, \nthe free list is traced by the garbage collector, and allocation is a special case of assignment. In \nfact, fill, reserve, create, and update operations are ZJ instances of a generic store operation, implemented \nas follows: MarkGmy(z) s if color [x] = White then color [z] i-Gray Store(z, i, y) ~ heap[s, i] + y MarkGmy \n(y) The collector cycle is divided in four steps (Figure 2): Mark: Mark objects referenced by global \nvariables. Scan: Scan the heap for maxked ( Gmy) objects, and trace them by marking their sons and Blackening \nthem. Re\u00adpeat the scan as needed to ensure all reachable objects are marked and traced. Sweep: Reclaim \nall white objects. Clear: Unmark all marked objects, establishing the precon\u00additions of the next collector \ncycle. The two invariants used in [9] to prove this algorithm are: o During the Scan step, every White \nreachable ob\u00adject is reachable from a Gmy object. At the beginning of the Sweep step, there is no ~my \nobject. From these invariants, one can deduce that all reachable ob\u00adjects must be Black at the beginning \nof the Sweep step. The second invariaut is easy to prove, assuming that MarkGmy is atomic. For the first \ninvaxiant, one proves that at most one Black-to-White pointer exists: the pointer horn x to y when the \nmut ator is between the two lines of Store.  > .\\ -o = Figure 3: If we don% mark the old value... \n The algorithm still works when MarkGmy is not atomic, but the proof is more complex. The detailed proofs \ncam be found in [9]. This algorithm is subject to floating garbage, i.e. garbage created during a collector \ncycle, which will not be reclaimed by this cycle, but by the next one. This means that a full collection \ncycle is composed of two collector cycles, 3.2 Local memory The baeic algorithm fails to take fact 1 \ninto account: the mutator must make sure that its local variables only point to objects that axe already \nreachable horn Globals. Not only does this mean that all the temporary variables of each mut ator must \nremain visible to the collector at all times, but also that all assignments to these temporary variables \nincur the overhead of MarkGmy; thus the basic algorithm i%ils our requirement (i). To correct this problem, \nwe decided that the local vari\u00adables (the roots) of the mutators are hidden to the collector and we added, \nas in [10], a hrmdshake between the collector and each mutator. The Mark step of the collector becomes: \nMark: foreach x E Globab do MarkGmy(x) issue a call for roots wait until all the mutators have answered \nAnd the mutators must execute the Coopemte procedure from time to time: C oopemte z if a call for roots \nis pending then call Mark Gray on all the roots answer the cdl This constraint seems to preclude calls \nto foreign functions, which will not call Coopemte; the implementation solves this problem by adding \na wrapper i-mound such functions. The wrapper synchronizes with the collector and delegates the cooperation \nwork to the collector thread itself. The syn\u00adchronization is only needed for long-running functions, \nso its overhead is negligible compared to the running time of the function. In this new setting, as stated \nin [10], we have to mark the old value of a field before the update, or the collector could reclaim objects \nthat are still in use. This is illustrated by the following counterexaruple with a single mutator A (Figure \n3): C calls for the roots A grays its only root, R answers to the call loads the value () of field O \nof R in a register sets field O of R to nil C notices that all mutators have answered blackens R, which \ncompletes the Mark step reclaims 0, which is still in use by A Figure 4: If we don t pause before marking. \n. . Marking the old value was am option in the basic algorithm; it was rejected early on, because it \nobviously generated more floating garbage [9]. However it has also been noted that most of the garbage \nis floating anyway [21]. This holds even if the garbage were generated randomly, whereas in practice \nmost of the garbage consists of recently allocated objects, which are always marked in the basic algorithm. \nHence controlling the allocation color to prevent almost all floating garbage in the Sweep and Clear \nsteps is more likely to reduce floating garbage effectively. 3.3 Multiple mutators While [10] concluded \ncorrectly that old values have to be marked, they missed an important point: with multiple mu\u00adtators, \nit is impossible to get the value of the old object reliably! To do so would require at least an atomic \ncom\u00adpare&#38;swap [11] and thus violate (ii). The Store operation of [10] was: Store(z, i, g) \u00adMarkGmy(heap[z, \ni]) heap[z, i] t-y MarkGmy(y) This does not work because the assignment is not guaran\u00adteed to overwrite \nthe value that was just shaded, as demon\u00adstrated by this counterexample with A,B (Figure 4): C calls \nfor the roots A grays its only root l answers the call loads field O of R (()) grays Q in preparation \nto a Store into field O of El Bgrays Cl anA answers the call grays (J, which is already gray sets field \nO of R to A grays A clears the register pointing to A C blackens zdl objects, completing the Scan step \nperforms its Sweep step (whitens all objects) starts a new cycle by calling for the roots B grays its \nonly root, R answers the call reloads field O of R (A) A resumes its Store by setting field O of R to \nnil grays its roots O and R (cI is already gray) amwers the call C blackens R and 0, completing its Scan \nstep reclaims A, which is still in use by B To sum up, first B lays a trap for A by putting a white \nobject in field O of 0, then A trips the trap by overwriting that field. Our algorithm uses a second \nhandshake before the call for roots to ensures that all traps laid during the Sweep step are tripped \nbefore the Mat-k step begins. We have two other counterexamples (only one of which appears in [10]) that \nshow the existence of a trade-off be\u00adtween: 1. addiu~ a third handshake 2. alway~ marking the new value \n  3. adding some overhead to Store We chose 1 over 2 to avoid the creation of floating garbage during \nthe Sweep step, and over 3 because the collector is not the bottleneck, and because 1 enables us to concentrate \nall the overhead of Store before the actual assignment. 3.4 Scan termination There is one obvious efficiency \nproblem with the bazic algo\u00adrithm: it scans the heap many times to find Gmy objects during the Scan phase. \nThe worst case is even quadratic in the heap size, and it is easily attainable with a list whose cells \nare in decreasing order, a common case when allocation is in increasing order. Since most of these Gmy \nobjects were marked by the collector itself, it is easy to add a cache of Gmy objects to the collector, \nAs long as this cache is not empty, the collector does not need to scan the heap to find Gmy objects. \nA further improvement is to turn dirty into a global variable and have the mutators set it when they \nmark an object. This only avoids the last scan, but in practice we only have one or two scans most of \nthe time, so saving one scan is a big win. Kung and Song [14] use a double-ended queue to avoid the scans \ncompletely, but their solution does not work with multiple mut ators without synchronization on update \nop\u00aderations. All the other proved algorithms use repeated scans of the heap. In the design of [14], objects \nare marked Gmy as they are inserted in the queue, which plays the same role as our cache. This policy \ndoes not work in our case, as the following counterexample shows (Figure 5): The last three objects in \nthe heap are A, 0, and R; field Oof O is A and field Oof R is 0; R is gray while A and O are white, and \nthe collector scan has reached R while dirty is still false and the cache is empty. The following can \noccur: A loads field O of R (Cl) .-, grays O (first step of an assignment to field O of R) C blackens \nR, w its only field is already gray . . . thus completing the Scan step A sets dirty + true (too late!) \nsets field O of El to nil loads field O of O (A) C reclaims A, which is still used by A Note that it \ndoes not help if A sets dirty + true before marking, as C can reset dirty and repeat the scan at any \ntime. Hence C must add any gray object it encounters to the cache, and thus mark them Black to avoid \nduplicates. Fur\u00adthermore, if C removes objects from an overflowing cache, it must reset their color to \nGmy. (This implies that mut ators should never write back the color of a Black object, which prohibits \nlogical or implementations of MarkGray.) We have a two-mutator version of this example to show that mutators \nmust set dirty +-true even when the old value is already gray. This compels us to make z a global variables, \nand make the mut ators test the position of the gray object compared to z before they change dirty, so \nthat  4+-% E d Figure 5: If we don t trace gray objects... repeated assignments of the same values do \nnot cause a spu\u00adrious scan of the entire heap (or even prevent termination of the Scan step). 4 Our \nalgorithm In this section we will describe the algorithm in the simple case where the sizes of the heap, \nthe objects, and the set of mutators are all constant. We delay the discussion of heap extension and \nrequirement (v) to section 5, as well as the discussion of variable-sized objects. We divide the description \nof our algorithm as follows: first the heap model and the description and evolution of the global variables, \nthen the mutator primitives and finally the collector code. 4.1 The heap and global variables We will \nreuse most of the heap model of the basic algorithm, with a number of additions and changes. First of \nall, there is a fixed set of processes: const MazPid E NAT type PID = {O,..., MaxPid} Unlike the basic \nalgorithm, we abstract from the represen\u00adtation of the free memory list, using a multiset rather than \na set so that we can prove there are no double insertions. The initial live data must not point to the \nfree list. var free c multiset of ADDR init Globals (Tfree = O Vx E ADDR \\ free Vi E INDEX, heap[z, i] \nG ADDR \\ f?ee We will use a fourth color, Blue, to indicate free locations where a heap object may be \ncreated. The corresponding areaa are ignored by the collector. All locations in fie must be Blue, but \nthe converse is not always true, as processes may withhold some free memory. type COLOR = { White, Gmy, \nBlack, Bluej Blue if z cJ%X init Vx c ADDR, color [x] = white *therwie { The collector cycle is still \ndivided in the same four steps: Mark, Scan, Sweep, and Clew. All the complex handshake synchronization \ntakes plsce during the Mark and Clear steps, although these steps were rather trivial in the bssic algorithm. \nThe collector keeps step Clear ~ Mark ~ scan ~ Sweep -tClear\u00ad1 phase Async + Sync ~ ~ Sync ~ t  @nc \n t II ............. ... ... ....... ... ... ... ... ... r.... ... ... ... . status~ 1.-..... ......1.......--.1 \n---- I III 1..... .....4-..........1.. ..... statusm ......... .....  (     {    [ marking \n~m I I I ........  swept ~oc.adoncohm B[;k @~ r White I ........1.........  1 ... .. I 1   II scanned \n I . . . . . . . . . . ... . . . . . . . . ..... .. ..... .........  I . . . . . . . . . . . . . ---------------------,_ \n..------p...... dirty 1--; I Figure6: Timing diagram for global variables sync ~ sync 1 A3ync sync ~ \nsync 1 Async +00 End o End 0 -w track of the handshake status in a phase variable, whose values after \nthe first, second, and third handshake are, re\u00adspectively, Sgncl indicating thatmutators willonly update \nfields with pointers to objects that will bemarked in this cycle. Syncz indicating thatmutators willonly \nupdate fields that point to objects that will bemarked in this cycle. Async indicating that all mutators \nhave marked the ob\u00adjects referenced by their registers at one point in this cycle, whence no reachable \nobject will be reclaimed during this cycle. We will have phase = Async at the beginning of the next cycle. \nAs illustrated in Figure 6, the Clear wd Mark steps end with the first and third handshakes, respectively; \nin practice these steps are quite short, hence most of the time we have phase = Async. The collector \nand all the mutators use a global status variable to implement the handshakes: type STATUS = {A sync, \nSyncl, Sync2 } var status c = Async E STATUS Vm E PID, var status~ = A sync E STATUS At rest all statuses \nequal phase. The collector initiates a handshake by advancing statuso, the mutators respond by following \nsuit, and finally the collector moves phase when all have responded. The first two handshakes require \nno other action from the collectors than completing pending actions (especially update); before competing \nthe third handshake mutators must mark all the objects they refer\u00adence (Figure 6). The collector must \nperform a polling loop to complete the hmdshake. Fortunately, the collector need not be idle during that \nperiod for the last two handshakes, as it haa other marking or tracing work to perform, and the first \nhandshake is likely to be extremely brief, as it requires al\u00admost no work from the mutators. Finally, \nthree globaJ variables are used to implement the efficiency refinements described in subsections 3.2 \nand 3.4. var swept = +00 E ADDR ~ {-m, +m} tracks the progress of the Sweep step, and is set to co and \n-co before and after the Sweep step, respectively. Mu\u00adtators test swept in create and update actions \nto avoid generating floating garbage during the Sweep step. var dirty G BOOL is used to ensure that the \nScan step only terminates when all reachable objects have been masked. It is set to false by the collector \neach time it starts a new scan, and reset to true by a mutator that detects the scam hae missed a gray \nobject, forcing the collector to repeat the scan. var warmed = 00 E ADDR &#38; { m} tracks the progress \nof the Ssan step, and is reset to m between scans. Mutators test scanned before resetting dirty to avoid \ncausing spurious scam. 4.2 The mutator actions The only local variables of a mutator are its multiset \nof heap pointers, and free memory pool. const MaxPool >0 ~ NAT var pool = k?E multiset of ADDR nlo ts \nG multiaet of ADDR init raots~free=fl There are two mutator marking actions. Mark Gray is used before \nthe Scan step, otherwise MarkAnd Warn is used to ensure that a concurrent scan does not miss the marked \nobject (more precisely, to ensure that the collector traces the object at least once during the Scan \nstep). MarkGray(z) \u00adif color [z] = White then color[z] + Gray MarkAnd Warn(z) s if CO1OT[Z]# Black then \nMarkGray(z) if x < scanned then dirty * true The code for mutator m should execute the Coopemte pro\u00adcedure \nat reasonably close intervals; the overhead is minimal except for the root marking that occurs once per \ncycle. We could also allow the mutator to relocate a pointer in a new heap object and mark this object \nrather thaa the one refer\u00adenced by the pointer, i.e., the marking can be performed by a local copying \ncollection cycle as in [10]. Coopemte = if status~ # status c then if status ~ = Sync2 then foreach x \nc roots do MarkGmy(x) status ~ 4-status G Memory reservation is the only action requiring a critical \nsection, introduced here by the await. . . do. . . construct. The pick x &#38; S wnstruct chooses and \nremoves one copy of a random element z ~ S. Reserve = await he # 0do repeat pick z c j%ee do pool t pool \n@ {z} until free = 0 v Ipooll = MaxPool The Create procedure chooses the color of the new object baaed \non the progress of the cycle to minimize floating gar\u00adbage. The race with the Sweep step is resolved \nwith the Gmy color; we could also defer the decision to the next allocation or handshake, Note how the \nsentinel values of swept simplify the logic. Create = pick x c pool do caior[z] + Black if status~ # \nAsync V x < swept then color [z] 4-White else if z = swept then color [z] +-Gmy ret urn z Although there \nis no overhead on the fill operation, the mu\u00adtator must completely fill the fields of an object before \nmark\u00ading or using the object, and in any case before marking its roots. Although the Update operation \ncarries the most over\u00adhead, it all occurs up front, before the store proper. The proof shows that during \nthe A sync phase, the marking over\u00adhesd effectively cuts out the field from the collector s tracing space. \nHence a mutator repeatedly modifying the same field only needs to incur the update once per collector \ncycle. Update (z, i, y) z if status~ # Async then MarkGmy (heap [z, i]) MarkGmy(y) else if swept = -m \nthen MarkAnd Warn (heap [x, i]) heap[z, i] + y  4.3 The collector We assume the size of the collector \ncache is bounded. const MaxCache> O c NAT Var cache = 0 E multiset of ADDR phase = Async E STATUS 1%.zceis \njust the standard Black tracing procedure, with the recursion stack made explicit by cache, and with \novertlow handled by the Gmy color. The comparison with scanned is tighter than in MarkAnd Warn, because \ntracing is not con\u00adcurrent with scanning. Zkace(s) = MarkBlack(z) while cache # 0 do pick y c cache do \nforeach i c INDEX do MarkBlack(heap[y, i]) MarkBlack(z) \u00ad if color[x] # Black then if Icachel < MaxCache \nthen color [z] + Black cache + cache @ {z} else color [z] + Gmy if x < scanned then dirty + true Because \nhandshakes are completely asynchronous for the mutators, they require some waiting on the part of collector. \nApart from access to the bee list, handshakes are the only synchronization overhead on the collector. \nHandshake(s) = datw c* 8 foreach m E PID do await status ~ # phase do skip phase + s The collector cycle \n(Figure 7) is a straightforward implemen\u00adtation of the diagrams of Figure 6. Note that both scanntxi \nand swept always point at the object under scrutiny or just before it. sweeps-bottom-up--but does not \notherwise affect the al- Clear: Handshake (Syncl) gorithm. Mark: swept + -m There is a mild clash between \nthis header convention cobegin and the system allocation conventions, which usually grow Handshake (Syncz) \n memory horn the top up. This cam be solved by setting a top Handshake (A sync) limit at the beginning \nof the Scan step. Since swept = 00 and at that time, only floating garbage can be created above foreach \nx c Globals do 7kace(x) limit. The Clear step must then start by unrnarking all Scan: repeat objects \ncreated above limit during the previous Scan and dirty e fake Sweep steps. scanned * O Block splitting \n(using only part of a bee memory block to while scanned < End do crest e an object) is delicate because \nit interferes with the if color[scanned] = Grey then comparisons with swept; the correct solution is \nto create !i%uce(scanned) the object at the top of the block, and to do the equality scanned + scanned \n+ 1 test with the block pointer rather than the object pointer. scanned 4- w Finally, the collector \nshould be able to merge adjacent until not dirty free blocks. In a sequential system this is done by \nrebuilding Sweep: swept t O the free list during the Sweep step. Doing this in a concur\u00ad while swept \n< End do rent system creates contention with the mutators, which can if wlor[swept] c {Black, Gmy} then \n be reduced by letting the collector reclaim large segments of wlor[swept] t White the free list for \nrebuilding. Since those segments must be else if cdor[swept] = White then white, we have the option \nof keeping the free list in white, coior[x] + Blue and marking the free objects blue when they are reserved \nawait true do jhe + &#38; @ {z} by a mutator. swept 4-swept + 1 swept t +03 Figure 7: The collector \ncycle 5 Extensions In this section, we describe how our algorithm can be ex\u00adtended to deal with more \nrealistic heap and process man\u00adagement. These extensions are absolutely needed for a use\u00adful implementation, \nand they interfere in non-trivial ways with correctness proofs. The model in the appendix and the proof \ncover all extensions discussed here, 5.1 Process management Because the collector must wait on all threads \nto complete a handshake, managing process creation and termination mainly poses liveness problems. We \nmust make sure that the collector only has to wait on a finite number of pro\u00adcesses to complete a cycle, \nby imposing that mutators call Cooperate before they launch a new process for the first time and always \ngive their own status to new processes: processes with the %vrong status will not beget offspring until \nthey answer the collector. We must also ensure that the collector only tests a finite number of processes. \nWe can do this by maintaining a list of active processes. The contention for the list can be resolved \nby using double indirection (handles) for each link, each pro\u00adcess inserting its recent offspring after \nitself on each status change, and letting the collector remove dead processes. 5.2 Heap management Realistic \nheap management involves dealing with variable\u00adsized objects, system allocation, and fragmentation. We \nstick to the traditional implementation of variable\u00adsized object, a header word containing the object \nsize and color followed by the pointer fields, in order not to inter\u00adfere with debugging. This ties the \ndirection of scans and 6 The proof A proof of a garbage collection algorithm is never a proof of an actual \nimplementation of that algorithm; it is a proof of some mathematical model that conveys the essential \nideaa of the algorithm. More often this model is chosen in order to make the proof as short and elegant \nas possible [9, 4, 7], so it is very high-level and abstract. This yields elegant papers, but also carries \na price: it is not clear how to fit the vast amount of details of an actual implementation in the small, \ncleverly crafted invariant of the published proof. This is somewhat unsettling for an asynchronous shared\u00admemory \ngarbage collector, where intricate synchronization problems invariably creep in the implementation of \nhigh\u00adlevel concepts. We purport to provide a proof that does provide for all the details of an actual \nimplementation, including all the ex\u00adtensions discussed above, but that remains abstract enough to be \ntractable. The key step here is the choice of the model. By giving dataflow description of the algorithm \nwe make the communication pattern between the vaxious internal states explicit. Writing down the safety \ninvariants-the most crit\u00adical part of a garbage collection algorithm proof then be\u00adcomes a simple, if \ntedious, matter of combining and relating the values of the various variables. During the course of this \nwork most of the problems with the algorithm were identified during the construction of the mode~ only \na few more appeared during the safety proof. The Iiveness proof is straightforward. 6.1 The model The \nmathematical model on which this proof is baaed is listed in Appendix A. The formalism we chose is a \ncross be\u00adtween algol, UNITY [7], and TLA [16]. Superficially our format resembles most UNITY: a set of \nconcurrent atomic assignments, with only weak fairness constraints. The code of the individual atomic \neasignments uses an algo]-like syn\u00adtax. (1) step c STEP A phase c {Async, Syncl, Syncz} (2) status c \n= phase = A sync  v (statusc = Async A phase = Syncz A step = Mark) v (statwC = Syncl A phase # Syncz \nA step = ~ear) V (statusc = Syncz A phase # Async A step = Mark) (3) Vm, status~ c {statusc, pha.se, \nDead, l+ee, Quick} (4) Vm, answering + status~ = phase # statusc (5) Vm, marking~ * statusm = Syncz \n# status c (6) Vm, statusm c {Dead, I+ee, Quick} * pc~ = Halt (7) {P] statwp = Quick} = ~~{child~ I \npc~ = Launch}  Figure 8: Handshake invariants Mathematically, however, our formalism is really sug\u00adared \nTLA, because this offers the best approach to proving independently that implementations of the coflector \nor pro\u00adcesses mat ch the model. From TLA we inherit the local variables of subprocesses amd the selective \nuse of fairness constraints--only statements cent aining a ~ are subject to a weak fairness constraint.1 \nWe express the algorithm in a datafiow rather than an imperative style, in keeping with the TLA view \nthat the eaaiest thing to abstract away from in a program is the pro\u00adgramming language syntax. Instead \nof having a single im\u00adperative variable z whose exact meaning at any given time depends on a PC variable \nthat could take several dozen val\u00adues, we use a handful of dataflow variables, each of which holds the \nset of values of x at a given processing state. We can use a single set to factor away common processing, \nmuch like we use procedures in an imperative setting for example the mark variable of the mutator model \ncorresponds to the MarkGray procedure. This datafiow style allows us to considerably reduce the number \nof PC values. For example the collector is almost completely parallelized; only the four steps remain. \nBesides the obvious gain in compactness, this also makes our model more general, indicating how the collector \ncould be paral\u00adlelized. In fact we have attempted to make the model as general as possible, e.g., we \nuse a rover pointer to allow the coflector to start tracing any Gmy object at any time. We take a rather \nhigh-level view of the free list mange\u00adment. Operations on the free list are viewed simply as atomic \nmultiset operations; their implementation on terms of semaphores and linked list operation is standard \nand does not interfere with the rest of the algorithm. We model the free list with two sets, j%ee and \nallot, of White and Blue objects, respectively. The memory action that transfers objects born free to \nallot can be assigned either to the col\u00adlector, for a Blue flee list, or to the mutators, for a White \nlist, as hinted in section 5. We are even more cavalier with process management. The process list is \nimplicit; two extra values, fie and Quick, indicate processes not on the list. While the implementation \noutlined in section 5 is a little tricky, it does not interact 1Free variables in an action are implicitly \nquant ified existentially in the action, so for example the collector action with precondition z c cache \nmust eventually be performed if cache b not empty infinitely often. (8) step E {Sweep, Clear} + whiten@ \nclaim g [0, ptr) (9) step = Sweep A ptr < limit 3 swept ~ ptr (10) step # Sweep * swept ~ { m, +00} \n (11) step = Cleur A phase = Async * swept= +ec (12) step = Clear A statusc # Async %-ptr = limit (13) \nstep = Clear A statusc # Async * whiten= 0 (14) step c {Mark, Scan} * whitera = claim = 0 (15) step \n= Mark A statusc = Async ~ swept = -w (16) step = Scan * swept = co (17) step = Scan +-scanned ~ ptr \nA scanned < limit (18) step = Scan A reset A scanned= cc ~ ptr = limit (19) step # Scan * reset (20) \nstep ~ {Sweep, Clear} * blacken= trace= fl (21) step 6 {Sweep, Clear} * cache= fields= 0 (22) step \n~ {Sweep, Clear} * rover= O  Figure 9: Collector invariants with the rest of the algorithm, so there \nis little point in introducing more detail. On the other hand, we have a detailed model of the heap layout, \nbecause the fragmentation procedures interfere quite subtly with the Sweep step. Each heap location contains \neither a pointer or an object header containing its size and color; objects start with a header and are \nadjacent in the heap. All actions in our model, except free list and process memagement actions, are \nasynchronous in the sense that they make at most one read or write on a global variable or heap location, \nif one discounts reads of variables that are read-only for all other processes, such as swept for the \ncol\u00adlector, processm for a running mutator m, or the size of a non-garbage object. Compliance with the \nlatter constraint has introduced a few bumps and twists in the model. For example the col\u00adlector uses \nan explicit register ptr to sweep the memory. However it is straightforward to show that the resulting \nbe\u00adhavior still conforms to the timing diagrams of Figure 6. Global invariant (l 7) (Figure 8) show that \nthe handshakes go through, and invariants (8-22) (Figure 9), which are lo\u00adcal to the collector, fill \nin the rest of the picture. Three not ation details: m always ranges over PID, local mut > tor variables \nare subscripted (e.g., markingm), and sets are considered a special caae of multisets, so (7) asserts \nthat {{child~} I PCm = Launch} is a partition of the set of Quick processes.  6.2 Safety Safety for \na garbage collector generally reduces to the col\u00adlector does not free reachable objects . Here, because \nof our more detailed model, we must also show that the object layout is not disrupted by the mutators \nor the coflector . The fist step towards this is to capture the layout and reachable concepts precisely, \nwhich we do in Figure 10. (23) U@j%ee@ claim @@mC. ~WUGUB (24) allot @ @m(poolm @ Sm) = O \\ (W U G U \nB) Xzy xYy Xxy ~ ~ 2 X E ADDR A heap [X] E HEADER A y = heap[z].size +Z + 1 d.z,xZz Ax<y<z ~Z,ZYZ A y \n= heap[z] (25) Vm,filim S {z ~ Y(new~) I Pcm 6 CREATE} (26)Vm, pcm c UPDATE + fieldm G Y(0) (2?) whiten \n~ V A fi~s ~ Y(0) A X*(M) ~ U U G (28)Vm, statusm # A sync V step c {Mark, Scan} * Cm~WUBApcm#GmyNew \nO 2 Z*(0) n [0, end) (29) vm, Pcm = Split + heap [new~].color = Black W ~ {z 60 I heap[z].color = White} \n(30) {ptr, limit, rover} ~ O U {end} G ~ {z 60 ] heap [z]. color = Gray} (31) ptr ~ limit A sublimit \n< limit B ~ {Z c O I heap [z]. color = Black} (32) end c Z*(0) cm ~ N $ s. s F. ~ Am~ {newm I pcm < \nCREATE\\ {Split}} {new~ j 3m, pc~ ~ CREATE\\ {Split, Fill}} {Oldm I pcm = split} {h@p[y] I Pcm ~ CREATE \nA new~ Y y # jillm} rootsm U mark~ U Fm U {x I (z= new~ V x = old~ V zYfieidJ A pCm E UPDATE} u {z 6 \na~sm I status~ # Quick} (33) vm, Pcm = Split =S old~ Y new~ (34) Vm, pcm = Split ~ Z(old~) = Z(newm) \n(35) step = Sweep + (U U (JmCm) n W ~ [0, ptr) (36) Vm, pcm = ClearNew A step = Sweep ~ newm (37) step \n= Sweep %\u00ad~ n [ptr, sublimit) = 0 (38) step = Sweep ~ B ~ ~tr, +m) U N U whiten (39) Vm, pc~ = TestSweep \nA step = Sweep A old~ # + newm @ [swept, ptr) \\ (W U whiten) < ptr swept U {x E argsp I pcm = Launch \nA p = Childm } (40) step = Sweep + O ~ [0, swept] U V U [ptr, +CCI) U ~ X* ((G U 1?) \\ (Jmcm) U UmX*(AJ \n(41) step = Clear ~ B ~ whiten U N\\c~m U ~tr, limit) V ~ (W UGuk?)\\~ (42) step E {Mark, Scan} ~ M = X*(M) \n~ K xTy ~ ~ $ V \\ Um(X*(AJ U C-) {fieldm I 3m, pcm~ UPDATE A status~ # Syncl A (pcm = Store v old~ # \nheapEeldJ)} 3z#K, xYz Ay= heap[z] ~B (43) m%e ~ G U B A blacken ~ W (44) Vm, PCm ~ UPDATE A statusm * \nnewm~BUGU&#38; (45) Vm, pc~ c { TestScan, SetDirty} a old~c GUB U G # Async A lmarking~ A step c {Mark, \nScan} R(7 ~ {z 6 G I step # Scan V z > ptr V reset V dirty} (46) Vm, pcm c UPDATE\\ {Store} ~ statusn \n= A sync U blacken U m~e U (heapfi~&#38;\\K] U tmce) \\ B (47) Vm, status-E {Dead, l+ee, Quick} - Am=@ \n&#38; ~ (mvk~ U {x c F~ I markingm}) \\ B (48) Vm, markingm + X* (Am) ~ M M ~ GuBu T*(Rcu U#&#38;) (49)Vm, \nstatus~ = * X*(A~) A sync A step E {Mark, Scan} ~ M A Cm ~ B A pcm # ClearNew Figure 10: Auxiliary definitions \n(50) step = Scan * U n G ~ [0, limit) (51) Vm, PCm = GmyOld A step = Scan * old~ < limit Figure 11: Safety \ninvariauts Z, Y, and X are the end , field> , ~d field v~ue re\u00ad lations, respectively, so X* is the \nreachability relation. O is the set of objects, W, G, B its color subsets. Am is the set of objects immediately \naccessible by mutator m. It includes not only roots ~ (the set underlying the multiset roots~ ), but \nalso objects that are being marked or updated, and filled fields F~ of an object being created. The latter \n(Cm) is not part of Am. U is the set of objects under use; it includes all objects reachable from the \nregisters Am, or from shaded objects not under creation (which may be used by the col\u00adlector). V is the \nset of valid objects, and O \\ V is the set of available memory blocks. J is the set of garbage objects: \nvalid objects that are not reachable from any mut ator. The main safety invariant is (23) which implies \nthat used objects only contain pointers to used objects, that they do not appear on the free list, which \nis a set white objects, and that there are no pointers to objects under creation (since the inclusion \nof a multiset union in a set implies that the union is disjoint). However all the invariants in Figure \n4 depend on each other to some extent (except 4647), and must be proved simultsmously. (24) asserts that \nall blue objects are accounted for. (25\u00ad31) ensure that mutator and collector pointer variables have \nproper values; (28) ensures that the mutators do not create unfilled gray objects when the collector \nis tracing. (32) ae\u00adserts that the object layout is consistent on all the used por\u00adtion of the heap, \nand is needed to establish (30-31); (33-34) ensure that fragmentation preserves (32). (35-37) ensure \nthat only garbage is reclaimed by the sweep step. (3841) ensure that the sweep and clear steps do not \nleave black objects behind, except newly created ob\u00adjects that will be cleared (N). (40) is the key property \nof the split-off-top policy: the sweep cannot leap over free memory block headers. This ensures (39), \nwhich in turn ensures that new objects me created with the right color. The remaining invariants ensure \nthat the mark and scan steps shade all objects, so that (35) is established at the beginning of the next \nsweep. These invariants are all based on the formula for M, the set of objects that would be traced by \nthe collector if the mutators cleared all their registers. M contains all shaded objects, plus all objects \nreachable by the trace relation T from the trace roots &#38; and &#38;. The trace relation is like the \nreachability relation, except it ignores black fields and fields that are being updated and whose values \nare unreliable (K). The main marking invariant is (49); it is the equivalent of the keachable objects \nare reachable from a gray invari\u00adant of the basic algorithm. In turn, (49) crucially depends on (42), \nwhich asserts that M is closed under reachability; it is the equivalent of the no black points to a white \ninvariant of the basic algorithm. Part of the proof of (49) is that M is non-decreasing after phase = \nSyncz. The purpose of the update overhead is to ensure that the inevitable incresse of K does not lead \nto a decrease of M, i.e., it ensures that old~ will always be traced. In sddition, K also contains the \nfields for which old~ is the wrong value, and the overhead is misspent. The status # A sync overhead \ncovers that case by ensuring that the value deposited in a field that remains in K because of a concurrent \nassignment is always traced. Finally, note that the invariant remain vahd if we add to K all the fields \nthat have been updated since the start of the mark step. Once a field has been cut off from the collector, \nit remains so. This implies that Async processes need to incur the update overhead at most once per cycle \nper updated field.  6.3 Liveness The liveness part of the proof is much more standard. We need to establish \nthat all garbage is eventually collected , i.e., z c J x z @ V. It is stmightforward to show that all \nquick garbage in J U W at the beginning of a U [0, limit)sweep step is collected by that step, and that \nthe rest of the garbage is whitened and thus becomes quick garbage during the sweep and clear steps, \nand remains quick garbage during the mark and scan steps. Therefore, we only need to show progress of \nthe collector cycle, and this is trivial except for the handshakes and the scan step. For the handshakes, \nfirst note that each active muta\u00adtor must eventually change its status after the collector has changed \nhis, either by doing an exit, or several cooperate actions. If m never does an exit, then R[pc~ # Halt \nso m eventually sets am wering ~. m can only reset answering~ by completing the coopemte, which it must \neventually do since all other sctions are blocked. In addition, only the mutators with pc # Halt at the \nstart of the handshake can spawn processes with st attu = phase; once these mutators have responded the \nset of mutators with status = phase decreases, hence the handshake completes. Let us assume the scan \nstep never terminates, D[step = Scan]. Note that no used white objects can be created dur\u00ading the scan \nstep, so that W n (UUM) is eventually constant. After all pending updates complete, no mutator will ever \nset the color of an object to Gnay. It follows from this and (43) that cache @G must decrease, so the \nnormal emptying of the cache must eventually stop. At this point the cache must be empty, since the overflow \naction cannot empty the cache. Therefore we must have cache = blacken = 0 from this point on, and G is \nconstant. Eventually we must also have l~elds = tmce = 0]. If R[lreset] at this point, then eventually \nR~tr = limit], so O[dirty], otherwise the scan step would end, aad by (17) O[reset], a contradiction. \nSo O[reset], and thus O[scunned = w]. From this point on we must have G n [0, scanned] = 0, since blacken \nmust remain empty. Thus once all pend\u00ading updates have completed, no mutator can set dirty. As above, \neventually we have reset A scanned = -co, and by (18) ptr = limit, whence eventually weset A ~dirty. \nThis implies Rl[mdirty A weset], which implies a contradiction by the above. References [1] AIWEL A. \nW. Compiling with continuations. Cam\u00adbridge University Press, 1992. [2] APPEL, A. W., ELLIS, J. R., AND \nLI, K. Real-time concurrent collection on stock multiprocessors. SIG-FLAN NOtlC&#38; 23, 7 (1988), 11 \n23. [3] BAKER, H. G. List processing in real time on a serial computer. Cornmun. ACM 21, 4 (1978), 28 \nfF294. [4] BEN-AFU, M. Algorithms for on-the-fly garbage collec\u00adtion. ACM Trans. Program. Lang. Syst. \n6, 3 (1984), 333-344. [5] BOEHM, H. J., DEMERS, A. J., AND SHENKER, S. Mostly paxallel garbage collection. \nSIGPLA N Notices 26, 6 (1991), 157 164. [6] BROOKS, R. A. Trading data space for reduced time and code \nspace in real-time garbage collection on stock hardware. In Lisp and Functional Prugmmming 1984 (1984), \nACM Press, pp. 256-262. [7] CHANDY, K. M., AND MISRA, J. Pamllel Pmgmm Design. Addison-Wesley, 1988. \n[8] CYPRESS. BiCMOS/CMOS data book. Cypress Semi\u00adconductor, 1991. [9] DIJKSTRA, E. W., LAMPORT, L., MARTIN, \nA. J., SHOLTEN, C. S., AND STEFFENS, E. F. M. On-the-fly garbage collection: an exercice in cooperation. \nCom\u00admun. ACM 21, 11 (1978), 966 975. [10] DOIJGEZ, D., AND LEROY, X. A concurrent, genera\u00adtional garbage \ncollector for a multithreaded implemen\u00adtation of ML. In Principles of Progmmming Languages 1993 (1993), \nACM Press, pp. 113 123. [11] HERLIHY, M., AND Moss, J. E. B. Non-blocking garbage collection for multiprocessors. \nTechnical report CELL 90/9, DEC Cambridge Research Lab., 1990. [12] HIBINO, Y. A practical garbage collection \nalgorithm aud its implementation. In 7th Annual International Symposium on Computer Architectwz (1980), \nACM Press, pp. 113-120. [13] HICKEY, T., AND COHEN, J. Performance analysis of on-the-fly garbage collection. \nCommun. ACM 27, 11 (1984), 1143-1154. [14] KUIfG, H. T., AND SONG, S. W. An efficient parzdlel garbage \ncollection system and its correctness proof. In Foundations oj Computer Science 1977 (1977), IEEE Computer \nSociety Press, pp. 120-131. [15] LAM~ORT, L. Garbage collection with multiple pro\u00adcesses: an exercise \nin parallelism. In Proc. IEEE Conf. Parallel Processing (1976), pp. 50-54. [16] LAMPORT, L. The temporal \nlogic of actions. Rmearck report 79, DEC Systems Research Center, 1991. [17] LEROY, X., AND MAUNY, M. \nThe Carol Light system, version 0.5 documentation and user s guide. Techni\u00adcal report L-5, INRIA, 1992. \n[18] NETTLES, S., O TOOLE, J., PIERCE, D., AND HAINES, N. Replication-baaed incremented copying collection. \nIn International Workshop in Memory Management 1992 (1992), vol. 637 of Lecture Notes in Computer Science, \nSpringer-verlag, pp. 357 364.  [19] NEWMAN, I. A., STALLARD, R. P., AND WOODWARD, M. C. A hybrid multiple \nprocessor garbage collection algorithm. The Computer Journal 30, 2 (1987), 119\u00ad  127. [20] NORTH, \nS. C., AND REPPY, J. H. Concurrent garbage collection on stock hardware. In Factional Pro\u00adgmmming Languages \nand Computer Amhitectum 1987 (1987), vol. 242 of Lecture Notes in computer Science, Springer-Verlag, \npp. 113-133. [21] WADLER, P. L. Analysis of an algorithm garbage collection. Commun. ACM 19, 500. A \nThe full algorithm model Global declarations type ADDR ~ NAT SIZE ~ NAT COLOR ~ {Blue, WZite, GraLJ, \nBlack} A wlor c COLOR EA ER = eCord size c SIZE { WORD k ADDR w HEADER PID STATUS ~ {Async, Syncl, Sync2, \nDead, var heap E array [ADDR] of WORD end E ADDR dirty G BOOL free, allot G multiset of ADDR statuso \nE STATUS swept E ADDRw { oo, +co) scnnned E ADDR u { w}  Vm G PID, status~ E STATUS args~ c multiset \nof ADDR Global initialization init end=O free = ailoc = 0 statwo = A sync Vm G PID, statusm G {l+es, \nAsgmc} {m G PID \\ statusm # Fbee} is finite Vm 6PID, aqsm = 0 Memory ( s E SIZE color * Blue s heap[end] \nt--record size ~ ~ { end~end+s+l \u00adallot + allot@ {end} ) (x Gfree =+ heap[x]. w~or -Blue tr-+-lkese{a} \na?20c +-allot@ {a} )  (xc free *frs--j%eee {z}) ( x E atloc * allot -allot e {z} ) heap [x]. wlor t \nWlite for real time 9 (1976), 491- Jbse, Quick) Mutatorm crest e { pc = Work A ~answering A s 6 SIZE \ntype CREATE ~{ Split, TestSweep, ClearNew, GrayNew, Fill) A x c pool A kap[z]. size >= s UPDATE ~ { TestOld, \nGray Old, TtwtSean, SetDirty, Store} =+ ~:l+tzpoot e {z} LABEL $ CREATE B UPDATE @ {Halt, Work, Launch) \nnew -x + hmp[~l. size s jiii + {new + i,: . . ,new + s} ~ Pc = Halt G LABEL wlor I+ Black roots = \npool = mark = fill = 0 E multiset of ADDR heap [new] record size s +~ answering = marking = false E \nBO OL if;ew >old child E PID pc + ?%sweep otherwise )   { { old, new, jield E ADDR ( pc = Split start \nup -WF\u00ad=+ heap[oid]. size + new 1 old (PC = Halt A status~ E {A9ync, Syncl, Sync2} WF pOO[ 4--pOOi \n@ {old} =+-rvots +-argsm PC + TestSweep ) argsm +-0 ( pc = TestSweep if status ~ # statusc thenanswen \nng + true ( ClearNew if status~ # Async V pC+-Work ) WF swept > new launch =%-pc+ GruyNew if swept \n= old (PC = Work A ~an.wering A p ~ PID A statusP = Free { Fill otherwise ) + chiid -p (PC = ClearNe; \nstatusp +-Quick WF =+ heap [new] .coior ~ White PC t-Launch ) pc t Fill) (pc = Launch Ax6roots Ap= \nchild ( pc = GrayNew * arpsP + argsp @ {~} ) (PC = Lawnch A p = child %F henp [new] .coior + Gray . \n WF A sync if marking PC + Fill) * statusp +\u00ad { status~ otherwise fill pC + Work ) - (g Eroots AzEfill \n.\u00ad exit = hap[z] t-y (PC = Work A mark= pool=@ if marking then mark ~ mark e {y} * status~ +-Dead jili \n+-fill e {z})answefn ng +-marking + false (PC=FiilAjiH=ti\u00ad roots+@ WF pc +-Halt ) ==+ roots + roots \n@ {new} cooperate if tnarking then mark + mark @ {new} (PC # Halt A status~ # statusc pC &#38; Work ) \nWF update - answering + true ) (PC = Work A -answering ( PC = Work A answering A ?marking . Ax,y 6roots \nAz<z< x+ heap[x]. size Y answering+ fd5e +new+y if status ~ = Sync2 then jield + z mark + mark @ roots \nold + heap[.z] markino + true if statusm # Async A ~marking then Syncl if status~ = Async mark + mark \n@ {new} statusm + Sync2 otherwise ) if status ~ = Sync2 then (PC = Work A marking A mark= 0 mark k mark \n@ {old} { Test Old if statusm = A sync % answering+ marking+ tldse Pc + store otherwise ) status~ e-Async \n) { ( pc E UPDATE A swept > cm mark e pc -store ) ( x e mark A heap [V]. CO1OT# White ( pC = TestOld \ns mark + mark e {z} ) Gray Old if heap[old].wlor = White( x G mark WF WF ~ PC t-TestSean if heap [old] \ncolor = Gray ==$-hcmp[z]. wlor + Gray store otherwise ) mark + mark @{x} ) { ( pc = Gray Old move WF \n( x e Toots =+ heap [ohi]. color + Gray s roots + roots @ {s} ) PC &#38; TestScnn ) { = c root. ( pc;FTcstScan \n=+ roots t-mOts e {z} ) SetDirty if scanned ~ old load -Pc + Store otherwise ) { ( x e roots A s < z \n~ a + heap[a].$ize ( pc = SetDirty e roots +-roots @ {henp [z]} ) % dirty + true reserve pc+ store ) \n(PC = Work A x Gallot ( pc = store =+ allot +-allot 0 {x} WF pool + pooi @ {z} ) -heap weld] t new pc+ \nWork ) ( x c pool * POO1 4-pool e {x} allot e allot ~ {a} )  Collector type STEP ~ {Sweep, Clear, Mark, \nScnn} var step = Sweep E STEP phase = Asgnc 6 STATUS ptr = limit = sublimit = rover= O G ADDR reset = \ntrue E BOOL whiten = blacken = tnace = 0 E set of A DDR claim = cache = fields = 0 G multiset of ADDR \n sweep ( step = Sweep A swept= ptr < sablimit ~ if hcaap[ptr].cdor E {Gray, Black} then whiten -whiten \nU {ptr} else if heap [ptr]. wlor = White then claim -claim @ {ptr} ptr + ptr + heap~tr].size + 1 ) ( \nstep= Sweep A swept< ptr < .ublimit WF ==+ swept +-ptr ) ( step = Sweep A sublimit < ptr < x ~ limit \n~jree-fie e{ptr,...,1}l} subtimit +-x )  ( step = Sweep A ptr = limit %F swept + +CO ) ( step= Sweep \nA swept= +W WF &#38; limit ~ end step t C7ear ) clear ( step= clear A ptr < limit %F if heap [ptr]. \ncolor 6 {Gray, Black} then whiten ~ whiten u {ptr} ptr G ptr + heop [ptr].$ize + 1 ) ( x 6 whiten % \nwhiten ~ whiten\\{x} heap [z]. cotor t-White)  ( step= Cknr A ptr = limit A whiten=@ WF + statuac * Syncl \n) ( statusc = phase= Syncl A claim = 0 WF ==+ statusc +-Sgnc2 step t Mark ) claim ( x 6 ciaim A y = \nz + heap[z].size + 1 ~ claim =+ claim + claim e {y} heap[a].size -size+ heap [g].size + 1 ) ( x E claim \n% claim+ claim e {x} b+fieo{o}) handshake ( statusc # phase A Vrn E PID, status~ # phase % phase+-statusc \n) { status~ = Dead %= statusm +-he ) globals ( step ~ {Mark, Scan} *rover +-O) ( step E {Mark, Scnn} \nA rover< end -rover _ rover+ heap[rover].size + 1) (step 6 {Mark, Scnn} A rover < end A heap[rover]. \nwlor = GmII ~ blacken + blacken U {rover} ) trace ( x G blacken % heap [x]. wlor +-Black blacken t blacken\\ \n{x} cache +-cache@ {z} )  (. Ecache Acache#{x} =+ cache -cnche e {m} heap [z]. wlor t Gmy if a < ptr \nthen reset -true )  ( z 6 cache % each.+-cache 9 {x} fields +-jields @ {z + 1,...,z+hmp[z].$ize} ( z \nE jields %F jields +-jie2ds e {z} trace +-trace U {heap [c]}) ( z G tmce % trace t-trace\\{=} if heap \n[z]. color ~ { White, Gray} then blacken +-blacken U {x} ) mark ( phase # A sync % swept +- cm ) ( statusc \n= phase= Sync2 A swept= co WF * statusc -Async ) ( step= Mark A phase= Async A scanned= m WF + ptr 6 \nlimit 6 end step t Scan )  reset ( reset WF . * If step = Scan then ptr ~ limit manned + 00 ) ( step \n= Sean A reset A scanned= m WF *ptr +-O reset -dirty e false ) ( step = Scan A scanned < ptr A dirty \nWF ==+ twset -true )  scan ( step= Scnn A scanned < ptr < limit % scanned +-ptr ) ( step = Scan A scanned \n= ptr < limit ~ if heap[ptr].cdor = Grog then blacken t blacken U {ptr} ptr + ptr + heap ~tr].size + \n1 )  ( step = Scan A ptr = limit A Tn%et A ~dirty A cake = jields = 0 A blacken = tnace = 0 WF * wet \n+-true rover + ptr +-sublimit e O step + Sweep )   \n\t\t\t", "proc_id": "174675", "abstract": "<p>We describe and prove the correctness of a new concurrent mark-and-sweep garbage collection algorithm. This algorithm derives from the classical on-the-fly algorithm from Dijkstra <italic>et al.</italic> [9]. A distinguishing feature of our algorithm is that it supports multiprocessor environments where the registers of running processes are not readily accessible, without imposing any overhead on the elementary operations of loading a register or reading or initializing a field. Furthermore our collector never blocks running mutator processes except possibly on requests for free memory; in particular, updating a field or creating or marking or sweeping a heap object does not involve system-dependent synchronization primitives such as locks. We also provide support for process creation and deletion, and for managing an extensible heap of variable-sized objects.</p>", "authors": [{"name": "Damien Doligez", "author_profile_id": "81100592225", "affiliation": "&#201;cole Normale Sup&#233;rieure, INRIA Rocquencourt &#201;cole Polytechnique", "person_id": "P57895", "email_address": "", "orcid_id": ""}, {"name": "Georges Gonthier", "author_profile_id": "81100568047", "affiliation": "INRIA Rocquencourt, 78153 LE CHESNAY CEDEX, France", "person_id": "P96170", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/174675.174673", "year": "1994", "article_id": "174673", "conference": "POPL", "title": "Portable, unobtrusive garbage collection for multiprocessor systems", "url": "http://dl.acm.org/citation.cfm?id=174673"}