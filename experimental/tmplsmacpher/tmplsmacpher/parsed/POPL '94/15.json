{"article_publication_date": "02-01-1994", "fulltext": "\n Implementation of the Typed Call-by-Value A-calculus using a Stack of Regions Mads Tofte, University \nof Copenhagen* Jean-Pierre Talpin, European Computer-Industry Research Center, t Abstract We present \natranslation scheme forthepolymorphi\u00adtally typed call-by-value A-calculus. All runtime val\u00adues, including \nfunction closures, are put into regions. The store consists of a stack of regions: Region in\u00adference \nand effect inference are used to infer where regions can be allocated and de-allocated. Recursive functions \nare handled using a limited form of polymor\u00adphic recursion. The translation is proved correct with respect \nto a store semantics, which models a region\u00adbased run-time system. Experimental results suggest that \nregions tend to be small, that region allocation is frequent and that overall memory demands are usually \nmodest, even without garbage collection. Introduction The stack allocation scheme for block-structured \nlanguages [9] often gives economical use of memory re\u00adsources. Part of the reason for this is that the \nstack discipline is eager to reuse dead memory locations (i.e. locations, whose contents is of no consequence \nto the rest of the computation). Every point of allocation is matched by a point of de-allocation and \nthese points can easily be identified in the source program. In heap-based storage management schemes[4, \n19, 18], allocation is separate from de-allocation, the lat\u00adter being handled by garbage collection. \nThis sepa\u00adration is useful when the lifetime of values is not ap\u00adparent from the source program. Heap-based \nschemes are less eager to reuse memory. Generational garbage *Postal address: Department of Computer \nScience (DIKU), University of Copenhagen, Universitetsparken 1, DK-21OO Copenhagen @, Denmark; email: \ntof te~diku. dk. t work done ~h~le at Ecole des Mines de Paris. Cur\u00adrent address: European Computer-Industry \nResearch Center (ECRC GmbH), Arabella Straf3e 17, D-81925 Miinchen; email jprfJecrc. de Permission to \ncopy without fee all or part of this material is Oranted provided that the copies are not made or distributed \nfor direct commercial advantage, the ACM copyright notica and the title of the publication and its date \nappeer, end notice is given thet copying is by permission of the Association for Computing Machinery. \nTo copy otherwise, or to republish, requires a fee and/or specific permission. POPL 94-1/94, Portland \nOregon, USA @ 1994 ACM 0-69791-636-0/94/001 ..$3.50 collection collects young objects when the allocation \nspace is used up. Hayes[11] discusses how to reclaim large, old objects. Garbage collection can be very \nfast. Indeed, there is a much quoted argument that the amortized cost of copying garbage collection tends \nto zero, as memory tends to infinity [2, page 206]. Novice functional pro\u00adgrammers often report that \non their machines, mem\u00adory is a constant, not a variable, and that this constant has to be uncomfortably \nlarge for their programs to run well, The practical ambition of our work is to reduce the required size \nof this constant significantly. We shall present measurements that indicate that our translation scheme \nholds some promise in this respect. In this paper, we propose a translation scheme for Milner s call-by-value \nA-calculus with recursive func\u00adtions and polymorphic let [22, 7]. The key features of our scheme are: \n1. It determines lexically scoped lifetimes for all run\u00adtime values, including function closures, base \nval\u00adues and records; 2. It is provably safe; 3. It is able to distinguish the lifetimes of different \ninvocations of the same recursive function;  This last feature is essential for obtaining good mem\u00adory \nusage (see Section 5). Our model of the runtime system involves a stack of regions, see Figure 1. We \ndo not expect always to be able to determine the size of a region when we allo\u00adcate it. Part of the reason \nfor this is that we consider recursive dat atypes, such as lists, a must; the size of a region which \nis supposed to hold the spine of a list, say, cannot in general be determined when the region is allocated. \nTherefore, not all regions can be allo\u00adcated on a hardware stack, although regions of known size can. \nOur allocation scheme differs from the classical stack allocation scheme in that it admits functions \nas first-class values and is intended to work for recursive datatypes. (So far, the only recursive datatype \nwe have dealt with is lists.) n D  7-1 7-3 Figure 1: The store is a stack of regions; a region is \na box in the picture. Ruggieri and Murtagh[28] propose a stack of regions in conjunction with a traditional \nheap. Each region is associated with an activation record (this is not neces\u00adsarily the case in our scheme). \nThey use a combination of interprocedural and intraprocedural data-flow anal\u00adysis to find suitable regions \nto put values in. We use a type-inference based analysis. They consider updates, which we do not. However, \nwe deal with polymor\u00adphism and higher-order functions, which they do not. Inoue et al. [15] present an \ninteresting technique for compile-time analysis of runtime garbage cells in lists. Their method inserts \npairs of HOLD and RECLAIMq instructions in the target language. HOLD holds on to a pointer, p say, to \nthe root cell of its argument and RECLAIMq collects those cells that are reachable from p and fit the \npath description q. HOLD and RE-CLAIM pairs are nested, so the HOLD pointers can be held in a stack, \nnot entirely unlike our stack of regions. In our scheme, however, the unit of collection is one entire \nregion, i.e., there is no traversal of values in con\u00adnection with region collection. The path descriptions \nof Inoue et al. make it possible to distinguish between the individual members of a list. This is not \npossible in our scheme, as we treat all the elements of the same list as equal. Inoue et al. report a \n100% reclamation rate for garbage list cells produced by Quicksort [15, page 575]. We obtain a 100% reclamation \nrate (but for 1 word) for all garbage produced by Quicksort, without garbage collection (see Section \n5). Hudak[13] describes a reference counting scheme for a first-order call-by-value functional language. \nRefer\u00adence counting may give more precise use information, than our scheme, as we only distinguish between \nno use and perhaps some use. Georgeff[lO] describes a implementation scheme for typed lambda expressions \nin so-called simple form to\u00adgether with a transformation of expressions into simple form. The transformation \ncan result in an increase in the number of evaluation steps by an arbitrarily large factor[lO, page 618]. \nGeorgeff also presents an imple\u00admentation scheme which does not involve translation, although this relies \non not using call-by-value reduc\u00adtion, when actual parameters are functions. We translate every well-typed \nsource language ex\u00adpression, e, into a target language expression, e , which is identical with e, except \nfor certain region annota\u00adtions. The evaluation of e corresponds, step for step, to the evaluation of \ne. Two forms of annotations are elat p letregion p in e2 end The first form is used whenever el is an \nexpression which directly produces a value. (Constant expres\u00adsions, A-abstractions and tuple expressions \nfall into this category.) The p is a region variable; it indicates that the value of el is to be put \nin the region bound to p. The second form introduces a region variable p with local scope e2. At runtime, \nfirst an unused region, r, is allocated and bound to p. Then ez is evaluated (probably using r). Finally, \nT-is de-allocated. The letregion expression is the only way of introducing and eliminating regions. Hence \nregions are allocated and de-allocated in a stack-like manner. The device we use for grouping values \naccording to regions is unification of region variables, using es\u00adsent ially the idea of Baker[3], namely \nthat two value\u00adproducing expressions el and ez should be given the same at p annotation, if and only \nif type check\u00ading, directly or indirectly, unifies the type of el and e2. Baker does not prove safety, \nhowever, nor does he deal with polymorphism. To obtain good separation of lifetimes, we introduce explicit \nregion polymorphism, by which we mean that regions can be given as arguments to functions at run\u00adtime. \nFor example, the successor function succ = Az.s + 1 is compiled into A [p, p ] .Ax.letregion p in (r \n+ (1at p )) at p end  which has the type scheme Vp, p .(int, p) get(p) put(p )} >(int, p ) meaning \nthat, for any p and p , the function accepts an integer at p and produces an integer at p (performing \na get operation on region p and a put operation on region p in the process). Now succ will put its result \nin different regions, depending on the context: ... succ [P12, P91 (5 at P12) .. succ [PI, P41 (x) Moreover, \nwe make the special provision that a recur\u00adsive function, .f, can call itself with region arguments which \nare different from its formal region parameters and which may well be local to the body of the recur\u00adsive \nfunction. Such local regions resemble the activa\u00adtion records of the classical stack discipline. We use \neffect inference[20, 21, 14] to find out where to wrap letregion p in . . . end around an expres\u00adsion. \nMost work on effect inference uses the word effect as a short-hand for (side-effect . We have no side-effects \nin our source language our effects are side-effects relative to an underlying region-based store model. \nThe idea that effect inference makes it possible to delimit regions of memory and delimit their lifetimes \ngoes back to early work on effect systems[6]. Lucassen and Gifford[21] call it effect rnaskin~ they prove \nthat effect masking is sound with respect to a store se\u00admantics where regions are not reused. Talpin[29] \nand Talpin and Jouvelot [30] present a polymorphic effect system with effect masking and prove that it \nis sound, with respect to a store semantics where regions are not reused. We have found the notion of \nmemory reuse surpris\u00adingly subtle, due to, among other things, pointers into de-allocated regions. Since \nmemory reuse is at the heart of our translation scheme, we prove that our translation rules are sound \nwith respect to a region\u00adbased operational semantics, where regions explicitly are allocated and de-allocated. \nThis is the main tech\u00adnical contribution of this paper. The rest of this paper is organised as follows. \nThe source and target languages are presented in Section 2. The translation scheme is presented in Section \n3. The correctness proof is in Section 4. In Section 5 we dis\u00adcuss strengths and weaknesses of the translation \nand give experimental results. Due to space limitations, most proofs have been omitted. Detailed proofs \n(and an inference algorithm) are available in a technical report [31]. 2 Source and target languages \n2.1 Source language We assume a denumerably infinite set Var of variables. Each variable is either an \nordinary variable, Z, or a letrec variable, f. The grammar for the source lan\u00adguage isl .. e .. x \\k.e \n]ele2 Ilet z=el in e2end I letrec ~ (z) = el in ez end A finite map is a map with finite domain. The \ndomain and range of a finite map f are denoted 1For brevity, we omit pairs and projections from this \npaper. They are treated in [31]. Dom(~) and Rng(~), respectively. When ~ and g are finite maps, f + g \nis the finite map whose do\u00admain is Dom( f ) U Dom(g) and whose value is g(x), if z e Dom(g), and f(z) \notherwise. f J A means the restriction of f to A. A (non-recursive) closure is a triple (z, e, -E), where \nE is an environment, i.e. a finite map from variables to values. A (recursive) closure takes the form \n(z, e, E, f ) where f is the name of the fiunction in question. A value is either an integer or a closure. \nEvaluation rules appear below. Source Expressions u E(Z) =v E(f) = v (1) EFx*v Et-f-iv (2) E > k.e -+ \n(z, e,E) E + el 4 (rO, eo, EO) Eke2+v2 EO+{zO~wzJ+eO-+w (3) Eke1e2~v Eke1e2kv (4) Etel+vl E+{xt-ivl}t-ez-+v \n(5) E1-letx =elinezend~v E+{ f~(x, el, E, f)}t-e2~v (6) E E letrec f(x) = el in e2 end --+ v  2.2 Target \nlanguage Let p range over a denumerably infinite set RegVar of region variables. Let r range over a denumerably \nin\u00adfinite set RegName = {rl, r2, . ..} of region names. Region names serve to identify regions uniquely \nat runt ime, i.e. a store, s, is a finite map from region names to regions. Let p range over the set \nof places, a place being either a region variable or a region name. The grammar for the target language \nis: P ::=plr e ::= x IAxe at p Ielez I let x =el in e2end I letrec f [~] (x) at p = el in e2 end I f[~latp \nI letregion p in e end where ~ranges over finite sequences pl, ..., pk of region variables and $ ranges \nover finite sequences pi,... ,pk of places (k > O). We write IF I for the length of a se\u00adquence @ .For \nany finite set {PI,... , pk } of region vari\u00adables (k > O), we write letregion ~ in e end for letregion \npl in ... letregion pk in e end ... end A region is a finite map from offsets, o, to storable values. \nA storable value, SV, is either an integer or a closure. A (plain) closure is a triple (z, e, VE), where \ne is a target expression and VE is a variable environ\u00adment, i.e. a finite map from variables to addresses. \nA region closure takes the form (~, x, e, VE) where $ is a (possible empty) sequence PI,. ,pk of distinct \nregion variables, called the formal region parameters of the closure. Region closures represent region-polymorphic \nfunctions. For any sequence @= PI,... ,pk, the simul\u00adtaneous substitution of p, for free occurrences \nof p? in e(i=l . . . k), is written e[~/f7]. For simplicity, we assume that all values are boxed. Hence \na value v is an address a = (r, o), where r is a region name and o is an offset. A region-based operational \nsemantics appears be\u00adlow. We are brief about indirect addressing. Thus, whenever a is an address (r, \no), we write s(a) to mean s(r) (o) and we write a G Dom(s) as a shorthand for r c Dom(s) and o G Dom(s(r)). \nSimilarly, when s is a store and sv is a storable value, we write s + {(r, o) = SV} as a shorthand for \ns + {r w (s(r) + {o H SV})}. We express the popping of an entire region r from a store s by writing s \n~ {r} , which formally means the restriction of s to Dom(s) \\ {r}. Target Expressions ~ VE(Z) = V ./ \n(7) s, VE1-x-iv, s VE(f) = a, s(a) = (~, z, e, VEO) 1~1 = \\~\\ o @Dom(s(r)) sv = (z, e[@/~], VEO) (8)s, \nVEt-~[fil at r ~ (r, o), s+{(r, o) + SV} o # Dom(s(r)) a = (r, o) (9) s, VEI-k.e at r --i a,s+{a H (z, \ne, VE)} s,VE t-el A al, sl Sl(al) = (zo, eo, VEo) sl, VE1-e2bv2, s2 S2,VE0 + {x. H V2} F e. -+ V,S ,.[10)s, \nVE1-e1e2-+v, s s,VEF el -+ Vl, sl sl, VE+{z~vl}t-e2~v, s s,VEt let x = el in e2 end~v, s (11) o f! Dom(s(r)) \nVE = VE + {f w (r, o)} s + {(r, o) H (~, x,el, VE )}, VE t-ez -+ V,S S,VE Fletrec f[~] (x) at r = el \nin ez end ~ V,St (12) r @Dom(s) s + {r ~ {}}, VE > e[r/p] ~ v, SI s, VE t-letregion p in e end --+ v, \nSI \\ {r} (13) For arbitrary finite maps .fl and f2, we say that .fz extends fl, written .fl ~ .fz, if \nDom(.fl ) G Dom(.fz) and for all x E Dom(jl), .fl(z) = .fz(x). We then say that sz succeeds SI, written \nS2 2 S1 (or S1 L S2), if Dom(sl) C Dom(s2) and sl(r) C sz(r), for all r G Dom(sl). Lemma 2.1 If s, VE \n~ e ~ v, s then Dom(s) = Dom(s ) and s ~ s . The proof is a straightforward induction on the depth of \ninference ofs, VE F e ~ v, .4. Example The source expression let z = (2,3) in Ay. (fst z, g)end 5 translates \ninto e s letregion p4, p5 in letregion P6 in let ~ = (2 at P2, 3 at @5)at P4 in (Au. (fst z, y) at pl) \nat p.5 end end 5 at p3 end Notice that pl, p2 and p3 occur free in this expression. That is because \nthey will hold the final result (a fact which the translation infers). To start the evaluation of et, \nwe first allocate three regions, say rl, r2 and r3. Then we substitute ri for pi in e (i = 1..3). Figure \n2 shows three snapshots from the evaluation that follows, namely (a) just after the closure has been \nallocated; (b) just before the closure is applied and (c) at the end. The maximal depth of the region \nstack is 6 regions and the final depth is 3 regions. Notice the dangling, but harmless, pointer at (b). \nrl rl  Eppla (c) Figure 2: Three snapshots of an evaluation 3 The Translation Let a and e range over \ndenumerably infinite sets of type variables and effect variables, respectively. We assume that the sets \noft ype variables, effect variables, region variables and region names are all pairwise dis\u00adjoint. An \neffect, p, is a finite set of atomic effects. An atomic eflect is either a token of the form get(p) or \nput (p), or it is an effect variable. Types, ~, decorated types, p, simple type schemes, n, and compound \ntype schemes, m, take the form: T ::= int I pap p ::= (T, p) (7 ::= T I dC1.a T ::= ~ \\ VCk!.f r The \nreason for the apparent redundancy between the productions for simple and compound type schemes is this. \nIn the target language there is a distinction between plain functions and region\u00adpolymorphic functions. \nThe former are represented by plain closures, the latter by region closures that must be applied to zero \nor more places in order to yield a plain closure. Thus plain functions and region\u00adpolymorphic functions \nhave different effects (even in the case of region-polymorphic functions that are ap\u00adplied to zero places). \nWe choose to represent this dis\u00adtinction in the type system by a complete separation of simple and compound \ntype schemes. Only region\u00adpolymorphic functions have compound type schemes. (The underlining in the production \nT ::= z makes it possible always to tell which kind a type scheme is.) When a type r is regarded as a \ntype scheme, it is always regarded as a simple type scheme. An object of the form C.P (formally a pair \n(c, p)) is called an arrow eflect. Here q is the effect of calling the function. The c. is useful for \ntype-checking pur\u00ad poses, as explained in more detail in Appendix A. A type environment, TE, is a finite \nmap from ordinary variables to pairs of the form (a, p) and from letrec variables to pairs of the form \n(m, p). A substit ution S is a triple (Sr, St, S.), where S, is a finite map from region variables to \nplaces, St is a finite map from type variables to types and Se is a finite map from effect variables \nto arrow effects. Its effect is to carry out the three substitutions simultaneously on the three kinds \nof variables. For any compound type scheme and type T , we say that r is an instance of r (via S), \nwritten 7r ~ r , if there exists a substitution S=({pl=pl,.. ., Pk + +Pk}, {% +- + rl, . . ..an i-+ Tn}, \n{q +-+ E{. (pi,... ,6m HE&#38; .W~}) such that S(T) = T . Similarly for simple type schemes. We infer \nsentences TE R e ~ e : ~, ~, read: in TE, e translates to e!, which has type and place p and ef\u00ad fect \nq. In the example in Section 2.2, ~ is ((int, pz) * (int, P3), Pi), p is {put(pl), put(pz), put(ps)} \nand TE is empty. Translation TEFe~e :p, p TE(z) = (ojp) 0> ~ (14)TE+x+z:(T, P), O TE+{xt--i p1}t-e>e \n:p2, p p~p TE F k.e ~ k.e at p : (pl --@+ P2, p), {put(p)} (15) (18)  ., TE+ {z++ TEF letx=el (al,pl)}t-ez \nine2 +-ej end+ :IJ,w (17) let x = e; in e! end: p,~1Up2 TE(j) = (r, p ) r = Vpl. ..pk. dd.b <~ m 2 T \nvia S q = {get(p ), put(p)} (19) TEH$a~[S(pl),. . ., S(pk)l at p: (T,p), p TE + e + e : ~, p p = Observe(TE, \np)(p) {Pl ,..., p,k}=frv(p \\@) TE !--e + letregion pi.. .pk in e end : p,@ (20) For any semantic object \nA, frv(A) denotes the set of region variables that occur free in A, frn(A) denotes the set of region \nnames that occur free in A, ftv(A) denotes the set of type variables that occur free in A, fev(A) denotes \nthe set of effect variables that occur free in A and fv(A) denotes the union of all of the above. Rule \n14 is essentially the usual instantiation rule for polymorphic variables in Milner s type discipline[22, \n7]. In rule 18, notice that ~ can be used region\u00adpolymorphically, but not type-polymorphically, inside \ne;. As for rule 20, assume TE F-e +. e : p, p and that p is a region variable which occurs free in ~, \nbut does not occur free in TE or in p. Then p is purely 10\u00adcal to the evaluation of e , in the sense \nthat the rest of the computation will not access any value stored in p. Since p is no longer needed, \nwe can introduce a letregion p in ... end around e and discharge any effect containing ,0 from p. Thus, \nfollowing Talpin and Jouvelot [30], for every effect p and semantic ob\u00adject A, we detine the observable \npart of p with respect to A, written Observe(A)(p), to be the following sub\u00adset of V: Observe(A)(p) = \n{put(p) G p I p e fv(A)} u {get(p) c q I P G MA)} U {e G p I e s fev(A)} Every expression which is typable \nin Milner s type system [7] can be translated using our rules, by refrain\u00ading from using region polymorphism, \nabstaining from rule 20, choosing a fixed region p. everywhere and choosing the arrow effect Co.{get \n(po), put (po), Co} ev\u00aderywhere. (A good region inference algorithm natu\u00adrally does the exact opposite \nand makes all regions as distinct and local as possible.) Lemma 3.1 If TE 1-e ~ e : p, p then S(TE) 1-e \n~ S(e ) : S(p), S(p), for all substitutions S. An example of a translation where region polymor\u00adphism \ncomes into play is found in Appendix B. 4 Correctness In an attempt to prove that the translation rules \nare sound, one might try to define a consistency relation between values in the source language semantics \nand values in the target language semantics and prove a theorem to the effect that consistency is preserved \nif E and VE are consistent in store s and e translates to e and E E-e ~ v then there exists a store s \nand a value v such that s, V13 1-e ~ v , s [25, 8]. However, Definition The relation Consistent is the \nlargest relation satisfying: . Consistent (R, V, v,s, v ) w.r.t. p * (writing p as (~, p) and v as (r \n, o )) if get(p) ~ p then v e Dom(s) and # = R(p) and 1) If v is an integer i then T = int and s(v ) \n= i; 2) If v is a closure (z, e, E) then s(v ) is a closure (z, e , W3), for some e and VJ!3, and there \nexist TE, R and e such that TE F kz.e a Xz.e at p : #,{put(p)} and Consistent(R, TE, E,s, VE) w.r.t. \np and R and R agree on p and R (e ) = e ;  3) If v is a closure (z, e, E, f) then s(v ) = (z, e , VE), \nfor some e and VE, and there exist TE, ~, p , R and e such that TE + {f w (a, p )} + kr.e * k.e at p \n: p, {put(p)} and Consistent(R, TE + {j H (a, p )}, E + {.f M v}, S, VE) W.r.t. P and R and R agree \non p and R (e ) = e ; . Consistent(R, (a, p), v,s, v ) w.r.t. p u (writing v as (r , o )) if get(p) e \np then v c Dom(s) and r = R(p) and for all r, if a > ~ then Consistent(R, (~, p), v,s, v ) w.r.t. p; \n. Consistent (R, (n, p), v,s, v ) w.r.t. p -+=+ (writing v as (r , o )) if get(p) ~ y then v is a recursive \nclosure (z, e, E, f) and s(v ) = (~, x, e , VE), for some ~, e and VE, and there exist TE, R and e such \nthat Consistent(R, TE + {f H (n, p)}, E + {f w v}, S, VE) w.r.t. q and ~ can be written in the form v$.va~~.z \n where none of the bound variables occur free in (TE, p), and TE + {f w (T, p)} k Axe* k.e at P : (T, \np), {put(p)} and R and R agree on p and R (F, z, e , VE) = (~, x, e , VE) eConsistent(R, TE, E,s, VE) \nw.r.t. p u DomTE =DomE=DomVE andforallz . Dom TE, Consistent(R, TE(z), E(z),s, VE(X)) w.r.t. P Figure \n3: The definition of Consistent no matter how we tried to define the notion of con\u00ad sistency, we were \nunable to prove such a preserva tion theorem. The key observation is that consistency, in an abso\u00adlute \nsense, is not preserved rather it decreases mono\u00adtonically. In the example in Section 2, the consistency \nthat existed between the pair (2,3) and its representa\u00adtion in the store at point (a) is obviously only \npartially preserved at point (b). The saving fact is that there is always enough consistency left! We \ntherefore define consistency with respect to an effect, which, intuitively speaking, stands for the ef\u00adfect \nof executing the rest of the program. A region environment, R is a finite map from region variables to \nplaces. R connects q to s, if frv(R(q)) = 0 and frn(R(p)) ~ Dom(s). Two region environments RI 194 and \nRz agree on effect p, if RI(p) = R2 (p), for all p 6 frv(p). Region environments can be applied to target \nex\u00adpressions and even to region closures (~, Z, e, VE) pro\u00advided one renames bound region variables, \nwhen nec\u00adessary, to avoid capture. The consistency relation is defined in Figure 3. It is the maximal \nfixed point of a monotonic operator on sets; properties about consistency can therefore be proved using \nco-induction [23]. For example, one can prove[31] that consistency is preserved under increas\u00ad ing stores, \nwith respect to decreasing effects: Lemma 4.1 If Consistent (R, p, v, s1, v ) w.r.t. PI and 92 c P1 \nand S1 G S2 then Consistent(R, v, W,s2, v ) w.r.t. pz. This lemma is a special case of a the following \nlemma, which we shall see an application of later: Lemma 4.2 1. Consistent(RI, p, v, S1, v ) w.r.t. PI \nandPZCPI andRzandR1agreeonyqandslJ. frn(Rxpz) C sz then Consistent(Rz, p, v, SZ,v ) w.r.t. Wo The next \nlemma states that, in certain circumstances, consistency can even be preserved with respect to in\u00adcreasing \neffects ! Lemma 4.3 1$ Consistent(R, 733, E,s, V-E) w.r.t. q and p f! frv(TE, p), r @ Dom(s) and p C \n{put(p), get(p)} U {6,,... ,Q}, where El,... ,Ck are eflect variables (k 2 O) then Consistent(R + {p \nH r}, TY3, E,s + {r w {}}, Vi?) w.r.t. @ U p. The proof of Lemma 4.3 has to deal with the possibil\u00adity \nthat there are old pointers into r [31]. This lemma will be used in the proof of the soundness of rule \n20. Here is the main theorem: Theorem 4.1 If TE 1-e * e : p,p and Consistent(R, TE, E,s, VE)w.r.t.@J@ \nand E 1-e ~ v and R connects @J@ tos and R and R agree on @J@ then there exist s and v such that s, VE \nk R (e ) + v , s and Consistent(R, ~, v, s , v ) w.r.t. p . Proof The proof is by depth of the derivation \nof E t\u00ad e --t v with an inner induction on the number of rule 20 steps that terminate the proof of TE \nt-e * e : p, p. The inner inductive argument is independent of e, We show the (inner) inductive step \nconcerning letregion and the (outer) case concerning function application, as examples. In both cases, \nwe assume Consistent(R, TE, E,s, VE) w.r.t. q U @ (22) E re~v (23) R connects ~ Up to s (24} R and R \nagree on p up (25) I Inner proof case: the letregion rule was applied I Assume (21) takes the form TE \nF e * letregion pl.. .pk in e; : U, p which must have been inferred by rule 20 on the premises p = Observe(TE, \nK) (p+) (27) {PI>... >pk} = frv(P+ \\ f ) (28) Without loss of generality we can choose PI, ..., pk such \nthat {PI, . . . ! pk} n frv(p ) = 0 as well as (27)\u00ad(28). Thus {p~, ... ,Pk} n frv(TE, P U p ) = 0. Let \nrl, . . ..rk be distinct addresses none of which are in Dom(s). Then by repeated application of Lemma \n4.3 starting from (22) we get Consistent(R+, TE, E, s+, VE) w.r.t. p+ U p (29) where R+= R+{pl Hrl, .... \npk H rk} and s+ = s+{rl ~{},..., rk H {}}. Also by (24) R+ connects V+ U # to s+ (30) and by (25) R + \nand R+ agree on p+ U @ (31) l+=R/+{plHrl?.-.l where R pk H rk}. By induc\u00adtion on (26), (29), (23), (30) \nand (31) there exist s{ and v such that Consistent(R+, N, v,s;, v ) w.r.t. q (33) Write R (letregion \npl.. .pk in e; end) in the form let region p:.. .p~ in e: end. Then e~[rl/pj, . . . . ?_k/p~]= R1+e~ \nThus, repeated application of rule 13 starting from (32) gives s, VE F R (letregion P1 pk in ei end) \n-+ v , s where s = s; ~ {rl, ..., rk}. Note that R+ and R agree on p (as {pi, . . . , pk} n frV(@) = \n0). AlSO, S~ 1 frn(R@) C s by (24). Then by Lemma 4.2 on (33) we get Consistent(R, p, v, s , v ) w.r.t. \np , as required. Application of non-recursive closure, rule 3 Here ~ s ele~, for some el and z. For the \nbase case of the inner inductive proof we have that e z e; e;, for some ej and ej and that (21) was inferred \nby rule 16 on premises Tl?31-el +e~ : (P -P,P),PI (34) TEFe2*e~:p , p2 (35) p = w U 92 U {c,ge~(p)} u \n90 (36) Moreover, (23) was inferred by rule 3 on premises E+el-ivl, VI = (xO, eO,EO) (37) E1-e2~v2 (38) \nEo+{zot+v2}Eeo~v (39) Let pi = 92 U {c, get(p)} U p. U p , i.e. the effect that remains after the computation \nof e;. Note that p U p = PI Up; so from (22), (24) and (25) we get Consistent(R, TE, E,s, VE) w.r.t. \nPI U pi (40) R connects 91 U pi to s (41) R and R agree on PI U q; (42) By induction on (34), (40), (37), \n(41) and (42) there exist S1 and v; such that s,VE 1-R (ej) ~ vj, sl (43) Consistent(R, (~ w V, P)> \nVl! Sl> v;)w.r.t.~i (44) Notice that get(p) 6 ~~. Thus, by the definition of Consistent, (44) tells us \nthat vj ~ Dom(sl) and r of v; = R(p) and there exist e~, VEj, TEO, e{ and R. such that sl(v~) = (zo, \ne~, VEj) (45) TEO t-ko.eo ~ ko.e{ atp : (~ 90 >u,p), {put(p)} (46) Consistent(R, TEo, Eo, s1, VEO) w.r.t. \npi (47) R. and R agree on pi (48) Ro(e&#38; ) = e~ (49) Let pj = {c, get(p)} U PO U p , i.e. the effect \nthat remains after the computation of e~. Note that p2 U A ~Pu @and sL s1,sob Lemma 4.1On(22) we have \nConsistent (R, TE, E, S1, VE) w.r.t. p2 U pj (50) Also, from (24) and (25) we get R connects p2 U p; \nto S1 (51) R and R agree on p2 U p; (52) 196 By induction on (35), (50), (38), (51) and (52) there exist \nS2 and v; such that S1, VE + R (ej) -+ v~, s2 (53) Consistent(R, K , VZ, SZ, vi) w.r.t. pi (54) Let TE~ \n= TEO + {z. w ~ }. By (46) there exists a Wh such that Y% L PO and TE~l-eO*e~:P,P~ (55) By Lemma 4.1 \non (47) and p~ ~ PO we have Consistent(R, TEO, Eo, S2, VEO) w.r,t. p~ U p (56) and by Lemma 4.1 on (54) \nand p~ Q PO we get Consistent(R, p , V2, S2, vi) w.r.t. pi U @ (57) Let E; = E.+ {z. H V2} and let VE~ \n= VEO+{z. H vj}. Combining (56) and (57) we get Consistent(R, TE~, E;, S2, VE~) w.r.t. p~ U p (58) iiko, \nby (24) and s c S2 we get R connects p~ Up to S2 (59) and by (48) R. and R agree on p; Up (60) Then by \ninduction on (55), (58), (39), (59) and (60) there exist s and v such that S2, VE~ F Ro(e{) ~ v , s (61) \nConsistent(R, ~, v, s , v ) w.r.t. @ (62) But by (49) we have Ro(e{) = e~ so (61) reads S2,VE0 + {z. \n~ V2} k e~ -v , s (63) From (43), (45), (53) and (63) we get s,VE + R (ej ej) ~ v , s (64) which together \nwit h (62) is the desired result. 5 Strengths and weaknesses In Standard ML[24], recursive functions \ncannot be used polymorphically within their own declaration. At first sight, our translation rules resemble \nthe Mil\u00adner/Mycroft calculus [26], in which recursive functions can be used polymorphically within their \nown body. The type-checking problem for the Milner/Mycroft is equivalent to the semi-unification problem[12, \n1], and semi-unification is unfortunately undecidable [17]. fib(15) Thecomputation of the15th Fibonacci \nnumber bythe ``naive'' method (e.g. [16, page 235] ). The computation of fib(n) requires number of function \ncalls which is L exponential in n. Sum(loo) Here sum(n) computes the sum X~=l Z, by n recursive calls, \nnone of which are tail sumit (100) As above, but the sum is computed iteratively, by n tail recursive \ncalls. hsumit (100) As above, but computed by folding the plus operator over the list [1, ... 100]: \nfoldr (op +) O [1, . . ,100]; acker(3, 6) Ackermann s function, as defined in [16, page 239], except \nthat our version is not d. ackerMon (3,6) As above, but with Ackermann s function made region monomorphic. \n appell(100) A program, which Appel discusses in his chapter on space complexity [2, page 134] : fun \ns(0) = nil I s(i) = O :: s(i-1) fun f (n,x) = let val z = length(x) fun go = f(n-1, s(100)) in if n=O \nthen O else go end val result = f(lOO, nil); F Same as appell, but with go replaced by go + 1. (Discussed \nby Appel[2, page 135] A variant of the appeli obtained by in-lining g and making f region monomorphic. \n(Not present in Appel s book.) Generation of list of n random numbers, followed by Quicksort (from Paulson[27, \npp. 96 98] .) Figure 4: Test programs In a technical report [31] we describe an inference al-can be \nupdated destructively. This helps to get a good gorithm which appears to be sound with respect to the \nhandling of tail recursion. One more optimization is rules in this paper and appears always to terminate. \nmentioned in Appendix B. These were the only opti\u00ad(This rather weak statement due to the fact that we \ndo mization performed. not have a proof, as yet. ) We know of examples (all of The quantities measured \nwere: which involve subtle uses of region polymorphism) for which the algorithm finds a compound type \nscheme (1) Maximal depth of region stack (unit: one region) which is not the most general one permitted \nby the (2) Total number of region allocations translation rules. The practical implications of this situation \nare discussed at the end of this section. (3) Total number of value allocations The algorithm has been \nimplemented. The imple\u00admentation also handles pairs, lists, and conditionals, (4) Maximum number of \nstorable values held (unit: 1 so that one can write non-trivial programs. We wrote SW)roughly 1500 lines \nof test programs. After translation, the target programs were run on an instrumented in\u00ad (5) Number \nof values stored in the final memory (unit: terpreter, written in Standard ML. No garbage collec\u00ad 1 SW) \ntor was implemented. The purpose of the experiments was to understand memory behaviour, not to estimate \nThe test programs in Figure 4 are representative of execution times. best and worst behaviour. The results \nare shown in After translation, the system performs a simple stor-the tables below. The numbers in the \nfirst column age mode analysis to discovers cases, where regions always refer to the the quantities enumerated \nabove. fib(15) Sum(loo) sum(n) quick (1000) I quick(5000) (1) 47 205 2n+5 (1) I 3,020 I 15,020 (2) 15,030 \n606 6n+6 (3) 15,030 606 6n+6 (4) 32 104 n+4  (5)1 11 w Notice that fib and sum used very little \nmemory, at the expense of very frequent region allocation and de\u00adallocation. From lines (2) and (3) we \nsee that the re\u00adgion analysis can be so fine-grained that there is a one\u00adto-one correspondence between \nvalues and regions. In the above examples, this is due to region polymor\u00adphism. The third column gives \nthe exact figures, as a function of n. These are obtained by inspection of the target program, which \nappears in Appendix B. sumit (100) hsumit (100) (1) 6 12 (2) 406 715 (3) 707 1,214 (4) 6 507 (5) 1 101 \n The results for swnit illustrate the behaviour on tight, tail-recursive loops. When computing sumit \n(n), the number of the highest region, namely 6, and the maximum memory size, also 6, are both independent \nof n. When we compute the sum by folding the plus op\u00aderator over the list (hsumit ( 100) ), all the results \nof the plus operation are put into one region, because the operator is a lambda-bound parameter of the \nfold op\u00aderation and hence cannot be region-polymorphic. In this case, however, the analysis of storage \nmodes does not discover that destructive updates are possible, so the final memory size is 101, of which \nonly one word is live. I acker(3,6) ackerMon(3, 6) (1) 3,058 514 (2) 1,378,366 1,119,767 (3) 1,378,367 \n1,550,599 (4) 2,043 86,880 (5)1 1 The strength of region polymorphism is illus\u00ad trated by the differences \nobserved between acker and ackerMon. The latter, where region polymorphism has been disabled, has a much \nlarger maximal memory size, 86,880, than the former, 2,043. quick(50) quick(500) (1) 170 1,520 (2) 2,729 \n45,691 (3) 3,684 65,266 (4) 603 8,078 (5) 152 1,502  r  A list occupies three regions: one for the \nelements, one for the constructors (cons and nil) and one for the pairs, to which cons is applied. Thus, \na list with n different integers is represented by 3n + 1 values. We see that, apart from one word, the \nfinal results are the only values left at the end of the computation.2 Also, the maximal number of regions \nallocated (line 1) is roughly the same as the number of values in the final result. The rat io between \nthe maximal memory size and the final memory size varies between roughly 4.0 and 5.5. appell (100) appe12(100) \ninline(100) (1) ] 911 I 1,111 \\ 311 The programs appel 1 and appe12 use @(lV2) space (line 4), although \n~(~) ought to be enough, This is an example of a deficiency which our scheme has in common with the classical \nstack discipline: cre\u00adating a large argument for a function which only uses it for a small part of its \nactivation leads to waste of memory (see also Chase [5] ). inline ( 100) uses only ~(~) space, as the \nstorage mode analysis discovers that updates are possible. In cases where the algorithm infers a compound \ntype scheme which is not the most general one permitted by the translation rules, the implementation \ndetects the situation, prints a warning and completes the trans\u00adlation using a less general type scheme. \nAmongst our total supply of test programs, only those specifically designed to provoke the warning provoked \nit. Garbage collection If one wants to combine region allocation with garbage collection, dangling pointers \nare a worry. They can be avoided by adding the extra side-condition Yy ~ FV(Xr.e). frv(TE(y)) ~ frv(p \n) to rule 15. This affects the precision of the inference rules, but obviously not their soundness. 2The \none additional value sterns from the last iteration of the random number generator. \\ Conclusion The \nexperiments presented in this report suggest that the scheme in many cases leads to very economical use \nof memory resources, even without the use of garbage collection. They also reveal that region al\u00adlocation \nand de-allocation are very frequent and that many regions are small and short-lived. Regions with statically \nknown, finite size can be allocated on a hard\u00adware stack; small regions can in principle even be held \nin machine registers. Magnus Vej lstrup is workkig on inferring the sizes of regions. Lars Birkedal is \nwriting a compiler from region-annotated programs to C, to\u00adgether with a runtime system in C. In this \nsystem, a variable-sized region is represented by a linked list of fixed-size pages, which are taken \nfrom and returned to a free-list. Acknowledgments Ritz Henglein s expertise on semi-unification was \nmost helpful. Peter Sestoft contributed in essential ways to the storage mode analysis mentioned in Sec\u00adtion \n5. Lars Birkedal wrote parts of the current imple\u00admentation. Andrew Appel, David MacQueen, Flem\u00adming \nNielson, Hanne Riis Nielson, David Schmidt and David N. Turner contributed with discussions and valuable \ncriticism. This work is supported by Danish Research Council grant number 5.21.08.03 under the DART project. \nReferences [1] J. Tiuryn A. J. Kfoury and P. Urzyczyn. Type reconstruction in the presence of polymorphic \nrecursion. ACM Transactions on Programming Languages and Systems, 15(2):290 311, April 1993. [2] Andrew \nW. AppeL Compiling with Continua\u00adtions. Cambridge University Press, 1992. [3] Henry G. Baker. Unify and \nconquer (garbage col\u00adlection, updating, aliasing, ...) in functional lan\u00adguages. In Proceedings of the \n1990 ACM Con\u00adference on Lisp and Functional Programming, pages 218-226, June 1990. [4] H.G, Baker. List \nprocessing in real time on a serial computer. Communications of the ACM, 21(4):280-294, April 1978. [5] \nDavid R, Chase, Safety considerations for stor\u00adage allocation optimizations. In Proceedings of the SIGPLAN \n88 Conference on Programming Language Design and Implementation, pages 1\u00ad10, ACM Press, June 22-241988. \n[6] J. M. Lucassen D. K. Gifford, P. Jouvelot and M.A. Sheldon. FX-87 Reference Manual. Techni\u00adcal Report \nMIT/LCS/TR-407, MIT Laboratory for Computer Science, Sept 1987. [7] L. Damas and R. Milner. Principal \ntype schemes for functional programs. In Proc. 9th Annual ACM Symp. on Principles of Programming Lan\u00adguages, \npages 207 212, Jan. 1982. [8] Joelle Despeyroux. Proof of translation in natural semantics. In Proc. \nof the 1st Symp. on Logic in Computer Science, IEEE, Cambridge, USA, 1986. [9] E. W. Dijkstra. Recursive \nprogramming. Nu\u00admerische Math, 2:312 318, 1960. Also in Rosen: Programming Systems and Languages , McGraw-Hill, \n1967. [10] Michael Georgeff. Transformations and reduc\u00adtion strategies for typed lambda expressions. \nACM Transactions on Programming Languages and Systems, 6(4) :603 631, Ott 1984. [11] Barry Hayes. Using \nkey object opportunism to collect old objects. In Proceedings: Conference on Object-Oriented Programming \nSystems, Lan\u00adguages and Applications, Sigplan Notices, Vol 2?6, Number 11, 1991. [12] Fritz Henglein. \nType inference with polymorphic recursion. ACM Transactions on Programming Languages and Systems, 15(2):253, \nApril 1993. [13] Paul Hudak. A semantic model of reference counting and its abstraction. In ACM Symposium \non List and Functional Programming, pages 351 363, 1986. [14] Pierre Jouvelot and D.K. Gifford. Algebraic \nre\u00adconstruction of types and effects. In Proceedings of the 18th ACM Symposium on Principles of Programming \nLanguages (POPL), 1991. [15] Hiroyuki Seki Katsuro Inoue and Hikaru Yagi. Analysis of functional programs \nto detect run\u00adtime garbage cells. ACM Transactions on Pro\u00adgramming Languages and Systems, 10(4) :555 \n578, 1988. [16] ~ke Wikstrom. Functional Programming Using Standard ML. Series in Computer Science, Pren\u00adtice \nHall, 1987. [17] A. Kfoury, J. Tiuryn, and P. Urzyczyn. The undecidability of the semi-unification problem. \nIn Proc. 2?.2nd Annual ACM Symp. on Theory of Computation (STOC), Baltimore, Maryland, pages 468-476, \nMay 1990. [18] Donald E. Knuth. Fundamental Algorithms. Vol- Appendix A. Arrow effects ume 1 of The \nArt of Computer Programming, Addison-Wesley, 1972. The purpose of this appendix is to motivate the use \nof arrow effects of the special form c.p. The 6. has to [19] Henry Lieberman and Carl Hewitt. A real-time \ndo with type checking. Effects are sets. Having sets garbage collector based on the lifetimes of ob\u00ad \non the function arrow [14, 30] forces one to re-think jects. Communications of the ACM, 26(6):419\u00ad the \nuse of unification as the basic mechanism for type 429, June 1983. checking. [20] J. M. Lucassen. Types \nand Effects, towards the integration of functional and imperative program\u00adming, PhD thesis, MIT Laboratory \nfor Computer Science, 1987. MIT/LCS/TR-408. Milner s algorithm W[22] works on the following principle. \nLet e be an expression and let TE be a type environment giving the types of the free vari\u00adables of e. \nThen IV(TE, e) attempts to find not just a type 7 for e, but also a substitution S, such that [21] J.M. \nLucassen and D.K. Gifford. Polymorphic ef- S(TE) E e : I-. Informally speaking, the substitution fect \nsystems. In Proceedings of the 1988 ACM says how the types in the type environment must be Conference \non Principles of Programming Lan\u00ad refined in order to make e typable. guages, 1988. In effect systems \nan important form of type refine\u00ad [22] R. Milner. A theory of type polymorphism in programming. J. Computer \nand System Sciences, 17:348-375, 1978. ment is that of increasing an effect (under the order\u00ading of set \ninclusion). For example, consider the type checking of the expression Ah. if e then h else (k.z + 1) \n[23] Robin Milner and Mads To&#38;e. Co-induction in relational semantics. Theoretical Computer Sci\u00ad \nwhere we assume that e is an expression which con\u00ad ence, 87:209 220, 1991. tains an application of h. \nAssume for the moment that arrow effects are just effects. After the then [24] Robin Milner, Mads Tofte, \nand Robert Harper. branch has been analysed, the type environment might The Definition of Standard ML. \nMIT Press, 1990. contain the binding: {h H ((a, PI) L(D, PZ), p3)}. [25] F. L. Morris. Advice on structuring \ncompilers Next, the type of (kz.z + 1) might be inferred to be and proving them correct. In Proc. ACM \nSymp. ((int, p~) {getMhputOiJl >(int, f$), p~). We want on Principles of Programming Languages, 1973. \nthe unification of these types to refine the type of h [26] A. Mycroft. Polymorphic type schemes and \nre\u00ad to have the effect {get (pj ), put (pi ) } on the function cursive definitions. In Proc. 6th Int. \nConf. on arrow. Programming, LNCS 167, 1984. Talpin and Jouvelot [30] introduce effect variables to achieve \nthis. In their algorithm, one always has just [27] Laurence C. Paulson. ML for the Working Pro\u00ad an effect \nvariable on every function arrow. In addi\u00ad grammer. Cambridge University Press, 1991. tion, their algorithm \ninfers a set of constraints of the [28] Cristina Ruggieri and Thomas P. Murtagh. Life\u00adtime analysis of \ndynamically allocated objects. In Proceedings of the 15th Annual ACM Sympo\u00adsium on Principles of Programming \nLanguages, pages 285-293, January 1988. form e a p. Their algorithm then alternates between solving constraint \nsets and inferring types. Our arrow effects give a variation of their scheme which allows substitution \nto do all refinement without constraint sets. In the present system, under the assumption [29] Jean-Pierre \nTalpin. Theoretical and practical as\u00adpects of type and effect inference. Doctoral Dis\u00ad {h H ((a, pl) \n~(~, PZ), m)} the type of the then branch above is ((a, PI) -(~, pz), ps) and the type of the else branch \nis sertation. May 1993. Also available as Research Report EMP/CRI/A-236, Ecole des Mines de Paris. Unification \nthen gives a substitution on region and [30] Jean-Pierre Talpin and Pierre Jouvelot. Polymor\u00ad type variables, \nbut it also produces the effect substi\u00ad phic type, region and effect inference. Journal of t ution Functional \nProgramming, 2(3), 1992. S. = { cl ~ el.{get(p~), put(p~)}, [31] Mads Tofte and Jean-Pierre Talpin. A \nTheory of 62 ++ C1.{get(pi), Put(fi)}} Stack Allocation in Polymorphically Typed Lan- Thus the resulting \ntype of h in the type environment guages. Technical Report DIKU-report 93/15, is Department of Computer \nScience, University of Copenhagen, 1993. ((int, po {get(pi) put( P~)} ~(int, p~), p!) Appendix B. A \nlarger example The source program sum mentioned in Section 5 is letrec sum =Ax . if z=O then 1 else z+sum($-1) \nin sum(100) end It translates into the target program: letregion pI in letrec sum[pz,p31 at pl G (A \nZ:(int,pz). if letregion pd in letregion p5 in (x=(O at p5)) at p4 end end then 1at p3 else letregion \npb in (x+ ~etreg~on p7,p8 in s~m[~g,pb] at p7 letregion pg in (x-(1 at pg)) at p8 end end ) at P3 end \n) at PI in letregion pIo,pII in sum[pll, pol at p10 (100 at pIl) end end end Note that sum becomes region-polymorphic \nand that this region polymorphism is exploited inside the body ofsumitselfi regions p6andp8arelocalto \nthefunction body and are passed to the recursive call (pg holds the argument andp6 is where the result \nis to be placed). Note that the regions are allocated and de-allocated much as they would be in the classical \nstack discipline. In fact, we can count how many regions will be allo\u00adcated, as a function of n. For \nn = O, the maximal stack depth is 6 (po, PI, P1O, PH, P4 and P5). For n > 0, the maximal stack depth \nis 6 + 3n (the fac\u00adtor 3 stems from regions 06, P7 and m: 09 disappears before the recursive call). The \noptimization which we hinted at in Section 5 discovers that p7 and pIo can be de-allocated during the \ncalls they serve, bringing the maximal stack depth down to 2n + 5. 201 \n\t\t\t", "proc_id": "174675", "abstract": "<p>We present a translation scheme for the polymorphically typed call-by-value &#955;-calculus. All runtime values, including function closures, are put into <italic>regions</italic>. The store consists of a stack of regions. Region inference and effect inference are used to infer where regions can be allocated and de-allocated. Recursive functions are handled using a limited form of polymorphic recursion. The translation is proved correct with respect to a store semantics, which models as a region-based run-time system. Experimental results suggest that regions tend to be small, that region allocation is frequent and that overall memory demands are usually modest, even without garbage collection.</p>", "authors": [{"name": "Mads Tofte", "author_profile_id": "81100142765", "affiliation": "Department of Computer Science (DIKU), University of Copenhagen, Universitetsparken 1, DK-2100, Copenhagen &#248;, Denmark", "person_id": "PP39029504", "email_address": "", "orcid_id": ""}, {"name": "Jean-Pierre Talpin", "author_profile_id": "81100203844", "affiliation": "European Computer-Industry Research Center, (ECRC GmbH), Arabella Stra&#946;e 17, D-81925 M&#252;nchen", "person_id": "P136963", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/174675.177855", "year": "1994", "article_id": "177855", "conference": "POPL", "title": "Implementation of the typed call-by-value &#955;-calculus using a stack of regions", "url": "http://dl.acm.org/citation.cfm?id=177855"}