{"article_publication_date": "02-01-1994", "fulltext": "\n A Functional Theory of Local Names Martin Odersky Universitat Karlsruhe 76128 Karlsruhe, Germany oderskyQira.uka. \nde Abstract the ~-calculus [9]. However, Milner relies on names and processes alone, and requires an \nimplementation map\u00adping to recapture functional programming [8]. This im- Au is an extension of the A-calculus \nwith a binding con\u00adplementation is not fully abstract in that it invalidates struct for local names. \nThe extension has properties observational equivalences that hold in a purely func\u00ad analogous to classical \nA-calculus and preserves all ob\u00adtional programming language. servational equivalences of A. It is useful \nas a basis for modeling wide-spectrum languages that build on a func-By contrast, this paper presents \na syntactic theory for tional core. names that builds directly on (call-by-name) A-calculus. The basic \nidea is to generalize the notion of constant symbol already present in applied ~-calculus, by intro\u00adducing \nan abstraction vn.M that binds a name n. Con- Introduction stant symbols in classical applied ~-calculus \nthen be\u00ad come a special case of names that are not bound any-Recent years have given us a good deal \nof theoreti-where. The new calculus, Av, is pleasingly symmetric: cal research on the interaction of \nimperative program-Names can be bound just like placeholder identifiers in ming (exemplified by variable \nassignment) and function-~-abstractions, and both names and identifiers are sub\u00adal programming (exemplified \nby higher order functions) ject to a-renaming. The difference between the two lies [3, 6, 18,20, 23]. \nThe common method of all these works in the operations that can be applied to them. One can is to propose \na ~-calculus extended with imperative fea-substitute a term for an identifier, and one can compare tures \nand to carry out an exploration of the operational two names for equality, but not vice versa. semantics \nof the new calculus. In a sense, names are the greatest common denomina-Based on our own experience in \ndevising such an ex-tor of all programming languages that are not purely tended J-calculus [13], the \npresent work singles out the functional. Hence, one expects a theory that combines name, whose only observational \nproperty is its identity, names with A-abstractions to help in understanding de\u00adas an essential component \nof any such extension. We sign issues of wide-spectrum languages that build on a present a simple extension \nof the pure A-calculus with functional core. So far, the main results of this work names; we show by \nexamples how much of the flavor are: of imperative programming is captured by this simple extension, \nand we prove compatibility of the extended @ Names can be added to the A calculus in a refer\u00adcalculus \nwith the pure calculus in terms of both opera-entially transparent way. Full ~ remains a valid tional \nand denotational semantics. reduction rule. We are in good company; for instance Milner s Turing The \nresulting calculus, Av, is confluent and admits Award Lecture emphasizes naming as the key idea a standard \nevaluation function. The addition of names is fully compatible with * Most of this work was done while \nat Yale University. functional programming: Every observational Perrrission to copv without fee efl or \npart of this material is equivalence in A carries over to Av. This has im\u00ad grented provided that the \ncopies are not made or distributed for direct commercial advantege, the ACM copyright notice and the \nportant practical consequences. We are guaranteed title of the publication end its date eppear, and notice \nis given that every equational technique for verifying, trans\u00adthat copying is by permission of the AS60CifJtiOf? \nfor Computing forming, or compiling functional programs is also Machinery. To copy otherwise, or to republish, \nrequires e fee applicable to programs with local names. end/or epecific permission. POPL 94-1B4, Portiand \nOregon, USA ~ 1994 ACM O-69791 -636-01 94/Wl ..$3.50 The extension property also applies to denotational \nsemantics. There is a model of (simply typed) }V that is a conservative extension of the continuous function \nmodel of PCF. Related work. A theory with a scope close to Av has also been developed independently \nby Pitts and Stark [16]. The term languages of both theories are strikingly similar, but their operational \nsemantics are quite differ\u00adent. The nu-calculus of Pitts and Stark is intended to model names as they \narise in ML-style references, for instance. It is not intended to be a referentially trans\u00adparent extension \nof a functional core (this is discussed further in Section 2). Recent work on monads [10, 21,22, 15, \n5] shares with JV the motivation to extend functional programming lan\u00adguages to new application domains. \nMonads solve the problem of making sequencing explicit, which is needed if state is to be updated destructively. \nJv solves the or\u00adthogonal problem of expressing and encapsulating refer\u00adences. The two techniques complement \neach other well, as is shown in Example 3.2. Some of the more syntactic themes of this paper have also \nbeen addressed in the context of ~..r [13]. The present work extends the scope of [13] with an inves\u00adtigation \nof models for ~v. It also achieves considerable simplifications by isolating the treatment of names from \nall other issues of imperative programming. This sep\u00adaration of concerns helped simplify the (rather \nhard) proofs on the observational equivalence theories of the imperative language. For this reason, we \nhave based an extended version of the &#38;aT-report on Av [12]. The rest of this paper is organized \nas follows. Sec\u00adtion 2 describes term syntax and reduction rules of b. Section 3 presents two applications \nof local names, a type reconstruction algorithm and an implementation of state. Section 4 shows properties \nof Av, in particular its confluence and its standard evaluation order. Sec\u00adtion 5 discusses the observational \nequivalence theory of Av and shows that it is a conservative extension of the corresponding theory of \n}. Section 6 gives a denotation\u00adal semantics for ~v. Section 7 concludes. 2 The AV Calculus Terms. The \nterm-forming productions of Av are giv\u00aden in Figure 1. The three productions on the first line are those \nof classical, pure A-calculus. The three pro\u00adductions on the next line are particular to Av. Besides \nAbound identifiers there is a new, countably infinite al\u00adphabet of names. Names fall into two classes, \nglobal and local. A global name n is an atomic constant. We assume that there are two such constants \ndenoting the Boolean values true and ~cdse. A local name n is a name that is bound in a name abstraction \nvnv.M. In contrast to the case of A-bound identifiers, nothing is ev\u00ader substituted for a name. Rather, \nnames can be tested for equality, as in nl == n2. Both constants and local names can be operands of (==). \nWe study here an applied variant of b. Accordingly, we have on the last line productions for pairs (Ml, \nM2) and applied primitive operators p M. Primitive operators are always unary, but operators of greater \narity can be simulated by currying. We assume that at least the following operators are defined: pair? \n(Ml, Mz) = true pair? -= false name? n = true name ? . = false fSt (Ml, M2) = MI snd (Ml, M2) = M2 Notational \nconventions. We use J3V(M) and FV(M) to denote the bound and free identifiers in a term M, respectively. \nAnalogously, BIV(lkf) and FIV(iV) denote bound and free local names in a term M. A term is closed if \nFV(M) = FN(M) = 0. Closed terms are also called programs. Note that programs do not contain free local \nnames n , but they may contain constants. We use M s N for syntactic equality of terms (modulo a-renaming) \nand reserve M = N for convertibility. If R is a notion of reduction, we use ~ to express that M reduces \nin one R reduction step to N, and M ~ N to express that M reduces in zero or more R-steps to N. We also \nuse M ~ N to express that M reduces to N by contracting redex A in M. The syntactic category of values \nV comprises constants, names, pairs, and A abstractions. An obse? vable value (or answev) A is an element \nof some nonempty subset of the alphabet of constants. v ::= n I (M1, Mz) I kc.M Ac Answevs ~ Namesc \nA context C[ ] is a term with a single hole [ ] in it. C [M] denotes the term that results from replacing \nthe hole in (7[] with M. Following Barendregt [1], we take terms that differ only in the representatives \nof bound identifiers and names to Idents h-bound identifiers x E n E n= e nv 6 P= M e M ::= I I @ 6 eq \nZ-q VP Vn  Names = Namesc U Names names Names constants Names v-bound local names Primops primitive \noperators Au terms z I~x.M IMl Mz nlvn.MIMl==M, (MI, M,) I pM Figure 1: Syntax of Av (Xr.M) N + [N/z] \nM pv + 6(p,v) n==n -+ true n==m. -+ false (n # m) vn. Az. M 4 Ax.vn.M vn. (M1, M2) --+ (vn.Ml, vn.M2) \nvn.m -+m (n # m) Figure 2: Reduction rules for Jv be equal. That is, all terms we write are representa-ues \nV to terms. 6 can be arbitrary, as long as its result tives of equivalence classes of a-convertible terms. \nTo does not depend on the body of a an argument func\u00adavoid name capture problems in substitutions we \nre-tion, or the value of a local argument name. That is, strict ourselves to representatives in which \nbound and we postulate that for every primitive operator p there free identifiers are always distinct, \nand we employ the exist closed terms N: (c e Namesc ). N;, N: and N~,, same conventions for names. such \nthat for all values V for which 6(p, V) is defined: Reduction Rules. Figure 2 gives the reduction rules \nof Av. They define a reduction relation between terms in INP if V is a local name the usual way: we take \n(--t) to be the smallest relation 6(p,v)= N; if V is a A-abstractionA on Av x Av that contains the rules \nin Figure 2 and that, N~,,, Ml Mz if V E (Ml, M2) for any context C, is closed under the implication \nNote that all primitive operators are strict, since 6 re- M-+ N ~ C[M] -+ C[N]. quires its arguments \nto be values, Rule ~ is the usual reduction rule of pure A-calculus. The remaining rules of Figure 2 \nare particular to Av. Rule 6 expresses rewriting of applied primitive opera-Rule eq defines (==) to be \nsyntactic identity. Rule VA tors. To abstract from particular primitive operators says that v-and A-prefixes \ncommute. Rule VP says that and their rewrite rules, we only require the existence of v-prefixes distribute \nthrough pairs. Finally, rule Pm says a partial function 6 from primitive operators p and val-that a v-prefixes \nis absorbed by any name that differs 50 from the name bound in the prefix. Taken together, these rules \nhave the effect of pushing names into a term, thus exposing the term s outer structure and allowing it \nto interact with its environment. An important consequence of these rules is that the term vn. n cannot \nbe reduced further, but is not a value ei\u00adther, and hence cannot be decomposed or compared. In other \nwords, the identity of a name is known only within its (dynamic) scope. This does not restrict expressive\u00adness \nsince it is always possible to extend the scope of a variable by passing the rest of the computation \nas a continuation (see the examples in the next section). An Alternative. Instead of pushing v-prefixes \ninto a term, one might also consider to pull them out of a function application. I.e. rather than with \nthe v rules of Figure 2 one might want to work with the rules VL (zm.M1) M2 + zm. (M1 M2) ~R Ml (zm.M2) \n-+ zm. (M1 M2). These rules can be regarded as an axiomatization of gensym in Scheme. They closely correspond \nto the op\u00aderational semantics of the nu-calculus [16]. Rule VL is q-equivalent to rule VA. But adding \nrule v~ to the A calculus breaks the Church-Rosser property. For instance, (XZ.(Z, z)) (vn.n) reduces \n(with @ to (vn.n, vn.n) but also reduces (with v~ and then P) to vn. (n, n), and the two reducts do not \nreduce by ~vL VR to a common term. Hence, ~ needs to be abandoned if we want to have a confluent calculus \nwith VR. The difference between the the nu-calculus and Av can also be illustrated by looking at their \nreductions on the term (~z.z == z) (vn.n). With va and a suitably restricted /3-rule this reduces to \ntrue, while in Av this reduces to vn.n== vn.n, a term in normal form that is not a value (such terms \nare often called stuck ). Intuitively, reduction gets stuck since the value of a symbol is undefined \noutside its scope. This restriction is required to ensure that all equalities of the underlying A-calculus \nare preserved. Indeed, the preservation law even extends to all observational equiv\u00adalences (Theorem \n5.9). A Note on Church-Encoding Pairs. We have cho\u00adsen to make the pairing function (., .) a primitive \nterm constructor with associated primitive projections fst and snd. What would have happened if we had \nen\u00adcoded pairs as functions instead? The Church-encoding of pairs defines a pairing function P = Ax. \nAy.Af.j x y and associated projections 7rl = +2.p (k. Ay.z) T2 = Ap.p (Ady.y). The crucial question \nis what happens to VP, or, rather its Church-encoded form zm.P M N = P (m.M) (zm.iV). (1) It is easily \nverified that this not an equality derivable from the other reductions. On the other hand, if we apply \na projection ~i to each side of (1) then we do get an equality that is derivable from /3 and VJ. This \nis shown by some straightforward computation: ml (zm.P M N) = (by definition of ~1, P) (Ap.p (Atz.Ay.z)) \n(wz.Af.f M N) = (by /f?) (vn.~~.~ M N) (Az.Ay.z) = (by v,) (~~.vn.~ M N) (Az.Ay.x) = (by /?) zm. M = \n(by definition of rl, P and /3) ml (P (vn.M) (zm.N)) The case where the projection is Tz is completely \nanalo\u00adgous. In summary, the VP rule for Church-encoded pairs is subsumed by VA and ~, as long as pairs \nare used as intended (i.e. only projections are applied to them). 3 Applications To demonstrate how \nthe Av-extensions can be used in a functional programming language, we study two exam\u00adple applications: \na type reconstruction algorithm and an implementation of state transformers. We use a pro\u00adgramming notation \nthat extends Haskell with a new construct new n -> M, the ASCII form of zm. M. A name has type Name a, \nfor some type a, The typing rule rule for new is: ll.n:Namer k M:r l?tnewn->M:T data Id = String unify \n:: Type -> Type -> SubstTran a data Term . ID Id I AP Term Term I LAM Id Term unify tl t2 k s = case \nmgu (s tl) (s t2) of data TID . Name () Suc s > k (S . S ) data Type . TV TID I Type :-> Type Err -> \nErr dataE a . Suc a I Err tp :: TypeEnv -> Term -> Type type TypeEnv = Id -> Type -> SubstTran a type \nSubst . Type -> Type type SubstTran a = (Subst -> E a) -> Subst -> E a tp e (ID n) t = unify (e n) t \ntpe(APab)t =newn-> upd :: (a-> b) ->a->b->(a->b) tpea(TVn:-> t). upd f x a y = if y == x then a else \nf y tp e b (TV n) tpe(LAMxa)t= newn->newm-> mgu :: Type -> Type -> E Subst unify (TV n :-> TV IU) t . \n-\u00ad most general unifier; definition 1s left out tp (upd e x (TV n)) a (TV m) Figure 3: Type reconstruction \nalgorithm for the simply typed ~-calculus. Example 3.1 (Type Reconstruction) Type recon\u00adstruction algorithms \nfor polymorphically typed lan\u00adguages need to define fresh identifiers for type vari\u00adables on the fly \n. To this purpose, a name supply is usually passed along as an additional argument to the type reconstruction \nfunction. As an alternative, we present here a type reconstruction algorithm for the sim\u00adply typed ~-calculus \nthat replaces the name supply by bound Av names. The code for the type checkeris given in Figure3. Types \nare either variables fV n or function types t I : > t2. The identifying part n of a type variable TV \nn is a name (of type TID, which is a synonym for Name ()). The main function tp constructs aprooffor \nagoale 1-a:t, where e is a typing environment, a is a term, andt is a type. e, a and t are the first \nthree arguments of tp. Fresh names are created in the clauses of tp that have to do with function abstraction \nand application. tp is written in continuation passing style in order to extend the scope of names as \nfar as needed. Its result is a substitution transformer (of type SubstTran), which is a mapping that \ntakes a continuation and a substitution and yields either failure or succeeds with some result type that \nis determined by the continuation. Example 3.2 (St ate Transformers) Using state-transformers, one can \nwrite imperative pro\u00adgrams in a functional programming language, by treat\u00ading an imperative statement \nas a function from states to states (and, possibly, intermediate results). State trans\u00adformers can be \nclassified according to whether they are global or local, and according to whether state is fixed or \ndynamic. [21] and [22] describe local state-transformers that can be embedded in other terms and that \noperate on a ,fized state data structure. By contrast, [15] describes global state-transformers that \nact as the main program and thus cannot be embedded in another term. State in [15] is dynamic, i.e. it \nconsists of a heap with dynamically created references. Figure 4 shows an implementation of local state\u00ad \ntransformers with dynamic state. This is to my knowl\u00adedge the first fully formal treatment of this class \nof state\u00adtransformers, even if [4] and [5] contain similar informal proposals. State is represented as \na polymorphic function from names of type Name a to terms of type a. Its type is: all a.Neme a > a A \nstate-transformer of type ST a is a function that takes a continuation and a state as arguments, and \nreturns the result of the continuation. Its type is: all b. (a -> State -> b) -> State -> b Note that \nthe polymorphic types of state and state transformers exceed the capabilities of first-order type syst \nems such as Haskell s or ML s. However, an efficient implementation of state transformers would treat \ntype type type State ST a = = all all a. b. Name a -> a (a -> State -> b) -> State -> b -- Monadic Operators: \n-- State-Based Operators: return (>>=) pure ::a :: :: -> ST a STa->(a->STb)->ST STa->a b newref (:=) \nderef :: ,,. . :: ST (Name a) Name a -> a -> Name a -> ST a ST () return (p>>=q) pure p bot a k s ks \n=kas = p(\\x->qxk)s = p (\\X > = bot \\S > X) bot neuref (n:=a) deref upd s n n x ks= ks= ks= n = new n \n-> k n s k () (upd s n a) k(sn)s if n == a then x else s 10 Figure4: State Transformers ST aasanabstract \ndatatype andwould hide type state altogether in order to guarantee that state is single\u00ad threaded. Such \nan implementation could do with just ML-style let-polymorphism. State transformers form a Kleisli monad, \nwith return as the monad unit, and with infix (>>=) as the bind op\u00aderator. If we leave out the redundant \nstate parameter s this is just the standard continuation monad. The result type of a continuation is \nan observer of type State -> a (as in [20]). Function pure, of type ST a -> a, allows one to get out \nof the ST monad. pure runs its state transformer argu\u00adment in an empty initial state with a continuation \nthat yields its first argument as answer. The remaining operations access state. newref returns a freshly \nallocated reference as result. Its implementa\u00adtion is based on u-abstraction. (n : = a) updates the state, \nreturning the unit value as result, while deref n returns the current value of the state at reference \nn. This concludes our first implementation of state in Av. It is perhaps surprising how simple such an \nimplementa\u00adtion can be, once the problem of expressing local names is taken care of. However, one could \nargue that we have oversimplified, in that the implementation of Figure 4 does not really describe state! \nIndeed, there are two trouble-spots. The first problem is caused by the fact that the state ar\u00adgument \ns is not linear in the definition of deref. There\u00adfore, access to state is only single-threaded if the \nappli\u00adcation s n in the body of deref gets resolved before control is passed to the continuation. But \nnothing in the implementation forces this evaluation order! One could solve the problem by making continuations \nstrict in their first argument. However, this forces s n to be reduced to a value, which is needlessly \ndrastic. To en\u00adsure single-threadedness, it is enough to just perform the function application without \nfurther evaluation. Another problem concerns the meaning of readers and assignments that involve names \nfrom some outer block. In the implementation of Figure 4, such accesses are not errors. Instead, the \nread or write is performed on a lo\u00adcally allocated cell that is named by the non-local name. Therefore, \nthe same name might identify several loca\u00adtions in different states. This approach, which is similar \nto the semantics of state in [19], is perfectly acceptable from a theoretical standpoint. But it raises \nsome imple\u00admentation problems, since it prevents the identification of names with machine addresses. \nBoth problems are solved by a slightly more refined im\u00adplementation that marks stored terms with a data \ncon\u00adstructor. We modify the type of state as follows: type State =alla, Nsmea->Da data Da =Da The implementation \nof the state-based operators then becomes: nmiref Ks = newn > k n (upd s n (D bottom)) (n := a)ks= case \ns n of Confluence Db->ko(updsn (Da)) deref n k s = case s n of We show in this section analogues for \nAu of the Finite Da->kas Developments and Church-Rosser theorems for the J\u00ad calculus. In the new implementation, \nbody of deref forces s n to is passed to the case-branch. the case construct be evaluated before This \ntakes care of in the control the first Definition labeled reduction 4.1 redexes rules Let AOV (Aoz.M) \nbe the N and extension p. V and of with Av with labeled problem. Moreover, both readers and that an entry \nfor the accessed reference local state, and newref allocates such writers require exists in the an entry \nfor a Po : &#38; : ( A@.A q Po v N + -+ [N/2J] M 6(p, v). freshly created reference. This takes care \nof the second problem. The contribution of ~v to this implementation is rather subtle. It consists of \nthe v-abstraction in the code of newref and the equality test in function upd. Never\u00adtheless, the presence \nof local names is important for modeling dynamic local state in a simple way. To see this, let s try \nto model local state without local names, by representing heaps as arrays with references as in\u00addices, \nsay. Now, any implementation of local state has to distinguish between variables that are defined in \ndif\u00adferent pure-blocks. This is necessary to guard against access to non-local variables and against \nexport of lo\u00adcal variables out of their block, both referentially opaque operations. A straightforward \nscheme to distinguish be\u00adtween variables defined in different blocks would pass a name supply to each \nblock, such that the block, and all the variables defined in it, can be tagged with a unique identifier. \nThe problem with this scheme is that it has a poisoning effect on the environment that surrounds a block. \nEach function now has to pass along name\u00adsupply arguments even if the function itself does not contain \npure-blocks as subterms. It is not clear what is gained by this method over a program that contains a \nsingle, global state, and hence is imperative all the way to the top.  Reduction This section details \nthe fundamental laws of Av\u00adreduction: reduction is confluent and there is a standard evaluation order. \nThe treatment largely follows [1], and we assume that the reader is familiar with some of the more fundamental \ndefinitions and theorems given there. Most of the proofs in this and the following chapters are sketched \nor left out; for a more detailed treatment, see [11]. Let ~ be the reduction relation generated by PO, \n60, eq, VA, VP) Vn. Theorem 4.2 (Finite Developments) ~ is strongly normalizing. Proof: The proof is \nsimilar to the proof of finite de\u00advelopments in the pure ~ calculus ([l], CH.ll, \\2). We construct a \nfamily of non-negative decreasing weighi\u00adngs and show that each reduction step maps a term with a decreasing \nweighting to a term with a smaller decreasing weighting. Theorem 4.3 The notion of reduction in ~v is \nChurch- Rosser: if M -+ Ml and M + M2 then there is a term M3 s.t. Ml -+ M3 and M2 -+ M3. Proof: Using \na case analysis on reduction rules, cou\u00adpled with a case analysis on the relative position of redexes, \none shows that the notion of reduction 6V is weakly Church-Rosser and commutes with ~. Then by Theorem \n4.2 and Newman s lemma ([l], CH.3,jl) 6V is Church-Rosser, and together with the lemma of Hind\u00adley/Rosen \n([1] ,CH.3, 33) this implies the proposition. Evaluation As programmers, we are interested not only in \nproving equality of terms, but also in evaluating them, i.e. re\u00adducing them to an answer. We now define \na computable evaluation function that maps a term to an answer A iff AU 1-M = A. Following Felleisen \n[2], the evalua\u00adtion function is defined by means of a context machine. At every step, the machine separates \nits argument term deterministically into an evaluation context and a redex and then performs a reduction \non the redex. Evaluation stops once the argument is an answer. Evaluation con\u00adtexts for Av are defined \nas follows: E ::= []1 EM IPE/vn.E (2) The first three clauses generate evaluation contexts for the applied \ncall-by-name A-calculus, whereas the last clause is particular to Av. Definition. Thedeterministic reduction \nrelation~on terms in Avis the smallest relation that satisfies M-%N * E[M]~E[N]. A simple inspection \nof the productions for E establishes that ~ is indeed deterministic: Proposition 4.4 For any redexes \nAl, A2 and evalua\u00adtion contexts El, E2, El[Al] a E2[A2] + El a E2 AAl s A2. A redex A is a head redez \nof a term M if M E E[A], for some evaluation context E, A redex that is not head redex is called an internal \nrede~. Reduction of internal redexes keeps head and internal redexes separate, in the sense of Lemma \n4.5 Let M be a program s.t. M ~ N where A is an internal redex of M. Then, (i) If N has a head redex \nthen so has M, (ii) the residual of M s head redex is head redex in N, (iii) the residuals of every internal \nredex in M are in\u00ad ternal redexes in N. Theorem 4.6 (Correspondence) For every program M c AU and every \nanswer A, M+ AwM--j+A. Proof: Direction + follows immediately. To prove + , assume that M ~ A. One shows \nfirst as an inter\u00admediate result that, whenever M + A, there is a term N s.t. M ~ N ~ A, where the reduction \nsequence N ~ A from N to A consists of only internal reduc\u00adtions. This result corresponds to the main \nlemma for the Curry /Feys standardization theorem ([l], CH.11,$4) and has exactly the same proof. That \nproof uses only the theorem of finite developments (Theorem 4.2 for b) and a lemma equivalent to Lemma \n4.5. The proposition then follows from the observation that no internal Jv re\u00adduction ends in an answer, \nhence we must have N z A.  5 Observational Equivalence Observational equivalence is the most comprehensive \nnotion of equivalence between program fragments. Intu\u00aditively, two terms are observationally equivalent \nif they cannot be distinguished by some experiment. Experi\u00adments wrap a term in some arbitrary context \nthat binds all free identifiers and local names in a term. The only observation allowed in an experiment \nis whether the resulting program reduces to an answer, and, if so, to which one. We define observational \nequiva\u00adlence for arbitrary extensions of applied J calculus. In the following, let T be an equational \ntheory that ex\u00adtends ~ and has term language Terms(T) and a set of answers Ans(7) C Namesc (7). We assume \nthat Namesc (7)\\ Ans(T) is infinite. Definition 5.1 Two terms M, N ~ Terms(T) are ob\u00adservationally equivalent \nin T, written T + M E N, iff for all contexts C in T erms(T) such that C[M] and C [N] are closed, and \nfor all answers A c Ans(T), 7 b C[M] = A~T1-C[N]=A. Proposition 5.2 The following are observational equivalences \nin Av: vn.vm.M Z um.vn. M (n # m) vn. M %M (n~FN(M)) Definition 5.3 T is an observational extension of \nTo if Terms(T) ~ Z erms(To) and, for all M ~ Terms(To), 70~MSN+T~MSN. The extension is conservative if \nthe implication can be strengthened to an equivalence. The main result of this section states that h \nis an ob\u00adservational extension of A. The proof relies on the con\u00adstruction of a syntactic embedding from \nAv to A. Syn\u00adtactic embedding were first defined in [13]; we use here the following, simplified definitions. \nDefinition 5.4 Given an inductively defined term lan\u00adguage Terms, an extended term is formed from the \nin\u00adductive definitions of Terms and []. (Hence, both terms and contexts are extended terms). Definition \n5.5 A term M is J-closed iff FV(M) = 0. M may contain free occurrences of local names. Definition 5.6 \n(Syntactic Embedding) Let 7 and 70 be extensions of J such that Terms(T) ~ Terms(To) and Ans(T) = Ans(To). \nLet &#38; be a syntactic mapping from extended T-terms to extended To-terms. Then &#38; is a syntactic \nembedding of T in To if it satisfies the following two requirements. 1. ~ preserves Xclosed To-subterms. \nFor all T\u00adcontexts C, ~-closed To-terms M, 70 E &#38;[c[M]]=&#38;[c][ikt]. 2. 8 preserves semantics. \nFor all closed T-terms M, answers A, 7t-M=A+70t-&#38;[M]=A. Theorem 5.7 Let T and To be extensions of \nA such that Z emns( T) ~ Tem-ns(To) and Ans(T) = Ans(70). If there is a syntactic embedding of T in TO \nthen T is an observational extension of To. The next lemma was shown in [11]. Lemma 5.8 There exists \na syntactic embedding of Av in A. Together with Theorem 5.7, this implies: Theorem 5.9 b is a conservative \nobservational exten\u00ad sion of A. Proof: By Lemma 5.8, $ is a syntactic embedding of Av in A. By Theorem \n5.7 this implies that Av is an observational extension of A. That the extension is conservative follows \ndirectly from the observation that Av-convertibility is a conservative extension of A convertibility. \n 6 Denotational Semantics We develop a denotational semantics for a typed version of Jv that results \nfrom adding v-abstractions to PCF terms. The semantics is an extension of the continuous function model \nfor PCF [17]. In that sense, it follows the spirit of previous sections, where Jv was studied as an extension \nof ~-calculus, rather than as a theory of its own. We use a possible worlds semantics [14], where a world \nis characterized by a finite set of names. Intuitively, these are the names available for program evaluation. \nAs a new twist, the meaning of the term vn.M in a world W is the intersection of the meaning of M in \nall possible worlds that extend W with a new suitable location. A location is suitable if it does not \nclash with locations used in other parts of the program. Instead of trying to trace these locations explicitly, \nwe simply choose the best) co-finite set L of possible candidate locations inthe information ordering. \nI.e. It is a consequence of Theorem 6.6 that the least upper bound always exists. The meaning of all \nother con\u00adstructs is the same as in PCF. Example 6.1 The meaning of vn.n is bottom: [won] P = u~.@..f..(me)e) \n(16L z =L This corresponds to the term vn.n being stuck in the reduction semantics. It reflects on the \nfact that the identity of a name is known only within its scope. Example 6.2 The meaning of vn.vm.n == \nm is false. Indeed, [zm.vrn.n == m] p = (_JK nk.KUL nz.L~=z COf~~(Name). If K, k, and where K and L range \nover p L are chosen, then nle~ k = 1 is either 1 (if k e L) or false (if k + L). Hence, for any given \nK and k, the value of l_jLEPcOtl.(~a~ej (ll.L k = 1 is false. But this implies [vn. vm.n == m] p = false. \n In the rest of this section, we make these notions precise. In particular, we need to give a semantic \ncharacteriza\u00adtion of the functions that belong to a world W infor\u00admally, these are the functions that \naccess only locations in W. We also have deal with the fact that the lub of a chain of functions that \naccess strictly increasing sets of locations accesses an infinite number of locations, and hence is not \na member of any world. As a consequence, our domains form a locally complete partial order (icpo) [7] \nrather than a cpo. We base our discussion on a typed version of Av, given by the typing rules in Figure \n5. We also assume the usual constants and operations of PCF, without listing their typing rules explicitly. \nDefinition 6.1 Let Name be a countably infinite set of names, and let m, n e Name. The ezclu.mge Xm,n \nis the unique logical relation such that for names z, y, zX~,~Y u m==z Ay=n V m,=y Az=nv m#z=y #n, for \nelements of other ground types, x Xm,n y e X=y, and such that 1 Xm,n l-. (ID) (NAME) 17, n: Name 1-n \n: Name (ABS) (NU) I , n: Name 1\u00ad M:r I 1-vn.M:r PI- M:u-+T I FN:u 17t M: Name I FN: Name (APPL) (EQ) \nrt-MN:~ 17t M== N: Bool Figure 5: Typing Rules for Av (NAME) [1 , n: Name D n :Name] p = pn (NU) [r \nD vn.M : 7-] p = UL6pc0f*m(Na7ne)nt,~ [r, n:Name D M: T] p[n H 1] (EQ) [1 PM== N: Bool]p = [1 DM:Name]p= \n[r PN:Name]p Figure 6: Semantic Function ~.] Exchanges have the property that they are closed under intersections \nand unions: Lemma 6.2 (i) If, for all i ~ 1, AZ X~,n B,, then A; X~,n  n (w ieI i&#38;I (ii) If {AZ \nI i c 1} and {B, I i e 1} are directed sets and for all i c I, Ai X~,n B,, then iel id Definition 6.3 \nThe smooth set of a value z e D, smooth(z) = {m : Name 13L ~ pcO~in(Name). Vn cL. zXm,n z}. The support \nof z is the complement of its smooth set, support(z) = Name \\ smooth(z). Informally, suppmt(z) is z if \nz is a name, and is the set of names accessed by x if x is a function. A character\u00adization of suport \nand smooth that is easier to use in proofs is given by: Lemma 6.4 m c smooth(z) * Vn ~ smooth(z). z Xm,n \nz. This equivalence cannot be used to define smooth, how\u00adever, since its right hand side is not monotonic \nin smooth(z). Example 6.3 The support of the name n is {n). The support of the function f ~t Az. x == \nm is {m]. This can be derived as follows: Let n be any name differ\u00adent from m. Then m Xm,. n. But ~m \n# ~n, which proves 7( f Xm,n f ) and hence shows that m is not in smooth(f). On the other hand, let k, \n1 be ar\u00adbitrary names different from m. It is easy to check that ~ Xk,l ~. Hence, by Lemma 6.4, smooth(~) \n~ Name\\{ m}. In summary, smooth(f) = Name\\{ m}, and hence support(f) = {m}. Definition 6.5 For type r \nand finite name set W, the domains [~] ~ and [T] are defined as follows: [Name]w = VVl. For all other \nground types o, [o] ~ is the usual in\u00ad terpretation of o in PCF. [(J -+ T]w = {f : [0] A [T] j Suppo? \nt(f) g w}, 7 Conclusions where D ~ E denotes the locally continuous func\u00adtions from D to E. We have studied \nreduction semantics, observational equivalence theory and denotational semantics of }v, [~1 = a theory \nfor functions that create local names. Each of Uw,pqvame)udw these three equational theories for ~v \nis a conservative The interpretation of Av terms is defined in Figure 6. extension of the corresponding \nstandard theory for A Let 17 be a set of type hypotheses and let W be a finite (respectively PCF). Avis \nin that sense fully compatible set of names. A (l_ , W)-environment is a function p with functional programming. \nThere is also good evi\u00adon identifiers and names that maps each identifier z ~ dence that it is a useful \nfoundation for modelling many dom(l?) to a value in [I (z)], and that maps each name constructs that \nso far were outside the domain of func\u00adn c dom(I ) to a unique name in W. The semantic tional programming. \nFor instance, Example 3.2 shows function [o] takes as arguments a type judgement r D how imperative programming \nwith mutable local vari- M : ~ and a (17, W)-environment p. It yields a value in ables can be expressed \nin Av. It would be interesting to [T]~. see other applications of the calculus, such as in logic or concurrent \nprogramming. Theorem 6.6 For all valid type judgments 17 1-M : ~, finite name sets W and (I , W)-environments \np, Acknowledgements This work was supported in part by grant NOO014-91-J-4043 from DARPA. I thank [r \nFM: T]pe[T]w. Vincent Dornic, Paul Hudak and Dan Rabin for their comments on earlier versions of the \npaper. Dan Rabin Proof: A standard induction on type derivations. The in particular helped to improve \nits presentation consid\u00adfollowing lemma is needed for the abstraction case. erably. John Launchbury, \nJayadev Misra, David Turner and Phil Wadler also commented on this work in helpful discussions. Lemma \n6.7 Let m,n e Name. Let I t-M :~ be a valid type judgement. Let p, p be (I , W) environments such that, \nfor all z e dom(I ), p z X~,~ p z. Then References [rD&#38;f:T]pXm,. [rb&#38;.f:~]p . [1] H. P. Barendregt. \nThe Lambda Catculus: its Syntax Theorem 6.8 [.] defines a computationally adequate and Semantics, volume \n103 of Studies in Logic and the model of W. Fozmdations of Mathematics. North-Holland, Amster\u00addam, revised \nedition, 1984. PToof: One verifies easily that all reductions in ~v are [2] E. Crank and M. Felleisen. \nParameter-passing and the equalities in the model. To show adequacy, we adapt lambda-calculus. In Proc. \n18th A C34 Symposium on Plotkin s adequacy proof for PCF [17]. Say M is com- Principles of Programming \nLanguages, Orlando, Flori\u00ad putable if one of conditions (l)-(4) holds. da, pages 233-244, January 1991. \nM+A. (1) M is closed of ground type, and [M]= [A] implies [3] M. Felleisen and R. Hleb. The revised report \non the (2) M is closed, of type u + ~, and M N is computable syntactic theories of sequential control \nand state. The\u00ad for all closed, computable terms N of type a. oretical Computer Science, 103:235 271, \n1992. (3) z : ~ is free in M, and [N/z]M is computable for all closed, computable terms N of type T. \n[4] P. Hudak and D. Rabin. Mutable abstract datatypes (4) n.: Name is free in AK, and vn.M is computable, \n-or how to have your state and munge it too. Re- Using structural induction on M, one shows that every \nsearch Report YALEU/DCS/RR-914, Yale University, term in Av is computable, which implies the proposition. \nDepartment of Computer Science, July 1992. [5] J. Launchbury. Lazy imperative programming. In The model \nseems to be rather close to the observational SIPL 93 ACM SIGPLAN Workshop on State in Pro\u00adequivalence \ntheory of Av, even if the question whether it is fully abstract is still open. For instance, adaptations \ngramming Languages, Copenhagen, Denmark, pages of the equivalences of [7] to the simpler setting of Av \n46-56, June 1993. Yale University Research Report can all be validated. YALEU/DCS/RR-968. [6] I. Mason \nand C. Talcott. Axiomatizing operational equivalence in the presence of side effects. In IEEE Symposium \non Logic in Computer Science, pages 284\u00ad303, Asilomar} California, June 1989. [7] A. R. Meyer and K. \nSieber. Towards fully abstract se\u00admantics for local variables: Preliminary y report. In Proc. 15th A \nCikl Symposium on Principles of Programming Languages, pages 191-203. ACM, ACM Press, January 1988. [8] \nR. Mdner. Functions as processes. Rapport de Recherche 1154, INRIA Sophia-Antipolis, February 1990. [9] \nR. Mdner. Elements of interaction. Communications of the A CM, 36(1):78 89, January 1993. Turing Award \nlecture. [10] E. Moggi. Computational lambda-calculus and mon\u00adads. In Proceedings 1989 IEEE Symposium \non Logic in Computer Science, pages 14-23. IEEE, June 1989. [II] M. Odersky. A syntactic theory of local \nnames. Re\u00adsearch Report YALEU/DCS/RR-965, Department of Computer Science, Yale University, May 1993. \n[12] M. Odersky and D. Rabin. The unexpurgated call\u00adby-name, assignment, and the lambda-calculus. Re\u00adsearch \nReport YALEU/DCS/RR-930, Department of Computer Science, Yale University, May 1993. [13] M. Odersky, \nD. Rabin, and P. Hudak. Call-by-name, call-by-value, and the lambda calculus. In Proc. 20th ACM Symposium \non Principles of Programming Lan\u00adguages, pages 43-56, January 1993. [14] F. J. Oles. A Category-Theoretic \nApproach to the Se\u00admantics of Programming Languages. PhD thesis, Syra\u00adcuse University, August 1982. [15] \nS. L. Peyton Jones and P. Wadler. Imperative func\u00adtional programming. In Proc. 20th A Clf Symposium on \nPrinciples of Programming Languages, pages 71 84. ACM Press, January 1993. [16] A. Pitts and I. Stark. \nOn the observable properties of higher order functions that dynamically create lo\u00adcal names. In SIPL \n93 A Cll SIGPLA N Workshop on State in Programming Languages, Copenhagen, Den\u00admark, pages 31-45, June \n1993. Yale University Research Report YALEU/DCS/RR-968. [17] G. D. Plotkin. LCF considered as a programming \nlan\u00adguage. Theoretical Computer Science, 5:223-255, 1977. [18] J. C. Reynolds. Preliminary design of \nthe programming language Forsythe. Technical Report CMU-CS-88-159, Carnegie Mellon University, June 1988. \n [19] J. G. Riecke. Delimiting the scope of effects. In Proc. Conf. on Functional Programming and Computer \nAr\u00adchitecture, pages 146 155, June 1993. [20] V. Swarup, U. S. Reddy, and E. Ireland. Assignments for \napplicative languages. In J. Hughes, editor, Func\u00adtional Programming Languages and Computer Archi\u00adtecture, \npages 192-214. Springer-Verlag, August 1991. Lecture Notes in Computer Science 523. [21] P. Wadler. Comprehending \nmonads. In Proc. ACM ~ Conf. on Lisp and Functional Programming, pages 61\u00ad78, June 1990. [22] P. Wadler. \nThe essence of functional programming. In Proc. 19th ACM Symposium on Principles of Program\u00adming Languages, \npages 1 14, January 1992. [23] S. Weeks and M. Felleisen. On the orthogonality of as\u00adsignments and procedures \nin Algol. In Proc. 20th AC&#38;l Symposium on Principles of Programming Languages, pages 57-7o. ACM Press, \nJanuary 1993. 59  \n\t\t\t", "proc_id": "174675", "abstract": "<p>&#955;v is an extension of the &#955;-calculus with a binding construct for local names. The extension has properties analogous to classical &#955;-calculus and preserves all observational equivalences of &#955;. It is useful as a basis for modeling wide-spectrum languages that build on a functional core.</p>", "authors": [{"name": "Martin Odersky", "author_profile_id": "81100056476", "affiliation": "Universit&#228;t Karlsruhe, 76128 Karlsruhe, Germany", "person_id": "PP14030830", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/174675.175187", "year": "1994", "article_id": "175187", "conference": "POPL", "title": "A functional theory of local names", "url": "http://dl.acm.org/citation.cfm?id=175187"}