{"article_publication_date": "08-31-2009", "fulltext": "\n Complete and Decidable Type Inference for GADTs Tom Schrijvers * Simon Peyton Jones Martin Sulzmann \nKatholieke Universiteit Leuven, Belgium Microsoft Research Cambridge, UK Intaris Software GmbH, Germany \ntom.schrijvers@cs.kuleuven.be simonpj@microsoft.com martin.sulzmann@gmail.com Dimitrios Vytiniotis Microsoft \nResearch Cambridge, UK dimitris@microsoft.com Abstract GADTs have proven to be an invaluable language \nextension, for ensuring data invariants and program correctness among others. Unfortunately, they pose \na tough problem for type inference: we lose the principal-type property, which is necessary for modular \ntype inference. We present a novel and simpli.ed type inference approach for local type assumptions from \nGADT pattern matches. Our approach is complete and decidable, while more liberal than previous such approaches. \n Categories and Subject Descriptors D.3.2 [Programming Lan\u00adguages]: Language Classi.cations Functional \nLanguages; F.3.3 [Logics and Meanings of Programs]: Studies of Program Constructs Type Structure General \nTerms Algorithms, Languages Keywords Haskell, type inference, GADTs 1. Introduction Generalized Algebraic \nData Types (GADTs) pose a particularly tough problem for type inference: we lose the principal-type prop\u00aderty, \nwhich is necessary for modular type inference (CH03), and it is even undecidable whether or not a term \nhas a principal type (Section 4.3). A variety of papers have tackled this problem, by a combination of \nuser-supplied type annotations and/or constraint-based inference (PVWW06; PRG06; SP07; SSS08). Unfortunately, \nnone of these approaches is satisfying, even to their originators, for a variety of reasons (Section \n9). Simonet and Pottier give an excellent executive summary in the closing sentences of their recent \npaper (SP07): We believe that one should, instead, strive to produce sim\u00adpler constraints, whose satis.ability \ncan be ef.ciently deter\u00admined by a (correct and complete) solver. Inspired by Pey\u00adton Jones et al. s \nwobbly types (PVWW06), recent work by * Post-doctoral researcher of the Fund for Scienti.c Research -Flanders. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP \n09, August 31 September 2, 2009, Edinburgh, Scotland, UK. Copyright c &#38;#169; 2009 ACM 978-1-60558-332-7/09/08. \n. . $5.00 Pottier and R\u00b4 egis-Gianas (PRG06) proposes one way of do\u00ading so, by relying on explicit, user-provided \ntype annotations and on an ad hoc local shape inference phase. It would be interesting to know whether \nit is possible to do better, that is, not to rely on an ad hoc preprocessing phase. This is the challenge \nwe meet in this paper. In particular, our contributions are: We present OutsideIn, a new inference algorithm \nfor GADT programs (Sections 4 and 5). It deals with the tricky problem of solving so-called implication \nconstraints (Section 4.2) by al\u00adlowing information to propagate from outside a GADT pattern match to \nthe inside, but not vice versa.  The declarative speci.cation of the type system is given in Sec\u00adtion \n6. While still not entirely satisfactory, is arguably signi.\u00adcantly simpler than earlier attempts. It \nis also rather expressive: it types strictly more programs than GHC s existing algorithm (PVWW06), and \nvery nearly all those typed by (PRG06) Section 9 elaborates.  Our type system has the crucial principal-types \nproperty; and any program accepted by our type system is also typed by the simpler natural type system \nfor GADTs, which lacks princi\u00adpal types. Furthermore, all programs typeable in our approach do have principal \ntypes in the natural type system for GADTs and hence our approach is not adhoc (Section 7.1). That is \nnot the case for either (PVWW06) or (PRG06).  The type inference algorithm is sound and complete with \nre\u00adspect to the speci.cation; and it is decidable (Section 7.2).  The type inference algorithm is easy \nto implement (Section 8). The inference engine gathers and solves constraints, but that is something \nHaskell compilers already do for type classes; all we do here is add some new forms of constraints. Nevertheless \ninference remains ef.cient, because almost all equalities can be solved with on-the-.y uni.cation in \nthe conventional Hindley-Milner way, with constraints gathered only when necessary. Our prototype implementation \nis available for download. Note: we have not yet implemented it in GHC, but expect to have done so before \nICFP.  Our approach builds directly on the work of others. We urge the reader to consult Section 9 for \na summary of these foundations.  2. The challenge we address Generalized Algebraic Data Types (GADTs) \nhave proved ex\u00adtremely popular with programmers, but they present the type in\u00adference engine with tricky \nchoices. Consider the following GADT program: data T :: *->* where T1 ::Int->TBool T2 ::[a]->Ta f1(T1n) \n=n>0 What type should be inferred for function f1? Alas there are two possible most-general types, neither \nof which is an instance of the other: f1 :: .a. T a . Bool f1 :: .a. T a . a The loss of principal types \nis both well-known and unavoidable (CH03). Since f1 has no principal type (one that is more general than \nall others) the right thing must be to reject the program, and ask the programmer to say which type is \nrequired by means of an explicit type signature, like this, for example: f1::Ta ->a f1(T1n) =n>0 But \nexactly which programs should be rejected in this way? For example, consider f2: f2(T1n) =n>0 f2 (T2 \nxs) = null xs Since null :: [a] -> Bool returns a Bool, and T2 is an or\u00addinary (non-GADT) data constructor, \nthe only way to type f2 is with result Bool, so the programmer might be confused at being required to \nsay so. After all, there is only one solution: why can t the compiler .nd it? An exactly similar issue \narises in relation to variables in the envi\u00adronment. Consider h1x(T1n) =x&#38;&#38;n>0 h1x(T2 xs) =nullxs \nWhich of these two incomparable types should we infer? h1 :: .a. a . T a . Bool h1 :: .a. Bool . T a \n. Bool Again, since neither is more general than the other, we should reject the program. But if we somehow \nknow from elsewhere that x is a Bool, then there is no ambiguity, and we might prefer to accept the de.nition. \nHere is an example h2x(T1n) =x&#38;&#38;n>0 h2x(T2 xs) =notx The key dif.culty is that a GADT pattern \nmatch brings local type constraints into scope. For example in the T1 branch of the de.ni\u00adtion of f1, \nwe know that the constraint a ~ Bool holds, where the second argument of f1 has type T a.1 Indeed, while \nthe declaration for the GADT T above is very convenient for the programmer, it is quite helpful to re-express \nit with an explicit equality constraint, like this2: data T :: *->* where T1 :: (a~Bool) => Int -> T \na --Was: T1 :: Int -> T Bool T2 ::[a]->Ta 1 We consistently use ~ to denote type equalities, because \n= is used for too many other things. 2 GHC allows both forms, and treats them as equivalent. Term variables \nx, y, z Type constructors S, T Type variables a, b, c Data constructors K Uni.cation variables a, \u00df, \n. Programs and data type declarations prog ::= dd1 . . . ddn; e dd ::= data Ta1...am where K :: . a1...am,b1...bn.C \n. t1 . ... . tp . Ta1...am Terms e ::= K | x | .x.e | ee | let {g = e} in e | let {g :: s = e1} in e2 \n| case e of [pi . ei]i.I Patterns p ::= Kx1...xn Type envt G ::= {x1 : s1, ..., xn : sn} Type variables \n. ::= a | a Monotypes t, . ::= . | t . . | Tt\u00af Type Schemes st |.\u00af ::= a.C . t Constraints C, D ::= \nt ~ t | C . C | E Impl. Constraints F ::= C | [\u00afa](.\u00afb.C . F ) | F . F Uni.ers . ::= \u00d8| ., {a := t}Substitutions \nf ::= \u00d8| f, {. := t} fuv(t )= The free uni.cation variables of t (and similarly fuv(G)) Substitution \nf(F1 . F2)= f(F1) . f(F2) f([\u00afa].\u00afb.C . F )=[fuv(f(\u00afa))].\u00afb.f(C) . f(F ) Substitution on C and t is conventional \nAbbreviations .\u00af a.E . t a.t.\u00af [\u00afa](.\u00afb.F ) [\u00afa](.\u00afb.E . F ) Figure 1. Syntax of Programs You may imagine \na value of type T t , built with T1, as a heap\u00adallocated object with two .elds: a value of type Int, \nand some evidence that t ~Bool. When the value is constructed the evidence must be supplied; when the \nvalue is de-constructed (i.e. matched in a pattern) the evidence becomes available locally. While in \nmany systems, including GHC, this evidence has no run-time existence, the vocabulary can still be helpful \nand GHC does use explicit evidence-passing in its intermediate language (SCPD07). 3. Formal setup Before \nwe can present our approach, we brie.y introduce our language, and the general form of its type system. \n 3.1 Syntax Figure 1 gives the syntax of terms and types, which should look familiar to Haskell programmers. \nA program consists of a set of data type declarations together with a term e. Terms consist of the lambda \ncalculus, together with let bindings (perhaps with a user-supplied type signature), and simple case expressions \nto perform pattern matching. A data type declaration introduces a type constructor T and one or more \ndata constructors Ki, each of which is given a type signature. As described in Section 2, in the case \nof  C, G f e : t C, G fp p . e : t . . K :: .\u00afC, G f e : t1 a.D . . (VAR) (x : .\u00aff = {a := t } (CON) \nf = {a := t} = f(D) (EQ) C |= t1 ~ t2 a..) . G C | C, G f x : f(.) C, G f K : f(.) C, G f e : t2 C, G \n.{x : t1}f e : t2 C, G f e1 : t1 . t2 C, G f e2 : t1 (ABS) (APP) C, G f .x.e : t1 . t2 C, G f e1e2 : \nt2 C, G .{g : t1}f e1 : t1 \u00afC, G .{g : .\u00af a = fv(t1) - fv(C, G) a.t1}f e1 : t1 (LET) C, G .{g : .\u00af(LETA) \na.t1}f e2 : t2 a.t1}f e2 : t2 C, G .{g : .\u00afC, G f let {g = e1} in e2 : t2 C, G f let {g :: .\u00af=a.t1 e1} \nin e2 : t2 \u00af K::.a,\u00afb.D . .1 . ... . .p . Ta\u00afC, G f e : t1 fv(C, G,t,tr) n \u00afb = \u00d8 f = {a := t } consistent(C \n. f(D)) (CASE) C, G fp pi . ei : t1 . t2 for i . I (PAT) C . f(D), G . f{x1 : .1,...,xp : .p}f e : tr \nC, G f case e of [pi . ei]i.I : t2 C, G fp Kx1...xp . e : Tt\u00af. tr C |= t ~ . (TRUE) (REFL) (SYM) C |= \nEC |= t ~ tC |= . ~ t C |= t1 ~ t2 C |= t2 ~ t3 (TRANS) C |= t1 ~ t3 C |= F1 C |= F2 (GIVEN) (CONJ) C1 \n. C2 |= C2 C |= F1 . F2 C |= ti ~ .i C |= Tt\u00afi ~ T.\u00afi (STRUCT) (TCON) C |= Tt\u00afi ~ T.\u00afi C |= ti ~ .i C \n. C1 |= F \u00afb n fv(C)= \u00d8 (IMPL) C |= [\u00afa](.\u00afb.C1 . F ) Figure 3. Equality theory GADTs the data constructor \ns type contains a set of constraints D, that are brought into scope when K is used in a pattern match, \nand required when K is used as a constructor. The syntax of types, and of constraints, is also given \nin Figure 1. Note that uni.cation variables a denote unknown types and only appear during type inference, \nnever in the resulting typings. To avoid clutter we use only equality constraints t1 ~t2 in our formal\u00adism, \nalthough in GHC there are several other sorts of constraint, in\u00adcluding implicit parameters and type \nclasses. We treat conjunction (.) as a commutative and associative operator as is conventional. Implication \nconstraints F will be introduced in Section 4.4.  3.2 Type system The declarative speci.cation of a \ntype system usually takes the form of a typing judgement G f e : t with the meaning in type environment \nG the term e has type t . In a system with GADTs, however, a pattern match may bring into scope some \nlocal equality constraints. The standard way to express Figure 2. Simple but over-permissive typing \nrules this is with the judgement C, G f e : t meaning in a context where constraints C are in scope, \nand type environment G the term e has type t . For example, here is a valid judgement: (a ~ Bool), {x \n: a, not : Bool . Bool}f not x : Bool The judgement only holds because of the availability of the local \nequality a ~ Bool. The type system of Figure 2 takes exactly this form. For example, rule (CON) instantiates \nthe type scheme of a data constructor in the usual way, except that it has the additional premise C |= \nf(D) This requires that the wanted constraints f(D) must be deducible from the given constraints C. To \nbe concrete we give the (routine) de.nition of |= in Figure 3. Compare rule (CON) to rule (VAR), where \nthe type scheme does not mention constraints. Rule (EQ) allows us to use the available constraints C \nto adjust the result type t1 to any equal type t2. Finally, a case expression uses an auxiliary judgement \nfp to typecheck the case alternatives. No\u00adtice the way that the local constraints C are extended when \ngoing inside a pattern match (in rule (PAT)), just as the type environment is augmented when going inside \na lambda-term (in rule (ABS)). Whenever we go inside a pattern match, we require the given constraint \nC . f(D) to be consistent, de.ned by the rule: .f. E |= f(C) (CONSISTENT) consistent(C ) i.e. C is consistent \nif it has a uni.er. Consistency implies that we will reject programs with inaccessible case branches. \nA second point to notice about rule (PAT) is that a data constructor \u00af may have existential type variables \nb as well as universal type variables a\u00af3. Rule (PAT) must check that the existential variables 3 The \nformer are called existential, despite their apparent quanti.cation with ., because the constructor s \ntype is isomorphic to K::.\u00afb.D \u00d7 .1 \u00d7 a.(.\u00af... \u00d7 .p) . Ta\u00af.  are not mentioned in the environment C, \nG, or the scrutinee type Tt, or the result type tr. In the following example, fx1 is well\u00adtyped, but \nfx2 is not because the existential variable b escapes: data X where X1 :: forall b. b -> (b->Int) -> \nX fx1(X1x f)=fx fx2(X1x f)=x  3.3 Properties The type checking problem for GADTs is decidable (CH03; \nSP07). However, type inference turns out to be extremely dif.cult. The example from Section 2 shows that \nGADTs lack principal types. The dif.culty is that the type system can type too many terms. Hence, our \ngoal is to restrict the type system to reject just enough programs to obtain a tractable type inference \nsystem which enjoys principal types. Nevertheless, we regard Figure 2 as the natural type system for \nGADTs, against which any such restricted system should be compared. 4. A new approach In this section \nwe describe our new approach to type inference for GADTs. Type system designers often develop a type \ninference algorithm hand-in-hand with the speci.cation of the type system: there is no point in a speci.cation \nthat we cannot implement, or an implementation whose speci.cation is incomprehensible. We begin with \nthe inference algorithm. 4.1 Type inference by constraint solving It is well known that type inference \ncan be carried out in two stages: .rst generate constraints from the program text, and then solve the \nconstraints ignoring the program text (PR05). The generated constraints involve uni.cation variables, \nwhich stand for as-yet\u00adunknown types, and solving the constraints produces a substitution that assigns \na type to each uni.cation variable. The most basic form of constraint is a type equality constraint of \nform t1 ~ t2, where t1 and t2 are types. For example, consider the de.nition data Pair :: *->*->* where \nMkP::a-> b->Pairab f=\\x-> MkP xTrue The data type declaration speci.es the type of the constructor MkP, \nthus: MkP : .ab. a . b . Pair ab Now consider the right-hand-side of f. The constraint generator makes \nup uni.cation variables as follows: a type of the entire right-hand side \u00dfx type of x .1,.2 instantiate \na, b respectively, when instantiating the call of MkP From the text we can generate the following equalities: \n\u00dfx ~ .1 First argument of MkP Bool ~ .2 Second argument of MkP a ~ Pair .1 .2 Result of MkP These constraints \ncan be solved by uni.cation, yielding the substi\u00adtution {a := Pair \u00dfx Bool,.2 := Bool,.1 := \u00dfx}. This \nsubsti\u00adtution constitutes a solution , because under that substitution the constraints are all of form \nt ~ t. Not only that, but the uni.cation algorithm .nds the most general substitution that solves the \ncon\u00adstraints. Temporarily leaving aside the question of generalization that s all there is to type inference \nfor ML. 4.2 Constraint solving with GADTs What happens when GADTs enter the picture? Consider our stan\u00addard \nexample term: \\x ->case xof {T1n->n>0} recalling the type of T1: T1 : .a.(Bool ~ a) . Int . T a Again \nwe make up fresh uni.cation variables for any unknown types: a type of the entire right-hand side \u00dfx \ntype of x Matching x against a constructor from type T imposes the con\u00adstraint \u00dfx ~ T., for some new \nuni.cation variable .. From the term n>0 we get the constraint a ~ Bool, but that arises inside the branch \nof a case that brings into scope the constraint . ~ Bool. We combine these two into a new sort of constraint, \ncalled an im\u00adplication constraint: . ~ Bool . a ~ Bool Now our dif.culty becomes clear: there is no most-general \nuni.er for implication constraints. The substitutions {a := Bool} and {a := .} are both solutions, but \nneither is more general than the other. On the other hand, sometimes there obviously is a unique solution. \nConsider f2 from Section 2: \\x ->casexof {T1 n->n>0;T2 xs->nullxs} From the two alternatives of the case \nwe get two constraints, respectively: . ~ Bool . a ~ Bool and a ~ Bool Since the second constraint can \nbe solved only by {a := Bool}, there is a unique most-general uni.er to this system of constraints. \n4.3 GADT type inference is undecidable Multiple pattern clauses give rise to a conjunction of implication \nconstraints DD (C1 . C1) . ... . (Cn . Cn) The task of GADT type inference is to .nd a substitution . \nsuch that each .(CiD) follows from .(Ci). This problem is identical to the simultaneous rigid E-uni.cation \nproblem which is known to be undecidable (DV95). Hence, we can immediately conclude that GADT type inference \nis undecidable in the unrestricted type system. To restore decidability and most general solutions, we \nconsider a restricted implication solver algorithm.  4.4 The OutsideIn solving algorithm Our idea is \na simple one: we must refrain from unifying a global uni.cation variable under a local equality constraint. \nBy global we mean free in the type environment4 , and we must record that information in the implication \nconstraint itself, thus [a](. ~ Bool . a ~ Bool) because a is free in the type environment. Here . ~ \nBool is a given equality constraint that may only locally be assumed to hold, i.e., to solve the constraint \nto the right of the implication sign: a ~ Bool. 4 We must treat the result type as part of the type environment. \n When solving this constraint we must refrain from unifying {a := Bool}; hence, the constraint by itself \nis insoluble. It can be solved only if there is some other constraint that binds a. The syntax of implication \nconstraints F is given in Figure 1. An implication constraint is an ordinary constraint C, or a conjunction \nof implications, or has the form [\u00afa].\u00afb.C . F . We call the set of uni.cation variables a\u00afthe untouchables \nof the constraint, and the set of type variables \u00afb the skolems of the constraint. Applying a substitution \nto an implication constraint requires a moment s thought, because an untouchable might be mapped to a \ntype by the substitution, so we must take the free uni.cation variables of the result; see Figure 1. \nWe often omit the untouchables, skolems, or C when they are empty. More precisely, to solve a set of \nimplication constraints F , proceed as follows: 1. Split F into Fg . Fs, where all the constraints in \nFg are proper implications, and Fs are all simple. An implication is simple if it does not involve any \nlocal equalities, and proper otherwise: Fg ::= Fg . Fg | [\u00afa].\u00afb.C . FC = E Fs ::= Fs . Fs | C | [\u00afa].\u00afb.E \n. Fs 2. Solve the simple constraints Fs by ordinary uni.cation, yield\u00ading a substitution .. 3. Now apply \n. to Fg, and solve each implication in .(Fg).  In the last step, how do we solve a proper implication \n[\u00afa].\u00afb.C . F ? Simply .nd f, the most general uni.er of C, and solve f(F ), under the restriction that \nthe solution must not bind a\u00af. This algorithm is conservative: if it .nds a uni.er, that solution will \nbe most general, but the converse is not true. For example, the algorithm fails to solve the constraint \n[a](. ~ Bool . a ~ Int) but the constraint actually has a unique solution, namely {a := Int}. 5. The \nOutsideIn approach in detail It is time to nail down the details. Our approach relies on constraint generation \nand constraint solving. We specify top-level constraint generation with G fW e : t, F to be read as: \nin the environment G, we may infer type t for the expression e and generate constraint F . Solving a \nconstraint F to produce a substitution . is speci.ed with fs F : .. The top-level inference algorithm \nis then given by the judgement finf in Figure 4.5 We start by discussing constraint generation (Section \n5.1) and con\u00adstraint solving (Section 5.2). Subsequently we present the high\u00adlevel declarative type system \n(Section 6). 5.1 Generating implication constraints The constraint generation algorithm is given in \nFigure 4 with the judgement G fW e : t, F In this judgement, thought of as an algorithm, G and e are \ninputs, while t and F are outputs. Rules (VAR), (CON), (ABS), and (APP) are straightforward. Rule (PAT) \ngenerates an implication constraint, as described infor\u00admally in Section 4.2. Rule (CASE) peeks inside \nthe pattern 5 We start with an initially-empty environment, informally relying on a .xed, implicit global \nenvironment to specify the types of each data con\u00adstructor. finf e : t fW e : t, F fs F : . (INFER) finf \ne : .(t) G fW e : t, F (x : .a.t\u00af) . G a fresh f = {a := a} (VAR) G fW x : f(t),E K :: .a.C\u00af. ta fresh \nf = {a := a} (CON) G fW K : f(t ),f(C) G fW e1 : t1,F1 G fW e2 : t2,F2 (APP) a fresh F = F1 . F2 . (t1 \n~ t2 . a) G fW e1 e2 : a, F a fresh G .{x : a}fW e : t, F (ABS) G fW .x.e : a . t, F G .{g : .\u00afe1 : t \nD,F1 a.t }fW G .{g : .\u00afe2 : ., F2 a.t }fW (LETA) F = F2 . [fuv(G)](.\u00af a.F1 . t ~ t D)) G fW let {g :: \n.a.t\u00af= e1} in e2 : ., F a fresh G .{g : a}fW e1 : t, F1 F1 D = F1 . a ~ tFs = simple(F1D) fs Fs : fs \n\u00df = fuv(fs(t )) - fuv(fs(G)) (LET) b fresh .k = {\u00df := b}G .{g : .\u00afb..k(fs(t))}fW e2 : ., F2 F = F2 . \n[fuv(G)].\u00afb..k(F1D) G fW let {g = e1} in e2 : ., F T = constructor(pi) for i . I G fW e : te\u00af ,Fe a, \n\u00df fresh (CASE) G fP pi . ei : Ta\u00af. \u00df, Fi for i . I V F = Fe . te ~ Ta\u00af. i.I Fi G fW case e of [pi . ei]i.I \n: a, F G fP p . e : t . ., F \u00af K::.\u00afb.D . .1 . ... . .p a a, . T \u00afb . ftv(G,tr) f = {a := t}(PAT) G . \nf{x1 : .1,...,xp : .p}fW e : te,Fe F =[a . fuv(G,te)](.\u00afb.f(D) . Fe . te ~ tr) G fP Kx1 ...xp . e : Tt \n. tr,F Figure 4. Translation to Constraints match alternatives to determine the constructor type T (by \ncall\u00ading constructor(pi)) and subsequently pushes the type of e (Ta\u00af) in the typing clause for each alternative \n(rule (PAT)). Finally rule (CASE) returns the constraints arising from the alternatives. Rule (LETA) \ngenerates implicationconstraints foran annotated let\u00adbinding. Pay attention to two details: (a) the inferred \ntype t D must equate to the declared type t , and (b) the universally quanti.ed variables a\u00afmust not \nescape their scope. The .rst is captured in an additional equality constraint t ~tD, and the latter in \nthe degenerate implication constraint.  Rule (LET) for unannotated let-expressions is much trickier. \nFirst, it derives the constraint F1 for the bound expression e1. The con\u00adventional thing to do at this \npoint is to create fresh type variables \u00afb \u00af for the variables \u00df that are not free in the environment \nwith a sub\u00adstitution .k = {\u00df := b}, and abstract over the constraints, inferring the following type for \ng (SP07): g : .\u00afb..k(F1 . t) This is correct, but by postponing all solving until the second phase we \nget unexpectedly complicated types for simple de.nitions. For example, from the de.nition g=\\x-> x&#38;&#38;True \nwe would infer the type g :: .b.b ~ Bool . b . Bool when the programmer would expect the equivalent but \nsimpler type Bool . Bool. Furthermore, this approach obviously requires that types can take the form \nF . t including the possibility that F is itself an implication! It all works .ne (see (SP07) for example), \nbut it makes the types signi.cantly more complicated and, in an evidence-passing internal language such \nas that used by GHC, creates much larger elaborated terms. Instead, we interleave constraint generation \nand constraint solving in rule (LET), thus6: Generate constraints for e1 under the assumption that g \n: a (we allow recursion in let).  Add the constraint a ~ t to tie the recursive knot in the usual way, \nforming F1D .  We cannot, at this stage, guarantee to solve all the constraints in  F D 1, because \nthe latter might include implications that can only be solved in the presence of information from elsewhere. \nSo we extract from F1 D the simple constraints, Fs: simple(C)= C simple(F1 . F2)= simple(F1) . simple(F2) \nsimple([\u00afa](.\u00afb.F )) = [\u00afa].\u00afb.simple(F ) simple([\u00afa](.\u00afb.C . F )) = EC = E Solve Fs appealing to our \nsolver f Fs : fs. Notice that this fs may bind skolems, a point that we will return to. Moreover, notice \nthat if uni.cation fails for a simple constraint (such as Bool ~ Int) then the program is de.nitely untypeable. \n Apply the solving substitution fs to t and G, and compute the set of variables \u00df\u00afover which to quantify \nin the usual way.  Skolemise the variables we can quantify over, using a substitu\u00adtion .k.  Typecheck \nthe body of the let, with a suitable type for g.  Lastly we .gure out the constraint F to return. It \nincludes F2 of course, and F1 D suitably wrapped in a . to account for the skolemized variables just \nas in (LETA).  There are two tricky points in this process. First, notice that the substitution returned \nby solving Fs is a f-substitution and not merely a .-substitution, and hence can 6 This interleaving \nis not so unusual: every Haskell compiler does the same for type-class constraints. Alternatively, Pottier \nand R\u00b4emy (PR05) show how to defer quanti.cation to the solving phase and avoid interleaving. fs F : \nf (S-SOLVE) simple(F ) = Fs f;s Fs : f f;s F : . \u00b7 f f;s f(F ) : . f; s F : f f; s F1 : f1 (S-EMPTY) \n(S-SPLIT) s f1(F2): f2 f;f; s E : \u00d8 f; s F1 . F2 : f2 \u00b7 f1 f;s ( V ti ~ ti D): f (S-REFL) (S-CONS) i \nf;s t ~ t : \u00d8f;s Tt\u00af~ Tt\u00afD : f . . t. . t (S-UL) f = {. := t } (S-UR) f = {. := t }f;s . ~ t : f f;s \nt ~ . : f f;\u00af s F : f fv(f(\u00afa)) n \u00afb = \u00d8 b n dom(f)= \u00d8 (S-SIMPL) f; s [\u00afa](.\u00afb.F ): f f; C = E s C : \nf (S-PIMPL) fs f(F ): .a\u00afn dom(.)= \u00d8 f;s [\u00afa](.\u00afb.C . F ): . Figure 5. Solver algorithm bind skolem variables. \nThis is perhaps unintuitive after all in ordinary Hindley-Milner we would require that the substitution \nbinds only uni.cation variables. Nevertheless, in the presence of given equations this is not enough. \nConsider: data T where MkT ::forallab.(a ~b) =>a-> b-> T foo= case eof MkTyz->leth=[y,z] in() Constraint \ngeneration for the inner let de.nition produces the constraint a ~ b, where a and b are the existential \nvariables introduced by the pattern match. But we must not fail at this point and hence the solver of \nthe Fs constraint must be prepared to encounter equalities between skolem variables. Second, notice that \nwe do not apply fs to F1D. Why not? Be\u00adcause fs may bind variables free in G, and we must not lose that \ninformation. But the very same information is present in the original F1D, so if we return F1 D unchanged \n(apart from applying the skolemizing substitution .k, then the rest of the derivation will be able to \nsee it too. Finally, notice that there is quite a bit of junk in F1D. Consider the de.nition of g given \nearlier in this subsection. We will get t = \u00df . Bool,F 1 D = \u00df ~ Bool,.s = {\u00df := Bool} Now \u00df plays no \npart in the rest of the program, but still lurks in F1D . Because of our freshness assumptions, however, \nit does no harm either.  5.2 The OutsideIn Implication Solver Figure 5 presents the rules of our implication \nsolver. The solver judgement is of the form fs F : f. This judgement should be thought of as taking F \nas input and producing a f, such that |= f(F ) according to the equational theory of Figure 3. The judgement \nappeals to simple(F ) .rst, to extract the simple part of the constraint Fs. It solves the simple part \nusing the auxiliary judgement f;s F : f. It applies the substitution to the original constraint and tries \nto solve the returned constraint.7  Notice that the solver returns a f substitution, which can bind \nboth skolem variables and uni.cation variables. As discussed in the previous section, being able to handle \nequalities between skolem variables is important for the interleaving of solving and constraint generation \nin rule (LET). Nevertheless, only a . is returned the second time we attempt to solve the constraints. \nThis is because the second time the solver will attempt to solve the proper implications that remain \n and solutions to those may only bind uni.cation variables as we shall shortly see (rule (S-PIMPL)). \nThe judgement f;s F : f is the core of our constraint solver. Rules (S-EMPTY) and (S-SPLIT) are straightforward. \nThe remain\u00ading rules deal with a single equality constraint. Rule (S-CONS) de\u00adconstructs a type constructor \napplication, and Rule (S-REFL) dis\u00adcharges trivial equality constraints. Rules (S-UL) and (S-UR) ac\u00adtually \ninstantiate a type variable variable . with a type t. They must be careful not to violate the occurs-check \n(. . t ). Simple implication constraints, i.e. with empty given constraints, are treated by the (S-SIMPL) \nrule. A simple implication constraint is treated almost as if it were just a basic constraint with two \ndifferences. First, we make sure that the returned f does not unify any of the skolemized variables of \nthe constraint it would be unsound to do otherwise. Second, we must never instantiate any of the variables \ncaptured in [\u00afa] with a type that contains some of the skolemized variables \u00afb. (In this case untouchables \nfor the a\u00afvariables is a bad name. For example, it is .ne indeed essential to unify a in [a].b.a ~ \nBool.) Proper implication constraints are tackled by the (S-PIMPL) rule. First it computes f that solves \nthe assumptions C if there is no solution, the implication constraint originates from a dead code branch. \nNext, it applies it to F and solves F recursively yielding .. Finally, it checks that the solution . \ndoes not touch any of the untouchables. There are several tricky points: There is some non-determinism \nin rule (S-SPLIT), but it is harmless. When solving simple constraints, the order of solving them does \nnot matter; and when solving conjunctions of proper constraints solutions from one can never affect the \nother.  Some non-determinism appears in (S-PIMPL). For example, consider the constraint [a]..C . a ~ \n\u00df. The recursive invo\u00adcation of fs could return either f = {a := \u00df} or {\u00df := a}, but only one will satisfy \nthe untouchables check. In contrast, any most-general uni.er of C will do for f. Similarly, in a sim\u00adple \nconstraint [].c.\u00df ~ c there is a choice to bind either \u00df or c when we solve the constraint \u00df ~ c. However, \nbecause of the conditions in rule (S-SIMPL), only the solution {\u00df := c} is acceptable.  Rule (S-PIMPL) \ndoes not need the skolem-escape check that appears in (S-SIMPL). Because . does not affect a, such a \ncheck cannot fail.  In (S-PIMPL), solving C requires us to bind skolem variables as well as uni.cation \nvariables, and hence we return a f. This  7 A more realistic implementation would split the constraint, \nsolve the simple part and use that substitution to solve the proper part no need to re-solve the simple \npart. We chose our current formalism as it saves us the de.nition of splitting. is important to type \nconstraints whose assumptions involve skolem variables, such as (a ~ Int . Int ~ a). Furthermore, in \nrule (S-PIMPL) the solution of the right-hand side of the constraint is required to be a .. The reason \nis because this rule is triggered whenever we are trying to solve a proper implication constraint, and \nhence the solver is not called from rule (LET), but rather after constraint generation has .nished. In \norder to solve such a constraint at the end, it is unsound to bind skolem variables: Equalities that \ninvolve skolems may only be discharged by given equalities. Hence we must not return a f, but a substitution \nthat binds uni.cation variables only (i.e. a .).  5.3 Example Consider again our standard example \\x-> \ncase xof{T1n->n>0} for which the type ax . \u00df is derived, and the constraint F = ax ~ T a . [a, ax,\u00df](a \n~ Bool . \u00df ~ Bool) If we solve .rst the simple constraint on the left, we get the sub\u00adstitution [ax := \nT a]. We apply this substitution on the implica\u00adtion constraint, yielding [a, \u00df](a ~ Bool . \u00df ~ Bool). \nNext, we try to solve the implication constraint. Firstly, applying the mgu of a ~ Bool, i.e. [a := Bool], \nto \u00df ~ Bool) has no impact. Secondly, we try to solve \u00df ~ Bool by substituting \u00df for Bool. Yet this fails, \nbecause \u00df is an untouchable . Hence, our algorithm rejects the program. Now let s add a second branch \nto the example \\x-> case xof{T1n->n>0;T2xs-> null xs} Again the type ax . \u00df is derived, now with the \nconstraint D DDDD F = F . ax ~ T a. [a] ~ [a] . \u00df ~ Bool The .rst additional constraint originates from \nthe pattern T2 xs, the second and third from null xs. Solving all simple constraints .rst, we get the \nsubstitution [ax := T a, aD := a, aDD := a, \u00df := Bool]. These reduce the implication constraint to [a](a \n~ Bool . Bool ~ Bool), which is now readily solved. Hence, the expression is accepted with type T a . \nBool. 6. Specifying the restricted type system It is all very well having an inference algorithm, but \nmust also explain to the programmer which programs are accepted by the type checker and which are not. \nEvery GADT inference algorithm has dif.culty with this point, and ours is no exception. Figure 6 presents \nthe rules of the restricted type system. The top\u00adlevel typing judgement is C, G fR e : t which asserts \nthat expression e has type t with respect to environment G and type constraints C. This judgement is \nde.ned by rule (R-MAIN) which in turn is de.ned in terms of the auxiliary judgement C, G fr e : t, P \nwhich should be read under constraints C and type environment G, the term e has type t and suspended \ntyping judgements P . What are these suspended judgements? The idea is that we type\u00adcheck the original \nterm simply ignoring any GADT case alterna\u00adtives. Instead, these ignored alternatives, along with the \ncurrent environment and result type, are collected in a set P of tuples (C, G, e, t ). Suppose the original \ntop-level program term can be typed, so that G fr e : t, P holds. Then, for every such typing (or, more \nrealistically for the principal typing) we require that all the suspended typing prob\u00adlems in P are soluble. \nThat is what the (rather complicated) rule  C, G fR e : t consistent(C) C, G fr e : t,P (R-MAIN) .t \nD,P D . (C, G fr e : t D,P D) . .(Ci, Gi,ei,ti). P D .Ci, Gi fR ei : ti C, G fR e : t C, G fr e : t, \nP K :: .a.D\u00af. . C, G fr e : t1,P (R-VAR) (x : .\u00aff = {a := t} f = {a := t} = f(D) C | a..) . G (R-CON) \nC |(R-EQ) = t1 ~ t2 C, G fr x : f(.), \u00d8 C, G fr K : f(.), \u00d8 C, G fr e : t2,P C, G fr e1 : t1 . t2,P1 \nC, G fr e2 : t1,P2 C, G .{x : t1}fr e : t2,P (R-APP) (R-ABS) C, G fr e1 e2 : t2,P1 . P2 C, G fr .x.e \n: t1 . t2,P C, G .{g : t1}fr e1 : t1,P1 a\u00af= fv(t1) - fv(C, G) C, G .{g : .\u00afe1 : t1,P1a.t1}fr (R-LET) \nC, G .{g : .\u00afe2 : t2,P2a.t1}fr (R-LETA) C, G .{g : .\u00afe2 : t2,P2a.t1}, fr C, G fr let {g = e1} in e2 : \nt2,P1 . P2 C, G fr let {g :: .\u00af= a.t1 e1} in e2 : t2,P1 . P2 C, G fr e : t1,P C, G frp pi . ei : t1 \n. t2,Pi for i . I (R-CASE) S C, G fr case e of [pi . ei]i.I : t2,P . i.I Pi C, G frp p . e : t . ., P \n(R-VPAT) K : .\u00afa, \u00afb.E . .1 . ... . .p . T \u00afa fv(C, G, \u00aft, tr) n \u00afb = \u00d8 f = {a := t }C, G . f{x1 : .1, \n. . . , xp : .p} fr e : tr, P (R-GPAT) K : .\u00afa, \u00afb.D . .1 . ... . .p . T \u00afa D = E fv(C, G, \u00aft , tr) n \n\u00afb = \u00d8 f = {a := t}P = {(C . f(D), G . f{x1 : .1, . . . , xl : .l}, e, tr)} C, G frp K x1 . . . xp . \ne : T \u00aft . tr, P C, G frp K x1 . . . xl . e : T \u00aft . tr, P Figure 6. Typing Rules for the Restricted \nType System (R-MAIN) says. It ensures that typing information from inside a GADT match does not in.uence \nthe typing of code outside that match just as the algorithm does. Observe the recursive nature of rule \n(R-MAIN), which defers and processes nested case expres\u00adsions one layer at a time. The only rule that \nadds a deferred typings to P is R-GPAT; it defers the typing of a branch of a case expression that matches \na GADT constructor pattern. This rule only applies to GADT constructors that bring a type equality into \nscope. In all other cases, when no new type equalities are brought into scope, the rule R-PAT applies, \nwhich does not defer the typing. 7. Formal properties In this section we describe the properties of our \ntype system and its inference algorithm. 7.1 Properties of the type system As we have discussed, implication \nconstraints arising from pro\u00adgram text may have a .nite or in.nite set of incomparable solu\u00adtions. This \nambiguity makes type inference hard. Even in the case when the solutions are .nite (but cannot be described \nby a com\u00admon most general solution) modular type inference is impossible. Our restricted system however \nimposes conditions on the typeable programs of the unrestricted system, which ensure that we can per\u00adform \ntractable type inference without having to search the complete space of possibly incomparable solutions \nfor the arising constraints. First, the restricted type system is sound wrt. the unrestricted type system: \nTHEOREM 7.1 (Soundness). If E, G fR e : t in the restricted type system (Figure 6), then E, G f e : t \nin the unrestricted type system (Figure 2). It is fairly easy to see that this theorem holds. In addition \nto all the constraints of the unrestricted type system, the restricted type system imposes one more constraint \non well-typing: the universal well-typing of the deferred typings discussed above. Moreover, the restricted \ntype system has the important property that it only admits expressions that have a principal type. THEOREM \n7.2 (Principal Typing in the Restricted Type System). If an expression e is typeable in the restricted \ntype system wrt. a type environment G, then there is a principal type tp such that E, G fR e : tp and \nsuch that for any other t for which E, G fR e : t , there exists a substitution f such that f(tp)= t \n. Note that the principality is not an artifact of the restricted type system. A principal type in the \nrestricted type system is also a principal type in the unrestricted type system: THEOREM 7.3 (Principal \nTyping in the Unrestricted Type System). Assume that the type tp is the principal type of e wrt. a type \nen\u00advironment G in the restricted type system. Then, for for any other t for which E, G f e : t , there \nexists a substitution f such that f(tp)= t .  Figure 7. The space of programs Note that not all programs \nwith a principal type in the unrestricted type system, are accepted in the unrestricted type system. \nConsider the following program: data TawhereMkT::(a~ Bool)=> Ta f:: Ta->Char fx=let h= casexofMkT->3 \nin a The principal type for h in the unrestricted type system is Int. The restricted, ignoring the case \nbranch, attempts to assign .b.b as the principal type for h. However, this does not allow the implication \n(a ~ Bool) . (b ~ Int) to be solved. Hence, the program is rejected. Hence, the gray area in Figure 7 \nis non-empty. We leave it as a challenge for future work to expand the innermost area towards the dashed \nline. Finally, we observe that nearly all well-typings in the unrestricted type system can be recovered \nin the restricted type system by adding additional type annotations to the program. Because our lan\u00adguage \ndoes not provide a means to name existential type variables brought into scope by GADT pattern matches, \nwe cannot recover thos well-typings that require mentioning them. Open type annota\u00adtions8 would lift \nthat limitation.  7.2 Properties of the inference algorithm The solver algorithm has a number of vital \nproperties. First, the search for solution always terminates, either in failure or success. THEOREM 7.4 \n(Termination). The solver algorithm terminates. Second, when a solution is found, it is a proper well-typing \nin the restricted type system. THEOREM 7.5 (Soundness). If finf e : t then E, \u00d8fR e : t Third, when a \nsolution is found, it is not an arbitrary solution, but the principal solution. THEOREM 7.6 (Principality). \nThe inferred type is the principal type in the restricted type system: If finf e : t and E, \u00d8fR e : . \nthen . = f(t ) for some f. Finally, if an expression is well-typed, then the solver algorithm .nds a \nsolution. THEOREM 7.7 (Completeness). If E, \u00d8fR e : t then finf e : .. Of course, in order to prove the \nsolver algorithm properties, we have to generalize appropriately the statements of the theorems 8 i.e. \ncontaining free occurrences of lexically scoped type variables. in this section, but we refrain from \npresenting the generalized statements for the sake of clarity of exposition. 8. Implementation Aspects \nA key property of OutsideIn is that it is easy to implement, and the implementation is ef.cient. To substantiate \nthis claim we brie.y describe our implementation of OutsideIn in Haskell. Our imple\u00admentation is available \nfor download from http://research.microsoft.com/people/dimitris/ and additionally supports bidirectional \ntype checking, open type annotations, and type annotations with constraints. We introduce a datatype \nMetaTv for uni.cation variables a, \u00df, . . . and a datatype TyVar for skolem variables a, b, . . .. As \nin tradi\u00adtional implementations (PVWS07), the MetaTv contains a refer\u00adence cell that may contain a type \nto which the variable is bound: data MetaTv = Meta Name (IORef (Maybe Type)) newtype TyVar = TyV Name \nThe main type checker is written in a monad Tc a, which is a func\u00adtion from environments TcEnv and encapsulates \nIO and threading of error messages. newtype Tc a = Tc (TcEnv -> IO (Either ErrMsg a)) data TcEnv = TcEnv \n{ var_env :: Map Name Type , lie_env :: IORef [Constraint] , untouchables :: [MetaTv] , ... } Among other \n.elds, the TcEnv environment contains a typing en\u00advironment var_env, which is a map from term variable \nnames to types. The .eld lie_env collects the set of Constraints that arise during type inference.9 The \nConstraint datatype holds equality and implication constraints. 8.1 Constraint generation In traditional \nimplementations, uni.cation variables are typically eagerly uni.ed to types as type inference proceeds. \nIn contrast, the algorithm of Figure 4 .rst generates (lots of) constraints, and then solves them, which \nis much less ef.cient. In our implementation we choose an intermediate path, which results in much more \ncompact generated constraints. The environment TcEnv is equipped with the untouchables .eld, which records \nthe untouchable variables. As type inference proceeds we perform eager uni.cation by side effect in the \nusual way, except that we refrain from unifying a variable a from the untouchable set to a type t . In \nthat case, we defer the constraint a ~ t , to be dealt with after constraint generation is .nished. Hence, \nthe uni.er has signature: unify :: Type -> Type -> Tc [Constraint] It accepts, two types to unify, uni.es \nthem (perhaps using side effects on MetaTvs that are not untouchable), and returns a list of deferred \nequalities for variables that belong in the untouchables .eld of the environment. How does the untouchables \nenvironment .eld get updated? Whenever we perform type inference for a pattern match clause with non-empty \ngiven equations, the main type checker: 1. extends the untouchables .eld with the uni.cation variables \nof the scrutinee and the environment and the return type, as required by Figure 4, 9 The name lie env \nis folklore from type class implementations, where it stands for Local Instance Environment.  2. performs \ntype inference for the right-hand-side of the clause and returns the deferred constraints, and 3. defers \nan implication constraint whose right-hand side consists of the aforementioned deferred constraints. \n  8.2 Constraint solving During type inference we need to solve the generated constraints at two points: \nwhen the constraints for the complete program have been generated (rule (INFER), Figure 4), but also, \nmore sub\u00adtly, when we encounter a let-bound de.nition with no annotation (rule (LET), Figure 4) in the \nlatter case we must only solve the simple constraints. Post-constraint-generation-solving After constraint \ngeneration is .nished, the lie_env .eld holds the set of deferred constraints. At this point we may appeal \nto our constraint simpli.er, which is written in a lightweight error-threading monad, implemented with \nHaskell s Either datatype. By design, this monad is pure in the sense that it does not support in-place \nupdating of MetaTvs. solveConstraints :: [MetaTv] -> [CConstraint] -> Either SimplifierError () solveConstraints \nuntch cs = do { let (simples, propers) = splitCConstrs cs ; subst <-solveSimples (Unif untch) simples \n; spropers <-substToCConstrs subst propers ; mapM_ solveProper spropers } The function solveConstraints \naccepts a list of untouchable variables and a list of constraints (cs)10 to simplify. It splits the constraints \nto simples and propers, solves the simples, applies the substitution to the propers (yielding spropers) \nand solves spropers. The function solveConstraints is the .nal step of type inference, and we need not \nreturn any value back hence the () return type. We will return to solveSimples and the meaning of the \nargument (Unif untch), but for now let us focus on the solvePropers function: solveProper :: CConstraint \n-> Either SimplifierError () The function solveProper accepts a single proper implication and solves \nit. Notice that, since the argument is a proper implication, its solution cannot affect anything in the \nenvironment and hence we may simply return () the substitution in Figure 5, rule (S-PIMPL) is only there \nto enable clean statements and proofs of some formal properties. We now turn to solveSimples, below: \nsolveSimples :: SimplifierMode -> [CConstraint] -> Either SimplifierError Substitution solveSimples mode \n= foldM (solveSimple mode) emptySubst solveSimple :: SimplifierMode -> Substitution -> CConstraint -> \nEither SimplifierError Substitution The Substitution datatype denotes substitutions from either MetaTv \nor TyVar variables to types. Notice that solveSimples is de.ned as a fold, that starts-off with the empty \nsubstitution and updates it as it solves each simple constraint. In contrast, we use mapM_ to solve each \nproper constraint independently in solveConstraints, because they cannot affect each other. The SimplifierMode \nargument to solveSimple stands for the mode of operation: 10 The CConstraint datatype is a canonicalized \nvariant of Constraint, and we can ignore their differences below. If the .ag is (Unif untch) then the \nreturned Substitution binds only uni.cation variables that do not appear in the list of untouchables, \nuntch.11  If the .ag is All then the returned Substitution binds in\u00advariably skolem and uni.cation variables. \nNotice that it would be wrong to apply this substitution to uni.cation variables as a side-effect for \nexample it is de.nitely wrong in the context of solving the local assumptions of an implication constraint. \n One reason we need the .ag All is because solveSimple has to unify both skolem and uni.cation variables \nwhen called on the given equalities of implication constraints. Concretely, here is the de.nition of \nsolveProper (simpli.ed): solveProper (CImplicConstraint envs sks gs ws) = do { subst <-solveSimples All \ngs ; ws_cs <-substToCConstrs subst ws --find untouchables from envs and subst ; let all_envs = ... ; \nsolveConstraints all_envs ws_cs } The datatype CImplicConstraint envs sks gs ws stands for the proper \nconstraint [envs].sks.gs . ws. Notice characteristi\u00adcally that the givens gs are uni.ed using the All \n.ag. Subsequently, the substitution is applied to ws, and the new untouchable vari\u00adables are calculated \n(all_envs). Finally, solveConstraints is recursively called with the new list of untouchables. The function \nsolveConstraints returns () but that s all that we need when solving the right-hand side of proper implication \nconstraints: Any solution for a proper implication constraint could only bind inter\u00adnal variables to \nthat constraint (i.e. not in the untouchables) and consequently does not affect any other constraint. \nIt is because of this recursive call to solveConstraints from in\u00adside of solving a proper implication \nthat we need to pass it the list of untouchable variables our top-level call to solveConstraints is \nwith empty untouchable variables. Solving for let-bound de.nitions When type checking a let\u00adbound de.nition, \nrule (LET) in Figure 4 requires that we solve the generated simple constraints. We already have the mechanism \nfor doing so, via solveSimples. We give below a code excerpt from type checking let bindings. --type \ncheck binding ... --call the simplifier ; (propers, phi) <-simplifyTc $ do { ... --cs: the constraints \nfrom type checking ; let (simples,propers) = splitCConstrs cs ; phi <-solveSimples All simples ; return \n(propers, subst) } ... --compute quantified vars ; let forall_tvs = ... --create new skolems ; sks <-... \n--skolemizing substitution forall_tvs |-> sks ; let thetak = ... ; let phi_thetak = thetak composeSubst \nphi ; spropers = map (substToConstr phi_thetak) propers --write back constraints ; deferred <-eqCheckSubst \nphi_thetak ; deferImpl env_tvs sks [] (spropers ++ deferred) --quantify and return type ... 11 We could \nin principle apply the returned substitution as side-effect but we chose to not do so in order to treat \nthis case uniformly with the case when the .ag is All, to be described next.  We .rst type check the \nbinding and get the resulting constraints and its type. Subsequently, we call the simpli.er: we split \nthe con\u00adstraints to simples and propers, we solve the simples (using mode All) and return the propers \nand the resulting substitution, subst. Next, we compute the variables to quantify and the skolem\u00adizing \nsubstitution .k of rule (LET) in Figure 4 (thetak). Next, we need to extend the lie_env with a constraint. \nAt this point we could in principle return the original constraint to which we have applied .k, wrapped \nas a simple implication constraint, as in rule (LET). As an optimization however, we call unify on each \nbinding . := t in phi_thetak; in the common case where . is a (touchable) uni.cation variable a unify \nwill update a in-place, otherwise it will defer the constraints. Those deferred constraints are bound \nto deferred, and .nally return a simple implication constraint that contains the skolemized proper part \nof the original (spropers) and those deferred. 9. Related Work Since GADTs have become popular there \nhas been a .urry of pa\u00adpers on inference algorithms to support them in a practical pro\u00adgramming language. \n9.1 Fully-annotated programs One approach is to assume that the program is fully type-annotated, i.e. \neach sub-expression carries explicit type information. Under this (strong) assumption, we speak of type \nchecking rather than in\u00adference. Type checking boils down to uni.cation which is decid\u00adable. Hence, we \ncan conclude that type checking for GADTs is decidable. For example, consider (CH03) and (SP07). 9.2 \nEntirely unannotated programs Type inference for unannotated programs turns out to be extremely hard. \nThe dif.culty lies in the fact that GADT pattern matches bring into scope local type assumptions (Section \n2). Following the standard route of reducing type inference to constraint solving, GADTs require implication \nconstraints to capture the inference problem precisely (SSS08). Uni.cation is no longer suf.cient to \nsolve such constraints. We require more complicated solving methods such as constraint ab\u00adduction (Mah05) \nand E-uni.cation (GNRS92). It is fairly straight\u00adward to construct examples which show that no principal \nsolutions (and therefore no principal types) exist. We can even conclude that GADT inference is undecidable \nby reduction to simultaneous rigid E-uni.cation problem which is known to be undecidable (DV95). How \ndo previous inference approaches tackle these problems? Simonet and Pottier (SP07) solve the inference \nproblem by admit\u00adting (much) richer constraints. They sidestep the problems of un\u00addecidability and lack \nof principal types altogether by reducing type inference to type checking. Their inference approach only \naccu\u00admulates (implication) constraints and refrains from solving them. As a result, implications may \nappear in type schemes, which is a serious complication for the poor programmer (we elaborate in Section \n5.1). Furthermore, no tractable solving algorithm is known for the constraints they generate, largely \nbecause of the (absolutely necessary) use of implications. Sulzmann et al (SSS08) go the other direction, \nby keeping con\u00adstraints (in types) simple, and instead apply a very powerful (abduc\u00adtive) solving mechanism. \nTo avoid undecidability, they only con\u00adsider a selected set of intuitive solutions. However they give \nonly an inference algorithm, and it is not clear how to give a declarative description that speci.es \nwhich programs are well-typed and which are not. Furthermore their system lacks principal types.  9.3 \nPractical compromises We conclude that tractable type inference for completely unanno\u00adtated programs \nis impossible. It is therefore acceptable to demand a certain amount of user-provided type information. \nWe know of two well-documented approaches: R\u00b4 egis-Gianas and Pottier stratify type inference into two \npasses. The .rst .gures out the shape of types involving GADTs, while the second performs more-or-less \nconventional type inference (PRG06). R\u00b4egis-Gianas and Pottier present two different shape analysis procedures, \nthe Wob and Inst systems. The Wob system has similar expressiveness and need for annotation as in (PVWW06). \nThe Ibis system on the other hand has similar expressiveness as our system, with a very aggressive iterated \nshape analysis process. This is reminiscent of our uni.cation of simple constraints arising potentially \nfrom far-away in the program text, prior to solving a particular proper constraint. In terms of expressiveness, \nthe vast majority of programs typeable by our system are typeable in Ibis but we conjecture that there \nexist programs typeable in our sys\u00adtem not typeable in Ibis, because uni.cation of simple (global) constraints \nmay be able to .gure more out about the types of ex\u00adpressions than the preprocessing shape analysis of \nIbis. On the other hand, Ibis lacks a declarative speci.cation that does not force the programmer to \nunderstand the intricacies of shape propagation. Peyton Jones et al require that the scrutinee of a GADT \nmatch has a rigid type, known to the type checker ab initio. A number of ad hoc rules describe how a \ntype signature is propagated to control rigidity (PVWW06). Because rigidity analysis is more aggressive \nin our system we type many more programs than in (PVWW06), including the carefully-chosen Example 7.2 \nfrom (PRG06). On the other hand a program fails to type check in our approach if the type of a case branch \nis not determined by some outer constraint: dataEqabwhere{Refl:: foralla.Eq aa} test::forall ab.Eqab->Int \ntest x = let funny_id = \\z -> case x of Refl -> z in funny_id 3 By contrast this program is typeable \nin (PVWW06). Arguably, though, this program should be rejected, because there are several incomparable \ntypes for funny_id (in the unrestricted system of Figure 2), including .c.c . c and a . b. The implementation \nof GHC is a slight variation that requires that the right-hand-side of a pattern match clause be typed \nin a rigid environment12. Hence, it would reject the previous example. Our system is strictly more expressive \nthan this variation: test::forall ab.Eqab->Int test x = (\\z -> case x of Eq -> z) 34 The above program \nwould fail to type check in GHC, as the wob\u00adbly variable z cannot be used in the right-hand-side of a \npattern match clause, but in our system it would be typeable because the outer constraint forces z to \nget type Int. In both approaches, inferred types are maximal, but not necessarily principal in the unrestricted \nnatural GADT type system. The choice for a particular maximal type over others relies on the ad hoc rigidity \nanalysis or shape pre-processing. By contrast, in our system only programs that enjoy principal types \nin the unrestricted type system are accepted. 12 GHC s algorithm is described in an Appendix to the online \nversion of the paper, available from: http://research.microsoft.com/people/simonpj/papers/gadt  Moreover, \nin both approaches the programmer is required to under\u00adstand an entirely new concept (shape or rigidity \nrepectively), with somewhat complex and ad hoc rules (e.g. Figure 6 of (PRG06)). Nor is the implementation \nstraightforward; e.g., GHC s implemen\u00adtation of (PVWW06) is known to be .awed in a non-trivial way. 10. \nFurther work Although we have focused exclusively on GADTs, we intend to ap\u00adply our ideas in the context \nof Haskell, and more speci.cally of the Glasgow Haskell Compiler. The latter embodies numerous exten\u00adsions \nto Haskell 98, some of which are highly relevant. Notably, a data constructor can bring into scope a \nlocal type-class constraint: classEqa where {(==)::a-> a->Bool } dataD awhere {D1::Eqa =>a->Da} h::a \n->Da ->Bool h x (D1 y) = x==y The pattern match on D1 brings the (Eq a) constraint into scope, which \ncan be used to discharge the (Eq a) constraint that arises from the occurrence of (==). Note that D1 \nis not a GADT; it brings into scope no new type equalities. The same thing may happen with Haskell s \nimplicit parameters (LLMS00). Since type inference for Haskell already involves gathering and solving \ntype-class constraints, the constraint-gathering approach to inference is quite natural. The above extension \nto Haskell gener\u00adalises the idea of local type constraints to constraints other than equalities, and \nthese naturally map to the same implication con\u00adstraints we need for GADTs. More ambitiously, GHC also \nsupports indexed type families and type-equality constraints between them (SJCS08). So we may write type \nfamily F :: * -> * type instance F Int = Int type instance F [a] = F a data Eawhere{E1:: (Fa~Int)=>a \n->E a} Here, when we match on E1 we get the local constraint that F a ~ Int, which in turn gives rise \nto new questions for the solver (SJCS08). Unsurprisingly, these extensions raise similar issues that \nwe found with simple equality constraints. For example, it turns out that type classes suffer from the \nsame lack of principal types as equality constraints (SSS06). Consider this function: data Tawhere{MkT::Eq \na=> Ta } fxy=casexof {MkT-> y==y }::Bool What type should be inferred for f? Here are two, neither of \nwhich are more general than the other: f :: .a.T a . a . Bool f :: .ab.Eq b . T a . b . Bool Hence, the \ndeclarative speci.cation of the type system and the inference algorithm must be extended to cope with \nadditional kinds of constraints. Finally, in practice, our type checker algorithm would have to be augmented \nwith the generation of evidence, witnessing that the wanted constraints hold. In GHC s intermediate language, \nevidence for equality constraints takes the form of type equality coercions, while dictionaries are the \nevidence for type class constraints. We have omitted evidence handling here so as not to distract from \nthe essence of the OutsideIn algorithm. Acknowledgements We are grateful to the anonymous ICFP 2009 reviewers, \nand to James McKinna s team for their comments. References [CH03] J. Cheney and R. Hinze. First-class \nphantom types. TR 1901, Cornell University, 2003. [DV95] A. Degtyarev and A. Voronkov. Simultaneous regid \nE\u00aduni.cation is undecidable. In Proc. of CSL 95, volume 1092 of LNCS, pages 178 190. Springer, 1995. \n[GNRS92] J. H. Gallier, P. Narendran, S. Raatz, and W. Snyder. Theorem proving using equational matings \nand rigid e-uni.cation. J. ACM, 39(2):377 429, 1992. [LLMS00] J. R. Lewis, J. Launchbury, E. Meijer, \nand M. Shields. Implicit parameters: Dynamic scoping with static types. In POPL, pages 108 118, 2000. \n[Mah05] M. Maher. Herbrand constraint abduction. In Proc. of LICS 05, pages 397 406. IEEE Comp. Soc., \n2005. [PR05] F. Pottier and D. R\u00b4emy. The essence of ML type in\u00adference. In Benjamin C. Pierce, editor, \nAdvanced Top\u00adics in Types and Programming Languages, chapter 10, pages 389 489. MIT Press, 2005. [PRG06] \nF. Pottier and Y. R\u00b4egis-Gianas. Strati.ed type infer\u00ad ence for generalized algebraic data types. In \nProc. of POPL 06, pages 232 244. ACM, 2006. [PVWS07] S. Peyton Jones, D. Vytiniotis, S. Weirich, and \nM. Shields. Practical type inference for arbitrary-rank types. J. of Func. Prog., 17:1 82, January 2007. \n[PVWW06] S. Peyton Jones, D. Vytiniotis, S. Weirich, and G. Washburn. Simple uni.cation-based type inference \nfor GADTs. In Proc. of ICFP 06, pages 50 61. ACM, 2006. [SCPD07] M. Sulzmann, M. Chakravarty, S. Peyton \nJones, and K. Donnelly. System F with type equality coercions. In Proc. of TLDI 07. ACM, 2007. [SJCS08] \nT. Schrijvers, S. Peyton Jones, M. Chakravarty, and M. Sulzmann. Type checking with open type func\u00adtions. \nSIGPLAN Not., 43(9):51 62, 2008. [SP07] V. Simonet and F. Pottier. A constraint-based ap\u00adproach to guarded \nalgebraic data types. ACM Trans. Prog. Languages Systems, 29(1), January 2007. [SSS06] M. Sulzmann, T. \nSchrijvers, and P. J. Stuckey. Prin\u00adcipal type inference for GHC-style multi-parameter type classes. \nIn Proc. of APLAS 06, volume 4279 of LNCS, pages 26 43. Springer, 2006. [SSS08] M. Sulzmann, T. Schrijvers, \nand P. Stuckey. Type inference for GADTs via Herbrand constraint abduc\u00adtion. Report CW 507, K.U.Leuven, \nBelgium, 2008.     \n\t\t\t", "proc_id": "1596550", "abstract": "<p>GADTs have proven to be an invaluable language extension, for ensuring data invariants and program correctness among others. Unfortunately, they pose a tough problem for type inference: we lose the principal-type property, which is necessary for modular type inference.</p> <p>We present a novel and simplified type inference approach for local type assumptions from GADT pattern matches. Our approach is complete and decidable, while more liberal than previous such approaches.</p>", "authors": [{"name": "Tom Schrijvers", "author_profile_id": "81100049265", "affiliation": "Katholieke Universiteit Leuven, Leuven, Belgium", "person_id": "P1613965", "email_address": "", "orcid_id": ""}, {"name": "Simon Peyton Jones", "author_profile_id": "81100271851", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P1613966", "email_address": "", "orcid_id": ""}, {"name": "Martin Sulzmann", "author_profile_id": "81100115708", "affiliation": "Intaris Software GmbH, Freiburg, Germany", "person_id": "P1613967", "email_address": "", "orcid_id": ""}, {"name": "Dimitrios Vytiniotis", "author_profile_id": "81100156369", "affiliation": "Microsoft Research, Cambridge, United Kingdom", "person_id": "P1613968", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1596550.1596599", "year": "2009", "article_id": "1596599", "conference": "ICFP", "title": "Complete and decidable type inference for GADTs", "url": "http://dl.acm.org/citation.cfm?id=1596599"}