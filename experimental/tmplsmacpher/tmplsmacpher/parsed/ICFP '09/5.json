{"article_publication_date": "08-31-2009", "fulltext": "\n Experience Report: Embedded,Parallel Computer-Vision witha Functional DSL Ryan R. Newton Teresa Ko \nMIT CSAIL, Cambridge, MA, USA UCLA Vision Lab, Los Angeles, CA, USA newton@csail.mit.edu tko@cs.ucla.edu \n Abstract This paper presents our experience using a domain-speci.c func\u00adtional language, WaveScript, \nto build embedded sensing applica\u00adtions usedin scienti.c research.We focus ona recent computer\u00advision \napplication for detecting birds in their natural environment. The application was ported from a prototype \nin C++. In reimple\u00admenting the application, we gained a much cleaner factoring of its functionality (through \nhigher-order functions and better inter\u00adfaces to libraries) and a near-linear parallel speed-up with \nno ad\u00additional effort. These bene.ts are offset by one substantial down\u00adside:thelackoffamiliaritywiththe \nlanguageofthe original vision researchers, who understandably tried to use the language in the familiar \nway theyuse C++ and thus ran into various problems. Categories and Subject Descriptors: D.3.2Concurrent, \ndistributed, and parallel languages; Applicative (functional) languages; Data-.ow languages GeneralTerms: \nDesign, Languages, Performance Keywords:stream processing languages, computer vision 1. Introduction \nA sensor network deployment typically involves a collaboration between domain experts and computer scientists \n(though the lat\u00adter would ideally be optional). The domain experts are often pro\u00adgrammers themselves, \noftenbuilding prototypesinMatlab or C++. Theexpertisein short supplyisin embedded software development. \nTherefore, tools that make it easier to transition from prototypes to embedded code are of great value. \nFunctional programming is not known for its use in embedded programming, to say the least. But following \nthe recent trend in two-stage domain-speci.c languages (DSLs) (3; 7; 5), we .nd that a stream-processing \nDSL can retain the software engineering bene\u00ad.ts of functional programming (in the metaprogram), while \ngener\u00adating good embedded code,exploiting parallelism, and partitioning programs transparently across \nembedded devices and more power\u00adful servers . In this paper we describe our experience using the WaveScript \nlanguage to implement the latest version of our com\u00adputer vision application for sensor networks. This \npaper is not about Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page.To copyotherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. ICFP 09, August 31 September 2, 2009, Edinburgh, Scotland, UK. Copyright c &#38;#169; 2009ACM \n978-1-60558-332-7/09/08... $5.00 Figure 1. Example background subtraction results. theWaveScript implementation,but \nrather the software engineer\u00ading impact of speci.c language features on the implementation of our application, \nnamely: (1) multi-stage programming;(2)higher\u00adorder functions;(3)parametric and ad-hoc polymorphism;and \n(4) shared-nothing message-passing parallelism. But .rst we need to describe the application itself. \n2. James ReserveVisionApplication Anumber of pertinent questions about the impact of climate change on \nour ecosystem are most readily answeredbyvisually monitoring .ne-scale interactions between animals, \nplants, and their environ\u00adment.Forexample, species distribution, feeding habits, and timing of plant \nblooming events are often best observed through visual sensing. Some quantities, such as CO2 intake of \nplants, have no in the wild sensor and can only be captured through visual sensing. In this paper, we \nfocus on detecting birds at a feeder station in the wild with a network of cameras. Bird populations \nare par\u00adticularly informative about changes in the ecosystem, as species distributions can quickly change \ndue to their mobility. The camera infrastructure used is part of theJames ReserveWildlife Observa\u00adtory.Afeeder \nstationwas constructed and equipped withawebcam and server. It captures a frame a second at 704x480 pixels. \nThere is inherent pressure to increase a camera s coverage at the cost of reducing the size of the objects \nof interest in the image, thereby creatinga more challenging detection and recognition task. Similarly, \nincreasing temporal coverage (battery lifetime) pushes for lower sampling rates, limiting the applicable \nmethods. The resulting image sequence will inevitably have small birds with little features to distinguish \nthem from one another or from the background, and instances of the same bird being in a completely different \nlocation in consecutive frames. Our vision system is able to identify instances of a single bird in spite \nof these challenges. The system consists of two major components: background subtraction and bird classi.cation. \nThe case study in this paper will focus on the background subtraction component, because it is both computationally \nintensive and a substantial improvement over the state of the art in this domain.  2.1 Background on \nBackground Natural environments such as the forest canopypresent an extreme challenge to background subtraction \nbecause the foreground ob\u00adjects,by necessity, blend with the background, and the background itself changes \ndue to the motion of the foliage and the rapid tran\u00adsition between light and shadow.For instance, images \nof birds at a feeder station exhibit a larger per-pixel variance due to changes in the background than \ndue to the presence of a bird. Rapid back\u00adground adaptationfails because birds, when present, are often \nmov\u00ading less than the background and often end up being incorporated into it. Our background subtraction \napproach is based on building a model of the colors seen in the neighborhood around each pixel and then \ncomputing the difference between each new pixel value and the historical model for that pixel s neighborhood. \nTherefore, the algorithm must maintain state for each pixelin the image (its model) and traverse each \ninput image, comparing each new pixel against the model, and updating the model based on the values of \nsurrounding pixels. An example result can be seen in Figure 1. The background model for the pixel located \nat the ith row and jth column is in general a non-parametric density estimate, denoted by pij (x). The \nfeature vector, x . R3, is a colorspace representation of the pixel value. For computational reasons, \nwe consider the simplest estimate, given by the histogram X pij (x)= 1 d(s - x), (1) |S| s.S where S, \nthe set of pixel values contributing to the estimate, is de.ned as S = {xt(a, b) ||a - i| < C, |b - j| \n< C, 0 = t<T }, (2) where xt(a, b) is the colorspace representation of the pixel at the ath row and bth \ncolumn of the image taken at time t. The feature vector, x, is quantized to better approximate the true \ndensity. To detect foreground at timet , a distribution, qij,t (x), is simi\u00adlarly computed for the pixel \nlocated in the ith row and jth column using only the image at time t according to X qij,t (x)= 1 d(s \n- x), (3) |St | s.St where St , the set of pixel values contributing to the estimate is de.ned as St \n= {xt (a, b) ||a - i| < C, |b - j| <C}, (4) The Bhattacharyya distance between qij,t (x) and the corre\u00adsponding \nbackground model distribution for that location, pij,t-1(x), calculated from the previous frames, is \ncomputed to determine the foreground/background labeling. The Bhattacharyya distance be\u00adtweentwo distributionsisgivenby \nZ p d = pij,t-1(x)qij,t (x)dx, (5) X where X is the range of valid x s and d ranges from0to1.Larger values \nimply greater similarity in the distribution.A threshold on the computed distance, d,is used to distinguish \nbetween foreground and background. While subtle, this combination of background model and classi.er allows \nfor large articulated movements in the background to be ignored and small foreground objects to be detected. \n3. WaveScript, Brie.y AWaveScript program constructs a data.ow graph of stream op\u00aderators that executes \nin a non-synchronous (event-driven) manner. Each operator consistsofawork functionand optionalprivate \nstate. Figure 2. Background Subtraction: Lines of code. Each work function is an imperative routine \nthat processes a single stream element, updates the private state for that data.ow operator, and produces \nelements on output streams. The job of the Wave-Script front-end is to partially evaluate the source \n(meta) program to create the data.ow graph, whereas theWaveScript backend per\u00adforms graph optimizations, \npro.les and partitions graphs across de\u00advices (6), and reduces work functions to an intermediate language \nthat can be fed to a number of backend code generators. The .nal intermediate languageforwork functionsisamonomor\u00adphic \n.rst-order language that is easily retargetable to anyplatform that hasa C-compiler (and manythat don \nt).WaveScript currently supports many embedded platforms including TinyOS motes , smartphones running \nJavaME, iPhones, and embedded Linux de\u00advices such as routers. WaveScript is used for embedded sensing \napplications that involve digital signal processing together with more irregularevent processing.Forexampleithas \nbeen usedfor acoustic localization of wild animals (2) and detection of potholes with sensor-equipped \ntaxicabs (4). WaveScript itselfis essentiallyan ML-dialectwithaC-likesyn\u00adtax, a special form for accessing \n.rst-class streams, and miscella\u00adneousextensions (e.g.,extensible records).Atop-level source pro\u00adgram \nreturnsa streamvalue.Timers and drivers for hardware sen\u00adsors provide stream sources, and a pair of primitives \nare the sole means of processing streams: merge combines streams in real-time order of arrival, and iterate \nis a for-each style construct whose evaluation creates a new data.ow operator and provides its work function, \nand whose return value is a new stream. The user manual contains details (1). 4. ImplementationinWaveScript \nThe applicationwas portedtoWaveScript fromaprototypein C++. Figure 2 shows a breakdown of how lines of \ncode were spent in both the C++ andWaveScriptversionsof the application. The porting process consisted \nof four steps: 1. Port codeverbatimtoWaveScript. 2. Factor duplicated code using higher-order functions. \n 3. Remove unnecessary .oating point. 4. Parameterize design; expose parallelism.  The most interestingstepisexposing \nparallelism.The algorithm is clearly data parallel.Infact,aseparate process can compute each pixel s \nBhattacharyya distance (and update each pixel s model) in\u00addependently. But the data-access pattern is \nnon-trivial.To update each pixel s model, each process must read an entire patch of pix\u00adels from the \nimage around it. Thus, tiling the matrix and assigning tilestoworker threadsis complicatedbythefactthatsuchtilesmust \n for r =0 to rows-1 { // create the left most pixel s histogram from scratch c:: Int =0; roEnd = r - \noffset + SizePatch; // end of patch coEnd = c - offset + SizePatch; // end of patch for ro =r-offset \nto roEnd-1 { // cover the row roi = if ro < 0 then -ro-1 else if ro >= rows then 2 * rows-1-ro else ro; \nfor co =c-offset to coEnd-1 { // cover the col coi = if co < 0 then -co-1 else if co >= cols then 2 * \ncols-1-co else co; // get the pixel location i = (roi * cols + coi) * 3; // figure out which histogram \nbin : binB = (Int) ((Float)image[i ] * inv sizeBins1); binG = (Int) ((Float)image[i+1] * inv sizeBins2); \nbinR = (Int) ((Float)image[i+2] * inv sizeBins3); // add to temporary histogram tempHist[binB][binG][binR] \n+= sampleWeight; } }; // copy temp histogram to left most patch for cb = 0 to NumBins1-1 { for cg = \n0 to NumBins2-1 { for cr =0 to NumBins3-1 { bgHist[k][cb][ cg][ cr] += tempHist[cb][cg][ cr]; }}}; // \nincrement pixel index k += 1; // compute the top row of histograms for c =1 to cols-1 { ... // Here: \ntwo more ro/co loops like above. // These add and subtract new data from the // histogram to update it \nincrementally. ... }} Figure 3. An excerpt from the verbatim port. overlapsoeachpixelmayreachits neighbors.Forthese \nreasons,it is not straightforward to implement this algorithm in most stream processing languages. For \nexample, stream processing languages tend to require that the input to each stream operator be a linear \nsequence of data. Exposing parallelism and exploiting locality in the background subtraction stage then \nrequires an appropriate seri\u00adalization of the matrix (for example, using Morton-order matrices), butthisin \nturn creates complicatedindexing.Itis reasonabletosay that the stream-processing paradigm is not a natural \n.t for parallel matrix computations.Yetitcanbemadetoworkusingahigh-level streaming language with a full \ndatatypes (algebraic datatypes, dy\u00adnamic allocation) and the additional power of meta-programming. 4.1 \nPortingVerbatim Because WaveScript has imperative constructs and a C-like con\u00adcrete syntax,itis straightforwardtodoaverbatim \ntranslationofC or C++ code. This does not in any way extract parallelism (it re\u00adsults in a data.ow graph \nwith one operator). But it is the best way to establish correspondence with the output of the original \nprogram and then proceed by correctness preserving refactorings. The original source code possessed substantial \ncode duplication (Figure 3), having mainly to do with repeated processing of nested arrays, including \nindex calculations. The code in Figure3 is part of the populateBg function, whichbuilds the initial background \nmodel for each pixel and takes as input storage space for the models and an input image. It has the following \nsignature: populateBg :: (Array4D Float, Image) -> (); type Image = (RawImage * Int * Int); // With wid,height \ntype RawImage = Array Color; type Array4D t = Array (Array (Array (Array t)));  Figure 4. Single threaded \nperformanceof portedversions vs. orig\u00adinal C++ version. Shows average time for processing each frame \non a 3.2 gHz Xeon machine. populateBg is called repeatedly with a series of Images to ready the background \nmodel before processing (classifying) new frames. In this version of the code, no signi.cant type abstraction \nhas yet been applied. The model for each pixel is a three-dimensional histogram in color space (the argument \nto populateBg is four di\u00admensional to include a 3D histogram for each pixel in the image). The background \nsubtraction algorithm as a whole consists of 1300 lines of code containing three functions very much \nlike populateBg. A second function updates the model for each new frame, and a third compares each new \nimage with the existing model to compute Bhattacharyya distances for each pixel. These functions traverse \nboth the input image and stored histograms. The performance of the original version, initial port, and \nsubsequent refactorings is illustrated in Figure 4. Generally speaking, exclud\u00ading automatic memory management, \nthe object-language generated byWaveScript shares mostof the characteristicsofCcode.  4.2 Refactoring \nCode The next step was to simply clean up the code. Some of this con\u00adsisted of factoring out simple .rst-order \nfunctions to capture re\u00adpeated index calculations(a refactoring applied just as easily to the original \nC++). Other refactorings involved using higher order func\u00adtions,forexample,to encapsulatetraversalsovertheimage \nmatri\u00adces and thereby remove for-loops and indexing expressions. After refactoring, the codewas reduced \nto 400lines. The clearer struc\u00adture of the populateBg function can be seen in Figure 5. Both Fig\u00adures3and5contain \nan optimization: the difference in histograms for neighboring pixels is small, and one can incrementally \nbe com\u00adputed from the other: adding some samples, removing others, and thereby sliding the patch. But \nthis optimization has become much clearer in the structure of Figure 5. In this version we have begun \nto abstract the types used. Rather than a 4D nested array to represent a 5D space (a matrix of his\u00adtograms), \nwe use the preexisting WaveScript 2D and 3D matrix libraries. These provide ADTs with multiple implementations, \nin\u00adcludingaWaveScript nativeone andaGnu Scienti.c Library wrap\u00adper (which uses BLAS). Not needing linear \nalgebra, we use the for\u00admerinthispaper.Swappingina .attenedrow-major representation results in fewer \nsmall objects and fewer pointer dereferences, cre\u00adating the performance improvement shown in Figure 4. \n(Note that the initial Factoring damaged performance, possibly by obscur\u00ading backend compiler optimizations.) \nAlso, it sa banal point,but parametric polymorphism for data types is critical. Most likely, the inconvenienceof \nemulating thisin C++ (templates) andthe lackof  type PixelHist = Matrix3D Float; populateBg :: (Matrix \nPixelHist , Image) -> (); fun populateBg(bgHist , (image,cols ,rows)) { // bgHist : background histograms \n// image : frame of video stream assert eq( Image size: , length(image), rows* cols *3); tempHist = \nPixelHist:make(rows,cols); // Strong assumption about order of matrix traversal : Matrix:foreachi(bgHist, \nrows,cols, fun(r,c, bgHist rc) {if c==0 then initPatch(r,c, rows,cols, tempHist, image) else shiftPatch(r,c, \nrows,cols, tempHist, image); // copy temp histogram to left most patch: Matrix3D:map inplace2(bgHist \nrc, tempHist, (+)); }) } Figure 5. The populateBg function builds background models (histograms) for \nthe Patch centered around each pixel. First it creates a histogram for the leftmost pixel in a row. Then \nthe next pixel s histogram is calculated incrementally by shiftPatch: (1) removing pixels in the left \nmost col of the previous patch from the histogram and (2) adding pixels in the right most col of the \ncurrent pixel s patch to the histogram. The foreachi function (as opposed to foreach)also passes indices \nfor the data being accessed. built-in matrix libraries resulted in the use of monomorphic, nested arrays \nin the original source.  4.3 Reducing FloatingPoint One of our goals in porting this application was \nto run it on a wide range of embedded hardware as well as on multicore desktops (and partitioned between \nthe two). In particular, we used Nokia smart\u00adphones (N95) with ARM processors lacking .oating-point units. \nThus, the penultimate step was to reduce the use of .oating point calculations (for example, in calculating \nindices into the color his\u00adtograms), replacing them with integer or .xed-point calculations. This results \nin a signi.cant speedup even on desktop machines (Figure4).WaveScriptofferedno special supportforthisrefactor\u00ading. \nWhileithas what amountstoabuilt-in Num type class, which helps write reusable code, ideally there would \nbe some tool sup\u00adport for this common problem: porting to .xed point, monitoring over.ows and quantifying \nthe loss of accuracy.  4.4 ExposingParallelism, DesignParameterization Finally, the most interesting \npart of this case study was using WaveScript to parallelize the application.Fortunately, refactoring \nfor clarity (abstracting data types, matrix transforms) had gotten us mostoftheway.The essentialchangewastomoveawayfromcode \nhandling monolithic matrices (arrays) to expressing the transform locally on image tiles we use tile \nto refer to a .xed submatrix of the image and then .nally at the level of the individual pixel (withthe \nstipulationthatapixel transformmustalsoaccessitslocal neighborhood). The end result was a reusable library \nfor parallel matrix computations (see parmatrix.ws). The .rst step is to implement transforms on tiles. \nFrom the perspective of the client code, this is the same as doing the trans\u00adform on the original matrix \n(only smaller). The library code han\u00addles splitting matrices into (overlapping) tiles and disseminating \nthose tiles to workers. The resulting data.ow graph structure is seen in Figure 6. The results of each \nindependent worker are joined, combined into a single matrix, and passed downstream to the remaining \ncomputation. In Figure 7 we see the interface for building tile kernels via the function tagged tile \nkernel. Call\u00ading tagged tile kernel(x, y, w, transform, init) will construct a stream transformer that \nsplits matrices on its input stream into Figure 6. An example data.ow graph resulting from using a tile/pixel \ntransform with rows = cols =2 (generated by the compilerusingAT&#38;T GraphViz).Even thoughthepixels \nare parti\u00adtionedintofour disjointtiles(dark purple),anextramarginmustbe included around each tile (orange) \nto ensure that each pixel within the tile may access its local neighborhood. x \u00d7 y tiles, with an overlap \nof w pixels in both dimensions. First, the init function is called (at metaprogram evaluation) to initial\u00adizes \nthe mutable state for each worker. Then, at runtime, each tile is processed by the transform function, \nproducing a new tile. The type signature for tagged tile kernel is listed in Figure 7. The tagged part \nis an additional complication introduced by the control-structure of the application. Because there is \nno shared state betweenkernels, all data must be passed through streams.Typical of stream-processing \napplications, thereisa tension betweendivid\u00ading an application into .ner-grained stream kernels and avoiding \ncomplicated data movement betweenkernels (forexample, pack\u00ading manycon.guration parameters into the stream)1. \nIn the case of the background subtraction algorithm it is de\u00adsirable to pass an extra piece of information \n(tag) from the origi\u00adnal stream of matrices down to each individual tile-or pixel-level worker,whichisexactlywhatthe \ninterfacetagged tile kernel al\u00adlows.For the background subtraction application, an earlier phase of processing \ndetermines what mode the computation is in (popu\u00adlating initial background model, or estimating foreground) \nand at\u00adtaches a mode .ag (boolean) on the stream of images. From tiles to pixels: The next stepinbuilding \nthe parmatrix.ws li\u00adbrarywastowrapthe tile-level operatortoexposeonlyapixel-level transform. The modi.ed \ninterface is shown in Figure 8. Note that the result a stream transformer on matrices has the same type \nas the tile-level version. The core of the background subtraction al\u00adgorithm, using the pixel-level interface, \nis shown in Figure 9. There is, however, one problem. When processing image data at the tile level, it \nis still possible to incrementally update histograms within a tile, albeit with decreased bene.t as tiles \nget smaller. The pixel\u00adlevel version based on the interface in Figure 8, however, cannot leverage this \noptimization.Wewill returnto this issueinamoment. In Figure 8, the Nbrhood type is used to represent \nthe method for accessing the pixels in a local vicinity. It is a function mapping 1This is analogous \nto the sometimes awkward growth in the number of function arguments in purely functional programs, where \nfunction argu\u00adments are the sole means of communication between disparate program fragments. Of course \nthis problem can be addressed by structuring tech\u00adniques, for example, using a Reader monad.  tagged \ntile kernel :: // First , provide # X/Y workers and depth of // neighborhood access ( overlap ) required: \n(Int, Int, Int, // Work function at each tile : ((tag, st , Tile px) -> Tile px2), / / Per-tile state \ninitializer : (Tile px) -> st) -> Stream (tag * Matrix px) -> Stream (Matrix px2); type Tile t = (Matrix \nt * (Int * Int) * (Int * Int)); Figure 7. Signature for tile-level transform. This function creates X\u00d7Yworkers, \neach of which handles a region of the input image. The transform is applied to each tile, and may maintain \nstate be\u00adtween invocation, so long as that state is encapsulated in a mutable value passed as an argument \nto the transform. This assumes the overlap between tilesis the samein both dimensions.A tileisa piece \nof the original matrix together with metadata to tell where it came from; its .elds are: (1) a matrix, \n(2) tile origin on original matrix, and (3) original image dimensions. tagged pixel kernel with nbrhood \n:: (Int, Int, Int, // X,Y, overlap (tag, st , Nbrhood px) -> px2, / / Per-pixel state initializer , takes \nindices: (Int , Int) -> st) -> Stream (tag * Matrix px) -> Stream (Matrix px2); type Nbrhood a = (Int \n,Int) -> a; Figure 8. Signature for pixel-level transform. tagged pixel kernel with nbrhood ( workersX \n, workersY , overlap , // This is the work function at each pixel. fun(bgEstimateMode, bghist, nbrhood) \n{ if bgEstimateMode then populatePixHist(bghist , nbrhood); else estimateFgPix(bghist , nbrhood); } \n, // Initialize per-pixel state ; create a histogram : fun(i,j) Matrix3D:make(NumBins1 , NumBins2, NumBins3, \n0)) Figure 9. Background subtraction using a pixel-level transform. (x, y) locations onto pixel values. \nAt (0, 0) the function gives the value of the center pixel (the one being transformed and updated). With \nthis we are able to express the background subtraction appli\u00adcationasasimplepixel-level transformation.The \ncoreoftheimple\u00admentation is shown in Figure 9. Given a boolean tag on the input stream(bgEstimateMode), \nand a state argument that contains the histogram for just that pixel(bghist), thekernel decides whether \nto populate the background(populatePixHist)or to estimate the foreground(estimateFgPix). Restoring incremental \nhistograms: The .nal step in porting our background subtraction algorithm was to reenable incremental \ncomputation of histograms in spite of the pixel-level interface to images. This is not dif.cult,but it \ndoes make the interface more complex (seen in Figure 10). Rather than direct access to neighbor\u00ading pixelvalues, \nnow the pixelkernel seesa sliding patch across the image (currently square,but couldbe generalizedtoa \nrectan\u00adgle). The carried over result from the last position is used, together with the pixels sliding \ninto view and the pixels sliding out, to com\u00adpute the new result. The underlying implementation is still \nbased tagged pixel kernel sliding nbrhood :: (Int, Int, Int, // Work function takes pixels in and pixels \nout. // carry will represent the last computed result: (tag, st, carry ,PixSetpx, PixSetpx) -> (px2, \ncarry) , / / Per-pixel state initializer , takes indices: (Int , Int) -> st , // Function to compute \nthe first carry: Nbrhood px -> carry) -> Stream (tag * Matrix px) -> Stream (Matrix px2); type PixSet \nt =((Int,Int,t) -> ()) -> () Figure 10. Signature for pixel-level transform supporting incre\u00admental computationof \nresult.With PixSets we avoid constructing new sets in memory, rather we let the client visit the relevant \npix\u00adels (and indices). Whole-program function inlining removes any performance penalty with this pattern. \non tagged tile kernel, and can only leverage incremental results within a tile. 5. WaveScript Learning \nCurve The core background subtraction algorithm was ported by the .rst author, who is also the primary \nimplementor of WaveScript, and naturally .nds it easy to use. However, as other members of the UCLA group \ngot involved and usedWaveScript for other parts of the application, the retraining challenges became \nclear. There were two main lessons learned, having to do with C-like syntax and quotation-free metaprogramming. \nFirst, WaveScript s syntactic similarity to C-family languages does reduce initial trepidation (even \nif perhaps it shouldn t). Cer\u00adtainly, several domain speci.c languages (e.g., Bluespec (7)) have ended \nup mimickingC orVerilog syntax for this reason. But we found that it also encouraged attempts to directly \nreuse inappro\u00adpriate programming idioms. Setting aside basic misunderstandings ofWaveScript constructs \n(forexample, one programmer, unfamil\u00adiar with type inference, thought type declarations were necessary \nfor assigning types to variables rather than de.ning new types), the major problem we found was with \nthe use of mutable state. Of course, manyCprogrammers use mutationby habit.WaveScript s support for mutablevariables \nand arrays can encourage this.Forex\u00adample, programmerswould often declare state globally and attempt \nto modify it within the work functions for stream operators: myvar = 0; S2 = iterate x in S1 { myvar++; \n... } Dangerously, this example actually works;theWaveScriptevalu\u00adation model involves reifying a stream \nvalue back into code, and whatever state is found in the environment of the closure attached toadata.ow \noperator(work function) becomestheprivate statefor that operator. However, sharing state between operators \n(the same mutable object reachable by two closures) is disallowed and will resultina compile-timeerror.TheWaveScriptdesignis \npredicated on the idea that understanding these meta-programevaluationfail\u00adures is easier than understanding \nthe error messages generated by a suf.ciently sophisticated type system to rule out the errors. Nev\u00adertheless, \nit still helps to teach a beginner mode, where a special state keyword forces each operator s state to \nbe declared in a re\u00adstricted lexical scope: S2 = iterate x in S1 { state { myvar = 0 } myvar++; ... } \nThe second major hurdlewas understanding meta-programming in WaveScript. Again, WaveScript assumes that \na simple model with some exceptions and corner cases is easier to learn than a more sophisticated one. \nSpeci.cally, unlike more general meta\u00adFigure11. Parallelspeedup:16 data-parallelworkers withvariable \nnumber of enabled processor cores. Test platform was an AMD Barcelona with four quad-core processors. \nCores were disabled using Linux s /sys/devices/system/cpu interface. The data point at 0 shows the single \nthreaded speed i.e. the program con.gured with only a single worker. The drop in performance at data-point \n1 is due to the overhead of splitting and reassembling the matrix.  programming languages likeMetaML \n(8),WaveScript does not use explicit quotation and anti-quotation constructs for creating code values \n. Rather, the programmer is told that everything outside of an iterate will evaluate at compile-time. \nNonetheless we saw fre\u00adquent confusion about whetheradata structure shouldbe initialized at meta-program \nevaluation time, or at the beginning of runtime. Also, there is the issue of distinguishing the capabilities \nof the meta-and object-languages. Like manyother two-stage DSLs, WaveScript is anasymmetric meta-programming \nsystem, where the meta-language differs from the object-language. (For example, the object-language lacks \nclosures.) Attempting to use meta-language featuresinthe object-language resultsinacompile-time error(with \ncode location).Forexample, one programmer triedto read con.g\u00aduration .les at runtime, which is not possible \nif the code is running on an embedded platform such asaphone. One related problem had to do with the \nforeign-function interface (FFI), which can only be accessed at runtime. Programmers ran into dif.culties \ntrying to use theFFI beforetheyhada.rm graspofthe language.Someof these uses of the FFI were spurious, \nwhile others were an unfortunate consequence of the need to interface with hardware to get offthe ground \nin sensing applications. Possible .xes would include ban\u00adning the FFI in the aforementioned beginner \nmode, or restricting its use to strict idioms for data acquisition. 6. Results and Discussion The end \nresultof this projectwasa cleanedup implementation that also exposes parallelism. (And a reusable parallel \nmatrix library!) Parallel speedups for the .nal version of the background subtrac\u00adtion algorithm are \nshown in Figure 5. These results are generated given a single, .xed 4 \u00d7 4 tiling of the matrix (16 tiles) \nthat results in 16 stream operators ( workers ) running on 16 threads. Another approach is to havethe \nmetaprogram set the tiling parameters based on the number of CPUs on the target machine. But this is \ncompli\u00adcatedbytheneedtofactorthetarget numberof threadsinto sepa\u00adrate x and y components such that xy \n= numthreads, which re\u00adsultsintilesofvaryingaspect ratios.Somewhat suprisingly,theop\u00aderating system does \na great job of juggling these 16 threads among avariable numberof processor cores, with theexceptionofthe \nun\u00adfortunate case at 11 cores. If the OS were doing poorly, we would expect to see an outlier at 16 cores \nwhere the mapping is one-to-one (and perhaps 8, 4, and 2). Allowing the metaprogram to read the number \nof CPUs and determineatilesizeisanexampleoftheutilityofthe metaprogram asa separate phase that precedes \ntheWaveScript compiler sown data.ow-graph schedulingandoptimization. Still,itwouldbe ideal to expose \nmore of this tuning problem to the compiler itself. In the future, perhaps a method will be discovered \nto expose the compiler sown pro.le-driven optimization and auto-tuning process so that the programmer \nmay delegate the tile-size decision. This application also turned out to be a good candidate for dis\u00adtributed \n(inter-device) partitioning. After performing background subtraction most of the image is simply blacked \nout; with simple run-length encoding, these frames require much less network band\u00adwidth when sent back \nto the server over a wireless network. More\u00adover, once the parmatrix.ws library is used, the space of \nchoices becomes more continuous. Each tile-level worker can be placed on the embedded or server-side. \nHosting half the workers results in half the data-reduction at half the cost, and, importantly, half \nthe memory usage forexpensive3D histograms.Fora detailed discus\u00adsionofWaveScript s partitioning methodology, \nsee (6). Ultimately, while this application was greatly improved during its reimplementation, some of \nthe interfaces we used represent a more imperative formulation than we would like for example, kernels \naccepting a mutable state argument rather than producing a fresh state. A pure formulation would be ideal, \nbut we are not currently able to achieve it with the near zero performance penalty that we require. Impure \nor not, abstracting control-.ow was never\u00adtheless valuable in this application. References [1] Wavescript \nusers manual, http://regiment.us/wsman/. [2] Michael Allen,Lewis Girod,RyanNewton, Samuel Madden, DanielT. \nBlumstein, and Deborah Estrin. Voxnet: An interactive, rapidly\u00addeployable acoustic monitoring platform. \nIn IPSN 08: Information processing in sensor networks, 2008. [3] Lennart Augustsson, Howard Mansell, \nand Ganesh Sittampalam. Par\u00adadise: a two-stage dsl embedded in haskell. ICFP Experience Report, pages \n225 228, 2008. [4] Jakob Eriksson, Lewis Girod, Bret Hull, Ryan Newton, Samuel Mad\u00adden, and Hari Balakrishnan. \nThe pothole patrol: using a mobile sensor network for road surface monitoring. In MobiSys 08: Proceeding \nof the 6th international conference on Mobile systems, applications, and services, pages 29 39,NewYork,NY, \nUSA, 2008.ACM. [5] Geoffrey Mainland, Greg Morrisett, and Matt Welsh. Flask: staged functional programming \nfor sensor networks. SIGPLAN Not., 43(9):335 346, 2008. [6] Ryan Newton, Sivan Toledo, Lewis Girod, Hari \nBalakrishnan, and Samuel Madden. Wishbone: Pro.le-based partitioning for sensornet applications. In NSDI \n09: Networked Systems Design and Implementa\u00adtion, 2009. [7] R. Nikhil. Bluespec system verilog: ef.cient, \ncorrect rtl from high level speci.cations. Formal Methods and Models for Co-Design, 2004. MEMOCODE 04., \npages 69 70, June 2004. [8]W.Taha andT. Sheard. Multi-stage programming withexplicit anno\u00adtations. In \nPartial Evaluation and Semantics-Based Program Manipu\u00adlation, Amsterdam, The Netherlands, June 1997, \npages 203 217. New York:ACM, 1997.   \n\t\t\t", "proc_id": "1596550", "abstract": "<p>This paper presents our experience using a domain-specific functional language, WaveScript, to build embedded sensing applications used in scientific research. We focus on a recent computervision application for detecting birds in their natural environment. The application was ported from a prototype in C++. In reimplementing the application, we gained a much cleaner factoring of its functionality (through higher-order functions and better interfaces to libraries) and a near-linear parallel speed-up with no additional effort. These benefits are offset by one substantial downside: the lack of familiarity with the language of the original vision researchers, who understandably tried to use the language in the familiar way they use C++ and thus ran into various problems.</p>", "authors": [{"name": "Ryan R. Newton", "author_profile_id": "81341494555", "affiliation": "MIT, Cambridge, MA, USA", "person_id": "P1613987", "email_address": "", "orcid_id": ""}, {"name": "Teresa Ko", "author_profile_id": "81309490460", "affiliation": "UCLA, Los Angeles, CA, USA", "person_id": "P1613988", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1596550.1596562", "year": "2009", "article_id": "1596562", "conference": "ICFP", "title": "Experience report: embedded, parallel computer-vision with a functional DSL", "url": "http://dl.acm.org/citation.cfm?id=1596562"}