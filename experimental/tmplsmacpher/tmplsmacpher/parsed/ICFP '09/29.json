{"article_publication_date": "08-31-2009", "fulltext": "\n Implementing First-Class Polymorphic Delimited Continuations by a Type-Directed Selective CPS-Transform \nTiark Rompf Ingo Maier Martin Odersky Programming Methods Laboratory (LAMP) \u00b4 Ecole Polytechnique F\u00b4ed\u00b4erale \nde Lausanne (EPFL) 1015 Lausanne, Switzerland {.rstname.lastname}@ep..ch Abstract We describe the implementation \nof .rst-class polymorphic delim\u00adited continuations in the programming language Scala. We use Scala s \npluggable typing architecture to implement a simple type and effect system, which discriminates expressions \nwith control ef\u00adfects from those without and accurately tracks answer type modi\u00ad.cation incurred by control \neffects. To tackle the problem of im\u00adplementing .rst-class continuations under the adverse conditions \nbrought upon by the Java VM, we employ a selective CPS trans\u00adform, which is driven entirely by effect-annotated \ntypes and leaves pure code in direct style. Benchmarks indicate that this high-level approach performs \ncompetitively. Categories and Subject Descriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs \nand Features Control structures General Terms Languages, Theory Keywords Delimited continuations, selective \nCPS transform, control effects, program transformation 1. Introduction Continuations, and in particular \ndelimited continuations, are a ver\u00adsatile programming tool. Most notably, we are interested in their \nability to suspend and resume sequential code paths in a controlled way without syntactic overhead and \nwithout being tied to VM threads. Classical (or full) continuations can be seen as a functional ver\u00adsion \nof the infamous GOTO-statement (Strachey and Wadsworth 2000). Delimited (or partial, or composable) continuations \nare more like regular functions and less like GOTOs. They do not em\u00adbody the entire rest of the computation, \nbut just a partial rest, up to a programmer-de.ned outer bound. Unlike their undelimited coun\u00adterparts, \ndelimited continuations will actually return control to the caller after they are invoked, and they may \nalso return values. This means that delimited continuations can be called multiple times in succession, \nand the program can proceed at the call site afterwards. This ability makes delimited continuations strictly \nmore powerful than regular ones. Operationally speaking, delimited continuations Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. ICFP 09, August 31 September 2, 2009, Edinburgh, \nScotland, UK. Copyright c &#38;#169; 2009 ACM 978-1-60558-332-7/09/08. . . $5.00 do not embody the entire \ncontrol stack but just stack fragments, so they can be used to recombine stack fragments in interesting \nand possibly complicated ways. To access and manipulate delimited continuations in direct\u00adstyle programs, \na number of control operators have been proposed, which can be broadly classi.ed as static or dynamic, \naccording to whether the extent of the continuations they capture is determined statically or not. The \ndynamic variant is due to Felleisen (1988); Felleisen et al. (1988) and the static variant to Danvy and \nFilinski (1990, 1992). The static variant has a direct, corresponding CPS\u00adformulation which makes it \nattractive for an implementation using a static code transformation and thus, this is the variant underly\u00ading \nthe implementation described in this paper. We will not go into the details of other variants here, but \nrefer to the literature instead (Dyvbig et al. 2007; Shan 2004; Biernacki et al. 2006); suf.ce it to \nnote that the two main variants, at least in an untyped setting, are equally expressive and have been \nshown to be macro-expressible (Felleisen 1991) by each other (Shan 2004; Kiselyov 2005). Ap\u00adplying the \ntype systems of Asai and Kameyama (2007); Kameyama and Yonezawa (2008), however, renders the dynamic \ncontrol oper\u00adators strictly more expressive since strong normalization holds only for the static variant \n(Kameyama and Yonezawa 2008). In Danvy and Filinski s model, there are two primitive opera\u00adtions, shift \nand reset. With shift, one can access the current continuation and with reset, one can demarcate the \nboundary up to which continuations reach: A shift will capture the control context up to, but not including, \nthe nearest dynamically enclosing reset (Biernacki et al. 2006; Shan 2007). Despite their undisputed \nexpressive power, continuations (and in particular delimited ones) have not yet found their way into \nthe majority of programming languages. Full continuations are standard language constructs in Scheme \nand popular ML dialects, but most other languages do not support them natively. This is partly because \nef.cient support for continuations is assumed to require special provisions from the runtime system (Clinger \net al. 1999), like the ability to capture and restore the run-time stack, which are not available in \nall environments. In particular, popular VM s such as the JVM or the .NET CLR do not provide this low\u00adlevel \naccess to the run-time stack. One way to overcome these limitations is to simulate stack inspection with \nexception handlers and/or external data structures (Pettyjohn et al. 2005; Srinivasan 2006). Another \navenue is to use monads instead of continuations to ex\u00adpress custom-de.ned control .ow. Syntactic restrictions \nimposed by monadic style can be overcome by supporting more language constructs in the monadic level, \nas is done in F# s work.ow ex\u00adpressions. Nevertheless, the fact remains that monads or work.ows impose \na certain duplication of syntax constructs that need to be made available on both monadic and direct \nstyle levels. Besides that, it is common knowledge that delimited continuations are able to express any \nde.nable monad (Filinski 1994, 1999). In this paper we pursue a third, more direct alternative: trans\u00adform \nprograms using delimited continuations into CPS using a type-directed selective CPS transform. Whole \nprogram CPS trans\u00adforms were previously thought to be too inef.cient to be practical, unless accompanied \nby tailor-made compiler backends and run\u00adtimes (Appel 1992). However, we show that the more localized \nCPS-transforms needed for delimited continuations can be imple\u00admented on stock VMs in ways that are competitive \nin terms of per\u00adformance. 1.1 Contributions To the best of our knowledge, we are the .rst to implement \ndirect\u00adstyle shift and reset operators with full answer type polymor\u00adphism in a statically type-safe \nmanner and integrated into a widely available language. We implement a simple type and effect system \nwhich discrimi\u00adnates pure from impure expressions, while accurately tracking an\u00adswer type modi.cation \nand answer type polymorphism. We thereby extend the work of Asai and Kameyama (2007) to a slightly dif\u00adferent \nnotion of purity, which identi.es all uses of shift in a program and thus is a suitable basis for applying \na selective CPS transform (Nielsen 2001). To the best of our knowledge, we are the .rst to use a selective \nCPS transform to implement delimited continuations. With our implementation, we present evidence that \nthe standard CPS transform, when applied selectively, is a viable means to ef\u00ad.ciently implement static \ncontrol operators in an adverse environ\u00adment like the JVM, under the condition that closures are available \nin the host language.  1.2 Related Work Filinski (1994) presented an ML-implementation of shift and \nreset (using callcc and mutable state), which has .xed an\u00adswer types. Gasbichler and Sperber (2002) describe \na direct imple\u00admentation in Scheme48, which, of course, is not statically typed. Dyvbig et al. (2007) \npresented a monadic framework for delimited continuations in Haskell, which includes support for shift \nand reset among other control operators and supports multiple typed prompts. This framework does not \nallow answer type modi.ca\u00adtion, though, and the control operators can only be used in monadic style (e.g. \nusing Haskell s do notation) but not in direct-style. Kise\u00adlyov et al. (2006) presented a direct-style \nimplementation in (byte\u00adcode) OCaml, which is inspired by Dyvbig et al. s framework. The OCaml implementation \ndoes not support answer type modi.cation, though, and the type system does not prevent using shift out\u00adside \nthe dynamic scope of a reset. In this case, a runtime excep\u00adtion will occur. All of the above implementations \ncannot express Asai s type-safe implementation of printf (Asai 2007). Kiselyov (2007) gave an adaption \nof Asai and Kameyama (2007) s type sys\u00adtem (powerful enough to express printf) in Haskell, which is fully \ntype safe and provides answer type polymorphism, but can\u00adnot be used in direct-style (in fact, due to \nthe use of parameterized monads (Atkey 2006), do notation cannot be used either). Asai and Kameyama (2007) \ndid not provide a publicly available implemen\u00adtation of their calculus. On the JVM, continuations have \nbeen implemented using a form of generalized stack inspection (Pettyjohn et al. 2005) in Kilim (Srinivasan \n2006; Srinivasan and Mycroft 2008). These continua\u00adtions can in fact be regarded as delimited, but there \nis no published account of their delimited nature. Kilim also tracks control effects using a @pausable \nannotation on methods but there are no ex\u00adplicit or de.nable answer types. Danvy and Filinski (1989) \npresented a monomorphic type sys\u00adtem for shift and reset, which was extended by Asai and Kameyama (2007) \nto provide answer type polymorphism. A type and effect system for full continuations has been presented \nby Thi\u00adelecke (2003). None of these allow to identify all uses of shift (including trivial ones like \nin shift(k => k(3))) in a given source program. The selective CPS transform has been introduced by Nielsen \n(2001), but it has not been applied in the context of de\u00adlimited continuations. 1.3 Overview The rest \nof this paper is structured as follows. Section 2 gives a short overview of the Scala language and the \nlanguage subset relevant to our study. Section 3 is the main part of this paper and describes the typing \nrules and program transformations which constitute the implementation of delimited continuations in Scala. \nSection 4 presents programming examples, Section 5 performance .gures, and Section 6 concludes. 2. The \nHost Language This section gives a quick overview of the language constructs of Scala as far as they \nare necessary to understand the material in this paper. Scala is different from most other statically \ntyped languages in that it fuses object-oriented and functional programming. Most features from traditional \nfunctional languages such as Haskell or ML are also supported by Scala, but sometimes in a slightly differ\u00adent \nway. Value de.nitions in Scala are written val pat = expr where pat is a pattern and expr is an expression. \nThey corre\u00adspond to let bindings. Monomorphic function de.nitions are writ\u00adten def f(params): T = expr \n where f is the function s name, params is its parameter list, T is its return type and expr is its body. \nRegular by-value parameters are of the form x: T, where T is a type. Scala also permits by\u00adname parameters, \nwhich are written x: => T. It is possible to leave out the parameter list of a function completely. In \nthis case, the function s body is evaluated every time the function s name is used. De.nitions in Scala \nprograms are always nested inside classes or objects.1 A simple class de.nition is written class C[tparams](params) \nextends Ds { defs } This de.nes a class C with type parameters given by tparams, value parameters given \nby params, superclasses and -traits given by Ds and de.nitions given by defs. All components except the \nclass name can be omitted. Classes are instantiated to objects using the new operator. One can also de.ne \nan object directly with almost the same syntax as a class: object O extends Ds { defs } Such an object \nis an instance of an anonymous class with the given parent classes Ds and de.nitions defs. The object \nis created lazily, the .rst time it is referenced. The most important form of type in Scala is a reference \nto a class C, or C[Ts] if C is parameterized. Unary function types from S to T are type instances of \nclass Function1[S, T], but one usually uses the abbreviated syntax S =>T for them. By-name function 1 \nDe.nitions outside classes are supported in the Scala REPL and in Scala scripts but they cannot be accessed \nfrom outside their session or script. types can be written (=> S) => T. Most of Scala s libraries are \nwritten in an object-oriented style, where operations apply to an implicit this receiver object. For \ninstance, a List class would support operations map and flatMap in the following way: class List[T] { \n... def map[U](f: T => U) = this match { case Nil => Nil case x :: xs => f(x) :: xs.map(f) } def flatMap[U](f: \nT => List[U]) = this match { case Nil => Nil case x :: xs => f(x) ::: xs.flatMap(f) } } Here, :: is list \ncons and ::: is list concatenation. The implemen\u00adtations above also show Scala s approach to pattern \nmatching using match expressions. Similar to Haskell and ML, pattern matching blocks that enclose a number \nof cases in braces can also appear outside match expressions; they are then treated as function liter\u00adals. \nMost forms of expressions in Scala are written similarly to Java and C, except that the distinction between \nstatements and expres\u00adsions is less strict. Blocks { ... }, for example, can appear as expressions, including \nas function arguments. Another departure from Java is support for function literals, which are written \nwith an in.x =>. For instance, (x:Int) => x +1 represents the incrementation function on integers. All \nbinary operations in Scala are treated as method calls. x op y is treated as x.op(y) for every operator \nidenti.er op, no matter whether op is symbolic or alphanumeric. In fact, map and flatMap correspond closely \nto the operations of a monad. flatMap is monadic bind and map is bind with a unit result. Together, they \nare suf.cient to express all monadic expressions as long as injection into the monad is handled on a \nper-monad basis. Therefore, all that needs to be done to implement monadic unit is to provide a corresponding \nconstructor operation that, in this case, builds one-element lists. Similarly to Haskell and F#, Scala \nsupports monad comprehensions, which are called for\u00adexpressions. For instance, the expression for (x \n<-xs; y <-f(x)) yield g(x, y) is expanded to xs.flatMap(x => f(x).map(y => g(x, y))) De.nitions as well \nas parameters can be marked as implicit. Implicit parameters that lack an actual argument can be instantiated \nfrom an implicit de.nition that is accessible at the point of call and that matches the type of the parameter. \nImplicit parameters can simulate the key aspects of Haskell s type classes (Moors et al. 2008). An implicit \nunary function can also be used as a conversion, which implictly maps its domain type to its range. De.nitions \nand types can be annotated. Annotations are user\u00adde.ned metadata that can be attached to speci.c program \npoints. Some annotations are visible at run-time where they can be ac\u00adcessed using re.ection. Others \nare consumed at compile-time by compiler plugins. The Scala compiler has a standardized plugin architecture \n(Nielsen 2008) which lets users add additional type checking and transformation passes to the compiler. \nSyntactically, annotations take the form of a class constructor preceded by an @-sign. For instance, \nthe type String @cps[Int, List[Int]] is the type String, annotated with an instance of the type cps applied \nto type arguments Int and List[Int]. reset { val x = shift { k: (Int=>Int) => \"done here\" No output (continua\u00ad} \ntion not invoked) println(x) } reset { val x = shift { k: (Int=>Int) => k(7) Output: 7 } println(x) } \nval x = reset { shift { k: (Int=>Int) => k(7) } + 1 } * 2 println(x) Output: 16 val x = reset { shift \n{ k: (Int=>Int) => k(k(k(7))) } + 1 } * 2 println(x) Output: 20 val x = reset { shift { k: (Int=>Int) \n=> k(k(k(7))); \"done\" } + 1 } println(x) Output: done def foo() = { 1 + shift(k => k(k(k(7)))) } def \nbar() = { foo() * 2 } def baz() = { reset(bar()) } println(baz()) Output: 70 Figure 1. Examples: shift \nand reset In this paper, we study the addition of control operators shift and reset to this language \nframework, which together implement static delimited continuations (Danvy and Filinski 1990, 1992). The \noperational semantics of shift is similar to that of callcc in languages like Scheme or ML, except that \na continuation is only captured up to the nearest enclosing reset and the capturing is always abortive \n(i.e. the continuation must be invoked explicitly). Figure 1 presents some examples to illuminate the \nrelevant cases. 3. Implementation Broadly speaking, there are two ways to implement continuations (see \n(Clinger et al. 1999) for a more detailed account). One is to stick with a stack-based execution architecture \nand to reify the cur\u00adrent continuation by making a copy of the stack, which is reinstated when the continuation \nis invoked. This is the approach taken by many language implementations that are in direct control of \nthe runtime system. Direct implementations of delimited continuations using an incremental stack/heap \nstrategy have also been described (Gasbichler and Sperber 2002). In the Java world, stack-copying has \nbeen used to implement continuations on the Ovm virtual ma\u00adchine (Dragos et al. 2007). For Scala, though, \nthis is not a viable op\u00adtion, since Scala programs need to run on plain, unmodi.ed, JVMs, which do not \npermit direct access or modi.cation of stack contents. A variant of direct stack inspection is generalized \nstack inspec\u00adtion (Pettyjohn et al. 2005), which uses auxiliary data structures to simulate continuation \nmarks that are not available on the JVM or CLR architectures. That approach is picked up and re.ned by \nKilim (Srinivasan 2006; Srinivasan and Mycroft 2008), which transforms compiled programs at the bytecode-level, \ninserting copy and restore instructions to save the stack contents into a separate data structure (called \na .ber) when a continuation is to be accessed. The other approach is to transform programs into continuation\u00adpassing-style \n(CPS) (Appel and Jim 1989; Danvy and Filinski 1992). Unfortunately, the standard CPS-transform is a whole\u00adprogram \ntransformation. All explicit or implicit return state\u00adments are replaced by function calls and all state \nis kept in closures, completely bypassing the stack. For a stack-based architecture like the JVM, of \ncourse, this is not a good .t. On the other hand, regarding manually written CPS code shows that only \na small number of functions in a program actually need to pass along continuations. What we are striving \nfor is thus a se\u00adlective CPS transform (Nielsen 2001) that is applied only where it is actually needed, \nand allows us to stick to a regular, stack-based runtime discipline for the majority of code. As a side \neffect, this by design avoids the performance problems associated with imple\u00admentations of delimited \ncontinuations in terms of undelimited ones (Balat and Danvy 1997; Gasbichler and Sperber 2002). In general, \na CPS transform is feasible only if the underlying architecture sup\u00adports constant-space tail-calls, \nwhich is the case for the .NET CLR but not yet for the JVM2. So far, we have not found this a prob\u00adlem \nin practice. One reason is that for many use-cases of delim\u00adited continuations, call depth tends to be \nrather small. Moreover, some applications lend themselves to uses of shift and reset as parts of other \nabstractions, which allow a transparent inclusion of a trampolining facility, in fact introducing a back-door \ntail-call optimization. 3.1 Syntax-Directed Selective CPS Transform Taking a step back, we consider \nhow we might implement delim\u00adited continuations as user-level Scala code. The technique we use comes \nas no surprise and is a straightforward generalization of the continuation monad to one that is parametric \nin the answer types. On a theoretical level, parameterized monads have been studied in (Atkey 2006). \nAs a .rst step, we de.ne a wrapper class to hold shift blocks and provide methods to extend and compose \nthem. The method flatMap is the monadic bind operation: class Shift[+A,-B,+C](val fun: (A => B) =>C) \n{ def map[A1](f: (A => A1)): Shift[A1,B,C] = { new Shift((k:(A1 => B)) => fun((x:A) => k(f(x)))) } def \nflatMap[A1,B1,C1<:B](f: (A => Shift[A1,B1,C1])): Shift[A1,B1,C] = { new Shift((k:(A1 => B1)) => 2 Tail-call \nsupport for the JVM has been proposed by JSR 292 (Rose 2008) fun((x:A) => f(x).fun(k))) } }  Note the \n+/-variance annotations on the type parameters of class Shift, which make the class covariant in parameters \nA and C and contravariant in B. This makes Shift objects consistent with the subtyping behavior of the \nparameter fun. We go on by de.ning reset to operate on Shift objects, in\u00advoking the body of a given shift \nblock with the identity function to pass the result back into the body (which is the standard CPS de.nition \nof reset): def reset[A,C](c: Shift[A,A,C]) = c.fun(x:A => x) With these de.nitions in place, we can \nuse delimited continua\u00adtions by placing Shift blocks in for comprehensions, which are Scala s analog \nto the do notation in Haskell: val ctx = for { x <-new Shift((k:Int=>Int) => k(k(k(7)))) } yield (x +1) \n reset(ctx) // 10 This works because during parsing, the Scala compiler desugars the for comprehension \ninto invocations of map and flatMap: val ctx = new Shift((k:Int=>Int) => k(k(k(7)))) .map(x => x + 1) \nreset(ctx) // 10 So for all practical matters, we have a perfectly workable se\u00adlective CPS transform, \nalbeit a syntax-directed one, i.e. one which is carried out by the parser on the basis of purely syntactic \ncri\u00adteria, more speci.cally the placement of the keywords for and yield. Being forced to use for comprehensions \neverywhere con\u00adtinuations are accessed does not make for a pleasant programming style, though. Instead, \nwe would like our CPS to be type-directed, i.e. carried out by the compiler on the basis of expression \ntypes. 3.2 Effect-Annotated Types The motivation for this approach is to transparently mix code that \nmust be transformed with code that does not. Therefore, we have to disguise the type Shift[A,B,C] as \nsomething else, notably something that is compatible with type A because A is the argument type of the \nexpected continuation (recall the de.nition of Shift). Thus, we make use of Scala s pluggable typing \nfacilities and in\u00adtroduce a type annotation @cps[-B,+C], with the intention that any expression of type \nA @cps[B,C] should be translated to an expression of type Shift[A,B,C]. The approach of using annotated \ntypes to track control effects has a close correspondence to the work on polymorphic delimited continuations \n(Asai and Kameyama 2007). It has been noted early (Danvy and Filinski 1989) that in the presence of control \noperators, standard typing judgements of the form G f e : t, which associate a single result type t with \nan expression e, are insuf.cient to accurately describe the result of evaluating the expression e. The \nreason is that evaluating e may change the answer type of the enclosing computation. In the original \ntype system by Danvy and Filinski (1989), typing judgements thus have the form G; a f e : t ; \u00df meaning \nthat if e is evaluated in a context represented by a func\u00adtion from t to a, the type of the result will \nbe \u00df or equivalently In a context where the (original) result type was a, the type of e is t and the \nnew type of the result will be \u00df . Asai and Kameyama (2007) present a polymorphic extension of this \n(monomorphic) type system and prove a number of desir\u00adable properties, which include strong type soundness, \nexistence of principal types and an ef.cient type inference algorithm. A key ob\u00adservation is that if \ne does not modify its context, a and \u00df will be identical and if G; a f e : t; a is derivable for any \na, the expres\u00adsion does not have any measurable control effect. In other words, pure expressions (e.g. \nvalues) are intuitively characterized as being polymorphic in the answer type and not modifying it (Thielecke \n2003). Pure expressions such as lambda abstractions (or other values) should thus be allowed to be used \npolymorphically in the language. The ability to de.ne functions that are polymorphic in how they modify \nthe answer type when invoked plays a crucial role e.g. in the implementation of type-safe printf (Asai \n2007). Asai and Kameyama therefore use two kinds of typing judgements to distinguish pure from impure \nexpressions, and they require that only pure expressions be used in right-hand sides of let-bindings, \nin order to keep their (predicative) type system sound. The kinds of judgements used are G fp e : t G; \na f e : t ; \u00df for pure and impure expressions, respectively. Expressions classi\u00ad.ed as pure are variables, \nconstants, lambda abstractions and uses of reset. In addition, pure expressions can be treated as impure \nones that do not change the answer type: G fp e : t G; a f e : t ; a Instead of the standard function \ntypes s . t, types of the form s/a . t/\u00df are used (denoting a change in the answer type from a to \u00df when \nthe function is applied).  3.3 Pure is not Pure For our goal of applying a selective CPS transform, \nwe need a slightly different notion of purity. Since we have to transform all expressions that actually \naccess their continuation (and only those), we have to be able to identify them accurately. Neither the \nintuitive notion of purity nor the purity judgement of Asai and Kameyama does provide this classi.cation. \nFor example, the ex\u00adpression shift(k => k(3)), which needs to be transformed, would be characterized \nas pure in the intuitive sense (it is polymor\u00adphic in the answer type and does not modify it) but the \npurity judge\u00adment is not applicable. The expression id(3), however, which should not be CPS-transformed, \nis intuitively pure but impure as de.ned by applicability of the purity judgement, as are function applications \nin general. We thus de.ne an expression as pure if and only if it does not reify its continuation via \nshift in the course of its evaluation. In order to adapt the effect typing to this modi.ed notion of \npurity we use a slightly different formulation. We keep the standard typing judgements of the form G \nf e : t , but we enrich the types themselves. That is, t can be either A, denoting a pure type, or A \n@cps[B,C], denoting an impure type that describes a change of the answer type from B to C. We will write \nAa when we talk about both pure and impure types. We present typing rules for a selected subset of the \nScala lan\u00adguage in Figure 2. Impure types are introduced by shift expres\u00adsions (SHIFT).3 Impure types \nare eliminated by reify expressions 3 The given typing of shift(f), which requires f to be a pure function, \nis slightly different from the usual presentation, which would allow f to have non-trivial control effects \nitself. This is no limitation, however, since the usual de.nition of shift wraps its body with an implicit \nreset. Thus, adding an explicit reset around the body of an impure f will make the expression well-typed \nand achieve the standard behavior. G f f : (A => B) => C (SHIFT) G f shift(f) : A @cps[B,C] G f c : A \n@cps[B,C] (REIFY) G f reify(c) : Shift[A,B,C] G f f : (A => (B.)) a G f e : A\u00df d = comp(a\u00df.) (APP-VALUE) \nG f f(e) : Bd G f f : ((=>A\u00df) =>(B.)) a G f e : A\u00df d = comp(a.) (APP-NAME) G f f(e) : Bd G f f : ((=>A \n@cps[C,C]) =>(B.)) a G f e : Ad = comp(a.) G f f(e) : Bd (APP-DEMOTE) G,x : A, f : (A=>B\u00df) f e : B\u00df G,f \n: (A=>B\u00df) f{r} : C. G f def f(x:A): B\u00df = e; r : C. (DEF-CBV) G,x : A a,f : ((=>Aa)=>B\u00df) f e : B\u00df G,f \n: ((=>Aa)=>B\u00df) f{r} : C. G f def f(x:=>Aa): B\u00df = e; r : C. (DEF-CBN) G f e : Aa G,x : A f{r} : B\u00df d \n= comp(a\u00df) G f val x: A = e; r : Bd (VAL) G f s : Aa G f e : B\u00df d = comp(a\u00df) (SEQ) G f{s; e} : Bd Figure \n2. Typing rules for a selected subset of Scala expressions. Lowercase letters are expressions, uppercase \nletters types without annotations, greek letters are either annotations or no annotations. comp(E)= E \ncomp(@cps[B,C])= @cps[B,C] comp(a)= @cps[V ,W ] W<: B comp(@cps[B,C]a)= @cps[V ,C] (A => B) => C<: (U \n=> V ) => W A @cps[B,C] <: U @cps[V ,W ] Figure 3. Composition of control effects and subtyping between \nannotated types. Lowercase letters are expressions, uppercase let\u00adters are types without annotations, \nE denotes the empty sequence of annotations, other greek letters are either annotations or no annota\u00adtions. \n (REIFY),whichallow a Scala program todirectlyaccessthe Shift object that results from CPS-transforming \nan expression. We show in Section 3.4 how to express reset in terms of reify. As opposed to the type \nsystem of Asai and Kameyama, which provides no distinction between pure and impure functions, we can \ndistinguish the two cases by looking at the return type. If no @cps annotation is present, and only then, \nthe function is considered pure. Functions with a single by-value parameter are of the type A => (B\u00df) \n(DEF-CBV). That the effect of applying a function is coupled to its return type is consistent with the \nintuitive assump\u00adtion that the return type describes what happens when the function is applied. The formal \nparameter is not allowed to have an effect. This is also intuitively consistent, because for a by-value \nparame\u00adter, any effect the evaluation of an argument might have will oc\u00adcur at the call site (APP-VALUE), \nso inside the function, accessing the argument will be effect-free. On the other hand, functions in Scala \ncan also have by-name parameters. A function with a sin\u00adgle by-name parameter will have the type (=>Aa) \n=> (B\u00df) (DEF-CBN), which is consistent with the assumption that the effect of evaluating the argument \nnow happens inside the function body (APP-NAME). If a function taking an impure parameter is applied \nto a pure expression, the argument is demoted to impure provided that the parameter type does not demand \nchanging the answer type (APP-DEMOTE). The typing rules for other kinds of expressions (e.g. conditionals) \nare similar in spirit to those presented for func\u00adtion applications. Since functions can be polymorphic \nin their answer type mod\u00adi.cation, we allow right-hand-sides of def statements to be im\u00adpure. We also \nallow impure expressions in val de.nitions (these are monomorphic in Scala) that occur inside methods, \nbut the iden\u00adti.er will have a pure type since the effect occurs during evaluation of the right hand \nside and has already happened once the identi.er is assigned (VAL). The effect is instead accounted to \nthe enclosing block (SEQ). In Scala, val de.nitions are also used to de.ne ob\u00adject or class level .elds. \nContrary to those inside methods, these val de.nitions are required to be pure since we cannot capture \na continuation while constructing an object. Subtyping between impure types takes the annotations into \nac\u00adcount, with proper variances as induced by the corresponding CPS representation (see Figure 3). There \nis no subtyping or general sub\u00adsumption between pure and impure types, but pure expressions may be treated \nas impure (and thus polymorphic in the answer type) where required, as de.ned by the typing rules in \nFigure 2. This is a subtle difference that allows us to keep track of the purity of each expression and \nprevents the loss of accuracy associated with Asai and Kameyama s subsumptive treatment of pure expressions \nas impure ones. The CPS transform will detect these conversion cases in the code and insert shifts where \nnecessary to demote pure expressions to impure ones. In addition, impure expressions can be treated as \npure ones in all by-value places, i.e. those where the expression is reduced to a value. The expression \ns effect (which happens during evaluation) is then accounted to the enclosing ex\u00adpression. And this is \nexactly what will drive the selective CPS conversion: Every use of an impure expression as a pure one \nmust reify the context as a continuation and explicitly pass it to the translated impure expression. \nWhen we say accounted to the enclosing expression , we are actually a bit imprecise. The correct way \nto put it is that every ex\u00adpression s cumulated control effect (which may be none) is a com\u00adposition \nof its by-value subexpressions control effects in the or\u00adder of their evaluation. For such a composition \nto exist, the answer types must be compatible (according to the standard rules, also manifest in the \ntype constraints of the class Shift and its method flatMap). During composition, pure expressions are \ntreated neu\u00ad f : (A => B) => C [ shift(f)] = new Shift[A,B,C](f ) (SHIFT) c : A @cps[B,C] [ reify(c)] \n= [ c] (REIFY) e : A @cps[B,C] {[ r] } : U @cps[V ,W ] [ val x: A = e; r] = [ e] .flatMap(x:A => {[ \nr] }) (VAL-IMPURE) e : A @cps[B,C] {[ r] } : U [ val x: A = e; r] = [ e] .map(x:A => {[ r] }) (VAL-PURE) \n[ def f(x:A)= e; r] = def f(x:A)= [ e] ; [ r] (DEF) [ s; r] = s; [ r] [ {r}] = {[ r] } (SEQ) Figure \n4. Type-directed selective CPS transform for a subset of Scala. Lowercase italic letters denote untransformed \nexpressions, uppercase letters expression sequences or types. Rules are applied deterministically from \ntop to bottom. trally. This is how we achieve answer type polymorphism in our system. If no composition \nexists, a type error is signaled. The rules that de.ne the composition relation are given in Figure 3. \n 3.4 Type-Directed Transformation We will de.ne the selective CPS transform in two steps and start with \nthe one that comes last. A subset of the transformation rules is shown in Figure 4. We denote the transformation \nitself by [ .] , and we let Scala pro\u00adgrams access transformed expressions with the primitive reify (REIFY). \nInvocations of shift are translated to creations of Shift objects (SHIFT). If an impure expression appears \non the right-hand-side of a value de.nition, which is followed by a se\u00adquence of expressions, then the \nright-hand-side is translated to a Shift object, upon which flatMap or map is invoked with the translated \nremaining expressions wrapped up into an anonymous function (VAL-IMPURE,VAL-PURE). Whether flatMap or \nmap is used depends on whether the remaining expressions are translated to a Shift object or not. The \nsemantics of shift require to .at\u00adten out nested Shift objects because otherwise, multiple nested reset \nhandlers would be needed to get at the result of a sequence of shift blocks. In this case, all but the \n.rst shift would es\u00adcape the enclosing reset4. The use of map is an optimization. We could as well wrap \nthe remaining code into a stub shift that behaves as identity and then use flatMap. But that would introduce \nunnecessary administrative redexes, which customary CPS-transform algorithms go to great lengths to avoid \n(Danvy et al. 2007). Right-hand sides of function de.nitions are translated inde\u00adpendently of the context \n(DEF). Finally, block expressions {...} 4 This is in fact Felleisen s model (Felleisen 1988) [ {r; e}] \n= {[ r] ; [ e] } Inline [ s; r] =[ s] ; [ r] Inline Inline Inline [ e] = r; gg : A @cps[B,C] [ e] = \nr; val x: A = g; x Inline [ f] = r; g [ e] = s; h Inline Inline (BY-VALUE APPLY) [ f(e)] = r; s; g(h) \n[ f] = r; g [ e] = s; h Inline Inline (BY-NAME APPLY) [ f(e)] = r; g({s; h}) Figure 5. Selective ANF \ntransform (only selected rules shown). Lowercase italic letters denote untransformed expressions, upper\u00adcase \nletters expression sequences or types. are translated by applying the other rules to the enclosed expression \nsequence, possibly skipping a pre.x of non-CPS terms (SEQ). Applying the transformation rules given in \nFigure 4, we can transform code like reset(reify { val x = shift(k => k(k(k(7)))) x+1 }) into the following: \nreset(new Shift(k => k(k(k(7)))).map(x => x + 1)) We are still somewhat restricted, though, in that CPS \nexpres\u00adsions may only appear in value de.nitions. Fortunately, we can reach this form by a pre-transform \nstep, which assigns synthetic names to the relevant intermediate values, lifting them into value de.nitions. \nIn analogy to the selective CPS transform, we can de\u00adscribe this step as a selective ANF transform (administrative \nnor\u00admal form (Flanagan et al. 1993)). We present a subset of the trans\u00adformation rules in Figure 5. For \nthe ANF pre-transform, we use two mutually recursive functions, [ .] and [ .] that map expressions to \nexpression se- Inline quences ([ .] is extended pointwise to expression sequences). Inline The latter \nis used to lift nested CPS-expressions and insert a val de.nition inline, preceding the parent expression. \nSince we do not want to introduce value de.nitions for expressions that are already in tail position, \nwe use either transformation depending on the con\u00adtext. Again, we illustrate the main principle by considering \nfunc\u00adtion applications. We consider application of functions with a sin\u00adgle by-value parameter .rst. \nThe function and the argument are nested expressions and thus transformed using [ .] , each of Inline \nthem yielding a statement sequence followed by an expression. The Scala semantics demand that the function \nbe evaluated .rst, so the result is the function s statements, followed by the argument s statements, \nfollowed by applying the expressions. When consider\u00ading functions with by-name parameters, by contrast, \nthe statements that result from transforming the corresponding argument must not be inserted preceding \nthe application. In this case, the whole result\u00ading sequence is wrapped up in a block and passed as an \nargument to the transformed function. For other kinds of Scala expressions like conditionals, pattern \nmatching, etc., the transformation works accordingly, depending on the context whether the by-name or \nby\u00advalue style is used. Note that in Figure 5, the insertion of new value de.nitions is triggered by \na @cps annotation on the result of transforming the expression in question. While this is a sound premise \nin the de\u00adscription at hand, we actually make sure in the implementation that the expression itself is \nannotated accordingly. This is done by an annotation checker, which hooks into the typer phase of the \nScala compiler, promoting CPS annotations outwards to expressions that have nested CPS expressions in \npositions where [ .] will be Inline applied. In the actual implementation, the selective ANF transform \nis also slightly more complex than described here. One reason is that we have to accommodate for possibly \nerroneous programs. Therefore, the actual transform takes two additional parameters, namely an expected \n@cps annotation (or none if a pure expres\u00adsion is expected) for the current expression sequence and an \nactual one, which is built up as we go along. When reaching the end of an expression sequence, these \ntwo must either match, or, if an annota\u00adtion is expected but none is present, an implicit shift is inserted \nthat behaves as identity. Summing up the transformation steps, we implement reset in terms of reify, \nusing a by-name parameter: def reset[A,C](ctx: => A @cps[A,C]) = { reify(ctx).fun(x:A => x) }  Finally, \nwe can express our working example as reset { shift(k => k(k(k(7)))) + 1 }  which is exactly what was \nintended. 4. Programming Examples There are many well-known use cases for delimited continuations and \nmost of them can be implemented in Scala straightforwardly. 4.1 Type-Safe printf As a .rst example, we \npresent the Scala implementation of type\u00adsafe printf (Danvy 1998; Asai 2007): val int = (x: Int) => x.toString \nval str = (x: String) => x def format[A,B](toStr: A => String) = shift { k: (String => B) => (x:A) => \nk(toStr(x)) } def sprintf[A](str: =>String @cps[String,A]) = { reset(str) } val f1 = sprintf[String](\"Hello \nWorld!\") val f2 = sprintf(\"Hello \" + format[String,String](str) + \"!\") val f3 = sprintf(\"The value of \n\" + format[String,Int=>String](str) + \" is \" + format[Int,String](int) + \".\") println(f1) println(f2(\"World\")) \nprintln(f3(\"x\")(3)) This example is instructive for its use of both answer type modi.cation and answer \ntype polymorphism. As we can see in the code above, format takes a function that converts a value of \ntype A to a string. In addition, it modi.es the answer type from any type B to a function from A to B. \nIn a context whose result type is String, invoking format(int) will change the answer type to Int => \nString; an additional integer argument has to be provided to turn the result into a string. Unfortunately, \nScala s local type inference cannot reconstruct all the type parameters here so we must give explicit \ntype arguments for uses of format.  4.2 Direct-Style Monads Another interesting example is the use of \nmonads in direct-style programming (Filinski 1994, 1999). As has been shown by Filin\u00adski, delimited continuations \ncan express any de.nable monad. We identify monadic types structurally by the existence of a bind op\u00aderation \n(flatMap), making use of type constructor polymorphism (Moors et al. 2008) to describe its required signature: \ntype Monadic[+U, C[_]] = { def flatMap[V](f: U => C[V]): C[V] } We go on by de.ning an adapter class \nthat allows to re.ect monadic values, passing the current continuation to the underlying monadic bind \noperation: class Reflective[+A, C[_]](xs: Monadic[A,C]) { def reflect[B](): A @cps[C[B], C[B]] = { shift \n{ k:(A => C[B]) => xs.flatMap(k) } } } De.ning an implicit conversion for iterables, we can e.g. use \nthe list monad in direct-style. The unit constructor List is used here as Filinski s reify operation: \nimplicit def reflective[A](xs:Iterable[A]) = new Reflective[A,Iterable](xs) reset { val left = List(\"x\",\"y\",\"z\") \nval right = List(4,5,6) List((left.reflect[Any], right.reflect[Any])) } // result: cartesian product \nThe same mechanism applies to other monads, too. Using the option monad, for example, we can build a \ncustom exception han\u00addling mechanism and the state monad could be used as an alterna\u00adtive to thread-local \nvariables. 4.3 Concurrency Primitives Using delimited continuations, we can implement a rich variety \nof primitives for concurrent programming. Among others, these include bounded and unbounded buffers, \nrendezvous cells, fu\u00adtures, single-assignment variables, actor mailboxes, and join pat\u00adterns. Without \ngoing into the details of the implementation, we show how our implementation of extensible join patterns \nor dy\u00adnamic functional nets (Fournet and Gonthier 1996; Odersky 2000; Rompf 2007) can integrate join-calculus \nbased programming into Scala. The following code implements, with a common interface, synchronous rendezvous \ncells and asynchronous reference cells backed by a one-place buffer: abstract class ReferenceCell[A] \n{ val put = new (A ==> Unit) val get = new (Unit ==> A) } // synchronous reference cell (no buffering) \nclass SyncRefCell[A] extends ReferenceCell[A] { join { case put(x <== return_put) <&#38;> get(_ <== \nreturn_get) => println(\"exchanging \" + x) return_put() <&#38;> return_get(x) } } // asynchronous reference \ncell (1-place buffer) class AsyncRefCell[A] extends ReferenceCell[A] { val empty = new (Unit ==> Unit) \nval item = new (A ==> Unit) join { case put(x <== return_put) <&#38;> empty(_ <== _) => return_put() \n<&#38;> item(x) } join { case get(_ <== return_get) <&#38;> item(x <== _) => println(\"exchanging \" + \nx) return_get(x) <&#38;> empty() } spawn { empty() } }  4.4 Actors Scala Actors provide an implementation \nof the actor model (Agha and Hewitt 1987) on the JVM (Haller and Odersky 2009). To make ef.cient use \nof VM threads, actors, when waiting for incom\u00ading messages, can suspend in event-based mode with an explic\u00aditly \npassed continuation closure instead of blocking the underly\u00ading thread (Haller and Odersky 2006). This \nis accomplished by the primitive react that takes a message handler (the continuation closure), and suspends \nthe current actor in event mode. The un\u00adderlying (pool) thread is released to execute other runnable \nactors. Using react, however, imposes some restrictions on the program structure. In particular, no code \nfollowing a react is ever exe\u00adcuted, only the explicitly provided closure. For example, consider implementing \na communication protocol using actors. It would be tempting to handle the connection setup in a separate \nmethod: def establishConnection() = { server ! SYN react { case SYN_ACK => server ! ACK } }  which \nis then used as part of a more complex actor behavior: actor { establishConnection() transferData() ... \n } But unfortunately, this does not work as is. The use of react inside establishConnection precludes \nthe execution of transferData. To make this example work, one would have to use explicit andThen combinators \nto chain the individual pieces of behavior together. In the presence of complex control structures, programming \nin this style quickly becomes cumbersome. In addi\u00adtion, the type system does not enforce the use of combinators \nso errors will manifest only at runtime. Using delimited continuations, we can simplify programming \nevent-based actors signi.cantly. Moreover, we can do so without changing the implementation of the existing \nprimitives, thereby maintaining the high degree of interoperability with standard Java threads (Haller \nand Odersky 2009). This approach, which has been suggested by Philipp Haller, introduces a higher-order \nfunction proceed that can be applied to react, such that the message handling closure is extended with \nthe current continuation: def proceed[A, B](fun: PartialFunction[A, Unit] => Nothing): PartialFunction[A, \nB] => B @cps[Unit, Unit] = (cases: PartialFunction[A, B]) => shift((k: B => Unit) => fun(cases andThen \nk)) Wrapping each react with a proceed and inserting a reset to delineate the actor behavior s outer \nbound we can ac\u00adtually code the above example as follows. It is worth mentioning that leaving out the \nreset would cause the compiler to signal a type error, since an impure expression would occur in a pure \ncontext: def establishConnection() = { server ! SYN proceed(react) { case SYN_ACK => server ! ACK } } \nactor { reset { establishConnection() transferData() ... } } Alternatively, the implementations of react \nand actor could be modi.ed to make use of the necessary control operators directly. But using proceed \nis a good example of incorporating delimited continuations into existing code in a backwards-compatible \nway.  4.5 Functional Reactive Programming Functional reactive programming (FRP) is an effort to integrate \nreactive programming concepts into functional programming lan\u00adguages (Elliott and Hudak 1997; Courtney \net al. 2003; Cooper and Krishnamurthi 2006). The two fundamental abstractions of FRP are signals and \nevent streams5. A signal represents a continuous time-varying value; it holds a value at every point \nin time. An event stream, on the other hand, is discrete; it yields a value only at certain times. Signals \nand event streams can be composed through combi\u00adnators, some of which are known from functional collections, \nsuch as map, flatMap, or filter. Our implementation of a reactive library in Scala takes the basic ideas \nof FRP and extends it with support for imperative program\u00adming. One key abstraction to achieve this is \ncalled behaviors.A behavior can be used to conveniently react to complex event pat\u00adterns in an imperative \nway. To give an idea how behaviors work, 5 We use different terminology than most FRP implementations, \nwho use the term behavior for signals. In our implementation, this term is reserved for a different concept \nas discussed below. we take an example from our user interface toolkit whose event handling details \nare implemented exclusively with our reactive pro\u00adgramming library. The interactive behavior of a button \nwidget can be implemented as follows: behavior { next(mouse.leftDown) showPressed(true) val t = loop \n{ showPressed(next(mouse.hovers.changes)) } next(mouse.leftUp) t.done() showPressed(false) if (mouse.hovers.now) \nperformClick() } The .rst action of the behavior above is to wait until the left mouse button is pressed \ndown. Method next blocks the current behavior and returns the next message that becomes available in \na given event stream. In our case, the behavior drops that message and then updates the button view and \nstarts a loop. A loop is a child behavior that is automatically terminated when the current cycle of \nthe parent behavior ends. The loop updates the button view whenever the mouse enters or leaves the button \narea. We do this by waiting for changes in the boolean signal mouse.hovers, which indicates whether the \nmouse currently hovers over the button widget. The call tochanges converts that boolean signal to an \nevent stream that yields boolean messages. We use the event message to determine whether the mouse button \nis currently over the button. In the parent behavior, in parallel to the loop, we wait for the left mouse \nbutton to be released. On release, we terminate the loop by calling done, which causes the child behavior \nto stop after it has processed all pending events. Note that this does not lead to race conditions since, \nin constrast to actors, behaviors are executed sequentially and should not be accessed from different \nthreads. Eventually, we update the button view and perform a click if the mouse button has been released \nwhile inside the bounds of the button widget. The use of the CPS transform API is hidden inside behavior, \nnext, and loop. Methods behavior and loop delimit the continua\u00adtion scope while method next captures \nthe continuation and passes it to an event stream observer which invokes the continuation on noti.cation. \n 4.6 Asynchronous IO Using a similar model, we can use scalable asynchronous IO prim\u00aditves in a high-level \ndeclarative programming style. Below, we con\u00adsider the Scala adaptation of an asynchronous webserver \npresented in (Rompf 2007). The basic mechanism is to request a stream of callbacks matching a set of \nkeys from a selector. This stream can be iterated over and transformed into a higher-level stream by \nim\u00adplementing the standard iteration methods (e.g. foreach) used by Scala s for comprehensions. A stream \nof sockets representing incoming connections can be implemented like this: def acceptConnections(sel: \nSelector, port: Int) = new Object { def foreach(body: (SocketChannel => Unit @suspendable)) = { val serverSock \n= ServerSocketChannel.open() for (key <-callbacks(serverSock, sel, SelectionKey.OP_ACCEPT)) { body(serverSock.accept()) \n} } }  Note that the client handler (the parameter body of foreach) might capture a continuation and \nthus interrupt the accepting of new connections. The annotation @suspendable expresses the common case \nof a control effect that occurs in a context with an\u00adswer type Unit and keeps the answer type unchanged: \ntype suspendable = cps[Unit,Unit] In the same way as above, we can implement a stream of events indicating \nincoming data on a speci.c socket: def readBytes(selector: Selector, socketChannel: SocketChannel) = \nnew Object { def foreach(body: (ByteBuffer => Unit @cps[Unit,Unit])) = val buf = ByteBuffer.allocateDirect(4096) \nfor (key <-callbacks(socketChannel, selector, SelectionKey.OP_READ)) { buf.flip() body(buf) buf.clear() \n} } Adapting this stream of incoming data, we can build a stream of incoming requests, which invokes \nits handler only when a new, complete request has been parsed. Using these building blocks, we can de.ne \nthe main server loop: val sel = createAsyncSelector() for (socketChannel <-acceptConnections(sel, 80)) \n{ spawn { println(\"Connect: \" + socketChannel) for (req <-readRequests(sel, socketChannel)) { val res \n= handleRequest(req) writeResponse(sel, socketChannel, res) } println(\"Disconnect: \" + socketChannel) \n} } Using spawn to of.oad handling of requests to a thread pool, this server loop, despite its strictly \nsequential appearance, can han\u00addle large numbers of concurrently active connections using scalable asynchronous \nIO with only few native platform threads. 5. Performance In assessing the performance of our implementation \nof delimited continuations, we focus on comparing running times with other means of implementing continuations \non the JVM .rst. The ap\u00adproach of Kilim (Srinivasan 2006; Srinivasan and Mycroft 2008) reportedly exhibits \nvery good performance and is thus a natural tar\u00adget for a head-to-head comparison. All numbers were taken \non a late-2008 MacBook Pro (Intel Core 2 Duo, 2.4GHz, 4GB RAM) running MacOS X 10.5.5 and Java 1.6.0 \n07 (64 Bit). Scala code was compiled using a pre-release build of scalac 2.8.0 with option -optimize. \nThe Kilim version used was 0.5. Numbers shown are median values of 5 consecutive measurements. 5.1 Actors \nOn top of its byte-code transformation, Kilim also provides an im\u00adplementation of actors, which is known \nto outperform the Scala ac\u00adtor framework on a number of benchmarks. It must be noted how\u00adever, that Kilim \ns actors lack several important features of Scala s Figure 6. Ping-Pong actor benchmark. Two actors, \nexchanging n messages.  actors such as message pattern matching or actor linking. In our .rst benchmark, \nwe compare Kilim actors to a vastly stripped\u00addown reimplementation of Scala actors, where blocking reads \non mailboxes are implemented using shift. The benchmark used is the Ping-Pong example included in both \nthe Kilim and the Scala distribution, consisting of two actors that alternatingly exchange a .xed number \nof messages. The measured results are shown in Figure 6. Test runs were done using a single-threaded \nactor im\u00adplementation without any locking and with two slightly different thread-safe implementations \nusing standard Java locking primitives and the FJTask library (Lea 2000) as a thread pool. The thread-safe \nimplementations differ in whether the continuation of a read opera\u00adtion is directly executed on the calling \nthread if data is available or whether it is submitted to the thread pool. The data shown in Fig\u00adure \n6 indicates a speedup of our thread-safe implementations over Kilim s of about 30%. The single-threaded \ncase performs slightly less than three times faster than the thread-safe one. 5.2 Generators For the \nnext benchmark, the aim was to exclude any effects that might result from using multiple threads. We \nturn our attention to generators, which are also included in the Kilim distribution. Using generators, \na possibly in.nite sequence of values can be generated in push mode, demand-driven by one or more clients \nthat seek to pull items out of the generator. An implementation using continuations is straightforward. \nFor every data item that is to be generated, the continuation is captured and stored in a mutable variable, \nas is the data item. The client of the generator can access the generated value and, once it is ready \nto retrieve the next item, invoke the stored continuation, which will trigger generation of the next \nitem. We present performance measurements for two different styles of generators. One will generate values \nusing a strictly linear, tail\u00adrecursive or iterative call pattern and thus use only constant stack space, \nwhile the other one exhibits a tree-like call pattern with logarithmic stack depth. The results are shown \nin Figures 7 and 8, respectively. While we can see a 30% speedup in the linear case (similar to the actors \nbenchmark), the speedup for the tree-like case is more signi.cant and amounts to more than a factor of \nseven. 5.3 Samefringe Another direction for performance evaluation is to assess how well solutions using \ndirect-style control operators perform in relation to other solutions. We consider the samefringe-problem \n(Gabriel 1991) and compare Scala implementations using iterators, lists, streams and delimited continuations \nin Figure 9. The task is to com\u00ad  Figure 7. Generator benchmark. Generating numbers 0 ...n lin-Figure \n9. Samefringe benchmark. Comparing a fully balanced bi\u00adearly. Call depth O(1). nary tree of size n to \nitself. Leaves are integers. Run with -Xms2G -Xmx2G. Figure 8. Generator benchmark. Generating numbers \n0 ...n re\u00adcursively, in a binary-search like fashion. Call depth O(log n). pare the in-order sequences \nof leaves of two binary trees. For lists and streams (which are lists where the tail is computed lazily), \nthere are two implementations each. The .rst one uses a modi.ed tree traversal function to propagate \na partial list downwards, to which the leaves are prepended using cons. The other one does not pass any \npartially constructed information downwards, so partial struc\u00adtures have to be combined using append. \nFor the continuation\u00adbased case, there are also two implementations. One is almost iden\u00adtical to the \ngenerators described above and the other, purportedly less ef.cient one differs in that it will not save \nthe captured con\u00adtinuations directly into a mutable variable but leave it to another shift in the client \ncode to access them. Regarding the results displayed in Figure 9, we see that streams and lists using \ncons perform best, followed within a factor of two by the faster continuations implementation and within \na factor of three by the slower one. Streams and lists using append perform worse than continuations. \nThat streams perform best here is no sur\u00adprise, since the way they are implemented with by-name function \narguments leads to a byte-code translation which is very similar to a hand-optimized CPS implementation, \nwhich avoids creating inter\u00admediate Shift objects as is done in the translation of the direct\u00adstyle control \noperators. It is instructive, though, to do another test run with more limit\u00ading memory restrictions \n(see Figure 10). Here we see that lists do not scale to these conditions, even though they performed \nwell in the previous run. Streams and continuations are the only mecha-nisms that provide a solution \nin this case, since all other implemen\u00adtations terminate prematurely with an OutOfMemoryError. The continuation-based \nsolutions still exhibit a running time that is not too far off the optimal case and still perform better \nthan streams using append.  6. Conclusion In this paper, we have described an ef.cient way of implementing \ndelimited continuations and the associated static control operators shift and reset under the adverse \nconditions of the JVM. In doing so, we employ a selective CPS transform, which is driven by a type and \neffect system that tracks uses of control operators. We have applied delimited continuations in several \ndifferent con\u00adtexts ranging from asynchronous IO to actor-based concurrency to reactive programming for \nuser interfaces. Our experiences and per\u00adformance evaluation indicate that the technique is practical \nand per\u00adforms adequately. Acknowledgments We would like to thank Philipp Haller for suggesting the use \nof proceed to make Scala actors continuation aware. We also thank the reviewers for their comments. References \nAgha, Gul, and Carl Hewitt. 1987. Concurrent programming using actors. In Object-oriented concurrent \nprogramming, 37 53. MIT Press, Cam\u00adbridge, MA, USA. Appel, Andrew W. 1992. Compiling with continuations. \nCambridge University Press, New York, NY, USA. Appel, Andrew W., and Trevor Jim. 1989. Continuation-passing, \nclosure\u00adpassing style. In Proc. POPL 89, 293 302. Asai, Kenichi. 2007. On typing delimited continuations: \nThree new solu\u00adtions to the printf problem. Tech. Rep. OCHA-IS 07-1, Department of Information Science, \nOchanomizu University, Tokyo, Japan. Available from: http://pllab.is.ocha.ac.jp/ asai/papers/. Asai, \nKenichi, and Yukiyoshi Kameyama. 2007. Polymorphic delimited continuations. In Proc. APLAS 07, vol. 4807 \nof LNCS, 91 108. Atkey, Robert. 2006. Parameterised notions of computation. In Proc. MSFP 06, 31 45. \nElectronic Workshops in Computing, British Com\u00adputer Society. Balat, Vincent, and Olivier Danvy. 1997. \nStrong normalization by run-time code generation. Tech. Rep. BRICS RS-97-43, Department of Computer Science, \nUniversity of Aarhus, Denmark. Biernacki, Dariusz, Olivier Danvy, and Chung-chieh Shan. 2006. On the \nstatic and dynamic extents of delimited continuations. Science of Com\u00adputer Programming 60(3):274 297. \nClinger, William D., Anne H. Hartheimer, and Eric M. Ost. 1999. Imple\u00admentation Strategies for First-Class \nContinuations. Higher-Order and Symbolic Computation 12(1):7 45. Cooper, Gregory H., and Shriram Krishnamurthi. \n2006. Embedding dy\u00adnamic data.ow in a call-by-value language. In Proc. ESOP 06, 294 308. Courtney, Antony, \nHenrik Nilsson, and John Peterson. 2003. The Yampa arcade. In Proc. ACM SIGPLAN workshop on Haskell, \n7 18. Danvy, Olivier. 1998. Functional unparsing. J. Funct. Program. 8(06):621 625. Danvy, Olivier, and \nAndrzej Filinski. 1989. A Functional Abstraction of Typed Contexts. Tech. Rep., DIKU University of Copenhagen, \nDen\u00admark. . 1990. Abstracting control. In Proc. LFP 90, 151 160. . 1992. Representing Control: A Study \nof the CPS Transformation. Mathematical Structures in Computer Science 2(4):361 391. Danvy, Olivier, \nKevin Millikin, and Lasse R. Nielsen. 2007. On one-pass CPS transformations. J. Funct. Program. 17(6):793 \n812. Dragos, Iulian, Antonio Cunei, and Jan Vitek. 2007. Continuations in the Java Virtual Machine. In \nProc. ICOOOLPS 07. Dyvbig, R. Kent, Simon Peyton-Jones, and Amr Sabry. 2007. A monadic framework for \ndelimited continuations. J. Funct. Program. 17(6):687 730. Elliott, Conal, and Paul Hudak. 1997. Functional \nreactive animation. In Proc. ICFP 97. Felleisen, Matthias. 1991. On the expressive power of programming \nlan\u00adguages. Science of Computer Programming 17(1-3):35 75. Felleisen, Matthias, Mitch Wand, Daniel Friedman, \nand Bruce Duba. 1988. Abstract continuations: a mathematical semantics for handling full jumps. In Proc. \nLFP 88, 52 62. Felleisen, Mattias. 1988. The theory and practice of .rst-class prompts. In Proc. POPL \n88, 180 190. Filinski, Andrzej. 1994. Representing monads. In Proc. POPL 94, 446 457. . 1999. Representing \nlayered monads. In Proc. POPL 99, 175 188. Flanagan, Cormac, Amr Sabry, Bruce F. Duba, and Matthias \nFelleisen. 1993. The essence of compiling with continuations. In Proc. PLDI 93, vol. 28(6), 237 247. \nFournet, C\u00b4edric, and Georges Gonthier. 1996. The re.exive CHAM and the join-calculus. In Proc. POPL \n96, 372 385. Gabriel, Richard P. 1991. The design of parallel programming languages. In Arti.cial intelligence \nand mathematical theory of computation: papers in honor of john mccarthy, 91 108. Academic Press Professional, \nSan Diego, CA, USA. Gasbichler, Martin, and Michael Sperber. 2002. Final shift for call/cc:: direct implementation \nof shift and reset. In Proc. ICFP 02, 271 282. Haller, Philipp, and Martin Odersky. 2006. Event-based \nprogramming without inversion of control. In Proc. JMLC 06, vol. 4228 of LNCS, 4 22. . 2009. Scala actors: \nUnifying thread-based and event-based pro\u00adgramming. Theor. Comput. Sci 410(2-3):202 220. Kameyama, Yukiyoshi, \nand Takuo Yonezawa. 2008. Typed dynamic control operators for delimited continuations. In Proc. FLOPS \n08, vol. 4989 of LNCS, 239 254. Kiselyov, Oleg. 2005. How to remove a dynamic prompt: static and dynamic \ndelimited continuation operators are equally expressible. Tech. Rep. TR611, Department of Computer Science, \nIndiana University. . 2007. Genuine shift/reset in haskell98. Announcement and explanations posted on \nthe Haskell mailing list on 12/12/2007. Imple\u00admentation available from: http://okmij.org/ftp/Haskell/ShiftResetGenuine.hs. \nKiselyov, Oleg, Chung-chieh Shan, and Amr Sabry. 2006. Delimited dy\u00adnamic binding. In Proc. ICFP 06, \n26 37. Lea, Doug. 2000. A Java fork/join framework. In Proc. ACM Java Grande, 36 43. Moors, Adriaan, \nFrank Piessens, and Martin Odersky. 2008. Generics of a higher kind. In Proc. OOPSLA 08, 423 438. Nielsen, \nAnders Bach. 2008. Scala compiler phase and plug-in initializa\u00adtion. Available from: http://lampsvn.epfl.ch/svn-repos/scala/lamp-sip/ \ncompiler-phase-init/sip-00002.xhtml. Nielsen, Lasse R. 2001. A selective CPS transformation. Tech. Rep. \nRS\u00ad01-30, BRICS, Department of Computer Science, Aarhus University. Odersky, Martin. 2000. Functional \nNets. In Proc. European Symposium on Programming Languages and Systems, 1 25. Pettyjohn, Greg, John Clements, \nJoe Marshall, Shriram Krishnamurthi, and Matthias Felleisen. 2005. Continuations from generalized stack \ninspection. SIGPLAN Not. 40(9):216 227. Rompf, Tiark. 2007. Design and implementation of a programming \nlan\u00adguage for concurrent interactive systems. Master s thesis, Institute of Software Technology and Programming \nLanguages, University of L\u00a8ubeck, Germany. Available from: http://vodka.nachtlicht-media.de/docs.html. \nRose, John. 2008. JSR 292: Supporting dynamically typed languages on the Java platform. http://jcp.org/en/jsr/detail?id=292. \nShan, Chung-chieh. 2004. Shift to control. In Proc. ACM SIGPLAN workshop on Scheme and functional programming, \n99 107. . 2007. A static simulation of dynamic delimited control. Higher-Order and Symbolic Computation \n20(4):371 401. Srinivasan, Sriram. 2006. A thread of one s own. In New horizons in compilers workshop, \nhipc, bangalore. Srinivasan, Sriram, and Alan Mycroft. 2008. Kilim: Isolation-typed actors for Java. \nIn Proc. ECOOP 08, 104 128. Strachey, Christopher, and Christopher P. Wadsworth. 2000. Continuations: \nA mathematical semantics for handling full jumps. Higher-Order and Symbolic Computation 13(1):135 152. \nThielecke, Hayo. 2003. From control effects to typed continuation passing. In Proc. POPL 03, 139 149. \n   \n\t\t\t", "proc_id": "1596550", "abstract": "<p>We describe the implementation of first-class polymorphic delimited continuations in the programming language Scala. We use Scala's pluggable typing architecture to implement a simple type and effect system, which discriminates expressions with control effects from those without and accurately tracks answer type modification incurred by control effects. To tackle the problem of implementing first-class continuations under the adverse conditions brought upon by the Java VM, we employ a selective CPS transform, which is driven entirely by effect-annotated types and leaves pure code in direct style. Benchmarks indicate that this high-level approach performs competitively.</p>", "authors": [{"name": "Tiark Rompf", "author_profile_id": "81442614474", "affiliation": "&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne (EPFL), 1015 Lausanne, Switzerland", "person_id": "P1613959", "email_address": "", "orcid_id": ""}, {"name": "Ingo Maier", "author_profile_id": "81442616052", "affiliation": "&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne (EPFL), 1015 Lausanne, Switzerland", "person_id": "P1613960", "email_address": "", "orcid_id": ""}, {"name": "Martin Odersky", "author_profile_id": "81100056476", "affiliation": "&#201;cole Polytechnique F&#233;d&#233;rale de Lausanne (EPFL), 1015 Lausanne, Switzerland", "person_id": "P1613961", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1596550.1596596", "year": "2009", "article_id": "1596596", "conference": "ICFP", "title": "Implementing first-class polymorphic delimited continuations by a type-directed selective CPS-transform", "url": "http://dl.acm.org/citation.cfm?id=1596596"}