{"article_publication_date": "08-31-2009", "fulltext": "\n Non-Parametric Parametricity Georg Neis Derek Dreyer Andreas Rossberg MPI-SWS MPI-SWS MPI-SWS neis@mpi-sws.org \ndreyer@mpi-sws.org rossberg@mpi-sws.org Abstract Type abstraction and intensional type analysis are \nfeatures seem\u00adingly at odds type abstraction is intended to guarantee para\u00admetricity and representation \nindependence, while type analysis is inherently non-parametric. Recently, however, several researchers \nhave proposed and implemented dynamic type generation as a way to reconcile these features. The idea \nis that, when one de.nes an abstract type, one should also be able to generate at run time a fresh type \nname, which may be used as a dynamic representative of the abstract type for purposes of type analysis. \nThe question remains: in a language with non-parametric polymorphism, does dynamic type generation provide \nus with the same kinds of ab\u00adstraction guarantees that we get from parametric polymorphism? Our goal \nis to provide a rigorous answer to this question. We de.ne a step-indexed Kripke logical relation for \na language with both non-parametric polymorphism (in the form of type-safe cast) and dynamic type generation. \nOur logical relation enables us to es\u00adtablish parametricity and representation independence results, \neven in a non-parametric setting, by attaching arbitrary relational inter\u00adpretations to dynamically-generated \ntype names. In addition, we explore how programs that are provably equivalent in a more tradi\u00adtional \nparametric logical relation may be wrapped systematically to produce terms that are related by our non-parametric \nrelation, and vice versa. This leads us to a novel polarized form of our logical relation, which enables \nus to distinguish formally between positive and negative notions of parametricity. Categories and Subject \nDescriptors D.3.3 [Programming Lan\u00adguages]: Language Constructs and Features Abstract data types; F.3.1 \n[Logics and Meanings of Programs]: Specifying and Verify\u00ading and Reasoning about Programs General Terms \nLanguages, Theory, Veri.cation Keywords Parametricity, intensional type analysis, representation independence, \nstep-indexed logical relations, type-safe cast 1. Introduction When we say that a language supports \nparametric polymorphism, we mean that abstract types in that language are really abstract that is, no \nclient of an abstract type can guess or depend on its underlying implementation [20]. Traditionally, \nthe parametric na\u00adture of polymorphism is guaranteed statically by the language s Permission to make \ndigital or hard copies of all or part of this work for personal or classroom use is granted without fee \nprovided that copies are not made or distributed for pro.t or commercial advantage and that copies bear \nthis notice and the full citation on the .rst page. To copy otherwise, to republish, to post on servers \nor to redistribute to lists, requires prior speci.c permission and/or a fee. ICFP 09, August 31 September \n2, 2009, Edinburgh, Scotland, UK. Copyright c &#38;#169; 2009 ACM 978-1-60558-332-7/09/08. . . $5.00 \n type system, thus enabling the so-called type-erasure interpretation of polymorphism by which type abstractions \nand instantiations are erased during compilation. However, some modern programming languages include \na use\u00adful feature that appears to be in direct con.ict with parametric poly\u00admorphism, namely the ability \nto perform intensional type analy\u00adsis [12]. Probably the simplest and most common instance of in\u00adtensional \ntype analysis is found in the implementation of languages supporting a type Dynamic [1]. In such languages, \nany value v may be cast to type Dynamic, but the cast from type Dynamic to any type t requires a runtime \ncheck to ensure that v s actual type equals t . Other languages such as Acute [25] and Alice ML [23], \nwhich are designed to support dynamic loading of modules, require the abil\u00adity to check dynamically whether \na module implements an expected interface, which in turn involves runtime inspection of the module s \ntype components. There have also been a number of more experi\u00admental proposals for languages that employ \na typecase construct to facilitate polytypic programming (e.g., [32, 29]). There is a fundamental tension \nbetween type analysis and type abstraction. If one can inspect the identity of an unknown type at run \ntime, then the type is not really abstract, so any invariants con\u00adcerning values of that type may be \nbroken [32]. Consequently, lan\u00adguages with a type Dynamic often distinguish between castable and non-castable \ntypes with types that mention user-de.ned ab\u00adstract types belonging to the latter category and prohibit \nvalues with non-castable types from being cast to type Dynamic. This is, however, an unnecessarily severe \nrestriction, which ef\u00adfectively penalizes programmers for using type abstraction. Given a user-de.ned \nabstract type t implemented internally, say, as int it is perfectly reasonable to cast a value of type \nt . t to Dynamic, so long as we can ensure that it will subsequently be cast back only to t . t (not \nto, say, int . int or int . t), i.e., so long as the cast is abstraction-safe. Moreover, such casts are \nuse\u00adful when marshalling (or pickling ) a modular component whose interface refers to abstract types \nde.ned in other components [23]. That said, in order to ensure that casts are abstraction-safe, it is \nnecessary to have some way of distinguishing (dynamically, when a cast occurs) between an abstract type \nand its implementation. Thus, several researchers have proposed that languages with type analysis facilities \nshould also support dynamic type genera\u00adtion [24, 21, 29, 22]. The idea is simple: when one de.nes an \nab\u00adstract type, one should also be able to generate at run time a fresh type name, which may be used \nas a dynamic representative of the abstract type for purposes of type analysis.1 (Wewill seea con\u00adcrete \nexample of this in Section 2.) Intuitively, the freshness of type name generation ensures that user-de.ned \nabstract types are viewed dynamically in the same way that they are viewed statically i.e., as distinct \nfrom all other types. 1 In languages with simple module mechanisms, such as Haskell, it is possible to \ngenerate unique type names statically. However, this is not suf.cient in the presence of functors and \nlocal or .rst-class modules. The question remains: how do we know that dynamic type generation works? \nIn a language with intensional type analysis i.e., non-parametric polymorphism can the systematic use \nof dy\u00adnamic type generation provably ensure abstraction safety and pro\u00advide us with the same kinds of \nabstraction guarantees that we get from traditional parametric polymorphism? Our goal is to provide a \nrigorous answer to this question. We study an extension of System F, supporting (1) a type-safe cast \nmechanism, which is essentially a variant of Girard s J operator [9], and (2) a facility for dynamic \ngeneration of fresh type names. For brevity, we will call this language G. As a practical language mech\u00adanism, \nthe cast operator is somewhat crude in comparison to the more expressive typecase-style constructs proposed \nin the liter\u00adature,2 but it nonetheless renders polymorphism non-parametric. Our main technical result \nis that, in a language with non-parametric polymorphism, parametricity may be provably regained via judi\u00adcious \nuse of dynamic type generation. The rest of the paper is structured as follows. In Section 2, we present \nour language under consideration, G, and also give an example to illustrate how dynamic type generation \nis useful. In Section 3, we explain informally the approach that we have developed for reasoning about \nG. Our approach employs a step\u00adindexed Kripke logical relation, with an unusual form of possible world \nthat is a close relative of Sumii and Pierce s [26]. This section is intended to be broadly accessible \nto readers who are generally familiar with the basic idea of relational parametricity but not with the \ndetails of (advanced) logical relations techniques. In Section 4, we formalize our logical relation for \nG and show how it may be used to reason about parametricity and represen\u00adtation independence. A particularly \nappealing feature of our for\u00admalization is that the non-parametricity of G is encapsulated in the notion \nof what it means for two types to be logically related to each other when viewed as data. The de.nition \nof this type-level log\u00adical relation is a one-liner, which can easily be replaced with an alternative \nparametric version. In Sections 5 8, we explore how terms related by the paramet\u00adric version of our logical \nrelation may be wrapped systemati\u00adcally to produce terms related by the non-parametric version (and vice \nversa), thus clarifying how dynamic type generation facilitates parametric reasoning. This leads us to \na novel polarized form of our logical relation, which enables us to distinguish formally be\u00adtween positive \nand negative notions of parametricity. In Section 9, we extend G with iso-recursive types to form G\u00b5 \nand adapt the previous development accordingly. Then, in Sec\u00adtion 10, we discuss how the abovementioned \nwrapping function can be seen as an embedding of System F (+ recursive types) into G\u00b5, which we conjecture \nto be fully abstract. Finally, in Section 11, we discuss related work, including recent work on the relevant \nconcepts of dynamic sealing [27] and multi\u00adlanguage interoperation [13], and in Section 12, we conclude \nand suggest directions for future work.  2. The Language G Figure 1 de.nes our non-parametric language \nG. For the most part, G is a standard call-by-value .-calculus, consisting of the usual types and terms \nfrom System F [9], including pairs and existential types.3 We also assume an unspeci.ed set of base types \nb, along with suitable constants c of those types. Two additional, non-standard constructs isolate the \nessential aspects of the class of languages we are interested in: 2 That said, the implementation of \ndynamic modules in Alice ML, for instance, employs a very similar construct [23]. 3 We could use a Church \nencoding of existentials through universals, but distinguishing them gives us more leeway later (cf. \nSection 5). Types t ::= a | b | t . t | t \u00d7 t |.a.t |.a.t Values v ::= x | c | .x:t.e |(v1,v2)| .a.e \n| pack (t, v) as t Terms e ::= v | ee |(e1,e2)| e.1 | e.2 | et | pack (t, e) as t | unpack (a, x)=e in \ne | cast tt | new a t in e Stores s ::= E | s, a t Con.g s . ::= s; e Type Contexts . ::= E | .,a | .,a \nt Value Contexts G ::= E | G,x:t .; G e : t \u00b7\u00b7\u00b7 . t1 . t2 (ECAST) .; G cast t1 t2 : t1 . t2 . t2 . t \n.,a t ;G e : t ' . t ' (ENEW) .; G new a t in e : t ' .; G e : t ' . t t ' (ECONV) .; G e : t . t a \nt . . (TNAME) \u00b7\u00b7\u00b7 . a . t t a t . . (CNAME) \u00b7\u00b7\u00b7 . a t . : t ss; E e : tE t (CONF) s; e : t s;(.x:t.e) \nv'. s; e[v/x] s; (v1,v2).i '. s; vi s;(.a.e) t'. s; e[t/a] s; unpack (a, x)=(pack (t, v)) in e'. s; \ne[t/a][v/x] (a/. dom(s)) s; new a t in e'. s, a t ; e (t1 = t2) s; cast t1 t2 '. s; .x1:t1..x2:t2.x1 \n(t1= t2) s; cast t1 t2 '. s; .x1:t1..x2:t2.x2 (...plus standard search rules ...) Figure 1. Syntax and \nSemantics of G (excerpt) cast t1 t2 v1 v2 converts v1 from type t1 to t2. It checks that those two types \nare the same at the time of evaluation. If so, the operator succeeds and returns v1.Otherwise, it fails \nand defaults to v2, which acts as an else clause of the target type t2.  new a t in e generates a fresh \nabstract type name a.Values of type a can be formed using its representation type t .Both types are deemed \ncompatible, but not equivalent. That is, they are considered equal as classi.ers, but not as data. In \nparticular, cast at vv' will not succeed (i.e., it will return v').  Our cast operator is essentially \nthe same as Harper and Mitchell s TypeCond operator [11], which was itself a variant of the non\u00adparametric \nJ operator that Girard studied in his thesis [9]. Our new construct is similar to previously proposed \nconstructs for dynamic type generation [21, 29, 22]. However, we do not require explicit term-level type \ncoercions to witness the isomorphism between an abstract type name a and its representation t . Instead, \nour type system is simple enough that we perform this conversion implicitly. For convenience, we will \noccasionally use expressions of the form let x=e1 in e2, which abbreviate the term (.x:t1.e2) e1 (with \nt1 being an appropriate type for e1). We omit the type annotation for existential packages where clear \nfrom context. Moreover, we take the liberty to generalize binary tuples to n-ary ones where necessary \nand to use pattern matching notation to decompose tuples in the obvious manner. 2.1 Typing Rules The \ntyping rules for the System F fragment of G are completely standard and thus omitted from Figure 1. We \nfocus on the non\u00adstandard rules related to cast and new. Full formal details of the type system appear \nin the expanded version of this paper [16]. Typing of casts is straightforward (Rule ECAST): cast t1 \nt2 is simply treated as a function of type t1 . t2 . t2.Its .rst argument is the value to be converted, \nand its second argument is the default value returned in the case of failure. The rule merely requires \nthat the two types be well-formed. For an expression new a t in e, which binds a in e,Rule ENEW checks \nthat the body e is well-typed under the assumption that a is implemented by the representation type t \n. For that pur\u00adpose, we enrich type contexts . with entries of the form a t that keep track of the representation \ntypes tied to abstract type names. Note that t may not mention a. Syntactically, type names are just \ntype variables. When viewed as data, (i.e., when inspected by the cast operator), types are con\u00adsidered \nequivalent iff they are syntactically equal. In contrast, when viewed as classi.ers for terms, knowledge \nabout the representation of type names may be taken into account. Rule ECONV says that if a term e has \na type t ' , it may be assigned any other type that is compatible with t ' . Type compatibility, in turn, \nis de.ned by the judgment . t1 t2. We only show the rule CNAME,which discharges a compatibility assumption \na t from the context; the other rules implement the congruence closure of this axiom. The important point \nhere is that equivalent types are compatible, but compatible types are not necessarily equivalent. Finally, \nRule ENEW also requires that the type t ' of the body e does not contain a (i.e., t ' must be well formed \nin . alone). A type of this form can always be derived by applying ECONV to convert t ' to t ' [t/a]. \n 2.2 Dynamic Semantics The operational semantics has to deal with generation of fresh type names. To \nthat end, we introduce a type store s to record generated type names. Hence, reduction is de.ned on con.gurations \n(s; e) instead of plain terms. Figure 1 shows the main reduction rules. We omit the standard search rules \nfor descending into subterms according to call-by-value, left-to-right evaluation order. The reduction \nrules for the F fragment are as usual and do not actually touch the store. However, types occurring in \nF constructs can contain type names bound in the store. Reducing the expression new a t in e creates \na new entry for a in the type store. We rely on the usual hygiene convention for bound variables to ensure \nthat a is fresh with respect to the current store (which can always be achieved by a-renaming).4 The \ntwo remaining rules are for casts. A cast takes two types and checks that they are equivalent (i.e., \nsyntactically equal). In either case, the expression reduces to a function that will return the appropriate \none of the additional value arguments, i.e., the value to be converted in case of success, and the default \nvalue otherwise. In the former case, type preservation is ensured because source and target types are \nknown to be equivalent. 4 A well-known alternative approach would omit the type store in favor of using \nscope extrusion rules for new binders, as in Rossberg [21]. Type preservation can be expressed using \nthe typing rule CONF for con.gurations. We formulate this rule by treating the type store as a type context, \nwhich is possible because type stores are a syntactic subclass of type contexts. (In a similar manner, \nwe can write s for well-formedness of store s, by viewing it as a type context.) It is worth noting that \nthe representation types in the store are actually never inspected by the dynamic semantics. They are \nonly needed for specifying well-formedness of con.gurations and proving type soundness. 2.3 Motivating \nExample Consider the following attempt to write a simple functional binary semaphore ADT [17] in G. Following \nMitchell and Plotkin [15], we use an existential type, as we would in System F: tsem := .a.a \u00d7 (a . a) \n\u00d7 (a . bool) esem := pack (int, (1,.x: int .(1 - x),.x: int .(x =0))) as tsem A semaphore essentially \nis a .ag that can be in two states: either locked or unlocked. The state can be toggled using the .rst \nfunction of the ADT, and it can be polled using the second. Our little module uses an integer value for \nrepresenting the state, taking 1 for locked and 0 for unlocked. It is an invariant of the implementation \nthat the integer never takes any other value otherwise, the toggle function would no longer operate correctly. \nIn System F, the implementation invariant would be protected by the fact that existential types are parametric: \nthere is no way to inspect the witness of a after opening the package, and hence no client could produce \nvalues of type a other than those returned by the module (nor could she apply integer operations to them). \nNot so in G. The following program uses cast to forgeavalue s of the abstract semaphore type a: eclient \n:= unpack (a, (s0, toggle, poll )) = esem in let s = cast int a 666 s0 in (poll s, poll (toggle s)) \nBecause reduction of unpack simply substitutes the representation type int for a, the consecutive cast \nsucceeds, and the whole ex\u00adpression evaluates to (true, true) although the second component should have \ntoggled s and thus be different from the .rst. The way to prevent this in G is to create a fresh type \nname as witness of the abstract type: esem1 := new a ' int in pack (a ' , (1,.x: int .(1 - x),.x: int \n.(x =0))) as tsem After replacing the initial semaphore implementation with this one, eclient will evaluate \nto (true, false) as desired the cast expression will no longer succeed, because a will be substituted \nby the dy\u00adnamic type name a ' ,and a ' = int. (Moreover, since a ' is only visible statically in the \nscope of the new expression, the client has no access to a ' , and thus cannot convert from int to a \n' either.) Now, while it is clear that new ensures proper type abstraction in the client program eclient, \nwe want to prove that it does so for any client program. A standard way of doing so is by showing a more \ngeneral property, namely representation independence [20]: we show that the module esem1 is contextually \nequivalent to another module of the same type, meaning that no G program can observe any difference between \nthe two modules. By choosing that other module to be a suitable reference implementation of the ADT in \nquestion, we can conclude that the real one behaves properly under all circumstances. The obvious candidate \nfor a reference implementation of the semaphore ADT is the following: esem2 := new a ' bool in pack \n(a ' , (true,.x: bool .\u00acx, .x: bool .x)) as tsem  Here, the semaphore state is represented directly \nby a Boolean .ag and does not rely on any additional invariant. If we can show that esem1 is contextually \nequivalent to esem2, then we can conclude that esem1 s type representation is truly being held abstract. \n 2.4 Contextual Equivalence In order to be able to reason about representation independence, we need \nto make precise the notion of contextual equivalence. A context C is an expression with a single hole \n[ ],de.ned in the usual manner. Typing of contexts is de.ned by a judgment form C : (.; G; t ) (. ' ;G \n' ; t ' ), where the triple (.; G; t ) indicates the type of the hole. The judgment implies that for \nany expression e with .; G e : t we have . ' ;G ' C[e]: t ' .The rules are straightforward, the key rule \nbeing the one for holes: . . . ' G . G ' [ ] : (.;G; t ) (. ';G' ; t ) We can now de.ne contextual approximation \nand contextual equivalence as follows (with s; e . asserting that s; e terminates): De.nition 2.1 (Contextual \nApproximation and Equivalence) Let .; G e1 : t and .; G e2 : t . def .; G e1 . e2 : t ..C, t ' ,s. s \n. C : (.; G; t ) (s; E; t ' ) . s; C[e1] . =. s; C[e2] . def .; G e1 . e2 : t . .; G e1 . e2 : t . .; \nG e2 . e1 : t That is, contextual approximation .; G e1 . e2 : t means that for any well-typed program \ncontext C with a hole of appropriate type, the termination of C[e1] implies the termination of C[e2]. \nContextual equivalence .; G e1 . e2 : t is just approximation in both directions. Considering that G \ndoes not explicitly contain any recursive or looping constructs, the reader may wonder why termination \nis used as the notion of distinguishing observation in our de.ni\u00adtion of contextual equivalence. The \nreason is that the cast opera\u00adtor, together with impredicative polymorphism, makes it possible to write \nwell-typed non-terminating programs [11]. (This was Gi\u00adrard s reason for studying the J operator in the \n.rst place [9].) More\u00adover, using cast, one can encode arbitrary recursive function de.\u00adnitions. Other \nforms of observation may then be encoded in terms of (non-)termination. See the expanded version of this \npaper for details [16].  3. A Logical Relation for G: Main Ideas Following Reynolds [20] and Mitchell \n[14], our general approach to reasoning about parametricity and representation independence is to de.ne \na logical relation. Essentially, logical relations give us a tractable way of proving that two terms \nare contextually equivalent, which in turn gives us a way of proving that abstract types are really abstract. \nOf course, since polymorphism in G is non-parametric, the de.nition of our logical relation in the cases \nof universal and existential types is somewhat unusual. To place our approach in context, we .rst review \nthe traditional approach to de.ning logical relations for languages with parametric polymorphism, such \nas System F. 3.1 Logical Relations for Parametric Polymorphism Although the technical meaning of logical \nrelation is rather woolly, the basic idea is to de.ne an equivalence (or approxima\u00adtion) relation on \nprograms inductively, following the structure of their types. To take the canonical example of arrow \ntypes, we would say that two functions are logically related at the type t1 . t2 if, when passed arguments \nthat are logically related at t1, either they both diverge or they both converge to values that are logically \nre\u00adlated at t2.The fundamental theorem of logical relations states that the logical relation is a congruence \nwith respect to the constructs of the language. Together with what Pitts [17] calls adequacy i.e., the \nfact that logically related terms have equivalent termination behavior the fundamental theorem implies \nthat logically related terms are contextually equivalent, since contextual equivalence is de.ned precisely \nto be the largest adequate congruence. Traditionally, the parametric nature of polymorphism is made \nclear by the de.nition of the logical relation for universal and ex\u00adistential types. Intuitively, two \ntype abstractions, .a.e1 and .a.e2, are logically related at type .a.t if they map related type argu\u00adments \nto related results. But what does it mean for two type argu\u00adments to be related? Moreover, once we settle \non two related type '' ' arguments t1 and t2, at what type do we relate the results e1[t1/a] and e2[t2' \n/a]? One approach would be to restrict related type arguments to be the same type t ' . Thus, .a.e1 and \n.a.e2 would be logically related at .a.t iff, for any (closed) type t ' , it is the case that '' ' e1[t \n/a] and e2[t /a] are logically related at the type t [t /a]. A key problem with this de.nition, however, \nis that, due to the quanti.cation over any argument type t ' , the type t [t ' /a] may in fact be larger \nthan the type .a.t , and thus the de.nition of the logical relation is no longer inductive in the structure \nof the type. Another problem is that this de.nition does not tell us anything about the parametric nature \nof polymorphism. Reynolds alternative approach is a generalization of Girard s candidates method for \nproving strong normalization for System F [9]. The idea is simple: instead of de.ning two type arguments \nto be related only if they are the same, allow any two different type arguments to be related by an (almost) \narbitrary relational interpretation (subject to certain admissibility constraints). That is, we parameterize \nthe logical relation at type t by an interpretation function ., which maps each free type variable of \nt to a pair of types t1' ,t2 ' together with some (admissible) relation between values of those types. \nThen, we say that .a.e1 and .a.e2 are logically related at type .a.t under interpretation . iff, for \nany closed types t1 ' and t2 ' and any relation R between values of those types, it is the case that \ne1[t1' /a] and e2[t2' /a] are logically related at type t under interpretation ., a . (t1' ,t2' ,R). \nThe miracle of Reynolds/Girard s method is that it simultane\u00adously (1) renders the logical relation inductively \nwell-de.ned in the structure of the type, and (2) demonstrates the parametricity of polymorphism: logically \nrelated type abstractions must behave the same even when passed completely different type arguments, \nso their behavior may not analyze the type argument and behave in different ways for different arguments. \nDually, we can show that two ADTs pack (t1,v1) as .a.t and pack (t2,v2) as .a.t are logically related \n(and thus contextually equivalent) by exhibiting some relational interpretation R for the abstract type \na,even if the underlying type representations t1 and t2 are different. This is the essence of what is \nmeant by representation independence . Unfortunately, in the setting of G, Reynolds/Girard s method is \nnot directly applicable, precisely because polymorphism in G is not parametric! This essentially forces \nus back to the .rst approach suggested above, namely to only consider type arguments to be logically \nrelated if they are equal. Moreover, it makes sense: the cast operator views types as data, so types \nmay only be logically related if they are indistinguishable as data. The natural questions, then, are: \n(1) what metric do we use to de.ne the logical relation inductively, since the structure of the type \nno longer suf.ces, and (2) how do we establish that dynamic type generation regains a form of parametricity? \nWe address these questions in the next two sections, respectively.  3.2 Step-Indexed Logical Relations \nfor Non-Parametricity First, in order to provide a metric for inductively de.ning the logical relation, \nwe employ step-indexing. Step-indexed logical relations were proposed originally by Appel and McAllester \n[7] as a way of giving a simple operational-semantics-based model for general recursive types in the \ncontext of foundational proof\u00adcarrying code. In subsequent work by Ahmed and others [3, 6], the method \nhas been adapted to support relational reasoning in a variety of settings, including untyped and imperative \nlanguages. The key idea of step-indexed logical relations is to index the de.nition of the logical relation \nnot only by the type of the pro\u00adgrams being related, but also by a natural number n representing (intuitively) \nthe number of steps left in the computation . That is, if two terms e1 and e2 are logically related at \ntype t for n steps, then if we place them in any program context C and run the re\u00adsulting programs for \nn steps of computation, we should not be able to produce observably different results (e.g., C[e1] evaluating \nto 5 and C[e2] evaluating to 7). To show that e1 and e2 are contextually equivalent, then, it suf.ces \nto show that they are logically related for n steps, for any n. To see how step-indexing helps us, consider \nhow we might de.ne a step-indexed logical relation for G in the case of universal types: two type abstractions \n.a.e1 and .a.e2 are logically related at .a.t for n steps iff, for any type argument t ' , it is the \ncase that '' ' e1[t /a] and e2[t /a] are logically related at t [t /a] for n - 1 steps. This reasoning \nis sound because the only way a program context can distinguish between .a.e1 and .a.e2 in n steps is \nby .rst applying them to a type argument t ' which incurs a step of computation for the \u00df-reduction (.a.ei) \nt ' '. ei[t ' /a] and then distinguishing between e1[t ' /a] and e2[t ' /a] within the next n - 1 steps. \nMoreover, although the type t [t ' /a] may be larger than .a.t , the step index n - 1 is smaller, so \nthe logical relation is inductively well-de.ned.  3.3 Kripke Logical Relations for Dynamic Parametricity \nSecond, in order to establish the parametricity properties of dy\u00adnamic type generation, we employ Kripke \nlogical relations, i.e., logical relations that are indexed by possible worlds.5 Kripke log\u00adical relations \nare appropriate when reasoning about properties that are true only under certain conditions, such as \nequivalence of mod\u00adules with local mutable state. For instance, an imperative ADT might only behave according \nto its speci.cation if its local data structures obey certain invariants. Possible worlds allow one to \ncod\u00adify such local invariants on the machine store [18]. In our setting, the local invariant we want \nto establish is what a dynamically generated type name means. That is, we will use possible worlds to \nassign relational interpretations to dynamically generated type names. For example, consider the programs \nesem1 and esem2 from Section 2. We want to show they are logically related at .a. a \u00d7 (a . a) \u00d7 (a . \nbool) in an empty initial world w0 (i.e., under empty type stores). The proof proceeds roughly as follows. \nFirst, we evaluate the two programs. This will have the effect of generating a fresh type name a ' , \nwith a ' int extending the type store of the .rst program and a ' bool extending the type store of \nthe second program. At this point, we correspondingly extend the initial world w0 with a mapping from \na ' to the relation R = {(1, true), (0, false)}, thus forming a new world w that speci.es the semantic \nmeaning of a ' . 5 In fact, step-indexed logical relations may already be understood as a special case \nof Kripke logical relations, in which the step index serves as the notion of possible world, and where \nn is a future world of m iff n = m. We now must show that the values pack (a ' , (1,.x: int .(1 - x),.x: \nint .(x =0))) as tsem and pack (a ' , (true,.x: bool .\u00acx, .x: bool .x)) as tsem are logically related \nin the world w. Since G s logical relation for existential types is non-parametric, the two packages \nmust have the same type representation, but of course the whole point of using new was to ensure that \nthey do (namely, it is a ' ). The remainder of the proof is showing that the value components of the \npackages are related at the type a ' \u00d7 (a ' . a ' ) \u00d7 (a ' . bool) under the interpretation . = a ' . \n(int, bool,R) derived from the world w. This last part is completely analogous to what one would show \nin a standard representation independence proof. In short, the possible worlds in our Kripke logical \nrelations bring back the ability to assign arbitrary relational interpretations R to abstract types, \nan ability that was seemingly lost when we moved to a non-parametric logical relation. The only catch \nis that we can only assign arbitrary interpretations to dynamic type names, not to static, universally/existentially \nquanti.ed type variables. There is one minor technical matter that we glossed over in the above proof \nsketch but is worth mentioning. Due to nondetermin\u00adism of type name allocation, the evaluation of esem1 \nand esem2 may result in a ' being replaced by a ' 1 in the former and a2 ' in the lat\u00adter (for some fresh \na ' 1 = a2' ). Moreover, we are also interested in proving equivalence of programs that do not necessarily \nallocate exactly the same number of type names in the same order. Consequently, we also include in our \npossible worlds a partial bijection . between the type names of the .rst program and the type names of \nthe second program, which speci.es how each dynami\u00adcally generated abstract type is concretely represented \nin the stores of the two programs. We require them to be in 1-1 correspondence because the cast construct \npermits the program context to observe equality on type names, as follows: def equal?: .a..\u00df. bool = \n.a..\u00df. cast ((a . a) . bool)((\u00df . \u00df) . bool) (.x:(a . a). true)(.x:(\u00df . \u00df). false)(.x:\u00df.x) We then consider \ntypes to be logically related if they are the same up to this bijection. For instance, in our running \nexample, when extending w0 to w, we would not only extend its relational in\u00adterpretation with a ' . (int, \nbool,R) but also extend its . with a ' . (a ' 1,a2' ). Thus, the type representations of the two existen\u00adtial \npackages, a ' 1 and a ' 2, though syntactically distinct, would still be logically related under w. \n 4. A Logical Relation for G: Formal Details Figure 2 displays our step-indexed Kripke logical relation \nfor G in full gory detail. It is easiest to understand this de.nition by making two passes over it. First, \nas the step indices have a way of infecting the whole de.nition in a super.cially complex but really \nvery straightforward way, we will .rst walk through the whole de.nition ignoring all occurrences of n \ns and k s (as well as auxiliary functions like the L\u00b7Jn operator). Second, we will pinpoint the few places \nwhere step indices actually play an important role in ensuring that the logical relation is inductively \nwell-founded. 4.1 Highlights of the Logical Relation The .rst section of Figure 2 de.nes the kinds of \nsemantic objects that are used in the construction of the logical relation. Relations R are sets of atoms, \nwhich are pairs of terms, e1 and e2, indexed by a possible world w. The de.nition of Atom[t1,t2] requires \nthat e1 and e2 have the types t1 and t2 under the type stores w.s1 and w.s2, respectively. (We use the \ndot notation w.si to denote the i-th Atomn[t1,t2] Reln[t1,t2] SomeReln Interpn Conc Worldn L(s1,s2,., \n.)Jn L.Jn L(t1,t2,R)Jn LRJn rR Vn[[a]]. def = Vn[[b]]. def = Vn[[t \u00d7 t ' ]]. def = Vn[[t ' . t ]]. def \n= def Vn[[.a.t ]]. = def Vn[[.a.t ]]. = def En[[t ]]. = def Tn[[O]]w = def Gn[[E]]. = def Gn[[G,x:t \n]]. = def Dn[[E]]w = def Dn[[.,a]]w = def Dn[[.,a t ]]w = .; G def = {(k, w, e1,e2) | k<n . w . Worldk \n. w.s1; e1 : t1 . w.s2; e2 : t2} def = {R . Atomval[t1,t2] |.(k, w, v1,v2) . R. .(k ' ,w ' ) ; (k, w). \n(k ' ,w ' ,v1,v2) . R} n def = {r =(t1,t2,R) | fv(t1,t2)= \u00d8. R . Reln[t1,t2]} def .n = {. . TVar . SomeReln} \ndef .n = {. . TVar . TVar \u00d7 TVar |.a, a ' . dom(.).a = a ' . .1(a)= .1(a ' ) . .2(a)= .2(a ' )} def \n = {w =(s1,s2,., .) | s1 . s2 . . . Conc . . . Interp. dom(.)= dom(.) . .a . dom(.).s1 (a) .1(a) . s2 \n(a) .2(an )} .1 .2 def =(s1,s2,., L.Jn) (k '' defk '' ,w ) ; (k, w) .= k . w . Worldk/ . def '' = \n{a.LrJn | .(a)= r} w .. ; w.. . w .. ;Lw..Jk/ . def .i .{1, 2}.w ' .si . w.si . =(t1,t2, LRJn) def rng(w \n' ..i) - rng(w..i) . = {(k, w, e1,e2) . R | k<n} ' dom(w .si) - dom(w.si) def def . ' ; . ..a . dom(.).. \n' (a)= .(a) = {(k, w, e1,e2) | k =0 . . ' def(k - 1, LwJk-1,e1,e2) . R}; . ..a . dom(.).. ' (a)= .(a) \nL.(a).RJn {(k, w, c, c) . Atomn[b, b]} {(k, w, (v1,v1' ), (v2,v2' )) . Atomn[.1(t \u00d7 t ' ),.2(t \u00d7 t ' \n)] | (k, w, v1,v2) . Vn[[t ]]. . (k, w, v 1' ,v2' ) . Vn[[t ' ]].} {(k, w, .x:t1.e1,.x:t2.e2) . Atomn[.1(t \n' . t ),.2(t ' . t )] | ' '' .(k ' ,w ,v1,v2) . Vn[[t ]].. (k ' ,w ) ; (k, w) . (k ' ,w ' ,e1[v1/x],e2[v2/x]) \n. En[[t ]].} {(k, w, .a.e1,.a.e2) . Atomn[.1(.a.t ),.2(.a.t )] | .(k '' ' ,w ) ; (k, w). .(t1,t2,r) \n. Tk/ [[O]]w. (k '' ,w ,e1[t1/a],e2[t2/a]) . rEn[[t ]]., a.r} {(k, w, pack (t1,v1), pack (t2,v2)) . \nAtomn[.1(.a.t ),.2(.a.t )] | .r. (t1,t2,r) . Tk[[O]]w . (k, w, v1,v2) . rVn[[t ]]., a.r} {(k, w, e1,e2) \n. Atomn[.1(t ),.2(t )] | .j<k. .s1,v1. (w.s1; e1 '.j s1; v1) . ' '' . * .w ,v2. (k - j, w ' ) ; (k, \nw) . w .s1 = s1 . (w.s2; e2 'w.s2; v2) . (k - j, w ' ,v1,v2) . Vn[[t ]].} {(w..1(t ),w..2(t ), (w..1(t \n),w..2(t ),Vn[[t ]]w..)) | fv(t ) . dom(w..)} {(k, w, \u00d8, \u00d8) | k<n . w . Worldk} {(k, w, (.1,x.v1), (.2,x.v2)) \n| (k, w, .1,.2) . Gn[[G]]. . (k, w, v1,v2) . Vn[[t ]].} {(\u00d8, \u00d8, \u00d8)} {((d1,a.t1), (d2,a.t2), (., a.r)) \n| (d1,d2,.) . Dn[[.]]w . (t1,t2,r) . Tn[[O]]w} {((d1,a.\u00df1), (d2,a.\u00df2), (., a.r)) | (d1,d2,.) . Dn[[.]]w \n. .a ' .w..(a ' )= r . w..(a ' )=(\u00df1,\u00df2) . w.s1(\u00df1)= d1(t ) . w.s2(\u00df2)= d2(t ) . r.R = Vn[[t ]].} def \n e1 ; e2 : t . .; G e1 : t . .; G e2 : t . .n = 0. .w0 . Worldn. .(d1,d2,.) . Dn[[.]]w0 . .(k, w, .1,.2) \n. Gn[[G]].. (k, w) ; (n, w0) . (k, w, d1.1(e1),d2.2(e2)) . En[[t ]]. Figure 2. Logical Relation for G \ntype store component of w, and analogous notation for projecting two values v1 and v2 under a world w, \nthen the relation must relate out the other components of worlds.) those values in any future world of \nw. (We discuss the de.nition of Rel[t1,t2] de.nes the set of admissible relations, which are world extension \nbelow.) Monotonicity is needed in order to ensure permitted to be used as the semantic interpretations \nof abstract that we can extend worlds with interpretations of new dynamic type types. For our purposes, \nadmissibility is simply monotonicity i.e., names, without interfering somehow with the interpretations \nof the closure under world extension. That is, if a relation in Rel relates old ones. Worlds w are 4-tuples \n(s1,s2,.,.), which describe a set of assumptions under which pairs of terms are related. Here, s1 and \ns2 are the type stores under which the terms are typechecked and evaluated. The .nite mappings . and \n. share a common domain, which can be understood as the set of abstract type names that have been generated \ndynamically. These semantic type names do not exist in either store s1 or s2.6 Rather, they provide a \nway of referring to an abstract type that is represented by some type name a1 in s1 and some type name \na2 in s2. Thus, for each name a . dom(.)=dom(.),the concretization . maps the semantic name a to a pair \nof concrete names from the stores s1 and s2, respectively. (See the end of Section 3.3 for an example \nof such an ..) As the de.nition of Conc makes clear, distinct semantic type names must have distinct \nconcretizations; consequently, . represents a partial bijection between s1 and s2. The last component \nof the world w is ., which assigns rela\u00adtional interpretations to the aforementioned semantic type names. \nFormally, . maps each a to a triple r =(t1,t2,R),where R is a monotone relation between values of types \nt1 and t2.(Again,see the end of Section 3.3 for an example of such a ..) The .nal con\u00addition in the de.nition \nof World stipulates that the closed syntactic types in the range of . and the concrete type names in \nthe range of . are compatible. As a matter of notation, we will write .i and .i to denote the type substitutions \n{a . ai | .(a)=(a1,a2)} and {a . ti | .(a)=(t1,t2,R)}, respectively. The second section of Figure 2 displays \nthe de.nition of world extension. In order for w ' to extend w (written w ' ; w), it must be the case \nthat (1) w ' speci.es semantic interpretations for a superset of the type names that w interprets, (2) \nfor the names that w interprets, w ' must interpret them in the same way, and (3) any new semantic type \nnames that w ' interprets may only correspond to new concrete type names that did not exist in the stores \nof w. Although the third condition is not strictly necessary, we have found it to be useful when proving \ncertain examples (e.g., the order independence example in Section 4.4). The last section of Figure 2 \nde.nes the logical relation itself. V [[t ]]. is the logical relation for values, E[[t ]]. is the one \nfor terms, and T [[O]]w is the one for types as data, as described in Section 3 (here, O represents the \nkind of types). V [[t ]]. relates values at the type t , where the free type variables of t are given \nrelational interpretations by .. Ignoring the step indices, V [[t ]]. is mostly very standard. For instance, \nat certain points (namely, in the . and . cases), when we quantify over logically related (value or type) \narguments, we must allow them to come from an arbitrary future world w ' in order to ensure monotonicity. \nThis kind of quanti.cation over future worlds is commonplace in Kripke logical relations. The only really \ninteresting bit in the de.nition of V [[t ]]. is the use of T [[O]]w to characterize when the two type \narguments (resp. components) of a universal (resp. existential) are logically related. As explained in \nSection 3.3, we consider two types to be logically related in world w iff they are the same up to the \npartial bijection w... Formally, we de.ne T [[O]]w as a relation on triples (t1,t2,r), where t1 and t2 \nare the two logically related types and r is a rela\u00adtion telling us how to relate values of those types. \nTo be logically related means that t1 and t2 are the concretizations (according to w..) of some semantic \ntype t ' . Correspondingly, r is the logi\u00adcal relation V [[t ' ]]w.. at that semantic type. Thus, when \nwe write E[[t ]]., a . r in the de.nition of V [[.a.t ]]., this is roughly equiv\u00adalent to writing E[[t \n[t ' /a]]]. (which our discussion in Section 3.2 might have led the reader to expect to see here instead). \nThe reason for our present formulation is that E[[t [t ' /a]]]. is not quite right: 6 In fact, technically \nspeaking, we consider dom(.)= dom(.) to be bound variables of the world w. the free variables of t are \ninterpreted by ., but the free variables of t ' are dynamic type names whose interpretations are given \nby w... It is possible to merge . and w.. into a uni.ed interpretation . ' ,but we feel our present approach \nis cleaner. Another point of note: since r is uniquely determined from t1 and t2, it is not really necessary \nto include it in the T [[O]]w relation. However, as we shall see in Section 6, formulating the logical \nrelation in this way has the bene.t of isolating all of the non\u00adparametricity of our logical relation \nin the de.nition of T [[O]]w. The term relation E[[t ]]. is very similar to that in previous step\u00adindexed \nKripke logical relations [6]. Brie.y, it says that two terms are related in an initial world w if whenever \nthe .rst evaluates to a value under w.s1, the second evaluates to a value under w.s2,and the resulting \nstores and values are related in some future world w ' . The remainder of the de.nitions in Figure 2 \nserve to formalize a logical relation for open terms. G[[G]]. is the logical relation on value substitutions \n., which asserts that related . s must map vari\u00adables in dom(G) to related values. D[[.]]w is the logical \nrelation on type substitutions. It asserts that related d s must map variables in dom(.) to types that \nare related in w. For type variables a bound as a t ,the d s must map a to a type name whose semantic \nin\u00adterpretation in w is precisely the logical relation at t . Analogously to T [[O]]w, the relation D[[.]]w \nalso includes a relational interpre\u00adtation ., which may be uniquely determined from the d s. Finally, \nthe open logical relation .; G e1 ; e2 : t is de.ned in a fairly standard way. It says that for any starting \nworld w0,and any type substitutions d1 and d2 related in that world, if we are given related value substitutions \n.1 and .2 in any future world w, then d1.1e1 and d2.2e2 are related in w as well. 4.2 Why and Where \nthe Steps Matter As we explained in Section 3.2, step indices play a critical role in making the logical \nrelation well-founded. Essentially, whenever we run into an apparent circularity, we go down a step by \nde.ning an n-level property in terms of an (n-1)-level one. Of course, this trick only works if, at all \nsuch stepping points , the only way that an adversarial program context could possibly tell whether the \nn\u00adlevel property holds or not is by taking one step of computation and then checking whether the underlying \n(n-1)-level property holds. Fortunately, this is the case. Since worlds contain relations, and relations \ncontain sets of tuples that include worlds, a na\u00a8ive construction of these objects would have an inconsistent \ncardinality. We thus stratify both worlds and relations by a step index: n-level worlds w . Worldn contain \nn-level interpretations . . Interpn, which map type variables to n-level relations; n-level relations \nR . Reln[t1,t2] only contain atoms indexed by a step level k<n and a world w . Worldk.Al\u00adthough our possible \nworlds have a different structure than in previ\u00adous work, the technique of mutual world and relation \nstrati.cation is similar to that used in Ahmed s thesis [2], as well as recent work by Ahmed, Dreyer \nand Rossberg [6]. Intuitively, the reason this works in our setting is as follows. Viewed as a judgment, \nour logical relation asserts that two terms e1 and e2 are logically related for k steps in a world w \nat a type t under an interpretation . (whose domain contains the free type variables of t ). Clearly, \nin order to handle the case where t is just a type variable a, the relations r in the range of . must \ninclude atoms at step index k (i.e., the r s must be in SomeRelk+1). But what about the relations in \nthe range of w..? Those relations only come into play in the universal and existential cases of the log\u00adical \nrelation for values. Consider the existential case (the universal one is analogous). There, w.. pops \nup in the de.nition of the rela\u00adtion r that comes from Tk[[O]]w.However, that r is only needed in de.ning \nthe relatedness of the values v1 and v2 at step level k-1 (note the de.nition of rR in the second section \nof Figure 2). Con\u00adsequently, we only need r to include atoms at step k-1 and lower (i.e., r must be in \nSomeRelk), so the world w from which r is derived need only be in Worldk. As this discussion suggests, \nit is imperative that we go down a step in the universal and existential cases of the logical relation. \nFor the other cases, it is not necessary to go down a step, although we have the option of doing so. \nFor example, we could de.ne k-level relatedness at pair type t1 \u00d7 t2 in terms of (k-1)-level relatedness \nat t1 and t2. But since the type gets smaller, there is no need to. For clarity, we have only gone down \na step in the logical relation at the points where it is absolutely necessary, and we have used the r \nnotation to underscore those points.  4.3 Key Properties The main results concerning our logical relation \nare as follows:  Theorem 4.1 (Fundamental Property for ;) If .; G e : t ,then .; G e ; e : t . Theorem \n4.2 (Soundness of ; wrt. Contextual Approximation) If .; G e1 ; e2 : t ,then .; G e1 e2 : t . These theorems \nestablish that our logical relation provides a sound technique for proving contextual equivalence of \nG programs. The proofs of these theorems rely on many technical lemmas, most of which are standard and \nstraightforward to prove. We highlight a few of them here, and refer the reader to the expanded version \nof this paper for full details of the proofs [16]. One key lemma we have mentioned already is the monotonicity \nlemma, which states that the logical relation for values is closed under world extension, and therefore \nbelongs to the Rel class of relations. Another key lemma is transitivity of world extension. There are \nalso a group of lemmas Pitts terms them compati\u00adbility lemmas [17] which show that the logical relation \nis a pre\u00adcongruence with respect to the constructs of the G language. Of particular note among these \nare the ones for cast and new. For cast, we must show that cast t1 t2 is logically related to itself \nunder a type context . assuming that t1 and t2 are well\u00adformed in .. This boils down to showing that, \nfor logically related type substitutions d1 and d2, it is the case that d1t1 = d1t2 if and only if d2t1 \n= d2t2. This follows easily from the fact that d1 and d2, by virtue of being logically related, map the \nvariables in dom(.) to types that are syntactically identical up to some bijection on type names. For \nnew, we must show that, if .,a t ' ;G e1 ; e2 : t , then .; G new a t ' in e1 ; new a t ' in e2 : t (assuming \n.G and . t ). The proof involves extending the . and . components of some given initial world w0 with \nbindings for the fresh dynamically-generated type name a.The . is extended with a . (a1,a2),where a1 \nand a2 are the concrete fresh names that are chosen when evaluating the left and right new expressions. \nThe . is extended so that the relational interpretation of a is simply the logical relation at type t \n' . The proof of this lemma is highly reminiscent of the proof of compatibility for ref (reference allocation) \nin a language with mutable references [6]. Finally, another important compatibility property is type \ncom\u00adpatibility, i.e., that if . t1 t2 and (d1,d2,.) . Dn[[.]]w,then Vn[[t1]]. = Vn[[t2]]. and En[[t1]]. \n= En[[t2]].. The interesting case is when t1 is a variable a bound in . as a t2, and the result in this \ncase follows easily from the de.nition of D[[.,a t ]]w. 4.4 Examples Semaphore. We now return to our \nsemaphore example from Sec\u00adtion 2 and show how to prove representation independence for the two different \nimplementations esem1 and esem2. Recall that the former uses int, the latter bool. To show that they \nare contextu\u00adally equivalent, it suf.ces by Soundness to show that each logi\u00adcally approximates the other. \nWe prove only one direction, namely esem1 ; esem2 : tsem ; the other is proven analogously. Expanding \nthe de.nitions, we need to show (k, w, esem1,esem2) . En[[tsem ]]\u00d8. Note how each term generates a fresh \ntype name ai in one step, resulting in a package value. Hence all we need to do is come up with a world \nw ' satisfying (k - 1,w ' ) ; (k, w),  w ' .s1 = w.s1,a1 int and w ' .s2 = w.s2,a2 bool,  (k - 1,w \n' , pack(a1,v1), pack(a2,v2)) . Vn[[tsem ]]\u00d8.  where vi is the term component of esemi s implementation. \nWe construct w ' by extending w with mappings that establish the relation between the new type names: \n'' '' val R := {(k ,w ,vint,vbool ) . Atomk-1[int, bool] | (vint,vbool )= (1, true) . (vint,vbool )=(0, \nfalse)} r := (int, bool,R) w ' := LwJk-1 (a1 int,a2 bool,a.(a1,a2),a.r) The .rst two conditions above \nare satis.ed by construction. To show that the packages are related we need to show the exis\u00ad ''' tence \nof an r with (a1,a2,r ) . Tk-1[[O]]w such that (k - ' '' 2, Lw Jk-2,v1,v2) . Vn[[tsem ]]., a.r ' ,where \ntsem = a \u00d7 (a . a) \u00d7 (a . bool).Since ai = w ' ..i(a), r ' must be (int, bool,Vk-1[[a]]w ' ..) by de.nition \nof T [[O]]. Of course, we de.ned w ' the way we did so that this r ' is exactly r. ' The proof of (k \n- 2, Lw ' Jk-2,v1,v2) . Vn[[tsem ]]., a.r de\u00ad ' composes into three parts, following the structure of \ntsem: 1. (k - 2, Lw ' Jk-2, 1, true) . Vn[[a]]., a.r This holds because Vn[[a]]., a.r = R.  2. (k - \n2, Lw ' Jk-2,.x:int.(1 - x),.x:bool.\u00acx) . Vn[[a . a]]., a.r  Suppose we are given related arguments \nin a future world: (k '' '''' ,w ,v1,v2) . Vn[[a]]., a.r = R. '' '' Hence either (v1,v2)=(1, true) or \n(v1,v2)= (0, false).  Consequently, 1 - v1 ' and \u00acv2 ' will evaluate in one step, without effects, to \nvalues again related by R.  '' '' In other words, (k '' ,w , 1 - v1, \u00acv2) . En[[a]]., a.r. 3. (k - 2, \nLw ' Jk-2,.x.(x =0),.x.x) . Vn[[a . bool]]., a.r Like in the previous part, the arguments v1 ' and v2 \n' will be related by R in some future (k '' ,w '' ). Therefore v1 ' =0 will reduce in one step without \neffects to v2' , which already is a value. Because of the de.nition of the logical relation at type ''' \n' bool, this implies (k '' ,w ,v1 =0,v2) . En[[bool]]., a.r. Partly Benign Effects. When side effects \nare introduced into a pure language, they often falsify various equational laws concern\u00ading repeatability \nand order independence of computations. In this section, we offer some evidence that the effect of dynamic \ntype generation is partly benign in that it does not invalidate some of these equational laws. First, \nconsider the following functions: v1 := .x:(unit . t ). let x ' = x () in x () v2 := .x:(unit . t ).x \n() The only difference between v1 and v2 is whether the argument x is applied once or twice. Intuitively, \neither x () diverges, in which case both programs diverge, or else the .rst application of x terminates, \nin which case so should the second. Second, consider the following functions: ' ''' v1 := .x:(unit . \nt )..y:(unit . t ). let y = y () in (x (),y ) v2 ' := .x:(unit . t )..y:(unit . t ' ).(x (),y ()) The \nonly difference between v1 ' and v2 ' is the order in which they call their argument callbacks x and \ny. Those calls may both result in the generation of fresh type names, but the order in which the names \nare generated should not matter. Using our logical relation, we can prove that v1 and v2 are con\u00adtextually \nequivalent, and so are v1 ' and v2' . (Due to space considera\u00adtions, we refer the interested reader to \nthe expanded version of this paper for full proof details [16].) However, as we shall see in the example \nof e1 ' and e2 ' in the next section, our G language does not enjoy referential transparency. This is \nto be expected, of course, since new is an effectful operation and (in-)equality of type names is observable \nin the language.   5. Wrapping We have seen that parametricity can be re-established in G by introducing \nname generation in the right place. But what is the right place in general? That is, given an arbritrary \nexpression e with polymorphic type te, how can we systematically transform it into an expression e ' \nof the same type te that is parametric? One obvious but unfortunately bogus idea is the following: transform \ne such that every existential introduction and every uni\u00adversal elimination creates a fresh name for \nthe respective witness or instance type. Formally, apply the following rewrite rules to e: pack (t, e) \nas t ' new a t in pack (a, e) as t ' et new a t in ea Obviously, this would make every quanti.ed type \nabstract, so that any cast that tries to inspect it would fail. Or would it? Perhaps surprisingly, the \nanswer is no. To see why, consider the following expressions of type (.a.t ' ) \u00d7 (.a.t ' ): e1 := let \nx = pack (t, v) in (x, x) e2 := (pack (t, v), pack (t, v)) They are clearly equivalent in a parametric \nlanguage (and in fact they are even equivalent in G). Yet rewriting yields: e ' := let x =(new a t in \npack (a, v)) in (x, x) 1 e ' 2 := (new a t in pack (a, v), new a t in pack (a, v)) The resulting expressions \nare not equivalent anymore, because they perform different effects. Here is one distinguishing context: \nlet p =[ ] in unpack (a1,x1) = p.1 in unpack (a2,x2) = p.2 in equal? a1 a2 Although the representation \ntype t is not disclosed as such, sharing between the two abstract types in e1 ' is. In a parametric language, \nthat would not be possible. In order to introduce effects uniformly, and to hide internal sharing, the \ntransformation we are looking for needs to be de.ned on the structure of types, not terms. Roughly, for \neach quanti.er occurring in te we need to generate one fresh type name. That is, instead of transforming \ne itself, we simply wrap it with some expression that introduces the necessary names at the boundary, \nby induction on the type te. In fact, we can re.ne the problem further. When looking at a G expression \ne, what do we actually mean by making it parametric ? We can mean two different things: either ensuring \nthat e behaves parametrically, or dually, that any context treats e parametrically. In the former case, \nwe are protecting the context against e,inthe latter we protect e against malicious contexts. The latter \nis what is sometimes referred to as abstraction safety. def Wr\u00b1 t (e)= let x=e in Wr\u00b1 t (x) (if e not \na value) def Wr\u00b1 a (v)= v def Wr\u00b1 b (v)= v def Wr\u00b1 (v)= (Wr\u00b1 (v.1), Wr\u00b1 (v.2)) t1\u00d7t2 t1 t2 def Wr\u00b1 (v)= \n.x1:t1. Wr\u00b1 (v Wr\u00b1 (x1)) t1.t2 t2 t1 Wr\u00b1.a.t (v)= .a. new \u00b1 t (va) def a in Wr\u00b1 def Wr\u00b1 (v)= unpack (a, \nx)=v in .a.t new \u00b1 a in pack (a, Wr\u00b1 t (x)) as .a.t def new + a in e = new a ' a in e[a ' /a] def new \n- a in e = e Figure 3. Wrapping Figure 3 de.nes a pair of wrapping operators that correspond to these \ntwo dual requirements: Wr+ protects an expression e : te from being used in a non-parametric way, by \ninserting fresh names for each existential quanti.er. Dually, Wr- forces e to behave para\u00admetrically \nby creating a fresh name for each polymorphic instanti\u00adation. The de.nitions extend to other types in \nthe usual functorial manner. Both de.nitions are interdependent, because roles switch for function arguments. \nThese operators are similar to the type\u00addirected translation that Sumii and Pierce suggest for establishing \ntype abstraction in an untyped language [27] (they propose the de\u00adscriptive terms .rewall for Wr+, and \nsandbox for Wr-). How\u00adever, their use of dynamic sealing instead of type generation results in the insertion \nof runtime coercions to seal/unseal each individual value of abstract type, while our wrapping leaves \nsuch values alone. Given these operators, we can go back to our semaphore ex\u00adample: esem1 can now be \nobtained as Wr+ tsem (esem) (modulo some harmless .-expansions). This generalises to any ADT: wrapping \nits implementation positively will guarantee abstraction by making it parametric. We prove that in the \nnext section. Positive wrapping is reminiscent of module sealing (or opaque signature ascription) in \nML-style module languages. If we view e as a module and its type te as a signature, then Wr+ te (e) corresponds \nto the sealing operation e :>te. While module sealing typically only performs static abstraction, wrapping \ndescribes the dynamic equivalent [22]. In fact, positive wrapping is precisely how sealing is implemented \nin Alice ML [23], where the module language is non-parametric otherwise. The correspondence to module \nsealing motivates our treatment of existential types. Notice that Wr+ causes a fresh type name to be \ncreated only once for each existentially quanti.ed type that is, corresponding to each existential introduction. \nAnother option would be to generate type names with each existential elimination. In fact, such a semantics \nwould arise naturally were we to use a Church encoding of existentials in conjunction with our wrapping \nfor universals. However, in such a semantics, unpacking an existen\u00adtial value twice would have the effect \nof producing two distinct ab\u00adstract types. While this corresponds intuitively to the generativity of \nunpack in System F, it is undesirable in the context of dynamic, .rst-class modules. In particular, in \norder for an abstract type t de\u00ad.ned by some dynamic module M to have some permanent identity (so that \nit can be referenced by other dynamic modules), it is im\u00adportant that each unpacking of M yields a handle \nto the same name for t. Moreover, as we show in the next section, our approach to de.ning wrapping is \nsuf.cient to ensure abstraction safety. 6. Parametric Reasoning The logical relation developed in Section \n4 enables us to do non\u00adparametric reasoning about equivalence of G programs. It also T . def ''' ''' \n[[O]]w = {(t1,t2, (t1,t2,R)) | t . w.si ti t . R . Reln[t1,t2]} n ii (everything else as in Figure 2) \nFigure 4. Parametric Logical Relation enables us to do parametric reasoning, but only indirectly: we \nhave to explicitly deal with the effects of new and to de.ne worlds containing relations between type \nnames. It would be preferable if we were able to do parametric reasoning directly. For example, given \ntwo expressions e1, e2 that do not use casts, and assuming that the context does not do so either, we \nshould be able to reason about equivalence of e1 and e2 in a manner similar to what we do when reasoning \nabout System F. 6.1 A Parametric Logical Relation Thanks to the modular formulation of our logical relation \nin Fig\u00adure 2, it is easy to modify it so that it becomes parametric. All we need to do is swap out the \nde.nition of T [[O]]w, which relates types as data. Figure 4 gives an alternative de.nition that allows \nchoos\u00ading an arbitrary relation between arbitrary types. Everything else stays exactly the same. We decorate \nthe set of parametric logical relations thus obtained with . (i.e., V . , E., etc.) to distinguish them \nfrom the original ones. Likewise, we write ;. for the notion of parametric logical approximation de.ned \nas in Figure 2 but in terms of the parametric relations. For clarity, we will refer to the original de.nition \nas the non-parametric logical relation. This modi.cation gives us a seemingly parametric de.nition of \nlogical approximation for G terms. But what does that actually mean? What is the relation between parametric \nand non-parametric logical approximation and, ultimately, contextual approximation? Since the language \nis not parametric, clearly, parametrically equiv\u00adalent terms generally are not contextually equivalent. \nThe answer is given by the wrapping functions we de.ned in the previous section. The following theorem \nconnects the two notions of logical relation and approximation that we have introduced: Theorem 6.1 (Wrapping \nfor ;.) 1. If e1 ;. e2 : t ,then t (e1) ; Wr+ Wr+ t (e2): t . 2. If e1 ; e2 : t ,then t (e1) ;. t (e2): \nt . Wr- Wr- This theorem justi.es the de.nition of the parametric logical re\u00adlation. At the same time \nit can be read as a correctness result for the wrapping operators: it says that whenever we can relate \ntwo terms using parametric reasoning, then the positive wrappings of the .rst term contextually approximates \nthe positive wrapping of the second. Dually, once any properly related terms are wrapped negatively, \nthey can safely be passed to any term that depends on its context behaving parametrically. What can we \nsay about the content of the parametric relation? Obviously, it cannot contain arbitrary non-parametric \nG terms e.g., cast t1 t2 is not even related to itself in E.. However, we still obtain the following \nrestricted form of the fundamental property: Theorem 6.2 (Fundamental Property for ;.) If .; G e : t \nand e is cast-free, then .; G e ;. e : t . In particular, this implies that any well-typed System F term \nis parametrically related to itself. The relation will also contain terms with cast, but only if the \nuse of cast does not violate parametricity. (We discuss this further in Section 7.) Along the same lines, \nwe can show that our parametric logical relation is sound w.r.t. contextual approximation, if the de.nition \nof the latter is limited to quantifying only over cast-free contexts.  6.2 Examples Semaphore. Consider \nour running example of the semaphore module again. Using the parametric relation, we can prove that the \ntwo implementations are related without actually reasoning about type generation. That aspect is covered \nonce and for all by the Wrapping Theorem. Recall the two implementations, here given in unwrapped form: \nesem1 ' := pack (int, (1,.x: int .(1 - x),.x: int .(x =0))) as tsem esem2 ' := pack (bool, (true,.x: \nbool .\u00acx, .x: bool .x)) as tsem We can prove e ' ;. e ' : using conventional para\u00ad sem1 sem2 tsem metric \nreasoning about polymorphic terms. Now de.ne esem1 = Wr+ (esem1' ) and esem2 =Wr+ (esem2' ), which are \nsemantically tsem tsem equivalent to the original de.nitions in Section 2.3. The Wrapping Theorem then \nimmediately tells us that esem1 ; esem2 : tsem. AFreeTheorem. We can use the parametric relation for \nproving free theorems [30] in G. For example, for any g : .a.a . a in G it holds that Wr-(g) either diverges \nfor all possible arguments t and v : t , or it returns v in all cases. We .rst apply the Fundamental \nProperty for ; to relate g to itself in E, then transfer this to E. for Wr-(g) using the Wrapping Theorem. \nFrom there the proof proceeds in the usual way.  7. Syntactic vs. Semantic Parametricity The primary \nmotivation for our parametric relation in the previous section was to enable more direct parametric reasoning \nabout the result of (positively) wrapping System F terms. However, it is also possible to use our parametric \nrelation to reason about terms that are syntactically,or intensionally, non-parametric (i.e., that use \ncast s), so long as they are semantically,or extensionally, parametric (i.e., the use of cast is not \nexternally observable). For example, consider the following two polymorphic functions of type .a.ta (here, \nlet b2i = .x:bool. if x then 1 else 0): ta := .\u00df. (a \u00d7 a . \u00df) \u00d7 (\u00df . a) \u00d7 (\u00df . a) g1 := .a. pack (a \u00d7 \na, (.p.p, .x.(x.1),.x.(x.2))) as ta g2 := .a. cast tbool ta (pack (int, (.p:(bool \u00d7 bool). b2i(p.1) + \n2\u00d7b2i(p.2), .x:int.x mod 2=0, .x:int.x div 2=0)) as tbool ) (g1 a) These two functions take a type argument \na and return a simple generic ADT for pairs over a.But g2 is more clever about it and specializes the \nrepresentation for a = bool. In that case, it packs both components into the two least signi.cant bits \nof a single integer. For all other types, g2 falls back to the generic implementation from g1. Using \nthe parametric relation, we will be able to show that Wr+(g1) Wr+(g2): .a.ta. One might .nd this surprising, \nsince g2 is syntactically non-parametric, returning different imple\u00admentations for different instantiations \nof its type argument. How\u00adever, since the two possible implementations g2 returns are exten\u00adsionally \nequivalent to each other, g2 is semantically indistinguish\u00adable from the syntactically parametric g1. \nFormally: Assume that t1, t2 are the types and Ra . Rel[t1,t2] is the relation the context picks, parametrically, \nfor a.If t2 = bool, the rest of the proof is straightforward. Otherwise, we do not know def Vn \u00b1[[a]]. \n= V \u00b1 def n [[b]]. = V \u00b1' def n [[t \u00d7 t ]]. = def Vn \u00b1[[t ' . t ]]. = def Vn \u00b1[[.a.t ]]. = V \u00b1 def n \n[[.a.t ]]. = def En \u00b1[[t ]]. = T + def n [[O]]w = T - def n [[O]]w = .; G L.(a).RJn {(k, w, c, c) . Atomn[b, \nb]} '' '' {(k, w, (v1,v1), (v2,v2)) . Atomn[.1(t \u00d7 t ),.2(t \u00d7 t )] | (k, w, v1,v2) . Vn \u00b1[[t ]]. . (k, \nw, v 1' ,v2' ) . Vn \u00b1[[t ' ]].} {(k, w, .x:t1.e1,.x:t2.e2) . Atomn[.1(t ' . t ),.2(t ' . t )] | ' '' \n .(k ' ,w ,v1,v2) . Vn \u00b1[[t ]].. (k ' ,w ) ; (k, w) . (k ' ,w ' ,e1[v1/x],e2[v2/x]) . E\u00b1[[t ]].} n {(k, \nw, .a.e1,.a.e2) . Atomn[.1(.a.t ),.2(.a.t )] | .(k '' ' ,w ) ; (k, w). .(t1,t2,r) . Tk\u00b1 / [[O]]w. (k \n' ,w ' ,e1[t1/a],e2[t2/a]) . rEn \u00b1[[t ]]., a.r} {(k, w, pack (t1,v1), pack (t2,v2)) . Atomn[.1(.a.t \n),.2(.a.t )] | .r. (t1,t2,r) . T \u00b1[[O]]w . (k, w, v1,v2) . rVn \u00b1[[t ]]., a.r} k {(k, w, e1,e2) . Atomn[.1(t \n),.2(t )] | .j<k. .s1,v1. (w.s1; e1 's1; v1) . .j ' '' . * .w ,v2. (k - j, w ' ) ; (k, w) . w .s1 \n= s1 . (w.s2; e2 'w.s2; v2) . (k - j, w ' ,v1,v2) . Vn \u00b1[[t ]].} T . D+ def D. n [[O]]w n [[.]]w = n[[.]]w \nD- def Tn[[O]]w n [[.]]w = Dn[[.]]w def e1 ;\u00b1 e2 : t . .; G e1 : t . .; G e2 : t . .n = 0, .w0 . Worldn \n. .(d1,d2,.) . D\u00b1[[.]]w0. .(k, w, .1,.2) . G\u00b1[[G]].. n n (k, w) ; (n, w0) . (k, w, d1.1(e1),d2.2(e2)) \n. En \u00b1[[t ]]. Figure 5. Polarized Logical Relations anything about t1 and Ra, because t1 and t2 are related \nin T . . Nevertheless, we can construct a suitable relational interpretation R\u00df . Rel[t1 \u00d7 t1, int] for \nthe type \u00df: R\u00df := {(k, w, (v, v ' ), 0) | (k, w, v, false), (k, w, v ' , false) . Ra}.{(k, w, (v, v ' \n), 1) | (k, w, v, true), (k, w, v ' , false) . Ra}.{(k, w, (v, v ' ), 2) | (k, w, v, false), (k, w, v \n' , true) . Ra}.{(k, w, (v, v ' ), 3) | (k, w, v, true), (k, w, v ' , true) . Ra} As it turns out, we \ndo not need to know much about the structure of Ra to de.ne R\u00df. What we are relying on here is only the \nknowledge that all values in Ra are well-typed, which is built into our de.nition of Rel. From that we \nknow that there can never be any other value than true or false on the right side of the relation Ra. \nHence we can still enumerate all possible cases to de.ne R\u00df , and do a respective case distinction when \nproving equivalence of the projection operations. Interestingly, it seems that our proof relies critically \non the fact that our logical relations are restricted to syntactically well-typed terms. Were we to lift \nthis restriction, we would be forced (it seems) to extend the de.nition of R\u00df with a junk case, but the \ncalls to b2i in g2 would get stuck if applied to non-boolean values. We leave further investigation of \nthis observation to future work.  8. Polarized Logical Relations The parametric relation is useful for \nproving parametricity proper\u00adties about (the positive wrappings of) G terms. However, it is all-or\u00adnothing: \nit can only be used to prove parametricity for terms that ex\u00adpect to be treated parametrically and also \nbehave parametrically cf. the two dual aspects of parametricity described in Section 5. We might also \nbe interested in proving representation independence for terms that do not behave parametrically themselves \n(in either the syntactic or semantic sense considered in the previous section). One situation where this \nmight show up is if we want to show rep\u00adresentation independence for generic ADTs that (like the ones \nin Section 7) return different results for different instantiations of their type arguments, but where \n(unlike in Section 7) the difference is not only syntactic but also semantic. Here is a somewhat contrived \nexample to illustrate the point. Consider the following two polymorphic functions of type .a.ta: ta := \n.\u00df. (a . \u00df) \u00d7 (\u00df . a) f1 := .a. cast tint ta (pack (int, (.x:int.x+1,.x:int.x)) as tint) (pack (a, (.x:a.x, \n.x:a.x)) as ta) f2 := .a. cast tint ta (pack (int, (.x:int.x, .x:int.x+1)) as tint) (pack (a, (.x:a.x, \n.x:a.x)) as ta) These functions take a type argument a and return a simple ADT \u00df. Values of type a can \nbe injected into \u00df, and projected out again. However, both functions specialize the behavior of this \nADT for type int for integers, injecting n and projecting again will give back not n,but rather n +1. \nThis is true for both functions, but they implement it in a different way. We want to prove that both \nimplementations are equivalent under wrapping using a form of parametric reasoning. However, we cannot \ndo that using the parametric relation from the previ\u00adous section since the functions do not behave parametrically \n(i.e., they return observably different packages for different instantia\u00adtions of their type argument), \nthey will not be related in E. . To support that kind of reasoning, we need a more re.ned treat\u00adment \nof parametricity in the logical relation. The idea is to separate the two aforementioned aspects of parametricity. \nConsequently, we are going to have a pair of separate relations, E+ and E-.The former enforces parametric \nusage, the latter parametric behavior. Figure 5 gives the de.nition of these relations. We call them \npolarized, because they are mutually dependent and the polarity (+ or -) switches for contravariant positions, \ni.e., for function arguments and for universal quanti.ers. Intuitively, in these places, term and context \nswitch roles. Except for the consistent addition of polarities, the de.nition of the polarized relations \nagain only represents a minor modi.cation of the original one.7 We merely re.ne the de.nition of the \ntype re\u00ad 7 In fact, all four relations can easily be formulated in a single uni.ed de.nition indexed \nby . ::= E |.| + |-. We refrained from doing so here for the sake of clarity; see the expanded version \nof this paper for details [16]. . eG E+ Wr + Wr- E. . eFeG . E Wr - Wr+ E- Figure 6. Relating the Relations \nlation T [[O]]w to distinguish polarity: in the positive case it behaves parametrically (i.e., allowing \nan arbitrary relation) and in the nega\u00adtive case non-parametrically (i.e., demanding r be the logical \nrela\u00adtion at some type). Thus, existential types behave parametrically in E+ but non-parametrically in \nE-, and vice versa for universals. 8.1 Key Properties The way in which polarities switch in the polarized \nrelations mir\u00adrors what is going on in the de.nition of wrapping. That of course is no accident, and \nwe can show the following theorem that relates the polarized relations with the non-parametric and parametric \nones through uses of wrapping: Theorem 8.1 (Wrapping for ;\u00b1) 1. If e1 ;+ e2 : t ,then Wr+ t (e2): t . \nt (e1) ; Wr+ 2. If e1 ; e2 : t ,then t (e1) ;- t (e2): t . Wr- Wr- 3. If e1 ;+ e2 : t ,then Wr- t (e1) \n;. Wrt -(e2): t . 4. If e1 ;. e2 : t ,then Wr+ t (e2): t .  t (e1) ;- Wr+ Moreover, we can show that \nthe inverse directions of these impli\u00adcations require no wrapping at all: Theorem 8.2 (Inclusion for \n;\u00b1) 1. If e1 ; e2 : t or e1 ;. e2 : t ,then e1 ;+ e2 : t . 2. If e1 ;- e2 : t ,then e1 ; e2 : t and \ne1 ;. e2 : t .  This theorem can equivalently be stated as: E- . E . E+ and E- . E. . E+ . Note that \nTheorem 6.1 follows directly from Theorems 8.1 and 8.2. Similarly, the following property follows from \nTheorem 8.2 together with Theorem 4.1: Corollary 8.3 (Fundamental Property for ;+) If .; G e : t ,then \n.; G e ;+ e : t . Interestingly, compatibility does not hold for ;\u00b1 (consider the polarities in the rule \nfor application), which has the consequence that we cannot show Corollary 8.3 directly. For a similar \nreason, we cannot show any such property for ;- at all. Figure 6 depicts all of the above properties \nin a single diagram. Unlabeled arrows denote inclusion, while labeled arrows denote the wrapping that \nmaps one relation to the other. The .-operators show the fundamental properties for the respective relations, \ni.e., which class of terms are included (G terms or F terms).  8.2 Example Getting back to our motivating \nexample from the beginning of the section, it is essentially straightforward to prove that f1 ;+ f2 : \n.a.ta. The proof proceeds as usual, except that we have to make a case distinction when we want to show \nthat the function bodies are related in E+ . At that point, we are given a triple (t1,t2,r) . T -[[O]]w. \n If t1 = int, then we know from the de.nition of T - that t2 = int, too. We hence know that both sides \nwill evaluate to the specialized version of the ADT. Since we are in E+, we get to pick some (t1' ,t2' \n,r ' ) . T +[[O]]w as the interpretation of \u00df,where the ' '' choice of r is up to us. The natural choice \nis to use t1 = t2 = int with the relation r ' =(int, int, {(k, w, n +1,n) | n . Z}).The rest of the proof \nis then straightforward. If t1 = int we similarly know that t2 = int from the de.nition of T -. Hence, \nboth sides use the default implementations, which are trivially related in E+, thanks to Corollary 8.3. \nFinally, applying the Wrapping Theorem 8.1, we can conclude that Wr+(f1) ; Wr+(f2): .a.ta, and hence \nby Soundness, Wr+(f1) Wr+(f2): .a.ta. Note how we relied on the knowledge that t1 and t2 can only be \nint at the same time. This holds for types related in T - but not in T + or T . . If we had tried to \ndo this proof in E., the types t1 and t2 would have been related by T . only, which would give us too \nlittle information to proceed with the necessary case distinction.  9. Recursive Types We now add iso-recursive \ntypes to G and call the result G\u00b5: Types t ::= ... | \u00b5a.t Values v ::= ... | roll v as t Terms e ::= \n... | roll e as t | unroll e The extensions to the semantics are standard and therefore omitted they \ndo not affect the type store. Also, the de.nition of contextual equivalence does not change (except there \nare more contexts). 9.1 Extending the Logical Relations The step-indexing that we used in de.ning our \nlogical relations makes it very easy to adapt them to G\u00b5. There are two natural ways in which we could \nde.ne the value relation at a recursive type: def 1.Vn.[[\u00b5a.t ]]. = {(k, w, roll v1, roll v2) . Atomn[... \n] |(k, w, v1,v2) . rVk.[[t ]]., a.Vk.[[\u00b5a.t ]].} def 2.Vn.[[\u00b5a.t ]]. = {(k, w, roll v1, roll v2) . Atomn[... \n] | (k, w, v1,v2) . rVk.[[t [\u00b5a.t /a]]].}  For . .{E, .} i.e., for the non-parametric and parametric \nforms of the logical relation the above two formulations are equivalent due to the validity of a standard \nsubstitution property. Unfortu\u00adnately, though, we do not have such a property for the polarized relation. \nIn fact, for . .{+, -}, the .rst de.nition wrongly records a .xed polarity for a. It is thus crucial \nthat we choose the second one; only then do all key properties continue to hold in G\u00b5 . 9.2 Extending \nthe Wrapping How can we upgrade the wrapping to account for recursive types? Given an argument of type \n\u00b5a.t , the basic idea is to .rst unfold it to type t [\u00b5a.t /a], then wrap it at that type, and .nally \nfold the result back to type \u00b5a.t . Of course, since t [\u00b5a.t /a] may be larger than \u00b5a.t , a direct implementation \nof this idea will not result in a well-founded de.nition. The solution is to use a .xed-point (de.nable \nin terms of re\u00adcursive types, of course), which gives us a handle on the wrapping function we are in \nthe middle of de.ning. Figure 7 shows the new de.nition. We .rst index the wrapping by an environment \n. that maps recursive type variables a to wrappings for those variables. Roughly, the wrapping at type \n\u00b5a.t under environment . is a re\u00adcursive function F , de.ned in terms of the wrapping at type t un\u00adder \nenvironment ., a . F . Since the bound variable of a recursive type may occur in positions of different \npolarity, we actually need two mutually recursive functions and then select the right one de\u00adpending \non the polarity. The cognoscenti will recognize this as a def Wr\u00b1 a;.(v)= v (if a/. dom(.)) def .\u00b1 Wr\u00b1 \n= (if a . dom(.)) a;.(v)(a) v def Wr\u00b1 = letrec f+ = t;./ (unroll x)[\u00b5a.t /a]) \u00b5a.t;.(v) .x. roll (Wr+ \nand f- = t;./ (unroll x)[\u00b5a.t /a]) .x. roll (Wr- in f\u00b1 v (where . ' = ., a.(f+,f-)) (other cases as before \nexcept for the consistent addition of .) Figure 7. Wrapping for G\u00b5 polarized variant of the so-called \nsyntactic projection function as\u00adsociated with a recursive type [8]. Note that the environment only plays \na role for recursive types, and that for any t that does not involve recursive types, Wr\u00b1 t;\u00d8 is the \nsame as our old wrapping Wr\u00b1 t from Section 5. Taking Wr\u00b1 t to be shorthand for Wr\u00b1 t;\u00d8, all our old \nwrapping theorems for G continue to hold for G\u00b5. Full proofs of these theorems are given in the expanded \nversion of this paper [16].   10. Towards Full Abstraction The de.nition of the parametric relation \nE. (including the exten\u00adsion for recursive types) is largely very similar to that of a typical step-indexed \nlogical relation EF\u00b5 for F\u00b5 , i.e., System F extended with pairs, existentials and iso-recursive types \n[3]. The main dif\u00adference is the presence of worlds, but they are not actually used in a particularly \ninteresting way in E.. Therefore, one might expect that any two F\u00b5 terms related by the hypothetical \nEF\u00b5 would also be related by E. and vice versa. However, this is not obvious: G\u00b5 is more expressive than \nF\u00b5 , i.e., terms in the parametric relation can contain non-trivial uses of casts (e.g., the generic \nADT for pairs from Section 7), and there is no evident way to back-translate these terms into F\u00b5, as \nwould be needed for function arguments. That invalidates a proof approach like the one taken by Ahmed \nand Blume [5]. Ultimately, the property we would like to be able to show is that the embedding of F\u00b5 \ninto G\u00b5 by positive wrapping is fully abstract: e1 t (e1) Wr+ F\u00b5 e2 : t .. Wr+ t (e2): t This equivalence \nis even stronger than the one about logical relat\u00adedness in EF\u00b5 and E., because ; is only sound w.r.t. \ncontextual approximation, not complete. Since F\u00b5 is a fragment of G\u00b5,and F\u00b5 contexts cannot observe any \ndifference between an F\u00b5 term and its wrapping, the direction from right to left, called equivalence \nre.ection, is not hard to show. Theorem 10.1 (Equivalence Re.ection) If .; G F\u00b5 e1 : t and .; G F\u00b5 e2 \n: t and .;G Wr+ t (e1) t (e2): t ,then .; G e1 e2 : t . Wr+ F\u00b5 Unfortunately, it is not known to us \nwhether the other direction, equivalence preservation, holds as well. We conjecture that it does, but \nare not aware of any suitable technique to prove it. Note that while equivalence re.ection also holds \nfor F and G i.e., in the absence of recursive types equivalence preservation does not, because non-termination \nis encodable in G but not in F.  11. Related Work Type Generation vs. Other Forms of Data Abstraction. \nTradi\u00adtionally, authors have distinguished between two complementary forms of data abstraction, sometimes \ndubbed the static and the dy\u00adnamic approach [13]. The former is tied to the type system and relies on \nparametricity (especially for existential types) to hide an ADT s representation from clients [15]. The \nlatter approach is typi\u00adcally employed in untyped languages, which do not have the ability to place static \nrestrictions on clients. Consequently, data hiding has to be enforced on the level of individual values. \nFor that, languages provide means for generating unique names and using them as keys for dynamically \nsealing values. A value sealed by a given key can only be inspected by principals that have access to \nthe key [27]. Dynamic type generation as we employ it [21, 29, 22] can be seen as a middle ground, because \nit bears resemblance to both ap\u00adproaches. As in the dynamic approach, we cannot rely on para\u00admetricity \nand instead generate dynamic names to protect abstrac\u00adtions. However, these are type-level names, not \nterm-level names, and they only seal type information. In particular, individual val\u00adues of abstract \ntype are still directly represented by the underlying representation type, so that crossing abstraction \nboundaries has no runtime cost. In that sense, we are closer to the static approach. Another approach \nto reconciling type abstraction and type anal\u00adysis has been proposed by Washburn and Weirich [31]. They \nin\u00adtroduce a type system that tracks information .ow for terms and types-as-data. By distinguishing security \nlevels, the type system can statically prevent unauthorized inspection of types by clients. Multi-Language \nInteroperation. The closest work to ours is that of Matthews and Ahmed [13]. They describe a pair of \nmutually re\u00adcursive logical relations that deal with the interoperation between a typed language ( ML \n) and an untyped language ( Scheme ). Un\u00adlike in G, parametric behavior is hard-wired into their ML side: \npolymorphic instantiation unconditionally performs a form of dy\u00adnamic sealing to protect against the \nnon-parametric Scheme side. (In contrast, we treat new as its own language construct, orthog\u00adonal to \nuniversal types.) Dynamic sealing can then be de.ned in terms of the primitive coercion operators that \nbridge between the ML and Scheme sides. These coercions are similar to our (meta\u00adlevel) wrapping operators, \nbut ours perform type-level sealing, not term-level sealing. The logical relations in Matthews and Ahmed \ns formalism are somewhat reminiscent of E. and E, although theirs are distinct logical relations for \ntwo languages, while ours are for a single language and differ only in the de.nition of T [[O]]w.In order \nto prove the fundamental property for their relations, they prove a bridge lemma transferring relatedness \nin one language to the other via coercions. This is analogous to our Wrapping Theorem for ;., but the \nlatter is an independent theorem, not a lemma. Also, they do not propose anything like our polarized \nlogical relations. A key technical difference is that their formulation of the logical relations does \nnot use possible worlds to capture the type store (the latter is left implicit in their operational semantics). \nUnfortunately, this resulted in a signi.cant .aw in their paper [4]. They have since reportedly .xed \nthe problem independently of our work using a technique similar to ours, but they have yet to write up \nthe details. Proof Methods. Logical relations in various forms are routinely used to reason about program \nequivalence and type abstraction [20, 14, 17, 3]. In particular, Ahmed, Dreyer and Rossberg recently \nap\u00adplied step-indexed logical relations with possible worlds to reason about type abstraction for a language \nwith higher-order state [6]. State in G is comparatively benign, but still requires a circular def\u00adinition \nof worlds that we stratify using steps. Pitts and Stark used logical relations to reason about program \nequivalence in a language with (term-level) name generation [18] and subsequently generalized their technique \nto handle mutable ref\u00aderences [19]. Sumii and Pierce use them for proving secrecy re\u00adsults for a language \nwith dynamic sealing [26], where generated names are used as keys. Their logical relation uses a form \nof possi\u00adble world very similar to ours, but tying relational interpretations to term-level private keys \ninstead of to type names. Their worlds come into play in the interpretation of the type bits of encrypted \ndata, whereas in our setup the worlds are important in the interpretation of universal and existential \ntypes. In another line of work, Sumii and Pierce have used bisimulations to establish abstraction results \nfor both untyped and polymorphic languages [27, 28]. However, none of the languages they investigate \nmixes the two paradigms. Grossman, Morrisett and Zdancewic have proposed the use of abstraction brackets \nfor syntactically tracing abstraction bound\u00adaries [10] during program execution. However, this is a compar\u00adatively \nweak method that does not seem to help in proving para\u00admetricity or representation independence results. \n 12. Conclusion and Future Work In traditional static languages, type abstraction is established by \nparametric polymorphism. This approach no longer works when dynamic typing features like casts, typecase, \nor re.ection are added to the mix. Dynamic type generation addresses this problem. In this paper, we \nhave shown that dynamic type generation suc\u00adceeds in recovering type abstraction. More speci.cally: (1) \nwe pre\u00adsented a step-indexed logical relation for reasoning about program equivalence in a non-parametric \nlanguage with cast and type gen\u00aderation; (2) we showed that parametricity can be re-established sys\u00adtematically \nusing a simple type-directed wrapping, which then can be reasoned about using a parametric variant of \nthe logical relation; (3) we showed that parametricity can be re.ned into parametric be\u00adhavior and parametric \nusage and gave a polarized logical relation that distinguishes these dual notions, thereby handling more \nsubtle examples. The concept of a polarized logical relation seems novel, and it remains to be seen what \nelse it might be useful for. Inter\u00adestingly, all our logical relations can be de.ned as a single family \ndiffering only in the interpretation T of types-as-data. An open question is whether the wrapping, when \nseen as an embedding of F\u00b5 into G\u00b5, is fully abstract. We conjecture that it is, but we were only able \nto show equivalence re.ection, not equiva\u00adlence preservation. Proving full abstraction remains an interesting \nchallenge for future work. On the practical side, we would like to scale our logical rela\u00adtion to handle \na more realistic language like ML. Unfortunately, wrapping cannot easily be extended to a type of mutable \nrefer\u00adences. However, we believe that our approach still scales to a large class of languages, so long \nas we instrument it with a distinc\u00adtion between module and core levels. Speci.cally, note that wrap\u00adping \nonly does something interesting for universal and existential types, and is the identity (modulo .-expansion) \notherwise. Thus, for a language like Standard ML, which does not support .rst\u00adclass polymorphism or Alice \nML, which supports modules-as\u00ad.rst-class-values, but not existentials wrapping could be con.ned to the \nmodule level (as part of the implementation of opaque sig\u00adnature ascription). For core-level types it \ncould just be the identity. This is a real advantage of type generation over dynamic sealing since, for \nthe latter, the need to seal/unseal individual values of ab\u00adstract type precludes any attempt to con.ne \nwrapping to modules.  References [1] Mart\u00b4in Abadi, Luca Cardelli, Benjamin Pierce, and Didier R\u00b4emy. \nDynamic typing in polymorphic languages. JFP, 5(1):111 130, 1995. [2] Amal Ahmed. Semantics of Types \nfor Mutable State. PhD thesis, Princeton University, 2004. [3] Amal Ahmed. Step-indexed syntactic logical \nrelations for recursive and quanti.ed types. In ESOP, 2006. [4] Amal Ahmed. Personal communication, 2009. \n[5] Amal Ahmed and Matthias Blume. Typed closure conversion preserves observational equivalence. In ICFP, \n2008. [6] Amal Ahmed, Derek Dreyer, and Andreas Rossberg. State-dependent representation independence. \nIn POPL, 2009. [7] Andrew W. Appel and David McAllester. An indexed model of recursive types for foundational \nproof-carrying code. TOPLAS, 23(5):657 683, 2001. [8] Karl Crary and Robert Harper. Syntactic logical \nrelations for polymorphic and recursive types. In Computation, Meaning and Logic: Articles dedicated \nto Gordon Plotkin. 2007. [9] Jean-Yves Girard. Interpr\u00b4\u00b4 etation fonctionelle et elimination des coupures \nde l arithm\u00b4etique d ordre sup\u00b4erieur. PhD thesis, Universit\u00b4e Paris VII, 1972. [10] Dan Grossman, Greg \nMorrisett, and Steve Zdancewic. Syntactic type abstraction. TOPLAS, 22(6):1037 1080, 2000. [11] Robert \nHarper and John C. Mitchell. Parametricity and variants of Girard s J operator. Information Processing \nLetters, 1999. [12] Robert Harper and Greg Morrisett. Compiling polymorphism using intensional type analysis. \nIn POPL, 1995. [13] Jacob Matthews and Amal Ahmed. Parametric polymorphism through run-time sealing, \nor, theorems for low, low prices! In ESOP, 2008. [14] John C. Mitchell. Representation independence and \ndata abstraction. In POPL, 1986. [15] John C. Mitchell and Gordon D. Plotkin. Abstract types have existential \ntype. TOPLAS, 10(3):470 502, 1988. [16] Georg Neis. Non-parametric parametricity. Master s thesis, Universit\u00a8at \ndes Saarlandes, 2009. [17] Andrew Pitts. Typed operational reasoning. In Benjamin C. Pierce, editor, \nAdvanced Topics in Types and Programming Languages, chapter 7. MIT Press, 2005. [18] Andrew Pitts and \nIan Stark. Observable properties of higher order functions that dynamically create local names, or: What \ns new? In MFCS, volume 711 of LNCS, 1993. [19] Andrew Pitts and Ian Stark. Operational reasoning for \nfunctions with local state. In HOOTS, 1998. [20] John C. Reynolds. Types, abstraction and parametric \npolymorphism. In Information Processing, 1983. [21] Andreas Rossberg. Generativity and dynamic opacity \nfor abstract types. In PPDP, 2003. [22] Andreas Rossberg. Dynamic translucency with abstraction kinds \nand higher-order coercions. In MFPS, 2008. [23] Andreas Rossberg, Didier Le Botlan, Guido Tack, Thorsten \nBrunk\u00adlaus, and Gert Smolka. Alice ML through the looking glass. In TFP, volume 5, 2004. [24] Peter Sewell. \nModules, abstract types, and distributed versioning. In POPL, 2001. [25] Peter Sewell, James Leifer, \nKeith Wansbrough, Francesco Zappa Nardelli, Mair Allen-Williams, Pierre Habouzit, and Viktor Vafeiadis. \nAcute: High-level programming language design for distributed computation. JFP, 17(4&#38;5):547 612, \n2007. [26] Eijiro Sumii and Benjamin C. Pierce. Logical relations for encryption. JCS, 11(4):521 554, \n2003. [27] Eijiro Sumii and Benjamin C. Pierce. A bisimulation for dynamic sealing. TCS, 375(1 3):161 \n192, 2007. [28] Eijiro Sumii and Benjamin C. Pierce. A bisimulation for type abstraction and recursion. \nJACM, 54(5):1 43, 2007. [29] Dimitrios Vytiniotis, Geoffrey Washburn, and Stephanie Weirich. An open \nand shut typecase. In TLDI, 2005. [30] Philip Wadler. Theorems for free! In FPCA, 1989. [31] Geoffrey \nWashburn and Stephanie Weirich. Generalizing parametric\u00adity using information .ow. In LICS, 2005. [32] \nStephanie Weirich. Type-safe cast. JFP, 14(6):681 695, 2004.  \n\t\t\t", "proc_id": "1596550", "abstract": "<p>Type abstraction and intensional type analysis are features seemingly at odds-type abstraction is intended to guarantee parametricity and representation independence, while type analysis is inherently non-parametric. Recently, however, several researchers have proposed and implemented \"dynamic type generation\" as a way to reconcile these features. The idea is that, when one defines an abstract type, one should also be able to generate at run time a fresh type name, which may be used as a dynamic representative of the abstract type for purposes of type analysis. The question remains: in a language with non-parametric polymorphism, does dynamic type generation provide us with the same kinds of abstraction guarantees that we get from parametric polymorphism?</p> <p>Our goal is to provide a rigorous answer to this question. We define a step-indexed Kripke logical relation for a language with both non-parametric polymorphism (in the form of type-safe cast) and dynamic type generation. Our logical relation enables us to establish parametricity and representation independence results, even in a non-parametric setting, by attaching arbitrary relational interpretations to dynamically-generated type names. In addition, we explore how programs that are provably equivalent in a more traditional parametric logical relation may be \"wrapped\" systematically to produce terms that are related by our non-parametric relation, and vice versa. This leads us to a novel \"polarized\" form of our logical relation, which enables us to distinguish formally between positive and negative notions of parametricity.</p>", "authors": [{"name": "Georg Neis", "author_profile_id": "81442619526", "affiliation": "MPI-SWS, Saarbr&#252;cken, Germany", "person_id": "P1614007", "email_address": "", "orcid_id": ""}, {"name": "Derek Dreyer", "author_profile_id": "81100381796", "affiliation": "MPI-SWS, Saarbr&#252;cken, Germany", "person_id": "P1614008", "email_address": "", "orcid_id": ""}, {"name": "Andreas Rossberg", "author_profile_id": "81100550426", "affiliation": "MPI-SWS, Saarbr&#252;cken, Germany", "person_id": "P1614009", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1596550.1596572", "year": "2009", "article_id": "1596572", "conference": "ICFP", "title": "Non-parametric parametricity", "url": "http://dl.acm.org/citation.cfm?id=1596572"}