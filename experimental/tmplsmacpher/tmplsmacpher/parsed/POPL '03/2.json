{"article_publication_date": "01-15-2003", "fulltext": "\n Environment Classi.ers Extended Abstract Walid Taha* Michael Florentin Nielsen Department of Computer \nScience Department of Computer Science Rice University IT University of Copenhagen taha@cs.rice.edu erik@it-c.dk \nABSTRACT This paper proposes and develops the basic theory for a new approach to typing multi-stage languages \nbased a notion of environment classi.ers. This approach involves explicit but lightweight tracking at \ntype-checking time of the origina\u00adtion environment for future-stage computations. Classi.ca\u00adtion is \nless restrictive than the previously proposed notions of closedness, and allows for both a more expressive \ntyping of the run construct and for a unifying account of typed multi-stage programming. The proposed \napproach to typing requires making cross\u00adstage persistence (CSP) explicit in the language. At the same \ntime, it o.ers concrete new insights into the notion of levels and in turn into CSP itself. Type safety \nis established in the simply-typed setting. As a .rst step toward introduc\u00ading classi.ers to the Hindley-Milner \nsetting, we propose an approach to integrating the two, and prove type preservation in this setting. \n Categories and Subject Descriptors D.3 [Software]: Programming Languages Formal De.ni\u00adtions and Theory, \nLanguage Constructs and Features; F.3 [Theory of Computation]: Logics and Meanings of Pro\u00adgrams Semantics \nof Programming Languages, Studies of Program Constructs General Terms Design, Reliability, Languages, \nTheory, Veri.cation.  Keywords Multi-stage programming, type systems, type safety, linear temporal logic, \nmodal logic. * Supported by NSF ITR-0113569. This work was done at Yale University. Work done while visiting \nYale University Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. POPL 03, January 15 17, 2003, New Orleans, Louisiana, USA. Copyright 2003 ACM 1-58113-628-5/03/0001 \n...$5.00. 1. INTRODUCTION At the untyped level, multi-stage languages are a unify\u00ading framework for the \nessence of partial evaluation [32, 11, 10, 34, 25, 52], program generation [36, 59, 3], runtime code \ngeneration [2, 17, 18, 28, 29], and generative macro-systems [21]. But until now, this was not the case \nfor the typed set\u00adting, as there have been di.erent, orthogonal proposals for typing multi-stage languages. \nIn fact, ever since the incep\u00adtion versions of these formalisms, including those of Nielson and Nielson \n[44, 46, 47, 51, 48, 45, 49, 50] on one hand, and Gomard and Jones [35, 26, 27, 34] on the other, the \nquestion of whether these languages should support either closed code or open code has been unresolved. \nCode is open if fully evaluated runtime value of this type can contain free variables. Code is closed \notherwise. Note that traditionally in both call-by-name and call-by-value languages, values are closed. \nLanguages supporting closed code naturally allow for safe runtime execution of this code. Languages supporting \nopen code naturally admit a form of symbolic computation. Combining the two notions has been the goal \nof numerous previous works. 1.1 Multi-stage Basics Multi-stage programming languages provide a small \nset of constructs for the construction, combination, and execution of delayed computations. Programming \nin a multi-stage lan\u00adguage such as MetaOCaml [39] can be illustrated with the following classic example1: \nlet evenn=(nmod2)=0 let squarex=x *x let rec power n x = (* int -> .<int>. -> .<int>. *) if n=0 then \n.<1>. else if even n then .<square .~(power (n/2) x)>. else .<.~x * .~(power (n-1) x)>. let power72 = \n(* int -> int *) run .<fun x -> .~(power 72 .<x>.)>. Ignoring the type constructor .<t>. and the three \nstaging annotations brackets .<e>., escapes .~e and run, the above code is a standard de.nition of a \nfunction that computes x n , which is then used to de.ne the specialized function x 72 . Without the \nstaging, however, the last step just pro\u00adduces a closure that invokes the power function every time 1Dots \nare used around brackets and escapes to disambiguate the syntax in the implementation. They are dropped \nwhen we talk about underlying calculus rather than the imple\u00admentation. it gets a value for x. To understand \nthe e.ect of the staging annotations, it is best to start from the end of the exam\u00adple. Whereas a term \nfunx -> e x is a value, an anno\u00adtated term .<fun x -> .~(e .<x>.)>. is not. Brackets in\u00addicate that we \nare constructing a future stage computation, and an escape indicates that we must perform an immedi\u00adate \ncomputation while building the bracketed computation. The application e .<x>. has to be performed even \nthough x is still an uninstantiated symbol. In the power example, power 72 .<x>. is performed immediately, \nonce and for all, and not repeated every time we have a new value for x. In the body of the de.nition \nof the power function, the re\u00adcursive applications of power are also escaped to make sure that they are \nperformed immediately. The run on the last line invokes the compiler on the generated code fragment, \nand incorporates the result of compilation into the runtime system. 1.2 When is Code Executable? A basic \nchallenge in designing typed multi-stage languages is ensuring that future stage code can be executed \nin a type\u00adsafe manner. In particular, not all code arising during a multi-stage computation is executable. \nIn the expression such as .<fun x -> .~(e .<x>.)>. the sub-expression e should not attempt to execute \nthe term .<x>.. For example, e should not be run. 1.2.1 State of the Art Moggi pointed out that early \napproaches to multi-level languages seem to treat code either as always being open or always being closed \n[40]. These two approaches are best exempli.ed by two type systems motivated by di.erent sys\u00adtems from \nmodal logic: .0 Motivated by the 0 modality from linear time tem\u00adporal logic, this system provides a \nsound framework for typing constructs that have the same operational semantics as the bracket and escape \nconstructs men\u00adtioned above [14]. As illustrated above, the brackets and escapes can be used in to annotate \n.-abstractions so as to force symbolic computations. This type sys\u00adtem supports generating code, but \ndoes not provide a construct corresponding to run. .D Motivated by the D modality from modal logic, this \nsystem provides constructs for constructing and run\u00adning code [15]. Until now, the exact correspondence \nbetween these constructs and brackets, escape, and run where not established. It is known, however, that \nall values generated during the evaluation of terms in this language are closed. Thus, the connection \nbe\u00adtween this system and symbolic evaluation is less ob\u00advious than for the previous system. There have \nbeen two distinct e.orts to combine the features of these two type systems: .R The essence of this approach \nis to count the num\u00adber of run s surrounding the term .<x>. [42]. Un\u00adfortunately, this means that run \ncannot be lambda\u00adabstracted. This is a serious expressivity limitation, because we cannot type let x \n= .<1+1>. in run x. when let is seen as syntactic sugar for a beta-redex. The run counting approach propagates \nthe informa\u00adtion about the presence of run and its impact on the value it takes as its argument by change \nonly the locally perceived typing of the environment. .BN This approach uses combinations of the temporal \n0 modality and the modal logic D modality to allow both open code and a means to express that a cer\u00adtain \ncode fragment is closed [42, 5, 8, 6, 7]. Using a type constructor for closed values it is possible to \nassign fun x -> run x the type [.<A>.]->[A], which means that run takes a closed code fragment and re\u00adturns \na closed value. But not all open code is unsafe to run. Additionally, this approach is acceptable for \nexecuting single-stage programs (which do not contain future stage variables), but it is unnatural in \nthe multi\u00adstage setting, and treats open code as a second class citizen. Thus, while the .rst approach \nallows us to run open code but not abstract run, the second allows us to do the latter but not the former. \nThis paper presents a system that provides both features.  1.3 Implicit Goals The explicit goal of the \npresent work is to address the above limitations. This can be viewed as a quest for more accurate types \nfor multi-stage program. But an implicit goal is to improve (or at least maintain) the particularly light\u00adweight \nnature of previous proposals for syntax, types, and equational theory for multi-stage languages. This \ngoal ex\u00adplains why explicit representations of future stage code are not solutions that we will consider \n(c.f [60]). For example, representing future stage computations by strings or even datatypes does not \nprovide the programmer with any help in avoiding the inadvertent construction of syntactically in\u00adcorrect \nor ill-typed programs. A better alternative would be the use of dependently typed inductive datatypes \n(as is done for object languages programs in the recent work on Meta-D [54]). This option, however, is \nsubstantially more verbose than using a quotation mechanism like brackets and escape. In addition, it \nforces the user to move to the dependently typed setting and to give up Hindley-Milner type inference. \nMore importantly, it does not provide any immediate sup\u00adport for avoiding inadvertent variable capture \nproblems, un\u00adless we also have access to FreshML types [55, 43], which have not yet been studied in the \ndependent type setting. Finally, all such representations are intensional. While this allows the programmer \nto express program transformations, it reduces the equational theory on future stage computa\u00adtions to \nsyntactic equivalence [62, 67]. This reduction is not always desirable. 1.4 Approach We have considered \nre.ecting the free variables of a term explicitly in the types of open fragments, and borrowing ideas \nfrom linking calculi [9], implicit parameters [38], mod\u00adule systems [57], explicit substitutions [4], \nand program anal\u00adysis [19]. The general .avor of such an approach can be illustrated by the following \nhypothetical judgment: G f(x) : (t){x:t} Closer inspection of this approach suggests that it may not \nbe as appealing as it seems at .rst. A practical programming concern with this approach is that types \nbecome very big, as the size of a type would be linear in the number of variables used in the term. Furthermore, \nto deal with a-renaming correctly, variable uses should not be directly mentioned in types. Thus, the \nterm language needs to be extended to handle this problem. In addition, a notion of polymorphism would \nbe essential. For example, the term fun f -> .<fun x -> .~(f .<x>.)>. is a two-level .-expansion [13], \nand is used quite often in multi-stage programming. It would be highly desirable to have a single type \nfor this function, so that it would not be de.ned afresh every time we need it. This function would need \nto take a value of type (t1)e .(t2)e and to return a value of type (t1 . t2)e for any environment e. \nA reason\u00adable approach to dealing with this problem is to introduce . polymorphism [66], but we would \nneed to use negative side conditions in the type system to stop the type {x : t}from going outside the \nscope of this term. Negative side conditions complicate uni.cation, and in turn inference. It is also \nunclear how this approach could be generalized to the multi-level setting. 1.5 Organization and Contributions \nSection 2 explains the need for explicit cross-stage per\u00adsistence (CSP), which is necessary for the development \nof the notion of environment classi.ers. The key insight be\u00adhind the work presented in this paper is \nthat a carefully crafted notion of polymorphic variables that are never con\u00adcretely instantiated is both \npossible and su.cient for provid\u00ading an expressive type system for multi-stage programming and at the \nsame time avoiding the typing problems associ\u00adated with introducing signatures into types. These variables \nwill be called environment classi.ers, and are introduced in Section 3. The soundness of Hindley-Milner \npolymorphism in the presence of statically typed brackets and escapes does not seem to have been addressed \nin the literature (c.f. [7]). Dy\u00adnamically typed versions of brackets, escape, and run have been used \nto introduce a notion of staged type inference [58]. Type safety has been demonstrated in this setting, \nbut it was also found that care must be taken in de.ning the semantics of such language. Section 4 demonstrates \nthe soundness of typed multi-stage programming in the presence of Hindley-Milner polymorphism. Section \n5 shows how a type system based on this approach provides a unifying account of typed multi-stage program\u00adming. \nThis is demonstrated by presenting two embeddings of both .0 and .D into the new typed language. The \nnew type system has no more constructs than the previous sys\u00adtems.  2. CROSS-STAGE PERSISTENCE The proposed \napproach requires the use of an explicit treatment of cross-stage persistence. At the same time, it sheds \na new light on this basic notion. Cross-stage persis\u00adtence (CSP) [64] is the ability to use a value available \nin the current stage in a future stage. If a user de.ned the list reverse function, there is usually \nno reason to prohibit them from using reverse inside future-stage code. This fea\u00adture is used to allow \nthe usage of both * and square inside brackets in the power example. The treatment of this feature has \nsubtle interactions with the run typing problem. Type theoretically, CSP can be introduced in two distinct \nways: Implicit and explicit. With the implicit approach (used in the power example above), CSP is only \nadmitted on variables through a rule such as: G(x)= tm m = n n G f x : t which compares the bracket-depth \nat which a variable is bound (m) and makes sure that it is no greater than that at which the variable \nis used (n). It must then be separately demonstrated the there is an analogous notion of implicit CSP \n(called promotion ) that holds on terms [63, 42]. The implicit approach, therefore, allows less structure \nthan what we show here to be possible and is essential for executing open terms. In particular, the implicit \napproach (and devel\u00adopments based on it [7]) considers a term to be cross-stage persistent if and only \nif its variables can be made cross-stage persistent. With the explicit approach, there is a dedicated \nconstruct with the following typing: n G f e : t n+1 G f %e : t which essentially allows us to pretend \nthat we are surrounded by one less bracket when we are typing the term e. To illus\u00adtrate the kind of \nstructure missing in the implicit presenta\u00adtion, consider the term: .<fun x -> .~(run .<.<x>.>.)>. which \nevaluates under the standard untyped big-step seman\u00adtics for multi-stage languages (c.f. [62]) to .<fun \nx -> x>.. In the initial term, x is surrounded by only one bracket when it is bound, and two brackets \nwhen it is used. Implicit CSP means that we can consider the argument to run to be a term .<.<...>.>. \ncontaining a cross-stage persistent constant x. This is in fact not a reasonable interpretation, because \nthe inner brackets will eventually be canceled by the escape in the original term. Thus, the variable \nx is surrounded imme\u00addiately by the right brackets, and should not be treated as a cross-stage persistent \nconstant. An acceptable inter\u00adpretation, however, is that the argument to run is a term .<...>. containing \na cross-stage persistent constant .<x>.. The intuition is that inside the escape .<x>. is a legitimate \n(typable) value, and we wish to use it inside another pair of brackets. Equationally, these observations \ncan be inter\u00adpreted as: (%(e)) . ((%e)) for any notion of typed equality that we would be inter\u00adested \nin. This distinction cannot be made if CSP is implicit. Exactly why explicit CSP is useful for preserving \nthe seman\u00adtics of classi.cation becomes clear in details of the demotion lemma. This lemma is the cornerstone \nin the argument for why running a given code fragment preserves typing.  3. ENVIRONMENT CLASSIFIERS \nWe introduce the idea of environment classi.ers by means of a multi-stage calculus called .a . After \npresenting its type system and semantics, we demonstrate its basic properties, such as type safety. We \nalso relate the various features of .a to previous proposals. a, \u00df . W A . W * ::= t . T ::= G . G ::= \ne . E ::= Environment Classi.ers Named Levels Types Environments Expressions Types, Environments, and \nNamed Levels: a . dom(G) GV (t) . dom(G) f G a .. G f G G f t G f ai f G G f ai G f a G f t f [] f G, \na f G, x : ta1,...,an G a1,...,an f Terms: G A f G(x) = tA G A f G, x : tA 1 A f e : t2 G A f e1 : t1 \n. t2 G A f e2 : t1 G A G,a f e : t A G f (a)e :(a)t A AA f i : int G f x : t G f .x.e : t1 . t2 A A,a \nA G f e :(a)t G f \u00df G f e : t G f a G f e : (t)a A A A,a G f e[\u00df]: t[a := \u00df]G f(e)a : (t)a G f e : t \nA G f e1 e2 : t2 A A,a G f e : t G f A,a G f %e : t A G f e :(a)(t)a A G f run e :(a)t Figure 1: Syntax \nand Static Semantics of Simply Typed .a Notation 1. We de.ne sets of terms in three ways: ::= is followed \nby a set of productions that can be used to derive a term in the set being de.ned. + :: = is followed \nby a set of productions that are allowed in addition to ones previously introduced. = is standard set \nequality. 3.1 Basic De.nitions Figure 1 presents the static semantics of .a . The .rst syn\u00adtactic category \nintroduced is environment classi.ers, ranged over by a and \u00df, drawn from a countably in.nite set of names \nW . Environment classi.ers allow us to name parts of the environment in which a term is typed. Named \nlevels are sequences of environment classi.ers. They will be used to keep track of which environments \nare being used as we build nested code. Named levels are thus an enrichment of the traditional notion \nof levels in multi-stage languages [14, 64, 62], the latter being a natural number which keeps track \nonly of the depth of nesting. The .rst two type constructs are standard: Integers int, and functions \nt1 . t2. Next is a-closed types (a)t, read a-closed t .2 Note that the occurrence of a here is in a binding \nposition, and it can occur free in t. Last is the type for code fragments (t)a, read code t in a . Here \na is in a usage occurrence. Compared to previous work, the (t)a type is a re.nement of .0 s 0t [14] (the \nlatter also being essentially the open code type used in previous proposals for type systems for MetaML \n[63, 42, 60].) The a in this type is an abstract reference to the environment in which this code fragment \nwas created. Environments are ordered sequences that can carry either a variable declaration x : tA indicating \nthat x is a variable 2This quanti.er is similar to universal quanti.cation in sys\u00adtem F. The main di.erence \nis that it is restricted to a par\u00adticular kind, and never instantiated to a concrete value. As the full \nimplications of these restriction are not yet known, we have avoided using the notation . for this quanti.er. \nof type t that has been introduced at named level A, or an environment declaration a. Additional well-formedness \nrequirements are given, but .rst we introduce expressions. The .rst four kinds of expressions are standard: \nintegers i, variables x drawn from some countably in.nite set of names, lambda abstractions .x.e, and \napplications e1 e2. The next two constructs are a introduction (a)e, read a-closed e , and instantiation \ne[a], read e of a . They allow the pro\u00adgrammer to declare the start of new, named environments and the \nembedding of an a-closed value into a weaker con\u00adtext. The next three constructs are essentially the \nstandard constructs of MetaML [64]: Brackets (e)a , escape e, and run run e. Having an a annotation, \nhowever, is not stan\u00addard. While this annotation has no e.ect on the operational semantics, it is a declaration \nof the environment this code fragment should be associated with. We take the last a in the environment \nas the default, and require the user to pro\u00advide one explicitly only when it is di.erent from the default. \nNext is an explicit construct for CSP %e. In MetaML, CSP is limited (by typing rules) to variables [64]. \nIn the current proposal, however, CSP will be allowed on terms. As mentioned before, environments are \nordered. There are additional requirements on environments. A type is well\u00adformed under a given environment, \nwritten G f t, when all the free environment classi.ers in t, written GV (t), are contained in the declarations \nin G. An environment is well\u00adformed, written f G, when all free variables in a type and the named level \nfor a binding are introduced in the environment to its left.  3.2 Type System The .rst four rules are \nmostly standard. As in type sys\u00adtems for multi-level languages, the named level A is prop\u00adagated without \nalteration to the sub-terms in these con\u00adstructs. In the variable rule, the named level associated with \nthe variable being typed is checked and is required to be the same as the current level. In the lambda \nabstraction rule, the named level of the abstraction is recorded in the environment. a1,...,an int | \nt1 . t2 | (a)t |(t)a [] | G,x : tA | G,a i | x | .x.e | e1 e2 | (a)e | e[a] |(e)a | e | run e | %e Values \nn, m . N e n . En n+ En+ e . v 0 . V 0 V n+ v n+ . Demotion (and Auxiliary De.nitions): ::= 0 | n+ ::= \ni | x | .x.en | e n e n |(e n+)a | run e n | (a)e n | e n[a] + ::= e n | %e n (Note de.nition of En \nabove also). ::= i | .x.e0 |(v 1)a n | %v n := e .x.(e .X,x:A i.X = i, x.X = x, .x.e .X = A ),e1 e2 \n.X = e1 .X AAA AA (e)a .X =(e .X , e.X (e.X run e .X = run (e .X A ), A ), %ae = %e, %a,A,a' e = (%a,A(e)a'), \n%(G,a) = A A,a )a A,a = A A e2 .X (a)e.X = (a)(e.X e[a] .X = e .X [a], A , AA ), AA %e.X = %(e .X %e \n.xi:Ai = e[xi := %Ai xi] a,A,a' a,A), a %G, %(G,x : tA) = (%G,x := %Ax) |(G,a)|=|G|, |(G,x : t)|= (|G|,x \n: A), (G,a)A = GA, a, (G,x : tA' )A = (G,x : tA,A' ) Notions of Reduction: (.x.e0) v 0 -.\u00df e 0[x := v \n0] (v 1)a -.E v 1 ((a)v 0)[\u00df] -.W v 0[a := \u00df] run (a)(v 1)a -.R (a)(v 1 .a[] ) Figure 2: Strati.ed Expressions, \nValues, Demotion, and Reductions for .a The next two rules are for a introduction and instanti\u00adation. \nFor a (new) a to be introduced around a type, the term of that type must be typable under the current \nenviron\u00adment extended with a at the top. The type system and the well-formedness conditions ensure that \na was not introduced previously by the environment G. The well-formedness con\u00additions on environments \ntherefore ensure that a can only occur in environments used higher up in the type derivation tree, and \nto the right of this a. Proof-theoretically, these environments are the ones that a classi.es. The rule \nfor a instantiation allows replacing a in any a-closed type by any classi.er \u00df in the current environment. \nThe rule for brackets is almost the same as in .0 and in previous type systems for MetaML. First, for \nevery code type a classi.er must be assigned. This classi.er must al\u00adready be declared in the environment. \nSecond, while typing the body of the code fragment inside brackets, the named level of the typing judgment \nis extended by the name of the current classi.er. This information will be used in both the variable \nrule and the escape rule to make sure that only variables and code fragments of the same classi.cation \nare ever incorporated into this code fragment. The escape rule at level A, a only allows the incorporation \nof code fragments of type (t)a . The rule for CSP itself is standard: It allows us to in\u00adcorporate a \nterm e at a higher level. However, we will see in the rest of the section that using named levels has \na signi.cant e.ect on the role of CSP. Finally, the rule for run allows us to execute a code fragment \nof type (t)a only if it is a-closed.  3.3 Reduction Semantics Figure 2 presents the de.nition of the \nreduction semantics for .a, and some auxiliary de.nitions needed for character\u00adizing the behavior of \ntypings under reductions. Levels are natural numbers. Strati.ed expressions are used to de.ne values. \nThere are two essential properties that strati.cation is used to capture: First, escapes can only oc\u00adcur \nat levels n+ in expressions and n + + in values. Second, % can only occur at level n+ in both expressions \nand values. Demotion is an operation needed to convert a value (v 1) into an expression e 0 . This is \nneeded to carry out the run reduction, which takes a term free of level 1 escapes and runs it. In multi-stage \ncalculi where there is no explicit CSP, this operation is syntactic identity (c.f.[42]). The de.nition \nhere is similar to previous de.nitions used in calculi with explicit CSP (c.f. [7]), except that previous \nwork de.nes demotion in the case of % at the lowest level (0) as: %e .0 = e[xi := %xi] {xi}= FV (e) The \nde.nition presented here: 1. uses the named level of the argument rather the level of the result (in \nthis case a rather than 0). The names of the levels will be used to generate the coercions dis\u00adcussed \nnext. 2. does not perform the substitution for all the free vari\u00adables, but rather, for a speci.c set \nof variables that come from the set X. As we will see in this section, the variables that are unaltered \nare essentially the ones that come from outside the current environment clas\u00adsi.er a . Given the typing \nof run, this also means that they are variables outside the scope of the current in\u00advocation of the run \nconstruct. This is essential for correctly dealing with the execution of open code, and will allow us \nto ensure that a term such as:  .<fun x -> .~((run (a) .<%.<x>.>.)[b])>. reduces to .<fun x -> x>. 3. \ndoes not substitute with % but rather %A, which in\u00advolves an additional set of escapes and brackets around \nits argument to make sure that the bracket that is be\u00ading removed corresponds to the right environment. \nAs we will explain at the end of this section, %s and matching brackets and escapes are computationally \nir\u00adrelevant, so this coercion is used only to capture the information needed to make these operations \ntype the\u00adoretically correct. ni . i n+0 x . x .x.e . .x.e n+nn+1ei . ei+2 e1 . e2 e1 . e2 n n+n+1 . \n(a)e2 e1 e2 . e3 e4 (a)e1 e1[a] . e2[a] 0e1 . (a)(e2)a n+00e1 . e2 e1 .(e2)a e2 .a [] . e3  n++10 \ne1 . e2 e1 . e2 run e1 . (a)e3 Error-generating extension (used for proving type safety): 00= (e3)a \ne1 . e3 e3 .= .x.e e1 . e2 e3 . 001 x . err e1 e2 . err e1 . err Error-propagating extension: 0e1 .(e2)a \n00n+ e2 . err e2 . err ei . err 00n+e1 e2 . err run e1 . err e1 e2 . err 0 e1 . .x.e n+0 e1 . e2 e[x \n:= e2] . e3 n+0 .x.e1 . .x.e2 e1 e2 . e3 0n+e1 . (a)e2 e1 . e2 0 n e1[\u00df] . e1[a := \u00df] (e1)a .(e2)a \nn+ne1 . e2 e1 . e2 n+n+1 run e1 . run e2 %e1 . %e2 0e3 = (e4)a 0 e1 . e3 .e1 . e2 e2 .= (a)e3 00run \ne1 . err e1[\u00df] . err n+ e1 . err e = run e1 or .x.e1 n+ e . err n+n+ e1 . err e1 . err n . err n++ \n(e1)a e1 . err Figure 3: Big-step Operational Semantics for .a Essentially all previous formulations \nof the demotion oper\u00adation, whether explicit or implicit, traverse the whole term that is being demoted, \nonly counting brackets, and not act\u00ading in a special way when a CSP point is encountered. This is a weakness, \nas brackets contained in a cross-stage persis\u00adtent constant really bear no connection to the brackets \nthat are currently being eliminated. The de.nition of demotion proposed here re.ects this action in the \ncase of %. There are four basic notions of reduction for .a . The \u00df reduction is almost standard. The \nrestriction to strati.ed expressions and values of level 0 means that we cannot apply this reduction \nwhen any of the sub-terms involved contains an escape that is not matched by a surrounding bracket [62]. \nThe W reduction is similar to \u00df, but is for the classi\u00ad.er constructs. The escape reduction says when \nan escape can cancel a bracket. Similarly, the run reduction says when a run can cancel a bracket. Like \nprevious de.nitions, the value restriction is essential for demotion to work: we can only eliminate a \npair of brackets when all their corre\u00adsponding escapes have been eliminated. Demotion is then used to \nmake sure that the level 1 value is converted to an appropriate level 0 expression. This only involves \nreorganiz\u00ading %s, which we will argue are computationally irrelevant at the end of this section. The \nde.nitions of %G, |G|, and GA will be used in charac\u00adterizing the typing behavior of demotion. 3.3.1 \nSubject Reduction A desirable property of a typing is to withstand reduction: Theorem 2 (Subject Reduction). \nLet . range over A {\u00df, E, R, W }. Whenever G f e1 : t and e1 -.. e2, then A G f e2 : t. Establishing \nthis theorem requires proving the key property for each of the reductions. For the \u00df reduction, the main \nlemma needed is one that shows that typing is well-behaved under substitution: A1 Lemma 1 (Substitution). \n1. G f e1 : t1 and G,x : A2 A2A1 t1 , G' f e2 : t2 implies G, G' f e2[x := e1]: t2. A 2. \u00df . dom(G) and \nG f e : t implies A[a:=\u00df] G[a := \u00df] f e[a := \u00df]: t[a := \u00df]. The reduction for escape is straightforward. \nThe reduction for run requires characterizing the manner in which demo\u00adtion a.ects typing. In the special \ncase, demotion can be characterized as follows: A,a Lemma 2 (Special Demotion). G,a f v 1 : t A implies \nG,a f v 1 .a: t This lemma gives us a way to take a value v . V 1 typable at level A, a, and under an \nenvironment where the classi.er a is at the top, and produce a term that has the same type, but at level \nA. This term will be computed by demoting v. Having such a well-de.ned set of conditions for shifting \na term down a level is necessary for safe execution of code. Both to carry out the proof for the above \nlemma, and to show that reduction at any level preserves typing, we need a more general (albeit less \nreadable) result: A,a,A ' |a,A ' | Lemma 3 (Demotion). G, a, G'A,a f v: t A,A ' |a,A ' | .|G 'a| implies \nG, a, G'A f v a,A ' : t A ' , G '' Lemma 4. G, a, G 'A,a f e : t implies A ' , G '' G, a, G 'A f e[%G \n'a]: t Where GA and %G are de.ned in Figure 2. Note that the latter converts an environment into a substitution. \nThe ap\u00adplication of this substitution to a term e is denoted by e[%G].  3.4 Type Safety Figure 3 presents \nthe big-step semantics for .a . With the exception of classi.er abstraction and instantiation and run, \nthe rest of the rules are standard for multi-stage languages (see for examples [60, 42, 62, 7]). The \nrule for run is almost standard, except for the fact that it requires its argument to evaluate to a classi.er \nabstraction rather than just a code fragment. Furthermore, it propagates this classi.er abstrac\u00adtion \nin the return value. n Lemma 5. 1. e . e ' then it is the case that e ' . V n . AA |A| 2. G+ f e : t \nand e . e ' implies that G+ f e ' : t. If evaluation goes under some lambda abstraction, it must be \nat some named level a, A, and not simply a named level. To express this fact in typing judgments, we \nintroduce the following auxiliary de.nition: G+ G+ . ::= [] | G+ ,x : ta,A | G+,a To establish type \nsafety, we must extend our big-step se\u00admantics with rules for generating and propagating errors. Errors \nare represented by extending all expression families by a unique term err. The main problematic case \nfor multi\u00adstage languages is that evaluation at level 0 should not en\u00adcounter a free variable. Thus, \nit is necessary to include this as an error-generating case in the augmented semantics. A |A| Theorem \n3. G+ f e : t and e . e ' then e .= err. The proof uses the lemmas introduced for subject reduction, \nin addition to properties of the big-step semantics. 3.5 Erasure Semantics As the reference point we \nuse the untyped big-step and reduction semantics for MetaML [62]. The additional con\u00adstructs introduced \nin this paper are designed to be compu\u00adtationally irrelevant. The sense in which they are irrelevant \nis captured by an erasure function from .a to .U (of [62]), and is de.ned as follows: | i| = i, | x| \n= x, | .x.e| = .x.| e| , | e1 e2| =| e1| | e2| , | (a)e| =| e| , | e[a]| =| e| , ||(e)a| = (||e||), | \ne| = | e| , | run e| = run | e| , | %e| = ((.x.(x)) | e| ) A basic equational theory can be built from \nthe re.exive, symmetric transitive closure of the notions of reductions pre\u00adsented above. We expect to \nbe able to justify the soundness of such an equational theory by lifting the equational theory for the \nunderlying untyped calculus .U using the erasure function above. We use a standard de.nition of observa\u00adtional \nequivalence but which is indexed by levels. We leave this development to future work.  4. POLYMORPHISM \nBecause of the practical utility of automatic type infer\u00adence, an important extension of the .a calculus \nis the one to Hindley-Milner polymorphism [12, 31]. In this setting, poly\u00admorphism is implicit, but is \nlimited to de.nitions introduced by a let-construct. Thus, the term let id = .x.x in e will bind the \npolymorphic identity function with type .t.t . t in the body e whereas (.id.e)(.x.x) will bind a monomor\u00adphic \nidentity of type (say) int . int in e. As (a)t is already a form of quanti.cation at the level of types \n(albeit over classi.ers rather than general types) it can interfere with polymorphism. The central problem \nhas to do with the a-substitution on types, which is needed in the rule for a-instantiation: A G f e \n:(a)t G f \u00df A,a G f e[\u00df]: t[a := \u00df] Substitution is problematic when t is (or contains) a type variable: \nThis type variable may at a later point become in\u00adstantiated with a type containing a. As a concrete \nexample consider the following legal typings of the term .x.x[\u00df]: \u00df f .x.x[\u00df] : ((a)int) . int \u00df f .x.x[\u00df] \n: ((a)(int)a) .(int)\u00df What could be a type that generalizes both of these types? If this problem is \nnot addressed, then the system lacks prin\u00adcipal types. A reasonable candidate is .t.((a)t ) . t . But \nthis type cannot be instantiated to the type in the second derivation above, as it would require the \nvalue of t to depend on the locally-bound name a. One solution to dealing with this problem would be \nto use function types, thus allowing type variables to depend on the context in which they are used. \nThey would allow us to unify the two above mentioned types into one type: .t.((a)t [a]) . t[\u00df] But with \ngeneral type functions it is likely that type infer\u00adence would become problematic. Thus we consider here \na less standard approach that allows us to prove type safety for an expressive language, and which seems \nlikely to enjoy reasonable inference properties. This approach explicitly de\u00adlays the a-substitutions \nin type schemes until type variables are instantiated, at which point the a-substitutions can be resumed. \nThe type scheme for the term in the derivations above would be .t.((a)t) . (t (a := \u00df)). Instantiating \n(int)a for t would give the type ((a)(int)a) .(int\u00df ). The type schemes need to remember any a-substitution \nso we extend the syntax for types with delayed a-substitutions. As a-substitutions can be pushed all \nthe way down to type variables, we will only annotate type variables: t (.) where . = {ai := a ' i} is \na set of a-substitutions. The syntax and type system for polymorphic .a are pre\u00adsented in Figure 4. The \nmain change to the simply typed version of the type system is that environments carry type schemes instead \nof types. In the variable rule type schemes G are instantiated according to the s . t relation. The \nab\u00adstraction rule binds the variable to a monomorphic type: .().t1 which has only t1 as an instance. \nOn the other hand the rule for let generalizes the type t1 over all free type vari\u00adables in t1 that are \nnot in G. Type Schemes Types with Variables a-Substitution Expressions Auxiliary de.nitions: G f t ' \nG .t.t . t{t := t '} Type System: A A G G f G(x)= sA s . t G f G A f i : int G A f x : t G, a A f e \n: t G A f (a)e : (a)t G A f e : (t)a G A,a f e : t G A f e : t G A,a f G A,a f %e : t i  Evaluation. \nThe same rules as for \u00b7.\u00b7 in Figure 3: 0 e2[x := e1] . e4 0 let x = e1 in e2 . e4 s . S ::= T t + t \n. ::= . . R ::= Et + e . ::= {t1,...,tn} = FTV(t) \\ FTV(G) close(t, G) =.t1,...,tn..t AA A A G,x : .().t1 \nf e : t2 G f e1 : t1 . t2 G f e2 : t1 A A G f .x.e : t1 . t2 G f e1e2 : t2 .t1,...,tn.t t (.) a1 := \u00df1,...,an \n:= \u00dfn let x = e1 in e2 A G f e :(a)t G f \u00df A G f e[\u00df]: t{a := \u00df} A A,a G f e : t G f a A G f(e)a : \n(t)a A A G G f e :(a)(t)a G f e1 : t1 G,x : close(t1, G)A f e2 : t2 A A f run e :(a)t G f let x = e1 \nin e2 : t2 n+ n+ e1 . e3 e2 . e4 n+ let x = e1 in e2 . let x = e3 in e4 Figure 4: Polymorphic .a The \nmost subtle change to the a-substitution is in the a-instantiation rule. It is replaced with a non-standard \nsub\u00adstitution operation t{a := \u00df} that delays the substitution on the type-variables in t. This in turn \nimplies that type instantiation should resume the delayed substitutions. This G is done by de.ning the \n. relation using a non-standard type substitution t{t := t ' }. Examples of the two non-standard substitutions \nare: ((t )a . t ){a := \u00df} = (t(a := \u00df))\u00df . t(a := \u00df)  ((t (a := \u00df))\u00df . t (a := \u00df)){t := (int)a} = ((int)\u00df \n)\u00df .(int)\u00df  ((t )a . t ){t := (int)a} = ((int)a)a .(int)a  (((int)a)a .(int)a){a := \u00df} = ((int)\u00df)\u00df \n.(int)\u00df Notice the di.erence between the meta-level a-substitution t{.} and the object-level a-substitution \nt (.). The primary property that demonstrates that this ap\u00adproach is sensible is this: Lemma 6. t{.}{t \n:= t '} = t{t := t '}{.} This lemma states that the a-substitution and type sub\u00adstitution commute, and \nin e.ect delayed a-substitutions are correctly applied when type instantiation is performed. This lemma \ntogether with a host of less interesting lemmas about the di.erent kinds of substitutions can be used \nto prove sub\u00adstitution, demotion, and subject reduction properties: A Lemma 7 (Substitution). G1,x : \n.t.t1, G2 f e2 : t2 and G1 f e1 : t1 and {t }. FTV(G1)= \u00d8 implies A G1, G2 f e2[x := e1]: t2 For subject \nreduction, we extend our reductions with one rule: 00 00 let x = v in e -.L e [x := v ] Theorem 4 (Subject \nReduction). Let . range over A {\u00df, E, R, W, L}. Whenever G f e1 : t and e1 -.. e2, then A G f e2 : \nt. 5. EMBEDDINGS OF OTHER SYSTEMS We present embeddings for the two main calculi repre\u00adsenting the two \nmain approaches to modeling staging into .a . 5.1 Linear Temporal Logic The embedding of .0 [14] into \n.a is direct. We assume that the base type b is int. We pick an arbitrary classi.er a, and de.ne the \nembedding as follows: [ int] = int, [ 0t] =([ t] )a , [ t1 . t2] = [ t1] . [ t2] [ n] = an , [ xi : \nt ni i ] = xi :[ ti] [ ni] [ x] = x, [ .x.e] = .x.[ e] , [ e1 e2] = [ e1] [ e2] [ next e] =([ e] )a \n, [ prev e] = [ e]  This embedding preserves typability in the following sense: Lemma 9. G0; ... ;Gn \nf e : t implies Lemma 8. G f0 e : t implies (a, [[G]]) f [ e] : [ t]  Note that only a single classi.er \nis needed to embed a .0 program. The translation [ e] maps syntactic constructs to syntac\u00adtic constructs \nthat have the same big-step semantics, so it is obvious that there is a lock-step simulation. However, \nit should be noted that notions of equivalence can di.er be\u00adtween .0 and .a: In the absence of a run \nconstruct, there is no context that can distinguish between next .x.x and next .x.., but in the target \nlanguage these terms can be run (and then applied), and we can observe a di.erence. 5.2 Modal Logic \nThe primary strength of calculi working only with closed code is that there is no danger of running open \ncode simply because there is none. Closed code calculi have traditionally been based on the modal logic \nS4 with the logic operator Dt denoting code of type t. The .a calculus cannot express that a code fragment \nis closed only that it is closed with respect to an environment a via the type (a)(t)a . It is a natural \nquestion whether this notion of closedness is enough to allow for an embedding of S4 into .a . We consider \nan S4 calculus [16, Section 4.3] that is fairly close to the Kripke-model of S4 in that it has a stack \nof envi\u00adronments representing knowledge in di.erent sets of worlds. Furthermore the use of the box and \nunbox constructs is sim\u00adilar to that of the (-) and - construct, so an easy em\u00adbedding seems feasible. \nThe embedding on types should map Dt to (a)(t ' )a to piggy-back on .a s notion of a-closed code: [ Dt] \n= (a)([ t] )a , [ t1 . t2] = [ t1] . [ t2] , [ int] = int The translation of the term box e becomes \n(a)(e ' )a , but when it comes to translating unboxn e, an a ' is needed to instantiate (a)(t)a . The \nrole of unboxn e (for n> 0) is to splice in e into the surrounding code, and as all code is closed, it \nalso means linking e s environment (albeit empty) to the environment of the surrounding code construction. \nTherefore the embedding on S4-terms must maintain a list of as coming from surrounding a-quanti.cations: \n[ box e] A = (a)([ e] A,a)a [ unbox0 e] A,a = (run [ e] A,a)[a] n [ unboxn+1 e] A,a,an+1,...,a1 = %( \n([[e] A,a[a])) [ i] A = i, [ x] A = x [ .x.e] A = .x.[ e] A, [ e1e2] A = [ e1] A[ e2] A The translation \nof unboxn depends on the subscript n. When n> 0 the term unboxn corresponds to -, but if n> 1 it also \ndigs into the environment stack to get code from previous stages, thus the need for the sequence of %s. \nOn the other hand unbox0 corresponds to running the code, and is translated into the .a version of run. \nNote however, that run leaves an unneeded a-quanti.er, which has to be removed. The embedding of S4 environments \n(not stacks) is: [ x1 : t1,...,xn : tn] = x1 :[ t1] ,...,xn :[ tn]  Then the embedding of S4 into .a \ncan be formulated as: a1,...,an a0, [[G0] ,...,an, [[Gn] f [ e] a0,...,an :[ t] This formulation of \nS4 was initially not presented with a direct operational semantics, but rather, via an interpreta\u00adtion \ninto another explicit calculus [15]. A reduction se\u00admantics is presented in more recent work [16]. We \nexpect that the reduction semantics can be used to derive a deter\u00administic operational semantics, which \ncan then be used for formally establishing a simulation result.  6. RELATED WORK Multi-stage programming \nis a paradigm that evolved out of experience with partial evaluation [20, 35, 30, 34, 10] and runtime \ncode generation systems [2, 28, 17, 18, 29]. Re\u00adsearch in this area aims at providing the programmer \nwith constructs that can be used to attain the performance ben\u00ade.ts of the above mentioned techniques. \nThese languages are also a natural outgrowth of two-level [48, 27] and multi\u00adlevel languages [23, 24, \n25, 15, 14], which where initially conceived to study the semantic foundations and e.cient implementation \ntechniques for both partial evaluation and runtime code generation. Recently, multi-stage languages have \nalso been used to develop type systems for expressive, generative macros [21]. The use of an abstract \nquanti.er was inspired by the re\u00adcent work on FreshML [55, 43], parametricity [56, 65, 1], the typing \nof runST [37, 58, 41], and work on integrating system F with Hindley-Milner type systems [22]. A formal \naccount of these connections remains an interesting open question. Nanevski s recent work on the combination \nof .D with type-safe intensional analysis is a promising way to give .D a semantics closer to the calculi \ndiscussed in this paper [43]. It seems possible, however, that this may be primarily due to the power \nof intensional analysis (which should, in princi\u00adple, allow the programmer to express arbitrary transforma\u00adtions). \nAs with the explicit environment typing approach discussed in the introduction, types in Nanevski s system \ncould in principle grow linearly in the number of free vari\u00adables. There is currently no notion of polymorphism \nto deal with this issue in the context of Nanevski s system. Classi\u00ad.ers could be a useful approach to \nproviding a such a mech\u00adanism. Early attempts at developing a reduction semantics for untyped multi-stage \nlanguages involved a construct that can be interpreted as an explicit CSP constant (the bubble of .T \nof [60]), and included a number of reductions that prop\u00adagate this construct outward in terms. The non-local \nna\u00adture of the demotion function presented here suggests that, while such notions of reduction could \nstill be useful in im\u00adplementations based on untyped calculi, they maybe incom\u00adpatible with the type \ntheory of multi-stage languages. Michael Florentin Nielsen has been investigating exten\u00adsions of Davies \nand Pfenning s modal calculus that provide a more direct remedy to the symbolic evaluation question. \nThe full presentation is beyond the scope of this paper, but current results indicate that .a provides \na lighter notation than this approach because it avoids the need to explicitly list the name and type \nof each variable potentially free in each code fragment. Another di.culty that .a seems to avoid is that \nthe open code type allows inserting code frag\u00adments made in one environment into other environments. \nThis implicit form of polymorphism must be made explicit in systems that Nielsen has developed based \non Davies and Pfenning s modal calculus, unless an additional notion of polymorphism (possibly similar \nto .-polymorphism) is in\u00adtroduced. Note that even in .a there are no polymorphic variables that deal \nwith environments: only environment classi.ers, which in a sense range over whole classes of envi\u00adronments, \nand which are never instantiated to concrete in\u00adstances. We continue to pursue a modal calculus, but \nwe ex\u00adpect that its primary applications will be in providing better understanding of the semantics and \npossibly implementation techniques, and not necessarily in actual programming. Davies3 considered a similar \napproach to the one pre\u00adsented here. His work is directly based on natural deduction rules for two logical \noperators: universal world quanti.ca\u00adtion and truth in a particular world . The resulting lan\u00adguage has \nsome di.erences from the one presented here, but the basic idea seems related. One notable di.erence \nfrom our language is that there was no separate run construct (because the typing rule for run involves \ntwo type construc\u00adtors, while each natural deduction rule should only refer to a single logical operator). \nInstead, there was a single (non\u00advariable) world called root , and the evaluation of code occurred whenever \nthis world was substituted for a world variable. 7. CONCLUSIONS AND FUTURE WORK We have presented a \nnew approach to typing multi-stage languages, and showed how it can be used to embed previ\u00adous approaches. \nWe also showed that the approach is still sound in the presence of Hindley-Milner polymorphism. Key insights \nthat come out of this work relate to subtleties in\u00advolved in specifying a demotion lemma for an expressive \ntype system. These details, in turn, provide concrete in\u00adsights into the interplay between CSP and the \npresence of the run construct in a multi-stage language. Currently, we have built only prototype implementations \nfor the system presented here. We expect that the notion of classi.ers will provide a natural mechanism \nto allow us to safely store and communicate open values, which to date has not been possible [8, 6, 7]. \nA crucial next step will be establishing the feasibility of type inference in the presence of environment \nclassi.ers. It will be interesting to see if the delayed substitutions approach developed in this paper \nis more helpful than using a more general approach, such as type functions. An overall goal will be to \nminimize type annotations, but not necessarily to eliminate the need for ex\u00adplicit world introduction \nand elimination in programs. Once these questions are resolved, a system based on .a will be introduced \ninto the MetaOCaml public release. Implement\u00ading the system in the context of a full-.edged language \nwill be essential for validating its practical expressivity. The development presented here has two features \npoten\u00adtially relevant to dependent types. First, because of the presence of classi.ers, we have treated \nenvironments as or\u00addered, and this was not problematic. Because ordered envi\u00adronments are a common feature \nof dependently typed lan\u00adguages, this may suggest that integration with dependently typed languages maybe \nbe seamless. Second, also because of classi.ers, we perform substitution on environments. This gives \nrise to a need for careful treatment of types in the Hindley-Milner polymorphic setting, but type safety \nstill 3Rowan Davies. Personal communication, Sept. 4th, 2002. goes through. It maybe that some features \nof the present system maybe useful in the question of integrating depen\u00addent types with Hindley-Milner \npolymorphism. Acknowledgments: Discussions with John Launchbury, Erik Meijer, Eugenio Moggi and Tim Sheard \ncontributed greatly to the genesis of the ideas developed here. Cris\u00adtiano Calcagno, Rowan Davies, and \nEugenio Moggi provided valuable feedback on a draft of this paper. The review\u00aders provided many comments \nthat improved the presenta\u00adtion greatly. Luke Hoban, Richard Nathan Linger and Emir Pa.sali\u00b4c eliminated \nmany typos in the .nal manuscript. 8. REFERENCES [1] Mart\u00b4in Abadi, Luca Cardelli, and Pierre-Louis \nCurien. Formal parametric polymorphism. In Conference Record of the Twentieth Annual ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, pages 157 170. ACM New York, NY, 1993. [2] Joel Auslander, \nMatthai Philipose, Craig Chambers, Susan J. Eggers, and Brian N. Bershad. Fast, e.ective dynamic compilation. \nIn Proceedings of the Conference on Programming Language Design and Implementation, pages 149 159, Philadelphia, \n1996. [3] Don Batory. Re.nements and product line architectures. In [61], pages 3 4, 2000. [4] Zine-El-Abidine \nBenaissa, Daniel Briaud, Pierre Lescanne, and Jocelyne Rouyer-Degli. .., a calculus of explicit substitutions \nwhich preserves strong normalisation. Journal of Functional Programming, 6(5):699 722, 1996. [5] Zine \nEl-Abidine Benaissa, Eugenio Moggi, Walid Taha, and Tim Sheard. Logical modalities and multi-stage programming. \nIn Federated Logic Conference (FLoC) Satellite Workshop on Intuitionistic Modal Logics and Applications \n(IMLA), 1999. [6] Cristiano Calcagno and Eugenio Moggi. Multi-stage imperative languages: A conservative \nextension result. In [61], pages 92 107, 2000. [7] Cristiano Calcagno, Eugenio Moggi, and Tim Sheard. \nClosed types for a safe imperative MetaML. Journal of Functional Programming, 2003. To appear. [8] Cristiano \nCalcagno, Eugenio Moggi, and Walid Taha. Closed types as a simple approach to safe imperative multi-stage \nprogramming. In the International Colloquium on Automata, Languages, and Programming (ICALP 00), volume \n1853 of Lecture Notes in Computer Science, pages 25 36, Geneva, 2000. Springer-Verlag. [9] Luca Cardelli. \nProgram fragments, linking, and modularization. In Conference Record of POPL 97: The 24th ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, pages 266 277, Paris, France, 15 17 January 1997. \n[10] Charles Consel and Olivier Danvy. Tutorial notes on partial evaluation. In ACM Symposium on Principles \nof Programming Languages, pages 493 501, 1993. [11] Charles Consel, Calton Pu, and Jonathan Walpole. \nIncremental partial evaluation: The key to high performance, modularity and portability in OPerating \nsystems. In Partial Evaluation and Semantics-Based Program Manipulation, Copenhagen, Denmark, June 1993, \npages 44 46. ACM, 1993. [12] Lu\u00b4is Damas and Robin Milner. Principal type schemes for functional languages. \nIn 9th ACM Symposium on Principles of Programming Languages. ACM, August 1982. [13] Olivier Danvy, Karoline \nMalmkjaer, and Jens Palsberg. Eta-expansion does the trick. Technical Report RS-95-41, University of \nAarhus, Aarhus, 1995. [14] Rowan Davies. A temporal-logic approach to binding-time analysis. In the Symposium \non Logic in Computer Science (LICS 96), pages 184 195, New Brunswick, 1996. IEEE Computer Society Press. \n[15] Rowan Davies and Frank Pfenning. A modal analysis of staged computation. In the Symposium on Principles \nof Programming Languages (POPL 96), pages 258 270, St. Petersburg Beach, 1996. [16] Rowan Davies and \nFrank Pfenning. A modal analysis of staged computation. Journal of the ACM, 48(3):555 604, 2001. [17] \nDawson R. Engler. VCODE : A retargetable, extensible, very fast dynamic code generation system. In Proceedings \nof the Conference on Programming Language Design and Implemantation, pages 160 170, New York, 1996. ACM. \n[18] Dawson R. Engler, Wilson C. Hsieh, and M. Frans Kaashoek. C: A language for high-level, e.cient, \nand machine-independent dynaic code generation. In In proceedings of the ACM Symposium on Principles \nof Programming Languages (POPL), pages 131 144, St. Petersburg Beach, 1996. [19] Adam Fischbach and John \nHannan. Speci.cation and correctness of lambda lifting. In [61], pages 108 128, 2000. [20] Yoshihiko \nFutamura. Partial evaluation of computation process an approach to a compiler-compiler. Systems, Computers \nand Control, 2(5):45 50, 1971. [Via [33]]. [21] Steven Ganz, Amr Sabry, and Walid Taha. Macros as multi-stage \ncomputations: Type-safe, generative, binding macros in MacroML. In the International Conference on Functional \nProgramming (ICFP 01), Florence, Italy, September 2001. ACM. [22] Garrigue and Remy. Semi-explicit .rst-class \npolymorphism for ML. INFCTRL: Information and Computation (formerly Information and Control), 155, 1999. \n[23] Robert Gl\u00a8uck and Jesper J\u00f8rgensen. E.cient multi-level generating extensions for program specialization. \nIn S. D. Swierstra and M. Hermenegildo, editors, Programming Languages: Implementations, Logics and Programs \n(PLILP 95), volume 982 of Lecture Notes in Computer Science, pages 259 278. Springer-Verlag, 1995. [24] \nRobert Gl\u00a8uck and Jesper J\u00f8rgensen. Fast binding-time analysis for multi-level specialization. In Dines \nBj\u00f8rner, Manfred Broy, and Igor V. Pottosin, editors, Perspectives of System Informatics, volume 1181 \nof Lecture Notes in Computer Science, pages 261 272. Springer-Verlag, 1996. [25] Robert Gl\u00a8uck and Jesper \nJ\u00f8rgensen. An automatic program generator for multi-level specialization. LISP and Symbolic Computation, \n10(2):113 158, 1997. [26] Carsten K. Gomard. Partial type inference for untyped functional programs. \nIn ACM Conference on Lisp and Functional Programming, 1990. [27] Carsten K. Gomard and Neil D. Jones. \nA partial evaluator for untyped lambda calculus. Journal of Functional Programming, 1(1):21 69, 1991. \n[28] Brian Grant, Markus Mock, Matthai Philipose, Craig Chambers, and Susan J. Eggers. Annotation-directed \nrun-time specialization in C. In Proceedings of the Symposium on Partial Evaluation and Semantics-Based \nProgram Manipulation, pages 163 178, Amsterdam, 1997. [29] Brian Grant, Matthai Philipose, Markus Mock, \nCraig Chambers, and Susan J. Eggers. An evaluation of staged run-time optimizations in DyC. In Proceedings \nof the Conference on Programming Language Design and Implementation, pages 293 304, 1999. [30] Torben \nAmtoft Hansen, Thomas Nikolajsen, Jesper Larsson Tr\u00a8a., and Neil D. Jones. Experiments with implementations \nof two theoretical constructions. In Lecture Notes in Computer Science 363, pages 119 133. Springer Verlag, \n1989. [31] J. Roger Hindley. Basic Simple Type Theory, volume 42 of Cambridge Tracts in Theoretical Computer \nScience. Cambridge University Press, Cambridge, 1997. [32] N. D. Jones, P. Sestoft, and H. S\u00f8ndergaard. \nAn experiment in partial evaluation: the generation of a compiler generator. In J.-P. Jouannaud, editor, \nRewriting Techniques and Applications, Dijon, France, volume 202 of Lecture Notes in Computer Science, \npages 124 140. Springer-Verlag, 1985. [33] Neil D. Jones. Mix ten years later. In Proceedings of the \nSymposium on Partial Evaluation and Semantics-Based Program Manipulation, pages 24 38. ACM, 1995. [34] \nNeil D. Jones, Carsten K. Gomard, and Peter Sestoft. Partial Evaluation and Automatic Program Generation. \nPrentice-Hall, 1993. [35] Neil D. Jones, Peter Sestoft, and Harald Sondergraard. An experiment in partial \nevaluation: The generation of a compiler generator. In Jean-Pierre Jouannaud, editor, Rewriting Techniques \nand Applications, volume 202 of Lecture Notes in Computer Science, pages 124 140. Springer-Verlag, 1985. \n[36] Sam Kamin, Miranda Callahan, and Lars Clausen. Lightweight and generative components II: Binary-level \ncomponents. In [61], pages 28 50, 2000. [37] John Launchbury and Simon L. Peyton Jones. State in haskell. \nLISP and Symbolic Computation, 8(4):293 342, 1995. pldi94. [38] Je.rey R. Lewis, John Launchbury, Erik \nMeijer, and Mark Shields. Implicit parameters: Dynamic scoping with static types. In In proceedings of \nthe ACM Symposium on Principles of Programming Languages (POPL), pages 108 118, N.Y., January 19 21 2000. \nACM. [39] MetaOCaml: A compiled, type-safe multi-stage programming language. Available online from http://cs-www.cs.yale.edu/homes/taha/MetaOCaml/, \n2001. [40] Eugenio Moggi. Functor categories and two-level languages. In Foundations of Software Science \nand Computation Structures (FoSSaCS), volume 1378 of Lecture Notes in Computer Science. Springer Verlag, \n1998. [41] Eugenio Moggi and Amr Sabry. Monadic encapsulation of e.ects. Journal of Functional Programming, \n2001. [42] Eugenio Moggi, Walid Taha, Zine El-Abidine Benaissa, and Tim Sheard. An idealized MetaML: \nSimpler, and more expressive. In European Symposium on Programming (ESOP), volume 1576 of Lecture Notes \nin Computer Science, pages 193 207. Springer-Verlag, 1999. [43] Aleksander Nanevski. Meta-programming \nwith names and necessity. In the International Conference on Functional Programming (ICFP 02), Pittsburgh, \nUSA, October 2002. ACM. [44] Flemming Nielson. Program transformations in a denotational setting. ACM \nTransactions on Programming Languages and Systems, 7(3):359 379, 1985. [45] Flemming Nielson. Correctness \nof code generation from a two-level meta-language. In B. Robinet and R. Wilhelm, editors, Proceedings \nof the European Symposium on Programming (ESOP 86), volume 213 of Lecture Notes in Computer Science, \npages 30 40, Saarbr\u00a8ucken, 1986. Springer. [46] Flemming Nielson. A formal type system for comparing \npartial evaluators. In D Bj\u00f8rner, Ershov, and Jones, editors, Proceedings of the workshop on Partial \nEvaluation and Mixed Computation (1987), pages 349 384. North-Holland, 1988. [47] Flemming Nielson and \nHanne Riis Nielson. Two-level semantics and code generation. Theoretical Computer Science, 56(1):59 133, \n1988. [48] Flemming Nielson and Hanne Riis Nielson. Two-Level Functional Languages. Number 34 in Cambridge \nTracts in Theoretical Computer Science. Cambridge University Press, Cambridge, 1992. [49] Flemming Nielson \nand Hanne Riis Nielson. Multi-level lambda-calculi: An algebraic description. In O. Danvy, R. Gl\u00a8uck, \nand P. Thiemann, editors, Partial Evaluation. Dagstuhl Castle, Germany, February 1996, volume 1110 of \nLecture Notes in Computer Science, pages 338 354. Berlin: Springer-Verlag, 1996.  [50] Flemming Nielson \nand Hanne Riis Nielson. A prescriptive framework for designing multi-level lambda-calculi. In Proceedings \nof the Symposium on Partial Evaluation and Semantics-Based Program Manipulation, pages 193 202, Amsterdam, \n1997. ACM. [51] Hanne Riis Nielson and Flemming Nielson. Automatic binding time analysis for a typed \n.-calculus. In ACM Symposium on Principles of Programming Languages, pages 98 106, 1988. [52] Fran\u00b8cois \nNo\u00a8el, Luke Hornof, Charles Consel, and Julia L. Lawall. Automatic, template-based run-time specialization: \nImplementation and experimental study. In Proceedings of the 1998 International Conference on Computer \nLanguages, pages 132 142. IEEE Computer Society Press, 1998. [53] Oregon Graduate Institute Technical \nReports. P.O. Box 91000, Portland, OR 97291-1000,USA. Available online from ftp://cse.ogi.edu/pub/tech-reports/README.html. \nLast viewed August 1999. [54] Emir Pa.sali\u00b4c, Walid Taha, and Tim Sheard. Tagless staged interpreters \nfor typed languages. In the International Conference on Functional Programming (ICFP 02), Pittsburgh, \nUSA, October 2002. ACM. [55] Andrew M. Pitts and Murdoch J. Gabbay. A metalanguage for programming with \nbound names modulo renaming. In Mathematics of Programme Construction, volume 1837 of Lecture Notes in \nComputer Science, pages 230 255. Springer-Verlag, 2000. [56] John C. Reynolds. Towards a theory of types \nstructure. In Proceedings Colloque sur la Programmation, pages 408 423. Springer-Verlag, New York, 1974. \n[57] Claudio Russo. Types for Modules. PhD thesis, Edinburgh University, 1998. [58] Mark Shields, Tim \nSheard, and Simon L. Peyton Jones. Dynamic typing through staged type inference. In In proceedings of \nthe ACM Symposium on Principles of Programming Languages (POPL), pages 289 302, 1998. [59] Yannis Smaragdakis \nand Don Batory. DiSTiL: A transformation library for data structures. In USENIX Conference on Domain-Speci.c \nLanguages, 1997. [60] Walid Taha. Multi-Stage Programming: Its Theory and Applications. PhD thesis, Oregon \nGraduate Institute of Science and Technology, 1999. Available from [53]. [61] Walid Taha, editor. Semantics, \nApplications, and Implementation of Program Generation, volume 1924 of Lecture Notes in Computer Science, \nMontr\u00b4eal, 2000. Springer-Verlag. [62] Walid Taha. A sound reduction semantics for untyped CBN multi-stage \ncomputation. Or, the theory of MetaML is non-trivial. In Proceedings of the Workshop on Partial Evaluation \nand Semantics-Based Program Maniplation (PEPM), Boston, 2000. ACM. [63] Walid Taha, Zine-El-Abidine Benaissa, \nand Tim Sheard. Multi-stage programming: Axiomatization and type-safety. In 25th International Colloquium \non Automata, Languages, and Programming (ICALP), volume 1443 of Lecture Notes in Computer Science, pages \n918 929, Aalborg, 1998. [64] Walid Taha and Tim Sheard. Multi-stage programming with explicit annotations. \nIn Proceedings of the Symposium on Partial Evaluation and Semantic-Based Program Manipulation (PEPM), \npages 203 217, Amsterdam, 1997. ACM. [65] Philip Wadler. Theorems for free! In Proc. of 4th Int. Conf. \non Funct. Prog. Languages and Computer Arch., FPCA 89, London, UK, 11 13 Sept. 1989, pages 347 359. ACM, \nNew York, 1989. [66] Mitchell Wand. Complete type inference for simple objects. In Second Annual IEEE \nSymp. on Logic in Computer Science, 1987. [67] Mitchell Wand. The theory of fexprs is trivial. Lisp and \nSymbolic Computation, 10:189 199, 1998.  \n\t\t\t", "proc_id": "604131", "abstract": "This paper proposes and develops the basic theory for a new approach to typing multi-stage languages based a notion of <i>environment classifiers</i>. This approach involves explicit but lightweight tracking -- at type-checking time -- of the origination environment for future-stage computations. Classification is less restrictive than the previously proposed notions of closedness, and allows for both a more expressive typing of the \"run\" construct and for a unifying account of typed multi-stage programmin.The proposed approach to typing requires making cross-stage persistence (CSP) explicit in the language. At the same time, it offers concrete new insights into the notion of levels and in turn into CSP itself. Type safety is established in the simply-typed setting. As a first step toward introducing classifiers to the Hindley-Milner setting, we propose an approach to integrating the two, and prove type preservation in this setting.", "authors": [{"name": "Walid Taha", "author_profile_id": "81100239752", "affiliation": "Rice University", "person_id": "PP39034018", "email_address": "", "orcid_id": ""}, {"name": "Michael Florentin Nielsen", "author_profile_id": "81100583440", "affiliation": "IT University of Copenhagen", "person_id": "P414185", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/604131.604134", "year": "2003", "article_id": "604134", "conference": "POPL", "title": "Environment classifiers", "url": "http://dl.acm.org/citation.cfm?id=604134"}