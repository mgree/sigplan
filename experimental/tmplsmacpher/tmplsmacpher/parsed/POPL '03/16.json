{"article_publication_date": "01-15-2003", "fulltext": "\n Static Prediction of Heap Space Usage for First-Order Functional Programs Martin Hofmann Steffen Jost \nLMU M\u00a8unchen, Institut f\u00a8ur Informatik Oettingenstra\u00dfe 67, 80538 M\u00a8unchen, Germany {} mhofmann, jost@informatik.uni-muenchen.de \n ABSTRACT We show how to e.ciently obtain linear a priori bounds on the heap space consumption of .rst-order \nfunctional pro\u00adgrams. The analysis takes space reuse by explicit deallocation into account and also furnishes \nan upper bound on the heap us\u00adage in the presence of garbage collection. It covers a wide variety of \nexamples including, for instance, the familiar sort\u00ading algorithms for lists, including quicksort. The \nanalysis relies on a type system with resource anno\u00adtations. Linear programming (LP) is used to automatically \ninfer derivations in this enriched type system. We also show that integral solutions to the linear pro\u00adgrams \nderived correspond to programs that can be evaluated without any operating system support for memory \nmanage\u00adment. The particular integer linear programs arising in this way are shown to be feasibly solvable \nunder mild assump\u00adtions. Categories and Subject Descriptors F.3.2 [Logics and Meanings of Programs]: \nSeman\u00adtics of Programming Languages Program analysis; D.1.1 [Programming Techniques]: Applicative (functional) \nprogramming; D.3.3 [Programming Languages]: Lan\u00adguage Constructs and Features Dynamic storage manage\u00adment \n General Terms Languages, Theory, Reliability, Performance.  Keywords Functional Programming, Resources, \nHeap, Garbage Collec\u00adtion, Program Analysis. Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. POPL 03, January 15 17, 2003, New Orleans, Louisiana, USA. Copyright \n2003 ACM 1-58113-628-5/03/0001 ...$5.00. 1. INTRODUCTION This paper addresses the following problem. \nGiven a func\u00adtional program containing a function f of type, say, L(B) . L(B), i.e., turning lists of \nbooleans into lists of booleans .nd a function . such that the the computation f(w)requires no more than \n.(w) additional heap cells. In this generality, the problem admits the following trivial solution: We \ncan instrument the code for f by a counter that is augmented each time we require allocation of a heap \ncell. The function . is then the function computed by this instrumented code followed by a projection \nthat discards the output and only keeps the value of the counter. Even if we require that . depend only \non the length of the input w and not w itself, we could for a given input length l run the instrumented \ncode on all boolean lists of length l and take the maximum. We still have a computable function that \nbounds the heap space required by the computation of f. This trivial solution su.ers from two .aws. First, \neval\u00aduating . requires as many resources as evaluating f itself. Moreover, even though the code for . \nconstitutes a math\u00adematical description of the bounding function .,it isina form that allows one to say \nvery little about its global be\u00adhaviour. Both .aws are unacceptable in a scenario where independently \nveri.able certi.cates on resource usage of mo\u00adbile code are desired [14, 1]. What one would rather expect \nin this situation is a state\u00adment of the form: running f on an input of length n will require no more \nthan b(n) heap cells where b(n)is an expres\u00adsion like 3n+7or 2.5n 3 +4n 2 or 21.5n . It is only from \nsuch an expression that one can glean immediate information about the expected behavior of the code to \nbe run. In this paper we describe a method for automatically ob\u00adtaining linear bounds on the heap space \nusage of functional programs. Of course, it is undecidable whether a given pro\u00adgram admits such a linear \nbound, so we must accept certain restrictions. We claim, however, that the restrictions we make are quite \nnatural and moreover, our analysis is prov\u00adably e.cient in this case. An important limitation of our \nwork is that only .rst\u00adorder programs are considered. This means that a program is a mutual recursive \nde.nition of .rst-order top level func\u00adtions. While perhaps being against the credo of functional programming \nit o.ers us surprising bene.ts and moreover many uses of higher-order functions are actually a de.ni\u00adtional \nextension of .rst-order functional programming: in principle one can eliminate them by code duplication. \nWe comment on this and on the di.culties encountered with fully general higher-order functions later \nin Section 11. 1.1 Overview of results We assume an operational semantics that maintains a free\u00adlist \nwhich is reduced whenever a constructor function like cons is evaluated. On the other hand, we assume \nthat cer\u00adtain pattern matches returns the matched cell to the freelist which accordingly increases in \nthe branches of the match. If we try to evaluate a constructor under an insu.ciently large freelist the \nevaluation gets stuck. We then devise an annotation of typing derivations with nonnegative rational values \nwhich allows for prediction of the freelist size required to evaluate the program. For in\u00adstance, if \nwe derive x : L(L(B,1) ,2) ,3 f e : L(B,4) ,5 then this signi.es that if we evaluate e in a situation \nwhich binds x toalist [l1,...,lm] then a freelist of size at least 3+2m+1|li| su.ces to prevent evaluation \nfrom getting i stuck. If the evaluation terminates with a result l then the freelist will have size 5 \n+ 4|l|.Here |\u00b7| denotes the length of a list. We note two crucial features: First, the size estimate \nfor the freelist left after evaluation is given as a function of the result type rather than the input. \nSecond, estimates do not just depend on the overall size of arguments but may attach di.erent weight \nto various parts of the data. In the example the length of the input list counts twice, whereas the lengths \nof the component lists only count once. We .nd that these features allow for a surprisingly smooth compositional \nformulation of the annotations. Given a concrete program P we then set up a skeleton of an annotated \nderivation which contains variables in place of actual annotations. The various side conditions in our \nrules then take the form of linear inequalities between these variables. We thus obtain a linear program \nL(P) whose solu\u00adtions are in one-to-one correspondence to valid annotations. As is well-known such solutions \ncan be e.ciently computed. We also show that integral solutions to the L(P)are in 1-1 correspondence \nto enriched versions of P in the pro\u00adgramming language LFPL [8] which bypasses memory man\u00adagement by \nexplicitly passing around memory cells as part of the data. Programs in LFPL largely behave like imperative \nprograms that modify heap-allocated data in-place rather than claiming fresh memory for results of computations \nand returning unused memory. In this way, our inference can also be viewed as type inference for LFPL. \nIt must be said, though, that not all possible LFPL pro\u00adgrams arise as reconstructions from solutions \nof the con\u00adstraint system. The problem of reconstructing arbitrary LFPL programs is considered in more \ndetail in [11]. While obtaining integral solutions to linear programs is in general NP hard, we prove \nthat in several important and natural sub-cases of our setting they can be obtained e.\u00adciently. We emphasize \nthat our functional programs are not neces\u00adsarily required to be linearly typed. Indeed, we have a con\u00adtraction \nrule corresponding to aliasing that allows us to iden\u00adtify two variables provided we split the resource \nannotations accordingly. For example, if we have x:L(B,3) ,y:L(B,6) ,5 f e : C,6 then the contraction \nrule allows us to derive z:L(B,9) ,5 f e : C,6. Operationally, x,y point toashared memeory region. If \nwe use this contraction rule then validity of our analysis relies on the following semantic condition: \nif at any point in the evaluation of a program a heap cell is deallocated in a destructive pattern match \nthen this cell must not be acces\u00adsible from the variables occurring in the remaining program fragment. \nWe speak of benign sharing in this case. A viola\u00adtion of the property is called malignant sharing. Notice \nthat if a program exhibits malignant sharing then it will not necessarily crash due to null pointer access \nbecause it might not actually follow the path to the dangling refer\u00adence even though this is possible. \nOne may thus compare benign sharing to the property ensured by garbage collec\u00adtion. We formalise benign \nsharing on the level of the operational semantics as a judgment S,s f e .bs v,s' which asserts that in \nstack S and heap s the evaluation of e results in value v and new heap s' and, moreover, all sharing \nduring that evaluation is benign. For particular programs we may be able to assert benign sharing by \ninspection or logical reasoning. More interest\u00adingly, we would like to guarantee it by some static type \nsystem. We already know that linear typing, i.e., the ab\u00adsence of contraction, provides such a guarantee; \nwe conjec\u00adture that the more general read-only type systems and anal\u00adyses described in [2, 12, 15, 18] \nall are able to provide such a guarantee as well, by suitably restricting but not altogether excluding \nthe contraction rule. The important point here is that the semantic formalisa\u00adtion of benign sharing \nmakes no reference to resource an\u00adnotations so that discharging the extra assumption made is orthogonal \nto the work described in this paper. We also mention that, of course, we can recursively de.ne cloning \nfunctions in the strictly linear fragment, for instance clone : L(B,2) . L(B,0) .L(B,0). The two copies \nreturned are not aliased but one of them is constructed using fresh heap space. Notation: The set of \nnatural numbers denoted Iis assumed to contain zero. We let Q+ denote the set of non\u00adnegative rational \nnumbers. If f is a .nite function we write f\\ x for fr(dom f\\{x}), that is, the restriction of f to its \ndomain less the element x. We write f[x .v] to denote the .nite function that maps x to v and acts like \nf otherwise. FV(e) denotes the set of free variables occurring within the term e. The substitution of \na free variable v by t in term e is denoted by e[t/v]. If l denotes a list, then |l| denotes the length \nof the list. Equivalently, |l| is the number of nodes of l in a machine representation. Acknowledgements: \nPart of this research was carried out within the EU project IST-2001-33149 Mobile Resource Guarantees \n. We also acknowledge .nancial support by the Deutsche Forschungsgemeinschaft (DFG).  2. FUNCTIONAL \nLANGUAGE We de.ne a .rst-order typed functional language LF as fol\u00adlows. zero-order types: A::= 1 | B \n| L(A) | A. A| A+ A .rst-order types: F ::= (A,...,A) . A Here B is thetypeof Booleans, L(A) is the type \nof lists with entries from A, sum and product are denoted by +,.. Finally, 1 is a singleton type. We \ncan also include labelled trees, but refrain from doing so to save space. However, one of our examples \nuses trees. Since we are interested in memory consumption, we de.ne at this point a function SIZE : LF-type \n. Ifor later use: SIZE (1)= SIZE (B)= SIZE (L(A)) = 1 SIZE (A. C)= SIZE (A)+ SIZE (C) () SIZE (A+ C)= \n1+maxSIZE (A) ,SIZE (C) To save space we omit the grammar for LF terms as well as the typing rules. Both \ncan be reconstructed from the typing rules for the annotated version LFO, given in Section 4. Allthatneedstobedoneisto \nremoveall reference to resource constraints as shown in the following example of the two variable rules. \nx. dom(G) x. dom(G) n = n ' (LF:Var)(LFO:Var) G f S x:G(x)G,nf S x:G(x),n ' We draw attention to the \npresence of the two pattern matching constructs match and match ' governed by rules LFO:List-Elim and \nLFO:List-Elim . These rules di.er only in the resource annotations so that both pattern matches have \nidentical LF-typing rules. The semantics of match is a destructive one: the list node being matched against \nis deallocated afterwards; in a match ' the matched node is preserved for subsequent use. We also point \nout that the typing rules for LFO,hence the typing rules for LF, are formulated in a linear style. That \nis, multiple occurrences of a variables are explicitly introduced via the rule LFO:Share. For convenience, \nwe give the LF\u00adversion here: G,x:A,y:Af S e:C (LF:Share) G,z:Af S e[z/x,z/y]:C An LF program P consists \nof a signature S and a col\u00adlection of terms ef for each f . dom(S) such that for all f . dom(S) one has \ny1:A1,...,yk:Ak f S ef :C when S(f)=(A1,...,Ak) -. C. In concreteexamples weindi\u00adcate the association \nof de.ning terms with function symbols by writing down equations of the form f(y1,...,yk)= ef . We usually \nconsider a .xed but arbitrary program P throughout the following. We denote by LFlin the fragment of \nLF which neither contains the term constructor match ' nor the typing rules LF:Share, LF:List-Elim .Note \nthat LFlin is an a.ne lin\u00adear functional language. 2.1 Examples Throughout the examples, the type Ais \nany .xed (but arbi\u00adtrary) LF-type. In an implemented version of LF one would presumably want to allow \ntype variables and possibly even polymorphic quanti.cation over these. Example 1. The following example \nde.nes a function that reverses the order of the elements in a list of booleans. reverse :(L(A)) -. L(A) \nrev aux :(L(A) ,L(A)) -. L(A) reverse(l)= rev aux(l,nil) rev aux(l,acc)= match l with | nil . acc | \ncons(h,t) . rev aux(t,cons(h,acc)) We furthermore de.ne reverse ' and rev aux ' similarly, just replacing \nmatch by match ' . Example 2. The next example corresponds to the well\u00adknown insertion sort algorithm: \nsort :(L(A)) . L(A) ins :(A,L(A)) . L(A) leq :(A. A) . B . (A. A) ins(n,l)= match l with | nil . cons(n,nil) \n| cons(h,t) . ('') match leq(n,h) with b. n . h . if b then cons(n ' ,cons(h ' ,t)) else cons(h ' ,ins(n \n' ,t)) sort(l)= match l with | nil . nil | cons(h,t) . ins(h,sort(t)) To simplify notation we have used \nsome syntactic sugar in these examples: notably we allow nesting of terms which ex\u00adpands into nested \nlet-constructs and also allow nested pat\u00adterns as in line 4 of ins which expand into a sequence of nested \nmatches. Here we assume the comparison function leq to return its arguments so that this example makes \nsense in the fragment LFlin . Example 3. The function clone doubles its input: clone :(L(B)) . L(B) . \nL(B) clone(l)= match l with |nil . nil . nil | cons(h,t) . match clone(t) with t1 . t2 . if h then cons(tt,t1) \n. cons(tt,t2) else cons(ff,t1) . cons(ff,t2) Example 4. The function tos replaces each third element \nof a list by a value depending on its two predecessors, so it does not change the length of the list, \nbut this implemen\u00adtation of tos is composed of two auxiliary functions, which do change the length of \nthe list in between. Namely, sec deletes every third element whereas tpo inserts a new ele\u00adment in every \nthird position. The signi.cance of the type B . B as opposed to B or an unspeci.ed type will be explained \nin Section 7. tos :(L(B . B)) -. L(B . B) sec :(L(B . B)) -. L(B . B) tpo :(L(B . B)) -. L(B . B) tos(l)= \ntpo(sec(l)) sec(l)= match l with | nil .nil | cons(h1,t1) .match t1 with | nil .cons(h1, nil) | cons(h2,t2) \n.match t2 with () | nil .consh1, cons(h2, nil) ( ) | cons(h3,t3) .consh1, cons(h2, sec(t3)) tpo(l)= match \nl with | nil .nil | cons(h1,t1) .match t1 with | nil .cons(h1, nil) | cons(h2,t2) . (( )) consh1, consh2, \ncons(h1, tpo(t2))  3. OPERATIONAL SEMANTICS We use a freelist containing available heap cells. We treat \nthis freelist simply as an integer value giving the number of free words. Issues of alignment are assumed \nto be dealt with by an ap\u00adpropriate defragmentation routine to be launched whenever arequest for t aligned \nwords cannot be met although the freelist has size larger or equal than t. Admittedly, defrag\u00admentation \nis costly to implement. If desired, we can avoid fragmentation by assuming that all allocated blocks \nare of the same size. See also the remark on garbage collection at the end of this section. Let Loc be \na set of locations which model memory ad\u00addresses on a heap abstracted over possible renaming that may \nbecome necessary upon defragmentation. We use f to range over elements of Loc. Next we de.ne a set of \nval\u00adues Val, ranged over by v which occur as values of program variables, results, and values bound to \nlocations in a heap. v ::= c | f | NULL | (v, v) | inl(v) | inr(v) A value is either a boolean constant \nc,a location f,a null value NULL, a pair of values (v, v) or a value marked with either inl or inr. Occasionally \nwe use a short hand notation for tuples, e.g. we write (v, v, v) instead of (v, (v, v)). We assume that \nthe LF type derivation is implicitly ac\u00adcessible (e.g. by adding a pointer to a type to each value as \nis done in Java), hence we allow ourselves to extend the size function to SIZE : Val .I. The idea is \nthat value v occupies SIZE (v) words when stored in the heap. We are aware that this is not rigorous, \nhowever, the reduction on notational clutter outweighs the formal disadvantages by far. A stack S:Var \n-Val is a .nite partial mapping from vari\u00adables to values, and a heap s:Loc -Val is a .nite partial mapping \nfrom locations to values. Evaluation of an expres\u00adsion e takes place with respect to a given stack and \nheap, and yields a value and a possibly updated heap. Moreover, the size of the freelist may shrink or \ngrow upon evaluation. Thus we have a relation of the form m, S, s f e . v, s ' ,m ' expressing that the \nevaluation of e under stack S and heap s succeeds in the presence of a freelist of size m and results \nin value v. As a side e.ect the heap is modi.ed to s ' and the size of the freelist becomes m ' .The \nvalues m and m ' are arbitrary natural numbers. The stack is extended with additional variable bindings \nwhenever we enter a new scope, inside subterms in the premises of the evaluation rules. When we evaluate \na func\u00adtion body we use a stack which only mentions the actual parameters, intuitively preventing access \nbeyond the stack frame. Notice that the stack may contain pointers into the heap (i.e., locations), but \nthere are no pointers going from the heap into the stack. The operational semantics is given with respect \nto a .xed signature and program. m, S, s f*. NULL,s, m (.O:Unit) m, S, s fc . c, s, m (.O:Const) m, S, \ns fx . S(x),s,m (.O:Var) S(x1)= v1 \u00b7\u00b7\u00b7 S(xn)= vn m, [y1.v1,...,yn.vn],s fef . v, s ' ,m ' the yi are \nthe symbolic arguments of ef (.O:Fun) m, S, s ff(x1,...,xn) . v, s ' ,m ' m, S, s fe1 . v1,s0,m0 m0,S[x.v1],s0 \nfe2 . v, s ' ,m ' (.O:Let) m, S, s flet x=e1 in e2 . v, s ' ,m ' S(x) m, S, s fet . v, s '' =0 ,m (.O:If-t) \nm, S, s fif x then et else ef . v, s ' ,m ' S(x)=0 m, S, s fef . v, s ' ,m ' (.O:If-f) m, S, s fif x \nthen et else ef . v, s ' ,m ' () m, S, s fx1 .x2 . S(x1),S(x2),s,m (.O:Pair) S(x)=(v1,v2) m,S[x1.v1][x2.v2],s \nfe . v, s ' ,m ' m, S, s fmatch x with (x1 .x2) .e . v, s ' ,m ' (.O:Match-Pair) m, S, s finl(x) . inl(S(x)),s,m \n(.O:Inl) m, S, s finr(x) . inr(S(x)),s,m (.O:Inr) ' ' ' ] fe1 . v, s ' S(x)= inl(v ) m, S[y.v ,m match \nx with | inl(y) .e1 | inr(y) .e2 . v, s ' ,m ' (.O:Match-Inl) '' ' S(x)= inr(v ) m, S[y.v ] fe2 . v, \ns ' ,m match x with | inl(y) .e1 | inr(y) .e2 . v, s ' ,m ' (.O:Match-Inr) m, S, s fnil . NULL,s, m (.O:Nil) \n() v = S(xh),S(xt)f .dom(s) m + SIZE (v) ,S,s fcons(xh,xt) . f,s[f.v],m (.O:Cons) S(x)= NULL m, S, s \nfe1 . v, s ' ,m ' m, S, s fmatch x with | nil .e1 . v, s ' ,m ' | cons(xh,xt) .e2 (.O:Match-Nil) S(x)= \nfs(f)=(vh,vt) m0 = m + SIZE (s(f)) m0,S[xh.vh][xt.vt],s \\f fe2 . v, s ' ,m ' m, S, s fmatch x with | \nnil .e1 . v, s ' ,m ' | cons(xh,xt) .e2 (.O:Match-Cons) S(x)= NULL m, S, s fe1 . v, s ' ,m ' m, S, s \nfmatch ' x with | nil .e1 . v, s ' ,m ' | cons(xh,xt) .e2 (.O:Match -Nil) S(x)= fs(f)=(vh,vt) m, S[xh.vh][xt.vt],s \nfe2 . v, s ' ,m ' m, S, s fmatch ' x with | nil .e1 . v, s ' ,m ' | cons(xh,xt) .e2 (.O:Match -Cons) \nThe only rules that deserve an explanation are the ones pertaining to the match constructs for lists. \nIt is assumed that the match construct immediately deallocates the node matched against, whereas it is \npreserved in a match ' con\u00adstruct. Accordingly the freelist grows in the branches of a match whereas \nit stays the same in a match ' .At this point, the programmer decides which one to use. It is conceiv\u00adable \nthat this decision can be automated in such a way that the best possible resource behaviour is obtained. \nThis is, however, left for future research. Note that given m, S, s, e it need not be the case that there \nexist v, s ' ,m ' with m, S, s f e . v, s ' ,m ' for one of the following reasons: Non-termination (this \nmanifests itself as an in.nite backwards application of rule .O:Fun)  Wrong elements in stack or heap, \ne.g. a Boolean where either NULL or a pair is expected.  Insu.ciently large freelist, e.g. m =0,e = \ncons(1, nil).  We choose to accept nontermination and rely on a standard typing discipline to deal with \nwrong elements. The main contribution here is to devise static methods that ensure absence of insu.ciently \nlarge freelists. We remark at this point that the judgement m, S, s fe . v, s ' ,m ' admits the following \nalternative interpretation. If we evaluate e using a garbage collector which collects after every pattern \nmatch then the heap size during the evaluation will not exceed the initial heap size by more than m. \n3.1 Operational semantics without freelist In order to be able to formally state correctness of the static \nanalysis we are going to describe, it is convenient to in\u00adtroduce an auxiliary operational semantics \nwhich does not rely on freelists. To this end, we introduce a judgment S, s f e . v, s ' which intuitively \nreads as in stack S and heap s expression e evaluates to result v and leaves heap s ' . The rules de.ning \nthis judgment are like the ones that de.ne the instrumented judgment m, S, s f e . v, s ' ,m ' but without \nall reference to freelist sizes. For example, we have the rule () v = S(xh),S(xt)f .dom(s) (.:Cons) S, \ns fcons(xh,xt) . f,s[f.v] We can understand this judgment as formalizing evaluation in a C-like environment \nwhere space is allocated whenever a cons-cell is formed and deallocated whenever we match against a cons-cell. \nIn earlier work [8, 2] it was shown that under a linear typing discipline, in particular in LFlin, this \njudgment rep\u00adresents the intended functional semantics. In this paper, we will rely on the essence of \nthese earlier results and do not speak about functional semantics at all. More precisely, we will establish \na result of the following kind. Correctness property. If G fS e:A in LF and our static analysis derives \na minimum freelist size n then when\u00adever S, s fe . v, s ' without malignant sharing then for all m =n \nthere exists m ' such that m, S, s fe . v, s ' ,m ' . 3.2 Formalisation of benign sharing We de.ne a \nvariant of the operational semantics: S, s f e .bs v, s ' which di.ers from the original operational \nse\u00admantics in that it prohibits malignant sharing in the sense described in the Introduction. The auxiliary \nfunction R :heap \u00d7Val -. P(Loc)is de\u00ad.ned as follows: R(s, c)= \u00d8 R(s, NULL)= \u00d8 R(s, (v1,v2)) = R(s, v1) \n.R(s, v2) R(s, inl(v)) = R(s, v) R(s, f)= {f}.R(s, s(f)) R(s, inr(v)) = R(s, v) We set R(s, s(f)) := \n\u00d8 when f . dom(s). We extend R .() to stacks by: R(s, S):= Rs, S(x).Intuitively, x.dom S R(s, S) is the \nset of locations accessible from S. The judgment S, s f e .bs v, s ' is now inductively de\u00ad.ned by the \nrules for the ordinary (resource-free) operational semantics except for the rules .:Let and .:Match-Cons \nwhich are replaced by the following ones. The rules concern\u00ading match ' are not altered. S, s fe1 .bs \nv1,s0 S[x.v1],s0 fe2 .bs v, s ' srR(s, S ' )= s0rR(s, S ' ) S ' = SrFV(e2) (.bs :Let) e2 .bs S, s flet \nx=e1 in v, s ' S(x)= fs(f)=(vh,vt) ( ) f .Rs, S[xh.vh][xt.vt]rFV(e2)S[xh.vh][xt.vt],s \\f fe2 .bs v, s \n' S, s fmatch x with | nil .e1 | cons(xh,xt) .e2 .bs v, s ' (.bs :Match-Cons) Since these rules have \nstrengthened preconditions com\u00adpared to their counterparts we clearly have Lemma 1. s, S fe .bs v, s \n' =. s, S fe . v, s ' Let us consider short program fragments illustrating malig\u00adnant sharing: let x=reverse(y) \nin y,where reverse is de\u00ad.ned as in Example 1. The function reverse reverses the list y destructively, \nhence the rule .bs:Let is not applicable, as y is contained in the reachable region and changes after \neval\u00aduation of reverse(y). Note that the rule .:Let would go through. If the fragment would call reverse \n' instead, which produces a reversed copy via the use of match ' instead of match, the program fragment \nabove would be acceptable. However, the di.erence would be revealed in the di.erent resource consumption \nas will be shown in Section 4.1. Now consider the fragment let x=y in x++ y,where the in.x ++ denotes \nlist concatenation (see de.nition in Exam\u00adple 7). Here the rule .bs:Let would be applicable, but fails \nsince x++ y cannot be evaluated, unless S(y)= NULL.The reason is that the evaluation of x++ y deallocates \nx, but the locations reachable from x can also be reached via y,hence the precondition added to .bs:Match-Cons \nis violated. Of course, we could de.ne a copying version of append us\u00ading match ' . Note that our semantics \ndoes not cater for in place update. We can either create a new cell or deallo\u00adcate a cell, but never \nchange the contents of an existing cell. This precludes, in particular, the creation of circular data \nstructures. bs The annotated version .Ois formulated similarly, the resource related constraints do not \nchange.  4. LF WITH RESOURCE ANNOTATIONS In this section we introduce resource annotations for LF which \nwill allow us to predict the amount of heap space needed to evaluate a program. This prediction will \nbe a linear expression involving the sizes of the arguments. We call this annotated version LFO. Accordingly, \nthe lin\u00adearly typed fragment not containing the rule LFO:Share and the match ' -term constructors will \nbe called LFlin . OThe types of LFOare given by the following grammar: pure zero-order: P ::= 1 | B | \nP . P | R+ R | L(R) rich zero-order: R ::= (P,k)(for k . Q+ ) .rst-order: F ::= (P,...,P,k) . R (for \nk . Q+ ) The underlying LF-type | A| of LFO-type A is de\u00ad.ned by removing all resource annotations, for \nexample | L(L(B,5) ,7)| = L(L(B)). Furthermore we de.ne SIZE : LFO-type . Iby SIZE (A):= SIZE (| A| ), \nthus SIZE (A) does not depend on the annotations contained in A. Let S be an LFOsignature mapping a .nite \nset of func\u00adtion identi.ers to LFO.rst-order types, G be an LFOtyping context mapping a .nite set of \nidenti.ers to LFOpure zero\u00adorder types, and let n,n ' be positive rationals. An LFOtyp\u00ading judgment G,nf \nS e:A,n ' then reads under signature S, in typing context G and with n memory resources available, the \nLFOterm e has type A with n ' unused resources left over . In each of the following typing rules, let \nfurthermore A,B,C denote arbitrary LFOzero-order types and n,k,p, possibly decorated, denote arbitrary \nvalues in Q+ . n = n ' (LFO:Const Unit) G,n f S * :1,n ' c aboolean constant n = n ' (LFO:Const Bool) \nG,n f S c:B,n ' x. dom(G) n= n ' (LFO:Var) G,n f S x:G(x),n ' S(f)=(A1,...,Ap,k) -. (C,k ' ) n = kn- \nk+ k ' = n ' (LFO:Fun) G,x1:A1,...,xp:Ap,n f S f(x1,...,xp):C,n ' G1,nf S e1:A,n0 G2,x:A,n0 f S e2:C,n \n' (LFO:Let) G1,G2,nf S let x=e1 in e2:C,n ' G,n f S et:A,n ' G,n f S ef :A,n ' (LFO:If) G,x:B,n f S if \nx then et else ef :A,n ' n = n ' (LFO:Pair) G,x1:A1,x2:A2,n f S x1 . x2:A1 . A2,n ' G,x1:A1,x2:A2,nf \nS e:C,n ' G,x:A1 . A2,nf S match x with x1 . x2 . e:C,n ' (LFO:Pair-Elim) n= kl + n ' (LFO:Inl) G,x:A,nf \nS inl(x):(A,kl)+(B,kr),n ' n= kr + n ' (LFO:Inr) G,x:B,n f S inr(x):(A,kl)+(B,kr),n ' G,y:A,n+ kl f S \ne1:C,n ' G,y:B,n+ kr f S e2:C,n ' ' G,x:(A,kl)+(B,kr),n f S match x with | inl (y) . e1:C,n | inr(y) \n. e2 (LFO:Sum-Elim) n= n ' (LFO:Nil) G,n f S nil:L(A,k) ,n ' n = SIZE (A. L(A,k)) + k+ n ' G,xh:A,xt:L(A,k) \n,n f S cons(xh,xt):L(A,k) ,n ' (LFO:Cons) G,nf S e1:C,n ' G,xh:A,xt:L(A,k) ,n+ SIZE (A. L(A,k)) + k f \nS e2:C,n ' G,x:L(A,k) ,n f S match x with | nil . e1 :C,n ' | cons(xh,xt) . e2 (LFO:List-Elim) G,nf S \ne1:C,n ' G,xh:A,xt:L(A,k) ,n+ k f S e2:C,n ' G,x:L(A,k) ,nf S match ' x with | nil . e1 :C,n ' | cons(xh,xt) \n. e2 (LFO:List-Elim ) G,x:A1,y:A2,nf S e:C,n ' (LFO:Share) G,z:A1 . A2,nf S e[z/x,z/y]:C,n ' where A1 \n. A2 is de.ned as follows when | A1| = | A2| : 1 . 1 = 1B . B = B () (A,k1) . (C,k2)=A. C,k1 + k2(A1 \n. C1) . (A2 . C2)=(A1 . A2) . (C1 . C2) (A1 + C1) . (A2 + C2)= A1 . A2 + C1 . C2 L(A) . L(C)= L(A. C) \nWe observe that the following type rule is admissible: G,nf S e:A,n0 n ' = n0 + k (LFO:Waste) G,n+ k \nf S e:A,n ' If P is an LFOprogram, then | P| denotes the underlying LF program: Lemma 2. G,n LF. f S \ne:C,n ' =.|G| LF f |S| e:| C| 4.1 Examples We revisit the Examples presented in 2.1. Since the term \nlanguages of LF and LFOare identical, we just give the proper LFOsignatures here. Again, A denotes a \n.xed pure LFO-type; let a . Q+ be .xed (but arbitrary) as well. Example 1. reverse :(L(A, a) , 0) -. \n(L(A, a) , 0) rev aux :(L(A, a) , L(A, a) , 0) -. (L(A, a) , 0) While reverse reverses its input in place \nat no additional resource costs, reverse ' copies its argument so that it can be reused. For a0 = a + \nSIZE (A . L(A)) = a + SIZE (A)+1 we obtain the typing reverse ' :(L(A, a0) , 0) -. (L(A, a) , 0) rev \naux ' :(L(A, a0) , L(A, a) , 0) -. (L(A, a) , 0) In the explicit case A = B and a =0(hence a0 =2), we \nsee that reverse can be computed without any additional resources, while reverse ' consumes 2n previously \nunused cells if run on an input list of length n (which itself already occupies 2n cells). Example 2. \nLet again a0 = a + SIZE (A)+ 1. sort :(L(A, a) , 0) -. (L(A, a) , 0) ins :(A, L(A, a) ,a0) -. (L(A, a) \n, 0) leq :(A . A, 0) -. (B . (A . A) , 0) Example 3. clone :(L(B, 2) , 0) -. (L(B, 0) . L(B, 0) , 0) \nExample 4. tos :(L(B . B, 0) , 3) -. (L(B . B, 0) , 0) ((3 )) sec :(L(B . B, 0) , 3) -. LB . B, 2 , 0 \n((3 )) tpo : LB . B, 2 , 0-. (L(B . B, 0) , 0) The intuition behind the fractional annotations will be \nex\u00adplained in Section 7.  5. TRANSLATION TO LFPL In [8] we have introduced a linear functional language \nthat can be translated into C without dynamic memory alloca\u00adtion, i.e., without using the system calls \nmalloc() and free(). This was achieved by introducing an abstract type 0 standing for memory locations \nbig enough to hold any struc\u00adture node occurring in a particular program. Elements of this abstract type \nmay be passed around as data, in par\u00adticular they can arise as input, output, and components of structures. \nConstructors of recursive types take an extra argument of type 0, e.g., cons :(0,A, L(A)) . L(A). In \nthe translation to C the space pointed to by this extra argument is used to store the newly create structure \nnode. Conversely, in a pattern match we gain access to an element of type 0 when matching against a recursive \nconstructor such as cons. We will explain how LFlin canbe usedtoinfer LFPL-typings O for LFlin -programs. \nSince LFPL handles resources as elements of type 0we restrict to integral annotations. For this purpose \nlet LF.,lin O denote the fragment of LFlinwhere all annotations are re- O stricted to nonnegative integers. \nFurthermore, we temporarily rede.ne SIZE (A)to be1 for all types A. This corresponds to the assumption \nmade in LFPL that all structure nodes are stored in heap portions of equal size. .,lin Types in LFOcanthenbe \ntranslated to LFPL-types by mapping each annotation n to an n-fold product of type 0, for instance, the \ntype (A, L(A, 1) , 2) . (L(A, 1) , 0) is mapped to (A, L(A . 0) , 0. 0) . (L(A . 0)). The translation \nof terms follows the structure of a deriva\u00adtion in LF.,lin ; we omit the (essentially obvious) details. \nO This is useful since the resulting C-programs can be ex\u00adecuted without overhead such as freelists, \ndefragmentation, or garbage collection which makes them suitable in resource\u00adrestricted environments. \n 6. LF< AND SPACE-AWARE SEMANTICS In this section we will prove a correspondence between full LFOand \nthe space-aware operational semantics from Sec\u00adtion 3. We must formalize that a given stack and heap \n.t a certain typing context: s f NULL:1 (Unit) s f c:B (Bool) s f v:A1 s f w:A2 (Pair) s f (v, w):A1 \n. A2 s f v:A (Inl) s f inl(v):A + B s f v:B (Inr) s f inr(v):A + B s f NULL:L(A)(List-Nil) s \\ f f s(f):A \n. L(A) (List-Node) s f f:L(A) . xi . dom(G).s f S(xi):G(xi) (Context) s f S:G Furthermore we extend to \nLFOby s f S:AO. s f S:| AO| where AOis an LFOtype and similarly for contexts. Lemma 3. Let s, t be heaps. \nIf s f v:A and . f . R (s, v).s(f)= t (f) then t f v:A Proofs of this and all subsequent propositions \nare con\u00adtained in a technical report available on request and cur\u00adrently visible at our homepage. Lemma \n4. If G f S e:A and s f S:GrFV(e) and S,s f e.bs '' v,s then s f v:A. We de.ne . : heap \u00d7 Val \u00d7 LF-type \n-. Q+ by .(s,v,1)= .(s,c,B)=0 .(s,(v1,v2),A. B)=.(s,v1,A)+ .(s,v2,B) .(s,inl(v),(A,k)+(B,l)) = k+.(s,v,A) \n.(s,inr(v),(A,k)+(B,l)) = l+.(s,v,B) .(s,NULL,L(A,k)) = 0 .(s,f,L(A,k)) = k+.(s,s(f),A. L(A,k)) () and \nfurthermore .(s,S,G):= .s,S(x),G(x). x.dom G The amount of additional heap space needed to evaluate a \nfunction f :(A1,...,Ap,k) . (B,k ' ) depends on the size of the input to f.If s f S:{ x1:A1,...,xp:Ap} \n,the amount of additional heap space required to compute f is k+.(s,S,{ x1:A1,...,xk:Ak} ). In particular, \nif f :(L(B,a) ,b) . (L(B,c) ,d)then evalu\u00adating f(w) takes at most a| w| + b extra space to evaluate, \nwhere | w| is the length of w.If we evaluate f(w)given a freelist of size a| w| + b + k (where k = 0) \nthen after the evaluation the freelist will have size at least c| f(w)| + d+ k. Lemma 5. If srR (s,v)= \ns ' rR (s,v) then .(s,v,A)= .(s ' ,v,A). Lemma 6. For all s,S,A1,A2, it holds that .(s,v,A1 . A2)= .(s,v,A1)+.(s,v,A2) \nprovided that .(s,v,A1. A2) is de.ned. Theorem 1. Let P be a valid LFOprogram with signa\u00adture S. For \nall LFOterms e such that G,n f S e:A,n ' and whenever S,s f e.bs v,s ' and s f S :(GrFV(e)) then for \nall q . Q+ and for all m. Isuch that m= n+.(s,S,G)+q there exists m ' . Isatisfying m ' = n ' +.(s ' \n,v,A)+ q such that m,S,s f e.bs v,s ' ,m ' . O Corollary 1. If P is a valid LFOprogram containing a function \nsymbol ()((')') f : L(B,n1) ,...,L(B,nk) ,m-. LB,n ,m then the function call f(l1,...,lk) evaluates properly \nto a list l ' , provided that there are at least m+ k ni| li| free mem\u00ad i=1 ory cells available, where \n| li| denotes the number of nodes of ' '' list li. After the evaluation there are at least m + n | l \n| free cells available.  7. INFERENCE OF ANNOTATIONS Recall that a linear program (LP) is a pair (V,C)where \nV is a set of variables and C is a set of inequalities of the form a1x1 + ...anxn = b where the xi are \nvariables from V and the ai and b are rational numbers. In addition, one may specify an objective function \nwhich is a term of the form c1x1 + \u00b7\u00b7\u00b7 + cnxn where the xi are from V and the ci are rational numbers. \nIn this case, one de.nes an optimal solution to be a solution that minimizes the value of the objective \nfunction. Our aim in this section is the following. Given an LF program P we want to discover whether \nthere exists an LFO program P ' such that | P ' | = P. To this end, we notice that the structure of any \nLFO-derivation is determined by its underlying LF-derivation. This means that if we are given an LF-derivation \nof some program P all that needs to be done in order to obtain a corresponding LFO-derivation is to .nd \nthe numerical val\u00adues arising in type annotations in such a way that all the numerical side conditions \nare satis.ed. To discover these annotations, we assign to a given LF\u00adprogram P (assumed to be equipped \nwith a typing deriva\u00adtion) an LP L (P) with the property that solutions to L (P) are in 1-1 correspondence \nwith LFOprograms P ' such that | P ' | = P.The LP L (P) is the pair (V,C)where V con\u00adtains one speci.c \nvariable for every occurrence of a numeri\u00adcal value in a possible LFOtyping derivation. The set C collects \nall the inequalities arising as side condi\u00adtions in such a derivation. This includes in particular equal\u00adity \nconstraints that are implicit in that types are sometimes required to be equal, e.g. in rule LFO:Var.Note \nthat an equality constraint may be encoded as a pair of inequality constraints. Furthermore we add the \nconstraints that all occurring variables are nonnegative, as all LFO-type anno\u00adtations are nonnegative. \nAs an illustrative example, we consider a program P that contains a single function symbol rev aux :(L(A) \n,L(A)) . L(A) with the de.ning expression as given in Example 1. We have the LF typing derivation shown \nin Figure 1. In order to form L (P) we consider an indeterminate LFO-derivation as in Figure 2. It is \nclear that any LFO\u00adderivation matching the LF-derivation of P arises as an in\u00adstantiation of the derivation \nin Figure 2 satisfying the con\u00adstraints given in Figure 3. Of course, we can readily elimi\u00adnate all simple \nequality constraints given in Figure 3 leaving c = n2 - SIZE (A) - 1 - b1 n3 = c n2 = SIZE (A)+1+ b2 \n+ n3 n3 - c+ d= d c = d plus the nonnegativity constraints. Since we are only inter\u00adested in the values \nof variables occurring within .rst-order types, we eliminate n2,n3 here in this example for a better \nunderstanding of the set of solutions and obtain: c = d= 0 b1 = b2 = b3 = 0 An optimal solution with \nrespect to the sum of all variables is then given by c = d = b1 = b2 = b3 =0. Hence the typing rev aux \n:(L(A,0) ,L(A,0) ,0) . (L(A,0) ,0) can be derived in LFO, which signi.es that rev aux can be evaluated \nwithout any extra heap space. These equations may also be regarded as the most gen\u00aderal LFO-type of rev \naux,e.g. by b1 = b2 = b3 we eas\u00adily see that rev aux may also operate on lists containing an arbitrary \namount of extra heap space, hence rev aux : (L(A,7) ,L(A,7) ,0) . (L(A,7) ,0) could be derived if nec\u00adessary \nby using rev aux in a more complicated program con\u00adtext. The program from Example 4 portrays the usefulness \nof rational solutions. For the sake of simplicity we unify some variables which are obviously equated. \nWe therefore assume the following enriched indeterminate signature: tos :(L(B . B,l1) ,x1) . (L(B . B,l3) \n,x3) sec :(L(B . B,l1) ,x1) . (L(B . B,l2) ,x2) tpo :(L(B . B,l2) ,x2) . (L(B . B,l3) ,x3) S(rev aux)=(L(A) \n,L(A)) .L(A) LF:Cons LF:Fun y:L(A) ,h:Afcons(h,y): L(A) t:L(A) ,r:L(A) frev aux(t,r): L(A) LF:Var LF:Let \ny:L(A) fy : L(A) y:L(A) ,h:A,t:L(A) flet r=cons(h,y) in rev aux(t,r): L(A) LF:List-Elim x:L(A) ,y:L(A) \nfmatch x with | nil .y | cons(h,t) .let r=cons(h,y) in rev aux(t,r): L(A) Figure 1: Derivation of P in \nLF LFO:Cons LFO:Fun y:L(A,a3) ,h:A,n2 f t:L(A,a5) ,r:L(A,a6) ,n3 f cons(h,y): L(A,a4) ,m2 rev aux(t,r): \nL(A,a7) ,m3 LFO:Var LFO:Let y:L(A,a1) ,n1 f y:L(A,a8) ,h:A,t:L(A,a9) ,n4 f y : L(A,a2) ,m1 let r=cons(h,y) \nin rev aux(t,r): L(A,a10) ,m4 LFO:List-Elim x:L(A,a11) ,y:L(A,a12) ,n5 f match x with | nil .y | cons(h,t) \n.let r=cons(h,y) in rev aux(t,r): L(A,a13) ,m5 where rev aux :(L(A,b1) ,L(A,b2) ,c) .(L(A,b3) ,d). As \nan indeterminated LFO-type, A may contain further parameters. Figure 2: Indeterminate derivation of P \nin LFO. a1 = a2,n1 =m1 LFO:Var a3 = a4,n2 =SIZE (A)+1+ a3 + m2 LFO:Cons a5 = b1,a6 = b2,a7 = b3,n3 =c,n3 \n-c+ d=m3 LFO:Fun a8 = a3,a9 = a5,a4 = a6,a10 = a7, n4 = n2,m2 = n3,m3 = m4 LFO:Let a12 = a1,a12 = a8,a11 \n= a9,a13 = a2,a13 = a10, n5 = n1,m5 = m1,n5 = n4 -SIZE (A) -1 -a11,m5 = m4 LFO:List-Elim c = n5,d = m5,b1 \n= a11,b2 = a12,b3 = a13 Valid program a1,...,a13,b1,...,b3,c,d,n1,...,n5,m1,...m5 =0 Nonnegativity There \nmay be further trivial constraints arising from the indeterminates in A. Figure 3: Constraints of LFO-derivation \nin Figure 2 After simpli.cation and elimination of all variables not occurring within the signature we \nare left with the following inequalities: x1 =x2 x1 =-(3 + l1)+(3 + l2)+ x2 x1 =-2(3 + l1)+2(3 + l2)+ \nx2 x1 =-3(3 + l1)+2(3 + l2)+ x1 -x2 + x2 x2 =x3 x2 =-(3 + l2)+(3 + l3)+ x3 x2 =-2(3 + l2)+3(3 + l3)+ \nx2 -x3 + x3 plus nonnegativity constraints. A sensible solution to these inequalities is tos :(L(B .B,0) \n,3) .(L(B .B,0) ,0) () sec :(L(B .B,0) ,3) .(LB .B, 32 ,0) () tpo :(LB .B, 23 ,0) .(L(B .B,0) ,0) Suppose \nwe want to apply tos to the list l stored at f in the heap s having length |l|= n. This list occupies \n3nheap cells (3 cells per node: a pair of booleans and one pointer, also see rule .O:Cons). According \nto the type of tos,0n+3 extra heap cells are required for evaluation (the additionally reserved heap \nspace for l,which is .(s,f,L(B .B,0)) = 0 plus 3 explicitly reserved cells). This amounts to 3n+3 heap \ncells in total. Now we .rst apply sec to l and call the resulting heap s ' Since sec destroys every third \nelement of the list, .. |sec(l)|= 2 n . Calculating the memory resources again, 3 .. now according to \nthe result type of sec yields: 3( 2 n )+ ().... 3 ' 22 2 .(s ,f,LB .B, )= 3( n )+ 3 n = 3n +3. The 3 \n323 memory cells freed by deleting list nodes of the input list allow an increase of additionally reserved \nheap space for the output list: Each deleted node frees three cells; as there are at least 2 remaining \nnodes per deleted node, the additional reserved heap space per node is 23 . The inequality shows a possible \nmemory leak of at most three cells in the case that l has length divisible by three. This is due to the \nfact that sec needs 3 additional cells to () ensure the type LB .B, 23 in the case that l has length \nn =3i+2 for some i.I. If the length is divisible by three, these extra resources are not needed, thus \nwasted. We notice that the toplevel function tos also exhibits a resource leak since the three additional \nunits required to call never show up in the result regardless of the length of the input. We remark that \ndeforestation , i.e., elimination of the intermediate result of the call to sec could overcome this. \nWhether this is an instance of a general pattern we cannot say at this point. While it should be clear \nthat fractional annotations de\u00adscribe the correct asymptotic behaviour one may wonder whether there might \nbe problems with concrete inputs since, for example, allocating 23 cells is not possible. Consider a \nlist l of length two, thus occupying 6 cells in view of SIZE (B .B .L(\u00b7)) = 3. Applying sec to l returns \n3 an identical version of l and because of the annotation 2 signals the availability of 3 = 2 \u00b7 23 cells \nthus returning the three extra cells requested by sec in this case. But now suppose that we match against \nthis list; the rule LFO:List-Elim then indicates the availability of 32 + 3 cells in the cons-branch. \nOf these, we can only use 4 immediately for storing operations on the heap. However, if we match again \nagainst the remaining part we gain access to the entire 9 = 6 + 3 cells. Recall that SIZE (A) .I.  8. \nINFERENCE FOR LFN< ,lin In this section we consider the problem of inferring deriva\u00adtions in the fragment \nLFO,lin from Section 5 which removes the sharing rule and restricts resource annotations to natu\u00adral \nnumbers. Clearly, such derivations for a given program P are in 1-1 correspondence to integral solutions \nof L(P). As is well-known .nding integral solutions of arbitrary LPs, let alone optimal ones, is an NP-hard \nproblem. However, we show that in a certain simpli.ed subcase we can e.ciently .nd integral solutions \nto L(P)thatare opti\u00admal with respect to any objective function c whose coe.\u00adcients are all nonnegative. \nAs we want to minimize resource consumption, this is a sensible assumption on the objective function \nin the simpli.ed subcase. Moreover, we show that in the general case .nding integral solutions is again \nfeasible whereas .nding optimal solutions is NP-hard. 8.1 Inferring toplevel annotations Suppose that \nwe are only interested in solutions where all variables that occur within zero-order (sub-)types are \nzero as well as the variables occurring to the right hand side of .rst-order types. In particular, we \nare looking at signatures of the form (A1,...,Ae,n) .(B,0) where the Ai and B are LFO-types with all \nannotations equal to zero. Inspection of the typing rules then shows that after simpli\u00ad.cation of equality \nconstraints the remaining system consists entirely of constraints of the form x0 =a1x1 + a2x2 + \u00b7\u00b7\u00b7+ \naexe + b where the xi are not necessarily distinct variables, the ai are nonnegative integer coe.cients, \nand b is an arbitrary inte\u00adger constant. The only typing rules which might produce inequalities not of \nthis form are LFO:Fun, LFO:Sum-Elim, LFO:List-Elim, but we know that here the problematic neg\u00adative variables \n(i.e. those occurring positively on the right hand side of the = or negatively on the left hand side) \nare all zero by the assumption made in the simpli.ed case. We call such a constraint almost positive. \nTheorem 2. Let ({x1,...,xd},C) be an LP where C consists entirely of almost positive constraints. Let \nc1,...,cd . I. The optimal integral solution of this LP with respect to the objective function c1x1 + \n...cdxd can be found in polynomial time. To prove this one shows that the optimal rational solution is \nnecessarily integral. For an example we consider the LP arising from Exam\u00adple 2. In the enriched signature \nthere are only three variables remaining in the simpli.ed case: sort :(L(A,0) ,xs) .(L(A,0) ,0) ins :(A,L(A,0) \n,xi) .(L(A,0) ,0) leq :(A.A,xl) .(B .(A.A) ,0) We do not give a concrete implementation of leq here and \njust assume that a call to leq does not require any resources. Therefore we immediately set xl := 0 throughout \nthis exam\u00adple. The actual value of SIZE (A) is unimportant. Now we derive the LP as usual, inserting \n0 whenever a new numerical value is needed within an LFOzero-order type or in the right-hand side of \na .rst-order type. After simplifying we are left with four almost positive con\u00adstraints: xi =SIZE (A)+1 \nxs =0 xi =2xi -(SIZE (A)+1) xi =0 hence xs =0 and xi = SIZE (A) + 1 would be the optimal solution for \nany objective function c1xs + c2xi with c1,c2 = 0. Many more programs fall under the simpli.ed subcase. \nThis includes the quicksort example in Section 9 and all the LFPL-examples contained in [8]. We remark \nthat setting the annotations contained in types and in result positions to .xed values other than zero \nalso leads to almost positive LPs. 8.2 Ef.cient solutions for the general case Let us call an LP almost \nconical if all inequalities are of one of the following two forms: a1x1 + \u00b7\u00b7\u00b7+ aexe =0 x=b where ai ..and \nb.I. In this case, the set of rational solutions is closed under multiplication with scalars .=1. Therefore, \nwe can obtain an integer solution from a rational solution by multiplying with the least common denominator. \nWe now show that for any LFlin -program P the LP L(P) can be transformed into an almost conical one by \nperforming a substitution of variables. Solving the resulting system and substituting back then yields \na solution of L(P). We observe that the only places where constants di.erent from zero are introduced \ninto constraints is via SIZE (\u00b7)in the rules LFO:Cons, LFO:List-Elim. The nonzero constants of the form \nSIZE (A) always occur together with the variable measuring the resource content of the corresponding \nlist type. Hence, grouping these constants together with their associated variables by a substitution \ncan be shown to yield an almost conical system. Theorem 3. Let P be a valid LFlin -program then there \nexists an almost conical ILP (V,C) and a nonnegative in\u00adteger vector c such that the solution set of \nL(P) is equal to {x-c|x solves C}. We remark that this result does not hold in the presence of rules \nLFO:Share and LFO:List-Elim . Corollary 2. There exists a polynomial time algorithm that given a valid \nLFlin -program P determines a solution of L (P ) if one exists and reports failure otherwise. Reconsidering \nExample 4 with this method yields: tos :(L(B . B, 3) , 6) . (L(B . B, 3) , 0) sec :(L(B . B, 3) , 6) \n. (L(B . B, 6) , 0) tpo :(L(B . B, 6) , 0) . (L(B . B, 3) , 0) We note that this integral solution requires \nadditional re\u00adsources three times the length of the input list, which are .nally left over after computation, \nwhereas the fractional solution shows that these are unnecessary as can also be seen by merging the de.nitions \nof tpo and sec into speci.c optimized linear functional code for tos. Although there are other integral \nsolutions for this ex\u00adample, the presented solution is (under certain aspects) the best integral solution. \nHowever we cannot guarantee this. While .nding a solution to an almost conical LP is feasible, .nding \nan optimal solution is not: Theorem 4. For every instance F of 3SAT with m vari\u00adables we can .nd an almost \nconical LP and an objective function so that a solution of objective value = n exists i. F is satis.able. \nMoreover, it was shown in [11] that such ILPs may indeed arise from inference problems. Hence we have: \nCorollary 3. Let P be a valid LF program. Finding an optimal solution of I (P ) with respect to a given, \narbitrary objective function is an NP-hard task. 9. EXAMPLES In this section we collect several illustrative \nexamples. Example 5. We demonstrate that the Quicksort algo\u00adrithm falls within the simpli.ed subcase \npresented in Sec\u00adtion 8.1: qsort :(L(A, 0) , 0) -. L(A, 0) split by :(A, L(A, 0) , 0) -. L(A, 0) . L(A, \n0) in.x = :(A . A, 0) . (B, 0) qsort(l)= match l with | nil . nil | cons(h, t) . match split by(h, t) \nwith u . l . qsort(u)++ cons(h, nil)++ qsort(l) split by(p, l)= match l with | nil . nil . nil | cons(h, \nt) . match split by(p, t) with u . l . if h = p then cons(h, u) . l else u . cons(h, l) Please note that \nthe standard functional implementation of quicksort, using a .ltering function twice with mutually ex\u00adclusive \n.lter conditions instead of split by, has no valid LFO-derivation. Calling the .lter twice requires the \ndupli\u00adcation of the input list, while the type information is not enough to deduce that the .lter cuts \ndown each copy so that the sum of the lengths of each list is equal to the original list.   The sharing \nof heap-allocated data structures may sim\u00adulate a duplication in some situations, but this of course \nrestricts the use to read-only access (except for the last ac\u00adcess) in order to prevent malignant sharing. \nThe following two examples show a sensible use of sharing and hence rely on rule LFO:Share; their evaluation \nexhibits no malignant sharing on all possible inputs so that Theo\u00adrem 1 applies. Example 6. For calculating \nthe length of a list it is con\u00advenient to assume a type representing a .nite part of the natural numbers \nand the presence of the usual arithmetic functions, e.g. N := B.32 . length :(L(A, 0) , 0) . (N, 0) length(l)= \nmatch ' l with | nil . 0 | cons(h, t) . 1+ length(t) Example 7. While the length of a list could still \nbe com\u00adputed in LFlin without destroying the list (length might im- O mediately rebuild the input list \nand return it together with the value for the length) at the cost of inconvenient pro\u00adgramming, the following \nexample exhibits proper sharing of heap-allocated data structures. This example uses a type T(A) of binary \ntrees whose internal nodes are labelled with A; leaves are unlabelled and represented by NULL. Its annotated \nversion is T(A, k). We have .(s, NULL, T(A, k)) = 0and .(s, f, T(A, k)) = k +.(s, s(f),A . T(A, k) . \nT(A, k)). Thus, the amount of resource associated with such a tree is k times the number of its internal \nnodes. pathlist :(T(A, 1) , 2) . (L(L(A, 0) , 0) , 0) pathacc :(T(A, 1) , L(A, 0) , 2) . (L(L(A, 0) , \n0) , 0) in.x++: (L(C, a) , L(C, a) , 0) . (L(C, a) , 0) As we referred to ++ a few times, we present \nhere a generic version. For this example it su.ces to set C = L(A, 0) and a := 0. pathlist(t)= pathacc(t, \nnil) pathacc(t, c)= match t with | leaf . cons(c, nil) | node(a, l, r) . let x=cons(a, c) in ()() pathaccl, \nx++ pathaccr, x ++(l, r)= match l with | nil . r | cons(h, t) . cons(h, t ++ r) The function pathlist \nturns a tree into a list of lists of booleans which contains the path from each leaf to the root. The \nnodes of the sublists (one for each leaf) are aliased among each other, thereby mimic the exact structure \nof the former tree within the heap, saving an exponential amount of space. 10. RELATED WORK Approaches \nbased on abstract interpretation and symbolic evaluation [7, 13, 4, 20, 5, 6] go in the direction of \nthe naive approach mentioned in the Introduction. The structure of the inferred resource bound matches \nthe structure of the program. Where the program contains a while loop or a re\u00adcursion the bounding function \nwill do so as well. This is not meant to diminish the value of those works: To begin the abstract interpretation \nremoves useless computation so that computing the bound . will in general be easier than run\u00adning f itself. \nThis can greatly simplify pro.ling and testing. Furthermore, in many cases the recurrences reminiscent \nof iteration constructs in the original code can be solved using various methods from computer algebra. \nWhat distinguishes our approach from these is that the resulting linear bounds once established are trivial \nto evalu\u00adate for concrete input lengths, that they are independently veri.able and that the algorithm \nfor their intention is prov\u00adably successful and e.cient in a well-delineated subset of programs which \ncomprises most textbook examples of func\u00adtional programming such as reversal, quicksort, insertion sort, \nheap sort, Hu.man codes, tree traversal, etc. Indeed, Unnikrishnan et al. [20] report performance problems \nwith medium-sized inputs and recommend to .t an algebraic ex\u00adpression into a value table obtained from \nsmall inputs. This is acceptable for pro.ling purposes but certainly not for re\u00adsource certi.cation. \nIn other works like [3] the user must provide a conjectured resource bound. The formalism can be used \nto validate it but even for the validation user interaction is required. Moreover, this work only accounts \nfor execution time not heap space. Another piece of well-known related work are Hughes and Pareto s sized \ntypes [10]. This system allows one to certify upper bounds on the number of constructor symbols in in\u00adductive \ndata types. For example List kA is thetypeof Lists of type A of length at most k, and accordingly append \nhas thetypeList k1 A . List (k2 +1) A . List (k1 + k2) A.A comparison to the type of the append function \n++from Ex\u00adample 7 reveals the di.erent use of the annotations: While the annotation of sized lists yields \nupper bounds on the length, our annotation is a multiplicative constant which does not restrict the length \nof lists of this type. The ap\u00adproaches are thus quite di.erent technically. Nevertheless, sized types \ncan also be used to infer space bounds. The transition from size to space is made via region\u00adbased memory \nmanagement [19] which however, imposes un\u00adnatural restrictions due to the fact that a given data struc\u00adture, \ne.g. a list, must reside entirely in one region. This prevents the analysis of computations in which \nlifetimes of data structures overlap, e.g. in the insertion sort algorithm according to \u00a75.7 of [10]. \nThe authors speculate on a possi\u00adble solution based on region resetting and liveness inference, but this \nis not worked out in [10] nor in the later [16]. We emphasize that proper dynamic memory allocation is \nnot modelled in [10]. This is acceptable in view of the intended application of sized types to embedded \nprogramming, but not in our opinion in a general functional programming context. Another possible advantage \nof inferring space bounds di\u00adrectly, as we do, could lie in improved e.ciency: Merely checking sized \ntype requires Presburger Arithmetic (com\u00adplete for doubly exponential time) compared to the poly\u00adnomial \ntime LP that we use. In this regard it would of course be interesting to know the exact complexity of \nsized type checking; more mundanely, whether the full strength of Presburger Arithmetic is really needed \nfor this problem. The feasibility of inference as opposed to checking is left unanswered in [16, 10]. \nUnlike [10] and [5] we do not analyse stack size in this paper. We think that the linear bounds on stack \nsize are often not adequate since typical algorithms can either be optimised using tail recursion to \nuse constant stack or use a stack of logarithmic size, e.g. divide-and-conquer methods. Furthermore, \nour system naturally encompasses trees, lists of trees, etc., whereas sized types seem to work pri\u00admarily \nfor linear data structures. While trees appear in the formal presentation in [16] none of the examples \nuses them; not even the type of the constructor for trees appears ex\u00adplicitly. On the other hand, [16] \ncontains a detailed and interesting account of in.nite lists (streams). An exploration of streams in \nour framework must be left to further research. 11. CONCLUSIONS We have presented an e.cient and automatic \nanalysis of heap usage of .rst-order functional programs. While we .nd that our analysis is surprisingly \nversatile and accurate there are a number of ways in which it can be improved. Our analysis sometimes \ngives too modest assumptions about the memory available after execution of a function. A typical example \nis flatten : L(L(A)) . L(A) assumed to be the natural implementation of .attening on lists of lists. \nCalling flatten(w) returns |w| heap space. However, our system assigns for example the type L(L(A,0) \n, 0) . L(A,0) hence not notifying the net resource-gain. To .x this particular case it is tempting to \nintroduce some kind of dependent typing allowing one to refer to the size or length of the input in the \ncost term of the result position. However, developing such a system whilst maintaining guar\u00adantees on \ne.cient solvability is a delicate matter and must be left for future research. As it stands, the system \nis sometimes insu.ciently poly\u00admorphic. Namely, it can happen that two usages of an already de.ned function \nrequire two di.erent annotations. Even if both these annotations are compatible with the de.\u00adnition of \nf only one of them can actually be assigned in LFO. Consider, for instance, the identity function f : \nL(B) . L(B) de.ned by f(x)= x.In LFOwe must assign a partic\u00adular type, say L(B, 5) , 3 . L(B, 5) , 3. \nIn this case, we are not able to apply f to an argument of type L(B, 0). To address this problem within \nthe framework of the given system we can split a program into blocks of mutually de\u00adpendent functions \nand perform the analysis separately for each of the blocks of de.nition. When using a function f outside \nits block of de.nition we can consider the entire LP of function f s de.nition rather than a particular \nsolution. This approach can be seen as a de.nitional extension if we consider each occurrence of f outside \nits de.ning block as the usage of an identical copy of f. If we also want to enable polymorphic recursion, \ni.e., a di.erent instantiation of constraint variables in every recur\u00adsive call, we must replace LFOwith \na constrained type sys\u00adtem whose judgments are of the form C, G,n f e:A,n where G,A,m,n may contain variables \nand C is a set of linear in\u00adequalities constraining these. The details are left for future work, but \nappear to be within the reach of the methods developed here. A similar issue arises with higher-order \nfunctions. Simple use of higher-order functions merely as a means for modular\u00adization such as in combinators \nlike map, filter,etc. can be accommodated by introducing several de.nitions, one for each usage, possibly \nhidden under some appropriate syn\u00adtactic sugar. Formally, this kind of usage of higher-order functions \nis the one supported by the C language: the only expressions of function types are variables and constants. \nIf we aim for more general function expressions like partially-applied functions and lambda expressions \nas in functional programming languages the problem of heap space inference becomes much more complicated \nas we need to monitor the size of closures which are much more depen\u00addent on dynamic aspects. This is \ndiscussed in some detail in [9]. We do not see at this point how our work could be extended to cover \ngeneral higher-order functions, not even linear ones. One referee suggested to investigate Reynolds idea \nof defunctionalisation [17] which eliminates closures in favour of sum types. Again, we leave this to \nfuture work. 12. REFERENCES [1] Mobile resource guarantees. EU Project No. IST-2001-33149, see http://www.dcs.ed.ac.uk/home/mrg/. \n [2] David Aspinall and Martin Hofmann. Another Type System for In-Place Update. In D. Le Metayer, editor, \nProgramming Languages and Systems (Proc. ESOP 02), volume Springer LNCS 2305, 2002. [3] K. Crary and \nS. Weirich. Resource bound certi.cation. In Proc. 27th Symp. Principles of Prog. Lang. (POPL), pages \n184 198. ACM, 2000. [4] P. Flajolet, B. Salvy, and P. Zimmermann. Lambda-Upsilon-Omega: An assistant \nalgorithms analyzer. In T. Mora, editor, Applied Algebra, Algebraic Algorithms and Error-Correcting Codes, \nvolume 357 of Lecture Notes in Computer Science, pages 201 212, 1989. Proceedings AAECC 6, Rome, July \n1988. [5] Gustavo G\u00b4omez and Yanhong A. Liu. Automatic accurate cost-bound analysis for high-level languages. \nIn Frank Mueller and Azer Bestavros, editors, Languages, Compilers, and Tools for Embedded Systems, ACM \nSIGPLAN Workshop LCTES 98, Montreal, Canada. Springer, 1998. LNCS 1474. [6] Gustavo G\u00b4omez and Yanhong \nA. Liu. Automatic time-bound analysis for a higher-order language. In Proceedings of the 2002 ACM SIGPLAN \nworkshop on Partial evaluation and semantics-based program manipulation, pages 75 86. ACM Press, 2002. \n[7] Bernd Grobauer. Topics in Semantics-based Program Manipulation. PhD thesis, BRICS Aarhus, 2001. [8] \nMartin Hofmann. A type system for bounded space and functional in-place update. Nordic Journal of Computing, \n7(4):258 289, 2000. An extended abstract has appeared in Programming Languages and Systems, G. Smolka, \ned., Springer LNCS, 2000. [9] Martin Hofmann. The strength of non size-increasing computation. 2002. \nProc. ACM Symp. on Principles of Programming Languages (POPL), Portland, Oregon. [10] J. Hughes and L. \nPareto. Recursion and dynamic data structures in bounded space: towards embedded ML programming. In Proc. \nInternational Conference on Functional Programming (ACM). Paris, September 99., pages 70 81, 1999. [11] \nSte.en Jost. Static prediction of dynamic space usage of linear functional programs, 2002. Diploma thesis \nat Darmstadt University of Technology, Department of Mathematics. Available at www.tcs.informatik. uni-muenchen.de/~jost/da_sj_28-02-2002.ps. \n[12] Naoki Kobayashi. Quasi-linear types. In Proceedings ACM Principles of Programming Languages, pages \n29 42, 1999. [13] H.-W. Loidl. Granularity in Large-Scale Parallel Functional Programming. PhD thesis, \nDepartment of Computing Science, University of Glasgow, 1998. [14] George Necula. Proof-carrying code. \nIn Proc. 24th Symp. Principles of Prog. Lang. (POPL). ACM, 1997. [15] Martin Odersky. Observers for linear \ntypes. In B. Krieg-Br\u00a8uckner, editor, ESOP 92: 4th European Symposium on Programming, Rennes, France, \nProceedings, pages 390 407. Springer-Verlag, February 1992. Lecture Notes in Computer Science 582. [16] \nLars Pareto. Types for crash prevention.PhD thesis, Chalmers University, G\u00a8oteborg, Sweden, 2000. [17] \nJohn C. Reynolds. De.nitional interpreters for higher-order programming languages. In Proceedings of \nthe 25th ACM National Conference, pages 717 740, 1972. [18] Natarajan Shankar. E.ciently executing PVS. \nTechnical report, Computer Science Laboratory, SRI International, 1999. [19] M. Tofte and J.-P. Talpin. \nRegion-based memory management. Information and Computation, 132(2):109 176, 1997. [20] Leena Unnikrishnan, \nScott D. Stoller, and Yanhong A. Liu. Automatic accurate live memory analysis for garbage-collected languages. \nIn Proceedings of The Workshop on Languages, Compilers, and Tools for Embedded Systems (LCTES 2001), \nJune 22-23, 2001 / The Workshop on Optimization of Middleware and Distributed Systems (OM 2001), June \n18, 2001, Snowbird, Utah, USA.   \n\t\t\t", "proc_id": "604131", "abstract": "We show how to efficiently obtain linear a priori bounds on the heap space consumption of first-order functional programs.The analysis takes space reuse by explicit deallocation into account and also furnishes an upper bound on the heap usage in the presence of garbage collection. It covers a wide variety of examples including, for instance, the familiar sorting algorithms for lists, including quicksort.The analysis relies on a type system with resource annotations. Linear programming (LP) is used to automatically infer derivations in this enriched type system.We also show that integral solutions to the linear programs derived correspond to programs that can be evaluated without any operating system support for memory management. The particular integer linear programs arising in this way are shown to be feasibly solvable under mild assumptions.", "authors": [{"name": "Martin Hofmann", "author_profile_id": "81452607849", "affiliation": "LMU M&#252;nchen, Institut f&#252;r Informatik, M&#252;nchen, Germany", "person_id": "PP14027136", "email_address": "", "orcid_id": ""}, {"name": "Steffen Jost", "author_profile_id": "81100111171", "affiliation": "LMU M&#252;nchen, Institut f&#252;r Informatik, M&#252;nchen, Germany", "person_id": "P414189", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/604131.604148", "year": "2003", "article_id": "604148", "conference": "POPL", "title": "Static prediction of heap space usage for first-order functional programs", "url": "http://dl.acm.org/citation.cfm?id=604148"}