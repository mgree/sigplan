{"article_publication_date": "01-15-2003", "fulltext": "\n Selective Memoization * Umut A. Acar Guy E. Blelloch Robert Harper School of Computer Science Carnegie \nMellon University Pittsburgh, PA 15213 {umut,blelloch,rwh}@cs.cmu.edu Abstract We present a framework \nfor applying memoization selectively. The framework provides programmer control over equality, space \nus\u00adage, and identi.cation of precise dependences so that memoiza\u00adtion can be applied according to the \nneeds of an application. Two key properties of the framework are that it is ef.cient and yields programs \nwhose performance can be analyzed using standard tech\u00adniques. We describe the framework in the context \nof a functional language and an implementation as an SML library. The language is based on a modal type \nsystem and allows the programmer to express pro\u00adgrams that reveal their true data dependences when executed. \nThe SML implementation cannot support this modal type system stati\u00adcally, but instead employs run-time \nchecks to ensure correct usage of primitives. Categories and Subject Descriptors D.3.0 [Programming \nLanguages]: General; F.2.0 [Analysis of Algorithms and Problem Complexity]: [General]; D.3.1 [Programming \nLanguages]: Formal De.nitions and Theory; D.3.3 [Programming Languages]: Language Constructs and Fea\u00adtures \nControl Structures General Terms Languages, Performance, Algorithms Keywords Memoization, selective, \nprogrammer controlled, performance * This research was supported in part by NSF grants CCR-9706572, CCR-0085982, \nand CCR-0122581. Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. POPL 03, January 15 17, 2003, New Orleans, Louisiana, USA. Copyright 2003 ACM 1-58113-628-5/03/0001 \n...$5.00 1 Introduction Memoization is a fundamental and powerful technique for result re-use. It dates \nback a half century [7, 21, 22] and has been used extensively in many areas such as dynamic programming \n[4, 9, 10, 19], incremental computation [11, 34, 12, 36, 16, 1, 37, 20, 14, 2], and many others [8, 23, \n17, 25, 26, 20]. In fact, lazy evaluation provides a limited form of memoization [18]. Although memoization \ncan dramatically improve performance and can require only small changes to the code, no language or library \nsupport for memoization has gained broad acceptance. Instead, many successful uses of memoization rely \non application-speci.c support code. The underlying reason for this is one of control: since memoization \nis all about performance, the user must be able to con\u00adtrol the performance of memoization. Many subtleties \nof memoiza\u00adtion, including the cost of equality checking and the cache replace\u00adment policy for memo tables, \ncan make the difference between ex\u00adponential and linear running time. To be general and widely applicable \na memoization framework must provide control over these three areas: (1) the kind and cost of equality \ntests; (2) the identi.cation of precise dependences be\u00adtween the input and the output of memoized code; \nand (3) space management. Control over equality tests is critical, because this is how re-usable results \nare identi.ed. Control over identi.cation of precise dependences is important to maximize result reuse. \nBe\u00ading able to control when memo tables or individual their entries are purged is critical, because otherwise \nthe user will not know whether or when results are re-used. In this paper, we propose a framework for \nmemoization that pro\u00advides control over equality and identi.cation of dependences, and some control over \nspace management. We study the framework in the context of a small language called MFL and provide an \nimple\u00admentation for it in the Standard ML language. We also prove the type safety and correctness of \nMFL i.e., that the semantics are pre\u00adserved with respect to a non-memoized version. As an example, we \nshow how to analyze the performance of a memoized version of Quicksort within our framework. In the next \nsection we describe background and related work. In Section 3 we introduce our framework via some examples. \nIn Sec\u00adtion 4 we formalize the MFL language and discuss its safety, cor\u00adrectness, and performance properties. \nIn Section 5 we present a simple implementation of the framework as a Standard ML library. In Section \n6 we discuss how the framework might be extended to allow for better control of space usage, and discuss \nthe relationship of this work to our previous work on adaptive computation [2]. 2 Background and Related \nWork A typical memoization scheme maintains a memo table mapping argument values to previously computed \nresults. This table is con\u00adsulted before each function call to determine if the particular ar\u00adgument \nis in the table. If so, the call is skipped and the result is returned; otherwise the call is performed \nand its result is added to the table. The semantics and implementation of the memo lookup are critical \nto performance. Here we review some key issues in im\u00adplementing memoization ef.ciently. Equality. Any \nmemoization scheme needs to search a memo ta\u00adble for a match to the current arguments. Such a search \nwill, at minimum, require a test for equality. Typically it will also require some form of hashing. In \nstandard language implementations test\u00ading for equality on structures, for example, can require traversing \nthe whole structure. The cost of such an equality test can negate the advantage of memoizing and may \neven change the asymptotic behavior of the function. A few approaches have been proposed to alleviate \nthis problem. The .rst is based on the fact that for memo\u00adization equality need not be exact it can return \nunequal when two arguments are actually equal. The implementation could therefore decide to skip the \ntest if the equality is too expensive, or could use a conservative equality test, such as location equality. \nThe problem with such approaches is that whether a match is found could depend on particulars of the \nimplementation and will surely not be evident to the programmer. Another approach for reducing the cost \nof equality tests is to en\u00adsure that there is only one copy of every value, via a technique known as \nhash consing [13, 5, 35]. If there is only one copy, then equality can be implemented by comparing locations. \nIn fact, the location can also be used as a key to a hash table. In theory, the overhead of hash-consing \nis constant in the expected case (expecta\u00adtion is over internal randomization of hash functions). The \nreality, however, is rather different because of large memory demands of hash-consing and its interaction \nwith garbage collection. In fact, several researchers have argued that hash-consing is too expensive \nfor practical purposes [32, 33, 6, 24]. As an alternative to hash con\u00adsing, Pugh proposed lazy structure \nsharing [32]. In lazy structure sharing whenever two equal values are compared, they are made to point \nto the same copy to speed up subsequent comparisons. As Pugh points out, the disadvantage of this approach \nis that the per\u00adformance depends on the order comparisons and thus it is dif.cult to analyze. We note \nthat even with hash-consing, or any other method, it re\u00admains critical to de.ne equality on all types \nincluding reals and functions. Claiming that functions are never equivalent, for exam\u00adple, is not satisfactory \nbecause the result of a call involving some function as a parameter will never be re-used. Precise Dependences. \nTo maximize result re-use, the result of a function call must be stored with respect to its true dependences. \nThis issue arises when the function examines only parts or an ap\u00adproximation of its parameter. To enable \npartial equality checks, the unexamined parts of the parameter should be disregarded. To increase the \nlikelihood of result re-use, one should be able to match on the approximation, rather than the parameter \nitself. As an exam\u00adple, consider the code fun f(x,y,z) = if (x > 0) then fy(y) else fz(z) The result \nof f depends on either (x,y) or (x,z). Also, it depends on an approximation of x whether or not it is \npositive rather than its exact value. Thus, the memo entry (7,11,20) should match (7,11,30) or (4,11,50) \nsince, when x is positive, the result de\u00adpends only on y. Several researchers have remarked that partial \nmatching can be very important in some applications [28, 27, 1, 14]. Abadi, Lampson, L\u00b4evy [1], and Heydon, \nLevin, Yu [14] have suggested program anal\u00adysis methods for tracking dependences for this purpose. Although \ntheir technique is likely effective in catching potential matches, it does not provide a programmer controlled \nmechanism for speci\u00adfying what dependences should be tracked. Also, their program analysis technique \ncan change the asymptotic performance of a pro\u00adgram, making it dif.cult to asses the effects of memoization. \nSpace management. Another problem with memoization is its space requirement. As a program executes, its \nmemo tables can become large limiting the utility of memoization. To alleviate this problem, memo tables \nor individual entries should be disposed of under programmer control. In some application, such as in \ndynamic programming, most result re-use occurs among the recursive calls of some function. Thus, the \nmemo table of such a function can be disposed of whenever it ter\u00adminates. In other applications, where \nresult re-use is less structured, individual memo table entries should be purged according to a re\u00adplacement \npolicy [15, 33]. The problem is to determine what exact replacement policy should be used and to analyze \nthe performance effects of the chosen policy. One widely used approach is to replace the least recently \nused entry. Other, more sophisticated, policies have also been suggested [33]. In general the replacement \npolicy must be application-speci.c, because, for any .xed policy, there are programs whose performance \nis made worse by that choice [33]. 3 A Framework for Selective Memoization We present an overview of \nour framework via some examples. The framework extends a purely functional language with several con\u00adstructs \nto support selective memoization. In this section, we use an extension to an ML-like language for the \ndiscussion. We formal\u00adize the core of this language and study its safety, soundness, and performance \nproperties in Section 4. The framework enables the programmer to determine precisely the dependences \nbetween the input and the result of a function. The main idea is to deem the parameters of a function \nas resources and provide primitives to explore incrementally any value, including the underlying value \nof a resource. This incremental exploration pro\u00adcess reveals the dependences between the parameter of \nthe function and its result. The incremental exploration process is guided by types. If a value has the \nmodal type ! t, then the underlying value of type t can be bound to an ordinary, unrestricted variable \nby the let! construct; this will create a dependence between the underlying value and the result. If \na value has a product type, then its two parts can be bound to two resources using the let* construct; \nthis creates no dependences. If the value is a sum type, then it can be case analyzed using the mcase \nconstruct, which branches according to the outermost form of the value and assigns the inner value to \na resource; mcase creates a dependence on the outer form of the value of the resource. The key aspect \nof the let* and mcase is that they bind resources rather than ordinary variables. Non-memoized Memoized \nfun fib (n:int)= if (n < 2) then n else fib(n-1) + fib(n-2) mfun mfib (n :!int)= let !n = n in return \n( if (n < 2) then n else mfib(!(n-1)) + mfib(!(n-2))) end fun f (x:int, y:int, z:int)= if (x > 0) then \nfy y else fz z mfun mf (x :int, y :!int, z :!int)= mif (x > 0) then let !y = y in return (fy y) end else \nlet !z = z in return (fz z) end Figure 1. Fibonacci and expressing partial dependences. Exploring the \ninput to a function via let!, mcase, and let* builds a branch recording the dependences between the input \nand the re\u00adsult of the function. The let! adds to the branch the full value, the mcase adds the kind \nof the sum, and let* adds nothing. Con\u00adsequently, a branch contains both data dependences (from let! \ns) and control dependences (from mcase s). When a return is en\u00adcountered, the branch recording the revealed \ndependences is used to key the memo table. If the result is found in the memo table, then the stored \nvalue is returned, otherwise the body of the return is evaluated and the memo table is updated to map \nthe branch to the result. The type system ensures that all dependences are made explicit by precluding \nthe use of resources within return s body. As an example consider the Fibonacci function fib and its \nmemo\u00adized counterpart mfib shown in Figure 1. The memoized version, mfib, exposes the underlying value \nof its parameter, a resource, before performing the two recursive calls as usual. Since the re\u00adsult depends \non the full value of the parameter, it has a bang type. The memoized Fibonacci function runs in linear \ntime as opposed to exponential time when not memoized. Partial dependences between the input and the \nresult of a function can be captured by using the incremental exploration technique. As an example consider \nthe function f shown in Figure 1. The function checks whether x is positive or not and returns fy(y) \nor fz(z). Thus the result of the function depends on an approximation of x (its sign) and on either y \nor z. The memoized version mf captures this by .rst checking if x is positive or not and then exposing \nthe underlying value of y or z accordingly. Consequently, the result will depend on the sign of x and \non either y or z . Thus if mf is called with parameters (1,5,7) .rst and then (2,5,3), the result will \nbe found in the memo the second time, because when x is positive the result depends only on y . Note \nthat mif construct used in this example is just a special case of the more general mcase construct. A \ncritical issue for ef.cient memoization is the implementation of memo tables along with lookup and update \noperations on them. In our framework we support expected constant time memo table lookup and update operations \nby representing memo tables using hashing. To do this, we require that the underlying type t of a modal \ntype !t be an indexable type. An indexable type is associ\u00adated with an injective function, called an \nindex function, that maps each value of that type to a unique integer; this integer is called the index \nof the value. The uniqueness property of the indices for a given type ensures that two values are equal \nif and only if their indices are equal. In our framework, equality is only de.ned for Non-memoized Memoized \ntype irl=(int*real) list type irl=(int*real) blist fun ks (c:int,l:irl) = mfun mks (c :!int,l :!irl) \nlet !c=c in let !l = l in return ( caselof case (unbox l) of nil => 0 NIL=>0 |(w,v)::t => | CONS((w,v),t) \n=> if(c<w) then if(c<w) then ks (c,t) mks(!c,!t) else let else let v1 = ks(c,t) v1 = mks(!c,!t) v2 = \nv+ks(c-w,t) v2 = v+mks(!(c-w),!t) in in if (v1>v2) then v1 if (v1>v2) then v1 else v2 else v2 end end) \nend end Figure 2. Memo tables for memoized Knapsack can be dis\u00adcarded at completion. indexable types. \nThis enables us to implement memo tables as hash tables keyed by branches consisting of indices. We assume \nthat each primitive type comes with an index function. For examples, for integers, the identity function \ncan be chosen as the index function. Composite types such as lists or functions must be boxed to obtain \nan indexable type. A boxed value of type t has type t box. When a box is created, it is assigned a unique \nlocations (or tag), and this location is used as the unique index of that boxed value. For example, we \ncan de.ne boxed lists as follows. datatype a blist = NIL | CONS of a *((a blist ) box) type a blist = \n(a blist ) box Based on boxes we implement hash-consing as a form of memoiza\u00adtion. For example, hash-consing \nfor boxed lists can be implemented as follows. mfun hCons (h :!a), t :!(a blist)) = let!h=h in let !t=t \nin return (box (CONS(h,t))) end end The function takes an item and a boxed list and returns the boxed \nlist formed by consing them. Since the function is memoized, if it is ever called with two values that \nare already hash-consed, then the same result will be returned. The advantage of being able to de\u00ad.ne \nhash-consing as a memoized function is that it can be applied selectively. To control space usage of \nmemo tables, our framework gives the programmer a way to dispose of memo tables by conventional scop\u00ading. \nIn our framework, each memoized function is allocated its own memo table. Thus, when the function goes \nout of scope, its memo table can be garbage collected. For example, in many dynamic-programming algorithms \nresult re-use occurs between re\u00adcursive calls of the same function. In this case, the programmer can \nscope the memoized function inside an auxiliary function so that its memo table is discarded as soon \nas the auxiliary function returns. As an example, consider the standard algorithm for the Knapsack Problem \nks and its memoized version mks Figure 2. Since result sharing mostly occurs among the recursive calls \nof mks, it can be scoped in some other function that calls mks; once mks returns its memo table will \ngo out of scope and can be discarded. We note that this technique gives only partial control over space \nusage. In particular it does not give control over when individual Non-memoized Memoized empty = box \nNIL fun fil (g:int->bool, fun mfil (g:int->bool, l:int list) = l:int blist)= case l of case (unbox l) \nof nil=>nil NIL => empty |h::t=> | CONS(h,t) => let let tt = fil(g,t) tt = mfil(g,t) in in case (g h) \nof case (g h) of true => h::tt true => hCons(h,tt) |false => tt |false => tt end end fun qs (l:int list) \n= mfun mqs (l :int blist) = let !l =l in return ( case l of case (unbox l) of nil=>nil NIL=>nil | cons(h,t) \n=> | CONS(h,t) => let let s = fil(fn x=>x<h,t) s = mfil(fn x=>x<h,t) g = fil(fn x=>x>=h,t) g = mfil(fn \nx=>x>=h,t) in in (qs s)@(h::(qs g)) (mqs s)@(h::(mqs g)) end end) end Figure 3. The Quicksort algorithm. \nmemo table entries are purged. In Section 6, we discuss how the framework might be extended so that each \nmemo table is managed according to a programmer speci.ed caching scheme. The basic idea is to require \nthe programmer to supply a caching scheme as a parameter to the mfun and maintain the memo table according \nto the chosen caching scheme. Memoized Quicksort. As a more sophisticated example, we con\u00adsider Quicksort. \nFigure 3 show an implementation of the Quicksort algorithm and its memoized counterpart. The algorithm \n.rst di\u00advides its input into two lists containing the keys less than the pivot, and greater than the \npivot by using the .lter function fil. It then sorts the two sublists, and returns the concatenation \nof the results. The memoized .lter function mfil uses hash-consing to ensure that there is only one copy \nof each result list. The memoized Quicksort algorithm mqs exposes the underlying value of its parameter \nand is otherwise similar to qs. Note that mqs does not build its result via hash-consing it can output \ntwo copies of the same result. Since in this example the output of mqs is not consumed by any other func\u00adtion, \nthere is no need to do so. Even if the result were consumed by some other function, one can choose not \nto use hash-consing be\u00adcause operations such as insertions to and deletions from the input list will \nsurely change the result of Quicksort. When the memoized Quicksort algorithm is called on similar in\u00adputs, \none would expect that some of the results would be re-used. Indeed, we show that the memoized Quicksort \nalgorithm computes its result in expected linear time when its input is obtained from a previous input \nby inserting a new key at the beginning. Here the expectation is over all permutations of the input list \nand also the internal randomization of the hash functions used to implement the memo tables. For the \nanalysis, we assume, without loss of general\u00adity, that all keys in the list are unique. Theorem 1 Let \nL be a list and let L!=[a,L]. Consider running memoized Quicksort on L and then on L!. The running time \nof Quicksort on the modi.ed list L!is expected O(n)where n is the length of L!. Figure 4. The recursion \ntree for Quicksort with in\u00adputs L =[15,30,26,1,3,16,27,9,35,4,46,23,11,42,19](left) and L!=[20,L](right). \nProof: Consider the recursion tree of Quicksort with input L, de\u00adnoted Q(L), and label each node with \nthe pivot of the correspond\u00ading recursive call (see Figure 4 for an example). Consider any pivot (key) \np from L and let Lp denote the keys that precede p in L.It is easy to see that a key k is in the subtree \nrooted at p if and only if the following two properties are satis.ed for any key k!.Lp. 1. If k!< p then \nk > k!, and 2. if k!> p then k < k!.  Of the keys that are in the subtree of p, those that are less \nthan p are in its left subtree and those greater than p are in its right subtree. Now consider the recursion \ntree Q(L!)for L!=[a,L]and let p be any pivot in Q(L!). Suppose p < a and let k be any key in the left \nsubtree of p in Q(L). Since k < p, by the two properties k is in the left subtree of p in Q(L!). Similarly \nif p > a then any k in the right subtree of p in Q(L)is also in the right subtree of p in Q(L!). Since \n.ltering preserves the respective order of keys in the input list, for any p, p < a, the input to the \nrecursive call corresponding to its left child will be the same. Similarly, for p > a, the input to the \nrecursive call corresponding to its right child will be the same. Thus, when sorting L!these recursive \ncalls will .nd their results in the memo. Therefore only recursive calls corresponding to the root, to \nthe children of the nodes in the rightmost spine of the left subtree of the root, and the children of \nthe nodes in the leftmost spine of the right subtree of the root may be executed (the two spines are \nshown with thick lines in Figure 4). Furthermore, the results for the calls adjacent to the spines will \nbe found in the memo. Consider the calls whose results are not found in the memo. In the worst case, \nthese will be all the calls along the two spines. Consider the sizes of inputs for the nodes on a spine \nand de.ne the random variables X1 ...Xk such that Xi is the least number of recursive calls i 3 (nodes) \nperformed for the input size to become n or less after (i-1)4 3 it .rst becomes n or less. Since k =[log4/3 \nnl, the total and the expected number of operations along a spine are [log4/3 nl i-1 C(n) = . Xi3 n, \nand 4 i=1 [log4/3 nl i-1 3 E[C(n)] = . E[Xi]4n. i=1  Since the probability that the pivot lies in \nthe middle half of the list is 12, E[Xi] =2 for i =1, and we have [log4/3 nl i-1 E[C(n)] = . 23 n. 4 \ni=1 Thus, E[C(n)] = O(n) This bound holds for both spines; therefore the number of operations due to \ncalls whose results are not found in the memo is O(n). Since each operation, including hash-consing, \ntakes expected constant time, the total time of the calls whose results are not in the memo is O(n). \nNow, consider the calls whose results are found in the memo, each such call will be on a spine or adjacent \nto it, thus there are an expected O(logn) such calls. Since, the memo table lookup overhead is expected \nconstant time the total cost for these is O(log n). We conclude that Quicksort will take expected O(n) \ntime for sorting the modi.ed list L! . . It is easy to extend the theorem to show that the O(n) bound \nholds for an insertion anywhere in the list. Although, this bound is better than a complete rerun, which \nwould take O(nlog n), we would like to achieve O(logn). In Section 6 we discuss how a combination of \nmemoization and adaptivity [2] may be used to reduce the expected cost of a random insertion to O(log \nn). 4 MFL In this section we study a small functional language, called MFL, that supports selective memoization. \nMFL distinguishes memo\u00adized from non-memoized code, and is equipped with a modality for tracking dependences \non data structures within memoized code. This modality is central to our approach to selective memoization, \nand is the focus of our attention here. The main result is a soundness theorem stating that memoization \ndoes not affect the outcome of a computation compared to a standard, non-memoizing semantics. We also \nshow that the memoization mechanism of MFL causes a constant factor slowdown compared to a standard, \nnon-memoizing semantics.  4.1 Abstract Syntax The abstract syntax of MFL is given in Figure 5. The \nmeta-variables x and y range over a countable set of variables. The meta-variables a and b range overf \na countable set of resources. (The distinction will be made clear below.) The meta-variable l ranges \nover a count\u00adable set of locations. We assume that variables, resources, and lo\u00adcations are mutually \ndisjoint. The binding and scope conventions for variables and resources are as would be expected from \nthe syn\u00adtactic forms. As usual we identify pieces of syntax that differ only in their choice of bound \nvariable or resource names. A term or ex\u00adpression is resource-free if and only if it contains no free \nresources, and is variable-free if and only if it contains no free variables. A closed term or expression \nis both resource-free and variable-free; otherwise it is open. The types of MFL include 1 (unit), int, \nproducts and sums, recur\u00adsive data types \u00b5u.t, memoized function types, and bang types ! .. MFL distinguishes \nindexable types, denoted ., as those that accept an injective function, called an index function, whose \nco-domain is integers. The underlying type of a bang type ! . is restricted to be an indexable type. \nFor int type, identity serves as an index function; for 1 (unit) any constant function can be chosen \nas the index function. For non-primitive types an index can be supplied by boxing values of these types. \nBoxed values would be allocated Ix. Types . :: = 1 |int |... Types t :: = . |! . |t1 \u00d7t2 |t1 + t2 |\u00b5u.t \n|t1 .t2 Op s o :: = + |-|... Expr s Terms e t :: = :: = return(t) |let ! x:.be t in eend |let a1:t1\u00d7a2:t2 \nbe t in eend |mcase t of inl (a1:t1) .e1 |inr (a2:t2) .e2 v |o(t1,... ,tn ) |(t1,t2 )|mfun f (a:t1):t2 \nis eend |t1 t2 |! t |inlt1+t2 t |inrt1+t2 t |roll(t) |unroll(t) Values v :: = x |a |* |n |! v |(v1,v2)|mfunl \nf (a:t1):t2 is eend Figure 5. The abstract syntax of MFL. in a store and the unique location of a box \nwould serve as an index for the underlying value. With this extension the indexable types would be de.ned \nas . :: = 1 |int |t box. Although supporting boxed types is critical for practical purposes, we do not \nformalize this here to focus on the main ideas. The syntax is structured into terms and expressions, \nin the terminol\u00adogy of Pfenning and Davies [30]. Roughly speaking, terms evaluate independently of their \ncontext, as in ordinary functional program\u00adming, whereas expressions are evaluated relative to a memo \ntable. Thus, the body of a memoized function is an expression, whereas the function itself is a term. \nNote, however, that the application of a function is a term, not an expression; this corresponds to the \nen\u00adcapsulation of memoization with the function, so that updating the memo table is benign. In a more \ncomplete language we would in\u00adclude case analysis and projection forms among the terms, but for the sake \nof simplicity we include these only as expressions. We would also include a plain function for which \nthe body is a term. Note that every term is trivially an expression; the return expres\u00adsion is the inclusion. \n 4.2 Static Semantics The type structure of MFL extends the framework of Pfenning and Davies [30] with \na necessitation modality, ! ., which is used to track data dependences for selective memoization. This \nmodality does not correspond to a monadic interpretation of memoization effects (Ot in the notation of \nPfenning and Davies), though one could imagine adding such a modality to the language. The intro\u00adductory \nand eliminatory forms for necessity are standard, namely ! t for introduction, and let ! x:. be t in \neend for elimination. Our modality demands that we distinguish variables from re\u00adsources. Variables in \nMFL correspond to the validity , or unre\u00adstricted , context in modal logic, whereas resources in MFL \ncorre\u00adspond to the truth , or restricted context. An analogy may also be made to the judgmental presentation \nof linear logic [29, 31]: variables correspond to the intuitionistic context, resources to the linear \ncontext.1 1Note, however, that we impose no linearity constraints in our type system! Var, Res (G(x)=t) \n(.(a)=t) G;.fx:t G;.fa:t Unit &#38; Nums G;.fn : int G;.f* :1 G;.fti : ti (1 =i =n) fo o : (t1,... ,tn)t \n Prim G;.fo(t1,... ,tn) : t G;.ft1: t1 G;.ft2: t2 Pairs G;.f(t1,t2 ): t1 \u00d7t2 G, f :t1 .t2;.,a:t1 fe : \nt2 Fun G;.fmfun f (a:t1):t2 is eend : t1 .t2 G, f :t1 .t2;.,a:t1 fe : t2 FunVal G;.fmfunlf (a:t1):t2 \nis eend : t1 .t2 G;.ft1: t1 .t2 G;.ft2: t1 Apply G;.ft1 t2: t2 Bang G;0/ft : . G;.f!t : ! . G;.ft : t1 \nInl, Inr G;.finlt1+t2 t : t1 +t2 G;.ft : t2 G;.finrtt : t1 +t2 1+t2 G;.ft : [\u00b5u.t/u]t (Un)Roll G;.froll(t) \n: \u00b5u.t G;.ft : \u00b5u.t G;.funroll(t) : [\u00b5u.t/u]t Figure 6. Typing judgments for terms. The inclusion, return(t), \nof terms into expressions has no ana\u00adlogue in pure modal logic, but is speci.c to our interpretation \nof memoization as a computational effect. The typing rule for return(t) requires that t be resource-free \nto ensure that any de\u00adpendence on the argument to a memoized function is made explicit in the code before \ncomputing the return value of the function. In the .rst instance, resources arise as parameters to memoized \nfunctions, with further resources introduced by their incremental decomposi\u00adtion using let\u00d7and mcase. \nThese additional resources track the usage of as-yet-unexplored parts of a data structure. Ultimately, \nthe complete value of a resource may be accessed using the let! construct, which binds its value to a \nvariable, which may be used without restriction. In practice this means that those parts of an argument \nto a memoized function on whose value the function de\u00adpends will be given modal type. However, it is \nnot essential that all resources have modal type, nor that the computation depend upon every resource \nthat does have modal type. The static semantics of MFL consists of a set of rules for deriving typing \njudgments of the form G;.ft : t, for terms, and G;.fe : t, for expressions. In these judgments Gis a \nvariable type assignment, a .nite function assigning types to variables, and .is a resource type assignment, \na .nite function assigning types to resources. The rules for deriving these judgments are given in Figures \n6 and 7. G;0/ft : t Return G;.freturn(t) : t G;.ft : ! .G,x:.;.fe : t Let! G;.flet ! x:.be t in eend \n: t G;.ft : t1 \u00d7t2 G;.,a1:t1,a2:t2 fe : t Let\u00d7 G;.flet a1:t1\u00d7a2:t2 be t in eend : t G;. f t : t1 +t2 \nG;.,a1:t1 f e1: t G;.,a2:t2 f e2: t Case G;.fmcase t ofinl (a1:t1) . e1: t | inr (a2:t2) . e2 Figure \n7. Typing judgments for expressions. 4.3 Dynamic Semantics The dynamic semantics of MFL formalizes selective \nmemoization. Evaluation is parameterized by a store containing memo tables that track the behavior of \nfunctions in the program. Evaluation of a function expression causes an empty memo table to be allocated \nand associated with that function. Application of a memoized function is affected by, and may affect, \nits associated memo table. Should the function value become inaccessible, so also is its associated memo \ntable, and hence the storage required for both can be reclaimed. Unlike conventional memoization, however, \nthe memo table is keyed by control .ow information rather than by the values of ar\u00adguments to memoized \nfunctions. This is the key to supporting se\u00adlective memoization. Expression evaluation is essentially \nan explo\u00adration of the available resources culminating in a resource-free term that determines its value. \nSince the exploration is data-sensitive, only certain aspects of the resources may be relevant to a particular \noutcome. For example, a memoized function may take a pair of integers as argument, with the outcome determined \nindependently of the second component in the case that the .rst is positive. By recording control-.ow \ninformation during evaluation, we may use it to provide selective memoization. For example, in the situation \njust described, all pairs of the form (0,v)should map to the same result value, irrespective of the value \nv. In conventional memoization the memo table would be keyed by the pair, with the result that redundant \ncomputation is performed in the case that the function has not previously been called with v,even though \nthe value of v is irrelevant to the result! In our framework we instead key the memo table by a branch \nthat records suf.cient control .ow information to capture the general case. Whenever we encounter a return \nstatement, we query the memo table with the current branch to determine whether this result has been \ncomputed before. If so, we return the stored value; if not, we evaluate the return statement, and associate \nthat value with that branch in the memo table for future use. It is crucial that the returned term not \ncontain any resources so that we are assured that its value does not change across calls to the function. \nThe dynamic semantics of MFL is given by a set of rules for deriving te ! judgments of the form s,t .v,s! \n(for terms) and s,l:\u00df,e .v,s(for expressions). The rules for deriving these judgments are given in Figures \n8 and 9. These rules make use of branches, memo tables, and stores, whose precise de.nitions are as follows. \nA simple branch is a listof simple events corresponding to choice points in the evaluation of an expression. \nSimple Event e :: = !v | inl | inr Simple Branch \u00df :: = | e \u00b7\u00df We write \u00df.e to stand for the extension \nof \u00df with the event e at the end. A memo table, ., is a .nite function mapping simple branches to values. \nWe write .[\u00df . v], where \u00df ./dom(.), to stand for the extension of . with the given binding for \u00df. We \nwrite .(\u00df) . to mean that \u00df ./dom(.). A store, s, is a .nite function mapping locations, l, to memo tables. \nWe write s[l . dom(s), to stand for the extension of . .], where l /s with the given binding for l. When \nl . dom(s), we write s[l . .] for the store s that maps l to . and l! = l to s(l!). Term evaluation is \nlargely standard, except for the evaluation of (memoizing) functions and applications of these to arguments. \nEvaluation of a memoizing function term allocates a fresh memo ta\u00adble, which is then associated with \nthe function s value. Expression evaluation is initiated by an application of a memoizing function to \nan argument. The function value determines the memo table to be used for that call. Evaluation of the \nbody is performed relative to that table, initiating with the null branch. Expression evaluation is performed \nrelative to a current memo table and branch. When a return statement is encountered, the current memo \ntable is consulted to determine whether or not that branch has previously been taken. If so, the stored \nvalue is re\u00adturned; otherwise, the argument term is evaluated, stored in the current memo table at that \nbranch, and the value is returned. The let! and mcase expressions extend the current branch to re.ect \ncontrol .ow. Since let! signals dependence on a complete value, that value is added to the branch. Case \nanalysis, however, merely extends the branch with an indication of which case was taken. The let\u00d7 construct \ndoes not extend the branch, because no additional information is gleaned by splitting a pair. 4.4 Soundness \nof MFL We will prove the soundness of MFL relative to a non-memoizing semantics for the language. It \nis straightforward to give a purely functional semantics to the pure fragment of MFL by an inductive \nde.nition of the relations t .tp v and e .ep v. Here t, e, and v are pure in the sense that they may \nnot involve subscripted function values. The underlying term, t-,ofan MFL term, t, is obtained by erasing \nall location subscripts on function values occurring within t. The soundness of MFL consists of showing \nthat evaluation with memoization yields the same outcome as evaluation without mem\u00adoization. Theorem \n2 (Soundness) - If 0/,t .t v,s, where 0/;0/ f t : t, then t-.t v. p The full proof is given in [3]. The \nstatement of the theorem must be strengthened considerably to account for both terms and expres\u00adsions, \nand to take account of non-empty memoization contexts. The proof then proceeds by induction on evaluation. \nIt is easy to show that the non-memoizing semantics of MFL is type safe, using completely conventional \ntechniques. It follows that the Unit s,* .t *,s Number s,n .t n,s s,t1 .t v1,s1 . . . sn-1,tn .t vn,sn \nv = app(o,(v1,... ,vn )) PrimOp s,o(t1,... ,tn ) .t v,sn s,t1 .t v1,s! s!.t v2,s!! ,t2 Pair s,(t1 ,t2 \n).t (v1,v2),s!! (e = mfun f (a:t1):t2 is e! end) (v = mfunlf (a:t1):t2 is e! end) (l.dom(s), s! = s[l \n. 0/ ]) Fun s,e .t v,s! (v = mfunlf (a:t1):t2 is e! end,l . dom(s)) FunVal s,v .t v,s s,t1 .t v1,s1 s1,t2 \n.t v2,s2 s2,l: ,[v1 ,v2/f ,a] e .e v,s! (v1 = mfunlf (a:t1):t2 is eend) Apply s,t1 t2 .t v,s! s,t .t \nv,s! Bang s,! t .t ! v,s! s,t .t v,s! Inject s,inlt1+t2 t .t inlt1+t2 v,s! s,t .t v,s! s,inrt1+t2 t .t \ninrt1+t2 v,s! s,t .t v,s! (Un)Roll s,roll(t) .t roll(v),s! s,t .t roll(v),s! s,unroll(t) .t v,s! Figure \n8. Evaluation of terms. memoizing semantics is also type-safe, for if not, there would be a closed value \nof a type t that is not canonical for that type. How\u00adever, erasure preserves and re.ects canonical forms, \nhence, by the Soundness Theorem, MFL must also be type safe.  4.5 Performance We show that memoization \nslows down an MFL program by a con\u00adstant factor (expected) with respect to a standard, non-memoizing \nsemantics even when no results are re-used. The result relies on representing a branch as a sequence \nof integers and using this se\u00adquence to key memo tables, which are implemented as hash tables. To represent \nbranches as integer sequences we use the property of MFL that the underlying type . of a bang type, ! \n., is an indexable s(l)(\u00df)=v (Found) s,l:\u00df,return(t) .e v,s s(l)=..(\u00df). ! s,t .t v,s ! s!(l)=. Ret (Not \nFound) s,l:\u00df,return(t) .e v,s![l . .![\u00df. v]] ! s,t .t ! v,s ! !!! s,l:!v \u00b7\u00df,[v/x]e .t v,s Let! ! !! s,l:\u00df,let \n! x : .be t in eend .e v,s ! s,t .t v1 \u00d7v2,s! !! s,l:\u00df,[v1/a1,v2/a2]e .e v,s Let\u00d7 !! s,l:\u00df,let a1\u00d7a2 \nbe t in eend .t v,s ! s,t .t inlt1+t2 v,s ! !! s,l:inl \u00b7\u00df,[v/a1 ]e1 .e v1,sCase !! s,l:\u00df, mcase t of \ninl (a1:t1) . e1 .t v1,s| inr (a2:t2) . e2 ! s,t .t inrt1+t2 v,s ! !! s,l:inr \u00b7\u00df,[v/a2 ]e2 .e v2,s !! \ns,l:\u00df, mcase t of inl (a1:t1) . e1 .t v2,s| inr (a2:t2) . e2 Figure 9. Evaluation of expressions. type. \nSince any value of an indexable type has an integer index, we can represent a branch of dependencies \nas sequence of integers corresponding to the indices of let! ed values, and zero or one for inl and inr. \nConsider a non-memoizing semantics, where the return rule al\u00adways evaluates its body and neither looks \nup nor updates memo tables (stores). Consider an MFL program and let T denote the time it takes (the \nnumber of evaluation steps) to evaluate the program with respect to this non-memoizing semantics. Let \nT! denote the time it takes to evaluate the same program with respect to the mem\u00adoizing semantics. In \nthe worst case, no results are re-used, thus the difference between T and T! is due to memo-table lookups \nand updates done by the memoizing semantics. To bound the time for these, consider a memo table lookup \nor update with a branch \u00dfand let |\u00df| be the length of the branch. Since a branch is a sequence of integers, \na lookup or update can be performed in expected O(|\u00df|) time using nested hash tables to represent memo \ntables. Now note that the non-memoizing semantics takes |\u00df| time to build the branch thus, the cost of \na lookup or update can be charged to the evalua\u00adtions that build the branch \u00df, i.e., evaluations of let! \nand mcase. Furthermore, each evaluation of let! and mcase can be charged by exactly one return. Thus, \nwe conclude that T! =O(T )in the expected case. 5 Implementation We describe an implementation of our \nframework as a Standard ML library. The aspects of the MFL language that relies on the syntactic distinction \nbetween resources and variables cannot be enforced statically in Standard ML. Therefore, we use a separate \ntype for resources and employ run-time checks to detect violations of correct usage.    structure \nExamples = struct type a box = a Box.box (** Some utilities **) fun iBang v =bang (fn i=> i) v fun bBang \nb = bang (fn b => Box.key b) b (** Fibonacci **) fun mfib f (n ) = letBang (expose n ) (fn n => return \n(fn()=> if n <2 then n else mapply f (iBang(n-1))+ mapply f (iBang(n-2)))) fun mfib n = mapply (mfun \nrec mfib ) n (** Boxed lists **) datatype a blist = NIL | CONS of ( a * (( a blist ) box)) type a blist \n= ( a blist ) box (** Hash Cons **) fun hCons (x ) = letx (expose x ) (fn (h ,t ) => letBang (expose \nh ) (fn h => letBang (expose t ) (fn t => return (fn()=> box (CONS(h,t)))))) val hCons = mfun hCons (** \nKnapsack **) fun mks mks (arg) = letx (expose arg) (fn (c ,l ) => letBang (expose c ) (fn c => letBang \n(expose l ) (fn l => return (fn () => case (unbox l) of NIL=>0 | CONS((w,v),t) => if (c < w) then mapply \nmks (pair (iBang c) (bBang t)) else let val arg1 = pair (iBang c) (bBang t) val v1 = mapply mks arg1 \nval arg2 = pair (iBang (c-w)) (bBang t) val v2 = v + mapply mks arg2 in if (v1 > v2) then v1 else v2 \n end)))) fun mks x = mapply (mfun rec mks ) x (** Quicksort **) fun mqs () = let val empty = box NIL \nval hCons = mfun hCons fun fil f l= case (unbox l) of NIL => empty | CONS(h,t) => if (f h) then mapply \nhCons (pair (iBang h) (bBang (fil f t))) else fil ft fun qs qs(l )= letBang (expose l ) (fn l => return \n(fn () => case (unbox l) of NIL=>nil | CONS(h,t) => let val ll = fil (fn x=>x<h) t val gg = fil (fn \nx=>x>=h) t val sll = mapply qs (bBang ll) val sgg = mapply qs (bBang gg) in sll@(h::sgg) end)) in mfun \nrec qs end end The implementation extends the operational semantics of the MFL language (Section 4.3) \nwith boxes. The bang primitive takes a value and an injective function, called the index function, that \nmaps the value to an integer, called the index. The index of a value is used to key memo tables. The \nrestriction that the indices be unique, en\u00adables us to implement memo tables as a nested hash tables, \nwhich support update and lookup operations in expected constant time. The primitive letBang takes a value \nb of bang type and a body. It applies the body to the underlying value of b, and extends the branch with \nthe index of b. The function letx takes a pair p and a body. It binds the parts of the pair to two resources \nand and applies the body to the resources; as with the operational semantics, letx does not extend the \nbranch. The function mcase takes value s of sum type and a body. It branches on the outer form of s and \nbinds its inner value to a resource. It then applies the body to the resource and extends the branch \nwith 0 or 1 depending on the outer form of s. The elimination forms of sums and products for the term \ncontext, split and choose are standard. The return primitive .nalizes the branch and returns its body \nas a suspension. The branch is used by mfun rec or mfun, to key the memo table; if the result is found \nin the memo table, then the sus\u00adpension is disregarded and the result is re-used; otherwise the sus\u00adpension \nis forces and the result is stored in the memo table keyed by the branch. The mfun rec primitive takes \na recursive function f as a parameter and memoizes f by associating it with a memo pad. A subtle issue \nis that f must calls its memoized version recursively. Therefore f must take its memoized version as \na parameter. Note also that the memoized function internally converts its parameter to a resource before \napplying f to it. The interface of the library provides no introduction form for re\u00adsources. Indeed, \nall resources are created by the library inside the letx, mcase, mfun rec, and mfun. The function expose \nis the elimination form for resources. If, for example, one would like to apply letBang to a resource, \nthen he must .rst expose the re\u00adsource, which exposes the underlying value. Figure 12 show the examples \nfrom Section 3 written in the SML library. Note that the memoized Fibonacci function mfib creates a memo \ntable every time it is called. When mfib .nishes, this table can be garbage collected (the same applies \nto mks). For Quicksort, we provide a function mqs that returns an instance of memoized Quicksort when \napplied. Each such instance has its own memo table. Note also that mqs creates a local instance of the \nhash-cons function so that each instance of memoized Quicksort has its own memo table for hash-consing. \nIn the examples, we do not use the sum types provided by the library to represent boxed lists, because \nwe do not need to. In general, one will use the provided sum types instead of their ML counterparts (for \nexample if an mcase is needed). The examples in Figure 12 can be implemented using the following de.nition \nof boxed lists. datatype a boxlist = ROLL of (unit, (( a, a boxlist box) prod)) sum type a boxlist = \n( a boxlist ) box Changing the code in Figure 12 to work with this de.nition of boxed lists requires \nseveral straightforward modi.cations.  6 Discussion Space and Cache Management. Our framework associates \na sep\u00adarate memo table with each memoized function. This allows the programmer to control the life-span \nof memo tables by conven\u00adtional scoping. This somewhat coarse degree of control is suf.cient in certain \napplications such as in dynamic programming, but .ner level of control may be desirable for applications \nwhere result re\u00aduse is less regular. Such an application can bene.t from specifying a caching scheme \nfor individual memo tables so as to determine the size of the memo table and the replacement policy. \nWe discuss how the framework can be extended to associate a cache scheme with each memo table and maintain \nthe memo table accordingly. The caching scheme should be speci.ed in the form of a param\u00adeter to the \nmfun construct. When evaluated, this construct will bind the caching scheme to the memo table and the \nmemo ta\u00adble will be maintained accordingly. Changes to the operational semantics to accommodate this \nextension is small. The store s will now map a label to a pair consisting of a memo table and its caching \nscheme. The handling of the return will be changed so that the stores do not merely expand but are updated \naccord\u00ading to the caching scheme before adding a new entry. The fol\u00adlowing shows the updated return rule. \nHere S denotes a caching scheme and . denotes a memo table. The update function de\u00adnotes a function that \nupdates the memo table to accommodate a new entry by possibly purging an existing entry. The program\u00admer \nmust ensure that the caching scheme does not violate the integrity of the memo table by tampering with \nstored values. s(l)=(.,S) .(\u00df)=v (Found) s,l:\u00df, return(t) .e v,s s(l)=(.,S) .(\u00df). s,t .t v,s! s!(l)=(.! \n,S) .!! =update(.! ,S, (\u00df, v)) (Not Found) v,s![l . .!!] s,l:\u00df, return(t) .e For example, we can specify \nthat the memo table for the Fibonacci function, shown in Figure 1, can contain at most two entries and \nbe managed using the least-recently-used replacement policy. This is suf.cient to ensure that the memoized \nFibonacci runs in linear time. This extension can also be incorporated into the type system described \nin Section 4. This would require that we associate types with memo stores and also require that we develop \na type system for safe update functions if we are to enforce that the caching schemes are safe. Local \nvs. Non-local Dependences. Our dependence tracking mechanism only captures local dependences between \nthe input and the result of a function. A local dependence of a function f is one that is created inside \nthe static scope of f. A non-local dependence of f is created when f passes its input to some other function \ng, which examines f s input indirectly. In previous work, Abadi et. al. [1] and Heydon et. al. [14] showed \na program anal\u00adysis technique for tracking non-local dependences by propagating dependences of a function \nto its caller. They do not, however, make clear the performance implications of their technique. Our \nframework can be extended to track non-local dependences by introducing an application form for memoized \nfunctions in the ex\u00adpression context. This extension would, for example, allow for de\u00adpendences of non-constant \nlength. We chose not to support non\u00adlocal dependences because it is not clear if its utility exceeds \nits performance effects. Memoization and Adaptivity. The work we present in this paper was motivated \nby our previous work on adaptive computation [2]. We brie.y discuss the relationship between memoization \nand adap\u00adtivity and how they can be combined to obtain ef.cient dynamic or incremental algorithms. An \nadaptive computation maintains a dynamic dependence graph representing data and control dependences. \nWhen the input is modi.ed, a change propagation algorithm updates the output and the dependence graph. \nThe adaptivity mechanism handles deep changes ef.ciently. We say that a change is deep if it affects \ncalls that occur at leaves of the call tree for the computation. In contrast, a change is shallow if \nit affects by a calls that occur at the roots of the call tree. As an example consider the Quicksort \nalgorithm that picks the .rst key of its input as pivot. Inserting a new key at the end of the in\u00adput \nlist is a deep change because this change will affect the last recursive calls of some .lter functions \nand will become pivot only at the end of some sequence of recursive calls to Quicksort. In contrast, \ninserting a new key at the beginning of the list is a shal\u00adlow change for Quicksort, because the new \nkey will be selected as a pivot immediately by the .rst call to Quicksort. The adaptivity mechanism based \non dynamic dependence graphs handles an in\u00adsertion at the end of the input, a deep change, in expected \nO(log n) time [2], whereas the insertion at the beginning of the list, a shallow change, will cause a \ncomplete rerun, which takes O(nlog n) time. Using memoization, however, an insertion at the beginning \nof the list can be handled in O(n) time as showed in Section 3. Any change can be thought of a combination \nof shallow and deep changes. Since memoization and adaptivity complement each other in their handling \nof deep and shallow changes, we would expect that a combination of these two techniques would handle \ngeneral changes ef.ciently. For example, in Quicksort, we expect that an insertion in a random position \nin the list would be handled in ex\u00adpected O(logn) time by a combination of these two techniques. 7 Conclusion \nWe presented a framework for selective memoization under pro\u00adgrammer control. The framework makes explicit \nthe performance effects of memoization and yields programs whose running times can be analyzed using \nstandard techniques. A key aspect of the framework is that it can capture both control and data dependences \nbetween input and the result of a memoized function. The main contributions of the paper are the particular \nset of primitives we suggest and the semantics along with the proofs that it is sound. We gave a simple \nimplementation of the framework in the Standard ML language. We expect that this framework can be implemented \nin any purely-functional language. 8 References [1] M. Abadi, B. W. Lampson, and J.-J. Levy. Analysis \nand caching of dependencies. In International Conference on Functional Programming, pages 83 91, 1996. \n[2] U. A. Acar, G. E. Blelloch, and R. Harper. Adaptive func\u00adtional programming. In Proceedings of the \nTwenty-ninth An\u00adnual ACM-SIGPLAN-SIGACT Symposium on Principles of Programming Languages, Jan. 2002. \n[3] U. A. Acar, G. E. Blelloch, and R. Harper. Selective memo\u00adization. Technical Report CMU-CS-02-194, \nCarnegie Mellon University, Computer Science Department, Dec. 2002. [4] A. V. Aho, J. E. Hopcroft, and \nJ. D. Ullman. The Design and Analysis of Computer Algorithms. Addison-Wesley, 1974. [5] J. Allen. Anatomy \nof LISP. McGraw Hill, 1978. [6] A. W. Appel and M. J. R. Gonc\u00b8alves. Hash-consing garbage collection. \nTechnical Report CS-TR-412-93, Princeton Uni\u00adversity, Computer Science Department, 1993. [7] R. Bellman. \nDynamic Programming. Princeton University Press, 1957. [8] R. S. Bird. Tabulation techniques for recursive \nprograms. ACM Computing Surveys, 12(4):403 417, Dec. 2002. [9] N. H. Cohen. Eliminating redundant recursive \ncalls. ACM Transactions on Programming Languages and Systems, 5(3):265 299, July 1983. [10] T. H. Cormen, \nC. E. Leiserson, and R. L. Rivest. Introduction to Algorithms. MIT Press/McGraw-Hill, 1990. [11] A. Demers, \nT. Reps, and T. Teitelbaum. Incremental evalua\u00adtion of attribute grammars with application to syntax \ndirected editors. In Conference Record of the 8th Annual ACM Sym\u00adposium on POPL, pages 105 116, Jan. \n1981. [12] J. Field and T. Teitelbaum. Incremental reduction in the lambda calculus. In Proceedings of \nthe ACM 90 Conference on LISP and Functional Programming, pages 307 322, June 1990. [13] E. Goto and \nY. Kanada. Hashing lemmas on time complex\u00adities with applications to formula manipulation. In Proceed\u00adings \nof the 1976 ACM Symposium on Symbolic and Algebraic Computation, pages 154 158, 1976. [14] A. Heydon, \nR. Levin, and Y. Yu. Caching function calls using precise dependencies. ACM SIGPLAN Notices, 35(5):311 \n320, 2000. [15] J. Hilden. Elimination of recursive calls using a small table of randomly selected function \nvalues. BIT, 16(1):60 73, 1976. [16] R. Hoover. Alphonse: incremental computation as a program\u00adming abstraction. \nIn Proceedings of the 5th ACM SIGPLAN conference on Programming language design and implemen\u00adtation, \npages 261 272. ACM Press, 1992. [17] R. J. M. Hughes. Lazy memo-functions. In Proceedings 1985 Conference \non Functional Programming Languages and Computer Architecture, 1985. [18] S. P. Jones. The Implementation \nof Functional Programming Languages. Prentice-Hall, 1987. [19] Y. A. Liu and S. D. Stoller. Dynamic programming \nvia static incrementalization. In European Symposium on Program\u00adming, pages 288 305, 1999. [20] Y. A. \nLiu, S. D. Stoller, and T. Teitelbaum. Static caching for incremental computation. ACM Transactions on \nProgram\u00adming Languages and Systems, 20(3):546 585, 1 May 1998. [21] J. McCarthy. A Basis for a Mathematical \nTheory of Computa\u00adtion. In P. Braffort and D. Hirschberg, editors, Computer Pro\u00adgramming and Formal Systems, \npages 33 70. North-Holland, Amsterdam, 1963. [22] D. Michie. memo functions and machine learning. Nature, \n218:19 22, 1968. [23] J. Mostov and D. Cohen. Automating program speedup by deciding what to cache. In \nProceedings of the Ninth Interna\u00adtional Joint Conference on Arti.cial Intelligence, pages 165 172, Aug. \n1985. [24] T. Murphy, R. Harper, and K. Crary. The wizard of TILT: Ef\u00ad.cient(?), convenient and abstract \ntype representations. Tech\u00adnical Report CMU-CS-02-120, School of Computer Science, Carnegie Mellon University, \nMar. 2002. [25] P. Norvig. Techniques for automatic memoization with ap\u00adplications to context-free parsing. \nComputational Linguistics, pages 91 98, 1991. [26] H. A. Partsch. Speci.cation and Transformation of \nPrograms A Formal Approach to Software Development. Springer-Verlag, 1990. [27] M. Pennings. Generating \nIncremental Attribute Evaluators. PhD thesis, University of Utrecht, Nov. 1994. [28] M. Pennings, S. \nD. Swierstra, and H. Vogt. Using cached functions and constructors for incremental attribute evalua\u00adtion. \nIn Seventh International Symposium on Programming Languages, Implementations, Logics and Programs, pages \n130 144, 1992. [29] F. Pfenning. Structural cut elimination. In D. Kozen, edi\u00adtor, Proceedings of the \nTenth Annual Symposium on Logic in Computer Science, pages 156 166. Computer Society Press, 1995. [30] \nF. Pfenning and R. Davies. A judgmental reconstruction of modal logic. Mathematical Structures in Computer \nScience, 11:511 540, 2001. Notes to an invited talk at the Workshop on Intuitionistic Modal Logics and \nApplications (IMLA 99), Trento, Italy, July 1999. [31] J. Polakow and F. Pfenning. Natural deduction \nfor intuition\u00adistic non-commutative linear logic. In J.-Y. Girard, editor, Proceedings of the 4th International \nConference on Typed Lambda Calculi and Applications (TLCA 99), pages 130 144. Springer-Verlag LNCS 1581, \n1999. [32] W. Pugh. Incremental computation via function caching. PhD thesis, Department of Computer \nScience, Cornell University, 1987. [33] W. Pugh. An improved replacement strategy for function caching. \nIn Proceedings of the 1988 ACM conference on LISP and functional programming, pages 269 276. ACM Press, \n1988. [34] W. Pugh and T. Teitelbaum. Incremental computation via function caching. In Conference Record \nof the 16th Annual Symposium on POPL, pages 315 328, Jan. 1989. [35] J. M. Spitzen and K. N. Levitt. \nAn example of hierarchical design and proof. Communications of the ACM, 21(12):1064 1075, 1978. [36] \nR. S. Sundaresh and P. Hudak. Incremental compilation via partial evaluation. In Conference Record of \nthe 18th Annual ACM Symposium on POPL, pages 1 13, Jan. 1991. [37] Y. Zhang and Y. A. Liu. Automating \nderivation of incremental programs. In Proceedings of the third ACM SIGPLAN inter\u00adnational conference \non Functional programming, page 350. ACM Press, 1998.  \n\t\t\t", "proc_id": "604131", "abstract": "We present a framework for applying memoization selectively. The framework provides programmer control over equality, space usage, and identification of precise dependences so that memoization can be applied according to the needs of an application. Two key properties of the framework are that it is efficient and yields programs whose performance can be analyzed using standard techniques.We describe the framework in the context of a functional language and an implementation as an SML library. The language is based on a modal type system and allows the programmer to express programs that reveal their true data dependences when executed. The SML implementation cannot support this modal type system statically, but instead employs run-time checks to ensure correct usage of primitives.", "authors": [{"name": "Umut A. Acar", "author_profile_id": "81100077236", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P286793", "email_address": "", "orcid_id": ""}, {"name": "Guy E. Blelloch", "author_profile_id": "81100282539", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P100820", "email_address": "", "orcid_id": ""}, {"name": "Robert Harper", "author_profile_id": "81100140064", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP39029370", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/604131.604133", "year": "2003", "article_id": "604133", "conference": "POPL", "title": "Selective memoization", "url": "http://dl.acm.org/citation.cfm?id=604133"}