{"article_publication_date": "05-01-2000", "fulltext": "\n On Loops, Dominators, and Dominance Frontier G. Ramalingam IBM T.J. Watson Research Center P.O. Box \n704, Yorktown Heights, NY, 10598, USA E-mail: rama@watson.ibm.com 1 Introduction This paper illustrates \nthe use of loop nesting forests in two appli\u00adcations. The .rst is a new algorithm for computing the iterated \ndominance frontier of a set of vertices in a graph, which can be used to construct representations such \nas the SSA form [7] and Sparse Evaluation Graphs [5]. The second is a new algorithm for constructing \nthe dominator tree [10] of a graph. The new algorithms run in almost linear time. The primary contributions \nof the paper, however, are not these end results (linear time algorithms are already known for these \nproblems), but the means used to achieve these ends. In particular, the paper illustrates for these two \nproblems how arbitrary prob\u00adlem instances (including those based on irreducible graphs) can be transformed \ninto equivalent problem instances based on acyclic graphs. This lets us generalize simpler algorithms \nthat work only for acyclic graphs to work for arbitrary graphs. Such approaches have previously been \nused for reducible graphs (e.g., [6, 15, 2]) and this paper generalizes such approaches to irreducible \ngraphs. Our problem reduction strategy makes use of loop nesting forests, a data structure that represents \nthe loops in a control-.ow graph and the containment relation between them. The concept of loops is widely-used \nin optimizing compilers [11]. However, while there is a well accepted notion of what the loops in a reducible \ngraph are [19], there is less agreement about how the loop nesting forest should be de.ned for arbitrary \ngraphs. For instance, Steensgaard [18], Sreedhar et. al. [17], and Havlak [9] each provide a different \nde.nition. Each of these de.nitions has its advantages and disadvantages. We sidestep the question of \nwhich of these de.nitions is the right one by introducing an axiomatic de.nition of a loop nesting for\u00adest \nthat all three forests satisfy. We also introduce an equivalent constructive characterization of a family \nof loop nesting forests. We study the properties shared by this family of forests and show that our problem \nreduction strategy works correctly with any forest belonging to this family. This implies we can safely \nuse any of the three forests men\u00adtioned above in our two applications. However, these three forests turn \nout to be less than ideal for our purpose. Our applications run in linear time if they utilize Steensgaard \ns forest, but gener\u00adating Steensgaard s forest takes quadratic time in the worst case. Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, or republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 2000, Vancouver, \nBritish Columbia, Canada. Copyright 2000 ACM 1-58113-199-2/00/0006...$5.00. Havlak s forest can be generated \nin almost linear time [13], but our applications run in quadratic time (in the worst case) if they use \nHavlak s forest. The Sreedhar-Gao-Lee forest poses no such ef.ciency dilemma: it can be generated in \nalmost linear time [13], and our applications run in linear time if they utilize this forest. However, \nthe algorithm for generating the Sreedhar-Gao-Lee for\u00adest requires the dominator tree. This makes the \nSreedhar-Gao-Lee forest inappropriate for the application of generating the dominator tree! We introduce \nyet another loop nesting forest, one that .ts into the same framework as the other three forests but \ndoes not posess any of the above mentioned disadvantages. Our two applications run in linear time if \nthey utilize this new forest. The new forest can be generated in almost linear time, using a simple bottom \nup traversal of the depth-.rst search tree. In summary, the contributions of this paper are (a) It provides \nus with a better understanding of loop nesting forests, in particu\u00adlar, of the similarities and differences \nbetween the different loop nesting forests de.ned previously; (b) It introduces a new, easy\u00adto-construct, \nloop nesting forest that has some advantages over previous loop forests; and (c) It presents new algorithms \nfor con\u00adstructing the dominator tree and the SSA form (iterated dominance frontiers). While ef.cient \nalgorithms are already known for these problems, the new algorithms do provide compiler implementors \nwith more choices. (For instance, one can choose to construct the SSA form from either the loop forest \nor the dominator tree whichever is more convenient.) Finally, it would be interesting to see if the problem \nreduction strategy utilized in this paper (for trans\u00adforming arbitrary graph problem instances into equivalent \nacyclic graph problem instances) can be adapted for other applications, such as structure-based program \nanalysis. 2 Terminology and Notation A control-.ow graph Gis a directed graph with a distinguished entry \nvertex. We will denote the vertex set of Gby V(G)(or V), the edge set of Gby E(G)(or E), and the entry \nvertex by entry(G). For convenience, we assume that entry(G)has no predecessorsand that every vertex \nin Gis reachable from entry(G).If Yis a setof vertices in a graph G, then hYiG, the subgraph of Ginduced \nby Y, consists of the set of vertices Yand the set of edges E(G)\\(YxY). If no confusion is likely, we \nwill omit the subscript G. A set Xof vertices is said to be strongly connectedif there exists a path, \nconsisting only of vertices in X, between any two vertices of X. Further, Xis said to be a strongly connected \ncomponent of the graph if Xis strongly connected and no proper superset of X is strongly connected. A \nstrongly connected component is said to non-trivial if it consists of two or more vertices or if it consists \nof entry (b) (a) (c)  (d) (e)    u u x u x uv  x x w exit  Figure 1: An example illustrating \ndifferent loop nesting forests for a single control-.ow graph, shown in (a). The internal vertices of \nthe forest, shown as ellipses, denote loops, with the loop s headers shown inside the ellipse. The leaves \nof the forest, shown as rectangles, identify vertices in the control-.ow graph. The ancestor-descendant \nrelation in this forest captures the loop containment relation. (b) The Sreedhar-Gao-Lee forest. (c) \nSteensgaard s forest. (d) Havlak s forest. (e) A new loop nesting forest, obtained from Havlak s forest. \none vertex that has a self-loop (an edge from the vertex to itself). Given a graph G, let SCC(G)denote \nthe set of non-trivial strongly connected components of G. We say that a vertex xdominates a vertex yif \nevery path from the entry vertex to ypasses through x. We say that xstrictly dominates yif xdominates \nyand x#6y. The domination relation can be concisely represented by a tree, called the dominator tree, \nsuch that xstrictly dominates yiff xis an ancestor of yin the dominator tree. We refer to the parent \nof a vertex uin the dominator tree as u s immediate dominator. 3 What s in a Loop This paper is centered \naround the use of loop nesting forests to solve two problems. Given a structured program, the loops in \nthe program and the nesting relation between them can be easily identi.ed. In particular, the use of \ncertain looping constructs (such as while-do and repeat-until) identi.es loops. Any two such loops will \nbe either mutually disjoint or one must be contained in the other. This leads to a nesting relation between \nthe loops, which can be represented by a forest. Given an unstructured program, however, it is no longer \nobvious what the loops in the program are. Arbitrary programs, including unstructured ones,can be represented \nby control-.ow graphs. Loop identi.cation is a (partial) attempt at identifying the structure of a program, \ngiven its control-.ow graph representation. The classical algorithm for identifying loops is Tarjan s \ninter\u00adval .nding algorithm [19], which is restricted to reducible graphs. Recently, several algorithms \nhave been proposed for identifying loops in arbitrary graphs. For certain irreducible graphs, each algo\u00adrithm \nidenti.es a different set of loops. Consider the control-.ow graph shown in Fig. 1(a). In this example, \nthe Sreedhar-Gao-Lee algorithm [17] identi.es a single loop fu,v,w,xg, while Steensgaard s algorithm \n[18] identi.es two loops fu,v,w,xg and fw,xg, while Havlak s algorithm [9] identi.es three loops fu,v,w,xg, \nfw,x,vgand fx,vg. (The loops identi.ed by Havlak s algorithm actually depend on the order in which vertices \nare visited during depth-.rst search; in the above example, we as\u00adsume that vertex uis visited before \nv.) The formal de.nition of these different forest will be presented later. Which of these de.nitions \nis the right one? Some of these de.nitions may (subjectively) appear to be more natural than the others. \nWhat really matters, however, is whether a particular forest can be used in a particular application \nand what the performance implications of using a particular forest are. As mentioned earlier, our algorithm \nwill work correctly with all of the abovementioned forests, and we will establish this by presenting \nan axiomatic de.n\u00adition of a loop nesting forest that is satis.ed by all of the abovemen\u00adtioned forests \nand by showing that our algorithm works correctly with any loop nesting forest that satis.es these axioms. \n 3.1 Loop Nesting Forests: An Axiomatic Characterization What we seek is an abstract treatment of loops \nthat will enable results that are applicable to several different loop nesting forests. The key to this \nis to consider a loop in a graph Gto benot a set of vertices, but a pair (B,H)of non-empty sets of vertices \nB and H, with H B, where Bis the body of the loop and H is the set of headers of the loop. Thus, a loop \nis an element of 2V(G) X2V (G), where 2V(G) denotes the powerset of V(G).A (G) X2V loop nesting forest \nis a set of loops, i.e. a subset of 2V(G). We will sometimes represent a loop nesting forest as a pair \nhB,Hi, where B2V(G) is the set of all loop bodies, and H2B!2V(G) is a function that maps each loop body \nto the set consisting of its loop headers. Thus, hB,Hiis an alternative representation for the set f(B,H(B))jB2Bg. \nClearly, not every pair hB,Hiof the above form is a meaningful loop nesting forest for G. We now describe \nsome properties we expect a loop nesting forest to satisfy. The .rst, and obvious, property we expect \nof loops is that the loop body of a loop be strongly connected. The second property we assume of a loop \nnesting forest is that it has the proper nesting property: a set of loops is said to have the proper \nnesting property if for any two loops in the set, either the loop bodies of the two loops are disjoint \nor the loop body of one is contained within the loop body of the other. A set of loops with this property \ncan be represented compactly by a forest over the set of loops and vertices, where a loop Lxis a descendant \nof another loop Lyiff the body of Lxis contained in the body of Ly and a vertex uis a descendant of a \nloop Lyiff uis contained in the body of Ly. We will usually use the term loop nesting forest to refer \nto a set of loops satisfying the various properties described here, but occasionally we will use the \nterm to denote the forest that represents such a set (as explained above). In particular, it should be \nclear what it means for one loop to be the parent of another loop. We also expect the set of loops to \nbe complete in some sense. We say that a pair (B,H)coversa set Xif B;Xand X\\H6 #c. We will require that \nevery non-trivial strongly connected set in the given graph be covered by some loop in the forest. We \nwill soon see how this condition implies completeness (see Theorem 1.) The .nal property we assume concerns \nloop headers. We as\u00adsume that a vertex dominated by some other vertex in the loop cannot be a header \nof the loop. Given a set of vertices X, let Undom(X)denote the set of vertices in Xthat are not dominated \nby any other vertex in X. Then, for any loop (B,H)we assume that H Undom(B). We combine these assumptions \ninto the following de.nition: 2V(G) De.nition 1 A pair hB,Hi, where B and H2B! 2V(G), is said to be a \nloop nesting forest for Gif: (a) 8B2B:Bis a non-trivial strongly connected set. (b) Every non-trivial \nstrongly connected set Xin the graph is covered by (B,H(B))for some B2B. (c) The set of loops have the \nproper nesting property: 8B2 1 B:8B22B:B1\\B2=cor B1 B2or B2 B1. (d) A header of a loop is not dominated \nby any other vertex in the loop: 8B2B:c6H(B) Undom(B). = Let Lbe a loop nesting forest for a graph G. \nWe refer to an edge from a vertex in a loop (body) to one of its headers as a loopback edge of the loop \nand the graph. Let FL(G)denote the graph obtained by removing all the loopback edges of G. Theorem 1 \nIf Lis a loop nesting forest for Gthen, FL(G)is an acyclic graph. Proof Consider any cycle Cin G. Since \nCis a non-trivial strongly connected set, it must be covered by some loop (B,H)2L(condi\u00adtion (b) of De.nition \n1). This implies that Ccontains some header h2H. Since C B, the incoming edge of vertex hin cycle Cis \na loopback edge (by de.nition). This implies that every cycle Cin graph Gmust contain at least one loopback \nedge, and the theorem follows. 2 Thus, a loop nesting forest lets us decompose a graph into an acyclic \ngraph and a set of loopback edges. The above theorem generalizes a well known and frequently used property \nof reducible graphs. The theorem partially justi.es De.nition 1 (especially condition (b)), as it shows \nhow a forest satisfying these axioms may be used to break all cycles in the graph. However, we will see \nlater that there is more to our problem reduction strategy than just this theorem. De.nition 2 A loop \nnesting forest is said to be a minimal loop nesting forest if no loop body in the forest is covered by \nanother loop in the forest. The above de.nition is equivalent to requiring that every non\u00adtrivial strongly \nconnected set in the graph be covered by exactly one loop in the loop nesting forest. The de.nition also \nhas a simple interpretation in terms of headers . It implies that a header of a loop Lshould not be containedin \nany inner loop of L. The adjective minimal used in the above de.nition is meant to be suggestive, but \nit is important not to be misled by the word. The minimality condition does not apply to the set of loop \nbodies. In other words, a loop nesting forest hB,Himay be minimal even though there exists another loop \nnesting forest hB0,H0isuch that B0is a proper subset of B. As an example, we will later see that the \nforests constructed by Steensgaard s algorithm, the Sreedhar-Gao-Lee algorithm, and Havlak s algorithm \nare all minimal loop nesting forests according to the above de.nition, even though the set of loop bodies \nin Havlak s forest can be a superset of the set of loop bodies in Steensgaard s forest, which can itself \nbe a superset of the set of loop bodies in the Sreedhar-Gao-Lee forest. It is important to note that \nthe de.nition of a loop nesting forest presented above is not intended to be complete . The above de.n\u00adition \nwas partially guided by the applications we present later. The de.nition is general enough to include \nvarious speci.c forests that have been previously de.ned, while strong enough for our intended application \nand to establish several interesting properties. How\u00adever, other speci.c applications of loop nesting \nforests may require stronger properties than those implied by the above de.nitions.  3.2 Loop Nesting \nForests: A Constructive Characterization We now present a constructive scheme for generating a family \nof loop nesting forests. The following de.nition generalizes de.ni\u00adtions due to Steensgaard [18] and \nHavlak [9], by abstracting the header function. V(G)2V(G) Consider any function H:2!such that for every \nnon empty X, c6H(X)Undom(X). We will show that = this identi.es a collection of loops (with Has its header \nfunction) satisfying De.nition 1. Consider SCC(G), the collection of non-trivial strongly con\u00adnected \ncomponents of G. We identify elements of SCC(G)as the outermost loops of G. Consider any Xin SCC(G). \nThe set H(X) is the set of headers for X. Recall that an edge from a vertex inside Xto one of its headers \nis referred to as a loopback edge of X. Let F1(G)denote the graph obtained by dropping the loopback H \nedges of the outermost loops of G(i.e., SCC(G)). For i1, .1 de.ne Fi(G)to be F1(Fi(G)). For the sake \nof convenience, HHH let F0 H(G)denote the original graph G. S De.nition 3 LoopsH(G)=i?0SCC(Fi H(G)) This \nset of loop bodies, along with function H, identi.es a loop nesting forest: De.nition 4 LoopForestH(G)=hLoopsH(G),Hi \n2V(G)2V(G) Theorem 2 If H2!is such that for every non empty X, c6H(X) Undom(X), then LoopForestH(G)is \na = minimal loop nesting forest for G. Proof (a) Every B2LoopsH(G)is a non-trivial strongly con\u00adnected \nset in some Fi(G). But every Fi(G)is a subgraph of G. HH Hence, every B2LoopsH(G)is a non-trivial strongly \nconnected set in G. (b) Let Xbe any non-trivial strongly connected set of vertices in G. Consider the \nmaximum isuch that Xis a non-trivial i strongly connected set in FH(G). Then, Xmust be contained i in \nsome strongly connected component Bof FH(G). Further, X must contain at least one of B s headers. Otherwise, \nXwould i+1 be a non-trivial strongly connected set in FH(G)also. Hence, (B,H(B))covers X. Further, it \nshould be clear that (B,H(B)) is the only loop in LoopForestH(G)that covers X. (c) Note that any two \ndistinct elements of SCC(Fi(G))are disjoint. Further, H if ijthen for every element Yof SCC(Fj(G))there \nexists H an element Y0of SCC(Fi(G))such that Y0is a proper super- H set of Y. Hence, the set LoopsH(G)clearly \nhas the proper nesting property. (d) This follows directly from our assumption about H. 2 Conversely, \nevery minimal loop nesting forest can be generated using the above scheme. Note that the above scheme \ncan be used even if His a partial function, as long as His de.ned for the elements of LoopsH(G). It can \nbe shown that if L=hB0,H0iis a minimal loop nesting forest for G, then B0must be LoopsH0 (G).  3.3 Previously \nDe.ned Loop Nesting Forests We now show how the three speci.c loop nesting forests mentioned previously \ncan be obtained as special cases of our de.nition by choosing suitable header functions H. Given a set \nof vertices X, a vertex in Xis said to be an entry vertex of Xif it has a predecessor outside X. Let \nE(X)denote the set of all entry vertices of X. Steensgaard s forest [18] is the forest LoopForestE(G)obtained \nas a special case of our de.nition, by identifying the headers of a loop to be its entry vertices. It \nfollows (a) entry (b) entry (c) entry (d)   u uv uv  uv  ({u,v,w,x},  ({w,x}, {u,v}) {w,x}) x \nx x w w w  exit exit exit 111 1 (e) entry (f) entry (g) entry (h) entry (i)    26 26 26 26 uv \nuv uv uv  ({u,w,x,v}, ({w,x,v},  ({x,v}, {u}) {w}) {x}) w  3x 3x 3x 3x 4 4 4 4 w w w  exit exit \nexit exit (m) u (j) entry (k) entry (l) x uv uv  ({u,v,w,x}, {u,v,w,x}) w x x w  exit exit Figure \n2: An example illustrating the construction of the different loop nesting forests. Every arrow identi.es \nan outermost loop (shown as a pair (loop body, loop headers) inside the arrow) in the graph that is the \nsource of the arrow. The target of the arrow is the graph obtained by dropping the loopback edges of \nthe identi.ed loop. (a)-(d) Steensgaard s forest. (e)-(i) Havlak s forest. (j)-(l) The Sreedhar-Gao-Lee \nforest. (m) The Reduced Havlak forest. from Theorem 2 that Steensgaard s loop nesting forest is a minimal \nloop nesting forest. Consider the graph in Fig. 2(a). Identifying the non-trivial SCCs of this graph \nyields one outer loop fu,v,w,xg. The headers of this loop are its entry vertices uand v. Dropping the \nloopback edges of the loop yields the graph in Fig. 2(b). Identifying the non-trivial SCCs of this graph \nyields one inner loop fw,xg. Theheadersofthis loop are its entry vertices wand x. Dropping the loopback \nedges of this loop yields the graph in Fig. 2(c). As this graph is acyclic, the process halts, yielding \nthe loop nesting forest in Fig. 2(d). The internal vertices of the forest, shown as ellipses, denote \nthe loops in the program. The headers of a loop are shown inside the ellipse. The leaves of the forest, \nshown as rectangles, identify vertices in the control-.ow graph. The loops identi.ed by Havlak s algorithm \n[9] depend on the order in which vertices are visited during depth-.rst search (DFS). Given a depth-.rst \nsearch tree DFSTand a set of vertices X, let FirstDFST(X)denote the singleton set consisting of the vertex \nin Xthat is visited .rst during DFS. The Havlak forest is de.ned to be LoopForestFirstDF(G)Clearly, Havlak \ns forest is also a minimal ST loop nesting forest. (Havlak also outlines a simple extension to his algorithm \nthat constructs a more re.ned forest with more loops. It can be shown that this re.ned forest is a loop \nnesting forest according to our de.nition, though not a minimal one.) Consider the graph in Fig. 2(e). \nAssume that the vertices are vis\u00adited in the order entry, u, w, exit, x, v during depth .rst search. \n(The superscripts attached to the vertices in the .gure indicate the ver\u00adtices depth .rst numbering.) \nThe graphs in Fig. 2(f)-(h) illustrate the generation of the Havlak forest, which consists of three loops: \nan outermost loop fu,v,w,xg, an intermediate loop fw,x,vg, and an innermost loop fx,vg. The resulting \nloop nesting forest is shown in Fig. 2(i). The de.nition presented in Section 3.2 is constructive, but \nit is not the most ef.cient way to construct Havlak s forest. Havlak s forest can be constructed in almost \nlinear time using a bottom up traversal of the DFS tree [9, 13]. Sreedhar, Gao and Lee [17] outline an \nalgorithm, based on a bottom up traversal of the dominator tree, for identifying the loops in a graph. \nWe can show that the algorithm constructs a loop nesting forest (satisfying De.nition 1) but not a minimal \none. However, the set of loops constructed by this algorithm consist of a primary set of loops as well \nas an additional set of reducible loops. It turns out that the set of primary loops identi.ed by the \nSreedhar, Gao, and Lee algorithm is, in fact, equal to the minimal loop nesting forest LoopForestUndom(G), \nthe forest generated by the scheme of Section 3.2 with Undom as the header function. The Sreedhar, Gao, \nand Lee algorithm has a worst case quadratic complexity but can be improved to run in almost linear time \n[13]. The Sreedhar-Gao-Lee forest of the graph in Fig. 2(j) consists of only one loop, namely fu,v,w,xg, \nand is shown in Fig. 2(l).  3.4 A New Loop Nesting Forest Our goal is to explore the use of loop nesting \nforests in solving the two problems of computing iterated dominance frontiers and con\u00adstructing the dominator \ntree. The approach we take is to generalize simple algorithms that work for acyclic graphs by showing \nhow a problem instance involving an arbitrary graph can be transformed into an equivalent problem instance \nover an acyclic graph, given any minimal loop nesting forest for the graph. Though our approachcan be \nused with any minimal loop nesting forest in principle, not all minimal loop nesting forests are equally \nappropriate for use. In fact, all the three forests we have looked at so far turn out to be unattractive \nfor the applications we consider. Steensgaard s forest is unattractive because the best known al\u00adgorithm \nfor generating this forest takes quadratic time in the worst case. On the other hand, both Havlak s forest \nand the Sreedhar-Gao-Lee forest can be generated in almost linear time. The algorithm for constructing \nthe Sreedhar-Gao-Lee forest, however, requires the dominator tree. The .rst application we consider later \non is the construction of the dominator tree itself, and, hence, using the Sreedhar-Gao-Lee forest is \nmeaningless in the context of that ap\u00adplication. The algorithm for generating Havlak s forest is simple \nand based on depth-.rst search. Unfortunately, the size of the transformed acyclic graph generated by \nour approach (described later in Sec\u00adtion 4.3) can be quadratic in the size of the initial graph if we \nuse Havlak s forest in the transformation. (In contrast, the size of the transformed graph is at most \ntwice the size of the initial graph if we use either Steensgaard s forest or the Sreedhar-Gao-Lee forest \nto perform the transformation.) We will now show how we can construct a smaller version of Havlak s forest \nwithout such disadvantages, by merging loops that have a common entry vertex. Lemma 1 Let Lbe a minimal \nloop nesting forest for a graph G. Let (Bp,H)and (Bc,Hc)be two loops in Lsuch that (Bp,H) pp is the parent \nof (Bc,Hc)in L.If Hc.Undom(Bp), then L\u00adf(Bp,Hp),(Bc,Hc)g[f(Bp,Hp[Hc)gis also a minimal loop nesting forest \nfor G. Proof Straight forward. Note that the lemma says that if a loop s headers are not dominated by \nany vertex in it s parents loop body, then it can be merged with its parent (by eliminating the loop \nand adding its headers to it s parent s headers). 2 Our goal is to construct a smaller version of Havlak \ns forest by eliminating some loops in the forest using the above lemma. However, rather than merge any \ntwo loops that satisfy the conditions of the above lemma we will only merge loops that share a common \nentry vertex, as this is easier and turns out to be suf.cient for our purpose. Let .denote the smallest \nequivalence relation on the . loops of Havlak s forest such that l1 l2 for any two loops l1 and l2that \nhave a common entry vertex. The union of two loops (B1,H1)and (B2,H2)is de.ned to be (B1[B2,H1[H2). Let \nr denote the set of equivalence classes of Havlak loops. The Reduced S Havlak forest is de.ned to be \nf l2\" lj,2rg. Theorem 3 The Reduced Havlak forest is a minimal loop nesting forest. Proof First note \nthat if two loops l1and l2have a common entry vertex, then all loops that lie in-between l1and l2in the \nloop nest\u00ading forest must also have the same common entry vertex. Now, let (Bp,H)and (Bc,H)be two loops \nthat share a common entry pc vertex u, and let (Bp,H)be the parent of (Bc,H). Then, none of pcthe vertices \nin Bcare dominated by any of the vertices in Bp-Bc (since the entry vertex uprovides a path to vertices \nin Bthat cdoes not pass through any vertex in Bp-Bc). Consequently, the Reduced Havlak Forest can be \ngenerated from the Havlak Forest by repeatedly merging adjacent loops that satisfy the conditions of \nLemma 1. The result follows from Lemma 1. 2 Fig. 2(m) illustrates our new loop nesting forest (the Reduced \nHavlak forest), obtained by merging together the loops in Havlak s forest (shown in Fig. 2(i)) that have \na common entry vertex. In this example, all the three loops in Havlak s forest share a common entry vertex, \nnamely v. Note that the collapsed forest contains the same set of loop bodies as the Sreedhar-Gao-Lee \nforest but has a different set of headers. (This does not hold true in general.) The algorithm outlined \nby Ramalingam [13] for generating Havlak s forest can be adapted to construct the Reduced Havlak forest \nin almost linear time. 4 Constructing the Dominator Tree We now present our .rst application of loop \nnesting forests, an al\u00adgorithm for constructing the dominator tree of a control-.ow graph. 4.1 Acyclic \nGraphs Consider an acyclic graph. Let ube a vertex with predecessors v1,,vk. A vertex wstrictly dominates \nuiff wdominates all the vertices v1through vk. In other words, wis a proper ancestor of uin the dominator \ntree iff wis an ancestor of v1through vkin the dominator tree. This implies that the immediate dominator \nof u must be the least common ancestor of v1through vkin the dominator tree. This suggests the following \nalgorithm for constructing the dominator tree of an acyclic graph incrementally by processing the vertices \nin topological sort order. function BuildDominatorTree(G : Acyclic Graph) f DomTree := an empty tree; \nadd entry(G) as the root of DomTree ; for every vertex u in V(G) -fentry(G) g in topological sort order \ndo let z denote the least-common-ancestor, in DomTree, of the predecessors of u; add u as a child of \nz in DomTree ; end for g Gabow [8] describesa tree data structure in which the operations of adding a \nnew vertex to the tree and .nding the least common ancestor of two vertices can both be done in constant \ntime. The above algorithm runs in linear time if we utilize Gabow s data structure to implement DomTree. \nThe algorithm described above appears in [15] and [2]. 4.2 Reducible Graphs An edge u!vis said to be \na backedge if vdominates u. Re\u00admoving the backedges of a graph does not change the domination relation \non the vertices of the graph. In other words, the dominator tree of a graph Gis the same as the dominator \ntree of the graph obtained by removing all backedges from G. A control-.ow graph is said to be reducible \nif the graph obtained by removing all its backedges is acyclic. The backedges of a reducible graph can \nbe identi.ed easily (in linear time) using depth .rst search. Hence, the dominator tree of a reducible \ngraph can be constructed by .rst identifyingits backedgesandthenapplyingthealgorithmdescribed above (Section \n4.1) to the acyclic graph obtained by removing all backedges [2].  4.3 Irreducible Graphs Our goal is \nto show how loop nesting forests can be used to extend the above algorithm to handle cyclic, possibly \nirreducible, graphs. As we have seen earlier (Theorem 1) a loop nesting forest Lof a graph Gidenti.es \na set of edges, the loopback edges, whose deletion yields an acyclic graph FL(G). The trouble is that, \nin the  (c) entry (d) entry(a) entry (b) us us us d  w v wvw exit exit exit Figure 3: (a) An irreducible \ngraph G. (b) A loop nesting forest Lfor G. (c) The acyclic subgraph FL(G). (d) The transformed graph \nlL(G). presence of irreducibility, the dominator tree for the resulting graph may not be the same as \nthe dominator tree of the original graph. Consider the irreducible graph Gshown in Fig. 3. Both Steens\u00adgaard \ns forest and the Sreedhar-Gao-Lee forest of this graph are the same, which is shown in Fig. 3(b). The \nforest consists of a single loop fv wgwith two loop headers vand w. (Havlak s forest consists of the \nsame single loop body, but with a single header, which is either vor wdepending on the order in which \nthe ver\u00adtices are visited during depth-.rst search.) The acyclic subgraph FL(G)obtained by eliminating \nthe loopback edges is shown in Fig. 3(c). Note that udominates vin FL(G), but not in G. Thus, the dominator \ntree of FL(G)is different from the dominator tree of G. The same holds true if we use Havlak s forest. \nIn gen\u00aderal, the graph FL(G)may even contain vertices unreachable from entry(G). (The Sreedhar-Gao-Lee \nforest of the graph in Fig. 1(a) illustrates this phenomenon.) The solution is that we delete the loopback \nedges, but add some other edges that compensate for the deleted edges without creating cycles in the \ngraph. A vertex outside a loop is said to be a pre-entry vertex for that loop if it has a successor inside \nthe loop. Let pbe a pre-entry vertex of a loop L. When we delete a loopback edge u!hof the loop L, we \npotentially lose information about the presence of a path from pto the header hthrough the vertices in \nthe loop. We can compensate for this by adding edges from every pre-entry vertex of the loop to every \nheader of the loop. If we apply the transformation to every loop in the graph, we end up with an acyclic \ngraph that has the same dominator tree as the original graph. Unfortunately, this transformation can \nadd a quadratic number of edges to the graph in the worst case, e.g. when a loop has B(n) headers and \nB(n)pre-entry vertices. To prevent such a blowup in the number of edges, we use a modi.ed transformation \nthat achieves the same effect, as follows: We create a dummy header vertex 5for the loop, and add edges \nL from every pre-entry vertex of the loop to the dummy header, and edges from the dummy header to every \nreal header of the loop. Consider the example in Fig. 3. The headers of the loop in this graph are vand \nw. The pre-entry vertices of this loop are uand s. Our transformation deletes the loopback edges w!vand \nv!w, but compensatesfor them by adding a vertex 5and the edges u!5, s!5, 5!v, and 5!w. This gives us \nthe acyclic graph in Fig. 3(d). We actually use a slightly more general transformation than the above. \nIf the loop contains header vertices that are not entry vertices of the loop (the Sreedhar-Gao-Lee loop \nnesting forest may contain such loops, for example), the transformation will end up replacing all incoming \nedges of such headers by a single new edge from the new dummy vertex. This ends up being undesirable \nin the context of our second application (Section 5). So, in addition to the edges involving the dummy \nheader 5L, we need to add some more edges. For every loop header hthat is not an entry vertex, we select \nsome arbitrary pre-entry vertex pof the loop, and add the edge p!hto the graph. More formally, De.nition \n5 Given a loop Lin a graph G, let PreEntries(L)denote the set of all pre-entry vertices of L, let LoopBack(L)denote \nthe set of all loopback edges of L. For any non-empty set X, let Arb(X) denote an arbitrary element of \nX. Recall that E(X)denote the set of all entry vertices of X. We will denote the set of headers of Lby \nH(L), abusing notation. We de.ne the graph lL(G)to be (V0E0)where: V0=V(G)[f5Lg E0=E(G)-LoopBack(L) [fp!5jp2PreEntries(L)g \n L [f5L!hjh2H(L)g [fArb(PreEntries(L))!hjh2(H-E(L))g Let Lbe a minimal loop nesting forest for G. We \nde.ne lL(G) to be the graph obtained by applying the above transformation to every loop Lin L, where \nouter loops are transformed before inner loops. Note that if Lis an outermost loop, then the transformation \nlLdoes not modify the set of entry or pre-entry vertices of any other loop in the graph. We choose to \nde.ne lLas the sequential composition of a series of transformations of the form lLas it enables proving \nproperties of lLby proving them for the simpler single loop transformations of the form lL. The complex \ntransformation de.ned above (De.nition 5 is re\u00adquired only for irreducible loops (loops with multiple \nentry ver\u00adtices). For a reducible loop, its unique entry vertex can be used in place of the new vertex \n5and the transformation requires only L dropping the loopback edges of the loop. We ignore such an opti\u00admization \nhere for the sake of simplicity. What is the size of the transformed graph lL(G)? If every vertex is \nthe entry vertex of at most one loop in the forest L(this is trueof Steensgaard sforest, theSreedhar-Gao-Leeforest, \naswellas the Reduced Havlak forest), then the size of the graph lL(G)can be shown to be at most twice \nthe size of the initial graph. However, it is possible for a vertex to be the entry vertex of many loops \nin Havlak s forest. Hence, the size of lL(G)can be quadratic in the size of Gif Lis Havlak s forest. \nGiven a tree Tand a set of leaves Lin T, let T-Ldenote the subtree of Tobtained by removing all the leaves \nin L. Let .L denote the set f5LjL2Lg. Theorem 4 If Lis a minimal loop nesting forest for G, then DomTree(G)=DomTree(lL(G))-.L: \nProof See [14]. 2 It should now be clear how a minimal loop nesting forest of a graph can be used in \nconjunction with the algorithm outlined in Section 4.1 to construct the dominator tree of the graph. \nLet us now consider the complexity of this algorithm. Once the acyclic graph \\L(G)has been constructed, \nthe dominator tree can be con\u00adstructed in time linear in the size of \\L(G). Hence, by using the Reduced \nHavlak forest, we obtain an almost linear time algorithm for constructing the dominator tree of a graph. \n 5 Computing the Iterated Dominance Frontier We now present a second application of loop nesting forests, \nan algorithm for constructing the iterated dominance frontier of a set of vertices. 5.1 The Problem The \ndominance frontier of a vertex xin a graph G,denoted DFG(x), is the set of all ysuch that xdominates \nsome predecessor zof y but does not strictly dominate y. The dominance frontier of a set of vertices \nis de.ned to be the union of the dominance frontiers of its elements. Let Xbe a set of vertices. De.ne \nDFi)to G(X .1 be DFG(X)if i#1and DFG(X[DFi(X))if i1. The G iterated dominance frontier of Xis de.ned \nto be the limit of this sequence and will be denoted by DF+ ). G(X A vertex wis said to be a join node \nfor two distinct vertices u and v, if there exist two non-null paths C:u!*wand j:v!*w such that the only \nvertex common to the two paths is the vertex w. Given a set of vertices X, we say that a vertex wis a \njoin node for Xif wis a join node for some u,v2X, where u6v. The join #set JG(X)is de.ned to be the set \nof all join nodes of X. De.ne .1 ii JG(X)to be JG(X)if i#1and JG(X[JG(X))if i1. The limit of this sequence \nis called the iterated join set of X, denoted + JG(X). The subscript Gwill be occasionally omitted. For \nany set Xthat includes the entry vertex of the graph, Cytron et al. [7] show that J+(X)= DF+(X). Weiss \n[20] establishes the stronger result that J(X)= DF+(X). Thus, the notions of iterated dominance frontier, \niterated join set, and join set are all equivalent (for sets that include the entry vertex). The concept \nof iterated dominance frontier has several applications. In particular, it is directly useful in computing \nsparse evaluation graphs, the SSA form, and control dependences. We refer the reader to [7] for more \ninformation about these concepts. 5.2 Acyclic Graphs Consider a set of vertices Xin an acyclic graph \nG. The iter\u00adated dominance frontier of Xis the same as the iterated join + set JG(X[fentry(G)g). Let \nus refer to the vertices in the + set X[fentry(G)g[JG(X[fentry(G)g)as de.nitions (borrowing terminology \nused in the context of the SSA form). A de.nition dis said to reach another node uif there is a path \nfrom dto unot containing any de.nition other than dor u. Consider any vertex u6). #entry(GAt least one \nde.nition node must reach usince every vertex in the graph is assumed to be reachable from entry(G). \nIf at least two de.nitions reach u, then umust be a join + node for X[fentry(G)g[JG(X[fentry(G)g)and, \nhence, u + must be in JG(X[fentry(G)g). In other words, vertices not in + JG(X[fentry(G)g)must have exactly \none reaching de.nition. This suggests the following algorithm, which visits the vertices of the graph \nin topological sort order and computes their reaching de.nitions. Vertices with more than one reaching \nde.nition are added to the iterated dominance frontier. The computation is sim\u00adpli.ed by the fact that \nany vertex is either a de.nition node or has a unique reaching de.nition. The resulting algorithm runs \nin linear time, if appropriate implementations of the various sets are used. This algorithm is not new; \nit appears in [6]. function ComputeIteratedDominanceFrontier( G : Acyclic Graph, X : Subset of V(G) ) \nf ItDomFr := fg; for every vertex u of G in topological sort order do reachingDefs := fg; for every predecessor \nv of u do if v 2(ItDomFr[X [fentry(G) g) then add v to reachingDefs; else add uniqueReachingDef(v) to \nreachingDefs; end for if jreachingDefsj=1 then uniqueReachingDef(u) := the only element of reachingDefs; \nelsif (u 6 #entry(G)) then add u to ItDomFr; end for return ItDomFr; g  5.3 Reducible Flow Graphs How \ncan the above algorithm be extended to handle reducible graphs? A reducible graph Gcan be decomposed \ninto an acyclic graph F(G)and a set of backedges. The contribution of backedges to the iterated dominance \nfrontier of a set of vertices can be iden\u00adti.ed using the graph s loop nesting forest. Consider the following \nobservation. If a vertex xis contained in a loop, then the iterated dominance frontier of xwill include \nthe entry vertex of the loop. The reason for this is that, since a loop is strongly connected, there \nexists a path from xto the loop s entry vertex consisting only of vertices in the loop. On the other \nhand, there is a path from the entry vertex of the graph to the loop s entry vertex consisting only of \nvertices outside the loop. Hence, the loop s entry vertex is a join node for xand entry(G). For any vertex \nu, let HLC(u)denote the entries of the set of loops containing vertex u. Given a set of vertices X, de.ne \nHLC(X)to be [u2XHLC(u). Clearly, the iterated dominance frontier of Xincludes HLC(X). It turns out that \nthis precisely identi.es the contribution of backedges to the iterated dominance frontier. In particular, \nwe can show that: Theorem 5 DF+ )#HLC(X)[DF+ (X[HLC(X)). G(X F(G) (We omit any proof of this theorem, \nas we will soon consider a generalization of this theorem in the context of irreducible graphs.) This \nshows how the algorithm outlined earlier for acyclic graphs can be utilized to compute DF+ )using the \nloop nesting forest. G(X In particular, the set of loops containing any given vertex is given by the \nancestors of the vertex in the loop nesting forest. Given a set of vertices X, HLC(X)can be identi.ed \nby performing an upward traversal of the loop nesting forest starting from all vertices in X. This takes \ntime proportional to the size of HLC(X). Once we determine HLC(X), we can identify the iterated dominance \nfrontier of X[HLC(X)in the acyclic graph F(G)using the algorithm presented earlier. Theorem 5 then yields \nus the iterated dominance frontier of Xin G. For example, assume we want to compute the iterated domi\u00adnance \nfrontier of vertex ein the graph in Fig. 4(a). The loop nesting forest of the graph is shown in Fig. \n4(b). HLC(e), which is ob\u00adtained by walking up this forest from e,is fc,ag. Fig. 4(c) shows the acyclic \ngraph F(G)obtained by dropping all backedges of G.  (c) entry  (a) entry (b)  exit a b  c j d \nk e g h i  l m n  exit exit Figure 4: An example illustrating the use of loop nesting forest in computing \nthe iterated dominance frontier of a set of vertices. (a) A reducible control-.ow graph G. (b) Its loop \nnesting forest. (c) The acyclic graph obtained by dropping the backedges of G. To identify the iterated \ndominance frontier of ein G, we .rst iden\u00adtify the iterated dominance frontier of feg[HLC(e)= fe,a,cgin \nF(G). By applying our earlier algorithm to the acyclic graph, we determine that the iterated dominance \nfrontier of fe,a,cgin F(G) is fg,mg. Hence, the iterated dominance frontier of ein Gis given by HLC(e)[fg,mg= \nfc,a,g,mg. Since the loop nesting forest of a reducible graph can be con\u00adstructed in almost linear time \n[19], this gives us a simple almost linear time for computing the iterated dominance frontier of a set \nof vertices in a reducible graph. This approach for reducible graphs is used by Cytron et al. [6].  \n5.4 Irreducible Graphs We will now see how the ideas described so far can be extended to deal with irreducible \ngraphs. A loop nesting forest Lfor a graph G identi.es a set of loopback edges whose deletion yields \nan acyclic graph FL(G). Generalizing our earlier de.nition of HLC(X),we de.ne HLCL(X)to be the set of \nheaders of loops containing some vertex in X. However, just replacing F(G)by FL(G)and HLC(X)by HLCL(X)in \nTheorem 5 does not yield a valid theorem. In re\u00adducible graphs, the loop containment relationship was \nsuf.cient to capture the contribution of deleted edges in the construction of it\u00aderated dominance frontiers. \nThis is no longer true in the case of irreducible graphs. Consider the example in Fig. 3(a). The iterated \ndominance frontier of uin the graph of Fig. 3(a) includes vertices vand w, thanks to the loopback edges \nv!wand w!v. The contribution of these edges to the iterated dominance frontier of uis, however, not captured \nby the loop containment relation. In particular, uis not contained in any loop, and HLC(u)is empty. If \nwe drop the loopback edges w!vand v!w, we get the acyclic graph FL(G)shown in Fig. 3(c). The iterated \ndominance frontier of uin this acyclic graph does not include vand w! Thus, Theorem 5 fails to hold true \nin irreducible graphs if we just replace F(G)by FL(G)and HLC(X)by HLCL(X). The solution is the same one \nwe used in Section 4.3: when we delete the loopback edges, we add other edges that compensate for the \ndeleted edges without creating cycles in the graph. Consider the example in Fig. 3(a). The headers of \nthe loop in this graph are vand w. The pre-entry vertices of this loop are uand s. Our transformation \ndeletes the edges w!vand v!w, but compensates for them by adding a new vertex 5and the new edges u!5, \ns!5, 5!v, and 5!w. (As this example involves only one loop L, we simply use 5in place of 5L.) This gives \nus the acyclic graph in Fig. 3(d). It can be veri.ed that the iterated dominance frontier of uin the \ntransformed graph does include both vand w. More generally, we can show that the iterated dominance fron\u00adtier \nof any set of vertices Xin a graph Gcan be found by com\u00adputing the iterated dominance frontier of a corresponding \nset X[ HLCL(X)in the acyclic graph lL(G), (Recall the de.nition of lL(G)from Section 4.3). Denote the \nloop body of Lby B(L) and the set of headers of Lby H(L). De.ne .L(X)to be f5LjL2Land X\\B(L)6#.g. Thus, \n.L(X)is the set of dummy headers added for loops that overlap X. De.ne .Lto be f5LjL2Lg. Thus, .Lis the \nset of all dummy headers added. We can show that: Theorem 6 Let Lbe a minimal loop nesting forest for \na graph G and let Xbe any set of vertices in G. ++ DFG(X)#DFt(X[.L(X))-.L L(G) Proof See [14]. 2 Theorem \n6 shows how the algorithm of Section 5.2 can be adapted to work for arbitrary graphs using loop nesting \nforests. Given any set Xof vertices in a graph G, we walk up any loop nesting forest Lof Gto identify \n.L(X). We then apply the algorithm of Section 5.2 to the set X[.L(X)in the acyclic graph lL(G)to identify \nthe iterated dominance frontier of Xin G.If we use the Reduced Havlak loop nesting forest, the whole \nalgorithm runs in almost linear time. (The construction of the loop nesting forest runs in almost linear \ntime, and the subsequent steps run in linear time.) 6 Related Work Loops play a fundamental role in several \nloop optimizations and transformations [11]. The classical algorithm for identifying loops is Tarjan \ns interval .nding algorithm [19], which is restricted to reducible graphs. Recently, several algorithms \nhave been proposed for identifying loops in arbitrary graphs. This includes the algo\u00adrithms described \nby Steensgaard [18], Sreedhar et. al. [17], and Havlak [9]. Ramalingam [13] improves upon the ef.ciency \nof these different algorithms. The concepts of domination and dominator tree have many uses in program \nanalysis and optimization. The standard algorithm for computing dominators is Lengauer and Tarjan s [10] \nalmost linear time algorithm. Alstrup et al. [3, 1] and Buchsbaum et al. [4] present linear time algorithms \nfor this problem. The concept of the iterated dominance frontier was brought to prominence by the work \nof Cytron et al. [7] on the SSA form, a data structure with numerous applications in program optimization. \nThe Cytron et al. algorithm for computing the iterated dominance frontier of a set of vertices takes \nquadratic time in the worst case, but is competitive with other linear time algorithms [12, 16] for this \nproblem in practice. 7 Conclusion In this paper, we have presented new, almost linear time, algorithms \nfor two graph-theoretic problems, that of constructing the dominator tree of a graph and that of computing \nthe iterated dominancefrontier of a set of vertices in a graph. Though linear time algorithms are already \nknown for these problems we believe that these new algorithms are interesting because of the approach \nwe take. In particular, we have utilized these two applicationsas a vehicle for understanding the concepts \nof loops and loop nesting forests. We have shown how three previously de.ned loop nesting forests can \nbe generated as instances of a single parametric de.nition, and studied the properties common to the \nfamily of loop nesting forests that can be generated from this de.nition. We have shown how these forests \ncan be used (in our two applications) to transform arbitrary problem instances (including those based \non irreducible graphs) into equivalent problem instances based on acyclic graphs. We have also introduced \na new loop nesting forest, which too is an instance of our parametric de.nition. This new forest, which \ncan be constructed in almost linear time, turns out to be better suited for the two applications we consider. \nIt would interesting to explore possible uses of the problem reduction strategy used in this paper in \nother applications such as structure-based program analysis. 8 Acknowledgments I would like to thank \nJohn Field, V. C. Sreedhar, Vivek Sarkar and Mark Wegman for their feedback on this paper. References \n[1] Stephen Alstrup, Dov Harel, Peter W. Lauridsen, and Mikkel Thorup. Dominators in linear time. SIAM \nJ. Comput. To appear. [2] Stephen Alstrup and Peter W. Lauridsen. A simple and opti\u00admal algorithm for \n.nding immediate dominators in reducible graphs. Technical Report D-261/96, TOPPS Bibliography, 1996. \n[3] Stephen Alstrup, Peter W. Lauridsen, and Mikkel Thorup. Dominators in linear time. Technical Report \n96/35, Depart\u00adment of Computer Science, University of Copenhagen, 1996. [4] Adam L. Buchsman, Haim Kaplan, \nAnne Rogers, and Jeffrey Westbrook. A new, simpler linear-time dominators algorithm. ACM Transactions \non Programming Languages and Systems, 20(6):1265 1296, 1998. [5] Jong-DeokChoi,RonCytron,andJeanneFerrante.Automatic \nconstruction of sparse data .ow evaluation graphs. In Confer\u00adence Record of the Eighteenth ACM Symposium \non Principles of Programming Languages, pages 55 66, 1991. [6] R. Cytron, A. Lowry, and F. K. Zadeck. \nCode motion of con\u00adtrol structures in high-level languages. In Conference Record of the 13th ACM Symposium \non Principles of Programming Languages, pages 70 85, 1986. [7] Ron Cytron, Jeanne Ferrante, Barry K. \nRosen, Mark N. Weg\u00adman, and F. Kenneth Zadeck. Ef.ciently computing sta\u00adtic single assignment form and \ncontrol dependence graph. ACM Transactions on Programming Languages and Systems, 13(4):452 490, October \n1991. [8] H. N. Gabow. Data structure for weighted matching and near\u00adest common ancestors with linking. \nIn Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, pages 434 443, 1990. [9] \nPaul Havlak. Nesting of reducible and irreducible loops. ACM Transactions on Programming Languages and \nSystems, 19(4):557 567, July 1997. [10] T. Lengauer and R. E. Tarjan. A fast algorithm for .nding dominators \nin a .owgraph. ACM Transactions on Program\u00adming Languages and Systems, 1:121 141, 1979. [11] Robert Morgan. \nBuilding an Optimizing Compiler. Butterworth-Heinemann, Woburn, MA, 1998. [12] Keshav Pingali and Gianfranco \nBilardi. Optimal control dependence computation and the roman chariots problem. ACM Transactions on Programming \nLanguages and Systems, 19(3):462 491, May 1997. [13] G. Ramalingam. Identifying loops in almost linear \ntime. ACM Transactions on Programming Languages and Systems, 21(2):175 188, 1999. [14] G. Ramalingam. \nOn loops, dominators, and dominance fron\u00adtiers. Technical Report RC21513, IBM Research Division, June \n1999. [15] G. Ramalingam and Thomas Reps. An incremental algorithm for maintaining the dominator tree \nof a reducible .owgraph. In ConferenceRecordofthe 21stACM SymposiumonPrinciples of Programming Languages, \npages 287 298, 1994. [16] Vugranam C. Sreedhar and G.R. Gao. A linear time algorithm for placing .-nodes. \nIn Conference Record of the 22nd ACM Symposium on Principles of Programming Languages, pages 62 73, 1995. \n[17] Vugranam C. Sreedhar, Guang R. Gao, and Yong-Fong Lee. Identifying loops using DJ graphs. ACM Transactions \non Programming Languages and Systems, 18(6):649 658, No\u00advember 1996. [18] B. Steensgaard. Sequentializing \nprogram dependence graphs for irreducible programs. Technical Report MSR-TR-93-14, Microsoft Research, \nRedmond, Wash., October 1993. [19] Robert E. Tarjan. Testing .ow graph reducibility. J. Comput. Syst. \nSci., 9:355 365, 1974. [20] Michael Weiss. The transitive closure of control dependence: The iterated \njoin. ACM Letters on Programming Languages and Systems, 1(2):178 190, 1992.   \n\t\t\t", "proc_id": "349299", "abstract": "", "authors": [{"name": "G. Ramalingam", "author_profile_id": "81100519054", "affiliation": "IBM T.J. Watson Research Center, P.O. Box 704, Yorktown Heights, NY", "person_id": "PP31045870", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/349299.349330", "year": "2000", "article_id": "349330", "conference": "PLDI", "title": "On loops, dominators, and dominance frontier", "url": "http://dl.acm.org/citation.cfm?id=349330"}