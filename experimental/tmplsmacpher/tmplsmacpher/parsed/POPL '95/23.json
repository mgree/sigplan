{"article_publication_date": "01-25-1995", "fulltext": "\n Default Timed Concurrent Constraint Programming Vij ay A. Saraswat Radha Jagadeesan Vineet Gupta (saraswat@parc.xerox.tom) \nradha@math.luc.edu vgupt a@p arc .xerox. com Systems and Practices Lab. Dept. of Math. Sciences Systems \nand Practices Lab Xerox PARC Loyola University Xerox PARC Palo Alto, Ca 94304 Chicago, 1160626 Palo Alto, \nCa 94304 (Extended Abstract) In such systems the fact that the environment has failed to respond in \nan expected way (i. e., an interrupt signaling a jam has not been received; a response to a password \nquery Abstract has not been received even though the time-period allowed has elapsed) is a piece of information \nof the same status as We extend the model of [SJG94b] to express strong time\u00ad information received in \nan explicit message from the envi\u00adouts (and pre-emption): if an event A does not happen ronment. In particular \nit should be possible to act instant a\u00adthrough time t, cause event B to happen at time t. Such neously \nin response to this implicit information (e.g., power constructs arise naturally in practice (e.g. in \nmodeling tran\u00ad should continue to be supplied to motors in the first case; sistors) and are supported \nin languages such as ESTER.EL the connection should time-out in the second). (through instantaneous watchdogs) \nand LUSTRE (through While the problem of representing and reasoning about the current operator). negative \ninformation is present in all reactive programming The fundamental conceptual difficulty posed by these \nop\u00ad languages, it shows up in a particularly pure form in frame\u00aderators is that they are non-monotonic. \nWe provide a sim\u00ad works based on a computational interpret at ion of logic, such ple compositional semantics \nto the non-monotonic version as concurrent constraint programming (CCP) [Sar93,SRP91]. of concurrent \nconstraint programming (CCP) obtained by This framework is based on the idea that concurrently ex\u00adchanging \nthe underlying logic from intuitionistic logic to Re\u00ad ecuting systems of agents interact by posting (telhng) \nand iter s default logic [Rei80]. This allows us to use the same checking (asking) constraints in a shared \npool of (positive) construction (uniform extension through time) to develop information. Constraints \nare expressions of the form X > Y, Default Timed CCP (Default tee) as we had used to develop or the sum \nof the weights of the vehicles on the bridge must Timed CCP (tee) from CCP [S JG94b]. Indeed the smooth \nnot exceed a given limit . They come equipped with their embedding of CCP processes into Defa u It cc \nprocesses lifts own entailment relation, which determines what pieces of to a smooth embedding of tcc \nprocesses into Defa u It tcc pro\u00ad information (e.g., X > Z) follow from which collections of cesses. \nInteresting tcc properties such as determinacy, multi\u00ad other pieces (e.g. X ~ Y, Y > Z). Synchronization \nis achieved form time, a uniform pre-emption construct ( clock ), full\u00ad by suspending ask agents until \nenough information is availa\u00adabstraction, and compositional compilation into automat a ble to conclusively \nanswer the query; the query is answered are preserved. affirmatively if it is entailed by the constraints \naccumulated Default tcc thus provides a simple and natural (deno\u00ad hitherto. tational) model capable of \nrepresenting the full range of Such a framework for concurrent computation is prov\u00adpre-emption constructs \nsupported in ESTEREL, LUSTRE and ing fruitful in several investigations [SKL90,HSD92, JH91, other synchronous \nprogramming languages. SHW94,Kac93], with applications in areas ranging from mod\u00ad eling physical systems, \nto combinatorial exploration and nat-Keywords: Programming paradigms constraint pro-ural language analysis. \ngramming, reactive systems, synchronous programming; For-There are however some fundamental limitations \nto this mal approaches denot ational semantics, semantics of con- monotonic accumulation approach to \nconcurrent compu\u00adcurrency tation. The Quiescence Detection Problem. Within 1 Introduction and Motivation \nthe framework, quiescence of computation cannot be de\u00ad tected and triggered on.1 Two examples should \nmake mat- We elaborate a framework for the design of programming ters clearer. languages that permit \ninstant aneous detection of negative information, that is, detection of the absence of information. Example \n1.1 (Histogram, due to K. Pingali) Assume given an array A[l ... n] taking on values in 1...m. It is \nPermi&#38;ion to oopy without fee all or part of this material is granted provided that the copies are \nnot made or distributed for desired to obtain an array B[l. . . m] such that for all k, direct commercial \nadvantaqe, the ACM copyright notice and the B[k] contains exactly the indices i such that A[i] = k. (The \ntitle of the publication and its date appear, and notice is given that copyin is by permission of the \nAssociation of Computing 1In many cases, qmescence detection can be exphcltly pro\u00adgrammed. However, this \ncan become quite cumbersome to achieve. Machinery. ? o copy otherwise, or to republish, requires a fee \nardor specific permission. POPL 951/95 San Francisco CA USA @ 1995 ACM 0-89791-892-1/95/0001 .....$3.50 \nhistogram of A can then be obtained by associating with lay (next ), and de{ayed negative ask (c w next \nA). 2 each kc l... m the cardinalit y of B [k]. ) The comput at ion c + next A auows A to be executed \nat the next time in\u00ad of B should be done in parallel. stant if the store on quiescence is not strong \nenough to entail In a language based on monotonic accumulation it is c. This allows the programming of \nweak time-outs if an possible to simultaneously assert, for every j c 1, . . n that event A does not \nhappen by time t, cause event B to hap\u00ad j c B[A[j]]. This is however, not good enough to force the pen \nby time t + 1 while still allowing the computation at sets B [k] to cent ain exactly the required indices \n all that is each time step to be monotone and determinate. We showed being forced is that B[k] cent \nains at least the given indices. that the mathematical framework of such an integration is n u obtained \nin a simple way by uniformly extending the mathematical framework of CCP over (discrete) time. In- Example \n1.2 (Composition of model fragments) Sim\u00ad deed, many complex patterns of temporal behavior such ilar \nexamples arise when using such languages for composi\u00ad as the do A watching c construct of ESTEREL which \nal\u00ad tional modeling of physical systems (see, e.g. [For88]). In lows the agent A to execute, aborting \nit at the time instant such an application computation progresses via repeated it\u00ad after a c is detected \n could be programmed as defined eration of two phases: a model-construction phase and a combinators in \ntee. In general, it was possible to capture model execution phase. In the construction phase, pieces \nthe idea of havirw rmocesses clocked bv other (recursive) of information ( model fragments ) about the \nvariables and processes, thus g&#38;/ing very powerful u~er-programmable~ constraints relevant in the \nphysical situation being modeled pre-emption control constructs. The denotational model is are ~enerat \ned. For examde. it mav be determined that some./ very simple and in full accord with an intuitive operational \nreal-valued variable, e.g. current; is monotonically depen\u00ad semantics and an underlying logic discrete \ntime, intu\u00ad dent on voltagedrop, and also on conductance. On ter\u00ad itionistic linear temDoral loiric. \nmination of this phase, it is desired to collect together all More generally, ~cc prov~des a powerful \nsetting in which the variables that current is now known to depend on (say, to program systems of reactive, \nembedded agents per\u00ad its just voltagedrop and conductance) and then postulate haps modeling aspects \nof the real, physical world which that these are the only variables that it depends on. That is, autonomously \nmaintain internal beliefs in the face of change it is desired to postulate the existence of a function \n~ and as\u00ad induced by interaction with the environment. At each step, sert the relationship current = \nf (volt agedrop, conductance ). the agent has an internal theory that describes its compu\u00ad u t ational \nstate, its assumptions about its environment, and rules for inferring new information from old. On the \nbasis Such detection of quiescence is inherently non-monotonic: of these, and the input information, \nthe agent decides to act if more information is provided in the input, di~ererzt (rather (send messages \nto the outside world) and revises its internal than just more) information may be produced at the output. \nstate. In particular, it is useful for agents to consider their beliefs to be interruptible, subject \nto abandonment in the The Instantaneous Interrupts Problem. An\u00ad face of new information communicated \nby the environment. other fundamental source of examples is real-time systems, The main drawback of the \ntcc model, however, is its where the detection of absence of information is necessary inability to express \nstrong time outs [Ber93]: if an event A to handle interrupts. To get at these examples, however, does \nnot happen by time t,cause event B to happen at time we first take a short detour to explain Timed Concurrent \nt.This is the behavior, for example, of the do A watching Constraint (tee) languages [SJG94b]. immediately \nc construct of ESTEREL: the execution of A tcc arises from combining CCP with work on the syn\u00ad is interrupted \nas soon as c is detected (rather than one step chronous languages such as [BG92], [HCP91], [GBGM91], \nlater). Weak time outs cause the action to be taken to be [Har87], [CLM91]. These languages are based \non the hy\u00ad queued up for the next interaction with the environment. pothesis of Perfect Synchrony: Program \ncombinators are While this unit delay is unproblematic in many cases, it is determinate primitives that \nrespond instantaneously to in\u00ad intolerable in cases where these delays can cascade, thereby put signals. \nAt any instant the presence and the absence of causing these queued actions to become arbitrarily out \nof signals can be detected. In synchronous languages, physical sync with the time when they were actually \nsupposed to time has the same status as any other external event, i.e. happen. If there is a feedback \nloop, then such a model of time is multiform. So, combination of programs with differ\u00ad pre-emption may \nsimply fail to work. ent notions of time is allowed. Programs that operate only on signals can be compiled \ninto finite state automata with Example 1.3 (Modeling a transistor) More concretely, simple transitions. \nThus, the single step execution time of consider a transistor whose emitter is grounded, and whose the \nprogram is bounded and makes the synchrony assump\u00ad collector is connected to high voltage by a resistor. \nUnless tion realizable in practice. there is current flowing into the base, the collector is not Integrating \nCCP with synchronous languages yields tee: shorted to ground, and remains pulled high. Because the at \neach time step the computation executed is a concur\u00ad user may desire to cascade several such transistors \n(and in\u00ad rent constraint program. Computation progresses in cycles: troduce feedbacks), it is not possible \nto tolerate a unit delay input a constraint from the environment, compute to quies\u00ad between detection \nof absence of current in the base, and de\u00ad cence, generating the constraint to be output at this time \ntermination of the status of the collector such unit delays instant, and the program to be executed \nat subsequent time can build up unfoundedly wrecking the timing information instants. There is no relation \nbetween the store at one time in the circuit being modeled. o instant and the next constraints that \npersist, if any, must explicitly be part of the program to execute at subsequent In addition, CCP allows \nfor a form of hiding, corresponding to existential quantification. The proper treat ment of hiding, hOwever, \ntime instants. introduces several complications that we have chosen to Ignore. See To the combinators \nof CCP (namely, tell (c), ask (c + Section 4 for more comments. A) and parallel composition (Al II AZ)), \ntcc adds unit de\u00ad Examples of the need for instantaneous detection of neg\u00adative information abound in \nthe literature on default rea\u00adsoning (e.g. [Rei80]). Example 1.4 (Constraint-based User Interfaces) Con\u00adsider \na setting like THmGLAB [Bor79], in which it is possible for users to draw diagrams, e.g. a parallelogram, \nthat must obey certain constraints. If the user moves a vertex of the parallelogram, then the system \nmoves other vertices in re\u00adsponse so as to maintain the constraints. Here it would not do to queue up \nthe computed location of a vertex X for the next interaction, because the user may move X in that in\u00adteraction. \nRather the location of the vertex should be com\u00adputed and displayed instantaneously, even if no constraint \non the location of the vertex arrives from the environment. D As an example of the use of tcc to model \naspects of time\u00advarying, real world situations, consider the following prob\u00adlem. Example 1.5 (Yale Shooting \nProblem, [Sho88]) The scenario to be modeled is this: a gun is loaded at time T = 2. It is fired at Fred \nat time T = 4. Inbetween, it is possible that the gun may have been subject to various other acts: for \nexample, it may have become unloaded. Various other common-sense facts are known: for instance, guns \nonce loaded do not spontaneously become unloaded, if a loaded gun is fired at a live person, and the \ngun is functioning normally, then the person may cease to be live, etc. In a setting such as this, it \nis crucial that a gun be deemed to be loaded at present only if it was loaded at some time in the past, \nand not unloaded at any time since then zn\u00adclucling the present. Similarly, for success, the gun should \nbe fired in the direction of the perceived current position of the target, not the known past position \nof the target. Even one-step delays introduced due to the modeling framework can invalidate the representation. \nD 1.1 Defaults The fundamental conceptual difficult y with the inst ant a\u00adneous detection of negative \ninformation is that it is not monotonic. On receipt of further information a conclusion arrived at earlier \nmay have to be withdrawn. This is just not expressible in the CCP framework, which is monotone. Fur\u00adthermore, \nno principled analyses of non-monotonic processes have hitherto been available which would allow us integrate \nthem into a reactive real-time programming framework. The fundamental move we now make is to allow the \nex\u00adpression of defaults, after [Rei80]. We allow agents of the form c + A (to be read as c else A ), \nwhich intuitively mean that in the absence of information c, reduce to A. Note however that A may itself \ncause further information to be added to the store; and indeed, several other agents may simultaneously \nbe active and adding more information to the store. Therefore requiring that information c be ab\u00adsent \namounts to making an assumption about the future evolution of the system: not only does it not entail \nc now, but also it will not entail c in the future. Such a demand on stabihty of negative information \nis inescapable if we want a computational framework that does not produce re\u00adsults dependent on vagaries \nof the differences in speeds of processors executing the program. How expressive is the resulting system? \nAll the ESTEREL\u00adstyle combinators, including do A watching immediately c (which we write as do A watching \nc) are now expressible (see Section 3.5). All the examples considered above can be represented here. \n(In the following always A is the agent that executes A at every time instant.) Example 1.6 (Histogram, \nrevisited) The program is: histogram(A, N, B, M) :: B : array (l..M), VI in I..N : (I in BIAII]]), VI \nin 1..M: VS Q BII] : S# BII] -S= BII]. Intuitively, for every subset S of l?[l] other than the largest \nsubset, it will be possible to establish that S # 11[1]. Hence, for each 1, the default will fire just \nonce for the largest subset, and will assert then that S is equal to the largest subset. For example, \nif the assertions 3 in B[2], 6 in B[2], 5 in B[2] had been made, then it can be estab\u00adlished that B[2] \n# {3, 6}. However, it cannot be established that B[2] # {3,5,6}. o The compositional modeling example \nis similar in flavor to the Histogram problem. Assertions about the dependence of a variable V on other \nvariables can be stated as positive pieces of information, e.g. as constraints imposing member\u00adship in \nthe set of dependent variables of V. The associated set can then be completed by using defaults as above, \nand then decomposed as a fully-formed set to build the term (e.g. f(vl, ..., Vn) to be equated to V). \nExample 1.7 (Default values for variables) Consider the program: default (X, V) ::X# V-+ X= V. It establishes \nthe value of X as V unless it can be estab\u00adlished that the value of X is something other than V. IJ Example \n1.8 (Transistor model) Using defaults, we can express the transistor model as: transistor(Base, Emitter, \nCollector) :: Emitter = Ov, Base = on--iEmitter == collector, default (Base, off), default (Collector, \n5v). In the absence of any information, the least reachable so\u00adlution is Collect or=5v, Base=of f; however \nin the presence of Base= on, we get Collect or=Ov, Base= on. n always VP,location(V) = P ~next default \n(location(V), P). Note that always the last value of the location will be tracked. Also note that every \nagent can be wrapped in a do/watching construct even an always assertion. Thus, if it was desired to \nbe able to retract the above de\u00adfault, all that needs to be done is to wrap it in a do/watching that \nawaits the retraction command (letfiloat (V)): do always VP.locat ion(V) = P -+ next default (location(V), \nP) watching let-float(V). D Example 1.10 (Yale Shooting Problem) Various elem\u00adents of this scenario can \nbe modeled directly. Variables are introduced to correspond to objects in the situation to be modeled \n(possibly with time-varying state). Constraints are placed on the values that the variables may take \nover time. Typically, one states (using a do/watching loop) that the value of a variable is to be kept \nthe same, unless some ac\u00adtions of interest take place. Actions are represented as base atomic formulas \nwhose applicability may be contingent on the presence of some information in past stores, and whose effect \nis stated in terms of changes in the values of affected variables from the present moment onwards. Thus, \nfor example, the occurrence of a load action causes the gun to maintain the state of being loaded until \nsuch time as an occurrence of a shoot or an unload action: always (occurs (load) -ido always loaded watching(occurs( \nshoot) V occurs(unload)))). The default. persistence of life, and other facts, are for\u00admulated as: do \nalways alive watching death. always occurs(shoot)-+loaded-+death. always occurs(shoot)-+= loaded. always \noccurs (unload) ~~loaded. always death+ always dead. Note that the death event causes the fluent dead \nto be unequivocally asserted for all time to come the state of being dead cannot be interrupted . Executing \na program like this, in the presence of no ad\u00additional information from the environment, will ensure \nthat Fred is dead when shot at time T = 4. II Model. First, what should a model for such a program\u00adming \nlanguage look like? The basic intuition behind our approach is as follows. An agent in CCP denotes a \nclo\u00adsure operator (a function on constraints that is idempotent, monotone and extensive) which can be \nrepresented by its range. In the presence of defaults, an agent A is taken to denote a set of closure \noperators, a different operator for each assumption with respect to which the defaults in A are to be \nresolved. That is, the denotation is a set of pairs Example 1.9 (Default setting for vertices) In this \nset\u00adting it may be desirable to impose the default that the lo\u00adcat ion of a vertex V remains unchanged, \nunless there is a reason to change it. This can be expressed by: Thus the addition of the construct \nc v A to the language gives us a very powerful programming system. However, three central issues arise \nimmediately. (~, C) where j is a closure operator on the sub-lattice of constraints below c. On this \nspace of denotations we de\u00adfine the combinators for conjunction (parallel composition), tell, positive \nask and negative ask, Furthermore, we provide a simple operational semantics and show that the denota\u00adtional \nsemantics is natural by providing a full-abstraction theorem. Checking for Determinacy. Second, a program \nmay now easily have zero or more distinct evolution paths fterminatirw in different answers). as ormosed \nto CCP in . . /, ... which there is exactly one distinct evolutlon path terminat\u00ading in a single answer. \nFor example, the program X = 1 + A = 1 (or more generally c * c) allows the addition of X = 1 in the \nempty store . . . only to have that violate the assumption underlying its addition, namely that X = 1 \nnot be entailed by the store. So this program has no evolution path. Similarly the program (X = 1 w Y \n= 1) II (Y = 1 * X = 1) has multiple evolution paths one in which the first assumption is made, resulting \nin the addition of Y = 1 to the store (which blocks the assumption of the second de\u00adfault), and one in \nwhich the second assumption is made, resulting in the addition of X = 1 (which blocks the as\u00adsumption \nof the first default). In reactive systems intended for embedded control, preserving system determinacy \nis cru\u00adcial, and thus identifying determinate programs (those with exact ly one distinct evolution path, \non every input) is a cen\u00adtral problem. In Section 2.3 we present an algorithm uniform over constraint \nsystems to check at compile-time whether a program is determinate or not. The key idea here is to recognize \nthat the effect of running a program P on any input d can be simulated by running the program on one \nof only finitely many projections (onto the space of constraints the program can discriminate on). This, \nin essence, allows a finite representation of the effects of P on any input, and hence provides an algorithm \nfor checking that every input is mapped to a single output. Unfortunately, because of the free composition \nof defaults allowed, such a determinacy checking algorithm cannot be compositional: determinacy is a \nglobal property of the entire program, and cannot be established by examining pieces in isolation. Compiling \nprograms. Third, how are programs to be implemented efficiently? A naive implementation may in\u00advolve \nperforming the act ual guessing at run-time, and back\u00adtracking if the assumption about the future evolution \nof the system is violated dynamically. In Section 2.3 we show (ex\u00adtending [S JG94b]) that in fact it \nis possible to (composi\u00adtionally) compile determinate (recursion-free) programs into finite constraint \nautomata so that there is no guessing or backtracking involved at run-time. We are able to achieve compositionality \n unlike compilers for ESTEREL and LCTS-TRE by labeling the nodes of the automata with Defau It cc programs \n(for which a notion of parallel composition is already defined). Rest of this paper. The rest of this \npaper contains the detailed technical development of these ideas. After a discussion of related work, \nwe develop and explore the mathematical foundation, operational semantics, determi\u00adnacy checking and \ncompilation algorithms for Default cc, and then reD eat this for Defa u k tee. In Dartic ular, we de\u00advelop \na sound and complete axiomatization for the (mono\u00adtonic) logic of default cc programs. This logic can \nbe used to establish the equivalence of two agents A and B.  1.2 Related work. More broadly our contributions \ncan be cast in the following general light. The integration of defaults with constraint programming is \na long-standing problem for which there has been no clean mathematical or practical solution. We believe \nthat this paper makes a basic contribution to this problem, with ramifications in non-monotonic reasoning \nand knowledge representation. Furthermore, from the viewpoint of the theory of (synchronous) reactive \nsystems, the basic model we present can be adapted, with minor adjustments to provide a model for ESTEREL \nand LUSTRE as well in\u00addeed Default tcc provides a setting in which ESTEREL and LUSTRE can be combined \nsmoothly. Non-monotonic reasoning. Our work builds on [Rei80] directly, and is related to the stable \nsemantics model of [GL88]. To our knowledge this is the first paper that pro\u00advides a compositional semantics \nfor default logic and that mathematically connects default logic with reasoning about time-outs in reactive, \nsynchronous programming. There is a very large literature on non-monotonic reason\u00ading ([GHR94] is a recent \nhandbook on this subject), doing justice to which is not possible in the space available to us. So a \nfew remarks will have to suffice. Our analysis seems to brirw the following novel ideas to the research \naround non-monotonic reason~ng. First, we explicitly introduce the notion of a two-level logical system: \nthe program combi\u00adnators provide a logical scaffolding on top of an underly\u00ading logical language of constraints. \nQuestions of entailment and disentailment have to be decided purely with respect to constraints. This \nmakes the languages far more practical than non-monotonic formalisms based directlv on reasoning . about \nentailment/disentailment in full first-order logic; since the constraint language can be chosen so that \nits expressive\u00adness, and hence complexity, is appropriate for the needs of the application at hand. Second, \nwe explore these ideas in the context of agents embedded in an autonomous world with which they cannot \ncontrol the rate of interaction. This necessarily implies that the com~utations that an agent can afford \nto Derform be\u00adtween in~eractions with the ~xternal world mus{ be limited, indeed bounded by some a priori \nconstant. In Default tcc this means that recursion in a time instant is not allowed; consequently there \nis hope for compiling away default pro\u00adgrams into a finite state machine, so that only some very simple \ntests have to be done at run-time. Third, the notion of reactive computation forces us to view a default \ntheory as a triansducen it must be open to the receipt of unknown new information at run-time, and must \nproduce then an extension beyond that input. This emphasis on the relational nature of default deduction \n also to be found in [MNR90 ,MNR92] is a key idea behind our development of a denotational semantics. \nIt forces us not to look at just what is deducible from the given theory, but ask what is deducible from \nthe theory in the presence of new information. And in particular, it causes is to develop conditions \nfor the determinacy of default programs. Similarly, the desire to get a denotationcd semantics for such \ntransducers forced us to ask the question: what as-Dects of the internal construction of a default theorv \n. need to be preserved in order for us to construct the denotation of a conjunctive composition from \nthe denotation of its con\u00adstituents? It forced us to develop the interm.dlogic of default theories: A \nk B if any observation that can be made of B can also be made of A. This logic can be used to establish \nthe equivalence of two default agents. To our knowledge, the development of such an inference relation \nbetween de\u00adfault programs is original to this paper. The model presented in this paper smoothly enriches \nthe model in [S J G94b] by allowing the instantaneous detection of negative information. All the results \nof [S J G94b] continue to hold in this richer setting; there is a straightforward em\u00adbedding of (the \ndenotations of) tcc programs into Defau It tee. Concurrent constraint Programming. A non\u00admonotonic framework \nfor cone urrent constraint program\u00adming has been presented in [dBKPR93]. The paper focuses on providing \nfor general constructions for retracting con\u00adstraints once they have been established, and for checking \nfor disentailment. A version of existential are worked out. The connection between this work and default \nlogic (and its notions of extensions) and reactive programming is however, not clear. This will be the \nsubject of future investigations. Synchronous languages. The synchronous langua\u00adges mentioned above implicitly \nadopt specialized forms of default reasoning for handling absence of signals: A signal is absent at a \ntime instant if and only if it is not emitted by some process. This paper extends this view to generic \nconstraint systems, and provides a formal recipe to design snch languages. Our analysis breaks down the \ndesign of syn\u00adchronous languages into three inter-related components: (1) details of actual synchronization \nmechanisms are suppressed through the entailment relation of a constraint system (2) the notion of defaults \nis analyzed at the level of the ba\u00adsic (untimed) concurrent logic language (3) the synchronous language \nis obtained by extending the untimed language uni\u00adformly over time. In addition, this analysis clarifies \nthe hith\u00aderto not well understood relationship between the combina\u00adtors that are present in the above \nlanguages. We show that Timed Default CCP supports the derivation of a clock construct that allows a \nprocess to be clocked by another (re\u00adcursive) process; it generalizes the undersampling constructs of \nSIGNAL and LUSTRE, and the pre-emption/abortion con\u00adstructs supported by ESTEFUZL3. 3tcc exhibited this \nrelationship for monotone/weak pre\u00ademption/abortion constructs Timed Default CCP generalizes this to \nnon-monotone/instantaneous pre-emption and abortion 2 Default Concurrent Constraint Program\u00adming 2.1 \nBasic model Constraint systems. A constraint system [Sar92] is essentially a first-order system of partial \ninformation. Briefly, we may understand a constraint system C as coming equipped wit h the following \ndata: (1) a set D of first-order formulas (closed under variable renamings, where an infinite underly\u00ading \nset of variables is assumed) called primitive constraints or tokens, and (2) an inference relation t-c \nthat is finitary (in that it relates finite sets of tokens to tokens), decidable and records which tokens \nfollow from which collection of tokens. Let the +-closed subsets of D be denoted by ID I. (l D/, ~) is \na complete aJgebraic lattice; we will use the notation U and n for the joins and meets of this lattice, \nand the name true for the element D. A (finite) constraint is an element of [Dl generated from a (finite) \nset of tokens; for a set of tokens u, we will use ii to denote the closure of u under +. We usually denote \nfinite sets of tokens by the letters a, b, anj constraints by the letters c, d, e. We write a x b if \nii = b. Sometimes, we will say d entails e to mean that d ~ e. For real-time computation we have found \nthe simple con\u00adstraint system Gentzen (~) to be very useful [SJG94a]. The tokens of Gentzen are atomic \nformulas drawn from a pre\u00adspecified logical vocabulary; the entailment relation is triv\u00adial, i.e. cl, \n. . . . Cn FG c iff c = c~ for some i. Gentzen provides the very simple level of functionality that is \nneeded to rep\u00adresent signals, e.g. as in ESTEREL and LUSTRE. 2.1.1 The model. What should a model for \ndefaults look like? Consider first the definition of the model for CCP [SRP91]. The crucial insight there \nwas to develop a very simple no\u00adtion of observation: observe for each agent A those stores d in which \nthey are quiescent, that is those stores d in which executing A does not result in the generation of \nany more information. Formally, define the predicate AJd (read: A converges on d ). The intended interpretation \nis: A when executed in d does not produce any information that is not entailed by d. We then have the \nevident axioms for the primitive combinators: abort There are no rules for abort: it does not converge \non any input. Tell The only inputs on which a can converge are those which skeady cent ain the information \nin a: Ask The first corresponds to the case in which the ask is not answered, and the second in which \nit is:  Ji.-2L (a+ A)Jd (a flf)Jd Parallel Composition To converge on d, both components must converge \non d: Al + AZld (A, II A,) Jd Note that these axioms for the relation are composi\u00adtional : whether an \nagent converges on d is determined by some conditions involving whet her its sub-agents converge on d. \nThis suggests taking the denotation of an agent A to be the set of all d such that A J.d; because of \nthe axioms above, the denotation is compositional. We can now use the denotational semantics of an agent \nto reason about the actual input/output behavior (the op\u00aderational semantics ): the output of an agent \nA on an input c is exactly the least d above c (if any) for which A converges. Conversely, one can ask \nwhich sets of observations can be viewed as determining the denotation of a process. The answer is quite \nstraightforward: the key idea is that from the set it should be possible to determine a unique output \nabove every input (if the process converges). That is, the set S should have the property that above \nevery (input) constraint c, there is a unique minimal element in S (the o utput). We can say this generally \nby requiring that S be closed under glbs of arbitrary non-empty subsets. In particular, 0 is a process \n the process which diverges on every input, i.e. 0 is the denotation of abort. We thus have an independent \nnotion of processes, on which all the combinators of interest to us are definable. Two further questions \narise: (1) Expressive completeness: are all processes definable by agents, and (2) Full abst rac\u00adtion: \nif the denotations of two agents A and B are distinct, then is there in fact a context, i.e. a third \nagent P with a hole in it, such that plugging the hole with A and B separately would produce agents with \nobservably different behaviors? If the given language is expressively complete, then we know that everv \nrnocess is the denotation of some . agent. If the model is fully abstract for the given language and \nnotion of observation, then we know that the model does not make distinctions that are too fine: if the \ndeno\u00adt ations of two agents are different, then there is a reason, namely, there is another agent which \ncan be used to distin\u00adguish between the two. Together, these two nice properties imply that a logic for \nreasoning about processes (semantic entities) can be used to reason safely about agents and their operational \nbehavior. The model for CCP we motivated above is both expres\u00adsively complete and fully abstract. Adding \ndefaults. How does the situation change in the presence of defaults? The critical question is: how should \nthe notion of obser\u00advation be extended? Intuitively, the answer seems obvious: observe for each agent \nA those stores d in which they are quiescent, given the guess e obout the jinai result. Note that the \nguess e must always be stronger than d itmust con\u00adtain at least the information on which A is being \ntested for quiescence. Formally, we define a predicate A J: (read as: A converges on d under the guess \ne ). The intended in\u00adt erpret ation is: if the guess e is used to resolve defaults, then executing A \nin d does not produce any information not entailed by d, and executing A in e does not produce any information \nnot entailed by e. We then have the evident axioms for the primitive com\u00adbinators: abort There are no \nrules for abort: it does not converge on any input. Tell The information about the guess e is not needed: \nd~a  a 1: Positive Ask The first two rules cover the case in which the ask is not answered, and the \nthird the case in which it is: 2 ~ AJ: (a: AfJ~ (a+A)~~ (a+ A)J~ Parallel Composition Note that a guess \ne for AI II AZ is propagated down as the guess for AI and Az: Al J: AZ1: (AI 1[Az) J: Negative Ask In \nthe first case, the default is disabled, and in the second it can fire: d e3a e (a+ A)J~ (aflj)~~ Again, \nnote that these axioms for the relation are com\u00adpositional : whether an agent converges on (d, e) is \ndeter\u00admined by some conditions involving whether its sub-agents converge on (d, e). This suggests taking \nthe denotation of an agent A to be the set of all (d, e) such that A l:; be\u00adcause of the axioms above, \nthe denotation is compositional. Furthermore, we can recover the input/output relation ex\u00adhibited by \nA from its denotation: the output of A on input c are exactly those d s above c such that A J.: and there \nis no constraint e ~ c distinct from d such that A J:. That is, the result of running A on input c should \nbe just those constraints d such that A can produce no more information than d (under the guess that \nd is the output), and such that there is no place to stop above c and strictly below d (so that d, can, \nin fact, be generated by A on input c). Again, conversely, one can ask which sets S of observa\u00adtions \ncan be viewed as determining the denotation of a pro\u00adcess. The two intuitive conditions we wish to capture \nare the following: Local determinacy the idea is that once a guess is made, every process behaves like \na determinate CCP agent. This is expressed by saying that under every guess d (that is, for every d such \nthat (d, d) E S) the set of constraints on which the process is claimed to be convergent under the guess \nd (i.e., the set {c \\ (c, d) 6 S}) should be closed under glbs. The second idea to capture is the anti\u00admonotoniczty \nof defaults the only affect a stronger guess can have is to cause fewer defaults to fire, resulting in \neven more convergent points. This is the requirement that for every agent A, if it converges on input \nd under the guess e, then it is going to also converge on input d under any guess e ~ e. We now have \nthe basic ideas in hand to proceed some\u00adwhat more formally. We establish the basic notion of a pro\u00adcess, \nprovide an operational semantics for processes, explore some properties, and show that the model is fully \nabstract. The basic model. Definition 2.1 (Observations) SObs, the set of simple observations is the \nset {(d, e) c 1111x 1111[ e ~ d}. n For a set S and element e, we use the notation (S, e) to stand for \nthe set {(d, e) I d E S}, and ns to stand for the greatest lower bound of S. Definition 2.2 (Process) \nA process P is a set of simple observations satisfying: Guess-convergence (e, e) E P if (d, e) c P Local \nDeterminacy (ilS, e) c P if S # 0 and (S, e) ~ P. Anti-monotonicity (c, e) ~ P if (c, d) G P, d ~ e, \n(e, e) c P. Processes are naturally ordered by inverse set inclusion: define P < Q if P ~ Q. Under this \nordering, SObs is a process, the least process which converges on every con\u00adstraint; it is the denotation \nof the agent true. 0 is the unique maximal process. Furthermore, the limit of every chain of processes \nis itself a process: that is, given a set of processes sllJs2 ..., the set n, S, denotes a process. This \nmeans that recursion can be handled in the model: the denotation of a recursive agent A is simply the \nintersection of the deno\u00adtation of the all the agents obtained by replacing recursive calls by i-fold \nexpansions. We can now provide exriicit semantic definition for var\u00adious combinators: D[abort] ~ 0 D[a] \n~ {(d, e) c SObs d~a} D[a ~ A] ~ {(d, e)c SObs D[a-+A] ~ {(d, e)c SObs [e ~ a a (d, e) c D[A]} D[A II \nB] : DIA]II D[B] Each of these combinators is seen to yield a process when applied to a process, and \nto be continuous and monotone in its process argument. Recursion. Default cc programs are given as a \nset of declarations g :: A along with an agent. (Here g names a procedure. ) The names of the agents \ng can now occur in the program. We will denote a recursively defined process as uX. A[X]. As indicated \nabove, the meaning of recursive processes is obtained in the standard way by taking least fixed points \nin the given complete partial order of processes. Obtaining the operational semant its. HOW do we obtain \nthe result of executing an agent A on an input constraint i from the denotation D[A]? The output is going \nto be all those constraints o ~ i such that there is no place for the process to stop strictly below \no: Definition 2.3 (1/0 mapping) The input-output relation r(P) induced by a process P is defined by: \n~(P) ={(i, o) CSObsl(o, o)~P, v(j, o) CP. j~i+j=o} II Note that T(P) may be no~-monotone, e.g. r(D[a \n-b]) is non-monotone it maps 0 to ~ and E to ~. (A relation R is non-monotone iff it is not monotone. \nIt is monotone iff a R band a ~ a implies there is a b z bsuch that a R ht.) Examples. With the above \ndefinitions, we can work out on configurations indexed by final constraints e that will the denotation \nof any Default cc process. Here we consider two interesting examples. D[a-+ a]= {(d, e)cSObs Ie ~ a} \nThis is an example of a default theory which does not have any extensions [Rei8 O]. However, it does \nprovide some in\u00adformation, it says that the quiescent points must be greater than a, and it is necessary \nto keep this information to get a compositional semantics. It is different from b + b, whereas in default \nlogic and synchronous Iauguages both these agents are considered the same, i.e. meaningless, and are \nthrown away. D[a+bll a-b]= {(d, e)< SObsle2b, ((e2a)v(d2a))+d2b} This agent is almost like if a then \nb else b , and illustrates the basic difference between positive and negative informa\u00adtion. In most semantics, \none would expect it to be identical to the agent b. However, a + b is not the same as ma ~ b, in the \nsecond case some agent must explicitly write =U in the store, if -a is a constraint, but in the first \ncase merely the fact that no agent can write a is sufficient to trigger b. This difference is demonstrated \nby running both b and a* bII a-+ bin parallel with b+ a bproduces aUbon true, while a -+ b II a * b produces \nno output. These two examples show that designing a logic for this language is not entirely trivial. \nWe come back to this a little later. Expressive completeness. Given a process S, is there a finite (recursion-free) \nagent A such that S = D[A]? We can characterize the class of processes for which this is possible these \nare precisely the finite elements in the lattice of processes (.P < Q s P ~ Q). Recall that a finite \nelement P is one such that if U, P, ~ P, then there is a P,~ P. Now given any process P, we can write \ndown a (possibly infinit ary) agent which has P as its denotation. For each (e,e) GP, define P. = {d \nI(d, e) c P}. Then Pc is (the fixed-point set of) a closure operator, and can be written as an ask-tell \nagent. Now form the conjunction lle(~; -G-... -Pe) for all e c g(P), where z~ s are aJl the constraints \ngreater than e. We also take all the constraints e which are mapped to nothing by the i/o relation, and \nadd the agents e ~ abort to the agent. The antimonotonicit y property assures us that the denotation \nof this agent is P. Theorem 2.1 If P is a finite process, then its agent can be expressed finitely. Conversely, \nevery finite agent denotes a jlnite process. operational semantics A simple non-deterministic execution \nmechanism (operational semantics) can be pro\u00ad vided for recursion-free Defa u It cc by extending the \nopera\u00ad tional semantics of cc computations. We take a configuration to be simply a multiset of agents. \nFor any configuration r, let o(r) be the subset of primitive constraints in 17. We define binary transition \nrelations +~ be used to evaluate defaults: ~(r) + a (r,a + B) +, (r,B) 0(1 ) 1-a (r, a-+ B)-er (r, A \nII 1?) +. (r, A,B) From this family of transition relations, we may provide a definition of the operational \nsemantics: Definition 2.4 OIA] ~ {(z, e) E SObs I31. (A, a) J. B +. and a(B) %e} o The result of running \nA on input a, TOIA](Z), may be extracted thus: {e I (E, e) c @[A]}. The operational semantics described \nabove can be used to compute the result of running the agent in a given store only if the final store \nis known beforehand. For finite agents P, we now show how this non-determinism can be bounded, and hence \nmade effective (e.g., by backtracking). Let c(P) be the sublattice generated by the finite number of \nconstraints that syntactically occur in P. Now, clearly, any input d can be mapped by P only to some \nelement in d u c(P)(~ {d U e I e E c(P)}. Therefore rO(P)(d) can be computed by considering just the \nfinitely many relations { ~. I e Cd Uc(P)}. Full abstraction. The following results establish the connections \nbet ween these two characterizations: Theorem 2.2 Cl[A] = D[A] and ro([A])(d) = r([A])(d) Theorem 2.3 \n(Full abstraction for Default cc) 1.f D[P] # D[Q], then there exists an agent C such that P II C is observatzonally \ndistinct from Q it C. Proof Sketch 2.3 Since the two denotations are different, suppose there is a (cl, \ne) E D[P], but (d, e) @ D[Q]. Now if (e, e) @Q, then since (d, e) E D[P] + (e, e) G D[P], e is an agent \nseparating P and Q. Otherwise, we follow extant proofs in [SRP91,JPP91]. Consider the closure operators \nP. = {d I (d, e) c D[P]} and Qc = {d I (d, e) c D[Q]}. These are unequal, so differ on some input, say \na. If Pe(a) ~ Q.(a), then the agent a II (P.(a) + e) is the required agent: a II (P.(a) + e) II P produces \ne, but a II (Pe(a) + e) // Q does not. (Note that if Pe(a) and Q=(a) are not finite, there is some finite \nelement where they differ, and this may be chosen instead. ) o Determinate processes. Definition 2.5 \n(Determinate processes) A process P is said to be determinate if T(P) is the graph of a total func\u00adtion. \nH How can the functions generated by determinate pro-sequent is valid if every observation that can \nbe made of cesses be characterized? system consisting of the A, running in parallel can be made Closure \noperators are functions ~ : L -+ L that satisfy of (at least) one of the BJ. In the following, we will \nlet r, A (for all a,b &#38; L): range over multisets of agents. a(r) will stand for the sub\u00admultiset \nof constraints in r and M l (17) for the multiset a< fb-fa<fb (1) {a I Ma c 17}. The Structural and Identity \nrules of inference for the and logic are the rules of Exchange, Weakening and Contraction, a< b~fa<fb \n(2) and the Identity and Cut rules. Thus the logic is classical. The other proof rules are: The functions \ngenerated by determinate processes will continue to satisfy Condition 1. Instead of being monotone, however, \nthey are locally monotone: ~(r) Ea c -;(;) ;f~aE a (M)r+ A,a a< b< fa--+fa<fb (3) Let us call functions \nthat satisfy Conditions 1 and 3 local closure operators. We now show that the i/o functions asso\u00adciated \nwith determinate processes are precisely local closure operators. ,! Definition 2.6 For f : L + L a local \nclosure operator, define p(f), the process associated with ~, by: Let u[A] be defined as U~~A [A]. Note \nthat while in general the union of two processes is not a process, the re\u00adstriction that we place upon \nA all but one of its processes JO) ~ {(4c) c sobs If(e) = e~(f(d) = e + d = e)} is of the form Ma ensures \nthat it is a process. In fact, [Ma] U [A]= [a --T A]. Theorem 2.6 (Soundness) r t-A implies [17] ~ u[A]. \neasy to verify that p(f) is a process. In fact, p(f) is maximal Roughly, p(f) is the complement of the \ngraph of f. It is Proof Sketch 2.6 Straightforward. The only possibly non\u00adamong all processes whose i/o \nrelation is given by f. trivial case is R + which is proved thus. Theorem 2.4 r(p(f)) = f In fact (r, \np) form a Galois connection. Determinate, Monotone processes HOW do CCP processes embed in the space \nof Default CC processes? It is easy to see that: The last step follows since r is a process, [Ma] U [A] \n= [a+ A]andb+ a--+ A=a~b -A. c1 Proposition 2.5 For any process P, r(P) is the graph of a monotone function \naff P sattsjies the property: Completeness is proved by structural induction on the non-t rivial formula \nB in A. Monotonicity (d, d) c P if (d, e) 6 P. Theorem 2.7 (Completeness) [r] ~ u[A] zmplies r +In such \na case, the fixed point set of r(P) is just {d I (d, d) C A P}. Conversely, given a closure operator \nf, the Default cc process corresponding to it is given by {(d, e) c SObs I d, e ~ Proof Sketch 2.7 Suppose \nthe non-trivial formula B = b. f}. Then the left rules are applied until they can be applied no further. \nNow the left side consists of a, Ma], ..., kfa~, and 2.2 Logic for Default cc some implications (which \nare ignored). Now if we cannot use (M) to prove In this section we consider a proof-system for recursion-free \nDefault cc agents. a, Mal, ..., Makl-Mbl,. ... Mb~, b The denotational semantics for Default cc induces \na nat\u00adural logic, namely the logic for proving, for agents A and then that means that for each Mb, on \nthe right, there must B that [A] s [B]. Note that this logic is necessarily a be a pair (Z, %() on the \nleft such that ~ ~ ~. Then the pair monotone logic. (E, m~~}) is also on the left, and so it must be \nin [b]. So The syntax of formulas in the logic is E ~ b, and we can use (C) to prove the result. The \nother cases for B are straightforward. For B = (Agents) A ::= al Mala+Ala-+A IAll A (4) B1 A Bz, apply \nRA, and use the proof trees for BI and B2. Sequents are of the form Al, . . . . An k Bl, ..., B~, where \nFor B = a + B , apply R + and use the proof tree for B . For B = a + B , proceed as follows. By assumption \nevery cept at most one of the Bj is of the form Ma, which is (d, e) c [r] lies either in [a -+ B ] or \nin [A]. But this is understood to stand for a * a. We say that the remain-means that (d, e) E [I \\l a] \nimplies (d, e) G [B , D], which the A,, Bj are all agents, with the requirement that all ex\u00adcan be established \nby the induction hypothesis. c1ing Bj is the non-trivial formula of the RHS. Intuitively, a 2.3 Default \ncc: Implementation issues We consider now the implementation of recursion-free De\u00adfault cc agents these \nare the agents that will be generated by a compiler for Defa u It tee. The two key issues to be resolved \nare: a determinacy detection algorithm, and an implementation of Default cc. Note that both these issues \nare resolved by the operational semantics. However, the operational semantics involves guessing of defaults; \nthus, a priori, it is not clear that it induces a backtracking free implementation of Defa u It cc. Following \nsynchronous languages, we will exploit the deno\u00adtational semantics to yield an efficient implementation, \nThe key idea behind both aspects of the implementa\u00adtion is to construct a finite representation of T(P) \n the input-output behavior of the process P. This construction is developed formally below. Definition \n2.7 Let C be a constraint system. Then, 13(C) is the free Boolean Algebra over the generators (constraints \noccurring in C) and relations (c ~ d = true, if c ~ d). o The finite constraint system relevant to an \nagent P, de\u00adnoted CP, is the sub-Boolean algebra of l?(C) that is gener\u00adated by the constraints occurring \nin P. Note that Cp is a finite poset. Also, since CP has finite joins, it can be viewed as a constraint \nsystem. Furthermore, there is a natural pro\u00adjection function p : C + Cp defined as p(d) = U{c c CP Id+ \nc= true in II(C)} Though we have described p(d) abstractly, we note that for any d c C, p(d) can be computed \nusing the entailment relation of C (i.e. queries to the constraint solver) and the axioms of Boolean \nAlgebras. In this extended abstract, we do not present these standard details. Determine the denotation \nof the agent P with respect to the constraint system CP. In turn, this denotation yields a jinite input-output \nrelation, denoted by rf (P). The fol\u00adlowing theorem relates rf (P) to T(P) -the input-output relation \nof P with respect to the constraint system C. Theorem 2.8 (Representation theorem) r(P)(d) = {du d I \nd c r~(P)(p(d)), for any agent P. The above theorem is exploited to yield a determinacy detection algorithm \nand a compilation algorithm for Default cc. Determinacy detection: The determinacy of P is estab\u00adlished \nby showing that rf (P) is the graph of a function. Compilation: The relation rf (P) is computed at compile \ntime. The execution proceeds as follows. On input d, first compute p(d); next, use the relation rf (P) \nto determine the output on p(d); next, use Theorem 2.8 to determine the output of P in d. This last step \ninvolves one more tell action on the constraint solver. 2.4 Definable eombinat ors We now show how to \ngeneralize the ask combinator (c ~ A) to allow for simple process arguments. Intuitively, in 13 ~ A, \nB evolves only if the store is a quiescent point of A. Formally, Ill -+ A is defined as: D[B+A] ~ { (d, \ne)< Obsl (d, e) c D[A] % (d, e) c DUB], (e, e) c D[A] + (e, e) G D[B]} However, B + A may not be a process \nfor arbitrary D[B]. So, we will restrict the processes B to be generated by the grammar: B ::= c]13\\l \nB[c~abort For such processes B, 11 ~ A is indeed a process. The extension to process arguments can be \ncompiled away composition ally to the existing combinators of Defa u It cc using the laws: (c-+abort)~A \n= c-A (B, IIB,)+ A = B, + (B, IIA) 3 Timed Default CCP We consider now the extension of Defa u It cc \nto the Timed setting.  3.1 Basic Model First, we extend the set of observations over time: Definition \n3.1 Ohs, the set of observations, is the set of finite sequences of simple observations, n Intuitively, \nwe shall observe the quiescent sequences of interactions for the system. We let s, u, v range over sequences \nof simple observations, and let z be a simple observation. We use (e to denote the empty sequence. The \nconcatenation of sequences is denoted by . ; for this purpose a simple observation z is regarded as the \none-element sequence (z). Given S ~ Obs and s G Ohs, we will write S after s for the set {z ~ SObs Is \n.z c S] of simple observations of S in the instant after it has exhibited the observation s. Definition \n3.2 P ~ Obs is a process iff it satisfies the fol\u00adlowing conditions: 1. (Non-emptiness) c G P, 2. (Prefix-closure) \ns 6 P whenever s o tc P, and 3. (Determinacy) P after s is a Default cc process when\u00adever s6P.  II \nThe new combinators introduced by the additional struc\u00adture are: ~[Skip] ~ Obs D[abort] ~ {.} D[next \nl?] ~ {c} U {z .s 6 Obs The definitions of the other basic combinators of Default tcc are straightforward \ncounterparts of their definitions for Default cc. D[a] ~ {(d, e). se Obsld~a} Guarded Recursion. Defa \nu It tcc programs are given as a set of declarations g :: A along with an agent. (Here g names a parameterless \nprocedure.) The names of the agents g can now occur in the program, the only restric\u00adtion being that \nthey occur within the scope of a next . This is necessary to make the computation in each step lex\u00adically \nbounded, and also gives us unique solutions for recur\u00adsive equations. We will write a recursively defined \nagent as ,uX.A[X]. 3.2 Operational semantics The operational semantics for Defa u It tcc is just like \nthe op\u00aderational semantics for tcc except that a Defa u It cc agent is executed at every time step rather \nthan a cc agent. Fur\u00adther details are provided by the automata construction in Section 3.4. The proof \nof full abstraction for Defa u It tcc follows es\u00adsentially immediately from the proof for Default cc: \nTheorem 3.1 (Full abstraction for Default tee) It D[F ] # D[Q], then there exists a context C such that \nP II C as ob.seruationally dzstanct from Q 1[ C. 3.3 Determinacy detection for Default tee. From the \ncompilation algorithm described below, it suffices to describe an algorithm to check the determinacy \nof a finite recursion free Defa u It cc agent a Default tcc agent is determinate iff the Default cc \nagents at each node of the compiled automaton are determinate. 3.4 Compilation Default constraint automata \nThe automata con\u00adstruction for Default tcc is similar to the construction for tcc provided in [S JG94b]. \nA Default cc automaton is specified by the following data (1) a set of states Q, with each state q E \nQ labeled with a Default cc agent (2) a distinguished start state, and (3) a set of directed edges between \npairs of states, labeled with constraints. The set of labels will be drawn from the constraints of the \nfinite sublattice of con\u00adstraints occurring in the agent. The automaton will satisfy the property that \nfor every node the set of labels on outgoing edges are closed under least upper bounds (lubs). The execution \nis as follows The automaton starts in the start state. Upon receiving an input Z, it executes its De\u00adfau \nIt cc agent P in conjunction with the input, and the out\u00adput, r(P)(i) is the output for this time instant. \n(The Defau It cc agent can be executed as described in Section 2.2.) The edge labeled with the greatest \nconstraint less than r(P) (i) is then taken to a new state, where this process is repeated. In order \nto prove the finiteness of the number of states, we need the notion of a derivative of an agent. Given \na pro\u00adcess P, a derivative of P is a process {t ~ Obs I s ~t e D[.P]} this is the residual process after \nP has produced the se\u00adquence of observations s. The finiteness of the number of states of the automaton \nis then guaranteed by the following theorem. Theorem 3.2 Every Default tcc agent has a jinite number \nof derivatives. Each stat e now corresponds with one derivative, which predicts the entire future of \nthe process. Compilation algorithm. Following synchronous languages, Theorem 3.2 induces a non-compositional \ncom\u00adpilation of Default tcc agents. However, Default tcc admits a compositional compilation as well. \nWe sketch below the au\u00adtomaton construction for parallel composition and a + P, the other cases are simple \nand hence omitted. Automaton for ~1 II P2. This is a variant of the classical product construction on \nautomata. We are given the Default cc automaton for PI and P2, say Al and A2 respectively. The states \nof the automaton for PI II P2 are induced by pairs of states ql, qz from Al, A2. We will call the induced \nstate (ql, qQ). The start state corresponds to the pair of start states. The Default cc agent in (ql, \nq2) is the parallel composition of the agents in the g, s. Now transitions are induced by the following \nrule if on output a, there is a transition from ql to q; in Al, and also on output a there is a transition \nfrom q2 to g; in AZ, then we get a transition on a from (gl, q2 ) to (q{, ~~). In order to determine \nall the possible transitions, we take all the a s in the finite sublattice of the constraint system generated \nby the constraints in agents in ql and q2. Automaton for a -.-+ P. The automaton for a + P is derived \nfrom A, the automaton for P. We make a copy q~ of the start state q. of A, and label it with the Defa \nu It cc agent a + q, where g was the Defau It cc agent labeling qo. For each transition from go to ql \nlabeled by d, we create a transition from gj to ql, if 6! ~ a. We also create a transition from qj to \na dead state and label it a. The rest of the automaton for a -+ P is a copy of the automaton of P. 3.5 \nDefinable Combinators We present clock a powerful derived combinator, and show how to define a number \nof other common patterns of tem\u00adporal activity in terms of it. The clock combinator. clock B do A is \na process that executes A only on those instants which are quiescent points of B. It is the extension \nof the Defa u It cc construct B + A over time. Clearly, it is in the flavor of the when con\u00adstruct (undersampling) \nin LUSTRE and SIGNAL, generalize to general processes B instead of boolean streams. Let P be a process. \nWe identify the maximal subse\u00adquence tPof the sequence tthat is an element of the process Th e tollowmg \nlaws hold f or the clock combmator: clock a do A = a+All a * next clock a do A clock a-abort do A = aw \nA clock (131 II B2 ) do A = clock B1 do (clock B2 do i clock u~ next BdoA = a+ clock next BdoAII a+A \nclock a-+next BdoA = aw clock next BdoAII a+A For P = next B, we do a case analysis on A: clock next \nB do abort = abort clock next B do sldp = skip clock next Bdo b = b clock next B do (A1 II Az) = (clock \nnext B do AI) (clock next B do Az) clock next B do (b+ A) = b+ clock next B do J clock next B do (b+ \nA) = b+ clock next B do ~ clock next B do (next A) = next clock II do A Recursion in either argument \nis now done by expanding the code we expand pX.A[X] to A[~X.A[X]], and th~ same for B, and then apply \nthe laws above. Table 1: Laws for clock P. tp is defined inductively as follows. Ep=e (SP) . (d, e), \nif (d, e) C (P after SF) (s. (d, e))p = (sP), otherwise { Now, recognizing that A is executed only at \nthe quiescent points of B we can state: clock B do A ~ {t c Obs It~u~n ~ D[A]} However, B + A may not \nbe a process for arbitrary D[B]. So, we will restrict the processes B to be generated by the grammar: \nB ::= alBllBla~abort la ~ next B la + next B lpX.B[X] For such processes B, B + A is indeed a process. \nThe laws that allow us to eliminate occurrences of the clock construct are given in Table 1, Expressiveness. \nWe now show how various primitive combinators in ESTEREL and other languages can be de\u00adfined on top of \nclock. We use the following abbreviations. always A executes A repeatedly; it is the agent pg.A II next \ng. whenever a do A executes A at the first instant at which a is entailed; it is the agent pg. (a ~ A) \nII (a \u00adnext g). (Note that whenever a do A = clock a do A.) Multiform time: time A on a. time A on c \ndenotes a process whose notion of time is the occurrence of the tokens a A evolves only at the time \ninstants at which the store entails a. This is definable as: time A on a = clock (always a) do A Watchdogs: \ndo A watching a. This is an in\u00adterrupt primitive related to strong abor-tionin ESTEREL [Ber93J. do A \nwatching a behaves like A till a time instant when a is entailed; when a is entailed A is killed instantaneously. \n(We can similarly define the related exception handler prim\u00aditive, do A wat thing a timeout B, thatalso \nactivates a handler B when A is killed.) Using clock this is definable as: do A watching a = clock (whenever \na do abort) do A Suspension-Activation primitive: SaAb(A). This is a preemption primitive that is a variant \nof weak susp\u00adension in ESTEREL [Ber93]. &#38;.&#38;(A) behaves like A till a time instant when a is entailed; \nwhen a is entailed A is sus\u00adpended from the next time instant onwards (hence the S.). A is reactivated \nin the time instant when b is entailed (hence the Ah). The familiar (control -Z, fg) is a construct in \nthis vein. ~This can be expressed as: &#38;Ab(A) = clock (whenever a do next b) do A Compiling clock. \nThe laws given in Table 1 provide one way of removing the clock construct from the top level. However \nit is possible to directly compile an automaton for clock B do A given the automata for A and B. The \ncon\u00adstruction is similar to the product construction described above. The states of the automaton are \ngiven by the Carte\u00adsian product of the states of the automata for A and B. If pl is the agent labeling \na state ql in A, and pz labels q2 in B, then the label for (ql, qz) is the Default cc agent pz +p~. The \nsyntax for the processes B ensures that the Default cc process pz -+ pI is well-defined; i, e. pz satisfies \nthe conditions in Section 2.4. Transitions from the state (ql, qz ) are given as follows consider all \nthe a s in the finite sublat tice of the constraints occurring in pl, pz. If (a, a) is not in the denotation \nof PZ, then there is a transition back to the state (ql, 92 ). If (a, a) is in the denotation of p2, \nthere is a transition on a from (91, 92) to (q{, q;) where, on a, the automaton for A goes to q; and \nB goes to qj, 4 Conclusion and acknowledgements This paper has used ideas from non-monotonic reasoning \nto extend real-time languages with a coherent, mathemati\u00ad cally tenable notion of interrupts. The topic \nhas been de\u00ad veloped using the methodology of concurrency theory and denotational semantics of programming \nlanguages: the con\u00ad struction of a model, and the definition of a language and a process algebra on the \nmodel, and the definition of a logic for reasoning about substitutability of programs in the lan\u00ad guage. \nFrom our perspective, this synthesis of ideas is long overdue. Fundamentally the fields of Qualitative \nPhysics, Reasoning about action and state change, reactive real-time 283 computing and hybrid systems, \nand concurrent program\u00adming languages are about the same subject matter: the rep\u00adresentation, design \nand analysis of (at least partially com\u00adputational) continuous and discrete dynamical systems. We look \nforward to further developments in this very rich area. The very simple compositional semantics for default \nlogic opens up several possibilities. It is now possible to develop coherent notions of timed default \nlogic, and possibly hybrid default logic, for talking about action and change for systems involving continuous \nand discrete values. Existential. Another avenue for future work is to en\u00adrich the model to allow for \nthe definition of first-order exis\u00adtential (hiding). Somewhat surprisingly, hiding is not de\u00adfinable \nin the current model. Intuitively, the process X A is supposed to behave like the process A[Y/X], where \nY is some new variable distinct from any variable occurring in the environment. The reason is simple. \nThe union of two processes is not a process. Therefore, the internal choice (or blind choice) combinator \nA n B of Hoare is not expressible in the model. Intuitively, A n B is expected to behave like either \nA or B, and the choice cannot be influenced by the environment. Hiding, can, however, mimic internal \nchoice, in the pres\u00ad ence of defaults. To illustrate, consider the process A ~ (X=l-Y=l, X= 2) II(X=2-Z=l, \nX= l). These are two conflicting defaults. The process contains in its denotation the observations ((Y \n= 1,X = 2), (Y = l, Z=l, X=2)), and(Z=l, X= l), (Y=l, Z= I,X= 1)). However, no information about X can \nappear in the de\u00adnotation of the process X A. Consequently, one would ex\u00adpect .Y A to exhibit the observation \n(Y= 1, (Y = 1, Z = 1)) and (Z= 1, (Y= l,Z = l)). If X Ais to be a process how\u00adever, it be locally determinate: \nit must also exhibit the glb of these two observations, namely (true, (1 = 1, Z = 1)). However, it cannot \ndo that, since it must either produce Y = 1 or produce Z = 1. Thus, X A cannot be a process. A pathway \nfor resolving this problem seems clear: one must move to a richer model where in fact local determinacy \nis not required and such hidden choices can be expressed. Similar ideas have been worked out in [SRP91] \naround the semantics of the indeterminate cc languages (which support blind choice). We expect to elaborate \nsuch a model in future work. Future work. The use of concurrent constraint pro\u00ad gramming as a basis for \na synchronous language provides a natural setting for the combination of the combinators of Esterel and \nLustre. The development of clock, a gen\u00ad eral strong preemption construct, should lead to a theory of \n strong preemption, which could not have been developed in tee. The underlying logical basis for the \nmodel of the present paper needs to be explored further. This should lead to the development of an intuitionistic \nversion of temporal default logic. Acknowledgements. We gratefully acknowledge dis\u00adcussions with Gerard \nBerry, George Gonthier, Johan de Kleer, Danny Bobrow and Markus Fromherz. We thank Peter Bigot for comments \non earlier version of the paper, and the POPL referees for surprisingly detailed reviews. Work on this \npaper has been supported in part by ONR through grants to Vijay Saraswat and to Radha Jagadeesan, and \nby NASA. References [Ber93] G. Berry PreemptIon m concurrent systems, In Proc, of FS7 TCS Sprmger-Verlag, \n1993, LNCS 781 [BG92] G Berry and G Gonthler The esterel programming lan\u00adguage. Design, semantics and \nImplementation Sczence of Computer Programming, 19(2):87 152, November 1992. [Bor79] Alan Borning, THINGLAB-A \nconstraint orzented sim\u00adutatton {aborator-y. PhD thesm, Stanford, 1979. Also published as Xerox PARC \nReport SSL-79-3, July 1979, [CLM91] E M Clarke, D E Long, and K, L McMillan, A language for compositional \nspecification and verification of finite state hardware controllers Proceedings of the IEEE, 79(9), September \n1991 [dBKPR93] Frank S. de Boer, Joost N, Kok, Catuscia Palamidessi, and Jan J,M,M. Rutten. Logtc Programming \n Pro\u00adceedings of the 1993 International Symposzum, chapter Non-monotonic Concurrent Constraint Programming \nMIT Press, 1993, [F0r88] Ken Forbus. llcplomng A?-ttjctaf Inte/?tgence, chapter Qualitative Physics Past, \nPresent and Future, pages 239 296 AAAI and Morgan Kaufmann, 1988 [GBGM91] P Le Guernic, M Le Borgne, \nT. Gauthler, and C Le Maine Programmmg real time applications with signal In Spectal zssue on Another \nLook at Real-tzme Systems, Proceedings of the IEEE, September 1991, [GHR94] Dov M Gabbay, C J Hogger, \nand J A Robinson, edi\u00adtors, Handbook of Logzc tn Artafictal Intelligence and Logzc Programming, Vol 3: \nNonmonotonac Reasonzng and Uncertain Reasonzng Oxford Science Publications, 1994. [GL88] Michael Gelfond \nand Vladlmm Lifsch~tz The stable model semantics for loglc programming. In Logzc Pro\u00adgramming: Proceedings \noj the Fafth Intematzonal Con\u00adference and Sympostum, pages 1070-1080, August 1988, [Har87] D Harel Statecharts. \nA visual approach to complex systems, S czence of Computer Prog~ammzng, 8.231 274, 1987. [HCP91] N Halbwachs, \nP Caspl, and D Pdaud The synchronous programming language Iustre. In Spec%al %ssue on An\u00adother-Look at \nReal-t%me Systems, Proceedings of the IEEE, Special issue on Another Look at Real-time Sys\u00adtems, September \n1991 [HsD92] Pascal Van Hent enryck, VIJ ay A. Saraswat, and Yves Deville Constraint processing in cc(fd) \nTechmcal re\u00adport, Computer Science Department, Brown University, 1992. [JH91] Sverker J anson and Seif \nHarldl. Programmmg Paradigms of the Andorra Kernel Language In Logzc Programming: Proceedings of the \n1991 International Symposzum MIT Press, 1991. [JPP91] R Jagadeesan, P, Panangaden, and K, Pingali, A \nfully\u00adabstract semantics for a functional language with logic variables. ACM Transactions on Programming \nLan\u00adguages and Systems, 13(4), October 1991, [Kac93] Hassan Alt Kacl. An introduction to LIFE Program\u00adming \nwith Logic, Inheritance, Functions and Equations In Dale Mdler, editor, Logtc Prograrnmtng, Proceedings \nof the 1993 International Sympos%um, MIT Press, 1993. [MNR90] W Marek, A Nerode, and J, Remmel A theory \nof non\u00admonotomc rule systems i, Annals of Mczthernattcs and Artzfictat Intelhgence, 1:241 273, 1990 \n[MNR92] W. Marek, A, Nerode, and J Remmel, A theory of non. monotomc rule systems ii Annals of Mathematics \nand AWzf7cta/ Intelhgence, 5229 264, 1992 [Rei80] Ray Reiter A logic for default reasoning Artzficzat \nIn\u00adteikgence, 13.81 132, 1980, [Sar92] [Sar93] [Sho88] [SHW94] [SJG94a] [SJG94b] [SKL90] [SRP91] Vi.jay \nA. Saraswat. The Category of Constraint Systems is Cartesian-closed. In Proc 7th IEEE Symp. on Logtc \nan Computer S c%ence, Santa Crwr, 1992. ViJay A. Saraswat. Concurrent Gonstra%nt Program\u00ad ming. Logic \nProgramming and Doctoral Dissertation Award Series MIT Press, March 1993. Yoav Shoham. Chronological \nignorance: Experiments in nonmonotonic temporal reasoning. Ar-tzficta? lntel?z\u00adgence, 36279 331, 1988 \nGert Smolka, Henz, and J, Werz Constraint Program\u00ad ming: The Newport Papers, chapter Object-oriented \nprogramming in Oz MIT Press, 1994 Vi.j ay A. Saraswat, Radha J agadeesan, and Vineet Gupta. Constr-atnt \nPrograrnrnzng, chapter Programming in Timed Concurrent Constraint Languages. NATO Ad\u00advanced Science Institute \nSeries, Series F: Computer and System Sciences. Springer-Verlag, 1994. To appear m LNCS. Vij ay A Saraswat, \nRadha Jagadeesan, and Vineet Gupta. Foundations of timed concurrent constraint pro\u00adgrammmg. In Samson \nAbramsky, editor, Proceedings of the N%nth Annual IEEE Sympostum on Logac an Com\u00adputer Science. IEEE \nComputer Press, July 1994 Vijay A. Saraswat, Ken Kahn, and Jacob Levy Janus: A step towards distributed \nconstraint programmmg. In Pr-oceedzngs oj the North Ame?_ican Conjevence on Logzc Programming, October \n1990 Vij ay A. Saraswat, Mart m Rlnard, and Prakash Panan\u00adgaden, Semantic foundations of concurrent constraint \nprogramming. In Proceedings of Eighteenth ACM Sym\u00adposaum on Prznctples of Programming Languages, Or\u00ad \n?ando, January 1991. \n\t\t\t", "proc_id": "199448", "abstract": "<p>We extend the model of [SJG94b] to express strong time-outs (and pre-emption): if an event <italic>A</italic> does not happen through time <italic>t</italic>, cause event <italic>B</italic> to happen at time <italic>t</italic>. Such constructs arise naturally in practice (e.g. in modeling transistors) and are supported in languages such as ESTEREL (through instantaneous watchdogs) and LUSTRE (through the &#8220;current&#8221; operator).</p><p>The fundamental conceptual difficulty posed by these operators is that they are non-monotonic. We provide a simple compositional semantics to the non-monotonic version of concurrent constraint programming (CCP) obtained by changing the underlying logic from intuitionist logic to Reiter's default logic. This allows us to use the same  construction (uniform extension through time) to develop Default Timed CCP (<bold>Default tcc</bold>) as we had used to develop Timed CCP (<bold>tcc</bold>) from CCP. Indeed the smooth embedding of CCP processes into <bold>Default cc</bold> processes lifts to a smooth embedding of <bold>tcc</bold> processes into <bold>Default tcc</bold> processes. Interesting <bold>tcc</bold> properties such as determinacy, multiform time, a uniform pre-emption construct (&#8220;clock&#8221;), full-abstraction, and compositional compilation into automata are preserved.</p><p><bold>Default tcc</bold> thus provides a simple and natural (denotational) model capable of representing the full range of pre-emption constructs supported in ESTEREL, LUSTRE and other synchronous programming languages.</p>", "authors": [{"name": "Vijay A. Saraswat", "author_profile_id": "81100152268", "affiliation": "Systems and Practices Lab., Xerox PARC, Palo Alto, Ca", "person_id": "P291132", "email_address": "", "orcid_id": ""}, {"name": "Radha Jagadeesan", "author_profile_id": "81100214384", "affiliation": "Dept. of Math. Sciences, Loyola University, Chicago, Il", "person_id": "P237380", "email_address": "", "orcid_id": ""}, {"name": "Vineet Gupta", "author_profile_id": "81100020249", "affiliation": "Systems and Practices Lab., Xerox PARC, Palo Alto, Ca", "person_id": "PP14020191", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/199448.199513", "year": "1995", "article_id": "199513", "conference": "POPL", "title": "Default timed concurrent constraint programming", "url": "http://dl.acm.org/citation.cfm?id=199513"}