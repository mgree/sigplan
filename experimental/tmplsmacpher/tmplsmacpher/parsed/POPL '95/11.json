{"article_publication_date": "01-25-1995", "fulltext": "\n Compiling Polymorphism Using Intensional Type Analysis* Robert Harpert Greg Morrisett$ School of Computer \nScience Carnegie Mellon University Pittsburgh, PA 15213-3891 Abstract Traditional techniques for implementing \npolymorphism use a universal representation for objects of unknown type. Of\u00adten, this forces a compiler \nto use universal representations even if the types of objects are known. We examine an al\u00adternative approach \nfor compiling polymorphism where types are passed as arguments to polymorphic routines in order to determine \nthe representation of an object. This approach allows monomorphic code to use natural, efficient represen\u00adtations, \nsupports separate compilation of polymorphic defi\u00adnitions and, unlike coercion-based implementations \nof poly\u00admorphism, natural representations can be used for mutable objects such as refs and arrays. We \nare particularly interested in the typing properties of an intermediate language that allows run-time \ntype anal\u00adysis to be coded within the language. This allows us to compile many representation transformations \nand many lan\u00adguage features without adding new primitive operations to the language. In this paper, we \nprovide a core target lan\u00adguage where type-analysis operators can be coded within the language and the \ntypes of such operators can be accurately tracked. The target language is powerful enough to code a variety \nof useful features, yet type checking remains decid\u00adable. We show how to translate an ML-like language \ninto the target language so that primitive operators can analyze types to produce efficient representations. \nWe demonstrate the power of the user-level operators by coding flattened tuples, marshaling, type classes, \nand a form of type dynamic within the language. Introduction Many compilers assume a universal or boxed \nrepresen\u00adtation of a single machine word if the type of a value is unknown. This allows the compiler \nto generate one simple *This work was sponsored by the Advanced Research Projects Agency, CSTO, under \nthe title The Fox Project: Advanced De\u00ad velopment of Systems Software , ARPA Order No. 8313, issued \nby ESD/AVS under Contract No. F19628 91 C-016S. tE-mail: ~wh@cs.cmu.edu $E-mail: jgmorris@cs.cmu. edu \n Permission to copy without fee all or part of this materfal is granted provided that the copies are \nnot made or distributed for direct commercial advantage, the ACM copyright notice and the title of the \npublication and its date appear, and notice is given that copying is by permission of the Association \nof Computing Machinery. To copy otherwise, or to republish, requires a fee and/or specific permission. \nPOPL 95 1/95 San Francisco CA USA @ 1995 ACM 0-89791-692-1/95/0001 ....$3.50 piece of code to manipulate \nthe value. But boxed represen\u00adtations often require more space and provide less efficient access than \nnatural representations. For example, an array of small unknown objects, such as booleans or characters, \nis represented as an array of words, wasting the majority of the space. An object larger than a word, \nsuch as a double\u00adprecision floating-point value, is allocated and a pointer is used in place of the value. \nConsequently, accessing the value requires an additional memory access. As word sizes in\u00adcrease from \n32 to 64-bits, and memory latencies increase, it becomes increasingly important to minimize boxing. In \nmodern programming languages such as Modula-3, Standard ML (SML), and Haskell, unknown types and thus \nboxed representations arise because of two key language fea\u00adtures: types imported from a separately compiled \nprogram unit and types within polymorphic routines. Polymorphic values are particularly troublesome because \nwe can simulta\u00adneously view them as having any one of an infinite number of monomorphic types. For example, \na polymorphic routine that maps a function across the elements of an anay can be simultaneously seen \nas a function that works on boolean arrays and a function that works on real arrays. The routine can \nthus be used in place of a function that was compiled knowing whether the argument array contains booleans \nor reals. Consequently, monomorphic routines are forced to use the same representations as polymorphic \nroutines and the entire program pays the price of the increased space and execution-time overheads of \nthe universal representations. 1.1 Coercion Implement at ions The problem with polymorphism stems from \nthe assumption that vtewmg a polymorphic value as a monomorphic value should have no computational effect. \nRecent work by Leroy [30] and others [41, 24, 43] has suggested that the instantia\u00adtion of a polymorphic \nvalue should correspond to a run-time coercion from the universal representation to the appropri\u00adate \nspecialized representation. At function types, this re\u00adquires the dual coercion (for the function argument) \nthat converts specialized representations to the universal repre\u00adsentation. For example, when the identity \nfunction of type Va.cY ~ a is instantiated to have type int -+ int, a coer\u00adcion is generated that takes \nan integer argument, boxes it, passes it to the identity function, and unboxes the result. This approach \nallows monomorphic code to use the natural, efficient representations. Leroy s coercions produce an isomorphic \ncopy of a data structure. For example, to coerce a tuple, we project the components of the tuple, box/unbox \nthem, and then form a new tuple. Unfortunately, copying coercions are impractical for large data structures \nsince the cost of making the copy of\u00adten outweighs the benefits of the unboxed representation (as pointed \nout by Leroy [30, page 184]). More problematically, copying coercions do not work for mutable data structures \nsuch as arrays, If we make a copy of the value to box the components then updates to the copy will not \nbe reflected in the original array and vice versa.  1.2 Type Passing An alternative approach to coercions, \nfirst suggested by the Napier 88 implementation [37], is to pass the types that are unknown at compile-time \nto primitive operations at link\u00adtime or even run-time. Then the primitive operations can analyze the \ntype in order to select the appropriate code to manipulate the natural represent ation of an object. \nFor ex\u00adample, a polymorphic subscript function for arrays might be compiled into the following pseudo-code: \nsub = Aa.typecase a of bool a boolsub [ real a realsub [ ~ + boxedsub[~] Here, sub is a function that \ntakes a type argument (a), and does a case analysis to determine the appropriate special\u00adized subscript \nfunction that should be returned. For exam\u00adple, sub[bool] returns the boolean subscript function that \nexpects an array of bits, while sub[rea 1] returns the floating point subscript function that expects \na double-word aligned array of floating point values. For all other types, we assume the array haa boxed \ncomponents and thus return the boxed subscript function. If the sub operation is instantiated with a \ntype that is known at compile-time (or link-time), then the overhead of the case analysis can be eliminated \nby duplicating and spe\u00adcializing the definition of sub at the appropriate type. For example, the source \nexpression Su b(z, 4) + 3.14 will be compiled to the target expression Sub [rea 1](z, 4) + 3.14 since \nthe result of the sub operation is constrained to be a real. If the definition of sub is inlined into \nthe target expression and some simple reductions are peformed, this yields the optimized expression real \nsub(z, 4) +3.14 . Thus, parameterizing the primitive operations by type provides a single, consistent \nmethodology for type analysis at compile\u00adtime, link-time, and run-time. In languages where polymorphic \ndefinitions are restricted to computational values (essentially constants and func\u00adtions), polymorphic \ndefinitions can always be duplicated and specialized or even inlined. Lazy languages such as Hsskell \nsatisfy this constraint, and Wright has determined empir\u00adically that such a restriction does not effect \nthe vast ma\u00adjority of SML programs [52]. Languages like core-SML and Haskell only allow polymorphic values \nto arise as the result of a let binding and restrict the type of such values to be prenex-quantified. \nThat is, the type must be of the form Vm,. ... cin .T where r contains no quantifier. Thus, the only \nthing that can be done to a polymorphic value is to instan\u00adtiate it. Since the scope of a let is closed, \nit is possible to determine all of the instantiations of the polymorphic value at compile time and eliminate \nall polymorphism through du\u00ad plication andd specialization. Such an approach is used, for instance, by \nBlelloch et al. in their NESL compiler [6] and more recently by Jones to eliminate Haskell overloading \n[27]. Furthermore, Jones reports that this approach does not lead to excessive code-blowup. Unfortunately, \neliminating all of the polymorphism in a program is not always possible or pratical. In particular, there \nis no way to eliminate the polymorphism when sepa\u00adrately compiling a definition from its uses because \nit is im\u00adpossible to determine the types at which the definition will potentially be used. This prevents \nus from separately com\u00adpiling polymorphic libraries or polymorphic definitions en\u00adtered at a top-level \nloop. Furthermore, in languages that al\u00adlow polymorphic values to be first-class such as XML [21] and \nQuest [9], it is impossible to eliminate all polymorphism at compile-time. Therefore, we view duplication \nand spe\u00adcializat ion as an important optimization, but consider some run-time type analysis to still \nbe necessary for practical km\u00adguage implementation. 1.3 Type-Checking Type Analysis In this paper, we \nshow how to compile ML-like polymorphic languages to a target language where run-time type anal\u00adysis \nmay be used by the primitive operations to determine the representation of a data structure. We are particularly \ninterested in the typing properties of a language that al\u00adlows run-time type analysis. The sub definition \nabove is ill-typed in ML because it must simultaneously have the types boolarray x int + bool, realarray \nx int + real, ae well aa Va. (~) boxedarray x int + a Since boolarray and real array are nullary constructors \nand not instantiations of (a) boxedarray, it is clear that there is no ML type that unifies all of these \ntypes. Our approach to this problem is to consider a type sys\u00adtem that provides analysis of types via \na type-level (Type\u00adcast construct. For example, the sub definition above can be assigned a type of the \nform: Vcr.SpclArray[~] x int + cr where the specialized array constructor SpclArray is defined using \nTypecase as follows: SpclArray[~] = Typecase a of bool +-boolarray I real * realarray I ~ +-(~) boxedarray \n The definition of the constructor parallels the definition of the term: If the parameter a is instantiated \nto bool, then the resulting type is boolarray and if the parameter is instan\u00adtiated to real, the resulting \ntype is real array. In its full generality, our target language allows types to be analyzed not just \nby case analysis, but also via primitive recursion. This allows more sophisticated transformations to \nbe coded within the language, yet type checking for the target language remains decidable, An example \nof a more sophisticated translation made possible by primitive recur\u00adsion is one where arrays of tuples \nare represented as tuples of arrays. For example, an array of bool x real is represented as a pair of \na boolarray and a realarray. This representation al\u00adlows the boolean components of the array to be packed \nand allows the real components to be naturally aligned. The subscript operation for this represent at \nion is defined using a recursive typecase construct called typerec in the following Ifsubis given a product \ntype, ~1 xrz, it returns a function that takes a pair of arrays ((x, y)) and an index (i) and returns \nthe pair of values from both arrays at that index, recursively calling the sub operation at the types \nrl and m. manner: typerec sub[bool] = boolsub Isub[real]= realsub lsub[~,x~z] = A((x, u), i).(sub[n] \n(x, i), sub[n] (y, i)) lsub[~]= boxedsub[~] The type of this sub operation is: Va. RecArray[a] x int \n+ cr where the recursive, specialized array constructor RecArray is defined using a type-level Typerec \n: Typerec RecArray [bool] = boolarray [ RecArray [real] = realarray I RecArray [n x 72] = RecArray[~,] \nx RecArray[m] I RecArray[~] = (~) boxedarray Again, the definition of the constructor parallels the defini\u00adtion \nof the sub operation. If the parameter is instantiated to bool, then the resulting type is boolarray. \nIf the parameter is instantiated with rl x 72, then the resulting type is the product of RecArray[~l] \nand RecArray[n]. Run-time type analysis can be used to provide other use\u00adful language mechanisms besides \nefficient representations. In particular, ad hoc polymorphic operators, such as the equality operator \nof SML, or an overloaded operator ex\u00adported from a Haskell type class, can be directly imple\u00admented in \nour target language without the need to tag val\u00adues. Furthermore, the static constraints of SML S equality \ntypes and Haskell s type classes may be coded using our Typerec construct. Our target language is also \nable to ex\u00adpress marshaling of data structures and a form of type dynamic. In Section 2 we describe the \ntype-analysis approach to compilation as a type-based translation from a source km\u00ad guage, Mini-ML, to \nour target language, J,ML. The key properties of A,ML are stated, and a few illustrative exam\u00adples involving \ntyperec and Typerec are given. In Section 3 we show how many interesting and useful language constructs \ncan be coded using typerec, including flattened representa\u00adtions, marshaling, type classes, and type \ndynamic. In Sec\u00adtion 4 we discuss related work, and in Section 5 we summa\u00adrize and suggest directions \nfor future research. Type-Directed Compilation In order to take full advantage of type information during \ncompilation, we consider translations of typing derivations from the implicitly-typed ML core language \nto an explicitly\u00adtyped target language, following the interpretation of poly\u00admorphism suggested by Harper \nand Mitchell [20]. The source language is based on Mini-ML [11], which captures many of the essential \nfeatures of the ML core language. The tar\u00ad get language, ~~~, is an extension of A L, also known as XML \n[21], a predicative variant of Girard s FW [16, 17, 42], enriched with primitives for intentional type \nanalysis. 2.1 Source Language: Mini-ML The source language for our translations is a variant of Mini-ML \n[11]. The syntax of Mini-ML is defined by the following grammar: (monotypes) -r ::= t/int[7_l -+~2171x7_2 \n[:*) L7 ::= 7-[ Vt.u e ::= xlfil(el,ez)17rle/mel Ax. e/ele211etz= vine (values) v ::= xlfil (vi, v2) \nIke. e Monotypes (r) are either type variables (t), i nt, arrow types, or binary product types. Polytypes \n(a) (also known as type schemes) are either monotypes or prenex quantified types. We write Vtl ,.... \ntn.rto represent the polytype Vtl. . . .Vt~.r. The terms of Mini-ML (e) consist of identifiers, numerals \n(fi), pairs, first and second projections, abstractions, appli\u00adcations, and let expressions. Values (v) \nare a subset of the terms and include identifiers, integer values, pairs of values, and abstractions. \nThe static semantics for Mini-ML is given in Figure 1 as a series of inference rules. The rules allow \nus to derive a judgement of the form A; 17 D e : T where A is a set of free type variables and r is a \ntype assignment mapping identifiers to polytypes. We write to denote the substitution of [T/t]T the type \n-r for the type variable tin the type expression ~ . We use A u A to denote the union of two disjoint \nsets of type variables, A and A , and 17w {x : a} to denote the type assignment that extends I so that \nx is assigned the polytype u, assuming z does not occur in the domain of 17. Let-bound expressions are \nrestricted to values so that our translation, which makes type abstraction explicit, is correct (see \nbelow). 2.2 Target Language: ~,~~ The target language of our translations, APL, is based on AML [20], \na predicative variant of Girard s Fti [16, 17, 42]. The essential departure from the impredicative systems \nof Girard and Reynolds is that the quantifier Vt.u ranges only over small types, or monotypes , which \ndo not include the quantified types. This calculus is sufficient for the inter\u00adpretation of ML-style \npolymorphism (see Harper and Mitchell [20] for further discussion of this point.) The language A~L extends \nJML with intentional (or structural [19]) polymor\u00ad phism, that allows non-parametric functions to be \ndefined by intensional analysis of types. ML, kinds (k), construc- The four syntactic classes for Ji \ntors (p), types (a), and terms (e), are given below: (kinds) K ::= (con s) p ::= (types) a ::= (terms) \ne ::= (cl, ea) o I 7rf ff2 e / 7r~1 a2e ] At::~. e I e[p] I typerec p Of [t. C7](ei [e+ IeX ) Kinds \nclassify constructors, and types classify terms. Con\u00adstructors of kind Q name %mall types or monotypes \n. The monotypes are generated from Int and variables by the F2 V([~n/tn](. . . ([~+1]~) . . .)) G A (var) \n(int) A;r D ii : int A;rw{$:vtl,..., tn.T} b z : [Tn/&#38;z](. . . ([TI/tl]T) . . .) (pair) A;rbel:~l \nA; I D(el, &#38;~De2:T2 ez) :71 xrz (m) A;17~e:~lx~z A;r D7r%e:T% (i= 1,2) (abs) A;rw{z:~1}be:72 A;r \nDAx. e: Tl+T2 (app) A;r Del:7 +T A;17Pelez:r A;r De2:T Au{tl,. . . ,tn}; rDV: 7_ (let) A;rw{x: A; vtl,..., \ntT.}De:T:T I Dletz=vine:~ Figure 1: Mini-ML Typing Rules constructors + and x. The application and abstraction \ncon\u00adstructors correspond to the function kind ISl -+ ~Z. Types in Ai ~ include the monotypes, and are \nclosed under prod\u00aducts, function spaces, and polymorphic quantification. We distinguish constructors \nfrom types, writing T(,u) for the type corresponding to the constructor p. The terms are an explicitly-typed \nA-calculus with explicit constructor abstrac\u00adtion and application forms. The official syntax of terms \nshows that the primitive op\u00aderations of the language are provided with type information that may be used \nat run-time. For example, the pairing operation is (el, ez ) 1 U2, where e~ : a~, reflecting the fact \nthat there is (potentially) a pairing operation at each pair of types. In a typical implementation, the \npairing operation is implemented by computing the size of the components from the types, allocating a \nsuitable chunk of memory, and copying the parameters into that space. However, there is no need to tag \nthe resulting value with type information because the projection operations (r:  e) are correspond\u00adingly \nindexed by the types of the components so that the ap\u00adpropriate chunk of memory can be extracted from \nthe tuple. Similarly, the application primitive (QU el ez) is indexed by the domain type of the functionl \nand is used to determine the calling sequence for the function. Of course, primitive operations can ignore \nthe type if a universal representation is used. Consequently, the implementor can decide whether to use \na natural or universal representation. We use a sim\u00adplified term syntax without the types when the information \nis apparent from the context. However, it is important to bear in mind that the type information is present \nin the fully explicit form of the calculus. The Typerec and typerec forms provide the ability to define \nconstructors and terms by structural induction on monotypes. These forms may be thought of as eliminatory \nforms for the kind f2 at the constructor and term level. (The introductory forms are the constructors \nof kind Q; there are no introductory forms at the term level in order to preserve the phase dktinction \n[8, 21].) At the term level typerec may be thought of as a generalization of typecase that provides for \nthe definition of a term by induction on the structure of a monotype. At the constructor level Typerec \nprovides a similar ability to define a constructor by induction on the 1In general, application could \nalso depend upon the range type, but our presentation is simplified greatly by restricting the depen\u00addency \nto the domain type. structure of a monotype. The static semantics of #L consists of a collection of rules \nfor deriving judgments of the following forms, where A is a kind assignment, mapping type variables (t) \nto khds, and r is a type assignment, mapping term variables to types. APp::K p is a constructor of kind \nK AD,ul=pz::E pI and ,uz are equivalent constructors APO u is a valid type A~01cu2 UI and uz are equivalent \ntypes A; J7Pe:u e is a term of type u The formation rules for constructors are largely stan\u00addard, with \nthe exception of the Typerec form: AP,LL::f2 A>~i::~ ADp+ ::o+fl+fc+lc+ti APpx :: O+G+K+K+K A D Typerec \nP of (~il~-.t l~x ) :: K The whole constructor has kind n if the constructor to be analyzed, p, is of \nkind fl (z. e., a monotype), ~i is of kind I% andp+and pxaxe eachof kind!d+fl-rt-+~+tc. The constructor \nequivalence rules (see Figure 2) axiom\u00adatize definitional equality [47, 31] of constructors to consist \nof @conversion together with recursion equations governing the Typerec form. Conceptually, Typerec selects \n~i, PX, or p+ according to the head-constructor of the normal form of p and passes it the components \nof p and the unrolling of the Typerec on the components. The level of constructors and kinds is a variation \nof Godel s T [18]. Every construc\u00adtor, V, has a unique normal form, AT(p), with respect to the obvious \nnotion of reduction derived from the equivalence rules of Figure 2 [47]. This reduction relation is confluent, \nfrom which it follows that constructor equivalence is decid\u00adable [47]. The type formation, type equivalence, \nand term forma\u00adtion rules for ~,yL are omitted due to lack of space, but can be found in a previous report \n[22]. The rules of type equiv\u00ad alence define the interpretation T(p) of the constructor p as a type. \nFor example, T(lnt) ~ int and T(+(pl, P2)) ~ T(pl) + T(p2). Thus, T takes us from a constructor which \nnames a type to the actual type. The term formation rules are standard with the exception of the typerec \nform, which A~~i::~ Abp+::O-+nBtc-+IC-+E AkJ{t::K }DpI::K APp2::i Ab,ux :: Q+ fl+K,4K!--+K AD (At::K \n./J1)J2]2] = [~2/t]~l :: K A D Typerec Int Of (~il~+l~x) ~ #i :: K ADpI::fl AF/L2::Q AD~i::~ A~p+. ::a+fl-+lc+ \nK+&#38; ADPX :: fl+fl+fi+K+ft A D Typerec (-+(~1, P2)) of (pi 1P-+ IPX) s P+ PI P2 (Tyww HI of (~il~+ \n/Px )) (Typerec ,u2 of (Pi 1P+ kJX )) :: K A D Typerec (X(PI, P2)) of (~il~+ IPX ) z PX PI P2 (Twerec \nPI of (Pi]P+ Ipx)) (TwerecP2 of (Pi[P+lPX )) :: K { Figure 2: Constructor Equivalence is governed by \nthe following rule: Ab,u::n A u {t::f)}bu A; r D ei : [lnt/t]u A;r D e-+ t2::~.[tl/t]u+ [+(tl,t2)/i]~ \n: vtl,+ [t2/t]fJ A;r Dex : vtl,[tl/t]a+ [x(tl, t2)/t]o t2::~.+ [t2/t]a A; 17D typerec p of ):[p/t]a \n [t.~](eile-+[ex The argument constructor p must be of kind fl, and the re\u00adsult type of the typerec \nexpression is determined as a func\u00adtion of the argument constructor, namely the substitution of p for \ntin the type expression a. The ~ [tpro\u00ad o] label vides the type information needed to check the construct \nwithout infererence. Typically the constructor variable t occurs in a as the argument of a Typerec expression \nso that [p/t]a is determined by a recursive analysis of p. Similar to normalization of a Typerec constructor, \nthe evaluation of a typerec expression selects ei, e X, or e+ according to the head constructor of the \nnormal form of p and passes it the components of p and the unrolling of the typerec on the components. \nType checking for Ai L reduces to equivalence checking for types and constructors. In view of the decidability \nof constructor equivalence, we have the following important result: Proposition 2.1 It is decidable whether \nor not A; 17D e : u is derivable in A~L. To fix the interpretation of typerec, we specify a call-by\u00advalue, \nnatural semantics for J$XL as a relation of the form e w v where w is a closed (with respect to both \ntype and value variables), syntactic value. Values are derived from the following grammar: v ::= fi I \nkc:a. e I (w, w2)m1 02I At::tt. e Type abstractions are values, reflecting the fact that evalu\u00ad ation \ndoes not proceed under A. Figure 3 defines the evaluation relation with a series of axioms and inference \nrules. The semantics uses an auxiliary judgment, p % p , (not formally defined here) that deter\u00admines \nthe normal forms of constructors. During evaluation, we only need to determine normal forms of closed \nconstruc\u00adtors of kind Q. This amounts to evaluating constructors of the form Typerec(...) and (pl [pz]) \nby orienting the equiva\u00adlences of Figure 2 to the right and adding the appropriate congruences. The rest \nof the semantics is standard except for the eval\u00ad uation of a typerec expression which proceeds as follows: \nFirst, the normal form of the constructor argument is deter\u00admined. Once the normal form is determined, \nthe appropriate subexpression is selected and applied to any argument con\u00adstructors. The resulting function \nis in turn applied to the {unrolling of the typerec at each of the argument construc\u00adtors. Some simple \nexamples using typerec may be found at the end of this subsection. The semantics uses meta-level substitution \nof closed val\u00adues for variables and closed constructors for type variables. In a lower-level semantics \nwhere substitution is made ex\u00adplicit, an environment would be needed not only for value variables, but \nalso for type variables. Tolmach [51] describes many of the issues involved in implementing such a language. \nProposition 2.2 (Type Preservation) If 0; 0 D e : u ande-v, then @;@Dv:u. By inspection of the value \ntyping rules, only appropriate values occupy appropriate types and thus evaluation will not go wrong \n. In particular, it is possible to show that when evaluating well-typed programs, we only use the proj \nevaluation rule when aj z al and U! = uz and we only use the app rule when a -a. Furthermore, programs \nwritten in pure J~L (i.e., without general recursion operators or recursive types) always terminate. \nProposition 2.3 (Termination) l~e is an expression such that @J;fJ D e : U, then there exists a value \nv such that e v v. A few simple examples will help to clarify the use of typerec. The function sizeof \nof type Vt: :fli nt that computes the size of values of a type can be defined as follows. sizeof = At:: \nf2.typerec tof [t .int](eile+ Iex ) where i i = e+ = Atl::fLAtz::fLJsl: int.Jxz:int.i ex = At1::f2.At2::f2 \n.kzl:int.Azz:int.xl + X2 (Here we assume that arrow types are boxed and thus have size one. ) It is easy \nto check that sizeof has the type Vt::Q. int. Note that in a parametric setting this type contains only \nconstant functions. As another example, Girard s formulation of System F [16] includes a distinguished \nconstant O. of type r for each type ~ (including variable types). We may define an analogue of these \nconstants using typerec as follows: zero = At:: fLtyperec tof [t ./ex) Z (t )](eile+.  el V VI ez _ \nv2 e+ (vI, v2)@~ u~ (vaZ) v + v (proj) (i= 1,2) =Ul P2 pair) (cl, e2)U 2 % (VI, v2) 1 02 z e+v~ [v /x]e \n+ v [p/t]e + (app) (tapp) Q ele2+v e[p] % P + +(P1, P2) typerec pl Of [t.a](eile+[e~) + VI typerec p2 \nOf [t.a](eile+ Iex ) + V2 Q[p2/ ]u(@[p1/~]a(e+ [fll][p2]) vI) u2 * u (tree-fn) typerec p Of [t.cT](eile+ \nIex ) f+ v Figure 3: Operational where =0 i e+ = Atl::f2.Atz::CUzl: T(tl).Azz:T(tz) .kc:Z (tl).zz ex \n= Atl::$Q.At2::QAz1 :Z (tl).k2:T(t2 ).(zl, ZZ) It is easy to check that zero has type Vt::f2.T (t), the \nempty type in System F and related systems. The presence of typerec violates parametricity to achieve \na more flexible pro\u00adgramming language. To simplify the presentation we usually define terms such as zero \nand sizeof using recursion equations, rather than as a typerec expression. The definitions of zero and \nsizeof are given in this form as follows: sizeof[lnt] = i sizeof[x (,ul, p2)] = ~izeof[pl] + sizeof[p2] \nsizeof [+-(P1, p2)] = 1 zero[lnt] = O zero[x (PI, p2)] = (zerohl], =ro[wl) zero[+(pl, p2)] = Az:T(P1 \n).zero[wd Whenever a definition is presented in thk form we tacitly assert that it can be formalized \nusing typerec.  2.3 Translating Mini-ML into ~,~~ A compiler from Mini-ML to A,ML is specified by a \nrelation A; 17D es : r + et that carries the meaning that A; r D e. : r is a derivable typing in Mini-ML \nand that the translation of the source term es determined by that typing derivation is the A,ML expression \net. Since the translation depends upon the typing derivation, it is possible to have many different translations \nof a given expression. However, all of the trans\u00ad lation schemes we consider axe coherent in the sense \nthat any two typing derivations produce observationally equiva\u00adlent translations [7, 26, 20].2 Here, \nwe give a straightforward compiler whose purpose is to make types explicit so that the primitive operations \nsuch as pairing and projection can potentially analyze their types at run-time. This simple translation \ndoes not utilize zWe omit explicit consideration of the coherence of our translations here. v p W Int \nei+V (tree-int) v typerec p Of [t.a](eile+lex) + v /.4+ x(pl, /.J2) typerec pl Of [t.~](ei Ie+lex ) + \nVI typerec p2 Of [t.u](eile+lex )+ VZ @[P2f ]U(QIP11 ]U (ex [pl][pz]) v,) v2 + v (tree-pair) typerec \np )+ IJ Of [t.a](eile+]r?x Semantics for A~L typerec or Typerec, but subsequent translations take advan\u00adtage \nof these constructs. We begin by defining a translation from Mini-ML types to AZ~L constructors, written \nII-I: ltl= t Iintl = Int ITI + T21 = -+(1711, IT21) IT, x 721 = X(17, [,[T21) The translation is extended \nto map Mini-ML type schemes to APL types as follows: Irl. = 2 (17]) pdt.+ = Vt::Q.lfJl. Finally, we \nwrite 1A I for the kind assignment mapping tto the kind fl for each tE A, and 11 I for the type assignment \nmapping z to [I (z) IS for each z c dom(17). Proposition 2.4 The type stitution: l[~?l./L](  ([n/tl]~) \n )[ The term translation is inference rules that parallel The var rule turns Mini-ML variables into \nA~L explicit this corresponds to passing translation commutes with sub\u00ad = [k nvbd(  ([hlhzlkl)  ) given \nin Figure 4 as a series of the typing rules for Mini-ML. implicit instantiation of type type application. \nOperationally, the types to the polymorphic value at run-time. The let rule makes the implicit type \nabstraction of the bound expression explicit. The trans\u00ad lation of A-abstraction, application, pairing, \nand projection is straightf orward except that these primitive operations are labelled with their types. \n The translation may be characterized by the following type preservation property. Theorem 2.5 IfA;rb \ne : T + e , then IA[; Irl De : Irl. Given a standard, call-by-value operational semantics for Mini-ML \nwith the value restriction, and given the stratifi\u00adcation between monotypes and polytypes in both Mini-ML \nand AML, it is possible to modify a standard binary log\u00adical r~lations-style argument for the simply-typed \nlambda calculus [48, 15, 40, 45, 46] to show the correctness of the A; f Del:~l*ej A; I De2:~2+e~ A; \nI De:~1x~2+e (pair) (7r) (i= 1,2) A;r D (el, e2) :71 X rZ + (e~, e\\)1711s r _21n A;r D 7r, e :7, + 7r~T11 \n1T21se (abs) A;17W{z:~l}De:m A;rDAx.e:71+72+Ax:lrl[8.e *e (app) A;r Del:r +r A;r S-e~ A;l_ DeZ:T +e~ \nDe1e2:7+Q1T tSeje~ AW{tl, ...,tn};r>v:~ +ej A;rw{x: vtl,..., tT.]De:r+e; e; (let) A;r~letz=vine:~+ \n~]vt,,...,tr.l l. (~~ : Vtl::q... , t~::Q.lr ].. ej)(Atl::Q,..., tw::fLe~) Figure 4: Translation from \nMini-ML to Jt~L translation, That is, we may show that at base type, if a Mini-ML program computes a \nvalue, then its J,ML transla\u00adtion computes the same value. In the presence of computational effects such \nas non\u00adtermination, if we did not restrict the bound expression in a let to be a value, then the translation \nwould be in\u00ad correct since evaluation in &#38; L does not proceed under A\u00adabstractions. In other words, \nthe expression might diverge (or print hello ) while its translation would not. 3 Applications of Type \nAnalysis In this section, we show how to implement a variety of useful and interesting constructs by \nextending the simple transla\u00adtion from Mini-ML to At L to take advantage of typerec and Typerec. We have \nalready shown how simple operations like ML. These Operations sizeof and zero can be defined in &#38; \ncan be exported directly to Mini-ML as constants of the appropriate type. In the following subsections, \nwe define new operations that may be exported to Mini-ML and mod\u00adify the standard translation to change \nthe representation of various types. 3.1 Flattening We consider the flat representation of Mini-ML tuples \nin which nested tuples are represented by a sequence of atomic values (for the present purposes, any \nnon-tuple is regarded as atomic ). To simplify the development we give a translation in which nested \nbinary tuples are repre\u00adsented in right-associated form, so that, for example, the Mini-ML type (int \nx int) x int will be compiled to the A~L type int x (int x int). The compilation makes use of inten\u00adtional \ntype analysis at both the term and constructor levels. We begin by modifying the type translation on \nMini-ML tuples: IT, X721 = Prod[l~ll][l~21] Here Prod is a constructor of kind Q -+ 0 + 0 defined below \nas: Prod[lnt][p] = x(lnt, p) Prod[+(p=, ~b)][p] = X(+(PCZ,W))P) prod[x (Pa, M)IIB1 = x(,u., Prod[~b][p]) \nInformally, the constructor Prod computes the right-associated form of a product of two types. For example, \n](int x int) x intl = Prod[Prod[lnt][ lnt]][lnt] and lint x (int x int)l = Prod[lnt][Prod[ lnt][lnt]] \nand the equation D Prod[Prod[int][ lnt]][lnt] -Prod[lnt][Prod[ lnt][ln~]] :: Q is derivable in J,ML. \nThe term translation is modified by changing the behav\u00adior of the pair and n rules: A; I Del:n%. e~ A; \nI De2:72*ej A; r D (cl, ez) : rl x I-Z a mkpair[[~ll][l~21] e; e; A; I De:rl Xr2+e (i= 1,2) A; I D m, \ne : r, + proj,[l~ll][l~~l] e The modified translation makes use of three auxiliary func\u00adtions, mkpair, \nproj ~ and proj2, with the following types: mkpair : Vtl, t2 :: Q. T(tl) + Z (tz) + Z (Prod[tl][t2]) \nprojl : Vtl,t2::fl.T(Prod[tl][t2]) + T(tl) proj2 : Vtl,tz::O!Z (Prod[tl][tz]) + T(t2) The m kpair operation \nis defined as follows, using the unof\u00adficial syntax of the language: mkpair[lnt][p] = knT(lnt). ~y:!f \n(p). (m, y) mkpair[+(p~, /Jb)][/J] = kC:~(+(#a,Pb)). Ay:T(,u). (z, y) mhnir[x(k, flb)][~] = k:~(X(Pa, \nPb)). Ayff(p). (m z, mkpair[pb][p](m~ z) y) The verification that m kpa i r has the required type proceeds \nby case analysis on the form of its first argument, relying on the defining equations for Prod. For example, \nwe must check that mkpai r[lnt][p] has type T(lnt) + 1 (p) + Z (Prod[lnt][p]) which follows from the \ndefinition of m kpair[l nt] [p] and the fact that Z (Prod[lnt]~]) z int x l (p). Similarly, we must \ncheck that rnkpair[x (pa, pb)][fl] has type T(x(,&#38;, /@)) + T(/J) + T(prOd[x(/&#38;z, ~b)][~] which \nfollows from its definition, the derivability of the equa\u00adtion Z (Prod[x (pa, ,Ub)][P]) E ~(h) x ~(prod[Pb]h]), \n and, inductively, the fact that m kpai r[Pb] [p] has type T(Pb) ~ T (p) ~ T(PrOd[pb][p]). The operations \nproj ~ and proj2 are defined as follows: projl[lnt][p] = k: Z (Prod[lnt][p]). m x ProJl [~(h, /Jb)][d \n= kZ (Prod[~(p~, pb)][p]). m x kT(Prod[x (%, Pb)][P]). ProJl[x (Pa, Pb)][,fJ] = (ml x, P@l[Pb][P](~2 \n~)) proj2[lnt][p] = Az:T(Prod[lnt]~]). 7FZz prOj2[~(Pa, ,Ub)][P] = k: T (Prod[~(pa, Pb)][P]). 7T2z M:T-(Prod[x \n(P=? pb)][p]). Projz[x (Pa, IJb)][d = .. .. ProJ2 kJb]hJ](~2 ~) The verification that these constructors \nhave the required type is similar to that of mkpair, keeping in mind the equa\u00adtions governing T( ) and \nProd[ ][ ]. One advantage of controlling data representation in this manner is that it becomes possible \nto support a type-safe form of casting that we call a view. Let us define two Mini-ML types rl and TZ \nto be similar, T1 E T2, iff they have the same represent ation i.e., iff 1~1I is definitionally equivalent \nto l~zl in&#38; L. Ifrl s rz, then every value of type 71 is also a value of type 7-z, and vice-versa. \nFor example, in the case of the right-associative representation of nested tuples above, we have that \nrl % rz iff TI and rz are equivalent modulo associativity of the product constructor, and a value of \na (nested) product type is a value of every other association of that type. In contrast to coercion implementations \nof type equiva\u00adlence, such an approach to views is compatible with mutable types (z. e., arrays and refs) \nin the sense that ~1 ref is equiv\u00adalent to r2 ref iff rl is equivalent to 7-2. This means that we may \nfreely intermingle updates with views of complex data structures, capturing some of the expressiveness \nof C casts without sacrificing type safety. The right-associated representation does not capture all \n aspects of flatness . In particular, access to components is not constant time, given a standard implementation \nof the pairing and projection operations. This may be overcome by extending A,ML with n-tuples (tuples \nof vwiable arity), and modifying the interpretation of the product type appro\u00ad priately. A rigorous formulation \nof the target language ex\u00ad tended with n-tuples is tedious, but appears to be straight\u00ad forward. 3.2 \nMarshaling Ohori and Kato give an extension of ML with primitives for distributed computing in a heterogeneous \nenvironment [39]. Their extension haa two essential features: one is a mech\u00adanism for generating globally \nunique names ( handles or capabilities ) that are used as proxies for functions pro\u00advided by servers. \nThe other is a method for representing arbitrary values in a form suitable for transmission through a \nnetwork. Integers are considered transmissible, as are pairs of transmissible values, but functions cannot \nbe transmitted (due to the heterogeneous environment) and are thus repre\u00adsented by proxy using unique \nidentifiers. These identifiers are associated with their functions by a name server that may be contacted \nthrough a primitive addressing scheme. In this section we sketch how a variant of Ohori and Kato s representation \nscheme can be implemented using intensional polymorphism. To accommodate Ohori and Kate s primitives \nthe A,~L language is extended with a primitive constructor Id of kind !i2 + fJ and a corresponding type \nconstructor id(o), linked by the equation Z (Id[p]) E id(T (p)). The Typerec and typerec primitives are \nextended in the obvious way to ac\u00adcount for constructors of the form Id [~]. For example, the following \nconstructor equivalence is added: ADp::f2 AD~i::fl AD,L+, px::f2+f2-+K-+ K.+ K AD~id::fl+K+K Typerec \nId[p] Of (PilP+ IPX lPid) ~ Pid If (Typerec P of (Pi kJ+ bJX IIJid)) The primitives newid and rpc are \nadded with the follow\u00ading types: newid : Vt~, t~::f2.(T(Tran[tl]) -+ Z (Tran[tz])) + T(Tran[~(tl, tz)]) \nrpc : Vtl, t2::fl(Z (Tran[~ (tl, tz)])) ~ T(Tran[tl]) ~ T (Tran[tz]) where Tra n is a constructor coded \nusing Typerec as follows: Tran[lnt] = Int Tran[a(pl, P2)] = ld[a(Tran[~l], Tradwd)l Tran[x(pl, p2)] = \nx(Tran[pll, Tran[,m]) Tran[ld[p]] = Id[p] The constructor Tran[,u] maps p to a constructor where each \naxrow is wrapped by an Id constructor. Thus, values of type T(Tran[p]) do not contain functions and are \ntherefore transmissible. It is easy to check that Tra n is a constructor ofkind Q+ Q From an abstract \nperspective, newid maps a function on transmissible representations to a transmissible representa\u00adtion \nof the function and rpc is its (left) inverse. Opera\u00adtionally, newid takes a function between transmissible \nval\u00adues, generates a new, globally unique identifier and tells the name server to associate that identifier \nwith the function on the local machine. For example, the unique identifier might consist of the machine \ns name paired with the address of the function. The rpc operation takes a proxy identifier of a remote \nfunction, and a transmissible argument value. The name server is contacted to discover the remote machine \nwhere the value actually lives. The argument value is sent to this machine, the function associated with \nthe identifier is applied to the argument, and the result of the function is transmitted back as the \nresult of the operation. The compilation of Ohori and Kato s distribution prim\u00ad itives into this extension \nof AVL relies critically on a mar\u00ad shaling operation M that converts a value to its transmissi\u00ad ble representation \nand an unmamhalling operation U that converts a value from its transmissible representation. The types \nof these operations can be easily expressed in terms of Tran: M : Vt::CLT(t) -+ T(Tran[t]) u : Vt::Q.Z \n(Tran[t]) ~ T(t)  The operations themselves can be defined as follows using the unofficial syntax of \ntyperec:3 M[lnt] = kz:int.x M[--@1,P2)] = lf:T(-01,P2)). newid[pl][p2] (ku: I (Tran[pl]). M[wd(f (UIPI] \nz))) M[x(w, P2)] = kZ (X(N1,P2)). (M[p,](m, z), M[p2](7r2 z)) M[ld[p,]] = k:T(id[~]). z U[lnt] = Az:int.z \nU[~(pI, p2)] = Afj~(l$~H;\\Tran[pl], Tran[p2])]). u[~a](rpc[pl][,u,] f (MIPII z)) U[x(~I, p2)] = Jz:Z \n(x(Tran[~l], Tran[p2])). (U[p,](m z), u[p2](7r2 z)) U[ld[p]] = kmT(ld[p]).z At arrow types, M converts \nthe function to one that takes and returns transmissible types and then allocates and amo\u00adciates a new \nidentifier with this function via newid. Corre\u00adspondingly, U takes an identifier and a marshaled argument, \nperforms an rpc on the identifier and argument, takes the result and unmarshalls it. The M and U functions \nare used in the translation of client phrases that import a server s function and in the translation \nof server phrases that export functions. The reader is encouraged to consult Ohori and Kate s paper [39] \nfor further details.  3.3 Type Classes The language Haskell [25] provides the ability to define a class \nof types with associated operations called methods. The canonical example is the class of types that \nadmit equal\u00adity (also known as equality types in SML [33, 19]). Consider adding a distinguished type \nvoid (with associ\u00adated constructor Void) to A,ML in such a way that void is empty . That is, no closed \nvalue has type void. We can encode a type class definition by using Typerec to map types in the class \nto themselves and types not in the class to void. In this fashion, Typerec may be used to compute a predi\u00adcate \n(or in general an n-ary relation) on types. Definitional equality can be used to determine membership \nin the class. For example, the class of types that admit equality can be defined using Typerec as follows: \nEq::fl-+fi Eq[int] = Int Eq[Bool] = Bool Eq[x(p,, K2)] = X(h[ml, Wd) Eq[~(pl, P2)] = Void Eq [Void] = \nVoid 3~o ~ompUte M and u Using the official syntax, we have tO use a single typerec that returns a pair \nholding the two functions for that type. Here, Eq serves as a predicate on types in the sense that a \nnon-Void constructor p is definitionally equal to Eq [p] only if ~ is a constructor that does not contain \nthe constructor +( , ). The equality method can be coded using typerec as fol\u00adlows, where we assume primitive \nequality functions for i nt and bool and omit some type labels for simplicity: eq[lnt] = eqint eq[Bool] \n= eqbool Jz.Ay.eq[Eq[pl] ](ml Z)(TI y) and eq[Eq[p2]](m2 z)(7r2 y) eq[-+(pl, P2)I = kc:void.~y:void. \nfalse eq[Void] = kz:void.~y:void .false w[x(w,~2)l = It is straightforward to verify that: eq : Vt::Q.Z \n(Eq[t]) ~ T(Eq[t]) ~ bool Consequently, eq [p] el ea can be well typed only if el and ez have types \nthat are definitionally equal to T(Eq[p]). The en\u00adcodingis not entirely satisfactory because eq [+(P1, \nK2 )] can be a well-typed expression. However, the function resulting from evaluation of this expression \ncan only be applied to values of type void. Since no such values exist, the function can never be applied. \n 3.4 Dynamics In the presence of intentional polymorphism a predicative form of the type dynamic [2] \nmay be defined to be the exis\u00adtential type The rules existential 3t::fLT(t).typing for types are as follows: \nD ADp::~ ~&#38; {t::K}a A; r b e: [p/t]u A;r b packewith pas%::fi.a : ~t::ti.a ADU A; 17Del : %::d AkI \n{t::~}; r M{m } De, : C7 A; r D abstypeel ist::~, z:o in e2 end :0 The pack operation introduces existential \nby packaging a type with a value. The a bstype operation eliminates exis\u00adtential by allowing the type \nand value to be unpacked and used within a certain scope. Under this interpretation, the introductory \nform dynamic[~] (e) stands for pack e with r The eliminatory form, as 3t::fl.Z (t).typecase d of (eile+ \nle~ ), where d : dynamic, ei : 0, and e+, eX : Vtl, ta::f).a,as follows: is defined abstype dkt::fl, \nz:T(t) in typerec tof [t.u](eile +]e~ )end Here e + = Atl::Q.At2::Uk1 :a.Ar2:u.e+ [t1][t2], and simi\u00adlarly \nfor e~. This form of dynamic type only allows values of monomor\u00adphic types to be made dynamic, consistent \nwith the sepa\u00ad ration between constructors and types in J, L. The possi-ML to admit impredicative quantifiers \nbilities for enriching J, (and hence account for the full power of dynamic typing including non-termination) \nare discussed in the conclusion. Related Work There are two traditional interpretations of polymorphism, \nthe ezplicit style (due to Girard [16, 17] and Reynolds [42]), in which types are passed to polymorphic \noperations, and the implicit style (due to Milner [32]), in which types are erased prior to execution. \nIn their study of the type the\u00adory of Standard ML Harper and Mitchell [20] argued that an explicitly-typed \ninterpretation of ML polymorphism has better semantic properties and scales more easily to cover the \nfull language. Harper and Mitchell formulated a pred\u00adicative type theory, XML, a theory of dependent \ntypes aug\u00admented with a universe of small types, adequate for captur\u00ading many aspects of Standard ML. \nThis type theory was re\u00adfined by Harper, Mitchell, and Moggi [21], and provides the basis for this work. \nThe idea of intensional type analysis ex\u00adploited here was inspired by the work of Constable [12, 13], \nfrom which the term intentional analysis is taken. The rules for typerec, and the need for Typerec, are \nderived from the universe elimination rules in NuPRL (described only in unpublished work of Constable). \nThe idea of passing types to polymorphic functions is exploited by Morrison et al. [37] in the implementation \nof Napier 88. Types are used at run-time to specialize data representations in roughly the manner described \nhere. The authors do not, however, provide a rigorous account of the type theory underlying their implementation \ntechnique. The work of Ohori on compiling record operations [38] is sim\u00adilarly based on a type-passing \ninterpretation of polymor\u00adphism, and was an inspiration for the present work. Ohori s solution is ad \nhoc in the sense that no general type-theoretic framework is proposed, but many of the key ideas in his \nwork are present here. Jones [28] has proposed a general framework for passing data derived from types \nto quali\u00adfied polymorphic operations, called evidence passing. His approach differs from ours in that \nwhereas we pass types to polymorphic operations, that are then free to analyze them, Jones passes code \ncorresponding to a proof that a type sat\u00adisfies the constraints of the qualification. From a practical \npoint of view it appears that both mechanisms can be used to solve similar problems, but the exact relationship \nbetween the two approaches is not clear. Recently Duggan and Ophel [14] and Thatte [50] have independently \nsuggested semantics for type classes that are similar in spirit to our proposal. In particular both ap\u00adproaches \nrepresent the restriction of a class as a user-defined, possibly recursive, kind definition in a predicative \nlanguage. Both sets of authors are concerned with providing a source\u00adlevel overloading facility and consequently \nexamine hard is\u00adsues such as type inference and open-scoped definitions that do not directly concern \nus, since we are primarily concerned with a target-level type-anaJysis facility. The implementa\u00adtion \ntechnique proposed by Duggan and Ophel is similar to ours in that polymorphic routines are passed type \nnames at run-time and a typecase construct is used to determine the behavior of an overloaded operation. \nAs with type classes and Jones s qualified types, it appears that we can code many of their kind definitions \nusing Typerec with the ap\u00adproach sketched in Section 3.3. However, Typerec can also be used to transform \ntypes a facility crucial for represen\u00adtation transformations such as flattening and marshaling. That \nis, neither Duggan and Ophel nor Thatte provide a fa\u00adcility for coding constructors such as Prod or Tran \nthat map types to types. A number of authors have considered problems pertain\u00ading to representation analysis \nin the presence of polymor\u00adphism. The boxing interpretation of polymorphism has been studied by Peyton \nJones and Launchbury [29], by Leroy [30], by Poulsen [41], by Henglein and Jorgensen [24], and by Shao \n[43] with the goal of minimizing the overhead of box\u00ading and unboxing at run-time. All but the first \nof these approaches involve copying coercions. Of a broadly similar nature is the work on soft type systems \n[3, 10, 23, 49, 53] that seek to improve data representations through global analysis techniques. All \nof these methods are based on the use of program analysis techniques to reduce the overhead of box and \ntag manipulation incurred by the standard compi\u00adlation method for polymorphic languages. Many (includhg \nthe soft type systems, but not Leroy s system) rely on global analysis for their effectiveness. In contrast \nwe propose a new approach to compiling polymorphism that affords control over data representation without \ncompromising modularity. Finally, a type-passing interpretation of polymorphkm is exploited by Tolmach \n[51] in his implementation of a tag\u00adfree garbage collection algorithm. Tolmach s results demon\u00adstrate \nthat it is feasible to build a run-time system for ML in which no type information is associated with \ndata in the heap4. Morrisett, Harper, and Felleisen [36] give a semantic framework for discussing garbage \ncollection, and provide a proof of correctness of Tolmach s algorithm. 5 Summary and Future Directions \nWe have presented a type-theoretic framework for express\u00ading computations that analyze types at run-time. \nThe key feature of our framework is the use of structural induction on types at both the term and type \nlevel. This allows us to ex\u00adpress the typing properties of non-trivial computations that perform intensional \ntype analysis. When viewed as an inter\u00admediate language for compiling ML programs, much of the type analysis \nin the translations can be eliminated prior to run-time. In particular, the prenex quantification restriction \nof ML ensures good binding-time separation between type mguments and value arguments and the value restriction \non polymorphic functions, together with the well-founded\u00adness of type induction, ensures that a polymorphic \ninstan\u00adtiation always terminates. This provides important oppor\u00adtunities for optimization. For example, \nif a type variable t occurring as the parameter of a functor is the subject of intensional type analysis, \nthen the typerec can be simplified when the functor is applied and tbecomes known. Similarly, link-time \nspecialization is possible whenever t is defined in a separately-compiled module. Inductive analysis \nof type variables arising from let-style polymorphism is ordhm.rily handled at run-time, but it is possible \nto expand each in\u00adstance and perform type analysis in each case separately. The type theory considered \nhere extends readily to in\u00adductively defined types such as lists and trees. However, extending typerec \nand Typerec to handle generally recursive types is problematic because of the negative occurrence of \nfl in a recursive constructor. In particular, termination can no longer be guaranteed, which presents \nproblems not only for optimization but also for type checking. The restriction to predicative polymorphism \nis sufficient for compiling ML programs. More recent languages such as Quest [9] extend the expressive \npower to admit impred\u00adicative polymorphism, in which quantified types may be 4However, types are passed \nindependently as data and associated with code. instantiated by quantified types. (Both Girard s [16] \nand Reynolds s [42] calculi exhibit this kind of polymorphism.) It is natural to consider whether the \nmethods proposed here may be extended to the impredicative case. Since the uni\u00adversal quantifier may \nbe viewed as a constant of kind (Q + !2) -+ f2, similar problems arise as for recursive types. In particular, \nwe may extend type analysis to the quantified case. but onlv at the exDense of termination. due to the \nnegative occu~rence of !2 in the kind of the quantifier. Ad hoc solutions are possible, but in general \nit appears neces\u00adsary to sacrifice termination guarantees. Compiling polymorphism using intensional type \nanaly\u00adsis enables data representations that are impossible using type-free techniques. Setting aside \nthe additional expres\u00adsiveness of the present approach, it is interesting to consider the performance \nof a type-passing implementation of ML as compared to the type-free approach adopted in SML/NJ [5]. As \npointed out by Tolmach [51], a type-passing implemen\u00adtation need not maintain tag bits on values for \nthe sake of garbage collection. The only remaining use of tag bits in SML/NJ is for polymorphic equality, \nwhich can readily be implemented using intensional type analysis. Thus tag bits can be eliminated, leading \nto a considerable space savings. On the other hand, it costs time and space to pass type argu\u00adments at \nrun-time, and it is not cle~ whether type analysis is cheaper in practice than carrying tag bits. An \nempirical study of the relative performance of the two approaches is currently planned by the second \nauthor, and will be reported elsewhere. The combination of intensional polymorphism and exis\u00adtential \ntypes [35] raises some interesting questions. On the one hand, the type dynamic [2] may be defined in \nterms of existential. On the other hand, data abstraction may be violated since a client of an abstraction \nmay perform in\u00adtentional analysis on the abstract type, which is replaced at run-time by the implementation \ntype of the abstraction. This suggests that it may be advantageous to distinguish two kinds of types, \nthose that are analyzable and those that are not. In this way paramet ricit y and represent at ion in\u00addependence \ncan be enforced by restricting the use of type analysis. The idea of intensional analysis of types bears \nsome re\u00adsemblance to the notion of reflection [44, 4] we may think of type-passing as a reification \nof the meta-level notion of types. It is interesting to speculate that the type theory proposed here \nis but a speciaf case of a fully reflective type theory. The reflective viewpoint may provide a solution \nto the problem of intensional analysis tified types since, presumably, types syntactic form that is more \namenable first-order, rather than higher-order, Acknowledgments of recursive and quan\u00adwould be reified \nin a to analysis using abstract syntax. We are grateful to Martin Abadi, Andrew Appel, Lars Birkeda \nJ> Luca Cardelli, Matthias Felleisen, Andrzej Filinski, Mark Jones, Simon Peyton Jones, Mark Leone, Phil \nWadler, Jean\u00adnette Wing and the reviewers for their comments and sug\u00adgestions. References [I] M. Abadi, \nL. Cardelli, B. Pierce, and G. Plotkin. Dynamic typing in a statically-typed language. In Proceedings \nof the Sixteenth Annual ACM grammmg Languages, [2] M. Abadi, L. Cardelli, typing in a statically-typed \nProgramming Languages 1991. Revised version [3] A. Aiken, E. Wimmers, with conditional types. Symposium \non Principles of Pro-Austin. ACM, January 1989. B. Pierce, and G. Plotkin. Dynamic language. A CM Transactions \non and Systems, 13(2):237 268, Apr. of [I]. and T. K. Lakshman. Soft typing In Twenty-First ACM Symposium \non Principles of Programming Languages, pages 163 1 73, Portland, OR, Jan. 1994. [4] S. F. Allen, R. \nL. Constable, The semantics of reflected Logic in Computer Science, June 1990. IEEE. [5] A. W. Appel. \nCompiling University Press, 1992. [6] G. Blelloch, S. Chatterjee, M. Zagha. Implementation language. \nIn Proceedings D. J. Howe, and W. E. Aitken. proof. In Fifth Symposium on pages 95-106, Philadelphia, \nPA, with Continuations. Cambridge J. C. Hardwick, J. Sipelstein, and of a portable nested data-parallel \nof the Fourth ACM SIGPLAN Symposium on Principles and Practice of Parallel Program\u00adming, pages 102 111, \nMay 1993. [7] V. Breazu-Tannen, T. Coquand, C. A. Gunter, and A. Sce\u00addrov. Inheritance as implicit coercion. \nInformation and Computation, 93:172-221, 1991. [8] L. Cardelli. Phase distinctions in type theory. Unpublished \nmanuscript. [9] L. Cardelli. Typeful programming. Technical Report 45, DEC Systeme Research Center, \n1989, [10] R. Cartwright and M. Fagan. Soft typing. In Proc. SIG-PLAN 91 Conference on Programming Language \nDesign and Implementation, pages 278 292. ACM, June 1991. [11] D. C16ment, J. Deepeyroux, T. Despeyroux, \nand G. Kahn. A simple applicative language: Mini-ML. In f 986 ACM Conf. on LISP and Functional Prog., \n1986. [12] R. L. Constable. Intensional analysis of functions and types. Technical Report CSR 1 18 82, \nComputer Science Depart\u00adment, University of Edinburgh, June 1982. [13] R. L. Constable and D. R. Zlatin. \nThe type theory of PL/CV3, ACM Transactions on Programming Languages and Systems, 7(1):72 93, Jan, 1984, \n[14] D. Duggan and J. Ophel. Kinded parametric overloading. Technical Report CS-94-35, University of \nWaterloo, Depart\u00adment of Computer Science, September 1994. Supersedes CS-94-15 and CS-94-16, March 1994, \nand CS-93-32, August 1993. [15] H. IMedman. Equality between functional. In R, Parikh, editor, Logic \nColloquium 75, Studiee in Logic and the Foun\u00addation of Mathematics, pages 22-37. North-Holland, 1975. \n[16] J.-Y. Girard. Une extension de l interpretation de Godel a l analyse, et son application a l 61imination \ndes coupures dane l analyse et la theorie des types. In J. E. Fenstad, editor, Proceedings of the Second \nScandinavian Logic Symposium, Studies in Logic and the Foundations of Mathematics, pages 63 92. North-Holland, \n1971. [17] J.-Y. Girard. Interpretation Fonctionnelle et Elimination des Coupures clans 1 Arithm6tique \nd Ordre Supc%eure. PhD thesis, Universit6 Paris VII, 1972. [18] K. Godel. Uber eine bieher noch nicht \nbenutzte Erweiterung des finiten Standpunktes. Dialectic, 12:280 287, 1958. [19] C. A. Gunter, E. L. \nGunter, and D. B. MacQueen. Comput\u00ading ML equality kinde using abstract interpretation, Infor\u00admation \nand Computation, 107(2):303 323, Dec. 1993. [20] R. Harper and J. C. Mitchell. On the type structure \nof Stan\u00addard ML. ACM Transactions on Programming Languages and Systems, 15(2):211 252, April 1993. (See \nalso [34].). 140 [21] R. Harper, J. C. Mitchell, and E. Moggi. Higher-order mod\u00adules and the phase distinction. \nIn Seventeenth ACM S~rn\u00adposium on Principles of Programming Languages, San Fran\u00adcisco, CA, January 1990. \n[22] R. Harper and G. Morrisett. Compiling polymorphism using intensional type analysis. Technical Report \nCMU-CS-94\u00ad185, School of Computer Science, Carnegie Mellon Univer\u00adsity, Pittsburgh, PA, September 1994. \n(Also published m Fox Memorandum CMU-CS-FOX-94-07). [23] N. Heintze. Set-based analysis of ML programs. \nIn Proc. 1994 ACM Conf. on LISP and Factional Programming, pages 306-317, Orlando, FL, June 1994. ACM. \n[24] F. Henglein and J. J@rgensen. Formally optimal boxing. In Twenty-First ACM Symposium on Principles \nof Program\u00adming Languages, pages 213 226, Portland, OR, Jan. 1994. ACM. [25] P. Hudak, S. L. P. Jones, \nand P. Wadler. Report on the pro\u00adgramming language Haekell, version 1.2. SZGPLAN Notices, 27(5), May \n1992. [26] M. Jones. Coherence for qualified types. Research Report YALEU/DCS/RR-989, Yale University, \nNew Haven, Con\u00adnecticut, USA, September 1993. [27] M. Jones. Partial evaluation for dictionary-free overloading. \nIn ACM Conference on Partial Evaluation and Semantics-Based Program Manipulation, 1994. [28] M. P. Jones. \nQualified Types: Theory and Practice. PhD the\u00adsis, Programming Research Group, Oxford University Com\u00adputing \nLaboratory, July 1992. Currently available as Tech\u00adnical Monograph PRG-106, Oxford University Computing \nLaboratory, Programming Research Group, 11 Keble Road, Oxford OX1 3QD, U.K. email: library@ comlab.ox.ac.uk. \n[29] S. P. Jones and J. Launchbury. Unboxed values as first\u00ad.1sss citizens. In Proc. Conf. on Factional \nProgmmming and Computer Architecture, volume 523 of Lecture Notes in Computer Science, pages 636 666. \nACM, Springer-Verlag, 1991. [30] X. Leroy. Unboxed objects and polymorphic typing. In Con\u00adference Record \nof the Nineteenth Annual ACM SIGPLAN-SIGA CT Symposium on Principles of Programming Lan\u00adguages, Albuquerque, \npages 177 188. ACM Press, January 1992. [31] P. Martin-Lof. About models for intuitionistic type theo\u00adries \nand the notion of definitional equality. In S. Kanger, editor, Proceedings of the Third Scandinavian \nLogic Sympo\u00adsium, Studies in Logic and the Foundations of Mathematics, pages 81-109. North-Holland, 1975. \n[32] R. Milner. A theory of type polymorphism in program\u00adming languages. Journal of Computer and System \nSciences, 17:348-375, 1978. [33] R. Milner, M. Tofte, and R. Harper. The Definition of Stan\u00addard ML. \nMIT Press, 1990. [34] J. Mitchell and R. Harper. The essence of ML. In Fifteenth ACM Symposium on Principles \nof Programming Languages, San Diego, California, Jan. 1988. [35] J. C. Mitchell and G. Plotkin. Abstract \ntypes have existential type. ACM Transactions on Programming Languages and Systems, 10(3):470-502, 1988. \n[36] G. Morrisett, M. Felleisen, and R. Harper. Abstract models of memory management. In preparation, \nOtt. 1994. [37] R. Morrison, A. Dearle, R. C. H. Connor, and A. L. Brown. An ad hoc approach to the implementation \nof polymorphism. ACM Transactions on Programming Languages and Systems, 13(3):342-371, July 1991. [38] \nA. Ohori. A compilation method for ML-style polymorphic record calculi. In Nineteenth ACM Symposium on \nPrinciples of Progmmming Languages, pages 154 165, Albuquerque, NM, Jan. 1992. Association for Computing \nMachinery. [39] A. Ohori and K. Kate. Semantics for communication prim\u00aditives in a polymorphic language. \nIn Twentieth ACM Sym\u00adposium on Principles of Progmmming Languages, pages 99 112, Charleston, SC, Jan. \n1993. Association for Computing Machinery. [40] G. Plotkin. Lambda-definability in the full type hierarchy. \nIn J. P. Seldin and J. R. Hindley, editors, To H. B. Curry: Essays in Combinatory Logic, Lambda Calculus \nand For\u00admalism, pages 363 373. Academic Press, 1980. [41] E. R. Poulsen. Representation analysis for \nefficient imple\u00admentation of polymorphism. Technical report, Department of Computer Science (DIKU), University \nof Copenhagen, Apr. 1993. Msster Dissertation. [42] J. C. Reynolds. Towards a theory of type structure. \nIn Colloq. sur la Programmation, volume 19 of Lecture Notes in Computer Science, pages 408 423. Springer-Verlag, \n1974. [43] Z. Shao. Compiling Standard ML for Ef7icient Execution on Modern Machines. PhD thesis, Princeton \nUniversity, Prince\u00adton, NJ, November 1994. [44] B. C. Smith. Reflection and semantics in LISP. In Eleventh \nACM Symposium on Principles of Programming Languages, pages 23 35, 1984. [45] R. Statman. Completeness, \ninvariance, and lambda\u00addefinability. Journal of Symbolic Logic, 47:17-26, 1982. [46] R. Statman. Logical \nrelations and the typed J-calculus. In\u00adformation and Control, 65:85-97, 1985. [47] S. Stenlund. Combinators, \nA-terms and Proof Theory. D. Reidel, 1972. [48] W. W. Tait. Intentional interpretation of functional \nof finite type. Journal of Symbolic Logic, 32(2):187 199, June 1967. [49] S. R. Thatte. Quasi-static \ntyping. In Seventeenth ACM Symposium on Principles of Programming Languages, pages 367 381, San Francisco, \nCA, Jan. 1990. [50] S. R. Thatte. Semantics of type classes revisited. In Proc. 1994 ACM Conference on \nLISP and Functional Program\u00adming, pages 208 219, Orlando, June 1994. ACM. [51] A. Tolmach. Tag-free garbage \ncollection using explicit type parameters. In Proc. 1994 ACM Conference on LISP and Functional Programming, \npages 1 11, Orlando, FL, June 1994. ACM. [52] A. K. Wright. Polymorphism for imperative languagee with\u00adout \nimperative types. Technical Report TR93 200, Depart\u00adment of Computer Science, Rice University, Houston, \nTX, Feb. 1993. To appear, Lisp and Symbolic Computation. [53] A. K. Wright and R. Cartwright. A practical \nsoft type system for Scheme. In Proc 1994 ACM Conference on LISP and Functional Progmmming, pagee 250 \n262, Orlando, FL, June 1994. ACM. 141   \n\t\t\t", "proc_id": "199448", "abstract": "<p>Traditional techniques for implementing polymorphism use a universal representation for objects of unknown type. Often, this forces a compiler to use universal representations even if the types of objects are known. We examine an alternative approach for compiling polymorphism where types are passed as arguments to polymorphic routines in order to determine the representation of an object. This approach allows monomorphic code to use natural, efficient representations, supports separate compilation of polymorphic definitions and, unlike coercion-based implementations of polymorphism, natural representations can be used for mutable objects such as refs and arrays.</p><p>We are particularly interested in the typing properties of an intermediate language that allows run-time type  analysis to be coded within the language. This allows us to compile many representation transformations and many language features without adding new primitive operations to the language. In this paper, we provide a core target language where type-analysis operators can be coded within the language and the types of such operators can be accurately tracked. The target language is powerful enough to code a variety of useful features, yet type checking remains decidable. We show how to translate an ML-like language into the target language so that primitive operators can analyze types to produce efficient representations. We demonstrate the power of the &#8220;user-level&#8221; operators by coding flattened tuples, marshalling, type classes, and a form of type <bold>dynamic</bold> within the  language.</p>", "authors": [{"name": "Robert Harper", "author_profile_id": "81100140064", "affiliation": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP39029370", "email_address": "", "orcid_id": ""}, {"name": "Greg Morrisett", "author_profile_id": "81339518683", "affiliation": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP43136279", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/199448.199475", "year": "1995", "article_id": "199475", "conference": "POPL", "title": "Compiling polymorphism using intensional type analysis", "url": "http://dl.acm.org/citation.cfm?id=199475"}