{"article_publication_date": "01-25-1995", "fulltext": "\n Using Functor Categories to Generate Intermediate Code * John C. Reynolds Department of Computing School \nof Computer Science Imperial College Carnegie Mellon University London SW7 2BZ, Great Britain Pittsburgh, \nPA 15213-3890, USA jr@ldoc.ic.ac.uk john.reynolds@lcs. cmu.edu Abstract 2 Types and Syntax In the early \n80 s Oles and Reynolds devised a semantic An Algol-like language is a typed lambda calculus with an model \nof Algol-like languages using a category of functors unusual repertoire of primitive types. Throughout \nmost of from a category of store shapes to the category of predo-this paper we assume that the primitive \ntypes are mains. Here we will show how a variant of this idea can be used to define the translation of \nan Algol-like language comm(and) int (eger)exp(ression) to intermediate code in a uniform way that avoids \nunneces\u00ad int(eger)acc(eptor) int(eger)var(iable) ,sary temporary variables, provides control-flow translation \nof boolean expressions, permits online expansion of proce\u00ad and that the set @ of types is the least set \ncontaining these dures, and minimizes the storage overhead of calls of closed primitive types and closed \nunder the binary operation +. procedures. The basic idea is to replace continuations by in- We write \n< for the least preorder such that struction sequences and store shapes by descriptions of the structure \nof the run-time stack. intvar < intexp intvar < intacc 1 Introduction When O <19 , 0 is said to be a \nsubtype of 8 . To construct a compiler for a modern higher-level program- A type assignment is a mapping \nfrom some finite set ming language, one needs to structure the translation to a of identifiers into types; \nwe write ~ for the set of type machine-like intermediate language in a way that reflects assignments. \nThen we write the typing T 1-p : (3 to indicate the semantics of the language. Little is said about such \nthat the phrase p has type O under the type assignment m. structuring in compiler texts that are intended \nto cover a We omit both the definition of the syntax of phrases and wide variety of programming languages. \nMore is said in the the inference rules for typings, beyond noting that phrases literature on semantics-directed \ncompiler construction [1], include identifiers and the lambda-calculus operations of ap\u00adbut here too \nthe viewpoint is very general (though limited plication and abstraction, and the inference rules include \nthe to languages with a finite number of syntactic types). On standard rules for the typed lambda calculus \nwith subtypes. the other hand, there is a considerable body of work using the continuation-passing transformation \nto structure com\u00ad3 Functor-Category Semantics pilers for the specific case of call-by-value languages \nsuch as Scheme and ML [2, 3]. The basic assumption that an Algol-like language is a speciesIn this paper, \nwe will describe a method of structuring of typed lambda calculus is captured by using a cartesian the \ntranslation of Algol-like languages that is based on the closed category to provide its semantics. More \nspecifically,functor-category semantics developed by Reynolds [4] and we assume that there is a functor \n[ ], from El (preordered byOles [5, 6]. the subtype relation and viewed as a category) to a carte-An \nalternative approach using category theory to struc\u00ad sian closed semantic category K, that interprets \nthe type ture compilers is the early work of F. L. Morris [7], which constructor + as the exponentiation \noperation of K: anticipates our treatment of boolean expressions, but does not deal with procedures. \n*This research was sponsored in part by National Science Founda\u00adtion Grant CC R-S922109 and in part by \na fellowship from the Science (If the type system includes type constructors for tuples or and Engineering \nResearch Council. records, these will be interpreted by products in K. Intersec\u00adtion types would be interpreted \nby pullbacks, as discussed Permission to copy without fee all or part of this material is in [8, 9, 10]. \n) granted provided that the copies are not made or distrfbutad for direct commercial advantage, the \nACM copyright notice and the The functor [ ] interprets types as objects of the se\u00adtitle of the publication \nand Its date appear, and notice is given mantic category K. In addition, whenever O is a subtype that \ncopyi is by permission of the Association of Computing of 19 (i.e. O < 0 ), it maps the unique morphism \nfrom d to Machinery.Y o copy otherwise, or to republish, requires a fee # into an implicit conversion \nmorphism , which we denote ancUorspadic permission. by [0 < 0 ], from the meaning of O to the meaning \nof 19 . POPL 951/95 San Francisco CA USA 43 1995 ACM 0-89791-692-1/95/0001 ,...$3.50 The meaning of type \nassignments is specified by a func\u00adtor [ ]*, from @* (preordered pointwise and viewed as a category) \nto K, that maps each type assignment into an appropriate product in the semantic category: [7r]* = ~K \n[T,]. ,Cd.mz When r k p : 0, the semantics of the phrase p, with respect to n and 0, is a morphism \nfrom the meaning of T to the meaning of O that we denote by k]=, [fin a [@n (This redundant use of \nemphatic brackets is saved from am\u00adbiguity by the subscripts, which qualify the semantics of a phrase \nbut not the functorial use of the brackets.) Throughout this paper, we will write A&#38;B to denote \nthe set of morphisms from A to B in the category C, and A~Btodenote theexponentiation of Bby Ain C. When \nthe subscript is omitted, the relevant category is either that of domains and continuous functions or \nof predomains and continuous functions. (Of course, + is also used as the type constructor for procedural \ntypes. ) The semantics ~]=e is specified by giving a semantic equation for each syntactic construct of \nthe language, plus an equation describing the effect of implicit conversions: when 9< #, blx, = b]=,; \nu~ s 0 (1) where the semicolon denotes the composition of morphisms in K (in diagrammatic order). The \nabove equation is not syntax-directed, i.e. it does not define the semantics of p in terms of the semantics \nof its subphrases, but rather defines one semantics of p in terms of another. As discussed in [10], this \nmeans that ~]=~ must be defined by structural induction on the proof of the typing -n R p : 0 rather \nthan on the syntactic structure of p. This has the advantage that semantics (and similarly translation) \nis only defined for type-correct programs, but it introduces the requirement of coherence, i.e. that \ndifferent proofs of the same typing must not lead to different meanings. For\u00adtunately, the proof of coherence \ngiven in [10], for a language using intersection types, carries over to the much simpler language discussed \nin this paper. If we were defining a purely functional, call-by-name lan\u00adguage, we could take the semantic \ncategory K to be the cat\u00adegory of domains (c. p.o. s with least elements) and continu\u00adous functions. \nIt is less obvious, however, how to provide a clear semantics of languages that include assignment. In \nthe early 80 s, Frank Oles and I devised such a semantics that makes the block structures of Algol-like \nlanguages explicit. Our basic idea was that the meaning of a type should be a family of domains parameterized \nby state sets (which Oles called store shape~ ): [cOmm]S = S ~ S. [intexp]S = S + 2L [intacc]S = 2 -+ \n(S + S1) [intvar]S = [intacc]S x [intexp]S Similarly, the semantics of a phrase was a family of contin\u00aduous \nfunctions parameterized by state sets: bn.es ~ [d s -+ [0]s Conslder, for example, the Algol-like program \nnew x:intvar in (x :=x+ 1 ; newy:intvar in(y:=x+y; x:=x+l; ... )). In the outer block, where only a \nsingle variable is declared, the appropriate set of states is the set of integers, while in the inner \nblock, where a second variable is declared, the appropriate set of states is the set of pairs of integers, \nThus the semantics of the two occurrences of x:=x+1 are provided by different members of the family [x \n= x + 1] The T,comm. member of this family appropriate to the occurrence in the outer block is [X:=x+l] \nE [7r]*z + (,Z + 21) , T ,Comnl z which maps an environment appropriate to states that are integers \ninto a state-transition function on integers, If ~ is an environment specifying that x denotes the integer \nthat is the entire state, then [x := x + 1] Zq will be the T,comm function that increases an integer \nby one. On the other hand, the member of [x :== x + 1] that lr, comm is appropriate to the occurrence \nin the inner block is [X,=X+1] 7r,cornm (2X.2)= [7r]*(z xz) + ((z xz) + (z x2)1) , which maps an environment \nappropriate to states that are pairs of integers into a state-transition function on such pairs. If q \nis an environment specifying that x denotes the first component of the state, then [x :=x+1] (z x Z)q \n?r, conlm will be the function mapping a pair (z, y) into (z + 1, y). In both cases, command execution \nis described by a state transition that preserves the shape of the state. Indeed, this is generally true \nsince, for any command c, [c] s E ~7r]*s + (s+ Sl) r,comm implies that [c] Sq preserves the shape S. \n7r, c0mm From the viewpoint of category-theoretic semant its, pa\u00adrameterization by state sets is realized \nby taking the seman\u00adtic category to be the functor category K = PDOMX , where X is a category whose \nobjects are state sets and PDOM is the category of predomains and continuous func\u00adtions. Of course, this \nimplies that the meanings of types are functors that act on morphisms of Z as well as objects, and that \nthe semantics of phrases are natural transforma\u00adtions between such functors. In this brief synopsis, \nhowever, we will only remark that a morphism in S ~ S , called an <expansion in [4, 5, 6], shows how \na small state in S can be extracted from a large state in S and how a small\u00adstate transition in S s S \nl can be extended to a large-state transition in S + S;. It is shown in [5, 6] that the functor category \nPDOMX is cartesian closed (actually for any Z). In particular, expo\u00adnentiations are functors whose action \non objects of X is (F~G)S=homxSx F~G. (Here pointwise ordering is used to regard the set on the right \nas a predomain, homz is the curried hom-functor for the category E, and homx SS = S ~ S is regarded as \na discretely ordered predomain. ) To see how this exponentiation captures the interaction of procedures \nand block structure, suppose is the meaning of a procedure of type 6 1 + 02. Then p is a natural transformation \nsuch that ps 6(s -# s ) x [01]s +-[02]s Here S is the state set that is appropriate to the point in \nthe program where the procedure is defined (and that contains states specifying the values of any variables \noccur\u00adring globally in the procedure). For example, if p were the meaning of the procedure in new x:intvar \nin let silly = Ac: comm. (c ; x:=x+ 1 ; c) in new y: intvar in silly(x :=x + y) then S would be a set \nof integers specifying the global vari\u00adable x. However, as illustrated by the procedure call in the above \nprogram, the procedure with meaning p can be called from an inner block where a set S of larger states \nis appropriate, and these larger states, rather than the members of S, may be needed to specify variables \nin the actual parameter of the call. Thus the state set S must be given to p as a hidden argument, and \nboth the explicit argument of p (the meaning of the actual parameter) and the result of p (the meaning \nof the call) must be appropriate to S . In addition, p must be supplied with a further hidden argument, \nwhich is a morphism in X showing how a state in S can be expanded to a state in S . In the above program, \nfor example, the meaning of the procedure call would be pS (L, a), where S is the set of pairs of integers, \nL is an expansion identifying the integers in S with one component of the pairs in S , and a e [comm]S \nis the meaning of the actual parameter x := x + y. For simplicity, we have used direct semantics in this \nin\u00adtroduction. However, the method applies even more ele\u00adgantly to continuation semantics, without any \nchange in the category K. One introduces two new types: completion) int (eger)compl(etion) whose meanings \nare command continuations and integer con\u00adtinuations, respectively. More precisely, [compl]S = S +-O \n[intcompl]S = Z a (S ~ O) , where O is an unspecified domain of outputs . The remain\u00ad ing types are then \ndefined by exponentiation and (pointwise) products in K: [comm] = [compl] ~ [compl] [intexp] = [intcompl] \n~ [compl] [intacc] = [compl] ~ [intcompl] (2) [intvar] = [intacc] X [intexp] [e+ e ]=[e]y [e ] . In \nfact, as one might expect from the prevalence of contin\u00aduations in compiler design, it is this continuation \nsemantics that will be the starting point for our development of an intermediate-code generator. (Strictly, \nit is a cent inuat ion semantics with respect to the imperative aspects of our il\u00adlustrative language, \nbut still a direct semantics with respect to the call-by-name procedural aspects.) 4 Stack Descriptors \nDuring program execution, the variables and other informa\u00adtion accessible to the program will lie in \na sequence of con\u00adtiguous blocks, called frames, contained within stack; when this sequence has length \nn, we will denote its members by jrame counts between O and n 1, in order of their their po\u00adsition from \nthe bottom to the top (most recently allocated and highest addressed portion) of the stack. We assume \nthat the frames are organized as a linked list called a static chain, specifically that a register SR \npoints to the base of frame n 1 and that the first (least addressed) word in each frame except frame \nO points to the base of the previous frame. For simplicity, we also assume that integer variables and \npointers both occupy single words, and that addressing is by words. (In fact, our approach extends straightforwardly \nto more complex cases where different kinds of variables require fields of different sizes, and these \nfields must be aligned on different-sized word boundaries.) During compilation, for each variable the \ncompiler will know the count Sf of the frame containing the variable, and the displacement &#38;, which \nis the distance from the base of the containing frame to the location of the variable. This pair S = \n(Sf, S~) of nonnegative integers is called a stack descriptor. As one would expect, the stack descriptors \nof variables will be embedded (implicitly) in a compile-time environment describing the free identifiers \nof the phrase to be compiled. However, compilation will also be influenced by more gen\u00aderal information \nabout the stack that is not particular to any variable; in the simple case considered in this paper this \ncompile-time information consists of the total number of frames (minus one) and the size of the top frame. \nWe call this pair of integers, which will depend upon position in the intermediate code being compiled, \nthe current stack descriptor SCU . Note that the current stack descriptor de\u00adscribes the beginning of \nthe free portion of the stack, i.e. the position of the next variable to be allocated. Stack descriptors \nare ordered lexicographically: (Sf, S,) ~ (S}, S~) iff S f <S} or (Sf = S; and S, ~ S~) Thus the effect \nof pushing the stack, either by enlarging the current top frame or by adding a new frame, is to increase \nthe current stack descriptor. We also define the addition or subtraction of a stack descriptor and an \ninteger by Thus the requirement that a variable described by S must lie within a frame in the currently \nactive portion of the stack implies that S ~ S  1. The key to moving from a functor-category description \nof semantics to an analogous description of of intermedlate\u00adcode generation is to replace Oles s the \ncategory Z of store shapes by the ordered set of stack descriptors (viewed as a category), which we will \nalso denote by X. 5 The Intermediate Language The intermediate language into which we translate programs \ncan be described by an abstract van Wijngaarden grammar with four stack-descriptor-indexed families of \nnonterminals: lefthand sides (Ls), simple righthand sides (Ss), righthand sides (Rs), and instruction \nsequences (1s). The intent of the indexing is that a member of (1s) is an instruction sequence that can \nbe meaningfully executed when the current stack descriptor is S: (L~) ::= S when S ~S 1 (SS) ::= (Ls) \nI lit (integer) (Rs) ::= (Ss) [ (unary operator) (S.s) [ (Ss)(binary operator) (1s) ::= stop / (Ls+J) \n:= (Rs) [J] ; (k+J) I if (Ss)(relation operator) [d] when s, + ~ > ~ then (IS+A) else (IS+J) } I adjustdisp \n[6] ; (Is+,) ) Ipopto S ;(is, ) when S ~ S (Additional forms will be introduced later.) Here sbrs de\u00adnotes \na register used to communicate the result of function procedures that are implemented by closed subroutines, \nand lit (integer) is a constant (or in compiler jargon, a literal). Notice that neither a right operand \nof the assignment op\u00aderator := nor a relation following if can contain more than one oDerator. In various \ninstructions here, the bracket ed integers d are displacement ad@ments, indicating an amount to be added \nto the current stack descriptor when the instruction is executed. because of the allocation or deallocation \nof ei\u00adther program variables or temporary variables. This adjust\u00adment of the current stack descriptor \nis the only effect of the adjustdisp instruction. The final instruction popto S causes the current stack \ndescriptor to be reset to S ; it is used to reduce the number of frames and causes a chamze in the register \nSR during program execution. Although a change in the frame count of the current stack descriptor causes \na change in the register SR during program execution, adjustments of the displacement have no effect \nduring program execution, since displacements are not actually computed at run time. However, the compiler \nmust keep track of these adjustments in translating intermediate code into machine language. Strictly \nspeaking, the (Is) are domams of instruction se\u00adquences, formed by completing the sets described by the \nabove grammar in the sense of Scott s lattice of flow dia\u00adgrams [11]. (Equivalently, the (Is) are components \nof the carrier of an initial continuous algebra [12] whose many\u00adsorted signature is specified by the \ngrammar. ) Fortunately, the only infinite or partial instruction sequences that arise during compilation \ncan be represented by data structures wit h loops, which can be implemented using references (in the \nsense of ML). More generally, references can be used to avoid duplicat\u00ading code: Whenever an instruction \nsequence i may be dupli\u00adcated by the compiler, it is replaced by a unique reference whose value is i. \nFor example, an instruction sequence of the form if then c ; z else d ; z (which might arise from the \ncompilation of a conditional command followed by another command), would be represented by if then c;relsed; \nr where r is a unique reference whose value is i. In the conver\u00adsion to actual machine code, all but \nat most one occurrence of such a reference is replaced by a jump to the code ob\u00adtained from its value, \nrather than a copy of such code. From the viewpoint this paper, however, the treatment of loops, the \navoidance of code duplication, and the distinction between instructions and their addresses are questions \nof representation. The mathematics of compilation is much cleaner if we abstract away from finite instruction \nsequences with references or jumps, to the possibly infinite sequences that they represent. 6 From Semantics \nto Compilation To apply functor-category semantics to intermediate code generation, in addition to taking \nZ to be the ordered set of stack descriptors, one must change the meaning of the basic types. The translation \nof a phrase of type compl appropri\u00adate to the stack descriptor S is an instruction sequence in (Is). \nThus [compl]S = (1s) The translation of a phrase of type intcompl is more com\u00adplex: Roughly speaking, \nit is a function from righthand sides to instruction sequences (which one can think of as an in\u00adstruction \nsequence containing a hole to be filled by a right\u00adhand side), but more precisely it is an exponential \nobject in the functor category: [intcompl] = 1? ~ [complj , where %? is the functor such that 7ZS=(RS). \nThe remaining types are defined by Equations (2) in ex\u00adactly the same way as in the functor-category \ncontinuation semantics described earlier. However, since Z is a preorder (actually a total order) viewed \nas a category, the operation of exponentiation in ICE can be simplified. We have seen that, if pc(F~G)S=homzSx \nF~G , then pS e(S> S ) xFS -+GS But the morphism set S &#38; S contains a single morphism when S ~ S \nand is empty otherwise. Thus a simpler but equivalent condition is that pS belongs to FS ~ GS when S \n~ S and is the empty function otherwise. We indicate this by p(S > S) cFS ~ GS or p(S ~ S)(z e FS ) c \nGS We are skirting over the requirement that both the mor\u00ad phisms in K and the members of (F ~ G)S should \nbe natural transformations. In fact, this requirement must be relaxed: Where naturality would require \npairs of instruction sequences to be equal, we will only require them to have the same denot ational \nbehavior, i.e. to denote the same func\u00adtional continuation from states to final outputs. In some cases \nthese instruction sequences will differ operationally, say by popping the stack at different steps. A \nsimilar situation holds with regard to coherence. Just as with semantics, the translation ~]me is defined \nby struc\u00adtural induction on the proof of the typing m E p : 0. How\u00adever, different proofs of the same \ntyping are not required to lead to the same translation, but merely to translations with the same denotational \nbehavior. Such translations may vary in the points where implicit conversions are invoked. Except for \ncompletions, which are translated into in\u00adstruct ion sequences, and integer variables, which are trans\u00adlated \ninto acceptor-expression pairs, each phrase of the input language is translated into a functional value \nin the compiler that will be applied at compile-time to produce instruction sequences. Moreover, the \ntype of the phrase in the input language will determine the type of its translation within the compiler. \nHowever, this categorical type discipline uses dependent function spaces that cannot be expressed in \nmost languages (such as ML) in which the compiler might be writ\u00adten. In such languages, one must give \ntranslations a single type (e.g. a recursive functional data type in ML) that in\u00adcludes all the kinds \nof translations described above, as well as a variety of nonsensical translations that are guaranteed \nby the categorical discipline not to occur during any compi\u00adlation. Commands If the phrase c has type \ncomm under the type assignment ~, then c [7r] * ~ [comm] , [4n,cmnm so that [comm]S = ([compl] ~ [compl])S, \nand thus [c] S(q c [m]*S)(S > S)(K e (Is,)) e (Is, ) 7r, comm Thus the translation of c is a function \nthat accepts an en\u00advironment q appropriate to the stack descriptor S and an instruction sequence K appropriate \nto a possible larger stack descriptor S , and returns an instruction sequence appropri\u00adate to S . In \nthe absence of jumps, ~ will describe the com\u00adputation to be performed after c, so that the result of \nthis function will be obtained by prefixing instructions for per\u00adforming c to the sequence ~. We will \ncall ~ (like its semantic counterpart) a continuation. The translation of skip returns its continuation \nargu\u00adment K without change: [skip] srps K = i-c. 7r, comm On the other hand, the translation of c1 ; \nC2 first prefixes instructions for cz to ~, and then prefixes instructions for c1. Put the other way \nround, the translation of c1 ; cz is the translation of c1 using a continuation that is the translation \nof C2 using the continuation ~ that is to be performed after c1 ;C2: [cl;c21*,=ommw ~[c21n,commsqs ~) \n = [cln=,commsqs ( The translation of assignment commands is described by an equation that is formally \nsimilar to the previous one: [a:= e] SqS ~ = [e]=, in,eXP S~S ([a]~,i*~.CCsqs ) , T,conlm except for \nthe typing, since the subphrase [a]SqS ~ belongs to [intcompl] rather than [compl]. The value of this \nsub\u00adphrase is an instruction sequence with a hole , the result of [e]SqS ( ) is obtained by filling this \nhole with a righthand side that will evaluate to the value of e, and then prefixing any instructions \nneeded to set temporary variables appear\u00ading in the righthand side. The close connection between this \napproach to compi\u00adlation and functor-category semantics is exemplified by the fact that all three of \nthe above equations for command trans\u00adlations are identical to the analogous semantic equations in functor-category \ncontinuation semantics. This pleasant situ\u00adation occurs for a surprising number of language constructs. \nHowever, there must be exceptions somewhere something must act ually compute intermediate-language instructions. \nIn fact, there are only three kinds of constructs whose trans\u00adlation is a nontrivial deviation from functor-category \nseman\u00adtics: expressions, where temporary variables must be allo\u00adcated, variable declarations, where program \nvariables must be allocated, and closed and/or recursive procedure decla\u00adrations, where calling sequences \nmust be generated. A similar situation holds for implicit conversions. Both the general specific equaceptors \nand Equation tions for expressions: (1) the for implicit conversions conversions from variables and to \nthe ac\u00ad [intvar ~ intacc]S(a, e) = a [intvar ~ intexp]S(a, e) = e are the same for translation as for \nsemantics. However, if we extended our illustrative language to include a conver\u00adsion from, say, integer \nto real expressions, then the corre\u00adsponding equation for converting translations would explic\u00aditly describe \nthe intermediate code for changing numerical represent at ion. 8 Integer Expressions If the phrase e \nhas type intexp under the type assignment n, then [e]r,intexps(~ ~ [~]*s)(s > S)(P c [intcompl]S ) e \n(1s,) , where /3 e [intcompl]S implies ~(S > S )(T-e (Rs,, )) E (is,, ) In essence, the translation of \ne must fill the hole in ~ by ap\u00adplying /3 to a righthand side r that will evaluate to the value of e, \nand then prefix to the resulting instruction sequence any instructions needed to set up temporary variables \nin r. The translation of a constant, when given an integer con\u00adtinuation ~, simply fills the hole in \n~ by applying it to an appropriate lit eral: U71r,int.-xps Vs P = ~S (lit 7) On the other hand, the translation \nof a unary expression such as e is obtained by applying the translation of the subexpression e to an \naltered integer continuation /? : [-elT,i~~,XPSqS P = [e]m,i~teXPSqS @ Here the effect of /3 depends \nupon whether the righthand side r to which it is applied is a simple righthand side. If so, then r is \na righthand side that evaluates to the value of e and cent ains the same temporary variables as r, so \nthat the original /3 can be filled with r: ,B S T= ps (-? ) when r e (Ss// ) Otherwise, however, r would \ncontain more than one op\u00aderator, so that a temporary variable must be used instead. Then the effect of@ \nis to fill @ with the negation of the tem\u00adporary, and to prefix to the resulting instruction sequence \nan assignment of r to the temporary: f?S r = S := r[S~ S!] ; ,bS S ) ) when r @(SS, ) , where s = s \nand S =s +1. In the latter case, [ e]=,in,eXPSqS ~ will give an instruc\u00adtion sequence of the form  \n,J2?iEEuj::=r[s -s$:s ( (-s It is important to understand the roles of the various stack descriptors \nhere: . S is appropriate to the environment q and is simply passed along with q. It describes a portion \nof the stack containing any program variables that may be accessed during the evaluation of e. E S will \nbe the current stack descriptor before e is eval\u00aduated. It may be larger than S since the computation \nto be done after evaluating e may refer to variables higher in the stack than the portion described by \nS. o S = S describes the temporary variable used to store the value of e, which is placed on the stack \nimmediately above the portion described by S . E S will be the current stack descriptor just before the \nassignment S := r. It may be larger than S since the stack at this point may include temporaries occurring \nin r. E s = S + 1 will be the current stack descriptor just after the assignment S := r. It is just \nlarge enough to include the temporary S . Thus, the effect of the displacement increment [S: S\\] is \nto deallocate any temporaries occurring in r and allocate the temporary S . The equation for [ e] can \nbe written succinctly as [-elm,intexpsVs P= [elT,intexpSqS (Usetmp S (AS . Ar. @S ( r))) , where usetmp \nis a function encapsulating the use of tempo\u00adrary variables: usetmp S ~S r = f ~S r when r e (S.S/ ) \nSimilarly, as the reader may verify, the function usetmp can be used to handle temporary variables in \nbinary expressions: [el + e2]T,intexpsqs P = [ellm,l.,.XPSnS (usetmp S (M , Arl. iIejlT,l~,,XPSqS (usetmp \nS (JS . ~r~. ~S (rl +rz))))) 9 Variable Declarations The other construct for which translation involves \nstorage allocation is the variable declaration. Suppose c is a com\u00admand in which free occurrences of \nthe identifier L have type intvar. Then the translation of the command new L: intvar in c gives an instruction \nsequence that allocates a new vari\u00adable, initializes it (say, to zero), executes c, deallocates the new \nvariable, and finally executes the continuation to be done after the whole command. Notice that the dealloca\u00adtion \nis done by an adjustdisp instruction prefixed to the continuation: [new L: intvar in Sq(s ~ S)(K e (is, \n)) = c] 7r>comm S := lit O[1] ; S ijS (adjustdisp[ l] ; ~) Ucl[7rl :intvar],comm Here s = s and S =s \n+l, so that the new variable is placed just above the stack de\u00adscribed by S , and S describes the extended \nstack contain\u00ading this variable. The environment used to translate c is ij= [~7r]*(s< S )q I L:(cL, e)] \n, which is the extension of q that maps L into an acceptor\u00ad expression pair describing the new variable. \n(We will explain shortly why [n] (S < S )q occurs here rather than ~.) The expression component e E [intexp] \nS fills the hole in ,B with the stack descriptor S for the new variable: eS /3 = /?S S , while the acceptor \ncomponent a E [intacc] S prefixes to its continuation ~ an assignment of a hole to S : aS K S r = S \n:= r[Sj S[ ] ; K Notice that the functor-category discipline insures that S is larger than S , so \nthat the new variable lies within the stack described by S . The descriptor S may be still larger, since \nit must include any temporaries occurring in r. Since the environment fj maps L into (a, e) E [intvar]S \n, it must belong to [[n [ L: intvar ]]* S . Thus it cannot be an extension of q e [T]* S, but must be \nan extension of some related environment in [n]* S . In fact, this environment is obtained by applying \nthe raising function [m]* (S < S ) to q. When F is a functor that is the meaning of a type or type assignment, \nwe write I (S < S ) for the application of the morphism part of F to the unique morphism in X from S \nto a larger stack descriptor S . In general, such an appli\u00adcation gives a function that serves to raise \na translation or environment appropriate to S to a similar entity appro\u00adpriate to S . For the type compl, \nthis operation prefixes 30 an appropriate adjustment of the stack to the instruction sequence that is \nits argument: [compl](S < S )(K e (Is)) = adjust disp[S~ S~] ; K when S; = Sf popto S; K otherwise{ \n For exponentiations, the function f E (F ~ G)S, whose domain is the set of stack descriptors greater \nthan S, is restricted to the set of stack descriptors greater than S : (F~G)(S<S )f = fl{S \\ S >} }. \n For products, the morphism parts are defined component\u00adwise: (F xx G)(S < S )(a, e) = (F(S < S )a, G(S \n< S )e) Similarly, the morphism parts of the meanings of type as\u00adsignments, which are products of meanings \nof types over sets of identifiers, are also defined componentwise: [7r]*(s < S )rp = [m](s < s )(?),) \n. 10 Boolean Expressions and Conditionals It would be straightforward to translate boolean expressions \nin the same manner as integer expressions. However, it is more interest ing, and in most casesmore efficient, \nto provide a control-flow translation, in which boolean expressions are compiled into trees of branch \ninstructions. To describe this approach, we extend our illustrative lan\u00adguage with the new types boolexp \nand boolcompl. The meaning of boolean expressions is defined analogously to that of integer expressions: \n[boolexp] = [boolcompl] ~ [compl] , but boolean completions are defined quite differently: [boolcompl] \n= [compl] x [compl] . The translation of a boolean expression b accepts a pair (K, ii) of continuations \nand produces an instruction sequence that branches to w when b is true or to it when b is false. In this \napproach the translation of constants is trivial: [truelr,boo,expsqs (~, %)= K s@ (K, K) = it , [fawlm,bookp \n while the translation of relations gives rise to test instruc\u00adtions, with temporary variables being \nhandled in the same way as with binary arithmetic operations: lel S e21T,boo1exPS@ (~, @ = Kellm,inteXPSqS \n(usetmp S (AS . AT,. lIe21=,in,.XPS~S (usetmp S (M . Ar2. if T-1< r2[Sj S$ ] then w else it)))) . On \nthe other hand, the translations of boolean opera\u00adtions and conditional commands simply compose or rear\u00adrange \nthe trees produced by subexpressions: S?ps (tt, ii) = [b]m,boolexpsqs ( ii, W) b %,bookxp lb or h]m,boolexpth$ \n(~, R) = [bdm,boolexps@ (K~ [b2]m,bcdexps@ (K, )) [if b then c1 else c2] Sqs K = n,comm [b]m,boolexps~s \n([cl] m,..mms~s K, [c2]T,comm%s 4 Notice that the second equation describes short-circuit evaluation \nfor or. 11 Open Procedures The functor-category semantics of the lambda-calculus as\u00adpects of Algol-like \nlanguages is described by the following semantic equations, which are determined by the cartesian closed \nnature of K and the definition of let L = p in p by the redex (AL. p )p: There is also an equation for \nimplicit conversion from one procedural type to another: [0, -+ 02 <e; -+ ej]s(f 6 [e, -+ 62]s) (s > \nS)(a c [6!]s ) = [% < o;]s (fs ([oj < !9,]S LL)) when Oj < 81and 02< 8; These equations all carry over \nto compilation, where they describe the translation of (nonrecursive) procedures into open or inline \ncode. (They have been written above in the simplified form that is appropriate when Z is a partial order. \n) Essentially, these equations describe a compiler where the lambda-calculus aspects of the source language \nare com\u00adpletely reduced at compile-time, leaving target code that is purely imperative. This is in pleasant \ncontrast with con\u00adventional approaches to compiling conventional languages, where inline implementation \nof procedures is notoriously hard to get right. 12 Closed Subroutines Closed subroutines are necessary \nfor the implementation of procedures, and other types of phrases, that are defined re\u00adcursively. (It \nwould be straightforward to also provide a letclosed definition for nonrecursive entities that are to \nbe implemented by closed subroutines.) We use the term procedure for lambda expressions and their meanings, \nand the term subroutine or closed subroutine for instruction sequences that may be called from several \npoints in the intermediate-code program. It is important to distinguish these concepts for two reasons: \nAs we have already seen, a procedure may be implemented by inline ex\u00adpansion rather than by a subroutine, \nand on the other hand, because of the use of call by name, a phrase such as a com\u00admand or an expression, \neven though it is not a procedure, will be implemented by a subroutine if it is defined by a recursive \ndefimtion or is a parameter to a procedure that is implemented by a subroutine. Similarly, we will distinguish \nbetween parameters, which are source-language phrases passed to procedures, and ar\u00adguments, which are \ninstruction sequences (actually subrou\u00adtines) passed to subroutines. While procedures are classified \nby types, subroutines are classified by simple types: (simple type) ::= compl \\ intcompl ] (simple type) \n-+ (simple type) The exact connection between types and simple types will be explained in Section 14. \nRoughly speaking, however, a simple type is obtained from a type by replacing comm by compl -+ compl \nintexp by intcompl + compl intacc by compl + intcompl For example, a procedure of type 0~+((On4co mm)) \n would be implemented by a subroutine of simple type PI ~ ( (p. -+ (compl + compl)) ) , (where each \np, is the simple type corresponding to 0,), which would accept n+ 1 arguments. The extra argument of \nsimple type compl plays the role of a return address. Thus in the n = O case, even a command is implemented \nby a subroutine accepting a (return address argument of simple type compl. However, such an argument, \nor any other subroutine of simple type compl, accepts no argu\u00adments. Calling a subroutine is a more complex \noperation than merely jumping to an instruction sequence, since it may be necessary to switch context \nfrom a frame list appropriate to the calling program to a frame list appropriate to the subroutine, and \nsince arguments may be passed by placing them in a vector accessible from the new frame list. In general, \nto call a subroutine one must specify 1. the subroutine to be called, 2. the global frame list to be \nused during execution of the subroutine, 3. a list of the arguments, which are themselves subrou\u00adtines. \n  To execute the call, when there are one or more arguments, one switches context to a frame list that \nis formed by adding a new frame (allocated on top of the current stack) to the global frame list, and \nthen sends control to the subroutine. The context switch causes the register SR to increase by an amount \n6 that is the current frame displacement Sj r at the time of the call. The new frame contains two words: \nthe lower word points to the global frame list, while the upper word points to a call block, which in \nturn contains the argument list and the quantity 6. The latter is the distance between the base of the \nframe pointing to the call block and the old frame list, which is in turn the global frame list to be \nused when calling the arguments. Notice that the contents of the call block are the same for all executions \nof a particular call, and are known at compile\u00adtime. Thus a single copy of the call block can be placed \nin code space, rather than placing multiple copies (in the case of a recursive call) on the stack. It \nis important to distinguish the special case when the subroutine being called takes no arguments, since \nin this case the information in the new frame is vacuous, so that it is more efficient simply to take \nthe new frame list to be the global frame list. This will remove from the stack everything above the \nmost recent frame of the global frame list, but it is easy to see that this data is inaccessible (since \nall pointers in the stack point downward). Indeed this is the (stack pop that occurs when a subroutine \npasses control to its return address. The specific method of achieving all this depends upon whether \nthe subroutine being called is the result of compiling a definition, or is an argument to a subroutine \ncontaining the call. In the first case, the identity of the subroutine being called is known at compile \ntime, and Its global frame list is a tail of the current frame list. If there are arguments, then the \ncall is performed by executing the instruction sequence call if(al, . . .. an). where i is the subroutine \nbeing called, ~ is the frame count of the (top frame of the) global frame list, and al, , an are the \narguments. This instruction sequence changes an Fl SR to SR  f +P ., frame : ~ El a and sends control \nto i. If the subroutine being called takes no arguments, however, then in place of call i f () one simply \nresets SR to point to frame f and sends control to i. On the other hand, if the subroutine being called \nis an argument then it will occur, say in position j, in a call block pointed to by a frame, say with \nframe count f, in the cur\u00adrent frame list, and the relevant global frame list will also be pointed to \nby the frame f. If the subroutine being called takes arguments, then the call is performed by the instruc\u00adtion \nsequence acalljf (al, . . .. an). which changes corresponding formal parameter, e.g. the parameter x \nin L-1 letrecp =h. ~x . . ..pl)xl) x.. in. ... frame 6 f 6 Er and sends control to a;. If the subroutine \nbeing called takes no arguments, however, then in place of acall j ~ () one resets SR to point to frame \nf and then executes ajump j , which changes a$ # to R 6 + } SR --El and sends control to a:. In summary, \nthree new forms of instruction sequence have been introduced for calling subroutines: (Is) ::= call (If+) \nf (( SRJ ),..., (SR~n)) I acall j f ((SR$ ),. . . . (SR~ )) [ ajump j where f < Sj, f+ = (f +1,3), n \n~ 1,andj ~ 1. Here SR$ denotes a subroutine of simple type q whose global frame list is described by \nthe stack descriptor S: (SR}) ::= (Is) when p < {compl, intcompl} (SR}) ::= (1s+) otherwise , where \n(Sf, S~)+ = (Sf + 1,3). In passing, we note that the calling conventions described here differ from those \nused in traditional Algol compilers [13, 14] in that all arguments to a subroutine are associated with \nthe same global frame list, instead of each argument having its own global frame list. The advantage \nof our ap\u00adproach is that it reduces the amount of stack storage used to call subroutines. The disadvantage \nis that, when a recur\u00adsive call has an actual parameter that is identical with the an nth-level evaluation \nof the parameter will invoke a chain of n subroutines. However, this inefficiency can be avoided if the \nprogrammer (or an optimizing compiler) eliminates the parameter by using a global identifier. In any \nevent, although we have not pursued the matter, we expect that more traditional calling conventions should \nalso be expressible within the functor-category framework. 13 Compiling Subroutines and their Calls Subroutines \nand their calls are compiled by three families of functions indexed by simple types. The translation \nof a phrase is mapped into a subroutine by mk-subrq S e [p]S -+ (SR~) , while a subroutine is mapped \ninto a call (more precisely into a function that, when applied to appropriate arguments yields a call) \nby mk-callPS G (SR $) + [p]S . Finally, there is a family of functions that produce calls of arguments: \nmk-argcallp S GN -+ [p]S , where JV denotes the set of positive integers. Specifically, mk-argcallv S \nj gives a call of an argument of simple type p that is the jth argument in the call block accessed from \nthe top frame of the frame list described by S. These three families of functions are defined by mutual \ninduction on simple types, reflecting the fact that compil\u00ading a subroutine involves compiling calls \nof its arguments, and compiling a call involves compiling subroutines for ar\u00adguments: mk-subrCO~PIS K \n= K mk-callco~PIS i = i mk-argcallcO~PIS j = a.iump j , and when v = ql ~ (... ~ (pn ~ compl) ...) for \nsome 7221: mk-subr~ S(c e [p]S) = c S+ (mk-argcallvl S+l) . . . S+ (mk-argcallvn S+n) mk-callPSi Sl(al \ne [P1]S1) ~Sn(a~ G [p~]Sn) = call i Sf mk-subrwm S ([pn](S < S )an)) mk-argcallWSj Sl(al e [pl]Sl) . \n. . Sm(a~ c [P~]S~) = acall j Sf Further equations deal with the cases where p ends in intcompl rather \nthan compl, which arise when function procedures or expressions are compiled into closed subrou\u00adtines. \nHere the special register sbrs is used to transmit integer results. Let saveres c [intcompl] ~ [compl] \nbe . the function such that saveres S/3 = S := sbrs [S: S~] ; /3S S , where S =s and S =s +l. Then mk-subrintco~P)S \n~ = saveres S ~ rnk-call,ntCOmPISi S r = sbrs := r [S~ Sj] ; i mk-argcallintCOmPlSjS r =sbrs:=r[S~ S~] \n;ajumpj , and when p = PI -+ (. . ~ (pm ~ intcompl) .) for some n>l: mk-subrW S(9 E [p]S) = saveres S+ \n( ,8S+ (mk-argcallp, S+l) S+ (mk-argcallwn S+n)) mk-callWSi Sl(al E [pl]Sl) . Sn(a~ G [p~]Sn)S (r c (R,s \n)) = sbrs :=r[S: Sj] ; call i Sf mk-subrp. S ([p~] (Sn < S )a~)) mk-argcallWSj S1(al E [pl]Sl) Sn(an \nE [pn]Sn)S (r E (R,s )) = sbrs :=r[S$ S:]; acall j Sf (mk-subrWISn([p~ ](S < Sn)aI), mk-subr~. Sn([(fn](sn \n< S )%)) Using these functions, it is straightforward to translate recursive definitions: [letrec ~ -pin \np ]me, Sv = ~ ]~xl,,q~,o,sq , Here q and z are mutual fixed points. This can be repre\u00adsented in the compiler \nby making the instruction sequence a loop, e.g. by making the i-field of the call instruction generated \nby ink-call a reference whose value is eventually set to i, The reader may wonder why the contents of \nthe register sbrs is stored in a temporary variable immediately upon return from a subroutine that produces \na result. The reason, illustrated by the integer expression letrecx -.inletrecy~ ..inx+y, is that sbrs \nmay be reset by later calls before its contents is used. 14 Subroutines for Product Types The method \nfor compiling closed subroutines described in the previous section does not deal with integer variables \nor with boolean expressions. Specifically, the mapping from types to simple types does not apply to types \ncontaining intvar, boolcompl, or boolexp. The key to filling this lacuna is that the meanings of a type \nsuch as are isomorphic to pairs of meanings of the types L91+ (. (On + intexp) ) Thus a procedure of \nthe first type can be implemented by a pair of subroutines corresponding to the second and third types. \nThe general situation is that a type is mapped into a sequence of simple types by the function r such \nthat r compl = compl r intcompl = intcompl r comm = compl + compl r intexp = intcompl -+ compl r intacc \n= compl -+ intcompl r intvar = compl -+ intcompl, intcompl + compl 17boolcompl = compl, compl 17boolexp \n= compl -+ compl + compl , and if  r6=p1, ....pm and ro =p; ,.. .,p: then Although the details are too \ntedious to record in this paper, it is straightforward to define two functions GoS and QoS such that, \nwhen rO = pl, . . ..pn. is an isomorphism. When 176= pi,. .,p~, this isomorphism can be used to define \nthe compilation of a phrase p of type .9 into a collection of n subroutines of simple types WI, , pn. \nIn place of the equations at the end of the previous section, we have: where and using the definitions \nof mk-subr and ink-call, one ob\u00ad q = [v 1L:VeS(mk-callW, Sil, ....mk-callvn Sin) ] il = mk-subr~l S al \nin = mk-subrvn S an (al,..., an) = @eS(lMCTl,:el,OS~ ). Here q and il, . . .. in are mutual fixed points \nthat can be represented in the compiler by using a reference for each of the instruction sequences il, \n. . .. in. It is clear that the method outlined in this section could also be used to deal with source \nlanguage types, such as record or object types, that are defined by products. To treat binary products, \nfor example, one would take r(e x e ) = (re) o (re ), where o denotes concatenation of sequences of \nsimple types. 15 Completions and Iteration Although the type compl plays a major role in our ap\u00adproach \nto compilation, it does not occur in the original type structure of the illustrative language. In contrast, \nthe Algol\u00adlike language Forsythe [9] includes phrases of type compl (though not intcompl or boolcompl) \nthat provide a capa\u00adbility similar to goto s and labels in Algol 60. To extend our illustrative language \nsimilarly, we intro\u00adduce the type compl into the language, as a subtype of comm, with the implicit conversion \n[compl < comm]S@~ = [compl](S < S )K. A completion can be constructed by joining a command and a completion \nwith a sequencing operator: [Cl ; c2nm,comp,s71 = [cln=,commsns([czn=,comp,s~) , or by joining two completions \nwith a conditional: [if b then c1 else c2]=,cOmP,Sq= [blm,boolexpsvs( [cll=,complsn> Mm,comp,sq) We \nalso provide an escape command that binds an iden\u00adtifier to a completion that causes an exit from the \nescape command: [escape L in c] s7pSK= x,comm S [[7T]*(S < s )~ I L: K]S K . M[=, :comp,],.omm All of \nthese equations are the same for translation as for semantics. Once the language includes completions, \nvarious itera\u00adtive constructs can be defined a syntactic sugar. A trivial example is a recursive definition \nof the completion loop c that repeats the command c ad infinitum (until c executes an escape): loop c \n~f letrec k= c;kin k, tains the translation s [loop c] where i = [c] SrlSi . r,compl q 2 r,comm A less \ntrivial example is the while command:  while b do c Sf escape e in letrec ks if bthen (c; k)else ein \nk, where e and k are identifiers not occuring free in b or c. This definition leads to the translation \n[while b do c] SrlS K = i , z,comm where [b]m,boolexps ([7r]*(s < S )q)s i= ([c] s ([7r]*(s < S )q)s \ni, K) r,comln This is a correct translation, but i = [b]=, bOOleXP ~ s s ([c] m,mnm S?psi,K) gives a \nsimpler translation with the same denotational be\u00adhavior that sometimes pops the stack sooner. 16 An \nExample The following example illustrates many of the aspects of translation discussed in this paper. \nLet P be the command new x: intvar in letrec pr S Ac: comm. (c ; x:=x+ 1 ; if x < 10 then pr(c ; c) else \nskip) in new y:intvar in pr(y := y+ x x x) . Then [P][l,cOmm, applied to appropriate arguments for trans\u00adlating \na complete program, is Pl[],c.mm (o,o)[] (o,o)stop= (0,0) := lit O[1] ; (O,1) := lit O[1] (0,0) (0,1) \n call i O ((1,3) := (0,0) x (0,0) [1] (0,2) (1,3) (0,1) := (0,1)+ (1,3) [-1] ajump 1, (1,4) (1,3) adjustdisp[ \n1] ; adjustdisp[ 1] ; stop) , (0,2) (0,1) (0,0) where i is acall 11 ((O, O) := (0,0) + lit 1 [0] ; (1,3) \n(1,3) if (O,O) < lit 10 [0] then (1,3) call i O (acall 11 (acall 11 (ajump l)), (1,3) (2,3) (2,3) (2,3) \najump 2) (1,3)  where k is an identifier not occuring free in c. By substitut-else ajump 2) ing this \nsyntactic definition into the translation equations, (1,3) Under each instruction sequence in the above \ndisplays, we have placed the stack descriptor that will be current when the sequence begins execution. \n17 Conclusions In the spring of 1994, the basic approach described here was used in an undergraduate \ncompiling course to construct an intermediate code generator, written in Standard ML, for a simple Algol-like \nlanguage. In the coming months, we hope to extended it for use in implementing the language Forsythe. \nA major research question is to what extent the approach can be extended to generate more efficient intermediate-Ianguage \ncode. We suspect that a richer form of stack de\u00adscriptor can be devised that will provide information \nabout the caching of variables in registers and the use of displays (groups ofregisters pointing directly \nto active frames). On the other hand, theapproach depends soheavilyon the use of continuations that it \nmay be difficult to vary evaluation order (say, byinterleaving the evaluation ofsubexpressions) with \nsufficient flexibility, especially for RISC machines. A second question is whether the approach will \nlend it\u00adself to a proof of compiler correctness. One would expect that the close connections between \nfunctor-category seman\u00adtics and our approach to code generation would lead to sim\u00adple proofs of the relationship \nbetween semantics and compi\u00adlation. However, we have not yetpursued this topic beyond intuitive arguments. \nReferences [1]Jones, N. D. and Schmidt, D. A. Compder Genera\u00adtion from Denotataonal Semantics. in: Semantics-Directed \nCompiler Generation, Proceedings of a Workshop, Aarhus, Denmark, January 14 18, edited by N. D Jones. \nLecture Notes in Computer Science, vol. 94, Springer-Verlag, Berlin, 1980, pp. 70 93. [2] Steele .Jr., \nG. L. RABBIT: A Compiler for SCHEME (A Study in Compder Opttmizatton). no. AI-TR-474, Massachusetts Institute \nof Technology, Artificial Intel\u00adligence Laboratory, May 1978, iii+272 pp. [3] Wand, M. Dertvmg Target \nCode as a Representa\u00adt~on of Continuation Semantzcs. ACM Transactions on Programming Languages and Systems, \nvol. 4 (1982), pp. 496-517. [4] Reynolds, J. C. The Essence of A lgol. in: Algorithmic Languages, Proceedings \nof the International Sympo\u00adsium on Algorithmic Languages, Amsterdam, October 26-29, edited by J. W. de \nBakker and J. C. van Vliet. North-Holland, Amsterdam, 1981, pp. 345-372. [5] Oles, F. J. A Category-Theoretic \nApproach to the Se\u00admantics of Programming Languages, Ph. D. Disserta\u00adtion. Syracuse University, August \n1982, vi+240 pp. [6] Oles, F. J. Type Algebras, Functor Categories, and Block Structure. in: Algebraic \nMethods in Seman\u00adtics, edited by M. Nivat and J. C. Reynolds. Cambridge University Press, Cambridge, \nEngland, 1985, pp. 543\u00ad 573. [7] Morris, F. L. Correctness of Translations of Program\u00admmg Languages \nAn Algebrazc Approach, Ph. D. Dis\u00adsertation. Stanford University, August 1972. [8] Reynolds, J. C. Conjunctive \nTypes and A lgol-lake Lan\u00adguages (Abstract of Invited Lecture). in: Proceed\u00adings Symposium on Logic in \nComputer Science, Ithaca, New York, June 22-25. 1987, p. 119. [9] Reynolds, J. C. Preliminary Design \nof the Program\u00admmg Language Forsythe. Report, no. CMU CS 88 159, Carnegie Mellon University, Computer \nScience De\u00adpartment, June 21, 1988. [10]Reynolds, J. C. The Coherence of Languages with In\u00adtersection \nTypes. in: Theoretical Aspects of Com\u00adputer Software, International Conference TACS 91, Proceedings, \nSendai, Japan, September 24-27, 1991, edited by T. Ito and A. R. Meyer. Lecture Notes in Computer Science, \nvol. 526, Springer-Verlag, Berlin, 1991, Pp. 675-700. [11]Scott, D. S. The Lattice of Flow Diagrams. \nin: Sym\u00adposium on Semantics of Algorithmic Languages, edited by E. Engeler. Lecture Notes in Mathemat\u00adics, \nvol. 188, Springer-Verlag, Berlin, 1971, pp. 31l 366. [12] Goguen, J. A., Thatcher, J. W., Wagner, E. \nG., and Wright, J. B. Inatzal Algebra Semantics and Continu\u00adous Algebras, Journal of the ACM, vol. 24 \n(1977), pp. 68-95. [13] Dijkstra, E. W. Recursive Programming. Numerische Mathematik, vol. 2 (1960), \npp. 312 318. [14] Naur, P, The Deszgn of the GIER ALGOL Compder, Part I. BIT, vol. 3 (1963), pp. 124 \n140, Reprinted m Goodman, Rtchard, editor, Annual Review in Auto\u00admatic Programmmg, Vol. 4, Pergamon Press, \nOxford (1964) 49-85. \n\t\t\t", "proc_id": "199448", "abstract": "<p>In the early 80's Oles and Reynolds devised a semantic model of Algol-like languages using a category of functors from a category of store shapes to the category of predomains. Here we will show how a variant of this idea can be used to define the translation of an Algol-like language to intermediate code in a uniform way that avoids unnecessary temporary variables, provides control-flow translation of boolean expressions, permits online expansion of procedures, and minimizes the storage overhead of calls of closed procedures. The basic idea is to replace continuations by instruction sequences and store shapes by descriptions of the structure of the run-time stack.</p>", "authors": [{"name": "John C. Reynolds", "author_profile_id": "81100470240", "affiliation": "Department of Computing, Imperial College, London SW7 2BZ, Great Britain and School of Computer Science, Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP39077815", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/199448.199452", "year": "1995", "article_id": "199452", "conference": "POPL", "title": "Using functor categories to generate intermediate code", "url": "http://dl.acm.org/citation.cfm?id=199452"}