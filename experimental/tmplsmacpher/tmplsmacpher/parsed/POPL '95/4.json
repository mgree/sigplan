{"article_publication_date": "01-25-1995", "fulltext": "\n Precise Interprocedural Dataflow Analysis via Graph Reachability Thomas Reps, + Susan Horwitz,t and \nMooly Sagivf $ University of Wisconsin Abstract The paper shows how a large class of interprocedural \ndataflow-analysis problems can be solved precisely in poly\u00adnomial time by transforming them into a special \nkind of graph-reachability problem. The only restrictions are that the set of dataflow facts must be \na finite set, and that the dataflow functions must distribute over the confluence operator (either union \nor intersection). This class of prob\u00adlems includes but is not limited to--the classical separ\u00adable problems \n(also known as gen/kill or bit-vector problems) e.g., reaching definitions, available expres\u00adsions, and \nlive variables. In addition, the class of problems that our techniques handle includes many non-separable \nproblems, including truly-live variables, copy constant pro\u00adpagation, and possibly-uninitialized variables, \nResults are reported from a preliminary experimental study of C programs (for the problem of finding \npossibly\u00aduninitialized variables). 1. Introduction This paper shows how to find precise solutions to \na large class of interprocedural dataflow-analysis problems in polynomial time. In contrast with intraprocedural \ndataflow analysis, where precise means meet-over-all-paths [ 20], a precise inter-procedural dataflow-analysis \nalgorithm must provide the meet-over-all-valid-paths solution. (A path is valid if it respects the fact \nthat when a procedure finishes it returns to the site of the most recent call [31, 15,6,24,21,29] see \nSection 2.) Relevant previous work on precise interprocedural dataflow analysis can be categorized as \nfollows: Polynomial-time algorithms for specific individual problems (e.g., constant propagation [5, \n14], flow\u00adsensitive summary information [6], and pointer analysis [241). o A polynomial-time algorithm \nfor a limited class of problems: the locally separable problems (the interpro\u00adcedural versions of the \nclassical bit-vector or gen\u00ad +Work performed while visiting the Datatogisk Institut, University of Copenhagen, \nUniversitetsparken 1, DK-21OO Copenhagen East, Denmark. *On leave from IBM Scientific Center, Haifa, \nIsrael. This work was supported in part by a David and Lucile Packard Fellow\u00adship for Science arrd Engineering, \nby the National Science Foundation under grants CCR-8958530 and CCR-9 100424, by the Defense Advanced \nResearch Projects Agency under ARPA Order No. 8856 (monitored by the Office of Naval Research under contract \nNOO014-92-J-1937), by the Air Force Office of Scientific Research under grant AFOSR-9 1-0308, and by \na grant from Xerox Corporate Research. Authors address: Computer Sciences Department; Univ. of Wisconsin; \n1210 West Dayton Street; Madison, WI 53706; USA. Electronic mail: {reps, horwitz, sagiv) @cs.wise.edu. \nPermission to copy wfthout fee all or part of this material is granted provided that the copies are not \nmade or distributed for direct commercial advanta~e, the ACM copyright notice and the title of the publication \nand Its date appear, and notice is given that copying is by permission of the Association of Computing \nMachinery. To ecrpyotherwise, or to republish, requires a fee and/or specific permission. POPL 951/95 \nSan Francisco CA USA 1995 ACM O-89791-892-l/9WOOOl....$3.50 kill problems), which include reaching definitions, \navailable expressions, and live variables [22]. . Algorithms for a very general class of problems [10,31,21]. \nThe work cited in the third category concentrated on gen\u00aderality and did not provide polynomial-time \nalgorithms. In contrast to this previous work, the present paper pro\u00advides a polynomial-time algorithm \nfor finding precise solu\u00adtions to a general class of interprocedural dataflow-analysis problems. This \nclass consists of all problems in which the set of dataflow facts D is a finite set and the dataflow \nfunc\u00adtions (which are in 2~ + 2~) distribute over the meet operator (either union or intersection, depending \non the problem). We will call this class the interprocedurai, finite, distributive, subset problems, \nor IFDS problems, for short, All of the locally separable problems are IFDS prob\u00adlems. In addition, many \nnon-separable problems of practi\u00adcal importance are also IFDS problems for example: truly-live variables \n[13], copy constant propagation [12, pp. 660], and possibly-uninitialized variables. Our results are \nbased on two insights: (i) By restricting domains to be powersets of atomic dataflow facts and dataflow \nfunctions to be distributive, we are able to efficiently create simple representations of functions that \nsummarize the effects of procedures (by supporting efficient lookup operations from input facts to output \nfacts). For the locally separable prob\u00adlems, the representations of summary functions are sparse. This \npermits our algorithm to be as efficient as the most efficient previous algorithm for such prob\u00adlems, \nbut without losing generality. (ii) Instead of calculating the worst-case cost of our algo\u00adrithm by \ndetermining the cost-per-iteration of the main loop and multiplying by the number of iterations, it is \npossible to break the cost of the algorithm down into three contributing aspects and bound the total \ncost of the operations performed for each aspect (see the Appendix).  The most important aspects of \nour work can be summar\u00ad ized as follows: In Section 3, we show that all IFDS problems can be solved precisely \nby transforming them into a special kind of graph-reachability problem: reachability along interprocedurally \nrealizable paths. In contrast with ordinary reachability problems in directed graphs (e.g., transitive \nclosure), realizable-path reachability prob\u00adlems involve some constraints on which paths are con\u00adsidered. \nA realizable path mimics the call-return struc\u00adture of a program s execution, and only paths in which \nreturns can be matched with corresponding calls are considered. In Section 4, we present a new polynomial-time \nalgo\u00adrithm for the realizable-path reachability problem. The algorithm runs in time O (ED 3); this is \nasymptotically Jaster than the best previously known algorithm for the problem [16], which runs in time \nO (D3~ CallPEP +-D4~ Cal$). 2. The IFDS Framework for Distributive Interpro\u00ad * As cii~cussed in Sect~on \n5, the new realizable-path reachability algorithm is adaptive, with asymptotically better performance \nwhen applied to common kinds of problem instances that have restricted form. For exam\u00adple, there is an \nasymptotic improvement in the algorithm s performance for the common case of locally separable problems. \nOur work generalizes that of Knoop and Steffen [22] in the sense that our algo\u00adrithm handles a much larger \nclass of problems, yet on the locally separable problems the algorithm runs in the same time as that \nused by the Knoop-Steffen algorithm-O (ED). Imprecise (overly conservative) answers to interpro\u00adcedural \ndataflow-analysis problems could be obtained by treating each interprocedural dataflow-analysis prob\u00adlem \nas if it were essentially one large intraprocedural problem. In graph-reachability terminology, this \namounts to considering all paths rather than considering only the interprocedurally realizable paths. \nFor the IFDS problems, we can bound the extra cost needed to obtain the more precise (realizable-path) \nanswers. In the important special case of locally separable prob\u00adlems, there is no penalty at all both \nkinds of solu\u00adtions can be obtained in time O (ED). In the distribu\u00adtive case, the penalty is a factor \nof D: the running time of our realizable-path reachability algorithm is O (ED 3), whereas all-paths reachability \nsolutions can be found in time O (ED 2). However, in the preliminary experiments reported in Section \n6, which involve exam\u00adples where D is in the range 70-142, the penalty observed is at most a factor of \n3.4.  Callahan has given algorithms for several interpro\u00adcedural flow-sensitive side-effect problems \n[6]. Although these problems are (from a certain technical standpoint) of a slightly different character \nfrom the IFDS dataflow-analysis problems, with small adapta\u00adtions the algorithm from Section 4 can be \napplied to these problems and is asymptotically faster than the algorithm given by Callahan. In addition, \nour algorithm handles a natural generalization of Callahan s problems (which are locally separable problems) \nto a class of dis\u00adtributive flow-sensitive side-effect problems. (This and other related work is described \nin Section 7.)  The realizable-path reachability problem is also the heart of the problem of interprocedural \nprogram slicing, and the fastest previously known algorithm for the problem is the one given by Horwitz, \nReps, and Bink\u00adley [16]. The realizable-path reachability algorithm described in this paper yields an \nimproved interprocedural-slicing algorithm-one whose running time is asymptotically faster than the Horwitz-Reps-Binkley \nalgorithm. This algorithm has been found to run six times as fast as the Horwitz-Reps-Binkley algo\u00adrithm \n[28].  Our dataflow-analvsis al~orithm has been imdemented and used to analy~e sev~ral C programs. Preliminary \nexperimental results are reported in Section 6.  Space constraints have forced us to treat some of the \nabove material in an abbreviated form. Full details including proofs of all theorems stated in the paper \nas well as a great deal of additional material, can be found in [27]. cedural Dataflow-Analysis Problems \nThe IFDS framework is a variant of Sharir and Pnueli s functional approach to interprocedural dataflow \nanalysis [31], with an extension similar to the one given by Knoop and Steffen in order to handle programs \nin which recursive procedures have local variables and parameters [21]. These frameworks generalize Kildall \ns concept of the meet-over-all-paths solution of an irztraprocedural dataflow-analysis problem [20] to \nthe meet-over-all\u00advalid-paths solution of an interprocedural dataflow\u00adanalysis problem. The IFDS framework \nis designed to be as general as pos\u00adsible (in particular, to support languages with procedure calls, \nparameters, and both global and local variables). Any problem that can be specified in this framework \ncan be solved efficiently using our algorithms; semantic correct\u00adness is an orthogonal issue. A problem \ndesigner who wishes to take advantage of our results has two obligations: (i) to encode the problem so \nthat it meets the conditions of our framework; (ii) to show that the encoding is consistent with the \nprogramming language s semantics [9, 10]. Encoding a problem in the IFDS framework may involve some loss \nof precision. For example, in languages in which parameters are passed by reference there may be a loss \nof precision for problem instances in which there is aliasing. However, the process of finding the solution \nto the result\u00ading IFDS problem introduces no further loss of precision. To specify the IFDS framework, \nwe need the following definitions: Definition 2,1. In the IFDS framework, *a p$ogram is represented using \na directed graph G = (N , E ) called a supergraph. G consists of a collection of flow graphs G~, G2, \n (one for each procedure), one of which, Groin, represents the program s main procedure. Each flowgraph \nG has a unique start node SP, and a unique exit node eP. T~e other nodes of the flowgraph represent the \nstatements and predicates of the procedure in the usual way, except that a procedure call is represented \nby two nodes, a call node and a return-site node. (The sets of call and return\u00adsite nodes of procedure \np will be denoted by CallP and Ret , respectively; the sets of all call and return-site nodes in tL e \nsupergraph will be denoted by Call and Ret, respec\u00adtively.) In addition to the ordinary intraprocedural \nedges that connect the nodes of the individual flowgraphs, for each procedure* call, represented by call-node \nc and return-site node r, G has three edges: o An intraprocedural call-to-return-site edge from c to \nn An interprocedural call-to-start edge from c to the start node of the called procedure;  An interprocedural \nexit-to-return-site edge from the exit node of the called procedure to r. 0  (The call-to-return-site \nedges are included so that the IFDS framework can handle programs with local variables and parameters. \nThe dataflow functions on call-to-return\u00adsite and exit-to-return-site edges permit the information about \nlocal variables that holds at the call site to be com\u00adbined with the information about global variables \nthat holds at the end of the called procedure.) When discussing time and space requirements, we use the \nname of a set to denote the set s size. For example, we declare g: integer k S.SC4V /...------\u00ad program \nmain ., ..,, ,,. .,.-% / ,,. begin i declare x integer s main ,/ ,: P read(x) ,/ ;/ ENTER P ENTER main \ncall P (x) ~/ :: U j end LS.s ks.{x,g] ,: 1 / It4 d ;: procedure P (value a: integer) READ(x) lFa>O \n,;~ begin if (a > O)then ?.S.s-(x} @ ,:; P ,; read(g) n.5 .,. a:= a-g ra / READ(g) call P(a) CALL P / \n ?,s.s Ls.s-{g) ,.. ............. ?,s.s ~.,, print(a, g) %.. i fi ks.s-{g) n6 ......... ......... . \n;,, a :=a-g . ..44 RE%RN lS.if (a&#38;S)or(gcS) . ..,, rl FROMP . { thenSU[a] ..,, . elseS-(a) .... n7 \n?.ss ..,, ..,. ,.. CALL P 1 e main EXIT main I ?I 1S.S-(.] ~ / PRINT(a,g) \\ ,: \\/ L S.s :. ;j; ;. :: \n,.,\\ P . .. ......... EXIT P F ... ... ,,.. .........  (a) Example program (b) Its supergraph G * Figure \n1. An example program and its supergraph G*. The supergraph is annotated with the dataflow functions \nfor the possibly\u00aduninitialized variables problem. The notation Scfla> denotes the set S with x renamed \nto a. use Call, rather thqn I Call 1, to denote the number of call nodes in graph G . (We make two small \nde~iatious fr~m this convention, using N and E to stand for IN I and IE 1, respectively.) Example. Figure \n1 shows an example program and its supergraph G . 0 Definition 2.2. A path of length j from node m to \nnode n is a (possibly empty) sequence of j edges, which will be denoted by [el, e2,  , ej], such that \nfor all i, 1< i <j-1, the target of edge ei is the source of edge ei +1. 0 The notion of an (interprocedural&#38;) \nvalid path cap\u00ad tures the idea that not all paths in G r~present potential execution paths: Definition \n2.3. Let each call node in G* be given a unique index i. For each such indexed call node ci, label Ci \ns out\u00adgoing call-to-start edge by the symbol (i . Label the incoming exit-to-return-site edge of the \ncorresponding return-site node by the symbol )i . For each pair of nodes m, n in the same procedure, \na path from m ton is a same-level valid path iff the sequence of labeled edges in the path is a string \nin the language of balanced parentheses generated from nonterminal matched by the following context-free \ngrammar: matched -) (i matched )i matched for 1 S i < Call I&#38; For each pair of nodes m, n in supergraph \nG , a path from m to n is a valid path iff the sequence of labeled edges in the path is a string in the \nlanguage generated from uonterminal valid in the following grammar (where matched is as defined above): \nvalid + valid (i matched for 15 i < Call I matched We denote the set of all valid paths from m to n by \nIVP(m, n). In the formulation of the IFDS dataflow-analysis frame\u00adwork (see Definitions 2.4 2.6 below), \nthe same-level valid paths from m to n will be used to capture the transmission of effects from m to \nn, where m and n are in the same pro\u00adcedure, via sequences of execution steps during which the call stack \nmay temporarily grow deeper because of calls but never shallower than its original depth, before eventually \nreturning to its original depth. The valid paths from s~~i~ to n will be used to capture the transmission \nof effects from Smin, the program s start node, to n via some sequence of execution steps. Note that, \nin general, such an execution sequence will end with some number of activa\u00ad tion records on the call \nstack; these correspond to unmatched (i s in a string of language L (valid). Example. In supergraph G \n* shown in Figure 1, the path [S~ain+nl, nl+n2, n2-+s , sP-+n4, n4+e , eP-+n3] is a (same-level) valid \npath; fiowever, the path fsmain-nl, nl+n2, n2+sP, SP+n4, n4+eP, e +n8] is not a valid path because the \nreturn edge eP+ n8 does not correspond to the preceding call edge n2 + SP. 0 We now define the notion \nof an instance of an IFDS problem: Definition 2.4. An instance 1P of an interprocedural, finite, distributive, \nsubset problem (or IFDS problem, for short) is a five-tuple, 1P = (G*, D, F, M, m), where (i) G is a \nsupergraph as defined in Definition 2.1. (ii) D is a finite set,  (iii) F G 2~ + 2~ is a set of distributive \nfunctions. (iv) M: E * + F is a map from G * s edges to dataflow functions. (v) The meet operator n \nis either union or intersection.D  In the remainder of the paper we consider only IFDS problems in which \nthe meet operator is union. It is not hard to show that IFDS problems in which the meet operator is intersection \ncan always be handled by dualizing (i. e., by transforming such a problem to the complementary union \nproblem). Informally, if the must-be-X problem is an intersection IFDS problem, then the may-not-be-X \nprob\u00adlem is*a union IFDS problem. Furthermore, for each node n~N, the solution to the must-be-X problem \nis the complement (with respect to D) of the solution to the may-not-be-X problem. Example. In Figure \n1, the supergraph is annotated with the dataflow functions for the possibly-uninitialized vari\u00adables \nproblem. The possibly-uninitialized* variables problem is to determine, for each node n G N , the set \nof program variables that may be uninitialized just before exe\u00adcution reaches n. A variable x is possibly \nuninitialized at n either if there is an x-definition-free valid path to n or if there is a valid path \nto n on which the last definition of x uses some wu-iable y that itself is possibly uninitialized. For \nexample, the dataflow function associated with edge n6 + n7 shown in Figure 1 adds a to the set of possibly\u00aduninitialized \nvariables if either a or g is in the set of possibly-uninitialized variables before node n6. 0 To simplify \nthe presentation, we assume in Definition 2.4 that there is a single global space of dataflow facts, \nD. This assumption is made strictly for expository purposes; the more general setting, in which for each \nprocedure p there is a (possibly) different space of dataflow facts, DP, presents no additional difficulties \n[27]. Our implementation of the IFDS framework, discussed in Section 6, supports the more general setting. \nDefinition 2.5. Let 1P= (G*, D, F, M, tl) be an IFDS problem instanc~, and let q = [e 1, e z, -., ej \n] be a non\u00adempty path in G . The path function that corresponds to q, denoted by pfq, is the function \npf df fi o  Ofz of 1, where for all i, 1< i <j, $ = M (e,). %he path function for an empty path is \nthe identity function, Lxx. 0 Definition 2.6. Let 1P= (G*, D, F, M, n) be an IFDS problem instance. The \nmeet-over-all-valid-paths solution to 1P consists of the collection of values MVP~ defined as follows: \nMVP~ = ,G,vgm, ,n, fq(T) oreachn= * 3. Interprocedural Dataflow Analysis as a Graph-Reachability Problem \n3.1. Representing Distributive Functions In this section, we show how to represent distributive func\u00adtions \nin 2D + 2D in a compact fashion-each function can be represented as a graph with at most (D+ 1)2 edges \n(or, equivalently, as an adjacency matrix with (D+ 1)2 entries). Throughout this section, we assume that \nf and g denote functions in 2D -+ 2D and that f and g distribute over u. Definition 3.1. The representation \nrelation of f, Rf~(Du{O })x(D u{O }), is a binary relation (i.e., graph) defined as follows: R~=~~ { \n(o, o) } u {(o, y)lyef(0)} u {(x, y) I y~~({x}) andydf(0)}. 0 R~ can be thought of as a graph with 2(D \n+ 1) nodes, where each node represents an element of D (except for the two O nodes, which (roughly) stand \nfor 0). Example. The following table shows three functions and their representation relations: id:2{ \n b}+2{b)b) a:2[a, b}+2(a, b) f2~a,b,c}+2(4b,cl id= )S.S a=kl{a) f= LS.(,S-{a))u {b] Note that one consequence \nof Definition 3.1 is that there is never an edge of the form (x, O), where x e D. Another consequence \nof Definition 3.1 is that edges in representation relations obey a kind of subsumption pro\u00adperty . That \nis, if there is an edge (O, y), for y e (D u { O }), there is never an edge (x, y), for any x e D. For \nexample, in constant-function a, edge (O, a) subsumes the need for edges (a, a) and (b, a). 0 Representation \nrelations and, in fact, all relations in (D u { 0)) x (D u { O})-can be interpreted as functions in 2D \n+ 2 . as follows: Definition 3.2. Given a relation R c (D u { O }) x (D u { O }), its interpretation \n[R]: 2D +~D is the function defined as follows: [R] =~~LX.({y I 3x~Xsuch that(x, y)~R } u{ YI(UY)CR})-{0}. \n0 the relational composition Rf and Rg relates to the relations R~c S x S and Theorem 3.3. [l?fll = \n$ Our next task is to show how of two representation relations function composition g ofi Definition \n3.4. Given two R c S x S, their composition Rf; Rg c S x S is defined as follows: Rf; Rg =df {(x, y)= \nSXS I 3ze S such that (x, z)e Rf and (z, y)e Rg }. 0 Theorem 3.5. For all f, g = 2D +. 2D, [Rf; R~] = \ng of Definition 3.4 and Theorem 3.5 imply that the composi\u00adtion of any two distributive functions in \n2D + 2D can also be represented by a graph (relation) with at most (D+ 1)2 edges. In other words, the \ndistributive functions in 2D + 2D are compressible : there is a bound on the size of the graph needed \nto represent any such function as well as the composih on of any two such functions! Corollary 3.6. Given \na collection offinctions forl<i <j, fio$-lo  ofzofl URf, ;Rf,;  ;Rtl. 3.2. From Dataflow-Analysis \nProblems to Path Reachability Problems In this section, we show how to convert IFDS realizable-path graph-reachability \nproblems. lar, for each instance 1P of an IFDS problem, a graph G~ and an instance of a realizable-path \nJ: 2D+ 2*, Realizable\u00ad problems to In particu\u00adwe construct reachabil\u00ad ity problem in G~p. The edges \nof G~p correspond to the representati~n relations of the dataflow functions on the edges of G . Because \nof the relationship between function composition and paths in composed representation-relation graphs \n(Corollary 3.6), the path problem can be shown to be equivalent to 1P: dataflow-fact d holds at supergrapb \nnode n iff there is a realizable path from a distinguished node in Gfp (which represents the fact that \n0 holds at the start of procedure main) to the node in GfP that represents Oag g r--cT-l ,/ ,. P ,,UJ,,, \n /// ~o o ,, ; ENTERP ENTERmain ,. ;; ,.. ~ ... ~ #ill OXg ;~ / n4 Oag 111~ ~ a% f.~ ;. ; READ(x) ,; \n Fa O 7 // ~~ ,, ~ l_\\ .,,,,/ Ill ? [1 111 q:= a-g fi!~ , j ~ -......,. I HII n6 IWI ,,,*Iw ....,,-n, \n ...,,, -pit. ..,, HH -J\u00ad  \\iiiIllI@ ---I MauiI , ~ -- CA:P .q -~\\ @!m!!d ( \\ \\\\ - 1, EXITP 1~~ \n \\\\  ... Figure 2. The exploded supergraph that corresponds to the instance of the possibly-uninitialized \nvariables problem shown in Figure 1. Closed circles represent nodes of G% that are reachable along realizable \npaths from (sWi., O). Open circles represent nodes not reachable along such paths. fact d at node n (see \nTheorem 3.8). (Smain,@to(ep,a). c! Definition 3.7. Let 1P= (G*, D, F, M, u) be an IFDS problem instance. \nWe define the exploded supergraph for 1P, denoted by G~P, as follows: G~P= (N#, E#), where N#=N*x(Du{O}), \nE#={(m, dl)-+(n, d2) I (m, n)=E* and (dl, d2)~ R~(~,., }. 0 The nodes of G~P are pairs of the form (~ \nd); each node n of ~P is exploded into D + 1 nodes of GIP. Each edge e of E with dataflow function f \nis exploded into a number of edges of G~p according to representation relation Rfl Dataflow-problem 1P \ncorresponds to a single-source realizable-path reachability problem in Gfp, where the source node is \n($mi., O). Example. The exploded super~aph that corresponds to the instance of the possibly-uninitialized \nvariables prob\u00adlem shown in Figure 1 is shown in Figure 2. 0 Throughout the remainder of the paper, we \nuse the terms (same-level) realizable path and (same-level) valid path to refer to two related concepts \nin the exploded supergraph and the supergraph. For both realizable paths and valid paths , the idea is \nthat not every path corresponds to a potential execution path: the constraints imposed on paths mimic \nthe call-return structure of a program s execution, and only paths in which returns can be matched with \ncorresponding calls are permitted. However, the term realizable paths will always be used in connection \nwith paths in the exploded supergraph; the term valid paths will always be used in connection with paths \nin the supergraph. We now state the main theorem of this section, Theorem 3.8, which shows that an IFDS \nproblem instance 1P is equivalent to a realizable-path reachability problem in graph G$: Theorem 3.8. \nLet G~p = (Ne, E#) be the e~ploded super\u00adgraph for IFDS problem instance I!= (G , D, F, M, u), and let \nn be a program point in N . Then d e MVP. iff there is a realizable path in graph G!P from node (s~aic, \nO) to node (n, d). The practical consequence of this theorem is that we can find the meet-over-all-valid-paths \nsolution to 1P by solving a realizable-path reachability problem in graph G!p. Example. In the exploded \nsupergraph shown in Figure 2, which corresponds to the instance of the possibly\u00aduninitialized variables \nproblem shown in Figure 1, closed circles represent nodes that are reachable along realizable paths from \n(sMi., O). Open circles represent nodes not reachable along realizable paths. (For example, note that \nnodes (n8, g) and (n9, g) are reachable only along non\u00adrealizable paths from (s~ai~, O).) This information \nindicates the nodes values in the meet-over-all-valid-paths solution to the dataflow-analysis problem. \nFor instance, in the meet-over-all-valid-paths solution, MVP~, = { g }. (That is, variable g is the only \npossibly-uninitialized variable just before execution reaches the exit node of procedure p.) In Figure \n2, this information can be obtained by determining that there is a realizable path from (s~ai., 0) to \n(eP, g), but not from 4. An Efficient Algorithm for the Realizable-Path Reachability Problem In this \nsection, we present our algorithm for the realizable\u00adpath reachability problem. The algorithm is a dynamic\u00adprogramming \nalgorithm that tabulates certain kinds of same-level realizable paths. As discussed in Section 5 and \nthe Appendix, the algorithm s running time is polynomial in various parameters of the problem, and it \nis asymptoti\u00adcally faster than the best previously known algorithm for the problem. The algorithm, which \nwe call the Tabulation Algorithm, is presented in Figure 3. The algorithm uses the following functions: \n retumSite: maps a call node to its corresponding return-site node;  procO$ maps a node to the name \nof its enclosing pro\u00adcedure;  calledProc: maps a call node to the name of the called procedure;  callers: \nmaps a procedure name to the set of call nodes that represent calls to that procedure.  The Tabulation \nAlgorithm uses a set named PathEdge to record the existence of path edges, which represent a sub\u00adset \nof the same-level realizable paths in graph Gfp. In par\u00adticular, the source of a path edge is always \na node of the form (s , dl ) such that a realizable path exists from node (smin, 6 to (s,, all). In other \nwords, a path edge from (sP, dl ) to (n, d2) represents the suffix of a realizable path from node (smifl, \nO) to (n, d2). The Tabulation Algorithm uses a set named Sum\u00admaryEdge to record the existence summary \nedges, which represent same-level realizable paths that run from nodes of the form (n, d 1), where n \nc Call, to (returnSite (n), d2). In terms of the dataflow problem being solved, summary edges represent \n(partial) information about how the dataflow value after a call depends on the dataflow value before \nthe call. The Tabulation Algorithm is a worklist algorithm that accumulates sets of path edges and summary \nedges. The initial set of path edges represents the O-length same-level realizable path from (sm,n, 0) \nto (s~in, O) (see line [21). On each iteration of the main loop in procedure ForwardTabu\u00adlateSLRPs (lines \n[10] -[39]), the algorithm deduces the existence of additional path edges (and summary edges). The configurations \nthat are used by the Tabulation Algo\u00adrithm to deduce the existence of additional path edges are depicted \nin Figure 4. Once it is known that there is a realizable path from (smin, Q to (Sp, 4, path edge (sp, \nd) + (sP, d) is inserted into WorkList (lines [ 14]-[ 16]). In this case, path edge (sP, d) + (sP, d) \nrepresents the O-length suffix of a realiz\u00ad able path from (Smain,O) to (sp, d). (The idea of inserting \nonly relevant (SP,d) ~ (?P, d) edges into WorkList is simi\u00ad lar to the idea of avoldmg unnecessary function \napplica\u00ad tions during abstract interpretation, known variously as chaotic iteration with needed information \nonly [10] or the minimal function-graph approach [18].) It is important to note the role of lines [26] \n-[28] of Fig\u00ad ure 3, which are executed only when a new summary edge is discovered: declare PathEdge, \nWorkList, SummaryEdge: global edge set algorithm Tabulate(G~P) begin [1] Let (Ne, E#) = G~P [2] PathEdge \n:= ( (~mi., O) + (~wi., 0) } [3] WorkList := { (~mi., O) + (~mi., 0) } [4] SummaryEdge:= 0 [5] ForwardTabulateSLRPso \n[6] for each n EN* do [7] X. := {d2 G D I3d1 (Du { O}) such that (SP,OCOf(n),+ (n, dJG PathEdge dl) \n} [8] od end procedure Propagate(e) begin  [9] if e < PathEdge then Insert e into PathEdge; Insert \ne into WorkList fi end procedure ForwardTabulateSLRPso hetin --=--\u00ad [10] while WorkList # 0 do [11] \nSelect and remove an edge (SP,dl ) + (n, d2) from WorkList [12] switch n [13] case n E Callp : [14] for \neach d3 such that (n, d2) + (s.all.~p,..(.), d3)~ E# do [15] propagate((~c.~k~r.. (.,, ds ) + (~calte~proc(n) \n~ ds )) [16] od [17] for each d3 such that (n, d2) + (returnSite (n), d3) c (Ex u SummaryEdge) do [18] \npropagate((sP, dl ) + (returnSite (n), ds)) [19] od [20] end case [21] casen =e. : [22] for each c E \ncallers (p) do [23] for each d4, d5 such that (c, d4) + (sp, dl ) e E# and (ep, d2) + (returnSite (c), \nd5)e E# do [24] if (c, d4) + (returnSite (c), d5) # SummaryEdge then [25] Insert (c, d4) + (refumSite \n(c), d5) into SummaryEdge [26] for each d3 such that (sP,OCof+ do ~,,, d3) (c, d4) e PathEdge [27] proPagate((~prOcOf(.), \nd3) + (returnSite (c), d5)) [28] od [29] fi [30] od [31] od [32] end case [33] casene (N -Callp {ep}) \n: [34] for each [m, d3) such that (n, d2) + (m, d3) E E# do [35] propagate((sp, dl) + (m, ds)) [36] od \n[37] end case [38] end switch [39] od end Figure 3. The Tabulation Algorithm determines the meet-over-all-valid-paths \nsolution to 1P by determining whether certain same-level realizable paths exist in G~P. [26] for each \ndq such that (sp,..oj(.), d3) + (c, ~4) The final step of the Tabulation Al~orithm (lines [6]-[8]) = \nPathEdge do is to create values X., for each n e N , by gathering up the [271 Propagate((sP,o.of ~.), \nd~) + (returnSite (c), d5)) set of nodes associated with n in GfP that are targets of path [28] od edges \ndiscovered by procedure ForwardTabulateSLRPs: Unlike edges in E#, edges are inserted into SummaryEdge \n[7] Xn:={dzc D 13dl~(Du{ O})suchthat on-the-fly. The purpose of line [27] is to restart the pro-(sP,OCof~n),dl \n) + (n, d2) = PathEdge } cessing that finds same-level realizable paths from As mentioned above, the \nfact that edge ( $proco(c), ~3) edge (sP,OCof(.), dl ) + (n, d2) is in PathEdge implies that there (c, \ndl~ + (retut-nSite~), d5) ~~d been%~%%all along. is a realizable path from (s-i., O) to (n, d2). Consequently, \nby Theorem 3.8, when the Tabulation Algorithm ter\u00adminates, the value of X. is the value for node n in \nthe calledProc(n) Lines [14] -[16]  (+) c P I P Line [25] P Lines [34]-[36] Figure4. Theabove five \ndiagrams show thesituations handled inlines tion Algorithm. meet-over-all-valid-paths solution to 1P, \nTheorem 4.1. (Correctness of the Tabulation Algorithm.) The Tabulation Algorithm always t~rminates, and \nupon ter\u00admination, X~ = MVP., for all n ~ N . 5. The Cost of the Tabulation Algorithm The running time \nof the Tabulation Algorithm varies depending on what class of dataflow-analysis problems it is applied \nto. We have already mentioned the locally separ\u00adable problems; it is also useful to define the class \nof h\u00adsparse problems: Definition 5.1. A problem is h-sparse if all problem instances have the following \nproperty: For each function on an ordinary intraprocedural edge or a call-to-return-site Lines [17]-[19] \n(sp, d,) T ~~(ep(=n), d) 2 P Lines [26] -[28] KEY ordinary E # edge call-to-return-site E#edgeor summary \nedge .........\u00ad call-to-start orexit-to-rehm-site E#edge pati edge u,,,, c,,~ (possibly new) pathedge \n(possibly new) summary edge [14]-[16], [17]-[19], [25], [26] -[28], and[34]-[36] of the Tabula\u00ad edge, \nthe total number of edges in the function s represen\u00adtation relation that emanate from the non-O nodes \nis at most hD. 1 In general, when the nodes of the control-flow graph represent individual statements \nand predicates (rather than basic blocks), and there is no aliasing, we expect most dis\u00adtributive problems \nto be h-sparse (with h < D): each state\u00adment changes only a small portion of the execution state, and \naccesses only a small portion of the state as well. The dataflow functions, which are abstractions of \nthe state\u00adments semantics, should therefore be close to the iden\u00adtity function, and thus their representation \nrelations should have roughly D edges. For many problems of practical interest h S 2 (see [27]). Example. \nWhen the nodes of the control-flow graph represent individual statements and predicates, and there is \nno aliasing, every instance of the possibly-uninitialized\u00ad variables problem is 2-sparse. The only non-identity \ndataflow functions are those associated with assignment statements. The outdegree of every non-O node \nin the representation relation of such a function is at most two: a variable s initialization status \ncan affect itself and at most one other variable, namely the variable assigned to. 0 In analyzing the \nTabulation Algorithm, we assume that all primitive set operations are unit-cost. This can be achieved, \nfor instance, by the representation described in [27, pp. 20]. Table 5.2 summarizes how the Tabulation \nAlgorithm behaves (in terms of worst-case asymptotic running time) for six different classes of problems: \nTable 5.2. Asymptotic running time of the Tabulation Algorithm for six different classes of dataflow-analysis \nproblems. The details of the analysis of the running time of the Tabu\u00adlation Algorithm on distributive \nproblems are given in the Appendix. The bounds for the other five classes of prob\u00adlems follow from simplifications \nof the argument given there. The storage requirements for the Tabulation Algorithm consist of the storage \nfor graph G~p and the three sets WorkList, PathEd e, and Summa Edge, which are 8 Y bounded by O (ED \n), O (ND2), O (ND ) and O (Call D2). 6. Preliminary Experimental Results We have carried out a preliminary \nstudy to determine the feasibility of the Tabulation Algorithm. In the study, we compared the algorithm \ns accuracy and time requirements with those of the safe, but naive, reachability algorithm that considers \nall paths in the exploded supergraph, rather than just the realizable paths. The two algorithms were \nimple\u00admented in C and used with a front end that analyzes a C program and generates the corresponding \nexploded super\u00adgraph for the possibly-uninitialized-variables problem. (The current implementation of \nthe front end does not account for aliases due to pointers.) The study used four example C programs: \nstruct-beauty, the beautification phase of the Unix struct program [3]; twig, a code-generator generator \n[2]; ratjior, a preprocessor that converts a structured Fortran dialect to standard For\u00adtran [19]; and \nC-parser, a lex/yacc-generated parser for C. Tests were carried out on a Sun SPARCstation 10 Model 30 \nwith 32 MB of RAM. The following table gives information about the source code (lines of C, lex, and \nyacc) and the parameters that characterize the size of the control-flow graphs and the exploded supergraph. \nII llLines II CFG statistics G# statistics of Example source P Call N E D N# E# code struct-beauty 897 \n36 214 2188 2860 90 183.9k 220.6k C-parser 1224 48 78 1637 1992 70 104.4k 112.4k ratfor 1345 52 266 2239 \n2991 87 179.5k 217.7k twig 2388 81 221 3692 4439 142 492.2k 561.lk In practice, most of the E# edges \nare of the form (m, d)+ (n, d), and our implementation takes advantage of this to represent these edges \nin a compact way. The following table compares the cost and accuracy of the Tabulation Algorithm and \nthe naive algorithm. The running times are user cpu-time + system cpu-time ; in each case, the time reported \nis the average of ten execu\u00adtions. Tabulation Algorithm Naive Algorithm (realizable paths) (any path) \nTime Reported Time Reported Example (sec.) usesof (sec.) usesof possibly possibly uninitialized uninitialized \nvariables variables struct-beauty 4.83+0.75 543 1.58+0.04 583 C-Darser 0.70+0. 19 11 0.54+0.02 127 ra;for \n3.15+0.58 894 1.46+0.04 998 twig 5.45+1.20 767 5.04+0. 11 775 The number of uses of possibly-uninitialized \nvariables reported by the Tabulation Algorithm ranges from 9% to 99% of those reported by the naive algorithm. \nBecause the possibly-uninitialized-variables problem is 2-sparse, the asymptotic costs of the Tabulation \nAlgorithm and the naive algorithm are O (Call D 3 + ED 2, and O (ED), respectively. In these examples, \nD ranges from 70 to 142; however, the penalty for obtaining the more precise solutions ranges from 1.3 \nto 3.4. Therefore, this preliminary experiment suggests that the extra precision of meet-over-all-valid\u00adpaths \nsolutions to interprocedural datatlow-analysis prob\u00adlems can be obtained by the Tabulation Algorithm \nwith acceptable cost. 7. Related Work Previous Interprocedural Datajlow-Analysis Frameworks The IFDS \nframework is based on earlier interprocedural dataflow-analysis frameworks defined by Sharir and Pnueli \n[31] and Knoop and Steffen [21]. It is basically the Sharir-Pnueli framework with three modifications: \n(i) The dataflow domain is restricted to be a subset domain 2D, where D is a finite se~ (ii) The dataflow \nfunctions are restricted to be distributive functions;  (iii) The edge from a call node to the corresponding \nreturn-site node can have an associated dataflow func\u00adtion. Conditions (i) and (ii) are restrictions \nthat make the IFDS framework less general than the full Sharir-Pnueli frame\u00adwork. Condition (iii), however, \ngeneralizes the Sharir\u00ad Pnueli framework and permits it to cover programming languages in which recursive \nprocedures have local vari\u00adables and parameters (which the Sharir-Pnueli framework does not). (A different \ngeneralization to handle recursive procedures with local variables and parameters was pro\u00adposed by Knoop \nand Steffen [21].) The IFDS problems can be solved by a number of previ\u00adous algorithms, including the \nelimination , iterative , and call-strings algorithms given by Sharir and Pnueli [31] and the algorithm \nof Cousot and Cousot [10]. However, for general IFDS problems both the iterative and call\u00ad strings algorithms \ncan take exponential time in the worst case. Knoop and Steffen give an algorithm similar to Sharir and \nPnueli s elimination algorithm [21]. The efficiencies of the Sharir-Pnueli and Knoop-Steffen elimi\u00adnation \nalgorithms depend, among other things, on the way functions are represented. No representations are discussed \nin [31] and [21]. However, even if representation relations (as defined in Section 3.1) are used, because \nthe Sharir-Pnueli and Knoop-Steffen algorithms manipulate functions as a whole, rather than pointwise, \nfor distributive and h\u00adsparse problems, they are not as efficient as the Tabulation Algorithm. Honey \nand Rosen investigated qualified dataflow analysis problems, where qualifications are a device to specify \nthat only certain paths in the flow graph are to be considered [15]. They employ an expansion phase that \nhas some similarities to our creation of the exploded super\u00adgraph. However, Honey and Rosen do not take \nadvantage of distributivity to do the expansion pointwise, and thus for the IFDS problems they would \ncreate 2D points per flow\u00adgraph node, as opposed to the D points used in our approach. Furthermore, for \ninterprocedural problems the Honey-Rosen approach is equivalent to the (impractical) Sharir-Pnueli call-strings \napproach. Reps investigated the use of deductive databases (i.e., logic programs with a bottom-up evaluation \nengine) to implement locally separable interprocedural dataflow\u00adanalysis problems [29]. This approach \ncan be viewed as a pointwise tabulation method. Although the present paper does not make use of logic-programming \nterminology, the Tabulation Algorithm has a straightforward implementation as a logic program. Thus, \nanother contribution of the present paper is that it shows how to extend the logic\u00adprogramming approach \nfrom the class of locally separable problems to the class of IFDS problems. Datajlow Analysis via Graph \nReachability and Pointwise Computation of Fixed Points Our work shows that a large subclass of the problems \nin the Sharir-Pnueli and Knoop-Steffen frameworks can be posed as graph-reachability problems. Other \nwork on solving dataflow-analysis problems by reducing them to reachabil\u00adity problems has been done by \nKou [23] and Cooper and Kennedy [7,8]. In each case a dataflow-analysis problem is solved by first building \na graph-derived from the program s flow graph and the dataflow functions to be solved and then performing \na reachability analysis on the graph by propagating simple marks. (This contrasts with standard iterative \ntechniques, which propagate sets of values over the flow graph.) Kou s paper addresses only intraprocedural \nproblems. Although he only discusses the live-variable problem, his ideas immediately carry over to all \nthe separable intrapro\u00adcedural problems. Cooper and Kennedy show how certain flow-insensitive interprocedural \ndataflow-analysis problems can be converted to reachability problems. Because they deal only with flow-insensitive \nproblems, the solution method involves ordinary reachability rather than the more difficult question \nof reachability along realizable paths. Zadeck developed intraprocedural dataflow analysis algorithms \nbased on the idea of partitioning a problem into many independent problems (e.g., on a per-bit basis \nin the case of separable problems) [32]. Although our tech\u00adnique of exploding a problem into the exploded \nsuper\u00adgraph transforms locally separable problems into a number of independent per-fact subproblems, \nthe technique does not yield independent subproblems for h-sparse and general distributive IFDS problems. \nFor example, in the 2-sparse possibly-uninitialized variables problem, a given variable may be transitively \naffected by any of the other variables. Nevertheless, these problems can be solved efficiently by the \nTabulation Algorithm. Graph reachability can also be thought of as an imple\u00admentation of the pointwise \ncomputation of fixed points, which has been studied by Cai and Paige [4] and Nielson and Nielson [26,25]. \nTheorem 3.3, the basis on which we convert dataflow-analysis problems to reachability prob\u00adlems, is similar \nto Lemma 14 of Cai and Paige; however, the relation that Cai and Paige define for representing dis\u00adtributive \nfunctions does not have the subsumption property. Although it does not change the asymptotic complexity \nof the Tabulation Algorithm, using relations that have the sub\u00adsumption property decreases the number \nof edges in the exploded supergraph and consequently reduces the running time of the Tabulation Algorithm. \nCai and Paige show that pointwise computation of fixed points can be used to compile programs written \nin a very\u00adhigh-level language (SQ+) into efficient executable code. This suggests that it might be possible \nto express the prob\u00ad lem of finding meet-over-all-valid-paths solptions to IFDS problems as an SQ+ fixed-point \nprogram and then automat\u00ad ically compile it into an implementation that achieves the bounds established \nin this paper (i.e., into the Tabulation Algorithm). Nielson and Nielson investigated bounds on the cost \nof a general fixed-point-finding algorithm by computing the cost as (# of iterations) x (cost per iteration) \n. Their main contribution was to give formulas for bounding the number of iterations based on properties \nof both the functional and the domain in which the fixed-point is computed. Their formula for strict \nand additive functions can be adapted to our context of (non-strict) distributive functions, and used \nto show that the number of iterations of the Tabulation Algorithm is at most ND 2. The cost of a single \niteration can be O (Call D 2 + kD 2), where k is the maximum outde\u00adgree of a node in the control-flow \ngraph. Thus, this approach gives a bound for the total cost of the Tabulation Algorithm of O ((ND2) x \n(Call D2 + kD2)) = O (Call ND4 + kND 4), which compares unfavorably with our bound of 0(ED3). In contrast, \nthe bound that we have presented for the cost of the Tabulation Algorithm is obtained by breaking the \ncost of the algorithm into three contributing aspects and bounding the total cost of the operations performed \nfor each aspect (see the Appendix). Another example of pointwise tabulation is Landi and Ryder s algorithm \nfor interprocedural alias analysis for single-level pointers [24]. The algorithm they give is simi\u00adlar \nto the Tabulation Algorithm. A limitation of the IFDS framework is that information at a return-site \nnode can only be expressed as the meet of the information at the corresponding call node and the appropriate \nexit node. Because in the single-level-pointer problem the combining function for return-site nodes is \nnot meet, the problem does not tit into the IFDS framework. Flow-Sensitive Side-Effect Analysis Callahan \ninvestigated two flow-sensitive side-effect prob\u00adlems: must-modify and may-use [6]. The must-modify problem \nis to identify, for each procedure p, which vari\u00adables must be modified during a call on p; the may-use \nproblem is to identify, for each procedure p, which vari\u00adables may be used before being modified during \na call on p. Callahan s method involves building a program summary graph, which consists of a collection \nof graphs that represent the intraprocedural reaching-definitions informa\u00adtion between start, exit, call, \nand return-site nodes together with interprocedural linkage information. 1 Although the must-modify and \nmay-use problems are not IFDS problems as defined in Definition 2.4, they can be viewed as problems closely \nrelated to the IFDS problems. The basic difference is that IFDS problems summarize what must be true \nat a program point in all calling contexts, while the must-modify and may-use problems summarize the \neffects of a procedure isolated ji-om its calling contexts. That is, Callahan s problems involve valid \npaths from the individual procedures start nodes rather than just the start node of the main procedure. \nThe must-modify problem is actually a same-level-valid-path problem rather than a valid-path problem; \nthe must-modify value for each pro\u00adcedure involves only the same-level valid paths from the procedure \ns start node to its exit node. Consequently, Callahan s problems can be thought of as examples of problems \nin two more general classes of problems: a class of distributive valid-path problems, and a class of \ndistribu\u00adtive same-level valid-path problems. The method utilized in the present paper is to convert \ndistributive valid-path dataflow-analysis problems into realizable-path reachability problems in an exploded \nsuper\u00adgraph. By transformations analogous to the one given in Section 3, (i) the distributive valid-path \nproblems can be posed as realizable-path problems; (ii) the distributive same-level valid-path problems \ncan be  posed as same-level realizable-path problems. In particular, the may-use problem is a locally \nseparable problem in class (i); the must-modify problem is a locally separable problem in class (ii). \nThe payoff from adopting this generalized viewpoint is that, with only slight modifications, the Tabulation \nAlgo\u00adrithm can be used to solve all problems in the above two classes (i.e., distributive and h-sparse \nproblems, as well as the locally separable ones). The modified algorithms have lAlthough the equations \nthat Catlahan gives contain both A and v opera\u00adtors, this is not because his problems are some kind of \nheterogeneous meet/join problems . For example, when Callahan s flow-sensitive Kill problem is reformulated \nin the Sharir-Pnueli framework, A corresponds to meet, but v corresponds to composition of edge functions. \nthe same asymptotic running time as the Tabulation Algo\u00adrithm. In particular, for the locally separable \nproblems such as must-modify and may-use the running time is bounded by O (ED). This is an asymptotic \nimprovement over the algorithms given by Callahan: the worst-case cost for building the program summary \ngraph is O (DZ CallPEP); given the program summary graph, the worst~case cost for computing must-modify \nor may-use is O (DE Cal$). P Demand Algorithms for Inter-procedural Datajlow Analysis The goal of demand \ndataflow analysis is to determine whether a given dataflow fact holds at a given point (while minimizing \nthe amount of auxiliary dataflow information computed for other program points). One of the benefits \nof the IFDS framework is that it permits a simple implementa\u00adtion of a demand algorithm for interprocedural \ndataflow analysis [27,17]. Other work on demand interprocedural dataflow analysis includes [29] and [11 \n]. The IDE Framework Recently, we generalized the IFDS framework to a larger class of problems, called \nthe IDE framework. In the IDE framework, the dataflow facts are maps ( environments ) from some finite \nset of symbols to some (possibly infinite) set of values, and the dataflow functions are distributive \nenvironment transformers [30]. ( IDE stands for Znter\u00adprocedural Distributive Environment problems.) \nThe IDE problems are a proper superset of the IFDS problems in that there are certain IDE problems (including \nvariants of interprocedural constant propagation) that cannot be encoded as IFDS problems. Although the \ntransformation we apply to IDE problems is similar to the one used for IFDS problem, the transformed \nproblem that results is a realizable-path sum\u00admary problem, not a realizable-path reachability problem. \nThat is, in the transformed graph we are no longer con\u00adcerned with a pure reachability problem, but with \nvalues obtained by applying functions along (realizable) paths. (The relationship between transformed \nIFDS problems and transformed IDE problems is similar to the relationship between ordinary graph-reachability \nproblems and general\u00adized problems that compute summaries over paths, such as shortest-path problems, \nclosed-semiring path problems, etc. [1].) The algorithm for solving IDE problems is a dynamic-programming \nalgorithm similar to the Tabulation Algorithm. Appendix: The Running Time of the Tabulation Algo\u00ad rithm \nIn this section, we present a derivation of the bound given in Table 5.2 for the cost of the Tabulation \nAlgorithm on distributive problems. Instead of calculating the worst-case cost-per-iteration of the loop \non lines [10] -[39] of Figure 3 and multiplying by the number of iterations, we break the cost of the \nalgorithm down into three contributing aspects and bound the total cost of the operations performed for \neach aspect. In partic\u00adular, the cost of the Tabulation Algorithm can be broken down into (i) the cost \nof worklist manipulations, Thus, the total cost of all executions of line [24] is bounded (ii) the cost \nof installing summary edges at call sites (lines [21] -[32] of Figure 3), and  (iii) the cost of closure \nsteps (lines [13] -[20] and [33]\u00ad [37] of Figure 3). Because a path edge can be inserted into WorkList \nat most once, the cost of each worklist-manipulation opera\u00adtion can be charged to either a summary-edge-installation \nstep or a closure step; thus, we do not need to provide a separate accounting of worklist-manipulation \ncosts. The Tabulation Algorithm can be understood as k + 1 simultaneous semi-dynamic multi-source reachability \nproblems one per procedure of the program. For each procedure p, the sources which we shall call anchor \nsites are the D + 1 nodes in N# of the form (SP,d). The edges of the multi-source reachability problem \nassociated with p are {(m, dl)+(n, d2)~E# I m,ne Nf andm+n isan intraprocedural edge or a ca l-to-return-site \nedge } U{ (m, dl) + (n, d2) e SummaryEdge ] m = CallP }. In other words, the graph associated with procedure \np is the exploded flow graph of procedure p, augmented with summary edges at the call sites of p. The \nreachability prob\u00adlems are semi-dynamic (insertions only) because in the course of the algorithm, new \nsummary edges are added, but no summary edges (or any other edges) are ever removed. We first turn to \nthe question of computing a bound on the cost of installing summary edges at call sites (lines [2 l]\u00ad \n[32] of Figure 3). To express this bound, it is useful to introduce a quantity B that represents the \nbandwidth for the transmission of dataflow information between pro\u00adcedures: In particular, B is the maximum \nvalue for all cant\u00ado-start edges and exit-to-return-site edges of (i) the max\u00adimum outdegree of a non-O \nnode in a call-to-start edge s representation relation; (ii) the maximum indegree of a non-O node in \nan exit-to-return-site edge s representation relation. (In the worst case, B is D, but it is typically \na small constant, and for many problems it is 1.) For each summary edge (c, d4) + (returnSite (c), d5), \nthe conditional statement on lines [24] -[29] will be exe\u00adcuted some number of times (on different iterations \nof the loop on lines [10] -[39]). In particular, line [24] will be executed every time the Tabulation \nAlgorithm finds a three-edge path of the form [(c, dJ-+(sP, all), (S ,dl)--+(e ,dJ, (eP, d,)+ (returnfite \n(c), d5)r (t) as shown in the diagram marked Line [25] of Figure 4. When we consider the set of all summary \nedges at a given call site c: { (c, d4) -+ (returnSite (c), d5) }, the exe\u00adcutions of line [24] can be \nplaced in three categories: dd#Oandd5#0 There are at most D 2 choices for a (d4, d5) pair, and for each \nsuch pair at most B 2 possible three-edge paths of the form (~), d4=Oandd~#0 There are at most D choices \nfor d5 and for each such choice at most BD possible three-edge paths of the form ( f). db=Oandd5=0 There \nis only one possible three-edge path of the form (7). by O (Call B2D2). Because of the test on line [24], \nthe code on lines [25]\u00ad [28] will be executed exactly once for each possible sum\u00admary edge. In particular, \nfor each summary edge the cost of the loop on lines [26] -[28] is bounded by O(D). Since the total number \nof summary edges is bounded by Call D2, the total cost of lines [25] -[28] is O (Call D 3). Thus, the \ntotal cost of installing summary edges during the Tabula\u00adtion Algorithm is bounded by O (Call B2D 2 + \nCall D 3). To bound the total cost of the closure steps, the essential observation is that there are \nonly a certain number of attempts the Tabulation Algorithm makes to acquire a path edge (s , d ~) + (n, \nd2). The first attempt is successful an~ (s,, d, ) + (n, d2) is inserted into PathEdge; all remaining \nattempts are redundant (but seem unavoidable). In particular, in the case of a node n d Ret, the only \nway the Tabulation Algorithm can obtain a path edge (SP,d 1) + (n, d2) is when there are one or more \ntwo\u00ad edge paths of the form [(s , d,) + (m, d), (m, d) + (n, dg)], where (sP, d~ ~ ~m, d) is in PathEdge \nand {m, d)+ (n, d2) is m E , as depicted below: Consequently, for a given anchor site (SP,d, ), the cost \nof the closure steps involved in acquiring path edge (sP, d, ) --+ (n, d2) can be bounded by indegree \n((n, d2)). For distributive problems, the representation relation of the function on an ordinary intraprocedural \nedge or a call-to\u00adreturn-site edge can contain up to O (D 2, edges. Thus, for each anchor site, the total \ncost of acquiring all its outgoing path edges can be bounded by 0( indegree ((n, d))) = O (EPD 2). E \n(~,~)e ~and n 64Ret The accounting for the case of a node n e Ret is similar. The only way the Tabulation \nAlgorithm can obtain a path edge (sP, dl ) -+ (n, dJ is when there is an edge in PathEdge of the form \n(s , dl ) + (m, d) and either there is an edge {m, d) ~ (n, d2f in E# or an edge (m, d) + (n, d2) in \nSummaryEdge. In our cost accounting, we will pessim\u00adistically assume that each node (n, d2), where n \n Ret, has the maximum possible number of incoming summary edges, namely D. Because there are at most \nCallpD nodes of N# of the form (n, d2), where n E Ret, for each anchor site [s , d 1) the total cost \nof acquiring path edges of the form &#38;P, dl) + (n, d2) is O ( ~ indegree ((n, d2)) + surnnzary-indegree((n, \nd2))) (n,d,)c ~ and n ISRet which equals O (CallpD 2). Therefore we can bound the total cost of the \nclosure steps performed by the Tabulation Algorithm as follows: Cost of closure steps = ~ (# anchor sites) \nx O (CallPD2 + E,D ) = ~(D3~ (Call, + E,)) = O (D3 Call + E)) { = O (ED ). Thus the total runnin time \nof the Tabulation Algorithm is boun~ed by 0(Ca~~B$D2 + ED ] It is possible to  this bound to O (Call \nBD2 + ED3 ) by trea;~~p~~cedure linkages as if they were (B-sparse) procedures in their own right and \nintroducing new linkages to the linkage procedures with bandwidth 1. Because Call < E and B SD, this \nsimplifies to O (ED 3), the bound reported in Table 5.2. References 1. Aho, A.V., Hopcroft, J.E., and \nUIlman, J.D., The Design and Analysis of Computer Algorithms, Addison-Wesley, Reading, MA (1974). 2. \nAho, A. V., Ganapathi, M., and Tjiang, S.W.K., Code generation using tree matching and dynamic programming, \nACM Trans. Pro\u00adgram. Lung. Syst. 11(4) pp. 491-516 (October 1989). 3. Baker, B., An algorithm for structuring \nflowgraphs, J. ACM 24(1) pp. 98-120 (hutuary 1977). 4. Cai, J. and Paige, R., Program derivation by \nfixed point computa\u00adtion: Science of Computer Programming 11 pp. 197-261 (1988/89). 5. Callahan, D., \nCooper, K. D., Kennedy, K., and Torczon, L., lnterpro\u00adcedural constant propagation; Proceedings of the \nSIGPLAN 86 Sym\u00adposium on Compiler Construction, (Palo Alto, CA, June 25-27, 1986), ACM SIGPLAN Notices \n21(7) pp. 152-161 (July 1986). 6. Catlahan, D., The program summary graph and flow-sensitive inter\u00adprocedural \ndata flow anatysis; Proceedings of the ACM SIGPLAN 88 Conference on Programming I.arguage Design and \nImplementation, (Atlanta, GA, June 22-24, 1988), ACM SIGPLAN Notices 23(7) pp. 47-56 (holy 1988).  7, \nCooper, K.D. and Kennedy, K., Interprocedural side-effect anafysis in linear time, Proceedings of the \nACM SIGPLAN 88 Conference on Programming Language Design and Implementation, (Atlanta, GA, June 22-24, \n1988), ACM SIGP.L4N Notices 23(7) pp. 57-66 (July 1988). 8. Cooper, K.D. and Kennedy, K., Fast interprocedural \nafias anatysis, pp. 49-59 in Conference Record of the Sixteenth ACM Symposium on Principles of Programming \n.brguages, (Austin, TX, Jan. 11-13, 1989), ACM, New York, NY (1989).  9. Cousot, P. and Cousot, R., \nAbstract interpretation: A unified lattice model for static analysis of programs by construction or approxima\u00adtion \nof fixpoints; pp. 238-252 in Conference Record of the Fourth ACM Symposium on Principles of Programming \nLanguages, (Los Angeles, CA, January 17-19, 1977), ACM, New York, NY (1977). 10. Cousot, P. and Cousot, \nR., Static determination of dynamic proper\u00adties of recursive procedures, pp. 237-277 in Formal Descriptions \nof Programming Concepts, (IFIP WG 2.2, St. Andrews, Canada, August 1977), ed. E.J. Neuhold,North-Holland, \nNew York, NY (1978). 11. Duesterwald, E., Gupta, R., and Soffa, M.L., Demand-driven com\u00adputation of \nintesprocedurnl data flow, in Conference Record of the Twenty-Second ACM Symposium on Principles of \nProgramming Lunguages, (San Francisco, CA, Jan. 23-25, 1995), ACM, New York, NY (1995). (To appear.) \n 12. Fk.cher, C.N. and LeBlanc, R.J., Crafting a Compiler, Benjarnirr/Cummings Publishing Company, Inc., \nMenlo Park, CA (1988). 13. Glegerich, R., Moncke, U., and Wilhelm, R., Invariance of approxi\u00admative \nsemantics with respect to program transformation, pp. 1-10 in Informatik-Fachberichte 50, Spnnger-Verlag, \nNew York, NY (1981). 14. Grove, D. and Torczon, L., InterProcedural constant propagation: A study of \njump function implementation, pp. 90-99 in Proceedings of  the ACM SIGPLAN 93 Conference on Programming \nLanguage Design and Implementation, (Albuquerque, NM, June 23-25, 1993), ACM, New York, NY (1993). 15. \nHoney, L.H. and Rosen, B.K., Quahfied data flow problems; IEEE Transactions on Software Engineering SE-7(1) \npp. 60-78 (January 1981). 16. Horwitz, S., Reps, T., and Binkley, D., InterProcedural slicing using \ndependence graphs, ACM Trans. Program. Lung. Syst. 12(1) pp. 26-60 (hwy 1990). 17. Horwitz, S., Reps, \nT., and Sagiv, M., Demand interprocedural dataflow anafysis~ Unpublished Report, Computer Sciences Depart\u00adment, \nUniversity of Wk.consin, Madkon, WI (). (In preparation.) 18. Jones, N.D. and Mycroft, A., Data flow \nanalysis of applicative pro\u00adgrams using minimal function graphs, pp. 296-306 in Conference Record of \nthe Thirteenth ACM Symposium on Principles of Program\u00adming Lunguages, (St. Petersburg, FL, Jan. 13-15, \n1986), ACM, New York, NY ( 1986). 19. Kemighan, B.W., Ratfor A preprocessor for a rational Fortmn, \nSoftware -Practice &#38; Experience 5(4) pp. 395-406 (1975). 20. Kildafl, G., A unified approach to \nglobal program optimization, pp. 194-206 in Conference Record of the First ACM Symposium on Prin\u00adciples \nof Programming Languages, ACM, New York, NY (1973). 21. Knoop, J. and Steffen, B., The interprocedural \ncoincidence theorem, pp. 125-140 in Proceedings of the Fourth International Conference on Compiler Construction, \n(Paderbom, FRG, October 5\u00ad7, 1992), Lecture Notes in Computer Science, Vol. 641, ed. U. Kastens and P. \nPfnhler,Spnnger-Verlag, New York, NY (1992). 22. Knoop, J. and Steffen, B., Efficient and optimal bit-vector \ndata flow analyses: A uniform interprocedumt framework, Bericht Nr. 9309, Institut fuer Inforrnatik und \nPraktische Mathematik, Christian\u00adAlbrechts-Universitaet zu Kiel, Klel, Germany (April 1993). 23. Kou, \nL. T., On live-dead anatysis for global data flow problems, Journal of the ACM 24(3) pp. 473-483 (July \n1977). 24. Landi, W. and Ryder, B.G., Pointer-induced atiasing: A problem classification, pp. 93-103 \nin Conference Record of the Eighteenth ACM Symposium on Principles of Programming Languages, (Orlando, \nFL, January 1991 ), ACM, New York, NY (1991). 25. Nielson, F. and Nielson, H.R., Finiteness conditions \nfor fixed point iteration, m Conference Record of the 1992 ACM Symposium on Lisp and Functional Programming, \n(San Francisco, CA, June 22-24 1992), ACM, New York, NY (1992). 26. Nielson, H.R. and Nielson, F., Bounded \nfixed point iteration, pp. 71-82 in Conference Record of the Nineteenth ACM Symposium on Principles of \nProgramming Languages, (Albuquerque, NM, January 1992), ACM, New York, NY (1992). 27. Reps, T., Sagiv, \nM., and Horwitz, S., Interprocedumf dataflow analysis via graph reachability, TR 94-14, Datalogisk Institut, \nUniversity of Copenhagen, Copenhagen, Denmark (April 1994). (Available through World Wide Web at ftp://ftp.diku.dk/dikrdsemantics/papers/D-2 \n15.ps.Z.) 28. Reps, T., Horwitz, S., Sagiv, M., and Resay, G., Speeding up slic\u00ading; SIGSOFT 94: Proceedings \nof the Second ACM SIGSOFT Sym\u00adposium on the Foundations of Software Engineering, (New Orleans, LA, December \n7-9, 1994), ACM SIGSOFT Software Engineering Notes 19(December 1994). (To apperw.) 29. Reps, T., Solving \ndemand versions of interprocedurnl analysis prob\u00adlems, pp. 389-403 in Proceedings of the Fifth International \nConfer\u00adence on Compiler Construction, (Edinburgh, Scotland, April 7-9, 1994), Lecture Notes in Computer \nScience, Vol. 786, ed. P. Fritzson,Sprhrger-Verlag, New York, NY (1994). 30. Sagiv, M., Reps, T., and \nHorwitz, S., Precise interprocedural dataflow analysis with applications to constant propagation: Unpub\u00adlished \nReport, Comp. Sci. Dept., Univ. of Wisconsin, Madison, WI (Oct. 1994). (Submitted for conference publication.) \n 31. Shark, M. and Pnueli, A., Two approaches to interprocedumt data flow anafysisj pp. 189-233 in Program \nFlow Analysis: Theory and Applications, ed. S.S. Muchnick and N.D. Jones,Psentice-Hafl, Englewood Cliffs, \nNJ (1981 ). 32. Zadeck, F.K., Incremental data flow anafysis in a structured program  edhor, Proceedings \nof the SIGPLAN 84 Symposium on Compiler Construction, (Montreal, Can., June 20-22, 1984), ACM SIGPLAN \nNotices 19(6) pp. 132-143 (June 1984). 61 \n\t\t\t", "proc_id": "199448", "abstract": "<p>The paper shows how a large class of interprocedural dataflow-analysis problems can be solved precisely in polynomial time by transforming them into a special kind of graph-reachability problem. The only restrictions are that the set of dataflow facts must be a finite set, and that the dataflow functions must distribute over the confluence operator (either union or intersection). This class of probable problems includes&#8212;but is not limited to&#8212;the classical separable problems (also known as &#8220;gen/kill&#8221; or &#8220;bit-vector&#8221; problems)&#8212;<italic>e.g.</italic>, reaching definitions, available expressions, and live variables. In addition, the class of problems that our techniques handle includes many non-separable problems, including truly-live variables, copy constant propagation, and possibly-uninitialized variables.</p><p>Results are reported from a preliminary experimental study of C programs (for the problem of finding possibly-uninitialized variables).</p>", "authors": [{"name": "Thomas Reps", "author_profile_id": "81100117392", "affiliation": "Computer Sciences Department, Univ. of Wisconsin, 1210 West Dayton Street, Madison, WI", "person_id": "PP40023877", "email_address": "", "orcid_id": ""}, {"name": "Susan Horwitz", "author_profile_id": "81100357689", "affiliation": "Computer Sciences Department, Univ. of Wisconsin, 1210 West Dayton Street, Madison, WI", "person_id": "PP39039239", "email_address": "", "orcid_id": ""}, {"name": "Mooly Sagiv", "author_profile_id": "81100150928", "affiliation": "Computer Sciences Department, Univ. of Wisconsin, 1210 West Dayton Street, Madison, WI and IBM Scientific Center, Haifa, Israel", "person_id": "PP39029858", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/199448.199462", "year": "1995", "article_id": "199462", "conference": "POPL", "title": "Precise interprocedural dataflow analysis via graph reachability", "url": "http://dl.acm.org/citation.cfm?id=199462"}