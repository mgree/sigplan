{"article_publication_date": "01-25-1995", "fulltext": "\n A Formal Model and Specification Language for Procedure Calling Conventions Mark W Bailey Jack W Davidson \nmark@virgi.nia. edu jwd@virginia. edu Department of Computer Science University of Virginia Charlottesville, \nVA 22903, U.S.A. Abstract Procedure calling conventions are used to provide uniform proce\u00ad dure-call \ninterfaces. Applications, such as compilers and debug\u00ad gers, which generate, or process procedures at \nthe machine\u00ad language abstraction level require knowledge of the calling con\u00ad vention. In this paper, \nwe develop a formal model for procedure calling conventions called P-FSA S. Using this model, we are \nable to ensure several completeness and consistency properties of call\u00ad ing conventions. Currently, applications \nthat manipulate proce\u00ad dures implement conventions in an ad-hoc manner. The resulting code is complicated \nwith details, diftlcult to maintain, and often riddled with errors. To alleviate the situation, we introduce \na call\u00ad ing convention specification language, called CCL. The combina\u00ad tion of CCL and P-FSA S facilitates \nthe accurate specification of conventions that can be shown to be both consistent and complete. 1 Introduction \nProcedures, or functions, in programming languages work in con\u00ad cert to implement the intended function \nof programs. To facilitate this cooperation between procedures, we must accurately specify the procedure-call \ninterface. This interface must define how to pass actual parameters and describe function return values, \nand which machine resources, such as registers, the called procedure must preserve. This understanding \nbetween the calle~ and callee3 is known as the procedure calling convention. Because of the machine-specific \nnature of the calling convention, calling conven\u00ad tions vary widely from machine-to-machine, programming-lan\u00ad \nguage-to-programming-language, and, language-implementation\u00ad to-language-implementation. 1.1 Why a Calling \nConvention Specification? Currently, information about a particular calling convention can be found by: \nlooking in the programmer s reference manual for the given machine, or reverse-engineering the code generated \nby the compiler. Reverse-engineering the compiler has many obvious shortcomings. Using the programmer \ns reference manual may be 1. TMs work was supported in part by National Science Foundation grant CCR-9214904. \n 2. The calfing procedure is known as the caller 3. The called procedure is known as the callee.  Permission \nto copy without fee all or part of this material is grantsd provided that the copias are not made or \ndistributed for direct commercial advantage, the ACM copyright notice and the title of the publication \nand its date appear, and notice is given that copying is by permission of the Association of Computing \nMachinery. To copy otherwise, or to republish, requires a fee andhx specific permission. POPL 95 1/95 \nSan Francisco CA USA @ 1995 ACM 0-89791-892-119510001 ....$3.50 equally problematical. As with much of \nthe information in the pro\u00adgrammer s manual, the description is likely to be written in English and is \nliable to be ambiguous, or inaccurate. For example, in the MIPS programmer s manual [KANE92] the English \ndescrip\u00adtion is so difiicult to understand that the authors provide fifteen examples, several of which \nare contradictory [i?ms93]-and this is the second edition. Furthermore, the convention, once understood, \nis difficult to implement. For example, the GNU ANSI C compiler fails on an example listed in the manual. \nDigital, in recognizing the problem, has published a calling standard document for their new Alpha series \nprocessors [DEC93] that exceeds 100 pages4. Thus, it should be clear that there is a need for an accurate, \nconcise descrip\u00adtion of procedure calling conventions. 1.2 Applications Any application that must process \nor generate procedures at the machine-language abstraction level is likely to need to know about a procedure \ncalling convention. Examples of such uses include compilers, debuggers, evaluation tools such as profilers, \nand docu\u00admentation. The code that implements the calling convention in these applications lends itself \nto automatic generation, In many cases, the convention itself is not difficult to understand, or imple\u00adment \nfor a given instance of a procedure. However, the implemen\u00adtation of the general case is complicated \nwith details that are difilcult to implement correctly for all cases. Compilers, perhaps would benefit \nmost from specification of the calling convention. The calling convention is exhibited in the calling \nsequence the compiler uses when generating code. A call\u00ading sequenceis a sequence of instructions that \nimplements the tail\u00ading convention. Thus, a calling sequence is an instantiation of the more general \ncalling convention, Frequently, a compiler will use a calling convention that differs from the one used \nby the native compiler for the machine. In such cases, it is desirable to be able to call procedures \nthat were generated using the native compiler. Sys\u00adtem library functions, which would be compiled using \nthe native compiler, are such an example. It therefore would be convenient for a compiler to cope with \nmore than one calling convention. In many compilers, the portion of code that implements the calling \nconvention is lengthy, detailed, and therefore difficult to modify or parametrize by the calling convention, \nThe existence of a method for accurately specifying calling conventions also makes it possible to experiment \nwith different conventions. Johnson and Richie have identified the issues in pro\u00ad 4. Afthough this document \nafso includes information on exception handling and information pertinent to muhktmaded execution environments, \nmore than 42 pages are devoted to documenting the calling convention. vialinganeftlcient calling sequenceafteronehasalreadydefineda \ncalling convention [JOHNSON]. However, the convention makes many choices that directly affect the etllciency \nof calling proce\u00addures. We therefore feel that it is important to experiment with dif\u00adferent conventions \non each to tune the convention to the machine. Davidson and Whalley have performed a limited experiment \nin investigating different calling conventions [DAv191 ]. However, due to the enormous amount of work \nrequired to change their com\u00adpiler from one calling convention to another, their experiment was limited \nto several different methods of saving and restoring regis\u00adters. 1.3 Contributions This paper makes several \ncontributions, It provides a formal model for procedure calling conventions that can be used in a variety \nof system software. The paper presents a specification language that, when used in conjunction with the \nformalism, can provide accurate convention information to an application. Further, it shows that by modeling \na convention in this reamer, several desirable properties about calling conventions can be established. \nIt also shows how conventions that are not complete, or are inconsistent can be auto\u00admatically identified. \nFinally, the paper shows how this formalism can be used by an optimizing compiler to automatically generate \nprocedure calling sequences. 2 The Lenguage Concepts This section describes the underlying model for \nthe convention descriptions. Many features of the description language have their foundation in the underlying \nmodel. 2.1 Convention vs. Sequence When one first tries to model the procedure call interface, one would \nlikely consider as we did simply modeling the calling sequence. This is natural since compiler writers \nare most familiar with calling sequences, Traditionally, the terms calling sequence and calling convention \nhave been used interchangeably in the liter\u00adature to refer to the calling sequence. However, after some \nthought, the subtle differences between the convention and the sequence become apparent. The calling \nconvention defines how two procedures, on either side of a procedure call interface, interact. It is \nan agreement between the caller and the callee about where information is found and how to manage machine \nresources. Choosing which registers retain their values across a procedure call, or the order and location \nof procedure arguments, or where the return address is found, are all decisions that one makes when defining \na procedure calling convention. One can think of the calling convention as a definition of what is done \nby whom. The calling sequence, on the other hand, is an implementation of the calling convention. There \nmay be many calling sequences for given calling convention. In particular, since the calling sequence \nimplements the calling convention, it is impossible for the caller to determine if the callee is using \nthe same sequence, and vice versa. Thus, while it is imperative that a caller and a callee use the same \ncalling convention, it is not necessary that they use the same calling sequence. 2.2 Interfaces and \nAgents So far, we have referred to the procedure call interface. In fact, there are two interfaces: the \nprocedure call interface and the proce\u00addure return interface, On each side of these interfaces, there \nis an agent, An agent ensures that thatside of the interface satisfies the requirements of the calling \nconvention. These agents are the whom in the definition of the calling convention. For the procedure \ncall interface, there are the caller prologue and callee prologue agents that are responsible for correctly \npassing the procedure arguments and constructing an environment that the callee can execute in. For the \nprocedure retom interface, there are the callee epilogue and caller epilogue that are responsible for \ncorrectly passing the proce\u00addure return values and restoring the environment of the caller. The responsibilities \nof each of the four agents are closely related. The caller prologue and callee prologue agents must agree \non how to pass information, as do the caller epilogue and cake epilogue. Additionally, actions of the \nepilogue agents must be symmetric to the actions of the prologue agents to properly restore the environ\u00adment \n(e.g., if the call decrements the stack pointer, the return must increment it). It is precisely these \nrestrictions that make it difficult correctly construct a calling sequence. Caller Procedurecall Interface \nA Callee 3 Pmwdure Return Intetface J Q Figure 1: The Role of Agents in Procedure Call and Retom Interfaces. \n2.3 Defining the Interface The procedure call interfaces are defined in terms of two concepts: data \nplacement and view change. These abstractions are all that one needs to accurately specify procedure \ncalling conventions, 2.3.1 Data Placement Data placement specifies where information should be placed/ \n found as well as who is to place it there. This mechanism is used primarily for defining where information \nis to be placed to pass across an interface (procedure arguments and return values) and where to save \ninformation to restore later (contents of registers). In the former, this is an agreement between two \nagents on opposite sides of an interface. For the latter, this is an agreement between agents in the \ncaller or agents in the callee, Abstractly, data placement definitions are functions that map values \nonto machine resources. The functions take a value and cor\u00adresponding attributes (such as data type) \nand decide where the value belongs. More precisely, placement definitions are finite state machines, \nsince the mapping is order-dependent. Figure 2 illustrates an application of a placement definition to \nplace proce\u00addure arguments. In this example, floating-point values are placed in evenlodd register pairs, \nstructures are placed on the stack, and integers are placed in the next available register. When argument \nregisters are exhausted, the stack is used. The placement is compli\u00adcated by restrictions. An example \nrestriction is registers are that are passed over (i.e., an odd numbered register when placing a floating-point \nvalue) cannot be subsequently used. Such restric\u00ad tions are common in real calling conventions, and must \ntherefore be captured in the data placement definition.  1. Registers al, a2, a3, and a4 are 32-bit \nargument-trrmsmit- T Argument 2 (Float) Argument 3 (Structure) Argument 4 (Int) Figure2: Mapping from \narguments to machine resources. 2.3.2 View Change View change indicates something has happened that \ncaused loca\u00adtions to appear to move. The register window mechanism on the SPARC microprocessor is an \nexample. When the register window slides, the contents of the registers appear to move because the names \nof the registers have changed. We wish to indicate this change without causing the move to actually occur. \nThe change of view indicates how the names of locations have changed. View change is used more commonly \nwhen describing that a frame must be pushed on the stack. When a push occurs, all locations refer\u00adenced \nby the stack pointer appear to shift. 3 The Language In this section, we present CCL (Calling Convention \nLanguage), the language that we use to capture the concepts described in the previous section. 3.1 A \nSimple Calling Convention The calling convention is the set of rules to which the caller and callee must \nconform. Figure 3 contains the calling convention rules for a hypothetical machine. Consider the following \nANSI C prototype for a function f 00: int foo (char PI, int P2, int P3, double P4) ; For the purpose \nof transmitting procedure arguments for our sim\u00adple convention, we are only interested in the signature \nof the pro\u00adcedure, We define a procedure s signature to be the procedure s name, the order and types \nof its arguments, and its return type. This is analogous to ANSI C s abstract declaratory, which for \nthe above function prototype would be: int foo (char, i.nt, int, double) ; which defines a function that \ntakes four arguments (a char, two int s, and a double), and returns an int. With f oo s signature, we \ncan apply the calling convention in Figure 3 to determine how to call placed in the following locations: \no PI in register al p2 in register a2 p3 in register a3  p4 on the stack in M[sp:sp  f oo. f oo s \narguments would be + 7] (M denotes memory) ting registers. 2. Arguments may be passed on the stack in \nincreasing mem\u00adory locations starting at the stack pointer (M[sp]). 3. An argument may have type char \n(1 byte), int (4 bytes), or double (8 bytes). 4. An argument is passed in registers (if enough are available \nto hold the entire argument), and then on the stack. 5. Arguments of type int are 4-byte aligned on \nthe stack. 6. Arguments of type double are 8-byte aligned on the stack. 7. Stack elements that are \nskipped over cannot be allocated later. 8. Return values are passed in 9. Values of registers a6, \na7,    TEEH--SP+32 across a procedure call. Figure 3: Rules for a simple re sters al and a2. P9 a \n, and a must be preserved calling convention. Notice that although register a4 is available, p4 is placed \non the stack since it cannot be placed completely in the remaining register (rule 4). Such restrictions \nare common in actual crdling conven\u00adtions. Now that we have seen how arguments are transmitted for a \nsimple example, we can describe the objects in our model. The pri\u00admary objects of interest are machine \nresources. A machine resource is simply any location that can store a value. Examples include registers \nand memory locations, such as the stack. Detln\u00ading where required values are located is accomplished \nby specify\u00ading a mapping from one resource to another. We call such a mapping a placement. Although a \nprocedure s arguments and its return vahre are technically not machine resources by the above definition, \nwe consider them as speeial resources in our model. We partition a machine s resources into two categories: \nfinite and infinite. Resources such as register sets that can easily be enu\u00admerated are considered finite. \nResources that are conceptually unbounded such as the stack are considered infinite. Although the stack \nis finite for any particular implementation of a machine, we model it as infinite since the programmer \nconsiders it, for all intents and purposes, to be infinite. This distinction is important since we must \ntreat infinite resources in a special way. 3.2 Typographical Extensions Figure 4 contains the complete \nCCL calling convention. The first thing to tions is prevalent use of typographical standard ASCII character \nset used in specification for the simple notice about CCL descrip\u00adextensions. We extend the most machine-readable \nlan\u00ad guages to include multiple fonts, super/subscript s, and variations in font angle (italic) and \nweight (bold). This approach helps accomplish two of our goals in the language desigrr conciseness and \nnaturalness. Since information can be encoded in the fonts, we can reduce the size of the descriptions. \nSecond, in contrast to sim\u00adple ASCII text, it provides a more natural way to describe many data types \nused in CCL. The following is a list sions used in CCL: Sets: (2:9 ) = {2,3,4,5,6,7,8,9}  Ordered sets: \n<2,8,3,9,4,10>, <0:-> Labeled sets: {chac 1, sho~ 2, longword: ble: 8} e M[14] = M 14 d$l[r14:r14+3 \n1]>= Arrays: , Operators: mod. >,, A, c, ~ . Keywords: external, alias, call prologue, set . Comments: \nThis is a comment of many expres\u00ad 4, float: 4, dou\u00ad<M[r14(32)]> resources, map, 1 external NVSIZE, SPILL \nSIZE, LOCALS_SIZE 2 non-volatile { ab, a7, a8, ag] 3 alias sp = as 4 caller prologue 5 view change 6 \nV offset e {-w:-]  7 M[sp + ojfset] becomes M[sp + offset + ARG_SIZE] 8 end view change 9 data transfer \n(asymmetric) 10 ~: :;$:::Y:< 11 12 resources {argregs,CM mindex>) 13 internal ARG_SIZE + ~(<M[addr] \nsize \\ addr G mindex A M[addr].assignerb) 14 classregs +-<-aegisteo I register E argregs> 15 class imem \n+ <<M[uddr]> 1addr G mindex A addr ~ 4 = O> 16 class dmem + <<M[addr > addr G mindex A addr ~ 8 = 0> \n l:A&#38;)TA~ 17 V argument E <ARG 18 map argument + argurnent.type,1 { 19 than <regs, MmlDdex>, 20 \nint: <regs, ime~, 21 double: <regs, dmerm, 22 ) 23 end data transfer 24 end caller prologue 25 callee \nprologue 26 view change 27 V oflset e (-CO:CO} 28 M[sp + ofiset] becomes M[sp + offset + SPILL_SIZE + \nLOCALS_SIZE + NVSIZE] 29 end view change 30 end callee prologue 31 callee epilogue 32 data transfer (asymmetric) \n33 resources {al:z ) 34 map RVAL1 + <<<al>>> 35 end data transfer 36 end callee epilogue 37 caller epilogue \n38 end caller epilogue Figure 4A Complete Simple Example, An advantage of using typographical extensions \nis that a sim-3.3 Outer Environment ple, concise convention indicates the portions of descriptions that \nCCL is a part of a larger description system we are developing at are literals, meta-symbols, and predefine \nelements. Comments the University of Virginia. CCL is part of the compiler-specific are clearly offset \nfrom the remaining description because they are description. Although CCL is used to capture all information \nabout both italic and set in a different font. Sets are used heavily in the a calling convention, a CCL \ndescription does not contain all neces\u00adlanguage and adhere to their natural syntax in mathematics. Key-sary \ninformation to produce a calling sequence. Indeed, CCL words are in bold making them easy to identify. \ndescriptions are not complete by themselves. CCL descriptions There are two minor disadvantages of typographical \nexten-require information from the outer environment to complete the sions. One is that descriptions \ncamot be edited with existing text descriptions. Information about the machine and language, such as \neditors (e.g., emacs, vi, etc.), rather it requires the use of tools such the size of registers, the \nbase data types and local procedure infor\u00adas a specialized editor and postscript viewer. However, such \ntools mation, such as the amount of space needed for tempormy vari\u00adare widely available as are postscript \nprinters for printing descrip-ables, and which registers are used, must be provided by the outer tions, \nIndmd, such a tool was used to develop the CCL descrip-environment, Four variables that are always defined \nby the outer tions in this paper. A second disadvantage is the tools that process environment are the \nspecial resources ARG, RVAL, and the corre-CCL are slightly more complicated as they must deal with an \ninter-sponding special resource sizes ARG.TOTAL and mediate representation that has typographical information \nRVAL_TOTAL. Since these values are always defined, they are included. Our initial experiments show that \nthis is not be a major implicitly declared as external values. All other variables whose obstacle. Consequently, \nthe benefits of this approach far outweigh values are provided by the outer environment are declared \nusing the minor disadvantages. the external statement. A CCL description is typically language dependent \nas well, This is, in part, because the language definition influences the call\u00ading convention. For example, \nthe C language [KMW8] defines a slightly different calling convention than its successor ANSI C [KERN88]. \nOne difference is that C always promotes arguments of type float to type double, while ANSI C does not, \nThese differ\u00adences are part of the calling convention, and are, therefore, present in the resulting CCL \ndescriptions. Although ANSI C is now the standard, all of the examples in this paper assume the traditional \nC language calling convention since it presents more interesting examples. 3.4 Placement of Procedure \nArguments First, we examine the placement of procedure arguments. We use the simple calling convention \nspecification shown in Figure 4. For placement of arguments, we focus on the data transfer statement \nwithin the caller prologue section of the description (lines 9-23). We use the alias statement to introduce \nthe name argregs as a name for the parameter passing registers and mindex as a set of stack addresses \n(a5 is the stack pointer). Line 12 defines the set of possible destinations for data placement, which \nwe call the resources. Lines 14-16 specify classes that each defines a subset of these resources where \nplacements may start. Since the convention has two different alignment restrictions for memory, which \nare based on argument type, there is a corresponding class for each restriction as well as a class for \nthe argument registers. The lan\u00adguage requires classes to be ordered sets of ordered sets. Classes simply \npartition the resources into sets of valid locations to place values. The outer set indicates the order \nin which to consider plac\u00ading the arguments. In this example, when passing arguments in memory, we consider \nmemory locations in low-to-high address order. The inner set typically contains a single element (the \nstarting location). More complicated conventions make more use of the inner set as we will see later. \nThe remaining lines (17-22) of the data transfer contain the argument placement description. The universal \nquantifier (V) operator iterates over the set, each time binding the variable argu\u00adment to an element \nof the set. Here, the set is ordered, ensuring that argument will take values in the set in order. The \nresource ARG is a special resource that is provided by the outer environment. It containsinformation \nsuchasthetypeandsizeoftheargumentsfor the call. The two operators on line 18 complete the placement descrip\u00adtion, \nThe placement operator (+) is invoked for each value argu\u00adment is assigned. The placement operator takes \na value (here an argument) and a list of classes. The classes are searched, in order, for an available \nresource to place the given value. When a resource is found, the location is marked as used, by setting \nthe assigned attribute, to ensure unique locations for each placed value, The selection operator (1) \nis used on labeled sets. This is simply a case expression. Based on the value of argument s type attribute, \none expression from the labeled set is selected. 3.4.1 Placement of Procedure Return Values Specifying \nthe locations of procedure return values is similar to procedure arguments. To determine the return value \nplacement, we examine the data transfer statement within the callee epilogue section for Figure 4. Here, \nwe see RVAL, the other special resource defined by the outer environment, which refers to the list of \nreturn values (in most languages, there is only one). The resources used for returning values are the \nregisters al and a2. These registers are used for returning values of all types. Recall that the registers \nhave size 4 bytes, integers are 4-byte quantities and doubles are 8-byte quantities. So, this s ecitication \nindicates only al will be used for chars and ints, but a72and a will be used for double values. This \nlevel of conciseness is achieved by indicat\u00ading only the starting location rather than indicating the \nsize, which can be attained from the type. 3.4.2 Non-Volatile Registers Non-volatile registers are registers \nthat contain values that the caller expects to be preserved during a procedure call. This expec\u00adtation \nis part of the calling convention. If the callee wishes to use a non-volatile register, the register \ns value must be preserved by the callee, and restored to its original value prior to returning to the \ncaller. Registers whose values are non-volatile are listed in line 2 of Figure 4. ho important details \nabout non-volatile registers are missing from this specification. These are where the registers values \nare saved, and how they saved. The former is defined by the frame lay\u00ad out, while the latter is defined \nby the calling sequence. Although these details are important for the callee s implementation, they are \nof no concern of the caller. Since they are of no concern of the caller, they are not part of the calling \nconvention. Thus, while we could easily include this information in our CCL descriptions, we have chosen \nnot to include it to avoid unnecessary restrictions in our calling convention specifications. 3.4.3 Putting \nit All Together So far, we have examined the specification of each aspect of our simple convention in \nisolation. We now broaden our view to the entire description shown in Figure 4. A description is divided \ninto five sections: one section for each agent in our model, and a global declaration section. We place \ndata transfer and view change statements within agent sections. Finally, we place the two data placement \nschemes discussed above in their corresponding loca\u00adtions in the description. First, let s examine the \ncaller prologue section. This section specifies the responsibilities of the caller prologue agent. Most \ndata transfer statements have been described previously. Line 13, however, has not. It computes the amount \nof space that was assigned by the placement operator. Although this computation has been placed before \nthe placement operation, its value will not actu\u00adally be computed until after, since the computation \nis dependent on the results of the placement. The result of this computation is then used in the above \nview change statement. 1 The view change indi\u00adcates that the value in location M[sp] will now be found \nin location M[sp + ARG_SIZE]. Such a change of view corresponds to a dec\u00adrement of the stack pointer \n(a push) of precisely the amount needed to pass the arguments. Although the location of the procedure \narguments must be known for both the caller prologue and the callee prologue, the placement description \nonly resides in the caller prologue section. This is because the callee prologue can determine the locations \nof the arguments by applying the appropriate view change to the description located in the caller prologue \nsection. Hence, describ\u00ading the change of view makes it unnecessary to restate where the procedure arguments \nare located when the view changes. A final note about this description. The two data transfer statements \n(for passing arguments and return values) are tagged with the keyword (asymmetric). This indicates that \nthe transfer is done by the agent, but not undone (values transferred back) by the symmetric agent (callee \nepilogue for callee prologue, caller epi\u00adlogue for caller prologue). However, for all of the view changes, \nthe lack of the (rssymmetric) keyword indicates that a symmetric action takes place in the symmetric \nagent. For example, in this specification, the caller epilogue is empty. However, the caller epi\u00adlogue \nperforms the symmetric view change shown in the callee 1. There is no set ordering for view change and \ndata tranafer statements. However, since the view change occurs before the data transfer, afl refer\u00adences \nto resource M are in terms of the new view. Had the view change been after the data transfer, this would \nnot be the case. qo= . 0000 c OQo --Q dd Figure 5: P-FSA for transmission of parameters prologue and \nhas access to the procedure return value data trans\u00adfer statement in the callee epilogue. Without this \nconcept of sym\u00admetry, the description in Figure 4 would be considerably more involved. Our simple calling \nconvention illustrates how many common features in calling conventions are described. However, real-world \nexamples tend to have additional constraints that complicate the descriptions, Appendix A contains a \ncomplete specification for the MIPS R3000 calling convention and a brief English description, 4 The Formal \nModel This section presents the formal model that we use as a foundation for implementing procedure calling \nconventions. 4.1 P-FSA Representation We use finite state automata to model each placement in the calling \nconvention. One such FSA is shown in Figure 5. This FSA models the placement of procedure arguments for \nthe simple calling con\u00advention. The placement FSA (P-FSA) takes a procedure s signa\u00adture as input and \nproduces locations for the procedure s arguments as output. The automaton works by moving from state \nto state as the location of each argument is determined. During transition, information about the current \nparameter is read from the input, and the resulting placement is written to the output. The states of \nthe machine represent that state of allocation for the machine resources. For example, the state labeled \nq2 represents the fact that register al and a2 have been allocated, but that a3, a4 and stack locations \nhave not been allocated. The transitions between states represent the placement of a single argument. \nSince arguments of different types and sizes impose different demands on the machine s resources, we \nmay find more than one transition leaving a particular state. In our example, qs has three transitions \nc for a simple calling convention. even though two of them (i.nt and double) have the same target state \n(q4). This duplication is required since the output from map\u00adping an int is different from the output \nfrom mapping a double. Modeling the allocation of an infinite resource, such as the stack, using an \nFSA poses a problem, however. As stated above, the state indicates which resources have been allocated. \nFor finite resources, this is easily accomplished by maintaining a bit vector. When a resource no longer \nmaybe used, the associated bit is set to indicate this. For an infinite resource this scheme cannot work \nif we hope to use an FSA, since this would require a bit vector of infinite length. To simplify the problem, \nwe impose a restriction on infinite resources: their allocation must be contiguous. Thus, for an infinite \nresource I= {il, iz, ... ), we can store the allocation state by maintaining an index p whose value corresponds \nto the index of the first available resource in I. Because the allocation of Z must be contiguous, p \npartitions the resources, since a resource ~ is unavailable ifj < p or available ifj 2 p. For instance, \nif the stack is the infinite resource, p can be considered the stack pointer. Nevertheless, we still \nhave a problem. Although for a particu\u00adlar machine, the value of p must be finite, the resulting FSA \ncould have as many as 232 stack allocation states for a 32-bit machine, However, we can significantly \nreduce this number by observing that the decision of where to place a parameter in memory is not based \non p, but rather on alignment restrictions. For our example, we care only if the next available memory \nlocation is one-, four-, or eight-byte aligned. Consequently, we can capture the allocation state of \nthe machine with three bits that distinguish the memory allocation states. We call these the distinguishing \nbits for infinite resource allocation. Handling passing structures by value creates a complimentary \nproblem. Since only the alignment state of the stack is of inter\u00adest, structures that affect the state \nof the P-FSA dhlerently must use different transitions. So for a convention that requires stmc\u00ad L 90 \nql 92 !73 94 char a a a a 000 int a a a a memla ala a a a3a4 double memjc memj Table I: Definition of \nk for example P-FSA. a. mem~ = 000001010011 b.rrremz= 100101110111 c. mems= 000001010011 100101110111 \n  tures to be passed in 8-byte aligned memory locations, all strttc\u00adtures of size n where n mod 8=1 \nshare the same transition out of a given state. Therefore, number of transitions leaving a state is lim\u00adited \nby the alignment restrictions of the machine. 4.2 P-FSA Definition To generalize our approach, we have \nthe set of finite machine resources R = {r-l,r2, .... m}, infinite resource I = {iI, i~, ..,}1, and selection \ncriteria C = {cl, C2, .... cm]. The selection criteria corre\u00adspond to characteristics about arguments \n(such as their type and size) that the calling convention uses to select the appropriate placement for \nan argumfnt. We encode the signature of a proce\u00addure with a string w e C . Each state q in the automaton \nis labeled according to the allocation state that it represents. The label includes a bit vector v of \nsize n that encodes the allocation of each of the finite resources in R. Additionally, to express the \nstate of allocation for an infinite resource, we included, the distinguishing bits of index p. So, a \nstate label is a string vd that indicates the resource allocation state. In our example, n = 4, and Ildll \n= 3. So, each state is labeled by a string from the language {O, 1 4{0, 1}3. i The output of M is a \nstrings P,where P=Ru {O,1] 1, which contains the placement information. So, from our example in Figure \n5, state qs is labeled 1111100 to indicate that each of the argument registers has been used, and that \nthe first available stack location is four-byte aIigned. From the above discussion, we have the following \nvalues that are pertinent to defining a finite state machine: a set of finite resources R = {rl, r2, \n.... r-n}.  an infinite resource I = {il, i2, ...}.  d, the distinguishing bits of p, selection criteria \nC = {cl, c2, .... cm}. bitvectorv= {bl, bz, . . . bn], where bi is set if resource ri is used.  the \nset of placement strings P = R u {O, 1}Ildl. We now formalize our definition of a P-FSA for modeling \nplacement. Since the P-FSA produces output on transitions, we have a Mealy machine [MEAL55]. We define \nthe P-FSA as a six\u00adtntie2 M = (Q, 2, A, S, k, oJ, where: . Q is t~e set of stat~~ with labels {O, 1]n{O, \n1]Ildl represent\u00ad ing the allocation state of machine resources, . the input alphabet Z = C, is the set \nof selection criteria, . the output alphabet A = P, is the set of placement strings, . the transition \nfunction &#38;Q x X + Q, . the output function k:Q x Z + A+, 1. This can easily be extended to model \nmore than one infinite resource. 2. In this paper, we use the notation of Hopcroft and Ulhnan for finite \nstate automata and regular expressions [HoPc79]. We use letters early in the alphabet (a, b, c) to denote \nsingle symbols. Letters late in the atphabet (w,  x, Y,z) will denote strings of symbols. q5 96 q7 98 \nq9 910 qll 001 010 011 100 101 110 111 mem~b mem~ mem2 mem2 meml meml meml memj memj memj mems memj mem3 \nmemj q. is the state labeled by Onw where Ilwll = Ildll is the initial state of d. Wealsodefine 8:Qx \nZ*+ Qand~:Q xZ + A*which arejust string versions (defined by Hopcroft and Unman [HoPc79]) of 5 and l., \nrespectively. So, for our example, we have M = (Q, {char, int, double}, {al, a2, a3, a4}u{0, 1 }3, 8, \n~, qo), where Q and 8 are pictured in Figure 5 and L is defined in Table I. Note that we have modified \nthe traditional definition of L to allow multiple sym\u00adbols to be output on a single transition. This \nreflects the fact that arguments can be located in more than one resource. For example, in state q~ on \nan int, Table I indicates that M produces the string of four symbols 100101 110111 that indicates four \nbytes that are four-byte aligned, but are not eight-byte aligned. The signature: int phred (double, double, \nchar, int ) ; will take the P-FSA in Figure 5 from state q. to qd producing the string (al a2) (a3 a4) \n(000) (100 101 110 111) along the way. The parentheses in the output string are required to determine \nwhere the placement of one argument ends and the next argument s place\u00adment begins. Although these are \nnecessary, we have omitted them from our automaton definition to simplify its presentation. From the \nstring, we can derive the placement of the phred s arguments. The first double is placed in registers \nal and a , the second in registers a3 and a4, the char at the first stack location and the int starting \nin the fifth stack location. The padding on the stack between the char and the int is indicated by the \nomission of locations 001,010 and 011 that correspond to the pad locations. 4.3 Automatic P-FSA Construction \nIn this section, we present an algorithm for automatically con\u00adstructing automata to model placement \ncomputations. For the moment, we assume the existence of a function j!Z* --+ A*. ~com\u00adputes the same \nvalue as M. Since~and M are equivalent, why con\u00adstruct M at all? The answer is that f may have undesirable \nproperties. For instance, M may be used in a context, such as a compiler, where performance is an issue. \nIf ~is implemented as an interpreter, the time it takes to compute a placement may not sat\u00adisfy the performance \nconstraints. Additionally, by using a P-FSA, there are several properties (such as an upper bound on \nM s execu\u00adtion time) we can prove about the P-FSA that we cannot prove about$ We present such properties \nin Section 5, We construct the P-FSA by performing a depth-first-traversal of the states in Q to determine \nthe set of reachable states from q. At each state q, the states that are reachable from q in one step \nare determined by using each element of {WC I c e C] as input to ~ Each newly reachable state q is added \nto Q and is subsequently visited by BuILD-P-FSA (The algorithms are included in Appendix A). Finally, \nthe appropriate additions to 5 and L are made for q . BuILD-P-FSA also uses an auxiliary function STATE-LABEL:P \n+ Q. STATE-LABEL takes an output string from M and computes the label for the state that M was in when \nthe input was exhausted. Our construction is now complete, except the definition of the function J We \nsupply f s definition using an interpreter. We have designed and implemented a language for specifying \nprocedure calling conventions, The language has an interpreter that takes as input a calling convention \nspecification, information about a pro\u00adcedure s signature and some additional information about the tar\u00adget \nmachine, and produces the necessary mapping information to properly call the given procedure. Thus, this \ninterpreter can be used to implement ~ in our algorithm above, In Section 6, we present the interpreter \ns use in an implementation. 5 Completeness snd Consistency in P-FSA S In this section, we consider a \nnumber of different properties of pro\u00adcedure calling conventions. But first we identify several imple\u00ad \nmentation difficulties that one might encounter when dealing with a calling convention. 5.1 Common Difficulties \nApplications, such as compilers and debuggers, which generate, or process procedures at the machine-language \nlevel require knowl\u00adedge of the calling convention. Until now, the portion of such an application s implementation \nthat concerned itself with the proce\u00addure call interface was constructed in an ad-hoc manner. The resulting \ncode is complicated with details, difficult to maintain, and often incorrect. In our experience, we have \nencountered many recurring difficulties in the calling convention portion of a retar\u00adgetable compiler, \nThere are three sources for these problems: the convention specification, the convention implementation, \nand the implementation process. We address each of these in the following paragraphs. Many problems arise \nfrom the method of convention specifi\u00adcation. Often, no specification exists at all. Instead the native \ncom\u00adpiler uses a convention that must be extracted by reverse\u00adengineering it. In the cases where a specification \nexists, it typically takes the form of written prose, or a few general rules (e.g., our example description \nin Figure 3). Such methods of specification have obvious deficiencies, Furthermore, even if we have an \naccu\u00adrate method for specifying a convention, it still may be possible to describe conventions that are \ninternally inconsistent, or incom\u00adplete. For example, the convention may require that more than one procedure \nargument be placed in a particular resource. Another possibility is that the specification may omit rules \nfor a particular data type, or combination of data types, Those problems that do not stem from the specification \nresult from incorrect implementation of the convention. Many of the same problems in the specification \nprocess also plague the imple\u00admentation. Many conventions have numerous rules, and excep\u00adtions that must \nbe reflected in the implementation. Another dit%culty is that the implementation may require the use \nof the convention in several different locations. Maintaining a correspon\u00addence between the various implementations \ncan itself be a great source of errors. Finally, this problem is exacerbated by the fact that the implementation \nfrequently undergoes incremental devel\u00adopment. Rather than taking on the chore of implementing the entire \nconvention at once, a single aspect of the convention, such as providing support for a single data type, \nis tackled. After suc\u00adcessfully implementing this subset, the next increment is tackled. In doing so, \nsome aspect of the first stage may break due to the interactions between the two pieces, The result of \nthese observations is that there are several prop\u00aderties that we would like to ensure about a specification \nand imple\u00admentation. The above discussion motivates the following categories of questions: 1. Completeness: \na. Does the spectfied convention handle any number of arguments ? b. Does the convention handle any \ncombination of argu\u00adment types ?  2. Consistency: a. Does the convention map more than one argument \nto a single machine resource ? b. Do the caller and callee b implementations agree on the  convention \n? Many questionslike thesecanbeansweredusingP-FSA S,Thefol\u00adlowing sections show how we can prove certain \nproperties about conventions that ensure desirable responsesto the above questions. 5.2 Completeness \nThe completeness properties address how well the convention cov\u00aders the possible input cases. A convention \nmust handle any proce\u00addure signature. If we could guarantee that the convention was complete, or covered \nthe input set. then we could answer the com\u00adpleteness questions posed in the previous section. We can \ndeter\u00admine if a convention is complete by looking at the resulting P-FSA. For example, will the convention \nwork for any combination of argument types? The answer lies in the P-FSA transitions. For the convention \nto be complete, each state q = Q must have 8(q, c) defined for all c c C. Using P-FSA S, we can guarantee \nthat no incomplete conven\u00adtion will go undetected. For an incomplete convention K to not be detected, \nit would first have to be constructed using our algorithm. Assume such a P-FSA M exists for K. Then there \nmust be some state qk that is reachable from q. but does not have ~(q~, a) defined for someaGC, LetW~ \ndenote the set of all strings x such that $ (qO, x) = qk That is, W~is the set of strings that take M \nfrom state qo to qk. Thus> for all strings x such hat x e k! Xa represents a@\u00adnature that K does not \ncover. However, during construction, BuILD-P-FSA visited state q~ with some string w such that 8 (qo, \nw) = qk Thus, w must be in wk and must not be covered by K. Since BuILD-P-FSA callsflwc) for all c = \nC,f will be called using flwa). Since wa is not covered by K, fiwa) will be undefined. At this point \nthe construction process will signal that K is incomplete. 5.3 Consistency The consistency properties \naddress whether the convention is internally and externally consistent. A convention is internally consistent \nif there is no machine resource that can be assigned to more than one argument, A convention is externally \nconsistent if the caller and callee agree on the locations of transmitted values. In our model, we detect \ninternal inconsistency, and prevent external inconsistency. To detect internal inconsistencies, we again \nturn to the P-FSA. If the convention only used finite resources, detecting a cycle in the P-FSA would \nbe sufficient to detect the error, However, when infinite resources are introduced, so are cycles. We \ncannot have an internal inconsistency for an infinite resource since p is defined to be monotonically \nincreasing. We detect finite resource inconsistencies in the following manner. An inconsistency cart \noccur when there is a transition from some state qj to qk where bit in the finite bit vector is 1 in \nq} but O in qti At this point, M has lost the information that resource ri was already allocated. We \ncan detect this change by comparing all pairs of bit vectors Vl, V2such that VI labels qj V2 labels qk \nand fi(qj, c)= qk for some c e c. To do the comparison, we compute V3 = (VI @ v2) A VI. VI @ V2 selects \nall bits that differ between VI and V2. We logically and (A) this with V1 to determine if any set bits \nchange value. Thus, if V3 has any bit set, we have an inconsistency. Our convention specification language \nprevents external inconsistencies in the calling convention. A convention specifica\u00adtion only defines \nthe argument transmission locations once. Although both the caller and the callee must make use of this \ninfor\u00admation, the specification does not duplicate the information. Since we only have a single definition \nof argument locations, we only construct a single P-FSA to model the placement mapping. This single P-FSA \nis used in both the caller and callee. By doing so, we prevent external inconsistencies by requiring \nthe caller and callee use the same implementation for the placement mapping. 6 The Implementation 6.1 \nThe Interpreter We have implemented an interpreter for the CCL specification lan\u00adguage. The interpreter \ns source is approximately 2500 lines of Icon code [GRIs90]. The interpreter takes as input the CCL description \nof a procedure calling convention, a procedure s signature, and some additional information about the \ntarget architecture, and pro\u00adduces locations of the values to be transmitted, in terms of both the callee \nand the caller s frame of reference. We have developed CCL specifications for the following machines: \nMIPS R2000, SPARC, DEC VAX-11, Motorola M68020, and Motorola M88 100. Each of these CCL specifications \nis approximately one page in length. Using the specification for tbe MIPS, and the CCL interpreter, we \nconstructed a P-FSA that implements the MIPS calling convention. The MIPS P-FSA uses only 16 out of a \npossible 512 states (the state label has 9 bits), but requires nine transitions for each state to implement \nthe selection criteria for the C programming language. Since the MIPS conven\u00adtion has more machine resource \nclasses and alignment require\u00adments than any of the other machines, it represents the most complicated \nconvention we have. Therefore, we would expect P-FSA S for the other architectures to be significantly \nsmaller. For machines that pass procedure arguments on the stack with no alignment restrictions, such \nas the VAX-11, would only be a few states. For comparison purposes, we have examined the calling con\u00advention \nspecific code for a retargetable compiler. The MIPS imple\u00admentation requires 781 lines of C code, while \nthe SPARC implementation has 618 lines. This code is one of the most com\u00adplex sections of the machine-dependent \ncode. This code is replaced by the P-FSA tables and a simple automaton interpreter. 6.2 Realizing the \nCalling Sequence In this section, we present how the information from our CCL descriptions can be used \nto generate calling sequences for the vpcd vpo optimizing compiler[BEN188 ][BEN194]. In our compiler, \nthe code for the procedure bodies is gener\u00ad ated without knowledge of the calling convention. For a \ncallee, the optimizer treats formal parameters as local variables. It assigns each parameter either a \nregister or a memory location, based on the parameter s predicted reference frequency. Thus, although \nan established convention for where values cross the procedure call interface exists, the code generated \nby our compiler for a proce\u00ad dure s body may not conform to the convention. To correct this problem, \ninstructions are placed before and after the callee s body, and before and after the call site in the \ncaller. We call these instructions the caller/callee prologue/epi\u00adlogue sequences. It is these sequences \nof instructions that are col\u00adlectively called the calling sequence. The sequences introduce four new \ninterfaces shown as ~ in Figure 6. In each sequence, the instructions transform a convention interface \nto a code body inter\u00adface or vice versa. Since these sequences of instructions are used to glue the procedure \nbodies to the convention interfaces, they cor\u00adrespond to the agents, shown in Figure 1, of our high-level \nmodel.  W/P- Callee QBody Csltw @ilMJtw s6qlMmc* Gwm !xpkEJJe $W#m k$3 Caller Body Figure 6: Calling \nSequence Locations An agent s responsibilities fall into one of three categories: allocation or deallocation \nof storage space, movement of values from their locations in the first interface to locations in the \nsecond interface, and the constructiorhestoration of procedure execution environments. Hence, to generate \nan agent s actions, we must have information about where the calling convention expects values, what \nspace to allocate or free, and the procedure s environment structure. We can automatically generate the \nfirst two. To illustrate our technique, we show how to generate the instruction sequence for one agent. \nThe instruction sequences that correspond to the other three agents are generated exactly the same way. \nFor our example, we focus on the prologue callee agent for the procedure f oo introduced earlier. Recall \nthat for our hypothetical machine, f oo s arguments are placed by the caller in locations a , a2, a3, \nM[sp:sp+7]. The frame layout on the stack just before control passes to f oo is shown in Figure 7a. Assume \nthat in generating the f oo s body, the optimizer uses two non-volatile registers, allocates 12 bytes \nof memory for local variables (including f oo s arguments) and uses 8 bytes of spill space. One possible \nframe layout for f oo is shown in Figure 7b. The relative locations of the temporary spill space, local \nvariable space and non-volatile register save space are deter\u00admined by the optimizer. The optimizer provides \nthe locations where the callee body expects values. These are listed in the sec\u00adond column of Table II. \nThese locations represent an agreement between the callee body and the callee prologue agent. The optimizer \ncalls the P-FSA interpreter with the foo s sig\u00adnature and values of the external variables: tination, \notherwise the source value will be lost. It is not uncom\u00admon for a circularity to exist. For example, \nif al+a2 and a2+al, we must introduce a third location to break the circularity: foo s Iboals Temporary \nSpill Space Non-Volatile Save Space n p4 44 Caller Caller Frame Frame I Figure 7a: Frame before call. \nI Figure 7b: f oo s frame layout. Figure Z Frame layouts at different stages of procedure call. [sPILL_sIzE=8, \nLocALs_sIzE=12, NVSIZE=8, (ARGl, type: char, size: 1), (ARG2, type:int, size:4), (ARG3, type:int, size:4), \n(ARG4, typedouble, size:8)] The P-FSA returns view changes, a list of argument locations that correspond \nto the calling convention, and a list of non-volatile reg\u00adisters: [(V oflset ~ (-c-ax=], M[sp + oflsei] \n: M[sp + offset + 28]), [(ARG1, al), (ARG2, a2), (ARG3, a3), (ARG4, M[sp+28:sp+35]), [non-volatile: ab, \na7, a8, ag]] In this example, the view change occurred before the list of loca\u00adtions. Therefore, the \nlocations reflect this fact. View change information corresponds to the allocation or deallocation of \nstorage space. Ilk view change indicates that any memory location s address, that contains a valid value \nfor offset, shifts down by 28 bytes. Since offset can take on any positive or negative value (--x=), \nthis corresponds to all addresses relative to the stack pointer. Thus, a decrement of the stack pointer \nby 28 bytes is needed. This allocation of stack space will appear as a view change since it changes the \nnames of all locations referenced by the stack pointer. A table is consulted for each view change in \nthe CCL description. The table maps all view changes to valid machine instructions. After the view change \nhas been performed, the necessary moves must be made to transform the agreement between the caller prologue \nagent and callee prologue agent to the agreement between the callee prologue agent and the callee body. \nTable II summarizes the location information. Column 1 shows the loca\u00adtions returned by the P-FSA. Column \n2 shows the locations that the optimizer supplies. Column 3, which can be trivially derived from columns \n1 and 2, indicates the necessary actions. Each of these moves is a register/memory to register/memory \nmove. A table of available move instructions is consulted to determine the necessary instructions to \nbe inserted into the crdlee prologue s sequence. After the agent s actions are determined, the list of \nsources and destinations must be examined to determine if there are any dependencies. If a source is \nalso a destination, the move containing the source must be performed before the move containing the des\u00adal+temp, \nazaa 1, temp+a2. Either an available register or a memory location must be used to temporary hold one \nof the val\u00adues. In our optimizer, we usually have a register available. Cake Prologue Callee Prologue \nAgent Agent/Callee Actions Agreement pl:a3 a 1+a3 p2 :M[sp+4:sp+7] a2+M[sp+4:sp+7] P3 ;a4 a3+a4 I P4:M[sp+28:sp+35] \np4:a1,a2 M[sp+28:sp+35]+al,a2 M[sp+20:sp+23] a6+M[sp+20:sp+23] M[sp+24sp+27] a7+M[sp+24:sp+27] a . a \nlkble Ik Summary indicating how callee prologue agent actions are determined from placement information \nfrom both interfaces. For our implementation of the C language, the cake pro\u00adlogue has no other responsibilities. \nHowever, in other implementa\u00adtions, or other languages, special environment initialization might be required. \nFor example, in PASCAL, the variable display that is used for addressing outer-block variables might \nneed to be setup. Although this would probably be performed in the callee prologue sequence, the initialization \nis not part of the calling convention and is, therefore beyond the scope of thiss ystem. At this point, \nthe callee prologue instruction sequence is com\u00adplete. So far, we have not addressed instmction sequence \neffi\u00adciency. Because of the frequency of procedure calls, generating efilcient instruction sequences \nis an important feature of optimiz\u00ading compilers. In our compiler, the resulting instruction sequences \nare processed by the optimizer. Thus, although the instruction sequences that are initially generated \nby this process are naive, they benefit from thorough optimization just as other code does. 6.3 Related \nIssues Providing support for procedures that may receive a varying num\u00adber of arguments is always difficult, \nIn the C language, the mecha\u00adnism used is varargs which is more a convention than a language feature. \nJohnson and Ritchie spend considerable time explaining the ramifications that varargs has on the calling \nsequence [JOHNSON]. In fact, providing support for C s varargs frequently has profound influence on the \ncalling convention. However, in C, procedures that receive variable numbers of arguments still adhere \nto the defined calling convention. While varargs must be consid\u00adered when developing a particular calling \nsequence, information about varargs is not present in the definition of the calling conven\u00adtion. An important \ndecision when designing a calling convention is deciding which registers retain their value across a \nprocedure call. If some registers retain their value, it is the responsibility of the callee to restore \nthe original values of any such register that is used. Rather than define the mechanism employed in the \nconven-10 References I tion as caller or callee save, we simply define who is responsible for the save. \nThis is accomplished by indicating that registers are non-volatile. Volatile register values must be \nsaved by the caller, while non-volatile register values must be saved by the callee if it uses them. \nThe specifications in this paper, and the implementation that we have presented are for the C language. \nWe have not, as yet, considered how CCL could be used for languages that are drasti\u00adcally different from \nC. However, we anticipate that CCL could handle features such as heap-based parameter passing without \nmodification. 7 Related Work What little work there has been in calling sequences has been ad\u00adhoc. For \nexample, Johnson and Richie discuss some rules of thumb for designing and implementing a calling sequence \nfor the C pro\u00ad gramming language [JOHNSON]. Davidson and Whalley experi\u00admentally evaluated several different \nC calling conventions [DAv191]. No attempts have been made to formally analyze calling conventions. Onthe \nother hand, the use of FSAformodeling parts of a compiler, and as an implementation tool has a long and \nsuccessful history. Forexample, Johnson et al. [Jom68] describe theuseof FSA S to implement Iexical analyzers. \nMore recently, Proebsting and Fraser [PROE94], and Muller [MuLL93] have used finite state automata to \nmodel and detect structural hazards in pipelines for instruction scheduling. 8 Summary Current methods \nof procedure call specification are frequently imprecise, incomplete, contradictory or inconsistent. \nThis comes from the lack of a formal model, orspecification kmguaget hat guarantee these properties. \nWe have presented a formal model, called P-FSA S, forprocedure calling conventions that can ensure these \nproperties. Furthermore, we have developed a language and interpreter for the specification of procedure \ncalling conventions. With the interpreter, a P-FSA that models a convention can be automatically constructed \nfrom the convention s specification. During construction, the convention can be analyzed to determine \nif it is complete and consistent. The resulting P-FSA can then be directly used as an implementation \nof the convention in an applica\u00adtion. 9 Acknowledgments We express our thanks to John Reppy and Sanjay \nJinturkar for their extensive comments on earlier drafts of this paper. We should mention in particular \nRicky Benitez who provided many insightful conversations and the implementation of the optimizing compiler \nused in this work. Finally, we would also like to thank the review\u00aders for their helpful suggestions. \n[BAIL93] Bailey, .W. and Davidson, J.W. A Formal Specljica\u00ad 4 tion for PI ocedure Calling Conventions. \nTechnical Re\u00adport CS-J 3-59. University of Virginia, 1993. [BAIL94] Bailey, d .W. and Davidson, J.W. \nA Formal Model for Procedu e Calling Conventions. Technical Report CS\u00ad94-57. U iversity of Virginia, \n1994. ! [BEN188] Be~te~, ~.E. and Davidson, J.W. A Portable Global Optlmlze and Linker. In Proceedings \nof the SIGPLAN 88 Con ~rence on Programming Lunguage Design and Imp ementation, Atlanta, Georgia, June, \n1988, 329-338. i [BEN194] Benitez, M.E. and Davidson, J.W. The Advantages of Machine Dependent Global \nOptimization. In Proceed\u00adings of t i e 1994 Conference on Programming Lan\u00adguages and Systems Architectures, \nZurich, Switzerl Jnd, March 1994, 105-124. / [DAv191] Davidso#, J.W. and Whalley, D.B. Methods for Saving \nand Rest 1ring Register Values across Function Calls. 1 Softiare Practice and Experience 21(2):149-165 \nFebruary 1991. r [DEC78] Digital Equipment Corporation. VAX Architecture Handbook. Digital Equipment \nCorporation, 1978. [DEC93] Digital E uipment Corporation. Calling Standard for AXP I Digital Equipment \nCorporation, July Sys ems. 1993. [FRAS93] Fraser, tlW. Personal Communication, November, 1993. [GRIs90] \nGriswold R.E. and Griswold, MT. The Icon Program\u00adming La ~guage, 2nd edition, Prentice-Hall, 1990. [HoPc79] \nHopcroft J.E. and Unman, J.D. Introduction to Autom\u00adata l heo~, Languages, and Computation. Addison-Wesley, \n1979. [JOHNSON]Johnson, .C. and Ritchie, D.M. The CLanguage Call\u00ading Sequ / rice. Bell Labs. [JOHN68] \nJohnson, W. L., J.H. Porter, S.1. Ackley, and D.T. Ross. Automati~ generation of efficient lexical processors \nusing fimte state techniques, Communications of the ACM, 111(12), 805 813. [KANE92] Kane, G. and Heinrich, \nJ. MIPS RISC Architecture. H Prentice all, 1992. [KERN78] Kemigh~n, B. W. and Ritchie, D.M. The C Program\u00adming \nLa~guage. Prentice-Hall, 1978, [KERN88] Kemigh all , B.W. and Ritchie, D.M. The C Program\u00adming La~guage, \n2nd edition. Prentice-Hall, 1988. [MEAL55] Mealy, .H, A method for synthesizing sequential cir\u00ad d cuits, \nB~ll System Technical Journal, 34(5): 1045 1079, 1955. [MuLL93] Muller, T. Employing Finite Automata \nfor Resource Scheduli~g. In Proceedings of the 26th Annual Inter\u00adnational Symposium on Microarchitecture, \n1993, 12 20. [PROE94] Proebstiq g, T.A. and Fraser, C.W. Detecting Pipeline Structural Hazards Quickly. \nIn Proceedings 21st ACM SIGPLM$-SIGACT Symposium on the Principles of Program, L mg Languages, 1994,280-286. \n Appendix A A.1 Construction Algorithms We define the algorithm BuILD-P-FSA in Figure 8. The algorithm \nstarts with theinitial state qoasthe only element of Q, Since there are no transitions yet, ~ and fi \nhave no rules. A call to BUILD-P- FSAtakes three prrrameters, q,w, andx. qrepresents the state for BuILD-P-FSA \nto visit, while w represents the input string such that (qo, W) yields (q, 0, and x is output string \nupon reaching q. From this definition, the initial call to BuILD-P-FSA must be BUILD-P\u00adFSA(qo, 8, Q. \nfunction BuILD-P-FSA(q, w, x) //qe Q,we Z*, xeA*l~(w)=x for each criterion c E C do //compute placement \nfor signature wc y +flwc); //compute state label from placement q + STATE-LABEL(Y); ifq ~ Qthen Q+-Qu{q \n}; BuIL,D-P-FSA(q , WC, JJ); end if //set a as the sum ofynot inx a+ blxb=y, add A(q, c)= q ; add 5(q, \nc) = a; end for end function Figure 8: Algorithm to build the P-FSA The algorithm for STATE-LABEL is \nsimple. We start with state qo. AS STATE-LABEL reads each symbol from the stfing, it encoun\u00adters either \nthe name of a finite resource, or a symbol representing the distinguishing bits ofp. In the finite case, \nthe bit corresponding to the resource is set in the finite resource vector. In the infinite case, the \ndistinguishing bits of the state are set to the input symbol that was read. At the end of the input, \nall finite resources that have been read have their bits set to indicate they are unavailable, and the \ndistinguishing bits indicate the last set of distinguishing bits read. To complete the computation, we \nneed to move the infinite resource index to the next available resource (it currently points to the last \nunavailable one)l. The result of this computation is pre\u00adcisely the label for the final state of M for \noutput w since it indi\u00adcates which resources are available for allocation. The complete algorithm is \nshown in Figure 9. A.2 A Complex Example We now present a significantly more complex example: the MIPS \nR3000. The MIPS is a RISC machine with both integer and float\u00ading-point registers. Unlike most machines, \nthe MIPS convention designates that not only some integer registers but also some float\u00ad ing-point registers \nare to be used for passing arguments. Figure 10 contains the complete convention specification. Although \nthe MIPS convention is more complicated, the description is quite similar to our previous example with \na few additional restrictions. First, notice that the resource list (line 14) now includes the floating-point \nregisters. Each resource set is ordered to indicate that the resources within them must be assigned in \nsequence, This prevents the subsequent placement operator from using element n after element n + 1 has \nbeen assigned. Sec\u00ad function STATE-LABEL(W) //w E A Z+o r; ij z is the finite resource vector while w \n# &#38;do //extract the first symbol from w define a and x such that ax = w; W +x, //set w to the rest \nof w ifael?then //forjinite resources: //mark it as used set a s corresponding bit in Z; else //for injinite \nresources: dha; //keep the last one encountered end if end while //set d to the next resource (first \navailable) d-d+l; //return the state label made up of z and d return zd, end function Figure 9 Definition \nof STATE-LABEL end, we have added several new classes.These reflect the addition of registers for passing \narguments and alignment constraints placed on the registers and stack. For example, the class intfpregs \nis the set of starting points in the integer register set that have even register numbers. The class \namem is the set of stack locations that are 8-byte aligned. Finally, the class smem contains a set of \nstarting-point pairs. The pair is used to indicate that if the first resource exhausts, the placement \ncontinues using the second resource starting point. This class is used in passing structure argu\u00adments \nand indicates that a single structure argument may span the argument registers and stack. After properly \ndefining the classes, the placement (lines 27\u00ad34) is straightforward, For each type, a list of classes \nto use is spec\u00adified. In each case, a register class is first, followed by the corre\u00adsponding stack class. \nThis reflects the convention that registers are used until exhausted, followed by stack use. The placement \nis slightly complicated in the floating-point case since the register class to use is dependent on the \ntype of the first argument. When the first argument is a floating-point value, the floating-point regis\u00adters \nare used. When the first value is any other type, the integer registers are used to pass floating-point \nvalues. The MIPS convention has two other features we must convey. The first requires that the initial \n16 bytes of the frame, which cor\u00adrespond to the argument registers, must be reserved so the callee can \nsave the register arguments if necessary. This is specified on line 15 by setting the assigned attribute \nfor these resources, The second constraint is that floating-point argument registers are asso\u00adciated \nwith the integer registers (~ with r4 and r5, f7 with r6 and r7). The association requires that if a \nregister in one class is assigned, the associated register in the other class cannot be assigned. Each \nof the four associations is specified, on lines 23-26, using the existential quantifier (3) which is \nsimply a conditional expression. These restrictions complete the calling convention for the MIPS. The \nremaining details are similar to the simple example presented earlier. 1. An ordered list of values for \np s disdngukhing bits is known so that we can perform this calculation, although this is usuatly just \nan increment. 1 external NVSIZE, SPILL_SIZE, LOCALS_SIZE 2 alias REG ARGS = 16 3 alias Sp= 79 4 non-volatile \n{r1:3, r8:11,r16:31} caller prologue 6 view change 7 V offset E {-M:co) 8 M[sP + oflset] becomes M[SP \n+ oflset + rARG_SIZE181 9 end view change data transfer (asymmetric) 11 alias rindex = <4:7> 12 #las \nfpindex = <6:7> 13 aHas rnindex = <sp:co> 14 resources {-@ndex>, <Fpindex>,-d@ dex> ] V register G {M[sp(REG_ARGS)] \n} set register. assigned +--true 16 interml ARG_SIZE + X(<M[ad&#38;] size I addr e rnindex A M[add) 17 \nclass intregs e <<rnndex>> 18 class intfpregs e <<P> I x e rindex A x DIQLI2 = O> 19 class fpfpregs + \n<<f% I x e fpindex A x Q@ 2 = O> chws mem + <df[addr]> I addrs mindex A addr ID@ A = O> 21 class amem \n+--<~[addr]> I addr e rnindex A addr L@ 8 = 0> 22 class smem -<<rnndex, M[addr]> I addr e mindex A addr \n~ 8 = 23 ~ reg = {reg I reg c {~) A reg.assigned) =$ set r4 5.assigned +\u00ad true 24 q ?r?g= {reg I reg \ne {f7) A reg.assigned) a set r6:7.assigned + true ~ reg G {reg I regs {r4:5} A reg.assigned} =$ set ~.assigued \n-true 26 27 3 reg 6 {reg V argument I reg G {r6:7~,A&#38;A<~~A~si~ed) E <ARG -> ~ set f .assigned +-true \n28 map argument -+ argument.type 1 { 29 byte, word, longword: <intregs, merm, Struct: <smem, amerm, 31 \nfloat, double: ARG1.type -L ( 32 struct, byte, word, longword: <intfpregs, amem>, 33 float, double: <fpfpregs, \namem> 34 1 1 36 end data transfer 37 end caller prologue 38 callee prologue 39 view change V offset \n{-w:co) 41 M[sp + oj%et] becomes M[sp + offset + [SPILL_SIZE + LOCA 42 end view change 43 end callee \nprologue 44 callee epilogue 46 data transfer (as mmetric);resources {r ,fO) 47 map RVAL1 + RVAL1.type \nL { 48 byte, word, longword: <<<r2>>>, 49 float, double: <<<P>>>, Struct: <t(<<rZ>>)> 51 1 52 end data \ntransfer 53 end callee epilogue Figure 10:The MIPS R3000 Specification lssigned>) > ~_SIZE + NVSIZE18] \n \n\t\t\t", "proc_id": "199448", "abstract": "<p>Procedure calling conventions are used to provide uniform procedure-call interfaces. Applications, such as compilers and debuggers, which generate, or process procedures at the machine-language abstraction level require knowledge of the calling convention. In this paper, we develop a formal model for procedure calling conventions called P-FSA's. Using this model, we are able to ensure several completeness and consistency properties of calling conventions. Currently, applications that manipulate procedures implement conventions in an <italic>ad-hoc</italic> manner. The resulting code is complicated with details, difficult to maintain, and often riddled with errors. To alleviate the situation, we introduce a calling convention specification language, called CCL. The combination of CCL and P-FSA's facilitates the accurate specification of conventions that can be shown to be both consistent and complete.</p>", "authors": [{"name": "Mark W. Bailey", "author_profile_id": "81100645474", "affiliation": "Department of Computer Science, University of Virginia, Charlottesville, VA", "person_id": "PP15038355", "email_address": "", "orcid_id": ""}, {"name": "Jack W. Davidson", "author_profile_id": "81100099215", "affiliation": "Department of Computer Science, University of Virginia, Charlottesville, VA", "person_id": "PP14044617", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/199448.199517", "year": "1995", "article_id": "199517", "conference": "POPL", "title": "A formal model and specification language for procedure calling conventions", "url": "http://dl.acm.org/citation.cfm?id=199517"}