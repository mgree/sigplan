{"article_publication_date": "10-19-2012", "fulltext": "\n Scaling Symbolic Execution using Ranged Analysis Junaid Haroon Siddiqui Sarfraz Khurshid University \nof Texas at Austin 1 University Station Austin, TX 78712 {jsiddiqui,khurshid}@ece.utexas.edu Abstract \nThis paper introduces a novel approach to scale symbolic execution a program analysis technique for systematic \nex\u00adploration of bounded execution paths for test input gener\u00adation. While the foundations of symbolic \nexecution were de\u00adveloped over three decades ago, recent years have seen a real resurgence of the technique, \nspeci.cally for systematic bug .nding. However, scaling symbolic execution remains a pri\u00admary technical \nchallenge due to the inherent complexity of the path-based exploration that lies at core of the technique. \nOur key insight is that the state of the analysis can be rep\u00adresented highly compactly: a test input \nis all that is needed to effectively encode the state of a symbolic execution run. We present ranged \nsymbolic execution, which embodies this insight and uses two test inputs to de.ne a range, i.e., the \nbeginning and end, for a symbolic execution run. As an ap\u00adplication of our approach, we show how it enables \nscalabil\u00adity by distributing the path exploration both in a sequential setting with a single worker node \nand in a parallel setting with multiple workers. As an enabling technology, we lever\u00adage the open-source, \nstate-of-the-art symbolic execution tool KLEE. Experimental results using 71 programs chosen from the \nwidely deployed GNU Coreutils set of Unix utilities show that our approach provides a signi.cant speedup \nover KLEE. For example, using 10 worker cores, we achieve an average speed-up of 6.6X for the 71 programs. \nCategories and Subject Descriptors D.2.5 [Testing and Debugging]: Symbolic execution General Terms Algorithms, \nPerformance Keywords Test input as analysis state, ranged analysis, par\u00adallel symbolic execution, incremental \nanalysis, KLEE Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, USA. Copyright c &#38;#169; 2012 ACM 978-1-4503-1561-6/12/10. \n. . $10.00 1. Introduction Symbolic execution is a powerful program analysis tech\u00adnique based on a systematic \nexploration of (bounded) pro\u00adgram paths, which was developed over three decades ago [9, 24]. A key idea \nin symbolic execution is to build path conditions given a path, a path condition represents a con\u00adstraint \non the input variables, which is a conjunction of the branching conditions on the path. Thus, a solution \nto a (feasi\u00adble) path condition is an input that executes the correspond\u00ading path. A common application \nof symbolic execution is indeed to generate test inputs, say to increase code cover\u00adage. Automation of \nsymbolic execution requires constraint solvers or decision procedures [3, 11] that can handle the classes \nof constraints in the ensuing path conditions. A lot of progress has been made during the last decade \nin constraint solving technology, in particular SAT [40] and SMT [3, 11] solving. Moreover, raw computation \npower is now able to support the complexity of solving formulas that arise in a number of real applications. \nThese technological advances have fueled the research interest in symbolic ex\u00adecution, which today not \nonly handles constructs of mod\u00adern programming languages and enables traditional analy\u00adses, such as test \ninput generation [8, 16, 23, 34], but also has non-conventional applications, for example in checking \npro\u00adgram equivalence [32], in repairing data structures for error recovery [13], and in estimating power \nconsumption [35]. Despite the advances, a key limiting factor of symbolic execution remains its inherently \ncomplex path-based analy\u00adsis. Several recent research projects have attempted to ad\u00address this basic \nlimitation by devising novel techniques, including compositional [15], incremental [31], and paral\u00adlel \n[7, 17, 37, 41] techniques. While each of these techniques offers its bene.ts (Section 5), a basic property \nof existing techniques is the need to apply them to completion in a single execution if completeness \nof analysis (i.e., complete exploration of the bounded space of paths) is desired. Thus, for example, \nif a technique times out, we must re-apply it for a greater time bound, which can represent a costly \nwaste of computations that were performed before the technique timed out.  This paper presents ranged \nsymbolic execution, a novel technique for scaling symbolic execution for test input gen\u00aderation. Our \nkey insight is that the state of a symbolic exe\u00adcution run can, rather surprisingly, be encoded succinctly \nby a test input speci.cally, by the input that executes the last terminating (feasible) path explored \nby symbolic execution. By de.ning a .xed branch exploration ordering e.g., tak\u00ading the true branch before \ntaking the false branch at each non-deterministic branch point during the exploration an operation already \n.xed by common implementations of symbolic execution [2, 8, 23], we have that each test input partitions \nthe space of (bounded) paths under symbolic ex\u00adecution into two sets: explored paths and unexplored paths. \nMoreover, the branch exploration ordering de.nes a linear order among test inputs; speci.cally, for any \ntwo inputs (that do not execute the same path or lead to an in.nite loop), the branching structure of \nthe corresponding paths de.nes which of the two paths will be explored .rst by symbolic execution. Thus, \nan ordered pair of tests, say (t, t'), de.nes a range of (bounded) paths [.1,...,.k] where path .1 is \nexecuted by t and path .k is executed by t', and for 1 = i<k, path .i+1 is explored immediately after \npath .i. Encoding the analysis state as a test input has a number of applications. The most direct one \nis to enable symbolic exe\u00adcution to be paused and resumed. To illustrate, if an analysis runs out of \nresources, the last test input generated allows it to be effectively paused for resumption later (possibly \non an\u00adother machine with greater resources) without requiring the previously completed work to be re-done. \nAnother key ap\u00adplication, which is the focus of this paper, is a novel way to partition the path exploration \nin symbolic execution to scale it both in a sequential setting with one worker node and in a parallel \nsetting with several workers. The encoding al\u00adlows dividing the problem of symbolic execution into sev\u00aderal \nsub-problems of ranged symbolic execution, which have minimal overlap and can be solved separately. It \nalso allows effective load balancing in a parallel setting using dynamic re.nement of ranges based on \nwork stealing with minimal overhead due to the compactness of a test input. We make the following contributions: \n Test input as analysis state. We introduce the idea of encoding the state of a symbolic execution run \nusing a single test input.  Resumable symbolic execution. Our encoding allows symbolic execution to \nbe paused and resumed using min\u00adimal book-keeping just a single test input.  Two test inputs as analysis \nrange. We introduce the idea of using two test inputs to de.ne a range of paths to be explored using \nsymbolic execution and to restrict it to that range.  Ranged symbolic execution. Restricting symbolic \nexe\u00adcution to a range allows simply using a set of inputs to divide the problem of symbolic execution \nof all bounded  execution paths into a number of sub-problems of ranged symbolic execution, which can \nbe solved separately. Dynamic range re.nement using work stealing. We introduce load-balancing for parallel \nsymbolic execution using dynamically de.ned ranges that are re.ned using work stealing.  Implementation. \nWe implemented ranged symbolic ex\u00adecution using KLEE [8] an open-source symbolic ex\u00adecution tool, which \nanalyzes LLVM [1], an intermediate compiler language that is closer to assembly and only has two-way \nbranches, but has more type/dependency infor\u00admation than assembly. We developed a work stealing ver\u00adsion \nusing MPI [39] message communication.  Evaluation. We evaluated ranged symbolic execution us\u00ading 71 \nprograms from GNU Coreutils the widely de\u00adployed set of Unix utilities. We observed an average speedup \nof 6.6X for the 71 programs using 10 workers.  2. Illustrative overview Forward symbolic execution is \na technique for executing a program on symbolic values [10, 24]. There are two funda\u00admental aspects of \nsymbolic execution: (1) de.ning semantics of operations that are originally de.ned for concrete values \nand (2) maintaining a path condition for the current program path being executed a path condition speci.es \nnecessary constraints on input variables that must be satis.ed to exe\u00adcute the corresponding path. As \nan example, consider the following program that re\u00adturns the middle of three integer values. 1 int mid(int \nx, int y, int z) { 2 if (x<y) { 3 if (y<z) return y; 4 else if (x<z) return z; 5 else return x; 6 } else \nif (x<z) return x; 7 else if (y<z) return z; 8 else return y; } To symbolically execute this program, \nwe consider its be\u00adhavior on integer inputs, say X, Y, and Z. We make no as\u00adsumptions about the value \nof these variables (except what can be deduced from the type declaration). So, when we en\u00adcounter a conditional \nstatement, we consider both possible outcomes of the condition. We perform operations on sym\u00adbols algebraically. \nSymbolic execution of the program mid explores 6 paths: path 1:[X<Y < Z] L2-> L3 path 2:[X<Z < Y] L2-> \nL3 -> L4 path 3:[Z<X < Y] L2-> L3 -> L4->L5 path 4:[Y<X < Z] L2-> L6 path 5:[Y<Z < X] L2-> L6 -> L7 path \n6:[Z<Y < X] L2-> L6 -> L7->L8  .. ' . ' . .    Figure 1. Symbolic execution between paths . and \n. ' . Note that for each path that is explored, there is a corre\u00adsponding path condition (shown in square \nbrackets). While execution on a concrete input would have followed exactly one of these paths, symbolic \nexecution explores all six paths. The path conditions for each of these paths can be solved using off-the-shelf \nSAT solvers for concrete tests that exer\u00adcise the particular path. For example, path 2 can be solved \nto X=1, Y=3, and Z=2. Ranged symbolic execution enables symbolic exploration between two given paths. \nFor example, if path 2 and path 4 are given, it can explore paths 2, 3, and 4. In fact, it only needs \nthe concrete solution that satis.es the corresponding path condition. Therefore it is ef.cient to store \nand pass paths. Ranged symbolic execution builds on a number of key observations we make: A concrete \nsolution corresponds to exactly one path in code and it can be used to re-build the path condition that \nleads to that path. Solving a path condition to .nd concrete inputs is computationally intensive. However, \nchecking if a given solution satis.es a set of constraints is very light-weight. Thus we can symbolically \nexecute the method again and at every branch only choose the direction satis.ed by the concrete test. \n We can de.ne an ordering on all paths if the true side of every branch is always considered before \nthe false side. Since, every concrete test can be converted to a path, the ordering can be de.ned over \nany set of concrete inputs.  Using two concrete inputs, we can .nd two paths in the program and we can \nrestrict symbolic execution between these paths according to the ordering de.ned above. We call this \nranged symbolic execution.  For example, consider that we are given test inputs t(X=1, Y=3, Z=2) and \nt '(X=2, Y=1, Z=3) which take paths . and . ' in code (path 2 and path 4 in above exam\u00adple), and we want \nto symbolically execute the range between them. We show this example in Figure 1. We start symbolic execution \nas normal and at the .rst comparison x<y, we note that . goes to the true side while . ' goes to the \nfalse side. (a) Standard (b) Ranged sym\u00ad (c) Only bound\u00ad symbolic execution bolic execution (4 aries \nredundantly ranges) analyzed Figure 2. High level overview of dividing symbolic execu\u00adtion into non-overlapping \nranges for independent symbolic executions. At this point, we also know that .<. ' in the ordering we \nde.ned. Thus, when x<y, we only explore what comes af\u00adter . in the ordering and when x <y we explore \nwhat comes before . '. At the next comparison y<z we skip the true side and only explore the false side \nsatis.ed by .. Similarly we can skip three states using . '. Skipped states are drawn in gray color in \nFigure 1. Three paths are explored as a result. We consider the range [t, t ' ) as a half-open interval \nwhere the start is considered part of the range but not the end. Thus we produce two test cases as a \nresult. Once we have the basic mechanism for ranged symbolic execution, we use it in three novel ways: \n Resumable execution: Ranged symbolic execution en\u00adables symbolic execution to be paused at any stage \nand it can be restarted later with minimal overhead using the last input it generated as the start of \nnew range.  Parallel execution: Ranges of symbolic execution can be analyzed in parallel. For example, \nwe can have three non\u00adoverlapping ranges for the above example [null,t), [t,t ' ), and [t ' ,null), where \nnull designates un\u00adbounded end of a range. Executing these in parallel will completely analyze the above \nfunction without any communication between parallel nodes. Figure 2 shows a high level overview of dividing \nsymbolic execution into non-overlapping ranges. Only the paths dividing the ranges are redundantly analyzed \nas path of both ranges. The initial set of dividing points can come from manual or random test cases \nor from symbolic execution of a previous version of code.  Dynamic range re.nement: We further provide \nan algo\u00adrithm for dynamic range re.nement that enables parallel symbolic execution using work stealing \nwhen there is no initial set of inputs to form the ranges. For example, if a parallel node starts symbolic \nexecution of the mid func\u00adtion and reaches the .rst branch x<y, it proceeds with the true branch while \nqueueing the false branch in a list of work to be .nished later. In the meanwhile, if another parallel \nnode is free for work, it can steal work from the queue of this node and explore paths where !(x<y). \n  3. Technique In this section, we discuss using a single test case as anal\u00adysis state and using two \ntest cases to de.ne an analysis range (Section 3.1), performing symbolic execution within a range (Section \n3.2), using ranged symbolic execution for parallel and resumable analysis (Section 3.3), as well as dy\u00adnamic \nrange re.nement to enable distributed work stealing (Section 3.4). Our presentation assumes a standard \nbounded depth-.rst symbolic execution where path exploration is sys\u00adtematic and for each condition, the \ntrue branch is explored before the false branch. Such exploration is standard in commonly used symbolic \nexecution techniques, such as gen\u00aderalized symbolic execution using JPF [23], CUTE [34], and KLEE [8]. \n 3.1 Test input as analysis state We introduce three concepts in this section: (1) describing an analysis \nstate using a single concrete test, (2) de.ning an ordering of tests based on paths taken, and (3) using \ntwo concrete tests to de.ne an analysis range for symbolic execution. We .rst introduce the concept of \ndescribing an analysis state using a single concrete test. De.nition 1. Let t be a test and .t be the \npath taken by t in the program under analysis using symbolic execution. Given a total order O of all \npaths . explored by the analysis, any concrete test t de.nes a state of analysis in which every path \n.<.t under O has been explored and none of the rest of the paths has been explored. De.nition 1 assumes \nthe existence of translation from concrete tests to paths and an algorithm to compare tests based on \nthe ordering taken by the path-based analysis. The translation from concrete tests to paths can be done \nsimply by executing the test and observing the path it takes (assum\u00ading deterministic execution). In \npractice, however, we will not need to .nd the corresponding path separately and it will be calculated \nalong with other operations as discussed in the next section. We describe test ordering next. De.nition \n2. Given two tests t and t ' and the correspond\u00ading paths . and . ', where (b0,...,bk) is the sequence \nof basic blocks in . and (b' ,...,b' k. ) is the sequence of basic 0 blocks in . ', we de.ne that .<. \n' if and only if there exists a j < min(k, k ' ) such that .j bi = b' i and the terminat\u00ad i=0 ing instruction \nin bj is a conditional branch with bj+1 as the then basic block and b' as the else basic block. j+1 De.nition \n2 orders tests based on the paths they take. We .nd the .rst branch where the two paths differ. We consider \nthe test taking the true branch smaller than the test taking the false branch. If two tests take the \nsame path till the end, we consider them equivalent. Ordering more than two tests can be done by any \nsorting algorithm. Algorithm 1: Algorithm to compare two tests. This can be used with any sorting algorithm \nto order any number of tests. input : test t, test t ' output: BIGGER, SMALLER, or EQUIVALENT 1 de.ne \npath-cond ., address-space AS, address-space AS ; 2 i = .rst instruction in code under symbolic execution; \n3 repeat 4 if i is-a conditional branch then 5 cond . condition of i; 6 if PathTakenByTest(t, ..cond, \nAS) then 7 if NOT PathTakenByTest(t ' , ..cond, AS ) then 8 return BIGGER; 9 end 10 . . .. cond; 11 i \n. .rst instruction in then basic block; 12 else 13 if PathTakenByTest(t ' , ..cond, AS ) then 14 return \nSMALLER; 15 end 16 . . .. NOT(cond); 17 i . .rst instruction in else basic block; 18 end 19 else 20 update \nAS for i using t; 21 update AS for i using t ' ; 22 i . successor of i; 23 end 24 until i is the last \ninstruction; 25 return EQUIVALENT; De.nition 3. Let t and t ' be two tests with execution paths . and \n. ' respectively, we de.ne a range [t, t ' ) to be the set of all paths .i such that . = .i <. ' . Thus, \ngiven three tests ta < tb < tc, we have that [ta, tc)=[ta, tb) . [tb, tc). Given a set of n tests, we \ncan .nd the paths they execute and order them (Algorithm 1). If the tests take p distinct paths (p = \nn), they de.ne p +1 ranges of paths. Note that p<n when multiple tests take the same path in code and \nare thus equivalent. The .rst and last range use special tests begin and end, where begin is the smallest \npath and end is one beyond the biggest path. The end is de.ned as one beyond the last path because we \nde.ne ranges as half-open and we want all paths explored. Lemma 1. Ranged analyses on a set of n - 1 \nranges [t1, t2), ..., [tn-1, tn) explore the same set of paths as the ranged analysis on [t1, tn).  \n 3.2 Ranged symbolic execution This section describes how we restrict symbolic execution to a given range \nof paths to divide the problem of symbolic execution into several sub-problems. We term this approach \nranged symbolic execution. De.nition 4. Let t and t ' be two tests that execute paths . and . ' where \n.<. '. De.ne ranged symbolic execution for [t, t ' ) as symbolic execution of all paths .i such that \n. = .i <. ' . Given a set of tests, ranged symbolic execution has two key steps: (1) de.ning the ranges \nbased on the given tests; and (2) symbolically executing the paths within the ranges. To de.ne ranges \nfor a given set of tests, any standard sorting algorithm can be used given a comparator for tests. Two \ntests can be compared either by running them separately and analyzing the branches taken or by analyzing \nthe two paths simultaneously until the .rst point they differ. The second approach requires only executing \nthe common part of the two paths and not exploring two complete paths. Algorithm 1 gives the algorithm \nfor analyzing the com\u00admon part of paths taken by two tests. The algorithm depends on a predicate function \nthat checks if a given test satis.es a given condition. For that, we iteratively compute path condi\u00adtions \nfor the common initial execution segments for the two tests and check the conditions for satis.ability \nagainst the tests. Note that checking if a path condition is satis.ed by a given input is a very ef.cient \noperation it does not require any constraint solving. To restrict symbolic execution to a range de.ned \nby two tests, we have to (1) convert the tests into paths, (2) .nd all paths in the range, and (3) execute \nthose paths symbolically. We interleave the three steps and thus have no intermediate storage requirements. \nSymbolic execution state for a particular path contains the set of path constraints and address space. \nAt branches, the state is split into two states. States to be visited in the future are added to a queue \nof states. The order of choosing states from the queue determines the search strategy used. We use depth \n.rst search in this work. For restricting symbolic execution to a range, we intro\u00adduce new variables \nto represent the starting and ending tests in the symbolic execution state. The starting and ending tests \nare initialized as input parameters. If one of the parameters is a special begin or end symbol (i.e. \nan unde.ned bound), we just use null in its place. We perform symbolic execution normally but using Algorithm \n2 for conditional branches. Algorithm 2 works by checking if the current state has a starting test assigned \nand that starting test does not satisfy the branch condition. Since we de.ned test ordering with true \nbranches preceding false branches, we need to eliminate the true branch from the search. Similarly if \nwe have an ending test which does satisfy the branch condition, we eliminate the false side from being \nexplored. Algorithm 2: Algorithm for handling a branch for ranged symbolic execution. Each state works \nwithin a range de.ned by a start test tstart and an end test tend. A new state is created using a basic \nblock to start exe\u00adcution from, and a pair of tests to de.ne the range. input : state, branch, test tstart, \ntest tend output: set of states to be explored 1 cond . branch condition of branch; 2 BBthen . then basic \nblock of branch; 3 BBelse . else basic block of branch; 4 if tstart .\u00ac(tstart . cond) then 5 return \n{new state(BBelse, tstart, tend)}; 6 end 7 if tend . tend . cond then 8 return {new state(BBthen, tstart, \ntend)}; 9 end 10 if cond is unsatis.able then 11 return {new state(BBelse, tstart, tend)}; 12 else if \n\u00accond is unsatis.able then 13 return {new state(BBthen, tstart, tend)}; 14 else if both are unsatis.able \nthen 15 // triggers for unreachable code; 16 return \u00d8; 17 else 18 return {new state(BBthen, tstart, null), \nnew state(BBelse, null, tend) }; 19 end  3.3 Parallel and resumable analysis Ranged symbolic execution \nenables parallel and resumable analysis. For parallel analysis, we take a set of tests and use them to \ndivide the symbolic analysis into a number of ranges. These ranges are then evaluated in parallel. We \ncan use more ranges then available workers so that workers that .nish quickly can pick another range \nfrom the work queue. The initial set of tests can come from manual tests, a symbolic execution run on \na previous version of code, or even from a shallow symbolic execution run on the same code. In our evaluation, \nwe pick random collection of tests from a sequential run and use it to de.ne ranges for the parallel \nrun. In the next section, we introduce another way to parallelize that requires no initial set of tests. \nIt uses work stealing to take some to-be-explored states from a busy worker to give to a free worker, \nand in doing so, dynamically rede.ning the ranges for both workers. Ranged symbolic execution also enables \nresumable ex\u00adecution, where we can pause symbolic execution and re\u00adsume it by giving it a concrete test \ncorresponding to the last path explored as the starting point. To use it in combination with parallel \nanalysis, we would also need the original end\u00ading point of the paused range. In the evaluation, we show \n Algorithm 3: Algorithm for work stealing coordinator. 1 de.ne lists of waiting workers and busy workers; \n2 count of workers with no theft started = 0; 3 give the whole task to the .rst worker; 4 while true \ndo 5 receive message m from worker w; 6 if m=need work then 7 .nd a worker w2 where no theft has been \ninitiated; 8 if no such process then 9 increment count of workers with no theft started; 10 if this count \n= total number of workers then 11 terminate, we are done; 12 end 13 else 14 ask w2 to give stolen work; \n15 end 16 add w to list of waiting workers; 17 else if m=stolen work then 18 give stolen work to a waiting \nworker w2; 19 remove w2 from list of waiting workers; 20 if count of workers with no theft started > \n0 then 21 ask w2 to give stolen work (again); 22 decrement count of workers with no theft started; 23 \nend 24 else if m=cannot steal then 25 choose another busy worker w2; 26 ask w2 to give some stolen work; \n27 end 28 end a scheme, where pre-de.ned ranges are analyzed in incre\u00adments resulting in negligible \noverhead and greater .exibility.  3.4 Dynamic range re.nement Dynamic range re.nement enables dynamic \nload balancing for ranged symbolic execution using work stealing. It starts with a single worker node \nresponsible for the complete range [a, c). Whenever this node hits branches it explores the true side \nand puts the false side on a queue to be considered later. As other workers become available, they can \nsteal work from this queue. The state on the queue is persisted as a test case b and the range is rede.ned \nto [a, b). The stolen range [b, c) is taken up by another worker. Our implementation of distributed symbolic \nexecution using work stealing utilizes a master coordinator node and uses MPI for communication. Algorithm \n3 gives the algo-Algorithm 4: Algorithm for work stealing worker node performing ranged symbolic execution. \n1 while true do 2 receive message m from coordinator; 3 if m=exit then 4 terminate; 5 end 6 else if m=new \nwork then 7 start ranged symbolic execution of new work ; 8 else if m=steal work then 9 if stealable \nstates exist in symbolic execution state then 10 remove state and convert it to a concrete test; 11 send \nthe concrete test to coordinator; 12 update the end of current symbolic execution range; 13 else 14 inform \ncoordinator that stealing failed 15 end 16 end 17 end rithm for work stealing coordinator. It maintains \nlists for waiting workers and busy workers. Whenever a node needs work it tries to .nd a busy worker \nand tries to steal work. If a previously started stolen work request completes, it passes the work to \na waiting worker. Sometimes, a stolen work re\u00adquest fails because the node is already .nished or there \nis no work in the queue at that time. In such a case, it tries to steal work from another worker node. \nAlgorithm 4 is the algorithm for a worker node. When it receives a range from the coordinator, it performs \nranged symbolic execution on it. If it receives a request to steal work, it checks if there is any state \nin the work queue. If so, it converts the request to a concrete test to easily pass to the coordinator, \nand rede.nes the current symbolic execution range to end at that test. If there is no state in the work \nqueue, it informs the coordinator of a failure. The worker repeats getting work and stealing ranges until \nthe coordinator tells it to shut down. Using intermediate states in this manner is different from using \nconcrete tests that represent complete paths in code (like Section 3.3). Intermediate states, on the \nother hand, represent partial paths. Partial paths can result in overlap\u00adping ranges and more work than \nabsolutely necessary. We circumvent this by choosing zero values for any .elds not accessed by the concrete \ntest. This extends the partial path to make a complete path that satis.es a zero value assignment for \nthe remaining .elds. It is possible that such a path ends up being infeasible, but it is a complete path \nand suf.cient to de.ne non-overlapping symbolic execution ranges.  4. Evaluation To evaluate ranged \nsymbolic execution, we consider the following research questions: How does ranged symbolic execution \nin a sequential set\u00adting perform in comparison with standard symbolic exe\u00adcution?  How does ranged symbolic \nexecution in a parallel setting using statically de.ned ranges perform in comparison with standard symbolic \nexecution?  How does ranged symbolic execution in a parallel setting using dynamic range re.nement perform \nin comparison with using statically de.ned ranges?  How does ranged symbolic execution in a parallel \nsetting using dynamic range re.nement scale?  In the following subsections, we describe (1) the set \nof test programs we use, (2) our methodology, (3) the experi\u00admental results, and (4) the threats to validity. \n4.1 Subjects To evaluate ranged symbolic execution, we use GNU core utilities (Coreutils)1 the basic \n.le, shell, and text manipu\u00adlation core utilities for the GNU operating system. Coreutils are medium \nsized programs between 2000 and 6000 lines of code. Some of these programs do a particular task with \na lot of error checks and thus form a deep search tree while oth\u00aders perform multiple functions and form \na broad search tree. Deep trees likely provide less opportunity for ef.cient par\u00adallel analysis than \nbroad trees. These utilities provide a good mix of subject programs where parallelism in symbolic exe\u00adcution \nlikely helps for some but not others. Coreutils were also used in the evaluation of the KLEE tool [8]. \nAs we im\u00adplement ranged symbolic execution using KLEE, Coreutils provide a good benchmark for comparison \nwith KLEE. We ran KLEE on each program in Coreutils for ten min\u00adutes and chose the 71 utilities for which \nKLEE covered more than a hundred paths in this time. 4.2 Methodology In this section, we discuss our \nevaluation setup, how we ensure that all techniques cover the same paths for a fair comparison, how we \nde.ne static ranges, and how we setup work stealing. We performed the experiments on the Lonestar Linux \ncluster at the Texas Advanced Computing Center (TACC)2. TACC enables reliable experiments as the processors \nare fully allocated to one job at a time. Ranged symbolic execution and standard symbolic ex\u00adecution \ncover the same paths under a given depth bound. However, our experiments also use a time bound of 10 \nmin\u00adutes. Since ranged symbolic execution analyzes paths in par\u00ad 1 http://www.gnu.org/s/coreutils 2 http://tacc.utexas.edu \nallel starting from many starting points, the paths it covers in 10 minutes may not be the same as those \ncovered by standard symbolic execution on the same program in 10 minutes. To allow fair comparison we \nuse the last test generated by stan\u00addard symbolic execution as an upper bound for the ranged executions. \nThus, we ensure that every technique covers the same paths. The time of standard symbolic execution shown \nin the tables is calculated from the start of execution to when this last completed path was covered. \nFor evaluating the performance of ranged symbolic exe\u00adcution using static ranges, we choose nine tests \nat random from those generated using standard symbolic execution to de.ne ten ranges for ranged symbolic \nexecution. The end of the last range is .xed to the last test generated by stan\u00addard symbolic execution \n(as discussed above). As the per\u00adformance of ranged symbolic execution depends on the tests chosen randomly, \nwe repeat the random selection and ranged symbolic execution .ve times and .nd the minimum, maxi\u00admum, \nand average of the times taken. We also .nd the mini\u00admum, maximum, and average times for the range taking \nthe longest time for each set. For evaluating the performance of ranged symbolic exe\u00adcution using dynamic \nrange re.nement, we use 10 worker processors and 1 coordinator processor to symbolically ex\u00adecute the \nsame problem with no a priori division. This ex\u00adperiment is not repeated multiple times as there is no \nnon\u00addeterministic choice of ranges to be made. All ranges are dynamically formed. For evaluating how \nranged symbolic execution in a paral\u00adlel setting using dynamic range re.nement scales, we choose 15 programs \nand run parallel symbolic execution using 5, 10, and 20 workers. Speci.cally, we choose 5 programs that \ngave the worst speedup, 5 programs that gave the median speedup, and 5 programs that gave the best speedup \nusing dynamic range re.nement on 10 workers.  4.3 Experimental results Table 1 shows the results for \nall 71 programs we tested. The second column has time for standard symbolic execution us\u00ading KLEE. The \nthird column gives the minimum, maximum, and average times for covering the same paths divided into 10 \nranges at random. The fourth column has the minimum, maximum, and average time for the range taking the \nmost time using the same ranges. Note that while the total time is pretty close for different random \nranges, the time for the range taking the most time varies a lot. Thus, the bene.t of running in parallel \ndepends on how good a static range is. This restriction applies to other parallel schemes as well that \nuse static partitioning, e.g. [41]. The next column shows the calculated range of speedup achieved. The \nlast two columns have the time and speedup for 11 processors (10 workers and 1 coordinator) when performing \nparallel symbolic execution using work stealing. We chose 10 workers so that the times can be directly \ncompared to the times for 10 parallel workers using random static ranges (column 4).  Program Name Standard \nsymbolic execution time (s) Resumable sym\u00adbolic execution time (s) min / avg / max Parallel symbolic \nexecution using 10 workers using static random ranges using work stealing time (s) min / avg / max speedup \ntime (s) speedup base64 600 365 / 377 / 388 68 / 100 / 119 5.0 -8.8X 83 7.2X basename 156 110 / 115 / \n126 18 / 32 / 63 2.5 -8.6X 47 3.3X cat 600 465 / 497 / 518 114 / 175 / 247 2.4 -5.3X 90 6.6X chcon 596 \n401 / 438 / 479 233 / 251 / 283 2.1 -2.6X 193 3.1X chgrp 569 283 / 301 / 325 68 / 138 / 175 3.3 -8.4X \n41 13.8X chmod 550 243 / 256 / 267 73 / 78 / 88 6.2 -7.6X 46 12.0X chown 598 263 / 283 / 300 64 / 87 \n/ 120 5.0 -9.4X 41 14.4X chroot 599 358 / 393 / 414 102 / 151 / 238 2.5 -5.8X 330 1.8X comm 607 730 / \n929 / 1125 338 / 472 / 599 1.0 -1.8X 630 1.0X cp 600 231 / 264 / 290 58 / 120 / 175 3.4 -10.3X 56 10.8X \ncsplit 601 349 / 366 / 387 105 / 162 / 196 3.1 -5.7X 57 10.5X cut 600 427 / 442 / 465 144 / 171 / 221 \n2.7 -4.2X 105 5.7X date 278 252 / 260 / 275 83 / 113 / 130 2.1 -3.3X 84 3.3X dd 601 353 / 379 / 402 121 \n/ 162 / 195 3.1 -5.0X 278 2.2X df 341 151 / 153 / 154 38 / 59 / 69 5.0 -8.9X 49 7.0X dircolors 600 460 \n/ 468 / 485 101 / 147 / 198 3.0 -5.9X 113 5.3X dirname 618 628 / 701 / 758 377 / 534 / 616 1.0 -1.6X \n574 1.1X du 601 482 / 540 / 578 134 / 180 / 232 2.6 -4.5X 115 5.2X echo 600 400 / 419 / 441 112 / 156 \n/ 203 3.0 -5.3X 101 6.0X env 600 492 / 503 / 512 114 / 171 / 236 2.5 -5.3X 116 5.2X expand 600 334 / \n352 / 367 60 / 110 / 169 3.6 -10.1X 59 10.2X factor 609 609 / 622 / 640 93 / 156 / 185 3.3 -6.5X 540 \n1.1X fmt 601 743 / 781 / 826 142 / 176 / 215 2.8 -4.2X 255 2.4X fold 600 216 / 227 / 246 62 / 73 / 83 \n7.3 -9.7X 45 13.3X ginstall 596 429 / 451 / 500 105 / 163 / 232 2.6 -5.7X 281 2.1X groups 588 658 / 667 \n/ 686 130 / 169 / 214 2.7 -4.5X 350 1.7X head 600 229 / 282 / 380 42 / 111 / 246 2.4 -14.3X 85 7.1X id \n600 257 / 270 / 293 104 / 125 / 140 4.3 -5.7X 49 12.3X join 594 499 / 530 / 582 108 / 131 / 162 3.7 -5.5X \n192 3.1X kill 600 207 / 214 / 223 43 / 65 / 107 5.6 -13.9X 76 7.9X ln 600 179 / 213 / 255 38 / 99 / 166 \n3.6 -16.0X 53 11.4X mkdir 596 605 / 735 / 847 259 / 313 / 400 1.5 -2.3X 474 1.3X mknod 609 549 / 790 \n/ 1134 485 / 555 / 662 0.9 -1.3X 572 1.1X mktemp 600 352 / 375 / 402 197 / 212 / 256 2.3 -3.1X 240 2.5X \nmv 598 438 / 482 / 601 257 / 305 / 335 1.8 -2.3X 353 1.7X nice 600 254 / 299 / 368 80 / 153 / 255 2.3 \n-7.5X 64 9.4X nl 600 253 / 285 / 330 72 / 141 / 210 2.9 -8.3X 53 11.3X nohup 601 323 / 365 / 422 107 \n/ 185 / 276 2.2 -5.6X 290 2.1X od 601 609 / 637 / 654 120 / 209 / 264 2.3 -5.0X 122 4.9X paste 600 380 \n/ 397 / 433 85 / 130 / 206 2.9 -7.1X 83 7.3X pathchk 599 313 / 364 / 442 100 / 169 / 208 2.9 -6.0X 178 \n3.4X pinky 600 173 / 198 / 227 47 / 67 / 81 7.4 -12.7X 46 13.1X pr 601 538 / 580 / 606 93 / 169 / 237 \n2.5 -6.4X 108 5.6X printenv 588 337 / 549 / 749 96 / 251 / 352 1.7 -6.2X 46 12.8X printf 598 188 / 219 \n/ 273 53 / 81 / 121 4.9 -11.3X 46 12.9X readlink 600 247 / 266 / 305 86 / 108 / 137 4.4 -7.0X 41 14.7X \nrm 603 344 / 375 / 392 109 / 148 / 194 3.1 -5.6X 185 3.3X runcon 598 227 / 252 / 280 54 / 86 / 141 4.2 \n-11.2X 55 10.8X seq 600 287 / 312 / 333 90 / 110 / 133 4.5 -6.6X 105 5.7X setuidgid 600 507 / 552 / 623 \n95 / 156 / 206 2.9 -6.3X 253 2.4X sha1sum 600 312 / 324 / 332 72 / 111 / 144 4.2 -8.4X 70 8.6X shred \n600 334 / 397 / 452 96 / 154 / 203 2.9 -6.3X 95 6.3X shuf 600 338 / 358 / 380 82 / 114 / 142 4.2 -7.3X \n74 8.1X split 600 496 / 513 / 524 134 / 206 / 254 2.4 -4.5X 123 4.9X stat 599 246 / 268 / 290 73 / 88 \n/ 104 5.8 -8.2X 79 7.6X stty 601 154 / 170 / 183 37 / 49 / 74 8.2 -16.5X 63 9.6X su 418 331 / 340 / 348 \n115 / 134 / 143 2.9 -3.6X 300 1.4X sum 600 240 / 282 / 340 86 / 136 / 204 2.9 -7.0X 52 11.5X tac 602 \n381 / 480 / 579 210 / 313 / 406 1.5 -2.9X 160 3.8X tail 600 349 / 369 / 397 102 / 152 / 204 2.9 -5.9X \n81 7.4X tee 600 280 / 306 / 336 84 / 128 / 207 2.9 -7.1X 50 12.0X touch 561 312 / 333 / 371 81 / 115 \n/ 157 3.6 -7.0X 282 2.0X tr 597 497 / 638 / 730 395 / 459 / 583 1.0 -1.5X 569 1.0X tsort 600 541 / 545 \n/ 551 113 / 153 / 189 3.2 -5.3X 121 5.0X tty 588 517 / 530 / 556 174 / 222 / 308 1.9 -3.4X 294 2.0X uname \n599 156 / 194 / 230 31 / 71 / 109 5.5 -19.3X 34 17.7X unexpand 600 508 / 528 / 541 102 / 148 / 196 3.1 \n-5.9X 121 5.0X uniq 600 370 / 391 / 430 119 / 150 / 175 3.4 -5.0X 58 10.3X vdir 596 377 / 440 / 553 162 \n/ 263 / 425 1.4 -3.7X 125 4.8X wc 600 555 / 570 / 591 109 / 136 / 187 3.2 -5.5X 125 4.8X who 600 304 \n/ 332 / 377 69 / 123 / 225 2.7 -8.8X 70 8.6X Average 581 371 / 409 / 454 117 / 166 / 220 3.3 -6.8X 160 \n6.6X Table 1. Ranged symbolic execution for resumable and parallel checking for 71 program from GNU \nCoreutils suite of Unix utilities. At times the speedup is greater than 10X because of optimal use of \ncaches in KLEE. KLEE is likely more ef.cient at solving multiple smaller problems than a single large \nproblem. 15X 8X 1X  commtrdirnamefactor mknod mkdir su groupsmvchroot touch ttyginstallnohupddfmt setuidgid \nmktempchcon join basenamedate rmpathchktacvdir wcod split tsort unexpanddu envdircolors prcut seqechoshredcatdfheadbase64 \npastetail statkillshuf sha1sum who nice sttyexpanduniqcsplit cprunconnl ln sumchmodteeidprintenvprintfpinkyfold \nchgrpchown readlink uname Figure 3. Speedup with 10 worker nodes using ranged symbolic execution for \n71 program from GNU Coreutils suite of Unix utilities. Vertical bars show the range of speedup achieved \nusing different random static ranges with the average pointed out. The line shows the speedup achieved \nusing dynamic load balancing using work stealing. Program Name Serial time(s) 5+1p 10+1p 20+1p time(s) \nspeedup time(s) speedup time(s) speedup comm 607 573 1.1X 630 1.0X 514 1.2X tr 597 509 1.2X 569 1.0X \n595 1.0X dirname 618 567 1.1X 574 1.1X 526 1.2X factor 609 557 1.1X 540 1.1X 482 1.3X mknod 609 593 1.0X \n572 1.1X 505 1.2X dircolors 600 142 4.2X 113 5.3X 95 6.3X pr 601 138 4.4X 108 5.6X 86 7.0X cut 600 130 \n4.6X 105 5.7X 67 9.0X seq 600 129 4.7X 105 5.7X 102 5.9X echo 600 139 4.3X 101 6.0X 38 15.8X fold 600 \n62 9.7X 45 13.3X 32 18.8X chgrp 569 74 7.7X 41 13.8X 39 14.6X chown 598 68 8.8X 41 14.4X 39 15.3X readlink \n600 63 9.5X 41 14.7X 34 17.6X uname 599 48 12.5X 34 17.7X 27 22.2X Average 600.5 252.8 5.1X 241.3 7.2X \n212.1 9.2X Table 2. Ranged symbolic execution with work stealing for 15 programs from GNU Coreutils \non different number of workers. The +1 designates a separate coordinator node. These are the worst 5, \nmedian 5, and best 5 utilities from Figure 3 based on performance on 10 workers. Speedup for parallel \nsymbolic execution using work stealing ranges from 1.0X (no speedup) to 17.7X. As 17.7 is more than the \nnumber of workers, we investigated and found that KLEE uses a lot of internal caches which can perform \nmuch better when they are of a smaller size. Thus, KLEE is likely more ef.cient at solving smaller problems \nthan one big problem. This is intuitive as symbolic execution main\u00adtains a lot of internal state and \nmemory maps with frequent search operations. These search operations become more ef\u00ad.cient for smaller \nproblems (with or without caching). Thus, ranged symbolic execution often makes KLEE faster even when \nall ranges are executed sequentially. We also note that 13 of the 71 utilities observed a slowdown in \nat least one run in a resumable setting. However, on average (last row in Table 1), even the worst resumable \nrun is faster than a standard execution. Thus, in most cases, we observe better performance with resumable \nsymbolic execution. Figure 3 contains a plot of the speedup of all 71 utilities ordered by the speedup \nachieved using work stealing. The line graph shows the speedup for parallel symbolic execution using \nwork stealing, while the vertical lines show the range of speedup for parallel symbolic execution using \nstatic ran\u00addom ranges. The dot on the vertical line shows the average speedup for static ranges. Note \nthat for a third of the sub\u00adject programs, work stealing gives a speedup similar to the minimum speedup \nachieved using static ranges while for the other two thirds, it is about the maximum speedup achieved \nusing static ranges or even more. We believe that the .rst set of programs have narrow and deep trees \nwhile the second set of programs have broad trees that enable better parallelism. Table 2 shows the results \nof running work stealing based ranged symbolic execution on a smaller set of 15 programs using 5, 10, \nand 20 workers with 1 coordinator processor and compares it to the performance of analyzing sequentially. \nData for 1 and 10 processors is taken from Table 1. This data is plotted in Figure 4. These are the 5 \nworst, 5 median, and 5 best performing programs in the .rst experiment as discussed in Section 4.2. The \n5 programs that performed worst in the .rst experiment do not gain anything from more processors and \nhardly give any further speedup. Most of  22X 15X 8X 1X Figure 4. Speedup achieved by 15 programs from \nGNU Coreutils on different number of workers for ranged sym\u00adbolic execution with work stealing. These \nare the worst 5, median 5, and best 5 utilities from Figure 3 based on perfor\u00admance on 10 workers. The \nworst 5 overlap at or near 1.0X and are hard to distinguish. the other 10 programs, however, gained more \nspeedup. The speedup possible using any parallel technique for symbolic execution is restricted by the \nprogram structure. If a program has a deep and narrow execution tree (e.g., one main path and only branching \nfor error checks), then one or a few paths take nearly as much time as the time for complete analysis. \nAny scheme that completely checks one path on one processor is unlikely to improve performance of such \nprograms.  4.4 Threats to validity We tested our technique on one set of programs. It is possible that \nother programs exhibit different behavior. We mitigate this threat by choosing a suite of medium sized \nprograms and then considering all of them. This can be seen in the results where we achieve a speedup \nof 1X (no speedup) to over 17X. We selected random paths as range boundaries. We ex\u00adpect that in real \nscenarios, it might be more meaningful to divide ranges using tests from some manual test suite. It is \npossible that such ranges from manual tests provide much worse or much better performance. We mitigate \nthis threat by repeating the random selection multiple times and report\u00ading the range of speedups in \nboth Table 1 and Figure 3. 5. Related Work Symbolic execution. Clarke [10] and King [24] pioneered traditional \nsymbolic execution for imperative programs with primitive types. Much progress has been made on symbolic \nexecution during the last decade. PRE.x [5] is among the .rst systems to show the bug .nding ability \nof symbolic execution on real code. Generalized symbolic execution [23] de.nes symbolic execution for \nobject-oriented code and uses lazy initialization to handle pointer aliasing. Symbolic execution guided \nby concrete inputs has been a topic of extensive investigation during the last seven years. DART [16] \ncombines concrete and symbolic execu\u00adtion to collect the branch conditions along the execution path. \nDART negates the last branch condition to construct a new path condition that can drive the function \nto execute on another path. DART focuses only on path conditions in\u00advolving integers. To overcome the \npath explosion in large programs, SMART [15] introduced inter-procedural static analysis techniques to \ncompute procedure summaries and reduce the paths to be explored by DART. CUTE [34] ex\u00adtends DART to handle \nconstraints on references. EGT [6] and EXE [7] also use the negation of branch predicates and symbolic \nexecution to generate test cases. They increase the precision of symbolic pointer analysis to handle \npointer arithmetic and bit-level memory locations. KLEE [8] is the most recent tool from the EGT/EXE \nfamily. KLEE is open-sourced and has been used by a variety of users in academia and industry. KLEE works \non LLVM byte code [1]. It works on unmodi.ed programs written in C/C++ and has been shown to work for \nmany off the shelf programs. Ranged symbolic execution uses KLEE as an enabling technology. A couple \nof recent research projects have proposed tech\u00adniques for parallel symbolic execution [37, 41]. ParSym \n[37] parallelized symbolic execution by treating every path ex\u00adploration as a unit of work and using \na central server to dis\u00adtribute work between parallel workers. While this technique implements a direct \napproach for parallelization [7, 17], it re\u00adquires communicating symbolic constraints for every branch \nexplored among workers, which incurs a higher overhead. In contrast, static partitioning [41] uses an \ninitial shallow run of symbolic execution to minimize the communication overhead during parallel symbolic \nexecution. The key idea is to create pre-conditions using conjunctions of clauses on path conditions \nencountered during the shallow run and to restrict symbolic execution by each worker to program paths \nthat satisfy the pre-condition for that worker s path explo\u00adration. However, the creation of pre-conditions \nresults in different workers exploring overlapping ranges, which re\u00adsults in wasted effort. Moreover, \nstatic partitioning does not use work stealing. In contrast to these existing techniques, ranged symbolic \nexecution uses dynamic load balancing, en\u00adsures workers have no overlap (other than on the paths that \nde.ne range boundaries), and keeps the communication low. Conceptually it is easy to implement approaches \nsuch as DART, CUTE, and KLEE in a parallel setting using fork\u00ading on every branch. However, doing so \nis unlikely to be feasible as it would require spawning processes (or threads with expensive locking) \nproportional to the number of paths in the program. As observed in previous work [37, 41], the more the \nnumber of parallel work items, the poorer the per\u00adformance because of high overhead. ParSym [37] notes \nthe high communication overheads because of exploring paths separately. A scheme like forking for each \npath would not be ef.cient because 1) forking across machines is a very costly operation, 2) even on \nthe same machine, forking symbolic execution is costly as the address space of the symbolically executed \nprogram will incur heavy copy-on-write penalties because of the way symbolic execution explores code \npaths, and 3) no shared caches for solutions of partial clauses etc. can be made. As an example, KLEE \ngets more than 10X slower if its caching is disabled.  KleeNet [33] uses KLEE to .nd interaction bugs \nin dis\u00adtributed applications by running the distributed components under separate KLEE instances and \ncoordinating them using a network model. KleeNet performs separate symbolic exe\u00adcution tasks of each \ncomponent of the distributed application in parallel. However, it has no mechanism of parallelizing a \nsingle symbolic execution task. Hybrid concolic testing [28] uses random search to pe\u00adriodically guide \nsymbolic execution to increase code cov\u00aderage. However, it explores overlapping ranges when hop\u00adping \nfrom symbolic execution in one area of code to another, since no exploration boundaries are de.ned (other \nthan time out). Ranged symbolic execution can in fact enable a novel form of hybrid concolic testing, \nwhich avoids overlapping ranges by hopping outside of the ranges already explored and not re-entering \nthem. Staged symbolic execution [38] is a technique to apply symbolic execution in stages, rather than \nthe traditional ap\u00adproach of applying it all at once, to compute abstract sym\u00adbolic inputs that can later \nbe shared across different methods to test them systematically. Staged symbolic execution con\u00adceptually \ndivides symbolic execution in horizontal slices called stages that can be executed sequentially. On the \nother hand, ranged symbolic execution conceptually divides symbolic execution in vertical slices called \nranges that can be explored in parallel. Directed incremental symbolic execution [31] leverages differences \namong program versions to optimize symbolic execution of affected paths that may exhibit modi.ed behav\u00adior. \nThe basic motivation is to avoid symbolically executing paths that have already been explored in a previous \nprogram version that was symbolically executed. A reachability anal\u00adysis is used to identify affected \nlocations, which guide the symbolic exploration. More recently, memoized symbolic execution [44] presents \na novel technique to re-use results of a previous run of symbolic execution by storing them in a trie-based \ndata structure and re-using them by maintaining and updating the trie in the next run of symbolic execution \non the modi.ed program. We believe ranged symbolic exe\u00adcution can provide an alternative technique for \nincremental symbolic execution where program edits are wrapped in test pairs that are computed based \non the edit locations and the pairs provide the ranges for symbolic execution. Other parallel techniques \nfor dynamic analysis. Korat [4] is a tool for constraint-based test input generation, which was parallelized \nusing two approaches [29, 36]. Given a Java predicate that represents desired input constraints and a \nbound on input size, Korat generates desired test inputs as object graphs that satisfy the constraints \nusing execution\u00addriven pruning. Korat internally uses a candidate vector to represent candidate inputs, \nwhich are checked for validity and either generated as desired tests or .ltered out and used for pruning \nthe search space. Korat s candidate vector repre\u00adsentation is compact and provides a succinct and precise \nen\u00adcoding of the state of Korat search a candidate vector par\u00adtitions the search space into (1) unexplored \nspace and (2) ex\u00adplored or pruned space. This property formed the key insight into the .rst approach \nfor parallel Korat [29]. Korat draws much of its ef.ciency by using the execution of the given predicate \non the current candidate input to decide what can\u00addidate input to generate next, which allows it to prune \nlarge parts of search space. However, this step makes the Korat search inherently sequential, which makes \nparallelizing Ko\u00adrat hard. Nonetheless, at each such step, a set of candidates that will certainly get \nexplored in future is already de.ned. A more recent parallel approach [36] simply forks off the Korat \nsearch at such steps when idle workers are available. To our knowledge, the Korat algorithm is the only \nanalysis that has previous to this paper been shown to exhibit a suc\u00adcinct representation of the analysis \nstate and parallelized by leveraging that representation [29]. Parallel model checkers have also been \ndeveloped. Stern and Dill s parallel Murf [42] is an example of a parallel model checker. It keeps the \nset of visited states shared be\u00adtween parallel workers so that the same parts of the state space are \nnot searched by multiple workers. Keeping this set synchronized between the workers results in expensive \ncom\u00admunication so the algorithm does not scale well. A similar technique was used by Lerda and Visser \n[43] to parallelize the Java PathFinder model checker [27]. Parallel version of the SPIN model checker \n[19] was produced by Lerda and Sisto [26]. More work has been done in load bal\u00adancing and reducing worker \ncommunication in these algo\u00adrithms [21, 25, 30]. Parallel Randomized State Space Search for JPF by Dwyer \net al. [12] takes a different approach with workers exploring randomly different parts of the state space. \nThis often speeds up time to .nd .rst error with no worker communication. However when no errors are \npresent, every worker has to explore every state. Parallel search algorithms in general have been studied \n[18, 20, 22] even earlier. 6. Future work We envision a number of exciting new research avenues that \nbuild on this paper. The notion of sorting execution paths and the corresponding test inputs can enable \nnovel techniques for regression testing, e.g., by using binary search an elemen\u00adtary algorithm on a sorted \ntest suite, say to .nd the small\u00adest and largest paths that enclose the changed code and identify an \nimpacted range. Developing the idea of pausing and resuming an analysis using a succinct representation \nof the analysis state can be generalized to other program anal\u00adysis techniques to address a key practical \nproblem in pro\u00adgram analysis, namely how to proceed if an analysis run times out? . Ranging the run of \nan analysis can allow de\u00advelopment of novel methods for applying different program analysis techniques \nin synergy, e.g., where each technique handles its speci.c range(s), to further scale effective check\u00ading \nof complex programs. The insights into ranged symbolic execution can help develop novel forms of ranged \nanalysis for other techniques, e.g., a run of a software model checker can be ranged [14] using sequences \nof choices along exe\u00adcution paths, thereby conceptually restricting the run using vertical boundaries, \nwhich contrasts with the traditional approach of using a horizontal boundary, i.e., the search depth \nbound, and can provide an effective way to deal with the state-space explosion problem.  7. Conclusions \nThe connection between symbolic execution and test inputs speci.cally, to use symbolic execution to generate \ninputs was .rst established over three decades ago, and since then, has undergone extensive and thorough \nresearch investiga\u00adtion. But this connection remains conceptually in just one di\u00adrection: from symbolic \nexecution to tests. The novelty of our work is to de.ne the connection in the opposite direction from \na test input to symbolic execution speci.cally, to use a test input to encode the state of a run of symbolic \nexecution and show how this direction enables a number of novel approaches for more effective symbolic \nexecution for test input generation. The focus of this paper was on our approach to range symbolic execution \nusing two tests, which enables (statically and dynamically) partitioning the symbolic execution prob\u00adlem \ninto several sub-problems for scalability. As an enabling technology we leveraged the open-source tool \nKLEE, which is a state-of-the-art tool for symbolic execution. Experimen\u00adtal results using 71 programs \nchosen from the widely de\u00adployed GNU Coreutils set of Unix utilities show that our approach provides \na signi.cant speedup over KLEE. For ex\u00adample, using 10 worker cores, we achieve an average speed\u00adup of \n6.6X for the 71 programs. We believe our encoding of the state of an analysis run using a single test \ninput and our ranging of an analysis using two test inputs will provide a foundation for new scalable \napproaches for more effective symbolic execution. We hope such approaches will also be developed for \nother analysis techniques, such as software model checking and sound static analysis, and lead to a veri.cation \ntool-set that enables the development of more reliable software at a much reduced cost. Acknowledgments \nWe thank Lingming Zhang and the anonymous reviewers for detailed and helpful comments. This material \nis based upon work partially supported by the Fulbright program, the Na\u00adtional Science Foundation under \nGrant No. CCF-0845628, and AFOSR grant FA9550-09-1-0351. References [1] V. Adve, C. Lattner, M. Brukman, \nA. Shukla, and B. Gaeke. LLVA: A Low-level Virtual Instruction Set Architecture. In Proc. 36th International \nSymposium on Microarchitecture (MICRO), pages 205 216, 2003. [2] S. Anand, C. S. P.areanu, and W. Visser. \nJPF-SE: a Symbolic as.Execution Extension to Java PathFinder. In Proc. 13th , pages 134 138, 2007. [3] \nC. Barrett and C. Tinelli. CVC3. In Proc. 19th Inter\u00adnational Conference on Computer Aided Veri.cation \n(CAV), pages 298 302, 2007. [4] C. Boyapati, S. Khurshid, and D. Marinov. Korat: Automated Testing based \non Java Predicates. In Proc. 2002 International Symposium on Software Testing and Analysis (ISSTA), pages \n123 133, 2002. [5] W. R. Bush, J. D. Pincus, and D. J. Sielaff. A Static Analyzer for Finding Dynamic \nProgramming Errors. Software Practice Experience , 30(7):775 802, June 2000. [6] C. Cadar and D. Engler. \nExecution Generated Test Cases: How to make systems code crash itself. In Proc. International SPIN Workshop \non Model Checking of Software , pages 2 23, 2005. [7] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill, \nand D. R. Engler. EXE: Automatically Generating Inputs of Death. In Proc. 13th Conference on Computer \nand Communications Security (CCS), pages 322 335, 2006. [8] C. Cadar, D. Dunbar, and D. R. Engler. KLEE: \nUnassisted and Automatic Generation of High-Coverage Tests for Complex Systems Programs. In Proc. 8th \nSymposium on Operating Systems Design and Implementation (OSDI), pages 209 224, 2008. [9] L. A. Clarke. \nA System to Generate Test Data and Symboli\u00adcally Execute Programs. IEEE Transactions on Software En\u00adgineering \n, 2(3):215 222, May 1976. [10] L. A. Clarke. Test Data Generation and Symbolic Execution of Programs \nas an aid to Program Validation. PhD thesis, University of Colorado at Boulder, 1976. [11] L. de Moura \nand N. Bj\u00f8rner. Z3: An Ef.cient SMT Solver. In International Conference on Tools and Algorithms for the \nConstruction and Analysis of Systems (TACAS), pages 337 340, 2008. [12] M. B. Dwyer, S. Elbaum, S. Person, \nand R. Purandare. Par\u00adallel Randomized State-Space Search. In Proc. 2007 Inter\u00adnational Conference on \nSoftware Engineering (ICSE), pages 3 12, 2007. [13] B. Elkarablieh, I. Garcia, Y. L. Suen, and S. Khurshid. \nAssertion-based Repair of Complex Data Structures. In Proc.  22nd International Conference on Automated \nSoftware Engi\u00adneering (ASE), pages 64 73, 2007. [14] D. Funes, J. H. Siddiqui, and S. Khurshid. Ranged \nmodel checking. Under submission. [15] P. Godefroid. Compositional Dynamic Test Generation. In Proc. \nSymposium on Principles of Programming Languages (POPL), pages 47 54, 2007. [16] P. Godefroid, N. Klarlund, \nand K. Sen. DART: Directed Automated Random Testing. In Proc. 2005 Conference on Programming Languages \nDesign and Implementation (PLDI), pages 213 223, 2005. [17] P. Godefroid, M. Y. Levin, and D. A. Molnar. \nAutomated Whitebox Fuzz Testing. In Proc. Network and Distributed System Security Symposium (NDSS), 2008. \n[18] A. Grama and V. Kumar. State of the Art in Parallel Search Techniques for Discrete Optimization \nProblems. IEEE Trans\u00adactions on Knowledge and Data Engineering , 11(1):28 35, Jan. 1999. [19] G. J. Holzmann. \nThe Model Checker SPIN. IEEE Transac\u00adtions on Software Engineering , 23(5):279 295, May 1997. [20] V. \nK. Janakiram, D. P. Agrawal, and R. Mehrotra. A Random\u00adized Parallel Backtracking Algorithm. IEEE Transactions \non Computers, 37(12):1665 1676, Dec. 1988. [21] M. D. Jones and J. Sorber. Parallel Search for LTL Violations. \nInternational Journal Software Tools Technology Transfer ,7 (1):31 42, Feb. 2005. [22] R. M. Karp and \nY. Zhang. Randomized Parallel Algorithms for Backtrack Search and Branch-and-bound Computation. Journal \nof the ACM, 40(3):765 789, July 1993. [23] S. Khurshid, C. S. Pasareanu, and W. Visser. Generalized Symbolic \nExecution for Model Checking and Testing. In Proc. 9th International Conference on Tools and Algorithms \nfor the Construction and Analysis of Systems (TACAS), pages 553 568, 2003. [24] J. C. King. Symbolic \nExecution and Program Testing. Com\u00admunications ACM, 19(7):385 394, July 1976. [25] R. Kumar and E. G. \nMercer. Load Balancing Parallel Explicit State Model Checking. Electronics Notes Theory Computer Science \n, 128(3):19 34, Apr. 2005. [26] F. Lerda and R. Sisto. Distributed-Memory Model Checking with SPIN. In \nProc. 5th International SPIN Workshop on Model Checking of Software , pages 22 39, 1999. [27] F. Lerda \nand W. Visser. Addressing Dynamic Issues of Pro\u00adgram Model Checking. In Proc. 8th International SPIN \nWork\u00adshop on Model Checking of Software , pages 80 102, 2001. [28] R. Majumdar and K. Sen. Hybrid Concolic \nTesting. In Proc. 29th International Conference on Software Engineering (ICSE), pages 416 426, 2007. \n[29] S. Misailovic, A. Milicevic, N. Petrovic, S. Khurshid, and D. Marinov. Parallel Test Generation \nand Execution with Korat. In Proc. 6th joint meeting of the European Software Engineering Conference \nand Symposium on Foundations of Software Engineering (ESEC/FSE), pages 135 144, 2007. [30] R. Palmer \nand G. Gopalakrishnan. A Distributed Partial Order Reduction Algorithm. In Proc. 22nd International Conference \non Formal Techniques for Networked and Distributed Systems (FORTE), page 370, 2002. [31] S. Person, G. \nYang, N. Rungta, and S. Khurshid. Directed In\u00adcremental Symbolic Execution. In Proc. 2011 Conference \non Programming Languages Design and Implementation (PLDI), pages 504 515, 2011. [32] D. A. Ramos and \nD. R. Engler. Practical, Low-Effort Equiv\u00adalence Veri.cation of Real Code. In Proc. 23rd International \nConference on Computer Aided Veri.cation (CAV), pages 669 685, 2011. [33] R. Sasnauskas, O. Landsiedel, \nM. H. Alizai, C. Weise, S. Kowalewski, and K. Wehrle. KleeNet: Discovering In\u00adsidious Interaction Bugs \nin Wireless Sensor Networks Before Deployment. In Proc. 9th International Conference on In\u00adformation \nProcessing in Sensor Networks (ISPN 2010), pages 186 196, 2010. [34] K. Sen, D. Marinov, and G. Agha. \nCUTE: A Concolic Unit Testing Engine for C. In Proc. 5th joint meeting of the European Software Engineering \nConference and Symposium on Foundations of Software Engineering (ESEC/FSE), pages 263 272, 2005. [35] \nC. Seo, S. Malek, and N. Medvidovic. Component-Level Energy Consumption Estimation for Distributed Java-Based \nSoftware Systems. In Proc. 11th International Symposium on Component-Based Software Engineering, pages \n97 113, 2008. [36] J. H. Siddiqui and S. Khurshid. PKorat: Parallel Generation of Structurally Complex \nTest Inputs. In Proc. 2nd International Conference on Software Testing Veri.cation and Validation (ICST), \npages 250 259, 2009. [37] J. H. Siddiqui and S. Khurshid. ParSym: Parallel Symbolic Execution. In Proc. \n2nd International Conference on Software Technology and Engineering (ICSTE), pages V1: 405 409, 2010. \n[38] J. H. Siddiqui and S. Khurshid. Staged Symbolic Execution. In Proc. Symposium on Applied Computing \n(SAC): Software Veri.cation and Testing Track (SVT), 2012. [39] M. Snir and S. Otto. MPI-The Complete \nReference: The MPI Core. MIT Press, 1998. [40] N. S\u00a8orensson and N. Een. An Extensible SAT-solver. In \nProc. 6th International Conference on Theory and Applications of Satis.ability Testing (SAT), pages 502 \n518, 2003. [41] M. Staats and C. P.as.areanu. Parallel Symbolic Execution for Structural Test Generation. \nIn Proc. 19th International Symposium on Software Testing and Analysis (ISSTA), pages 183 194, 2010. \n[42] U. Stern and D. L. Dill. Parallelizing the Murphi Veri.er. In Proc. 9th International Conference \non Computer Aided Veri.cation, pages 256 278, 1997. [43] W. Visser, K. Havelund, G. Brat, S. P. Park, \nand F. Lerda. Model Checking Programs. Automated Software Engineering Journal , 10(2):203 232, Apr. 2003. \n[44] G. Yang, C. Pasareanu, and S. Khurshid. Memoized symbolic execution. In Proc. International Symposium \non Software Testing and Analysis (ISSTA), pages 144 154, 2012.   \n\t\t\t", "proc_id": "2384616", "abstract": "<p>This paper introduces a novel approach to scale symbolic execution --- a program analysis technique for systematic exploration of bounded execution paths---for test input generation. While the foundations of symbolic execution were developed over three decades ago, recent years have seen a real resurgence of the technique, specifically for systematic bug finding. However, scaling symbolic execution remains a primary technical challenge due to the inherent complexity of the path-based exploration that lies at core of the technique.</p> <p>Our key insight is that the state of the analysis can be represented highly compactly: a test input is all that is needed to effectively encode the state of a symbolic execution run. We present ranged symbolic execution, which embodies this insight and uses two test inputs to define a range, i.e., the beginning and end, for a symbolic execution run. As an application of our approach, we show how it enables scalability by distributing the path exploration---both in a sequential setting with a single worker node and in a parallel setting with multiple workers. As an enabling technology, we leverage the open-source, state-of-the-art symbolic execution tool KLEE. Experimental results using 71 programs chosen from the widely deployed GNU Coreutils set of Unix utilities show that our approach provides a significant speedup over KLEE. For example, using 10 worker cores, we achieve an average speed-up of 6.6X for the 71 programs.</p>", "authors": [{"name": "Junaid Haroon Siddiqui", "author_profile_id": "81435605664", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P3856125", "email_address": "jsiddiqui@utexas.edu", "orcid_id": ""}, {"name": "Sarfraz Khurshid", "author_profile_id": "81100052115", "affiliation": "The University of Texas at Austin, Austin, TX, USA", "person_id": "P3856126", "email_address": "khurshid@ece.utexas.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384654", "year": "2012", "article_id": "2384654", "conference": "OOPSLA", "title": "Scaling symbolic execution using ranged analysis", "url": "http://dl.acm.org/citation.cfm?id=2384654"}