{"article_publication_date": "10-19-2012", "fulltext": "\n Program Extrapolation with Jennisys K. Rustan M. Leino Aleksandar Milicevic Microsoft Research Massachusetts \nInstitute of Technology (MIT) Redmond, WA, USA Cambridge, MA, USA leino@microsoft.com aleks@csail.mit.edu \n Abstract The desired behavior of a program can be described using an abstract model. Compiling such \na model into executable code requires advanced compilation techniques known as synthesis. This paper \npresents an object-based language, called Jennisys, where programming is done by introducing an abstract \nmodel, de.ning a concrete data representation for the model, and then being aided by automatic synthesis \nto produce executable code. The paper also presents a syn\u00adthesis technique for the language. The technique \nis built on an automatic program veri.er that, via an underlying SMT solver, is capable of providing \nconcrete models to failed veri.cations. The technique proceeds by obtaining sample input/output values \nfrom concrete models and then extrapo\u00adlating programs from the sample points. The synthesis aims to produce \ncode with assignments, branching structure, and possibly recursive calls. It is the .rst to synthesize \ncode that creates and uses objects in dynamic data structures or ag\u00adgregate objects. A prototype of the \nlanguage and synthesis technique has been implemented. Categories and Subject Descriptors D.1.2 [PROGRAM-MING \nTECHNIQUES]: Automatic Programming General Terms program synthesis, programming language design, program \nveri.cation Keywords abstract speci.cations, concrete representations, coupling invariants, preconditions, \nJennisys, Dafny 0. Introduction One important approach to ensuring program correctness is to raise the \nlevel of abstraction provided by programming languages. If a language lends itself to clean descriptions \nof solutions in the problem domain, then a programmer may be more likely to get programs correct. Two \ndesiderata in this Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, USA. Copyright c &#38;#169; 2012 ACM 978-1-4503-1561-6/12/10. \n. . $10.00 approach, which may seem to be at odds with each other, are (D0) allowing higher-level descriptions \nof programs in a general-purpose programming language and (D1) allow\u00ading ef.cient run-time representations \nof programs [22]. In this paper, we present a language framework that combines these two. The language \nis called Jennisys, and because it al\u00adlows program designs to be recorded ahead of their concrete implementations, \nthe language slogan is This is where pro\u00adgrams begin . Most programming languages provide some delineation \nbetween the public speci.cation of a procedure, type, or module and the private implementation thereof. \nIn some cases, a public speci.cation consists of just a type signature; in other cases, it may include \na behavioral contract [5, 18]. Jennisys takes the delineation a step further, dividing every program \ncomponent (or class, if you will) into three parts, which allows a separation between data-structure \nde.nitions and code. The .rst part of a Jennisys component is the public in\u00adterface (cf. Fig. 0, the \ninterface declaration). It de.nes an abstract model of the component, given in terms of vari\u00adables whose \ntypes are often mathematical structures, like sets and sequences. The public interface also de.nes the \ncomponent s operations and the behavioral effects of these, typically given in terms of simple code snippets \nthat act on the model variables. The model variables and the code act\u00ading on these describe the component, \nbut are not compiled as part of the run-time manifestation of the program. The second part describes \nthe data structure used to rep\u00adresent the component at run time (cf. Fig. 1, the datamodel declaration). \nMore speci.cally, it declares concrete variables (object .elds, if you will) that are part of each instance \nof the component, gives an account of which other compo\u00adnent instances are part of the representation \n(this is called the frame), and speci.es an invariant that both constrains the concrete variables and \nframe and couples these with the model variables in the public interface. The third part of a Jennisys \ncomponent is responsible for the executable code that will implement the component op\u00aderations (e.g. \ncode IntSet{}). The vision is for the language to provide the programmer with a variety of ways to pro\u00adduce \nthe code, including automatic code synthesis (which interface IntSet { var elems: set[int] constructor \nSingleton(x: int) elems := {x} constructor Dupleton(x: int,y: int) requires x = y elems := {x y} method \nFind(x: int) returns (ret: bool) ret := x . elems } Figure 0. A Jennisys public interface IntSet that \nabstractly de.nes an integer set data structure. datamodel IntSet { var data: int var left: IntSet var \nright: IntSet frame left right* invariant elems = {data} + (left null ? left.elems : {}) = + (right null \n? right.elems : {}) = left null . ==(. e e . left.elems =. e < data) right null . == (. e e . right.elems \n=. data < e) } Figure 1. A concrete data structure, namely a binary tree for the IntSet interface. Model \nvariable elems is used to describe the behavior of the operations, but is itself not compiled into executable \ncode. is our focus in this paper), code-generation hints, program sketches [28], and, as a last resort, \nold-fashioned manual coding. Jennisys is general purpose, addressing (D0). Its public interfaces let \nprogrammers write clean descriptions whose correctness can more easily be ascertained by human scrutiny. \nThe variety of ways to obtain code aims to speed up code production and maintenance. The data-structure \ndescription addresses (D1) by letting programmers use their insights into de.ning good data structures. \nJennisys is still a prototype. In this paper, we focus on the automatic code synthesis. In particular, \nwe contribute a tech\u00adnique that from abstract variables, abstract code, concrete variables, and a coupling \ninvariant (in other words, from the interface and datamodel of a component) synthesizes loop\u00adless structured \nprograms, where each if branch contains assignments to modi.able .elds (one assignment per .eld) and \npossibly some method calls. The synthesis technique is most readily applicable to constructors, but its \nclass of appli\u00adcations extends beyond that; for example, we show we can synthesize code for some recursive \nmethods for traversing or computing some properties of complex data structures. In a nutshell, our technique \nuses a program veri.er to ob\u00adtain sample input/output values that satisfy the given speci\u00ad.cations. The \nsample values are then extrapolated into code for all input values. Frequently, the synthesized code \nwill contain necessary branching structure, will allocate new in\u00adstances of other components, and will \ncall methods on those components in order to change their state. As far as we know, this is the .rst \ncode synthesizer to reason about pointers to objects, let alone synthesize code that allocates and uses \nob\u00adjects in data structures. 1. Examples In this section, we give examples that illustrate the use of \nJennisys and the code it synthesizes. Figure 0 shows the public interface of a Jennisys compo\u00adnent that \nwe will use as a running example, IntSet.0 Ab\u00adstractly, an IntSet is an integer set, which we de.ne by \nmodel variable elems. The constructors create a set of size 1 or 2, respectively, and method Find returns \nwhether or not a given integer is part of the set. An operation can de.ne a pre\u00adcondition (keyword requires), \nwhich obligates callers to in\u00advoke the operation only when the condition is met. The effect of an operation \nis given by assignments (as in Fig. 0) or re\u00adlations (constraints) on the pre-and post-states (see Fig. \n16). A concrete data structure for IntSet is described us\u00ading the datamodel declaration. It contains \nthree kinds of declarations var, frame, and invariant which we explain next. The variable declarations \n(e.g. var data: int) introduce the familiar .elds of a binary-tree node. Unlike the model variables in \nthe public interface, these concrete variables will be present in the run-time representation of IntSet \ncompo\u00adnents. The frame declaration says that the memory locations used to represent an IntSet include \nnot just the IntSet ob\u00adject itself, but also those memory locations that are used to represent the IntSet \ncomponents left and right. The star, inspired by the notation of separation logic [21], says that the \nsets of memory locations used by left and right are dis\u00adjoint. The frame declaration is necessary for \nthe veri.cation of candidate synthesized programs and tells the synthesis en\u00adgine which parts of the \nunderlying state a method may mu\u00adtate. 0 In this paper, we sometimes stray from the concrete syntax of \nour Jennisys prototype in order to make programs easier to read. Most notably, we replace the ASCII syntax \nof some operators by common mathematical notation. The actual Jennisys programs are available online \nin the Jennisys distribution. The invariant declaration de.nes a relation between the model variables \nand the concrete variables, as in a coupling invariant (aka an abstraction invariant or retrieve relation, \nsee, e.g., [1, 2, 14]). It also constrains the values of the concrete representation, as in a class invariant \n[18]. From Figs. 0 and 1, Jennisys automatically synthesizes code for the three operations. We give an \nexcerpt of that code in Fig. 2. The target language is Dafny [16], which for us has the advantage that \nwe can use the Dafny veri.er to double check the correctness of the synthesized code. We also use Dafny \nduring the synthesis itself. Dafny compiles to the .NET virtual machine, so there is in principle no \nreason why Jennisys could not compile to any Java-like language. Some interesting things to note about \nthe synthesized code are the if statements in Dupleton and Find. Also, note the dynamic allocation of \nobjects on line 50, the call of another constructor on line 51 (to respect the abstraction boundary of \nthe non-this object gensym85), the use of ghost variables on lines 2, 46, 53, 56, . . . (these are needed \nonly during veri.cation, not at run time), and the recursive calls to Find on lines 83, 84, 88, and 92. \nNote, although the operations in the public IntSet inter\u00adface in Fig. 0 can only construct sets with \ncardinality 1 or 2 (because our Jennisys prototype is currently not up to the task of synthesizing code \nfor a Union method), the data rep\u00adresentation we de.ne in Fig. 1 allows arbitrarily large sets. Indeed, \nthe synthesized code for Find will work for any con\u00adcrete data structure satisfying the invariant. 2. \nDynamic Synthesis This section focuses on the algorithm for program synthe\u00adsis behind Jennisys. We call \nthis algorithm dynamic synthe\u00adsis, because it combines ideas from both concrete and sym\u00adbolic execution, \nin a way that is similar to what concolic test\u00ading [6, 25, 31] does. In contrast to concolic testing, \nhowever, declarative speci.cations are being executed, rather than tra\u00additional imperative code. We .rst \ndescribe how Dafny [16], a program veri.er for functional correctness, can be used to execute .rst-order \ndeclarative speci.cations of Jennisys. Dafny is implemented on top of Boogie [4], an intermediate veri.cation \nlanguage, which via an SMT solver, namely Z3 [7], attempts to auto\u00admatically discharge veri.cation conditions. \nExecuting a speci.cation gives only a single valid in\u00adput/output pair, that is, a pair of concrete instances \nof the program heap (one for pre-state and one for post-state) for which the speci.cation holds. In order \nto synthesize a pro\u00adgram that is correct for all possible cases (i.e. all possible pre-states) this is \nclearly not enough. To this end, we next present an algorithm for systematic state exploration and program \nextrapolation from concrete instances. Since the problem of synthesis is undecidable, the algorithm does \nnot always succeed, but when it does, the synthesized program is provably correct (it can be automatically \nveri.ed against the 1 class IntSet { 2 ghost var Repr: set<object>; 3 ghost var elems: set<int>; 4 var \ndata: int, left: IntSet, right: IntSet; 27 function Valid(): bool (omitted, is de.ned to return true \nwhen the invari\u00adants of all reachable objects hold) 43 method Dupleton(x: int,y: int) 44 modifies this; \n45 requires x = y; 46 ensures Valid() . fresh(Repr -{this}); 47 ensures elems = {x, y}; 48 { 49 if (x \n< y) { 50 var gensym85 := new IntSet; 51 gensym85.Singleton(y); 52 this.data := x; 53 this.elems := {x, \ny}; 54 this.left := null; 55 this.right := gensym85; 56 this.Repr := {this}+ this.right.Repr; 57 assert \ngensym85.Valid(); 58 } else { (the other case is symmetric) 74 }} 75 76 method Find(x: int) returns \n(ret: bool) 77 requires Valid(); 78 ensures Valid() . fresh(Repr -old(Repr)); 79 ensures ret = (x . elems); \n80 decreases Repr; 81 { 82 if (this.left = null . this.right = null){ 83 var x_27 := this.left.Find(x); \n84 var x_28 := this.right.Find(x); 85 ret := (x = this.data . x_27) . x_28; 86 } else { 87 if (this.left \n= null){ 88 var x_29 := this.left.Find(x); 89 ret := x = this.data . x_29; 90 } else { 91 if (this.right \n= null){ 92 var x_30 := this.right.Find(x); 93 ret := x = this.data . x_30; 94 } else { 95 ret := x = \nthis.data; 96 }}}} 120 } Figure 2. Excerpts of the Dafny code that Jennisys synthe\u00adsizes for the IntSet \nexample. For brevity, the .gure com\u00adbines some lines. Dafny s ghost variables are not present during \nthe run-time execution of Dafny programs, but are needed to verify the correctness of the synthesized \nprogram.  Figure 3. Architecture of the Jennisys tool. The Jennisys synthesizer relies on Dafny, a program \nveri.er for functional correctness implemented on top of Boogie/Z3, to (1) execute Jennisys speci.cations \n(i.e., obtain concrete program heaps that satisfy such a speci.cation), and (2) verify the correctness \nof programs extrapolated from those concrete heaps. This process is done iteratively until a correct \nprogram is synthesized or the search heuristic terminates. original speci.cation using Dafny). The overall \narchitecture of the Jennisys tool is depicted in Fig. 3. 2.1 Concrete Speci.cation Execution with Dafny \nBy executing a method speci.cation we mean .nding arbitrary pre-and post-states that satisfy that speci.ca\u00adtion \n1. Dafny, even though designed for program veri.\u00adcation, is suitable for this task. The basic idea is \nto tell Dafny to assume (using the assume keyword) the pre\u00adcondition, the post-condition, and all the \ninvariants, then ask it to derive false from there (as in Fig. 4, which shows a Dafny code snipped used \nto execute the speci.cation of the IntSet.Dupleton method). If Dafny succeeds, the pre-and post-conditions \nare mutually inconsistent, so any attempt to synthesize code for such a speci.cation would be futile. \nOtherwise, Dafny returns a counterexample where all the assumed constraints hold is returned, so concrete \nvalues for the pre-and post-states can be directly extracted from it. 2.2 Symbolic and Concrete Execution \nCombined Assigning concrete values (constants) obtained by execut\u00ading a speci.cation to output variables \nis unlikely to result in a program that is correct for inputs other than the one discovered by the execution \nof that speci.cation. The goal is, therefore, to try and generalize from a concrete instance and .nd \nsymbolic assignments for output variables. Further\u00admore, even though more general than constants, such \nsym\u00adbolic assignments might be correct only for certain program scenarios represented by the concrete \ninstance used. When that is the case, a logical condition (guard) must be inferred to characterize those \nparticular scenarios. To solve the problem of .nding a guard and a set of sym\u00adbolic assignments, the \nspeci.cation is .rst partially eval\u00aduated with respect to the previously obtained concrete in\u00adstance. \nThis process yields a speci.cation that is simpler and more speci.c to the current instance. This simpli.ed \nspeci\u00ad.cation is then symbolically executed to arrive at a set of symbolic expressions that can be used, \ndepending on the type, as potential guards or variable assignments. 1 Note that this is slightly different \nfrom some previous work where exe\u00adcuting speci.cations is part of the runtime system (e.g. [19, 23]). \nIn those systems, the pre-state is always explicitly known (it is the state of the run\u00adning program before \nthe speci.cation is executed), so the goal there is to .nd a valid post-state for a given pre-state. \nclass IntSet { ghost var elems: set<int>; var data: int; var left: SetNode, right: SetNode; function \nValid(): bool { --all invariants inlined } method Dupleton() modifies this;{ var x: int,y: int; assume \na = b . elems = {a, b}; assume Valid(); assert false; } } Figure 4. Translation of IntSet.Dupleton into \nDafny for speci.cation execution. Since Jennisys and Dafny share the same language (modulo the exact \nsyntax), this translation is fairly straightforward. If it can be veri.ed that the chosen symbolic assignments \nare correct given the inferred guard, one branch of the tar\u00adget program is successfully synthesized. \nTo discover the rest of the program, a new program speci.cation is created by adding the negation of \nthe inferred guard as an additional pre-condition. The synthesis process is then recursively re\u00adpeated \nfor the new speci.cation to discover the else coun\u00adterpart of the previously synthesized branch. This \nprocess allows for synthesis of programs in the form of an arbitrarily long if-then-elseif-then-elseif-...-else \nstructure. The question of termination immediately comes to mind; we discuss this question in Sec. 3.6. \n3. Synthesis Algorithm in Depth 3.1 Partial Speci.cation Evaluation Let us assume throughout this section \nthat the initial exe\u00adcution of the speci.cation of Dupleton yielded the instance shown in Fig. 5(a). \nA method speci.cation can be unfolded for a given concrete instance by means of inlining invariants of \nevery  (a) Dupleton (b) Find Figure 5. Concrete instances automatically generated for methods Dupleton \nand Find. heap object in that instance. Unfolding the speci.cation of Dupleton for the instance from \nFig. 5(a) gives: x = y . n1.elems = {x y} n1.elems = {n1.data} + (n1.left = null ? n1.left.elems : {}) \n+ (n1.right = null ? n1.right.elems : {}) n1.left = null =. (. e e in n1.left.elems =. e < n1.data) \nn1.right = null =. (. e e in n1.right.elems =. n1.data < e) n2.elems = {n2.data} + (n2.left = null ? \nn2.left.elems : {}) + (n2.right = null ? n2.right.elems : {}) n2.left = null =. (. e e in n2.left.elems \n=. e < n2.data) n2.right = null (. e e in n2.right.elems =. n2.data < e) This expression as a whole \nmust evaluate to true, because the instance was generated so that the speci.cation holds for it. The \ninsight is, however, that some subexpressions of the speci.cation need not be relevant for the particular \ninstance at hand (e.g., a consequent of an implication whose antecedent is false). For example, in this \nconcrete instance, n1.right, n2.left, and n2.right are all null, so with that in mind, the previous constraint \ncan easily be simpli.ed to arrive at what we will refer to as a heap expression: x = y . n1.elems = {x \ny} n1.elems = {n1.data} + n1.left.elems . e e in n1.left.elems =. e < n1.data n2.elems = {n2.data} \nWe call this notion of simpli.cation partial evaluation and de.ne it formally in Fig. 62. The basic idea \nis to drop all disjunction terms that when fully evaluated (using the eval3 function) give false, since \nthey are likely to be irrelevant for the current instance. The apply function is used to reconstruct \nsymbolic ex\u00adpressions along the way. Its signi.cance is that it additionally 2 For brevity, the instance \nparameter is not explicitly used in the de.nition in Fig. 6; it is instead assumed to be the current \ninstance. 3 The eval function, given a concrete instance evaluates an expression to a constant. This \nis a well-known notion of evaluation, so we do not give a formal de.nition here. performs some well-known \nsimpli.cations. Besides short\u00adcircuiting boolean expressions, it implements several rules speci.cally \ndesigned for the task of synthesis. The most in\u00adteresting example would be the simpli.cation rules for \nop\u00aderations over sequences, as depicted in Fig. 7; in particu\u00adlar, they enable decomposition of speci.cations \ninvolving sequences into smaller bits which are often simpler to syn\u00adthesize code from. 3.2 Symbolic \nSpeci.cation Execution After obtaining a heap expression for the current instance (by computing E(e), \nwhere e is the unfolded version of the original speci.cation), a database of premises is created. All \npremises are boolean expressions, e.g., a = 5 or a>b, but not a+b. The initial set of premises includes \nall the conjuncts of the heap expression: x = y; n1.elems = {x y}; n1.elems = {n1.data} + n1.left.elems; \n. e e in n1.left.elems =. e < n1.data; n2.elems = {n2.data};  as well as v = eval(v) mappings for all \nvariables: this = n1; x = 1; y = -2; n1.data = 1; n1.left = n2; n1.right = null n2.data = -2; n2.left \n= null; n2.right = null  Using the inference rules de.ned in Fig. 8, new premises are derived from existing \nones and are added to the database. This process is repeated until either a .xpoint or a prede.ned maximum \nnumber of iterations is reached. The main purpose of the inference rules from Fig. 8 is to decompose \nand simplify expressions over the built\u00adin data structures. For example, from a speci.cation like x . \ne1 + e2, and a concrete instance in which x is not in the sequence e2, x . e1 can be safely derived. \nThese rules derive expressions speci.c to the current instance, and thus help infer appropriate guards \nand symbolic assignments. Some rules are independent of the concrete instance, e.g., x . [e0,e1, \u00b7\u00b7\u00b7 \n,en-1] f x . [e0]+[e1, \u00b7\u00b7\u00b7 ,en-1]; their purpose is mainly to enable rules of the previous kind to get \ninstantiated more often. 3.3 Choosing Correct Assignments for Output Variables At the end of the previous \nstep, the database might (and typ\u00adically does) contain multiple assignments for each variable. Jennisys \nautomatically rules some of them out, and uses a heuristic to rank the remaining ones. In order for an \nassign\u00adment to be considered valid, its right hand side must contain only references to either pre-state \nor unmodi.able variables. Between the valid assignments, Jennisys prefers those that contain symbolic, \nrather than constant values. E : Expr . Expr rewriting rules E(Const) = Const E(V ar) = V ar E(|e|) \n= apply(||, E(e)) E([e0,e1,...,en-1]) = List.map E [e0,e1,...,en-1] E({e0,e1,...,en-1}) = Set.map E{e0,e1,...,en-1} \nE(lst[idx]) = apply([], E(lst), E(idx)) E(e1 .e2) = apply(., E(e1), E(e2)) . - relational operator: \n=, =, <, =, >, =, ., ./E(e1 ae2) = apply(a, E(e1), E(e2)) a - arithmetic operator: +, -, *, /, % E(.v \n e) =.v e simpli.cation of logic expressions E(c ? t : e) = if eval(c) then E(t) else E(e) E(e1 . e2) \n= apply(., E(e1), E(e2)) E(e1 . e2) = match eval(e1), eval(e2) with | true, true . apply(., E(e1), E(e2)) \n| true, false .E(e1) | false, true .E(e2) | false, false . F alse E(e1 =. e2) =E(\u00ace1 . e2) E(e1 .. e2) \n=E((e1 . e2) . (\u00ace1 .\u00ace2)) E(\u00ace) = apply(\u00ac, E(e)) helper functions: eval : Expr . Const evaluates an \nexpression to a constant wrt the current instance apply : Op . Expr list . Expr applies a given operator \nto given operands Figure 6. Partial expression evaluation function (E): partially evaluates a given expression \nwith respect to a concrete instance, making it simpler and more speci.c to that instance. apply : Op \n. Expr list . Expr Simpli.cations for the || operator apply(||,l1 + l2) = apply(||,l1)+ apply(||,l2) \napply(||, [e0, ..., en-1]) = n Simpli.cations for the [] operator apply([], [e0, ..., ei, ..., en-1],i) \n= ei apply([], [e0, ..., ek-1]+ l, i) = if i<k then ei else apply([], l, i - k) Figure 7. Simpli.cations \nof the sequence length and sequence select expressions performed by the apply function. Figure 8. Inference \nrules for symbolic execution. inference rules for . x . [] f F alse (1) x . [e] f x = e (2) x . [e0, \ne1, . . . , en-1] f x . [e0] + [e1, . . . , en-1] (3) x . {} x . {e}x . {e0, e1, . . . , en-1}x . e1 \n+ e2 f f f F alse x = e x . {e0} + {e1, . . . , en-1} (4) (5) (6) when eval(x . e1) . eval(x /. e2) f \nx . e1 (7) when eval(x /. e1) . eval(x . e2) f x . e2 (8) else f x . e1 . x . e2 (9) inference rules \nfor . .x . [e0, . . . , en-1] p f p[x o e0] . . . . . p[x o en-1] (10) .x . {e0, . . . , en-1} p .x \n. e1 + e2 p f f p[x o e0] . . . . . p[x o en-1] (.x . e1 p) . (.x . e2 p) (11) (12) From the initial \ndatabase for the Dupleton example, just by applying transitivity of equality, the following candidate \nsolution is quickly discovered (other assignments exists in the database, but they all contain constant \nvalues): n1.elems := {x y}; n2.elems := {y}; n1.data := x; n2.data := y; n1.left := n2; n2.left := null; \nn1.right := null; n2.right := null;  As expected, this solution does not verify against the original \nspeci.cation of the Dupleton method. Knowing the properties of binary search trees, it is easy for us \nto con\u00adclude that the solution we just discovered is valid only for cases where y<x holds. In the next \nsubsection we show how, when needed, Jennisys automatically infers such log\u00adical conditions (guards). \nWhen no guard is needed (i.e., the candidate solution veri.es at this point), the solution is simply \nreturned to the top-level synthesis function (see Sec. 3.5) where the algorithm .nishes, since the last \nelse branch of the outer if-then-elif-...-else structure has just been found. 3.4 Inference of Guards \nThe main insight for successful guard inference is that an appropriate guard is likely to be a logical \nproperty of the current instance. Therefore, a guard is likely to consist of one or more premises from \nthe database. Going back to the example, the y<x condition was in\u00addeed derived during the execution of \nthe .xpoint algorithm. Namely, from n1.left = n2 n2.elems = n2 . e e in n1.left.elems =. e < n1.data \n just by applying transitivity of equality the following premise is derived: . e in {n2.data} e < n1.data \n Applying rule 11 leads to n2.data < n1.data, from which y<x immediately follows (since both n2.data \n= y and n1.data = x are already in the database). Jennisys selects a candidate guard by going through \nthe database and looking for expressions that involve only un\u00admodi.able variables and constants (expressions \nwithout con\u00adstants are again ranked higher). When multiple such expres\u00adsions exist, a conjunction of \nall of them is used .rst. If a can\u00addidate solution veri.es under the assumption of a selected guard, \nthe guard is minimized by iteratively trying to remove one clause at a time. For example, during the \nsynthesis of the Dupleton method, x = y . y<x was selected as a guard .rst, and was next minimized to \ny<x. 3.5 Top-level Algorithm The top-level synthesis function, synth, is given in Fig. 9. At the very \nbeginning (line 2), it invokes synth_branch to .nd a solution for the current instance only (exactly \nby following the procedure described so far). If no veri.ed solution is found (line 4), Jennisys gives \nup. If both guard and a solution were found (line 6), the guard is negated and appended to the list of \npre-conditions to ensure that all subsequent concrete instances obtained by executing the speci.cation \nfall outside this of branch. The whole process is then repeated to .nd a solution for the else branch. \nFinally, if a solution was found for which a guard was not needed (line 5), a solution for the entire \nprogram is discov\u00adered (not just the current instance!). That is true because a solution is just proven \nunconditionally correct for the portion of the program space not covered by the previously synthe\u00adsized \nbranches. This solution represents the last else branch of the if-then-elif-...-else structure that our \napproach synthe\u00adsizes. 0 let Solution = FlatSol | IfThenElse(Guard, FlatSol, Solution) 1 let rec synth \n(m: Method): Solution = 2 let guardOpt,flatSolOpt = synth_branch m 3 match flatSolOpt, guardOpt with \n4 | None, _ -> None 5 | Some(flatSol), None -> Some(flatSol) 6 | Some(flatSol), Some(guard) -> 7 match \nsynth (AddPrecondition m (not guard)) with 8 | None -> None 9 | Some(solElse) -> Some(IfThenElse(guard, \nflatSol, solElse)) Figure 9. Top level algorithm in pseudo F#  3.6 Termination The synthesis algorithm \nterminates when one of the follow\u00ading conditions is met: (0) a candidate solution is found and it veri.es \nwithout needing a guard (synthesis succeeds), (1) a candidate solution is found, but it doesn t verify \nand a guard cannot be inferred (synthesis fails), or (2) no candidate solu\u00adtion is found (synthesis fails). \nAn important question is whether the algorithm is guar\u00adanteed to always terminate. The only way for the \nsynth function not to terminate is if it is possible to forever keep generating new concrete instances \nand each time .nding a guarded solution. The way we generate new instances guar\u00adantees that at each step \nthe remainder of the search space is getting smaller, because every new instance is guaran\u00adteed to be \noutside of the previously discovered classes of programs (characterized by previously discovered guards). \nIt can happen, however, that at each step the inferred guard is over-constrained (e.g., it does not allow \nany instance other than the current one). In that case, if the search space is un\u00adbounded (that is, there \nare in.nitely many different instances for the program under analysis), the algorithm potentially never \nterminates. To mitigate this, Jennisys always prefers solutions and guards with no constants so that \nat every step the remainder of the search space is shrunk as much as pos\u00adsible. In practice, this means \nthat the algorithm is likely to either terminate with a solution or fail quickly. 4. Synthesizing Recursive \nMethods The synthesis algorithm described so far was designed to support constructors in the form of \na single (but of arbi\u00adtrary length) if-then-elseif-...-else structure, where the only allowed statements \nare assignments to output variables. In this section, we show how we extended the algorithm to allow \nmethod calls (including recursion) in the assignment statements. Allowing recursion somewhat makes up \nfor the lack of looping constructs. Two modi.cations to the synthesis algorithm are needed: (0) after \nbuilding the initial set of premises, parameter\u00adized expressions corresponding to method speci.cations \nare added to the database; and (1) the inference engine for sym\u00adbolic execution is modi.ed so that it \nallows matching with uni.cation. Allowing parameterized expressions means allowing ex\u00adpressions to have \nplaceholders (or variables, if you will), which can be substituted by any other expressions of the same \ntype. Concretely, expressions corresponding to method speci.cations will have such placeholders for the \nmethod pa\u00adrameters and the method receiver object. For example, such an expression for the IntSet.Find \nmethod would look like: $this.Find($x) = $x . $this.elems (0) To be able to instantiate inference rules \nagainst param\u00adeterized expression, a form of uni.cation is needed. In our prototype implementation, we \nused a simple syntactic uni.\u00adcation algorithm, which currently enables us to synthesize only read-only \nmethods (such as IntSet.Find). Replacing this algorithm with a suitable form of semantic uni.cation would \npotentially enable synthesis of more complex recur\u00adsive methods (such as binary search tree insertion). \nTo illustrate this, consider the IntSet.Find method. Let us assume that after its speci.cation is executed \nfor the .rst time, the instance from Fig. 5(b) is discovered. The initial set of premises looks almost \nthe same as before (since the instance is almost the same), with a difference of the .rst line (the pre-condition \nfrom the previous example) be\u00ading replaced with the post-condition of the Find method (ret = x . this.elems) \nand a parameterized speci.cation for the Find method. The derivation then goes as follows4: ret = x . \nthis.elems . ret = x . {this.data} + this.left.elems (1) . ret = x . {this.data} . x . this.left.elems \n(2) . ret = (x = this.data) . x . this.left.elems (3) . ret = (x = this.data) . this.left.Find(x) (4) \n  Equations 2 and 3 are derived directly by applying rules 9 and 5 (from Fig. 8) respectively. Equation \n4 is next de\u00adrived by matching up x . this.left.elems (from equation 3) and $x . $this.elems (from premise \n0, i.e., the right-hand side of the parameterized speci.cation of the Find method). To establish that \nmatch, the following two uni.cations are needed: $this o this.left and $x o x. Finally, with those two \nuni.cations and premise 0, x . this.left.elems can be replaced with this.left.Find(x), which directly \nde\u00adrives equation 4. The remainder of the process stays the same. The guard for this instance (this.left \n= null) is easily inferred (note that it is okay now to use this.left in the guard, because 4 Note that \nthe derivation would be slightly different if, for example, in the concrete instance it happens that \nthe set contains the input value x. In that case, at the second step either rule 7 or 8 would be instantiated \ninstead of rule 9, meaning that the disjunction would be simpli.ed so that only one side remains, depending \non where the value x is actually found. this is unmodi.able in this case) and the process continues \nthe same way to synthesize the rest of the program. The .nal program is shown in Fig. 2. 5. Boilerplate \nCode to Aid Veri.cation As noted earlier, our synthesis algorithm requires a fully au\u00adtomated program \nveri.er. The algorithm described in Sec. 3 and 4, however, is veri.er agnostic any automated tool for \nfunctional program veri.cation (capable of generating con\u00adcrete counterexamples) can be used. Full functional \nveri.cation of object-oriented programs with pointers, memory allocation, and recursive calls is not \nan easy task, and, in general, cannot be done automatically. Jennisys uses the Dafny program veri.er, \nwhich is fully au\u00adtomated, but for successful veri.cation (of a program al\u00adready correct) it often requires \nsome extra input from the user (in the form of extra code or constraints, but not inter\u00adactive sessions \nduring the veri.cation process). Luckily, cer\u00adtain Dafny speci.cation idioms are known to be helpful \nin such cases. We describe here how Jennisys uses these speci\u00ad.cations idioms to aid veri.cation. A common \nidiom in Dafny is to have a ghost .eld (typi\u00adcally named Repr) to hold the set of all the constituent \nobjects of this (i.e., the objects used to represent the data structure of this, aka the footprint of \nthis). In the IntSet example, the Repr .eld holds all objects of the IntSet (that is, all nodes reachable \nfrom the current node by following the left and right pointers). The Repr .eld is then conveniently used \nto specify common frame properties like: (0) all objects except this that a constructor makes part of \nthe footprint are newly allocated fresh(Repr-{this}) (e.g., Fig. 2, line 46), and (1) all objects in \na method s post-state footprint that were not in the method s pre-state footprint are newly allocated \n fresh(Repr-old(Repr)) (e.g., Fig. 2, line 78). Furthermore, we use the Repr .eld as a termination measure \nto prove ter\u00admination of recursive methods; we use it idiomatically in the form of decreases Repr (e.g., \nFig. 2, line 80) since a recur\u00adsion is often invoked on an object with a smaller footprint. Invariants \nare required to hold in the pre-and post-states of each Jennisys method. To supply such information to \nDafny, a standard idiom is to encapsulate the de.nition of the invariant in a function (in our case called \nValid), and then as\u00adsert that it holds in both pre-and postcondition (e.g., Fig. 2, lines 77 and 78). \nGenerated from the Jennisys component speci.cation, the Valid function says that the representation and \ncoupling invariants de.ned in the Jennisys model hold, that Repr contains all reachable objects, and \nthat these reach\u00adable objects are themselves valid (by the same de.nition). Since this is a recursive \nde.nition, Jennisys can be con.g\u00adured to unroll it a given number of times, or to generate a recursive \nDafny function (using the decreases Repr trick to prove its termination), or to do both (which, in our \nexperi\u00adence, is often useful). For an example, see how the Valid function is generated for the singly-list \nexample (Fig. 13). 6. Experiments and Evaluation To evaluate our synthesis algorithm, we show that Jen\u00adnisys \ncan successfully and reasonably quickly synthesize constructors for several complex data structures, \nas well as some read-only recursive methods, solely from abstract .rst\u00adorder speci.cations. To the best \nof our knowledge, no other approach generates code with such dynamic features from declarative speci.cations. \nWe wrote abstract speci.cations in Jennisys for a num\u00adber of constructors and methods for the following \ndata structures: binary search tree (IntSet), binary heap (BHeap), singly-linked list (List), and doubly-linked \nlist (DList). We also speci.ed several simple mathematical operations to show how Jennisys is capable \nof handling convoluted declar\u00adative speci.cations. Jennisys programs for these experiments are given \nin Figs. 0, 10, 12, 14, and 16 respectively, and cor\u00adresponding synthesized programs are given in Figs. \n2, 11, 13, 15, and 17. Table 0 shows the results of the experiments. For each program, we show whether \nit is a constructor or a method (type), how many branches it has (#branches), how many times the veri.er \nwas invoked (#Dafny), and the total syn\u00adthesis time in seconds (time). The #Dafny column is the to\u00adtal \nnumber of times Dafny was run for all different purposes, including executing a speci.cation, verifying \na synthesized program, various auxiliary veri.cation tasks (e.g., during the minimization of guards), \netc. All experiments were done on an Intel R &#38;#169; CoreTM2 Duo CPU @ 2.40GHz computer, with 4GB \nof RAM, running 32-bit Windows 7. Most of the programs were successfully synthesized within 25 seconds. \nSome of the programs, whose solutions required 4 branches, had to run the program veri.er up to 23 times, \nand therefore the entire synthesis process took longer, up to 65 seconds. Jennisys was able to handle \nthe full declarativeness of the speci.cations we wrote. For example, the speci.cation for List.Size (Fig. \n12) is simply the length of the abstract list .eld used to model the contents of this data structure. \nOther than the coupling invariant between the abstract and concrete state (best programming practices \nwould recommend this invariant to be written anyway), no other hints about the program structure had \nto be given. The synthesized code is a recursive method (Fig. 13). Another example of Jennisys being \nable to handle declar\u00adative speci.cations are the Min methods in the Math compo\u00adnent (Fig. 16). The speci.cation \nof Min2 (minimum of two integers) is written in a direct, almost imperative way, using two implications \nwhich could be translated to an imperative language based on syntactic rules only. Writing a speci.\u00adcation \nfor the Min4 method (minimum of four) in the same style, however, would be much less convenient, and \nwould require explicit enumeration of possible orderings between the four input arguments. Instead, we \nwrote it succinctly in a more declarative fashion, simply saying that the result must be equal to one \nof the four inputs, and that it must be less than or equal to each one of them. Synthesizing code from \nsuch a speci.cation becomes much harder and an attempt to translate it based on syntactic rules would \nlikely fail. Note how the IntSet and BHeap examples demonstrate a key feature of a programming language \nsupported by synthe\u00adsis. The data model for IntSet in Fig. 1 says that the concrete data structure should \nbe a binary search tree. Suppose the IntSet developer later decides that a binary-heap representa\u00adtion \nwould be a better choice. This change is accomplished by simply replacing the invariant with the one \nin Fig. 10. The necessary code changes are left for Jennisys to take care of; in fact, Jennisys will \nthen synthesize the code shown in Fig. 11. Currently, Jennisys can synthesize only constructors that \ncreate objects of a .xed (known in advance) size. In other words, our algorithm can, for example, synthesize \ncode that constructs a binary heap of 2 objects, or 3 objects, but not of all objects in a given list \n(because such an operation would require a loop). On the other hand, for a constructor with a .xed number \nof input parameters, Jennisys can au\u00adtomatically partition the input space (which is possibly in.\u00adnite) \ninto a .nite number of parts, for each part synthesizing straight-line code that implements the constructor \nfor that part of the input space. 7. Related Work The idea of automatic code generation dates back to \nthe .rst Autocoder [8] systems from the 1950s which offered an automatic translation from a high-level \nsymbolic language into actual (machine-level) object code. Soon thereafter, the goal of automatic programming, \ni.e., automatic synthesis of programs from even higher-level speci.cations, was born and has been a dream \nfor more than four decades. The idea that software engineering would be a better place if programmers \ncould spend their time editing speci.cations, rather than trying to maintain optimized programs, is argued \nconvincingly in a paper that tried to predict the future [3]. Pioneering efforts in the synthesis area \naround 1970 used theorem provers to verify the existence of an output for ev\u00adery input and then synthesized \nexecutable programs from the ingredients of these proofs [9, 17]. More encompassing de\u00advelopment systems \nwith synthesis included the 1970s PSI program synthesis system [10] and the 1980s Programmer s Apprentice \nproject [22]. These ambitious systems tried to aid programmers by engaging in a dialog about the program \nto be developed, offering advice, keeping track of details, and synthesizing code. The systems made use \nof a signi.\u00adcant knowledge base of the domains and template scenarios (so-called clich\u00e9s) of the programs \nto be developed, and PSI also included a major natural-language component. In com\u00adparison, the abstract \nmodels one can de.ne in Jennisys look much more like programs. type #branches #Dafny t (s) Binary Search \nTree (see Figs. 0, 1 and 2) IntSet.Singleton constr 1 2 5.4 IntSet.Dupleton constr 2 5 15.5 IntSet.Find \nmethod 4 17 64.8 Binary Heap (see Figs. 10 and 11) BHeap.Singleton constr 1 2 5.2 BHeap.Dupleton constr \n2 5 19.3 BHeap.Tripleton constr 3 13 61.6 BHeap.Find method 3 17 51.9 Singly-Linked List (see Figs. 12 \nand 13) List.Singleton constr 1 2 4.9 List.Dupleton constr 1 2 5.2 List.Elems method 2 6 14.6 List.Get \nmethod 3 10 23.6 List.Find method 2 7 16.8 List.Size method 2 6 14.5 Doubly-Linked List (see Figs. 14 \nand 15) DList.Singleton constr 1 2 4.8 DList.Dupleton constr 1 2 5.0 DList.Elems method 2 6 14.6 DList.Get \nmethod 3 10 23.5 DList.Find method 2 7 16.7 DList.Size method 2 6 14.4 Simple Math Functions (see Figs. \n16 and 17) Math.Min2 method 2 5 10.4 Math.Min3Sum method 3 13 26.4 Math.Min4 method 4 23 45.7 Math.Abs \nmethod 2 6 12.3 Table 0. Total synthesis time for each of the benchmarks (t), number of branches in \nthe synthesized program (#branches), and the total number of times the veri.er was invoked during synthesis \n(#Dafny). Developed in the late 1980s, the comprehensive KIDS system provided a number of tools to support \nalgorithm de\u00adsign and program transformations [27]. Besides major de\u00adsign decisions like semantically \ninstantiating algorithm tem\u00adplates, the operations performed with KIDS are correctness\u00adpreserving transformations \nre.nement steps that can take an algorithm description into an ef.cient program. The Jennisys language \nis in many ways similar to one step of a re.nement process, where Jennisys offers syn\u00adthesis as one way \nof obtaining the re.ned program. Mon\u00adahan has suggested de.ning components in three parts (spec/abstr/impl) \n[20], which is also what Jennisys does. Jennisys also shares in the vision of the language SETL [24], \nwhich sought to provide ways to .rst describe programs cleanly and then provide them with ef.cient data \nrepresen\u00adtations. The construction of programs from examples is a power\u00adful idea that has been explored \nfrom the 1970s. For example, THESYS synthesis system generated LISP programs [30] and QBE generated SQL \nqueries [32]. Queries by Exam\u00adple became a competitive feature of the Paradox relational database system \nin the 1980s and 1990s, and techniques with similar goals are being explored in the context of spread\u00adsheets \ntoday [12]. Jennisys also extrapolates programs from examples, but the examples are not supplied by users \nbut are instead sample points from speci.cations supplied by users. An advantage of having speci.cations \nis that one can then verify the synthesized program, as opposed to just knowing it is correct for the \nexamples provided. Interest in program synthesis seems to be on the rise again, possibly in part due \nto the success of SMT solvers in program veri.cation and other applications. Kuncak et al. are exploring \nfeatures like generalized assignments in a mainstream programming language, backed up by automatic synthesis \nprocedures [15]. The PINS [29] system takes a program and a template and synthesizes an inversion of \nthe given program. The technique of program sketching lets programmers supply some ingredients of a program \n(i.e. a program sketch) while a tool worries about the details to .nd a correct way to combine the ingredients \n[28]. The notion of correctness is taken from another correct (but presumably inef.cient) im\u00adplementation \nof the same program, that has to be supplied by the user. Storyboard programming [26] improves on that \nidea by letting the users draw a series of input/output exam\u00adples instead of providing an alternative \ncorrect implementa\u00adtion (it still requires a sketch, though). Similarly, instead of a sketch, the Brahma \ntool [11, 13] takes a library of compo\u00adnents to be used as building blocks and either an explicit set \nof input/output pairs or a speci.cation describing the relation between inputs and outputs, and synthesizes \na loop-free pro\u00adgram (currently focused on bit-vector manipulations) from the given components. In comparison, \nJennisys does not re\u00adquire any input from the user other than a speci.cation in the form of pre-and post-conditions, \nit targets object-oriented programs with dynamic allocation, but is unable to synthe\u00adsize as wide a class \nof programs as the storyboard program\u00adming. The key advances in Jennisys are twofold. As for what our \nsynthesis algorithm achieves, it is able to generate pro\u00adgrams that create dynamic data structures with \npointers, and it does this from an abstract (declarative) description of the operations (in the form \nof pre-and post-conditions) and a link to the concrete data structure. We have not seen this kind of \nsynthesis done before in a class-based setting. As for how our synthesis algorithm makes a technical \nadvance, it uses a combination of symbolic execution and uni.cation to produce candidate program snippets, \nand then uses a detailed counterexample-producing program veri.er to determine the applicable scope of \neach such snippet. 8. Conclusion In this paper, we have contributed a language design that promotes writing \ndown an abstract model of each compo\u00adnent, gives control over the data structure used to implement a \ncomponent, and opens the door for synthesis techniques to .ll in the code. The paper also contributes \na synthesis technique for the language, which operates in the context of an in.nite state space, dynamic \nobject allocation, and object references. Finally, the paper contributes a prototype imple\u00admentation \nof the language and synthesis technique. The pro\u00adtotype is available as open source5, and experiments \nwith it are encouraging. Still, much work lies ahead. We are interested in explor\u00ading the limits of the \napproach to coding based solely on syn\u00adthesis from interface speci.cations and data-model invari\u00adants. \nA next step in this direction is to extend our synthesis engine to support mutating methods. Another \nis to explore different domains of programs that can be automatically syn\u00adthesized purely from speci.cations. \nBut, as we mentioned in the introduction, our vision is also to blend the idealistic synthesis-only approach \nwith ways that give programmers the ability to supply code-generation hints, like in program sketching \n[28]. Acknowledgments We would like to thank the various referees for their thought\u00adful comments on drafts \nof this paper. References [1] J.-R. Abrial. Modeling in Event-B: System and Software Engineering. Cambridge \nUniversity Press, 2010. [2] R.-J. Back and J. von Wright. Re.nement Calculus: A Sys\u00adtematic Introduction. \nGraduate Texts in Computer Science. Springer, 1998. [3] R. Balzer, T. E. Cheatham, Jr., and C. Green. \nSoftware tech\u00adnology in the 1990 s: Using a new paradigm. IEEE Computer, 16(11):39 45, 1983. [4] M. Barnett, \nB.-Y. E. Chang, R. DeLine, B. Jacobs, and K. R. M. Leino. Boogie: A modular reusable veri.er for object-oriented \nprograms. In FMCO 2005, volume 4111 of LNCS, pages 364 387. Springer, 2006. [5] L. Burdy, Y. Cheon, \nD. R. Cok, M. D. Ernst, J. R. Kiniry, G. T. Leavens, K. R. M. Leino, and E. Poll. An overview of JML \ntools and applications. J. STTT, 7(3):212 232, 2005. [6] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. \nDill, and D. R. Engler. EXE: automatically generating inputs of death. In ACM Conference on Computer \nand Communications Security, pages 322 335, 2006. [7] L. de Moura and N. Bj\u00f8rner. Z3: An ef.cient SMT \nsolver. In TACAS 2008, volume 4963 of LNCS, pages 337 340. Springer, 2008. [8] R. Gold.nger. The ibm \ntype 705 autocoder. In Papers pre\u00adsented at the February 7-9, 1956, joint ACM-AIEE-IRE west\u00adern computer \nconference, AIEE-IRE 56 (Western), pages 49 51, New York, NY, USA, 1956. ACM. doi: 10.1145/1455410. 5 \nhttp://boogie.codeplex.com 1455427. URL http://doi.acm.org/10.1145/1455410. 1455427. [9] C. Green. \nApplication of theorem proving to problem solving. In IJCAI 1969, pages 219 240. William Kaufmann, 1969. \n[10] C. Green. The design of the PSI program synthesis system. In ICSE, pages 4 18. IEEE Computer Society, \n1976. [11] S. Gulwani, S. Jha, A. Tiwari, and R. Venkatesan. Synthesis of loop-free programs. In PLDI, \nPLDI 11, pages 62 73, New York, NY, USA, 2011. ACM. [12] W. R. Harris and S. Gulwani. Spreadsheet table \ntransforma\u00adtions from examples. In PLDI 2011, pages 317 328. ACM, 2011. [13] S. Jha, S. Gulwani, S. A. \nSeshia, and A. Tiwari. Oracle\u00adguided component-based program synthesis. In ICSE, ICSE 10, pages 215 224, \nNew York, NY, USA, 2010. ACM. [14] C. B. Jones. Systematic Software Development using VDM. Series in \nComputer Science. Prentice-Hall International, sec\u00adond edition, 1990. [15] V. Kuncak, M. Mayer, R. Piskac, \nand P. Suter. Complete functional synthesis. In PLDI 2010, pages 316 329. ACM, 2010. [16] K. R. M. Leino. \nDafny: An automatic program veri.er for functional correctness. In LPAR-16, volume 6355 of LNCS, pages \n348 370. Springer, 2010. [17] Z. Manna and R. J. Waldinger. Towards automatic program synthesis. Commun. \nACM, 14(3):151 165, 1971. [18] B. Meyer. Object-oriented Software Construction. Series in Computer Science. \nPrentice-Hall International, 1988. [19] A. Milicevic, D. Rayside, K. Yessenov, and D. Jackson. Uni\u00adfying \nexecution of imperative and declarative code. In ICSE, pages 511 520, 2011. [20] R. Monahan. Data Re.nement \nin Object-Oriented Veri.ca\u00adtion. PhD thesis, Dublin City University, 2010. [21] J. C. Reynolds. Separation \nlogic: A logic for shared mutable data structures. In LICS 2002, pages 55 74. IEEE Computer Society, \n2002. [22] C. Rich and R. C. Waters. The Programmer s Apprentice: A research overview. IEEE Computer, \n21(11):10 25, 1988. [23] H. Samimi, E. D. Aung, and T. D. Millstein. Falling back on executable speci.cations. \nIn ECOOP, pages 552 576, 2010. [24] J. T. Schwartz, R. B. K. Dewar, E. Dubinsky, and E. Schon\u00adberg. Programming \nwith Sets: An Introduction to SETL. Texts and Monographs in Computer Science. Springer, 1986. [25] K. \nSen, D. Marinov, and G. Agha. CUTE: a concolic unit testing engine for C. In ESEC/SIGSOFT FSE, pages \n263 272, 2005. [26] R. Singh and A. Solar-Lezama. Synthesizing data structure manipulations from storyboards. \nIn ESEC/FSE 2011, pages 289 299, New York, NY, USA, 2011. ACM. ISBN 978-1\u00ad4503-0443-6. [27] D. R. Smith. \nKIDS: A semi-automatic program development system. IEEE Transactions on Software Engineering, 16(9): \n1024 1043, 1990. [28] A. Solar-Lezama, L. Tancau, R. Bod\u00edk, S. Seshia, and V. Saraswat. Combinatorial \nsketching for .nite programs. In ASPLOS 2006, pages 404 415. ACM, 2006. [29] S. Srivastava, S. Gulwani, \nS. Chaudhuri, and J. S. Foster. Path\u00adbased inductive synthesis for program inversion. In PLDI 2011, pages \n492 503. ACM, 2011. ISBN 978-1-4503-0663-8. [30] P. D. Summers. A methodology for LISP program construc\u00adtion \nfrom examples. J. ACM, 24(1):161 175, 1977. [31] N. Williams, B. Marre, P. Mouy, and M. Roger. PathCrawler: \nAutomatic generation of path tests by combining static and dynamic analysis. In EDCC, pages 281 292, \n2005. [32] M. M. Zloof. Query by example. In AFIPS National Com\u00adputer Conference 1975, pages 431 438. \nAFIPS Press, 1975. A. Code Listings for the BHeap Example // exactly the same as the interface for IntSet \ninterface BHeap { var elems: set[int] constructor Singleton(x: int) elems := {x} constructor Dupleton(a: \nint,b: int) requires a = b elems := {a b} constructor Tripleton(x: int,y: int,z: int) requires x = y \n. y = z . z = x elems := {x y z}  method Find(n: int) returns (ret: bool) ret := n . elems } datamodel \nBHeap { var data: int var left: BHeap var right: BHeap frame left right* invariant elems = {data} + (left \n= null ? left.elems : {})  + (right = null ? right.elems : {}) left = null =.. e e in left.elems =. \ne < data right = null =.. e e in right.elems =. e < data left = null =. right = null left = null . right \n= null =. left.elems = {left.data} } Figure 10. Binary heap speci.ed abstractly (declaratively) in Jennisys. \nNote that the interface speci.cation is exactly the same as for the binary search tree (IntSet from Fig. \n0); only the datamodel is different to impose a different concrete representation. class BHeap { ghost \nvar Repr: set<object>; ghost var elems: set<int>; var data: int; var left: BHeap; var right: BHeap; \nfunction Valid_repr(): bool reads *; { this in Repr . null . Repr . (left = null =. left in Repr . \nleft.Repr = Repr . this . left.Repr) . (right = null =. right in Repr . right.Repr = Repr . this . right.Repr) \n} function Valid_self(): bool reads *; { Valid_repr() . (elems = ({data} +  (if left = null then left.elems \nelse {})) + (if right = null then right.elems else {})) . (left = null =. (. e e in left.elems =. e \n< data)) . (right = null =. (. e e in right.elems =. e < data)) } function Valid(): bool reads *; decreases \nRepr; { this.Valid_self() . (left = null =. left.Valid()) . (right = null =. right.Valid()) . (left \n= null =. left.Valid_self()) . (right = null =. right.Valid_self()) . (left = null . left.left = null \n=. left.left.Valid_self()) . (left = null . left.right = null =. left.right.Valid_self()) . (right = \nnull . right.left = null =. right.left.Valid_self()) . (right = null . right.right = null =. right.right.Valid_self()) \n}   method Singleton(x: int) method Tripleton(x: int, y: int, z: int) modifies this; modifies this; \nensures fresh(Repr -{this}); requires x = y . y = z . z = x; ensures Valid(); ensures fresh(Repr -{this}); \nensures elems = {x}; ensures Valid(); { ensures elems = {x, y, z}; this.data := x; { this.elems := {x}; \nif (z < y . x < y) { this.left := null; var gensym75 := new BHeap; this.right := null; var gensym77 := \nnew BHeap; // repr stuff this.data := y; this.Repr := {this}; this.elems := {x, z, y}; } this.left := \ngensym77; this.right := gensym75; method Dupleton(a: int, b: int) gensym75.data := x; modifies this; \ngensym75.elems := {x}; requires a = b; gensym75.left := null; ensures fresh(Repr -{this}); gensym75.right \n:= null; ensures Valid(); gensym77.data := z; ensures elems = {a, b}; gensym77.elems := {z}; { gensym77.left \n:= null; if (b < a) { gensym77.right := null; var gensym71 := new BHeap; // repr stuff var gensym73 := \nnew BHeap; gensym75.Repr := {gensym75}; this.data := a; gensym77.Repr := {gensym77}; this.elems := {b, \na}; this.Repr := ({this} + {gensym77}) + {gensym75}; this.left := gensym73; } else { this.right := gensym71; \nif (x < z) { gensym71.data := b; var gensym75 := new BHeap; gensym71.elems := {b}; var gensym77 := new \nBHeap; gensym71.left := null; this.data := z; gensym71.right := null; this.elems := {x, y, z}; gensym73.data \n:= b; this.left := gensym77; gensym73.elems := {b}; this.right := gensym75; gensym73.left := null; gensym75.data \n:= x; gensym73.right := null; gensym75.elems := {x}; // repr stuff gensym75.left := null; gensym71.Repr \n:= {gensym71}; gensym75.right := null; gensym73.Repr := {gensym73}; gensym77.data := y; this.Repr := \n({this} + {gensym73}) + {gensym71}; gensym77.elems := {y}; } else { gensym77.left := null; var gensym71 \n:= new BHeap; gensym77.right := null; var gensym73 := new BHeap; // repr stuff this.data := b; gensym75.Repr \n:= {gensym75}; this.elems := {a, b}; gensym77.Repr := {gensym77}; this.left := gensym73; this.Repr := \n({this} + {gensym77}) + {gensym75}; this.right := gensym71; } else { gensym71.data := a; var gensym75 \n:= new BHeap; gensym71.elems := {a}; var gensym77 := new BHeap; gensym71.left := null; this.data := x; \ngensym71.right := null; this.elems := {z, y, x}; gensym73.data := a; this.left := gensym77; gensym73.elems \n:= {a}; this.right := gensym75; gensym73.left := null; gensym75.data := y; gensym73.right := null; gensym75.elems \n:= {y}; // repr stuff gensym75.left := null; gensym71.Repr := {gensym71}; gensym75.right := null; gensym73.Repr \n:= {gensym73}; gensym77.data := z; this.Repr := ({this} + {gensym73}) + {gensym71}; gensym77.elems := \n{z}; }} gensym77.left := null; gensym77.right := null; // repr stuff gensym75.Repr := {gensym75}; \ngensym77.Repr := {gensym77}; this.Repr := ({this} + {gensym77}) + {gensym75}; } } } method Find(n: \nint) returns (ret: bool) requires Valid(); ensures fresh(Repr -old(Repr)); ensures Valid(); ensures ret \n= (n in elems); decreases Repr; { if (this.left = null){ ret := n = this.data; } else { if (this.right \n= null){ var x_10 := this.left.Find(n); var x_11 := this.right.Find(n); ret := (n = this.data . x_10) \n. x_11; } else { var x_12 := this.left.Find(n); ret := n = this.data . x_12;  } } } } Figure 11. Imperative \nDafny code that Jennisys synthesizes for the abstract BHeap program from Fig. 10. B. Code Listings for \nthe List Example interface List[T] { var list: seq[T] invariant |list| > 0 constructor Singleton(t: T) \nlist := [t] constructor Dupleton(p: T, q: T) list := [p q] method Elems() returns (ret: seq[T]) ret \n:= list method Get(idx: int) returns (ret: T) requires 0 = idx . idx < |list| ret := list[idx] method \nFind(n: T) returns (ret: bool) ret := n . list  method Size() returns (ret: int) ret := |list| } datamodel \nList[T] { var data: T var next: List[T] frame next invariant next = null =. list = [data] next = null \n=. list = [data] + next.list } Figure 12. Singly-linked list speci.ed abstractly (declara\u00adtively) in \nJennisys. class List<T> { ghost var Repr: set<object>; ghost var list: seq<T>; var data: T; var next: \nList<T>; function Valid_repr(): bool reads *; { this in Repr . null . Repr . (next = null =. next in \nRepr . next.Repr = Repr . this . next.Repr) } function Valid_self(): bool reads *; { Valid_repr() \n. (next = null .. list = [data] . list[0] = data) . (next = null =. list = [data] + next.list) . (|list| \n> 0) } function Valid(): bool reads *; decreases Repr; { this.Valid_self() . (next = null =. next.Valid()) \n. (next = null =. next.Valid_self() . next.next = null =. next.next.Valid_self()) } method Singleton(t: \nT) modifies this; ensures fresh(Repr -{this}); ensures Valid(); ensures list = [t]; { this.data := t; \nthis.list := [t]; this.next := null; // repr stuff this.Repr := {this}; }  method Dupleton(p: T, q: \nT) method Find(n: T) returns (ret: bool) modifies this; requires Valid(); ensures fresh(Repr -{this}); \nensures fresh(Repr -old(Repr)); ensures Valid(); ensures Valid(); ensures list = [p, q]; ensures ret \n= (n in list); { decreases Repr; var gensym71 := new Node<T>; { gensym71.data := q; if (this.next = null) \n{ gensym71.list := [q]; ret := n = this.data; gensym71.next := null; } else { this.data := p; var x_5 \n:= this.next.Find(n); this.list := [p, q]; ret := n = this.data . x_5; this.next := gensym71; } // repr \nstuff } gensym71.Repr := {gensym71}; this.Repr := {this} + this.next.Repr; method Size() returns (ret: \nint) } requires Valid(); ensures fresh(Repr -old(Repr)); method Elems() returns (ret: seq<T>) ensures \nValid(); requires Valid(); ensures ret = |list|; ensures fresh(Repr -old(Repr)); decreases Repr; ensures \nValid(); { ensures ret = list; if (this.next = null) { decreases Repr; ret := 1; { } else { if (this.next \n= null) { var x_8 := this.next.Size(); ret := [this.data]; ret := 1 + x_8; } else { } var x_7 := this.next.Elems(); \n} ret := [this.data] + x_7; } } } Figure 13. Imperative Dafny code that Jennisys synthesizes for the \nabstract List program from Fig. 12. method Get(idx: int) returns (ret: T) requires Valid(); requires \n0 = idx; requires idx < |list|; ensures fresh(Repr -old(Repr)); ensures Valid(); ensures ret = list[idx]; \ndecreases Repr; { if (this.next = null) { ret := this.data; } else { if (idx = 0) { ret := this.data; \n} else { var x_6 := this.next.Get(idx -1); ret := x_6; } } }  C. Code Listings for the DList Example \n// exactly the same as the interface for List interface DList[T] { var list: seq[T] invariant |list| \n> 0 constructor Init(t: T) list := [t] constructor Double(p: T, q: T) list := [p q] method Elems() \nreturns (ret: seq[T]) ret := list method Get(idx: int) returns (ret: T) requires 0 = idx . idx < |list| \nret := list[idx] method Find(n: T) returns (ret: bool) ret := n . list  method Size() returns (ret: \nint) ret := |list| } datamodel DList[T] { var data: T var next: DList[T] var prev: DList[T] frame next \ninvariant next = null =. list = [data] next = null =. (list = [data] + next.list . next.prev = this) \nprev = null =. prev.next = this } Figure 14. Doubly-linked list speci.ed abstractly (declar\u00adatively) \nin Jennisys. Note that the interface speci.cation is exactly the same as for the singly-linked list (List \nfrom Fig. 12); only the datamodel is different to impose a different concrete representation. class DList<T> \n{ ghost var Repr: set<object>; ghost var list: seq<T>; var data: T; var next: DList<T>; var prev: DList<T>; \n function Valid_repr(): bool reads *; { this in Repr . null . Repr . (next = null =. next in Repr . \nnext.Repr = Repr . this . next.Repr) } function Valid_self(): bool reads *; { Valid_repr() . (next \n= null =. (list = [data] . list[0] = data) . |list| = 1) . (next = null =. list = [data] + next.list \n. next.prev = this) . (prev = null =. prev.next = this) . (|list| > 0) } function Valid(): bool reads \n*; decreases Repr; { this.Valid_self() . (next = null =. next.Valid()) . (next = null =. next.Valid_self()) \n. (next = null . next.next = null =. next.next.Valid_self()) } method Singleton(t: T) modifies this; \nensures fresh(Repr -{this}); ensures Valid(); ensures list = [t]; ensures list[0] = t; ensures |list| \n= 1; { this.data := t; this.list := [t]; this.next := null; this.prev := null; // repr stuff this.Repr \n:= {this}; }  method Double(p: T, q: T) modifies this; ensures fresh(Repr -{this}); ensures Valid(); \nensures list = [p, q]; ensures list[0] = p; ensures list[1] = q; ensures |list| = 2; { var gensym71 := \nnew DList<T>; this.data := p; this.list := [p, q]; this.next := gensym71; this.prev := null; gensym71.data \n:= q; gensym71.list := [q]; gensym71.next := null; gensym71.prev := this; // repr stuff this.Repr := \n{this} + {gensym71}; gensym71.Repr := {gensym71}; } method Elems() returns (ret: seq<T>) { // same as \nList.Elems } method Get(idx: int) returns (ret: T) { // same as List.Get } method Find(n: T) returns \n(ret: bool) { // same as List.Find } method Size() returns (ret: int) { // same as List.Size } } Figure \n15. Imperative Dafny code that Jennisys synthesizes for the abstract DList program from Fig. 14. D. \nCode Listings for the Math Example interface Math { method Min2(a: int,b: int) returns (ret: int) ensures \na<b =. ret = a ensures a = b =. ret = b method Min3Sum(a: int,b: int,c: int) returns (ret: int) ensures \nret . {a+b a+c b+c} ensures . x x . {a+b a+c b+c} =. ret = x method Min4(a: int,b: int,c: int,d: int) \nreturns (ret: int) ensures ret . {a b c d} ensures . x x . {a b c d} =. ret = x method Abs(a: int) \nreturns (ret: int) ensures ret . {a (-a)} . ret = 0 } datamodel Math {} Figure 16. Several math operations \nspeci.ed abstractly (declaratively) in Jennisys. class Math { ghost var Repr: set<object>; function Valid_repr(): \nbool reads *; { this in Repr . null . Repr } function Valid_self(): bool reads *; { Valid_repr() } \nfunction Valid(): bool reads *; { this.Valid_self() } method Min2(a: int,b: int) returns (ret: int) \nrequires Valid(); ensures fresh(Repr -old(Repr)); ensures Valid(); ensures a<b =. ret = a; ensures a \n= b =. ret = b; { if (a < b) { ret := a; } else { ret := b; } } method Min3Sum(a: int,b: int,c: int) \nreturns (ret: int) requires Valid(); ensures fresh(Repr -old(Repr)); ensures Valid(); ensures ret in \n{a+b, a+c, b+c}; ensures ret = a+b . ret = a+c . ret = b+c; { if (a+b = a+c . a+b = b+c) { ret := a+b; \n} else { if (b+c = a+b . b+c = a+c) { ret := b+c; } else { ret := a+c; } } } method Min4(a: int,b: int,c: \nint,d: int) returns (ret: int) requires Valid(); ensures fresh(Repr -old(Repr)); ensures Valid(); ensures \nret in {a, b, c, d}; ensures ret = a . ret = b . ret = c . ret = d; { if ((a = b . a = c) . a = d) { \nret := a; } else { if (d = b . d = c) { ret := d; } else { if (c = b) { ret := c; } else { ret := b; \n} } } } method Abs(a: int) returns (ret: int) requires Valid(); ensures fresh(Repr -old(Repr)); ensures \nValid(); ensures ret in {a, -a} . ret = 0;  { if (-a = 0) { ret := -a; } else { ret := a; } } } Figure \n17. Imperative Dafny code that Jennisys synthesizes for the abstract Math program from Fig. 16.  \n\t\t\t", "proc_id": "2384616", "abstract": "<p>The desired behavior of a program can be described using an abstract model. Compiling such a model into executable code requires advanced compilation techniques known as synthesis. This paper presents an object-based language, called Jennisys, where programming is done by introducing an abstract model, defining a concrete data representation for the model, and then being aided by automatic synthesis to produce executable code. The paper also presents a synthesis technique for the language. The technique is built on an automatic program verifier that, via an underlying SMT solver, is capable of providing concrete models to failed verifications. The technique proceeds by obtaining sample input/output values from concrete models and then extrapolating programs from the sample points. The synthesis aims to produce code with assignments, branching structure, and possibly recursive calls. It is the first to synthesize code that creates and uses objects in dynamic data structures or aggregate objects. A prototype of the language and synthesis technique has been implemented.</p>", "authors": [{"name": "K. Rustan M. Leino", "author_profile_id": "81100225265", "affiliation": "Microsoft Research, Redmond, WA, USA", "person_id": "P3856106", "email_address": "leino@microsoft.com", "orcid_id": ""}, {"name": "Aleksandar Milicevic", "author_profile_id": "81330495596", "affiliation": "Massachusetts Institute of Technology, Cambridge, MA, USA", "person_id": "P3856107", "email_address": "aleks@csail.mit.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384646", "year": "2012", "article_id": "2384646", "conference": "OOPSLA", "title": "Program extrapolation with jennisys", "url": "http://dl.acm.org/citation.cfm?id=2384646"}