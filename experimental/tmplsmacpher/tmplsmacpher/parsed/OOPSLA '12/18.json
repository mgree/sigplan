{"article_publication_date": "10-19-2012", "fulltext": "\n Molecule: Using Monadic and Streaming I/O to Compose Process Networks on the JVM S\u00e9bastien Bocq Koen \nDaenen Bell Labs, Alcatel-Lucent Antwerp, Belgium {sebastien.bocq, koen.daenen}@alcatel-lucent.com Abstract \nMolecule is a domain speci.c language library embedded in Scala for easing the creation of scalable and \nmodular concur\u00adrent applications on the JVM. Concurrent applications are modeled as parallel process \nnetworks that exchange infor\u00admation over mobile and type-safe messaging interfaces. In this paper, we \npresent a concurrent programming envi\u00adronment that combines functional and imperative program\u00adming. Using \na monad, we structure the sequential or parallel coordination of user-level threads, without JVM modi.ca\u00adtions \nor compiler support. Our mobile channel interfaces ex\u00adpose reusable and parallelizable higher-order functions, \nas if they were streams in a lazily evaluated functional pro\u00adgramming language. The support for graceful \ntermination of entire process networks is simpli.ed by integrating chan\u00adnel poisoning with monadicexceptions \nand resource control. Our runtime and system-level interfaces leverage message batching and a novel .ow \nparallel scheduler to limit expen\u00adsive context switches in multicore environments. We illus\u00adtrate the \nexpressiveness and performance bene.ts on a 24\u00adcore AMD Opteron machine with three classical examples: \na thread ring,a genuine prime sieve anda chameneos-redux. Categories and Subject Descriptors D.3.3[Programming \nLanguages]:Language Constructs and Features Concurrent programming structures; patterns; recursion; D.1.3 \n[Pro\u00adgramming Techniques]: Concurrent Programming; D.2.11 [Software Engineering]: Software Architectures \nDomain\u00adspeci.c architecture; languages; patterns; D.3.2[Program\u00adming Languages]: Language Classi.cations \nConcurrent, distributed, and parallel languages GeneralTerms Design, Languages, Performance Permission \nto make digital or hard copies of all or part of this work for personal or classroomuseisgrantedwithout \nfeeprovidedthat copies arenot madeordistributed forpro.tor commercialadvantage andthat copiesbearthisnotice \nandthefullcitation onthe .rstpage.To copy otherwise,to republish,topost onserversorto redistribute tolists, \nrequirespriorspeci.cpermission and/ora fee. OOPSLA 12, October19 26,2012,Tuscon,Arizona,USA. Copyright \nc &#38;#169; 2012ACM978-1-4503-1561-6/12/10.. .$10.00 Keywords Concurrent, parallel, multicore, DSL, \nDSEL, process networks, stream, functional programming, Scala 1. Introduction The design of concurrent \nsystems has been studied for sev\u00aderal decades already [Kahn 1974] and is getting increasing attention \nnow that multicore and cloud computing platforms are a commodity. Manyimplementations depend on special\u00adized \nlanguages and runtimes to make ef.cient use of paral\u00adlelism on multicore architectures. More recently, \nthere have been several efforts [Karmani et al. 2009] to provide ef.cient solutions on mainstream JVMs. \nThis is to leverage a mature and widely available execution platform, preserve interop\u00aderability with \na vast ecosystem of libraries and recycle the expertise gained by a large community of programmers. A \nnumber of important challengesfaced in the design of these systems are the following: How to leverage \nparallelism and shield programmers from data race issues?  How to coordinate interactions with non-blocking \nI/O interfaces, which are asynchronous and callback-driven, in a robust, scalable and composable manner? \n How to handle asynchronous termination, both in normal and exceptional cases?  How to schedule ef.ciently \nconcurrent tasks in multicore environment?  To adress the .rst point and ease reasoning about concur\u00adrent \napplications, a well established pattern is to structure these applications as networks of asynchronous \nand sequen\u00adtial activities that do not share state and interact exclusively over messaging interfaces. \nThe second and third points are related to each other. The main issue with programming di\u00adrectly against \ncallback interfaces is that the continuations [Clinger et al. 1988] capturing the different control .ows \nof a program have to be threaded explicitly by the pro\u00adgrammer through his program at the detriment of \nexpres\u00adsiveness. It violates encapsulation of the execution state as offered by threads [von Behren et \nal. 2003]. Furthermore, it forces developers to propagate termination information ex\u00adplicitly though \nthe control .ows of an application, both in normal and exceptional cases, which is intrusive and error \nprone. Existing work [Rompf et al. 2009; Srinivasan 2010] can restore the illusion of a lightweight threaded \nprogram\u00adming model in asynchronous settings in such a way that it integrates well with the native exception \nhandling mech\u00adanism present on mainstream JVMs using compile-time continuation-passing style (CPS) transformations. \nHowever, aprogrammer is still responsible for propagating termination information explicitly through \nthe data .ows embodied by a network of asynchronous activities, which is again intrusive and error prone. \nUnfortunately, compile-time transforma\u00adtions are themselves not trivial to maintain compared to pure \nlibrary approaches. They are also dif.cult to extend because they interact in non obvious manner with \nthe host platform threading model and language features such as exceptions and recursion. To gain a better \nunderstanding and control over termination, expressiveness and scheduling issues, this paper presents \ninstead a pure library approach that lever\u00adages Scala s [Odersky et al. 2011] support for functional \nprogramming on the JVM.  In this paper, we describe Molecule, a concurrent pro\u00adgramming library that \nruns on unmodi.ed JVMs. Molecule combines a process-oriented programming model [Sampson 2010], a domain \nspeci.c embedded language (DSEL) [Hu\u00addak 1998] and a run-time system. We exploited the higher extensibility \nof a pure library approach to offer a program\u00adming environment that combines the following advantages: \n An application-level threading model with support for se\u00adquential execution, parallel execution and \nspace-ef.cient tail calls. Molecule s user-level threading programming model [Anderson et al. 1992] implements \na continuation\u00adpassing form of monadic I/O [Peyton Jones andWadler 1993] at application-level to encapsulate \nlightweight pro\u00adcess interactions over non-blocking messaging interfaces in a simple and composable manner. \nThese user-level threads are not limited to sequential interactions and can interact safely in parallel \nover multiple type-safe messag\u00ading interfaces within a process in a non-blocking manner. In contrast \nto native JVM threads, theypermit also space\u00adef.cient tail calls within the monadic domain. Our users \ncan thus express sophisticated protocol state machines as in Erlang[Virdinget al. 1996] without theburdenof \nus\u00ading a code generator [Banker et al. 1998].  Control structures for automating the graceful termina\u00adtion \nof parallel process networks. Graceful termination is a well known pattern proposedbyWelch [1989] to \npre\u00advent deadlocks and resource leaks in process networks. However, the mechanism relies on the explicit \npropaga\u00adtion of a termination signal, which is tedious and error prone. As an extension, our monadic \nthreading model of\u00adfers resource control structures coupled with exception handling to seamlessly propagate \ntermination informa\u00ad  tion over the messaging interfaces of a process that ter\u00adminates, without explicit \nsupport from the application. Word-at-a-time and streaming communication primi\u00adtives. Compared to most \nconcurrent programming frame\u00adworks, our library also addresses theVon Neumann Bot\u00adtleneck [Backus 1978] \nby not restricting its messaging interfaces to word-at-a-time primitives only. Its type-safe communication \ninterfaces can be transformed lazily us\u00ading higher-order functions, like streams in functional pro\u00adgramming \nlanguages. Supporting streaming primitives on communication interfaces not only improves the ex\u00adpressiveness \nbut also permits the ef.cient processing of message batches.  A .ow parallel scheduler that exploits \nthe structure of process networks to optimize parallel resources usage.  The execution of parallel process \nnetworks is known to suffer inherently from a massive amount of context switches [Ritson et al. 2009].To \nalleviate this issue, we devised a scheduler that exploits our high-level abstrac\u00adtions to eliminateexpensive \nand unnecessarykernel-level context switches dynamically, whenever the data .ow is purely sequential. \nThe structure of the paper is as follows. Section 2 de\u00adscribes how Molecule models concurrent systems \nafter pro\u00adcess networks. Section 3 provides a detailed description of monadic user-level threads along \nwith our extensions for parallel interactions andexceptions. Section4describes our extensible channel \ninterfaces with their support for stream\u00ading primitives. Section 5 introduces the resulting program\u00adming \nmodel and our .ow parallel scheduler. In Section 6, we revisit several classical concurrent programming \nexamples to illustrate the expressiveness of our programming model. We augment the description with microbenchmarks \nto show the positive impact of our runtime optimizations in multi\u00adcore environments. Section7discusses \nthe relatedwork and Section8concludes. A monad [Wadler 1995] is a well known abstraction for computationsthathasbeenextensively \nstudiedinthe context of Haskell [Peyton Jones and Hughes 1999], a non-strict and pure functional programming \nlanguage. We do not assume any prior knowledge of Haskell but we require the reader to be familiar with \nScala 2.8 and its support for functional programming.  2. The Molecule Model Most concurrent programming \nframeworks aimed at real\u00adworld usage diverge from the seminal mathematical mod\u00adels that inspired their \ndesign.For instance, manyapproaches claim to be derived from the Actor model [Agha 1986; He\u00adwitt et al. \n1973] but they differ more or less importantly with it [Karmani et al. 2009]. Molecule s model cannot \nbe strictly categorized either. To avoid confusion with exist\u00ading models, we begin with its description \nand the terminol\u00adogy used throughout this paper in relation to previous work (Section 2.1). Finally, \nwe list the conventions clients of our library must follow to avoid the data race issues stemming from \nhosting a concurrent DSEL in an impure language like Scala (Section 2.2).  2.1 Model andTerminology \nIn Molecule, process networks are composed from three ab\u00adstractions: processes, channel interfaces and \ncommunication channels.Aprocess embodiesa coordination and computing activity [Gelernter and Carriero \n1992] and interacts with its external environment exclusively by manipulating channel interfaces.Achannel \ninterface is unidirectional it has ei\u00adther input or output modality.Acommunication channel, or a channel \nfor short, represents the set of physical means allo\u00adcated for the transport of information between its \ninterfaces. For performance reasons, a process can input/output a list of messages, which we call a segment, \nfrom/to a channel in\u00adterface in a single I/O operation. In our model, channel inter\u00adfaces aremobile in \nthe sense that they can be referenced as .rst-class values inside messages. One could say we differ from \nthe original p-calculus [Milner 1999] in that we dis\u00adtinguish between channels and their interfaces, \nand that the channel themselves are not mobile.Yet, we share the same intent, which is to ease the expression \nof recon.gurable sys\u00adtems that reorganize their network dynamically by exchang\u00ading channel information. \nA process can also install one or more transformation functions, which we call transformers, on a channel \ninter\u00adface, which can be thought as a stream in functional pro\u00adgramming languages.Forexample,a transformed \ninterface may map a function repeatedly to the segments that pass through it during I/O operations. A \ntransformation may be statful or not. It may also be temporary. For example, prepending a message on \na channel interface transforms this interfaceintoabuffered one untilthenextI/O operation. In addition \nto being dynamically recon.gurable, a pro\u00adcess network is also elastic. It grows dynamically when pro\u00adcesses \ncreate new channel interfaces or new processes, or install a new transformation function on a channel \ninterface. Channel interfaces are responsible for allocating resources for a given channel on a physical \nmedium. A process net\u00adwork shrinks when a process terminates, when a transforma\u00adtion ends, or when channel \ninterfaces are terminated. Aprocess may terminate a channel interface using asig\u00adnal that indicates the \nreason for termination. This is called poisoning because the signal spreads like poison through the network. \nThe behavior of an interface poisoned by a pro\u00adcess depends on its modality. When an output interface \nis poisoned, all the messages it may havebuffered will be pro\u00adcessed but any additional message output \nto it will be poi\u00adsoned. A message that is poisoned will never be delivered. Therefore, to ensure the \npropagation of termination infor\u00admation, we require that a poisoned message propagates the signal to \nall the channel interfaces it may reference.We call this mechanism message poisoning. If an input interface \nis poisoned with a certain signal, then any message buffered on the interface is poisoned with the same \nsignal and no new message will be delivered on that interface. In the remaining of this paper, we will \nsay that an input is poisoned and an output is closed to distinguish between both behaviours. In\u00adterfaces \npoisoned by a process must clear the resources they allocated on a channel and propagate the poison signal \nto the underlying channel. The subsequent behavior is channel spe\u00adci.c.Forexample,a channelmay decideornotto \npropagate the poison signal to all its other interfaces. Additionally, in\u00adterfaces must poison themselves \nwith an error signal if they detectafailure on the underlying channel.In both cases, the poisoning behavior \nis inverted when interfaces are poisoned from the channel side. In all cases, whenever an interface is \npoisoned, the corresponding signal is always returned to\u00adgether with the result of the last I/O operation. \nOutput channel interfaces can be poisoned synchronously during the emission of the last segment via an \nout-of-band signal token. Save for the last output operation, processes synchronizewithachannelbywaitingforthe \nresultofanI/O operation. We call it channel-driven scheduling. By hold\u00ading back the result of an I/O \noperation, channels can enforce ad-hoc .ow control schemes, independently from how pro\u00adcesses are implemented. \nThis permits for example to prevent the risks of unbounded growth of message queues present in purely \nasynchronous messaging systems. For example, a cooperative channel is a point-to-point channel interconnecting \ntwo processes within the same net\u00adwork. It exposes, therefore, both an input and an output channel interface. \nThe channel-driven scheduling policy of this kind of channel enforces that, irrespective of the order \nin which processes interact, there is never more than one input oroutput operationpendingatatime.Notethat,asexplained \nin the previous paragraph, a process can proceed immedi\u00adately after outputting its last segment, regardless \nof whether an input operation is pending or not on the same channel1. Because of this subtle distinction, \ncooperative channels are not strictly equivalent to synchronous channel or rendezvous channel used in \nimplementations of communicating sequen\u00adtial processes (CSP) [Hoare 1978].  2.2 Restrictions on Side \nEffects Processes and channel transformation functions may be ex\u00adecuted in parallel. Therefore, the following \nrestrictions must be applied to prevent data races: 1. Processes are isolated, i.e. theymust not share \nreferences to mutable state. 2. Higher-order streaming primitives must accept only pure functions. \n 1Note that we apply the argument that a synchronous handshake between intermediate parts of a distributed \nsystem is not a substitute for end-to\u00adend delivery mechanisms [Saltzer et al. 1984]. Reliable end-to-end \ndelivery cannot be guaranteed in absence of end-to-end feedback.  In Scala, the .rst requirement can \nbe enforced by leveraging existing work on a uniqueness type plugin [Haller and Oder\u00adsky2010]. Enforcing \nthe second one requires a type and ef\u00adfect system in Scala, which is work in progress at the time of \nthis writing [Rytz et al. 2012]. In their absence, we rely on the good will of the clients of our library \nto follow these rules as conventions.We will assume that these conventions are strictly followed in the \nremainder of this paper.  3. Monadic User-Level Threads This section describes the design of our lightweight \nand ex\u00adtensible threading programming model. Then, we introduce two extensions not available with native \nJVM threads: inter\u00adleaved parallelism and user-level exceptions with resource control. The support for \nbatching, higher-order streaming primitives and poisoning will be introduced in Section 4. 3.1 Monadic \nStyle In manyconcurrent programming frameworks, non-blocking programs are written in so-called callbackstyle. \nIn this style, non-blocking methods accept a callback handler as param\u00adeter and return immediately while \nthe result is computed asynchronously. In Scala, a callback is simply a function of type A => Unit, where \nA is an abstract parameter type. The callback function captures a one-shot and effectful con\u00adtinuation \nclosure it is called once and captures the rest of an effectful computation from a given point in a \npro\u00adcess. To shield application developers from callback inter\u00adfaces, Molecule introduces a touch of \nlaziness by encapsu\u00adlating callback-driven effects behind the IO class shown in Figure 1. This class \nis essentially combining a mutable-state monad and a specialized form of continuation monad, called Responder \nin Scala s standard library. trait UThread { def submit(task: => Unit):Unit def platform:Platform } final \nclass IO[+A]( val ask:(UThread, A => Unit) => Unit ){ def bind[B](react:A => IO[B]):IO[B] = new IO((t, \nk) => ask(t, a => react(a).ask(t, k))) def >>\\[B](react:A => IO[B]):IO[B] = bind(react) def >>[B](next: \n=> IO[B]):IO[B] = bind(_ => next) def flatMap[B](f:A => IO[B]):IO[B] = bind(f) def map[B](f:A => B):IO[B] \n= new IO((t, k) => ask(t, a => k(f(a)))) } object IO { def apply[A](a: => A):IO[A] = new IO((t, k) => \nk(a)) } Figure 1. The IO class. In monadic style, non-blocking methods implement the ask function, which \ntakes a user-level thread UThread and a continuation of type A => Unit as argument, but return it wrapped \nin an object of type IO[A], commonly called ac\u00adtion.A user-level thread is responsible for mapping the \nexe\u00adcution of the continuation tasks of a lightweight process to a common multitasking system abstracted \nby the Platform class. This assumes that the application of a continuation to its result is rescheduled \nby an asynchronous action as a task to its accompanying user-level thread. Below is a short example illustrating \nthe encapsulation of an asynchronous function called fooAsync into an asynchronous action foo: def fooAsync(a:A, \nk:B => Unit):Unit = ... def foo(a:A):IO[B] = new IO[B]((t, k) => fooAsync(b => t.submit(k(b))) ) The \nsubmit methods captures the application of the contin\u00aduation as a task using a call-by-name parameter. \nThe ability to control this mappingisvaluable.Forexample,a platform may schedule continuation tasks over \na dedicated thread pool or over a single threaded executor whose thread local storage is set to an OpenGL \nrendering context. In contrast to callback methods, an action defers the exe\u00adcution of a continuation \nuntil its ask function is invoked.We chose to call this function ask to emphasize the demand\u00addriven and \nasynchronous execution, i.e. one asks for the re\u00adsult of an action, and executes it, by applying its \nask func\u00adtion to a user-level thread and a continuation. A crucial bene.t of introducing laziness via \nthis extra level of indi\u00adrection, compared to programming against callback inter\u00adfaces directly, is that \nactions can be composed sequentially into bigger actions in a type-safe and modular manner us\u00ading the \nmonadic binding combinator bind, or the equivalent >>\\ operator2. The bind operator permits to chain \nthe next action as a function of the result of the previous one; we call this function reaction. For \nexample, assuming the abstract types A and B are strings, to bind the result of the action foo to another \ncall to foo, one can write: foo(\"a\") >>\\ { s => foo(s) } instead of: new IO[String]((t, k) => fooAsync(\"a\", \ns => t.submit( fooAsync(s, ss => t.submit(k(ss))) ))) The >> operator is another common monadic operator \nused to sequence two actions that are not related by the intermediate result. The method flatMap and \nmap are methods required 2We chose this operator over the \u00bb= operator commonly used in Haskell because \nof special precedence rules applied to operators with the = symbol in Scala.  to use monadic actions \nin Scala s for-comprehensions. The factory method, commonly calledunit or return in monadic terms, is \nimplemented by the apply method of the compan\u00adion object. It creates a new action that results in the \nvalue of its call-by-name parameter. It can be easily proven, by applying equational reason\u00ading rules \nin Scala, that the IO class satis.es the three monad laws. These laws ensure that the monadic combinators \ncon\u00adstrain the execution of effectful actions in a robust and in\u00adtuitive manner, independently from the \nevaluation order or from the side effects executed within the ask function. Intu\u00aditively, this can be \ndeduced by observing that the composi\u00adtion of monadic actions does not produce anyside effect only their \nexecution does. Although the user-level thread interface bears some simi\u00adlarities with the executor service \ninterface found in the stan\u00addard Java library, it differs in that it must obeythe two addi\u00adtional requirements \nlisted in the paragraphs below. Space-ef.cient recursion (R1). Since we arebuildinga sys\u00adtem where processes \ninteract with the external world only through non-blocking channel interfaces, the side effects of a \nprocess can only be the byproducts of executing contin\u00aduations, which will themselves trigger other continuations, \nand so on. Therefore, the execution of a process is recur\u00adsive and the stack of the underlying native \nthread must be unwound after executing each continuation task to prevent risks of stack over.ows. Sequential \ntask execution (R2). Werequire thatauser-level thread executes each task it gets submitted sequentially \nand that the effects of one task are visible to the next task in a happens-before relationship [Manson \net al. 2005]. This eases reasoning about the behavior of the implementationbut also guarantees that mutable \ndata structures can be manipulated safely from within a process, even if a process interacts over multiple \nchannel interfaces simultaneously. Space-Ef.cientTail Calls Given thefact that asynchronous actions resubmit \ntheir continuation to the user-level thread, thanks to R1, the invocation of an asynchronous action in \ntail call position in a bind expression does not create ad\u00additional stack or heap usage. This property \ncan be demon\u00adstrated easily using equational reasoning in Scala, writing the justi.cation for each step \nin the right hand column. The proof depends on two intermediate lemmas. Lemma 1 (L1). An action that \nhas no other effect than passing control to another action m is equivalent to that action. new IO((t, \nk) => m.ask(t, k)) = m Proof: By construction, to ask for the result of the left-hand side of the equation \nis equivalent to ask for the result of m. Lemma2(L2). To ask for the result of the action created by \nbinding the action m to a function f is equivalent to apply f to the result of m, and then to ask the \nresult of the action thus created. (m >>\\ f).ask(t, k) = m.ask(t, a => f(a).ask(t, k)) Proof: (m >>\\ \nf).ask(t, k) = new IO((t, k) => bind m.ask(t, a => f(a).ask(t, k)) ).ask(t, k) = m.ask(t, a => f(a).ask(t, \nk)) (L1) Theorem. The execution of an action bound in a tail position does not increase stack or heap \nusage. Proof: Given requirement R1, the stack is unwound each time an action is executed. Given L2, the \ncontinuation k passed to an action resulting from a bind operation is the same as the one passed to the \naction bound in tail position. This does not create new objects or reference older objects on the heap. \nExamples Thanks to their support for space-ef.cient tail calls, our monadic threads permit the de.nition \nof recursive control structures or .nite state machines as easily as in Erlang [Wadler 1998]: just have \none method returning an action for each state, with state transition represented by a bindtoan actionin \ntail call position.Forexample, without anyadditional library support, we can easily create a space\u00adef.cient \nlooping structure that repeats an action a given number of times before returning control with the unit \nvalue: def repeat[A](n:Int)(action:IO[A]):IO[Unit] = if (n == 0) IO(()) else action >> repeat(n -1)(action) \n We can contrast the native and the monadic thread models on a simple example where a process writes \nthe .rst string it receives from its input to its output in lower case, and then writes the ten subsequent \nstrings it receives in upper case. According to our model, we implement each interaction of a process \nwith the environment as a read or write I/O operation on a channel interface. As such a process can be \nwritten as a main function that takes a number of input and output interfaces as arguments, and returns \nthe .nal result of the process. The natively threaded version of this process that uses blocking I/O \ninterfaces is shown on Figure 2. The non-blocking version, based on our lightweight threading mechanism \nto interact over monadic I/O interfaces, is shown in Figure 3. Since we have de.ned the map and flatMap \nmethods, we can take advantage of for-comprehensions to sequence actions. Notwithstanding some minor \nsyntactic noise created by the for-comprehension and the IO type used to denote ef\u00adfects, the non-blocking \nversion reads the same way as a na\u00adtively threaded implementation. In both cases, the thread executing \nthe process is threaded transparently through se\u00adquential statements that appear on consecutive lines \nin the program.  trait Input[+A] { def read():A } trait Output[-A] { def write(a:A):Unit } def main( \nin:Input[String], out:Output[String] ):Unit = { val s = in.read(); out.write(s.toLowerCase); for (i <-0 \nuntil 10) { val s = in.read(); out.write(s.toUpperCase); } } Figure 2. Example using a native thread. \ntrait Input[+A] { def read():IO[A] } trait Output[-A] { def write(a:A):IO[Unit] } def main( in:Input[String], \nout:Output[String] ):IO[Unit] = for { s <-in.read() _ <-out.write(s.toLowerCase) _ <-repeat(10) { for \n{ s <-in.read() _ <-out.write(s.toUpperCase) } yield () } } yield () Figure 3. Example using a monadic \nthread. In some cases, the syntax of the for-comprehension may appear a bit clumsy and it is not uncommon \nfor seasoned functional programmers [Peyton Jones et al. 1996] to rely directly on monadic binding(>>\\ \n)and sequence(>> )combi\u00adnators like this: in.read() >>\\ {out.write(_.toLowerCase)} >> repeat(10) { in.read() \n>>\\ {out.write(_.toUpperCase)} } Whichever style of monadic expression one chooses, it rep\u00adresents a \nsubstantial improvement in clarity and modularity compared to what can be achieved by programming directly \nagainst callback interfaces.For completeness, we musthow\u00adever mention two potential causes of mistakes. \nOne comes from how Scala s for-comprehensions are desugarized and the other from the lack of a type and \neffect system. Atail call within a for-comprehensions is not space-ef.cient. An in.nite loop written \nusing a for-comprehension: def forever[A](action:IO[A]):IO[Nothing] = for (_ <-action; _ <-forever(action)) \nyield () is expanded by the compiler to: def forever[A](action:IO[A]):IO[Nothing] = action.flatMap(_ \n=> forever(action).map(_ => ())) The return type IO[Nothing] indicates that the method does not return \nnormally. Since the call to forever is fol\u00adlowed by a map, it is not in tail call position and each iter\u00adation \nwill accumulate a continuation until the program ex\u00adhausts the heap space. Therefore, one must take care \nthat tail calls appear only as argument to the bind combinator, for example by binding the tail call \nafter a for-comprehension. Actions on consecutive lines must be separated by the se\u00adquence combinator. \nIf one forgets the monadic sequence op\u00aderator(>> )between actions appearing on consecutive lines, the \ncode will compile,but only the action on the last line will be executed. Such error could be caught at \ncompile-time us\u00ading a type directed compiler plugin aware that IO objects do not induce side effects \nuntil they are executed.  3.2 InterleavedParallelism The bind operator ensures that an action is executed \nin re\u00adactiontoaprevious action.Aprocessmayalso interactover multiple channels and execute several unrelated \nactions on each channel simultaneously before joining the .nal results. The execution of two unrelated \nactions can be coordinated by de.ning an additional par combinator on the IO class, as shown in Figure \n4. def par[B](other:IO[B]):IO[(A, B)] = new IO[(A, B)]({(t, k) => var first:Option[Any] = None val ka:A \n=> Unit = {a => first match { case None => first = Some(a) case Some(b:B) => k((a, b)) } } val kb:B => \nUnit = {...} this.ask(t, ka) other.ask(t, kb) }) Figure 4. The parallel interleaving combinator. The \npar combinator creates a new action that executes, in one task, the current action and the action passed \nas pa\u00adrameter, and then collects each result in a pair. The two ac\u00adtions will have their continuation \ntasks scheduled by chan\u00adnel interactions independently from each other, in a non\u00addeterministic manner. \nSinceauser-level threadexecutes con\u00adtinuation tasks sequentially (R2), we call it interleaved par\u00adallelism. \nThis is the reason whywe can safely store the result of the .rst action using a mutable variable until \nthe second result becomes available.  Note that this combinator shares the same algebraic prop\u00aderties \nas the fork operator discussed by Jones and Hudak [1993]. It is associative and it is also commutative \nonly if both actions executed are themselves commutative, this last property being left as a proof obligation \non the programmer.  3.3 Exceptions, Resource Control and Graceful Termination Being able to signal the \nend of communication is required in order to support .nite communication between processes. For normal \nexecution it is suf.cient to support a close op\u00aderation on an output interface and let a channel propagate \na signal downstream. However, a receiver may stop communi\u00adcating as well, because of a network or hardware \nfailure, a bug, or other interruptions. Although this is not a substitute for transactions, a mechanism \nto inform a sender process to stop using resources because its messages cannot be deliv\u00adered has been \nproposed by Hilderink [2005]. In this scheme, an output interface can be invalidated downstream with \na poison signal. Subsequent interactions on that interface raise an exception that can be caught inside \na process using an ex\u00adception handler scoped around that interaction. If the process cannot handletheexception,itis \nresponsiblefor propagating it by poisoning its other interfaces in the exception handler before terminating. \nHowever, propagating explicitly poison\u00ading information within exception handlers to ensure graceful termination \nis intrusive and very brittle given that spurious errors often occur where you leastexpect them.To address \nthese issues, we augmented our monadic threads with a re\u00adsource control mechanism that poisons automatically \nchan\u00adnel interfaces acquired within a block guarded by an excep\u00adtion handler. The library can then wrap \nthe main action of a process within an exception handler such that any chan\u00adnel interface it acquired \ndynamically (including the initial ones) is automatically poisoned once the process terminates. Since \nwe share the same signal type for both user-level ex\u00adceptions and poison signals, the termination information \nwill be seamlessly propagated through the channels registered as resource to the current context. The \nscheme encompasses normal termination, user-levelexceptions raisedbypoisoned channels and Java runtime \nexceptions. The UThreadContext class shownin Figure5augments a user-level thread with exception and resource \ncontrol. Its constructor takes as parameter the user-level thread to aug\u00adment, a Context object used \nto track managed resources and two continuations used to handle exceptional control .ows. Channel interfaces, \nor any other resource inheriting from the Resource trait, can be registered to the local re\u00adsource control \nby calling the add method on the Context object referenced by the user-level thread. This implemen\u00adtation \ndistinguishes between non-fatal and fatal exceptions and assumes that the corresponding raise and fatal \ncon\u00ad trait Signal case object EOS extends Signal case class JThrowable(t:Throwable) extends Signal trait \nResource { def shutdown(signal:Signal):Unit } class Context extends Resource { def add(r:Resource):Unit \n= ... def remove(r:Resource):Unit = ... def shutdown(s:Signal):Unit = ... } class UThreadContext( val \nuthread:UThread, val context:Context, val raise:Signal => Unit, val fatal:Signal => Unit ) extends UThread \n{ def submit(task: => Unit):Unit = uthread.submit { try { task } catch { case t => fatal(JThrowable(t)) \n} } def platform:Platform = uthread.platform def askInNewContext[A]( ask:(UThreadContext, A => Unit) \n=> Unit, k:A => Unit, handle:Signal => Unit):Unit = { val newContext = new Context() def cleanup(signal:Signal) \n= { newContext.shutdown(signal) } val newUThread = new UThreadContext( uthread, newContext, {signal \n=> // (3) non-fatal exception cleanup(signal); handle(signal)}, {signal => // (2) fatal exception cleanup(signal); \nfatal(signal)} ) ask(newUThread, {a => // (1) normal termination cleanup(EOS); k(a)}) } } Figure 5. The \nuser-level thread context. tinuations call the shutdown method of the Context object to propagate the \nsignal to the resources it manages. Java run\u00adtime exceptions caught inside the submit method during the \nexecution of a task are passed as a JThrowable signal to the fatal continuation. The raise continuation \nis called by a poisoned channel interface to raise its signal as a user-level exception when a process \nattempts to read or write to it.  For example, processes can raise an exception using the following \nmethod3: def raise(signal:Signal):IO[Nothing] = new IO[Nothing]((t, _) => t.raise(signal)) The askInNewContext \nmethod scopes the execution of a speci.c action to a new context and manages the different control .ows \nsuch that the contract is respected. It takes as paraleter the ask function of the action to execute, \na continuation k on which to pass the result of the action if there is no exception, and another continuation \nhandle that is invoked if a non-fatal signal is raised during the execution of the action. Whichever \nway the action scoped by this method terminates (see comments (1), (2), (3) in Figure 5), all the resources \nit registered to the new con\u00adtext during its execution are automatically poisoned by the cleanup method. \nIf the action terminates normally (1), its resources are poisoned with a standard end-of-stream (EOS) \nsignal before the continuation k is applied to its result. If an exception occurs (2 and 3), resources \nare poisoned with the corresponding signal. The subsequent behavior depends on whether it is a fatal \nexception or not. A Java runtime exception, which is raised as a fatal exception (2), cannot be intercepted \nwithin the process where it occurs and ul\u00adtimately causes the termination of that process by poison\u00ading \nall its channels. Yet, since its channels have been poi\u00adsoned, the signal will be raised as a non-fatal \nexception (3) within a neighbour process that attempts to interact on one of these channels. Non-fatal \nexceptions are passed to the handle continuation. This hook is used in conjunction with the orCatch method \nde.ned on the IO monad we refac\u00adtored below to let application developers implement fault\u00adtolerance actions \nfor signals de.ned by a partial function: final class IO[+A]( val ask:(UThreadContext, A => Unit) => \nUnit ) {... def orCatch[B >: A]( handler:PartialFunction[Signal, IO[B]] ):IO[B] = new IO({(t, k) => t.askInNewContext(ask, \nk, {signal => if (handler.isDefinedAt(signal)) // continue in the parent context handler(signal).ask(t, \nk) else // raise in the parent context t.raise(signal) }) }) } Since orCatch scopes resource control \nand exception han\u00addling to the action they target, exception handlers can be safely nested within each \nother. Depending on whether a sig\u00ad 3We could resubmitthe continuationtotheuser-level threadinsynchronous \nactions as well to prevent exhausting the stack in case the given action is expected to be called many \ntimes successively. However, we don t .nd it necessary as this situation does not occur in practice. \nnal handler is de.ned or not for an exception signal, the sig\u00adnal will be handled by a user-de.ned action \nin the parent context or propagated up the chain of exception handlers. Custom coordination methods de.ned \nby application de\u00adveloperscantakeadvantageofthis resource control.Forex\u00adample, the control structure \nwe de.ned previously to repeat an action can be rewritten like this: def managed[A](action:IO[A]):IO[A] \n= action.orCatch { case signal => raise(signal) } def repeat[A](n:Int)(action:IO[A]):IO[Unit] = if (n \n== 0) IO(()) else managed { action } >> repeat(n -1)(action) The call to managed creates an execution \ncontext for the action by wrapping it inside a user-level exception handler. This ensures that all the \nresources acquired by the repeated action are automatically cleared up after each iteration. Note that \nthe implementation of par we saw previously is made slightly more complex by the introduction of user\u00adlevelexceptions.For \ninstance,it mustinvoke ask ina new context to handle potential signals raised by interleaved ac\u00adtions \nand ensure that the control is returned only when both actions have terminated, successfully or not. \nNote also the remarkable encapsulation propertiesof monadic threads.We introduced more sophisticated \ncontrol .ows, including state, without impacting the expressiveness of anyof the programs shown earlier \nas examples.  4. Communication Channels This section describes Molecule schannel interfaces.Forex\u00adtensibility \nand reusability concerns, the design of our chan\u00adnel interfaces has been split over three distinct layers, \neach one with well de.ned responsibilities. System-level channel interfaces encapsulate side effects. \nDevelopers implement these interfaces to create new I/O channels that convert messages into real-world \nside ef\u00adfects and back, independently from our user-level thread\u00ading model (Section 4.1). Stream channel \ninterfaces wrap system-level channels into channels that expose reusable streaming primitives implemented \nby the library (Section 4.2). Process-level interfaces wrap stream channels into the monadic I/O interfaces \nintroduced in the previous section. These are registered as resources to the user-level thread context \nof a process and manipulated conveniently from ac\u00adtions, using either word-at-a-time or streaming primitives \n(Section 4.3). Thanks to this separation of concerns, new system-level interfaces, whether they are blocking \nor not, can be integrated easily in Molecule. This is alsofacilitated by the hybrid imperative-functional \nnature of Scala, which lets developers access directly low-level interfaces exposed by the JVM.  4.1 \nSystem-Level Channel Interfaces In Molecule, all communication effects are encapsulated within the minimalist \nsystem-level channel interfaces listed in Figure 6. Stream generators, cooperative channels, timer channels \nand other I/O channels offered by the library or de.ned by the end user must implement one or both of \nthese interfaces. trait SysIChan[+A] { def read(k:(Seg[A], SysIChan[A]) => Unit):Unit def poison(signal:Signal):Unit \n } trait SysOChan[-A] { def write(data:(Seg[A], Option[Signal]), k:SysOChan[A] => Unit):Unit def close(signal:Signal):Unit \n} case class NilChan(signal:Signal) extends SysIChan[Nothing] with SysOChan[Any] { def read(...):Unit \n= sys.error(\"Nil:\" + signal) def write(...):Unit = sys.error(\"Nil:\" + signal) def poison(signal:Signal):Unit \n= {} def close(signal:Signal):Unit = {} } Figure 6. System-Level Channel Interfaces. These interfaces \nare modeled after a standard recursive pattern in Haskell to lift side effects inside immutable set\u00adtings. \nIn this pattern, any modi.cation brought to a stream returns a reference to the channel used in subsequent \ninter\u00adactions, also called a seed [Coutts et al. 2007]. Here, we rely on the continuation k to return \nthe seed lazily and we ex\u00adposeanextra methodto poison channels asynchronously.A system-level input channel \nSysIChan encapsulates batches of side effects produced by a communication interface in\u00adside an immutable \nstream segment abstracted by the class Seg.Asystem-level output channel SysOChan abstracts the reverse \noperation: it consumes immutable segments to pro\u00adduce side effects. In addition, system-level output \nchannels support synchronous poisoning by allowing an optional sig\u00adnal to be piggy backed with the last \nmessage sent. Clients of these channel interfaces can detect termination, and extract the poisoning signal \nindicating the cause of termination, by matching the next seed channel against the invalidated chan\u00adnel \nNilChan. Since we require that channel interfaces are non-blocking, the only proof of obligation for \nthe developer that wishes to implement a channel that must perform blocking I/O is to store a reference \nto the continuation and reschedule block\u00ading tasks in an external thread managed behind the channel. \nThe continuation, suspended on a read or write operation, can then be invoked back later by the thread \nafter it has completed the corresponding blocking I/O operation. For example, the one shot timer channel \nshown in Figure 7 re\u00adlies on an external executor for scheduling an event after a given delay and holds \nthe read continuation in a private variable kopt until the event occurs. object TimerChan { import java.util.concurrent._ \nval executor:ScheduledExecutorService = ... def after(delay:Long, unit:TimeUnit):SysIChan[Unit] = new \nSysIChan[Unit] with Runnable { type K = (Seg[Unit], IChan[Unit]) => Unit val sf = executor.schedule(this, \ndelay, unit) var kopt:Option[K] = None var ready = false def read(k:K):Unit = synchronized { if (ready) \nk(Seg(()), NilChan(EOS)) else kopt = Some(k) } def run() = synchronized { kopt match { case Some(k) \n=> kopt = None; k(Seg(()), NilChan(EOS)) case None => ready = true } } def poison(signal:Signal) = synchronized \n{ sf.cancel(false) kopt foreach {k => k(NilSeg, NilChan(signal))} } } } Figure 7. Aone shot timer channel. \n 4.2 Stream Channel Interfaces Stream channel interfaces (Figure 8) are implemented by the library. \nThey provide reusable streaming primitives on top of system-level channels, which are automatically lifted \nto stream channels using implicit conversions. The role of the Message context bound can be ignored for \nthe moment; it will be described further down this section. Stream input channels have the following \nfeatures and responsibilities: Theyreschedule the application of continuations invoked by system-level \nchannels as a task to the user-level thread passed as argument to their read or write method (R1).  \nThey stack higher-order transformations passed to the add method on the underlying channel. The library \noffers various stream transformation functions, we call stream transformers, for .ltering, mapping functions \nto, parsing, grouping or splitting streams (in this case, the remainder of a stream is returned via another \ncontinuation), and so on. For convenience, the trait exposes several methods named after classical list \noperations. Some transforma\u00adtions may not be permanent. For example, the prepend   operator :: de.ned \non this trait adds a transformer that returnsa newchannel whose read operation returnsa seg\u00adment containing \nthe prepended message together with the original channel. They parallelize stream transformations above \na com\u00adplexity cutoff threshold (CCT) con.gured by the user. This threshold limits the number of synchronous \ntrans\u00adformations stacked on a channel, which is tracked by the complexity method. When the threshold \nis exceeded, the block of transformations previously stacked on the channel will be parallelized transparently \nby the library and the complexity of the channel resulting from the last transformation is set back to \n0. The threshold should not be taken too large to avoid exhaustion of the stack space. However, there \nis some room for tuning this value since the stack size left to a new transformation is given by the \nformula StackSize = StackSizeMax - complexity, where StackSizeMax is the maximum stack size of na\u00adtive \nthreads, which is usually quite high.  They split segments when their size exceeds a library wide segment \nsize threshold (SST) con.gured by the end user. The remaining part of a segment is prepended to the next \nseed channel. Using large segments may improve the throughput of applications while using shorter ones \nhelps to preserve the reactiveness of the system.  They may fuse stream transformations dynamically \nto eliminate intermediate segment creation [Wadler 1988]. A similar technique described by Coutts et \nal. [2007] is used as a compile-time optimization in Haskell to remove intermediate list creations. Here \nthe library performs pat\u00adtern matching on the class of the transformer passed to the add method at runtime \nto decide if it can be fused with the previous one or not using hard-coded rules4.  Stream output channels \nfollow a similar design philos\u00adophy. For example, they support transformations to .lter, mapa functionorbuffer \nmessages senttothe channel.They do not track the complexity because we have not yet en\u00adcountered a use \ncase where manyoutput transformations are stacked together on an output channel. The ability to apply \nhigher-order transformations to both input and output channels, which is particularity of our li\u00adbrary, \nbene.ts expressiveness and performance. For exam\u00adple, instead of inserting a process between a decoder \nand an encoder process, a process can just add decoding and encod\u00ading functions respectively to its input \nand output channels. These will apply the transformation functions directly to the messages carried in \nthe underlying segments in a tight loop. Message Poisoning Messages in transit may be dropped because \nthey are .ltered by a channel or because the input 4Every fusion framework should come with a rigorous \ncorrectness proof, however carrying such a proof is not a trivial exercise, as explained by Coutts et \nal. and it would largely exceed the scope of this paper. trait IChan[+A] { def complexity:Int def read(t:UThread, \nk:(Seg[A], IChan[A]) => Unit):Unit def add[B:Message]( transformer:IChan[A] => IChan[B]):IChan[B] def \npoison(signal:Signal):Unit def ::[B >: A :Message](b:B):IChan[B] = add(IBufferT(b)) def map[B:Message](f:A \n=> B):IChan[B] = add(IMapperT(f)) def filter(p:A => Boolean) (implicit ma:Message[A]):IChan[A] = add(IFilterT(p)) \n... } trait OChan[-A] { def write(t:UThread, data:(Seg[A], Option[Signal]), k:OChan[A] => Unit):Unit \ndef poison(signal:Signal):Unit def add[B:Message]( transformer:OChan[A] => OChan[B]):OChan[B] def map[B:Message](f:B \n=> A):OChan[B] = add(OMapperT(f)) ... } Figure 8. Stream Channel Interfaces. interfaceofa channelis poisoned \nwhileitisbuffering mes\u00adsages that are pending delivery. Since messages may them\u00adselves reference channels \ninterfaces, our poisoning scheme must know how to poison the channel interfaces carried in\u00adside these \nmessages to ensure the proper propagation of the poisoning signal. For convenience, the library uses \nScala s type classes mechanism [Oliveira et al. 2010] to let the compiler pass implicitly a Message dictionary \nto functions that may need to poison messages: abstract class Message[-A] { def poison(a:A, signal:Signal):Unit \n} The library takes care of providing sensible default values for standard type messages. This is for \nexample the case for stream channel types themselves: implicit def ichanIsMessage[A]:Message[IChan[A]] \n= new Message[IChan[A]] { def poison(ichan:IChan[A], signal:Signal):Unit = { ichan.poison(signal) } } \nimplicit def ochanIsMessage[A]:Message[OChan[A]] = ... By default, user de.ned messages are pure , i.e. \nthe poi\u00adson method does nothing and the messages will be simply garbage collected. This behavior may \nbe overridden using Scala s standard implicit prioritization mechanism, for ex\u00adample, by providing a \nspecialized implicit de.nition in the companion object of a user de.ned message.  4.3 Process-Level \nChannel Interfaces Process-level channel interfaces shown in Figure 9 are I/O interfaces manipulated \nfrom monadic threads (Section 3). They expose streaming, word-at-a-time and poisoning prim\u00aditives. The \ndescription of these methods will be covered pro\u00adgressively in the various examples introduced later \nin this paper. End users invoke the open coordination primitives shown below to lift stream channels \ninterfaces into process\u00adlevel interfaces. def open[A:Message](ichan:IChan[A]):IO[Input[A]] = new IO((t, \nk) => k(new Input(t, ichan))) def open[A:Message](ochan:OChan[A]):IO[Output[A]] = new IO((t, k) => k(new \nOutput(t, ochan))) These interfaces keep track of the seed passed to continu\u00adation of stream channel \ninterfaces on behalf of lightweight processes using a private variable. They also register them\u00adselves \nas resources to the user-level thread context passed as argument to their constructor such that theyget \nautomati\u00adcally poisoned when the context is cleaned up. Alternatively, end users may invoke their release() \nmethod to get back the underlying stream channel and removethe interface from the resource control of \nthe current process. abstract class SelInput[+A] { //Selectable Input def read():IO[A] def foreach[B](f:A \n=> IO[B]):IO[Unit] def <+>[B](right:SelInput[B]):SelInput[Either[A, B]] } class Input[+A:Message]( t:UThreadContext, \nprivate[this] var ichan:IChan[A]) extends SelInput[A] extends Resource { def map[B:Message](f:A => B):Input[B] \n= ... def filter(p:A => Boolean):Input[A] = ... def span(p:A => Boolean):Input[A] = ... ... def release():IO[IChan[A]] \n= ... def poison(s:Signal = EOS):IO[Unit] = ... } class Output[-A:Message]( t:UThreadContext, private[this] \nvar ochan:OChan[A]) extends Resource { def write(a:A):IO[Unit] = ... def flush(in:Input[A]):IO[Unit] \n= ... def map[B:Message](f:B => A):Output[B] = ... ... def release():IO[OChan[A]] = ... def close(s:Signal \n= EOS):IO[Unit] = ... } Figure 9. Process-Level Channel Interfaces. Buffered I/O Although process-level \nchannel interfaces expose streaming primitives, sometimes it is convenient to process messages one at \na time using imperative read and write primitives. To preserve the performance bene.ts of batching, process-level \nchannels are buffered. Messages buffered on an output during write operations are .ushed in a single \nsegment once the output is closed or when the pro\u00adcessis suspended.For instance,a process canbe suspended \nduring a read operation if it has consumed all the messages containedinthe lastsegmentbufferedby that \ninput. 4.4 An Example of Choice We call the<+> operator de.ned on process-level input chan\u00adnels, the \ninput choice, in analogy to the p-calculus + opera\u00adtor. The action: (x <+> y).read() >>\\ { case Left(v) \n=> P(v) case Right(w) => Q(w) } will either read a value v from channel x and then behave likeP or readavalue \nw from channel y and behave like Q. As observed by Peyton Jones et al. during the design of Concurrent \nHaskell [1996], the choice operator is expensive to implement, but we .nd it useful. For example, this \nop\u00aderator can be used in conjunction with the one shot timer channel de.ned in Section 4.1 to de.ne a \nmethod that reads a message within a given delay: def readWithin[A](in:Input[A], delay:Long, unit:TimeUnit \n):IO[Option[A]] = managed { open(TimerChan.after(delay, unit)) >>\\ {timer => (timer <+> in).read() map \n{ _.fold(Function.const(None), Some(_)) }} } This method attempts to read a message on an input, but \nreturns none if a timeout occurs before a new message is available. Wrapping the action in a managed \nblock is not mandatory. It only prevents that a timer task gets unneces\u00adsarily triggered if a message \nis available before the timeout by poisoning the timer channel.  5. Programming Model and Scheduling \nStrategies In this section, we outline the process-oriented programming model we built upon the abstractions \ndescribed in this pa\u00adper. Secondly, we describe how we leveraged these abstrac\u00adtions to build a scheduler \nthat eliminates unnecessary con\u00adtext switches when interactions in a process network occur sequentially. \nIn our model, component types are speci.ed by de.ning the main method of an abstract process type class \npatterned after function types in Scala:  type Process[R] = (UThread, OChan[R]) => Unit abstract class \nProcessTypeixj[ I1 :Message, ..., Ii :Message, O1 :Message, ..., Oj :Message, R:Message] { ... def apply(i1 \n:IChan[I1 ], ..., oj :OChan[Oj ] ):Process[R] = ... protected def main(i1 :Input[I1 ], ..., oj :Output[Oj \n] ):IO[R] } By substituting the indices iand jfora numberof inputsand outputs in the code template above \nwe obtain the real code of a process type i.e. ProcessType1x0, ProcessType0x1, ProcessType1x1, etc. The \nabstract class is parameterized by the type Ii and Oj of the input and output channel inter\u00adfaces passed \nas argument to the main method of a process, followed by its result type R. End users apply the factory \nmethod apply of a process type to stream interfaces to cre\u00adate a new process instance Process whose behavior \nis de\u00ad.ned by the main method. The process instance will take care of opening the corresponding process-level \ninterfaces on behalf of the end user before calling the main method. These interfaces will be automatically \npoisoned after the main action terminates thanks to the resource control mech\u00adanism described in Section \n3.3. A Platform takes care of creating a new user-level thread and a result channel for processes passed \nas argu\u00adment to its launch method: abstract class Platform { def launch[R:Message](p:Process[R]):IChan[R] \n} The result channel will carry either the .nal result or the uncaught exception signal that caused the \ntermination of the main action. It is worth noting that monadic processes can launch new processes as \nwell through the platform .eld referenced by their user-level thread: def launch[R:Message](p:Process[R]):IO[IChan[R]] \n= new IO[IChan[R]]((t, k) => k(t.platform.launch(p))) Aplatform can adopt different strategies for scheduling \nthe tasks submitted to its user-level threads. The following de\u00adscribes the schedulers used in our evaluation. \nFlowParallelScheduler (FP). The .owparallel scheduler exploits the structure of our design to maximize \nthe utiliza\u00adtion of native threads before they return to their underlying thread pool to execute another \ncontinuation task. The aim is to reduce the impact of factors that affect negatively the performance \nin multicore environments like contention on shared pool resources, context switches, and the likelihood \nto suspend and resume native threads when a new task is submitted. Our design makes use of two trampolines \n[Ganz et al. 1999] that let native threads execute sequential inter\u00adactions without having to return \nto their thread pool. First, all the continuation tasks submitted to the user-level thread of a running \nprocess are executed sequentially using a .rst trampoline (T1) until it yields. A running process yields, \nor becomes suspended, once all its continuations are sus\u00adpended. Secondly, the scheduling algorithm relies \non the observation that during an input or output interaction on a channel, one process is running while \nthe neighbour may be suspended. A reference to the continuation task submitted by a suspended neighbour \nprocess resumed during such in\u00adteraction is temporarily held back in a thread-local variable (TLV) maintained \nby the native thread executing the running process. If the running process resumes another process be\u00adfore \nit yields, the task kept in the TLV is submitted to the thread pool for parallel execution and replaced \nby the con\u00adtinuation of the newly resumed process. Once the running process yields, the current native \nthread executes immedi\u00adately a neighbour s continuation stored in its TLV without returning to its thread \npool. This design ensures that if mul\u00adtiple processes are resumed, at least one process is resumed within \nthe same thread. This way, the execution of an appli\u00adcation remains purely sequential as long as one \nprocess is resumed at a time. Naive Scheduler (NS). Each user-level thread created by this scheduler \nmaintains also a local task queue to submit continuation tasks sequentially to their underlying executor. \nBut, in contrast to the previous scheduler, both T1 and T2 trampolines are disabled and every continuation \ntask is sub\u00admitted to the underlying thread pool. This scheduler will be used in the benchmarks below \nto demonstrate the relative performancegains of the .ow parallel scheduler.  6. Examples and Experimental \nResults This section describes three novel implementations of classi\u00adcalexamplesusedtoshowcasetheexpressivenessof \nconcur\u00adrent programming frameworks: a thread ring [Halen et al. 1998], a parallelgenuine prime sieve \n[Kahn and Macqueen 1977] and a chameneos-redux [Kaiser and Pradat-Peyre 2003].We chose here popularexamples \nthat are well docu\u00admented such that curious readers can easily lookup similar implementationsin theirfavorite \nprogrammingenvironment. We benchmarked implementations based on Molecule, using either the .ow parallel \nscheduler (Molecule/FP) or the naive scheduler (Molecule/NS), and implementations based on the standard \nScala Actors library [Haller and Odersky 2008]bundled with Scala 2.9.1. This last one is merely pro\u00advided \nas reference because it shares the same programming language andexecution platform as ours.Afull comparison \nwith the state-of-the-art on real world examples is left for fu\u00adture work as it would largely exceed \nthe scope of this paper. All benchmarks were performed on a 2 times 12-cores 64\u00adbit machine (AMD Opteron \n6174, 2.2 GHz per core), run\u00adning a Java HotSpot 1.7.0u4 Server VM con.gured with the NUMA-aware parallelgarbage \ncollector under Linux 3.3.0. Scala Actors and Molecule schedulers were con.gured to submit their continuations \nto the same implementation of the JSR166 fork/join pool [Lea 2000].We ran the same bench\u00admarks using \nvarious pool sizes to measure how performance is affected by multicore execution. In each case we took \nthe median of5 runs.  6.1 The Thread Ring The threadring application consistsina networkof P neigh\u00adbour \nprocesses interconnected in a ring con.guration by in\u00adteger channels. Each process is con.gured with \na distinct label indexing its position in the ring. A process forwards any integer value received on \nits input decremented by 1 to its downstream neighbour. The application starts by feeding a value N to \nthe .rst process in the ring and ends by display\u00ading the label of the process that receives 0 on its \ninput. The code sample below implementsaword-a-at-timever\u00adsion of a ring process, we call a node: object \nNode extends ProcessType2x2[Int, Int, Int, Int, Unit] { def main(label:Input[Int], in:Input[Int], out:Output[Int], \nresult:Output[Int]):IO[Unit] = for { l <-label.read() _ <-in.foreach {i => if (i > 0) out.write(i -1) \nelse result.write(l) >> out.close() } } yield () } The node is parameterized by its label, its neighbour \nchan\u00adnels and a channel on which to forward its label once it .nds 0. After the label has been written \ndown, the process closes its output channel, which propagates the EOS signal to its neighbour process \ndownstream. The foreach loop of the neighbour will then terminate, exactly as such loop behaves on regular \nlists. Since there is nothing else to do after the loop, the process terminates and poisons its channels, \ncaus\u00ading the next process to terminate, and so on, until the entire network collapses. The code sample \nbelow shows an implementation of the same component,but using streaming primitives: object Node extends \nProcessType2x2[...] { def main(...):IO[Unit] = out.flush(in.span(_ > 0).map(_ -1)) >> unless (in.isEmpty) \n{ result.flush(label) } } def unless(b:Boolean)(action: IO[Unit]):IO[Unit] = if (b) action else IO(()) \n The span primitive creates a temporary stream that ends with EOS once an elements does not satisfy its \npredicate. The map primitive is used here to decrement every value received on the temporary stream. \nWhen the predicate becomesfalse, the span primitive resets its input interface to the remaining of the \nstream. The flush streaming primitive forwards to its output every segment received on the input channel \ninterface passed as argument. It returns control to the caller once the input stream has entirely been \nconsumed. The process will then write its label only if the remaining stream contains one element, which \ncan then only be 0. After, the process termi\u00adnates and all its channels are poisoned automatically with \nthe EOS signal. This propagates the termination downstream to its neighbour until the entire network \ncollapses in a graceful manner. In both cases, the process networks terminate seam\u00adlessly as soon as \none of the processes of the ring dies, i.e. without any explicit support from the application to propa\u00adgate \npoison signals. The thread ring is wired using the following test method: def test(platform:Platform, \nP:Int, N:Int) { val first = Chan[Int]() val result = OChan.stdout val last = (1 until P).foldLeft(N :: \nfirst) { case (prev, label) => val next = Chan[Int]() platform.launch(Node(label, prev, next, result)) \nnext } platform.launch(Node(P, last, first, result)) platform.collect() } The Chan object implementsafactory \nmethod for coopera\u00adtivechannels. These inherit from both system-level input and output interfaces. The \nchannel SysOChan.stdout encapsu\u00adlates the JVM standard output into an system-level output. The standard \noutput channel ignores poison signals; it re\u00admains perpetually open and can be shared safely between \nmultiple processes. System-level channels are automatically lifted inside stream interfaces (c.f. Section \n4), for instance when we call the :: operator to prepend a value in front of a channel. The platform.collect() \nmethod blocks the na\u00adtive bootstrap thread until all the processes launched on the platform have terminated. \nFigure 10 shows the throughput of message passing for a ring of 503 nodes while gradually increasing \nthe number of native threads con.gured in the underlying platform. Bench\u00admarks with Molecule/FP exhibit \nclearly the highest perfor\u00admance compared to Molecule/NS and Scala Actors. Since this process network \nnever triggers more than one interac\u00adtion at a time, Molecule/FP executes all the processes within the \nsame thread using the trampolines described in Section 5. This is muchfaster because it eliminates entirely \nthe nega\u00adtive impact of resuming and suspending threads sequentially. Indeed,intheother cases,above1thread,eachI/Otasksub\u00admitted \nsequentially by the current thread is likely to wake up another thread in the underlying thread pool, \nwhich adds a signi.cant overhead in this benchmark.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n20 21 22 23 24 Native Threads The difference between word-at-a-time and streaming versions is not particularly \nsigni.cant here because segments .owing through the ring never carry more than one message. Therefore, \nstreaming primitives cannot take advantage of batching.Partof theoverheadin theword-at-a-timeversion \nmust be attributed to the extra level of indirection brought by the IO monad, which puts more pressure \non thegarbage collector. This is not the sole explanation because this con\u00adstant overhead is slightly \nmore important with Molecule/NS (50000 msgs/s in average), which submit every continua\u00adtion to the fork/join \npool, than with Molecule/FP (in 20000 msgs/s in average), which executes every continuation in its trampolines. \nThis differenceis interestingbut wedo not .nd it important enough to investigate further the causes in \nthe scope of this paper. Theoverheadofgarbage collectionis more apparent with Molecule/FP on small rings \nas seen on Figure 11, which compares the throughput of streaming and word-at-a-time versionswhilegrowingtheringfrom0to80 \nnodes.Itcanbe seen also that the throughput is much higher than for large rings and then drops sharply \naround 64 nodes to a similar level. Since our Opteron server has 64KB of Level-1 (L1) data cache and \neach node uses about 1KB of heap5, or a bit less in the case of the streaming version, the drop occurs \nas soon as the heap space occupied by the ring does not .t in the L1 data cache, which happens around \n64 nodes.  6.2 TheParallel Genuine Prime Sieve Many parallel implementations of this algorithm have \nbeen provided in the literature. Ours is special because of its sup\u00adport for termination and because \nprime numbers are .ltered by channel transformations, and not by processes. Its imple\u00admentation is the \nfollowing: 5We con.rmed this value by measuring the difference of heap space occu\u00adpied by two rings of \ndifferent size. 2 10 20 30 40 50 60 70 80 Ring Size Figure 11. Cache effect in the thread ring. object \nSieve extends ProcessType1x1[Int, Int, Unit] { def main(ints:Input[Int], log:Output[Int]) = for { prime \n<-ints.read() orCatch { case EOS => shutdown(()) } _ <-log.write(prime) _ <-handover( Sieve(ints.filter(_ \n% prime != 0), log) ) } yield () } The process logs each newly discovered prime in a stream of increasing \nintegers to its output channel until there is nothing else to read on the input stream. If there is a \nnew prime, it re\u00adcurses by launching a new instance of itself connected to the input channel, transformed \nto .lter all the multiples of that prime, and the original output channel. This relies on an ad\u00additionalfactory \nmethod on process types that takes theextra step of releasing stream channels from the current process \n.rst. The handover method is a coordination primitive like launch, excepted that the new process instance \nreuses the result channel of the current process, and the method does not return normally it halts the \nexecution and closes all the channels of the calling process. Therefore, there is never more than one \nprocess instance running in this application, only an increasing number of .lter transformations stacked \nup on the input channel. If there is no more data to read on the input channel, the termination signal \nEOS is raised as a user-level exception and the shutdown method is invoked. The shutdown method is a \ntype safe coordination primitive parameterized by the result of the process type: def shutdown[R](r:R):IO[Nothing] \n= ... Itpoisons all outputs and inputs with theEOS signal and then terminates the process immediately \nwith the result passed as argument. The method testing the prime sieve application is simple:  def test(platform:Platform, \nN:Int) { val ints = IChan(2 to N) val log = OChan.stdout platform.launch(PrimeSieve(ints, log)) platform.collect() \n} The stream of incrementing integers ints is obtained by applyingafactory method presentin the companion \nobject of system-level input channels to a standard Scala range. Figure 12 shows the evolution of the \ntime it takes to .nd all primes between 2 and 150000 when we vary the Complexity Cutoff Threshold (CCT) \nand the Segment Size Threshold (SST) optimisation parameters con.gured within the runtime. Since this \nexample stacks many stream trans\u00adformations together and runs over a long stream, it can ben\u00ade.t from \nparallelization and batching. The CCT dictates how many synchronous .lter transformations can be stacked \non a channel before they are automatically parallelized by the library. The SST controls the size of \nthe segments generated by the input channel of incrementing integers. Additionally, synchronous .lter \ntransformations applied to a channel are dynamically fused together by the library to eliminate the creation \nof intermediate segments. This relies on a built-in rule specifying that the fusion of two .lter transformations \nwith predicate pand q is equivalent to a single .lter transfor\u00admation whose predicate is the conjunction \nof p and q. 1 2 4 6 8 10 12 14 16 18 20 22 24 26 28 Native Threads As expected, the implementation based \non Scala Actors performs poorly in this benchmark because its runtime does not implement any of the optimizations \npresented in this paper. Even when all optimisations are turned off, that is whenSSTandCCT areequalto1, \nMolecule/NSis about4 timesfaster than Scala Actors. One reason is that streaming primitives, like the \none used to .lter integers, are extremely lightweight compared to actors and create littlegarbage.For \nthe same settings(SST=1,CCT=1),wegain anotherfactor 2.5 speedup by replacing Molecule/NS with Molecule/FP. \nIndeed, some messages will be entirely .ltered out from the input stream and, depending on the asynchronism, \nsome sections of the pipeline may become purely sequential for a while and thus the execution will bene.t \nfrom the fast trampolines implemented by this scheduler. Another means to reduce the context switching \noverhead is to increase CCT and SST values such that the application does more work per continuation \ntask. Increasing these val\u00adues permits to optimize signi.cantly the execution of this example.Wegain \nanother26 times speedupby setting them to 50, which is high enough to make context switching neg\u00adligible.At \nits peak performance Moleculeis 100 timesfaster than Scala Actors and 65 times faster than Molecule/NS \nunoptimized. Note that fusions played a signi.cant role in reaching these high performance .gures as \nshown in the benchmark where fusions are turned off.  6.3 The Chameneos-Redux The chameneos-redux is \na more sophisticated example of application that bene.ts from the expressiveness of strongly typed and \n.rst-class communication channel interfaces. This application is described by Kaiser and Pradat-Peyre \n[2003] along with its implementation in Java.We will not provide here the complete implementationbut \nwe will highlight the higher expressiveness resulting from the higher-order and type-safe communication \nprimitives of Molecule and their embedding in Scala s type system. De.ning the protocol. Each Chameneo \nprocess sends a MallRequest message to the Mall process, which groups these requestsbytwo. This request \ncarries information about the Chameneo that initiated the request and a reply channel on which it waits \nfor a response of type ChameneoMessage. A valid response from the Mall is either a Meet request or a \nCopy message. The .rst Chameneo in a group receives a Meet request whose reply channel is set to the \nreply channel of the second Chameneo in a group. It can then only reply with a Copy message, which tells \nthe second Chameneo to copyits color. The code below shows how we have encoded this protocol in the Scala \ntype system: trait ReplyChannel[-A] { def replyCh:OChan[A] } case class ChameneoId(label:Int, color:Color) \ncase class MallRequest(id:ChameneoId)( val replyCh:OChan[ChameneoMessage] ) extends ReplyChannel[ChameneoMessage] \nabstract class ChameneoMessage case class Meet(peer:ChameneoId)( val replyCh:OChan[Copy] ) extends ChameneoMessage \nwith ReplyChannel[Copy] case class Copy(id:ChameneoId) extends ChameneoMessage The messages carrying \na reply channel are marked by the ReplyChannel trait. Note that although the types do not specify how \nmanymessages might be exchanged on a chan\u00adnel, they express clearly the ordering and the types of mes\u00adsages \nexchanged in a protocol.  Using streaming primitives to group chameneos. The Mall lazily groups by two \na number of meeting requests received on the input interface mallIn of a server channel using the grouped \nand take streaming primitives, which are similar to those de.ned on regular lists in the Scala stan\u00addard \nlibrary: def behave(n:Int, mallIn:Input[MallRequest]) = mallIn.grouped(2).take(n).foreach { mates => \nval first :: second :: Nil = mates replyTo(first)(Meet(second.id)(second.replyCh)) } A server channel \nis a N-to-1 channel producing messages sentby multiple clientsinthe orderin whichtheyarrive.The Mall \nprocess, which can be assimilated to a signaling server, replies with the id and the reply channel of \nthe second Chameneo request to the .rst one in the group. The replyTo method is a convenience method \noffered by the library to reply to requests, i.e. messages that carry a reply channel: def replyTo[A:Message](req:ReplyChannel[A])(a:A) \n= open(req.replyCh) >>\\ {out => out.write(a) >> out.close()} After it has arranged n meetings, the Mall \nprocess termi\u00adnates and its input server channel interface mallIn is au\u00adtomatically poisoned. This poisons \nin turn all the requests the server channel mayhavebuffered or might receivein the future. This includes \ntheir response channel thanks to the following default implicit de.nition offered by the library for \nrequest messages, which inherit from the ReplyChannel trait. implicit def reqIsMsg[Rq <: ReplyChannel[_]] \n= new Message[Rq] { def poison(m:Rq, signal:Signal):Unit = m.replyCh.close(signal) } De.ning chameneos \nbehavior. Chaneneo processes can send requests using the following convenience method of\u00adfered by the \nlibrary. def requestTo[Rq <: ReplyChannel[Rp], Rp:Message] (out:Output[Rq])(mkReq:OChan[Rp] => Rq):IO[Rp] \n= { val chan = Chan[Rp]() out.write(mkReq(chan)) >> open(chan:IChan[Rp]) >>\\ {_.read()} } This sends \na request to an output channel in the p-calculus style, i.e. by embedding a reply channel inside the \nrequest and then reading the response on the other end.AChameneo can then send repeatedly requests to \nthe the Mall using the output interface mallOut of the server channel and count the number of meetings \nin which it participated using the recursive loop de.ned below. def behave(count:Int, id:ChameneoId):IO[Nothing] \n= { requestTo(mallOut)(MallRequest(id)) orCatch { case _ => shutdown(count) } } >>\\ { case other@Meet(otherId) \n=> val newColor = complement(id.color, otherId.color) val newId = id.copy(color = newColor) replyTo(other)(Copy(newId)) \n>> behave(count + 1, newId) case Copy(otherId) => val newId = id.copy(color = otherId.color) behave(count \n+1, newId) } Asa call to behave is in tail call position within the monadic domain, it will not increase \nstack or heap usage (c.f. Section3).AChameneowill catchthe poisoningofthe reply channel of one of its \nrequests as an exception once the Mall terminates. It will then shutdown itself by returning the number \nof chameneos it met as a result. Using interleaved parallelism to collect the status of child processes \nThe Chameneo results are collected by a super\u00advisor process using the parl action, which collects the \nre\u00adsults of a list of actions into a list: def parl[A](ios:List[IO[A]]):IO[List[A]] = ... parl(chameneos).map{_.sum} \nThe parl action is implemented in a similar manner as the par combinator described in Section 3.2. Here, \nchameneos is a list of actions where each action launches a Chameneo process and then reads the number \nof meetings in which it participated on its result channel. Benchmarking Figure 13 compares the performance \nof Scala Actors and Molecule/NS for 300 chameneos and 300000 meetings as we increase the number of nativethreads \nin the underlying platform. The SST threshold controls here the maximum number of requests that can be \nread in a single segment by the Mall process on its server channel. This application does not scale well \nin multicore environ\u00adment because the Mall process is shared amongst all chame\u00adneos and hence the main \nbottleneck. The contention created by sending concurrent requests to the Mall quickly starts to overcome \nthe bene.ts of parallelization above a few threads until there are as many threads as cores available \nin the un\u00adderlying hardware (24). The same pattern can be observed in each of these benchmarks. When \nthe SST is set to 1, the con\u00adtention dominates above3threads.We attribute thefact that the contention \nincreasesfaster with Molecule/NS than with  1 2 3 4 5 6 8 10 12 14 16 18 20 22 24 26 28 Native Threads \nScala Actors to the implementation of our server channel. We can speedup the average execution time by \nincreasing the SST threshold to reduce the amount of context switches. We obtain the best timings in \naverage when the SST is set to 6, which lets the Mall dispatch up to3 parallel meetings in a single task. \nIncreasing the SST further to8does not bring signi.cant improvements anymore in this example. The per\u00adformance \nis then optimal with 10 threads where it is almost 2timesfasterthanthe unoptimizedversion(SST=1).How\u00adever, \none could argue whether it is worth spending 7 ad\u00additional threads for a negligible improvement compared \nto when SST is set to 2. With this last setting, a performance close to the optimum is attained with \nonly3threads. 1 2 3 4 5 6 8 10 12 14 16 18 20 22 24 26 28 Native Threads As seen in Figure 14, the .ow \nparallel scheduler yields better results by reducing the impact of context switches. Infact, we measured \nthat it captures the submission of two tasks on three in its trampolines for this application. This occurs \nessentially during the sequential color exchange be\u00adtween pairs of chameneos. In each case, the optimal \nper\u00adformance is attained with 4 threads, independently from the SST value. There, Molecule/FP is 2 times \nfaster than Molecule/NSand3timesfasterthanScala Actors.Giventhe FP scheduler executes so many tasks sequentially \nalready, increasing the SST threshold has little effect. Slightly annoy\u00adingly, although the impact is \nlimited, increasing this thresh\u00adold affects negatively the performance above 10 threads. Providing a \ndeep analysis of the dynamics of this com\u00adplex feedback system is beyond the scope of this document. \nHowever, we guess that setting the SST low throttles down the number of meetings triggered at the same \ntime which reduces contention on the other side of the server queue. Thankfully, increasing the SST value \nbeyond 6 does not harm performance further (16% in the worst case) and, even though it cannot alleviate \nthe contention issue inherent to this kind of application, the .ow parallel scheduler yields systematically \nthe most interesting results.  7. RelatedWork The topics of asynchronous and concurrent programming \nhave given rise to a vast literature. Some work focuses ex\u00adclusively on language-level extensions to \nease asynchronous programming with callbacks and leaves the de.nition of a high-level concurrent programming \nmodel open for library developers. In absence of coroutines, many solutions ap\u00adply some variation of \na CPS transformation to the source code in a manner that blends well with the host languages features, \nsuch as exception handling, resource control (only on .NET) and built-in control structures. F# asynchronous \nwork.ows [Syme et al. 2011], C# async [Torgersen 2010] and Scala s continuation plugin [Rompf et al. \n2009] fall in this category. The F# approach based on computation ex\u00adpressions bears manysimilarities \nwith how Molecule lever\u00adages Scala s for-comprehension to desugarize monadic ex\u00adpressions. C# async, \non the other hand, depends on the gen\u00aderation of state machines, which is harder to maintain. On the \nJVM, Scala s continuation plugin implements a selective CPS transform, which is driven entirely by effect-annotated \ntypes. The solution uses .rst-class polymorphic delimited continuations, which can be composed in a .exible \nman\u00adner at application-level using shift and reset operations devisedby Danvy and Filinski [1992].Ade.nite \nadvantage over Molecule s application-level monad is its support for effect tracking. However, we .nd \nthat exposing the type of our monad in method signatures is more natural and offers more valuable information \nto application developers to dis\u00adtinguish and compose asynchronous control .ows compared to manipulating \nannotated types using Danvy and Filinski operators. Performance wise, the major bottleneck observed in \nour benchmarks in absence of contention is due to context switching, which is inherently higher during \nword-at-a-time interactions, and less by the extra level of indirection intro\u00adduced by monadic I/O, which \ncreates small and short lived immutable objects that can be ef.cientlygarbage collected.  Li and Zdancewic \n[2007] designed an application-level continuation monad in Concurrent Haskell [Peyton Jones et al. 1996] \nto schedule concurrent interactions between monadic threads and system-level interfaces, in a way that \nscales to real-world network services. Their monadic threads supportexceptions and asynchronous I/Obut \nnot streaming I/O. Although streaming I/O was found awkward in Con\u00adcurrent Haskell and dropped in favor \nof monadic I/O, they cohabit well together in our programming model. Many libraries offer a high-level \nconcurrent program\u00adming model based on the Actor model on the JVM [Karmani et al. 2009]but none of them \nfeature higher-order streaming primitives or message poisoning. Kilim [Srinivasan 2010] and Scala Actors \n[Haller and Odersky 2008] are two mod\u00adern and representative approaches that come the closest to Moleculein \ntermsof features.Bothofthemworkon unmod\u00adi.ed JVMs and offer lightweight communication primitives built \nupon continuations. Kilimisaconcurrent programming library for Java. Unlike Molecule, which uses pure \nlibrary approach, Kilim depends on a CPS bytecode post-processor for its user-level threads, called Fibers. \nIts Actors communi\u00adcate using one or more type-safe message mailboxes. These are mobile and may suspend \nsenders by holding back their continuation. However, Kilim does not offer anysupport for termination. \nLike Molecule, Scala Actors is a pure DSEL library written in Scala. Scala Actors and Erlang [Virding \net al. 1996] share a similar programming model. In contrast to Molecule, each Actor features a single \nmailbox and com\u00admunicate using asynchronous messaging and untyped com\u00admunication primitives. An Actor \nmay catch termination no\u00adti.cations from other Actors. However, the termination links must be wired explicitly. \nMoreover, as opposed to Molecule and Erlang, which offer a uniform lightweight threaded pro\u00adgramming \nmodel, Scala Actors uses a hybrid model that solves half the problem with callbacks. While it can support \nan andThen combinator to sequence in a modular way non\u00adblocking interactions using a mutable variable \nand control exceptions, the same mechanism cannot thread the result of a non-blocking interaction to \nthe next one in a modular man\u00adner like the monadic bind operator. JCSP [Sputh and Allen 2005] and CHP \n[Brown 2008] are two examples of process-oriented libraries written re\u00adspectively in plain Java and Haskell. \nBoth draw on Hoare s CSP model and, as such, do not feature mobile channels. CHP s standard library offers \nreusable higher-order pro\u00adcesses, which implement classical map and .lter func\u00adtions on top of read/write \nprimitives, but no higher-order channel interfaces. Both libraries offer a graceful termina\u00adtion mechanism \nto terminate process networks by spreading a poison signals. However, they don t implement resource controlfacilities. \nTherefore, theyrely on the application de\u00adveloper to catch and propagate the poison explicitely within \nexception clauses. Occam-p [Welch and Barnes 2005] is an ef.cient and safe binding of key elements from \nHoare s CSP and Mil\u00adner s p-calculus into a programming language of indus\u00adtrial strength. Occam-p implements \nsynchronous messaging and distinguishes I/O modalities on its mobile channel in\u00adterfaces. It compiles \ndown to native code and implements lightweight threads. In contrast to Molecule, it does not fea\u00adture \nresource control, message poisoning or higher-order channel interfaces. Its CCSP scheduler [Ritson et \nal. 2009] exploits dynamically application-level communication pat\u00adterns like Molecule s .ow parallel \nscheduler. The design of the .ow parallel scheduler is more modular and simpler: it is orthogonal to \nbatching and delegates parallel task execution to an external thread pool, e.g. the JSR166 fork-join \npool used in our benchmarks, which implements a work-stealing algorithm. There is a vast body of related \nwork on process-oriented programming in other languages and platforms [Sampson 2010] as well. Manyof \nthese support the dynamic creation of processes and their runtime reconnectionbut, to the best of our \nknowledge, Molecule is the only one to offer support for seamless termination and higher-order streaming \nprimitives on both its input and output channel interfaces.  8. Conclusion We presented Molecule, a \npractical model for composing re\u00adcon.gurable process networks that grow or shrink dynami\u00adcally and its \nhigh-performance application to multicore pro\u00adgramming hosted as a DSEL library in the Scala program\u00adming \nlanguage on the JVM. The hybrid support for func\u00adtional and imperative programming in Scala let us address \nboth high-level expressiveness and low-level runtime issues in our programming model. Our DSEL leverages \ntwo language abstractions originally developed separately for lazy and pure functional program\u00adming languages, \nmonadic and streaming I/O,but combines them in a novel manner into a rich process-oriented pro\u00adgramming \nmodel on the JVM. The clarity in the novel im\u00adplementation of the classical examples stems from the use \nof higher-order streaming primitives, resource control in\u00adtegrated with user-level exception handlers, \nand the use of type-safe channel that guide the design of sophisticated pro\u00adtocols involving channel \nmobility. Since we retain the ability to use word-at-a-time read or write primitives on channels, in \naddition to higher-order streaming primitives, end users have the freedom to select and combine both \nimperative and functional styles in the manner they.nd the most appropri\u00adate. Our runtime exploits the \ndynamics of application-level abstractions that capture the execution of user-level threads and their \ninteraction over communication channels to mit\u00adigate transparently the cost of context switching faced \nby process-oriented designs in multicore settings. Next to run\u00adtime optimizations like message batching, \nfusions and par\u00adallelization of consecutive stream transformations, the .ow parallel scheduler contributed \nsystematically to improve the performance of our examples by restricting dynamically the parallelism \nengendered by continuation tasks whenever the communication is purely sequential. Experimental results \nshowuptoa65 times speedup dependingonthe dynamicsof the hosted application, as illustrated throughout \nthe classical examples studied in this paper. Since real-world concurrent applications are likely to \ncombine algorithmic and dynamic aspects of these examples, chances are that they may reap similar expressiveness \nand performance bene.ts.   Acknowledgments We would like to thank the (anonymous) reviewers for a considerable \nnumber of constructive comments, useful ques\u00adtions and suggested references.  References AGHA, G. Actors: \na model of concurrent computation in dis\u00adtributed systems. MIT Press, 1986. ANDERSON, T., BERSHAD, B., \nLAZOWSKA, E., AND LEVY, H. Scheduler activations: effectivekernel support for the user-level management \nof parallelism. ACMTrans. Comput. Syst. 10 (Feb. 1992), 53 79. BACKUS,J. Can programmingbe liberated \nfrom thevon Neumann style?: a functional style and its algebra of programs. Commun. ACM 21,8(Aug. 1978), \n613 641. BANKER,R.,DAVIS,G., AND SLAUGHTER,S. Softwaredevelop\u00adment practices, software complexity, and \nsoftware maintenance performance: a .eld study. Manage. Sci. 44 (Apr. 1998), 433 450. BROWN, N. C. C. \nCommunicating Haskell Processes: Compos\u00adable Explicit Concurrency using Monads. In Communicating Processes \nArchitecture 2008 (Sept. 2008), pp. 67 83. CLINGER, W., HARTHEIMER, A., AND OST, E. Implementation strategies \nfor continuations. In Proceedings of the 1988 ACM conference on LISP and functional programming (July \n1988), pp. 124 131. COUTTS, D., LESHCHINSKIY, R., AND STEWART, D. Stream fusion: from lists to streams \nto nothing at all. SIGPLAN Not. 42 (Oct. 2007), 315 326. DANVY,O., AND FILINSKI,A. Representing Control:AStudyof \nthe CPS Transformation. Mathematical Structures in Computer Science2,4(1992), 361 391. GANZ,S.,FRIEDMAN,D., \nAND WAND,M.Trampolined style. In Proceedings of the 4thACM SIGPLAN InternationalConference on Functional \nProgramming (1999), pp. 18 27. GELERNTER, D., AND CARRIERO, N. Coordination languages and their signi.cance. \nCommun.ACM 35 (Feb. 1992), 97 107. HALEN, J., KARLSSON, R., AND NILSSON, M. Perfor\u00admance measurements \nof threads in Java and processes in Er\u00adlang. Available at http://www.sics.se/~joe/ericsson/ du98024.html, \nLast visit April 2012. HALLER, P., AND ODERSKY, M. Scala actors: Unifying thread\u00adbased and event-based \nprogramming. Theoretical Computer Science (2008). HALLER,P., AND ODERSKY,M. Capabilities for Uniqueness \nand Borrowing. In Proceedings of the 24th EuropeanConference on Object-Oriented Programming (2010). HEWITT,C.,BISHOP,P., \nAND STEIGER,R.Auniversal modular ACTOR formalism for arti.cial intelligence. In Proceedings of the 3rd \ninternational joint conference on Arti.cial intelligence (1973), pp. 235 245. HILDERINK, G. Managing \nComplexity of Control Software through Concurrency. PhD thesis, University of Twente, May 2005. HOARE,C.A.R. \nCommunicating sequential processes. Commun. ACM 21 (Aug. 1978), 666 677. HUDAK, P. Modular domain speci.c \nlanguages and tools. In Proceedings of the 5th International Conference on Software Reuse (1998), pp. \n134 . JONES, M., AND HUDAK, P. Implicit and Explicit Parallel Pro\u00adgramming in Haskell. Tech. Rep. YALEU/DCS/RR-982, \nDe\u00adpartment ofComputer Science,Yale University, Aug 1993. KAHN, G. The Semantics of a Simple Language \nfor Parallel Programming. In Information Processing 74: Proceedings of the IFIP Congress. North-Holland, \nAug. 1974, pp. 471 475. KAHN, G., AND MACQUEEN, D. Coroutines and Networks of Parallel Processes. In \nInformation Processing 77: Proceedings of the IFIP Congress. North-Holland, 1977, pp. 993 998. KAISER,C., \nAND PRADAT-PEYRE,J. Chameneos,a concurrency game for Java, Ada and others. Int. Conf. ACS/IEEE AICCSA \n(2003). KARMANI,R.K.,SHALI,A., AND AGHA,G. Actor frameworks for the JVM platform: a comparative analysis. \nIn Proceedings of the 7th International Conference on Principles and Practice of Programming inJava (2009), \npp. 11 20. LEA, D. AJava fork/join framework. InProceedings of the ACM 2000 conference onJava Grande \n(2000), pp. 36 43. LI, P., AND ZDANCEWIC, S. Combining events and threads for scalable network services \nimplementation and evaluation of monadic, application-level concurrency primitives. In PLDI 07: Proceedings \nof the 2007 ACM SIGPLAN conference on Programming language design and implementation (2007), pp. 189 \n199. MANSON, J., PUGH, W., AND ADVE, S. V. The Java memory model. SIGPLAN Not. 40 (Jan. 2005), 378 391. \nMILNER, R. Communicating and Mobile Systems: the Pi-Calculus. Cambridge University Press, June 1999. \nODERSKY, M., SPOON, L., AND VENNERS, B. Programming in Scala, Second Edition. Artima, 2011. OLIVEIRA,B.C.,MOORS,A., \nAND ODERSKY,M.Type classes as objects and implicits. In Proceedings of the ACM interna\u00adtional conference \non Object oriented programming systems lan\u00adguages and applications (2010), pp. 341 360. PEYTON JONES, \nS., GORDON, A., AND FINNE, S. Concurrent Haskell. In 23rd ACM Symposium on Principles of Program\u00adming \nLanguages (1996), pp. 295 308. PEYTON JONES,S., AND HUGHES,J. Report on the programming language Haskell \n98, a non-strict, purely functional language. Tech. rep., Haskell comittee, 1999. PEYTON JONES, S., AND \nWADLER, P. Imperative functional programming. In Proceedings of the 20th ACM SIGPLAN-SIGACT symposium \non Principles of programming languages (1993), pp. 71 84.  RITSON,C.,SAMPSON,A., AND BARNES,F. Multicore \nschedul\u00ading for lightweight communicating processes. In Proceedings of the 11th international conference \non Coordination Models and Languages (2009), pp. 163 183. ROMPF, T., MAIER, I., AND ODERSKY, M. Implementing \nFirst-Class Polymorphic Delimited Continuations by a Type-Directed SelectiveCPS-Transform. In Proceedings \nof the 14th ACM SIGPLAN international conference on Functional programming (2009). RYTZ, L., ODERSKY, \nM., AND HALLER, P. Lightweight Poly\u00admorphic Effects. In Proceedings of the 26th European Confer\u00adence \non Object-Oriented Programming (2012). SALTZER, J. H., REED, D. P., AND CLARK, D. D. End-to-end arguments \nin system design. ACMTrans. Comput. Syst.2 (Nov. 1984), 277 288. SAMPSON,A. Process-OrientedPatterns \nfor Concurrent Software Engineering. PhD thesis, University ofKent, Oct. 2010. SPUTH,B.H.C., AND ALLEN,A.R. \nJCSP-Poison: Safe termina\u00adtion of CSP process networks. In Proceedings of the 28th confer\u00adence on Communicating \nProcess Architectures (2005), pp. 71 107. SRINIVASAN, S. Kilim: A server framework with lightweight actors, \nisolation types and zero-copy messaging. Tech. Rep. UCAM-CL-TR-769, University of Cambridge, Computer \nLab\u00adoratory, Feb. 2010. SYME, D., PETRICEK, T., AND LOMOV, D. The F# Asyn\u00adchronous Programming Model. \nIn Proceedings of the 13th In\u00ad ternational Symposium on Practical Aspects of Declarative Lan\u00adguages (2011), \npp. 175 189. TORGERSEN, M. Asynchronous Programming in C# and Visual Basic. White paper, Microsoft, Oct. \n2010. Available online. VIRDING, R., WIKSTR\u00d6M, C., AND WILLIAMS,M. Concurrent programming in ERLANG (2nd \ned.). Prentice Hall International (UK) Ltd., 1996. VON BEHREN, J. R., CONDIT, J., AND BREWER, E. A. Why \nEvents Are a Bad Idea (for High-Concurrency Servers). In Proceedings of the 2003 HotOS Workshop (May \n2003), pp. 19 24. WADLER, P. Deforestation: transforming programs to eliminate trees. Theor.Comput. Sci. \n73 (Jan. 1988), 231 248. WADLER, P. Monads for functional programming. In Advanced Functional Programming, \nFirst International Spring School on Advanced Functional Programming Techniques-Tutorial Text (1995), \npp. 24 52. WADLER,P. An angry half-dozen. SIGPLAN Not. 33 (Feb. 1998), 25 30. WELCH, P., AND BARNES, \nF. Communicating mobile processes: introducing occam-pi. In 25Years of CSP (Apr. 2005), pp. 175 210. \nWELCH, P. H. Graceful Termination Graceful Resetting. In Applying Transputer-Based Parallel Machines, \nProceedings of OUG 10 (Apr. 1989), pp. 310 317.  \n\t\t\t", "proc_id": "2384616", "abstract": "<p>Molecule is a domain specific language library embedded in Scala for easing the creation of scalable and modular concurrent applications on the JVM. Concurrent applications are modeled as parallel process networks that exchange information over mobile and type-safe messaging interfaces. In this paper, we present a concurrent programming environment that combines functional and imperative programming. Using a monad, we structure the sequential or parallel coordination of user-level threads, without JVM modifications or compiler support. Our mobile channel interfaces expose reusable and parallelizable higher-order functions, as if they were streams in a lazily evaluated functional programming language. The support for graceful termination of entire process networks is simplified by integrating channel poisoning with monadic exceptions and resource control. Our runtime and system-level interfaces leverage message batching and a novel flow parallel scheduler to limit expensive context switches in multicore environments. We illustrate the expressiveness and performance benefits on a 24-core AMD Opteron machine with three classical examples: a thread ring, a genuine prime sieve and a chameneos-redux.</p>", "authors": [{"name": "S&#233;bastien Bocq", "author_profile_id": "81548462556", "affiliation": "Bell-Labs, Alcatel-Lucent, Antwerp, Belgium", "person_id": "P3856091", "email_address": "sebastien.bocq@alcatel-lucent.com", "orcid_id": ""}, {"name": "Koen Daenen", "author_profile_id": "81464658190", "affiliation": "Bell-Labs, Alcatel-Lucent, Antwerp, Belgium", "person_id": "P3856092", "email_address": "koen.daenen@alcatel-lucent.com", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384640", "year": "2012", "article_id": "2384640", "conference": "OOPSLA", "title": "Molecule: using monadic and streaming I/O to compose process networks on the JVM", "url": "http://dl.acm.org/citation.cfm?id=2384640"}