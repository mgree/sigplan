{"article_publication_date": "10-19-2012", "fulltext": "\n Speculative Analysis of Integrated Development Environment Recommendations Kivanc\u00b8 Mus\u00b8lu , Yuriy Brun \n, Reid Holmes , Michael D. Ernst , David Notkin Computer Science &#38; Engineering Department of Computer \nScience School of Computer Science University of Washington University of Massachusetts University of \nWaterloo Seattle, WA, USA {kivanc, mernst, notkin}@cs.washington.edu  Abstract Modern integrated development \nenvironments make recom\u00admendations and automate common tasks, such as refactorings, auto-completions, \nand error corrections. However, these tools present little or no information about the consequences of \nthe recommended changes. For example, a rename refactor\u00ading may: modify the source code without changing \nprogram semantics; modify the source code and (incorrectly) change program semantics; modify the source \ncode and (incorrectly) create compilation errors; show a name collision warning and require developer \ninput; or show an error and not change the source code. Having to compute the consequences of a recommendation \n either mentally or by making source code changes puts an extra burden on the developers. This paper \naims to reduce this burden with a technique that informs developers of the consequences of code transfor\u00admations. \nUsing Eclipse Quick Fix as a domain, we describe a plug-in, Quick Fix Scout, that computes the consequences \nof Quick Fix recommendations. In our experiments, developers completed compilation-error removal tasks \n10% faster when using Quick Fix Scout than Quick Fix, although the sample size was not large enough to \nshow statistical signi.cance. Categories and Subject Descriptors D.2.0 [Software Engi\u00adneering]: General; \nD.2.3 [Software Engineering]: Coding Tools and Techniques; D.2.6 [Software Engineering]: Pro\u00adgramming \nEnvironments General Terms Algorithms, Experimentation, Human Fac\u00adtors Keywords Quick Fix Scout, Eclipse, \nQuick Fix dialog, Quick Fix, speculative analysis, IDE, recommendations Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, \nUSA. Copyright c @ 2012 ACM 978-1-4503-1561-6/12/10. . . $10.00 Amherst, MA, USA Waterloo, ON, Canada \nbrun@cs.umass.edu rtholmes@cs.uwaterloo.ca 1. Introduction Integrated development environments (IDEs), \nsuch as Eclipse and Visual Studio, provide tools that automate common tasks, such as refactoring, auto-complete, \nand correction of compilation errors. These tools have two goals: increasing developer speed and reducing \ndeveloper mistakes. These tools are widely used: they are the most frequent developer actions after common \ntext editing commands such as delete, save, and paste [12]. Despite their popularity, these recommendations \nare pro\u00advided with little or no information about their consequences. For example, a rename refactoring \nchanges the name of a variable everywhere in a program. However, this refactoring cannot be correctly \nand automatically applied when there are compilation errors or name collisions in the project. In those \ncases, if the developer is lucky, the IDE will detect the failure and either roll back the refactoring \nor assist the developer in performing the refactoring manually. For an unlucky de\u00adveloper, the IDE will \nperform an incomplete refactoring and break the code without noti.cation, causing the developer to spend \ntime determining if and why the refactoring failed, and .xing the code. As another example, whenever \nthere is a compilation error in an Eclipse project, Eclipse offers Quick Fix proposals: transformations \nthat may resolve the error. However, some of these proposals may not resolve the compilation error and \nmay even introduce new errors. When this happens, a developer may waste time undoing the proposal or \ntrying other proposals, and may even give up on Quick Fix. Figure 1 shows a Quick Fix dialog with proposals \nfor a compilation error. Clicking on a proposal shows an additional yellow window previewing the changed \ncode. However, the developer still needs to answer the following questions about each proposal: Does \nit resolve this compilation error?  Does it resolve other compilation errors?  Does it introduce new \ncompilation errors?   Figure 1. A Quick Fix dialog with 12 proposals. The window on the right previews \nthe highlighted proposal. Considering Quick Fix proposals in isolation can be limiting because developers \nmay further wish to consider the following question: Which proposal, among those that would be offered \nfor all compilation errors in the project, resolves the largest number of errors? The Quick Fix dialog \ndoes not answer these questions. The developer can try to compute the answers mentally, or the developer \ncan apply a proposal and manually investigate its effects on the programs. Both approaches are error-prone \nand time-consuming. We aim to improve Quick Fix by informing developers of the consequences of each proposal, \nspeci.cally of the proposal s effect on the number of compilation errors. As a proof-of-concept, we have \nbuilt an Eclipse plug-in, Quick Fix Scout, that computes which compilation errors are resolved by each \nproposal. When a user invokes Quick Fix, Quick Fix Scout augments the standard dialog with additional, \nrelevant proposals, and sorts the proposals with respect to the number of compilation errors they resolve. \nThis paper makes the following contributions: A novel technique for automatically computing the conse\u00adquences \nof Quick Fix recommendations.  An open-source, publicly-available tool Quick Fix Scout: http://quick-fix-scout.googlecode.com \nthat communicates the consequences of a Quick Fix proposal to the developer.  A case study that shows \nthat most of the time (93%) developers apply one of the top three proposals in the dialog (Section 5.1). \n A controlled experiment with 20 users that demonstrates that Quick Fix Scout allows developers to remove \ncom\u00adpilation errors 10% faster, compared to using traditional Quick Fix (Section 5.2).  The rest of \nthe paper is organized as follows. Section 2 explains the problem with Eclipse s Quick Fix. Section 3 \npresents speculative analysis and the Quick Fix Scout imple\u00admentation. Section 4 introduces global best \nproposals the Figure 2. A Java program with two compilation errors. There is only one logical error: \nthe type sTRING should be String. additional proposals Quick Fix Scout adds to the dialog. Sec\u00adtion \n5 details the case study and controlled experiment design and results, and Section 6 discusses threats \nto the validity of these results. Section 7 places Quick Fix Scout in the context of related work. Finally, \nSection 8 concludes the paper. 2. Not Knowing the Consequences Eclipse uses a fast, incremental compiler \nto identify and underline compilation errors with a red squiggly . A developer who invokes Quick Fix \nat an error sees a pop\u00adup dialog with a list of actions each of which may .x the error. The Eclipse documentation \nnotes that Quick Fix can be used not only to provide suggestions but also as a shortcut for more expert \nusers. 1 Figures 2 4 demonstrate a situation in which Quick Fix falls short. Figure 2 shows a program \nwith two compilation errors due to a single type mismatch between a variable dec\u00adlaration and a use site. \nThe variable name should be declared to be of type String but is instead declared as sTRING. In\u00advoking \nQuick Fix at the declaration error shows 12 proposals (Figure 3). The correct proposal Change to String \n is the fourth choice in the list. Ideally, Eclipse would pro\u00advide the correct proposal as the .rst recommendation. \nLower positions in the list likely cause the user to spend more time studying the choices or to cancel \nQuick Fix and address the error manually. Invoking Quick Fix at the use error is worse for the developer. \nFigure 4 shows the 15 Quick Fix proposals, none of which resolves either error. Sophisticated users may \nrealize this, cancel the invocation, and .nish the change manually. Others may apply a proposal and either \nquickly realize that this was a poor choice and undo it, or perform more actions attempting to resolve \nthe error, creating successively more dif.cult situations to recover from. 2.1 Visualizing Quick Fix \nconsequences Quick Fix Scout pre-computes the consequences of each proposal and visualizes this information \nby augmenting the Quick Fix dialog in three ways: 1 http://wiki.eclipse.org/FAQ_What_is_a_Quick_Fix%3F \n  Figure 3. 12 Quick Fix proposals to resolve the type error from Figure 2. Figure 4. 15 Quick Fix \nproposals to resolve the assignment error from Figure 2. None of these proposals resolves either compilation \nerror. 1. To the left of each proposal, add the number of compila\u00adtion errors that remain after the proposal \ns hypothetical application. 2. Sort the proposals with respect to the number of remaining compilation \nerrors. 3. Color the proposals: green for proposals that reduce the number of compilation errors, black \nfor proposals that do not change the number of compilation errors, and red for proposals that increase \nthe number of compilation errors.  Figure 5 the Quick Fix Scout equivalent of Figure 3 shows all these \naugmentations, except the red coloring. Section 4 discusses one additional feature of Quick Fix Scout: \nglobal best proposal, which addresses the problem in Figure 4. Changing sTRING to String (offered only \nat the Figure 5. Quick Fix Scout sorts the 12 proposals offered by Eclipse (shown in Figure 3) by the \nnumber of errors that the proposal .xes. .rst error s site) resolves both compilation errors. However, \nQuick Fix does not present this proposal at the second error s site, even though it is relevant. Quick \nFix Scout addresses this problem by providing the relevant proposal at both compilation error locations. \nQuick Fix Scout uses the number of remaining compi\u00adlation errors as the main criterion to reorder and \ncolor the proposals. Since the primary intent of Quick Fix is to re\u00adsolve compilation errors, we assume \nthat a proposal that resolves more compilation errors is likely to be preferred by the developer. The \nproposals that resolve the same number of compilation errors are sorted using Quick Fix s standard ordering. \nThis allowed us to measure the effects of the main criterion more accurately when evaluating Quick Fix \nScout. The empirical data support the premise that the developers prefer proposals that resolve the highest \nnumber of compila\u00adtion errors. Case study participants (Section 5.1) who used Quick Fix Scout selected \na proposal that resolved the most compilation errors 90% of the time. Similarly, controlled experiment \nparticipants (Section 5.2) who used Quick Fix Scout selected such proposals 87% of the time, and those \nwho used Quick Fix, 73% of the time. 3. Quick Fix Scout Speculative analysis [2] explores possible future \ndevelopment states to help the developer make a decision that may lead to one or more of those states. \nQuick Fix Scout [10] is an Eclipse plug-in that speculatively applies each available Quick Fix proposal \nand compiles the resulting program. Quick Fix Scout augments the Quick Fix dialog to show how many compilation \nerrors would remain after each proposal s hypothetical application, and sorts the proposals accordingly. \nNext, Section 3.1 details the mechanism for computing Quick Fix proposals consequences. Then, Section \n3.2 de\u00ad scribes the requirements for seamless background computa\u00adtion. Section 3.3 explains additional \noptimizations speci.c Figure 6. A high-level description of the speculative analysis algorithm for computing \nthe compilation errors that remain after applying each Quick Fix proposal. The publishResults() method \naugments the Quick Fix dialog with the proposal consequences.  1 while (true) { 2 waitUntilChangeInErrors(); \n3 for (Error err: copy.getErrors()) { 4 for (Proposal p: err.quickFixes()) { 5 copy.applyProposal(p); \n6 copy.saveAndBuild(); 7 results.add(p, copy.getErrors()); 8 copy.applyProposal(p.getUndo()); 9 } 10 \npublishResults(); 11 } 12 } to Quick Fix Scout. Section 3.4 discusses implementation limitations. Finally, \nSection 3.5 provides insight into gener\u00ad alizing the technique and the implementation to other IDEs and \nrecommendations. 3.1 Computing Quick Fix consequences Quick Fix Scout uses the speculative analysis algorithm, \nde\u00adscribed at a high level in Figure 6, to compute the conse\u00ad quences of Quick Fix proposals. Quick Fix \nScout maintains a separate, hidden copy of the developer s code and performs all its analysis on that \ncopy, to avoid disturbing the devel\u00adoper s workspace. (Section 3.2 further describes the use of the copy.) \nWhenever the developer introduces a new com\u00adpilation error or .xes an old one (line 2), Quick Fix Scout \napplies each proposal to the copy (line 5), one at a time, saves and builds the copy (line 6), and associates \nthat proposal with the set of compilation errors that remain (line 7). Quick Fix Scout then undoes the \nproposal to restore the copy s state (line 8). Quick Fix Scout updates the Quick Fix dialog after computing \nthe consequences of all the proposals (line 10). 3.2 Managing a copy of the developer s code Quick Fix \nScout maintains a copy of the developer s workspace. The copy is changed in two ways: Whenever the developer \nedits the main workspace, the copy is edited to keep it in sync with the mail workspace. Quick Fix Scout \nuses Eclipse s resource change listeners to listen for edits.  Quick Fix Scout applies Quick Fix proposals, \nanalyzes the consequences, and reverts the modi.cations.  Suppose the developer makes an edit while \nQuick Fix Scout is applying and reverting proposals. If the edit does not change the current compilation \nerrors, then Quick Fix Scout buffers the changes until its speculative analysis completes, and only then \napplies them to the copy. If the edit does change the current compilation errors, then Quick Fix Scout \nabandons and restarts its speculative computation. This prevents stale results from being displayed and \nimproves responsiveness. 3.3 Optimizations for a responsive UI Ideally, Quick Fix Scout computes the \nconsequences of a new error s proposals in the time between when the developer introduces the error and \ninvokes Quick Fix. Quick Fix Scout includes the following optimizations and heuristics: It only recomputes \nconsequences if a code change affects the compilation errors, as described in Section 3.2.  It uses \na user-adjustable typing session length to identify atomic sets of changes. A series of edits without \na typing-session-length pause constitute an atomic set of edits. Quick Fix Scout waits for an entire \natomic session to complete before recomputing consequences. Thus, for example, Quick Fix Scout ignores \nthe temporary compilation errors that arise in the middle of typing a complete token.  It considers \n.rst the errors that are closest to the cursor in the currently open .le.  It caches the consequences \n(i.e., the remaining compila\u00adtion errors) for each proposal and uses the cache whenever Eclipse offers \nthe same proposal at multiple locations.  It updates the Quick Fix dialog incrementally, as results \nfor errors (but not individual proposals for each error) become available. This is shown in Figure 6. \n In general, each proposal application is a small change and, even for large projects, Eclipse can incrementally \ncompile the updated project extremely quickly. Therefore, Quick Fix Scout s computation scales linearly \nwith the number of proposals (which is proportional to the number of compilation errors), and independently \nof the size of the project. During typical coding, at any particular time, a project has several compilation \nerrors with several proposals for each. The total number of proposals is typically less than a couple \nhundreds. As a worst-case example, we experimented with an 8K-line project with 50 compilation errors \nand 2,400 proposals. A 2.4GHz Intel Core i5 (quad core) MacBook Pro with 8GB of RAM computed all the \nconsequences in 10 seconds, on average (computed over 10 consecutive computations, after allowing Eclipse \ns incremental compiler to optimize). This suggests Quick Fix Scout can scale well to large projects. \nFinally, since each proposal is analyzed separately, the analysis can be parallelized, though we have \nnot yet implemented that functionality.  3.4 Current implementation limitations There are at least four \nways to invoke Quick Fix in Eclipse: (1) by pressing the keyboard shortcut, (2) by selecting Quick Fix \nthrough the context menu, (3) by clicking on the icon on the left of the screen, and (4) by hovering \nthe mouse over the compilation error. Internally, the .rst three methods create a Quick Fix dialog and \nthe last method creates a Hover Dia\u00adlog. The Hover Dialog is handled by org.eclipse.jdt.ui plug-in and \nthe Eclipse installation does not permit us to mod\u00adify this plug-in as we modi.ed org.eclipse.jface.text. \nThough we have an implementation that works in debug mode for the Hover Dialog, our installation fails \nwhen it in\u00adcludes a modi.ed jdt.ui. A future version of Eclipse will include a public API for reordering \ncontent assist type rec\u00adommendations (e.g., auto-complete and Quick Fix),2 which would simplify our implementation \nand might remove this limitation.  For each proposal, the Eclipse API provides an undo change that rolls \nback the associated proposal application. After analyzing each proposal, Quick Fix Scout uses this mechanism \nto return the copy project to its initial state. The proposals Change compilation unit to typeName and \nMove typeName to packageName have a bug in their implementation: the corresponding undos do not restore \nthe project to its original state.3 We have reported both bugs to Eclipse and they have been reproduced \nby the developers, but they have not yet been resolved. Quick Fix Scout must either skip analyzing these \ntwo proposals or re-copy the copy project after their analysis. Since re-copying can take considerable \ntime for large projects, for performance reasons, the current implementation skips the analysis of these \nproposals and produces no consequence information for them, leaving the appropriate lines in the Quick \nFix dialog unaugmented. Quick Fix Scout uses an internal Eclipse API to apply proposals to the copy project. \nBy default, this API acts as a no-op for the proposals that require user interaction. Therefore, currently, \nQuick Fix Scout does not compute the consequences of these proposals and leaves the appropriate lines \nin the Quick Fix dialog unaugmented. However, to our best knowledge, there are only four such proposals: \nCreate class, interface, annotation, and enum typeName . These proposals do not modify existing code, \nbut instead create new code. Therefore, it is relatively simple for developers to mentally predict their \nconsequences.  3.5 Generalizing beyond Quick Fix and Eclipse The ideas we demonstrated on Quick Fix \nScout within Eclipse also apply to engines that produce other types of recommendation, such as refactorings \nand automatic code completions, and to other IDEs, such as NetBeans, IntelliJ, and Visual Studio. Analysis \nof the possible future states of a non-pure rec\u00adommendation that modi.es the source code when applied \n cannot be applied to the developer s working copy as it 2 http://blog.deepakazad.com/2012/03/ jdt-3842-m6-new-and-noteworthy.html \n 3 https://bugs.eclipse.org/bugs/show_bug.cgi?id=338983 and https://bugs.eclipse.org/bugs/show_bug.cgi?id=339181 \n might interfere with development. Most popular types of recommendations, such as refactorings, automatic \ncode com\u00adpletions, and automatic code corrections, are non-pure code transformations. Section 3.2 proposes \none way to separate the analysis from the developer s working copy using a code copy. Although this method \nuses Eclipse-speci.c constructs, such as resource change listeners, these constructs are a common design \npattern available in all major IDEs. Therefore, the use of code copies for background analysis integration, \nwithout disturbing the developer s possibly active code, generalizes to other IDEs and recommendations. \nAny recommendation may become obsolete when the code changes. Thus, most of the optimizations and heuristics \nin Section 3.3 apply to other recommendations. For example, automatic code completions that are closest \nto the current cursor position can be prioritized and computed .rst. Finally, Quick Fix Scout is an instantiation \nof speculative analysis: the future states are generated via Quick Fix proposals, and the consequences \nare represented by the number of remaining compilation errors. By generating future states and representing \nconsequences in other ways, speculative analysis can generalize to other consequences and recommendation \nengines. For example, refactoring suggestions can generate future states, and failing tests could represent \nthe consequences. 4. Global Best Quick Fixes Quick Fix Scout helps developers to quickly locate the best \nlocal proposals the proposals that resolve the most compilation errors by sorting them to the top in \nthe Quick Fix dialog. However, sometimes, Eclipse offers the best proposal to .x an error at a different \nlocation than the error itself (recall Section 2). Quick Fix Scout s speculative analysis handles such \nsituations because the analysis is global and applies to all compilation errors and proposals in the \nproject, thus computing the information necessary to offer the global best proposal at all the relevant \nlocations [11]. Figure 7 (the Quick Fix Scout equivalent of Figure 4) shows a global best proposal at \nthe top of the dialog. That proposal is suggested by Eclipse at a different compilation error location, \nand is not displayed by the original Quick Fix. For global best proposals, Quick Fix Scout adds the following \ncontext information: 1. The location of the error where Eclipse offers the proposal (Motivation.java:5:17 \nin Figure 7). 2. The remote context that will be modi.ed ( sTRING is added to the original message Change \nto String in Figure 7).  While this context information is not necessary for local proposals, it is \nuseful when the proposal is displayed at a dif\u00adferent location than the error to which it directly applies. \nFor example, a developer may interpret Change to String Figure 7. Quick Fix Scout computes the global \nbest proposal for each compilation error and adds it to the Quick Fix dialog for that error. The addition \nof the associated error location (Motivation.java:5:17) and the associated error context ( sTRING ) distinguish \nglobal best proposals from normal proposals. If the global best proposal is already one of the local \nproposals, Quick Fix Scout makes no additions.  incorrectly, without knowing what token, and on what \nline, will be changed to String . As a consequence of the above process, global best pro\u00adposals are only \nshown if they resolve the local error, among other errors. While it is possible to augment the dialogs \nof all errors with the proposal that resolves the most errors in the project overall, we believe that \nshowing a .x for an unrelated error might confuse developers. However, if invoked on a location without \na warning or a compilation error, Quick Fix Scout does show the proposal that resolves the most errors \n(Figure 8). One of the controlled experiment (Section 5.2) participants articulated the usefulness of \nglobal best proposals: [Global best proposals] were great, because hon\u00adestly the source of error is often \nnot at the [location where I invoke Quick Fix]. 5. Evaluation Our evaluation was based on two activities. \nFirst, over a roughly one-year period, we distributed a version of Quick Fix Scout to a collection of \n13 friendly users (including three of the authors) and gathered information about their Quick Fix and \nQuick Fix Scout behavior in their normal work.ow (Section 5.1). Second, we ran a controlled experiment \nwith a within-participants mixed design across 20 participants, asking them to resolve various compilation \nerrors on code they had not previously seen (Section 5.2). Figure 8. If invoked on a location without \na warning or a compilation error, Quick Fix Scout shows the proposals that resolve the most errors whereas \nthe default implementa\u00adtion would only inform the user that there are no available proposals for that \nlocation. The friendly users selected, at their discretion, to use either Quick Fix or Quick Fix Scout \nduring each logged session. The design of the controlled experiment determined the situations in which \nparticipants used Quick Fix and Quick Fix Scout. For both activities, we acquired data with an instrumented \nversion of the tool. The tool logs: whether Quick Fix or Quick Fix Scout is is running,  the proposals \noffered by Quick Fix or Quick Fix Scout,  whether the user selected a Quick Fix proposal or canceled \nthe invocation,  which proposal the user selected, if any, and  how long it took the user to either \nmake a selection or cancel the invocation.  The tool also tracks information that lets us detect some \nsituations in which a user applies a proposal but soon after undoes that proposal. 5.1 Case study: friendly \nusers The goal of our informal case study was to understand how Quick Fix is used in the wild by developers. \nWe wished to investigate the following questions: Does the ordering of the displayed proposals affect \nwhich proposal is selected?  Does the number of proposals displayed affect which proposal is selected? \n Does the kind of proposal displayed affect which proposal is selected?  5.1.1 Case study design Over \napproximately one year, 13 developers including three of the authors ran our tool and allowed us to \nview its logs. For each Eclipse session, each participant was free to use either the standard Quick Fix \nor our Quick Fix Scout; all sessions were logged.  Standard Quick Fix Quick Fix Scout User ID # completed \nQF selection rate sessions 1st 2nd 3rd top 3 # completed QF selection rate sessions 1st 2nd 3rd top 3 \n1 4 100% 0% 0% 100% 1 100% 0% 0% 100% 2 0 1 100% 0% 0% 100% 3* 45 64% 16% 13% 93% 362 81% 15% 2% 98% \n4 167 78% 20% 1% 99% 0 5 17 47% 24% 0% 71% 0 6* 25 40% 24% 8% 72% 22 55% 27% 0% 82% 7* 82 70% 22% 2% \n94% 28 68% 18% 0% 86% 8 9 67% 22% 11% 71% 0 9 7 71% 0% 0% 71% 10 60% 10% 10% 80% 10 6 33% 17% 33% 83% \n0 11 0 0 12 6 17% 0% 17% 34% 0 13 0 2 50% 0% 0% 50% All 368 69% 20% 4% 93% 426 78% 15% 2% 95% Figure \n9. Case study information. A * in the User ID indicates the participant is an author of this paper. Completed \nsessions are the number of times the user invoked Quick Fix and selected a proposal. For each of the \n.rst three proposals in the Quick Fix menu, we report how often that proposal was selected. For example, \nuser 9 never selected the second or third offered proposal from a standard Quick Fix menu, but did so \nwhen using Quick Fix Scout. 5.1.2 Case study results Figure 9 shows that users selected the .rst (top) \nproposal 70% of the time, one of the top two proposals 90% of the time, and one of the top three proposals \n93% of the time. For Quick Fix Scout sessions, the percentages are slightly higher, at 78%, 93%, and \n95%. Given the small difference, and that three of the participants are authors, this data does not con.rm \na hypothesis that Quick Fix Scout is different from Quick Fix in this dimension. For the completed sessions, \nQuick Fix offered as many as 72 (mean=5.7, median=2) proposals. For the canceled sessions, Quick Fix \noffered as many as 80 (mean=6.4, me\u00addian=4) proposals. In contrast, for the completed sessions, Quick \nFix Scout offered as many as 38 (mean=4.2, median=2) proposals. For the canceled sessions, Quick Fix \nScout offered as many as 27 (mean=5.1, median=3) proposals. These data may suggest that when a user does \nnot .nd an expected or a useful proposal easily, the invocation is more likely to be can\u00adceled. To investigate \nthis further, we looked for a correlation between the number of proposals offered in the dialog and the \nsession completion rate. We found no such correlation, further suggesting that as long as the correct \nproposal is lo\u00adcated near the top of the list, the number of proposals shown might not have an effect \non developers decisions. Eclipse documentation categorizes the Quick Fixes (see the column headings in \nFigure 10).4 Five out of the nine proposal types represent 92% of all selected proposal types. 4 http://help.eclipse.org/galileo/index.jsp?topic=/org. \neclipse.jdt.doc.user/reference/ref-java-editor-quickfix. htm  Figure 11 presents the most-frequently \nselected propos\u00ad als and their selection ratios. Except for one user, these six proposals constitute \nabout 80% of the selected proposals. Note the similarity in selection ratio between the proposals Import \n. . . , Add Throws Declaration , and Add Unim\u00adplemented Methods and their types Types , Exception Handling \n, and Constructor respectively. The Change to . . . proposal falls into Methods and Fields &#38; Variable \n, depending on its recipient. Though there is some variation between participants, the results suggest \nthat all proposals do not have the same importance: there are a few proposals that are favored by the \ndevelopers. This observation can be explained by the nature of these proposals. For example, the Import \n. . . proposal is offered whenever the developer declares an unresolvable type. If the developer makes \nthis mistake intentionally, most of the time, she either wants to import that type or create a new type \nwith that name. Therefore, there is a high probability that one of these proposal will be selected. Add \nthrows declaration and Surround with Try/Catch are two proposals that are always offered for exception-handling-related \ncompilation errors. When there is an exception-handling error, it is very likely that the developer will \neither propagate that exception or handle it immediately, which suggests that one of these proposals \nwill be selected. The imbalance in proposal selection rate can be used to improve Quick Fix by prioritizing \nproposals with respect to the user s history. Bruch et al. [1] have already done this for auto-complete. \n User ID Types Exception Handling Methods Constructors Fields &#38; Variables Other Unknown Package \nDeclaration Imports Build Path Problems 1 100% 0% 0% 0% 0% 0% 0% 0% 0% 0% 2 100% 0% 0% 0% 0% 0% 0% 0% \n0% 0% 3 26% 22% 29% 11% 9% 1% 3% 0% 0% 0% 4 2% 65% 11% 10% 1% 5% 2% 0% 4% 0% 5 94% 0% 0% 0% 6% 0% 0% \n0% 0% 0% 6 51% 19% 17% 0% 2% 0% 6% 0% 4% 0% 7 49% 0% 13% 9% 14% 7% 3% 5% 0% 1% 8 44% 0% 0% 11% 33% 11% \n0% 0% 0% 0% 9 59% 18% 6% 6% 12% 0% 0% 0% 0% 0% 10 67% 0% 0% 0% 33% 0% 0% 0% 0% 0% 11 0% 0% 0% 0% 0% 0% \n0% 0% 0% 0% 12 0% 0% 83% 0% 17% 0% 0% 0% 0% 0% 13 0% 0% 0% 0% 0% 0% 0% 100% 0% 0% All 30% 27% 21% 10% \n8% 3% 3% 3% 1% 1% Figure 10. Proposal types and their selection ratios during the case study. The proposals \nwhose type was unclear are listed as Unknown .   5.2 Controlled experiment: graduate students The goal \nof our controlled experiment was to determine whether users behave differently when using Quick Fix and \nwhen using Quick Fix Scout. Each participant performed two sets of tasks a and \u00df task sets of 12 tasks \neach. Each task presented the partici\u00adpant with a program that contained at least two compilation errors \nand required the participant to resolve all the compila\u00adtion errors. The non-compilable program states \nwere chosen randomly from the real development snapshots captured dur\u00ading the case studies from Section \n5.1. For 6 of the tasks in each task set, we manually seeded each task with either 1 or 2 additional \nmutation errors, such as changing a .eld type or a method signature. The mutations introduced an average \nof 2.8 extra compilation errors per task. Our study answers two research questions: RQ 1: Does the additional \ninformation provided by Quick Fix Scout speci.cally, the count of remaining compilation errors, and \nthe coloring and reordering of proposals allow users to remove compilation errors more quickly? RQ 2: \nDoes Quick Fix Scout affect the way users choose and use Quick Fix proposals? 5.2.1 Controlled experiment \ndesign We recruited 20 participants, all graduate students who were familiar with Quick Fix but had never \nused Quick Fix Scout.5 We used a within-participants mixed design. We consid\u00adered two factors: the tool \nor treatment factor (Quick Fix vs. Quick Fix Scout), and the task factor (a vs. \u00df task sets). To re\u00adduce \nthe confounding effects from developer differences and learning effects, we de.ned four blocks the cross-product \n5 Approved human subject materials were used; participants were offered a $20 gift card. of the two factors. \nWe used a balanced randomized block pro\u00adtocol, randomly selecting which participants perform which block \nwith a guarantee that each block is performed an equal number of times. (We rejected a full within-participants \nfacto\u00adrial design because of the learning effects we would anticipate if a participant performed the \nsame set of tasks twice using Quick Fix and then Quick Fix Scout or vice versa.) Each participant received \na brief tutorial about Quick Fix Scout, performed the two blocks (task sets), and took a concluding survey \ncomparing Quick Fix Scout and Quick Fix around the two blocks. The two blocks differed in both the tool/treatment \nfactor (from Quick Fix to Quick Fix Scout, or vice versa) and also the task factor (from the a task set \nto the \u00df task set, or vice versa). To answer RQ 1, we measured the time it took participants to complete \ntasks. In addition to the time per task group (a and \u00df), we calculated per-task time by using the screen \ncasts. The beginning of a task is de.ned to be the time when the participant opens the related project \nfor the .rst time and the end of a task is de.ned to be the time when the participant resolved all compilation \nerrors in the task and was satis.ed with the implementation. To answer RQ 2, we measured whether the \nuser selected a proposal after invoking the Quick Fix menu or canceled the menu, how long it took the \nuser to make that decision, which proposal the user selected, and whether the user undid a selected proposal. \n 5.2.2 Controlled experiment results We used R to perform a 4-way blocked MANOVA test utiliz\u00ading all \nindependent and dependent variables. This minimizes the risk of a type 1 statistical error. All independent \nvari\u00adables (user, Quick Fix vs. Quick Fix Scout, task, and order of task) had statistically signi.cant \neffects, so we examined the analysis-of-variance results of the MANOVA test.  User ID Import . . . Add \nThrows Declaration Create Method . . . Change to . . . Add Unimplemented Methods Surround with Try/Catch \nTotal 1 100% 0% 0% 0% 0% 0% 100% 2 100% 0% 0% 0% 0% 0% 100% 3 24% 21% 21% 10% 7% 0% 83% 4 2% 47% 11% \n1% 8% 14% 83% 5 76% 0% 0% 6% 0% 0% 82% 6 34% 11% 2% 26% 0% 6% 79% 7 37% 0% 11% 7% 9% 0% 64% 8 44% 0% \n0% 33% 11% 0% 88% 9 53% 18% 0% 24% 6% 0% 100% 10 50% 0% 0% 50% 0% 0% 100% 11 0% 0% 0% 0% 0% 0% 0% 12 \n0% 0% 0% 83% 0% 0% 83% 13 0% 0% 0% 0% 0% 0% 0% All 25% 23% 15% 10% 7% 4% 84% Figure 11. Most-frequently \nselected proposals and their selection ratios for the case study. Proposals that are selected less than \n3% overall (represented by the All row) are excluded.  treatment type 1st treatment 2nd treatment all \ntreatments a QF QFS 27m 17m 19m 15m 23m 16m \u00df QF QFS 31m 36m 22m 21m 27m 29m QF QFS 29m 26m 20m 18m 25m \n22m Figure 12. Mean time to remove compilation errors, in minutes.  RQ 1 Participants completed tasks \n10% faster, on average, when using Quick Fix Scout than Quick Fix (Figure 12). However, this result was \nnot statistically signi.cant (p=.11). All the other independent variables did have statistically signi.cant \neffects on task completion time: user (p=5\u00d710-7), task (p=2\u00d710-16), and order (p=3\u00d710-6). Even the task \ngroup had an effect (p=3\u00d710-5): tasks in the \u00df group were harder, and in fact .ve participants could \nnot complete all tasks in \u00df. We had not anticipated any difference between the task groups. Future work \nshould investigate how the \u00df tasks differ from the a tasks and why Quick Fix Scout caused a slight (but \nnot statistically signi.cant) slowdown on the \u00df tasks. Per-task descriptive statistics appear in Figure \n13. There is a learning bias (p=4\u00d710-8): the participants completed a task set 22% faster if it was their \nsecond task set. Possible explanations for this bias include participants getting used to resolving compilation \nerrors and participants becoming familiar with the code (since multiple tasks were drawn from the same \ndevelopment projects). RQ 2 Figure 14 summarizes the data we collected regarding user behavior with respect \nto Quick Fix. Use of Quick Fix Scout improved the best proposal selection rate by 14% (p=10-8). This \nincrease and the frequent (75%) usage of global best proposals suggest that the participants were resolving \nmore compilation errors per Quick Fix invocation with Quick Fix Scout. Though the difference between \nthe total number of Quick Fix invocations is low (36) between treatments, we believe that the Quick Fix \nScout increased usefulness of completed Quick Fix invocations, which helped the participants to save \ntime overall. One participant noted: With [Quick Fix Scout] I had a much better idea of what the error \nwas. . . I found [Quick Fix] to be more vague. . . Use of Quick Fix Scout increased by .8 seconds the \ntime spent selecting a proposal (p=.004). Possible explanations for this phenomenon include that (1) \nthe Quick Fix Scout dia\u00adlog contains extra information that the participants took extra time to process, \nand (2) Quick Fix Scout may take time to compute causing the participants to wait for the information \nto appear. Explanation (1) also explains the overall productiv\u00adity improvement. If the participant gets \nenough information from the dialog, she could resolve the error without having to investigate the related \ncode. Supporting this hypothesis, half of the participants agreed that they needed to type more manually \n instead of using Quick Fix proposals to re\u00adsolve compilation errors when not using Quick Fix Scout \n(Figure 17). Use of Quick Fix Scout did not have any other statistically signi.cant effects. This stability \nbetween treatments strength\u00adens our hypothesis that Quick Fix Scout did not change the way participants \nused Quick Fix, rather the extra information provided by Quick Fix Scout increased participants under\u00adstanding \nof the code and helped them make better decisions. One participant noted:  It was pretty apparent after \nusing regular Quick Fix second, that [Quick Fix] Scout sped things up. I got frustrated as I d have to \nscan from error to error to .x a problem rather than just go to the .rst error I saw. What s more, I \nhad to spend more time staring at the [Quick Fix dialog] often to .nd that there was nothing relevant. \nThe data, the analysis, and the qualitative insights from the case study and controlled experiment participants \nsuggest that RQ 2 holds: Quick Fix Scout indeed changes the way in which users choose and use Quick Fix \nproposals. We have not teased out which aspects of Quick Fix Scout have the most in.uence. 6. Threats \nto Validity We assess our evaluation activities in terms of simple charac\u00adterizations of internal and \nexternal validity. Internal validity refers to the completeness and the correctness of the data collected \nthrough the experiments. External validity refers to the generalizability of our results to other settings. \nOne threat to internal validity is that, due to implemen\u00adtation dif.culties, we log all Quick Fix invocations \nexcept those invoked through the Hover Dialog. We tried to limit this threat by rejecting participants \nwho indicated that they consistently use Hover Dialog for invoking Quick Fix and by mentioning this restriction \nto accepted participants, recom\u00admending that they invoke Quick Fix in a different way. So the data we \nlogged about invocations is accurate, although it may be incomplete. Another threat to internal validity \nis in our computation of which proposal resolves the most errors. Since the developer might complete \na Quick Fix invocation before the speculation computation completes, and because some proposals are omitted \na priori (for example, a Create class proposal), we may not always log the number of compilation errors \nthat would remain for every Quick Fix proposal. In some cases, these omitted proposals could resolve \nmore compilation errors than the ones we identify as resolving the most errors. In our case study, only \n6% of all completed Quick Fix invocations are completed before the speculative analysis .nishes. Further, \nin our case study, none of the users selected instances of the a priori omitted proposals. In addition \nto common external validity threats (such as having students rather than professional developers as participants), \na key threat is the decisions we made about which programs to use in the controlled experiment:  treatment \n# invocations (invs.) undone invs. rate +invs. rate avg. time +invs. -invs. 1st prop. rate 2nd prop. \nrate 3rd prop. rate BP rate GBP rate a QF QFS 554 449 17% 10% 58% 68% 3.0s 6.8s 4.6s 8.8s 79% 79% 18% \n16% 0% 0% 76% 90% 79% \u00df QF QFS 572 631 13% 17% 56% 55% 4.3s 7.9s 4.4s 6.8s 73% 71% 20% 22% 2% 2% 71% \n85% 67% QF QFS 1116 1080 15% 14% 57% 60% 3.7s 7.4s 4.5s 7.4s 76% 75% 19% 19% 1% 1% 73% 87% 75% Figure \n14. Quick Fix and Quick Fix Scout invocation duration and proposal selection rate results. Invocations \nthat were immediately undone by the participant are excluded. + and -invocations are ones for which the \nparticipant selected and did not select a proposal, respectively. For each treatment, we report the rates \nwith which participants chose the 1st, 2nd, and 3rd proposal, as well as the best (BP) and global best \nproposals (GBP). Best proposals are de.ned as the proposals that resolve the highest number of compilation \nerrors for a given Quick Fix invocation.  Using small programs with multiple compilation errors.  \nUsing snapshots from the case study participants to popu\u00adlate our tasks in the controlled experiment. \n Adding seeded errors to half of the snapshots using mutation operators, as well as using a speci.c \nset of mutation operators.  Although there are strong motivations for each of these decisions in our \nexperimental design, they could still, in principle, lead to inaccurate conclusions about how Quick Fix \nScout would work if it were broadly distributed and used. 7. Related Work The interest in software recommendation \nsystems soft\u00adware . . . that provides information items estimated to be valu\u00adable for a software engineering \ntask in a given context [15] has grown over the past few years, with an increasing number of research \nresults and tools, as well as an ongoing workshop [6]. Work in recommendation systems includes: de.ning \nrecommendations for new domains, such as requirements elicitation [5] and team communication [17]; frameworks \nfor de.ning recommendation systems [9]; and techniques for choosing recommendations to include in a system, \nsuch as data mining [16]. Some of efforts that are more directly relevant to Quick Fix Scout also aim \nto improve IDE recommendations. Robbes and Lanza propose eight different ways to reorder code\u00ad completion \nrecommendations; they evaluated these tech\u00ad niques on a realistic benchmark, and show that reordering \nthe matches based on historical usage provides the greatest improvement [14]. Bruch et al. reorder and \n.lter the Eclipse auto-complete dialog using mined historical data and developer usage habits [1]. Recently, \nPerelman et al. showed that Visual Studio auto-complete (IntelliSense) can be improved by using developer-supplied \npartial types, to search all APIs for auto-completions that would transform the input type to the expected \noutput type [13]. In contrast to the .rst two of these approaches, which rely on past usage patterns, \nQuick Fix Scout reorders rec\u00adommendations based on information about properties of the program that will \nbe created if a recommendation is selected. In contrast to the third approach, the developer need not \nadd any information to the program for Quick Fix Scout (or, of course, Quick Fix) to work. In addition, \nwe have recently shown how to improve IDE recommendations by considering the interactions between existing \nrecommendations [11]; this is a key motivation for global best proposals (Section 4). In addition to \nindustrial efforts related to Quick Fix,6 some research efforts address various aspects of Quick Fix. \nFor example, a paper on automatic refactoring in the face of prob\u00adlems such as references to unavailable \ndeclarations mentions an experimental participant s idea to augment the system with invocations to Quick \nFix [8]. As another example, a recom\u00ad mendation system approach to increasing reuse also suggests integrating \ntheir system through Quick Fix [7]. Quick Fix Scout is built on speculative analysis: a tech\u00adnique that \ncomputes precise information about likely future states of a program and presents this information to \nthe de\u00adveloper so that she can make better and more informed deci\u00adsions [2]. Applying speculative analysis \non collaborative soft\u00ad ware development [4], we built Crystal [3]: a tool that noti.es developers as \nsoon as a con.ict emerges. The biggest differ\u00adence between Crystal and Quick Fix Scout is the granularity \nof the speculation. For collaboration con.icts, it is acceptable if the developer is noti.ed after the \ncon.ict emerges since she would still be able to .nd the reason of the con.ict and coordinate it. As \na result, Crystal does not have to work on the most recent copy of the project and might report results \nwith some delay. However, when a developer invokes Quick Fix, she needs the results for the recent version \nof the project as the results from any previous version is not acceptable and 6 http://eclipse.org/recommenders \n  User ID Status in the Department Java Know-Eclipse Know-QF Usage ledge (Years) ledge (Years) Frequency \nKeyboard Quick Context Shortcut Fix Icon Menu Hovering CS01 4th year BS 6 3 2 v v v CS02 1st year PhD \n4 1.5 1 v CS03* 2nd year PhD 7 7 4 v v CS04 1st year Post-doc 13 9 3 v v CS05 6th year PhD 2 2 3 v v \nv v CS06* Assistant Prof. 11 4 4 v v v CS07* Assistant Prof. 12 10 4 v v CS10 5th year PhD 7 3 2 v v \nv CS12 3rd year PhD 7 6 4 v v CE01 1st year PhD 3 3 3 v v v CE02 2nd year PhD 11 5 3 v v v v CE03 2nd \nyear PhD 10 10 3 v CE04 5th year PhD 10 9 1 v v CE05 1st year PhD 3 2 2 v v CE06 2nd year PhD 1 1 1 v \nCE07 2nd year PhD 2 2 1 v v CE08 3rd year PhD 10 8 3 v v v CE09 2nd year PhD 8 2 3 v v CE10 2nd year \nPhD 5 5 2 v v CE11 2nd year PhD 5 5 2 v v CE12 3rd year PhD 3 2 1 v v CE13 6th year PhD 10 3 3 v v CE14 \n2nd year PhD 6.5 6.5 4 v v v CE15 1st year PhD 7 3 2 v v CE16 2nd year PhD 6 7 1 v v CE17 3rd year PhD \n3 1 1 v CE18 2nd year PhD 8 3 1 v v v CE19 3rd year PhD 4 2 3 v CE20 2nd year PhD 4 4 3 v v v Figure \n15. Case study and controlled experiment participants familiarity with Java, Eclipse and Quick Fix. CS \nand CE pre.xes in user id represent case study and controlled experiment participants respectively. QF \nUsage Frequency is how frequently the participants use Quick Fix on a scale from 0 to 4, 0 meaning never \nand 4 meaning very frequently. A check mark in the last four columns represent that the participant prefers \nQuick Fix using the method in the column header. Case study participants # 8, 9, 11, and 13 are not shown \nsince they have not completed our survey.  actionable. In addition, the developers want to see the results \nas soon as the Quick Fix dialog is created since it takes a couple of seconds for them to decide what \nto choose. 8. Contributions Quick Fix Scout is an enhancement of Eclipse s standard Quick Fix that computes \nand reports to the user the number of compilation errors that would remain in the program for each Quick \nFix proposal. Our prototype Eclipse plug-in addresses issues ranging from challenges in the user interface \n(additional information must be presented in roughly the same space used by the Quick Fix dialog) to \nchallenges in keeping a background copy of the developer s code in sync with the dynamically changing \ncode (Quick Fix Scout uses a copy to speculatively apply the proposals). We evaluated Quick Fix Scout \nin two ways: an informal case study of how a set of friendly users use both Quick Fix and Quick Fix Scout \nin their own work, and a 20-user, within-subjects, mixed-design controlled experiment that compares Quick \nFix and Quick Fix Scout. Users .xed compilation errors 10% faster, on average, when using Quick Fix Scout, \nalthough this improvement was not statistically signi.cant. We are considering several improvements to \nQuick Fix Scout. First, if errors remain after applying a proposal, Quick Fix Scout can apply the approach \nrepeatedly until all compi\u00adlation errors are resolved or no progress can be made. Such multiple-ply speculation \ncan identify proposals that resolve few errors but lead Quick Fix to generate new proposals that may \nresolve more errors. One goal of the approach would be to produce the smallest set of consecutive proposal \nappli\u00adFigure 16. The four-question survey, and a summary of the participants responses, administered \nafter each participant used Quick Fix Scout. S. Agree (resp. Disagree) represents Strongly Agree (resp. \nDisagree).  Question S. Agree Agree Neutral Disagree S. Disagree N/A Number of remaining compilation \nerrors was helpful. 4 13 2 1 0 0 Reordering of proposals was helpful. 7 13 0 0 0 0 Coloring of proposals \nwas helpful. 5 7 5 0 0 3 I liked the user experience provided by Quick Fix Scout. 7 12 1 0 0 0 Question \nBoth Quick Fix Scout Quick Fix Neither Quick Fix (Scout) is helpful when resolving compilation errors. \n19 1 0 0 There was no performance issues before Quick Fix dialog is updated. 10 1 2 7 For some tasks, \nI undid a proposal when using Quick Fix (Scout). 12 1 7 0 I manually resolved errors more often with \nQuick Fix (Scout). 2 0 10 8 Figure 17. The four-question survey, and a summary of the participants responses, \nadministered at the end of each participant s experiment session. cations that resolves all, or the most \npossible, errors. This improvement raises several performance concerns, as the search space of proposals \nmay be large. Second, Quick Fix Scout can use more-complex analyses to identify the conse\u00adquences of \npossible future states. For example, if each of multiple proposals removes all compilation errors, Quick \nFix Scout can speculatively run tests to determine which proposal makes the most tests pass. This information \nwould likely allow users to make better decisions. As another example, successfully-compiling code might \nstill cause version con\u00adtrol con.icts; Quick Fix Scout could integrate our approach to proactively identify \nversion control con.icts [4]. Again, these analyses may be computationally intensive and raise performance \nconcerns for Quick Fix Scout. The use of speculative analysis in software development is promising but \nfull of technical challenges. Quick Fix Scout is an exemplar for speculative analysis. The underlying \nenviron\u00adment (Eclipse s Quick Fix) de.nes the actions that generate likely future states, and the computation \nof consequences is made ef.cient by Eclipse s incremental compiler. Find\u00ading other domains, and other \nimplementation techniques, that provide an effective balance between performance and information to usefully \nguide developers, is a dif.cult but worthwhile effort. Acknowledgments We thank Deepak Azad and Dani \nMegert for explaining, on the Eclipse JDT forum, the internal Eclipse API and several implementation \ndetails. We thank Daniel Perelman, Colin Gordon, and Ivan Beschastnikh for piloting our experiment. We \nespecially acknowledge the detailed and pertinent reviews that helped us signi.cantly improve the paper. \nThis material is based upon work supported by the Bradley Chair in Computer Science &#38; Engineering, \nthe National Sci\u00adence Foundation under Grants CNS-0937060 to the Com\u00adputing Research Association for \nthe CIFellows Project and CCF-0963757, and by Microsoft Research through a Soft\u00adware Engineering Innovation \nFoundation grant. A. Appendix This section presents additional details of the data gathered during the \nexperiments. Figure 15 summarizes the partic\u00ad ipants familiarity with Java, Eclipse, and Quick Fix. Fig\u00adures \n16 and 17 summarize the surveys given to the controlled experiment participants. References [1] M. Bruch, \nM. Monperrus, and M. Mezini. Learning from examples to improve code completion systems. In Proceed\u00adings \nof the the 7th Joint Meeting of the European Software Engineering Conference and ACM SIGSOFT Symposium \non The Foundations of Software Engineering (ESEC/FSE09), pages 213 222, Amsterdam, The Netherlands, 2009. \ndoi: 10.1145/1595696.1595728. [2] Y. Brun, R. Holmes, M. D. Ernst, and D. Notkin. Speculative analysis: \nExploring future states of software. In Proceedings of the 2010 Foundations of Software Engineering Working \nConference on the Future of Software Engineering Research, FoSER 10, Santa Fe, NM, USA, November 2010. \ndoi: 10.1145/1882362.1882375. [3] Y. Brun, R. Holmes, M. D. Ernst, and D. Notkin. Crys\u00adtal: Proactive \ncon.ict detector for distributed version control. http://crystalvc.googlecode.com, 2010. [4] Y. Brun, \nR. Holmes, M. D. Ernst, and D. Notkin. Proactive detection of collaboration con.icts. In Proceedings \nof the 8th Joint Meeting of the European Software Engineering Confer\u00ad  ence and ACM SIGSOFT Symposium \non the Foundations of Software Engineering, ESEC/FSE 11, pages 168 178, Szeged, Hungary, September 2011. \ndoi: 10.1145/2025113.2025139. [5] C. Castro-Herrera, C. Duan, J. Cleland-Huang, and B. Mobasher. A recommender \nsystem for requirements elici\u00adtation in large-scale software projects. In Proceedings of the 2009 ACM \nSymposium on Applied Computing, SAC 09, pages 1419 1426, 2009. doi: 10.1145/1529282.1529601. [6] R. Holmes, \nM. Robillard, R. Walker, T. Zimmermann, and W. Maalej. International Workshops on Recommendation Systems \nfor Software Engineering (RSSE). https://sites. google.com/site/rsseresearch, 2012. [7] W. Janjic, D. \nStoll, P. Bostan, and C. Atkinson. Lowering the barrier to reuse through test-driven search. In Proceed\u00adings \nof the 2009 31st International Conference on Software Engineering Workshop on Search-Driven Development-Users, \nInfrastructure, Tools and Evaluation, SUITE 09, pages 21 24, 2009. doi: 10.1109/SUITE.2009.5070015. [8] \nP. Kapur, B. Cossette, and R. J. Walker. Refactoring references for library migration. In Proceedings \nof the ACM International Conference on Object Oriented Programming Systems Lan\u00adguages and Applications, \nOOPSLA 10, pages 726 738, 2010. doi: 10.1145/1869459.1869518. \u00b4source framework for general-purpose recommender \nsystems. In Proceedings of the 14th International ACM SIGSOFT Symposium on Component Based Software Engineering, \nCBSE 11, pages 67 72, 2011. doi: 10.1145/2000229.2000239. [9] F. M. Melo and A. Pereira Jr. A component-based \nopen\u00ad [10] K. Mus\u00b8lu, Y. Brun, R. Holmes, M. D. Ernst, and D. Notkin. Quick Fix Scout. http://quick-.x-scout.googlecode.com, \n2010. [11] K. Mus\u00b8lu, Y. Brun, R. Holmes, M. D. Ernst, and D. Notkin. Improving IDE recommendations by \nconsidering global im\u00ad plications of existing recommendations. In Proceedings of the 34th International \nConference on Software Engineering, New Ideas and Emerging Results Track, ICSE 12, Zurich, Switzerland, \nJune 2012. doi: 10.1109/ICSE.2012.6227082. [12] G. C. Murphy, M. Kersten, and L. Findlater. How are Java \nsoftware developers using the Eclipse IDE? IEEE Software, 23(4):76 83, July 2006. doi: 10.1109/MS.2006.105. \n[13] D. Perelman, S. Gulwani, T. Ball, and D. Grossman. Type\u00addirected completion of partial expressions. \nIn Proceedings of Programming Language Design and Implementation, PLDI 12, Beijing, China, June 2012. \ndoi: 10.1145/2254064. 2254098. [14] R. Robbes and M. Lanza. How program history can improve code completion. \nIn Proceedings of the 23rd IEEE/ACM International Conference on Automated Software Engineering, ASE 08, \npages 317 326, L Aquila, Italy, 2008. doi: 10.1109/ ASE.2008.42. [15] M. Robillard, R. Walker, and T. \nZimmermann. Recommen\u00addation systems for software engineering. IEEE Software, 27: 80 86, 2010. doi: 10.1109/MS.2009.161. \n[16] K. Schneider, S. G\u00a8ugge.artner, T. Wehrmaker, and B. Br\u00a8Recommendations as learning: From discrepancies \nto software improvement. In Proceedings of the International Workshop on Software Recommendation Systems, \nRSSE 12, pages 31 32, 2012. doi: 10.1109/RSSE.2012.6233405. [17] P. F. Xiang, A. T. T. Ying, P. Cheng, \nY. B. Dang, K. Ehrlich, M. E. Helander, P. M. Matchen, A. Empere, P. L. Tarr, C. Williams, and S. X. \nYang. Ensemble: a recommendation tool for promoting communication in software teams. In Pro\u00adceedings \nof the International Workshop on Recommendation Systems for Software Engineering, RSSE 08, pages 2:1 \n2:1, 2008. doi: 10.1145/1454247.1454259.    \n\t\t\t", "proc_id": "2384616", "abstract": "<p>Modern integrated development environments make recommendations and automate common tasks, such as refactorings, auto-completions, and error corrections. However, these tools present little or no information about the consequences of the recommended changes. For example, a rename refactoring may: modify the source code without changing program semantics; modify the source code and (incorrectly) change program semantics; modify the source code and (incorrectly) create compilation errors; show a name collision warning and require developer input; or show an error and not change the source code. Having to compute the consequences of a recommendation -- either mentally or by making source code changes -- puts an extra burden on the developers. This paper aims to reduce this burden with a technique that informs developers of the consequences of code transformations. Using Eclipse Quick Fix as a domain, we describe a plug-in, Quick Fix Scout, that computes the consequences of Quick Fix recommendations. In our experiments, developers completed compilation-error removal tasks 10% faster when using Quick Fix Scout than Quick Fix, although the sample size was not large enough to show statistical significance.</p>", "authors": [{"name": "K&#305;van&#231; Mu&#351;lu", "author_profile_id": "81485645867", "affiliation": "University of Washington, Seattle, WA, USA", "person_id": "P3856158", "email_address": "kivanc@cs.washington.edu", "orcid_id": ""}, {"name": "Yuriy Brun", "author_profile_id": "81332491503", "affiliation": "University of Massachusetts, Amherst, MA, USA", "person_id": "P3856159", "email_address": "brun@cs.umass.edu", "orcid_id": ""}, {"name": "Reid Holmes", "author_profile_id": "81100345666", "affiliation": "University of Waterloo, Waterloo, ON, Canada", "person_id": "P3856160", "email_address": "rtholmes@cs.uwaterloo.ca", "orcid_id": ""}, {"name": "Michael D. Ernst", "author_profile_id": "81100204056", "affiliation": "University of Washington, Seattle, WA, USA", "person_id": "P3856161", "email_address": "mernst@cs.washington.edu", "orcid_id": ""}, {"name": "David Notkin", "author_profile_id": "81100636585", "affiliation": "University of Washington, Seattle, WA, USA", "person_id": "P3856162", "email_address": "notkin@cs.washington.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384665", "year": "2012", "article_id": "2384665", "conference": "OOPSLA", "title": "Speculative analysis of integrated development environment recommendations", "url": "http://dl.acm.org/citation.cfm?id=2384665"}