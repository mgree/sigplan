{"article_publication_date": "10-19-2012", "fulltext": "\n Towards a Practical Secure Concurrent Language Stefan Muller Carnegie Mellon University smuller@cs.cmu.edu \nAbstract We demonstrate that a practical concurrent language can be extended in a natural way with information \nsecurity mech\u00adanisms that provably enforce strong information security guarantees. We extend the X10 \nconcurrent programming lan\u00adguage with coarse-grained information-.ow control. Central to X10 concurrency \nabstractions is the notion of a place:a container for data and computation. We associate a security level \nwith each place, and restrict each place to store only data appropriate for that security level. When \nplaces interact only with other places at the same security level, then our security mechanisms impose \nno restrictions. When places of differing security levels interact, our information security analysis \nprevents potentially dangerous information .ows, including information .ow through covert scheduling \nchan\u00adnels. The X10 concurrency mechanisms simplify reasoning about information .ow in concurrent programs. \nWe present a static analysis that enforces a noninterfer\u00adence-based extensional information security \ncondition in a calculus that captures the key aspects of X10 s place ab\u00adstraction and async-.nish parallelism. \nWe extend this secu\u00adrity analysis to support many of X10 s language features, and have implemented a \nprototype compiler for the resulting lan\u00adguage. Categories and Subject Descriptors D.3.3 [Programming \nLanguages]: Language Constructs and Features Concurrent programming structures; D.4.6 [Operating Systems]: \nSecu\u00adrity and Protection Information .ow controls Keywords Language-based security; information-.ow con\u00adtrol; \nX10. 1. Introduction Enforcement of strong information security guarantees for concurrent programs poses \nboth a challenge and an oppor- Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, USA. Copyright c &#38;#169; \n2012 ACM 978-1-4503-1561-6/12/10. . . $10.00 Stephen Chong Harvard University chong@seas.harvard.edu \ntunity. The challenge is that, given current hardware trends towards increased parallelism, and the large \nnumber of com\u00adputer systems that handle data of varying sensitivity, it is increasingly important to \nreason about and enforce informa\u00adtion security guarantees in the presence of concurrency. Al\u00adthough progress \nhas been made towards this end, there are not yet practical enforcement mechanisms and usable im\u00adplementations. \nThe opportunity is to adapt new and existing language abstractions for concurrency to reason precisely \nabout information security in concurrent programs. Infor\u00admation security, like concurrency, is intimately \nconnected to notions of dependency [1]. As such, there is potential for synergy between language mechanisms \nfor concurrency, and enforcement mechanisms for information security in concur\u00adrent programs. The X10 \nprogramming language [10] is an object-oriented language with abstractions to support .ne-grained concur\u00adrency. \nCentral to X10 concurrency abstractions is the notion of a place. A place is a computational unit that \ncontains computation and data. For example, each core of a single machine or each machine within a distributed \nsystem might be represented by a different place. Data held at a place, and computation running at a \nplace, are said to be local to the place. Places are .rst-class in X10. Multiple threads of execution, \nwhich in X10 are known as activities, may execute concurrently within a place. Activities at the same \nplace share memory, and an activity may only access data at the place where it is located. Places may \ncommunicate using message passing, but X10 is designed to discourage excessive communication between \nplaces, since this reduces concurrency. We extend X10 language abstractions for concurrency with information \nsecurity mechanisms, and call the resulting language SX10 (for Secure X10). Speci.cally, in SX10 each \nplace is associated with a security level, and a (completely static) security analysis ensures that each \nplace stores only data appropriate for that security level. Thus, all computa\u00adtion within a place is \non data at the same security level. In the case where places communicate only with other places at the \nsame security level, then our security mechanisms do not im\u00adpose any restrictions on programs. Communication \nbetween places with different security levels may pose security con\u00adcerns, but because message-passing \ncommunication is used between places, it is relatively simple to restrict such com\u00admunication: the security \nanalysis ensures that data may be sent to another place only when the security level of the des\u00adtination \nis suf.ciently high. Interaction between places may in.uence the scheduling of activities at a place, \nleading to potential covert information channels; our security analysis tracks and controls these covert \nchannels.  We believe that this coarse-grained approach to provid\u00ading information security in concurrent \nprograms is simple, practical, and useful. All data at a place is at the same se\u00adcurity level, which \nboth provides simplicity of reasoning for the programmer, and allows a high degree of concurrency within \na place without compromising security. There are many highly concurrent systems that compute with data \nof varying sensitivity that .t naturally into such a model. The following are some examples. Machine \nlearning A service such as Pandora processes a large amount of public data, which is then used to make \nrecommendations to individual users based on their private usage data. All public data is at the same \nsecurity level and processing it is highly parallel; data from many users are processed in parallel. \n Social networks Users specify that some posts are visi\u00adble to all other users, and some are visible \nonly to friends. Many users may use the system concurrently.  Shopping carts An online shopping cart \ncollects infor\u00admation about items ordered, which may appear in low\u00adsecurity logs, and credit card information, \nwhich must remain secure. Many customers may use the system con\u00adcurrently.  Motivating example Reasoning \nabout information secu\u00adrity in the presence of concurrency can be subtle. Consider Program 1, which exhibits \na timing channel. 1 2 3 at Low {async {// Activity 1 4 if (hi > 0) longComputation(); 5 output pos ; \n6 7 }// Activity 2 8 mediumComputation(); output nonpos ; 9 } Program 1. Assume that memory location \nhi contains high-security (e.g., secret) data. Instruction at Low s indicates that s is ex\u00adecuted at \na place called Low, which we assume is allowed to handle only low-security data. Outputs at place Low \nshould not reveal high-security information. Instruction async s cre\u00adates a new activity to execute statement \ns, and the current activity continues with the following statement. Thus, the if statement and subsequent \noutput of the string pos ex\u00adecute concurrently with the output nonpos statement. If high-security \nmemory location hi is positive, then Activity 1 outputs pos after a long time; otherwise it outputs \n pos immediately. Activity 2 computes for a medium amount of time, and outputs nonpos . It is likely \nthat the order of outputs will reveal secret information, and the program is thus insecure. This is an \nexample of an internal timing chan\u00adnel [48], where the order of publicly observable events de\u00adpends upon \nhigh-security information. Program 1 is not an SX10 program: low-security place Low is not allowed to \nhold high-security data, such as that stored in memory location hi. Suppose, however, that High is a \nplace that is permitted to hold secret information. Then Program 2 is a SX10 program and exhibits a similar \ntiming channel. (It is correctly rejected by our security analysis.) 1 2 3 at Low {async {// Activity \n1 4 5 at High { // activity 1 moves to High if (hi > 0) longComputation(); 6 7 }// activity 1 moves back \nto Low 8 output pos ; 9 10 }// Activity 2 11 mediumComputation(); output nonpos ; 12 } Program 2. \nIn this example, Activity 1 moves to place High in order to perform computation on high-security data, \nbefore returning to place Low to perform the output of the string pos . We assume that the scheduling \nof activities at each place depends only on the activities at that place, an assumption that holds in \nthe X10 2.2 runtime [14]. Nonetheless, in Pro\u00adgram 2, the scheduling of Activity 2 at place Low depends \non whether Activity 1 is running at Low, which in turn depends on how long the computation at place High \ntakes. Thus, the scheduling of output pos and output nonpos may be in\u00ad.uenced by high-security data. \nOur security analysis detects this potential information .ow, and rejects the program. Program 2 is inherently \nnondeterministic: it could per\u00adform the two outputs in either order. The scheduler re\u00adsolves the nondeterminism, \nbut in doing so, may reveal high\u00adsecurity information a form of re.nement attack [39]. One way to prevent \nsuch re.nement attacks is to require that any observable behavior be deterministic [6, 49]. Our security \nanalysis requires such observational determinism when the resolution of nondeterminism may reveal high-security \nin\u00adformation. It is, however, possible to allow some observable nonde\u00adterminism within a secure concurrent \nprogram. Intuitively, if the resolution of the nondeterminism does not depend on high-security information, \nthen observable nondetermin\u00adism is secure [31]. If place P does not communicate with any other places, \nthen, since scheduling is performed per\u00adplace, resolution of nondeterminism at P will not reveal high-security \ninformation. In some cases it is also possible to allow nondeterminism at place P even if P interacts \nwith places of higher security levels. Consider Program 3: Activ\u00adity 1 executes at place Low concurrently \nwith Activity 2 s ex\u00adecution at place High. The .nish s instruction executes state\u00adment s, and waits \nuntil s and all activities spawned by s have terminated before continuing execution. Thus, Activity 3 \nand Activity 4 execute concurrently at place Low after Activi\u00adties 1 and 2 have .nished. Although the \norder of output B and output C is nondeterministic, resolution of this non\u00addeterminism is not in.uenced \nby how long the high-security computation takes, and so does not reveal high-security in\u00adformation. \n 1 2 3 4 at Low {.nish {async {// Activity 1 5 output A ; 6 7 }// Activity 2 8 9 at High {if (hi > 0) \nlongComputation(); 10 11 12 13 }}async {// Activity 3 14 output B ; 15 16 }// Activity 4 17 output \nC ; 18 } Program 3. Contributions The key contribution of this paper is to demonstrate that practical \nand useful concurrency mecha\u00adnisms can be extended in a natural way with information se\u00adcurity mechanisms \nthat provably enforce strong information security guarantees. We enforce coarse-grained information\u00ad.ow \ncontrol [39], requiring that every place can store only data at a single security level. If places interact \nonly with other places at the same security level, then our security mechanisms do not restrict concurrency \nnor require deter\u00adminism for security. When places of differing security in\u00adteract, our information security \nanalysis prevents potentially dangerous information .ows by using X10 s concurrency mechanisms to reason \nboth about data sent between places, and about how the scheduling of activities at a place may depend \non high-security information. In Section 2 we present a calculus, based on Feather\u00adweight X10 [22], that \ncaptures key aspects of the X10 place abstraction, and its async-.nish parallelism. We de.ne a knowledge-based \nnoninterference semantic security condi\u00adtion [2, 12] for this calculus in Section 3, and present a se\u00adcurity \nanalysis that provably enforces it. The language SX10 is the result of extending this analysis to handle \nmany of the language features of X10. We have implemented a prototype compiler for SX10 by modifying \nthe X10 compiler, and this is described in Section 4. We discuss related work in Sec\u00adtion 5 and conclude \nin Section 6. 2. FSX10: a secure parallel calculus In this section, we introduce the calculus FSX10, \nbased on Featherweight X10 [22]. Like Featherweight X10, this calculus captures X10 s async-.nish parallelism, \nbut adds places and interaction with the external environment via input and output instructions. 2.1 \nSyntax The abstract syntax of FSX10 is presented in Figure 1. A place P is a container for data and activities. \nIn FSX10, as in X10, every memory location r and every activity is asso\u00adciated with a place. In FSX10, \nhowever, places are simply identi.ers and are not .rst-class values. Function Place(\u00b7) describes how \nmemory locations are mapped to places: memory location r is held at place Place(r), and only code executing \nat that place is allowed to access the location. For simplicity, we restrict values in the calculus to \ninte\u00adgers. Expressions e consist of integer constants v, variables x, memory reads !r (where r is a memory \nlocation), and total binary operations over expressions e1 .e2. Statements s are sequences of instructions. \nEvery instruc\u00adtion is labeled with a program point. For example, a store instruction r :=p e has program \npoint p. For convenience we write sp to indicate that program point p is the program point of the .rst \ninstruction of statement s. When the pro\u00adgram point of an instruction is irrelevant, we omit it. Instructions \ninclude no-ops (skip), selection (if e then s else s), and iteration (while e do s). Instruction r := \ne eval\u00aduates expression e and updates memory location r with the result. Instruction let x = e in s evaluates \nexpression e to a value, and uses that value in place of variable x in the evalua\u00adtion of statement s. \nOnce de.ned, variable x is immutable. A variable de.ned at place P may be used at a different place P \n', which can be thought of as P sending the value of the variable to P '. Instruction async s creates \na new activity that starts exe\u00adcuting statement s, and the current activity continues exe\u00adcuting the \nnext instruction. Instruction at Ps executes state\u00adment s at place P . Note that at Ps does not create \na new activity: execution of the next instruction waits until s has terminated. That is, given the statement \nat Ps; r := 42; skip, the assignment of 42 to memory location r will not occur until after statement \ns has .nished execution. Instruction backat Ps does not appear in source programs, but is used by Metavariables \n P ranges over places p ranges over program points v ranges over integer constants x ranges over program \nvariables r ranges over memory locations . ranges over total binary integer functions Expressions e ::= \nv Integer constant | x Variable | !r Memory read | e.e Binary operation Statements s ::= skipp No-op \n| i; s Sequence Instructions i ::= skipp No-op | r :=p e Memory write | ifp e then s else s Conditional \n| whilep e do s Iteration | letp x = e in s Let | outputp e Output | inputp r Input p | asyncs Asynchronous \n| atp Ps At | .nishp s Finish | backatp P Back at Trees T ::= (P, s) Activity | T || T Parallel | T. \n(P, s) Join | . Done Figure 1. FSX10 syntax the operational semantics to track when control will return \n'' back to place P as a result of .nishing an at Ps instruc\u00adtion. Finally, instruction .nish s will block \nuntil statement s, and all activities created by s, have terminated. FSX10 programs can communicate with \nthe external en\u00advironment via input and output instructions. We assume, without loss of generality, that \nevery place has a single com\u00admunication channel. Instruction output e, when executed at place P , will \nevaluate expression e to a value, and output that value on P s channel. Similarly, instruction input \nr, when executed at P , will input a value from P s channel, and store the result in location r. We assume \nthat there is always data available for input on a channel, and thus input instructions are non-blocking. \nConcurrently executing activities in FSX10 are repre\u00adsented using trees. Tree (P, s) is an activity at \nplace P exe\u00adcuting statement s. Tree T1 || T2 represents trees T1 and T2 executing concurrently. Tree \n. indicates a terminated activ\u00adity, and tree T.(P, s) indicates that activity (P, s) is blocked until \nall activities in T have terminated.  2.2 Events, traces, and input strategies As a program executes, \nit generates input and output events. Input event i(v, P ) is generated when an input instruction accepts \nvalue v from P s channel. Output event o(v, P ) is generated when an output instruction outputs value \nv on P s channel. A trace t is a (possibly empty) sequence of input, output and location assignment events. \nOther events are not tracked. We write E for the empty trace. We write t P for the subse\u00adquence of events \nof t that occur at place P . More formally, we have E P = E (t P ) \u00b7 a if Place(a)= P (t \u00b7 a) P = t \nP otherwise where function Place(a) is the place at which a occurred: Place(i(v, P)) = P Place(o(v, P)) \n= P. We model input from the external environment with input strategies [31]. Input strategy . is a \nfunction from places and traces to values, such that given trace t, value .(P, t P ) is the next value \nto input on the channel for P . Note that the choice of the next value that will be input on a channel \ncan depend on the previous outputs of the channel. In Section 3, where we consider the security of FSX10 \nprograms, we will be concerned with ensuring that low-security attackers are unable to learn about the \ninputs to high-security places.  2.3 Scheduling Since program execution, and information security, depends \non scheduling, we model the scheduler in FSX10. We explic\u00aditly re.ne the nondeterminism inherent in scheduling \nusing re.ners [31] to represent the decisions made by the sched\u00aduler. Essentially, all nondeterminism \nin program execution is encapsulated in a re.ner; once a re.ner has been chosen, program execution is \ndeterministic. In X10, a place represents a distinct computational node with a distinct scheduler [14]. \nIn accordance with this model, we assume that scheduling decisions are made on a per-place basis, and \nthe choice of which activity to run at a given place depends only on the set of activities currently \nexecuting at that place.  PLACE Sch(P )= chs \u00b7 ch PointsRunning(T,P )= \u00d8 IDLEPLACE p ch(PointsRunning(T,P \n)) = p (H; .; t; T ) . (H'; .; t'; T ') PointsRunning(T,P )= \u00d8 ' (H; .;(P \u00b7 P s, Sch); t; T ) . (H'; \n.;(P s, Sch[P . chs]); t; T ')(H; .;(P \u00b7 P s, Sch); t; T ) . (H; .;(P s, Sch); t; T ) PointsRunning(.,P \n)= \u00d8  {p} if P ' = P PointsRunning((P ',sp),P )= \u00d8 if P '= P PointsRunning(T1 || T2,P )= PointsRunning(T1,P \n) . PointsRunning(T2,P ) ' PointsRunning(TC (P ,s),P )= PointsRunning(T,P ) ' Figure 2. Program semantics \n(H; .; R; t; T ) . (H ; .; R ' ; t ' ; T ' ) We model these assumptions by representing a re.ner R as \na pair (P s, Sch), where Ps is a stream of places indicating the order in which places take steps, and \nSch is a function from places to streams chs of scheduling functions. A scheduling function ch takes \na set of program points (representing the set of activities currently executing at the place), and returns \nan element of that set (representing which of the activities should be scheduled). We write P \u00b7 Ps for \na stream with .rst element P and remaining elements Ps. Thus, if the re.ner is (P \u00b7P s, Sch), then place \nP will take a step next, and if Sch(P )= ch \u00b7 chs (where ch is the .rst element of the stream of scheduling \nfunction, and chs is the remainder of the stream), then scheduling function ch will be used to determine \nwhich of the current activities at P will be scheduled. Note that each time a place takes a step, it \nmay use a different scheduling function. However, the sequence of scheduling functions at a given place \nmust be decided in advance, and may not depend on the history of computation at the place. The use of \na stream of scheduling functions per place al\u00adlows our model to capture many realistic scheduling algo\u00adrithms, \nsuch as round robin, shortest remaining time, and .xed priority. Scheduling algorithms that depend on \nthe his\u00adtory of computation at a place (such as the work-stealing scheduling algorithm used in the X10 \nruntime [14, 15]) can\u00adnot be directly represented in this model. However, we be\u00adlieve the security guarantees \nstill hold for the X10 runtime; we further discuss the security of the X10 scheduler in Sec\u00adtion 4. \n 2.4 Operational semantics A program con.guration is a 5-tuple (H; .; R; t; T ). Heap H maps locations \nr to values, and is updated as the program executes. Input strategy . is used to determine values in\u00adput \non channels; the input strategy does not change during execution, but we include it in the program con.guration \nfor notational convenience. Re.ner R is used to determine scheduling, and is updated during execution. \nTrace t is the trace (of input, output, and location assignment events) pro\u00adduced so far by the program \ns execution. Tree T is the tree of currently executing activities. The small-step operational semantics \nrelation '' (H; .; R; t; T ) . (H ; .; R ' ; t ; T ' ) describes how a program con.guration changes as \na result of execution. Due to the use of re.ners, the operational semantics is deterministic. Inference \nrules for this relation are given in Figure 2. Rule PLACE uses the re.ner to select a place P to exe\u00adcute, \nand to select a scheduling function ch to schedule an activity at P . Set PointsRunning(T,P ) is the \nset of program points of running activities located at P (also de.ned in Fig\u00adure 2), which is given to \nscheduling function ch to select an activity. Rule IDLEPLACE handles the case where the re\u00ad.ner has selected \nplace P to execute, but P does not have any currently running activities. Judgment p '' (H; .; t; T ) \n-(H ; .; t ; T ' ) is used to indicate that tree con.guration (H; .; t; T ) exe\u00adcutes the instruction \nat program point p to produce tree con\u00ad ' .guration (H ; .; t ' ; T ' ). Tree con.gurations are similar \nto program con.gurations, but omit the re.ner, since the re.ner is used only to determine which activity \nto execute. p ' Inference rules for (H; .; t; T ) -(H ; .; t ' ; T ' ) are given in Figure 3. Rules PARALEFT, \nPARARIGHT, PAR-ALEFTDONE, PARARIGHTDONE, JOIN, and JOINDONE navigate through the tree structure to .nd \nthe appropriate activity to execute. Rule SKIP1 reduces a skip statement to a terminated activity .. \nThe remaining rules execute a single instruction. Several of the rules for evaluating instructions evaluate \nexpressions to values, using judgment P ; H; e . v, which is de.ned in Figure 4. Evaluation of expressions \nis standard, with the exception of memory read !r, which requires that memory location r is held at place \nP , the current place of the activity performing the read.  PARALEFT ''' ' (H; .; t; T1) p (H ; .; t \n; T1) T1 = . ' '' (H; .; t; T1 || T2) p (H ; .; t ; T1 || T2) PARALEFTDONE (H; .; t; T1) p (H ' ; .; \nt ' ; .) '' (H; .; t; T1 || T2) p (H ; .; t ; T2) JOIN p ''' ' (H; .; t; T )(H ; .; t ; T ) T = . ' '' \n(H; .; t; TC (P, s)) p (H ; .; t ; TC (P, s)) SKIP1 (H; .; t; (P, skipp)) p (H; .; t; .) WRITE P ; H; \ne . v Place(r)= P (H; .; t; (P, r :=p e; s)) p (H[r . v]; .; t; (P, s)) ASYNC (H; .; t; (P, asyncp s1; \ns2)) p (H; .; t; (P, s1) || (P, s2)) AT PARARIGHT ''' ' (H; .; t; T2) p (H ; .; t ; T2) T2 = . '' ' (H; \n.; t; T1 || T2) p (H ; .; t ; T1 || T2) PARARIGHTDONE (H; .; t; T2) p (H ' ; .; t ' ; .) '' (H; .; t; \nT1 || T2) p (H ; .; t ; T1) JOINDONE (H; .; t; T ) p (H ' ; .; t ' ; .) (H; .; t; TC (P, s)) p (H ' ; \n.; t ' ; (P, s)) SKIP2 (H; .; t; (P, skipp; s)) p (H; .; t; (P, s)) LET P ; H; e . vs1 ' = s1{v/x} (H; \n.; t; (P, letp x = e in s1; s2)) p (H; .; t; (P, s 1 ' s2)) FINISH (H; .; t; (P, .nishp s1; s2)) p (H; \n.; t; (P, s1) C (P, s2)) BACKAT (H; .; t; (P1, atp P2 s1; s2)) p (H; .; t; (P2,s1 (backat P1; s2)))(H; \n.; t; (P2, backatp P1; s)) p (H; .; t; (P1,s)) OUTPUT INPUT P ; H; e . v Place(r)= P.(P, t P )= v (H; \n.; t; (P, outputp e; s)) p (H; .; t \u00b7 o(v, P ); (P, s))(H; .; t; (P, inputp r; s)) p (H[r . v]; .; t \n\u00b7 i(v, P ); (P, s)) IF1 IF2 P ; H; e . vv =0 P ; H; e . vv =0 (H; .; t; (P, ifp e then s1 else s2; s3)) \np (H; .; t; (P, s1 s3))(H; .; t; (P, ifp e then s1 else s2; s3)) p (H; .; t; (P, s2 s3)) WHILE (H; .; \nt; (P, (whilep e do s1); s2)) p (H; .; t; (P, (if e then (s1 while e do s1; skip) else skip); s2)) p \n' Figure 3. Tree and statement semantics (H; .; t; T )(H ; .; t ' ; T ' ) -  CONST READ H(r) = v Place(r) \n= P P ; H; v . v P ; H; !r . v OP P ; H; e1 . v1 P ; H; e2 . v2 P ; H; e1 .e2 . v1 .v2 Figure 4. Expression \nsemantics P ; H; e . v Rule SKIP2 handles the instruction skip it is a no-op. Rule WRITE executes write \ninstruction r :=p e by evaluat\u00ading expression e to a value v and updating the heap to map location r \nto v. Note that location r must be stored at the place at which the activity is executing: Place(r)= \nP . Rule LET executes let instruction let x = e in s by eval\u00aduating expression e to value v, and substituting \nuses of variable x in s with v using capture-avoiding substitution s{v/x}. The rule uses the operation \n to stitch together two statements into a single statement. This operation is de\u00ad.ned recursively as \nfollows. (i; s1) s2 = i;(s1 s2) skip s2 = s2 Instruction async s1 creates a new activity to execute s1, \nand the current activity continues with the next statement. Thus, rule ASYNC executes the activity (P, \nasync s1; s2) by reducing it to the tree (P, s1) || (P, s2). Statement .nish s1; s2 executes s1, and \nwaits until all activities spawned by s1 have terminated before executing s2. Rule FINISH transforms \nactivity (P, .nish s1; s2) to the tree (P, s1)(P, s2). Statement at Ps1; s2 executes statement s1 at \nplace P , and then executes s2 at the original place. Rule AT thus ' transforms activity (P, at Ps1; \ns2) to an activity at place P : '' (P, s1 (backat P ; s2)). We insert the instruction backat P ' to let \nus know both that execution of s2 will be at place P , ' and that the movement of the activity to P is \nthe result of returning from a previous at instruction. Rule BACKAT for ' statement backat P simply changes \nthe place of the activity ' back to place P . Rule OUTPUT evaluates output instruction output e by evaluating \ne to value v, and appending event o(v, P ) to the program s trace, where P is the current place of the \nactiv\u00adity. Similarly, rule INPUT evaluates input instruction input r by inputting value v from P s communication \nchannel, up\u00addating the heap to map location r to v, and appending event i(v, P ) to the program s trace. \nThe value to input is deter\u00admined by input strategy ., and is equal to .(P, t P ), where P is the current \nplace of the activity, and t P is the program s trace so far restricted to events occurring at place \nP . Rules IF1 and IF2 handle the conditional instruction if e then s1 else s2 by reducing it to s1 if \ne evaluates to a non\u00adzero value, and reducing it to s2 otherwise. Rule WHILE handles a while e do s1 \ninstruction by unrolling it into a con\u00additional instruction.  2.5 Program execution A program is an \nactivity (P, s), that is, a statement s that is intended to start execution at place P . Program execution \ndepends on an input strategy . and a re.ner R. The initial con.guration of a program is (Hinit; .; R; \nE; (P, s)), where Hinit is a distinguished heap and E is the empty trace. For program (P, s), input strategy \n., and re.ner R, we write ((P, s), ., R) emits t to indicate that program execution can produce trace \nt. That ' is, there is some heap H ', re.ner R ' and tree T such that ' (Hinit; .; R; E; (P, s)) . * \n(H ; .; R ' ; t; T ' ) where .* is the re.exive transitive closure of the small-step relation .. 3. Security \nWe are interested in enforcing strong information security in concurrent programs. Towards that end, \nin this section, we de.ne a noninterference-based [12] de.nition of security for FSX10, and present a \ntype system that enforces security while allowing many useful and highly concurrent programs. 3.1 De.ning \nsecurity Intuitively, we want to ensure that a consumer of low\u00adsecurity information from a FSX10 program \ndoes not learn anything about high-security information. In our setting, consumers of low-security information \nare entities that can observe the communication channel of low-security places, and the high-security \ninformation that needs to be protected are the values input at high-security places. We assume that there \nis a set of security levels L with a partial order g that describes relative restrictiveness of the security \nlevels. We further assume that every place P is associated with a security level, denoted L(P ). Intuitively, \nplace P will be allowed to store and handle only data of security level L(P ) and lower, and to send \nvalues to, and ' invoke code on, only places P such that L(P ) gL(P ' ). For a given security level \u00a3 \n.L,a low-security place is any place P such that the level of the place is less than or equal to \u00a3, that \nis, L(P ) g \u00a3. All other places are high\u00adsecurity places, i.e., P is a high-security place if L(P ) g \n\u00a3. We de.ne a semantic security condition based on at\u00adtacker knowledge [2]. An attacker observes the \ncommuni\u00adcation channels of low-security places. The knowledge of an attacker is the set of input strategies \nthat are consistent with the attacker s observations: the smaller the set, the more ac\u00adcurate the attacker \ns knowledge. The semantic security con\u00addition will require that at all times, the attacker s knowledge \nincludes all possible input strategies for high-security places.  That is, all possible input strategies \nfor high-security places are consistent with the attacker s observations. For ease of presentation, we \nwill use a slightly weaker semantic secu\u00adrity condition, a progress-insensitive condition [3] that also \nallows the attacker to learn not only the input strategies for low security places, but also whether \nlow-security output is produced. Trace equivalence Given an attacker with security level \u00a3 .L (i.e., \nwho can observe communication channels of places P such that L(P ) g \u00a3), two executions of a program \nlook the same to the attacker if the trace of inputs and outputs at low-security places are the same \nin both executions. We de.ne this formally via \u00a3-equivalence of traces. De.nition 1 (\u00a3-equivalence of \ntraces). Let \u00a3 .L. Traces t0 and t1 are \u00a3-equivalent, written t0 ~c t1, if t0 c = t1 c, where E c = E \n(t c) \u00b7 a if L(Place(a)) g \u00a3 (t \u00b7 a) c = t c otherwise Attacker knowledge For a given execution of a \nprogram, starting from program con.guration (Hinit; .; R; E; (P, s)), that produces trace t, the knowledge \nof an attacker with security level \u00a3, written k((P, s), R, t, \u00a3), is the set of input strategies that \ncould have produced a trace that is equivalent to what the attacker observed. De.nition 2 (Attacker knowledge). \nFor any \u00a3 .L, program (P, s), trace t, and re.ner R, the attacker s knowledge is: k((P, s), R, t, \u00a3)= \n' {. |.t. ((P, s), ., R) emits t ' . t ~c t ' } We de.ne what information an attacker with security level \n\u00a3 is permitted to learn about input strategies by de.ning \u00a3-equivalence of input strategies. Intuitively, \nif two strategies are \u00a3-equivalent, then they provide the exact same inputs for all low-security places, \nand an attacker with security level \u00a3 should not be able to distinguish them. De.nition 3 (\u00a3-equivalence \nof input strategies). Let \u00a3 .L. Input strategies .0 and .1 are \u00a3-equivalent, written .0 ~c .1, if for \nall places P such that L(P ) g \u00a3, and for all traces t, we have .0(P, t P )= .1(P, t P ). Relation ~c \nis an equivalence relation, and we write [.]c for the equivalence class of . under the relation ~c. Given \na program con.guration (Hinit; .; R; E; (P, s)) that produces trace t, progress knowledge [3] is the \nset of input strategies that could have produced a trace that is \u00a3\u00adequivalent to t, and could produce \nat least one more ob\u00adservable event. We will use progress knowledge as a lower bound on the allowed knowledge \nof an attacker. That is, we will explicitly allow the attacker to learn whether a program will produce \nanother observable event. This means that the attacker may be permitted to learn the termination behavior \nof statements that depend on high-security information. De.nition 4 (Progress knowledge). For any \u00a3 .L, \nprogram (P, s), trace t, and re.ner R, progress knowledge is: k+((P, s), R, t, \u00a3)= ' {. |.t ' , a. ((P, \ns), ., R) emits (t \u00b7 a) . t ~c t ' .L(Place(a)) g \u00a3} Our security condition requires that, for all attackers, \nand all executions, for each event the attacker can observe, the attacker learns no more than the input \nstrategy for low\u00adsecurity places, and the fact that another event was produced. De.nition 5 (Security). \nProgram (P, s) is secure if for all \u00a3 .L, traces t \u00b7 a, re.ners R, and input strategies . such that ((P, \ns), ., R) emits (t \u00b7 a) we have k((P, s), R, t \u00b7 a, \u00a3) . [.]c n k+((P, s), R, t, \u00a3). Recall that the \nattacker s knowledge is set of input strate\u00adgies that are consistent with the attacker s observations: \na smaller set means more precise knowledge. Security requires that there are lower bounds to the precision \nof the attacker s knowledge. That is, there is information that the attacker is not permitted to learn. \nThus, security requires that attacker s knowledge is a superset of the knowledge it is permitted to learn. \nAccording to this de.nition of security, Program 2 from the Introduction is insecure (assuming that memory \nlocation hi is initialized from an input from place High), since there exists a re.ner and a strategy \nthat will produce a trace that allows an observer of low-security outputs to learn some\u00adthing about the \nhigh-security input strategy. Indeed, our def\u00adinition of security rules out internal timing channels \n[48], in which the order of low-security events (here, input, out\u00adput, and accesses to memory locations) \ndepends upon high\u00adsecurity information. Program 3 does not exhibit an internal timing channel, and is \nsecure. This de.nition of security is progress insensitive [3], as it permits the attacker to learn that \nprogram execution makes progress, and produces another observable output. This def\u00adinition can be strengthened \nin a straightforward way to a progress sensitive security condition. While the type sys\u00adtem of Section \n3.2 enforces progress insensitive security, it can be modi.ed using standard techniques (to conservatively \nreason about termination of loops) to enforce progress sen\u00adsitive security [28]. We refrain from doing \nso to simplify the presentation of the type system.  3.2 Enforcing security We enforce security using \na security type system. The type system ensures that each place P stores and handles only ' data input \nfrom places P such that L(P ' ) gL(P ). How\u00adever, as noted in the Introduction, it is possible for the \nscheduling of activities at place P to be in.uenced by in\u00ad ' put from a place P such that L(P ' ) gL(P \n). Our type system tracks and controls information .ow through this covert channel through program point \ncontexts. A program point context . is a function from program points to security levels such that .(p) \nis an upper bound on the level of information that may in.uence the scheduling of program point p. More \nprecisely, it is an upper bound on information that may affect the presence or absence of activities \nthat may run concurrently with p at the same place. Each program point is statically associated with \na place, and we write Place(p) for the place at which program point p will execute. Intuitively, since \nprogram point p is executed at place Place(p), and Place(p) handles data at security level L(Place(p)), \nwe would expect that .(p) is at least as restrictive as L(Place(p)). Indeed, the type system ensures \nfor all p that L(Place(p)) g .(p). It is often the case that L(Place(p)) is also an upper bound of .(p). \nThat is, the scheduling of p does not de\u00adpend on any high-security information. However, if p may happen \nimmediately after a computation at a high-security place .nishes (as with the output pos instruction \nin Pro\u00adgram 2), or in parallel with another program point at the same place whose scheduling depends \non high-security in\u00adformation, then it is possible that .(p) gL(Place(p)). In that case, in order to \nensure that the scheduling decision at place Place(p) does not leak high-security information, we require \nobservational determinism [49] at Place(p) during the scheduling of p. That is, for each memory location \nstored at Place(p), there are no data races on that location, and the order of input and output at Place(p) \nis determined. Finally, variable context G maps program variables to the place at which the variable \nwas created. The type system uses the variable context to ensure that if variable x was ' declared at \nplace P , then x is used only at places P such that L(P ) gL(P ' ). May-happen-in-parallel analysis The \ntype system relies on the results of a may-happen-in-parallel analysis, such as the one presented by \nLee and Palsberg for Feather\u00adweight X10 [22]. The async-.nish parallelism of X10 is amenable to a precise \nmay-happen-in-parallel analysis. We write MHPP(p) for the set of program points that may hap\u00adpen in parallel \nwith program point p at the same place (i.e., at Place(p)). Typing expressions Judgment p; G; . f e indicates \nthat expression e, occurring at program point p is well typed un\u00adder variable context G and program point \ncontext .. Infer\u00adence rules for this judgment are given in Figure 5. Constants ' noWrite(r, p) = .p . \nMHPP(p). instruction at ' p does not write to r noReadWrite(r, p) = noWrite(r, p) . ' .p . MHPP(p). instruction \nat ' p does not read r. '' noIO(p) = .p . MHPP(p). instruction at p does not perform input or output. \nFigure 6. Predicate de.nitions v are always well typed, and the use of variable x is well typed if the \nlevel of the place at which x is de.ned (L(G(x))) is less than or equal to the level of the place at \nwhich x is used (L(Place(p))). Expression e1 . e2 is well typed if both e1 and e2 are well typed. There \nare two different rules for reading memory loca\u00adtion r. The .rst rule, rule T-READNONDET, handles the \ncase where the scheduling of the expression s execution at place Place(p) is in.uenced by information \nat most at level L(Place(p)). In that case, there are no restrictions on when the read may occur: it \nmay occur concurrently with activities at the same place that write to the location since the resolu\u00adtion \nof the data race will not be a covert information channel. (The existence of a data race may, however, \nbe undesirable in terms of program functionality.) The second rule, rule T-READDET, applies when the \nscheduling of the expression may be in.uenced by informa\u00adtion that is not allowed to .ow to level L(Place(p)). \nIn that case, the read is required to be observationally deterministic: predicate noWrite(r, p) must \nhold, implying that the read of memory location r at program point p must not execute con\u00adcurrently with \nany statement that may write to r. Predicate noWrite(r, p) is de.ned in Figure 6. Typing statements Judgment \nG; . f s : \u00a3 indicates that statement s is well typed in variable context G and program point context \n., and that security level \u00a3 is an upper bound on the security level of information that may in.uence \nthe scheduling of the last program point of s. Inference rules for the judgment are given in Figure 7. \np Every inference rule for a statement sincludes the ' premise .p . MHPA(p). .(p ' ) g .(p). Intuitively, \nthe set MHPA(p) is the set of program points that may in.u\u00adence the presence or absence of activities \nrunning in parallel with p at the same place. Assuming that Place(p)= P , MHPA(p) contains the program \npoints of backat P instruc\u00adtions that may happen in parallel with p, and the set of pro\u00ad 1 gram points \nimmediately following an atpP ' s ' instruction, ' where Place(p ' )= P and p may happen in parallel \nwith p. The set MHPA(p) is a subset of the program points that may happen in parallel with p, and can \neasily be computed from the results of a may-happen-in-parallel analysis. Given this de.nition, the premise \nabove requires that .(p), the up\u00ad  T-OP T-READDET T-CONST T-VAR p; G; . f e1 T-READNONDET .(p) g L(Place(p)) \nL(G(x)) g L(Place(p)) p; G; . f e2 .(p) g L(Place(p)) noWrite(r, p) p; G; . f v p; G; . f x p; G; . f \ne1 .e2 p; G; . f!r p; G; . f!r Figure 5. Expression typing judgment p; G; . f e T-LET T-SKIP2 p; G; \n. f e G[x . Place(p)]; . f s1 : f1 T-SKIP1 G; . f s : f .(p) g .(p1) G;. f s2 : f2 .(p) g .(p1) f1 g \n.(p2) '' '' .p . MHPA(p). .(p ' ) g .(p) .p . MHPA(p). .(p ' ) g .(p) .p . MHPA(p). .(p ) g .(p) p1 p1 \np2 G; . f skipp : .(p) G;. f skipp; s: f G; . f letp x = e in s1 ; s2 : f2 T-ASYNC T-FINISH G; . f s1 \n: f1 G; . f s2 : f2 .(p) g .(p1) G;. f s1 : f1 G; . f s2 : f2 .(p) g .(p1) L(Place(p2)) g .(p2) ''' ''' \n.(p) g .(p2) .p . MHPA(p). .(p ) g .(p) .p . MHPP(p). .(p ) g .(p2) .p . MHPA(p). .(p ) g .(p) pp1 p2 \np1 p2 G; . f asyncs; s: f2 G; . f .nishp s; s: f2 12 12 T-AT T-BACKAT G; . f s1 : f1 G; . f s2 : f2 .(p) \ngL(P ) G;. f s : f .(p) g .(p1) '' '' L(P ) g .(p1) f1 g .(p2) .p . MHPA(p). .(p ) g .(p) .p . MHPA(p). \n.(p ) g .(p) G; . f atp Psp1 ; sp2 12 : f2 T-WRITENONDET .(p) gL(Place(p)) G; . f s : fp; G; . f e .(p) \ng .(p1) .p ' . MHPA(p). .(p ' ) g .(p) G; . f r :=p e; sp1 : f T-OUTPUTNONDET .(p) gL(Place(p)) G; . \nf s : fp; G; . f e .(p) g .(p1) .p ' . MHPA(p). .(p ' ) g .(p) G; . f outputp e; sp1 : f T-INPUTNONDET \n.(p) gL(Place(p)) G;. f s : f .(p) g .(p1) .p ' . MHPA(p). .(p ' ) g .(p) G; . f backatp P ; sp1 : f \nT-WRITEDET .(p) gL(Place(p)) noReadWrite(r, p) G; . f s : fp; G; . f e .(p) g .(p1) .p ' . MHPA(p). .(p \n' ) g .(p) G; . f r :=p e; sp1 : f T-OUTPUTDET ' ) g .(p) .(p) g L(Place(p)) noIO(p) G; . f s : f p; \nG; . f e .(p) g .(p1) ' .p . MHPA(p). .(p G; . f outputp e; sp1 : f T-INPUTDET .(p) gL(Place(p)) noReadWrite(r, \np) noIO(p) G; . f s : f .(p) g .(p1) .p ' . MHPA(p). .(p ' ) g .(p) p1 p1 G; . f inputp r; s: f G; . \nf inputp r; s: f T-IF T-WHILE G; . f s1 : f1 G; . f s2 : f2 G; . f s3 : f3 G; . f s1 : f1 G; . f s2 : \nf2 p1; G; . f e p; G; . f e .(p) g .(p1) .(p) g .(p2) .(p) g .(p1) f1 g .(p) f1 g .(p2) '' '' f1 g .(p3) \nf2 g .(p3) .p . MHPA(p). .(p ) g .(p) .p . MHPA(p). .(p ) g .(p) p1 p2 p3 p1 p2 G; . f ifp e then selse \ns; s: f3 G; . f whilep e do s; s: f2 1 23 12 Figure 7. Statement typing judgment G; . f s : \u00a3 per bound \non the scheduling of s, is at least as restrictive as the scheduling of any program point that may in.uence \nthe presence or absence of activities running in parallel with p at the same place. Also, almost all \ninference rules for statements ensure that ' if program point p executes after p (for example, because \nthey are in sequence), then .(p ' ) g .(p). The intuition here is that if information at level .(p ' \n) may in.uence the scheduling of p ', and p follows in sequence after p ', then information at level \n.(p ' ) may in.uence the scheduling of p1 p2 p3 p. For example, the typing rule for ifp e then selse \ns; s 1 23 requires that .(p) g .(p1) and .(p) g .(p2), since the execution of s1 and s2 will occur only \nafter the evaluation of the conditional guard. Similarly, since the execution of s3 will follow the execution \nof either s1 or s2, the rule requires that \u00a31 g .(p3) and \u00a32 g .(p3), where \u00a31 and \u00a32 are upper bounds \nof the scheduling of the last program points of s1 and s2 respectively. We discuss only the inference \nrules that have premises in addition to those common to all rules. p1 p2 Statement letp x = e in s; sdeclares \na variable x, and 12 allows x to be used in the scope of statement s1. Rule T-LET thus allows s1 to be \ntyped with a variable context that maps variable x to the place at which it was de.ned: Place(p). p1 \np2 Statement .nishp s; sexecutes statement s1, and 12 waits until all activities spawned by s1 have .nished \nbefore executing s2. Rule T-FINISH requires that .(p) g .(p1) (since p1 is executed after p) but notably \ndoes not require either .(p) g .(p2) or \u00a31 g .(p2), despite the fact that p2 is executed after p and \np1. The intuition is that because the scheduling behavior at place P = Place(p) depends only on the current \nactivities at P , by the time that p2 is sched\u00aduled, program points p and p1 (and all activities spawned \nby s1) have .nished execution, and do not in.uence the scheduling of p2. In Program 3 in the Introduction, \nthis rea\u00adsoning is what permits us to conclude that the scheduling of output B and output C do not \ndepend on high-security computation. 1 2 3 at Low {async {// Activity 1 4 mediumComputation(); output \n nonpos ; 5 6 7 }.nish {// Activity 2 8 9 at High {if (hi > 0) longComputation(); 10 11 12 }}// Activity \n3 13 output pos ; 14 } Program 4. However, it may be possible that scheduling of activi\u00adties spawned \nby s1 indirectly in.uences the scheduling of p2. Consider Program 4, which contains a .nish s1; s2 state\u00adment \nwhere s2 = output pos , and s1 invokes compu\u00adtation at high-security place High. There is an additional \nactivity that executes concurrently with the .nish statement: mediumComputation(); output nonpos . The \nscheduling of this activity relative to s2 will depend on the high-security computation. Indeed, this \nprogram is equivalent to Pro\u00adgram 2, and both are insecure. Thus, typing rule T-FINISH requires that \n.(p2) is at least as restrictive as .(p ' ) for any ' program point p that may execute in parallel with \np at the same place. This ensures that insecure Program 4, and others like it, are rejected by the type \nsystem. p2 Statement atp Psp1 ; sexecutes s1 at place P , and then 12 executes s2 back at place Place(p). \nRule T-AT requires that the upper bound on the scheduling of the at instruction is permitted to .ow to \nthe level of place P (.(p) gL(P )). Thus the type system restricts the creation of an activity at place \nP to reveal only information that is allowed to .ow to p1 level L(P ). Also, because statement sis executing \nat place 1 P , information at level L(P ) will in.uence the scheduling p2 of p1: L(P ) g .(p1). Finally, \nbecause statement sis 2 executed only after s1, the scheduling of p2 depends on when the last statement \nof s1 is scheduled: \u00a31 g .(p2) where \u00a31 is an upper bound on the scheduling of the last program point \nof s1. Similar to the typing rules for reading memory loca\u00adtions, there are two rules for writing memory \nlocations: T-WRITENONDET and T-WRITEDET. As with the rules for reading memory, the .rst is for the case \nwhere the schedul\u00ading of the write is not in.uenced by high-security informa\u00adtion, and there are thus \nno restrictions on when the write may occur. Rule T-WRITEDET applies when the schedul\u00ading of the write \nmay be in.uenced by high-security informa\u00adtion, and requires observational determinism via the predi\u00adcate \nnoReadWrite(r, p), de.ned in Figure 6, which ensures that no reads or writes to the same memory location \nmay happen in parallel. The rules for input and output are similar to the rules for reading and writing \nmemory locations: if the scheduling of input or output may depend on high-security information, the input \nor output must be observationally deterministic, which is achieved for output by requiring that there \nis no other input or output at that place that may happen in parallel (see predicate noIO(p), de.ned \nin Figure 6). Since an input instruction writes to a memory location r, rule T-INPUTDET requires both \nthat no input or output may happen at the place in parallel, and that no reads or writes to r may happen \nin parallel. Typing trees Judgment G; . f T means that tree T is well typed in variable context G and \nprogram point context .. Inference rules for the judgment are given in Figure 8. The rules require that \nall activities in the tree are well typed.  T-ACTIVITY T-PARA G; . f s : f L(P ) g .(p) G; . f (P, sp) \nG; . f T1 G; . f T2 G; . f T1IT2 T-JOIN G; . f T G; . f(P, sp) T-DONE .p ' . MHPP(p). .(p ' ) g .(p) \nG; . f TC (P, sp) G; . f . Figure 8. Tree typing judgment G; . f T Also, the rule for tree T (P, sp), \nT-JOIN, requires that .(p) is at least as restrictive as .(p ' ) for any program point p ' that may execute \nin parallel with p at place P , for similar reasons to the typing rule for .nish statements, T-FINISH. \nSoundness of type system The type system enforces secu\u00adrity. That is, if a program is well typed, then \nit is secure. Theorem 1. If (P, s) is a program such that G; . f(P, s)for some variable context G and \nprogram point context ., then (P, s) is secure according to De.nition 5. We present a brief sketch of \nthe proof here. A more de\u00adtailed proof appears in the companion technical report [29]. Outline of Proof. \nThe proof uses a technique similar to that of Terauchi [45]. We .rst introduce the concept of an erased \ncon.guration. A con.guration m erases to a con.guration ' m at security level \u00a3 if m ', when executed, \nperforms no computation at places with security level higher than \u00a3 but ' m and m otherwise agree. Erased \nprograms are de.ned similarly, with erased con.gurations containing erased pro\u00adgrams. Suppose we have \na well-typed program (P, s), some se\u00adcurity level \u00a3, and two \u00a3-equivalent input strategies .1 and .2. \nFirst, we erase the program (P, s) to program (P, s ' )at level \u00a3 and consider side-by-side executions \nof these two programs with the same input strategy. Suppose the original program with input strategy \n.1 produces trace t1. Then the erased program with input strategy .1 can produce a trace t ' 1 that is \n\u00a3-equivalent. Similarly, if the original program with input strategy .2 produces trace t2, then the erased \npro\u00adgram with input strategy .2 can produce a trace t ' that is 2 \u00a3-equivalent. Second, we consider the \nexecutions of the erased program with strategy .1 and strategy .2 that produced traces t ' 1 ' and t \nrespectively. Since the erased program performs no 2 computation at high-security places, either t ' \nis a pre.x of 1 t ' , or vice versa. Combining this with the previous result, 2 if ((P, s),.1,R) emits \nt1 and ((P, s),.2,R) emits t2, then either the low-security events of t1 are a pre.x of the low\u00adsecurity \nevents of t2, or vice versa. Knowledge-based security can then be shown as follows. Let . be an input \nstrategy, R a re.ner, and \u00a3 a security level. Suppose that ((P, s), ., R) emits t \u00b7 a. Let . ' be another \ninput strategy such that . ~c . ' and ((P, s),. ' ,R) emits t ' \u00b7 a ' such that t ~c t ' and L(Place(a \n' )) g \u00a3. The above result implies that either a = a ' or L(Place(a)) g \u00a3. In either case, t \u00b7 a ~c t \n' \u00b7 a ', and so the inclusion required by De.nition 5 is proven. 4. SX10 prototype implementation We \nhave extended the principles of the security analysis of Section 3 to handle many of the language features \nof X10. The resulting language, called SX10, is a subset of X10. We have implemented a prototype compiler \nfor SX10 by extend\u00ading the open-source X10 compiler (version 2.1.2), which is implemented using the Polyglot \nextensible compiler frame\u00adwork [30], and is included in the X10 distribution. Our exten\u00adsion comprises \napproximately 8,500 lines of non-comment non-blank lines of Java code. We do not modify the X10 run-time \nsystem: SX10 pro\u00adgrams run using the standard X10 run-time system. We thus do not provide a performance \ncomparison of SX10 with X10 or with other secure concurrent systems. Such a performance comparison is \nnot directly useful, as it would evaluate the ef\u00ad.ciency of the X10 runtime, not our enforcement technique, \nwhich is entirely static. In this section, we describe how we extend the analysis to handle additional \nlanguage features of X10 and present some example SX10 programs. May-happen-in-parallel analysis We have \nimplemented the may-happen-in-parallel (MHP) analysis of Lee and Pals\u00adberg [22] for SX10, which is a \nstraightforward exercise. However, for additional precision in our security analysis, we implemented \na place-sensitive MHP analysis. In our cal\u00adculus FSX10, for every program point it is possible to stat\u00adically \ndetermine which place the program point would ex\u00adecute on. In SX10, however, code for a given class may \nbe executed at more than one place, since objects of the same class may reside at different places. Thus, \nif an activity at place P is executing code from program point p, our place\u00adsensitive MHP analysis conservatively \napproximates the set MHP(p, P ) such that if (p ' ,P ' ) . MHP(p, P ) then an ac\u00ad ' tivity at place P \nmay concurrently be executing code from ' program point p . Places We assume that all places are statically \nknown, and that a security level is associated with each place. A con.guration .le speci.es the set of \nsecurity levels L, the ordering g over the levels, and maps places to levels. Our prototype implementation \ndoes not currently support .rst\u00adclass places. If places are computed dynamically, then the choice of \nthe place at which to execute a computation could be a covert channel, and would thus require the security \nanalysis to track and control information .ow through this channel. In this respect, .rst-class places \nare similar to .rst\u00adclass security levels (e.g., [13, 50]), and the security analysis could be extended \nto handle .rst-class places using similar techniques, such as dependent type systems.  As in FSX10, \nwe restrict at statements to allow place P ' to invoke code on place P only if L(P ) gL(P ' ). In addition \nto at statements, X10 has at expressions: at Pe evaluates expression e at place P . We allow at ' expressions, \nbut only from place P to place P where L(P )= L(P ' ). If the security level of the places differed, \nthen either data would be sent from a high-security place to a low-security place, or a high-security \nplace would in\u00advoke code on a low-security place. Either way, a potentially dangerous information .ow \noccurs, and must be ruled out. Concurrency mechanisms The X10 async and .nish state\u00adments are restricted \nsimilarly to their counterparts in FSX10. X10 provides additional synchronization mechanisms, in\u00adcluding \nclocks (a form of synchronization barrier), futures, and atomic blocks. Our prototype implementation \ndoes not currently support these additional mechanisms. However, they can be incorporated in a straightforward \nmanner by ex\u00adtending the MHP analysis to reason about them. Once the MHP analysis supports these constructs, \nour security anal\u00adysis can be extended to add constraints similar to those for async and .nish statements. \nObjects Fields of objects can be mutable locations, and we enforce restrictions similar to those of other \nmemory loca\u00adtions: we require determinism on accesses when scheduling may be in.uenced by high-security \ninformation. If an ob\u00adject is sent in a message from one place to another, the X10 runtime will create \na copy of the object, thus ensuring that if an activity at a place attempts to update a .eld of an ob\u00adject, \nthe memory location is local to the place. When objects are copied to send to another place, we impose \nrestrictions similar to the use of variables: a copy of an object created at ' place P may be sent to \nplace P only if L(P ) gL(P ' ). Control-.ow constructs X10 has much richer control\u00ad.ow constructs than \nthe calculus FSX10. We support local\u00adcontrol-.ow constructs, such as for loops and switch state\u00adments. \nWe support dynamic dispatch of methods, using class information to conservatively over-approximate the \nset of possible callees at a method call site. We do not currently support exceptions, although they \ncan be incorporated by extending the MHP analysis. Note that exceptions interact in an interesting way \nwith the concurrency mechanisms, due to X10 s rooted exception model [41]. Input and output The security \nanalysis for SX10 restricts input and output from the system to enforce strong informa\u00adtion security \nguarantees. We currently require methods that perform communication with the external environment to \nbe explicitly annotated as such, but it is straightforward to infer where such methods are used, for \nexample, detecting method calls to objects of classes x10.io.Printer, x10.io.Reader, etc. (Fields x10.io.Console.OUT \nand x10.io.Console.IN are in\u00adstances of Printer and Reader, respectively.) Arrays Our implementation \nsupports local arrays, since these are simply objects of the class x10.array.Array[T], and elements of \nthe array are stored at a single place. We do not currently support distributed arrays, which store elements \nover multiple places. Adding support for distributed arrays would require support for .rst-class places. \nX10 runtime scheduler The X10 runtime scheduler uses a work-stealing algorithm to schedule activities \nwithin a place. This requires that threads maintain a double-ended queue of pending activities, and idle \nthreads may steal activities from busy threads. Because the state of the queues may be in.uenced by which \nactivities were or were not running at the place in the past, such work-stealing algorithms cannot be \nrepresented in our scheduling model in FSX10, which requires that scheduling functions do not depend \non the history of computation at a place. The type system relies on this requirement only in the rule \nfor a .nish s1; s2 statement, which allows the program point context of the .rst program point of s2 \nto be lower than program point context of the last program point of s1 when there are no other activities \nrunning at the place. However, in that situation there are no other activities to schedule other than \ns1 and activities spawned by s1: activity s2 will not start execution until it is the only activity at \nthe place. In that case, the state of the work queues for threads will be independent of the history \nof the computation up to that point. Thus, we expect the security guarantee to transfer to the actual \nscheduler used by the X10 runtime. It is future work to extend the model of schedulers in FSX10 to include \nsuch work-stealing schedulers. Improvements to Analysis In implementing the SX10 compiler, we add an \noptimization that allows the type sys\u00adtem to be more permissive without compromising security. ' If statement \nat Ps is executed at place P and no statement ' at P is dependent on the termination of s, then the schedul\u00ad \n' ing of activities at P is independent of when s terminates, and we do not need to increase the program \npoint context of statements that may happen in parallel. This corresponds to having a more precise de.nition \nof the set MHPA(p). 4.1 Example programs Distributed Machine Learning Consider a music recom\u00admendation \nservice, such as Pandora. Here, a large database of music information exists: the Music Genome Project. \nThe service would like to process this data perhaps run\u00adning machine-learning algorithms on it and then \ncombine it with data from individual users to produce recommenda\u00adtions for users. We assume the database \nof music informa\u00adtion is public, but the personal data from users is secret, and should not in.uence \nthe results observed by other users. We assume that the processing of the public data can be performed \nin parallel. We will process this data at a number of places pub0 through pubn, all with the same low \nsecurity level L. Results from the processing will be sent back to the coordinator place, and collated \ninto a value called results. We use the results of the processing of public data to compute recommendations \nfor each user. We assume that each user Ui has its own place Pi, with a unique security level Hi such \nthat L g Hi.  A sketch of the code for this system appears in Program 5. Public data is supplied in \nthe array pubData and we assume that place Pi already holds the data for user Ui. 1 2 3 4 at coordinator \n{.nish {async at pub0 {val res = processPublicData(pubData(0)); 5 6 7 at coordinator { addResult(res); \n}} ... 8 9 async at pubn {val res = processPublicData(pubData(n)); 10 11 12 13 } } at coordinator { addResult(res); \n} 14 15 async { at P0 { processPrivateData(results); } } ... 16 17 } async { at Pn { processPrivateData(results); \n} } Program 5. A distributed machine learning system Note that no additional synchronization is required \nto make this program secure, and the secure program is in fact allowed to be highly concurrent. The translation \nof this pro\u00adgram from X10 to SX10 does, however, require signi.cant code duplication due to the lack \nof support for distributed arrays and .rst-class places. Natural X10 programming style would use a loop \nover places to execute a block of code at each place, rather than duplicate the code as we do here. Online \nShopping Following Tsai et al. [47], we consider a server running a shopping website. We assume that \nthe server is concerned with keeping credit card data secure. Our example program models a multithreaded \nserver accepting input from two web forms. On the .rst form, a user enters the item number they wish \nto purchase. This form is submitted along with the user s unique customer ID, which persists through \nthe user s session. When this form is processed, the user s order is both saved on the server and output \nto a log for inventory purposes. The user is then presented with the next form, which requests his or \nher credit card number. This form is submitted with the same customer ID, and the credit card number \nis sent to an external service for processing. This example contains two security levels. The customer \nID and order are considered low-security, and the log is con\u00adsidered low-security output. The customer \ns credit card num\u00adber is high-security, and so the action of exporting it should occur at a high place. \nWe would like to ensure that no data from either the second form or the credit card processing service \ncan leak to the log. The code for handling one cus\u00adtomer s purchase is shown in Program 6. Simpson s \nRule Our .nal example program demonstrates that in programs, or sections of programs, in which all data \nis at the same security level, our analysis requires very few changes to the code for compilation. Thus, \nwhen a program operates on homogenous data, our security analysis does not signi.cantly impact usability. \nThe code for this example was taken from the Simpson s Rule example available on the X10 website1. The \noriginal program consists of approximately 200 non-blank non-comment lines of X10 code. Converting this \nprogram to SX10 required modifying seven lines of code, most of them trivially, and adding ten. The changes \nwere as follows: Five statements producing console output were annotated as required by SX10.  The \noriginal program uses all available places. Since SX10 requires static places, Place.MAX PLACES, which \nin X10 is set to the number of places, was replaced with a new (arbitrary) constant, set to four for \nthe purposes of this example. Identi.ers representing these four places were declared.  The code to \nstart computation at each place was dupli\u00adcated, since SX10 does not support loops over places. This \nrequired .ve additional lines of code.  Note that neither the number of lines modi.ed nor the num\u00adber \nadded necessarily scales with the size of the code. Most required modi.cations were to input or output \nstatements, and the number of lines of code added was proportional to the number of places used, not \nthe size of the program. Discussion of Example Programs The example programs demonstrate that it is possible \nto write realistic, highly con\u00adcurrent programs in SX10. Note that the .rst two examples contain a high \ndegree of nondeterminism. The order in which blocks of data are processed in Program 5 and the order \nin which entries are written to the log and credit card service in Program 6 are nondeterministic. This \nis secure because the resolution of this nondeterminism can in no way reveal high\u00adsecurity information. \nAs will be discussed in Section 5, some previous security-type systems for noninterference in con\u00adcurrent \nprograms would rule out this nondeterminism and require additional synchronization and overhead. The \nthird example demonstrates that our analysis does not signi.cantly prohibit the compilation and execution \nof programs that operate on a single security level. The biggest restriction in SX10 is the lack of .rst-class \nplaces. As we gain more experience writing SX10 programs, we will identify and address further challenges \nto practical and secure concurrent programming. 5. Related work This work seeks to provide strong language-based \ninforma\u00adtion security guarantees for concurrent programs. We discuss 1 http://x10-lang.org/  1 async \n{ 2 at lowform { 3 val custID = Int.parse(Console.IN.readLine().trim()); 4 // Input item number (low \nsecurity) 5 items(custID) = Int.parse(Console.IN.readLine().trim()); 6 at log Console.OUT.println(custID \n+ \\t + items(custID)); 7 at highform { 8 // Input credit card number (high security) 9 val card = Int.parse(Console.IN.readLine().trim()); \n 10 at cc Console.OUT.println(card + \\t + costs(items(custID))); 11 } 12 } 13 } Program 6. An online \nshopping cart related work, focusing on recent work that controls informa\u00adtion .ow in concurrent settings. \nObservational determinism Our security analysis ensures that if the scheduling of input, output, or memory \naccesses may leak sensitive information, then the order of such in\u00adstructions must be deterministic. \nThis approach is inspired by Zdancewic and Myers [49], who propose (following McLean [27] and Roscoe \n[33]) that there should be no non\u00addeterminism (including thread scheduling) observable by a low-security \nobserver. They present a semantic security con\u00addition that, for each observable memory location, requires \ndeterminism of the sequence of updates to that location. Huisman et al. [19] point out that this semantic \nsecurity con\u00addition may reveal more information than intended, and pro\u00adpose that the sequence of updates \nto all observable memory locations should be deterministic. Terauchi [45] presents a type system that \nenforces such a semantic security condition in a shared-memory setting using fractional capabilities. \nMantel et al. [26] present semantic conditions that al\u00adlow composition of concurrent programs. The semantic \ncon\u00additions use assume-guarantee reasoning to ensure that the composed program is free of data races, \nand thus is observa\u00adtionally deterministic. Requiring observational determinism throughout a pro\u00adgram \nis, however, overly restrictive. O Neill et al. [31] note that low-observable nondeterminism is acceptable \nso long as its resolution depends only on low-observable information. We thus allow nondeterminism in \nthe scheduling of activities at a place, provided that the resolution of the nondetermin\u00adism cannot leak \nsensitive information. Our model assumes that scheduling of activities at a place depends only on the \nactivities at that place, and our security analysis exploits this assumption to allow non-determinism \nwhere possible. Recent work on deterministic concurrency (e.g., [7, 46]) highlights functional bene.ts \nof determinism, and also al\u00adlows some nondeterminism when it is safe to do so [8]. Scheduler independence \nSabelfeld and Sands [38, 40] ar\u00adgue that the de.nition of security in multi-threaded programs should \nbe scheduler independent, since the scheduler is typi\u00adcally outside of the language speci.cation, and \nviolations of scheduler assumptions may lead to vulnerabilities. By con\u00adtrast, Boudol and Castellani \n[9] present a type system for schedulers and threads, and show that well-typed schedulers and threads \nsatisfy a de.nition of security [4]. Barthe et al. [5] have developed a framework for security of multi-threaded \nprograms that allows programs to be writ\u00adten without knowledge of the scheduler, i.e., in a scheduler\u00adindependent \nmanner. Mechanisms to interact with the sched\u00aduler and secure timing channels are introduced during com\u00adpilation, \nand enable a security-aware scheduler to enforce strong information security guarantees. Mantel and Sabelfeld \n[24] show a scheduler-independent security property in a multi-threaded while language. Russo and Sabelfeld \n[35] suggest a model in which threads may increase and decrease their security levels and permit\u00adted \nscheduling decisions depend on the security levels of threads. Mantel and Sudbrock [25] prove a security \nproperty for programs consisting of threads with assigned security levels when these are run under any \nscheduler in a class of robust schedulers. Robust schedulers, such as round-robin schedulers, have the \nproperty that the probability that a par\u00adticular low thread will be selected to run from among all low \nthreads remains the same if high threads are removed. Our assumptions about scheduling in the X10 runtime \nim\u00adply that schedulers for places are robust, in that scheduling of activities at a place cannot depend \nupon the existence or non-existence of activities at higher-security places. We do not provide scheduler \nindependence. Our type\u00adsystem and security proof assume that scheduling at a place depends only on the \nactivities currently executing at a place. While this assumption enables greater concurrency while preserving \nsecurity, it perhaps violates an abstraction bound\u00adary, as it makes assumptions about the behavior of \nthe X10 runtime that are not necessarily intended as part of the run\u00adtime s speci.cation.  Dynamic enforcement \nof concurrent information security Tsai et al. [47] extend work of Li and Zdancewic [23] and Russo and \nSabelfeld [34] to encode information-.ow con\u00adtrol in Haskell with support for concurrency and side-effects. \nHowever, their mechanism relies on co-operative (i.e., non\u00adpreemptive) scheduling, which may not be suitable \nfor mod\u00adern operating systems. Stefan et al. [44] present a dynamic information-.ow con\u00adtrol system that \neliminates termination and internal timing channels, and mitigates external timing channels, without \nre\u00adlying on co-operative scheduling. Implemented as a Haskell library, their technique requires that \nthe security level of a thread A that waits on a forked thread B must be at least as restrictive as the \ninformation that in.uences the control .ow of thread B. A similar restriction is true of our static mech\u00adanism: \nthe security level of a program point p that occurs ' after execution of program point p is at least \nas restrictive as information that in.uences the scheduling of p '. However, our static analysis allows \nus to lower the security level of p in a particular situation: for a .nish s1; s2 statement, the pro\u00adgram \npoint context of the .rst program point of s2 can be lower than program point context of the last program \npoint of s1 if there are no other activities running at the place. The dynamic nature of the system of \nStefan et al. allow them to be more precise than our static analysis in certain situations, highlighting \nthe incomparability of static and dynamic .ow\u00adsensitive security [36]. Le Guernic [21] uses a hybrid \nexecution monitor (which combines static and dynamic analyses) to enforce a strong security condition. \nThe enforcement mechanism (similar to the type system of Smith and Volpano [43]) is restrictive: while \nloops cannot have high-security guards, and while loops are not permitted in branches of if commands \nwith high-security guards. These restrictions are severe enough to rule out many useful programs. Process \ncalculi Focardi et al. [11] establish a link be\u00adtween language-based security for imperative programs, \nand process-algebraic frameworks of security properties. How\u00adever, they consider only sequential imperative \nprograms, and do not explore concurrency. Honda et al. [18] present a security-type system for the p-calculus \n(further devel\u00adoped by Honda and Yoshida [16, 17]) to address internal timing and progress channels. \nIn their type system, chan\u00adnels are assigned security levels, and may be given linear types. Linear channels \nmust statically have a single send and receive, which enables precise reasoning about syn\u00adchronization \nbetween processes. Non-linear channels may have non-deterministic behavior, and processes cannot send \nlow-security outputs after receiving high-security input on a non-linear channel, as the resolution of \nthe non-determinism may be a covert channel. Pottier [32] presents a simpler type system (without linear \nchannel types, and with a simpler proof) that also prevents low-security outputs after receiving high-security \ninput. Kobayashi [20] presents a type system for p-calculus that allows low-security output after high-security \nsynchroniza\u00adtion for a variety of synchronization mechanisms. It extends the idea of linear channels \nby using types to describe the channel usage, which permits precise reasoning about the information .ow \nresulting from synchronization. Security-type systems Other work concerned with in\u00adformation security \nin concurrent systems have also used security-type systems to enforce strong semantic security conditions \n(e.g., [5, 9, 37, 40, 42, 43, 45, 48, 49]). Some of these previous security-type systems are overly restric\u00adtive \non synchronization between threads, either disallowing low-security output after synchronization with \nhigh-security threads or activities, or disallowing nondeterminism even when resolution of the nondeterminism \nis not in.uenced by high-security information. The key difference in this work is that we integrate information-security \nguarantees with modern concurrency abstractions (i.e., X10 places). In doing so, we reason about information \nat coarser granularity than previous work, which simpli.es reasoning about information .ow (and thus, \nwe believe, leads to increased practicality). Our type system does not track information .ow on a per-location \nbasis, but rather focuses on tracking how interaction with high-security places affects the scheduling \nof program points at a place. 6. Conclusion We have extended the X10 concurrent programming lan\u00adguage \nwith coarse-grained information-.ow control. The re\u00adsulting language, SX10, provides information security \nfor concurrent programs. Each place is associated with a secu\u00adrity level, and may only handle data that \nis appropriate for the security level. We believe this language provides a bet\u00adter intuition for information \n.ow than previous methods for controlling information .ow, and will allow programmers to write secure \nprograms more effectively. The security analysis bene.ts from X10 s abstractions for concurrency: potentially \ndangerous information .ows correspond to interactions between places, which are rela\u00adtively easy to detect, \nsince communication between places is by message passing. Interaction between places may re\u00adsult in the \nscheduling of activities at a place being in.u\u00adenced by high-security information. Through a may-happen\u00adin-parallel \nanalysis for X10 [22], our security analysis will determine when this situation may arise, and requires \nobser\u00advational determinism [49] to hold, which prevents activity scheduling from being a covert information \nchannel. In the absence of interaction between places with different secu\u00adrity levels, our security mechanism \nplaces no restrictions on the concurrent program. While some restrictions on concur\u00adrency necessarily \nremain, this allows a large class of useful programs to be written without burdensome synchronization \nbetween threads for the purposes of security.  This work highlights the opportunity for synergy between \nmechanisms for concurrency and mechanisms for informa\u00adtion security: both rely on reasoning about dependencies \nwithin a program. We believe it is a promising step towards languages and tools for building secure concurrent \nsystems. Acknowledgments We thanks Greg Morrisett, Eddie Kohler, and the anonymous reviewers for their \nhelpful comments. This research is sup\u00adported by the National Science Foundation under Grant No. 1054172. \nReferences [1] M. Abadi, A. Banerjee, N. Heintze, and J. G. Riecke. A core calculus of dependency. In \nConference Record of the Twenty-Sixth Annual ACM Symposium on Principles of Programming Languages, pages \n147 160, New York, NY, USA, 1999. ACM Press. [2] A. Askarov and A. Sabelfeld. Gradual release: Unifying \nde\u00adclassi.cation, encryption and key release policies. In Proceed\u00adings of the IEEE Symposium on Security \nand Privacy, pages 207 221. IEEE Computer Society, 2007. [3] A. Askarov, S. Hunt, A. Sabelfeld, and D. \nSands. Termination\u00adinsensitive noninterference leaks more than just a bit. In Proceedings of the 13th \nEuropean Symposium on Research in Computer Security, Oct. 2008. [4] G. Barthe and L. P. Nieto. Formally \nverifying information .ow type systems for concurrent and thread systems. In Proceedings of the 2004 \nACM workshop on Formal methods in security engineering, pages 13 22, New York, NY, USA, 2004. ACM. [5] \nG. Barthe, T. Rezk, A. Russo, and A. Sabelfeld. Security of multithreaded programs by compilation. ACM \nTransactions on Information and System Security, 13(3):21:1 21:32, July 2010. [6] R. L. Bocchino, V. \nS. Adve, S. V. Adve, and M. Snir. Parallel programming must be deterministic by default. In Proceed\u00adings \nof the First USENIX Workshop on Hot Topics in Paral\u00adlelism, 2009. [7] R. L. Bocchino, Jr., V. S. Adve, \nD. Dig, S. V. Adve, S. Heumann, R. Komuravelli, J. Overbey, P. Simmons, H. Sung, and M. Vakilian. A type \nand effect system for deter\u00administic parallel Java. In Proceedings of the 24th ACM SIG-PLAN Conference \non Object Oriented Programming Systems Languages and Applications, pages 97 116, New York, NY, USA, 2009. \nACM. [8] R. L. Bocchino, Jr., S. Heumann, N. Honarmand, S. V. Adve, V. S. Adve, A. Welc, and T. Shpeisman. \nSafe nondetermin\u00adism in a deterministic-by-default parallel language. In Pro\u00adceedings of the 38th Annual \nACM SIGPLAN-SIGACT Sympo\u00adsium on Principles of Programming Languages, pages 535 548, New York, NY, USA, \n2011. ACM. [9] G. Boudol and I. Castellani. Non-interference for concurrent programs and thread systems. \nTheoretical Computer Science, 281(1):109 130, June 2002. [10] P. Charles, C. Grothoff, V. Saraswat, C. \nDonawa, A. Kielstra, K. Ebcioglu, C. von Praun, and V. Sarkar. X10: an object\u00adoriented approach to non-uniform \ncluster computing. In Pro\u00adceedings of the 20th Annual ACM SIGPLAN Conference on Object-oriented Programming, \nSystems, Languages, and Ap\u00adplications, pages 519 538, New York, NY, USA, 2005. ACM. [11] R. Focardi, \nS. Rossi, and A. Sabelfeld. Bridging language\u00adbased and process calculi security. In Foundations of Software \nScience and Computation Structure, volume 3441 of Lecture Notes in Computer Science, pages 299 315, Edinburgh, \nUK, Apr. 2005. Springer-Verlag. [12] J. A. Goguen and J. Meseguer. Security policies and secu\u00adrity models. \nIn Proceedings of the IEEE Symposium on Secu\u00adrity and Privacy, pages 11 20. IEEE Computer Society, Apr. \n1982. [13] R. Grabowski and L. Beringer. Noninterference with dynamic security domains and policies. \nIn 13th Asian Computing Science Conference, Focusing on Information Security and Privacy, 2009. [14] \nD. Grove, O. Tardieu, D. Cunningham, B. Herta, I. Peshansky, and V. Saraswat. A performance model for \nx10 applications. In Proceedings of The First X10 Workshop, 2011. [15] Y. Guo, R. Barik, R. Raman, and \nV. Sarkar. Work-.rst and help-.rst scheduling policies for async-.nish task parallelism. In Proceedings \nof the 2009 IEEE International Symposium on Parallel &#38; Distributed Processing, pages 1 12, Washington, \nDC, USA, 2009. IEEE Computer Society. [16] K. Honda and N. Yoshida. A uniform type structure for secure \ninformation .ow. In Conference Record of the Twenty-Ninth Annual ACM Symposium on Principles of Programming \nLanguages, pages 81 92, New York, NY, USA, Jan. 2002. ACM Press. [17] K. Honda and N. Yoshida. Noninterference \nthrough .ow analysis. Journal of Functional Programming, 15(2):293 349, Mar. 2005. [18] K. Honda, V. \nVasconcelos, and N. Yoshida. Secure informa\u00adtion .ow as typed process behaviour. In Proceedings of the \nNinth European Symposium on Programming, volume 1782 of Lecture Notes in Computer Science, pages 180 \n199. Springer, 2000. [19] M. Huisman, P. Worah, and K. Sunesen. A temporal logic characterisation of \nobservational determinism. In Proceed\u00adings of the 19th IEEE Workshop on Computer Security Foun\u00addations, \n2006. [20] N. Kobayashi. Type-based information .ow analysis for the pi-calculus. Acta Informatica, 42(4-5):291 \n347, 2005. [21] G. Le Guernic. Automaton-based Con.dentiality Monitoring of Concurrent Programs. In Proceedings \nof the 20th IEEE Computer Security Foundations Symposium, pages 218 232, 2007. [22] J. K. Lee and J. \nPalsberg. Featherweight X10: a core calculus for async-.nish parallelism. In Proceedings of the 15th \nACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming, pages 25 36, New York, \nNY, USA, January 2010. ACM.  [23] P. Li and S. Zdancewic. Encoding information .ow in Haskell. In Proceedings \nof the 19th IEEE Workshop on Computer Security Foundations, pages 16 27, Washington, DC, USA, 2006. IEEE \nComputer Society. [24] H. Mantel and A. Sabelfeld. A generic approach to the secu\u00adrity of multi-threaded \nprograms. In Proceedings of the 14th IEEE Computer Security Foundations Workshop, page 126, Washington, \nDC, USA, 2001. IEEE Computer Society. [25] H. Mantel and H. Sudbrock. Flexible scheduler-independent \nsecurity. In Proceedings of the 15th European Conference on Research in Computer Security, pages 116 \n133, Berlin, Heidelberg, 2010. Springer-Verlag. [26] H. Mantel, D. Sands, and H. Sudbrock. Assumptions \nand guarantees for compositional noninterference. In Proceedings of the 24th IEEE Computer Security Foundations \nSymposium (CSF), pages 218 232. IEEE Computer Society, 2011. [27] J. McLean. Proving noninterference \nand functional correct\u00adness using traces. Journal of Computer Security, 1(1):37 58, 1992. [28] S. Moore, \nA. Askarov, and S. Chong. Precise enforcement of progress-sensitive security. In Proceedings of the 19th \nACM Conference on Computer and Communications Security, New York, NY, USA, 2012. ACM Press. [29] S. Muller \nand S. Chong. Towards a practical secure concurrent language. Technical Report TR-05-12, Harvard University, \n2012. [30] N. Nystrom, M. R. Clarkson, and A. C. Myers. Polyglot: An extensible compiler framework for \njava. In In 12th Interna\u00adtional Conference on Compiler Construction, pages 138 152. Springer-Verlag, \n2003. [31] K. R. O Neill, M. R. Clarkson, and S. Chong. Information\u00ad.ow security for interactive programs. \nIn Proceedings of the 19th IEEE Computer Security Foundations Workshop, pages 190 201. IEEE Computer \nSociety, June 2006. [32] F. Pottier. A simple view of type-secure information .ow in the p-calculus. \nIn Proceedings of the 15th IEEE Computer Security Foundations Workshop, pages 320 330, June 2002. [33] \nA. W. Roscoe. CSP and determinism in security modelling. In Proceedings of the 1995 IEEE Symposium on \nSecurity and Privacy, pages 114 127, Washington, DC, USA, 1995. IEEE Computer Society. [34] A. Russo \nand A. Sabelfeld. Security for multithreaded pro\u00adgrams under cooperative scheduling. In Proceedings of \nAn\u00addrei Ershov International Conference on Perspectives of Sys\u00adtem Informatics, volume 4378 of Lecture \nNotes in Computer Science, pages 474 480. Springer-Verlag, 2006. [35] A. Russo and A. Sabelfeld. Securing \ninteraction between threads and the scheduler. In Proceedings of the 19th IEEE Computer Security Foundations \nWorkshop, pages 177 189, 2006. [36] A. Russo and A. Sabelfeld. Dynamic vs. static .ow-sensitive security \nanalysis. In Proceedings of the IEEE Computer Security Foundations Symposium, 2010. [37] A. Sabelfeld. \nThe impact of synchronisation on secure infor\u00admation .ow in concurrent programs. In Proceedings of Andrei \nErshov 4th International Conference on Perspectives of Sys\u00adtem Informatics, volume 2244 of Lecture Notes \nin Computer Science, pages 225 239. Springer-Verlag, 2002. [38] A. Sabelfeld. Con.dentiality for multithreaded \nprograms via bisimulation. In Proceedings of the Andrei Ershov Interna\u00adtional Conference on Perspectives \nof System Informatics, vol\u00adume 2890 of Lecture Notes in Computer Science, pages 260 273. Springer-Verlag, \n2003. [39] A. Sabelfeld and A. C. Myers. Language-based information\u00ad.ow security. IEEE Journal on Selected \nAreas in Communi\u00adcations, 21(1):5 19, Jan. 2003. [40] A. Sabelfeld and D. Sands. Probabilistic noninterference \nfor multi-threaded programs. In Proceedings of the 13th IEEE Computer Security Foundations Workshop, \npages 200 214. IEEE Computer Society, July 2000. [41] V. Saraswat, B. Bloom, I. Peshansky, O. Tardieu, \nand D. Grove. X10 Language Speci.cation: Version 2.1.2, Feb. 2011. Available at http://x10.sourceforge.net/ \n\\-documentation/\\-languagespec/\\-x10-212.pdf. [42] G. Smith. A new type system for secure information \n.ow. In Proceedings of the Proceedings of the 14th IEEE Computer Security Foundations Workshop, pages \n115 125. IEEE Com\u00adputer Society, June 2001. [43] G. Smith and D. Volpano. Secure information .ow in a \nmulti-threaded imperative language. In Conference Record of the Twenty-Fifth Annual ACM Symposium on \nPrinciples of Programming Languages, pages 355 364, New York, NY, USA, Jan. 1998. ACM Press. [44] D. \nStefan, A. Russo, P. Buiras, A. Levy, J. C. Mitchell, and D. Mazi` eres. Addressing covert termination \nand timing chan\u00adnels in concurrent information .ow systems. In Proceed\u00adings of the 17th ACM SIGPLAN International \nConference on Functional Programming, New York, NY, USA, June 2012. ACM Press. [45] T. Terauchi. A type \nsystem for observational determinism. In Proceedings of the 21st IEEE Computer Security Foundations Symposium, \npages 287 300, June 2008. [46] T. Terauchi and A. Aiken. A capability calculus for concur\u00adrency and determinism. \nACM Transactions on Programming Languages and Systems, 30(5):27:1 27:30, Sept. 2008. [47] T. Tsai, A. \nRusso, and J. Hughes. A library for secure multi\u00adthreaded information .ow in haskell. In Proceedings \nof the 20th IEEE Computer Security Foundations Symposium, pages 187 202, Washington, DC, USA, 2007. IEEE \nComputer So\u00adciety. [48] D. Volpano and G. Smith. Probabilistic noninterference in a concurrent language. \nIn Proceedings of the 11th IEEE Com\u00adputer Security Foundations Workshop, pages 34 45, Washing\u00adton, DC, \nUSA, 1998. IEEE Computer Society. [49] S. Zdancewic and A. C. Myers. Observational determinism for concurrent \nprogram security. In Proceedings of the 16th IEEE Computer Security Foundations Workshop, pages 29 43, \nPaci.c Grove, California, June 2003. IEEE Computer Society. [50] L. Zheng and A. C. Myers. Dynamic security \nlabels and noninterference. In Formal Aspects in Security and Trust, Toulouse, France, Aug. 2004.  \n \n\t\t\t", "proc_id": "2384616", "abstract": "<p>We demonstrate that a practical concurrent language can be extended in a natural way with information security mechanisms that provably enforce strong information security guarantees. We extend the X10 concurrent programming language with coarse-grained information-flow control. Central to X10 concurrency abstractions is the notion of a place: a container for data and computation. We associate a security level with each place, and restrict each place to store only data appropriate for that security level. When places interact only with other places at the same security level, then our security mechanisms impose no restrictions. When places of differing security levels interact, our information security analysis prevents potentially dangerous information flows, including information flow through covert scheduling channels. The X10 concurrency mechanisms simplify reasoning about information flow in concurrent programs. We present a static analysis that enforces a noninterference-based extensional information security condition in a calculus that captures the key aspects of X10's place abstraction and async-finish parallelism. We extend this security analysis to support many of X10's language features, and have implemented a prototype compiler for the resulting language.</p>", "authors": [{"name": "Stefan Muller", "author_profile_id": "81549021756", "affiliation": "Carnegie Mellon University, Pittsburgh, PA, USA", "person_id": "P3856036", "email_address": "smuller@cs.cmu.edu", "orcid_id": ""}, {"name": "Stephen Chong", "author_profile_id": "81548379156", "affiliation": "Harvard University, Cambridge, MA, USA", "person_id": "P3856037", "email_address": "chong@seas.harvard.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384621", "year": "2012", "article_id": "2384621", "conference": "OOPSLA", "title": "Towards a practical secure concurrent language", "url": "http://dl.acm.org/citation.cfm?id=2384621"}