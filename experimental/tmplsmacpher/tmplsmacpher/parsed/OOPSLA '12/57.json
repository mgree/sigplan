{"article_publication_date": "10-19-2012", "fulltext": "\n Typestate-Based Semantic Code Search over Partial Programs Alon Mishne Sharon Shoham Eran Yahav * Technion \nTel Aviv Yaffo Academic College Technion amishne@cs.technion.ac.il sharon.shoham@gmail.com yahave@cs.technion.ac.il \n Abstract We present a novel code search approach for answering queries focused on API-usage with code \nshowing how the API should be used. To construct a search index, we develop new techniques for statically \nmining and consolidating temporal API speci.\u00adcations from code snippets. In contrast to existing semantic\u00adbased \ntechniques, our approach handles partial programs in the form of code snippets. Handling snippets allows \nus to consume code from various sources such as parts of open source projects, educational resources \n(e.g. tutorials), and expert code sites. To handle code snippets, our approach (i) extracts a possibly \npartial temporal speci.cation from each snippet using a relatively precise static analysis track\u00ading \na generalized notion of typestate, and (ii) consolidates the partial temporal speci.cations, combining \nconsistent partial information to yield consolidated temporal speci.\u00adcations, each of which captures \na full(er) usage scenario. To answer a search query, we de.ne a notion of relaxed inclusion matching \na query against temporal speci.cations and their corresponding code snippets. We have implemented our \napproach in a tool called PRIME and applied it to search for API usage of several challeng\u00ading APIs. \nPRIME was able to analyze and consolidate thou\u00adsands of snippets per tested API, and our results indicate \nthat the combination of a relatively precise analysis and consol\u00adidation allowed PRIME to answer challenging \nqueries effec\u00adtively. Categories and Subject Descriptors D.2.4 [Program Veri.ca\u00adtion]; D.2.1 [Requirements/Speci.cations]General \nTerms Algorithms, Veri.cation Keywords Speci.cation Mining, Static Analysis, Typestate, Code Search Engine, \nRanking Code Samples * Deloro Fellow Permission to make digital or hard copies of all or part of this \nwork for personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, USA. Copyright c &#38;#169; \n2012 ACM 978-1-4503-1561-6/12/10. . . $10.00 1. Introduction Programmers make extensive use of frameworks \nand li\u00adbraries. To perform standard tasks such as parsing an XML .le or communicating with a database, \nprogrammers use standard frameworks rather than writing code from scratch. Unfortunately, a typical framework \nAPI can involve hun\u00addreds of classes with dozens of methods each, and often requires speci.c sequences \nof operations that have to be in\u00advoked on speci.c objects in order to perform a single task (e.g., [6, \n27, 39 41]). Even experienced programmers might spend hours trying to understand how to use a seemingly \nsimple API [27]. To write code that uses a library correctly, one can rely on code examples from other \nprograms that use that library. The availability of textual code search services (e.g., Koders [22], \nGitHub search [15]) and expert sites (e.g., [34]) exposes the programmer to a vast number of API usage \nexamples in the form of code snippets arbitrary segments of code. Under\u00adstanding how to use an API by \nmanually browsing through such snippets, however, is an extremely challenging task: (i) A code snippet \noften covers only part of the desirable use case, and extracting a full scenario may require putting \nseveral different snippets together. (ii) A code snippet may invoke methods where the method body is \nnot available, and thus its effect is unknown. (iii) Code snippets using the API of interest may appear \nin different contexts, making it hard for a programmer to tease out the relevant details. (iv) While \nmost code snippets using the API are doing so correctly, some may be erroneous. As a result, manually \nbrowsing through the massive number of snippets, searching for the right ones , is time consuming and \nerror-prone making it hard for a human to bene.t from this vast amount of avail\u00adable information. Furthermore, \nthe same reasons also present a signi.cant challenge for automatic analysis techniques. Goal Our long \nterm goal is to develop a search-engine that can answer semantic code-search queries, dealing with how \nan API is used, in a way that consolidates, distills, and ranks matching code snippets. To construct \na search index for a particular API, we aim to use all available snippets we can .nd using textual code \nsearch engines, expert sites, and other sources. Therefore, in contrast to many existing approaches (e.g., \n[32, 44]), we do not assume that we have the full code of the projects in which we are searching, and \nour goal is to be able to handle a large number of code snippets obtained from various sources without \nrequiring the ability to build or run entire projects. This goal presents two major challenges: (i) analysis \nof snippets (partial programs) (ii) consolidation of the partial information obtained from individual \nsnippets.  The way to address these challenges depends on the level of semantic information used as \na basis for search. The se\u00admantic information maintained for each code snippet should be: rich enough \nto describe the usage scenarios demonstrated by the code, feasible to construct ef.ciently, and amenable \nto ef.cient comparison operations. In this paper, we focus on (potentially partial) temporal speci.cations \ncapturing se\u00adquences of API method invocations. Technically, we use a slightly generalized notion of \ntypestate properties (see Sec\u00adtion 4) that we believe to be a sweet spot in that regard. In contrast \nto existing approaches that only track sequences of method calls in terms of their resulting types (e.g., \n[27, 36]), we track generalized typestate properties, providing a more accurate description of API usage. \nThroughout the paper, we use the term potentially partial temporal speci.cation (PTS) to refer to the \nsemantic information extracted from a code snippet. Extracting temporal speci.cations from partial code \nOne of the main challenges we face is extracting temporal speci.cations from partial code that is most \nlikely non\u00adexecutable, and often cannot even be compiled using a standard compiler. By nature of their \nincompleteness, snip\u00adpets are virtually impossible to run, presenting a signi.cant obstacle to dynamic \nspeci.cation mining techniques (e.g., [4, 7, 14, 43]), and motivating the use of static analysis tech\u00adniques. \nEven when turning to static analysis, new challenges arise: While handling partial code snippets is no \nobstacle to static approaches that are syntactic in nature (such as textual search), it poses a signi.cant \nchallenge for approaches that require semantic analysis of the code (e.g.,[32, 44]), as im\u00adportant parts \nof the code such as type and method de.nitions may be missing. Combining partial temporal speci.cations \nA code snippet may be partial in two respects: (i) it may be covering only part of an API usage scenario, \n(ii) because the snippet may only contain part of the original program s code, it may in\u00advoke client \nmethods for which the method body is not avail\u00adable. As a result, obtaining a full temporal speci.cation \noften requires consolidation of information extracted from several code snippets. Consolidating PTSs \nrequires a representation that can capture the missing information in one PTS and use other PTSs to consistently \ncomplete it. Our Approach We present a novel code search engine capable of answering API-usage code search \nqueries with consolidated results showing how the API should be used. Index Representation We capture \ntemporal speci.cations which exhibit relations between different API classes. We extend the classical \nnotion of single-object typestate proper\u00adties [35] by adding a creation context that can span multiple \nobjects. This generalization naturally captures the common case of initialization sequences building \nan ensemble of ob\u00adjects to accomplish a task [27]. To handle partial examples, we allow temporal speci.\u00adcations \nto contain edges with unknown labels. Such edges represent an invocation of an unknown method, possibly \nhid\u00ading an arbitrary sequence of API calls. The unknown edges serve as markers that information at this \npart of the speci.\u00adcation is missing. Technically, a speci.cation is represented as a deterministic .nite-state \nautomaton (DFA). Every edge in the DFA is labeled by an unknown event or by a signature of a method in \nthe API (not necessarily all from the same API class). The DFA therefore de.nes the (partial) language \nof interactions with that API. Index Construction To obtain temporal speci.cations from snippets we need \nto: (i) accurately track (unbounded) se\u00adquences of API calls in each snippet and use them to derive (partial) \nspeci.cations. (ii) because the sequences from each snippet may be partial, consolidate them into larger \nspeci.\u00adcations that capture the full behavior of the API. Analyzing a Snippet We use a relatively precise \nstatic inter\u00adprocedural analysis tracking aliasing information to analyze a snippet and produce a PTS. \nWe use unknown edges in the PTS to represent missing information. For example, when the body of an invoked \nclient method is not present, we cap\u00adture this fact using an unknown edge in the PTS. However, when the \nbody of an invoked client method is present in the snippet, we perform inter-procedural analysis of the \ninvoked method. Consolidating Partial Temporal Speci.cations To obtain temporal speci.cations that capture \nthe full use cases of the API we need to consolidate and amalgamate the individual partial speci.cations. \nTowards that end, we develop a tech\u00adnique of unknown elimination that iteratively attempts to consolidate \nmatching PTSs such that unknown edges in a PTS are replaced with matching paths found in other PTSs. \nCode Search Given a search query in the form of a par\u00adtial program using unknowns (similar to SKETCH \n[33]), our search algorithm .nds consolidated temporal speci.cations, each of which covers the query, \nalong with their matching code snippets. This is done by mapping the given query into the speci.cation \nspace and using a notion of relaxed inclu\u00adsion to match its PTS with PTSs in the index. By keeping a \nmapping from each point in the speci.cation space back to its corresponding code snippet, we can report \ncode snip\u00adpets to the programmer. The ranking of the results is done by counting the number of similar \nsnippets. This measure can also give the programmer an indication of whether her use of the API agrees \nwith common usage patterns (and thus is likely correct) or not (and is thus often incorrect).  Related \nWork The problems of code search and code recommendation systems have seen increasing interest in recent \nyears, and many inspiring solutions have been de\u00adveloped targeting different aspects of these problems \n(e.g., [2, 17, 18, 31, 32, 36, 44]). The closest works to ours are [44] and [32], which target static \nmining of temporal API speci.cations. These works, as most previous work on semantic code search and \nstatic speci.cation mining, rely on the ability to compile entire projects for complete type information, \nwhich prevents them from exploiting many examples available on the internet. This is a critical difference, \nas the challenge of obtaining all the code required for successfully building and analyzing a large-scale \nproject remains a signi.cant barrier to semantic indexing of large code bases. Assuming that the full \ncode is available dodges the problem of consolidation which is a central challenge in our work. Other \nworks such as [36] and [27] can only answer queries about how to obtain one type from another via a sequence \nof method calls. The relatively shallow analysis employed by these can handle partial programs, but it \npro\u00adduces a large number of answers that lack the temporal in\u00adformation about how a component is to be \nused, making it hard for the programmer to pick the right sequence. An elaborate discussion of related \nwork appears in Sec\u00adtion 8. Main Contributions The contributions of this paper are: We present a novel \nsemantic code search algorithm ca\u00adpable of answering API-usage code search queries in the form of partial \nprograms. Queries are answered with con\u00adsolidated code showing how an API should be used.  To obtain \nsemantic information from code we develop new techniques for statically mining and consolidating temporal \nAPI speci.cations from code snippets. The mined speci.cations are generalized typestate proper\u00adties that \ncontain a creation context potentially spanning multiple objects, and may be partial, possibly containing \nunknown edges.  We consolidate partial temporal speci.cations by a novel alignment technique that eliminates \nunknowns in a par\u00adtial speci.cation using information from other (closely related) speci.cations. To \nour knowledge, we are the .rst to apply such consolidation techniques in the context of code search or \nspeci.cation mining.  We introduce a notion of relaxed inclusion and corre\u00adsponding techniques to match \nPTSs to a query and pro\u00adduce a consolidated collection of snippets that cover the desired usage scenario. \n We have implemented our approach in a tool called PRIME, and evaluated it on a number of challenging \nAPIs. We show that PRIME can be used to successfully answer expressive search queries.  1 FTPClient \nconnectTo(String server, String user,String pass) { 2 FTPClient ftp = new FTPClient(); 3 ftp.connect(server); \n4 if(ftp.getReplyCode() != 230) return null; 5 ftp.login(user, pass); 6 return ftp; 7 } 1 void disconnectFrom(FTPClient \n2 if (ftp.isConnected()) { 3 ftp.logout(); 4 ftp.disconnect(); 5 } 6 } 1 void storeFile(FTPClient ftp, \n ftp) { String username, 2 String password, String remotePath, InputStream input) { 3 ftp.login(username, \npassword); 4 ftp.storeFile(remotePath, input); 5 ftp.logout(); 6 } 1 void upload(String server, String \nuser, 2 String pass, String remotePath, InputStream input) { 3 FTPClient ftp = new FTPClient(); 4 ftp.connect(server); \n5 if(ftp.getReplyCode() == 230) { 6 MyFTPUtils.uploadFile(ftp, user, pass, remotePath, input); 7 ftp.disconnect(); \n8 } 9 } Figure 1: Code snippets using FTPClient. FTPClient ftp = new FTPClient(); ftp.connect(server); \nftp.?; ftp.storeFile(rem, in); ftp.?; ftp.disconnect(); Figure 2: A partial-code query written by a \nuser. 2. Overview 2.1 Motivating Example Given a task such as uploading a .le to an FTP server, and \na Java API such as the FTPClient class from the Apache Commons Net library capable of doing that, the \nquestion is, how do we use that API to perform the task? FTPClient exposes around a hundred methods \nand actually requires a speci.c method invocation sequence to successfully upload a .le, leaving us lost \nand forcing us to seek help. Manually searching for code examples online requires time and effort, and \n.nding the precise example that matches our needs may not be easy. Instead, we run PRIME, which allows \nus to search for relevant examples based on our partial knowledge of what the code should look like. \nPRIME .rst uses textual search to download thousands of code snippets using the FTPClient API, among \nthem partial snippets similar to those shown in Fig. 1. The obtained snippets are used for construction \nof a search index. Snippets are typically entire methods, or even entire classes, though PRIME can also \nhandle snippets that contain holes . PRIME then receives a query in the form of partial code, for instance \nas in Fig. 2 this query is typical  of a user who generally understands how to communicate with a \nserver, but is not aware of the .ne details of the API. In this example, no code snippet demonstrates \nthe full use case of an FTPClient all the way from connect to storeFile and eventually to disconnect. \nTherefore, when observing the individual code snippets and comparing them to the query, no match is found. \nThis problem re.ects the challenge in dealing with partial programs as the basis for search. To address \nthis challenge, PRIME applies consolidation techniques during index construction for combining PTSs extracted \nfrom individual snippets. Intuitively, each PTS can be thought of as a piece of a puzzle, and consolidation \ncan be understood as putting these pieces together to obtain the full picture. Technically, PRIME analyzes \neach snippet to produce an automaton as shown in Fig. 3 and consolidates the individual automata together \nto create two summaries of usage, as shown in Fig. 4. Generally, the state numbering in the .gures does \nnot affect the meaning of the speci.cation and is only used for presentation purposes. In these .gures, \nwe use the state numbering to show correspondence between the individual (partial) and the consolidated \nautomata. The query is now matched by one of the consolidated re\u00adsults. The relevant pieces of code, \ne.g. connectTo, storeFile and disconnectFrom from Fig. 1, are then returned, aligned together, giving \nus a simple yet effective visual guide for writing the code. In addition to consolidation of partial \nspeci.cations, PRIME assists the programmer in identifying common use cases by ranking the results based \non the number of snippets that correspond to each speci.cation. This is useful even when the query can \nbe matched by a PTS before consolida\u00adtion. In the simple example of this section, each code snippet corresponds \nto a simple sequence of method invocations. However, in practice, many of the obtained automata have \na more complex structure, for example if some method can be invoked repeatedly, or if two different methods \ncan follow the same method invocation.  2.2 Our Approach PRIME downloads thousands of code snippets \nautomatically using a textual code search engine. These code snippets (partial programs) are used to \nconstruct a search index for a set of APIs of interest, as de.ned by the user. When a query is given, \nPRIME evaluates it against the index. Index Representation PRIME extracts from each snippet a potentially \npartial temporal speci.cation that captures se\u00adquences of API method invocations. We use a deterministic \n.nite-state automaton (DFA) to represent a temporal speci\u00ad.cation. We refer to such a DFA as a history. \nThe histories generated for our example are depicted in Fig. 3. There are several points to observe here: \n(a) (b) (c) (d)   Figure 3: Partial Speci.cations obtained from (a) connectTo(), (b) disconnectFrom(), \n (c) storeFile() and (d) upload().  void listFiles(String server, String username, String password, \nString dir, int n) { FTPClient ftp = new FTPClient(); ftp.connect(server); ftp.login(username, password); \nFTPListParseEngine engine = ftp.initiateListParsing(dir); while (engine.hasNext()) { FTPFile[] files \n= engine.getNext(n); printFiles(files); } ftp.logout(); ftp.disconnect(); } Figure 6: Listing all the \n.les in a remote directory, n at a time. Partial method sequences In the absence of a clear entry point \nfor an example (e.g. if the snippet was an entire class), we consider each method as a possible entry \npoint. Thus, the API methods invoked on each object do not necessarily con\u00adtain its creation phase. Similarly, \na single snippet does not necessarily capture the full sequence of events in an object s lifetime. For \nexample, connectTo() by itself leaves an FTPClient object in an intermediate state, without properly \nlogging out and disconnecting, while disconnectFrom() does not show the pre.x of a common usage. In such \ncases, we use a special unknown event, denoted ?, to model an unknown sequence of events (e.g. Fig. 3(b)). \nThe unknown event records the fact that the partial speci.cation can agree with other speci.cations that \nmatch it up to unknowns. Our goal is for the missing sequence to be .lled-in by other ex\u00adamples. Unknown \nmethods The method upload() invokes the method MyFTPUtils.uploadFile() whose code is in\u00adaccessible and \nits de.ning class MyFTPUtils is unknown. Similarly to the treatment of partial method sequences, we use \nan unknown event to denote the invocation of an un\u00adknown method.  Figure 4: Consolidated speci.cations. \n Figure 5: Partial speci.cation extracted from a search query. Figure 7: Creation-context-enabled result \nfor the object of type FTPListParseEngine Method sequences across multiple types Some API usage scenarios \nspan multiple objects of different types. While the relation between objects can potentially be complex, \none common pattern is that of objects being created by API methods invoked on different objects. For \nexample, the code in Fig. 6 demonstrates how to list all the remote .les in an FTP server directory, \nn entries at a time, using an object of type FTPListParseEngine. Our histories exhibit the creation-relation \nbetween ob\u00adjects, adding the history of the creating object as the pre\u00ad.x of the history of the created \nobject. This allows us to see the entire .ow of API method invocations over multi\u00adple objects of related \ntypes required to create an API ob\u00adject and perform a certain task. For example, Fig. 7 shows a creation-context-enabled \nDFA recorded for the object of type FTPListParseEngine when analyzing the code of Fig. 6. The logout() \nand disconnect() methods that are invoked on the creating object of type FTPClient will only be part \nof the creating object s DFA. Note that techniques that mine single-object typestate speci.cations (e.g., \n[32]) can only capture speci.cations such as the small part highlighted in Fig. 7. Techniques that only \ntrack type conversions (e.g., [27, 36]) cannot track state changes such as the fact that FTPClient needs \nto be con\u00adnected and logged-in before creating an FTPListParseEngine, or like the state changes in the \nspeci.cation of Fig. 4i. Index Construction To tackle the challenges arising when considering arbitrary \ncode snippets, PRIME separates the construction of the search index into two phases: the analy\u00adsis phase \nand the consolidation phase. Analysis phase During the analysis phase, each code snippet is analyzed \nseparately to distill and gather relevant seman\u00adtic data. Some of the code snippets cannot be compiled, \nlet alone executed. PRIME therefore analyzes the down\u00adloaded code snippets using interprocedural static \nanalysis with points-to and aliasing information, and tracks the se\u00adquences of API method invocations \nobserved in them for each API object, in order to derive the PTSs. In particular, PRIME has a special \ntreatment for unknown types and meth\u00adods to allow us to work around them and extract the know\u00adable information, \nwhile clearly marking the unknowns. We emphasize that only non-API methods whose implementa\u00adtion is either \nmissing or unresolved are treated as unknown. In any other case, an interprocedural analysis takes place. \nIn order to capture creation-context, the analysis main\u00adtains a relation between objects at the point \nof creation, copying the pre.x of the creating object into the created ob\u00adject. Unbounded sequences and \nsets of allocated objects The analysis has to address two sources of unboundedness: un\u00adbounded number \nof allocated objects (e.g., objects of type FTPFile in Fig. 6), and an unbounded length of API method \ninvocation sequences (e.g., the while loop calling hasNext and getNext on an FTPListParseEngine in Fig. \n6). To address the former, we use a heap abstraction based on ac\u00adcess paths, similar to the ones used \nin [12]. To address the latter, we introduce a new abstraction representing se\u00adquences (with unknowns) \nin a bounded way using DFAs, as described in Section 4.2. The abstraction is responsible for transforming \nthe tracked sequences into PTSs. Consolidation phase The consolidation phase is responsible for making \nsense of the partial speci.cations obtained from individual code snippets, by completing their unknowns \nwhen possible and amalgamating them together. As our ex\u00adperiments indicate, this is a crucial ingredient \nin a successful search-engine. To our knowledge, we are the .rst to apply such consolidation techniques \nin the context of code search or speci.cation mining.  Unknown Elimination In many cases, unknowns in \none his\u00adtory can be resolved based on other histories. For example, the unknown event in Fig. 3a follows \na login() event. It can therefore be matched to the sequence storeFile(), logout(), ? from Fig. 3c, which \nalso follows a login() event. This matching based on shared context implies that the unknown event most \nlikely represents the above se\u00adquence and can therefore be replaced by it. Our approach generalizes the \nsame principle to perform unknown elimina\u00adtion in DFAs, where an unknown-edge can be replaced by a DFA. \nThe unknown-elimination process is iterated until no fur\u00adther eliminations can take place (special care \nis needed to en\u00adsure termination). Elimination of some unknown-transitions can enable elimination of \nothers. For example, the .rst unknown event in history Fig. 3d cannot be eliminated at .rst, since no \nother history contains a matching context of both a preceding getReplyCode() event and a following disconnect() \nevent. However, as a result of other elimina\u00adtions it is eventually eliminated. In this example, all \nhistories except for Fig. 3b are consolidated into Fig. 4i, which de\u00adscribes a correct usage of an FTPClient \nto store .les. We therefore managed to mine a correct spec for FTPClient even though no single snippet \ncontained the complete speci\u00ad.cation. Summarization Histories that are isomorphic or included in one \nanother are merged together. In this process, method in\u00advocations (edges) which appear at the same point \nin the his\u00adtory of more than one sample are assigned increased weights (exempli.ed by edges labeled \u00d73 \nin Fig. 4i). With a high enough number of samples, the edge weights allow us to identify the more likely \nfull sequences which are performed on objects of type FTPClient. Query Language We consider a straightforward \nquery lan\u00adguage which is nearly identical to Java, except that we allow a question mark character to \nfollow the dot operator. A call x.? is interpreted as an unknown sequence of API method invocations on \nthe object pointed by x (resembling the inter\u00adpretation of an unknown client method invocation to which \nx was passed as a parameter). If this call is a part of an as\u00adsignment y = x.?, then it is interpreted \nas an unknown ini\u00adtialization sequence of the object pointed by y, starting from the object pointed by \nx (and possibly referring to other ob\u00adjects of other types as well). Alternative query languages are \npossible as long as queries can be translated to partial speci\u00ad.cations in the form of DFAs with unknowns. \nQuery Evaluation To answer a query in the form of a partial program, PRIME .rst uses similar static analysis \ntechniques to extract a PTS from the query s partial code. For example, for the query given in Fig. 2, \nthe obtained partial speci.ca\u00adtion is depicted in Fig. 5. Matches to the query are found based on a novel \nnotion of relaxed inclusion, tailored to han\u00addle partial speci.cations with unknown edges. Relaxed Inclusion \nRelaxed inclusion resembles automata inclusion, except that unknown-edges of the included au\u00adtomaton \ncan be replaced by paths (or sub-automata) of the including automaton. This captures the intuition that \na match to the query should include it, but should also complete it in the sense of replacing its unknowns \nwith more complete se\u00adquences of events. In our example, Fig. 5 is included in Fig. 4i by the relaxed \nnotion even though it is not included in it by standard automata-inclusion and is therefore returned \nas a match to the query. Recall that while this example demonstrates the idea on simple sequences, we \nin fact handle the more general notion of an automaton. Search Results Before we present the user with \nresults, we distill the obtained matches (in the form of consolidated his\u00adtories) from parts that are \nirrelevant to the query and break them into linear sequences, for clarity. These sequences are ranked \nbased both on the number of speci.cations summa\u00adrized into the matching history, and on the likelihood \nof the particular sequence within its history (re.ected by the weights of the corresponding history edges). \nIn order to present the user with code snippets, we keep a mapping from speci.cations back to the snippets \nfrom which they were created. In particular, each edge in a (consoli\u00addated) speci.cation is mapped to \na set of relevant snippets. For example, the storeFile() edge of Fig. 4i is mapped to the storeFile snippet \nonly, while the login() edge is mapped to both connectTo and storeFile. The user can browse through the \nrelevant code snippets accordingly. The code snippets returned for the query in Fig. 2 appear in the \nthesis version of this work [28]. 3. Background We .rst de.ne what we mean by the terms API and client \nprogram. Library API: A library API is a collection of class names T1,...,Tn, where each class has an \nassociated set of method signatures corresponding to methods provided by the class. Client: We use the \nterm client program of an API to refer to a program that uses a given API by allocating objects of API \nclasses and invoking methods of the API classes. We assume that API methods only affect the internal \nstate of the library and do not change other components of the global state of the client program. Concrete \nSemantics We assume a standard imperative object\u00adoriented language, and de.ne a program state and evaluation \nof an expression in a program state in the standard manner. Restricting attention to reference types \n(the only types in Java that can receive method invocations), the semantic do\u00admains are de.ned in a standard \nway as follows:  2objects. Lq . q v. Val = objectsq .{null} .q . Env = VarId . Val pq . Heap = objectsq \n\u00d7 FieldId . Val States =2objects. stateq = (Lq,.q,pq). \u00d7 Env \u00d7 Heap where objectsq is an unbounded set \nof dynamically allocated objects, VarId is a set of local variable identi.ers, and FieldId is a set of \n.eld identi.ers. To simplify notation, we omit typing from the de.nition. In practice, objects are typed \nand all components admit correct typing. A program state keeps track of the set Lq of allocated objects, \nan environment .q mapping local variables to values, and a mapping pq from .elds of allocated objects \nto values. Partial Programs Our approach requires handling of par\u00adtial programs. To simplify presentation, \nwe assume that the code of each method we inspect is known in full, which means that all modi.cations \nof local state are known. An inspected method may invoke unknown methods, and refer to unknown types \nand .elds. Our implementation also han\u00addles the more general (but less common) case of a method in which \npart of the code is missing. We assume a standard semantics of partial programs up\u00addating a program state \n(Lq,.q,pq), where an invocation of an unknown method can allocate any number of fresh objects and can \nmodify its reachable objects arbitrarily (e.g. [8]). 4. From Snippets to Partial Speci.cations The .rst \nstep of the index construction phase of our approach is analyzing each code snippet individually to extract \na par\u00adtial temporal speci.cation. In this section we .rst de.ne an instrumented concrete se\u00admantics for \npartial programs that tracks histories for each tracked object, representing the way the API has been \nused. The notion of a history de.nes our choice of a formalism for index representation. Then, we describe \nan analysis respon\u00adsible for deriving histories from individual snippets in terms of an abstraction of \nthe instrumented concrete semantics. 4.1 Instrumented Semantics Tracking Partial Specs Events We refer \nto the invocation of an API method as an event. An event has a receiver object and a method signature. \nThe receiver is the object whose method is invoked. Since static API method calls have no receiver, we \ninstead treat those as an event for each of the method s arguments, where the receiver is the argument \nand the signature is that of the static method. Other than this exception, we ignore the arguments since \nthey lie beyond the focus of this paper. Representing Unknowns A partial program might invoke a client \n(non-API) method where the method body is not avail\u00adable. Since an unknown client method may perform \nan arbi\u00adtrary sequence of API operations on its arguments, an invo\u00adcation of such a method may hide an \narbitrary sequence of events. To model this behavior, we introduce special events, called unknown events. \nAn unknown event stands for any possible sequence of events (including the empty sequence). An unknown \nevent has a receiver and a signature, denoted T :?, where T is the type of its receiver. For each tracked \nobject passed as an argument to an unknown method, we generate an unknown event with that tracked object \nas a receiver. When T is clear from the context, it is omitted. We denote by U the set of all unknown \nevents, and by S? =S . U the set of events extended by the unknown events. This set de.nes the alphabet \nover which program histories are de.ned. Histories In our instrumented semantics, sequences of events \nthat have occurred on the tracked objects are recorded by concrete histories . Technically, we de.ne \nthe notion of a history as capturing a regular language of event sequences. DEFINITION 4.1. Given a set \nof events S?,a history h is a .nite automaton (S?, Q, init, d, F), where Q is a set of states, init is \nthe initial state, d : Q\u00d7 S? . 2Q is the transition relation, and F \u00d8 is a set of .nal states. We = de.ne \nthe traces represented by h, Tr(h), to be the language L(h). A concrete history hq is a special case \nof a history that encodes a single .nite trace of events, that is, where Tr(hq) consists of a single \n.nite trace of events. In Section 4.2 we will use the general notion of a history to describe a regular \nlanguage of event sequences. We refer to a history that possibly describes more than a single trace of \nevents as an abstract history. In this section, we use the histories of Fig. 3 as examples for concrete \nhistories. Despite the fact that these histories result from our analysis, in this special case they \nare just sequences and can be thus used as example for concrete histories. A history describes a partial \ntemporal speci.cation. In principle, a history may be associated with different levels of a state, such \nas: (i) Fully relational history: a single history may be associated with a global state and track the \nglobal sequence of events over all API objects. Because a global history maintains the order between \nall events, it may create arti.cial ordering between events of independent objects. (ii) Per-object history: \na history may be associated with a single object in the state. Such a per-object history does not capture \nany ordering between events on different objects, even when such relationship is important (cf. Fig. \n7 in Section 2). Our instrumented semantics offers a compromise, where it maintains a creation context \nfor an object as part of its his\u00adtory, allowing to observe the sequences of events observed on other \nobjects that lead to its creation. Creation-Context Histories We maintain a creation relation between \nobjects. When an object is allocated by a method of a tracked object, e.g. x = y.m(...), then we consider \nthe sequence of events of the receiver object o1 (pointed by y) up until the assignment into o2 (pointed \nby x), called the creation context of o2, as part of the events invoked on o2. Note that o1 might also \nhave a creation context, which will therefore also be a part of o2 s creation context. This approach \nallows us to record the concrete history of each object separately, while maintaining the creation context. \nWe refer to such histories as per-object histories with creation context. The creation context replaces \nthe init event, which typically exists upon allocation of objects.  EXAMPLE 4.2. Consider our FTPClient \nexample. In Fig. 6, an invocation of initiateListParsing on an FTPclient object (pointed by ftp) returns \nan FTPListParseEngine object (pointed by engine). Up until the creation time of the FTPListParseEngine \nobject, the following sequence of events were invoked on the FTPclient object: <FTPClient:<init>(), FTPClient:connect(String), \nFTPClient:login(String, String), FTPClient:initiateListParsing(String)> This sequence of events, which \nis the concrete history of ftp, is therefore considered the creation context of the FTPListParseEngine \nobject, pointed by engine, and it initializes its concrete history. Later, when engine invokes hasNext(), \nits history is extended by the corresponding event, resulting in: <FTPClient:<init>(), FTPClient:connect(String), \nFTPClient:login(String, String), FTPClient:initiateListParsing(String), FTPListParseEngine:hasNext()> \n Note that the pre.x of this history consists of events that refer to a different receiver than the suf.x. \nIn this example, a single history combines two receiver types, but in more complex examples, more complex \ncreation contexts, involv\u00ading more receivers, will arise. Instrumented Semantic: State We denote the \nset of all con\u00adcrete histories by Hq. We augment every concrete state (Lq,.q,pq) with an additional mapping \nhisq : Lq -Hq that maps an allocated object of a tracked type to its con\u00adcrete history. A state of the \ninstrumented concrete semantics is a tuple (Lq,.q,pq, hisq). Instrumented Semantics: Transformers Dealing \nwith par\u00adtial programs adds nondeterminism to the semantics due to the arbitrary effect of unknown client \nmethods and API methods on the heap. Thus, each statement generates a set of possible successor states \nfor a concrete state. We focus on the hisq component of the states. The hisq component of the concrete \nstate tracks the histories for all tracked objects. It is updated as a result of allocation and calls \nto methods of a tracked type in a natural way. Here, we only show the treatment of creation context and \ninvocations of unknown methods: Creation Context: If an object is created by a statement y = x.m(...) \nwhere both x and y are of tracked types, the concrete history of the object pointed by y is initialized \nto the concrete history of the object pointed by x, re.ecting '' its creation context: hisq(.q(y)) = \nhisq(.q(x)). The return value of x.m(...) can also be an existing object, in which case no history update \nis needed (this is taken into account by the nondeterministic semantics updating (Lq,.q,pq)).  Unknown \nClient Methods: For an invocation foo(y1,...,yn), where foo is an unknown client method: Let Reach de\u00adnote \nthe set of arguments of foo, objects reachable from them, and fresh objects allocated in foo, restricted \nto tracked types. Note that the interpretation of Reach is nondeterministic due to the nondeterministic \nsemantics updating (Lq,.q,pq). The concrete history of each object o . Reach is extended by an unknown \nevent T :?, where T is the type of o. If the concrete history of o already ends with an unknown event, \nit remains unchanged. Since the semantics considers each method as a potential entry point, we assume \nimplicitly unknown pre.xes/suf.xes for the generated histories, unless an init event is observed. init \ngrounds a pre.x because we know that no event can precede it. Histories that start with any event other \nthan init are considered non-initialized, and an unknown-transition is prepended to them. Similarly, \nan unknown-transition is appended to all histories, re.ecting the unknown suf.x. EXAMPLE 4.3. The histories \ndepicted by Fig. 3b and Fig. 3c are non-initialized. Indeed, these histories result from track\u00ading FTPClient \nobjects when considering the methods disconnectFrom and storeFile (see Fig. 1) as entry points, thus \nnot exhibiting the allocation and initialization of the corresponding objects. Fig. 3d depicts the history \nextracted from the upload code snippet for the FTPClient object pointed by ftp. This history contains \nan ?-transition, resulting from the unknown client method MyFTPUtils.uploadFile(ftp,...).  4.2 Abstractions \nfor Partial Programs The instrumented concrete semantics uses an unbounded de\u00adscription of the program \nstate, resulting from a potentially unbounded number of objects and potentially unbounded histories. \nWe now describe an abstract semantics that con\u00adservatively represents the instrumented semantics using \na bounded program state, and provides a basis for our analysis. Speci.cally, the analysis propagates \na sound approximation of program state which is based on a heap abstraction and a history abstraction. \nThe heap abstraction is in fact quite subtle, but applies standard concepts from modular analy\u00adses (e.g., \n[8]). In this paper, we focus on the abstraction of histories. History Abstractions A concrete history \nsimply encodes a sequence of events. A conservative abstraction for it can be de.ned in many ways, depending \non the information we wish to preserve.  In practice, automata that characterize API speci.cations are \noften simple, and further admit simple characterizations of their states (e.g. their incoming or outgoing \nsequences). This motivates using quotient structures of automata to rea\u00adson about abstract histories. \nQuotient Structure Given an equivalence relation R on the states of a history automaton, the quotient \nstructure of the au\u00adtomaton overapproximates the history by collapsing together equivalent states: Let \n[q] denote the equivalence class of q. Then QuoR(h) = (S?, {[q] | q . Q}, [init],d ' , {[q] | q . '' \n' F}), where d ' ([q],s)= {[q ' ] |.q . [q]: q . d(q '' ,s)}. k-Past Abstraction with Unknowns API usage \nsequences often have the property that a certain sequence of events is always followed by the same behaviors. \nThis motivates an equivalence relation in which states are considered equiva\u00adlent if they have a common \nincoming sequence of length k (e.g., [32]). In order to differentiate between unknown transitions in \ndifferent contexts, we increase the length of the sequence to be considered for equivalence when the \nlast event is un\u00adknown. DEFINITION 4.4. The k-past abstraction with unknowns is a quotient-based abstraction \nw.r.t. the k-past relation with unknowns R[k] de.ned as: (q1,q2) . R[k] if one of the following holds: \n q1,q2 have a common incoming sequence of length k whose last event =?, or  q1,q2 have a common incoming \nsequence of length k +1 whose last event is ?, or  q1,q2 have a common maximal incoming sequence of \nlength <k, where an incoming sequence of length l is maximal if it cannot be extended to an incoming \nsequence of length >l.  In particular, the initial states of all histories generated by the k-past abstraction \nhave no incoming transitions and are therefore equivalent by R[k]. In addition, the produced histories \nare deterministic. When k =1, all the incoming transitions of a state q are labeled by the same event \na, and all transitions labeled by a point to q. States of the automaton with an incoming ?\u00adtransition \nare characterized by their incoming sequences of length 2. In particular, there can be multiple history \nstates with an incoming ?-transition, but each of these states has exactly one incoming transition. Therefore, \nit is character\u00adized by its (unique) predecessor. As a result, the number of states of the history automaton \nis bounded by twice the num\u00adber of events, which ensures a bounded description of histo\u00adries. In this \npaper, we consider histories obtained with the 1\u00adpast abstraction with unknowns. (a) (b) (c)  Figure \n8: Abstract histories (a) and (b) merged into (c). Abstract Histories: Transformers In the concrete semantics, \na concrete history is updated by either initializing it to a given history, or appending an event to \nit. The abstract se\u00admantics is de.ned via the following transformers: Abstract extend transformer: appends \nthe new event s to the .nal states, and constructs the quotient of the result, with one exception: Final \nstates that have an incoming unknown transition, are not extended by (possibly other) unknown events. \n Merge operator: constructs the union of the given au\u00adtomata and returns the quotient of the result. \nThe abstract history component for a fresh object is ini\u00ad  tialized to a history re.ecting an init event, \nor to the ab\u00adstract history of the object that created it. When an observ\u00adable event occurs, the semantics \nupdates the relevant histo\u00adries using the extend transformer. As long as the domain of abstract histories \nis bounded, the abstract analysis is guaranteed to terminate. Yet, in prac\u00adtice, it can easily suffer \nfrom an exponential blowup due to branching control .ow. The merge operator will mitigate this blowup, \naccelerating convergence. Speci.cally, at con\u00adtrol .ow join points, all abstract histories associated \nwith the same abstract object (representing different execution paths) are merged. This introduces additional \noverapproximation but reduces the number of tracked histories. EXAMPLE 4.5. Histories (a) and (b) from \nFig. 8 are merged into history (c), where the two states labeled 2 are collapsed into one. As a result, \nadditional sequences that do not exist in the union of histories (a) and (b) are introduced, such as \nthe sequence (a, b, g ). 5. From Partial Specs to Search Index The analysis of the previous section works \non a large number of code snippets and produces a large number of partial spec\u00adi.cations (abstract histories). \nThese are the building blocks of the search index. Since the generated speci.cations are partial and \ncontain many unknowns, and their number might be enormous, their consolidation is essential.  In this \nsection, we discuss the consolidation phase of the index construction and present techniques for consolidating \npartial speci.cations. Consolidation has the following goals: Completion of partial speci.cations Speci.cations \nobtained from a single example may contain unknown transitions and may describe a non-initialized and \nnon-.nalized behavior. Our approach relies on having a large number of examples, and on combining the \npartial speci.cations obtained from different examples. Putting partial speci.cations together is an \nalignment problem. Amalgamation of partial speci.cations To answer code queries, we would like to present \na user with a manage\u00adable number of relevant code snippets based on our analysis. For that purpose we \nneed to collapse together similar results, while maintaining the support of each result. Noise reduction \nThe analysis will inevitably infer some spu\u00adrious usage patterns, due to either analysis imprecision \nor rare (and thus likely incorrect) examples. Such rare speci.\u00adcations should be treated as noise and \ndiscarded. 5.1 General Approach In the consolidation phase, we rede.ne the notion of an event (and accordingly \nof the alphabet S?) to refer to the signature of the invoked method (or unknown event), while omitting \nthe identity of the receiver. At this phase the identity of the receiver is irrelevant since we are only \ninterested in the invoked methods for each type. As partial speci.cations are being consolidated, we \nmain\u00adtain the total number of times a transition appears in a par\u00adtial speci.cation. We refer to this \nnumber as the weight of a transition, and it indicates how common a transition (or a sequence of transitions) \nis. Consolidation is performed by applying the following techniques: (a) unknown elimination, which makes \npartial speci.cations more complete by aligning them with others to match their unknowns with alternative \nknown behaviors, and (b) summarization, which merges together histories where one is included in the \nother (by the standard automata\u00adtheoretic notion of inclusion or some relaxation of it, such as the one \nde.ned in Section 6.1), while increasing the weights of the shared transitions.  These two techniques \ncan be repeated in any order. Noise reduction is intertwined with these steps, and is performed by discarding \ntransitions (or histories) whose weights are below a given threshold. In the rest of this section we \nfocus on the unknown elimination procedure.  5.2 Elimination of Unknowns We mine partial histories which \ncontain ?-transitions, mod\u00adeling unknown sequences of events. In this section we de\u00advelop a technique \nfor eliminating ?-transitions by replacing them with suitable candidates. Roughly speaking, candidates \nare found by aligning histories containing ?-transitions with other histories that share the context \nof the ?-transition. Given a ?-transition (qs, ?,qt), candidates to replace it are sequences that appear \nin the same context, i.e. following the same pre.x and followed by the same suf.x. To identify such sequences, \nwe de.ne the set of past-equivalent states .- - . [q] and the set of future-equivalent states [q] for \na state q. The set of candidates is then computed as the union of all paths between a past equivalent \nstate of qs and a future equivalent state of qt, as described in Alg. 1. Algorithm 1: Alternative Paths \nComputation Input: Set of histories H, Transition t Output: History h summarizing alternative paths QS \n= FindPastEquivalentStates(Source(t), H) QT = FindFutureEquivalentStates(Target(t), H) h = EmptyHistory() \nfor qs : QS do for qt : QT do h = Union(h, GetRestrictedAutomaton(qs, qt, H) return h The procedure \nGetRestrictedAutomaton(qs, qt, H) looks for a history hst in H that contains both qs and qt, if such \na history exists (otherwise, an empty automaton is returned). It then restricts the history hst to a \nsub-automaton whose initial state is qs and whose .nal state is qt. If the restricted automaton contains \nan ?-transition from qs to qt, the transi\u00adtion is removed. Given an automaton h representing the set \nof alternatives for the ?-transition (as returned by Alg. 1), we eliminate the transition by replacing \nit with that automaton h, and constructing the quotient of the result. Past-and Future-Equivalent States \nFor a state q, the set of past-equivalent states and the set of future-equivalent states are: . - ' [q]={q \n' |q and q have a joint initialized incoming sequence} - . ' [q]={q ' |q and q have a joint terminating \noutgoing sequence} Approximations Computing the sets of past-and future\u00adequivalent states is not feasible. \nWe therefore overapproxi\u00admate these sets by overapproximating the equivalence rela\u00adtions. This is done \nby parameterizing the relations by a limit k on the length of incoming and outgoing sequences. The resulting \nrelations are the k-past relation of Section 4.2, and its dual, called the k-future relation. Overapproximating \nthe past-and future-equivalent states results in an overapproxi\u00admation of the set of candidates to replace \nthe unknown.  (a) (b) (c) (d) (e)  Figure 9: Partial histories (a-c), the automaton (d) represent\u00ading \nthe alternative paths for the ?-transition in (c), and the history (e) obtained after elimination of \nthe unknown transi\u00adtion in (c). EXAMPLE 5.1. Consider the toy example depicted in Fig. 9. Histories (a-c) \ndepict the input histories. In particular, history (c) contains an ?-transition, preceded by an a event \nand followed by e. This de.nes the context of the ?-transition. The alternative paths computation .nds \ntwo past-equivalent states to the source of the transition and two future-equivalent states to the target \nof the transition, re\u00adsulting in two alternative sub-automata. The result of the alternative paths computation \nis therefore their union, as presented by automaton (d). Replacing the unknown transi\u00adtion with this \nautomaton results in history (e). Iterative Unknown Elimination Alg. 1 eliminates a single ?-transition. \nIt is iterated until no further ?-transitions can be eliminated. Special care is given to the order in \nwhich ?\u00adtransitions are eliminated in order to guarantee termination (a naive approach could lead to \nnon-termination, example is available in [28]). To guarantee termination, we handle all ?-transitions \nthat share a context simultaneously. This ensures termination of the algorithm since it ensures that \nonce all ?-transitions with some context are eliminated, they can never reappear. However, a single ?-transition \ncan have several contexts (e.g., it can be followed by two distinct events). As a pre\u00adliminary step in \nthe iterative unknown-elimination algo\u00adrithm we therefore split each such transition to several ?-transitions, \neach with a unique context (i.e., a unique com\u00adbination of preceding and following events). We say that \ntwo ?-transitions, each with a unique context, are equivalent if their context is the same. We partition \nthe set of split ?-transitions from all histories into sets of equivalent transitions (based on the unique \ncon\u00adtext). In each iteration, one of these sets is considered and all ?-transitions within it are eliminated \nsimultaneously. Let UT be the currently eliminated set of (equivalent) ?\u00adtransitions. We use Alg. 1 to \ncompute the set of alternative paths for an arbitrary transition, say (qs, ?,qt), in UT . Recall that \nthis computation disregards paths consisting of an ?\u00adtransition only (such paths result from the equivalent \n?\u00adtransitions in UT ). The obtained automaton h describing the set of alternative paths is common to \nall ?-transitions in UT . We therefore continue with the application of the unknown\u00adelimination algorithm \nfor each of the transitions in UT based on the same automaton h representing the alternative paths. On \ntop of its importance for correctness, handling equiva\u00adlent ?-transitions simultaneously is also more \nef.cient, since it prevents repeating the same computation for each of them separately. As a result of \nprevious unknown-elimination steps, ?\u00adtransitions that could previously not be eliminated, might become \namenable for elimination. Therefore, the elimina\u00adtion process continues until no further ?-transitions \n(or sets) can be eliminated. EXAMPLE 5.2. We summarize this section by demonstrating the consolidation \nphase on our motivating example. Con\u00adsider the histories depicted in Fig. 3. We describe in detail the \niterative unknown-elimination is this example. The inter\u00admediate histories are depicted in Fig. 10. Throughout \nthe example we denote the context of an ?-transition as a pair (pre, post) where pre precedes the ?-transition, \nand post follows it. In this example each ?\u00adtransition has a unique context since all histories describe \nsimple sequences. Therefore the preliminary splitting step is not needed. We .rst eliminate the ?-transition \nfrom state 4 to state 10 in (a) whose context is (login, -). We .nd a match in history (c), and history \n(a) is transformed to the history (a ) depicted in Fig. 10. Now, we simultaneously eliminate the two \nequivalent ?-transitions with context (logout, -), in histories (a ) and (c) (each of these transitions \nis from state 6 to state 10 in the corresponding history). The transitions are eliminated based on history \n(b). The resulting histories (a ) and (c ) are depicted in Fig. 10. Next, the ?-transition from state \n0 to state 3 in (c ) with context (-, login) is eliminated based on history (a ) resulting in the history \n(c ). Last, the ?-transition from state 3 to state 9 in (d) with context (getReplyCode, disconnect) is \neliminated based on histories (a ) and (c ), resulting in history (d ). No further ?-transitions can \nbe eliminated. In particular, the ?-transitions in history (b) are not eliminated.  Note that in this \nexample, the ?-transition from state 3 to state 9 in history (d) cannot be eliminated at .rst, but is \neliminated after other elimination steps are performed. When the iterative unknown-elimination algorithm \ntermi\u00adnates, a summarization step is applied. Since histories (a ), (c ) and (d ) are all isomorphic, \nthey are merged into one. The consolidated results are depicted in Fig. 4. 6. Querying the Index The \nprevious sections discussed index representation and construction. In this section, we describe our approach \nfor answering code search queries. Given a query in the form of a partial program, we .rst use the analysis \ndescribed in Section 4 to transform it into an automaton. We then compare the query automaton to the \n(consolidated) automata in the index in order to .nd matches. We observe that a match for the query should \nin\u00adclude it in the sense of including all the temporal informa\u00adtion present in the query, and .lling \nin its unknowns. Our approach therefore looks for automata that include the query automaton by some relaxed \nnotion of inclusion as described in Section 6.1. The obtained automata are simpli.ed, ranked and transformed \nback to code snippets. 6.1 Query Evaluation by Relaxed Inclusion A similarity measure is a key ingredient \nin the development of a search algorithm, as it determines the matches found for the given query. Our \nnotion of similarity is motivated by automata inclu\u00adsion. Intuitively, a good match for the query should \ninclude it. To handle ?-transitions, we relax the standard notion of automata inclusion. The intuition \nis that an unknown event in the query stands for some sequence of events, which might also contain unknowns \n(since the index we are searching in might still contain partial speci.cations, even after the unknown-elimination \nstep). Therefore, we say that the query is included in some automaton from the search index if its ?\u00adtransitions \ncan be completed in some way such that standard automata-inclusion will hold. Before we turn to the formal \nde.nition, we demonstrate the intuition on our motivating example. In this example, the automaton representing \nthe query, depicted in Fig. 5, is included in the .rst automaton from Fig. 4 if the .rst ?-transition \nis completed by ( getReplyCode, login )and the second ?-transition is completed by the sequence (logout \n). Note that in this example all automata represent simple sequences, but in practice more complex automata \narise. This leads us to the following relaxed de.nition of inclu\u00adsion. Let Q? .Q denote the targets of \nunknown transitions in a history. Recall that each such state q .Q? has a unique predecessor, which we \ndenote pred(q). Then DEFINITION 6.1 (Relaxed Inclusion). A history h1 = (S?, Q1, init1,d1, F1) is relaxly-included \nin a history h2 = (a) (b)   (S?, Q2, init2,d2, F2) if there is a mapping f : Q1 . Q2 . 2Q2 such that \n(1) f(q1) . 2Q2 iff q1 .Q?1, in which case we require that all states in f(q1) are reachable from ' f(pred(q1)), \n(2) If q1 .Q?1, then whenever q1 . d1(q1,a) ' for a . S, then f(q1) . d2(f(q1),a) as well, and (3) If \n' q1 .Q?1, then whenever q . d1(q1,a) for a . S, then 1 ' there exists q . f(q1) such that f(q1) . d2( \nq, a) as well. Intuitively, a history is relaxly-included in another if it can be embedded in it where \nunknown transitions are re\u00adplaced by more complete sub-automata. This de.nition resembles the problem \nof subgraph isomorphism, which is NP-complete. Fortunately, due to the simple characterization of the \nhistory states when using the k-past abstraction (with unknowns), checking if a history is relaxly-included \nanother is easy in our setting: the characterization of the states in\u00adduces the (potential) mapping for \nall states except for the mapping of Q?. The candidates for the mapping of states in Q? are found by \nexamining their successors. Thus it remains to check if this mapping ful.lls the requirements. EXAMPLE \n6.2. History (a) depicted in Fig. 11 is relaxly\u00adincluded in history (b). Intuitively speaking, history \n(b) in\u00adcludes history (a) when the ?-transition in (a) is com\u00adpleted by the rectangle in (b). Note that \nthis rectangle still contains an ?-transition, but it is more complete than the ?-transition of (a). \nTechnically, the mapping of states in this example is the following: 0 . 0 ' , 1 . 1 ' , 2 .{4 ' , 6 \n' }, 3 . 5 ' , 4 . 7 ' . EXAMPLE 6.3. Histories (a), (c), (d) depicted in Fig. 3 are all included by \nour notion of relaxed inclusion in the top con\u00adsolidated history from Fig. 4. Note that standard automata\u00adinclusion \ndoes not hold here.  6.2 Search Results In order to transform the consolidated histories that match \nthe query into code snippets and present them to the user in a useful way, we use the following steps. \n  Extracting Sequences from Consolidated Automata The histories matching the query represent a multitude \nof possi\u00adble method call sequences, some of which are irrelevant to the given query, and would not be \nuseful as (a part of) a search result. In addition, some of the obtained automata are large and complex, \nand do not lend themselves well to being returned as human-readable search results. To address these \ntwo issues, we .rst extract from each history h that matches the query (i.e., relaxly-includes it), a \nsub-automaton hmin representing all minimal sub-automata that still relaxly-include the query. hmin still \nmatches the query and it summarizes all the information relevant for the query. It is computed as the \nintersection of h with the result of applying the unknown-elimination algorithm on the query automaton \nbased on h. The history hmin is then decomposed into simple paths, each of which encodes a single sequence \nof events, by a repetition-free depth-.rst-traversal of hmin. This means that although the consolidated \nautomata may contain loops, the .nal human-friendly results never do. Ranking The history-paths extracted \nfrom the automata that match the query are ranked according to: Their support: the support of a history-path \nis inherited from the history that the path was extracted from. It corresponds to the number of histories \nsummarized into the history during the consolidation phase of the index construction (see Section 5). \n Their probability: this is the probability of following the history-path (and observing the sequence \nof events label\u00ading it) in its source history. It is computed by normalizing all the weights on the source \nhistory transitions such that the sum of all outgoing transitions for each state is 1. This turns the \nhistory into a probabilistic automaton, where the  probability of each path corresponds to the multiplication \nof all probabilities along its transitions. Since it is possible that two or more similar paths will \nbe returned from different histories, the paths are summarized (merged together by inclusion) to avoid \nredundant search re\u00adsults. In such cases, the supports are summarized as well, and the probability is \nchosen to be the maximal probability among the summarized paths. Paths are .rst sorted accord\u00ading to \ntheir (accumulated) support. Paths with the same sup\u00adport are then ranked by their (maximal) probabilities. \nFrom Automata to Code Starting at the index construc\u00adtion phase and up until the query evaluation phase, \nwe main\u00adtain for each transition of a history the set of code snippets responsible for introducing it. \nThis set is initialized during the analysis of individual snippets (where each transition is associated \nwith the snippets that produced it), and it is up\u00addated during unknown-elimination and summarization. \nThis enables us to transform history-paths and their correspond\u00ading sequences of events back to code \nsnippets. The problem of .nding a smallest set of snippets that cover all of the rel\u00adevant transitions \nis NP-complete. Still, in many cases it is possible to .nd such small sets. 7. Evaluation 7.1 Prototype \nImplementation We have implemented our approach in an open-source tool called PRIME. The tool and the \ndata used for our experiments are available from http://priming.sourceforge.net/. For collecting snippets \nwe have used automatic scripts to search and download from GitHub, Stackover.ow and (before it was closed) \nGoogle Code Search. Partial snippet compilation, needed for simplifying Java to an intermedi\u00adate language \nfor analysis, is done using a specialized partial compiler [9]. Code analysis relies on the Soot static \nanaly\u00adsis framework [37], but adds custom-made points-to analysis which can handle partial code snippets, \nas well as an inter\u00adprocedural analysis mechanism which can also deal with re\u00adcursion and takes parameters \nand return values into consid\u00aderation.  PRIME can track objects across upcasts and downcasts, and can \nhandle method calls on sub-or super-types of the tracked object s type even when it is not aware of the \nrela\u00adtions between the types. This is done by collapsing parallel edges together if they correspond to \ndifferent implementa\u00adtions of the same method. Our textual search queries return many thousands of ex\u00adamples, \nwhich PRIME then proceeds to analyze. When oper\u00adating on pre-downloaded, locally-available snippets, \nPRIME is capable of analyzing hundreds of thousands and even mil\u00adlions of snippets. We assume that downloading \nand con\u00adstructing the index for a family of APIs is done before queries are evaluated. Analysis We have \nused the k-past abstraction with un\u00ad knowns, setting k =1. Performance Index construction was run on \na 2.66 GHz In\u00adtel Xeon X5660 CPU machine with 48 GB memory. Each group of 1000 snippets took approximately \n1 hour to com\u00adpile, 30 minutes to analyze and 5 minutes to consolidate. Querying was done on a 1.7 GHz \nIntel Core i5 machine with 4 GB memory. It took 1 to 3 seconds to .nd matches to a query, but extracting \nsequences and ranking them takes be\u00adtween 1 and 45 seconds, depending on the number and size of the found \nmatches. Optimizing the performance of query\u00ading and extracting sequences could be done but was outside \nthe scope of our initial work.  7.2 Benchmarks and Methodology For the purpose of evaluation we selected \nseveral high\u00adpro.le APIs in which method sequence order is important. We used PRIME to construct an indexed \ndata set from them and to query them. For the sake of the evaluation of PRIME s results, we chose APIs \nfor which tutorials exist, and can provide familiarity with the desired outcome. Benchmarks The APIs \nwe have chosen to show are taken from the popular libraries: Apache Ant A project building library. \n Apache Commons CLI A library for parsing command\u00adline options (and in particular GnuParser, its command \nline parser).  Apache Commons Net A network communications li\u00adbrary (and particularly its FTPClient \ncomponent).  Eclipse The popular modular Java IDE (in particular its UI, JDT and GEF plugins).  JDBC \nA built-in Java library for interacting with databases.  WebDriver A widely-used browser automation \nframe\u00adwork. These libraries are all widely-used, and our personal experi\u00adence indicates that some of \nthem are quite tricky to use. Experiments We ran several experiments on our collected data set: Distilling. \nTo evaluate the ability of PRIME to distill a large number of snippets into illustrative examples, we \nran PRIME and checked whether the few top results in\u00adclude the examples present in a tutorial of the \nAPI. We show that a user can use PRIME to browse a small number of distilled examples instead of sifting \nthrough thousands of results returned from a textual search engine.  Prediction. To evaluate the quality \nof our results, we used PRIME to answer prediction queries. We gathered example method invocation sequences \nfor several of our selected APIs, representing a common use of that API. The examples were either produced \nfrom online tutorials or manually crafted according to the API documentation. They were transformed into \nprediction queries by replac\u00ading their suf.xes with unknown events.  Consolidation. To evaluate the \nimportance of consolida\u00adtion, we gathered several queries which represent parts of common use-cases over \nhigh-pro.le APIs, and show that these produce high-quality results after consolidation is applied, but \nno results or poor results without consolida\u00adtion.  We now elaborate on these experiments and their \nresults.  7.3 Results 7.3.1 Distilling To show the advantage of distilling and ranking search re\u00adsults \naccording to history support, we use a simple 1-method query for each API and check whether the top results \nre\u00adturned by PRIME include the tutorial example, and if so, how it was ranked. This experiment is similar \nto the evaluation approach used in [44]. However, our queries used what we considered to be the key method \nin each tutorial, not just the .rst one. The value of PRIME is not only in .nding the tuto\u00adrial result, \nbut also in establishing the support of this result in term of commonality. The results are summarized \nin Table 1. The .rst column shows the API used and how many of its snippets PRIME an\u00adalyzed. In this \nspeci.c case, each snippet is an entire class (the granularity of .les obtained from GitHub). The second \ncolumn shows the query used (not including surrounding un\u00adknowns). The third column shows the number \nof results re\u00adturned from GitHub s textual search, i.e., the number of pos\u00adsible matches the user has \nto browse (notice this is less than the number of snippets given to PRIME, as not all snippets actually \ncontain the method in question directly, though they may of course call it indirectly). The last two \ncolumns shows  API used for the query, num of downloaded snippets Query description Query method Number \nof textual matches Tutorial s rank Tutorial s support WebDriver 9588 snippets Selecting and clicking \nan element on a page WebElement.click() 2666 3 2k Apache Commons CLI 8496 snippets Parsing a getting \na value from the command line CommandLine.getValue(Option) 2640 1 873 Apache Commons Net 852 snippets \n connect -> login -> logout -> disconnect sequence FTPClient.login(String, String) 416 1 446 JDBC 6279 \nsnippets Creating and running a prepared statement PreparedStatement.executeUpdate() 378 1 431 Committing \nand then rolling back the commit Connection.rollback() 177 4 28 Eclipse UI 17,861 snippets Checking whether \nsomething is selected by the user ISelection.isEmpty() 1110 2 411 Eclipse JDT 17,198 snippets Create \na project and set its nature IProject.open(IProgressMonitor) 3924 1 1.1k Eclipse GEF 5981 snippets Creating \nand setting up a ScrollingGraphicalViewer GraphicalViewer.setEditPartFactory (EditPartFactory) 219 1 \n14 Table 1: Experimental Results -Distilling. In this case, each snippet is a complete class. the rank \nthat the tutorial example was found in, and the sup\u00adport for that tutorial. As can be seen from Table \n1, PRIME always returned the tutorial example as one of the top few results, and in many cases as the \n.rst result. This means that a user can rely solely on looking at the top few results returned from PRIME \ninstead of manually browsing through the hundreds or thousands of results returned from regular textual \nsearch. The WebElement.click() tutorial was only ranked 3rd because it is very common to click on some \nelement only when a certain condition holds. Therefore, the two preceding matches contained calls to \ngetter methods before click(). Connection.rollback() was ranked 4th be\u00adcause although there are required \npreceding and succeeding method calls that appeared in all top results, there are often other various \ncalls on that object in-between. The GEF tuto\u00adrial was matched as .rst but has poor support because there \nare many different use-cases for the setEditPartFactory method.  7.3.2 Prediction Table 3 lists the \nsequences used to obtain prediction queries, their description, and their prediction accuracy by PRIME. \nAccuracy was measured by checking the prediction PRIME gave for each method in the sequence when the \nsuf.x start\u00ading with it was replaced by an unknown. We adapted PRIME to use the same principles described \nin Section 6 in order to return a ranked list of possible next methods, which we compared to the actual \nmethod from the sequence. We use the average, median, and max rank of the prediction over the entire \nsequence to evaluate accuracy. Any rank less than half the number of methods de.ned in the type is better \nthan blind guess, and any rank less than 1.5 means that most of the time PRIME s prediction was perfect. \nTable 3 shows that PRIME was generally successful in predicting the next method in a sequence given the \nprevious ones. In all cases the correct method was within the .rst Result 2, supported by 5 histories: \n Result 3, supported by 3 histories: Figure 12: Results of GnuParser search query of Table 2 on an index \nwithout consolidation. Note that the support is signi.cantly lower. (Difference between results 1 and \n3 is in the last call.) dozen methods presented by PRIME, and in the majority of times it was actually \nthe 1st ranked, giving a perfect prediction. Prediction did not fare as well in JDBC as in the other \nAPIs, mainly because there are various popular ways to use a Connection and ResultSet, leaving no clear \nadvantage to the way described in the tutorial.  7.3.3 Effect of Consolidation Table 2 shows a number \nof search queries and the top-ranked results obtained from PRIME when using a consolidated in\u00addex. When \nevaluated over a non-consolidated index, only one of these queries can be answered, and its result is \nshown in Fig. 12. The queries were hand-crafted from of.cial tu\u00adtorials and documentations, so they always \nrepresent correct sequences, but portions of them have been replaced by un\u00adknown edges. This replacement \nis done to demonstrate how a user only partially familiar with the API can still get ac\u00adcurate results \neven with just partial information about her goals. For each query we show the three highest-ranked se\u00adquences \nextracted from the results matching it.  Query Consolidated Results A query which users a cached database \nman\u00adager to obtain a connection, then creates and runs a prepared statement and .nally gets a Result \n1, supported by 36 histories: double value form a speci.c .eld. InitialContext ic = new InitialContext(); \nResult 2, supported by 36 histories: ic.?; PreparedStatement ps = ic.?; ResultSet rs = ps.executeQuery(); \nrs.?; double d = rs.getDouble(\"column\"); Result 3, supported by 36 histories: Looking for any sequence \nwhich uses a spe\u00adci.c implementation of a WebDriver, that creates a WebElement from the WebDriver via \na speci.c method, and that clears and then submits a web form. Result 1, supported by 739 histories: \nWebDriver d = new FirefoxDriver(); d.?; By by = ?; Result 2, supported by 478 histories: WebElement e \n= d.findElement(by); e.?; e.clear(); e.? e.submit(); Result 3, supported by 478 histories: Aiming to \nobtain a String from command\u00adline arguments that adhere to the GNU style. The query only requires initialization \nof a GnuParser instance, and that at a certain Result 1, supported by 312 histories: point a String will \nbe obtained from it. GnuParser p = new GnuParser(); p.?; String s = p.?; Result 2, supported by 273 histories: \ns.?; Result 3, supported by 20 histories: A query typical of a user who wants to re\u00adtrieve a .le via \nFTP and only knows she needs to login .rst. FTPClient c = ?; Result 1, supported by 74 histories: c.login(\"username\", \n\"password\"); c.?; c.retrieveFile(\"file path\", out); Result 2, supported by 74 histories: Result 3, supported \nby 74 histories: This query tries to .nd out how to get the web page s source using the simple HtmlU\u00adnit \nbrowser. Result 1, supported by 4k histories: WebDriver d = new HtmlUnitDriver(); d.?; d.getPageSource(); \nResult 2, supported by 3k histories: Result 3, supported by 603 histories: Table 2: Results of search \nqueries over an index with consolidated partial speci.cations. For all of these queries but the 3rd no \nresults were found when the index construction does not use consolidation. For the 3rd query, results \nwithout consolidation are shown in Fig. 12. GnuParser p = new GnuParser(); p.?; String s = p.?; s.?; \n Figure 13: Obtaining a String from a command-line parser  Figure 14: A result for the query of Fig. \n13 when the analysis was done on a single global object. Results of PRIME for this query are shown in \nTable 2. For FTPClient, we omitted the pre.x FTPClient from all calls so we can .t the histories into \nthe .gure. Of interest are the .rst row and the last row. In the .rst row, PRIME demonstrates the ability \nto complete very long sequences when required to do so by the query. The event names are dif.cult to \nread in this example, but the im\u00adportant property is the length of the sequences. In the last row, the \nresults exhibit very high support values, since the query describes an extremely common use-case of scraping \nthe source of a web page (extracting information from the HTML) using the simplest available browser. \nNote that de\u00adspite of the popularity of this usage scenario, a match for the query was not found on a \nnon-consolidated index. As shown in Fig. 12, in the (only) case where matches to the query were found \nalso in the non-consolidated index, the support of each result is still much higher when searching in \na consolidated index.  7.4 Importance of Tracking Typestate To demonstrate the importance of tracking \ntypestate for indi\u00advidual (abstract) objects in the context of search we show an example of the results \nreturned when the distinction between abstract objects is removed and all objects are considered to be \nthe same single global object. We do that by running a modi.ed version of PRIME which does not distinguish \nbe\u00adtween abstract objects. This has the effect of tracking global event sequences. The query in Fig. \n13, for instance, was an\u00adswered by the sequence in Fig. 14, which is not helpful, as it contains the \nunrelated StringBuilder.toString() call after the parse, which cannot be invoked on a GnuParser. In contrast, \nthe results of PRIME for this query are shown as part of Table 2. We have observed similar loss of precision \nfor most other APIs we considered. Attempting to address this limitation by .ltering the ob\u00adjects by \ntypes is not feasible, since with partial samples types are not known and the type hierarchy may not \nbe available.  7.5 Comparison with Related Work Prospector Since the analysis is aware of creation context, \nPRIME can theoretically .nd many of the type conversions found by Prospector ([27]), by composing a query \ncon\u00adtaining both in input type and output type. For instance, [27] shows a conversion between IWorkbenchPage \nand IDocumentProvider; given the query containing both types, PRIME was able to .nd and analyze a relevant \nex\u00adample as seen in Fig. 15. With this approach, running on the 20 examples provided in [27], PRIME found \n8 of the 18 conversions identi.ed by Prospector, as well as one conver\u00adsion not identi.ed by Prospector \n(IWorkspace . IFile). Prospector could identify the remaining conversions primar\u00adily because they rely \non a connection between method ar\u00adguments and return value, which our concept of creation context ignores, \nthough it can be extended to include it. MAPO We have experimented with the GEF framework (e.g. Table \n1), which was also used as the experimental eval\u00aduation of MAPO ([44]). PRIME s ability to deal with \npartial code snippets allowed PRIME to easily obtain a lot more snip\u00adpets to work with for the GEF API \nthan was possible with MAPO [44], enabling a higher support for each result. Note that despite the partialness \nof the snippets being used, PRIME still performs a more precise typestate analysis with aliasing support. \n8. Related Work Our work mines temporal speci.cations as the basis for code search. There has been a \nlot of work on speci.cation mining, recommendation systems, and various forms of se\u00admantic code-search. \nIn this section, we survey some of the closely related work. We note that there are other lines of re\u00adlated \nresearch such as clone detection and code comparison (e.g. [19]) that can provide alternative similarity \nmeasures between snippets. For example, some works on clone detec\u00adtion considered syntactic information \nsuch as the tokens that appear in each sample (e.g., [11, 20]), other works are based on ASTs which maintain \nsome structural information (e.g., [5, 19, 25, 38]), or on more semantic information based on program \ndependence graphs (e.g., [13, 23, 24]). However, this is not the focus of this work. Code Search and \nRecommendation Several approaches addressing the problem of semantic code search and its variation were \nproposed in the literature. MAPO [44] uses API usage patterns as the basis for recommending code snippets \nto users. Their work differs from our work in several crucial aspects: (i) MAPO does not deal with missing \nparts of an implementation. As a result it does not handle arbitrary code snippets, such as many of the \nexamples found online, nor their challenges. Our approach handles arbitrary partial programs, and uses \nconsolidation techniques to derive from them a much more complete view of the API than obtained from \nindividual methods. (ii) MAPO s analysis tracks global sequences of method invocations on various types, \ndisregarding their as\u00adsociation with individual objects, resulting in noise re.ecting mixed usage patterns \nof multiple objects. Our work tracks the receiver of an event even in the presence of aliasing,  API/Type \nNature of sequence (source) Length Avg Rank Median Rank Max Rank Apache Commons Net / FTPClient Apache \nCommons CLI / CommandLine Apache Ant / CommandLine.Argument Apache Ant / Path JDBC / ResultSet JDBC / \nConnection Eclipse JDT / ITypeBinding Eclipse JDT / IProjectDescription Eclipse UI / PluginAction Eclipse \nUI / IEditorInput Upload a .le (of.cial tutorial) Parse a command-line and get values from it (of.cial \nusage guide) Prepare the executable and argument of a command-line (online tutorial) Create a path element \nand append it to existing and boot paths (authors) Run a query and iterate over the results (many online \ntutorials) Commit and then rollback a transaction (of.cial tutorial) Get the key of an array element \ntype (authors) Get the description and nature IDs of a Java project (online tutorial) Create a new action \n(online tutorial) Get the input for the current editor (online tutorial) 7 4 4 6 8 5 5 4 5 5 1.14 1.50 \n1.25 1.33 3.13 4.60 4.20 2.00 1.00 2.80 1 1 1 1 2 3 1 1 1 3 2 2 2 3 10 12 12 4 1 5 Table 3: Experimental \nResults -Prediction Figure 15: IDocumentProvider example found by querying over both IWorkbenchPage \nand IDocumentProvider. The conversion between the types appears between states 2 and 4. through method \ncalls, drastically reducing noise from sur\u00adrounding objects and method calls. (iii) MAPO mines sim\u00adple \nsequences ignoring loops, whereas we mine generalized typestate. (iv) While we use relaxed inclusion \nto .nd sim\u00adilarities between typestates, MAPO clusters the mined se\u00adquences by various clustering techniques. \nThe consideration of such techniques for typestates is the subject of future work. Strathcona [17] matches \nthe structure of the code under development to the code in the examples. The query in this case is implicit \nand consists of the pre.x of the currently written code. The search is performed over a sample repos\u00aditory \n(e.g., the existing project), thus no partial code frag\u00adments are considered. The search is based on \nstructural con\u00adtext which comprises details of the method being written, its containing class and previous \nmethods invoked. Temporal information such as the order of method invocations is not considered. Mandelin \net al. [27] use static analysis to infer a sequence of code (jungloid) that shows the programmer how \nto ob\u00adtain a desired target type from a given source type. This code-sequence is only checked for type-safety \nand does not address the .ner notion of typestate. Thummalapenta and Xie [36] introduce a tool called \nPARSEWeb to expand on Mandelin s approach by gathering samples online, partially\u00adcompiling them and analyzing \nthe results with a simple static analyzer. We employ a similar technique in the .rst phases of our solution, \nand we draw from their experience. However, like with Mandelin s work, their analysis is only concerned \nwith the object types appearing in code sequences. More\u00adover, their approach is AST-based and does not \nperform a deeper semantic analysis tracking objects. XSnippet [31] uses queries that refer to object \ninstantia\u00adtions, possibly with some additional context from the user s code. Their analysis is based \non a graph representation of the code, which describes the types, methods and .elds appear\u00ading in the \ncode, but does not track objects and sequences of operations applied on them. Alnusair et al. [2] use \nontologies to represent semantic information about object instantiation sequences. They use an interprocedural \npoints-to analysis to obtain a precise re\u00adturn type for API methods based on the framework code. This \nallows them to rely on library-side semantic informa\u00adtion rather than relying just on information from \nsnippets. Considering richer ontological models of library code seems like a promising direction that \ncan complement the semantic information we use in our approach. Kim et al. [21] search code for the purpose \nof attaching code examples to documentation. Their index construction is based on intraprocedural AST-based \nanalysis and considers each snippet as a full use case. Their search is based on method names. This approach \nis too crude to provide quality results for the kind of queries we address in this paper. Reiss [30] \nuses a combination of class or method signa\u00adtures and dynamic speci.cations such as test-cases and con\u00adtracts \nsupplied by a user as a basis for semantic code search. The candidate code snippets, initially obtained \nby textual search, undergo several transformations aimed at generat\u00ading candidates that match the signature \nprovided by the user. Matches among these candidates are then found by dynami\u00adcally checking the test-cases \n(and additional dynamic speci\u00ad.cations if exist). Our approach does not require the user to supply test-cases \nor their kind as a part of the query. In addi\u00adtion, we do not consider the dif.cult problem of synthesizing \nexecutable code, which makes the usage of test-cases inap\u00adplicable. In cases where the results are indeed \nexecutable, we can bene.t from a similar dynamic approach to .nd matches to the query.  Speci.cation \nMining Dynamic Speci.cation Mining There has been a lot of past work on dynamic speci.cation mining for \nextracting various forms of temporal speci.cations (e.g., [4, 7, 10, 26, 42, 43]). Dynamic speci.cation \nmining does not suffer from the dif.\u00adculties inherent to abstraction required in static analysis. Be\u00adcause \nour focus on this paper is on analysis of code snippets, employing dynamic analysis would be extremely \nchalleng\u00ading. Still, when it is feasible to run a program with adequate coverage, dynamic analysis represents \nan attractive option for speci.cation mining. Component-side Static Analysis In component-side static \nanalysis, a tool analyzes a component s implementation, and infers a speci.cation that ensures the component \ndoes not fail in some predetermined way, such as by raising an ex\u00adception. For example, Alur et al. [3] \nuse Angluin s algorithm and a model-checking procedure to learn a permissive inter\u00adface of a given component. \nIn contrast, client-side mining produces a speci.cation that represents the usage scenarios in a given \ncode-base. The two approaches are complemen\u00adtary, as demonstrated in [42]. Our index construction in \nthis paper performs client-side speci.cation mining. Client-side Static Analysis Many papers have applied \nstatic analysis to client-side speci.cation mining. Weimer and Necula [41] use a simple, lightweight \nstatic analysis to infer simple speci.cations from a given code\u00adbase. Their insight is to use exceptional \nprogram paths as negative examples for correct API usage. We believe that our approach could also bene.t \nfrom using exceptional paths as negative examples. Weimer and Necula learn speci.ca\u00adtions that consist \nof pairs of events (a, b), where a and b are method calls, and do not consider larger automata. They \nrely on type-based alias analysis, and so their techniques should be much less precise than ours. On \nthe other hand, their pa\u00adper demonstrates that even simple techniques can be surpris\u00adingly effective \nin .nding bugs. Monperrus et al. [29] attempt to identify missing method calls when using an API by mining \na codebase and sharing our assumption that incorrect usage will be infrequent. They only compare objects \nthat have identical type and same con\u00adtaining method signature, which only works for inheritance\u00adbased \nAPIs. Their approach deals with identical histories or identical histories minus k method calls, and \nunlike PRIME it cannot handle incomplete programs, non-linear method call sequences, and general code \nqueries. Wasylkowski, Zeller, and Lindig [40] use an intrapro\u00adcedural static analysis to automatically \nmine object usage patterns and identify usage anomalies. Their approach is based on identifying usage \npatterns, in the form of pairs of events, re.ecting the order in which events should be used. In contrast, \nour work mines temporal speci.cations that over-approximate the usage scenarios in a code-base. The work \nof [16] is similar in spirit, but more lightweight. Here too, speci.cations are only pairs of events, \nand are used to detect anomalies. Acharya et al. [1] also mine pairs of events in an attempt to mine \npartial order between events. Their analysis is for C, which is a fundamental difference since it is \nnot an object\u00adoriented language. Wasylkowski and Zeller [39] mine speci.cations (opera\u00adtional preconditions) \nof method parameters in order to detect problems in code. They use intraprocedural analysis, without \nany pointer analysis. The mined speci.cations are CTL for\u00admulas that .t into several pre-de.ned templates \nof formulas. Therefore, the user has to know what kind of speci.cations she is looking for. In addition, \nno consolidation of partial speci.cations is applied. Shoham et al. [32] use a whole-program analysis \nto stat\u00adically analyze clients using a library. Their approach is lim\u00adited to single-object typestate. \nMore importantly, their ap\u00adproach is not applicable in the setting of partial programs since they rely \non the ability to analyze the complete pro\u00adgram for complete alias analysis and for type information. \nThe transition to partial programs and partial speci.cations is a signi.cant departure from this work. \nOther than the ad\u00additional challenges during the analysis, dealing with partial speci.cations raises \nnew challenges while processing the re\u00adsults. In [32] the focus was on reducing noise, whereas a signi.cant \npart of our focus is on consolidating the partial speci.cations into complete ones. In particular, partial \nspeci\u00ad.cations include unknown events (?-transitions). To that end, we suggest unknown elimination and \nrelaxed-inclusion tech\u00adniques which are different in implementation as well as gen\u00aderal goal. 9. Conclusion \nWe present a semantic code search approach capable of searching over arbitrary code snippets, including \npartial snippets, such as the ones obtained from expert code sites. Our search is based on novel static \nanalysis techniques for speci.cation mining which (a) extract partial temporal spec\u00adi.cations in the \nform of typestate with creation context from (partial) code snippets, and (b) consolidate partial speci.\u00adcations \nin a way that completes their unknowns whenever possible. In order to answer code search queries, we \npropose a new notion of relaxed inclusion tailored for partial speci.\u00adcations with unknowns. We show \nthat our approach is useful for answering code search queries dealing with how an API is used. Acknowledgements \nWe would like to thank Barthelemy Dagenais, whose work on a partial compiler ([9]) enabled us to approach \notherwise\u00adproblematic partial code snippets, and who was generously willing to extend his tool for our \nneeds. We would like to thank Hongseok Yang for many insightful discussions.  This research was partially \nsupported by The Israeli Sci\u00adence Foundation (grant no. 965/10), and the German-Israeli Foundation for \nScienti.c Research and Development (grant no. 2248-2045.6). References [1] ACHARYA, M., XIE, T., PEI, \nJ., AND XU, J. Mining API patterns as partial orders from source code: from usage sce\u00adnarios to speci.cations. \nIn ESEC-FSE 07, pp. 25 34. [2] ALNUSAIR, A., ZHAO, T., AND BODDEN, E. Effective API navigation and reuse. \nIn IRI (aug. 2010), pp. 7 12. [3] ALUR, R., CERNY, P., MADHUSUDAN, P., AND NAM, W. Synthesis of interface \nspeci.cations for Java classes. In POPL (2005). [4] AMMONS, G., BODIK, R., AND LARUS, J. R. Mining speci.cations. \nIn POPL 02, pp. 4 16. [5] BAXTER, I. D., YAHIN, A., MOURA, L., SANT ANNA, M., AND BIER, L. Clone detection \nusing abstract syntax trees. In ICSM 98. [6] BECKMAN, N., KIM, D., AND ALDRICH, J. An empirical study \nof object protocols in the wild. In ECOOP 11. [7] COOK, J. E., AND WOLF, A. L. Discovering models of \nsoftware processes from event-based data. ACM Trans. Softw. Eng. Methodol. 7, 3 (1998), 215 249. [8] \nCOUSOT, P., AND COUSOT, R. Modular static program analysis, invited paper. April 6 14 2002. [9] DAGENAIS, \nB., AND HENDREN, L. J. Enabling static analy\u00adsis for partial Java programs. In OOPSLA 08, pp. 313 328. \n[10] DALLMEIER, V., LINDIG, C., WASYLKOWSKI, A., AND ZELLER, A. Mining object behavior with ADABU. In \nWODA 06. [11] DUCASSE, S., RIEGER, M., AND DEMEYER, S. A language independent approach for detecting \nduplicated code. In ICSM 99. [12] FINK, S., YAHAV, E., DOR, N., RAMALINGAM, G., AND GEAY, E. Effective \ntypestate veri.cation in the presence of aliasing. In ISSTA 06, pp. 133 144. [13] GABEL, M., JIANG, L., \nAND SU, Z. Scalable detection of semantic clones. In ICSE 08, pp. 321 330. [14] GABEL, M., AND SU, Z. \nJavert: fully automatic mining of general temporal properties from dynamic traces. In FSE 08. [15] github \ncode search. https://github.com/search. [16] GRUSKA, N., WASYLKOWSKI, A., AND ZELLER, A. Learn\u00ading from \n6,000 projects: Lightweight cross-project anomaly detection. In ISSTA 10. [17] HOLMES, R., AND MURPHY, \nG. C. Using structural context to recommend source code examples. In ICSE 05. [18] HOLMES, R., WALKER, \nR. J., AND MURPHY, G. C. Strath\u00adcona example recommendation tool. In FSE 05, pp. 237 240. [19] JIANG, \nL., MISHERGHI, G., SU, Z., AND GLONDU, S. Deckard: Scalable and accurate tree-based detection of code \nclones. IEEE Computer Society, pp. 96 105. [20] KAMIYA, T., KUSUMOTO, S., AND INOUE, K. CCFinder: a multilinguistic \ntoken-based code clone detection system for large scale source code. IEEE Trans. Softw. Eng. 28, 7 (July \n2002), 654 670. [21] KIM, J., LEE, S., WON HWANG, S., AND KIM, S. Towards an intelligent code search \nengine. In AAAI 10. [22] Koders. http://www.koders.com/. [23] KOMONDOOR, R., AND HORWITZ, S. Using slicing \nto iden\u00adtify duplication in source code. In SAS 01, pp. 40 56. [24] KRINKE, J. Identifying similar code \nwith program depen\u00addence graphs. In WCRE (2001), pp. 301 309. [25] LIVIERI, S., HIGO, Y., MATUSHITA, \nM., AND INOUE, K. Very-large scale code clone analysis and visualization of open source programs using \ndistributed CCFinder: D-CCFinder. In ICSE 07. [26] LO, D., AND KHOO, S.-C. SMArTIC: towards building \nan accurate, robust and scalable speci.cation miner. In FSE 06. [27] MANDELIN, D., XU, L., BODIK, R., \nAND KIMELMAN, D. Jungloid mining: helping to navigate the API jungle. In PLDI 05, pp. 48 61. [28] MISHNE, \nA. Typestate-based semantic code search over partial programs. Master s thesis, Technion-Israel Institute \nof Technology, Haifa, Israel, 2012. [29] MONPERRUS, M., BRUCH, M., AND MEZINI, M. Detecting missing method \ncalls in object-oriented software. In ECOOP (2010), T. D Hondt, Ed., vol. 6183 of Lecture Notes in Com\u00adputer \nScience, Springer, pp. 2 25. [30] REISS, S. P. Semantics-based code search. In ICSE 09. [31] SAHAVECHAPHAN, \nN., AND CLAYPOOL, K. XSnippet: min\u00ading for sample code. In OOPSLA 06. [32] SHOHAM, S., YAHAV, E., FINK, \nS., AND PISTOIA, M. Static speci.cation mining using automata-based abstractions. In ISSTA 07. [33] SOLAR-LEZAMA, \nA., RABBAH, R., BOD\u00cdK, R., AND EBCIO . GLU, K. Programming by sketching for bit-streaming programs. In \nPLDI 05. [34] stackover.ow. http://stackover.ow.com/. [35] STROM, R. E., AND YEMINI, S. Typestate: A \nprogramming language concept for enhancing software reliability. IEEE Trans. Software Eng. 12, 1 (1986), \n157 171. [36] THUMMALAPENTA, S., AND XIE, T. PARSEWeb: a pro\u00adgrammer assistant for reusing open source \ncode on the web. In ASE 07, pp. 204 213. [37] VALL\u00c9E-RAI, R., CO, P., GAGNON, E., HENDREN, L., LAM, P., \nAND SUNDARESAN, V. Soot -a Java bytecode op\u00adtimization framework. In CASCON 99, IBM Press, pp. 13 . [38] \nWAHLER, V., SEIPEL, D., WOLFF, J., AND FISCHER, G. Clone detection in source code by frequent itemset \ntechniques. In Source Code Analysis and Manipulation (2004). [39] WASYLKOWSKI, A., AND ZELLER, A. Mining \ntemporal speci.cations from object usage. In Autom. Softw. Eng. (2011), vol. 18. [40] WASYLKOWSKI, A., \nZELLER, A., AND LINDIG, C. Detect\u00ading object usage anomalies. In FSE 07, pp. 35 44. [41] WEIMER, W., \nAND NECULA, G. Mining temporal speci.ca\u00adtions for error detection. In TACAS (2005). [42] WHALEY, J., \nMARTIN, M. C., AND LAM, M. S. Auto\u00admatic extraction of object-oriented component interfaces. In ISSTA \n02. [43] YANG, J., EVANS, D., BHARDWAJ, D., BHAT, T., AND DAS, M. Perracotta: mining temporal API rules \nfrom imperfect traces. In ICSE 06, pp. 282 291. [44] ZHONG, H., XIE, T., ZHANG, L., PEI, J., AND MEI, \nH. MAPO: Mining and recommending API usage patterns. In ECOOP 09.    \n\t\t\t", "proc_id": "2384616", "abstract": "<p>We present a novel code search approach for answering queries focused on API-usage with code showing how the API should be used. To construct a search index, we develop new techniques for statically mining and consolidating temporal API specifications from code snippets. In contrast to existing semantic-based techniques, our approach handles partial programs in the form of code snippets. Handling snippets allows us to consume code from various sources such as parts of open source projects, educational resources (e.g. tutorials), and expert code sites. To handle code snippets, our approach (i) extracts a possibly partial temporal specification from each snippet using a relatively precise static analysis tracking a generalized notion of typestate, and (ii) consolidates the partial temporal specifications, combining consistent partial information to yield consolidated temporal specifications, each of which captures a full(er) usage scenario.</p> <p>To answer a search query, we define a notion of relaxed inclusion matching a query against temporal specifications and their corresponding code snippets.</p> <p>We have implemented our approach in a tool called PRIME and applied it to search for API usage of several challenging APIs. PRIME was able to analyze and consolidate thousands of snippets per tested API, and our results indicate that the combination of a relatively precise analysis and consolidation allowed PRIME to answer challenging queries effectively.</p>", "authors": [{"name": "Alon Mishne", "author_profile_id": "81548290556", "affiliation": "Technion, Haifa, Israel", "person_id": "P3856225", "email_address": "amishne@cs.technion.ac.il", "orcid_id": ""}, {"name": "Sharon Shoham", "author_profile_id": "81333491015", "affiliation": "Tel Aviv-Yaffo Academic College, Tel Aviv, Israel", "person_id": "P3856226", "email_address": "sharon.shoham@gmail.com", "orcid_id": ""}, {"name": "Eran Yahav", "author_profile_id": "81100285431", "affiliation": "Technion, Haifa, Israel", "person_id": "P3856227", "email_address": "yahave@cs.technion.ac.il", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384689", "year": "2012", "article_id": "2384689", "conference": "OOPSLA", "title": "Typestate-based semantic code search over partial programs", "url": "http://dl.acm.org/citation.cfm?id=2384689"}