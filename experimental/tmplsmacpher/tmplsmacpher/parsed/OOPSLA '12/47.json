{"article_publication_date": "10-19-2012", "fulltext": "\n Energy Types Michael Cohen Haitao Steve Zhu Senem Ezgi Emgin Yu David Liu Department of Computer Science \nSUNY Binghamton Binghamton NY 13902, USA {mcohen3,hzhu1,semgin1,davidL}@binghamton.edu Abstract This \npaper presents a novel type system to promote and facilitate energy-aware programming. Energy Types is \nbuilt upon a key insight into today s energy-ef.cient systems and applications: despite the popular perception \nthat energy and power can only be described in joules and watts, real-world energy management is often \nbased on discrete phases and modes, which in turn can be reasoned about by type systems very effectively. \nA phase characterizes a distinct pattern of program workload, and a mode represents an energy state the \nprogram is expected to execute in. This paper describes a programming model where phases and modes can \nbe intuitively speci.ed by programmers or in\u00adferred by the compiler as type information. It demonstrates \nhow a type-based approach to reasoning about phases and modes can help promote energy ef.ciency. The \nsoundness of our type system and the invariants related to inter-phase and inter-mode interactions are \nrigorously proved. Energy Types is implemented as the core of a prototyped object\u00adoriented language ET \nfor smartphone programming. Prelim\u00adinary studies show ET can lead to signi.cant energy savings for Android \nApps. Categories and Subject Descriptors D.3.3 [Programming Languages]: Language Constructs and Features; \nC.0 [Com\u00adputer Systems Organization]: General Hardware/Software Interfaces Keywords Energy Ef.ciency, \nEnergy-Aware Software, Type Systems 1. Introduction There is a long history of designing type systems \nto improve software quality, such as robustness, reliability, and security. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, \nUSA. Copyright &#38;#169; 2012 ACM 978-1-4503-1561-6/12/10. . . $10.00 As we look forward, energy ef.ciency \nis increasingly loom\u00ading large as a critical software metric. From cloud comput\u00ading servers, to sensor \nnetworks, to iPads and Droids, new hardware platforms rede.ne what acceptable software is occasional \ncrashes may be tolerated, but unacceptable are electricity bills in an astronomical amount for a data \ncenter, or battery life of just a few hours for a smartphone. Prior re\u00adsearch on energy ef.ciency concentrates \non innovations in VLSI (e.g. [7]), architectures (e.g. [17]), operating systems (e.g. [38]), and compiler \noptimizations (e.g. [18]). A much less explored path is how innovations on programming mod\u00adels [4, 30, \n34] can help build energy-friendly software, and in particular, how programming language technologies \ncan help reason about energy management. To some extent, the lack of development in reasoning energy-aware \nsoftware is understandable. First, energy is measured in joules and watts continuous values (or their \n.oating-point number representations) that are often un\u00adfriendly to reasoning techniques. Second, energy \nconsump\u00adtion is a combined effect of many hardware components such as CPUs, caches, DRAMs, I/O devices \n and they of\u00adten interact in complex ways so that energy consumption is impossible to precisely estimate. \nThird, unlike lower-layer solutions where effectiveness can be quanti.ed unambigu\u00adously e.g. this CMOS \ncircuit contributes to an energy saving of 0.31 \u00b5W . innovations on language designs as\u00adsume a rational \nprogrammer, and the effectiveness depends on the programmer and the nature of the program. This paper \npresents Energy Types, a practical type sys\u00adtem to reason about energy-aware software. Instead of di\u00adrectly \nreasoning about joules and watts over complex hard\u00adware an ambitious task perhaps impossible to get \nperfectly right and practical Energy Types reasons about phases and modes, two recurring motifs in modern \nenergy-aware soft\u00adware. 1.1 Phases as Types An established fact in architecture research is that a program \nusually demonstrates phased behaviors of energy consump\u00adtion ([8, 17]): the rate of energy consumption \n(i.e. power) .ows and ebbs in phases, steady within but drastically differ\u00adent across. Intuitively, program \nfragments with different log\u00adical goals have distinct workloads, which yield distinct pat\u00adterns of CPU \nusage, memory accesses, cache misses, and I/O operations, and eventually lead to a distinct pattern of \nenergy consumption. Program phase characterization determining the number of phases, and the boundary \nof each provides important insight into understanding program energy con\u00adsumption behaviors, and further \nguides energy management techniques for better decision-making. Existing phase pre\u00addiction techniques \n(e.g. [16, 31]) usually combine dynamic monitoring and pro.ling with sophisticated classi.cation or prediction \nalgorithms.  Phase Support in Energy Types Energy Types brings the knowledge of programmers into the \nequation. We argue that a programmer often intuitively knows the logical sub-goals of her program, which \noften corresponds to phases with distinct patterns of energy consumption. For example, it is not dif.cult \nfor a programmer to realize that her Mars landing game is composed of a (CPU-intensive) physics calculation \nphase and an (I/O-intensive) 3D rendering phase. Programmers in Energy Types can label data and opera\u00adtions \nwith phase type quali.ers, directly specifying phased behaviors by relating computational elements to \nphases of energy consumption. Energy Types helps programmers pre\u00adserve a consistent view of phase placement \nby enforcing phase distinction: each data or operation must commit to i.e. be typed with one and only \none phase. The type system further enforces phase isolation: any cross-phase interaction must be accompanied \nwith explicit type coercion. There are two important energy ef.ciency bene.ts that result from building \nphases into an energy-aware program\u00adming language. First, hardware-level energy management procedures \noften need to adjust the status of hardware (to save energy) based on the status of the software runtime. \nPhase type quali.ers are invaluable at this software/hard\u00adware interface: ENERGY MANAGEMENT BENEFIT 1 \n(Guiding Hardware through Types). Phase type information can be used to guide hardware-level energy management, \nbecause it taps both the knowledge of the programmer through type decla\u00adration, and the ability of a \ntype system to propagate phase information. Concretely, the host language of Energy Types ET is equipped \nwith a dynamic semantics that supports CPU dy\u00adnamic voltage and frequency scaling (DVFS) [29] directed \nby phase type information. As one of the most time-honored hardware-level energy management strategies, \nDVFS is a trade-off between energy and speed. It is most advantageous to scale down the CPU frequency, \nso that energy can be saved, but only at a time when the CPU is least busy, so that performance degrades \nthe least. Its effectiveness is largely dependent upon choosing the right scaling point ( where to scale \n) and the right scaling factor ( what frequency/voltage to scale to ). We offer a language design, accompanied \nby an experimental validation, to demonstrate phases as types can provide answers to both questions that \nyield energy savings. Thanks to the type system enforcement of phase distinc\u00adtion and phase isolation, \nphases as types further promote phased behaviors. In Energy Types, intra-phase object in\u00adteraction say \nmessaging is supported in the same syntax as in the familiar Java model, whereas any inter-phase in\u00adteraction \nrequires explicit type coercion, an inconvenience programmers would rather avoid. Given the requirement \nof phase isolation, the programmer is motivated to re-factor the code to cluster calculation operations \nseparately from ren\u00addering operations, instead of intertwining code with distinct patterns of system \nusages. To summarize: ENERGY MANAGEMENT BENEFIT 2 (Promoting Phased Behaviors). Phase distinction and \nphase isolation promote the construction of programs with more stable power con\u00adsumption within phases \nand fewer phase changes, both ben\u00ade.cial for phase-based energy management.  1.2 Modes as Types Application-speci.c \nenergy savings are another important source for software energy ef.ciency. It has been observed that \n[4, 26, 30, 34] applications can often be programmed in different ways. All are acceptable, but different \nchoices may consume different levels of energy and be best used in different energy states. For example, \na programmer may decide to render a high-.delity Mars lander image when her smartphone is fully charged, \nand only a low-.delity image when the battery level of the phone is below 20%. Mode Support in Energy \nTypes Energy Types builds on this insight, and offers programmers the capability to asso\u00adciate data and \noperations with mode type quali.ers. Each mode is a programmer-de.ned and typed energy state, in\u00addicating \nthe expected energy usage context associated with speci.c data or operations, such as battery high and \nbat\u00adtery low. Allowing for programmer mode declarations is in sync with our philosophy on constructing \na practical static reasoning system for energy management: instead of painstakingly determining why rendering \na high-.delity im\u00adage consumes more energy than a low-.delity image through advanced static analysis, \nwe believe programmers intuitively know. The goal of Energy Types is thus to assist rational yet imperfect \nprogrammers to consistently assign energy con\u00adsumption expectations to program elements. Building modes \ninto an energy-aware programming lan\u00adguage leads to two bene.ts toward energy ef.ciency: ENERGY MANAGEMENT \nBENEFIT 3 (Encouraging Appli\u00adcation-Speci.c Energy Savings). The process of thinking how many modes should \nbe supported, and how data and operations should be assigned to each mode is the same as designing application-speci.c \nenergy-saving strategies.  ENERGY MANAGEMENT BENEFIT 4 (Regulating Energy States). The type-based approach \nregulates what program fragments can be used under different energy states, which on the high level is \naligned with the programmer intuition of constructing energy-aware programs friendly to distinct energy \nstates. To achieve Bene.t 4, our type system enforces a water\u00adfall invariant: a program element associated \nwith a higher energy state one with more availability for energy con\u00adsumption may access an element \nwith a lower energy state, but not vice versa. This design decision is driven by the requirement of energy-aware \nprogramming: invoking a function associated with a higher energy state often more energy-consuming \nwhen the system is in a low energy state may drain the system energy source, an energy error.  1.3 Energy \nTypes Energy Types is a foundational study of the fabrics of energy-aware software, abstracting the recurring \nthemes of energy management as the reasoning of phases and modes. The type system and its host language \nET are one of the .rst efforts to build common energy management strategies directly into a programming \nlanguage, and guarantee the consistency of the programmers energy management inten\u00adtions during their \npractice of energy-aware programming. In addition to Bene.ts 1-4, Energy Types inherits some bene.ts \nfrom type system solutions which may be appeal\u00ading for energy-ef.cient computing in general: it is portable \nand platform independent; it promotes compositional rea\u00adsoning of energy management behaviors; and it \nserves as lightweight and consistent documentation throughout the of\u00adten iterative process of energy \noptimization. This paper makes the following contributions: It introduces one of the .rst systematic \nstudies on static reasoning for energy-aware software, in the shape of a type system that has been proven \nsound;  It formulates invariants related to recurring themes of energy management as properties of phases \nand modes, with their enforcement on the language level formally proved;  It provides a small-step semantics \nthat demonstrates how traditional energy-saving strategies such as DVFS can be type-directed, and a formal \nillustration on type-based scaling factor selection;  It offers an easy-to-use programming model that \nhas been implemented as a prototyped compiler, and evaluated through programming Android Apps.  The \nrest of the paper is organized as follows. Sec.2 is an informal discussion on Energy Types and ET. The \nformal Energy Types system is presented in Sec. 3 and the imple\u00ad mentation of ET and its evaluation is \npresented in Sec. 4. The last sections describe related work and future work. 1 2 3 4 5 6 7 8 9 11 12 \n13 14 15 16 17 18 19 21 22 23 24 25 26 27 28 29 31 32 33 34 35 36 37 38 39 41 42 43 44 45 46 47 48 49 \n51 52 53 54 55 56 57 58 59 61 62 63 64 65 66 67 68 69 71 72 73 74 phases { graphics <cpu main ; main \n<cpu math ; }modes { hifi <: full ; lofi <: hifi ; }class Main { main () { Recognizer rz = new Recognizer \n(); View v= adapt ( new View ()); while ( true ) { Gesture g = processInput (); int result = rz.recognize(g); \n v. paintOverlay ( adapt [graphics] g, result ); } } Gesture processInput () { ... return new Gesture \n@phase (math )(); }}class Recognizer { Matcher@mode( full ) m1 = newM(0.995); Matcher@mode( hifi ) m2 \n= newM(0.9); Matcher@mode( lofi ) m3 = newM(0.5); DistCal d1 = new Cosine@mode( hifi )(); DistCal d2 \n= new Euclidean@mode( lofi )(); int recognize ( Gesture g) { mswitch ( batteryState ()) {case full : \nreturn m1.match(g, d1); case hifi : return m2.match(g, d2); case lofi : return m3.match(g, d2); } } Matcher \nnewM( double p) { return adapt ( new Matcher(p )); } modev batteryState () {if (Util . batterycharged \n()) return full ; if ( Util . batterylevel () > 0.3) return hifi else return lofi ; }}class Matcher \n@phase ( math ) { double precision ; Gesture[] ps = ...; // recognizable patterns Matcher ( double precision \n) { this . precision = precision ; } int match (Gesture g, DistCal dc) {Gesture gs = sampling(g, precision); \nfor ( int i=0; i< ps.length; i++) { if ( dc.compute(gs, ps[i]) < THRES ) return i; } } ... } class View@phase \n( graphics ) {Gesture[] p = ...; // recognizable patterns void paintOverlay(Gesture g, int result ) { \npaint (g); paint(p[result ]); } void paint ( Gesture g) { Util .draw(g. Coordinates ()); }}class DistCal \n{ ... }class Cosine extends DistCal { ... }class Euclidean extends DistCal { ... }class Gesture { ... \n}static class Util { boolean batterycharged () { ... } double batterylevel () { ... } void draw ( int \nco ) {} } Figure 1. A Gesture Recognition Program in ET  2. Energy-Aware Programming in ET ET is a \nJava-like object-oriented language for smartphone programming an immediate testing ground we choose \nfor Energy Types. A sample ET program is illustrated in Fig. 1. Key language features are highlighted \nin red. This program, inspired by android.gesture APIs, applies pattern recognition techniques to determine \nwhat gesture the .ngers of a smartphone user perform on the touch screen. The core program logic follows \nthe predictable input-recognize-render sequence, in L. 8 -10. The recog\u00ad nition logic is encapsulated \nin the Recognizer class, which selects different recognition algorithms based on the battery state of \nthe smartphone (L. 25 -29). The math\u00ad ematical core of the recognition is implemented by class Matcher, \nwhich can be instantiated with different recogni\u00adtion precision settings and different mathematical rou\u00adtines \nto compute distances in a vector space, such as either in Cosine distance or in Euclidean distance. The \nPre-ET Era To motivate the need for ET, let us imag\u00adine what a green-conscious Android Java programmer \nwould do in her attempt of energy-aware programming. First, an informed programmer especially one from \nar\u00adchitecture/VLSI/OS communities might know that pro\u00adgrams of different workloads often react to CPU \nscal\u00ading differently, in that scaling down CPU frequency/volt\u00adage of a I/O-bound part of the program \nsuch as the paintOverlay method, may lead to energy savings with little performance penalty. Her plan \nthus is to insert a pair of DVFS system calls in the source code, one before the mes\u00adsaging on L. 10 \nto scale down the CPU (say she decides to use 300Mhz) and then the other right after the messaging to \nscale the CPU back up to the previous level. The ensuing program might be faced with a number of usability, \nef.\u00adciency, and robustness issues, in that such DVFS calls might be: platform-dependent, e.g. the same \nprogram might be de\u00adployed to a machine that does not support 300Mhz  redundant, e.g. both the message \nsender and the receiver insert the same DVFS calls to err on the safe side  unbalanced, e.g. DVFS is \nused to scale the CPU down before paintOverlay messaging, but forgotten to be used afterwards to scale \nthe CPU back up  inconsistent e.g. the View object is thought to be I/O in\u00adtensive at some program point, \nbut may .ow to a variable used as if it were CPU-intensive  Second, a green-conscious programmer may \nalso apply to application-speci.c savings, such as creating different Matcher objects similar to L. \n19 -L.21 but without the quali.ers each for a different battery level. What is required for her is to \nmemorize the energy consumption traits for individual program fragments m1, m2, m3 in the program and \nhopefully not accidentally use a m1 or m2 object when the system is low on battery. This task may appear \nto be simple for a program as short as Fig. 1, but not obviously so when the program grows larger, where \nobjects references are routinely passed around, stored on the heap, and aliased. This is not to mention \nthe fact that the dif.culties de\u00adscribed above are indeed the privileges of advanced Android programmers. \nThe majority of Apps programmers are not even aware of the options of energy-aware programming in the \n.rst place. It is these kinds of problems that ET ad\u00addresses. Phases and Modes The most noticeable features \nof ET are the optional type quali.ers of phases and modes. Instead of thinking how low-level CPU frequencies \nshould be scaled, ET programmers are encouraged to think how CPU-intensive each program fragment is. \nEither a class (L. 56) or an object (L. 15) can be associated with a phase quali.er to characterize such \nintensity. In addition, ET pro\u00adgrammers can declare a partial order <cpu, meaning less CPU-intensive \nthan, through the phases declaration. For example, L. 1 says that phase graphics is less CPU\u00adintensive \nthan the phase of the bootstrapping code with a built-in phase named main, which in turn is less CPU\u00adintensive \nthan phase math. This relation encourages pro\u00adgrammers to contribute in their knowledge, so that DVFS \ncalls are inserted automatically, and the decision of scaling down/up is conducted by the compiler based \non the par\u00adtial order. Based on our experience, aligning a logical pro\u00adgram unit with distinct CPU characteristics \nis not hard. For instance, the graphics/math differentiation here is in fact a common pattern in game \nprogramming. In Sec. 3.3, we show how this partial order may affect our choice of frequency scaling factors. \nIn addition, the ET programmer does not need to implic\u00aditly memorize that m2 is more energy-consuming \nthan m3. She instead can explicitly indicate in L. 20 that the m2 ob\u00adject has a mode called hifi and \nin L. 21 that the m3 ob\u00adject there has a mode called lofi. In addition, by using the modes construct \nin L. 2, the programmer indicates that ob\u00ad jects quali.ed by lofi should be used when a lower energy \nconsumption is expected. Indeed, modes naturally fall into a lattice, each indicating a level of expected \nenergy consump\u00adtion. The <: relation speci.ed in modes construct is a sub\u00adtyping relation. This can be \nexplained in the same fashion where the waterfall invariant was explained in Sec. 1: when the program \nis expecting to interact with a high energy\u00adconsumption object, it is OK to end up interacting with a \nlow energy-consumption object, but not vice versa. The run-time manifestation of a phase is a portion \nof the execution with a relatively stable yet distinct intensity of CPU usage. The run-time manifestation \nof a mode is a portion of the execution speci.cally for a particular energy state. When they are represented \nin programs, especially in an object-oriented setting, both are represented by a network  Figure 2. \nAn Illustration of the Gesture Recognition program in Fig. 1 of objects interacting with each other. \nThis view does not lie far apart from the foundational view of object orientation: each object is an \nencapsulation of data and their related op\u00aderations; together, they are composed as a program, in the \nform of a network of messages. In that light, by labeling an object with a particular phase or mode quali.er, \nwe are not only labeling data, but also (perhaps more importantly) de.ning the nature of the interactions \nthe object is participat\u00ading in through sending/receiving messages. It is these object interactions we \nneed to investigate in more detail next. Healthy Interactions Overall, our type system reasons about \nphases and modes through a core reminiscent of region types [36], with additional invariants on healthy \ninter\u00ad phase and inter-mode interaction. To set the analogy with region types further, Energy Types on \nthe high level can be imagined as assigning objects (or expressions that represent them) to the intersection \nof a phase region and a mode region. Such declarations pigeonhole objects. Each object by declaration \nor inference lives in the intersection of one mode hole and one phase hole , as seen in Fig. 2. What \nis more unique to Energy Types is how objects in these pigeonholes interact healthily in the presence \nof energy\u00adaware programming. The region type formulation provides natural support for both phase distinction \nand phase isolation we mentioned in Sec. 1. As a result, an object may freely access other ob\u00ad jects \nbelonging to the same phase (such as messaging and .eld access) their interactions together form the \nexecution sequence with stable CPU usage but when cross-phase ac\u00adcess is needed, programmers need to \nexplicitly allow it. This in ET is represented as a phase coercion operator, the adapt expression. For \nexample in L. 10, a Gesture object g is adapted to the graphics phase, so that it can be accessed freely \nwithin the paintOverlay method of an object of graphics phase. A common pattern of adaptation is to adapt \nan object to the phase of the enclosing object. As a convenience, we allow programmers to elide the phase \nname in this case. L. 32 is one such example. Adaptation in ET is static type coercion with no run-time \noverhead. Similarly, objects with the same mode can also interact freely their interactions together \nform the execution se\u00adquence speci.cally prepared for an energy state of the sys\u00adtem. For objects with \ndifferent modes to interact, the water\u00adfall invariant we introduced in Sec. 1 applies. For example in \nFig. 2, the Matcher object m2 is sending a message to the Euclidean object d2, but the former is of mode \nhifi, whereas the latter is of mode lofi.  Without additional support, a program subject to the waterfall \ninvariant would drop further and further to a lower mode. This clearly does not align with our notion \nthat smartphones are rechargeable, and a large number of today s devices are powered by renewable power \nsources. The mswitch expression is designed to help programmers re-align the system energy state with \nthe mode of current context a type coercion on the mode of the context. Based on the value mswitch guards \non, the mode of the enclosing context can be coerced to a new one. For instance, L. 25-29 coerces the \nmode of the context to either full, hifi, or lofi based on the return value of batteryState. To facilitate \nthis programming pattern, we allow modes to be values, and their type is modev, as in L. 34. Overall, \non the spectrum of inter-phase/mode interac\u00adtions, where no interaction and arbitrary interaction on \ntwo ends, Energy Types takes a middle-of-the-road model: no interaction unless explicitly speci.ed. This \nis more pro\u00adnounced for phases, where cross-phase messaging requires an adapt a hassle that programmers \ntry to avoid but cannot live without because phase isolation otherwise would dissect the program into \ndisjoint components. For modes, cross-mode messaging from a higher energy state to a lower one is implicitly \nallowed thanks to the waterfall in\u00advariant, but not the other way around. mswitch plays the role of enabling \nmessaging in that direction, but only when pro\u00adgrammers explicitly intend so. Inference We believe green-conscious \nprogrammers are receptive to changes to their coding habits, but may only be willing to do so if changes \nare minimalistic and incremental. This belief in.uenced our implemented language ET to take the implicit \nform of parametric polymorphism as default. Type information such as @phase or @mode declarations can \nappear anywhere a type may appear, but can be elided anywhere a programmer chooses to. In this light, \nET can be viewed as a polymorphic system heavy on type inference but light on declaration. To see parametric \npolymorphism at work, note that our algorithm is able to analyze whether dc.compute in L. 50 conforms \nto the waterfall invariant separately for the three invocations at L. 26-28. Inference is a double-edged \nsword with standard trade\u00adoffs: the more helpful the language is able to save program\u00admer annotation \nefforts, the less helpful it is to produce modu\u00adlar program speci.cations. It is our belief that in the \ncontext of energy-aware programming a nascent practice where any additional programming task is overhead \nfor average Apps programmers we as language designers should start with solutions minimalistic in syntax. \nAs an effort to sepa\u00adrate this implementation decision from foundations, the for\u00admal type system presented \nin this paper is based on the more standard explicit form of parametric polymorphism to eluci\u00addate ideas. \nEnergy Types with inference is fully formalized in a technical report [37]. Formal Guarantees Energy \nTypes is a sound constraint\u00adbased type system. Translating this to energy management, it ensures that \na consistent view of the programmer s energy characterization and energy management intentions is main\u00adtained. \nFor instance, it would lead to a type error if a pro\u00adgrammer in one part of the program characterizes \nan object as phase graphics mode hifi, but in another part of the program forgets and uses the same \nobject as if it be\u00adlonged to phase math mode lofi. Type preservation (subject reduction) from a temporal \nangle tells an intuitive fact about what a program should behave: its execution should be stable in maintaining \nits phase and mode characterization (the types), except when explicit phase change or mode change happens. \nA typechecked ET program is free of two kinds of errors: (1) an object accesses (.eld access or messaging) \nto another object belonging to a different phase without explicit adapt; (2) an object sends a message \nto another object in a higher mode without explicit mswitch; The details of these guaran\u00adtees will be \nelaborated in Sec. 3.4.  Unfortunately but predictably, Energy Types does not have the guarantee of \nsaving energy. Indeed, no magical technologies be it out of computer science, chemical engi\u00adneering, \nmaterial science, or sub-atomic physics can guar\u00adantee energy savings. The importance of ET is to provide \nformal guarantees to make sure the principles of energy management are promoted and abided by, which \nin turn pro\u00adduces high-quality energy-aware software with effective en\u00adergy management, and ultimately \nleads to energy savings. ET in the Context of Energy-Ef.cient Computing The in\u00adnate drawback of a programming \nlanguage approach es\u00adpecially through the lens of solutions from lower compute stacks is that it can \nnever prevent a rogue programmer. For instance, a rogue programmer, for the sake of proving a point, \ncould intentionally declare lofi to an object known to lead to heavy energy consumption, and systematically \nuse this object as if it consumed little energy. This is analogous to scenarios such as an information \n.ow language user inten\u00adtionally declares a password string with a low-security label. ET is however \nan asset to a good-intentioned but imper\u00adfect programmer. Bene.t 1 allows programmers to express their \nhigh-level knowledge relevant to low-level energy man\u00adagement. Bene.t 2 encourages programmers to refactor \ntheir code to be friendly for energy management. Bene.t 3 allows programmers to write code adaptive to \ndifferent energy state. Bene.t 4 discourages the imperfect programmers from writ\u00ad ing code that may unnecessarily \ndrain energy. Overall, the type system provides formal guarantees for effective energy\u00adaware programming. \nThe roles of ET and existing dynamic approaches are complementary. To construct a primitive feedback \nloop from  . ::= PO MO C program ' PO ::= p <cpu pphase decl ' MO ::= m <: mmode decl C ::= class \nc . extends t{KFM } class K ::= c(t fd){super(fd); this.fd:=fd} constructor F ::= t fd .eld M ::= . t \nmd(t x){e} method e ::= x | e.fd | new t(e) expressions | e.md(.)(e) | (t)e | adapt[f]e | mswitch (e){m \n: e, e'}p . PCONST phase name m . MCONST mode name c . CN .{Object, Main} class name md . MN .{main} \nmethod name fd .eld name x . VAR variable name Figure 3. Energy Types Abstract Syntax dynamics, imagine \nan iterative development process where a programmer incrementally adds phase and mode decla\u00adrations to \na program, each after running an energy pro.ler to help her make decisions. From that perspective, the \nmild level of annotations of ET can help pro.ler users consis\u00adtently document the traits of energy consumption, \nfollowing the types as documentation slogan. On the .ip side, a pro\u00adgramming language approach can broaden \nthe optimization space of energy ef.ciency by bringing in the programmer knowledge into the equation. \nOverall, the emphasis of this paper is to offer a type system approach to look at energy management, \nnot to trumpet a purely static approach. It is interesting future work to see whether Energy Types can \nbe extended with pro.le-guided typing [11] or hybrid typing [2, 3, 20, 32] to integrate the static and \nthe dynamic. 3. The Formal System We now present Energy Types, the formal core of ET. 3.1 Abstract Syntax \nand Preliminaries The abstract syntax is de.ned in Fig. 3 where notation X represents a sequence X1,...,Xn \nof some n. A program . is de.ned as phase ordering declarations PO, mode ordering declarations MO, as \nwell as classes C . The .rst two parts correspond to the phases and modes declarations in the con\u00adcrete \nsyntax. The formalized object-oriented features resem\u00adble Featherweight Java [14]. We follow their convention \nof using the highly stylized constructor de.nition (K ), encod\u00ading assignment and statement sequencing \nas local method invocations, omitting .eld update, and choosing Object as the name of the inheritance \nroot. In the mswitch (e){m : e, e'} expression, m : e are all the case s de.ned in the con\u00adcrete syntax; \ne' is the default case when none of m matches the value of e. The bootstrapping expression is enclosed \nin class Main and method main. We use metavariables c, md, fd, x, p, and m to represent names of classes, \nmethods, .elds, variables, phases, and modes. this . VAR. Type-related el\u00adements, such as t and ., will \nbe formally de.ned shortly in Sec. 3.2. We choose to formalize an explicit form of parametric polymorphism \nin this short presentation. As a result, the ab\u00adstract syntax here carries additional type annotations \n such as . (whose de.nition we shall see soon) that the imple\u00admented language does not need. The gap \nbetween the syntax here and the programmer syntax is .lled by a polymorphic type inference, which has \nbeen implemented in ET. We de\u00adscribe this relatively independent topic toward the end of Sec. 3.2. This \npresentation choice also allows our formal system to bear greater resemblance to other classic systems \nof parametric polymorphism in object-oriented languages such as Featherweight Generic Java (FGJ) so \nthat our dis\u00adcussion can be more focused on elucidating energy-related features. Notations For any binary \nrelation R, we use dom(R) to represent its domain, range(R) to represent its range, whole(R) to represent \nthe union of the domain and the range, (R)* as the re.exive and transitive closure of R, and R |S to \nrepresent the restriction of binary relation R to set S. The ubiquitous X, Y notation is used for concatenation \nof sequences X and Y . The concatenation is .at in that we do not create sequences of sequences. We use \nE to represent an empty sequence, and the element itself to represent a (degenerate) 1-element sequence. \nWhen no confusion arises, we liberally treat a sequence as a set, and apply common operators such as \n., .. We call a sequence in the form of [a1 . b1,...an . bn] as a mapping sequence. When order does not \nmatter, we also view a mapping sequence as a binary relation, i.e. {(a1,b1),..., (an,bn)}. Given two \nmapping sequences X and Y , binary operation X l Y is de.ned as X, Y if dom(X) n dom(Y )= \u00d8; it is unde.ned \notherwise.  3.2 The Type System Types Type-related elements are de.ned in Fig. 4. A type can either \nbe an object type c(.) or a primitive type modev for mode values. If we take the standard view of a type \nas a characterization of values, the particular form of c(.) aligns with our high-level intuition that \nany two objects instanti\u00adated from the same class c may have drastically different energy consumption \ncharacteristics, depending on how they are initialized, and what objects they interact with. Con\u00adstruct \n. captures this notion, with each element in its phase sublist (f) describing the phase characteristics \nof an object the current object interacts with, and each element in its mode sublist (\u00b5) describing the \nmode characteristics. As a special case, the .rst element in f and that of \u00b5 describe the phase and mode \nof the current object. For that purpose,  t ::= c(.)| modev type . ::= f; \u00b5 energy characterization \nparams . ::= (f; \u00b5) context object characterization f ::= p | pt phase \u00b5 ::= m | mt mode pt phase type \nvariable mt mode type variable S ::= T; O constraints T ::= = f ' f ~phase constraints ' O ::= \u00b5<:\u00b5 mode \nconstraints . ::= .;S energy speci.cation Figure 4. Type Elements we use metavariable . to represent \nthe energy characteriza\u00ad def tion of the current object, and further de.ne ethis(.)= (f; \u00b5) where . = \n(f, f; \u00b5, \u00b5). For example, a declared type Matcher @phase(maths) @mode(hifi) in the source code can be \nencoded in the formal system as: Matcher(maths,f1,...,fm; hifi,\u00b51,...,\u00b5n) where f1,...,fm and \u00b51,...,\u00b5n \nare characterizations for objects the Matcher object interacts with (inferred by the ET compiler). Type-theoretically, \nthis syntactical form in\u00addicates that Energy Types belongs to the family of System F type systems (e.g. \n[14, 27, 36]). The non-trivial observa\u00ad tion in this particular instance is that energy consumption for \ncode is fundamentally parametric. Type Constraints Unlike System F<: systems (e.g. FGJ) where constraints \ncome only in one form (associating type variables with upper bounds), the type constraints of Energy \nTypes come in two forms to re.ect the different natures of phases and modes. Constraint f ~= f ' says \nf and f ' must be uni.ed, intuitively meaning they must be representations of the same programmer-declared \nphase in PO. Constraint ' \u00b5<:\u00b5 says \u00b5 must represent a mode less energy-consuming than that of \u00b5 '. Sets \nT and O are used to hold the two kinds of constraints respectively and we use S to represent both. Energy \nSpeci.cation The combination of energy charac\u00adterization parameters (.) and the constraints over them \n(S) form the speci.cation of an object s energy speci.cation, represented by metavariable .. When . appears \nin the class de.nition C , its energy characterization parameters is com\u00adposed of type variables pt \nfor phases and mt for modes which serve as type parameters that can be customized for different instances \nof the same class, the instantiation in parametric polymorphism. De.nition .1 finst . . .2 says that \nparametric energy speci.cation .2 can be instantiated by energy characterization parameters . under energy \nspeci\u00ad.cation .1. class c .' \u00b7\u00b7\u00b7 . .. finst . . .' (WF-TClass) . fwft c(.) . = f; \u00b5 . finst . . E; \u00d8; \n\u00d8 (WF-TTop) . fwft Object(.) (WF-TModev). fwft modev Figure 5. Type Well-Formedness .= PO MO C T re.exive \nand transitive T |PCONST identity whole(T) . whole(PO) . f (WF-PSet) f; \u00b5 fwfp T .= PO MO C O re.exive \nand transitive MO =O |MCONST whole(O) . whole(MO) . \u00b5 (WF-MSet) f; \u00b5 fwfm O . fwfp T . fwfm O (WF-Spec) \nfwfs .; T; O Figure 6. Energy Speci.cation Well-Formedness .i = .i;Ti;Oi . .1 T2{./.2}. T1 O2{./.2}. \nO1 .1 finst . . .2 where {. ' /.} is standard type variable substitution with being either a T, O, \nor t. For . = pt; mt and . ' = f; \u00b5, the operator substitutes every occurrence of pti with fi and every \noccurrence of mtj with \u00b5j . The partial function is de.ned iff |pt| = |f|, |mt| = |\u00b5|, pt n f = \u00d8, mt \nn \u00b5 = \u00d8. ' Predicate (f; \u00b5) (f ; \u00b5 ' ) holds iff f . f ' . whole(PO) ' and \u00b5 . \u00b5 . whole(MO) where .= \nPO MO C . Following the FGJ, all de.nitions and rules in this paper are implicitly parameterized by the \nimmutable code base .. Well-formedness Judgment . fwft t says type t is well\u00adformed under ., de.ned in \nFig. 5. Judgment . fwfp T says phase constraint set T is well-formed under . and . fwfm O says mode constraint \nset O is well-formed under .. Judgment fwfe . says energy speci.cation . is well-formed. Their de.nitions \nare de.ned in Fig. 6. The most important rules are perhaps (WF-PSet) and (WF-MSet). (WF-PSet) characterizes \nthe essence of phase distinction : any two phases with distinct names as declared in PO should never \nunify the restriction of T to constant phase names is thus an identity relation. (WF-MSet) says that \nthe ordering de.ned by MO must not be violated the restriction of O to constant mode names indeed yields \nMO. In addition, both rules further require that all constant names used in constraints have been declared \nand all type variables are bound by the current energy characterization parameters.  (T-Var) G;. f x \n: G(x) fields(t)= t fd G; . f e : t . fwft t (T-New) G; . f new t(e): t ' G; . f e : t . fwft t (T-Cast) \nG; . f (t )e : t G; . f e : t .= .; T; O f. (T-Adapt) G; . f adapt[f] e :(t . f) G; . f e : modev .' \n=. . m ' G; .' f e : t G; . f e : t (T-Mswitch) G; . f mswitch(e){m : e, e ' } : t G; . f e : t G; . \nf e : t{.0/. ' } mtype(md,t )=.' .(t . t ') . finst .0 . .' .= .; T; O .' = . ';T';O' phase(.) ~ = phase(t) \n. T mode(t )<:mode(.) . O (T-Msg) G; . f e.md(.0)(e): t ' {.0/. ' } G; . f e : t fields(t)= t fd .= .; \nT; O phase(.) ~ = phase(t ) . T (T-Field) G; . f e.fdi : ti ' G; . f e : t t<: t (T-Sub) ' G; . f e : \nt Figure 7. Expression Typing Expression Typing Expression typing is de.ned in Fig. 7. Judgment G; . \nf e : t , which means expression e has type t under typing environment G and energy speci.cation .. Typing \nenvironment G is de.ned as sequence x . t and G(x) as ti where xi = x and i is the right most position \nin G where x occurs. Notations such as G; . f e : t denotes G; . f e1 : t1, ... , G; . f en : tn. We \nde.ne def def ethis(c(.))= ethis(.) and ethis(.;S) = ethis(.). (S-Re.) f t<: t ' ''' f t<: t f t<: t \n(S-Trans) '' f t<: t class c . extends t \u00b7\u00b7\u00b7 . . .= . ';S (S-Class) f c(.) <: t {./. ' } Figure 8. Subtyping \nGiven ethis(.)= (f; \u00b5), we de.ne overloaded functions phase and mode as: def def phase(c(.))= f mode(c(.))= \n\u00b5 def def phase(.;S) = f mode(.;S) = \u00b5 (T-Adapt) and (T-Mswitch) both involve type coercion. (T-Adapt) \ncoerces the phase of the object, whereas (T-Mswitch) coerces the mode of the context. We designed the \ntwo expressions with coercions on opposite parties (con\u00adtext vs. object) because we found they happened \nto be the most natural way of programming: the adapt expression is used when the programmer intends to \nadjust the message receiver object to become compatible with the phase where it is used, whereas the \nmswitch is commonly used when the mode of the current context is readjusted based on the physical battery \nstate. The abbreviated adapt e expression we used in the ex\u00adample in Fig. 1 can be encoded as adapt[f] \ne where f = phase(.) adapting to the phase of the enclosing object. The mswitch expression is designed \nto resemble the Java\u00adlike switch expression to promote the common program\u00adming pattern that mode-adaptive \ncode is often multiplexed based on energy states. Evaluating an expression e under a particular coerced \nenergy context (say hifi) can be simply encoded as mswitch(hifi){hifi : e, e}. The object/con\u00adtext coercions \nare achieved by an overloaded . operator. Given . = f, f; \u00b5, \u00b5, the operator is de.ned as: def c(.). \nf ' = c(f ' ,f; \u00b5, \u00b5)'' def .;S . \u00b5 = f, f; \u00b5 ,\u00b5;S The rules that de.ne how objects interact are (T-Msg) \nand(T-Field). The most interesting aspect of (T-Msg) is per\u00adhaps the two constraints that capture the \nessence of water\u00adfall invariants. Constraint phase(.) ~phase(t) says the = phases of the message sender \nand the message receiver must unify, intuitively a manifestation of phase isolation. Con\u00adstraint mode(t)<:mode(.) \nsays that the receiver s mode must be a less energy consuming one than the sender s. In (T-Field), we \nfurther enforces phase isolation on public .eld ac\u00ad  ethis(.) = ethis(t) fwfs . F = t fd . fwft t,t \nM OK IN c, .,t constructorOK(K , c, F ,t) (T-Class) class c . extends t{KFM } OK .' = .;S .+.' fwft \nt,t x : t, this : c(.);.+.' f e : t ' override(md,t , ..(t . t )) (T-Method) ' . t md(tx){ e } OK IN \nc, .' ,t Figure 9. Class Typing cess. Removing this requirement does not affect soundness, but we .nd \nthe requirement helpful because a large number of cross-phase public .eld accesses as exhibited by many \nadapt s usually signify the need for more refactoring. The two rules use two FGJ standard functions: \nmtype(md,t) computes the signature for method md of object t , in the form of ..(t . t) where . is the \nenergy speci.cation associated with the method; fields(t) computes the .eld signatures for object t in \nthe form of t fd. These functions are delayed to the Appendix. Both instantiation-time and messaging-time \npolymorphism are supported. fields(t ) is also used for (T-New), object instantiation. (T-Cast) models \nJava-style casting. We do not re.ne this rule with a stupid cast warning [14] in this formalization, \nas it does not affect the type soundness result. Note that the casting expression is only meant for the \ncoercion of Java nominal types, not the coercion of phases or modes. The lat\u00adter goals should be achieved \neither via adapt and mswitch respectively. Our dynamic semantics (the dynamic check in\u00adserted for casting) \nwill ensure that any abuse of the casting expression for mode/phase coercion would fail. Indeed, the \n(t)e syntax we use here is only meant for facilitating the for\u00admalization; in the implemented language, \nthe programmer syntax for casting is (c)e. (T-Var) models variable typing. ' (T-Sub) is used for subtyping. \nSubtyping relation t<: t is de.ned in Fig. 8, including the predictable rules for re.ex\u00ad ivity (S-Re.), \ntransitivity (S-Trans), and Java-style nominal typing (S-Class). Program Typechecking A program .= PO \nMO C typechecks, denoted as fP ., iff PO is a partial order, MO is a lattice, and C OK for each C in \nC . The last part, class typing, is de.ned in Fig. 9. Condition ethis(.) = ethis(t) guarantees that in \nthe presence of inheritance, the superclass and the subclass assume the same phase and mode for objects \ninstantiated from the subclass. The binary + operator over energy speci.cations is de.ned as: ' e::=\u00b7\u00b7\u00b7 \n| cl(., e, e ') | e; e |< . | v runtime expressions v::=o | m value ' o::=obj(t,t , v) object value E::=8| \nnew t(..., v, E, e, . . . ) evaluation context | cl(., E,e) | E.md(.)(e) | o.md(.)(..., v, E, e, . . \n. ) | (t)E | adapt[p] E | mswitch(E){m : e, e} Figure 10. Run-Time Elements .i = pti; mti;Ti;Oi,i =1, \n2 pt1 n pt2 = \u00d8 mt1 n mt2 = \u00d8 def .1 +.2 =(pt1, pt2); (mt1, mt2); (T1 . T2); (O1 . O2) FGJ-like predicate \nconstructorOK(K , c,t fd,t) holds '' ' iff K = c(t fd ,t fd){super(fd ); this.fd:=fd} and ' '' fields(t)= \nt fd . Predicate override(md,t , ..(t . t)) holds iff function mtype(md,t ') is either unde.ned, or it \nis computed as ..(t . t). Additional ET Type System Features The type system implemented by ET supports \ntwo additional features: polymorphic type inference: all type variables in the en\u00adergy characterization \nparameters (.) and all type con\u00adstraints (S) are fully inferred. ' mode subtyping: we allow t to be a \nsubtype of t if t ' and t are identical except mode(t)<:mode(t '). Intu\u00aditively, this aligns with our \nintuition that in energy man\u00adagement, implicitly replacing a program fragment with a potentially less \nenergy-consuming one is OK, but not vice versa. The accompanying technical report [37] formalizes these \nfeatures, and the enriched type system is also proved sound. The type inference algorithm is a direct \nadaptation of the presented system in which the smallest number of con\u00adstraints for T and O that satisfy \nthe typechecking algorithm are collected. The challenging issue of determining the size of . is addressed \nthrough one key insight: the labels used to differentiate contexts in context-sensitive algorithms [25] \nserve as an ideal naming scheme for type variable refresh\u00ading/instantiation. Flexible mode subtyping \nrequires variance on parametric types. This is a thoroughly explored topic (e.g. [15]); ET s type inference \ndetermines variance by use and requires no annotations from programmers.  3.3 Dynamic Semantics . ' \nRelation e =. e denotes expression e is one-step reduced ' to e under context object characterization \n.. Runtime ex\u00adpressions and values are de.ned in Fig. 10.  Expression cl(., e, e ') is a function closure, \ni.e. expres\u00adsion e under context object characterization ., with destruc\u00ad '' tor e evaluated before the \nclosure is destructed. e; e is a standard expression continuation. Expression < . indicates that CPU \nshould be scaled to the frequency associated with context .. Values can either be a mode value, or an \nobject ' value obj(t,t , v) where t is the type of the object at its in\u00ad ' stantiation, t is its current \ntype, and v holds values of the .elds. Notation (.; e). denotes that computation e under . diverges. \nA reduction is stuck if a pre-condition is not sat\u00adis.ed. The initial con.guration of reduction for program \n., denoted as init(.), is (.main ; e) where .main = pmain ; mmain ; E; E and pmain and mmain are built-in \nphase/\u00admode names for the bootstrapping code. In addition, we have mbody(main(E), Main(E))= E.e under \ncode base .. The reduction rules are de.ned in Fig. 11. (R-Msg) and (R-MsgScale) de.nes the behavior \nfor messaging. Scaling is needed when the message sender and message receiver do not agree on the phases. \nIn both cases, ethis(t) keeps the original phase of the object o, i.e. the phase associated with its \ninstantiation point. The decision of scaling is made by comparing it with the phase of the context. If \nthe two agree such as the two are declared with the same phase (the de.nition of agreement will be given \nshortly) no scal\u00ading is needed. The FGJ standard function mbody(md(.),t) computes the method body of \nmethod md of object t with its type parameters instantiated with ., in the form of x.e where x are arguments \nthat may occur free in body e. The phase agreement relation is de.ned as: def (p; m)~(p ' ; m ' ) = SM(p)= \nSM(p ') where SM : PCONST . AF is a monotone function and AF represents a total order of available frequencies \nor frequency/voltage pairs. Intuitively, SM maps each distinct programmer-declared phase name to an available \nfrequency (in AF), which is speci.c to the hardware and OS. There is no need to scale iff the message \nsender s phase and the receiver s phase map to the same frequency. Since our reduction system does not \nexplicitly model CPU state, the scaling operator itself is de.ned as a no\u00adop, as in (R-Scale). The important \nissue of scaling factor selection however should not be ignored. Indeed, the short answer would be that \nthe CPU should scale to frequency SM(p ') given .' = (p ' ; m ' ). When the lattice of mode ordering \nhappens to fall into a total order, we in addition support proportional scaling, a case of interaction \nbetween phases and modes. Here, we proportionally set the range of CPU frequencies program phases can \nmap to based on mode information. Under a lower mode, the range of CPU frequencies to be assigned to \nphases should not include the highest ones when system energy state is low, the program should save \nas much energy as possible by not running code on the most expensive frequencies. Formally, this means \nthat the frequency should be used is SMm (p), where mapping SMm : PCONST . AFm is a monotone function \ns. t. AFm . AF, and for any m1<:m2 . (MO)* , 'AFm1 ' = 'AFm2 ' and LAFm1 _ = LAFm2 _, where '' and L_ \ncompute the greatest and smallest elements of the total order respectively and .= PO MO C . (R-MSwitchM) \nand (R-MSwitchD) de.ne the behavior of the mswitch expression. If there is a match for the mode value, \n(R-MSwitchM) applies and note that the mode of the context object characterization is coerced. Otherwise, \nthe default behavior applies according to (R-MSwitchD). (R-Adapt) coerces the phase of the object. (R-New), \n(R\u00adField),(R-Cast), (R-Closure) de.ne the standard behaviors of object instantiation, .eld access, casting, \nand closure elimination. (R-Context) reduces the redex in the evaluation context, whose de.nition appears \nin Fig. 10. We use notation E. to represent the evaluation context with the cl(., e, e ') expression \nimmediately enclosing the hole (8). Formally, E.[] is de.ned as cl(., E[],e). It should be noted that \nthe reduction rules here and the data structures they operate on are optimized for proofs, not for \nimplementation. For instance, we choose to have the function closure cl(., e, e ') to dynamically carry \nthe context ' object characterization ., and the heap object obj(t,t , v) to dynamically carry the coerced \ntype t '. As a result, (R-MswitchM), (R-Adapt), and (R-New) all need to dynami\u00adcally maintain these data \nstructures. In fact, both pieces of dynamically carried information can be statically inferred and hence \nsafely erased from the dynamic semantics. On the high level, the erasure of . from the construct of function \nclosure also says that the decision of scaling the choice between (R-Msg) and (R-MsgScale) can be statically \nde\u00adtermined, a fact that comes with no surprise considering our static approach. Since we are not presenting \nthe inference algorithm, we do not formally de.ne the erasure semantics here. Our implemented language \ndoes support full inference, ' and hence the erasure of . from cl(., e, e ') and t from ' obj(t,t , v). \n 3.4 Properties In this section, we describe several properties of ET. All proofs can be found in a \ntechnical report [37]. The typing rules for the auxiliary expressions are given in Fig. 12. Properties \nof the Type System The main property is soundness, which is proved via subject reduction and progress: \nethis(.) Lemma 1 (Subject Reduction). If G; . f e : t , e =. ' e ', then G; . f e : t . Also known as \nthe type preservation lemma, subject re\u00adduction from the angle of energy-aware programming guarantees \na computation, i.e. expressions over a reduction sequence, has to commit to one phase and one mode, a \ncom\u00adputational interpretation of stable energy consumption traits of program elements.  (R-Msg) (R-MsgScale) \n(R-Scale) (R-MswitchM) (R-MswitchD) (R-Adapt) (R-New) (R-Field) (R-Cast) (R-Closure) (R-Context) . o.md(.)(v \n')=. cl(.' ,e{v ' /x}{o/this}, v) if .' = ethis(t ), . ~ .' , any v . o.md(.)(v ')=. < .' ; cl(.' ,e{v \n' /x}{o/this}, < .) if .' = ethis(t ), . ~ .' false . < .' ; e =. e . mswitch (mi) {m : e, e0} =. cl((p; \nmi),ei, v) any v . ' mswitch (m ') {m : e, e0} =. e0 if m = mi . '' adapt[p ']o =. obj(t, t . p , v) \n. new t0(v ')=. obj(t0,t0, v ') o.fdi =.. vi . ' (t0)o =. o if t<: t0 . cl(.' , v,e0)=. e0; v .' E.' \n[ e1 ]=. E.' [ e2 ] if e1 =. e2 . ' for all rules: o = obj(t,t , v), mbody(md(.),t ')= x.e, and .= (p; \nm) Figure 11. Reduction Rules G; .' f e : t '' ethis(.')=. G;. f e : t (T-Cl) G; . f cl(., e, e '): t \nany t (T-Scale) G; . f < .: t m . whole(MO) .= PO MO C (T-Mv) G; . f m : modev G; . f v : t ' t = t . \nf for some f fields(t)= t fd (T-Obj) '' G; . f obj(t,t ,v): t '' G; . f e : t G; . f e : t (T-Cont) ' \nG; . f e; e : t Figure 12. Auxiliary Run-time Expression Typing ' De.nition 1 (Bad Cast). Expression \n(t0)obj(t,t ,v) is a ' bad cast iff t<: t0 does not hold. Lemma 2 (Progress). If G; . f e : t, then either \ne . V, or ethis(.) ' e is a bad cast, or there exists some e ' such that e =. e . Theorem 1 (Type Soundness). \nIf G; . f e : t, then either . e =.* v, or (.; e)., or e is a bad cast, where .= ethis(.). The theorem \nhere does not explicitly relate a statically typed program . with the run time, which we state now as \nThm.2: Theorem 2 (Sound Static Typing). If fp ., init(.) = . (.; e), then e =.* v, or (.; e)., or e is \na bad cast. Last we state decidable type checking: Theorem 3 (Type Decidability). For any program ., \nit is decidable whether fp . holds. Mode and Phase Invariants We now prove that both phase isolation \nand the waterfall invariant for modes hold. De.nition 2 (Redex). (.; e) is a redex over program . iff \nethis(.0) e0 =. * E.[e] where init(.) = (.0; e0). Theorem 4 (Phase Isolation). Given a program . such \n' that fp . and any redex (p; m; obj(t,t ,v ').md(.)(v)), then phase(t ')= p. '' Observe here that t \nin obj(t,t ,v ') is the current type in the presence of adaptation, so this property says that either \n1) there is no adaptation (t = t ') and then the phase of the object at instantiation time and the phase \nof the calling object must unify, or 2) there is adaptation (t t = '), and then the phase of the object \nafter the last adaptation and the phase of the calling object must unify. Theorem 5 (Waterfall Invariant). \nGiven a program . such ' that fp . and any redex (p; m; obj(t,t ,v ').md(.)(v)), mode(t)<:m . MO where \n.= PO MO C . Note that the mswitch expression directly updates the context object characterization, so \nthis lemma subsumes mswitch coercion.  4. Implementation and Evaluation This section describes an ET \ncompiler implementation, some programming case studies and benchmarking results of ET programs on the \nAndroid operating system [1]. 4.1 Compiler ET has been implemented on top of the Polyglot compiler framework \n[28]. All features presented in the formal sys\u00ad tem have been implemented. The compiler in addition im\u00adplemented \nconstraint-based type inference, and some con\u00advenience features such as class-level phase/mode quali.ers, \nand a noscale declaration for short methods (such as get\u00adters and setters) where the otherwise small \noverhead of fre\u00adquency scaling may outweigh the bene.t. The source code of the compiler can be downloaded \nonline [37]. The solutions of the phase type variables in type infer\u00adence are mapped back to the AST, \nso that the pass of code generation can decide whether DVFS calls need to be in\u00adserted (i.e. type-directed \nfrequency scaling). The code for frequency scaling is written in C, and interfaces with target code through \nJava Native Interface (JNI). A small portion of target code speci.c to Android, such as setting governors, \nis also automatically generated. Our compiler can analyze Android library sources as ET programs. To \navoid analyzing uninteresting library code which arti.cially increases LOC count, our compiler conser\u00advatively \nexcludes library code that does not affect a paramet\u00adric analysis, such as method invocations with primitive \ndata as arguments and return values, or operations on built-in Java objects such as System and String. \n 4.2 Evaluation We have converted several Android programs into ET, with basic information as follows. \nSpaceBlaster and Asteroids are from a reference book [33]; the rest are from Android s developer site \n[1]. The selection is intended to cover Android Apps of distinct natures, such as games, GUI applications, \nI/Os, and mathematical computations. name description LOC Asteroids interactive game 2236 BackupRestore \n.le I/O 326 CubeLiveWallpaper GUI design 241 GesturesDemo gesture recognition 3205 SpaceBlaster interactive \ngame 1700 Programming Experience We found that the amount of effort required to convert a Java program \nto an ET program was mild. Incremental programming, i.e. starting from a Java program and adding ET features \ngradually, does not appear dif.cult in our case studies. We now use SpaceBlaster as an example to describe \nour programming experience in greater detail. The SpaceBlaster program is declared with 4 phases, the \nmain phase, the math phase for the computation\u00adintensive part of the program, the graphics phase for \nrendering-related operations, and the audio phase for sound-related operations. Their impact on DVFS \nis re.ected in our phase de.nition: phases { main <cpu math ; graphics <cpu main ; audio <cpu main ; \n} The modes declared in SpaceBlaster are lofi, hifi, and full, in a similar way as in the example we \nused in Sec. 2. The program contains 17 adapt and 8 mswitch expressions, a relatively small programming \neffort for a program with 1700LOC. The attribution of most objects to phases is fairly predictable. For \nmodes, each rendering element (the BitMap objects) the ship, the meteor, the .res, and the bullet is \nde.ned with two or three different implementations, each using a slightly different pixel size. We found \nthat several operations, speci.cally some render\u00ading operations, have a high impact on energy consumption \nbecause games have a relatively high frame rate for graphics rendering. We use mswitch in these operations \nto select a smaller or larger bitmap, depending on the current battery state. We now report the insights \nwe gained and the lessons we learned throughout this experience. First, it is common in Android programming \nto unneces\u00adsarily intertwine operations of distinct CPU usage patterns (see Bene.t 2). The original SpaceBlaster \ncode mixed physics-related mathematical computations such as com\u00adputing the background, computing the \nvelocity of the space\u00adship with their display. After declaring graphics and math as separate phases, \nphase isolation naturally guided us in separating physics-related operations into an object of its own, \nwhich is only adapt ed once from the graphics phase to compute physics for each game frame. Second, for \nobjects that genuinely cross phase boundaries typically objects recording game data the interesting \nquestion is which phases they should be declared with. As lazy programmers, we naturally wish to use \nas few adapt s as possible. The decision of selecting an appropriate phase for declaration is thus based \non how often or complex such objects are used in individual phases. For instance, if the uses of the \nPosition object are scattered through the math phase, but are very few and concentrated in the graphics, \nit is our inclination to declare it as a math object and only adapt when being used in graphics. We speculate \nthis methodology also improves data locality, which, with ad\u00advanced data memory management, further contributes \nto en\u00adergy ef.ciency (see Sec. 6). Third, Bene.t 4 is effective in helping us organize pro\u00ad grams. Among \nthe compiler error messages given by ET, we .nd the messages involving the violation of the waterfall \ninvariant very useful for improving the code quality. For in\u00adstance, we have a resource container ResContainer \nclass that keeps the ship, meteor, bullet, etc, instances:  class ResContainer { SBBitmap ship ; SBBitmap \nbullet ; void setShip(SBBitmap s) { ship = s; } void setBullet (SBBitmap b) { bullet = b; } void setFM \n( int i) {ship .setFM(i ); bullet .setFM(i ); } ... } In a multi-mode program such as ours, it is natural \nto as\u00adsociate each mode with a ResContainer object. We need a methodology that helps prevent, for instance, \na ResContainer object of lofimode from accidently in\u00adcluding a ship object which is hifi. In the following \ncode, it would be a type-error if the last line were included: SBBitmap@mode( hifi ) ship high = MyBitmapFactory \n. load ( . . . ) ; SBBitmap@mode( lofi ) ship low = MyBitmapFactory . load ( . . . ) ; ... res high = \nnew ResContainer@mode ( h i f i ) ( ) ; res low = new ResContainer@mode ( l o f i ) ( ) ; res high.setShip(ship \nhigh); res low . setShip ( ship low ); res low.setShip(ship high); // error Fourth, the process of attributing \nobjects to phases and modes also promotes object-oriented programming in gen\u00aderal. The original SpaceBlaster \nprogram was written in a C-style disguised in Java syntax, with very few (yet large) classes. When we \nconverted this application to ET, and were required to add phase and mode quali.ers to our objects, the \nsame thought process of attributing different methods and .elds to different phases and modes also helps \nus refactor the code into more objects. Fifth, the type coercion aspect of adapt and mswitch is useful \nto maintain the .exibility of the type system. One of the commonly cited problems of a type system approach \nis its innate conservativeness may disallow useful but excep\u00adtional to the type invariant programs. \nFor instance, the wa\u00adterfall invariant dictates that an object in the lofi mode should not send messages \nto a hifi object directly. In our case studies, we occasionally run into a situation where an Android \nlibrary object, say libHi, is used mostly in the high battery state hence justi.ably declared as hifi \n but one or two of its methods, say lowUse, may also need to be invoked in the lofi mode. This problem \ncan typically be avoided by refactoring such as breaking the class of the aforementioned object into \ntwo but in the presence of li\u00adbrary classes, such a solution may lead to problems of back\u00adward compatibility. \nWith mswitch, the following code can appear in a lofi context, reminiscent of declassi.cation in language-based \nsecurity [41] or approximation endorsement in EnerJ [30]: mswitch ( hifi ) { hifi: libHi.lowUse(); } \nThe programming experience also revealed one possible weakness of Energy Types. Because we do not have \na top phase , every utility object has to be placed into a phase of our declaration as well. This is \nnot a problem for those utility objects only used in one phase our type inference algorithm will just \nunify them to that phase but it involves awkward adapt coercions in cases such as when an object factory \nis used in multiple phases. To add a top phase as a top type is a trivial type system addition. The open \nquestion is whether full-.edged support of phase subtyping the more elegant solution from a type theory \nperspective  is really bene.cial to real-world programming (i.e. not an over-design).  Experiment Setup \nThe target code is benchmarked on a Motorola Droid X with Android version 2.2.1 (Froyo) and API level \n8. For this con.guration, four CPU frequencies are available: 1Ghz, 800Mhz, 600Mhz, 300Mhz. Energy consumption \nis measured by Watts up? (PRO/ES/.Net) 1. All experiments are conducted at full battery to minimize the \neffect of battery charging. Each application is tested under 6 scenarios: A is original Android, i.e. \nAndroid code with no phases and modes, running at 1GHz on a governor with no frequency scaling;  B is \nphase only + full-range frequencies, i.e. code with phase declarations and phases are mapped to the whole \nrange of frequency levels (300Mhz -1Ghz);  C is phase only + partial-range frequencies, i.e. code with \nphase declarations and phases are mapped to a lower range of frequency levels (300Mhz -800hz). This case \nis designed to test proportional scaling, the idea we described in Sec. 3.3;  D is phase + degraded \nmode. The choice here is application-speci.c (see the description later). The de\u00adgraded mode here is \nlofi and the original mode for A, B, C is hifi;  E is Android with on-demand CPU scaling. Android is \nequipped with an ondemand governor that allows for frequency scaling based on performance metrics.  \n1 www.wattsupmeters.com  F is lowest frequency only, i.e. Android code with no phases and modes, running \nat 300Mhz on a governor with no frequency scaling. Since the same program may execute in different speeds \nunder different scenarios, the same logical task say playing 2500 frames of a game loop may not take \nthe same time to complete. With energy as a cumulative value over time, the only fair energy comparison \nacross scenarios would be to have all energy measurements conducted for the same log\u00adical task. For Asteroids \nand SpaceBlaster, the log\u00adical task chosen for measurement is 2500 frames of game loop; for BackupRestore, \nit is 1M integer writes; for CubeLiveWallPaper, it is 1250 frames of display; for GestureDemo, it is \nperforming and recognizing 7 ges\u00adtures. We have modi.ed Asteroids and SpaceBlaster, so that the two games \ncan be run in the auto-pilot mode. The only application that involves signi.cant user interaction is \nGestureDemo. In this case, the testing users are trained to follow the same routine (the rate of touch, \nthe path of .nger movement) until energy consumption stabilizes (usually 2-5 trials), and the mean of \nthe next 5 trials is chosen. We found such experiments yield very stable results, with variations ranging \n\u00b12 joules in most cases. DVFS Overhead DVFS is known to incur a small over\u00adhead. The conventional wisdom \nis that the switching time is usually in the tens of microseconds (e.g. 20 \u00b5s for Intel Xscale) that \nare often ignored on application-level studies (e.g. [30]) and the switching energy cost is so small \nthat even many architecture-level studies (e.g. [23, 39]) do not consider it. Our experiments however \nshowed a dispropor\u00adtionate amount of time and energy consumed on DVFS: Average DVFS time: 0.95ms -1.05ms \n Energy consumption per DVFS: 0.8 mJ -1.0mJ.  This data is almost 1-2 magnitude higher than the assump\u00adtions \nof the state-of-the-art energy simulators. We believe this results from the inef.ciency of JNI use for \nDVFS calls. To perform DVFS, we have to invoke a JNI method .rst, and then invoke the DVFS system calls \non the C side (invok\u00ading system calls directly from the Java side is even slower). If a technology like \nours turns out to be useful for Android platforms, we expect more ef.cient ways to perform DVFS would \nbe developed in future Android API s. In the follow\u00ading report, we adjust our data in the following conservative \nmanner: Adjusted DVFS time: 200\u00b5s. This is still one magnitude higher than Intel Xscale, but we would \nrather err on the safe side. 200\u00b5s Adjusted DVFS energy consumption: 0.9mJ \u00d7. In 1ms other words, we \nproportionally adjust energy consump\u00adtion by time. We think this is reasonable because 1) the Figure \n13. Benchmark Results: Energy Consumption (joules) and Time (seconds) relation between energy consumption \nand time is theo\u00adretically linear; 2) considering most simulation-based en\u00adergy research ignores DVFS \nenergy cost altogether, any good-faith adjustment is indeed on the conservative side. Benchmarking Results \nThe benchmarking result is illus\u00adtrated in Fig. 13. Phases appear to be an effective approach for reducing \nenergy consumption. For all experiments we conducted with the only exception of BackupRestore, a case \nwe will discuss in separation at the end of this section en\u00adergy consumption in B, C, D columns is lower \nthan A. Even with a conservative approximation of the DVFS overhead, our experiments suggest that the \ngain well offsets the over\u00adhead in most cases. For Asteroids, GestureDemo, and SpaceeBlaster, energy \nconsumption is reduced from A to B by 30%-50%. What is even more striking is that in all three cases, \nthe time between A and B almost remains the same. This con.rms that slowing down the CPU frequency at \nthe graphics-intensive phase is a good choice. Note that Asteroids even had a mild speed up from A to \nB. We speculate this shows that the dominating factor in graphics\u00adrelated code is the status of I/O, \nnot CPU frequency at all. CubeLiveWallPaper shows very little gain in energy savings by performing DVFS. \nThe execution time in fact in\u00adcreases slightly as a result, a fact not too surprising since energy and \ntime are often trade-offs. This benchmark dis\u00adplaying some animated wall papers maintains a very low \nlevel of computation, and we think this is a reminder that the relative effectiveness of our approach \nincreases when the application grows more complex. As the application grows, the weight of the computation \nmakes CPU scaling worth it.  We are relatively conservative on our experiments re\u00adlated to modes, because \nthe effectiveness of this feature is application-speci.c. Lacking an objective framework to de\u00ad.ne, say, \nwhat a 3% .delity degradation means, we choose to only change certain parameters of the original Android \napplications so that the programs execute with no or little perceptive difference. For example, both \nSpaceBlaster and Asteroids reduce the image size (spaceships, aster\u00adoids) by a small percentage (such \nas 20 points) in the lofi mode, whereas GesuturesDemo increases the stroke tol\u00aderance from 3 to 6. This \nis why our results (column D) do not often yield dramatic energy savings. Green [4] has in\u00ad teresting \nproposals on de.ning QoS and hence more sophis\u00adticated experiments in this regard. What is somewhat striking \nis our static approach can in fact fare better than the purely dynamic approach toward CPU scaling (column \nE) in most cases. As we mentioned in Sec. 2, the relationship between the static approach and the dynamic \napproach is complementary. That being said, the experimental results suggest a standalone static approach \nmay have a future of its own in many scenarios where pro\u00adgrammers are willing to participate in the process \nof energy\u00adef.cient computing. The most baf.ing case is BackupRestore. In this pro\u00adgram, we have scaled \ndown the frequency when I/O hap\u00adpens, which in this case means writing a large number of integers to \na .le. Our hope had been to take advantage of the CPU slacks resulted from .le I/O, but this does not \nseem to work. We do not fully understand why a .le I/O-intensive application is so resistant to DVFS: \nrunning the program to 30% of the original frequency increases the execution time by 3 times. The only \ndiscovery we have is that the .le I/O uses java.io.RandomAccessFile s write method, which is a C native \nmethod invoked through JNI. Considering JNI caused signi.cant slow-downs on DVFS system calls themselves, \nwe speculate there might be some internal mechanism with JNI that is rather CPU-intensive. The lessons \nwe draw from this anomaly are twofold. First, there are cases whose energy consumption patterns a well\u00adintentioned \nprogrammer simply cannot characterize cor\u00adrectly. A more complete approach would be a uni.ed one involving \nboth statics and dynamics, a blueprint we sketched at the end of Sec. 2. Second, for energy-conscious \nplatforms such as Android, elements of the platform that have high performance and energy impacts, such \nas JNI, should be well documented by Android developers, as well as targets for improvement. 5. Related \nWork Designing programming models for energy ef.ciency is a relatively nascent direction. Sensor network \nlanguage Eon [34] supports data .ows conditioned by programmer-de.ned energy states. The Green framework \n[4] allows programmers to specify and calibrate QoS. Flicker [21] programmers can identify non-critical \ndata in their program so that they can be placed in a memory area with lower memory refresh rate. None \nof these efforts is equipped with a reasoning frame\u00adwork. More distant are efforts on embedded systems \npro\u00adgramming sensor network programming in particular that often indirectly address energy consumption \nby reduc\u00ading execution sequence length and memory footprint. Flask [24] uses a .avor of meta programming \nto allow more ef.\u00adcient (and more energy-friendly) code. On the philosophical level, this project is \naligned with a number of application\u00adlevel power management approaches [9, 22] in that the spirit of \nusers/programmers know more is shared. In EnerJ [30], programmers can annotate whether data are part \nof an approximate computation or a precise one. For approximate data, rich hardware support is offered \nto save energy, such as cache-line-based object layout, width reduction for .oating point operations, \nand reducing DRAM refresh rate. EnerJ is equipped with a type system to enforce interactions of approximate \nand precise data, on the high\u00adlevel can be related to a 2-mode Energy Types system. EnerJ adopts an information \n.ow model an approximate value can neither directly nor indirectly interfere with a precise value. EnerJ \ndoes not overlap with the design of phases in ET. Recently, more re.ned architectural support for EnerJ\u00adlike \napproximate programming is developed [10]. Several formal frameworks are not directly related to energy \nconsumption, but have the potential to impact the practice of energy-aware programming. Amortized resource \nanalysis [12] offers precise cost-based worst-case analysis for resource usage in a functional setting. \nRecently, a rela\u00adtional assertion logic [6] is constructed to reason about pro\u00ad gram relaxation and acceptability. \nIt provides a rigorous set\u00adting to help programmers express and verify the properties of program approximation. \nEnergy ef.ciency is more discussed in the context of compiler optimization. Kandemir et. al. [18] studied \nthe im\u00ad pact of various compiler techniques (such as loop unrolling) on energy consumption. Fen et. al. \n[40] investigated the pros and cons of compiler-assisted dynamic voltage scaling. Hsu and Kremer [13] \ndesigned an algorithm combining pro.ling and static analysis to identify scaling points. Dynamic approaches \nsuch as via online monitoring and of.ine pro.ling are the majority of today s power manage\u00adment techniques; \nfor a survey, see [19]. 6. Conclusion This paper is a systematic study on constructing and more importantly \n reasoning about energy-aware software. It lays a type-theoretic foundation for phase-based and mode-based \nenergy management, and validates the ideas in the concrete context of smartphone programming.  This \npaper is a small step toward a direction that calls for more investigation. Considering the advanced \nstatus of type system research, many interesting ideas beyond the scope of this paper effect types, \ntype states, dynamic/soft/grad\u00adual typing, cost-based resource typing, dependent types, to name a few \n may be applicable for reasoning energy-aware software. Along this line, Energy Types is neither the \nmost precise in characterizing energy consumption, nor the most expressive in capturing the intentions \nof energy-aware pro\u00adgrammers. Now that the bridge between type systems and phase-based and mode-based \nenergy management is built, the real excitement lies upon how many type system ideas are relevant in \nbuilding energy-aware software. On this long wish list, an immediate future work of ET is to promote \nmore expressive interactions between mode values and ob\u00adject types in a hybrid setting that involves \nboth static reason\u00ading and lightweight dynamic reasoning. We are also interested in exploring how phase \ninfor\u00admation can guide memory management towards energy\u00adef.cient computing. It is a widely accepted fact \nthat cache misses and the resulting memory roundtrips are a major con\u00adtributor of energy consumption \n[35]. So, in addition to the bene.ts we described in Sec. 1, phases as types may further promote energy \nef.ciency by guiding memory systems to reduce cache misses. We are in particular interested in mod\u00adifying \nthe virtual machines to co-allocate objects in the same phase. This paper uses DVFS as a low-level energy \nmanagement strategy to demonstrate the usefulness of Energy Types. A broader question is whether and \nhow the solutions from the lower layers of the compute stack can bene.t from high\u00adlevel program information \nsuch as phases and modes. For instance, workload characterization is important in virtual\u00adization [5] \nand energy-ef.cient cloud computing. It is an open question whether phases and modes can offer useful \nhints that scheduling and consolidation algorithms can ben\u00ade.t from. Acknowledgments We thank the anonymous \nreviewers for their useful suggestions, and Thomas Bartenstein, Michael Carbin, Juan Chen, Xinyu Feng, \nKanad Ghose, Jan Hoff\u00admann, Suresh Jagannathan, Frank Lu, Andrew Myers, Sasa Misailovic, Jens Palsberg, \nAdrian Sampson, Scott Smith, and Jan Vitek for useful discussions. This work is supported by NSF CAREER \nAward CCF-1054515 and a Google Fac\u00adulty Award. References [1] http://developer.android.com. [2] M. Abadi, \nL. Cardelli, B. Pierce, and G. Plotkin. Dynamic typ\u00ading in a statically-typed language. In POPL 89: Proceedings \nof the 16th ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages 213 227, 1989. \n[3] Alexander Aiken, Edward L. Wimmers, and T. K. Lakshman. Soft typing with conditional types. In POPL \n94: Proceedings of the 21st ACM SIGPLAN-SIGACT symposium on Principles of programming languages, pages \n163 173, 1994. [4] Woongki Baek and Trishul M. Chilimbi. Green: a frame\u00adwork for supporting energy-conscious \nprogramming using controlled approximation. In PLDI 10: Proceedings of the 2010 ACM SIGPLAN conference \non Programming language design and implementation, pages 198 209, 2010. [5] Paul Barham, Boris Dragovic, \nKeir Fraser, Steven Hand, Tim Harris, Alex Ho, Rolf Neugebauer, Ian Pratt, and Andrew War.eld. Xen and \nthe art of virtualization. In Proceedings of the nineteenth ACM symposium on Operating systems prin\u00adciples, \nSOSP 03, pages 164 177, 2003. [6] Michael Carbin, Deokhwan Kim, Sasa Misailovic, and Mar\u00adtin C. Rinard. \nProving acceptability properties of relaxed non\u00addeterministic approximate programs. In PLDI, pages 169 \n180, 2012. [7] Anantha P. Chandrakasan, Samuel Sheng, and Robert W. Brodersen. Low power cmos digital \ndesign. IEEE Journal of Solid State Circuits, 27:473 484, 1992. [8] Ashutosh S. Dhodapkar and James E. \nSmith. Managing multi\u00adcon.guration hardware via dynamic working set analysis. In ISCA 02: Proceedings \nof the 29th annual international sym\u00adposium on Computer architecture, pages 233 244, Washing\u00adton, DC, \nUSA, 2002. IEEE Computer Society. [9] Carla Schlatter Ellis. The case for higher-level power manage\u00adment. \nIn HOTOS 99: Proceedings of the The Seventh Work\u00adshop on Hot Topics in Operating Systems, page 162, Washing\u00adton, \nDC, USA, 1999. IEEE Computer Society. [10] Hadi Esmaeilzadeh, Adrian Sampson, Luis Ceze, and Doug Burger. \nArchitecture support for disciplined approximate pro\u00adgramming. In ASPLOS 12, pages 301 312, 2012. [11] \nMichael Furr, Jong-hoon (David) An, and Jeffrey S. Foster. Pro.le-guided static typing for dynamic scripting \nlanguages. In OOPSLA 09: Proceeding of the 24th ACM SIGPLAN con\u00adference on Object oriented programming \nsystems languages and applications, pages 283 300, 2009. [12] Jan Hoffmann, Klaus Aehlig, and Martin \nHofmann. Multivari\u00adate amortized resource analysis. In POPL 11, pages 357 370, 2011. [13] Chung-Hsing \nHsu and Ulrich Kremer. The design, implemen\u00adtation, and evaluation of a compiler algorithm for cpu energy \nreduction. In PLDI 03: Proceedings of the ACM SIGPLAN 2003 conference on Programming language design \nand imple\u00admentation, pages 38 48, New York, NY, USA, 2003. ACM. [14] Atsushi Igarashi, Benjamin Pierce, \nand Philip Wadler. Feath\u00aderweight java -a minimal core calculus for java and gj. In TOPLAS, pages 132 \n146, 1999. [15] Atsushi Igarashi and Mirko Viroli. Variant parametric types: A .exible subtyping scheme \nfor generics. TOPLAS, 28(5):795 847, 2006. [16] Canturk Isci, Gilberto Contreras, and Margaret Martonosi. \nLive, runtime phase monitoring and prediction on real systems with application to dynamic power management. \nIn MICRO 39: Proceedings of the 39th Annual IEEE/ACM International Symposium on Microarchitecture, pages \n359 370, Washing\u00adton, DC, USA, 2006. IEEE Computer Society.  [17] Canturk Isci and Margaret Martonosi. \nIdentifying program power phase behavior using power vectors. In Workshop on Workload Characterization, \n2003. [18] M. Kandemir, N. Vijaykrishnan, M. J. Irwin, and W. Ye. In\u00ad.uence of compiler optimizations \non system power. In DAC 00: Proceedings of the 37th Annual Design Automation Con\u00adference, pages 304 307, \nNew York, NY, USA, 2000. ACM. [19] Stefanos Kaxiras and Margaret Martonosi. Computer Archi\u00adtecture Techniques \nfor Power-Ef.ciency. Morgan and Clay\u00adpool Publishers, 1st edition, 2008. [20] Kenneth Knowles and Cormac \nFlanagan. Hybrid type check\u00ading. ACM Trans. Program. Lang. Syst., 32(2):1 34, 2010. [21] Song Liu, Karthik \nPattabiraman, Thomas Moscibroda, and Benjamin G. Zorn. Flikker: saving dram refresh-power through critical \ndata partitioning. In ASPLOS, pages 213 224, 2011. [22] Yung-Hsiang Lu, Luca Benini, and Giovanni De \nMicheli. Requester-aware power reduction. In In Proceedings of the International Symposium on System \nSynthesis, pages 18 24, 2000. [23] Grigorios Magklis, Michael L. Scott, Greg Semeraro, David H. Albonesi, \nand Steven Dropsho. Pro.le-based dy\u00adnamic voltage and frequency scaling for a multiple clock do\u00admain \nmicroprocessor. In ISCA 03, pages 14 27, 2003. [24] Geoffrey Mainland, Greg Morrisett, and Matt Welsh. \nFlask: staged functional programming for sensor networks. In ICFP 08: Proceeding of the 13th ACM SIGPLAN \ninternational con\u00adference on Functional programming, pages 335 346, 2008. [25] Ana Milanova, Atanas Rountev, \nand Barbara G. Ryder. Pa\u00adrameterized object sensitivity for points-to analysis for java. TOSEM, 14:1 \n41, January 2005. [26] Sasa Misailovic, Stelios Sidiroglou, Henry Hoffmann, and Martin Rinard. Quality \nof service pro.ling. In ICSE 10: Proceedings of the 32nd ACM/IEEE International Conference on Software \nEngineering, pages 25 34, 2010. [27] James Noble, John Potter, and Jan Vitek. Flexible alias pro\u00adtection. \nIn ECOOP 98, Brussels, Belgium, July 1998. [28] Nathaniel Nystrom, Michael R. Clarkson, and Andrew C. \nMyers. Polyglot: An extensible compiler framework for java. In CC 03, pages 138 152, April 2003. [29] \nTrevor Pering, Tom Burd, and Robert Brodersen. The simu\u00adlation and evaluation of dynamic voltage scaling \nalgorithms. In ISLPED 98: Proceedings of the 1998 international sym\u00adposium on Low power electronics and \ndesign, pages 76 81, 1998. [30] A. Sampson, W. Dietl, E. Fortuna, D. Gnanapragasam, L. Ceze, and D. Grossman. \nEnerJ: Approximate Data Types for Safe and General Low-Power Computation. In Program\u00ad ming Language Design \nand Implementation (PLDI), June 2011. [31] Timothy Sherwood, Suleyman Sair, and Brad Calder. Phase tracking \nand prediction. In ISCA 03: Proceedings of the 30th annual international symposium on Computer architecture, \npages 336 349, New York, NY, USA, 2003. ACM. [32] Jeremy Siek and Walid Taha. Gradual typing for objects. \nIn ECOOP 07: Proceedings of the 21st European confer\u00adence on ECOOP 2007, pages 2 27, Berlin, Heidelberg, \n2007. Springer-Verlag. [33] V. Silva. Pro Android Games. Apress Series. Apress, 2010. [34] Jacob Sorber, \nAlexander Kostadinov, Matthew Garber, Matthew Brennan, Mark D. Corner, and Emery D. Berger. Eon: a language \nand runtime system for perpetual systems. In SenSys 07: Proceedings of the 5th international confer\u00adence \non Embedded networked sensor systems, pages 161 174, 2007. [35] Ching-Long Su and Alvin M. Despain. Cache \ndesign trade\u00adoffs for power and performance optimization: a case study. In ISLPED 95: Proceedings of \nthe 1995 international sympo\u00adsium on Low power design, pages 63 68, 1995. [36] Mads Tofte and Jean-Pierre \nTalpin. Region-based memory management. Information and Computation, 1997. [37] Energy Types. http://www.cs.binghamton.edu/ \ndavidL/et/. [38] Mark Weiser, Brent Welch, Alan Demers, and Scott Shenker. Scheduling for reduced cpu \nenergy. In OSDI 94: Proceed\u00adings of the 1st USENIX conference on Operating Systems De\u00adsign and Implementation, \npage 2, Berkeley, CA, USA, 1994. USENIX Association. [39] Qiang Wu, Philo Juang, Margaret Martonosi, \nand Douglas W. Clark. Formal online methods for voltage/frequency control in multiple clock domain microprocessors. \nIn ASPLOS-XI, pages 248 259, 2004. [40] Fen Xie, Margaret Martonosi, and Sharad Malik. Compile\u00adtime dynamic \nvoltage scaling settings: opportunities and lim\u00adits. In PLDI 03: Proceedings of the ACM SIGPLAN 2003 \nconference on Programming language design and implemen\u00adtation, pages 49 62, 2003. [41] Steve Zdancewic \nand Andrew C. Myers. Robust declassi.ca\u00adtion. In in Proc. IEEE Computer Security Foundations Work\u00adshop, \npages 15 23. IEEE Computer Society Press, 2001. A. Additional De.nitions The mtype, mbody, and fields \nomitted in the main text of the draft are de.ned in Fig. 14.  ' .' class c .' extends t {M ..}. .= \n. ';S . t md(t x){e}. M (D-MTClass) def mtype(md, c(.)) = (..(t . t )){./. ' } ' .' class c .' extends \nt {M ..}. .= . ';S . t md(t x){e}./M (D-MTSuper) def mtype(md, c(.))= mtype(md,t ' {./. ' }) ' class \nc .0 extends t {M ..}. ..0 = . ' 0;S0 . t md(t x){e}. M .= . ';S' (D-MBClass) def mbody(md(.), c(.0))= \nx.e{.0/.0' }{./. ' } ' class c . extends t {M ..}. ..0 = . ' ;S0 . t md(t x){e}./M 0 (D-MBSuper) def \n mbody(md(.), c(.0))= mbody(md(.),t ' {.0/. ' 0}) ' class c . extends t {F ; ..}. . .= . ';S fields(t{./. \n' })= F (D-FClass) ' fields(c(.)) \u00a3 F l F {./. ' } (D-FBase) fields(Object(f; \u00b5)) \u00a3 E Figure 14. FGJ-like \nDe.nitions   \n\t\t\t", "proc_id": "2384616", "abstract": "<p>This paper presents a novel type system to promote and facilitate energy-aware programming. Energy Types is built upon a key insight into today's energy-efficient systems and applications: despite the popular perception that energy and power can only be described in joules and watts, real-world energy management is often based on discrete phases and modes, which in turn can be reasoned about by type systems very effectively. A phase characterizes a distinct pattern of program workload, and a mode represents an energy state the program is expected to execute in. This paper describes a programming model where phases and modes can be intuitively specified by programmers or inferred by the compiler as type information. It demonstrates how a type-based approach to reasoning about phases and modes can help promote energy efficiency. The soundness of our type system and the invariants related to inter-phase and inter-mode interactions are rigorously proved. Energy Types is implemented as the core of a prototyped object-oriented language ET for smartphone programming. Preliminary studies show ET can lead to significant energy savings for Android Apps.</p>", "authors": [{"name": "Michael Cohen", "author_profile_id": "81548505956", "affiliation": "SUNY Binghamton, Binghamton, NY, USA", "person_id": "P3856186", "email_address": "mcohen3@binghamton.edu", "orcid_id": ""}, {"name": "Haitao Steve Zhu", "author_profile_id": "81549311756", "affiliation": "SUNY Binghamton, Binghamton, NY, USA", "person_id": "P3856187", "email_address": "hzhu1@binghamton.edu", "orcid_id": ""}, {"name": "Emgin Ezgi Senem", "author_profile_id": "81548379656", "affiliation": "SUNY Binghamton, Binghamton, NY, USA", "person_id": "P3856188", "email_address": "semgin1@binghamton.edu", "orcid_id": ""}, {"name": "Yu David Liu", "author_profile_id": "81549095356", "affiliation": "SUNY Binghamton, Binghamton, NY, USA", "person_id": "P3856189", "email_address": "davidl@binghamton.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384676", "year": "2012", "article_id": "2384676", "conference": "OOPSLA", "title": "Energy types", "url": "http://dl.acm.org/citation.cfm?id=2384676"}