{"article_publication_date": "10-19-2012", "fulltext": "\n Finding Reusable Data Structures GuoqingXu UniversityofCalifornia,Irvine guoqingx@ics.uci.edu Abstract \n1. Introduction A big source of run-time performance problems in large\u00adscale, object-orientedapplicationsisthefrequentcreation \nof data structures(by the same allocation site) whoselifetimes are disjoint, and whose shapes and data \ncontent are always the same.Constructing thesedata structures and computing the same data values many \ntimes is expensive; signi.cant performanceimprovements canbe achievedbyreusingtheir instances, shapes, \nand/ordata values ratherthan reconstruct\u00ading them.Thispaperpresents a run-time technique that can be \nusedtohelpprogrammers .ndallocation sites that create such data structures to improve performance. At \nthe heart of the technique are three reusability de.nitions and novel summarization approachesthat compute \nsummariesfordata structures based on these de.nitions. The computed sum\u00admaries are usedsubsequentlyto \n.nddata structuresthathave disjointlifetimes, and/orthathavethe same shapes andcon\u00adtent.Wehaveimplementedthis \ntechniquein theJikesRVM and performed extensive studies on large-scale, real-world programs. We describe \nour experience using six case stud\u00adies,in which wehave achievedlargeperformancegainsby .xingproblems \nreportedby our tool. Categories and Subject Descriptors D.3.4[Programming Languages]: Processors Memory \nmanagement, optimiza\u00adtion, run-time environments; F.3.2 [Logics and Meaning of Programs]: Semantics of \nProgramming Languages Program analysis; D.2.5 [Software Engineering]: Testing andDebugging Debuggingaids \nGeneral Terms Language,Measurements,Performance Keywords object reuse, data structure encoding, memory \nmanagement,performance optimization Permission to make digital or hard copies of all or part of this \nwork for personal or classroomuseisgranted withoutfeeprovided that copiesarenot madeordistributed forpro.tor \ncommercial advantage andthat copiesbearthis notice andthefull citation onthe .rstpage.Tocopy otherwise,torepublish,topostonservers \nortoredistribute tolists, requiresprior speci.cpermission and/or afee. OOPSLA 12, October19 26,2012,Tuscon,Arizona,USA. \nLarge-scale object-oriented applications commonly suffer from run-timeperformanceproblemsthatcanleadto \nsignif\u00adicantdegradation and reduced scalability.Experiences[28, 39, 44] show that many such bottlenecks \nin Java applica\u00adtionsare causedbychronicrun-timebloat,atermthatisused to refer to excessive memory usage \nand computation to ac\u00adcomplish relatively simple tasks. Although modern compil\u00aders offer sophisticated \noptimization techniques, these tech\u00adniques cannot effectively removebloat,becauselarge appli\u00adcations \noftenlackhot spots[42] inef.cient operations ex\u00adist throughouttheprogram, makingitextremelydif.cultfor \nthe(intraprocedural) compileranalysesto .nd and remove. In addition,traditionaloptimizersdetect opportunitiesbased \nprimarilyon controlpro.ling,whilelargebottlenecksare of\u00adten closely related todata activities[39].Finding \nthesebot\u00adtlenecks requires the invention of novel techniques that can better understandhowdatais computedand \naggregateddur\u00adingthe execution of a real-worldprogram. In many cases, systemic bloat stems from performance\u00adunconsciousdesign/implementationchoices,whicharesome\u00adtimes \nencouraged by the culture of object-orientation. For example, programmers are taught to freely create \nobjects evenfor extremely simpletasks,taking forgranted thatthe object creation and garbage collection \n(GC) are entirely free. However, this is only true for applications that need toprocess a very small \namount ofdata.Forlarge allocation\u00adintensiveapplications(such as webgraphprocessing sys\u00adtems andsocial \nnetworks)that oftenhave massive-scaledata to process, the excessive creation of objects can cause the \nheap toquicklygrow,leading to signi.cantlyincreasedGC effort and reduced scalability.In a managedlanguage(such \nasJava)thatdoes not support explicit memorymanagement, one wayto effectivelyreducethe allocation andGCpressure \nis to reuse existing objects in the heap for certain repeated tasks instead of reclaiming them and creating \nnew objects, because, in many cases, objects created for different tasks (e.g.,iterations ofan eventloop,database \ntransactions, etc.) have completely disjoint lifetimes and can never be used simultaneouslyduringthe \nexecution. Poor performance does not come only from excessive object creation and garbage collection; \ncreating one single Copyright cobject often involves the creation of a set of other objects, &#38;#169; \n2012ACM978-1-4503-1561-6/12/10. . .$10.00  class SSAGraph{ void findEquivalentNodes() { for(CFG cfg: \ncfgs){ cfg.visit(new TreeVistior(){ void visitBlock(Block b){b.visitBlockNodes();} }); } ... } ... } \nclass Block{ void visitBlockNodes(){ for(Statement s: statements){ s.visit(new NodeVisitor(){ void visitExpression(Expr \ne){e.visitChildren();} }); } ... } ... } class Expr{ void visitChildren(){ for(Expr child: children){ \nchild.visit(new ExprVisitor(){...}); } ... } ... } (a) for(String dateStr : dates){ SimpleDateFormat \nsdf = new SimpleDateFormat(); try{ Date newD = sdf.parse(dateStr); ... }catch(...) {...} } (b) Figure \n1. Real-world examples of reusabledata structures: (a)Iteratively visiting agraph using the visitorpattern; \nand (b)creating a SimpleDateFormat objectperiteration of the loop whose shape and data are completely \nindependent of theloop. the computation of their data content, and the combination of these objects into \na valid data structure. Repeating this processis unnecessarilyexpensiveif the reference structure and/or \nthe data content are unchanged. Hence, additional performancebene.ts may be obtainedif we reuse not only \nobject instances, but also their reference relationships and data content, because the heavy value computation \ncan be avoided. Figure1(a) and(b) showtwo real-world examplesthat illustrate, respectively,theproblems \nofexcessive object cre\u00adation and offrequent construction ofdata structures withthe same shapes and content.The \ncode snippetinFigure1(a) is adaptedfrombloat, a staticbytecode optimizationframe-workforJava.Method findEquivalentNodes \nin class SSAGraph identi.es expressions of equivalent types in a set of control.owgraphs(CFGs)byiteratively \nvisitingpro\u00adgram entitiesin them, such asbasicblocks, statements, and expressions. To implement this \ntraversal, bloat declares an anonymous visitor class for each type of program entity and creates an object \nof the class to visit each entity ob\u00adject. However, manyof these visitor objects are created in nestedloops.The \nnumbers oftheirinstances cangrow expo\u00adnentially with the layer of loop nesting, putting signi.cant run-timepressure \non the object allocator andGC. In this example, it is easy to observe that the lifetimes of instances \nof a visitor class are entirely disjoint the in\u00adstances are never needed simultaneously during the execu\u00adtion.To \noptimizethis case(including visitors not shownin Figure1(a)), weimplemented a singletonpatternfor each \nvisitorclass and used a single visitorobjectto visit allpro\u00adgram entities ofthe sametypethroughoutthe \nexecution.The content of this objectis reset every timeitis used tovisit a differententity.Thishasled \nto a37.3% runningtime reduc\u00adtion, a 16.7% reduction on the number of GC invocations, and a 11.1% reduction \non the peak memory consumption (onSunHotspot1.6.027). Figure1(b) shows an example(extractedfrom anIBM \napplication) where a more aggressive optimization can be applied.In this example, a new SimpleDataFormat \nob\u00adjectis createdin eachiteration oftheloop toparse a string into a Date object. Note that the data structure \nrooted at this objectis completelyloop-invariant:it cannot escape the iteration where it is created, \nand its shape and data content never change.We can simplyhoist this allocation site out of theloopinordertoreuse(1) \ntheobjectinstance,(2) all ob\u00adjects reachablefromitand their reference relationships, and (3)theirdata \ncontent.Thesereusabledata structures arethe focus of this paper we develop a novel dynamic analysis techniquethatcanhelpdevelopers \n.nd suchdatastructures in aprogramduringits representative runs. Focus on allocation sites The .rst challenge \nin this work is how to .nd an appropriate static object abstraction so that reuse opportunities canbedetected \namong the set of run-time objectsthat maptothe same abstraction.Inthispa\u00adper, wefocus on allocation sites, \nthatis, our technique com\u00adpares data structures created by the same allocation site to determine whether \nor not there exist opportunities with this allocation site.Our tool eventually ranks and reports alloca\u00adtion \nsites where reuse opportunities canbefound.For exam\u00adple,fortheprogramsinFigure1(a) and(b), our analysis \nwould report the allocation sites that create visitor objects andthat create SimpleDateFormat object, \nrespectively. Whilethere are manyothertypes ofabstractionsthat may also be considered for object reuse, \nwe .nd that focusing on allocation sites achieves the right balance between the amount of optimization \nopportunities that can be detected andthedif.culty ofdeveloping.xes.Consideringa coarser\u00adgrainedabstraction \nsuchas a class can miss reuse opportuni\u00adtiesthat existinindividualinstantiationsof theclass, while considering \na .ner-grained abstraction such as an allocation site under a speci.c calling context[4,11,21,35]maylead \ntothe reportingofproblemsthataredif.cultto .x.Itis often not easyto understandhowto reuse adata structure \nonly un\u00adder certain callingcontexts.Notethat simply rankingalloca\u00adtion sitesbased ontheir executionfrequencies \ncannot reveal reuse opportunities.For example,in a typicallarge applica\u00adtion, the most frequently executed \nallocation site is one in HashMap.put thatkeeps creatingMap$Entry objectsto  for(inti=0;i<N;i++){Aa=newA();a.f=1; \nBb=newB();b.g=1;a.link=b; ; a.f();//usea} (a) Original program for(int i = 0; i < N; i++) { for(int i \n= 0; i < N; i++) { for(int i = 0; i < N; i++) { A a= A.getInstance(); A a= A.getInstance(); A a= A.getInstance(); \na.f = 1; a.f = 1; ; a.f(); B b = B.getInstance(); a.link.g = 1; } b.g = 1; ; a.f(); static A instance \n= null; a.link = b; } static A getInstance() { ; a.f(); static A instance = null; if(instance == null) \n{ } static A getInstance() { instance = new A(); static A instance = null; if(instance == null) { instance.f \n= 1; static A getInstance() { instance = new A(); B b = new B(); if(instance == null) B b = new B(); \ninstance.link = b; instance = new A(); instance.link = b; b.g = 1; return instance; } } } return instance; \nreturn instance; static B getInstance() { } } } (b) Optimization based on (c) Optimization based on (d) \nOptimization based on instance-reusability shape-reusability data-reusability Figure 2. A simpleprogram \nandits optimizationsbased on the three reusabilitylevels. store newly-addedkeys and values.Objects createdby \nthis allocationsite are notreusableat all.Hence,itis necessary todevelop new metricsfor allocation sites \nthat can strongly correlate with their reusability. Levels of reusability In order to fully exploit reuse \nopportunities in a program, we classify allocation sites of interest into three categories, each at a \ndifferent reusability level. The .rst category (I) includes allocation sites that ex\u00adhibit instance reusability. \nFor each such allocation site, the number of its instances needed simultaneously during the executionis \nvery small(e.g.,boundedby a constant value). If this allocation site is frequently executed, we may cache \nitsinstances and reuse them to reduce the allocation/GC ef\u00adfort. The second reusability level is shape \nreusability. This level correspondsto a category(S)of allocation sites such that not only theirinstances \ncanbe reusedbut alsothe run\u00adtime shapes of the data structures rooted at these instances are unchanged. \nBy reusing both the instances and the ref\u00aderence relationships among them(i.e., objectgraph edges), we \nmayget additionalperformancebene.tsfrom savingthe efforttoform the shape manytimes.Thehighest reusability \nlevelis data reusability.Each allocation sitein this category (D)createsdata structures that are completely \nequivalentto each other their instances, shapes, and data values can all be reused. Figure2 shows a simpleprogram \nwith redundancies and the possible optimizations based on these three reusability de.nitions.In the program, \nthe loop keeps constructing the samedata structure(rooted at an object oftype A). At the levelofinstance \nreusability(showninFigure2(b)), an opti\u00admizationcanemploy a singletonpatternforeach class, and reuses \ntheinstances of A and B to amelioratethehigh object creation andGCpressure.As afurther step, a more aggres\u00adsive \noptimization can additionally reuse the reference edge between the two objects, based on the observation \nthat the shape of the structureis unchanged(showninFigure2(c)). Finally,once we .ndthatthedata valueswrittenintoa.f \nand b.g arealsoindependent of theloop,wecandevelop an op\u00adtimization that reuses the entiredata structureincluding \nthe instance, the shape, and thedata(showninFigure2(d)).In this example, it is possible to further optimize \nthe program by hoisting the call A a = A.getInstance(). How\u00adever, how to hoist an allocation site is \nout of the scope of this paper. In addition, in a real-world program, an alloca\u00adtion site that exhibitshigh \nreusability maybefar(e.g., many calls) awayfrom the main eventloop, makingitdif.cultfor the developer \nto hoist it. Our experience shows that a more common andpractical way to reusedata structuresis to em\u00adploysingletonpatterns, \nasillustratedinFigure2. The relationshipamong the three categoriesis D.S. I. As the reusabilitylevelincreases(from \nI to D), theper\u00adformancegains resulting fromthedata structure reuse may alsoincrease.Theproposedtechnique \naimsto expose oppor\u00adtunities atallthethreelevelstohelpaprogrammermaximize the possibility of improving \nperformance through reusing data structures. Particularly, for each reusability category, we report a \nranked list of allocation sites to the developer for manualinspection.Note that this techniquedoes not \n.x problems automatically. The optimizations in Figure 2 are shown onlyforillustrationpurposes.Theydemonstrate \ntyp\u00adical .x patterns that can be employed by a real-world pro\u00adgrammer to reuse data structures. In fact, \nour experience shows that true problems reported in each reusability cat\u00adegory can always be .xed using \none or a combination of these patterns. Details of our experiments can be found in Section4.  Figure \n3. An overview ofourtechnique. Approximations It is not always possible to precisely understand the three \nreusability properties for each data structureatruntime.For example,.ndingreusableinstances requires \nthepreciseidenti.cation of objectlifetimes, which is very dif.cult in a managed language like Java because \nobjectsdo notdieimmediately afterthey are nolonger used. Theirlifetimes aredeterminedby the GCpointsin \nthe exe\u00adcution.As anotherexample,understandingwhethertwodata structures contain the same data values \nrequires value pro\u00ad.ling [12], an expensivetechnique thatcannot scale tolarge applications.In ordertoimprovescalability,wedevelop \nan approach to approximate each level of reusability instead of attempting to compute precise solutions. \nIn particular, wedevelop a new metricto approximateinstance reusabil\u00adity, and summarize data structure \nshapes and value content to approximateshape anddata reusability.Thedetailed ap\u00adproximation algorithms \naredescribedinSection2. Overview The overview of our technique is shown in Figure3.Our toolhas two major \ncomponents:(1) an online data structure encoder that uses various approximations to summarizedata structures, \nand(2) an of.ine reusable data structure detector that compares summaries to .nd reuse opportunities \nat the end of the execution (but before the JVM exits).The encoderpiggybacksongarbagecollection to encode \nheap data structures based on their allocation sites. The detector consists of three stages to .nd reusable \ndata structures after all summaries are generated. It starts with scanning all allocation sites and ranking \nthem based ontheirinstance reusability(e.g.,instance summariesshown in Figure 3). The top M allocation \nsites on the list are then reported to the user for manual inspection. M can be given by the user as \na parameter to our analysis. A part of this ranked list (whose length is much larger than M) is fed to \nthe next stage the reusable shape detector will scan only these allocation sites to .nd those that exhibit \nhigh shape reusability.Thisisbecausedata structures at a certain reusability level must also exhibit \nreusability at all lower levels in order to be reused. For example, it can be very dif.cult,if notimpossible, \nto reusedata structures thathave the same data values but different shapes and overlapping instances. \nWehaveimplementedthis techniqueinJikesRVM3.1.0 (http://jikesrvm.org), a high-performance Java-in-Java \nvir\u00adtual machine, and successfully applied it to large-scale ap\u00adplications such asEclipse.Theimplementationisdescribed \nin Section 3. Our technique incurs an overall 10.8% run\u00adning time overhead and a 30.3% space overhead. \nThe de\u00adtailed executionstatistics arereportedinSection4.2.While the overhead is probably too high for \nproduction runs, we found it acceptable for performance tuning and debugging. Using our tool, we have \nidenti.ed reuse opportunities in allprogramsin ourbenchmark set. Section4.1presents six case studies \non applications wherelargeimprovements(e.g., 37.3% running time reduction and22%GC time reduction) wereachievedfromproblem \n.xes.Theexperimental results stronglyindicatethattheproposedtechnique canbe adopted in real-worlddevelopment \nand tuning tohelpprogrammers quickly.ndoptimization opportunitiesand reusedata struc\u00adturesforincreased \nef.ciency. The main contributions ofthis work are: A three-level reusabilityde.nition that aims tohelppro\u00adgrammers \nmaximize their chances of .nding optimiza\u00adtions opportunities.  A run-time techniquethat consists of \nthree algorithmsto approximate reusability at theselevels.  An implementation of this technique in the \nJikes RVM that piggybacks on garbage collection to .nd reusable data structures.  Six case studies demonstrating \nthat our technique can help programmers quickly identify reuse opportunities and.xproblemsforlargeperformancegains. \n 2. Encoding Data Structures to Approximate Reusability In this section, we describe our key algorithms \nthat encode data structures to .nd reuse opportunities. As observed in prior work onheap analysis(e.g.,[1,31]),garbage \ncollec\u00adtion(GC) in a managedlanguage executionisparticularly suitablefor computingheap-relatedprogramproperties.Be\u00adcauseGC \nrequires atraversalof alllive objectsintheheap,it is a naturalidea to associate an objectgraphtraversal-based \nanalysis withGC sothatthe analysis canbeperformedalong with the regular GC traversal to avoid the additional \nrun\u00adtime cost. In this paper, we employ a similar approach: the encoder(as showninFigure3) summarizesheapdata \nstruc\u00adturesfor each allocation siteduringGC runs, and thedetec\u00ad   1  2 3 4  5 6   2 1 Figure \n4. An exampleillustrating the lifetimes of different instances ofthe same allocation site. tor eventually \nanalyzes the generated summaries and .nds reusable opportunities. 2.1 Approximating Instance Reusability \nFinding an allocation site that exhibits instance reusability requires the understanding of whether the \nlifetimes of its instances can overlap.The smallerthe number ofinstances whose lifetimes can overlap \nis, the more likely it is for a developer to cache and reuse instances for this allocation site.Becauseitisgenerally \nundecidabletodetermine object liveness in a managed language, approximations have to be employed. A typical \nhandling is to use reachability to approximate liveness a set of checkpoints is scatteredover the execution \nand object reachability is inspected at each checkpoint.If an objectis not reachable(froma set of root \nobjects) at a checkpoint, its lifetime is treated as the time distancebetweenthischeckpoint and thepointwhenit \nwas created.Veryoften,GCrunsareusedascheckpointsbecause GC necessitates a reachability analysis. In our \nanalysis,however, using this approximation could cause alarge number of objects(createdbythe same alloca\u00adtion \nsite)tohave overlappinglifetimes,leadingtothefailure of detecting many truly reusable data structures. \nTo illus\u00adtrate, considerthe example showninFigure4.We use Oi to denote the i-th object created by the \nallocation site. At the checkpointGC1,all the.rst .veobjects(O1,...,O5)have overlapping lifetimes based \non this approximation, even though three of them(O2,O3,O4)are completely disjoint. Clearly, this approximationis \ntoo conservativetobe usedin our analysis.As a moreprecisehandling,theMerlin[19] ap\u00adproachmaybe usedtogeneratean \nobjecteventtracethatcan be subsequently analyzed to compute lifetimes of objects. However, performing \ndynamic whole-heap object tracing and trace analysis can incur a prohibitively large overhead for allocation-intensive \napplications (e.g., 70-300\u00d7 slow\u00addown reportedin[19] evenfor relatively smallprograms). Hence, it is \nmore suitable for an of.ine analysis than an online analysis such as the oneproposedin thepaper. 2.1.1 \nA New Approximation Toalleviatetheproblem,weproposea newmetricto approx\u00adimateinstancereusability.This \nmetricconsiders,ateachGC, the ratio between the number of dead objects and the num\u00adber of live objects \ncreated by the same allocation site. This ratio is referred to as the DL ratio in the rest of the paper. \nFor an allocation site, the larger its DL ratio is, the higher instance reusability it exhibits. This \nis because of the fol\u00adlowing two reasons:(1) the numberoflive objects at aGC is an(under-)approximationofthe \nobjectsthat are needed simultaneouslyfrom an allocation site.Thelarger this num\u00adberis,thelesslikely theinstancesof \nthisallocationsite are tobereused; and(2) thenumberofdead objectsat aGCis an(over-)approximationof the \nobjects whoselifetimes are disjoint. The higher this number is, the more likely it is to reuseinstances \ncreatedby the allocation site. To make moresense ofthis metric, considerthefollowing two extreme cases. \nIn the .rst case, there is an allocation site that creates completely disjoint instances during the execution. \nAt any GC, the number of live objects for this allocation siteis at most1, andthe number ofdead objectsis \natleastthenumberof objectscreated(sincethelastGC) -1. Ifthe number oflive objectsis0, we cannotcompute \na valid DL ratio and thus this information is discarded; otherwise, the DL ratio is a big number that \nimplies high instance reusability. In the second case, all objects created by an allocation site are \nstoredin a container and are needed simultaneously for a certain task. After the task is done, all of \nthem die together.Inthis case,the numberoflive objects at aGCis either the total number of objects created \nby the allocation site or 0, and the number of dead objects is either 0 or the total number of objects \ncreated. If the number of live objects is 0, the information is discarded again; otherwise, the number \nofdead objects mustbe0 and thus theDL ratio is 0, implying a very low chance for reuse. Eventually, the \nDL ratios computed at all GCs are averaged so that the informationlossdue to thelack oflive objects at \nsomeGCs would nothavebigimpact on our analysis outcome. It is clear to see that using DL ratio computed \nat a GC to approximate liveness may lead to both false positives andfalsenegatives.Forexample,inthe .rst \ncase(described above),ifthe numberoflive objectsis0, noDL ratiois com\u00adputed, resulting in afalse negative(becausethe \nobjects are indeeddisjoint).Inthe secondcase,ifGC occursinthe mid\u00addle of a resource releaseprocess where \nmany objects(cre\u00adatedby the allocation site) aredeadbut afew are stilllive, a big DL ratio may begeneratedforthis \nallocation sitelead\u00adingto afalsepositive.However,despitetheinformationloss andtheimprecision at one singleGC, \nwefoundthat averag\u00adingDL ratios at allGCpointsfor an allocation site can sig\u00adni.cantly reduce both false \npositives and false negatives becauseGCpoints aregenerallyindependentof each other, it is much less likely \nthat DL ratios computed at different GCsfor an allocation site are affectedbythe same mistreat\u00adment of \nits object lifetimes. This is the case especially for large-scale and long-running applications that \noften have a great number of GC runs. A detailed measurement of false positives reportedbyourtool canbefoundinSection4.1. \n Example Consider again the example in Figure 4. At GC1 and GC2, the DL ratios for the allocation site \nare 3/2 and2/1,respectively,makingits .nalDL ratio1.75.Thisra\u00adtiodoes notindicate anyproblembyitself, \nunlessitis com\u00adpared with DL ratios for other allocation sites. In this pro\u00adgram, however, reuse opportunities \ndo exist. For example, in an ideal case, creating 2 instances would be suf.cient at any point in the \nexecution, the maximum number of in\u00adstances needed simultaneouslyis2.  2.1.2 Computing DL Ratios In \norderto computetheDLratiofor each allocation site, we needtoidentifybothitslive objectsanddeadobjects \natGCs. Thisis done through tagging each object withits allocation site ID. Finding live objects is straightforward: \nduring the GC heap traversal, the number of reachable objects tagged with the same ID is counted and \nstored into a DL table. This table records, for each allocation site, the numbers of itslive objects \nanddeadobjects at eachGC.These numbers areused tocalculatea .nalDL ratiowhenareportisabout tobegenerated. \nFinding dead objects Itis much moredif.culttoiden\u00adtifydeadobjects at aGC.These objects cannotbefoundin \na regular objectgraph traversalbecause they are unreachable. A naive way of .nding such objects is to \ncreate a separate whole-heap traversalpass inGC that works after the reach\u00adable object graph traversal. \nIn this pass, each heap cell is visited to check if it contains a reference to a valid object thathas \nnotbeen marked aslive.However, visiting all cells in a big heap can be expensive and may thus incur a \nlarge run-time overhead. We use a modi.ed reference-counting algorithm to ef.\u00adciently detect dead objects. \nPerforming this algorithm re\u00adquires an additional space in each object to store its ref\u00aderence counter. \nGenerally, at each heap store a.f = b (or A.f = b), the old object originally contained in a.f (or A.f \n)is retrieved and its reference counter is decremented, and then the reference counter of the objectpointed \nto by b isincremented.If an object s referencecounterbecomes0, itis addedto a deadobjectqueue forfurtherprocessing. \nThere are many objects whose references are never as\u00adsigned toheaplocations.They are referenced onlyby \nstack variables and die immediately after their containing meth\u00adods return. If we instrument only heap \nwrite statements, these objects would not be added into the queue. To effec\u00adtively .nd them,we additionallyinstrument \neachheapload b = a.f to check the reference counter of the accessed ob\u00adject: if the reference counter \nof the object pointed to by a is 0, this object is also added to the queue. It will be re\u00admoved if its \nreference is written into a heap location later. Figure 5. An example ofdeadobjectqueue. The onlykind \nof(dead) objects that may still be missingin the queue are those that are never read and written during \ntheir lifetimes. Such objects are extremely rare and can be easily optimized awayby a compileroptimization(e.g.,via \ndeadcode removal). At eachGC,thedead objectqueue contains root(dead) objectsfrom which(almost) alldead \nobjectsin theheap can be reached. The queue may also contain some live objects (that are referencedonly \nby stack variables). These objects are .ltered out and will not be processed. In the garbage collector, \nwe create a separate pass after the regular object graph traversal to iteratively identify dead objects. \nWhen this pass executes, all live objects in the heap have already been visited and marked.Thispass then \ntraverses the object graph startingfromthe(root) dead objectsinthequeueto .ndthose that are not marked(aslive).An \nexampledead objectqueueis showninFigure5.Object O6 is alive object referenced by a stack variable and \nis not processed in this pass. There are many objects reachable from O4, among which only objectsnot \nmarked L (live) areidenti.ed.  2.1.3 Objects v.s. Data Structures Reportingreuse opportunitiesfordata \nstructures(with mul\u00adtiple levels of objects) can be more useful than doing so forindividual objects.Todo \nthis,for eachGC, we compute DL ratios only for allocation sites whose objects are in the deadobjectqueue.Theseobjectsare \nusuallythe rootsofdata structures containing many other objects.To accountfor the size of eachdata structurein \nour metric, theDL ratiofor an allocation site a is modi.ed to S *(D/L), whereD/L is the originalDL ratiodescribed \nearlier and S is a size measure\u00adment of the dead data structures created by a. The value of S is computed \nby calculating the average number of dead objects(directly and transitively) reachablefrom a s objects \nin the queue. Hence, S measures the size of the data struc\u00adture that has the same liveness property as \nthe root object. This part of object graph may be reused together with the root.Itis alsothetargetforourshapeanddatasummariza\u00adtiondescribedlaterin \nthis section.In the example shownin Figure5, thedeaddata structure rootedat O4 ishighlighted in the box, \nand the value of S for O4 s allocation site is 5.  These newDLratios are used asinstance summaries(shown \ninFigure3)to rank allocation sitesin the end.  2.2 Encoding Shapes The second reusability level is \nshape reusability. The goal of our analysis at this level is to .nd allocation sites that keepgeneratingdata \nstructures withthe same shapes(i.e., reference relationships).Asdescribed earlierin this section, data \nstructures we are interested in are the dead data struc\u00adtures rootedat objectsinthedeadobjectqueue(showninthe \nboxinFigure5),because objectsin thesedata structuresdie together and thus may have the same liveness \nproperty. In this stage, we comparethe shapes of alldeaddata structures rootedat objects createdbythe \nsame allocation sitethrough\u00adout the execution todetermine the shape reusabilityfor this allocation site. \nTwo heap data structures are considered to havethe same shapeif(1)their objectsubgraphs areisomor\u00adphic \nand(2)the correspondingobjectsin the two subgraphs are createdby the same allocation sites.Allocation \nsites are consideredbecauseit may notbepossibleto reusethe shape if objects constituting the shape in \ndifferent data structures are createdbydifferent allocation sites. Determiningwhethertwographsareisomorphicisknown \nto be NP-complete. What makes the problem even more complicatedisthattwodata structurescreatedby the \nsame allocation site are not always availablefor comparison,be\u00adcause at the time one data structure exists \nin the heap, the other one mayhave alreadybeengarbage collected.In order to enable ef.cient comparison, \nwe compute a shape sum\u00admaryfor eachdeaddata structure and recordit withits root allocation sitein a shape \ntable.This summary encodesboth the shape of a subgraph and its allocation site information. Summariesfordata \nstructures createdbythe same allocation site are comparedlatertodeterminethe shape reusabilityfor the \nallocation site. 2.2.1 Balanced-Parentheses Tree Encoding Algorithm While there exist many techniques \nto encode trees and graphs(primarilyinthe theory community),theirfocusis the space ef.ciency and the \nability of quickly performing common data structure operations (such as subtree, chil\u00addren, root, etc.) \nin the encoded form. On the contrary, our top concern is how to encode the allocation site IDs of the \nobjectsin adata structure withits run-time shape. We have studied a set of related encoding algorithms \n(e.g.,[5,17,20,29]),andfoundthatthebalanced-parentheses (BP) encoding algorithm is particularly suitable \nfor our shape summarization. The BP algorithm is proposed by Munro andRaman[29,30] to ef.ciently representbinary \ntrees, rooted orderedtrees, andbalancedparenthesis expres\u00adsions.This algorithmuses an amountofspace within \nalower order term of the information theoretic minimum and sup\u00adports a rich set of navigational operationsin \nconstanttime. Thekeyideais to representa tree containing n nodes with a string ofbalancedparentheses \noflength2n.A nodeis rep\u00ad   +5 . 3 .  +7 . + + ...   7 . 3 . + 5 . +  3 .  3 . + 5 . Figure \n6. An example showing our data structure shape encoding algorithm:(a) thebalanced-parenthesesencoding \nof an orderedtree;(b) assigningfactorsto nodes; and(c)the actual shape summary computation. resentedby \napairof matchingparentheses ( ... ) , which denote,respectively,thestartingpoint(i.e., ( ) and the.n\u00adishingpoint(i.e., \n) ) of adepth-.rsttraversal of thesubtree rooted at this node.Alldescendants ofthe node are encoded in \norder between its matching parentheses. A detailed ex\u00adample of this encoding is illustrated in Figure \n6 (a). It is straightforward to see that the resulting string records the depth-.rsttraversalofthe entiretree \nandit canbe ef.ciently storedin abit vector. This algorithmis suitablefor our analysisfor thefollow\u00ading \nthree reasons.First of all, each nodeis explicitly repre\u00adsentedinthe summary, makingit easierfor ustoincorporate \nallocationsiteIDs(notethatin aheapobjectgraph,the num\u00adberannotated with each nodeisitsallocationsiteID).Sec\u00adond,it \ncanbe computed ef.cientlyby a single tree traversal, which .ts well into the pass that we create for \ncomputing DL ratios(describedinSection2.1).Finally, theBP encod\u00ading respects the order of nodes in a \ntree. This is important forourshapeencoding,becausedifferent .eldsinanobject are ordered based on their \noffsets. Two data structures that reference the same objects in different orders should have differentsummaries. \n 2.2.2 Our Encoding Algorithm In orderto adapttheBP algorithmthat encodes only acyclic data structures, \nwe .rst have to break cycles in our data structures to turn them into trees. This can be easily done \nby computing a spanning tree of a data structure using a depth-.rsttraversal, whichis neededanywaytoperformthe \nBP encoding. While this causes information loss, we may miss only a very small number of (back) edges. \nBecause our summaries are usedfor comparisonpurposes(i.e., not for recoveringthe shape),thesebackedges \nare not critically important.Infact, wedidnot.nd any signi.cantfalse report due to thelackof such edgesin \nour experiments.  The original BP bit vector representation is insuf.cient when allocation sites aretakeninto \naccount.The major chal\u00adlengehereis how toincorporate allocation site IDsinto the BP parentheses. Explicitly \nrecording an allocation site ID with its corresponding parentheses would not be scalable, because, to \ndo this, a bit vector has to be expanded to an integer vector, which consumes orders of magnitude more \nspace. It is too expensive to record one such integer vector per run-timedata structureforthepostmortem \ncomparisons. To solve thisproblem,instead of using a vector to represent adata structure, wedevelopa \nnew algorithmthat computesa (probabilistically)unique valuefor thedata structure shape, together with \nits allocation site IDs, and uses this value as the shape summary of the data structure. This is conceptu\u00adally \nsimilar to encoding a dynamic calling context with a (probabilistically)unique value[11].Our encodingfunction \n. for a nodei in the treeis recursivelyde.nedas: (1). (i)= ( Ni + Sj.[0,#children-1]fj \u00d7.(child (j)) \n) where Ni is the number associated with node i. For a heap object, Ni is its allocation site ID, and \nchild (j)denotes the j-th reference-typed .eld of the object. ( and ) are the parentheses for node i \nin the BP bit vector representation. They are not explicitly representedin the summary, and are shownhere \nonlyforillustrationpurposes.For each nodein thetree,this recursivede.nitionallows usto computea sum\u00admaryforeach \nsubtreeof the nodeseparately(i.e.,rooted at child (j)) and compose them to form the summary for the node.Node \ni ssummaryiscomputed asthesumofits own ID and each of its children s summary .(child (j)) multi\u00adpliedbyafactor \nfj .Different child(i.e., subtree)is assigned adifferent fj ,and thustheorderof.eldsisrespectedinthe \nsummary. For the j-th child(j starts from 0), fj is simply de.ned as 2 \u00d7 j +3.Itisguaranteed tobe an(non-1) \nodd number,whichislesslikely(compared to an evennumber) to cause different fj \u00d7 .(child (j))to have the \nsame result. Obviously,thefunctionis non-commutativebecause of the mixture of addition and multiplication.Figure6(b) \nshows thefactor assignmentfor each node(exceptthe root).The actual summary computationbased on theBP \nstring andthe assignedfactorsis showninFigure6(c). As discussed earlier, the summary computed for each \ndata structure is recorded in a shape table for further com-parison.Because an allocation site canhave \nagreatnumber of distinct data structures, recording encoded values for all of them is not scalable. To \nmake our analysis scale to real\u00adworld applications,wereservea .xed-sizearray(e.g., s)of slotsfor each \nallocation sitein the table to store summaries. The summary of each data structure created by this alloca\u00adtion \nsiteis mappedinto a slot using a simple mod operation. In other words, for each summary . computed, we \nincre\u00adment the counter storedin s[. % |s|].Eventually,the shape reusabilityfor this allocation siteis \ncalculated as (2)maxi.[0,|s|-1] s[i]/ Si.[0,|s|-1]s[i] Thehigherthis value(whose maximumis1) is, the \nmore data structures created by the allocation site may have the same shape.In ourexperiments,wehavetried \na numberof differentsizes(from4to11)forthis array.Wefoundthat(1) alarge number(i.e., more slots)preserves \nmoreinformation than a small number(for obvious reasons) and(2) aprime numberpreservesmoreinformationthana \ncompositenum\u00adber.We chose7 as the size of this arrayin our experiments, becauseitisthelargestprimenumberforwhichallprograms \nin ourbenchmarkset could correctly run.OutOfMemory er\u00adror was seenin somelargeprograms(such asEclipse) \nwhen the nextprime number(i.e.,11) was used.  2.2.3 Computing Shape Summaries As dead data structures \nare our focus, the shape summary computationisdone along with theDL ratio computationin the additionalGCpass(describedearlierinSection2.1)that \ntraversesdead objects.One challengehereis that the object graphtraversalimplementedinGCis often a worklist-based \nbreadth-.rstalgorithm, while our summary computation re\u00adquires adepth-.rst traversal, which,ifimplementednaively \n(e.g., using recursion), cannot scale to large object graphs that are oftenhundreds oflayersdeep. We \ndevelop an ef.cientdepth-.rst traversal algorithm to computesummaries.This algorithmis conceptually similar \nto the one used in [1] to check the assert-ownedBy assertions.Thealgorithmis stillbased onworklistbutdoes \ndepth-.rst traversalby coloring objects.Algorithm1 shows thedetails ofthis algorithm. We maintain three \nworklistsinparallel an objectwork\u00adlist O that stores objectsforprocessing,afactor worklist F that containsfactors(fi)for \nthe correspondingobjectsin O, and a summary worklist F that contains the encoded sum\u00admaries for the subtrees \nrooted at the corresponding objects in O. There are three colors that can be used to mark ob\u00adjects: WHITE, \nGREY, and BLACK. Eachobject is marked WHITE initially. The .rst time an object is reached by the depth-.rst \ntraversal, it is marked GREY, indicating its sub\u00adtree is currently being visited. When this traversal \nis done, the object s coloris changed toBLACK,indicating this ob\u00adjecthasbeen visited. Eachiteration ofthe \nmainloop(line5)retrieves an object from worklist O (line 6). This object is not processed if it has alreadybeen \nvisitedbefore oritis stilllive(line7).Live objects cannot be part of a dead data structure. If it is \nthe .rst time to see this object during the traversal (line 11\u00ad18), we mark it GREY and push it back \nonto the worklist Algorithm 1: Computing shape summary for a dead data structure.  Input:Object o in \nthedead objectqueue Output:Shape summary . for thedata structure rooted at o 1 mark(o, WHITE ) 2 Objectworklist \nO .{o} 3 Factor worklist F .{1} 4 Summary worklist F . allocID(o) 5 while O= \u00d8 do 6 a . pop(O) 7 if \ncolor(a) = BLACK or isLive(a) = TRUE then 8 pop(F) 9 pop(F) 10 else 11 if color(a) = WHITE then // The \nfirst time we see it 12 mark(a, GREY ) 13 push(O, a) 14 foreach Non-null object b referencedin the i-th \n.eld of a do 15 mark(b, WHITE ) 16 push(O, b) 17 push(F, 2 * i + 3) 18 push(F, allocID(b)) 19 else // \nThe traversal of its subtree is done 20 mark(a, BLACK ) 21 fa . pop(F) 22 .a . pop(F) 23 index . .ndObjectWithColor(O, \nGREY ) 24 F(index) . F(index) + fa * .a 25 if O = \u00d8 then 26 . = .t 27 return . (line12-13).Allits children(i.e., \nobjectsit references)are pushed onto the worklist O (line 14-16). In addition, for each child i, we computeitsfactor \nfi basedonitsindex and pushthefactor onto thefactory worklist F (line17).Its own allocation siteIDispushed \nonto the summary worklist F as itsinitialsummary(line18).This value willbe updatedonce the summariesforits \nsubtrees are computed.Itis clearto see that the sequence of GREY objects in O identi.es the path currentlybeing \nexploredbythe traversal. Seeing thisGREY object again(line19-26)impliesthat its entire subtree has been \nvisited and the summary for the subtree has been appropriately computed. We mark it BLACK(line20),and \nretrievesits correspondingfactor fa and summary .a (line21-22).Next, we needto attributethis node s fa \n\u00d7 .a to the summary of its parent. The index of its parent node can be easily obtained by .nding the \nnext GREY object in O (line 23). The summary of the parent node(i.e., F(index ))is then updatedaccordingly(line24). \nExample Toillustrate,Figure7 containsthe .rstseven steps of computing the shapesummaryforthe rootnodein \nFigure6.O, F, and Fare thethree worklistsinAlgorithm1. Whilein realityOcontainsobjectreferences,theirallocation \nsite IDs are used here for illustration purposes. Figure 7 (a)showstheinitial state of theworklists(correspondingto \nlines 2 4 in Algorithm 1): O contains the root object, the initialfactorforthe root objectis1(in F), \nandF contains theallocationsiteID of theroot object,whichis1.The .rst step of the algorithm pops the \nobject out of O, changes its color toGREY, andpushesback onto O (lines6,12, and13 inAlgorithm1).All objectsdirectly \nreferencedby the .rst object are found and pushed onto O, as shown in Figure 7 (b). At this point, the \nfactors for objects 2, 6, and 8 are determined(i.e.,theyare 3, 5, and 7)andpushed ontofactor worklist \nF. Fcontains theirinitial allocation siteIDs. Next,object8isprocessed,andits children(objects9 and 10) \nare pushed onto O.Figure7(c) showsthe state of the worklists during the processing of object 10. Note \nthat objects whose colors are GREY in O form the current ex\u00adploration path(i.e., 1 . 8 . 10) in the depth-.rst \ntraver\u00adsal. At this moment, object 10 does not have any children and its color is GREY, so it is popped \nout of O (line 21 in Algorithm 1) and marked BLACK. BLACK nodes are not displayed in the example, because \nthey are not part of any worklist. Object 10 s f * f is calculated(line23 24inAl\u00adgorithm1)and added to \nthe summary ofitsparent(i.e., the nextGREY objectin O), makingthe summaryofobject8 58 (=8+5*10),as showninFigure7(d).Similarly, \nobject9is poppedanditsf * f (=3*9 =27)is addedtothe summary of object8.In step(e), theprocessing of the \nsubtree rooted at object 8 is done, and its shape summary is 85. Object 8 is thenpopped andits f * f \n(=7* 85 =595)is attributed to the summary of its parent, which is the root object. The last two steps \nshow the worklist updates when the subtree rooted at object6istraversed.Whenthedepth-.rsttraversal .nishes \nand object 1 is popped, worklist F will contain the shape summaryfor the entiredata structure.  2.3 \nEncoding Data Thethird stageof theanalysisisto .nd allocationsitesthat producedata structures with the \nsamedata content.Finding such allocation sites requires the encoding of data values containedinprimitive-typed \n.elds of eachdeaddata struc\u00adture.Wedevelop an algorithmsimilartothe shape summa\u00adrization approach to \nencode data values. Based on a depth\u00ad.rsttraversal, allprimitive-typeddatain adeaddata struc\u00adture are \nencodedinto a(probabilistically) unique value, and thenthevalueismappedtoaslotina .xed-sizearrayforthe \nallocation site.Thedata summaryfor adata structure rooted at object o isde.nedas: (3). (o)= Sj.[0,#.elds-1]fj \n\u00d7 pj child (j) Thej-th .eldhasaprimitivetype pj = .(child (j)) otherwise Unlike the shape summary computation \nthat considers al\u00adlocation site IDs and reference-typed .elds, this de.nition focuses on values in primitive-typed \n.elds and summarizes all such valuesin a recursive manner.Allocation siteIDs of objects are not consideredin \nthis algorithm.Similarly to the  OF F OF F OF F  OF F OF F OF F OF F 11     (a) (b) (c) (d) (e) \n(f) (g) Figure 7. A step-wise exampleillustrating the shape summary computationfor the treeinFigure6. \nshape summarization, a factor fj is assigned to each .eld, regardless of its type. If the .eld has a \nprimitive type, its valueis retrieveddirectlyandmultipliedwiththefactor;oth\u00aderwise, we recursivelycomputedata \nsummaryfor(the object referencedby)this .eld andthenattributetheresulting sum\u00admary tothe .nal summaryforthedatastructure.Thesame \nfunction(i.e.,2\u00d7j +3)is used todetermine fj for a .eld. Data summary computation is performed together \nwith shape summary computationin one singledepth-.rsttraver\u00adsal of the objects in the dead object queue. \nOur technique summarizesall typesofdatavalues.The .naldatasummary . is a 64-bit double value and this \nvalue is converted to a long valueforthe mod operation.For eachprimitive-typed array, we summarize allits \nelements, andfor each reference\u00adtyped array, we recursively summarize allits containing ob\u00adjects.Similarlytotheshapesummarycomputation,the \n.nal data summaryfor an allocation siteis a ratio(between0and 1)computedbyformula(2). Example Figure \n8 shows an example of computing the data summary for a data structure that contains 4 ob\u00adjects.Eachobjectis \nrepresentedby an array and each cellin the array represents a .eld. For each primitive-typed .eld, its \nvalue is directly shown in the cell, while a cell for a reference-typed.eld containsalinkpointing toanotherob\u00adject. \nThe factor assigned to each .eld is shown under the cellforthe .eld.Similarlytotheshapesummarization,each \nfactoris anodd numberstartingfrom3.Thedata summary for each objectis computedbased onformula(3) and then \nused to compute the data summary for its parent. The de\u00adtailed computation steps arelisted aside.If aprimitive-typed \n.eld containsabooleanor a charvalue,itis .rst converted to an integer before the computation is performed. \nFinally, summary DS0 is converted to along value(i.e.,35479) on which the mod operation(i.e., mod 7 in \nour experiments) isperformed.The counterinthe3-rd(= 35479%7)slot of the array reservedforthe allocation \nsiteinthedatatableis incremented.  2.4 Ranking and Reporting At the end of the execution, each allocation \nsite in the pro\u00adgram has three summaries computed by the encoder the averagedatastructureDL ratio(discussedinSection2.1.3) \nasitsinstance summary, andthe ratios computedbyformula (2)on the encoded shapes and the encoded data \nvalues as its shape and data summary. To report reuse opportunities, all allocation sites are .rst ranked \nbased on their instance summaries.There aretwo waysto usethis rankedlist.The topN allocation sites areforwarded \ntothe next stage(i.e., reusableshapedetector)forre-ranking.ThetopMallocation sites(M < N)are reportedtothe \nuserdirectlyfor manualin\u00adspection. Regardless of whether or not larger opportunities can be found in \nlater stages, these M allocation sites may point tointerestingproblems themselves andare thus worth inspecting. \nIn our experiments, M and N are set to 20 and 200, respectively. It appears that these are the appropriate \nchoices Mis a small enough so thatitdoes not overwhelm the user andNisbig enoughsothattheforwardedallocation \nsites retain most of the optimization opportunities. The N(= 200)allocation sites arethen re-rankedbased \nontheirshapesummaries.Similarly tothe .rst step,thetop M(= 20)allocation sites are reported to the user \ndirectly while alongerlist(whoselengthis150)isforwardedto the reusabledatadetector, which,in turn, re-ranksthelistbased \non their data summaries and reports the top 20 allocation sitesfor manualinspection.Notethat althoughthese \nspeci.c numbers are chosenfor our experiments, they canbe easily changedby adifferent user viaJVM command-line \noptions. 3. Implementation Wehaveimplementedour reusabledata structuredetectorin JikesRVM3.1.0, ahigh-performanceJavaVirtualMachine. \nWe add one word (32-bit) to the header of each object. This space is shared by the allocation site ID \n(the lower 16bits) and the reference counter(the upper16bits).We found that this space is suf.cient to \nstore these two pieces of information even in large applications such as Eclipse. During the dead object \ngraph traversal, the upper 16 bits  DS0= 3 * 1 + 5 * DS1 + 7 * 0.3 + 9 * DS2 + 11 * 6 + 13 * 143 = 35479.1 \nHeader 1 0.3 6 c 3 57 911 13  DS1= 3 * DS3 + 5 * 8.7 + 7 * 9  DS2= 3 * 1 + 5 * 4.1 + 7 * 5 = 6604.5 \n = 58.5 3 57  3 57 DS3= 3 * 142 + 5 * 145 + 7 * 145 = 2166 Factors 3 57 Figure 8. An example ofdata \nsummarycomputation. are also usedto storethe color of each visited object(see Algorithm1)because the \nreference counter ofadead object is nolonger needed. Wehave modi.edboththebaseline compiler andthe op\u00adtimizing \ncompiler to do the instrumentation. Our tool adds instrumentation at each allocation site that storesitsIDinto \nthe allocated object s header space. This ID can be used to .nd the sourcecodelocation(class, method,andline \nnum\u00adber)ofthe allocationsite.AsdescribedearlierinSection2.1, our tool alsoinstruments eachheap access \nstatement toper\u00adform appropriate reference counter updates. Objects whose reference counters are0 are \nadded to thedead objectqueue while objects that are alreadyin thequeuebut are written to heaplocations \nare removedfromthequeue.An optimization hereis to use onebit to markan object whenitis addedinto thequeue \nso that wedo not enqueue the object againifitis encounteredin aheap read.Thebitis clearedifitis removed \nfromthequeue. Although the technique piggybacks on garbage collec\u00adtion, it requires only a very small \nset of changes to an ex\u00adistinggarbage collector.In additionto addingapassto sum\u00admarize dead data structures, \nwe need to modify the regular object graph traversal to count the number of live objects foreachallocationsite.Ourcurrentimplementationsupports \nall non-generational tracinggarbagecollectors(e.g.,Mark\u00adSweep,MarkCompact, andImmix).The algorithmsmaynot \nwork well with a generational GC because a nursery GC scans only part of the heap, which may prevent \nour shape and data summarization algorithm from correctly identify\u00adingdeadobjects. 4. Evaluation We have \nperformed a variety of studies with our reusable data structure detector primarily using the DaCapo bench\u00admark \nset[8].Ourbenchmarks(showninTable2) include 11 programs in the DaCapo 2006 release, an additional set \nof 2 programs in its recent (9.12-bach) release, and the SPECJbb2000benchmark.Somelarge(server)programsin \ntheDaCapo9.12-bachrelease were notchosen,becausethey could not run onthe version of theJikesRVM we used(i.e., \n3.1.0). DaCapo programs were executed with their large workloads,andSPECJbb2000 was executed underits \nstan\u00addardcon.guration(i.e.,ramp up seconds =30andmeasure\u00adment seconds =120).All experimentswererunonaquad\u00adcore \nmachine with anIntelXeonE56202.40GHzprocessor, runningLinux2.6.18.The maximumheap size speci.edfor eachprogram \nrun was1GB. 4.1 Case Studies We have carefully inspected the tool reports and found op\u00adtimization opportunitiesin \nall of the14benchmarks.In this subsection, we report our studies on 6 benchmarks: bloat, chart,luindex,lusearch, \nxalan, andSPECJbb2000.Problems in these programs are chosen to report because they point tolarge optimization \nopportunities byreusingthe reported data structures, we have achieved either large total running time \nreduction(e.g.,37.3%inbloat) orlargeGCtime re\u00adduction(e.g.,22%in xalan).Ittook us about1.5 weeksto .nd \ntheproblemsandimplementthe .xesforthese6 appli\u00adcations we were not familiar with. More insightful changes \ncould have been made if their developers had seen the re\u00adportsandcomeup with.xesthemselves.Although weused \ntheJikesRVM to .nd reusabledatastructures,performance statistics(beforeand afterproblem .xes) werecollected \non Hotspot 64-bit Server VM build 1.6.0 27. Jikes RVM ap\u00adpeared to be unstable we often saw inconsistent \nperfor\u00admance reports for different runs of the same application on it. In order to avoid the compilation \ncost and the execution noise, each application was run 5 times and the median of the runningtimesis reportedin \nthis subsection. chart chartis agraphplotting toolkitthatplotsa num\u00adber ofcomplexlinegraphs and rendersthem \naspdf viaitext. The No. 1 allocation site in all the three reusability reports was at line 767 of class \ndacapo.chart.Datasets, which creates an array of XYSeries objects in method createPtrAgeHistData.Theaveragesize \nofthe(dead) data structures createdbythis allocation site was94663 and all their shapes were the same \n(i.e., its shape reusability was1).Althoughtheirdata values weredifferent(itsdata reusability is 0.66), \nwe found a way to reuse their shapes andinstances.Becausedifferentinstances of the array(as well asthe \nXYSeries objectsinthem) are never needed si\u00admultaneouslyintheprogram,we moved this allocationsite out \nofthe method createPtrAgeHistData and madeit referencedbya static .eld.As such, notonlythe arrayobject \nbut also its containing XYSeries objects are cached. We inserted code into the method to reinitialize \nan XYSeries object(by resetting it with the new content) only ifitis re\u00adquested. In fact, we found that \nin many executions of the method, a number of XYSeries objects were not used at all, and thus, the effort \nto recreate and reconstruct these objects was completely saved by our .x. The .x led to a runningtime \nreduction of24.2%(from7073msto5364ms). The number ofGCruns andthetotalGCtime were reduced, respectively,by6.5% \nandby15.3%.No reduction was seen on thepeak memory consumption.  luindex luindex is a text index tool \nthat indexes a set ofdocuments.The allocation site relatedtotheproblem was No.2inthereusableinstancereportandNo.1inthereusable \nshape report. It created an array of Posting objects in methodsortPostingTable ofclass DocumentWriter. \nThe average size of the data structures created by this allo\u00adcation site was2094.The methodtakes aHashtable \nasinput, sorts the elements of this table using a quicksort algorithm, and returns alist containingthe \nsorted elements.Becauseits implementation ofquicksortworks only on arrays,this allo\u00adcation site creates \nan array simply to store the elements of the Hashtable to be processed by quicksort. After the sort\u00ading \n.nishes, a new list is created. The sorted elements are copied from the array to the list, which is .nally \nreturned. Weimplementedtwo .xes:we .rstpulled outthelist alloca\u00adtionsiteand used astatic .eld tocacheitsinstance,because \none instance of the list would suf.ce for all executions of the method.Second, we eliminated this array \nallocation and used aninsertionsort algorithmtogradually copy elements fromtheHashtabletothislist.We \nsaw a17.6%runningtime reduction(from8298ms to6783ms) and a21.8% reduction on the total number of objects \ncreated(from36019657 to 28183309).The number ofGC runs and thetotalGC time were reduced from 35 to 28 \n(20%) and from 1048ms to 929ms(11.4%), respectively.Thepeak memory consump\u00adtion was reducedfrom46468KBto41384KB(12.3%). \nbloat bloatis abytecode-leveloptimizationtoolforJava that analyzes and optimizes some ofits own classes.Almost \nall allocationsitesinthethreereportspointtoreuse oppor\u00adtunities.One major category ofproblems was thepervasive \nuse ofanonymousclasses(implementingthe visitorpattern), asdescribedinSection1.By reusinginstancesand \ncontent of these allocation sites, we achieved a reduction of 37.3% in running time(from28783msto18053ms).The \nnumber ofGC runs and thetotalGC time were reducedfrom66 to Bench Categories I S D chart 5 5 4 bloat 0 \n0 0 luindex 8 6 2 lusearch 6 4 2 xalan 0 0 0 jbb 4 4 1  Table 1. Numbers offalsepositivesin the top20allocation \nsites of each reusability categoryfortheprogramswehave studied. 55(16.7%) andfrom4132msto3694ms(10.6%), \nrespec\u00adtively. The peak memory consumption was reduced from 813264KBto732140KB(11.1%). lusearch lusearch \nis a text search tool that looks for keywords over a corpus of data. The .rst allocation site in the \nreusable instance report was at line 119 in method parse of class QueryParser. This allocation site cre\u00adates \na QueryParser objecteach time a newquery string is generated in order to parse the string into a Query \nob\u00adject. Because the parser object never escapes to the heap, each thread needs only one instance of \nthis data struc\u00adture at any point during the execution. To solve the prob\u00adlem, we created a static QueryParser \narray that main\u00adtains one QueryParser object per thread, and added a reset method in class QueryParser. \nEach time a QueryParser objectis needed, this methodisinvoked to resetitscontent.Whilethissimple .xdid \nnotlead tosignif\u00adicantrunningtime reduction onHotspot(onlyfrom1872ms to 1867ms), it reduced the number \nof GC runs from 34 to 31(9%) andthepeak memory consumptionfrom78.6MB to75.0MB(4.7%). xalan xalan is an \nXSLT processor for transforming XML documents. The .rst allocation site in the reusable instance report \nwas in the constructor of class XPath that created an XPathParser object to parse each expres\u00adsion string \ninto an XPath object. Similarly to the han\u00addling of QueryParser in lusearch, we created a static .eld \nto cache its instance and reset it upon request. In ad\u00addition, a few allocation sites in the reusable \ndata report in\u00addicated that objects of type TransformerImpl might have the same content. Upon code inspection, \nwe found that these objects were transitively created by a call in dacapo.xalan.XalanHarness. This call \nsite is lo\u00adcated in a while loop and creates an XML transformer per iterationofthelooptotransformanincomingXML.le.Be\u00adcausethesetransformerdata \nstructures are exactlythe same, wehoisted thiscall siteout of theloop.These .xesreduced thetotal number \nofGC runsfrom50 to37(26%), and the totalGC timefrom2819msto2200ms(22.0%).No signif\u00adicant reduction was \nseen on the running time and the peak memory consumption.  SPECJbb2000 SPECJbb2000 simulates an online \ntrad\u00ading system.The .rst .veallocationsitesinthethreereports were the same. Each of these allocation \nsites creates an ob\u00adject ofatransactiontype(i.e., DeliveryTransaction, OrderStatusTransaction,PaymentTransaction, \nNewOrderTransaction,and StockLevelTransac\u00adtion)per iteration of the main loop, while all transaction \nobjects of the same type are completely disjoint, and have the same shapes and data content. We employed \na thread\u00adsingleton pattern in the implementation of each transaction class, and this .x improved the \noverall throughput from 148128opr/secto155414opr/sec(4.7%).No reduction was seen on GC running time and \nmemory consumption, be\u00adcausetheperformanceofSPECJbb2000is evaluatedbased ona .xed-timeexecution.A moreef.cientimplementation \nshould process a larger workload in a speci.ed period of time (re.ected by the improved throughput), \nbut does not necessarily reduce the GC effort and the memory require\u00adment. Summary and discussion Despite \nthe approximations usedinouranalysis,wedid not .nd manyfalsepositivesin thetoolreports.Table1showsthe \nnumbersoffalsepositives we identi.ed during the inspection of the top 20 allocation sitesfor eachprogram.An \nallocation siteis considered as a falsepositiveifeitheritis clearly not aproblem or we could notdevelop \na solution to reuseits objects.Wefound that an important source of false positives is the use of linked \ndata structures. For example, both luindex and lusearch create a greatnumberofToken objectsduringtheparsingofexpres-sions.These \nobjects arelinkedthroughtheir next .eld and any regular operation of the list can break a link and make \nmany such objectsbecome unreachable.The allocation sites creating them often have big DL ratios while \ntheir objects are not truly reusable. We did not .nd any false positives resultingfromthehash collisionsinthe \nshape anddata sum\u00admarization algorithms.Data structures(amongthetop20 re\u00adportedallocation sites) whose \nshape anddata summaries are 1 are indeed completely invariant. False positives found in the second and \nthird stage reports are all inheritedfrom the .rst stage report.Thisis not surprisingbecauseprecisely \nap\u00adproximatingobjectlifetimesisthe mostdif.cultpartinthe detection ofreusabledata structures. Whileitisinteresting \nto understand the collision ratesin the shape/data summarization, they are dif.cult to measure for large \nprograms. To verify whether run-time data struc\u00adtures createdbythe same allocation sitehavethe same shape \nor data content would require a whole program execution tracethat records allheap accesses and valuesduringthe \nex\u00adecution. Such a trace can only be obtained through whole programdynamicslicing[2,48,49,50] andvaluepro.l\u00ading[12], \natask thatisimpossibleto scaleto real-world ap\u00adplications. We found that true problems are often very \neasy to .x. OnesolutionoracombinationofsolutionsshowninFigure2 is always suf.cientforusto reusetheidenti.eddata \nstruc\u00adtures.Anotherimportant observationisthat shape reusabil\u00adity often couples tightly with data reusability. \nIn each pro\u00adgram we studied, morethanhalfofthe allocation sitesinthe shape reusability report also appear \nin the data reusability report.Thisinfact makesit easierforustoimplement .xes because the overlap often \npoints to data structures that are completelyinvariantduring the execution.For afew alloca\u00adtion sitesinSPECJbb2000, \nwe classi.ed them asfalseposi\u00adtivesbecause we couldnot understandwhytheyare reusable byinspectingonlythe \nallocation sites.These allocation sites arelocatedinfactorymethodsthatcreate objects,arrays,and strings \nfor many different components of the program, and therefore, it is dif.cult to understand under what \ncontexts these objects canbe reused without moredetailedinforma\u00adtion.Future work may considerto add contextpro.linginto \nthis analysis toprovidedevelopers with more usefuldebug\u00adginginformation.  4.2 Reusability and Overhead \nMeasurements All overhead statistics reportedinthis subsectionwere col\u00adlected from Jikes RVM 3.1.0, running \na high-performance con.guration FastAdaptiveImmix. This con.guration uses theoptimizing compilertocompileboth \ntheJVM codeand the application code, and the Immix garbage collection al\u00adgorithm [7]. Section (a) in \nTable 2 reports the measure\u00adments of reuse opportunities. Each column in Section (a) shows, for each \nprogram, the size of the intersection of the reported allocation sites in different categories. The higher \nthese numbers are, the easier it is for human developers to .nd optimization opportunities and implement \n.xes. Note that many allocation sites appear in all of the three reports (shown in I n S n D), whichstrongly \nindicates reuse op\u00adportunities. Column #Inv reports the numbers of invariant data structures both their \nshapes and their data values are unchangedthroughoutthe execution.Evenif theirinstances may notbe reusable,these \nallocation sites maypointtodeep design/implementationissues(e.g.,designing an algorithm that is unaware \nof the characteristics of its input data) and .xing theseissues canoftenlead tolargerperformanceim\u00adprovement(thanjustreusingdata \nstructureinstances). Section(b) of thetable showsthe overhead of thetech\u00adnique.The running time measuredforourtool(shownin \ncolumn T1) includes both the time for the program execu\u00adtion(including the online summarization) and \nthetimefor thepostmortemanalysis,becausethe analysisisperformed beforetheJVMcompletely exits.Overall, \nourtool slowsthe programsdownby10.8%.The space overheadis measured byidentifyingthe maximumpost-GCmemory \nconsumption during the execution.The overall space overheadis30.3%, whichisprimarilyduetothe additionalheader \nspaceper ob\u00adjectand thedead objectqueue.In one case(i.e.,jython), the peak memory consumption for our \ntool is even lower than thatforthe originalrun,presumablybecauseGCistriggered at a different set of program \npoints (in the modi.ed run) Table 2. Reusability and overhead measurements:Section(a) showsthe numbers \nof allocation sitesthat appearinboth the report ofinstance reusability and that of shape reusability(I \nn S), the numbers ofallocation sites that appear in the reports ofinstance anddata reusability(S n D),the \nnumbersofallocation sitesthat appearin all thethree reports(I n S n D), and the numbers of allocation \nsites whose shape summaries anddata summaries are1(#Inv);section(b) reports the runningtimes of the original(T0)and \ntheinstrumented(T1)programs, andtheirpeak memory consumptions(S0 and S1 respectively). .We measurethroughputinstead \nof runningtime.  Bench (a)Reusabilitymeasurements (b)Overheadmeasurements I nS S nD I nS nD #Inv T0(s) \nT1(s) S0(MB) S1(MB) antlr 6 14 4 1 10.8 11.7(8.7%) 42.3 59.1(39.7%) bloat 3 13 3 1 41.2 43.2(4.8%) 63.7 \n89.1(39.9%) chart 8 4 3 13 43.9 44.9(2.5%) 37.2 63.1(69.6%) eclipse 8 14 7 1 15.3 17.0(11.0%) 35.3 78.9(123.0%) \nfop 11 14 6 22 1.1 1.2(14.7%) 66.2 97.3(30.3%) hsqldb 3 17 3 18 6.5 8.0(23%) 32.6 36.5(12.0%) jython \n5 18 5 19 25.7 30.4(18.3%) 108.6 85.2(-21.5%) luindex 8 12 3 10 11.9 13.6(13.8%) 48.9 85.7(75.3%) lusearch \n9 16 5 10 5.7 13.9(143%) 74.7 97.3(30.3%) pmd 4 15 4 12 11.6 12.7(9.6%) 90.8 111.0(22.3%) xalan 3 17 \n3 25 13.1 29.7(127.4%) 17.8 23.4(31.1%) avrora 15 18 13 28 22.1 22.9(3.4%) 66.3 70.0(5.6%) sun.ow 10 \n11 5 21 43.5 43.9(1.0%) 104.9 129.7(23.7%) SPECJbb 11 13 7 15 110583. 104936. (5.1%) 513.7 513.9(0%) \nGeoMean 10.8% 30.3% that happens to have a lower maximum reachable memory size. While these overheads \nmay be too high in a produc\u00adtion setting, we found they are acceptable for performance tuninganddebuggingpurposes \ntheyhave notprevented us from collectingdatafrom anyreal-world application.Future work could use sampling \nto reduce overhead.We may also de.ne a tradeoff framework between the quality of the re\u00adported information \nand the frequency of running the addi\u00adtional(deaddatastructuresscanning) pass,and .nd abal\u00adance point \nwhere suf.cient information can be reported at acceptablylow cost. 5. Related Work GC-based heap analysis \nThere exists abody of work that piggybacks on garbage collection to discover heap-related programproperties,such \nas object staleness[10,45],types withgrowinginstances[22], and object reachabilityprop\u00aderties[1,4,37].Merlin[19] \nis anef.cientalgorithmthat canprovideprecise time-of-death statisticsforheap objects by computing when \nobjectsdie using collected timestamps. While our work alsofallsinto this category, ourgoalisdif\u00adferentfrom \nall existing techniques we usegarbage collec\u00adtionto .nd reusabledatastructures. Heap optimization for \nJava programs Object Equality Pro.ling (OEP) [23] is a run-time technique that discov\u00aders opportunitiesforreplacing \na set of equivalent objectin\u00adstances with a single representative object to save space. Unlike our approach \nthat encodesdata structure shapes and valuesto approximatetheir reusability,OEP recordsan ex\u00adecution \ntrace and usesit todetect equivalent objects of.ine. Hence, OEP can incur a signi.cantly higher overhead \nthan our summarization-based approach. In addition, by focus\u00adingon allocation sites and comparing objects \ncreatedby the same allocation site, our analysis is able to produce more speci.cdiagnosticinformationthanOEP, \nwhich attemptsto .nd opportunities among arbitrary objects of the same type. Sartor et al. [33, 34] propose \nrun-time techniques to com\u00adpress heap data, particularly arrays. Instead of optimizing programs atsuch \nalow(system)level, our techniquetargets logical data structures and attempts to .nd both space and time \noptimization opportunities by detecting reusable data structures. Software bloat analysis Aslarge-scale \nobject-orientedap\u00adplications arepervasivelyused and theirperformanceprob\u00adlems become signi.cant, a body \nof work has been devoted to software bloat analysis [3, 25, 27, 28, 36, 40, 41, 42, 43, 44, 47] that \nattempts to .nd and remove performance problems due to inef.ciencies in the code execution and the use \nof memory.Prior work[24,25]proposes metrics to provide performance assessment of use of data structures. \nMitchell et al. [26]proposea manualapproach thatdetects bloatby structuringbehavioraccording tothe .owofinfor\u00admation,andtheirlaterwork[25] \nintroducesawayto .nd data structures that consume excessive amounts of memory. WorkbyDufouret al. [15]uses \nablended escape analysisto characterizeand .nd excessiveuseof temporarydatastruc\u00adtures.This work approximates \nobjectlifetimes using control .ow regions such as a method invocation or a sequence of method invocations, \nwhereas our work is more concerned about whether lifetimes of different objects created by the same allocationsite \ncan overlap,whichis much moredif.\u00adcult to .nd using static analysis.  Shankaret al. proposeJolt[36], \nwhichmakes aggressive methodinlining decisionsbased ontheidenti.cation of re\u00adgionsthatmake extensive \nuse oftemporaryobjects.Workby Xuet al. [42]detects memorybloatbypro.lingcopy chains and copygraphs.Other \nwork[35]dynamicallyidenti.esin\u00adappropriately used Java collections and recommends to the userthosethat \nshould reallybe used.Recent work[13]iden\u00adti.es11 commonpatterns of memoryinef.ciencies andpro\u00adposes aContainerOrContainedmodeltodetectsuchpatterns \ninheapsnapshots.Differentfromallexistingwork,ourtech\u00adniqueisanewtypeofbloatanalysisthataimsto .nd reuse \nopportunitiesin theprogram usingGC-basedheap analysis. Static liveness approximation Escape analyses[9,14,16, \n38] are designed to identify objects whose lifetimes are within thelifetime of the stackframe of the \nmethod that al\u00adlocates the objects.These objects canbe stack allocatedfor increasedperformance.WorkbyRuggieriandRuggieri[32] \nattempts to use static data.ow analysis to approximate ob\u00adjectlifetimesin orderto enable various optimizations \non ob\u00adjectallocationanddeallocation.Gheorghioiuet al. proposea static analysis[18] toidentify unitary \nallocation sites whose instances are completelydisjoint so that theseinstances can bepre-allocated and \nreused.Whilethisis similartothede\u00adtectionof reusableinstancesinourwork,we can .nd more opportunities \nsuch as reusable shapes and reusabledata.Re\u00adcent work such as [6, 46] uses static analysis to identify \nreusable data structures created in a loop. However, in a large-scale application, reuse opportunities \nmay be located in methods far away from a loop, limiting signi.cantly the real-world usefulness of these \nanalyses. In addition, static techniquescan .nd onlydatastructuresthat arereusablefor all possible runs \nand thus may miss opportunities that exist only for certain executions.Our work overcomestheprob\u00adlem \nby .nding reusable data structures completely online, leading to the detection of more opportunities \nand the im\u00adprovedusefulness. 6. Conclusions and Future Work The paper presents the .rst dynamic technique \nto .nd data structures that can be reused for better performance. In order to fully expose optimization \nopportunities, we de\u00ad.ne reusability at three different levels: instance reusabil\u00adity, shape reusability, \nand data reusability, each providing a unique perspective in .nding reuse opportunities. It is impossible \nto compute precise reusability information, and thus,for eachreusability category,wedevelopa correspond\u00ading \napproximation to .nd data structures that fall into this category. Particularly, we compute Dead/Live \nratios to ap\u00adproximate instance reusability, and summarize data struc\u00adture shapes and data values to \napproximate shape and data reusability, respectively. We have implemented this tool in the Jikes RVM \nand applied it to a set of large-scale appli\u00adcations. Our experimental results demonstrate that the tool \nincursa reasonableoverhead and reportsproblemsthat can beeasily.xedforlargeperformancegains. The positive \nresults from this work would serve as the motivation for the further investigation of the problem of \nreusing objects/data structures. For example, the existence of a large number of reusable data structures \nstrongly calls for a new runtime system that can automatically cache and reusedata structuresduringtheprogram \nexecution.Weplan todevelop such a systemin thefuture. Acknowledgments We wouldliketothankMichaelBondforhishelpful \ncom\u00adments on an earlydraft ofthepaper.We alsothanktheOOP-SLAreviewersfortheir valuable and thoroughcomments. \nReferences [1] E. E. Aftandilian and S. Z. Guyer. GC assertions: Using the garbage collectorto checkheapproperties. \nInACMSIGPLAN Conference on Programming Language Design and Imple\u00admentation(PLDI),pages235 244, 2009. \n[2] H. Agrawal and J. R. Horgan. Dynamic program slicing. In ACM SIGPLAN Conference on Programming Language \nDesign andImplementation(PLDI),pages246 256, 1990. [3] E.Altman,M.Arnold,S.Fink, andN.Mitchell. Performance \nanalysis of idle programs. In ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, \nLan\u00adguages, andApplications(OOPSLA),pages739 753, 2010. [4] M. Arnold, M. Vechev, and E. Yahav. QVM: \nAn ef.cient runtime for detecting defects in deployed systems. In ACM SIGPLAN International Conference \non Object-Oriented Pro\u00adgramming,Systems,Languages, andApplications(OOPSLA), pages143 162, 2008. [5] D.Benoit,E.D.Demaine,J.I.Munro, \nR.Raman,V.Raman, andS.S.Rao. Representing trees ofhigherdegree. Algorith\u00admica,43:275 292, 2005. [6] S. \nBhattacharya, M. Nanda, K. Gopinath, and M. Gupta. Reuse, recycle tode-bloat software. In European Conference \non Object-OrientedProgramming(ECOOP),pages408 432, 2011. [7] S.M.Blackburn andK.S.McKinley. Immix: amark-region \ngarbage collector with space ef.ciency, fast collection, and mutator performance. In ACM SIGPLAN Conference \non Programming LanguageDesign andImplementation(PLDI), pages22 32,2008. [8] S. M. Blackburn, R. Garner, \nC. Hoffman, A. M. Khan, K. S. McKinley, R. Bentzur, A. Diwan, D. Feinberg, D. Framp\u00adton, S. Z. Guyer, \nM. Hirzel, A. Hosking, M. Jump, H. Lee, J. E. B. Moss, A. Phansalkar, D. Stefanovi\u00b4c, T. VanDrunen, D. \nvon Dincklage, and B. Wiedermann. The DaCapo bench\u00admarks:Javabenchmarkingdevelopment and analysis.In \nACM SIGPLAN International Conference on Object-Oriented Pro\u00ad  gramming,Systems,Languages, andApplications(OOPSLA), \npages169 190, 2006. [9] B. Blanchet. Escape analysis for object-oriented languages. ApplicationstoJava.InACMSIGPLANInternationalConfer\u00adence \non Object-Oriented Programming, Systems, Languages, andApplications(OOPSLA),pages20 34,1999. [10] M. \nD. Bond and K. S. McKinley. Bell: Bit-encoding online memoryleakdetection. In InternationalConference \nonArchi\u00adtectural Support for Programming Languages and Operating Systems(ASPLOS),pages61 72,2006. [11] \nM. D. Bond and K. S. McKinley. Probabilistic calling con\u00adtext. In ACMSIGPLANInternationalConference onObject-Oriented \nProgramming, Systems, Languages, and Applica\u00adtions(OOPSLA),pages97 112,2007. [12] B. Calder, P. Feller, \nand A. Eustace. Value pro.ling. In In\u00adternationalSymposium onMicroarchitecture(MICRO),pages 259 269,1997. \n[13] A. E. Chis, N. Mitchell, E. Schonberg, G. Sevitsky, P. O Sullivan, T. Parsons, and J. Murphy. Patterns \nof mem\u00adoryinef.ciency. In EuropeanConference onObject-Oriented Programming(ECOOP),pages383 407, 2011. \n[14] J. Choi, M. Gupta, M. Serrano, V. Sreedhar, and S. Midkiff. Escape analysis for Java. In ACM SIGPLAN \nInternational Conference on Object-Oriented Programming, Systems, Lan\u00adguages, and Applications(OOPSLA),pages1 \n19,1999. [15] B.Dufour,B.G.Ryder, andG.Sevitsky. Ascalabletechnique for characterizing the usage of temporaries \nin framework\u00adintensive Java applications. In ACM SIGSOFT Interna\u00adtional Symposium on the Foundations \nof Software Engineer\u00ading(FSE),pages59 70,2008. [16] D. Gay and B. Steensgaard. Fast escape analysis and \nstack allocation for object-based programs. In International Con\u00adference onCompilerConstruction(CC), \nLNCS 1781, pages 82 93,2000. [17] R.F.Geary,R.Raman, and V.Raman. Succinct ordinal trees with level-ancestor \nqueries. In ACM-SIAM Symposium on DiscreteAlgorithms(SODA),pages1 10,2004. [18] O. Gheorghioiu, A. Salcianu, \nand M. Rinard. Interprocedu\u00adral compatibility analysis for static object preallocation. In ACM SIGPLAN-SIGACT \nSymposium on Principles of Pro-grammingLanguages(POPL),pages273 284, 2003. [19] M.Hertz,S.M.Blackburn,J.E.B.Moss,K.S.McKinley, \nand D.Stefanovi\u00b4c. Generating objectlifetimetraceswithMerlin. ACMTransactions onProgrammingLanguages \nandSystems, 28(3):476 516, 2006. [20] J. Jansson, K. Sadakane, and W.-K. Sung. Ultra-succinct representation \nof ordered trees. In ACM-SIAMSymposium on DiscreteAlgorithms(SODA),pages575 584, 2007. [21] R.E.Jones \nandC.Ryder. A study ofJava objectdemograph\u00adics. In International Symposium on Memory Management (ISMM),pages121 \n130, 2008. [22] M. Jump and K. S. McKinley. Cork: Dynamic memory leak detectionforgarbage-collectedlanguages.InACMSIGPLAN-SIGACT \nSymposium on Principles of Programming Lan\u00adguages(POPL),pages31 38,2007. [23] D.Marinov andR.O Callahan. \nObjectequalitypro.ling. In ACMSIGPLANInternationalConference onObject-Oriented Programming,Systems,Languages, \nandApplications(OOP\u00adSLA),pages313 325, 2003. [24] N. Mitchell. The runtime structure of object ownership. \nIn European Conference on Object-Oriented Programming (ECOOP),pages74 98,2006. [25] N. Mitchell and G. \nSevitsky. The causes of bloat, the lim\u00adits of health. ACM SIGPLAN International Conference on Object-OrientedProgramming,Systems,Languages, \nandAp\u00adplications(OOPSLA),pages245 260, 2007. [26] N.Mitchell,G.Sevitsky,andH.Srinivasan.Modeling runtime \nbehaviorinframework-based applications. In European Con\u00adference on Object-Oriented Programming (ECOOP), \npages 429 451, 2006. [27] N. Mitchell, E. Schonberg, and G. Sevitsky. Making sense of large heaps. In \nEuropean Conference on Object-Oriented Programming(ECOOP),pages77 97,2009. [28] N. Mitchell, E. Schonberg, \nand G. Sevitsky. Four trends leading to Java runtime bloat. IEEE Software, 27(1):56 63, 2010. [29] J. \nMunro and V. Raman. Succinct representation of balanced parentheses, static trees and planar graphs. \nIn IEEE Sym\u00adposium onFoundations ofComputerScience(FOCS), pages 118 126, 1997. [30] J.I.Munro andV.Raman.Succinct \nrepresentation ofbalanced parentheses andstatictrees. SIAMJ.Comput.,31(3):762 776, 2001. [31] C.Reichenbach, \nN.Immerman, Y.Smaragdakis, E.Aftandil\u00adian, and S. Z. Guyer. What can the GC compute ef.\u00adciently? A language \nfor heap assertions at GC time. In ACM SIGPLAN International Conference on Object-Oriented Pro\u00adgramming,Systems,Languages, \nandApplications(OOPSLA), pages256 269, 2010. [32] C. Ruggieri and T. P. Murtagh. Lifetime analysis of \ndynam\u00adically allocated objects. In ACM SIGPLAN-SIGACT Sym\u00adposium on Principles of Programming Languages \n(POPL), pages285 293, 1988. [33] J. B. Sartor, M. Hirzel, and K. S. McKinley. No bit left behind:thelimitsofheapdatacompression. \nIn International Symposium on Memory Management (ISMM), pages 111 120,2008. [34] J. B. Sartor, S. M. \nBlackburn, D. Frampton, M. Hirzel, and K.S.McKinley. Z-rays:divide arrays and conquer speed and .exibility. \nIn ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI), pages 471 482,2010. \n[35] O.Shacham,M.Vechev, andE.Yahav. Chameleon:Adaptive selection of collections. In ACM SIGPLAN Conference \non Programming LanguageDesign andImplementation(PLDI), pages408 418, 2009. [36] A. Shankar, M. Arnold, \nand R. Bodik. JOLT: Lightweight dynamic analysis and removal of object churn. In ACM SIGPLAN International \nConference on Object-Oriented Pro\u00adgramming,Systems,Languages, andApplications(OOPSLA), pages127 142, \n2008.  [37] M. Vechev, E. Yahav, and G. Yorsh. PHALANX: Parallel checking of expressiveheap assertions. \nIn InternationalSym\u00adposium onMemoryManagement(ISMM),pages41 50,2010. [38] J. Whaley and M. Rinard. Compositional \npointer and escape analysis for Java programs. In ACM SIGPLAN International Conference on Object-Oriented \nProgramming, Systems, Lan\u00adguages, and Applications(OOPSLA),pages187 206, 1999. [39] G. Xu. Analyzing \nLarge-Scale Object-Oriented Software to Find and Remove Runtime Bloat. PhD thesis,TheOhioState University,2011. \n[40] G.Xu andA.Rountev.PrecisememoryleakdetectionforJava software using container pro.ling. In International \nConfer\u00adence on SoftwareEngineering(ICSE),pages151 160, 2008. [41] G.Xu andA.Rountev.Detectinginef.ciently-usedcontainers \nto avoid bloat. In ACM SIGPLAN Conference on Program\u00adming Language Design and Implementation (PLDI), \npages 160 173,2010. [42] G.Xu,M.Arnold,N.Mitchell,A.Rountev, andG.Sevitsky. Go with the .ow: Pro.ling \ncopies to .nd runtime bloat. In ACM SIGPLAN Conference on Programming Language De\u00adsign and Implementation(PLDI),pages419 \n430, 2009. [43] G. Xu, M. Arnold, N. Mitchell, A. Rountev, E. Schonberg, and G. Sevitsky. Finding low-utility \ndata structures. In ACM SIGPLANConference onProgrammingLanguageDesign and Implementation(PLDI),pages174 \n186, 2010. [44] G.Xu,N.Mitchell,M.Arnold,A.Rountev, andG.Sevitsky. Software bloat analysis: Finding, \nremoving, and preventing performance problems in modern large-scale object-oriented applications. In \nFSE/SDPWorkingConference ontheFuture of Software Engineering Research(FoSER), pages 421 426, 2010. [45] \nG. Xu, M. D. Bond, F. Qin, and A. Rountev. Leakchaser: Helping programmers narrow down causes of memory \nleaks. In ACM SIGPLAN Conference on Programming Language Design andImplementation(PLDI),pages270 282, \n2011. [46] G. Xu, D. Yan, and A. Rountev. Static detection of loop\u00adinvariant data structures. In European \nConference on Object-Oriented Programming(ECOOP),pages738 763, 2012. [47] D. Yan, G. Xu, and A. Rountev. \nUncovering performance problemsinJava applications withreferencepropagationpro\u00ad.ling. In International \nConference on Software Engineering (ICSE),pages134 144, 2012. [48] X. Zhang. Fault Localization via Precise \nDynamic Slicing. PhD thesis,University ofArizona,2006. [49] X.ZhangandR.Gupta. Cost effectivedynamicprogram \nslic\u00ading. In ACM SIGPLAN Conference on Programming Lan\u00adguage Design and Implementation (PLDI), pages \n94 106, 2004. [50] X. Zhang, R. Gupta, and Y. Zhang. Precise dynamic slicing algorithms. In International \nConference on Software Engi\u00adneering(ICSE),pages319 329, 2003.   \n\t\t\t", "proc_id": "2384616", "abstract": "<p>A big source of run-time performance problems in large-scale, object-oriented applications is the frequent creation of data structures (by the same allocation site) whose lifetimes are disjoint, and whose shapes and data content are always the same. Constructing these data structures and computing the same data values many times is expensive; significant performance improvements can be achieved by reusing their instances, shapes, and/or data values rather than reconstructing them. This paper presents a run-time technique that can be used to help programmers find allocation sites that create such data structures to improve performance. At the heart of the technique are three reusability definitions and novel summarization approaches that compute summaries for data structures based on these definitions. The computed summaries are used subsequently to find data structures that have disjoint lifetimes, and/or that have the same shapes and content. We have implemented this technique in the Jikes RVM and performed extensive studies on large-scale, real-world programs. We describe our experience using six case studies, in which we have achieved large performance gains by fixing problems reported by our tool.</p>", "authors": [{"name": "Guoqing Xu", "author_profile_id": "81350590981", "affiliation": "University of California, Irvine, Irvine, CA, USA", "person_id": "P3856228", "email_address": "guoqingx@ics.uci.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384690", "year": "2012", "article_id": "2384690", "conference": "OOPSLA", "title": "Finding reusable data structures", "url": "http://dl.acm.org/citation.cfm?id=2384690"}