{"article_publication_date": "10-19-2012", "fulltext": "\n From Clarity to Ef.ciency for Distributed Algorithms * Yanhong A. Liu Scott D. Stoller Bo Lin Michael \nGorbovitski Computer Science Department, State University of New York at Stony Brook, Stony Brook, NY \n11794, USA {liu.stoller.bolin.mikg} s.stonybrook.edu Abstract This paper describes a very high-level \nlanguage for clear de\u00adscription of distributed algorithms and optimizations nec\u00adessary for generating \nef.cient implementations. The lan\u00adguage supports high-level control .ows where complex syn\u00adchronization \nconditions can be expressed using high-level queries, especially logic quanti.cations, over message his\u00adtory \nsequences. Unfortunately, the programs would be ex\u00adtremely inef.cient, including consuming unbounded \nmem\u00adory, if executed straightforwardly. We present new optimizations that automatically trans\u00adform complex \nsynchronization conditions into incremen\u00adtal updates of necessary auxiliary values as messages are sent \nand received. The core of the optimizations is the .rst general method for ef.cient implementation of \nlogic quan\u00adti.cations. We have developed an operational semantics of the language, implemented a prototype \nof the compiler and the optimizations, and successfully used the language and implementation on a variety \nof important distributed algo\u00adrithms. Categories and Subject Descriptors D.1.3 [Programming Techniques]: \nConcurrent Programming Distributed pro\u00adgramming; D.3.2 [Programming Languages]: Language Classi.cations \nVery high-level languages; D.3.4 [Pro\u00adgramming Languages]: Processors Code generation, Com\u00adpilers, Optimization; \nF.3.1 [Logics and Meanings of Pro\u00adgrams]: Specifying and Verifying and Reasoning about Programs Speci.cation \ntechniques; F.3.2 [Logics and Meanings of Programs]: Semantics of Programming Lan\u00adguages Operational \nsemantics; I.2.4 [Computing Method\u00adologies]: Knowledge Representation Formalisms and Meth\u00adods Predicate \nlogic * This work was supported in part by ONR under grant N000140910651 and N000140710928; and NSF under \ngrant CCF-0964196 and CNS\u00ad0831298. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, USA. Copyright c &#38;#169; \n2012 ACM 978-1-4503-1561-6/12/10. . . $10.00 General Terms Algorithms, Design, Languages, Perfor\u00admance \nKeywords distributed algorithms, incrementalization, logic quanti.cations, program optimization, very \nhigh-level lan\u00adguages 1. Introduction Distributed algorithms are at the core of distributed systems. \nYet, developing practical implementations of distributed al\u00adgorithms with correctness and ef.ciency assurances \nremains a challenging, recurring task. Study of distributed algorithms has relied on either pseu\u00addocode \nwith English, which is high-level but imprecise, or formal speci.cation languages, which are precise \nbut harder to understand, lacking mechanisms for building real distributed systems, or not executable \nat all.  At the same time, programming of distributed systems has mainly been concerned with program \nef.ciency and has relied mostly on the use of low-level or complex libraries and to a lesser extent on \nbuilt-in mechanisms in restricted programming models.  What s lacking is (1) a simple and powerful language \nthat can express distributed algorithms at a high level and yet has a clear semantics for precise execution \nas well as for veri.cation, and is fully integrated into widely used pro\u00adgramming languages for building \nreal distributed systems, together with (2) powerful optimizations that can transform high-level algorithm \ndescriptions into ef.cient implementa\u00adtions. We have developed a very high-level language, DistAlgo, \nfor clear description of distributed algorithms, combining advantages of pseudocode, formal speci.cation \nlanguages, and programming languages. The main control .ow of a process, including sending messages \nand waiting on conditions about received mes\u00adsages, can be stated directly as in sequential programs; \nyield points where message handlers execute can be spec\u00adi.ed explicitly and declaratively.  Complex \nsynchronization conditions can be expressed using high-level queries, especially quanti.cations, over \nmessage history sequences, without manually writing   message handlers that perform low-level incremental \nup\u00addates and obscure control .ows. DistAlgo supports these features by building on an object\u00adoriented \nprogramming language. We also developed an op\u00aderational semantics for the language. The result is that \ndis\u00adtributed algorithms can be expressed in DistAlgo clearly at a high level, like in pseudocode, but \nalso precisely, like in for\u00admal speci.cation languages, and be executed as part of real applications, \nas in programming languages. Unfortunately, programs containing control .ows with synchronization conditions \nexpressed at such a high level are extremely inef.cient if executed straightforwardly: each quanti.er \nwill cause a linear factor in running time, and any use of the history of messages sent and received \nwill cause space usage to be unbounded. We describe new optimizations that allow ef.cient im\u00adplementations \nto be generated automatically, extending pre\u00advious optimizations to distributed programs and to the most \nchallenging quanti.cations. Our method transforms sending and receiving of mes\u00adsages into updates to \nmessage history sequences, in\u00adcrementally maintains the truth values of synchroniza\u00adtion conditions and \nnecessary auxiliary values as those sequences are updated, and .nally removes those se\u00adquences as dead \ncode as appropriate.  To incrementally maintain the truth values of general quanti.cations, our method \n.rst transforms them into set queries. In general, however, translating nested quan\u00adti.cations simply \ninto nested queries can incur asymp\u00adtotically more space and time overhead than necessary. Our transformations \nminimize the nesting of the result\u00ading queries.  Quanti.ed order comparisons are used extensively in \nnon-trivial distributed algorithms. They can be easily in\u00adcrementalized when not mixed with other conditions \nor with each other. We systematically extract single quanti\u00ad.ed order comparisons and transform them \ninto ef.cient incremental operations.  Overall, our method signi.cantly improves time complexi\u00adties \nand reduces the unbounded space used for message his\u00adtory sequences to the auxiliary space needed for \nincremental computation. Systematic incrementalization also allows the time and space complexity of the \ngenerated programs to be analyzed easily. There has been a signi.cant amount of related research, as \ndiscussed in Section 7. Our work contains three main contributions: A very high-level language that \ncombines the best of pseudocode, speci.cation, and programming languages.  A systematic method for incrementalizing \ncomplex syn\u00adchronization conditions with respect to all sending and receiving of messages in distributed \nprograms.  A general and systematic method for generating ef.\u00adcient implementations of arbitrary logic \nquanti.cations together with general high-level queries. We have implemented a prototype of the compiler \nand the optimizations and experimented with a variety of im\u00adportant distributed algorithms, including \nPaxos, Byzantine Paxos, and multi-Paxos. Our experiments strongly con.rm the bene.ts of a very high-level \nlanguage and the effective\u00adness of our optimizations.  2. Expressing distributed algorithms Even when \na distributed algorithm appears simple at a high level, it can be subtle when necessary details are considered, \nmaking it dif.cult to understand how the algorithm works precisely. The dif.culty comes from the fact \nthat multiple processes must coordinate and synchronize to achieve global goals, but at the same time, \ndelays, failures, and attacks can occur. Even determining the ordering of events is nontrivial, which \nis why Lamport s logical clock [33] is so fundamental for distributed systems. Running example. We use \nLamport s distributed mutual exclusion algorithm [33] as a running example. Lamport de\u00adveloped it to \nillustrate the logical clock he invented. The problem is that n processes access a shared resource, and \nneed to access it mutually exclusively, in what is called a critical section (CS), i.e., there can be \nat most one process in a critical section at a time. The processes have no shared memory, so they must \ncommunicate by sending and receiv\u00ading messages. Lamport s algorithm assumes that communi\u00adcation channels \nare reliable and .rst-in-.rst-out (FIFO). Figure 1 contains Lamport s original description of the algorithm, \nexcept with the notation < instead of =. in rule 5 (for comparing pairs of timestamps and process ids) \nand with the word acknowledgment added in rule 5 (for simplicity when omitting a commonly omitted [19, \n43] small optimization mentioned in a footnote). This description is the most authoritative, is at a \nhigh level, and uses the most precise English we found. The algorithm satis.es safety, liveness, and \nfairness, and has a message complexity of 3(n - 1).It is safeinthatat most one process can be in a critical \nsection at a time. It is live in that some process will be in a critical section if there are requests. \nIt is fair in that requests are served in the order of the logical timestamps of the request messages. \nIts message complexity is 3(n - 1) in that 3(n - 1) messages are required to serve each request. Challenges. \nTo understand how this algorithm is carried out precisely, one must understand how each of the n pro\u00adcesses \nacts as both Pi and Pj in interactions with all other processes. Each process must have an order of handling \nall the events according to the .ve rules, trying to reach its own goal of entering and exiting a critical \nsection while also responding to messages from other processes. It must also  The algorithm is then \nde.ned by the following .ve rules. For convenience, the actions de.ned by each rule are assumed to form \na single event. 1. To request the resource, process Pi sends the message Tm:Pi requests resource to every \nother process, and puts that message on its request queue, where Tm is the timestamp of the message. \n 2. When process Pj receives the message Tm:Pi requests resource, it places it on its request queue and \nsends a (times\u00adtamped) acknowledgment message to Pi. 3. To release the resource, process Pi removes \nany Tm:Pi requests resource message from its request queue and sends a (timestamped) Pi releases resource \nmessage to every other process. 4. When process Pj receives a Pi releases resource message, it removes \nany Tm:Pi requests resource message from its re\u00adquest queue. 5. Process Pi is granted the resource when \nthe following two conditions are satis.ed: (i) There is a Tm:Pi requests resource message in its request \nqueue which is ordered before any other request in its queue by the relation <. (To de.ne the relation \n< for messages, we identify a message with the event of sending it.) (ii) Pi has received an acknowledgment \nmessage from every other process timestamped later than Tm. Note that conditions (i) and (ii) of rule \n5 are tested locally by Pi.  Figure 1. Original description in English. keep testing the complex condition \nin rule 5 as events hap\u00adpen. State machine based formal speci.cations have been used to .ll in such details \nprecisely, but at the same time, they are lower-level and harder to understand. For example, a formal \nspeci.cation of Lamport s algorithm in I/O automata [43, pages 647-648] occupies about one and a .fth \npages, most of which is double-column. To actually implement distributed algorithms, details for many \nadditional aspects must be added, for example, creating processes, letting them establish communication \nchannels with each other, incorporating appropriate logical clocks (e.g., Lamport clock or vector clock \n[44]) if needed, guaranteeing the speci.ed channel properties (e.g., reliable, FIFO), and integrating \nthe algorithm with the application (e.g., specifying critical section tasks and invoking the code for \nthe algorithm as part of the overall application). Further\u00admore, how to do all of these in an easy and \nmodular fashion? Our approach. We address these challenges with the DistAlgo language, compilation to \nexecutable programs, and especially optimization by incrementalization of expensive synchronizations, \ndescribed in Sections 3, 4, and 5, respec\u00adtively. An unexpected result is that incrementalization let \nus discover simpli.cations of Lamport s original algorithm in Figure 1; the simpli.ed algorithm can be \nexpressed using basically two send-statements, a receive-de.nition, and an await-statement.  3. DistAlgo \nLanguage To support distributed programming at a high level, four main concepts can be added to commonly \nused object\u00adoriented programming languages, such as Java and Python: (1) processes as objects, and sending \nof messages, (2) yield points and waits for control .ows, and handling of received messages, (3) synchronization \nconditions using high-level queries and message history sequences, and (4) con.gura\u00adtion of processes \nand communication mechanisms. DistAlgo supports these concepts, with options and generalizations for \nease of programming. We have developed an operational se\u00admantics for DistAlgo. Processes and sending \nof messages. Distributed processes are like threads except that each process has its private mem\u00adory, \nnot shared with other processes, and processes com\u00admunicate by message passing. Three constructs are \nused, for de.ning processes, creating processes, and sending mes\u00adsages. Process de.nition can use any \nclass, say P, that extends a special class Proess. lassPextendsProess: lass body So a process is an object \nof class Proess. This is analogous to thread de.nition in Java and Python, except that Proess is used \nin place of Thread, and that the .elds of an object of class Proessare local to the process. So, like \nfor an object of Thread, one can de.ne a runmethod and call startto start the process and execute the \nrunmethod. Process creation can use a statement of the following form, where Pis a class that extends \nclass Proess,and s is an optional additional parameter that speci.es a site, i.e., a machine, by its \nhost name or IP address. newP(...,s) This creates a new process of class Pon site s,oronthe machine running \nthis statement if sis omitted, and returns a reference to the process. This is the same as thread cre\u00adation \nexcept for the additional parameter s. For high-level programming, newproesses(n,P,s)creates and returns \na set of nprocesses of class Pon site s. Process references are ordered. Sending messages to other processes \nuses a send-statement: sendrtop This sends message rto process p. A message can be a value of any type \nand is usually a tuple where the .rst component is a string specifying the kind of the message. We allow \na set psof processes in place of p, to send the message to each process in ps. Control .ows and handling \nof received messages. The key idea is to use labels to specify program points where control .ow can yield \nto handling of messages and resume afterwards. Three constructs are used, for specifying yield points, \nhandling of received messages, and synchronization.  A yield point is a statement of the following form, \nwhere lis a label that names this point in the program: --l This speci.es a program point, l, that can \nbe referred to in specifying handling of messages, described next, to specify where the messages can \nbe handled. Handling of received messages uses receive-de.nitions, which are members of class de.nitions \nfor processes and have the form: reeiver1 frorp1 ,...,ri frorpi atl1 ,...,lj : strt where each rk is \na variable or tuple pattern. This allows mes\u00adsages that match any one of r1 frorp1 ,...,ri frorpi to \nbe handled at yield points labeled any one of l1 ,...,lj ,by executing the statement strtat those points. \nA tuple pat\u00adtern is a tuple in which each component is a constant, a variable possibly pre.xed with \"=\", \nor a wildcard. A con\u00adstant or a variable pre.xed with = means that the corre\u00adsponding component of the \ntuple being matched must equal the constant or the value of the variable, respectively, for pattern matching \nto succeed. A variable not pre.xed with = matches any value and gets bound to the corresponding part \nof the tuple being matched. A wildcard, written as , matches any value. The at-clause is optional, and \nthe default is all yield points. The from-clause is also optional, and if used, the language provides \nthe identity of the sender. Sup\u00adport for receive-de.nition mimics common usage in pseu\u00addocode, allowing \na message handler to be associated with multiple yield points without using method de.nition and invocations. \nAs syntactic sugar, a reeivethat is handled at only one yield point can be written at that point. Synchronization \ncan use await-statements of the form: awaitbexptireouttire This waits for the value of Boolean expression \nbexpto be\u00adcome true or until tireseconds have passed. The timeout\u00adclause is optional, and the default \nis to wait only for bexp to become true. If an await-statement exits due to a timeout, it sets self.tireoutto \ntrue. If it exits due to the awaited condition being true, it sets self.tireoutto false.Were\u00adquire that \nan await-statement be preceded by a yield point; if a yield point is not speci.ed explicitly, the default \nis that all message handlers can be executed at this point. Otherwise, the program would deadlock here \nif bexpis false. These few constructs make it easy to specify any process that has its own .ow of control \nwhile also responding to messages. It is also easy to specify any process that only responds to messages, \nfor example, by writing just receive\u00adde.nitions and a runmethod containing only awaitfalse, or by writing \njust a method containing only a while run true loop whose body is a receive-de.nition. Synchronization \nconditions using high-level queries. Syn\u00adchronization conditions and other conditions can be ex\u00adpressed \nusing high-level queries quanti.cations, compre\u00adhensions, and aggregates over sets of processes and se\u00adquences \nof messages. High-level queries are used commonly in distributed algorithms because (1) they make complex \nsynchronization conditions clearer and easier to write, and (2) the theoretical ef.ciency of distributed \nalgorithms is measured by message complexity, not time complexity of local processing. Quanti.cations \nare especially common because they di\u00adrectly capture the truth values of synchronization conditions. \nWe discovered a number of errors in our initial programs that used aggregates in place of quanti.cations \nbefore we devel\u00adoped the method to systematically optimize quanti.cations. For example, we regularly \nexpressed vis larger than all ele\u00adments of s as vrx()and either forgot to handle the case asthat sis \nempty or handled it in ad hoc fashions. Naive use of aggregates like raxmay also hinder generation of \nmore ef.cient implementations. We de.ne operations on sets; operations on sequences are the same except \nthat elements are processed in order, and square brackets are used in place of curly braces. Quanti.cations \nare of the following two forms. Each variable vi enumerates elements of the set value of ex\u00adpression \nexpi ; the return value is whether, for each or some, respectively, combination of values of v1 ,...,vk \n, the value of Boolean expression bexpis true.When an existential quanti.cation returns true, variables \nv1 ,...,vk are bound to a witness. eahv1 inexp1 ,...,vk inexpk bexp sorev1 inexp1 ,...,vk inexpk bexp \nComprehensions are of the following form. Each variable vi enumerates elements of the set value of expression \nexpi ; for each combination of values of v1 ,...vk ,if the value of Boolean expression bexpis true,the \nvalue of expression expforms an element of the resulting set. {exp:v1 inexp1 ,...,vk inexpk bexp} We \nabbreviate {v:vinexp bexp}as {vinexp bexp}. Aggregates are of the form agg(exp),where aggis an operation, \nsuch as size, sur,or rax, specifying the kind of aggregation over the set value of exp.  In the query \nforms above, each vi can also be a tuple pattern, in which case each enumerated element of the set value \nof expi is .rst matched against the pattern before expression bexpis evaluated. We omit bepwhen bexp \n x is true. We use {}for empty set; use s.add(x)and s.del(x)for element addition and deletion, respectively; \nand use xin s and xnotinsfor membership test and its negation, re\u00adspectively. We allow tuple patterns \nto be used in any access of set elements. We assume that hashing is used in imple\u00admenting sets, and the \nexpected time of set membership tests and updates involving one element is O(1).  DistAlgo has two built-in \nsequences, reeivedand sent, containing all messages received and sent, respectively, by a process. Sequence \nreeivedis updated only at yield points. An ar\u00adrived message rfor which the program contains a match\u00ading \nreceive-de.nition is added to reeivedwhen the pro\u00adgram reaches a yield point where ris handled, and all \nmatching message handlers associated with that yield point are executed for r. An arrived message for \nwhich the program contains no matching receive-de.nitions is added to reeivedat the next yield point. \nThe sequence sent is updated at each send-statement.  We use reeived(rfrorp)as a shorthand for rfror \npinreeived; frorpis optional, but when speci.ed, each message in reeivedis automatically associated with \nthe corresponding sender. We use sent(rtop)as a shorthand for rtopinsent; topis optional, but when speci.ed, \npis the process or set of processes in the corresponding send-statement.  If implemented straightforwardly, \nreeivedand sentcan create a huge memory leak, because they can grow un\u00adbounded, preventing their use \nin practical programming. Con.guration. One can specify channel types, handling of messages, setup for \nstarting processes, and other con.gura\u00adtion items. Such speci.cations are declarative, so that algo\u00adrithms \ncan be expressed without unnecessary implementa\u00adtion details. We describe a few basic kinds of con.guration \nitems. Channel can be speci.ed to be fifo, for FIFO, in which case messages between two processes are \nguaranteed to be received in the order that they were sent. This is speci.ed using: usefifo hannel Similarly, \nchannels can be speci.ed to be reliable using use reliable hannel. By default, channels are not required \nto be FIFO or reliable. One can also specify different channel types for different channels. One can \nspecify how much effort is spent processing messages at yield points. For example, usehandling all means \nthat all matching received messages that are not yet handled must be handled before execution of the \nmain .ow of control continues past any yield point; this is the default. For another example, one can \nspecify a time limit. One can also specify different handling effort for different yield points. Logical \nclocks [17, 33, 44] are used in many distributed algorithms. One can specify that Lamport logical clock \nis used: useLarport lok which con.gures sending and receiving of messages to up\u00addate the clock appropriately; \none can call Larport lok() to get the value of the clock. This can be implemented with a module that \nprovides the function Larport lok()as well as the functions called at sending and receiving of messages. \nOther language constructs. For other constructs, we use those in high-level object-oriented languages. \nWe mostly use Python syntax (indentation for scoping, : for separation, # for comments, etc.), for succinctness, \nexcept with a few conventions from Java (keyword extendsfor subclass, key\u00adword newfor object creation, \nand omission of self, equiva\u00adlent of thisin Java, when there is no ambiguity), for ease of reading. Example. \nFigure 2 shows Lamport s algorithm expressed in DistAlgo. The algorithm in Figure 1 corresponds to the \nbody of sand the two receive-de.nitions, 15 lines total; the rest of the program, 15 lines total, shows \nhow the algorithm is used in an application. The execution of the application starts with method rain, \nwhich con.gures the system to run (lines 24-30). Method sand the two reeive-de.nitions are executed when \nneeded and follow the .ve rules in Figure 1 (lines 5-20). Note that Figure 2 is not meant to replace \nFigure 1, but to realize Figure 1 in a precisely executable manner. Figure 2 is meant to contrast with \nlower-level speci.cations and programs.  4. Compiling to executable programs Compilation generates code \nto create processes on the spec\u00adi.ed machine, take care of sending and receiving messages, and realize \nthe speci.ed con.guration. In particular, it in\u00adserts appropriate message handlers at each yield point. \nProcesses and sending of messages. Process creation is compiled to creating a process on the speci.ed \nor default machine and that has a private memory space for its .elds. Each process is implemented using \ntwo threads: a main thread that executes the main .ow of control of the process, and a helper thread \nthat receives and enqueues messages sent to this process. High-level programming constructs, such as \nnewproesses(n,P,s), can easily be compiled into loops. Sending a message rto a process or set of processes, \np, is compiled into calls to a standard message passing API. If the sequence sentis used in the program, \nwe also insert sent.add(rtop)to be executed. Calling a method on a remote process object is compiled \ninto a remote method call. Control .ows and handling of received messages. Each yield point lis compiled \ninto a call to a message handler method l()that updates the sequence reeived,if it is used in the program, \nand executes the bodies of the receive\u00adde.nitions whose at-clause includes l. Precisely:  1lassPextendsProess: \n23 4 defsetup(s): self s=s self q={} #set#set ofof allotherproesses pendingrequests 56 7 8 9 defs(task): \n#for-\u00adrequest self =Lamport lok() send('request',,self)tos q add(('request',,self)) al task()inCS #1in# \n# ling Fig1 #waitforownreq<othersinq #andforaksfromallins 10 awaiteah('request',2,p2)inqI #5inFig1 (2,p2)!=(,self)implies(,self)<(2,p2) \n11 andeahp2insI # somereeived('ak',2,=p2)I2> 12 task() #ritialsetion 13 --release 14 q del(('request',,self)) \n#3inFig1 15 send('release',Lamport lok(),self)tos# 16reeive('request',2,p2): #2inFig1 17 q add(('request',2,p2)) \n# 18 send('ak',Lamport lok(),self)top2 # 19reeive('release', ,p2): #4inFig1 20q del(('request', ,=p2)) \n# 21defrun(): #mainmethodfortheproess #maydonon-CStasksofthepro 22 deftask(): #defineritialsetiontask \n23 s(task) #allstodotaskinCS #maydonon-CStasksofthepro 24defmain(): #mainmethodfortheappliation #othertasksoftheappliation \n25usereliable hannel #onfigurehanneltobereliable 26usefifo hannel #onfigurehanneltobeFIFO 27useLamport \nlok #onfiguretouseLamportlok 28ps=newproesses(50,P)#reate50proessesofPlass 29forpinps:p setup(ps-{p})#passtoeahprootherpros \n30forpinps:p start() #starteahpro,allmethodrun #othertasksoftheappliation Figure 2. Original algorithm \n(lines 3-4 and 6-20) in a com\u00adplete program in DistAlgo. 1. Each receive-de.nition is compiled into a \nmethod that takes a message ras argument, matches ragainst the message patterns in the receive-clause, \nand if the match\u00ading succeeds, binds the variables in the pattern appro\u00adpriately, and executes the statement \nin the body of this receive-de.nition. 2. Method l()compiled for yield point ldoes the follow\u00ading: for \neach message rfrom pin the queue of messages not yet handled, (1) if rmatches a message pattern in a \nreceive-de.nition whose at-clause includes l,then exe\u00adcute reeived.add(rfrorp)if reeivedis used in the \nprogram and call the methods generated from the receive\u00adde.nitions whose at-clause includes l;(2) if \nrdoes not match any message pattern in any receive-de.nition, then execute reeived.add(rfrorp)if reeivedis \nused in the program. In both these cases, remove rfrom the mes\u00adsage queue afterward.  An await-statement \ncan be compiled into a synchroniza\u00adtion using busy-waiting or blocking. For example, for busy\u00adwaiting, \na statement awaitbexpthat immediately follows a label lis compiled into a call l()followed by whilenot \nbexp:l(). Con.guration. Con.guration options are taken into ac\u00adcount during compilation in a straightforward \nway. Libraries and modules are used as much as possible. For example, when fifo hanneland reliable hannelare \nspeci.ed, the compiler can generate code that uses TCP sockets.  5. Incrementalizing expensive synchronizations \nIncrementalization transforms expensive computations into ef.cient incremental computations with respect \nto updates to the values on which the computations depend. It (1) iden\u00adti.es all expensive queries, (2) \ndetermines all updates to the parameters of these queries, and (3) transforms the queries and updates \ninto ef.cient incremental computations. Much of this has been studied previously. The new method here \nis for (1) systematic handling of quanti.cations for synchronization as expensive queries, es\u00adpecially \nnested alternating universal and existential quanti.\u00adcations and quanti.cations containing complex order \ncom\u00adparisons and (2) systematic handling of updates caused by all sending, receiving, and handling of \nmessages in the same way as other updates in the program. The result is drastic reduction of both time \nand space complexities. Expensive computations using quanti.cations. Expen\u00adsive computations in general \ninvolve repetition, including loops, recursive functions, comprehensions, aggregates, and quanti.cations \nover collections. Loops were studied most; less for recursive functions and comprehensions, and least \nfor quanti.cations, basically corresponding to how fre\u00adquently each construct has traditionally been \nused in pro\u00adgramming. However, high-level queries are increasingly used in programming, and quanti.cations \nare dominantly used in writing synchronization conditions and assertions in speci.cations and very high-level \nprograms. Unfortunately, if implemented straightforwardly, each quanti.cation incurs a cost factor that \nis linear in the size of the collection quan\u00adti.ed over. Optimizing expensive quanti.cations in general \nis dif.\u00adcult, which is a main reason that they are not used in prac\u00adtical programs, not even logic programs, \nand programmers manually write more complex and error-prone code. The dif.culty comes from expensive \nenumerations over collec\u00adtions and complex combinations of join conditions. We ad\u00address this challenge \nby converting quanti.cations into aggre\u00adgate queries that can be optimized systematically using pre\u00adviously \nstudied methods. However, a quanti.cation can be converted into multiple forms of aggregate queries. \nWhich one to use depends on what kinds of updates must be han\u00addled, and on how the query can be incrementalized \nunder those updates. Direct conversion of nested quanti.cations into nested queries can lead to much \nmore complex incre\u00admental computation code and asymptotically worse time and space complexities for maintaining \nthe intermediate query results.  Note that, for an existential quanti.cation, we convert it to a more \nef.cient aggregate query if a witness is not needed; if a witness is needed, we incrementally compute \nthe set of witnesses. Converting quanti.cations to aggregate queries. We present all converted forms \nhere and describe which forms to use after we discuss the updates that must be handled. The pro\u00adcess \nto develop them was nontrivial, even though the end results look simple. The correctness of all rules \npresented are proved using .rst-order logic and set theory. These rules ensure that the value of a resulting \nquery expression equals the value of the original quanti.ed expression. Table 1 shows general rules for \nconverting single quan\u00adti.cations into equivalent queries that use sizeaggregates. These rules are general \nbecause bexpcan be any Boolean expression, but they are for converting single quanti.cations. Nested \nquanti.cations could be converted one at a time from inside out, but the results can be much more complicated \nthan necessary. For example, eahxinssoreyintbexp would be converted using rule 1 to eahxinssize({yintbexp})!=0 \nand then using rule 2 to size({xinssize({yintbexp})!=0}) ==size(s) Quanti.cation Using Aggregate 1 sorexinsbexp \nsize({x insbexp})!=0 2 3 eahxinsbexp size({xsize({x insbexp})==size(s) insnotbexp})==0 Table 1. Rules \nfor converting single quanti.cations. Table 2 shows general rules for converting nested quan\u00adti.cations \ninto equivalent, but non-nested, queries that use sizeaggregates. These rules yield much simpler results \nthan repeated use of the rules in Table 1. For example, rule 2 in this table yields a much simpler result \nthan using two rules in Table 1 in the previous example. More signi.cantly, rules 1, 4, and 5 generalize \nto any number of the same quanti.er, and rules 2 and 3 generalize to any number of quanti.ers with one \nalternation. We have not encountered more complicated quanti.cations than these. It is well-known that \nmore than one alternation is rarely used, so commonly used quanti.ca\u00adtions can all be converted to non-nested \naggregate queries. Table 3 shows general rules for converting single quan\u00adti.cations with a single order \ncomparison into equivalent queries that use raxand rinaggregates. These rules are use\u00adful because single \nquanti.ed order comparison, when there are no element deletions, can be computed more ef.ciently, with \na constant instead of linear space overhead. Boolean combinations of order comparisons and other conditions \ncan be transformed .rst into quanti.cations each involving at most one order comparison at a time. Existential \nUsing Aggregate 1 sore xinsy <=x s !={}andy<=rax(s) 2 sore xinsx =y 3 sore xinsy =x s !={}andy=rin(s) \n4 sore xinsx <=y 5 sore xinsy <x s !={}andy<rax(s) 6 sore xinsx y 7 sore xinsy x s !={}andyrin(s) 8 sore \nxinsx <y Universal Using Aggregate 9 eah xinsy <=x s =={}ory<=rin(s) 10 eah xinsx =y 11 eah xinsy =x \ns =={}ory=rax(s) 12 eah xinsx <=y 13 eah xinsy <x s =={}ory<rin(s) 14 eah xinsx y 15 eah xinsy x s =={}oryrax(s) \n16 eah xinsx <y Table 3. Rules for single quanti.ed order comparison. Table 4 shows general rules for \ndecomposing combi\u00adnations of conditions in general quanti.cations, to extract quanti.cations each involving \na single order comparison. For example, eahxinsbexpirpliesy<x can be converted using rule 6 to eahxin{xinsbexp}y<x \nwhich can be converted using rule 13 of Table 3 to {xinsbexp}=={}ory<rin({xinsbexp}) Quanti.cation Decomposed \nQuanti.cations 1 sorexins e1ande2 sorexin{xinse1} e2 2 sorexins e1ore2 sorexinse1or sorexinse2 3 sorexins \ne1irpliese2 sorexinsnote1or sorexinse2 4 eahxins e1ande2 eahxinse1and eahxinse2 5 eahxins e1ore2 eahxin{xinsnote1} \ne2 6 eahxins e1irpliese2 eahxin{xinse1} e2 Table 4. Rules for decomposing conditions to extract quan\u00adti.ed \ncomparisons. Updates caused by message passing. Parameters of a query are variables in the query whose \nvalues may affect the query result. Updates to a parameter are operations that  Nested Quanti.cations \nUsing Aggregate 1 sore x inssoreyint bexp size({true:xins,yintbexp})!=0 2 eah x inssoreyint bexp size({x:xins,yintbexp})==size(s) \n3 sore x inseahyint bexp size({x:xins,yintnotbexp})!=size(s) 4 eah ineahin bexp size({(x,y):xins,yintbexp})==size({(x,y): \nxins,yint}) 5 x syt size({(x,y):xins,yintnotbexp})==0 Table 2. Rules for converting nested quanti.cations. \nmay change the value of the parameter. The most common updates are assignments, v=exp, which is an update \nto v. Other updates can all be expressed as assignments. For objects, all updates can be expressed as \n.eld assignments, o.f=exp. For collections, all updates can be expressed as initialization to empty and \nelement additions and removals. For distributed algorithms, a distinct class of important updates are \ncaused by message passing. Updates are caused in two ways: 1. Sending and receiving messages updates \nthe sequences sentand reeived, respectively. Before incrementaliza\u00adtion, code is generated, as described \nin Section 4, to ex\u00adplicitly perform these updates. 2. Handling of messages by code in receive-de.nitions \nup\u00addates variables that are parameters of the queries for com\u00adputing synchronization conditions, or that \nare used to compute the values of these parameters.  Once these are established, updates can be determined \nusing previously studied analysis methods, e.g., [21, 39]. Incremental computation. Given expensive queries \nand updates to the query parameters, ef.cient incremental com\u00adputations can be derived for large classes \nof queries and up\u00addates based on the language constructs used in them or by using a library of rules \nbuilt on existing data structures [39 41, 50]. For aggregate queries converted from quanti.cations, al\u00adgebraic \nproperties of the aggregate operations are exploited to ef.ciently handle possible updates. In particular, \neach re\u00adsulting aggregate query result can be obtained in O(1) time and incrementally maintained in O(1) \ntime per update to the sets maintained and affected plus the time for evaluating the conditions in the \naggregate query once per update. Addition\u00adally, if raxand rinaggregates are used and there are no el\u00adement \ndeletions from the sets queried, the space overhead is constant. Note that if raxand rinare used naively \nand there are element deletions, there would be an overhead of O(n) space and O(log n) update time from \nusing more so\u00adphisticated data structures to maintain the raxor rinunder element deletion [13, 22, 67, \n68]. To allow the most ef.cient incremental computation un\u00adder all given updates, our method transforms \neach top-level quanti.cation as follows: For nested quanti.cations, the rules in Table 2 are used. For \nnon-nested quanti.cations, if the conditions contain no order comparisons or there are deletions from \nthe sets or sequences whose elements are compared, the rules in Table 1 are used. The space overhead \nis linear in the sizes of the sets maintained and being aggregated over. For non-nested quanti.cations, \nif the conditions contain order comparisons and there are no deletions from the sets or sequences whose \nelements are compared, the rules in Table 4 are .rst used to extract single quanti.ed order comparisons, \nand then the rules in Table 3 are used to convert the extracted quanti.cations. In this case, the space \noverhead is constant.  Multiple ways of conversion may be possible: for univer\u00adsal quanti.cations using \nrules 2 and 3 in Table 1 and rules 4 and 5 in Table 2, for nested quanti.cations with two or more alternations \nusing rules 2 and 3 in Table 2 (each way of conversion corresponds to a choice of which two al\u00adternating \nquanti.ers to eliminate using one of the rules), and for quanti.cations with symmetric ways of decom\u00adposing \ncombinations of conditions using rules 1, 5, and 6 in Table 4. Our method transforms in all these ways, \nobtains the time and space complexities for each result, and chooses one with the best complexities. \n Table 5 summarizes well-known incremental computation methods for these aggregate queries. The methods \nare ex\u00adpressed as incrementalization rules: if a query in the program matches the query form in the table, \nand each update to a pa\u00adrameter of the query in the program matches an update form in the table, then \ntransform the query into the corresponding replacement given in the table and insert at each update the \ncorresponding maintenance; a fresh variable is introduced for each different query. The overall incrementalization \nalgorithm [39, 40, 50] (1) introduces new variables to store the results of expensive queries and subqueries, \nas well as appropriate additional val\u00adues, (2) transforms the queries and subqueries to use the stored \nquery results and additional values, and (3) transforms updates to query parameters to also do incremental \nmainte\u00adnance of the stored query results and additional values. If queries are nested, inner queries \nare transformed be\u00adfore outer queries. Note that a comprehension such as {xin s bexp}is incrementalized \nwith respect to changes to pa\u00adrameters of Boolean expression bexpas well as addition and removal of elements \nof s;if bexpcontains nested subqueries, then after the subqueries are transformed, incremental main\u00adTable \n5. Incrementalization rules for sizeand for rax.The rule for rinis similar to the rule for rax.  Query \nReplacement Cost size(s) ount O(1) Updates Inserted Maintenance Cost s={} ount=0 O(1) s.add(x) ifxnotins:ount+=1 \nO(1) s.del(x) ifxins:ount-=1 O(1) Query Replacement Cost rax(s) raxirur O(1) Updates Inserted Maintenance \nCost s={x} raxirur=x O(1) s.add(x) ifxraxirur:raxirur=x O(1) tenance of their query results become additional \nupdates to the enclosing query. This is one of the reasons that incre\u00admentalization is challenging. At \nthe end, variables and computations that are dead in the transformed program are eliminated. In particular, \nse\u00adquences reeivedand sentwill be eliminated as appro\u00adpriate, because queries using them have been compiled \ninto message handlers that only store and maintain values needed for incremental evaluation of the synchronization \ncondi\u00adtions. Example. In the program in Figure 2, three quanti.ca\u00adtions are used in the synchronization \ncondition in the await\u00adstatement, and two of them are nested. The condition is copied below, except that \n('ak',2,p2)inreeivedis now used. eah('request',2,p2)inq (2,p2)!=(,self)irplies(,self)<(2,p2) andeahp2ins \nsore('ak',2,=p2)inreeived2 Converting quanti.cations into aggregates as described using Tables 1 through \n4 proceeds as follows. In the .rst conjunct, the universal quanti.cation is converted using rule 2 or \n3 in Table 1, because it contains an order comparison with elements of qand there are element deletions \nfrom q; rule 3 is used here because it is slightly simpler after the negated condition is simpli.ed. \nIn the second conjunct, the nested quanti.cation is converted using rule 2 in Table 2. The resulting \nexpression is: size({('request',2,p2)inq (,self)(2,p2)})==0 and size({p2:p2ins,('ak',2,=p2)inreeived \n2})==size(s) Updates to parameters of the .rst conjunct are additions and removals of requests to and \nfrom q, and also assignment to . Updates to parameters of the second conjunct are ad\u00additions of ack-messages \nto reeived, and assignment to , after the initial assignment to s. Incremental computation [39 41, 50] \nintroduces vari\u00adables to store the values of all three aggregates in the con\u00adverted query, transforms \nthe aggregates to use the introduced variables, and incrementally maintains the stored values at each \nof the updates, yielding the following: For the .rst conjunct, store the set value and the size value \nin two variables, say earlierand ount, respec\u00adtively; when is assigned a new value, let earlierbe qand \nlet ount1be its size, taking O(|earlier|) time, amortized to O(1) time when each request in earlieris \nserved; when a request is added to q,if is de.ned and (,self)(2,p2)holds, add the request to earlier \nand increment ount1by 1, taking O(1) time; similarly for deletion from q. Note that at the addition \nand removal of ('request',, self)in particular, earlierand ount1are not updated, because (,self)(,self)is \ntrivially false.  For the second conjunct, store the set value and the two sizevalues in three variables, \nsay responded, ount2, and total, respectively; when sis initialized in setup, assign totalthe size of \ns,taking O(|s|) time, done only once for each process; when is assigned a new value, let respondedbe \n{},and let ount2be 0, taking O(1) time; when an ack-message is added to reeived, if the associ\u00adated conditions \nhold, increment ount2by 1, taking O(1) time.  Note that incrementalization uses basic properties about \nprimitives and libraries. These properties are incorporated in incrementalization rules. For the running \nexample, the property used is that a call to Larport lok()returns a timestamp larger all timestamps of \nmessages previously re\u00adceived, and thus at the assignment to ,we have that earlier is qand respondedis \n{}. Figure 3 shows the optimized program after incremental\u00adization of the synchronization condition on \nlines 10-11 in Figure 2. All commented lines are new except that the syn\u00adchronization condition in the \nawait-statement is simpli.ed. The synchronization condition now takes O(1) time, com\u00adpared with O(|s|2) \nif implemented straightforwardly. The trade-off is the much smaller amortized O(1) time overhead at updates \nto and qand on receiving of ack-messages. Note that the sequence reeivedused in the synchro\u00adnization \ncondition in Figure 2 is no longer used after incre\u00admentalization. All values needed for evaluating the \nsynchro\u00adnization condition are stored in new variables introduced: earlier, ount1, responded, ount2,and \ntotal, a drastic space improvement from unbounded for reeivedto linear in the number of processes. Simpli.cations \nto the original algorithm. Consider the original algorithm in Figure 2. Note that incrementalization \ndetermined that there is no need for a process to update aux\u00adiliary values for its own request. Based \non this, we discov\u00adered that updates to qfor a process s own request do not  1lassPextendsProess: 2 \ndefsetup(s): 3 self s=s 4 self q={} 5 self total=size(s) # totalnumofotherpros 6 defs(task): 7 -\u00adrequest \n8 self =Lamport lok() 9 self earlier=q # setofpendingearlierreqs 10 self ount1=size(earlier)# numofpendingearlierreqs \n11 self responded={} # setofrespondedpros 12 self ount2=0 # numofrespondedpros 13 send('request',,self)tos \n14 q add(('request',,self)) 15 awaitount1==0 andount2==total# usemaintainedresults 16 task() 17 -\u00adrelease \n18 q del(('request',,self)) 19 send('release',Lamport lok(),self)tos 20 reeive('request',2,p2): 21 if!=undefined: \n# ifisdefined 22 if(,self)>(2,p2): # omparisoninonjunt1 23 if('request',2,p2)notinearlier:#ifnotin 24 \nearlier add(('request', 2,p2))#addtoearlier 25 ount1+=1 #inrementount1 26 q add(('request',2,p2)) 27 \nsend('ak',Lamport lok(), self)top2 28 reeive('ak',2,p2): # newmessagehandler 29 if2>: # omparisoninonjunt2 \n30 ifp2ins: # membershipinonjunt2 31 ifp2notinresponded:# ifnotrespondedalready 32 responded add(p2) \n# addtoresponded 33 ount2+=1 # inrementount2 34reeive('release',,p2): 35 if!=undefined: #ifisdefined \n36 if(,self)>(2,p2): #omparisoninonjunt1 37 if('request',2,p2)inearlier:#ifinearlier 38 earlier del(('request',2,p2))#deleteit \n39 ount1-=1 #derementount1 40 q del(('request',,=p2)) Figure 3. Optimized program after incrementalization. \nDef\u00adinitions of runand rainare as in Figure 2. affect the only use of q, on line 10, so we can remove \nthe updates to qon lines 9 and 14 as well as the test (2,p2) !=(,self), which becomes always true, in \nthe synchro\u00adnization condition. Furthermore, note that the remaining up\u00addates to qare merely maintaining \npending requests by oth\u00aders, so we can remove lines 4, 17, 20 and the entire receive\u00adde.nition for release, \nby using, for the .rst conjunct in the await-statement, eahreeived('request',2,p2) not(sorereeived('release',3,=p2)32) \nirplies(,self)<(2,p2) Figure 4 shows the simpli.ed algorithm. Incrementalizing this program yields essentially \nthe same optimized program as in Figure 3.  6. Implementation and experiments We have implemented a \nprototype compiler and optimizer for DistAlgo. The system can parse a DistAlgo program, ap\u00adply analyses \nand optimizations to it, and generate executable Python code. 1lassPextendsProess: 2defsetup(s): 3 self \ns=s 4defs(task): 5 --request 6 self =Lamport lok() 7 send('request',,self)tos 8 awaiteahreeived('request',2,p2)I \n not(somereeived('release',3,=p2)I3>2) implies(,self)<(2,p2) 9 andeahp2insI somereeived('ak',2,=p2)I2> \n10 task() 11 --release 12 send('release',Lamport lok(),self)tos 13reeive('request',2,p2): 14 send('ak',Lamport \nlok(),self)top2 Figure 4. Simpli.ed original algorithm. De.nitions of run and rainareas inFigure2. We \nimplemented DistAlgo as slightly extended Python because Python has rich support of very high-level con\u00adstructs \nfor ease of programming, and simple and consis\u00adtent syntax for ease of reading. We mostly exploit Python \ns support for comprehensions, aggregates, and quanti.cations over sets and sequences, albeit with a slightly \ndifferent syn\u00adtax than in this paper. Processes are implemented using Python s multiprocessing package. \nMessage passing is im\u00adplemented using the socket library, with support for UDP or TCP as the underlying \nprotocol. Await-statements are com\u00adpiled into blocking synchronization, not busy-waiting. Our compiler \nand optimizer are implemented in Python, building on Python s parser module and AST package. Our compiler \nruns on either a modi.ed or unmodi.ed Python parser. The modi.ed parser is a 390-line patch to the C \ncode of the Python source distribution and extends the Python grammar to support labels and message handlers \nwith the syntax used in this paper. When using unmodi.ed Python, our compiler supports labels and message \nhandlers speci.ed using specially named Python statements and methods; this alternate syntax avoids the \nneed for the Python parser patch. The latter approach is used also for the rest of the exten\u00adsions: process \ncreation, sending messages, synchronization, and con.gurations. The rest of the compiler and optimizer \nconsists of about 1850 lines of Python, including code for transforming quanti.cations into set and aggregate \nqueries, and excluding code for applying incrementalization to those queries. Applying incrementalization \nuses the methods and implementation from previous work [21, 39 41]. The best program generated from incrementalizing \ndifferently con\u00adverted aggregate queries is currently selected manually. We have programmed a variety \nof well-known distributed algorithms using DistAlgo, applied our analyses and op\u00adtimizations, and generated \nexecutable Python code for all of them. We discuss our experiments and experiences with twelve of them, \nlisted in Table 6. DistAlgo has also been used by undergraduate and graduate students to easily im\u00adplement \na variety of distributed algorithms used in dis\u00ad  Algorithm Description La mutex Lamport s distributed \nmutual exclusion [33] La mutex2 RA mutex RA token La mutex with optimization in footnote in [33] Ricart-Agrawala \ns distributed mutual exclusion [57] Ricart-Agrawala s token-based mutual exclusion [58] SK token Suzuki-Kasami \ns token-based mutual exclusion [61] CR leader Chang-Robert s leader election [11] HS leader Hirschberg-Sinclair \ns leader election [27] 2P commit Two-phase commit [24] DS crash Dolev-Strong s consensus under crash \nfailures [15] La Paxos CL Paxos Lamport s Paxos for distributed consensus [34, 35] Castro-Liskov s Paxos \nunder Byzantine failures [10] vR Paxos van Renesse s pseudocode for multi-Paxos [66] Algorithm DistAlgo \nPlusCal IOA Overlog Bloom La mutex 32 90 [46] 64 [43] La mutex2 33 RA mutex 35 RA token 43 SK token 42 \nCR leader 30 41 [28] HS leader 56 2P commit 44 68 [65] 85 [64] DS crash 22 La Paxos 43 83 [45] 145 [29] \n230 [49] 157 [51] CL Paxos 63 166 [45] vR Paxos 156 Table 6. Well-known distributed algorithms. tributed \n.le sharing and other services, including Kademlia, Tapestry, Pastry, and Chord, and parts of HDFS and \nUpright. All reported running times are obtained with all processes running on one Xen virtual machine \nwith 6GB of main memory on an Intel Core-i7 2600K CPU with 16GB of main memory, running a Linux 3.2.0 \nkernel. Unless stated otherwise, experiments use Python 3.2.2, reported results are averages over 10 \nruns, and program sizes are numbers of lines excluding comments and empty lines. Programming distributed \nalgorithms. We compared dis\u00adtributed algorithms expressed in DistAlgo with distributed algorithms expressed \nin very different programming and speci.cation languages. We found that DistAlgo programs are generally \nmuch easier to read and write. It took very little time to actually write them, some just a few minutes \nbefore generated code ran as intended, but signi.cant effort was spent trying to understand the algorithms \nfrom papers and textbooks, some taking days and weeks. Being able to express synchronization conditions \nusing high-level quan\u00adti.cations and apply incrementalization also allowed us to uncover errors in our \ninitial DistAlgo programs that sub\u00adconsciously used extensive message handlers to do ad hoc incremental \nupdates. It also helped us discover improve\u00adments to some of the algorithms, for correctness and for \nef.ciency [42], such as the simpli.cations that led to the algorithm in Figure 4. Directly quantifying \nthe ease of programming and clar\u00adity of programs is hard, so we use code size as an indirect measure, \nas is common in programming practice. Table 7 lists the sizes of DistAlgo programs that express these \nal\u00adgorithms, and sizes of programs written by other people in other languages, PlusCal [36], IOA [30, \n43], Overlog [3], and Bloom [8], that also express these algorithms. DistAlgo programs are consistently \nsmall, expressing the algorithms almost exactly like the pseudocode descriptions except with a precise \nmeaning for execution. We also compared Lamport s distributed mutual exclu\u00adsion algorithm written in \nC, Java, Python, Erlang, PlusCal, and DistAlgo, as summarized in Table 8. These programs or Table 7. \nSizes of programs in different languages, with ci\u00adtations. speci.cations vary in the mechanisms used \nfor processes and communications, and their sizes. The .rst four were devel\u00adoped by ourselves before \nwe started implementing DistAlgo and are our best efforts to use each language in the best way for implementing \nthis algorithm. The PlusCal version is from [46]. The C and Java programs required much more effort than \nthe Python and Erlang programs, which required much more effort than the DistAlgo program. For compari\u00adson \nof program sizes, we formatted our programs according to the suggested styles of the languages; for C, \nthe K&#38;R style is used. Our experience con.rmed that, as higher-level language features are used, \nprogramming effort and program size decrease. Language Distributed programming features used Total Clean \nC TCP socket library 358 272 Java TCP socket library 281 216 Python multiprocessing package 165 122 Erlang \nbuilt-in message passing 177 99 PlusCal single process simulation using array 134 90 DistAlgo built-in \nhigh-level synchronization 48 32 Table 8. Main distributed programming features used and program sizes \n(total number of lines, and number of lines without comments and empty lines) for Lamport s dis\u00adtributed \nmutual exclusion algorithm. Compilation and optimization. We describe compilation and optimization times, \ngenerated program sizes, and perfor\u00admance of generated implementations. We do not discuss im\u00adplementation \nof automatic incrementalization [21, 39 41], because it is prior work. We implemented an interface be\u00adtween \nour DistAlgo compiler and the incrementalizer In\u00advTS [21, 41], so all the examples can be automatically \ncom\u00adpiled and optimized except for some remaining trivial man\u00adual steps and selection of the best program \nas mentioned above. It is not easy to integrate our DistAlgo compiler and the incrementalizer InvTS, \nbecause the incrementalizer uses   25 50 75 100 125 150Number of processes Figure 5. Running time and \nmemory usage of Lamport s distributed mutual exclusion. 1.3 6000 Table 9. Compilation time and sizes \nof generated programs after compilation and after incrementalization. 1.2 1.1 1 0.9 Memory (kB)Time \n(sec) 0.8 0.7 3000 0.6 Python 2.5, which is incompatible with Python 3, used by 0.5 2000 our compiler. \n0.4 0.3 Table 9 shows the compilation time and the sizes of the 0.2 DistAlgo programs, generated Python \nprograms after compi\u00adlation, and generated Python programs after incrementaliza\u00adtion. Compilation time \ndoes not include incrementalization time, which was well under 30 seconds for all of our pro\u00adgrams. The \ngenerated programs include 1300 lines of .xed library code. For some of the algorithms, the given origi\u00adnal \ndescription and pseudocode already contain all incre\u00ad 0.1 0 0 Number of acceptors Figure 6. Running time \nand memory usage of Castro\u00adLiskov s Byzantine Paxos. 3000 mental updates, so applying incrementalization \nto the gen\u00ad 2500 erated program from compilation does not change the pro\u00ad gram. These algorithms and \nsome of the other algorithms could be written at a higher level, so the synchronization conditions can \nbe expressed more directly and thus easier to understand and verify. Incremental updates for ef.cient \nim\u00adplementations can then be generated by incrementalization; higher-level programs can also allow more \nef.cient incre\u00admental programs to be generated. Figures 5 7 compare the time and space performance of \ngenerated implementations, for original programs and incre\u00admentalized programs. A process s memory usage \nis mea\u00adsured after the process has completed all of its work, so the sequences sentand reeivedno longer \ngrow. The reported memory usage is the sum of the raw sizes of all data struc\u00adtures created by the generated \nPython code, measured using Pympler.1 Figure 5 shows the running time and memory us\u00adage of Lamport s \ndistributed mutual exclusion algorithm; the running time is the CPU time for each process to complete \na call to s(task), including time spent handling messages from other processes, averaged over processes \nand over runs of 30 calls each. Figure 6 shows the running time and mem\u00adory usage of Castro-Liskov s \nByzantine Paxos algorithm; the running time is the CPU time for a proposer to suc\u00adceed, averaged over \nproposers, from when it .rst proposes 1 http://pakages.python.org/Pympler/ 500 0 10 20 30 40 50 Number \nof calls to cs(task) Memory (kB) 2000 1500 1000 Figure 7. Memory usage of Lamport s distributed mutual \nexclusion. until it learns that one of its proposals has succeeded, with the indicated number of acceptor \nprocesses and 10 proposer processes. When an acceptor accepts a proposal, it noti.es only the proposer. \nThe fault tolerance parameter f is set to l(N - 1)/3J,where N is the number of acceptors. Figure 7 shows \nthe average per-process memory usage of Lamport s distributed mutual exclusion algorithm with 75 processes, \nas a function of the number of calls to s(task).Use of the sequences reeivedand sentcauses memory usage \nof the un-incrementalized program to grow linearly with the num\u00adber of calls, while the memory usage \nof the incrementalized program remains constant. We can see that incrementaliza\u00adtion improves the time \nand space performance of generated implementations asymptotically.  Time (sec) 0.12 0.1 0.08 0.06 0.04 \n0.02 0 25 50 75 100 125 150 Number of processes Figure 8. Running time of programs for Lamport s dis\u00adtributed \nmutual exclusion written in different languages. Figure 8 compares the ef.ciency of our programs for \nLamport s distributed mutual exclusion algorithm written in different languages. For C, Java, and Erlang, \nwe used GCC 4.6.1, JDK 1.6.0, and R14B04, respectively. The .gure shows the CPU time for each process \nto do a round of re\u00adquesting and releasing the CS, averaged over processes and over runs of 30 rounds \neach. We can see that Erlang is the fastest; we think it is partly because Erlang processes are lighter \nweight. The Python code generated from DistAlgo takes 3 times as long as the manually written Python; \nit is because of the overhead in the generated code for pattern matching against messages received and \nfor method invoca\u00adtion for message handling at yield points. This overhead is not intrinsic and could \nbe optimized away so that the generated implementations can be as fast as manually written Python programs. \nPython is generally slower than Erlang, C, and Java, but is nevertheless widely used for distributed \napplications.  7. Related work A wide spectrum of languages and notations have been used to describe \ndistributed algorithms, e.g., [4, 19, 32, 36, 43, 55, 56, 63]. At one end, pseudocode with English is \nused, e.g., [32], which well gives a high-level .ow of the algo\u00adrithms, but lacks the details and precision \nneeded for a com\u00adplete understanding. At the other end, state machine based speci.cation languages are \nused, e.g., I/O automata [30, 43], which is completely precise, but uses low-level control .ows that \nmake it harder to write and understand the algorithms. There are also many notations in between these \nextremes, some being much more precise or completely precise while also giving a high-level control .ow, \ne.g., Raynal s pseu\u00addocode [55, 56] and Lamport s PlusCal [36]. However, all of these languages and notations \nstill lack concepts and mecha\u00adnisms for building real distributed applications, and most of the languages \nare not executable at all. Many programming languages support programming of distributed algorithms and \napplications. Most support dis\u00adtributed programming through messaging libraries, ranging from relatively \nsimple socket libraries to complex libraries such as MPI [47]. Many support Remote Procedure Call (RPC) \nor Remote Method Invocation (RMI), which allows a process to call a subroutine in another process without \nthe programmer coding the details for this. Some programming languages, such as Erlang [16], based on \nthe actor model [2], have support for message passing and process management built into the language. \nThey all lack constructs for express\u00ading control .ows and complex synchronization conditions at a much \nhigher level, because these high-level constructs are extremely dif.cult to implement ef.ciently. DistAlgo \ns con\u00adstruct for declaratively and precisely specifying yield points for message handlers is a new feature \nthat we have not seen in other languages. There has been much work on generating executable im\u00adplementations \nfrom formal speci.cations, e.g., from process algebras [26], I/O automata [20], Unity [23], and Seuss \n[31], as well as from more recently proposed high-level languages for distributed algorithms, e.g., Datalog-based \nlanguages Overlog [3] and Bloom [8], and a logic-based language EventML [9, 14]. Compilation of DistAlgo \nto executable implementations is easy because it is designed to be so and is given an operational semantics. \nHigh-level queries and quanti.cations used for synchronization conditions can be compiled into loops \nstraightforwardly, but they may be ex\u00adtremely inef.cient. None of these prior works study pow\u00aderful optimizations \nof quanti.cations. Ef.ciency concern is a main reason that similar high-level language constructs, whether \nfor queries or assertions, are rarely used, if sup\u00adported at all, in widely used languages. Incrementalization \nhas been studied extensively, e.g., [54], both done systematically based on languages, and routinely \napplied in ad hoc fashions to speci.c problems. However, all systematic incrementalization methods based \non languages have been for centralized sequential programs, e.g., for set languages [25, 40, 50], recursive \nfunctions [1, 37, 53], logic rules [38, 60], and object-oriented languages [39, 48, 59]. This work is \nthe .rst to extend incrementalization to dis\u00adtributed programs, where all sending and receiving of mes\u00adsages \nare systematically transformed into updates to mes\u00adsage history sequences. This allows the large body \nof pre\u00advious work on incrementalization, especially on sets and sequences, to be used for optimizing \ndistributed programs. Quanti.cations are the centerpiece of .rst-order logic, and are dominantly used \nin writing synchronization con\u00additions and assertions in speci.cations, but there are few results on \ngenerating ef.cient implementations of them. In databases, despite extensive work on ef.cient implementa\u00adtion \nof high-level queries, ef.cient implementation of uni\u00adversal quanti.cation has only been studied in limited \nscope or for extremely restricted query forms, e.g., [5 7, 12]. In logic programming, implementations \nof universal quanti.\u00adcation are all based on variants of brute-force Lloyd-Topor transformations, e.g., \n[18, 52]; even state-of-the-art logic programming systems [62, 69] do not support universal quanti.cation. \nOur method is the .rst general and system\u00adatic method for incrementalizing arbitrary quanti.cations. \nAlthough they are much more challenging to optimize than set queries, our method combines a set of general \ntransfor\u00admations to transform them into aggregate queries that can be most ef.ciently incrementalized \nusing the best previous methods.  To conclude, this paper presents a powerful language and method for \nprogramming and optimizing distributed algorithms. There are many directions for future work, from formal \nveri.cation on the theoretical side, to generating code in lower-level languages on the practical side, \nwith many additional analyses and optimizations in between.  Acknowledgments We are grateful to the \nfollowing people for their helpful comments and discussions: Ken Birman, Andrew Black, Jon Brandvein, \nWei Chen, Ernie Cohen, John Field, Georges Gonthier, Leslie Lamport, Nancy Lynch, Lambert Meertens, Stephan \nMerz, Don Porter, Michel Raynal, John Reppy, Gun Sirer, Doug Smith, Robbert van Renesse, and anonymous \nreviewers.  References [1] U. A. Acar, G. E. Blelloch, and R. Harper. Adaptive func\u00adtional programming. \nACM Transactions on Programming Languages and Systems, 28(6):990 1034, 2006. [2] G. Agha. Actors: a model \nof concurrent computation in distributed systems. MIT Press, 1986. [3] P. Alvaro, T. Condie, N. Conway, \nJ. Hellerstein, and R. Sears. I do declare: Consensus in a logic language. ACM SIGOPS Operating Systems \nReview, 43(4):25 30, 2010. [4] H. Attiya and J. Welch. Distributed Computing: Fundamen\u00adtals, Simulations, \nand Advanced Topics. Wiley, 2nd edition, 2004. [5] A. Badia. Question answering and database querying: \nBridg\u00ading the gap with generalized quanti.cation. Journal of Applied Logic, 5(1):3 19, 2007. [6] A. Badia, \nM. Gyssens, and D. Van Gucht. Query languages with generalized quanti.ers. In R. Ramakrishnan, editor, \nApplications of Logic in Databases. Kluwer Academic, 1994. [7] A. Badia, B. Debes, and B. Cao. An implementation \nof a query language with generalized quanti.ers. In Proceedings of the 27th International Conference \non Conceptual Model\u00ading. Springer, 2008. [8] Berkeley Orders of Magnitude. Bloom Programming Lan\u00adguage. \nhttp:llwww.bloor-lang.netl. [9] M. Bickford. Component speci.cation using event classes. In Proceedings \nof the 12th International Symposium on Component-Based Software Engineering, pages 140 155. Springer, \n2009. [10] M. Castro and B. Liskov. Practical Byzantine fault tolerance and proactive recovery. ACM Transactions \non Computer Sys\u00adtems, 20:398 461, 2002. [11] E. J. H. Chang and R. Roberts. An improved algorithm for \ndecentralized extrema-.nding in circular con.gurations of processes. Communications of the ACM, 22(5):281 \n283, 1979. [12] J. Clau\u00dfen, A. Kemper, G. Moerkotte, and K. Peithner. Opti\u00admizing queries with universal \nquanti.cation in object-oriented and object-relational databases. In Proceedings of the 23rd International \nConference on Very Large Data Bases, pages 286 295. Morgan Kaufman, 1997. [13] T. H. Cormen, C. E. Leiserson, \nR. L. Rivest, and C. Stein. Introduction to Algorithms. MIT Press, 3rd edition, 2009. [14] CRASH Project. \nEventML. http:llwww.nuprl.orgl softwarel#WhatisEventML, Last dated March 2012. [15] D. Dolev and H. R. \nStrong. Authenticated algorithms for Byzantine agreement. SIAM J. Comput., 12(4):656 666, 1983. [16] \nErlang Programming Language. Erlang Programming Lan\u00adguage. http:llwww.erlang.orgl. [17] C. J. Fidge. \nTimestamps in message-passing systems that preserve the partial ordering. In Proceedings of the 11th \nAustralian Computer Science Conference, pages 56 66, 1988. [18] F. Fioravanti, A. Pettorossi, M. Proietti, \nand V. Senni. Program transformation for development, veri.cation, and synthesis of programs. Intelligenza \nArti.ciale, 5(1):119 125, 2011. [19] V. K. Garg. Elements of Distributed Computing. Wiley, 2002. [20] \nC. Georgiou, N. A. Lynch, P. Mavrommatis, and J. A. Tauber. Automated implementation of complex distributed \nalgorithms speci.ed in the IOA language. International Journal on Soft\u00adware Tools for Technology Transfer, \n11(2):153 171, 2009. [21] M. Gorbovitski, Y. A. Liu, S. D. Stoller, T. Rothamel, and T. Tekle. Alias \nanalysis for optimization of dynamic lan\u00adguages. In Proceedings of the 6th Symposium on Dynamic Languages, \npages 27 42. ACM, 2010. [22] D. Goyal and R. Paige. The formal reconstruction and im\u00adprovement of the \nlinear time fragment of Willard s relational calculus subset. In Algorithmic Languages and Calculi, pages \n382 414. Chapman &#38; Hall, 1997. [23] A. Granicz, D. M. Zimmerman, and J. Hickey. Rewriting UNITY. \nIn Proceedings of the 14th International Conference on Rewriting Techniques and Applications, pages 138 \n147, 2003. [24] J. Gray. Notes on Data Base Operating Systems. In Advanced Course: Operating Systems, \nvolume 60 of Lecture Notes in Computer Science, pages 393 481, 1978. [25] A. Gupta, I. S. Mumick, and \nV. S. Subrahmanian. Maintain\u00ading views incrementally. In Proceedings of the 1993 ACM SIGMOD International \nConference on Management of Data, pages 157 166, 1993. [26] D. Hansel, R. Cleaveland, and S. A. Smolka. \nDistributed prototyping from validated speci.cations. Journal of Systems and Software, 70(3):275 298, \n2004. [27] D. S. Hirschberg and J. B. Sinclair. Decentralized extrema\u00ad.nding in circular con.gurations \nof processors. Communica\u00adtions of the ACM, 23(11):627 628, 1980. [28] I/O Automata Description of Leader \nElection Algorithm. http:llgroups.sail.rit.edultdslioalleader. htrl. [29] IOA toolkit extended version. \nhttp:llgroups.sail.rit. edultdslioaldistributionsliOA Toolkit-tools. tar.gz. The Paxos code is under \nExamples/Paxos. [30] D. Kaynar, N. Lynch, R. Segala, and F. Vaandrager. The Theory of Timed I/O Automata. \nMorgan Claypool Publishers, 2nd edition, 2010. [31] I. H. Kr\u00fcger. An experiment in compiler design for \na con\u00adcurrent object-based programming language. Master s thesis, The University of Texas at Austin, \n1996. [32] A. Kshemkalyani and M. Singhal. Distributed Computing: Principles, Algorithms, and Systems. \nCambridge University Press, 2008. [33] L. Lamport. Time, clocks, and the ordering of events in a distributed \nsystem. Communications of the ACM, 21:558 565, 1978. [34] L. Lamport. The part-time parliament. ACM Transactions \non Computer Systems, 16(2):133 169, 1998. [35] L. Lamport. Paxos made simple. SIGACT News (Distributed \nComputing Column), 32(4):51 58, 2001. [36] L. Lamport. The PlusCal algorithm language. In Proceedings \nof the 6th International Colloquium on Theoretical Aspects of Computing, pages 36 60, 2009.  [37] Y. \nA. Liu and S. D. Stoller. Dynamic programming via static incrementalization. Higher-Order and Symbolic \nComputa\u00adtion, 16(1-2):37 62, 2003. [38] Y. A. Liu and S. D. Stoller. From Datalog rules to ef.cient programs \nwith time and space guarantees. ACM Transactions on Programming Languages and Systems, 31(6):1 38, 2009. \n[39] Y. A. Liu, S. D. Stoller, M. Gorbovitski, T. Rothamel, and Y. E. Liu. Incrementalization across \nobject abstraction. In Proceedings of the 20th ACM Conference on Object-Oriented Programming, Systems, \nLanguages, and Applications, pages 473 486, 2005. [40] Y. A. Liu, C. Wang, M. Gorbovitski, T. Rothamel, \nY. Cheng, Y. Zhao, and J. Zhang. Core role-based access control: Ef\u00ad.cient implementations by transformations. \nIn Proceedings of the ACM SIGPLAN 2006 Workshop on Partial Evaluation and Semantics-Based Program Manipulation, \npages 112 120, 2006. [41] Y. A. Liu, M. Gorbovitski, and S. D. Stoller. A language and framework for \ninvariant-driven transformations. In Proceed\u00ad ings of the 8th International Conference on Generative \nPro\u00adgramming and Component Engineering, pages 55 64, 2009. [42] Y. A. Liu, S. D. Stoller, and B. Lin. \nHigh-level executable speci.cations of distributed algorithms. In Proceedings of the 14th International \nSymposium on Stabilization, Safety, and Security of Distributed Systems. Springer, 2012. To appear. [43] \nN. A. Lynch. Distributed Algorithms. Morgan Kaufman, 1996. [44] F. Mattern. Virtual time and global states \nof distributed sys\u00adtems. In Proc. International Workshop on Parallel and Dis\u00adtributed Algorithms, pages \n120 131, 1989. [45] Mechanically Checked Safety Proof of a Byzantine Paxos Algorithm. Mechanically checked \nsafety proof of a Byzan\u00adtine Paxos algorithm. http:llresearh.rirosoft.orl en-uslurlpeoplellarportltlalbyzpaxos.htrl.Last \nmodi.ed 1 September 2011. [46] S. Merz. Lamport s algorithm, 2010. Email. [47] Message Passing Interface \n(MPI) Forum. Message Passing Interface (MPI) Forum. http:llwww.rpi-forur.orgl. [48] H. Nakamura. Incremental \ncomputation of complex object queries. In Proceedings of the 16th ACM SIGPLAN Confer\u00adence on Object-Oriented \nProgramming, Systems, Languages, and Applications, pages 156 165, 2001. [49] P2. https:llsvn.delarativity.netl \noverlog-paxoslsrlolglorel. [50] R. Paige and S. Koenig. Finite differencing of computable expressions. \nACM Transactions on Programming Languages and Systems, 4(3):402 454, 1982. [51] Paxos in Bud Sandbox. \nhttps:llgithub.orl bloor-langlbud-sandboxltreelrasterlpaxos. [52] V. Petukhin. Programs with universally \nquanti.ed embedded implications. In Proceedings of the 4th International Confer\u00adence on Logic Programming \nand Nonmonotonic Reasoning, pages 310 324, 1997. [53] W. Pugh and T. Teitelbaum. Incremental computation \nvia function caching. In Conference Record of the 16th Annual ACM Symposium on Principles of Programming \nLanguages, pages 315 328, 1989. [54] G. Ramalingam and T. Reps. A categorized bibliography on incremental \ncomputation. In Conference Record of the 20th Annual ACM Symposium on Principles of Programming Languages, \npages 502 510, 1993. [55] M. Raynal. Distributed Algorithms and Protocols. Wiley, 1988. [56] M. Raynal. \nCommunication and Agreement Abstractions for Fault-Tolerant Asynchronous Distributed Systems. Morgan \n&#38; Claypool, 2010. [57] G. Ricart and A. K. Agrawala. An optimal algorithm for mutual exclusion in \ncomputer networks. Communications of the ACM, 24(1):9 17, 1981. [58] G. Ricart and A. K. Agrawala. Author \ns response to On Mu\u00adtual Exclusion in Computer Networks by Carvalho and Rou\u00adcairol. Communications of \nthe ACM, 26(2):147 148, 1983. [59] T. Rothamel and Y. A. Liu. Generating incremental imple\u00admentations \nof object-set queries. In Proceedings of the 7th International Conference on Generative Programming and \nComponent Engineering, pages 55 66, 2008. [60] D. Saha and C. R. Ramakrishnan. Incremental evaluation \nof tabled logic programs. In Proceedings of the 19th Inter\u00adnational Conference on Logic Programming, \npages 392 406, 2003. [61] I. Suzuki and T. Kasami. A distributed mutual exclusion algorithm. ACM Transactions \non Computer Systems, 3(4): 344 349, 1985. [62] T. Swift, D. S. Warren, et al. The XSB System Version \n3.3. Sourceforge.Net, 2011. http:llxsb.soureforge.netl. [63] G. Tel. Introduction to Distributed Algorithms. \nCambridge University Press, 2nd edition, 2000. [64] Two-phase commit in Bud Sandbox. https:llgithub.orl \nbloor-langlbud-sandboxlbloblrasterl2pl2p.rb. [65] Two-Phase Commit in PlusCal. http:llresearh. rirosoft.orlen-uslurlpeoplellarportltlal \ntwo-phase.htrl. [66] R. van Renesse. Paxos made moderately complex, October 11, 2011. An online version \nis at www.s.ornell.edul oursesl....12l2011splpaxos.pdf. [67] D. E. Willard. Ef.cient processing of relational \ncalculus ex\u00adpressions using range query theory. In Proceedings of the 1984 ACM SIGMOD International Conference \non Manage\u00adment of Data, pages 164 175, 1984. [68] D. E. Willard. An algorithm for handling many relational \ncalculus queries ef.ciently. Journal of Computer and System Sciences, 65:295 331, 2002. [69] G. Yang, \nM. Kifer, H. Wan, and C. Zhao. Flora-2: User s Manual Version 0.95. Sourceforge.Net and Stony Brook Uni\u00adversity, \n2008. http:llflora.soureforge.netl.  \n\t\t\t", "proc_id": "2384616", "abstract": "<p>This paper describes a very high-level language for clear description of distributed algorithms and optimizations necessary for generating efficient implementations. The language supports high-level control flows where complex synchronization conditions can be expressed using high-level queries, especially logic quantifications, over message history sequences. Unfortunately, the programs would be extremely inefficient, including consuming unbounded memory, if executed straightforwardly.</p> <p>We present new optimizations that automatically transform complex synchronization conditions into incremental updates of necessary auxiliary values as messages are sent and received. The core of the optimizations is the first general method for efficient implementation of logic quantifications. We have developed an operational semantics of the language, implemented a prototype of the compiler and the optimizations, and successfully used the language and implementation on a variety of important distributed algorithms.</p>", "authors": [{"name": "Yanhong A. Liu", "author_profile_id": "81549097356", "affiliation": "State University of New York at Stony Brook, Stony Brook, NY, USA", "person_id": "P3856102", "email_address": "liu@cs.stonybrook.edu", "orcid_id": ""}, {"name": "Scott D. Stoller", "author_profile_id": "81100262890", "affiliation": "State University of New York at Stony Brook, Stony Brook, NY, USA", "person_id": "P3856103", "email_address": "stoller@cs.stonybrook.edu", "orcid_id": ""}, {"name": "Bo Lin", "author_profile_id": "81549052056", "affiliation": "State University of New York at Stony Brook, Stony Brook, NY, USA", "person_id": "P3856104", "email_address": "bolin@cs.stonybrook.edu", "orcid_id": ""}, {"name": "Michael Gorbovitski", "author_profile_id": "81100574809", "affiliation": "State University of New York at Stony Brook, Stony Brook, NY, USA", "person_id": "P3856105", "email_address": "mickg@cs.stonybrook.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384645", "year": "2012", "article_id": "2384645", "conference": "OOPSLA", "title": "From clarity to efficiency for distributed algorithms", "url": "http://dl.acm.org/citation.cfm?id=2384645"}