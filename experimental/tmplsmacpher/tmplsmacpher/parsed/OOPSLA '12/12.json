{"article_publication_date": "10-19-2012", "fulltext": "\n An Abstract Interpretation Framework for Refactoring with Application to Extract Methods with Contracts \n Patrick Cousot Radhia Cousot ENS, CNRS, INRIA &#38; NYU CNRS, ENS, INRIA pcousot @cims.nyu.edu, {cousot, \nrcousot}@ens.fr Abstract Method extraction is a common refactoring feature provided by most modern IDEs. \nIt replaces a user-selected piece of code with a call to an automatically generated method. We address \nthe problem of automatically inferring contracts (pre\u00adcondition, postcondition) for the extracted method. \nWe re\u00adquire the inferred contract: (a) to be valid for the extracted method (validity); (b) to guard \nthe language and program\u00admer assertions in the body of the extracted method by an opportune precondition \n(safety); (c) to preserve the proof of correctness of the original code when analyzing the new method \nseparately (completeness); and (d) to be the most general possible (generality). These requirements rule \nout trivial solutions (e.g., inlining, projection, etc). We propose two theoretical solutions to the \nproblem. The .rst one is simple and optimal. It is valid, safe, complete and general but unfortunately \nnot effectively computable (except for unrealistic .niteness/decidability hypotheses). The second one \nis based on an iterative forward/backward method. We show it to be valid, safe, and, under reasonable \nassumptions, complete and general. We prove that the second solution subsumes the .rst. All justi.cations \nare provided with respect to a new, set-theoretic version of Hoare logic (hence without logic), and abstractions \nof Hoare logic, revisited to avoid surprisingly unsound inference rules. We have implemented the new \nalgorithms on the top of two industrial-strength tools (CCCheck and the Microsoft Roslyn CTP). Our experience \nshows that the analysis is both fast enough to be used in an interactive environment and precise enough \nto generate good annotations. Categories and Subject Descriptors D. Software [D.1 Programming Techniques]: \nD.1.0 General, D.2.1 Require\u00adments/Speci.cations, D.2.2 Design Tools and Technique, D.2.4 Software/Program \nVeri.cation, D.2.5 Testing and De\u00adbugging General Terms Design, Documentation, Experimentation, Human \nFactors, Languages, Reliability, Veri.cation. Permission to make digital or hard copies of all or part \nof this work for personal or classroom use is granted without fee provided that copies are not made or \ndistributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. OOPSLA 12, October 19 26, 2012, Tuscon, Arizona, USA. Copyright \nc &#38;#169; 2012 ACM 978-1-4503-1561-6/12/10. . . $10.00 Francesco Logozzo Michael Barnett Microsoft \nResearch {logozzo,mbarnett}@microsoft.com Keywords Abstract interpretation, Design by contract, Method \nextraction, Program transformation, Refactoring, Static analysis. 1. Introduction In their everyday activity, \nprofessional programmers heavily rely on the use of refactoring tools to improve, simplify, clean up, \ndocument, and modularize their code. Modern Integrated Development Environments (IDE) such as Eclipse, \nIntelliJ IDEA, or Visual Studio offer simple user interfaces to automate very tedious and error-prones \nactivities. Method extraction is used at design time to avoid code-bloat, to improve code readability, \nto emphasize reuse, and to simplify methods. Method extraction consists in selecting a piece of code \nand asking the IDE refactoring engine to produce a new version of the program where: (i) the selected \ncode is replaced by a call to a newly generated method (the extracted method); and (ii) the extracted \nmethod s parameters are the variables used (read/written) in the selected code and its body is the selected \ncode. The engine must guarantee that the new program is a syntactically legal program, i.e., if the original \nprogram compiled with no errors, then the new one compiles successfully, too. Furthermore, the concrete \nsemantics of the original program (up to the additional method call) should be preserved in the new version. \nThe problem of generating a syntactically correct refactored program (e.g., [21, 24, 31]) is now considered \na solved problem. However, the interaction between refactoring and static program analysis and veri.cation \nhas received minimal, if any, attention. We are interested in the interaction between method ex\u00adtraction \nand static analysis and veri.cation in a Design by Contract context (DbC) [35]. We focus our attention \non the in\u00ad ference of good contracts (preconditions and postconditions) for the extracted method. Contracts \nare useful for automatic generation of documentation and for separate modular anal\u00adysis and veri.cation. \nIn DbC, contracts are used to reason across method boundaries. Our static analysis is based on an assume/guarantee \nreasoning where the correctness proof is split between the callee and the caller. During the analy\u00adsis \nof a method body, its precondition is assumed and the postcondition should be proved. Dually, when the \ncaller is analyzed, the precondition of the callee should be proven and its postcondition can be assumed. \n Currently, refactoring tools bind the programmer to manu\u00adally add the contracts in order to prove the \nmodi.ed method with its call to the extracted method (e.g., by adding post\u00adconditions to the extracted \nmethod). Our goal is not only to infer the contracts automatically, but also to have good contracts. \nIntuitively, a good inferred contract should: (a) be valid for the extracted method (validity); (b) guard \nthe language and programmer assertions in the body of the ex\u00adtracted method by an opportune precondition \n(safety); (c) preserve the proof of correctness of the original code when analyzing the new method separately \n(completeness); and (d) be the most general possible (generality). In particular, the generality requirement \nallows the new method to be called in contexts other than the original refactoring context, and it rules \nout trivial solutions such as, e.g., projecting the abstract states at the beginning and the end of the \nselected text. 2. Informal introduction of the problem Imprecision induced by refactoring We illustrate \nthe prob\u00adlem with some C# examples. We use the CodeContracts API [4] to speci.y contracts1. Example 1. \nLet us consider the simple code snippet below. We assume the C# compiler is invoked with the -checked+ \nswitch, to generate over.ow/under.ow checks. public int Decrement(int x) { Requires(x >= 5); Ensures(Result<int>() \n>= 0); while (x != 0) x--; return x; } Assuming the precondition holds, CCCheck proves that: (i) no \narithmetic over.ow/under.ow happens; and (ii) that the method exit is reached with x = 0, validating \nthe (weaker user-provided) postcondition. Let us now select the loop and apply the extract method refactoring \nprovided by Visual Studio. The new program public int Decrement(int x) { Requires(x >= 5); Ensures(Result<int>() \n>= 0); x = NewMethod(x); return x; } private int NewMethod(int x) { while (x != 0) x--; return x; \n} can no longer be proved correct by CCCheck:  The analyzer suggests a necessary precondition for NewMethod \n(message #1), i.e., a precondition that should hold other\u00adwise the execution will de.nitely fail later. \nThe precondi\u00adtion is not suf.cient to ensure that NewMethod is correct, though. It reports that it cannot \nprove that the postcondition of Decrement holds on exit (messages #2, #3) and that the decrement of x \ndoes not under.ow (message #4). The imprecision is caused by the modular reasoning perfomed by CCCheck: \nit analyzes each method in isolation, using method contracts as summaries for all called methods. So \nwhen analyzing Decrement, since NewMethod has no contracts, it assumes the worst case: the return value \nof NewMethod can be any integer. And when analyzing NewMethod, since it has no contracts, x is unconstrained: \nthe decrement may under.ow (e.g., for an initial negative value of x). Our work is motivated by the weaknesses \nof the following state-of-the-art strawman solutions. First solution: Method Inlining One way to solve \nthe prob\u00adlem is to perform the inverse operation of method extraction: method inlining. In general, inlining \nmakes the analysis more precise. Nevertheless, we reject this solution. We want the analysis to be modular, \nand to use only boundary annota\u00adtions to reason on method calls. Boundary annotations have many advantages. \nFirst, they provide documentation for the method. Accurate documentation and early error-checking (e.g., \nby means of defensive programming) are crucial aspects of robust programming. Second, they make the analysis \nmore scalable: a method can be analyzed once and its results/spec\u00adi.cation can be used many times. Conversely, \ninlining may cause code bloat, with the same piece of code analyzed again and again. Third, boundary \nannotations provide check gates, which help in quickly understanding regressions and make the analysis \nresults easier to understand for the end-user. For example, let us suppose that a method m returns a \npositive value, and that this fact is used by the callers to infer some complex property f which eventually \nis used to discharge the assertion a. Now, let us suppose in the next version of the program the implementation \nof m is changed so to return a non-negative value. The value is propagated to the callers (i.e., by inlining \nm), f is no more inferred, and a cannot be proven anymore, so the analyzer issues a warning for a. For \nthe user, it is in general very hard to trace back the cause of the problem to the change in m, in particular \nif she does not own m. However, with explicit postconditions, m would have the postcondition that it \nreturns a positive value, so the static veri.er can immediately spot the problem where it occurs, and \nprovide better error messages to the user. Fourth, the extracted method may be later moved to another \nmodule, so that, e.g., its body will no longer be available for inlining. Second solution: Isolated analysis \nAnalyzing only the extracteded method in isolation does not take into account the context of the refactored \ncode. It would result in the trivial method precondition true, which is in general too 1 In CodeContracts, \ncontracts are speci.ed as opportune method calls of static members of the .NET type Contract. In the \nexamples, for the sake of readibility, we omit the explicit reference to the type Contract.  Figure \n1. A screenshot of the extract method with contracts. The suggested contract for the extracted method \nis valid, safe, complete and the most general one. imprecise. In particular, some information present \nin the original code (programmer assertions, runtime errors, etc) is lost when the refactored code is \nstatically analyzed separately. This can be avoided by using the method safety contract suggested by \nCCCheck. When the safety precondition is violated, the execution of the extracted method will either \nnot terminate or de.nitely yield a run-time error [18]. So the safety precondition is necessary for avoiding \nruntime errors. As shown by our example, the safety precondition is in general not suf.cient to guarantee \nthe absence of runtime errors: when the safety precondition is satis.ed, the execution of the extracted \nmethod may or may not fail/terminate 2. Once the necessary safety precondition is inferred [18], it can \nbe used to get a safety post-condition by isolated reachability analysis of the method body [11, 13]. \nIn general, an independent separate safety static analysis of the extracted method which does not take \ninto account the pre-invariant and post-invariant of the selected code is too weak. It might not be strong \nenough to guarantee that the refactored code invariant is still provable separately. Our main motivation \nfor this work was that the isolated analysis raised numerous (and self-evident) complaints from end-users \nof CCCheck. Third solution: User assistance Another way of solving the problem is to require the user \nto provide the precondition and the postcondition for the extracted method. This is the actual state \nof the art: programmers using any form of DbC (CodeContracts, Spec#, JML, Eiffel, Separation Logic, etc.) \nneed to manually insert the contracts for the extracted methods. We think that this is overkill and that \nthis represents another barrier for a wider adoption of DbC methods. We think that method extraction \nshould come with 2 The safety precondition is not a weakest liberal precondition that would be suf.cient \nbut maybe not necessary to guarantee the absence of runtime errors. The difference is that this suf.cient \nprecondition might exclude valid executions while the necessary safety precondition only excludes executions \nwhich are guaranteed to be de.nitely invalid or will not terminate. automatic contract refactoring, which \nautomatically infers good contracts for the extracted method. Forth solution: Abstract states projection \nAn immediate idea to solve the problem consists in projecting the relevant variables from the original \nabstract proof so as to get the required modular proof. Such a solution is unsatisfactory for three main \nreasons. First, it does not work when refactoring unreachable code: the abstract state is empty, so the \ngenerated precondition is false. Second, too much information may be lost (e.g., for relational analyzes) \nor too much information may be preserved (e.g., not related to the method correctness). For instance, \nin Ex. 1, the projection of the abstract state produces the too strong precondition 5 = x for the extracted \nmethod. Ideally we d love to infer the precondition 0 = x. Third, programs evolve over time so a refactoring \nmight work when performed but no longer work with later program modi.cations. Example 2. Suppose that \nwe want to extract a method MakeRoom from (*)...(**) in the code below. Insert(string[] list, ref int \ncount, string newElement) { Requires(list != null &#38;&#38; // in bounds 0 <= count &#38;&#38; count \n<= list.Length &#38;&#38; // no overflows on resize list.Length < 33554432); if (list.Length == count) \n{ (*) var tmp = new string[count*2 + 1]; CopyArray(list, tmp); list = tmp; (**) } list[count++] = newElement; \nreturn list; } If we simply project the abstract states, the contract for the new method is Requires(list!=null \n&#38;&#38; list.Length==count (1) &#38;&#38; count <= 33554432); Ensures(Result<string[]>() != null); \nThe precondition is too strong for the callers. The refactored method MakeRoom can only be invoked when \ncount is ex\u00adactly the length of the array and the array is not too large (less than 225 elements). Furthermore, \nin the postcondition, because of the imprecision of the projection, we lost the rela\u00adtion between the \nlength of the result array and count. With our technique, we instead infer the more general contract: \nRequires(list != null &#38;&#38; 0 <= count * 2 + 1); Ensures(Result<string[]>() != null &#38;&#38; 2 \n* count -Result<string[]>().Length == -1); The precondition ensures that the internal allocation is safe \n(even with possible arithmetic over.ows) and that we copy a valid list. The postcondition guarantees \nthat the array returned by MakeRoom is large enough. Overall, many more callers are enabled and no (new) \nwarning is raised in Insert.  Our solution We want to suggest good contracts for ex\u00adtracted methods. \nThe suggested contracts should enjoy some theoretical properties, to rule out the problems illustrated \nby the strawman solutions above. (a) validity First, the inferred contract should be valid for the extracted \nmethod. For instance, in Ex. 1, the following contract for NewMethod Requires(5 <= x); Ensures(Result<int>() \n== 12345); would allow the proof of Decrement go through, but clearly is not satis.ed by NewMethod s \nimplementation. (b) safety Second, the extracted method precondition should check the language and programmer \nassertions in the body of the extracted method [18]. For instance, the empty precondition for NewMethod \nin Ex. 1 does not meet this crite\u00ad rion (a negative input value causes an under.ow). Without the safety \nprecondition, the language and programmer assertions within the selected code would be hidden in the \nextracted method call. So the inference of a safety contract for the method enclosing the selected code, \nif any, would become impossible. The semantics is preserved, up to the fact that de.nite errors will \nbe signaled earlier, at the method call, whereas in the original call they would have been signaled later, \nduring execution of the selected code. (c) completeness Third, the veri.cation of the origi\u00adnal code \nshould remain unchanged when analyzing the new method separately. For instance, the following contract \nfor NewMethod in Ex. 1:  Requires(5 <= x); Ensures(Result<int>() <= OldValue(x)); satis.es the (a) \nvalidity and (b) safety criteria, but it fails (c) completeness. (d) generality Fourth, the automatically \ninferred con\u00adtract should be the most general possible with the above properties. The generality criterion \nis important for reusabil\u00adity of the extracted method as well as to guarantee that other program modi.cations/transformations/refactorings \nare not in.uenced at all by this method refactoring. For instance, the following contract for NewMethod \nRequires(5 <= x); Ensures(Result<int>() == 0); satis.es the three requirements (a c) above, but it is \nnot the most general one. The most general one is the one shown in Fig. 1. As also illustrated in Ex. \n2, the generality criterion rules are important to rule out the trivial solution of using the (projection \nof the) abstract states at the beginning and at the end of the selected code as the new contract. When \nthe four conditions (a d) above are satis.ed, the refactored code is veri.able with the same precision \nas the original code, so that method extraction is guaranteed not to perturb the veri.cation process. \nIn general, the problem is undecidable, hence requires approximate solutions as dis\u00adcussed in this paper \nor speci.c additional hypotheses to en\u00adsure decidability (such as unrealistic .nite state/decidability \nhypotheses). 3. Informal introduction of the solution An example of the user experience with the algorithms \nin this paper using CCCheck and Roslyn is shown in Fig. 1. Given the selected portion of code, the IDE \nprovides the option of the standard refactoring or our new refactoring. When selecting the new option, \nthe preview shows the extracted method with the suggested contracts. We informally describe the main \nsteps of our solution. When the user selects a piece of code S and asks for the extract method with contracts \n, we .rst invoke the usual extract method service of the IDE. If the selection cannot be made into a \nnew method, then the refactoring fails and we stop here. Otherwise we obtain a snapshot of the source \nprogram as it appears after the refactoring. Our goal is to annotate the NewMethod with good contracts, \ni.e., contracts satisfying the four requirement (a d) exposed in the previous section. After a static \nanalysis of the original program, the .rst step of our solution is to detect the pre-state and post-state \nof the selected code S on the variables of interest. We identify the variables of interest from the invocation \nof NewMethod in the refactored code. In Ex. 1, x is a variable of interest for both the pre-state and \nthe post-state: for the former since x is the actual parameter in the invocation of NewMethod and for \nthe latter since it is where the return value of NewMethod is stored. To get the pre-state (resp. post-state), \nwe query the underlying static analysis for the abstract value of x at the beginning (resp. end) of the \nselection. In the example the pre\u00adstate is PS \u00a3 5 = x. Intuitively, PS is a lower bound for the desidered \nprecondition: in general we seek a more general (weaker) precondition for NewMethod. Similarly, the post\u00adstate \nis the (abstract) value of x at the end of the selection, i.e., QS \u00a3 x =0. Intuitively, QS is an upper \nbound for the desidered postcondtion: in general we seek a more speci.c (stronger) postcondition for \nNewMethod. The next step of our solution is to infer the safety (or nec\u00adessary) precondition for NewMethod \n(and the corresponding postcondition). The idea is that of pushing inevitable safety checks (e.g., runtime \nerrors) back to the entry of the method so to expose them to the callers. Suppose for a second that we \nhave an effective algorithm: (i) to infer the best safety precon\u00additions; and (ii) to compute the strongest \npostconditions. Then we have a solution to our problem: the precondition is the best safety precondition \nand the postcondition is the strongest postcondition starting from that precondition (Th. 10). In Ex. \n1 the best safety precondition is 0 = x: an initial negative value for x de.nitely causes an arithmetic \nunder.ow. Unfor\u00adtunately, in practice and in the general case, such a precise and terminating algorithm \ndoes not exist the problem is undecidable. As a consequence we must perform some ap\u00adproximations to \nmake the problem tractable. The next steps of our solution are designed to cope with that issue. Intuitively \nwe use a combination of over-and under-approximations, and of forward and backward analyses to compensate \nfor the loss of precision inherent in the abstraction (Th. 11 and Th. 22).  We .rst compute an under-approximation \nof the best safety precondition [18]. In the example, our analysis infers a safety precondition Pm \u00a3 \nx MinValue. If this fails = to hold, execution certainly results in an error. However, it does not guarantee \nthe absence of errors. Starting with the abstract state Pm , we use an over-approximating forward analysis \nto compute the corresponding postcondition Qm . The postcondition captures the .nal states of executions \nthat do not result in an error. In the example Qm \u00a3 x =0 if the loop terminates at all, it terminates \nin that state. The contract (Pm ,Qm ) is more general than (PS ,QS ) the precondition enables more calling \ncontexts and Qm = QS . However, the contract is not safe, e.g., an error still occurs when x = -1. Therefore \nwe need to further re.ne it. We use an over\u00adapproximating backwards analysis starting from Qm to infer \na better precondition. In our example this precondition is PR \u00a3 0 = x note that PR implies Pm . The \ncorresponding postcondition, obtained by the forward analysis remains QR \u00a3 x =0. The contract (PR,QR) \nis more general than (PS ,QS ). While in general continuing the iterations may improve the contract, \nin our example we already found a .xpoint. Our analysis proves that the contract is safe no runtime \nerror will occur in NewMethod body. Therefore, we annotate NewMethod with the contract (PR,QR). Overall, \nwe inferred a contract satisfying (a d). In particular, it is a better contract than (PS ,QS ), i.e., \nwe improved over the simple abstract states projection. The example above did not really exploit Pm : \nthe back\u00adwards analysis compensated for any imprecision in the safety precondition inference. The refactoring \nof Insert shows an example where a precise Pm and forward analysis are relevant. We already reported \nthe projected contract (PS ,QS ) in (1). The inferred safety precondition is Pm \u00a3 list = null . 0 = 2 \n\u00b7 count + 1. It manifests the fact that CopyArray will fail if given a null reference and that the allocation \nwill fail if count is negative or so large that doubling it causes over\u00ad.ow. The corresponding postcondition \nis Qm \u00a3 result= null.result.Length =2\u00b7count+1. (Pm ,Qm ) is a better contract than (PS ,QS ), as Pm is \nmore general than PS and Qm is more speci.c than QS . In this case, the backwards analysis does not improve \nthe contract. (Pm ,Qm ) is the .xpoint, and it satis.es (a d). These are the two extremes. In general, \nthe combination of the safety precondition inference with the forward/backwards iterations improve each \nother, and provide a very powerful algorithm to infer good contracts (Alg. 5). 4. Main Results In order \nto rigorously de.ne the Extract Method with Con\u00adtracts (EMC) problem and the refactoring with contracts \nin general, we need an opportune mathematical formalism, for instance to reason about method calls. Intuitively, \nHoare Logic provides such a formalism. We seek generality so that our results can be applied in many \ndifferent contexts, with different abstract domains and speci.cation logics. There\u00adfore, we do not want \nto be speci.c to a particular assertion language, e.g., .rst order logic [7, 22], separation logic [39], \nor region logic [2]. To the best of our knowledge there is no such general theory to reason about contracts, \nand so we had to build it. Our .rst contribution is the development of a new set\u00adtheoretic version of \nHoare logic (Algebraic Hoare Logic, Sec. 5), with the idea that the particular logics used by the analysis/veri.cation \ntools are just an abstraction of those sets. A surprising result is that common inference rules in Hoare \nLogic, like the conjuction and disjunction rules are false in general (Ex. 5). We use algebraic Hoare \nlogic to de.ne the elements of the domain C[m] of the contracts for a method m and two orders \u00d7 over \nsuch domain, a covariant order =.. and a contravariant cc order =. (Sec. 6). The .rst order captures \nthe intuition that a . =\u00d7.-stronger contract is better for the callee: assuming more on the precondition \nlet it guarantee more on the postcondition. The second order captures the intuition that a =cc.-stronger \ncontract is better for the callers: it is more general and it can be used in more contexts. The set C[m] \nof contracts for m \u00d7 cc ordered either by =.. or by =. is a complete lattice. The algebraic Hoare logic, \nthe set of contracts and the two orders provide a basic framework for the de.nition of contract-based \nrefactorings. We instantiate it to state the new problem of the extract method with contracts (EMC, Sec. \n8). We formally de.ne the four requirements (a d) of the previous section in terms of algebraic Hoare \nlogic and the \u00d7cc two orders =.. and =.. A main theoretical result of the paper is that in the concrete \nthe EMC problem always has a solution, and this solution is unique (Th. 10). Roughly, the suggested precondition \nis the strongest safety precondition Pm (to make sure the caller encounters no runtime error when m is \nexecuted) and the suggested postcondition is the strongest postcondition from Pm . The result is of great \ntheoretical interest, but of little practical application: the strongest safety precondition and the \nstrongest postcondition are not computable in general. The direct abstraction is likely to produce a \nvery imprecise result, as over-approximation may lose completeness. Therefore, we provide an equivalent \ncharacterization for the solution of the EMC problem, in terms of the iteration of a forwards analysis \nand of a backwards analysis (Th. 11) allowing for a more precise algorithm in the abstract. To provide \nan effective solution to the EMC problem we should perform some abstraction. We de.ne the notion of abstract \ncontracts, essentially contracts where the assertion language is some abstraction of sets of states (Sec. \n10). Surprisingly enough, we found that in general the property of being a more precise abstract contract \nis not preserved in the concrete (Ex. 12). We restate the EMC problem in terms of the primitives of the \nunderlying abstract domain (EMC, Sec. 12). We prove soundness, i.e., a solution to EMC is a solution \nfor EMC (Th. 15). We present some examples proving that, in general, a complete EMC is impossible.  \nWe abstract the iterated formulation of the EMC solu\u00adtion to provide an effective static analysis to \ncompute EMC (Sec. 13). Let us assume to have an abstract transformer (roughly, the two-directional static \nanalysis for the method body) safely approximating the concrete semantics of the method and a projection \nof the abstract states in the origi\u00adnal method (before the extraction of the method) (P/,Q/). SS Then \nthe iterations of the abstract transformer starting from (P/,Q/) provide a correct solution (Th. 20). \nWhen the SS abstract transformer is the best approximation of the con\u00adcrete transformer, the abstract \nforwards/backwards iterations provide the most precise solution for EMC (Th. 21). When the underlying \nabstract domain does not satisfy the Ascend\u00ading/Descending chain conditions, a .xpoint acceleration op\u00aderator \n(narrowing [11]) should be used to enforce the con\u00advergence of the iterations (Algorithm EMC in Alg. \n5). The resulting contract is still a correct solution (Th. 22), but we may not get the most general \nsolution just one more gen\u00aderal than the simple projection. We implemented the new algorithms by integrating \nthe Code Contracts for .NET static analyzer (CCCheck) [20] with the Microsoft Roslyn CTP (Roslyn) [37]. \nWe use Roslyn, a new implementation of .NET languages to support the compiler-as-service paradigm, as \nour refactoring engine. We use CCCheck as the underlying static analyzer. Unlike similar tools (e.g., \n[22, 23]), CCCheck is based on abstract interpretation, and it automatically infers and propagates loop \ninvariants intra-procedurarly, so that annotations are needed only for the method boundaries. The inferred \ninvariants are used to validate both the user-provided contracts as well as the absence of runtime errors \n(e.g., null dereference, under.ow/over.ow, buffer overruns, etc.). Our experience shows that the proposed \nmethod extraction with contracts is quite effective (Sec. 14). 5. Algebraic Hoare Logic We use Hoare \nlogic [29] to formalize Contracts [4, 35]. The concrete Hoare rules are used to specify the program axiomatic \nsemantics, i.e., all possible program executions. We use an abstract version of Hoare logic to formalize \ncontract-based separate static analyses. The abstract Hoare rules are used to specify how the static \nanalyzer should work for a given abstraction. In this abstract Hoare logic, predi\u00adcates are replaced \nby abstract properties chosen in computer\u00adrepresentable abstract domains with computable transformers \nand .xpoint approximation [12] such as intervals [10], oc\u00adtagons [36], subpolyhedra [30], or polyhedra \n[16]. The general correctness argument is that static analyzers are correct because they implement an \nabstract Hoare logic which is itself sound because it correctly abstracts a concrete Hoare logic describing \nprecisely the language semantics. Both concrete and abstract Hoare logics can be formalized in a single \nuni.ed framework using algebraic Hoare triples and abstract interpretation to relate algebraic Hoare \nlogics operating at different levels of abstraction. In this context the conjunction rule is potentially \nproblem\u00adatic in the abstract (as illustrated in the forthcoming Ex. 5). We cannot get rid of this conjunction \nrule because it for\u00admalizes the use of reduced products [13] in static analyzers. Therefore we study \nsuf.cient conditions on the abstraction for this conjunction rule to be sound (Th. 6) which is useful \nbeyond the speci.c problem of method refactoring (Ex. 7). We .rst introduce some de.nitions and notations \nused in the rest of the paper. Galois Connections We recall from [11] that a Galois . .-- connection \n(C, -)--.(A, g) is such that (C, -) and a (A, g) are partial orders, a . C . A and . . C . A satisfy \n.x . C : .y . A : a(x) g y .. x -.(y). We . .--- write (C, -) ---. (A, g) to denote that the abstraction \na function a is surjective, and hence that there are no multiple representations for the same concrete \nproperty in the abstract. If the C and A are complete lattices, and a is join-preserving, . .-- then \nit exists a unique . such that (C, -)--.(A, g). a Abstract domains We let S . S[v ] be a statement with \nvisible variables v and P[vv] be the set of unary predicates on variables vv. Predicates can be isomorphically \nrepresented as Boolean functions P .P[vv] \u00a3 Vv[vv] . B mapping values vv .Vv[vv] of vector values of \nvariables vv to Booleans: P (vv) . B \u00a3 {true, false}. Predicates are ordered according to =. ., i.e., \nthe pointwise lifting of logical implication to functions: P =..P ' \u00a3 .vv . vv)=. P '(v ). V[v ] : P \n(vFor example . x . x =0=... x . x . 0. Predicates with partial order =..form a complete Boolean lattice: \n(P[vv], .., f ..... =alse, true, ., ., \u00ac)where false.is the in.mum, true is the supremum, ..is the .least \nupper bound (lub), ..is the greatest lower bound (glb), and \u00ac.is the unique complement for the partial \norder =. . on the set P[vv]. The precondition abstract domain (A[vv], g) is an abstract 1 domain expressing \nproperties of the variables vv where the partial order g abstracts logical implication. The meaning 1 \nof an abstract property P . A[vv] is a concrete property .1(P ) .P[vv] where the concretization .1 .(A[vv], \ng) . (P[vv], =. 1 .) '' 1 is increasing (i.e., P g P implies .1(P )=...1(P )). Example 3. Assume that \nvv \u00a3 x is reduced to a single variable x. Let A[vv] be the lattice with the ordering g de.ned 1 by the \nfollowing Hasse diagram:  ..1(=) \u00a3 . x .x : 0 .1(=) \u00a3 . x .x =0 .1(=) \u00a3 . x .x 0 .1(<) \u00a3 . x .x< 0 \n.1(=) \u00a3 . x .x =0 .1(>) \u00a3 . x .x> 0 .1(T) \u00a3 true 1 g) .1(.) f . \u00a3 alse . (A[x], According to the de.nition \nof .1, A[x] is interpreted in the concrete as specifying the sign of values x .Vv[x] of variable x [13]. \n2 The postcondition abstract domain (B[v ,v ], g) is an abstraction of the complete lattice (P[v ,v ], \n.., f .true, ., ., \u00ac) =alse, .... of binary predicates, e.g., postconditions relating the initial and \n.nal values of variables. The meaning .2(Q) of an abstract relation Q . B[v ,v ] is given by a .nite-meet\u00adpreserving \nconcretization 2 .2 .(B[v ,v ], g) . (P[v ,v ], =. .), satifying .2(Q f2Q ')= .2(Q) ...2(Q '). The .nite-meet \nhypothesis is needed to avoid the problems exposed in the forthcoming Ex. 5. The .nite-meet hypoth\u00adesis \nimplies that .2 is increasing. The function .2 is meet\u00adpreserving if and only if it preserves in.nite \nmeets hence is the upper-adjoint of a Galois connection [13]. A meet\u00adpreserving function is trivially \n.nite-meet preserving. Example 4. Assume that v \u00a3 x is reduced to a single variable x. Let B[v ,v ] be \nthe lattice with the ordering g 2 de.ned by the following Hasse diagram: . .2(T) \u00a3 true ' .2(=) \u00a3 . x, \nx ' . x : x ' .2(=) \u00a3 . x, x ' . x = x ' .2(=) \u00a3 . x, x ' . xx ' .2(<) \u00a3 . x, x ' . x < x ' .2(=) \u00a3 . \nx, x ' . x = x ' .2(>) \u00a3 . x, x ' . x > x 2 g) .2(.) f . \u00a3 alse . According to the de.nition of .2, B[x, \nx] is interpreted in the concrete as specifying a relation between the values x (B[x, x], ' and x of \nvariable x (e.g., before and after executing a piece of code to be refactored). Concrete Hoare triples \nA concrete Hoare triple {P } S {Q} denotes the partial correctness of a program statement S . It denotes \nthe fact that if the precondition P .PS[[vv ]].holds of the values of the variables before ex\u00adecuting \nstatement S, and the execution of the statement S does terminate, then the postcondition/before-after \nrelation Q .P[v ,v ] holds and relates the initial and .nal values of the variables v before and after \nthe execution of S. Concrete Hoare triples can be understood as Boolean functions: 3 { } { } .P[v \n] \u00d7 S[v ] \u00d7P[v ,v ] . B . Concrete Hoare logic rules The classical axiomatization of Hoare logic remains \nvalid in set-theoretical form as shown in Fig. 2. The disjunction rule (.) and conjunction rule (.) in \nFig. 2 are usually not shown in Hoare logic axiomatization since they derive from the other rules, by \ninduction on the structure of programs. Predicate transformers We use a generalization of the usual Dijkstra \ns strongest postconditions predicate tran\u00adformer [19] to sets (instead of logical formulas). The set\u00adtheoretic \nforward predicate transformer post . S[v ] . (P[v ] .P[v ,v ]) of [9] provides such a generalization. \nThe transformer post veri.es the two properties: { P } S { post [S]P }, (2) .Q .P[v ,v ] : { P } S { \nQ } =. (post [S]P =. Q) . The forward predicate transformer post [S] is join-preserving. Therefore, it \nhas a unique adjoint p pre[S] such that pre[S] p .----- (P[v ], =.).-----.(P[v ,v ], =.).(3) post[S] \nis a Galois connection, i.e., .P .P[v ] : .Q .P[v ,v ] : (post [S]P =. Q) .. (P =. pre[S]Q). Intuitively, \np pre[S] is a generalization to sets of Dijkstra s weakest liberal p preconditions predicate transformer. \nAbstract Hoare triples An abstract Hoare triple is similar to a concrete Hoare triple except that the \nprecondition and postcondition are chosen in abstract domains as used, e.g., by a static analyzer or \na SMT-solver [17]: \u00af { }\u00af {\u00af }\u00af. A[v ] \u00d7 S[v ] \u00d7 B[v ,v ] . B The concrete Hoare triples are a particular \ncase of abstract Hoare triples by choosing A[v ] = P[v ], B[v ,v ] = P[v ,v ], .1 and .2 to be the identity. \nWe say that an abstract Hoare triple is sound if and only if \u00af\u00af\u00af { P } S {\u00afQ } = { .1(P ) } S { .2(Q) \n} (4) Abstract Hoare Logic Rules In the abstract, program state\u00adments are handled by abstraction [11]. \nThe corresponding ab\u00adstract rules are in Fig. 3. Surprisingly, the following counter\u00adexample shows that \nthe abstract rules of Fig. 3 may be un\u00adsound in the sense of (4). This is because the classical version \nof Hoare logic makes implicit assumptions upon the accept\u00adable interpretations of logical predicates/assertions \nwhich may not be preserved by the abstraction since, e.g., for (.), 1. .1( i P i)=..y .1(P i) but not \ninversely when .1 is in\u00ad i.. i.. creasing but not join-preserving. Example 5 (Unsound abstract interpretation). \nConsider the following abstractions where A is the pre-condition abstract domain 3 This point of view \nconsists in considering a particular interpretation of Hoare logic, the one corresponding to the programming \nlanguage semantics.  { false.} S { Q } (.) .v : P (v )=. I(v , v ), { P } S { true } (T) { .v ' . .v \n: I(v , v ') } assert(E); S {J }, . ''' '''), .v ,v ,v : I(v , v ') . J(v ,v '')=. I(v , v ' ' . P \n(v ) . v (s) { P } skip { .v , v = v } ' { P } assert(E) { .v , v ' . P (v ) . [E]v . v = v } (a) ' \n { P } x = E { .v , v ' . P (v ) . v = v [x . [E]v ] } (=) { P }S1 { Q }, { .v ' . .v : P (v )=. Q(v \n, v ') } S2 { R } (;) { P } S1 ; S2 { .v , v '' . .v ' : Q(v , v ') . R(v ' ,v '') }{ .v . P (v ) . \n[E]v }S1 { Q1 }, {.v . P (v ) . [\u00acE]v } S2 { Q2 } (i) {P } if(E) S1 else S2 { Q1 ..Q2 } Figure 2. Concrete \nHoare triples axiomatization. \u00af\u00af\u00af If A[v ] has an in.mum .A such that .1(.A)= f .{ .A } S {\u00afQ (.) alse \nthen for all Q . B, } = true \u00af\u00af\u00af .} S \u00af If B[v ,v ] has a supremum TB such that .2(TB)= true then for \nall P . A, { P { TB } = true (T) { .1(P ) }S { .2(Q) } (S)\u00af\u00af\u00af { P }S {\u00afQ }P g P ' . {\u00afP ' }\u00afS {\u00afQ ' }\u00af. \nQ ' g Q 12 ( . )\u00af\u00af\u00af { P }S {\u00afQ } Figure 3. Abstract Hoare triple axiomatization. Without additional \nhypotheses, the rules (.) and (.) are unsound. and the post-condition abstract domain B preserves neither \njoins nor meets. We have \u00af\u00af\u00af { x = 0 }\u00afx = -x { x = 0 }\u00afand {\u00afx = 0 }\u00afx = -x { x = 0 }\u00af but de.nitely \nnot the conjunction in A \u00d7 B \u00af\u00af 1 { x = 0 f x = 0 }\u00afx = -x { x = 0 f2x = 0 }\u00af which is \u00af\u00af { x =0 }\u00afx \n= -x { false }\u00af Similarly, \u00af { x< 0 }\u00afx = x*x {\u00afx> 0 }\u00af. \u00af x { x> 0 l1x> 0 }\u00af\u00af =x*x { x> 0 }\u00af. The Ex. \n5 shows the necessity for .2 to preserve .nite conjunction for the abstract conjunction rule (.) to be \nsound for .nite abstract conjunctions. Similarly, (.) is not sound when .1 is not join-preserving. More \ngenerally: Theorem 6 (Sound abstract interpretation). The abstract Hoare triple axiomatization of Fig. \n3, without (.) and (.) is sound in the sense of (4). Moreover if .1 is increasing, the glbs do exist, \n.2 is .nite\u00admeet-preserving and . is .nite then the abstract conjunction (.) is also sound. If .2 is \nincreasing, the lub exists, and .1 is .nite-join-preserving and . is .nite or .1 is join preserving then \nthe abstract disjunction rule (.) is also sound. The notion of Algebraic Hoare Logic developped in this \nSec. 5 and the issues with the unsoundness of the (.) and (.) rules of the abstract Hoare logic of Fig. \n3 as well as the discussion for when they are sound in Th. 6 are applicable beyond the speci.c problem \nof method re-factoring. Example 7. Concurrent separation logic [38] is an example of algebraic Hoare \nlogic where abstract domains are predi\u00adcates over a separation algebra [27]. Because of the conjunc\u00adtion \nrule, the logic is unsound unless resource invariants are precise, i.e., unambiguously carve out an area \nof the heap. For example, the separation logic assertion x . 0, denoting a cell { x> 0 }\u00afx = x*x {\u00afx> \n0 }\u00afand \u00afThe disjunction in B \u00d7 A is \u00af 2 { x< 0 l x> 0 }\u00afx=x* \u00af that is the unsound {\u00aftrue }x '' .v , \nv : I(v , v ') . [\u00acE]v =. Q(v , v ') (w) { P } while(E) S { Q }P =..P ' .{ P ' } S { Q ' }. Q ' =. . \nQ (.) { P } S { Q }.i . .: { Pi } S { Qi } {..i . .: Pi } S {..i . .: Qi } (.) .i . .: { Pi } S { Qi \n} {..i . .: Pi } S {..i . .: Qi } (.) \u00af\u00af .i . .: {\u00afP i } S {\u00afQi }\u00af\u00af\u00af { 1P i } S {\u00af2Qi } (.) i.. i.. \u00af\u00af \n.i . .: {\u00afP i } S {\u00afQi }\u00af\u00af\u00af 2 { 1 P i } S {\u00afQi } (.) i.. i..  at the address x storing 0, is precise; \nhowever, the assertion x . 0 . emp, denoting either the cell or the empty heap, is not. In particular, \nimprecise resource invariants allow the two premisses of the conjunction rule to make con.icting choices \nabout how to partition the heap. For imprecise predicates, the concretization may not preserve intersection \n[27, Def. (14)]. As stated in Th. 6, one solution is to restrict the abstract domain (i.e., the predicates \nover a separation algebra) to be .nite-meet-preserving, which is the case for precise resource invariants, \nas in [6]. The second solution is to exclude the conjunction rule, as in [27]. The third solution would \nbe to design a sound abstract version of the disjunction rule by abstract interpretation so as to under-approximate \nthe concrete disjunction. Abstract Hoare Logic Rules for Static Analysis In the following we will use \na sound version of the abstract Hoare logic with the conjunction rule (.) but not with disjunction rule \n(.). Abstract conjunction rule The conjunction rule (.) is of interest for static analyzers using reduced \nproducts [13]. Re\u00adduced products allow the automatic combination of separately designed analyzes so as \nto express conjunctions of different abstract properties. Classical abstract domains such as intervals \n[10], octagons [36], subpolyhedra [30], or polyhedra [16] do satisfy the hy\u00adpotheses of Th. 6 ensuring \nthe soundness of the conjunction rule (.) since in those cases .2 is .nite-meet-preserving (al\u00adthough \nnot in.nite meet-preserving since e.g., for polyhedra [16] the concretization is not the upper-adjoint \nof a Galois connection). Abstract disjunction rule For the disjunction rule, enforcing .1 to preserve \n(in.nite) joins for (.) is a very restrictive hypothesis essentially forbidding the approximation of \njoins which is the basis for static analysis. However, the disjunction rule (.) is not needed in static \nanalyzers since disjunctions are usually handled speci.cally in each abstract domain. 6. Formalization \nof Contracts We de.ne the two notions of valid and safe method contracts in terms of Algebraic Hoare \ntriples. We also introduce two partial orders needed for the formalization of the extract method with \ncontracts. Valid contract We write S|gto mean that all variables p\\gg used or modi.ed by a program statement \nS belong either to vp or vg. The variables in vp are (potentially) read or written whereas those in vg \nare de.nitely unmodi.ed by any execution of statement S. This is formalized as: ' { . (vp,vg) . true \n} S|g{ . (vp ,vg '), (vp,vg) . vg = vg ' }. (5) p\\gg When refactoring S|ginto a new method m(vp){ S|g}, \np\\ggp\\gg the variables vp are passed as parameters while the variables vg are global. It is always sound \nto .-over-approximate the set vp and .-under-approximate the set vg. We assume that the extracted method \nand the contracts are speci.ed as follows: private void m(vp) { (6) Requires( PR(vp) ); Ensures( QR(OldValue(vp),vp) \n); Ensures( .x . p : OldValue(x) == x ); S|g p\\gg } where OldValue(vp) denotes the values of the actual \nparame\u00adters when calling method m. The precondition PR(pv) is checked when the method is called on the \nvalues pvof the actual parameters vp. The postcondition QR(vp p (denoted p, v') relates the initial values \nvOldValue(vp) in (6)) of the parameters vp on method entry ' to their .nal values pv(denoted vp in (6)) \non method exit. The postcondition is checked at runtime on exit. In the case of a contract failure, the \nexecution halts. The fact that none of the variables other than vp can be modi.ed by a method call is \neither speci.ed explicitly, if allowed by contract speci.cations, or recorded together with the method \ncontract, or else assumed implicitly. This assumption will be needed to guarantee the soundness of the \nseparate method call proof rules of Sec. 7 and Sec. 11. We let the set of all the contracts for the method \nm to be C[m] \u00a3 P[vp] \u00d7P[vp,vp] . De.nition 8. A contract (P, Q).C[m] is a valid m contract if and only \nif { P } S|g{ Q }. p,gg In absence of valid contracts, we can always use the trivial cc .. true \u00a3 (true, \ntrue) . Safety pre-condition A property Pm .P[vp] is a safety precondition for a method void m { S|g} \nif and only if p\\gg { f . { \u00ac.Pm } S|galse } . p\\gg Intuitively, if Pm does not hold then the execution \nof the method body S|gis doomed to fail either because of non\u00ad p\\gg termination or because of a runtime \nerror causes the program to stop. By (2), we have post [S|gp\\gg ] \u00ac.Pm . f . =alse, which, by (3), is \nequivalent to \u00ac.pre[S|galse =.. In practice . Pm pp\\gg ]f .* the strongest precondition P \u00a3 \u00ac.pre[S|galse \nis not m pg ]f . p\\g computable and so will have to be over-approximated by a * weaker precondition Pm \nsuch that P =.. Any one of the . Pm m backward static analyses in [18] can be used to effectively compute \nan abstract version of Pm . It follows that \u00ac.Pm under\u00ad ** approximates \u00ac.P in that \u00ac.Pm =.\u00ac P and so, \nby (.), . . mm { f .\u00ac.Pm satis.es { \u00ac.Pm } S|galse }. p\\gg Safety post-condition Once a safety pre-condition \nPm . P[vp] has been inferred, a safety post-condition Qm .P[vp,vp], relating the initial values pvof \nthe parameters vp and their .nal ' values vp must be inferred satisfying{ Pm } S|g{ Qm } p\\gg  or equivalently, \nPm =..pre[S|p\\g ]Qm . Again the strongest g p Qm is not computable and so will have to be over-approximated \nin the abstract by a relational reachability analysis [11]. Safety contract The pair of a method safety \npre-condition and post-condition yields a safety contract. De.nition 9. A method safety contract for \nthe method void m ( vp) { S|} is a pair (Pm ,Qm ).C[m] such gp\\g that { \u00ac.} S|alse } and { Pm } S|{ \nQm Pm { f .} . gp\\g gp\\g The intuition is that either the safety pre-condition Pm does not hold and \nthe method call is doomed to fail, so on exit of S (which never happens) Qm does hold. Otherwise the \nsafety pre-condition Pm does hold in which case the post-condition Qm describes the effect of the call, \nif it ever terminates. In the abstract, over-approximations are inferred by the static analysis. By Def. \n9, this abstract safety contract will always be valid but it may not be precise enough to ensure completeness \nor generality. For example, in absence of precise method safety contract, we can always choose (Pm , \ncc Qm ) \u00a3 true. Safety versus validity For contracts, validity and safety are two different concepts. \nAny safety contract is valid but some valid contracts may not be safe. For example x =1 } x=1/x { x =1 \n} is valid but not safe since{ x =1 } x=1/x { false } does not hold. However { x = 0 } x=1/x { x =0 } \nis safe hence valid. Callee/covariant partial order on contracts We de.ne the callee/covariant partial \norder on concrete contracts on precondition to get more on postcondition). The order =cc. will be used \nin Sec. 8 to de.ne the most general extracted method contracts. cc cc cccc The set (C[m], =cc., ., T, \n., .) of all contracts for a method m is a complete lattice for partial order =cc. where cc cc . \u00a3 (true, \nf .T \u00a3 (f .true) is .alse) is the in.mum, alse, . cc the supremum, the (in.nitary) join is \\ (Pi,Qi) \n\u00a3 ( y.Pi, i..i.. . cc \\ Qi). The de.nition of y is dual. i.. 7. Separate method veri.cation In order \nto formalize the problem of extract method with contracts, we need to reason about method calls. We now \nformalize what we mean by separate veri.cation of the correctness of the callee and the method caller. \nWe assume the simplifying hypotheses of Sec. 6 for the variables modi.ed by a method call. In general, \ne.g., to handle the heap or concurrency, more complex rules are needed to express the frame conditions. \nThe problem is orthogonal to this paper, and so we assume sequential programs with only scalar variables. \nLet m(vp){ S } be a method de.nition with contract (P, Q)and let m(vq) be a method call where the actual \nparameters vq are variables such that v V[vq] = Vv[vp]. We de.ne the separate method call proof rule. \nFirst, the contract (P, Q) of m should be valid, i.e., { P } S|{ Q }. gp\\g ' Second, the call precondition \nP should imply the method precondition P when projecting away the unmodi.ed global variables: ..vg : \nP ' =..P. If the two conditions hold then the caller can assume the postcondition Q: .' { P } S|{ Q }, \n.vg : P =..P gp\\g ' } m(vq) { . ((vg), (v q,vq,v (P, Q) . =.(P \u00d7 ' . Q . Q ' ' ,Q ' ) \u00a3 P =..P =. The \nintuition is that stronger is better for the callee (assuming . ') } . g are unaffected by the call, \nthe (8) ' ,vg ')) . Q(vq q more on the precondition to guarantee more on the postcon\u00ad { P As the global \nvalues v dition). The order .\u00d7 =. will be used in Sec. 8 to de.ne the information available on them before \nthe call is still valid safety of the extracted method contract. The set of concrete after the call: \n(9) {P }S|g{Q } p\\gg \u00d7\u00d7\u00d7\u00d7 \u00d7 contracts for method m is the complete lattice ..... =., {P } S { . (p p,p \n } . g), (p ',pp,pp,pg ')) . pg ' g ') . P (pg) . Q((pg), (p ',p= pg (C[m], . is the in.mum, . is the \nglb for the partial order ., T, ., .) The two rules (8) and (9) can be combined via the con\u00ad junction \nrule (.) to provide the concrete separate method call .\u00d7 \u00d7 \u00d7 .. T is the supremum, . is the lub, where \n\u00d7 . \u00d7 =. and proof rule. . on the set C[m]. Caller/contravariant partial order on contracts We de.ne \ncc the contract caller/contravariant partial order =. on C[m]as cc ' (P, Q) =.(P ' ,Q ' ) \u00a3 (P =.(7) \n. P ) . '' ,v'(v,v. Q ') . (. pvp . Pp ') . Q(pvp) =. The intuition behind this order is that a =cc.-stronger \ncontract is more general and a =cc.-weaker contract is more speci.c, cc since if (P, Q) =.(P ' ,Q ' ) \nand { P } S { Q } hold then { P ' }S { Q ' } does hold. Concretely it means that from the caller point \nof view all proofs done with the contract ' (P,Q ' ) can also be done with (P, Q). This intuition is \ntherefore that stronger is better for the caller (assuming less 8. Extract Method with Contracts We devise \na two-step algorithm for the extract method with contracts. The classical syntactic extract method is \n.rst ap\u00adplied to the user selection. If it succeeds (e.g., a syntactically correct program is generated), \nwe apply our algorithm EMC in Alg. 5 to infer good contracts for the new method. In order to formalize \n(and solve!) the problem both in the concrete and in the abstract, we need .rst to make explicit the \nassumptions on the underlying syntactic refactoring engine and on the analysis. These assumptions are \nformulated in the concrete but should also hold in the abstract, up to concretization, as considered \nin Sec. 12.  Assumptions When the end-user selects a piece of code S, the refactoring engine produces \na new program with the refactored code only if this is a syntactically valid program. Otherwise stated, \nwe rule out syntactically ill-formed pro\u00adgrams. We only consider in-out parameters and procedures for \nsimplicity, but we handle the general case in our imple\u00admentation. The new method appears in the same \nclass of the selected code. The method is marked as private so there is no need to ensure that the class \ninvariant is preserved4. We assume the extracted method to be in the form of: private void m(vp) { Contract.Ensures( \n.x . p : Contract.OldValue(x) == x)); S| gp\\g } . We explicitly record in the contract which variables \nare nei\u00adther read nor written by the method (otherwise the assumption remains implicit, or guaranteed \nby the semantics of the lan\u00adguage, e.g., for parameters of struct type). At the call site, the selected \ncode S|is refactored into a gp\\g method call m(vp), where vp is the vector of actual parameters. We \nassume that a pre-invariant PS .P[(vp,vg)] and a post\u00adinvariant QS .P[(vp,vg), (vp,vg)] are available \nfor the selected code S such that { PS } S { QS }. The pre-(post-)invariants can be derived by projecting \nthe abstract state of the analyzer in the program point just before (after) S (formally followed by a \nconcretization when reasoning in the concrete). Other\u00ad cc wise, it is always possible to use true. These \nassumptions can be summarized as {PS } S|{ QS } . gp\\g The projection of (PS ,QS ) for S on the read/written \nvariables vp is (P /,Q/). It satis.es the following conditions: SS ' ') ' '' '''), (v'')) . PS/(pv\u00a3 .vg \n.Vv[vg] : PS (pv,vg) and QS/(pv,vp) \u00a3 .vg .Vv[vg] : QS ((vp ,vg p,vg (10) From what said above and (10), \nit immediately follows that the following triples are valid, stating that the extracted method does not \nmodify the globals and that the projected pre-and post-invariants are still valid contracts: ' . (vg) \n. true } m(vpg p,vg = v' } and p,vp) {. (v,v'), (vg) . vg{ P /} S|{ Q/} . S gp\\g S We assume that a safety \ncontract (Pm ,Qm ) (cf. Def. 9) for the extracted method m can be inferred by running an isolated analysis \nfor m (formally followed by a concretization when cc reasoning in the concrete). At worst, true is always \na safe choice. The problem of method extraction with contract (EMC) We want to generate a contract (PR,QR).C[m] \nfor the (new) extracted method m. The extracted method will then be 4 The situation is slightly different \nfor public methods, and orthogonal to our problem. analyzed separately (to prove its contract (PR,QR) \ncorrect) and the contract (PR,QR) will be used to derive the post\u00adinvariant QS from the pre-invariant \nPS in a forward analysis of the method call (and/or the pre-invariant PS from the post\u00adinvariant QS in \ncase of backward analysis). The contract (PR,QR) for extracted method m must guarantee that the proof/analysis \nthat succeeded before the refactoring still succeeds after the refactoring. Differently stated, the problem \nis to .nd an appropriate refactored contract (PR,QR) with pre-condition PR and post-condition QR of the \nform (6). We put the following requirements on this refactored contract (PR,QR): (s) validity Assuming \nthe refactored contract pre-con\u00addition, the post-condition must hold. Formally: { PR } S|{ QR } . gp\\g \n (b) safety The refactored contract (PR,QR) is stronger than the method safety contract (Pm ,Qm ): . \n(PR,QR) =\u00d7.(Pm ,Qm ) . The refactored contract requires more (so that PR implies Pm which ensures the \nabsence of runtime errors when executing the extracted method) and ensures more (so QR implies Qm and \nso takes at least into account on method exit what can be learned from the method precondition Pm followed \nby the execution of the method body). (c) completeness The refactored code is still prov\u00adable with the \nsame precision as the original code. The triple{PS } m(vp) {QS } is provable by the separate method call \nproof rule (8) using the extracted method contract (PR,QR). (d) generality The refactored contract (PR,QR) \nis the most general possible: the pre-condition of the refactored contract (PR,QR) is the weakest possible \n(so that the extracted method applicability is as general as possible) and its post-condition is the \nstrongest possible (so that calls to the extracted method get as much information as possible on its \neffect). However we do not consider type generalization [42], which is a separate problem.  Independent \nrequirements The validity, safety, complete\u00adness and generality requirements are all mutually independent. \nFor example, { false } S { true } is always safe, invalid for reachable code, validity for unreachable \ncode but (in general) incomplete and not general. Consequences We report some consequences of our re\u00adquirements \nand de.nitions. From the requirement (a) validity and (8) it follows that the (opportunely instantiated) \nrefactored contract is valid at the call site: ' { . (vq ,vg ') . PR(vq ') }m(vq) (11) '' { . ((vq ,vg \n'), (q,vvg)) . QR(vq ,vq) . vg = vg ' } After refactoring, { PS } m(vq) { QS } can be proved using (11) \nif and only if  '' .pv,vg : PS (pv,vg)=. PR(pv') (12) '' ' .vpp,vpp)=. QS ((v,vp,v ,vg : QR(v,vpg), \n(vg)) . The conditions in (12) can be strengthened to take run-time errors into account. Although mathematically \nuseless, this is useful to minimize the loss of information in abstract in\u00adterpretation. Therefore, after \nrefactoring, { PS } m(vq) { QS }can be proved if and only if '' .vp ,vg : (PS (pv,vg) . Pm (pv')) =. \nPR(vp ') (13) '' ' .vp ,vp,vg : (PS (vp ,vg) . Pm (vp ') . QR(pv,vp)) =. (14) ' QS ((pvg), (vg)) . ,vp,vPlease \nnote that if the method pre-condition Pm does not hold, then the selected code S would have de.nitely \nfailed on some language or programmer assertion while the refactored code will also de.nitely fail, but \nearlier, when calling method m. So it is possible that PS (vg) does hold and the execution p, v goes \non (until de.nitely failing later somewhere within S) whereas Pm does not hold on method call so that \nexecution just fails right on call. However, this changes nothing as far as the post-condition QS is \nconcerned. Finally, the most general contract refactoring requirement (d) generality can be equivalently \nrestated as ' if (P ,Q ' ) satis.es (a) validity, (b) safety, (15) RR cc ' and (c) completeness, then \n(PR,QR) =.(PR, Q ' ) . R 9. Exact method refactoring We show that the EMC problem has a unique solution, \nand we give two equivalent formulations of the solution. The .rst one is nicer from a mathematical point \nof view, but less suitable for abstraction. The second one involves a combination of backwards and forwards \niterations, and it will be the base for our static analysis. Concrete solution of EMC We devise a solution \nto EMC as follows. The precondition PR for the method is the safety precondition Pm all the internal \nsafety checks are made explicit to the caller. The postcondition is the strongest postcondition from \nPm . Theorem 10 (Exact contract refactoring). The unique con\u00adtract satisfying (a) validity, (b) safety, \n(c) completeness, and (d) generality is: (PR,QR) \u00a3 (Pm , post [S|gp\\g ]Pm ). (16) In an ideal world (e.g., \n.nite and small enough) where everything is exactly computable, EMC is very simple: com\u00adpute the safety \nprecondition and then propagate it forwards to get the postcondition (as in model checking). In practice \npost [S|gp\\g ]Pm is not effectively computable the set of states is in.nite or extremely large. Therefore \nan approximation is needed all the fully automatic static analysis methods for in.nite state systems \nare necessarily ap\u00adproximate. An abstract version of Th. 10 is essentially useless: static analyses compute \nan over-approximation of post and this over-approximation may easily cause the requirement (c) completeness \nnot to be satis.ed. We propose a solution to EMC nicer to abstract than (16). First we need to recall \nsome facts on greatest .xpoints. Greatest .xpoints We write gfp.f for the g-greatest .x\u00ad a point of f \n. L . L g-less than or equal to a . L, if any (e.g., (L, g) is a dual cpo, f is increasing and a . L \nis a post-.xpoint of f, i.e., f(a) g a). Otherwise, gfp.f is the a limit, if any, of the iterates of \n. x . x f f(x) from a (which yield the same de.nition with the previous hypotheses), see [14]. Iterated \nsolution of EMC We propose a solution to EMC based on the combination of a forward and a backward analy\u00adsis, \ninspired by [8]. The idea is to compensate for the loss of information in the abstract by an iterated \nforward/backward analysis. Starting with the projection of the pre-and post\u00adconditions (P /,Q/) at the \noriginal call site on the relevant SS variables, the contract is iteratively generalized by succes\u00adsive \nforward .xpoint propagations strengthening the postcon\u00addition and backwards .xpoint propagations weakening \nthe precondition. The iteration of these .xpoint computations ultimately stabilize, in general after \nin.nitely many decreas\u00ading iterations in the concrete, which we express as a greatest .xpoint (which \nis therefore a .xpoint of .xpoints). The method contract transformer FR[S] .C[m] .C[m]re.nes the safety \ncontract (Pm ,Qm ) with the precondition and postcondition transformers: (16) FR[S]((X, Y )) \u00a3 (Pm ..pre[S|p\\g \n]Y, Qm ..post[S| pggp\\g ]X). Observe that pre[S|and post[S|p\\g ]X both involve pgp\\g ]Y g .xpoint computations \n[11, 13]. The .xpoint of the descending iterations of FR from (P /, S Q/) is the solution to EMC: S Theorem \n11 (Iterated contract refactoring). Under the as\u00adsumptions of this paper, cc =. (Pm , post [S|gp\\g ]Pm \n) = gfp.,Q/FR[S] (17)PS/S ) and, by Th. 10, is the unique solution to (a) validity, (b) safety, (c) completeness, \nand (d) generality. The .xpoint formulation of the solution to EMC, (17), is the concrete solution to \nour problem. As stated earlier, in the general case, the computation is unfeasible and we need to perform \nsome approximation. Next we provide abstract counterparts to the separate method analysis rules of Sec. \n7 and the formulation in the abstract of EMC. 10. Abstract Contracts Abstract domain primitives In addition \nto the requirements of Sec. 5, we assume the precondition abstract domain A and the postcondition abstract \ndomain B to de.ne: (i) a predicate for the unchanged variables; (ii) an embedding from A to B; (iii) \na variable projection; and, (iv) a variable anti-projection. Please note that those assumptions are in \nno measure restrictive, we just make them explicit all static analyzers implement those primitives, \ne.g., the projection to remove variables when they go out of scope.  The predicate [\u00b7] denotes the unmodi.ed \nvariables. Given a set of variables vg . v , then [vg] . B[v ,v ] is the abstract statement that none \nof the values of the variables vg has changed, that is ' .2( [vg]) \u00a3 .v ,v . .x . vg : v '(x)= v (x). \nThe embedding .2 . A[v ] . B[v ,v ] embeds unary 1 predicates into binary predicates. It respects the \nsoundness condition: '' ,v . v(P ))(v ,v )= .1(P )(v ') . .P . A[v ] : .v V[v ] : .2(.21 ' 1 We assume \nthat the embedding is increasing, i.e., if P g P ' 2 then .2(P ) g.2(P ). 11 The abstract projection \n.gp\\g projects onto the parameters and global variables. It satis.es the following soundness criteria: \n(P . A[vp,vg] and Q . B[(vp,vg), (vp,vg)]) 1 P g.(P ) gp\\g (..vg : .1(P )vp,vg) = .1(.(P )) gp\\g (..vg \n: .2(Q)) =. .2(. .gp\\g (Q)) .p\\g is increasing . g Global variables can be reintroduced by the abstract \nan\u00adtiprojection .. B[vp,vp] . B[(vp,vg), (vp,vg)]. It satis.es gp\\g the soundness requirement: (Q . \nB[vq,vq]) ' '' ,v'), (vg)) . .2(Q)(v,vg = v.(... ((vqg q,vqq) . vg =. .2(Q)) gp\\g In the following, \nwe leave variable renaming implicit, identifying A[vp] and A[vq] whenever Vv[vq] = Vv[vp]. Abstract contracts \nIn analogy to what was done in Sec. 6 for the concrete contracts, we de.ne abstract contracts and a covariant \nand contravariant order on those. An abstract contract is an element of A[vp] \u00d7 B[vp,vp]. The callee/covariant \npartial order on abstract contracts is de.ned as '' '' . \u00d712 (P, Q)g(P,Q ) \u00a3 P g P . Q g Q. The meaning \nis given by the concretization function .\u00d7 . (A[vp] \u00d7 B[vp], .. p,v\u00d7=\u00d7 g) . (C[m], .) de.ned as .\u00d7((P, \nQ)) \u00a3 (.1(P ),.2(Q)). The caller/contravariant partial order on abstract contracts is de.ned as cc ''' \n'' 12 2 (P, Q)g(P,Q ) \u00a3 P g P ..2(P ) f Q g Q. 1 The meaning is given by the concretization function \n.. cc cc cc (A[vp] \u00d7 B[vp,vp], g) . (C[m], =.) de.ned as .((P, Q)) \u00a3 (.1(P ),.2(Q)) . (18) cc It is easy \nto observe that .is increasing. However, if .2 cc is increasing but not meet-preserving then the property \nthat an abstract contract is more precise than another one may not be preserved in the concrete, as shown \nby the following counter-example. 2 We have P ' g1P ..21(P ') f2Q g Q ' and so (P, cc cccc cc ' Q)g(P, \nQ ' ) but not .((P, Q))=. .((P ' ,Q ' )) since .2(.12(P . .2(Q) =. ')) .. .2(Q '). So even if in the \nabstract the contract (P, Q) is more precise that the contract ' (P,Q), this is not true in the concrete. \nSo in this case, improving the precision of a contract in the abstract does not guarantee that the concretization \nalso improves. We now have two reasons for assuming .2 to be .nite\u00admeet-preserving. One is to ensure \nthe soundness of the abstract conjunction rule (.), i.e., the reduced product (Th. 6) and the other to \npreserve the precision relation between abstract contracts in the concrete. 11. Abstract separate method \nanalysis We are now ready to formalize the rule in the abstract Hoare logic to handle the method call. \nWe abstract the corresponding rules for method call of Sec. 7. We obtain the abstract separate method \ncall analysis rule by replacing the concrete Hoare triples, implications, projection etc. of (8) with \ntheir abstract counterparts de.ned ' above: (P . A[vp,vg], P . A[vp], and Q . B[vp,vp]): ' \u00af' \u00af\u00af\u00af { P \n} S|{Q }, .(P ) g1P gp\\g gp\\g . (19) \u00af\u00af { P } m(vq) {\u00af.(Q) }\u00af gp\\g The abstract version of (9) propagates \nthe properties of the unmodi.ed variables vg through the call. \u00af\u00af\u00af\u00af { P }S|{ Q } gp\\g (20) 22 {\u00afP }\u00afS|gp\\g \n{\u00af.12(P ) f Q f [vg] }\u00af. Theorem 13 (Soundness of the abstract separate method call analysis rule). Abstract \nrules (19) and (20) are sound in the sense of (4). 12. Extract Method with Abstract Contracts We de.ne \nthe problem of the Approximate Extract Method with Contracts EMC, by providing the abstract counterparts \nfor the de.nitions and requirements of Sec. 8. We prove that the EMC implies EMC, but that the converse \ndoes not hold.  Assumptions The assumptions on code and invariant selec\u00adtion are similar to the concrete \nones in Sec. 8, but now relative to abstract predicates. We assume the variable decomposition is v = \nvp,vg and \u00af\u00af\u00af\u00af { P S } S|{ QS } so that the analysis of the selected code gp\\g is sound. Those hypotheses \nessentially ensure the correctness of the code to be extracted. The next two hypotheses are completeness \nhypotheses requiring the abstraction to be expressive enough. We assume that the post-condition of the \nselected code 212[vg]).is strong enough in that QS g (.2(P S ) f This implies that the information known \non the initial values of the parameters and the fact that variables vg are unchanged is '' not lost, \nthat is for all pv,vg ,vp,vg, '' .2(QS )((pv,vg '), (vg)) =. p ,vg ') (21) p,v.1(P S )(v '' .2(QS )((pv,vg \n'), (p,vvg)) =. (vg = vg) . Furthermore, we assume that the analysis of the selected code is independent \nof the unread/unwritten variables, viz. (.(.g(.2 [vg])) [vg]) 2 gp\\g p\\g 1(P S ) f2QS f2f2g QS (22) The \nfollowing contrived example shows why we need this hypothesis. Even if the selected code S does not depend \nupon the variables vg the analysis of this code might nevertheless depend upon these neither used nor \nmodi.ed variables vg. Example 14. Let us consider the following syntactic refac\u00adtoring: ... ... { g in \n[11, 11] } . { g in [11, 11] } p = 0; NewMethod(p); while(p<10) {pin[10, 11]} p=p+1; ... { p in [10, \n11] } private static void NewMethod (int p) { { Pr(p ) = true } p = 0; while (p < 10) p = p + 1; { Qr(p \n, p) = p in [10, +oo] } } We assume that the static analysis is an interval analysis with a widening \nusing thresholds. The thresholds are assumed to be obtained by looking at all visible variables with \na constant interval. So the analysis of the selected code uses the threshold 11 from the value of g while \nthe analysis of the extracted method has no threshold at all so widen to +8. Then the method post-condition \nis too weak to prove the selected code post-invariant. Of course the constants of the program (e.g., \n10) could also be used as thresholds or a narrowing could improve the result but we assume that this \nis not the case in this contrived example. Finally, we assume that the abstract safety contract for the \nextracted method: \u00af\u00af (P m |,Qm |) is such that {\u00afP m } S {\u00afQm }. gp gp,gp The safety precondition P m \nis .rst obtained by a backward analysis of the method body S [18] and then Qis derived m form P m by \na forward reachability analysis of S [11]. Method extraction with abstract contracts, EMC We pro\u00advide \nabstract counterparts for the requirements of EMC of Sec. 8. We call the problem EMC. (a) validity The \nabstract refactored contract (P R, QR) is valid: assuming the refactored abstract contract pre\u00adcondition, \nthe post-condition must hold: \u00af\u00af\u00af\u00af { P R }S|{ QR } . gp\\g (b) safety The abstract refactored contract \n(P R,QR)is stronger than the abstract method safety contract (P m , Q): P m is a necessary but possibly \nnot suf.cient condition m for the absence of run-time error when the method is called [18]. Qover-approximates \nthe post-condition resulting from m the execution of the method body assuming P m on entry. The abstract \nrefactored contract requires more, so that P R implies P m which is necessary (but possibly not suf.cient) \nfor the absence of runtime errors when executing the extracted method. The abstract refactored contracts \nensures more, so QR implies Qm . It takes at least into account on method exit what can be learned in \nthe abstract from the method pre\u00adcondition P m followed by the execution of the method body, which can \nbe summarized by: (P R,QR) .m ,Q \u00d7 g(P ) . (23) m (c) completeness The refactored code is still prov\u00adable \nin the abstract with the same precision as the original \u00af\u00af code: {\u00afP S } m(vp) {\u00afQS } is provable by \nthe abstract sepa\u00adrate method call analysis rule of Th. 13 using the extracted method abstract contract \n(P R,QR). (d) generality Optionally, the abstract refactored con\u00adtract (P R,QR) is the most general: \nThe pre-condition of the refactored contract (P R,QR) is the weakest possible (so that the extracted \nmethod applicability is as general as possible) and its post-condition is the strongest possible (so \nthat calls to the extracted method get as much information as possible on its effect) for the considered \nabstract domains. It can be '' shown that if (P R,QR) satis.es requirements (a) validity, cc ' (b) safety, \nand (c) completeness then (P R,QR)g(P R, ' QR). Theorem 15 (Correctness of the abstract requirements). \nThe abstract requirements (a) validity, (b) safety, and (c) completeness respectively imply the concrete \nrequire\u00adments (a) validity, (b) safety, and (c) completeness for the concretization of the abstract \npredicates. Therefore, by Th. 13, method extraction with abstract contracts is sound. Notice that Th. \n15 does not state that abstract complete\u00adness implies concrete completeness for any concrete contract. \nIt states that abstract completeness implies concrete com\u00adpleteness for the concretization of abstract \ncontracts. So it should be understood as meaning that properties of abstract contracts hold in the concrete \nup to their concretization. The intuition is that the separate method call analysis rule is more powerful \nin the concrete than in the abstract. Of course, some concrete contracts are not the concretization of \nany abstract contract and Th. 15 states nothing on these contracts. Th. 10 and 11 are stronger than Th. \n15 since Th. 15 is only valid in the concrete for concrete contracts expressible in the abstract without \nany loss of information while Th. 10 and 11 hold for any concrete contract.  Impossibility of complete \nabstract refactoring Approxi\u00admations introduce new dif.culties. In practice, the abstract requirement \n(c) completeness can only be optional the concretization of the best abstract refactored contract, if \nany, might not be the best concrete refactored contract considered in (c) completeness. The following \ncounter-example proves that abstract refactoring is necessarily incomplete. Example 16 (Impossibility \nof complete abstract refactoring, I). Consider the following refactoring ... { Ps(p, g) = (g == 0) } \nwhile (1) p = 0; { Qs(p, g, p , g ) = (g == g == 7) } ... { Ps(p, g) = (g == 0) } NewMethod(p); { Qs(p, \ng, p , g ) = (g == g+1 == 7) } ... private static void NewMethod (int p) { { Pr(p) = true } while (1) \np = 0; { Qr(p, p ) = (p == p-2 == 17) } } The loop does not terminate so the exit invariant is false \n'' which is over-approximated by QS (p,g,p ,g ') \u00a3 (g = g = ' 7) in the original code and by QR(p, p \n') \u00a3 (p = p - 2= 17) in the extracted method. QS and QR are a perfectly correct partial-correctness invariants/post-conditions \nsince false...QS alse =. =and f .. QR. However, assuming ' PS (p, g) \u00a3 (g = 0) and QR(p, p ') \u00a3 (p = \np - 2 = 17), and ignoring the method body, it is impossible to prove that '' QS (p,g,p ,g ') \u00a3 (g = g \n= 7) does hold. This proves that abstract refactoring is necessarily incomplete (since termination is \nundecidable). Please note that this is not in contradiction with the fact that there is no problem (except \nincomputability) with exact refactoring, since the method body exact post-condition QR shall be f . alse. \nExample 17 (Impossibility of complete abstract refactoring, II). Consider the following situation where \nthe selected code S does not read or modify g. ... { Ps(p, g) = (g == 10) } while (1) do { p = p }; { \nQs(p, g, p , g ) = ( g == g == 1 ) } ... { Ps(p, g) = (g == 10) } NewMethod(p); { Qs(p, g, p , g ) = \n( g == g == 1 ) } ... private static void NewMethod (int p) { { Pr(p) = true } while (1) do { p = p }; \n{ Qr(p, p ) = true } } The separate analysis of the extracted method cannot prove ' the post-condition \nQS despite the fact that QR(p ,p)=. '' ' .g, g : QS ((p, g), (p ,g ')) (choose g = g =1). The prob\u00adlem \ncomes from the fact that false, which is the strongest post-condition for the selected code, was over-approximated \n'' by QS (p,g,p ,g ') \u00a3 (g = g = 1) and by QR(p, p ') \u00a3 ' true after the body of the refactored procedure. \nSince g is not available in the procedure body, it is impossible to make the same over-approximation \nof false in the method body as it was done in the selected code. The counter-example is based on the \nfact that, in case of non-termination, since QS can state properties of g which are completely different \nform those stated by PS although g is not modi.ed by the loop body. This situation can hardly happen \nin practice since abstract transformers and widening/\u00adnarrowing will leave g abstract properties unchanged \nsince the selected code neither reads nor writes g. Examples 16 and 17 are based on non-termination, \nin which case false can be approximated differently in the selected and refactored code. 13. Approximate \niterated method refactoring We want a static analysis to effectively solve EMC. The main idea is to abstract \nthe iterated exact refactoring of Th. 11. We see under which hypotheses the computed solution is the \nbest one and how we can derive an approximated solution. Initial state When the user selects a piece \nof code S, the underlying static analyzer extracts a pair (P S ,QS ) containing the pre-state and the \npost-state for S. The pre-state (resp. the post-state) is the semantic information known to the analyzer \nat the program point just before (resp. after) the selected code: PS \u00a3 .1(P S ) and QS \u00a3 .2(QS ). (24) \nThe pre-state and the post-state are projected onto the parameters of the extracted method: P /\u00a3 .(P \nS ) and Q/\u00a3 .(QS ) (25) S gp\\g S gp\\g The initial abstract state for the (greatest) .xpoint compu\u00adtation \nsoundly approximates the initial concrete state: Lemma 18. Equations (25) and (24) imply that (P /,Q/) \nSS cc =. .S ,Q/ ((P /)). The underlying static analyzer may infer an approximated safety condition P \nm , in which case we let Pm \u00a3 .1(P m ). Otherwise we assume Pm to be the strongest safety precondi\u00adtion. \nIn both cases Qm = post [SIgp ]Pm is the corresponding strongest relational post-condition. Abstract \ntransformer An abstract contract transformer F R[S] has to be designed that soundly overapproximates \nthe concrete contract transformer (16). The speci.cation of F R[S] is therefore: FR[S] . .cc. F R[S] \ncc S cc =...(26) cc In practice this means that we have, for a program statement S, either a forward \nstatic analysis, or a backwards static analysis, or, preferably, both of them. Knowing the concrete transformer \nFR[S] de.ned by structural induction on S, the design of an abstract transformer F R[S] is classical \nin abstract interpretation [11].  Best iterated solution The iterations of F R[S] provide a sound appoximation \nof the concrete .xpoint: Theorem 19. Equations (25) and (26) imply that cc =. FR[S] cc(F R[S]) gfp cc \n,Q/) =. .gfp . cc PS/S P /,Q/)SS In general F R[S] may be any over-approximation of FR[S]. Therefore \nit may not ensure that . \u00d7 gfp cc P /,Q/) F R[S] g (T.,Qm ), SS i.e., it does not satisfy the abstract \nrequirement (b) safety. In order to guarantee that the limit of the iterations of the abstract transformer \nis a correct solution to EMC we need the additional requirement: . \u00d7 .(X, Y ) : F R[S]((X, Y )) g (T.,Q) \n(27) m This requirement can always be met by re.ning a given abstract transformer F R such that the postcondition \nis no weaker than Qm : . \u00d7 . (X, Y ) .F R[S]((X, Y )) f (T.,Q). (28) m With the extra requirement (27), \nthe iterative application of F R from (P /S ,Q/) provides a correct solution to EMC: S Theorem 20. Let \nF R be an abstract transformer satisfy\u00ading (25), (26) and (27). Then cc (P R,QR) \u00a3 gfp (29) P /,Q/) F \nR[S] SS satis.es the abstract requirements (a) validity, (b) safety, and (c) completeness. cc Equation \n(29) ensures that (P R,QR)g(P /S ,Q/), i.e., S the result of the .xpoint computation is a more precise \ncontract than the trivial solution consisting of projecting the pre-state and post-state of the selected \ncode. Most general abstract contract refactoring In general the abstract refactoring (P R,QR) in Th. \n20 is not the most pre\u00adcise abstract contract refactoring the abstract requirement (d) generality does \nnot hold in general. There are three pos\u00ad sible reasons for that. First, there is no most precise abstraction \nof the concrete cc solution of Th. 10 or 11 for g in Def. (18) of .a case cc illustrated in Fig. 4. This \ncan be remedied, e.g., by requiring: (i) .to be the upper-adjoint of a Galois connection cc equivalently \n.is a complete meet morphism; and (ii) the cc a is to be surjective equivalently .is injective to cc \navoid a redundant representation in the abstract of the same concrete property: .1 ---- 1 (P[v ], =.).-.---. \n(A[v ], g) a1 .2 ---- 2 (P[v ,v ], =.).-g).---. (B[v ,v ], a2 Figure 4. Absence of most precise abstraction \nof the con\u00adcrete contract. Second, the abstract transformer F R[S] satisfying (26) might not be the most \nprecise one. This situation can be avoided by requiring the abstract transformer F R[S] to be the most \nprecise abstract transformer, in which case (26) must be strengthened into: = .(30) cc cc FR[S] . .. \nF R[S] Third, the abstract projection (P /S ,Q/) (cf. (25)) might S be too approximated. This can be \nexcluded by requiring the abstract projection .gp\\g to be the most precise possible. Theorem 21 (Most \nprecise abstract contract refactoring). Un\u00adder the hypotheses of Th. 20 and of this subsection (includ\u00ad \ning (30)), (P R,QR) also satis.es the abstract requirement (d) generality. The best abstract transformer \ncondition of (30) is rarely met in practice. A consequence is that the abstract require\u00adment (d) generality \nis mostly of theoretical interest. How\u00ad ever, experience in Sec. 14 shows that abstract completeness \nis achieved in many cases. Iterated Solution with Convergence Accelerators The un\u00adderlying abstract domains \nA, B may not satisfy the Ascend\u00ading/Descending chain conditions. As a consequence a narrow\u00ading operator \n[11] should be used to enforce the convergence of the greatest .xpoint computation of (29) to an (over-) \nap\u00adproximate solution (P R,QR). The greatest .xpoint iteration with narrowing ensures that cc cc (P R,QR)g(P \nR,QR) S ,Q/) . (31) g(P / S We need to prove that (P R,QR) is effectively a solution of EMC, and therefore \nit can be used in practice. This is guaranteed by the following theorem: Theorem 22 (Correctness of the \napproximate abstract con\u00adtract refactoring). In addition to the hypotheses of Th. 20, let (P R,QR) be \nsatisfying (31) and QR g Q. Then 2 m (P R,QR) satis.es the abstract requirements (a) validity and (b) \nsafety.  /* P S : pre-state, S:refactored code, vp: variables potentially used in S, vg: variables de.nitely \nunmodi.ed by S, QS :post\u00ad \u00af\u00af\u00af\u00af state such that {P S } S|{ QS } holds. */ gp\\g RefactorContract(P S \n, S, vp, vg, QS ) { 1 use (Avp], f, .1) // precondition abstract domain p,vf, .2) // postcondition abstract \ndomain post // forward analyser with widening/narrowing pre // backward analyser with widening/narrowing \n(B[ vp], 2 p // abstract projection on potentially used variables vp (P /S ,Q/) = (.(P S ), .(QS )); \nS gp\\g gp\\g // infer a correct safety abstract contract Let P m be the abstract safety pre-condition \nfor S computed by the static analysis [18]; Q= post[SIgp ]P m ; // forward abstract static analysis m \n\u00af\u00af\u00af // {\u00afP m }S|{ Q} holds m gp\\g (P R,QR) = (P /S ,Q/); S do // compute (X, Y ) = F R[S]((P R,QR)) \nX = P m f P R f pre[SIp ]QR; // backward analysis 11 g p 22 Y = Qf post[SIp ]P R; // forward analysis \nm f QRg(P R,QR) = (P R .1 X, QR .2 Y ); // narrowing while (P R,QR) = (X, Y ); cc cc cc // gfp P /,Q/F \nR[S] g(P R,QR) S ,Q/S g(P /) holds ) SS return (P R,QR); // (a) validity &#38; (b) safety hold } Algorithm \n5. Algorithm EMC (Extract Methods with Ab\u00adstract Contracts) computing an approximation of a greatest \n.xpoint with convergence acceleration. Th. 22 states that all the abstract contracts included between \nthe best solution (29) and the abstract projections of the abstract states are a solution of our problem. \nA natural way to compute (P R,QR) is to perform the downwards iterates of F R[S] from (P /S ,Q/) with \nnarrowing. The algorithm EMC S is given in Alg. 5. An optimization using chaotic iterations with memory \n[8] would have Y = Qm f QR f post[SIgp ]X; // forward analysis 22 This is the solution we implemented, \nwith more details given in the next section. 14. Experience The underlying tools We implemented the algorithms \nof the previous section on top of two industrial-strength tools, Roslyn and CCCheck. Roslyn exposes the \n(C# and VB) compiler internals (syntax trees, object model, data-.ow analyses, refactoring, etc.) to \nexternal developers, so that they can develp new plugins (code analyses, refactorings) on top of it. \nCCCheck is a static contract veri.er for CodeContracts. It analyzes each method in isolation, assuming \nthe precondi\u00adtion and asserting the postcondition. CCCheck can also do backward analyses to infer a precondition \nfrom the postcon\u00addition. CCCheck is based on abstract interpretation and hence has more advanced inference \ncapabilities than similar tools. For instance, it infers loop invariants and it suggests method preconditions \nand postconditions (the (P m ,Q) in this pa\u00ad m per). CCCheck contains several abstract domains for the \nheap, non-nullness, numerical properties, array contents, enums, but also to track (simple) existential \nand quanti.ed proper\u00adties [20]. Most of these abstract domains use widenings so completeness cannot be \nguaranteed in the theoretical sense for tortuous counter-examples and the contracts cannot tech\u00adnically \nbe the most general. The benchmarks ran with the default settings show that the inferred contracts can \nhardly be improved manually for the abstraction used by the static analyzer. The implementation We preferred \nnot to implement our\u00adselves the syntactic extract method from scratch. We used Roslyn, which takes care \nof both the user interface (e.g., code selection, right click, previews, etc.) and the basic refac\u00adtorings. \nFurthermore, we did not want to try our examples on toy implementations or abstract domains, hence we \n(mod\u00adi.ed and) used CCCheck to implement the EMC algorithm. CCCheck runs as a background service in Roslyn. \nWhile Roslyn provides syntactic, source-level, ASTs, CCCheck an\u00adalyzes bytecode. Therefore there is some \n(non-trivial) glue code connecting the two. The extract method with contracts is implemented as a Visual \nStudio extension for C#. When the user selects a piece of code S, Roslyn in the background (and concurrently), \ninvokes the extension asking it to provide a refactoring, if any. Our extension .rst forwards the call \nto the refactoring engine of Roslyn. If no method is extracted from the selection (e.g., not all the \nbranches of S are terminated by a return statement), the extraction fails, and we stop there. If the \nextraction succeeds, then we generate a contract for the new method. The .rst step of the algorithm EMC \nis to deduce (P /S ,Q/), S the starting point for the greatest .xpoint computation. In the\u00adory, this \ninformation can be obtained by fetching the program points corresponding to the user selection, and then \nasking CCCheck for the corresponding invariants and Roslyn for S|. Unfortunately there are some practical \nissues that com\u00ad gp\\g plicate the theoretical schema. First, CCCheck does not keep an explicit map from \nsource locations to bytecode offsets, but only the inverse map, used to report warnings and sugges\u00adtions. \nSecond, for memory consumption reasons, CCCheck throws away the inferred invariants once it is done with \nthe analysis of a method. So at the time the refactoring is invoked, that information is already gone. \nThird, because of the heap analysis, the mapping between source level variables and internal variables \nused by the abstract domains in CCCheck is pretty complex (e.g., the same syntactic variable may have \ndifferent internal names at different program points). Luckily, the refactoring engine of Roslyn indirectly \nprovides the par\u00adtition (vp,vg) and the information on modi.ed variables via the parameters. Roughly, \nthe actual parameters are the variables read/written in S, and the actual parameters passed by ref are \nthose that may be modi.ed in S and whose value may be used in the callers. Our solution is then to use \ntwo dummy method calls as markers for the precondition and the postcondition, inserted, respectively, \nat the beginning and at the end of the selection. The .rst marker, the precondition marker, is a fresh \nmethod call whose actual parameters are the variables in vp that can be modi.ed inside S. For the other \nvariables in vp, we have the guarantee that their value either does not change or does not affect the \nmethod on return (i.e., they are dead variables). The second marker, the postcondition marker, is a fresh \nmethod call whose actual parameters are as above plus an extra one denoting the return value.  Example \n23 (Markers). For the initial example in Sec. 2, the annotated code is: __PreconditionMarker(); while \n(x != 0) x--; __PostconditionMarker(x, true); The Boolean .ag indicates whether or not the next-to-last \nparameter is the variable the return value is assigned to (refactoring may generate void methods, in \nwhich case the .ag is false). When the Boolean .ag is set, then all the occurrences of the next-to-last \nvariable in Q/are replaced S by Contract.Result, i.e., the return value of the method is made explicit \nin the postcondition. We then analyze the annotated method with a switch to trigger the generation of \n(P /S ,Q/): CCCheck analyzes the S method, collects at the marked points (P S ,QS ), and then uses the \nactual parameters to project them onto the variables of interest to emit (P /S ,Q/). S The second step \nof the algorithm, inserts (P S ,QS ) for the extracted method, and then runs CCCheck to infer (P m ,Q). \nm In the third step, we add (P m ,Q) (to enforce (27)) to m the extracted method and we iterate the forward/backwards \nschema until we reach a .xpoint, or we run out of stamina, in which case we return the current approximation \n this never happened in our experience, though. Finally, we instrument the extracted method with (P R \n, QR ), and we propose it as a refactoring to the user, e.g., Fig. 1. Benchmarks It is very hard, if \nnot impossible, to evaluate automatically the effect of the extract method, as it depends on user interaction. \nA random selection of S is not very meaningful either. It is very likely to generate ill-formed programs, \nand it may not be representative of the effective use. Furthermore, in order to evaluate our analysis, \nwe should .rst .x what we evaluate. Our goal is to have the extract method with contracts integrated \nin a continuous veri.cation (or semantic) IDE. As such, two metrics are relevant: (i) performance (the \nanalysis should happen in real time); and (ii) precision and generality of the results (no new warning \nshould be introduced, and the result should be as general as possible). We evaluated those two aspects \non some benchmarks (randomly) extracted from the CCCheck regression suite. The CCCheck regression test \nsuite contains many corner cases and small, yet tricky, bug repros reported by users in order to stress \nthe analyzer. We report the experimental results in Fig. 6. The .rst column is the name of the test. \nThe second column contains the time required for Roslyn to extract the method. The third column is the \ncost of step one (inference of (P /S ,Q/)) and S the fourth column is the combined cost of steps 2 and \n3 (inference of (P m ,Q) and (P R,QR)). The last column is m the total time taken by the extract with \ncontracts refactoring. Note that the total is slightly larger than the sum of the other three columns \nbecause it also includes the cost of annotating the syntax trees, context switching, etc., due to multithreading. \nThe tests are not very long per se, but rather complex, as can be noticed by the raw time spent by the \noptimized refactoring engine to perform the syntactic method extraction. In general, the cost of our \nanalysis is comparable with that of the extract method alone. In most of the cases, the total time remains \nwell below one second, meeting the .rst requirement (real time). The only real slow-down is in the Loop-2 \ntest, which is caused by the overhead of using exceptions as control .ow in the analysis for certain \ncorner cases. This idiom causes an extreme slowdown while running with the debugger attached, which was \nthe easiest way for us to record the timings. Without the debugger attached, the wall-clock time improved \ndramatically. In all of the tests we succeeded in extracting a contract which was both precise enough \nto not break the veri.cation of the caller and general enough to be used elsewhere. We were positively \nimpressed by the inferred invariants. For instance, for BeyerEtAl (Fig. 1 of [5]), we selected the body \nof the loop. The extract method with contracts was able to infer the right pre-and post-conditions (3*i \n= a + b), generalizing it for non-negative values of i, a, and b but also restraining i to be less than \n231 - 1 (otherwise an over.ow may occurr). In the PeronHalbwachs example computing the max of an array \n(Fig. 1(a) of [28]): int Max(int[] a) { Requires(a != null &#38;&#38; a.Length > 0); Ensures(ForAll(0, \na.Length, j => Result<int>() <= a[j])); Ensures(Exists(0, a.Length, j => Result<int>() == a[j])); var \nmax = a[0]; for(var i = 1; i < a.Length; i++) if(a[i] > max) max = a[i]; return max; } CCCheck infers \nthe loop invariant .j . [0, i).a[j] = max and .j . [0, i).a[j]= max, and uses it to prove the postcondition. \n Test Extraction Step 1 Steps 2/3 Total Decrement 0.18 0.10 0.12 0.42 Generalize 0.20 0.09 0.14 0.45 \nBinarySearch 0.23 0.14 0.32 0.70 Abs 0.23 0.07 0.12 0.43 Arithmetic 0.20 0.07 0.28 0.56 Rem 0.20 0.09 \n0.20 0.49 Guard 0.17 0.07 0.14 0.40 Loop 0.18 0.07 0.10 0.37 Exp 0.34 0.18 0.24 0.79 Main 0.20 0.14 0.20 \n0.56 Karr 0.35 0.09 0.14 0.71 Loop-2 0.28 0.18 1.99 2.43 Loop-3 0.21 0.10 0.14 0.46 SankaEtAl [40] 0.24 \n0.09 0.00 0.35 McMillan [33] 0.24 0.18 0.43 0.93 BeyerEtAl [5] 0.34 0.18 0.28 0.82 PeronHalbwachs [28] \n0.47 0.33 0.31 1.13 Figure 6. The experimental results (in seconds). The additional cost is of the same \norder of magnitude as the syntactic method extraction. The precision was good enough in all tests to \npreserve the veri.cation of the caller and generalize the precondition of the extracted method. In the \nbenchmark, we selected the body of the loop, and got the following contract: Requires(a != null &#38;&#38; \n0 <= i &#38;&#38; i < a.Length); Requires(Exists(0, a.Length, j => max == a[j])); Ensures(Exists(0, a.Length, \nj => Result<int>() == a[j])); Ensures(a[i] <= Result<int>()); Ensures(max <= Result<int>()); This is \nthe most general contract possible for CCCheck ab\u00adstract domains, which are not disjunctive. On entry, \nthe array a should be non-null, the index i should be in its bounds and max should be equal to some element \nin a. On exit, the returned value is an array element, larger than both max and a[i]. The precondition \nof the extracted method is proven in the refactored Max. The postcondition is used to infer the same \nloop invariant as in the original Max. Note that the correctness proof of Max does not need a stronger \ncontract with universally quanti.ed invariants. The analysis is smart enough to automatically deduce \nit. Otherwise, the postcon\u00addition ForAll(0, i, j => a[j] <= Result<int>()) would have generated the precondition \nForAll(0, i-1, j => a[j] <= max), a requirement that would be too strong on the caller, dramatically \nreducing the admissible calling contexts. 15. Related work Program source to source transformation and \nsupporting tools were very popular in the late 70 s and early 80 s ([32, 41], to cite a few). The research \nsubject went out of fashion probably because program transformation systems needed too large catalogues \nof transformation rules that were hard to master in batch mode by programmers and transfor\u00admation enabling \nconditions ensuring the correctness/incor\u00adrectness of program behavior preservation/re.nement were hard \nto prove (either manually or automatically) [1]. The sub\u00ad ject rose from the ashes through code refactoring \n[24, 34, 43], a computer-aided reorganization of the code preserving its be\u00adhavior (and hopefully improving \nits readability, modi.ability and maintainability). Program transformation and refactor\u00ading look very \nsimilar in particular since they share similar catalogues of transformations. However, the correctness \nof refactoring transformations (so-called semantic preserva\u00adtion ) is ultimately left on the shoulders \nof programmers, not on the refactoring tools, which is therefore never falling short nor faulty. Various \nformalizations of refactoring have been proposed in the concrete such as [3, 25, 31]. Refactoring can \nalso be for\u00ad malized as a special case of semantic program transformation [15]. [26] consider the problem \nof merging similar classes (but not method extraction). To the best of our knowledge, we are the .rst \nto address the refactoring problem in the general context of abstract semantics and abstract proof preserva\u00adtion, \nnot only types [42]. The problem of unsoundness of the conjunction rule in Hoare logic was already shown \nby John Reynolds in the context of concurrent Separation Logic [38]. However, the proposed solution was \ntied to the particular logic (enforcing the resources to be precise). We give a more general characterization, \nin terms of abstract Hoare Logic, and a general solution (Th. 6) to the problem. 16. Further Work Static \nanalysis might be used to help the end-user select the code to be extracted. She might be prompted to \nextend the code to include initializations, or exclude code irrelevant to the computed result. Static \nanalysis would also be useful to automatically check whether the extracted method preserves the class \ninvariant, in which case the end-user may be offered the wider choice of declaring the extracted method \neither as public or private. Alternatively, the class invariant may be weakened automatically for public \nmethods. A extracted method can also be placed outside the class of the refactored code if and only if \nit does not depend on the state of the objects of that class. Static analysis could also help in generalizing \nthe parame\u00adter types to the most general types that preserve the extracted method semantics. Of course \nsemantic smelling and cloning would then be useful to help identify clones of the method body in the \ncode that could be replaced by procedure calls. 17. Conclusions Method refactoring is very useful in \neveryday practice. In the design by contract programming methodology, this must be accompanied by providing \na contract for the new method. We have given conditions on this contract to ensure that the veri.cation \nof the original program is not broken when refac\u00adtoring the code. We have provided an exact solution \nto the undecidable problem which is not computable. This led to an iterated forward-backward abstract \ninterpretation to automat\u00adically compute an approximate solution. The implementation using Roslyn and \nCCCheck shows that the proposed algo\u00adrithm is fast and precise enough in practice to entirely support \nthe veri.cation task of the programmer during design time.  Acknowledgments Peter O Hearn and Mooly \nSagiv for pointing out that the conjunction rule is unsound in concurrent separation logic (Ex. 7). We \nthanks the anonymous referees who proposed signi.cant presentation improvements. This material is based \nupon work supported by the National Science Foundation under Grant No. 0926166. References. [1] J. Arsac. \nSyntactic source to source transforms and program manipulation. Comm. ACM, 22(1):43 54, 1979. [2] A. \nBanerjee, D. A. Naumann, and S. Rosenberg. Regional logic for local reasoning about global invariants. \nIn ECOOP, pp. 387 411, 2008. [3] F. Bannwart and P. M\u00a8Changing programs correctly: uller. Refactoring \nwith speci.cations. In FM 2006, volume 4085 of LNCS, pp. 492 507, 2006. [4] M. Barnett, M. F\u00a8 ahndrich, \nand F. Logozzo. Embedded contract languages. In SAC 10, pp. 2103 2110. ACM, 2010. [5] D. Beyer, T. A. \nHenzinger, R. Majumdar, and A. Rybalchenko. Path invariants. In PLDI, pp. 300 309, 2007. [6] S. Brookes. \nA semantics for concurrent separation logic. Theor. Comput. Sci., 375(1-3):227 270, 2007. [7] L. Burdy, \nY. Cheon, D. R. Cok, M. D. Ernst, J. R. Kiniry, G. T. Leavens, K. R. M. Leino, and E. Poll. An overview \nof JML tools and applications. STTT, 7(3):212 232, 2005. [8] P. Cousot. M\u00b4eratives de construction et \nd approxi\u00ad ethodes it\u00b4 mation de points .xes d op\u00b4 erateurs monotones sur un treillis, analyse s\u00b4ese \nd \u00b4 emantique de programmes (in French). Th`Etat `ematiques, Universit\u00b4edicale es sciences math\u00b4e scienti.que \net m\u00b4de Grenoble, 1978. [9] P. Cousot. Constructive design of a hierarchy of semantics of a transition \nsystem by abstract interpretation. TCS, 277(1 2): 47 103, 2002. [10] P. Cousot and R. Cousot. Static \ndetermination of dynamic prop\u00aderties of programs. In Proc. Second Int. Symp. on Programming, pp. 106 \n130. Dunod, Paris, France, 1976. [11] P. Cousot and R. Cousot. Abstract interpretation: a uni.ed lattice \nmodel for static analysis of programs by construction or approximation of .xpoints. In POPL, pp. 238 \n252, 1977. [12] P. Cousot and R. Cousot. Static determination of dynamic properties of recursive procedures. \nIn E. Neuhold, editor, IFIP Conf. on Formal Description of Programming Concepts, pp. 237 277. North-Holland, \n1977. [13] P. Cousot and R. Cousot. Systematic design of program analysis frameworks. In POPL, pp. 269 \n282, 1979. [14] P. Cousot and R. Cousot. Constructive versions of Tarski s .xed point theorems. Paci.c \nJ. Math., 82(1):43 57, 1979. [15] P. Cousot and R. Cousot. Systematic design of program transformation \nframeworks by abstract interpretation. In POPL, pp. 178 190, 2002. [16] P. Cousot and N. Halbwachs. Automatic \ndiscovery of linear restraints among variables of a program. In POPL, pp. 84 97, 1978. [17] P. Cousot, \nR. Cousot, and L.Mauborgne. The reduced product of abstract domains and the combination of decision procedures. \nIn FOSSACS, pp. 456 472, 2011. [18] P. Cousot, R. Cousot, and F. Logozzo. Contract precondition inference \nfrom intermittent assertions on collections. In VMCAI, pp. 150 168, 2011. [19] E. W. Dijkstra. Guarded \ncommands, nondeterminacy and formal derivation of programs. CACM, 18(8):453 457, 1975. [20] M. F\u00a8 ahndrich \nand F. Logozzo. Static contract checking with abstract interpretation. In FoVeOOS, pp. 10 30, 2010. [21] \nA. Feldthaus, T. D. Millstein, A. M\u00f8ller, M. Sch\u00a8 afer, and F. Tip. Tool-supported refactoring for JavaScript. \nIn OOPSLA, pp. 119 138, 2011. [22] J.-C. Filli e. The Why/Krakatoa/Caduceus atre and M. March\u00b4platform \nfor deductive program veri.cation. In CAV, pp. 173 177, 2007. [23] C. Flanagan, K. R. M. Leino, M. Lillibridge, \nG. Nelson, J. B. Saxe, and R. Stata. Extended static checking for Java. In PLDI, pp. 234 245, 2002. [24] \nM. Fowler, K. Beck, J. Brant, W. Opdyke, and D. Roberts. Refactoring: Improving the Design of Existing \nCode. Addison-Wesley Professional, 1999. [25] A. Garrido and J. Meseguer. Formal speci.cation and veri.ca\u00adtion \nof Java refactorings. Technical Report UIUCDCS-R-2006\u00ad2731, Univ. of Illinois at Urbana-Champaign, 2006. \n[26] M. Goldstein, Y. Feldman, and S. Tyszberowicz. Refactoring with contracts. In AGILE, pp. 53 64. \nIEEE Computer Society, 2006. [27] A. Gotsman, J. Berdine, and B. Cook. Precision and the conjunction \nrule in concurrent separation logic. Electr. Notes Theor. Comput. Sci., 276:171 190, 2011. [28] N. Halbwachs \nand M. P\u00b4Discovering properties about eron. arrays in simple programs. In PLDI, pp. 339 348, 2008. [29] \nC. A. R. Hoare. An axiomatic basis for computer programming. Commun. ACM, 12(10):576 580, 1969. [30] \nV. Laviron and F. Logozzo. Subpolyhedra: a family of numeri\u00adcal abstract domains for the (more) scalable \ninference of linear inequalities. STTT, 13(6):585 601, 2011. [31] Q. Long, J. He, and Z. Liu. Refactoring \nand pattern-directed refactoring: A formal perspective. UNU-IIST Research Report 318, The United Nations \nUniv., 2005. [32] D. Loveman. Program improvement by source-to-source transformation. Journal of the \nACM, 24(1):121 145, 1977. [33] K. L. McMillan. Relevance heuristics for program analysis. In POPL, pp. \n145 146, 2008. [34] T. Mens and T. Tourw\u00b4 e. A survey of software refactoring. IEEE Trans. Software Eng., \n30(2):126 139, 2004. [35] B. Meyer. Eiffel: The Language. Prentice Hall, 1991. [36] A. Mine.\u00b4The octagon \nabstract domain. Higher-Order and Symbolic Computation, 19:31 100, 2006. [37] K. Ng, M. Warren, P. Golde, \nand A. Hejlsberg. The Roslyn Project, Exposing the C# and VB compiler s code analysis. http://msdn.microsoft.com/en-us/roslyn, \n2011. [38] P. W. O Hearn. Resources, concurrency, and local reasoning. Theor. Comput. Sci., 375(1-3):271 \n307, 2007. [39] P. W. O Hearn, H. Yang, and J. C. Reynolds. Separation and information hiding. In POPL, \npp. 268 280, 2004. [40] S. Sankaranarayanan, F. Ivancic, and A. Gupta. Program analysis using symbolic \nranges. In SAS, pp. 366 383, 2007. [41] T. Standish, D. Kibler and J. Neighbors. Improving and re.ning \nprograms by program manipulation. In ACMNC, pp. 509 516, 1976. [42] F. Tip. Refactoring using type constraints. \nIn SAS, pp. 1 17, 2007. [43] W. Wake. Refactoring Workbook. Addison-Wesley, 2003.  \n\t\t\t", "proc_id": "2384616", "abstract": "<p>Method extraction is a common refactoring feature provided by most modern IDEs. It replaces a user-selected piece of code with a call to an automatically generated method. We address the problem of automatically inferring contracts (precondition, postcondition) for the extracted method. We require the inferred contract: (a) to be valid for the extracted method (validity); (b) to guard the language and programmer assertions in the body of the extracted method by an opportune precondition (safety); (c) to preserve the proof of correctness of the original code when analyzing the new method separately (completeness); and (d) to be the most general possible (generality). These requirements rule out trivial solutions (e.g., inlining, projection, etc). We propose two theoretical solutions to the problem. The first one is simple and optimal. It is valid, safe, complete and general but unfortunately not effectively computable (except for unrealistic finiteness/decidability hypotheses). The second one is based on an iterative forward/backward method. We show it to be valid, safe, and, under reasonable assumptions, complete and general. We prove that the second solution subsumes the first. All justifications are provided with respect to a new, set-theoretic version of Hoare logic (hence without logic), and abstractions of Hoare logic, revisited to avoid surprisingly unsound inference rules.</p> <p>We have implemented the new algorithms on the top of two industrial-strength tools (CCCheck and the Microsoft Roslyn CTP). Our experience shows that the analysis is both fast enough to be used in an interactive environment and precise enough to generate good annotations.</p>", "authors": [{"name": "Patrick M. Cousot", "author_profile_id": "81100592699", "affiliation": "New York University, New York, NY, USA", "person_id": "P3856065", "email_address": "pcousot@cims.nyu.edu", "orcid_id": ""}, {"name": "Radhia Cousot", "author_profile_id": "81100592574", "affiliation": "&#201;cole normale sup&#233;rieure, Paris, France", "person_id": "P3856066", "email_address": "rcousot@ens.fr", "orcid_id": ""}, {"name": "Francesco Logozzo", "author_profile_id": "81100572523", "affiliation": "Microsoft, Redmond, WA, USA", "person_id": "P3856067", "email_address": "logozzo@microsoft.com", "orcid_id": ""}, {"name": "Michael Barnett", "author_profile_id": "81336487723", "affiliation": "Microsoft, Redmond, WA, USA", "person_id": "P3856068", "email_address": "mbarnett@microsoft.com", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384633", "year": "2012", "article_id": "2384633", "conference": "OOPSLA", "title": "An abstract interpretation framework for refactoring with application to extract methods with contracts", "url": "http://dl.acm.org/citation.cfm?id=2384633"}