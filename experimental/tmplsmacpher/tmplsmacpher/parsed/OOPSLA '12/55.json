{"article_publication_date": "10-19-2012", "fulltext": "\n Open and Ef.cient Type Switch for C++ Yuriy Solodkyy Gabriel Dos Reis Bjarne Stroustrup Texas A&#38;M \nUniversity Texas, USA {yuriys,gdr,bs}@cse.tamu.edu Abstract Selecting operations based on the run-time \ntype of an object is key to many object-oriented and functional programming techniques. We present a \ntechnique for implementing open and ef.cient type switching on hierarchical extensible data types. The \ntechnique is general and copes well with C++ multiple inheritance. To simplify experimentation and gain \nrealistic perfor\u00admance using production-quality compilers and tool chains, we implement a type switch \nconstruct as an ISO C++11 li\u00adbrary, called Mach71. This library-only implementation pro\u00advides concise \nnotation and outperforms the visitor design pattern, commonly used for case analysis on types in object\u00adoriented \nprogramming. For closed sets of types, its perfor\u00admance roughly equals equivalent code in functional \nlan\u00adguages, such as OCaml and Haskell. The type-switching code is easier to use and is more expressive \nthan hand-coded visitors are. The library is non-intrusive and circumvents most of the extensibility \nrestrictions typical of the visitor design pattern. It was motivated by applications involving large, \ntyped, abstract syntax trees. Categories and Subject Descriptors D.1.5 [Programming techniques]: Object-oriented \nProgramming; D.3.3 [Pro\u00adgramming Languages]: Language Constructs and Features General Terms Languages, \nDesign Keywords Type Switch, Typecase, Visitor Design Pattern, Memoization, C++ 1. Introduction Classic \nalgebraic data types as seen in functional languages are closed and their variants are disjoint, which \nallows for ef\u00ad 1 The library is available at http://parasol.tamu.edu/mach7/ Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. OOPSLA 12, October 19 26, 2012, Tucson, Arizona, \nUSA. Copyright &#38;#169; 2012 ACM 978-1-4503-1561-6/12/10. . . $10.00 .cient implementation of case \nanalysis on such types. Data types in object-oriented languages are extensible and hier\u00adarchical (implying \nthat variants are not necessarily disjoint). To be general, case analysis on such types must be open: \nallow for independent extensions, modular type-checking, and dynamic linking. To be accepted for production \ncode, its implementation must also equal or outperform all known workarounds. Existing approaches to \ncase analysis on hier\u00adarchical extensible data types are either ef.cient or open, but not both. Truly \nopen approaches rely on expensive class\u00admembership tests combined with decision trees. Ef.cient ap\u00adproaches \nrely on sealing either the class hierarchy or the set of functions, which loses extensibility (\u00a72.5). \nConsider for example a simple expression language: exp ::= val I exp +exp I exp -exp I exp *exp I exp/exp \nIn an object-oriented language without direct support for algebraic data types, the type representing \nan expression tree in the language will typically be encoded as an abstract base class, with derived \nclasses implementing speci.c variants: struct Expr { virtual int eval() = 0; }; struct Value : Expr { \n. int eval (); int value; }; struct Plus : Expr { . Expr&#38; e1; Expr&#38; e2; }; A simple evaluator \nfor this language can be implemented with the aid of a virtual function eval() declared in the base class \nExpr. The approach is intrusive, however, as the base class has to be modi.ed every time we add a new \nfunction\u00adality. With Mach7, we offer an external introspection of ob\u00adjects with case analysis: int eval \n(const Expr&#38; e) { Match(e) Case(const Value&#38; x) return x.value; Case(const Plus&#38; x) return \neval (x. e1)+eval(x. e2); Case(const Minus&#38; x) return eval(x. e1)-eval(x. e2); Case(const Times&#38; \nx) return eval(x. e1)*eval(x. e2); Case(const Divide&#38; x) return eval(x. e1)/eval (x. e2); EndMatch \n} This is all a user of Mach7 has to write. The syntax is provided without any external tool support \nor additional de.nitions from the user. The library is implemented in standard ISO C++11 [28] with template \nmeta-programming, and a few macros (\u00a73.7). It runs about as fast as OCaml and Haskell equivalents (\u00a74.3), \nand occasionally comes close or outperforms the handcrafted C++ code based on the visitor design pattern \n(\u00a74.1). The ideas and the Mach7 library were motivated by our unsatisfactory experiences working with \nvarious C++ front\u00adends and program analysis frameworks [1, 2, 15, 36]. The problem was not in the frameworks \nper se, but in the fact that we had to use the visitor design pattern [21] to inspect, traverse, and \nelaborate abstract syntax trees of target lan\u00adguages. We found visitors unsuitable to express application \nlogic directly, surprisingly hard to teach students, and of\u00adten slower than handcrafted workaround techniques. \nInstead, users were relying on dynamic casts in many places, often nested, thus preferring shorter, cleaner, \nand more direct code to visitors. The consequential performance penalty was usu\u00adally not discovered until \nlater, when it was hard to remedy. 1.1 Summary This paper makes the following contributions: A technique \nfor implementing open and ef.cient type switching on extensible hierarchical data types as seen in object-oriented \nlanguages.  The technique delivers equivalent performance to that of closed algebraic data types, and \noutperforms the visitor design pattern for open class hierarchies.  A library implementation provides \nthe notational con\u00advenience of functional-language constructs for selecting among types.  A new approach \nto type switching that combines subtype tests and type conversion, outperforming approaches that combine \nsubtype tests (even constant-time ones) with decision trees, even over small class hierarchies.  Complete \nintegration with the existing C++ abstraction mechanisms and object model.  A constant-time function \nthat partitions a set of objects with the same static type into equivalence classes based on the inheritance \npath of the static type within the dy\u00adnamic type.  In particular, our technique for ef.cient type switching: \n Is open by construction (\u00a73.2), non-intrusive, and avoids the control inversion, as typical for visitors. \n Works in the presence of multiple inheritance, both re\u00adpeated and virtual, as well as in generic code \n(\u00a73.7).  Comes close to and often signi.cantly outperforms the workaround techniques used in practice, \ne.g. the visitor design pattern, without sacri.cing extensibility (\u00a74.1).  Does not require any changes \nto the C++ object model or computations at link or load time.  Can be used in object-oriented languages \nwith object models similar to that of C++.  Is implemented as a library written in ISO Standard C++11. \n This is the .rst technique for handling type switching ef.\u00adciently in the presence of the general multiple \ninheritance present in C++. Being a library, Mach7 can be used with any ISO C++11 compiler (e.g., Microsoft, \nGNU, or Clang) with\u00adout requiring any additional tools or preprocessors. It sets a new threshold for \nacceptable performance, brevity, clarity, and usefulness of a forthcoming compiler implementation of \nthe open type switch in C++. 2. Overview A class hierarchy is a partially ordered set (H, <:) where H \nis a potentially open set of classes and <: is a re.exive, transitive and anti-symmetric subtyping relation \non H. We use class and type interchangeably. When two classes are in a subtyping relation D<:B, the class \nD is said to be a (possibly indirect) derived class (or subtype) of B; the class B is called a (possibly \nindirect) base class (or supertype) of D. The dynamic type of an object is the type used to create it. \nThe static type of an expression is the type of that expression as given by the static semantics. 2.1 \nType Switch In general, a type switch or typecase is a multiway branch statement that distinguishes values \nbased on their type. In a multi-paradigm programming language like C++, which supports parametric, ad-hoc, \nand subtyping polymorphisms, such a broad de.nition subsumes numerous different type\u00adcase constructs \nstudied in the literature [24, 26, 51]. In this work, we only look at typecasing scenarios based on the \nclass inheritance of C++, similar to those studied by Glew [24]. We use the term type switch instead \nof a broader typecase to stress the run-time nature of the type analysis similar to how regular switch-statement \nof C++ performs case analysis of values at run time. The term object descriptor means either a pointer \nor a reference to an object. Given an object descriptor, called subject, of static type S referred to \nas the subject type, and a list of target types Ti associated with the branches, a type switch statement \nneeds to identify a suitable clause m based on the dynamic type D <: S of the subject as well as a suitable \nconversion that coerces the subject to the target type Tm. Due to multiple inheritance, types Ti may \nnot all directly derive from the static type S. However, the type of the applicable clause Tm will necessarily \nhave to be a supertype of the subject s dynamic type D <: Tm.A hypothetical type switch statement, not \ncurrently supported by C++, may look as following: switch (subject) { case T1: s1; ... case Tn: sn; } \n There is no need for an explicit default clause in our setting because it is semantically equivalent \nto a case clause guarded by the subject type: case S: s. The only semantic difference such a choice makes \nis in the treatment of null pointers. One may naively think that null pointers should be handled by the \ndefault clause. However, not distinguishing between invalid object and valid object of a known static \nbut unknown dynamic type may lead to nasty run-time errors. Similar control structures exist in many \nprogramming languages, e.g. match in Scala [39], case in Haskell [29] and ML [37], typecase in Modula-3 \n[6] and CLOS (as a macro), tagcase in CLU [34], union case in Algol 68, and date back to at least Simula \ns Inspect statement [11]. The statement can, in general, be given numerous plausible semantics: First-.t \nsemantics will evaluate the .rst statement si such that Ti is a base class of D.  Best-.t semantics \nwill evaluate the statement correspond\u00ading to the most-specialized base class Ti of D if it is unique \n(subject to ambiguity).  Exact-.t semantics will evaluate statement si if Ti = D.  All-.t semantics \nwill evaluate all statements si whose guard type Ti is a supertype of D (order of execution has to be \nde.ned).  Any-.t semantics might choose non-deterministically one of the statements enabled by the all-.t \nsemantics.  The list is not exhaustive and depending on a language, any of them is a plausible choice. \nFunctional languages, for ex\u00adample, often prefer .rst-.t semantics because it is similar to case analysis \nin mathematics. Object-oriented languages are typically inclined to best-.t semantics due to its similarity \nto overload resolution and run-time dispatch; however, some do opt for .rst-.t semantics to mimic the \nfunctional style: e.g. Scala [39]. Exact-.t semantics can often be seen in lan\u00adguages supporting discriminated \nunion types (sum types): e.g. variant records in Pascal, Ada and Modula-2, oneof and variant objects \nin CLU, unions in C and C++, etc. All-.t and any-.t semantics might be seen in languages based on pred\u00adicate \ndispatching [20] or guarded commands [14], where a predicate can be seen as a characteristic function \nof a type, while logical implication as subtyping.   2.2 The Expression Problem Type switching is \nrelated to a more general problem mani\u00adfesting the differences in functional and object-oriented pro\u00adgramming \nstyles. Conventional algebraic datatypes, as found in most functional languages, allow for easy addition \nof new functions on existing data types. However, they fall short in extending data types themselves \n(e.g. with new constructors), which requires modifying the source code. Object-oriented languages make \ndata type extension trivial through inheritance, but the addition of new functions oper\u00adating on these \nclasses typically requires changes to the class de.nition. This dilemma is known as the expression prob\u00adlem \n[10, 52]. Classes differ from algebraic data types in two important ways. Firstly, they are extensible, \nfor new variants can be added later by inheriting from the base class. Secondly, they are hierarchical \nand thus typically non-disjoint since vari\u00adants can be inherited from other variants and form a subtyp\u00ading \nrelation between themselves [24]. In contrast, variants in conventional algebraic data types are disjoint \nand closed. Some functional languages e.g. ML2000 [3] and its prede\u00adcessor, Moby, were experimenting \nwith hierarchical exten\u00adsible sum types, which are closer to object-oriented classes then algebraic data \ntypes are, but, interestingly, they pro\u00advided no facilities for performing case analysis on them. Zenger \nand Odersky re.ned the expression problem in the context of independently extensible solutions [56] as \na challenge to .nd an implementation technique that satis.es the following requirements: Extensibility \nin both dimensions: It should be possible to add new data variants, while adapting the existing opera\u00adtions \naccordingly. It should also be possible to introduce new functions.  Strong static type safety: It should \nbe impossible to apply a function to a data variant, which it cannot handle.  No modi.cation or duplication: \nExisting code should neither be modi.ed nor duplicated.  Separate compilation: Neither datatype extensions \nnor addition of new functions should require re-typechecking the original datatype or existing functions. \nNo safety checks should be deferred until link or runtime.  Independent extensibility: It should be \npossible to com\u00adbine independently developed extensions so that they can be used jointly.  While these \nrequirements were formulated for extensible data types with disjoint variants, object-oriented languages \nprimarily deal with hierarchical data types. We thus found it important to state explicitly an additional \nrequirement based on the Liskov substitution principle [33]: Substitutability: Operations expressed on \nmore general data variants should be applicable to ones that are more speci.c. We will refer to a solution \nthat satis.es all of the above requirements as open. Numerous solutions have been pro\u00adposed to dealing \nwith the expression problem in both func\u00adtional [22, 35] and object-oriented camps [25, 32, 41, 55], \nbut very few have made their way into one of the mainstream languages. We refer the reader to Zenger \nand Odersky s orig\u00adinal manuscript for a discussion of the approaches [56]. Most of the discussed object-oriented \nsolutions focused on the vis\u00aditor design pattern and its extensions, which even today seem to be the \nmost commonly used approach to dealing with the expression problem in object-oriented languages. A lot \nhas been written about the visitor design pattern [21, 40, 41, 55]. Its advantages include extensibility \nof functions, speed, and being a library solution. Nevertheless, the so\u00adlution is intrusive, speci.c \nto hierarchy, and requires a lot of boilerplate code to be written. It also introduces control inversion, \nbut, most importantly, hinders extensibility of classes.  2.3 An Open Type Switch Type switch alone \ndoes not solve the expression problem in the context of an object-oriented language, for the existing \ncode may have to be modi.ed to consider new variants. Re\u00adlying on a default clause is not an acceptable \nsolution in this situation, because often the only reasonable default behav\u00adior is to raise an exception. \nZenger and Odersky observed that defaults transform type errors that should manifest stati\u00adcally into \nruntime exceptions [56]. In our experience, newly added variants were more often extending an existing \nvari\u00adant than creating an entirely disjoint one. In a compiler, for example, a new kind of type expression \nwill typically extend a TypeExpression variant, while a new form of annotation will extend an Annotation \nvariant, thus not extending the root ASTNode directly. Due to the substitutability require\u00adment, this \nnew variant will be treated as a variant it extends in all the existing code. The functions that will \nbe affected by its addition and thus have to be modi.ed will be limited to functions directly analyzing \nthe variant it extends and not providing a default behavior. To account for this subtlety of extensible \nhierarchical data types, we use a term open type switch to refer to a type switch that satis.es all the \nrequirements of an open solution to the expression problem stated above except for the no modi.cation \nor duplication requirement. We loosen it to allow modi.cation of functions for which the newly added \nvariant becomes a disjoint (orthogonal) case not handled by a default clause. We believe that the loosened \nrequirement allows us to express pragmatically interesting restrictions that developers are willing to \nlive with. Furthermore, open type switch overcomes all the major shortcomings of the visitor design pattern: \n Case analysis with an open type switch is non-intrusive as it inspects the hierarchy externally and \ncan be applied retroactively.  New variants can be accounted for in the newly written code and will \nbe seen as a base class or default in the existing code.  The affected functions are limited to those \nfor which the newly added variant is a disjoint case.  The code avoids the control inversion and the \nneed for boilerplate code that visitors introduce, and is thus a more direct expression of the intent. \n 2.4 C++ Speci.cs: Subobjects C++ supports two kinds of multiple inheritance: non-virtual inheritance \nand virtual inheritance [18]. The difference be\u00ad tween the two only arises in situations where a class \nindi\u00adrectly inherits from the same base class via more than one path in its class hierarchy. Rigorous \naccounts of C++ multi\u00adple inheritance semantics use the notion of subobject [44]. Figure 1. Multiple \nInheritance in C++ Consider the simple class hierarchy in Figure 1(1). Class D indirectly inherits from \nclass A through its B and C base classes. In this case, the user may opt to keep distinct subob\u00adjects \nof class A (repeated inheritance) or a shared one (virtual inheritance) by specifying how B and C inherit \nfrom A. The kind of inheritance is thus not a property of a given class, but a property of an inheritance \nrelation between classes and it is possible to mix the two. A class hierarchy gives rise to a subobject \ngraph, where a given class node may be replicated when inherited repeat\u00adedly or left shared when inherited \nvirtually. The edges in such a graph represent subobject containment and indicate whether such containment \nis shared or exclusive. Every class C in the class hierarchy will have its own subobject graph representing \nthe subobjects of an object of dynamic type C. Figure 1(2) shows subobject graph for class D obtained \nfor the class hierarchy in Figure 1(1) under repeated (a) and vir\u00adtual (b) inheritance of class A by \nclasses B and C. The shared containment is indicated with the dashed arrows, while ex\u00adclusive with the \nsolid ones. C++ s notion of multiple inheritance is fundamentally about subobjects, not just types. Virtual \ninheritance is about sharing the base-class subobjects, whereas non-virtual inher\u00aditance re.ects distinction \nin base-class subobjects from dis\u00adtinct class inheritance paths [18]. An object descriptor of static \ntype A referencing an object of the dynamic type C can be understood as any C::*::A\u00adnode in the subobject \ngraph of C. Casts can be understood as a change from one subobject to another. We use the terms source \nsubobject and target subobject to refer to the argument and result of the cast, respectively. Their static \ntypes will be referred to as source type and target type respectively. C++ distinguishes three kinds \nof casts: upcasts, downcasts, and crosscasts.  An upcast is a cast from a derived class to one of its \nbases. When the base class is unambiguous, such casts are implicit and require no additional annotations. \nWhen the base class is ambiguous, cast failure is manifested statically in the form of a compile-time \nerror. For example, this is the case with casting D to A under repeated multiple inheritance of A, in \nwhich case the user needs to explicitly cast the object to B or C .rst in order to indicate the desired \nsubobject and re\u00adsolve the ambiguity. In some cases, however, introduction of such an explicit cast is \nnot possible: e.g. in implicit con\u00adversions generated by the compiler to implement covariant return types, \ncrosscasts or conversions in generic code. This does not mean that in such cases we violate the Liskov \nsub\u00adstitution principle: the classes are still in a subtyping rela\u00adtion, but an implicit conversion is \nnot available. A downcast is a cast from a base class to one of its derived classes. The cast has to \ndetermine at run-time whether the source subobject is contained by a subobject of the target type in \nthe dynamic type s subobject graph. Failure of such a cast is manifested dynamically at run-time. A crosscast \nis a cast between classes that are not nec\u00adessarily related by inheritance except by sharing a common \nderived class (subclass). Accordingly to the C++ semantics such cast is de.ned to be a composition of \nupcast to target type and downcast to the dynamic type. While the downcast to the dynamic type is always \nguaranteed to succeed regard\u00adless of the source subobject, the upcast to the target type may be ambiguous, \nin which case the cast will fail at run\u00adtime. A cast from Y to B inside an object of dynamic type D in \nFigure 1(2a,2b) is an example of a successful crosscast. A similar cast from Y to A inside D under the \nrepeated in\u00adheritance in Figure 1(2a) will fail because of the ambiguous upcast from D to A. An interesting \nartifact of these distinctions can be seen in an example of casting a subobject of type Z to a subob\u00adject \nof type A in Figure 1(2a). The subobject D::B::A::Z will be successfully cast to D::B::A, while the D::C::A::Z \nwill be successfully cast to D::C::A. These casts do not involve downcasting to D followed by an upcast \nto A, which would be ambiguous, but instead take the dynamic type of a larger subobject (D::B or D::C) \nthat the source subobject is con\u00adtained in into account in order to resolve the ambiguity. A similar \ncast from Y to A will fail; should Y have also been non-virtually derived from Z, the cast from D::C::Y::Z \nto A would have failed. This shows that the distinction between crosscast and downcast is not based solely \non the presence of a subtyping relation between the source and target types, but also on the actual position \nof the source subobject in the dynamic type s subobject graph. The C++ inheritance model, presented here \ninformally, further complicates the de.nition and implementation of a type switch compared to simpler \nmodels. We have to de.ne the type switch so that only unambiguous casting between a source and a target \nwithin an object is possible. That is, the implementation of the cast between source and target subob\u00adjects \nmust take into account the location of the source sub\u00adobject in the subobject graph, rather than just \nthe dynamic and target types, which would suf.ce for a simple subtype testing. Of course, every use of \ndynamic casting and every implicit cast are type safe [53].  2.5 Existing Approaches to Type Case Analysis \nThe closed nature of algebraic data types allows for their ef\u00ad.cient implementation. The traditional \ncompilation scheme assigns unique (and often small and sequential) tags to every variant of the algebraic \ndata type and type switching is then simply implemented with a multi-way branch [46] (usually a jump \ntable) over all the tags [4]. Dealing with extensible hierarchical data types makes this approach infeasible: \n Extensibility implies that the compiler may not know the exact set of all the derived classes until \nlink-time (due to separate compilation) or even run-time (due to dynamic linking).  Substitutability \nimplies that we should be able to match tags of derived classes against case labels representing tags \nof base classes.  The presence of multiple inheritance might require pointer adjustments that are not \nknown at compile time (e.g. due to virtual base classes, ambiguous base classes or cross\u00adcasting).  \nThere are two main approaches to implementing case anal\u00adysis on extensible hierarchical data types discussed \nin the literature. The .rst approach is based on either explicit or implicit sealing of the class hierarchy \non which type switching can be performed. C++11, for example, allows the user to prohibit further derivation \nby specifying a class to be .nal [28], similar to Scala and Java. The compiler then may use the above \ntag allocation over all variants to implement type anal\u00adysis [19, \u00a74.3.2]. In some cases, the sealing \nmay happen im\u00adplicitly. For example, languages with both internal and ex\u00adternal linkage may employ the \nfact that classes with inter\u00adnal linkage will not be externally accessible and are thus ef\u00adfectively \nsealed. While clearly ef.cient, the approach is not open as it avoids the question rather than answers \nit. The broader problem with this approach is that techniques that rely on unique or sequential compile \nor link-time con\u00adstants violate independent extensibility since without a cen\u00adtralized authority there \nis no guarantee same constant will not be chosen in a type-unsafe manner by independent ex\u00adtensions. \nUpdating such constants at load time may be too costly even when possible. An important practical solution \nthat follows this approach is the visitor design pattern [21]. The set of visit methods in a visitor \ns interface essentially seals the class hierarchy.  Extensions have been proposed in the literature \n[55], but they have problems of their own, as discussed in \u00a75. The second approach employs type inclusion \ntests com\u00adbined with decision trees [5] to avoid unnecessary checks. Its ef.ciency is then entirely focused \non the ef.ciency of type inclusion tests [7, 9, 12, 17, 23, 31, 45, 50, 54, 57]. C++ has handled general \ndynamic casting since 1987, when multiple inheritance was added to the language [47]. Wirth later presented \na technique that can be used to imple\u00adment subtype tests by traversing a linked list of types [54]. His \nencoding required little space, but ran in time propor\u00adtional to the distance between the two types in \nthe class hi\u00aderarchy. A trivial constant-time type inclusion test can be implemented with a binary matrix, \nencoding the subtyping relation on the class hierarchy [12]. While ef.cient in time, it has quadratic \nspace requirements, which makes it expen\u00adsive for use on large class hierarchies. Cohen proposed the \n.rst space-ef.cient constant-time algorithm, but it can only deal with single inheritance [9]. Hierarchical \nencoding is an\u00adother constant-time test that maps subtype queries into sub\u00adset queries on bit-vectors \n[7, 31]. The approach can handle multiple inheritance, but the space and time required for a subtype \ntest in this encoding increases with the size of the class hierarchy; also, Caseau s approach [7] is \nlimited to class hierarchies that are lattices. Schubert s relative num\u00adbering [45] encodes each type \nwith an interval [l, r], ef\u00adfectively making type inclusion tests isomorphic to a sim\u00adple range checking. \nThe encoding is optimal in space and time, but it is limited to single inheritance. PQ-Encoding of Zibin \nand Gil employs PQ-trees to improve further space and time ef.ciency of the constant-time inclusion testing \n[57]. While capable of handling type inclusion queries on hier\u00adarchies with multiple inheritance, the \napproach makes the closed world assumption and can be costly for use with dy\u00adnamic linking because it \nis not incremental. The approach of Gibbs and Stroustrup [23] employs divisibility of numbers to obtain \na constant-time type inclusion test. The approach can handle multiple inheritance and was the .rst constant-time \ntechnique to addresses the problem of casts between subob\u00adjects. Unfortunately, the approach limits the \nsize of the class hierarchies that can be encoded with this technique. Ducour\u00adnau proposed a constant-time \ninclusion test based on the fact that, in an open solution, a class has a known number of base classes, \nand thus perfect hashes can be used to map them to this-pointer offsets typically used to implement subobject \ncasts [17]. Unfortunately, the approach addresses only vir\u00adtual multiple inheritance and (similarly to \nother approaches) relies on load-time computations. An excellent introduction to and detailed analysis \nof existing constant-time type inclu\u00adsion tests can be found in [50, 57]. With the exception of work \nby Gibbs and Stroustrup [23], all the approaches to ef.cient type-inclusion testing we found in the literature \nwere based on the assumption that the outcome of a subtyping test as well as the subsequent cast depend \nonly on the target type and the dynamic type of the object. Although that assumption is sound for subtyping \ntests and subtype casts for shared inheritance (including sin\u00adgle), it does not re.ect the relationship \nbetween subobjects in the general case of multiple inheritance as found in C++.  2.6 The Source of Inef.ciency \nWhile constant-time type inclusion tests are invaluable in optimizing subtype tests in programming languages, \ntheir use in implementing a type switch is inferior to some workaround techniques. This may prevent wide \nadoption of a language implementation of such a feature due to its inferior performance. We implemented \n3 constant-time type inclusion tests: binary matrix [50], Cohen s algorithm [9], and fast dynamic cast \n[23] and combined them with a de\u00adcision tree to implement a type switch on a class hierarchy ideally \nsuited for such scenarios: a perfect binary tree with classes number 2i and 2i +1 derived from a class \nnumber i. Our workaround techniques included the visitor design pattern and a switch on the sealed sequential \nset of tags. Figure 2. Type switch based on constant-time subtype tests The chart in Figure 2 shows \nthe number of cycles (Y-axis) each technique took to recognize an object of the dynamic type i (X-axis). \nDespite known limitations, binary matrix and Cohen s algorithm are some of the fastest known type inclusion \ntests for single inheritance [50]. It is nonetheless easy to see that the logarithmic cost associated \nwith the de\u00adcision tree very quickly surpasses the constant overhead of double dispatch (20 cycles) present \nin the visitor design pat\u00adtern or the jump-table implementation of the switch on all tags (11 cycles). \nWe expect the cost of techniques capable of handling multiple inheritance to be even higher, especially \nthose addressing casting between subobjects (e.g. fast dy\u00adnamic cast). The edgy shape of timing results \nre.ects the shape of the class hierarchy used for this experiment. 3. Type Switching Mach7 explicitly \nsupports at least two encodings of alge\u00adbraic datatypes: runtime type information discriminant, and numerical \ntag data member shared by all classes in a given hierarchy. The library handles them differently to let \nthe user choose between openness and ef.ciency. The type switch for tagged encoding (\u00a73.1) is simpler \nand more ef.cient for many typical use cases, however, making it open eradicates its performance advantages \n(\u00a74.2).  3.1 An Attractive Non-Solution While Wirth linked list encoding was considered slow for subtype \ntesting, it can be adopted for quite ef.cient type switching on a class hierarchy with no repeated inheritance. \nThe idea is to combine fast switching on closed algebraic datatypes with a loop that tries the tags of \nbase classes when switching on derived tags fails. For simplicity of presentation we assume a pointer \nto an array of tags be available directly through the subject s taglist data member. The array is of \nvariable size: its .rst el\u00adement is always the tag of the subject s dynamic type, while its end is marked \nwith a dedicated end of list marker, dis\u00adtinct from all the tags. The tags in between are topologically \nsorted according to the subtyping relation with incomparable siblings listed in local precedence order \n the order of the di\u00adrect base classes used in the class de.nition. The list resem\u00adbles the class precedence \nlist of object-oriented descendants of Lisp (e.g. Dylan, Flavors, LOOPS, and CLOS) used there for linearization \nof class hierarchies. We also assume the tag-constant associated with a class Di is accessible through \na static member Di::class tag. These simpli.cations are not essential and the library does not rely on \nany of them. A type switch, below, proceeds as a regular switch on the subject s tag. If the jump succeeds, \nwe found an exact match; otherwise, we get into a default clause that obtains the next tag in the list \nand jumps back for a rematch: size t attempt = 0; size t tag = subject.taglist[attempt]; ReMatch: switch \n(tag) { default: tag = subject.taglist[++attempt]; goto ReMatch; case end of list: break; case D1::class \ntag: D1&#38; match = static cast.D1&#38;.(*subject); s1; break; ... case Dn::class tag: Dn&#38; match \n= static cast.Dn&#38;.(*subject); sn; break; } The above structure, which we call a tag switch, implements \na variation of best-.t semantics based on local precedence order. It lets us dispatch to the case clause \nof the most\u00adspecialized class with an overhead of initializing two local variables, compared to an ef.cient \nswitch used on algebraic data types. Dispatching to a case clause of a base class will take time roughly \nproportional to the distance between the matched base class and the derived class in the inheritance \ngraph, thus the technique is not constant. When none of the base class tags was matched, we will necessarily \nreach the end of list marker and exit the loop. The default clause, again, can be implemented with a \ncase clause on the subject type s tag: case S::class tag: The ef.ciency of the above code crucially depends \non the set of tags being small and sequential to justify the use of a jump table instead of a decision \ntree to implement the switch. This is usually not a problem in closed hierarchies based on tag encoding \nsince the designer of the hierarchy handpicks the tags herself. The use of a static cast however, essentially \nlimits the use of this mechanism to non-repeated inheritance only. This only refers to the way target \nclasses inherit from the subject type they can freely inherit from other classes. Due to these restrictions, \nthe technique is not open because it may violate independent extensibility. We discuss in \u00a74.2 that making \nthe technique more open will also eradicate its performance advantages. 3.2 An Open but Inef.cient Solution \nInstead of starting with an ef.cient solution and trying to make it open, we start with an open solution \nand try to make it ef.cient. The following cascading-if statement im\u00adplements the .rst-.t semantics for \nour type switch in a truly open fashion: if (T1 * match=dynamic cast.T1 *.(subject)) {s1;} else if (T2 \n* match=dynamic cast.T2 *.(subject)) {s2;} else ... if (Tn * match=dynamic cast.Tn *.(subject)) {sn;} \n Its main drawback is performance: a typical implementation of dynamic cast takes time proportional to \nthe distance between base and derived classes in the inheritance tree. What is worse is that due to the \nsequential order of tests, the time to uncover the type in the ith case clause will be proportional to \ni, while failure to match will take the longest. In a test involving a .at hierarchy of 100 variants, \nit took 93 cycles to discover the .rst type and 22760 to discover the last (with their linear combination \nfor the types in between). Relying on dynamic cast also makes an implicit seman\u00adtic choice where we are \nno longer looking for the .rst/best\u00ad.tting type that is in subtyping relation, but for the .rst/best\u00ad.tting \ntype to which a cast is possible from the source sub\u00adobject (\u00a72.4).  3.3 A Memoization Device Let us \nlook at a slightly more general problem than type switching. Consider a generalization of the switch \nstatement that takes predicates on a subject as its clauses and executes the .rst statement si whose \npredicate is enabled: switch (x) { case P1(x): s1; ... case Pn(x): sn; }  Assuming that predicates are \nfunctional (i.e. do not involve any side effects), the next time we execute the switch with the same \nvalue x, the same predicate will be enabled .rst. We thus would like to avoid evaluating preceding predicates \nand jump to the statement it guards. In a way, we would like the switch to memoize the case enabled for \na given x. The idea is to generate a simple cascading-if statement interleaved with jump targets and \ninstructions that associate the original value with enabled target. The code before the statement looks \nup whether the association for a given value has already been established, and, if so, jumps directly \nto the target; otherwise, the sequential execution of the cascading\u00adif is started. To ensure that the \nactual code associated with the predicates remains unaware of this optimization, the code preceding it \nafter the target must re-establish any in\u00advariant guaranteed by sequential execution (\u00a73.7). Described \ncode can be easily produced in a compiler setting, but generating it in a library is a challenge. Inspired \nby Duff s Device [48], we devised a construct that we call Memoization Device doing just that in standard \nC++: typedef decltype(x) T; // T is the type of subject x static std::unordered map.T,size t. jump targets; \nswitch (size t&#38; jump to = jump targets[x]) { default: // entered when we have not seen x yet if (P1(x)) \n{ jump to = 1; case 1: s1;} else if (P2(x)) { jump to = 2; case 2: s2;} else ... if (Pn(x)) { jump to \n= n; case n: sn;} else jump to = n +1; case n +1: // none of the predicates is true on x } The static \njump targets hash table will be allocated upon .rst entry to the function. The map is initially empty \nand according to its logic, request for a key x not yet in the map will allocate a new entry with its \nassociated data default initialized (to 0 for size t). Since there is no case label 0 in the switch, \nthe default case will be taken, which, in turn, will initiate sequential execution of the interleaved \ncascading\u00adif statement. Assignments to jump to effectively establish association between value x and \ncorresponding predicate, since jump to is a reference to jump targets[x]. The last assignment records \nabsence of enabled predicates for x. To change the .rst-.t semantics of the above construct into sequential \nall-.t, we remove the else-statements and rely on fall-through behavior of the switch. We make the assignments \nconditional to make sure, only the .rst is recorded: if (Pi(x)) { if (jump to ==0) jump to = i; case \ni: si;} Note that the protocol that has to be maintained by this struc\u00adture does not depend on the actual \nvalues of case labels. We only require them to be different and include a prede\u00ad.ned default value. The \ndefault clause can be replaced with a case clause for the prede.ned value, but keeping the default clause \ngenerates faster code. A more important considera\u00adtion is to keep the values close to each other. Not \nfollowing this rule might result in a compiler choosing a decision tree over a jump table implementation \nof the switch, which in our experience signi.cantly degrades the performance. The .rst-.t semantics is \nnot an inherent property of the memoization device. Assuming that the conditions are ei\u00adther mutually \nexclusive or imply one another, we can build a decision-tree-based memoization device that will effectively \nhave most-speci.c semantics an analog of best-.t seman\u00adtics in predicate dispatching [20]. Imagine that \nthe predicates with the numbers 2i and 2i+1 are mutually exclusive and each imply the value of the predi\u00adcate \nwith number i, i.e. .i.x ..j Domain(Pj).P2i+1(x). Pi(x).P2i(x).Pi(x).\u00ac(P2i+1(x).P2i(x)) holds. Ex\u00adamples \nof such predicates are class membership tests where the truth of testing membership in a derived class \nimplies the truth of testing membership in its base class. The following decision-tree-based memoization \ndevice will execute the statement si associated with the most\u00adspeci.c predicate Pi (i.e. the predicate \nthat implies all other predicates true on x) that evaluates to true or will skip the entire statement \nif none of the predicates is true on x. switch (size t&#38; jump to = jump targets[x]) {default: if (P1(x)) \n{ if (P2(x)) { if (P4(x)) { jump to = 4; case 4: s4;} else if (P5(x)) { jump to = 5; case 5: s5;} jump \nto = 2; case 2: s2; } else if (P3(x)) {if (P6(x)) { jump to = 6; case 6: s6;} else if (P7(x)) { jump \nto = 7; case 7: s7;}jump to = 3; case 3: s3; } jump to = 1; case 1: s1; } else { jump to = 0; case 0: \n; }} Our library solution prefers the simpler cascading-if ap\u00adproach only because the necessary code \nstructure can be laid out with macros. A compiler solution will use the decision\u00adtree approach whenever \npossible to lower the cost of the .rst match from linear in case s number to logarithmic. The main advantage \nof the memoization device is that it can be built around almost any code, providing that we can re-establish \nthe invariants guaranteed by sequential execu\u00adtion. Its main disadvantage is the size of the hash table \nthat grows proportionally to the number of different values seen. Fortunately, the values can often be \ngrouped into equivalence classes that do not change the outcome of the predicates. The map can then associate \nthe equivalence class of a value with a target instead of associating the value with it.  In application \nto type switching, the idea is to use the memoization device to learn the outcomes of type inclusion \ntests (with dynamic cast used as a predicate). The objects can be grouped into equivalence classes based \non their dy\u00adnamic type: the outcome of each type inclusion test will be the same on all the objects of \nthe same dynamic type. We can use the address of a class type info object obtained in con\u00adstant time \nwith the typeid() operator as a unique identi.er of each dynamic type. This could have been a solution \nif we were only interested in class membership. More often than not, however, we will be interested in \nobtaining a reference to the target type of the subject, and we saw in \u00a72.4 that the cast between the \nsource and target subobjects depends on the position of the source subobject in the dynamic type s subobject \ngraph. We thus would like to have different equivalence classes for different subobjects.  3.4 Virtual \nTable Pointers Figure 3 shows a typical object layout generated by a C++ compiler for class D from Figure \n1(1) under repeated (1) and virtual (2) inheritance of A. The layouts represent an en\u00adcoding of the corresponding \nsubobject graphs from Figures 1(2a) and 1(2b) respectively. Figure 3. Object Layout under Multiple Inheritance \nDue to the extensibility of classes, the layout decisions for classes must be made independently of their \nderived classes a property of the C++ object model that we will refer to as layout independence. In turn, \nthe layout of derived classes must conform to the layout of their base classes relatively to the offset \nof the base class within the derived one. For example, the layout of A in C is exactly the same as the \nlayout of A in B and is simply the layout of A. Base classes inherited virtually do not contribute to \nthe .xed layout because they are looked up indirectly at run-time; however, they are not exempt from \nlayout independence, since their lookup rules are agnostic of the concrete dynamic type. Under non-virtual \ninheritance, members of the base class are typically laid out before the members of derived class, resulting \nin the base class being at the same offset as the de\u00adrived class itself. In our example, the offset of \nA in B under regular (non-virtual) inheritance of A is 0. Under multiple inheritance, different base \nclasses might be at different off\u00adsets in the derived class, which is why pointers of a given static \ntype may be pointing only to certain subobjects in it. These positions are marked in the picture with \nvertical ar\u00adrows decorated with the set of pointer types whose values may point into that position. Run-time \nconversions between such pointers represent casts between subobjects of the same dynamic type and may \nrequire adjustments to this-pointer (shown with dashed arrows) for type safety. A class that declares \nor inherits a virtual function is called a polymorphic class. The C++ standard [28] does not prescribe \nany speci.c implementation technique for virtual function dispatch. However, in practice, all C++ compilers \nuse a strategy based on so-called virtual function tables (or vtables for short) for ef.cient dispatch. \nThe vtable is part of the rei.cation of a polymorphic class type. C++ compil\u00aders embed a pointer to a \nvtable (vtbl-pointer for short) in every object of polymorphic class type (and thus every sub\u00adobject \nof that type inside other classes due to layout indepen\u00addence). CFront, the .rst C++ compiler, puts the \nvtbl-pointer at the end of an object. The so-called common vendor C++ ABI [8] requires the vtbl-pointer \nto be at offset 0 of an object. We do not have access to the unpublished Microsoft ABI, but we have experimental \nevidence that their C++ com\u00adpiler also puts the vtbl-pointer at the start of an object. While the exact \noffset of the vtbl-pointer within the (sub)object is not important for this discussion, because of layout \nindependence every (sub)object of a polymor\u00adphic type S will have a vtbl-pointer at a prede.ned off\u00adset. \nSuch offset may be different for different static types S, in which case the compiler will know at which \noff\u00adset in type S the vtbl-pointer is located, but it will be the same within any subobject of a static \ntype S. For a li\u00adbrary implementation we assume the presence of a function template .typename S.intptr \nt vtbl(const S*s); that re\u00adturns the address of the virtual table corresponding to the subobject pointed \nto by s. Such a function can be trivially implemented for the common vendor C++ ABI, where the vtbl-pointer \nis always at offset 0: template .typename S. std::intptr t vtbl(const S* s) { static assert(std::is polymorphic.S.::value, \nerror ); return *reinterpret cast.const std::intptr t*.(s); } Each of the vtbl .elds shown in Figure \n3 holds a vtbl-pointer referencing a group of virtual methods known in the object s static type. Figure \n4(1) shows a typical layout of virtual function tables together with objects it points to for classes \nB and D. Entries in the vtable to the right of the address pointed to by a vtbl-pointer represent pointers \nto functions, while entries to the left of it represent various additional .elds like a pointer to a \nclass type information, offset to top, offsets  Figure 4. VTable layout with and without RTTI to virtual \nbase classes, etc. In many implementations, this\u00adpointer adjustments required to dispatch properly the \ncall were stored in the vtable along with function pointers. Today most implementations prefer to use \nthunks or trampolines additional entry points to a function, that adjust this-pointer before transferring \nthe control to the function, which was shown to be more ef.cient [16]. Thunks in general may only be \nneeded when virtual function is overridden. In such cases, the overridden function may be called via \na pointer to a base class or a pointer to a derived class, which may not be at the same offset in the \nactual object. The intuition behind our proposal is to use the values of vtbl-pointers stored inside \nthe object to uniquely identify the subobject in it. There are several problems with the approach, however. \nFirst, the same vtbl-pointer is usually shared by multiple subobjects when one of them contains the other. \nFor example, the .rst vtbl-pointer in Figure 3(1) will be shared by objects of static type Z*, A*, B* \nand D*. This is not a problem for our purpose, because the subobjects of these types will be at the same \noffset in the object. Secondly, and more importantly, however, there are legitimate optimizations that \nlet the compiler share the same vtable among multiple subobjects of often-unrelated types. Generation \nof the Run-Time Type Information (or RTTI for short) can typically be disabled with a compiler switch \nand the Figure 4(2) shows the same vtable layouts once RTTI has been disabled. Since neither baz nor \nfoo were overridden, the pre.x of the vtable for the C subobject in D is exactly the same as the vtable \nfor its B subobject, the A subobject of C, or the entire vtable of A and B classes. Such a layout, for \nexample, is produced by Microsoft Visual C++ 11 when the command-line option /GR- is speci.ed. The Visual \nC++ compiler has been known to unify code identical on binary level, which in some cases may result in \nsharing of the same vtable between unrelated classes (e.g. when virtual functions are empty). We now \nwould like to show more formally that in the presence of RTTI, a common vendor C++ ABI compliant implementation \nwould always have all the vtbl-pointers dif\u00adferent. To do so, we need a closer look at the notion of \nsub\u00adobject, which has been formalized before [43, 44, 53]. We follow here the presentation of Ramamanandro \net al [43].  3.5 Subobjects We assume a program P is represented by its class ta\u00adble, which can be queried \nfor inheritance relations between classes. All subsequent de.nitions are implicitly parameter\u00adized over \na given program P. A class B is a direct repeated base class of D if B is mentioned in the list of base \nclasses of D without the virtual keyword (D .R B). Similarly, a class B is a direct shared base class \nof D if B is men\u00adtioned in the list of base classes of D with the virtual key\u00adword (D .S B). A re.exive \ntransitive closure of these re\u00adlationships .*= (.R ..S)* de.nes the subtyping relation on types of program \nP. A base class subobject of a given complete object is represented by a pair s =(h, l) with h .{Repeated, \nShared} representing the kind of inheritance (single inheritance is Repeated with one base class) and \nl representing the path in a non-virtual inheritance graph. A judgment of the form P .C -s >A states \nthat in a program P, s designates a subobject of static type A within an object of type C. Omitting the \ncontext P: C .S BB -(h, l)>A C -(Repeated,C ::E)>C C -(Shared,l)>A C .R BB -(Repeated,l)>A C -(Repeated,C \n::l)>A E indicates an empty path, but we will generally omit it in writing when understood from the \ncontext. In the case of repeated inheritance in Figure 1(1), an object of the dy\u00adnamic class D will have \nthe following Repeated subobjects: D::C::Y, D::B::A::Z, D::C::A::Z, D::B::A, D::C::A, D::B, D::C, D. \nSimilarly, in case of virtual inheritance in the same example, an object of the dynamic class D will \nhave the fol\u00adlowing Repeated subobjects: D::C::Y, D::B, D::C, D as well as the following Shared subobjects: \nD::A::Z, D::Z, D::A. See Figure 1 for illustration. It is easy to show by structural induction on the \nabove de.nition, that C -s >A =. s =(h, C ::l1).s =(h, l2 :: A :: E), which simply means that any path \nto a subobject of static type A within the object of dynamic type C starts with C and ends with A. This \nobservation shows that sj = (Shared,E) does not represent a valid subobject. If SP is the domain of all \nsubobjects in the program P extended with sj, then a cast operation can be understood as a function d \n: SP . SP. We use sj to indicate an impossibility of a cast. The fact that d is de.ned on subobjects \nas opposed to actual run-time values re.ects the non-coercive nature of the operation, i.e. the underlying \nvalue remains the same. Any implementation of such a function must thus satisfy the following condition: \n C -s1 >A .d(s1)=s2 =. C -s2 >B i.e. the dynamic type of the value does not change during casting, only \nthe way we reference it does. Following the de.nitions from \u00a72.4, A is the source type and s1 is the \nsource subobject of the cast, while B is the target type and s2 is the target subobject of it. The type \nC is the dynamic type of the value being casted. The C++ semantics states more requirements to the implementation \nof d: e.g. d(sj)= sj etc. but their precise modeling is out of scope of this discussion. We would only \nlike to point out here that since the result of the cast does not depend on the actual value and only \non the source subobject and the target type, we can Proof. Let us assume .rst a1.vtbl = a2.vtbl but C1 \n. C2. In this case we have rtti(a1.vtbl)=rtti(a2.vtbl). By de.nition rtti(a1.vtbl)= C1 while rtti(a2.vtbl)= \nC2, which contra\u00addicts that C1 .C2. Thus C1 =C2 = C. Let us assume now that a1.vtbl = a2.vtbl but s1 \n. s2. Let s1 =(h1,l1),s2 =(h2,l2) If h1 . h2 then one of them refers to a virtual base while the other \nto a repeated one. Assuming h1 refers to a virtual base, vbase(a1.vtbl) has to be de.ned inside the vtable \naccording to the ABI, while vbase(a2.vtbl) should not. This would contradict again that both vtbl refer \nto the same virtual table. We thus have h1 = h2 = h. If h = Shared then there is only one path to such \nA in C, which would contradict s1 . s2. If h = Repeated then we must have that l1 . l2. In this case \nlet k be the .rst position in which they differ: .j < k.l. 1 . l2 . j 1 = l j 2 l kk Since our class \nA is memoize the outcome of a cast on one instance in order to a base class for classes l k 1 and l k \n2 , both of which are in apply its results to another.  3.6 Uniqueness of vtbl-pointers under common \nABI Given a reference a to polymorphic type A that points to a subobject s of the dynamic type C (i.e. \nC -s >A is true), we will use the traditional .eld access notation a.vtbl to refer to the virtual table \nof that subobject. The exact structure of the virtual table as mandated by the common vendor C++ ABI \nis immaterial for this discussion, but we mention a few .elds that are important for the reasoning [8, \n\u00a72.5.2]: rtti(a.vtbl): the typeinfo pointer points to the typeinfo object used for RTTI. It is always \npresent and is shown as the .rst .eld to the left of any vtbl-pointer in Figure 4(1). o.2top(a.vtbl): \nthe offset to top holds the displacement to the top of the object from the location within the object \nof the vtbl-pointer that addresses this virtual table. It is always present and is shown as the second \n.eld to the left of any vtbl-pointer in Figure 4(1). The numeric value shown indicates the actual offset \nbased on the object layout from Figure 3(1).  vbase(a.vtbl): Virtual Base (vbase) offsets are used to \naccess the virtual bases of an object. Such an entry is required for each virtual base class. None is \nshown in our example in Figure 4(1) since it discusses repeated inheritance, but they will occupy further \nentries to the left of the vtbl-pointer, when present.  We also use the notation o.set(s) to refer to \nthe offset of a given subobject s within C, known by the compiler. Theorem 1. In an object layout that \nadheres to the common vendor C++ ABI with RTTI enabled, equality of vtbl-pointers of two objects of the \nsame static type implies that they both belong to subobjects with the same inheritance path in the same \ndynamic class. .a1,a2 :A I a1 .C1 -s1 >A .a2 . C2 -s2 >A a1.vtbl = a2.vtbl .C1 = C2 .s1 = s2 turn base \nclasses of C, the object identity requirement of C++ requires that the relevant subobjects of type A \nhave different offsets within class C: o.set(s1). o.set(s2) However o.set(s1)=o.2top(a1.vtbl)=o.2top(a2.vtbl)= \no.set(s2) since a1.vtbl = a2.vtbl, which contradicts that the offsets are different. Conjecture in the \nother direction is not true in general as there may be duplicate vtables for the same type present at \nrun-time. This happens in many C++ implementations in the presence of Dynamically Linked Libraries (or \nDLLs for short) as the same class compiled into executable and DLL it loads may have identical vtables \ninside the executable s and DLL s binaries. Note also that we require both static types to be the same. \nDropping this requirement and saying that equality of vtbl\u00adpointers also implies equality of static types \nis not true in general because a derived class can share a vtbl-pointer with its primary base class. \nThe theorem can be reformulated, however, stating that one subobject will necessarily have to contain \nthe other, but that would require bringing in the for\u00admalism for subobject containment [53]. The current \nformu\u00adlation is suf.cient for our purposes. During construction and deconstruction of an object, the \nvalue of a given vtbl-pointer may change. In particular, that value will re.ect the fact that the dynamic \ntype of the object is the type of its fully constructed part only. This does not affect our reasoning, \nas during such transition we also treat the object to have the type of its fully constructed base only. \nSuch interpretation is in line with the C++ semantics for vir\u00adtual function calls and the use of RTTI \nduring construction and destruction of an object. Once the complete object is fully constructed, the \nvalue of the vtbl-pointer will remain the same for the lifetime of the object.  3.7 Vtable Pointer \nMemoization The C++ standard implies that information about types is available at run time for three \ndistinct purposes [8, \u00a72.9.1]: to support the typeid operator,  to match an exception handler with \na thrown object, and  to implement the dynamic cast operator.  and if any of these facilities are used \nin a program that was compiled with RTTI disabled, the compiler shall emit a warning. Some compilers \n(e.g. Visual C++) additionally let a library check presence of RTTI through a prede.ned macro, thus letting \nit report an error if its dependence on RTTI cannot be satis.ed. Since our solution depends on dynamic \ncast, according to the third requirement we im\u00adplicitly rely on the presence of RTTI and thus fall into \nthe setting that guarantees the preconditions of Theorem 1. Be\u00adsides, all the objects that will be coming \nthrough a particular type switch will have the same static type, and thus the the\u00adorem guarantees that \ndifferent vtbl-pointers will correspond to different subobjects. The idea is thus to group them ac\u00adcording \nto the value of their vtbl-pointer and associate both jump target and the required offset through the \nmemoization device: typedef pair.ptrdi. t,size t. target info; //(o.set,target) static unordered map.intptr \nt, target info. jump targets; auto* sptr = &#38;x; // name to access subject const void* tptr; target \ninfo&#38; info = jump targets[vtbl(sptr)]; switch (info.second) {{ default: The code for the ith case \nnow evaluates the required offset on the .rst entry and associates it and the target with the vtbl-pointer \nof the subject. The call to adjust ptr.Ti. re\u00adestablishes the invariant that match is a reference to \ntype Ti of the subject x. if (tptr = dynamic cast.const Ti *.(sptr)) { if (info.second ==0) { // supports \nfall-through info..rst = intptr t(tptr)-intptr t(sptr); // o.set info.second = i; // jump target } case \ni: // i is a constant - clause s position in switch auto match = adjust ptr.Ti.(sptr,info..rst); si; \n} Class std::unordered map provides amortized constant time access on average and linear in the number \nof elements in the worst case. We show in the next section that most of the time we will be bypassing \ntraditional access to its elements. We need this extra optimization because, as-is, the type switch is \nstill about 50% slower than the visitor design pattern. Looking back at the example from \u00a71 and allowing \nfor a few unimportant omissions, the .rst code snippet corre\u00adsponds to what the macro Match(x) is expanded \nto when given a subject expression x. In order to see what Case(Ti) is expanded to, the second snippet \nhas to be split on the line containing si; (excluding si; itself, which comes from source) and the second \npart (i.e. } here) moved in front of the .rst one. The macro thus closes the scope of the previ\u00adous case \nclause before starting the new one. Case s expan\u00adsion only relies on names introduced by Match(x), its \nar\u00adgument Ti, and a constant i, which can be generated from the LINE macro, or, better yet, the COUNTER \nmacro when supported by the compiler. The EndMatch macro sim\u00adply closes the scopes (i.e. }} here). We \nrefer the reader to the library source code for further details.  3.8 Minimization of Con.icts Virtual \ntable pointers are not constant values and are not even guaranteed to be the same between different runs \nof the application, because techniques like address space layout randomization or rebasing of the module \nare likely to change them. The relative distance between them will remain the same as long as they come \nfrom the same module. Knowing that vtbl-pointers point into an array of function pointers, we should \nexpect them to be aligned accordingly and thus have a few lowest bits as zero. Moreover, since many derived \nclasses do not introduce new virtual functions, the size of their virtual tables remains the same. When \nallo\u00adcated sequentially in memory, we can expect a certain num\u00adber of lowest bits in the vtbl-pointers \npointing to them to be the same. These assumptions, supported by actual obser\u00advations, made virtual table \npointers of classes related by in\u00adheritance ideally suitable for hashing: the values obtained by throwing \naway the common bits on the right were compactly distributed in small disjoint ranges (\u00a74.4). We use \nthem to address a cache built on top of the hash table in order to eliminate a hash table lookup in most \nof the cases. Let . be the domain of integral representations of point\u00aders. Given a cache with 2k entries, \nwe use a family of hash functions Hkl : . .[0..2k -1] de.ned as Hkl(v)= v/2l mod 2k to index the cache, \nwhere l .[0..32] (assuming 32 bit addresses) is a parameter modeling the number of com\u00admon bits on the \nright. Division and modulo are implemented with bit operations since the denominator in each case is \na power of 2, which in turn explains the choice of the cache size. Given a hash function Hkl, pointers \nv ' and v '' are said to be in con.ict when Hkl(v ')= Hkl(v ''). For a given set of pointers V . 2., \nwe can always .nd such k and l that Hkl will render no con.icts between its elements, but the required \ncache size 2k can be too large to justify the use of memory. The value K such that 2K-1 <IV I= 2K is \nthe smallest value of k under which absence of con.icts is still possible. We thus allow k to vary only \nin the range [K, K +1] to ensure that the cache size is never more than 4 times bigger than the minimum \nrequired cache size. Given a set V ={v1, ..., vn}, we would like to .nd a pair of parameters (k, l) such \nthat Hkl will render the least number of con.icts on the elements of V . Since for a .xed set V , parameters \nk and l vary in a .nite range, we can always .nd the optimal (k, l) by trying all the combinations. Let \nHV :V .[0..2k-1] be the hash function corresponding  kl to such optimal (k, l) for the set V . In our \nsetting, the set V represents the set of vtbl-pointers coming through a particular type switch. While \nthe exact values of these pointers are not known until run-time, their offsets from the module s base \naddress are. This is generally suf.cient to estimate optimal k and l in a compiler setting. In the library \nsetting, we recompute them after a given number of actual collisions in cache. When HV is injective (renders \n0 con.icts on V ), the kl frequency of any given vtbl-pointer vi coming through the type switch does \nnot affect the overall performance of the switch. However when HV is not injective, we would prefer kl \nthe con.ict to happen on less frequent vtbl-pointers. Given a probability p(vi) of each vtbl-pointer \nvi . V we can compute the probability of con.ict rendered by a given Hkl: ... p(vi)2 2k-1 ..vi.V j kl \npkl(V )=. .. p(vi).1 - 2 j=0 .vi.V j .. . p(vi). . kl . .. .. vi.V j kl where V j ={v . V IHkl(v)= j}. \nIn this case, the optimal kl hash function HV can similarly be de.ned as Hkl that min\u00ad kl imizes the \nabove probability of con.ict on V . The probabilities p(vi) can be estimated in a compiler setting through \npro.ling, while in a library setting we let the user enable tracing of frequencies of each vtbl-pointer. \nThis introduces an overhead of an increment into the critical path of execution, and according to our \ntests degrades the perfor\u00admance by 1-2%. This should not be a problem as long as the overall performance \ngains from a smaller probability of con\u00ad.icts happening at run time. Unfortunately, in our tests the \nsigni.cant drop in the number of actual collisions was not re.ected in a noticeable decrease in execution \ntime, which is why we do not enable frequency tracing by default. As we will see in \u00a74.4, this was because \nthe hash function HV ren\u00ad kl ders no con.icts on vtbl-pointers in most cases and the few collisions we \nwere getting before inferring the optimal k and l even in non-frequency-based caching where incomparably \nsmaller than the number of successful cache hits. Assuming uniform distribution of vi in V and substituting \nthe probability p(vi)= 1 , where n =IV I, into the above n formula we get: 2k-1 j j IV I-1 kl pkl(V )= \n.[IV I.0] klj=0 n We use the Iverson bracket [p] here to refer to the outcome j of a predicate p as numbers \n0 or 1. The value IV I represents kl the number of vtbl-pointers vi . V that are mapped to the same location \nj in cache with HV Only one such vtbl\u00ad kl. pointer will actually be present in that cache location at \nany j given time, which is why the value IV I-1 represents the kl number of extra pointers mapped into \nthe entry j on which a collision will happen. The overall probability of con.ict thus only depends on \nthe total number of these extra or con.icting vtbl-pointers. The HV obtained by minimization kl of probability \nof con.ict under uniform distribution of vi in V is thus the same as the original HV that was minimizing \nkl the number of con.icts. An important observation here is that since the exact location of these extra \nvtbl-pointers is not important and only the total number m is, the probability of con.ict under uniform \ndistribution of vi in V is always going to be of the discrete form m , where 0 =m <n. n 4. Evaluation \nWe performed several independent studies of our approach to demonstrate its effectiveness. The .rst study \ncompares our approach to the visitor design pattern and shows that the type switch is comparable or faster \n(\u00a74.1). While we do not advocate for the closed solution of \u00a73.1, we included the comparison of type \nswitching solutions made under open and closed world assumptions (\u00a74.2). Our library supports both solutions \nwith the same surface syntax, which is why we believe many users will try them both before settling on \none. The second study does a similar comparison with built\u00adin facilities of Haskell and OCaml and shows \nthat the open type switch for extensible and hierarchical data types can be almost as ef.cient as its \nequivalent for closed algebraic data types (\u00a74.3). In the third study we looked at how well our caching \nmechanisms deal with some large real-world class hierarchies in order to demonstrate that our performance \nnumbers were not established in overly idealistic conditions (\u00a74.4). In the last study we rewrote an \nexisting visitor-based application using our approach in order to compare the ease of use, readability \nand maintainability of each approach, as well as to show the memory usage and the startup costs associated \nwith our approach in a real application (\u00a74.5). 4.1 Comparison with Visitor Design Pattern Our comparison \nmethodology involves several benchmarks representing various uses of objects inspected with either visitors \nor type switching. The repetitive benchmark (REP) performs calls on differ\u00adent objects of the same dynamic \ntype. This scenario happens in object-oriented setting when a group of polymorphic ob\u00adjects is created \nand passed around (e.g. numerous particles of a given kind in a particle simulation system). We include \nit because double dispatch becomes twice faster (20 vs. 53 cycles) in this scenario compared to others \ndue to hardware cache and call target prediction mechanisms. The sequential benchmark (SEQ) effectively \nuses an ob\u00adject of each derived type only once and then moves on to an object of a different type. The \ncache is typically reused the least in this scenario, which is typical of lookup tables, where each entry \nis implemented with a different derived class.  The random benchmark (RND) is the most representative \nas it randomly makes calls on different objects probably be the most common usage scenario in the real \nworld. Presence of forwarding in any of these benchmarks refers to the common technique used by visitors \nwhere, for class hi\u00aderarchies with multiple levels of inheritance, the visit method of a derived class \nwill provide a default implementation of forwarding to its immediate base class, which, in turn, may \nforward it to its base class, etc. The use of forwarding in visi\u00adtors is a way to achieve substitutability, \nwhich in type switch corresponds to the use of base classes in the case clauses. The class hierarchy \nfor non-forwarding test was a .at hi\u00aderarchy of 100 derived classes, encoding an algebraic data type. \nThe class hierarchy for forwarding tests had two lev\u00adels of inheritance with 5 intermediate base classes \nand 95 derived ones. The benchmarks were executed in the following con.g\u00adurations referred to as Linux \nDesktop and Windows Laptop respectively: Lnx: Dell Dimension\u00ae desktop with Intel\u00ae Pentium\u00ae D (Dual Core) \nCPU at 2.80 GHz; 1GB of RAM; Fedora Core 13 G++ 4.4.5 executed with -O2; x86 binaries  Win: Sony VAIO\u00ae \nlaptop with Intel\u00ae Core i5 460M  CPU at 2.53 GHz; 6GB of RAM; Windows 7 Pro. G++ 4.6.1 / MinGW executed \nwith -O2; x86 binaries MS Visual C++ 2010 Professional x86/x64 binaries with and without Pro.le-Guided \nOptimizations To improve accuracy, timing in all the con.gurations was performed with the help of RDTSC \ninstruction available on x86 processors. For every number reported here we ran 101 experiments timing \n1,000,000 dispatches each (all through either visitors or type switch). The .rst experiment was serv\u00ading \nas a warm-up, during which the optimal caching param\u00adeters were inferred, and typically resulted in an \noutlier with the largest time. Averaged over 1,000,000 dispatches, the number of cycles per dispatch \nin each of the 101 experiments was sorted and the median was chosen. We preferred median to average to \ndiminish the in.uence of other applications and OS interrupts as well as to improve reproducibility of \ntimings between the runs of application. In particular, in the diagnostic boot of Windows, where the \nminimum of drivers and applications are loaded, we were getting the same num\u00adber of cycles per iteration \n70-80 out of 101 times. Timings in non-diagnostic boots had somewhat larger absolute val\u00adues, however \nthe relative performance of type switch against visitors remained unchanged and equally well reproducible. \nTo understand better the relative numbers of Figure 6, we present in Figure 5 few absolute timings taken \nby visi- Figure 5. Absolute timings for different benchmarks tors and open type switch to execute an \niteration of a given benchmark. These absolute timings correspond to the rela\u00adtive numbers from column \nOpen/G++/Win of Figure 6. The actual bars show the timings without forwarding, while the black lines \nindicate where the corresponding bar would be in the presence of forwarding. It is easy to see that visitors \ngenerally become slower in the presence of forwarding due to extra call, while type switch becomes faster \ndue to smaller jump table. As discussed, both timings are much smaller for repetitive benchmark due to \nhardware cache. Figure 6 provides a broader overview of how both tech\u00adniques compare under different \ncompiler/platform con.gu\u00adrations. The values are given as percentages of performance increase against \nthe slower technique. Open Closed G++ MS Visual C++ G++ MS Visual C++ Lnx Win PGO w/o PGO Lnx Win PGO \nw/o PGO x86-32 x86-32 x86-32 x86-64 x86-32 x86-64 x86-32 x86-32 x86-32 x86-64 x86-32 x86-64 REP 16% 14% \n1% 18% 2% 37% 124% 640% 603% 122% 467% 470% 100% 29% 35% 41% 15% 20% 76% 30% 32% 37% 10% 6% SEQ RND 56% \n56% 12% 0% 48% 9% 22% 19% 2% 5% 46% 46% ForwardingREP SEQ RND 33% 55% 78% 22% 233% 25% 8% 135% 3% 17% \n135% 4% 24% 193% 13% 36% 32% 23% 53% 86% 88% 49% 290% 33% 24% 48% 8% 11% 139% 1% 20% 12% 18% 36% 24% \n16% Figure 6. Relative performance of type switching vs. visi\u00adtors. Numbers in regular font (e.g. 14%), \nindicate when type switching was faster than visitors, while underlined numbers in bold (e.g. 18%), indicate \nwhen visitors were faster by cor\u00adresponding percentage. We can see that type switching wins by a good \nmargin when implemented with tag switch (\u00a73.1) as well as in the presence of at least one level of forwarding. \nNote that the numbers are relative, and thus the ratio depends on both the performance of virtual function \ncalls and the performance of switch statements. Visual C++ was generating faster vir\u00adtual function calls, \nwhile GCC was generating faster switch statements, which is why their relative performance seem to be \nmuch more favorable for us in the case of GCC. Similarly, the code for x86-64 is only slower relatively: \nthe actual time spent for both visitors and type switching was smaller than that for x86-32, but it was \nmuch smaller for visitors than type switching, which resulted in worse relative performance. Lastly, \nthe code on the critical path of our type switch implementation bene.ts signi.cantly from branch hinting \nas some branches are much more likely than others. We use the branch hinting directives in GCC to guide \nthe compiler, but, unfortunately, Visual C++ does not provide any similar facilities. Instead, Microsoft \nsuggests using Pro.le-Guided Optimizations (PGO) to achieve the same, which is why we list the results \nfor Visual C++ both with and without pro.le\u00adguided optimizations.  4.2 Open vs. Closed Type Switch \nWith only a few exceptions, we saw in the Figure 6 that the performance of the closed tag switch dominates \nthe per\u00adformance of the open type switch. We believe that the dif\u00adference, often signi.cant, is the price \none pays for the true openness of the vtable pointer memoization solution. As we mentioned in \u00a73.1, the \nuse of tags, even when allo\u00adcated by a compiler, may require integration efforts to ensure that different \nDLLs have not reused the same tags. Random\u00adization of tags, similar to a proposal of Garrigue [22], will \nnot eliminate the problem and will surely replace jump tables in switches with decision trees. This will \nlikely signi.cantly degrade the numbers for the part of Figure 6 representing closed tag switch, since \nthe tags in our experiments were all sequential and small. The reliance of a tag switch on static cast \nhas severe limi\u00adtations in the presence of multiple inheritance, and thus is not as versatile as open \ntype switch. Overcoming this problem will either require the use of dynamic cast or techniques similar \nto vtable pointer memoization, which will likely de\u00adgrade tag switch s performance numbers even further. \nNote also that the approach used to implement open type switch can be used to implement both .rst-.t \nand best-.t semantics, while the tag switch is only suitable for best\u00ad.t semantics. Their complexity \nguarantees also differ: open type switch is constant on average, but slow on the .rst call with given \nsubobject. Tag switch is logarithmic in the size of the class hierarchy (assuming a balanced hierarchy), \nincluding the .rst call. This last point can very well be seen in Figure 6, where the performance of \na closed solution degrades signi.cantly in the presence of forwarding, while the performance of an open \nsolution improves. 4.3 Comparison with OCaml and Haskell In this test, we timed small OCaml and Haskell \napplications performing our sequential benchmark on an algebraic data type of 100 variants. Corresponding \nC++ applications were working with a .at class hierarchy of 100 derived classes. The difference between \nthe C++ applications lies in the en\u00adcoding used. Kind encoding is the same as Tag encoding, but it does \nnot require substitutability, and thus can be im\u00adplemented with a direct switch on tags without a ReMatch \nloop. It is only supported through specialized syntax in our library as it differs from the Tag encoding \nonly semantically. We used the optimizing OCaml compiler ocamlopt.opt version 3.11.0 working under the \nVisual C++ toolset as well as the Glasgow Haskell Compiler version 7.0.3 (with -O switch) working under \nthe MinGW toolset. The C++ ap\u00adplications were compiled with Visual C++ as well and all the tests were \nperformed on the Windows 7 laptop. Similar to comparison with visitors, the timing results presented \nin Figure 7 are averaged over 101 measurements and show the number of seconds it took to perform a 1,000,000 \ndecompo\u00adsitions within our sequential benchmark. We compare here time and not cycles, as that was the \nonly common measure\u00adment in all three environments. Figure 7. Performance comparison with OCaml &#38; \nHaskell  4.4 Dealing with real-world class hierarchies For this experiment, we used a class hierarchy \nbenchmark previously used in the literature to study ef.ciency of type inclusion testing and dispatching \ntechniques [17, 31, 50, 57]. We use the names of each benchmark from Vitek et al [50, Table 2], since \nthe set of benchmarks we were working with was closest (though not exact) to that work. While not all \nclass hierarchies originated from C++, for this experiment it was more important for us that the hier\u00adarchies \nwere man-made. While converting the hierarchies into C++, we had to prune inaccessible base classes (di\u00adrect \nbase class that is already an indirect base class) when used with repeated inheritance in order to satisfy \nsemantic requirements of C++. We maintained the same number of virtual functions present in each class \nas well as the number of data members; the benchmarks, however, did not preserve the exact types of those. \nThe data in Figure 8 shows various parameters of the class hierarchies in each benchmark, after their \nadoption to C++. LIBRARY LANGUAGE CLASSES PATHS HEIGHT ROOTS LEAFS BOTH PARENTS CHILDREN AVG MAX AVG \nMAX DG2 SMALLTALK 534 534 11 2 381 1 1 1 3.48 59 DG3 SMALLTALK 1356 1356 13 2 923 1 1 1 3.13 142 ET+ \nC++ 370 370 8 87 289 79 1 1 3.49 51 GEO EIFFEL 1318 13798 14 1 732 0 1.89 16 4.75 323 JAV JAVA 604 792 \n10 1 445 0 1.08 3 4.64 210 LOV EIFFEL 436 1846 10 1 218 0 1.72 10 3.55 78 NXT OBJECTIVE-C 310 310 7 2 \n246 1 1 1 4.81 142 SLF SELF 1801 36420 17 51 1134 0 1.05 9 2.76 232 UNI C++ 613 633 9 147 481 117 1.02 \n2 3.61 39 VA2a SMALLTALK 3241 3241 14 1 2582 0 1 1 4.92 249 VA2k SMALLTALK 2320 2320 13 1 1868 0 1 1 \n5.13 240 VW1 SMALLTALK 387 387 9 1 246 0 1 1 2.74 87 VW2 SMALLTALK 1956 1956 15 1 1332 0 1 1 3.13 181 \nOVERALLS 15246 63963 17 298 10877 199 1.11 16 3.89 323 Figure 8. Benchmark class hierarchies  The number \nof paths represents the number of distinct inheritance paths from the classes in the hierarchy to the \nroots of the hierarchy. This number re.ects the number of possible subobjects in the hierarchy. The roots \nlisted in the table are classes with no base classes. We will subsequently use the term non-leaf to refer \nto the possible root of a subhierarchy. Leafs are classes with no children, while both refers to utility \nclasses that are both roots and leafs and thus neither have base nor derived classes. The average for \nthe number of parents and the number of children were computed only among the classes having at least \none parent or at least one child correspondingly. With few useful exceptions, it generally makes sense \nto apply type switch only to non-leaf nodes of the class hi\u00aderarchy. 71% of the classes in the entire \nbenchmarks suite were leaf classes. Out of the 4369 non-leaf classes, 36% were spawning a subhierarchy \nof only 2 classes (including the root), 15% a subhierarchy of 3 classes, 10% of 4, 7% of 5 and so forth. \nTurning this into a cumulative distribution, a% of subhierarchies had more than b classes in them: a \n1% 3% 5% 10% 20% 25% 50% 64% 100% b 700 110 50 20 10 7 3 2 1 These numbers re.ect the percentage of \nuse cases one may expect in the real word that have a given number of case clauses in them. For each \nnon-leaf class A we created a function perform\u00ading a type switch on every possible derived class Di of \nit as well as itself. The function was then executed with every possible subobject Di -sj >A it can possibly \nbe applied to, given the static type A of the subject. It was executed multi\u00adple but the same number \nof times on each subobject to ensure uniformity on one side (since we do not have the data about the \nactual probabilities of each subobject in the benchmark hierarchies) as well as let the type switch infer \nthe optimal parameters k and l of its cache indexing function HV . We kl then plotted a point in chart \nof Figure 9 relating 2 charac\u00adteristics of each of the 4396 type switches tested: the opti\u00admal computed \nprobability of con.ict p achieved by the type switch and the number of subobjects n that came through \nthat type switch. The actual frequencies of collisions were within one tenth of a percentage point of \nthe computed prob\u00adabilities, which is why we did not use them in the chart. To account for the fact that \nmultiple experiments could have re\u00adsulted in the same pair (n, p), we use a shadow of each point to re.ect \nsomewhat the number of experiments yielding it. The curves on which the results of experiments line up \ncorrespond to the fact that under uniform distribution of n subobjects, only a .nite number of different \nvalues repre\u00adsenting the probability of con.ict p is possible. In particular, all such values p , where \n0 = m < n. The number m = m n re.ects the number of subobjects an optimal cache indexing function HV \ncould not allocate their own entry for and we kl showed in \u00a73.8 that the probability of con.ict under \nuniform distribution of n subobjects depends only on m. The curves thus correspond to graphs of functions \ny for different = m x Figure 9. Probability of con.ict in real hierarchies values of m. The points on \nthe same curve (which becomes a line on a log-log plot) all share the same number m of ex\u00adtra vtbl-pointers \nthat optimal cache indexing function could not allocate individual entries for. While it is hard to see \nfrom the chart, 87.5% of all the points on the chart lay on the X-axis, which means that the optimal \nhash function for the corresponding type switches had no con.icts at all (m = 0). In other words, only \nin 12.5% of cases the optimal HV for the set of vtbl-pointers V kl coming through a given type switch \nhad non-zero probability of con.ict. Experiments laying on the .rst curve amount to 5.58% of subhierarchies \nand represent the cases in which optimal HV had only one extra vtbl-pointer (m = 1). kl 2.63% of experiments \nhad HV with 2 con.icts, 0.87% with kl 3 and so forth as shown in Figure 10(K +1). m 0 K +1 87.50% 1 5.58% \n2 2.63% 3 0.87% 4 0.69% 5 0.69% 6 0.30% >6 1.76% K 72.55% 12.27% 4.87% 2.61% 1.42% 0.94% 0.80% 4.55% \nFigure 10. Percentage of type switches with given number of con.icts (m) under different size constraints \n In cases when the user is willing to trade performance for better space ef.ciency she may restrict \nk to [K, K] instead of [K, K + 1] as discussed in \u00a73.8. We redid all the 4396 experiments under this \nrestriction and obtained a similar histogram shown in Figure 10(K). The average probability of con.ict \nover the entire set increased from 0.011 to 0.049, while the maximum probability of con.ict increased \nfrom 0.333 to 0.375. The average load factor of the cache expectedly increased from 75.45% to 82.47%. \nIt is important to understand that the high ratio of cases in which the hash function could deliver perfect \nindexing does not indicate that the hash function we used is better than other hash functions. It does \nindicate instead that the values representing vtbl-pointers in a given application are not random at \nall and are particularly suitable for such a hash function.  4.5 Refactoring an existing visitors based \napplication For this experiment, we reimplemented a visitor based C++ pretty printer for Pivot[15] using \nMach7. The Pivot s class hierarchy consists of 154 node kinds representing various entities in the C++ \nprogram. The original code had 8 visitor classes each handling 5, 7, 8, 10, 15, 17, 30 and 63 cases, \nwhich we turned into 8 match statements with correspond\u00ading numbers of case clauses. Most of the rewrite \nwas per\u00adformed by sed-like replaces that converted visit methods into respective case-clauses. In several \ncases we had to manually reorder case-clauses to avoid redundancy as visit-methods for base classes were \ntypically coming before the same for derived, while for type switching we needed them to come after due \nto .rst-.t semantics. Redundancy checking support provided by Mach7 was invaluable in .nding all such \ncases. Both pretty printers were executed on a set of header .les from the C++ standard library and the \nproduced output of both program was byte-to-byte the same. We timed execu\u00adtion of the pretty printing \nphase (not including loading and termination of the application or parsing of the source .le) and observed \nthat on small .les (e.g. those from C run-time library and few small C++ .les) visitors-based implementa\u00adtion \nwas faster because the total number of nodes in AST and thus calls did not justify our set-up calls. \nIn particular, visitor-based implementation of the pretty printer was faster on .les of 44 588 lines \nof code, with average 136 lines per those inputs, where visitors win. On these input .les, visi\u00adtors \nare faster by 1.17% 21.42% with an average speed-up of 8.75%. Open type switch based implementation of \nthe pretty printer was faster on .les of 144 9851 lines of code, with average 3497 lines per those input \n.les, where open type switch wins. On these inputs, open type switch is faster by 0.18% 32.99% with \nan average speed-up of 5.53%. Figure 11. Memory usage in real application The bars represent the total \nsize of memory in bytes each of the 8 match statements (marked A-H) used. Information[n/c] next to the \nletter indicates the actual number of differ\u00adent subobjects (i.e. vtbl-pointers) n that came through \nthat match statement, and the number of case clauses c the match statement had (the library uses c as \nan estimate of n). n is also the number of cases the corresponding match statement had to be executed \nsequentially (instead of a direct jump). The lower part of each bar (with respect to dividing line) corresponds \nto the memory used by cache, while the upper part to the memory used by the hash table. The ratio of \nthe darker section of each part to the entire part indicates the load factors of cache and hash-table \nrespectively. The black box additionally indicates the proportion of cache entries that are allocated \nfor only one vtbl-pointer and thus never result in a cache miss. The actual number of hits and misses \nfor each of the match statements is indicated on top of the corresponding column. The sum of them is \nthe total number of calls made. The number of misses is always larger than or equal to n since we need \nto execute the switch sequentially on each of them once in order to memoize the outcome. The library \nalways preallocates memory for at least 8 sub\u00adobjects to avoid unnecessary recomputations of optimal \npa\u00adrameters k and l this is the case with the last 3 match statements. In all other cases it allocates \nthe memory pro\u00adportional to 2K+1 where 2K-1 < max(n, c)= 2K . We make c a parameter, because in a library \nsetting n is not known up front and estimating it with c allows us to avoid unnecessary recomputations \nof l and k even further. The table does not have to be hash table and can be im\u00adplemented with any other \ncontainer i.e. sorted vector, map etc. that let us .nd quickly by a given vtbl-pointer the data associated \nwith it. In fact we provide a slightly less ef.cient caching container that avoids the table altogether, \nthus sig\u00adni.cantly reducing the memory requirements instead.  4.6 Limitations Currently the de.nition \nof each class used in a case clause must be visible to the compiler because dynamic cast op\u00aderator used \nin the type switch does not allow incomplete types as a target type. For particularly large type switches \n(e.g. >1000 case clauses) this may easily reach some com\u00adpiler limitations. Both GCC and Visual C++, \nfor example, could not generate object .les for such translation units sim\u00adply because the sheer size \nof v-tables and other compiler data in it were exceeding the limits. The problem is not spe\u00adci.c to our \ntechnique though and allowing dynamic cast on classes that were declared but not de.ned yet would solve \nthe problem. While it might be reasonable to expect from linkers to layout v-tables close to each other \n the property that makes our hashing function ef.cient they are not required to do so. We believe, nevertheless, \nthat should our approach be\u00adcome popular through the library implementation, its com\u00adpiler implementation \nwill encourage compiler vendors to en\u00adforce the property in order to keep the type switching fast.  \n5. Related Work Lookup caches have been long used to reduce the overhead of dynamically-bound message \npassing in Smalltalk [49]. Inline caching improves on that by noting that the type of the receiver at \na given call site rarely varies so that the call instruction can be speculatively modi.ed to jump directly \nto a previously looked up method [13]. In this case, the method must ensure that the type of the receiver \nhas not changed and redirect the call to generic lookup otherwise. The effects of inline caching on modern \narchitectures can be seen through hardware call target prediction, which in our case is exempli.ed by \nrepetitive benchmark: both virtual function calls and the underlying jump-table implementation of the \nMatch-statement are about twice as fast as usual. Polymorphic Inline Caches [27] generalize the idea \nof in\u00adline caches further by building a decision tree in the method prologue that caches all lookup results. \nThe main difference of this approach from our work is that it requires code gener\u00adation at run time, \nwhile we do not require re-compilation, re\u00adlinking or any computations in case of dynamic linking. The \nreason for this is the difference in the initial setting: they map an arbitrary number of receiver types \nto an arbitrary number of implementations, while we map an arbitrary number of receivers to a .xed number \nof jump targets. This lets us gen\u00aderate code at compile time that incorporates both the initial and memoized \nexecution. Extensible Visitors with Defaults [55, \u00a74.2] offer a solu\u00adtion to the extensibility problem \nof visitors. The visitation interface hierarchy can easily be grown linearly, but inde\u00adpendent extensions \nby different programmers require man\u00adual coordination. In addition to the double dispatch, the so\u00adlution \nincurs two additional virtual calls and a dynamic cast for each level of visitor extension. The solution \nis simpler with virtual inheritance, which adds even more indirections. L\u00a8 oh and Hinze proposed to extend \nHaskell s type system with open data types and open functions [35]. The solution allows top-level data \ntypes and functions to be marked as open with concrete variants and overloads de.ned anywhere in the \nprogram. The semantics of open extension is given by transformation into a single module, which assumes \na whole-program view and thus is not an open solution by our de.nition. Besides, open data types are \nextensible but not hierarchical, which avoids the problems discussed here. Andrew Kennedy et al [30] \nconsidered encoding of gen\u00aderalized algebraic data types [42] using visitor design pat\u00adterns in C#. That \ntranslation made essential use of generic methods, the equivalent of virtual function template (as they \nwould be called if such functionalities existed in C++) to handle some of the open set aspects of GADTs. \nPolymorphic variants in OCaml [22] allow the addition of new variants, while de.ning subtyping on them. \nThe sub\u00adtyping, however, is not de.ned between the variants, but be\u00adtween combinations of them. This \nmaintains disjointness be\u00adtween values from different variants and makes an important distinction between \nextensible sum types like polymorphic variants and extensible hierarchical sum types like classes. Our \nmemoization device can be used to implement pattern matching on polymorphic variants as well. Tom is \na pattern-matching compiler that can be used to\u00adgether with Java, C or Eiffel to bring a common pattern \nmatching and term rewriting syntax into the languages [38]. Its type patterns and %match statement can \nbe used as a type switch, however, their implementation is based on decision trees and an instanceof-like \npredicate. Pattern matching in Scala [39] also supports type switch\u00ading through type patterns. The language \nsupports extensi\u00adble and hierarchical data types, but their handling in a type switching constructs varies. \nSealed classes are handled with an ef.cient switch over all tags, while extensible classes are handled \nwith a combination of an InstanceOf operator and a decision tree [19]. 6. Conclusions and Future Work \nType switching is an open alternative to the visitor design pattern that overcomes the restrictions, \ninconveniences, and dif.culties in teaching and using visitors. Our implementa\u00adtion signi.cantly outperforms \nthe visitor design pattern in most cases and roughly equals it otherwise. This is the case even though \nwe use a library implementation and highly op\u00adtimized production-quality compilers. An important bene.t \nof our solution is that it does not require any changes to the C++ object-model or require any computations \nat load time. To provide a complete solution, we use the same syntax for closed sets of types, where \nour performance roughly equals the equivalent built-in features in functional lan\u00adguages, such as Haskell \nand OCaml. We prove the uniqueness of vtbl-pointers in the pres\u00adence of RTTI. This is potentially useful \nin other compiler optimizations that depend on the identity of subobjects. Our memoization device can \nalso become valuable in opti\u00admizations that require mapping run-time values to execution paths, and is \nespecially useful in library setting. Using a library implementation was essential for exper\u00adimentation \nand for being able to test our ideas on multi\u00adple production-quality compiler systems. However, now we \nhope to re-implement our ideas in a compiler. This would allow us to improve further surface syntax, \ndiagnostics, and performance. Acknowledgments We would like to thank Xavier Leroy and Luc Maranget for \nvaluable feedback, and suggestions for improvements on the initial idea; Gregory Berkolaiko and Suhasini \nSubba Rao for ideas related to minimization of con.icts; Jaakko J\u00a8arvi for assistance in comparison to \nother languages; and, Peter Pirkelbauer, Andrew Sutton, and Abe Skolnik for useful discussions that helped \nshape this work. We also bene.tted greatly from the insightful comments by our anonymous reviewers. Finally, \nwe would like to thank Karel Driesen for letting us use his class hierarchies benchmark for this work. \nThis work was partially supported by NSF grants CCF-0702765, CCF-1043084, and CCF-1150055.  References \n[1] Clang: a C language family frontend for LLVM. http://clang.llvm.org/, 2007. [2] Liz: A System for \nAxiomatic Programming. http://liz.axiomatics.org/, 2012. [3] A. Appel, L. Cardelli, K. Fisher, C. Gunter, \nR. Harper, X. Leroy, M. Lillibridge, D. B. MacQueen, J. Mitchell, G. Morrisett, J. H. Reppy, J. G. Riecke, \nZ. Shao, and C. A. Stone. Principles and a preliminary design for ML2000. March 1999. [4] L. Augustsson. \nCompiling pattern matching. In Proc. of a conference on Functional programming languages and com\u00adputer \narchitecture, pages 368 381, New York, NY, USA, 1985. Springer-Verlag New York, Inc. [5] L. Cardelli. \nCompiling a functional language. In Proc. of the 1984 ACM Symposium on LISP and functional programming, \nLFP 84, pages 208 217, New York, NY, USA, 1984. ACM. [6] L. Cardelli, J. Donahue, M. Jordan, B. Kalsow, \nand G. Nel\u00adson. The Modula-3 type system. In Proc. of the 16th ACM SIGPLAN-SIGACT symposium on Principles \nof programming languages, POPL 89, pages 202 212, New York, NY, USA, 1989. ACM. [7] Y. Caseau. Ef.cient \nhandling of multiple inheritance hier\u00adarchies. In Proc. of the 8th conference on Object-oriented programming \nsystems, languages, and applications, OOPSLA 93, pages 271 287, New York, NY, USA, 1993. ACM. [8] CodeSourcery, \nCompaq, EDG, HP, IBM, Intel, Red Hat, and SGI. Itanium C++ ABI, March 2001. http://www.codesourcery.com/public/cxx-abi/. \n[9] N. H. Cohen. Type-extension type test can be performed in constant time. ACM Trans. Program. Lang. \nSyst., 13(4):626 629, Oct. 1991. [10] W. R. Cook. Object-oriented programming versus abstract data types. \nIn Proc. of the REX School/Workshop on Founda\u00adtions of Object-Oriented Languages, pages 151 178, London, \nUK, 1991. Springer-Verlag. [11] O.-J. Dahl. SIMULA 67 common base language, (Norwegian Computing Center. \nPublication). 1968. ISBN B0007JZ9J6. [12] J. Dean, G. DeFouw, D. Grove, V. Litvinov, and C. Chambers. \nVortex: an optimizing compiler for object-oriented languages. In Proc. of the 11th ACM SIGPLAN conference \non Object\u00adoriented programming, systems, languages, and applications, OOPSLA 96, pages 83 100, New York, \nNY, USA, 1996. [13] L. P. Deutsch and A. M. Schiffman. Ef.cient implementa\u00adtion of the smalltalk-80 system. \nIn Proc. of the 11th ACM SIGACT-SIGPLAN symposium on Principles of programming languages, POPL 84, pages \n297 302, New York, NY, USA, 1984. ACM. [14] E. W. Dijkstra. Guarded commands, non-determinacy and formal \nderivation of programs. Jan. 1975. [15] G. Dos Reis and B. Stroustrup. A principled, complete, and ef.cient \nrepresentation of C++. In Proc. Joint Conference of ASCM 2009 and MACIS 2009, volume 22 of COE Lecture \nNotes, pages 407 421, December 2009. [16] K. Driesen and U. H\u00a8olzle. The direct cost of virtual func\u00adtion \ncalls in C++. In Proc. of the 11th ACM SIGPLAN con\u00adference on Object-oriented programming, systems, languages, \nand applications, OOPSLA 96, pages 306 323, New York, NY, USA, 1996. ACM. [17] R. Ducournau. Perfect \nhashing as an almost perfect subtype test. ACM Trans. Program. Lang. Syst., 30(6):33:1 33:56, Oct. 2008. \nISSN 0164-0925. [18] M. A. Ellis and B. Stroustrup. The annotated C++ refer\u00adence manual. Addison-Wesley \nLongman Publishing Co., Inc., Boston, MA, USA, 1990. ISBN 0-201-51459-1. [19] B. Emir. Object-oriented \npattern matching. PhD thesis, Lausanne, 2007. [20] M. D. Ernst, C. S. Kaplan, and C. Chambers. Predicate \ndispatching: A uni.ed theory of dispatch. In ECOOP 98, the 12th European Conference on Object-Oriented \nProgramming, pages 186 211, Brussels, Belgium, July 20-24, 1998. [21] E. Gamma, R. Helm, R. E. Johnson, \nand J. M. Vlissides. De\u00adsign patterns: Abstraction and reuse of object-oriented de\u00adsign. In Proc. of \nthe 7th European Conference on Object-Oriented Programming, ECOOP 93, pages 406 431, Lon\u00addon, UK, UK, \n1993. Springer-Verlag. [22] J. Garrigue. Programming with polymorphic variants. In ACM Workshop on ML, \nSept. 1998. [23] M. Gibbs and B. Stroustrup. Fast dynamic casting. Softw. Pract. Exper., 36:139 156, \nFebruary 2006. [24] N. Glew. Type dispatch for named hierarchical types. In Proc. of the 4th ACM SIGPLAN \ninternational conference on Func\u00adtional programming, ICFP 99, pages 172 182, New York, NY, USA, 1999. \n[25] C. Grothoff. Walkabout revisited: The runabout. In ECOOP 2003 -Object-Oriented Programming, pages \n103 125. Springer-Verlag, 2003. [26] R. Harper and G. Morrisett. Compiling polymorphism us\u00ading intensional \ntype analysis. In Proc. of the 22nd ACM SIGPLAN-SIGACT symposium on Principles of programming languages, \nPOPL 95, pages 130 141, New York, NY, USA, 1995. ACM. [27] U. H\u00a8olzle, C. Chambers, and D. Ungar. Optimizing \ndynamically-typed object-oriented languages with polymor\u00adphic inline caches. In Proc. of the European \nConference on Object-Oriented Programming, volume 512 of Lecture Notes in Computer Science, pages 21 \n38, Berlin, Germany, 1991. Springer-Verlag. [28] International Organization for Standardization. ISO/IEC \n14882:2011: Programming languages: C++. Geneva, Switzerland, 3rd edition, 2011. [29] S. P. Jones, editor. \nHaskell 98 Language and Libraries The Revised Report. Cambridge University Press, Cambridge, England, \n2003.  [30] A. Kennedy and C. V. Russo. Generalized algebraic data types and object-oriented programming. \nIn Proc. of the 20th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, \nand applications, OOPSLA 05, pages 21 40, New York, NY, USA, 2005. ACM. [31] A. Krall, J. Vitek, and \nR. N. Horspool. Near optimal hierar\u00adchical encoding of types. In In Proc. European Conference on Object-Oriented \nProgramming, ECOOP 97, Lecture Notes in Computer Science, pages 128 145. Springer-Verlag, 1997. [32] \nS. Krishnamurthi, M. Felleisen, and D. Friedman. Synthesiz\u00ading object-oriented and functional design \nto promote re-use. In E. Jul, editor, ECOOP 98 -Object-Oriented Programming, volume 1445 of Lecture Notes \nin Computer Science, pages 91 113. Springer Berlin / Heidelberg, 1998. [33] B. Liskov. Keynote address \n-data abstraction and hierarchy. In OOPSLA 87: Addendum to the proc. on Object-oriented programming systems, \nlanguages and applications, pages 17 34, New York, NY, USA, 1987. ACM Press. [34] B. Liskov, R. R. Atkinson, \nT. Bloom, E. B. Moss, R. Schaffert, and A. Snyder. Clu reference manual. Technical report, Cambridge, \nMA, USA, 1979. [35] A. L\u00a8oh and R. Hinze. Open data types and open functions. In Proc. of the 8th ACM \nSIGPLAN international conference on Principles and practice of declarative programming, PPDP 06, pages \n133 144, New York, NY, USA, 2006. ACM. [36] Microsoft Research. Phoenix compiler and shared source common \nlanguage infrastructure. http://research.microsoft.com/phoenix/, 2005. [37] R. Milner, M. Tofte, and \nR. Harper. The De.nition of Standard ML. MIT Press, Cambridge, MA, USA, 1990. [38] P.-E. Moreau, C. Ringeissen, \nand M. Vittek. A pattern match\u00ading compiler for multiple target languages. In Proc. of the 12th international \nconference on Compiler construction, CC 03, pages 61 76, Berlin, Heidelberg, 2003. Springer-Verlag. [39] \nM. Odersky, V. Cremet, I. Dragos, G. Dubochet, B. Emir, S. Mcdirmid, S. Micheloud, N. Mihaylov, M. Schinz, \nE. Sten\u00adman, L. Spoon, and M. Zenger. An overview of the Scala pro\u00adgramming language (2nd edition). Technical \nReport LAMP\u00adREPORT-2006-001, Ecole Polytechnique Federale de Lau\u00adsanne, 2006. [40] B. C. Oliveira, M. \nWang, and J. Gibbons. The visitor pat\u00adtern as a reusable, generic, type-safe component. In Proc. of the \n23rd ACM SIGPLAN conference on Object-oriented pro\u00adgramming systems languages and applications, OOPSLA \n08, pages 439 456, New York, NY, USA, 2008. ACM. [41] J. Palsberg and C. B. Jay. The essence of the visitor \npattern. In Proc. of the 22nd International Computer Software and Ap\u00adplications Conference, COMPSAC 98, \npages 9 15, Washing\u00adton, DC, USA, 1998. IEEE Computer Society. [42] S. Peyton Jones, D. Vytiniotis, S. \nWeirich, and G. Washburn. Simple uni.cation-based type inference for GADTs. In Proc. of the 11th ACM \nSIGPLAN international conference on Func\u00adtional programming, ICFP 06, pages 50 61, New York, NY, USA, \n2006. ACM. [43] T. Ramananandro, G. Dos Reis, and X. Leroy. Formal ver\u00adi.cation of object layout for \nC++ multiple inheritance. In Proc. of the 38th annual ACM SIGPLAN-SIGACT symposium on Principles of programming \nlanguages, POPL 11, pages 67 80, New York, NY, USA, 2011. ACM. [44] J. G. Rossie, Jr. and D. P. Friedman. \nAn algebraic semantics of subobjects. In Proc. of the 10th conference on Object-oriented programming \nsystems, languages, and applications, OOPSLA 95, pages 187 199, New York, NY, USA, 1995. ACM. [45] L. \nSchubert, M. Papalaskaris, and J. Taugher. Determining type, part, color, and time relationships. Computer, \n16:53 60, 1983. ISSN 0018-9162. [46] D. A. Spuler. Compiler Code Generation for Multiway Branch Statements \nas a Static Search Problem. Technical Report Technical Report 94/03, James Cook University, Jan. 1994. \n[47] B. Stroustrup. Multiple inheritance for C++. In Proc. of the Spring 87 EUUG Conference, EUUG 87, \nMay 1987. Revised version in AT&#38;T C++ Translator Release Notes, June 1989. Also, USENIX Computing \nSystems, V2 no 4, Fall 1989, pp 367-396. [48] Tom Duff. Duff s Device, Aug 1988. http://www.lysator.liu.se/c/duffs-device.html. \n[49] D. Ungar and D. Patterson. Berkeley smalltalk: Who knows where the time goes? In G. Krasner, editor, \nSmalltalk-80: Bits of History and Words of Advice, pages 189 206. Addison-Wesley, 1983. ISBN 0-201-11669-3. \n[50] J. Vitek, R. N. Horspool, and A. Krall. Ef.cient type inclu\u00adsion tests. In Proc. of the 12th ACM \nSIGPLAN conference on Object-oriented programming, systems, languages, and appli\u00adcations, OOPSLA 97, \npages 142 157, New York, NY, USA, 1997. ACM. [51] D. Vytiniotis, G. Washburn, and S. Weirich. An open \nand shut typecase. In Proc. of the 2005 ACM SIGPLAN international workshop on Types in languages design \nand implementation, TLDI 05, pages 13 24, New York, NY, USA, 2005. ACM. [52] P. Wadler. The expression \nproblem. Mail to the java-genericity mailing list, November 1998. [53] D. Wasserrab, T. Nipkow, G. Snelting, \nand F. Tip. An op\u00aderational semantics and type safety proof for multiple inheri\u00adtance in C++. In Proc. \nof the 21st annual ACM SIGPLAN con\u00adference on Object-oriented programming systems, languages, and applications, \nOOPSLA 06, pages 345 362, New York, NY, USA, 2006. ACM. [54] N. Wirth. Type extensions. ACM Trans. Program. \nLang. Syst., 10(2):204 214, Apr. 1988. [55] M. Zenger and M. Odersky. Extensible algebraic datatypes \nwith defaults. In Proc. of the 6th ACM SIGPLAN inter\u00adnational conference on Functional programming, ICFP \n01, pages 241 252, New York, NY, USA, 2001. ACM. [56] M. Zenger and M. Odersky. Independently extensible \nsolu\u00adtions to the expression problem. In Proc. FOOL 12, Jan. 2005. [57] Y. Zibin and J. Y. Gil. Ef.cient \nsubtyping tests with PQ\u00adencoding. In Proc. of the 16th ACM SIGPLAN conference on Object-oriented programming, \nsystems, languages, and appli\u00adcations, OOPSLA 01, pages 96 107, New York, NY, USA, 2001. ACM.   \n\t\t\t", "proc_id": "2384616", "abstract": "<p>Selecting operations based on the run-time type of an object is key to many object-oriented and functional programming techniques. We present a technique for implementing open and efficient type switching on hierarchical extensible data types. The technique is general and copes well with C++ multiple inheritance. To simplify experimentation and gain realistic performance using production-quality compilers and tool chains, we implement a type switch construct as an ISO C++11 library, called Mach7. This library-only implementation provides concise notation and outperforms the visitor design pattern, commonly used for case analysis on types in object-oriented programming. For closed sets of types, its performance roughly equals equivalent code in functional languages, such as OCaml and Haskell. The type-switching code is easier to use and is more expressive than hand-coded visitors are. The library is non-intrusive and circumvents most of the extensibility restrictions typical of the visitor design pattern. It was motivated by applications involving large, typed, abstract syntax trees.</p>", "authors": [{"name": "Yuriy Solodkyy", "author_profile_id": "81337493686", "affiliation": "Texas A&#38;M University, College Station, TX, USA", "person_id": "P3856218", "email_address": "yuriys@cse.tamu.edu", "orcid_id": ""}, {"name": "Gabriel Dos Reis", "author_profile_id": "81309496659", "affiliation": "Texas A&#38;M University, College Station, TX, USA", "person_id": "P3856219", "email_address": "gdr@cse.tamu.edu", "orcid_id": ""}, {"name": "Bjarne Stroustrup", "author_profile_id": "81100106139", "affiliation": "Texas A&#38;M University, College Station, TX, USA", "person_id": "P3856220", "email_address": "bs@cse.tamu.edu", "orcid_id": ""}], "doi_number": "10.1145/2384616.2384686", "year": "2012", "article_id": "2384686", "conference": "OOPSLA", "title": "Open and efficient type switch for C++", "url": "http://dl.acm.org/citation.cfm?id=2384686"}