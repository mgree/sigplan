{"article_publication_date": "06-12-2005", "fulltext": "\n Composing Security Policies with Polymer Lujo Bauer Jay Ligatti David Walker Carnegie Mellon University \nPrinceton University Princeton University lbauer@cmu.edu jligatti@cs.princeton.edu dpw@cs.princeton.edu \n Abstract We introduce a language and system that supports de.nition and composition of complex run-time \nsecurity policies for Java applica\u00adtions. Our policies are comprised of two sorts of methods. The .rst \nis query methods that are called whenever an untrusted application tries to execute a security-sensitive \naction. A query method returns a suggestion indicating how the security-sensitive action should be handled. \nThe second sort of methods are those that perform state updates as the policy s suggestions are followed. \nThe structure of our policies facilitates composition, as policies can query other policies for suggestions. \nIn order to give program\u00admers control over policy composition, we have designed the system so that policies, \nsuggestions, and application events are all .rst\u00adclass objects that a higher-order policy may manipulate. \nWe show how to use these programming features by developing a library of policy combinators. Our system \nis fully implemented, and we have de.ned a formal semantics for an idealized subset of the language containing \nall of the key features. We demonstrate the effectiveness of our system by implementing a large-scale \nsecurity policy for an email client. Categories and Subject Descriptors D.3.2 [Language Classi.ca\u00adtion]: \nSpecialized application languages; D.2.1 [Requirements/ Speci.cations]: Languages; D.2.4 [Software/Program \nVeri.ca\u00adtion]: Formal methods; D.3.1 [Formal De.nitions and Theory]: Semantics, syntax; D.2.5 [Testing \nand Debugging]: Monitors General Terms Languages, Security Keywords Program monitors, run-time enforcement, \ncomposable security policies, edit automata, security automata 1. Introduction Security architects for \nlarge software systems face an enormous challenge: the larger and more complex their system, the more \ndif.cult it is to ensure that it obeys some security policy. Like any large software problem, the security \nproblem can only be dealt with by breaking it down into smaller and more manageable pieces. These smaller-sized \nproblems are easier to understand and reason about, and their solutions are simpler to implement and \nverify. When decomposing the security problem into parts, it is tempt\u00ading to scatter access-control checks, \nresource-monitoring code, and Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. other mechanisms across the many modules that implement these components. This \nis especially true when the enforcement of some property involves several low-level components drawn \nfrom other\u00adwise logically different parts of the system. For instance, in order to implement a policy \nconcerning data privacy, it may be neces\u00adsary to consider the operation of a wide variety of system compo\u00adnents \nincluding the .le system and the network, as well as printers and other forms of I/O. Unfortunately, \na scattered implementation of a policy is much more dif.cult to understand and verify than a centralized \nimplementation even .nding all the pieces of a dis\u00adtributed policy can be problematic. Moreover, the \ndistribution of the security policy and mechanism through a large body of code can make it more dif.cult \nto update a policy in response to security breaches and vulnerabilities. In the current security climate, \nwhere new viruses can spread across the Internet in minutes, speedy reac\u00adtion to vulnerabilities is critical. \nThis paper describes Polymer, a new language and system that helps engineers enforce centralized security \npolicies on untrusted Java applicatons by monitoring and modifying the applications be\u00adhavior at run \ntime. Programmers implement security policies by ex\u00adtending Polymer s Policy class, which is given a \nspecial interpre\u00adtation by the underlying run-time system. Intuitively, each Policy object contains three \nmain elements: (1) an effect-free decision pro\u00adcedure that determines how to react to security-sensitive \napplica\u00adtion actions (i.e., method calls), (2) security state, which can be used to keep track of the \napplication s activity during execution, and (3) methods to update the policy s security state. We call \nthe decision procedure mentioned above a query method. This method returns one of six suggestions indicating \nthat: the action is irrelevant to the policy; the action is OK; the action should be reconsidered after \nsome other code is inserted; the return value of the action should be replaced by a precomputed value; \na security exception should be thrown instead of executing the action; or, the application should be \nhalted. These objects are referred to as suggestions because there is no guarantee that the policy s \ndesired reaction will occur when it is composed with other policies. Also for this reason, the query \nmethod should not have effects. State up\u00addates occur in other policy methods, which are invoked only \nwhen a policy s suggestion is followed. In order to further support .exible but modular security pol\u00adicy \nprogramming, we treat all policies, suggestions, and applica\u00adtion actions as .rst-class objects. Consequently, \nit is possible to de.ne higher-order security policies that query one or more subor\u00addinate policies for \ntheir suggestions and then combine these sug\u00adgestions in a semantically meaningful way, returning the \noverall result to the system, or other policies higher in the hierarchy. We facilitate programming with \nsuggestions and application events by introducing pattern-matching facilities and mechanisms that allow \nprogrammers to summarize a collection of application events as an abstract action. PLDI 05 June 12 15, \n2005, Chicago, Illinois, USA. We have demonstrated the effectiveness of our design by devel- Copyright \n2005 ACM 1-59593-056-6/05/0006...$5.00. oping a library of the most useful combinators, including a con\u00ad \njunctive policy that returns the most restrictive suggestion made by any subpolicy and a dominates policy \nthat tries one policy .rst and, if that policy considers the application action irrelevant, then passes \nthe application event on to the next policy. One of the major challenges here is developing a strategy \nthat makes combin\u00ading policies in the presence of effects semantically reasonable. In addition to our \ngeneral-purpose policy combinators, we have de\u00adveloped a collection of application-speci.c policy combinators \nand policy modi.ers, including a higher-order policy that dynamically checks for policy updates to load \ninto the virtual machine and an audit policy that logs all actions of an untrusted application and all \nsuggestions made by another policy acting on that application. To test our language in a realistic setting, \nwe have written a large-scale security policy, composed of smaller modular policies, for email clients \nthat use the JavaMail interfaces. We have exten\u00adsively tested this policy with the Pooka email client \n[16] and found that we can use Polymer to correctly enforce sophisticated security constraints. 1.1 \nRelated Work Safe language platforms, such as the Java Virtual Machine (JVM) [14] and Common Language \nRuntime (CLR) [15], use stack inspection as the basis of their security monitoring systems. Unfortunately, \nwhile stack inspection can be effective in many situations, it has some serious drawbacks as well. First, \nstack inspection is just one algorithm for implementing access control, and, as explained by several \nresearchers [9, 18], this algorithm is inherently partial. More recent systems make decisions based on \nthe entire history of a computation and all the code that has had an impact on the current system state, \nnot just the current control stack [1, 6, 7, 8, 9, 11, 12]. A second important .aw in the stack inspection \nmodel is that op\u00aderations to enable privileges and perform access-control checks are scattered throughout \nthe system libraries. Consequently, in order to understand the policy that is being enforced, one must \nread through arbitrary amounts of library code. Our current language and system are directly inspired \nby ear\u00adlier theoretical research on automata-theoretic characterizations of security policies. Schneider \n[18] developed the notion of security automata, which are a form of B\u00a8uchi automata that can recog\u00adnize \nsafety properties. We generalized this idea by de.ning edit au\u00adtomata [13], which are formal machines \nthat transform a sequence of program actions via the operations of sequence truncation, inser\u00adtion of \nnew actions, or suppression of actions. The current research may be viewed as an implementation of edit \nautomata with a prac\u00adtical set of editing capabilities and support for composition of automata. The design \nand implementation of Polymer is most closely related to Evans and Twyman s Naccio [8] and to Erlingsson \nand Schneider s PoET/Pslang [7]. One of the crucial observations they make is that the entire security \npolicy, including the set of security\u00adrelevant program points, should be de.ned separately from the main \napplication. This architecture makes it is easier to understand, verify, and modify the security policy. \nThe new contributions of our work include the following. 1. We have designed a new programming methodology \nthat per\u00admits policies to be composed in meaningful and productive ways. A key innovation is the separation \nof a policy into an effectless method that generates suggestions (OK, halt, raise exception, etc.) and \nis safe to execute at any time, and effect\u00adful methods that update security state only under certain \ncondi\u00adtions.  2. We have written a library of .rst-class, higher-order policies and used them to build \na large-scale, practical security policy  that enforces a sophisticated set of constraints on untrusted \nemail clients. 3. We have developed a formal semantics for an idealized ver\u00adsion of our language that \nincludes all of the key features of our implementation including .rst-class policies, suggestions, and \napplication events. A formal semantics helps nail down corner cases and provides an unambiguous speci.cation \nof how secu\u00adrity policies execute a crucial feature of any security mech\u00adanism, but particularly important \nas our security policies have imperative effects. We prove our language is type safe, a nec\u00adessary property \nfor protecting the program monitor from un\u00adtrusted applications. We also make a number of smaller contributions. \nFor instance, unlike Naccio and PoET/Pslang, we allow a monitor to replace an entire invocation of a \nsecurity-relevant action with a provided re\u00adturn value via a replace suggestion. Some policies, such \nas the IncomingMail policy in Section 3.2, require this capability. In addition, we faithfully implement \nthe principle of complete me\u00addiation [17]. In other words, once a policy is put in place, every security-sensitive \nmethod is monitored by the policy every time it is executed, even if the method is called from another \npolicy com\u00adponent. This has a performance cost, but it guarantees that every policy sees all method calls \nthat are relevant to its decision. The de\u00adtails of our language, including its pattern-matching facilities \nand our complementary notion of an abstract program action, which allows grouping of related security \nfunctions, also differ from what appears in previous work. Our monitor language can be viewed as an aspect-oriented \npro\u00adgramming language (AOPL) in the style of AspectJ [10]. The main high-level difference between our \nwork and previous AOPLs is that our aspects (the program monitors) are .rst-class values and that we \nprovide mechanisms to allow programmers to explicitly control the composition of aspects. Several researchers \n[19, 20] describe functional, as opposed to object-oriented, AOPLs with .rst-class aspect-oriented advice. \nHowever, they do not support aspect combi\u00adnators like the ones we have developed here. In general, composing \naspects is a known problem for AOPLs, and we hope the ideas pre\u00adsented here will suggest a new design \nstrategy for general-purpose AOPLs.  2. Polymer System Overview Similarly to the designs of Naccio \nand PoET/Pslang, the Polymer system is composed of two main tools. The .rst is a policy compiler that \ncompiles program monitors de.ned in the Polymer language into plain Java and then into Java bytecode. \nThe second tool is a bytecode rewriter that processes ordinary Java bytecode, inserting calls to the \nmonitor in all the necessary places. In order to construct a secure executable using these tools, programmers \nmust perform the following series of steps. 1. Write the action declaration .le, which lists all program \nmeth\u00adods that might have an impact on system security. 2. Instrument the system libraries speci.ed in \nthe action decla\u00adration .le. This step may be performed independently of the speci.cation of the security \npolicy. The libraries must be in\u00adstrumented before the Java Virtual Machine (JVM) starts up since the \ndefault JVM security constraints prevent many li\u00adbraries from being modi.ed or reloaded once the JVM \nis run\u00adning. 3. Write and compile the security policy. The policy compiler translates the Polymer policy \ninto ordinary Java and then in\u00advokes a Java compiler to translate it to bytecode. Polymer s policy language \nis described in Section 3; its formal semantics appear in Section 5.  Target application Java core classes \n  Figure 1. A secure Polymer application 4. Start the JVM with the modi.ed libraries. 5. Load the \ntarget application. During this loading, our specialized class loader rewrites the target code in the \nsame way we rewrote the library code in step 2. 6. Execute the secured application.  Figure 1 shows \nthe end result of the process. The instrumented target and library code run inside the JVM. Whenever \nthis code is about to invoke a security-sensitive method, control is redirected through a generic policy \nmanager, which queries the current policy. The current policy will return a suggestion that is interpreted \nby the policy manager. 3. Polymer Language In this section, we describe the core features of the Polymer \nlan\u00adguage. We begin with the basic concepts and show how to program simple policies. Then, we demonstrate \nhow to create more com\u00adplete policies by composing simpler ones. 3.1 Core Concepts Polymer is based on \nthree central abstractions: actions, suggestions, and policies. Policies analyze actions and convey their \ndecisions by means of suggestions. Actions Monitors intercept and reason about how to react to security-sensitive \nmethod invocations. Action objects contain all of the information relevant to such invocations: static \ninformation such as the method signature, and dynamic information like the calling object and the method \ns parameters. For convenient manipulation of actions, Polymer allows them to be matched against action \npatterns.An Action object matches an action pattern when the action s signature matches the one speci.ed \nin the pattern. Patterns can use wildcards: * matches any one constraint (e.g., any return type or any \nsingle parameter type), and .. matches zero or more parameter types. For example, the pattern <public \nvoid java.io.*.<init>(int, ..)> matches all public constructors in all classes in the java.io pack\u00adage \nwhose .rst parameter is an int. In place of <init>, which refers to a constructor, we could have used \nan identi.er that refers to a particular method. Action patterns appear in two places. First, the action \ndeclara\u00adtion .le is a set of action patterns. During the instrumentation pro\u00adcess, every action that \nmatches an action pattern in the action dec\u00adlaration .le is instrumented. Second, policies use action \npatterns in aswitch statements to determine which security-sensitive ac\u00adtion they are dealing with. aswitch \nstatements are similar to Java s switch statements, as the following example shows. aswitch(a) { case \n<void System.exit(int status)>: E; ... } If Action a represents an invocation of System.exit, this statement \nevaluates expression E with the variable status bound to the value of the method s single parameter. \nSuggestions Whenever the untrusted application attempts to exe\u00adcute a security-relevant action, the monitor \nsuggests a way to han\u00addle this action (which we often call a trigger action because it trig\u00adgers the \nmonitor into making such a suggestion). The monitor s decision about a particular trigger action is con\u00adveyed \nusing a Sug object. Polymer supplies a subclass of Sug for each type of suggestion mentioned in Section \n1: An IrrSug suggests that the trigger action execute uncondi\u00adtionally because the policy does not reason \nabout it.  An OKSug suggests that the trigger action execute even though the action is of interest to \nthe policy.  An InsSug suggests that making a .nal decision about the target action be deferred until \nafter some auxiliary code is executed and its effects are evaluated.  A ReplSug suggests replacing the \ntrigger action, which com\u00adputes some return value, with a return value supplied by the policy. The policy \nmay use InsSugs to compute the suggested return value.  An ExnSug suggests that the trigger action not \nbe allowed to execute, but also that the target be allowed to continue running. Whenever following an \nExnSug, Polymer noti.es the target that its attempt at invoking the trigger action has been denied by \nthrowing a SecurityException that the target can catch before continuing execution.  A HaltSug suggests \nthat the trigger action not be allowed to execute and that the target be halted.  Breaking down the \npossible interventions of monitors into these categories provides great .exibility. In addition, this \nbreakdown, which was re.ned by experience with writing security policies in Polymer, simpli.es our job \ntremendously when it comes to controlling monitor effects and building combinators that compose monitors \nin sensible ways (see Section 3.3). Policies Programmers encode a run-time monitor in Polymer by extending \nthe base Policy class (Figure 2). A new policy must pro\u00advide an implementation of the query method and \nmay optionally override the accept and result methods. query analyzes a trigger action and returns a \nsuggestion indi\u00adcating how to deal with it.  accept is called to indicate to a policy that its suggestion \nis about to be followed. This gives the policy a chance to perform any bookkeeping needed before the \nthe suggestion is carried out.  result gives the policy access to the return value produced by following \nits InsSug or OKSug. The three arguments to result are the original suggestion the policy returned, the \nreturn value of the trigger action or inserted action (null if the return type was void and an Exception \nvalue if the action completed abnormally), and a .ag indicating whether the action completed abnormally. \n The accept method is called before following any suggestion except an IrrSug; the result method is \nonly called after follow\u00ading an OKSug or InsSug. After result is called with the result of an InsSug, \nthe policy is queried again with the original trig\u00ad public abstract class Policy {public abstract Sug \nquery(Action a); public void accept(Sug s) {}; public void result(Sug s, Object result, boolean wasExnThn) \n{}; } Figure 2. The parent class of all policies public class Trivial extends Policy {public Sug query(Action \na) {return new IrrSug(this); }} Figure 3. Policy that allows all actions ger action (in response to which \nthe policy had just suggested an InsSug). Thus, InsSugs allow a policy to delay making a decision about \na trigger action until after executing another action. A policy interface consisting of query, accept, \nand result methods is fundamental to the design of Polymer. We can compose policies by writing policy \ncombinators that query other policies and combine their suggestions. In combining suggestions, a com\u00adbinator \nmay choose not to follow the suggestions of some of the queried policies. Thus, query methods must not \nassume that their suggestions will be followed and should be free of effects such as state updates and \nI/O operations. 3.2 Simple Policies To give a feel for how to write Polymer policies, we de.ne sev\u00aderal \nsimple examples in this section; in Sections 3.3 and 4.2 we will build more powerful policies by composing \nthe basic policies presented here using a collection of policy combinators. We begin by considering the \nmost permissive policy possible: one that allows everything. The Polymer code for this policy is shown \nin Figure 3. Because the query method of Trivial always returns an IrrSug, it allows all trigger actions \nto execute uncondi\u00adtionally. To enable convenient processing of suggestions, every Sug constructor has \nat least one argument, the Policy making the Sug. For our second example, we consider a more useful pol\u00adicy \nthat disallows executing external code, such as OS system calls, via java.lang.Runtime.exec(..) methods. \nThis pol\u00adicy, shown in Figure 4, simply halts the target when it calls java.lang.Runtime.exec. The accept \nmethod noti.es the user of the security violation. Notice that this noti.cation does not ap\u00adpear in the \nquery method because it is an effectful computation; the noti.cation should not occur if the policy s \nsuggestion is not followed. In practice, there can be many methods that correspond to a single action \nthat a policy considers security relevant. For example, a policy that logs incoming email may need to \nobserve all actions that can open a message. It can be cumbersome and redundant to have to enumerate \nall these methods in a policy, so Polymer makes it possible to group them into abstract actions. Abstract \nactions allow a policy to reason about security-relevant actions at a different level of granularity \nthan is offered by the Java core API. They permit policies to focus on regulating particular be\u00adhaviors, \nsay, opening email, rather than forcing them to individually regulate each of the actions that cause \nthis behavior. This makes it easier to write more concise, modular policies. Abstract actions also make \nit possible to write platform-independent policies. For example, the set of actions that fetch email \nmay not be the same public class DisSysCalls extends Policy {public Sug query(Action a) {aswitch(a) {case \n<* java.lang.Runtime.exec(..)>: return new HaltSug(this, a); } return new IrrSug(this); } public void \naccept(Sug s) {System.out.println(\"Illegal method called: \" + s.getTrigger()); }} Figure 4. Policy that \ndisallows Runtime.exec methods public class GetMail extends AbsAction {public boolean matches(Action \na) { aswitch(a) {case <Message IMAPFolder.getMessage(int)> : case <void IMAPFolder.fetch(Message[], *)> \n: ... return true; } return false; } public static Object convertResult(Action a, Object res) {aswitch(a) \n{case <Message IMAPFolder.getMessage(int)> : return new Message[] {(Message)res}; case <void IMAPFolder.fetch(Message[] \nma, *)> : return ma; ... default: return res; }}} Figure 5. Abbreviated abstract action for receiving \nemail mes\u00adsages; the abstract action s signature is Message[] GetMail() on every system, but as long \nas the implementation of the abstract GetMail action is adjusted accordingly, the same policy for regu\u00adlating \nemail access can be used everywhere. Figure 5 shows an abstract action for fetching email messages. The \nmatches method of an abstract action returns true when a provided concrete action is one of the abstract \naction s constituents. The method has access to the concrete action s run-time parameters and can use \nthis information in making its decision. All constituent concrete actions may not have the same parameter \nand return types, so one of the abstract action s tasks is to export a consistent inter\u00adface to policies. \nThis is accomplished via convertParameter and convertResult methods. The convertResult method in Fig\u00adure \n5 allows the GetMail abstract action to export a return type of Message[], even though one of its constituents \nhas a void return type. Naccio [8] implements an alternative notion, called platform in\u00adterfaces, that \nsupports a similar sort of separation between concrete and abstract actions. It appears that our design \nis slightly more gen\u00aderal, as our abstract actions allow programmers to de.ne many\u00admany relationships, \nrather than many-one relationships, between public class IncomingMail extends Policy {... public Sug \nquery(Action a) { aswitch(a) { case <abs * examples.mail.GetMail()>: return new OKSug(this, a); case \n<* MimeMessage.getSubject()>: case <* IMAPMessage.getSubject()>: String subj = spamifySubject(a.getCaller()); \nreturn new ReplSug(this, a, subj); case <done>: if(!isClosed(logFile)) return new InsSug(this, a, new \nAction( logFile, \"java.io.PrintStream.close()\")); } return new IrrSug(this, a); } public void result(Sug \nsugg, Object res, boolean wasExnThn) {if(!sugg.isOK() || wasExnThn) return; log(GetMail.convertResult(sugg.getTrigger(), \nresult)); }} Figure 6. Abbreviated policy that logs all incoming email and prepends the string SPAM: \nto subject lines on messages .agged by a spam .lter concrete and abstract actions. In addition, our abstract \nactions are .rst-class objects that may be passed to and from procedures, and we support the convenience \nof general-purpose pattern matching. The example policy in Figure 6 logs all incoming email and prepends \nthe string SPAM: to subject lines of messages .agged by a spam .lter. To log incoming mail, the policy \n.rst tests whether the trigger action matches the GetMail abstract action (from Fig\u00adure 5), using the \nkeyword abs in an action pattern to indicate that GetMail is abstract. Since query methods should not \nhave effects, the policy returns an OKSug for each GetMail action; the policy logs the fetched messages \nin the result method. Polymer triggers a done action when the application terminates; the policy takes \nadvantage of this feature to insert an action that closes the mes\u00adsage log. If the InsSug recommending \nthat the log be closed is accepted, the policy will be queried again with a done action after the inserted \naction has been executed. In the second query, the log .le will already be closed, so the policy will \nreturn an IrrSug. The policy also intercepts calls to getSubject in order to mark email as spam. Instead \nof allowing the original call to execute, the policy fetches the original subject, prepends SPAM: if \nnecessary, and returns the result via a ReplSug. Sometimes, a policy requires notifying the target that \nexe\u00adcuting its trigger action would be a security violation. When no suitable return value can indicate \nthis condition to the target, the policy may make an ExnSug rather than a ReplSug. For exam\u00adple, an email \nAttachments policy that prevents executable .les from being created may, rather than by halting the target \noutright, signal policy violations by making ExnSugs. These will cause SecurityExceptions to be raised, \nwhich can be caught by the application and dealt with in an application-speci.c manner. 3.3 Policy Combinators \nPolymer supports policy modularity and code reuse by allowing policies to be combined with and modi.ed \nby other policies. In Polymer, a policy is a .rst-class Java object, so it may serve as an argument to \nor be returned by other policies. We call a policy pa\u00adrameterized by other policies a policy combinator. \nWhen referring to a complex policy with many policy parts, we call the policy parts subpolicies and the \ncomplex policy a superpolicy. We have written a library of common combinators; however, security policy \narchi\u00adtects are always free to develop new combinators to suit their own speci.c needs. We use each of \nthe following kinds of combinators in the email policy described in Section 4.2. Conjunctive combinator \nIt is often useful to restrict an applica\u00adtion s behavior by applying several policies at once and, for \nany particular trigger action, enforcing the most restrictive one. For ex\u00adample, a policy that disallows \naccess to .les can be used in com\u00adbination with a policy that disallows access to the network; the re\u00adsulting \npolicy disallows access to both .les and the network. In the general case, the policies being conjoined \nmay reason about overlapping sets of actions. When this is the case, we must con\u00adsider what to do when \nthe two subpolicies suggest different courses of action. In addition, we must de.ne the order in which \neffectful computations are performed. Our conjunctive combinator composes exactly two policies; we can \ngeneralize this to any number of subpolicies. Our combinator operates as follows. If either subpolicy \nsuggests insertions, so does the combinator, with any insertions by the left (.rst) conjunct occurring \nprior to insertions by the right conjunct. Following the principle of complete mediation, the monitor \nwill recursively examine these inserted actions if they are security-relevant.  If neither subpolicy \nsuggests insertions, the conjunctive com\u00adbinator computes and returns the least upper bound of the two \nsuggestions, as described by the following lattice, which orders suggestions in terms of increasing semantic \nimpact.  Replace(v1) Replace(v2) Irrelevant OK  Exception Halt Replace(v3) . . . For instance, IrrSug \nhas less impact than OKSug since an IrrSug indicates the current method is allowed but irrelevant to \nthe policy whereas OKSug says it is allowed, but relevant and updates of security state may be needed. \nReplSugs have more impact than OKSugs since they change the semantics of the application. ReplSugs containing \ndifferent replacements are considered inequivalent; consequently, the conjunction of two ReplSugs is \nconsidered to be an ExnSug. Note that a sequence of insertions made by one conjunct may affect the second \nconjunct. In fact, this is quite likely if the sec\u00adond conjunct considers the inserted actions security-relevant. \nIn this case, the second conjunct may make a different suggestion regard\u00ading how to handle an action \nbefore the insertions than it does after. For example, in the initial state the action might have been \nOK, but after the intervening insertions the second conjunct might suggest that the application be halted. \nAn abbreviated version of the conjunctive combinator is shown in Figure 7. The calls to SugUtils.getNewSug \nin the query method simply create new suggestions with the same type as the .rst parameter in these calls. \nNotice that the suggestion returned by the combinator includes the suggestions on which the com\u00adbinator \nbased its decision. This design makes it possible for the combinator s accept and result methods to notify \nthe appro\u00adpriate subpolicies that their suggestions have been accepted and followed. Precedence combinators \nWe have found the conjunctive policy to be the most common combinator. However, it is useful on oc\u00adcasion \nto have a combinator that gives precedence to one subpol\u00adicy over another. One example is the TryWith \ncombinator, which public class Conjunction extends Policy {private Policy p1, p2; public Conjunction(Policy \np1, Policy p2) { this.p1 = p1; this.p2 = p2; } public Sug query(Action a) { Sug s1=p1.query(a), s2=p2.query(a); \nif(s1.isInsertion()) return SugUtils.getNewSug( s1, this, a, new Sug[]{s1}); if(s2.isInsertion()) return \nSugUtils.getNewSug( s2, this, a, new Sug[]{s2}); if(s1.isHalt() &#38;&#38; s2.isHalt()) return SugUtils.getNewSug(s1, \nthis, a, new Sug[]{s1,s2}); if(s1.isHalt()) return SugUtils.getNewSug( s1, this, a, new Sug[]{s1}); ... \n} public void accept(Sug sug) {//notify subpolicies whose suggestions were accepted Sug[] sa = sug.getSuggestions(); \nfor(int i = 0; i < sa.length; i++) { sa[i].getSuggestingPolicy().accept(sa[i]); } } ... } Figure 7. \nConjunctive policy combinator queries its .rst subpolicy, and if that subpolicy returns an IrrSug, OKSug,or \nInsSug, it makes the same suggestion. Otherwise, the combinator defers judgment to the second subpolicy. \nThe email policy described in Section 4.2 uses the TryWith combinator to join a policy that allows only \nHTTP connections with a policy that allows only POP and IMAP connections; the resulting policy al\u00adlows \nexactly those kinds of connections and no others. A similar sort of combinator is the Dominates combinator, \nwhich always follows the suggestion of the .rst conjunct if that conjunct considers the trigger action \nsecurity-relevant; otherwise, it follows the suggestion of the second conjunct. Note that if two sub\u00adpolicies \nnever consider the same action security-relevant, compos\u00ading them with a Dominates combinator is equivalent \nto compos\u00ading them with a Conjunction combinator, except the Dominates combinator is in general more \nef.cient because it need not always query both subpolicies. In our email policy we use Dominates to construct \na policy that both restricts the kinds of network connec\u00adtions that may be established and prevents executable \n.les from being created. Since these two subpolicies regulate disjoint set of actions, composing them \nwith the Conjunction combinator would have needlessly caused the second subpolicy to be queried even \nwhen the trigger action was regulated by the .rst subpolicy, and therefore clearly not of interest to \nthe second. Selectors Selectors are combinators that choose to enforce ex\u00adactly one of their subpolicies. \nThe IsClientSigned selector of Section 4.2, for example, enforces a weaker policy on the target application \nif the target is cryptographically signed; otherwise, the selector enforces a stronger policy. Policy \nmodi.ers Policy modi.ers are higher-order policies that enforce a single policy while also performing \nsome other actions. Suppose, for example, that we want to log the actions of a target application and \nthe suggestions made by a policy acting on that target. Rather than modifying the existing policy, we \ncan accom\u00adplish this by wrapping the policy in an Audit unary superpolicy. When queried, Audit blindly \nsuggests whatever the original pol\u00adicy s query method suggests. Audit s accept and result meth\u00adods perform \nlogging operations before invoking the accept and result methods of the original policy. Another example \nof a policy modi.er is our AutoUpdate su\u00adperpolicy. This policy checks a remote site once per day to \ndeter\u00admine if a new policy patch is available. If so, it makes a secure connection to the remote site, \ndownloads the updated policy, and dynamically loads the policy into the JVM as its new subpolicy. Policies \nof this sort, which determine how to update other policies at run time, are useful because they allow \nnew security constraints to be placed on target applications dynamically, as vulnerabilities are discovered. \nNote however that because library classes (such as java.lang.Object) cannot in general be reloaded while \nthe JVM is running, policies loaded dynamically should consider security\u00adrelevant only actions appearing \nin the static action declaration .le. For this reason, we encourage security programmers to be reason\u00adably \nconservative when writing action declaration .les for dynam\u00adically updateable policies. A third useful \nsort of policy modi.er is a Filter that blocks a policy from seeing certain actions. In some circumstances, \nself\u00admonitoring policies can cause loops that will prevent the target program from continuing (for example, \na policy might react to an action by inserting that same action, which the policy will then see and react \nto in the same way again). It is easy to write a Filter to prevent such loops. More generally, Filters \nallow the superpolicy to determine whether an action is relevant to the subpolicy.  4. Empirical Evaluation \nExperience implementing and using Polymer has been instrumental in con.rming and re.ning our design. \n 4.1 Implementation The principal requirement for enforcing the run-time policies we are interested in \nis that the .ow of control of a running program passes to a monitor immediately before and after executing \na security-relevant method. The kind of pre-and post-invocation control-.ow modi.cations to bytecode \nthat we use to implement Polymer can be done by tools like AspectJ [10]. Accordingly, we considered using \nAspectJ to insert into bytecode hooks that would trigger our monitor as needed. However, we wanted to \nretain pre\u00adcise control over how and where rewriting occurs to be able to make decisions in the best \ninterests of security, which is not the primary focus of aspect-oriented languages like AspectJ. Instead, \nwe used the Apache BCEL API [3] to develop our own bytecode rewriting tool. Custom class loaders have \noften been used to modify bytecode before executing it [2, 4]; we use this technique also. Since libraries \nused internally by the JVM cannot be rewritten by a custom class loader, we rewrite those libraries before \nstarting the JVM and the target application. Further discussion of the implementation, including design \nde\u00adcisions and performance, can be found in a prior technical re\u00adport [5]. Performance It is instructive \nto examine the performance costs of enforcing policies using Polymer. We did not concentrate on making \nour implementation as ef.cient as possible, so there is much room for improvement here. However, the \nperformance of our implementation does shed some light on the costs of run-time policy enforcement. Our \nsystem impacts target applications in two phases: before and during loading, when the application and \nthe class libraries are instrumented by the bytecode rewriter; and during execution. The total time to \ninstrument every method in all of the standard Java library packages (i.e., the 28742 methods in the \n3948 classes in the  Figure 8. Email policy hierarchy java and javax packages of Sun s Java API v.1.4.0) \nwas 107 s, or 3.7 ms per instrumented method.1 This cost is reasonable because library instrumentation \nonly needs to be performed once (rather than every time a target application is executed). The average \ntime to load non-library classes into the JVM with our specialized class loader, but without instrumenting \nany methods, was 12 ms, twice as long as the VM s default class loader required. The cost of transferring \ncontrol to and from a Polymer policy while executing a target is very low (approximately 0.62 ms); the \nrun-time overhead is dominated by the computations actually performed by the policy. Hence the cost of \nmonitoring a program with Polymer is almost entirely dependent on the complexity of the security policy. \n 4.2 Case Study: Securing Email Clients  To test the usefulness of Polymer in practice, we have written \na large-scale policy to secure untrusted email clients that use the JavaMail API. The entire policy, \npresented in Figure 8, is approx\u00adimately 1800 lines of Polymer code. We have extensively tested the protections \nenforced by the policy on an email client called Pooka [16], without having to inspect or modify any \nof the approx\u00adimately 50K lines of Pooka source code. The run-time cost of en\u00adforcing the complex constraints \nspeci.ed by our policy is dif.cult to measure because the performance of the email client depends largely \non interactions with the user; however, our experience indi\u00adcates that the overhead is rarely noticeable. \nThe component policies in Figure 8 each enforce a modular set of constraints. The Trivial and Attachments \npolicies were de\u00adscribed in Section 3.2; the Conjunction, TryWith, Dominates, Audit, and AutoUpdate superpolicies \nwere described in Sec\u00adtion 3.3. The left branch of the policy hierarchy (shaded in Figure 8) describes \na generic policy that we include in all of our high-level Polymer policies. This branch of policies ensures \nthat a target can\u00adnot use class loading, re.ection, or system calls maliciously and alerts the user when \nthe memory available to the virtual machine is nearly exhausted. The nonshaded branch of the policy hierarchy \ndescribes policies speci.cally designed for securing an email client and enforces constraints as follows. \n1 The tests were performed on a Dell PowerEdge 2650 with dual Intel Xeon 2.2 GHz CPUs and 1 GB of RAM, \nrunning RedHat Linux 9.0. The times represent real time at low average load. We performed each test multiple \ntimes in sets of 100. The results shown are the average for the set with the IsClientSigned tests whether \nthe email client is cryptograph\u00adically signed. If it is, we run Trivial but continue to log security-relevant \nactions and allow dynamic policy updates. If the client is not signed, we run a more restrictive policy. \n ConfirmAndAllowOnlyHTTP pops up a window seeking con\u00ad.rmation before allowing HTTP connections, and \ndisallows all other types of network connections.  AllowOnlyMIME allows only standard email socket connec\u00adtions \n(POP and IMAP).  QueryCalls is a policy modi.er that allows security-sensitive actions invoked in the \nquery method of its subpolicy to exe\u00adcute unconditionally. QueryCalls OKs these actions without requerying \nthe subpolicy in order to prevent in.nite loops that can occur when the subpolicy invokes actions that \nit also moni\u00adtors. The implementation of QueryCalls inspects the dynamic call stack to determine whether \na trigger action was invoked in the subpolicy s query method.  OutgoingMail logs all mail being sent, \npops up a window con.rming the recipients of messages (to prevent a mali\u00adcious client from quietly sending \nmail on the user s behalf), backs up every outgoing message by sending a BCC to poly\u00addemo@cs.princeton.edu, \nand automatically appends contact in\u00adformation to textual messages.  IncomingMail was shown in an abbreviated \nform in Figure 6. In addition to logging incoming mail and prepending SPAM: to the subject lines of email \nthat fails a spam .lter, this policy truncates long subject lines and displays a warning when a message \ncontaining an attachment is opened.  5. Formal Semantics In this section, we give a semantics to the \ncore features of our lan\u00adguage. The main purpose of the semantics is to communicate the central workings \nof our language in a precise and unambiguous manner. We have chosen to give the semantics in the context \nof a lambda calculus because lambda calculi are inherently simpler to specify than class-based languages \nsuch as Java.2 More impor\u00adtantly, the central elements of our policy language do not depend upon Java-speci.c \nfeatures such as classes, methods and inheri\u00adtance. We could just as easily have implemented policies \nfor a func\u00adtional language such as ML or a type-safe imperative language. 2 Even the lightest-weight \nspeci.cation of Java such as Featherweight Java lowest average, after removing outliers. is substantially \nmore complex than the simply-typed lambda calculus. types : . t ::= Bool |( t) |t Ref |t1 .t2 |Poly |Sug \n|Act |Res programs : P ::= (F F,M,epol,eapp) monitored functions : F ::= funf(x:t1):t2{e}memories : M \n::= \u00b7|M,l : v values : . v ::= true |false |( v) |l |.x:t.e|pol(vquery,vacc,vres) |irrs |oks |inss(v) \n|repls(v) |exns |halts |act(f,v) |result(v:t) expressions : . e ::= v |x|( e) |e1; e2 |ref e|!e|e1:=e2 \n|e1 e2 |pol(equery,eacc,eres) |inss(e) |repls(e) |act(f,e) |invk e|result(e:t) |case e1 of (p .e2 | .e3) \n| try e1 with e2 |raise exn |abort patterns : . p ::= x|true |false |( p) |pol(x1,x2,x3) |irrs |oks |inss(p) \n|repls(p) |exns |halts |act(f,p) |result(p:t) Figure 9. Formal syntax Type safety protects the program \nmonitor s state and code from the untrusted application. Figure 9 describes the main syntactic elements \nof the calculus. The language is simply-typed with types for booleans, n-ary tuples, references, and \nfunctions. Our additions include simple base types for policies (Poly), suggestions (Sug), actions (Act), \nwhich are suspended function applications, and results of those suspended function applications (Res). \nPrograms as a whole are 4-tuples consisting of a collection of functions that may be monitored, a memory \nthat maps memory lo\u00adcations to values, and two expressions. The .rst expression repre\u00adsents the security \npolicy; the second expression represents the un\u00adtrusted application. Execution of a program begins by \nreducing the policy expression to a policy value. It continues by executing the application expression \nin the presence of the policy. Monitored functions (funf(x:t1):t2{e}) are syntactically sep\u00adarated from \nordinary functions (.x:t.e).3 Moreover, we treat mon\u00aditored function names f as a syntactically separate \nclass of vari\u00adables from ordinary variables x. Monitored function names may only appear wrapped up as \nactions as in act(f,e). These actions are suspended computations that must be explicitly invoked with \nthe command invk e. Invoking an action causes the function in question to be executed and its result \nwrapped in a result construc\u00adtor result(e:t). The elimination forms for results and most other objects \ndiscussed above is handled through a generic case expres\u00adsion and pattern matching facility. The class \nof patterns p includes variable patterns x as well as patterns for matching constructors. Ordinary, unmonitored \nfunctions are executed via the usual func\u00adtion application command (e1 e2). To create a policy, one applies \nthe policy constructor pol to a query function (equery), which produces suggestions, and security state \nupdate functions that execute before (eacc) and after (eres) the monitored method. Each suggestion (irrs, \noks, inss, repls, exns, and halts) also has its own constructor. For instance, the repls constructor \ntakes a result object as an argument and the inss suggestion takes an action to execute as an argument. \nEach suggestion will be given a unique interpretation in the operational semantics. 3 As usual, we treat \nexpressions that differ only in the names of their bound variables as identical. We often write let x \n= e1 in e2 for (.x:t.e2)e1. S; C fe : t S; C fequery :Act .Sug S; C feacc :(Act,Sug) .() S; C feres :Res \n.() S; C fpol(equery,eacc,eres): Poly S; C firrs : Sug S; C foks : Sug S; C fe :Act S; C finss(e) : \nSug S; C fe :Res S; C frepls(e) : Sug S; C fexns : Sug S; C fhalts : Sug C(f)= t1 .t2 S; C fe : t1 S; \nC fe :Act S; C fact(f,e): Act S; C finvk e :Res S; C fe : t S; C fresult(e:t): Res S; C fe1 : t' C fp \n:(t'; C') S; C,C' fe2 : tS; C fe3 : t S; C fcase e1 of (p .e2 | .e3): t f(F F,M,epol,eapp): t fFF: CC \nfM : S S; C fepol :Poly S; C feapp : t f(F F,M,epol,eapp): t Figure 10. Static semantics (selected rules) \nStatic Semantics Figure 10 presents selected rules from the static semantics for the language. The main \njudgment, which types ex\u00adpressions, has the form S; C f e : t where S maps reference locations to their \ntypes and C maps variables to types. Whenever we add a new binding x:t to the context, we implicitly \nalpha-vary x to ensure it does not clash with other variables in the context. A secondary judgment C \nf p :(t; C') is used to check that a pat\u00adtern pwill match objects with type t and binds variables with \ntypes given by C'. We have worked hard to make the static semantics a simple but faithful model of the \nimplementation. In particular, notice that all actions share the same type (Act) regardless of the type \nof object they return when invoked. Dynamically, the result of invoking an action is a value wrapped \nup as a result with type Res. Case analysis is used to safely extract the proper value. This choice allows \npolicy objects to process and react to arbitrary actions. To determine the precise nature of any action \nand give it a more re.ned type, the policy will use pattern matching. We have a similar design for action \nresults and replacement values. The judgement for overall program states has the form f (F F,M,epol,eapp): \nt where t is the type of the application code eapp. This judgment relies on two additional judgments \n(de.nitions not shown) which give types to a library of monitored functions FFand types to locations \nin memory M. '' ' ( F. ( F F,M,epol,eapp) .F,M ,epol,eapp) ( F'' F,M,Triv,e) .\u00df (M ,e ) ( F. ( F'' ],eapp) \nF,M,E[e],eapp) .F,M ,E[e where Triv = pol(.x:Act.irrs,.x:(Act,Sug).(),.x:Res.()) ( F'' ) F,M,vpol,e) \n.\u00df (M ,e ( F. ( F'' F,M,vpol,E[e]) .F,M ,vpol,E[e ]) ( F'' F,M,vpol,eapp) .\u00df (M ,eapp) ( F F,M,vpol,(.x:t.e)v) \n.\u00df (M,e[v/x]) Fi . F FFi =funf(x:t1):t2{e} ( F F,M,vpol,invk act(f,v)) .\u00df (M,Wrap(vpol,Fi,v)) where Wrap(pol(vquery,vacc,vres),funf(x:t1):t2{e},v)= \nlet s= vquery(act(f,v)) in case sof irrs . let x= v in result(e:t2) | oks . vacc(act(f,v),s); let x= \nv in let r =result(e:t2)in vres r; r | repls(r) . vacc(act(f,v),s); r | exns . vacc(act(f,v),s); raise \nexn | inss(a) . vacc(act(f,v),s); vres(invk a); invk act(f,v) | . abort Figure 11. Dynamic semantics \n(selected rules) Dynamic Semantics To explain execution of monitored pro\u00adgrams, we use a context-based \nsemantics. The .rst step is to de.ne a set of evaluation contexts E, which mark where a beta-reduction \ncan occur. Our contexts specify a left-to-right, call-by-value evalu\u00adation order. (We omit the de.nition \nto conserve space.) We specify execution through a pair of judgments, one for top\u00adlevel evaluation and \none for basic reductions as shown in Figure 11. The top-level judgment reveals that the policy expression \nis .rst reduced to a value, and then execution of the untrusted applica\u00adtion code begins. Execution of \nmany of the constructs is relatively straightforward. One exception is execution of function application. \nFor ordinary functions, we use the usual capture-avoiding substitu\u00adtion. Monitored functions, on the \nother hand, may only be executed if they are wrapped up as actions and then invoked using the invk command. \nThe invk command applies the query method to dis\u00adcover the suggestion the current policy makes and then \ninterprets the suggestion. Notice, for instance, that to respond to the irrele\u00advant suggestion (irrs), \nthe application simply proceeds to execute the body of the security-relevant action. To respond to the \nOK sug\u00adgestion (oks), the application .rst calls the policy s accept method, then executes the security-relevant \naction before calling the pol\u00adicy s result method, and .nally returns the result of executing the security-relevant \naction. Language Properties To check that our language is well-de.ned, we have proven a standard type-safety \nresult in terms of Preserva\u00adtion and Progress lemmas. Due to space considerations, we have omitted the \nproofs. Theorem 1 If f ( F F,M,epol,eapp): t '' ' . ( F and (F,M,eFpol,eapp) .F,M ,e app) pol,e '' ' \nthen f (F,M F,e app): t. pol,e Theorem 2 If f ( FF,M,epol,eapp) is .n\u00ad F,M,epol,eapp): t then either \n( Fished (i.e., eapp is a value, or epol or eapp is E[abort],or epol or eapp is E[raise exn] where E \n' [try E '' = E with e]), or there ex\u00ad '' ' ists a con.guration (F,M F,epol,e ) such that ( F appF,M,epol,eapp) \n'' ' . ( F .F,M ,epol,eapp). Observations The semantics gives insight into some of the sub\u00adtler elements \nof our implementation, which are important both to system users and to us as implementers. For example, \none might want to consider what happens if a program monitor raises but does not catch an exception (such \nas a null pointer exception). Tracing through the operational semantics, one can see that the exception \nwill percolate from the monitor into the application itself. If this behavior is undesired, a security \nprogrammer can create a top-level superpolicy that catches all exceptions raised by the other policies \nand deals with them as the programmer sees .t. As another example, analysis of the operational semantics \nshows a corner case in which we are unable to fully obey the prin\u00adciple of complete mediation. During \nthe .rst stage of execution, while the policy itself is evaluated, monitored functions are only protected \nby a trivial policy that accepts all actions because the actual policy we want to enforce is the one \nbeing initialized. Policy writers need to be aware of this unavoidable behavior in order to implement \npolicies correctly. 6. Summary We have developed a programming methodology for writing general-purpose \nsecurity policies. The design is radically differ\u00adent from existing policy-speci.cation languages in \nits division of policies into effectless methods that make suggestions regarding how to handle trigger \nactions and effectful methods that are called when the policy s suggestions are followed. This design \nallows general security policies to be composed in meaningful and pro\u00adductive ways. We have implemented \nour design and shown a sound formal semantics for it. We also demonstrated the practicality of the language \nby building a sophisticated security policy for email clients from simple, modular, and reuseable policies. \nAcknowledgments We are grateful to Greg Morrisett and the anonymous reviewers for supplying valuable \nfeedback on earlier versions of this paper. This research was supported in part by ARDA grant no. NBCHC030106, \nby National Science Foundation grants no. CCR-0238328 and CCR-0306313, by the Army Research Of.ce through \ngrant no. DAAD19-02-1-0389, and by a Sloan Fellowship. References [1] M. Abadi and C. Fournet. Access \ncontrol based on execution history. In 10th Annual Network and Distributed System Security Symposium, \n2003. [2] O. Agesen, S. N. Freund, and J. C. Mitchell. Adding type parameteri\u00adzation to the Java language. \nIn Object Oriented Programing: Systems, Languages, and Applications (OOPSLA), Oct. 1997. [3] Apache Software \nFoundation. Byte Code Engineering Library, 2003. http://jakarta.apache.org/bcel/. [4] L. Bauer, A. W. \nAppel, and E. W. Felten. Mechanisms for secure modular programming in Java. Software Practice and Experience, \n33(5):461 480, 2003. [5] L. Bauer, J. Ligatti, and D. Walker. A language and system for composing security \npolicies. Technical Report TR-699-04, Princeton University, Jan. 2004. [6] T. Colcombet and P. Fradet. \nEnforcing trace properties by program transformation. In Twenty-Seventh ACM Symposium on Principles of \nProgramming Languages, pages 54 66, Boston, Jan. 2000. ACM Press. \u00b4 inspection. In IEEE Symposium on \nSecurity and Privacy, Oakland, CA, May 2000. [7] U. Erlingsson and F. B. Schneider. IRM enforcement \nof Java stack [8] D. Evans and A. Twyman. Flexible policy-directed code safety. In IEEE Security and \nPrivacy, Oakland, CA, May 1999. [9] C. Fournet and A. Gordon. Stack inspection: Theory and variants. \nIn Twenty-Ninth ACM Symposium on Principles of Programming Languages, Jan. 2002. [10] G. Kiczales, E. \nHilsdale, J. Hugunin, M. Kersten, J. Palm, and W. Griswold. An overview of AspectJ. In European Conference \non Object-oriented Programming. Springer-Verlag, 2001. [11] M. Kim, M. Viswanathan, H. Ben-Abdallah, \nS. Kannan, I. Lee, and O. Sokolsky. Formally speci.ed monitoring of temporal properties. In European \nConference on Real-time Systems, York, UK, June 1999. [12] I. Lee, S. Kannan, M. Kim, O. Sokolsky, and \nM. Viswanathan. Run\u00ad time assurance based on formal speci.cations. In International Conference on Parallel \nand Distributed Processing Techniques and Applications, Las Vegas, NV, June 1999. [13] J. Ligatti, L. \nBauer, and D. Walker. Edit automata: Enforcement mechanisms for run-time security policies. International \nJournal of Information Security, 4(1 2):2 16, Feb. 2005. [14] T. Lindholm and F. Yellin. The Java Virtual \nMachine Speci.cation. Addison-Wesley, 2nd edition, 1999. [15] E. Meijer and J. Gough. A technical overview \nof the Common Language Infrastructure. http://research.microsoft.com/ ~emeijer/Papers/CLR.pdf. [16] A. \nPetersen. Pooka: A Java email client, 2003. http://www. suberic.net/pooka/. [17] J. H. Saltzer and M. \nD. Schroeder. The protection of information in computer systems. In IEEE 63, 9, pages 1278 1308, Sept. \n1975. [18] F. B. Schneider. Enforceable security policies. ACM Transactions on Information and Systems \nSecurity, 3(1):30 50, Feb. 2000. [19] D. B. Tucker and S. Krishnamurthi. Pointcuts and advice in higher\u00adorder \nlanguages. In Proceedings of the 2nd International Conference on Aspect-Oriented Software Development, \npages 158 167, 2003. [20] D. Walker, S. Zdancewic, and J. Ligatti. A theory of aspects. In ACM International \nConference on Functional Programming, Uppsala, Sweden, Aug. 2003.   \n\t\t\t", "proc_id": "1065010", "abstract": "We introduce a language and system that supports definition and composition of complex run-time security policies for Java applications. Our policies are comprised of two sorts of methods. The first is <i>query</i> methods that are called whenever an untrusted application tries to execute a security-sensitive action. A query method returns a <i>suggestion</i> indicating how the security-sensitive action should be handled. The second sort of methods are those that perform state updates as the policy's suggestions are followed.The structure of our policies facilitates composition, as policies can query other policies for suggestions. In order to give programmers control over policy composition, we have designed the system so that policies, suggestions, and application events are all first-class objects that a higher-order policy may manipulate. We show how to use these programming features by developing a library of policy combinators.Our system is fully implemented, and we have defined a formal semantics for an idealized subset of the language containing all of the key features. We demonstrate the effectiveness of our system by implementing a large-scale security policy for an email client.", "authors": [{"name": "Lujo Bauer", "author_profile_id": "81350570444", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P475697", "email_address": "", "orcid_id": ""}, {"name": "Jay Ligatti", "author_profile_id": "81100429229", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP33026131", "email_address": "", "orcid_id": ""}, {"name": "David Walker", "author_profile_id": "81100426485", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP18001632", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065047", "year": "2005", "article_id": "1065047", "conference": "PLDI", "title": "Composing security policies with polymer", "url": "http://dl.acm.org/citation.cfm?id=1065047"}