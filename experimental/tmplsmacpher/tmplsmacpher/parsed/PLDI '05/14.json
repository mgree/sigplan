{"article_publication_date": "06-12-2005", "fulltext": "\n Differential Register Allocation Xiaotong Zhuang Santosh Pande Georgia Institute of Technology Georgia \nInstitute of Technology College of Computing College of Computing Atlanta, GA, 30332-0280 Atlanta, GA, \n30332-0280 xt2000@cc.gatech.edu santosh@cc.gatech.edu Abstract Micro-architecture designers are very \ncautious about expanding the number of architected registers (also the register .eld), because increasing \nthe register .eld adds to the code size, raises I-cache and memory pressure, complicates processor pipeline. \nEspecially for low-end processors, encoding space could be extremely limited due to area and power considerations. \nOn the other hand, the number of architected registers exposed to the compiler could directly affect \nthe effectiveness of compiler analysis and optimization. For high performance computers, register pressure \ncan be higher than the available registers in some regions, e.g. due to optimizations like aggressive \nfunction inlining, software pipelining etc. The compiler cannot effectively perform compilation and optimization \nif only a small number of registers are exposed through the ISA. Therefore, it is crucial that more architected \nregisters are available at the compiler s disposal without expanding the code size signi.cantly. In this \npaper, we look at a new register encoding scheme called differential encoding that allows more registers \nto be addressed in the operand .eld of instructions than the direct encoding currently being used. We \nshow it can be implemented with very low over\u00adhead. Based upon differential encoding, we apply it in \nseveral ways such that the extra architected registers can bene.t the performance. Three schemes are \ndevised to integrate differential encoding with register allocation. We demonstrate that differential \nregister alloca\u00adtion is helpful in improving the performance of both high-end and low-end processors. \nMoreover, We can combine it with software pipelining to provide more registers and reduce spills. Our \nresults show that differential encoding signi.cantly reduces the number of spills and speeds up program \nexecution. For a low\u00adend con.guration, we achieve over 12% speedup while keeping code size almost unaffected. \nFor optimization on loops, it sig\u00adni.cantly speeds up loops with high register pressure (over 70% speedup). \nCategories and Subject Descriptors D.3.4 [Programming Lan\u00adguages]: Processors Code generation,Compilers,Optimization \n; G.2 [Discrete Mathematics]: Graph Theory General Terms Languages, Design, Algorithm, Performance Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 05, June 12 \n15, 2005, Chicago, Illinois, USA. Copyright 2005 ACM 1-59593-056-6/05/0006...$5.00. Keywords Register \nAllocation, Architected Register, Differential Encoding 1. Introduction The width of the register .eld \nin an instruction determines the num\u00adber of architected register that can be managed by the compiler. \nIn other words, the compiler can only allocate registers that are ex\u00adposed to it through the ISA (Instruction \nSet Architecture), although physical registers are normally more than architected ones. Micro\u00adarchitecture \ndesigners are very cautious about expanding the num\u00adber of architected registers (or the register .eld \nin the ISA) due to a number of reasons. First, the register .eld directly affects code size. Notice that, \nadding 1 bit to the register .eld typically leads to an increase of 2 or more bits for each instruction \ndue to multiple register .elds. We observe that register .elds take a signi.cant portion of the code \nsize, since most of the instructions in the generated code use reg\u00adister(s) one way or another. For example, \nregister .eld takes about 28% of the Alpha binary and 25% of the ARM binary). Therefore, the size of \nthe register .eld heavily in.uences the size of generated code. Secondly, the memory footprint of a program \nalso affects the memory traf.c to the code segment and determines the access pres\u00adsure on the I-cache. \nIf instructions become wider, signi.cant pres\u00adsure is imposed on the I-cache. Meanwhile, wider instructions \nalso complicate the decode stage in the pipeline, stretching clock cycles, increasing die size and the \npower consumption, etc. For low-end processors, encoding space could be very limited due to tight area \nand power constraints. Typically instruction cache accounts for a big portion of the die area and overall \npower con\u00adsumption. A recent power consumption analysis on the ARM pro\u00adcessor reveals that cache power \naccounts for about half of the power budget on ARM. Moreover the I-cache (with the same size as D\u00adcache) \nconsumes about 40% more power than the D-cache [19]. Thus, the number of architected registers is limited \nto avoid in\u00adstruction width growth. Even if the hardware can support more reg\u00adisters, the number of architected \nregisters de.ned by ISA is much smaller due to these encoding issues. For example, the Motorola DSP 56300 \nchip [13] is a 24-bit processor; however only 6 reg\u00adisters are available for ALU instructions and all \nregister numbers are compactly encoded. StarCore SC 110 contains 16 registers but only exposes either \nthe HI (top 8) or LO (lower 8) registers at a time to a given instruction. Intel s StrongARM processor \nprovides two sets of ISAs: 32 bit ARM ISA and 16 bit THUMB ISA [6]. Most THUMB instructions can only \naccess 8 registers although all 16 registers are physically present. The compact THUMB in\u00adstruction set \ndemonstrates better I-cache power saving but lower performance partially due to the small number of architected \nregis\u00adters available [8]1. Study in [8] shows that compiling the same pro\u00adgram with 16-bit THUMB mode \ninstead of the 32-bit ARM mode can save up to 19% I-cache energy. Similar to ARM/THUMB, the MIPS-16 [12] \nprocessor also adopts two instruction sets. However, restricting the number of architected registers \ntypi\u00adcally incurs performance penalty since compiler managed register allocation can only utilize the \nexposed architected registers. Limit\u00ading architected registers impedes compiler optimizations. This is \nespecially true for VLIW machines where the compiler plays a crucial role in optimizing the code. Typically \nfor superscalar ma\u00adchines, the number of architected registers does not affect regis\u00adter allocation to \nscalar variables much, since in most cases register pressure is lower than the number of architected \nregisters. However, in certain circumstances, register pressure could be very high. For example, if functions \nare aggressively inlined to reduce function call overhead, high register pressure regions may appear. \nSoftware pipelining is performed to pipeline loops, which might increase reg\u00adister pressure as well. \nTherefore a .exible and low overhead regis\u00adter encoding scheme is desirable to effectively increase the \nnumber of architected registers for such code segments, whereas it can be easily turned off for the rest \nof the code with low register pressure. As discussed earlier, for low-end processors, the number of spills \nis very sensitive to the number of architected registers. More spills lead to more accesses to the memory \nsubsystem, incurring longer delays and power consumption in the D-cache. Although the hardware can support \nmore registers such as on ARM and MIPS, the ISA bottleneck prevents them from being addressed and utilized. \n[8] mentions that with a compact ISA (THUMB or MIPS-16), instruction count can increase by 9% to 41%, \nwhich not only slows down the execution but eliminates some of the bene.ts brought about by a compact \nISA. Due to the above reasons, we .nd it necessary to devise a performance-driven approach to work around \nthe ISA bottleneck due to architected registers. In this paper, we .rst propose a new encoding scheme \ncalled differential encoding. Instead of encoding register numbers directly, differential encoding encodes \nthe differ\u00adence between register numbers of the current access and the pre\u00advious access. Differential \nencoding can potentially address more registers than direct encoding. We .rst show that the hardware \ncost to implement such encoding is very low. We then present several approaches that make use of the \nextra architected registers, includ\u00ading performing better register allocation and reducing spills for \nsoftware pipelining, etc. Our results show that differential encod\u00ading signi.cantly reduces the number \nof spills and speeds up pro\u00adgram execution. For a low-end con.guration, we can achieve 12% speedup with \nslightly reduced code size. For optimization on loops, it signi.cantly speeds up loops with high register \npressure (over 70% speedup). The rest of the paper is organized as follows: Section 2 in\u00adtroduces the \ndifferential encoding scheme; Section 3 provides an overview of our approach; Section 4 discusses how \nto model this problem and our optimization objective; Section 5, Section 6 and Section 7 give the details \nof the three approaches and how they are combined with register allocation; Section 8 and Section 9 pro\u00advide \nsome other considerations and optimization techniques; Sec\u00adtion 10 evaluates the algorithms; Section \n11 discusses related work and Section 12 concludes the paper.  2. Differential Register Encoding To \nsimplify the discussion and illustration, we assume a RISC ISA and assume that the registers under consideration \nare uniform and 1 Although a few instructions like MOV can access all 16 registers, the majority of THUMB \ninstructions only see 8 registers  Figure 1. Calculate the difference classless. In Section 9, we will \ndiscuss the case of registers forming multiple classes. Traditionally, register numbers are encoded directly \nin the reg\u00adister .eld, i.e. to encode R5, we just put 5 in the register .eld. To encode RegN number of \nregisters, the register .eld should have at least RegW = llog2 RegNl bits. We call this most widely used \nscheme as direct encoding. On the contrary, differential register en\u00adcoding encodes the difference between \ncurrently accessed register number and the previously accessed one. Therefore, with differen\u00adtial register \nencoding, the register .eld encodes differences . For example, consider that we want to access registers \nR1, R3, and R8 in that order, the encoded differences are then 2 (from R1 to R3) and 5 (from R3 to R8). \nSuppose we encode DiffN distinct dif\u00adferences . It will then take DiffW = llog2 DiffNl bits. Our goal \nis to make DiffW < RegW while all RegN registers can still be properly addressed with little cost. First \nof all, differential register encoding assumes registers are accessed in a certain sequence, so that \nwe can distinguish between current access and previous access . Registers are decoded ac\u00adcording to the \nscheme before they are actually accessed. Therefore, we must de.ne a nominal register access order or \naccess order. Naturally, registers should be accessed by following the instruc\u00adtion order. For register \n.elds in the same instruction, they should follow a certain predetermined order. For example, access \nsource operands one by one then the destination operand: src1, src2., dst. Access order must be agreed \nupon beforehand to make the encod\u00ading and decoding work consistently. Based on the access order, we can \nconstruct the register access sequence or access sequence from the original code. Formally, suppose the \ncode has register access sequence as fol\u00adlows: Rn1 ,Rn2 ...Rnk , where n1,n2 ...nk are register numbers \n(which will be put in the register .elds under direct encoding). Also, assume n0 =0. Under differential \nencoding, the encoded numbers are d1,d2 ...dk such that: di =(ni - ni-1) mod RegN (1) To decode, we should \ndo: ni =(di + ni-1) mod RegN (2) For clarity, we de.ne the modulo (mod) operation as follows: De.nition \n1. Modulo Operation If A mod M = B, where M is a positive integer, then there is an integer k such that \nA - B = kM and B . [0,M - 1]. Some examples are : 4 mod 3 = 1, -1 mod 3 = 2. Therefore Equation (1) gives \na value from 0 to RegN - 1. In other words, if ni = ni-1, then di = ni - ni-1, otherwise di = ni - ni-1 \n+ RegN. An illustration is shown in Figure 1. If we order 0, 1 . . . RegN -1 on a clockwise circle, di \nis actually the number of hops from ni-1 to ni following the clockwise direction. Here n1 is 2 hops away \nfrom n0, n2 is 3 hops away from n1, and n3 is 2 hops away from n2. In Figure 2.a, direct encoding simply \nputs the register numbers into the corresponding register .elds, e.g. if the register is R1, we simply \nput 1. Figure 2.b and c illustrate differential encoding. First we de.ne the register access order as \nsrc1, src2...dst. Thus the Figure 2. Illustrations for direct encoding and differential encod\u00ading  assembly \ncode in Figure 2.b yields the access sequence as shown in Figure 2.c and the .nal encoding in Figure \n2.d. The bottom of the .gure shows the encoded differences. As shown in this example, under direct encoding \nwe need to encode register numbers from 0 to 3, i.e. RegN =4 and 2 bits should be allocated for each \nregister .eld, i.e RegW =2. Notice that, with differential encoding, we only need to encode two different \nnumbers: 0 and 1. In other words, the register .eld only needs 1 bit, i.e. DiffN =2, DiffW =1. However \nall 4 registers can be properly addressed as in the original code. This achieves 50% reduction of encoding \nspace in the address .eld. In short, differential encoding uses DiffW bits but can address RegN registers, \nwhere DiffW < RegW = llog2 RegNl, so we are able to save encoding space. Alternatively, with a given \namount of encoding space we are able to access more registers than direct addressing. To decode an instruction \ngenerated with differential register en\u00adcoding, we need a storage space to store the register number \nthat is accessed last time. We call it the last reg register, which should contain RegW bits. To decode \nan instruction, we decode the reg\u00adister .elds one by one according to the access order, (modulo) add \nthe difference stored in the register .eld to last reg, get the de\u00adcoded register number, and then assign \nit back to last reg in order to decode the next register .eld. Notice that as long as instructions are \ndecoded in-order (which is almost always true), differential en\u00adcoding is applicable. 2.1 Implementation \nOverhead Before discussing compiler techniques that can exploit differential encoding, we .rst show that \nits implementation overhead in hard\u00adware is very low. Compared with direct encoding, differential encoding \nrequires one extra register for last reg. This is negligible even for embed\u00added processors. For superscalar \nmachines, multiple last reg regis\u00adters are needed if the processor speculatively fetches and executes \non several paths. Given that speculating on multiple paths already demands a lot more resources, this \nis lesser of an overhead. Equation (2) shows that we must decode register .elds sequen\u00adtially, i.e. only \nafter one register .eld is decoded, can we decode the next. Since decoding is on the critical path, we \nshould speed it up as much as possible. Actually, by modifying the formula slightly, all operands can \nbe decoded in parallel. Suppose there are two operands in one instruction, encoded as d1 and d2, we can \ndecode them in parallel as follows: Figure 3. Example for multi-path inconsistency n1 =(last reg + d1) \nmod RegN n2 =(last reg + d1 + d2) mod RegN Compared with sequential decoding, we need more modulo adders. \nTherefore, it becomes extremely important that the mod\u00adulo adder is implemented ef.ciently. Note that, \nmodulo adders are very similar to normal adders. In the case of differential decoding, values involved \nin modulo addition are typically small. For embed\u00added processors with 16 registers, the adder only needs \nto handle 4-bit input/outputs which can be simply implemented with two\u00adlevel combinational logic. Such \ncircuits only incur two-gate delay. According to HSPICE, it is less than 0.4ns, i.e. 1/5 cycle if the \npro\u00adcessor is clocked at 500MHz. For 2 input adders, we need to build an 8-bit input and 4-bit output \ncombinational circuit. For 3 input adders, a 12-bit input and 4-bit output combinational circuit is re\u00adquired. \nEven for the latter, a rough estimation tells us that it can be built with less than 2k transistors, \nwhich is negligibly small. For superscalar machines, the number of architected registers increases a \nlot, e.g. Alpha 21264 has 32 integer registers, Itanium has 128 registers. Also, multiple instructions \nmight be decoded in each cycle. However, even with 128 registers, 7-bit modulo adders can be constructed \neasily given that typical adders on those machines are 64-bit. As a matter of fact, Intel s adders can \nnow be clocked at 3-4 GHz. In addition, operand decoding is normally conducted in parallel with operator \ndecoding, therefore its latency can be mostly hidden. Thus the delay due to differential decoding should \nnot be a concern at all. Finally, differential encoding only adds slight complexity to the decode stage. \nIt is entirely transparent to the rest of the processor pipeline. 2.2 Two Important Issues The above \ndiscussion may lead to the perception that differential register encoding is always bene.cial. Actually, \ndifferential register encoding is not always applicable in a straightforward manner. In this subsection, \nwe discuss two important issues: difference out of range and multi-path inconsistency . 2.2.1 Difference \nout of Range Sometimes the differences between register numbers can go out of range. For instance, in \nthe previous example of Figure 2.b, if the .rst instruction is R1 = R0 + R2, we need to encode (2 - 0)mod4 \n= 2 for the second source operand, which means we must allow encoding the difference of 0, 1 and 2. If \nwe allow di to take 3 different values, the register .eld must be extended to 2 bits, i.e. DiffW =2. \nThis will completely eliminate the bene.ts of differential encoding since DiffW = RegW . In practice, \nwe get all di values from Equation (1) to see if DiffW can be smaller than RegW . Naturally, we hope \ndi . [0, DiffN - 1] instead of [0, RegN - 1]. In case some di s are out of this range, i.e. di . [DiffN, \nRegN - 1], we can still enforce DiffW < RegW and handle out-of-range di s afterwards, i.e. we use special \ninstructions to tackle out of range cases separately details will be given in Section 2.3. 2.2.2 Multi-Path \nInconsistency During decoding, we always need a unique ni-1, i.e. the previous register number in the \nlast reg to decode the current register num\u00adber. This is quite straightforward for sequential code since \nni-1 is always uniquely determined. However, this may be an issue at control .ow join points. Multiple \npaths from different predeces\u00adsors of a basic block may have different ni-1 s stored in last reg. This \ncauses inconsistency for decoding. As shown in Figure 3, if we assume the access order to be src1, src2.dst, \nthere could be two possible values in last reg at the entry point of BB3. If the ex\u00adecution goes from \nBB1 to BB3, then last reg =1, since R1 is the last register in the access sequence at this point. If \nthe execu\u00adtion goes from BB2 to BB3, then last reg should be 2. Remember that register .elds contain \ndifferences instead of absolute register numbers, therefore we must rely on a unique last reg to decode \nproperly. Multiple execution paths to the same instruction with dif\u00adferent values in last reg could be \nproblematic.  2.3 ISA Extension To solve both problems mentioned above, a special instruction is in\u00adtroduced \nto change the value in last reg. We call it set last reg. Two parameters can be passed to set last reg. \nThe complete for\u00admat is as follows: set last reg(value) set last reg(value, delay num) The .rst type \nof set last reg just assigns the value to last reg, while the second type sets the value after a certain \nnumber of register .elds are decoded. The second type is particularly useful when we want to change last \nreg in the middle of decoding an instruction. For example, instruction R1= R0+ R2 cannot be differential \nencoded because the difference between .rst and second source operands is larger than 1 (assume DiffN \n=2). We can put set last reg(2, 1) in front of this instruction. In this manner, after encoding source \noperand 1, last reg isset to 2, therefore the second .eld can be encoded as 0, which is less than DiffN. \nThe muti-path inconsistency problem can be solved as well. For the example in Figure 3, we can insert \na set last reg at the entry point of BB3, so that last reg will contain the same value regardless of \nwhere the control .ow comes from. Alternatively, we can insert such instruction at the end of one or \nmore predecessors to maintain a consistent last reg value when the execution reaches the join point. \nThe implementation cost of set last reg is as cheap as a move instruction. It actually moves an immediate \nvalue to last reg dur\u00ading instruction decoding. Besides, such instructions are removed after decoding. \nIn other words, for all pipeline stages after decod\u00ading, they do not exist.  3. Overview of Our Approach \nSo far, we have shown that differential encoding can expose more architected registers to the compiler. \nThe previous section hints at how to convert a program after register allocation to the one that uses \ndifferential encoding. However, simply encoding the program with differential encoding could introduce \nmany set last reg in\u00adstructions as indicated in the evaluation section. Therefore, it is im\u00adportant that \nthe increased architected registers can be fruitfully uti\u00adlized towards performance improvements by overcoming \nthe extra cost due to set last reg instructions. We will show several optimization techniques and their \nappli\u00adcations. First we look at how to enhance the register allocation in general through three approaches: \n1) remap the register numbers for differential encoding after register allocation is done. 2) modify \n Figure 4. Overview of the three approaches the select stage of a graph-coloring based register allocator. \n3) com\u00adbine it with the coalescence &#38; select stages of a optimal spilling register allocator [1]. \nWe also discuss other optimizations in Sec\u00adtion 8. Notice that, the optimization s impact increases from \nthe .rst approach to the third approach. Also, the latter ones can make use of the former ones, i.e. \nthey can be combined together. Figure 4 illustrates the 3 approaches. Figure 4.a is the most primitive \nap\u00adproach called differential remapping. Differential remapping can follow any register allocator, therefore \nit is a post-pass approach. It remaps register numbers that are given by the register allocator and attempts \nto maximize the bene.ts of differential encoding. Fig\u00adure 4.b is the second approach, called differential \nselect. We assume a graph coloring based register allocator such as [3, 15, 5]. The al\u00adgorithm is built \ninto the select stage to select register numbers that are bene.cial to differential encoding. Finally, \nthe third approach is based on an optimal spilling regis\u00adter allocator [1]. After the optimal number \nof spills are decided, we construct an interference graph, which is provably colorable with the number \nof registers available (therefore no extra spills get gen\u00aderated) but we still need to remove a large \nnumber of move instruc\u00adtions through coalescence. The original algorithm does aggressive coalescence \nand graph coloring. If the coalescence makes the graph uncolorable, they undo it. We propose differential \ncoalesce, which is combined with the coalesce stage to favor differential encoding. In other words, we \nneed to reduce the number of both moves as well as set last reg instructions. Our approach attempts to \nmerge these two goals. Also, differential select is invoked during the select stage. Furthermore, differential \nremapping can always be invoked after approach 2 or 3, since the two have been integrated into reg\u00adister \nallocation, whereas differential remapping is a post-pass opti\u00admization.  4. Problem Modeling To integrate \ndifferential encoding into register allocation, we need to build not only the interference graph, but \nan adjacency graph. The adjacency graph captures the adjacency of (register resident) variable accesses. \nWe de.ne the adjacency graph as follows. De.nition 2. Adjacency Graph A directed weighted graph, each \nnode represents a live range or a register. An edge from node vi to vj with weight wij means live range \nor register vj immediately follows vi for wij times in the access sequence. Notice that the adjacency \ngraph can be built during register al\u00adlocation or after register allocation (as used in differential \nremap\u00adping). If it is built during register allocation, the nodes are live ranges2. If it is built after \nregister allocation, each node represents a register that has been allocated to one or more live ranges. \nThere\u00adfore the adjacency graph can be more restrictive for post-pass opti\u00ad 2 Sometimes they are called \nvirtual registers. Figure 5. Example for problem modeling mizations, since multiple live ranges might \nbe assigned to the same register leading to more edges being linked to one node. As an example, Figure \n5.a shows a piece of code with 6 live ranges L1 to L6. The access sequence is shown in Figure 5.b, given \naccess order as src1, src2 . . . dst. We assume only L5 and L6 are live after the end of the code segment \nand the interference graph is shown in Figure 5.c. Based on the access sequence and our de.nition of \nthe adjacency graph, we can build the adjacency graph in Figure 5.d. We observe that there is edge with \nweight 2 between L1 and L2 because L1 and L2 appear consecutively in the ac\u00adcess sequence twice. Similarly, \nL2,L3 , L3,L4 , L4,L1 , L2,L5 , L5,L4 , L4,L6 all appear once in the access se\u00adquence, which are shown \nas edges with weight 1 on the adjacency graph. Also notice that, we do not draw any self-looped edge \non the same node for adjacent access pairs like L2,L2 , L3,L3 because they are always covered with differential \nencoding, i.e. we can specify the difference to be 0 and put 0 in the register .eld. Next, we want to \naddress the objective function associated with the differential register allocation. Eventually each \nnode will be as\u00adsigned a register number. Traditional register allocation only en\u00adsures that the same \nregister should not be assigned to co-live (in\u00adterfering) ranges at a program point. However, with differential \nen\u00adcoding, we are not only interested in enforcing the above restriction but are also concerned with \nthe actual register numbers that are as\u00adsigned to live ranges. Intuitively, the adjacency graph speci.es \nthe requirements for the register numbers that are assigned to two ad\u00adjacently accessed nodes. Suppose \nthere is an edge from node vi to node vj with weight wij . If the register number for vi is reg no(vi) \nand the register number for vj is reg no(vj ), they should satisfy: 0 = (reg no(vj ) - reg no(vi)) mod \nRegN < DiffN (3) Only when condition (3) is satis.ed, we can use differential encoding to encode vi when \nthe previous access is to vj . Otherwise, we need extra set last reg instruction to adjust last reg after \naccessing vi. The weight of the edge represents the number of times vj immediately follows vi. Thus, \nif condition (3) cannot be satis.ed, we will need wij set last reg instructions. Thus, as an objective \nfunction we must minimize the total cost which is the sum of edge weights in adjacency graph that do \nnot satisfy condition (3). For the example in Figure 5, we give an optimal solution in Figure 5.e, assuming \nRegN =3 and DiffN =2. Notice that all edges on the adjacency graph satisfy condition (3), therefore we \nneed no extra instructions for differential encoding. Formally, the optimization objective is expressed \nas follows. OPTIMIZATION OBJECTIVE. Devise a register allocation scheme to all live ranges which not \nonly considers the objective of a tradi\u00adtional register allocation but also tries to minimize the sum \nof edge weights on the adjacency graph that do not satisfy condition (3). Notice that, differential register \nallocation is built on top of a traditional register allocator which means it must .rst satisfy the requirements \nof a register allocation algorithm such as: at any program points, co-live live ranges should not be \nassigned with the same register and the number of co-live live ranges should not exceed the total number \nof registers. Since the number of set last reg instructions is also an extra cost involved in the reg\u00adister \nallocation, we consider this together with other costs such as the number of spills. Many complicated \nregister allocation schemes have been pro\u00adposed in literature. Techniques such as variable coalescence \n[3] can change the shape of the adjacency graph, however we can always modify the adjacency graph accordingly \nand get the cost for differ\u00adential register encoding. Therefore, the adjacency graph is a viable means \nto help with a traditional register allocator for the purpose of differential encoding. The example in \nFigure 5 is only a piece of sequential code. For adjacent access pairs that cross basic block boundary, \ni.e. from the last access in the predecessor to the .rst access in the current basic block, we can set \nthe edge weight differently. Although there could be multiple edges from the last accesses of several \npredecessors of a basic block, actually we need at most one set last reg instruction at the beginning \nof the basic block. Thus, in such cases we divide the add-on weight of the edge by the number of predecessors \nof the basic block. Finally, pro.le information could be incorporated to improve the cost estimation. \nDifferent adjacent access pairs have different execution frequencies. For a better estimation, the frequency \nshould be re.ected in the edge weights.  5. Differential Remapping Our .rst approach attempts to remap \nthe register numbers after a register allocator has completed register allocation. As mentioned in Section \n2, we temporarily assume the registers under considera\u00adtion are uniform and classless. Differential remapping \npermutes the register numbers and thus it does not change the solution given by a traditional register \nallocator (which only enforces the constraint that co-live ranges should get different registers). However, \npermut\u00ading the register numbers could lead to different costs for differen\u00adtial register encoding and \nthis is what we attempt to optimize in the post-pass. A simple example is shown in Figure 6. The interference \ngraph is in Figure 6.b; we have 3! ways to assign registers to the live ranges. In other words, as long \nas the 3 live ranges are assigned to different registers, the solution is acceptable for a traditional \nregister allocator. Using the adjacency graph shown in Figure 6.b, we calculate the cost as described \nin the last section (according to condition (3)), assuming RegN =3 and DiffN =2. The costs under different \npermutations are different, since the actual register numbers do matter for differential encoding. Differential \nremapping comes after register allocation, therefore all live ranges have been assigned register numbers. \nIt attempts per\u00admutations of register numbers as illustrated in Figure 6. First of all, we take the code \nand build an adjacency graph with RegN nodes, where each node is a register (e.g. the top of Figure 6.d). \nSince the live ranges have been assigned registers and each register .eld must contain one of the RegN \nregisters, the adjacency graph should con\u00adsist of RegN nodes only. We then check the permutations of \nthe RegN registers and calculate the cost from the adjacency graph to .nd better solutions. For example, \nin Figure 6.d, we permute the register numbers and get a solution with 0 cost. An exhaustive search algorithm \nhas to try all RegN! Permu\u00adtations. For each permutation, it needs to check all the edges on the adjacency \ngraph to .nd the cost. Thus the complexity of the exhaustive search is O(RegN2RegN!). This is actually \ntractable  Figure 6. Example for register remapping for small RegN values, but can cost long compilation \ntime when RegN gets bigger, e.g. 32. Thus, we give a polynomial time heuristic algorithm as shown in \nFigure 7. It is a greedy algorithm, which .nds a path in the solution space that achieves the fastest \ncost reduction until a local minimum is reached. We .rst de.ne register vector RV as a vector with RegN \nelements. The register vector represents a permutation of the RegN numbers from 0 to RegN - 1. Given \nthe register vector, we can have the permutation P as P (i)= RV [i], where i . [0, RegN -1]. Initially, \nthe RV is set to < 0, 1, 2 . . . RegN -1 >, which means, the register numbers are not permuted and have \none\u00adto-one correspondence to the nodes on the adjacency graph. The algorithm contains a main loop. During \neach iteration, we attempt all possibilities to swap two elements in the register vector. After each \nswap, the new register vector is used to .nd out the new cost on the adjacency graph. Only the swap yielding \nthe biggest cost reduction is picked during a given iteration. Therefore, after each iteration the cost \nis reduced. When no further cost reduction results, we have found a local minimum and the search stops \nimmediately. To improve solution quality, we also select a number of (1000) initial RV s to start with \nand pick the best solution amongst those generated. The complexity of the algorithm includes two terms \nmulti\u00adplied together. During each iteration in the main loop, RegN \u00d7 (RegN - 1)/2 pairs can be swapped \nand checking the cost on the adjacency graph requires O(RegN2). Finally, each iter\u00adation must reduce \nthe cost somehow, therefore we would have O(sum of weights on the adjacency graph) \u00d7 O(RegN4) as the \ncomplexity of the algorithm, which is reasonably small.  6. Differential Select Differential remapping \ncan be conveniently employed after any register allocator, however its effectiveness is quite limited. \nThe reason is that the adjacency graph consists of registers and not live ranges which makes it very \ndense (in terms of node degrees) and restrictive . For instance, if one node has more than DiffN neighbors \nwith different register numbers assigned, no permutation could satisfy condition (3) for all edges incident \nto these neighbors. Thus, in this section, we attempt our optimization in the select stage of a graph-coloring \nregister allocator hoping to get better solution by working on the adjacency graph consisting of live \nranges in stead of registers. For a graph-coloring based register allocator, the select stage is in charge \nof picking register numbers (or colors) for the nodes (live ranges) when adding them back to the interference \ngraph. When picking register number for a node, we need to check the register numbers that have been \nused by its neighbors on the interference graph. If its neighbors have used all the colors (RegN colors), \nwe have to spill the live range. On the other hand, if there are colors unused by its neighbors, the \nnew node can be colored with one of them. If there are multiple unused colors available, most algorithms \njust pick a color arbitrarily. In [15], the author proposed biased coloring to select colors that can \npotentially reduce extra spills, i.e. try to color the source and destination operands of a move instruction \nwith the same color. In this paper, we also intentionally pick colors that can bene.t from differential \nencoding. In a graph coloring register allocator, nodes are popped from a stack and inserted into the \n(partial) interference graph (consisting of nodes popped earlier), while the differential select algorithm \nas shown in Figure 8 inserts nodes into both interference graph and adjacency graph. Edges from the new \nnode to those previously inserted are recovered. Next, we determine if the currently popped node should \nbe spilled or not. If it must be spilled, the register allocator will handle this as usual, otherwise \nwe get a number of register numbers (colors) that can be safely assigned to this node. At this point, \npicking any register number is acceptable for the constraints on the interference graph, therefore we \nonly need to look at the adjacency graph. We then calculate the extra cost of allocating each of the \navailable colors to the node based on condition (3). Finally, we simply pick the register number that \nincurs the minimal cost.  7. Differential Coalesce In this section, we discuss how to apply differential \nencoding to an optimal spilling register allocator [1]. The register allocator uses ILP solver to .nd \noptimal spilling at the .rst step. Optimal spilling is achieved by enforcing that at each program point, \nat most RegN live ranges are co-live. This gives an optimal number of spills because we can always assign \nregisters to live ranges if enough move instructions are inserted. In the worst case, there will be a \nlarge number of moves inserted to split the live ranges. The second step of the register allocator uses \na heuristic algorithm to coalesce moves and color the interference graph. They .rst do this aggressively \nas in Chaitin s register allocation, then undo  Figure 8. Differential select algorithm some coalescences \nonce the graph becomes over-constrained, i.e. becomes uncolorable without introducing spills. A .ow graph \nof the differential coalesce algorithm is shown in Figure 9. It coalesces nodes step by step and every \ntime it tries to pick a pair of nodes for maximal cost reduction during coalescing. Notice that the rebuild&#38;simplify \nand differential select stages have been made into functions, which get called and return the cost on \nthe adjacency graph or return uncolorable if the graph becomes uncolorable after current coalescence. \nThe result of each coalescence attempted is recorded but the coalescence itself is not committed. We \nundo the coalescence and try another coalescence until all possibilities have been exhausted on the current \ngraph. Then we apply the one with maximal cost reduction. Here, the cost not only includes the one for \ndifferential encoding (calculated from the adjacency graph) but also includes the cost eliminated due \nto move instructions removed. As we have observed, the cost reduction is actually more sensitive to the \nreduction of differential encoding cost. Besides, we assume that a set last reg instruction is of the \nsame computation cost as a move instruction since the former also moves a value to an on-chip register. \nIn case either there is no cost reduction or all coalescences lead to uncolorable graph, the algorithm \nterminates. By considering the cost due to both move and set last reg instructions, the algorithm targets \nthe overall optimization objective. The complexity of the algorithm is higher than the original one, \nwhich coalesces aggressively .rst instead of trying all pos\u00adsible coalescences and picking the best candidate \nat each coales\u00adcence. Theoretically, we have the complexity as O((#moves)2) \u00d7 O(complexity of differential \nselect). Here the subroutine consist\u00ading rebuild&#38;simplify and differential select is invoked at most \nO((#moves)2) times, and the complexity of differential select is much higher than rebuild&#38;simplify \n. Figure 10. Modulo scheduling .owchat  8. Other Applications We now discuss other applications of differential \nencoding. 8.1 Software Pipelining Software pipelining attempts to extract parallelism out of loops by \noverlapping the execution of several consecutive iterations. The overlapping of iterations could impose \nhigh register requirements. Besides, if loop optimizations like unroll and jam , subexpres\u00adsion elimination \n, back substitution are applied as well, the reg\u00adister pressure could be further increased. Although \nhardware man\u00adaged rotating registers (for example in the Itanium processor) could help to reduce register \npressure, they are not always available. On the other hand, compile-time renaming through modulo variable \nexpansion (MVE) [9] has to unroll the loop kernel leading to higher register pressure. As indicated in \n[21], a signi.cant portion of the execution time is spent on loops requiring more than 64 registers. \nThere are many register allocation schemes proposed with respect to modulo scheduling, such as [11, 16, \n18, 20]. Typically the al\u00adgorithms follow the .owchart in Figure 10. The register allocation algorithm \ndoes not introduce spills, because spills occupy memory units, thus spill decision must be made together \nwith scheduling. Due to the relatively small number of instructions in a loop, the reg\u00adister allocator \nis normally highly optimized. As a result, we propose to apply differential remapping only, such that \nour scheme does not affect the original register allocator. Notice that, set last reg in\u00adstructions do \nnot enter the execution stage, therefore inserting such instruction will not affect the original schedule. \nTo avoid disrupt\u00ading the instruction words that impact multiple instructions, we can choose to promote \nall set last reg instructions before the module scheduled code. By setting the delay number properly, \nall instruc\u00adtions can be differential decoded properly.  Figure 9. Differential coalesce algorithm \n8.2 Selectively Enable Differential Encoding Even for processors with ample architected registers, register \npres\u00adsure can increase due to compiler optimizations like aggressive in\u00adlining, allocating global variables \nand promoting aliased variables etc. It is likely that in some regions register pressure is very high, \ntypically those frequently executed and heavily optimized code segments. Differential encoding can be \neasily turned on and off. In other words, we only need to enable differential encoding when the bene.ts \nof performance improvements exceed the extra costs due to set last reg instructions.  9. Other Considerations \n9.1 Register Classes Normally, registers belong to multiple classes such as integer regis\u00adters, .oating \npoint registers etc. Our approach is still applicable un\u00adder such circumstances. We can categorize register \naccesses based on their classes and perform encoding and decoding separately. During encoding, the access \nsequence only contains registers be\u00adlonging to the same register class. In other word, if we start to \nen\u00adcode integer registers, accesses to other classes are skipped. Dur\u00ading decoding, we need a separate \nlast reg register for each class. Therefore, all register allocation algorithms can be applied accord\u00adingly \nto each class of registers. 9.2 Special Purpose Registers Some of the registers may have special purposes, \nsuch as stack pointer, frame pointer, zero register, etc. Such registers might be used so frequently \nthat the nodes on the adjacency graph become over-constrained. Thus it is not bene.cial to include these \nregis\u00adters in differential encoding, which could induce a large number of set last reg instructions, \nbecause we will frequently see these registers being accessed after other registers. These registers \nmust still be properly addressed. Remember that we have DiffW bits for encoding. In practice, we can \nreserve some register numbers in the encoding space for the special purpose registers, therefore DiffN \n< 2DiffW . For both encoding and decoding, these reg\u00adister numbers are assumed to be encoded directly \n(may add by a constant value). For instance, if there are 16 physical registers R0 ...R15, and R15 is \nstack pointer. To encode into 3 bits, we can reserve number 7 for the stack pointer. Then DiffN actually \nequals 7, i.e. only 0..6 are used for differential encoding. Whenever we see 7 in the register .eld, \nit is the stack pointer. We add it by 8 to get R15. 9.3 Context Switches, Function Calls During context \nswitches, only the last reg should be stored to\u00adgether with the context. This overhead is almost negligible. \nFunc\u00adtion calling conventions typically designate a number of registers as caller-saved/callee-saved. \nFor approaches 2 and 3, they are just part of the register allocator, therefore they won t affect the \nway the register aclloctor handles the calling convention (typically these registers are precolored etc.). \nFor differential remapping, if all allo\u00adcated registers are remapped, the caller-saved/callee-savee registers \nmight be remapped to other registers, breaking the calling conven\u00adtion. This problem can be solved as \nfollows. We .rst apply differ\u00adential remapping regardless of the caller-save/callee-save conven\u00adtions, \nthen remedy them separately by inserting a few set last reg instructions. For example, if the caller-save \nregisters are r4,r5,r6, and they are remapped to r8,r0,r1. There should be store instruc\u00adtions in front \nof a function call. They originally look like ST r4..; ST r5..; ST r6.. and now becomes ST r8..; ST r0..; \nST r1 We can simply restore them to the original register numbers then apply dif\u00adferential encoding, \ni.e. we may insert a few set last reg instruc\u00adtions in the middle of these caller-save instructions if \ndifferences are out of range. 9.4 Other Alternatives Furthermore, there are other interesting alternatives \nthat can be evaluated further. For example, we can change the last reg per instruction instead per register \n.eld. Also, the access order can be more .exible. For instance, different types of instructions may have \ndifferent access order. Since access order decides the order of registers in the access sequence and \nthe edge connection on the adjacency graph, a more .exible access order may incur less cost. Due to the \nlimited scope of this paper, we have not looked at these alternatives.  9.5 Work with Instruction Scheduling \nOur approaches 2 and 3 are part of the register allocation pass inside the compiler. In other words, \nour optimization has been integrated with register allocation, therefore instruction scheduling can be \nap\u00adplied either before or after. Approach 1 works as a postpass opti\u00admization. It can be applied after \nboth register allocation and instruc\u00adtion scheduling when the access sequence has been completely de\u00adtermined. \nFinally, with differential encoding, set last reg instruc\u00adtions only exists till decode stage, they will \nnot enter the pipeline and affect scheduled code. 10. Evaluation We evaluate our schemes for two types \nof machine con.gurations using the Simplerscalar toolset [2]. As mentioned earlier, differen\u00adtial register \nallocation is only pro.table when the bene.t of more architected registers exceeds the cost due to extra \ninstructions. If differential register allocation is simply combined with a register allocator, it is \nonly pro.table for low-end processors with tight en\u00adcoding space. The bene.ts decrease as more registers \nare supported on the architecture. However, if we use it adaptively for high reg\u00adister pressure regions, \nsuch as software pipelined code, it becomes pro.table even for high performance processors. 10.1 Evaluation \non a Low-end Processor with Tight Encoding Space We evaluate our approaches on a machine model similar \nto the ARM/THUMB architecture. It is a 5-stage in order issue processor Table 1. We assume the original \nISA only allows 8 registers to be addressed but the architecture actually supports 16 registers. We evaluate \n10 benchmark programs from Mibench [17]. The Mibench is quite close to the industrial standard EEMBC \nbenchmark suite for embedded processors. Due to library problems, we only pick part of the benchmark \nsuite that can run successfully. Besides, we do not measure power, area, etc., since our main objective \nis to improve performance. In this experiment, we replace gcc s register allocation phase by implementing \niterated register allocation [5]. We call it the baseline code. The second setup is called remapping \n, in which the baseline code undergoes differential remapping as described in Section 5. The third setup \ncalled select follows differential se\u00adlect, where the select phase of the iterated register allocator \nis mod\u00adi.ed as described in Section 6. To evaluate differential coalesce, we implemented the optimal \nspill register allocation [1] and modi.ed its coalesce phase as in Section 7. Please note that differential \nencoding allows more registers to be used and thus the binaries for remapping , select and co\u00adalesce \nare produced with appropriately higher number of regis\u00adters than the baseline and the optimal spill register \nallocator, which used eight registers only, i.e. RegN = DiffN =8. In other words, no differential encoding \nis applied. All register .elds are di\u00adrectly encoded. For the three approaches with differential register \nencoding and allocation, we set RegN = 12 for Figure 11 to Fig\u00adure 14. Thus, the code for remapping , \nselect and coalesce can address 12 registers as against 8 registers used for the base\u00adline and optimal \nspill cases. Since there are 3 bits for each register .eld and no special purpose registers are included, \nwe always have DiffN =8 and DiffW =3. Figure 11 shows comparison for percentage of static spills gen\u00aderated \nover the entire code. We observe dramatic decrease of spills from the baseline for all three approaches, \nsince differential encod\u00ading allocates with 12 registers which contributes to the reduction of spills. \nDifferential remapping and select are quite close, indi\u00adcating that the number of spills is not sensitive \nto our algorithm but to the available registers and the register allocator. For O-spill (optimal spill), \nalthough it achieves much less spills than the base\u00adline, it is still a little bit worse than the differential \nones, because it allocates with 8 registers. On average, the spill code percentages are 10.44%, 6.87%, \n6.84%, 7.32%, 5.55% for baseline , remap\u00adping , select , O-spill and coalesce respectively. Figure 12 \ncompares the cost for the 3 differential algorithms. Here cost means the number of set last reg instructions \nintro\u00adduced over the entire code as a percentage. These are static num\u00adbers. Not surprisingly, remapping \ngenerates a large number of set last reg instructions, whereas the other two approaches are much better. \nBetween the last two approaches, differential coalesce is slightly better. On average, the percentages \nfor the 3 algorithms are 10.41%, 4.21%, 3.04% respectively. Figure 13 shows code size comparison. All \nnumbers are nor\u00admalized to the baseline. Although differential encoding reduces the number of spills, \nsome of the approaches cause more set last reg instructions. In short, remapping increases code size \nby 7% over the baseline, whereas differential select only affects the code size by less than 1%. Both \nO-spill and coalesce actually reduce the code size (4% and 2%).  Figure 12. Cost comparison Figure 13. \nCode size comparison Finally, we look at the speedup of the 4 cases over the baseline Figure 14. Due \nto the high cost incurred for remapping, most of the bene.ts with more registers are eliminated. Also, \ncoalesce is best due to its reduction in spills and set last reg instructions. The amount of improvement \nis quite irregular across benchmarks, perhaps because we rely on static weight estimation instead of \npro\u00ad.le information. In summary, the three approaches achieve aver\u00adage speedups of 4.5%, 9.7%, 12.1% \nrespectively, whereas O-spill achieves 4.1% speedup.  Figure 14. Speedup comparison  10.2 Evaluation \non a High-Performance Processor We evaluate the differential encoding on a VLIW machine model with 32 \narchitected registers and 64 physical registers. There are 4 functional units, 2 memory ports. We adopt \nthe modulo scheduling algorithm as described in [21]. The scheduling algorithm carefully spills variables \nwhen the number of used registers exceeds the number of available registers. Notice that, in such cases \nwe can increase the Initiation Interval (II) to reduce register pressure which might avoid spills. However \nearlier research has suggested that spilling most likely leads to less slowdown. We studied 1928 (innermost) \nloops that are selected from the SPEC2000 integer benchmark suites. The execution of these loops constitutes \nover 80% of all execution time. We also assume that other loop optimizations have been enabled in the \ncompiler during the code generation. We found that among these loops, about 11% require more than 32 \nregisters, which means they must incur spills. These loops are typically big and account for a signi.cant \nportion of the overall loop execution time (over 30%). We set DiffN = 32, then change RegN to a number \nof values: 32,40,48,56,64. When RegN = 32, it means no differential encoding is involved, i.e. it is \nthe original software pipelined code but without differential encoding. Notice that we only use differential \nencoding for those loops demanding more than 32 registers to reduce their spills. For loops with enough \nregisters (no spills), differential encoding is turned off to avoid extra cost due to set last reg instructions. \nWe count the extra instructions to turn on/off differential encoding as well, although they are not involved \nin loops and their performance impact is marginal. Table 2 shows the speedup for the code after our optimiza\u00adtion. \nWe can observe signi.cant speedup for the loops that are optimized-as shown in the second column. Larger \nRegN tends to improve the performance a lot, however the improvement gradually saturates after RegN is \nlarger than 48. The speedup for all loops is from 10.23(regN = 40) to 17.24(RegN = 64). The overall speedups \nare close to those for all loops because most of the cycles are spent on loops. Table 2. Speedup comparison \nTable 3. Spill and code growth comparison Table 3 presents the number of spills in optimized loops and \nthe code growth. Clearly, the number of spills decrease considerably when RegN is increased from 32 to \n40 and 48. The 3rd to 5th columns are about code growth for optimized loops , all loops and all code \nrespectively. Although spills are reduced, more costs are induced with larger RegN as mentioned earlier. \nAlso, since we conly apply differential remapping , the number of set last reg instructions increases \na lot. However the part of loops that are being optimized only takes a small portion of the entire code. \nTherefore the overall code growth is 1.13% at most. Notice that, when RegN = 40, we can actually reduce \ncode size, because more spills are saved than the extra cost. We observe very small compilation time \nfor our approaches (tens of seconds), except the optimal spill register allocator (gen\u00aderating the optimal \nspilling takes time as it involves CPLEX solver, but this is not due to our algorithm). Since our approaches \nare mostly used for low-end systems, where applications are relatively small or part of the big applications \non high-performance proces\u00adsor, compilation time should not be an issue in both cases. Besides, we did \nnot present results on power, since the goal of this work is to improve performance.  11. Related Work \n[7] proposes a scheme to make use of more physical registers by mapping architected registers to physical \nregisters dynamically. Special instructions are added to designate the mapping and there is a mapping \ntable managed by the hardware. Their scheme is more complicated, therefore may not be suitable for low-end \nmachines. Compared with their work, this paper proposes lightweight ap\u00adproaches that can be widely applicable \nwith good performance. By making small changes in the ISA and using the differential regis\u00adter addressing, \nwe have shown that it is possible to overcome the addressing bottleneck in the ISA. [23] talks about \nmanaging extended registers, i.e. registers not addressable through ISA, with hardware support. Their \napproach not only complicates hardware design but is less precise, since register allocation information \nis conveyed to the hardware through offsets of spills. The results given in [23] only show moderate performance \nimprovements. Compiler-controlled memory (CCM) [4] is a piece of on-chip memory for spills. The compiler \ncan allocate spills to the CCM. However, CCM is typically much bigger, e.g. over 1KB, thus is slower \nand costs more power. Instead our scheme has a very small overhead. Also the CCM optimization actually \ncan be combined with our algorithm to redirect some spills to the CCM. Other architecture solutions to \nextend the register .le like the hierarchical register .le [22] and stack value .le [10] can induce high \nhardware cost but do not provide a ways to tackle the ISA bot\u00adtleneck that restricts the number of registers \nseen by the compiler. Therefore, these work are orthogonal to this paper. Register window e.g. the one \nused on SPARC and IA-64 ma\u00adchines, provides another way to expose more registers to reduce function call/context \nswitch overhead. Differential encoding is more widely applicable because all code can be allocated with \nmore registers. Clustered architectures, like the Alpha 21264 and some VLIW machines distribute and associate \nregisters .les with functional units. The compiler must explicitly allocate register to different clusters \nand copy values across clusters [14]. This work provides a general scheme that does not require such \narchitecture. Also our modi.cation and overhead to the architecture is very small, making it applicable \nto a wide range of machines, especially for embedded processors with stringent encoding restrictions. \n 12. Conclusion This paper proposes differential encoding that can provide more architected registers \nthan the register .eld allows. We study 3 approaches to combine it with register allocation to achieve \nbetter performance. We also propose a combined approach to reduce spills for software pipelining. Although \ndifferential encoding induces set last reg instruc\u00adtions, these instructions are much cheaper than spills. \nAs long as we properly choose RegN/DiffN and apply the schemes to cases when more architected registers \nyield enough bene.ts (such as re\u00adduce a signi.cant number of spill), differential encoding can help improve \nthe performance. In this paper, we illustrated it in two sce\u00adnarios, i.e. register allocation for low-end \nsystem with stringent en\u00adcoding limitation, and high-end system where software pipelining results in \nincreased register pressure. Actually, there could be wider applications of the scheme if more architected \nregisters can be con\u00adverted into performance improvements. Our results show that differential encoding \nsigni.cantly reduces the number of spills and speeds up program execution. For a low\u00adend con.guration, \nit achieves 12% speedup with slightly reduced code size. For optimization on loops, it signi.cantly speeds \nup loops with high register pressure (over 70% speedup). Acknowledgments We would like to thank anonymous \nPLDI referees for their com\u00adments and suggestions and also Mr. Josh Fryman from Georgia Tech for his \nhelp on the architecture side. References [1] Andrew W. Appel and Lal George. Optimal spilling for cisc \nmachines with few registers. In Proceedings of the ACM SIGPLAN 2001 conference on Programming language \ndesign and implementation, pages 243 253, 2001. [2] D. Burger and T.M. Austin. The SimpleScalar Tool \nSet. Version 2.0, Tech. Report No. 1342, Computer Sciences Department, University of Wisconsin-Madison, \nJune 1997. [3] Gregory J. Chaitin, Marc A. Auslander, Ashok K. Chandra, John Cocke, Martin E. Hopkins, \nand Peter W. Markstein. Register allocation via coloring. Computer Language, 6(1):47 57, 1981. [4] Keith \nD. Cooper and Timothy J. Harvey. Compiler-controlled memory. In Proceedings of the eighth international \nconference on Architectural support for programming languages and operating systems, pages 2 11, 1998. \n[5] Lal George and Andrew W. Appel. Iterated register coalescing. ACM Trans. Program. Lang. Syst., 18(3):300 \n324, 1996. [6] Intel Inc. SA-110 Microprocessor Technical Reference Manual, September 1998. [7] Tokuzo \nKiyohara, Scott Mahlke, William Chen, Roger Bringmann, Richard Hank, Sadun Anik, and Wen-Mei Hwu. Register \nconnection: a new approach to adding registers into instruction set architectures. In Proceedings of \nthe 20th annual international symposium on Computer architecture, pages 247 256, 1993. [8] A. Krishnaswamy \nand R. Gupta. Pro.le Guided Selection of ARM and Thumb Instructions. In ACM SIGPLAN Joint Conference \non Languages Compilers and Tools for Embedded Systems (LCTES). ACM, June 2002. [9] M. S.-L. Lam. A Systolic \nArray Optimizing Compiler. Carnegie Mellon University, 1987. [10] Hsien-Hsin S. Lee, Mikhail Smelyanskiy, \nGary S. Tyson, and Chris J. Newburn. Stack value .le: Custom microarchitecture for the stack. In Proceedings \nof the Seventh International Symposium on High-Performance Computer Architecture (HPCA 01), 2001. [11] \nJosep Llosa, Mateo Valero, and Eduard Ayguad\u00b4e. Heuristics for register-constrained software pipelining. \nIn Proceedings of the 29th annual ACM/IEEE international symposium on Microarchitecture, pages 250 261, \n1996. [12] MIPS Technologies. MIPS32 Architecture for Programmers Volume IV-a: The MIPS16 Application \nSpeci.c Extension to the MIPS32 Architecture, March 2001. [13] Motorola Inc. Motorola DSP56300 Family \nManual, Revision 3.0, November 2000. \u00a8 schedule: A new approach to scheduling for clustered register \n.le microarchitectures. In Proceedings of the 31st Annual ACM/IEEE International Symposium on Microarchitecture \n(MICRO-98), pages 308 315, November 1998. [14] E. Ozer, S. Banerjia, and T. M. Conte. Uni.ed assign and \n[15] P.Briggs, K.Cooper, and L.Torczon. Improvements to Graph Coloring Register Allocation. In Proceedings \nof the ACM SIGPLAN 2001 conference on Programming language design and implementation (PLDI). ACM, 1994. \n[16] B. R. Rau, M. Lee, P. P. Tirumalai, and M. S. Schlansker. Register allocation for software pipelined \nloops. In Proceedings of the ACM SIGPLAN 1992 conference on Programming language design and implementation, \npages 283 299, 1992. [17] Andrew M. R.Guthaus, J.S.Ringenberg, D.Ernst, T.M.Austin, T.Mudge, and R.B. \nBrown. Mibench: A free, commercially representative embedded benchmark suite. In IEEE 4th Annual Workshop \non Workload Characterization. IEEE, 2001. [18] John Ruttenberg, G. R. Gao, A. Stoutchinin, and W. Lichtenstein. \nSoftware pipelining showdown: optimal vs. heuristic methods in a production compiler. In Proceedings \nof the ACM SIGPLAN 1996 conference on Programming language design and implementation, pages 1 11, 1996. \n[19] S. Segars. Low Power Design Techniques for Micro-processors. In IEEE International Solid-State Circuits \nConference (ISSCC), 2001. [20] Jian Wang, Andreas Krall, M. Anton Ertl, and Christine Eisenbeis. Software \npipelining with register allocation and spilling. In Proceed\u00adings of the 27th annual international symposium \non Microarchitec\u00adture, pages 95 99, 1994. [21] Javier Zalamea, Josep Llosa, Eduard Ayguad\u00b4e, and Mateo \nValero. Improved spill code generation for software pipelined loops. In Proceedings of the ACM SIGPLAN \n2000 conference on Programming language design and implementation, pages 134 144, 2000. [22] Javier Zalamea, \nJosep Llosa, Eduard Ayguad\u00b4e, and Mateo Valero. Two-level hierarchical register .le organization for \nvliw processors. In Proceedings of the 33rd annual ACM/IEEE international sympo\u00adsium on Microarchitecture, \npages 137 146, 2000. [23] Xiaotong Zhuang, Tao Zhang, and Santosh Pande. Hardware\u00ad managed register allocation \nfor embedded processors. In Proceedings of the 2004 ACM SIGPLAN/SIGBED conference on Languages, compilers, \nand tools, pages 192 201, 2004.  \n\t\t\t", "proc_id": "1065010", "abstract": "Micro-architecture designers are very cautious about expanding the number of architected registers (also the register field), because increasing the register field adds to the code size, raises I-cache and memory pressure, complicates processor pipeline. Especially for low-end processors, encoding space could be extremely limited due to area and power considerations. On the other hand, the number of architected registers exposed to the compiler could directly affect the effectiveness of compiler analysis and optimization. For high performance computers, register pressure can be higher than the available registers in some regions, e.g. due to optimizations like aggressive function inlining, software pipelining etc. The compiler cannot effectively perform compilation and optimization if only a small number of registers are exposed through the ISA. Therefore, it is crucial that more architected registers are available at the compiler's disposal without expanding the code size significantly.In this paper, we look at a new register encoding scheme called differential encoding that allows more registers to be addressed in the operand field of instructions than the direct encoding currently being used. We show it can be implemented with very low overhead. Based upon differential encoding, we apply it in several ways such that the extra architected registers can benefit the performance. Three schemes are devised to integrate differential encoding with register allocation. We demonstrate that differential register allocation is helpful in improving the performance of both high-end and low-end processors. Moreover, We can combine it with software pipelining to provide more registers and reduce spills.Our results show that differential encoding significantly reduces the number of spills and speeds up program execution. For a low-end configuration, we achieve over 12% speedup while keeping code size almost unaffected. For optimization on loops, it significantly speeds up loops with high register pressure (over 70% speedup).", "authors": [{"name": "Xiaotong Zhuang", "author_profile_id": "81100621952", "affiliation": "Georgia Institute of Technology, Atlanta, GA", "person_id": "PP28017370", "email_address": "", "orcid_id": ""}, {"name": "Santosh Pande", "author_profile_id": "81409594751", "affiliation": "Georgia Institute of Technology, Atlanta, GA", "person_id": "PP17009986", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065031", "year": "2005", "article_id": "1065031", "conference": "PLDI", "title": "Differential register allocation", "url": "http://dl.acm.org/citation.cfm?id=1065031"}