{"article_publication_date": "06-12-2005", "fulltext": "\n Register Allocation for Software Pipelined Multi-dimensional Loops Hongbo Rong Alban Douillet Guang \nR. Gao Department of Electrical and Computer Engineering, University of Delaware, Newark, DE 19716-3130 \n {rong, douillet, ggao}@capsl.udel.edu Abstract Software pipelining of a multi-dimensional loop is an \nimportant optimization that overlaps the execution of successive outermost loop iterations to explore \ninstruction-level parallelism from the en\u00adtire n-dimensional iteration space. This paper investigates \nregister allocation for software pipelined multi-dimensional loops. For single loop software pipelining, \nthe lifetime instances of a loop variant in successive iterations of the loop form a repetitive pattern. \nAn effective register allocation method is to represent the pattern as a vector of lifetimes (or a vector \nlifetime using Rau s terminology) and map it to rotating registers. Unfortunately, the software pipelined \nschedule of a multi-dimensional loop is consid\u00aderably more complex, and so are the vector lifetimes in \nit. In this paper, we develop a way to normalize and represent vec\u00adtor lifetimes in multi-dimensional \nloop software pipelining, which capture their complexity, while exposing their regularity that en\u00adables \nus to develop a simple, yet powerful solution. Our algorithm is based on the development of a metric, \ncalled distance, that quantitatively determines the degree of potential overlapping (con\u00ad.icts) between \ntwo vector lifetimes. We show how to calculate and use the distance, conservatively or aggressively, \nto guide the regis\u00adter allocation of the vector lifetimes under a bin-packing algorithm framework. The \nclassical register allocation for software pipelined single loops is subsumed by our method as a special \ncase. The method has been implemented in the ORC compiler and produced code for the Itanium architecture. \nWe report the effective\u00adness of our method on 134 loop nests with 348 loop levels. Several strategies \nfor register allocation are compared and analyzed. Categories and Subject Descriptors D.3.4 [PROGRAMMING \nLANGUAGES]: Processors Compilers, Optimization General Terms Algorithms, Languages Keywords Software \nPipelining, Register Allocation 1. Introduction Software pipelining of a multi-dimensional loop nest \noverlaps the execution of successive outermost loop iterations to explore instruction-level parallelism \nfrom the entire n-dimensional itera\u00adtion space. The traditional approaches mainly focus on scheduling \nof the innermost loop, and extend the schedule toward an outer loop by hierarchical reduction [9, 11]. \nAn alternative way is to perform innermost loop software pipelining after loop transformations [3]. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 05 June 12 \n15, 2005, Chicago, Illinois, USA. Copyright 2005 ACM 1-59593-056-6/05/0006...$5.00. Single-dimension \nSoftware Pipelining (SSP) [14, 13] is a unique resource-constrained software pipelining framework that \noverlaps the iterations of an n-dimensional (n-D) loop. It simpli\u00ad.es the n-D loop scheduling problem \ninto a 1-D (1-dimensional) loop scheduling problem, produces a 1-D schedule, and maps it back to the \nn-D iteration space to generate a parallelized loop nest. The classical modulo scheduling [1] is subsumed \nby SSP as a spe\u00adcial case. This paper investigates register allocation for software pipelined loop nests \nby SSP. To the best of our knowledge, no study has ever been reported on the topic. Existing methods \nfor allocating registers for loop nests [6, 2] are extensions of the traditional graph color\u00ading approach \n[4] and do not aim at software pipelining. However, lifetimes in a software pipelined loop have regular \npatterns [12], which should be taken advantage of by an ef.cient register allo\u00adcator. Traditional software \npipelining of loop nests [9, 11] centers around scheduling, with little discussion on register allocation. \nFor single loop software pipelining, the lifetime instances of a loop variant in successive iterations \nof the loop form a repetitive pattern. An effective register allocation method is to represent the pattern \nas a vector of lifetimes (or a vector lifetime using Rau s terminology) and map it to rotating registers \n[12, 5]. Unfortunately, the software pipelined schedule of a loop nest is considerably more complex, \nand so are the vector lifetimes in it, which leads to interesting and serious challenges for register \nallocation, e.g., how to represent such vector lifetimes? How close and how far can two vector lifetimes \nbe put together without con.ict? How to identify legal and illegal registers for a vector lifetime? And \nwhat strategy should we use to minimize the number of allocated registers? In this paper, we develop \na way to normalize and represent vec\u00adtor lifetimes, which capture their complexity in multi-dimensional \nloop software pipelining, while exposing their regularity that en\u00adables us to develop a simple, yet powerful \nsolution. The problem is formulated as bin-packing of the multi-dimensional vector life\u00adtimes on the \nsurface of a cylinder, with time as axis and registers as the circle, such that there is no con.ict between \nlifetimes and the circumference of the circle is minimized. Our algorithm is based on the development \nof a metric, called distance, that determines quantitatively the degree of potential overlapping (con.ict) \nbetween two vector lifetimes. We show how to calculate and use the distance, conservatively and aggressively, \nto guide the bin-packing of the lifetimes. The classical register allocation for software pipelined single \nloops [12, 5] is subsumed by our method as a special case. This approach has been implemented in the \nORC compiler for Itanium architecture. Experiments indicate impressive effective\u00adness of our approach \nin minimizing the number of allocated reg\u00adisters. Several allocation strategies are compared and analyzed. \n 2. Register Allocation For Software Pipelined Single Loops 2.1 Software Pipelining Software pipelining \n[1] exposes instruction-level parallelism by overlapping successive iterations of a loop. Modulo scheduling \n[9, 7, 8] is an important and probably the most commonly used ap\u00adproach of software pipelining. TN1 \nIn modulo scheduling, instances of an operation from succes\u00adsive iterations are scheduled with an Initiation \nInterval (II) of T cycles. The schedule length l is de.ned as the execution time of a single iteration. \nThen each iteration is composed of S = I l l T TN2 number of stages, with each stage taking T cycles. \nThe schedule consists of three phases: the prolog to .ll the pipeline, the kernel to be executed multiple \ntimes, and the epilog to drain the pipeline. leading blade (omega=1) scalar lifetime of the first iteration \n(iteration 0) start=1 end=3 0000000000000000 000000000000000 000000000000000 000000000000000 000000000000000 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 trailing blade (alpha=1) \nst 0000000000000000 000000000000000 000000000000000 000000000000000 000000000000000 1111111111111111 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 end=6art=0 1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 Registers Registers \n for (i=0; i; i++) { . ... a: TN2=TN1{1}... b: TN1= ... : ...=TN2 } 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T Time \nRepeating the kernel (a) Space-Time Diagram for the Example in Fig. 1(a) (with N1 =7) 2 1 0 4 3 00000000000000 \n00000000000000 00000000000000 00000000000000 00000000000000 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 1111111111111111 000000000000000 000000000000000 000000000000000 000000000000000 0000000000000000 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 000000000000000 \n000000000000000 000000000000000 000000000000000 00000000000000000 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 11111111111111111 000000000000000 000000000000000 000000000000000 000000000000000 0000000000000000 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 000000000000000 \n000000000000000 000000000000000 000000000000000 000000000000000 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 1111111111111111 000000000000000 000000000000000 000000000000000 000000000000000 000000000000000 \n1111111111111111 1111111111111111 1111111111111111 1111111111111111 1111111111111111 000000000000000 \n000000000000000 000000000000000 000000000000000 0000000000000000 1111111111111111 1111111111111111 1111111111111111 \n1111111111111111 1111111111111111 TN2 TN1 (a) Source (b) Modulo Schedule Figure 1. A Software-Pipelined \nLoop Example: Fig. 1(a) shows an example intermediate representation of a single loop, where a Temporary \nName (TN) represents a variant. If a TN value is used i iterations after where it is produced, ithas \na live-in distance equal to i. The TN value is annotated with the live-in distance. For example, TN{1} \nrefers to the TN value de.ned in the previous loop iteration, with the live-in distance being 1. Suppose \nthere are two function units, and operations a, b and c have a latency of 5, 1, and 1 cycles, respectively. \nThen a possible modulo schedule is shown in Fig. 1(b) with T =2, l =6 and S =3. The kernel is highlighted \nin darker color.  2.2 Register Allocation We brie.y review the classical register allocation for software\u00adpipelined \nsingle loops [12, 5], with target architecture support in the form of a rotating register .le [12, 8]. \nA scalar lifetime is the lifetime of a loop variant for a given iteration of the loop. The variant has \none operation to produce a value and one or more operations to consume the value. The scalar lifetime \nstarts when the producer is issued and ends when all of the consumers have .nished. All the scalar lifetimes \nof the loop variant over all the iterations of the loop compose the vector lifetime of the loop variant. \nThe vector lifetime can be represented on a space\u00adtime diagram, where time is on the horizontal axis \nand the registers on the vertical axis. For example, the space-time diagram for TN1 and TN2 in Fig. 1 \nis shown in Fig. 2(a). A vector lifetime is composed of a wand (the diagonal band), a leading blade in \ncase of live-in values, and a trailing blade in case of live-out values. In Fig. 2(a), TN2 is made of \na wand only. TN1 has a leading blade for it has a live-in value, and a trailing blade (Assume it has \na live-out value). Correspondingly, a vector lifetime is represented by a 4-tuple (start, end, omega, \nalpha). The start and end values refer to the start and end cycles of the scalar lifetime corresponding \nto the .rst iteration of the loop, i.e., iteration 0. Then, the scalar lifetime corresponding to iteration \ni starts at start +i * T and ends at end +i * T . Omega is the number of live-in values for the loop \nvariant. It is also the maximum live-in distance of the loop variant. Alpha represents the number of \nlive-out values for the loop variant. For example, the vector lifetimes of TN1 and TN2 are represented \nas (1, 3, 1, 1) and (0, 6, 0, 0), respectively. A physical register x is said to be allocated to a vector \nlifetime v if it is allocated to the scalar lifetime of v corresponding to the .rst iteration. The next \nphysical register x - 1is then allocated to the scalar lifetime corresponding to the second iteration, \nand so on. Due to the cyclic nature of the rotating register .le, the register index wraps around to \nthe highest index when it becomes -1. 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T (b) An Optimal Bin-Packing \n(Circumference=5) Figure 2. Register Allocation For the same reason, a space-time diagram can be seen \nas a cylinder with time as the axis and registers as the circle. The circumference of the circle is the \ntotal number of registers required to allocate to the loop. The register allocation problem consists \nof packing the vector lifetimes on the surface of the cylinder, such that there is no con.ict and the \ncircumference is minimized. Con.ict refers to the fact that two scalar lifetimes that overlap in time \nare allocated to the same register. An optimal register allocation for the space-time diagram in Fig. \n2(a) is displayed in Fig. 2(b), where TN1 is allocated physical register 0, and TN2 register 2, with \na circumference of 5 after the diagram is wrapped into a cylinder. To achieve such register allocation, \nthe algorithm sorts the vec\u00adtor lifetimes and inserts them one by one on the surface of the space-time \ncylinder without backtracking. Three sorting heuristics can be used: start time ordering, where the earliest \nvector lifetime is inserted .rst; adjacency ordering, where the vector lifetime to be inserted minimizes \nthe horizontal distance with the previously inserted lifetime; and con.ict ordering, which is to vector \nlife\u00adtimes what graph coloring [4] is to scalar lifetimes. The insertion of the chosen lifetime is then \ndecided by one of three strategies: best, .rst, and end .ts. Best .t .nds a register that minimizes the \ncurrent register usage. First .t chooses the .rst compatible regis\u00adter starting from register 0, while \nend .t starting from the register allocated to the vector lifetime inserted at the last step. Note that \nthe register allocation problem can be formulated as a Traveling Salesman Problem (TSP) as well, which \nis known to be NP-Complete [12].  3. Register Allocation For Software Pipelined Loop Nests This section \nbrie.y reviews SSP, characterizes the vector lifetimes in an SSP schedule, formulates the corresponding \nregister alloca\u00adtion problem, and .nally proposes key observations to solve it. 3.1 Single-dimension \nSoftware Pipelining Single-dimension Software Pipelining (SSP) [14, 13] is a resource\u00adconstrained scheduling \nmethod to software pipeline a loop nest. In 1st group 2nd group 3rd group (iterations 0, 1, 2) (iterations \n3, 4, 5) (iterations 6, 7, 8) 54 L: for (i=0; i; i++) { . .... a: TN1 = TN1{1}... stage i1 32 0= 0 1 \n2 3 4 5 6 7 8 910 b: TN2 = ... index 1 A  L: for (i=0;i;i++) { . .... T =2 : TN3 = TN2... d: ... = \nTN3 e: TN2 = ... S =3 B n }//end L .}//end L. S1=6 (a) Loop Nest (b) 1-D Schedule (Kernel)  C T =2 cycles \n a0 b0 a1 b1  L2 : for (i2 =1; i2 < N2; i2++) { Prolog (2 partial kernels) L1 : for (i1 =0; i1 < N1; \ni1+=3 ) { D  E with stages permuted to ILES make the inner (the entire L2 ) loop run i2 -1i1+2,c i2 \n-1i1 e , i2 -1i1+2,d i2i1 c , i2di1, i2 -1i1+1,e i1+1,i2c i1+1, i2d i2 -1i1+2,e iterations after this \ncycle 3 partial kernels F sequentially in each iteration } //end L2 } //end L1   Epilog (3 partial \nkernels) G H (c) Final Schedule in the form of a Parallel Loop Nest Figure 3. A Loop Nest Scheduled \nby SSP Figure 4. Final Schedule (with N1 =9, N2 =3) contrast to traditional innermost-loop-centric approaches \n[9, 11], SSP chooses the most pro.table loop level from the entire loop nest. Here pro.tability can be \nmeasured in terms of instruction\u00adlevel parallelism, data reuse, or any other optimization criteria. SSP \nretains the simplicity of the classical modulo scheduling technique for single loops, yet under the same \ncondition, achieves the shortest computation time that could be achieved by traditional innermost\u00adcentric \napproaches [14]. The classical modulo-scheduling is sub\u00adsumed by SSP as a special case. SSP consists \nof three steps: (1) Loop selection. A loop in the loop nest is chosen to be software pipelined. Only \nthis loop will be parallelized. Its outer loops, if any, remain intact. Note that this selected loop \nmay have its own inner loops and thus be a loop nest itself. (2) Dependence simpli.cation and 1-D schedule \nconstruc\u00adtion. The n-dimensional (n = 1) data dependence graph (DDG) of the selected loop is simpli.ed \ninto a 1-dimensional DDG, and based on that, a 1-dimensional schedule is computed, represented by a kernel. \nNo matter how many inner loops the selected loop has, it is scheduled as if it were a single loop. Any \ntraditional modulo scheduling technique may be applied to compute this 1-D sched\u00adule. (3) Final schedule \ncomputation. The 1-D schedule is mapped back to the n-dimensional iteration space to form the .nal sched\u00adule, \nsemantically equivalent to the selected loop. This approach is referred to as Single-dimension Software \nPipelining because the problem of multi-dimensional scheduling is simpli.ed to 1-dimensional scheduling \nand mapping. Intuitively, in the .nal schedule, the iterations of the selected loop are issued in parallel, \nwhereas the inner loops within each of the iterations run sequentially. Let Sn be the total number of \nstages corresponding to the innermost loop in the kernel, and T be the initiation interval of the kernel. \nEvery T cycles, an iteration of the selected loop is issued, until the processor resources become insuf.cient \nto support any new iteration. Then a single group of Sn iterations, already issued, execute their inner \nloops in parallel. Until this group is going to .nish and frees the resources, all the  The kernel is \nthen used as a template to build the .nal schedule. The general form of the .nal schedule is shown in \nFig. 5(c). Unless stated otherwise, the term iteration always refers to Stage index fn+1 fn fx+1 fx an \niteration of the outermost loop L1.A loop variant refers to a 21...... temporary name that has a de.nition \nin loop L1, including its inner L: for (i=0; i; i++) { ..... T L. : . for (i. =0; i. T . ; i.++) { \n. Ln: for (in=0; in n; in++) { Tn }//end Ln  }end L}//end L. . (a) Generic Source Loop Nest  3.2 \nAssumptions and Conventions Throughout the paper, we will assume that a loop nest is composed of nloops: \nL1, L2, ..., Ln, as shown in Fig. 5(a), where OPSETx represents a set of non-branch operations between \nthe beginnings of two adjacent loops. The loop nest is a single loop if n =1. Without loss of generality, \nwe assume that SSP selects the outermost loop L1 for scheduling, and constructs a 1-D schedule, which \nis represented by a kernel. The stages in the kernel are numbered from right to left as 0,1,\u00b7\u00b7\u00b7, as shown \nin Fig. 5(b). Each stage takes T cycles to execute. If an operation is scheduled at cycle cof stage s, \nwhere cycle cis relative to the beginning of the stage and 0= c<T, its 1-D schedule time is equal to \ns*T +c. The operations from the same loop Lx, including its inner loops, are scheduled into contiguous \nstages. The .rst such stage is referred to as fx, and the last one lx. The total number of stages for \nloop Lx is termed Sx, which equals lx -fx +1. (c) The General Form of a Final Schedule Figure 5. Generic \nLoop Nest Scheduled by SSP other iterations stall. In this paper, such a stall period is referred to \nas an inner loop execution segment (ILES). Example: Fig. 3(a) shows the intermediate representation of \na dou\u00adble loop nest. Assume that L1 is selected by SSP, 3 function units are available, and operations \na,b,c,d,ehave latencies of 2, 5, 1, 4, and 1 cycles, respectively. Fig. 3(b) shows a possible 1-D schedule \n(the kernel) constructed. From this kernel, a .nal schedule is com\u00adputed and the loop nest can be rewritten \naccordingly, as shown in Fig. 3(c), where oi1,i2 refers to the instance of operation owith i1 the outer \nloop index and i2 the inner loop index. An L1 iteration is issued every T =2cycles, and executes sequentially. \nThe issu\u00ading continues until the 10th cycle. Otherwise, there would be re\u00adsource con.icts with the already \nrunning L1 iterations. Then, only the .rst group of Sn =3L1 iterations continue executing their inner \nloops. Once done, the group starts draining the pipeline and freeing processor resources. Then other \nL1 iterations continue to issue and execute. To facilitate understanding, the .nal schedule in Fig. 3(c) \nis illustrated cycle by cycle in Fig. 4, where ineffec\u00adtive operation instances whose i1 indexes are \nbeyond the L1 itera\u00adtion range, [0,N1 -1], are masked from execution using predica\u00adtion [13], as shown \nin gray color in Fig. 4. Due to the regular stalls and issuing, repeating patterns naturally appear in \nthe .nal schedule. The .nal schedule is composed of a prolog, the repetition of an outermost loop pattern \n(OLP) and an ILES, and an epilog. Each of them consists of multiple copies of the kernel, as illustrated \nin Fig. 3(c). loops. To be simple, we assume that at each loop level, the variant is either not de.ned \nor de.ned only once. 3.3 Features of the Vector Lifetimes Fig. 6 shows the space-time diagram for each \nof the loop variants in our example, corresponding to the .nal schedule in Fig. 4, with segments A through \nH marked accordingly. They include all the typical features of a vector lifetime in any SSP .nal schedule. \nSimilarly to the single loop case, a vector lifetime may have a leading blade when there are live-in \nvalues, and a trailing blade when there are live-out values. For example, in Fig. 6, TN1 has a leading \nblade, and TN2 a trailing blade (Assume it has two live\u00adout values). The wand, however, has unusual features \nspeci.c to a multi-dimensional loop, due to the following two reasons: First, an iteration has inner \nloops within it. This leads to the following features: 1. Multiple intervals in a scalar lifetime. A \nvariant can be de.ned and killed multiple times during the execution of an inner loop. See TN2 and TN3 \nin Fig. 6 for example. 2. Unknown length of an interval at compile time. A variant has an interval live \nthrough an inner loop if the variant is live, but never rede.ned, during the execution of this loop. \nThe length of the interval depends on the number of iterations of this loop and those of its inner loops, \nwhich may be unknown at compile-time. Second, an iteration may be stalled and resumed. This leads to \ntwo other interesting features: 3. Stretched intervals. An interval may be stretched longer than usual \nin the period of an ILES. For example, Fig. 4 illustrates the .rst interval, produced by operation band \nconsumed by opera\u00adtion c, in each scalar lifetime of TN2 corresponding to iterations 0 to 5. All the \nintervals have the same length except the two intervals from iterations 3 and 4, which start before but \nend after the .rst ILES, segment C. 4. Delayed initiation of intervals. For example, in Fig. 4, the \nintervals from successive iterations initiate every T =2cycles, except that the interval from iteration \n5 is delayed until after the .rst ILES. The above 4 features present novel challenges to the register \nal\u00adlocation. Fortunately, there is also one useful and important feature: 5. Repetition of the OLP and \nILES segments, as indicated by the general form of a .nal schedule in Fig. 5(c). When an OLP (ILES) repeats, \nany interval in it repeats as well. This implies that the part of the vector lifetime within an OLP (or \nILES) must be identical to that in any other OLP (or ILES). The only exception is that the .rst and last \nOLPs, and the last ILES may contain a subset of intervals of other OLPs and ILESes due to the ineffective \noperations at the beginning and the end of the .nal schedule (See Fig. 4).   3.4 Problem Formulation \nThe problem to be addressed in this paper can be formulated as fol\u00adlows: Given a loop nest composed of \nn loops L1,L2,...,Ln, sup- TN1 AB C (1st ILES) DE (2nd ILES) FG (3rd ILES) H 0*T 1*T 2*T 3*T 4*T 5*T \n6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T 15*T 16*T 17*T 18*T 19*T 20*T 21*T 22*T 23*T 24*T 25*T 26*T \n27*T 28*T 29*T 30*T 31*T 32*T TN2 AB C (1st ILES) DE (2nd ILES) FG (3rd ILES) H 1st group 2nd group 3rd \ngroup 111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 00000 00000 00000 \n00000 00000 11111 11111 11111 11111 11111 0000 0000 0000 0000 0000 11111 11111 11111 11111 11111 111 \n111 111 111 111 111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 00000 \n00000 00000 00000 00000 11111 11111 11111 11111 11111 00000 00000 00000 00000 00000 11111 11111 11111 \n11111 11111 111 111 111 111 111 111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 \n0000 0000 0000 0000 0000 11111 11111 11111 11111 11111 00000 00000 00000 00000 00000 11111 11111 11111 \n11111 11111 111 111 111 111 111 0000 0000 0000 0000 0000 11111 11111 11111 11111 11111 0000 0000 0000 \n00000 00000 11111 11111 11111 11111 11111 111 111 111 111 111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 000 000 000 000 000 11111 11111 11111 11111 11111 0000 \n0000 0000 0000 0000 11111 11111 11111 11111 11111 111 111 111 111 111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 \n111111111111111 0000 0000 0000 0000 0000 11111 11111 11111 11111 11111 0000 0000 0000 0000 0000 11111 \n11111 11111 11111 11111 111 111 111 111 111 00000 00000 00000 00000 00000 11111 11111 11111 11111 11111 \n00000 00000 00000 00000 00000 11111 11111 11111 11111 11111 111 111 111 111 111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 00000 00000 00000 00000 00000 11111 11111 11111 11111 11111 \n00000 00000 00000 00000 00000 11111 11111 11111 11111 11111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 111111111111111111111111111111111111111111111 \n111111111111111111111111111111111111111111111 0000000 0000000 0000000 0000000 0000000 11111111 11111111 \n11111111 11111111 11111111 111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 \n00000 00000 00000 00000 00000 11111 11111 11111 11111 11111 00000 00000 00000 00000 00000 11111 11111 \n11111 11111 11111 111 111 111 111 111 first and the last stretched intervals in iterations 3 and 4. firstStretch=3, \nlastStretch=4,bottom=5 scalar lifetime of the first iteration. Mutiple intervals. outermostIntervalOnly=FALSE, \ntop=0 trailing blade 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T 15*T 16*T 17*T \n18*T 19*T 20*T 21*T 22*T 23*T 24*T 25*T 26*T 27*T 28*T 29*T 30*T 31*T 32*T TN3 AB C (1st ILES) DE (2nd \nILES) FG (3rd ILES) H 1st group 2nd group 3rd group  0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 sc \nala r l ife ti me of th e first i te rat io n. 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 ou ter m \nos tIn ter va lO nl y= F AL SE, t op = 0 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 0011 0 00 11 11 \n011 0 00 11 11 000111 0 00 11 11 0011 0 0 11 11 11 0 0 11 11 0011 0 0 11 11 11 0 0 11 11 0011 0 0 11 \n11 0011 0 0 11 11 t he sc al ar lif eti me a t t he bo tto m of th e IL ES . Fro m it era tion . 2 0011 \n0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 fir stS tr etc h= + , l ast St ret ch = - , b ot to m= 3 0011 \n0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 0*T 1*T 2*T 3*T \n4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T 15*T 16*T 17*T 18*T 19*T 20*T 21*T 22*T 23*T 24*T 25*T \n26*T 27*T 28*T 29*T 30*T 31*T 32*T Figure 6. The Final Form of the Vector Lifetimes pose the outermost \nloop L1 is software-pipelined by SSP. Allocate minimum number of registers to the loop variants, in the \npresence of the rotating register .le. Considering the cyclic structure of a rotating register .le, the \ntask is to pack the vector lifetimes on the surface of a cylinder, where time is the axis and the number \nof reg\u00adisters is the circumference, such that there is no con.ict between any two scalar lifetimes and \nthe circumference is minimized.  3.5 Key Concepts and Intuition The key to the entire register allocation \nproblem is to ef.ciently abstract the vector lifetimes, such that their complexity is captured, and their \nregularity is exposed to enable us to develop a simple so\u00adlution. Based on the abstract representation \nof the vector lifetimes, the next key is to accurately measure how close and how far two vector lifetimes \ncan be packed together on the space-time diagram. We propose a dynamic view of a vector lifetime, which \ngreatly simpli.es both lifetime representation and the measurement of the distance between two vector \nlifetimes. We further propose a conservative and an aggressive ways for the measurement. 3.5.1 The Dynamic \nView of a Vector Lifetime: the Simplest, Ideal, and Final Forms A vector lifetime can be viewed in a \ndynamic way, from its simplest form, to its ideal form, and eventually to its .nal form. The simplest \nform of a vector lifetime corresponds to the spe\u00adcial case that the number of iterations of any inner \nloop equals 1. The loop nest is then equivalent to a single loop. Therefore it is easy to represent and \nhandle the vector lifetimes using the classical register allocation for software pipelined single loops \npresented in Section 2.2. For our example, the simplest form of the three vector lifetimes are shown \nin Fig. 7(a). The simplest form is composed of prolog, OLPs, and epilog, but without ILESes. The ideal \nform of a vector lifetime corresponds to the ideal case that all the scalar lifetimes are evenly issued \nevery T cycles. Each iteration runs without stopping as if there were no resource constraint. In this \nsituation, there is no stall in the .nal schedule. Therefore there are no stretched intervals. The ideal \nform can be reached by adding to the simplest form the intervals produced PLDI 05 5 during the execution \nof the inner loops. The ideal form of the vector lifetimes for our example is shown in Fig. 7(b). The \n.nal form corresponds to the .nal schedule, which does have stalls to account for resource constraints. \nThe .nal form of the vector lifetimes for our example is represented in Fig. 6. Every part of each vector \nlifetime is represented, without any omission. With this dynamic view, it is much easier to mathematically \nabstract any vector lifetime. First, the simplest form is used to abstract the start and end of the scalar \nlifetimes. Then the ideal form is used to add the intervals de.ned at the inner loop levels. Finally, \nthe .nal form is used for abstraction of the stretched intervals. Repetition exists in all the three \nforms. (1) In the simplest and ideal forms, all scalar lifetimes are identical, except for the leading \nand trailing blades. (2) For a scalar lifetime in the ideal form, the interval de.ned at an inner loop \nlevel repeats itself with the sequential execution of this inner loop. (3) In the .nal form, the ILESes \nrepeat themselves as well, as discussed in Section 3.3. Due to the repetition, in representing and handling \na vector lifetime, we can simply focus on the scalar lifetime corresponding to the .rst iteration, the \n.rst instance of the interval de.ned at each inner loop level, and the .rst ILES, and take them as a \npoint of reference. 3.5.2 The Distances between Two Vector Lifetimes There are two ways to pack two \nvector lifetimes on the space-time diagram: with and without interleaving. Fig. 8(a) shows a register \nallocation for our example without interleaving. The diagram has already been wrapped around into a cylinder. \nThe circumference is 9. Fig. 8(b) shows another register allocation where vector life\u00adtimes are interleaved \nwhen possible. In this case, the second scalar lifetime of TN3 is interleaved with the .rst scalar lifetime \nof TN2, and so on. The interleaving results in a smaller circumference of 7. One may observe that this \nis an optimal solution: the circumference cannot be further reduced. Correspondingly, we propose conservative \ndistance and ag\u00adgressive distance, which measure how close and how far, in num\u00adber of registers, two \nvector lifetimes can be on the space-time dia\u00adgram without con.ict. The conservative distance does not \nallow for interleaving, whereas the aggressive distance does. The two dis\u00ad 2005/4/19 start [1]=0, end \n[1]=3, nextStart[1]= + , start[2]=+ , end[2]=- ,nextStart[2]=+ TN1 TN1 111 111 111 111 111 001100011000110001101111111 \n001100000011111111 00 111 00 00 00 111 111 111 111 001100011000110001101111111 001100000011111111 00 \n111 00 00 00 111 111 111 111 10101010101010101111111 001100000011111111 00 111 00 00 00 111 111 111 111 \n001100011000110001101111111 001100000011111111 00 111 00 00 00 111 111 111 111 001100011000110001101111111 \n001100000011111111 00 111 00 00 00 111 111 111 111 10101010101010101111111 001100000011111111 00 111 \n00 00 00 111 111 111 111 10101010101010101111111 001100000011111111 00 111 00 00 00 111 111 111 111 001100011000110001101111111 \n001100000011111111 00 111 00 00 00 111 111 111 111 111 111 111 111 111 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T \n8*T 9*T 10*T 11*T 12*T 13*T 14*T 15*T 16*T 17*T 18*T 19*T 20*T 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T \n10*T 11*T 12*T 13*T 14*T start [1]=1, end [1]=7, nextStart [1]=start [2]=11, end [2]=13, nextStart [2]=17 \nTN2 TN2 A B D F H 111111111111111 1111111111 111111111111111 1111111111 111111111111111 111 111 111 \n111 111 111 111 111 111 111 o l din bl ade om e =0 111111111111111 1111111111 111111111111111 1111111111 \n111111111111111 111 111 111 111 111 111 111 111 111 111 n ea g ( ga ) 111111111111111 1111111111 111111111111111 \n1111111111 111111111111111 111 111 111 111 111 111 111 111 111 111 tr ai ling bla de 111111111111111 \n1111111111 111111111111111 1111111111 111111111111111 111 111 111 111 111 111 111 111 111 111 (a lp ha \n=2 ) s ing le St art =1 111111111111111 1111111111 111111111111111 1111111111 111111111111111 111 111 \n111 111 111 111 111 111 111 111 111 11 111 11 111 111 111 111 11 111 11 111 111 111 111 11 111 11 111 \n111 111 111 11 1111111111111111111 11 111 111 111 111 111 11 111 11 111 111 111 111 11 111 11 111 111 \n111 111 11 111 11 111 111 111 111 11 1111111111111111111 1111111 111 111 11111 111 111 111 si ng le En \nd= 12 111111111111111 11111111 111111111111 11111111 111111111111 111 111 111 111 0000000000001111111111111111 \n000000001111111111 00 00 00 00 111 111 111 111 111 111 11 111 11 111 111 111 111 11 111 11 111 111 111 \n111 11 111 11 111 111 111 111 11 1111111111111111111 11 111 111 111 111  111111111111111 111111111111111 \n111111111111111 111111111111111 111111111111111 0000 0000 0000 0000 11111 11111 11111 11111 11111 11111 \n11111 11111 11111 11111 111 111 111 111 111 111111111111111 111111111111111 111111111111111 111111111111111 \n111111111111111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 111 111 111 111 111 111111111111111 \n111111111111111 111111111111111 111111111111111 111111111111111 11111 11111 11111 11111 11111 11111 11111 \n11111 11111 11111 111 111 111 111 111 111111111111111 111111111111111 111111111111111 111111111111111 \n111111111111111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 111 111 111 111 111 111111111111111 \n111111111111111 111111111111111 111111111111111 111111111111111 0000 0000 0000 0000 11111 11111 11111 \n11111 11111 0000 0000 0000 0000 11111 11111 11111 11111 11111 111111111111111 111111111111111 111111111111111 \n111111111111111 111111111111111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 111 111 111 \n111 111 11111 11111 11111 11111 11111 11111 11111 11111 11111 11111 111 111 111 111 111 11111 11111 11111 \n11111 11111 11111 11111 11111 11111 11111 111 111 111 111 111 111111111111111 111111111111111 111111111111111 \n111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 \n111111111111111 111111111111111 111111111111111 111111111111111 111111111111111 11111 11111 11111 11111 \n11111 11111 11111 11111 11111 11111 111 111 111 111 111 11111111 11111111 11111111 11111111 11111111 \n 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T 15*T 16*T 17*T 18*T 19*T 20*T 0*T 1*T \n2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T start[1]=+ , end[1]=- ,nextStart [1]=start \n[2]=6, end [2]=8,nextStart [2]=12 TN3 TN3 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T \n14*T 15*T 16*T 17*T 18*T 19*T 20*T 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T \n(a) The Simplest Form: Prolog+OLPs+Epilog. No ILES (b) The Ideal Form: No Stall or Resource Constraints \n  Figure 7. The Simplest and Ideal Forms of the Vector Lifetimes 2 1 0 8 7 6 5 4 3 11 TN 3 00111 0 \n0 11 11 11 00111 0 0 11 11 11 00111 0 0 11 11 11 000000000000000111111111111111 00000000001111111111 \n00 00 00 00 00 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 \n1111111111111111111111 111 1111111111 111111111111111 1111111111 111111111111111111111111111111111111 \n111111 11111111111111111111111111111 11 111111111111111111111111111111111111 111111 111111111111111 111111 \n111111 111111 111 11111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 111 111 111 111 111 000111 0 00 11 11 0011 0 00 11 11 0011 0 00 11 \n11 000000000000000111111111111111 00000000001111111111 00 00 00 00 00 111 111 111 111 111 111111111111111 \n1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 11111111 111111 111111111111111111111 \n11 11111111 111111 11111111 1111111111111 11 111 11111111 111111111111 111 111 111 111 111 000000000000000111111111111111 \n00 00 00 00 00 11 11 11 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 \n00000000001111111111 00 00 00 00 00 111 111 111 111 111 11 TN 2 00111 0 0 11 11 11 00111 0 0 11 11 11 \n00111 0 0 11 11 11 111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 \n111 11111111 111111111111 11111111 111111111111 11111111 111111111111 11111111 111 111 111 111 111111111111111 \n1111111111 111111111111111 1111111111 111111111111111 111 111 111 111 111 000000000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 \n111 111 111 111 111 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 \n111 111 111 111 111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 111 111 111 111 111 0011 0 0 11 11 0011 0 0 11 11 11 0 0 11 11 111 \n111 111 111 111 000000000000000111111111111111 00000000001111111111 00 00 00 00 00 111 111 111 111 111 \n111111111111111 1111111111 111111111111111 1111111111 111111111111111 111 111 111 111 111 000000000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 \n111 111 111 111 111 00111 0 0 11 11 11 111 0 0 11 11 11 00111 0 0 11 11 11 000000000000000111111111111111 \n00000000001111111111 00 00 00 00 00 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 \n111111111111111 111 111 111 111 111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 \n111111 111111 000000000000000111111111111111111 00 00 00 00 00 111 111 111 111 111 11111 111 111 111 \n111 111 111 111 111 0011 0 0 11 11 0011 0 0 11 11 11 0 0 11 11 11 TN 1 000000000000000111111111111111 \n00000000001111111111 00 00 00 00 00 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 \n111111111111111 1111111111111111111111 111 1111111111 111111111111111 1111111111 1111111111111111111111111111111 \n111111 1111111111111111111111111111111 111111 111111111111111111111111111111111111 1111 111111111111 \n111111 111 11111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 0000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 111 111 111 111 111 00111 0 0 11 11 11 111 0 0 11 11 11 00111 0 0 \n11 11 11 000000000000000111111111111111 00000000001111111111 00 00 00 00 00 111 111 111 111 111 111111111111111 \n1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 1111111111111 1111 1111111111111 \n1111 1111111111111 1111 11111111 11111 11111111 111111111111 11111111 111111111111 111 111 111 111 111 \n000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 00 00 \n00 00 00 111 111 111 111 111 111 111 111 111 111 11 0 0 11 11 0011 0 0 11 11 11 0 0 11 11 111111111111111 \n1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 111 111111 111111111 111111 \n111111111 111111 111111111 111111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 \n111 111 111 111 111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 0000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 111 111 111 111 111 00111 0 0 11 11 11 111 0 0 11 11 11 00111 0 0 \n11 11 11 Registers Registers 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T 15*T \n16*T 17*T 18*T 19*T 20*T 21*T 22*T 23*T 24*T 25*T 26*T 27*T 28*T 29*T 30*T 31*T 32*T (a) Register Allocation \nUsing the Conservative Distance. Circumference=9 2 1 0 6 5 4 3 0011 0 0 11 11 T N3 0011 0 0 11 11 0011 \n0 0 11 11 000000000000000111111111111111 00000000001111111111 00 00 00 00 00 111 111 111 111 111 111111111111111 \n1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 111 1111111111 111111111111111 \n111111111111111111111111 111111 111111111111111111111111 111111 111111111111111111111111 111111 111111111111111111111111 \n111111 111 11111111 111 111 111 11 0 0 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 \n111 111 0011 0 0 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 11 0 0 11 11 \n111 111 111 111 111 111 111 111 111 111 1 111111111111111 1111111111 111111111111111 1111111111TN 1111111111111112 \n111 111 111 111 111 00111 0 0 11 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 \n111 00111 0 0 11 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 00111 0 0 11 \n11 11 111 111 111 111 111 000000000000000111111111111111 00000000001111111111 00 00 00 00 00 111 111 \n111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 \n11111 11111111 111111111111 11111111 111111111111 11111111 111111111111 11111111 111111111111 11111111 \n111111111111 111 111 111 111 111 00111 0 0 11 11 11 000000000000000111111111111111 00 00 00 00 00 11 \n11 11 11 11 111 0 0 11 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 00111 \n0 0 11 11 11 000000000000000111111111111111 00000000001111111111 00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 \n00000000001111111111 00 00 00 00 00 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 \n111111111111111 111 111 111 111 111 0011 0 0 11 11 000000000000000111111111111111 00 00 00 00 00 111 \n111 111 111 111 0011 0 0 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 0011 \n0 0 11 11 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 \n111 11111111 111 11 111 11 111 11 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 \n111 111 111 111 111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 111 111 111 111 111 000000000000000111111111111111 00000000001111111111 \n00 00 00 00 00 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 \n111 111 111 111 111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 000000000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 00111 0 0 11 11 11 111 111 111 111 111 00111 0 0 11 11 11 111 0 0 \n11 11 11 111 111 111 111 111 TN 1 000000000000000111111111111111 00000000001111111111 00 00 00 00 00 \n111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 \n111 1111111111 111111111111111 1111111111 1111111111111111111111111111 1111111111 1111111111111111111111111111 \n1111111111 1111111111111111111111111111 1111111111 111111111111111 111 111 111 111 111 0011 0 0 11 11 \n000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 11 0 0 11 11 0000000000111111111111111 \n00 00 00 00 00 111 111 111 111 111 0011 0 0 11 11 111 111 111 111 111 11111111111111111111 111111111111111111 \n111111111111111111 111111111111111111 000000000000000111111111111111 00000000001111111111 00 00 00 00 \n00 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111111111111111 \n11111111 111111 1111111111111111 1111 11111111 111111 11111111 11111111 11111111 111111111111 1111111111 \n111111111111111 111 111 111 111 111 00111 0 0 11 11 11 000000000000000111111111111111 00 00 00 00 00 \n111 111 111 111 111 00111 0 0 11 11 11 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 \n111 111 0 0 11 11 11 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 \n1111111111111111111111 111 11111111 111111111111 11111111 111111111111 11111111 111111111111 11111111 \n111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 111 111 111 111 \n111 000000000000000111111111111111 00 00 00 00 00 111 111 111 111 111 0000000000111111111111111 00 00 \n00 00 00 111 111 111 111 111 0011 0 0 11 11 111 111 111 111 111 11 0 0 11 11 0011 0 0 11 11 0*T 1*T \n2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T 15*T 16*T 17*T 18*T 19*T 20*T 21*T 22*T 23*T \n24*T 25*T 26*T 27*T 28*T 29*T 30*T 31*T 32*T (b) Register Allocation Using the Aggressive Distance. Circumference=7 \nFigure 8. Register Allocation Examples tances play a key role in effectively minimizing register usage. \nThe aggressive distance enforces .ner control upon the selection of a register for a vector lifetime, \nas to be con.rmed by our experiments. The three forms of the vector lifetimes will be used appropriately \nto compute the distances.   4. Solution Our approach consists of the following steps: (1) Lifetime \nnor\u00admalization. First, the vector lifetimes are normalized such that any interval has a length known \nat compile time. (2) Lifetime repre\u00adsentation. The normalized vector lifetimes are then abstracted by \na set of parameters. (3) Distance Calculation. Using those param\u00adeters, a conservative and an aggressive \ndistances between any two vector lifetimes, including the distances between a vector lifetime and itself, \nare computed. Then either the conservative or the ag\u00adgressive distance can be used in the following steps: \n(4) Sorting. The distance is used to order the vector lifetimes. (5)Bin-packing. The ordered vector lifetimes \nare inserted one by one onto the sur\u00adface of the space-time cylinder with one of the strategies (best, \n.rst, and end .ts), assuming maximum circumference, with the distance between any pair of vector lifetimes \nrespected. (6) Circumference minimization. The last step minimizes the circumference of the If the loop \nvariant is live through the innermost loop Ln,a dummy use and a dummy de.nition with time = fn* T are \nadded into the references set. This is equivalent to inserting a copy oper\u00adation TN=TN at the .rst cycle \nof the innermost loop stages in the 1-D schedule, although we never really do such insertion. Inserting \nthe copy instruction at any other cycle of the innermost loop stages is also feasible. Here we choose \nthe .rst cycle arbitrarily. cylinder. The main algorithm is shown in Fig 9. So far, we use a sorting \nprocess similar to that in the traditional register allocation for single loops [12, 5], as to be shown \nin Sec-stage 54 3 21 0= tion 6. However, any other sorting heuristic may also be feasible. L1 :for(i1 \n=0;i1 <N1;i1 ++) { The other steps will be presented in detail below. a :TNx=... index T =2 b :...=TNx \nL3 : for(i3 =0;i3 <N3;i3 ++) { L2 : for(i2 =0;i2 <N2;i2 ++) { S =3 n  ALLOCATE REGISTERS(strategy): \n... 1: VLT .- \u00d8 //an empty list for vector lifetimes 2: for each loop variant tn do 3: REF S . Normalize(tn) \n//gather and normalize tn references 4: vlt . Represent(REF S) //abstract lifetime from REFS 5: VLT . \nVLT .{ vlt} //append the lifetime to the list 6: for each vector lifetime A . VLT do 7: for each vector \nlifetime B . VLT do 8: CONS[A, B] . Compute Conservative Distance(A,B) 9: AGGR[A, B] . Compute Aggressive \nDistance(A,B) 10:DIST . CONS or AGGR 11:VLT . Sort Lifetimes(VLT,DIST ) 12:Insert Lifetimes(VLT,DIST,strategy) \n//bin-packing 13:Minimize Circumference(VLT,DIST )     Figure 9. Register Allocation Algorithm 4.1 \nLifetime Normalization An obstacle to lifetime representation is that the length of an inter\u00adval may \nbe unknown at compile time, if it is live through a loop, as discussed in Section 3.3. Without this information, \nit is impossible to characterize the interval accurately. In order to represent the vector lifetimes \nuniformly, we .rst normalize them such that after normalization, any interval has a length known at compile \ntime. To achieve this purpose, any interval that is live through any loop needs to be cut in the middle \nso that it is not live through the loop any more. Due to the nesting structure } //end L3 S2=4 } //end \nL2 } //end L1  S1=6 (a) The 2nd Example (b) The Kernel L1 :for(i1 =0;i1 <N1;i1 ++) { a :TNx=... L2 : \nfor(i2 =0;i2 <N2;i2 ++) { b :...=TNx L3 : for(i3 =0;i3 <N3;i3 ++) { c: TNx=TNx ... is unknown } //end \nL3 1111111111111111111...... L2 The length of the interval } //end 1111111111111111111 } //end L1 \n0*T 1*T 2*T 3*T 4*T 5*T Path 1: both L2 and L3 finish Path 2: L3 finishes and L2 repeats operation a \nstarts here Path 3: L3 repeats (c) The First Scalar Life-(d) Conceptual Illustration of time of TNx \nin the Ideal the Effect of Normalization Form start [1] end[1] of the loops, if the interval is live \nthrough any outer loop, it must be live through the innermost one. Therefore, preventing it from being \nlive through the innermost loop is suf.cient to prevent it from being live through any other loop. Conceptually, \nthis can be done by inserting a dummy copy instruction TN=TN in the innermost loop, where TN is the variant \ncorresponding to the vector lifetime start[3] nextStart[3] end[3] nextStart[1] under discussion. Example: \nFig. 10(a) shows another example loop nest, where TNx is de.ned at L1 level, live in L2 and L3 without \nbeing rede.ned. A 1-D schedule is shown in Fig. 10(b). Then its .rst scalar lifetime of TNx in the ideal \nform would be like that shown in Fig. 10(c). The scalar lifetime has a single interval, which has inde.nite \nlength. The normalization is equivalent to inserting a dummy copy instruction in the innermost loop. \nFig. 10(d) conceptually illustrates this effect. Fig. 10(e) shows the intervals to be observed by lifetime \nrepresen\u00adtation in the following step, due to the normalization. An interval is highlighted within a \ndotted box. The normalization cuts the long interval into repetitive smaller intervals, with the execution \nof the inner loops L3 and L2. We will further study the representation of the intervals later. Fig. 11 \nshows the algorithm of lifetime normalization. All the references of the variant, de.nitions and uses, \nare gathered into a set, REF S.A reference is expressed as a 4-tuple (time, USE/DEF, omega, level), where \ntime is the 1-D schedule time of the oper\u00adation that refers to the variant; USE/DEF indicates whether \nthe ref\u00aderence is a de.nition or use; omega is the live-in distance of the reference in the operation; \nand level is the nesting level of the loop that immediately encloses the operation. EARLIEST LATEST Issue \ntime of the 1st issue time of the 2nd instance of operation c instance of operation c Representation: \nstart[1]=0, end[1]=7, nextStart [1]=6 start [2]=+ nextStart[2] , end[2]=- , nextStart[2]=6 start[3]=6, \nend[3]=15, nextStart[3]=12 (e) Representation after Normalization Figure 10. Normalize a Vector Lifetime \nto Simplify the Represen\u00adtation  4.2 Lifetime Representation A vector lifetime can be fully abstracted \nby characterizing its sim\u00adplest and ideal forms only, with some core parameters. Then the stretched intervals \nin the .nal form can be represented by some derived parameters, deduced from the core parameters. NORMALIZE(tn): \n1: REF S .- \u00d8 //an empty set for tn references 2: for each operation op do 3: time .- 1-D schedule time \nof op 4: level .- the level of the loop immediately enclosing op 5: for each source operand of op equal \nto tn do 6: omega .- live-in distance of the operand 7: ref .- (time, USE, omega, level) 8: add ref into \nREF S 9: for each result operand of op equal to tn do 10: ref .- (time, DEF, 0, level) 11: add ref into \nREF S 12: if tn is live in Ln but not de.ned in it then 13: ref1 .- (fn * T, USE, 0,n) 14: ref2 .- (fn \n* T, DEF, 0,n) 15: add ref1 and ref2 into REF S 16: return REF S Figure 11. Lifetime Normalization Algorithm \n4.2.1 Core Parameters: Characterizing the Simplest and Ideal Forms of a Vector Lifetime First, let us \ncharacterize the simplest form, in the same way as the traditional register allocation for software pipelined \nsingle loops does [12]. SingleStart and singleEnd are the start and end time of the scalar lifetime corresponding \nto the .rst iteration. Omega and alpha are the total live-in values and total live-out values, respectively. \nNext, we characterize the ideal form. Two elements in a scalar lifetime need to be considered: interval \n, and hole between two adjacent intervals. For the interval de.ned at a loop level and the hole following \nit, we represent them by the .rst instance of the interval and the .rst instance of the hole in the scalar \nlifetime corresponding to the .rst iteration. The representation maximizes the length of the interval, \nbut minimizes that of the hole. This is necessarily for two reasons: (1) The de.nition of the interval \nmay have last uses, and successor de.nitions, on different control .ow paths, due to the multiple loop-back \nedges of the loop nest. Therefore, the lengths of the interval and the hole may vary. (2) This is required \nby distance calculation. For example, in calculating the aggressive distance of two vector lifetimes \nA and B, an interval of B is put into a hole of A. If, in the worst case that the interval is the longest \npossible and the hole is the shortest possible, the hole is still long enough to contain the interval \nwithout con.ict, then any instances of the interval and the hole would .t without con.ict, whatever paths \nare followed by the interval and the hole. Similar request is from calculating the conservative distance \nas well. The intervals de.ned at every loop level, and the holes following them, are represented by 3 \narrays, start, end, and nextStart.For each level i, we ensure that end[i] - start[i] is the maximal length \nof the interval de.ned at this level, and nextStart[i] - end[i] is the smallest possible size of the \nhole following it. Start[i] is the issue time of the de.nition of the variant at level i, which is equal \nto its 1-D schedule time. End[i] is one plus the latest issue time of all possible uses of the de.nition. \nThere are two special cases: (1) When the de.nition has no use, end[i] is the completion time of the \nde.nition, i.e., one plus the issue time of the de.nition. (2) When there is no de.nition of the variant \nat level i at all, (start[i],end[i]) are set as (+8 , -8 ), indicating that no interval is really de.ned \nat this level since the length of the interval is end[i]- start[i] < 0. For this reason, the interval \nwill be referred to as a phantom interval. This setting of (start[i],end[i]) naturally enables us to \ntreat the phantom interval the same way as a real interval, without any special consideration, later \nin calculating the distances. NextStart[i] is the earliest issue time of all possible de.nitions that \nare following this interval in the same iteration. NextStart[i] is naturally de.ned to be +8 if there \nis no such de.nition. In short, a vector lifetime can be fully represented as a 7-tuple: (singleStart, \nsingleEnd, omega, alpha, start, end, nextStart). The tuple is de.ned based on the references set REF \nS, which is the output of the lifetime normalization. Formal de.nitions are given in the Appendix. Example: \nFig. 7(a) and 7(b) show how the vector lifetimes for our example in Fig. 6 are characterized in the simplest \nand ideal forms. Fig. 10(e) shows another example how the ideal form is de\u00adscribed. The variant has no \nde.nition at L2 level. So (start[2], end[2])= (+8 , -8 ). This phantom interval has a next inter\u00adval \nde.ned at L3 level by operation c (See Fig. 10(d)). Thus nextStart[2] = start[3]. For that next interval, \nits start, start[3], is equal to the issue time of the .rst instance of operation c. The interval may \nterminate along three different paths, as shown in Fig. 10(d). Among the three paths, the second one \nleads to the longest interval, and the third one the smallest hole. Both paths reach the second instance \nof operation c. The instance has the latest issue time if it is along the second path, and the earliest \nissue time along the third one, which determine end[3] and nextStart[3], respectively. Note that the \nhole following the interval has a negative size, i.e., nextStart[3]- end[3] < 0. However, it can be handled \nin the same way as a normal hole with positive size, without any special concern, later in calculating \nthe distances. 4.2.2 Derived Parameters: Characterizing the Final Form of a Vector Lifetime The derived \nparameters describe the stretched intervals in the .nal form of a vector lifetime. The length of a stretched \ninterval cannot be accurately char\u00adacterized, even after lifetime normalization. Unlike the inde.nite\u00adlength \nintervals due to the liveness of the variant, which can be normalized to have .nite-length by breaking \nthe liveness in the middle of the intervals, stretched intervals are caused by stalls in the .nal schedule \ndue to limited processor resources, which is un\u00adavoidable. For example, the vector lifetimes in Fig. \n7(b) are normal, however, its .nal form in Fig. 6 still has stretched intervals, whose lengths remain \ninde.nite at compile time. Thus, we cannot directly describe a stretched interval horizon\u00adtally , i.e., \nfrom the view point of time in its space-time dia\u00adgram, as we did for the scalar lifetimes in the simplest \nand ideal forms. Fortunately, it is feasible and suf.cient for register alloca\u00adtion to characterize the \nstretched intervals vertically , i.e., from the viewpoint of space in the space-time diagram. This leads \nto the following parameters derived from the core parameters: (outer\u00admostIntervalOnly, .rstStretch, lastStretch, \ntop, bottom). The boolean variable outermostIntervalOnly is true when the loop variant is de.ned only \nat the outermost level. FirstStretch and lastStretch are the iteration indexes of the .rst and last stretched \nintervals of the variant, respectively, that appears in the .rst ILES. If there is no stretched interval \nat all, we set (firstStretch, lastStretch)= (+8 , -8 ). Top is the iteration index of the intervals at \nthe top of the .rst ILES. Bottom is one plus the iteration index of the intervals at the bottom of the \n.rst ILES. When there is no interval in an ILES, we set (top, bottom)=(+8 , -8 ). The difference bottom \n- top represents the vertical thickness of the vector lifetime in an ILES. Example: Fig. 6 shows the \nderived parameters of the lifetimes. The derived parameters are formally de.ned in the Appendix.  4.3 \nDistance Calculation For any two vector lifetimes A and B, a metric, called distance, is used to measure \nhow close and how far A and B can be packed together on the space-time diagram without con.ict. There \nare two types of distances: conservative and aggressive distances. Let rA and rB be the registers to \nbe allocated to A and B, respectively. Each of the conservative distance, denoted CONS[A, B], and the \naggressive distance, denoted AGGR[A, B], de.nes a legal range of rB - rA, within which A and B do not \ncon.ict in the space-time diagram. The conservative distance does not allow the vector lifetimes to interleave, \nwhile the aggressive distance does. For convenience, let INTL[A, B] be the legal range of rB - rA when \nthe vector lifetimes interleave, called interleaving distance. Then AGGR[A, B]=CONS[A, B]. INTL[A, B] \nMore speci.cally, for the conservative distance, B is to the right of any intervals of A. For the interleaving \ndistance, an interval of B is to the right of the corresponding interval of A de.ned at the same loop \nlevel. For convenience, in either case, we will say that B is to the right of A,or B is after A. Equivalently, \nwe may also say A is to the left of B,or A is before B. Note that the relative positions of A and B are \ndifferent in AGGR[A, B] and AGGR[B, A]. Thus in general, they are not equal. That is, AGGR is not symmetric. \nSimilarly, INTL and CONS are not symmetric, either. 4.3.1 Conservative Distance singleEnd(A),if outermost-adjusted- \n=IntervalOnly(A)SingleEnd(A) max(singleEnd(A),ln * T ), otherwise d1 = radjustedS ingleEnd(A)- singleStart(B) \nT 1(1) { d2 = d1 max(d1,omega(A)) if omega(B)=0 otherwise. (2) d3 = { d2 max(d2,alpha(A)) if alpha(A)=0 \notherwise. (3) d4 = max(d3, bottom(B)- top(A)) (4) =. CONS[A, B]=[d4, +8] Figure 12. Conservative Distance \nComputation First, singleEnd(A)is adjusted, which will be explained later. To compute the conservative \ndistance between two vector life\u00adtimes A and B, we consider the simplest form of the vector life\u00adtimes. \nThe problem is then equivalent to that of the single loop case [12] and the following conditions must \nbe veri.ed: the wand of B must be after the wand of A, and the leading/trailing blades of B must be above \nthe leading/trailing blades of A. Formally, singleStart(B)+(rB -rA)*T = adjustedSingleEnd(A) rB - rA \n= omega(A) if omega(B)> 0 rB - rA = alpha(A) if alpha(A)> 0 Solving these inequalities results in formulas \n1, 2, 3 in Fig. 12. Next, we further consider the vector lifetimes in their .nal form by putting ILESes \ninto their simplest form. Because interleaving is not allowed, if A and B have intervals in those segments, \na segment of B should be above the corresponding segment of A, i.e., rB - bottom(B)= rA - top(A). This \nleads us to formula 4. Example: Fig. 13 illustrates the computation of CONS[TN3,TN1] for the example \nin Fig. 6 and 7. D3 and d4 ensure that there is no con.ict outside and inside the ILESes, respectively. \nIn this exam\u00adple, d3 =d4 =5, and thus CONS[TN3,TN1]=[5, +8]. Why singleEnd(A)needs adjustment? The simplest \nform of a vector lifetime is composed of the prolog, OLPs, and epilog. In these segments, there should \nnot be any con.ict before and after expanding the simplest form into the .nal form. Unfortunately, since \nILESes are not included in the simplest form, there is one and only one exception: when an interval s \nde.nition is before, but its consumer is in, an ILES, since the ILES is not in the simplest form and \nneither the consumer, the interval would be shorter than usual. This may leads to a value of d1 smaller \nthan necessary. Fig. 14(a) shows a simple loop nest. With the 1-D schedule in Fig. 14(b), the vector \nlifetimes are shown in Fig. 14(c). From the .gure, the lower bound of CONS[TNz, TNy]should be 3. However, \nin the simplest form (Fig. 14(d)), the .rst instance of operation c, c0,0, produces a value without the \nconsumer. The consumer is in the .rst ILES, which is not in the simplest form. Thus the interval lasts \nfor only one cycle. This leads to d1 =2. A B D F H 111 111 111 111 111 T N1 0000000000111111111111111 \n00000000001111111111 00 00 00 00 00 111 111 111 111 111 0000000000111111111111111 00000000001111111111 \n00 00 00 00 00 111 111 111 111 111 d3 = 5 000000000000000111111111111111 00000000001111111111 00 00 00 \n00 00 111 111 111 111 111 0000000000111111111111111 00000000001111111111 00 00 00 00 00 111 111 111 111 \n111 no co n f ct ou ts ide t he 000000000000111111111111000111 00000000111111110011 00 00 00 00 111 111 \n111 111 00 111 li TN 3 11 0 0 11 11 000111000000000000111111111111 00110000000011111111 00 111 00 00 \n00 00 111 111 111 111 IL ES es : TN 1 is af ter T N 3 0011 0 0 11 11 000000000000000111111111111111 00000000001111111111 \n00 00 00 00 00 111 111 111 111 111 0011 0 0 11 11 00000000000111111111111111 00000000001111111111 000 \n00 00 00 00 111 111 111 111 111 0011 0 0 11 11 111 111 111 111 111 11 0 0 11 11 a dju st ed Si ng le \nE nd =1 0 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 0*T 1*T 2*T 3*T 4*T 5*T 6*T 7*T \n8*T 9*T 10*T 11*T 12*T 13*T 14*T (a) In the simplest form of the vector lifetimes A B C(1st ILES) D 111 \n111 111 111 111 T N1 no co n f ct in th e 0000000000111111111111111 00000000001111111111 00 00 00 00 \n00 111 111 111 111 111 li 00000000000111111111111111 00000000001111111111 00 00 00 00 000 111 111 111 \n111 111 d4 = 5 I L ES : T N 1 is ab o ve 000000000000000111111111111111 00000000001111111111 00 00 00 \n00 00 111 111 111 111 111 T N 3 in th e IL ES 0000000000111111111111111 00000000001111111111 00 00 00 \n00 00 111 111 111 111 111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111 \n111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111 111111111111111 1111111111 \n111 111 111 111 111 TN 3 11 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 000000000000000111111111111111 00000000001111111111 \n000 00 00 00 00 111 111 111 111 111 0011 0 0 11 11 11 0 0 11 11 0011 0 0 11 11 000000000000000111111111111111 \n00000000001111111111 000 00 00 00 00 111 111 111 111 111 0011 0 0 11 11 0011 0 0 11 11 0011 0 0 11 11 \n000000000000000111111111111111 00 00 00 00 00 11 11 11 11 11 0011 0 0 11 11 0011 0 0 11 11 0*T 1*T 2*T \n3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T 12*T 13*T 14*T (b) In the .nal form of the vector lifetimes Figure \n13. Illustration of Conservative Distance Computation Then in the .nal form, since TNy has no interval \nin the ILESes and thus bottom(TNy)= -8,wehave d4 = d1 =2, which is obviously wrong: There is con.ict \nin the .rst OLP, because the interval starting from c0,0 now lasts into the .rst ILES. Due to the repetitiveness \nof OLP and ILES, there would be con.ict in other OLPs as well. To avoid such con.ict, in the simplest \nform, we only need to elongate that interval to reach the end of the .rst OLP so as to take that piece \nof space exclusively. Having a consumer in an ILES means that there is a use at an inner loop level. \nSince after normalization, a loop cannot have only uses in it without a de.nition, that further means \nthere is a de.nition at an inner loop level. That is, outermostIntervalOnly is false. In general, in \ncalculating CONS[A, B], we adjust singleEnd(A) to the end of the .rst OLP, if it is before that end and \noutermostIn\u00adtervalOnly(A) is false. This will suf.ciently prevent any future con\u00ad.ict outside the ILESes. \nIn the above example, singleEnd of TNz needs to be adjusted to the end of the .rst OLP (cycle 3* T ,or \nin general, ln * T ). That leads to d1 =3. In fact, Fig. 14(c) is the result using the adjusted singleEnd. \nExample: In Fig. 7(a), singleEnd of TN3 is adjusted to cycle 10. It remains the same for the other two \nvariants.  4.3.2 Aggressive Distance The aggressive distance is the union of the conservative and inter\u00adleaving \ndistances. Below we introduce how to compute the inter\u00adleaving distance. First, we consider the ideal \nform of the vector lifetimes. For each loop level i, let IA and IB be the intervals from vector lifetimes \nA and B de.ned at this level, respectively. To interleave them, IB must be put to the hole behind IA. \nThere is one special case to be considered: if IB is a phantom, the interval following it in the same \n r1 end(IA)-nextStart(IB) if IB is {T 32 1 0 stage a phantom (5) l(IA,IB)= L:for (i=0; i; i++) { index \n ..... a:TNy=... otherwise r1 end(IA)-start(IB) T :TNz=TNz...  u(IA,IB)= b:TNz=TNy T =2 L: for (i=0;i;i++) \n{ nextStart(IA)- end(IB) . .... (6) T ... S =3 n }//end L}//end L. S1=4 {} .interval pair (IA,IB) \nl(IA,IB) from A and B . (7) d5 = max (a) The 3rd Example (b) The Kernel 1st OLP 1st ILES 2nd OLP 2nd \nILES epilog {} .interval pair (IA,IB) d6 = min u(IA,IB) (8) from A and B d7 = max (d5, bottom(B)- firstStretch(A)) \n(9) { d6 if outermostIntervalOnly(A) d8 = min(d6,firstStretch(B)-Sn)otherwise (10) { d7 if omega(B)=0 \nd9 = (11) max(d7,omega(A)) otherwise. { d9 if alpha(A)=0 d10 = (12) max(d9,alpha(A)) otherwise. 0*T 1*T \n2*T 3*T 4*T 5*T 6*T 7*T 8*T 9*T 10*T 11*T (c) The Final Form of the Vector Lifetimes (with N1 = 6,N2 \n=2) =. INTL[A, B]=[d10,d8] AGGR[A, B]=CONS[A, B]. INTL[A, B] Conflict appears before the ILES Figure \n15. Aggressive Distance Computation Finally, similarly to formulas 2 and 3, the constraints from the \nlive-in and live-out values are added through formulas 11 and 12. Example: Fig. 16 illustrates the major \nsteps in computing the interleaving distance INTL[TN3,TN2]. For clarity, we use only the .nal form, and \nadd the phantom intervals of TN3 to show how the extreme values, +8 and -8, are used in the formulas \nnaturally without any special concern. (d) Pack the Simplest (e) Expand to the Final Form TN3 s interval \nat level 1 Form Figure 14. Adjusting SingleEnd scalar lifetime of B should be naturally after IA. That \nis, start(IB)+(rB - rA)* T = end(IA) end(IB)+(rB - rA)* T = nextStart(IA)   nextStart(IB)+(rB - rA)* \nT = end(IA)if IB is a phantom where start(Iv), end(Iv), and nextStart(Iv) refer to start[i], end[i], \nand nextStart[i]of the vector lifetime v, with i . [1,n] being the loop level under discussion. This \nleads to the [l, u] range de.ned by equations 5 and 6 in Fig. 15. The intersection of all the ranges \ncalculated from the The first stretched interval of TN3. FirstStretch(TN3)=+ vertical position of the \ninterval=r-firstStretch(TN3)= Legend: 11 Phantom interval. Only to show how the extreme values 111 + \nand are used without special concern. Results: for level 1: after before  u=-1l= after u=-1 for \nlevel 2: l=-1 before (IA,IB)pairs of all loop levels is the range within which no con\u00ad [d5, d6]=[ , \n-1] [-1, -1]=[-1, -1] d7=d5=-1 above bottom(TN2)-firstStretch(TN3)=  .ict would occur between any interval \nof A and B. This intersec\u00ad tion is de.ned by equations 7 and 8 for the lower and upper bounds, respectively. \nbelow firstStretch(TN2)-Sn=0 d8=d6=-1 INTL[TN3, TN2]=[-1, -1] Then we consider the stretched intervals \nin the .nal form. Intu\u00aditively, the stretched intervals of B should be between the stretched Figure 16. \nIllustration of Aggressive Distance Computation intervals of A and the intervals of A de.ned at the inner \nloop levels. More formally, rB - bottom(B) = rA - firstStretch(A) 4.4 Bin-packing on the Cylinder 4.5 \nCircumference Minimization rB - firstStretch(B) = rA - Sn if not outermost - IntervalOnly(A) These translate \ninto formulas 9 and 10. Once the distance between any two vector lifetimes is computed, the vector lifetimes \nare inserted one after the other on the surface of a space-time cylinder of a circumference equal to \nthe maximum number of available registers, R. The algorithm is shown in Fig. 17. PLDI 05 10 2005/4/19 \n   INSERT LIFETIMES( VLT,DIST,strategy ): 1: for each vector lifetime A . VLT do 2: illegal[A] .- \u00d8 \n//empty set of illegal registers 3: for each unallocated vector lifetime A . VLT do 4: legal . [0,R - \n1] - illegal[A] 5: Allocate to A a register rA . legal using strategy 6: for each other unallocated vector \nlifetime B . VLT do 7: illegal[B] .- illegal[B] . newIllegal(B, A, R) where newIllegal(B, A, x)= { i \nmod x|. i . .,i /. legalSet(B, A)} legalSet(B, A)=(rA - DIST [B, A]) . (rA + DIST [A, B]) Figure 17. \nLifetime Insertion Algorithm For any given vector lifetime A, illegal[A] is the set of registers that \ncannot be allocated to A to avoid con.ict with already-placed vector lifetimes. Its difference with the \nfull set of available registers [0,R - 1], i.e., ([0,R - 1] - illegal[A]), is the set of candidate registers \nallocatable to A. Assume that A is allocated register rA. For any other unallo\u00adcated vector lifetime \nB, its illegal set needs to be updated. B can be placed either to the right of A, or to the left of A.If \nB is to be placed to the right of A, rA + DIST [A, B] is the set of reg\u00adisters that can be allocated \nto B without con.ict with A.If B is placed to the left of A, rA - DIST [B, A] is. The union of the sets \nin both cases is noted legalSet(B, A). Here DIST is the dis\u00adtance, CONS or AGGR, and x \u00b1 set denotes \na new set that is { x \u00b1 y|. y . set} . The complement of legalSet(B, A) is the set of illegal registers \nfor B, due to con.icts with A. Fig. 18 illustrates legalSet(B, A) with thin arrows when DIST is CONS, \nand bold arrows when DIST is AGGR. Note that the former is a subset of the latter. Because the number \nof physical registers is limited to R, the set of illegal registers wraps around the cylinder and is \ntherefore considered modulo R into newIllegal(B, A, R). A legal register before wrapping around can become \nillegal after that, if any illegal register, after wrapping around, overlaps with it, as shown by the \nannotation for parts 1 and 2 in Fig. 18. So far the solution uses the maximum number of physical registers, \nR, as the circumference of the cylinder. The last step tries to compress the cylinder to decrease the \nactual number of registers required. First, the circumference is initialized as the distance between \nthe smallest and the biggest registers allocated. Then the allocation is translated such that the smallest \nregister allocated equals 0. A vector lifetime A may con.ict with itself after wrapping around, if the \ncircumference is not within DIST [A, A], where DIST is either CONS or AGGR. It also con.icts with a different \nvector lifetime B,if B is allocated an illegal register with respect to A under the current circumference. \nIf there is no con.ict between any pair of vector lifetimes, including a vector lifetime with itself, \nthe search is over. Otherwise, we increment the circumference until a legal solution is found. Note that \na circumference of R is always valid, and thus the search will de.nitely terminate. The algorithm is \nshown in Fig. 19. MINIMIZE CIRCUMFERENCE(VLT,DIST ): 1: minReg .- the smallest register allocated 2: \nmaxReg .- the biggest register allocated 3: c .- maxReg - minReg +1 //c: circumference 4: for each vector \nlifetime A . VLT do 5: rA .- rA - minReg //rA: A s register 6: Next: 7: for each vector lifetime A . \nVLT do 8: if c/. DIST [A, A] then 9: c .- c +1 10: goto Next 11: for each vector lifetime B . VLT , s.t. \nB = A do 12: if rB . newIllegal(B, A, c) then //rB:B s register 13: c .- c +1 14: goto Next Figure 19. \nCircumference Minimization Algorithm  5. Properties and Time Complexity THEOREM 1. Given two vector \nlifetimes A and B, if the loop nest is a single loop (n =1), then CONS[A, B]= AGGR[A, B]= [x, +8 ), where \nx is the lower bound calculated by the classical register allocation for software pipelined single loops \n[12]. In this sense, the approach in this paper subsumes the classical approach as a special case. Intuitively, \na vector lifetime in a single loop has only one inter\u00adval for each scalar lifetime. Thus putting the \nvector lifetime B to the right of A is equivalent to interleaving B to the right of A.So CONS[A, B]= \nINTL[A, B]= AGGR[A, B]. PROOF. According to the de.nitions in Section 4.2, for any vec\u00adtor lifetime in \na single loop, we have outermostIntervalOnly is true, singleStart = start[1] and is equivalent to start \nin the traditional case, singleEnd = end[1] and is equivalent to end in the traditional case, nextStart[1]= \n+8 . Since there is no ILES, (firstStretch, lastStretch)= (+8 , -8 ), and (top, bottom)=(+8 , -8 ). Apply \nthem to the formulas in Fig. 12 and 15. We obtain the same formulas used in Rau s method. Next we analyze \nthe time complexity of our solution. Let l be the total vector lifetimes, and o the number of operations. \nLifetime normalization and representation has a time complexity of O(o) per variant, and O(l * o) for \nall the variants. The total time spent in computing distances is O(l2) for all pairs of variants. Sorting \ncan be done in O(l2) time. Bin-packing uses the same strategies as those for the single loops [12], given \nthe distances. The time complexity for .rst and end .ts are quadratic(O(l2)), and cubic for Figure 18. \nLifetime Insertion on the Space-Time Cylinder best .t(O(l3)) [12]. Circumference minimization loops \nat most R times, with each time costing O(l2)time. In summary, the overall time complexity is O(lx +l \n* o), where x =2for .rst and end .t strategies, and x =3for best .t.  6. Experiments The register allocation \nmethod proposed in this paper, as well as the rest of the SSP framework, was implemented in the ORC 2.1 \ncompiler. The input of the register allocator is the kernel produced by the scheduling phase [14], and \nthe output is a register-allocated kernel that is sent to the code generator [13]. 6.1 Experimental Framework \nThe vector lifetimes are sorted in increasing order by adjacency. Ties are broken using singleStart, \nthen adjustedSingleEnd modulo T . The adjacency represents the number of cycles a register is idle. It \nis de.ned as singleStart(B)-adjustedSingleEnd(A)+ d3(A, B)* T , where A is the vector lifetime previously \nselected at the last step, B the vector lifetime to be selected, and d3(A, B)is the d3 value in calculating \nCONS[A, B]in Fig. 12. The heuristic is an extension to the (adjacency, start time) heuristic used in \nthe traditional register allocation for single loops [12]. Seven different strategies were used for inserting \nthe vector life\u00adtimes on the space-time cylinder. The .rst, referred to as Simple, ignores the speci.c \nshape of a vector lifetime A and exclusively al\u00adlocates to it S1 +omega(A)physical registers, which is \nthe max\u00adimum number of instances of a loop variant that can be live simul\u00adtaneously in the .nal schedule \n[13]. As described in Section 4, bin\u00adpacking and circumference minimization can use either the conser\u00advative \nor the aggressive distance. The two choices, combined with the .rst, best, and end .ts introduced in \nSection 2.2, lead to 6 strate\u00adgies: ConsFirst, ConsBest, ConsEnd, AggrFirst, AggrBest, and AggrEnd. Besides, \na theoretical lower bound, named MaxLive,is used for measuring optimality. It is the maximum number of \nscalar lifetimes live simultaneously at any cycle in the .nal schedule. A total of 134 loop nests were \ngathered from NAS, Livermore and SPEC2000 benchmark suites. To test the register pressure related with \ndifferent levels, SSP was applied to each feasible level, leading to a total of 348 loop levels tested. \nNote that even for the same variant in the same source code, software pipelining of two different levels \nresults in completely different vector lifetimes. The distribution of the nesting depths is shown in \nTable 1. Here nesting depth is 1 plus the total number of inner loops of the loop level under consideration. \nA maximum circumference of 1024 was assumed. When the number of registers allocated did not exceed 96 \nrotating integer and .oating-point registers, the total rotating registers in Itanium architecture, the \nparallelized loop nest was run on an Itanium2 machine with 1.4GHz/1GB RAM, and correctness was validated \nby comparing its output with that of the same loop nest compiled with GCC or the original ORC2.1 binary. \nSome statistics about the loops are shown in Fig. 20(a). Overall, 60% of the loops have 47 operations \nor less , but 12% of the loops have more than 200. 64% of the loops have an II of less that 10 cycles, \nand 8.4% of them have an II larger than 40 cycles. Note that, because a smaller II may be related to \na higher number of stages, it tends to increase the register pressure. 80% of the loops have 56 integer \nloop variants or less and the maximum is 174. For .oating-point loop variants, 80% of the loops has less \nthan 45 with a maximum of 96. The total number of stages never exceeds 11 and the number of live-in values \nnever goes above 7. Nesting Depth 1 2 345 Number 127 108 68 33 12  Table 1. Number of Loops for Each \nNesting Depth 6.2 Results 1. The conservative and aggressive distances, used with the best or .rst .t \nstrategies, greatly improve the success rate of the register allocation, close to the limit set by an \nideal register al\u00adlocator.By success, we refer to the fact that the total number of registers allocated \nis within 96. A register allocator is ideal if it al\u00adlocates exactly maxLive number of registers. Fig. \n20(b) and 20(c) show the distribution curves for loop nests of depths 2 to 5. For integer registers, \nof all the loops that can be successfully handled by an ideal register allocator, the simple heuristics \ncan successfully handle only 30%. The rate is improved up to 53% using the con\u00adservative distance, and \nup to 91.7% using the aggressive distance. This con.rms the importance of characterization and exploitation \nof the speci.c patterns of the software pipelined vector lifetimes to achieve ef.cient register allocation. \nConsidering the fact that maxLive is not the optimal lower bound 1, this result is encour\u00adaging and impressive. \nOverall, with only 96 integer registers, our method allows us to successfully compile 76.5% of all the \nloop nests. We analyzed several loops to further investigate why the aggres\u00adsive distance can be so effective. \nFig. 21 shows an excerpt of the integer space-time cylinder of a double loop nest from the initial\u00adization \nprocedure of the Livermore benchmark, automatically gen\u00aderated by our compiler (except for the annotations). \nA symbol in the .gure represents a vector lifetime. Surprisingly, intervals from four different vector \nlifetimes, h, i, g, and 9, are interleaved. The allocation is impressively compact. Further investigation \nof some other loops shows that this phenomenon is not uncommon. 2. The .rst .t strategy is found to be \nalmost as effective as the best .t strategy, with signi.cantly less compile time. Their cumulative distribution \ncurves on the number of registers allocated in Fig. 20(b) and 20(c) are close and cannot be distinguished. \nThey both outperform the end .t strategy by succeeding in compiling at least 15% more of the loops. However, \n.rst .t takes 0.009 seconds on average, while best .t 11 seconds. Table 2 shows the average time distribution \nin each phase of register allocation. AggrBest consumes signi.cantly more time in bin-packing than AggrFirst. \nThere is no meaningful difference in the time of any other phase. Fig. 20(d) shows the average registers \nneeded for each loop level for AggrF irst. For a single loop, the register requirement is almost minimized. \nFor a multi-dimensional loop, as the nest deepens, the register requirement is relatively closer to maxLive. \nNorma- Repre- Computing Sorting Bin- Circumference lization sentation Distance packing Minimization AggrFirst \n0.004 0.004 0.019 0.006 0.009 0.006 AggrBest 0.004 0.004 0.028 0.008 11.19 0.006 Table 2. Average Compile \nTime Distribution (in Seconds) 3. The experiments con.rm that, in the single loop case, our method subsumes \nthe traditional register allocation as a special case, and achieves near-optimality. Fig. 20(e) and Fig. \n20(f) show that there is no difference between using the conservative distance or the aggressive distance, \nas proved in Section 5. 4. The improvement of register allocation does make a dif\u00adference in performance. \n18 loop nests, depth 2 to 5, were con\u00adsidered. For all of them, AggrF irst succeeds, while Simple and \nConsF irst fails. The loop nests were rescheduled with higher IIs so that Simple and ConsF irst may succeed. \nHowever, simple cannot succeed for 11 loops even II is increased to in.nitely big, and ConsF irst for \n5 loops. This is because the register pressure stops decreasing when II is above certain threshold. Similar \nsitu\u00adation is also noticed in software pipelining of single loops [10]. For all the other loops, we divided \nthe .nal II (execution time) of each loop against that of AggrF irst, and get the II ratio (execution \ntime ratio). On average, the IIs of Simple and ConsF irst were then 81% and 25% larger, respectively. \nAnd the execution time was 69% and 28% longer, respectively.   7. Conclusion In the context of multi-dimensional \nsoftware-pipelining, vector lifetimes with complex shapes present unusual challenges to regis\u00ad 1 For \ninstance, in Fig. 8(b), the optimal number of registers required is 7, but the maximum number of scalar \nlifetimes live at each cycle is 6. 96 registers 96 registers 100 100   0 50 100 150 200 250 300 350 \n0 100 200 300 400 500 (a) Cumulative Distribution of the Proper-(b) Cumulative Distribution of the Number \nties of the Input Loop Nests (Depth 1-5)of Integer Registers Allocated(Depth 2-5) 96 registers100 0 50 \n100 150 200 250 300 350 400 450 500 (c) Cumulative Distribution of the Num\u00adber of Floating-Point Registers \nAllocated (Depth 2-5) 96 registers100  80 80 % of loops 60 60 40 40 4 99.42 119.48 15.75 20.50 20 20 \n3 74.70 90.75 19.02 24.68 2 46.92 54.61 17.37 22.86 0 0 % of loops  Integer Floating-point   5 135.00 \n161.00 14.00 20.67 1 21.78 22.40 15.79 16.19 (d) Average Register Requirement(e) Cumulative Distribution \nof the Number (f) Cumulative Distribution of the Num\u00ad of Integer Registers Allocated (Depth 1) ber of \nFloating-Point Registers Allocated (Depth 1) Figure 20. Cumulative Distribution Statistics about the \nLoop Nests 10 66 ddddddjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj66 ddddddjjjjjjjjjjjjjjjjjjjjjjjjjjjjj 9 \n66 ddddddjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj66 ddddddjjjjjjjjjjjjjjjjjjjjjj 8 66 ddddddjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj66 \nddddddjjjjjjjjjjjjjjj 7 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 66 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhh 66 99 \nhhhhhhhhh 6 gggggg 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhh gggggg 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhh gggggg \n99 hh 5 iiiiiiigggggg 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhiiiiiiigggggg 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhiiiiiiigggggg \n4 iiiiiiigggggg 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhiiiiiiigggggg 99 hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhiiiiiii \n Intervals from 3 different vector lifetimes are interleaved in a single hole. Registers Figure 21. \nExcerpt of the Integer Space-time Cylinder for a Double Loop Nest Average II ratio Average execution \ntime ratio #loops failed ref as time(ref), type(ref) (USE or DEF), omega(ref), and Simple 1.81 1.69 11 \nlevel(ref), respectively. ConsFirst 1.25 1.28 5 Table 3. Impact of Register Allocation Strategies upon \nPerfor\u00ad A.1 SingleStart, SingleEnd, Omega, and Alpha mance ter allocation. This paper has presented a \nsystematic solution. The essential problems of lifetime representation and normalization were addressed \nto precisely abstract the lifetimes. The conserva\u00adtive and aggressive distances were proposed to guide \nbin-packing and circumference minimization free of con.ict, with multiple .t strategies. The method subsumes \nthe classical register allocation for software pipelined single loops as a special case. Experiments \nindicate that .rst .t strategy aided with the aggressive distance ef\u00adfectively minimizes register usage \nwith insigni.cant compile time.  A. Appendix: Formal De.nitions for Lifetime Representation The core \nand derived parameters are de.ned from the references set REF S. For convenience, we refer to the elements \nin a reference PLDI 05 13 singleStart = min {time(r), .r .REF S s.t. type(r)=DEF}singleEnd = max {time(r)+1+omega(r)* \nT, .r .REF S} omega = max {omega(r), .r .REF S} SingleStart and singleEnd are equivalent to the start \nand end time used in traditional register allocation for single loops [12], described in Section 2.2. \nIn de.ning singleEnd, not only uses, but also de.nitions must be considered: in case a variant is de.ned, \nbut not used, the end time of that variant should be the completion time of the last de.nition. In a \nhealthy program, only a reference at the outermost loop level, which is software pipelined, may have \na non-zero omega. The loop nest in Fig. 3(a) is a typical example. Also, omega of a de.nition is always \n0. Alpha depends on the code outside the loop nest, and cannot be computed from the references. We assume \nit has already been given by an earlier phase of the compiler. 2005/4/19 A.2 Start and End Given a loop \nlevel i . [1,n],if level i has no de.nition in REF S, we set (start[i],end[i])=(+8, -8). Otherwise, let \nthe de.ni\u00adtion be d . REF S, then start[i]=time(d) end[i]=max(time(d)+1,time(u)+1+omega(u)* T +loopbackOffset(d, \nu), .u .USES(d)) where USES(d)is the set of all possible uses of d. Note that a value produced at an \ninner loop level cannot be consumed at the outermost loop level. Otherwise, the dependence (called negative \ndependence) should have prevented the outermost loop level to be software pipelined [14]. Therefore, \nUSES(d)excludes any use at L1 level if d is at an inner loop level, even if d can reach the use from \nthe standard data .ow analysis. Formally, USES(d)={u|type(u)=USE and d reaches u and (level(u)=1 or level(d)=1)} \nIn the term of data .ow analysis, a point x in the control .ow graph reaches another point y if there \nis a path from x to y without any de.nition of the variant under consideration between them. The control \n.ow graph in this paper is that for the original loop nest (before software pipelining) de.ned in Fig. \n5(a), which contains n back edges, one for each loop. LoopbackOffset(x, y)is the offset due to the execution \nof an inner loop Lj . Since the inner loop runs sequentially, the offset equals Sj *T . Formally, if \nx reaches y without going along the back edge of any inner loop, loopbackOffset(x, y)=0. Otherwise, loopbackOffset(x, \ny)=max(Sj *T )for any inner loop Lj (2= j = n), along whose back edge x can reach y. See the example \nin Fig. 10(d). A.3 NextStart Given a loop level i . [1,n], let x be a point at this level. If level \ni has a de.nition d . REF S, let x = d. Otherwise, let x be the starting point of loop Li, i.e., x is \nat the .rst cycle of the .rst stage of Li. Then {min{ time(d )+loopbackOffset(x, d ), .d .NEXT DEF S(x)} \nnextStart[i]= IfNEXT DEF S(x)is not empty +8 Otherwise where NEXT DEF S(x)is the set of all possible \nnext de.nitions in the same iteration as point x. The back edge of the outermost loop should not be followed \nin calculating this set. Otherwise, the set may contain a de.nition from the next iteration. Formally, \nNEXT DEF S(x)={y|y . REF S and type(y)=DEF and x can reach y without going along the back edge of the \noutermost loop } A.4 FirstStretch and LastStretch Take the .rst ILES as a point of reference. Let x \n= 0 be the iteration index of a stretched interval at loop level i. The interval is stretched if it is \nde.ned before the .rst cycle of the .rst ILES, but its last use reaches or goes beyond that cycle, and \nis not within the .rst group of iterations. For example, in Fig. 4, the interval of TN2 de.ned by operation \nb3 spans across the .rst ILES, and the use c3,0 is in the second group. Formally, the conditions are: \nstart[i]+x * T<ln * T, end[i]+x * T>ln * T, x +omega = Sn when i =1, x = Sn when i> 1, and x = 0. Let \nfirst and last be the smallest and largest solutions of x to the above inequalities. That is, lJ end[i]-1 \nfirst = min max(0,Sn - span, ln - T ) .i.[1,n] r1 start[i]+1 last = max (ln - T ) .i.[1,n] where span \n=omega if i =1,or span =0otherwise. Note that when n =1or first > last, there is no stretched interval \nat all. Thus we de.ne (+8, -8) if n =1or (firstStretch, lastStretch)= first > last (first, last) otherwise \n A.5 Top and Bottom Again take the .rst ILES as a point of reference. If outermostInter\u00advalOnly is true, \nthe segment is made of only stretched intervals, if any. Otherwise, there are Sn scalar lifetimes from \nthe .rst group, followed by stretched intervals, if any. For example, in Fig. 6, TN1 has only a stretched \ninterval in the .rst ILES, while TN2 has Sn =3scalar lifetimes and two stretched intervals. Therefore, \n(firstStretch, lastStretch +1) if outer- (top, bottom)= mostIntervalOnly (0,max(Sn, lastStretch +1)) \notherwise Note that if outermostIntervalOnly is true, and no interval is stretched (i.e., (firstStretch, \nlastStretch)= (+8, -8)), the ILES would have no interval in it. In this case, according to the formulas, \n(top, bottom)would be (+8, -8), as expected.   Acknowledgments We are grateful to Chan Sun, Ross Towle, \nShuxin Yang, Jose Nel\u00adson Amaral, R. Govindarajan, Jean C. Beyler, and Michel Strasser for their valuable \ncomments.  References [1] V. H. Allan, R. B. Jones, R. M. Lee, and S. J. Allan. Software pipelining. \nACM Computing Surveys, 27(3):367 432, 1995. [2] D. Callahan and B. Koblenz. Register allocation via hierarchical \ngraph coloring. In Proc. of PLDI 91, pages 192 203, 1991. [3] S. Carr, C. Ding, and P. Sweany. Improving \nsoftware pipelining with unroll-and-jam. In Proc. of HICSS 96, pages 183 192, 1996. [4] G. J. Chaitin. \nRegister allocation &#38; spilling via graph coloring. In Proc. of CC 82, pages 98 101. ACM Press, 1982. \n[5] J. C. Dehnert and R. A. Towle. Compiling for the Cydra 5. J. Supercomput., 7(1-2):181 227, 1993. \n[6] L. J. Hendren, G. R. Gao, E. R. Altman, and C. Mukerji. A register allocation framework based on \nhierarchical cyclic interval graphs. In Computational Complexity, pages 176 191, 1992. [7] R. A. Huff. \nLifetime-sensitive modulo scheduling. In PLDI 93, pages 258 267, 1993. [8] Intel. Intel IA-64 Architecture \nSoftware Developer s Manual, Vol. 1. Intel, 2001. [9] M. Lam. Software pipelining: An effective scheduling \ntechnique for VLIW machines. In Proc. of PLDI 88, pages 318 328, 1988. [10] J. Llosa, M. Valero, and \nE. Ayguad. Heuristics for Register-Constrained Software Pipelining. In Proc. of MICRO 96, pages 250 261, \n1996. [11] K. Muthukumar and G. Doshi. Software pipelining of nested loops. LNCS, 2027:165 181, 2001. \n[12] B. R. Rau, M. Lee, P. P. Tirumalai, and M. S. Schlansker. Register allocation for software pipelined \nloops. In PLDI 92, pages 283 299, 1992. [13] H. Rong, A. Douillet, R. Govindarajan, and G. R. Gao. Code \ngeneration for single-dimension software pipelining of multi\u00addimensional loops. In Proc. of CGO 04, pages \n175 186, 2004. [14] H. Rong, Z. Tang, R. Govindarajan, A. Douillet, and G. R. Gao. Single-dimension software \npipelining for multi-dimensional loops. In Proc. of CGO 04, pages 163 174, 2004.  \n\t\t\t", "proc_id": "1065010", "abstract": "Software pipelining of a multi-dimensional loop is an important optimization that overlaps the execution of successive outermost loop iterations to explore instruction-level parallelism from the entire n-dimensional iteration space. This paper investigates register allocation for software pipelined multi-dimensional loops.For single loop software pipelining, the lifetime instances of a loop variant in successive iterations of the loop form a repetitive pattern. An effective register allocation method is to represent the pattern as a vector of lifetimes (or a <i>vector lifetime</i> using Rau's terminology) and map it to rotating registers. Unfortunately, the software pipelined schedule of a multi-dimensional loop is considerably more complex, and so are the vector lifetimes in it.In this paper, we develop a way to normalize and represent vector lifetimes in multi-dimensional loop software pipelining, which capture their complexity, while exposing their regularity that enables us to develop a simple, yet powerful solution. Our algorithm is based on the development of a metric, called <i>distance</i>, that quantitatively determines the degree of potential overlapping (conflicts) between two vector lifetimes. We show how to calculate and use the distance, conservatively or aggressively, to guide the register allocation of the vector lifetimes under a bin-packing algorithm framework. The classical register allocation for software pipelined single loops is subsumed by our method as a special case.The method has been implemented in the ORC compiler and produced code for the Itanium architecture. We report the effectiveness of our method on 134 loop nests with 348 loop levels. Several strategies for register allocation are compared and analyzed.", "authors": [{"name": "Hongbo Rong", "author_profile_id": "81100595852", "affiliation": "University of Delaware, Newark, DE", "person_id": "PP27004925", "email_address": "", "orcid_id": ""}, {"name": "Alban Douillet", "author_profile_id": "81100062046", "affiliation": "University of Delaware, Newark, DE", "person_id": "P441716", "email_address": "", "orcid_id": ""}, {"name": "Guang R. Gao", "author_profile_id": "81100134147", "affiliation": "University of Delaware, Newark, DE", "person_id": "P100128", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065030", "year": "2005", "article_id": "1065030", "conference": "PLDI", "title": "Register allocation for software pipelined multi-dimensional loops", "url": "http://dl.acm.org/citation.cfm?id=1065030"}