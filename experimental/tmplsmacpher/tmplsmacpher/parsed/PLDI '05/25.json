{"article_publication_date": "06-12-2005", "fulltext": "\n PADS: A Domain-Speci.c Language for Processing Ad Hoc Data Kathleen Fisher Robert Gruber * AT&#38;T \nLabs Research Google 180 Park Ave., E244 1600 Amphitheatre Pkwy Florham Park, NJ Mountain View, CA kfisher@research.att.com \ngruber@google.com Abstract PADS is a declarative data description language that allows data an\u00adalysts \nto describe both the physical layout of ad hoc data sources and semantic properties of that data. From \nsuch descriptions, the PADS compiler generates libraries and tools for manipulating the data, including \nparsing routines, statistical pro.ling tools, transla\u00adtion programs to produce well-behaved formats such \nas XML or those required for loading relational databases, and tools for run\u00adning XQueries over raw PADS \ndata sources. The descriptions are concise enough to serve as living documentation while .exible enough \nto describe most of the ASCII, binary, and Cobol formats that we have seen in practice. The generated \nparsing library pro\u00advides for robust, application-speci.c error handling. Categories and Subject Descriptors \nD.3.3 [Programming lan\u00adguages]: Language constructs and features Input/output General Terms Languages \nKeywords Data description language, domain-speci.c languages  1. Introduction Vast amounts of useful \ndata are stored and processed in ad hoc formats. Traditional databases and XML systems provide rich in\u00adfrastructure \nfor processing well-behaved data, but are of little help when dealing with ad hoc formats. Examples that \nwe face at AT&#38;T include call detail data [13], web server logs [26], net.ows captur\u00ading internet \ntraf.c [2], log .les characterizing IP backbone resource utilization, wire formats for legacy telecommunication \nbilling sys\u00adtems, etc. Such data may simply require processing before it can be loaded into a data management \nsystem, or it may be too large or too transient to make such loading cost effective. Processing ad hoc \ndata can be challenging for a variety of reasons. First, ad hoc data typically arrives as is : the analysts \nwho receive it can only say thank you, not request a more convenient * Work carried out while at AT&#38;T \nLabs Research. Permission to make digital or hard copies of all or part of this work for personal or \nclassroom use is granted without fee provided that copies are not made or distributed for pro.t or commercial \nadvantage and that copies bear this notice and the full citation on the .rst page. To copy otherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. PLDI 05, June 12 15, 2005, Chicago, Illinois, USA. Copyright 2005 ACM 1-59593-056-6/05/0006...$5.00. \nformat. Second, documentation for the format may not exist at all, or it may be out of date. A common \nphenomenon is for a .eld in a data source to fall into disuse. After a while, a new piece of information \nbecomes interesting, but compatibility issues prevent data suppliers from modifying the shape of their \ndata, so instead they hijack the unused .eld, often failing to update the documentation in the process. \nThird, such data frequently contain errors, for a variety of rea\u00adsons: malfunctioning equipment, race \nconditions on log entry [26], non-standard values to indicate no data available, human error in entering \ndata, unexpected data values, etc. The appropriate re\u00adsponse to such errors depends on the application. \nSome applica\u00adtions require the data to be error free: if an error is detected, pro\u00adcessing needs to stop \nimmediately and a human must be alerted. Other applications can repair the data, while still others can \nsimply discard erroneous or unexpected values. For some applications, er\u00adrors in the data can be the \nmost interesting part because they can signal where two systems are failing to communicate. A fourth \nchallenge is that ad hoc data sources can be high vol\u00adume: AT&#38;T s call-detail stream contains roughly \n300 million calls per day requiring approximately 7GBs of storage space. Although this data is eventually \narchived in a database, analysts mine it prof\u00aditably before such archiving [14, 15]. More challenging, \nthe Al\u00adtair project at AT&#38;T accumulates billing data at a rate of 250-300GB/day, with occasional \nspurts of 750GBs/day. Net.ow data arrives from Cisco routers at rates over a gigabyte per second [16]! \nSuch volumes mean it must be possible to process the data without loading it all into memory at once. \nFinally, before anything can be done with an ad hoc data source, someone has to produce a suitable parser \nfor it. Today, people tend to use C or PERL for this task. Unfortunately, writing parsers this way is \ntedious and error-prone, complicated by the lack of docu\u00admentation, convoluted encodings designed to \nsave space, the need to produce ef.cient code, and the need to handle errors robustly to avoid corrupting \ndown-stream data. Moreover, the parser writers hard-won understanding of the data ends up embedded in \nparsing code, making long-term maintenance dif.cult for the original writ\u00aders and sharing the knowledge \nwith others nearly impossible. The PADS system makes life easier for data analysts by address\u00ading each \nof these concerns.1 It provides a declarative data descrip\u00adtion language that permits analysts to describe \nthe physical layout of their data, as it is. The language also permits analysts to describe expected \nsemantic properties of their data so that deviations can be .agged as errors. The intent is to allow \nanalysts to capture in a PADS description all that they know about a given data source and to provide \nthe analysts with a library of useful routines in exchange. 1 PADS is short for Processing Ad hoc Data \nSources. PADS descriptions are concise enough to serve as documenta\u00adtion and .exible enough to describe \nmost of the data formats we have seen in practice, including ASCII, binary, Cobol, and mixed data formats. \nThe fact that PADS generates useful software artifacts from the descriptions provides strong incentive \nfor keeping the de\u00adscriptions current, allowing them to serve as living documentation. Given a PADS description, \nthe PADS compiler produces cus\u00adtomizable C libraries and tools for parsing, manipulating, and sum\u00admarizing \nthe associated data. The core C library includes functions for reading the data, writing it back out \nin its original form, writing it into a canonical XML form, pretty printing it in forms suitable for \nloading into a relational database, and accumulating statistical properties. An auxiliary library provides \nan instance of the data API for Galax [5, 18], an implementation of XQuery. This library al\u00adlows users \nto query data with a PADS description as if the data were in XML without having to convert to XML. In \naddition to these li\u00adbraries, the PADS system provides template programs to summarize the data, format \nit, or convert it to XML. The declarative nature of PADS descriptions facilitates the inser\u00adtion of error \nhandling code. The generated parsing code checks all possible error cases: system errors related to the \ninput .le, buffer, or socket; syntax errors related to deviations in the physical format; and semantic \nerrors in which the data violates user constraints. Be\u00adcause these checks appear only in generated code, \nthey do not clut\u00adter the high-level declarative description of the data source. The result of a parse \nis a pair consisting of a canonical in-memory rep\u00adresentation of the data and a parse descriptor. The \nparse descrip\u00adtor precisely characterizes both the syntactic and the semantic er\u00adrors that occurred during \nparsing. This structure allows analysts to choose how to respond to errors in application-speci.c ways. \nBecause of the size of typical datasets, performance is critical. The PADS system addresses performance \nin a number of ways. First, we compile PADS descriptions rather than simply interpret them to reduce \nrun-time overhead. Second, the generated parser provides multiple entry points, so the data consumer \ncan choose the appropriate level of granularity for reading the data to accom\u00admodate very large data \nsources. Finally, we parameterize library functions by masks, which allow data analysts to choose which \nse\u00admantic conditions to check at run-time, permitting them to specify all known properties in the source \ndescription without forcing all users of that description to pay the run-time cost of checking them. \nGiven the importance of the problem, it is perhaps surpris\u00ading that more tools do not exist to solve \nit. XML and relational databases only help with data already in well-behaved formats. Lex and Yacc are \nboth over-and under-kill. Overkill because the divi\u00adsion into a lexer and a context free grammar is not \nnecessary for many ad hoc data sources, and under-kill in that such systems re\u00adquire the user to build \nin-memory representations manually, sup\u00adport only ASCII sources, have a limited error model, and don \nt provide extra tools. ASN.1 [17] and related systems [1] allow the user to specify an in-memory representation \nand generate an on\u00addisk format, but this doesn t help when given a particular on-disk format. Existing \nad hoc description languages [9, 29, 4] are steps in the right direction, but they focus on binary, error-free \ndata and they do not provide auxiliary tools. In building the PADS system, we faced challenges on two \nfronts: designing the data description language and crafting the generated libraries and tools. In the \nrest of the paper, we describe each of these designs. We also give examples to show how useful they have \nbeen at AT&#38;T. 2. Example data sources Before discussing the PADS design, we describe a selection \nof data sources, focusing on those we use as running examples. Fig\u00adure 1 summarizes some of the sources \nwe have worked with. They include ASCII, binary, and Cobol data formats, with both .xed and variable-width \nrecords, ranging in size from relatively small .les through network applications which process over a \ngigabyte per second. Common errors include undocumented data, corrupted data, missing data, and multiple \nmissing-value representations such as None , - , etc. 2.1 Common Log Format Web servers use the Common \nLog Format (CLF) to log client requests [26]. Researchers use such logs to measure properties of web \nworkloads and to evaluate protocol changes by replaying the user activity recorded in the log. This ASCII \nformat consists of a sequence of records, each of which has seven .elds: the host name or IP address \nof the client making the request, the account associated with the request on the client side, the name \nthe user provided for authentication, the time of the request, the actual request, the HTTP response \ncode, and the number of bytes returned as a result of the request. The actual request has three parts: \nthe request method (e.g., GET, PUT), the requested URI, and the protocol version. In addition, the second \nand third .elds are often recorded only as a - character to indicate the server did not record the actual \ndata. Figure 2 shows a couple of typical records. 2.2 Provisioning data In the telecommunications industry, \nthe term provisioning refers to the steps necessary to convert an order for phone service into the actual \nservice. To track AT&#38;T s provisioning process, the Sirius project compiles weekly summaries of the \nstate of certain types of phone service orders. These ASCII summaries store the summary date and one \nrecord per order. Each order record contains a header followed by a sequence of events. The header has \n13 pipe separated .elds: the order number, AT&#38;T s internal order number, the order version, four \ndifferent telephone numbers associated with the order, the zip code of the order, a billing identi.er, \nthe order type, a mea\u00adsure of the complexity of the order, an unused .eld, and the source of the order \ndata. Many of these .elds are optional, in which case nothing appears between the pipe characters. The \nbilling identi.er may not be available at the time of processing, in which case the system generates \na unique identi.er, and pre.xes this value with the string no ii to indicate the number was generated. \nThe event se\u00adquence represents the various states a service order goes through; it is represented as \na new-line terminated, pipe separated list of state, timestamp pairs. There are over 400 distinct states \nthat an order may go through during provisioning. The sequence is sorted in or\u00adder of increasing timestamps. \nFigure 3 shows a small example of this format. It may be apparent from these paragraphs that English \nis a poor language for describing data formats!  3. PADS Design A PADS description speci.es the physical \nlayout and semantic properties of an ad hoc data source. The language provides a type\u00adbased model: basic \ntypes describe atomic data such as integers, strings, dates, etc., while structured types describe compound \ndata built from simpler pieces. The PADS library provides a collection of broadly useful base types. \nExamples include 8-bit unsigned integers (Puint8), 32\u00adbit integers (Pint32), dates (Pdate), strings (Pstring), \nand IP addresses (Pip). Semantic conditions for such base types in\u00adclude checking that the resulting \nnumber .ts in the indicated space, i.e., 16-bits for Pint16. By themselves, these base types do not provide \nsuf.cient information to allow parsing because they do not specify how the data is coded, i.e., in ASCII, \nEBCDIC, or binary. To resolve this ambiguity, PADS uses the ambient coding, which Name &#38; Use Representation \nSize Common Errors Web server logs (CLF): Measuring web workloads Fixed-column ASCII records =12GB/week \nRace conditions on log entry Unexpected values AT&#38;T provisioning data (Sirius): Monitoring service \nactivation Variable-width ASCII records 2.2GB/week Unexpected values Corrupted data feeds Call detail: \nFraud detection Fixed-width binary records 7GB/day Undocumented data AT&#38;T billing data (Altair): \nMonitoring billing process Various Cobol data formats 4000 .les/day, 250-300GB/day Unexpected values \nCorrupted data feeds IP backbone data (Regulus) Monitoring network performance ASCII = 15 sources 15 \nGB/day Multiple missing-value representations Undocumented data Net.ow Monitoring network performance \nData-dependent number of .xed-width binary record =1Gigabit/second Missed packets Figure 1. Selected \nad hoc data sources. We will use the bold data sources in our examples. the programmer can set. By default, \nPADS uses ASCII. To spec\u00adify a particular coding, the description writer can select base types which \nindicate the coding to use. Examples of such types include ASCII 32-bit integers (Pa_int32), binary bytes \n(Pb_int8), and EBCDIC characters (Pe_char). In addition to these types, users can de.ne their own base \ntypes to specify more specialized forms of atomic data. To describe more complex data, PADS provides \na collection of structured types loosely based on C s type structure. In particular, PADS has Pstructs, \nPunions, and Parrays to describe record\u00adlike structures, alternatives, and sequences, respectively. Penums \ndescribe a .xed collection of literals, while Popts provide con\u00advenient syntax for optional data. Each \nof these types can have an associated predicate that indicates whether a value calculated from the physical \nspeci.cation is indeed a legal value for the type. For example, a predicate might require that two .elds \nof a Pstruct are related or that the elements of a sequence are in increasing or\u00adder. Programmers can \nspecify such predicates using PADS expres\u00adsions and functions, written using a C-like syntax. Finally, \nPADS Ptypedefs can be used to de.ne new types that add further con\u00adstraints to existing types. PADS types \ncan be parameterized by values. This mechanism serves both to reduce the number of base types and to \npermit the format and properties of later portions of the data to depend upon earlier portions. For example, \nthe base type Puint16_FW(:3:) speci.es an unsigned two byte integer physically represented by exactly \nthree characters, while the type Pstring(: :) de\u00adscribes a string terminated by a space. Parameters \ncan be used with compound types to specify the size of an array or which branch of a union should be \ntaken. Figure 4 gives the PADS description for CLF web server logs, while Figure 5 gives the description \nfor the Sirius provisioning data. We will use these two examples to illustrate various features of the \nPADS language. In PADS descriptions, types are declared before they are used, so the type that describes \nthe totality of the data source appears at the bottom of the description. Pstructs describe .xed sequences \nof data with unrelated types. In the CLF description, the type declaration for version_t illustrates \na simple Pstruct. It starts with a string literal that matches the constant HTTP/ in the data source. \nIt then has two unsigned integers recording the major and minor version numbers separated by the literal \ncharacter . . PADS supports character, string, and regular expression literals, which are interpreted \nwith the ambient character encoding. The type request_t similarly describes the request portion of a \nCLF record. In addition to phys\u00adical format information, this Pstruct includes a semantic con\u00adstraint \non the version .eld. Speci.cally, it requires that obso\u00adlete methods LINKand UNLINKoccur only under HTTP/1.1. \nThis constraint illustrates the use of predicate functions and the fact that earlier .elds are in scope \nduring the processing of later .elds, as the constraint refers to both the meth and version .elds in \nthe Pstruct. Punions describe variation in the data format. For example, the client_t type in the CLF \ndescription indicates that the .rst .eld in a CLF record can be either an IP address or a hostname. During \nparsing, the branches of a Punion are tried in order; the .rst branch that parses without error is taken. \nThe auth_id_t type illustrates the use of a constraint: the branch unauthorized is chosen only if the \nparsed character is a dash. PADS also supports a switched union that uses a selection expression to determine \nthe branch to parse. Typically, this expression depends upon already\u00adparsed portions of the data source. \nPADS provides Parrays to describe varying-length sequences of data all with the same type. The eventSeq_tdeclaration \nin the Sirius data description uses a Parrayto characterize the sequence of events an order goes through \nduring processing. This declaration indicates that the elements in the sequence have type event_t. It \nalso speci.es that the elements will be separated by vertical bars, and that the sequence will be terminated \nby an end-of-record marker (Peor). In general, PADS provides a rich collection of array-termination conditions: \nreaching a maximum size, .nding a terminating literal (including end-of-record and end-of-source), or \nsatisfying a user-supplied predicate over the already-parsed portion of the Parray. Finally, this type \ndeclaration includes a Pwhere clause to specify that the sequence of timestamps must be in sorted order. \nIt uses the Pforall construct to express this constraint. In general, the body of a Pwhere clause can \nbe any boolean expression. In such a context for arrays, the pseudo-variable elts is bound to the in-memory \nrepresentation of the sequence and lengthto its length. Returning to the CLF description in Figure 4, \nthe Penum type method_t describes a collection of data literals. During parsing, PADS interprets these \nconstants using the ambient character encod\u00ading. The Ptypedef response_t describes possible server re\u00adsponse \ncodes in CLF data by adding the constraint that the three\u00addigit integer must be between 100 and 600. \nThe order_header_t type in the Sirius data description contains several anonymous uses of the Popt type. \nThis type is syntactic sugar for a stylized use of a Punionwith two branches: the .rst with the indicated \ntype, and the second with the void type, which always matches but never consumes any input. Finally, \nthe Precordand Psourceannotations deserve com\u00adment. The .rst indicates that the annotated type constitutes \na record, while the second means that the type constitutes the to\u00adtality of a data source. The notion \nof a record varies depending upon the data encoding. ASCII data typically uses new-line char\u00ad 207.136.97.49 \n--[15/Oct/1997:18:46:51 -0700] \"GET /tk/p.txt HTTP/1.0\" 200 30 tj62.aol.com --[16/Oct/1997:14:32:22 -0700] \n\"POST /scpt/dd@grp.org/confirm HTTP/1.0\" 200 941 Figure 2. Tiny example of web server log data. 0|1005022800 \n9152|9152|1|9735551212|0||9085551212|07988|no_ii152272|EDTF_6|0|APRL1|DUO|10|1000295291 9153|9153|1|0|0|0|0||152268|LOC_6|0|FRDW1|DUO|LOC_CRTE|1001476800|LOC_OS_10|1001649601 \n Figure 3. Tiny example of Sirius provisioning data. Punion client_t { Pip ip; /-135.207.23.32 Phostname \nhost; /-www.research.att.com }; Punion auth_id_t { Pchar unauthorized : unauthorized == - ; Pstring(: \n :) id; }; Pstruct version_t { \"HTTP/\"; Puint8 major; . ; Puint8 minor; }; Penum method_t { GET, PUT, \nPOST, HEAD, DELETE, LINK, UNLINK };  bool chkVersion(version_t v, method_t m) { if ((v.major == 1) \n&#38;&#38; (v.minor == 1)) return true; if ((m == LINK) || (m == UNLINK)) return false; return true; \n }; Pstruct request_t { \\\" ; method_t meth; ; Pstring(: :) req_uri; ; version_t version : chkVersion(version, \nmeth); \\\" ; }; Ptypedef Puint16_FW(:3:) response_t : response_t x => { 100 <= x &#38;&#38; x < 600}; \n Precord Pstruct entry_t { client_t client; ; auth_id_t remoteID; ; auth_id_t auth; \" [\"; Pdate(: ] \n:) date; \"] \"; request_t request; ; response_t response; ; Puint32 length; }; Psource Parray clt_t \n{ entry_t []; } Figure 4. PADS description for web server log data. Precord Pstruct summary_header_t \n{  \"0|\"; Puint32 }; tstamp; Pstruct no_ramp_t { \"no_ii\"; Puint64 id; }; Punion dib_ramp_t { Pint64 ramp; \nno_ramp_t genRamp; }; Pstruct order_header_t { Puint32 | ; Puint32 | ; Puint32 | ; Popt pn_t | ; Popt \npn_t | ; Popt pn_t | ; Popt pn_t | ; Popt Pzip | ; dib_ramp_t | ; Pstring(: | :) | ; Puint32 | ; Pstring(: \n| :) | ; Pstring(: | :) | ; }; order_num; att_order_num; ord_version; service_tn; billing_tn; nlp_service_tn; \nnlp_billing_tn; zip_code; ramp; order_type; order_details; unused; stream; Pstruct event_t { Pstring(: \n| :) state; Puint32 tstamp; }; | ; Parray eventSeq { event_t[] : Psep( | ) &#38;&#38; Pterm(Peor); \n} Pwhere { Pforall (i Pin [0..length-2] : (elts[i].tstamp <= elts[i+1].tstamp)); }; Precord Pstruct \nentry_t { order_header_t header; eventSeq events; }; Parray entries_t { entry_t[]; }; Psource Pstruct \nout_sum{ summary_header_t h; entries_t es; }; Figure 5. PADS description for Sirius provisioning data. \nacters to delimit records, binary sources tend to have .xed-width records, while COBOL sources usually \nstore the length of each record before the actual data. PADS supports each of these encod\u00adings of records \nand allows users to de.ne their own encodings. By default, PADS assumes records are new-line terminated. \nBefore parsing, however, the user can direct PADS to use a different record de.nition. More information \nabout the PADS language may be found in the PADS manual [7].  4. Generated library From a description, \nthe PADS compiler generates a C library for parsing and manipulating the associated data source. We chose \nC as the target language for pragmatic reasons: there were libraries that made building the compiler \nand run-time libraries easier, our target users are comfortable with C, and it can serve as a lingua \nfranca in that essentially all languages have provisions for calling C libraries. Nothing about the PADS \nlanguage mandates compiling to C, however, and we envision eventually building alternate bindings. From \neach type in a PADS description, the compiler generates an in-memory representation,  a mask, which \nallows users to customize generated functions,  a parse descriptor, which describes syntactic and semantic \ner\u00adrors detected during parsing,  parsing and printing functions, and  a broad collection of utility \nfunctions.  To give a feeling for the library that PADS generates, Figure 6 includes selected portions \nof the generated library for the Sirius entry_tdeclaration. The C declarations for the in-memory representation, \nthe mask, andtheparsedescriptorallsharethestructureofthe PADS typedec\u00adlaration. The mapping to C for \neach is straightforward: Pstructs map to C structs with appropriately mapped .elds, Punions map to tagged \nunions coded as C structs with a tag .eld and an embed\u00added union, Parrays map to a C struct with a length \n.eld and a dynamically allocated sequence, Penums map to C enumerations, Popts to tagged unions, and \nPtypedefs to C typedefs. Masks include auxiliary .elds to control behavior at the level of a struc\u00adtured \ntype, and parse descriptors include extra .elds to record the state of the parse, the number of detected \nerrors, the error code of the .rst detected error, and the location of that error. The parser takes a \nmask as an argument and returns an in\u00admemory representation and a parse descriptor. The mask allows the \nuser to specify which constraints the parser should check and which portions of the in-memory representation \nit should .ll in. This control allows the description-writer to specify all known constraints about the \ndata without worrying about the run-time cost of verifying potentially expensive constraints for time-critical \napplications. Appropriate error-handling can be as important as processing error-free data. The parse \ndescriptor marks which portions of the data contain errors and characterizes the detected errors. Depending \nupon the nature of the errors and the desired application, program\u00admers can take the appropriate action: \nhalting the program, discard\u00ading parts of the data, or repairing the errors. If the mask requests that \na data item be veri.ed and set, and if the parse descriptor in\u00addicates no error, then the in-memory representation \nsatis.es the se\u00admantic constraints on the data. Because we generate a parsing function for each type \nin a PADS description, we support multiple-entry point parsing, which allows us to accommodate larger-scale \ndata. For a small .le, programmers can de.ne a PADS type that describes the entire .le and use that type \ns parsing function to read the whole .le with one call. For larger-scale data, programmers can sequence \ncalls to parsing func\u00adtions that read manageable portions of the .le, e.g., reading a record at a time \nin a loop. The parsing code generated for Parrays allows users to choose between reading the entire array \nat once or reading it one element at a time, again to support parsing and processing very large data \nsources. The ratio of the size of the data description to the size of the generated code gives a rough \nmeasure of the leverage of the declarative description. For the 68 line Sirius data description, the \ncompiler yields a 1432 .h .le and a 6471 .c.le. This expansion comes from the extensive error checking \nin the generated parser and the number of generated utility functions. We discuss details of the generated \nlibrary in the following section as we describe its uses.  5. PADS in practice Because the PADS language \nis declarative, we can leverage PADS descriptions to build additional tools besides the core parsing \nand printing library. As a result, PADS provides direct support for a number of different uses: computing \nwith the data, developing a high-level understanding of the data through statistical summaries, converting \nthe data into a more standard form, and querying. In this section, we give a survey of some of these \nuses. 5.1 General computation 5.1.1 Normalizing data We start by showing in Figure 7 a simple use of \nthe core library to clean and normalize Sirius data. After initializing the PADS li\u00adbrary handle and \nopening the data source, the code sets the mask to check all conditions in the Sirius description except \nthe sorting of the timestamps. For brevity, we have omitted from the .gure the code to read and write \nthe header. The code then echoes error records to one .le and cleaned ones to another. The raw data has \ntwo different representations of unavailable phone numbers: sim\u00adply omitting the number altogether, which \ncorresponds to the NONE branch of the Popt, or having the value 0in the data. The function cnvPhoneNumbers \nuni.es these two representations by con\u00adverting the zeroes into NONEs. The function entry_t_verify ensures \nthat our computation hasn t broken any of the semantic properties of the in-memory representation of \nthe data. 5.1.2 Hancock streams Another programmatic use of the core library is to de.ne Hancock streams. \nHancock is a domain-speci.c language for building persis\u00adtent pro.les of entities described in transaction \nstreams [13]. Data analysts at AT&#38;T use Hancock programs over streams of call-detail records to build \npro.les of phone numbers, capturing behaviors like the frequency with which a given number makes a phone \ncall. They uses these pro.les to detect fraud. De.ning the input streams turned out to be one of the \nmost dif.cult parts of writing Hancock programs because the parsing code had to handle erroneous val\u00adues \nand decipher complex encodings. Also, the analysts wanted to have one stream description for their many \napplications, but each application could only afford to check for the errors immediately relevant to \nit. Hence they parameterized the stream descriptions by .ags to toggle various error checking code. This \napplication pro\u00advided the initial motivation for the PADS project in general, and for masks in particular. \n  5.2 Statistical summaries Before using a data source, analysts must develop an understanding of both \nthe layout and the meaning of the data. Because documen\u00adtation is usually incomplete or out-of-date, \nthis understanding must be developed through exploring the data itself. Typical questions include: how \ncomplete is the description of the syntax of the data typedef struct { Pbase_m compoundLevel; // Struct-level \ncontrols, eg., check Pwhere clause order_header_t_m h; eventSeq_t_m events; } entry_t_m; typedef struct \n{ Pflags_t pstate; // Normal, Partial, or Panicking Puint32 nerr; // Number of detected errors. PerrCode_t \nerrCode; // Error code of first detected error Ploc_t loc; // Location of first error order_header_t_pd \nh; // Nested header information eventSeq_t_pd events; // Nested event sequence information } entry_t_pd; \ntypedef struct { order_header_t h; eventSeq_t events; } entry_t; /* Core parsing library */ Perror_t \nentry_t_read (P_t *pads,entry_t_m *m,entry_t_pd *pd,entry_t *rep); ssize_t entry_t_write2io (P_t *pads,Sfio_t \n*io,entry_t_pd *pd,entry_t *rep); /* Selected utility functions */ void entry_t_m_init (P_t *pads,entry_t_m \n*mask,Pbase_m baseMask); int entry_t_verify (entry_t *rep); /* Selected accumulator functions */ Perror_t \nentry_t_acc_init (P_t *pads,entry_t_acc *acc); Perror_t entry_t_acc_add (P_t *pads,entry_t_acc *acc,entry_t_pd \n*pd,entry_t *rep); Perror_t entry_t_acc_report (P_t *pads,char const *prefix,char const *what, int nst,entry_t_acc \n*acc); /* Formatting */ ssize_t entry_t_fmt2io (P_t *pads,Sfio_t *io,int *requestedOut, char const *delims,entry_t_m \n*m,entry_t_pd *pd,entry_t *rep); /* Conversion to XML */ ssize_t entry_t_write_xml_2io (P_t *pads,Sfio_t \n*io,entry_t_pd *pd, entry_t *rep,char const *tag,int indent); /* Galax Data API */ PDCI_node_t *entry_t_node_new \n(PDCI_node_t *parent,char const *name,void *m, void *pd,void *rep,char const *kind,char const *whatfn); \nPDCI_node_t *entry_t_node_kthChild (PDCI_node_t *self,PDCI_childIndex_t idx); Figure 6. Selected portions \nof the library generated for the entry tdeclaration from Sirius data description. source, how many different \nrepresentations for data not available are there, what is the distribution of values for particular .elds, \netc. PADS addresses these kinds of questions with the notion of an ac\u00adcumulator. For each type in a PADS \ndescription, accumulators track the number of good values, the number of bad values, and the dis\u00adtribution \nof legal values. Selected functions from this portion of the library appear in Figure 6. We can of course \nuse these functions by hand to write a program to compute the statistical pro.le of any PADS data source. \nHowever, ad hoc sources are often simply a sequence of records, perhaps pre.xed by a header, so we can \ncreate a complete accumulator program from minimal extra information. Both the web server log and the \nSirius data sources exhibit this pattern.2 Consequently, given only the names of the optional header \ntype and the record type, the PADS system will generate an accumulator program. The accumulator report \nfor the length .eld of the web server data looks 2 Note that a data format that can be read in one bulk \nread also .ts this pattern. as follows when run on a data set used in several studies of web traf.c [27, \n28]: <top>.length : uint32 +++++++++++++++++++++++++++++++++++++++++++ good: 53544 bad: 3824 pcnt-bad: \n6.666 min: 35 max: 248591 avg: 4090.234 top 10 values out of 1000 distinct values: tracked 99.552% of \nvalues val: 3082 count: 1254 %-of-good: 2.342 val: 170 count: 1148 %-of-good: 2.144 val: 43 count: 1018 \n%-of-good: 1.901 val: 9372 count: 975 %-of-good: 1.821 val: 1425 count: 896 %-of-good: 1.673 val: 518 \ncount: 893 %-of-good: 1.668 val: 1082 count: 881 %-of-good: 1.645 val: 1367 count: 874 %-of-good: 1.632 \nval: 1027 count: 859 %-of-good: 1.604 val: 1277 count: 857 %-of-good: 1.601 ...................... SUMMING \ncount: 9655 %-of-good: 18.032 P_t *p; entry_t entry; entry_t_pd pd; entry_t_m mask; ... P_open(&#38;p, \n0, 0); P_io_fopen(p, \"sirius/data/2004.11.11\"); ... entry_t_m_init(p, &#38;mask, P_CheckAndSet); mask.events.compoundLevel \n= P_Set; ... while (!P_io_at_eof(p)) { entry_t_read(p, &#38;mask, &#38;pd, &#38;entry); if (pd.nerr \n> 0) { entry_t_write2io(p, ERR_FILE, &#38;pd, &#38;entry); } else { cnvPhoneNumbers(&#38;entry); if \n(entry_t_verify(&#38;entry)) { entry_t_write2io(p, CLEAN_FILE, &#38;pd, &#38;entry); } else { error(2, \n\"Data transform failed.\"); } } } Figure 7. Code fragment to .lter and normalize Sirius data. By default, \naccumulators track the .rst 1000 distinct values seen in the data source and report the frequency of \nthe top ten values. In this particular run, 99.552% of all values were tracked. When generating the accumulator \nprogram (or when using the library directly), PADS users can specify the number of distinct values to \ntrack and the number of values to print in the report. Perhaps surprisingly, the report shows that 6.66% \nof the length .elds contained errors. A glance at the error log generated by the program (which contains \nall records .agged as errors) reveals that web servers occasionally store the - character rather than \nthe actual number of bytes returned, a possibility not mentioned in the documentation [26]. Accumulators \ncan also be used to pro.le data sources automat\u00adically. Indeed, this application motivated the initial \ndesign of accu\u00admulators. AT&#38;T s Altair project receives roughly 4000 data .les per day in various \nCobol formats. This volume makes looking at each .le by hand prohibitively expensive. However, accumulator \npro.les can be used to determine automatically which pro.les have high percentages of errors and which \nhave signi.cantly different statistical pro.les than earlier versions of the same .le. To support this \nusage, we built a tool that automatically translates Cobol copy\u00adbooks into PADS descriptions. In practice \nat AT&#38;T, accumulators have proven themselves very useful for data exploration. The Regulus project \nuses PADS accu\u00admulator programs to .nd all the different representations of data not available, typical \nexamples of which include 0, a blank, NONE, and Nothing. An accumulator program revealed the two repre\u00adsentations \nof missing phone numbers in the Sirius data that the ex\u00adample program in Section 5.1.1 repaired. Accumulators \nalso often serve as a quick tool for iteratively re.ning a PADS description until only genuine errors \nremain.  5.3 Format Conversion Another common need is to convert ad hoc data into a more well\u00adbehaved \nformat, such as delimited .elds suitable for loading into a spreadsheet or relational database, or into \nXML. 5.3.1 Formatting To support converting ad hoc data into a delimited format, the PADS library generates \na formatting function for each type. This function, an example of which appears in Figure 6, takes a \ndelimiter list as an argument. At each .eld boundary, it prints the .rst delimiter. At each nested type \nboundary, it advances the delimiter list unless the list is exhausted, in which case it reuses the last \ndelimiter. The mask argument allows the user to suppress printing of portions of the data. Programmers \ncan use the library directly to write formatting programs by hand. However, as in the accumulator case, \nPADS can generate a formatting program for commonly occurring data patterns given only the header type \n(optional), record type, and a delimiter string. Users can further customize the generated program by \nspecifying an output format for dates and mask values. Given the delimiter string \"|\" and the output \ndate format \"%D:%T\", the generated web server log formatting program yields the output shown in Figure \n8 when applied to the sample data in Figure 2. To support customization, PADS allows users to provide \ntheir own formatting functions for any type. AT&#38;T s Regulus project uses generated formatting programs \nto convert various data sources into a format suitable for loading into Daytona [22], a relational database \nin widespread use at AT&#38;T. 5.3.2 XML Generation PADS also supports converting ad hoc data into XML \nby provid\u00ading a canonical mapping from PADS descriptions into XML. This mapping is quite natural, as \nboth PADS and XML are languages for describing semi-structured data. One interesting aspect of the mapping \nis that we embed not just the in-memory representation of PADS values, but also the parse descriptors \nin cases where the data was buggy. This choice allows users to explore the error portions of their data \nsources, which can be the most interesting parts of the data. Given a PADS speci.cation, the PADS compiler \ngenerates an XML Schema describing the canonical embedding for that data source. As an example, the following \nis the portion of the generated XML Schema for the eventSeq type in the Sirius data descrip\u00adtion. <xs:complexType \nname=\"eventSeq_pd\"> <xs:sequence> <xs:element name=\"pstate\" type=\"Pflags_t\"/> <xs:element name=\"nerr\" \ntype=\"Puint32\"/> <xs:element name=\"errCode\" type=\"PerrCode_t\"/> <xs:element name=\"loc\" type=\"Ploc_t\"/> \n<xs:element name=\"neerr\" type=\"Puint32\"/> <xs:element name=\"firstError\" type=\"Puint32\"/> </xs:sequence> \n</xs:complexType> <xs:complexType name=\"eventSeq\"> <xs:sequence> <xs:element name=\"elt\" type=\"event\" \n minOccurs=\"0\" maxOccurs=\"unbounded\"/> <xs:element name=\"length\" type=\"Puint32\"/> <xs:element name=\"pd\" \ntype=\"eventSeq_pd\" minOccurs=\"0\" maxOccurs=\"1\"/> </xs:sequence> </xs:complexType> The PADS compiler \ngenerates a write_xml_2io function for each type, an example of which is shown in Figure 6. Given a spec\u00adi.cation \nof the top level type, PADS can also generate a conversion program automatically, the output of which \nconforms to the gener\u00adated XML Schema.  5.4 Queries Our .nal use-scenario is querying data. Given a \ndata source, a natural desire is to ask questions about the data, a desire which led to SQL and its many \nvariants for relational data and XQuery for XML data [11]. Analysts working with ad hoc data would also \nlike to query their data, but the lack of tools generally means they code 207.136.97.49|-|-|10/16/97:01:46:51|GET|/tk/p.txt|1|0|200|30 \ntj62.aol.com|-|-|10/16/97:21:32:22|POST|/scpt/dd@grp.org/confirm|1|0|200|941 Figure 8. Formatted CLF \nrecords. their queries in an imperative fashion in languages such as AWK, PERL, or C. Indeed, the analyst \nworking with the Sirius data took this approach. He coded queries such as Select all orders starting \nwithin a certain time window, Count the number of orders going through a particular state, and What \nis the average time required to go from a particular state to another particular state in a mixture of \nAWK and PERL. He was able to get the answers to his questions, but he had to code the queries explicitly, \nand the query-related code ended up embedded in his already-brittle parsing code. We wanted to support \ndeclarative querying over ad hoc sources, but we didn t want to invent an entirely new query language, \nwhich led us to examine existing languages. Because XQuery is designed to manipulate semi-structured \ndata, its expressiveness matched our data sources well. We were able to code all the Sirius-related queries \nin XQuery. For example, the XQuery $sirius/sirius/order[event[1] [timeStamp >= xs:date(\"2002-04-14\") \nand timeStamp <= xs:date(\"2002-05-25\") ]] asks for all orders starting within the given time window. \nHappy with XQuery s expressiveness, we worked with the de\u00adsigners of the Galax [18] open-source implementation \nof XQuery to de.ne a data API [5]. This API presents the source as a tree to Galax. With this architecture, \nGalax can incorporate any data source accessible through an instance of the data API. We then ex\u00adtended \nthe PADS system to produce such instances. We were able to de.ne the bulk of the API generically, having \nto generate on a per type basis only a handful of functions. Figure 6 contains the key generated functions \nfor the entry_t type from the Sirius data. The node_new function creates a node in the tree representation \nof the data, storing the supplied name, mask, parse descriptor, and in-memory representation. It makes \nthe argument node the parent of the newly created node. The node_kthChild function takes a tree corresponding \nto an entry_t node and a child index and returns the appropriate child. For the entry_ttype, possible \nchil\u00addren are the header, the event sequence, or a parse descriptor. At the moment, it is possible to \nuse the resulting system to query ad hoc data sources that can be loaded entirely into memory, and a \nversion that allows the data to be read lazily is well underway. How best to optimize Xqueries over ad \nhoc data sources is an open research area.  6. Implementation From a PADS description, the PADS compiler \ngenerates .h and .c.les that together implement the data structures and operations necessary for manipulating \nthe types declared in the source .le. The PADS run-time library implements all shared functionality, \nincluding .le operations, regular expression manipulation, memory management, the provided base types, \nand the generic portions of the Galax data API. PADS generates a recursive descent parser that makes \nit easy to provide multiple entry points. We used the CKIT library [12] to implement the PADS compiler. \nThis library greatly facilitated the construction of the compiler as it provides a framework for extending \nC, typechecking the extension, and then pretty printing the result. Because of CKIT, we were able to \nhave a working version of the PADS compiler very quickly. Currently, our compiler consists of 10,000 \nlines of SML/NJ code layered on top of CKIT. The PADS run-time library comprise approximately 30,000 \nlines of C code, built on top of the AST [19] and SFIO [25] libraries. These libraries provide support \nfor regular expressions, container data types, a date parsing library, and various I/O routines. To make \nthe collection of base types user-extensible, the com\u00adpiler reads all base type speci.cations from .les. \nAt compile time, the user can provide a list of such .les to augment the provided base types. A base \ntype speci.cation declares the names of the in\u00admemory representation, mask, and parse descriptor data \nstructures and the names of the functions that implement the parsing, writing, formatting, etc. operations. \nSupport for accumulators is optional, as is support for the Galax data API. The user is responsible for \npro\u00adviding a C library with implementations of all the named types and functions. More information about \nuser-de.ned base types appears in the PADS manual [7]. The PADS implementation is available from the \nPADS website with a non-commercial use license: http://www.padsproj.org  7. Performance To get a rough \nfeel for the performance of PADS, we compare the parser PADS generates for the Sirius data description \nwith a hand\u00adwritten PERL program. We opted to compare with PERL because PERL is the language that our \nuser base typically chooses. We measured the performance of the two approaches on two different tasks: \nvetting Sirius data in a fashion similar to the .lter program of Figure 7 and collecting the order number \nof all records that ever pass through a particular state. For the .rst task, we check all the speci.ed \nproperties of the data, including the constraint that the timestamps in the events appear in sorted order. \nFor the second task, we turn off all error checking and simply output the desired order numbers on standard \nout. We pass as input to the selection programs the cleaned data .le produced by the vetter programs. \nWe attempted to write the equivalent PERL programs in as ef.cient a manner possible, given the speci.ed \ntasks. For each record, the PERL vetter uses the built-in split operator to produce an in-memory array \nof the pipe-separated .elds. The PERL selection program uses PERL s regular expression pattern matcher \nto .nd lines with the desired state in any position after the 13th .eld. Figure 9 shows the relevant \nregular expression, looking for orders going through state $STATE. PERL compiles this pattern and applies \nthe compiled pattern to each line. The PERL vetter is 323 lines of well-commented PERL code, while the \nselection program is 66 lines. The PADS vetter is 153 lines of well\u00adcommented C code, while the PADS \nselection program is 120 lines. We used a Sirius data .le to exercise the programs. This 2.2GB .le contained \n11,773,843 records. The minimum number of states for an order was one, the maximum number was 156, and \nthe average was 5.5. One of these records violated the expected sorting order on event timestamps, and \n53 of them contained a syntax error. (These statistics are courtesy of the generated PADS accumulator \nprogram, a nice side-bene.t of the PADS description.) We conducted our experiments on one processor of \nan SGI Origin 2000 running Irix 6.5. The processor, a 500 Mhz R14000, has split 32KB instruction and \ndata caches and an 8MB secondary cache. The machine has more than 20GB of main memory. We used PERL version \n5.6.1 to execute the PERL scripts, and gcc version 3.2.2 with optimization level O2 to compile the PADS \nprograms. qr/ (\\d+)\\|(?:[ |]*\\|){12}(?:[ |]*\\|[ |]*\\|)*$STATE\\|/; Figure 9. Regular expression at the \nheart of the PERL selection program. pads vet perl vet.pl pads select perl select.pl 1619.1 3310.8 426.4 \n548.7 1600.7 3300.9 419.8 518.4 1627.5 3205.2 418.4 492.1 Figure 10. Elapsed time in seconds of PERL \nand PADS vetting and selection programs. We report the times for all three runs.  We ran each program \nthree times. Figure 10 reports the elapsed running times using the Unix time utility. For comparison, \na PERL program that simply counts the number of records takes on average 124 seconds. The corresponding \nPADS program takes 81 seconds. The PADS vetter was more than twice as fast as the PERL vetter, while \nthe PADS selection program outperformed the PERL selection program by a smaller margin. We have not yet \ndevoted signi.cant time to optimizing the generated parser or the base type library, so we expect improvements \nare possible.  8. Related work There are many tools for describing data formats. For example, ASN.1 \n[17] and ASDL [1] are both systems for declaratively describing data and then generating libraries for \nmanipulating that data. In contrast to PADS, however, both of these systems specify the logical representation \nand automatically generate a physical representation. Although useful for many purposes, this technology \ndoes not help process data that arrives in predetermined, ad hoc formats. Lex and yacc-based tools generate \nparsers from declarative de\u00adscriptions, but they require users to write both a lexer and a con\u00adtext free \ngrammar and to construct the in-memory representations by hand. In addition, they only work for ASCII \ndata, they do not easily accommodate data-dependent parsing, they have a limited error-handling model, \nand they do not provide auxiliary services. More closely related work includes ERLANG s bit syntax [4] \nand the PACKETTYPES [29] and DATASCRIPT languages [9], all of which allow declarative descriptions of \nphysical data. These projects were motivated by parsing protocols, TCP/IP packets, and JAVA jar-.les, \nrespectively. Like PADS, these languages have a type-directed approach to describing ad hoc data and \npermit the user to de.ne semantic constraints. In contrast to our work, these systems handle only binary \ndata and assume the data is error-free or halt parsing if an error is detected. Parsing non-binary data \nposes additional challenges because of the need to handle delimiter values and to express richer termination \nconditions on sequences of data. These systems also focus exclusively on the parsing/printing problem, \nwhereas we have leveraged the declarative nature of our data descriptions to build additional useful \ntools. The SDRR (Software Design for Reliability and Reuse) frame\u00adwork supports the de.nition and implementation \nof domain\u00adspeci.c languages [10]. To test the utility of the framework, the de\u00adsigners of SDRR used it \nin a case study to implement a data descrip\u00adtion language for describing messages. This language, called \nMSL, allows users to declaratively specify physical representations of ASCII data and transformations \nto a programmer-supplied logical format. The system infers reverse translations. The MSL language shares \ncore features with PADS, although MSL is more limited in its treatment of errors, is restricted to ASCII \ndata sources, and does not supply logical representations. Also, the tools generated from MSL are simply \nparsers and pretty printers. Having used SDRR to implement MSL, the designers set up a software engineering \nexperiment to measure the utility of their approach. In the experi\u00adment, four domain experts not af.liated \nwith the SDRR team each used either MSL or a more direct coding approach using ADA tem\u00adplates to handle \nvarious test formats. With statistically signi.cant con.dence levels exceeding 99%, the domain-speci.c \nlanguage approach produced higher productivity and fewer errors [24]. Al\u00adthough this comparison is for \na different data description language and a different host language, it suggests that the PADS approach \nmay be faster and more reliable than directly coding in C or PERL. Recently, a standardization effort \nhas been started whose stated goals are quite similar to those of the PADS project [3]. The descrip\u00adtion \nlanguage seems to be XML based, but at the moment, more details are not available. 9. Future work PADS \nalready de.nes a rich collection of tools for ad hoc data processing. However, there are a number of \ndirections for future research and possibilities for extension. Language expressiveness. We intend to \nadd bit-.eld and over\u00adlay constructs to PADS to support binary data sources better, in a fashion similar \nto that already supported in the DATASCRIPT and PACKETTYPES languages. We also plan to generalize the \nswitched union construct to permit arbitrary lookahead to better support pars\u00ading for complex ASCII formats \nsuch the HTTP packet speci.\u00adcation [6]. Further, we need to design a mechanism for specify\u00ading character \nencodings so that we may support Unicode [8] data sources. Generated artifacts. For research purposes, \nit would be very useful to be able to generate random data that conforms to a given speci.cation, or \ndeviates from it in speci.ed ways, particularly when the real data is proprietary or classi.ed. Given \na PADS speci.\u00adcation and a characterization of the desired distribution, it should be possible to generate \nsuch data. We also plan to augment the statisti\u00adcal pro.ling library with functions that use randomized \nand approx\u00adimate techniques to create small summaries such as histograms [20, 23], wavelet summaries \n[20], or quantile summaries[21]. Another useful tool we would like to generate from PADS descriptions \nis a graphical binary data editor. Semantics. We are in the process of developing a formal se\u00admantics \nfor the PADS language so that we may have a declarative speci.cation of what a PADS speci.cation means. \nApplication-speci.c customization. Ideally, PADS speci.ca\u00adtions describe everything about a given data \nsource, but nothing about how the data is to be used. This division allows a single de\u00adscription of a \ngiven source to be used for multiple applications. However, different applications have different performance, \nveri.\u00adcation, and error-handling needs. Currently, PADS allows users to customize the behavior of library \nfunctions at run-time by supply\u00ading appropriate masks and setting various error handlers. However, this \nleaves a run-time overhead. We would like to design a mech\u00adanism whereby users can specify application-speci.c \ninformation statically. The PADS system would then use this information to gen\u00aderate an application-speci.c \ninstance of the library. Conceptually, this would amount to partially evaluating the current PADS library \nby specifying mask arguments at binding time. Language bindings. Nothing about the PADS language is spe\u00adci.c \nto C. It would be very interesting to develop a binding for PADS in a higher-order functional language \nbecause the pattern\u00admatching constructs of such languages are extremely adept at ex\u00adpressing transformations, \nthe natural next step after parsing data. 10. Conclusions PADS is a declarative data description language \nthat allows its users to describe ad hoc data sources as they are, capturing layout information and semantic \nconstraints. The language is expressive enough to describe almost all of the ASCII, Cobol, and binary \ndata formats we have seen in practice at AT&#38;T, while being concise enough to serve as living documentation \nfor those data sources. The advantages of a declarative language for describing data are signi.cant. \nFirst, the user is spared from having to write the parser in the .rst place, which is an inherently tedious \nprocess. Second, because the parser is machine generated, it can check all the error conditions necessary \nto guard against corrupting down\u00adstream data without cluttering user code. Third, because of its con\u00adciseness, \nthe PADS description can serve as documentation for a data source. Given that the parser is generated \nfrom the descrip\u00adtion, there is strong incentive to maintain the description and hence the documentation \nas the data evolves. Finally, because we have a declarative speci.cation, we can generate not just a \nparser, but also a validator, a printer, a statistical pro.ler, various formatting tools, query support, \netc. In other words, we can leverage the declarative nature of the speci.cation to build a large number \nof useful tools. PADS has already been quite useful at AT&#38;T, and as the col\u00adlection of generated \ntools grows, it will only become more so. We look forward to developing a larger user base to get more \nfeedback to further improve the system. 11. Acknowledgments We would like to thank Mary Fern\u00b4er eon for \nandez and J\u00b4ome Sim\u00b4developing the Galax data API and our summer students Ricardo Medel and Yitzhak Mandelbaum \nfor their work on implementing the XML-related portions of the PADS system. Mary Fern\u00b4 andez, Yitzhak \nMandelbaum, David Walker, Rick Schlichting, and John Launchbury made many helpful comments on an earlier \ndraft.  References [1] Abstract syntax description language. http://sourceforge. net/projects/asdl. \n[2] Cisco net.ow. http://www.cisco.com/warp/public/ 732/Tech/nmp/netflow/index.shtml. [3] DFDL project. \nhttp://forge.gridforum.org/projects/ dfdl-wg. [4] Erlang bit syntax. http://www.erlang.se/euc/99/ binaries.ps. \n [5] Galax user manual. http://www.galaxquery.org/doc. html#manual. [6] Hypertext transfer protocol \n HTTP/1.1. http://www.w3.org/ Protocols/rfc2616/rfc2616.html. [7] PADS user manual. http://www.padsproj.org/doc.html# \nmanual. [8] Unicode home page. http://www.unicode.org/. [9] G. Back. DataScript -A speci.cation and scripting \nlanguage for binary data. In Proceedings of Generative Programming and Component Engineering, volume \n2487, pages 66 77. LNCS, 2002. [10] J. Bell, F. Bellegarde, J. Hook, R. B. Kieburtz, A. Kotov, J. Lewis, \nL. McKinney, D. P. Oliva, T. Sheard, L. Tong, L. Walton, and T. Zhou. Software design for reliability \nand reuse: A proof-of-concept demonstration. In TRI-Ada 94 proceedings, pages 396 404, 1994. [11] S. \nBoag, D. Chamberlin, M. F. Fern\u00b4andez, D. Florescu, J. Robie, and J. Sim\u00b4eon. XQuery 1.0 An XML Query \nLanguage, W3C Working Draft, Aug 2004. http://www.w3.org/TR/xquery. [12] S. Chandra, N. Heintze, D. MacQueen, \nD. Oliva, and M. Siff. C\u00adfrontend library for SML/NJ. See cm.bell-labs.com/cm/cs/ what/smlnj., 1999. \n[13] C. Cortes, K. Fisher, D. Pregibon, A. Rogers, and F. Smith. Hancock: A language for analyzing transactional \ndata streams. ACM Trans. Program. Lang. Syst., 26(2):301 338, 2004. [14] C. Cortes and D. Pregibon. Giga \nmining. In KDD, 1998. [15] C. Cortes and D. Pregibon. Information mining platform: An infrastructure \nfor KDD rapid deployment. In KDD, 1999. [16] C. Cranor, Y. Gao, T. Johnson, V. Shkapenyuk, and O. Spatscheck. \nGigascope: High performance network monitoring with an SQL interface. In SIGMOD. ACM, 2002. [17] O. Dubuisson. \nASN.1: Communication between heterogeneous systems. Morgan Kaufmann, 2001. [18] M. F. Fern\u00b4andez, J. \nSim\u00b4eon, B. Choi, A. Marian, and G. Sur. Implementing XQuery 1.0: The Galax experience. In VLDB, pages \n1077 1080. ACM, 2003. [19] G. Fowler, D. Korn, S. North, and P. Vo. The AT&#38;T AST opensource software \ncollection. In Proceedings of the FREENIX Track 2000 Usenix Annual Technical Conference, pages 187 195, \n2000. [20] A. C. Gilbert, S. Guha, P. Indyk, Y. Kotidis, S. Muthukrishnan, and M. Strauss. Fast, small-space \nalgorithms for approximate histogram maintenance. In STOC, pages 389 398, 2002. [21] A. C. Gilbert, Y. \nKotidis, S. Muthukrishnan, and M. Strauss. How to summarize the universe: Dynamic maintenance of quantiles. \nIn VLDB, pages 454 465, 2002. [22] R. Greer. Daytona and the fourth-generation language Cymbal. In A. \nDelis, C. Faloutsos, and S. Ghandeharizadeh, editors, SIGMOD 1999, Proceedings ACM SIGMOD International \nConference on Management of Data, June 1-3, 1999, Philadephia, Pennsylvania, USA. ACM Press, 1999. Also \navailable at www.research.att. com/projects/daytona. [23] S. Guha, P. Indyk, S. Muthukrishnan, and M. \nStrauss. Histogramming data streams with fast per-item processing. In ICALP, pages 681 692, 2002. [24] \nR. Kieburtz, L. McKinney, J. Bell, J. Hook, A. Kotov, J. Lewis, D. Oliva, T. Sheard, I. Smith, and L.Walton. \nA software engineering experiment in software component generation. In Proceedings of the 18th International \nConference on Software Engineering, 1996. [25] D. G. Korn and K.-P. Vo. SFIO: Safe/fast string/.le IO. \nIn Proc. of the Summer 91 Usenix Conference, pages 235 256. USENIX, 1991. [26] B. Krishnamurthy and J. \nRexford. Web Protocols and Practice. Addison Wesley, 2001. [27] B. Krishnamurthy and J. Wang. On network-aware \nclustering of web clients. In Proceedings of SIGCOMM 2000. ACM, 2000. [28] B. Krishnamurthy and C. Wills. \nImproving web experience by client characterization driven server adaptation. In Proceedings of WWW 2002. \nACM, 2002. [29] P. McCann and S. Chandra. PacketTypes: Abstract speci.cation of network protocol messages. \nIn ACM Conference of Special Interest Group on Data Communications (SIGCOMM), pages 321 333, August 1998. \n \n\t\t\t", "proc_id": "1065010", "abstract": "PADS is a declarative data description language that allows data analysts to describe both the physical layout of ad hoc data sources and semantic properties of that data. From such descriptions, the PADS compiler generates libraries and tools for manipulating the data, including parsing routines, statistical profiling tools, translation programs to produce well-behaved formats such as Xml or those required for loading relational databases, and tools for running XQueries over raw PADS data sources. The descriptions are concise enough to serve as \"living\" documentation while flexible enough to describe most of the ASCII, binary, and Cobol formats that we have seen in practice. The generated parsing library provides for robust, application-specific error handling.", "authors": [{"name": "Kathleen Fisher", "author_profile_id": "81331492634", "affiliation": "AT&T Labs Research, Florham Park, NJ", "person_id": "PP43124113", "email_address": "", "orcid_id": ""}, {"name": "Robert Gruber", "author_profile_id": "81100008776", "affiliation": "Google, Mountain View, CA", "person_id": "PP43124487", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065046", "year": "2005", "article_id": "1065046", "conference": "PLDI", "title": "PADS: a domain-specific language for processing ad hoc data", "url": "http://dl.acm.org/citation.cfm?id=1065046"}