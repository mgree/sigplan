{"article_publication_date": "06-12-2005", "fulltext": "\n Pin: Building Customized Program Analysis Tools with Dynamic Instrumentation Chi-Keung Luk Robert Cohn \nRobert Muth Harish Patil Artur Klauser Geoff Lowney Steven Wallace Vijay Janapa Reddi Kim Hazelwood \nIntel Corporation University of Colorado Website: http://rogue.colorado.edu/Pin, Email: pin.project@intel.com \nAbstract Robust and powerful software instrumentation tools are essential for program analysis tasks \nsuch as pro.ling, performance evalu\u00adation, and bug detection. To meet this need, we have developed a \nnew instrumentation system called Pin. Our goals are to pro\u00advide easy-to-use, portable, transparent, \nand ef.cient instrumenta\u00adtion. Instrumentation tools (called Pintools) are written in C/C++ using Pin \ns rich API. Pin follows the model of ATOM, allowing the tool writer to analyze an application at the \ninstruction level with\u00adout the need for detailed knowledge of the underlying instruction set. The API \nis designed to be architecture independent whenever possible, making Pintools source compatible across \ndifferent archi\u00adtectures. However, a Pintool can access architecture-speci.c details when necessary. \nInstrumentation with Pin is mostly transparent as the application and Pintool observe the application \ns original, unin\u00adstrumented behavior. Pin uses dynamic compilation to instrument executables while they \nare running. For ef.ciency, Pin uses sev\u00aderal techniques, including inlining, register re-allocation, \nliveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach \ndelivers signi.cantly better instru\u00admentation performance than similar tools. For example, Pin is 3.3x \nfaster than Valgrind and 2x faster than DynamoRIO for basic-block counting. To illustrate Pin s versatility, \nwe describe two Pintools in daily use to analyze production software. Pin is publicly avail\u00adable for \nLinux platforms on four architectures: IA32 (32-bit x86), EM64T (64-bit x86), Itanium R ., and ARM. In \nthe ten months since Pin 2 was released in July 2004, there have been over 3000 down\u00adloads from its website. \n Categories and Subject Descriptors D.2.5 [Software Engineer\u00ading]: Testing and Debugging-code inspections \nand walk-throughs, debugging aids, tracing; D.3.4 [Programming Languages]: Processors\u00adcompilers, incremental \ncompilers General Terms Languages, Performance, Experimentation Keywords Instrumentation, program analysis \ntools, dynamic com\u00adpilation Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page. \nTo copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c \npermission and/or a fee. PLDI 05 June 12 15, 2005, Chicago, Illinois, USA. Copyright 2005 ACM 1-59593-056-6/05/0006...$5.00. \n1. Introduction As software complexity increases, instrumentation a technique for inserting extra code \ninto an application to observe its behavior is becoming more important. Instrumentation can be performed \nat various stages: in the source code, at compile time, post link time, or at run time. Pin is a software \nsystem that performs run-time binary instrumentation of Linux applications. The goal of Pin is to provide \nan instrumentation platform for building a wide variety of program analysis tools for multiple archi\u00adtectures. \nAs a result, the design emphasizes ease-of-use, portabil\u00adity, transparency, ef.ciency, and robustness. \nThis paper describes the design of Pin and shows how it provides these features. Pin s instrumentation \nis easy to use. Its user model is similar to the popular ATOM [30] API, which allows a tool to insert \ncalls to instrumentation at arbitrary locations in the executable. Users do not need to manually inline \ninstructions or save and restore state. Pin provides a rich API that abstracts away the underlying instruction \nset idiosyncrasies, making it possible to write portable instrumentation tools. The Pin distribution \nincludes many sample architecture-independent Pintools including pro.lers, cache simu\u00adlators, trace analyzers, \nand memory bug checkers. The API also allows access to architecture-speci.c information. Pin provides \nef.cient instrumentation by using a just-in-time (JIT) compiler to insert and optimize code. In addition \nto some standard techniques for dynamic instrumentation systems includ\u00ading code caching and trace linking, \nPin implements register re\u00adallocation, inlining, liveness analysis, and instruction scheduling to optimize \njitted code. This fully automated approach distinguishes Pin from most other instrumentation tools which \nrequire the user s assistance to boost performance. For example, Valgrind [22] re\u00adlies on the tool writer \nto insert special operations in their in\u00adtermediate representation in order to perform inlining; similarly \nDynamoRIO [6] requires the tool writer to manually inline and save/restore application registers. Another \nfeature that makes Pin ef.cient is process attaching and detaching. Like a debugger, Pin can attach to \na process, in\u00adstrument it, collect pro.les, and eventually detach. The application only incurs instrumentation \noverhead during the period that Pin is attached. The ability to attach and detach is a necessity for \nthe in\u00adstrumentation of large, long-running applications. Pin s JIT-based instrumentation defers code \ndiscovery until run time, allowing Pin to be more robust than systems that use static instrumentation \nor code patching. Pin can seamlessly handle mixed code and data, variable-length instructions, statically \nunknown in\u00addirect jump targets, dynamically loaded libraries, and dynamically generated code. Pin preserves \nthe original application behavior by providing in\u00adstrumentation transparency. The application observes \nthe same ad\u00addresses (both instruction and data) and same values (both register and memory) as it would \nin an uninstrumented execution. Trans\u00adparency makes the information collected by instrumentation more \nrelevant and is also necessary for correctness. For example, some applications unintentionally access \ndata beyond the top of stack, so Pin and the instrumentation do not modify the application stack. Pin \ns .rst generation, Pin 0, supports Itanium R .. The recently\u00adreleased second generation, Pin 2, extends \nthe support to four1 architectures: IA32 (32-bit x86) [14], EM64T (64-bit x86) [15], Itanium R[13], and \nARM [16]. Pin 2 for Itanium R ..is still under development. Pin has been gaining popularity both inside \nand outside of Intel, with more than 3000 downloads since Pin 2 was .rst released in July 2004. This \npaper presents an in-depth description of Pin, and is organized as follows. We .rst give an overview \nof Pin s instrumentation capability in Section 2. We follow by discussing design and implementation issues \nin Section 3. We then evaluate in Section 4 the performance of Pin s instrumentation and compare it against \nother tools. In Section 5, we discuss two sample Pintools used in practice. Finally, we relate Pin to \nother work in Section 6 and conclude in Section 7. 2. Instrumentation with Pin The Pin API makes it \npossible to observe all the architectural state of a process, such as the contents of registers, memory, \nand control .ow. It uses a model similar to ATOM [30], where the user adds procedures (as known as analysis \nroutines in ATOM s notion) to the application process, and writes instrumentation routines to determine \nwhere to place calls to analysis routines. The arguments to analysis routines can be architectural state \nor constants. Pin also provides a limited ability to alter the program behavior by allowing an analysis \nroutine to overwrite application registers and application memory. Instrumentation is performed by a \njust-in-time (JIT) compiler. The input to this compiler is not bytecode, however, but a native ex\u00adecutable. \nPin intercepts the execution of the .rst instruction of the executable and generates ( compiles ) new \ncode for the straight\u00adline code sequence starting at this instruction. It then transfers con\u00adtrol to \nthe generated sequence. The generated code sequence is al\u00admost identical to the original one, but Pin \nensures that it regains control when a branch exits the sequence. After regaining control, Pin generates \nmore code for the branch target and continues execu\u00adtion. Every time the JIT fetches some code, the Pintool \nhas the op\u00adportunity to instrument it before it is translated for execution. The translated code and \nits instrumentation is saved in a code cache for future execution of the same sequence of instructions \nto improve performance. In Figure 1, we list the code that a user would write to create a Pintool that \nprints a trace of address and size for ev\u00adery memory write in a program. The main procedure initializes \nPin, registers the procedure called Instruction, and tells Pin to start execution of the program. The \nJIT calls Instruction when inserting new instructions into the code cache, passing it a handle to the \ndecoded instruction. If the instruction writes memory, the Pintool inserts a call to RecordMemWrite before \nthe instruction (speci.ed by the argument IPOINT BEFORE to INS InsertPredicatedCall), passing the instruction \npointer (speci.ed by IARG INST PTR), effective address for the mem\u00adory operation (speci.ed by IARG MEMORYWRITE \nEA), and number of bytes written (speci.ed by IARG MEMORYWRITE SIZE). Using 1 Although EM64T is a 64-bit \nextension of IA32, we classify it as a separate architecture because of its many new features such as \n64-bit addressing, a .at address space, twice the number of registers, and new software conven\u00adtions \n[15].     FILE * trace; // Print a memory write record VOID RecordMemWrite(VOID * ip, VOID * addr, \nUINT32 size) { fprintf(trace,\"%p: W %p %d\\n\", ip, addr, size); } // Called for every instruction VOID \nInstruction(INS ins, VOID *v) { // instruments writes using a predicated call, // i.e. the call happens \niff the store is // actually executed if (INS_IsMemoryWrite(ins)) INS_InsertPredicatedCall( ins, IPOINT_BEFORE, \nAFUNPTR(RecordMemWrite), IARG_INST_PTR, IARG_MEMORYWRITE_EA, IARG_MEMORYWRITE_SIZE, IARG_END); } int \nmain(int argc, char *argv[]) { PIN_Init(argc, argv); trace = fopen(\"atrace.out\", \"w\"); INS_AddInstrumentFunction(Instruction, \n0); PIN_StartProgram(); // Never returns return 0; } Figure 1. A Pintool for tracing memory writes. \nINS InsertPredicatedCall ensures that RecordMemWrite is invoked only if the memory instruction is predicated \ntrue. Note that the same source code works on all architectures. The user does not need to know about \nthe bundling of instructions on Itanium, the various addressing modes on each architecture, the different \nforms of predication supported by Itanium and ARM, x86 string instructions that can write a variable-size \nmemory area, or x86 instructions like push that can implicitly write memory. Pin provides a comprehensive \nAPI for inspection and instru\u00admentation. In this particular example, instrumentation is done one instruction \nat a time. It is also possible to inspect whole traces, procedures, and images when doing instrumentation. \nThe Pin user manual [12] provides a complete description of the API. Pin s call-based model is simpler \nthan other tools where the user can insert instrumentation by adding and deleting statements in an intermediate \nlanguage. However, it is equally powerful in its ability to observe architectural state and it frees \nthe user from the need to understand the idiosyncrasies of an instruction set or learn an in\u00adtermediate \nlanguage. The inserted code may overwrite scratch reg\u00adisters or condition codes; Pin ef.ciently saves \nand restores state around calls so these side effects do not alter the original applica\u00adtion behavior. \nThe Pin model makes it possible to write ef.cient and architecture-independent instrumentation tools, \nregardless of whether the instruction set is RISC, CISC, or VLIW. A combi\u00adnation of inlining, register \nre-allocation, and other optimizations makes Pin s procedure call-based model as ef.cient as lower-level \ninstrumentation models. 3. Design and Implementation In this section, we begin with a system overview \nof Pin. We then discuss how Pin initially gains control of the application, followed by a detailed description \nof how Pin dynamically compiles the application. Finally, we discuss the organization of Pin source code. \n3.1 System Overview Figure 2 illustrates Pin s software architecture. At the highest level, Pin consists \nof a virtual machine (VM), a code cache, and an instru\u00ad Address Space Figure 2. Pin s software architecture \nmentation API invoked by Pintools. The VM consists of a just-in\u00adtime compiler (JIT), an emulator, and \na dispatcher. After Pin gains control of the application, the VM coordinates its components to execute \nthe application. The JIT compiles and instruments applica\u00adtion code, which is then launched by the dispatcher. \nThe compiled code is stored in the code cache. Entering/leaving the VM from/to the code cache involves \nsaving and restoring the application register state. The emulator interprets instructions that cannot \nbe executed directly. It is used for system calls which require special handling from the VM. Since Pin \nsits above the operating system, it can only capture user-level code. As Figure 2 shows, there are three \nbinary programs present when an instrumented program is running: the application, Pin, and the Pintool. \nPin is the engine that jits and instruments the applica\u00adtion. The Pintool contains the instrumentation \nand analysis routines and is linked with a library that allows it to communicate with Pin. While they \nshare the same address space, they do not share any li\u00adbraries and so there are typically three copies \nof glibc. By making all of the libraries private, we avoid unwanted interaction between Pin, the Pintool, \nand the application. One example of a problematic interaction is when the application executes a glibc \nfunction that is not reentrant. If the application starts executing the function and then tries to execute \nsome code that triggers further compilation, it will enter the JIT. If the JIT executes the same glibc \nfunction, it will enter the same procedure a second time while the application is still executing it, \ncausing an error. Since we have separate copies of glibc for each component, Pin and the application \ndo not share any data and cannot have a re-entrancy problem. The same prob\u00adlem can occur when we jit \nthe analysis code in the Pintool that calls glibc (jitting the analysis routine allows us to greatly \nreduce the overhead of simple instrumentation on Itanium). 3.2 Injecting Pin The injector loads Pin \ninto the address space of an application. In\u00adjection uses the Unix Ptrace API to obtain control of an \napplication and capture the processor context. It loads the Pin binary into the application address space \nand starts it running. After initializing itself, Pin loads the Pintool into the address space and starts \nit run\u00adning. The Pintool initializes itself and then requests that Pin start the application. Pin creates \nthe initial context and starts jitting the application at the entry point (or at the current PC in the \ncase of attach). Using Ptrace as the mechanism for injection allows us to attach to an already running \nprocess in the same way as a debug\u00adger. It is also possible to detach from an instrumented process and \ncontinue executing the original, uninstrumented code. Other tools like DynamoRIO [6] rely on the LD \nPRELOAD en\u00advironment variable to force the dynamic loader to load a shared li\u00adbrary in the address space. \nPin s method has three advantages. First, LD PRELOAD does not work with statically-linked binaries, which \nmany of our users require. Second, loading an extra shared library will shift all of the application \nshared libraries and some dynami\u00adcally allocated memory to a higher address when compared to an uninstrumented \nexecution. We attempt to preserve the original be\u00adhavior as much as possible. Third, the instrumentation \ntool cannot gain control of the application until after the shared-library loader has partially executed, \nwhile our method is able to instrument the very .rst instruction in the program. This capability actually \nex\u00adposed a bug in the Linux shared-library loader, resulting from a reference to uninitialized data on \nthe stack. 3.3 The JIT Compiler 3.3.1 Basics Pin compiles from one ISA directly into the same ISA (e.g., \nIA32 to IA32, ARM to ARM) without going through an intermediate format, and the compiled code is stored \nin a software-based code cache. Only code residing in the code cache is executed the origi\u00adnal code is \nnever executed. An application is compiled one trace at a time. A trace is a straight-line sequence of \ninstructions which ter\u00adminates at one of the conditions: (i) an unconditional control trans\u00adfer (branch, \ncall, or return), (ii) a pre-de.ned number of conditional control transfers, or (iii) a pre-de.ned number \nof instructions have been fetched in the trace. In addition to the last exit, a trace may have multiple \nside-exits (the conditional control transfers). Each exit initially branches to a stub, which re-directs \nthe control to the VM. The VM determines the target address (which is statically un\u00adknown for indirect \ncontrol transfers), generates a new trace for the target if it has not been generated before, and resumes \nthe execution at the target trace. In the rest of this section, we discuss the following features of \nour JIT: trace linking, register re-reallocation, and instrumentation optimization. Our current performance \neffort is focusing on IA32, EM64T, and Itanium, which have all these features implemented. While the \nARM version of Pin is fully functional, some of the optimizations are not yet implemented. 3.3.2 Trace \nLinking To improve performance, Pin attempts to branch directly from a trace exit to the target trace, \nbypassing the stub and VM. We call this process trace linking. Linking a direct control transfer is straightforward \nas it has a unique target. We simply patch the branch at the end of one trace to jump to the target trace. \nHowever, an indirect control transfer (a jump, call, or return) has multiple possible targets and therefore \nneeds some sort of target-prediction mechanism. Figure 3(a) illustrates our indirect linking approach \nas imple\u00admented on the x86 architecture. Pin translates the indirect jump into a move and a direct jump. \nThe move puts the indirect target address into register %edx (this register as well as the %ecx and %esi \nshown in Figure 3(a) are obtained via register re-allocation, as we will discuss in Section 3.3.3). The \ndirect jump goes to the .rst predicted target address 0x40001000 (which is mapped to 0x70001000 in the \ncode cache for this example). We compare %edx against 0x40001000 using the lea/jecxz idiom used in Dy\u00adnamoRIO \n[6], which avoids modifying the conditional .ags reg\u00adister eflags. If the prediction is correct (i.e. \n%ecx=0), we will branch to match1 to execute the remaining code of the predicted target. If the prediction \nis wrong, we will try another predicted tar\u00adget 0x40002000 (mapped to 0x70002000 in the code cache). \nIf the target is not found on the chain, we will branch to LookupHtab 1, which searches for the target \nin a hash table (whose base address is (a) Chaining of predicted indirect targets 0x40000000 0x70001000 \n lea -0x40001000(%edx), %ecx jecxz $match1 jmp $0x70002000  0x70000000 0x70002000 match2: LookupHTab_1 \nmov %edx, %esi and $0x3ff, %esi cmp 0x30898200(, %esi,8), %edx jnz $VMEntry # miss jmp 0x30898204(, %esi,8) \n#hit (b) Using cloning to help predict return targets call F() A: B: F(): ret ret translated with cloning \nA : F (): A : F_A (): F_B (): B : B : lea B(%edx), %ecx jecxz $match2 jmp $LookupHtab_1 Figure 3. Compiling \nindirect jumps and returns 0x30898200 in this example). If the search succeeds, we will jump to the translated \naddress corresponding to the target. If the search fails, we will transfer to the VM for indirect target \nresolution. While our indirect linking mechanism is similar to the approach taken in DynamoRIO [6], there \nare three important differences. First, in DynamoRIO, the entire chain is generated at one time and embedded \nat the translation of the indirect jump. Therefore no new predicted target can be added onto the chain \nafter it is generated. In contrast, our approach incrementally builds the chain while the program is \nrunning and thus we can insert newly seen targets onto the chain in any order (e.g., Pin can put a new \ntarget either at the front or the end of the chain). These new targets can be found in the chain the \nnext time that they occur, without searching the hash table. The second difference is that DynamoRIO \nuses a global hash table for all indirect jumps whereas Pin uses a local hash table for each individual \nindirect jump. A study by Kim and Smith [17] shows that the local hash table approach typically offers \nhigher performance. The third difference is that we apply function cloning [10] to accelerate the most \ncommon form of indirect control transfers: returns. If a function is called from multiple sites, we clone \nmultiple copies of the function, one for each call site. Consequently, a return in each clone will have \nonly one predicted target on the chain in most cases, as illustrated by the example in Figure 3(b). To \nimplement cloning, we associate a call stack with each trace (more precisely to the static context of \neach trace, which we will discuss in Section 3.3.3). Each call stack remembers the last four call sites \nand is compactly represented by hashing the call-site addresses into a single 64-bit integer. 3.3.3 \nRegister Re-allocation During jitting, we frequently need extra registers. For example, the code for \nresolving indirect branches in Figure 3(a) needs three free registers. When instrumentation inserts a \ncall into an application, the JIT must ensure that the call does not overwrite any scratch reg\u00adisters \nthat may be in use by the application. Rather than obtaining extra registers in an ad-hoc way, Pin re-allocates \nregisters used in both the application and the Pintool, using linear-scan register allo\u00adcation [24]. \nPin s allocator is unique in that it does interprocedural allocation, but must compile one trace at a \ntime while incremen\u00adtally discovering the .ow graph during execution. In contrast, static compilers can \ncompile one .le at a time and bytecode JITs [5, 8] can compile a whole method at one time. We describe \ntwo issues that our trace-based register re-allocation scheme must address: register liveness analysis \nand reconciliation of register bindings. Register Liveness Analysis Precise liveness information of registers \nat trace exits makes register allocation more effective since dead registers can be reused by Pin without \nintroducing spills. Without a complete .ow graph, we must incrementally compute liveness. After a trace \nat address A is compiled, we record the liveness at the beginning of the trace in a hash table using \naddress A as the key. If a trace exit has a statically-known target, we attempt to retrieve the liveness \ninformation from the hash table so we can compute more precise liveness for the current trace. This simple \nmethod introduces negligible space and time overhead, yet is effective in reducing register spills introduced \nby Pin s register allocation. Reconciliation of Register Bindings Trace linking (see Sec\u00adtion 3.3.2) \ntries to make traces branch directly to each other. When registers are reallocated, the JIT must ensure \nthan the register bind\u00ading at the trace exit of the source trace matches the bindings of the entrance \nof the destination trace. A straightforward method is to re\u00adquire a standard binding of registers between \ntraces. For example Valgrind [22] requires that all virtual register values be .ushed to memory at the \nend of a basic block. This approach is simple but inef.cient. Figure 4(b) shows how Valgrind would re-allocate \nreg\u00adisters for the original code shown in Figure 4(a). Here, we assume that virtual %ebx is bound to \nphysical %esi in Trace 1 but to phys\u00adical %edi in Trace 2. Virtual %eax and %ebx are saved at Trace 1 \ns exit because they have been modi.ed in the trace, and they are reloaded before their uses in Trace \n2. EAX and EBX are the mem\u00adory locations allocated by the JIT for holding the current values of virtual \n%eax and %ebx, respectively. In contrast, Pin keeps a virtual register in the same physical register \nacross traces whenever possible. At a trace exit e,ifthe target t has not been compiled before, our JIT \nwill compile a new trace for t using the virtual-to-physical register binding at e, say Be. Therefore, \ne can branch directly to t. Figure 4(c) shows how Pin would re-allocate registers for the same original \ncode, assuming that target t has not been compiled before. Nevertheless, if target t has been previously \ncompiled with a register binding Bt Be, = then our JIT will generate compensation code [19] to reconcile \nthe register binding from Be to Bt instead of compiling a new trace for Be. Figure 4(d) shows how Pin \nwould re-allocate registers for the same original code, this time assuming that the target t has been \npreviously compiled with a different binding in the virtual %ebx.In practice, these bindings show differences \nin only one or two virtual registers, and are therefore more ef.cient than Valgrind s method. A design \nchoice we encountered was where to put the compen\u00adsation code. It could be placed before the branch, \nwhich is exactly the situation shown in Figure 4(d) where the two mov instructions (a) Original code \n(b) Valgrind s approach Trace 1 mov $1, %eax mov $2, %esi cmp %ecx, %edx mov $1, %eax mov %eax, EAX mov \n$2, %ebx mov %esi, EBX cmp %ecx, %edx jz t jz t Trace 2 t : mov EAX, %eax add $1, %eax mov EBX, %edi \nt: add $1, %eax sub $2, %edi sub $2, %ebx (c) Pin (no reconciliation needed)  Trace 1 mov $1, %eax \nmov $2, %esi cmp %ecx, %edx jz t Compile Trace 2 using the bindings: Virtual Physical %eax %eax %ebx \n%esi %ecx %ecx %edx %edx Trace 2 t : add $1, %eax sub $2, %esi  (d) Pin (minimal reconciliation needed) \nTrace 1 (being compiled) No need to recompile Trace 2, simply reconcile the bindings of virtual %ebx \nin Traces 1 and 2 Figure 4. Reconciliation of Register Bindings that adjust the binding are placed before \nthe jz. Or the compensa\u00adtion code could be placed after the branch (in that case, the two mov instructions \nin Figure 4(d) would be placed in between the jz and t.). We chose the before approach because our experimental \ndata showed that it generally resulted in fewer unique bindings, there\u00adfore reducing the memory consumed \nby the compiler. Placing the compensation code before the branch is equivalent to targeting the register \nallocation to match the binding at the branch target. To support reconciliation of register bindings, \nwe need to re\u00admember the binding at a trace s entry. This is done by associat\u00ading each trace with a static \ncontext (sct), which contains a group of static properties that hold at the trace s entry. Register bind\u00ading \nis one such property; another example property is the call stack of the trace, which is used for function \ncloning (see Sec\u00adtion 3.3.2). So, precisely speaking, a trace is de.ned as a pair < entryIaddr,entrySct \n>, where entryIaddr is the original instruction address of the trace s entry and entrySct is the static \ncontext of the trace. Before the JIT compiles a new trace, it will .rst search for a compatible trace \nin the code cache. Two traces are com\u00adpatible if they have the same entryIaddr and their entrySct s are \neither identical or different in only their register bindings (in that case we can reconcile from one \nregister binding to the other, as we have exempli.ed in Figure 4(d)). If a compatible trace is found, \nthe JIT will simply use it instead of generating a new trace. 3.3.4 Thread-local Register Spilling Pin \nreserves an area in memory for spilling virtual registers (e.g., EAX and EBX shown in Figure 4(b) are \ntwo locations in this spilling area). To support multithreading, this area has to be thread local. When \nPin starts an application thread, it allocates the spilling area for this thread and steals a physical \nregister (%ebx on x86, %r7 on Itanium) to be the spill pointer, which points to the base of this area. \nFrom that point on, any access to the spilling area can be made through the spill pointer. When we switch \nthreads, the spill pointer will be set to the spilling area of the new thread. In addition, we exploit \nan optimization opportunity coming from the absolute addressing mode available on the x86 architecture. \nPin starts an ap\u00adplication assuming that it is single threaded. Accesses to the spilling area are made \nthrough absolute addressing and therefore Pin does not need a physical register for the spill pointer. \nIf Pin later discov\u00aders that the application is in fact multithreaded, it will invalidate the code cache \nand recompile the application using the spill pointer to access the spilling area (Pin can detect multithreading \nbecause it intercepts all thread-create system calls). Since single-threaded ap\u00adplications are more common \nthan multithreaded ones, this hybrid approach works well in practice. 3.3.5 Optimizing Instrumentation \nPerformance As we will show in Section 4, most of the slowdown from instru\u00admentation is caused by executing \nthe instrumentation code, rather than the compilation time (which includes inserting the instrumen\u00adtation \ncode). Therefore, it is bene.cial to spend more compilation time in optimizing calls to analysis routines. \nOf course, the run\u00adtime overhead of executing analysis routines highly depends on their invocation frequency \nand their complexity. If analysis rou\u00adtines are complex, there is not much optimization that our JIT \ncan do. However, there are many Pintools whose frequently-executed analysis routines perform only simple \ntasks like counting and trac\u00ading. Our JIT optimizes those cases by inlining the analysis rou\u00adtines, which \nreduces execution overhead as follows. Without inlin\u00ading, we call a bridge routine that saves all caller-saved \nregisters, sets up analysis routine arguments, and .nally calls the analysis routine. Each analysis routine \nrequires two calls and two returns for each invocation. With inlining, we eliminate the bridge and thus \nsave those two calls and returns. Also, we no longer explicitly save caller-saved registers. Instead, \nwe rename the caller-saved registers in the inlined body of the analysis routine and allow the register \nal\u00adlocator to manage the spilling. Furthermore, inlining enables other optimizations like constant folding \nof analysis routine arguments. We perform an additional optimization for the x86 architecture. Most analysis \nroutines modify the conditional .ags register eflags (e.g., if an analysis routine increments a counter). \nHence, we must preserve the original eflags value as seen by the application. However, accessing the \neflags is fairly expensive because it must be done by pushing it onto the stack2. Moreover, we must switch \nto another stack before pushing/popping the eflags to avoid chang\u00ading the application stack. Pin avoids \nsaving/restoring eflags as much as possible by using liveness analysis on the eflags. The liveness analysis \ntracks the individual bits in the eflags written and read by each x86 instruction. We frequently discover \nthat the 2 On IA32, we can use lahf/sahf to access the eflags without involving the stack. However, we \ndecided not to use them since these two instructions are not implemented on current EM64T processors. \n Architecture Number of Number of Lines Source Files (including comments) Generic 87 (48%) 53595 (47%) \nx86 34 (19%) 22794 (20%) (IA32+EM64T) Itanium 34 (19%) 20474 (18%) ARM 27 (14%) 17933 (15%)  TOTAL \n182 (100%) 114796 (100%) Table 1. Distribution of Pin source among different architectures running Linux. \nOver 99% of code is written in C++ and the remain\u00ading is in assembly. eflags are dead at the point where \nan analysis routine call is in\u00adserted, and are able to eliminate saving and restoring of the eflags. \nFinally, to achieve even better performance, the Pintool writer can specify a hint (IPOINT ANYWHERE) \ntelling Pin that a call to an analysis routine can be inserted anywhere inside the scope of instrumentation \n(e.g., a basic block or a trace). Then Pin can exploit a number of optimization opportunities by scheduling \nthe call. For instance, Pin can insert the call immediately before an instruction that overwrites a register \n(or eflags) and thereby the analysis routine can use that register (or eflags) without .rst spilling \nit.  3.4 Organization of Pin Source Code Since Pin is a multi-platform system, source code sharing is \na key to minimizing the development effort. Our .rst step was to share the basic data structures and \nintermediate representations with Ispike [20], a static binary optimizer we previously developed. Then \nwe organized Pin source into generic, architecture dependent, or operating-system dependent modules. \nSome components like the code cache are purely generic, while other components like the register allocator \ncontain both generic and architecture-dependent parts. Table 1 shows the distribution of Pin source among \ndifferent architectures, in terms of number of source .les and lines. We combine IA32 and EM64T in Table \n1 since they are similar enough to share the same source .les. The x86 numbers do not include the decoder/encoder \nwhile the Itanium numbers do not include the instruction scheduler. The reason is that we borrow these \ntwo components from other Intel tools in library form and we do not have their sources. The data re.ects \nthat we have done a reasonable job in code sharing among architectures as about 50% of code is generic. \n  4. Experimental Evaluation In this section, we .rst report the performance of Pin without any instrumentation \non the four supported architectures. We then report the performance of Pin with a standard instrumentation \nbasic\u00adblock counting. Finally, we compare the performance of Pin with two other tools: DynamoRIO and \nValgrind, and show that Pin s instrumentation performance is superior across our benchmarks. Our experimental \nsetup is described in Table 2. For IA32, we use dynamically-linked SPECint binaries compiled with gcc \n-O3. We compiled eon with icc because the gcc -O3 version does not work, even without applying Pin. We \ncould not use the of.cial statically-linked, icc-generated binaries for all programs because DynamoRIO \ncannot execute them. We ran the SPEC2000 suite [11] using reference inputs on IA32, EM64T, and Itanium. \nOn ARM, we are only able to run the training inputs due to limited physical memory (128MB), even when \nexecuting uninstrumented binaries. Floating-point benchmarks are not used on ARM as it does not have \n.oating-point hardware. Hardware Linux Compiler Binary IA32 1.7GHz Xeon , 256KB L2 cache, 2GB Memory \n2.4.9 gcc 3.3.2, -O3 for SPECint (except in eon where we use icc) Shared icc 8.0 for SPECfp Static ARM \nItanium\u00ae EM64T 400 MHz XScale\u00ae 80200, 128 MB Memory 1.3GHz Itanium\u00ae2, 6MB L2 cache, 12GB Memory 3.4GHz \nXeon , 1MB L2 cache, 4GB Memory 2.4.18 2.4.18 2.4.21 Intel \u00ae compiler (icc 8.0), with interprocedural \n&#38; profile-guided optimizations gcc 3.4.1, -O2 Static Static Static Table 2. Experimental setup. \n 4.1 Pin Performance without Instrumentation Figure 5 shows the performance of applying Pin to the bench\u00admarks \non the four architectures, without any instrumentation. Since Pin 2/Itanium is still under development, \nwe instead use Pin 0 for Itanium experiments. The y-axis is the time normalized to the na\u00adtive run time \n(i.e. 100%). The slowdown of Pin 2 on IA32 and EM64T is similar. In both cases, the average run-time \noverhead is around 60% for integer and within 5% for .oating point. The higher overhead on the integer \nside is due to many more indirect branches and returns. The slowdown of Pin 0 on Itanium follows the \nsame trend but is generally larger than on IA32 and EM64T, especially for .oating-point benchmarks. This \nis probably because Itanium is an in-order architecture, so its performance depends more on the quality \nof the jitted code. In contrast, IA32 and EM64T are out\u00adof-order architectures that can tolerate the \noverhead introduced in the jitted code. Pin s performance on ARM is worse than the other three architectures \nbecause indirect linking (see Section 3.3.2) is not yet implemented and there are fewer computational \nresources (ILP and memory) available. One downside of dynamic compilation is that the compilation time \nis directly re.ected in the application s run time. To under\u00adstand the performance impact of dynamic \ncompilation, we divide the total run time into the components shown in Figures 5(a), (b), and (d) (Pin \n0 source code is not instrumented and hence does not have the breakdown). Code Cache denotes the time \nexecuting the jitted code stored in the code cache. Ideally, we would like this component to approach \n100%. We divide the JIT time into three categories: JIT-Decode, JIT-Regalloc, and JIT-Other. JIT-Decode \nis the time spent decoding and encoding instructions, which is a non\u00adtrivial task on the x86 architecture. \nJIT-Regalloc is the time spent in register re-allocation. JIT-Other denotes the remaining time spent \nin the JIT. The last component is VM, which includes all other time spent in the virtual machine, including \ninstruction emulation and resolving mispredicted indirect control transfers. As Figures 5 (a) and (b) \nshow, the JIT and VM components on IA32 and EM64T are mostly small except in gcc and perlbmk. These two \nbenchmarks have the largest instruction footprint in SPEC2000 and their execution times are relatively \nshort. Conse\u00adquently, there is insuf.cient code reuse for Pin to amortize its com\u00adpilation cost. In particular, \nPin pays a high cost in re-allocating reg\u00adisters compared to most other tools that do not re-allocate \nregisters. Nevertheless, the advantages provided by register re-allocation out\u00adweigh its compilation \noverhead (e.g., register re-allocation makes it easy to provide Pin and Pintools more virtual registers \nthan the number of physical registers supported by the hardware). In prac\u00adtice, the performance overhead \nis a serious concern only for long\u00adrunning applications. In that case, we would have suf.cient code reuse \nto amortize the cost of register re-allocation. Figure 5(d) shows a different trend for ARM, where the \nVM component is (a) Pin 2/IA32 Code Cache JIT-Decode  JIT-Regalloc JIT-Other VM Total 122 173  \nNormalized Execution Time (%) 400 350 300 250 200 150 100 50 0  (b) Pin 2/EM64T Code Cache JIT-Decode \n JIT-Regalloc JIT-Other VM Total 133 Normalized Execution Time (%)  400 350 300 250 200 150 100 50 \n0 (c) Pin 0/Itanium (d) Pin 2/ARM Code Cache JIT-Decode JIT-Regalloc JIT-Other 210260 120105125 357 \n125142126 Normalized Execution Time (%) 400 350 300 250 200 150 100 0  Normalized Execution Time (%) \n114 109128125 113135 99117100142104 132112115 600 200 0 Figure 5. Performance of Pin (without any instrumentation) \non four architectures. The y-axis is the time normalized to the native run time (i.e. 100%). INT-AriMean \nand FP-AriMean on the x-axis are the arithmetic means of the integer and .oating-point benchmarks, respectively. \nThe legends are explained in Section 4.1. large but all JIT components are small. This is because register \nre-largely depends on how well the JIT integrates it into the applica\u00adallocation and indirect linking \nare not yet implemented on ARM. tion. On the other hand, performance of a complex tool like de-As a result, \nall indirect control transfers are resolved by the VM. tailed cache simulation mostly depends on the \ntool s algorithm. In that case, our JIT has less of an impact on performance.  4.2 Pin Performance with \nInstrumentation Figure 6 shows the performance of basic-block counting using We now study the performance \nof Pin with basic-block counting, Pin on the IA32 architecture. Each benchmark is tested using four which \noutputs the execution count of every basic block in the ap-different optimization levels. Without any \noptimization, the over\u00adplication. We chose to measure this tool s performance because head is fairly \nlarge (as much as 20x slowdown in crafty). Adding basic-block counting is commonly used and can be extended \nto inlining helps signi.cantly; the average slowdown improves from many other tools such as Opcodemix, \nwhich we will discuss in 10.4x to 7.8x for integer and from 3.9x to 3.5x for .oating point. Section 5.1. \nAlso, this tool is simple enough that its performance The biggest performance boost comes from the eflags \nliveness Normalized Execution Time (%) 2000 1500 1000 500 0  Figure 6. Performance of Pin with basic-block \ncounting instrumentation on the IA32 architecture. analysis, reducing the average slowdown to 2.8x for \ninteger and (a) Without instrumentation 1.5x for .oating point. Scheduling of instrumentation code further \n reduces the slowdown to 2.5x for integer and 1.4x for .oating point. 1200 1188 Normalized Execution \nTime (%) Normalized Execution Time (%) 1000 800 600 400 200 0  4.3 Performance Comparison with Valgrind \nand DynamoRIO We now compare the performance of Pin against Valgrind and Dy\u00ad namoRIO. Valgrind is a popular \ninstrumentation tool on Linux and is the only binary-level JIT other than Pin that re-allocates regis\u00adters. \nDynamoRIO is generally regarded as the performance leader in binary-level dynamic optimization. We used \nthe latest release of each tool for this experiment: Valgrind 2.2.0 [22] and DynamoRIO 0.9.3 [6]. We \nran two sets of experiments: one without instrumenta\u00adtion and one with basic-block counting instrumentation. \nWe imple\u00admented basic-block counting by modifying a tool in the Valgrind package named lackey and a tool \nin the DynamoRIO package named countcalls. We show only the integer results in Figure 7 as integer codes \nare more problematic than .oating-point codes in (b) With basic-block counting  1583 terms of the \nslowdown caused by instrumentation. Figure 7(a) shows that without instrumentation both Pin and 1600 \n DynamoRIO signi.cantly outperform Valgrind. DynamoRIO is faster than Pin on gcc, perlbmk and vortex, \nmainly because Pin spends more jitting time in these three benchmarks (refer back to Figure 5(a) for \nthe breakdown) than DynamoRIO, which does not re-allocate registers. Pin is faster than DynamoRIO on \na few bench\u00ad marks such as crafty and gap possibly because of the advantages that Pin has in indirect \nlinking (i.e. incremental linking, cloning, and local hash tables). Overall, DynamoRIO is 12% faster \nthan Pin without instrumentation. Given that DynamoRIO was primar\u00ad 1400 1200 1000 800 600 400 200 ily \ndesigned for optimization, the fact that Pin can come this close 0 is quite acceptable. When we consider \nthe performance with instrumentation shown in Figure 7(b), Pin outperforms both DynamoRIO and Valgrind \nby a signi.cant margin: on average, Valgrind slows the applica\u00adtion down by 8.3 times, DynamoRIO by 5.1 \ntimes, and Pin by 2.5 times. Valgrind inserts a call before every basic block s entry but Figure 7. \nPerformance comparison among Valgrind, DynamoRIO, it does not automatically inline the call. For DynamoRIO, \nwe use and Pin. Eon is excluded because DynamoRIO does not work on its low-level API to update the counter \ninline. Nevertheless, Dy-the icc-generated binary of this benchmark. Omitting eon causes namoRIO still \nhas to save and restore the eflags explicitly around the two arithmetic means of Pin/IA32 slightly different \nthan the each counter update. In contrast, Pin automatically inlines the call ones shown in Figures 5(a) \nand 6. and performs liveness analysis to eliminate unnecessary eflags save/restore. This clearly demonstrates \na main advantage of Pin: it provides ef.cient instrumentation without shifting the burden to the Pintool \nwriter.   5. Two Sample PinTools To illustrate how Pin is used in practice, we discuss two Pintools \nthat have been used by various groups inside Intel. The .rst tool, Opcodemix, studies the frequency of \ndifferent instruction types in a program. It is used to compare codes generated by different compil\u00aders. \nThe second tool, PinPoints, automatically selects representa\u00adtive points in the execution of a program \nand is used to accelerate processor simulation. 5.1 Opcodemix Opcodemix, whose source code is included \nin the Pin 2 distribu\u00adtion [12], is a simple Pintool that can determine the dynamic mix of opcodes for \na particular execution of a program. The statistics can be broken down on a per basic-block, per routine, \nor per image basis. Conceptually this tool is implemented as a basic-block pro\u00ad.ler. We insert a counter \nat the beginning of each basic block in a trace. Upon program termination we walk through all the counters. \nFrom the associated basic-block s starting address, we can deter\u00admine the function it belongs to and \nthe instruction mix in that basic block. While the output of Opcodemix is ISA dependent (different ISAs \nhave different opcodes), the implementation is generic the same source code for Opcodemix is used on \nthe four architectures. Though simple, Opcodemix has been quite useful both for ar\u00adchitectural and compiler \ncomparison studies. As an example, the following analysis revealed a compiler performance problem. We \ncollected Opcodemix statistics for the SPEC2000 images produced by two compilers, which we refer to as \ncompilers A and B, for the EM64T architecture. For the benchmark crafty, we found that the image produced \nby compiler A executed 2% more dynamic in\u00adstructions than the image produced by compiler B. To understand \nthe cause of the extra instructions, we looked at the instruction dis\u00adtribution of frequently-executed \nroutines. The data for the routine PopCnt() is shown in Table 3, where opcodes with signi.cantly different \nfrequencies in the two compilers are marked with . . Examining the PopCnt() codes from the two compilers \nrevealed that the deltas in JE and JNZ were due to different code-layout deci\u00adsions, and the delta in \nMOVL was due to different register selections. The most surprising .nding was the extra PUSHQ and POPQ \ngener\u00adated by compiler A. Figure 8 shows the PopCnt() code generated by compiler A. After communicating \nwith compiler A s writers, we learned that the push and pop are used for stack alignment but are in fact \nunnecessary in this case. As a result, this performance prob\u00adlem is now .xed in the latest version of \ncompiler A. In addition to SPEC, we use Opcodemix to analyze the Oracle database performance. Typically, \nmore than 10 Oracle processes run on the system, but we want to ignore the database startup and only \nobserve a single process performing a transaction. We .rst run Oracle natively (i.e. without Pin) to \nstartup the database. Next we attach Pin to a single database server process and have it perform a transaction \nwhile collecting a pro.le. Pin s dynamic just-in-time instrumentation allows us to avoid instrumenting \nthe entire 60 MB Oracle binary, and the attach feature allows us to avoid instrumenting the database \nstartup and the other processes. 5.2 PinPoints The purpose of the PinPoints [23] toolkit is to automate \nthe oth\u00aderwise tedious process of .nding regions of programs to simulate, validating that the regions \nare representative, and generating traces for those regions. There are two major challenges in simulating \nlarge commercial programs. First, these programs have long run times, and detailed simulation of their \nentire execution is too time consuming to be practical. Second, these programs often have large resource \nrequirements, operating system and device-driver depen\u00addencies, and elaborate license-checking mechanisms, \nmaking it dif\u00ad.cult to execute them on simulators. We address the .rst chal- Instruction Type C o u n \nt Compiler A Compiler B Delta *total 712M 618M -94M XORL 94M 94M 0M TESTQ 94M 94M 0M RET 94M 94M 0M PUSHQ \n94M 0M -94M <-POPQ 94M 0M -94M <-JE 94M 0M -94M <-LEAQ 37M 37M 0M JNZ 37M 131M 94M <-ANDQ 37M 37M 0M \nADDL 37M 37M 0M MOVL 0M 94M 94M <- Table 3. Dynamic instruction distribution in PopCnt() of crafty benchmark. \n42f538 <PopCnt>: 42f538: push %rsi # unnecessary 42f539: xor %eax,%eax 42f53b: test %rdi,%rdi 42f53e: \nje 42f54c 42f540: add $0x1,%eax 42f543: lea 0xffffffffffffffff(%rdi),%rdx 42f547: and %rdx,%rdi 42f54a: \njne 42f540 42f54c: pop %rcx # unnecessary 42f54d: retq Figure 8. PopCnt() code generated by compiler \nA. lenge using SimPoint [28] a methodology that uses phase anal\u00adysis for .nding representative regions \nfor simulation. For the sec\u00adond challenge, we use Pin to collect SimPoint pro.les (which we call PinPoints) \nand instruction traces, eliminating the need to ex\u00adecute the program on a simulator. The ease of running \napplica\u00adtions with Pintools is a key advantage of the PinPoints toolkit. PinPoints has been used to collect \ninstruction traces for a wide variety of programs; Table 4 lists some of the Itanium applications (SPEC \nand commercial), including both single-threaded and multi\u00adthreaded applications. As the table shows, \nsome of the commercial applications are an order of magnitude larger and longer-running than SPEC, and \nfully simulating them would take years. Simulating only the selected PinPoints reduces the simulation \ntime from years to days. We also validate that the regions chosen represent whole\u00adprogram behavior (e.g., \nthe cycles-per-instruction predicted by Pin-Points is typically within 10% of the actual value [23]). \nBecause of its high prediction accuracy, fast simulation time, and ease-of-use, PinPoints is now used \nto predict performance of large applications on future Intel processors.  6. Related Work There is a \nlarge body of related work in the areas of instrumentation and dynamic compilation. To limit our scope \nof discussion, we con\u00adcentrate on binary instrumentation in this section. At the highest level, instrumentation \nconsists of static and dynamic approaches. Static binary instrumentation was pioneered by ATOM [30], \nfollowed by others such as EEL [18], Etch [25], and Morph [31]. Static instrumentation has many limitations \ncompared to dynamic instrumentation. The most serious one is that it is possible to mix code and data \nin an executable and a static tool may not have enough information to distinguish the two. Dynamic tools \ncan rely on execution to discover all the code at run time. Other dif.cult  Program Description Code \nDynamic Size Count (MB) (billions)   SPECINT SPEC CPU2000 integer 1.9 521 2000 suite [11] (avg.) SPECFP \nSPEC CPU2000 .oating 2.4 724 2000 -point suite [11] (avg.) SPECOMP SPEC benchmarks 8.4 4800 2001 for \nevaluating multithreaded OpenMP applications [26] Amber A suite of bio-molecular 6.2 3994 simulation \nfrom UCSF [1] Fluent Computational Fluid 19.6 25406 Dynamics code from Fluent Inc [2] LsDyna A general-purpose \ntransient 61.9 4932 dynamic .nite element analy\u00adsis program from Livermore Software Technology [3] RenderMan \nA photo-realistic rendering 8.5 797 application from Pixar [4] Table 4. Applications analyzed with PinPoints. \nColumn 3 shows the code section size of the application binary and shared libraries reported by the size \ncommand. Column 4 lists the dynamic in\u00adstruction count for the longest-running application input. problems \nfor static systems are indirect branches, shared libraries, and dynamically-generated code. There are \ntwo approaches to dynamic instrumentation: probe\u00adbased and jit-based. The probe-based approach works \nby dynam\u00adically replacing instructions in the original program with trampo\u00adlines that branch to the instrumentation \ncode. Example probe-based systems include Dyninst [7], Vulcan [29], and DTrace [9]. The drawbacks of \nprobe-based systems are that (i) instrumentation is not transparent because original instructions in \nmemory are over\u00adwritten by trampolines, (ii) on architectures where instruction sizes vary (i.e. x86), \nwe cannot replace an instruction by a trampoline that occupies more bytes than the instruction itself \nbecause it will overwrite the following instruction, and (iii) trampolines are im\u00adplemented by one or \nmore levels of branches, which can incur a signi.cant performance overhead. These drawbacks make .ne\u00adgrained \ninstrumentation challenging on probe-based systems. In contrast, the jit-based approach is more suitable \nfor .ne-grained in\u00adstrumentation as it works by dynamically compiling the binary and can insert instrumentation \ncode (or calls to it) anywhere in the bi\u00adnary. Examples include Valgrind [22], Strata [27], DynamoRIO \n[6], Diota [21], and Pin itself. Among these systems, Pin is unique in the way that it supports high-level, \neasy-to-use instrumentation, which at the same time is portable across four architectures and is ef.cient \ndue to optimizations applied by our JIT.  7. Conclusions We have presented Pin, a system that provides \neasy-to-use, portable, transparent, ef.cient, and robust instrumentation. It supports the IA32, EM64T, \nItanium R ., and ARM architectures running Linux. We show that by abstracting away architecture-speci.c \ndetails, many Pintools can work across the four architectures with little porting effort. We also show \nthat the Pin s high-level, call-based instrumentation API does not compromise performance. Auto\u00admatic \noptimizations done by our JIT compiler make Pin s instru\u00admentation even more ef.cient than other tools \nthat use low-level APIs. We also demonstrate the versatility of Pin with two Pin\u00adtools, Opcodemix and \nPinPoints. Future work includes develop\u00ading novel Pintools, enriching and re.ning the instrumentation \nAPI as more tools are developed, and porting Pin to other operating sys\u00adtems. Pin is freely available \nat http://rogue.colorado.edu/Pin.  Acknowledgments We thank Prof. Dan Connors for hosting the Pin website \nat Uni\u00adversity of Colorado. The Intel Bistro team provided the Falcon de\u00adcoder/encoder and suggested \nthe instruction scheduling optimiza\u00adtion. Mark Charney developed the XED decoder/encoder. Ramesh Peri \nimplemented part of the Pin 2/Itanium instrumentation.  References [1] AMBER home page. http://amber.scripps.edu/. \n[2] Fluent home page. http://www..uent.com/. [3] LS-DYNA home page. http://www.lstc.com/. [4] RenderMan \nhome page. http://RenderMan.pixar.com/. [5] A.-R. Adl-Tabatabai, J. Bharadwaj, D.-Y. Chen, A. Ghuloum, \nV. Menon, B. Murphy, M. Serrano, and T. Shpeisman. The StarJIT compiler: A dynamic compiler for managed \nruntime environments. Intel Technology Journal, 7(1):19 31, Feb 2003.  [6] D. L. Bruening. Ef.cient, \nTransparent, and Comprehensive Runtime Code Manipulation. PhD thesis, M.I.T. (http://www.cag.lcs.mit.edu/dynamorio/), \nSeptember 2004. [7] B. R. Buck and J. Hollingsworth. An api for runtime code patching. Journal of High \nPerformance Computing Applications, 14(4):317 329, 2000. [8] M. G. Burke, J.-D. Choi, S. Fink, D. Grove, \nM. Hind, V. Sarkar, M. J. Serrano, V. C. Sreedhar, H. Srinivasan, and J. Whaley. The Jalapeno dynamic \noptimizing compiler for java. In ACM Java Grande Conference, pages 129 141, June 1999. [9] B. M. Cantrill, \nM. W. Shapiro, and A. H. Leventhal. Dynamic instrumentation of production systems. In Proceedings of \nthe 6th Symposium on Operating Systems Design and Implementation, 2004. [10] K.D. Cooper, M.W. Hall, \nand K. Kennedy. A methodology for procedure cloning. Computer Languages, 19(2), April 1993. [11] J. L. \nHenning. SPEC CPU2000: measuring cpu performance in the new millennium. IEEE Computer, 33(7):28 35, July \n2000. [12] Intel. Pin User Manual. http://rogue.colorado.edu/Pin. [13] Intel. Intel Itanium Architecture \nSoftware Developer s Manual Vols 1-4, Oct. 2002. [14] Intel. IA-32 Intel Architecture Software Developer \ns Manual Vols 1-3, 2003. [15] Intel. Intel Extended Memory 64 Technology Software Developer s Guide Vols \n1-2, 2004. [16] Intel. Intel PXA27x Processor Family Developer s Manual, April 2004. [17] H.-S. Kim and \nJ. Smith. Hardware support for control transfers in code caches. In Proceedings of the 36th Annual ACM/IEEE \nInternational Symposium on Microarchitecture, Dec 2003. [18] J. Larus and E. Schnarr. EEL: Machine-independent \nexecutable editing. In Proceedings of the ACM SIGPLAN 95 Conference on Programming Language Design and \nImplementation, pages 291 300, June 1995. [19] P. Geoffrey Lowney, Stefan M. Freudenberger, Thomas J. \nKarzes, W. D. Lichtenstein, Robert P. Nix, John S. O Donnell, and John C. Ruttenberg. The Multi.ow Trace \nScheduling compiler. The Journal of Supercomputing, 7(1-2):51 142, 1993. [20] Chi-Keung Luk, Robert Muth, \nHarish Patil, Robert Cohn, and Geoff Lowney. Ispike: A Post-link Optimizer for the Intel Itanium Architecture. \nIn Proceedings of the 2nd Conference on Code Generation and Optimization, pages 15 26, 2004. [21] J. \nMaebe, M. Ronsse, and K. De Bosschere. Diota: Dynamic instrumentation, optimization and transformation \nof applications. In Compendium of Workshops and Tutorials held in conjunction with PACT 02, 2002. [22] \nN. Nethercote and J. Seward. Valgrind: A program supervision framework. In Proceedings of the 3rd Workshop \non Runtime Veri.cation. http://valgrind.kde.org/, 2003. [23] H. Patil, R. Cohn, M. Charney, R. Kapoor, \nA. Sun, and A. Karunanidhi. Pinpointing representative portions of large intel itanium progams with dynamic \ninstrumentation. In Proceedings of the 37th Annual ACM/IEEE International Symposium on Microarchitecture, \nDec 2004. [24] M. Poletto and V. Sarkar. Linear scan register allocation. ACM Transactions. on Programming \nLanguages and Systems, 21(5):895 913, Sept 1999. [25] T. Romer, G. Voelker, D. Lee, A. Wolman, W. Wong, \nH. Levy, B. Bershad, and B. Chen. Instrumentation and optimization of win32/intel executables using Etch. \nIn Proceedings of the USENIX Windows NT Workshop, pages 1 7, August 1997. [26] H. Saito, G. Gaertner, \nW. Jones, R. Eigenmann, H. Iwashita, R. Liberman, M. van Waveren, and B. Whitney. Large system performance \nof spec omp2001 benchmarks. In Proceedings of the 2002 Workship on OpenMP: Experiences and Implementation, \n2002. [27] K. Scott, N. Kumar, S. Velusamy, B. Childers, J. Davidson, and M. L. Soffa. Recon.gurable \nand retargetable software dynamic translation. In Proceedings of the 1st Conference on Code Generation \nand Optimization, pages 36 47, 2003. [28] T. Sherwood, E. Perelman, G. Hamerly, and B. Calder. Automatically \ncharacterizing large scale program behavior. In Proceedings of the 10th International Conference on Architectural \nSupport for Programming Languages and Operating Systems, Oct 2002. [29] A. Srivastava, A. Edwards, and \nH. Vo. Vulcan: Binary transformation in a distributed environment. Technical Report MSR-TR-2001-50, Microsoft \nResearch, April 2001. [30] A. Srivastava and A. Eustace. Atom: A system for building customized program \nanalysis tools. In Proceedings of the ACM SIGPLAN 94 Conference on Programming Language Design and Implementation, \npages 196 205, 1994. [31] X. Zhang, Z. Wang, N. Gloy, J. B. Chen, and M. D. Smith. System support for \nautomatic pro.ling and optimization. In Proceedings of the 16th Symposium on Operating System Principles, \nOctober 1997.  \n\t\t\t", "proc_id": "1065010", "abstract": "Robust and powerful software instrumentation tools are essential for program analysis tasks such as profiling, performance evaluation, and bug detection. To meet this need, we have developed a new instrumentation system called <i>Pin</i>. Our goals are to provide <i>easy-to-use, portable, transparent</i>, and <i>efficient</i> instrumentation. Instrumentation tools (called <i>Pintools</i>) are written in C/C++ using Pin's rich API. Pin follows the model of ATOM, allowing the tool writer to analyze an application at the instruction level without the need for detailed knowledge of the underlying instruction set. The API is designed to be <i>architecture independent</i> whenever possible, making Pintools source compatible across different architectures. However, a Pintool can access architecture-specific details when necessary. Instrumentation with Pin is mostly <i>transparent</i> as the application and Pintool observe the application's original, uninstrumented behavior. Pin uses <i>dynamic compilation</i> to instrument executables while they are running. For efficiency, Pin uses several techniques, including inlining, register re-allocation, liveness analysis, and instruction scheduling to optimize instrumentation. This fully automated approach delivers significantly better instrumentation performance than similar tools. For example, Pin is 3.3x faster than Valgrind and 2x faster than DynamoRIO for basic-block counting. To illustrate Pin's versatility, we describe two Pintools in daily use to analyze production software. Pin is publicly available for Linux platforms on four architectures: IA32 (32-bit x86), EM64T (64-bit x86), Itanium&#174;, and ARM. In the ten months since Pin 2 was released in July 2004, there have been over 3000 downloads from its website.", "authors": [{"name": "Chi-Keung Luk", "author_profile_id": "81100307206", "affiliation": "Intel Corporation", "person_id": "P44955", "email_address": "", "orcid_id": ""}, {"name": "Robert Cohn", "author_profile_id": "81100362956", "affiliation": "Intel Corporation", "person_id": "PP35028282", "email_address": "", "orcid_id": ""}, {"name": "Robert Muth", "author_profile_id": "81342505475", "affiliation": "Intel Corporation", "person_id": "PP43131943", "email_address": "", "orcid_id": ""}, {"name": "Harish Patil", "author_profile_id": "81100485093", "affiliation": "Intel Corporation", "person_id": "P107511", "email_address": "", "orcid_id": ""}, {"name": "Artur Klauser", "author_profile_id": "81100104010", "affiliation": "Intel Corporation", "person_id": "P22215", "email_address": "", "orcid_id": ""}, {"name": "Geoff Lowney", "author_profile_id": "81342502842", "affiliation": "Intel Corporation", "person_id": "PP43141227", "email_address": "", "orcid_id": ""}, {"name": "Steven Wallace", "author_profile_id": "81537914856", "affiliation": "Intel Corporation", "person_id": "PP14102223", "email_address": "", "orcid_id": ""}, {"name": "Vijay Janapa Reddi", "author_profile_id": "81100295002", "affiliation": "University of Colorado", "person_id": "PP14109177", "email_address": "", "orcid_id": ""}, {"name": "Kim Hazelwood", "author_profile_id": "81100418017", "affiliation": "Intel Corporation", "person_id": "PP14147884", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065034", "year": "2005", "article_id": "1065034", "conference": "PLDI", "title": "Pin: building customized program analysis tools with dynamic instrumentation", "url": "http://dl.acm.org/citation.cfm?id=1065034"}