{"article_publication_date": "06-12-2005", "fulltext": "\n Programming by Sketching for Bit-Streaming Programs Armando Solar-Lezama1 Rodric Rabbah2 Rastislav Bod\u00b4ik1 \nKemal Ebcio.glu3 1Computer Science Division, University of California, Berkeley 2Computer Science and \nArti.cial Intelligence Laboratory, Massachusetts Institute of Technology 3T.J. Watson Research Center, \nIBM Corporation {asolar, bodik}@cs.berkeley.edu, rabbah@mit.edu, kemal@us.ibm.com Abstract This paper \nintroduces the concept of programming with sketches, an approach for the rapid development of high-performance \nap\u00adplications. This approach allows a programmer to write clean and portable reference code, and then \nobtain a high-quality implemen\u00adtation by simply sketching the outlines of the desired implemen\u00adtation. \nSubsequently, a compiler automatically .lls in the missing details while also ensuring that a completed \nsketch is faithful to the input reference code. In this paper, we develop StreamBit as a sketching methodology \nfor the important class of bit-streaming programs (e.g., coding and cryptography). A sketch is a partial \nspeci.cation of the implementation, and as such, it affords several bene.ts to programmer in terms of \nproduc\u00adtivity and code robustness. First, a sketch is easier to write com\u00adpared to a complete implementation. \nSecond, sketching allows the programmer to focus on exploiting algorithmic properties rather than on \norchestrating low-level details. Third, a sketch-aware com\u00adpiler rejects buggy sketches, thus improving \nreliability while al\u00adlowing the programmer to quickly evaluate sophisticated imple\u00admentation ideas. We \nevaluated the productivity and performance bene.ts of our programming methodology in a user-study, where \na group of novice StreamBit programmers competed with a group of experi\u00adenced C programmers on implementing \na cipher. We learned that, given the same time budget, the ciphers developed in StreamBit ran 2.5\u00d7 faster \nthan ciphers coded in C. We also produced imple\u00admentations of DES and Serpent that were competitive with \nhand optimized implementations available in the public domain. Categories and Subject Descriptors D.2.2 \n[Software Engineer\u00ading]: Software Architectures, Design Tools and Techniques; D.3.3 [Programming Languages]: \nLanguage Constructs and Features; D.3.4 [Programming Languages]: Processors; D.3.2 [Program\u00adming Languages]: \nLanguage Classi.cations General Terms Languages, Design, Performance Keywords Stream Programming, StreamIt, \nSynchronous Data.ow, Sketching, Domain Speci.c Language, Domain Speci.c Compiler Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 05, June 12 15, 2005, Chicago, Illinois, \nUSA. Copyright 2005 ACM 1-59593-056-6/05/0006...$5.00. 1. Introduction Applications in domains like \ncryptography and coding often have the need to manipulate streams of data at the bit level. Such ma\u00adnipulations \nhave several properties that make them a particularly challenging domain from a developer s point of \nview. For exam\u00adple, while bit-level speci.cations are typically simple and concise, their word-level \nimplementations are often daunting. Word-level implementations are essential because they can deliver \nan order of magnitude speedup, which is important for servers where security\u00adrelated processing can consume \nup to 95% of processing capac\u00adity [20]. Converting bit-level implementations to word level imple\u00admentations \nis akin to vectorization, but the characteristics of bit\u00adstreaming codes render vectorizing compilers \nlargely ineffective. In fact, widely used cipher implementations often achieve perfor\u00admance thanks to \nalgorithm-speci.c algebraic insights that are not available to a compiler. Additionally, correctness \nin this domain is very important be\u00adcause a buggy cipher may become a major security hole. In 1996, a \nrelease of the BlowFish cipher contained a buggy cast (from un\u00adsigned to signed characters) which threw \naway two thirds of the encryption-key in many cases. As a result, 3/4 of all keys could be broken in \nless than 10 minutes [17]. This accident illustrates not only the severity of cipher bugs, but also the \ndif.culty with cipher testing. The buggy BlowFish cipher actually worked correctly on all test cases, \nexemplifying a common issue with many ciphers, es\u00adpecially those based on Feistel rounds. These ciphers \ncan encrypt and decrypt a .le even when coded incorrectly, thus complicating correctness checking and \nveri.cation. In this paper we present StreamBit as a new programming methodology that simultaneously \n(i) ensures correctness and (ii) supports semi-automatic performance programming. We achieve these goals \nby allowing the user to guide the compilation process by sketching the desired implementation. To explain \nhow sketching works, consider the following bit manipulation example we refer to as DropThird. It is \nconcisely described as: produce an output stream by dropping every third bit from the input stream . \nSome\u00adwhat surprisingly, this seemingly simple problem exhibits many is\u00adsues arising in the more involved \nbit-stream manipulations algo\u00adrithms, including parity checking and bit permutations. To illustrate why \nthis is a non-trivial example, consider a general-purpose processor with the usual suite of bitwise oper\u00adations: \nand, or, xor, left/right shift this is the target machine assumed in this paper. In order to obtain a \nhigh-performing im\u00adplementation on such a machine, we must satisfy several trade\u00adoffs. For example, we \ncan carefully prearrange the bits into words and therefore exploit more parallelism within a word. However, \nthe cost of prearrangement may not be offset by word-level paral\u00adlelism alone. In general, arriving at \na good implementation requires employing locally sub-optimal implementation strategies. Further\u00adFigure \n1. Two implementations of DropThird: (a) naive implemen\u00adtation with a O(w) running time; and (b) log-shifter \nimplementa\u00adtion with a O(log w) running time. more, the exact way in which the prearrangement is implemented \ncan lead to signi.cant differences in performance. This is illustrated in Figure 1. The naive scheme \nshown on the left needs O(w) steps, while the smarter scheme (on the right) requires O(log(w)) steps; \nw = 16 in our example and it represents the word size. The smarter algorithm, known to hardware circuit \ndesigners as a log-shifter, is faster because it utilizes the word parallelism better: it shifts more \nbits together while ensuring that no bit needs to be moved too many times again, a tricky trade-off. \nFinding a better implementation is worth it: on a 32-bit Pentium processor, the log-shifter imple\u00admentation \nis 1.6\u00d7 faster than the naive implementation; on a 64-bit Itanium architecture, it is 3.5\u00d7 faster; and \non an IBM SP processor, it is 2.3\u00d7 faster. The log-shifter is also signi.cantly faster than our table-lookup \nimplementations, on all our platforms. Besides .nding an implementation algorithm with a suitable trade-off, \nthe programmer faces several tedious and bug-prone tasks: Low-level details. Programming with low-level \ncodes results in implementations that are typically disproportionate in size and complexity to the algorithm \nspeci.cation. For example, a FORTRAN implementation of a log-shifter (for a DropThird variant) requires \n140 lines of code. The complexity is due to the use of different bit-masks at each stage of the algorithm. \n Malleability and portability. The low-level code is hard to mod\u00adify, even for simple changes to the \nprogram speci.cation (e.g., changing the speci.cation to drop the second of every three bits). Furthermore, \nporting a 32-bit implementation to a 64-bit machine typically requires rewriting the entire implementation \n(not doing so will halve the performance of DropThird).  Instruction-level parallelism. Micro-architectural \ncharacteris\u00adtics may signi.cantly in.uence performance. For example, the naive implementation in Figure \n1 may win on some machines because it actually offers more instruction-level parallelism than the log-shifter \n(there are less data dependencies). To .nd a suitable implementation, the programmer typically implements \nand measures the performance of various implementation ideas.  When programming with StreamBit, the \nprogrammer .rst writes a full behavioral speci.cation of the desired bit manipulation task. This speci.cation, \ncalled the reference program, is written in the StreamIt data.ow language [19], and is nothing more than \na clean, unoptimized program describing the task at the level of bits (rather than at the level of words). \nIn case of ciphers, the reference program is usually a simple transcription of the cipher standard. In \nthe absence of a Sketch, we compile the reference program to low-level C code with a base compiler. The \nbase compiler exploits word-level parallelism using a simple greedy strategy based on local substitution \nrules. Once the reference program is complete, either the programmer or a performance expert sketches \nan ef.cient implementation. The goal of sketching is to provide only a loosely constrained template of \nthe implementation, with the compiler .lling in the missing details. The details are obtained by ensuring \nthat when the sketch is resolved, it implements the reference program; that is, the resolved sketch is \nbehaviorally equivalent to the reference program. A challenge with sketching the outline of an implementation \nis that the programmer may want to sketch implementation ideas at different levels of abstraction. StreamBit \naffords such a conve\u00adnience by allowing the user-provided sketch to transform the pro\u00adgram at any point \nthrough the base compilation process. Effec\u00adtively, as the base compiler proceeds to transform the program \nto low-level C through local substitutions, the sketches will prompt additional transformations, which \nwill result in an implementation that will approach the level of performance that the expert desires. \nThe underlying intuition is that the local substitutions of the base compiler will perform a more optimal \ntranslation if the dif.cult global decisions are supplied via sketches this is especially im\u00adportant \nwhen the complexity of an optimization is well beyond the scope of what a compiler can autonomously discover. \nIn Figure 2, we illustrate the key ideas behind sketching. On the very left is the reference program \nin visual form. This bit manipulation task is translated by the base compiler into a task that is equivalent, \nbut also word-aligned. Now, if the base compiler is allowed to continue, it produces the slow implementation \nstrategy shown in Figure 1(a). Instead, the programmer supplies a sketch of how the word-aligned task \nshould be implemented. With sketching, the programmer states no more than a rough idea of the task: it \nis potentially possible to implement the DropThird permutation by .rst shifting some bits by one position, \nthen some bits by two positions, and so on. The sketch does not specify which bits must shift in each \nstep; in fact, it may not be possible to satisfy the sketch log-shifting of course does not work for \nall permutations. If the sketch is satis.able, then the details (i.e., which bits to shift) are derived \nautomatically. Otherwise, it is rejected, and thus the user cannot introduce bugs into the implementation. \nIn summary, the StreamBit methodology offers the following bene.ts: (1) it obviates the need to code \nlow-level details thereby making developers more productive, (2) it rejects buggy sketches and guarantees \ncorrectness by construction, (3) it allows the pro\u00adgrammer to rapidly test and evaluate various implementation \nideas, even before they are known to be correct without the fear of intro\u00adducing bugs. In addition, the \nsketches are robust because they are devoid of low-level details. For example, note that even though \nthe implementation of the log-shifter is slightly different for different words, the same sketch applies \nto all of them because the general strategy remains the same; only the details of exactly which bits \nto shift change. In fact, if DropThird is modi.ed to drop the second of every three bits, we simply need \nto change the reference program; the original sketch remains applicable. Thus, the sketch has a level \nof re-usability across a family of algorithms. This paper makes the following contributions. We describe \nprogramming by sketching, a method for rapidly developing correct-by-construction implementations of \nbit\u00adstreaming programs.  We develop a constraint solver for compiling sketch. The solver uses the reference \nprogram and the sketch to derive a complete (and optimized) implementation.  We develop a sketching \nlanguage that allows programmers to specify a large number of implementations.  We report the results \nof a user study which showed that in the same amount of time, StreamBit programmers were more pro\u00adductive, \nproducing code that ran 3\u00d7 faster than C programmers.  We show that sketched implementations of DES \nand Serpent perform as well as (and in some cases outperform) heavily optimized and widely used implementations \nof these ciphers.   Figure 2. An illustration of programming with sketches on our running example. \nThe compiler translates the reference program into machine code in several steps; at each step, it checks \nwhether there is a sketch on how to implement the given program. In the .gure, the compiler .rst unrolls \nthe reference program to operate on words, rather than bits. Then, this word-aligned task (a full speci.cation \nof a bit-stream manipulation function) is combined with the sketch (a partial speci.cation of the implementation) \nto derive the full implementation. The compiler then continues to translate the resolved sketch into \nmachine instructions. The remainder of the paper is organized as follows. Section 2 describes the StreamIt \nprogramming language and model of com\u00adputation. Sections 3 and 4 describe the program representation \nand base compiler infrastructure. Section 5 details the sketching methodology. Section 6 presents our \nevaluation and results. Lastly, a discussion of related work appears in Section 7, and our summary and \nconcluding remarks appear in Section 8.  2. StreamIt The StreamBit compiler is concerned with the domain \nof bit\u00adstreaming programs, with a focus on private-key ciphers. Such programs generally consume input \nbits from a stream (in blocks ranging in size from 32 to 256 bits), and produce output bits via a sequence \nof transformations on the stream. The transformations generally include permutations, substitutions, \nor arbitrary boolean functions. Additionally, in the case of ciphers, some functions will involve mixing \nan encryption key with the stream. An important characteristic of ciphers is that they tend to avoid \ndata dependent computations, since this makes them vulnerable to side channel attacks; in particular, \nloop trip counts are .xed at compile time [8]. The StreamBit system uses StreamIt as the language for \nwrit\u00ading the reference programs. StreamIt [19] embraces a synchronous data.ow model of computation. In \nthis model, a program consists of a collection of .lters that produce and consume data through output \nand input ports respectively, and a set of FIFO communica\u00adtion channels that connect the output and input \nports of different .lters. A .lter is an autonomous unit of computation that executes (or .res) whenever \nthere is a suf.cient amount of data queued on the input channel. In StreamIt, a .lter is a single input-single \noutput component with statically bound I/O rates that is, the amount of data produced and consumed during \na single .lter .ring is deter\u00admined at compile time. The static I/O bounds allow the compiler to orchestrate \nthe execution of the entire program, and to implicitly manage the buffers between .lters. The compiler \ncan thus lessen the burden on the programmer in terms of interleaving .lter execu\u00adtions or allocating \nadequate buffer space between .lters. Figure 3 illustrates a simple .lter that implements DropThird; \nthis .lter is our running example. The work function de.nes the output of the .lter as a function of \nits input. The work function may contain arbitrary code, but sketching is only allowed when the loop \nbounds in the work function are not dependent on the input data, and when the .lters do not maintain \nstate (i.e., the output is strictly a function of the input). These requirements, along with the requirement \nof statically de.ned input and output rates, are not an impediment in our domain, since ciphers tend \nto avoid data dependent computation, and are generally de.ned as a sequence of functions that do not \nresort to any saved state. In StreamIt, the communication channels are de.ned implicitly by composing \n.lters into pipelines or splitjoins. A pipeline is a bit->bit filter DropThird {work push 2 pop 3 { for \n(int i=0; i<3; ++i) {bit x = peek(i) if (i<2) push(x); pop(); }}} Figure 3. The reference program of \nDropThird, our running exam\u00adple, expressed here as a StreamIt .lter that drops every third bit. sequence \nof .lters that are linked together such that the output of .lter i is the input of .lter i +1. The StreamIt \nprogram below illustrates a pipeline that consumes an input stream and drops every third bit from it, \nand subsequently drops every third bit from the resulting stream. bit->bit pipeline DropTwice { add DropThird(); \n add DropThird(); } A splitjoin consists of a splitter which distributes its input stream to N children \n.lters, and a joiner which merges the out\u00adput of all N children. There are two types of splitters: duplicate \nsplitters and roundrobin splitters. A duplicate splitter passes iden\u00adtical copies of its input to every \none of its children. In contrast, a roundrobin splitter distributes the input stream to the individual \n.lters in a roundrobin fashion, according to the speci.ed rate for each .lter. Similarly, a roundrobin \njoiner reads data in a roundrobin fashion from every branch in the splitjoin and writes them in order \nto the output stream (such a joiner effectively concatenates its in\u00adputs). In the splitjoin example below, \nevery three consecutive bits x, y, z in the input stream are processed as follows: the duplicate splitter \nsends identical copies of these three bits to the two chil\u00addren .lters. The roundrobin joiner reads the \ntwo bits x, y from the output of the DropThird .lter, and one bit z from the output of the KeepThird \n.lter, and concatenates them, producing x, y, z again in the output stream. bit->bit splitjoin FunnyIdentity \n{ split duplicate; add DropThird(); add KeepThird(); join roundrobin(2,1); } In StreamIt, .lters, \npipelines, and splitjoins can be nested, lead\u00ading to a hierarchical composition of a stream program. \nThe lan\u00adguage exposes the communication between .lters and the task level parallelism in the program, \nwhile also affording modularity, mal\u00adleability, and portability. It is therefore well suited for our \npurpose, and is also rich and expressive enough to serve as an intermediate representation throughout \nthe compilation process. 3. Program Representation The synchronous data.ow programming model of the \nStreamIt lan\u00adguage serves as a convenient foundation for the intermediate repre\u00adsentation used throughout \nthe StreamBit compilation process. We use an abstract syntax tree (AST) to represent the three possible \nstream constructs: leaves represent .lters, and internal nodes repre\u00adsent pipelines and splitjoins. 3.1 \nFilters In general, a .lter can represent an arbitrary mapping between its input bit vector and its output \nbit vector. However, there is class of .lters whose output is an af.ne function of their input. Such \n.lters are important because they have useful algebraic properties, and can serve as building blocks \nto represent permutations and arbitrary boolean functions, and for this reason they will constitute the \nleaves of the AST. Af.ne Filters Formally, an af.ne .lter f is a .lter whose work function performs the \nfollowing transformation: [ f]](x)= Mx + v where x is a n-element boolean (i.e., binary) vector, M is \na m \u00d7 n boolean matrix, and v is a m-element offset boolean vector. Note that all vectors in this paper \nare column vectors but are sometimes written as row vectors for compactness. We denote an af.ne .lter \nwith f =(M, v), and the work function with [ f]](x). If the offset vector is the zero vector (i.e., v \n= [0,..., 0]), then we simply write f = M. We distinguish three types of af.ne .lters: and, or, and xor. \nThese .lters differ in the boolean operations used to carry out the scalar multiplication and scalar \naddition that make up the vector operations. The three types of .lters are summarized as follows. The \ntype of a .lter f is obtained via typeof (f). typeof (f) scalar multiplication scalar addition and . \n. or . . xor . . For the rest of the paper, unless otherwise noted, we assume .lters are of type xor. \nPermutation Filters In cipher implementations, permutations are a particularly important class of af.ne \n.lters. In this paper, a per\u00admutation is a .lter that optionally removes some bits from the n-bit input \nvector, and arbitrarily reorders the remaining input bits to ob\u00adtain an m-bit result. In StreamBit, as \na matter of convention, a per\u00admutation .lter is of type xor, but the type is not important because permutation \n.lters have a zero offset vector v, and a work matrix M with at most one non-zero value per row, and \nhence no addition is involved 1. As an example, the work matrix for the DropThird permutation .lter is: \n. 100 ] MDropThird = . 010 A natural way to interpret the matrices is to realize that each row corresponds \nto single output bit, and that the non-zero element in the row represents which of the input bits (if \nany) will appear in the output. 1 The only caveat to this statement is that if we want to represent a \npermu\u00adtation with an and.lter, we need to negate all the entries in the matrix and offset vector, i.e. \nwe must have one zero value per row, and the offset vector must be all ones. Arbitrary Boolean Functions \nFilters that implement arbitrary boolean functions can be transformed to pipelines of af.ne .l\u00adters. \nThis is possible because any boolean function is expressible in disjunctive normal form, i.e., as a disjunction \nof minterms. In StreamBit, a pipeline of three af.ne .lters implements functions in disjunctive normal \nform as follows: .rst, an xor .lter negates input bits; second, an and .lter computes the minterms; and \n.\u00adnally an or.lter performs the disjunction. The StreamBit compiler uses a more complicated algorithm \nbased on symbolic execution which is not exponential, unlike minterm expansion to produce a pipeline \nof and, or and xor .lters for work functions with arbi\u00adtrary boolean expressions. 3.2 Pipelines and \nSplitjoins In our intermediate representation, the internal nodes of the AST are pipelines and splitjoins. \nA pipeline AST node with children x1 to xn is denoted PL(x1,...,xn). The children may in turn represent \n.lters, pipelines, or splitjoins (since StreamIt allows for a hierarchical composition of stream components). \nFor example a pipeline of n .lters is represented as PL((M1,v1), ..., (Mn,vn)), whereas a pipeline of \nn pipelines is represented as PL(PL1(...), ..., P Ln(...)). In both cases however, the communication \ntopology is clear: the output of child xi is the input of child xi +1. A splitjoin AST node connects \nits children x1 to xn to a splitter sp and a joiner jn. A splitjoin is denoted SJsp,jn(x1,...,xn), with \nduplicate splitters denoted dup, and roundrobin splitters (or joiners) with rates k1,...,kn denoted rr(k1,...,kn). \nFor example, the splitjoin for FunnyIdentityin section 2 is described as: SJdup,rr(2,1)(MDropThird,MKeepThird). \nWhen the rates of a roundrobin splitter or joiner are equal (k1 = ... = kn), we simply write rr(k1). \nWe will use the notation rr[i] to refer to the ith rate in the round-robin. In StreamBit, we also support \na reduction joiner which is denoted red. There are three types of reducing joiners namely and, or, and \nxor each of which applies the corresponding boolean operator to n bits from the input stream (one bit \nfrom each of n input streams) and commits the result to the output stream. In other words, a reduction \njoiner is semantically equivalent to a rr(1) joiner whose output is consumed by an af.ne .lter f = M \nwhere typeof(f) corresponds to the type of the reduction joiner, and every entry of the binary work matrix \nM is non-zero.  4. The Base Compiler This section describes the base compilation algorithm that is \nused by the StreamBit system to produce code from the reference pro\u00adgram. The base algorithm is very \nfast and predictable, but the code it produces is not optimal. The next section will address this by \nex\u00adplaining how StreamBit builds on top of this algorithm to allow for sketching of user-de.ned implementations. \nThe base compilation works by applying local substitution rules on the AST to convert the reference program \ninto an equivalent StreamIt program with the property that each of its af.ne .lters corresponds to an \natomic operation in our machine model. A pro\u00adgram with these characteristics is said to be in Low-Level \nForm (LL-form). More formally, an LL-form program is de.ned as a pro\u00adgram with the following two properties: \n(1) Its communication network (AST internal nodes) transfers data in blocks of a size that can be handled \ndirectly by the atomic operations in the model machine. Figure 4. The Splitjoin Resizing transformations. \nThe original .lter (a) is transformed using Split Equivalence (b); the result is then transformed using \nJoin Equivalence (c). (2) Its .lters (AST leaves) correspond to a single atomic operation. Throughout \nthis paper, as well as in our current implementation, we use as our machine model a processor that can \nmove data in blocks of size w (the word-size), and apply any of the following atomic operations on it: \nright and left logical shift on words of size w, and, or and xor of two words of size w, and and, or \nand xor of one word of size w with a .xed constant. Programs in LL-form are easily mapped to C code, \nbecause their data.ow graphs consist of atomic operations linked together through communication channels \nthat de.ne how values .ow among them. Our choice of machine model makes translation into C easy, because \nall the atomic operations can be expressed in a single C statement. We chose C as the target of our compilation, \nboth for portability reasons, and to take advantage of the register allocation and code scheduling performed \nby good C compilers, which allows us to focus on higher level optimizations. The base compilation algorithm \nwill transform any program to satisfy the two properties of LL-form by following three simple steps, \nall based on local substitution rules: i) Splitjoin Resizing; ii) Leaf Size Adjustment; iii) Instruction \nDecomposition. Figure 6 shows the complete algorithm. Before describing each of the stages in detail, \nwe point out that the .rst two stages will be responsible for enforcing property (1), while the third \nstage will be responsible for property (2). Splitjoin Resizing This stage will apply local rewrite rules \nto the internal nodes of the AST when it is necessary in order to remove a violation of property (1). \nThis, it turns out, will only be necessary in the case of splitjoins with roundrobin splitters or joiners \nwhere there is an i for which rr[i], the number of bits to deliver, is not a multiple of w (w equals \nthe number of bits our assumed machine can handle in one instruction). In this case, we apply a transformation \nbased on the Join and Split Equivalences of Figure 5 to transform the splitter/joiner to one that makes \nno mention of rates, i.e., a duplicate spliter or a reduction joiner. Figure 4 illustrates the effect \nof the transformations on this stage for a simple splitjoin. As it will become apparent shortly, pipelines \nand other types of splitjoins do not need to make substitutions to the internal nodes of the AST to satisfy \nproperty (1), and therefore are not affected by this stage. In particular, this transformation is not \nneeded when compiling DropThird because DropThird has no splitjoins. Leaf Size Adjustment Once all splitjoins \nare transformed via Splitjoin Resizing, we complete the transformation to LL-form using only local rewrite \nrules on the leaves of the AST. We can do this because in the case of pipelines and splitjoins with dup \nsplitters or red joiners, property (1) is trivially maintained as long as all their children produce \nand consume bits in multiples of the w. Therefore, a simple inductive argument shows that we don t need \nto make any more changes to the internal nodes to satisfy property (1); we only need to guarantee that \nthe leaf nodes produce and consume bits in multiples of w. The Leaf Size Adjustment stage will enforce \nproperty (1) by forcing each leaf node to consume exactly w bits and produce w bits through the application \nof the UNROLL, COLSPLIT, and ROWS-PLIT substitution rules as shown in the pseudocode in Figure 6. To \nunderstand how the LEAF-SIZE-ADJ procedure works, con\u00adsider the running example as illustrated in Figure \n7. The .gure shows the complete sequence transformations we would perform on the DropThird .lter to compile \nit into instructions for a 4 bit wide machine. First, in step (a), we use the unroll equivalence from \nFigure 5 to substitute DropThird with an equivalent .lter whose size is a multiple of the word size. \n. MDropThird 000 . 0 MDropThird 00 Mu := ..= MDropThird . 00 MDropThird 0 . 000 MDropThird Then, in step \n(b), we use the column equivalence to replace the af.ne .lter with an equivalent splitjoin of .lters \nwhose input size is equal to the word size SJrr,or(M1,M2,M3)= Mu where the Mi are de.ned such that Mu \n=[M1,M2,M3] Finally, in step (c) we use the row equivalence to substitute each of the new af.ne .lters \nwith a splitjoin of .lters whose input and output size is equal to w. SJrr,or( SJdup,rr(M1,1,M1,2), SJdup,rr(M2,1,M2,2), \nSJdup,rr(M3,1,M3,2) )= SJrr,or(M1,M2,M3) Where [ Mi,1 ] Mi = Mi,2 Note that all we have done is apply \nlocal substitution rules to the leaves until all the leaf .lters take w bits of input and produce w bits \nof output, and as a consequence, property (1) is fully satis.ed. Also note that the validity of the substitutions \ncan be ascertained by looking only at a single node and its immediate children in the AST, so the process \nis very fast. Instruction Decomposition Once all the leaf nodes in the AST map one word of input to one \nword of output, we need to decom\u00adpose them into .lters corresponding to the atomic bit operations available \nin our assumed machine model. The pseudocode in Figure 6 shows the Instruction Decompo\u00adsition as simply \napplying to every leaf-node one last substitution called IDECOMP. The IDECOMP transformation is based \non the observation that any matrix can be decomposed into a sum of its diagonals. Each diagonal in turn \ncan be expressed as a product of a matrix cor\u00adresponding to a bit-mask with a matrix corresponding to \na bit shift. Thus, any matrix m of size w \u00d7 w can be expressed as m = Lw-1 ais i, where the ai are diagonal \nmatrices, and i=-(w-1) s i is a matrix corresponding to a shift by i. Given this decompo\u00adsition, we use \nthe sum and product equivalences from Figure 5 to Unroll Equivalence UNROLL[n]((M, v)) Where n is the \nnumber of times to unroll.  Column Equivalence COLSPLIT[s1,...,sn]((M, v)) Where the si de.ne the partition \nof matrix M into the Mi.  COLMERGE(SJ) Precondition: rr[i]= insize(Mi) and typeof (Mi)= typeof(red) \n.i Row Equivalence ROWSPLIT[s1,...,sn]((M, v)) Where the si de.ne the partition of matrix M into the \nMi.  Precondition: M ... 0 v 0 M ... v . ... (M, V ) . ( ... , ...) ... ... ... ... .. 0 ... M v \n([M1,M2,...,Mn] , .ni=1 vi) . SJrr,red((M1,v1), (M2,v2),..., (Mn,vn)) SJrr,red((M1,v1), (M2,v2),..., \n(Mn,vn)) . ([M1,M2,...,Mn] , .ni=1 vi) .. . M1 .. v1 . M2 v2 (... , ...) . SJdup,rr((M1,v1), (M2,v2),..., \n(Mn,vn)) ... ... .. Mn vn .) . .. .. . , Mn vn M1 . .. v1 ROWMERGE(SJ) SJdup,rr((M1,v1), (M2,v2),..., \n(Mn,vn)) . ( M2 v2 ... ... rr[i]= outsize(Mi) and typeof (Mi)= typeof(Mj ) .i, j Product Equivalence \n PCOLLAPSE(PL) Precondition: typeof (Mi)= typeof(Mj ) .i, j PEXPAND[M1,...,Mn]((M, v)) Where M1,...,Mn \nde.ne the partition of the Mi. Sum Equivalence SCOLLAPSE(SJ) Precondition: typeof (Mi)= typeof(Mj ) \n.i, j SEXPAND[M1,...,Mn]((M, v)) Where M1,...,Mn de.ne the partition of the Mi. Split Equivalence SJTODUP(SJ) \nSee Figure 4 for an example of this trans\u00adformation. Join Equivalence  SJTOXOR(SJ) See Figure 4 for \nan example of this trans\u00adformation. PL((M1,v1), (M2,v2),..., (Mn,vn)) . . (Mn * Mn-1 ... * M1, .n (Mn \n* Mn-1 ... * Mi+1)vi) i=1 (Mn * Mn-1 ... * M1, .n (Mn * Mn-1 ... * Mi+1)vi) . i=1 . PL((M1,v1), (M2,v2),..., \n(Mn,vn)) SJdup,red((M1,v1), (M2,v2),..., (Mn,vn)) . (.i=n Mi, .n i=1 i=1 vi) (.i=n Mi, .ni=1 vi) . SJdup,red((M1,v1), \n(M2,v2),..., (Mn,vn)) i=1 SJrr,any(F1,F2,...,Fn) . SJdup,any(PL(S1,F1),PL(S2,F2),...,PL(S3,Fn)) where \nSi is an M \u00d7 N matrix where M = rr[i] and N = .nl=1 rr[l] and the Si[j, k]=1 when k - j = .i-1 rr[l] \nand 1 = j = M, and is zero otherwise. l=1 SJany,rr(F1,F2,...,Fn) . SJany,red(PL(F1,S1),PL(F2,S2),...,PL(Fn,S3)) \nwhere Si is an M \u00d7 N matrix withM l=1 rr[l] and N = rr[i] = .n and the S1[j, k]=1 when j - k = .i-1 rr[l] \nand 1 = k = N, and is zero otherwise. l=1 Figure 5. Rewrite rules on our StreamIt AST. - - -\u00ad - - - \n-\u00ad - \u00ac= = = - -  Figure 7. An illustration of the base compilation algorithm for our running example, \nassuming a 4 bit machine: (a) involves unrolling the .lter to take in and push out a multiple of w, the \nword size; (b) shows how a .lter is broken into columns with a semantics preserving transformation; (c) \nshows the effect of a similar transformation for breaking into rows; (d) shows one of the .lters from \n(c) as it is .nally converted into LL-form .lters. Steps (a) through (c) correspond to size adjustment. \nStep (d) corresponds to instruction decomposition. de.ne IDECOMP as (M, v)= SJdup,red(PL(s1, (a1,v)),...,PL(sn,an)) \nAs an example, to continue with our DropThird running exam\u00adple, we can take matrix M1,1 and note that \n M1,1 = Diag[1100] * s0 + Diag[0010] * s1 = PL(s0, Diag[1100]) + PL(s1, Diag[0010]) = SJdup,or(PL(s 0, \nDiag[1100]),PL(s 1, Diag[0010])). In this case, the .rst equality is simply a statement about matrices. \nThe second one is an application of PEXPAND, and the third equal\u00adity is an application of SEXPAND, and \nthe composition of the two gives us IDECOMP. This transformation is illustrated in Figure 7(d). Note \nthat in the .gure, PL(s 0, Diag[1100]) has been replaced by Diag[1100] since s 0 corresponds to the identity \nmatrix. In the remainder of this section, we digress a little to show that this approach is actually \nquite general, and can allow us to build IDECOMP functions to produce code for more complicated machine \nmodels. For example, adding a rotation instruction to our machine + |i| model poses no major problem, \nsince for positive i, si = ai * r, - + - and for negative i, si = a * r|i|, where a and a are diagonal \ni ii matrices that mask either the upper i bits or the lower i bits. Thus, we only need to replace si \nin the original expression for m, and Lw-1 i collect terms to get a decomposition m = i=0 air in terms \nof rotations r i. With this new equation, the IDECOMP function can be produced trivially as a composition \nof SEXPAND and PEXPAND, just as with the original machine model. In fact, the same strategy works even \nfor more complicated shifts, like those found in some SIMD extensions, which have i 8*i shift instructions \nto shift entire bytes at a time t= s , as well as packed byte shifts u i which correspond to shifting \nseveral contiguous bytes independently but in parallel, with bits that move i .i/8. * past the boundary \nof a byte being lost. In that case, s = t i mod 8 .i/8.+1 * u u + t(i mod 8)-8, and just like before, \nwe can simply replace this expression for the si in the original formula and get a decomposition in terms \nof sequences of shifts of the form ti * uj . The base algorithm has the advantage that because the transfor\u00admation \nis based on local substitution rules, its results are easy to predict. In particular, the .nal number \nof operations is roughly pro\u00adportional to the number of diagonals in the original matrix. It will generally \nproduce suboptimal results because bits that shift by the same amount are shifted together all the way \nto their .nal position in a single operation. For example, in the case of DropThird, this strategy produces \nthe naive implementation from Figure 1(a). In order to get the better implementation, we ll need to use \nsketching.  5. Sketching We are now ready to describe the sketching compiler, which syn\u00adthesizes an \nimplementation that is functionally identical to the ref\u00aderence program while being structurally conformant \nto the sketched implementation. We will explain synthesis with sketches in two steps. We will .rst assume \nthat the sketch provided by the programmer is com\u00adplete, i.e., that it does not omit any implementation \ndetail. We will then explain how proper sketches, those which do omit details, can be resolved to complete \nsketches. In our running example, the data.ow program in Figure 2(d) is a complete sketch, while the \nprogram in Figure 2(c) is a proper sketch.2 2 Note that in Figure 2, the complete sketch (d) has been \nobtained automati\u00adcally, by resolving the proper sketch (c), but the programmer is nonetheless free to \ndevelop a complete sketch manually. This is still easier than devel\u00adoping the complete implementation, \nand is bene.cial when we desire an The bene.t of restricting ourselves initially to complete sketches \nis that we can focus on how to synthesize an implementation that conforms to a sketch, without distracting \nourselves with how sketches are resolved. Sketch resolution, which synthesizes the de\u00adtails missing in \na sketch, will be the focus of the second step. Our sketching constructs provide support for several \nimportant implementation patterns: implementation of an af.ne .lter, and in particular of permutations, \nas a sequence of steps; restructuring of pipelines and splitjoins; and implementation of .lters with \ntable lookups. We explain sketching on the problem of permutation de\u00adcomposition. Section 5.1 then explains \nhow we ef.ciently resolve sketches by means of combining search with constraint solving. In Sections \n5.2 4, we discuss sketching for the remaining implemen\u00adtation patterns. Complete sketches To motivate \nthe de.nition of the sketch, it helps to recall that we view the synthesis of a bit-streaming im\u00adplementation \nas a process of decomposing a data.ow program into Low-Level form; the base compiler performs one such \ndecompo\u00adsition. It is thus natural to view the sketch as a constraint on the shape of the decomposed \nprogram. We allow sketches to impose constraints at an arbitrary stage in the decomposition: constraining \nan early stage has the effect of sketching high-level steps of the implementation algorithm (e.g., that \nwe want to pack bits within words .rst), while constraining later stages sketches .ner details (e.g., \nhow to manipulate bits within a word). A key research question is what form these constraints on the \ndecomposition should take so that the sketch is both concise and natural to express. To obtain conciseness, \nwe rely on the base com\u00adpiler to perform most of the decomposition. The base compiler per\u00adforms a .xed \ndecomposition sequence, which permits the program\u00admer to anticipate the data.ow programs created throughout \nthe de\u00adcomposition, which in turn enables him to sketch these programs. The base compiler leads to conciseness \nbecause the programmer will control the compiler (with a sketch) only when its base algo\u00adrithm would \nmake a poor decoposition transformation. The question now is how to override the base compiler with a \nsketch while making it natural for the programmer to express the sketch. Our solution is to express sketches \nas rewrite rules; these rewrite rules will extend the set of rules employed by the base compiler. It \nmay seem awkward to sketch the desired implementation with a rewrite rule, but to the programmer a sketch \nlooks just like a program. Speci.cally, a complete sketch is a StreamIt program P that implements some \npermutation f. This program serves as a sketch in the following way: when the decomposition encounters \na leaf .lter with a permutation f, the .lter is not decomposed using the base rewrite rules; instead, \nit is replaced with the program P . In effect, the leaf .lter is rewritten with the AST of the program \nP . A compiler that consults the sketches in such a way is called sketching compiler. As an example, \nconsider the complete sketch in Figure 2(d). The StreamIt version of this complete sketch is below. The \n.lter Stage1 implements the .rst stage of the pipeline in the .gure; the other two stages are analogous. \nTo understand the code, recall that the .rst pop() reads the left-most bit in the pictured word. If the \ncode looks too complicated, note that the programmer actually writes the simpler proper sketch shown \nbelow. bit->bit pipeline LogShifter { add Stage1(); add Stage2(); add Stage3(); } implementation that \nsketching does not support, e.g., when one wants to decompose a general af.ne .lter in a way not expressible \nin our domain algebra. bit->bit filter Stage1 { work push 16 pop 16 { // lines below either copy or drop \na bit // or shift a group of bits by one position push(pop()); push(pop()); pop(); push(pop()); push(pop()); \npush(0); push(pop()); push(pop()); push(pop()); pop(); push(pop()); push(pop()); push(0); push(pop()); \npush(pop()); push(pop()); pop(); push(pop()); push(0); } } ... Although this StreamIt program has \nstructurally three pipeline stages, it implements the one-stage permutation shown in Fig\u00adure 2(b); its \nequivalence is provable using the Product Equivalence rules in Figure 5. Figure 2 also shows how the \nsketching compiler uses the sketch: the reference program shown in Figure 2(a) is de\u00adcomposed using base \nrules until one of the AST leaves is a .lter with the function in Figure 2(b). At this point, this .lter \nnode is rewritten into the one shown in Figure 2(d). After the sketch is ap\u00adplied, the compiler will \ncontinue its base decomposition, breaking down each stage of the pipeline into machine instructions using \nthe rule IDECOMP de.ned in Section 4. Note that in order take full ad\u00advantage of the log-shifter, the \nimplementation of DropThird should pack bits within a word before packing them across words. This is \nalso expressed with a sketch, which we omit for lack of space. Figure 6 shows that to extend the base \ncompiler into a sketching compiler, it suf.ces to perform all applicable sketches before a base rewrite \nrule is applied; this is done in the function APPLY-SKETCH. A careful reader has by now observed that \nmalformed sketches may prevent termination of the sketching compiler. Consider a sketch that decomposes \na .lter f into a pipeline PL(f, identity); such a sketch can be applied inde.nitely. Our current solution \nis to specify the position in the AST where each sketch should be applied. In the future, we plan to \nanalyze the sketches. Proper Sketches Informally, proper sketches differ from com\u00adplete ones in that \nthey omit some implementation details. For\u00admally, we de.ne proper sketches as non-deterministic StreamIt \npro\u00adgrams with the choice operator * . A non-deterministic program may compute one of several functions, \npotentially a different one for each of its executions. The process of resolving a sketch thus amounts \nto selecting the execution that computes the desired func\u00adtion f (if such an execution exists). We call \nthis process deter\u00adminization to function f. In other words, the deterministic portion of the sketch \nis what the implementation must adhere to; the rest is synthesized. To make it work with proper sketches, \nwe generalize the sketch\u00ading compiler slightly: when the compiler is about to decompose a .lter with \na permutation f, it looks not for a complete sketch that implements f but instead for a proper sketch \nwhose set of non\u00addeterministic executions includes f; if such a sketch exists, it is determinized to \nf and applied as if it was a complete sketch. As an example, consider the proper sketch in Figure 2(c). \nThe non-deterministic StreamIt program equivalent to this sketch is a Note that the complete sketch we \ngave above corresponds to one possible execution of this non-deterministic program. The set of all possible \nexecutions implement a generic version of the log-shifter that shifts, in the .rst stage, an unspeci.ed \nsubset of bits to the left by one position and copies the remaining bits; the remaining two stages are \nanalogous. The proper sketch is already more concise than the complete sketch, but the shifting pattern \nexpressed in the non-deterministic program is so common that we developed a small sketching lan\u00adguage \nto express it even more concisely. The proper sketch in this language is shown below. The meaning of \nthe sketch is that a per\u00admutation .lter is to be decomposed into a pipeline of three .lters, where the \n.rst pipeline shifts a subset of bits from the 1:16 range by either zero bits or by one bit; similarly \nfor the other pipeline stages. The language allows us to express only a restricted set of non-deterministic \npatterns, so it is not as expressive as the full non\u00addeterministic StreamIt would be, but this is what \nwill allow us to control the combinatorial explosion in the search space. SketchDecomp[ [shift(1:16 \nby 0 || 1)], // SketchedStage1 [shift(1:16 by 0 || 2)], // SketchedStage2 [shift(1:16 by 0 || 4)] // \nSketchedStage3 ]; Recall that resolving a sketch amounts to .nding an execution of the non-deterministic \nprogram that implements the desired func\u00adtion. A straightforward way to resolve a sketch is a brute-force \nsearch over all possible executions, but there are 23*16 of them for the non-deterministic pattern for \nthe 16-bit log-shifter given above (25*64 for a 64-bit version). To make the search feasible, we need \nto take advantage of the algebraic structure of the permutations to reduce the search space to a manageable \nsize. To do this, we sup\u00adport a restricted class of sketches; in particular, we support sketches expressed \nin the sketching language described in the next subsec\u00adtion. 5.1 Sketching Decompositions of Permutations \nWe present next the algorithm for resolving sketches that decom\u00adpose a permutation into a pipeline of \n(simpler) permutations. Our approach is to encode the desired pipeline as a vector of distances traveled \nby bits in a pipeline stage; these distances are our un\u00adknowns. We will express the sketch using two \nkinds of constraints on the decomposition vector: linear and non-linear; the former are solvable with \nlinear algebra, the latter are not. We will .rst solve the linear constraints, leaving us with a reduced \nlinear space of pos\u00adsible solutions. We then search for solutions in this space that also satisfy the \nnon-linear constraints. The search is exhaustive, but we take advantage of the linear properties of the \nspace to reduce it as much as possible. If the search space remains too large for a prac\u00adtical search, \nthe user is asked to add more details to the sketch to further constrain the space (this was not necessary \nin our experi\u00adments). Suppose a permutation consumes and produces a vector of bits numbered 1 to N. We \nexpress the permutation as a vector pipeline of three .lters as follows. (x1,x2,...,xN ) with xi = p \n di - p si bit->bit filter SketchedStage1 { where p work push 16 pop 16 { di is the .nal position of \nbit i and p si is the initial position while(*) { of bit i. Since bits are labeled by their initial \npositions, we have p si = i. A decomposition of this permutation into the desired k\u00ad switch (*) { case \nCopyOneBit: push(pop()); break; stage pipeline de.nes the decomposition vector YY: case ShiftBits: \nY11 pop(); while (*) push(pop()); push(0); Y = (y1,y 122 2 kkkN ) 2 ,...,y N ,y 1 ,y 2 ,...,y ,...,y \n1 ,y 2 ,...,y N } j-1 i ji ji , where p ji is the position of bit i at the end - p } 0 ki = p di \n. Once the constraints are si } i ji } The next step is to translate the sketch into constraints over \nthe decomposition vector YY. In our sketching language, a sketch can be built from four kinds of constraints. \nFor each stage of the sketched pipeline, the programmer can specify any combination of the four types \nof constructs. For each sketching construct, we give below its translation into constraints over YY. \n1. shift(b1,...,bM by j). Shifts by j positions all bits in the set {b1,...,bM }. The set can be expressed \nas a range a:b. The bits are identi.ed by their positions before stage 0 of the pipeline. Generated constraints: \nybk i = j, where k is the stage where the constraint appears and i .{1,...,M}. 2. shift(b1,...,bM by \n?). Shifts all bits in {b1,...,bM }by the same amount h, where h is unspeci.ed in the sketch. Generated \nconstraints: y k = y k , where i .{1,...,M -1}.  bi bi+1 3. pos(bi, p). Requires that bit bi will be \nin position p after k jjj-1 stage k, i.e., p = p. Since y= p- p, this constraint bi i ii translates to \nk0 j p + y= p. bi bi j=1 4. shift(b1,...,bM by a I b). Shifts each bit in {b1,..., bM } by either a or \nb positions. (Note that bits do not need to all move by the same amount.) Generated constraints: ybk \ni . {a, b}. This is a non-linear constraint. To ensure that the decomposition is semantics preserving, \nwe add two other constraints: 5. The .nal position of each bit must agree with the .nal position of the \nbit in the permutation being decomposed. This constraint is a special case of constraint (3), and is \nhandled the same way. 6. No two bits can reside in the same position at the end of any stage (otherwise, \nthey would overwrite each other). This constraint is non-linear.  The linear constraints will lead to \na matrix equation of the form S * YY= TY, where S is matrix and TYis a vector representing generated \nlinear constraints. This equation is solved in polynomial time using Gaussian elimination over the integers. \nThe result will be a particular solution ZYand a set of decomposition vectors of VY1, . . . , VYm such \nthat the decomposition vector YYcan be obtained as a linear combination of ZYand VYi: m YYY = Z + ai \n* VYi (1) i=1 Any such YYsatis.es our linear constraints. The goal now is to .nd a set of ai that makes \nYYsatisfy the non-linear constraints as well. We will show in detail how this is done for the constraints \nof type 4, and then outline handling of constraints of type 6. The key idea is to view Equation 1 as \na matrix equation by letting V be the matrix whose columns are vectors VYi. Then, we have V * aY= YY- \nZY. This equation has two unknowns, aYand YY. We can choose vec\u00adtor aYarbitrarily, but some of the entries \nof YYare limited by con\u00adstraints of type 4. Now, because at this stage we are only interested in solving \nthe non-linear constraints of type 4, we eliminate from the above equation rows corresponding to yji \non which we don t have constraints of type 4. We call the new matrix V ' and the new vectors YY' and \nY. Z'' Y' - Y' V * aY= YZ(2) Once we have this equation, we have two choices. One alter\u00adnative is to \nsearch the space of aY s until we .nd an aYthat makes the resulting YYsatisfy all the non-linear constraints, \nboth of type 4 and 6. Another alternative is to try the different alternatives YY' permit\u00adted by the \ntype 4 constraints until we .nd YY' that is in the column span of V '. In this case, we know from basic \nlinear algebra that YY' is in the column span of V ' as long as (V ' *V '+ -I)*(YY' -ZY')= 0, where V \n'+ is the pseudoinverse V '+ =(V 'T * V ')-1 * V 'T . This implies ' A * YY= BY(3) where A =(V ' * V \n'+ - I) and BY= A * ZY'. ki ki For each y in YY' we have a set of choices of the form y = bj bj (a or \nb or ...) (remember we eliminated those entries of YYfor which we didn t have constraints of type 4). \nThus, we need to search through all these choices until we .nd a set of choices that satisfy Equation \n3. In principle, we may have to explore all possible combinations of the possible values for each of \nthe y ki , bj but in practice, StreamBit .rst puts A in reduced row echelon form (rref ). In most cases \nthis allows they y ki to be isolated into bj small clusters that can be searched independently, reducing \nthe exponential blowup. For example, in the case of the sketch for DropThird, the rref reduction means \nthat instead of having to search a 23*16 search space, we have to do 16 searches on spaces of size 23 \n. Once the search is done, we have a YY' vector that we can use to .nd a set of solutions aYto Equation \n2. Now, given an aYthat satis.es Equation 2 for a YY' found through this process will make V *aY+ZYsatisfy \nall the constraints of type 1 through 5, so now we have to pick one of these aY s that also satis.es \nconstraint 6. Note, however, that at this point we are only searching among those decomposition vectors \nthat have satis.ed constraints 1 through 5.  5.2 Restructuring Restructuring transformations replace \na sub-tree in the AST with an equivalent but structurally different sub-tree. For example, re\u00adstructuring \nmay reorder .lters in a pipeline, hoist .lters out of splitjoins, sink them into splitjoins, or coalesce \nseveral leaf .lters into a single leaf .lter. Restructuring transformations are typically enabling transformations \nthat lead to dramatic code improvements through subsequent permutation decomposition. Sketching helps \nin performing restructuring by avoiding the need to specify the values of matrices for .lters composing \nthe new .lter structure. For ex\u00adample, in our implementation of DES, we moved a .lter across a joiner, \nand sketching automatically computed the compensating .lter that had to be inserted into the other input \nof the joiner.  5.3 Sketching Decompositions of Af.ne Functions It turns out that (sketches of) permutations \nare useful when imple\u00admenting the more general af.ne .lters. In this setting, permutations are often \nused to ef.ciently pack bits into words with the goal of fully exploiting word-level parallelism. Consider \na xor .lter with the matrix [1 1]. This .lter takes two consecutive bits from the input stream and xors \nthem to produce a single output bit. To implement this .lter ef.ciently on a machine with a w-bit word, \nwe want to permute 2 * w consecutive bits of the input stream such that all odd bits are in the .rst \nword and all even bits are in the second; after this transformation, the two words can be xor-ed with \nfull word\u00adlevel parallelism. This permutation can be achieved in three steps: .rst, using restructuring, \ninsert a 2 * w-bit identity .lter in front of the [1 1] .lter. Next, the following sketch shuf.es bits \nas desired using log\u00adshifting; speci.cally, the bits will be placed as desired at the entry to the last \nstage, which is unspeci.ed in the sketch. After sketching, this stage will shuf.e bits back into the \noriginal position so that the whole sketched pipeline remains an identity. In the last step, use restructuring \nto merge the last stage of the pipeline with the (a) (b) Figure 8. (a) A truncated version of the DES \nIP permutation. (b) Same permutation decomposed through sketching into a pipeline exposing two identical \npermutations in the second stage, which can now be implemented using a single table, reducing table storage \nfour-times. [1 1] .lter. This step will modify the [1 1] .lter to operate on the transformed stream. \nSketchDecomp[ [shift(1:2*w by 0 || 1 || -1)], [shift(1:2*w by 0 || 2 || -2)], [shift(1:2*w by 0 || \n4 || -4)], [shift(1:2*w by 0 || 8 || -8)], [shift(1:2*w by 0 || 16 || -16), pos(1:2:2*w to 1:w), pos(2:2:2*w \nto w+1:2*w)], [] ];  5.4 Table Conversion Tables play an important role in ef.cient cipher implementations. \nIn particular, a .lter with n input bits and m output bits can be implemented as a lookup in a table \nwith 2n entries of m-bit values. To reduce the table size, the .lter can be implemented using k tables \nwith 2n/k entries each using transformations based on the column equivalence from Figure 5. When .lter \nproperties permit, table conversion can be further optimized, with great help from sketching. Consider \nthe IP per\u00admutation from the DES cipher shown in Figure 8(a). With sketch\u00ading, this permutation can be \ndecomposed into a two-stage pipeline, shown in Figure 8(b), which the programmer obtained as follows: \nafter examining the IP permutation, he observed certain regularity in how IP shifts bits, which lead \nhim to suspect that IP is a compo\u00adsition of two narrower permutations. Guided by the observed regu\u00adlarity, \nhe sketched the .rst pipeline stage and the compiler produced the second stage. The result of the sketch \nis an ef.cient implemen\u00adtation: the .rst stage is very ef.cient; the second stage contains two table \nlookups that are not only narrower but also identical. As a re\u00adsult, the total table size was reduced \nfour-fold, producing a speedup of over 65% on an IA64 machine.  6. Evaluation In this section, we quantify \nthe productivity and performance re\u00adwards of sketching as compared to manually tuning programs writ\u00adten \nin C. We also show that the performance of a sketched imple\u00admentation is competitive with that of heavily \noptimized implemen\u00adtations for a couple of well known ciphers. 6.1 User Study We held a user study to \nevaluate the productivity and performance rewards attributed to sketching in general and StreamBit in \npartic\u00adular. Speci.cally, we were interested in two questions. Time to .rst solution. How quickly can \na reference program be developed and debugged by a programmer unfamiliar with the StreamIt data.ow programming \nlanguage? In summary, we found that novice StreamIt programmers develop the .rst working solution faster \nthan C programmers do (in C). Performance of base compiler. How good is the code gen\u00aderated from the \nreference program by the base compiler? In other words, can the base compiler compete with rapidly devel\u00adoped \nand tuned C code? In summary, we found that the base\u00adcompiled StreamBit code runs at least twice as fast \nas the C code, which took nearly twice as long to tune. 6.1.1 Methodology The study invited participants \nto implement a non-trivial cipher based on Feistel rounds. The cipher consisted of an initial permu\u00adtation \nof the bits in the input message, followed by three rounds of key mixing operations and a non-linear \ntransformation. The cipher is formally described by the following equations: X0 = IP(M) Xif +1 = Xib \n. F (Xif ,Ki) bf X= X i+1 i F (Xi,Ki)= L(Ki . Pi(Xi)) where M is the input message, IP is the application \nof an initial bit permutation, F performs the key mixing subject to some permuta\u00adtion P , and L applies \na non-linear transformation. Each Xi is split into a front half Xf and a back half Xib . i We recruited \ntwo sets of users: one set implemented the cipher in C and the other group implemented the cipher in \nStreamBit3. In all, there were six C participants of which .ve .nished the study and submitted working \nciphers. On the StreamBit side, there were seven participants of which four submitted working ciphers4. \nThe study participants were all well-versed in C but none had any experience with StreamBit prior to \nthe study; although they were provided with a short tutorial on StreamBit on the day of the study. C \nparticipants were also provided with a short tutorial, this one on well known (bit-level) optimizations, \nand we encouraged them to apply any other optimization ideas they could think of. In the case of C participants, \nwe did not restrict the number of submissions that a participant could make, and instead encouraged performance \ntuning of the initial solution.  6.1.2 Results In Figure 9(a), we report the results from our user study. \nThe x-axis represents development time (in hours), and the y-axis represents the performance of the ciphers \nin units of encrypted-words per mi\u00adcroseconds. Each point on the graph represents the development time \nand performance of a single participant; the C users have mul\u00adtiple points per participant connected \nby solid lines showing their progress over time. It is readily apparent that the StreamBit partic\u00ad 3 \nThe programming language used in StreamBit is StreamIt with a few extensions as detailed in Section 2. \nSolely for the sake of clarity will we refer to the language as StreamBit. 4 Users who left the study \nearly chose to do so due to personal constraints.  (a) (b) Figure 9. StreamBit vs. C : performance as \na function of development time. (a) Comparison of .rst solutions for StreamBit and C implementations. \n(b) Performance improvement through sketching. ipants spent between two and four hours implementing the \ncipher and achieved better performance compared to the C participants. We also note that all but one \nof the C participants tried to tune the performance of their ciphers. The C participants spent between \none and three hours optimizing their implementations, and while some improved their performance by 50% \nor more, the StreamBit ciphers were still two and a half times faster. The results highlight the complexity \nof tuning bit-level applications, and demonstrate the challenge in understanding which optimizations \npay off. The data also suggest that the scope of optimizations a program\u00admer might attempt are tied to \nthe implementation decisions made much earlier in the design process. Namely, if an optimization re\u00adquires \nmajor modi.cations to the source code, a programmer is less likely to try it, especially if the rewards \nare not guaranteed. The C implementations were compiled with gcc version 3.3 and optimization level -O3 \n-unroll-all-loops. The base StreamBit compiler produced low-level C code. This C code was subsequently \ncompiled with gcc and the same optimization .ags. All resulting executables were run on an Itanium2 processor. \nOur sample of users is relatively small, so it s hard to draw very de.nitive judgments from it, but in \nterms of the two questions we wanted to answer, we can see that it is possible for someone who has never \nused StreamIt to produce a working solution in less time than it would take an experienced programmer \nworking in C. We can also see that the performance of the base compilation algorithm is very good compared \nwith the performance of handwritten C code, even after it has been tuned for several hours.  6.2 Bene.ts \nof Sketching The user study showed that the StreamBit system can be a good choice when developing prototypes \nof ciphers, because it allows for the code to be developed faster, and the code is actually of much better \nquality than code produced by hand in a comparable amount of time. Next, we wanted to evaluate a sketched \nimplementation with a heavily optimized MiniCipher from the user study and also with widely-used cipher \nimplementations. 6.2.1 Optimizing the MiniCipher The user study also provided us with an opportunity \nto evaluate the separation of concerns afforded by sketching, and the potential for performance improvement \nin a benchmark more realistic than DropThird. First, we assigned a performance expert (one of the authors) \nto select one of the StreamBit reference programs written in the user study, and sketch for it a high-performance \nimplementation. The sketching expert managed to iterate through ten different im\u00adplementations in four \nhours, tripling the performance of the base\u00adcompiled code, which is a huge improvement considering the \nbase StreamBit implementation was already twice as good as the C implementations from the user study. \nIt is worth noting that this sketching was done with code produced by another developer who had no contact \nwith the performance expert. The performance ex\u00adpert did have a list of implementation ideas to try in \nhis sketches; the same list was available to the user study participants. As a point of comparison, we \nasked another member of our research group to serve as a C performance expert and tune an already working \nC implementation. He was done in just under eight hours, and achieved a performance of eight encrypted-words \nper microsecond. It must be said that of those eight hours, about 3/4 of an hour were spent understanding \nthe reference implementation and the speci.cation. The results from this exercise are reported in Figure \n9(b). The sketching methodology thus affords programmers the abil\u00adity to prototype and evaluate ideas \nquickly, as they are not con\u00adcerned with low-level details and can rest assured that the com\u00adpiler will \nverify the soundness of their transformations. This is in contrast to the C performance expert who must \npay close atten\u00adtion to tedious implementation details lest they introduce errors. As an added advantage, \nprogramming with sketches does not alter the original StreamBit code which therefore remains clean and \nmuch easier to maintain and port compared to the manually tuned C im\u00adplementation. 6.2.2 Implementation \nof Real Ciphers LibDES from OpenSSL We compare StreamBit generated code with a libDES, a widely used \npublicly available implementation of DES that is considered one of the fastest portable implementations \nof DES [21]. LibDES combines extensive high-level transforma\u00adtions that take advantage of boolean algebra \nwith careful low-level coding to achieve very high performance on many platforms. Ta\u00adble 1 compares libDES \nacross different platforms with DES imple\u00admentations produced by StreamBit. We were able to implement \nmost of the high-level optimizations that DES uses, and even a few more that were not present in libDES, \nincluding the one described in Section 5.4. Our code was missing some of the low-level optimizations \npresent in libDES. For example, our code uses lots of variables, which places heavy strains on the register \nallocation done by the compiler, and it assumes the compiler will do a good job with constant folding, \nconstant propagation and loop unrolling. Even with these handicaps, we were able to outperform libDES \non at least one platform. The 17% degradation on Pentium III is mainly due to not implementing a libDES \ntrick that our sketching currently does not support. Finally, it is worth noting that whereas the libDES \ncode is extremely hard to read and understand, the StreamBit reference program reads very much like the \nstandard [9]. processor P-IV P-III IA64 Solaris IBMSP performance 0.90 0.83 1.06 0.91 1.07 Table 1. \nComparison of sketched DES with libDES on .ve proces\u00adsors. Performance is given as ratio of throughputs; \nsketched DES was faster on IA64 and IBM SP. Serpent Serpent is considered the most secure of the AES \n.nal\u00adists5. Serpent is particularly interesting from the point of view of sketching because of the way \nit was designed. The cipher is de.ned in terms of bit operations including permutations, as well as lin\u00adear \nand non-linear functions. However, all of these functions were de.ned in such a way that a particular \ntransformation known as bit-slicing, together with some additional algebraic manipulation, would produce \na very ef.cient implementation of the cipher for regular 32-bit machines [2]. As part of their submission, \nthe Serpent team developed both a reference implementation using the bit-level de.nition as well as an \noptimized version of the cipher. Table 2 shows our results for Serpent. It is worth pointing out that \nthe level of abstraction of the StreamBit code is comparable to that of the bit-level reference implementation, \nyet the base compila\u00adtion algorithm produced code that was an order of magnitude faster than the C reference \nimplementation. This is not a small matter, considering that the reference implementations are used to \ngenerate correct outputs for large sets of inputs. The process of generating reference outputs can take \nseveral hours, and is on the critical path for testing optimized implementations. By simply sketching \nthe bit-slicing transformation, we were able to achieve half of the performance of the heavily optimized \nimplementations. We believe that the other half of performance can be had by implementing in our compiler \na smarter conversion from an arbitrary boolean function de.ned as a table-lookup into one de.ned as a \nboolean expression, a transformation used as part of bit-slicing. Furthermore, on the IA64, we were able \nto get 90% of the performance of the hand-optimized implementation by using 64-bit-speci.c optimizations. \nGranted, the optimized AES Serpent did not use 64-bit-speci.c optimizations, but it speaks of the .exibility \nof our approach that we were able to modify our sketch to produce 64-bit-speci.c optimizations by changing \nonly a single line in the sketch. processor reference base StreamBit bit-sliced StreamBit 64-bit StreamBit \nIA64 0.003 0.13 0.478 0.90 P-IV 0.003 0.08 0.62 N/A Table 2. Several Serpent implementations compared \nto the of.cial optimized Serpent. Performance is given as ratio of throughputs; sketched Serpent achieved \n62% of of.cial performance despite infrastructure limitations.   7. Related Work Our presentation of \nSketching was inspired by some of the work on partial programming in the AI community. For example, ALisp \n[3], 5 In 2000, a competition was held to de.ne the new Advanced Encryption Standard, to replace DES. \nSerpent was one of the .nalists, and was widely considered the most secure of the candidates. developed \nby Andre and Russell to program Reinforcement Learn\u00ading Agents is a form of lisp extended with non-deterministic \ncon\u00adstructs. In ALisp, the behavior of the non-deterministic branches is de.ned through learning. Sketches \nin StreamBit can also be thought of as non-deterministic descriptions of an algorithm, but their behavior \nis determined not through learning, but by matching them with the reference program. The sketch resolution \nproblem is a constraint satisfaction prob\u00adlem similar to those studied by the constraint programming \ncom\u00admunity [11]. The idea of separating the task description from the implemen\u00adtation speci.cation has \nbeen explored before. Ennals, Shart and Mycroft [7], for example, have built a system for programming \nnet\u00adwork processors that allows the user to describe the task in a high\u00adlevel domain-speci.c language \nand then specify an implementa\u00adtion by applying a series of semantics preserving transformations. Their \ntransformations, however, involve no sketching, and have to be fully speci.ed. Aspect-Oriented Programming \n(AOP) aims at supporting the programmer in cleanly separating concerns and aspects from each other, by \nproviding mechanisms that make it possible to abstract and compose them to produce the overall system \n[14]. Our ap\u00adproach can be understood as a form of AOP, where the algorithm speci.cation and the performance \nimproving transformations are the two aspects we are dealing with. There have been other efforts at applying \nAOP to restricted application domains, for example Ir\u00adwin et. al. demonstrate the use of AOP in the domain \nof sparse matrix computations [12]. Ef.ciently compiling domain-speci.c languages to achieve high-quality \nimplementations without user intervention has been an area of active research for a number of years. \nPadua et. al. have been very successful in producing high-quality code from MAT-LAB through the use of \naggressive type and maximum matrix size inference [1]. Kennedy et. al. have worked on an approach called \ntelescoping languages. The idea is that in many scripting languages, domain\u00adspeci.c abstractions are \nprovided through libraries. The telescop\u00ading language approach is to preprocess those libraries to create \nspe\u00adcialized versions of them to allow for aggressive optimization of the programs that use them without \nhaving to incur the cost of exten\u00adsive interprocedural analysis at compile time [5, 13]. One approach \nthat has recently gained popularity in the high\u00adperformance community has been the use of search to .nd \nopti\u00admal implementations for important kernels. The idea is to search through a suitably restricted implementation \nspace by actually gen\u00aderating code for the possible implementations and either run them directly on the \nmachine, or do very detailed simulation. For ex\u00adample, FFTW [10] uses a planner to try many different \nexecution plans for an FFT at run-time and .nd the best one. SPIRAL [18] is another example of the search \nbased approach; it generates high\u00adperformance DSP kernels by searching the space of possible im\u00adplementations, \ntaking advantage of the structure of the algorithm and implementation space to speed up the search. Demmel \net. al. [6] also use search based methods to generate dense and sparse linear algebra kernels. Wu, Weaver \nand Austin [20] developed an architecture aimed at executing ciphers, and they also used a search based \nmethod to derive optimal implementations of the ciphers for their architecture. However, the search was \nsimply to .nd an opti\u00admal way to map a data.ow graph for the already optimized ciphers into machine instructions. \nWe believe sketching complements the search based methods, because instead of having to restrict the \nspace of implementations a priori to make the search tractable, the sketch encodes knowledge the user \nhas about the best way to implement an algorithm, allowing the search to proceed faster. Finally, our \nwork builds very heavily on StreamIt [15, 19]. The StreamIt compiler automatically identi.es linear .lters, \nand performs many optimizations targeted towards DSP applications. The StreamIt language itself, traces \nits roots to the work on Syn\u00adchronous Data Flow by Edward Lee and his group since the 80 s [16, 4]. \n8. Conclusion In programming by sketching, the developer outlines the imple\u00admentation strategy and the \ncompiler .lls in the missing detail by ensuring that the completed sketch implements the reference pro\u00adgram, \nwhich serves as a full behavioral speci.cation. In this paper, sketching is explored in the context of \nbit\u00adstreaming. We believe that sketching is also applicable in other domains where a domain algebra for \nsemantics-preserving restruc\u00adturing of programs is available. One atractive candidate is sparse matrix \ncomputation. Depending on the development setting (and the point of view), bene.ts of sketching can take \ndifferent forms. First, sketching al\u00adlows collaboration between a domain expert (e.g., a crypto expert) \nand a performance expert who understands the processor and a lit\u00adtle about the domain algebra, such as \nbit permutations. While the former speci.es the crypto algorithm and keeps modifying it, the latter provides \nan ef.cient implementation by preparing a separate sketch. Via separation of concerns, sketching thus \nallows collabo\u00adration of programmer roles. An alternative view is that sketching is a method for rapid \nprototyping of an effective domain-speci.c compiler. Rather than implementing an analysis and a transformation, \nwhich may not be economical for a domain-speci.c compiler, we give a sketch that is .lled in according \nto the provided reference program. While a sketch is not as generally applicable as an optimization, \nit is easy to port to another reference program; it is also tailored to a given reference program, which \ngives it unique power. Acknowledgments This work is supported in part by the National Science Foundation, \nwith grants CCF-0085949, CCR-0105721, CCR-0243657, CNS\u00ad0225610, CCR-0326577, an award from University \nof California MICRO program, the Okawa Research Award, as well as donations from IBM and Intel. This \nwork has also been supported in part by the Defense Advanced Research Projects Agency (DARPA) under contract \nNo. NBCHC020056. The views expressed herein are not necessarily those of DARPA or IBM. The StreamIt project \nis supported by DARPA grants PCA\u00adF29601-03-2-0065 and HPCA/PERCS-W0133890; NSF awards CNS-0305453 and \nEIA-0071841; and the MIT Oxygen Alliance. We would like to thank Vivek Sarkar for his invaluable help \nin initiating this project and organizing the user study. Our gratitude also goes to the many user study \nsubjects who suffered through the glitches of our infrastructure. We would also like to thank Brian Fields, \nDave Mandelin, Bill Thies and Renju Thomas for helping with preparations for the user study. References \n[1] G. Almasi and D. Padua. Majic: Compiling matlab for speed and responsiveness. In Proceedings of ACM \nSIGPLAN Conference on Programming Language Design and Implementation, pages 294 303, June 2002. [2] R. \nAnderson, E. Biham, and L. Knudsen. Serpent: A proposal for the advanced encryption standard. The implementation \nwe tested can be found at http://www.cl.cam.ac.uk/ rja14/serpent.html. [3] D. Andre and S. Russell. Programmable \nreinforcement learning agents. Advances in Neural Information Processing Systems, 13, 2001. MIT Press. \n[4] J. Buck, S. Ha, E. A. Lee, and D. G. Messerschmitt. Ptolemy: A framework for simulating and prototyping \nheterogeneous systems. Int. Journal of Computer Simulation, 4:155 182, April 1994. special issue on Simulation \nSoftware Development . [5] A. Chauhan, C. McCosh, and K. Kennedy. Automatic type-driven library generation \nfor telescoping languages. In Proceedings of SC: High-performance Computing and Networking Conference, \nNov. 2003. [6] J. Demmel, J. Dongarra, V. Eijkhout, E. Fuentes, A. Petitet, R. Vuduc, C. Whaley, and \nK. Yelick. Self adapting linear algebra algorithms and software. Proceedings of the IEEE, 93(2), 2005. \n[7] R. Ennals, R. Sharp, and A. Mycroft. Task partitioning for multi-core network processors. In Compiler \nConstruction, Edinburgh, Scotland, April 2005. [8] N. Ferguson and B. Schneier. Practical Cryptography. \nWiley Publishing Inc, 2003. [9] Data encryption standard (des). U.S. DEPARTMENT OF COM\u00adMERCE/National \nInstitute of Standards and Technology, December 1993. http://www.itl.nist.gov/.pspubs/.p46-2.htm. [10] \nM. Frigo and S. Johnson. Fftw: An adaptive software architecture for the fft. In ICASSP conference proceedings, \nvolume 3, pages 1381 1384, 1998. [11] P. V. Hentenryck and V. Saraswat. Strategic directions in constraint \nprogramming. ACM Comput. Surv., 28(4):701 726, 1996. [12] J. Irwin, J.-M. Loingtier, J. R. Gilbert, G. \nKiczales, J. Lamping, A. Mendhekar, and T. Shpeisman. Aspect-oriented programming of sparse matrix code. \nIn Proceedings International Scienti.c Computing in Object-Oriented Parallel Environments (ISCOPE), number \n1343 in LNCS, Marina del Rey, CA, 1997. Springer-Verlag. [13] K. Kennedy, B. Broom, A. Chauhan, R. Fowler, \nJ. Garvin, C. Koelbel, C. McCosh, and J. Mellor-Crummey. Telescoping languages: A system for automatic \ngeneration of domain languages. Proceedings of the IEEE, 93(2), 2005. [14] G. Kiczales, J. Lamping, A. \nMendhekar, C. Maeda, C. V. Lopes, J.-M. Loingtier, and J. Irwin. Aspect-oriented programming. In proceedings \nof the European Conference on Object-Oriented Programming (ECOOP), number 1241 in LNCS. Springer-Verlag, \nJune 1997. [15] A. A. Lamb, W. Thies, and S. Amarasinghe. Linear analysis and optimization of stream \nprograms. In ACM SIGPLAN Conference on Programming Language Design and Implementation, San Diego, CA, \nJune 2003. [16] E. A. Lee and D. G. Messerschmitt. Synchronous data .ow. Proceedings of the IEEE, September \n1987. [17] M. Morgan. http://www.schneier.com/blow.sh-bug.txt. [18] M. P\u00a8uschel, B. Singer, J. Xiong, \nJ. Moura, J. Johnson, D. Padua, M. Veloso, and R. Johnson. Spiral: A generator for platform\u00adadapted libraries \nof signal processing algorithms. Journal of High Performance Computing and Applications, accepted for \npublication. [19] W. Thies, M. Karczmarek, and S. Amarasinghe. Streamit: A language for streaming applications. \nIn International Conference on Compiler Construction, Grenoble, France, Apr. 2002. [20] L. Wu, C. Weaver, \nand T. Austin. Cryptomaniac: A fast .exible architecture for secure communication. In 28th Annual International \nSymposium on Computer Architecture (28th ISCA 2001), Goteborg, Sweden, June-July 2001. ACM SIGARCH / \nIEEE. [21] E. Young. http://www.openssl.org. libDES is now part of OpenSSL.  \n\t\t\t", "proc_id": "1065010", "abstract": "This paper introduces the concept of <i>programming with sketches</i>, an approach for the rapid development of high-performance applications. This approach allows a programmer to write clean and portable reference code, and then obtain a high-quality implementation by simply <i>sketching</i> the outlines of the desired implementation. Subsequently, a compiler automatically fills in the missing details while also ensuring that a completed sketch is faithful to the input reference code. In this paper, we develop StreamBit as a sketching methodology for the important class of bit-streaming programs (e.g., coding and cryptography).A sketch is a <i>partial</i> specification of the implementation, and as such, it affords several benefits to programmer in terms of productivity and code robustness. First, a sketch is easier to write compared to a complete implementation. Second, sketching allows the programmer to focus on exploiting algorithmic properties rather than on orchestrating low-level details. Third, a sketch-aware compiler rejects \"buggy\" sketches, thus improving reliability while allowing the programmer to quickly evaluate sophisticated implementation ideas.We evaluated the productivity and performance benefits of our programming methodology in a user-study, where a group of novice StreamBit programmers competed with a group of experienced C programmers on implementing a cipher. We learned that, given the same time budget, the ciphers developed in StreamBit ran 2.5x faster than ciphers coded in C. We also produced implementations of DES and Serpent that were competitive with hand optimized implementations available in the public domain.", "authors": [{"name": "Armando Solar-Lezama", "author_profile_id": "81100173160", "affiliation": "University of California, Berkeley", "person_id": "P728828", "email_address": "", "orcid_id": ""}, {"name": "Rodric Rabbah", "author_profile_id": "81100434259", "affiliation": "Massachusetts Institute of Technology", "person_id": "PP14152880", "email_address": "", "orcid_id": ""}, {"name": "Rastislav Bod&#237;k", "author_profile_id": "81100033082", "affiliation": "University of California, Berkeley", "person_id": "P517421", "email_address": "", "orcid_id": ""}, {"name": "Kemal Ebcio&#287;lu", "author_profile_id": "81100654810", "affiliation": "T.J. Watson Research Center, IBM Corporation", "person_id": "P726609", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065045", "year": "2005", "article_id": "1065045", "conference": "PLDI", "title": "Programming by sketching for bit-streaming programs", "url": "http://dl.acm.org/citation.cfm?id=1065045"}