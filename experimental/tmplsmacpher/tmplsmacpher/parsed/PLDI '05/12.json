{"article_publication_date": "06-12-2005", "fulltext": "\n Garbage Collection Without Paging Matthew Hertz Yi Feng Emery D. Berger Department of Computer Science \nUniversity of Massachusetts Amherst Amherst, MA 01003 {hertz, yifeng, emery}@cs.umass.edu Abstract Garbage \ncollection offers numerous software engineering advan\u00adtages, but interacts poorly with virtual memory \nmanagers. Exist\u00ading garbage collectors require far more pages than the application s working set and \ntouch pages without regard to which ones are in memory, especially during full-heap garbage collection. \nThe re\u00adsulting paging can cause throughput to plummet and pause times to spike up to seconds or even \nminutes. We present a garbage collector that avoids paging. This bookmarking collector cooperates with \nthe virtual memory manager to guide its eviction decisions. Using sum\u00admary information ( bookmarks ) \nrecorded from evicted pages, the collector can perform in-memory full-heap collections. In the ab\u00adsence \nof memory pressure, the bookmarking collector matches the throughput of the best collector we tested \nwhile running in smaller heaps. In the face of memory pressure, it improves throughput by up to a factor \nof .ve and reduces pause times by up to a factor of 45 over the next best collector. Compared to a collector \nthat con\u00adsistently provides high throughput (generational mark-sweep), the bookmarking collector reduces \npause times by up to 218x and im\u00adproves throughput by up to 41x. Bookmarking collection thus pro\u00advides \ngreater utilization of available physical memory than other collectors while matching or exceeding their \nthroughput. Categories and Subject Descriptors D.3.4 [Processors]: Mem\u00adory management (garbage collection); \nD.4.2 [Storage Manage\u00adment]: Virtual memory General Terms Algorithms, Languages, Performance Keywords \nbookmarking collection, garbage collection, genera\u00adtional collection, memory pressure, paging, virtual \nmemory 1. Introduction Garbage collection is a primary reason for the popularity of lan\u00adguages like \nJava and C# [45, 52]. However, garbage collection requires considerably more space than explicit memory \nmanage\u00adment [56, 31]. The result is that fewer garbage-collected applica\u00adtions .t in a given amount of \nRAM. If even one garbage-collected application does not .t in available physical memory, the garbage \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n05, 12 15 June 2005, Chicago, Illinois, USA Copyright 2005 ACM 1-59593-056-6/05/0006...$5.00. collector \nwill induce paging, or traf.c between main memory and the disk. Because disk accesses are approximately \nsix orders of magnitude more expensive than main memory accesses, paging signi.cantly degrades performance. \nPaging can also lead to pause times lasting for tens of seconds or minutes. Even when an application \ns working set .ts in main memory, collecting the heap may induce paging. During full-heap collec\u00adtions, \nmost existing garbage collectors touch pages without regard to which pages are resident in memory and \nvisit many more pages than those in the application s working set. Garbage collection also disrupts information \nabout the reference history tracked by the vir\u00adtual memory manager. While this phenomenon is widely known, \nprevious work has at\u00adtacked it only indirectly. For example, generational garbage collec\u00adtors concentrate \ntheir collection efforts on short-lived objects [37, 49]. Because these objects have a low survival rate, \ngenerational collection reduces the frequency of full-heap garbage collections. However, when a generational \ncollector eventually performs a full\u00adheap collection, it triggers paging. This problem has led to a number \nof workarounds. One stan\u00addard way to avoid paging is to size the heap so that it never ex\u00adceeds the size \nof available physical memory. However, choosing an appropriate size statically is impossible on a multiprogrammed \nsystem, where the amount of available memory changes. Another possible approach is overprovisioning systems \nwith memory, but high-speed, high-density RAM remains expensive. It is also gener\u00adally impractical to \nrequire that users purchase more memory in or\u00adder to run garbage-collected applications. Furthermore, \neven in an overprovisioned system, just one unanticipated workload exceed\u00ading available memory can render \na system unresponsive. These problems have led some to recommend that garbage collection only be used \nfor small applications with minimal memory foot\u00adprints [46]. Contributions: This paper introduces bookmarking \ncollection (BC), a garbage collection algorithm that virtually eliminates gar\u00adbage collector-induced \npaging. Bookmarking collection records summary information ( bookmarks ) about outgoing pointers from \npages that have been evicted to disk. Once a page is evicted from memory, BC does not touch it unless \nthe application itself makes it resident. Instead of visiting evicted pages, BC uses bookmarks to assist \ngarbage collection. These bookmarks, together with BC s heap organization and cooperation with the virtual \nmemory man\u00adager, allow BC to perform full-heap, compacting garbage collection without paging, even when \nlarge portions of the heap have been evicted. Because bookmarking necessarily sacri.ces some connec\u00adtivity \ninformation and could thus prevent garbage from being re\u00adclaimed (see Section 3.5), BC includes a fail-safe \nmechanism that preserves completeness by discarding bookmarks in the unlikely event of heap exhaustion. \n Figure 1. An example of bookmarking collection. We have implemented BC in Jikes RVM [7, 8] using the \nMMTk toolkit [19]. The bookmarking collector relies on some additional operating system support, which \nconsists of a modest extension to the Linux virtual memory manager (approximately six hun\u00addred lines \nof code). Without memory pressure, BC s performance matches that of generational mark-sweep (GenMS), \na collector that consistently provides high throughput [18]. Under memory pres\u00adsure, bookmarking collection \noutperforms the next best garbage collector we tested by a factor of .ve, and reduces pause times by \na factor of 45. Compared to GenMS, bookmarking collection yields up to a 218-fold reduction in pause \ntimes and improves throughput by up to 41x. Bookmarking collection thus provides greater utiliza\u00adtion \nof available physical memory than other collectors. The paper is organized as follows: Section 2 provides \nan overview of bookmarking collection, and Section 3 describes the bookmarking garbage collector in detail. \nSection 4 presents some key implementation details, including our extensions to the Linux virtual memory \nmanager. Section 5 presents empirical results com\u00adparing the performance of bookmarking collection to \na range of existing garbage collectors, both with and without memory pres\u00adsure. Section 6 discusses related \nwork, Section 7 presents directions for future work, and Section 8 concludes.  2. Overview The bookmarking \ncollector was designed to achieve three goals: low space consumption, high throughput, and the elimination \nof GC-induced page faults. While BC normally uses mark-sweep col\u00adlection, it minimizes space consumption \nby performing compaction when under memory pressure. BC provides high throughput by us\u00ading a nursery \ngeneration to manage short-lived objects. Finally, and most importantly, it organizes the heap into groups \nof pages and reacts to signals from the virtual memory manager whenever pages are scheduled for eviction \nto disk or made resident in main memory. Unlike existing garbage collectors, BC avoids paging caused \nby processing objects on evicted pages. BC scans pages prior to evic\u00adtion and remembers outgoing pointers \nby bookmarking targeted objects. When BC is noti.ed of an impending eviction and cannot shrink the heap \nor discard an empty page, BC ensures that only appropriate pages are evicted. BC scans each object on \nthe vic\u00adtim page, bookmarks the targets of any references, and increments counters in the target superpages \nheaders. After processing all of the objects, BC informs the virtual memory manager that the page can \nbe evicted. Because BC uses these bookmarks to recreate the evicted references, it can continue to collect \nthe heap without pag\u00ading. Figure 1 presents a snapshot of the heap after a collection with bookmarks. \nObjects are the small rectangles inside larger rectangles, which are pages. Live objects are shown in \nwhite, and unreachable objects (garbage) are shown in black. The middle page (in light gray) has been \nevicted to disk. The lines represent pointers. The dotted lines are pointers into non-resident pages; \nBC ignores these during collection. The dashed lines denote outgoing pointers from a non-resident page: \nthese induce bookmarks, represented by the letter B . BC also conservatively bookmarks all objects on \na page before it is evicted (see Section 3.4). The number 1 in the upper-left hand corner of the last \npage indicates that the bookmarks on this page are induced by exactly one evicted page. During collection, \nBC considers every bookmarked object to be live, even if it is not reachable from the roots. 3. Bookmarking \nCollection The bookmarking collector is a generational collector with a bump\u00adpointer nursery, a compacting \nmature space, and a page-based large object space. BC divides the mature space into superpages, page\u00adaligned \ngroups of four contiguous pages (16K). BC manages ma\u00adture objects using segregated size classes [12, \n13, 16, 36, 38, 42, 53]: objects of different sizes are allocated onto different super\u00adpages. Completely \nempty superpages can be reassigned to any size class [16, 38]. BC uses size classes designed to minimize \nboth internal and external fragmentation (which we bound at 25%). Each allocation size up to 64 bytes \nhas its own size class. Larger object sizes fall into a range of 37 size classes; for all but the largest \n.ve, these have a worst-case internal fragmentation of 15%. The .ve largest classes have between 16% \nand 33% worst-case internal fragmentation; BC could only do better by violating the bound on page-internal \nor external fragmentation. BC allocates objects larger than 8180 bytes (half the size of a superpage \nminus metadata) into the large object space. When the heap .lls, BC typically performs mark-sweep garbage \ncollection. We use mark-sweep for two reasons. First, it provides good program throughput and short GC \npauses. More importantly, mark-sweep does not increase memory pressure by needing a copy reserve of pages.1 \n3.1 Managing Remembered Sets Like all generational collectors, BC must remember pointers from the older \nto the younger generation. It normally stores these point\u00aders in page-sized write buffers that provide \nfast storage and process\u00ading but may demand unbounded amounts of space. To limit space overhead, BC processes \nbuffers when they .ll. During this process\u00ading, it removes entries for pointers from the mature space \nand in\u00adstead marks the card for the source object in the card table used during the marking phase of \ngarbage collection. BC begins each nursery collection by reviewing these cards and scanning only those \nobjects whose cards are marked. After pruning all possible pointers and compacting the entries remaining \nin the buffer, the .ltered slots are available for future storage. This .ltering allows the bookmark\u00ading \ncollector to use the fast processing of write buffers, but often consumes just a single page. 3.2 Compacting \nCollection Because mark-sweep collection does not compact the heap, frag\u00admentation can cause it to increase \nmemory pressure. Using mark\u00adsweep, the bookmarking collector cannot reclaim a superpage if it contains \njust one reachable object. BC avoids increased memory pressure by performing a two-pass compacting collection \nwhenever 1 Usually this copy reserve is half the heap size, but Sachindran et al. present copying collectors \nthat allow the use of much smaller copy reserves [43, 44]. a full garbage collection does not free enough \npages to satisfy the current allocation request. BC begins this compacting collection with a marking \nphase. Each time it marks an object, it also increments a counter for the object s size class. After \nmarking, BC computes the minimum number of superpages needed to hold the marked objects for each size \nclass. It then selects the minimum set of target superpages that contain enough space to hold all of \nthe marked objects. A second pass uses a Cheney scan to compact the reachable objects. Upon visiting \nan object in this second pass, BC checks if the object is on a target superpage. BC forwards those objects \nnot on target superpages, while preserving objects already on a target. When this pass completes, reachable \nobjects are only on target superpages and the remaining garbage (non-target) superpages are freed.  \n3.3 Cooperation with the Virtual Memory Manager The approach described so far allows BC to avoid increasing \nmem\u00adory pressure during garbage collection. In the face of paging, BC cooperates with the virtual memory \nmanager to shrink the heap and reduce memory pressure. The bookmarking collector uses its knowledge of \nthe heap to make good paging decisions. For this cooperation, we use an extended virtual memory manager; \nwe de\u00adscribe these extensions in Section 4.1. 3.3.1 Reducing System Call Overhead To limit overhead due \nto communication with the virtual memory manager, BC tracks page residency internally. Whenever BC allo\u00adcates \na new superpage, it checks in a bit array if the pages are al\u00adready memory resident. When they are not, \nit increases the estimate of the current footprint and marks the pages as resident. During gar\u00adbage collection, \nthe collector uses this bit array to avoid following pointers into pages that are not resident. 3.3.2 \nDiscarding Empty Pages The virtual memory manager initiates communication by sending a signal whenever \na page is scheduled for eviction or loaded back into memory. Upon receiving this signal, BC scans the \nbit array for an empty, memory-resident page and directs the virtual memory manager to reclaim this discardable \npage. When a discardable page cannot be found, BC triggers a collection and then directs the virtual \nmemory manager to discard a newly-emptied page (if one exists). Most operating systems (e.g., Linux and \nSolaris) already include this functionality by using the madvise system call with the MADV DONTNEED.ag. \n 3.3.3 Keeping the Heap Memory-Resident The noti.cation of a pending eviction also alerts BC that the \ncurrent heap footprint is slightly larger than the memory available to the application. Unlike previous \ncollectors, BC tries not to grow at the expense of paging, but instead limits the heap to the current \nfootprint. If memory pressure continues to increase, BC continues discarding empty pages and uses the \nnew estimate as the target footprint. BC shrinks the heap to keep it entirely in memory and thus avoid \nincurring the cost of a page fault. While BC expands the heap and causes pages to be evicted when this \nis necessary for program completion, it ordinarily limits the heap to what can .t into available memory. \n  3.4 Bookmarking When a non-discardable page must be evicted, BC selects a victim page. The page scheduled \nfor eviction is usually an appropriate choice, since the virtual memory manager approximates LRU order \nand will therefore evict pages that are unlikely to be used again soon. However, BC will not select pages \nthat it knows will soon be used, such as nursery pages or superpage headers (which we discuss below). \nIn this case, upon processing the signal, BC touches the page that has been scheduled in order to prevent \nits eviction. This touching causes a different victim page to be scheduled for eviction. If collecting \nthe heap does not yield any discardable pages, BC scans the victim page for outgoing pointers and bookmarks \nthe tar\u00adget objects of these outgoing references. These bookmarks (a single bit stored in the status \nword in the object header) act as a secondary set of root references, allowing full memory-resident collections \nwithout accessing evicted pages and thus without causing any page faults. In addition to setting the \nbookmark bit of all of the target objects, BC increments the incoming bookmark counter for the target \nobjects superpages. BC uses this counter (the number of evicted pages pointing to objects on a given \nsuperpage) to release bookmarks when incoming pages become resident (we discuss clearing bookmarks in \nSection 3.4.2). BC stores superpage metadata in each superpage header. This placement permits constant-time \naccess by bit-masking, which is important because the metadata is used both for allocation and collection. \nWhile this metadata could instead be stored off to the side, that would create a large pool of unevictable \npages, including information for superpages that do not exist. While storing the metadata in the superpage \nheader prevents BC from evicting one\u00adfourth of the pages, it reduces memory overhead and simpli.es the \nmemory layout, along with corresponding eviction/reloading code. Since superpage headers are always resident, \nBC can increment the incoming bookmark counters without triggering a page fault. BC cannot bookmark every \ntarget, however, since these may reside on evicted pages. To prevent this from causing errors, BC conserv\u00adatively \nbookmarks all objects on a page before it is evicted. Once bookmarking completes, the victim page can \nbe evicted. Having just been touched, however, it would not now be sched\u00aduled for eviction. BC thus communicates \nwith the virtual mem\u00adory manager one more time, informing it that the page should be evicted. While the \nstock Linux virtual memory manager does not provide support for this operation, BC uses a new system \ncall pro\u00advided by our extended kernel, vm relinquish. This call allows user processes to voluntarily \nsurrender a list of pages. The virtual memory manager places these relinquished pages at the end of the \ninactive queue from which they are quickly swapped out. A race condition could arise if the relinquished \npages are touched before the virtual memory manager can evict them. While BC would still have processed \nthese pages for bookmarks, they would never be evicted and BC would never be informed that they are memory-resident. \nTo eliminate this possibility, BC prevents pages from being accessed immediately after scanning it by \ndis\u00adabling access to them (via the mprotect system call). When a protected page is next touched, the \nvirtual memory manager no\u00adti.es BC. In addition to re-enabling page access, BC can clear bookmarks (see \nSection 3.4.2). 3.4.1 Collection After Bookmarking When the heap is not entirely resident in memory, \nBC starts the marking phase of each full-heap collection by scanning the heap for memory-resident bookmarked \nobjects. While this scan is ex\u00adpensive, scanning every object is often much smaller than the cost of \neven a single page fault. BC further reduces this cost by scanning only those superpages with a nonzero \nincoming bookmark count. During this scan, BC marks and processes bookmarked objects as if they were \nroot-referenced. Once BC completes this scan, it has re\u00adconstructed all the references in evicted objects \nand does not need to touch evicted pages. BC now follows its usual marking phase, but ignores references \nto evicted objects. After marking completes, all reachable objects are either marked or evicted. A sweep \nof the memory-resident pages completes the collection. When BC must compact the heap, slightly more processing \nis required. During marking, BC updates the object counts for each size class to reserve space for every \npossible object on the evicted pages. BC .rst selects all superpages containing bookmarked ob\u00adjects or \nevicted pages as compaction targets, selecting other super\u00adpages as needed. BC scans the heap to process \nbookmarked objects once more at the start of compaction. Because these bookmarked objects reside on target \nsuperpages, BC does not move them. BC thus does not need to update (evicted) pointers to bookmarked objects. \n 3.4.2 Clearing Bookmarks BC largely eliminates page faults caused by the garbage collector, but cannot \nprevent mutator page faults. As described in Section 3.4, BC is noti.ed whenever the mutator accesses \nan evicted page because this triggers a protection fault. BC then tries to clear the bookmarks it set \nwhen the page was evicted. BC scans the reloaded page s objects and decrements the incom\u00ading bookmark \ncounter of any referenced objects superpages. When a superpage s counter drops to zero, its objects are \nonly referenced by objects in main memory. BC then clears the now-unnecessary bookmarks from that superpage. \nIf the reloaded page s superpage also has an incoming bookmark count of zero, then BC clears the bookmarks \nthat it set conservatively when the page was evicted. 3.4.3 Complications So far, we have described \npage eviction as if the kernel schedules evictions on a page-by-page basis and maintains a constant number \nof pages in memory. In fact, the virtual memory manager schedules page evictions in large batches to \nhide disk latency. As a result, the size of available memory can .uctuate wildly. The virtual memory \nmanager also operates asynchronously from the collector, meaning that it can run ahead of the collector \nand evict a page before BC can even be scheduled to run and process the page. BC uses two techniques \nto avoid this problem. First, it maintains a store of empty pages and begins a collection when these \nare the only discardable pages remaining. If pages are scheduled for eviction during a collection, BC \ndiscards the pages held in reserve. When a collection does not free enough pages to replenish its empty \npage cache, BC examines the pages that had been scheduled for eviction and, processes and evicts any \nnon-empty pages. This preventive bookmarking ensures BC always maintains some pages in memory in which \nit can allocate objects and ensures BC can process pages before their eviction. BC employs a second technique \nto ensure it can process pages before they are evicted. Rather than discarding pages individually, BC \ndiscards all contiguous empty pages recorded on the same word in its bit array as the .rst discardable \npage it .nds. By tracking the number of extra pages it returns to the virtual memory manager, BC prevents \nthis aggressive discarding from decreasing its target memory footprint. This aggressiveness has other \nbene.ts. Provid\u00ading more empty pages for reuse limits the number of pages the virtual memory manager \nmust schedule for eviction and provides better program throughput by reducing the time BC spends han\u00addling \nthese noti.cations.  3.5 Preserving Completeness The key principle behind bookmarking collection is \nthat the gar\u00adbage collector must avoid touching evicted pages. A natural ques\u00adtion is whether complete \ngarbage collection (reclaiming all garbage objects) is possible without touching any evicted pages. In \ngeneral, it is impossible to perform complete garbage col\u00adlection without traversing non-resident objects. \nConsider the case when we must evict a page full of one-word objects that all point to objects on other \npages. A lossless summary of reachability in\u00adformation for this page requires as much memory as the objects \nthemselves, for which we no longer have room. This limitation means that, in the absence of other informa\u00adtion \nabout reachability, we must rely on conservative summaries of connectivity information. Possible summaries \ninclude summa\u00adrizing pointers on a page-by-page basis, compressing pointers in memory, and maintaining \nreference counts. To minimize the space and processing required for summaries, we use the smallest sum\u00admarization \nheuristic: a single bookmark bit already available in the object s header. When this bit is set, BC treats \nthe object as the target of at least one pointer from an evicted page. While this summary information \nis free , bookmarking has a potential space cost. Because BC must select all superpages con\u00adtaining bookmarked \nobjects and evicted pages as targets, compact\u00ading collection cannot always minimize the size of the heap. \nBy treating all bookmarked objects as reachable (even ones which may be garbage), BC is further limited \nin how far it can shrink the heap. Despite these apparent costs, bookmarking does not substan\u00adtially \nincrease the minimum heap size that BC requires. Section 5.3 shows that even in the face of megabytes \nof evicted pages, BC con\u00adtinues to run in very tight heap sizes. Such tight heaps mean that BC will perform \nmore frequent garbage collections, but the time needed for these collections is still far less than the \ncost of the page faults that would otherwise occur. In the event that the heap is exhausted, BC preserves \ncomplete\u00adness by performing a full heap garbage collection (touching evicted pages). Note that this worst-case \nsituation for bookmarking collec\u00adtion (which we have yet to observe) is the common case for existing \ngarbage collectors. We show in Section 5 that BC s approach effec\u00adtively eliminates collector-induced \npaging.  4. Implementation Details We implemented the bookmarking collector using MMTk [19] and Jikes \nRVM version 2.3.2 [7, 8]. When implementing the BC algorithm within MMTk and Jikes, we needed to make \ntwo minor modi.cations. In Jikes, object headers for scalars are found at the end of the object while \nobject headers for arrays are placed at the start of an object.2 This placement is useful for optimizing \nNULL checks [7], but makes it dif.cult for BC to .nd object headers when scanning pages. We solve this \nproblem by further segmenting our allocation to allow superpages to hold either only scalars or only \narrays. BC stores the type of objects contained in the superpage in each superpage header. Using this \ntype and size class information in the superpage header (accessed by bit-masking) allows BC to locate \nall objects on a page. BC does not employ two of the object layout optimizations in\u00adcluded in Jikes RVM. \nJikes normally aligns objects along word (4\u00adbyte) boundaries, but allocates objects or arrays containing \nlongs or doubles on an 8-byte boundary. Aligning data this way improves performance, but makes it impossible \nfor BC to locate object head\u00aders. BC would need to know an object s type to .nd its header, but the type \nis itself stored in the header. Another optimization al\u00adlows Jikes RVM to compute an object s hash code \nbased upon its address. While this provides many bene.ts, address-based hashing also requires that copied \nobjects grow by one word, disrupting the size-class object counts that BC maintains. While we needed \nto remove these optimizations from BC builds, we did not want to bias our results by removing them from \nbuilds that would bene.t from their presence. Therefore, all builds except BC include these optimizations. \n2 In a recently-released version of Jikes RVM, all headers start at the begin\u00adning of the object. 4.1 \nKernel Support The bookmarking collector improves garbage collection paging performance primarily by \ncooperating with the virtual memory manager. We extended the Linux kernel to enable this cooperative \ngarbage collection. This extension consists of changes or additions to approximately six hundred lines \nof code (excluding comments), as measured by SLOCcount [51]. The modi.cations are on top of the 2.4.20 \nLinux kernel. This kernel uses an approximate global LRU replacement algorithm. User pages are either \nkept in the active list (managed by the clock algorithm) or the inactive list (a FIFO queue). When the \napplication begins, it registers itself with the operating system so that it will receive noti.cation \nof paging events. The kernel then noti.es the runtime system just before any page is scheduled for eviction \nfrom the inactive list (speci.cally, whenever its corresponding page table entry is unmapped). The signal \nfrom the kernel includes the address of the relevant page. To maintain information about process ownership \nof pages, we applied Scott Kaplan s lightweight version of Rik van Riel s reverse mapping patch [34, \n50]. This patch allows the kernel to determine the owning process of pages currently in physical memory. \nBC needs timely memory residency information from the vir\u00adtual memory manager. To ensure the timeliness \nof this communi\u00adcation, our noti.cations use Linux real-time signals. Real-time sig\u00adnals in the Linux \nkernel are queueable. Unlike other noti.cation methods, these signals cannot be lost due to other process \nactivity.  5. Results We evaluated the performance of BC by comparing it to .ve garbage collectors included \nwith Jikes RVM: MarkSweep, Semi-Space, GenCopy, GenMS (Appel-style generational collectors us\u00ading bump-pointer \nand mark-sweep mature spaces, respectively), and CopyMS (a variant of GenMS which performs only whole \nheap garbage collections). Table 1 describes our benchmarks, which include the SPECjvm98 benchmark suite \n[27], pseudoJBB (a .xed-workload variant of SPECjbb [26]), and two applications from the DaCapo benchmark \nsuite, ipsixql and jython. We compare execution and pause times of the pseudoJBB benchmark on our extended \nLinux kernel. This benchmark is widely considered to be the most representative of a server workload \nand is the only one of our benchmarks with a signi.cant memory footprint. 5.1 Methodology We performed \nall measurements on a 1.6GHz Pentium M Linux machine with 1GB of RAM and 2GB of local swap space. This \nBenchmark statistics Benchmark Total Bytes Alloc Min. Heap SPECjvm98 201 compress 109,190,172 16,777,216 \n202 jess 267,602,628 12,582,912 205 raytrace 92,381,448 14,680,064 209 db 61,216,580 19,922,944 213 javac \n181,468,984 19,922,944 228 jack 250,486,124 11,534,336 DaCapo ipsixql 350,889,840 11,534,336 jython 770,632,824 \n11,534,336 SPECjbb2000 pseudoJBB 233,172,290 35,651,584 Table 1. Memory usage statistics for our benchmark \nsuite.  Figure 2. Geometric mean of execution time relative to BC absent memory pressure and across \nall benchmarks. At the smaller sizes, heap compaction allows BC to require less space while providing \nthe best performance. Compaction is not needed at larger heap sizes, but BC typically continues to provide \nhigh performance. processor includes a 32KB L1 data cache and a 1MB L2 cache. We report the mean of .ve \nruns with the system in single-user mode and the network disabled. To duplicate the environment found \nin live servers, all code is compiled by the optimizing compiler. We did not want compilation to affect \nour end results, however, as servers rarely spend time com\u00adpiling code. Following Bacon et al. [13], \nwe run two iterations of each benchmark, but report results only from the second iteration. The .rst \niteration optimizes all of the code. Because compilation allocates onto the heap, the heap size is allowed \nto change during this iteration. After the .rst iteration is complete, Jikes performs a full heap collection \nto remove compilation objects and data remain\u00ading from the .rst run. We then measure the second iteration \nof the benchmark. Using this compile-and-reset methodology, we can compare the performance of collectors \nin an environment similar to that found in a large server. To examine the effects of memory pressure \non garbage col\u00adlection paging behavior, we simulate increasing memory pressure caused by another application \nstarting up or increasing its work\u00ading set size. We begin these experiments by making available only \nenough memory for Jikes to complete the compilation phase with\u00adout any memory pressure. We then use an \nexternal process we call signalmem. The Jikes RVM noti.es signalmem when it com\u00adpletes the .rst iteration \nof a benchmark. Once alerted, signalmem uses mmap to allocate a large array, touches these pages, and \nthen pins them in memory with mlock. The initial amount of memory, total amount of memory, and rate at \nwhich this memory is pinned are speci.ed via command-line parameters. Using signalmem, we perform repeatable \nmeasurements under memory pressure while re\u00adducing disruption due to CPU load. This approach also allows \nus to compare the effects of different levels of memory pressure and a variety of page evictions rates. \n 5.2 Performance Without Memory Pressure While the key goal of bookmarking collection is to avoid paging, \nit would not be practical if it did not provide competitive throughput in the absence of memory pressure. \nFigure 2 summarizes the results for the case when there is suf.cient memory to run the benchmarks without \nany paging. We present the geometric mean increase in execution time relative to BC at each relative \nheap size for each collector. As expected, BC is closest in performance to GenMS, although BC will occasionally \nrun in a smaller heap size. Both collectors perform nursery collection and have a segregated-.t mark-sweep \nmature space, and behave similarly at large heap sizes and without memory pressure. At the largest heap \nsize (where heap compaction is not needed), the two collectors are virtually tied (BC runs 0.3% faster). \nHowever, at smaller sizes, BC s compaction allows it to run in smaller heaps. For example, BC runs 4% \nfaster at the 1.25x heap size. The next best collector is GenCopy, which runs as fast as BC at the largest \nheap sizes but averages 7% slower at heaps as large as twice the minimum. The fact that GenCopy generally \ndoes not exceed BC s performance suggests that BC s segregated size classes do not signi.cantly impact \nlocality. Unsurprisingly, BC s performance is much greater than the single-generation collectors. At \nthe largest heap size, MarkSweep averages a 20% and CopyMS a 29% slowdown. No collector at any heap size \nperforms better on average than BC, demonstrating that the BC provides high performance when memory pressure \nis low.  5.3 Performance Under Memory Pressure We evaluate the impact of memory pressure using three \nsets of ex\u00adperiments. We .rst measure the effect of steady memory pressure. Next, we measure the effect \nof dynamically growing memory pres\u00adsure, as would be caused by the creation of another process or a rapid \nincrease in demand (e.g., the Slashdot effect ). Finally, we run multiple JVMs simultaneously. We use \nthe pseudoJBBbench\u00admark for all these experiments. 5.3.1 Steady Memory Pressure To examine the effects \nof running under steady memory pressure, we measure the available memory needed so every collector can \nrun without evicting a page. Starting with that amount of available memory, we begin the second iteration \nby having signalmem re\u00admove memory equal to 60% of the heap size. Results of these ex\u00adperiments are shown \nin Figure 3. Note that we do not show results for MarkSweep in these graphs, because runs with this collector \ncan take hours to complete. Figure 3 shows that under steady memory pressure, BC out\u00adperforms most of \nthe other collectors (and all of the generational collectors). Although SemiSpace outperforms BC at the \n80-95MB heap sizes, its execution time goes off the chart soon after. CopyMS also outperforms BC in the \nsame range of heap sizes but runs nearly twice as slow as BC at the 130MB heap size. At this size, GenMS \ns average pause time is around 3 seconds, 30 times greater than BC s average pause time. To test CopyMS \ns behavior under greater mem\u00adory pressure, we measured the effect of removing memory equal to 70% of \nthe heap size. Under these conditions, CopyMS takes over an hour to execute pseudoJBB, while BC s execution \ntime remains largely unchanged.  5.3.2 Dynamic Memory Pressure To simulate a spike in memory pressure, \nwe invoke signalmem so that it initially allocates 30MB and then allocates additional memory at a rate \nof 1MB every 100ms until it reaches the desired level of available memory. Figure 4 shows the average \npause times and Figure 5 shows the average execution time for pseudoJBB as memory pressure increases \n(i.e., as available memory shrinks). Figures 4 and 5 show that under memory pressure, BC signi.\u00adcantly \noutperforms all of the other collectors both in total execution time and pause times. Note that, as with \nthe previous paging exper\u00adiments, we do not present MarkSweep here because of the dramatic performance \ndegradation it suffers. Because the mark-sweep based collectors do not perform com\u00adpaction, objects become \nspread out over a range of pages. Once Figure 4. Dynamic memory pressure (increasing from left to right): \naverage GC pause time running pseudoJBB. BC s average pause times remain unaffected by increasing memory \npressure.  heap pages are evicted, visiting these pages during a collection trig\u00adgers a cascade of page \nfaults and orders-of-magnitude increases in execution time. For instance, at the largest heap size, GenMS \ns av\u00aderage garbage collection pause takes nearly 10 seconds longer than it needed to execute pseudoJBB \nwithout memory pressure. Even when collections are relatively rare, spreading objects across a large \nnumber of pages can degrade performance by increasing mutator faults. Compacting objects onto fewer pages \ncan reduce faults, but the compacting collectors also suffer from paging effects. For example, the execution \ntimes for GenCopy shown in Figure 5(a) are an order of magnitude larger than its times when not paging. \nPaging also increases the average GenCopy pause to several seconds, while BC s pause times remain largely \nunchanged. The collectors that come closest in execution time to BC in Fig\u00adure 5 are SemiSpace and CopyMS. \nWhile these collectors perform well at low to moderate memory pressure, they perform far worse both under \nno memory pressure and under severe memory pressure. This effect is due to pseudoJBB s allocation behavior. \npseudo-JBB initially allocates a few immortal objects and then allocates only short-lived objects. While \nthese collectors reserve heap space to copy the survivors of a collection, little of this space is used. \nLRU ordering causes nursery pages .lled with dead objects to be evicted. While SemiSpace ultimately reuses \nthese pages in subsequent col\u00adlections, CopyMS s mark-sweep mature object space allows better heap utilization \nand fewer collections. This heap organization de\u00adlays paging, but does not prevent it. We next present \nmutator utilization curves [23]. Mutator utiliza\u00adtion is the fraction of time that the mutator runs during \na given time window. In other words, it is the amount of time spent by the appli\u00adcation rather than by \nthe garbage collector. We adopt the method\u00adology of Sachindran et al. and present bounded mutator utilization, \nor BMU [44]. The BMU for a given window size is the minimum mutator utilization for all windows of that \nsize or greater. Figure 6 shows the BMU curves for the dynamic memory pres\u00adsure experiments. With moderate \nmemory pressure (143MB avail\u00adable RAM), both variants of BC and MarkSweep do very well, but all of the \nother collectors exhibit poorer utilization. In particu\u00adlar, GenMS requires window sizes orders of magnitude \nlarger than BC s running time before the mutator makes any progress. Under severe memory pressure (93MB \navailable RAM), the full bookmarking collector outperforms the other collectors, achieving almost 0.9 \nutilization over a 10-second window. At this window (a) Execution time running pseudoJBB. (b) Average \nGC pause time running pseudoJBB. Figure 3. Steady memory pressure (increasing from left to right), where \navailable memory is suf.cient to hold only 40% of the heap. As the heap becomes larger, BC runs 7 to \n8 times faster than GenMS and in less than half the time needed by CopyMS. Bookmarking is faster and \nyields shorter pause times than just resizing the heap. (a) Execution time running pseudoJBB (b) Execution \ntime running pseudoJBB, .xed-size nursery collectors Figure 5. Dynamic memory pressure (increasing from \nleft to right). BC runs up to 4x faster than the next best collector and up to 41x faster than GenMS. \nWhile shrinking the heap can help, BC runs up to 10x faster when also using bookmarks. size, all of the \nother collectors have zero utilization. The non\u00adbookmarking variant of BC (shown as BC w/Resizing only \n) and CopyMS are the next best collectors, but peak at around 0.5 mutator utilization over a 40-second \nwindow. Interestingly, MarkSweep has the worst utilization here, requiring a window size of almost 10 \nminutes before achieving 0.25 mutator utilization. We also compared different variants of the bookmarking \ncol\u00adlector and the generational collectors to tease apart the impact of various strategies on paging. \nFixed-size nurseries: Fixed-size nurseries can achieve the same throughput as variable-sized nurseries \nbut are generally believed to incur lower paging costs. Figure 5(b) presents execution times for variants \nof the generational collectors with .xed-size nurseries (4MB). The graph shows that the .xed-nursery \nvariants of the other collectors do reduce paging, but perform as poorly as the variable\u00adsized generational \ncollectors once their footprint exceeds available memory. Bookmarking vs. resizing the heap: When memory \npressure is relatively low, BC s strategy of discarding empty pages is suf.cient to avoid paging. As \nmemory pressure increases, however, a variant of BC that only discards pages (shown as BC w/Resizing \nonly ) requires up to 10 times as long to execute as the full bookmarking collector. The results shown \nin Figures 3 and 4 demonstrate that bookmarking is vital to achieve high throughput and low pause times \nunder moderate or severe memory pressure.  5.3.3 Multiple JVMs Finally, we examine a scenario with two \nJVMs executing simul\u00adtaneously. For this experiment, we start two instances of Jikes running the pseudoJBB \nbenchmark and measure total elapsed time and garbage collection pause times. We cannot employ the compile-and-reset \nexperimental methodology here because com\u00adpiling the entire application generates too much paging traf.c \nand we cannot reset the virtual memory manager s history. Instead, we employ the pseudoadaptive methodology \n[32, 44], which opti\u00admizes only the hottest methods (as determined from the mean of 5 runs). This methodology \nminimizes the impact of the compiler as much as possible, and does so deterministically rather than relying \non the standard sampling-based approach. Eeckhout et al. report that all of the virtual machines they \nexamined exhibit similar be\u00ad (a) 143MB available: BC is largely unaffected by moderate levels of (b) \n93MB available: under heavy memory pressure, bookmarks become memory pressure. increasingly important. \nFigure 6. Dynamically increasing memory pressure: bounded mutator utilization curves (curves to the left \nand higher are better). BC consistently provides high mutator utilization over time. As memory pressure \nincreases (available memory shrinks), the importance of bookmarks to limit garbage collection pauses \nbecomes more apparent.  (a) Execution time running two instances of pseudoJBB (b) Average GC pause \ntime running two instances of pseudoJBB Figure 7. Execution time and pause times when running two instances \nof pseudoJBB simultaneously. Note that the execution times are somewhat misleading, because for the other \ncollectors, paging effectively deactivates one of the instances. Under heavy memory pressure, BC exhibits \npause times around 7.5x lower than the next best collector. havior for this benchmark, suggesting that \nthe performance impact of the pseudoadaptive compiler here should be minimal [29]. Figure 7 shows the \nresults of executing two instances of pseudoJBB, each with a 77MB heap. While BC performs the best, total \nelapsed time can be misleading: for all of the other col\u00adlectors, paging effectively serializes the benchmark \nruns. This se\u00adrialization means that .rst one instance of pseudoJBB runs to completion, and then the \nnext. The average pause time numbers are thus more revealing. As available memory shrinks, bookmark\u00ading \nshows a gradual increase in average pause times. At the lowest amount of available memory, BC exhibits \npause times averaging around 380ms, while average pause times for CopyMS (the next best collector) reach \n3 seconds, nearly an eightfold increase.   6. Related Work Most previous garbage collectors ignore \nvirtual memory altogether, making them VM-oblivious. The literature on such collectors is ex\u00adtensive; \nWilson s survey and Jones and Lins text provide excellent overviews [33, 53]. VM-sensitive garbage collectors \nare designed to limit paging in virtual memory environments. Such collectors either compact memory to \nreduce the number of pages needed to hold an appli\u00adcation s working set [14, 15, 20, 21, 22, 30], or \ndivide the heap into generations to reduce the need for full-heap collections [9, 17, 37, 39, 41, 49]. \nBookmarking collection builds on both: it employs compaction to reduce working set size and uses a nurs\u00adery \ngeneration to improve throughput, but uses bookmarking to avoid collector-induced paging. Bookmarking \ncollection may be thought of as a generalization of generational collection, where the evicted pages \ncomprise a distinct (and dynamically changing) mature-space generation, and bookmarks act as remembered \nsets. VM-cooperative garbage collectors receive information from or send information to the virtual memory \nmanager (or both). Moon s ephemeral collector receives signals from the virtual mem\u00adory manager whenever \nit evicts a page from main memory [39]. The collector then scans the page and records which generations \nit con\u00adtains references to. During GC, Moon s collector then scans only those evicted pages containing \npointers to the generation being col\u00adlected. Unlike Moon s collector, bookmarking collection does not \nrevisit any evicted pages during nursery or full-heap collections. Cooper et al. s collector informs \nthe VM of empty memory pages that can be removed from main memory without being writ\u00adten back to disk \n[25]. BC also identi.es and discards empty pages, but as we show in Section 5.3, BC s ability to evict \nnon-empty pages gives it a signi.cant advantage under memory pressure. Another class of VM-cooperative \ncollectors respond to memory pressure by adjusting their heap size. Alonso and Appel present a collector \nthat consults with the virtual memory manager indi\u00adrectly (through an advisor ) to shrink the heap after \neach garbage collection based upon the current level of available memory [6]. MMTk [19] and BEA JRockit \n[3] can, in response to the live data ratio or pause time, change their heap size using a set of pre-de.ned \nratios. HotSpot [1] can adjust heap size with respect to pause time, throughput, and footprint limits \nspeci.ed as command line argu\u00adments. Novell Netware Server 6 [2] polls the virtual memory man\u00adager every \n10 seconds, and shortens its GC invocation interval to collect more frequently when memory pressure is \nhigh. None of these approaches eliminate paging. Yang et al. report on an auto\u00admatic heap sizing algorithm \nthat uses information from a simulated virtual memory manager and a model of GC behavior to choose a \ngood heap size [55]. Like these systems, BC can shrink its heap (by giving up discardable pages), but \nit does not need to wait until a full heap garbage collection to do so. BC also eliminates paging even \nwhen the size of live data exceeds available physical memory. Researchers have leveraged virtual memory \nhardware to sup\u00adport garbage collection in other ways. Appel, Ellis and Li use vir\u00adtual memory protection \nto improve the speed and concurrency of Baker s algorithm [10]. Appel and Li present a variety of ways \nto use virtual memory to assist garbage collection, including provid\u00ading an inexpensive means of synchronization, \nremembering inter\u00adesting pointers, or saving long-lived data to disk [11]. These uses of virtual memory \nare orthogonal to this work and to the VM\u00adcooperative collectors described above, which use virtual memory \ncooperation primarily to reduce paging. Like bookmarking collection, distributed garbage collection al\u00adgorithms \nalso treat certain references (those from remote systems) as secondary roots.3 Distributed GC algorithms \ntypically employ either reference counting or listing. Unlike bookmarking, both of these require substantial \nadditional memory and updates on every pointer store, while BC only updates bookmarks when pages are \nevicted or made resident (relatively rare events). A number of researchers have focused on the problem \nof im\u00adproving application-level locality of reference by using the garbage collector to modify object \nlayouts [5, 24, 28, 32, 35, 47, 48, 54]. These studies do not address the problem of paging caused by \ngar\u00adbage collection itself, which we identify as the primary culprit. These approaches are orthogonal \nand complementary to the work presented here. Finally, bookmarking collection s use of segregated size \nclasses for compaction is similar to the organization used by Bacon et al. s Metronome collector [12, \n13]. Unlike the Metronome, BC uses seg\u00adregated size classes for mature objects only. BC s copying pass \nis also quite different. The Metronome sorts pages by occupancy, for\u00adwards objects by marching linearly \nthrough the pages and continues until reaching a pre-determined size, forwarding pointers later. BC instead \ncopies objects by .rst marking target pages and then for\u00adwarding objects as they are discovered in a \nCheney scan. This ap\u00ad 3 See Abdullahi and Ringwood [4] and Plainfoss\u00b4e and Shapiro [40] for excellent \nrecent surveys of this area. proach obviates the need for further passes and immediately brings memory \nconsumption to the minimum level. 7. Future Work While our results show that BC already yields signi.cant \nperfor\u00admance improvements and robustness under memory pressure, there are several directions in which \nwe would like to advance this work. First, because our modi.cations to the operating system kernel are \nstraightforward, we would like to incorporate these in other operat\u00ading systems to verify its generality \nand expand our range of bench\u00admark applications. Because memory pressure can be transient, BC may discard \nempty pages only to have memory again become available later. It is important that a brief spike in memory \npressure not limit throughput by restricting the size of the heap. We are evaluating strategies to allow \nBC to grow its heap when additional physical memory becomes available. We are also considering alternate \nstrategies for selecting victim pages. First, we can prefer to evict pages with no pointers, because \nthese pages cannot create false garbage. For some types of objects, e.g., arrays of doubles, we do not \neven need to scan the pages to determine that they are free of pointers. We could also prefer to evict \npages with as few non-NULL pointers as possible. We have not yet explored these possibilities because \nwe cannot predict the effect on the application of evicting a page that is not the last on the LRU queue \n(i.e., the one chosen by the virtual memory manager). Choosing to evict such a victim page may lead to \nmore page faults in the application. We are currently developing a more advanced virtual memory manager \nthat will enable us to predict the effect of selecting different victim pages and thus explore the tradeoffs \nof using more sophisticated eviction strategies. Finally, the bookmarking collector presented here is \na stop\u00adthe-world garbage collector, where all mutator work stops for garbage collection. However, server-based \nJVMs typically collect the heap concurrently while running the application. The current BC algorithm \nis not suitable for concurrent garbage collection: for example, a race could arise from the application \nmodifying a page that the collector is scanning. We are developing a concurrent variant of the bookmarking \ncollection algorithm. 8. Conclusion The increasing latency gap between disk and main memory means that \npaging is now intolerable. Garbage collection s reference be\u00adhavior can cause catastrophic paging. We \npresent bookmarking col\u00adlection, an algorithm that leverages cooperation between the gar\u00adbage collector \nand virtual memory manager to eliminate nearly all paging caused by the garbage collector. When memory \npressure is low, the bookmarking collector provides performance that gen\u00aderally matches or slightly exceeds \nthat of the highest throughput collector we tested (GenMS). In the face of memory pressure, BC improves \nprogram performance by up to 5x over the next best gar\u00adbage collector and reduces pause times by 45x, \nimproving even more dramatically over GenMS. BC thus provides greater mem\u00adory utilization and more robust \nperformance than previous garbage collectors.  Acknowledgements Thanks to Sam Guyer, Kathryn McKinley, \nEliot Moss, Pritesh Sharma, Yannis Smaragdakis, and Ben Zorn for their comments on drafts of this paper. \nWe are grateful to Scott Kaplan for his assistance in the implementation of our modi.ed Linux memory \nmanager. We are also grateful to IBM Research for making the Jikes RVM system available under open source \nterms. The MMTk memory management toolkit was particularly helpful. This material is based upon work \nsupported by the National Science Foundation under Award CNS-0347339. Any opinions, .ndings, and conclusions \nor recommendations expressed in this material are those of the author(s) and do not necessarily re.ect \nthe views of the National Science Foundation.  References [1] J2SE 1.5.0 Documentation -Garbage Collector \nErgonomics. Available at http://java.sun.com/j2se/1.5.0/docs/guide/ vm/gc-ergonomics.html. [2] Novell \nDocumentation: NetWare 6 -Optimizing Garbage Collection. Available at http://www.novell.com/documentation/ \nindex.html. [3] Technical white paper -BEA Weblogic JRockit: Java for the enterprise. Available at http://www.bea.com/content/ \nnews events/white papers/BEA JRockit wp.pdf. [4] S. E. Abdullahi and G. A. Ringwood. Garbage collecting \nthe Internet: a survey of distributed garbage collection. ACM Computing Surveys, 30(3):330 373, Sept. \n1998. [5] A.-R. Adl-Tabatabai, R. L. Hudson, M. J. Serrano, and S. Subra\u00admoney. Prefetch injection based \non hardware monitoring and object metadata. In Proceedings of the 2004 ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation (PLDI). ACM, June 2004. [6] R. Alonso and A. W. Appel. Advisor for \n.exible working sets. In Proceedings of the 1990 ACM Sigmetrics Conference on Measurement and Modeling \nof Computer Systems, pages 153 162, Boulder, CO, May 1990. [7] B. Alpern, C. R. Attanasio, A. Cocchi, \nD. Lieber, S. Smith, T. Ngo, J. J. Barton, S. F. Hummel, J. C. Shepherd, and M. Mergen. Implementing \nJalape no in Java. In Proceedings of the ACM Conference on Object-Oriented Systems, Languages and Applications, \nvolume 34(10), pages 314 324, Denver, CO, Oct. 1999. [8] B. Alpern, D. Attanasio, J. J. Barton, M. G. \nBurke, P. Cheng, J.- D. Choi, A. Cocchi, S. J. Fink, D. Grove, M. Hind, S. F. Hummel, D. Lieber, V. Litvinov, \nM. Mergen, T. Ngo, J. R. Russell, V. Sarkar, M. J. Serrano, J. Shepherd, S. Smith, V. C. Sreedhar, H. \nSrinivasan, and J. Whaley. The Jalape no virtual machine. IBM Systems Journal, 39(1), Feb. 2000. [9] \nA. W. Appel. Simple generational garbage collection and fast allocation. Software Practice and Experience, \n19(2):171 183, 1989. [10] A. W. Appel, J. R. Ellis, and K. Li. Real-time concurrent collection on stock \nmultiprocessors. ACM SIGPLAN Notices, 23(7):11 20, 1988. [11] A. W. Appel and K. Li. Virtual memory primitives \nfor user programs. ACM SIGPLAN Notices, 26(4):96 107, 1991. [12] D. F. Bacon, P. Cheng, and V. Rajan. \nControlling fragmentation and space consumption in the Metronome, a real-time garbage collector for Java. \nIn ACM SIGPLAN 2003 Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES 2003), \npages 81 92, San Diego, CA, June 2003. ACM Press. [13] D. F. Bacon, P. Cheng, and V. Rajan. A real-time \ngarbage collecor with low overhead and consistent utilization. In Conference Record of the Thirtieth \nAnnual ACM Symposium on Principles of Programming Languages, ACM SIGPLAN Notices, New Orleans, LA, Jan. \n2003. ACM Press. [14] H. D. Baecker. Garbage collection for virtual memory computer systems. Communications \nof the ACM, 15(11):981 986, Nov. 1972. [15] H. G. Baker. List processing in real-time on a serial computer. \nCommunications of the ACM, 21(4):280 94, 1978. [16] E. D. Berger, K. S. McKinley, R. D. Blumofe, and \nP. R. Wilson. Hoard: A scalable memory allocator for multithreaded applications. In ASPLOS-IX: Ninth \nInternational Conference on Architectural Support for Programming Languages and Operating Systems, pages \n117 128, Cambridge, MA, Nov. 2000. [17] P. B. Bishop. Computer Systems with a Very Large Address Space \nand Garbage Collection. PhD thesis, MIT Laboratory for Computer Science, May 1977. [18] S. M. Blackburn, \nP. Cheng, and K. S. McKinley. Myths and reality: The performance impact of garbage collection. In Sigmetrics \n-Performance 2004, Joint International Conference on Measurement and Modeling of Computer Systems, New \nYork, NY, June 2004. [19] S. M. Blackburn, P. Cheng, and K. S. McKinley. Oil and water? High performance \ngarbage collection in Java with MMTk. In ICSE 2004, 26th International Conference on Software Engineering, \nEdinburgh, May 2004. [20] D. G. Bobrow and D. L. Murphy. Structure of a LISP system using two-level storage. \nCommunications of the ACM, 10(3):155 159, Mar. 1967. [21] D. G. Bobrow and D. L. Murphy. A note on the \nef.ciency of a LISP computation in a paged machine. Communications of the ACM, 11(8):558 560, Aug. 1968. \n[22] C. J. Cheney. A non-recursive list compacting algorithm. Communi\u00adcations of the ACM, 13(11):677 \n8, Nov. 1970. [23] P. Cheng and G. Belloch. A parallel, real-time garbage collector. In Proceedings of \nSIGPLAN 2001 Conference on Programming Languages Design and Implementation, ACM SIGPLAN Notices, pages \n125 136, Snowbird, Utah, June 2001. ACM Press. [24] T. M. Chilimbi and J. R. Larus. Using generational \ngarbage collection to implement cache-conscious data placement. In Proceedings of the First International \nSymposium on Memory Management, volume 34(3), pages 37 48, Vancouver, BC, Canada, Oct. 1998. [25] E. \nCooper, S. Nettles, and I. Subramanian. Improving the performance of SML garbage collection using application-speci.c \nvirtual memory management. In Conference Record of the 1992 ACM Symposium on Lisp and Functional Programming, \npages 43 52, San Francisco, CA, June 1992. ACM Press. [26] S. P. E. Corporation. Specjbb2000. Available \nat http://www. spec.org/jbb2000/docs/userguide.html. [27] S. P. E. Corporation. Specjvm98 documentation, \nMar. 1999. [28] R. Courts. Improving locality of reference in a garbage-collecting memory management-system. \nCommunications of the ACM, 31(9):1128 1138, 1988. [29] L. Eeckhout, A. Georges, and K. D. Bosschere. \nHow Java programs interact with virtual machines at the microarchitectural level. pages 169 186. [30] \nR. R. Fenichel and J. C. Yochelson. A Lisp garbage collector for virtual memory computer systems. Communications \nof the ACM, 12(11):611 612, Nov. 1969. [31] M. Hertz and E. D. Berger. Automatic vs. explicit memory \nmanagement: Settling the performance debate. Technical report, University of Massachusetts, Mar. 2004. \n[32] X. Huang, S. M. Blackburn, K. S. McKinley, J. E. B. Moss, Z. Wang, and P. Cheng. The garbage collection \nadvantage: Improving program locality. In Proceeding of the ACM Conference on Object-Oriented Systems, \nLanguages and Applications, Vancouver, BC, Canada, Oct. 2004. [33] R. E. Jones and R. Lins. Garbage Collection: \nAlgorithms for Automatic Dynamic Memory Management. Wiley, Chichester, July 1996. [34] S. F. Kaplan. \nIn-kernel RIG: Downloads. Available at http: //www.cs.amherst.edu/~sfkaplan/research/rig/ download. [35] \nM. S. Lam, P. R. Wilson, and T. G. Moher. Object type directed garbage collection to improve locality. \nIn Proceedings of International Workshop on Memory Management, volume 637 of Lecture Notes in Computer \nScience, St Malo, France, 16 18 Sept. 1992. Springer-Verlag. [36] D. Lea. A memory allocator. http://gee.cs.oswego.edu/dl/html/malloc.html, \n1997. Available at http://gee.cs.oswego.edu/dl/html/ malloc.html. [37] H. Lieberman and C. E. Hewitt. \nA real-time garbage collector based on the lifetimes of objects. Communications of the ACM, 26(6):419 \n429, 1983. [38] T. F. Lim, P. Pardyak, and B. N. Bershad. A memory-ef.cient real\u00adtime non-copying garbage \ncollector. In Proceedings of the First International Symposium on Memory Management, volume 34(3), pages \n118 129, Vancouver, BC, Canada, Oct. 1998. [39] D. A. Moon. Garbage collection in a large LISP system. \nIn G. L. Steele, editor, Conference Record of the 1984 ACM Symposium on Lisp and Functional Programming, \npages 235 245, Austin, TX, Aug. 1984. ACM Press. [40] D. Plainfoss\u00b4e and M. Shapiro. A survey of distributed \ngarbage collection techniques. In Proceedings of the International Workshop on Memory Management, volume \n986 of Lecture Notes in Computer Science, Kinross, Scotland, Sept. 1995. Springer-Verlag. [41] J. H. \nReppy. A high-performance garbage collector for Standard ML. Technical memorandum, AT&#38;T Bell Laboratories, \nMurray Hill, NJ, Dec. 1993. [42] D. T. Ross. The AED free storage package. Communications of the ACM, \n10(8):481 492, Aug. 1967. [43] N. Sachindran and J. E. B. Moss. MarkCopy: Fast copying GC with less space \noverhead. In Proceedings of the ACM Conference on Object-Oriented Systems, Languages and Applications, \nAnaheim, CA, Nov. 2003. [44] N. Sachindran, J. E. B. Moss, and E. D. Berger. MC2: High\u00adperformance garbage \ncollection for memory-constrained environ\u00adments. In Proceedings of the ACM Conference on Object-Oriented \nSystems, Languages and Applications, Vancouver, BC, Canada, Oct. 2004. [45] P. Savola. LBNL traceroute \nheap corruption vulnerability. http: //www.securityfocus.com/bid/1739. [46] Software Veri.cation, Ltd. \nMemory Validator -Garbage Col\u00adlectors. Available at http://softwareverify.com/ memoryValidator/garbageCollectors.html. \n [47] D. Stefanovi\u00b4c, K. S. McKinley, and J. E. B. Moss. Age-based garbage collection. In Proceedings \nof the ACM Conference on Object-Oriented Systems, Languages and Applications, volume 34(10), pages 370 \n381, Denver, CO, Oct. 1999. [48] G. Tong and M. J. O Donnell. Leveled garbage collection. Journal of \nFunctional and Logic Programming, 2001(5):1 22, May 2001. [49] D. M. Ungar. Generation scavenging: A \nnon-disruptive high performance storage reclamation algorithm. In Proceedings of the ACM/SIGSOFT/SIGPLAN \nSoftware Engineering Symposium on Practical Software Development Environments, volume 19(5), pages 157 \n167, Apr. 1984. [50] R. van Riel. rmap VM patch for the Linux kernel. Available at http://www.surriel.com/patches/. \n[51] D. A. Wheeler. SLOCcount. Available at http://www. dwheeler.com/sloccount. [52] P. R. Wilson. Uniprocessor \ngarbage collection techniques. In Proceedings of the International Workshop on Memory Management, volume \n637 of Lecture Notes in Computer Science, St Malo, France, 16 18 Sept. 1992. Springer-Verlag. [53] P. \nR. Wilson, M. S. Johnstone, M. Neely, and D. Boles. Dynamic storage allocation: A survey and critical \nreview. In Proceedings of the International Workshop on Memory Management, volume 986 of Lecture Notes \nin Computer Science, pages 1 116, Kinross, Scotland, Sept. 1995. Springer-Verlag. [54] P. R. Wilson, \nM. S. Lam, and T. G. Moher. Effective static-graph reorganization to improve locality in garbage collected \nsystems. ACM SIGPLAN Notices, 26(6):177 191, 1991. [55] T. Yang, M. Hertz, E. D. Berger, S. F. Kaplan, \nand J. E. B. Moss. Automatic heap sizing: Taking real memory into account. In Proceedings of the 2004 \nACM SIGPLAN International Symposium on Memory Management, Nov. 2004. [56] B. Zorn. The measured cost \nof conservative garbage collection. Software Practice and Experience, 23:733 756, 1993. \n\t\t\t", "proc_id": "1065010", "abstract": "Garbage collection offers numerous software engineering advantages, but interacts poorly with virtual memory managers. Existing garbage collectors require far more pages than the application's working set and touch pages without regard to which ones are in memory, especially during full-heap garbage collection. The resulting paging can cause throughput to plummet and pause times to spike up to seconds or even minutes. We present a garbage collector that avoids paging. This <i>bookmarking collector</i> cooperates with the virtual memory manager to guide its eviction decisions. Using summary information (\"bookmarks\") recorded from evicted pages, the collector can perform in-memory full-heap collections. In the absence of memory pressure, the bookmarking collector matches the throughput of the best collector we tested while running in smaller heaps. In the face of memory pressure, it improves throughput by up to a factor of five and reduces pause times by up to a factor of 45 over the next best collector. Compared to a collector that consistently provides high throughput (generational mark-sweep), the bookmarking collector reduces pause times by up to 218x and improves throughput by up to 41x. Bookmarking collection thus provides greater utilization of available physical memory than other collectors while matching or exceeding their throughput.", "authors": [{"name": "Matthew Hertz", "author_profile_id": "81100478720", "affiliation": "University of Massachusetts Amherst, Amherst, MA", "person_id": "PP48024764", "email_address": "", "orcid_id": ""}, {"name": "Yi Feng", "author_profile_id": "81451595899", "affiliation": "University of Massachusetts Amherst, Amherst, MA", "person_id": "PP38023490", "email_address": "", "orcid_id": ""}, {"name": "Emery D. Berger", "author_profile_id": "81100228645", "affiliation": "University of Massachusetts Amherst, Amherst, MA", "person_id": "PP14089241", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065028", "year": "2005", "article_id": "1065028", "conference": "PLDI", "title": "Garbage collection without paging", "url": "http://dl.acm.org/citation.cfm?id=1065028"}