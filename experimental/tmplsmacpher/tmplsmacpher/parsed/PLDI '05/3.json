{"article_publication_date": "06-12-2005", "fulltext": "\n Path Slicing * Ranjit Jhala Rupak Majumdar CS Department, UC San Diego CS Department, UC Los Angeles \njhala@cs.ucsd.edu rupak@cs.ucla.edu Abstract We present a new technique, path slicing, that takes as \ninput a possibly in\u00adfeasible path to a target location, and eliminates all the operations that are irrelevant \ntowards the reachability of the target location. A path slice is a subsequence of the original path whose \ninfeasibility guarantees the infea\u00adsibility of the original path, and whose feasibility guarantees the \nexistence of some feasible variant of the given path that reaches the target location even though the \ngiven path may itself be infeasible. Our method combines the ability of program slicing to look at several \nprogram paths, with the pre\u00adcision that dynamic slicing enjoys by focusing on a single path. We have \nimplemented Path Slicing to analyze possible counterexamples returned by thesoftware modelchecker BLAST.Weshowitseffectiveness \nindrastically reducing the size of the counterexamples to less than 1% of their origi\u00adnal size. This \nenables the precise veri.cation of application programs (upto 100KLOC), by allowing the analysis to focus \non the part of the counterex\u00adample that is relevant to the property being checked. Categories and Subject \nDescriptors: D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation; D.3.4 [Programming Lan\u00adguages]: \nProcessors. General Terms: Languages, Veri.cation, Reliability. Keywords: Program slicing, counterexample \nanalysis.  1. Introduction We introduce path slicing, a technique to determine which subset of the edges \nalong a given control .ow path to particular target location are relevant towards demonstrating the (un)reachability \nof the target location along the given path. Static analyses used to verify safety properties return \ncontrol .ow paths to an error location as possible counterexamples demon\u00adstrating that the program is \nunsafe. As the static analysis is typically conservative, this path may or may not represent an actual \nviolation of the property. Traditionally, such control .ow paths, are examined manually to determine \nwhether they correspond to a feasible pro\u00adgram execution, and therefore, a bug [9, 8, 14, 23]. For large \npro\u00adgrams, the sheer length of the path makes such manual inspection dif.cult. More recently, counterexample-guided \nprogram analyses [3, 18, 7, 12] attempt to automatically .nd out if the path is feasi\u00adble, and if not, \nthey exploit the infeasibility of the path to re.ne the * This research was supported in part by the \ngrant NSF CCR-0427202. Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 05, June 12 15, 2005, Chicago, Illinois, USA. Copyright 2005 ACM 1-59593-056-6/05/0006...$5.00. \n Figure 1. (A) Ex2 (B) CFA for Ex2 (C)Path, Slice abstraction used for analysis. Once again, long counterexamples \ncomplicate this process. Consider the program Ex2 shown in Figure 1(A). For the mo\u00adment, let us assume \nthat the shaded grey code is missing, i.e., the program begins from the label 2:. This program is a simpli.ed \nversion of the following veri.cation instance: The variable x corre\u00adsponds to a .le; it is non-zero if \nthe .le has been opened. The .le may be opened and read depending on some condition, captured by the \nvariable a, that is unconstrained in the example (suppose it is an input). The .le should only be read \nif open; the branch at 6: mod\u00adels the check that the .le is indeed open, which is an assert that we put \nin just before an actual read from the .le takes place. Thus, the label ERR is reached if this assertion \nis violated. Let us suppose that the function f, whose code is not shown, always terminates, and that \nf does not modify the variables a, x. In this case, as the pro\u00adgram eventually breaks out of the loop, \na is unconstrained, and x is not set anywhere (recall that we are assuming the shaded lines are missing), \nthe target is indeed reachable. However, any feasible path to the target must contain a thousand unrollings \nof the for-loop , not to mention feasible paths through f. Any path to the target loca\u00adtion that does \nnot meet these requirements is infeasible, and if our static analysis returns such a path, we have no \noption but to dismiss it as a false positive arising from the imprecision of the analysis. In this case, \nthe analysis cannot be used to make any claim about the reachability of the target location. Counterexample-guided \nre\u00ad.nement based techniques are doomed to either take a long time to .nd an abstraction precise enough \nto force them around the loop a thousand times, or worse, not terminate, because of the dif.culty of \n.nding a feasible path through f, which may be arbitrarily com\u00adplex. The question then is, is it possible \nto use (overapproximate) static analyses to precisely report that the target location is reach\u00ad Figure \n2. (A)Program Ex1 (B)Path Slice able, without actually .nding a feasible path to it? Intuitively, the \ncode through the for-loop is irrelevant to the reachability of the er\u00adror location. In other words, if \nwe can reason that there exists some path from the start to the end of the loop, i.e., from location \n3: to 5:, and along such a path, the variables x, a are not modi.ed, then we are guaranteed that the \nlocation ERR: can be reached. Consider a candidate path to the location ERR: shown in Fig\u00adure 1(C). While \nthis particular path is infeasible, as we unroll the loop only once, if we delete the irrelevant operations \ncorrespond\u00ading to the loop (shown via the dotted edges), then the remaining sequence of operations is \nfeasible. We formalize this notion of re\u00admoving irrelevant instructions along a path as path slicing. \nA path slice of a control .ow path p in a program is a subse\u00adquence of the edges of p such that (1) if \nthe sequence of slice op\u00aderations is infeasible, then the original path is infeasible, and (2) if the \nsequence of slice operations is feasible, then the last location of p is reachable (modulo program termination). \nIntuitively, a path slice is obtained by dropping some edges along the path, but leav\u00ading the edges corresponding \nto branches that must be taken to reach the target, and assignments that feed the values to the expressions \nin the branches. Since a path slice concentrates attention on a particular control .ow path through the \nprogram, it can be much more precise than a statically computed program slice [25, 19, 24]. Consider \nthe program fragment shown in Figure 2(A). The function complex() does some computation that is hard \nto reason about statically, say it factors large numbers. Hence it is dif.cult to statically .nd a feasible \npath through it. However, suppose that complex() does not modify a. A backward program slice of Ex1 with \nrespect to the target location marked ERR, would not be able to remove the procedure complex(). This \nhappens as there is a path (namely that corresponding to the then branch of the conditional a > 0) along \nwhich the result of the function .ows into x, which in turn guards the branch before the target location. \nIf instead, we focus on the path shown in Figure 2(B), we .nd that the value returned by complex along \nthis path is irrelevant, and so a path slice would (1) eliminate the path through the function complex \nand (2) preserve the conditional corresponding to the else branch. Thus the states that can execute the \npath slice, namely those satisfying a = 0, all reach the target location (provided complex terminates). \nHence, a path slice can be signi.cantly more precise than static program slice. In the case where counterexamples \nare manually inspected, a path slice enables the human to focus on relevant sections of the abstract \ncounterexample path. In the case where counterexamples are automatically analyzed to guide abstraction \nre.nement, this extra precision can make the difference between termination and divergence: without this \nslice, we would iterate forever trying to .nd a feasible path through complex. Path slicing is distinct \nfrom dynamic slicing [20, 27] in two ways. First, the paths are not the result of a dynamic execution \nand hence are not guaranteed to be feasible. Second, and more importantly, we consider alternative program \npaths to .nd if some variant of the given path is in fact feasible, as shown by the path through Ex2. \nWe show how to ef.ciently compute a path slice, by performing a backwards data.ow analysis over the given \npath. Our algorithm, called PathSlice, iterates backwards over the path, tracking, at each point, the \nset of lvalues that determine if the suf.x of the path from that point is feasible, called the live lvalues \nand the source location of the last edge added to the slice, called the step location. We take an edge \ncorresponding to an assignment if the assignment is to a live variable. We take an edge corresponding \nto a conditional if either the conditional corresponds to the branch direction that must be taken to \nreach the step location, or if in the branch not taken, the program may have modi.ed a live variable. \nIf an edge is taken, the live set and step location are appropriately updated. We show how a must-reachability \nanalysis can be used to detect the former case, and a modi.ed-variable analysis can be used to detect \nthe latter case. Both these analyses are intraprocedural and hence give us an ef.cient path slicing algorithm. \nFor function calls, we only enter the body of the call if the function can modify a live variable, otherwise \nthe entire path through the call is sliced away. One limitation of path slicing is that it avoids the \ndif.cult ques\u00adtion of statically reasoning about termination. As a result, the fea\u00adsibility of a path \nslice guarantees that either the target location is reachable, or all states that can execute the path \nslice, cause the program to enter an in.nite loop. We have implemented Algorithm PathSlice in the counterex\u00adample \nanalysis phase of the software model checker BLAST [18]. We ran this enhanced algorithm to check for \n.le handling errors in a set of application programs. The largest programs checked had about 100K lines \nof code. Without the path slicing algorithm, the counterexample analysis phase of BLAST did not scale \nto any of these examples, because .rst the counterexamples were too large to analyze for feasibility, \nand second they contained many irrele\u00advant reasons for infeasibility, causing a blowup in the size of \nthe abstractions as well as the number of iterations taken to .nd the abstraction relevant to the property. \nWith the path slicing algorithm we were able to check .le han\u00addling errors in all the programs, and found \nviolations of the prop\u00aderty in some of them. In general, we found that slicing reduced counterexample \ntraces to less than 1% of their original size in most cases. In fact, as the size of counterexample traces \ngot bigger, the slicing was more effective (traces over 5000 basic blocks almost al\u00adways produced slices \nbetween 0.1% and 1% of their original sizes. The end-to-end veri.cation times (including model checking) \nfor these examples were all below one hour. In the cases where tool returns a feasible path slice it \nis much easier for the user to go over the more succinct slice to ascertain the veracity of the counterex\u00adample. \nThus, our experiments suggest that path slicing can extend the scope of static analysis by eliminating \nirrelevant details. Related Work. Program slicing [25] has been developed as a useful tool program debugging, \ncomprehension and testing [24]. Slicing is studied primarily in two forms: static and dynamic. In static \nslicing [19], the input is the static text of the program and a slicing criterion (for example, a set \nof variables at a par\u00adticular program point), and a static analysis algorithm is used to overapproximate \nthe set of all variables that may affect the slicing criterion [24]. Unfortunately, while the sliced \nprogram generated by these algorithms contains a subset of the statements and control predicates of the \noriginal algorithm, it is not guaranteed to be an ex\u00adecutable program. Moreover, static analysis algorithms \nfor slicing, especially in the presence of memory aliasing, are usually overly conservative, and manage \nto retain a large percentage of the origi\u00adnal program [22], as we found in experiments using a state-of-the\u00adart \nslicing tool [15]. The highly conservative nature of static slicing promoted the study of dynamic slicing \n[20, 27], where the program is executed on a particular test input, and the resulting execution trace \n(for that single input) is sliced. While this may not produce a slice for the entire program, it can \nbe more precise on the particular execution, and provide a smaller slice for applications in debugging. \nAs we have discussed in the prequel, path slicing is different from both of the above it combines the \nprecision of dynamic slic\u00ading with the static slicing s ability to reason about multiple paths. Parametric \nslicing [11] generalizes static and dynamic slicing by constraining a subset of the inputs to a program. \nPath slicing is dif\u00adferent because the control .ow path may not be feasible, moreover, the objective \nof the analysis is to construct suitable constraints on the inputs that makes some variant of the path \nfeasible. There has been some work in the model checking community to present to the user the cause of \nan error [2, 16, 4]. Typically these algorithms assume that the path is feasible, and use differenc\u00ading \nalgorithms to identify commonalities between multiple paths to error. The algorithm of [4] uses a dependence \nanalysis similar to path slicing for this purpose. In the past, automatic re.nement based techniques \n[3, 18] were used to analyze safety properties of low level device drivers. In our experience, the counterexamples \nfor such checks are typically two orders of magnitude smaller than counterexamples arising from application \nlevel programs, such as the ones we consider here, and hence could be directly analyzed [17]. It should \nbe noted that path slicing is orthogonal to parsimo\u00adnious abstractions [17] (.nding local predicates \nthat show the infea\u00adsibility of a trace). Path slicing .nds which operations along a trace can possibly \nin.uence reachability of the error location, while the re.nement algorithm of [17] analyzes the output \nof the path slicer to .nd why a path is infeasible.  2. Motivating Examples We begin by illustrating \npath slices and how our algorithm com\u00adputes them using some small examples. Recall the program Ex2 shown \nin Figure 1(A). The label ERR: corresponds to a target lo\u00adcation, and we are interested in whether the \nthe program can ever reach the target location, as this is equivalent to there being some program execution \nwhere the assertion being checked is violated. Control Flow Automata. We model programs as control .ow \nau\u00adtomata (CFA), which are essentially the CFG of each function, with the operations labeling the edges \ninstead of the vertices. A CFA consists of: (1) integer variables, (2) control locations, including the \nspecial locations start and exit, and (3) directed edges that con\u00adnect the locations. Control starts \nat the start location and ends at the exit location. Each edge is labeled by either an assignment that \nis executed when the program moves along the edge, or by an assume predicate which must be true for control \nto move along the edge, or a function call which corresponds to control jumping to the start lo\u00adcation \nof the called procedure. When the called procedure reaches its exit location, control transfers back \nto the successor of the call\u00adedge in the caller. A program is a set of CFA, one for each function. EXAMPLE \n1: [CFA] The CFA for Ex2 is shown on the right in Figure 1(B). We omit the CFA for the function f for \nbrevity. As with the program, let us assume for the moment that the shaded vertices are not present, \nand the CFA start node is 2. . Paths. A (program) path is a sequence of CFA edges, such that the calls \nand exits from functions are balanced, and within each CFA, the source of each edge in the sequence is \nthe target of the previous edge of the sequence. A path corresponds to a sequence of opera\u00adtions, namely \nthose labeling the edges. A path is feasible if there is some input on which the program executes the \ncorresponding sequence of operations. EXAMPLE 2: [Path] Figure 1(C) shows a path from the start lo\u00adcation \nof the CFA to the target location, again ignoring the shaded vertices. The path segment through f is \nomitted in the .gure for clarity. This path is infeasible. We set i to 1 at the start of the loop (on \nedge 3 - . 3 ), then go through the loop once, incrementing i once (on edge 4 - . 3 ) and then break \nout of the loop assuming that i exceeds 1000 (edge 3 -.  . 5) even though i is really 2. Path Slices. \nA slice of a path p is a subsequence of the edges of the p such that (1) (complete) whenever the sequence \nof operations labeling the subsequence is feasible, the target location is reach\u00adable1, and (2) (sound) \nwhenever the sequence of operations labeling the subsequence is infeasible, the path is infeasible. \n Intuitively, a path slice is obtained by dropping some edges along the path, but leaving the edges corresponding \nto branches that must be taken to reach the target, and assignments that feed the values to the expressions \nin the branches. EXAMPLE 3: [Completeness: Feasible Path Slice] In Figure 1(C), the set of solid edges \n(ignoring the shaded edge) is a slice of the en\u00adtire path shown. Notice that the sequence of operations \nlabeling the solid edges is feasible, and hence, by completeness, demonstrates that the target location \nis reachable. In particular, the inputs that can execute the sequence of solid edges are those that satisfy \nthe for\u00admula a = 0, and upon starting at any state satisfying this formula, the program can reach the \ntarget location. . EXAMPLE 4: [Soundness: Infeasible Path Slice] Let us now sup\u00adpose that the program \nEx2 in Figure 1(A) contains the shaded in\u00adstructions as well. In this case, the target location is not \nreachable, as the programmer has ensured that if a = 0, then x is set to 1. The corresponding CFA is \nthat shown in Figure 1(B) with the shaded vertices included, and a possible path to the target is shown \nin Figure 1(C), once again including the shaded vertices. The path through the loop remains infeasible, \nbut as it is irrelevant, the edges corresponding to the loop are omitted from the path slice. Note that \nthe two (inconsistent) branches that pertain to the reachability of the target remain in the slice. Thus \nany automatic re.nement scheme would be able to focus on the real reason for infeasibility, and hence \nthe real reason for the unreachability of the target, without gather\u00ading irrelevant facts about the loop \niterations. . Computing Path Slices. Our algorithm iterates backwards over the path, tracking at each \npoint (1) the live lvalues: the set of lvalues that determine if the suf.x of the path from that point \nis feasible, and (2) the step location: the source location of the last edge added to the slice. An assignment \nl := e gets added to the slice if l is an lvalue in the live set; in this case the lvalue is removed \nfrom the live set, and the lvalues of e are added to the set. The more interesting case is for branches. \nThe trace represents only one of the possible choices that the program may have made at a branch point, \nand an assume must be added to the slice if along any of these directions something may happen that affects \nthe slice suf.x. In particular, an assume 1 modulo termination, see Section 3 for details. branch is \nimportant if either along one of the other branch edges the program control veers off and does not return \nto the slice suf.x, or if along one of the other branch edges the program writes an lvalue that is live, \ni.e., read along the slice suf.x. The .rst case is important because only one direction leads to the \nerror along the slice suf.x, and the second case because the branch controls whether or not a live variable \ngets updated. To determine if the .rst case occurs, we check if there exists a path from the source of \nthe branch that can bypass the step loca\u00adtion altogether, if so then only the assume operation corresponds \nto the branch direction that leads to the step location and hence must be added. To determine if the \nsecond case occurs, we check if there exists a path between the source of the branch and the step location \nalong which a live variable is written. This analysis is different from dynamic slicing algorithms where \nwe know that the trace under consideration is feasible. In our algorithm, although the given path may \nbe infeasible, a vari\u00adant of it, obtained by dropping irrelevant edges, may be feasible. In path slicing, \nwe keep only those edges, in particular those branches, that must be taken along this path to reach the \ntarget location. EXAMPLE 5: [Computing a Path Slice] We now illustrate our algorithm by showing how the \npath slice shown in Figure 1 is computed. In Figure 1(C), the value of the step location and the live \nset is shown at each point along the path. We start at the last location, the target location. At this \npoint, the step location and the live set are (trivially) ERR and the empty set respectively. Next, we \nprocess the location 6. Notice that 6 can bypass the current step location ERR, if the operation corresponding \nto the else branch is taken. Hence, this assume is relevant, and we add the edge 6 - . ERR to the slice. \nThe step location and live set at 6 are updated to 6 and the set {a},as a appears in the branch condition. \nNext, we process the location 5. Notice that 5 can also bypass the current step location 6, again by \nfollowing the else branch. Thus, this assume edge is also added to the slice, and the step location and \nlive set at 5 are updated to 5 and {x, a}as a appears in the branch condition. Next, we process (the \nsecond instance) of location 3 . This time, we .nd that 3 cannot bypass the step location 5 unless either \nthe loop or f does not terminate, it is inevitable that location 5 will be reached. Also, on no path \nfrom 3 to 5, are any of the currently live variables {x, a}modi.ed. Hence, the assume edge 3 - . 5 is \nirrelevant and not added to the slice (is dotted in the .gure), and the step location and live set remain \nunchanged. Next, we process the edge 4 - . 3 . As none of the live variables are modi.ed by these assignments, \nwe discard the edge from the slice. We then process the assume edge 3 - . 4. Once again, as 3 cannot \nbypass the current step location 5, and no path from 3 to 5 modi.es a live variable, we omit the edge. \nThe assignments along the edges 3 -.3 are not to live variables and so these edges are . 3 and 2 -omitted \nfrom the slice. This is the slice of the program starting at node 2. If the shaded code is included, \nwe come to the last assume edge 0 - . 2. Notice that 0 cannot bypass the current step location 5 (node \n5 postdominates node 0). However, there exists a path from 0 to 5 along which the live variable x is \nmodi.ed, and this path is along the branch not taken. Hence, in order that the given path correspond \nto a path to the target, this particular branch must be taken. As a result, this edge is added to the \nslice, rendering the path slice infeasible. .  EXAMPLE 6: [Path Slicing vs. Program Slicing] In both \nthe pre\u00advious examples, a program slice would have suf.ced to eliminate the for loop. However, consider \nexample Ex1 in Figure 2(A). In Figure 2(B), the solid edges denote the path slice for the path cor\u00adresponding \nto all the edges (the subpath through complex is omit\u00adted for clarity). The annotations on the right \nare the values of the step location and live set as we iterate backwards over the path. The reader can \nuse them to verify that the slice shown is indeed the one that the above algorithm would compute. Hence, \nby focusing the slice on a particular path, we can eliminate the procedure complex entirely. Thus, without \nactually .nding a complete feasible path, we can show that if complex terminates, then upon starting \nfrom any state where a =0, the program can reach the target location. .  3. Programs, Paths, and Slices \nWe illustrate our algorithm on a small imperative language with integer variables, references, and functions \nwith call-by-value pa\u00adrameter passing. We begin by completely developing our technique for programs without \nprocedure calls or references. After this, we add pointers. In the next section, we show how the techniques \nare generalized to programs with procedure calls. 3.1 Syntax and Semantics We .rst consider a language \nwith integer valued variables, and no procedure calls. Boolean expressions arise via boolean combina\u00adtions \nof arithmetic comparisons. Operations. Our programs are built using two kinds of basic oper\u00adations: 1. \nAn assignment operation is of the form l := e; which corre\u00adsponds assigning the value of the expression \ne to the variable l, 2. An assume operation is of the form assume(p); if the boolean expression p evaluates \nto true, then the program continues, and otherwise the program halts. Assumes are used to model branch \nconditions.  The set of operations is denoted Ops. Control Flow Automata. Each function f is represented \nas a control .ow automaton (CFA) Cf =(PC f , pc0, pcout,Ef ,Vf ). The CFA Cf is a rooted, directed graph \nwith: (1) a set of control locations (or program counters) PCf which include a special start location \npc0 .PC f , and a special exit location pcout .PC f , (2) a set of edges Ef . PC f \u00d7Ops \u00d7PC f . We write \n ' (pc, op, pc) to denote the edge from pc to pc' labeled op. A CFA is the control .ow graph of a program; \nits locations corre\u00adspond to program locations, and its edges correspond to the com\u00admands that take the \nprogram from one location to the next. A pro\u00adgram comprises a single CFA Cf corresponding to a procedure \nf. States, Transitions. For a set of variables X,an X-state is a valuation for the variables X. The set \nof all X-states is written as Val.X. Each operation op gives rise to a transition relation opop . .Val.X \n\u00d7Val.X as follows. We say that s.s' if: ' s if op =assume(p) and s |= p s = s[l if op =l := e .s.e] \nWe say that a state s can execute the operation op if there exists op' some s' such that s.s. Weakest \nPreconditions. An alternative way to view the semantics of programs is via logical formulas. A formula \n. over the vari\u00adables X represents all X-states where the valuations of the vari\u00adables satisfy .. The \nweakest precondition of . w.r.t. an operation op, written WP...op is the set of states that can reach \na state in op . after executing op. Formally: WP...op ={s |.s' ...s.s'}. The weakest precondition operator \nfor our language can be com\u00adputed syntactically as a predicate transformer [10], as shown in the second \ncolumn of Figure 3. Traces. A trace t is a sequence of operations. We say that a state s can execute \nthe trace t if either t is the empty sequence E,or op t =op; t ' and there exists s ' such that s.s ' \nand s ' can execute the sequence t ' . We say that a trace t is feasible if there exists a state s that \ncan execute t , and we say the trace is infeasible otherwise. The weakest precondition operator extends \neasily to traces as: . if t =EWP...t = WP.(WP...op).t ' if t =t ' ; op It is easy to check that a trace \nt is feasible iff WP.true.t is satis.able [10]. Program Paths. A CFA edge (pc ' , \u00b7, \u00b7) is a successor \nof another CFA edge (\u00b7, \u00b7, pc),if pc = pc ' .A program path, or path in brief, is a sequence of CFA edges \np = p.1; ... ; p.n, such that for each 2 =i =n, the edge p.i is a successor of the edge p.(i -1).We denote \nby |p|the number of edges on the path p. We say that p is a path from pc to pc ' if p.1 =(pc, \u00b7, \u00b7) and \np.|p|=(\u00b7, \u00b7, pc ' ). The trace Tr.p of a path p is the sequence of operations labeling the edges along \nthe path. A state s can execute the path p if it can execute the trace Tr.p. A path p is feasible if \nthere is some state that can execute p, and infeasible otherwise. Reachability. A state s can reach a \nlocation pc if there exists a path p from pc0 to pc such that s can execute p, otherwise it cannot reach \nthe location. A location pc is reachable if there exists some state that can reach it. 3.2 Path Slices \nSlices. Let p be a path. Then any subsequence p ' =p.i1; ... ; p.ik for 1 =i1 <... < ik =|p|,isa path \nslice of p, written p ' -p. In the sequel assume that p is a program path from pc0 to (a special error \nlocation) pcE . Soundness. We say that a path slice p ' of p is a sound slice if WP.true.(Tr.p) .WP.true.(Tr.p \n' ). In other words, every state that can execute the trace Tr.p can also execute the trace Tr.p ' . \nIn particular, if p ' is a sound slice of p and WP.true.(Tr.p ' ) is not satis.able, then WP.true.(Tr.p) \nis not satis.able, i.e., p is infeasible. We can think of p ' as overapproximating p. While a sound slice \nmay be very coarse the empty slice is sound not all slices are sound. For example, the result of dropping \nthe second edge in the path (pc0, assume(l =0), pc1); (pc1, l := 1, pc2); (pc2, assume(l =1), pc3) is \nan unsound slice. Completeness. We say that p ' is a complete slice of p if for every s .WP.true.Tr.p \n' either: (1) there exists a program path p '' from pc0 to pcE such that s can execute p '' ,or, (2) \ns cannot reach pcout.  Hence, if p ' is a complete slice of a path to a particular (error) location, \nand Tr.p ' is feasible, then every state that can execute Tr.p ' either can reach the error location, \nor causes the program to loop forever. EXAMPLE 7: We can check that the path slice shown in Fig\u00adure 1(C) \nis sound and complete. Let us consider the program Ex2, without the shaded parts. In this case we .nd \nthat the slice com\u00adputed is sound because the WP over the operations in the slice is . =x =0 .a> 0, while \nthe weakest precondition over the entire trace is . conjoined with constraints arising from the path \nthrough f. The slice is complete because every starting state satisfying ., either gets stuck inside \nf during some iteration of the loop, and hence never reaches the exit, or, after spinning around the \nloop a thousand times, takes both the if branches and reaches the target location. .  3.3 Computing \nPath Slices We now describe our algorithm PathSlice that takes a program path and computes a sound and \ncomplete slice from it. Informally, PathSlice performs a data.ow analysis on the program path. We iterate \nbackwards, tracking at each point along the path: Live set. A set of relevant live lvalues whose valuations \nat that point determine whether or not the error location is reachable along the suf.x of the trace, \nand, Step location. The source location of the last edge along the path that was added to the slice. \nWe analyze each operation along the path in turn, and use the live set and the step location to decide \nwhether or not to add the current operation to the slice (Procedure Take). At each point, we call the \nedges that have already been added to the slice the slice suf.x. The live set and step location encode \nthe outstanding data and control dependencies at each point along the trace. We now give a formal description \nof the algorithm. We .rst de\u00adscribe a few sets and relations that are used to determine whether a given \noperation should be in the slice, then describe how these are combined inside Procedure Take, and .nally, \nhow the latter is used to obtain a sound and complete path slice in the Algo\u00adrithm PathSlice. Reads, \nWrites. We denote by Lvs.e the set of lvalues occurring in an expression e. This is extended to predicates \nin the nat\u00adural way. We say Rd.op.l to denote the fact that lvalue l is read by the operation op. We \nwrite Rd.op to denote the set {l |Rd.op.l}, i.e., the set of all lvalues read by op.Wesay Wt.op.l to \ndenote the fact that l is written (assigned to) by the operation op. We write Wt.op to denote the set \n{l |Wt.op.l}. A formal description of Rd and Wt is in the third and fourth column of Figure 3. Bypassing \nLocations. We say that a location pc can bypass loca\u00adtion pc ' , if there exists a path from pc to the \nexit location pcout for the function that does not visit pc ' . The set of locations that can bypass \npc ' is written as By.pc ' . This is the set of all loca\u00adtions that pc ' does not postdominate. Written \nBetween. We say that an lvalue l is written between locations (pc, pc ' ), denoted by WrBt.(pc, pc ' \n).l, if there exists a path p from pc to pc ' such that some operation along the path is an assignment \nto l, i.e., there exists some i such that p.i =(\u00b7, op, \u00b7) and Wt.op.l. We generalize this to sets of \nlvalues L as WrBt.(pc, pc ' ).L =.l .L : WrBt.(pc, pc ' ).l. Procedure Take. Armed with the above relations, \nwe de.ne the procedure Take which takes as input (1) the set of live lvalues L, (2) the step location \npcs, and (3) an edge (pc, op, pc ' ), and returns a boolean indicating whether this edge should be added \nto the slice. The formal de.nition of Take.(L, pcs).(pc, op, pc ' ) is given in the .fth column of Figure \n3. Assignments get taken if the lvalue written to is in the live set Live. Assumes, corresponding to \nbranches, are somewhat trickier. An assume gets taken if there is a path from the current edge that can \nbypass the step location, or if there exists a path from the current edge to the step edge along which \na live variable gets modi.ed. If the step location can be bypassed, then it means that if the program \nhad taken the other branch direction, then it may have bypassed the step location and hence not executed \nalong the slice suf.x. If there is a path between the source location and the step location along which \na live lvalue gets written, it means that if the program had taken the other branch direction then it \nmay have written that live lvalue (which it didn t along the path being sliced, as the lvalue is currently \nlive), and thus not been able to execute the slice suf.x. op WP...op Rd.op.l ' Wt.op.l ' Take.(L, pcs).(pc, \nop, pc ' ) l ' = l ' l := e .[e/x] . Lvs.el l . L assume(p) . . p l ' . Lvs.p false WrBt.(pc, pcs).L \n. pc . By.pcs f() . false Mods.f.l true return . false false Mods.f.L where pc ' = Cf .pcout Figure 3. \nWP, Rd, Wt, Take for PI Algorithm 1 PathSlice Input: Program Path p. Output: Path Slice p ' . 1: p ' \n:= [\u00b7] 2: i := |p| 3: Live := \u00d8; (\u00b7, \u00b7, pcstep):= p.i 4: while i = 1 do 5: e := p.i 6: tk := Take.(Live, \npcstep).e 7: if tk then p ' 8: := e :: p ' 9: (pc, op, \u00b7):= e 10: Live := (Live \\ Wt.op) . Rd.op 11: \npcstep := pc 12: i := i - 1 13: return p ' Algorithm PathSlice We now show how the above can be com\u00adbined \nto make a linear pass over a path to obtain its slice. The Al\u00adgorithm PathSlice is shown in Figure 1. \nThere is a main while loop which iterates backwards over the entire path, starting at the last edge. \nThe initial Live set is the empty set and the initial step location is the target location of the last \nedge of the path. In each iteration the loop, we invoke Take to see if the ith edge should be added to \nthe slice. If Take returns true then we (1) update the Live set by removing the lvalues written in the \nith operation and adding the lvalues read in this operation, (2) update the step location to be the source \nof the current operation, and (3) add the edge to the path slice. We then decrement i and proceed to \nthe next edge until we have processed all the edges, at which point we return the edges accumulated in \nthe slice so far as the path slice.  THEOREM 1. For any program path p PathSlice.p is a sound and complete \npath slice of p. Moreover, PathSlice.p is computed in time linear in the size of p, with a linear number \nof calls to WrBt and By. The above theorem can be shown by induction on the path. The algorithm PathSlice \nenjoys the stronger property, that as it iterates backwards over the path, at each point, the set of \nedges that it has taken in the slice, i.e., the slice suf.x is a sound and complete path slice for the \npath suf.x at that point. Precisely, the algorithm maintains the following inductive invariant. At any \nstep of the algorithm, we have already selected a subset of edges into the slice, call this the slice \nsuf.x S. Let . be WP.true.S, the weakest precondition along the slice suf.x. At any point in the path, \nlet the step location be pcs, the live lvalues be Live, and the current location be pc. The invariant \nis that if the program can reach pc with data values for the lvalues in Live satisfying ., then either \nthe program loops forever, or there is a feasible path in the CFA from pc to pcs such that the data values \nfor the lvalues in Live at the end of the path still satisfy .. Notice that the last condition implies \n(by de.nition of .) the slice suf.x is executable from pcs and this valuation to the lvalues all the \nway to the .nal location. 3.4 Pointers We now describe how the above generalizes to the setting where \nin addition to integer variables, the programs contain derefer\u00adences. Lvalues now generalize to memory \nlocations, and corre\u00adspond to either declared variables or dereferences of pointer-typed expressions. \nBoolean expressions are extended to contain checks of pointer equality. The only change that must be \nmade in the algorithm described above, is in the de.nition of Wt, which must be generalized to deal with \nupdates due to aliasing. Suppose that we have precomputed the aliasing relations MayAlias and MustAlias \non the lvalues of the program. We say MayAlias.l.l ' (respectively, MustAlias.l.lv ' ) if l may (respectively, \nmust) be aliased to l ' . We require that the computed MayAlias be an over-approximation of the actual \npoints to relation, and that the computed MustAlias be an under\u00adapproximation of the actual points to \nrelation. The de.nition of Wt.op.l ' (used to de.ne WrBt) is general\u00adized to Wt.op.l ' if op is l := \ne and MayAlias.l.l ' . The de.\u00adnition of Wt.op, used to update the Live set in line 10 of Al\u00adgorithm \nPathSlice, changes to the set {l ' | MustAlias.l.l ' } if op = l := e, and remains the empty set otherwise. \nThe algorithm PathSlice is identical to the one previously described, once the gen\u00aderalized versions \nof Wt are used. With these generalizations, The\u00adorem 1 holds for programs with pointers.   4. Programs \nwith Procedures We now describe how to generalize path slicing to programs with procedure calls. First, \nwe generalize the de.nition of the syntax and semantics of programs, and describe what program paths \nlook like in this setting. For clarity of exposition, we make the following assumptions: (1) all variables \nare integer valued, i.e., there are no pointers, (2) parameters and return values are passed to and from \nprocedures using global variables (i.e., there are no formal param\u00adeters or return values), (3) local \nvariables for different procedures have disjoint names, and there is no recursion. Our method gener\u00adalizes \nto and our implementation deals with programs without any of the above restrictions. Syntax. We generalize \nthe de.nition of programs from Section 3 to contain procedures and calls. A program contains a set of \nglobal variables V , and each procedure f contains in addition a set of local variables Vf . Parameters \nare passed to procedures via global vari\u00adables (i.e., parameters are written into some globals, and the \ncalled procedure copies the values from the globals into its own local vari\u00adables). Similarly, procedures \nreturn values via global variables. We extend the set of operations labeling CFA edges to include call \noperations of the form f() and return operations return.We assume that in any CFA Cf =(PC f , pc0, pcout,Ef \n,Vf ), every edge (pc, return, pc ' ) is such that pc ' = pcout, i.e., all return statements lead to \nthe exit location of the CFA. A program is a set of CFAs .= {Cf0 ,...,Cfk }, where each Cfi is the CFA \nfor a function fi. There is a special function main with CFA Cmain corresponding to the procedure where \nexecution begins. Semantics. With our various assumptions about the program, the de.nitions of states \nand transitions remain essentially unchanged. The relation op . for the new operations call and return \nis simply the identity relation. Similarly, the weakest precondition for a call or return statement is \nthe identity map. Program Paths. The only change brought about by the addition of procedures is in the \nde.nition of program paths, which must be extended to reason about calls and returns. Let p be a sequence \nof CFA edges p.1; ... ; p.n. De.ne Call.1=1 and for each 2 =i =n de.ne Call.i as: { i -1 if p.(i -1) \n= (\u00b7, f(), \u00b7) Call.i =Call.(Call.(i -1)) if p.(i -1) = (\u00b7, return, \u00b7) { Call.(i -1) o.w. We say that \np is a program path if for each 2 = i = n: (1) if p.(i -1) = (\u00b7, f(), \u00b7) then p.i =(Cf .pc0, \u00b7, \u00b7), (2) \nif p.(i -1) = (\u00b7, return, \u00b7) then p.i is a successor of p.(Call.(i-1)), and, (3) p.i is a successor of \np.(i -1) otherwise. Intuitively, Call.i is the operation that begins the call frame to which the ith \noperation belongs. It is easy to see that for any program path p, for all i> 1, the edge Call.i is of \nthe form (\u00b7, f(), \u00b7) for some f. As before, the trace Tr.p is the sequence of operations on the path \np. A path p is feasible if the trace Tr.p is feasible, and we say the path is infeasible otherwise. Path \nSlicing. We now describe how to generalize the algorithm from the previous section to work in the presence \nof procedure calls. To do so, we will require another (precomputable) relation Mods. Intuitively, for \na function f and lvalue l,wesay Mods.f.l if the lvalue l can be modi.ed directly inside f, or within \nany function that may (transitively) be called by f. Formally Mods.f.l =WrBt.(Cf .pc0,Cf .pcout).l where \nthe de.nition of WrBt is the same as before. We extend this to sets of lvalues L as: Mods.f.L =.l .L \n: Mods.f.l We write by Mods.f the set {l |Mods.f.l}. Notice that this set can be computed by using a \nstandard mod-ref analysis [1]. Next, we generalize Take to deal with calls and returns. Given a return \nstatement, we should only take it and analyze the path between the call corresponding to the return, \nif a variable in the live set can be modi.ed by the call. A call statement is always taken, as we shall \nsee below, this is done so as to keep the queries to WrBt, By intraprocedural. The formal de.nition of \nTake for calls and returns is shown in the third and fourth rows of Figure 3. Finally, to generalize \nPathSlice to handle calls and returns, we replace line 12 (in Figure 1) (i := i -1) with: i := if \u00actk \n&#38; op = return then Call.i -1 else i -1 That is, if we .nd that the return was not taken, meaning \nthe func\u00adtion being returned from is not relevant, then instead of processing the path through the function, \nwe set i to the .rst edge before the call. Notice that this implies that whenever a call operation is \npro\u00adcessed, the corresponding return must have been taken (or there was no corresponding return). With \nthese generalizations, Theo\u00adrem 1 holds for programs with procedures as well. 4.1 Intraprocedural Relations \nAs we always take call operations, the algorithm PathSlice de\u00adscribed above has the property that whenever \na query is made to WrBt or By, the pair of program locations used in the query belong to the same CFA. \nHence, ef.cient intraprocedural algorithms can be used to compute those relations. We next describe how \nto obtain these relations via a .xpoint computation which can either be done explicitly or using symbolic \ntechniques based on BDDs [26, 5]. We assume that Mods has been computed by a standard mod-ref analy\u00adsis, \nand hence, we can compute Wt for every operation (Figure 3). Computing WrBt. Recall that WrBt.(pc, pc \n' ).l if l is written between pc and pc ' , equivalently, if l is written on some edge that is both reachable \nfrom pc and can reach pc ' . Thus, we perform the following intraprocedural .xpoint computation. Let \nOut and In be the least .xed points of the equations below: In.pc =e .In.pc ' ' e:(pc,\u00b7,pc) and Out.pc \n=e .Out.pc ' . e:(pc,\u00b7,pc') The set In.pc (respectively, Out.pc) contains the set of edges that can reach \npc (respectively, can be reached from pc). Then WrBt is de.ned as: WrBt.(pc, pc ' ).l =.(\u00b7, op, \u00b7) .Out.pc \nnIn.pc ' : Wt.op.l. Computing By. The set By.pc is de.ned as the least .xpoint of the following equations: \nBy.pcout =\u00d8and for pc= pcout, By.pc =({pc}. out ) '''' '' {pc |(pc , \u00b7, pc ) .E .pc .By.pc}\\{pc} That \nis, a location pc ' belongs to By.pc if either it is the exit node, or it has a successor that belongs \nto By.pc (and pc never belongs to By.pc). Since By.pc is the set of all locations that pc does not postdominate, \nthis can be computed by an algorithm to compute postdominators. In case there are locations in the CFA \nthat do not reach the exit location, we .rst add dummy edges from all these locations to the exit location \nbefore running the postdomination algorithm. 4.2 Optimizations We analyze traces produced by a model \nchecker to discover whether a given program path is infeasible (and must be used to re.ne the set of \ndata.ow facts used for analysis), or whether it cor\u00adresponds to a feasible path to the error location \n(indicating a vio\u00adlation of the speci.cation being checked). We now describe some optimizations of the \nalgorithm that are particularly suited to this application. Unsatis.able Path Slices. An alternative \nway to compute the weakest precondition of a trace t is to .rst rename the variables so that they are \nin SSA form, so that the weakest precondition is the conjunction of a set of constraints, with each constraint \ndirectly corresponding to a (SSA-renamed) operation [13, 17]. As we iter\u00adate backwards over the path \nin order to obtain the slice, every time we take an operation, we generate the constraint corresponding \nto that operation, and assert that constraint to a decision procedure. If at any point the decision procedure \nreports that the set of asserted constraints is unsatis.able, we stop the slicing at that point and re\u00adturn \nthe sequence of edges taken till that point, since adding more operations to the slice will not alter \nthe fact that it is unsatis.able. Skipping Functions. The algorithm PathSlice works very well in slicing \naway paths through procedures that do not affect the live variables. In several of our examples, we found \npaths where the path to the target has a deep call stack at the end. Hence, along the given path, a sequence \nof calls must be made in order to reach the target location. As each function on this call stack calls \nthe next function under some speci.c conditions, all the guards preceding the calls get added to the \npath slice. However, each of these guards may be irrelevant to the reachability of the target: for our \npurposes, it is suf.cient that there is some feasible path from the start of each function on the stack \nto the location where the function calls the next function on the stack. On the other hand, if some live \nlvalue can be written between the start and the location where the next function is called, then we should \nnot slice away those edges. This is done by changing the else condition on the line 12 of PathSlice (Figure \n1) to be: if \u00actk &#38; \u00acWrBt.(pc0, pc).Live then Call.i else i - 1 We found that in some cases this enabled \nthe slice to contain only those branches that guarded modi.cations to variables relevant to the property. \nThis led to the discovery of the appropriate data.ow facts. Without this modi.cation, whenever the path \nto the error lo\u00adcation contained a deep call stack with several branches guarding the path from the entry \nof a function to the point where the next function on the stack was called, the resulting path slice \nwas infea\u00adsible because of these irrelevant branches, which caused irrelevant data .ow facts to be added \nto the system. However after this modi\u00ad.cation the resulting slice is not guaranteed to be complete. \n  5. Experiments We have implemented the algorithm to generate path slices in the BLAST software model \nchecker [18]. Benchmark Programs and Property. Table 1 shows our bench\u00admark programs. The column LOC \nshows lines of code before and after preprocessing, the number of lines before preprocessing is ob\u00adtained \nby simply running wc -l in the source directories, the pre\u00adprocessed lines of code do not include comments \nor blank spaces. The procedures column show the number of modeled procedures. This does not include external \nC system libraries to which calls may have been made. The benchmark ijpeg is taken from the Spec95 benchmarks \nsuite. We checked the correct behavior of .le pointers. We instru\u00admented the code to track the system \ncalls fopen and fdopen to mark the return value as an open .le pointer (in case it is non-null). For \nevery fprintf, fgets,or fputs, we check that the .le argu\u00adment is an open .le. Finally, we instrument \nfclose to expect an open .le, and change the .le state to closed. Our methodology to check the .le property \nwas the follow\u00ading. For each instrumented program, we check that a certain func\u00adtion call error introduced \nby the instrumentation can never be called. Each call to error in the program can be independently checked, \nand the program satis.es the property if error can\u00adnot be called on any program execution path. Instead \nof checking each error separately, we cluster calls to error accord\u00ading to their calling functions, and \nthen check each function that can potentially call error independently. The column Number of checks in \nTable 1 shows the number of functions that can po\u00adtentially call error directly (the .rst number), as \nwell as the total number of points instrumented with calls to error . The col\u00adumn Results shows the number \nof checks on which the tool proved that the .le access was safe, the tool claimed an error trace, and \nthe tool timed out, respectively. We set a timeout limit of 1000s per check. The total time shows the \ntotal time of all checks that .n\u00adished (i.e., excluding the 1000s for each check that timed out), and \nthe Maximum time is the maximum time taken by any one check that .nished. Finally, the number of re.nements \nshows the number of abstract counterexample traces produced. These are the traces that were reduced using \nAlgorithm PathSlice. We found three violations of the speci.cation in wuftpd. The part of the program \nrelevant to the error trace is shown in Figure 4. The error trace says that the fgets in statfilecmd \ncan fail. Since we do not model the library function getrlimit, it is possible for        void \nstatfilecmd(char *filename) { FILE *fin ; ... fin = ftpd popen(line, (char *) r\", 0); ... while(1) { \ntmp = fgets(line, sizeof(line), fin); ... }} FILE *ftpd popen(char *prgm, char *typ, int closestderr) \n{ FILE *iop ; rlp.rlim max = ~ 0UL; rlp.rlim cur = rlp.rlim max; tmp = getrlimit(7, &#38; rlp); if (tmp) \n{ return ((FILE *)((void *)0)); } ... } Figure 4. Counterexample in wuftpd Figure 5. Effect of PathSlice \nit to return a nonzero value, and hence it is possible for ftpd popen to return a NULL .le pointer. Since \nat other places of the program, the returned .le pointer from ftpd popen is checked for NULL, we believe \nthat this is a bug. The other violations were similar. In privoxy, the error trace read data off a con.guration \n.le and accessed an (unchecked) .le pointer based on the data read. Again, since we do not model con.guration \n.les, we .ag this as a possible error. Figure 5 shows the effect of running the path slicing algorithm \non the abstract counterexample traces produced in the check. The x-axis shows the size of the original \ntraces in number of basic blocks. The y-axis shows the size of the reduced trace as a percent\u00adage of \nthe original trace, computed as |PathSlice.p| \u00b7 100%, where p p Program Description LOC Procedures Number \nof Results Total time Max time Number of  checks  re.nements fcron 2.9.5 cron daemon 12K/14K 121 10/25 \n10/0/0 22.95 9.56 15 wuftpd 2.6.2 ftp server 24K/35K 205 33/59 30/3/0 2417.41 412.08 74 make 3.80 make \n30K/39K 296 19/44 18/1/0 89.8 32.7 35 privoxy 3.03 web proxy 38K/51K 291 15/54 13/2/0 107.5 69.1s 13 \nijpeg jpeg compression 31K/37K 403 21/43 21/0/0 128.0s 121.6 23 openssh 3.5.1 ssh server 50K/114K 745 \n24/84 23/0/1 2211.5 554.1 135 Table 1. Benchmarks and analysis times. is the original trace. The y-axis \nis in logarithmic scale. On the aver\u00adage, the projected traces are less than 5% of the original traces. \nThe largest projected trace is 57% of the original trace, this happens in openssh where the input trace \nhas 47 operations, and the output has 27. However, as the trace sizes go up, the ratio of projected trace \nto the original trace goes down. This is true across all our bench\u00admarks. In particular, for traces over \n1000 basic blocks in size, the projected traces are less than 1% of the original trace. This con\u00ad.rms \nour intuition that while the size of the counterexample traces grow with the size of the program, for \nsimple properties, there is usually a small abstraction that is suf.cient to prove the unsatis.\u00adability \nof a trace, and conversely that there is a simple explanation of a counterexample. Limitations. We now \ndescribe certain limitations that we found on further experiments. The .rst limitation is the use of \ndepth .rst search in the context-free reachability algorithm which results in very long counterexamples. \nWe are investigating breadth .rst search algorithms that .nd the shortest counterexamples. The sec\u00adond \nlimitation is in BLAST s imprecise modeling of the heap. The third is due to inef.ciencies in the current \nimplementation. We tried to check the .le property on the program muh (version 2.1rc1), an IRC proxy. \nThe program was 15K lines of code after preprocessing, had 152 functions, of which 14 were instrumented \nwith a total of 25 possible error points. We were surprised to .nd that 9 checks failed with error found \nor BLAST not .nding new predicates. On closer examination of the source code, we found that muh was handling \n.le pointers in the following way. There is a hash table (built as an array of linked lists) that keeps \na map from channel names (strings) to .le pointers. There are operations to add channels to this table, \nopen or close a .le pointer entry in the table, and to remove channels from this table. Since we do not \nmodel the heap precisely, BLAST was unable to reason about .le pointers being put inside these linked \nlists. We believe that techniques from shape analysis [23] may help in this example. Second, we tried \nto check the .le property on gcc. We took gcc code from the Spec95 benchmark suite. The total number \nof modeled procedures was 2026. We instrumented 703 sites for checks of correct .le usage, these instrumentations \nwere scattered in 132 different functions. Again, we tried to check correctness for all instrumentations \nin the same function together. We met with limited success on gcc. Of the 132 checks we ran on, only \n76 .nished in the allotted time of 1200s per query. This time includes all the model checking, projection, \nand re.nement time, but does not include the cost of building the alias and the mod/ref information. \nWe looked at the breakdown of the time taken, and in all cases, the time was dominated by the computation \nof By and WrBt. We believe that ef.cient implementations of these analyses using state-of-the-art techniques \nlike BDDs [6, 26, 21] to represent the information succinctly can ensure that the techniques scale to \nlarge programs. We are currently investigating such algorithms. However, re.nement steps that did .nish \nin the allotted time con.rmed our expectations that the projected trace will be much smaller than the \noriginal counterexample. Figure 6 shows the re- Figure 6. Trace projection results for gcc sults for \nAlgorithm PathSlice on 313 gcc counterexamples. The largest counterexample we encountered had 82,695 \nbasic blocks, however, after projection, the number of operations was a 43. For larger counterexamples, \nthe reduced trace was less than 0.1% of the original size. The reduced traces were amenable to usual \ncoun\u00adterexample analysis, but the original traces were not. The sizes of counterexamples also show that \nsome form of slicing must be performed in order to get ef.cient counterexample analysis in counterexample-guided \nabstraction re.nement, since the size of trace formulas generated is usually beyond the limit of current \nde\u00adcision procedures.  References [1] A.V. Aho, R. Sethi, and J.D. Ullman. Compilers: Principles, Techniques, \nand Tools. Addison-Wesley, 1986. [2] T. Ball, M. Naik, and S.K. Rajamani. From symptom to cause: Localizing \nerrors in counterexample traces. In POPL 03: Principles of Programming Languages, pages 97 105. ACM, \n2003. [3] T. Ball and S.K. Rajamani. The SLAM project: debugging system software via static analysis. \nIn POPL 02: Principles of Programming Languages, pages 1 3. ACM, 2002. [4] S. Basu, D. Saha, and S.A. \nSmolka. Localizing program errors for Cimple debugging. In FORTE 04: Formal Techniques for Networked \nand Distributed Systems, LNCS 3235, pages 79 96. Springer, 2004. [5] D. Beyer, A. Noack, and C. Lewerentz. \nSimple and ef.cient relational querying of software structures. In Proc. WCRE, pages 216 225. IEEE, 2003. \n[6] R.E. Bryant. Graph-based algorithms for boolean function manipula\u00adtion. IEEE Transactions on Computers, \nC-35(8):677 691, 1986. [7] S. Chaki, J. Ouaknine, K. Yorav, and E.M. Clarke. Automated compositional \nabstraction re.nement for concurrent C programs: A two-level approach. In SoftMC 03: Software Model Checking, \n2003. [8] H. Chen and D. Wagner. MOPS: An infrastructure for examining security properties of software. \nIn Proceedings of the 9th ACM Conference on Computer and Communications Security (CCS 02, Washington, \nDC), pages 235 244. ACM Press, 2002. [9] M. Das, S. Lerner, and M. Seigle. ESP: Path-sensitive program \nveri.cation in polynomial time. In PLDI 02: Programming Language Design and Implementation, pages 57 \n68. ACM, 2002. [10] E.W. Dijkstra. A Discipline of Programming. Prentice-Hall, 1976. [11] J. Field, G. \nRamalingam, and F. Tip. Parametric program slicing. In POPL 95: Principles of Programming Languages, \npages 379 392. ACM, 1995. [12] C. Flanagan, R. Joshi, X. Ou, and J.B. Saxe. Theorem proving using lazy \nproof explication. In CAV 03, LNCS, pages 355 367, 2003. [13] C. Flanagan and J.B. Saxe. Avoiding exponential \nexplosion: generating compact veri.cation conditions. In POPL 00: Principles of Programming Languages, \npages 193 205. ACM, 2000. [14] J.S. Foster, T. Terauchi, and A. Aiken. Flow-sensitive type quali.ers. \nIn PLDI 02: Programming Language Design and Implementation, pages 1 12. ACM, 2002. [15] Grammatech. Codesurfer \n1.9. Technical report, 2004. [16] A. Groce and W. Visser. What went wrong: Explaining counterex\u00adamples. \nIn SPIN 03: SPIN Workshop, LNCS 2648, pages 121 135. Springer, 2003. [17] T.A. Henzinger, R. Jhala, R. \nMajumdar, and K.L. McMillan. Abstractions from proofs. In POPL 04: Principles of Programming Languages, \npages 232 244. ACM, 2004. [18] T.A. Henzinger, R. Jhala, R. Majumdar, and G. Sutre. Lazy abstraction. \nIn POPL 02: Principles of Programming Languages, pages 58 70. ACM, 2002. [19] S. Horwitz, T. Reps, and \nD. Binkley. Interprocedural slicing using dependence graphs. ACM TOPLAS, 12:26 61, 1990. [20] B. Korel \nand J. Laski. Dynamic program slicing. Information Processing Letters, 29:155 163, 1988. [21] O. Lhotak \nand L.J. Hendren. Jedd: a BDD-based relational extension of Java. In PLDI 2004, pages 158 169, 2004. \n[22] M. Mock, D.C. Atkinson, C. Chambers, and S.J. Eggers. Improving program slicing with dynamic points-to \ndata. In FSE 02: Foundations of Software Engineering, pages 71 80. ACM, 2002. [23] S. Sagiv, T. Reps, \nand R. Wilhelm. Parametric shape analysis via 3-valued logic. ACM TOPLAS, 24:217 298, 2002. [24] F. Tip. \nA survey of program slicing techniques. Journal of Programming Languages, 3:121 189, 1995. [25] M. Weiser. \nProgram slices: formal, psychological, and practical investigations of an automatic program abstraction \nmethod. PhD thesis, 1979. [26] J. Whaley and M.S. Lam. Cloning-based context-sensitive pointer alias \nanalysis using binary decision diagrams. In PLDI 2004, pages 131 144. ACM, 2004. [27] X. Zhang and R. \nGupta. Cost effective dynamic program slicing. In PLDI 04: Programming Language Design and Implementation, \npages 94 106. ACM, 2004. \n\t\t\t", "proc_id": "1065010", "abstract": "We present a new technique, <i>path slicing</i>, that takes as input a possibly infeasible path to a target location, and eliminates all the operations that are irrelevant towards the reachability of the target location. A path slice is a subsequence of the original path whose infeasibility guarantees the infeasibility of the original path, and whose feasibility guarantees the existence of some feasible variant of the given path that reaches the target location even though the given path may itself be infeasible. Our method combines the ability of program slicing to look at several program paths, with the precision that dynamic slicing enjoys by focusing on a single path. We have implemented Path Slicing to analyze possible counterexamples returned by the software model checker <sc>Blast</sc>. We show its effectiveness in drastically reducing the size of the counterexamples to less than 1% of their original size. This enables the precise verification of application programs (upto 100KLOC), by allowing the analysis to focus on the part of the counterexample that is relevant to the property being checked.", "authors": [{"name": "Ranjit Jhala", "author_profile_id": "81100198278", "affiliation": "University of California at San Diego", "person_id": "P343132", "email_address": "", "orcid_id": ""}, {"name": "Rupak Majumdar", "author_profile_id": "81100319213", "affiliation": "University of California at Los Angeles", "person_id": "P335105", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065016", "year": "2005", "article_id": "1065016", "conference": "PLDI", "title": "Path slicing", "url": "http://dl.acm.org/citation.cfm?id=1065016"}