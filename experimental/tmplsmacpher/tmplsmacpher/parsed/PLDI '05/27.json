{"article_publication_date": "06-12-2005", "fulltext": "\n Formal Loop Merging for Signal Transforms Franz Franchetti Yevgen Voronenko Markus P\u00a8uschel Department \nof Electrical and Computer Engineering Carnegie Mellon University {franzf, yvoronen, pueschel}@ece.cmu.edu \nAbstract A critical optimization in the domain of linear signal transforms, such as the discrete Fourier \ntransform (DFT), is loop merging, which increases data locality and reuse and thus performance. In particular, \nthis includes the conversion of shuf.e operations into array reindexings. To date, loop merging is well \nunderstood only for the DFT, and only for Cooley-Tukey FFT based algorithms, which excludes DFT sizes \ndivisible by large primes. In this paper, we present a formal loop merging framework for general signal \ntransforms and its implementation within the SPIRAL code gener\u00adator. The framework consists of S-SPL, \na mathematical language to express loops and index mappings; a rewriting system to merge loops in S-SPL; \nand a compiler that translates S-SPL into code. We apply the framework to DFT sizes that cannot be handled \nus\u00ading only the Cooley-Tukey FFT and compare our method to FFTW 3.0.1 and the vendor library Intel MKL \n7.2.1. Compared to FFTW our generated code is a factor of 2 4 faster under equal implemen\u00adtation conditions \n(same algorithms, same unrolling threshold). For some sizes we show a speed-up of a factor of 9 using \nBluestein s algorithm. Further, we give a detailed comparison against the Intel vendor library MKL; our \ngenerated code is between 2 times faster and 4.5 times slower. Categories and Subject Descriptors D.3.4 \n[Programming Lan\u00adguages]: Processors compilers, optimization, code generation; F.2.1 [Analysis of Algorithms \nand Problem Complexity]: Numerical Algorithms and Problems computation of transforms; C.3 [Spe\u00adcial Purpose \nand Application-Based Systems] signal processing systems General Terms Algorithms, design, languages, \nmeasurement, performance, theory Keywords Linear signal transform, discrete Fourier transform, DFT, loop \noptimization, domain-speci.c language, automatic per\u00adformance tuning 1. Introduction Linear digital signal \nprocessing (DSP) transforms are the compu\u00adtational workhorses in DSP, occurring in practically every \nDSP ap\u00adplication or standard. The most prominent example is the discrete Permission to make digital or \nhard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 05, June 12 15, 2005, Chicago, Illinois,USA. \nCopyright 2005 ACM 1-59593-056-6/05/0006...$5.00. Fourier transform (DFT), which, beyond DSP, is arguably \namong the most important numerical algorithms used in science and en\u00adgineering. Typically, DSP transforms \nare used in applications that process large data sets or operate under realtime constraints, which poses \nthe need for very fast software implementations. It is meanwhile well-known that the design and implementation \nof highest performance numerical kernels for modern computers is a very dif.cult problem due to deep \nmemory hierarchies, com\u00adplex microarchitectures, and special instruction sets. Exacerbat\u00ading the problem, \noptimal code is often platform-dependent, which increases the development cost considerably. DSP transforms \nare no exception. On the positive side, fast algorithms for DSP trans\u00adforms are divide-and-conquer, which \ngenerally produces a struc\u00adture well-suited for good performance on memory hierarchies. On the negative \nside, the conquer step in these algorithms is iterative, i.e., requires multiple passes through the data. \nIn particular, some of these steps are complicated shuf.e operations, which can de\u00adteriorate performance \nconsiderably. As a consequence, one of the keys to obtaining high performance is to merge these iterative \nsteps to improve data locality and reuse. In particular, the shuf.e opera\u00adtions should not be performed \nexplicitly, but converted into a rein\u00addexing in the subsequent computation. For fully unrolled code this \noptimization is straightforward, since the array accesses can be pre\u00adcomputed and inlined. In contrast, \nmerging shuf.e operations with loops is very dif.cult. The general problem of loop merging [1, 6] is \nNP-complete. Further, loop merging requires array dependence information, for which the most general \nmethods, like [7], achieve exact results only if the array indices are af.ne expressions, and even for \nthis class the analysis has exponential worst-case runtime. Since DFT algorithms other than the Cooley-Tukey \nfast Fourier transform (FFT) use non\u00adaf.ne index mappings, standard array dependence tests do not work. \nIn the domain of signal transforms, the problem of loop merg\u00ading has been solved to date only for the \nDFT and only for one DFT method: the Cooley-Tukey FFT (see [10]). Examples include the fastest available \nDFT software provided by vendor libraries1,by the adaptable library FFTW [2, 4], and by the code generator \nSPI-RAL [9, 8]. Consequently, these libraries achieve very high per\u00adformance for DFT sizes that factor \ninto very small prime numbers, but, as we demonstrate in this paper, can be far suboptimal for other \nsizes. Contribution of this paper. This paper addresses the problem of automatically fusing loops and \nshuf.e operations for arbitrary linear DSP transform algorithms. We propose a domain-speci.c approach \nconsisting of three main components: A new language to symbolically represent transform algorithms called \nS-SPL. S-SPL is an extension to SPL [11], which is at 1 For vendor libraries we can only speculate which \noptimizations are used, since the source code is not available. the core of the original SPIRAL system. \nAs SPL, S-SPL is of mathematical nature, but makes loops and index mappings explicit. S-SPL borrows concepts \nfrom the early paper [5] on FFT manipulations. A rule-based framework to perform loop fusions on the \nS-SPL representation of a transform algorithm.  A compiler that translates S-SPL into code.  Next, \nwe apply this framework to the DFT and the four most important FFT methods and identify the necessary \noptimization rules speci.c to these algorithms. For the Cooley-Tukey FFT, the optimizations are equivalent \nto those performed in FFTW or in the original SPIRAL. For other FFT algorithms, namely the prime\u00adfactor \nFFT, Rader FFT, Bluestein FFT, or their combinations, the optimizations are novel. We implemented our \napproach as a rewriting system within the SPIRAL code generator, which enables us to automatically perform \nthese optimization as part of the code generation process. For DFT sizes that cannot be exclusively computed \nusing the Cooley-Tukey FFT, we generate DFT code that is 2 4 times faster than FFTW on a Pentium 4 and, \nfor some sizes, up to a factor of 9 when using Bluestein s FFT algorithm, which is not used in the current \nversion of FFTW. We also provide a detailed comparison against the Intel vendor library MKL, for which \nthe source code is not available. Here we observe anything from a speed-up of a factor of 2 to a slow-down \nof a factor of 4.5. Organization of this paper. In Section 2 we review the four most important recursive \nDFT algorithms, discuss the problems in implementing them ef.ciently and review FFTW and SPIRAL. Section \n3 motivates and describes the new language S-SPL. Sec\u00adtion 4 describes the actual loop optimizations \nperformed in S-SPL, including examples, and explains the implementation as a rewrit\u00ading system within \nSPIRAL. In Section 5 we show benchmarks of SPIRAL generated DFT code using the new optimizations against \nFFTW and the Intel MKL. Finally, we offer conclusions in Sec\u00adtion 6. 2. Background In this section we \n.rst introduce the four most important recursive methods for computing the DFT and discuss the problems \nthat arise in their ef.cient implementation. Then we explain how in FFTW and SPIRAL only one of these \nmethods, namely the Cooley-Tukey FFT, is implemented ef.ciently. The other three recursions, which are \nnecessary to handle all DFT sizes, are either implemented far suboptimally or not at all. Further, the \noptimization process for these algorithms is not even theoretically well understood. In this paper we \nsolve this problem to generate code that is considerably faster compared to previous methods. DFT. The \nDFT is a matrix-vector multiplication. Namely, if x is a complex input vector of length n, then the DFT \nof x is the vector y =DFTn x, where DFTn is the n \u00d7 n matrix ke - 2pi/n DFTn =[.n ]0= k,e<n,.n = e. Recursive \nFFTs: Overview. Direct computation of the DFT requires O(n 2) operations. However, several recursive \nmethods, called fast Fourier transforms (FFTs), are available that reduce the cost to O(n log(n)). We \nconsider only the four most impor\u00adtant FFTs, which are called Cooley-Tukey, prime-factor (or Good-Thomas), \nRader, and Bluestein. Each of these FFTs reduces the problem of computing a DFT of size n to computing \nseveral DFTs of different (and with one exception smaller) sizes. The applicabil\u00adity of each FFT depends \non the size n: Cooley-Tukey requires that n = km factors and reduces the DFTn to m DFTk s and k DFTm \ns. Prime-factor requires that n = km factors and that the factors are coprime, gcd(k, m)=1. Similar \nto Cooley-Tukey, the DFTn is then computed using m DFTk s and k DFTm s.  Rader requires that n = p is \nprime and reduces the DFTp to 2 DFTp- 1 s.  Bluestein is applicable to all sizes and computes a DFTn \nusing 2 DFTm s of larger size m = 2n - 1.  Besides the recursion, the .rst three FFTs involve shuf.e \nopera\u00adtions or permutations of the following forms. For Cooley-Tukey (n = km), i (1) . ki mod (n - 1), \nwhich can also be written without the modulo operation using two arguments i and j in the af.ne form \njm + i (2) . ik + j. For Good-Thomas and Rader, respectively, i (kL ki J + m(i mod k)) mod n, (3) . i \ng i mod n, (4) . and their inverses, where g is a suitably chosen, .xed integer. For high performance \nit is crucial to handle these permuta\u00adtions, and their combinations as a DFT is computed recursively, \nef.ciently. This means that ideally the permutations should not be performed explicitly, but translated \ninto an array reindexing in the subsequent computation. For fully unrolled code this optimization is \nrather straightforward, since all array accesses can be precom\u00adputed and inlined. This is done, for example, \nin FFTW s codelet generator [3]. For loop optimizations, the af.ne permutation (1) or (2) has been studied \nextensively in the compiler literature and is well understood in the context of FFTs, whereas the more \nex\u00adpensive prime-factor and Rader FFT mappings (3) and (4) have not received much attention. One main \ncontribution of this paper is to identify the compiler transformations necessary to optimize these permutations. \nThese transformations are not performed on the ac\u00adtual code, where they would be prohibitively expensive, \nbut at a higher level of abstraction provided by S-SPL introduced in this paper. Recursive FFTs: Details. \nWe provide the explicit form of the four FFTs mentioned above similar to [10] in the form of structured \nsparse matrix factorization using the mathematical language called SPL in SPIRAL. In the following, we \nuse In to denote an n \u00d7 n identity matrix, and [] A A . B = ,A . B =[akeB],A =[ake], B for the direct \nsum and tensor product of matrices, respectively. The Cooley-Tukey, prime-factor, Rader, and Bluestein \nFFT, re\u00adspectively, can be written as the following structured factorizations of the DFT matrix. DFTn \n=(DFTk . Im)T n (Ik . DFTm)Ln (5) mk V - 1 DFTn = n (DFTk . Im)(Ik . DFTm)Vn, (6) DFTn = Wn - 1(I1.DFTp- \n1)En(I1.DFTp- 1)Wn, (7) B\"D\"D\"\" DFTn = nDm DFTmm DFTmmBn. (8) Here, L, V, W are the permutation matrices \ncorresponding to the permutations in (1), (3), (4), respectively; T, D, D\" ,D\"\" are diagonal matrices, \nE is almost diagonal with 2 additional off\u00addiagonal entries, Bn appends m - n zeros to the input vector, \nand B\"extracts the .rst n entries of a length m vector. n As said above, the .rst three recursions break \ndown the DFT into smaller DFTs. The last, Bluestein, converts a DFT of size n into 2 larger DFTs of size \nm = 2n - 1. Usually, m is chosen in this case as a 2-power for fastest computation. This method does \nnot involve shuf.e operations and can serve as a fallback solution if the other methods become too slow. \nWe discuss Cooley-Tukey as an example. If n = km, then the DFT in (5) is computed in four steps (corresponding \nto the four factors in (5)). First, the input vector is shuf.ed according to the permutation matrix Lnk \n; then, n DFTm s are applied to subvectors of length m; then, the vector is scaled with Tkn; and, .nally, \nm DFTk s are applied at stride m. This straightforward implementation would produce four loops and four \npasses through the data and leads to suboptimal performance. The key to obtaining high performance with \nthe above recur\u00adsions is to reduce the number of passes through the data by fusing the loops to increase \nlocality. In particular, the scaling steps (di\u00adagonal matrices) have to be fused with the adjacent loops \narising from the tensor products, and the permutations should not be per\u00adformed explicitly, but ideally \nbe converted into reindexings in the subsequent loop. Since the above FFTs are applied recursively, di\u00adagonals \nand permutations occur at different levels of nesting, which makes these fusions a dif.cult problem. \nTo date this problem has been solved only for algorithms that arise by exclusively using (5), for example, \nin FFTW and SPIRAL as discussed next. For other algorithms based on combinations of the other FFTs we \npresent a solution in this paper. FFTW. FFTW is a self-adaptable FFT library. For small DFT sizes, FFTW \nuses pregenerated, highly optimized, fully unrolled codelets [3]. The codelet generator uses a variety \nof FFT algo\u00adrithms including Cooley-Tukey, prime-factor, and Rader. For large sizes, and thus loop code, \nFFTW has a built-in degree of freedom in recursing using Cooley-Tukey. A heuristic search selects at \nrun\u00adtime the best recursion strategy (or algorithm), called plan, for the given platform. The plan can \nthen be used as many times as desired. FFTW implements Cooley-Tukey very ef.ciently. The permutation \nL is never explicitly performed, but passed as an argument in the recursion. This is possible, because \nof special properties of L. Simi\u00adlarly, scaling by T (the twiddle factors) is not performed as an extra \nstep, but, also is passed down the recursion and .nally performed by special twiddle codelets. Thus, \nin a sense, the optimization of (5) is hardcoded into the infrastructure of FFTW. Besides (5), FFTW supports \nalso (7), but there the permutations are performed explicitly, which results in poor performance. The \nother two FFTs are not supported. SPIRAL. SPIRAL (see Figure 1) generates code for signal transforms \nof .xed size from scratch. In SPIRAL, the DFT re\u00adcursions are called rules and included in the system \nin the form shown in (5) (8). For a user-speci.ed transform and size, SPIRAL applies these rules recursively \nuntil all transforms are of size 2 to generate one out of many possible algorithms, mathematically rep\u00adresented \nas SPL formula. The formula may then be optimized using formula manipulation. Next, the SPL compiler \n[11] translates the formula into optimized C code, using a template mechanism. The C code, in turn, is \ncompiled and its runtime is measured. Based on the runtime, in a feedback loop, a search (or learning) \nengine trig\u00adgers the generation of different algorithms. Iteration of this loop leads to a fast, platform-adapted \nimplementation. For (5), SPIRAL performs optimizations equivalent to FFTW. Namely, when trans\u00adlating \nan SPL formula based on (5) into code, the SPL compiler fuses the twiddle factors and the stride permutation \nmatrix a special purpose template for SPL expressions of the form (Ik .Am)Lkmk and (Ak .Im)T km. In other \nwords, this optimization is hardcoded m speci.cally for Cooley-Tukey based algorithms. Summary. In summary, \nboth FFTW and SPIRAL handle (5) as a special case, an approach that is neither easily extensible, nor \none that gives any insight into how to optimize the other FFT recursions or other transforms. Since in \nSPIRAL the goal is to generate very DSP transform (user specified) Formula Generation controls Algorithm \nLevel  Formula Optimization algorithm as formula in SPL language Implementation Implementation controls \n Level Code Optimization (SPL Compiler) C/Fortran implementation Compilation Evaluation performance \n Level Performance Evaluation Search/Learning  optimized/adapted implementation Figure 1. SPIRAL s \narchitecture. fast code for all transform and all sizes, a new framework is needed, complementing but \nextending the original SPL and SPL compiler, to perform the necessary optimizations. This is the motivation \nfor S-SPL presented in the next section. We then apply this framework to the FFTs (6), (7), and (8), \nto generate fast code for all DFT sizes.  3. The S-SPL Language In this section we de.ne S-SPL after \npresenting the motivation and a short example. The original SPL language used in SPIRAL describes transform \nalgorithms as sparse structured matrix factorizations built from small matrices, permutation matrices, \ndiagonal matrices, tensor products, and other constructs. SPL captures the data .ow of an algorithm. \nHowever, all data reorganization steps are described explicitly as stages that perform passes through \nthe data. As an example, consider the SPL formula (Im .An)P, P a permutation matrix, (9) which is produced \nby the recursions (5) and (6). This formula de\u00adscribes two passes through the data. First, the data vector \nis shuf.ed according to P using a loop with mn iterations that just moves data. Second, a loop with m \niterations applies the computational kernel An to subvectors of size n. One of our goals is to merge \nthese two loops into one loop that implements the data reorganization given by P as readdressing of the \ninput of the computational kernel An. This optimization cannot be expressed in SPL and is impractical, \nif not unfeasible, to perform on the corresponding C code. This is the motivation for introducing S-SPL, \nwhich makes the index map\u00adpings explicit and enables this optimization. We brie.y show how this optimization \nis performed on (9) before we de.ne S-SPL in detail. Translating (9) into S-SPL yields m-1 Swj An Grjperm \np, (10) j=0 where the so-called gather matrix Grj denotes the reading or load\u00ading of n input values according \nto the index mapping function rj, and the scatter matrix Swj denotes the writing or storing of n output \nvalues according to the index mapping function wj . Observe also that the permutation matrix is now expressed \nin terms of its de.ning permutation p. Intuitively, the permutation can be incorporated di\u00adrectly into \nthe gather matrix by changing the gather index mapping. Below we give the optimized S-SPL formula for \n(9) with merged loops, obtained by applying a rewrite rule: m-1 () Swj An Gp.rj . (11) j=0 The permutation \nwas fused into the gather operation to yield the new gather index mapping p . rj ( . is the composition \nof func\u00adtions). For ef.cient computation, it is further crucial to simplify the composed index mapping \nfunctions resulting from loop merging. This is also done by identifying a small set of rewrite rules \nthat perform this simpli.cation for the considered domain of transform algorithms. Identifying these \nrules for the FFTs (5) (8) is one of the contributions of this paper. To make explicit which loops in \nSPL formulas persist and which are merged, we divide the SPL constructs into two categories: skeleton \nand decoration. Skeleton. The main loop structure of an SPL formula is de.ned by its skeleton. Examples \nof skeleton objects include direct sums and tensor products with identity matrices: A . B, A . In, and \nIn .A. When an SPL formula is mapped into S-SPL, skeleton objects are translated into iterative sums \nincluding gather/scatter operations, which makes the loop structure and the index mappings explicit (as \nin (10)). In our motivating example (9) the skeleton is Im .An. Decoration. Permutation matrices and \ndiagonal matrices are () called decorations. We introduce the container constructs perm p () and diag \nfto express loops originating from decorations. Our optimization merges these objects into the skeleton \nsuch that the () extra stages disappear. In (9) the decoration is P =perm pand the gather index mapping \nresulting from the loop merging in (11) is p . rj . With the above example as a motivation, we now provide \nthe formal de.nition of index mappings that we use and then de.ne S-SPL. 3.1 Index Mappings An important \nconcept in S-SPL is the index mapping, concisely expressed by a function mapping an interval into an \ninterval. For example, as we saw in (10), gather, scatter, and permutation matri\u00adces are parameterized \nby these functions. Further, we express in\u00addex mapping functions in terms of primitive functions and \nfunction operators to capture their structure and thus enable all necessary simpli.cations, which would \nbe exceedingly dif.cult on the corre\u00adsponding C code. Index mapping functions. We start with some de.nitions. \nAn integer interval is denoted by In = {0 ...,n - 1}. An index mapping function f with domain In and \nrange IN is denoted by f : In . IN ; i . f(i). We use the short-hand notation fn.N to refer to an index \nmapping function of the form f : In . IN . Index mapping functions may depend on parameters. Assuming \nthe parameter is j, we would write fj : In . IN ; i . fj (i). A bijective index mapping function p : \nIn . In; i . p(i) de.nes a permutation on n elements and is denoted by p n . To capture the structure \nof index mapping functions we use a few primitive functions and operators de.ned next. Primitive index \nmapping functions. We de.ne the identity index mapping function as in : In . In; i . i and the constant \nfunction on the domain I1, parameterized by 0 = j<n,as (j)n : I1 . In; i . j. In other words, (j)n maps \n0 to j. We also de.ne the add constant function, for k = N - n,as (k)n.N + : In . IN ; i . i + k. Function \noperators. Structured index mapping functions are built from the above primitives using function operators. \nFor the two index mapping functions f : Im . IM ; i . f(i) and g : In . IN ; i . g(i) with n = M, we \nde.ne the function composition in the usual way: g . f : Im . IN ; i . g(f(i)). Further, we de.ne the \ntensor product of index mapping func\u00adtions as (li J)f . g : Imn . IMN ; i . Nf n + g(i mod n). Intuitively, \nif Inm is organized as an m\u00d7n array, then f .g applies f to its rows and g to its columns to obtain an \nM \u00d7 N array which represents IMN . Tensor products of in and (j)m correspond to multi-linear in\u00addex mapping \nfunctions. The simplest case with only two terms ex\u00adpresses strided (vector) access and unit stride access, \nrespectively. Namely, in . (j)m : In . Imn; i . im + j, (12) (j)m . in : In . Imn; i . i + jn. (13) \n3.2 S-SPL S-SPL extends the original SPL with four new parameterized ma\u00adtrices that are described by \ntheir de.ning functions: ( )(fn.C)Grn.N , Swn.N , perm p n , and diag , where fn.C is a function from \nIn to C. Further, we introduce the new matrix operator iterative sum, n-1 Aj . j=0 In S-SPL the summands \nAj of an iterative sum are constrained such that actual additions (except the ones incurred by the Aj \n) are never performed. This means that for every output index k, there is at most one matrix Aj that \nhas non-zero entries in row k. These constructs are now explained in detail, together with their interpretation \nas actual C code, which is straightforward, and summarized in Table 1. For completeness, we include the \nmatrix product, which is part of standard SPL. Product of Matrices. For y = ABx .rst t = Bx is computed \nand then y = At, leading to the .rst compilation rule in Table 1. Iterative sums of matrices. The interpretation \nof the iterative sum as a loop makes use of the distributivity law: n-1 n-1 Aj x =(Aj x). (14) j=0 j=0 \nCode(AB,y,x) .Code(B,t,x);Code(A,y,t); ()Lk-1 Code j=0 Aj ,y,x. for(j=0; j<k; j++) Code(Aj ,y,x); Code(Gfn.N \n,y,x) . for(j=0; j<n; j++) y[j] = x[f(j)]; Code(Sfn.N ,y,x) . for(j=0; j<n; j++) y[f(j)] = x[j]; ( ) \nCode(perm p n ,y,x) . for(j=0; j<n; j++) y[j] = x[p(j)]; () fn.C Code(diag ,y,x) . for(j=0; j<n; j++) \ny[j] = f(j)*x[j]; Table 1. Translating S-SPL constructs to code; xdenotes the input and y the output \nvector. Due to the constraint that the iterative sum actually does not incur any additional operations, \nit encodes a loop where each iteration produces a non-overlapping part of the .nal output vector. Each \nsummand in the iterative sum typically consists of three factors that encode three parts of the .nal \nprogram: 1) A gather matrix (details below) specifying the addresses for loading the input, 2) a computational \nkernel specifying the actual computation, and 3) a scatter matrix (details below) specifying the addresses \nfor storing the results. The code for (14) is produced by the second rule in Table 1. n Gather matrices. \nLet ek .Cn\u00d71 be the canonical basis vector with entry 1 in position kand entry 0 elsewhere. An index \nmapping function fn.N generates the gather matrix ([\u00b7]T is the matrix transposition) []T NN N Gfn.N := \nef(0) |ef(1) |\u00b7\u00b7\u00b7|ef(n-1). This implies that for two vectors x =(x0,...,xN-1)T and y =(x0,...,xn-1)T, \ny =Gfn.N x . yi = xf(i), which explains the corresponding code produced by the third rule in Table 1. \nScatter matrices. An index mapping function fn.N generates the scatter matrix [] NN N Sfn.N := ef(0) \n|ef(1) |\u00b7\u00b7\u00b7|ef(n-1). Scatter and gather matrices generated by the same function are transposes of each \nother. This introduces for two vectors x = (x0,...,xn-1)T and y =(x0,...,xN-1)T the identity xi if j \n= f(i) y =Sfn.N x . yj =. 0 else Code for the matrix-vector product y =Sfn.N x when used within an iterative \nsum is shown by the fourth rule in Table 1. The elements set to zero can be omitted in this case since \nthey do not contribute to the result. Permutation matrices. A permutation matrix corresponding to its \nde.ning permutation p n is written as ( )[]T nn n perm p n := ep(0) |ep(1) |\u00b7\u00b7\u00b7|ep(n-1). Permutation \nmatrices are special cases of gather matrices with the constraint that the index mapping function must \nbe bijective. Thus, the algorithm to implement gather matrices is used to implement permutation matrices. \nDiagonal matrices. A function fn.C : In . C de.nes the n\u00d7ndiagonal matrix (fn.C)()diag := diag f(0),...,f(n-1). \n() fn.C The translation of the matrix-vector product y =diag xto code is shown by the last rule in Table \n1. Example. As explained in the beginning of this section, we use iterative sums to make the loop structure \nof skeleton objects in SPL explicit. The summands are sparse matrices that depend on the summation index. \nBy construction, the iterative sum does not lead to any additional arithmetic operations, since the elements \nof the original matrix are distributed among different matrix summands, and all the other summand elements \nare set to zero. For example, [] 11 I2 .F2 , F2 = 1 -1 becomes in S-SPL the sum [ ][][] F2 02 F2 02 02 \n02 =+ . (15) 02 F2 02 02 02 F2 With the de.nition of the scatter and gather matrices []T []T S0 =I2 |02 \nand S1 =02 |I2 , [] [] G0 =I2 |02 and G1 =02 |I2 , (15) can be written as the iterative sum 1 Sj F2 Gj \n. (16) j=0 However, in (16) the subscripts of S and G are integers and not functions. Using the identity \nfunction, the constant function, and the tensor product for functions (see Section 3.1), we express the \ngather and scatter matrices as Sj =S(j)2.i2 and Gj =G(j)2.i2 . The matrix-vector product y =(I2 .F2)xnow \nbecomes in S-SPL 1 y =S(j)2.i2 F2 G(j)2.i2 x. j=0 Using the rules in Table 1 we obtain the following \nunoptimized program: // Input: _Complex double x[4], output: y[4] _Complex double t0[2], t1[2]; for (int \nj=0;j<2;j++) { for (int i=0; i<2; i++) t0[i] = x[i+2*j]; t1[0] = t0[0] + t0[1]; t1[1] = t0[0] -t0[1]; \nfor (int i=0; i<2; i++) y[i+2*j] = t1[i]; } After standard optimizations (performed by the standard SPL \ncompiler), such as loop unrolling, array scalarization, and copy propagation, we obtain the following \noptimized program: // Input: _Complex double x[4], output: y[4] for (int j=0;j<2;j++) { y[2*j] = x[2*j] \n+ x[2*j+1]; y[2*j+1] = x[2*j] -x[2*j+1]; }  4. The S-SPL Rewriting System In this section we describe \nthe new loop optimization procedure and its implementation in SPIRAL. The optimizations are implemented \nas a series of rewriting systems operating on SPL and S-SPL expression trees. An overview of the different \nsteps is shown in Figure 2, which is inserted in the formula optimization block in SPL Code Figure 2. \nTranslating SPL to optimized code. SPIRAL (see Figure 1). The steps are generic for all transforms and \nalgorithms except the index simpli.cation (bold box), which requires the inclusion of rules speci.c to \nthe class of algorithms considered. We start with an overview; then we explain the steps in detail. Expansion \nof skeleton. In the .rst step we translate an SPL formula (as generated within SPIRAL) into a corresponding \nS-SPL formula. The skeleton (see Section 3) is expanded into iterative sums and the decorations are expressed \nin terms of their de.ning functions. Loop merging. A generic set of rules merges the decorations into \nadjacent iterative sums, thus effectively merging loops. In this process index mapping functions are \nsymbolically composed, and thus become complicated or costly to compute. Index simpli.cation. In this \nstage the index mapping functions are simpli.ed, which is possible due to their symbolic representa\u00adtion \nand a set of symbolic rules. The rules of this stage are trans\u00adform dependent and encode the domain speci.c \nknowledge how to handle speci.c permutations. Most identities are based on number theoretic properties \nof the permutations. Identifying these rules for a given transform is usually a research problem. Code \ngeneration. After the structural optimization the S-SPL compiler is used to translate the .nal expression \ninto initial code (see Table 1), which is then further optimized as in the original SPL compiler [11]. \nRunning example. In the following detailed explanation, we use the following simple formula, a special \ncase of (9), as a running example with emn m (Im . DFTn) Lmn m ,Lmn m : Imn . Imn, mapping =perm (emn \nm ), (17) i . (im)mod (mn - 1) mn - 1 if i<mn - 1, if i = mn - 1. (18) The direct translation of (17) \ninto code for m =5 and n =2 would lead to the following code: // Input: _Complex double x[10], output: \ny[10] _Complex double t[10]; // explicit stride permutation L^10_5 for (int i=0; i<10; i++) t[i] = x[i<9 \n? (i*5)%9 : 9]; // kernel loop I_5 x DFT_2 A . B . S . A G . + (19) (0)m.m+m(0)n.n+n ++ S .m+m. A G .n+n. \n(m)m(n)n ++ k-1 A . Ik . Sim.(j)k A Gin.(j)k (20) j=0 k-1 Ik .A . S(j)k.im A G(j)k.in (21) j=0 Table \n2. Rules to expand the skeleton. for (int i=0; i<5; i++) { y[2*i] = t[2*i] + t[2*i+1]; y[2*i+1] = t[2*i] \n-t[2*i+1]; } The code contains two loops, originating from the permutation matrix Lmn and from the computational \nkernel Im . DFTn. Note m that optimized methods to implement the stride permutation Lmn m using two nested \nloops can be found in [10]. However, we do not resort to such an implementation as this treats the stride \npermuta\u00adtion as a special case and we aim at solving the general problem. The goal in this example is \nto merge the two loops into one. 4.1 Expansion of Skeleton This stage translates SPL formulas, generated \nby SPIRAL, into S-SPL formulas. It translates all skeleton objects in the SPL formula into iterative \nsums and makes the de.ning functions of decorations explicit. Table 2 summarizes the rewrite rules used \nin this step, \u00d7n assuming A . Cm\u00d7n,B . Cm . . The tensor product structure of matrices is in S-SPL captured \nthrough the tensor product structure of the gather and scatter in\u00addex mapping functions. The add constant \nfunction is used in the conversion of direct sums of matrices. In our example (17), the rewriting system \napplies the rule (21) to obtain the S-SPL expression m-1 (emn) S(j)DFTn G(j)perm m . (22) .in .in mm \nj=0 4.2 Loop Merging The goal of loop merging is to propagate all index mapping func\u00adtions for a nested \nsum into the parameter of one single gather and scatter matrix in the innermost sum, and to propagate \nall diago\u00adnal matrices into the innermost computational kernel. Table 3 sum\u00admarizes the necessary rules. \nLoop merging consists of two steps: moving matrices into iterative sums, and actually merging or com\u00admuting \nmatrices. First, matrices are moved inside iterative sums by applying rules (24) and (25) that implement \nthe distributivity law. Note, that iterative sums are not moved into other iterative sums. Second, the \nsystem merges gather, scatter, and permutation ma\u00adtrices using rules (26) (29) and pulls diagonal matrices \ninto the computational kernel using (30) and (31). This step simply com\u00adposes de.ning functions, possibly \ncreating complicated terms that must be simpli.ed in the next step. After loop merging, (22) is transformed \ninto m-1 () S(j).in DFTn G emn . (23) m .((j).in) mm j=0 m-1 m-1 Aj M . Aj M (24) j=0 j=0 m-1 m-1 MAj \n. MAj (25) j=0 j=0 G . (26) sn.N1 G rN1.N Gr.s S . (27) vN1.N S wn.N1 Sv.w ( ) Grn.N perm pN . Gp.r \n(28) )(N perm p Swn.N . Sp-1.w (29) (fN.C) () Grn.N diag . diag f . rGr (30) (N.C ) () diag fSwn.N . \nSw diag f . w(31) Table 3. Loop merging rules. 4.3 Index Mapping Simpli.cation As said before, this \nis the only step that depends on the considered transform and its algorithms. We consider the DFT and \nthe FFTs (5) (7). These recursions involve permutations that involve integer power computations, modulo \noperations, and conditional compu\u00adtations. In addition to the stride permutation (18) in the Cooley-Tukey \ndecomposition (5), the prime-factor decomposition (6) uses () the permutation matrix Vr,s =perm vr,s, \nfor gcd(r, s)=1, with (lJ ) r,s i v: Irs . Irs; i . s s + r(i mod s)mod rs. For prime n, the Rader decomposition \n(7) requires an exponentia\u00ad () tion permutation matrix Wr,s =perm w1n,g, where g is a gener\u00adator of the \nmultiplicative group Z\u00d7, and n n 0 if i =0, w.,g : In . In; i . .gi-1 mod n else. Thus, our rewriting \nsystem requires powerful index mapping func\u00adtion simpli.cations, as the previous steps merge the already \ncom\u00adplicated index mappings from each stage into one very complicated index mapping function in the innermost \nnested sum. We express the index mappings using symbolic functions like in, (j)m, and (k)n.N as well \nas the tensor product and function + composition to enable simpli.cation. In order to handle (6) and \n(7) we have to introduce three helper functions, hn.N : In . IN ; i . b + is, s|N, (32) b,s n.N hb,s \n: In . IN ; i . b + is mod N, s|N, (33) n.Ni w.,g : In . IN ; i . .gmod N. (34) The power of using symbolic \nfunctions and operators becomes ap\u00adparent next. Namely, we can identify a rather small set of context \ninsensitive simpli.cation rules to simplify all index functions aris\u00ading from combining the FFT rules \n(5) (7). The required simpli.\u00adcations cannot be done solely using basic integer identities as con\u00ad.icting \nidentities and special number-theoretical constraints (e.g., a variable is required to be the generator \nof a cyclic group of order n) would be required. Our function symbols capture these conditions by construction \nwhile our rules encode the constraints. Table 4 summarizes the most important index simpli.cation rules. \nRules (35) (39) are used to simplify Cooley-Tukey FFT de\u00adcompositions. Rules (40) (42) are used for decompositions \nbased on the Cooley-Tukey FFT and other FFTs. Rules (43) (46) are used for the Rader FFT and (47) for \nthe prime-factor FFT. () emn k.nk.n m . (j)m . f. f. (j)m . (35) ()-1 emn emn m . n (36) (1.m ) f. h. \ng . f . (h . g) (37) () h . g 1.n. f . (h . f) . g (38) (f0 . f1) . (g0 . g1) . (f0 . g0) . (f1 . g1) \n(39) hn.n in . 0,1 (40) fm.M 1.NM.MN . g . hg(0),N . f (41) 1.NM.MN . fm.M g . hMg(0),1 . f (42) N 1.N \n1.N w.,g . (0)+ . (0)+ (43) NN-1.NN-1.N w.,g . (N - 1)+ . w.,g (44) N.N . hn.N. n.N w.,g b,s . w.gb,gs \n(45) n.N. w . hb,s . w (46) N.N n.N .,g .gb,gs r,s . hs.rs s.rs vb,1 . hb,r (47) Table 4. Index function \nsimpli.cation rules. The identi.cation of these rules is one of the main contributions of this paper. \nIn our example, the index function simpli.cation applies rule (35) to (23) to obtain m-1 ( ) S(j).in \nDFTn Gin.(j). (48) mm j=0 4.4 Code Generation The S-SPL compiler .rst generates unoptimized code for \nan S-SPL formula using the context insensitive mappings given in Ta\u00adble 1. As in the original SPL compiler \n[11], an unrolling parameter B to the S-SPL compiler controls which loops in a S-SPL for\u00admula will be \nfully unrolled and thus become basic blocks in which all decorations and index mappings are inlined. \nOur approach re\u00adlies on further basic block level optimizations to produce ef.cient code. These are a \nsuperset of the optimizations implemented in the original SPL compiler, including 1) full loop unrolling \nof compu\u00adtational kernels, 2) array scalarization, 3) constant folding, 4) alge\u00adbraic strength reduction, \n5) copy propagation, 6) dead code elim\u00adination, 7) common subexpression elimination, 8) loop invariant \ncode motion, and 9) induction-variable optimizations. Translating our running example (48) into optimized \ncode using the S-SPL compiler leads to the following: // Input: _Complex double x[10], output: y[10] \nfor (int j=0; j<5; j++) { y[2*j] = x[j] + x[j+5]; y[2*j+1] = x[j] -x[j+5]; } 4.5 Rader and Prime-Factor \nExample To demonstrate how our framework applies to more complicated SPL formulas, we show the steps \nfor compiling a part of a 3-level recursion for a non-power-of-2 size DFT that uses all three different \nrecursion rules (5) (7), namely a DFTpq with q prime, and q-1= rs. Initially the prime-factor decomposition \n(6) is applied for the size pq, then the Rader decomposition (7) decomposes the prime size q into q - \n1. Finally, a Cooley-Tukey step (5) is used to decompose q - 1 into rs. We only discuss a fragment of \nthe resulting SPL formula, namely rs (Ip . (I1 .(Ir . DFTs)Lr )Wq)Vp,q, which is also shown in (49) in \nTable 5. This formula has three different permutations, and a naive implementation would re\u00adquire three \nexplicit shuf.e operations, leading to three extra passes through the data vector. Our rewriting system \nmerges these permutation matrices into the innermost loop and then simpli.es the index mapping function, \neffectively reducing the number of necessary mod operations to approximately 3 mods per 2 data points \nand improving the locality of the computation at the same time. We discuss the intermediate steps following \nFigure 2. Expansion of skeleton. Rules (21) and (19) expand the skeleton to produce the unoptimized S-SPL \nformula (50) in Table 5. A direct compilation for p=4, q=7, r=3, and s=2would result in the following \ncode. 00 // Input: _Complex double x[28], output: y[28] 01 _Complex double t1[28]; 02 // permutation \nv^(4,7) 03 for(int i5 = 0; i5 <= 27; i5++) 04 t1[i5] = x[(3*i5 + 8*(i5%7))%28]; 05 // iterative sum 06 \nfor(int i1 = 0; i1 <= 3; i1++) { 07 _Complex double t3[7], t4[7], t5[7]; 08 // gather 09 for(int i6 = \n0; i6 <= 6; i6++) 10 t5[i6] = t1[7*i1 + i6]; 11 // permutation w^7 12 for(int i8 = 0; i8 <= 6; i8++) \n13 t4[i8] = t5[i8 ? pow(3, i8-1)%7 : 0]; 14 // gather, permutation i_1, scatter 15 t3[0] = t4[0]; 16 \n{ _Complex double t10[6], t11[6], t12[6]; 17 // gather 18 for(int i13 = 0; i13 <= 5; i13++) 19 t12[i13] \n= t4[i13 + 1]; 20 // permutation l^6_3 21 for(int i14 = 0; i14 <= 5; i14++) 22 t11[i14] = t12[i14/2 + \n3*(i14%2)]; 23 // iterative sum 24 for(int i3 = 0; i3 <= 2; i3++) { 25 _Complex double t14[2], t15[2]; \n26 // gather 27 for(int i15 = 0; i15 <= 1; i15++) 28 t15[i15] = t11[2*i3 + i15]; 29 // t14 = DFT_2*t15 \n30 t14[0] = t15[0] + t15[1]; 31 t14[1] = t15[0] -t15[1]; 32 // scatter 33 for(int i17 = 0; i17 <= 1; \ni17++) 34 t10[2*i3 + i17] = t14[i17]; 35 } 36 // scatter 37 for(int i19 = 0; i19 <= 5; i19++) 38 t3[i19 \n+ 1] = t10[i19]; 39 } 40 // scatter 41 for(int i20 = 0; i20 <= 6; i20++) 42 y[7*i1 + i20] = t3[i20]; \n43 } The code contains explicit data permutations (e.g., lines 3/4 and 12/13), has multiple iterative \nstages as re.ected by multiple temporary vectors, and contains expensive power (line 13) and mod operations. \nFor example, the index computation in line 4 involves two nested mod operations. Loop merging. The rules \nin Table 3 are used to merge the loops and thus move the decorations into the innermost sum. The resulting \nS-SPL formula is shown in (51) in Table 5. Note that the occurring index functions are very complicated. \nIndex simpli.cation. Using only the rules in Table 4 the gather and scatter index mapping functions are \nsimpli.ed to produce the optimized formula shown in (52) in Table 5. Code generation. Now the code can \nbe generated for some speci.c values of p, q, rand susing the S-SPL compiler. For the same parameters \nas above, p=4, q=7, r=3, s=2, we get: 00 // Input: _Complex double x[28], output: y[28] 01 int p1, b1; \n02 for(int j1 = 0; j1 <= 3; j1++) { 03 y[7*j1] = x[(7*j1%28)]; 04 p1=1; b1 =7*j1; 05 for(int j0 = 0; \nj0 <= 2; j0++) { 06 y[b1+2*j0+1] = 07 x[(b1 + 4*p1)%28] + x[(b1 + 24*p1)%28]; 08 y[b1+2*j0+2] = 09 x[(b1 \n+ 4*p1)%28] -x[(b1 + 24*p1)%28]; 10 p1 = (p1*3)%7; 11 } 12 } Each index computation involves now at \nmost one mod opera\u00adtion. Data is never explicitly copied between buffers and the com\u00adputation is fully \nrecursive. Note that simple optimizations like pre\u00adcomputing b1+4*p1 in lines 7 and 9 in each iteration \nare left to the compiler. 4.6 Veri.cation A very important advantage of doing optimization at the formula \nlevel is the possibility of exact veri.cation. Since a S-SPL formula still represents a sparse matrix \nfactorization, it can always be con\u00adverted, in the SPIRAL environment, into the dense transform ma\u00adtrix \nit represents and compared against the transform de.nition. For relatively small sizes it is thus feasible \nto perform veri.cation after each rule application, which makes it possible to pinpoint the rule that \nleads to a possibly invalid formula an important feature in our context of rather involved manipulations. \nBeyond formula and rule veri.cation, the presented approach bene.ts from SPIRAL s general code veri.cation \nroutines that are automatically applicable [8].  5. Experimental Results In this section we show runtime \nresults of SPIRAL generated DFT code using our new loop optimization approach. As said before, our focus \nis on DFT sizes that cannot be computed using exclusively the Cooley-Tukey FFT (5), since for these sizes, \nclose-to-optimal code is already available from vendor libraries, FFTW, or the orig\u00adinal SPIRAL. In other \nwords, we focus on DFT sizes that require at least one Rader step (7) that is not unrolled in the recursion. \nThis is the case if and only if the DFT size nhas a prime divisor p|n that is larger than the unrolling \nthreshold B, i.e., p>B. Further, since the Rader step is far more expensive than a prime-factor or Cooley-Tukey \nstep, we divide the set of all numbers into levels, de\u00adpending on how many Rader steps are needed. This \nis captured in the following de.nition. De.nition 1 Let B> 0be given (the unrolling threshold). With \nrespect to B, a prime number pis called level 0if p= B, and level i, i>0, if the largest level of all \nprime divisors of p-1is i-1.An integer is called level i, if the largest level of all its prime divisors \nis i. For example, if B =16, then n =11,n =33=3\u00b7 11are level 0, n=17,n=323=17\u00b7 19are level 1, and n=47is \nlevel 2, since 23|(47- 1)and 23 is level 1. (Ip . (I1 .(Ir . DFTs)Lrs) Wq) Vp,q (49) r p-1 S1.q perm(i1)G1.q \nS(j1)p .iq (0)(0) ++ j1=0 r-1 q-1 q p,q +Sq-1.q S(j0).is DFTs G(j0).is perm(er )Gq-1.q perm(w1,g)G(j1).iq \nperm(v) (50) (1)+ rr (1)+ p j0=0 p-1 ( S1.q G q 1.q ((j1).iq).(0).i1 vp,q.((j1).iq).w.(0) p + p 1,g + \nj1=0 r-1 ) +Sq-1.q DFTs G qq-1.q (51) ((j1).iq).(1).((j0)vp,q.((j1).iq).w.(1).ers.((j0) p + r .is) p \n1,g + rr .is) j0=0 p-1 ( r-1 ) p.pq s.pq p.pq + DFTs Ghq.pq s.q (52) Sh0,q .(j1)p Gh0,q .(j1)p Shqj1+sj0+1,1 \nb1,p .wf1,gs j1=0 j0=0 b1=qj1 j0 f1=g Table 5. Loop merging example for the formula fragment (49), arising \nfrom a combination of prime-factor, Rader, and Cooley-Tukey FFT. The steps follow Figure 2: After expansion \nof the skeleton (50); after loop merging (51); and the .nal S-SPL formula after index simpli.cation (52). \nIntuitively, if a DFT of size nis recursively expanded into a tree using the three recursions (5), (6), \nand (7), then the level of nis the number of levels in this tree that contain a Rader step. Since Rader \nis expensive, a higher level will imply a lower relative performance. If an unrolling threshold Bis chosen, \nthen the DFTs that can be computed exclusively using Cooley-Tukey are precisely those with a level 0 \nsize. For B=16, the numbers 1 = n= 1024 divide into levels as follows; only about one quarter are level \n0. level 0 1 234 how many 245 536 205 36 1 Experimental setup. We ran the experiments on a Pentium 4, \nprocessor number 560, 3.6 GHz, under Windows XP using the Intel C++ compiler 8.0 with .ags /Qc99 /O3 \n/Qrestrict /QxKWP. We considered only double precision code and measured the runtime of Intel s MKL 7.2.1, \nFFTW 3.0.1, and SPIRAL generated code using the new optimization approach. For best performance it is \nnecessary to use short vector instructions. The considered Pentium 4 provides for double precision the \ninstruction set extensions SSE2 and SSE3. Both provide 2-way vector instructions and SSE3 is a superset \nof SSE2, designed speci.cally to map complex arithmetic ef.ciently. The MKL provides code optimized for \nPentium 4 using SSE2 or SSE3, FFTW provides scalar and SSE2 code, and with SPIRAL we generated scalar \ncode and SSE3 code. The SSE3 code was obtained by generating complex C99 code and using compiler vectorization \n(.ag /QxKWP). The advantage of this method is that it can be applied regardless of the DFT size. The \ndisadvantage is that for sizes that are divisible by 4 (square of the vector length) we obtain roughly \n20 30% slower code than with the SSE2 code generated using our vectorization method in [8]. We chose \nSSE3 since it .ts seamlessly into the new S-SPL framework and does not require additional vectorization \neffort, thus allowing us to focus on the analysis of the new optimization approach. 5.1 SPIRAL vs. FFTW \nIn Figure 3 we compare the runtime of FFTW and SPIRAL gener\u00adated code. Since the default installation \nof FFTW provides unrolled basic blocks (codelets) up to size 16 (and for 32 and 64), we chose for SPIRAL \ntoo, an unrolling threshold of B=16 for fair compar\u00adison. As said above, we consider sizes of level 1 \nand higher with respect to this B. For FFTW (dashed lines), we measured scalar and SSE2 code (provided \nby FFTW), in both cases using FFTW s search for the best recursion tree. For SPIRAL, we generated scalar \ncode and SSE3 code (solid black lines), in both cases only using the FFTs (5) (7). Finally, we also generated \ncode with SPIRAL using Bluestein (8) (solid gray line), again as complex C99 code using compiler vectorization \nfor SSE3. Level 1 sizes. For sizes of level 1 (Figure 3, top) and scalar code (bullets), SPIRAL code \nis between 1.25 and 2 times faster than FFTW. FFTW s SSE2 code is only marginally faster than its scalar \ncode since most of the time is spent in the costly Rader permutations. SPIRAL s generated SSE3 code (vectorized \nby the compiler from explicit complex C99 code) consistently gains about another 50% in performance, \nindependent of the size, yielding a total improvement of a factor of 2 3 over FFTW. The Bluestein method \n(gray line) is not competitive for almost all level 1 num\u00adbers. Note that the Bluestein method (8) is \nabout constant within intervals 2k <n<2k+1, since all DFTs of these sizes are com\u00adputed using two DFTs \nof size 2k+2 . Level 2 sizes. For level 2 sizes, we observe, as expected because of the two Rader steps, \na larger gap between FFTW and SPIRAL generated code, which can now be as much as a factor of 3 for scalar \ncode, and a factor of 4 for vector code. Bluestein is still inferior for most sizes. Level 3 sizes. For \nlevel 3 sizes, the gap between FFTW and SPIRAL generated code further widens, and here Bluestein is faster \nin all cases, gaining up to a factor of 9 over FFTW. Summary. The experiments validate that our method \nfor loop merging produces signi.cant performance gains for DFT sizes of level 1 and higher. Further, \nby generating explicit complex code and vectorizing for SSE3, we obtain another consistent performance \ngain of 50%. The experiments show that for DFT sizes of level 1 and 2 the recursive FFTs are preferable, \nwhereas for levels 3 and higher Bluestein is faster. The search mechanism in SPIRAL will determine this \nautomatically. -4 Level 1 Sizes x 10 2.5 FFTW 3.0.1 FFTW 3.0.1 SSE2 SPIRAL Rader SPIRAL Rader SSE3 2 \nSPIRAL Bluestein SSE3 1.5 1 0.5 100 200 300 400 500 600 700 DFT Size -4 Level 2 Sizes x 10 FFTW 3.0.1 \n4 FFTW 3.0.1 SSE2 SPIRAL Rader SPIRAL Rader SSE3 3.5  5.2 SPIRAL vs. Intel MKL We compare SPIRAL against \nIntel s MKL. This time we only consider vector code: MKL uses SSE2 or SSE3, and our generated code uses \nSSE3 (as said above, this is achieved by generating complex C99 code and using compiler vectorization). \nThe source code of MKL is not available, and MKL s internal structure and the algorithms used are not \ndocumented. For this reason we .rst analyze MKL s runtime behavior. MKL DFT runtime behavior. In the \n.rst experiment we timed MKL for all DFT sizes up to 1024. Figure 4 shows the result. The points, and \nthus the DFT sizes, are partitioned into three classes: Class 1 includes all sizes whose largest prime \nfactor is smaller than 32 (black triangles); class 2 includes all sizes whose largest prime factor is \nbetween 32 and 150 (white squares); and class 3 includes all sizes whose largest prime factor exceeds \n150 (gray bullets). Note that this is not a division into levels (see De.nition 1). Class 1 is the set \nof level 0 numbers for unrolling threshold B =32; class 2 is the set of level 0 numbers for B =150, which \nare not in class 1; and class 3 is the set of all numbers of level 1 and higher for B =150. 800 900 From \nFigure 4 we speculate that MKL uses Cooley-Tukey (and maybe prime-factor), in tandem with a quadratic \ncost algorithm for prime size kernels smaller than 150 (each of the parabolic strands in class 2 seems \nto have quadratic or near-quadratic behavior as we con.rmed through polynomial curve .tting), and Bluestein \nfor class 3 numbers. In other words, it seems that Rader is not used. Runtime [s] Since class 1 sizes \nare precisely the level 0 numbers for the (reasonable) unrolling threshold B =32, we compare against \nSPIRAL Bluestein SSE3 MKL only for class 2 and class 3 sizes, and we choose B =32 as unrolling threshold \nin SPIRAL. Since we generate vector code, a larger threshold would be possible, but for 150 the basic \nblocks become too large. Runtime [s] 2.5 Class 2. Figure 5 shows the ratio of the runtimes of SPIRAL \ngenerated code and MKL for class 2 sizes. A value < 1signi.es that SPIRAL s code is faster. As we see \nfrom this plot, SPIRAL code is between 30% faster and 4.5 times slower. The median of all 1.5 ratios \nis 1.35, i.e., 35% slower. To better understand for which DFT sizes we fare worse, we further partition \ninto subclasses. If MKL does successfully use an O(n 2)algorithm for small prime sizes, one would expect \nthat we fare worse for sizes that require several 100 200 300 400 500 600 700 800 900 1000 Rader steps \nindependent of whether they are unrolled or not due DFT Size to their relatively high arithmetic cost. \nFor this reason we partition -4 Level 3 Sizes the size in Figure 5 into those of level 1 (black triangles), \nlevel 2 x 10 Runtime [s] 7 8 9 FFTW 3.0.1 FFTW 3.0.1 SSE2 SPIRAL Rader SPIRAL Rader SSE3 SPIRAL Bluestein \nSSE3 6 5 4 3 2 1 200 300 400 500 600 700 DFT Size 800 900 1000 Figure 3. DFT runtime results for sizes \nbetween 100 and 1000 (white squares), and level 3 and higher (gray bullets) for unrolling threshold 5 \n(the 5 was chosen empirically). As expected our code compares best for level 1 (median 1.02), a little \nworse for level 2 (median 1.36), and worst for level 3 and higher (median 2.78). Class 3. Figure 6 shows \nthe runtime of MKL s DFTs and SPI-RAL generated DFT code of problem sizes in class 3. Obviously, MKL \n(gray bullets) uses Bluestein (8). Class 3 sizes, as class 2 sizes, are level 1 or higher with respect \nto our unrolling thresh\u00adold 32. For level 1 sizes (black triangles), SPIRAL generated code runs up to \ntwice as fast as MKL code, and is faster for most sizes. For level 2 sizes (white squares) MKL is faster \nfor most numbers; however, SPIRAL s Bluestein (gray line) limits the slowdown to 30%, which is roughly \nthe loss of our SSE3 vectorization versus the better SSE2 vectorization in [8] for the 2-power FFTs used \nin Bluestein. Summary. SPIRAL generated code tends to be faster than MKL DFT code for level 1 sizes with \nrespect to unrolling threshold 32 and is comparable (with the disadvantage of SSE3 vectorization leading \nto 20 % slowdown) for level 0 and level 2 sizes. For level 0 sizes with prime factors of level 3 or higher \nwith respect to un\u00ad rolling threshold 5, however, SPIRAL generated code is far subop\u00ad of level 1 (top), \n2 (middle), and 3 (bottom): FFTW (dotted) and SPIRAL generated (solid). Lower is better. timal due to \nmultiple Rader steps (7) in basic blocks. Runtime [s] 7 8 x 10-5 MKL Class 1 MKL Class 2 MKL Class 3 \n6 5 4 3 2 1 100 200 300 400 500 600 DFT Size 700 800 900 1000 Figure 4. Runtimes of Intel MKL s DFT \nfor sizes up to 1024. The sizes are partitioned into 3 classes (explained in the text). 5 SPIRAL Level \n1 (B=5) SPIRAL Level 2 (B=5) SPIRAL Level 3+ (B=5) 4 4.5 SPIRAL Runtime / MKL Runtime 3.5 3 2.5 2 \n1.5 1 0.5 0 0 100 200 300 400 500 600 700 800 900 1000 DFT Size Figure 5. Runtime ratios of SPIRAL s \nDFT and MKL s DFT for class 2 sizes, partitioned into 3 classes (explained in the text).  6. Conclusions \nWe presented an extension of the SPL language and SPL compiler used in SPIRAL to enable loop optimization \nfor signal transform algorithms at the formula level. The approach concurs with the SPIRAL philosophy \nwhich aims to perform optimizations at the right level of abstraction. The right level depends on the \ntype of optimization and is usually a research question. For the loop optimizations considered in this \npaper, we found that the right level is between SPL and the actual code as re.ected by S-SPL, which, \nunlike SPL, represents loops and index mappings explicitly and compactly. We want to emphasize that the \nmain goal was not to optimize the discussed FFT algorithms, but to develop a general framework that can \nperform these loop optimizations for the entire domain of linear transforms considered by SPIRAL. Our \napproach is speci.c to this domain, but general within this domain. Of course, our approach requires \nus to identify for each con\u00adsidered transform and set of transform algorithms the proper set of index \nfunction simpli.cation rules, which, in this paper, we did for the FFTs (5) (8). As a result we could \ngenerate DFT code for sizes of level 1 and 2 that is considerably faster than FFTW under equal choice \nof algorithms and unrolling threshold. For sizes of level 3 and higher, we achieved an even higher speed-up, \nwhich, however was based on the Bluestein FFT, which we believe could be easily incorporated into FFTW. \nThe comparison to Intel s MKL produced mixed results, be\u00adtween considerable improvements for some sizes \nand considerably x 10-4 Runtime [s] 2 1.5 1 0.5  DFT Size Figure 6. Runtimes of SPIRAL s DFT and MKL \ns DFT for class 3 sizes (where MKL uses Bluestein). The SPIRAL runtimes are partitioned into 2 classes \n(explained in the text). SPIRAL s Bluestein is also shown. slower code for other sizes. Since we believe \nthat MKL does not use Rader, but some O(n 2) algorithm for small primes, we plan to incorporate the corresponding \nrules into SPIRAL to more carefully study the trade-offs. No matter which strategy for small primes is \nchosen, it is interesting to record that the Bluestein FFT is crucial for high performance if all DFT \nsizes are to be implemented. Finally, it was interesting to note that by generating explicit complex \nC99 code and using compiler vectorization for SSE3, we obtained, independent of the DFT size, a consistent \nperformance improvement of about 50%.  Acknowledgments This work was supported by NSF through awards \n0234293, 0310941, and 0325687. Franz Franchetti was supported by the Aus\u00adtrian Science Fund FWF s Erwin \nSchroedinger Fellowship J2322. The authors also wish to thank the anonymous reviewers for their suggestions \nthat helped to improve the paper. References [1] A. Darte. On the complexity of loop fusion. Parallel \nComputing, 26(9):1175 1193, 2000. [2] FFTW web site. www.fftw.org. [3] M. Frigo. A fast Fourier transform \ncompiler. In Proc. PLDI, pages 169 180, 1999. [4] M. Frigo and S. G. Johnson. The design and implementation \nof FFTW3. Proc. of the IEEE, 93(2):216 231, 2005. Special issue on Program Generation, Optimization, \nand Adaptation. [5] J. Johnson, R. W. Johnson, D. Rodriguez, and R. Tolimieri. A methodology for designing, \nmodifying, and implementing Fourier transform algorithms on various architectures. IEEE Trans. Circuits \nand Systems, 9, 1990. [6] K. Kennedy and K. S. McKinley. Maximizing loop parallelism and improving data \nlocality via loop fusion and distribution. In 1993 Workshop on Languages and Compilers for Parallel Computing, \nnumber 768, pages 301 320, Portland, Ore., 1993. Berlin: Springer Verlag. [7] W. Pugh and D. Wonnacott. \nConstraint-based array dependence analysis. ACM Trans. Progr. Lang. Syst., 20(3):635 678, 1998. [8] \nM. P\u00a8uschel, J. M. F. Moura, J. Johnson, D. Padua, M. Veloso, B. W. Singer, J. Xiong, F. Franchetti, \nA. Gaci.\u00b4 c, Y. Voronenko, K. Chen, R. W. Johnson, and N. Rizzolo. SPIRAL: Code generation for DSP transforms. \nProc. of the IEEE, 93(2):232 275, 2005. Special issue on Program Generation, Optimization, and Adaptation. \n[9] SPIRAL web site. www.spiral.net. [10] C. Van Loan. Computational Framework of the Fast Fourier Transform. \nSIAM, 1992. [11] J. Xiong, J. Johnson, R. Johnson, and D. Padua. SPL: A language and compiler for DSP \nalgorithms. In Proc. PLDI, pages 298 308, 2001.  \n\t\t\t", "proc_id": "1065010", "abstract": "A critical optimization in the domain of linear signal transforms, such as the discrete Fourier transform (DFT), is loop merging, which increases data locality and reuse and thus performance. In particular, this includes the conversion of shuffle operations into array reindexings. To date, loop merging is well understood only for the DFT, and only for Cooley-Tukey FFT based algorithms, which excludes DFT sizes divisible by large primes. In this paper, we present a formal loop merging framework for general signal transforms and its implementation within the SPIRAL code generator. The framework consists of &#917;-SPL, a mathematical language to express loops and index mappings; a rewriting system to merge loops in &#917;-SPL and a compiler that translates &#917;-SPL into code. We apply the framework to DFT sizes that cannot be handled using only the Cooley-Tukey FFT and compare our method to FFTW 3.0.1 and the vendor library Intel MKL 7.2.1. Compared to FFTW our generated code is a factor of 2--4 faster under equal implementation conditions (same algorithms, same unrolling threshold). For some sizes we show a speed-up of a factor of 9 using Bluestein's algorithm. Further, we give a detailed comparison against the Intel vendor library MKL; our generated code is between 2 times faster and 4.5 times slower.", "authors": [{"name": "Franz Franchetti", "author_profile_id": "81100496091", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP39045639", "email_address": "", "orcid_id": ""}, {"name": "Yevgen Voronenko", "author_profile_id": "81100647925", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "P728842", "email_address": "", "orcid_id": ""}, {"name": "Markus P&#252;schel", "author_profile_id": "81100268784", "affiliation": "Carnegie Mellon University, Pittsburgh, PA", "person_id": "PP17009912", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065048", "year": "2005", "article_id": "1065048", "conference": "PLDI", "title": "Formal loop merging for signal transforms", "url": "http://dl.acm.org/citation.cfm?id=1065048"}