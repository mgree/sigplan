{"article_publication_date": "06-12-2005", "fulltext": "\n Optimising AspectJ * Pavel Avgustinov1, Aske Simon Christensen2, Laurie Hendren3, Sascha Kuzins1, Jennifer \nLhot\u00b4ak3, Ond.rej Lhot\u00b4ak3, Oege de Moor1, Damien Sereni1, Ganesh Sittampalam1, Julian Tibble1 1 Programming \nTools Group 2 BRICS 3 Sable Research Group Oxford University University of Aarhus McGill University United \nKingdom Denmark Montreal, Canada http://aspectbench.org Abstract AspectJ, an aspect-oriented extension \nof Java, is becoming increas\u00adingly popular. However, not much work has been directed at opti\u00admising compilers \nfor AspectJ. Optimising AOP languages provides many new and interesting challenges for compiler writers, \nand this paper identi.es and addresses three such challenges. First, compiling around advice ef.ciently \nis particularly chal\u00adlenging. We provide a new code generation strategy for around ad\u00advice, which (unlike \nprevious implementations) both avoids the use of excessive inlining and the use of closures. We show \nit leads to more compact code, and can also improve run-time performance. Second, woven code sometimes \nincludes run-time tests to deter\u00admine whether advice should execute. One important case is the c.ow pointcut \nwhich uses information about the dynamic calling context. Previous techniques for c.ow were very costly \nin terms of both time and space. We present new techniques to minimise or eliminate the overhead of c.ow \nusing both intra-and inter\u00adprocedural analyses. Third, we have addressed the general prob\u00adlem of how \nto structure an optimising compiler so that traditional analyses can be easily adapted to the AOP setting. \nWe have implemented all of the techniques in this paper in abc, our AspectBench Compiler for AspectJ, \nand we demonstrate signi.cant speedups with empirical results. Some of our techniques have already been \nintegrated into the production AspectJ compiler, ajc 1.2.1. Categories and Subject Descriptors D.3.4 \n[Programming Lan\u00adguages]: Processors optimization; D.3.4 [Programming Lan\u00adguages]: Processors compilers \nGeneral Terms Performance, Experimentation, Languages Keywords AspectJ, optimization, aspect-oriented \nprogramming language, c.ow pointcut, around advice * This work was supported, in part, by NSERC, EPSRC \nand IBM. Thanks to Jingwu Li for his prototype implementation of around inlining to static methods. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 05, June 12 \n15, 2005, Chicago, Illinois, USA. Copyright c . 2005 ACM 1-59593-080-9/05/0006. . . $5.00. 1. INTRODUCTION \nAspect-oriented programming is a new programming paradigm that is rapidly growing in acceptance, in large \npart due to the popularity of AspectJ [4], an aspect-oriented extension of Java that is com\u00adpatible with \nexisting Java programs. Aspect-oriented programming encompasses many different language features, which \ncan be sep\u00adarated into two categories: static features, essentially a version of open classes; and dynamic \nfeatures. While the static features incur no substantial performance penalty, that is not necessarily \nthe case for the dynamic features. New optimisation strategies are required to improve the performance \nof programs written using the dynamic features of AspectJ. 1.1 Challenges The execution model for (the \ndynamic features of) AspectJ is that execution of the main program is monitored for certain programmer-speci.ed \nevents. When these occur, control is passed to advice, a special kind of method that contains the extra \ncode to be executed. Advice can be run before or after the event that triggers it, or it can be executed \naround it (instead of it). The monitoring of the base program to .nd points where advice should apply \ncan be expensive. Of course, the AspectJ language has been designed so that most of the conditions that \ncause advice to be triggered can be determined statically, and so do not induce over\u00adheads. A nice explanation \nfrom the viewpoint of partial evaluation can be found in [18]. However, some features of AspectJ require \nthe insertion of dynamic checks in the base programs, resulting in performance loss. Furthermore, around \nadvice, which we describe in more detail in Section 2, is a powerful language feature that is dif.cult \nto implement ef.ciently. It has been shown that the combination of these factors can result in substantial \noverhead in AspectJ programs [10]. Here, overhead should be understood as the additional cost for matching \nevents to advice, not the execution of advice code itself. In addition, we must consider space overhead. \nThis is the size of the extra code introduced when aspects are applied to a program. These problems highlight \nthe need for novel aspect-speci.c optimisation strategies. 1.2 The ajc Compiler The reference implementation \nof AspectJ, originally developed by the language s designers, is the ajc compiler [4], maintained as \npart of the Eclipse project. The ajc compiler has been designed with compilation speed in mind, and supports \nincremental compilation. These design aims reduce the opportunities for optimisation, and indeed ajc \nperforms only a small amount of intraprocedural analy\u00adsis and no whole-program analysis. This results \nin substantial over\u00adhead in programs produced by ajc when using certain features of AspectJ [10]. 1.3 \nThe AspectBench Compiler (abc) The observation that aspects can introduce substantial overheads has prompted \nus to build a new compiler for the AspectJ language, the AspectBench Compiler (abc) [1, 5], which is \nfreely available under the GNU LGPL. While abc uses a weaving strategy simi\u00adlar to ajc in many ways, \nby contrast its design was motivated by two goals: to be extensible (so that new features can be added \nto the input language) and provide a powerful analysis and optimi\u00adsation framework. This second feature, \nwhich aims to reduce the overheads of AOP, is the main focus of this paper. To achieve this, abc uses \nthe Soot program analysis and trans\u00adformation framework [24] as a backend. Soot provides a typed, three-address \nintermediate representation (called Jimple) and a li\u00adbrary of standard program analyses. In addition, \nit is straightfor\u00adward to de.ne new analyses in Soot, both intraprocedural and in\u00adterprocedural. In particular, \nthe Jimple IR is extremely well-suited to program analysis and transformation. 1.4 Contributions This \npaper is the .rst systematic study of the analysis and opti\u00admisation of aspect-oriented programs, in \nparticular for the AspectJ language. We present the following novel contributions: A novel implementation \nstrategy for around advice . Around advice is executed instead of the event that triggered it. Our im\u00adplementation \nstrategy avoids the use of closures in all but some pathological examples, unlike earlier implementations, \nwhich relied heavily on closures, and does not require inlining with the associated risk of code bloat. \nFurthermore, our implemen\u00adtation allows us to optionally run a postpass inliner which can selectively \ninline.  A number of intraprocedural optimisations to reduce the over\u00adheads of c.ow pointcuts . This \nfeature of AspectJ is used to intercept method calls in the dynamic scope of others, and its naive implementation \ncan be very costly.  An interprocedural analysis to completely eliminate the over\u00adheads of using c.ow \nin most cases. This analysis and the asso\u00adciated transformations illustrate our .nal contribution:  \nA general technique for leveraging analyses and transforma\u00adtions for pure Java on AspectJ programs. The \ntechnique con\u00adsists of .rst compiling the program naively, possibly inserting too many dynamic checks \n(for the applicability of advice) into the base program. We then analyse the resulting intermediate code, \nand reconsider the decisions to insert dynamic checks, based on the analysis results.  All these contributions \nhave been implemented in abc and, at our suggestion, some have also been adopted by ajc. We present exper\u00adiments \nto con.rm that the above techniques can result in dramatic improvements in run time as well as code size. \nWhile this paper il\u00adlustrates the techniques in the context of the AspectJ language, they equally apply \nto other aspect-oriented programming languages. 1.5 Outline This paper is structured as follows. We \n.rst brie.y introduce the relevant features and terminology of AspectJ in Section 2. Then, we describe \nthe optimisations used in abc s implementation of around advice in Section 3. Subsequently, optimisations \nspeci.c to the c.ow construct of AspectJ are given in Section 4. Section 5 sum\u00admarises further ef.ciency \nimprovements achieved by abc. Finally, we give related work in Section 6 and conclude in Section 7. \n 2. BACKGROUND AND DEFINITIONS The execution events in an AspectJ program that can be monitored and associated \nwith advice code are called join points. A join point is a span of time in the execution of the program. \nExample join points are a call of a method, an execution of a method body, a .eld read or an execution \nof an exception handler. For any particular join point, the textual part of the program executed during \nthe time span of that join point is called the shadow of the join point. AspectJ contains a query language \nfor picking out join points. Such a query is called a pointcut. An advice declaration consists of an \nadvice kind (before, after, around), a pointcut, and a body of code, called advice. The advice is to \nbe executed before, after, or instead of any join point which matches the pointcut. Whenever multiple \npieces of advice apply at the same join point, precedence rules determine the order in which they execute. \nA pointcut consists of a number of pointcut designators con\u00adnected by boolean connectives. Each pointcut \ndesignator is either static (de.ning a set of join point shadows) or dynamic (de.ning a run-time condition). \nSome examples of static pointcuts are call and execution, which match all calls to and executions of \na method matching a pattern; within, which matches all join points within class matching a pattern; and \nhandler, which matches exception handlers. Some examples of dynamic pointcuts are args (a), which matches \nwhen actual arguments of a method have speci.ed run\u00adtime types; if (e), which matches when the arbitrary \nJava expres\u00adsion e evaluates to true; and c.ow ( p), which matches when a join point is within the dynamic \nscope of a join point matched by point\u00adcut p. In addition to testing runtime conditions, dynamic pointcut \ndesignators may also bind context values to variables to make them available to the advice code and to \nthe code in if pointcuts. For in\u00adstance, the args pointcut designator may bind the actual arguments. \nAspectJ also contains standalone pointcut query constructs. The declare error and declare warning constructs \ntake a pointcut consisting of only static pointcut designators along with a message. If the pointcut \nmatches any join point shadow, the message is printed as a compile-time error or warning, respectively. \nThe process of compiling AspectJ programs is known as weav\u00ading. The base program and advice declarations \nare woven together into one program which behaves as if the aspects were monitoring execution of the \nbase program, and invoking the relevant advice. Weaving is a two-step process. The .rst step, pointcut \nmatch\u00ading, checks for each possible join point shadow in the program and each advice declaration, whether \nthe pointcut could possibly match a join point at that shadow. If so, it constructs a dynamic residue \nof the runtime checks to be performed at the shadow to determine whether the pointcut actually matches. \nThe second step is advice weaving. At each join point shadow where a piece of advice may apply, code \nis generated to evaluate the dynamic residue and, if it matches, to bind the context values and invoke \nthe advice. 3. OPTIMISING AROUND ADVICE Most advice in AspectJ programs adds some code to a join point, \neither before or after it. around advice is unique in that it is executed instead of each join point \nit applies to. It can, however, invoke the original join point at any time by using a proceed statement. \nThe following caching aspect demonstrates the usefulness of this interception mechanism. The aspect intercepts \ncalls to a method named foo and only executes a call if the result is not in the cache already: aspect \nCache { pointcut methodsToCache(Object arg) : call(Object foo(Object)) &#38;&#38; args(arg); Object around(Object \narg) : methodsToCache(arg) { if (!cacheContains(arg)) setCache(arg, proceed(arg)); return getCachedValue(arg); \n} boolean cacheContains(Object arg) {...} void setCache(Object arg, Object value) {...} Object getCachedValue(Object \narg) {...} } Like all forms of advice, around advice can have arguments. Each of these arguments has \nto be bound to an exposed context value by the pointcut expression: in the above example, args(arg) binds \nthe argument of foo to arg.A proceed statement looks like a method call with the same number of arguments \nas the advice, and it executes the original join point with the bound context values set to the arguments \nof the proceed call. The proceed call can therefore change the values of context values (such as method \narguments). 3.1 Implementation Issues A number of dif.culties arise in the implementation of around advice \n(and particularly the proceed statement), which we brie.y outline before giving possible solutions. The \n.rst problem is that around advice can apply in mul\u00adtiple places within the base program. For example, \nconsider a piece of around advice with pointcut execution(void foo(..)) || execution(void bar(..)). This \nwill apply to the bodies of methods foo and bar, and any occurrence of proceed in the advice body will \npass control back to the method that was matched. Furthermore, the context of the advice applications \n(the values of locals used in the advised statements) can certainly differ between applications to foo \nand bar. This polymorphic behaviour of proceed is the main dif.culty in its implementation. Matters are \nfurther complicated by the fact that proceed can occur in arbitrary places within the advice body, including \nlocal and anonymous classes. An important implication is that proceed statements may be executed after \nthe control .ow has left the advice body. Any context values needed for the proceed call must therefore \noutlive the execution of the advice in this case. Finally, aspects are not restricted to observing the \nbase program, and in fact advice can apply to other advice. In particular, a piece of around advice can \napply to the execution of its own body, directly or indirectly. Such circular adviceexecution applications \nare very rare, and usually pathological and a symptom of an error in the program. It is important to \nobserve that these can occur, however, as we shall have to treat such applications as special cases. \nNote that the application of around advice to any other advice other than itself, or to a statement within \nits body (but not the whole body) is not considered circular. These other cases are common, but circular \napplications are rare. 3.2 General Implementation Any piece of advice, regardless of its kind, is turned \ninto a plain Java method (the advice method) both by abc and ajc. The interest lies in the translation \nof the proceed statement, minding the issues described above. The polymorphic behaviour of proceed, coupled \nwith the need to store execution context, motivates the use of closures as a default and straightforward \nimplementation strategy. As a preparatory step to implementing around, any shadow that is advised by \nsome around advice is lifted into a separate method (the proceed method) that can be invoked by proceed. \nNote that this is necessary as shadows need not be entire method bodies. 3.2.1 Closures We shall now \ngive a brief description of the closure strategy. This approach works by de.ning a suitable interface \ntype (or class type) for each advice method, as follows: public interface Around$1 { public ret-type \nproceed$1(arg-type arg1, ...); } Then, all calls to proceed are translated to calls on this closure interface. \nNote that the arguments passed to proceed can be differ\u00adent from the arguments that were passed into \nthe advice method. public class AspectClass { ret-type adviceMethod$1(Around$1 closure, arg-type arg1, \n...) { ... ret-type result=closure.proceed$1(arg1 , ...); ... } ... } For each advice application, a \nspecialised closure type is de.ned that implements the interface and has members for the context values, \nand for each advice invocation, an instance of the closure class is passed to the advice method. This \nclosure must then call the proceed method. public class ShadowClass { public void shadowMethod() { Around$1 \nclosure=new Around$1$Impl(); ..initialise members with context values.. AspectClass.aspectOf().adviceMethod$1(closure, \n...) } } The major drawback of the closure approach is performance. Each time advice is triggered, a \nclosure object has to be allocated on the heap, which can be a signi.cant overhead. 3.2.2 Inlining In \nall cases apart from the case of advice applying to itself (ei\u00adther the whole advice or a statement within \nit), it is possible to avoid closures by duplicating the advice method for each point in the program \nwhere the advice applies. This so called inlining (in ajc terminology) eliminates the need for polymorphism \nas the pro\u00adceed statements in this specialised advice method always invoke the same join point shadow, \nand the join point context can be trans\u00adferred using method arguments. While inlining may be a good optimisation \nin certain situations, the duplication of the advice method for every advice application can lead to \ncode bloat and thus is unsuitable as the general ap\u00adproach. The proceed statement is implemented in ajc \nusing these two strategies, a generic strategy based on closures and an inlining strategy that is used \nin certain cases. We shall now describe abc s approach.  3.3 Around weaving in abc We present a novel \napproach for weaving around advice. Our ap\u00adproach is generic: the same strategy can be employed everywhere, \nand it does not rely on inlining. The only exception is the patholog\u00adical case of circular adviceexecution \napplications, described previ\u00adously. We will return to that case in Section 3.3.4. When compared to the \ndual strategy of ajc, abc s around weaver never performs signi.cantly worse and in many cases performs \nsigni.cantly better. Particularly, whenever ajc resorts to closure creation, abc can be expected to \nproduce faster code  when the advice code is big and applies at many locations, abc avoids ajc s code \nbloat  with circular adviceexecution applications, abc produces fewer closure objects and hence faster \ncode.  We shall now describe our weaving strategy in detail. 3.3.1 The Generic Implementation Instead \nof creating a closure class for each join point shadow where around advice could apply, abc places the \nproceed code from all join point shadows of a class in a single static proceed method in the class. If \nthe shadow exceeds a certain size, it is .rst extracted into a dedicated static method which is then \ncalled from the proceed method. This is an optimisation that prevents unreasonably large proceed methods. \nEach join point shadow at which around advice applies is re\u00adplaced with a call to the advice body. Into \nthe advice body, we pass a static class ID to identify the class from which we are calling it, and a \nshadow ID to identify the join point shadow within the class. To implement the proceed call, the advice \nbody uses the static class ID (using a switch statement) to select the class from which it was called, \nand calls the static proceed method in that class (note that the ID 0 is reserved for calls on a closure \ninterface in case the weaver has to fall back on closures). The static proceed method uses the shadow \nID to select the shadow whose proceed code it must execute. Because we keep the code of each join point \nshadow in the class where it originally occurred, there is no need to generate accessor methods for private \nmembers.  public class AspectClass { ret-type adviceMethod$1(Around$1 closure, int shadowID, int staticClassID, \nargs) { ... switch (staticClassID) { case 0: closure.proceed$1(shadowID, args); break; case 1: ShadowClass.proceed$1(shadowID, \nargs); break; ...dispatch to other classes to which the advice applies... } } public class ShadowClass \n{ public static ret-type proceed$1(int shadowID, args) { switch(shadowID) { case 0: ... do what the .rst \nshadow did... case 1: ... do what the second shadow did... ...handle further cases... } } ... } 3.3.2 \nContext and Advice Formals In addition to calling the right piece of code we must also ensure that values \nare passed for free variables used by this code (the context). We describe the implementation of context \npassing next. Passing context Context from the join point shadow is needed in two places. First, it is \nused by the code of the shadow itself. Since we have moved this code out from the original join point \nshadow to the static proceed method, we must pass the required context into this method. Second, the \nAspectJ pointcut designators args, this, and target allow values from the context of the join point to \nbe bound to formal parameters of the advice, and used in the advice body. Therefore, these values must \nbe passed from the join point shadow site to the advice method that is called. The dynamic residue of \nthe pointcut guarding the advice may or may not match at run time. If the residue does not match, the \nadvice is not executed, and the static proceed method is called directly from the shadow, so the context \nvalues are passed to it directly. If the residue does match, the advice body is called from the shadow, \nand it may in turn call the static proceed method (if the advice contains a proceed call). Therefore, \nfrom the shadow, we must pass to the advice body both the context needed by the advice body itself and \nthe context needed by the proceed code, so that the advice body can pass it to the static proceed method. \nOne complication is that one advice method can apply to many different join point shadows with different \ncontext values. There\u00adfore, we add a suf.cient number of parameters of each type to the method implementing \nthe advice to cover the context at all shadows at which the advice may apply. To keep the number of parameters \nreasonably small, we only add parameters of the types Object, int, .oat, double and long, since context \nvalues of any type can be con\u00adverted to one of these types to be passed into the method. A second complication \nis that the context value to be bound to an advice parameter may not be known until run time. Consider \nthe following pointcut: void around(Foo x) : args(x,..) || args(..,x) ... In this case, x may be bound \nto the .rst argument of a method (if it has type Foo), or the last argument.1 The dynamic residues at \nthe join point shadow determine which part of the pointcut matches, so at the shadow, at run time, we \nknow whether the x in the advice should be bound to the .rst or last parameter. A third complication \nis that the advice may modify the context that is to be passed to the proceed code for the shadow. The \npro\u00adceed expression in the advice body accepts the same number of ar\u00adguments as there are parameters \nto the advice body. In the proceed call to the original code from the shadow, these arguments replace \nthe context values that were bound to the corresponding advice pa\u00adrameters when the advice was invoked. \nIn the above example, if we call proceed (null) from the advice, the code of the shadow must be executed \nwith its .rst or last argument replaced with null, de\u00adpending on which clause of the pointcut matched \nat the join point before the advice was executed. Since this binding is only known at the dynamic residue \nand only at run time, we must communicate it from the residue to the advice method, which then communicates \nit to the static proceed method. To do this, at the dynamic residue, we create a bit vector specifying \nthe bindings, and pass it through to the relevant methods. 3.3.3 Local and anonymous classes As we have \nobserved previously, proceed statements can occur in local and anonymous classes within advice methods, \nand thus the proceed invocation can occur after control .ow has left the advice method (and so its context \nmust be stored). Our implementation strategy conveniently extends to this case, as all the necessary \ncontext is available in the advice method. We simply need to add new .elds to the local or anonymous \nclass to hold the context values and initialise these .elds when the classes are instantiated. 3.3.4 \nSpecial Cases In the previous sections we have described the generic implemen\u00adtation of around advice \nin abc. As mentioned above, in the patho\u00adlogical case of circular adviceexecution this cannot be used, \nand 1 ajc as of version 1.2.1 avoids this complication by issuing a compiler limitation error when encountering \nmultiple binding pointcut primitives for the same advice formal. we resort to closures instead. Furthermore, \nfor ef.ciency abc also chooses to inline advice methods in some cases (when the advice is small and does \nnot apply numerous times, to avoid code bloat). Here inlining is not taken in the ajc sense, but rather \nin the usual sense of substituting the body of the method (in this case, the ad\u00advice method) at the point \nwhere it is called. We now describe these two special cases in greater detail. Circular advice applications \nThe execution of advice is a join point itself, so advice can apply to the execution of advice (the entire \nbody of the advice method). These advice-on-advice appli\u00adcations can be expressed as a directed graph \nstructure. When weav\u00ading into the execution of a method, the whole body of the method is moved into the \ncorresponding proceed method. To simplify the weaving process, a topological sort is performed on the \ngraph struc\u00adture prior to weaving. This ensures that once an around advice method has been woven into, \nit itself is not applied to any join point shadows anymore. Obviously, a topological sort fails in the \npresence of cycles in the graph, and the weaver will encounter situations where the advice method to \nbe woven has already been woven into. This is the only case where we resort to the creation of closure \nobjects. The semantics of AspectJ dictate that in a cyclical graph, the order of the execution of advice \nmethods is determined by the dynamic residues before any advice is executed. Because those residues and \nthe resulting execution order can be arbitrarily complex, we decided that closures offer a clean, general \nsolution. As observed previously, cycles in the advice-on-advice applica\u00adtion graph are very rare and \nusually pathological. It therefore seems unnecessary to try to avoid closures under these circumstances. \nWe have, however, strived to minimise the cost of closures; we create specialised closure classes with \n.elds matching the types of context values, whereas ajc uses an expensive object array to store context \nvalues (requiring boxing of primitive types). Inlining as an optimisation pass For very small advice, \nthe most ef.cient strategy can be to inline the advice directly into the join point shadow. Inlining \ncan also be bene.cial if advice with Object return type applies to a join point with a simple type. In \nthis case, the inlining can lead to the subsequent removal of the boxing and unboxing code. Inlining \nis implemented in abc as an optimisation pass running after the around weaver. The inlining process is \nimplemented as a series of plain Java optimisations. The advice method is .rst inlined into the join \npoint shadow as a normal Java method. A constant propagator and switch statement folder are then used \nto remove checks on the static class ID. Finally, the proceed method is inlined also, and its switch \nstatement removed. Since multiple pieces of advice can apply at the same shadow, this whole process must \nbe repeated until there are no calls left to inline. A special boxing remover pass removes unnecessary \nboxing and unboxing operations.  3.4 Empirical Results To compare our strategy to ajc s and to experiment \nwith the dif\u00adferent tradeoffs of inlining strategies, we experimented with three base programs and three \naspects. The base programs are ants, an aspect-oriented simulation of an ants colony (following the speci\u00ad.cation \nof the ICFP 2004 programming contest) written by one of the authors (OdM) for use in an undergraduate \ncourse; sim, a dis\u00adcrete event simulator for certi.cate revocation simulation [2]; and weka, part of \nthe weka machine learning library [25]. All bench\u00admarks were run on a dual AMD Athlon 2000+ with 2GB \nRAM and the Sun J2SE 1.4.2 JVM. Table 1 shows the both the execution time (in seconds) and wo\u00adven code \nsize (in bytecode instructions). For each benchmark we Time (s) Size (instr.) Benchmark abc abc ajc abc \nabc ajc (inline) (inline) sim-nullptr 21.9 23.9 21.4 7893 10687 10186 sim-nullptr-rec 23.6 20.8 124.0 \n8216 20519 10724 weka-nullptr 19.0 17.8 16.0 103018 116364 134290 weka-nullptr-rec 18.9 18.0 45.5 103401 \n188666 130483 ants-delayed 17.5 17.6 18.2 3688 3906 3785 ants-pro.ler 22.5 19.2 21.2 7202 13333 13401 \n Table 1. Execution Times and Code Size give results for: abc, using abc s generic around weaver with \ninlin\u00ading disabled; abc (inline), the same as abc, but with the aggressive postpass inliner enabled; \nand ajc, the result given by ajc s around weaver (which is either closure-based or inlining, depending \non the benchmark). For each benchmark, we have put the fastest time and the smallest code size in bold. \nNote that in most cases either abc or abc (inline) gives the fastest code and that abc s code size is \nconsistently smallest, sometimes by a signi.cant margin. To compare abc s generic weaving strategy to \najc s closure\u00adbased and inlining strategies, we applied two versions of the nullptr aspect [3] to two \nbase programs, sim and weka (the .rst four lines in Table 1). The nullptr aspect is a very simple around \naspect for enforcing coding standards that we found on the web when searching for examples of aspects. \nIt simply checks for methods returning and issues error messages in the cases where null is returned. \nWe used two different versions of the aspect, a recursive one (the original form) where the advice applies \nto itself and a non-recursive version where we explicitly use !within(...) to avoid matches within the \nbody of the advice. The ajc compiler uses closure object creation for the .rst case (because of the recursion) \nand inlining for the second case, whereas abc uses its generic implementation for both cases. Comparing \nthe execution times for the non-recursive (sim\u00adnullptr and weka-nullptr) versions to the times for the \nrecursive ver\u00adsions (sim-nullptr-rec) and (weka-nullptr-rec), we can see that the execution time and \ncode size for abc is almost the same, whereas ajc produces much slower code for the recursive versions \n(6 times slower for sim and almost 3 times slower for weka). For the the non recursive cases, abc is \nslightly slower than ajc. From these experiments we can see that abc is fairly insensitive to whether \nthe advice is recursive or not, but ajc pays a huge penalty when it must switch to an explicit closure \nstrategy. abc s behaviour is bene.cial since programmers often make their advice recursive by accident \nand they need not pay a performance penalty. There are other situations where the ajc weaver uses closures, \nwhich is demonstrated by the ants-delayed benchmark. This bench\u00admark uses the DelayOutput aspect which \ncaptures calls to output methods and delays these calls until the end of the base program. This is accomplished \nusing a local class of type Runnable in the ad\u00advice method that calls proceed in its run() method. The \najc weaver has to instantiate closure objects in addition to the instances of the local class. Our weaving \nstrategy avoids this, which explains why the abc results are slightly faster. To demonstrate the adverse \neffects of a naive inlining strat\u00adegy, we applied a pro.ling aspect to our ants base program (ants\u00adpro.ler). \nThe pro.ling aspect contains a relatively big piece of around advice that is applied to the execution \nof every method in the base program. Note that ajc s inlining strategy can almost dou\u00adble the size of \nthe resulting class .les due to the duplication of the advice code for every advice application. Note \nthat this increase in code size can also be observed with abc s inlining strategy. How\u00adever, with our \nweaving strategy, inlining is optional and not nec\u00adessary for good performance. In ajc s case, the only \nalternative to inlining is the use of closures with the dramatic effects on perfor\u00admance shown in the \ntable. Furthermore, with our approach we can selectively inline and we are actively working on mixing \ndifferent inlining strategies. Currently we also have a prototype version of our inliner which inlines \nthe specialized advice to static methods in a similar manner to ajc s inliner, with similar performance \nand space usage. How\u00adever, we believe that we can further improve on both the perfor\u00admance and space \nusage. Instead of putting the specialized static ad\u00advice method in the class containing the shadow being \nadvised, we put the specialized advice method in the class for the aspect. This has the advantage of \navoiding visibility problems since the advice code stays in the aspect. Further, by collecting all of \nthe specialized methods together, and by inlining the specialized proceed bodies into the specialized \nadvice bodies, we have noticed that there are often clones produced. Thus, we believe that the space \nblowup can be reduced, in some important common cases, by recognizing the clones and only creating one \ncopy of the specialized static method for each set of clones. A further optimization is to remove unneeded \nfetches of the aspect instance. Once the advice has been expressed as a specialized static method there \nis often no need for the aspect instance, and we are actively working on eliminating redundant and dead \nfetches of the aspect instance.  4. OPTIMISING CFLOW In the previous section we introduced a new strategy \nfor weaving around advice. When weaving all advice (before, after and around) the weaver must generate \nef.cient code to handle dynamic point\u00adcuts, i.e. those pointcuts that need a dynamic test to determine \nif they should execute at a join point shadow or not. In this section we concentrate on the most challenging \ndynamic pointcut, the c.ow pointcut. The c.ow pointcut picks out join points that fall within the dynamic \nscope of certain events. Speci.cally, for any pointcut p, c.ow( p) applies at a point in the execution \nof the program if p matches some state in the call stack at that program point. If p contains variables \nto be bound, then these are bound to the actual values found in the match nearest the top of the call \nstack. For example, the pointcut call(* foo()) &#38;&#38; c.ow(call(* bar(*)) &#38;&#38; args(x)) matches \nall calls to foo that occur within the dynamic scope of a call to bar, and binds x to the value of the \nargument of the last call to bar. It is clear that the use of c.ow pointcuts requires, in general, the \ninsertion of dynamic tests in the program to test the current state against the condition c.ow( p). The \nnaive implementation of c.ow associates a state with each c.ow pointcut and updates this state incrementally \n(this implementation is described in [18]). The state is a stack of variable bindings that represents \nan abstraction of the call stack. Each time a join point that matches p is entered, a new item is pushed \nonto the stack, with all the variables in p bound to the appropriate values. When this join point is \nleft, the top of the stack is popped. Finally, to check whether c.ow( p) applies at a program point, \nit suf.ces to check whether or not the stack is empty; if it is non-empty then the pointcut applies and \nthe appropriate variable bindings can be found on top of the stack. The implementation of c.ow (as described \nabove and used in ajc) is clearly expensive, both because of the need to update the state (which happens \nevery time p applies) and because of the dynamic tests inserted (which can, in the worst case, apply \neverywhere). Performance experiments con.rm that the overhead introduced is substantial [10]. We introduce \na number of optimisations for c.ow, all imple\u00admented in abc. We .rst show a number of simple, intraprocedu\u00adral \noptimisations that reduce the overhead substantially. Then, we show how the overhead can be entirely \neliminated in many com\u00admon cases by an interprocedural analysis. Finally, we give empir\u00adical measurements \nshowing that the optimisations are very effec\u00adtive. 4.1 Intraprocedural Optimisations The simple c.ow \noptimisations focus on eliminating the more ob\u00advious inef.ciencies in updating the state and checking \nfor applica\u00adbility. They are straightforward but quite effective. 4.1.1 Sharing c.ow states The .rst \noptimisation that abc performs is to share the state up\u00addate and query code between related (or identical) \nc.ow pointcuts whenever possible. Consider the following pointcuts: call(* bar()) &#38;&#38; c.ow(call(* \nfoo(..)) &#38;&#38; args(t, *, *)) call(* bar()) &#38;&#38; c.ow(call(* foo(..)) &#38;&#38; args(*, s, \n*)) A naive implementation would keep a stack for each c.ow pointcut, and update and query them independently. \nWe optimise this by observing that a single c.ow pointcut can be written that covers the two existing \ninstances. In this case, it is c.ow(call(* foo(..) &#38;&#38; args(l1, l2, *)) (where l1 and l2 are fresh \nvariables). Note that this binds variables used in either one of the c.ow pointcuts in the original program. \nThe implementation of c.ow in abc attempts to unify each pair of c.ow pointcuts that it .nds. Uni.cation \nof two pointcuts suc\u00adceeds if the pointcuts are syntactically equivalent with the excep\u00adtion of free \nvariables, and returns a pointcut that carries enough state to cover both pointcuts (as in the above \nexample). In general, this sharing of state can improve performance sub\u00adstantially. In fact, cases similar \nto the above arise frequently due to inlining of named pointcuts, a strategy used both in ajc and abc. \nAn added bene.t is that some method bodies can become smaller when this is performed (by avoiding duplication \nof bookkeeping code). We present empirical measurements of the performance im\u00adprovements in Section 4.3. \n 4.1.2 Counters for c.ow without bound variables The next optimisation applies to pointcuts of the form \nc.ow( p), where p does not bind any values. In this case, the state of the c.ow( p) reduces to a stack \nof empty sets of variable bindings. In ajc 1.2, this is represented by a stack of arrays of length 0. \nWe improve on this in the obvious way, by replacing the stack with an integer counter that is incremented \nand decremented when p is entered and left respectively. This avoids repeated allocations of empty arrays. \nThe case of a parameterless c.ow appears to be quite common, so this optimisation is widely applicable. \n 4.1.3 Reuse of counters/stacks The .nal simple c.ow optimisation is the caching of c.ow state objects \n(stacks or counters). The state of a given pointcut c.ow( p) is thread-local, as it is an abstraction \nof the call stack. Multiple copies are therefore kept, one for each thread, and any operation on c.ow \nstate (updating or checking) involves retrieving the copy valid for the current thread (in the worst \ncase, a hash table lookup). In general, multiple operations on the same c.ow state can occur within the \nbody of the same method. In fact, updates to the state of a c.ow are always paired (the state is updated \nwhen entering and leaving a join point), so in most cases the state is retrieved at least twice in any \nmethod in which it is needed at all. We can therefore improve on the original implementation by retrieving \nthe appropriate state object only when it is .rst used in a given method, and storing it for future uses \nin the same method.  4.2 Interprocedural Optimisations The optimisations that we have described above \nreduce the over\u00adhead associated with c.ow, but this can still be substantial. Since the c.ow construct \ndepends on dynamic properties of the program in general, it is impossible to eliminate such overhead \nentirely. However, many uses of c.ow can be statically determined, at least at some program points. To \ntake a simple concrete example, the pointcut c.ow(call(* foo())) matches all points in the execution \nof the program within the dynamic scope of a call to foo. It is possi\u00adble to determine statically that \nsome program points can never be in the dynamic scope of foo, and that some program points always execute \nin its scope. At each such program point the c.ow pointcut is statically known to be true or false, so \nthe dynamic check can be eliminated. In addition, eliminating such dynamic matching code can allow the \ncompiler to eliminate some of the state-updating code for this c.ow (if its effects can no longer be \nobserved after dynamic checks are removed). Our empirical results in Section 4.3 show that c.ow pointcuts \ncan indeed be statically determined in almost all cases we have encountered to date. We will now describe \nthe analysis used in abc to achieve this. The idea for this analysis was introduced in [20] for a simple \nprocedural language. The analysis has been adapted to the much wider context of AspectJ and implemented \nwithin abc. It requires an interprocedural analysis, but has two substantial advantages: It eliminates \nthe overhead for c.ow completely in many com\u00admon cases, and  in those cases, it allows c.ow to be used \nin constructs that require static pointcuts (such as declare warning).  4.2.1 Analysis in abc One of \nthe design goals of abc was to make it possible to anal\u00adyse the code being woven, and use the analysis \nresults to optimise the weaving process to produce more ef.cient code. In particular, we wanted to be \nable to leverage the many analyses existing for Java code, without having to rewrite all of them to be \nspeci.c to AspectJ. This is, in fact, not merely a matter of convenience: it is very hard to work out \n(for example) the control .ow prior to the weaving of advice, because an analysis would have to take \ninto account complex advice precedence rules, 11 different join point types, the option to change the \narguments of a call via proceed, and so on. It follows that in general, an interprocedural .ow analysis \nbe\u00adfore weaving needs to contain all of the complexities of the point\u00adcut matching and advice weaving \nin an AspectJ compiler. Indeed, others who have studied the static analysis of aspect-oriented pro\u00adgrams \n[19, 26] (for the purpose of property checking), were forced to make strong restrictions in their implementation \nto circumvent these complexities when doing a direct analysis prior to weaving. Our aim, however, is \nto cover the full AspectJ language. For these reasons, abc includes a hook to perform analyses on the \nJimple code produced immediately after weaving, optimise the naive weaving instructions originally produced \nby the matcher, and then repeat the weaving process on the original code using the optimised weaving \ninstructions. Because the woven code being analysed has no AspectJ-speci.c constructs, it is possible \nto apply standard analyses already in Soot. Of course, we also implement analyses and optimisations speci.c \nto AspectJ, but these are greatly simpli.ed by being able to use the results of Java analyses. The structure \nof the abc backend which makes these analyses and optimisations possible is shown in Figure 1. In normal \nopera- Jimple from .class/frontend  Weaving Optimiser Instructions Woven Analyser Jimple Bytecode \nGenerator Figure 1. Reweaving in the abc backend tion, the phases are executed from top to bottom: matcher, \nweaver, bytecode generator (depicted in the middle column of the .gure). We now discuss each of these \ncomponents in more detail. The matcher takes as input information about all the pointcuts and advice \nfrom the frontend, as well as the Jimple intermediate representation of the bytecode. The matcher produces \na set of weaving instructions which specify where in the code they should be woven. A weaving instruction \nthus consists of a position in the code (which may be a single statement or a whole region of code), \na piece of advice (which is represented as a regular method), and a representation of the residue. Often \nthat residue is alwaysmatch or nevermatch which means no runtime test needs to be generated. Occasionally \nthe residue represents a truly dynamic test, for example a boolean expression for if pointcuts, a type \ninstance test for args, or a test on the relevant stack for c.ow. The weaver executes these instructions, \nproducing woven Jim\u00adple, where the dynamic tests and calls to the advice methods are inserted into the \nexisting Jimple. The woven Jimple code thus cor\u00adresponds to pure Java, with no aspect-oriented constructs \nat all. The standard code generator of Soot [24] can therefore translate wo\u00adven Jimple to bytecode. As \npart of this code generation pass, we also perform simple intraprocedural optimisations (such as com\u00admon \nsubexpression elimination and constant propagation) to clean up the results of weaving. Let us now consider \nhow this architecture, where the matcher and weaver have been separated, facilitates analyses and optimisa\u00adtion: \nin Figure 1, this is illustrated by the boxes in the right-hand column. Because woven jimple has no aspect-oriented \nfeatures, we can leverage standard Java analyses on woven Jimple, for instance the construction of a \ncall graph: there is no need to adapt stan\u00addard analyses for AspectJ. As mentioned earlier, this is very \nimpor\u00adtant, because it is (for example) extremely hard to work out control .ow in the presence of advice \nprior to the weaving process. The result of such analyses is then fed into an optimiser that operates \non the weaving instructions. Typically the optimiser turns dynamic residues (which would result in runtime \ntests when woven) into the static residues alwaysmatch or nevermatch. The weaver can then be invoked \nagain, producing better woven code, where certain dy\u00adnamic tests that always succeed or always fail no \nlonger appear. Note that this mechanism requires saving a copy of the original Jimple code prior to the \noriginal weaving pass, which abc does. So far, we have implemented an interprocedural c.ow analysis and \na thisJoinPoint escape analysis, but the approach is general; other analyses (and corresponding optimisations) \ncan be added to the boxes labelled Analyser and Optimiser in Figure 1. It is possible that an analysis \nwill produce more precise results if executed not on the naively woven Jimple, but on Jimple woven using \noptimised weaving instructions produced by an earlier pass of the analysis. Therefore, abc allows the \nWeaver-Analyser-Optimiser feedback loop to be repeated if desired. 4.2.2 Call Graph Estimating which \nshadows may or must be in the c.ow of other shadows requires a call graph approximating which methods \nmay be called from which call sites. We base our analyses on a con\u00adservative call graph: every method \ninvocation possible at run-time must be included in the call graph. Call graph construction for object-oriented \nlanguages like Java has been the subject of a sig\u00adni.cant amount of research (e.g. [6,9,22,23]). Rather \nthan reinvent the wheel, we construct call graphs using Paddle, a successor of Spark [13, 14], the points-to \nanalysis and call graph construction framework available in Soot [24]. In Java, most method calls are \nvirtual, meaning that the method invoked depends on the run-time type of the receiver object. The treatment \nof virtual calls is one of the key features distinguishing different call graph construction algorithms. \nThe Paddle framework allows us to experiment with call graphs constructed using algo\u00adrithms ranging from \nCHA [9], which conservatively assumes that receivers could have any type admitted by their declared type, \nto us\u00ading a subset-based points-to analysis to compute possible run-time receiver types. We used the \nlatter option in what follows: it turns out that the extra time spent to create a precise call graph \nsignif\u00adicantly reduces the time for the interprocedural c.ow analysis we describe below. Some applications \nof call graphs, such as devirtualisation, only require call edges for explicit invoke instructions present \nin the code. However, because methods invoked implicitly by the VM are de.ned to be in the c.ow of their \ncalling context, our call graph must include these implicit calls. In particular, we include implicit \ncalls to static initialisers [17, section 2.17.4], calls through the PrivilegedActioninterface, and implicit \nconstructor calls by the Class.newInstance method. For the latter, the user provides a list of all classes \nthat may be instantiated using re.ec\u00adtion. To ensure that this list (and our call graph) is complete, \nwe insert code into methods not reachable in the call graph to abort execution and alert us to the error. \nPaddle handles these tricky but important details for us; we do not need to consider them explicitly \nin our c.ow analysis. One type of implicit method invocation which we speci.cally exclude from the call \ngraph used for c.ow analysis is the invocation of the run method of newly created threads. In abc, we \nstrive to be consistent with the AspectJ language as speci.ed by the ajc implementation. In ajc, c.ow \nstacks are maintained separately for each thread, so the code executed by a thread is not considered \nto be in the c.ow of the code that created the thread. Paddle anotates each call graph edge with a kind, \nwhich we use to detect and remove edges of this unwanted kind. 4.2.3 Interprocedural c.ow analysis Desired \noptimisation The customary implementation of a c.ow pointcut expression c.ow( p) incurs overhead at two \nkinds of shad\u00adows. First, at each shadow matching p,a c.ow stack is pushed and popped to indicate when \nwe are in the dynamic scope of the c.ow. We denote these shadows with the term update shadow. Second, \nat each shadow where the c.ow pointcut could possibly match, we in\u00adsert a dynamic residue to test whether \nthe c.ow stack is non-empty. We denote these shadows with the term query shadow. We wish to perform two \nkinds of optimisation. First, if we can determine c.ow stack emptiness at a query shadow statically, \nwe can remove the dynamic residue at the query shadow, and possibly other code that becomes unreachable. \nSecond, if we can prove that a c.ow stack update operation will not be observed by a stack query within \nthe dynamic scope of an update shadow, we can remove the stack update operations at the update shadow. \nAnalysis information required For each c.ow stack st in the program, we de.ne two kinds of sets of instructions \nto be com\u00adputed, mustC.ow(st), and, for each update shadow sh updating st, mayC.ow(sh). mayC.ow(sh) contains \nevery instruction i in the program such that when i is executed, we may be in the dynamic scope of sh. \nThat is, i may execute after the push operation of sh has been performed, but before the corresponding \npop operation has been performed. mustC.ow(st) contains every instruction i such that whenever i is executed, \nwe must be in the dynamic scope of some update shadow sh updating st. Whenever a query shadow (on stack \nst) is not in mayC.ow(sh) for any update shadow sh (on the same stack st), we replace the dynamic test \nwith a constant false pointcut expression.2 Any query shadow in mustC.ow(st) is replaced with a constant \ntrue pointcut expression. In addition, we calculate a subset necessaryShadows(st) of up\u00addate shadows \nwhose effect may be observed at a query shadow. Each update shadow sh . necessaryShadows(st) satis.es \ntwo conditions. First, some query shadow qsh that has not been re\u00adsolved statically may occur in the \ndynamic scope of sh (i.e. qsh . mayC.ow(sh)). Second, sh may occur outside the dynamic scope of all update \nshadows of st (i.e. sh . mustC.ow(st)). This second condition enables us to mark as unnecessary those \nupdate shadows at which the stack is always already non-empty. The optimisations become more complicated \nwhen the c.ow binds arguments because, in this case, each query shadow not only tests whether the stack \nis non-empty, but also observes the entry at the top of the stack. We can still resolve statically those \nquery shadows not in mayC.ow (sh), since we know that the stack would always be empty when they are executed. \nHowever, at the query shadows where we know the stack is non-empty, we must keep the dynamic residues \nwhich read the entry from the stack. In addition, we can no longer remove update shadows just because \nthey are in the mustC.ow of the relevant stack, because we also need the correct entry to be pushed onto \nthe stack in addition to the stack being non-empty. Computing analysis information The exact extent of \na c.ow shadow depends on subtle details of advice precedence and the distinction between c.ow and c.owbelow, \nand the weaver must respect these details when weaving the c.ow stack update oper\u00adations. Because we \nperform the analysis on the woven code, we need not consider these details; we simply consider each c.ow \nshadow to start immediately after the point where the weaver wove the c.ow push instruction, and end \nimmediately before the corre\u00adsponding c.ow pop instruction. We need to unambiguously classify every instruction \nin the method as being either within or outside the c.ow shadow. This requires that there be no jumps \ninto or out of the shadow, which would bypass the push or pop instruction. Due to details of the weaving \nprocess, this requirement is always satis.ed, except in the case when the argument p of the c.ow expression \nc.ow( p) is not entirely static, and requires a dynamic residue. In this case, the weaver generates the \ndynamic test at the update shadow. If the pointcut p does not match, we do not enter 2 The c.ow expression \nmay be part of a more complicated pointcut expres\u00adsion. Constant folding of pointcut expressions is done \nin a separate phase prior to weaving. the dynamic scope of the c.ow, so a conditional jump skips the \nstack update operations. Therefore, when p is not entirely static, the instructions between the push \nand pop may execute within or outside the dynamic scope of the c.ow. Therefore, none of these instructions \nis a member of mustC.ow(st). Algorithm 1 is used to compute mayC.ow(sh). It begins with the statements \nin the intra-procedural shadow of sh. Then, it adds the statements of all methods that may be called \nfrom a statement already in the set, until a .xed point is reached. Algorithm 1 compute mayC.ow(sh) mayC.ow \n.{i | i is in intraprocedural shadow of sh} repeat for all methods m |.i . mayC.ow . i may call m do \nmayC.ow . mayC.ow . set of statements in m end for until mayC.ow does not change We have implemented \nall of the inter-procedural c.ow analyses using Jedd [15], an extension of Java for expressing analyses \nusing binary decision diagrams (BDDs), which it abstracts as relations. We chose to implement the analyses \nin Jedd for two reasons. First, they can be expressed in Jedd concisely and clearly. As an example, Figure \n2 shows the Jedd implementation of Algorithm 1. Notice that the implementation closely mirrors the algorithm. \nSecond, although the sets computed in the analyses may become quite large, they are likely to share many \nsimilarities. BDDs make is possible to represent these large sets compactly. <stmt> mayCflow(Shadow sh) \n{ <stmt> mayCflow = stmtsWithin(sh); <stmt> old; do { old = mayCflow; <method> targets = mayCflow{stmt} \n<> callTargets{stmt}; mayCflow |= targets{method} <> stmtsIn{method}; } while( mayCflow != old ); \n return mayCflow; } Figure 2. Jedd code implementing Algorithm 1 The set mustC.ow(st) is computed using \nAlgorithm 2. It .rst accumulates the set shadowStmts of all statements within any up\u00addate shadow having \nno dynamic residue. Every such statement is necessarily in the c.ow. The algorithm then starts with all \nstate\u00adments in the program, and removes statements that can be reached from the entry points of the call \ngraph without passing through a statement that is necessarily in the c.ow. The statements to be re\u00admoved \nare computed by starting with the entry points, and adding statements of methods called from the set \ncomputed so far, but ex\u00adcluding statements in shadowStmts, until a .xed-point is reached. Computation \nof necessaryShadows(st) is shown in Algo\u00adrithm 3. We begin with all the query shadows, and remove those \nknown statically to be false. Unless the c.ow binds arguments, we can also remove those known statically \nto be true. This leaves us with the query shadows that will be tested dynamically. The neces\u00adsary shadows \nare now those update shadows in whose mayC.ow any dynamic query shadow appears. Unless the c.ow binds \nargu\u00adments, we can also remove those update shadows which are already in the mustC.ow of another update \nshadow.  4.3 Empirical Results The c.ow optimisations we present in this paper have been empir\u00adically \nvalidated in two different AspectJ compilers. First, we have Algorithm 2 compute mustC.ow(st) shadowStmts \n.{sh | sh updates st and has no dynamic residue} mustC.ow . set of all statements targets . set of entry \npoints of call graph repeat targetStmts . {i |.m . targets . i is a statement in m}\\ shadowStmts mustC.ow \n. mustC.ow \\ targetStmts targets .{m |.i . targetStmts . i may call m} until mustC.ow does not change \nAlgorithm 3 compute necessaryShadows(st) queries . set of all query shadows on st n {mayC.ow(sh) | sh \nupdates st} if c.ow does not bind arguments then queries . queries \\ mustC.ow(st) end if necessaryShadows \n.{sh |.i . queries . i . mayC.ow(sh)} if c.ow does not bind arguments then necessaryShadows . necessaryShadows \n\\ mustC.ow(st) end if implemented all the optimisations in our abc compiler. Second, we suggested them \nto the ajc team, and they have implemented coun\u00adters (Section 4.1.2) and sharing (Section 4.1.1) in ajc \n1.2.1. 4.3.1 Benchmarks We tested the c.ow optimisations on benchmarks from a wide range of sources. \nWe list the benchmarks and their sizes (non\u00adcomment SLOC) in the .rst column of Table 2. Figure is a \ndemo from the AspectJ documentation. Quicksort is the exam\u00adple from [20] with modi.cations suggested \nby Gregor Kiczales. Sablecc is a compiler written using the SableCC compiler genera\u00adtor, with an aspect \napplied to count memory allocations in each of its phases. The base programs ants, certrevsim(sim) and \nweka were introduced in Section 3.4. Law of Demeter [16] is a style-checking aspect that we have applied \nto two code bases: Certrevsim and weka. Cona [21] is a framework for specifying and checking pre\u00adand \npost-conditions using aspects. We applied it to the stack exam\u00adple mentioned in the paper, and to the \nsimulator. 4.3.2 Intraprocedural optimisations No opt. Intra-proc Benchmark SLOC Stacks Stacks Counters \n.gure 94 5 0 1 quicksort 72 2 0 1 sablecc 31233 2 0 2 ants 939 1 1 0 LoD-sim 1586 13 0 1 LoD-weka 3912 \n13 0 1 Cona-stack 291 10 0 1 Cona-sim 1942 46 0 8 Table 2. Static intra-procedural optimisation counts \nIn Table 2, we present the static effects of our intra-procedural optimisations implemented in abc. The \ncolumn labelled No opt. Stacks shows the number of different stacks before our optimi\u00adsations; the Intra-proc \ncolumn shows the number of stacks and counters after intra-procedural optimisations have been applied. \nIn Benchmark abc ajc no-opt sharing sharing+ counters sharing+ counters+ reuse +inter-proc 1.2 1.2.1 \n(no-opt) (sharing+ counters) .gure quicksort sablecc ants LoD-sim LoD-weka Cona-stack Cona-sim 1072.2 \n122.3 29.0 18.7 1723.9 1348.7 592.8 75.8 238.3 75.1 29.1 18.8 46.6 142.5 80.1 75.3 90.3 27.9 22.8 18.7 \n32.8 91.9 41.2 73.8 20.3 27.4 22.5 17.9 26.2 75.2 27.4 72.0 1.96 27.3 20.4 13.1 23.7 66.3 23.1 73.6 450.5 \n167.7 123.5 28.9 29.7 24.2 33.0 32.9 4776.2 35.3 2349.2 113.5 1107.4 56.0 76.8 69.0 Table 3. Benchmark \nrunning times (seconds) most cases, sharing reduces the number of c.ow stacks (or coun\u00adters) signi.cantly, \noften down to one. In all benchmarks except ants, all c.ow stacks are replaced with counters. A counter \ncannot be used for ants because the c.ow pointcut binds a value. We present the benchmark running times \nin Table 3. The mid\u00addle section lists the running times of benchmarks compiled us\u00ading abc with c.ow optimisations \ndisabled (no-opt), with the intra\u00adprocedural optimisations: sharing (Section 4.1.1), counters (Sec\u00adtion \n4.1.2) and reuse (Section 4.1.3). The rightmost section lists running times when the benchmarks are compiled \nwith ajc ver\u00adsions 1.2 and 1.2.1. Between these two releases, two of the intra\u00adprocedural optimisations \npresented in this paper, sharing (Sec\u00adtion 4.1.1) and counters (Section 4.1.2), were added to ajc in \nre\u00adsponse to our suggestions. Using the abc compiler, the speedups due to our intra-procedural optimisations \nare very signi.cant (up to 54-fold) not only for small benchmarks (e.g. .gure, quicksort), but also for \nlarge benchmarks which use c.ow (e.g. the LoD benchmarks). We observe similar speedups with the ajc compiler \nbetween version 1.2 and 1.2.1, in which intra-procedural c.ow optimisations were added.  4.3.3 Interprocedural \noptimisations Static results of our inter-procedural c.ow analysis are shown in Table 4. The query shadows \ncolumn shows, for each c.ow point\u00adcut designator (corresponding to a stack or counter), the total num\u00adber \nof query shadows and, of those, how many the analysis deter\u00admined to be unreachable, how many are determined \nto never or always match, and how many cannot be determined statically and therefore still require a \ndynamic test. The update shadows col\u00adumn shows the total number of update shadows and the number that \nthe analysis determines to be necessary, and must remain as dynamic updates even after the analysis. \nWith the exception of one c.ow pointcut designator in sablecc, the analysis was able to statically determine \nthe outcome of all c.ow queries, and therefore entirely remove the dynamic updates and queries of the \nc.ow stacks or counters. The imprecision in the sablecc case is due to query shadows in a static initialiser; \nto deal with this case, we are developing a simple analysis to reduce the number of spurious static initialiser \nedges in our call graph. Even though the c.ow pointcut in ants binds an argument, we can eliminate it \nbecause it is never queried. This is because the pointcut is being used as an assertion to .nd an error \ncondition. By determining that the c.ow never matches, we have statically veri\u00ad.ed the assertion. The \nsuccess of the static analysis inspired us to begin experimenting with AspectJ extensions to allow dynamic \npointcuts such as c.ow in static declare error constructs. This provides a way for a programmer to specify \nproperties of the pro\u00adgram to be checked. When the analysis cannot prove the properties at compile time, \na warning is issued and a run-time check inserted. Benchmark Query shadows Update shs. Total Unreach. \nNever Always Dynamic Total Dynamic .gure 6 024 06 0 quicksort 6 02 4 03 0 sablecc 985 388 299 298 0 698 \n0 985 388 332 260 5 1 1 ants 84 084 0 01 0 LoD-sim 1313 798 515 0 0 41 0 LoD-weka 7031 3501 3530 0 0 \n41 0 Cona-stack 16 0 14 2 0 27 0 Cona-sim 2 02 0 02 0 3 300 018 0 4 310 031 0 0 000 02 0 7 520 020 0 \n0 000 06 0 4 040 05 0 0 000 03 0 Table 4. Static inter-procedural optimisation counts We were pleasantly \nsurprised that the inter-procedural analysis was so effective in resolving c.ow statically. To ensure \nthat these analysis results are indeed correct, we ran all the benchmarks with a special dynamic residue \nwoven in to check that the static analysis results always agreed with the run-time behaviour. The performance \nimprovements due to the removal of update shadows, query shadows, and the code of unreachable advice \nare shown in the abc inter-proc column of Table 3. On benchmarks making signi.cant use of c.ow, both \nsmall (e.g. .gure) and large (e.g. LoD), these optimisations provide large speedups, even on top of the \nalready large speedups from the intra-procedural optimisa\u00adtions and the use of cheap c.ow counters. Furthermore, \nwhen the c.ow binds an argument, the cheap counters cannot be used, so the inter-procedural optimisations \nenable the removal of expensive c.ow stacks, resulting in a 1.4-fold speedup in ants. Recall our earlier \ndecision to use a subset-based points-to anal\u00adysis to compute possible run-time receiver types in the \ncall graph construction. If instead we use a less precise call graph, the im\u00adprecision also affects the \nresults of our c.ow analysis. In particu\u00adlar, in the sablecc benchmark, the number of update shadows \nopti\u00admised stays the same, but the number of query shadows optimised changes. For the stack where there \nare 5 unoptimised queries with the precise call graph, this number grows to 361 with CHA. Fur\u00adthermore, \nas we remarked earlier, the extra time spent to create a precise call graph signi.cantly reduces the \ntime for the c.ow anal\u00adysis. Our implementations are however not yet tuned for compile\u00adtime performance, \nso we defer a detailed study of these issues to further work.  5. OTHER OPTIMISATIONS In addition to \naround and c.ow optimisations detailed in the pre\u00advious two sections, abc also implements numerous other \nsmall op\u00adtimisations which can also improve the performance of the woven code. Other optimisations fall \ninto three categories: (1) optimising re.ective access to join points; (2) reducing the amount of box\u00ading/unboxing; \nand (3) cleaning up the woven code using standard Soot optimisations. We discuss each of these categories \nin more detail below. 5.1 Optimising Re.ective Access to Joinpoints AspectJ supports re.ective access \nto information about join points via thisJoinPoint. The information available consists of static infor\u00admation, \nsuch as the kind of the join point and the source location, and dynamic information such as the current \nvalues of args, target and this. For each join point shadow, the static part is computed once, and stored \nin a static .nal .eld, when the class containing the shadows is .rst initialised. Thus, it has quite \nlow overhead. On the other hand, the dynamic part is much more expensive since the information is speci.c \nthe particular execution of a join point, and thus a join point object is created each time the join \npoint executes. Since it is very common for advice to only access the static part of the thisJoinPoint \nobject, the AspectJ language has a special vari\u00adable thisJoinPointStaticPart which provides only the \nstatic infor\u00admation and programmers are encouraged to use this variation when they only need the static \ninformation. Of course, it would also be nice if the compiler could automat\u00adically detect those cases \nwhen only the static part is needed and thus free the programmer from explicitly having to use thisJoint-PointStaticPart. \nIndeed, ajc already implements the lazy creation of the dynamic part and abc implements a similar strategy. \nIn par\u00adticular, abc performs a simple, conservative intraprocedural anal\u00adysis to determine whether the \ndynamic part is needed, and if not, it replaces the use of thisJoinPoint by thisJoinPointStaticPart. \nIn cases where we do need to keep the dynamic version, it is initialised lazily. In particular it is \nnot constructed prior to the dynamic point\u00adcut matching, as such construction might turn out to be in \nvain if the pointcut fails to match. We have plans to further improve upon our optimisations. Cur\u00adrently \nthere is only one type of join point object, so one must create the whole object, even if only one part \nof the dynamic context is needed. We would like to be able to specialise the join point objects based \non which parts are used. Secondly, we would like to examine the impact of interprocedural analyses to \nmore accurately deter\u00admine when the dynamic part is used and which parts are needed. 5.2 Reducing boxing/unboxing \nAt various points in an AspectJ implementation, context informa\u00adtion must be passed, and ajc often does \nso by passing Object arrays, and using boxing and unboxing as appropriate to retrieve the rele\u00advant context \ninformation. abc, by contrast, exercises a lot of care to avoid unnecessary heap allocations and boxing \noperations. A particular example concerns the context passing for around advice, and this was discussed \nin detail in Section 3.3.2. An\u00adother example occurs with the parameters of intertype constructors (where \nan aspect injects a new constructor into an existing class). ajc wraps all such arguments into a single \nObject array, but abc avoids boxing arguments of primitive types, at the expense of a slightly more complex \ncode generator. As a .nal example, prim\u00aditively typed values are sometimes boxed for passing to advice \nmethods to allow the same advice method to be used polymorphi\u00adcally. After inlining, the boxing and unboxing \noperations can often be removed from each join point shadow. 5.3 Standard Soot Optimisations Unlike \najc, which does not contain an optimising backend, in abc we can take full advantage of Soot to apply \nstandard compiler op\u00adtimisations after all weaving has taken place. This is bene.cial be\u00adcause we can \nproduce woven code which introduces spurious in\u00adstructions such as nops, copy statements or redundant \nbranches, and let the standard Soot analyses eliminate those extra instructions. One example of how this \nsimpli.es our compiler is that we introduce extra nop instructions to cleanly represent the beginning \nand ending of join point shadows. This technique works well since the nops we introduce have no control \n.ow entering them or leaving them and they serve as clean places on which to de.ne exception ranges. \nThus our weaver does not need to worry about patching up control .ow and exception ranges as we weave. \nThis allows the weaver to be quite compositional and extensible. After all weaving is complete the nops \nare removed using the standard Soot nop eliminator which automatically .xes up the control .ow and exception \nranges. One surprising result we found was that weaving aspects can generate a large number of new local \nvariables and performing Soot s register-allocation-type packing of these variables at the Jimple level \nresulted in signi.cant speedups on some popular JITs. Finally, we also apply standard Soot optimisations \nduring spe\u00adcialised passes like the around inliner. These are used to remove useless parameters, remove \nunused methods, simplify switches and eliminate useless casts.  6. RELATED WORK This work is the .rst \ngeneral study of analysis and optimisation strategies for aspect-oriented languages in general, and for \nAspectJ in particular. As a consequence, the amount of related work is rather sparse. There are however \na number of other industrial strength implementations of aspect-orientation, and we discuss these here. \nThe ajc Compiler The reference implementation of AspectJ (and in fact the only other implementation of \nthe language) is the ajc compiler. The weaving strategies of ajc and abc are similar, except for the \noptimisations described in this paper. Following the early success of our optimisations in abc, two of \nthem (c.ow counters and sharing of c.ow stacks) have been incorporated into ajc 1.2.1. Further details \non the implementation of weaving in ajc (similar to weaving in abc except for the optimisations described \nhere) can be found in [11]. Other AOP Systems There are a number of other systems besides AspectJ that \nsupport the use of aspects. Perhaps the most successful of these is AspectWerkz [8]; its features are \nin fact very similar to those of AspectJ.3 Aspects are however deployed using annotations or scripts, \nrather than in an extension of the Java language. Unlike AspectJ, AspectWerkz supports dynamic weaving: \nenabling new aspects at runtime, and also disabling them: The AspectWerkz system may however also be \nused in off-line mode, in the same way as ajc or abc. Because of its focus on run\u00adtime weaving, AspectWerkz \nemploys an event-based implementa\u00adtion of join points, where advice can register as a listener. In pre\u00adliminary \nexperiments, we have found this strategy leads to a slow\u00addown of a factor of 9 or more compared to ajc \nor abc. Because of this huge gap and the different aims of dynamic weaving, we fo\u00adcused on the most popular \nstatic weaving system, which is ajc. The 3 Indeed, since January 2005, the ajc and AspectWerkz projects \nhave merged the discussion here refers to AspectWerkz 1.0. other leading AOP system is JBoss [12], and \nthis employs a simi\u00adlar implementation strategy to AspectWerkz. It is evident that both these systems \ncould bene.t by the optimisations presented here, when used in off-line mode. For weaving at runtime, \nit would ap\u00adpear that our intraprocedural optimisations may be helpful. The same applies to efforts to \nsupport aspects in a modi.ed JVM, as in [7]. 7. CONCLUSIONS The .eld of optimising compilers for AOP \nlanguages is just start\u00ading, but we believe that this area will provide many interesting problems and \nchallenges that can be met with both existing and new compiler optimisation technology. In this paper \nwe have presented three main contributions to the .eld in the context of a new optimising compiler for \nAspectJ, abc. We have designed and implemented a new strategy for weaving around advice which aims to \navoid both the code size explosion of a pure inlining approach and the time and space overhead of an \nexplicit closure-based approach. Our experimental results demon\u00adstrate that this technique works very \nwell, it is much more ef.cient than the closure-based approach, and produces much less code than the \ninlining-based approach. Our second major contribution was to show how to reduce or eliminate the large \noverheads associated with c.ow. We gave some intra-procedural techniques that are both relatively simple \nand very effective at reducing large overheads for the common case. These optimisations have already \nbeen adopted by the implementors of the ajc compiler. We then showed that we can go even further by applying \ninter-procedural analyses that can statically approximate dynamic c.ow properties. Our experimental results \nshow that in many cases we can completely eliminate the c.ow overhead. Finally, the implementation strategies \npresented here show\u00adcase a novel methodology for de.ning new program analyses and ef.ciency-improving \nprogram transformations for aspect-oriented languages. In particular, the interprocedural c.ow analysis \nshows that reweaving is a useful technique. In reweaving, aspects are wo\u00adven .rst naively into the base \nprogram, the resulting program is analysed and the results of the analysis are used to guide subse\u00adquent \nweaving phases (so that better code can be produced). In general, reweaving can be iterated multiple \ntimes. The abc com\u00adpiler was designed speci.cally to support reweaving and thus can serve as a workbench \nfor developing new optimising transforma\u00adtions of AspectJ.  References [1] abc. The AspectBench Compiler. \nHome page with downloads, FAQ, documentation, support mailing lists, and bug database. http://aspectbench.org. \n \u00b0 [2] Andr\u00b4e Arnes. PKI certi.cate revocation. Available at http: //www.pvv.ntnu.no/ andrearn/certrev/. \n [3] R. Dale Asberry. Aspect Oriented Programming (AOP): Using AspectJ to implement and enforce coding \nstandards. http://www. daleasberry.com/newsletters/200210/20021002. shtml, 2002.  [4] AspectJ Eclipse \nHome. The AspectJ home page. http://eclipse.org/aspectj/, 2003. [5] Pavel Avgustinov, Aske Simon Christensen, \nLaurie Hendren, Sascha Kuzins, Jennifer Lhot\u00b4ak, Ond.rej Lhot\u00b4ak, Damien Sereni, Ganesh Sittampalam, \nand Julian Tibble. abc: An extensible AspectJ compiler. In AOSD 2005, pages 87 98, March 2005. [6] David \nF. Bacon and Peter F. Sweeney. Fast static analysis of C++ virtual function calls. In OOPSLA 1996, pages \n324 341, 1996. [7] Christoph Bockisch, Michael Haupt, Mira Mezini, and Klaus Ostermann. Virtual machine \nsupport for dynamic join points. In AOSD 2004, pages 83 92, 2004. [8] Jonas Bon\u00b4er. AspectWerkz dynamic \nAOP for Java. Available from URL: http://codehaus.org/ jboner/papers/ aosd2004_aspectwerkz.pdf, 2004. \n[9] Jeffrey Dean, David Grove, and Craig Chambers. Optimization of object-oriented programs using static \nclass hierarchy analysis. In ECOOP 1995, volume 952 of LNCS, pages 77 101, 1995. [10] Bruno Dufour, Christopher \nGoard, Laurie Hendren, Oege de Moor, Ganesh Sittampalam, and Clark Verbrugge. Measuring the dynamic behaviour \nof aspectj programs. In OOPSLA 2004, pages 150 169. ACM Press, 2004. [11] Erik Hilsdale and Jim Hugunin. \nAdvice weaving in AspectJ. In K. Lieberherr, editor, AOSD 2004, pages 26 35. ACM Press, 2004. [12] JBoss. \nJBoss Aspect Oriented Programming. Home page with down\u00adloads, documentation, wiki. http://www.jboss.org/index. \nhtml?module=html&#38;op=userdisplay&#38;id=developer% s/projects/jboss/aop. [13] Ond.rej Lhot\u00b4ak. Spark: \nA .exible points-to analysis framework for Java. Master s thesis, McGill University, December 2002. [14] \nOnd.rej Lhot\u00b4ak and Laurie Hendren. Scaling Java points-to analysis using Spark. In G. Hedin, editor, \nCC 2003, volume 2622 of LNCS, pages 153 169. Springer, April 2003. [15] Ond.rej Lhot\u00b4ak and Laurie Hendren. \nJedd: a BDD-based relational extension of Java. In PLDI 2004, pages 158 169, 2004. [16] Karl Lieberherr, \nDavid H. Lorenz, and Pengcheng Wu. A case for statically executable advice: checking the Law of Demeter \nwith AspectJ. In AOSD 2003, pages 40 49. ACM Press, 2003. [17] Tim Lindholm and Frank Yellin. The Java \nVirtual Machine Speci.cation. Addison-Wesley, second edition, 1999. [18] Hidehiko Masuhara, Gregor Kiczales, \nand Chris Dutchyn. A compilation and optimization model for aspect-oriented programs. In CC 2003, volume \n2622 of Springer Lecture Notes in Computer Science, pages 46 60, 2003. [19] Martin Rinard, Alexandru \nSalcianu, and Suhabe Bugrara. A classi.cation system and analysis for aspect-oriented programs. In Proceedings \nof the Twelfth International Symposium on the Foundations of Software Engineering, pages 147 158, 2004. \n[20] Damien Sereni and Oege de Moor. Static analysis of aspects. In AOSD 2003, pages 30 39, 2003. [21] \nTherapon Skotiniotis and David H. Lorenz. Cona: aspects for contracts and contracts for aspects. In OOPSLA \n2004 Companion, pages 196 197, 2004. [22] Vijay Sundaresan, Laurie Hendren, Chrislain Raza.mahefa, Raja \nVall\u00b4ee-Rai, Patrick Lam, Etienne Gagnon, and Charles Godin. Practical virtual method call resolution \nfor Java. In OOPSLA 2000, pages 264 280, 2000. [23] Frank Tip and Jens Palsberg. Scalable propagation-based \ncall graph construction algorithms. In OOPSLA 2000, pages 281 293, 2000. [24] Raja Vall\u00b4ee-Rai, Etienne \nGagnon, Laurie J. Hendren, Patrick Lam, Patrice Pominville, and Vijay Sundaresan. Optimizing Java bytecode \nusing the Soot framework: Is it feasible? In CC 2000, pages 18 34, 2000. [25] Ian H. Witten and Eibe \nFrank. Data Mining: Practical Machine Learning Tools and Techniques with Java implementations. Morgan \nKaufmann Publishers, 2000. [26] Jianjun Zhao and Martin Rinard. System dependence graph construction \nfor aspect-oriented programs. Technical Report MIT\u00adLCS-TR-891, Laboratory for Computer Science, MIT, \n2003.  \n\t\t\t", "proc_id": "1065010", "abstract": "AspectJ, an aspect-oriented extension of Java, is becoming increasingly popular. However, not much work has been directed at optimising compilers for AspectJ. Optimising AOP languages provides many new and interesting challenges for compiler writers, and this paper identifies and addresses three such challenges.First, compiling <i>around</i> advice efficiently is particularly challenging. We provide a new code generation strategy for <i>around</i> advice, which (unlike previous implementations) both avoids the use of excessive inlining and the use of closures. We show it leads to more compact code, and can also improve run-time performance. Second, woven code sometimes includes run-time tests to determine whether advice should execute. One important case is the <i>cflow</i> pointcut which uses information about the dynamic calling context. Previous techniques for <i>cflow</i> were very costly in terms of both time and space. We present new techniques to minimise or eliminate the overhead of <i>cflow</i> using both intra- and inter-procedural analyses. Third, we have addressed the general problem of how to structure an optimising compiler so that traditional analyses can be easily adapted to the AOP setting.We have implemented all of the techniques in this paper in <i>abc</i>, our AspectBench Compiler for AspectJ, and we demonstrate significant speedups with empirical results. Some of our techniques have already been integrated into the production AspectJ compiler, <i>ajc</i> 1.2.1.", "authors": [{"name": "Pavel Avgustinov", "author_profile_id": "81100580373", "affiliation": "Oxford University, United Kingdom", "person_id": "PP14200390", "email_address": "", "orcid_id": ""}, {"name": "Aske Simon Christensen", "author_profile_id": "81100285072", "affiliation": "University of Aarhus, Denmark", "person_id": "P640977", "email_address": "", "orcid_id": ""}, {"name": "Laurie Hendren", "author_profile_id": "81100646110", "affiliation": "McGill University, Montreal, Canada", "person_id": "PP14221385", "email_address": "", "orcid_id": ""}, {"name": "Sascha Kuzins", "author_profile_id": "81100211594", "affiliation": "Oxford University, United Kingdom", "person_id": "P717763", "email_address": "", "orcid_id": ""}, {"name": "Jennifer Lhot&#225;k", "author_profile_id": "81100503297", "affiliation": "McGill University, Montreal, Canada", "person_id": "P728834", "email_address": "", "orcid_id": ""}, {"name": "Ond&#345;ej Lhot&#225;k", "author_profile_id": "81100503314", "affiliation": "McGill University, Montreal, Canada", "person_id": "P677803", "email_address": "", "orcid_id": ""}, {"name": "Oege de Moor", "author_profile_id": "81100198102", "affiliation": "Oxford University, United Kingdom", "person_id": "PP14078760", "email_address": "", "orcid_id": ""}, {"name": "Damien Sereni", "author_profile_id": "81100584039", "affiliation": "Oxford University, United Kingdom", "person_id": "P439237", "email_address": "", "orcid_id": ""}, {"name": "Ganesh Sittampalam", "author_profile_id": "81100259191", "affiliation": "Oxford University, United Kingdom", "person_id": "PP14098545", "email_address": "", "orcid_id": ""}, {"name": "Julian Tibble", "author_profile_id": "81100521744", "affiliation": "Oxford University, United Kingdom", "person_id": "PP39046745", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065026", "year": "2005", "article_id": "1065026", "conference": "PLDI", "title": "Optimising aspectJ", "url": "http://dl.acm.org/citation.cfm?id=1065026"}