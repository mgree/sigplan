{"article_publication_date": "06-12-2005", "fulltext": "\n Automatic Pool Allocation: Improving Performance by Controlling Data Structure Layout in the Heap Chris \nLattner Vikram Adve University of Illinois at Urbana-Champaign {lattner,vadve}@cs.uiuc.edu Abstract \nThis paper describes Automatic Pool Allocation, a transformation framework that segregates distinct instances \nof heap-based data structures into seperate memory pools and allows heuristics to be used to partially \ncontrol the internal layout of those data structures. The primary goal of this work is performance improvement, \nnot automatic memory management, and the paper makes several new contributions. The key contribution \nis a new compiler algorithm for partitioning heap objects in imperative programs based on a context-sensitive \npointer analysis, including a novel strategy for correct handling of indirect (and potentially unsafe) \nfunction calls. The transformation does not require type safe programs and works for the full generality \nof C and C++. Second, the paper describes several optimizations that exploit data structure partitioning \nto fur\u00adther improve program performance. Third, the paper evaluates how memory hierarchy behavior and \noverall program performance are impacted by the new transformations. Using a number of bench\u00admarks and \na few applications, we .nd that compilation times are extremely low, and overall running times for heap \nintensive pro\u00adgrams speed up by 10-25% in many cases, about 2x in two cases, and more than 10x in two \nsmall benchmarks. Overall, we believe this work provides a new framework for optimizing pointer inten\u00adsive \nprograms by segregating and controlling the layout of heap\u00adbased data structures. Categories and Subject \nDescriptors D.3.4 [Processors]: Compil\u00aders, Optimization, Memory management General Terms Algorithms, \nPerformance Keywords Recursive data structure, data layout, cache, static analysis, pool allocation \n1. Introduction One of the most important tasks for modern compilers and run\u00adtime systems is the management \nof memory usage in programs, including safety checking, optimization, and storage management. Unfortunately, \ncompilers have proved much more effective at an- Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 05, June 12 15, 2005, Chicago, Illinois, USA. Copyright 2005 \nACM 1-59593-056-6/05/0006...$5.00. alyzing and controlling memory access patterns for dense arrays than \nfor pointer-based data structures. A key difference between the two is that compilers have precise knowledge \nof the runtime layout of arrays in memory, whereas they have much less informa\u00adtion about complex data \nstructures allocated on the heap. In such (pointer-based) data structures, both the relative layout of \ndistinct data structures in memory (which affects working set sizes) and the relative layout of nodes \nwithin a single data structure (which affects memory traversal patterns) are dif.cult to predict. One \ndi\u00adrect consequence is that irregular memory traversal patterns often have worse performance, both because \nof poor spatial locality and because techniques like hardware stride prefetching are not effec\u00adtive. \nA potentially more far-reaching consequence of the lack of layout information is that many compiler techniques \n(e.g., software prefetching, data layout transformations, and safety analysis) are either less effective \nor not applicable to complex data structures. Despite the potential importance of data structure layouts, \ncom\u00adpiler transformations for pointer-intensive programs are performed primarily using pointer and dependence \nanalysis, and not by con\u00adtrolling and using information about the layout of pointer-based data structures. \nSeveral compiler techniques attempt to modify the layout of pointer-based data structures by giving hints \nor memory layout di\u00adrectives to a runtime library [12], memory allocator [9], or garbage collector [28, \n29]. None of these techniques attempt to extract in\u00adformation about or to control the relative layouts \nof objects within a data structure or of distinct data structures, nor can they be directly extended \nto do so. Reliable data layout information and control are necessary for data layout properties to be \nused as a basis for further compiler transformations. An alternative approach for segregating heap objects \nunder compiler control is the work on automatic region inference for ML [45, 44, 24] and more recently \nfor Java [14, 10]. These tech\u00adniques partition objects into heap regions based on lifetimes, with the \nprimary goal of providing automatic memory management with little or no garbage collection for type-safe \nlanguages. In contrast, our primary goal in this work is to improve program performance by segregating \nheap data structures and by enabling further layout\u00adbased optimizations on these data structures (in \nfact, we do not try to reclaim memory automatically, except in limited cases). Because of their different \ngoals, these techniques do not explore how to ex\u00adploit data structure partitioning to optimize memory \nhierarchy per\u00adformance and do not support non-type-safe languages like C and C++, which are important \nfor many performance-sensitive applica\u00adtions. These previous approaches are compared with our work in \nmore detail in Section 10. This paper describes Automatic Pool Allocation, a transforma\u00adtion framework \nfor arbitrary imperative programs that segregates distinct instances of pointer-based data structures \nin the heap into seperate memory pools, and allows different heuristics to be used to partially control \nthe internal layout of those data structures. For example, each distinct instance of a list, tree, or \ngraph identi.ed by the compiler would be allocated to a separate pool. The paper also describes several \nsimple optimizations that exploit the partitioning of data structures on the heap to further improve \nprogram perfor\u00admance. These optimizations are possible because Automatic Pool Allocation is a rigorous \ntransformation performed by the compiler. In other work, we have used Automatic Pool Allocation and its \nunderlying pointer analysis to develop other new, compiler tech\u00adniques operating at the macroscopic level, \ni.e., at the level of entire data structures (rather than individual pointers or objects). These include \ntechniques for pointer compression [35] and mem\u00adory safety without garbage collection [19]. These techniques \nare very brie.y summarized in Section 7. The goal of this paper is to describe and evaluate the pool \nallocation transformation itself and simple optimizations directly based on it. More speci.cally, Automatic \nPool Allocation takes a context\u00adsensitive, .eld-sensitive points-to graph representation and parti\u00adtions \nthe heap so that objects represented by the same points-to graph node are allocated in a common pool1. \nBy using a context\u00adsensitive analysis with heap cloning, distinct data structure in\u00adstances that are \ncreated and processed by the same functions can be segregated into different pools. The lifetime of each \npool is deter\u00admined by bounding the lifetime of pointers to objects in that pool. The end result of pool \nallocation is a partitioning of the runtime heap into pools, a transformed program that allocates and \nfrees memory from pools, and a mapping from each static pointer to the pool it points into. Based on \nthis information, subsequent optimiza\u00adtions and analyses may be applied to the program. The Automatic \nPool Allocation algorithm supports arbitrary C and C++ programs, including programs with function point\u00aders \nand/or virtual functions, recursion, varargs functions, non-type\u00adsafe memory accesses (e.g., via pointer \ncasts and unions), setjmp/\u00adlongjmp, and exceptions. One of the key strengths of the algorithm is a simple \nstrategy for correctly handling indirect calls, which is dif.cult because different functions called \nvia a function pointer may have different allocation and deallocation behavior and be\u00adcause (in C or \nC++) may even have different signatures. The al\u00adgorithm solves these complex issues via a relatively \nsimple graph transformation phase, while keeping the code transformation pro\u00adcess essentially unchanged. \nThe transformation works correctly for incomplete programs, by only pool allocating memory that does \nnot escape the scope of analysis. Automatic Pool Allocation can directly improve program per\u00adformance \nin several ways. First, since programs typically traverse and process only one or a few data structures \nat a time, segregating logical data structures reduces the memory working sets of pro\u00adgrams, potentially \nimproving both cache and TLB performance. Second, in certain cases, the allocation order within each \ndata struc\u00adture pool will match the subsequent traversal order (e.g., if a tree is created and then processed \nin preorder), improving spatial local\u00adity. Intuitively, both bene.ts arise because the layout of individual \ndata structures is unaffected by intervening allocations for other data structures, and less likely to \nbe scattered around in the heap. Third, in some cases, the traversal order may even become a simple linear \nstride, allowing more effective hardware prefetching than be\u00adfore. Note that Automatic Pool Allocation \ncan also potentially hurt performance in two ways: by separating data that are frequently accessed together \nand by allocating nearly-empty pages to small 1 Less aggressive pointer analyses can also be used but \nmay not distinguish data structure instances or may give less precise information about their internal \nstructure. pools (some of the techniques described later are intended to ad\u00address these issues). This \npaper describes several optimizations based on pool alloca\u00adtion that further improve program performance. \nFirst, we show that in certain cases, individual free operations on objects in a pool can be eliminated \nand the entire memory for the pool reclaimed when the pool is destroyed (without increasing memory consump\u00adtion). \nSecond, we describe several customized memory manage\u00adment choices that can be used at run time for pools \nwith speci.c characteristics. The key to some of these optimizations is that dif\u00adferent logical data \nstructures tend to be used in different but well\u00adde.ned ways that can be exploited, whereas simply segregating \nby type, lifetime, or runtime pro.le information would not typically be suf.cient to apply all these \noptimizations. We evaluate the performance impact of Automatic Pool Alloca\u00adtion and the subsequent optimizations, \nusing heap-intensive bench\u00admarks from the SPEC, PtrDist [2], Olden [39] and FreeBench [40] benchmark \nsuites, and a few standalone applications. We .nd that many of these programs speed up by 10-25%, two \nby about 2x and two small benchmarks by more than 10x. Other programs are unaf\u00adfected, and importantly, \nnone are hurt signi.cantly by the transfor\u00admation. We also show that the total compile time for the transfor\u00admation \n(including the context-sensitive pointer analysis that com\u00adputes its input points-to graphs) is very \nsmall, requiring 1.25 sec\u00adonds or less for programs up to 100K lines of source code. Finally, the subsequent \noptimizations contribute improvements (over pool allocation alone) by 10-40% for eight cases and 0-10% \nfor the oth\u00aders. We also show that cache and/or TLB performance improves signi.cantly in all case with \nsigni.cant speedups, and in many cases hit rates are improved roughly similarly at all levels of the \nmemory hierarchy (L1 and L2 caches and TLB), indicating that the performance improvements are primarily \ndue to reduced working sets. Overall, this paper makes the following contributions: We propose a novel \napproach to improving performance of pointer intensive programs: segregating and controlling heap layout \nof pointer-based data structure instances and using fur\u00adther compiler optimizations that exploit this \nlayout information.  We present a new compiler algorithm for partitioning heap ob\u00adjects in C and C++ \nprograms that is based on a context-sensitive pointer analysis, including a novel and simple strategy \nfor cor\u00adrect handling of indirect function calls in arbitrary (including non-type-safe) programs.  We \npresent several simple but novel optimizations that opti\u00admize the performance of individual data structure \npools based on their speci.c patterns of memory deallocation or type infor\u00admation for pool contents. \nIn previous work [19, 35], we have demonstrated other uses of Automatic Pool Allocation as well.  We \npresent a detailed experimental evaluation of the perfor\u00admance impact of Automatic Pool Allocation, showing \nthat the transformation can signi.cantly improve memory hierarchy performance and overall running times \nof heap-intensive pro\u00adgrams, and that the transformation has very low compilation time in practice. \n Section 2 de.nes the assumptions we make about the points\u00adto graph input to the transformation. Section \n3 describes the main pool allocation transformation, and Section 4 describes several im\u00adportant re.nements. \nSections 5 and 6 de.ne a suite of simple pool optimizations and describe heuristics for pool collocation \n(respec\u00adtively). Section 7 describes the key properties provided by Auto\u00admatic Pool Allocation and two \nexample clients, Section 8 describes our implementation, and Section 9 contains our experimental eval\u00aduation \nof the transformation. Finally, Section 10 contrasts this work with prior work in the .eld and Section \n11 concludes the paper. struct list { list *Next ; int *Data ; }; struct list { list *Next ; int *Data \n; }; list * createnode ( int *Data ) { list * createnode (Pool *PD , int *Data ) { list *New = malloc \n( sizeof ( list )); list *New = poolalloc (PD, sizeof ( list )); New->Data = Data ; New->Data = Data \n; return New ; return New ; }} void splitclone ( list *L, list **R1, list **R2 ) { void splitclone (Pool \n*PD1 , Pool *PD2 , list *L, list **R1, list **R2 ) { if (L == 0) {*R1 = *R2 = 0; return ; } if (L == \n0) {*R1 = *R2 = 0; return ; } if ( some predicate (L->Data )) { if ( some predicate (L->Data )) { *R1 \n= createnode(L->Data ); *R1 = createnode(PD1, L->Data ); splitclone (L->Next , &#38;( *R1)->Next, R2); \nsplitclone(PD1, PD2, L->Next , &#38;( *R1)->Next , R2); } else {} else { *R2 = createnode(L->Data ); \n*R2 = createnode(PD2, L->Data ); splitclone (L->Next , R1, &#38;( *R2)->Next); splitclone(PD1, PD2, L->Next \n, R1, &#38;( *R2)->Next ); }}}}int processlist ( list * L) { int processlist ( list * L) {list *A, *B, \n*tmp; list *A, *B, *tmp ; Pool PD1 , PD2; poolcreate(&#38;PD1 , sizeof ( list ) , 8); // Clone L, splitting \nnodes in list A, and B. poolcreate(&#38;PD2 , sizeof ( list ) , 8); splitclone(L, &#38;A, &#38;B); splitclone(&#38;PD1, \n&#38;PD2, L, &#38;A, &#38;B); processPortion (A) ; // Process first list processPortion (A) ; // Process \nfirst list processPortion (B) ; // process second list processPortion (B) ; // process second list // \nfree A list // free A list : this loop is eventually eliminated while (A) { tmp =A->Next; free(A); A \n= tmp; } while (A) { tmp =A->Next; poolfree(&#38;PD1, A); A = tmp; } // free B list // free B list this \nloop is eventually eliminated while (B) { tmp =B->Next; free(B); B = tmp; } while (B) { tmp =B->Next; \npoolfree(&#38;PD2, B); B = tmp; }pooldestroy(&#38;PD1); pooldestroy(&#38;PD2); // destroy pools } } \n(a) Input C program manipulating linked lists (b) C code after the basic pool allocation transformation \nFigure 1. Example illustrating the Pool Allocation Transformation processlist copies a list into two \ndisjoint lists (based on some predicate), processes each, then frees them. After basic pool allocation, \nthe new lists are put in separate pools (PD1 and PD2) which are each contiguous in memory. After subsequent \noptimization, the calls to poolfree and the loops containing them are removed because pooldestroy frees \nall pool memory.     (a) DS Graph for createnode Figure 2. BU DSGraphs for functions in Figure \n1 (a) 2. Background: Points-To Graph &#38; Example In this section, we brie.y introduce the running \nexample used by this paper and specify the points-to graph representation and prop\u00aderties that are used \nby our description of Automatic Pool Allocation and its optimizations. Figure 1(a) shows the running \nexample we use to illustrate the pool allocation transformation. This program fragment traverses an input \nlist (L), creating two new lists (A and B) based on the input list, processes the new lists separately, \nand .nally deallocates them. Automatic Pool Allocation is driven by a points-to graph com\u00adputed by some \npointer analysis that uses an explicit representation of memory [27]. In our implementation, we use an \nalgorithm we call Data Structure Analysis (DSA) [32] to compute these points-to graphs. DSA is context-sensitive \n(both in its analysis and in that it distinguishes heap and stack objects by entire acyclic call paths), \nuni.cation-based, and .eld-sensitive, and we believe these prop\u00aderties are important for pool allocation \nfor the reasons explained below. We have shown that DSA is both extremely fast and scal\u00adable (it can \nanalyze programs of 220K lines of code like 176.gcc in under 2 seconds [32]), and requires a small fraction \nof the compi\u00adlation time taken by gcc -O3. Context-sensitive naming of heap objects by (acyclic) call \npaths is required to distinguish data structure instances that may be created, processed, or destroyed \nby calling common functions. For example, this property enables DSA to determine that lists Aand B are \ndisjoint in Figure 1(a) even though their nodes are allocated at a common allocation site, enabling pool \nallocation to assign them to distinct pools. With less or no context-sensitivity (e.g., if heap objects \nwere distinguished only by allocation site), such data struc\u00adtures would not be segregated into distinct \npools. A uni.cation-based pointer analysis [43] merges the potential targets of a pointer into a single \nset of objects , yielding a points\u00adto graph where every pointer variable or pointer .eld points to at \nmost one node. We use a uni.cation-based approach for two rea\u00adsons. First, as we argued in [32], it is \ncrucial to making DSA both extremely fast and scalable despite distinguishing memory objects by call \npaths. Second, it greatly simpli.es Automatic Pool Alloca\u00adtion because it ensures that every pointer \npoints to a unique node and hence a unique pool. Pool allocation without uni.cation would require a mechanism \n(e.g., fat pointers ) to track the pool pointed to by each pointer value at run time, which is signi.cantly \nmore complex and can hurt both performance and compatibility with ex\u00adternal libraries. Furthermore, there \nis some evidence that adding context-sensitivity substantially reduces the precision advantage of subset-based \nover uni.cation-based algorithms [36, 16, 32]. A .eld-sensitive pointer analysis distinguishes the targets \nof distinct pointer .elds within a record. This is important in prac\u00adtice for pool allocation with a \nuni.cation-based algorithm because merging the targets of unrelated pointer .elds in a node would lose \nmost of the internal structural information for multi-level pointer\u00adbased data structures. DSA is .eld-sensitive \nfor memory objects that are accessed in a type-consistent way, a property which it in\u00adfers during the \nanalysis. While we used DSA in our work, we know several other context-sensitive analyses [20, 37, 10, \n38] which provide all of the properties required by the transformation or could be extended to do so. \nWe describe the properties of the points-to graphs and other information required by the Automatic Pool \nAllocation transforma\u00adtion below. 2.1 Points-to Graph Assumptions This section describes the properties \nof the points-to graphs used by Automatic Pool Allocation, which we term Data Structure (or DS) Graphs. \nA DS graph is a compile-time description of the memory objects created by a function or program and their \npoints-to prop\u00aderties. We assume that a DS graph is computed for each function, representing the memory \nobjects reachable from variables in that function or from global variables. For reference, Figure 2 show \nthe graphs computed by DSA for the functions in the example. Formally, a DS Graph is a directed multi-graph, \nwhere the nodes and edges are de.ned as follows: DS Node: A DS node is a 5-tuple {t, F, M, A, G}. t is \nsome (program-de.ned) scalar, array, record or function type, or . rep\u00adresenting an unknown type. In \nthe transformation, . is treated like an unknown-size array of bytes (the A .ag, described below, is \nset to true when t = .). F is an array of .elds, one for each possible .eld of the type t . Scalar types \nand . have a single .eld, record types have a .eld for each element of the record, array types are treated \nas their element type (i.e. array indexing is ignored), and functions do not have .elds. M is a set of \nmemory classes, writ\u00adten as a subset of {H, S, G, U}, indicating Heap, Stack, Global and Unknown memory \nobjects respectively (multiple .ags can be set on one node due to the use of uni.cation). A node with \nU . M is assigned type .. Finally, if G . M, then G is a non-empty set of global variables and functions \nincluded in the objects for this node; otherwise, G is empty. A is a boolean that is true if the node \nin\u00adcludes an array object. Finally, though this paper does not use the information, DSA also infers Mod \nand Ref information, which are shown as M and R in the .gures. DS Edge: A DS edge is a 4-tuple {s, fs,t,ft}. \ns and t are DS nodes, while fs and ft are .elds of s and t respectively. Thus, the graph provides a .eld-sensitive \nrepresentation of points\u00adto information. A .eld of a node may lack an outgoing DS edge only if the .eld \nis known not to contain a pointer type, e.g., if the node represents a function (the function itself \ndoesn t point to anything else), is a .oating point or small integer type, or if M = {U}. In this paper, \nwe use the notation N(ptr) to indicate the node which the scalar pointer ptr points to. Figure 2(b) shows \nthe DS graph computed by our compiler for function splitclone of the example. Note that each node of \ntype list has two .elds2. The cycles indicate recursive data structures. 2 The diagrams in this paper \nshow pointers to nodes in cases where the pointer targets the .rst .eld of the node, due to limitations \nof the graph layout tool we use. void poolcreate(Pool* PD, uint Size, uint Align) Initialize a pool descriptor. \nvoid pooldestroy(Pool* PD) Release pool memory and destroy pool descriptor. void* poolalloc(Pool* PD, \nuint numBytes) Allocate an object of numBytes bytes. void poolfree (Pool* PD, void* ptr) Mark the object \npointed to by ptr as free. void* poolrealloc(Pool* PD, void* ptr, uint numBytes) Resize an object to \nnumBytes bytes. void poolinit bp(Pool *PD, uint Align) Initialize a bump-pointer pool descriptor. void \n*poolalloc bp(Pool *PD, uint NumBytes) Allocate memory from a bump-pointer pool. void pooldestroy bp(Pool \n*PD) Release a bump-pointer pool.  Figure 3. Interface to the Pool Allocator Runtime Library R1 and \nR2 point to distinct nodes, indicating that the two linked lists are completely disjoint. There are two \nother assumptions about DS graphs used in this work. First, we assume that the DS Graph for each function \nin\u00adcludes information about that function and all of the functions that it calls (but no information \nabout its callers). Section 3.3 explains why this assumption is safe. For example, a node with H . M \nindicates heap objects allocated or freed in the current function or its callees, but not its callers. \nSeveral context-sensitive analyses, in\u00adcluding DSA and others [37, 38], compute separate Bottom-Up (BU) \nand Top-Town (TD) graphs: the Bottom-Up graphs capture exactly the information required. For example, \nthe graph in Fig\u00adure 2(b) incorporates the points-to, mod/ref, and .ag effects of both calls to createnode \n: it includes two copies (one for each call) of the H .ag and the edge from the list node to the integer \ndata node present in Figure 2(a). Second, there are a few primitive operations on DS graphs used in the \ntransformation, including merging two graphs and matching nodes between graphs for a callee and a caller. \nThese are de.ned and explained where they are used in the next Section.  3. The Core Transformation \nThe pool allocation transformation operates on a program contain\u00ading calls to malloc and free, and transforms \nthe program to use a pool library, described below. The algorithm uses a points-to graph and call graph, \nboth of which are computed by DSA in our imple\u00admentation. The transformation is a framework which has \nseveral optional re.nements. In this section, we present a basic version of the transformation in which \nall heap objects are allocated in pools (i.e., none are allocated directly via malloc) and every node \nin the points-to graph generates a separate static pool (explained below). In the next section, we discuss \nre.nements to this basic approach. 3.1 Pool Allocator Runtime Library Figure 3 shows the interface to \nthe runtime library. Pools are iden\u00adti.ed by a pool descriptor of type Pool. The functions poolalloc, \npoolfree, and poolrealloc allocate, deallocate, and resize memory in a pool. The poolcreate function \ninitializes a pool descriptor for an empty pool, with an optional size hint (providing a fast path for \na commonly allocated size) and an alignment re\u00adquired for the pool (this defaults to 8, as in many standard \nmalloc libraries). pooldestroy releases all pool memory to the system heap. The last three functions \n(with suf.x bp ) are variants that use a fast bump pointer allocation method, described in Section 5. \nThe library internally obtains memory from the system heap in blocks of one or more pages at a time using \nmalloc (doubling the size each time). We implemented multiple allocation algorithms but the version used \nhere is a general free-list-based allocator with coalescing of adjacent free objects. It maintains a \nfour-byte header per object to record object size. The default alignment of objects (e.g., 4-or 8-byte) \ncan be chosen on a per-pool basis, for reasons described in Section 5. The pool library is general in \nthe sense that it does not require all allocations from a pool to be the same size.  3.2 Overview Using \nan Example The basic pool allocation transformation is illustrated for the ex\u00adample program in Figure \n1(b), which shows the results of our basic transformation in C syntax. The incoming list L and the two \nnew lists have each been allocated to distinct pools (the pool for L is not passed in and so not shown; \nthe new lists use pools PD1 and PD2). The list nodes for A and B will be segregated in the heap, unlike \nthe original program where they will be laid out in some unpre\u00addictable fashion (and possibly interleaved) \nin memory. The items in each pool are explicitly deallocated and the pools are destroyed within processList \nwhen the data they contain is no longer live. We can use this example to explain the basic steps of the \ntrans\u00adformation. The DS graphs are shown in Figure 2. First, we use each function s DS graph to determine \nwhich H nodes are accessible outside their respective functions, i.e., escape to the caller. The H nodes \nin createnode and splitclone do escape, because they are reachable from a returned pointer and a formal \nargument, re\u00adspectively. The two in processlist (A and B) do not. The latter are candidates for new pools \nin processlist. The transformation phase inserts code to create and destroy the pool descriptors for \nA (PD1) and B (PD2)in processlist (see Figure 1(b)). It adds pool descriptor arguments for every H node \nthat escapes its function, i.e., for nodes pointed to by R1 and R2 in splitclone and the node pointed \nto by New in createNode. It rewrites the calls to malloc and free with calls to poolalloc and poolfree, \npassing appropriate pool descriptors as arguments. Finally, it rewrites other calls to (e.g., the calls \nto splitclone and createnode) to pass any necessary pool descriptor pointers as arguments. At this point, \nthe basic transformation is complete. Further re.nements of the transformation move the pool\u00addestroy \nfor PD1 as early as possible within the function process\u00adlist, and then eliminate the calls to free items \nin the two lists (since these items will be released by pooldestroy before any new allocations from any \npool) and hence the loop enclosing those calls to free. The .nal resulting code (Figure 8) puts each \nlinked list into a separate pool on the heap, made the list objects of each list con\u00adtiguous in memory, \nand reclaims all the memory for each list at once instead of freeing items individually. In the example, \nthe list nodes are placed in dynamic allocation order within their pool. 3.3 Analysis: Finding Pool \nDescriptors for each H Node The analysis phase identi.es which pool descriptors must be avail\u00adable in \neach function, determines where they must be created and destroyed, and assigns pool descriptors to DS \nnodes. We use the term static pool to refer to a single poolcreate statement in the generated code. By \nde.nition, H . M for a node if the objects of that node are returned by malloc or passed into free by \nthe cur\u00adrent function or any of its callees, since we assume a Bottom-up DS graph (see Section 2.1). \nThese identify exactly those nodes for which a pool descriptor must be available in the current function. \nAutomatic Pool Allocation computes a map (pdmap) identify\u00ading the pool descriptor corresponding to each \nDS node with H . M. We initially restrict pdmap to be a one-to-one mapping from DS nodes to pool descriptor \nvariables; Section 6 extends pdmap to allow a many-to-one mapping. We must handle two cases: 1) the pool \nescapes the current function and 2) the pool lifetime is bound by the function. In the .rst case, we \nadd a pool descriptor argument to the function, in the second, we create a descriptor on the stack for \nthe function and call poolcreate/pooldestroy. These two cases are differentiated by the escapes property \nfor the DS node. The escapes property is determined by a simple escape anal\u00adysis on the bottom-up DS \ngraphs, implemented as a depth-.rst traversal. In particular, a node escapes iff 1) a pointer to the \nnode is returned by the function (e.g. createnode) 2) the node is pointed to by a formal argument (e.g. \nthe R1 node in splitclone) 3) the node is pointed to by global variable and the current function is not \nmain, or 4) (inductively) an escaping node points to the node. A subtle point is that any node that does \nnot escape a function will be unaffected by callers of the function, since the objects at such a node \nare not reachable (in fact, may not exist) before the current function is called or after it returns. \nThis explains why it is safe to use a BU graph for pool allocation: Even though the BU graph does not \nre.ect any aliases induced by callers, the non\u00adescaping nodes are correctly identi.able and all information \nabout them is complete, including their type t , incoming points-to edges, and .ags. In fact, in DSA, \nthe escapes property is explicitly com\u00adputed and all non-escaping nodes are marked using a C omplete \n.ag [32]. It can be computed easily using the above de.nition by any context-sensitive algorithm that \nhas similar points-to graphs. 3.3.1 The Basic Transformation Figure 4 shows the pseudocode for a basic \nversion of the Auto\u00admatic Pool Allocation transformation, which does not handle indi\u00adrect function calls. \nThe algorithm makes two passes over the func\u00adtions in the program in arbitrary order. The .rst (lines \n1 11) adds arguments to functions, creates local pool descriptors, and builds the pdmap. The second (lines \n12 20) rewrites the bodies of func\u00adtions using pdmap. basicpoolallocate(program P ) 1 .F .functions(P \n) 2 dsgraph G =DSGraphForFunction(F ) 3 .n .nodes(G) // Find pooldesc for heap nodes 4 if (H .n.M) 5 \nif (escapes(n)) // If node escapes fn 6 Pool* a = AddPoolDescArgument(F , n) 7 pdmap(n)= a // Remember \npooldesc 8 argnodes(F ) = argnodes(F ) .{n} 9 else // Node is local to fn 10 Pool* pd = AddInitAndDestroyLocalPool(F \n, n) 11 pdmap(n)= pd 12 .F .functions(P ) 13 .I .instructions(F ) // Rewrite function 14 if(I isa ptr \n= malloc(size) ) 15 replace I with poolalloc(pdmap(N(ptr)), size) 16 elseif(I isa free(ptr) ) 17 replace \nI with poolfree(pdmap(N(ptr)), ptr) 18 elseif(I isa call Callee(args) ) 19 .n .argnodes(Callee) 20 addCallArgument(pdmap(NodeInCaller(F, \nI,n))) Figure 4. Pseudo code for basic algorithm For each node that needs a pool in the function, the \nalgorithm either adds a pool descriptor argument (if the DS node escapes) or it allocates a pool descriptor \non the stack. Non-escaping pools are initialized (using poolcreate) on entry to the function and de\u00adstroyed \n(pooldestroy) at every exit of the function (these place\u00adment choices are improved in Section 4.2). Because \nthe DS node does not escape the function, we are guaranteed that any memory allocated from that pool \ncan never be accessed outside of the cur\u00adrent function, i.e., it is safe to destroy the pool, even if \nsome mem\u00adory was not deallocated by the original program. Note that this may actually eliminate some \nmemory leaks in the program! In the second pass (lines 12 20), the algorithm replaces calls to malloc() \nand free()3 with calls to poolalloc and poolfree. 3 Note that malloc wrappers (like calloc, operator \nnew, strdup, etc) do not need special support from the pool allocator. Their bodies are simply linked \ninto We pass the appropriate pool descriptor pointer using the pdmap information saved by the .rst pass. \nSince the DS node must have an H.ag, a pool descriptor is guaranteed to be available in the map. Calls \nto functions other than malloc or free must pass ad\u00additional pool descriptor arguments for memory that \nescapes from them. Because the BU Graph of the callee re.ects all accessed memory objects of all transitive \ncallees, any heap objects allocated by a callee will be represented by an Hnode in the caller graph (this \nis true even for recursive functions like splitclone). This prop\u00aderty guarantees that a caller will have \nall of the pool descriptors that any callee will ever need. A key primitive computable from DS graphs \nis a mapping, NodeInCaller(F, C, n). For a call instruction, C, in a function F ,if n is a DS node in \nany possible callee at that call site, then n . = NodeInCaller(F, C, n) identi.es the node in the DS \ngraph of F corresponding to node n due to side-effects of the call C (i.e., n . includes the memory objects \nof node n visible in F due to this call). The mapping is computed in a single linear-time traversal over \nmatching paths in the caller and callee graphs, starting from matching pairs of actual and formal nodes, \nmatching pairs of global variable nodes, and the return value nodes in the two graphs if any. If n escapes \nfrom the callee, then the matching node n . is guaranteed to exist in the caller s BU graph (due to the \nbottom-up inlining process used to construct the BU graphs), and is unique because the DS graphs are \nuni.cation-based [32]. Identifying which pool of the caller (F ) to pass for callee pool arguments at \ncall instruction I is now straightforward: for each callee node n that needs an argument pool descriptor, \nwe pass the pool descriptor for the node NodeInCaller(F, I, n) in the caller s DS graph. We record the \nset of nodes ( argnodes ) that must be passed into each function, in the .rst pass. Variable-argument \nfunctions do not need any special treatment in the transformation because of their representation in \nthe BU graphs computed by DSA. In particular, the DS graph nodes for all pointer-compatible arguments \npassed via the ... mechanism (i.e., received via va arg) are merged so that they are represented by a \nsingle DS node in the caller and callee. If the DS node pointed to by this argument node has H . M, a \nsingle pool argument is added to the function. At every call site of this function, the nodes for the \nactual argument (corresponding to the merged formals) will also have been merged, and the pool corresponding \nto this node will be found by NodeInCaller(F, I, n) and passed in as the pool argument. Note that explicit \narguments before the ... are not merged and can have distinct pools. 3.3.2 Passing Descriptors for Indirect \nFunctionCalls Indirect function calls make it much more complex to pass cor\u00adrect pool descriptor arguments \nto each function. There are multiple dif.culties. First, different functions called via a function pointer \nat the same call site may require different sets of pools. Figure 5 shows a simple example where func1 \nneeds no pools but func2 needs one pool, and both are called at the same site. Second, dif\u00adferent indirect \ncall sites can have different but overlapping sets of callees, e.g., {F1,F2} and {F2,F3} at two different \ncall sites. In order to avoid cloning F2 into two versions, we must pass the same pool arguments to all \nthree functions F1,F2 and F3. This raises a third major problem: because the call graph says that F3 \nis not a callee at the .rst call-site, its DS graph was never inlined into that of the caller at that \ncall-site. This means that the matching of nodes between caller and callee graphs, which is essential \nfor passing pool descriptors, may be unde.ned: NodeInCaller(F, C, n) may not exist for all escaping n. \nPrograms that violate the type signatures the program and treated as if they were a user function, getting \nnew pool descriptor arguments to indicate which pool to allocate from. int *func1 ( int *in ) {*in =1; \nreturn in ; } int *func2 ( int *in ) { free(in ); in =( int *) malloc ( sizeof ( int )); *in =2; return \nin ; } int caller ( int X) {int *( *fp )( int *)=(X > 1)? func1 : func2 ; int *p=( int *) malloc ( sizeof \n( int )); int *q= fp(p); return *q; } (a) Input C program with an indirect function call int *func1 ( \nPool *P, int *in ) {*in =1; return in ; } int *func2 ( Pool *P, int *in ) { poolfree(P, in); in =( int \n*) poolalloc (P , sizeof ( int )); *in =2; return in ; } int caller ( int X) {Pool PD1; poolcreate(&#38;PD1, \n...); int *( *fp )( int *)=(X > 1)? func1 : func2 ; int *p=( int *) poolalloc (PD1 , sizeof ( int )); \nint *q = fp(PD1, p); pooldestroy(&#38;PD1 ); return *q; } (b) C code after pool allocation   (c) Merged \nEBU Graph for (d): EBU Graph for caller func1 and func2 Figure 5. Example withfunction pointers Though \nfunc1 and func2 are called at the same call site, only one needs a pool descriptor. The algorithm puts \nthem in a single equivalence class, merges their DS graphs, adds a pool argument to both functions. of \nfunctions at call sites (not uncommon in C code) exacerbate all three problems because any attempt to \nmatch pool arguments ex\u00adplicitly for different callees must account for mismatches between the actual \nand formals for each possible callee. Our solution is composed of two key principles, described be\u00adlow, \nand shown in pseudocode in Figure 6. The .rst principle is to partition into equivalence classes so that \nall potentially callees at an indirect call site are in the same class. We then treat all functions in \nthe same equivalence class as potential callees for that call site. For example, func1 and func2 in the \nexample .gure are put into the same class, and so are F1,F2 and F3 in the example above. Lines 1-2 uses \nthe call graph to partition all the functions of the program into disjoint equivalence classes in this \nmanner. The second principle is to simplify matching nodes between dif\u00adferent callees at a call site \nwith the nodes of the caller by merging the graphs of all functions in an equivalence class, and then \nupdat\u00ading the caller graphs to be consistent with the merged callee graphs. Merging the graphs ensures \nthat an identical set of pool descriptor formal arguments will be inferred for all functions in the class. \nUp\u00addating the caller graphs to be consistent with the callee graphs (as explained below) ensures that \nthe third problem above .nding matching nodes between callee and caller is always possible. In the \nexample, the algorithm merges the DS graphs of func1 and func2 into the common graph shown in Figure \n5(c), and uses this common graph to transform both functions. This results in a matching set of pool \narguments for both functions, even though the pool will be unused in func1. This common graph is merged \ninto the caller, resulting in the graph shown in Figure 5(d). Using this graph, one descriptor is passed \nto both functions at the call site. The implementation of these graph merging and inlining steps (lines \n3-8 of Figure 6) use two primitive DSA operations merging two graphs and performing a bottom-up inlining \npass on strongly\u00adconnected components (SCCs) of the call graph. To merge the graphs of two functions \nin an equivalence class (lines 3-4), we copy one graph into the other, then unify corresponding formal \nargument nodes (ignoring any extra nodes in one of the graphs if the formal argument lists do not match), \nglobal nodes, and the return value node of each graph. Unifying nodes causes recursive merging and can \npotentially cause loss of some type information if merged nodes have incompatible types. Finally, we \nperform a bottom-up inlining pass on the strongly connected components (SCCs) of the call graph, inlining \nmerged graphs of the callees into their callers. This simply requires repeat\u00ading the bottom-up inlining \npass of the DSA algorithm (starting with the merged equivalence-class graphs of each function). This \nstep is described in detail in [32]. We call the resulting DS graphs the EBU ( equivalence bottom\u00adup \n) graphs. The EBU graph is more conservative than the original DS graph because functions known not to \nbe called at a call-site may be merged into the caller along with those that are (because they are in \nthe same equivalence class). Such cases do not arise often in practice, and the merging of equivalence \nclass graphs greatly simpli.es the overall transformation algorithm by solving the above three problems \nwith a uniform strategy based on existing DS graph primitives. completepoolallocate(program P ) 1 .cs \n. callsites(P ) // Build equivalence classes 2 unify equivclasses(callees(cs)) 3 .ec . equivclasses(functions(P \n)) // Build graph for each class 4 ECGraph(ec) = mergeGraphs(DSGraphs(members(ec))) 5 .scc . tarjanscc.nder(callgraph(P \n)) 6 ECGraph(scc) = mergeGraphs(ECGraphs(functions(scc))) 7 .cs . callsites(scc) // Inline callees into \ncaller 8 ECGraph(scc) = mergeGraph(cs, ECGraph(callees(cs))) 9 basicpoolallocate(P ) Figure 6. Pseudo \ncode for complete pool allocator Given the EBU graphs for a program, the pool allocator is now guaranteed \nto have all of the pool descriptors required at an indirect call site for any of the potential callees \nof the call site, allowing it to apply the basicpoolallocate algorithm safely. Note that lines 17-19 \nsimply have to use the common graph for all callees even though there may now be multiple callers for \nthe call at line 17. A detailed discussion of the complexity of the Automatic Pool Allocation algorithm \nis outside the scope of this work but is avail\u00adable in [32]. Brie.y, all parts of the algorithm with \nthe exception of lines 5-8 of Figure 6 are linear in the total size of all DS graphs and the number of \ninstructions in the program, and T(na(n)) in the number of call graph edges. The complexity of lines \n5 8, the EBU phase, is similar to the BU phase of DSA, i.e., T(na(n)+ka(k)c), if n, k and c denote the \ntotal number of instructions, the maximum size of a DS graph for a single procedure, and the number of \nedges in the call graph. In practice, k is very small, typically on the order of a hundred nodes or less, \neven for large programs [32].   4. Algorithm Re.nements and Implementation 4.1 Argument Passing for \nGlobal Pools A DS node reachable from a global variable requires a pool created in main because the heap \nobjects at that node may be live through\u00adout the lifetime of the program. This introduces a major source \nof runtime overhead because such a pool would have to passed down int processlist ( list * L) { list \n*A, * B, * tmp ; Pool PD1 , PD2 ; // initialize pools poolcreate(&#38;PD1, ...); poolcreate(&#38;PD2, \n...); splitclone(&#38;PD1, &#38;PD2, L, &#38;A, &#38;B); processPortion(A) ; // Process first list processPortion(B \n) ; // process second list while (A) { tmp=A->Next; poolfree(&#38;PD1, A); A=tmp; } pooldestroy(&#38;PD1 \n); // NOTE: this moved up while (B) { tmp=B->Next; poolfree(&#38;PD2, B); B=tmp; } pooldestroy(&#38;PD2 \n); // destroy pool PD2 } Figure 7. After moving pooldestroy(&#38;PD1) earlier int processlist ( list \n* L) {list *A, * B, * tmp ; Pool PD1 , PD2; poolcreate(&#38;PD1, ...); poolcreate(&#38;PD2, ...); splitclone(&#38;PD1, \n&#38;PD2, L, &#38;A, &#38;B); processPortion(A) ; // Process first list processPortion(B ) ; // process \nsecond list pooldestroy(&#38;PD1 ); // destroy pool ( including nodes ) pooldestroy(&#38;PD2 ); // destroy \npool ( including nodes ) } Figure 8. After eliminating poolfree calls and dead loops through many layers \nof function calls to be available in each func\u00adtion that actually allocates or frees data in the pool. \nIn practice, we have found that programs which have many heap nodes reachable from globals may get thousands \nof arguments added to the pro\u00adgram. The solution is simple: we create a global variable to hold the pool \ndescriptor for each heap node reachable from a global and use this where needed, instead of passing the \npool descriptor in via function arguments. In practice, this re.nement greatly reduces the number of \npool arguments that must be passed to functions in some C programs. Most importantly, it ensures that \nthe only pool arguments that must be passed to a function are for nodes reachable from pointers passed \nin as function arguments, making the number of pool arguments grow with the number of formal pointer \narguments in the original function. 4.2 poolcreate/pooldestroy Placement The algorithm described above \nplaces poolcreate/pooldestroy calls at the entry and exits of each function. In practice, the lifetime \nof the data objects in a pool may begin at a later point in the function and may end before the end of \nthe function. Moving the pool create/destroy calls later and earlier within the function reduces the \nlifetime of objects in the pool. This re.nement can also make it more likely that the re.nement in Section \n4.3 can apply. We modi.ed the basic algorithm so that it initially does not insert poolcreate / pooldestroy \ncalls but performs all other transformations. For each pool that must be created in a function, we use \ntwo simple depth-.rst traversals of the CFG to identify all basic blocks where the pool descriptor must \nbe live, based on its uses, and then place poolcreate/pooldestroy calls at edges entering or leaving \na live block from or to a non-live block. The overall algorithm is extremely simple and linear in the \nsize of CFG. Figure 7 illustrates this placement for the processlist func\u00adtion in our example. The call \nto pooldestroy(&#38;PD1) has been moved earlier in the function, to immediately after the while loop \nthat reads the Next .eld from nodes in PD1 pool. The poolcreate calls for both pools cannot be moved \nany later. In general, the poolcreate and pooldestroy calls can be moved interprocedurally to further \nreduce the lifetime of pools, similar to Aiken et al. s work [1]. However, that would likely require \na more expensive, .ow-sensitive interprocedural algo\u00adrithm [1] and we have not attempted this so far. \n 4.3 poolfree Elimination The .nal re.nement is to eliminate unnecessary poolfree calls. Many short-lived \ndata structures have a build-use-destroy pat\u00adtern, in which all allocations happen before any deallocations. \nFor example, consider Figure 7. Between the call to poolfree(&#38;PD1, A) and the call to pooldestroy(&#38;PD1), \nthere are no allocations out of any pool. This means that it is unnecessary to release the memory in \npool PD1 any earlier than the pooldestroy(&#38;PD1), when all the memory of the pool will be released \nback to the sys\u00adtem. We eliminate the call to poolfree(&#38;PD1, A), which also allows the compiler to \neliminate the enclosing loop (similarly for PD2). Effectively, we have performed a simple kind of static \ngarbage collection for the objects in this pool [31]. Note that mov\u00ading pooldestroy calls earlier in \nthe code can increase the oppor\u00adtunities for .nding candidate poolfree calls to eliminate. Again, we \nimplemented this optimization as a simple, backward data.ow analysis on the CFG, without interprocedural \ninformation. The analysis looks for any occurrence of poolfree(P) such that no path from the poolfree \nto the pooldestroy calls for P con\u00adtains any allocation out of any pool (including P ). The result for \nprocesslist is shown in Figure 8.  5. Pool Allocation Optimizations We describe four simple optimizations \nthat exploit the partitioning of heap objects and the differences in behavior of different pools. The \nbene.ts of all four optimizations are evaluated in Section 9. 1) Avoiding pool allocation for singleton \nobjects: Our sim\u00adplest optimization avoids pool-allocating nodes that appear to be used for a single \nobject. We identify such pools by .nding H nodes not pointed to by any other memory object (including \nitself), e.g. they are only pointed to by local scalar variables. This optimiza\u00adtion avoids creating \nand destroying a pool descriptor (minor) and avoids signi.cant wasted space when the object is much smaller \nthan the smallest internal page (potentially signi.cant when many such pools are created). We term this \nSelective PA . 2) Eliminating poolfree operations: The re.nement de\u00adscribed in Section 4.3 is an optimization \nthat can eliminate the .nal poolfree operations of a data structure, which we term Pool-FreeElim. In \nsome cases, this optimization can make entire data structure traversals dead, as in the example above. \nAs noted, this optimization is enhanced by smart pooldestroy positioning. Note that segregating data \nstructures into distinct pools is what enables this optimization to exploit the build-use-destroy pattern \nshown by (some) data structures. For example, if there were any allocations for the second list between \npooldestroy(&#38;PD1) and the second while loop, the optimization would not be possible without separating \nthe lists into distinct pools. 3) Bump-pointer allocation: If memory is never free d back to a pool, \nthere is no need for the pool library to maintain freelists or the 4-byte header on each object. The \nbump pointer optimization detects pools whose memory is only released by a pooldestroy, as explained \nbelow. It then changes the pool operations to use the bp versions of the pool routines for such pools. \nThis allocator has a shorter allocation path than the normal pool allocator and packs objects more densely \nin memory and cache (due to the missing object header). This optimization is clearly enhanced by the \npoolfree elimination optimization, which allows both pools in the example to be changed into bump pointer \npools. We implemented this as a simple post-pass over the program. Our implementation walks the use chain \nof each pool descriptor looking for any use that is not a poolcreate, pooldestroy,or poolalloc. If only \nthese uses occur, the pool is promoted to use a bump pointer by replacing the ordinary pool library calls \nwith the bp versions. Note that our implementation currently cannot promote any pools whose descriptors \nare passed into any other function, including user functions like those in the example. 4) Intelligent \nobject alignment: A traditional malloc library must be conservative about memory alignment because it \nlacks type information for the memory it allocates. Many architectures (e.g., Sparc V9) require that \ncertain 8-byte values (e.g., C doubles) must be 8-byte aligned, while others (e.g., x86) impose signi.cant \nper\u00adformance penalties if such values are misaligned. This forces many system malloc libraries to use \n8-byte alignment for all objects, in\u00adcreasing memory consumption and reducing cache density. For ex\u00adample, \ntwo successive 16 byte objects will be placed 24 bytes apart because 4 bytes are typically used as a \nmalloc object header, forc\u00ading an extra 4 bytes of padding per object for proper alignment. Because many \npools are type homogeneous, we have reliable compile-time information about data types in such pools. \nThere\u00adfore, we use 4-byte alignment when it is provably safe (i.e., a pool is type homogenous and no \n.eld of the object will be improperly aligned for the target architecture). Otherwise we use 8-byte align\u00adment. \nThe alignment is speci.ed when the pool is created. 6. Node Collocation Heuristics The pool allocation \nalgorithm so far provides a framework for segregating heap data structures but never collocates objects \nof two DS nodes into the same pool. We can adapt the algorithm to collocate a set of nodes by changing \nline 9 so that poolcreate and pooldestroy are inserted for only one of the nodes, and initializing pdmap \nto use the same descriptor for the other nodes. Since heap objects are laid out separately and dynamically \nwithin each pool, collocating objects can give the compiler some control over internal layout of data \nstructures. Even more so\u00adphisticated control might be possible using additional techniques (e.g., [9]) \ncustomized on each pool. We propose two example static options for choosing which H nodes should share \na common pool. We de.ne a Collection to be either a node with A = true, or any non-trivial strongly connected \ncomponent (i.e., containing at least one cycle) in the DS Graph. Given this, any H node reachable from \na Collection represents a set of objects that may be visited by a single traversal over the objects of \nthe Collection. OnePoolPerCollection: All candidate H nodes in a collection are assigned to a single \npool. Any other H node reachable from a collection (without going through another collection) is assigned \nto the same pool as the collection. This choice effectively partitions the heap so that each minimal \ntraversable collection of objects becomes a separate pool. Intuitively, this gives the .nest-grain par\u00adtitioning \nof recursive data structures, which are often hierarchical. It favors traversals over a single collection \nwithin such a hierarchi\u00adcal (i.e., multi-collection) data structure. MaximalDS: A maximal connected subgraph \nof the DS graph in which all nodes are H nodes are assigned to a single pool. This partition could be \nuseful as a default choice if there is no information about traversal orders within and across collections. \nOur implementation supports .exible colocation policies, but in practice we have found that using a static \ncollocation heuristics rarely outperform (and is often worse than) assigning each H node to a separate \npool (see [32] for a discussion). We expect that more sophisticated static analysis of traversal patterns \ncombined with pro.le data will be needed to statically choose the optimal colocation con.guration. We \nleave it to future work to develop an effective approach for pro.table collocation. The discussion above, \nshows, however that (a) collocation of pools can be implemented easily, and (b) qualitatively, the pointer \nanalysis and pool allocation provide a useful basis for per-data-structure choices. 7. Compiler Applications \nof Pool Allocation We believe that Automatic Pool Allocation combined with the un\u00adderlying pointer analysis \nprovides a new framework for analyzing and optimizing pointer-intensive programs, operating at the level \nof entire data structure instances, instead of individual load/store op\u00aderations or individual data types. \nThis is because Automatic Pool Allocation provides four fundamental bene.ts to subsequent com\u00adpiler passes: \n1. Data structure-speci.c policies via segregation: Allocating dis\u00adtinct data structures from different \npools allows compiler and run-time techniques to be customized for each instance. These techniques can \nuse both static pool properties (e.g., type in\u00adformation and points-to relationships) and dynamic properties \n(anything recordable in per-pool metadata). 2. Mapping of pointers to pool descriptors: The transformation \nprovides a static many-to-one mapping of heap pointers to pool descriptors. This information is key to \nmost transformations that exploit pool allocation because it enables the compiler to transform pointer \noperations into pool-speci.c code sequences. It is used by both the example applications described below. \n 3. Type-homogeneous pools: Many pools are completely type\u00adhomogeneous, as shown in Section 9, even C \nprograms. Novel compiler and run-time techniques are possible for type\u00adhomogeneous pools that would not \nbe possible on other pools or the general heap (e.g. the alignment optimization). 4. Knowledge of the \nrun-time points-to graph: One way to view pool allocation is that it partitions the heap to provide a \nrun\u00adtime representation of the points-to graph. The compiler has full information about which pools contain \npointers to other pools and, for type-homogeneous pools, where all the intra-pool and inter-pool pointers \nare located. Such information is useful any time pointers need to be traversed or rewritten at run-time. \n The optimizations described earlier show some simple exam\u00adples of how compiler techniques can exploit \nthese bene.ts. In other work, we developed two new compiler techniques that are much more sophisticated \nand exploit many or all of the above properties of pool allocation. We summarize these very brie.y here; \neach is described in detail elsewhere [19, 35]: Transparent Pointer Compression: After pool allocation, \nthe static mapping of pointers to pool descriptors allows us to use pool indices (i.e., byte offsets \nrelative to the pool base) instead of point\u00aders to identify objects in a pool. Since most individual \ndata struc\u00adtures are likely to have far less than 232 distinct nodes, segregating data structure instances \nallows us to represent these indexes with integers smaller than the pointer size (e.g., 32 bits on a \n64-bit host). In [35], we implement this transformation and show that it can have a signi.cant and sometimes \ndramatic impact on both the perfor\u00admance and the memory footprint of pointer-intenstive programs on 64-bit \nsystems. This transformation exploits the segregation of data structures into pools (which allows small \nindices), type homogene\u00adity (which allows compression of indices by rewriting structure ac\u00adcesses and \nallocations), and of course the mapping of pointers to pools (making the pool base implicit). We also \ndescribe a dynamic version of the algorithm where the pool runtime library dynamically rewrites nodes \nto grows pointers in data structures when the 232nd node is allocated. This allows us to speculatively \ncompress pointers to 32-bits while retaining the ability to dynamically expand them to 64-bits if full \naddressing generality is needed. Program Safety Without Garbage Collection: All the previous applications \nof pool allocation focus on improving performance. Another major application of pool allocation has been \nto enforce program safety while allowing explicit memory deallocation for C progams (the techniques for \na type-safe subset of C are described in [19] and a major extension to nearly arbitrary C is in progress). \nThis work exploits two key properties: pools in type-safe programs are type homogeneous, and the segregation \nof individual data struc\u00adtures into pools ensures that many pools are relatively short-lived. The type-homogeneity \nmeans that even with explicit deallocation, we can prevent dangling pointers into the pool from being \nable to cause unintended type violations. The short pool lifetimes ensure that memory consumption does \nnot increase signi.cantly. 8. Implementation We implemented Automatic Pool Allocation as a link-time \ntrans\u00adformation using the LLVM Compiler Infrastructure [34]. Perform\u00ading cross-module, interprocedural \ntechniques (like automatic pool allocation) at link-time has two advantages [3]: it preserves most of \nthe bene.ts of separate compilation (requiring few or no changes to Make.les for many applications), \nand it ensures that as much of the program is available for interprocedural optimization as possible. \nOur system compiles source programs into the LLVM repre\u00adsentation (for C and C++, we use a modi.ed version \nof the GCC front-end), applies standard intraprocedural optimizations to each module, links the LLVM \nobject .les into a single LLVM module, and then applies interprocedural optimizations. At this stage, \nwe .rst compute the complete Bottom-up DS graphs and then apply the Pool Allocation algorithm in Figure \n6. Finally, we run a few passes to clean up the resulting code, the most important of which are interprocedural \nconstant propagation (IPCP), to propagate null or global pool descriptors when these are passed as function \nar\u00adguments, and dead argument elimination (to remove pool pointer arguments made dead by IPCP). The resulting \ncode is compiled to either native or C code using one of the LLVM back-ends, and linked with any native \ncode libraries (i.e., those not available in LLVM form) for execution. Our implementation of Data Structure \nAnalysis and Automatic Pool Allocation are publicly available from the LLVM web site (http://llvm.cs.uiuc.edu/), \ntogether with the LLVM infras\u00adtructure, front-ends for C and C++, and most of the benchmarks used in \nthe experimental evaluation in Section 9.  9. Experimental Results We evaluated Automatic Pool Allocation \nexperimentally in order to study several issues: compilation time, overall performance impact of pool \nallocation, the contributions of the later optimizations it en\u00adables, and the effect on the performance \nof the memory hierarchy. For our experiments in this paper, we used the LLVM-to-C back-end and compiled \nthe resulting C code with GCC 3.4.2 at -O3. The experiments were run on an AMD Athlon MP 2100+ running \nFedora Core 1 Linux. This machine has exclusive 64KB L1 and 256KB L2 data caches. The C library on this \nsystem im\u00adplements malloc/free using a modi.ed Lea allocator, which is a high quality general purpose \nallocator. This allocator is used in all our experiments below, either directly from the application \nor the pool runtime library. All runtimes reported are the minimum user+system time from three executions \nof the program. For this work, we are most interested in heap intensive pro\u00adgrams, particularly those \nthat use recursive data structures. For this reason, we include numbers for the pointer-intensive SPECINT \n2000 benchmarks, the Ptrdist suite [2], the Olden suite [39], and the FreeBench suite [40]. We also include \na few standalone programs: Povray3.1 (a widely used open source ray tracer, available from povray.org), \nespresso, fpgrowth (a patent-protected, data min\u00ading algorithm [25]), llu-bench (a linked-list microbenchmark) \n[46], and chomp from the McGill benchmark suite. All but SPEC, fp\u00adgrowth and povray31 are available from \nllvm.cs.uiuc.edu. For lack of space, we elide many benchmarks from these suites that were unaffected \nby pool allocation. This happens for several reasons. Some of the benchmarks, including 181.mcf, 186.crafty, \n256.bzip2, and several FreeBench benchmarks, have very few dynamic memory allocations. A few (e.g. 197.parser, \n254.gap, 255.vortex) have custom memory allocators, which prevents dis\u00adambigution of allocated memory \nobjects and causes all objects to be placed in a single pool. As an experiment, we removed the cus\u00adtom \nmemory allocator from 197.parser and replaced it with wrap\u00adpers that just call malloc/free; this is called \n197.parser-b below. We can do this to 197.parser (but not the others) because its custom allocator has \nsemantics identical to malloc/free. Finally, almost all the codes in the McGill benchmark suite have \nrun times that are too small to be measured reliably. 9.1 Pool Allocation Statistics Table 1 shows several \nbasic statistics about pool allocation for each program. The StatPools column shows the number of static \npools created in the program (when using Selective PA). The NumTH column shows the static number of type \nhomogenous pools, and TH% is percentage of static pools that are type-homogenous. The DynPools column \nlists the number of dynamic pools created by the program. Tot Args and Max Args are the total number \nof formal arguments added to the program across all functions, and the maximum number for a single function. \n Program LOC Stat Num TH% Dyn Tot Max Pools TH Pools Args Args      164.gzip 8616 4 4 100% 44 1 \n1 175.vpr 17728 107 91 85% 44 23 4 197.parser-b 11204 49 48 98% 6674 76 16 252.eon 35819 124 123 99% \n66 549 41 300.twolf 20461 94 88 94% 227 1 1 anagram 650 4 3 75% 4 0 0 bc 7297 24 22 32% 19 6 2 ft 1803 \n3 3 100% 4 0 0 ks 782 3 3 100% 3 0 0 yacr2 3982 20 20 100% 83 0 0 analyzer 923 5 5 100% 8 0 0 neural \n785 5 5 100% 93 0 0 pcompress2 903 5 5 100% 8 0 0 llu-bench 191 1 1 100% 2 0 0 chomp 424 4 4 100% 7 10 \n8 fpgrowth 634 6 6 100% 3.4M 10 6 espresso 14959 160 160 100% 100K 191 13 povray31 108273 46 5 11% 14 \n290 4 bh 2090 1 0 0% 1 0 0 bisort 350 1 1 100% 1 1 1 em3d 682 12 12 100% 12 3 2 health 508 2 2 100% 2 \n4 2 mst 432 4 4 100% 4 0 0 perimeter 484 1 1 100% 1 1 1 power 622 3 3 100% 3 9 7 treeadd 245 6 6 100% \n6 1 1 tsp 579 1 1 100% 1 1 1 Table 1. Basic Pool Allocation Statistics The programs vary greatly in terms \nof the ratio of dynamic pool instances (Dyn Pools) to static pools (Stat Pools). fpgrowth has a particularly \nhigh ratio because it creates a new pool (for a local search tree) in each call to a recursive function. \nThe number of arguments added to the programs is generally modest. 252.eon has a large number of arguments \nadded because the standard C++ library is statically linked in, providing a large amount of cold code. \nThe Th% column also shows that for most pools, DSA is able to successfully prove that memory in the pool \nis used in a type\u00adconsistent manner, which we have found true across a wide range of C programs. This \nallows intelligent alignment decisions, gives the pool runtime information about expected size for single \nobjects,  and enables other novel compiler techniques described brie.y in Section 7. Program BP BP% \nPFE Program BP BP% PFE       164.gzip 1 25% 9 llu-bench 1 100% 0 175.vpr 27 25% 29 chomp 0 0% \n0 197.parser-b 3 6% 0 fpgrowth 0 0% 0 252.eon 0 0% 28 espresso 1 1% 3 300.twolf 61 65% 1 povray31 6 13% \n28 anagram 2 50% 0 bh 1 100% 0 bc 3 13% 0 bisort 1 100% 0 ft 2 67% 0 em3d 6 50% 0 ks 3 100% 0 health \n2 100% 0 yacr2 7 35% 0 mst 4 100% 0 perimeter 1 100% 0 analyzer 5 100% 0 power 3 100% 0 neural 5 100% \n0 treeadd 2 33% 0 pcompress2 0 0% 0 tsp 1 100% 0 Table 2. Statistics for Pool Optimizations Table 2 shows \nthe static number of pools that can use a bump pointer after poolfree elimination (BP), and number of \npoolfree calls deleted when PoolFree Elim is enabled (PFE). The table shows that in many programs (the \nlarger such examples are vpr, twolf, yacr2, and povray), a signi.cant fraction of pools are iden\u00adti.ed \nas eligible bump-pointer pools, i.e., individual pool objects are never freed back to the pool. For vpr, \ntwolf and povray, this is enabled by the elimination of several poolfree operations. This elimination \nindicates the presence of the build-use-destroy pattern explained in Section 5. In 175.vpr, for example, \npool allocation eliminates 29 poolfree calls.  9.2 Pool Allocation Compile Time Table 3 shows the compile \ntimes for pool allocation on programs bigger than 1000 lines of code. It breaks down this time into three \ncomponents: the total time for DSA (which can be used by other clients as well), the time to compute \nthe EBU graphs described in Section 3.3.2 (which are speci.c to pool allocation), and the time to perform \nthe pool allocation transformation itself. The GCC column lists the time to compile the program with \nGCC 3.4.2 at -O3. The total compilation time for pool allocation is extremely modest, taking less than \n1.25 seconds in all cases on our Athlon 2100+. The largest amount of time is spent analyzing 252.eon \n(which has a large portion of the standard C++ library statically linked into it), followed by povray31; \nthese are the only programs that took more than 1 second. Furthermore, much of the time is spent in DSA, \nwhich can be used for a variety of applications besides pool allocation [32]. Our implementation of the \nEBU and PA passes have not been optimized substantially, so they could probably be further reduced. Overall, \nthese compilation times are extremely small for a sophisticated interprocedural optimization.  Program \nLOC GCC DSA EBU PA Total GCC% 164.gzip 8616 2.67 0.02 0.01 0.01 0.03 1.1% 175.vpr 17728 9.39 0.06 0.03 \n0.05 0.14 1.5% 197.parser-b 11204 9.03 0.08 0.05 0.05 0.18 1.9% 252.eon 35819 131.13 0.51 0.30 0.42 1.23 \n0.9% 300.twolf bc ft 20459 7297 1803 3982 17.21 3.55 0.68 1.79 0.09 0.03 0.01 0.02 0.07 0.02 0.01 0.01 \n0.03 0.01 0.01 0.01 0.19 0.06 0.02 0.03 1.1% 1.7% 2.9% 1.7% yacr2 espresso povray31 bh 14959 108273 2090 \n10.28 39.20 0.85 0.14 0.58 0.01 0.08 0.33 0.01 0.08 0.27 0.01 0.30 1.18 0.01 2.9% 3.0% 1.2% Table 3. \nCompile time (seconds) for programs > 1000 LOC To put these times in perspective, the GCC% column (computed \nas (Total/GCC)*100), shows that the pool allocation transforma\u00adtion takes 3% or less of the time taken \nby GCC to compile these programs. This is signi.cant because GCC -O3 performs no cross-runtime library \n(even chomp) are much smaller than the aggregate module optimizations and inlining is the only interprocedural \nop-performance improvements due to pool allocation. timization it performs within a module. Overall, \nwe believe these Finally, the OnlyOH column aims to isolate the performance compilation times are quite \nacceptable for a production compiler. overheads in the transformed code, namely, extra pool arguments \n on functions and initializing and destroying pool descriptors. It is  9.3 Baselines and Pool Allocation \nOverheads computed by pool-allocating the program, but modifying the run\u00adtime library so that poolalloc/free \nsimply call malloc/free. Com-Program GCC NoPA One -OnePool Only -OnlyOH paring to NoPA shows that this \noverhead is negligible or quite low Pool Run % OH Run % (less than about 5%) in nearly all cases, but \nis slightly higher in 164.gzip 25.11 28.16 28.44 101.0% 28.17 100.0% 197.parser-b (7%), bc(10%), and \nfpgrowth (7%). The pool allo\u00ad 175.vpr 10.54 10.88 10.86 99.8% 10.87 99.9% 197.parser-b  cator must \novercome this overhead to provide a net performance 252.eon 12.59 12.42 17.86 142.7% 13.36 106.7% 1.15 \n0.86 0.85 98.8% 0.88 102.3% improvement. 300.twolf 20.26 20.10 19.98 99.4% 20.50  102.0% anagram 3.46 \n3.02 3.01 99.7% 3.02 100.0%  9.4 Pool Allocation and FullPA Aggregate Performance bc 1.71 1.55 1.48 \n95.5% 1.71 110.3% ft 63.74 68.73 66.08 96.1% 68.94 100.3% Table 5 shows the program running time and \nspeedups (rela\u00adks 4.56 4.43 5.30 119.6% 4.39 99.1% tive to NoPA) for automatic pool allocation alone \n(BasePA) and yacr2 3.76 3.86 3.94 102.0% 3.89 100.8% for pool allocation with all pool-based optimizations \n(FullPA). analyzer 324.54 312.25 314.69 100.8% 313.69  100.5% neural  FullPA therefore represents the \naggregate performance impact of pcompress2 88.82 87.34 87.35 100.0% 87.60 100.3% 38.61 37.77 37.44 99.1% \n38.04 100.7% this work. As the table shows, FullPA improves the performance llu-bench 106.63 106.50 \n108.86 102.2% 106.76 100.2% of many programs from 5% to 20%, improves analyzer and llu\u00ad chomp 17.26 16.71 \n10.63 63.6% 16.82 100.6% bench by roughly 2x, and ft and chomp more than 10x. In no case fpgrowth 36.27 \n36.62 36.49 99.7% 39.30  107.3% espresso  does FullPA hurt the performance of other programs relative \nto povray31 1.25 1.22 1.20 98.3% 1.26 103.3% 9.41 9.79 9.69 98.9% 9.81 100.2% NoPA. Not surprisingly, \nthere is no obvious correlation between the bh 14.02 9.33 9.32 99.9% 9.35 100.2% speedups obtained and \nthe number of static or dynamic pools. The bisort 12.59 13.06 13.14 100.6% 13.20 101.1% causes and breakdown \nof these improvements are studied below. em3d 9.55 6.80 6.76 99.4% 6.80  100.0% health 14.11 13.99 \n13.39 95.7% 13.98 99.9% Program NoPA BasePA BasePA/ FullPA FullPA/ mst 12.79 13.14 13.23 100.7% 13.34 \n101.5% NoPA NoPA perimeter 3.02 2.92 2.58 88.4% 3.00  102.7% power 164.gzip 28.09 27.93 0.99 28.40 \n 1.01 treeadd 4.61 2.91 2.93 100.7% 2.92 100.3% 175.vpr 10.88 10.85 1.00 10.30 0.94 tsp 17.48 17.41 \n17.29 99.3% 17.6 101.1% 197.parser-b 12.52 10.14 0.81 9.84 0.79 252.eon 7.17 7.24 7.08 97.8% 7.42 102.5% \n0.86 0.84 0.98 0.84   0.98 300.twolf 20.10 17.59 0.88 17.01 0.85 Table 4. Baseline (NoPA), allocator, \nand overhead comparisons anagram 3.02 3.00 0.99 3.00  0.99 Table 4 shows data to characterize the baseline \nwe use for bc 1.55 1.26 0.81 1.24  0.80 ft 68.73 5.89 0.09 4.98 0.07 comparison and isolate the overheads \nadded to a program by pool ks 4.43 4.38 0.99 4.39 0.99 allocation. The GCC column is the execution time \nof the program yacr2 3.89 3.89 1.01 3.87  1.00 with the GCC 3.4.2 compiler (at -O3). The NoPA column \nis the analyzer 312.25 183.64 0.59 130.53  0.42 program compiled with LLVM using exactly the same sequence \nneural 87.60 87.33 1.00 87.15 1.00 pcompress2 38.04 37.52 0.99 37.68 1.00 of transformation and cleanup \npasses as we do for pool allocation llu-bench 106.50 108.37 1.02 60.96 0.57 (see Section 8), but with \nthe pool allocator and all pool-based chomp 16.71 1.71 0.10 1.46  0.09 optimizations disabled. Using \nNoPA as a baseline for comparison fpgrowth 36.62 31.13 0.85 30.42  0.83 below isolates the speedup of \nthe pool allocator transformation espresso 1.22 1.15 0.94 1.09  0.89 povray31 9.79 9.31 0.95 9.12 0.93 \nand its optimizations by factoring out the impact of other LLVM bh 9.33 9.41 1.01 8.88 0.95 compiler \npasses. Comparing GCC to NoPA shows that the LLVM\u00ad bisort 13.06 13.02 1.00 11.04 0.85 generated code \nis no worse than 12% slower than GCC code and em3d 6.80 6.82 1.00 6.62  0.97 is sometimes much better. \nThis indicates that the code quality of health 13.99 13.35 0.95 12.02  0.86 mst 13.14 11.67 0.89 11.39 \n0.87 NoPA is reasonable to use a baseline for comparisons. perimeter 2.92 2.59 0.89 2.45 0.84 Another \nkey question is how the difference between the allo\u00ad power 2.91 2.91 1.00 2.91 1.00 cator in our pool \nruntime library (used after pool allocation) and treeadd 17.41 17.19 0.99 16.85  0.97 the standard libc \nmalloc library (used by NoPA) affect the compar\u00ad tsp 7.24 7.03 0.97 5.95  0.82 isons. This is signi.cant \nbecause our pool library implementation Table 5. Run time (seconds) and runtime ratios vs. NoPA is currently \nnot thread-safe (though it is otherwise fully general), and this or other implementation details could \nskew the results in  9.5 Locality improvements our favor. To measure this, we transformed the programs \nto allo\u00adcate out of a single global pool (this transformation does not add Figure 10 shows the measured \ncache miss ratio of FullPA compared pool arguments or other overhead to the program), effectively us-to \nNoPA, for each program that sped up at least 5%. The runtime ing our allocator to replace malloc and \nfree for the program (the ratios for these programs are shown in Figure 9 to help correlate OnePool column). \nComparing with NoPA shows that in all but 4 the improvements in cache misses and running times. The .gure \ncases (197.parser-b, ks, chomp and perimter), OnePool is within includes data for the number of accesses \nthat miss the Athlon s L1 about 5% of NoPA. The large slowdown for parser-b occurs be-D-cache, the number \nof accesses that miss the L2 D-cache, and cause we use a singly-linked free list and the order of frees \npre-the number of DTLB misses as measured by the Athlon perfor\u00advents coalescing adjacent free blocks. \nchomp is much faster with mance monitoring counters. The graph shows that the programs our allocator \nbecause our allocator has a fast path for .xed size with the largest speedups generally have dramatically \nreduced miss allocations (to exploit type homogeneous pools) and nearly all al-rates at every level of \nthe cache hierarchy. The bene.ts for twolf locations in chomp are (multiples of) this .xed size. As shown \nbe-and llu-bench are primarily at the TLB and those of ft are much low, in all cases except perimeter, \nany such advantages from our greater at the cache. For all other cases, the reductions are closely  \n          9.6 Contributions of Individual Optimizations Figure 11 shows the runtime ratio of \neach program with one op\u00adtimization disabled at a time, and compares it to a baseline of all optimizations \non. This shows how much the program slows down when a particular optimization is disabled, which is correlated \nto how much the optimization helps the performance of the code. Note that if two optimizations can provide \nthe speedup (e.g. either use of alignment-opt or bump-pointer to reduce inter-object padding), dis\u00adabling \neither will not show a slowdown. Despite this, this analysis does provide useful insight into the effect \nof the optimizations. All of the optimizations except SelectivePA contribute no\u00adticeable improvements \nto at least one program. SelectivePA pro\u00advides no signi.cant speedup but does not hurt performance and \nit is useful because it can improve memory consumption signi.\u00adcantly in some cases. The poolfree optimization \nimproves 175.vpr, 197.parser-b, espresso, and povray31. The bump pointer optimiza\u00adtion appears to be \nthe most signi.cant of the three, being partic\u00adularly valuable to 175.vpr, 300.twolf, ft, analyzer, llu-bench, \nand several Olden programs. Close inspection of 175.vpr is particularly interesting: BasePA is not faster \nthan NoPA, but a combination of poolfree elimination and the bump pointer optimization reduces the runtime \nof the program to 95.7% of NoPA (SelectivePA reduces it further to 94.6%). Finally, several programs \nbene.ted from the alignment optimization, particularly ft, chomp, health and tsp. The speedup potential \nof these simple pool optimizations are particularly notable because they are all very simple optimizations, \nbut can only be performed only once the heap has been segregated into pools.  10. Related Work correlated \nat all the three levels of the memory hierarchy. This in\u00ad dicates that in these cases, the performance \nbene.ts are primarily due to smaller working sets, which would be produced by defrag\u00ad menting the heap. \nTo characterize this effect, we discuss chomp in more detail. Chomp allocates three different nodes, \nwhich we call L, P, &#38; D. L is an 8-byte object of type list, P is a 16-byte object of type play, \nand D is an array of int. Chomp uses an irregular allocation pat\u00ad tern, but generally intermixes object \nallocations (e.g. it starts with DPDLDPDLDLDDDPDLDL...). When using malloc, these objects are interspersed \non the heap, roughly corresponding to allocation order (reuse of freed memory makes it inexact). When \nusing the Figure 9. Aggregate execution time ratios (1.0 = NoPA) The primary goal of the pool allocation \ntransformation is to give the compiler some control over the layout of data structures in the heap. We \nachieve this using a context-sensitive points-to graph to distinguish data structure instances and object \nlifetimes. We .rst contrast this work with previous approaches for in.uencing the layout of heap objects, \nand then with previous work on partitioning the heap for automatic (region-based) memory management. \nChilimbi et al. [12] describe a semi-automatic tool called ccmorph that reorganizes the layout of homogeneous \ntrees at run\u00adtime to improve locality. It relies on programmer annotations to identify the root of a \ntree and to indicate the reorganization is safe. We automatically identify and segregate instances of \nmany kinds of logical data structures, but do not yet identify when a run\u00adtime reorganization would be \nsafe. They also describe another tool, pool allocator, the three different objects are put in separate \npools, and objects in each pool are roughly in allocation order (P is exactly in allocation order). These \nlayout patterns mean that, without Pool Allocation, the L and P list nodes are dispersed in memory (e.g. \nwith variable strides of 100-500 bytes for the P objects) whereas the pool allocator packs them together \n(achieving a perfect stride of 20 bytes for the P objects, 16 for the object and 4 for the object header). \nThis change dramatically reduces the cache footprint of linked list traversals over the P and L nodes. \nIn the case of the P list, it yields optimal cache density and provides the hardware stride prefetcher \nwith a linear access pattern. This combination provides a reduction from 251M L1 misses to 63M L1 misses. \nWhile chomp is an extreme case, it illustrates exactly the effect we aim for. tspperimetermsthealthbisortpovray31espressofpgrowthchompllu-benchanalyzerftbc300.twolf197.parser-b175.vpr \n  perimeter perimeter mst mst health health bisort bisort povray31 povray31 espresso espresso fpgrowth \nfpgrowth chomp chomp llu-bench llu-bench analyzer analyzer ft ft bc bc 300.twolf 197.parser-b 300.twolf \n197.parser-b 175.vpr 175.vpr ccmalloc, which is a malloc replacement that accepts hints to allocate one \nobject near another object. These hints only provides local information for an object pair and not any \nglobal information about entire data structures. Hirzel et al. [28] describe a technique to improve the \neffective\u00adness of Garbage Collection by partitioning heap objects according to their connectivity properties. \nUnlike our work, their partitions are not segregated on the runtime heap, are not directly related to \ndistinct data structures, and the graph of partitions is restricted to be a DAG, which prevents .ne grained \npartitioning of mutually re\u00adcursive structures (like graphs). Several proposed techniques aim to improve \nstorage allocation or GC performance by relating objects based on their predicted life\u00adtimes [26, 18, \n4, 15, 13, 41]. These techniques use heuristics such as allocation site, call stack, or object size, \ncombined with pro.ling information, to predict lifetime properties approximately. In con\u00adtrast, our approach \nuses a more rigorous analysis to group objects both by structural relationships and statically derived \nlifetimes. Other authors have developed techniques (usually pro.le\u00adbased) to reorganize .elds within \na single structure or place objects near each other to improve locality of reference [23, 9, 41, 11, \n29]. These placement decisions are orthogonal to the choices made by Automatic Pool Allocation, and could \ntherefore be combined with our transformation. This an important direction for future work. There has \nbeen signi.cant work on runtime libraries for region\u00adbased memory management [5], and on language mechanisms \nfor manual region-based memory management as an alternative to garbage collection, e.g., Real-time Java \n[7], RC [21], Cy\u00adclone [30, 22], and others [21, 17, 8]. Compared with our approach, these library-or \nlanguage-based techniques are much easier to im\u00adplement, but require signi.cant manual effort to use. \nIn addition, although the region-based libraries and languages expose the rela\u00adtionship between objects \nand regions to the compiler, they do not expose any notion of higher-level data structures or how they \nre\u00adlate to objects and regions. Therefore, the compiler does not obtain information about data structures \nand traversals that could enable optimizations on logical data structures. There is a rich body of work \non automatic region inference as a technique for memory management, for both functional [45, 44, 1, 24] \nand object-oriented languages [14, 10]. Unlike this body of our work, our primary goal is to segregate \nand control the layout of data structures in the heap for better performance and to enable sub\u00adsequent \ncompiler techniques that exploit knowledge of these lay\u00adouts. We describe several optimizations that \nexploit data structure pools, and explore the performance implications of data structure segregation \non program performance in some detail. There are also some key technical differences between this prior \nwork and ours. First, all these previous techniques except the work of Cherem and Rugina [10] are based \non type inference with a region-based type system. It does not appear straightforward to extend the type \nin\u00adference approaches to work for weakly-typed languages like C and C++, which can contain pointer casts, \nvarargs functions, unions, etc., on which type information is dif.cult to propagate statically. In contrast, \nboth our underlying pointer analysis and our transfor\u00admation algorithm correctly handle all the complex \nfeatures of C and C++, by distinguishing objects with known and unknown type (in the points-to graph) \nand by using a conservative and very ef.\u00adcient graph merging technique (the same as in DSA) to deal with \npotentially type-unsafe uses of pointers during the transformation. Second, using a pointer analysis \nas the basis for our transformation enables additional optimizations by exploiting the explicit relation\u00adship \nbetween a points-to graph and pools. Finally, the use of type inference and a rich type-system is not \nwell suited for modern op\u00adtimizing compilers, which are usually based on a mid-level or low\u00adlevel internal \nrepresentation supporting multiple source languages. Our approach is speci.cally designed for use in \nsuch compilers, and relies only a simple, mid-level intermediate representation and pointer analysis. \nThe work of Cherem and Rugina [10] was performed concur\u00adrently with ours and our approaches are technically \nsimilar in some key ways. They describe a region inference approach for Java based on a .ow-insensitive, \ncontext-sensitive points-to analysis. Because their primary focus is automatic memory management, they \nare much more aggressive about computing region lifetimes, includ\u00ading loop-carried regions. Our regions \ncan be placed as .exibly as theirs, but we use a simpler placement analysis. Like the type\u00adinference \napproaches, however, their work also does not support weakly typed languages like C. Although the underlying \npointer analysis could be extended to do so (using our approach, for ex\u00adample), we believe the transformation \nwould be more dif.cult to extend. Furthermore, they too focus on automatic memory man\u00adagement, and do \nnot explore the impact of their work on memory hierarchy performance or consider other optimizations \nthat could exploit their region information. We expect that our optimization techniques could be fruitfully \ncombined with their region inference algorithm for Java programs. There is a wide range of work on techniques \nfor stack allocation of heap objects as well as techniques for static garbage collection, both of which \nare based on analyzing the lifetimes of objects in programs (e.g., see [6, 42, 31] and the references \ntherein). These techniques do not attempt to analyze or control the layout of logical data structures \nin the heap per se, and are largely orthogonal to our work. A minor exception is that our optimization \nto eliminate poolfree for a pool (when there are no intervening allocations before the subsequent pooldestroy) \nessentially replaces explicit deallocation with static reclamation of memory in the pool. This is the \ninverse of (and much more limited than) the work on static GC, which aims to replace or optimize runtime \nGC. Finally, in an early workshop paper [33], we proposed the basic idea of Automatic Pool Allocation. \nThat work did not consider how to handle the key dif.cult cases for this transformation, namely, function \npointers and ef.cient handling of recursion. It relied on an early, non-scalable version of DSA (which \ndid not support practical handling of non-type-safe data structures), did not describe any optimizations \nto exploit pool allocation, and did not evaluate the performance impact of pool allocation. The current \nalgorithm is general, practical and ef.cient, and supersedes the previous work. 11. Conclusions and \nFuture Work The primary contribution of this paper is a practical, ef.cient com\u00adpiler algorithm to segregate \ndistinct instances of logical data struc\u00adtures into separate pools in the heap. Our implementation of \nthe algorithm applies to the full generality of C and C++ programs and performs several additional optimizations \nthat take advantage of pool allocation. Our results show that for many programs, the transformation achieves \nthe major goal stated in the Introduction, namely, that it can improve program performance, sometimes \nquite substantially. The complete implementation and most of our bench\u00admarks are publicly available at \nllvm.cs.uiuc.edu. We believe that the combination of Data Structure Analysis and Automatic Pool Allocation \ntogether provide a new founda\u00adtion for analyzing and transforming pointer-intensive programs, not in \nterms of individual memory references or data elements but rather in terms of how such programs create \nand use entire logical data structures. We term this a macroscopic approach to pointer\u00adintensive data \nstructures. The broad goal of our ongoing work is to continue investigating novel macroscopic techniques \nfor pro\u00adgram optimization, program monitoring, memory safety, and au\u00adtomatic memory management. The .rst \ntwo major examples de\u00adscribed brie.y in Section 7 illustrate the potential power of this ap\u00adproach for \nenabling novel solutions to dif.cult compiler problems. Acknowledgments This work has been supported \nin part by an NSF CAREER Award (EIA-00-93426), the NSF Next Generation Software Pro\u00adgram (EIA-01-03756), \nthe MARCO Focus Research Center Pro\u00adgram through GSRC, and by an Intel Graduate Fellowship. The authors \nwould like to thank John Criswell for his assistance with Linux performance monitoring counters and with \nseveral bench\u00admarks, and Sumant Kowshik for his contributions to parts of the implementation. We are \nalso grateful to Shengnan Cong for her assistance with the fpgrowth program, the members of the LLVM \ngroup for their comments and suggestions on the paper, and the anonymous reviewers for their valuable \nfeedback. References [1] A. Aiken, M. F\u00a8ahndrich, and R. Levien. Better static memory management: Improving \nregion-based analysis of higher-order languages. In PLDI, pages 174 185, June 1995. [2] T. Austin, et \nal. The Pointer-intensive Benchmark Suite. www.cs.wisc.edu/~austin/ptr-dist.html, Sept 1995. [3] A. \nAyers, S. de Jong, J. Peyton, and R. Schooler. Scalable cross\u00admodule optimization. In PLDI, Montreal, \nJune 1998. [4] D. A. Barrett and B. G. Zorn. Using lifetime predictors to improve memory allocation performance. \nIn PLDI, pages 187 196, Albuquerque, New Mexixo, June 1993. [5] E. D. Berger, B. G. Zorn, and K. S. McKinley. \nReconsidering custom memory allocation. In OOPSLA, Seattle, Washington, Nov. 2002. [6] B. Blanchet. Escape \nAnalysis for Java(TM): Theory and Practice. TOPLAS, 25(6):713 775, Nov 2003. [7] G. Bollella and J. Gosling. \nThe real-time speci.cation for Java. Computer, 33(6):47 54, 2000. [8] C. Boyapati, A. Salcianu, W. Beebee, \nand M. Rinard. Ownership types for safe region-based memory management in real-time java. In PLDI, 2003. \n[9] B. Calder, K. Chandra, S. John, and T. Austin. Cache-conscious data placement. In Proc. ASPLOS-VIII, \npages 139 149, San Jose, USA, 1998. [10] S. Cherem and R. Rugina. Region analysis and transformation \nfor java programs. In 2004 Int l Symposium On Memory Management, Vancouver, Canada, Oct. 2004. [11] T. \nM. Chilimbi, B. Davidson, and J. R. Larus. Cache-conscious structure de.nition. In PLDI 99, pages 13 \n24. ACM Press, 1999. [12] T. M. Chilimbi, M. D. Hill, and J. R. Larus. Cache-conscious structure layout. \nIn PLDI 99, pages 1 12. ACM Press, 1999. [13] T. M. Chilimbi and J. R. Larus. Using generational garbage \ncollection to implement cache-conscious data placement. ACM SIGPLAN Notices, 34(3):37 48, 1999. [14] \nW.-N. Chin, F. Craciun, S. Qin, and M. Rinard. Region inference for an object-oriented language. In PLDI, \nWashington, DC, June 2004. [15] R. Courts. Improving locality of reference in a garbage-collecting memory \nmanagement system. CACM, 31(9):1128 1138, 1988. [16] M. Das. Uni.cation-based pointer analysis with directional \nassign\u00adments. In PLDI, pages 35 46, 2000. [17] R. DeLine and M. F\u00a8ahndrich. Enforcing high-level protocols \nin low-level software. In PLDI, Snowbird, UT, June 2001. [18] A. Demers, M. Weiser, B. Hayes, H. Boehm, \nD. Bobrow, and S. Shenker. Combining generational and conservative garbage collection: framework and \nimplementations. In Proc. ACM POPL, pages 261 269, 1990.  [19] D. Dhurjati, S. Kowshik, V. Adve, and \nC. Lattner. Memory safety without garbage collection for embedded applications. Transactions on Embedded \nComputing Systems, 4(1):73 111, Feb. 2005. [20] M. F\u00a8ahndrich, J. Rehof, and M. Das. Scalable context-sensitive \n.ow analysis using instantiation constraints. In PLDI, Vancouver, Canada, June 2000. [21] D. Gay and \nA. Aiken. Memory management with explicit regions. In PLDI, pages 313 323, Montreal, Canada, 1998. [22] \nD. Grossman, G. Morrisett, T. Jim, M. Hicks, Y. Wang, and J. Cheney. Region-based memory management in \ncyclone. In PLDI, June 2002. [23] D. Grunwald and B. Zorn. Customalloc: Ef.cient synthesized memory allocators. \nSP&#38;E, 23(8):851 869, 1993. [24] N. Hallenberg, M. Elsman, and M. Tofte. Combining region inference \nand garbage collection. In PLDI, Berlin, Germany, June 2002. [25] J. Han, J. Pei, and Y. Yin. Mining \nfrequent patterns without candidate generation. In SIGMOD, pages 1 12, 2000. [26] D. R. Hanson. Fast \nallocation and deallcoation of memory based on object lifetimes. SP&#38;E, 20(1):5 12, Jan 1990. [27] \nM. Hind. Pointer analysis: haven t we solved this problem yet? In PASTE, pages 54 61. ACM Press, 2001. \n[28] M. Hirzel, A. Diwan, and M. Hertz. Connectivity-based garbage collection. In OOPSLA, pages 359 373, \n2003. [29] X. Huang, S. Blackburn, K. McKinley, E. Moss, Z. Wang, and P. Cheng. The garbage collection \nadvantage: improving program locality. In OOPSLA, pages 69 80, 2004.  [30] T. Jim, G. Morrisett, D. \nGrossman, M. Hicks, J. Cheney, and Y. Wang. Cyclone: A safe dialect of C. In USENIX Annual Technical \nConference, Monterey, CA, 2002.  [31] R. Jones. Garbage Collection. Algorithms for Automatic Dynamic \nMemory Management. John Wiley &#38; Sons, 1999. [32] C. Lattner. Macroscopic Data Structure Analysis \nand Opti\u00admization. PhD thesis, Computer Science Dept., University of Illinois at Urbana-Champaign, Urbana, \nIL, May 2005. See http://llvm.cs.uiuc.edu. [33] C. Lattner and V. Adve. Automatic Pool Allocation for \nDisjoint Data Structures. In MSP, Berlin, Germany, Jun 2002. [34] C. Lattner and V. Adve. LLVM: A Compilation \nFramework for Lifelong Program Analysis and Transformation. In CGO, San Jose, USA, Mar 2004. [35] C. \nLattner and V. Adve. Transparent Pointer Compression for Linked Data Structures. In Proc. ACM Workshop \non Memory System Performance, Chicago, IL, Jun 2005. [36] D. Liang and M. J. Harrold. Ef.cient points-to \nanalysis for whole\u00adprogram analysis. In ESEC / SIGSOFT FSE, pages 199 215, 1999. [37] D. Liang and M. \nJ. Harrold. Ef.cient computation of parameterized pointer information for interprocedural analysis. In \nSAS, July 2001. [38] E. M. Nystrom, H.-S. Kim, and W. mei W. Hwu. Bottom-up and top-down context-sensitive \nsummary-based pointer analysis. In SAS, 2004. [39] A. Rogers, M. Carlisle, J. Reppy, and L. Hendren. \nSupporting dynamic data structures on distributed memory machines. TOPLAS, 17(2), Mar. 1995. [40] P. \nRundberg and F. Warg. The FreeBench v1.0 Benchmark Suite. http://www.freebench.org, Jan 2002. [41] M. \nL. Seidl and B. G. Zorn. Segregating heap objects by reference behavior and lifetime. In ASPLOS-VIII, \npages 12 23, San Jose, USA, 1998. [42] R. Shaham, E. Yahav, E. K. Kolodner, and M. Sagiv. Establishing \nlocal temporal heap safety properties with applications to compile\u00adtime memory management. In SAS, San \nDiego, USA, June 2003. [43] B. Steensgaard. Points-to analysis in almost linear time. In POPL, pages \n32 41, Jan 1996. [44] M. Tofte and L. Birkedal. A region inference algorithm. TOPLAS, 20(4):724 768, \nJuly 1998. [45] M. Tofte and J.-P. Talpin. Implementation of the typed call-by-value .-calculus using \na stack of regions. In POPL, pages 188 201, 1994. [46] C. B. Zilles. Benchmark health considered harmful. \nSIGARCH Comput. Archit. News, 29(3):4 5, 2001.  \n\t\t\t", "proc_id": "1065010", "abstract": "This paper describes <i>Automatic Pool Allocation</i>, a transformation framework that segregates distinct instances of heap-based data structures into seperate memory pools and allows heuristics to be used to partially control the internal layout of those data structures. The primary goal of this work is performance improvement, not automatic memory management, and the paper makes several new contributions. The key contribution is a new compiler algorithm for partitioning heap objects in imperative programs based on a context-sensitive pointer analysis, including a novel strategy for correct handling of indirect (and potentially unsafe) function calls. The transformation does not require type safe programs and works for the full generality of C and C++. Second, the paper describes several optimizations that exploit data structure partitioning to further improve program performance. Third, the paper evaluates how memory hierarchy behavior and overall program performance are impacted by the new transformations. Using a number of benchmarks and a few applications, we find that compilation times are extremely low, and overall running times for heap intensive programs speed up by 10-25% in many cases, about 2x in two cases, and more than 10x in two small benchmarks. Overall, we believe this work provides a new framework for optimizing pointer intensive programs by segregating and controlling the layout of heap-based data structures.", "authors": [{"name": "Chris Lattner", "author_profile_id": "81100275287", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL", "person_id": "P449180", "email_address": "", "orcid_id": ""}, {"name": "Vikram Adve", "author_profile_id": "81100524180", "affiliation": "University of Illinois at Urbana-Champaign, Urbana, IL", "person_id": "P291197", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1065010.1065027", "year": "2005", "article_id": "1065027", "conference": "PLDI", "title": "Automatic pool allocation: improving performance by controlling data structure layout in the heap", "url": "http://dl.acm.org/citation.cfm?id=1065027"}