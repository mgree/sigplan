{"article_publication_date": "05-17-2002", "fulltext": "\n A System and Language for Building System-Speci.c, Static Analyses Seth Hallem, Benjamin Chelf, Yichen \nXie, and Dawson Engler Stanford University ABSTRACT This paper presents a novel approach to bug-.nding \nanal\u00adysis and an implementation of that approach. Our goal is to .nd as many serious bugs as possible. \nTo do so, we de\u00adsigned a .exible, easy-to-use extension language for speci\u00adfying analyses and an e.cent \nalgorithm for executing these extensions. The language, metal, allows the users of our system to specify \na broad class of analyses in terms that re\u00adsemble the intuitive description of the rules that they check. \nThe system, xgcc, executes these analyses e.ciently using a context-sensitive, interprocedural analysis. \nOur prior work has shown that the approach described in this paper is e.ective: it has successfully found \nthousands of bugs in real systems code. This paper describes the un\u00adderlying system used to achieve these \nresults. We believe that our system is an e.ective framework for deploying new bug-.nding analyses quickly \nand easily.  Keywords Extensible compilation, error detection. General Terms Reliability, Security, \nVeri.cation.  Categories and Subject Descriptors Software [Software Engineering]: Coding Tools and Techniques \n1. INTRODUCTION This paper describes the implementation of an unusual approach to .nding bugs that we \ncall metacompilation (MC). The focus of our approach is pragmatism: we want to .nd as many serious bugs \nas possible. We do so using programmer-written compiler extensions (checkers). This paper presents a \nlanguage, metal, for implementing these extensions, and an analysis engine, xgcc, that executes ex\u00adtensions \nusing a context-sensitive, interprocedural analysis. Permission to make digital or hard copies of all \nor part of this work for personal or classroom use is granted without fee provided that copies are not \nmade or distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 02, June 17-19, 2002, Berlin, Germany. The main barrier to \n.nding bugs is simply knowing the correctness rules that code must obey. The more rules you can check, \nthe more bugs you will .nd. Thus, we designed metal to be (1) easy to use and (2) .exible enough to ex\u00adpress \na broad range of rules within a uni.ed framework. Metal must be easy to use since many rules are known \nonly to programmers; if they cannot write extensions, we can\u00adnot check these rules. Thus, metal is designed \nfor system implementers, not compiler writers. Metal must be .exible because we want to check arbitrary \nrules. We do not want a system that is limited to checking a speci.c set of proper\u00adties (e.g., synchronization \nconstraints; temporal rules) or a speci.c underlying assumption (e.g., the analysis must be conservative \n). Metal is easy to use because it provides the state ma\u00adchine (SM) as a fundamental abstraction. State \nmachines are an easy abstraction because they are a familiar concept in systems programming. Metal is \n.exible because it allows the extension writer to enhance the SM abstraction in near\u00adarbitrary ways with \ngeneral-purpose code. Metal s .exibility allows extensions to make the analysis rule-speci.c without \nmodifying the language or the underlying system. Our prior work has shown that metal works well. It requires \nlittle investment to get results: a day s work can produce an extension that .nds tens or even hundreds \nof se\u00adrious errors in actual code. Further, extensions are small usually between 10 and 200 lines of \ncode, depending mostly on the amount of error reporting that they do. Metal s .exibility is demonstrated \nby the fact that we were able to write over .fty checkers that express signi.cantly di.erent types of \nanalyses including: (1) .nding violations of known correctness rules [1, 9] and (2) automatically inferring \nsuch rules from source code [10]. We describe metal in Sections 2 through 4. We have three main requirements \nfor xgcc; it must: (1) provide the analysis needed to .nd bugs, (2) not signi.cantly restrict what metal \nextensions can do, and (3) scale to large programs. Our ideal division of labor is that extensions en\u00adcode \nonly the property to check, leaving the details of how to check the rule to xgcc. The second and third \nrequirements are important since the more rules we check and the more code we analyze, the more bugs \nwe will .nd. The main re\u00adstriction that xgcc places on extensions is determinism; they can otherwise \nperform arbitrary computations internally. In this paper, we present the analysis algorithm, implemented \nin xgcc, that executes our extensions. We describe xgcc in Sections 5 and 6. In Section 7, we discuss \nthe approximations that our Copyright 2002 ACM 1-58113-463-0/02/0006 ...$5.00. 1: state decl any_pointer \nv; 2: 3: start: { kfree(v) } ==> v.freed; 4: 5: v.freed: { *v } ==> v.stop, 6: { err(\"using %s after \nfree!\", mc_identifier(v)); } 7: | { kfree(v) } ==> v.stop, 8: { err(\"double free of %s!\", mc_identifier(v)); \n} 9: ; Figure 1: Free Checker analyses make and their implications. Section 8 discusses several analysis \ntechniques for handling false positives in\u00adcluding a simple, path-sensitive analysis for eliminating \nnonexecutable paths. Section 9 continues the false positive discussion by presenting the ways in which \nxgcc ranks er\u00adror reports. Finally, Section 10 discusses related work and Section 11 concludes. 2. OVERVIEW \nOur extensions are written in metal, a language for ex\u00adpressing a broad class of customized, static, \nbug-.nding analyses. The common thread among these analyses is that they all exploit the fact that many \nabstract program restric\u00adtions map clearly to source code actions [9]. While metal ex\u00adtensions are executed \nmuch like a traditional data.ow anal\u00adysis, they can easily be augmented in ways outside the scope of \ntraditional approaches, such as using statistical analysis to discover rules [10]. To check a rule, an \nextension does two things: (1) recog\u00adnizes interesting source code actions relevant to a given rule and \n(2) checks that these actions satisfy some rule-speci.c constraint. Metal organizes extensions around \na state ma\u00adchine (SM) abstraction. State machines are a concise way to represent many program properties. \nNote that the SM ab\u00adstraction provides sugar for common operations, it does not limit extensions to checking \n.nite-state properties. When needed, extensions can be augmented with general-purpose code. Metal extensions \nare executed by the interprocedural analysis engine, xgcc. Figure 1 shows the free checker that .ags \nwhen freed pointers are dereferenced or double-freed. We use this checker and the code example in Figure \n2 throughout the paper. The extension will .nd two errors in the example (lines 12 and 17). 2.1 Metal \nExtensions and State Machines Metal extensions de.ne a collection of one or more state machines. During \nexecution of an extension, the current state of the extension is simply the combination of all the current \nstates of the underlying state machines that the ex\u00adtension de.nes. Each of these state machines is logically \nseparate: transitions in one SM do not a.ect any of the oth\u00aders. The number of state machines grows and \nshrinks during the course of the analysis. Each individual SM s current state consists of one global \nstate value and one or more variable-speci.c state val\u00adues. Global state values capture a program-wide \nprop\u00aderty (e.g., interrupts are disabled ). Variable-speci.c state values capture program properties \nassociated with speci.c source objects (e.g., pointer p is freed ). Each state value de.ned above is \nassigned to an instance of a state variable. Each extension de.nes one global state 1:int contrived(int \n*p, int *w, int x) { 2: int *q; 3: 4: if(x) 5: { 6: kfree(w); 7: q=p; 8: p=0; 9: } 10: if(!x) 11: return \n*w; // safe 12: return *q; // using q after free! 13:} 14:int contrived_caller (int *w, int x, int *p) \n{ 15: kfree (p); 16: contrived (p, w, x); 17: return *w; // using w after free! 18:} Figure 2: Free \nChecker Example Code variable and, optionally, a variable-speci.c state variable. For simplicity, the \ndiscussion assumes that an extension has exactly one of each. A state variable has one or more in\u00adstances, \neach of which is assigned a state value. The global state variable has exactly one instance that persists \nthrough\u00adout the analysis. The variable-speci.c state variable has one instance for each program object \nwith an attached state. The number of such instances grows and shrinks as the anal\u00adysis decides to track \nnew program objects and ignore pre\u00adviously tracked objects. An SM state consists of the value of the \nglobal instance and the value of one of the variable\u00adspeci.c instances. Thus, the number of SMs de.ned \nwithin each extension at a given point in the analysis is equal to the number of program objects with \nattached state. In the free checker, the variable-speci.c state variable, v, is declared with the keywords \nstate decl. The notation v.freed means that the state value freed is bound to v.Thus, only instances \nof v can be assigned the value freed.The global state variable is implicitly-de.ned. The state value \nstart is bound to the global state variable because it has no explicit binding. The alphabet of each \nSM is de.ned by the metal pat\u00adterns used within the extension. Patterns are used to iden\u00adtify source \ncode actions that are relevant to a particular rule. The free checker uses patterns to recognize dealloca\u00adtions \n(using the pattern {kfree(v)} ) and dereferences of deallocated variables (using the pattern {*v} ). \nThe vari\u00adable v in these patterns will match pointers of any type. Each state value de.nes a list of \ntransitions. In the free checker, the start state de.nes a single transition rule and the v.freed state \nde.nes two. The transition for the start state (line 3) says that when the global instance has the value \nstart and the current program point matches the pat\u00adtern {kfree(v)}, a transition should execute that \nattaches the state freed to the abstract syntax tree (AST) matching v (i.e., the freed pointer). The \ntransition from start to v.freed is a special type of transition that creates a new instance of v and, \nthus, a new state machine. The v.freed state value has two transition rules: the .rst triggers when a \nfreed variable is dereferenced, and the second triggers when a freed variable is freed again. Both transi\u00adtions \nprint an error message that describes the error and identi.es the particular variable to which the erroneous \nac\u00adtion was applied. A transition that begins in a variable\u00adspeci.c state value is triggered by a speci.c \ninstance of the state variable bound to that value. Thus, the two transi\u00adtions in the v.freed state are \ntriggered when one of the freed variables that the extension is tracking is either double-freed or dereferenced. \nThese transitions update the value of the instance that triggered the transition to the special value \nstop. When an instance is assigned the value stop,the state machine tracking that instance is removed \nfrom the exten\u00adsion s collection of SMs. However, if the variable associated with the instance is freed \nagain, the transition in the start state will execute and thus reinstantiate the deleted SM. The initial \nstate of an extension contains one state ma\u00adchine that expresses the fact that nothing is known about \nthe program at the start of the analysis. Thus, the global state variable in the free checker initially \nhas the value start, and v has the special value <> that re.ects the fact that the extension does not \nknow about any freed variables. xgcc applies an extension to the control .ow graph (CFG) for a single \nfunction in depth-.rst order, one exe\u00adcution path at a time, beginning at the entry points to the callgraph \nfor the source base. At each program point, the ex\u00adtension looks for executable transitions in any of \nthe current SMs. After iterating over all the SMs, the analysis moves on to the next program point. As \ndescribed in Section 8, xgcc also enhances the extension with additional analysis to prune non-executable \npaths, follow simple value .ow, and delete the state attached to an expression that is rede.ned. 2.2 \nExecution of the Free Checker We tie all of these pieces together by following the exe\u00adcution of the \nfree checker on the example in Figure 2. caller has no known callers and is, thus, an entry point to \nthe callgraph for our exam\u00adple. We assume that none of the input parameters are aliased. The extension \nbegins in the initial state. 1. Line 14: contrived 2. Line 15: The kfree call will match the pattern \nin the start state and the transition on line 3 of the checker will execute, attaching the state freed \nto p. 3. Line 16: xgcc follows the call to contrived,tracking the variable p because it is passed as \na parameter. 4. Line 4: The analysis splits down the true and false paths, following the true path .rst. \nWhen the anal\u00adysis splits, a separate copy of the extension s state is applied to each path. The analysis \ntracks that x equals 0 and is not equal to 0 down each respective path. 5. Line 6: The call to kfree \nplaces w in the freed state. At this point, there are two instances of v with the value freed: p and \nw. 6. Line 7: The assignment causes xgcc to transparently create another instance of v for the variable \nq,also in the freed state. 7. Line 8: The assignment to variable p causes xgcc to transition p to the \nstop state, removing p from the extension s state. 8. Line 10: Rather than splitting at the conditional, \nxgcc uses the information that x is non-zero on this path to prune the true branch. If the true branch \nwere followed, there would be a false error report at line 11 because w has attached state freed (line \n6).  9. Line 12: The dereference pattern for v.freed matches *q and reports a use-after-free error. \nq is transitioned to the stop state. After analyzing the return, the analysis backtracks to follow the \nfalse branch from line 4. 10. Line 10: Rather than splitting at the conditional, xgcc uses the information \nthat x is equal to 0 on this path to prune the false branch. 11. Line 11: The path ends. We have explored \nall paths through contrived. 12. Line 17: Control returns to the caller. The set of out\u00adgoing instances \nof v is the union of all instances active at the exit from any path through contrived.There are two such \ninstances, p and w, active at lines 11 and 12, respectively. The extension .ags an error at the subsequent \ndereference on line 17.  The next two sections describe metal in more detail.  3. METAL STATES AND \nTRANSITIONS 3.1 Metal States Each state variable s domain consists of all the state values bound to that \nvariable. This section elaborates the discussion of state variables and provides a more precise de.\u00adnition \nof the extension s state and each state machine within it. The de.nition of extension state that we describe \nhere is translated to the data structures described in Section 5 that de.ne an extension from xgcc s \nperspective. The extension must be allowed to extend the state space using general-purpose code. The \nadvantage of this form of .exibility is that it allows our extensions to express proper\u00adties where the \nstate space is de.ned dynamically. We allow extensions to grow the state space by extend\u00ading the domain \nof each instance within general purpose code. For this reason, we enhance each variable-speci.c instance \nwith a data value that is a C structure of arbitrary size that the extension can manipulate within the \nescapes to C code. Extensions may also update the value of the global instance directly within an escape \nto C code to allow more complex transitions. An extension s state is de.ned as a set of state tuples, \neach of which corresponds to a single SM contained within that extension. A state tuple has one component \nthat is .lled by the value of the global instance. In the free exam\u00adple, this slot always contains the \nvalue start. The second component contains the value of a variable-speci.c instance (e.g., an instance \nof v in the free checker). For example, after analyzing line 15 in Figure 2, the free checker s state \nwould include the tuple (start, v : p . freed)because the state variable v has an instance attached to \nthe program object p whose value is freed. While the state tuples in this paper have only two com\u00adponents, \nthe actual implementation of metal allows the ex\u00adtension to de.ne tuples with additional components. \nThe actual implementation of the algorithms in this paper han\u00addles the more general case. 3.2 Metal \nTransitions Asimple metal transition consists of a source state value, a pattern, and a destination state \nvalue. The transition on line 3 of the free checker follows this template. The extension state decl { \nlock_t } l; start: {trylock(l) != 0} ==> true=l.locked, false=l.stop | {trylock(l) == 0} ==> true=l.stop, \nfalse=l.locked | {lock(l);} ==> l.locked | {unlock(l);} ==> { err(\"%s is not locked\", mc_identifier (l)); \n} ; l.locked: {lock(l);} || {trylock(l)} ==> { err(\"dbl. lock of %s\", mc_identifier (l)); } | {unlock(l);} \n==> l.unlocked | $end_of_path$ ==> { err(\"path ends with lock held\"); } ; Figure 3: Lock checker determines \nwhich transitions to execute by iterating through both global and variable-speci.c instances and determining \nwhether the value of each instance de.nes a transition that can execute. A transition can execute if \nits pattern matches at the current point in the analysis. An instance cannot trigger a transition at \nthe statement where that instance was created; this restriction prevents a variable that is freed for \nthe .rst time from triggering a double-free error at the same program point. Simple transitions can be \nenhanced with path-speci.c destination states and C code actions. Path-speci.c transitions. Path-speci.c \ntransitions allow the extension to track the value of simple boolean predicates (e.g., l is locked, p \nis null) or model functions that can have two possible outcomes. If a transition occurs at a branch condition \nin the source code, the extension can specify a di.erent destination state depending on whether the analysis \nfollows the true branch or the false branch from the condition. Figure 3 shows the lock checker, which \nwarns when locks are (1) released without being acquired, (2) dou\u00adble acquired, or (3) not released at \nall. The routine trylock, used for nonblocking lock acquisition, returns 1 if it acquires the lock and \n0 otherwise. Thus, in the .rst transition, we attach the state locked to the lock on the true path, and \nthe state stop to the lock on the false path. The special pattern $end of path$ in the last transition \nevaluates to true when either an instance of l in the locked state permanently leaves scope or when the \nprogram terminates. CCode actions. Transitions can include C code ac\u00adtions that execute whenever the \ntransition executes. Actions are another way that an extension can extend the basic SM abstraction. C \ncode actions allow the extension to perform arbitrary computations whenever a transition executes. We \ndescribe two types of actions that we have found useful: those that perform complex error reporting and \nthose that enhance the analysis machinery. To make error messages useful, checkers must report not only \nwhat the error was, but also why the error occurred. Thus, all of our checkers track the calculations \nthat found each error. These calculations depend on the particular characteristics of the extension. \nThe code to track why an error was .agged accounts for the bulk of each extension. In [10], we describe \nseveral checkers that use statisti\u00adcal analysis to infer checking rules. For example, to infer whether \nroutines a and b must be paired: (1) assume that they must, (2) count the number of times they occur \nto\u00adgether and (3) count the number of times they do not (rule violations). The reported violations are \nthen sorted using a statistical signi.cance test. We implemented this func\u00adtionality by using the C code \nactions to count the correct pairings and violations during the analysis. (Section 9 uses the same technique \nto rank rule violations.)  By default, a metal extension has a .nite, statically de\u00adtermined domain \nfor each state variable. The extension can extend this model by using C code actions to manipulate the \nextension s state directly using xgcc s internal interface. For example, we could extend the lock checker \ndescribed above to handle recursive locks by using the data values in each instance of l to track the \ncurrent depth of the lock. Whenever a lock operation or an unlock operation occurs, the resulting transition \ncould either increment or decrement the lock depth within the C code action. If this depth ever went \nbelow 0 or exceeded a small constant, the extension would report an incorrect lock pairing. Composition \nis another mechanism extensions can use to enhance the SM model. Extensions can be composed such that \neach extension uses the results of the previous one in its own analysis. Extensions implement this composition \nby using xgcc s internal interface to annotate the ASTs with arbitrary data values. Subsequent extensions \ncan retrieve and use these values. One common use of composition is the path-kill extension [10], which \n.ags all calls to panic so that subsequent analyses will not report errors on paths dominated by these \ncalls. When a subsequent extension sees a .agged function call, it stops traversing the current path. \n 4. METAL PATTERNS Metal patterns provide a simple way for extensions to identify source actions that \nare relevant to a particular rule. Patterns are written in an extended version of the source language \n(C) and can specify almost arbitrary language con\u00adstructs such as declarations, expressions, and statements. \nPatterns are easy to use because they syntactically mirror the source constructs that they are intended \nto match. A base pattern in metal is a bracketed code fragment written in our augmented version of C. \nBase patterns can be composed with the logical connectives &#38;&#38; and ||.The simplest base patterns \nin metal syntactically match the code that the extension wishes to recognize. Because we match ASTs, \nspaces and other lexical artifacts do not interfere with matching. For example, the base pattern {rand()}will \nmatch all calls to the rand function. A simple pattern could not, for example, match all pointer dereferences \nbecause each dereference refers to a dif\u00adferent pointer. The pattern on line 5 in the free checker matches \nall dereferences with a metal hole variable. Any metal variable declared with the keyword decl is a hole \nvari\u00adable. Hole variables let patterns contain positions where any source construct of the appropriate \ntype will match. Hole variables in metal must be typed. If a hole variable is assigned a C type, the \nhole can be .lled by any expres\u00adsion of that type. To match all pointer dereferences in the free checker, \nthough, we cannot assign v any single C type. Metal introduces new meta types that broaden holes to an \nentire class of related types. The hole variable v is declared with the meta type any pointer, which \nmatches pointers to storage of any type. Table 1 lists the hole types and their meanings. If the same \nhole variable appears multiple times in a pat\u00ad Hole Type Matches Any C type any expr any scalar any \nscalar value (int, .oat, etc.) any pointer any pointer of any type any arguments any argument list any \nfn call any function call Table 1: Hole types and their meanings. tern, each appearance must contain \nequivalent ASTs. For example, the pattern {foo(x,x)} matches calls of the form foo(0,0) and foo(a[i],a[i]), \nbut not foo(0,1). A hole variable used within an action (as opposed to a pattern) refers to the AST node \nthat matches the hole. Thus, the use of v on line 8 in the free checker refers to the AST for the freed \npointer matched on line 7. Callouts let programmers extend the matching language to express unanticipated \nor linguistically awkward features by writing boolean expressions in C code that determine whether a \nmatch occurs. Callouts are identi.ed syntactically by appending the pre.x $ to a base pattern. The degenerate \ncallouts, ${0} and ${1},match nothing and everything respectively. Callouts are most often used as a \nconjunct that re.nes a more general pattern. For example, { fn(args) } &#38;&#38; ${ mc_is_call_to(fn, \n\"gets\") } re.nes a pattern that matches all function calls to one that only matches calls to gets.The \nvariable fn is a hole variable of type any fn call, and the variable args is a hole with type any arguments. \nThis pattern could have been written as literal C code as well. Used alone, callout functions can only \nrefer to the cur\u00adrent program point, mc stmt, and any global state either within the extension or within \nxgcc. Used as a conjunct or disjunct with other patterns, the callout can refer to the hole variables \nused in these patterns as arguments (see fn in the example above). xgcc provides an extensive library \nof functions useful as callouts. Legal patterns can specify any C expression or statement (including \nloops, conditionals, or switch statements) with two restrictions. First, all identi.ers in the pattern \nmust be either hole variables de.ned in the extension or legal names in the scope of the code base being \nchecked. Second, the C constructs used in the pattern must compile in isolation. Example illegal patterns \ninclude a single case arm without any enclosing switch statement; an isolated break; etc. All of these \nconstructs can be matched with a callout. 5. INTRAPROCEDURAL ANALYSIS This section describes our intraprocedural \nalgorithm that applies metal extensions to a source base. The goal of this algorithm is to execute checkers \ne.ciently without compromising metal s .exibility. Extensions are applied to each AST in a single path \nin execution order. Execution order means that the tree for each individual statement is visited in the \norder that the corresponding instructions would execute. For example, a function call s arguments are \nvisited before the call; an as\u00adsignment s right-hand side is visited .rst, then the left-hand side, then \nthe assignment. We refer to AST nodes as pro\u00adgram points. At each program point, the extension decides \nwhether to execute any transitions and which transitions to execute. We implement this traversal with \na simple depth-.rst search (DFS) of the CFG starting at the entry block. Thus, the algorithm follows \na single control path, traversing each block along this path until the end of the function, then backtracks \nto the last branch point. The DFS portion of the analysis is straightforward; the important feature of \nthe analysis is the use of block-level state caching for speed. The algorithm records the extension state \nin each basic block before traversing that block. At a subsequent traversal of the same block, the traversal \nis aborted and the analysis backtracks to the last branch point if the extension state is contained within \nthis cache. We .rst describe how to execute an extension at a single program point. We then describe \ncaching at the block level. Finally, we outline the pseudocode for the DFS algorithm. 5.1 Applying an \nextension to a program point Figure 4 shows a simpli.ed version of the DFS algo\u00adrithm. We describe the \ndata structures below. Each variable-speci.c instance (var state) consists of an integer holding a state \nvalue, a tree for the program ob\u00adject to which the state is attached, and an extension-de.ned data value \nof arbitrary size. The tree in the var .eld can be any tree in the code (e.g., an l-value, a general \nexpression, a statement). An extension s state is represented by an sm instance structure, which has \nthree main components: (1) the exten\u00adsion s single global state, gstate, (2) a list of all variable\u00adspeci.c \ninstances, active vars, and (3) a pointer to the extension code, sm fn. Modi.cations to both gstate and \nactive vars are private to each path: mutations revert when the extension backtracks. The extension code \nperforms the following functions: (1) it determines which transitions to execute and (2) it exe\u00adcutes \nthese transitions. Together, these two steps specify the transfer functions for the analysis. When a \ntransition does execute, it can have one of the following e.ects on the sm instance structure: (1) it \ncan alter gstate,(2) it can add or remove elements from active vars, (3) it can alter the state and/or \ndata value of a member of active vars,or (4)itcan leavethe sm instance unchanged. To make the analysis \nalgorithm e.cient, we exploit the fact that if the extension is deterministic, applying the ex\u00adtension \nto the same program point in the same state will always produce the same result. Thus, we only need to \nap\u00adply the extension to each program point once in each state. More precisely, the determinism condition \nthat we require says that given a single state tuple and a program point, if we set the extension s state \nto that tuple and apply the sm fn function to the program point, it will always produce the same transformations \nto the sm instance structure. In addition, we require that each state tuple is a logically sep\u00adarate \nstate machine. We revisit the latter condition below. 5.2 Caching From xgcc s perspective, the state \nof an extension is viewed as a set of state tuples represented as pairs, (gstate, v),where gstate is \nthe extension s global instance and v is either a state variable instance from active vars or the distinguished \nplaceholder <>. The placeholder en\u00adsures that when the analysis begins, the extension state // instance \nof a state variable struct var_state { AST var; // AST for var int s; // state of var ANY data; // extension-specific \ndata }; // a summary edge. struct edge { struct point { int gstate; // global state var_state v; // \nstate var instance } start, end; }; struct block { block succs[]; // successors; includes backedges \nAST trees[]; // block s trees in execution order set edge blk_add; set edge blk_transition; * set edge \nsfx_add;  * set edge sfx_transition; }; struct sm_instance {  int gstate; // global state set var_state \nactive_vars; // instances sm_fn(sm_instance, AST); // SM function }; // Build set of all vars not in \nblock summary set cache_misses(sm, b) { s= {}; foreach v in sm.active_vars if((s1, s2) in b.blk_transition \nwhere s1 = (sm.gstate, v)) sU= v; return sm.active_vars -s; } // DFS traversal void traverse_cfg(sm, \nbacktrace, caller, b) { push (backtrace, b); sm.active_vars = cache_misses(sm, b); // prune path if visited \nblock in current state before if(sm.active_vars = {}) * relax (backtrace); return; sm = copy(sm); // \napply extension function to each AST node in block foreach tree t in b.trees { sm->sm_fn (sm, t); * if \n(t is function call) { * // t is last tree in b; b has exactly one succ * follow_call(sm,backtrace,caller,t,b->succs); \n * return;  } } // compute add and transition edges foreach v in sm.active_vars { e = (sm.gstate, v); \n// if v was active at block entry: create a // transition edge. if v in sm .active_vars where v.tree \n= v .tree b.blk_transition U= ((sm .gstate, v ), e); // otherwise v was created by b: create an add \nedge. else v = (v.tree, unknown, nil); b.blk_add U= ((sm .gstate, v ), e); } if is_exit_block(b) * relax(backtrace); \nelse // apply successor blocks to copy of current sm foreach s in b->succs traverse_cfg(copy(sm),copy(backtrace),caller,s); \n} contains exactly one state tuple. For example, the initial state of the free checker would be represented \nby the set {(start, <>)}, and, after the .rst free at line 15, would change to {(start, <>), (start, \nv : p . freed)}. As we described in Section 3, an extension s state is represented as a set of state \ntuples. Each basic block, b, contains a block summary that records the union of all ex\u00adtension states \nthat reach that block and also records how the SM corresponding to each tuple is transitioned during \nthe analysis of that block. Basic blocks are xgcc s internal repre\u00adsentation of the CFG for a function. \nThe transitions caused by the basic block are visible to xgcc through modi.cations to the current sm \ninstance structure. We divide the po\u00adtential ways an sm instance can change while traversing a single \nblock into two categories: (1) transitions that change the value of either the global instance or a variable-speci.c \ninstance and (2) additions that create a new variable-speci.c instance. The summary for a block, b, represents \nthese ef\u00adfects using two types of directed edges: '' 1. Transition edges: (s, v : t ,v : t. vs). . vs) \n. (s The initial state tuple speci.es that at the entry to b, the global instance had the value s andthere \nwasanin\u00adstance of state variable v with value vs attached to the program object t. The .nal state tuple \nspeci.es that, during the analysis of the block, the SM correspond\u00ading to the initial state tuple transitioned \nto the state ' where the global instance has value sand the variable\u00ad ' speci.c instance for t has value \nvs. Each state tuple that reaches a block generates exactly one transition edge, where the transition \ncan be the identity. Figure 5 shows the CFG for the example in Figure 2. The .rst row in each block in \nthe .gure shows the block summary. An example transition edge from the block summary in block 7 is: (start, \nv : p . freed) . (start, v : p. stop). This says that the free checker enters block 7 in the global state \nstart with an instance for p in the freed state and p is transitioned to the stop state (killed) during \nthe analysis of block 7. '' 2. Add edges: (s, v : t ,v : t. vs). . unknown) . (s The add edge says that \nwhen the global instance has initial value s, a new instance of v that attaches state ' vs to t is created \nwhile traversing the block. The start tuple for an add edge contains the special value v : t . unknown \nbecause the edge only applies when we know nothing about t at the entry to b. An example add edge for \nblock 2 in Figure 5 would be: (start, v : p . unknown) . (start, v : p . freed). At block 2 s entry, \nthe global instance has the value start. At its exit, the global instance still has the value start, \nbut the variable p now has attached state freed. The need for the special value in the start tuple is \nclear if we consider that if we knew that p was freed at the entry to block 2, we would report a double-free \nerror instead of transitioning p to the freed state.  The block summary is the union of all add and \ntransition edges produced by that block. Before applying the exten\u00adsion to a block, the analysis converts \nthe current extension to a set, s, of state tuples. It then removes any tuple, e, from s that is equivalent \nto the initial state tuple for some transition edge. After this process, if s is empty, the traver- \n Figure 4: Depth-.rst CFG traversal. Lines marked sal of the current path is aborted. After a block is \ntraversed, with a * are only relevant to the interprocedural case. the transition edges for each e . \ns and the add edges are both added to the summary. Note that while the intraprocedural algorithm does \nnot use either the add edges or the destination tuple of the tran\u00adsition edges, they are crucial for \nthe interprocedural caching described in the next section. Our algorithm computes a .xed point that is \nsimilar to the meet-over-paths solution in a traditional data.ow anal\u00adysis [16]. The analysis stops when \nthe block summary (i.e., cache) at each block contains all state tuples that can reach that block along \nany control path (i.e., the maximal .xed\u00adpoint solution). The algorithm in this section adds an additional \nrestric\u00adtion to metal extensions beyond determinism. The transi\u00adtions that a variable-speci.c instance \nattached to program object v undergoes at a program point cannot be a.ected by the presence, absence, \nor state of any other instance at\u00adtached to object v ' . This independence condition allows us to combine \nall state tuples that reach a block into a single set in the block summary because the state tuples represent \nin\u00addependent state machines that could, logically, execute sep\u00adarately. Without independence, the number \nof times that we analyze each program point would grow exponentially with the number of variable-speci.c \ninstances. With inde\u00adpendence, this number scales linearly with the number of these instances. Note that \ntransitions on a variable-speci.c instance can be coupled to the value of the global instance. 5.3 DFS \nWith Caching Pseudocode An extension, sm, is applied to a procedure, f, by calling the routine traverse \n cfg in Figure 4 with four arguments: sm, which is initialized to the start state, an empty stack, the \ncaller (relevant in the interprocedural case), and the entry block to f s CFG. In the start state, gstate \nis initialized to the .rst state in the extension text (start for the free checker) and the active vars \nset contains one element in the special <> state so that the extension s state consists of exactly one \nstate tuple. This element persists throughout the analysis, but it is ignored whenever active  vars \nis nonempty. Thus, we omit it from the block summaries in Figure 5 that contain at least one other element. \n The routine traverse  cfg implements the depth-.rst search with caching. This routine is mostly a \nstandard recur\u00adsive DFS exceptthatatthe entryto eachnew basic block, b, it calls the function cache misses \nto determine if the current extension state is a subset of the block summary as discussed above. cache \nmisses returns an updated active vars set such that the sm instance with the new set will only contain \nstate tuples that were not in the block summary. If all of the tuples in the current sm instance are \nin the block sum\u00admary, the DFS backtracks to the last branch point. If not,  cfg applies the extension \ncode to every tree in b in execution order and then traverses b s successors. Successors are applied \nto a copy of the current extension state.  traverse  6. INTERPROCEDURAL ANALYSIS This section describes \nour context-sensitive, interproce\u00addural analysis. At a high level, it works as follows: 1. The .rst preprocessing \npass compiles each .le in isola\u00adtion, emitting ASTs to a temporary .le. These emit\u00adted .les include all \ntype declarations, variable declara\u00adtions, and code within the source .le and are typically four or .ve \ntimes larger than the text representation. 2. The second analysis pass reads these temporary .les, reassembles \ntheir ASTs, and constructs the CFG and call graph. Functions with no callers are considered roots. When \ncomputing roots, recursive call chains are broken arbitrarily. 3. The system applies each extension \nto the CFG with a DFS traversal starting at each callgraph root. On each function call, the system retrieves \nthe CFG for the callee and restarts the traversal there. The extension state is re.ned at the call boundary \nand restored at the return. The rules for re.ne and restore follow C scoping rules unless the extension \nspeci.es otherwise.  By default, if the function s CFG is not available, the system silently continues \nto the next CFG node. To make the DFS algorithm e.cient, we add a summary cache to each function computed \nby combining the block summaries. This cache is checked at each function call. Sim\u00adilar to the intraprocedural \ncaching, if a hit occurs, the call is not followed. Unlike the intraprocedural case, however, we cannot \nsimply abort the current path when there is a cache hit at a function boundary. Because there are many \ncallsites for each function, we may not have analyzed the code after the call in the current state. Thus, \non a cache hit, we use both add and transition edges to update the sm instance and the traversal resumes \nafter the function call. The function summary memoizes the results of the state transformation de.ned \nby each function. Our algorithm does not require that the extension has a .nite state space, or that \nthe state space is even known when the analysis begins. The algorithm that we describe here is inspired \nby the dynamic programming algorithm in [18], but the algorithm in [18] requires that the state space \nof the analysis is .nite. The resulting practical di.erence is that our algorithm executes metal extensions \ntop-down. Thus, rather than analyzing each function starting from all pos\u00adsible states, we only analyze \neach function starting in the states that can reach that function along an interprocedu\u00adrally valid path \n(i.e., an interprocedural path that respects call andreturnsites). 6.1 Re.ne and Restore State re.nement \noccurs when a function call is encoun\u00adtered and that function call is followed. The state is restored \nwhen the analysis returns from the callee and resumes an\u00adalyzing the caller. The extension s global instance \npasses across the function call boundary unchanged. When the call is followed, any object that passes \nfrom the caller s scope to the callee s scope should retain its state. This operation often requires \nmoving the state from an ob\u00adject in the caller s scope to the corresponding object in the callee s scope. \nWhen the call returns, the restore opera\u00adtion may need to move the state back from an object in the callee \ns scope to the appropriate object in the caller s scope and, potentially, restore the original state \nin the caller. In addition, any variable-speci.c instances that left scope when the call was followed \nshould reappear when the call returns. We re.ne and restore the extension state at a function call according \nto the list of rules in Table 2. Each rule lists the actual parameter, the formal parameter, the object \nwhose state needs to be transferred, and how this state is Actual Formal State in Re.ne rule Restore \nrule xa &#38;xa xa xa xa xf xf xf xf xf xa xa xa.field xa->field *xa state (xf )= state(xa) state (*xf \n)=state (xa) state (xf .field)=state(xa.field) state (xf ->field)=state(xa->field) state (*xf )=state \n(*xa) state (xa)=state (xf ) (by reference) or state (xa) unchanged (by value) state (xa)=state (*xf \n) state (xa.field)= state(xf .field) (reference) or state (xa.field) unchanged (value) state (xa->field)= \nstate(xf ->field) state (*xa)= state(*xf ) Table 2: Re.ne and restore semantics for retargeting the \nanalysis across a function call. The .nal four rules actually apply at all levels of indirection (e.g., \np is the argument, **p has state). Note that the extension writer may specify whether or not the actual \nparameter should be treated as pass by value or pass by reference.  Figure 5: Supergraph for the example \ncode shown in Figure 2. The top .eld in each basic block shows the block summary, the middle .eld shows \nthe su.x summary, and the bottom .eld shows the source code in the block. Each block s number is listed \nin the .rst .eld. Note that none of the su.x summaries record any information about q because q is a \nlocal variable so the analysis would never use these edges. Edges that start and end in a tuple containing \nthe placeholder <> are omitted from the cache unless this tuple is the only element in the cache. Also, \nthe su.x summary intentionally omits edges that end in a tuple with the value stop. Su.x edges are only \nrelaxed along traversed paths, i.e. those not suppressed by the algorithm described in Section 8. The \nanalysis does not follow calls to kfree because the extension matches these calls. Thus, they are not \nconsidered callsites in the supergraph construction. re.ned to the callee and then restored to the caller. \nThe rules in the table only cover the case where the state passes through a function argument. Global \nvariables with attached state are not a.ected by the re.ne and restore operations. File-scope variables \nwill leave scope if the call is to a di.erent .le. One important nuance with .le-scope variables is that \nthey may reenter scope before the callee returns if the analysis reaches a func\u00adtion further down the \ncall chain that is in the same .le as the original caller. For this reason, .le-scope variables are passed \nacross the function boundary but they are temporar\u00adily inactivated (and, thus, ignored by the analysis) \nuntil the analysis returns to the .le in which they were declared. All state attached to variables and \nexpressions that are local to the caller is saved at the call boundary, deleted from the sm instance \nbefore the call is followed, then restored to the sm instance when the call returns.  6.2 Dynamic programming \nsummaries This subsection describes how we use block summaries to build additional summaries at the function \nlevel and at the su.x level. A function summary stores add and transi\u00adtion edges that summarize how an \nentire function updates the extension state. Function summaries are used to repro\u00adduce the e.ects of \nanalyzing a function when a cache hit occurs at a function call boundary. Each block, b,also has a su.x \nsummary that consists of add and transition edges starting at b and ending at the exit point, ep,to the \nenclos\u00ading function, p. A function summary canbe viewedas a su.x summary beginning at the entry block \nsp. ep s su.x summary equals its block summary. The second row for each block in Figure 5 shows the su.x \nsummary for that block. For example, the summary in block 10 says that if the analysis reaches that block \nin the state (start, v : w . freed), then the analysis will also reach the exit block in the state (start, \nv : w . freed). Thus, the transition edge (start, v : w . freed) . (start, v : w . freed) is part of \nblock 10 s su.x summary. Notice that none of the edges in the su.x summaries end in a tuple containing \nthe stop state. These edges are unnecessary to the analysis. Su.x summaries are necessary because distinct \nSMs can transition to the same state. Thus, an extension can begin analyzing a function call in a new \nstate so that there is no cache hit at the function boundary, but still have a cache hit within the called \nfunction. A common example occurs when some source variable v is killed at a program point p that it \nreaches in two di.erent states. To accurately re.ect the e.ects of the function call to the caller, the \nanalysis must recreate the e.ects of fully analyzing the called function. Su.x summaries provide exactly \nthis information. The relax function, which computes the su.x sum\u00admaries, is called whenever the analysis \nhits the end of an intraprocedural path or the analysis aborts a path because of a cache hit. Figure \n6 gives a sketch of the edge com\u00adputation algorithm in the relax function. The code walks backwards through \nthe list of blocks on the current path, stored in the backtrace, combining the edges in each block summary \nwith the su.x edges of the subsequent block in the backtrace. Each block stores the set of su.x edges \nin the .elds sfx add and sfx transition. Initially, all block and su.x summaries are empty. More speci.cally, \nthe code .rst checks if the current // Propagate addition and transition edges up path. relax(backtrace) \n{ b = pop(backtrace); // Initialize suffix edges. if(is_exit_block(b)) { b.sfx_add U= b.blk_add; b.sfx_transition \nU= b.blk_transition; } foreach prev in backtrace { // All add edges propagate backwards foreach e in \nb.sfx_add // Relabel gstate component of add state tuple foreach s in prev.blk_transition where s.end.gstate \n= e.start.gstate { e =e; e .start.gstate = s.start.gstate; prev.sfx_add U= e ; } // Transition edges \ncan descend from both edge types foreach e in b.sfx_transition { foreach s in prev.blk_transition where \ns.end = e.start prev.sfx_transition U= (s.start, e.end); foreach s in prev.blk_add where s.end = e.start \nprev.sfx_add U= (s.start, e.end); } b = prev; } } Figure 6: Pseudocode for the summary computation block, \nb, is an exit block. If so, it adds b s block sum\u00admary to its su.x summary. It then propagates both add \nand transition edges in b s su.x summary backwards to the previous block s (prev s) su.x summary. This \nbackwards propagation uses the block summary to extend the length of all of the su.x edges in b by one \nblock. It does so by creating new edges from the start point of a block summary edge and the endpoint \nof a su.x summary edge and adding these extended edges to prev s su.x summary. For a su.x add edge, ea,in \nb, the algorithm looks for an edge in prev s block summary whose end point matches the start of ea.Recall \nthat if ea adds an instance attached to the program object p, the start tuple of ea will contain the \nspecial value v : p . unknown. Each block summary records how that block updates the global instance \nwith an edge whose endpoints are state tuples that only include the global instance and the placeholder \n<>. For the purposes of relaxation, these special transition edges will match the initial state of an \nadd edge if the values of the global in\u00adstance match. For a su.x transition edge, et, the algorithm looks \nfor an add edge or transition edge in prev s block summary whose end tuple is equivalent to et s start \ntuple. The algorithm stops when it either .nishes walking over the backtrace or when no new edges are \npropagated (i.e., the previous block s summary does not grow). The input to our algorithm is the supergraph \nfor the source base, which is de.ned in [18]. The supergraph is constructed from the CFG for every function \nin the source base with the following modi.cations. First, the algorithm adds two nodes to each routine \np: an entry node, sp,and an exit node, ep. Second, it splits calls to p into two nodes: a callsite node, \ncp, and a return-site node, rp. Finally, it adds two directed edges: one from cp to sp, the other from \nep back to rp. The supergraph ensures that the only intraprocedural successor of cp is rp.  6.3 The \nTop-Down Algorithm in Detail The top-down algorithm traverses the supergraph depth-.rst starting at all \nfunction roots. As shown in Fig\u00adure 4, when a function call is encountered, follow call is called to \nrestart the traversal at the entry to the callee. The routine takes the sm instance, the caller s backtrace, \nthe caller s AST, the callee s AST, and the return-site node, and performs the following operations: \n1. Re.nes the extension state to the callee s scope as de\u00adscribed in Section 6.1. cfg with the re.ned \nsm instance,an empty backtrace, the callee s AST, and the callee s entry block. 2. Calls traverse 3. \nUses the callee s function summary to compute a set, s, of transition and add edges that apply to the \ncurrent extension state. 4. Restores the edges in s to the caller s context. 5. Creates new sm instance \nstructures for each disjoint exit state. The sm instance can only assign one state value to each instance \n(in both gstate and active  vars), and active vars can only contain one instance attached to a particular \nprogram object. Thus, s is partitioned into disjoint sets, each of which contains edges whose global \ninstance has the same value and whose variable-speci.c instances are all at\u00adtached to di.erent program \nobjects. These partitions are used to construct the new sm instance structures. 6. Uses the new sm instance \nstructures to analyze the re\u00admainder of the caller by calling traverse cfg on each new sm instance, the \nbacktrace saved at the callsite, the caller s AST, and the return block at the callsite. When a state \nvariable instance is transitioned to the sink state, stop, in the callee, the instance should be deleted \nfrom the extension state when the analysis returns to the caller. Any edges that end with a tuple containing \nan instance in the stop state are omitted from the function summary. Thus, steps 4-6 in the list above \nwill not add the stopped variable to the outgoing extension state. The analysis will terminate if each \nSM within an exten\u00adsion reaches a .nal state after a .nite number of transitions from every state. The \ncomplexity of this algorithm is similar to that in [18]. Note that our algorithm has an implementa\u00adtion \ndisadvantage over the algorithms in [5, 18] because we may analyze any given function at several di.erent \npoints in the analysis as we reach a call to that function in di.er\u00adent states. Thus, we cannot free \nthe storage associated with a function until we are sure that it will not be analyzed again. For large \nprograms, it may be necessary to create compact path summaries that only retain those portions of the \nAST that are relevant to the analysis. This has not, however, prevented our analysis from running e.ectively \non the Linux kernel. We leave this computation to future work.  7. UNSOUNDNESS The strength of our \nextensions is that they can express many rules in a concise way; they are not designed to express sound \nanalyses. It is easy for extensions to make approxima\u00adtions or use analyses that are not conservative. \nBecause the extensions are not intended to be sound, building a sound analysis engine is a misdirected \ne.ort; the analysis should instead focus on executing the extensions e.ectively.       Metal extensions \noften introduce unsoundness by mak\u00ading approximations or by using analysis techniques that pro\u00adduce good \nresults but are not necessarily correct. For exam\u00adple, using statistical analysis to infer which routines \nmust be paired (such as lock and unlock) is an e.ective technique, but cannot guarantee that these inferences \nare correct. The interprocedural analysis algorithm in xgcc is un\u00adsound because it does not analyze recursive \nloops conser\u00advatively, and it does not analyze value .ow conservatively. When a function cache hit occurs \nduring a recursive loop, the function summary may not be complete. The conserva\u00adtive solution is to assume \nthat the extension could be in any possible state after the cache hit. Instead, our algorithm assumes \nthat the existing function summary is su.cient. Our approach is vulnerable to both false negatives and \nfalse positives. False negatives occur when a checker fails to warn about an error in the program. For \ncertain classes of errors, such as security holes, false negatives may be a serious problem. However, \neven here, the tradeo.between soundness and unsoundness at a practical level is not clear\u00adcut. Our focus \non expressiveness means that we can easily check many security properties. As a result, to the best of \nour knowledge, we are able to .nd more security holes than sound analyses [1, 9, 10]. False positives \npresent a di.erent problem: if a checker s warnings are often wrong, then a user will ignore all of its \nwarnings. The next two sections discuss how we counter false positives with a variety of lightweight \nsuppression tech\u00adniques and a post-processing ranking step that tries to order the rule violations that \nwe report such that the most impor\u00adtant, most likely violations appear .rst. In an ideal world, we could \nwrite e.ective, sound anal\u00adyses to check every program rule that we could think of. Unfortunately, it \nis well known that it is infeasible to prove programs correct, so it is unlikely that we will ever approach \nthis goal. Thus, the ideal approach is one that is sound when it can be and unsound where the sound approach \nfails. Our approach explores the bene.ts and uses of unsoundness. Program rules fall into equivalence \nclasses where a vi\u00adolation of one rule is no less or more important than a vi\u00adolation of another. Common \nclasses include the set of all exploitable security holes or nondeterministic bugs. In such cases, .nding \n1000 bugs of a given class is more important than all 10 violations of a single rule in that class. It \nis the observable behavior of the program that actually mat\u00adters, not its behavior with respect to any \nof these properties. The observable behavior will not be correct until all of the bugs in the system \nare .xed. We are essentially making an end-to-end argument [20]: it makes little sense to expend signi.cant \nresources reducing the error rate of one part of a system below the residual error rate of the other \nparts. An unsound analysis that .nds more bugs improves the end-to\u00adend behavior of the system more than \na sound analysis that .nds fewer bugs. 8. FALSE POSITIVE SUPPRESSION Static analyses can make approximations \nthat lead to in\u00adcorrect error reports (false positives). This section describes our main techniques for \nfalse positive suppression. Killing variables and expressions. Whenever a vari\u00ad able is de.ned, xgcc \niterates through the list of program objects with attached state and determines if the de.ned variable \nis used within any of these objects. If so, the ob\u00adject is transitioned to the stop state, thereby deleting \nthe corresponding state variable instance. In Figure 2, xgcc au\u00adtomatically transitions the variable \np from the freed state to the stop state at the assignment, p=0, at line 8. The assignment case is obvious; \nthe slightly more subtle case is that an expression (e.g., a[i]) with attached state is transi\u00adtioned \nto the stop state when a component of that expression (e.g., i) is rede.ned. This analysis runs transparently \nunless a checker requests otherwise, and it is the single most im\u00adportant technique for suppressing false \npositives in checkers that attach state to speci.c program objects. Synonyms. If a variable tracked by \nan extension is as\u00adsigned to another variable, both variables become synonyms: state changes in one are \nmirrored in the other. For exam\u00adple, since p and q are equal in the following code fragment, a successful \ncheck that p is not null also implies that q is not null at the dereference: p = q = kmalloc(...); if(!p) \nreturn 0; *q; /* safe dereference: q = p = not null */ We implemented synonyms with a 50 line addition \nto our system. In addition to reducing false positives, synonyms also increase coverage by increasing \nthe number of variables with an attached state. In Figure 2, the assignment on line 7 allows the analysis \nto catch the error on line 12. False path pruning.1 Nonexecutable false paths caused by data dependencies \nare another source of false\u00adpositives. xgcc s simple path-sensitive analysis uses basic value tracking \ncombined with a congruence closure algo\u00adrithm to prune infeasible paths. In Figure 2, because the conditions \non lines 4 and 10 are contradictory, there are only two executable paths through the function contrived,not \nfour. xgcc s algorithm will prune the two infeasible paths. The algorithm executes the following steps: \n1. We track all variable assignments and comparisons, ei\u00adther to constants (e.g., x=10, x < 100)orto \nother variables (e.g., y=x, x<y). For each assignment to a variable, we assign a new name to that variable \nso that di.erent de.nitions of the variable are not con\u00adfused. If we see the statement (x <y),we record \nthat x<y holds along the true branch and x>= y holds along the false branch. 2. When we see an expression \n(e.g., y=x+1), we try to evaluate the expression based on what we already know. Ifwe knowthat x is 10, \nthen we will assign y the value 11. If we know nothing about x, we store the entire expression. 3. If \nwe see a loop, we set the value of all variables de.ned in the loop to unknown after the loop body. This \nstep eliminates the need to unroll loops. 4. We infer which variables must have the same value through \nthe =, ==,and != operators and place them  1Note that the algorithm described here was implemented in \na previous version of xgcc. Wehavenot yetported it to the current version with interprocedural analysis. \ninto a single equivalence class. Using a congruence clo\u00adsure algorithm [8], we then derive as many equalities \nand non-equalities as possible from the list of tracked assignments. If an equivalence class contains \na con\u00adstant, we know the exact value of everything in that equivalence class. If not, using the tracked \ninequal\u00adities we can derive relationships between equivalence classes. For example, if x<y holds, then \neverything in x s equivalence class is smaller than everything in y s equivalence class. 5. When the \nextension reaches a branch in the CFG, we .rst check if the branch condition is a comparison be\u00adtween \nan expression and a constant and we know the value of the expression. If so, we evaluate the condition \nand prune the false path. If not, we look through the list of relations between congruence classes. If \nthere is a relationship that either contradicts or con.rms the branch condition, we prune the true or \nfalse path. Oth\u00aderwise, we assume both paths are possible. 6. If a path is pruned, we remove all block \nsummary en\u00adtries that were inserted while analyzing the pruned path so that the summaries at each block \ndo not con\u00adtain any non-reachable state tuples.  Our algorithm is scalable because it does not track \nvalues or evaluate branches too precisely. The justi.cation for this choice is that most paths are executable \nand most data de\u00adpendencies are simple. Complex data dependencies are dif\u00ad.cult for programmers to understand, \nso they avoid them as bad practice. Targeted suppression of false positives. One com\u00admon cause of false \npositives is a con.ict between an idiomatic code sequence and an analysis approximation. Metal makes \nit easy for an extension to suppress these system-speci.c id\u00adioms. In some cases, this con.ict is an \nindication that the approximation is too coarse and a more thorough analysis is appropriate; in other \ncases, it is best to suppress the prob\u00adlematic sequence directly. A conservative version of the free \nchecker that .ags all uses of freed variables as errors is a good example. The false positives for this \nchecker came from two sources: (1) passing a freed pointer to a debugging function that prints the pointer, \nand (2) in BSD, passing the addresses of freed variables to functions that rede.ne them. We added eight \nlines of code to the checker to suppress both classes of false positives. History. Initially, we worried \nthat after the errors we reported were .xed, we would only detect false positives in newer versions that \nwould require heavyweight techniques to eliminate. A simple alternative is to just remember false positives \nfrom past versions and suppress them in future ver\u00adsions. We match error reports across versions by comparing \n.le name, function name, variable names involved in the analysis, and the actual error itself as stated \nby the checker. These .elds are relatively invariant under edits (unlike, for example, line numbers) \nand seem to work well in practice. 9. RANKING Given ten errors, you can inspect all of them. Given 1000 \nerrors, you cannot. An e.ective bug-.nding approach will report 100s or 1000s of errors in a real system. \nThe ideal error ranking will rank all true error reports before false er\u00adror reports, and it will order \nthe true error reports according to the severity of each bug. We try to approximate the ideal ranking \nby .rst stratifying errors based on their severity, then sorting within each class based on both the \nprobability of the error being a false positive and the di.culty of in\u00adspection. The user can then start \nwith the most important class, inspect within that class until the false positive rate is too high or \ninspection requires too much e.ort, and skip to the next class of errors.2 From our experience with Linux \nand BSD, implementers almost always .x errors that are di.cult to diagnose with testing .rst. These include \nuse-after-free errors, missing lock releases, and security holes. We rank these errors over those that \nare easier to diagnose with testing, such as memory allocation failures. We also group all errors that \nare computed from a com\u00admon analysis fact into the same class. For example, all use\u00adafter-free errors \nthat involve the same freeing function are placed in the same class. Such grouping makes it easy to suppress \nthem all if the analysis is wrong. Generic ranking. By default, our system sorts error messages using \nthe following criteria: 1. Distance. Errors that span hundreds of lines are more di.cult to diagnose \nthan those that span a few. We rank based on the distance between the statement that contains the error \nand the statement where the exten\u00adsion started checking the property that led to the error. 2. Number \nof conditionals. The more conditionals an er\u00adror spans, the harder it is to diagnose and the more likely \nit is to be a false path. Each conditional is arbi\u00adtrarily weighted as ten lines of distance. 3. Degree \nof indirection. We rank errors that use syn\u00adonyms below those that do not; the former are more di.cult \nto inspect. We then sort synonyms based on the length of the assignment chain. 4. Local versus interprocedural. \nLocal errors can take seconds to diagnose, whereas interprocedural errors can take minutes. We rank all \nlocal errors over global ones and then order global errors based on the length of the shortest call chain \nthat causes the error.  The latter two criteria partition error messages into di.erent classes, which \nare then sorted using the .rst two criteria. In dealing with Linux and OpenBSD implementers, we have \nobserved a curious phenomenon: given errors of equal importance, the more analysis required to .nd an \nerror, the lower the error should be ranked. As the number of analysis steps increases, the likelihood \nthat an analysis approxima\u00adtion made a mistake and the manual inspection e.ort both increase. Thus, these \nerror reports are more likely to be false positives and more di.cult to diagnose. Checker-speci.c and \nsystem-speci.c ranking. The domain knowledge that allows an extension to check a rule also helps it to \nrank errors more e.ectively by gathering checker-speci.c or system-speci.c information. We mostly use \nchecker-speci.c ranking to (1) rank errors by severity and (2) perform targeted demotion of errors. 2From \ninformal discussions with the PRE.x implementers, this strategy and many of the ranking rules in this \nsection have similarities to those that they use. Many extensions are composed with a simple extension \nthat annotates paths that can be triggered by the user (us\u00ading the string SECURITY) and paths that are \nlikely to be error paths (using the string ERROR). Errors on the .rst type of path pose security risks, \nsince they can be triggered by the user. Errors on the second are empirically more likely to be real \nerrors, in part because error paths are less tested. The extension can also add these two annotations \nand the ad\u00additional annotation MINOR manually. Errors annotated with SECURITY are ranked highest, those \nannotated with ERROR are ranked next, and those annotated with MINOR are ranked last. Statistical ranking. \nOur most novel ranking method uses statistical analysis. We have observed that an analysis mistake often \nleads to a local explosion of error reports. The most reliable rules are followed many times and violated \nrarely. We can use statistical analysis to sort errors based on these numbers. An earlier version of \nthe free checker used a .ow\u00adinsensitive, interprocedural analysis to compute a list of all functions \nthat freed their arguments or passed an argument to a function that did. It would then run a local pass \nthat used this list to .nd errors. The checker had an enormous number of false positives, most due to \na single limitation of our analysis: a small number of functions only freed one argument based on the \nvalue of another argument, but our analysis decided that these functions always freed their ar\u00adgument. \nThus, rather than having an error rate of one error per few hundred callsites, these functions had rates \ncloser to .fty errors per hundred callsites. When we sorted errors based on these rates, all of the real \nerrors went to the top and the errors caused by functions the analysis could not handle were pushed to \nthe bottom. We rank errors based on the reliability of the rules that caused them using the z-statistic \nfor proportions. The z\u00adstatistic evaluates the hypothesis that an outcome that oc\u00adcurs e times out of \nn is consistent with an expected prob\u00adability, p0, for that outcome. We compute the z-statistic as z(n, \ne)=(e/n - p0)/ (p0 * (1 - p0))/n Our null hypothesis is that a rule is obeyed or violated at random. \nIn this case, we expect half of all checks to be successful and half of all checks to fail, hence p0 \n=0.5. If a rule is obeyed at random, that rule is probably incorrect. Conversely, if a rule is almost \nalways followed, that rule is probably correct. We count the number of times the rule was followed (or \nexamples) as e and the number of rule violations (or counterexamples) as c. The total number of events, \nn,is the sum of e and c. The larger the computed value of the z-statistic, the higher the signi.cance \nlevel at which we can reject the null hypothesis. High values indicate a higher probability that the \ncounterexamples found are indeed violations of a valid rule, and are, therefore, most likely errors. \nFor the free checker above, each freeing function de.nes its own rule. That rule is violated when an \nerror is reported on a pointer passed to that function (c). The rule is followed when a pointer passed \nto that function is never touched again (e). Ranking code. If a particular block of code causes an explosion \nof errors, the analysis probably cannot handle some aspect of that code. We .rst applied this observation \nto an intraprocedural lock checker that .agged when calls to a locking function did not have a matching \nunlock. The major source of false positives for this extension was wrap\u00adper functions that either always \nacquired or always released locks. In this case, the locking rule is context-dependent; in some contexts \nthe rule is correct, in some contexts it is not. When each function is analyzed, we set e to the num\u00adber \nof times the function correctly acquired and released locks and c to the number of mismatched pairs. \nThe high\u00adest ranked functions had a large number of successful ac\u00adquire/release pairs with only a few \nerrors. These functions are exactly the ones that most likely contain errors. Interprocedural analysis \nwould solve this particular problem, but all analysis has limits. For example, if we ex\u00adtend the locking \nanalysis to include the Linux semaphore routines up and down, there will be a high rate of false positives \nsince semaphores are sometimes used as counters, which need not be paired, and sometimes as locks, which \nmust be paired. Ranking easily distinguishes these two dif\u00adferent uses, whereas adding interprocedural \nanalysis will not. Discussion. Statistical ranking can also be used to in\u00adfer the severity or likelihood \nof real errors. The most serious or most likely errors tend to violate rules that are almost al\u00adways \nfollowed. Thus, ranking is useful even for an approach that does not report any false positives. Sound \napproaches should .nd ranking especially useful because conservative assumptions often lead to large \nnumbers of false positives. In our experience, false positives are not randomly distributed but often \ncome from a small set of analysis mistakes that are automatically identi.ed with ranking. Ranking can \nbe a simple technique, but, from the error\u00adinspector s point of view, it makes an exhilarating di.erence. \n10. RELATED WORK In this section, we discuss other systems for .nding bugs in C programs. We divide these \nsystems into those that re\u00adquire programmer annotations and those that do not. Most of the systems discussed \nhere are sound whereas our system is not. We focus on checking a broad class of properties that are either \ndi.cult or impossible to specify soundly. Because metal is .exible, we believe that our system can check \na wider variety of properties with a wider variance in precision than any other systems with similar \ngoals. The discussion below focuses on other di.erences between our system and other static bug-.nding \ntools. 10.1 Bug-Finding Without Annotations ESP [5] is the project most similar in spirit to our own. \nProperties are speci.ed in ESP using a state machine lan\u00adguage similar to metal. These properties are \nthen veri.ed using a sound, interprocedural data.ow analysis based on the RHS algorithm [18]. ESP includes \nthe abstract sim\u00adulation algorithm, which is an interprocedural false-path pruning algorithm. Our false-path \npruning algorithm uses a congruence closure algorithm which, in the intraprocedu\u00adral case, is more powerful \nthan the algorithm actually used in ESP. The ESP approach is more likely to scale in the interprocedural \ncase than ours. The SLAM project [2] aims to verify temporal safety properties by using a combination \nof predicate abstrac\u00adtion [15], model checking [4], and predicate discovery. Our approach and the SLAM \napproach have di.erent goals: SLAM is a veri.cation tool intended for small, bug-prone pieces of larger \nsystems. It is e.ective within these scalabil\u00adity limits. Our approach is intended for large systems. \nIntrinsa s PRE.x [3] is an industrial-strength tool for C that performs symbolic evaluation of interprocedural \nexecu\u00adtion paths while looking for errors such as uses of uninitial\u00adized memory, bu.er over.ows, NULL-pointer \ndereferences, and memory leaks. PRE.x works on large software systems. It does a deeper, more expensive \nanalysis than our system by building a memory model along each execution path in the program. However, \nit only .nds a .xed set of error types using a .xed set of analyses. We allow programmers to extend both. \n10.2 Bug-Finding With Annotations There are many annotation-based checking projects. One of the most \ndeveloped is Extended Static Checking [7] (ESC) and ESC/Java [19], which are annotation-based tools that \nuse a theorem prover to .nd errors. The annotations used by ESC allow for varying levels of detail, which \nlets the annotator balance annotation e.ort, completeness, and ver\u00adi.cation time. For basic programming \nerrors, the reported annotation overhead for ESC ran as high as one annotation per three lines of code \nfor small programs. Recent work on inferring these annotations attempts to reduce this bur\u00adden [12]. \nBecause of this e.ort, they run on small code bases, and .nd relatively few bugs compared to our approach. \nLCLint [11] statically and unsoundly checks C programs with the aid of programmer annotations. LCLint \nrequires additional annotations to improve precision, which leads to a signi.cant annotation burden to \nproduce useful results. Cqual [14] is an annotation-based approach that adds .ow-sensitive quali.ers \nto standard C types. The analysis is interprocedural and sound. However, it requires annota\u00adtions both \nto express program properties and to suppress false positives caused by conservative aliasing assumptions. \nThese annotations are a signi.cant practical drawback. In general, bug-.nding techniques that rely on \nannota\u00adtions require strenuous, invasive code modi.cations. This annotation overhead can be prohibitive \nfor large systems. One of the most rigorous measurements of this overhead comes from Flanagan and Freund \nwho measured an annota\u00adtion overhead of one annotation per 50 lines of code at a cost of one programmer \nhour per thousand lines of code [13]. For a system the size of Linux (2MLOC), this would require two \nspells of 40 days and 40 nights of continuous annotating for a single property! In contrast, once the \n.xed cost of writing a metal extension is paid (often a day or so) there is little incremental cost to \napplying it to a large amount of code. 10.3 Language-based approaches We view language-based approaches \nto preventing bugs as largely complementary to our work. The Vault [6] lan\u00adguage lets users specify typestate \nproperties within the lan\u00adguage; the role analysis concept proposed in [17] can specify even more complex \nproperties by providing a language mech\u00adanism for specifying legal aliasing relationships. Programs written \ncorrectly using these languages would be protected from some of the bugs that we .nd. Tool-based analysis, \nhowever, does have some signi.\u00adcant practical advantages. First, our statistical extensions can automatically \ninfer some of the temporal properties that a languages like Vault requires programmers to manually specify \n[10]. Tools can also transparently check properties without requiring the use of a speci.c language for \ncode con\u00adstruction or rewrites. Language adoption has historically been an erratic process. Tools work \nimmediately. 11. CONCLUSION This paper describes a language for specifying program properties, metal, \nand an analysis engine for checking these properties statically, xgcc, that has found thousands of bugs \nin real source code. The approach we present centers around a single goal: to .nd as many bugs in real \nsystems as pos\u00adsible. Metal and xgcc are designed to support this goal. One implication of our work is \nthat .nding bugs is easy given the right approach. We present one possible approach that centers around \nextensibility. An extensible speci.ca\u00adtion language can express a broad class of properties within a \nsingle framework. Expressiveness in this language must be matched with an e.cient algorithm that does \nnot impose too many restrictions on the analyses it executes. Thus, extensi\u00adbility is a system-wide property. \nWe believe that metal and xgcc are a reasonable step towards building such a system. 12. ACKNOWLEDGMENTS \nAndy Chou built numerous pieces of the system that we describe. Wilson Hsieh, David Chen, and David Gupta \npro\u00advided helpful comments. We especially thank Godmar Back, Manu Sridharan, David Heine, and Robert \nHallem for many close reads, and John Mitchell for succinct, e.ective struc\u00adturing comments. This work \nwas supported by NSF award 0086160 and by DARPA contract MDA904-98-C-A933. 13. REFERENCES [1] Ken Ashcraft \nand Dawson Engler. Using programmer-written compiler extensions to catch security holes. In IEEE Symposium \non Security and Privacy, Oakland, California, May 2002. [2] T. Ball and S.K. Rajamani. Automatically \nvalidating temporal safety properties of interfaces. In SPIN 2001 Workshop on Model Checking of Software, \nMay 2001. [3] W.R. Bush, J.D. Pincus, and D.J. Siela.. A static analyzer for .nding dynamic programming \nerrors. Software: Practice and Experience, 30(7):775 802, 2000. [4] E.M. Clarke, O. Grumberg, and D. \nPeled. Model Checking. MIT Press, 1999. [5] Manuvir Das, Sorin Lerner, and Mark Seigle. Path-sensitive \nprogram veri.cation in polynomial time. In Proceedings of the ACM SIGPLAN 2002 Conference on Programming \nLanguage Design and Implementation, Berlin, Germany, June 2002. [6] R. DeLine and M. F\u00a8ahndrich. Enforcing \nhigh-level protocols in low-level software. In Proceedings of the ACM SIGPLAN 2001 Conference on Programming \nLanguage Design and Implementation, June 2001. [7] D.L. Detlefs. An overview of the extended static \nchecking system. In Proceedings of the First Workshop on Formal Methods in Software Practice, pages 1 \n9, January 1996. [8] P. J. Downey, R. Sethi, and R. E. Tarjan. Variations on the common subexpression \nproblem. Journal of the ACM, 27(4):758 771, October 1980. [9] D. Engler, B. Chelf, A. Chou, and S. Hallem. \nChecking system rules using system-speci.c, programmer-written compiler extensions. In Proceedings of \nOperating Systems Design and Implementation (OSDI), September 2000. [10] D. Engler, D. Chen, S. Hallem, \nA. Chou, and B. Chelf. Bugs as deviant behavior: A general approach to inferring errors in systems code. \nIn Proceedings of the Eighteenth ACM Symposium on Operating Systems Principles, 2001. [11] D. Evans, \nJ. Guttag, J. Horning, and Y.M. Tan. Lclint: A tool for using speci.cations to check code. In Proceedings \nof the ACM SIGSOFT Symposium on the Foundations of Software Engineering, December 1994. [12] C. Flanagan, \nK. Rustan, and M. Leino. Houdini, an annotation assistant for esc/java. In Symposium of Formal Methods \nEurope, pages 500 517, March 2001. [13] Cormac Flanagan and Stephen N. Freund. Type-based race detection \nfor Java. In SIGPLAN Conference on Programming Language Design and Implementation, pages 219 232, 2000. \n[14] J.S. Foster, T. Terauchi, and Alex Aiken. Flow-sensitive type quali.ers. In Proceedings of the ACM \nSIGPLAN 2002 Conference on Programming Language Design and Implementation, June 2002. [15] S. Graf and \nH. Saidi. Construction of abstract state graphs with PVS. In CAV 97: Computer Aided Veri.cation, 1997. \n[16] G. A. Kildall. A uni.ed approach to global program optimization. In Proceedings of the ACM Symposium \non Principles of Programming Languages, pages 194 206, 1973. [17] Victor Kuncak, Patrick Lam, and Martin \nRinard. Role analysis. In Conference Record of the Twenty-Ninth ACM Symposium of Principles of Programming \nLanguages, January 2002. [18] Thomas Reps, Susan Horowitz, and Mooly Sagiv. Precise interprocedural data.ow \nanalysis via graph reachability. In Proceedings of the 22th Annual Symposium on Principles of Programming \nLanguages, pages 49 61, 1995. [19] K. Rustan, M. Leino, G. Nelson, and J.B. Saxe. Esc/Java user s manual. \nTechnical note 2000-002, Compaq Systems Research Center, October 2001. [20] J.H. Saltzer, D.P. Reed, \nand D.D. Clark. End-to-end arguments in system design. ACM Transactions on Computer Systems, 2(4):277 \n288, November 1984.   \n\t\t\t", "proc_id": "512529", "abstract": "This paper presents a novel approach to bug-finding analysis and an implementation of that approach. Our goal is to find as many serious bugs as possible. To do so, we designed a flexible, easy-to-use extension language for specifying analyses and an efficent algorithm for executing these extensions. The language, <i>metal</i>, allows the users of our system to specify a broad class of analyses in terms that resemble the intuitive description of the rules that they check. The system, <i>xgcc</i>, executes these analyses efficiently using a context-sensitive, interprocedural analysis. Our prior work has shown that the approach described in this paper is effective: it has successfully found thousands of bugs in real systems code. This paper describes the underlying system used to achieve these results. We believe that our system is an effective framework for deploying new bug-finding analyses quickly and easily.", "authors": [{"name": "Seth Hallem", "author_profile_id": "81100048973", "affiliation": "Stanford University", "person_id": "P339604", "email_address": "", "orcid_id": ""}, {"name": "Benjamin Chelf", "author_profile_id": "81100321042", "affiliation": "Stanford University", "person_id": "P28828", "email_address": "", "orcid_id": ""}, {"name": "Yichen Xie", "author_profile_id": "81100418587", "affiliation": "Stanford University", "person_id": "P348282", "email_address": "", "orcid_id": ""}, {"name": "Dawson Engler", "author_profile_id": "81100222430", "affiliation": "Stanford University", "person_id": "PP14087286", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512529.512539", "year": "2002", "article_id": "512539", "conference": "PLDI", "title": "A system and language for building system-specific, static analyses", "url": "http://dl.acm.org/citation.cfm?id=512539"}