{"article_publication_date": "05-17-2002", "fulltext": "\n Pro.le-Directed Optimization of Event-Based Programs Mohan Rajagopalan Saumya K. Debray Department \nof Computer Science University of Arizona Tucson, AZ 85721, USA {mohan, debray}@cs.arizona.edu Matti \nA. Hiltunen Richard D. Schlichting AT&#38;T Labs-Research 180 Park Avenue Florham Park, NJ 07932, USA \n {hiltunen, rick}@research.att.com ABSTRACT Events are used as a fundamental abstraction in programs \nranging from graphical user interfaces (GUIs) to systems for building cus\u00adtomized network protocols. \nWhile providing a .exible structuring and execution paradigm, events have the potentially serious draw\u00adback \nof extra execution overhead due to the indirection between modules that raise events and those that handle \nthem. This pa\u00adper describes an approach to addressing this issue using static opti\u00admization techniques. \nThis approach, which exploits the underlying predictability often exhibited by event-based programs, \nis based on .rst pro.ling the program to identify commonly occurring event sequences. A variety of techniques \nthat use the resulting pro.le in\u00adformation are then applied to the program to reduce the overheads associated \nwith such mechanisms as indirect function calls and ar\u00adgument marshaling. In addition to describing the \noverall approach, experimental results are given that demonstrate the effectiveness of the techniques. \nThese results are from event-based programs written for X Windows, a system for building GUIs, and Cactus, \na system for constructing highly con.gurable distributed services and network protocols. Categories \nand Subject Descriptors D.3.4 [Programming Languages]: Processors compilers; opti\u00admization  General \nTerms Pro.ling, Events, Handlers, Performance 1. INTRODUCTION Events are increasingly being used as a \nfundamental abstraction for writing programs in a variety of contexts. They are used to Permission to \nmake digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 02 June 17-19, \n2002, Berlin, Germany. Copyright 2002 ACM 1-58113-463-0/02/0006 ...$5.00. structure user interaction \ncode in GUI systems [8, 18], form the basis for con.gurability in systems to build customized distributed \nservices and network protocols [4, 9, 16], are the paradigm used for asynchronous noti.cation in distributed \nobject systems [19], and are advocated as an alternative to threads in web servers and other types of \nsystem code [20, 23]. Even operating system kernels can be viewed as event-based systems, with the occurrence \nof interrupts and system calls being events that drive execution. The rationale behind using events is \nmultifaceted. Events are asynchronous, which is a natural match for the reactive execution behavior of \nGUIs and operating systems. Events also allow the modules raising events to be decoupled from those .elding \nthe events, thereby improving con.gurability. In short, event-based programming is generally more .exible \nand can often be used to realize richer execution semantics than traditional procedural or thread-oriented \nstyles. Despite these advantages, events have the potentially serious dis\u00adadvantage of extra execution \noverhead due to the indirection be\u00adtween modules that raise and handle events [5, 14]. Typically, there \nis a registry that maps an event to a collection of handlers to be exe\u00adcuted when the event occurs. Because \nthese handlers are not known statically and may in fact change dynamically they are invoked indirectly. \nDepending on the system, the number and type of the arguments passed to the handler may also not be known, \nrequiring argument marshaling. Finally, there may be repeated work, e.g., initialization or checking \nof shared data structures, across multiple handlers for a given event. All these extra costs can be surprisingly \nhigh our experiments indicate that they can account for up to 20% of the total execution time in some \nscenarios. This paper describes a collection of static optimizations designed to reduce the overhead \nof event-based programs. Our approach ex\u00adploits the underlying predictability of many event-based programs \nto generate an event pro.le that is conceptually akin to a path pro.le through the call graph of the \nprogram. These pro.les are then used to identify commonly encountered events, as well as the collec\u00adtion \nof handlers associated with each event and the order in which they are executed. This information is \nthen used to optimize event execution by, for example, merging handlers and chaining events. The techniques \nare speci.c to event-based programs, since stan\u00addard optimization techniques are largely ineffective \nin this con\u00adtext. For example, conventional static analysis techniques cannot generally discover the \nconnections between events and handlers, let alone optimize away the associated overheads. Dynamic opti\u00admization \nsystems such as Dynamo [2] can be used in principle, but they focus primarily on lightweight optimizations \nsuch as improv\u00ading locality and instruction-cache usage in an effort to keep runtime overheads low. In \ncontrast, the optimizations we consider are sub\u00adstantially more heavyweight, and in the context of event-based \nprograms offer correspondingly greater bene.ts. Our techniques are speci.cally designed to improve execution \non small mobile de\u00advices, where resource constraints make any reduction in overhead valuable. The remainder \nof the paper is organized as follows. Section 2 describes a general model for event-based programs. This \nis fol\u00adlowed in section 3 by a description of our approach to optimizing such programs, including our \npro.ling scheme and the collection of optimization techniques based on these pro.les. Section 4 gives \nexperimental results that demonstrate the potential improvements for three different examples. The .rst \ntwo, a video application and a con.gurable secure communication service, are built using Cac\u00adtus, a system \nfor constructing highly con.gurable distributed ser\u00advices and network protocols, that supports event-based \nexecution [10, 12]. The third is a client side tool that uses X Windows, a popular system for building \nGUIs [18]. This is followed by discus\u00adsions of possible extensions in section 5 and related work in section \n6. Finally, section 7 offers conclusions. 2. EVENT-BASED PROGRAMS While event-based programs differ \nconsiderably depending on the speci.cs of the underlying programming model and notation, their architectures \nhave a number of broad underlying similarities. Because of this, the optimizations described in this \npaper are gen\u00aderally applicable to most such systems. This section presents a general model for event-based \nsystems in order to provide a com\u00admon framework for discussion. As examples, we describe how both Cactus \nand the X Windows system map into the model. 2.1 Components Our general model consists of three main \ncomponents: events, handlers that specify the reaction to an event, and bindings that specify which handlers \nare to be executed when a speci.c event occurs. Events. Events abstract the asynchronous occurrence of \nstimuli that must be dealt with by a program. Mouse motion, button click, and key press are examples \nof such events in a user interface con\u00adtext, while receiving a packet from the network and message pass\u00ading \nare examples in a systems context. In addition to such external events, an event-based program may use \ninternal events that are generated and processed within the program. The set of events used in the event \nsystem may be .xed or the system may allow programs to de.ne new events. Basic events may be composed \ninto complex events. For example, two basic button click events within a short time period can be de.ned \nto constitute a double-click event. Handlers. Handlers direct the response of the program to event\u00adbased \nstimuli. Speci.cally, a handler is a section of code that speci.es the actions to be performed when a \ngiven event occurs. Typically, handlers have at least one parameter, the event that was raised; other \nparameters may be passed through variable argument lists or through shared data structures. The decoupling \nprovided by the event mechanism allows handlers to be developed indepen\u00addently from other handlers in \nthe program. Bindings. Bindings determine which handlers are executed when a speci.c event occurs. The \nbinding between an event and a hander is often provided using some type of runtime bind operation, although \nthe binding may also be prede.ned and .xed. Most systems allow multiple handlers to be bound to a single \nevent and a handler to be bound to more than one event. An event is ignored if no handlers are bound \nto the event. The execution order of multiple handlers bound to the same event may be important. Bindings \nmay be static, i.e., remain the same throughout the execution of the program, or dynamic, i.e., may change \nat runtime. Figure 1 illustrates bindings. Figure 1: Event bindings Bindings are maintained in a registry \nthat maps each event to a list of handlers. The registry may be implemented as a shared data structure \nlike the table shown in the .gure, or each list may be maintained as a part of an event data structure. \nFor distributed systems where handlers may be on distinct physical machines, the registry may be implemented \nusing either a centralized or decen\u00adtralized approach. 2.2 Execution The handlers bound to an event \nare executed when the event oc\u00adcurs. An event may occur because the program receives some exter\u00adnal stimulus \n(external event) or because some program component raises the event (internal event). An execution environment \nor run\u00adtime system is typically responsible for detecting or receiving exter\u00adnal stimuli and activating \nthe corresponding events. As a result, we say these events are raised implicitly, whereas events directly \nacti\u00advated by a program component are raised explicitly. Timed events are events that are activated at \na speci.ed time or after a speci.ed delay. We identify two major types of event activation: synchronous \nactivation and asynchronous activation. With synchronous activa\u00adtion, the speci.ed handlers are executed \nto completion before the activator continues execution. With asynchronous activation, the activator continues \nexecution without any guarantees as to when the handlers are executed. The different types of event activation \nhave speci.c uses in event-based systems. Synchronous activation can be used for internal events when \nthe event activator needs to know when the processing of a message has completed before con\u00adtinuing its \nown processing. Synchronous activation can be used for external events when the runtime system needs \nto ensure that such events are executed sequentially without interleaving. Asyn\u00adchronous activation can \nbe used when none of these requirements apply. The overall picture of the event-based program to be optimized \nthen consists of a program that reacts to stimuli from its environ\u00adment, such as user actions or messages. \nThese stimuli are con\u00adverted into events. Each event may have multiple handlers bound to it and handlers \nmay activate other events synchronously or asyn\u00adchronously. Thus, the occurrence of an event may lead \nto the ac\u00adtivation of a chain of handlers and other events and, in turn, their handlers. Events can also \nbe generated by the passage of time (e.g., timeouts). The type of event activation has implications on \nour optimization techniques. For example, since the handlers for a syn\u00adchronous activation are executed \nwhen the event is raised, an opti\u00admization that replaces the activation call with calls to the handlers \n Top API Micro-protocols Events DESPrivacy msgFromAbove RSAAuthenticity ClientKeyDistribution KeyedMD5Integrity \nkeyMiss msgFromBelow openSession . . . . . . Bottom API  Figure 2: Cactus composite protocol bound to \nthe event at that time results in a correct transformation. Similarly, it is easy to see that sequences \nof nested synchronous ac\u00adtivations can be readily optimized. The speci.c optimization tech\u00adniques and \ntheir limitations are discussed below in section 3. 2.3 Example Systems Cactus. Cactus is a system and \na framework for constructing con.gurable protocols and services, where each service property or functional \ncomponent is implemented as a separate module [10]. As illustrated in .gure 2, a service in Cactus is \nimplemented as a composite protocol, with each service property or other functional component implemented \nas a micro-protocol. A customized in\u00adstance of the composite protocol is constructed simply by choosing \nthe appropriate set of micro-protocols. A micro-protocol is struc\u00adtured as a collection of event handlers \nthat correspond to the han\u00addlers in our general event-based model. A typical micro-protocol consists \nof two or more event handlers. Events in Cactus are user\u00adde.ned. A typical composite protocol uses 10-20 \ndifferent events consisting of a few external events caused by interactions with soft\u00adware outside the \ncomposite protocol and numerous internal events used to structure the internal processing of a message \nor service request. Each event typically has multiple event handlers. As a re\u00adsult, Cactus composite \nprotocols often have long chains of events and event handlers activated by one event. Section 4 gives \nconcrete examples of events used in a Cactus composite protocol. The Cactus runtime system provides a \nvariety of operations for managing events and event handlers. In particular, operations are provided \nfor binding an event handler to a speci.ed event (bind) and for activating an event (raise). Event handler \nbinding is com\u00adpletely dynamic. Events can be raised either synchronously or asynchronously, and an event \ncan also be raised with a speci.ed delay to implement time-driven execution. The order of event han\u00addler \nexecution can be speci.ed if desired. Arguments can be passed to handlers in both the bind and raise \noperations. Other operations are available for unbinding handlers, creating and deleting events, halting \nevent execution, and canceling a delayed event. Handler execution is atomic with respect to concurrency, \ni.e., a handler is executed to completion before any other handler is started unless it voluntarily yields \nthe CPU. Cactus does not directly support com\u00adplex events, but such events can be implemented by de.ning \na new event and having a micro-protocol raise this event when the condi\u00adtions for the complex event are \nsatis.ed. The X Window system. X is a popular GUI framework for Unix systems. The standard architecture \nof an X based system is shown in .gure 3. The X server is a program that runs on each system supporting \na graphics display and is responsible for managing de\u00advice drivers. Application programs, also called \nX clients, may be local or remote to the display system. X servers and X clients use the X-protocol for \ncommunication. X clients are typically built on the Xlib libraries using toolkits such as Xt, GTK, or \nQt. X clients are implemented as a collection of widgets, which are the basic building blocks of X applications. \nAn X event is de.ned as a packet of data sent by the server to the client in response to user behavior \nor to window system changes resulting from interactions between windows [18]. Examples of X events include \nmouse motion, focus change, and button press. These events are recognized through device drivers and \nrelayed to the X server, which in turn conveys them to X clients. The Xlib framework speci.es 33 basic \nevents. X clients may choose to re\u00adspond to any of these based on event masks that are speci.ed at bind \ntime. Events are also used for communication between wid\u00adgets. Events can arrive in any order and are \nqueued by the X client. Event activation in X is similar to synchronous activation in the general model. \nThe X architecture has three mechanisms for handling events: event handlers, callback functions, and \naction procedures. All these map to handlers in the general model and are used to specify differ\u00adent \ngranularities of control. Event handlers, the most primitive, are simply procedures bound to event names. \nCallback functions and action procedures are more commonly used high-level abstractions. One difference \nbetween the three mechanisms relates to scope actions have global scope in an X client, while the scope \nof event handlers and callbacks is restricted to the widget in which they are de.ned. Another difference \nis their execution semantics. An event handler can be bound to multiple events in such a way that it \nis ex\u00adecuted when any of the associated events occur. A callback func\u00adtion, on the other hand, is bound \nto a speci.c callback name, and all functions bound to a name are executed when the correspond\u00ading callback \nis issued. Actions provide an additional level of in\u00addirection, where a mapping is created .rst between \nan event and the action name, and then between the action name and the action procedure. In addition \nto these three, X has a number of other mechanisms that can be broadly classi.ed as event handling, namely \ntimeouts, signal handlers, and input handlers. Each of these mechanisms allows the program to specify \na procedure to be called when a given condition occurs. For all these handler types, X provides operations \nfor registering the handlers and activating them.  3. OPTIMIZATION APPROACH Compiler optimizations are \nbased on being able to statically pre\u00addict aspects of a program s runtime behavior using either invariants \nthat always hold at runtime (i.e., based on data.ow analysis) or as\u00adsertions that are likely to hold \n(i.e., based on execution pro.les). Event-based systems, in contrast, are largely unpredictable in their \nruntime behavior due to the uncertainties associated with the be- EventGraph = 0; prev event = eventTrace-.rstEvent; \nwhile not (end of eventTrace) { event = eventTrace-nextEvent; if (prev event,event) not in EventGraph \n{ EventGraph += (prev event,event); EventGraph(prev event,event)-weight = 1; }else eventGraph(prev event,event)-weight++; \nprev event = event; } Figure 4: GraphBuilder algorithm. havior of their external environment, e.g., the \nuser s actions. We have found, however, that in practice, there is a signi.cant amount of predictability \nin their internal behavior that can be exploited for optimization purposes. This predictability occurs \nat two levels. At the event level, certain sequences of events occur in all (or most) system executions. \nAt the handler level, there is often more than one handler bound to a speci.c event, and all these handlers \nare ex\u00adecuted in sequence each time the event occurs. Handlers are gener\u00adally developed to work as independently \nas possible, and the over\u00adall execution .ow is determined by bindings performed at runtime. The use of \nruntime binding also means that the program s behavior can be changed dynamically by changing the event/handler \ncon.g\u00aduration from within the program. Event and handler pro.ling are used to identify predictable as\u00adpects \nof an event-based program s behavior. This section describes these techniques and the optimizations performed \nbased on the re\u00adsults. 3.1 Event Pro.ling We identify static optimization opportunities in an event-based \nprogram using event and handler execution pro.les. Pro.ling is used instead of static approaches such \nas code and registry data structure analysis since, as noted above, binding information is gen\u00aderally \navailable only at runtime and may in fact change during ex\u00adecution. We .rst identify commonly occurring \nevent sequences by instrumenting the event system to log an entry each time an event occurs, indicating \nthe event being raised and whether it is being raised synchronously or asynchronously. We then use the \nresulting event pro.les to identify frequently invoked event handlers, add in\u00adstrumentation code to each \nsuch handler, and log entries each time the handler is invoked, thereby obtaining handler pro.les. Pro.l\u00ading \nis done for one program and for con.gurable programs, one program con.guration at a time. At present, \nthe event framework is instrumented by hand, but this can easily be automated using well-understood techniques \n[3]. The analysis and optimizations are currently performed manually off-line after the program to be \nop\u00adtimized has been executed enough times to develop an adequate pro.le. On-line analysis and optimization, \nas well as automation, are potential extensions to this work and are discussed in section 5. The pro.ling \nalgorithm takes the event trace generated by the instrumented event framework and constructs an event \ngraph that summarizes the event sequences in the trace. There is an edge from node Ato node Bin the graph \nif event Ais ever followed immedi\u00adately by event Bin the trace. Each edge (A,B)has an associated weight \nindicating how many times the sequence (A,B)appeared in the trace. The algorithm used to generate the \nevent graph is pre\u00adsented in .gure 4. Note that in the event trace, if an event Ais fol\u00adlowed immediately \nby an event Bthat was raised synchronously, then we can infer that execution of Bfollows Asequentially. \nHow\u00adever, if Bwas raised asynchronously, then the fact that it follows    Figure 5: Event graph generated \nfrom video player Ain the event trace may not indicate causality, i.e., we cannot con\u00adclude that Ahad \nany role in raising B. For example, Bmay be the result of a timeout from an earlier event completely \nunrelated to A. The event graph is used as the starting point for the analysis that identi.es predictable \nevent and handler sequences. The .rst step is to use the edge weights to identify commonly occurring \nevent sequences; while this mapping is not exact and more sophisticated techniques could be applied, \nwe have found this approach to be suf.cient in practice. Given an event graph Gand a threshold T, an \nevent path of weight Tis de.ned to be a path in Gin which no edge has weight less than T. To simplify \nthe algorithm, we .rst discard from the event graph edges whose weights are below the threshold T; this \nproduces a reduced event graph from which event paths are extracted. Each event path indicates a frequent \nsequence of events and hence represents a candidate for optimization. The remainder of this discussion \nfocuses on event paths unless other\u00adwise mentioned. Note that the event paths so constructed are not \nquite the same as hot path pro.les. Path pro.ling at the level of events is not used since path pro.les \ntend to be large and expen\u00adsive to compute [13, 25], and since experimental results using the approach \ndescribed above suggest that it is adequate for the opti\u00admizations implemented. The next step is to perform \nhandler level pro.ling to identify pre\u00addictable sequences of handler activations. This pro.ling is needed \nfor two reasons. First, an event may have multiple handlers that are executed in sequence each time the \nevent occurs. Second, because of the decoupling between events and their handlers, knowing the events \nthat occur does not by itself tell us about the handlers that are activated. The event paths in the event \ngraph are used to identify the most promising events for handler level pro.ling. The handlers for the \nnodes in each event path are instrumented and an entry is logged each time the handler is invoked. Based \non this trace, an\u00adother graph called the handler graph is constructed to use as the basis for optimization. \nThe pro.ling and graph construction for handlers is carried out in the same way as before.  Figure 6: \nReduced event graph Figure 5 shows the event graph for a video player application im\u00adplemented on top \nof a con.gurable transport protocol called CTP built using Cactus [24]; the bold edges are discussed \nbelow in sec\u00adtion 3.2.1, while details of the application are given in section 4.2. Figure 6 shows the \ncorresponding reduced event graph for T 300. 3.2 Optimization Techniques Once the most frequent event \nand handler sequences have been identi.ed, the optimizations are performed based on the handler graph. \nThe goal is to eliminate: Marshalling overheads for event activations.  Indirect function call and \nvariable argument passing costs.  State maintenance (synchronization and locking) costs for global variables. \n Redundant initializations and code fragments for events with multiple handlers.  For synchronous events, \nwe also expect to observe event se\u00adquences that can be chained together. In addition, elimination of \nindirect function calls increases the potential for value-based op\u00adtimizations such as constant propagation. \nAnother option that has been explored is inlining code for raising popular events. All these optimizations \ncan be classi.ed broadly as either graph or compiler optimizations. This section describes each type \nin turn. 3.2.1 Graph Optimizations Graph optimizations try to reduce the costs associated with in\u00adteractions \nbetween events and handlers in the program by reducing the number of handler activations along common \nevent paths. This is done by reducing the number of nodes in an event graph and generating simpler collapsed \ngraphs, as well as by merging handler nodes to create super-handlers for events and chains. Of course, \ncorrectness of these transformations is an important requirement; this issue is discussed in the next \nsection. Handler Merging. In the case of events with multiple handlers, the handler graph shows a sequence \nof contiguous nodes. The event system is responsible for issuing calls to all handlers bound to the event. \nReferences to handlers are stored as function pointers in a list associated with the event, and each \nraise operation for the event Handler Merging  Event A Events Handlers   Handler123 { } H3_code \nH1_code H2_code Figure 7: Handler merging translates into a sequence of indirect function calls. There \nare two sources of overhead here: the cost of an indirect call, and since in general the identities and \nthe number of arguments taken by the handlers for an event are not statically known a cost associated \nwith argument marshaling and unmarshaling. However, we can use the handler graph obtained from our handler \npro.ling to identify the sequence of handlers activated when an event is raised. Given this information, \na simple approach for dealing with this overhead is to merge all the handlers associated with an event \ninto a single large handler. In the handler graph, this corresponds to collapsing all handler nodes for \na given event into a single super-handler node. The immediate savings from this transformation is the \nreduction in the number of indirect function calls. Figure 7 shows the effect of this optimization. Further \nsavings then result from the application of standard compiler optimizations, such as common subexpression \nelimination and dead-code elimination on the super-handler code. An important point to note in this context \nis that some event sys\u00adtems such as Cactus allow event bindings to change dynamically. We need to account \nfor such changes and ensure that correctness is preserved even if they do occur. This is done by checking \nwhether any changes have been made to the list of handlers bound to an event when it is raised, and then \ndropping back into the original unoptimized code if a change is detected. See section 3.3 for more details. \nRaise operations are typically generic in the sense that they can raise an arbitrary event. Because of \nthis, they incur overheads due to argument marshaling, indirect invocation of handlers, and state maintenance. \nThe number of activations and hence their to\u00adtal cost can be reduced using super-handlers, as discussed \nabove. However, super-handlers are still invoked indirectly and so incur some residual cost. These costs \ncan be reduced by replacing the raise operation with a direct call to the super-handler based on pro\u00ad.le \ninformation. This in turn opens up the possibility of inlining the function call into the call site, \nas discussed below. Event Chains and Subsumption. The unpredictable nature of events may suggest that \ndifferent events are largely independent of one another. However, our experiments indicate that there \nare often signi.cant correlations between different events of the form Event B always follows Event A. \nThis leads to commonly occurring se\u00adquences of events, which we term event chains, that are candidates \nfor optimization. An event chain is de.ned to be a path in the event graph ao-al- -an [0] satisfying \nthe following: (i)each vertex aiin the chain (except possibly for the last ver\u00adtex, an) has exactly one \nsuccessor edge corresponding to a synchronous event activation; and (ii)the edge ai-ai+lcorresponds to \na synchronous event ac\u00adtivation. Graph edges corresponding to asynchronous raises are not included since \nas mentioned above, if an event Ais followed by an asyn\u00adchronously raised event B, it cannot be inferred \nthat Anecessarily raised B. The intuition behind event chains is that they denote sequences of event \nactivations that are guaranteed to occur if the event at the head of the chain occurs. Such chains can \narise due to two reasons. One is that the con.guration of the event-based program may be such that a \nparticular set of events is raised in sequence under the appropriate circumstances. The other is that \nthe handlers of one event may (synchronously) raise other events. Two examples of event chains are shown \nin .gure 5 as sequences of bold edges. Event chains are optimized in two ways. First, the notion of handler \nmerging (section 3.2.1) is generalized to span event bound\u00adaries. The effect is to combine all the handlers \nfor all the events in the chain into a single handler, which avoids the runtime cost of multiple handler \ninvocations. Second, even if this is not possible (see below), the handlers for events later in the chain \ncan be op\u00adtimized using the knowledge that handlers for earlier events have been executed. This may allow \nus to eliminate some redundant work across handlers. Inter-event handler merging is not carried out if \nany of the activa\u00adtions in an event chain is asynchronous (or as a special case, timed; see section 2.2). \nThis is necessary to preserve the observable be\u00adhavior of the system with respect to timing semantics. \nFor example, suppose that an event Asignifying data transfer initiated is al\u00adways followed by an event \nBsignifying data transfer completed, but that Boccurs (at least) some .xed time after A. In this case, \nB is raised asynchronously, and so is not subjected to handler merg\u00ading. Note that this also maintains \nthe threading semantics of the system. That is, with synchronously activated events, the activator thread \nservices all its handlers, whereas with asynchronously acti\u00advated events this may not be the case. Not \noptimizing events that are raised asynchronously maintains this behavior. It should be noted that even \nthough handler merging is not carried out in such cases, the event chains can still be optimized to some \nextent based on knowledge about the context in which later events can be raised. For instance, when event \nBin this example is raised, the event A must have been raised and handled previously. An important special \ncase of event chain optimization is when the handlers bound to one event raise other events synchronously. \nThis leads to event chains where handlers for an event Bmay be embedded in the handlers for the parent \nevent A. An example of this is found in the video player example shown in .gure 5 and is il\u00adlustrated \nin .gure 8. The focus is on two distinct events from .gure 5, SegFromUserand Seg2Net; the former is shown \nunshaded, the latter is shaded gray. The relevant portion of the corresponding handler graph is shown \nat the right of .gure 8, with handlers exe\u00adcuted based on the actions of SegFromUsershown unshaded and \nthose executed based on Seg2Netshown shaded. The proper nest\u00ading of the shaded handler sequence within \nthe unshaded sequence indicates that Seg2Netis raised synchronously by the handlers of SegFromUser. In \nother words, if the event Seg2Net is raised Handler Graph View  Figure 8: Subsuming events from within \na handler for SegFromUser, the latter will wait un\u00adtil the handling of Seg2Net has been completed, at \nwhich point control will return to the handler for SegFromUser. In this case, the handler for Seg2Netcan \nbe subsumed into that for SegFro\u00admUser, thereby eliminating the synchronous event raise between them. \nFigure 9 illustrates the effects of subsumption for the events in .gure 8. SegFromUserand Seg2Neteach \nhave four handlers in this case: FEC-SFU1, SeqSegSFU, TDriver-SFU, and FEC-SFU2for SegFromUser, and PAU-S2N, \nWFC-S2N, FEC-S2N, and TD-S2Nfor Seg2Net. TDriver-SFUsynchronously raises the event Seg2Net, which causes \nexecution of its handlers. Af\u00adter completion, control returns to handling SegFromUser and causes the \nlast handler, FEC-SFU2, to be executed. Without sub\u00adsumption, the best that could be done would be to \nmerge the han\u00addlers for SegFromUser to create a super-handler, and similarly for Seg2Net. This would \nstill incur the overhead of an event raise of Seg2Netfrom TDriver-SFU. However, the synchronous na\u00adture \nof this activation allows this code to be optimized so that the raise of Seg2Netwithin the super-handler \nfor SegFromUseris replaced by the handler code for Seg2Net. This is illustrated in .gure 9. Figure 9: \nEffect of subsuming events 3.2.2 Compiler Optimizations The super-handlers resulting from graph optimization \nhave the effect of bringing together code that was scattered across the pro\u00adgram over a number of different \nhandler routines prior to optimiza\u00adtion. As a result, they become amenable to further improvement via \nstandard compiler optimization techniques. Here, we describe some optimizations that tend to be especially \nuseful in this con\u00adtext. The primary motivation in choosing these techniques is their relevance to the \nexpected gains, based on nature of code in event handlers. Function Inlining. Since most event handlers \ntend to be relatively small in size, function inlining applied aggressively along, and restricted to, \nfrequently executed event paths is very effective in reducing the overhead of function calls without \nsubstantial growth in code size. Additionally, a secondary bene.t of inlining is the re\u00adduction in the \ncost associated with supporting variable numbers of arguments to a function. Event-based systems typically \ndo not reg\u00adulate the number and types of parameters for a handler, which leads to the use of variable \nargument lists. Inlining handler code allows the elimination of overheads associated with argument marshaling \nand unmarshaling. Constant Propagation and Dead Code Elimination. Function inlining makes it straightforward \nto propagate information about constant arguments from the call site into the inlined code. This in turn \nexposes the potential for constant propagation optimizations to be applied to the super-handler. For \nexample, conditionals that test the value of one or more arguments can be eliminated if the values of \nthe corresponding arguments are known at the call site where inlining is carried out. As a speci.c case, \nthis allows us to take the code for a handler that could be invoked by multiple events (e.g., Handler \n4 in .gure 1), and create a customized version of the (inlined) handler corresponding to a frequently \nencountered event. Furthermore, event handlers are often shared across different events, with conditional \nstatements used to determine the steps used to handle each event. Constant propagation, together with \nopti\u00admizations it enables such as the elimination of conditional branches whose outcomes become known, \ncan cause code to become dead or unreachable. The elimination of such useless code further improves handler \nand system performance. Redundant Code Elimination. Structuring programs using events promotes the design \nof event handlers that are largely independent from one another. Because of this, they are usually written \nwith\u00adout making assumptions about actions that may be carried out by other handlers. This can lead to \nredundant code in the program. For example, a handler may evaluate expressions that have already been \nevaluated by preceding handlers in an event chain. Another common example is that of managing program \nstate: since the pro\u00adgram state may be changed by handlers, in a multithreaded context handlers typically \nstart by updating their state from the global state, and commit a new state at the end. In an event chain, \nthis can cause redundant updates. Such redundant operations can be identi.ed in the super-handler code \nand targeted for elimination.  3.3 Dealing with the Unexpected Pro.ling of the type used here has limitations, \nsince it cannot by de.nition explore all possible program execution paths. This mani\u00adfests itself in \nunexpected execution paths i.e., paths not exercised during the pro.ling test runs that must be dealt \nwith during exe\u00adcution. Such execution paths can occur, for example, if a different input is used or \nif handler bindings change dynamically during exe\u00adcution. Since the optimized program must operate in \nthe same way as the corresponding unoptimized version, there must be a mecha\u00adnism for ensuring that optimized \nsuper-handlers are only used when the unoptimized program would have taken the corresponding se\u00adquence \nof handlers. These problems are solved by bypassing the optimized super\u00adhandlers when the sequence of \nhandlers to be executed is different than the sequence that was optimized. To deal with changes in bindings, \nthe event framework associates a .ag with each event. When the bindings for an event change, it gets \nre.ected in the .ag. This .ag is then checked during the execution of a super-handler before the code \nassociated with this event is executed. If the .ag is set, the execution falls back to the original unoptimized \nprogram, and the handlers in the original version of the program are executed instead of the super-handler. \nNote that one effect of this approach is a larger code size since now the program must contain both the \nsuper-handlers and the orig\u00adinal unoptimized handlers. However, our experiments indicate that this increase \nis small, typically under 1.5% (see section 4.2). Con\u00adtinuous pro.ling could also be used to, in essence, \nreoptimize the program dynamically to deal with binding changes. This and other future work are discussed \nfurther in section 5  4. EXPERIMENTAL RESULTS 4.1 Overview Experiments were run on 650 MHz Pentium \n3 desktop machines with 128 MB memory and on laptops with 266 MHz Pentium II processors and 96 MB memory, \nall running Linux 2.4. We used Cactus/C, the C version of Cactus, and the XFree86 version 4.0.2 distribution \nof X including Xt, Xlib, and the Athena widget fam\u00adily. Cactus programs used for pro.ling included a \nH263-based video player implemented on top of a con.gurable transport pro\u00adtocol called CTP [24], and \nSecComm, a con.gurable secure com\u00admunication service [11]. For X-based programs, we focused on optimizing \nspeci.c event responses. Programs used for this pur\u00adpose included xterm, a popular terminal emulator \non Unix systems, and gvim, a graphical version of the vi text editor program. As might be expected, the \neffect of these optimizations is more pronounced on the the slower laptops. Common con.gurations for \nhandheld devices (206Mhz,?64Mb RAM) are similar to those of the laptops used for the experiments. We \nexpect the need for and effect of these optimizations to be even more signi.cant on such platforms. \n 4.2 Cactus Programs The video application displays video stored as a .le on a local disk. The input \nparameters for the video application include the resolution of the video and the frame rate. The experiments \nwere carried out on two data .les of 15-16 Mb recorded at 144x176 resolution. Both the original and the \noptimized versions of the pro\u00adgram were run 100 times each, at each of several different frame rates. \nIndividual times per event were computed by running each program only 10 times, since each event occurs \na large number of times on each run; during a run of the program about 8000 events 1000 of them asynchronous \nare raised. The execution time re\u00adported in each case is the average of the run times so obtained. The \nevent graph for this application contains 18 distinct events as shown in .gure 5. Each event has 2 4 \nevent handlers, with a total of 54 handlers in the program. Figures 10 and 11 show the effects of optimizing \nthe video player example on the laptop. The event processing times reported in .g\u00adure 11 were measured \nwhen running the program with frame rate of 10 frames/second, while .gure 10 shows the impact of the \nopti\u00admization on the total execution time of the program. Event Adapt has 2 handlers, while events SegFromUser \nand Seg2Net have 4 han\u00addlers each. In this experiment, our techniques reduce the time spent in event \nhandlers by 73 88%. Event processing accounts for about 10 15% of the total time, while I/O accounts \nfor about 60%. There is a concomitant improvement in the overall execution time, as shown in .gure 10, \nranging from 2.3% at a frame rate of 10 to about 11% for a frame rate of 25. The reason that the impact \nof the Total Execution Time (sec) Event Handler Time (sec) Frame rate Orig. (To) Opt. (Tl) Tl/To(%) \nOrig. (To) Opt. (Tl) Tl/To(%) 10 43.1 41.9 97.2 2.3 0.9 39.1 15 30.9 30.3 98.0 1.6 0.6 37.5 20 24.5 22.1 \n90.2 1.5 0.5 33.3 25 23.9 21.3 89.1 1.5 0.5 33.3 Key: Orig: Original program; Opt: Optimized program \nFigure 10: Video player optimization results. Event Processing Time (fsec) Speedup Original Optimized \n(%) Adapt 55 11 80.0 SegFromUser 346 41 88.2 Seg2Net 137 37 73.0 Figure 11: Event processing times in \nthe video player.  optimization on overall execution time becomes more pronounced as the frame rate \nincreases is that when the frame rate is low, the CPU is idle a large part of the time. As a result, \nthe unoptimized program can simply use a bit more of the idle time to keep up with the required frame \nrate. However, when the frame rate increases, both programs must do more work in a time unit and the \nidle time decreases. When the frame rate becomes high enough, the unopti\u00admized program runs out of extra \nidle time and starts falling behind the optimized program. This indicates that our optimizations are \nespecially effective for mobile systems such as handheld PDAs that tend to have less powerful processors \nthan desktop systems. SecComm is a con.gurable secure communication service that allows the customization \nof security attributes for a communica\u00adtion connection, including privacy, authenticity, integrity, and \nnon\u00adrepudiation. One of the features of SecComm is its support for implementing a security property using \ncombinations of basic se\u00adcurity micro-protocols. We optimized a con.guration of SecComm with three micro-protocols, \ntwo of which encrypt the message body (DES and a trivial XOR with a key) and the third that coordinates \nthe execution of the other two. SecComm is a much simpler com\u00adposite protocol than CTP and the video \nplayer, and the event behav\u00adior in this particular SecComm con.guration turns out to be quite predictable. \nIn particular, there is one event chain on the sender and one chain on the receiver. The majority of \nthe execution time in SecComm is spent in the cryptographic encryption and decryp\u00adtion routines. The \nSecComm measurements were performed on the desktops, as follows: .rst a dummy message was sent to initial\u00adize \nthe micro-protocols, after which a message was sent 100 times. This was repeated for different packet \nsizes, for a total of 1000 mes\u00adsages per packet size. The time reported in each case is the average of \nthe run times so obtained. Figure 12 shows the amount of time spent in the push and pop portions of SecComm \nbefore and after optimization. The push portion encompasses the message processing from the time it is \npassed to SecComm by the application until it is passed to the UDP socket. The pop portion encompasses \nthe message processing from the time it is received from the socket until SecComm passes it to the higher \nlayer (the application). The push portion includes the time taken by the encryption operations, whereas \nthe pop portion includes the decryption time. The time taken depends on the size of message packets, \nwhich is re.ected in the results. It can be seen that the time for the push portion is reduced markedly \nin most cases, with improvements of up to 13.3%. The improvements in the pop portion are also noticeable \nalthough not as high as for the push por\u00adtion, typically around 5% but going as high as 12%. An examination \nof the effects of our optimizations on these two programs indicates two main sources of bene.ts: the \nreduction of argument marshaling overhead when invoking event handlers, and handler merging that leads \nto a reduction in the number of han\u00addler invocations. The elimination of marshaling overhead seems to \nhave the largest effect on the overall performance improvements achieved. The main effect of handler \nmerging is to reduce the number of function calls between handlers that are executed in se\u00adquence. Merging \nalso creates opportunities for additional code im\u00adprovements due to standard compiler optimizations. \nCode in event handlers is usually a small fraction of the total program size. To measure the effects \nof our optimization on code size, we counted the number of instructions in the original and op\u00adtimized \nprograms using the command objdump -d program | wc -l. Our optimizations produce a code size increase \nof 1.3% for the video player and 1.1% for SecComm.  4.3 X clients X clients tend to be user driven, \nspending much of their time in the event loop waiting for user input. Hence, our focus in the case of \nthese programs is to improve the event response time, i.e., the time taken to handle an event. Common \napplications like gvim ex\u00adhibit several examples of multiple handlers binding to single events and hence \nare good candidates for applying such optimizations. This section is indicative of the potential of our \ntechniques. We evaluated our ideas on the xterm application provided with XFree86 and gvim. The effects \nof our optimizations on these pro\u00adgrams running on the laptop are shown in .gure 13. These numbers were \nobtained by raising the events 250 times. Popup represents the Menu Popup that is triggered by CTRL + \nMOUSE BUTTON in an xterm window. When handling this event, two action handlers are triggered in sequence. \nThe .rst initializes the menu object. This procedure is speci.c to the type of GUI toolkit and in our \ncase uses the SimpleMenu widget in the Athena Toolkit. The next action handler is responsible for constructing \nand displaying the menu. This action handler in turn invokes two call\u00adbacks to track mouse motion within \nthe menu. Our optimizations merge these two action handlers as described above. The Scroll event corresponds \nto motion of the scrollbar in a gvim window. Handling this event also involves two action handlers that \nmove the thumb1 and update the new position. The .rst action handler uses the underlying framework to \nget the co-ordinates of the thumb. The second is responsible for displaying the new position of the thumb \non the screen. Both these action handlers invoke callbacks tied to corresponding widgets. It can be seen \nthat the optimizations reduce the cost of Scroll by l Thumb here refers to a portion of the scrollbar. \n  64 128 256 512 1024 2048 274 287 304 336 430 572 241 263 273 299 373 552 88.0 91.6 89.8 89.0 86.7 \n96.5 397 460 484 494 608 1016 378 448 457 470 570 893 95.2 97.4 94.4 95.1 93.8 87.9 Figure 12: Impact \nof optimization in SecComm  Scroll 158 148 93.7 Popup 37 31 83.8 Figure 13: Optimization of X events \nabout 6% and that of Popup by over 16%. These techniques were applied here at the level of action handlers, \nalthough it would be possible to optimize one step further by opening up callbacks in the same way. These \noptimizations were performed using the Athena widget family based on Xt and Xlib provided with XFree86. \nThe Athena toolkit is a minimal toolkit with limited con.gurability, and there\u00adfore provided limited \nscope for applying our optimizations. The event model in more recent (and popular) toolkits such as Gnome \nGTK and KDE Qt provides functionality such as signals and slots that is very similar to the Cactus event \nmodel. Such functionality greatly increases the ease of use and development of client appli\u00adcations, \nbut increases the cost of event handling signi.cantly. Ap\u00adplication of our optimization techniques to \nthese systems would reduce these costs and make event handling through signals and similar mechanisms \nno more expensive than ordinary event han\u00addling, while signi.cantly enhancing ease of programming.  \n 5. POSSIBLE EXTENSIONS A number of extensions to these optimization techniques are pos\u00adsible. These \nrange from simple extensions and improved automa\u00adtion, to extensions for dealing with the dynamic aspects \nof the event system and with cases where event execution is not quite determin\u00adistic. An example of a \nsimple extension would be to perform han\u00addler merging for all events that have more than one handler \nrather than only the events in frequently executed event chains. Improved automation includes such items \nas developing toolkits for instru\u00admenting the code to do pro.ling and for generating the optimized code. \nAs noted, the ability in event-based programs to change execu\u00adtion behavior dynamically by, for example, \naltering event bindings is a challenge for an optimization approach based on identifying and utilizing \npredictable behavior. Our current approach is based on detecting any change in event bindings and falling \nback to the original code for any events affected by the change. A better ap\u00adproach would be to construct \nthe super-handler so that it can be used even if some of the bindings change. For example, consider a \npredictable event sequence (A,B,C,D) that has been optimized into one super handler (ABCD). If the handlers \nfor B change, the cur\u00adrent approach falls back to the original code for this entire event sequence and \nall of the performance improvement achieved by the ... if event binding for event B changed { call(original \ncode for event B); }else { merged, inlined, and optimized code for event B; } ... Figure 14: Extended \nsuper-handler for dynamic system optimization are lost. Alternatively, we could organize the (ABCD) super-handler \ninternally so that the code corresponding to different events is partitioned as illustrated for event \nB in .gure 14. Then, even if the event binding for event B changes, the optimized version can still be \nused for events A, C, and D. Other techniques could be used to extend the scope of the opti\u00admizations \nbeyond just predictable event chains. For instance, once all event chains have been optimized, the result \nis a reduced graph with no event chains. This reduced graph can be optimized further using a speculative \napproach. In this scheme, if event A is followed by B 90% of the time and C 10% of the time, free cycles \nduring the execution of A s handlers can be used to initialize the execution of B s handlers. Value-based \noptimization as suggested in [17] can also be extended to increase the accuracy of prediction. Another \nstrategy would be to perform minimal processing for A and defer the bulk of handling A until the next \nevent occurs. If the next event is B, optimized code for (AB) can then be executed. This type of deferral \nwould be particularly useful in a situation where event A is followed by B or C with equal probability. \nHeavier optimizations such as dominator / post-dominator analysis can be used to detect co-relations \nbetween events. Finally, another possible extension is to explore optimizing asyn\u00adchronously activated \nevents. As noted above, the current optimiza\u00adtion can only address event paths in which all activations \nbut the initial one are synchronous. An asynchronous activation by de.ni\u00adtion has much looser semantics \nthan a synchronous activation the handlers bound to this event must simply be executed some time after \nthe event has been activated. Although these semantics make it dif.cult to create an optimized program \nthat has identical behav\u00adior to an unoptimized one, it should be possible to generate one that executes \nthe events and handlers in an order that is consistent with the semantics of event operations. In particular, \nif an asynchronous activation of an event A is always eventually followed by the acti\u00advation of event \nB, it may be possible to merge the handlers of A and B in certain cases. We intend to explore program \ntransformations of this type. 6. RELATED WORK Only a small number of papers have addressed compilation \nori\u00adented optimization of event-based systems. Chambers et al. discuss the use of dynamic compilation \nto optimize event dispatching in the SPIN operating system [5]. Unlike our work, which uses pro.le\u00adbased \nstatic optimizations, the work of Chambers et al. relies on optimizations that are carried out during \nexecution. As with other dynamic optimization systems (e.g., Dynamo [2], Tempo [7]), the bene.ts of dynamic \noptimization have to be balanced against the overheads associated with runtime monitoring, optimization, \nand code generation. Because of this, dynamic code optimization sys\u00adtems generally rely on lightweight \noptimizations. In contrast, the optimizations used here are fairly heavyweight, with a correspond\u00adingly \nhigher payoff. Type feedback [1], which is used to reduce the overheads associated with virtual function \ncalls, is perhaps the closest counterpart in the object-oriented programming language domain. This approach \ninvolves monitoring individual call sites at runtime and using this information to predict and in turn \noptimize likely receiver types. Events and their variants have traditionally been used for inter\u00adaction \nbetween different layers of systems software. For example, Ensemble [9] uses events for communication \nbetween layers in a protocol stack. Ensemble protocol stacks are typically deep since they consist of \nsmall modules, each of which implements a spe\u00adci.c function. Ensemble focuses optimizations on the common \nse\u00adquence of operations (the normal case) that occur in a protocol stack. Each such sequence, called \nan event trace, is triggered by an event such as receipt of a message. The common operations are .rst \nannotated by the protocol designer. The code in an event trace is then optimized into one trace handler \nusing techniques rang\u00ading from eliminating intermediate events to inlining and traditional compiler optimization. \nMoreover, each event trace has a trace con\u00addition that must hold for the trace handler to be executed. \nThese conditions are speci.ed using predicates that are again provided by the protocol designer. In comparison, \nour approach does not require the protocol designer to provide any annotations or predi\u00adcates. Furthermore, \nour focus is on providing generally applicable optimization techniques for event-based systems rather \nthan for any one speci.c system or type of system. Also related to our work is research into program \nspecialization of the type done by Synthesis [22] and Synthetix [21] for operating systems. The primary \ndisadvantage of such systems is the resulting loss of portability and maintainability. While the above \nsystems used manual specializations, automated specialization approaches have also been described [15]. \nMost of these approaches rely on partial evaluation based on knowing the input values. In contrast, we \nuse program pro.ling to identify optimizable parts of the pro\u00adgram. Our technique can be thought of as \npro.le directed spe\u00adcialization and could easily be extended to all classes of programs optimizable through \nprevious specialization efforts. Event-based architectures are gaining popularity in designing complex \nsoftware systems. Event-based web servers of the SEDA project [23] outperform their thread-based counterparts \nin terms of responsiveness and scalability. This approach partitions a sys\u00adtem into many logically independent \nstages, where the different stages communicate using events. Each stage is serviced by its own thread \npool. Conceptually, this is in some sense the opposite of our approach, which attempts to reduce the \nnumber of events in the program. The primary difference is the targeted system ar\u00adchitecture. While our \nwork targets small single processor, possibly single-threaded, systems as expected on a mobile device, \nSEDA targets high-end server architectures with several SMPs. SEDA gains its performance improvement \nfrom maximizing parallelism by exploiting free cycles available on the SMPs, which improves performance \nby releasing a processor as soon as possible. Our ap\u00adproach gains by using traditional program optimization \ntechniques, such as eliminating procedure calls and other redundant code. Our performance results from \n.gure 10 partially con.rm the .ndings in [23]. When the frame rate is very low, our optimizations ac\u00adtually \nincrease the execution time slightly because locks are held longer by super-handlers, resulting in starvation \nof other threads even though the CPU utilization is low. As the frame rate and CPU utilization increase, \nhowever, the effect of our optimizations becomes more pronounced until a point is reached where system \nthroughput becomes the limiting factor. Finally, ILP (Integrated Layer Processing) [6] can be viewed \nas related work. ILP integrates data manipulation across protocol lay\u00aders to minimize memory references \nby merging the message data manipulation done on different layers into one loop where each data item \nis accessed only once. This technique can be used, for example, to merge encryption, checksum computation, \ncompres\u00adsion, and presentation formatting into one loop. Our optimizations do not speci.cally attempt \nto reduce memory references related to accessing message data, so ILP could in principle be added as \nan additional optimization technique to our approach. Note that pro\u00ad.ling the memory references in a \nsuper-handler the same way we pro.le events and handlers could automate the process of .nding candidate \ncode for ILP optimization. 7. CONCLUSION Event-based programs are used in a variety of domains due to \ntheir .exibility, yet have the disadvantage of potentially high per\u00adformance overhead. Due to the dynamic \nnature and unpredictabil\u00adity of events which events occur and when and event bindings which handlers \nare bound to an event when it is raised compiler optimization techniques have not traditionally been \nused in this do\u00admain. However, in this paper, we have described how such tech\u00adniques can in fact be applied \nby exploiting the underlying pre\u00addictability often exhibited by such programs. Our approach is based \non pro.ling the program to identify commonly occurring event se\u00adquences, and then applying a variety \nof techniques to reduce the overheads associated with such things as indirect function calls and argument \nmarshaling. Experimental results from event-based pro\u00adgrams written for Cactus and X Windows suggest \nthat the scope of possible improvement can be signi.cant. Our overall goal in this work is to reduce \nthe overhead of event-based execution to the point where the performance of such programs is competitive \nwith more traditionally structured alternatives. Acknowledgments K. H\u00a8ogstedt, W.-K. Chen, and the anonymous \nreferees provided excellent suggestions that improved the paper. P. Bridges provided assistance with \nthe Cactus video program. The work of S. Debray was supported in part by NSF under grants CCR-0073394, \nEIA\u00ad0080123, and CCR-0113633. The work of the other authors was supported in part by DARPA under grant \nN66001-97-C-8518 and by NSF under grants ANI-9979438 and CCR-9972192. 8. REFERENCES [1] G. Aigner and \nU. Holzle. Eliminating virtual function calls in C++ programs. In ECOOP 96 Conference Proceedings, Springer \nVerlag LNCS 1098, pages 142 166, 1996. [2] V. Bala, E. Duesterwald, and S. Banerjia. Dynamo: A transparent \ndynamic optimization system. In SIGPLAN 00 Conference on Programming Language Design and Implementation, \npages 1 12, 2000. [3] T. Ball and J. R. Larus. Optimally pro.ling and tracing programs. ACM Transactions \non Programming Languages and Systems, 16(4):1319 1360, July 1994. [4] N. Bhatti, M. Hiltunen, R. Schlichting, \nand W. Chiu. Coyote: A system for constructing .ne-grain con.gurable communication services. ACM Transactions \non Computer Systems, 16(4):321 366, Nov 1998. [5] C. Chambers, S. Eggers, J. Auslander, M. Philipose, \nM. Mock, and P. Pardyak. Automatic dynamic compilation support for event dispatching in extensible systems. \nIn Proceedings of the 1996 Workshop on Compiler Support for Systems Software (WCSSS-96), Feb 1996. [6] \nD. Clark and D. Tennenhouse. Architectural Considerations for a New Generation of Protocols. In SIGCOMM \nSymposium on Communications Architectures and Protocols, pages 200 208, Philadelphia, PA, September 1990. \nACM. [7] C. Consel, L. Hornof, J. Lawall, R. Marlet, G. Muller, J. Noy, S. Thibault, and E.-N. Volanschi. \nTempo: Specializing systems applications and beyond. ACM Computing Surveys, Symposium on Partial Evaluation \n(SOPE 98), 30(3), Sep 1998. [8] Microsoft Corporation. Microsoft Visual Basic 6.0 Programmer s Guide. \nMicrosoft Press, Aug 1998. [9] M. Hayden. The Ensemble system. Technical Report TR98-1662, Department \nof Computer Science, Cornell University, Jan 1998. [10] M. Hiltunen, R. Schlichting, X. Han, M. Cardozo, \nand R. Das. Real-time dependable channels: Customizing QoS attributes for distributed systems. IEEE Transactions \non Parallel and Distributed Systems, 10(6):600 612, Jun 1999. [11] M. Hiltunen, R. Schlichting, and C. \nUgarte. Enhancing survivability of security services using redundancy. In Proceedings of the International \nConference on Dependable Systems and Networks (DSN 2001), pages 173 182, Gothenburg, Sweden, Jul 2001. \n[12] M. Hiltunen, R. Schlichting, and G. Wong. Cactus system software release. http://www.cs.arizona.edu/cactus/software.html, \nDec 2000. [13] J. R. Larus. Whole program paths. In Proceedings of the ACM SIGPLAN 99 Conference on Programming \nLanguage Design and Implementation (PLDI-99), pages 259 269, Atlanta, Georgia, May 1 4, 1999. [14] R. \nMarlet, S. Thibault, and C. Consel. Ef.cient implementations of software architectures via partial evaluation. \nJournal of Automated Software Engineering (J.ASE), 6(4):411 440, Oct 1999. [15] D. McNamee, J. Walpole, \nC. Pu, C. Cowan, C. Krasic, A. Goel, P. Wagle, C. Consel, G. Muller, and R. Marlet. Specialization tools \nand techniques for systematic optimization of system software. In ACM Transactions of Computer Systems, \nVol 19, No 2, pages 217 251, May 2001. [16] H. Miranda, A. Pinto, and L. Rodrigues. Appia, a .exible \nprotocol kernel supporting multiple coordinated channels. In Proceedings of the 21st International Conference \non Distributed Computing Systems, pages 707 710, Phoenix, AZ, Apr 2001. [17] R. Muth, S. A. Watterson, \nand S. K. Debray. Code specialization based on value pro.les. In Static Analysis Symposium, pages 340 \n359, 2000. [18] A. Nye and T. O Reilly. X Toolkit Intrinsics Programming Manual. O Reilly and Associates, \n1992. [19] Object Management Group. Event Service Speci.cation (Version 1.1), March 2001. [20] J. Ousterhout. \nWhy threads are a bad idea (for most purposes). In 1996 USENIX Technical Conference, Jan 1996. Invited \nTalk. [21] C. Pu, T. Autrey, A. Black, C. Consel, C. Cowan, J. Inouye, L. Kethana, J. Walpole, and K. \nZhang. Optimistic incremental specialization: Streamlining a commercial operating system. In Proceedings \nof the 15th ACM Symposium on Operating Systems Principles (SOSP 95), pages 314 324, Copper Mountain, \nCO, Dec 1995. [22] C. Pu, H. Massalin, and J. Ioannidis. The Synthesis kernel. Computing Systems, 1(1):11 \n32, 1988. [23] M. Welsh, D. Culler, and E. Brewer. SEDA: An architecture for well-conditioned, scalable \ninternet services. In Proceedings of the Eighteenth Symposium on Operating Systems Principles (SOSP-18), \nBanff, Canada, Oct 2001. [24] G. Wong, M. Hiltunen, and R. Schlichting. A con.gurable and extensible \ntransport protocol. In Proceedings of the 20th Annual Conference of IEEE Communications and Computer \nSocieties (INFOCOM 2001), pages 319 328, Anchorage, Alaska, Apr 2001. [25] Y. Zhang and R. Gupta. Timestamped \nwhole program path representation and its applications. In Proceedings of the ACM SIGPLAN 01 Conference \non Programming Language Design and Implementation (PLDI-01), pages 180 190, June 20 22 2001.  \n\t\t\t", "proc_id": "512529", "abstract": "Events are used as a fundamental abstraction in programs ranging from graphical user interfaces (GUIs) to systems for building customized network protocols. While providing a flexible structuring and execution paradigm, events have the potentially serious drawback of extra execution overhead due to the indirection between modules that raise events and those that handle them. This paper describes an approach to addressing this issue using static optimization techniques. This approach, which exploits the underlying predictability often exhibited by event-based programs, is based on first profiling the program to identify commonly occurring event sequences. A variety of techniques that use the resulting profile information are then applied to the program to reduce the overheads associated with such mechanisms as indirect function calls and argument marshaling. In addition to describing the overall approach, experimental results are given that demonstrate the effectiveness of the techniques. These results are from event-based programs written for X Windows, a system for building GUIs, and Cactus, a system for constructing highly configurable distributed services and network protocols.", "authors": [{"name": "Mohan Rajagopalan", "author_profile_id": "81100428238", "affiliation": "University of Arizona, Tucson, AZ", "person_id": "PP31041865", "email_address": "", "orcid_id": ""}, {"name": "Saumya K. Debray", "author_profile_id": "81100148240", "affiliation": "University of Arizona, Tucson, AZ", "person_id": "P260625", "email_address": "", "orcid_id": ""}, {"name": "Matti A. Hiltunen", "author_profile_id": "81100627653", "affiliation": "AT&T Labs-Research, Florham Park, NJ", "person_id": "P194877", "email_address": "", "orcid_id": ""}, {"name": "Richard D. Schlichting", "author_profile_id": "81100062290", "affiliation": "AT&T Labs-Research, Florham Park, NJ", "person_id": "P242928", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512529.512543", "year": "2002", "article_id": "512543", "conference": "PLDI", "title": "Profile-directed optimization of event-based programs", "url": "http://dl.acm.org/citation.cfm?id=512543"}