{"article_publication_date": "05-17-2002", "fulltext": "\n Beltway: Getting Around Garbage Collection Gridlock Stephen M Blackburn* Richard Jones Dept. of Computer \nScience Computing Laboratory Australian National University University of Kent Canberra, ACT, 0200, Australia \nCanterbury, Kent, CT2 7NF, UK Steve.Blackburn@cs.anu.edu.au R.E.Jones@ukc.ac.uk ABSTRACT We present \nthe design and implementation of a new garbage collec\u00adtion framework that signi.cantly generalizes existing \ncopying col\u00adlectors. The Beltway framework exploits and separates object age and incrementality. It groups \nobjects in one or more increments on queues called belts, collects belts independently, and collects \nin\u00adcrements on a belt in .rst-in-.rst-out order. We show that Beltway con.gurations, selected by command \nline options, act and perform the same as semi-space, generational, and older-.rst collectors, and encompass \nall previous copying collectors of which we are aware. The increasing reliance on garbage collected languages \nsuch as Java requires that the collector perform well. We show that the generality of Beltway enables \nus to design and implement new col\u00adlectors that are robust to variations in heap size and improve to\u00adtal \nexecution time over the best generational copying collectors of which we are aware by up to 40%, and \non average by 5 to 10%, for small to moderate heap sizes. New garbage collection algorithms are rare, \nand yet we de.ne not just one, but a new family of col\u00adlectors that subsumes previous work. This generality \nenables us to explore a larger design space and build better collectors. Categories and Subject Descriptors \nD.3.4 [Programming Languages]: Processors Memory manage\u00adment (garbage collection)  General Terms Design, \nPerformance, Algorithms  Keywords Beltway, copying collection, generational collection, Java 1. Introduction \nGarbage collection (GC) automates the reclamation of memory that the program can no longer access. In \nobject-oriented languages, .This author did this work while at the University of Mas\u00adsachusetts. This \nwork is supported by NSF ITR grant CCR\u00ad0085792, NSF grant ACI-9982028, DARPA grants F30602-98\u00ad1-0101 \nand F33615-01-C-1892, EPSRC grant GR/R42252, and IBM. Any opinions, .ndings, conclusions, or recommendations \nex\u00adpressed in this material are the authors and do not necessarily re\u00ad.ect those of the sponsors. Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 02, June 17 \n19, 2002, Berlin, Germany. Copyright 2002 ACM 1-58113-463-0/02/0006 ...$5.00. Kathryn S McKinley J Eliot \nB Moss Dept. of Computer Sciences Dept. of Computer Science University of Texas at Austin University \nof Massachusetts Austin, TX, 78712, USA Amherst, MA 01003-4610, USA mckinley@cs.utexas.edu moss@cs.umass.edu \nGC improves programming productivity by reducing errors that re\u00adsult from explicit memory deallocation, \nand underpins sound soft\u00adware engineering principles of abstraction and modularity. Current GC algorithms, \nhowever, still have a performance overhead. Fig\u00adure 1(a) plots the fraction of time that six SPEC Java \nprograms spend in GC as a function of heap size, using a high performance generational copying collector \n[3] in the Jikes RVM [1, 2]. When heap space is tight, GC can comprise 35% of execution time. Ap\u00adplications \nmay reduce this cost simply by using a larger heap which decreases the load on the collector. However, \nas shown by Fig\u00adure 1(b) and by other research [10], the best total execution time is not always achieved \nwhen GC time is minimized by large heap sizes. Application cache, memory, and TLB locality may degrade \nwith large heaps. For example, paging degrades pseudojbb s per\u00adformance at the large heap sizes in Figure \n1(b). Thus, achieving high performance remains a challenge, especially for programs and workloads with \nlarge memory requirements. In more than forty years of research, a few key insights have shaped copying \ngarbage collection. (1) The weak generational hypothesis that most objects die young underpins generational \ngarbage collectors, which preferentially collect the youngest ob\u00adjects [34]. (2) As a corollary to this \nobservation, generational col\u00adlectors avoid collecting old objects. (3) Using incrementality to improve \nresponse time has led to the use of small nursery genera\u00adtions and to incremental algorithms [13, 24]. \n(4) Researchers also use small nurseries and copying collectors to improve data local\u00adity [25, 38]. (5) \nMore recently, Stefanovi\u00b4c et al. demonstrate that giving the very youngest objects time to die can improve \ncollector performance [32]. The Beltway collection framework is the .rst to combine and ex\u00adploit all \n.ve insights .exibly and ef.ciently. In addition, Beltway generalizes over previous work: we can con.gure \nBeltway to be\u00adhave as every other region-based copying collectors of which we are aware. A Beltway collector \nuses increments and belts as shown in Figure 2. An increment is the unit of collection. A belt groups \none or more increments into a .rst-in-.rst-out (FIFO) queue. Belt\u00adway collects each increment on a belt \nindependently in FIFO order, and also collects each belt independently. The promotion policy determines \nwhere to copy surviving objects, whether to the same or to another belt. Increments make belts more general \nthan gen\u00aderations since all objects within a generation must be collected en masse, but we collect increments \nindependently and there may be multiple increments on a belt. We demonstrate Beltway con.gu\u00adrations (from \ncommand line parameters) that behave as semi-space collectors, traditional generational copying collectors \n[34, 3], and older-.rst collectors [32]. To our knowledge, Beltway con.gura\u00adtions match all previous \ncopying collector organizations. We further show that this generality enables us to combine all 50% 45% \n40% 35% 30% 25% 20% 15% 10% 5% 0% Total time relative to best result (lower is better) Percentage of \ntime spent in GC (a) Percentage of time spent in GC. 1.5 1.45 1.4 1.35 1.3 1.25 1.2 1.15 1.1 1.05 1 \nHeap size relative to minimum heap size (log) (b) Total application performance. Figure 1: The impact \nof heap size on the performance of six SPEC benchmarks using the Appel-style generational collector. \nOptimal performance is not always attained at the largest heap size. the above ideas within a single \ncollector. We present the design and implementation of a range of copying collectors that exploit the \nhigh mortality of young objects, can avoid collecting the very youngest objects, avoid collecting previously \ncopied objects, and perform collection incrementally. Our generality increases pointer tracking costs \nbut we develop several novel mechanisms to bound these costs. For instance, we maintain the fewest possible \ncross\u00adincrement pointers, and we can trigger collections when the number of cross-increment pointers \nexceeds a threshold. We show several con.gurations that reduce garbage collection costs via reduced copying \nand better heap utilization compared to the best generational copying collector of which we are aware \n[3]. These reductions improve total execution time over generational collectors by an average of 5 to \n10%, and up to 35% on tight heaps, for 6 Java SPEC programs. Our new collectors thus use resources more \neffectively than generational collectors. We also present ev\u00adidence that our framework enables us to \nexplore the tradeoff be\u00adtween responsiveness and throughput, but we leave a more thor\u00adough investigation \nof responsiveness to future work. The remainder of the paper is organized as follows. We .rst present \nthe Beltway framework for exploring copying collection and the program characteristics that it exploits. \nSection 3.1 shows how to con.gure Beltway to implement a variety of copying collec\u00adtors. We then present \ntwo new collectors designed to reduce total execution time. Section 3.3 introduces several novel mechanisms \n2 survivors 1 allocation 0 survivors 2 1 allocation 0 2 survivors 1 allocation 0 Figure 2: A Beltway \ncon.guration with three belts, showing three successive collections (top to bottom). The light arrows \nshow allo\u00adcations going into the nursery, and darker arrows represent copying surviving objects from \nthe target to the source increments. Darker objects are younger. that make our collectors ef.cient. Section \n4 compares these col\u00adlectors to generational collectors and demonstrates that they reduce GC time and \ntotal execution time on 6 Java programs. Section 4.3 offers some sample responsiveness results. We .nd \nthat reduced total execution time can also be combined with improved respon\u00adsiveness, but this area needs \nfurther exploration. We then present related work and conclude. 2. Generalizing Copying Garbage Collection \nThe novelty of the Beltway framework is that it generalizes over copying collection by combining all \nthe key ideas of copying GC in a single collector. This section .rst outlines these ideas. We then describe \nthe Beltway framework and how it exploits the ideas. 2.1 Key Ideas in Copying GC Most objects die young. \nThe weak generational hypothesis is the basis for generational garbage collection [34]. A generational \ncollector divides the heap into regions called generations that con\u00adtain progressively more mature objects. \nThe youngest generation, called the nursery, is likely to contain a large fraction of dead ob\u00adjects and \nso is most frequently targeted for collections. The col\u00adlector promotes objects that survive by copying \nthem into the next generation. Avoid collecting old objects. A corollary is that those objects that do \nnot die young tend to be long lived, suggesting that older generations should be collected less frequently. \nGive objects time to die. A further observation is that while most objects die young, all objects require \nsome time to die. The older-.rst collector [32] exploits this observation by avoiding col\u00adlecting the \nvery youngest objects. Incrementality improves responsiveness. Length and frequency of collection limits \nthe responsiveness of garbage collected pro\u00adgrams. Generational collectors reduce average pause time \nby re\u00adpeatedly collecting the nursery, and occasionally collecting the whole heap. They therefore tend \nnot to improve on worst case pause time. Other algorithms are more aggressively incremental. For example, \nthe Mature Object Space collector [24] collects only one increment at a time and never collects the whole \nheap. Copying GC can improve locality. Programs often access ob\u00adjects of a similar age together [20]. \nCopying collectors exploit this pattern to improve locality with consequent bene.ts for cache and TLB \nbehavior [38]. Collectors copy older objects near to each other in the heap. This clustering reduces \nthe incidence of point\u00aders that span regions of the heap, and thus avoids retaining dead objects simply \nbecause they are referenced by a dead object in an uncollected region [35]. The nursery attains locality \nby keeping the youngest and most frequently accessed objects near each other. Previously, no collector \nhas exploited all of these ideas together. Simple semi-space collectors improve locality through copying, \nbut do not exploit any of the other ideas. Generational collectors do not give the very youngest objects \ntime to die and must occasionally collect the whole heap, so are not fully incremental. The older-.rst \ncollector cannot always avoid frequent copying of old objects, and because it does not collect the whole \nheap it is not complete, i.e., it cannot guarantee it will collect all garbage. 2.2 Beltway Collectors \nBeltway collectors depend on two very simple organizational prin\u00adciples. An increment is an independently \ncollectible region of mem\u00adory. A belt is a grouping of one or more increments, collected in strict FIFO \norder (analogous to conveyor belts). By selecting dif\u00adferent increment sizes, belt organizations, and \npromotion policies, a collector in the Beltway framework can be con.gured to imple\u00adment any of the well-known \ncopying collection algorithms. Figure 2 shows a Beltway collector with three belts, each with one or \nmore increments. This collector promotes survivors from each increment in to the next higher belt. It \ncopies survivors in the highest belt to the end of that belt. New allocations go to the last increment \nin the lowest, nursery belt. A Beltway collector can exploit each of the .ve ideas outlined above as \nfollows. Belts generalize over generations by decoupling incrementality from the generation size. Thus, \nthe lowest belt is analogous to the nursery in a generational collector. By preferen\u00adtially collecting \nincrements from the nursery belt, we exploit the weak generational hypothesis and avoid collecting old \nobjects. Be\u00adcause Beltway decouples collection and belts, it can be arbitrarily incremental. Because \nthe oldest increment on a belt will always be collected .rst (FIFO order), Beltway can give objects time \nto die. Finally, the copying, generational, and incremental aspects of Belt\u00adway improve the locality \nof surviving objects, and provide locality for the youngest objects by allocating them together in the \nnursery.  3. Concrete Instances of Beltway Collectors To demonstrate the generality of the Beltway \nframework, we de\u00adscribe Beltway con.gurations that correspond exactly to well-known copying collectors. \nWe then describe two new collectors, and the novel mechanisms that are key to implementing these new \ncollec\u00adtors ef.ciently. 3.1 Modeling Existing Copying Collectors One factor in common among all copying \ncollectors is that they must hold in reserve suf.cient memory to accommodate a collec\u00adtion of the largest \npossible increment. This copy reserve space must be large enough to accommodate the worst case survival \nfor a col\u00adlection, i.e. when all objects survive.1 If the copy reserve is .xed at half the heap, as it \nis in the semi-space collector and generational collector implementations, heap utilization and ef.ciency \ncan suf\u00adfer. In the remainder of this section we use the term usable memory to refer to the total heap \nspace less the appropriate copy reserve for that collector. Semi-space collectors are the simplest copying \ncollectors [12]. They correspond to a trivial Beltway con.guration: a single belt containing a single \nincrement, as large as the usable memory, col\u00adlected whenever it is full, as shown in Figure 3(a). We \ncall this con.guration BSS, Beltway Semi-Space. BSS copies survivors into a new increment on the same \nbelt. Appel-style generational collectors have two generations [3]. They make ef.cient use of memory \nby allowing the nursery to grow to consume all usable memory not consumed by the higher genera\u00adtion. \nConsequently, they collect the nursery only when both gener\u00adations consume all usable memory. Appel corresponds \nto Beltway con.gured with two belts, each with one increment capable of ac\u00adcommodating all usable memory, \nas depicted in Figure 3(b). We call this con.guration BA2, Beltway Appel with two generations. Whenever \nthe two increments consume all usable memory, BA2 collects the nursery increment, copying survivors to \nthe higher belt. When the higher increment consumes all usable memory, BA2 col\u00adlects it, copying survivors \nto a new increment on the same belt. (In practice, if the nursery size drops below some small .xed threshold, \nthe heap is considered full.) Older-First Mix algorithms are an incremental variation on the semi-space \ncollector [19, 31]. They are called older-.rst mix be\u00adcause they mix copies and newly allocated objects \nin memory. This Beltway con.guration, BOFM, shown in Figure 3(c), has one belt and multiple increments. \nBOFM both allocates and copies sur\u00advivors to the last increment on the belt, triggering collection when \nthe increments consume all usable memory. Older-First collectors organize the heap by object age [32]. \nThey collect a .xed-size window that slides through the heap from older to younger objects. When the \nheap is full, OF collects the window, returns any free space to the nursery, and then positions the window \nfor the next collection over objects just younger than those that survived. If it bumps into the allocation \npoint, it resets the window to the oldest end of the heap. This Beltway con.gura\u00adtion, BOF, illustrated \nin Figure 3(d), has an allocation belt A and a copy belt C where increments are the size of the collection \nwindow. BOF allocates to the back of belt A. Whenever all usable memory is consumed, BOF collects the \n.rst increment in belt A, copying survivors to the back of belt C. If all usable space is consumed and \nA is empty, then BOF .ips the belts, collects the .rst increment in the new belt A, and copies its survivors \nto the last increment in the new, now empty, belt C. BOF then continues to allocate to the back of the \nnew belt A.  3.2 New Beltway Con.gurations We now go beyond existing copying collectors and describe \ntwo new collector con.gurations, Beltway X.X and Beltway X.X.100. Beltway X.X collectors add incrementality \nto Appel-style gen\u00aderational collection. They have two belts, and each belt contains increments of maximum \nsize X, conventionally expressed as a per\u00adcentage of usable memory. The two belts correspond to genera\u00adtions, \nand X re.ects the degree of incrementality. As with Appel s collector, the lower, nursery belt grows \nuntil it consumes all re\u00ad 1In fact the copy reserve must be slightly more generous because the copied \ndata may not pack as well as the original data, as an artifact of object alignment and copying order. \nsurvivors allocation survivors 1 allocation 0 (a) BSS (b) BA2 C survivors allocation survivors \nallocation A  (c) BOFM (d) BOF 2 survivors survivors 1 1 allocation allocation  00 (e) Beltway X.X \n(f) Beltway X.X.100 Figure 3: The Beltway con.gurations described in Sections 3.1 and 3.2. Each diagram \nshows a con.guration of belts and increments during the copying of survivors. An arrow indicates the \nallocation that triggered the collection. maining usable space, at which point Beltway X.X collects the \nold\u00adest increment in the nursery. It promotes survivors to the youngest increment in the higher belt. \nWhen the higher belt becomes full, it collects the oldest increment in the higher belt, and copies sur\u00advivors \nto the youngest increment in the same belt. Similar to gener\u00adational collectors, Beltway X.X collects \nthe higher belt only when the higher belt is full and the nursery belt is thus empty. However, it collects \nonly a .xed size increment, rather than the entire belt. Beltway X.X combines most of the features of \nAppel s genera\u00adtional collector and the Older-First collector, and exploits all .ve ideas outlined in \nSection 2.1. In fact, BA2 is a special case of Belt\u00adway X.X where X is set to 100. When X <100, the steady \nstate differs from BA2 as follows. The nursery typically contains one increment that varies in size up \nto size X, and the older belt contains the other increments. To\u00adgether they can occupy no more than the \nusable heap space. For ex\u00adample with X =33, we can have four increments, one partially full and two completely \nfull increments on belt 1, and one partially full increment on belt 0. Our framework and implementation \nalso sup\u00adports Beltway X.Y collectors where X =Y , but we do not explore these con.gurations here. Unfortunately, \nwhen X <100, Beltway X.X lacks completeness: it does not guarantee the eventual collec\u00adtion of all garbage, \nbecause it fails to collect garbage cycles that span more than one increment. Beltway X.X.100 collectors \naddress the failure of Beltway X.X with respect to completeness by retaining the two lower belts with \nincrements of size X :100, and adding a third, highest belt with a single increment that may grow as \nlarge as the usable memory. Any objects Beltway X.X.100 does not reclaim in the lower belts, it promotes \nto the third belt, which it will collect in its entirety only once it has grown to consume all usable \nmemory. It thus guaran\u00adtees eventual collection of large dead structures. This con.guration achieves \ncompleteness at the expense of incrementality (the worst case collection increment is the same as the \nclassic semi-space and generational collectors). Note that when X is equal to 100, Beltway X.X.100 implements \na three-generational Appel-style collector. Section 4 shows that Beltway X.X.100 almost always outper\u00adforms \nthe Appel collector, sometimes by as much as 35% of total benchmark running time. An alternative approach \nto lack of com\u00adpleteness in the Beltway X.X collector is to use a complete, incre\u00admental collector (such \nas the Mature Object Space collector [24]) in place of the third belt, but that investigation is beyond \nthe scope of this work.  3.3 Realizing Ef.cient Beltway Collectors Three broad implementation issues \nare key to the viability of our approach. (1) Incrementality depends heavily on the use of write barriers, \nso the ef.ciency of write barriers and their associated data structures is critical. (2) We found that \nthe best time to collect is not always when the heap is full. To this end, Beltway collectors use collection \ntriggers to preempt identi.able performance problems in later collections. (3) Finally, we exploit a \ndynamically sized copy reserve based on the increment size and heap occupancy, which leads to better \nheap utilization and ultimately better performance. 3.3.1 Frames and Write Barriers In order to collect \nincrements independently and ef.ciently, garbage collectors must remember references into collected increments \nfrom the rest of the heap. A simple semi-space collector avoids the need for any such mechanism by always \ncollecting all usable memory. Generational collectors very cheaply notice and remember the cre\u00adation \nof any references into the nursery from the rest of the heap. For example, they place the nursery in \nhigh memory and observe the creation of any pointers that cross a boundary between high and low memory \n[7]. One also must instrument the mutator, (i.e., the application) with a write barrier to remember relevant \npointers. Beltway collectors implement increments by using frames.A frame is an aligned contiguous region \nof virtual memory that can accommodate an increment. Frames reduce the cost of incremental collection \nin two ways. First, frames are power-of-two aligned in the address space, and we can distinguish inter-frame \npointers from intra-frame pointers using a shift and compare. Second, we main\u00ad tain a number associated \nwith each frame that indicates the frame s relative collection order. When we encounter an inter-frame \nreference, we need to re\u00ad member it only if we might collect the target frame sooner than the source \nframe. We therefore do not record all inter-frame refer\u00ad ences. Further, if an increment spans multiple \nframes marked with the same collection time, we do not store pointers between the con\u00ad stituent frames. \nAlthough the barrier is not address-ordered, it is uni-directional with respect to frames. For example, \nin the BOFM collector (Figure 3), only cross-increment pointers in the right-to\u00ad left direction must \nbe remembered. Figure 4 shows a basic im\u00ad plementation of this frame-based, unidirectional write-barrier. \nWe partially inline the write barrier [7]. 1 public static final void writeBarrier(ADDRESS source, \n2 ADDRESS target) { 3 int s = (source>>>FRAME_SIZE_LOG); 4 int t = (target>>>FRAME_SIZE_LOG); 5 if \n((s != t) // pointer is inter-frame 6 &#38;&#38; (Belt.collect_[t] < Belt.collect_[s])) { 7 // target \nwill be collected before source 8 int rsidx = (s<<REMSET_SHIFT) | t; 9 GCTk_RememberedSet.insert(rsidx, \nsource); 10 }} Figure 4: The basic Beltway frame-based write-barrier.  3.3.2 Remembered Sets The total \nnumber of frames in a con.guration is limited by the in\u00ad crement size, the number of belts, and the total \nusable memory, and is tightly bounded. We can thus maintain distinct remembered sets, remsets, for each \ntarget-source frame pair. At run time, we enter each inter-frame reference in the appropriate set. An \nadvantage of this approach is that we can trivially delete all remsets relating to a frame. We also ignore \nremsets between two increments in the oc\u00ad casional case when we collect them together. For example, given \nsuf.cient copy reserve, if we are about to empty a lower belt and .ll the next higher belt, we will collect \nthe increment on the lower belt together with the .rst increment on the next belt. This opti\u00ad mization \nperforms a single collection, rather than two in immediate succession. Because of the high write-barrier \nactivity in the nursery, we lim\u00ad ited Beltway X.X and Beltway X.X.100 to a single, bounded nursery increment, \nwhich minimizes write-barrier activity. Jikes RVM in\u00ad troduces substantial write barrier overhead due \nto the initializing of each object s type ( TIB ) pointer. The type object is older, usu\u00ad ally much older, \nthan the object. To eliminate this overhead, we use a single nursery increment and extend the basic Beltway \nbar\u00ad rier to .lter any pointers where the source is in the nursery. This optimization foregoes older-.rst \nbehavior within the nursery. Sys\u00ad tems without this overhead should be able to bene.t from multiple nursery \nincrements.  3.3.3 Collection Triggers For a variety of reasons, it is not always best to collect only \nwhen the heap is completely full. For instance, .xed-size nursery col\u00adlectors collect when the nursery \nis full rather than when the heap is full. In this section, we describe a number of collection triggers \nthat de.ne a range of additional conditions that can initiate a garbage collection. We explored three \nmechanisms, nursery, remset, and time-to-die triggers with multiple nursery increments, and believe that \ncon.gurations of Beltway will bene.t from one or more of them. For the Beltway X.X and Beltway X.X.100 \ncon.gurations we report below, only the nursery trigger that limits the nursery to a single increment \nproved useful. Nursery Trigger. The size of the nursery belt may be bounded to ensure that we frequently \ncollect the young objects since many die quickly. An obvious example of this trigger is the classic .xed\u00adsize \nnursery generational collector which limits the nursery to one increment, where the size of that increment \nis always equal the maximum nursery size. In Beltway X.X and Beltway X.X.100,we use this trigger to limit \nthe maximum size, but not the minimum size of a single nursery increment. Remset Trigger. Because remembered \nset entries are collection roots, as the number of remset entries grows, the survival rate for an increment \ngoes up as well as the time to scan the remset itself. A simple and very effective solution to this problem \nis to trigger collection whenever remembered sets grow to some threshold. Time-to-Die Trigger. We may \nwant to collect a nursery in\u00adcrement before it reaches its maximum capacity. For example, an Appel-style \nnursery increment can accommodate all the usable memory, but we often collect the nursery when it is \nonly partially full. By using two increments on the youngest belt rather than one, we can avoid collecting \nthe very youngest objects, which would not yet have had time to die. The time-to-die trigger ensures \nthat all ob\u00adjects will have at least TTD time to die before we collect them (time is measured in bytes \nof allocation). When the heap is within TTD bytes of being full, we can use the time-to-die trigger to \nensure that all new allocations go into the second frame. If the system is allo\u00adcating into the .rst \nincrement, it then starts allocating objects into the second frame. Subsequently, when the heap .lls, \nit collects the .rst frame, which may not be full. This trigger prevents the collec\u00adtors from collecting \nthe objects allocated in the last TTD bytes of allocation (i.e., when they are too young). We believe \nfuture con.gurations of Beltway will be able to ex\u00adploit all these triggers to improve collector performance \nfurther, but we use only the nursery trigger in our results. 3.3.4 Dynamic Conservative Copy Reserve \nAs we pointed out in Section 3.1, all copying collectors need a copy reserve space into which to copy \nsurvivors. In order to avoid failure in the worst case, the copy reserve must be slightly larger than \nthe largest possible collection increment. Since the usable memory is the heap space less the copy reserve, \nit is obviously advantageous to minimize the copy reserve. Finer-grained incremental collec\u00adtors, such \nas Mature Object Space (MOS) collectors or Beltway X.X, where X.100, have a distinct memory utilization \nadvantage because they require only a small copy reserve. Classical genera\u00adtional and semi-space collectors \nmust reserve half the heap. Beltway collectors dynamically calculate a conservative mini\u00admal copy reserve \nthat will always accommodate survivors from the worst case collection sequence. The copy reserve is either \nthe largest increment size, or the largest potential increment occupancy at the next collection. We determine \nmaximum potential occupancy for each increment by adding its current occupancy plus the max\u00adimum occupancy \nof any other increment from which the collector could copy into this one. The dynamic conservative copy \nreserve is particularly effective in the Beltway X.X.100 collector where the third belt is rarely full. \nThe copy reserve is thus usually determined by the smaller incre\u00adment size. As the third belt .lls, the \ncopy reserve grows until it is .nally half of the heap (so that the third belt occupancy and the copy \nreserve are equal in size). After we collect the third belt, the copy reserve automatically falls back \nto a smaller size, thereby con\u00adtinuously maximizing usable memory. Benchmark Description Min. heap size \nTotal allocation GCs 202 jess 205 raytrace 209 db 213 javac 228 jack pseudojbb An expert system shell \nA ray tracing program Simulates a database management system The Sun JDK 1.02 Java compiler compiling \njess Generates a parser repeatedly Emulates a 3-tier transaction processing system 12MB 15MB 22MB 32MB \n20MB 70MB 301MB 127MB 102MB 266MB 320MB 381MB 24 337 9 139 5 115 10 100 16 135 4 126 Table 1: Benchmark \ncharacteristics: minimum heap size, total bytes allocated, and the number of GCs performed by an Appel-style \ncollector at large and small heaps respectively.   4. Results This section describes our experimental \nsetting, including our garbage collector environment, hardware, and benchmarks. We then present GC time \nand total execution time for Beltway and generational col\u00adlectors with a variety of con.guration parameters. \nFinally, we show some sample responsiveness results. 4.1 Experimental Setting Jikes RVM and GCTk. We \nuse Jikes RVM version 2.0.2 for our implementation study. Jikes RVM (formerly Jalape no) is a high performance \nVM written in Java that includes an aggressive opti\u00admizing compiler [1, 2]. We used the Jikes RVM adaptive \ncompiler and its fast build-time con.guration (which omits assertion check\u00ading and pre-compiles as much \nas possible into the Jikes RVM boot image). We have recently developed a new GC toolkit for Jikes RVM \ncalled GCTk, which includes Beltway as well as implementations of previous generational collectors. GCTk \nis an ef.cient and .exi\u00adble platform for GC experimentation that exploits the object-orientation of Java \nand the VM-in-Java property of Jikes RVM. Prior to de\u00adveloping Beltway, we implemented a number of GC \nalgorithms in GCTk. These collectors include Appel-style and .xed-nursery gen\u00aderational collectors whose \nperformance we report below. We found their performance to be similar to existing Jikes RVM GC imple\u00admentations. \nExisting Jikes RVM collectors all statically partition their heap into small and large object spaces, \nand unconditionally utilize the large object space. Unfortunately, GCTk currently does not yet implement \na large object space. Direct comparisons be\u00adtween GCTk and the native Jikes RVM collectors are therefore \nnot possible without signi.cant changes to one of the systems. After developing the generational collectors, \nwe tuned them over an eighteen-month period of heavy use in several contexts [7, 8]. For example, they \nuse a very fast address-order write barrier [7]. We compare Beltway against these collectors. These collectors \nare not limited in any way by the generalizations we employ in Belt\u00adway. We did however design GCTk using \nobject-oriented tech\u00adniques which enables the reuse of key GC infrastructure. Of the 26 classes in Beltway \nand in the generational collectors, 23 are com\u00admon to both. We implemented the Beltway collectors in \nGCTk as a single collector with command-line options to specify the con.g\u00aduration. Benchmarks. We use \nsix SPEC benchmarks, .ve drawn from the SPEC JVM98 suite, and pseudojbb, a slightly modi.ed vari\u00adant \nof SPEC JBB2000 [28, 29]. Rather than running for a .xed time and measuring transaction throughput, pseudojbb \nexecutes a .xed number of transactions. This modi.cation made it possible to compare running times reasonably. \nDieckman and H\u00a8olzle present a thorough analysis of SPEC JVM98 [17]. Table 1 shows some characteristics \nin our system: the minimum heap size in which an Appel-style collector does not fail, the bytes allocated \nin this sys\u00adtem, and the number of GCs at large and small heap sizes. We ran each program 5 times for \neach collector con.guration and picked the best execution time (i.e., the one least disturbed by other \neffects in the system). We separately performed a statistics gathering run for each con.guration to measure \nthe rate at which write barrier fast and slow paths were taken. We ran these pro\u00adgrams on 33 heap sizes, \nranging from the smallest one in which the program completes up to 3 times that size. Hardware. Our experimental \ntiming runs were performed on a Macintosh PowerMac G4, with a 733MHz processor, 32KB on\u00adchip L1 data \nand instruction caches, a 256KB uni.ed L2 cache, a 1MB L3 off-chip cache, and 128MB of memory, running \nPPC Linux 2.4.10. 4.2 Throughput This section examines the GC and total application performance for \na range of generational, Beltway X.X.100, and Beltway X.X collec\u00adtors. We begin by comparing Beltway \ncon.gurations that match Appel-style generational collectors and show they perform simi\u00adlarly. We then \nturn to the choice of generational collector; we com\u00adpare .xed-nursery collectors with a range of sizes \nto the .exible\u00adnursery Appel generational collector. Our experiments show that Appel improves performance, \ntypically by about 50%, regardless of nursery size. We therefore use it as our main comparison point. \nWe then explore the effect of increment sizes on Beltway X.X.100 and .nd that as long as the size is \nnot too small, Beltway X.X.100 is not very sensitive to increment size. We also compare Beltway X.X.100 \nto Beltway X.X for one increment size, and .nd their per\u00adformance comparable. We .nally present execution \nand collection times for Beltway X.X.100, Appel, and a .xed-size nursery col\u00adlector, which show that \nBeltway X.X.100 generally performs much better than generational collectors. 4.2.1 Beltway as Appel \nFigure 5(a) compares GC time, and (b) compares total application time. In all the performance graphs, \nthe left y-axis is the perfor\u00admance relative to the best in the .gure, the right y-axis is the actual \ntime, the bottom x-axis is the heap size relative to the minimum, and the top x-axis is the actual heap \nsize. Figure 5 compares Appel, Beltway 100.100 (the Appel con.gu\u00adration of Beltway), and Beltway 100.100.100, \nusing the geometric mean of our 6 benchmarks. These collectors adapt the nursery size to occupy all available \nspace not consumed by the higher genera\u00adtion. Garbage collection time is virtually the same for Appel \nand Beltway 100.100. Beltway 100.100.100, the logical generalization of Appel to 3 generations, enjoys \na collection time advantage at the smallest heap size, but has the same performance as Appel and Beltway \n100.100 at most heap sizes. There is more variation in the total time results because two programs, 209 \ndb and pseudojbb, are very sensitive to locality effects, which are magni.ed here by small variations \nin the collectors. For example, Appel uses a simple boundary crossing write barrier and thus must scan \nthe boot image on each collection [3]. Beltway 100.100 uses the general write bar\u00ad  23MB 29MB 34MB \n46MB 58MB 69MB 23MB 29MB 34MB 46MB 58MB 69MB 4 1.25 24.5 3.53.5 241.2 23.5 3 3 GC time relative to best \nresult (lower is better) GC time in seconds Total time relative to best result (lower is better)Total \ntime in seconds 23 1.15 22.5 2.5 2.5 22 1.1 2 2 21.5 21 1.05 1.5 1.5 20.5 20 1 1 1 Heap size relative \nto minimum heap size (log) Heap size relative to minimum heap size (log) (a) GC time (b) Total time Figure \n5: Comparison of the Appel-style collector with Beltway two-and three-generation Appel con.gurations. \n rier described in Section 3.3.1, which records as needed pointers from the boot image. Most importantly, \nthese results show that Beltway X.X.100 does not obtain performance improvements over Appel by simply \nadding a third generation.  4.2.2 Incrementality in Generational Collectors Incrementality is a key \nparameter for both generational and Belt\u00adway X.X.100 collectors. This section measures the performance \nof generational collectors, both with a range of .xed nursery sizes and also with a .exible nursery. \nIt then explores the impact of in\u00adcrementality on the Beltway X.X.100 collector. Figure 6 compares the \nperformance of four con.gurations of a .xed-size nursery generational collector and an Appel-style collec\u00adtor, \nwith respect to both GC time and total time, using a geometric mean of performance of all 6 benchmarks. \nThe Appel collector s superior space utilization naturally makes good trade-offs between frequency of \ncollection and space utilization, which results in its good total and collector performance. In contrast, \na small .xed-size nursery increases the frequency of GCs and limits time-to-die in the nursery. Both \ndegrade overall performance. A large .xed-size nursery reduces the available space for the higher generation \nand thus leads to more frequent full heap collections and worse overall performance. Furthermore, the \nreser\u00advation of a .xed proportion of the heap for the nursery signi.cantly impacts the collector s capacity \nto perform in tight heaps. The lack of results for small heap sizes in Figure 6 illustrates the failure \nof the generational collector to perform at all in small heap sizes. These results show that the Appel-style \ncollector is the best per\u00adforming generational con.guration, a result that to our knowledge has not previously \nappeared in the literature. On the basis of these results, we use the Appel-style con.guration, and the \nbest perform\u00ading .xed-size nursery collector with nursery size of 25% in subse\u00adquent comparisons. 4.2.3 \nIncrementality in Beltway Figure 7 compares the peformance of Beltway X.X.100 with four different increment \nsizes. We can see that Beltway X.X.100 is fairly robust across increment sizes, although the small increment \nsize of 10 degrades performance. This degradation could be attributed to more frequent nursery collections \nand less time-to-die, or to a diminished capacity to collect large cycles in the second generation. The \nlatter would increase the load on the third generation, and lead to a reduction in heap utilization because \nit also will increase the copy reserve. We use the 25.25.100 con.guration in the remainder of the results \nsection as it appears to perform well, and it is a natural point of comparison with the 25% .xed-size \nnursery generational collector. 4.2.4 Beltway X.X versus X.X.100 Figure 8 compares Beltway 25.25 to Beltway \n25.25.100 to explore if sacri.cing completeness improves performance. However, the geometric means for \nthese two con.gurations are the same. A few programs do improve slightly using Beltway 25.25,but 213 \njavac performance actually degrades because Beltway 25.25 never re\u00adclaims a large cyclic garbage structure. \n 4.2.5 Garbage Collection Time Figure 9(a) shows the geometric mean of the time spent in GC for Beltway \n25.25.100, a .xed-size 25% nursery generational collec\u00adtor, and an Appel-style collector. The robustness \nof Beltway with respect to heap size is clear. The Appel con.guration allows the higher generation to \ngrow as large as possible and so performs bet\u00adter than the .xed nursery con.guration, whereas Beltway \nX.X.100 exploits the small increment size, dynamic copy reserve, and FIFO behavior in the higher generations \nto reduce GC overhead substan\u00adtially in small heaps. 4.2.6 Total Time Figure 9(b) presents the geometric \nmean of the program execu\u00adtion times for Beltway 25.25.100, Appel-style generational, and a .xed-size \n25% nursery generational collector. Figure 10 shows the results for each benchmark. In general, Beltway \nimproves per\u00adformance signi.cantly in small to moderate heaps, and performs excellently across all heap \nsizes. Two interesting results standout. First, Appel performs very poorly in large heaps for pseudojbb \nbecause the program thrashes when its nursery becomes too large and spreads out live data too much. Second \nin 209 db, garbage collection is not a dominant factor. Again, locality effects cause the variations \nin performance across different heap sizes on all collectors. With the exception of 209 db and jbb, Appel \noutperforms the .xed nursery collector at all heap sizes and all programs. Comparing Appel to Beltway \n25.25.100 Appel s performance does not match Beltway X.X.100 until the heap grows to at least 209 db). \nIn ad\u00addition, Appel needs at least 2.5 times the minimum heap size for 1.5 times the minimum heap size \n(except for       23MB 29MB 34MB 46MB 58MB 69MB 23MB 29MB 34MB 46MB 58MB 69MB 1.25 3.5 1.2 GC time \nrelative to best result (lower is better)GC time relative to best result (lower is better)GC time relative \nto best result (lower is better) Total time in seconds Total time in seconds Total time in secondsGC \ntime in seconds Total time relative to best result (lower is better)  3 23 1.15 22.5 2.5 1.1 2 21.5 \n21 1.05 1.5 20.5 20 1 1 Heap size relative to minimum heap size (log) Heap size relative to minimum \nheap size (log) (a) GC time (b) Total time Figure 6: Impact of nursery size on performance of a two-generation \ncollector. 23MB 29MB 34MB 46MB 58MB 69MB 23MB 29MB 34MB 46MB 58MB 69MB 1.25 1.2 3 2.5 GC time in seconds \nTotal time relative to best result (lower is better)  24.5 24 23.5 23 1.15 2 22 1.1 21.5 1.5 1.05 1 \n1 Heap size relative to minimum heap size (log) Heap size relative to minimum heap size (log) (a) GC \ntime (b) Total time Figure 7: Impact of increment size on performance of Beltway X.X.100. 23MB 29MB 34MB \n46MB 58MB 69MB 23MB 29MB 34MB 46MB 58MB 69MB 8 7 6 5 1.256 5 4 GC time in seconds Total time relative \nto best result (lower is better)  1.2 23 22.5 22 1.15 3 1.1 2 1 1.05 1 Heap size relative to minimum \nheap size (log) Heap size relative to minimum heap size (log) (a) GC time. (b) Total time. Figure 8: \nComparisons of Beltway 25.25, Beltway 25.25.100, and Appel-style generational relative to best. 23MB \n29MB 34MB 46MB 58MB 69MB 23MB 29MB 34MB 46MB 58MB 69MB 1.256 24.5 245 1.2 23.5 234 GC time relative to \nbest result (lower is better) GC time in seconds Total time relative to best result (lower is better)Total \ntime in seconds 1.15 22.5 22 3 1.1 21.5 2 1 21 1.05 20.5 201 Heap size relative to minimum heap size \n(log) Heap size relative to minimum heap size (log) (a) GC time. (b) Total time. Figure 9: Performance \nof Beltway 25.25.100, Appel-style, and .xed-size 25% nursery generational collectors relative to best. \n 213 javac and 2 for 228 jack to match Beltway X.X.100 s per\u00adformance. Beltway X.X.100 uses small and \nmoderate heaps more effectively than Appel and the .xed nursery collector, achieving good performance \neven when memory is constrained. In 202 jess, 205 raytrace, 213 javac, and 228 jack, Beltway achieves \nwithin 5% of the best performance for virtually every con.guration. It thus performs well in a wide variety \nof circumstances.  4.3 Responsiveness We did not design Beltway to provide hard real-time performance. \nHowever, we did expect that some con.gurations would offer better responsiveness than other collectors, \nsuch as Appel. Simple mea\u00adsures, such as the length of the longest GC pause or a distribution of pause \ntimes, do not take into account clustering of GCs, which might prevent mutator progress over a longer \nperiod. To our knowl\u00adedge this issue was .rst considered by H\u00a8olzle and Ungar [22], with respect to pauses \ncaused by dynamic compilation. We follow the methodology of Cheng and Blelloch [13]. To incorporate such \npossibilities, we measure mutator utilization (MU). We de.ne MU to be the fraction of time the mutator \nruns within an interval [t0,t1). Clearly, MU ranges over [0,1]and higher MU means the GC is running less. \nIn our graphs, we present min\u00adimum mutator utilization (MMU). A point (w,m)lies on an MMU curve if, for \nall intervals (windows) of length w or more that lie entirely within the program s execution, the mutator \nutilization is at least m. MMU curves are monotonically increasing, with the x\u00adintercept being the maximum \nGC pause for the run, and the asymp\u00adtotic y-value being overall throughput (fraction of time spent in \nthe mutator). Figure 11 shows graphs of MMU curves for runs of 213 javac at two heap sizes. In each graph \nthere are two groups of curves. Those to the left indicate better responsiveness: higher MMU over the \nsame or smaller intervals. On both graphs, Beltway 10.10 and 10.10.100 behave similarly, and offer better \nresponsiveness (and throughput) than other con.gurations. In the second graph, we see that at larger \nheap sizes, the maximum pause time is larger (because the increment size is larger, being 10% of the \nusable heap, etc.), and that Beltway 33.33 and 33.33.100 offer behavior intermediate between 10.10/10.10.100 \nand Appel. It is clear that some con.gurations of Beltway offer better re\u00adsponsiveness than others, including \nAppel. Thus Beltway can be adjusted to provide better responsiveness, though we have not yet explored \nthe con.guration space fully, or related it to characteris\u00adtics of various benchmarks, to offer a tuning \nstrategy.         5. Related Work The Beltway framework combines and exploits key insights of \nin\u00adcremental garbage collection [6], segregating objects to different physical regions of the heap in \norder to improve collector (and sometimes mutator) performance. This section compares Beltway to other \ncollectors with respect to object segregation, pointer track\u00ading, promotion policies, incrementality, \ncompleteness, and hybrids. The most common segregation policy is by age: two or three age-based regions \nare common, but some collectors use more [27]. Generational age-based collectors exploit the weak generational \nhypothesis [34]. Older-.rst collection [32] and renewal older-.rst (here called older-.rst mix) [15, \n19] are premised upon the just al\u00adlocated (Older-First) or copied (renewal older-.rst) objects being \nlikely to stay reachable for a while. Beltway con.gurations ex\u00adploit these characteristics with multiple \nincrements on FIFO belts. Beltway X.X.100 is complete, unlike older-.rst. More importantly, Beltway generalizes \nover all these previous collector organizations, and, in addition, supports segregation by object characteristics \nsuch as size [21], type [27], or allocation-site (e.g., segregation of long\u00adlived, immortal, or immutable \nobjects) [8, 14], although we do not explore this type of segregation in this paper. Any references into \nan increment must be tracked if that incre\u00adment is to be collected independently. Pointer tracking may \nuse remembered sets [34], card marking [39], hardware support [4, 9, 16, 26], or a combination of techniques. \nCard tables [39] are a common alternative to the remsets we use in Beltway. Card tables trade a fast \nwrite-barrier (typically two or three machine instruc\u00adtions) for increased work scanning at collection \ntime. A marked entry in the card table means that one or more pointers were writ\u00adten to some address \nwithin the heap range (the card) corresponding to this mark; the collector must scan the card to .nd \nsuch pointers and test each one to discover whether it is interesting . Beltway collectors do not use \ncard tables for two reasons. First, Jikes RVM lays out array and scalar objects in different directions \nin the heap. Thus, the start of one object cannot be determined from the pre\u00advious object. Second, the \nperformance of card tables or remsets depends strongly on application behavior, and in particular on \nthe relative frequency of writes and remset/card table scanning. Earlier experience [23] suggests that \nremsets are generally faster. To give objects more time to die, generational collectors may vary the \nsize of the nursery [3], use an allocation threshold rather than a capacity [40] to trigger collection, \nor move the boundary be\u00adtween generations to re.ect demographic changes [35]. Beltway 12MB 15MB 18MB \n24MB 30MB 36MB 15MB 19MB 22MB 30MB 38MB 45MB 1.5 17 1.45 1.4 Total time relative to best result (lower \nis better) Total time relative to best result (lower is better)Total time relative to best result (lower \nis better) Total time in seconds Total time in seconds Total time in seconds Total time in seconds Total \ntime in seconds Total time in seconds Total time relative to best result (lower is better) Total time \nrelative to best result (lower is better)Total time relative to best result (lower is better)  16 15 \n14 1.35 1.3 1.25 1.2 1.15 13 1.1 1.05 12 1 Heap size relative to minimum heap size (log) Heap size relative \nto minimum heap size (log) (a) 202 jess (b) 205 raytrace 22MB 28MB 33MB 44MB 55MB 66MB 32MB 40MB 48MB \n64MB 80MB 96MB   1.5 1.45 58  56 54 52 50 48 46 44 42 40 1.4 1.35 1.3 1.25 1.2 1.15 1.1 1.05 1 (c) \n209 db (d) 213 javac 20MB 25MB 30MB 40MB 50MB 60MB 70MB 88MB 105MB 140MB 175MB 210MB   1.5 1.45 21 \n20  1.4 19 1.35 1.318 1.25 17 1.2 1.1516 15 14 1.1 1.05 1 Heap size relative to minimum heap size (log) \nHeap size relative to minimum heap size (log) (e) 228 jack (f) pseudojbb Figure 10: Execution times for \nBeltway 25.25.100, Appel-style, and .xed-nursery generational collectors relative to best.   Interval \nsize (microseconds) (b) 213 javac, heap size 115 Mb Figure 11: MMU plots for 213 javac at two heap sizes. \n can use these techniques, but not the threatening boundary tech\u00adnique [5]. To prevent less frequently \ncollected increments from .lling prematurely, some collectors further segregate surviving ob\u00adjects by \nage to mitigate early promotion [40]. For example, col\u00adlectors can control promotion by recording object \nages [36], or by organizing generations into creation and survivor spaces or into bucket brigades [34, \n37]. At collection time, these methods must access every object in the generation, whether to promote \nit, copy it within the generation, or increment its age. Beltway subsumes and improves on these techniques \nthrough multiple increments and time-to-die triggers in a belt. Not only does it prevent premature promotion, \nit also does not touch objects prematurely. By collecting one region at a time, region collectors provide \nin\u00adcrementality [24]. Generational collectors offer improved expected pause-times, but their need for \noccasional full-heap collections pre\u00advents any worst-case guarantee. The Beltway framework allows investigation \nof throughput and pause-time tradeoffs. Beltway X.X offers incrementality at the expense of completeness, \nand Beltway X.X.100 provides completeness at the cost of occasional full-heap collections. One possibility \nthat we leave to future work is adding Mature Object Space [24] copying rules to Beltway so as to obtain \ncompleteness without full-heap collections. It is common for region collectors to manage different regions \nwith different policies or through different managers. For exam\u00adple, large object areas or the oldest \ngeneration of a generational collector may be managed by a non-moving collector. A Mature Object Space \n(MOS) collector handles older generations specially, bounding the volume copied at any collection and \noffering (even\u00adtual) completeness [24]. Some regions may not be managed by a collector at all, either \nremaining uncollected [8], handled by static analysis [33], or via a stack-like discipline [11, 18, 30]. \nWe could combine Beltway with other collectors, but such exploration is be\u00adyond the scope of this paper. \n   6. Conclusion We present a new collector design, Beltway, that subsumes pre\u00advious work on copying \ncollectors. The generality of the Beltway framework enables the implementation of new copying collectors \nthat combine key ideas in the garbage collection literature. We il\u00adlustrate how Beltway encompasses all \nof the previous generational and region copying collectors of which we are aware, and iden\u00adtify two new \ncollectors, Beltway X.X and Beltway X.X.100. The design and implementation of these collectors introduces \nthe need for a number of new mechanisms, including the use of frames to minimize write barrier costs, \ncollection triggers to preempt future collection problems, and a dynamic conservative copy reserve to \nmake the most ef.cient use of heap space. Using these mecha\u00adnisms, our results show that Beltway X.X.100 \noutperforms both a state-of-the-art Appel-style collector and a .xed-size nursery gen\u00aderational collector. \nThe Beltway framework provides a novel, very general, and ef.cient design and implementation that results \nin bet\u00adter collectors, but more importantly opens to further exploration a large design space for copying \nregion collectors. 7. Acknowledgments We acknowledge with gratitude IBM Research for making the Jikes \nRVM system available to us, and especially the the generosity Mark Wegman, Vivek Sarkar, Mike Hind, Mark \nMergen, and their re\u00adsearch teams who built the Jikes RVM and worked with us. Thanks to Darko Stefanovi\u00b4c \nwho modi.ed SPEC JBB to produce pseu\u00addojbb, and to Emery Berger, Matthew Hertz, Tony Hosking, and Zhenlin \nWang for their contributions to this paper. 8. REFERENCES [1] Bowen Alpern, C. R. Attanasio, Anthony \nCocchi, Derek Lieber, Stephen Smith, Ton Ngo, John J. Barton, Susan Flynn Hummel, Janice C. Sheperd, \nand Mark Mergen. Implementing Jalape no in Java. In Proceedings of the 1999 ACM SIGPLAN Conference on \nObject-Oriented Programming Systems, Languages &#38; Applications, OOPSLA 99, volume 34(10) of ACM SIGPLAN \nNotices, pages 314 324, Denver, Colorado, USA, October 1999. ACM Press. [2] Bowen Alpern, Dick Attanasio, \nJohn J. Barton, M. G. Burke, P. Cheng, J.-D. Choi, Anthony Cocchi, Stephen J. Fink, David Grove, Michael \nHind, Susan Flynn Hummel, D. Lieber, V. Litvinov, Mark Mergen, Ton Ngo, J. R. Russell, Vivek Sarkar, \nManuel J. Serrano, Janice Shepherd, S. Smith, V. C. Sreedhar, H. Srinivasan, and J. Whaley. The Jalape \nno virtual machine. IBM System Journal, 39(1), February 2000. [3] Andrew W. Appel. Simple generational \ngarbage collection and fast allocation. Software Practice and Experience, 19(2):171 183, 1989. [4] Andrew \nW. Appel, John R. Ellis, and Kai Li. Real-time concurrent collection on stock multiprocessors. ACM SIGPLAN \nNotices, 23(7):11 20, 1988. [5] David A. Barrett and Benjamin Zorn. Garbage collection using a dynamic \nthreatening boundary. Computer Science Technical Report CU-CS-659-93, University of Colorado, July 1993. \n[6] Peter B. Bishop. Computer Systems with a Very Large Address Space and Garbage Collection. PhD thesis, \nMIT Laboratory for Computer Science, May 1977. Technical report MIT/LCS/TR 178. [7] Stephen M. Blackburn \nand Kathryn S. McKinley. In or out? Putting write barriers in their place. In Proceedings of the Third \nInternational Symposium on Memory Management, ISMM 02, volume 37 of ACM SIGPLAN Notices, Berlin, Germany, \nJune 2002. ACM Press. [8] Stephen M. Blackburn, Sharad Singhai, Matthew Hertz, Kathryn S. McKinley, and \nJ. Eliot B. Moss. Pretenuring for Java. In Proceedings of the 2001 ACM SIGPLAN Conference on Object-Oriented \nProgramming Systems, Languages and Applications, OOPSLA 2001, volume 36(11) of ACM SIGPLAN Notices, pages \n342 352, Tampa, Florida, USA, November 2001. ACM Press. [9] Hans-Juergen Boehm, Alan J. Demers, and Scott \nShenker. Mostly parallel garbage collection. ACM SIGPLAN Notices, 26(6):157 164, 1991. [10] Tim Brecht, \nEshrat Arjomandi, Chang Li, and Hang Pham. Controlling garbage collection and heap growth to reduce the \nexecution time of Java applications. In Proceedings of the 2001 ACM SIGPLAN Conference on Object-Oriented \nProgramming Systems, Languages and Applications, OOPSLA 2001, volume 36(11) of ACM SIGPLAN Notices, Tampa, \nFlorida, USA, November 2001. ACM Press. [11] Dante Cannarozzi, Michael Plezbert, and Ron Cytron. Contaminated \ngarbage collection. In Proceedings of the 2000 ACM SIGPLAN Conference on Programming Language Design \nand Implementation, PLDI 2001, volume 35(5) of ACM SIGPLAN Notices, Vancouver, Canada, May 2000. ACM \nPress. [12] C. J. Cheney. A non-recursive list compacting algorithm. Communications of the ACM, 13(11):677 \n8, November 1970. [13] Perry Cheng and Guy Belloch. A parallel, real-time garbage collector. In Proceedings \nof the 2001 ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 2001, volume \n36(5) of ACM SIGPLAN Notices, pages 125 136, Snowbird, Utah, USA, May 2001. ACM Press. [14] Perry Cheng, \nRobert Harper, and Peter Lee. Generational stack collection and pro.le-driven pretenuring. In Proceedings \nof the 1998 ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 98, volume \n34(5) of ACM SIGPLAN Notices, Montreal, Canada, May 1998. ACM Press. [15] William D. Clinger and Lars \nT. Hansen. Generational garbage collection and the Radioactive Decay model. In Proceedings of the 1997 \nACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 97, volume 32(5) of ACM \nSIGPLAN Notices, pages 97 108, Las Vegas, Nevada, USA, May 1997. ACM Press. [16] Robert Courts. Improving \nlocality of reference in a garbage-collecting memory management-system. Communications of the ACM, 31(9):1128 \n1138, 1988. [17] Sylvia Dieckman and Urs H\u00a8olzle. A study of the allocation behaviour of the SPECjvm98 \nJava benchmarks. In Erik Jul, editor, Proceedings of the 12th European Conference on Object-Oriented \nProgramming, ECOOP 98, volume 1445 of Lecture Notes in Computer Science, pages 92 115, Brussels, Belgium, \n1998. Springer-Verlag. [18] David Gay and Alex Aiken. Memory management with explicit regions. In Proceedings \nof the 1998 ACM SIGPLAN Conference on Programming Language Design and Implementation, PLDI 98, volume \n33(5) of ACM SIGPLAN Notices, pages 313 323, Montreal, Canada, May 1998. ACM Press. [19] Lars Thomas \nHansen. Older-.rst garbage collection in practice. PhD thesis, North-eastern University, November 2000. \n[20] Barry Hayes. Using key object opportunism to collect old objects. In Andreas Paepcke, editor, Proceedings \nof the Sixth Annual Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA \n91, volume 26(11) of ACM SIGPLAN Notices, pages 33 46, Phoenix, Arizona, USA, October 1991. ACM Press. \n[21] Michael Hicks, Luke Hornof, Jonathan T. Moore, and Scott Nettles. A study of Large Object Spaces. \nIn Richard Jones, editor, Proceedings of the First International Symposium on Memory Management, ISMM \n98, volume 34(3) of ACM SIGPLAN Notices, pages 138 145, Vancouver, Canada, March 1999. ACM Press. [22] \nUrs H\u00a8olzle and David Ungar. A third-generation Self implementation: Reconciling responsiveness with \nperformance. In Proceedings of the Ninth Annual Conference on Object-Oriented Programming Systems, Languages, \nand Applications, OOPSLA 94, volume 29(10) of ACM SIGPLAN Notices, pages 229 243, Portland, Oregon, USA, \nOctober 1994. ACM Press. [23] Antony L. Hosking, J. Eliot B. Moss, and Darko Stefanovi\u00b4c. A comparative \nperformance evaluation of write barrier implementations. In Andreas Paepcke, editor, Proceedings of the \nSeventh Annual Conference on Object-Oriented Programming Systems, Languages, and Applications, OOPSLA \n92, volume 27(10) of ACM SIGPLAN Notices, pages 92 109, Vancouver, Canada, October 1992. ACM Press. [24] \nRichard L. Hudson and J. Eliot B. Moss. Incremental garbage collection for mature objects. In Yves Bekkers \nand Jacques Cohen, editors, Proceedings of the First International Workshop on Memory Management, IWMM \n92, volume 637 of Lecture Notes in Computer Science, St. Malo, France, September 1992. Springer-Verlag. \n[25] Richard E. Jones. Garbage Collection: Algorithms for Automatic Dynamic Memory Management. Wiley, \nJuly 1996. With a chapter on Distributed Garbage Collection by R. Lins. [26] David A. Moon. Garbage collection \nin a large LISP system. In Guy L. Steele, editor, Proceedings of the 1984 ACM Conference on LISP and \nFunctional Programming, Austin, Texas, USA, August 1984. ACM Press. [27] John H. Reppy. A high-performance \ngarbage collector for Standard ML. Technical memorandum, AT&#38;T Bell Laboratories, Murray Hill, NJ, \nDecember 1993. [28] Standard Performance Evaluation Corporation. SPECjvm98 Documentation, release 1.03 \nedition, March 1999. [29] Standard Performance Evaluation Corporation. SPECjbb2000 (Java Business Benchmark) \nDocumentation, release 1.01 edition, 2001. [30] Bjarne Steensgaard. Thread-speci.c heaps for multi-threaded \nprograms. In Antony L. Hosking, editor, Proceedings of the Second International Symposium on Memory Management, \nISMM 2000, volume 36(1) of ACM SIGPLAN Notices, Minneapolis, Minnesota, USA, January 2001. ACM Press. \n[31] Darko Stefanovi\u00b4c. Properties of Age-Based Automatic Memory Reclamation Algorithms. PhD thesis, \nUniversity of Massachusetts, 1999. [32] Darko Stefanovi\u00b4c, Kathryn S. McKinley, and J. Eliot B. Moss. \nAge-based garbage collection. In Proceedings of the 1999 ACM SIGPLAN Conference on Object-Oriented Programming \nSystems, Languages &#38; Applications, OOPSLA 99, volume 34(10) of ACM SIGPLAN Notices, pages 370 381, \nDenver, Colorado, USA, October 1999. ACM Press. [33] Mads Tofte and Jean-Pierre Talpin. Region-based \nmemory management. Information and Computation, February 1997. [34] David M. Ungar. Generation scavenging: \nA non-disruptive high performance storage reclamation algorithm. ACM SIGPLAN Notices, 19(5):157 167, \nApril 1984. Also published as ACM Software Engineering Notes 9, 3 (May 1984) Proceedings of the ACM/SIGSOFT/SIGPLAN \nSoftware Engineering Symposium on Practical Software Development Environments, 157 167, April 1984. [35] \nDavid M. Ungar and Frank Jackson. An adaptive tenuring policy for generation scavengers. ACM Transactions \non Programming Languages and Systems, 14(1):1 27, 1992. [36] Derek White and Alex Garthwaite. The GC \ninterface in the EVM. Technical Report SML TR 98 67, Sun Microsystems Laboratories, December 1998. [37] \nPaul R. Wilson. A simple bucket-brigade advancement mechanism for generation-based garbage collection. \nACM SIGPLAN Notices, 24(5):38 46, May 1989. [38] Paul R. Wilson. Garbage collection and memory hierarchy. \nIn Yves Bekkers and Jacques Cohen, editors, Proceedings of International Workshop on Memory Management, \nvolume 637 of Lecture Notes in Computer Science, St Malo, France, September 1992. Springer-Verlag. [39] \nPaul R. Wilson and Thomas G. Moher. A card-marking scheme for controlling intergenerational references \nin generation-based garbage collection on stock hardware. ACM SIGPLAN Notices, 24(5):87 92, 1989. [40] \nBenjamin G. Zorn. Comparative Performance Evaluation of Garbage Collection Algorithms. PhD thesis, University \nof California at Berkeley, March 1989. Technical Report UCB/CSD 89/544.  \n\t\t\t", "proc_id": "512529", "abstract": "We present the design and implementation of a new garbage collection framework that significantly generalizes existing copying collectors. The <i>Beltway</i> framework exploits and separates object age and incrementality. It groups objects in one or more increments on queues called <i>belts</i>, collects belts independently, and collects increments on a belt in first-in-first-out order. We show that Beltway configurations, selected by command line options, act and perform the same as semi-space, generational, and older-first collectors, and encompass all previous copying collectors of which we are aware. The increasing reliance on garbage collected languages such as Java requires that the collector perform well. We show that the generality of Beltway enables us to design and implement new collectors that are robust to variations in heap size and improve total execution time over the best generational copying collectors of which we are aware by up to 40%, and on average by 5 to 10%, for small to moderate heap sizes. New garbage collection algorithms are rare, and yet we define not just one, but a new family of collectors that subsumes previous work. This generality enables us to explore a larger design space and build better collectors.", "authors": [{"name": "Stephen M Blackburn", "author_profile_id": "81100547435", "affiliation": "Australian National University, Canberra, ACT, 0200, Australia", "person_id": "P347525", "email_address": "", "orcid_id": ""}, {"name": "Richard Jones", "author_profile_id": "81100555993", "affiliation": "University of Kent, Canterbury, Kent, CT2 7NF, UK", "person_id": "PP39048397", "email_address": "", "orcid_id": ""}, {"name": "Kathryn S. McKinley", "author_profile_id": "81100402805", "affiliation": "University of Texas at Austin, Austin, TX", "person_id": "P348202", "email_address": "", "orcid_id": ""}, {"name": "J Eliot B Moss", "author_profile_id": "81406593781", "affiliation": "University of Massachusetts, Amherst, MA", "person_id": "P348262", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512529.512548", "year": "2002", "article_id": "512548", "conference": "PLDI", "title": "Beltway: getting around garbage collection gridlock", "url": "http://dl.acm.org/citation.cfm?id=512548"}