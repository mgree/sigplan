{"article_publication_date": "05-17-2002", "fulltext": "\n ESP: Path-Sensitive Program Veri.cation in Polynomial Time Manuvir Das Sorin Lerner Mark Seigle Microsoft \nResearch University of Washington University of Washington manuvir@microsoft.com lerns@cs.washington.edu \nseigle@cs.washington.edu ABSTRACT In this paper, we present a new algorithm for partial pro\u00adgram veri.cation \nthat runs in polynomial time and space. We are interested in checking that a program satis.es a given \ntemporal safety property. Our insight is that by accu\u00adrately modeling only those branches in a program \nfor which the property-related behavior di.ers along the arms of the branch, we can design an algorithm \nthat is accurate enough to verify the program with respect to the given property, without paying the \npotentially exponential cost of full path\u00adsensitive analysis. We have implemented this property simulation \nalgo\u00adrithm as part of a partial veri.cation tool called ESP. We present the results of applying ESP to \nthe problem of verify\u00ading the .le I/O behavior of a version of the GNU C compiler (gcc, 140,000 LOC). \nWe are able to prove that all of the 646 calls to fprintf in the source code of gcc are guaranteed to \nprint to valid, open .les. Our results show that property simulation scales to large programs and is \naccurate enough to verify meaningful properties. Categories and Subject Descriptors D.2.4 [Software \nEngineering]: Software/Program Veri.\u00adcation; D.2.5 [Software Engineering]: Testing and De\u00adbugging; D.3.4 \n[Programming Languages]: Compilers; F.3.1 [Theory of Computation]: Specifying and Verify\u00ading and Reasoning \nabout Programs General Terms Algorithms, Security, Veri.cation.  Keywords Path-sensitive analysis, \ndata.ow analysis, error detection. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 02, June 17-19, 2002, Berlin, Germany. Copyright 2002 ACM 1-58113-463-0/02/0006 \n...$5.00. 1. INTRODUCTION In recent years, program analysis techniques have been used to build tools \nfor partial veri.cation [25, 11, 3, 10]. The programmer provides a description of a temporal safety property \nwritten as a .nite state machine. An example of such a property is given in Figure 1. An analysis tool \nthen tracks the state of the property FSM through a program. If the error state is never reached, the \nprogram obeys the safety property. Previous work on partial veri.cation has focused on path\u00adsensitive \nanalysis methods [3, 14]. These methods are ac\u00adcurate enough for veri.cation because they are able to \nrea\u00adson about branch correlations, which is usually necessary to control the number of false error reports \ngenerated during veri.cation. However, the cost of path-sensitivity has lim\u00adited the applicability of \nthese methods to large programs. In this paper, we present a new path-sensitive method for partial veri.cation \nthat scales to large programs. Path-sensitive analysis can be expensive because accu\u00adrately tracking \nevery branch in the control-.ow of a program in which the execution state (e.g., values of variables) \ndi.ers along the two branch paths may result in an exponential or in.nite search space. However, given \na particular property to be checked, it is likely that most branches in the code are not relevant to \nthe property, even though they a.ect the execution state of the program. The trick is to identify and \naccurately track only relevant branches. In this paper, we present property simulation , a new method \nfor partial veri.cation that is based on the heuristic that a branch is likely to be relevant only if \nthe property FSM transitions to di.erent states along the arms of the branch. This heuristic leads to \na path-sensitive algorithm that is sensitive to the property state : symbolically eval\u00aduate the program, \ngenerating symbolic states that include both the execution state and the state of the property FSM. At \na merge point in the control .ow, if two symbolic states have the same property state, produce a single \nsymbolic state by merging their execution states as in data.ow anal\u00adysis. Otherwise, process the symbolic \nstates independently as in path-sensitive analysis. This method avoids exponen\u00adtial blowup and captures \nrelevant branching behavior. We make the following contributions: We present a framework for inter-procedural \nproperty simulation. Particular algorithms of varying precision and complexity can be obtained by .xing \nthe domain of execution states used in the framework.  We focus on one particular instantiation of the \nframe\u00ad  Print .. $uninit Close .. . | ..* . Open Close $error . . .. .. . OpenPrint Opened .. Figure \n1: A temporal safety property that encodes correct usage of the stdio .le output library. work, in which \nthe domain of execution states is cho\u00adsen to be the constant propagation lattice. We show that in this \ncase, inter-procedural property simulation terminates in polynomial time and space. We describe ESP, \na system that uses a combination of scalable alias analysis and property simulation to ver\u00adify that large \ncode bases obey temporal safety proper\u00adties. Property simulation can also be used to provide an accurate \nstarting point for a system based on iter\u00adative re.nement, such as SLAM [3].  We present the results \nof a case study: verifying out\u00adput .le manipulations in the gcc compiler (taken from SPEC95) using ESP. \nOur results show that:  Property simulation is accurate. We are able to verify that all of the 646 calls \nto fprintf in gcc are guaranteed to print to valid, open .les.  Property simulation is scalable. For \neach of the 15 .les to which gcc writes its output, we are able to perform inter-procedural simulation \nof the source code of gcc (140,000 LOC) on average in 70secs and 50MB. To our knowledge, our analysis \nis the .rst method to have veri.ed temporal safety properties of a program of this size.   The rest \nof this paper is organized as follows: In Section 2, we present a motivating example for our algorithm. \nIn Section 3, we present intra-procedural and inter-procedural versions of property simulation. In Section \n4, we describe the ESP veri.cation system. In Section 5, we present our case study. We survey related \nwork in Section 6, and con\u00adclude in Section 7. 2. EXAMPLE In this section, we use an example to explain \nhow certain types of programming errors can be detected using tempo\u00adral safety properties. We use the \nexample to motivate our property simulation algorithm. Consider the simpli.ed snippet of code from the \ngcc com\u00adpiler shown in Figure 2. Suppose we are interested in deter\u00admining whether this piece of code \ninteracts correctly with the stdio library through calls to fopen and fclose.For in\u00adstance, a .le handle \nmay be closed through a call to fclose only if it has previously been opened through a call to fopen, \nand it has not already been closed through a previous call to fclose. There is no mechanism in a language \nlike C to express such usage rules in the type system, so that they may be enforced by a compiler (cf. \n[10]). void main(){ if (dump) f = fopen(dumpFil,\"w\"); /* Open */ if (p) x= 0; else x= 1; l: if (dump) \nfclose(f); /* Close */ } Figure 2: A (simpli.ed) snippet of code from a ver\u00adsion of the gcc compiler. \nOne way to overcome this problem is to instrument the program by mapping calls to library functions to \ntransi\u00adtions in the property FSM from Figure 1. Program anal\u00adysis techniques can then be applied to conservatively \nover\u00adapproximate the possible states into which the property FSM may be driven along all execution paths. \nIf the error state is not encountered, veri.cation of the program with respect to the property succeeds. \nExample 1. Assume that calls to fopen and fclose are mapped to corresponding transitions Open and Close \nfrom the property FSM. The possible symbolic states inferred by three analyses at label l in Figure 2 \nare described below. Each symbolic state includes the possible states of the prop\u00aderty FSM and the execution \nstate of the program. Path-sensitive analysis. There are four feasible paths to l, resulting in the states: \n[$uninit, \u00acdump, \u00acp, x = 1][Opened, dump, \u00acp, x = 1] [$uninit, \u00acdump, p, x = 0][Opened, dump, p, x = \n0] These states capture the correlation between the property state and dump, which is necessary to avoid \nfollowing the true branch of the condition at l in the $uninit state. Standard data.ow analysis. States \nare merged at join points in the CFG. Therefore information about dump is lost, and the single state \nproduced at l is [{$uninit, Opened}]. As a result the Close transition is processed from the $uninit \nstate, leading to a false error report. Property simulation. Along the true branch of the .rst conditional, \nthe property state is changed from $uninit to Opened. Therefore, the two symbolic states from the .rst \nconditional are not merged. The second conditional does not a.ect the property state. Therefore, the \nfour symbolic states arising from the second conditional are merged into two states at l:[$uninit, \u00acdump]and \n[Opened, dump]. These states capture the correlation between the property state and dump, but drop the \ncorrelation between p and x,which is not relevant to checking the .le output property. . Property simulation \nis precise because it is designed to match the behavior of a careful programmer. Before calling a function \nthat a.ects the property state, she must check the current state of the property FSM to ensure that the \nfunction call will not result in an error. However, the pro\u00adgramming language provides no mechanism to \nexpress or check the property state. Instead, she uses conditionals to check the program state before \nthe function call. In other words, the programmer maintains an implicit correlation be\u00adtween a given \nproperty state and the execution states under global 1 Worklist :2N 2 Info : E . 2S procedure Solve(CFG \n= [N, E]) begin 3 for each e . E do Info(e):= {} 4 Info(OutT (nentry )) := {[$uninit, T]} 5 Worklist \n:= {dst(outT (nentry ))} 6 while Worklist= \u00d8 do 7 Remove a node n from Worklist 8 switch(n) 9 case n \n. Merge: 10 ss = Fmrg (n, Info(In0 (n)), Info(In1 (n))) 11 Add(OutT (n),ss) 12 case n . Branch: 13 ssT \n= Fbr (n, Info(In0 (n)), true) 14 ssF = Fbr (n, Info(In0 (n)), false) 15 Add(OutT (n),ssT ) 16 Add(OutF \n(n),ssF ) 17 case n . Other: 18 ss = Foth (n, Info(In0 (n))) 19 Add(OutT (n),ss) 20 return Info end \n procedure Add(e, ss) begin 21 if Info(e)= ss then 22 Info(e):= ss 23 Worklist := Worklist .{dst(e)} \n end Figure 3: Intra-procedural property analysis. which the property FSM is in that state. Property \nsimula\u00adtion makes this correlation explicit in the analysis. In the example above, we assumed that there \nis a single .le handle in the program, and that changes to its state can be identi.ed syntactically. \nIn practice, neither assump\u00adtion is valid. In Section 4, we describe ESP, a system that uses a combination \nof scalable alias analysis and property simulation to track multiple stateful values.  3. PROPERTY SIMULATION \nIn this section, we describe property simulation in detail. We .rst present property analysis, a general \nframework for tracking property states and execution states using path\u00adsensitive data.ow analysis. By \nvarying a function a that groups together execution states, we obtain three data.ow analyses: a fully \npath-sensitive analysis, a standard data.ow analysis, and property simulation. Each analysis can be further \ninstantiated to algorithms of particular precision and complexity by choosing a particular domain for \nexecution states. We describe an instantiation of property simulation based on constant propagation. \nWe show that for this case, property simulation runs in polynomial time and space. 3.1 Intra-procedural \nproperty analysis In this subsection we describe a generic data.ow analy\u00adsis, property analysis , that \ncomputes the set of possible property states at all points in a single procedure program. We assume a \nstandard CFG with a distinguished entry node nentry , merge nodes with exactly two predecessors, Fmrg \n(n, ss1 , ss2 )= a(ss1 . ss2 ) ' Fbr (n, ss, val)= a({s'|s= fbr (n, s, val) . s . ss . es(s')= .}) Foth \n(n, ss)= a({foth (n, s)|s . ss}) (a) Flow functions acs (ss)= ss .. adf (ss)= {[ as(s), es(s)]} s.ss \ns.ss . aas (ss)= {[{d}, s.ss[d] es(s)]|d . D . ss[d] = \u00d8} where ss[d]= {s|s . ss . d . as(s)} (b) Grouping \nfunction Figure 4: De.nitions of .ow functions and the grouping function. branch nodes with a single \npredecessor, a true successor, and a false successor, and computation nodes with a single predecessor \nand a single successor. We use appropriately named accessor functions to extract edge information from \nCFG nodes and vice versa (In,Out,src,dst). We use the following domains: D is the (.nite) set of states \nin the (deterministic) property state machine. D in\u00adcludes two distinguished states: $uninit, the initial \nstate, and $error, the error state. S is the domain of symbolic states. A symbolic state is a pair containing \nan abstract state, which is a set of property states, and an execution state. 1 Given a symbolic state \ns. S,wedenoteits abstract state by as(s), and its execution state by es(s). The prop\u00aderty analysis computes, \nfor each edge in the CFG, a data.ow fact from the domain 2S . The pseudo code for intra-procedural property \nanalysis is given in Figure 3. This is a standard worklist algorithm that updates a map from edges to \ndata.ow facts, until no further updates are possible. Figure 4(a) shows the .ow functions for the three \ntypes of nodes in the CFG. The .ow functions .rst compute a set of symbolic states, and then use a grouping \nfunction a :2S . 2S , described in detail later, to .lter this set. Fmrg combines the data.ow facts on \nits input edges into a single fact, using set union. Fbr takes a set of symbolic states on its input \nedge. It maps each input state to an output state using fbr ,the trans\u00adfer function for branch nodes. \nfbr has two e.ects: First, it uses a theorem prover to determine whether a given branch direction is \nfeasible using the information in the execution state. Second, if a branch direction is neither implied \nby nor ruled out by the execution state, it updates the execution state, setting the branch predicate \nto either true or false. Foth maps input states to output states using foth ,the transfer function for \ncomputation nodes. foth may update the abstract state if the node corresponds to a transition in the \nproperty FSM. It may also update the execution state. 3.1.1 Grouping symbolic states Property analysis \nuses a function a to group together cer\u00adtain sets of execution states. By de.ning aas in Figure 4(b), \nwe obtain three versions of property analysis corresponding 1. represents no behaviors; T represents \nall behaviors. to fully path-sensitive analysis, standard data.ow analysis, and property simulation: \nFully path-sensitive analysis. acs is the identity func\u00adtion. Therefore, merge nodes merely accumulate \ninforma\u00adtion from all of their predecessor edges. Standard data.ow analysis. adf merges all the sym\u00adbolic \nstates in a set into a single symbolic state. There\u00adfore, this analysis is similar to standard data.ow \nanalysis, in which sets of tuples are joined into a single tuple at merge points. Because of this merging, \nthe correlation between a given property state and the execution states under which the property state \narises is lost. Note that this analysis is predicate aware, in the sense that the correlation between \ntwo branches can be tracked provided there are no interven\u00ading merges between them. An e.cient version \nof the analysis can be obtained by .xing the execution states as T.This would result in a path-insensitive \nanalysis that only propa\u00adgates sets of property states. Property simulation. aas takes a set of symbolic \nstates and groups the elements of the set based on the property state. All of the execution states in \none group are merged. For example, aas ({[{a},l],[{a},m],[{b},n],[{b},o],})= {[{a},l. m],[{b},n. o]}.In \nother words, aas is designed to maintain the correlation between a given property state and the execution \nstates under which the property FSM is driven into that state at a given program point. 3.1.2 Termination \nand complexity We now argue the termination and complexity of intra\u00adprocedural property simulation. Let \nT be the cost of one call to the .ow function for execution states (fbr or foth), let J and Qbe the cost \nof the join operation and the equality operation on execution states, respectively. By the de.nition \nof aas , the number of symbolic states in each data.ow fact is bounded by |D|, the number of states in \nthe property FSM. During the analysis, each element of a set can become less precise repeatedly. If we \nassume that each element can become less precise at most H times, then the algorithm terminates. This \ncan be guaranteed either by requiring a .nite height lattice of execution states (of height H), or by \nusing widening operators [6]. Since the set on a given edge can have at most |D| elements, and each element \ncan become less precise at most H times, each edge is relaxed at most H|D| times, causing O(H|E||D|)nodes \nto be processed, where |E| is the number of edges in the CFG. In our implementation, when a node is added \nto the work\u00adlist, we keep track of the property state for which the exe\u00adcution state has changed. This \nallows us to (1) evaluate fbr or foth only on the execution state that has changed and (2) evaluate . \n(in aas ) and the equality test (on line 21 from Figure 3) only on the newly produced execution state. \nAs a result, each time a node is processed, there is at most one equality operation, one join operation, \nand one call to the .ow function (fbr or foth). Therefore, the complexity of intra\u00adprocedural property \nsimulation is O(H|E||D|(T + J + Q)). 3.1.3 A framework for property simulation In the de.nition of property \nsimulation given above, the choice of the domain for execution states and the join op\u00aderation on execution \nstates have been left open. Therefore, the de.nition provides a framework for property simulation. Particular \nalgorithms of varying precision and complexity can be obtained by .xing the domain and the join opera\u00adtion \nused for execution states. For instance, if the domain of execution states is chosen to be sets of symbolic \nstores (i.e., stores arising from symbolic evaluation), and the join operation is chosen to be set union, \nproperty simulation is identical to fully path-sensitive analysis. Therefore, property simulation should \nbe viewed as a tech\u00adnique for grouping together the execution states that imply a particular property \nstate. This grouping allows us to con\u00adtrol the complexity of the analysis by selecting the join op\u00aderation, \nwhile avoiding any loss of precision from merging execution states associated with di.erent property \nstates. 3.1.4 Instantiation to constant propagation The particular instantiation of property simulation \nwe use in our work is based on constant propagation. Execution states are chosen to be stores that map \nprogram variables to values from a standard constant propagation lattice. The join operation chosen is \nalso the standard join used in con\u00adstant propagation. If a variable has di.erent values in two stores \nthat are joined, its value is set to T.The theorem prover uses the execution state to replace variables \nin a predicate expression with their values, and then simpli.es the expression. If the resulting expression \nis either T or F, the appropriate branch is eliminated. Otherwise, if the sim\u00adpli.ed expression is of \nthe form x== c for some constant c, fbr updates the execution state accordingly along each branch. foth \nupdates the execution state at assignments to variables by simplifying the right hand side expression \nand updating the store. For this instantiation: (1) H =3V where V is the number of variables; (2) the \ncost of a single call to the theorem prover is V, and therefore T = V since fbr calls the theorem prover; \n(3) join and equality each take V time so that J = Q= V. Therefore, the complexity of the algorithm is \nO(V2|E||D|). For the rest of this paper, we limit our discussion to the constant propagation instantiation \nof the property simula\u00adtion framework.  3.1.5 Example Example 2. Figure 5 shows the data.ow facts produced \nby fully path-sensitive analysis (PSA), standard data.ow anal\u00adysis (Dataflow), and property simulation \n(PropSim)for the program in Figure 2, given the temporal safety property in Figure 1. We abbreviate dump \nwith d,[p . F,d . T]with !pd, $uninit with $u, Opened with o,etc. We now describe in detail the steps \ntaken by property simulation, pointing out the points at which property simu\u00adlation di.ers from the other \ntwo analyses. Step 1. The theorem prover does not have enough infor\u00admation in the execution state to \ndetermine the direction of branch n1, so the symbolic state is split, propagating [$u,d] and [$u,!d] \nto the true and false successor edges of n1. Step 2. n2 transitions the property state from $u to o, \nthus propagating [o,d] to its successor. Step 3. n3 merges the incoming facts, keeping the execu\u00adtion \nstates d and !d separate because the associated prop\u00aderty states are di.erent. Thus, the outgoing information \nis {[$u,!d],[o,d]}.Notice that Dataflow loses precision here compared to PropSim, since it merges all \nthe execution states into one, producing {[{$u,o},T]}. Step 4. Given either state d or state !d,the theorem \nprover cannot determine the direction of branch n4,soeach DataflowPropSim PSA PSA PropSim Dataflow [$u, \nT] [$u, T] [$u, T] F  T [$u, d] [$u, d] [$u, d] [$u,!d] [$u,!d] [$u,!d] n2 Open [ o, d] [ o, d] [ o, \nd] [$u,!d][$u,!d] [{$u,o},T] [ o, d] [ o, d] [$u,!p!d][$u,!p!d][$u,p!d][$u,p!d] [{$u,o},p][{$u,o},!p] \n [ o,!p d] [ o,!p d] F T [ o,p d] [ o,p d] n5 x:=1 n6 x:=0 [$u,p!d][$u,p!d] [$u,!p!d][$u,!p!d]  [{$u,o},!p] \n[{$u,o},p][ o,p d] [ o,p d][ o,!p d] [ o,!p d] F [$u,!p!d]  [{$u,o},!d] [$u,!d] [$u, p!d]  [ o,!pd] \n T [ o, d] [{$u,o},d] [ o, pd] n9 Close [$u,!pd] [$u, d] [{$u,$e},d][$u, pd] [$u,!p!d][$u,!p d][$u, \nT] [{$u,o,$e},T][$u, p!d][$u, p d] [$u,!p!d] [o,!p d][$u,!d] [{$u,o},T] [$u, p!d] [o, p d] [ o, d] Figure \n5: A comparison of fully path-sensitive analysis, standard data.ow analysis, and property simulation. \nsymbolic state is split, propagating {[$u, p!d], [o, pd]} and {[$u, !p!d], [o, !pd]} to the true and \nfalse successors of n4. Step 5-6.Nodes n5 and n6 add the value of x to the ex\u00adecution state. We drop \nthis information from the execution states in order to simplify the diagram. Step 7. n7 merges the incoming \nfacts {[$u, p!d], [o, pd]}and {[$u, !p!d], [o, !pd]} based on the property state. The re\u00adsult is {[$u, \n!d], [o, d]}, which says that either the property state is $uninit and dump is false, or the property \nstate is Opened and dump is true. This step shows how PropSim di.ers from PSA.In PSA, p is tracked accurately, \nthus dou\u00adbling the number of execution states that must be analyzed downstream of n7. However, PropSim \ndrops the value of p from the execution state because it is not correlated with the property state. Step \n8. When the theorem prover is invoked at n8 with either state d or state !d, it is able to determine \nthat only one leg of the branch is feasible: true for state d and false for state !d.As a result, {[o, \nd]} and {[$u, !d]} are propagated respectively to the true and false successors of n8. Step 9. n9 transitions \nthe property from o to $u,thus propagating [$u, d]. Notice how, because of the merge at node n3, Dataflow \nproduces a transition to $e at n9. .   3.2 Inter-procedural property simulation The pseudo code for \ninter-procedural property simulation is given in Figure 6. Property simulation is extended to the inter-procedural \ncase in a context-sensitive manner through the use of partial transfer functions, or summary edges, as \nin [27, 23]. The main idea is as follows: Suppose we are processing function foo and we encounter a call \nto func\u00adtion bar. We would like to apply a transfer function on the edge from the call site in foo to \nthe associated return node in foo. However, since the body of bar contains multiple nodes, the transfer \nfunction must be generated dynamically by analyzing bar. This is done by maintaining and updat\u00ading a \nsummary for bar that maps data.ow facts at entry to bar to data.ow facts at exit from bar. When a call \nsite is encountered in foo with data.ow fact s, the current sum\u00admary for bar is consulted. If the summary \ncontains an entry s . s ' , s ' is added at the return node in foo.Otherwise, data.ow is triggered at \nthe entry node of bar.The map Info is modi.ed to associate each data.ow fact generated in the body of \nbar with the data.ow fact at entry to bar for which data.ow was triggered. This modi.cation enables genera\u00adtion \nof the context-sensitive summaries described above. Context-sensitive property simulation may not terminate \nif the domain of execution states is in.nite, as in constant propagation. Therefore, we restrict context-sensitivity \nto property states. We treat execution states in a context\u00adinsensitive manner, by merging execution states \nfrom di.er\u00adent call sites at function entry nodes using aas (line 36). The algorithm in Figure 6 can \nbe implemented e.ciently using the framework of Reps, Horwitz and Sagiv (RHS, [23]). The complexity of \nthis implementation of property simula\u00adtion is O(V 2|D|(|E||D| + Calls|D|2)), where Calls is the number \nof call sites in the program. A detailed discussion of inter-procedural property simulation, its RHS \nimplemen\u00adtation and its complexity is given in [8]. global 1 Worklist :2N\u00d7D 2 Info :(E \u00d7D) .2S 3 Summary \n:(F \u00d7D) .2S procedure Solve(Global CFG = [N, E, F ]) begin 4 for each [f, d] .F \u00d7E do Summary(f , d):= \n\u00d8 5 for each [e, d] .E \u00d7D do Info(e, d):= \u00d8 6 e := OutT (entryNode(main)) 7 Info(e, $uninit):= {[$uninit, \nT]} 8 Worklist := {[e, $uninit]} 9 while Worklist = \u00d8do 10 Remove a pair [n, d]from Worklist 11 switch(n) \n12 case n .Call: 13 ssin := Info(In0 (n), d) 14 ssout := \u00d8 ' 15 for each d .D s.t. ssin [d ' ]= \u00d8do \n16 if Summary(callee(n), d ' )= \u00d8then 17 ssout := ssout .Summary(callee(n), d ' ) ' 18 AddTrigger(entryNode(callee(n)), \nd , ssin [d ' ]) 19 Add(OutT (n), d,aas (ssout )) 20 case n .Exit: 21 ssin := Info(In0 (n), d) 22 AddToSummary(n, \nd, ssin ) 23 case n .Merge: 24 ssout := Fmrg(n, Info(In0 (n), d), Info(In1 (n), d)) 25 Add(OutT (n),d, \nssout) 26 case n .Branch: 27 ssT := Fbr (n, Info(In0 (n), d), true) 28 ssF := Fbr (n, Info(In0 (n), d), \nfalse) 29 Add(OutT (n),d, ssT ) 30 Add(OutF (n),d,ssF ) 31 case n .Other: 32 ssout := Foth (n, Info(In0 \n(n), d)) 33 Add(OutT (n),d, ssout) 34 return Info end procedure AddTrigger(n, d, ss) begin 35 e := OutT \n(n) ' 36 ss := aas (ss .Info(e, d)) ' 37 Add(e, d, ss ) end procedure Add(e, d, ss) begin 38 if Info(e, \nd)= ss then 39 Info(e, d):= ss 40 Worklist := Worklist .{[dst(e),d]}end procedure AddToSummary(n, d, \nss) begin 41 if Summary(fn(n), d)= ss then 42 Summary(fn(n), d):= ss 43 for each m .returnSites(n) do \n' 44 for each d ' .D s.t. Summary(fn(m), d )= \u00d8do 45 Worklist := Worklist .{[callSite(m),d ' ]} end fn: \nmaps a node to the name of its enclosing function entryNode: maps a function name to its entry node callee: \nmaps a call node to the name of the called function callSite: maps a return-site node to its call-site \nnode returnSites: maps an exit node to its return-site nodes 3.3 Why is property simulation precise? \nProperty simulation selectively merges away information from execution states. Therefore, it is possible \nto construct programs for which property simulation is less precise than full simulation. One such example \nprogram is given in Fig\u00adure 7(a). In this program, because neither branch of the .rst conditional changes \nthe property state, the correlation between dump and flag is lost. As a result, the analysis is unable \nto detect that two of the four paths through the remaining conditionals are infeasible. This leads to \na false error report along the path in which a call to fclose is not preceded by a call to fopen. It \nmay appear that the program in Figure 7(a) represents a common situation in programs, namely that conditions \nguarding transitions are copied around. In fact, this exam\u00adple represents a much narrower class of programs, \nin which .ags are copied around before they are ever used to guard transitions, and di.erent copies of \nthe .ag are used to guard di.erent transitions. The example programs in Figures 7(b) and 7(c) represent \nvariations of the example in Figure 7(a) that occur much more frequently in practice. The program in \nFigure 7(b) represents a situation in which the guarding .ag is passed to another function, so that the \nguard on subsequent transitions is a di.erent variable. Prop\u00aderty simulation is accurate in this case. \nFor each property state at the end of the .rst conditional, the value of dump is known. As a result, \nonly one path is taken through the second conditional, and so the value of flag is known. In other words, \nthe correlation between the property state and flag is preserved. The program in Figure 7(c) represents \na situation in which the guard expression is a complex, expensive operation that the programmer does \nnot wish to repeat or cannot replicate later in the program. Therefore, a .ag is set to indicate whether \nthe .le was opened; this .ag is used later to decide if the .le should be closed. Property simulation \nis accurate in this case as well, because the correlation between flag and the property state is preserved. \nThis example also represents a situation in which a helper function is called to perform some transition. \nThe helper function returns a status code indicating whether it was able to perform the transition. The \n.ag dump may represent some complex condition on the state of the operating system, for instance. Because \nsubsequent transitions are only guarded by flag,there is no loss of precision if the analysis is unable \nto maintain the value of dump in the execution states. Property simulation is precise because it is designed \nto match the behavior of a careful programmer. In order to avoid programming errors, she must maintain \nan implicit correlation between a given property state and the execu\u00adtion states under which the property \nFSM is in that state. Property simulation makes this correlation explicit.  4. ESP In the previous \nsection, we assumed that programs update the state of a single global state machine. In practice, there \nare usually multiple values of a given type (for instance, .le handles) created during execution of the \nprogram; each such value has an associated property FSM, the state of which changes as the program executes. \nIn this section, we describe ESP (Error Detection via Scalable Program Analy- Figure 6: Inter-procedural \nproperty simulation. sis), a system that uses a combination of scalable alias anal\u00ad if (dump) if (dump) \nif (dump) { flag = 1; f = fopen(...); f = fopen(...); else flag = 1; flag = 0; if (dump) } flag = 1; \nelse if (dump) else flag = 0; f = fopen(...); flag = 0; if (flag) if (flag) if (flag) fclose(f); fclose(f); \nfclose(f); (a) (b) (c) Figure 7: Examples highlighting the precision of property simulation. ysis and \nproperty simulation to track the states of multiple stateful values in large C programs. ESP is a partial \nveri.cation method that borrows a key insight from the Metal checking system [11]. The insight behind \nMetal is that the abstraction gap between a tem\u00adporal safety property and C source code could be bridged \nby a programmer-supplied speci.cation. The speci.cation includes an FSM that encodes the property to \nbe checked, a set of source code patterns that indicate how fragments of source code map to transitions \nin the property FSM, and a set of patterns that indicate how fresh stateful values are created by the \nprogram. Figures 1 and 8 show the speci.cation we use for verify\u00ading calls to fprintf in gcc. According \nto this speci.cation, stateful values are created by calls to fopen. Each stateful value goes through \nstate transitions during program execu\u00adtion. A function call that matches a pattern causes a transi\u00adtion \non the property FSM of the value held by the expression in position e at the call site. If the property \nFSM of any stateful value reaches the error state, the program violates the safety property. ESP is a \nconservative system; when it does not report any errors, the programmer is guaranteed that the speci.ed \nproperty is not violated by the program. This characteristic imposes a heavy burden on ESP; the analysis \nmust at once be conservative, precise and scalable. 4.1 Insights behind scalable veri.cation The complication \nintroduced by multiple stateful values is that these values may .ow through assignments to function calls \nin the source code at which the expression in position e appears syntactically di.erent from the value. \nTherefore, a conservative system such as ESP must perform a global value .ow analysis as part of the \nproperty analysis, in order to determine which stateful values are a.ected by a given function call in \nthe code. However, value .ow analysis based on global data.ow analysis has so far proven intractable \non large programs. The .rst insight behind ESP is that property analysis for multiple values can be broken \nup into two sub-problems, each of which can be solved by an analysis at a di.erent precision level. We \ncan use a highly scalable .ow-insensitive but context-sensitive approximation of value .ow to discover \nwhich stateful values are a.ected at every function call in the program that matches a pattern. We can \nthen run property simulation on all of the stateful values, using the results of the previous analysis \ninstead of tracking value .ow directly during property simulation. C code pattern Transition Creation? \ne = fopen( ) Open Yes fclose(e) Close No fprintf(e, ) Print No Figure 8: Source code patterns in ESP. \nThe second insight behind ESP is that by restricting the speci.cation language to preclude properties \nthat correlate the states of multiple values, we can analyze one stateful value at a time, through the \nwhole program, much like a bit-vector data.ow analysis. This approach ampli.es the scaling e.ect of the \nheuristic used in property simulation, because when ESP is tracking one stateful value, branches that \na.ect the states of values other than the tracked value are merged away.  4.2 ESP analysis In this subsection, \nwe describe the analysis components of ESP. Our goal here is to provide enough of an overview so that \nit is clear how ESP utilizes property simulation. We use the simpli.ed version of the core gcc compiler \ncode in Figure 9 as a running example. ESP consists of the following analysis steps. a. CFG construction. \nWe run a scalable points-to anal\u00adysis [7] to produce a conservative approximation of the call graph of \nthe program. We replace every indirect call with di\u00adrect calls to all possible target functions at the \ncall site. The graph is potentially quadratic in the number of call edges, but is linear in practice \nbecause of a simple caching tech\u00adnique explained in [7]. While constructing the call graph, we also produce \nCFGs for all functions. b. Value .ow computation. We run a scalable context\u00adsensitive .ow-insensitive \npoints-to analysis [9] to produce a conservative approximation of the .ow of values in the program. The \nanalysis maps every expression to a node in a value .ow graph (VFG), and answers value .ow queries conservatively: \nif there is some run of the program in which the value of expression e .ows to e ' , then there is a \npath of zero or more .ow edges in the VFG from e to e ' .Because the VFG is context-sensitive, it is \nable to distinguish between value .ow at di.erent call sites to the same function. c. Abstract CFG construction. \nOnce the VFG is pro\u00adduced, we use the property speci.cation to replace calls to  FILE *f1, *f2; 2: \nrestOfComp() { int p1, p2; if (p1) 1 f1 i: printRtl -> inNodes: f f restOfComp -> 1: compFile() { printRtl(f1); \ni 2 j . . .| . if (p1) if (p2) f1 = fopen(...); j: printRtl(f2); inNodes: f1, f2 if (p2) restOfComp(); \n. f2 2 compFile ->f2 = fopen(...); } 3 restOfComp(); 3: printRtl(FILE *f) { } fprintf(f,...); } outNodes: \nf1, f2 (a) (b) (c) (d) Figure 9: Application of ESP on gcc. pattern functions in the CFGs with special \npattern nodes. Each pattern node is parameterized by the VFG node for the expression in position e at \nthe call; this node represents the possible stateful values that may have state transitions at that program \npoint. Example 3. Figures 9(b) and 9(c) show the call graph and the VFG for the program in Figure 9(a). \nThe label i2 on the .ow edge in the VFG indicates that the value of f1 .ows to f due to parameter passing \nat call site i.The subscript on i indicates that the call site is located in the body of function 2 (restOfComp). \nThis information adds a measure of .ow-sensitivity to the VFG. . d. Interface expression computation \n(bottom-up slic\u00ading). In order to track value .ow more accurately, we split up inter-procedural value \n.ow into smaller, more accurate .ows by introducing the concept of interface expressions. The input interface \nexpressions (inNodes) of a function bar include all globals, formal parameters of bar, and derefer\u00adences \nof these. At entry to bar, these expressions may hold stateful values that may have their state changed \nduring ex\u00adecution of bar. The output interface expressions (outNodes) of a function bar include all globals, \nthe return value of bar, and dereferences of these and the formal parameters of bar. At exit from bar, \nthese expressions may hold stateful val\u00adues that were created by bar. In large programs, these sets can \nbe very large, due to global variables. Further, in an unsafe language such as C, the sets cannot be \npruned based on declared types. Instead, we use a bottom-up slicing procedure on the call graph of the \nprogram to prune interface expression sets: An expression e canbe omittedfrominNodes(bar)if there is \nno pattern on expression e ' within bar (or functions called by bar) such that the value of e .ows to \ne ' between the start of bar and the execution of the pattern. Similarly, an expression e canbe omittedfrom \noutNodes(bar)if there is no value creation pattern on expression e ' within bar (or functions called \nby bar) such that the value of e ' .ows to e between the execution of the creation pattern and exit from \nbar. This slicing step allows us to dramatically reduce the number of interface expressions. Mod set \ncomputation. We also use the bottom-up slic\u00ading procedure to compute mod sets for all functions. The \nmod sets are represented implicitly, using VFG nodes in\u00adstead of sets of variables. Mod sets are used \nby property simulation: if a statement is encountered that is too com\u00adplicated for the simulation engine \nto process, the analysis can proceed conservatively by invalidating the values in the execution state \nfor those variables that are in the mod set of the statement. Alias set computation. ESP handles multiple \nstateful values by creating sets of interface expressions called alias sets . An alias set is a set of \nsyntactic expressions that may hold the same stateful value. The alias sets to be tracked in any function \nfoo are created from subsets of the inNodes of foo, or from subsets of the outNodes of functions called \nby foo. Alias sets for input values are created during property simulation. Alias sets for output values \nare created using the bottom-up slicing procedure. One way to view this step is as an escape analysis. \nThe result of this procedure is that for each created value in the program, there is an alias set s associated \nwith the highest (in the call graph) function foo to which the value escapes. We trigger property analysis \nfor each such s by as\u00adsociating a symbolic state [$uninit, T]with s at the entry node of foo. By triggering \ndata.ow in this way, we can dis\u00adcover errors that arise because a value was used before being created \n(for instance, a call to fclose was not preceded by acall to fopen). Example 4. Figure 9(d) shows the \ninterface expressions produced by ESP for the program in Figure 9(a). The po\u00adtential inNodes of printRtl \nare f1, f2, p1, p2,and f.A VFG query reveals that the only one of these whose value is transferred to \nf between the entry point of printRtl and the call to printf is f. The inNodes of restOfComp are f1 and \nf2, as they both .ow to inNode f of callee printRtl.There are two created values in compFile. They escape \nthrough outNodes f1 and f2. The top level function to which the values escape is compFile. The associated \nalias sets are {f1}and {f2}. . e. Property simulation. Intra-procedural case. Suppose we are tracking \nthe state of an alias set s. When we encounter a pattern on e ' , wequery theVFG.Ifsome e . s can .ow \nto e ' , we update the state of s based on the pattern. Furthermore, if some other e '' can .ow to e \n' ,we add an identity transition for s, because the transition may not have occurred on the value being \ntracked. This requirement is introduced because our VFG represents only may information.  Inter-procedural \ncase. Suppose we are tracking alias set s in foo, and we encounter a call to bar.We query  the VFG to \ndetermine which inNodes of bar s may .ow to at this call site. These nodes form an alias set s ' . We \ntrigger data.ow in bar from s ' in an initial state given by the state of s at the call site. Suppose \nwe are tracking alias set s in bar,and we encounter the exit node of bar.At this point, we have discovered \na new component of the summary of bar, namely a state transition d1 . d2 for alias set s.When such a \ntransition is discovered, we re.ect it back to every call site c to bar by adding transitions d1 . d2 \nat c for all alias sets in the caller that may .ow to s at c. As in the intra-procedural case, if multiple \nexpressions from the caller may .ow to s at c,we add the identity transition at c. Example 5. For the \nprogram in Figure 9(a), property simulation tracks the states of alias sets {f1} and {f2} from the entry \nnode of compFile.Consider tracking {f1}.The .rst branch in compFile causes a split in the state of {f1},so \nno merge is performed at the join point. The second branch does not a.ect the state of {f1}, so states \nare merged. As a result, information about p2 is lost. Simulation is trig\u00adgered in restOfComp in two \nways: {f1} in state Opened with p1=T,and {f1} in state $uninit with p1=F. The .rst case veri.es trivially \nbecause fprintf leaves the state Opened un\u00adchanged. In state $uninit, p1=F and therefore call site i \nis not reached. p2 is not tracked in the execution states; hence, call site j is considered. The VFG \nis queried to determine the alias set in printRtl. {f1} does not .ow to any inN\u00adode of printRtl at call \nsite j, resulting in an empty alias set. Therefore, simulation is not triggered in printRtl.A similar \nargument holds for {f2}. .  5. CASE STUDY: FILE OUTPUT IN GCC The goal of ESP is to verify safety properties \nof commer\u00adcial programs, which are typically both large and written in C++. As a .rst step, we have built \na system for ana\u00adlyzing large C programs. In order to understand both the e.ciency and the accuracy of \nproperty simulation, we have applied ESP to the problem of verifying calls to fprintf in the gcc compiler. \nIn this section, we discuss our results. 5.1 gcc We analyze the source code of a version of the gcc compiler \ntaken from the SPEC95 benchmark suite. The structure of this version of gcc is as follows: The main function \ncontains aloop that invokes compile file to compile individual com\u00adpilation units. compile file conditionally \nopens 15 output .les based on user .ags, runs compilation, and then condi\u00adtionally closes the output \n.les. At various points during the compilation process, fprintf is called to write out parts of the RTL \nand/or debugging messages to various output .les, if the corresponding user .ags are set and/or the .les \nare non-NULL. Figure 9(a) shows a snippet of the core gcc code that summarizes its .le output behavior. \ngcc is a complex program: It has 140,000 LOC in 2149 functions spread over 66 .les; there are 1,086 global \nand static variables; the call graph contains a strongly connected component (SCC) with over 450 functions. \nThis SCC comes about because of the recursive descent nature of gcc. The complexity of the call graph \nis not the result of our conserva\u00adtive points-to analysis. Even if we ignore function pointers, this \nSCC has 350 functions. Worse yet, most of the calls to fprintf are buried in functions that either are \nin this SCC or are called from functions in this SCC. 5.2 Veri.cation File output in gcc is a di.cult \nproperty for path-sensitive methods, because the code starts by conditionally creating 15 .le handles \nbased on un-correlated user .ags, and all of these .le handles can reach the calls to fprintf buried \nin the code. Therefore, path-sensitive methods may track all 215 combinations of .le states through the \ncode representing thecoreengineof gcc; this would likely beinfeasible. Our property simulation method, \non the other hand, is ideally suited for the problem. The .le handles are processed one at a time. When \n.le i is processed, all of the conditionals con\u00adtaining calls to fopen except the ith conditional are \nmerged, because they do not a.ect the state of .le i. Therefore, the core code of gcc is simulated in \ntwo con.gurations, one in which .le i is open and user .ag i is true, and another in which .le i is not \nopen but user .ag i, which guards the calls to fprintf reachable by .le i,isfalse. We used ESP to check \ngcc against the speci.cation in Figures 1 and 8. We were able to verify that there is no execution of \nthe program in which fprintf is called on a .le handle in states $uninit or Closed. In addition, a VFG \nquery con.rms that the only values on which fprintf is called are the .le handles created in compile \nfile, stdout,and NULL. The simulation guaran\u00adtees that fprintf is never called on NULL, for the following \nreason. The VFG shows that the only way NULL may .ow to fprintf is through the global .le variables tracked \nby ESP. Suppose that NULL does .ow to a call to fprintf through one of the global .le variables f. Then \nwhen f is processed, this call to fprintf will be reached with f in state $uninit, resulting in a transition \nto the error state. Put together, the conditions above guarantee that all of the 646 calls to fprintf \nin gcc print to valid, open .les. This is a useful, non-trivial property that cannot be expressed using \ntypes. To our knowledge, ESP is the .rst program veri.cation method to have successfully veri.ed temporal \nsafety properties of a program the size of gcc. 5.2.1 Methodology We perform context-sensitive inter-procedural \nproperty simulation of the downwards closure (~140,000 LOC) of compile file in the call graph of gcc. \nIn order to success\u00adfully verify gcc, we made a few changes to the gcc source code. These changes are \nlisted below: The obstack free function contains an indirect call to a free method that pollutes our \ncall graph. We hand modeled this function.  As noted in Section 3.2, our inter-procedural prop\u00aderty \nsimulation algorithm is context-insensitive with respect to the execution state. There are two pairs \nof .le handles (sched dump file/sched2  dump file,and cse dump file/cse2 dump file) for which this merg\u00ading \nblocks veri.cation. For this study, we avoided the problem by creating two copies each of functions cse \nmain, schedule insns,and schedule block.       RunTime (secs) MemUsage (MB) Average 72.9 49.7 \nMaximum 170 102 Table 1: Performance of property simulation. We are exploring ways of introducing context-sensitivity \nwith respect to execution states in a controlled manner. 5.2.2 Why is ESP precise? It is easy to see \nthat property simulation should be accu\u00adrate enough to track the correlated .le output behavior in gcc. \nBecause of the merge heuristic, all of the many thou\u00adsand conditionals in the code that are expensive \nor di.cult to track are merged away with no loss of precision. The other aspect of ESP is the value .ow \nanalysis. Our VFG is precise with respect to top level pointers, but con\u00adservative with respect to pointers \nstored in data structures. Because gcc does not store .le handles in heap-allocated data structures, \nwe are able to generate alias sets and track value .ow accurately. We accept this as a fair advantage, \nbecause our goal in this study is to determine the usefulness of property simulation rather than the \npower of ESP. In our preliminary experiments applying ESP to parts of a large commercial operating system, \nwe have yet to .nd any instances in which property simulation (in particular, the constant propagation \ninstantiation of property simulation) is inaccurate. We have not yet applied ESP in any context in which \nthe value .ow is too complicated for our value .ow analysis. It is likely that as we apply ESP to check \nother properties, the primary precision bottleneck will be the value .ow analysis. In order to address \nthis problem, we have designed a scalable path-sensitive value .ow analysis that tracks alias sets e.ciently, \nusing the merge heuristic built into property simulation.  5.3 Scalability We have implemented inter-procedural \nproperty simula\u00adtion as an extension of a global RHS-style data.ow engine [23, 8]. Some performance statistics \nare summarized in Ta\u00adble 1. The table reports average and maximum values, over the 15 .le handles, of \nrunning time in seconds (wall clock), and memory usage in MB per .le handle. These numbers do not include \nthe cost of building and loading CFGs. This data was generated on a Toshiba Tecra 8200 laptop with a \n1GHz Pentium III processor and 512MB RAM, running Windows XP. The algorithm is surprisingly e.cient, \nespecially consid\u00adering that we have not put signi.cant e.ort into optimizing our implementation. We \nbelieve that the cost of simulation can be amortized signi.cantly by caching states and reusing them \nacross simulations, and by using standard ordering and representation techniques from data.ow analysis. \nWhile we have considered only one program in our case study, we believe that the size and complexity \nof this pro\u00adgram provides a compelling argument that property sim\u00adulation is a scalable method for verifying \ntemporal safety properties of large programs.  6. RELATED WORK In this section, we survey related work \non partial program veri.cation and path-sensitive data.ow analysis. 6.1 Partial program veri.cation Program \nveri.cation [17, 22] has been viewed as the holy grail of software reliability for decades. Over the \nyears, it has been accepted that full scale veri.cation of large code bases is infeasible. However, there \nhas been a resurgence of research in recent years on partial veri.cation: check\u00ading a program against \na speci.cation of a particular tem\u00adporal safety property. We list some examples of projects along these \nlines below. Our work follows the lead of these projects. Typestate analysis. Most recent work on partial \nveri.\u00adcation can be viewed as tracking typestate, .rst introduced by Strom and Yemini in [25]. Typestate \nextends the ordi\u00adnary types in the program, which remain invariant through the lifetime of an object, \nwith a set of states between which values of a given type can transition. ESP can be viewed as a typestate \nchecker for large programs. Partial veri.cation tools. All of these tools can stati\u00adcally guarantee the \nabsence of errors. ESC-Java [14] applies theorem proving methods to verify functions in Java programs \nagainst speci.cations of their pre-conditions and post-conditions. ESC-Java is a local analysis that \nrequires programmer annotations; recent work has focused on automatically generating annotations [15]. \nOur method is less precise that ESC, but is global and free of annotations. The summaries produced by \nESP can be viewed as automatically generated annotations. SLAM [3] is a global path-sensitive veri.cation \nmethod based on iterative re.nement. It starts with a coarse ap\u00adproximation of the program and adds knowledge \nto the ab\u00adstraction in a goal directed manner. However, if the initial abstraction is too coarse, the \niteration e.ort may be too high. Property simulation can be viewed as a way of pro\u00adviding an e.ective \nstarting point for the iteration in SLAM. The .ow-sensitive type quali.er system [19] is similar to the \nanalysis engine in ESP, but is less precise, because it does not handle branch correlation, and it is \nnot context\u00adsensitive with respect to the property state. Error detection tools. All of these tools statically \nex\u00adamine only some execution paths through the code and/or ignore aliasing and complex value .ow. Therefore, \nthey can\u00adnot guarantee the absence of errors. Metal [11] is the error detection tool closest in spirit \nto ESP. The Metal mechanism for specifying safety properties and bridging the gap from source code to \nabstract speci.ca\u00adtion was the inspiration for our work. However, our goal is to guarantee the absence \nof errors. Unlike Metal, therefore, we use a combination of two conservative analyses. The core engine \nof Metal is a local data.ow analysis sim\u00adilar to the standard data.ow analysis described in Section 3. \nIn contrast, our analysis is both inter-procedural and path-sensitive2 . PRE.x [5] is a symbolic evaluator \nthat limits exploration of program paths by truncating the search within a function after an a priori \nbound. PRE.x has found many thousands of errors in very large code bases. LCLint [13] is based on a mix \nof type system extensions 2Recent extensions to Metal incorporate some degree of inter-procedural analysis \nand path-sensitivity [16]. and data.ow analysis. This tool is essentially a local analysis that uses \nfunction annotations if provided. Language mechanisms. The Vault programming lan\u00adguage [10] extends the \nC type system with primitives for tracking the typestate of data items in the program. The programmer \nplaces annotations on function types; the com\u00adpiler then performs local type checking to verify the code. \nThe advantage of this approach is that the programmer is forced to work with the compiler to eliminate \nall type er\u00adrors. However, the expressiveness of the language may be restricted. Recently, the notion \nof typestate has been extended to roles [21]. Roles generalize typestate; the role of an object captures \nits typestate as well as its involvement in aliasing relationships. It is not yet clear whether roles \ncan be checked in a scalable manner. Speci.cation generators. All of the work described above requires \nsome speci.cation of a property of interest from the programmer. Ammons et. al. describe a tech\u00adnique \nfor inferring property FSMs from execution traces, by examining patterns of interactions with a library \nof interest [1]. Engler et. al. describe a static method that identi.es pairs of functions that must \nbe used in a matched fashion by looking for pairs of matched function calls along execution paths [12]. \nBoth of these techniques can be used to generate property speci.cations for ESP. 6.2 Path-sensitive \ndata.ow analysis Our property simulation algorithm follows a long line of work on path-sensitive data.ow \nanalysis. Previous work in this area has focused on moving from the maximal-.xed\u00adpoint (MFP) solution \nto the meet-over-all-paths (MOP) so\u00adlution; For instance, Bodik and Anik introduce a value re\u00adnaming \nscheme in order to obtain MOP information using an MFP analysis [4]. Our particular interest is in ruling \nout infeasible paths. One way of viewing our work is that we have improved the precision of data.ow analysis \nfor our application of property analysis by tracking a .nite set of predicates (those that arise from \nproperty-related branches in the code) in addi\u00adtion to the standard set of data.ow facts (the FSM states). \nHolley and Rosen describe a general method for sharpening data.ow analysis in which data.ow precision \nis improved by adding a .nite set of predicates [18]. Tu and Padua pro\u00adpose a generalized SSA scheme \nin which SSA merge nodes are controlled by boolean predicates [26]. Ammons and Larus present a framework \nfor improving data.ow analy\u00adsis by splitting out a .nite set of interesting paths from the CFG [2]. Property \nsimulation could be viewed as an in\u00adstance of these frameworks; the novelty of our approach lies in the \nparticular choice of predicates and the precision and e.ciency of the resulting analyis. Our work can \nalso be viewed as providing a way of per\u00adforming MOP data.ow on an in.nite domain of data.ow facts. Essentially, \nwe have split the in.nite domain of con\u00adcrete stores into two components, one of which (the FSM states) \nis known to be .nite. We then merge based on the .nite component, guaranteeing termination of the anal\u00adysis. \nSte.en presents a method for splitting the CFG during data.ow analysis whenever the data.ow facts along \nincom\u00ading edges are di.erent [24]. If the data.ow domain is .nite, this strategy leads to an MOP solution \nin .nite time with no loss in precision. Knoop et al extended this work to in.nite domains by devising \na k-limiting heuristic for merging that guarantees termination [20]. Property simulation is novel in \nthat we employ a heuris\u00adtic for termination that matches our intuition about veri.\u00adcation: we maintain \nprecision for those branches that ap\u00adpear to a.ect the property to be checked. Our results show that \nthis heuristic employs the correct merge strategy at join points. Our work is also di.erent in that we \nexploit the special properties of the .nite component of the domain to obtain a polynomial complexity \nbound for our algorithm. This is important because our technique is intended for ap\u00adplication on large \nprograms. We have implemented inter-procedural property simula\u00adtion as an extension of the context-sensitive \nalgorithm of Reps, Horwitz and Sagiv [23]. This formulation allows us to obtain a more e.cient inter-procedural \nalgorithm, and better argue complexity.  7. CONCLUSIONS The application of veri.cation technology to \nlarge pro\u00adgrams has long been a desirable but unachievable goal. In this paper, we have described a new \nalgorithm for path\u00adsensitive program veri.cation that may o.er a way of ap\u00adproaching this goal. Our property \nsimulation algorithm runs in polynomial time and space and is designed to capture the common case of \ncorrelated branch behavior in programs. We have used the algorithm to provide the .rst veri.cation of \ntemporal safety properties for a program of the size of gcc.  Acknowledgements We would like to thank \nthe anonymous reviewers for their comments, Stephen Adams for implementing aspects of ESP, Matthai Phillipose \nfor his help in re-formulating the algo\u00adrithm, Jim Larus for reviewing drafts of this paper, mem\u00adbers \nof the PPRC team at Microsoft Research for building the parsing infrastructure used by ESP, and members \nof the Software Productivity Tools group at Microsoft Research for their help in designing ESP. REFERENCES \n[1] G. Ammons, R. Bodik, and J. Larus. Mining speci.cations. In Conference Record of the Twenty-Ninth \nACM Symposium on Principles of Programming Languages, 2002. [2] G. Ammons and J. Larus. Improving data-.ow \nanalysis with path pro.les. In Proceedings of the ACM SIGPLAN 98 Conference on Programming Language Design \nand Implementation, 1998. [3] T. Ball and S. K. Rajamani. Automatically validating temporal safety properties \nof interfaces. In Proceedings of SPIN 01, 8th Annual SPIN Workshop on Model Checking of Software, May \n2001. [4] R. Bodik and S. Anik. Path-sensitive value-.ow analysis. In Symposium on Principles of Programming \nLanguages, pages 237 251, 1998. [5] W. Bush, J. Pincus, and D. Siela.. A static analyzer for .nding dynamic \nprogramming errors. Software -Practice and Experience, 30(7):775 802, 2000. [6] P. Cousot and R. Cousot. \nAbstract interpretation: a uni.ed lattice model for static analysis of programs by construction or approximation \nof .xpoints. In Conference Record of the Fourth ACM Symposium on Principles of Programming Languages, \n1977. [7] M. Das. Uni.cation-based pointer analysis with directional assignments. In Proceedings of the \nACM SIGPLAN 2000 Conference on Programming Language Design and Implementation, 2000. [8] M. Das, S. \nLerner, and M. Seigle. ESP: Path-Sensitive Program Veri.cation in Polynomial Time. Technical Report MSR-TR-2002-41, \nMicrosoft Corporation, 2002. [9] M. Das, B. Liblit, M. F\u00a8ahndrich, and J. Rehof. Estimating the Impact \nof Scalable Pointer Analysis on Optimization. In 8th International Symposium on Static Analysis, 2001. \n[10] R. Deline and M. F\u00a8ahndrich. Enforcing high-level protocols in low-level software. In Proceedings \nof the ACM SIGPLAN 2001 Conference on Programming Language Design and Implementation, 2001. [11] D. Engler, \nB. Chelf, A. Chou, and S. Hallem. Checking system rules using system-speci.c, programmer-written compiler \nextensions. In Proceedings of the sixth USENIX Conference on Operating systems design and implementation, \n2000. [12] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf. Bugs as deviant behavior: A general \napproach to inferring errors in systems code. In Proceedings of the Eighteenth ACM Symposium on Operating \nSystems Principles, 2001. [13] D. Evans. Static detection of dynamic memory errors. In Proceedings of \nthe ACM SIGPLAN 96 Conference on Programming Language Design and Implementation, 1996. [14] C. Flanagan, \nK. R. M. Leino, M. Lillibridge, G. Nelson, J.B.Saxe, andR.Stata.ExtendedStatic Checking for Java. In \nProceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation, 2002. \n[15] C. Flanagan and R. Leino. Houdini, an annotation assistant for esc/java. In Symposium of Formal \nMethods Europe, March 2001., 2001. [16] S. Hallem, B. Chelf, Y. Xie, and D. Engler. A system and language \nfor building system-speci.c, static analyses. In Proceedings of the ACM SIGPLAN 2002 Conference on Programming \nLanguage Design and Implementation, 2002. [17] C. A. R. Hoare. An axiomatic basis for computer programming. \nIn C. A. R. Hoare and C. B. Jones (Ed.), Essays in Computing Science, Prentice Hall. 1989. [18] L. Holley \nand B. Rosen. Quali.ed data.ow analysis. In Conference Record of the Seventh ACM Symposium on Principles \nof Programming Languages, 1980. [19] A. Aiken J. S. Foster, T. Terauchi. Flow-Sensitive Type Quali.ers. \nIn Proceedings of the ACM SIGPLAN 2002 Conference on Programming Language Design and Implementation, \n2002. [20] J. Knoop, O. R\u00a8uthing, and B. Ste.en. Expansion-based removal of semantic partial redundancies. \nIn Proceedings of the 8th International Conference on Compiler Construction (CC 99) (Amsterdam, The Netherlands), \nLecture Notes in Computer Science, vol. 1575, pages 91 106. Springer-Verlag, Heidelberg, Germany, 1999. \n[21] V. Kuncak, P. Lam, and M. Rinard. Role analysis. In Conference Record of the Twenty-Ninth ACM Symposium \non Principles of Programming Languages, 2002. [22] G. Nelson and D. C. Oppen. Simpli.cation by cooperating \ndecision procedures. TOPLAS: ACM Transactions on Programming Languages and Systems, 1(2):245 257, 1979. \n[23] T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural data ow analysis via graph reachability. \nIn Conference Record of the Twenty-Second ACM Symposium on Principles of Programming Languages, 1995. \n[24] B. Ste.en. Property-oriented expansion. In LNCS 1145, 3rd International Symposium on Static Analysis, \n1996, pages 22 41. Springer-Verlag, 1996. [25] R. Strom and S. Yemini. Typestate: A programming language \nconcept for enhancing software reliability. IEEE Transactions on Software Engineering, 12(1):157 171, \n1986. [26] P. Tu and D. Padua. Gated SSA-based demand-driven symbolic analysis for parallelizing compilers. \nIn Proceedings of the 1995 ACM International Conference on Supercomputing, Barcelona, Spain, 1995. [27] \nR. Wilson and M. Lam. E.cient context-sensitive pointer analysis for C programs. In Proceedings of the \nACM SIGPLAN 95 Conference on Programming Language Design and Implementation, 1995.  \n\t\t\t", "proc_id": "512529", "abstract": "In this paper, we present a new algorithm for partial program verification that runs in polynomial time and space. We are interested in checking that a program satisfies a given temporal safety property. Our insight is that by accurately modeling only those branches in a program for which the property-related behavior differs along the arms of the branch, we can design an algorithm that is accurate enough to verify the program with respect to the given property, without paying the potentially exponential cost of full path-sensitive analysis.We have implemented this \"property simulation\" algorithm as part of a partial verification tool called ESP. We present the results of applying ESP to the problem of verifying the file I/O behavior of a version of the GNU C compiler (gcc, 140,000 LOC). We are able to prove that all of the 646 calls to <b>.fprintf</b> in the source code of gcc are guaranteed to print to valid, open files. Our results show that property simulation scales to large programs and is accurate enough to verify meaningful properties.", "authors": [{"name": "Manuvir Das", "author_profile_id": "81100143266", "affiliation": "Microsoft Research", "person_id": "PP14060503", "email_address": "", "orcid_id": ""}, {"name": "Sorin Lerner", "author_profile_id": "81100399150", "affiliation": "University of Washington", "person_id": "PP43119616", "email_address": "", "orcid_id": ""}, {"name": "Mark Seigle", "author_profile_id": "81100351618", "affiliation": "University of Washington", "person_id": "P348270", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512529.512538", "year": "2002", "article_id": "512538", "conference": "PLDI", "title": "ESP: path-sensitive program verification in polynomial time", "url": "http://dl.acm.org/citation.cfm?id=512538"}