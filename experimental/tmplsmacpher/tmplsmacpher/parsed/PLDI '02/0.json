{"article_publication_date": "05-17-2002", "fulltext": "\n Flow-Sensitive Type Quali.ers* Jeffrey S. Foster Tachio Terauchi Alex Aiken EECS Department University \nof California, Berkeley Berkeley, CA 94720-1776 {jfoster,tachio,aiken}@cs.berkeley.edu ABSTRACT We \npresent a system for extending standard type systems with .ow-sensitive type quali.ers. Users annotate \ntheir pro\u00adgrams with type quali.ers, and inference checks that the annotations are correct. In our system \nonly the type quali\u00ad.ers are modeled .ow-sensitively the underlying standard types are unchanged, which \nallows us to obtain an e.cient constraint-based inference algorithm that integrates .ow\u00adinsensitive alias \nanalysis, e.ect inference, and ideas from linear type systems to support strong updates. We demon\u00adstrate \nthe usefulness of .ow-sensitive type quali.ers by .nd\u00ading a number of new locking bugs in the Linux kernel. \n Categories and Subject Descriptors D.2.1 [Software Engineering]: Requirements/Speci.cations; D.2.4 [Software \nEngineering]: Software/Program Veri.\u00adcation; D.3.3 [Programming Languages]: Language Con\u00adstructs and \nFeatures; F.3.1 [Logics and Meanings of Pro\u00adgrams]: Specifying and Verifying and Reasoning about Pro\u00adgrams; \nF.3.3 [Logics and Meanings of Programs]: Stud\u00adies of Program Constructs  General Terms Algorithms, Design, \nReliability, Experimentation, Languages, Theory, Veri.cation  Keywords Types, type quali.ers, alias \nanalysis, e.ect inference, .ow\u00adsensitivity, constraints, restrict, locking, Linux kernel * This research \nwas supported in part by NSF CCR-9457812, NASA Contract No. NAG2-1210, NSF CCR-0085949, and DARPA Contract \nNo. F33615-00-C-1693. Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 02, June 17-19, 2002, Berlin, Germany. Copyright 2002 ACM 1-58113-463-0/02/0006 ...$5.00. \n1. INTRODUCTION Standard type systems are .ow-insensitive, meaning a value s type is the same everywhere. \nHowever, many impor\u00adtant program properties are .ow-sensitive. Checking such properties requires associating \ndi.erent facts with a value at di.erent program points. This paper shows how to extend standard type \nsystems with user-speci.ed .ow-sensitive type quali.ers, which are atomic properties that re.ne standard \ntypes. In our system users annotate programs with type quali.ers, and inference checks that the annotations \nare correct. The critical feature of our approach is that .ow-sensitivity is restricted to the type quali.ers \nthat decorate types the underlying standard types are unchanged which allows us to obtain an e.cient \ntype inference algorithm. Type quali.ers capture a natural class of .ow-sensitive properties, while e.cient \ninference of the type quali.ers allows us to apply an implementation to large code bases with few user \nannotations. As an example of type quali.ers, consider the type File used for I/O operations on .les. \nIn most systems File op\u00aderations can only be used in certain ways: a .le must be opened for reading before \nit is read, it must be opened for writing before it is written to, and once closed a .le cannot be accessed. \nWe can express these rules with .ow-sensitive type quali.ers. We introduce quali.ers open, read, write, \nreadwrite, and closed. The type open File describes a .le that has been opened in an unknown mode, the \ntype read File (respectively write File) is a .le that is open for reading (respectively writing), the \ntype readwrite File is a .le open for both reading and writing, and the type closed File is a closed \n.le. These quali.ers capture inher\u00adently .ow-sensitive properties. For example, the close() function \ntakes an open File as an argument and changes the .le s state to closed File. These .ve quali.ers have \na natural subtyping relation: readwrite = read = open and readwrite = write = open. The quali.er closed \nis incomparable to other quali.ers be\u00adcause a .le may not be both closed and open. Quali.ers that introduce \nsubtyping are very common, and our framework supports subtyping directly; in addition to a set of quali.ers, \nusers can de.ne a partial order on the quali.ers. Our results build on recent advances in .ow-sensitive \ntype systems [5, 7, 25] as well as our own previous work on .ow\u00adinsensitive type quali.ers [16, 24]. \nThe main contribution of our work is a practical, .ow-sensitive type inference al\u00adgorithm, in contrast \nto the type checking systems of [5, 7, 25]. Our .ow-sensitive type inference algorithm is made prac\u00adtical \nby solving constraints lazily. As in any .ow-sensitive analysis, explicitly forming a model of the store \nat every pro\u00adgram point is prohibitively expensive for large code bases. By generating a constraint system \nlinear in the size of the type-annotated program and solving only the portion of the constraints needed \nto check quali.er annotations, our algo\u00adrithm is able to scale to large examples. Finally, our system \nis designed to be sound; we aim to prove the absence of bugs, not just to be heuristically good at .nding \nbugs. For example, we believe that our system could be integrated into Java in a sound manner. We have \nshown soundness for restrict (Section 4), a key new con\u00adstruct in our system (see technical report [15]). \nSince the remainder of our system can be viewed as a simpli.cation of [25], we believe it is straightforward \nto prove soundness for our full type system using their techniques. In Section 5 we report on experience \nwith two applica\u00adtions, analyzing locking behavior in the Linux kernel and analyzing C stream library \nusage in application code. Our system found a number of new locking bugs, including some that extend \nacross multiple functions or even, in one case, across multiple .les. 1.1 System Architecture Our .ow-sensitive \nquali.er inference algorithm has several interlocking components. We .rst give an overview of the major \npieces and how they .t together. We expect programmers to interact with our type sys\u00adtem, both when adding \nquali.er annotations and when re\u00adviewing the results of inference. Thus, we seek a system that supports \ne.cient inference and is straightforward for a programmer to understand and use. Our type inference system \nintegrates alias analysis, e.ect inference, and ideas from linear type systems. We use a .ow-insensitive \nalias analysis to construct a model of the store. The alias analysis infers an abstract location for \nthe result of each program expression; ex\u00adpressions that evaluate to the same abstract location may be \naliased.  We use e.ect inference [20] to calculate the set of ab\u00adstract locations an expression e might \nuse during e s evaluation. These e.ects are used in analyzing func\u00adtion calls and restrict (see below). \nE.ect inference is done simultaneously with alias analysis.  We model the state at a program point as \nan abstract store, which is a mapping from abstract locations to types. We can use the abstract locations \nfrom the .ow\u00adinsensitive alias analysis because we allow only the type quali.ers, and not the underlying \nstandard types, to change during execution. We represent abstract stores using a constraint formalism. \nStore construc\u00adtors model allocations, updates, and function calls, and store constraints C1 = C2 model \na branch from the program point represented by store C1 to the pro\u00adgram point represented by store C2. \n We compute a linearity [25] for each abstract location at each program point. Informally, an abstract \nloca\u00adtion is linear if the type system can prove that it corre\u00adsponds to a single concrete location in \nevery execution; otherwise, it is non-linear. We perform strong updates  [4] on locations that are linear \nand weak updates on locations that are non-linear. A strong update can change the quali.er on a location \ns type arbitrarily. Weak updates cannot change quali.ers. Computing linearities is important because \nmost interesting .ow\u00adsensitive properties require strong updates. The system described so far has a serious \npractical weakness: Type inference may fail because a location on which a strong update is needed may \nbe inferred to be non-linear. We address this with a new anno\u00adtation restrict. The expression restrict \nx =e in e ' introduces a new name x bound to the value of e. The name x is given a fresh abstract location, \nand among all aliases of e, only x and values derived from x may be used within e ' . Thus the location \nof x may be linear, and hence may be strongly updated, even if the loca\u00adtion of e is non-linear. We use \ne.ects to enforce the cor\u00adrectness of restrict expressions soundness requires that the location of e \ndoes not appear in the e.ect of e . We use e.ects to increase the precision of the analysis. If an expression \ne does not reference location ., which we can determine by examining the e.ect of e, then it does not \naccess the value stored at ., and the analysis of . can simply .ow from the store preceding e to the \none immediately after e without passing through e.If e is an application of a function called in many \ndi.erent contexts, then this idea makes e fully polymorphic in all the locations that e does not reference. \n 2. RELATED WORK We discuss three threads of related work: type systems, data.ow analysis, and tools \nfor .nding bugs in software. Type Systems. Our type system is inspired by region and alias type checking \nsystems designed for low-level programs [5, 25, 29]. Two recent language proposals, Vault [7] and Cyclone \n[17], adapt similar ideas for checking high-level pro\u00adgrams. Both of these languages are based on type \nchecking and require programmers to annotate their programs with types. In contrast, we propose a simpler \nand less expressive monomorphic type system that is designed for e.cient type inference. Our system incorporates \ne.ect inference [20, 32] to gain a measure of polymorphism. Recent work on Vault [12] includes a construct \nfocus that is similar to restrict. The type state system of NIL [27] is one of the earliest to incorporate \n.ow-sensitive type checking. Xu et al [33] use a .ow-sensitive analysis to check type safety of machine \ncode. Type systems developed for Java byte code [22, 26] also incorporate .ow-sensitivity to check for \ninitialization before use and to allow reuse of the same local variable with di.erent types. Igarashi \nand Kobayashi [18] propose a general framework for resource usage analysis, which associates a trace \nwith each object specifying valid accesses to the object and checks that the program satis.es the trace \nspeci.cations. They provide an inference algorithm, although it is unclear how e.cient it is in practice \nsince it invokes as a sub-step an unspeci.ed algorithm to check that a trace set is valid. Flanagan and \nFreund [13] use a type checking system to verify Java locking behavior. In Java locks are acquired and \nreleased according to a lexical discipline. To model locking in the Linux kernel (as in Section 5) we \nmust allow non\u00adlexically scoped lock acquires and releases. The subset of our system consisting of alias \nanalysis and e.ect inference can be seen as a monomorphic variant of region inference [28]. The improvements \nto region infer\u00adence reported in [2] are a much more expensive and precise method for computing linearities. \nData.ow Analysis. Although our type-based approach is related to data.ow analysis [1], it di.ers from \nclassical data.ow analysis in several ways. First, we generate constraints over stores and types to model \nthe program. Thus there is no dis\u00adtinction between forward and backward analysis; informa\u00adtion may .ow \nin both directions during constraint resolution, depending on the speci.ed quali.er partial order. Second, \nwe explicitly handle pointers, heap-allocated data, aliasing, and strong/weak updates. Third, there is \nno distinction be\u00adtween interprocedural and intraprocedural analysis in our system. The strong/weak update \ndistinction was .rst described by Chase et al [4]. Several techniques that allow strong up\u00addates have \nbeen proposed for data.ow-based analysis of pro\u00adgrams with pointers, among them [3, 8, 31]. Jagannathan \net al [19] present a system for must-alias analysis of higher\u00adorder languages. The linearity computation \nin our system corresponds to their singleness computation, and they use a similar technique to gain polymorphism \nby .owing some bindings around function calls. Another recent system for checking typestate properties \nis ESP [6]. Like our proposal, ESP incorporates a conservative alias analysis. There are also signi.cant \ndi.erences: ESP is more directly based on data.ow analysis and incorporates a path-sensitive symbolic \nexecution component. ESP has been used to check the correctness of C stream library usage in gcc. Bug-Finding \nTools. The AST Toolkit provides a frame\u00adwork for posing user-speci.ed queries on abstract syntax trees \nannotated with type information. The AST Toolkit has been successfully used to uncover many bugs [30]. \nMeta-level compilation [9] is a system for .nding bugs in programs. The programmer speci.es a .ow-sensitive \nprop\u00aderty as an .nite state automaton. A program is analyzed by traversing control paths and triggering \nstate transitions of the automata on particular actions in program statements. The system warns of potential \nerrors when an automaton en\u00adters an error state. In [9] an intraprocedural analysis of lock usage in \nthe Linux kernel uncovered many local locking bugs. Our type-based system found interprocedural locking \nbugs that extended across multiple functions or even, in one case, across multiple .les (Section 5).1 \nNewer work on meta-level compilation [10] includes some interprocedural data.ow, but it is unclear how \ntheir interprocedural data.ow analysis han\u00addles aliasing. LCLint [11] is a data.ow-based tool for checking \nprop\u00aderties of programs. To use LCLint, the programmer adds extra annotations to their program. LCLint \nperforms .ow\u00adsensitive intraprocedural analysis, using the programmer s 1The bugs were found in a newer \nversion of the Linux kernel than examined by [9], so a direct comparison is not possible, though these \nbugs cannot be found by purely intraprocedu\u00adral analysis. annotations at function calls. ESC/Java [14] \nis a tool for .nding errors in Java programs. ESC/Java uses sophisticated theorem-proving technology \nto verify program properties, and it includes a rich language for program annotations.  3. TYPE SYSTEM \nWe describe our type system using a call-by-value lambda calculus extended with pointers and type quali.er \nannota\u00adtions. The source language is e ::= x | n | .x.e | e1 e2 | ref e | !e | e1 := e2 | assert(e, Q) \n| check(e, Q) Here x is a variable, n is an integer, .x.e is a function with argument x and body e, the \nexpression e1 e2 is the appli\u00adcation of function e1 to argument e2, the expression ref e allocates memory \nand initializes it to e, the expression !e dereferences pointer e, and the expression e1 := e2 assigns \nthe value of e2 to the location e1 points to. We introduce quali.ers into the source language by adding \ntwo new forms [16]. The expression assert(e, Q) asserts that e s top-level quali.er is Q, and the expression \ncheck(e, Q) type checks only if e s top-level quali.er is at most Q. Our type inference algorithm is \ndivided into two steps. First we perform an initial .ow-insensitive alias analysis and e.ect inference. \nSecond we generate and solve store and quali.er constraints and compute linearities. 3.1 Alias Analysis \nand Effect Inference We present the .ow-insensitive alias analysis and e.ect in\u00adference as a translation \nsystem rewriting source expressions to expressions decorated with locations, types, and e.ects. The target \nlanguage is e ::= x | n | .L x:t.e | e1 e2 | ref. e | !e | e1 := e2 | assert(e, Q) | check(e, Q) t ::= \na | int | ref (.) | t -. L t' L ::= . |{ .}| L1 . L2 | L1 n L2 The target language extends the source \nlanguage syntax in two ways. Every allocation site ref. e is annotated with the abstract location . that \nis allocated, and each function .L x:t.e is annotated with both the type t of its parameter and the e.ect \nL of calling the function. E.ects are unions and intersections of e.ect variables ., which represent \nan unknown set of e.ects that e.ect inference solves for, and e.ect constants ., which stands for either \na read, write, or allocation of location .. For simplicity in this paper we do not distinguish which \nof the three possible e.ects . stands for, although we do so in our implementation. Foreshadowing .ow-sensitive \nanalysis, pointer types are written ref (.), and we maintain a separate global abstract store CI mapping \nlocations . to types; CI (.)= t if location . contains data of type t . If type inference requires . \n= .', ' we also require CI (.)= CI (.'). Function types t -. L tcontain the e.ect L of calling the function. \nFigure 1 gives rules for performing alias analysis and ef\u00adfect inference while translating source programs \ninto our target language. This translation system proves judgments ' G f e . e: t; L, meaning that in \ntype environment G, ex\u00adpression e translates to expression e', which has type t, and the evaluation of \ne may have e.ect L. x .dom(G) (Var) G fx.x :G(x); \u00d8 (Int) G fn.n: int; \u00d8 ' G fe.e : t; LCI (.)= t. fresh \n(Ref) ' G fref e .ref. e : ref (.); L.{.} ' G fe.e : t; Lt = ref (.) . fresh (Deref) ' G f!e .!e : CI \n(.); L.{.} ' ' G fe1 .e1 : t1; L1 G fe2 .e2 : t2; L2 t1 = ref (.) CI (.)= t2 . fresh (Assign) '' G fe1 \n:= e2 .e1 := e : t2; L1 .L2 .{.} 2 ' G[x : t; LL .. a,. fresh .a] fe .e (Lam) ' G f.x.e...x:a.e : a -.. \nt; \u00d8 ' ' : t1; L1 t1 = t2 -.. \u00df .,\u00df fresh G fe1 .e1 G fe2 .e2 : t2; L2 (App) ' ' G fe1 e2 .e1 e : \u00df; \nL1 .L2 .. 2 ' G fe.e : t; L (Assert) G fassert(e,Q) .assert(e ' ,Q): t; L ' G fe .e : t; L (Check) ' \nG fcheck(e,Q) .check(e ,Q): t; L ' G fe.e : t; L (Down) ' G fe.e : t; Ln(locs(G) .locs(t)) Figure 1: \nType, alias, and e.ect inference The set of locations appearing in a type, locs(t), is locs(int)= \u00d8 locs(ref \n(.)) = {.}.locs(CI (.)) locs(t1 -.L t2)= locs(t1) .locs(t2) .L We assume that locs(a) is empty until \na is equated with a . constructed type. We de.ne locs(G) to be locs(t). [x .t.G] We brie.y discuss the \nrules in Figure 1: (Var) and (Int) are standard. In lambda calculus, a variable is an r-value, not an \nl-value, and accessing a variable has no e.ect.  (Ref) allocates a fresh abstract location .. We add \nthe e.ect {.}of the allocation to the e.ect and record in CI the type to which the location . points. \n (Deref) evaluates e, which yields a value of type t.As is standard in type inference, to compute the \nlocation e points to we create a fresh location . and equate the type t with the type ref (.). We look \nup the type of location . in CI and add . to the e.ect set.  (Assign) writes a location. Note that the \ntype of e2 and the type that e1 points to are equated. Because types contain locations, this forces potentially \naliased locations to be modeled by one abstract location.  (Lam) de.nes a function. We annotate the \nfunction with the e.ect . of the function body and the type a of the parameter. Function types always \nhave an e.ect  fun fw = fun{.z}fw: ref (.z)= let x = ref 0 let x= ref.x 0 y = ref(assert(1,qa)) y = \nref.y (assert(1,qa)) z = ref(assert(2,qb)) z = ref.z (assert(2,qb)) in in /* Write to x s cell */ x:= \n3; x:= 3; w:= 4; w:= 4; y:= assert(5,qc); y:= assert(5,qc); if (\u00b7\u00b7\u00b7) if (\u00b7\u00b7\u00b7) fz; fz; check(!y,qc) check(!y,qc) \n(a) Source program (b) Target program CI (.x)= CI (.y)= CI (.z)= int Figure 2: Example alias and e.ect \nanalysis variable . on the arrow, which makes e.ect inference easier. Notice that creating a function \nhas no e.ect (the potential allocation of a closure does not count as an e.ect, because a closure cannot \nbe updated). (App) applies a function to an argument. The e.ect of applying e1 to e2 includes the e.ect \n. of calling the function e1 represents. Notice that e1 s argument type is constrained to be equal to \nthe type of e2. As before, this forces possibly-aliased locations to have the same abstract location. \n (Assert) and (Check) are translated unchanged into the target language. Quali.ers are .ow-sensitive, \nso we do not model them during this .rst, .ow-insensitive step of the algorithm.  (Down) hides e.ects \non purely local state. If evaluat\u00ading e produces an e.ect on some location . neither in G nor in t, then \n. cannot be accessed in subsequent com\u00adputation. Thus we can conservatively approximate the set of e.ects \nthat may be visible as locs(G) .locs(t). By intersecting the e.ects L with the set of e.ects that may \nbe visible, we increase the precision of e.ect inference, which in turn increases the precision of .ow\u00adsensitive \ntype quali.er inference. Although (Down) is not a syntactic rule, it only needs to be applied once per \nfunction body [15].  Figure 2 shows an example program and its translation. We use some syntactic sugar; \nall of these constructs can be encoded in our language (e.g., by assuming a primitive Y combinator of \nthe appropriate type). In this example the constant quali.ers qa, qb, and qc are in the discrete partial \norder (the quali.ers are incomparable). Just before f re\u00adturns, we wish to check that y has the quali.er \nqc. This check succeeds only if we can model the update to y as a strong update. In Figure 2, we assign \nx, y, and z distinct locations .x, .y, and .z, respectively. Because f is called with argument z and \nour system is not polymorphic in locations, our alias analysis requires that the types of z and w match, \nand thus w is given the type ref (.z). Finally, notice that since x and y are purely local to the body \nof f, using the rule (Down) our analysis hides all e.ects on .x and .y. The e.ect of f is {.z}because \nf writes to its parameter w, which has type ref (.z). (More precisely, f has e.ect . where {.z}...) Let \nn be the size of the input program. Applying the rules in Figure 1 generates a constraint system of size \nO(n), using a suitable representation of locs(G) . locs(t) (see [15]). Resolving the type equality constraints \nin the usual way with uni.cation takes O(na(n)) time, where a(\u00b7 ) is the inverse Ackerman s function. \nThe remaining constraints are e.ect constraints of the form L . .. We solve these constraints on-demand \nin the next step of the algorithm we ask queries of the form . . L. We can answer all such queries for \na single location . in O(n) time [15]. . .1 .n 3.2 Stores and Quali.ed Types :t1,...,.:t1 { . ,...,. \nn n n ' Q= Q (Int=) ' Q int = Q int ' Q= Q (Ref=) ' Q ref (.)= Q ref (.) ' t ' = t ' Q= Qt2 = t1 12 '' \nC2 = C1 C1 = C2 (Fun=) '' ' Q(C1,t1)-. L (C ,t ' )= Q (C2,t2)-. L (C ,t ' ) 1122 ' ti = t ' .i = .i =1..n \nii (Store=) . 1 . :t ' 1 :t ' n n}={ . } 1 Next we perform .ow-sensitive analysis to check the quali.er\u00adrelated \nannotations. In this second step of the algorithm we Figure 3: Store compatibility rules S(C1) = S(C2) \naccording to the rules in Figure 3, and the take as input a program that has been decorated with types, \nlocations, and e.ects by the inference algorithm of Figure 1. Throughout this step we treat the abstract \nlocations . and e.ects L from the .rst step as constants. We analyze the input program using the extended \ntypes shown below: solution satis.es the rules in Figure 4. In Figure 3, constraints between stores yield \nconstraints t ::= Qs Q ::= . | B s ::= a | int | ref (.) | (C, t) -. L (C ' ,t ' ) C ::= e | Alloc(C, \n.) | Assign(C, . : t) | Merge(C, C ' ,L) | Filter(C, L) . ::= 0 | 1 | . Here quali.ed types t are standard \ntypes with quali.ers in\u00adserted at every level. Quali.ers Q are either quali.er vari\u00adables ., which stand \nfor currently unknown quali.ers, or constant quali.ers B, speci.ed by the user. We assume a supplied \npartial order = among constant quali.ers. The .ow-sensitive analysis associates a store C with each program \npoint. This is in contrast to the .ow-insensitive step, which uses one global store CI to give types \nto loca\u00adtions. Function types are extended to (C, t) -. L (C ' ,t ' ), where C describes the store the \nfunction is invoked in and C ' describes the store when the function returns. Each location in each store \nhas an associated linearity .. There are three linearities: 0 for unallocated locations, 1 for linear \nlocations (these admit strong updates), and . for non\u00adlinear locations (which admit only weak updates). \nThe three linearities form a lattice 0 < 1 <.. Addition on linearities is as expected: 0 + x = x,1+1= \n., and . + x = .. A store is a vector .1 .n { .:t1,...,.:tn} 1 n that assigns a type ti and a linearity \n.i to every abstract location .i computed by the alias analysis. We call such a vector a ground store.If \nG is a ground store, we write G(.) for . s type in G, and we write Glin(.) for . s linearity in G. Rather \nthan explicitly associating a ground store with ev\u00adery program point, we represent stores using a constraint \nformalism. As the base case, we model an unknown store using a store variable e. We relate stores at \nconsecutive program points either with store constructors (see below), which build new stores from old \nstores, or with store con\u00adstraints C1 = C2, which are generated at branches from the program point represented \nby store C1 to the program point represented by store C2. A solution to a system of store constraints \nis a mapping from store variables to ground stores, and from Assign(\u00b7\u00b7\u00b7 ) stores (see below) to types. \nA solution S satis.es a system of store constraints if for each constraint C1 = C2 we have between linearities \nand types, which in turn yield constraints between quali.ers and between stores. In our constraint resolution \nalgorithm, we exploit the fact that we are only interested in quali.er relationships to solve as little \nof the expensive store constraints as possible (see Section 3.4). In (Ref=) we require that the locations \non the left-and right-hand sides of the = are the same. Alias analysis en\u00adforces this property, which \ncorresponds to the standard re\u00adquirement that subtyping becomes equality below a pointer constructor. \nWe emphasize that in this step we treat ab\u00adstract locations . as constants, and we will never attempt \n(or need) to unify two distinct locations to satisfy (Ref=). In (Fun=) we require that the e.ects of \nthe constrained function types match exactly. It would also be sound to allow the e.ect of the left-hand \nfunction to be a subset of the e.ect of the right-hand function. Figure 4 formalizes the four kinds of \nstore constructors by showing how a solution S behaves on constructed stores. The store Alloc(C, .) is \nthe same as store C, except that location . has been allocated once more. Allocating location . does \nnot a.ect the types in the store but increases the linearity of location . by one. The store Merge(C, \nC ' ,L) combines stores C and C ' ac\u00adcording to e.ect L.If . . L, then Merge(C, C ' ,L) assigns . the \ntype it has in C, otherwise Merge(C, C ' ,L) assigns . the type it has in C ' . The linearity de.nition \nis similar. The store Filter(C, L) assigns the same types and linear\u00adities as C for all locations . such \nthat . . L. The types of all other locations are unde.ned, and the linearities of all other locations \nare 0. Finally, the store Assign(C, . : t) is the same as store C, except location . has been updated \nto type t ' where t = t ' (we allow a subtyping step here). If . is non-linear in C, then in Figure 4(c) \nwe require that the type of . in Assign(C, . : t) be at least the type of . in C; this corresponds to \na weak update. (In our implementation we require equality here.) Putting these together, intuitively \nif . is linear then its type in Assign(C, . : t)is t, otherwise its type is t S(C)(.), where is the least-upper \nbound.  3.3 Flow-Sensitive Constraint Generation Figure 5 gives the type inference rules for our system. \nIn this system judgments have the form G,C f e : t, C ' , meaning that in type environment G and with \ninitial store ' S(Alloc(C,. ))(.)= S(C)(.) {S(C)(.) . . L ' S(Merge(C,C ,L))(.)= ' S(C )(.) otherwise \nS(Filter(C,L))(.)= S(C)(.) . . L {t ' where t = t ' . = . ' ' S(Assign(C,. : t))(.)= S(C)(.) otherwise \n(a) Types (.) . = . ' {1+ S(C)lin' S(Alloc(C,. (.)= ))linS(C)lin(.) otherwise {(.) .. L S(C)lin S(Merge(C,C \n(.)= ' ' ,L))linS(C )lin(.) otherwise { (.) . . L S(C)lin 0 otherwiseS(Filter(C,L))lin(.)= ' S(Assign(C,. \n(.)= (.) : t))linS(C)lin (b) Linearities (.)= . =. S(C)(.) = S(Assign(C,. : t))(.) S(C)linfor all stores \nAssign(C,. : t) (c) Weak updates Figure 4: Extending a solution to constructed stores C, evaluating e \nyields a result of type t and a new store C ' . We write C(.) for the type associated with . in store \nC; we discuss the computation of C(.) in Section 3.4. We use the function sp(t) to decorate a standard \ntype t with fresh quali.er and store variables: sp(a)= .a . fresh sp(int)= . int . fresh sp(ref (.)) \n= . ref (.) . fresh ' ''' sp(t-. L t )= .(e,sp(t)) -. L (e,sp(t )) .,e,e fresh We brie.y discuss the \nrules in Figure 5: (Var) and (Int) are standard. For (Int), we pick a fresh quali.er variable . to annotate \nn s type.  (Ref) adds a location . to the store C ' , yielding the store Alloc(C ' ,.). The type t of \ne is constrained to be compatible with . s type in C ' . 2  (Deref) looks up the type of e s location \n. in the cur\u00adrent store C ' . In this rule, any quali.er may appear on e s type; quali.ers are checked \nonly by (Check), see below.  (Assign) produces a new store representing the assign\u00adment of type t to \nlocation ..  (Lam) type checks function body ein fresh initial store e and with parameter x bound to \na type with fresh quali.er variables.  2An alternative formulation is to track the type t of e as part \nof the constructed store Alloc(\u00b7 ,\u00b7 ), and only constrain t to be compatible with C ' (.) if after the \nallocation . is non-linear. x. dom(G) (Var) G,C f x:G(x),C . fresh (Int) G,C f n : . int,C ' G,C f e \n: t,C t = C ' (.) . fresh (Ref) ' G,C f ref. e: . ref (.),Alloc(C ,.) ' G,C f e : Q ref (.),C (Deref) \n' G,C f !e: C ' (.),C '' '' G,C f e1 : Q ref (.),C G,C f e2 : t,C (Assign) '' G,C f e1 := e2 : t,Assign(C \n,.: t) t = sp(t) e,e ' ,. fresh ' '' G[x. t],ef e: t ' ,C C = e (Lam) G,C f .Lx:t.e: .(e,t) -. L (e ' \n,t ' ),C ''' '' G,C f e1 : Q(e,t) -. L (e ,t ' ),C G,C f e2 : t2,C '' t2 = t Filter(C ,L) = e (App) \nG,C f e1 e2 : t ' ,Merge(e ' ,C '' ,L) '' ' G,C f e : Q s,C Q = Q (Assert) ' G,C f assert(e,Q): Qs,C \n'' ' G,C f e: Q s,C Q = Q (Check) '' G,C f check(e,Q): Q s,C Figure 5: Constraint generation rules (App) \nconstrains t2 = t to ensure that e2 s type is compatible with e1 s argument type. The constraint Filter(C \n'' ,L) = e ensures that the current state of the locations that e1 uses, which are captured by its e.ect \nset L, is compatible with the state function e1 expects. ' '' '' The .nal store Merge(e,C ,L) joins the \nstore C be\u00adfore the function call with the result store e ' of the function. Intuitively, this rule gives \nus some low-cost polymorphism, in which functions do not act as join points for locations they do not \nuse. (Assert) adds a quali.er annotation to the program, and (Check) checks that the inferred top-level \nquali.er Q ' of e is compatible with the expected quali.er Q. Figure 6 shows the stores and store constraints \ngenerated for our example program. We have slightly simpli.ed the graph for clarity. Here e is f s initial \nstore and e ' is f s .nal store. We use undirected edges for store constructors and a directed edge from \nC1 to C2 for the constraint C1 = C2. We step through constraint generation. We model the al\u00adlocation \nof .x with the store Alloc(e,.x). Location .x is ini\u00adtialized to 0, which is given the type .0 int for \nfresh quali.er variable .0. (Ref) generates the constraint .0 int = e(.x) to require that the type of \n0 be compatible with e(.x). We model the allocation and initialization of .y and .z sim\u00adilarly. Then \nwe construct three Assign stores to represent the assignment statements. We give 3 and 4 the types .3 \nint and .4 int, respectively, where .3 and .4 are fresh quali.er variables. For the recursive call to \nf, we construct a Filter and add a constraint on e. The Merge store represents the state when the recursive \ncall to f returns. We join the two branches of  MergeL = {.z}   e ' L  e.x .0 int = e(.x) qa int \n= Alloc(e, .x)(.y ) qb int = Alloc(Alloc(e, .x),.y)(.z ) e ' (.y) = qc int Figure 6: Store constraints \nfor example the conditional by making edges to e ' . Notice the cycle, due to recursion, in which state \nfrom e ' can .ow to the Merge, which in turn can .ow to e ' . Finally, the quali.er check requires that \ne ' (.y) has quali.er qc.  3.4 Flow-Sensitive Constraint Resolution The rules of Figure 5 generate three \nkinds of constraints: quali.er constraints Q = Q ' , subtyping constraints t = t ' , and store constraints \nC = e (the right-hand side of a store constraint is always a store variable). A set of m type and quali.er \nconstraints can be solved in O(m) time using well\u00adknown techniques [16, 23], so in this section we focus \non computing a solution S to a set of store constraints. Our analysis is most precise if as few locations \nas pos\u00adsible are non-linear. Recall that linearities naturally form a partial order 0 < 1 <.. Thus, given \na set of con\u00adstructed stores and store constraints, we perform a least .xpoint computation to determine \nS(C)lin(.). We initially assume that in every store, location . has linearity 0. Then we exhaustively \napply the rules in Figure 4(b) and the rule S(e)(.) = (max{C|C=e} S(C)(.)) until we reach a .x\u00ad linlin \npoint. This last rule is derived from Figure 3. In our implementation, we compute S(C)lin(.) in a sin\u00adgle \npass over the store constraints using Tarjan s strongly\u00adconnected components algorithm to .nd cycles \nin the store constraint graph. For each such cycle containing more than one allocation of the same location \n. we set the linearity of . to . in all stores on the cycle. Given this algorithm to compute S(C)lin(.), \nin principle we can then solve the implied typing constraints using the following simple procedure. For \neach store variable e, ini\u00adtialize S(e) to a map {.1 :sp(CI (.1)),...,.n :sp(CI (.n))} and for each store \nAssign(C, . : t) initialize S(Assign(C, . : t))(.)to sp(CI (.)), thereby assigning fresh quali.ers to \nthe type of every location at every program point. Replace uses of C(.) in Figure 5 with S(C)(.), using \nthe logic in Fig\u00adure 4(a). Apply the following two closure rules until no more con\u00adstraints are generated: \nC = e =. S(C)(.) = S(e)(.) for all . S(C)lin(.)= . =. S(C)(.) = S(Assign(C, . : t))(.) for all stores \nAssign(C, . : t) Given a program of size n, in the worst case this naive al\u00adgorithm requires at least \nn 2 space and time to build S(\u00b7) and generate the necessary type constraints. This cost is too high for \nall but small examples. We reduce this cost in practice by taking advantage of several observations. \nMany locations are .ow-insensitive. If a location . never appears on the left-hand side of an assignment, \nthen . s type cannot change. Thus we can give . one global type instead of one type per program point. \nIn imperative languages such as C, C++, and Java, function parameters are a major source of .ow-insensitive \nlocations. In these languages, because parameters are l-values, they have an associated memory location \nthat is initialized but then often never subsequently changed. Adding extra store variables trades space \nfor time. To compute S(C)(.) for a constructed store C, we must decon\u00adstruct C recursively until we reach \na variable store or an assignment to . (see Figure 4(a)). Because we represent the e.ect constraints \ncompactly (in linear space), deconstruct\u00ading Filter(\u00b7,L)or Merge(\u00b7, \u00b7,L) may require a potentially lin\u00adear \ntime computation to check whether . . L. We recover e.cient lookups by replacing C with a fresh store \nvariable e and adding the constraint C = e. Then rather than com\u00adputing S(C)(.) we compute S(e)(.), which \nrequires only a map lookup. Of course, we must use space to store . in S(e). However, as shown below, \nwe often can avoid this cost completely. We apply this transformation to each store Merge(C, C ' ,L) \nconstructed during constraint inference. Not every store needs every location. Rather than as\u00adsuming \nS(e) contains all locations, we add needed locations lazily. We add a location . to S(e) the .rst time \nthe analysis requests e(.) and whenever there is a constraint C = e or e = C such that . . S(C). Stores \nconstructed with Filter and Merge will tend to stop propagation of locations, saving space (e.g., if \nFilter(C, L) = e, . . S(e), but . . L, then we do not propagate . to C). We can extend this idea further. \nFor each quali.er vari\u00adable ., inference maintains a set of possible quali.er con\u00adstants that are valid \nsolutions for .. If that set contains every constant quali.er, then . is uninteresting (i.e., . is constrained \nonly by other quali.er variables), otherwise . is interesting.A type t is interesting if any quali.er \nin t is interesting, otherwise t is uninteresting. We then modify the closure rules as follows: C = e \n=. S(C)(.) = S(e)(.) for all . . S(C)or S(e) s.t. S(C)(.)or S(e)(.) interesting S(C)lin(.)= . =. S(C)(.) \n= S(Assign(C, . : t))(.) for all Assign(C, . : t) s.t. S(C)(.)or S(Assign(C, . : t))(.) interesting In \nthis way, if a location . is bound to an uninteresting type, then we need not propagate . through the \nconstraint graph. Figure 7 gives an algorithm for lazy location propagation. We associate a mark with \neach . in each S(e) and with . in Assign(C, . : t). Initially this mark is not set, indicating that location \n. is bound to an uninteresting type. If a quali.er variable . appears in S(e)(.), we associate the pair \n(., e) with ., and similarly for Assign stores. If during constraint resolution the set of possible solutions \nof . changes, we call Propagate(., C) to propagate ., and in turn ., through the store constraint graph. \n If Propagate(., C) is called and . is already marked in C, we do nothing. Otherwise, Back-prop() and \nForward-prop() make appropriate constraints between S(C)(.) and S(C ' )(.) for every store C ' reachable \nfrom C. This step may add . to C ' if C ' is a store variable, and the type constraints that Back-prop() \nand Forward-prop() generate may trigger subsequent calls to Propagate(). Consider again our running example. \nFigure 8 shows how locations and quali.ers propagate through the store con\u00adstraint graph. Dotted edges \nin this graph indicate inferred constraints (discussed below). For clarity we have omitted the Alloc \nedges (summarized with a dashed line) and the base types. The four type constraints in Figure 6 are shown \nas directed edges in Figure 8. For example, the constraint .0 int = e(.x) reduces to the constraint .0 \n= .x, which is a directed edge .0 . .x. Adding this constraint does not cause any propagation; this constraint \nis among variables. Notice that the assignment of type .3 int to .x also does not cause any propagation. \nThe constraint qa int = Alloc(e, .x)(.y) reduces to qa int = e(.y), which reduces to qa = .y. This constraint \ndoes trigger propagation. Propagate(.y,e) .rst pushes .y backward to the Filter store. But since .y . \nL, propagation stops. Next we push .y forward through the graph and stop when we reach the store Assign(\u00b7,.y \n: qc int); forward propagation assumes that this is a strong update. Since Assign(\u00b7,.y : qc int) contains \nan interesting type, .y is propagated from this store forward through the graph. On one path, propagation \nstops at the Filter. The other paths yield a constraint qc = . ' y. Notice that the constraint . ' y \n= qc remains satis.able. The constraint qb = .z triggers a propagation step as before. However, this \ntime .z . L, and during backward propagation when we reach Filter we must continue. Even\u00adtually we reach \nAssign(\u00b7,.z : .4 int) and add the con\u00adstraint .4 = .z. This in turn triggers propagation from Assign(\u00b7,.z \n: .4 int). This propagation step reaches e ' , adds .z to S(e ' ), and generates the constraint .4 = \n. ' z. Finally, we determine that in the Assign stores .x and .y are linear and .z is non-linear. (The \nlinearity computation uses the Alloc(\u00b7, \u00b7) stores, which are not shown.) Thus the update to .z is a weak \nupdate, which yields a constraint .z = .4. This example illustrates three kinds of propagation. The location \n.x is never interesting, so it is not propagated through the graph. The location .y is propagated, but \npropagation stops at the strong update to .y and also at the Filter,be\u00adcause the (Down) rule in Figure \n1 was able to prove that .y is purely local to f. The location .z, on the other hand, is not purely local \nto f, and thus all instances of .z are con.ated, and .z admits only weak updates. Propagate(., e)= case \nC of e: add .: sp(CI (.)) to S(e) if not already in S(e) if . is not marked in e mark . in S(e) Forward-prop(C, \n., S(e)(.)) '' for each C such that C = e ' Back-prop(C , ., S(e)(.)) ' Assign(C ,. : t): if . is not \nmarked in Assign(C ' ,.: t) ' mark . in Assign(C ,. : t) Forward-prop(C, ., t) Back-prop(C, ., t)= \ncase C of e: add .: sp(CI (.)) to S(e) if not already in S(e) S(e)(.) = t '' Alloc(C ,. ): ' Back-prop(C \n, ., t) ' '' Merge(C ,C ,L): if . . L ' then Back-prop(C , ., t) '' else Back-prop(C , ., t) ' Filter(C \n,L): if . . L ' then Back-prop(C , ., t) '' Assign(C ,. : t ' ): ' if . = . then t ' = t ' else Back-prop(C \n, ., t) Forward-prop(C, ., t)= for each e such that C = e add .: sp(CI (.)) to S(e) if not already in \nS(e) t = S(e)(.) '' for each C such that C is constructed from C ' case C of ' Alloc(C,. ): ' Forward-prop(C \n, ., t) Merge(C1,C2,L): if . . L and C = C1 ' then Forward-prop(C , ., t) if . . L and C = C2 ' then \nForward-prop(C , ., t) Filter(C,L): if . . L ' then Forward-prop(C , ., t) ' Assign(C,. : t ' ): ' if \n. = . ' then Forward-prop(C , ., t) Figure 7: Lazy location constraint propagation  4. RESTRICT As \nmentioned in the introduction, type inference may fail because a location on which a strong update is \nneeded may be non-linear. In practice a major source of non-linear lo\u00adcations is data structures. For \nexample, given a linked list l, our alias analysis often cannot distinguish l->lock from l->next->lock, \nhence both will likely be non-linear. Our solution to this problem is to add a new form restrict x =e1 \nin e2 to the language. Intuitively, this declares that of all aliases of e1, only x and copies derived \nfrom x will be used within {.y :. ' .z :. ' } y,z      L      e {.x :.x,.y :.y,.z :.z}  \n.0qaqb Figure 8: Constraint propagation e2. For example, consider restrict x= yin { x := ...; /* valid \n*/ y := ...; /* invalid */ } The .rst assignment through x is valid, but the assignment through y is \nforbidden by restrict. We check restrict using the following type rule, which is integrated into the \n.rst inference pass of Figure 1: '' G fe1 .e1 : t1; L1 t1 = ref (.) .,. fresh ' '' CI (. )= CI (.) G[x.ref \n(. )] fe2 .e2 : t2; L2 ' ..L2 . .locs(G) .locs(CI (.)) .locs(t2) (Restrict) G frestrict x=e1 in e2 . \n'' restrict.. x=e in e : t2; L1 .L2 .{.} 12 Here we bind x to a type with a fresh abstract location . \n' to distinguish dereferences of x from dereferences of other aliases of e1. The constraint . . L2 forbids \nlocation . from being dereferenced in e2; notice dereferences of . ' within e2 are allowed. We require \nthat . ' not escape the scope of e2 with . ' . locs(G) . locs(CI (.)) . locs(t2), and we also add . to \nthe e.ect set. We translate restrict into the target language by annotating it with the location . ' \nthat x is bound to. A full discussion of restrict, including a soundness proof, can be found in a technical \nreport [15]. We use restrict to locally recover strong updates. The key observation is that the location \n. of e1 and the location . ' of x can be di.erent. Thus even if the linearity of . is ., the linearity \nof . ' can be 1. Therefore within the body of e2 we may be able to perform strong updates of . ' . When \nthe scope of restrict ends, we may need to do a weak update from . ' to .. For example, suppose that \nwe wish to type check a state change of some lock deep within a data structure, and the lo\u00adcation of \nthe lock is non-linear. The following is not atypical of Linux kernel code: spin_lock(&#38;a->b[c].d->lock); \n/* invalid; */ ... /* non-linear loc */ spin_unlock(&#38;a->b[c].d->lock); Assuming the type system determines \nthat the ... above contains no accesses to aliases of the lock and does not alias the lock to a non-linear \nlocation, we can modify the code to type check as follows: restrict lock = &#38;a->b[c].d->lock in { \nspin_lock(lock); /* valid */ ... spin_unlock(lock); } In our .ow-sensitive step, we use the following \ninference rule for restrict: ' G,C fe1 : Q ref (.),C '' ' ) ' (.) =C '' ' C = Alloc(C ' ,. C (. ) ' \n'' ''' G[x.ref (. )],C fe2 : t2,C (Restrict) G,C frestrict.. x=e1 in e2 : t2, ''' ''' (. ' Assign(C ,. \n: C )) In this rule, we infer a type for e1, which is a pointer to some location .. Then we create a \nnew store C '' in which the location . ' of x is both allocated and initialized to C ' (.). In C '' , \nand with x added to the type environment, we evaluate e2. Finally, the result store is the store C ''' \nwith a potentially weak update assigning the contents of . ' to .. 5. EXPERIMENTS To test our ideas \nin practice we have built a tool Cqual that implements our inference algorithm. To use Cqual, programmers \nannotate their C programs with type quali\u00ad.ers, which are added to the C syntax in the same way as const \n[16]. The tool Cqual can analyze a single .le or a whole program. As is standard in type-based analysis, \nwhen analyzing a single .le, the programmer supplies type signa\u00adtures for any external functions or variables. \nWe have used Cqual to check two program properties: locking in the 2.4.9 Linux kernel device drivers \nand uses of the C stream library. Our implementation is sound up to the unsafe features of C: type casts, \nvariable-argument functions, and ill-de.ned pointer arithmetic. We currently make no attempt to track \nthe e.ect of any of these features on aliasing, except for the special case of type casting the result \nof malloc-like functions. In combination with a sys\u00adtem for enforcing memory safety, such as CCured [21], \nour implementation would be sound. In our implementation, we do not allow strong updates on locations \ncontaining functions. This improves e.ciency because we never need to recompute S(C)lin(.) weak up\u00addates \nwill not add constraints between stores. Additionally, observe that allocations a.ect linearities but \nnot types, and reads and writes a.ect types but not linearities. Thus in our implementation we also improve \nthe precision of the analy\u00adsis by distinguishing read, write, and allocation e.ects. We omit details \ndue to space constraints. The analysis results are presented to the user with an emacs-based user interface. \nThe source code is colored ac\u00adcording to the inferred quali.ers. Type errors are hyper\u00adlinked to the \nsource line at which the error .rst occurred, and the user can click on quali.ers to view a path through \nthe constraint graph that shows why a type error was de\u00adtected. We have found the ability to visualize \nconstraint solutions in terms of the original source syntax not just use\u00adful, but essential, to understanding \nthe results of inference. More detail on the ideas in the user interface can be found in [24]. 5.1 Linux \nKernel Locking The Linux kernel includes two primitive locking functions, which are used extensively \nby device drivers: void spin_lock(spinlock_t *lock); void spin_unlock(spinlock_t *lock); We use three \nquali.ers locked, unlocked, and T (unknown) to check locking behavior. The subtyping relation is locked \n< T and unlocked < T . We assign spin lock the type (C, ref (.)) -. {.} (Assign(C, . : locked spinlock \n t), void) where C(.) = unlocked spinlock t We omit the function quali.er since it is irrelevant. The \ntype of spin lock requires that the lock passed as the argument be unlocked (see the where clause) and \nchanges it to locked upon returning. The signature for spin unlock is the same with locked and unlocked \nexchanged. In practice we give spin lock this type signature by sup\u00adplying Cqual with the following de.nition: \nvoid spin_lock($unlocked spinlock_t *lock) { change_type(*lock, $locked spinlock_t); } Here change type(x, \nt) is just like the assignment x= ( something of type t) ; except that rather than give an explicit right-hand \nside we just give the type of the right-hand side. In this case the programmer needs to supply the body \nof spin lock because it is inline assembly code. Since our implementation currently lacks parametric \npoly\u00admorphism, we inline calls to spin lock and spin unlock. Using these type signatures we can check \nfor three kinds of errors: deadlocks from acquiring a lock already held by the same thread, attempts \nto release a lock already released by the same thread, and attempting to acquire or release a lock in \nan unknown (T ) state. We analyzed 513 whole device driver modules (a whole module includes all the .les \nthat make up a single driver). A module must meet a well-speci.ed kernel interface, which we model with \na main function that non-deterministically calls all possible driver functions registered with the kernel. \nWe also separately analyzed each of the 892 driver .les making up the whole modules. In these experiments \nwe removed the T quali.er so that locked and unlocked are incomparable, and we made optimistic assumptions \nabout the environment in which each .le is invoked. We examined the results for 64 of the 513 whole device \ndriver modules and for all of the 892 separately analyzed driver .les. We found 14 apparently new locking \nbugs, in\u00adcluding one which spans multiple .les. In .ve of the appar\u00adent bugs a function tries to acquire \na lock already held by a function above it in the call chain, leading to a deadlock. For example, the \nemu10k1 module contains a deadlock (we omit the void return types): emu10k1_mute_irqhandler(struct emu10k1_card \n*card) { struct patch_manager *mgr = &#38;card->mgr; ... spin_lock_irqsave(&#38;mgr->lock, flags); emu10k1_set_oss_vol(card, \n...); ... } emu10k1_set_oss_vol(struct emu10k1_card *card, ...) { ... emu10k1_set_volume_gpr(card, ...); \n... } emu10k1_set_volume_gpr(struct emu10k1_card *card, ...) { struct patch_manager *mgr = &#38;card->mgr; \n... spin_lock_irqsave(&#38;mgr->lock, flags); ... } Note that detecting this error requires interprocedural \nanal\u00adysis. One of our goals is to understand how often, and why, our system fails to type check real \nprograms. We have cat\u00adegorized every type error in the separate .le analysis of the 892 driver .les. \nIn this experiment, of the 52 .les that fail to type check, 11 .les have locking bugs (sometimes more \nthan one) and the remaining 41 .les have type errors. Half of these type errors are due to incorrect \nassumptions about the interface for functions; these type errors are eliminated by moving to whole module \nanalysis. The remaining type errors fall into two main categories. In many cases the problem is that \nour alias analysis is not strong enough to type check the program. Another com\u00admon class of type errors \narises when locks are conditionally acquired and released. In this case, a lock is acquired if a predicate \nP is true. Before the lock is released, P is tested again to check whether the lock is held. Our system \nis not path sensitive, and our tool signals a type error at the point where the path on which the lock \nis acquired joins with the path on which the lock is not acquired (since we did not use T in these single \n.le experiments in the whole module analysis, this error is detected later on, when there is an at\u00adtempt \nto acquire or release the lock in the T state). Most of these examples could be rewritten with little \ne.ort to pass our type system. In our opinion, this would usually make the code clearer and safer the \nduplication of the test on P invites new bugs when the program is modi.ed. Even after further improvements, \nwe expect some dynam\u00adically correct programs will not type check. As future work, we propose the following \nsolution. The quali.er T repre\u00adsents an unknown state. We can use the information in the constraints \nto automatically insert coercions to and from T where needed. During execution these coercions perform \nruntime tests to verify locks are in the correct state. Thus, our approach can introduce dynamic type \nchecking in situ\u00adations where we cannot prove safety statically. Of the 513 whole modules, 196 contain \ntype errors, many of which are duplicates from shared code. We examined 64 of the type error-containing \nmodules and discovered that a major source of type errors is when there are multiple aliases of a location, \nbut only one alias is actually used in the code of interest. Not surprisingly, larger programs, such \nas whole modules, have more problems with spurious aliasing than the optimistic single-.le analysis. \nWe added restrict an\u00adnotations by hand to the 64 modules we looked at, including the emu10k1 module, \nwhich yielded the largest number of such false positives. Using restrict, we eliminated all of the false \npositives in these modules that occurred because non-linear locations could not be strongly updated. \nThis supports our belief that restrict is the right tool for deal\u00ading with (necessarily) conservative \nalias analysis. Currently adding restrict by hand is burdensome, requiring a rela\u00adtively large number \nof annotations. We leave the problem of automatically inferring restrict annotations as future work. \n 5.2 C Stream Library As mentioned in the introduction, the C stream library Space (Mbytes) Time (sec) \nFlow sensitive Flow insensitive Parsing 140 120 100 80 60 40 20 0 0k 100k 200k 300k 400k 500k 600k 700k \n800k Size (preprocessed lines of code) 1000 900 800 700 600 500 400 300 200 100 0 0k 100k 200k 300k 400k \n500k 600k 700k 800k Size (preprocessed lines of code) Figure 9: Resource usage for whole module analysis \ninterface contains certain sequencing constraints. For ex\u00adample, a .le must be opened for reading before \nbeing read. A special property of the C stream library is that the result of fopen must be tested against \nNULL before being used, be\u00adcause fopen may or may not succeed. The class of C stream library usage errors \nour tool can detect includes .les used without having been opened and checked against NULL, .les opened \nand then accessed in an incompatible mode, and .les accessed after being closed. We omit the details \ndue to space constraints. We tried our tool on two application programs, man-1.5h1 and sendmail-8.11.6. \nWe were primarily interested in the performance of our tool on a more complex application (see below), \nas we did not expect to .nd any latent stream library usage bugs in such mature programs. However, we \ndid .nd one minor bug in sendmail, in which an opened log .le is never closed in some circumstances. \n 5.3 Precision and Ef.ciency The algorithm described in Section 3.4 is carefully de\u00adsigned to limit resource \nusage. Figure 9 shows time and space usage of whole module analysis versus preprocessed lines of code \nfor 513 Linux kernel modules. All experiments were done on a dual processor 550 MHz Pentium III with \n2GB of memory running RedHat 6.2. We divide the resource usage into C parsing and type checking, .ow-insensitive \nanalysis, and .ow-sensitive analy\u00adsis. Flow-insensitive analysis consists of the alias and e.ect inference \nof Figure 1 together with .ow-insensitive quali.er inference [16]. Flow-sensitive analysis consists of \nthe con\u00adstraint generation and resolution described in Sections 3.3\u00ad3.4, including the linearity computation. \nIn the graphs, the reported time and space for each phase includes the time and space for the previous \nphases. The graphs show that the space overhead of .ow-sensitive analysis is relatively small and appears \nto scale well to large modules. For all modules the space usage for the .ow\u00adsensitive analysis is within \n31% of the space usage for the .ow-insensitive analysis. The running time of the analysis is more variable, \nbut the absolute running times are within a factor of 1.3 of the .ow-insensitive running times. The analysis \nof sendmail-8.11.6, with 175,193 prepro\u00adcessed source lines, took 28.8 seconds and 264MB; man-1.5h1, \nwith 16,411 preprocessed source lines, took 1.85 seconds and 32MB. These results suggest that our algorithm \nalso behaves e.ciently when checking C stream library usage.  6. CONCLUSION We have presented a system \nfor extending standard type systems with .ow-sensitive type quali.ers. We have given a lazy constraint \nresolution algorithm to infer type quali.er annotations and have shown that our analysis is e.ective \nin practice by .nding a number of new locking bugs in the Linux kernel. 7. REFERENCES [1] A. V. Aho, \nR. Sethi, and J. D. Ullman. Compilers: Principles, Techniques, and Tools. Addison Wesley, 1988. [2] \nA. Aiken, M. F\u00a8ahndrich, and R. Levien. Better Static Memory Management: Improving Region-Based Analysis \nof Higher-Order Languages. In Proceedings of the 1995 ACM SIGPLAN Conference on Programming Language \nDesign and Implementation, pages 174 185, La Jolla, California, June 1995. [3] R. Altucher and W. Landi. \nAn Extended Form of Must Alias Analysis for Dynamic Allocation. In Proceedings of the 22nd Annual ACM \nSIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 74 84, San Francisco, California, \nJan. 1995. [4] D. R. Chase, M. Wegman, and F. K. Zadeck. Analysis of Pointers and Structures. In Proceedings \nof the 1990 ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 296 310, \nWhite Plains, New York, June 1990. [5] K. Crary, D. Walker, and G. Morrisett. Typed Memory Management \nin a Calculus of Capabilities. In Proceedings of the 26th Annual ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages, pages 262 275, San Antonio, Texas, Jan. 1999. [6] M. Das, S. Lerner, and M. \nSeigle. ESP: Path-Sensitive Program Veri.cation in Polynomial Time. In Proceedings of the 2002 ACM SIGPLAN \nConference on Programming Language Design and Implementation, Berlin, Germany, June 2002. To appear. \n[7] R. DeLine and M. F\u00a8ahndrich. Enforcing High-Level Protocols in Low-Level Software. In Proceedings \nof the 2001 ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 59 69, Snowbird, \nUtah, June 2001. [8] M. Emami, R. Ghiya, and L. J. Hendren. Context-Sensitive Interprocedural Points-to \nAnalysis in the Presence of Function Pointers. In Proceedings of the 1994 ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 242 256, Orlando, Florida, June 1994. [9] D. Engler, B. Chelf, \nA. Chou, and S. Hallem. Checking System Rules Using System-Speci.c, Programmer-Written Compiler Extensions. \nIn Fourth symposium on Operating System Design and Implementation, San Diego, California, Oct. 2000. \n[10] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf. Bugs as Deviant Behavior: A General Approach \nto Inferring Errors in Systems Code. In Proceedings of the 18th ACM Symposium on Operating Systems Principles, \nBan., Canada, Oct. 2001. [11] D. Evans. Static Detection of Dynamic Memory Errors. In Proceedings of \nthe 1996 ACM SIGPLAN Conference on Programming Language Design and Implementation, pages 44 53, Philadelphia, \nPennsylvania, May 1996. [12] M. F\u00a8ahndrich and R. DeLine. Adoption and Focus: Practical Linear Types \nfor Imperative Programming. In Proceedings of the 2002 ACM SIGPLAN Conference on Programming Language \nDesign and Implementation, Berlin, Germany, June 2002. To appear. [13] C. Flanagan and S. N. Freund. \nType-Based Race Detection for Java. In Proceedings of the 2000 ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation, pages 219 232, Vancouver B.C., Canada, June 2000. [14] C. Flanagan, \nK. R. M. Leino, M. Lillibridge, G. Nelson, J. B. Saxe, and R. Stata. Extended Static Checking for Java. \nIn Proceedings of the 2002 ACM SIGPLAN Conference on Programming Language Design and Implementation, \nBerlin, Germany, June 2002. To appear. [15] J. S. Foster and A. Aiken. Checking Programmer-Speci.ed Non-Aliasing. \nTechnical Report UCB//CSD-01-1160, University of California, Berkeley, Oct. 2001. [16] J. S. Foster, \nM. F\u00a8ahndrich, and A. Aiken. A Theory of Type Quali.ers. In Proceedings of the 1999 ACM SIGPLAN Conference \non Programming Language Design and Implementation, pages 192 203, Atlanta, Georgia, May 1999. [17] D. \nGrossman, G. Morrisett, Y. Wang, T. Jim, M. Hicks, and J. Cheney. Cyclone user s manual. Technical Report \n2001-1855, Department of Computer Science, Cornell University, Nov. 2001. Current version at http://www.cs.cornell.edu/projects/cyclone. \n[18] A. Igarashi and N. Kobayashi. Resource Usage Analysis. In Proceedings of the 29th Annual ACM SIGPLAN-SIGACT \nSymposium on Principles of Programming Languages, pages 331 342, Portland, Oregon, Jan. 2002. [19] S. \nJagannathan, P. Thiemann, S. Weeks, and A. Wright. Single and loving it: Must-alias analysis for higher-order \nlanguages. In Proceedings of the 25th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, pages 329 341, San Diego, California, Jan. 1998. [20] J. M. Lucassen and D. K. Gi.ord. Polymorphic \nE.ect Systems. In Proceedings of the 15th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming \nLanguages, pages 47 57, San Diego, California, Jan. 1988. [21] G. Necula, S. McPeak, and W. Weimer. CCured: \nType-Safe Retro.tting of Legacy Code. In Proceedings of the 29th Annual ACM SIGPLAN-SIGACT Symposium \non Principles of Programming Languages, pages 128 139, Portland, Oregon, Jan. 2002. [22] R. O Callahan. \nA Simple, Comprehensive Type System for Java Bytecode Subroutines. In Proceedings of the 26th Annual \nACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 70 78, San Antonio, Texas, \nJan. 1999. [23] J. Rehof and T. \u00c6. Mogensen. Tractable Constraints in Finite Semilattices. In R. Cousot \nand D. A. Schmidt, editors, Static Analysis, Third International Symposium, volume 1145 of Lecture Notes \nin Computer Science, pages 285 300, Aachen, Germany, Sept. 1996. Springer-Verlag. [24] U. Shankar, K. \nTalwar, J. S. Foster, and D. Wagner. Detecting Format String Vulnerabilities with Type Quali.ers. In \nProceedings of the 10th Usenix Security Symposium, Washington, D.C., Aug. 2001. [25] F. Smith, D. Walker, \nand G. Morrisett. Alias Types. In G. Smolka, editor, 9th European Symposium on Programming, volume 1782 \nof Lecture Notes in Computer Science, pages 366 381, Berlin, Germany, 2000. Springer-Verlag. [26] R. \nStata and M. Abadi. A Type System for Java Bytecode Subroutines. In Proceedings of the 25th Annual ACM \nSIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 149 160, San Diego, California, \nJan. 1998. [27] R. E. Strom and S. Yemini. Typestate: A Programming Language Concept for Enhancing Software \nReliability. IEEE Transactions on Software Engineering, 12(1):157 171, Jan. 1986. [28] M. Tofte and J.-P. \nTalpin. Implementation of the Typed Call-by-Value .-Calculus using a Stack of Regions. In Proceedings \nof the 21st Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages 188 201, \nPortland, Oregon, Jan. 1994. [29] D. Walker and G. Morrisett. Alias Types for Recursive Data Structures. \nIn International Workshop on Types in Compilation, Montreal, Canada, Sept. 2000. [30] D. Weise, 2001. \nPersonal communication. [31] R. P. Wilson and M. S. Lam. E.cient Context-Sensitive Pointer Analysis for \nC Programs. In Proceedings of the 1995 ACM SIGPLAN Conference on Programming Language Design and Implementation, \npages 1 12, La Jolla, California, June 1995. [32] A. K. Wright. Typing References by E.ect Inference. \nIn B. Krieg-Br\u00a8ucker, editor, 4th European Symposium on Programming, volume 582 of Lecture Notes in Computer \nScience, pages 473 491, Rennes, France, Feb. 1992. Springer-Verlag. [33] Z. Xu, T. Reps, and B. P. Miller. \nTypestate Checking of Machine Code. In D. Sands, editor, 10th European Symposium on Programming, volume \n2028 of Lecture Notes in Computer Science, pages 335 351, Genova, Italy, 2001. Springer-Verlag.  \n\t\t\t", "proc_id": "512529", "abstract": "We present a system for extending standard type systems with flow-sensitive type qualifiers. Users annotate their programs with type qualifiers, and inference checks that the annotations are correct. In our system only the type qualifiers are modeled flow-sensitively---the underlying standard types are unchanged, which allows us to obtain an efficient constraint-based inference algorithm that integrates flow-insensitive alias analysis, effect inference, and ideas from linear type systems to support strong updates. We demonstrate the usefulness of flow-sensitive type qualifiers by finding a number of new locking bugs in the Linux kernel.", "authors": [{"name": "Jeffrey S. Foster", "author_profile_id": "81338488852", "affiliation": "University of California, Berkeley, CA", "person_id": "PP42049823", "email_address": "", "orcid_id": ""}, {"name": "Tachio Terauchi", "author_profile_id": "81100563652", "affiliation": "University of California, Berkeley, CA", "person_id": "P348279", "email_address": "", "orcid_id": ""}, {"name": "Alex Aiken", "author_profile_id": "81100399954", "affiliation": "University of California, Berkeley, CA", "person_id": "PP39041079", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512529.512531", "year": "2002", "article_id": "512531", "conference": "PLDI", "title": "Flow-sensitive type qualifiers", "url": "http://dl.acm.org/citation.cfm?id=512531"}