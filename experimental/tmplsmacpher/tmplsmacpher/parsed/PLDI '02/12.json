{"article_publication_date": "05-17-2002", "fulltext": "\n Combining Region Inference and Garbage Collection Niels Hallenberg Martin Elsman* Mads Tofte nh@itu.dk \nmael@dina.kvl.dk tofte@itu.dk IT University of Copenhagen Glentevej 67, DK-2400 Copenhagen NV, Denmark \nABSTRACT This paper describes a memory discipline that combines region-based memory management and copying \ngarbage col\u00adlection by extending Cheney s copying garbage collection algorithm to work with regions. \nThe paper presents empiri\u00adcal evidence that region inference very signi.cantly reduces the number of \ngarbage collections; and evidence that the fastest execution is obtained by using regions alone, with\u00adout \ngarbage collection. The memory discipline is implemented for Standard ML in the ML Kit compiler and measurements \nshow that for a variety of benchmark programs, code generated by the compiler is as e.cient, both with \nrespect to execution time and memory usage, as programs compiled with Standard ML of New Jersey, another \nstate-of-the-art Standard ML compiler. Categories and Subject Descriptors D.1 [Programming Techniques]: \nApplicative (Functional) Programming; D.3 [Programming Languages]: Language Constructs and Features Dynamic \nstorage management; F.3 [Logics and Meanings of Programs]: Semantics of Programming Languages Program \nanalysis General Terms Algorithms, Languages  Keywords Garbage collection, region inference, Standard \nML 1. INTRODUCTION This paper presents a memory discipline that integrates region-based memory management \nand automatic heap man\u00adagement ( garbage collection ). * Part time at Royal Veterinary and Agricultural \nUniversity of Denmark. Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c In the \nrest of this section we describe the two strategies and summarise the di.erences between the two. The \nmain contributions are summarised in Section 1.2. 1.1 Background A popular memory management discipline \nfor block struc\u00adtured languages is stack allocation. Every allocation point is matched by a deallocation \npoint and these points are eas\u00adily identi.ed in the program. Allocation and deallocation take place at \nprocedure entry and exit, respectively. This strategy often leads to fast and compact use of memory. \nThe main limitation of the stack discipline is that for some algorithms, lifetimes of data simply are \nnot nested. Some other form of recycling is needed in such cases. In heap allocation, values that do \nnot .t in the stack discipline are allocted in the heap, which is a part of the store separate from the \nstack. The most basic form of heap allocation is manual heap allocation, in which the programmer is in \ncharge of allocat\u00ading and deallocating values. The technique is notoriously di.cult to use in practice: \nit is easy to allocate memory, but hard to know when to free it. Freeing memory too soon may lead the \nprogram to crash ( dangling pointers ) while freeing memory too late may lead to wasteful use of memory \n( memory leaks ). Automatic heap management addresses these problems by leaving deallocation of memory \nto a part of the runtime sys\u00adtem, the garbage collector. From time to time, the garbage collector interrupts \nthe user s program and recycles the parts of memory that are not needed for the remainder of the computation \n(i.e., the garbage ). Most implementations of functional languages and some implementations of object\u00adoriented \nlanguages use automatic heap management. Some even use automatic heap management and no stack at all \n[2]. However, automatic heap management is not perfect ei\u00adther. The separation of allocation and deallocation \nmakes it hard for the programmer to know how long values will live and therefore how much memory the \nprogram will use. Garbage collection can account for a high percentage of the running time, whereas deallocation \nin the stack discipline is very inexpensive. There is a large body of work concerning garbage collec\u00adtion \ntechniques, see for example [23, 14]. These techniques share the following features: Automation. Garbage \nis reclaimed automatically at runtime, by the garbage collector. permission and/or a fee. Lifetimes are \ndetermined at runtime. The garbage col- PLDI 02, June 17-19, 2002, Berlin, Germany. Copyright 2002 ACM \n1-58113-463-0/02/0006 ...$5.00. lector traverses values in order to locate garbage. . r1 r2 r3 r4 . Figure \n1: A stack of regions. A region is a rectangle in the picture. The stack grows to the right, i.e., r4 \nis the topmost region and is the .rst region to be deallocated. Each region may grow upwards. Uniformity. \nThe garbage collector uses a .xed strategy for all user programs, although some garbage collection algorithms \nrely on heuristics about common memory behaviour of programs (e.g., [15]). Region-based memory management \n[20, 3, 21, 17] attempts to achieve both the predictability and e.ciency of the stack discipline and \nthe .exibility and safety of automatic heap management. Conceptually, the store is organised as a stack \nof regions, see Figure 1. Allocation and deallocation direc\u00adtives of regions are inserted into the program \nat compile time, based on a program analysis called region inference [20, 3]. Value-creating expressions \nare annotated with in\u00adformation that directs in what region values go at runtime. Moreover, if e is some \nregion-annotated expression, then so is letregion r in e end Expressions of this form are evaluated as \nfollows. First a region is allocated on top of the stack and bound to the region variable r. Then e is \nevaluated, possibly using the region bound to r for holding values. Finally, upon reaching end, the region \nis reclaimed. A particularly important as\u00adpect of region inference is the notion of region polymorphism, \nwhich allows regions to be passed to functions at runtime. Region-based memory management provides the \nfollowing properties: Automation. Garbage is reclaimed automatically at runtime, by popping the region \nstack.  Lifetimes are decided at compile time. Region infer\u00adence and other static analyses decide lifetimes \nat com\u00adpile time [20, 3]. There is no tagging (for pointer traversal) and no runtime traversal of values \nin order to free memory.  Specialization. Region inference specializes memory management to the user \ns program.  Region-based memory management is implemented for Stan\u00addard ML in the ML Kit [18], a region-based \ncompiler for all of SML 97, including Modules and the Standard ML Basis Library. To date, the largest \nStandard ML programs com\u00adpiled under the region scheme are AnnoDomini, a 60,000 lines program and the \nML Kit itself, a 90,000 lines program. 1.2 Contributions of the Paper So far, there has been no direct \nway of comparing region\u00adbased memory management with garbage collection. Part of the reason is theoretical. \nIt is known that region-based memory management and garbage collection are incompa\u00adrable, in that there \nare programs that use arbitrary more space in one scheme than in the other. But even experimen\u00adtal comparisons \nare di.cult: a Standard ML compiler is a complex piece of software and di.erences in performance in code \nproduced by di.erent compilers may stem from many other factors than di.erences between regions and garbage \ncollection. At the same time, practical experimentation with region\u00adbased memory management has suggested \nthat although some rewriting of source programs is often necessary in order to get good memory behaviour, \noften very little rewriting is required, even for large programs. (In the case of AnnoDo\u00admini, a reasonably \ngood execution was obtained after mod\u00adifying 10 lines out of 60,000 [7].) This suggests that most of \nthe time, region inference estimates lifetimes correctly. The purpose of this paper is to investigate \nthe relation\u00adship between region inference and garbage collection more closely. In particular, can a \ncombination of garbage collec\u00adtion and region inference reduce the need for tuning pro\u00adgrams? Can such \na combination give practical results that are as good as the ones one obtain with tuned programs using \nregions alone? Conversely, from the point of view of garbage collection: is region inference an e.cient \nway of reducing the amount of garbage collection required? In order to answer these questions, we have \ndesigned a new back-end and runtime system for the ML Kit that allows one to compile and run programs \nin di.erent modes, including: 1. Using regions alone, with values untagged and support for dangling pointers \n(in a pure region based system where values are not traversed by a garbage collector, no tags are needed \nto distinguish pointers from non\u00adpointers) 2. Using regions alone, but with values tagged; this mode \nmakes it possible to isolate the e.ect of tagging on performance 3. Using a copying garbage collector \nwithin a degenerate region stack consisting of one region only 4. Using a combination of regions and \nthe copying garbage collector  The remainder of the paper is organised as follows. Sec\u00adtion 2 describes \nthe new runtime system for integrating re\u00adgion inference and garbage collection based on Cheney s copying \ngarbage collection algorithm. An overview of the ML Kit implementation is given in Section 3. Section \n4 presents evidence that region inference very signi.cantly re\u00adduces the number of garbage collections; \nevidence that the fastest execution is obtained by using regions alone, without garbage collection; and \nempirical evidence that the combi\u00adnation of region inference and garbage collection is compara\u00adble to \nStandard ML of New Jersey (another state-of-the-art Standard ML compiler) both regarding time and memory \nusage. Finally, in Sections 5 and 7 we describe related work and conclude.  2. GARBAGE COLLECTING REGIONS \nRegion inference imposes a restriction on how garbage col\u00adlection can work, namely, if two values belong \nto the same region before the collection and both survive the collection then they must belong to the \nsame region after the col\u00adlection. (Otherwise, the popping of the region stack could become unsound.) \nThe .rst design issue for a garbage collec\u00adtor then becomes whether one should try to garbage collect \njust one region at a time, or all regions. The former would allow, for example, that global regions (i.e., \nregions that are pushed onto the empty region stack when the program starts and not deallocated until \nthe program terminates) are garbage collected separately. However, determining the set of pointers that \npoint into a given region appears to be ex\u00adpensive, for, in principle, there can be pointers from any \nregion into the region in question. Thus the algorithm that we propose collects all regions in every \ngarbage collection. To discuss the algorithm in more detail, we need to de\u00adscribe the physical representation \nof regions, initially with\u00adout considering garbage collection. 2.1 Physical Representation of Regions \nThe store consists of a stack and, separate from the stack, a region heap. The stack consists of activation \nrecords. The region heap consists of a set of .xed-size region pages, some of which are linked together \nin a free-list. At runtime we distinguish between two kinds of regions [3]: 1. Regions inferred to hold \nonly one value at a time. The size of the region is the maximal size of the values that may be allocated \nin the region. Those regions are called .nite regions and are allocated in activation records on the \nstack. Finite regions usually contain tuples and closures. 2. Regions inferred to hold an unbounded \nnumber of val\u00adues are called in.nite regions. An in.nite region is represented by a linked list of region \npages, pointed to by a region descriptor, which resides in an activation record on the stack. In.nite \nregions usually contain lists and other recursive data structures.  A region descriptor is a triple \n(e, fp,a) of pointers, where e, the end pointer, points to the end of the most recently allocated page \nin the region; a, the allocation pointer, points to the .rst available free location in that page; and \nfp, the .rst-page pointer, points to the .rst page of the region [8]. Figure 2 shows an example runtime \nstack containing three region descriptors and one .nite region. Allocating a value is done at a if there \nis enough space in the region page; otherwise, the region is extended with a region page taken from the \nfree-list. An in.nite region is allocated by requesting a region page from the free-list and updating \na region descriptor. When an in.nite region is popped, its region pages are appended to the free-list; \nthis operation can be done in constant time . r1 r2 r3 r4 Figure 2: The runtime stack (bottom) contains \nthree region descriptors and a .nite region (r3). Each re\u00adgion descriptor is a triple of pointers. with \nthe use of the .rst-page pointer fp, the end-pointer e, and knowledge about the size of a region page. \nValues that .t in one word, such as integers and booleans, are implemented unboxed and therefore do not \nreside in dis\u00adtinguished regions. The size of an activation record is de\u00adtermined at compile time. An \nactivation record is allocated on the runtime stack at entry to a function and popped on exit. Addresses \nof unboxed values, .nite regions and region descriptors inside an activation record are statically deter\u00admined \no.sets from the stack pointer. Thus, allocating a value in a .nite region amounts to a store operation \nat a known o.set from the stack pointer. No code is needed for allocating or deallocating a .nite region \nat runtime, beyond the code for pushing and popping the enclosing activation record. 2.2 Cheney s Stop \nand Copy Algorithm Our garbage collection algorithm is based on Cheney s stop and copy algorithm [5]. \nCheney s algorithm has the advantage of being relatively straightforward. An argument against Cheney \ns algorithm might be that, unlike genera\u00adtional garbage collectors, it does not employ heuristics con\u00adcerning \nlifetimes. But region inference already separates data according to lifetimes, so it is not clear that \nthe garbage collector has to do so as well. In this section we review Cheney s algorithm. In Sec\u00adtion \n2.3 we describe how we have modi.ed it to deal with regions. Cheney s algorithm uses two address spaces \n(semi-spaces), called the from-space and the to-space, respectively. The program allocates values into \nthe from-space. Garbage col\u00adlection is initiated when the from-space is full. The root set is the set \nof variables that are live in the activation records on the stack. The algorithm copies all the values \nreachable from the root set from the from-space into the to-space. Thereafter the from-space and the \nto-space swap roles. The Cheney algorithm is outlined below: fun cheney(fromspace,tospace,s,a)= let fun \nevacuate(p)= case !p of FORWARDED p => p | VALUE v => let a0 = a in a:=a+size(v); tospace[a0..a-1]:= \nv; fromspace[p]:= FORWARDED a0; a0 end fun scan(v)= (for each pointer p in v do p:= evacuate(p); s:= \ns + size(v)) in while s<ado scan(!s) end The algorithm performs a breadth-.rst search and evacuates \nvalues from the from-space. It uses a scan pointer, s, and an allocation pointer, a, both of which point \ninto the to\u00adspace; a points at the .rst free location in to-space and s points at the next value to be \nscanned. The invariant s = a holds throughout. The part of the to-space between s and a serves as a queue \nfor the breadth-.rst search. The collection is complete when we obtain s = a. Every boxed representation \nof a value has a tag-.eld for implementing pointer traversal. After copying a value, the algorithm replaces \nthe tag-.eld in the original copy of the value with a forward pointer, which points at the new copy of \nthe value in to-space. Forward pointers can be distinguished from all other tags. The function scan scans \nthe value v pointed at by s and calls the function evacuate on all pointer .elds inside v. We think of \na value as a record of words, some of which are pointers. We assume a mechanism that can distinguish \nthe pointers of a value from the non-pointers. Each pointer .eld is updated to contain the result of \nevacuating it. Finally, scan increases s, in preparation for scanning of the next unscanned value. A \ncall evacuate(p), where p is a pointer, examines the tag\u00ad.eld of the contents of p (i.e., !p). If the \ntag-.eld is a forward pointer then the forward pointer is returned. Otherwise !p is a value v; in this \ncase we copy v into to-space (increasing a in the process) and replace the original copy of v by a forward \npointer. The algorithm assumes that there are no pointers from the heap to the stack. Initially, s and \na point at the .rst address in to-space. We then apply evacuate on all pointer values in the root set \nand update the pointers in the root set with the new locations. At this point, the memory between s and \na contains values evacuated from the root set. Then, cheney(fromspace,tospace, s, a) completes the collection. \n 2.3 Adapting Cheney s Algorithm for Regions Cheney s algorithm can be extended to work with regions, \nas follows. Intuitively, each region is associated with a from\u00adspace and a to-space. A region descriptor \nis now a quadruple (e, fp,a,b) where a plays the dual role of being the allocation pointer for region \ninference and for the garbage collector and b is a so-called region status, which we have more to say \nabout below. Scan pointers are kept in a scan stack; there is no scan pointer in the region descriptor. \nIn the following, when r is some region descriptor, we use the notation r . a to refer to the allocation \npointer in r; we use similar notation to access the other components of a region descriptor. We now apply \nCheney s algorithm locally on each region and use the stop criteria: .r . Reg :(r . a)= sr, where Reg \nis the set of region descriptors on the stack and sr is the scan pointer of r. The stop criteria is implemented \nusing the scan stack, which consists of those scan pointers sr for which sr =(r . a). The garbage collector \nnever allocates into from-spaces. At the start of a garbage collection, the region stack is traversed \nand the region pages in the from-space areas (pointed at by r . fp) are linked together to form a single \nglobal from\u00adspace area. Next, for every region descriptor r on the stack, r . fp is initialised to point \nat a fresh region page taken from the free-list. Moreover, r . a is initialised to point at the beginning \nof the page pointed to by r . fp and r . e at the end of the page pointed to by r . fp. While collection \nis in progress, region pages are allocated from the free-list, which is disjoint from the global from-space \narea. After garbage collection, the global from-space area is appended to the free-list in a constant-time \noperation. The Cheney algorithm extended to regions is outlined be\u00adlow: fun evacuate(p)= case !p of FORWARDED \np => p | VALUE v => let val r = regiondesc(p) val a = alloc(r, v) in if r->b = NONE then (r->b:= SOME; \npush_onto_scanstack(a)) else (); fromspace[p]:= FORWARDED a; a end fun cheney(fromspace,r,s,a)= (while \ns <> a do let valv=!s in for each pointer p in v do p:= evacuate(p); s:= next_value(v,r) end; r->b:= \nNONE) fun collect_regions()= while scanstack_not_empty() do let val s = pop_scanstack() val r = regiondesc(s) \nin cheney(fromspace, r, s, r->a) end In a call cheney(fromspace,r,s,a), r is the address of a region \ndescriptor of a region; it plays the role of the to\u00adspace. The for-loop scans the value v pointed at \nby s and calls the function evacuate on all pointer .elds inside v. The call next value(v,r) proceeds \nto the value after v in r (which may entail proceeding to the next region page in the region). Next consider \nfunction evacuate. Given a pointer p to a value v, regiondesc(p) returns the address of the region descriptor \nof the region containing v (see Section 2.4). The function alloc(r,v) allocates v in the region described \nby r, returning the address of the new copy. (alloc extends the region with a new page, if necessary.) \nThe .eld b in the region descriptor is a two-valued mark, called the region status; the .eld is NONE \nif sr =(r . a) and SOME if sr The .eld b is to NONE in function =(r . a). set cheney when all values \nhas been scanned. Because a region is composed of region pages, it is not always the case that sr = (r \n. a) but sr =(r . a) still signi.es that the queue of unscanned values in the region is empty. When this \nhappens, the region status of the region is changed to NONE. The algorithm maintains the invariant that \nthe region sta\u00adtus r . b of some region descriptor r is SOME if and only if either sr is on the scan \nstack or r denotes a region that is currently being scanned.1 Finally, collect regions repeatedly calls \ncheney on one region at a time, till the scan stack is empty. The maximal depth of the scan stack is \nlimited by the number of region descriptors on the region stack; at any time, at most one pointer for \neach region is on the scan stack. 2.4 Region Page Descriptors Every region page starts with a region \npage descriptor. It contains a pointer to the next region page in the region. It also contains an origin \npointer, which points back to the region descriptor of the region. As mentioned earlier, all region pages \nused by regions have the same .xed size. By instrumenting the compiler and the runtime system, it is \npossible to change the size of region pages to 2n, where 1 = n = w and w is the number of bits per word \n(typically 32). Furthermore, the runtime system ensures that every region page starts on an address divisible \nby 2n . Given the address p of value v, the region page descriptor of the page that contains v is found \nby computing the bitwise and of p and 1 \u00b7\u00b7\u00b710 \u00b7\u00b7\u00b70. '-v \"'-v \" w-nn Thus regiondesc(p) can be computed \nby accessing the re\u00adgion page descriptor as described above and then extracting the origin pointer from \nit. 2.5 Finite Regions So far, we have considered in.nite regions only. Unfor\u00adtunately, .nite regions \ncomplicate matters, for there can be pointers from region pages into .nite regions on the stack and indeed \nfrom a value in a .nite region into another .\u00adnite region. We therefore distinguish between three kinds \nof values: 1In the implementation, the region status occupies only one bit and is encoded in one of the \npointer .elds in the region descriptor. 1. Values allocated in in.nite regions. These values are traversed \nand evacuated as described above. 2. Values allocated in .nite regions residing in activation records \non the stack. Such values are traversed and updated but are not moved. 3. Constants in the data area \nof the program binary. Be\u00adcause such values do not point at values in .nite or in.nite regions, these \nvalues are not traversed, not up\u00addated, and not copied.  To revise the algorithm to work with all three \nkinds of values, a separate scan bu.er is used for .nite regions. A value in a .nite region is not moved \nand hence no forward pointer is stored after the value is traversed. To avoid that the algorithm traverses \n.nite regions more than once, traversed values in .nite regions are marked as constants by updating the \nvalue tags. After garbage collection, the constant-marks are removed and values obtain their original \ntags. The scan bu.er is used both for holding values that remain to be scanned (similary to the scan \nstack for values in in.nite regions) and for keeping track of traversed values in .nite regions. All \nwhat is needed is to revise the two functions evacuate and collect regions shown below: fun evacuate(p)= \ncase !p of FORWARDED p => p | CONSTANT c => p | VALUE v => if points_into_stack(p) then (p:= set_tag_const(!p); \nadd_scan_buffer(p); p) else let val r = regiondesc(p) val a = alloc(r, v) in if r->b = NONE then (r->b:= \nSOME; push_onto_scanstack(a)) else (); fromspace[p]:= FORWARDED a; a end fun collect_regions()= (while \nscanstack_not_empty() || scanbuffer_not_done() do (while scanbuffer_not_done() do let val s = get_scanbuffer() \nin for each pointer p in !s do p:= evacuate(p) end; while scanstack_not_empty() do let val s = pop_scanstack() \nval r = regiondesc(s) in cheney(fromspace, r, s, r->a) end); for each pointer p in scanbuffer do p:= \nremove_tag_const(!p)) Consider the function evacuate. Constant values are rec\u00adognized by inspecting \nthe tag-.eld of the value (see Sec\u00adtion 2.2). The result of evacuating a pointer to a constant is the \npointer itself. A pointer p pointing at a value v in a .nite region is recognized by a range check on \nthe stack bound\u00adaries (function points_into_stack). The value v has not yet been traversed; otherwise \nit would have been marked as a constant. The algorithm marks v as a constant and adds it to the scan \nbu.er (i.e., we postpone the traversal of v). The stop criteria in function collect regions is now im\u00adplemented \nusing both the scan stack and the scan bu.er. The function get scanbuffer obtains the next un-scanned \nvalue v in scan bu.er; the value v is not removed from the bu.er. At the end of a collection, we remove \nall constant\u00admarks (function remove tag const) on traversed values in .nite regions. The maximal size \nof the scan bu.er is limited by the number of .nite regions on the stack. 2.6 Dangling Pointers Region \ninference allows for both shallow and deep point\u00aders, that is, pointers from older regions to newer regions \nand from newer regions to older regions. A shallow pointer may turn into a dangling pointer if the newer \nregion is deallo\u00adcated before the older region [19]. When memory is not traversed by a garbage collector, \nsuch dangling pointers are safe because region inference has discovered that these point\u00aders are not \ndereferenced by the program at runtime. Our pointer-tracing garbage collection algorithm, however, does \nnot work when there are dangling pointers. Therefore, when garbage collection is enabled in the compiler, \nregion infer\u00adence is weakened to prevent dangling pointers by forcing val\u00adues stored in a closure to \nlive at least as long as the closure [20]. Only in special cases does this weakening of region inference \nalter region-annotations. Consider the following Standard ML program: funfa=() fungv=fn()=>fv valh=g \n(2,3) In this program, the function f makes no use of its argument. When applied to an argument v, the \nfunction g returns a clo\u00adsure containing v, which is a pointer if v is boxed. Applying the non-weakened \nversion of region inference to the program yields the following region-annotated program: fun fat r1 \n[] (a)=() fun g at r1 [r7] (v)= (fn () => f[] v)at r7 val h = letregion r8 in g[r1] (2,3)at r8 end Due \nto the region-annotated types that are inferred for f and g, region inference concludes that the argument \npassed to g can be deallocated after the application of g. The result is that, after deallocation of \nregion r8, h is bound to a closure containing a dangling pointer. When garbage collection is enabled, \non the other hand, the weakening of region inference ensures that regions hold\u00ading values captured in \na closure live at least as long as the closure itself. Thus when garbage collection is enabled the result \nof applying region inference to the binding of h yields the following region-annotated version of the \nbinding: val h = g[r1] (2,3)at r1 In this region-annotated version of the binding, the pair (2,3) is \nallocated in the global region r1, which happens to be the same region in which the closure returned \nby g is allocated. It turns out that for all the benchmark programs men\u00adtioned in Section 4, the weakening \nof region inference as described here has no visible e.ect on memory usage or ex\u00adecution time.  3. \nTHE ML KIT The ML Kit is a Standard ML compiler that uses region inference as the basis for memory management \n[18]. The ML Kit is extended to support garbage collection of regions as described in the previous sections. \nThe compiler is com\u00adposed of a series of translations that gradually compiles pro\u00adgrams into x86 machine \ncode:2  Elaboration. Programs that are invalid according to the language speci.cation are rejected [16]. \n Modules Compilation. In this phase, Modules are elim\u00adinated and program fragments are compiled into \nan explicitly typed language called LambdaExp [7].  Optimization. An optimizer rewrites LambdaExp frag\u00adments \nas long as it can guarantee that the resulting fragments run in less space than the original fragments. \nOptimizations include function inlining, specialization of recursive functions, unboxing of function \narguments, and elimination of polymorphic equality [6].  Region inference. In this phase, LambdaExp \nfragments are translated into a language RegionExp in which memory directives are explicit [17].  Region \nrepresentation inference. Regions are divided into .nite and in.nite regions based on a static ap\u00adproximation \nto the number of values that are stored in the particular region [3].  Register allocation and instruction \nselection. This trans\u00adlation compiles RegionExp fragments into x86 machine instructions [8, 13]. When \ngarbage collection is en\u00adabled in the compiler, values are tagged so as to allow pointer tracing and \npointer forwarding.  To execute a program compiled with the ML Kit, the gen\u00aderated x86 machine code \nis linked with a runtime system, written in C. The runtime system includes region primitives for manipulating \nthe region-stack, such as primitives for al\u00adlocating and deallocating regions, and primitives for allo\u00adcating \nin regions. When garbage collection is enabled in the compiler, the generated code is linked with a version \nof the runtime system that integrates the region primitives with the garbage collector described in the \nprevious sections. The runtime system may also be compiled with support for region pro.ling, which makes \nit possible to inspect mem\u00adory usage in regions over time [12]. 3.1 Large Objects There is one important \naspect of the runtime system that the previous description of the garbage collection algorithm does not \nmention, namely how the runtime system manages 2A bytecode backend to the ML Kit is available as well. \nlarge objects (i.e., objects that do not .t in a single region page). To manage large objects e.ciently \nand to allow ef\u00ad.cient natural representations of certain datatypes, such as strings and arrays, memory \nfor large objects is allocated using malloc and associated with a particular region in a linked list, \npointed to from a .eld in the region descriptor. Upon resetting or deallocation of a region, large objects \nin the associated linked list are deallocated using free. Although certain types of large objects (such \nas large ar\u00adrays and vectors) need be traversed by the garbage collector, large objects are never copied \nby the collector.  4. EXPERIMENTAL RESULTS In this section, we describe a series of experiments that \nserve to describe the relationship between region inference and the garbage collection algorithm shown \nin Section 2. We .rst investigate the e.ect of enabling tagging (Sec\u00adtion 4.1). Section 4.2 looks at \nexecution times and the num\u00adber of garbage collections performed when garbage collec\u00adtion is combined \nwith region inference. Section 4.3 seeks an answer to the question: of the memory reclaimed, what proportion \nis reclaimed by region management and what proportion is reclaimed by garbage collection? Finally, Sec\u00adtion \n4.4 compares memory usage and execution times with Standard ML of New Jersey (SML/NJ), another state-of\u00adthe-art \nStandard ML compiler. Section 4.5 compares the time and memory usage for bootstrapping the ML Kit with \nSML/NJ and the ML Kit itself, respectively. All benchmark programs are run on a 750Mhz Pentium III Linux \nbox with 512Mb RAM. Times reported are user CPU times and memory usage is measured in kilobytes using \nthe /proc special .le-system under the Linux operating system. We use mto specify memory usage (resident \nset size) and t to specify execution time (in seconds). Subscripts describe the mode of the compiler: \n* r signi.es region inference en\u00adabled, * t signi.es tagging enabled and * g signi.es garbage collection \nenabled (e.g., trt means time with regions and tag\u00adging enabled). We use tsmlnj and msmlnj to denote \nexecution time and memory usage for SML/NJ. The experiments are performed with the ML Kit version 4.1.0 \n[18] and Standard ML of New Jersey 110.0.7. The benchmark programs are listed in Figure 3. By disabling \nregion inference, we understand instructing the region inference algorithm to allocate all values that \nwould be allocated in in.nite regions in one global region. Then not a single in.nite region is deallocated \nat runtime and the garbage collection algorithm essentially reduces to Cheney s algorithm. Notice that \ndisabling region inference in this sense does not change the property that many values are allocated \nin .nite regions on the stack. Whenever the size of the free-list becomes less than 1/3 of the total \nregion heap, garbage collection is initiated upon the next function entry (i.e., safe point). After garbage \ncol\u00adlection, we make sure that the number of region pages in the region heap is at least three times \nthe size of to-space (the heap-to-live ratio). 4.1 Effect of Tagging When region inference is used without \ngarbage collection, values need not be tagged so as to implement pointer trac\u00ading. Table 1 isolates the \ne.ect of tagging by showing the execution time and memory usage for the benchmark pro\u00adgrams with tagging \nenabled and tagging disabled. In both Program Lines Description vliw 3676 VLIW instruction scheduler \nlogic 346 SML/NJ benchmark program zebra 302 Solves the Zebra puzzle tyan 1018 Grobner Basis calculation \ntsp 493 Traveling salesman problem mpuz 142 Emacs M-x mpuz puzzle DLX 2836 DLX RISC instruction simulation \nratio 619 Image analysis lexgen 1318 Lexer generation mlyacc 7353 Parser generation simple 1052 Spherical \n.uid-dynamics program professor 276 Solves puzzle by exhaustive search fib35 9 The Fibbonachi micro-benchmark \ntak 17 The Tak micro-benchmark msort 81 Sorting 100,000 integers kitlife 230 The game of life kitkb 725 \nKnuth-Bendix completion Figure 3: The benchmark programs span from small micro-benchmarks (fib35, tak, \nand msort) to larger programs, such as vliw and mlyacc, that solve real\u00adworld problems. The Lines column \nshows the size of each benchmark. None of the benchmark programs, except msort, kitlife, and kitkb, has \nbeen optimised for region inference. The benchmark programs fib35 and tak use only the runtime stack \nfor allocation. cases, region inference is enabled and garbage collection dis\u00adabled. The table shows \nthat tagging adds a substantial cost to execution time (tr <trt ) and to memory usage (mr <mrt ). For \nprograms where lists and reals account for the major\u00adity of the memory usage, the memory overhead of \ntagging is close to 50 percent, due to the value tags in allocated pair and real values [6].  4.2 Effect \nof Region Inference on Garbage Col\u00adlection Table 2 demonstrates the e.ect of region inference on garbage \ncollection. First, the table shows dramatic savings in number of garbage collections when enabling region \nin\u00adference (i.e., #GCrgt < #GCgt ). Second, for most of the benchmark programs, enabling region inference \ndecreases execution time (i.e., trgt <tgt ). Third, comparing Table 2 and Table 1, we see that tr < trgt \nfor all benchmark programs. The fastest execution is obtained by relying solely on region-based memory \nmanage\u00adment. Finally, Table 2 shows that, when combined with garbage collection, region inference often \nhas a negative e.ect on memory usage (i.e., mgt <mrgt ). This negative e.ect is mostly due to waste in \nregions, which we have more to say about in the next section. The programs DLX and msort be\u00adhave very \nwell without garbage collection (compare Table 2 and Table 1) and in these cases, when garbage collection \nis combined with region inference, garbage collection is initi\u00adated only at the start of execution; thus \nit does not become necessary to allocate three times the amount of live memory and therefore mrgt <mgt \n. E.ect of Region Inference on Garbage Collection Program Time (seconds) Memory (bytes) Collections \ntgt trgt % mgt mrgt % #GCgt #GCrgt % vliw 1.99 1.16 42 1640K 2376K 45 265 21 92 logic 6.94 7.02 1 892K \n892K 0 2582 2574 0 zebra 4.60 4.46 3 548K 644K 18 2071 408 80 tyan 10.2 7.16 30 1352K 2800K 107 1098 \n343 69 tsp 4.15 3.56 14 8532K 8536K 0 16 10 38 mpuz 10.2 10.2 0 568K 568K 0 2 2 0 DLX 9.33 7.40 21 5560K \n4428K 20 102 3 97 ratio 1.86 1.76 5 1628K 1640K 1 36 13 64 lexgen 7.87 6.77 14 3076K 3912K 27 293 155 \n47 mlyacc 0.51 0.35 31 2676K 3680K 38 60 29 52 simple 2.39 2.10 12 2372K 2452K 3 16 6 62 professor 1.04 \n0.73 30 576K 640K 11 2816 122 96 fib35 1.91 1.91 0 500K 500K 0 1 1 0 tak 14.0 14.0 0 500K 500K 0 1 1 \n0 msort 1.14 0.71 38 9912K 8328K 16 17 7 59 kitlife 1.89 1.83 3 612K 592K 3 818 2 100 kitkb 1.57 1.77 \n13 1076K 1352K 26 193 4 98 Table 2: There are signi.cant savings in number of garbage collections performed \nwhen region inference is enabled. For most programs, enabling region inference also signi.cantly reduces \nexecution time. With respect to memory usage, the e.ect of enabling region inference strongly depends \non the program. Improvements (e.g., (tgt - trgt )/tgt ) are written in percentages. E.ect of Tagging \non Time and Memory Usage Program Time (seconds) Memory (bytes) tr trt % mr mrt % vliw 0.89 0.98 10 4376K \n5880K 34 logic 3.15 3.82 21 128M 171M 34 zebra 3.68 3.91 6 6836K 10M 46 tyan 4.67 5.32 14 199M 283M 42 \ntsp 3.37 4.39 30 3624K 5820K 61 mpuz 8.01 9.17 14 524K 536K 2 DLX 6.01 6.99 16 2972K 3548K 19 ratio 1.44 \n1.54 7 2784K 3856K 39 lexgen 4.77 5.17 8 19M 27M 42 mlyacc 0.17 0.19 12 7796K 10M 28 simple 1.65 1.79 \n8 1276K 1708K 34 professor 0.66 0.68 3 4820K 6840K 42 fib35 1.38 1.69 22 480K 476K 0 tak 12.4 13.0 5 \n480K 476K 0 msort 0.50 0.57 14 4976K 6372K 28 kitlife 1.55 1.57 1 524K 564K 8 kitkb 1.60 1.64 2 1104K \n1136K 3 Table 1: The e.ect of enabling tagging in the ML Kit. The time overhead (trt - tr )/tr (written \nin per\u00adcentages) varies from 1 to 30 percent with an av\u00aderage of 11 percent. The memory usage overhead \nvaries between 0 and 60 percent with an average of 27 percent.  4.3 Memory Recycled by Region Inference \nWe now more deeply explore the relationship between garbage collection and region inference. We .rst \nask: of the memory that is reclaimed, what percentage is reclaimed by region inference? (The rest must \nbe collected by the garbage collector.) This fraction depends on the garbage collection strategy used; \neventually region inference reclaims all garbage, when the program ends. The fewer times we garbage collect, \nthe higher the fraction of garbage collected by region inference becomes. Table 3 shows, in percentages, \nhow much memory is re\u00adcycled by region inference (RI rgt ) and garbage collection (GC rgt ), respectively. \nThe table also shows the amount of region waste (i.e., non-used memory in region pages) as a percentage \nof the total amount of memory allocated for re\u00adgion pages. The region waste column is calculated as an \naverage of region waste computed at each garbage collec\u00adtion invocation. We see that region inference \nrecycles the vast amount of memory for many of the programs. However, for the bench\u00admark programs logic, \nzebra, tyan, lexgen, and mlyacc, a high percentage of memory is deallocated by the garbage collector. \nIt is important to notice that .nite regions are not accounted for here; .nite regions are allocated \nin activation records on the stack. Previous measurements demonstrate that a high percentage of all values \nmay be stored in .nite regions [3]. To compute, for each garbage collection, the fractions of memory \nreclaimed by garbage collection and region infer\u00adence, respectively, we proceed as follows. Let gi be \ngarbage collection phase i. Let Li be the amount of live data af\u00adter gi (i.e., number of region pages \nin the to-space) and let Ap be the total number of region pages requested in the period between gi and \ngi+1. Moreover, let Ai+1 be the number of region pages in from-space just before gi+1. Memory Recycling \nand Region Waste Program Recycling (%) Waste (%) RI rgt GC rgt Wrgt vliw 85.2 14.8 22.9 logic 0.1 99.9 \n3.2 zebra 33.1 66.9 27.2 tyan 7.7 92.3 16.2 tsp 91.7 8.3 4.4 mpuz 100 0.0 DLX 100 0.0 ratio 75.5 24.5 \n16.0 lexgen 24.2 75.8 18.9 mlyacc 27.8 72.2 19.4 simple 92.5 7.5 17.8 professor 85.7 14.3 19.5 fib35 \ntak msort 100 0.0 5.0 kitlife 100 0.0 kitkb 99.9 0.1 Table 3: The programs fib35 and tak do not use \nregions, hence no values appear in the columns for these programs. No value appears in the third col\u00adumn \nfor benchmark programs for which the garbage collector runs only a few times. The same heap-to\u00adlive ratio \nof 3.0 was used for all benchmarks. Then, the amount of data reclaimed by garbage collection is Ai+1 \n- Li+1 and the amount of data reclaimed by re\u00adgion inference is Li + Ap - Ai+1. The total amount of data \nreclaimed is Li + Ap - Li+1, thus, we get the fractions: Li+Ap -Ai+1 Ai+1-Li+1 RI = and GC =. Li+Ap -Li+1 \nLi+Ap -Li+1 Figure 4 shows the fraction GC (i.e., 1-RI) for the bench\u00admark professor as a function of \ntime. Throughout, region inference takes care of most of the deallocation. 4.4 Comparison with SML/NJ \nIn this section we compare memory usage and execu\u00adtion time for executables generated by the ML Kit with \nexecutables generated by Standard ML of New Jersey ver\u00adsion 110.0.7. The purpose here is not to suggest \nwhich com\u00adpiler is better, but merely to demonstrate that combining garbage collection with region inference \nmay produce re\u00adsults that are comparable in performance to state-of-the-art compilers. The measurements \nshould be taken with a grain of salt; as mentioned earlier, di.erences in performance in code produced \nby di.erent compilers may stem from many other factors than di.erences between regions and garbage collection. \nTable 4 shows execution times and memory usage for all benchmark programs compiled with Standard ML of \nNew Jersey. The benchmark programs can be divided into three groups of programs; those that run in less \ntime than with SML/NJ and uses less memory (programs zebra, DLX, professor, fib35, tak, and kitlife), \nthose that run in more time and uses more memory (programs tyan, lexgen, mlyacc, and simple), and the \nremaining programs (logic, tsp, mpuz, ratio, msort, and kitkb). The benchmark programs in the second \ngroup (in particu\u00ad0 20 40 60 80 100 gc no. Figure 4: The .gure shows the amount of memory (in percentages) \nreclaimed by garbage collection as a function of time. At garbage collection number 60, the garbage collector \nreclaims approximately 10 percent of the memory reclaimed since garbage col\u00adlection number 59. Hence \nregion inference reclaims 90 percent of the garbage in that period. Time is the garbage collection cycle \nnumber. Comparison with Standard ML of New Jersey Program Time (seconds) Memory (bytes) tsmlnj trgt tsmlnj \ntrgt msmlnj mrgt msmlnj mrgt vliw 1.44 1.16 1.2 556K 2668K 0.2 logic 3.75 7.02 0.5 1936K 1012K 1.9 zebra \n10.4 4.46 2.3 864K 852K 1.0 tyan 3.78 7.16 0.5 1820K 2972K 0.6 tsp 20.8 3.56 5.8 7408K 8640K 0.9 mpuz \n20.7 10.2 2.0 840K 768K 1.1 DLX 10.1 7.40 1.4 4892K 4564K 1.1 ratio 3.15 1.76 1.8 2500K 3312K 0.8 lexgen \n5.95 6.77 0.9 304K 3976K 0.1 mlyacc 0.33 0.35 0.9 1692K 3504K 0.5 simple 1.64 2.10 0.8 1880K 2520K 0.7 \nprofessor 2.18 0.73 3.0 924K 832K 1.1 fib35 2.72 1.91 1.4 1072K 652K 1.6 tak 22.4 14.0 1.6 860K 648K \n1.3 msort 0.87 0.71 1.2 3516K 8516K 0.4 kitlife 2.54 1.83 1.4 1064K 780K 1.4 kitkb 2.51 1.77 1.4 752K \n1572K 0.5 Table 4: Comparison of Standard ML of New Jer\u00adsey with the version of the compiler that combines \nregion inference and garbage collection. A heap-to\u00adlive ratio of 3.0 was used for all benchmarks. lar \ntyan and lexgen) suggest that the garbage collector does not always do a good job. There may be several \nreasons for this: All top-level variables are included in the root set. This ine.ciency may be overcome \nby applying an anal\u00adysis for nullifying top-level variables after their last use.  Region waste. As \nshown in Table 3, some benchmark programs cause a signi.cant amount of unused mem\u00adory in region pages. \n Insu.cient safe points. In the ML Kit, garbage collec\u00adtion may be initiated only at function entry \nnot at arbitrary allocation points.  Lack of tail-calls. It is possible for region inference to introduce \nletregion constructs around expressions that occur in tail-call contexts and that would other\u00adwise cause \napplications within the expression to be im\u00adplemented as tail-calls. By widening the scope of such letregion \nconstructs tail-calls may be implemented properly. This feature is not yet implemented.  For programs \nin the third group, it is possible to alter the trade-o. between memory usage and execution time by altering \nthe heap-to-live ratio (default is 3.0), because the heap-to-live ratio controls how often garbage collection \nis invoked. 4.5 Bootstrapping In this section we compare bootstrapping the ML Kit us\u00ading either SML/NJ \nor the ML Kit itself [18]. In the .rst setting, the SML/NJ compiler is used to compile the ML Kit sources \ninto a version of the ML Kit that, when run\u00adning, uses the SML/NJ runtime system. This version of the \nML Kit is called kit1. Using kit1 to compile the ML Kit sources into kit2 uses 809Mb and takes 40:41min.3 \nThe kit2 executable runs on the runtime system of the ML Kit using the combination of region inference \nand garbage collection. Using kit2 to compile the ML Kit sources into kit3 uses 904Mb and takes 17:33min. \nThe combination of region inference and garbage collection works very well on this large program. Figure \n5 shows the memory behavior of the ML Kit (using region inference and garbage collection) when compiling \nthe benchmark program kitkb. The global region r1 is by far the largest. The ML Kit is not optimized \nfor regions and without the garbage collector, region r1 would grow without ever decreasing.  5. RELATED \nWORK Related work fall into several categories. First, there is a large body of work concerning general \ngarbage collection techniques [23, 14] and escape analysis for improving stack allocation in garbage \ncollected systems [4]. The extra com\u00adplexity of region inference and the polymorphic multiplicity analysis \nimplemented in the ML Kit [3] allow more objects to be stack allocated than does traditional escape analyses, \nwhich allows only local, non-escaping values to be stack al\u00adlocated. 3A 1 GHz Pentium III (Coppermine) \nmachine equipped with 1Gb RAM is used for the bootstrapping experiments. Figure 5: A region pro.le of \nthe ML Kit using region inference and garbage collection when compiling the benchmark program kitkb. \nWithout garbage collec\u00adtion, region r1 would grow without ever decreasing. Gay and Aiken demonstrate \nhow explicit region based memory management may work succesfully for C when com\u00adbined with reference \ncounting of regions [9, 10]. In their RC system, however, individual objects in a region are not garbage \ncollected until the entire region is freed, which is im\u00adportant in our case where, for instance, a programmer \ncan\u00adnot be assumed to have arranged that the result of a func\u00adtion is stored in a region di.erent from \nintermediate results computed by the function. Aiken et al. [1] show how region inference may be improved \nfor some programs by removing the constraints of the stack discipline; such improvements to region inference \ncould cause a fall-back garbage collector to run less frequently. Also related to our work is the work \non Cyclone [11], a safe version of the C programming language that uses regions for memory management. \nIn Cyclone, a particular region the heap is garbage collected, whereas other regions, except regions \ncorresponding to individual activation records, must be allocated and deallocated explicitly by the programmer. \nSlightly related to our work is the work by Appel and Wang on integrating with a program a type-safe \nspecialized garbage collector for the program [22]. The focus of their work, however, is on type safety \nand it is yet to be shown how well the approach works in a real system. 6. FUTURE DIRECTIONS There are \nseveral directions for future work. First, the results in this paper suggest that the combination of \nre\u00adgion inference and garbage collection in a general purpose ML compiler is a viable and e.cient strategy \nfor memory management. As outlined in Section 4.4, however, there are several ways the interaction between \nregion inference and garbage collection can be improved. In particular, the widening of some letregion \nconstructs to ensure proper im\u00adplementation of tail calls is called for. Also, arranging that garbage \ncollection can be initiated at arbitrary allocation points instead of only at function entry points may \nim\u00adprove memory usage for some programs. A second direction for future work is to investigate the use \nof region inference as an advanced, polymorphic escape anal\u00adysis by collapsing all in.nite regions into \none single heap. In such a setting, which corresponds to the disabling of region inference in our benchmark \ntests, an e.cient generational collector could be used for the single heap. Finally, a third direction \nfor future work concerning the combination of garbage collection and region inference is to investigate \nthe possibility of combining region inference with a tag-free (or nearly tag-free) garbage collection \nscheme. In the basic region typing rules, two values are forced into the same region, only if their types \nare identical. This property suggests that tags for pointer traversal can be moved from individual values \nto the level of regions, which could improve memory usage signi.cantly for many programs. 7. CONCLUSION \nBased on Cheney s copying garbage collection algorithm, we have developed a runtime system that integrates \ngarbage collection with region based memory management. The runtime system is implemented for all of \nStandard ML in the ML Kit compiler. Concerning execution time, measurements show that the fastest execution \nis obtained by using regions alone. Concerning memory consumption, the experiments con.rm that most region-optimised \nprograms use less space and time when using regions alone than when using regions combined with garbage \ncollection or garbage collection alone. (Region inference does not need tags for pointer traversal, nor \nspace for copying.) For programs that are not optimised for regions, adding garbage collection re\u00adduces \nmemory usage but increases running times. From the point-of-view of garbage collection, the measure\u00adments \ndemonstrate that the pressure on garbage collection is reduced signi.cantly by integrating garbage collection \nwith region inference. Finally, measurements show that the combination of re\u00adgion inference and garbage \ncollection, as implemented in the ML Kit, is as e.cient with respect to memory usage and ex\u00adecution time \nas a state-of-the-art generational garbage col\u00adlection system. 8. ACKNOWLEDGMENTS We would like to thank \nKen Friis Larsen and Lars Birkedal for their careful reading of a draft of this paper. Also thanks to \nthe anonymous referees for detailed comments and sug\u00adgestions. 9. REFERENCES [1] Alexander Aiken, Manuel \nF\u00a8ahndrich, and Raph Levien. Better static memory management: Improving region-based analysis of higher-order \nlanguages. In ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI 95), pages \n174 185, La Jolla, CA, June 1995. ACM Press. [2] Andrew W. Appel. Compiling with Continuations. Cambridge \nUniversity Press, 1992. [3] Lars Birkedal, Mads Tofte, and Magnus Vejlstrup. From region inference to \nvon Neumann machines via region representation inference. In 23rd ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages, pages 171 183. ACM Press, January 1996. [4] Bruno Blanchet. Escape analysis \n: Correctness proof, implementation and experimental results. In 25th ACM SIGPLAN-SIGACT Symposium on \nPrinciples of Programming Languages (POPL 98), pages 25 37. ACM Press, January 1998. [5] C. J. Cheney. \nA non-recursive list compacting algorithm. Communications of the ACM, 13(11):677 678, November 1970. \n [6] Martin Elsman. Polymorphic equality no tags required. In Second International Workshop on Types \nin Compilation, March 1998. [7] Martin Elsman. Static interpretation of modules. In Fourth International \nConference on Functional Programming (ICFP 99), pages 208 219. ACM Press, September 1999. [8] Martin \nElsman and Niels Hallenberg. An optimizing backend for the ML Kit using a stack of regions. Student Project \n95-7-8, Department of Computer Science, University of Copenhagen (DIKU), July 5 1995. [9] David Gay and \nAlexander Aiken. Memory management with explicit regions. In ACM SIGPLAN Conference on Programming Language \nDesign and Implementation (PLDI 98), Montreal, Canada, June 1998. ACM Press. [10] David Gay and Alexander \nAiken. Language support for regions. In ACM SIGPLAN Conference on Programming Language Design and Implementation \n(PLDI 01), Snowbird, Utah, June 2001. ACM Press. [11] D. Grossman, G. Morrisett, T. Jim, M. Hicks, Y. \nWang, and J. Cheney. Region-based memory management in Cyclone. In ACM SIGPLAN Conference on Programming \nLanguage Design and Implementation (PLDI 02), Berlin, Germany, 2002. ACM Press. [12] Niels Hallenberg. \nA region pro.ler for a Standard ML compiler based on region inference. Student Project 96-5-7, Department \nof Computer Science, University of Copenhagen (DIKU), June 1996. [13] Niels Hallenberg. Combining garbage \ncollection and region inference in the ML Kit. Master s thesis, Department of Computer Science, University \nof Copenhagen, 1999. [14] Richard Jones and Rafael Lins. Garbage Collection. Wiley, 1996. [15] Henry \nLieberman and Carl Hewitt. A real-time garbage collector based on the lifetimes of objects. Communications \nof the ACM, 26(6):419 429, June 1983. [16] Robin Milner, Mads Tofte, Robert Harper, and David MacQueen. \nThe De.nition of Standard ML (Revised). MIT Press, 1997. [17] Mads Tofte and Lars Birkedal. A region \ninference algorithm. Transactions on Programming Languages and Systems (TOPLAS), 20(4):734 767, July \n1998. [18] Mads Tofte, Lars Birkedal, Martin Elsman, Niels Hallenberg, Tommy H\u00f8jfeld Olesen, and Peter \nSestoft. Programming with regions in the ML Kit (for version 4). Technical report, IT University of Copenhagen, \nOctober 2001. [19] Mads Tofte and Jean-Pierre Talpin. A theory of stack allocation in polymorphically \ntyped languages. Technical Report DIKU-report 93/15, Department of Computer Science, University of Copenhagen, \n1993. [20] Mads Tofte and Jean-Pierre Talpin. Implementing the call-by-value lambda-calculus using a \nstack of regions. In 21st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages, pages \n188 201. ACM Press, January 1994. [21] Mads Tofte and Jean-Pierre Talpin. Region-based memory management. \nInformation and Computation, 132(2):109 176, 1997. [22] Daniel Wang and Andrew Appel. Type-preserving \ngarbage collection. In Conference Record of the 28th Annual ACM SIGPLAN-SIGACT Symposium on Principles \nof Programming Languages (POPL), pages 166 178. ACM Press, January 2001. [23] Paul R. Wilson. Uniprocessor \ngarbage collection techniques. In Y. Bekkers and J. Cohen, editors, Memory Management, Proceedings, International \nWorkshop IWMM92, pages 1 42. Springer-Verlag, September 1992.  \n\t\t\t", "proc_id": "512529", "abstract": "This paper describes a memory discipline that combines region-based memory management and copying garbage collection by extending Cheney's copying garbage collection algorithm to work with regions. The paper presents empirical evidence that region inference very significantly reduces the number of garbage collections; and evidence that the fastest execution is obtained by using regions alone, without garbage collection. The memory discipline is implemented for Standard ML in the ML Kit compiler and measurements show that for a variety of benchmark programs, code generated by the compiler is as efficient, both with respect to execution time and memory usage, as programs compiled with Standard ML of New Jersey, another state-of-the-art Standard ML compiler.", "authors": [{"name": "Niels Hallenberg", "author_profile_id": "81100409888", "affiliation": "IT University of Copenhagen, DK-2400 Copenhagen NV, Denmark", "person_id": "P348275", "email_address": "", "orcid_id": ""}, {"name": "Martin Elsman", "author_profile_id": "81100301515", "affiliation": "IT University of Copenhagen, DK-2400 Copenhagen NV, Denmark", "person_id": "P192114", "email_address": "", "orcid_id": ""}, {"name": "Mads Tofte", "author_profile_id": "81100142765", "affiliation": "IT University of Copenhagen, DK-2400 Copenhagen NV, Denmark", "person_id": "PP39029504", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512529.512547", "year": "2002", "article_id": "512547", "conference": "PLDI", "title": "Combining region inference and garbage collection", "url": "http://dl.acm.org/citation.cfm?id=512547"}