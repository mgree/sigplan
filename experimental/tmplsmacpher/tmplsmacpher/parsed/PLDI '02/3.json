{"article_publication_date": "05-17-2002", "fulltext": "\n Preference-Directed Graph Coloring Akira Koseki Hideaki Komatsu Toshio Nakatani IBM Tokyo Research Laboratory \n1623-14, Shimotsuruma, Yamato-shi, Kanagawa-ken 242-8502, Japan {akoseki, komatsu, nakatani}@jp.ibm.com \n ABSTRACT This paper describes a new framework of register allocation based on Chaitin-style coloring. \nOur focus is on maximizing the chances for live ranges to be allocated to the most preferred registers \nwhile not destroying the colorability obtained by graph simplification. Our coloring algorithm uses a \ngraph representation of preferences called a Register Preference Graph, which helps find a good regis\u00adter \nselection. We then try to relax the register selection order cre\u00adated by the graph simplification. The \nrelaxed order is defined as a partial order, represented using a graph called a Coloring Prece\u00addence \nGraph. Our algorithm utilizes such a partial order for the register selection instead of using the traditional \nsimplification\u00addriven order so that the chances of honoring the preferences are effectively increased. \nExperimental results show that our coloring algorithm is powerful to simultaneously handle spill decisions, \nregister coalescing, and preference resolutions. Categories and Subject Descriptors D.3.4 [Programming \nLanguages]: Processors compilers, opti\u00admization.  General Terms Algorithms, Performance, Experimentation. \nKeywords: Register allocation, graph coloring, register coa\u00adlescing, irregular-register architectures. \n1. INTRODUCTION Good register allocation is essential for advanced optimizing compliers. Many optimizers \nuse high-level intermediate program representations, such as a register-transfer language, a graph, or \nsometimes a tree. They usually use an infinite number of live ranges. Since not all live ranges can be \nallocated to physical regis\u00adters, some are spilled to memory. The cost of accessing memory is very high, \nand therefore, the register allocator must generate a good mapping from live ranges to physical registers. \nThe commonly used approach of register allocation using graph coloring was originally developed by Chaitin \net al. [2]. They try to color a graph that abstracts the interference among live ranges using K colors, \nwhere K is the number of physical registers. This mainly consists of two tasks, simplification of the \ngraph and as\u00adsignment of colors. Simplification gives an order of coloring that guarantees K-colorability. \nAssignment is then made by giving colors to live ranges one by one in that order. This approach suc\u00adcessfully \npacks live ranges to registers to minimize the spill cost. Several approaches have been attempted for \nspill decision im\u00adprovements [16, 17, 18], spill cost minimization [19, 20], and colorability improvement \n[21]. Besides minimizing spill costs, the register allocator must try for a good selection of registers. \nA good selection can minimize trivial register-to-register copies and significantly influence the quality \nof the generated code. For example, many sophisticated optimiza\u00adtion techniques utilize the static single \nassignment (SSA) form [5]. In the SSA form, a program is transformed so that the assignment of a variable \nappears only once in the program. This is achieved by giving each definition of a variable a new name \nand changing each use of the variable to the reaching definition. When more than two definitions reach \na use of an operation, a f-function is inserted at the merge point of the definitions. A f-function has \na single destination and multiple sources, and performs a selective copy from those sources to the destination. \nThe use of the opera\u00adtion is changed to the destination of the f-function. Of course, a na\u00efve SSA-transformed \nprogram has many copy operations, and therefore, it is necessary to remove as many copies as possible \nby a good register selection. Furthermore, there are other requirements for a good register se\u00adlection. \nFor example, compiler-generated code should comply with several conventions that define how to pass parameters \nand return values, or define the volatility of register values over func\u00adtion calls. It is then important \nto minimize the copies from live ranges to parameters or from return values to live ranges, and reduce \nthe call overhead by using volatile and non-volatile regis\u00adters effectively. Other examples of register \nselection requirements come from irregular-register architectures. In such architectures, operands for \nsome operations have special register requirements. Some of them use only dedicated registers and others \nneed spe\u00adcific sets of registers. The register allocator has to take care of all these requirements. \nPermission to make digital or hard copies of all or part of this work for personal or classroom use is \ngranted without fee provided that copies are not made or distributed for profit or commercial advantage \nand that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, \nto post on servers or to redistribute to lists, requires prior specific permission and/or a fee. PLDI \n02, June 17-19, 2002, Berlin, Germany. Copyright 2002 ACM 1-58113-463-0/02/0006 $5.00. Several approaches \nhave been used for those purposes. Register coalescing [2, 3, 6, 7] is a technique that effectively removes \ncop\u00adies. Various improvements followed such as Briggs et al. [3], George and Appel [6], and Park and \nMoon [7]. Lueh and Gross introduced an improved Chaitin-style coloring that deals with the problem of \nchoosing volatile and non-volatile registers [8]. How\u00adever, these techniques do not always give a good \nregister selection in the presence of a variety of irregular register usages. This is because their approaches \ncan be used only for limited kinds of register selection requirements. Furthermore, their local heuristics \nare unaware of other register selection requirements and this may lead to poor results. The details of \nthe problems are described below. In this paper, we propose a new register allocation framework, in which \ngood spill decisions and good register selections can be achieved simultaneously. To obtain good spill \ndecisions, we use the same basic approach as Chaitin s so that live ranges are packed into registers \neffectively. We then attempt to maximize the chances for live ranges to be allocated to the preferred \nregisters. Our approach is done by modifying the phases of Chaitin-style coloring. First we introduce \na graph called a Register Preference Graph, which describes preferences for pairings between live ranges \nor between a live range and a physical register. This can be obtained by examining the intermediate code. \nReferring to the Register Preference Graph, the register selector can pick the most preferred register. \nHowever the order created by simplification is usually too restrictive to achieve a register selection \nwith the pref\u00aderences well reflected. To create more chances of honoring prefer\u00adences, we relax the order \nmade by simplification, but without destroying the obtained colorability. The relaxation of the order \ngives a partial order that can be used for a register selection in\u00adstead of using the simplification-driven \norder. This partial order is described as another graph called the Coloring Precedence Graph, which can \nbe built from the simplification result and the interfer\u00adence graph. A traversal of the Coloring Preference \nGraph directed by the Register Preference Graph then leads to a good register allocation with spill costs \nminimized and an effective preference\u00addriven register selection. The rest of this paper is structured \nas follows. Section 2 briefly describes register allocation using graph coloring. In Section 3 we classify \npreferences into several categories, and discuss previous techniques for reflecting those. Section 4 \nthen addresses problems of register selection in the presence of several requirements for honoring the \npreferences. Section 5 covers all our techniques for register allocation, and Section 6 gives the experimental \nresults. After discussing non-Chaitin-style register allocation techniques that take care of preferences \nin Section 7, Section 8 concludes the paper. 2. GRAPH-COLORING REGISTER AL-LOCATION The seminal work \non register allocation by Chaitin et al. [2] estab\u00adlished a heuristic approach for solving the problem, \nin which the register allocation problem is abstracted as graph coloring. In graph coloring, a node represents \na live range that appears in the program, and an edge represents the interference between live ranges \nthat are connected by the edge. Live ranges are considered to be interfering if they are live at the \nsame time. Since, given K colors, the problem of coloring each node is NP-complete [1], Chaitin et al. \ndeveloped a heuristic algorithm shown in Figure 1(a). In Chaitin-style coloring, after renaming all live \nranges and build\u00ading an interference graph in the first two phases, the coalesce phase shrinks two non-interfering \nnodes, if the value of one is a copy of the other. The result of shrinking nodes is iteratively re\u00ad \n(a) (b) Figure 1. Chaitin s allocator and Briggs allocator flected in the interference graph as coalescing \ncontinues. The following simplify phase finds and removes a node with fewer than K neighboring nodes, \nand pushes the node onto the stack. Such a node is called a low-degree node. Removing and pushing is \nrepeated until the graph becomes empty or all the remaining nodes have at least K neighbors. Such a node \nis called a signifi\u00adcant-degree node. If the graph is not empty, a node is removed while marking it spilled, \nand simplification continues. If any node is marked as spilled after simplification, each live range \nassociated with the node is split into smaller live ranges by spilling out the value after its definitions \nand spilling in before its uses, and the process then goes back to the first phase of coloring. This \ncontin\u00adues until simplification empties the graph. The select phase as\u00adsigns colors to the nodes. It \npops a node from the stack, and as\u00adsigns a color distinct from the neighboring nodes. Briggs et al improved \nChaitin's algorithm [3] using the phases shown in Figure 1(b). In their simplify phase, if all the remaining \nnodes have at least K neighbors, the potential spill phase optimis\u00adtically removes a node and pushes \nit onto the stack, and then con\u00adtinues simplification. Later, in the select phase, such nodes are popped \nand an attempt is made to color them. If no color is avail\u00adable for the popped node, the associated live \nrange is split and the phases are tried again as in Chaitin's method. This continues until all nodes \nare colored in the select phase. This approach is called optimistic coloring, and it improves the colorability. \n 3. REGISTER PREFERENCES AND PRIOR APPROACHES As described before, some registers cannot be used symmetrically. \nThat is, in some cases, only specific registers must be used, and in other cases, using some specific \nregisters is preferable. We call this kind of specific register usage a preference. These preferences \ndisrupt the regularity of register allocation. In this section, we first enumerate various preferences, \nthen consider earlier analyses and approaches for solving preference-related problems. 3.1 Register Preferences \nDedicated register usage: The first preference is a dedicated use of certain registers. The most common \ncases are for parameter passing and the return of values. Such values must be placed in specified registers \naccord\u00ading to the calling conventions. Also, in some architectures, spe\u00adcific registers are required \nfor certain operations. For example, multiply, shift, and divide operations in the x86 architecture are \nsuch cases [22]. Limited register usage: The second preference is a use of registers that are not dedicated \nbut functionally limited. In the x86 architecture, quarter-word load/store instructions are only allowed \nfor certain registers, and otherwise a zero-extension is needed. An add operation in IA-64 can use only \na few specific registers for the source operand when adding an immediate value of more than 14 bits. \n Preferred register usage: The third preference is a use of registers that are not limited but merely \npreferred. In general, besides parameter and return regis\u00adters, the architecture or operating system \noften has other types of conventions, which can be also determined by the compiler itself. Distinct use \nof volatile and non-volatile registers is a common example of this preference. To reduce the cost of \nsaving and re\u00adstoring registers over function calls, selecting volatile and non\u00advolatile registers can \nbe an important issue for register allocation. The register allocator should exploit non-volatile registers \nby allocating live ranges that are live across function calls, in order to reduce the caller-side save/restore \ncosts for those live ranges. Also, it is better to allocate live ranges that are not live across function \ncalls to volatile registers to use fewer non-volatile registers, in order to reduce the callee-side save/restore \ncosts (i.e. to reduce saving and restoring non-volatile registers at the procedure entry and exits). \n Dependent register usage: The fourth preference is a use of registers to allocate live ranges based \non other registers already used by other live ranges. A typi\u00adcal example is a register selection for \nlive ranges that can be coa\u00adlesced. If the value of a live range is a copy of another and these live \nranges do not interfere, it is better to allocate one to the same register used by the other. Other cases \nof dependency are from combined operations. In the IA-64 architecture [23], a coupled load instruction \nis available to load two words simultaneously from consecutive addresses. It requires two destination \nregisters, the number of one of which is odd and the other even (the condi\u00adtion varies when using register \nrotation). In the load operation in the S/390 architecture [24], multiple load instructions require sequential \ndestination registers. Multiple stores are also allowed under the same conditions. In the Power architecture \n[25], a cou\u00adpled load instruction can also be used if the two destination regis\u00adters are in sequence. \nThis list is not exhaustive. There are many kinds of preferences for various purposes. However, as long \nas preferences are de\u00adscribed as relations among live ranges and registers, they can be handled by our \nmethod. 3.2 Approaches to Resolve Preferences For the fourth type of preference to allocate live ranges \nto the same register, the technique called register coalescing [2, 3, 6, 7] is a powerful way to honor \nthis preference, and in some cases is also effective for the first type. Register coalescing can eliminate \nmost live-range-to-live-range copies so that coalesced live ranges are allocated to the same registers. \nIn the coalescing phase of Chaitin s allocator, any copy-related nodes [3] are coalesced if they do not \ninterfere with each other. This approach is called ag\u00adgressive coalescing. In terms of colorability, \ncoalescing has both negative and positive aspects. It may make a graph K-colorable because when the nodes \nconnected to a significant-degree node are coalesced, the number of edges of the significant-degree node \ndecreases. On the other hand, it may make a graph non-K\u00adcolorable because the number of edges of the \nnew coalesced node is the union of two nodes. Briggs et al. later described another heuristic algorithm \ncalled conservative coalescing [3]. Conserva\u00adtive coalescing was introduced to avoid coalescing copy-related \nnodes generated by an SSA transformation because coalescing such nodes is harmful for their spill-improving \ntechnique called rematerialization. This method coalesces only when the coalesced node has fewer than \nK significant-degree neighbors. This can avoid the negative aspect of coalescing but may miss chances \nfor more coalescing that improves the colorability. This can be com\u00adpensated by optimistic simplification \nand biased coloring. In bi\u00adased coloring, the coalescing phase marks two nodes that are coa\u00adlescing candidates \nbut not coalesced. It connects them using an\u00adother kind of edge to indicate that the connected nodes \nare copy\u00adrelated. Later in the select phase, if nodes are connected by such an edge, it tries to allocate \nthem to the same color. That is, a de\u00adferred coalescence is attempted. (a) (b) Figure 2. Iterated coalescing \nand optimistic coalescing Recently, new approaches have been proposed to increase the chance of coalescing \nwithout increasing the number of spilled nodes. Iterated coalescing by George and Appel [6], as shown \nin Figure 2(a), iterates conservative coalescing during simplification. Its simplify phase removes only \nnon-copy-related nodes. If simpli\u00adfication is blocked, it goes to the coalesce phase in which coalesc\u00ading \nis done in a conservative manner. If any two nodes are coa\u00adlesced, it returns to the simplify phase. \nOtherwise one low-degree copy-related node is marked as non-copy-related and simplifica\u00adtion continues. \nThis process is called a freeze. If there is no freez\u00adable node, it continues simplification using optimistic \nnode re\u00admoval. Their work successfully improved Briggs-style coalescing. However, Park and Moon reasoned \nthat iterated coalescing still misses many chances of coalescing, and may produce a lot of spill code \nbecause of not exploiting the positive aspect of coalescing [7]. They first try optimistically aggressive \ncoalescing and undo it later if necessary. Their method is called optimistic coalescing with the phases \nshown in Figure 2(b). If a coalesced node is marked to be spilled in the select phase, the undo coalesce \nphase tries to split the coalesced node to see if the split nodes can be allocated, and then continues \nselection. In the best case, each split node is colorable. However, using two colors for them affects \nthe Figure 3. Call-cost directed register allocation colorability of the rest of nodes in the stack. \nThis gives a color for only one node, and the other is inserted at the bottom of the stack. If one is \ncolorable and the other is not, the other becomes a spilled node. If both are uncolorable, both are spilled. \nIf all registers of the processor can be used symmetrically, register allocation is only concerned with \nminimizing both the spill code and register-to-register copies, and these elaborate coalescing techniques \nwork quite well. However, for the preferences that disrupt the regularity of register allocation, we \nneed something more to obtain optimal register allocation. For the first type of preferences, coalescing \ntechniques can be used, too. The register allocator can utilize nodes that represent physical registers \nor pre-colored nodes. These nodes can be coa\u00adlesced with other nodes in the usual manner. However, this \nkind of coalescing has a problem. For the second and third preference types, coalescing cannot contribute \nmuch. The details will be described in the next section. For the third type of preferences, Lueh and \nGross developed an effective technique [8] called call-cost directed register allocation, whose phases \nare shown in Figure 3. This is the first systematic approach to introduce the third type of preferences \nto Chaitin\u00adstyle graph coloring. They focused on exploiting the usage of volatile and non-volatile registers. \nTo make the right decision in selecting registers (or not selecting a register i.e. spilling), they devised \ntwo evaluation functions to calculate the benefit of using volatile and non-volatile registers, respectively. \nFor each live range, the benefit is obtained by comparing the cost when the live range resides in such \na register with the cost when residing in memory. Using such functions, the select phase chooses the \nright storage for live ranges. However, Chaitin-style simplification ignores preferences in making the \nselection order, and thus they introduced benefit-driven simplification, in which the lowest\u00adpriority \nnode is pushed onto the stack first so that higher-priority nodes are popped earlier. The priority for \neach node is obtained by combining the evaluation functions. Since this still does not guarantee that \nhigher-priority-nodes are allocated to preferred registers, they try to control the selection of registers \nprior to the select phase. This is called the preference decision. In the prefer\u00adence decision phase, \nfor each function call, the system detects the live ranges that are live across the call and then chooses \nthe most important R ones among them, where R is the number of non\u00advolatile registers. The rest are annotated \nthat they prefer volatile registers even if the evaluation functions suggest that using non\u00advolatile \nregisters is better than using volatile registers. By doing this, less important nodes popped earlier \nare not allocated to non\u00advolatile registers. As to coalescing, they just mentioned that their algorithm \nis based on Chaitin-style coloring, and thus we assume it is done in an aggressive manner as shown in \nFigure 3. They also described how their approach to optimistic coloring produced an inferior result to \ntheir improved version of Chaitin\u00adstyle coloring. Optimistic coloring gives more chances to live ranges \nbut it sometimes allocates live ranges that prefer to reside in memory to volatile registers, which leads \nto a higher overhead. We have described improved Chaitin-style approaches to resolve the preferences. \nOther approaches that are not based on Chaitin\u00adstyle coloring will be considered in Section 7.  4. PROBLEMS \nFirst, we examine the applicability of register coalescing to other types of preferences besides the \nfourth type. As previously men\u00adtioned, it is applicable to the first type of preferences. To honor the \nsecond type of preferences, coalescing by introducing pre\u00adcolored nodes is possible but not desirable. \nFor the first type, a pre-allocated color is uniquely decided. However, for the second type, a color \nfor pre-allocation must be chosen from many possi\u00adbilities. It is actually a difficult problem to choose \nsuitable regis\u00adters for several pre-allocation candidates. For the same reason, coalescing with a physical \nregister node is difficult. For the third preference type, applying coalescing is not a good approach \nbe\u00adcause this type of preference is not an actual limitation. A node that prefers non-volatile registers \ncan be allocated to volatile reg\u00adisters. This is, in many cases, better than spilling the node. There \nis no good reason to pre-determine a physical register for honor\u00ading the third type of preference. Besides \nthese applicability problems of coalescing, there are prob\u00adlems when coalescing is unaware of the existence \nof preferences, as shown in the following examples. A B C DE ... preference to non-volatile registers \nFigure 4. A form of possibly undesirable coalescing Figure 4 shows live ranges, in which the live ranges \nA, C, D, E are interfering but not to a significant degree, and B, C, D, E all have preferences to be \nallocated to non-volatile registers, and A and B are copy-related. In this case, A and B are coalesced, \neven in a conservative approach. If A and B are coalesced, the coa\u00adlesced live range AB should have a \npreference for non-volatile registers. This is because if AB is allocated to a volatile register, B suffers \nfrom the cost of caller-side saving. However, the simulta\u00adneously live ranges that have preferences for \nnon-volatile registers may then outnumber non-volatile registers. If this happens, the code quality is \ndegraded. v1 = [v0] v2 = [v0+8] v1 = ... call (taking arg0, arg1, ..) farg0 = v1 farg1 = ... farg0 = \nv1 farg2 = v2 call (taking farg0, farg1, farg2, ..) (a) (b) Figure 5. More forms of possibly undesirable \ncoalescing Figure 5(a) shows an example of missing a chance to issue a pow\u00aderful instruction caused by \nreckless coalescing. In this case, we could use a paired load. However, in the IA-64 architecture, a \npaired load requires two destination registers of different parity. If v1 and v2 have been coalesced \nwith arg0 and arg2, respectively, the paired load cannot be used here. Figure 5(b) shows a case, where \ncoalescing is influenced by a spill decision and register selection. In this case, v1 and farg0 can be \ncoalesced. However the benefit of coalescing varies depending on other aspects. The actual best approach \nin this case is not to coalesce them and allo\u00adcate v1 to a non-volatile register. If there is no non-volatile \nregis\u00adter for v1, and if v1 prefers memory to a volatile register, the best approach is not coalescing \nthem and spilling v1. Otherwise, coa\u00adlescing them gives a good result. Coalescing should take account \nof the state of other register allocation actions. preference to non-volatie registers  A = B C0 = ret \n T = C0 T = C1 C2 = T arg0 = A arg0 = A ret = C2 (a) (b) Figure 6. Another form of possibly undesirable \ncoalescing Figure 6 shows an example, in which the optimal coalescence order depends on the preferences. \nIn the figure, B and C1 prefer non-volatile registers, and any touching live ranges can be coa\u00adlesced. \nIn Figure 6(a), it is better to coalesce A and arg0. If A and B are coalesced, two copies are likely \nto remain because AB pre\u00adfers a non-volatile register. In Figure 6(b), it is better to coalesce C0, C2, \nT, and ret. Coalescing C1 and T only allows coalescing C0, C2, and ret, in which case two copies remain. \nWe now examine the applicability of call-cost directed register allocation by Lueh and Gross. They only \nmentioned a way to ex\u00adploit volatile and non-volatile registers, which we categorize in our third type \nof preference. We think, with a slight modification, their select phase can be used for other types of \npreferences. Be\u00adlow we show our similar register selection process. However when dealing with a combination \nof various types of preferences, their technique to create a preference-aware order of register se\u00adlections \nmay fail. This is because their evaluation of the prefer\u00adences is register-selection independent, a static \nanalysis. While sufficient for use with a simple preference model, it can only give good performance \nfor choosing a register from a couple of register classes. When preferences are combined, as in the examples \nshown in Figures 4-6, the decision of the best register for a live range is influenced by the state of \nspilling, by coalescing, and by prior register selections. This means another approach to manage the \nselection order is needed.  5. PREFERENCE-DIRECTED GRAPH COLORING We mentioned that register allocation \nactions such as register selection, spilling, and coalescing must take the preferences into account. \nExisting coalescing techniques cannot honor all types of preferences. Even for applicable cases, it was \nshown that prefer\u00adence-independent coalescing could be harmful. To handle these problems, we attempt \nall preference-resolving actions during the select phase. A germ of our approach can be seen in the biased \ncoloring introduced by Briggs [3]. Like this approach, we express live-range-to-live-range preferences \nas a graph, which can include copy-relatedness, and reflect such preferences during the select phase. \nWe also honor live-range-to\u00adphysical-register preferences during the select phase, whose func\u00adtionality \nis similar to Lueh and Gross [8]. The graph where the preferences are recorded is called a Register Preference \nGraph, as described in Section 5.1. George and Appel stated in their paper that the success of biased \ncolor selection is based on chance [6]. Our major concern is then with creating more chances for live \nranges to be allocated to the preferred registers. Lueh and Gross introduced benefit-driven simplification \nand the preference decision. However their static approach only works for certain preferences. To effectively \nin\u00adcrease the chances for desirable register selections, we try to relax the total order created by simplification. \nActually, we construct a partial order from the result of simplification of the interference graph. Any \ntopologically-sorted order from the partial order pre\u00adserves its colorability. Here, we don t take an \napproach that does not benefit from Chaitin-style simplification to keep more live ranges packed into \nregisters. The partial order preserving colora\u00adbility is expressed as a graph, which we call a Coloring \nPrece\u00addence Graph. Using the Register Preference Graph and Coloring Precedence Graph, we do a preference-directed \nand chance\u00admaximized register selection. Construction of the Coloring Prece\u00addence Graph, and the actual \nregister selection algorithm will be described in Sections 5.2 and 5.3, respectively. Our full-featured \ncoloring system will be described in Section 5.4. v0v1 v2v3 v4 arg0 i0: v0 = [arg0] i1: L1: v1 = [v0] \ni2: v2 = [v0+4] i3: v3 = v0 i4: v4 = v1 + v2 i5: arg0 = v3 i6: call i7: v0 = v4+1 i8: if v0 != 0 goto \nL1 i9: ret (a) stack v0 v4 v1 v2 v3 (d) (e)  vol:50, n-vol:48 coalesce sequential + sequential \u00ad \n  prefers vol:50, n-vol:48  (b) vol:40, n-vol:38 r1 = [r1] L1: r2,r3 = [r1] r3 = r2 + r3 call r1: \narg0, return, volatile r1 = r3 +1 r2: arg1, volatile if r1 != 0 goto L1 r3: non-volatile ret  (f) (g) \n(h) Figure 7. Sample code (a), interference graph (b), Register Preference Graph (c), a possible stack \nafter simplification (K=3) (d), Coloring Precedence Graphs (e) (K=3), (f) (K>=4), the result of assignment \n(g), and final code (h) 5.1 Register Preference Graph Our Register Preference Graph (RPG) is a directed \ngraph, in which a node represents a live range, a register, or a register class, while an edge represents \na preference. As long as a preference can be expressed as a relation between two nodes, it can be described. \nTo prioritize preferences, we weight each preference according to the benefit of honoring it. Our metric \nfor evaluating the benefit is derived from the method of Lueh and Gross [8]. The preference benefit for \na node is defined as an estimated performance differen\u00adtial between when the preference is honored and \nwhen the node is located in memory. The benefit is also weighted by the execution frequency, which can \nbe obtained using profiles if available, oth\u00aderwise by heuristics based on program structure. Figure \n7 shows an example of a RPG. Here, Figure 7(a) shows the target of register allocation, Figure 7(b) shows \nthe interference graph, and Figure 7(c) shows a RPG. This graph has four prefer\u00adence types: coalesce, \nsequential+, sequential-, and prefers. Coa\u00adlesce means it tries to use the same register as the one in \nthe desti\u00adnation node. Sequential+ means it tries to use the previous register relative to the one in \nthe destination node, while sequential\u00admeans it tries to use the next register. Prefers means it tries \nto use one of the registers included in the destination node. Each edge in the graph is weighted by the \nstrength of the preference. For exam\u00adple, the strength of the preference of v4 for a non-volatile register \nis 28. Strengths evaluation functions can have a parameter. The node v3 has a coalesce edge to v0, with \nstrength 40 when coalesc\u00ading to a volatile register, but 38 for a non-volatile register. These numbers \nare obtained by the following method: Str(V, P) = Mem_Cost(V) Ideal_Cost(V, P) Here, Str(V, P) gives \nstrength for a variable V when honoring a preference P, obtained by Mem_Cost(V) Ideal_Cost(V, P), the \noperation cost when spilling V and one when successfully resolv\u00ading P for V, respectively. These costs \ncan be calculated by esti\u00admating operation cycles when the variable resides in memory or the variable \nis allocated to the preferred register. The details of such calculations are described in the Appendix. \n 5.2 Coloring Precedence Graph A Coloring Precedence Graph (CPG) is a directed graph, in which a node \nrepresents a live range while an edge represents the prece\u00addence of register selection between the nodes \nthat are connected by the edge. Nodes also include the nodes for the top and bottom of the partial order. \nTo obtain a CPG from a result of simplifica\u00adtion, we try to detect orderings between pairs of nodes, \nsuch that removing one enables the other s removal. Here is the algorithm to create a CPG that examines \nthe accrued removability of nodes from the interference graph when removing a node: 1. Set the stack \nRS to be the reverse of the simplification stack. 2. Set the working interference graph (WIG) to the \noriginal interference graph, but from which the physical register nodes have been removed. 3. Create \nthe top and bottom nodes for the CPG. 4. Find each low-degree node in the WIG, create a new node in \nthe CPG associated with the node, add an edge from it to the bottom node, and mark it ready. Then find \neach spilled node, and do the same without marking it ready. 5. If RS is empty, halt. Otherwise, pop \na node from RS, and remove the corresponding node from WIG. Then find the corresponding node N in the \nCPG. This algorithm guarantees N will be successfully found. 6. Find nodes in WIG that are not yet removed \nand which were adjacent to the node popped in Step 5. For each such node,  create a new node in the \nCPG if the corresponding node has not been added to the CPG. 7. Among the nodes found in Step 6, find \nany nodes that are not ready. Add an edge from such non-ready nodes to N. If this makes some edges transitive, \nremove those transitive edges. If there are no such non-ready nodes, add an edge from the top node to \nN. 8. If a node in the WIG is now a low-degree node because of the removal of the popped node, mark \nthe corresponding node in the CPG ready. 9. Return to Step 5.  Here we show an example of making a \nCPG. Figure 7(d) shows a possible stack after simplification assuming three colors. The RS is [v3, v2, \nv1, v4, v0]. After creating the top and bottom nodes in the CPG, create v0 and v4 as ready nodes and \nmake them point to the bottom because they are low-degree. We then pop v0, remove it from the WIG, create \nneighboring v1 and v2 in the CPG. Be\u00adcause neither v1 nor v2 is ready, let them point to v0. Removal \nof v0 from the WIG now marks v1 and v2 ready because the removal makes v1 and v2 low-degree. The following \npop of v4 creates v3 in the CPG with an edge pointing to v4. The node v3 is then marked ready because \nremoving v4 makes v3 removable. When popping v1 next, remaining and neighboring v2 and v3 are al\u00adready \non the CPG. We make v1 be pointed from the top because v2 and v3 are ready. In a similar way, while popping \nv2 and v3, each does not have non-ready nodes, so make them be pointed from the top. Figure 7(e) shows \nthe result. For reference, we also show a CPG for more than three colors in Figure 7(f). 5.3 Register \nSelection This section describes our integrated register selection algorithm using the RPG and CPG. In \nthis paper, we tried a simple algo\u00adrithm that iterates finding ready-to-go nodes using the CPG, and choosing \nthe best node using the RPG. Trying a greedy preference resolution before or during a register selection \nalgorithm could be beneficial but are remained for further research. Our algorithm is as follows: 1. \nSet the queue Q to be the successors of the top node of the Coloring Precedence Graph. 2. For all nodes \nin Q, do Steps 2.1 to 2.3 to find honorable preferences. If Q is empty, terminate the algorithm.  2.1 \nDetect preferences for the node by referring to the RPG, and eliminate preferences that cannot be honored \nbecause of prior register selections. 2.2 Among the remaining preferences, remove live-range-to\u00adlive-range \npreferences whose destination nodes are not allocated to registers yet. 2.3 Among remaining preferences, \nfind the strongest and weakest. 3. Choose the node that has the largest strength differential between \nthe preferences found in 2.3  4. For the node chosen in 3, do Steps 4.1 to 4.4 to find a suit\u00adable register. \n4.1 Add the chosen node to the interference graph and find available registers that are not used by neighbors. \nIf there is no register available, the node is spilled. 4.2 For the registers chosen in 4.1, try honoring \nthe prefer\u00adences chosen in 2.2 from strongest to weakest. Honoring a preference screens registers and \nweaker preferences are at\u00adtempted for the remaining registers. 4.3 For the remaining registers, considering \nthe live-range-to\u00adlive-range preferences eliminated in 2.2 to be resolved, remove registers that prevent \nhonoring those preferences. 4.4 Allocate the chosen node to one of the remaining registers. 5. Remove \nedges from the chosen node to its successors. If this creates a successor with no predecessor, add the \nsuccessor to Q. 6. Return to Step 2.  Figure 7(g) shows the register-selected interference graph with \nthree registers, with the convention that r1 is the first argument and return register, r2 is the second \nargument register, and r1 and r2 are volatile registers while r3 is non-volatile. For the CPG in Figure \n7(e), v1, v2, and v3 are initially included in Q. For the preferences of nodes in Q, after eliminating \nsome according to Steps 2.1 and 2.2, v3 is chosen because it has the largest strength differential between \nthe remaining preferences. The node v3 is then added to the interference graph and allocated to r1 because \nv3 prefers arg0, i.e. r1. Consequently v4 is added to Q by Step 5 and next allocated to r3 because v4 \nhas a honorable and strongest preference for the non-volatile register, r3. Then v1 and v2 have the same \npriority for allocation. In this case, v1 is assumed to go first and is added to the interference graph. \nOnly registers r2 and r3 are available for v1, and r2 is chosen because of the sequen\u00adtial+ preference \nof v2 that will be honored later. After allocating v2 to r3, v0 is added to Q. The node v0 is then allocated \nto r1, since that is a unique register distinct from v0 s neighbors in the interference graph. Finally, \nwe show the register-allocated code in Figure 7(h), in which the preferences are properly reflected. \n 5.4 Coloring System Figure 8 shows the phases of our register allocation. After renam\u00ading the live ranges, \nwe construct a RPG and an interference graph. We then do optimistic simplification. Using the result \nof simplifi\u00adcation, we construct a CPG. Finally, we perform the integrated register selection, including \nspilling and resolving the preferences of all types. For our coloring system, we use optimistic simplification \nand register selection, allowing the spill decisions and preference\u00addirected register selections to reflect \neach other s state. Regarding the drawback of optimistic simplification described by Lueh and Gross, \nour coloring avoids this problem by actively spilling a node whose strongest preference is for being \nlocated in memory. We also sacrifice the positive aspect of coalescing to improve the colorability. However \noptimistic simplification can compensate for this. The experiments below show that optimistic simplifica\u00ad \nbuild tion and our deferred coalescing and spilling give comparable results.  6. EXPERIMENTAL RESULTS \nThis section describes the effectiveness of our coloring system. All numbers were obtained on an IBM \nIntelliStation Mpro (Intel Itanium 800 MHz uniprocessor with 2 GB memory). We used a product candidate \nof the IBM Developers Kit for IA-64, Java [14] Technology Edition, Version 1.3, running on Windows . \nWe implemented the coloring algorithm in the register allocator of our just-in-time compiler, as well \nas using other approaches for comparison. After performing many advanced optimizations [9], the SSA-transformed \nintermediate code reaches our register allo\u00adcator. In Section 6.1, we first examine the coalescing capability \nof our algorithm by comparing the coalescing and spilling results with those of the other approaches. \nAfter showing the importance of considering the preferences in Section 6.2, we then evaluate the effectiveness \nof honoring preferences in Section 6.3. In our meas\u00adurements, we considered three register usage models, \nnamely a high-pressure model, middle-pressure model, and low-pressure model, which use 16, 24, and 32 \nregisters, respectively. 6.1 Coalescing Capability In this section, we try to verify that our partial-order-based \nap\u00adproach gives good results of coalescing. Even when our algorithm only reflects preferences for coalescence, \nit is supposed to give a quality in spilling and coalescing comparable to the other ap\u00adproaches. Here, \nwe chose the high- and low-pressure register us\u00adage models to expose peculiar behaviors of the algorithms. \nThe results of coalescing and spilling for two such evaluation condi\u00adtions are shown in Figure 9. In \nFigure 9(a), we show the ratio of the number of eliminated move instructions by coalescing compared to \nthe base algorithm when using 16 registers (both for integer and floating-point val\u00adues). Figure 9(b) \nshows the ratios of the number of generated spill instructions to the base results, using 16 registers. \nWe also show the results with 32 registers, and the ratios of coalescing and spill\u00ading are shown in Figure \n9(c) and Figure 9(d), respectively. Regis\u00adter usage details will be described in Section 6.2 because \nthe de\u00adscription is not short and the conventions do not affect the results here. For the base algorithm, \nwe used Chaitin-style coloring with aggressive coalescing. The numbers were collected using tests in \nSPECjvm98 [15], an industry standard benchmark for Java. Among those programs, we show floating-point \nresults only for the mpegaudio and mtrt tests here (labeled as mpegaudio fp and mtrt fp ) because the \nother floating-point numbers were too small to compare. The other numbers in the figures show integer \nresults. Besides our algorithm, we show results using optimistic coalescing by Park and Moon (denoted \nas optimistic ), the best approach to date, and using Briggs-style coloring with only ag\u00adgressive coalescing \n(denoted as Briggs +aggressive ), regarded  Figure 9. Ratio of eliminated moves by coalescing using \n16 registers (a), 32 registers (c), and ratio of generated spill code us\u00ading 16 registers (b), 32 registers \n(d) 0 10 20 30 40 50 60 70 Time in secs compress jess db javac mpegaudio only coalecsing mtrt optimistic \njack geo. full preferences (a) 0 10 20 30 40 50 60 70 Time in secs compress jess db javac mpegaudio \nonly coalecsing mtrt optimistic jack geo. full preferences (b)  as the second best in their paper. For \nall algorithms, we used the same heuristics based on the metric in Section 5.1 to decide the spill candidate. \nThe numbers in Figure 9 show that all approaches successfully eliminated move instructions by coalescing \nwhile suppressing the generation of spill code. For 16 registers, they removed more than 90% of move \ninstructions, and a few percent more for 32 registers. They were also very good at reducing spill instructions. \nThey suppressed the number of spill instructions by around 30% com\u00adpared to Chaitin s when using 16 registers. \nIt is noteworthy that all algorithms eliminated about 90% of the spill instructions when using 32 registers. \nThe spill instructions for floating-values in the mpegaudio and mtrt tests are completely eliminated \nand the re\u00adsults of coalescing were very good. Generally looking at the re\u00adsults in these figures, we \ncan conclude that our approach achieves good coalescing. Compared to the other two approaches, ours is \nbest at reducing spill cost. Regarding the elimination of moves by coalescing, we are 1.2% better than \noptimistic coalescing in the 16-register case, and 3.8% worse in the 32-register case. The reason for \nthe better suppression of spill code is that our algorithm is register\u00adselection-sensitive so that the \ncoalescing rarely causes spills. In optimistic coalescing, in a few cases, it seems that their combina\u00adtion \nof aggressive coalescing and undoing leads to a non-optimal register selection order, resulting in some \nlive ranges that have to be spilled. The reason for our worse result in coalescing when using more registers \nis that sometimes a number of nodes are coa\u00adlesced into one, and aggressive coalescing can greedily coalesce \nthem. In the degree-increasing cases, such fat nodes are spill\u00adcausing when using fewer registers but \noffer a good coalescing result when using more registers. Our coalescing is done one by one, and thus \nwe can miss some opportunities to coalesce such nodes. To improve coalescence, a technique to aggressively \ncoa\u00adlesce non spill-causing nodes could be added to the algorithm in Section 5.3.  6.2 Preference Impacts \nWe have reached the conclusion that our algorithm has high coa\u00adlescing capability, but we did not show \nthe run-time performance numbers. This is because those approaches in Section 6.1 are not considering \nirregular register usages. Only by exploiting the vola\u00adtile and non-volatile registers can we greatly \ninfluence the per\u00adformance. This section analyzes the execution performance of SPECjvm98 to show the \nimpact of honoring the preferences for utilizing the irregular registers. We use all register usage models \nto see the tendency when increasing the register pressure. The results are shown in Figure 10. All numbers \nare the elapsed time for executing the tests. We conventionally omit the results of the check test because \nit does not run for enough long to compare the elapsed times. The results of the other tests when using \n16 registers, 24 registers, and 32 registers are shown in Figure 10(a), (b), and (c), respectively. In \nthese measurements, we used half of the registers as volatile registers, while the other half are used \nas non-volatile. We used up to eight floating-point volatile registers for parameter passing, and one \nof them is used for returning val\u00adues. The integer registers in IA-64 consist of global, input, local, \nand output registers. The last three are dynamically allocated as stack registers. We used the local \nand up to eight input registers as non-volatile registers as well as the registers for input parameters. \nThe global and up to eight output registers are also used as vola\u00adtile registers as well as the registers \nfor output parameters. A global register is dedicated for returning values. If a compiled method requires \nat least eight input and output parameters, and returns a value, we have to use 17 registers. In fact, \nour results with 16 registers include such a case, but we ignored this because the case rarely occurs. \nWe first compared the three algorithms. The first is our algorithm only doing coalescing (labeled as \nonly coalescing ). The second is optimistic coalescing. The third and last is our full-featured coloring \nreflecting various kinds of preferences in the IA-64 architecture, which is labeled as full preference. \nIn these meas\u00adurements, these include preferences for coalescing, enabling paired loads, using the parameter \nand return registers, and exploit\u00ading the volatile and non-volatile registers. The first two algorithms \ncan also utilize dedicated registers by register-to-live-range coa\u00adlescing, but in a way that ignores \nthe existence of the other prefer\u00adences. For selection of volatile and non-volatile registers, these \ntwo algorithm used a simple heuristic to use non-volatile registers first, then volatile registers, based \non the assumption they should not do any preference-aware register selection. Paired loads for those \ntwo algorithms are issued only when the code generator comes to find paired load candidates with destination \nregisters of different parity.  The numbers in Figure 10 show the importance of honoring the preferences \nas well as considering coalescing and spilling. The results of the full-featured algorithm are much better \nthan those of the first two. Furthermore, some tests are even degraded by in\u00adcreasing the available registers. \nSuch tendencies can be seen ex\u00adcept for the compress and mpegaudio tests, and most clearly in the jess, \ndb, javac, and jack tests. Considering that those tests make frequent function calls, the poor performance \nis thought to be due to the poor selection of volatile and non-volatile registers or use\u00adless copying \nof parameters and return values. Because increasing the number of registers should improve the performance \nof the parameter handling and returns of values, the major cause of poor performance would seem to be \nineffective use of the volatile and non-volatile registers. The other factors affecting the performance \ninclude preference-unaware coalescing that disturbs the dedicated or limited usage of registers. The \ninfluences of such preference\u00adunaware coalescing will be examined later. In this section, it suf\u00adfices \nto note that honoring the preferences for exploiting the ir\u00adregular registers has a large impact on performance. \n 6.3 Performance Evaluation We have shown the importance of utilizing the irregular registers effectively. \nThe impact of the effective usage of volatile and non\u00advolatile registers was especially large. For exploiting \nsuch regis\u00adters, the call-cost directed coloring by Lueh and Gross is an effec\u00adtive approach. The major \ndifference between call-cost directed coloring and our algorithm is that their approach independently \ntries coalescing and call-cost driven register selection, while our integrated approach tries such register \nallocation actions simulta\u00adneously using the RPG and CPG. To examine the effectiveness of our integrated \napproach, we prepared another algorithm by modi\u00adfying ours to perform Chaitin-style aggressive coalescing \nwith non-optimistic simplification and register selection, and consid\u00adered only preferences for allocating \nlive ranges to volatile or non\u00advolatile registers (or to spill them). Actually, by doing so, the behavior \nof our algorithm is close to that of call-cost directed coloring. Our selection of volatile and non-volatile \nregisters is at least as good as theirs using benefit-driven simplification. As to their preference decision, \nwe don t do this. However, our algo\u00adrithm should find an order that effectively exploits non-volatile \nregisters. If a less important live range was consequently given a non-volatile register before processing \nmore important live ranges, this order should be necessary to keep colorability. In this measurement, \nwe used the middle-pressure register usage model, because our focus is on the integration of several \nregister allocation actions, and because the influence of spilling is rather large or small for the other \nregister usage models. Figure 11 shows the relative elapsed times of the SPECjvm98 tests com\u00adpared to \nthe times when using our full-featured coloring. In this measurement, 24 registers are used with the \nsame register usage conventions as described in Section 6.2. The figure shows the results from the three \ncoalescing-only approaches already men\u00adtioned, an approach that performs aggressive coalescing and a \nmodified call-cost directed register selection (labeled as aggres\u00adsive+volatility ), and ours. As expected, \nthe three coalescing-only approaches show worse performance, but this is not a definitive conclusion \nbecause those algorithms make no real effort to select volatile and non-volatile registers well. However \nwe can still make a comparison among those three. Compared to optimistic coalescing and Briggs color\u00ading \nwith aggressive coalescing, our partial-order-based approach shows better results. This can be attributed \nto our adaptive coa\u00adlescing that effectively suppresses spill code and exploits the pa\u00adrameter and return \nregisters. Comparing aggressive+volatility and full preferences , i.e. ours, our results are better in \nfour tests, comparable in two tests, and worse in one. In the best case of the jess test, our algorithm \noffers a 16% improvement. The major reason for better results is that there are often cases where the \nregister-selection-independent coalescing disturbs the optimal usage of volatile and non-volatile registers, \nand our algorithm can avoid this. The other factors are our effective exploitation of the dedicated registers \nand the use of paired loads. Maximizing the chances of issuing paired loads is thought to contribute \nto the better performance of the mpegaudio test. In the worst case of the db test, our algorithm is 4% \nworse. This is a case in which our simple register selection misses some opportunities for aggressive \ncoalescing but does not impede pref\u00aderence resolution especially for exploiting volatile and non\u00advolatile \nregisters. However, it can be seen that our approach offers superior results in most cases.  7. RELATED \nWORK Priority-based coloring by Chow and Hennessy [4] established another approach to coloring-based \nregister allocation besides Chaitin s. Lueh and Gross concisely described the difference be\u00adtween Chaitin-style \ncoloring and priority-based coloring as lying in the policy of choosing the order of register assignment: \nthe former favors packing live ranges while the latter favors allocating more live ranges with higher \npriority though that may use more colors. Therefore, priority-based coloring probably uses more registers \nthan Chaitin s approach. This may lead to a loss of per\u00adformance because of spilling, and still be problematic \neven with\u00adout spilling if the register file is implemented as a stack, like the local general registers \nof IA-64. For such an architecture, using fewer registers is important to avoid the high cost of saving \nand restoring registers to and from the backing store [13]. The ap\u00adproach of Lueh and Gross successfully \nintroduced a priority\u00adaware ordering for Chaitin-style coloring. Our method offers a more integrated \nway of managing the order. Very different approaches have been taken in the last few years by using integer \nprogramming [10, 11, 12]. Goodwin and Wilken introduced a register allocation technique based on integer \npro\u00adgramming [10], which leads to the optimal combination of possi\u00adble register allocation actions. Kong \nand Wilken then extended their technique to handle irregular-register architectures [11]. The work by \nAppel and George proposed a two-phase approach for the architectures with a small set of registers [12]. \nThey use integer programming for deciding the optimal placement of spill code, followed by Chaitin-style \ngraph coloring with coalescing, but without spills. This reduced the compilation time and generated good \ncode. In an environment with a small set of registers, the register allocation problem becomes more complicated, \nand such approaches work very well. However integer programming seems still costly. We believe we can \nextend our algorithm for those cases with comparable results and much less compilation time. 8. CONCLUSIONS \nThis paper described a new framework of register allocation based on Chaitin-style coloring. First we \ndeveloped an algorithm to obtain a partial order of register selection from the result of the graph simplification. \nThe partial order helps find a mostly optimal order of register selection that reflects several requirements \nfor register allocation. We called it a Coloring Precedence Graph (CPG). We then introduced a graph representation, \ncalled a Regis\u00adter Preference Graph (RPG), to describe the register allocation requirements including \ncoalescing and the effective usage of ir\u00adregular registers. We finally showed an algorithm to select \nregis\u00adters using both the RPG and CPG that can meet a variety of regis\u00adter allocation requirements simultaneously. \nThe experimental results confirmed that our algorithm offers good allocation results compared to the \nexisting approaches. Some cases however remain, in which a greedy algorithm to resolve preference gives \nbetter results. We are working on a heuristic algorithm to manipulate the RPG and CPG for a register \nselection order that allows aggressive preference resolutions. 9. ACKNOWLEDGEMENTS We are grateful to \nthe people in Network Computing Platform at Tokyo Research Laboratory engaged in the development of the \nJIT compiler. We also thank to Tamiya Onodera, Takeshi Ogasa\u00adwara, and Kiyokuni Kawachiya for helpful \ndiscussions and com\u00adments on the earlier versions of this paper. Technical advice from Mikio Takeuchi, \nToshio Suganuma, Kazuaki Ishizaki, and Osamu Gohda on architecture-specific topics, and from Tatsushi \nInagaki on SSA forms was also helpful. Finally, we appreciate the careful work in editorial assistance \nby Shannon Jacobs. 10. REFERENCES [1] R. Sethi. Complete register allocation problems. SIAM Jour\u00adnal \non Computing, 4(3): 226-248, 1975 [2] G.J. Chaitin. Register allocation and spilling via graph color\u00ading. \nIn Proceedings of the ACM SIGPLAN 1982 Symposiumon Compiler Construction, pages 201-207, 1982. [3] P. \nBriggs, K.D. Cooper, and L. Torczon. Improvements to graph coloring register allocation. ACM TOPLAS, \n16(3): 428-455, 1994. [4] F.C. Chow and J.L. Hennessy. The priority-based coloringapproach to register \nallocation. ACM TOPLAS, 12(4): 501\u00ad536, 1990. [5] R. Cytron, J. Ferrante, B.K. Rosen, M.N. Wegman, and \nF.K.Zadeck. Efficiently computing static single assignment formand the control dependence graph. ACM \nTOPLAS, 13(4): 451-490, 1991. [6] L. George and A.W. Appel. Iterated register coalescing.ACM TOPLAS, \n18(3): 300-324, 1996. [7] J. Park and S.-M. Moon. Optimistic register coalescing. In Pro\u00adceedings of \nthe 1998 International Conference on Parallel Archi\u00adtecture and Compilation Techniques, pages 196-204, \n1998. [8] G. Lueh and T. Gross. Call-cost directed register allocation. InProceedings of the ACM SIGPLAN \n1997 Conference on Pro\u00adgramming Language Design and Implementation, pages 296\u00ad307, 1997. [9] K. Ishizaki, \nT. Yasue, M. Takeuchi, T. Ogasawara, T. Su\u00adganuma, T. Onodera, H. Komatsu, and T. Nakatani. Design, implementation, \nand evaluation of optimizations if a just-in\u00adtime compiler. In Proceedings of the ACM 1999 Java GrandeConference, \npages 119-128, 1999. [10] D.W. Goodwin and K.D. Wilken. Optimal and near-optimalglobal register allocation \nusing 0-1 integer programming. Software Practice and Experience, 26(8): 929-965, 1996. [11] T. Kong \nand K.D. Wilken. Precise register allocation for irregular architectures. In Proceedings of the 31st \nInternational Microarchi\u00adtecture Conference, pages 297-307, 1998. [12] A.W. Appel and L. George. Optimal \nspilling for CISC ma\u00adchines with few registers. In Proceedings of the ACM SIG-PLAN Conference on Programming \nLanguage Design and Im\u00adplementation, pages 243-253, 2001. [13] R. Zahir, J. Ross, D. Morris, and D. Hess. \nOS and compiler con\u00adsiderations in the design of the IA-64 architecture. In Proceedings of the 9th International \nConference on Architectural Support ofProgramming Languages and Operating Systems, pages 212-221, 2000. \n[14] J. Gosling, B. Joy, and G. Steele. The Java Language Speci\u00adfication. Addison-Wesley, 1996. [15] \nStandard Performance Evaluation Corporation. SPECjvm98 Benchmarks, http://www.spec.org/osg/jvm98. [16] \nD. Callahan and B. Koblenz. Register allocation via hierarchical graph coloring. In Proceedings of the \nACM SIGPLAN 1991 Conference on Programming Language Design and Implementa\u00adtion, pages 192-203, 1991. \n[17] T.A. Proebsting and C.N. Fischer. Probabilistic register alloca\u00adtion. In Proceedings of the ACM \nSIGPLAN 1992 Conference on Programming Language Design and Implementation, pages 300-310, 1992. [18] \nG. Lueh, T. Gross, and A. Adl-Tabatabai. Global register allocationbased on graph fusion. ACM TOPLAS, \n22(3): 431-470, 2000. [19] P. Bergner, P. Dahl, D. Engebretsen, and M. O Keefe. Spill code minimization \nvia interference region spilling. In Pro\u00adceedings of the ACM SIGPLAN 1997 Conference on Pro\u00adgramming \nLanguage Design and Implementation, pages 287\u00ad295, 1997. [20] S. Kurlander and C. Fisher. Zero-cost range \nsplitting. In Proceedings of the ACM SIGPLAN 1994 Conference on Programming Language Design and Implementation, \npages 257-265, 1994. [21] S.R. Vegdahl. Using node merging to enhance graph color\u00ading. In Proceedings \nof the ACM SIGPLAN 1999 Conference on Programming Language Design and Implementation, pages 150-154, \n1999. [22] Intel Corporation. Pentium processor family developer s manual, volume 3: architecture and \nprogramming manual, 1995 [23] Intel Corporation. Intel Itanium architecture developer s manual, volume \n3: instruction set reference, http://developer.intel.com/design/itanium/manuals. [24] International Business \nMachines. z/Architecture Principles of Operation, 2000. [25] International Business Machines. The PowerPC \narchitecture, Morgan Kaufmann, 1994. APPENDIX: Cost Calculation Details The strength for a variable V \nwhen honoring a preference P Str(V, P) is defined as follows: Str(V, P) = Mem_Cost(V) - Ideal_Cost(V, \nP) The cost when spilling Mem_Cost(V) is defined as follows: Mem_Cost(V) = Spill_Cost(V) + Op_Cost(V) \n The cost of spilling Spill_Cost(V) is defined as follows:  Spill_Cost(V) = S(Load_Cost(Using(V))*Freq_Fact(Using(V))) \n+ Java is a trademark of Sun Microsystems. IA-64 and Itanium are trademarks of Intel Corporation. Windows \nis a registered trade\u00admark of Microsoft Corporation S(Store_Cost(Defining(V))*Freq_Fact(Definig(V))) \n  Using(V) is an instruction using V. S(f(X)) is the summation of f() for each X.  Defining(V) is an \ninstruction defining V.  For each instruction I, Load_Cost(I) is 2, Store_Cost(I) is 1.  Freq_Fact(I) \nis 1 for i0 and i9, otherwise 10. (obtained by loop analysis) The cost of operation Op_Cost(V) is defined \nas follows:  Op_Cost(V) = S(Inst_Cost(Using(V))*Freq_Fact(Using(V))) + S(Inst_Cost(Defining(V))*Freq_Fact(Definig(V))) \n  Inst_Cost(I) is 2 for i0, i1 and i2, undefined for i6, otherwise 1. The cost when honoring the preference \nIdeal_Cost(V) is defined as follows:  Ideal_Cost(V, P) = Call_Cost(V) + Ideal_Op_Cost(V, P) The cost \nover function calls Call_Cost(V) is defined as follows:  Call_Cost(V) = S(Save_Restore_Cost(Call(V))*Freq_Fact(Call(V))) \n:     if V prefers a volatile register    Callee_Save_Cost(V) : if V prefers a non-volatile register \nCall(V) is a call instruction across V. Save_Restore_Cost(I) is always 3. Callee_Save_Cost(V) is always \n2. The operation cost with the preferred register Ideal_Op_Cost(V, P) is as follows:  Ideal_Op_Cost(V, \nP) = S(Ideal_Inst_Cost(Using(V), P)*Freq_Fact(Using(V))) + S(Ideal_Inst_Cost(Defining(V), P)*Freq_Fact(Definig(V))) \n  Ideal_Inst_Cost(I, P) = 0 : if P is sequential+ or sequential- and I is a paired load candidate and \nI loads V or P is coalesce and I is a move and I defines V or I lastly uses V Inst_Cost(I) : otherwise \n  \n\t\t\t", "proc_id": "512529", "abstract": "This paper describes a new framework of register allocation based on Chaitin-style coloring. Our focus is on maximizing the chances for live ranges to be allocated to the most preferred registers while not destroying the colorability obtained by graph simplification. Our coloring algorithm uses a graph representation of preferences called a Register Preference Graph, which helps find a good register selection. We then try to relax the register selection order created by the graph simplification. The relaxed order is defined as a partial order, represented using a graph called a Coloring Precedence Graph. Our algorithm utilizes such a partial order for the register selection instead of using the traditional simplification-driven order so that the chances of honoring the preferences are effectively increased. Experimental results show that our coloring algorithm is powerful to simultaneously handle spill decisions, register coalescing, and preference resolutions.", "authors": [{"name": "Akira Koseki", "author_profile_id": "81100190461", "affiliation": "IBM Tokyo Research Laboratory, Kanagawa-ken 242-8502, Japan", "person_id": "P11827", "email_address": "", "orcid_id": ""}, {"name": "Hideaki Komatsu", "author_profile_id": "81100557247", "affiliation": "IBM Tokyo Research Laboratory, Kanagawa-ken 242-8502, Japan", "person_id": "PP39048455", "email_address": "", "orcid_id": ""}, {"name": "Toshio Nakatani", "author_profile_id": "81100311827", "affiliation": "IBM Tokyo Research Laboratory, Kanagawa-ken 242-8502, Japan", "person_id": "PP14113792", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/512529.512535", "year": "2002", "article_id": "512535", "conference": "PLDI", "title": "Preference-directed graph coloring", "url": "http://dl.acm.org/citation.cfm?id=512535"}