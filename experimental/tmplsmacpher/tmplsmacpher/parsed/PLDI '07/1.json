{"article_publication_date": "06-10-2007", "fulltext": "\n CheckFence: Checking Consistency of Concurrent Data Types on Relaxed Memory Models * Sebastian Burckhardt \nRajeev Alur Milo M. K. Martin University of Pennsylvania University of Pennsylvania University of Pennsylvania \nsburckha@cis.upenn.edu alur@cis.upenn.edu milom@cis.upenn.edu Abstract Concurrency libraries can facilitate \nthe development of multi\u00adthreaded programs by providing concurrent implementations of familiar data types \nsuch as queues or sets. There exist many opti\u00admized algorithms that can achieve superior performance \non mul\u00adtiprocessors by allowing concurrent data accesses without using locks. Unfortunately, such algorithms \ncan harbor subtle concur\u00adrency bugs. Moreover, they require memory ordering fences to function correctly \non relaxed memory models. To address these dif.culties, we propose a veri.cation approach that can exhaustively \ncheck all concurrent executions of a given test program on a relaxed memory model and can verify that \nthey are observationally equivalent to a sequential execution. Our Check-Fence prototype automatically \ntranslates the C implementation code and the test program into a SAT formula, hands the latter to a standard \nSAT solver, and constructs counterexample traces if there exist incorrect executions. Applying CheckFence \nto .ve previously published algorithms, we were able to (1) .nd several bugs (some not previously known), \nand (2) determine how to place memory ordering fences for relaxed memory models. Categories and Subject \nDescriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation Formal Methods, Model Checking; \nD.1.3 [Programming Techniques]: Concurrent Pro\u00adgramming; F.3.1 [Logics and Meanings of Programs]: Specify\u00ading \nand Verifying and Reasoning about Programs Mechanical Veri.cation General Terms Veri.cation Keywords \nConcurrent Data Structures, Multi-Threading, Shared-Memory Multiprocessors, Memory Models, Lock-Free \nSynchro\u00adnization, Sequential Consistency, Software Model Checking  1. Introduction Shared-memory multiprocessors \nand multi-core chips are now ubiquitous. Nevertheless, programming such systems remains a challenge [44]. \nConcurrency libraries such as the java.util.concurrent * This research was partially supported by NSF \nawards CPA 0541149 and CSR-EHS 0509143 and by donations from Intel Corporation. Permission to make digital \nor hard copies of all or part of this work for personal or classroom use is granted without fee provided \nthat copies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, \nUSA. Copyright c &#38;#169; 2007 ACM 978-1-59593-633-2/07/0006. . . $5.00 PASS FAIL +  Figure 1. Black-box \nview of the CheckFence tool. package JSR-166 [27] or the Intel Threading Building Blocks [22] support \nthe development of safe and ef.cient multi-threaded pro\u00adgrams by providing concurrent data types, that \nis, concurrent im\u00adplementations of familiar data abstractions such as queues, sets, or maps. Client programs \nwith threads that execute concurrently on a multiprocessor can bene.t from implementations that are opti\u00admized \nfor concurrency. Many sophisticated algorithms that use lock-free synchronization have been proposed \nfor this purpose [17, 18, 31, 33, 34, 43]. Such implementations are not race-free in the classic sense \nbecause they allow concurrent access to shared mem\u00adory locations without using locks for mutual exclusion. \nAlgorithms with lock-free synchronization are notoriously hard to verify, as witnessed by many formal \nveri.cation efforts [6, 14, 46, 50] and by bugs found in published algorithms [10, 32]. Many more interleavings \nneed to be considered than for implementations that follow a strict locking discipline. Moreover, the \ndeliberate use of races prohibits the use of classic race-avoiding design method\u00adologies and race-detecting \ntools [1, 12, 19, 24, 36, 39, 41, 49]. To make matters worse, most commonly used multiprocessor architectures \nuse relaxed memory ordering models [2]. For exam\u00adple, a processor may reorder loads and stores by the \nsame thread if they target different addresses, or it may buffer stores in a lo\u00adcal queue. Whereas fully \nlock-based programs are insensitive to the memory model (because the lock and unlock operations are de\u00adsigned \nto guarantee the necessary memory ordering), implemen\u00adtations that use lock-free synchronization require \nexplicit memory ordering fences to function correctly on relaxed memory models. Fences counteract the \nordering relaxations by selectively enforcing memory order between preceding and succeeding instructions. \nA lack of fences leads to incorrect behavior, whereas an overzealous use of fences impacts performance. \nNevertheless, fence placements are rarely published along with the algorithm. To help designers and implementors \ndevelop correct and ef.\u00adcient programs for relaxed models, we present a method that can statically check \nthe consistency of a data type implementation for a given bounded test program and memory model (Fig. \n1). Given the implementation code, a small test program representing the client program, and a choice \nof memory model, our CheckFence proto\u00adtype veri.es for all concurrent executions of the test that the \nob\u00adserved results are consistent with the expected semantics of the data type. If the check fails, a \ncounterexample trace is presented to the user who can then analyze and .x the problem. We build upon \nand further automate the general technique de\u00adscribed in our prior case study [4]. At the heart of this \nmethod is an encoding that represents the executions of the test program as solutions to a propositional \nformula. To obtain this formula, we .rst compile the code for each thread into a bounded sequence of \ninstructions. Then we separately encode the thread-local program semantics (in the style of CBMC [5]) \nand the memory model (in axiomatic form). Once the encoding is complete, we can use a stan\u00addard SAT solver \nto solve for erroneous executions. Our method proceeds in two steps. First, we perform a speci.\u00adcation \nmining: we automatically create a speci.cation for the given test by enumerating the set of correct observations. \nAn observation is a combination of argument and return values, and it is correct if it is consistent \nwith some atomic interleaving of the operations. For example, for the test in Fig. 1, (A =0,B =1,X =0,Y \n=1)is a correct observation, whereas (A =0,B =1,X =0,Y =0)is not. After mining the speci.cation, we then \ncheck all executions of the test on the chosen memory model to see that the observed values are contained \nin the speci.cation. This step is called inclusion check. If the inclusion check fails, we produce a \ncounterexample trace. The trace presents the details of the execution to the user, who can then analyze \nand .x the problem. We implemented this method in a prototype called CheckFence and applied it to .ve \npreviously published algorithms, writing test programs and C code that closely follows the published \npseu\u00addocode. We were thus able to 1. Reproduce two known bugs in a concurrent deque algorithm known as \nsnark [8, 10, 26]. 2. Uncover a not-previously-known bug in a lazy list-based set im\u00adplementation. The \npublished pseudocode [18] fails to initialize a .eld, which was missed by a prior formal veri.cation \nusing the PVS interactive proof system [6]. 3. Show numerous failures on architectures with relaxed \nmemory models (the original algorithms assume sequentially consistent architectures), and .x them by \ninserting appropriate memory ordering fences.  2. Problem Formulation In this section, we describe \nthe parameters of the veri.cation prob\u00adlem (test programs, correctness condition, and memory models) \nmore concretely. 2.1 Test Programs To exercise the implementation code, we use test programs.A test program \nspeci.es a .nite sequence of operation calls for each thread. It may choose to leave the argument values \nunspeci.ed, which conveniently allows us to cover many scenarios with a single test. It may also specify \ninitialization code to be performed prior to the concurrent execution of the threads. 2.2 Correctness \nCondition The basic idea of our method is to compare the set of concurrent executions with the set of \nserial executions. Given a test program T that makes invocations to the operations of some abstract data \ntype, and an implementation I,we de.ne ET,I,Serial is the set of serial executions. Serial executions \nare executions by a single processor that interleaves the threads and treats the operations as atomic, \nthat is, does not switch threads within operations.  ET,I,Y is the set of multiprocessor executions \nfor memory model Y. The model Y mayuse relaxed memoryordering rules.  We de.ne these sets more formally \nbelow in Section 2.3.1 and proceed .rst to a description of how they relate to our correctness condition. \nFor a given execution ewe de.ne the observation vector obs(e)to consist of the argument and return values \nto the operations that occur in e. For test program T and implementation I,we de.ne the observation set \nas ST,I ={obs(e)| e. ET,I,Serial} The observation set Scaptures the intended behavior of the data type, \nand serves as a speci.cation in the following sense. For test T and observation set S, we say that the \nimplementation I satis.es S on memory model Y if and only if .e. ET,I,Y :obs(e). S Because the argument \nand return values are all that the client program observes, implementations that satisfy the speci.cation \nare guaranteed to appear to the client program as if they executed the operations atomically. Note that \nwe need not necessarily use the same implementation when extracting the speci.cation S and when performing \nthe in\u00adclusion check. In practice, it is often sensible to write a reference implementation (which need \nnot be concurrent and is thus simple) to construct the observation set. 2.3 Memory Models We currently \nsupport two hardware-level memory models. One is the classic sequential consistency [25], which requires \nthat the loads and stores issued by the individual threads are interleaved in some global, total order. \nSequential consistency is easiest to understand; however, it is not guaranteed by most multiprocessors \n[2]. The other model is Relaxed [4]. It allows the hardware to relax the ordering and atomicity of memory \naccesses. Speci.cally, it permits (1) reorderings of loads and stores to different addresses, (2) buffering \nof stores in local queues, (3) forwarding of buffered stores to local loads, (4) reordering of loads \nto the same address, and (5) reordering of control-or data-dependent instructions. 2.3.1 Set of Executions \nFor a test T with n threads, an implementation I, and a memory model Y, we de.ne the set of executions \nET,I,Y to consist of all execution traces e=(w1,...,wn)such that (1) each wi is a .nite sequence of basic \nmachine instructions (loads, stores, assignments, and fences) within which all instructions are annotated \nwith the execution values, (2) each instruction sequence wi corresponds to a sequential execution (under \nstandard semantics) of the code for thread i as speci.ed by T,I, and (3) the trace e satis.es the conditions \nof the memory model Y as de.ned in the next section. 2.3.2 Memory Model Axioms We now present the core \nof our axiomatic formulations for sequen\u00adtial consistency and Relaxed. First, we need some common nota\u00adtion. \nLet A be a set of addresses, and V be a set of values. For a given execution trace e=(w1,...,wn),let \nXe =Le . Se be the set of memory accesses in the trace, with Le being the set of loads and Se being the \nset of stores. For an access x. Xe,let a(x). A be the address of the accessed location, and v(x). V be \nthe value loaded or stored. For an address a. A,let i(a). V be the initial value of the memory location \na.Let <p be the program order, that is, a partial order on Xe such that x<p ywhenever xprecedes y within \nsome sequence wi. Sequential Consistency. An execution trace eis sequentially con\u00adsistent if there exists \na total order <M over Xe (the memory order) subject to the following conditions. For each load l. Le,let \nS(l) be the set of stores that are visible to l: S(l)={s. Se | a(s)=a(l). (s<M l)} Then the following \naxioms must be satis.ed: 1. if x<p y,then x<M y 2. if l. Le and S(l)=\u00d8,then v(l)=i(a) 3. if l . Le \nand s . S(l)and v(l)= v(s), then there exists a store s' . S(l)such that s<M s'.  Relaxed. An execution \ntrace eis allowed by the memory model Relaxed if there exists a total order <M over Xe (the memory order) \nsubject to the following conditions. For each load l. Le,let S(l)be the set of stores that are visible \nto l: S(l)={s. Se | a(s)=a(l). ((s<M l). (s<p l))} Then the following axioms must be satis.ed: 1. if \nx<p y, a(x)=a(y),and y. Se,then x<M y 2. if l. Le and S(l)=\u00d8,then v(l)=i(a) 3. if l . Le and s . S(l)and \nv(l) v(s), then there exists a  = store s' . S(l)such that s<M s'. The model Relaxed differs from sequential \nconsistency in two places. For one, axiom 1 has been weakened to allow the memory order to be different \nfrom the program order. Secondly, the set S(l)has been modi.ed to allow forwarding of values from stores \nsitting in a local store queue to subsequent loads by the same processor: S(l)may contain stores that \nprecede a load in program order (s<p l) but are performed globally only after the load is performed (l<M \ns). Seriality. We can conveniently formalize serial executions (exe\u00adcutions that interleave the operations \natomically) by de.ning serial\u00adity as a special kind of memory model as follows. Given T,Iand an execution \ntrace e, de.ne an equivalence relation ~ over Xe such that x~ ywhenever x,yare part of the same operation. \nThen, we say eis serial if and only if (1) it is sequentially consistent, and (2) '' if x~ x' and y~ \ny',then (x<M y). (x<M y). 2.3.3 Comparison to Other Memory Models Memory models can be compared in terms \nof the execution traces they allow. We call a model Y stronger than another model Y' if every execution \ntrace that is allowed by model Y is also allowed by Y'. For example, seriality is stronger than sequential \nconsistency, and sequential consistency is stronger than Relaxed. The purpose of Relaxed is to provide \na common, conserva\u00adtive approximation of several memory models (Sun SPARC v9 TSO/PSO/RMO [48], Alpha \n[7], and IBM 370/390/zArchitecture [23]). All of these models are stronger than Relaxed, which implies \nthat once code runs correctly on Relaxed, it will run correctly on the former. However, Relaxed is not \nstrictly weaker than the of.cial Pow\u00aderPC [13], IA-64 [21] and IA-32 [20] models because it globally \norders all stores (the execution in Fig. 2 illustrates this point). Even so, Relaxed still captures the \nmost important relaxations of those models and is useful to determine where to place fences. This lim\u00aditation \nis not fundamental to our methodology, and we are actively Figure 2. An execution trace that is not possible \non Relaxed,but not ruled out on PPC, IA-32, and IA-64. On the latter, we represent the load-load fence \nas follows: (PPC) lwsync, (IA-32) lfence, (IA\u00ad64) replace load that precedes the fence with load-acquire. \nInitially, x=y=0 thread 1 thread 2 thread 3 thread 4 store x, 1 store y, 1 load x, 1 load-load fence \nload y, 0 load y, 1 load-load fence load x, 0 working on formalizing a weaker version of Relaxed to \nclose the gap.   3. Solution We now describe how we implemented and applied our method. See Fig. 3 \nfor a schematic view of the internal structure of the tool. 3.1 The Front-End CheckFence has a front-end \nthat compiles the C code into an in\u00adtermediate representation. This intermediate representation uses \na custom language called load-store language (LSL) which precisely de.nes the possible instruction sequences \nof stores, loads, fences, and synchronization instructions for each thread. The front-end is based on \nthe CIL framework [37] which parses C and provides us with a cleaned-up and somewhat simpli.ed ab\u00adstract \nsyntax tree. From there, compilation into LSL is relatively straightforward for most programs. CheckFence \ntranslates concur\u00adrent data type implementations of realistic detail precisely and au\u00adtomatically, but \nit may refute some programs if they contain un\u00adsupported features. We discuss some of the choices we \nmade in the following paragraphs. See Fig. 4 for the abstract syntax of LSL. C multiprocessor semantics. \nThe C language does not specify a memory model (standardization efforts for C/C++ are still under way). \nTherefore, executing memory-model sensitive C code on a multiprocessor can have unpredictable effects \n[3]. On the machine language level, however, the memory model is of.cially de.ned by the hardware architecture. \nIt is therefore possible to write C code for relaxed models by exerting direct control over the C compilation \nprocess to prevent optimizations that would alter the program semantics. The details of how to do this \n(for example, volatile declarations, compiler pragmas, or command line options) are compiler-dependent \nand beyond the scope of this work. Here, we simply assume a vanilla compilation without optimizations, \nand we apply the hardware-level memory model to the resulting machine-level program. Values and types. \nWe found that the types present at C source level can not be relied upon (due to the presence of casts). \nThere\u00adfore, we chose to keep LSL untyped; however, we do track the type Figure 3. Schematic view of \nthe components. Figure 4. The abstract syntax of LSL (number) n .N (value) (register) v ::= r unde.ned \n| n | [ n ] (primitive op) f (procedure name) p (block tag) t (statement) s ::= (constant) r = v (primitive \nop) (store) (load) (fence X) (atomic block) (procedure call) (labeled block) (leave block) (repeat block) \n(assertion) (assumption) |r = f(r) |*r = r |r = *r |fenceX |atomic {s}|p(r)(r) |t: {s}|if (r) break t \n|if (r) continue t |assert (r) |assume (r) struct { long a; int b[3]; }x; int y; Pointer C value LSL \nvalue &#38;(x) 0x000 [ 0 ] &#38;(x.a) 0x000 [ 0 0 ] &#38;(x.b) 0x008 [ 0 1 ] &#38;(x.b[0]) 0x008 [ 0 \n1 0 ] &#38;(x.b[1]) 0x00C [ 0 1 1 ] &#38;(x.b[2]) 0x010 [ 0 1 2 ] &#38;(y) 0x014 [ 1 ] Figure 5. Representing \nC pointers in LSL. of values at runtime, by distinguishing between unde.ned, integer, and pointer values. \nThe back-end also recovers some static type in\u00adformation directly from the untyped code by performing \na range analysis (see Section 3.4). The runtime types help to automatically detect bugs. For example, \nwe detect if a program uses an unde.ned value in a computation or a condition. Pointer values. We represent \npointer values as a sequence of natural numbers [n1 ...nk]where (k =1), representing the base address \nn1 and sequence of offsets n2,...,nk. The offsets may be .eld or array offsets, providing a uni.ed way \nof handling arrays and structs. See Fig. 5 for an example of how C pointers can be represented in this \nmanner. The advantage of keeping the offsets separate from the base address is that we can avoid addition \nor multiplication when encoding pointer operations in the back-end. Moreover, our range analysis (Section \n3.4) can often determine that large portions of the sequence are statically .xed. Control .ow. To facilitate \na minimalistic unrolling of loops in the back end, we retain the nested block structure of the source \nprogram. Conditionals are represented by conditional breaks and continues which can exit or repeat an \nenclosing block identi.ed by its tag. Fences. Fences are special machine instructions that guarantee \nsome ordering among the memory accesses that precede and follow it. We currently support four kinds of \nmemory ordering fences: load-load, load-store, store-load and store-store (as used by the Sparc RMO memory \nmodel [48]). An X-Y fence guarantees that all accesses of type X that appear before the fence will be \nordered before all accesses of type Y that appear after the fence. Fences can guarantee some ordering \namong the memory accesses without enforcing full sequential consistency. bool cas(unsigned *loc, unsigned \nold, unsigned new) { atomic { if (*loc == old) { *loc = new; return true; } else { return false; } \n} } Figure 6. Pseudocode for the compare-and-swap (CAS) operation. typedef enum { free, held } lock_t; \n void lock(lock_t *lock) { lock_t val; do { atomic { val = *lock; *lock = held; } } while (val != free); \nfence(\"load-load\"); fence(\"load-store\"); } void unlock(lock_t *lock) { fence(\"load-store\"); fence(\"store-store\"); \natomic { assert(*lock == held); *lock = free; } } Figure 7. Pseudocode for the lock and unlock operations. \nSynchronization. We currently model all synchronization in LSL using atomic blocks. The instructions \nwithin an atomic block are guaranteed to execute in program order, and they are never inter\u00adleaved with \ninstructions in other threads. See Fig. 6 for a pseu\u00addocode example of how we model the compare-and-swap \ninstruc\u00adtions using an atomic block. Our lock and unlock operations are based on code from the SPARC \nv9 architecture manual [48] and use a spin loop, an atomic load-store primitive, and partial mem\u00adory \nordering fences (Fig. 7). To avoid an unbounded unrolling of the spin loop, we use a custom reduction \nfor side-effect free spin loops. C features. The C language has many features, not all of which are supported \nby our CheckFence prototype. We are adding fea\u00adtures as needed to handle the implementations we wish \nto study. Already supported are pointers, structs, arrays, full integer arith\u00admetic, limited pointer \narithmetic, nested loops, limited gotos, and packed structures.1 3.2 The Back-End The back-end .rst \ntransforms the test program T and implementa\u00adtion I by inlining the operation calls and unrolling the \nloops (more on this in Section 3.3). As a result, the code for each thread is a simple sequence of machine-level \ninstructions comprising only loads, stores, register assignments, fences, and forward branches. We now \nencode the possible executions as a propositional formula FT,I,Y (Z) over boolean variables Z such that \neach solution of F corresponds to an execution e . ET,I,Y (more on this in Sec\u00ad 1 Many implementations \npack structures into a single machine word with the intent of accessing the entire structure atomically \n(for example, using a compare-and-swap operation). tion 3.2.1). Once we have Fthus encoded, we can perform \nthe spec\u00adi.cation mining and inclusion check using a standard SAT solver as follows. Speci.cation mining. \nTo construct the observation set ST,I we use the following iterative procedure. First, we provide the \nformula FT,I,Serial(Z)as an input to the SAT solver. Next, we run the solver which will return a solution \nfor Z, corresponding to some serial ex\u00adecution e . ET,I,Serial.Let o1 be the observation of this execution. \nNow, we add additional constraints to the solver to exclude execu\u00adtions that have the observation o1 \nand run the solver again. If there is another solution, it gives us a new observation o2. By continuing \nthis process (adding constraints to rule out observations we already saw) until the SAT solver determines \ninsatis.ability (say, after k steps), we obtain the observation set ST,I ={o1,o2,...,ok}. Our practical \nexperience suggests that although the set of serial executions ET,I,Serial can be quite large (due to \nnondeterministic memory layout and interleavings), the observation set ST,I con\u00adtains no more than a \nfew thousand elements for the testcases we used. Therefore, the iterative procedure described above is \nsuf.\u00adciently fast, especially when used with a SAT solver that supports incremental solving. Inclusion \ncheck. For a given test T, implementation I,memory model Y, and .nite observation set S, we check the \ninclusion obs(ET,I,Y ). S by asking the SAT solver to .nd a solution for the variables Z subject to the \nconstraints ^ FT,I,Y (Z) . obs(Z)=o o.S If the SAT solver .nds a satisfying assignment, then the corre\u00adsponding \nexecution is a counterexample because its observation is not equal to any observation in S. On the other \nhand, if the SAT instance is unsatis.able, the inclusion check passes. 3.2.1 Encoding Concurrent Executions \nAfter inlining I in T and unrolling the loops, the code resembles a machine-level program consisting \nonly of loads, stores, register as\u00adsignments, fences, and forward branches. Following the de.nition of \nET,I,Y in Section 2.3.1, we can now encode the possible execu\u00adtion traces e=(w1,...,wn)by introducing \nvariables to represent the execution values and writing constraints over these variables to capture the \nconditions (2) and (3). To encode the thread-local semantics (condition 2), we use a formula .T,I,k for \neach thread k. To encode the memory model (condition 3), we use a formula TT,I,Y . The thread-local formulae. \nTo obtain .T,I,k, we follow a tech\u00adnique similar to the CBMC tool [5]; speci.cally, we use a reg\u00adister \nSSA (single static assignment) form that guarantees that for each program point and for each register \nthere is statically known, unique instruction that assigned it last. For each thread k, we introduce \na set of variables Vk containing one variable for each instruction, representing the LSL value pro\u00adduced \nby that instruction. Next, we introduce a set Ck of boolean variables containing one variable for each \nforward branch, repre\u00adsenting whether the branch is taken or not. We now create con\u00adstraints for each \nassignment to express the relationship between the consumed and produced values, and for each branch \nto express how the branch condition depends on the value of some register. By taking the conjunction \nof all these constraints we get a formula .T,I,k(Vk,Ck)that captures the possible executions of the thread \nin an unspeci.ed environment (that is, for unspeci.ed values re\u00adturned by the loads). The memory model \nformula. We construct a formula TT,I,Y to represent the memory model. In our case, T is simply the conjunction \nof the memory model axioms for Y (Section 2.3.2). If we represent the memory order <M by a variable M \n(ranging over all total orders of X), we thus get a formula TT,I,Y (M,V,C) SS where V =k Vk and C =k \nCk. This formula depends on the variables in V because the axioms make reference to the addresses and \nvalues used by instructions. It depends on the variables in C because the axioms apply to executed memory \naccesses only (an access that is skipped over by a branch is not part of the set Xe). The combined formula. \nWe combine the thread-local and com\u00admunication formulae as follows ^ FT,I,Y (M,V,C) = TT,I,Y (M,V,C) \n. .T,I,k(Vk,Ck) k Finally, we need to transform Fdown to the level of the SAT solver, which requires \nconjunctive normal form FT,I,Y (Z) for some set of boolean variables Z. We thus need to replace all quanti.ers \nby .nite conjunctions or disjunctions and break M and V down to boolean variables. During this process \nwe introduce auxiliary variables, as follows. 1. To encode the memory order M, we introduce auxiliary \nvari\u00adables {Mxy | x,y . X} such that Mxy represents x<M y. To express antisymmetry, we represent Mxy \nand Myx by the same SAT variable (adjusting the sign of literals). To express transitivity, we add explicit \nclauses. 2. To encode the value variables V, we use bitvectors. To get a conservative estimate on the \nrequired width, we perform a range analysis (Section 3.4). 3. For each pair of values v1,v2 . V, we \nintroduce auxiliary variables to represent the equalities v1 = v2. We use separate clauses to break the \nequalities down to the bit level (which we need only do for equality literals that appear in the formula). \n 4. We use for each l . Lan auxiliary variable Initl that represents whether S(l)=\u00d8, and for each s . \nS and l . L an auxiliary variable Flowsl that represents whether s is the maximal store in S(l).  The \nresulting CNF encoding is polynomial: the number of SAT variables and clauses is quadratic and cubic \nin the size of the unrolled test program, respectively.  3.3 Loop Bounds For the implementations and \ntests we studied, all loops are stati\u00adcally bounded. However, this bound is not necessarily known in \nad\u00advance. We therefore unroll loops lazily as follows. For the .rst run, we unroll each loop exactly \nonce. We then run our regular check\u00ading, but restrict it to executions that stay within the bounds. If \nan error is found, a counterexample is produced (the loop bounds are irrelevant in that case). If no \nerror is found, we run our tool again, solving speci.cally for executions that exceed the loop bounds. \nIf none is found, we know the bounds to be suf.cient. If one is found, we increment the bounds for the \naffected loop instances and repeat the procedure.  3.4 Range Analysis To reduce the number of boolean \nvariables, we perform a range analysis before encoding F. Speci.cally, we use a simple light\u00adweight .ow-insensitive \nanalysis to calculate for each SSA register r and each memory location m sets Sr, Sm that conservatively \napproximate the values that r or m may contain during a valid execution. We can sketch the basic idea \nas follows. First, initialize Sr and Sm to be the empty set. Then, keep propagating values as follows \nuntil a .xpoint is reached: ms2 Two-lock queue [33] msn Nonblocking queue [33] lazylist Lazy list-based \nset [6, 18] harris Nonblocking set [16] snark Nonblocking deque [8, 10]  Queue is represented as a linked \nlist, with two independent locks for the head and tail. Similar, but uses compare-and-swap for synchronization \ninstead of locks (Fig. 9). Set is represented as a sorted linked list. Per-node locks are used during \ninsertion and deletion, but the list supports a lock-free membership test. Set is represented as a sorted \nlinked list. Compare-and-swap is used instead of locks. Deque is represented as linked list. Uses double-compare-and-swap. \n Table 1. The implementations we studied. We use the mnemonics on the left for quick reference. constant \nassignments of the form r = c propagate the value c to the set Sr.  assignments of the form r = f(r1,...,rk) \npropagate values from the sets Sr1 ,...,Srk to the set Sr (applying the function).  stores of the form \n*r ' = r propagate values from the set Sr to the sets {Sm | m. Sr. }.  loads of the form r = *r ' propagate \nvalues from the sets {Sm | m. Sr. } to the set Sr.  This analysis is sound for executions that do not \nhave circular value dependencies. To ensure termination, we need an additional mechanism. First, we count \nthe number of assignments in the test that have unbounded range. That number is .nite because we are \noperating on the unrolled, .nite test program. During the propagation of values, we tag each value with \nthe number of such functions it has traversed. If that number ever exceeds the total number of such functions \nin the test, we can discard the value. We use the sets Sr for four purposes: (1) to determine a bitwidth \nthat is suf.cient to encode all integer values that can possibly occur in an execution, (2) to determine \na maximal depth of pointers, (3) to .x individual bits of the bitvector representation (such as leading \nzeros), and (4) to rule out as many aliasing relationships as possible, thus reducing the size of the \nmemory model formula.  4. Results We studied the .ve implementations shown in Table 1. All of them \nmake deliberate use of data races. Although the original publi\u00adcations contain detailed pseudocode, they \ndo not indicate where to place memory ordering fences. Thus, we set out to (1) verify whether the algorithm \nfunctions correctly on a sequentially consis\u00adtent memory model, (2) .nd out what breaks on the relaxed \nmodel and (3) add memory fences to the code as required. First we wrote symbolic tests (Fig. 8). To keep \nthe counterex\u00adamples small, we started with small and simple tests, say, two to four threads with one \noperation each. All memory model-related bugs were found on such small testcases. We then gradually added \nlarger tests until we reached the limits of the tool. Fig. 10 shows the tests we ran for each implementation. \n4.1 Bugs Found We found several bugs that are not related to relaxations in the memory model. The snark \nalgorithm has two known bugs [10, 26]. We found the .rst one quickly on test D0. The other one requires \na fairly deep execution. We found it with the test Dq, which took about an hour. We also found a not-previously-known \nbug in the lazy list\u00adbased set: the pseudocode fails to properly initialize the marked .eld when a new \nnode is added to the list. This simple bug went undetected by a formal correctness proof [6] because \nthe PVS source code did not match the pseudocode in the paper precisely [28]. This con.rms the importance \nof using actual code (rather than pseudocode and manual modeling) for formal veri.cation. Queue tests: \n(e,d for enqueue, dequeue) T0 =(e | d) Ti2 = e(ed | de ) T1 =(e | e | d | d) Ti3 = e(de | dde ) Tpc2 \n= (ee | dd) T53 = (eeee | d | d) Tpc3 = (eee | ddd) T54 = (eee | e | d | d) Tpc4 = ( eeee | dddd) T55 \n= (ee | e | e | d | d) Tpc5 = ( eeeee | ddddd) T56 = (e | e | e | e | d | d) Tpc6 = ( eeeeee | dddddd \n) Set tests: (a, c, r for add, contains, remove) Sac =(a | c) Sar =(a | r) Sacr = (a | c | r) Saacr \n= a(a | c | r) Sacr2 = aar(a | c | r) Saaarr = aaa(r | rc ) S1 =(a | a | c | c | r | r ) Sarr = (a | \nr | r) Deque tests: (al, ar, rl, rr for add/remove left/right) D0 =(al rr | ar rl) Db =(rr rl | ar | \nal) Da = al al (rr rr | rl rl) '''''' '' Dm =(al al al | rr rr rr | rl | ar) ''' ''''' Dq =(al | al | \nar | ar | rl | rl | rr | rr ) Figure 8. The tests we used. We show the invocation sequence for each thread \nin parentheses, separating the threads by a vertical line. Some tests include an initialization sequence \nwhich appears before the parentheses. If operations need an input argument, it is chosen nondeterministically \nout of {0,1}. Primed versions of the operations are restricted forms that assume no retries (that is, \nretry loops are restricted to a single iteration). 4.2 Missing Fences As expected, our testcases revealed \nthat all .ve implementations re\u00adquire extra memory fences to function correctly on relaxed memory models. \nTo give a concrete example, we show the source code for the non-blocking queue with appropriate fences \nin Fig. 9. To our knowledge, this is the .rst published version of Michael and Scott s non-blocking queue \nthat includes memory ordering fences. We ver\u00adi.ed that on Relaxed these fences are suf.cient and necessary \nfor the tests in Fig. 10. Of course, our method may miss some fences if the tests do not cover the scenarios \nfor which they are needed. An interesting observation is that the implementations we studied required \nonly load-load and store-store fences. On some architec\u00adtures (such as Sun TSO or IBM zSeries), these \nfences are automatic and the algorithm therefore works without inserting any fences on these architectures. \n 4.3 Description of Typical Failures Incomplete initialization. A common failure occurs with code sequences \nthat (1) allocate a new node, (2) set its .elds to some value and (3) link it into the list. On relaxed \nmemory models, the stores to the .elds (in step 2) may be delayed past the pointer store 1 typedef struct \nnode { 2 struct node *next; 3 value_t value; 4 } node_t; 5 typedef struct queue { 6 node_t *head; 7 node_t \n*tail; 8 } queue_t; 9 extern void assert(bool expr);  11 extern void fence(char *type); 12 extern int \ncas(void *loc, 13 unsigned old, unsigned new); 14 extern node_t *new_node(); 15 extern void delete_node(node_t \n*node); 16 17 void init_queue(queue_t *queue) 18 { 19 node_t *node = new_node(); node->next = 0; 21 queue->head \n= queue->tail = node; 22 } 23 void enqueue(queue_t *queue, value_t value) 24 { 25 node_t *node, *tail, \n*next; 26 node = new_node(); 27 node->value = value; 28 node->next = 0; 29 fence(\"store-store\"); while \n(true) { 31 tail = queue->tail; 32 fence(\"load-load\"); 33 next = tail->next; 34 fence(\"load-load\"); 35 \nif (tail == queue->tail) 36 if (next == 0) { 37 if (cas(&#38;tail->next, 38 (unsigned) next, (unsigned) \nnode)) 39 break; } else 41 cas(&#38;queue->tail, 42 (unsigned) tail, (unsigned) next); 43 } 44 fence(\"store-store\"); \n45 cas(&#38;queue->tail, 46 (unsigned) tail, (unsigned) node); 47 } 48 bool dequeue(queue_t *queue, value_t \n*pvalue) 49 { node_t *head, *tail, *next; 51 while (true) { 52 head = queue->head; 53 fence(\"load-load\"); \n54 tail = queue->tail; 55 fence(\"load-load\"); 56 next = head->next; 57 fence(\"load-load\"); 58 if (head \n== queue->head) { 59 if (head == tail) { if (next == 0) 61 return false; 62 cas(&#38;queue->tail, 63 \n(unsigned) tail, (unsigned) next); 64 } else { 65 *pvalue = next->value; 66 if (cas(&#38;queue->head, \n67 (unsigned) head, (unsigned) next)) 68 break; 69 } } 71 } 72 delete_node(head); 73 return true; 74 \n} Figure 9. C code for the non-blocking queue [33], with fences added. It is slightly simpli.ed: the \noriginal code stores a counter along with each pointer, which we omit because it is not required in all \ncontexts. No such modi.cations were made to the other algorithms. (in step 3). If so, operations by other \nthreads can read the node .elds before they contain the correct values, with fatal results. All .ve implementations \nshowed this behavior. The .x is the same in all cases: adding a store-store fence between steps (2) and \n(3). For example, the store-store barrier on line 29 of Fig. 9 was added for this reason. Reordering \nof value-dependent instructions. Some weak archi\u00adtectures (such as Alpha [7]) allow loads to be reordered \neven if they are value dependent. For example, the common code sequence (1) read a pointer p to some \nstructure and (2) read a .eld p->f is (somewhat surprisingly) susceptible to out-of-order execution: \nthe processor may perform the load of p->f before the load of p by speculating on the value of p and \nthen con.rming it afterward [30]. We found this behavior to cause problems in all .ve implementa\u00adtions. \nTo avoid it, we add a load-load fence between the two in\u00adstructions. For example, the load-load fence \non line 32 in Fig. 9 was inserted for this reason. Reordering of CAS operations. We model the compare-and\u00adswap \noperation without any implied fences (Fig. 6). As a result, two CAS instructions to different addresses \nmay be reordered. We observed this behavior only for the nonblocking queue, where it causes problems \nin the dequeue operation (Fig. 9) if the tail is ad\u00advanced (line 45) before the node is linked into the \nlist (line 37). To .x this problem, we added a store-store fence on line 44. Reordering of load sequences. \nThe nonblocking queue uses sim\u00adple load sequences to achieve some synchronization effects. For example, \nqueue->tail is loaded a .rst time on line 31; next, tail->next is loaded (line 33); then, queue->tail \nis loaded a second time (line 35) and the value is compared to the previ\u00adously loaded value. If the values \nare the same, the implementa\u00adtion infers that the values that were loaded for queue->tail and tail->next \nare consistent (that is, can be considered to have been loaded atomically). A similar load sequence is \nused in the enqueue operation (lines 52 and 58). For this mechanism to work, we found that the loads \nin the sequence must not be reordered, and we added a number of load-load fences to achieve this effect \n(lines 32, 34, 53, 55, 57). The other implementations did not exhibit this behavior.  4.4 Quantitative \nResults The performance results con.rm that our observation set method provides an ef.cient way to check \nbounded executions of concur\u00adrent C programs (with up to about 200 memory accesses). Further\u00admore, they \nindicate that for our encoding, the choice of the memory model has no signi.cant impact on the tool execution \ntime. Inclusion check statistics. To illustrate the character of the in\u00adclusion checks, we show statistics \nand graphs in Fig. 10. As de\u00adscribedinSection 3.2.1, CheckFence encodes the inclusion prob\u00adlem as a CNF \nformula which is then refuted by the zChaff SAT solver [35] (version 2004/11/15). To keep the trends \nvisible, we do not include the time required for the lazy loop unrolling because it varies greatly between \nindividual tests and implementations. Speci.cation mining statistics. We show information about the speci.cation \nmining in Fig. 11a. Most observation sets were quite small (less than 200 elements). The time spent for \nthe speci.cation mining averaged about a third of the total runtime (Fig. 11b). However, in practice, \nmuch less time is spent for observation set enumeration because (1) observation sets need not be recomputed \nafter each change to the implementation, and (2) we can often compute observation sets much more ef.ciently \nby using a small, fast reference implementation (as shown by the data points for refset ). Test Name \nUnrolled code instrs loads stores Encoding time [s] CNF formula vars clauses Zchaff [MB] time [s] Total \ntime [s] 0.001 0.01 0.1 1 10 100 1000 10000 0 100 200 300 memory accesses in unrolled code zchaff refutation \ntime [s] ms2 msn lazylist harris snark ms2 T0 T1 T53 T54 T55 T56 Ti2 Ti3 Tpc2 Tpc3 Tpc4 Tpc5 Tpc6 142 \n13 20 256 25 33 346 33 47 346 33 47 346 33 47 346 33 47 301 29 40 370 37 46 256 25 33 370 37 46 484 49 \n59 598 61 72 712 73 85 0.1 0.6 2.0 1.8 1.6 1.6 0.8 1.7 0.7 2.4 7.4 16.4 35.0 433 5,077 1,266 40,454 2,445 \n125,831 2,378 125,745 2,331 125,788 2,304 123,660 1,409 42,418 2,116 90,066 1,294 41,553 2,591 142,742 \n4,324 342,446 6,493 677,390 9,098 1,178,842 <1 <0.1 4 0.2 12 1.9 12 5.1 12 7.2 12 3.3 4 0.2 12 0.7 4 \n0.1 15 1.6 47 12.0 94 91.6 186 367.0 0.1 0.8 3.9 6.9 8.7 4.9 1.0 2.4 0.8 4.0 19.4 108.0 402.0 msn T0 \nT1 T53 Ti2 Ti3 Tpc2 Tpc3 Tpc4 Tpc5 Tpc6 214 22 14 1000 115 55 966 107 57 843 93 48 1086 122 60 454 48 \n27 694 74 40 934 100 53 1174 126 66 1414 152 79 0.2 22.0 22.0 8.5 25.6 1.4 5.4 16.4 42.0 130.0 1,004 \n12,151 14,848 1,597,115 14,536 1,426,104 10,407 709,416 16,344 1,633,713 3,496 126,013 7,638 468,274 \n12,979 1,165,993 19,679 2,347,472 27,747 4,133,783 1 <0.1 189 314.0 188 105.0 94 7.2 190 35.4 12 0.7 \n48 6.5 186 74.0 372 455.0 610 1930.0 0.2 336.0 127.0 15.7 61.0 2.0 11.9 90.4 497.0 2060.0 0.1 1 10 100 \n1000 0 100 200 300 memory accesses in unrolled code zchaff memory [kB] ms2 msn lazylist harris snark \nlazylist Sac Sar Sacr Saa Saacr Sacr2 Sarr S1 Saaarr 254 29 23 435 56 39 505 65 39 543 69 48 747 97 58 \n1071 141 81 842 114 67 821 107 56 1183 158 93 0.5 4.0 5.2 8.7 11.7 16.3 103.0 18.2 93.6 1,396 24,658 \n4,521 210,799 5,435 280,223 7,120 424,579 9,233 504,304 14,364 555,692 15,941 1,731,774 13,610 1,201,727 \n23,474 1,945,051 2 <0.1 24 0.8 47 0.7 80 2.1 81 3.5 93 11.6 318 47.3 186 66.4 321 86.4 0.5 4.8 5.9 10.8 \n15.2 27.9 150.3 84.6 180.0 harris SacSar Saa Sacr 406 34 14 575 51 18 896 77 28 1349 125 32 0.4 1.4 5.2 \n28.0 1,882 25,456 3,670 85,824 8,629 333,128 16,411 1,157,264 2 <0.1 12 0.1 48 1.0 187 6.9 0.5 1.6 6.3 \n34.9 snark Da D0 Db Dm Dq 760 77 51 810 89 65 980 107 75 748 77 57 748 77 57 4.1 19.9 47.4 8.1 7.0 5,229 \n230,292 9,254 1,075,792 12,278 1,815,494 8,086 698,752 8,015 710,252 24 0.8 121 9.3 191 49.6 62 28.7 \n62 123.0 4.9 29.2 97.0 36.8 130.0 Figure 10. (a) left: statistics about the inclusion checks. For a \ngiven implementation (listed in Table 1) and test (listed in Fig. 8), we show (from left to right): the \nsize of the unrolled code, the time required to create the SAT instance, the size of the SAT instance, \nthe resources required by the SAT solver to refute the SAT instance, and the overall time required. All \nmeasurements were taken on a 3 GHz Pentium 4 desktop PC with 1GB of RAM, using zchaff [35] version 2004/11/15. \n(b) right: charts show (on a logarithmic scale) how time and memory requirements increase sharply with \nthe number of memory accesses in the unrolled code. The data points represent the individual tests, grouped \nby implementation. 0.001 0.01 0.1 1 10 100 1000 1 enumeration time [s] (a) 10 100 1000 10000 observation \nset size ms2 msn lazylist harris snark refset average time breakdown zchaff refutation of inclusion test \n(33%) specification mining (38%) encoding of inclusion test as CNF formula (29%) (b) 0.1 1 10 100 1000 \n10000 0.1 1 10 100 1000 10000 without range analysis with range analysis (c) Figure 11. (a) characterization \nof speci.cation mining. The data points represent the individual tests (Fig. 8), grouped by implementation. \n (b) average breakdown of total runtime. (c) impact of range analysis on runtime. The data points represent \nthe individual tests. 1x 1000 We allow the operations of the implementation to be written as C code (rather \nthan requiring a manual translation). This improves the degree of automation and the precision, at the \n10x expense of a somewhat larger encoding. 100 10 Our observation set method is more automatic and more \ngen\u00aderal, because it does not require commit point speci.cations. Implementations such as the lazy list-based \nset [18] are not runtime for observation set method [s] Figure 12. Speed comparison between our observation \nset method and the commit point method [4]. Each data point corresponds to an individual test. Both axes \nare logarithmic, diagonal lines show constant ratios. The average speedup is 2.61\u00d7. Impact of range analysis. \nAs described earlier, we perform a range analysis prior to the encoding to obtain data bounds, alias \nanalysis, and range information. This information is used to im\u00adprove the encoding by reducing the number \nof boolean variables. Fig. 11c shows the effect of the range analysis on runtime. On aver\u00adage, the performance \nimprovement was about 42%. On larger test\u00adcases (where we are most concerned), the positive impact is \nmore pronounced (the tool .nished up to 3\u00d7 faster). Choice of memory model. All tests use the memory \nmodel Relaxed (see Sections 2.3 and 3.2.1). To .nd out if the choice of memory model has an effect on \nthe runtime, we separately eval\u00aduated the runtime for a sequentially consistent memory model. The results \nindicate that on average, performance is about 4% faster for sequential consistency, which is insigni.cant. \n  5. Related Work Most prior work on veri.cation of concurrent data types is based on interactive proof \nconstruction and assumes a sequentially con\u00adsistent memory model [6, 14, 40, 46, 50]. To our knowledge, \nanal\u00adogous proof strategies for relaxed memory models have not been investigated. Specialized algorithms \nto insert memory fences automatically during compilation have been proposed early on [11, 42]. However, \nthese methods are based on a conservative program analysis, which makes them less attractive for highly \noptimized implementations: fences can have a considerable performance impact [45, 47] and should be used \nsparingly. Most previous work on model checking executions on re\u00adlaxed memory models has focused on relatively \nsmall and hand\u00adtranslated code snippets (such as spinlocks or litmus tests). It can be divided into two \ncategories: explicit-state model checking com\u00adbined with operational memory models [9, 38], and constraint \nsolv\u00ading combined with axiomatic memory models [4, 15, 51]. We prefer the latter approach for two reasons: \n(1) axiomatic models can more easily capture of.cial speci.cations because the latter use an axiomatic \nstyle, and (2) constraint-based encodings can leverage the advances in SAT solving technology. When compared \nto our earlier case study [4], the method pre\u00adsented in this paper differs as follows: 1 0.1 known to \nhave commit points [6, 46]. Our observation method is faster. Fig. 12 shows a direct speed comparison \non a logarithmic scale; the diagonal lines show con\u00adstant speed ratios. On average, the speedup was about \n2.61\u00d7, but it approached an order of magnitude on some tests. 6. Conclusions Verifying concurrent data \ntype implementations that make deliber\u00adate use of data races and memory ordering fences is challenging \nbecause of the many interleavings and counterintuitive instruction reorderings that need to be considered. \nConventional veri.cation tools for multithreaded programs are not suf.cient because they make assumptions \non the programming style (race-free programs) or the memory model (sequential consistency). Our CheckFence \nprototype .lls this gap and provides a valuable aid to algorithm designers and implementors because it \n(1) accepts implementations written as C code, (2) supports relaxed memory models, memory ordering fences, \nand lock-free synchronization and (3) can verify that the implementation behaves correctly for a given \nbounded test or will produce a counterexample trace if it does not. Future work includes (1) enhancements \nto the front-end to sup\u00adport more C features and data type implementations from the lit\u00aderature, and \n(2) the use of SMT solvers and customized decision procedures to improve the ef.ciency of the back end. \nWe are also working on applying our method to memory models that are weaker than Relaxed (such as the \nPowerPC model [13]) or de.ned at the language level (such as the new Java Memory Model [29]). References \n[1] M. Abadi, C. Flanagan, and S. Freund. Types for safe locking: Static race detection for Java. ACM \nTrans. Program. Lang. Syst., 28(2):207 255, 2006. [2] S. Adve and K. Gharachorloo. Shared memory consistency \nmodels: a tutorial. Computer, 29(12):66 76, 1996. [3] H.-J. Boehm. Threads cannot be implemented as a \nlibrary. In Programming Language Design and Implementation (PLDI), pages 261 268, 2005. [4] S. Burckhardt, \nR. Alur, and M. Martin. Bounded veri.cation of concurrent data types on relaxed memory models: a case \nstudy. In Computer-Aided Veri.cation (CAV), LNCS 4144, pages 489 502. Springer, 2006. [5] E. Clarke, \nD. Kroening, and F. Lerda. A tool for checking ANSI-C programs. In Tools and Algorithms for the Construction \nand Analysis of Systems (TACAS), LNCS 2988, pages 168 176. Springer, 2004. [6] R. Colvin, L. Groves, \nV. Luchangco, and M. Moir. Formal veri.cation of a lazy concurrent list-based set algorithm. In Computer-Aided \nVeri.cation (CAV), LNCS 4144, pages 475 488. Springer, 2006. [7] Compaq Computer Corporation. Alpha Architecture \nReference Manual, 4th edition, January 2002. [8] D. Detlefs, C. Flood, A. Garthwaite, P. Martin, N. \nShavit, and G. Steele. Even better DCAS-based concurrent deques. In Conference on Distributed Computing \n(DISC), LNCS 1914, pages 59 73. Springer, 2000. 0.1 1 10 100 1000 runtime for commit point method [s] \n[9] D. Dill, S. Park, and A. Nowatzyk. Formal speci.cation of abstract memory models. In Symposium on \nResearch on Integrated Systems, pages 38 52. MIT Press, 1993. [10] S. Doherty, D. Detlefs, L. Grove, \nC. Flood, V. Luchangco, P. Martin, M. Moir, N. Shavit, and G. Steele. DCAS is not a silver bullet for \nnonblocking algorithm design. In Symposium on Parallel Algorithms and Architectures (SPAA), pages 216 \n224, 2004. [11] X. Fang, J. Lee, and S. Midkiff. Automatic fence insertion for shared memory multiprocessing. \nIn International Conference on Supercomputing (ICS), pages 285 294, 2003. [12] C. Flanagan and S. Freund. \nType-based race detection for Java. In Programming Language Design and Implementation (PLDI), pages 219 \n232, 2000. [13] B. Frey. PowerPC Architecture Book v2.02. International Business Machines Corporation, \n2005. [14] H. Gao and W. Hesslink. A formal reduction for lock-free parallel algorithms. In Computer-Aided \nVeri.cation (CAV), LNCS 3114, pages 44 56. Springer, 2004. [15] G. Gopalakrishnan, Y. Yang, and H. Sivaraj. \nQB or not QB: An ef.cient execution veri.cation tool for memory orderings. In Computer-Aided Veri.cation \n(CAV), LNCS 3114, pages 401 413, 2004. [16] T. Harris. A pragmatic implementation of non-blocking linked-lists. \nIn Conference on Distributed Computing (DISC), LNCS 2180, pages 300 314. Springer, 2001. [17] T. Harris, \nK. Fraser, and I. Pratt. A practical multi-word compare-and\u00adswap operation. In Conference on Distributed \nComputing (DISC), LNCS 2508, pages 265 279. Springer, 2002. [18] S. Heller, M. Herlihy, V. Luchangco, \nM. Moir, W. Scherer, and N. Shavit. A lazy concurrent list-based set algorithm. In Principles of Distributed \nSystems (OPODIS), 2005. [19] T. Henzinger, R. Jhala, and R. Majumdar. Race checking by context inference. \nIn Programming language design and implementation (PLDI), pages 1 13, 2004. [20] Intel Corporation. Intel \n64 and IA-32 Architectures Software Developer s Manual, Volume 3A, November 2006. [21] Intel Corporation. \nIntel Itanium Architecture Software Developer s Manual, Book 2, rev. 2.2, January 2006. [22] Intel Corporation. \nIntel Threading Building Blocks, September 2006. [23] International Business Machines Corporation. z/Architecture \nPrinciples of Operation, .rst edition, December 2000. [24] B. Jacobs, J. Smans, F. Piessens, and W. Schulte. \nA simple sequential reasoning approach for sound modular veri.cation of mainstream multithreaded programs. \nIn TV 06 Workshop, Federated Logic Conference (FLoC), pages 66 77, 2006. [25] L. Lamport. How to make \na multiprocessor computer that correctly executes multiprocess programs. IEEE Trans. Comp., C-28(9):690 \n691, 1979. [26] L. Lamport. Checking a multithreaded algorithm with +CAL. In Conference on Distributed \nComputing (DISC), LNCS 4167, pages 151 163. Springer, 2006. [27] D. Lea. The java.util.concurrent synchronizer \nframework. In PODC Workshop on Concurrency and Synchronization in Java Programs (CSJP), 2004. [28] V. \nLuchangco. Personal communications, October 2006. [29] J. Manson, W. Pugh, and S. Adve. The Java memory \nmodel. In Principles of Programming Languages (POPL), pages 378 391, 2005. [30] M. Martin, D. Sorin, \nH. Cain, M. Hill, and M. Lipasti. Correctly implementing value prediction in microprocessors that support \nmultithreading or multiprocessing. In International Symposium on Microarchitecture (MICRO), pages 328 \n337, 2001. [31] M. Michael. Scalable lock-free dynamic memory allocation. In Programming Language Design \nand Implementation (PLDI), pages 35 46, 2004. [32] M. Michael and M. Scott. Correction of a memory management \nmethod for lock-free data structures. Technical Report TR599, University of Rochester, 1995. [33] M. \nMichael and M. Scott. Simple, fast, and practical non-blocking and blocking concurrent queue algorithms. \nIn Principles of Distributed Computing (PODC), pages 267 275, 1996. [34] M. Moir. Practical implementations \nof non-blocking synchronization primitives. In Principles of distributed computing (PODC), pages 219 \n228, 1997. [35] M. Moskewicz, C. Madigan, Y. Zhao, L. Zhang, and S. Malik. Chaff: Engineering an ef.cient \nSAT solver. In Design Automation Conference (DAC), pages 530 535, 2001. [36] M. Naik, A. Aiken, and J. \nWhaley. Effective static race detection for Java. In Programming Language Design and Implementation (PLDI), \npages 308 319, 2006. [37] G. Necula, S. McPeak, S. Rahul, and W. Weimer. CIL: Intermediate language and \ntools for analysis and transformation of C programs. In Conf. on Compiler Constr. (CC), 2002. [38] S. \nPark and D. Dill. An executable speci.cation, analyzer and veri.er for RMO. In Symposium on Parallel \nAlgorithms and Architectures (SPAA), pages 34 41, 1995. [39] P. Pratikakis, J. Foster, and M. Hicks. \nLOCKSMITH: context\u00adsensitive correlation analysis for race detection. In Programming Language Design \nand Implementation (PLDI), pages 320 331, 2006. [40] I. Rabinovitz and O. Grumberg. Bounded model checking \nof concurrent programs. In Computer-Aided Veri.cation (CAV),LNCS 3576, pages 82 97. Springer, 2005. [41] \nS. Savage, M. Burrows, G. Nelson, P. Sobalvarro, and T. Anderson. Eraser: A dynamic data race detector \nfor multithreaded programs. ACM Trans. Comp. Sys., 15(4):391 411, 1997. [42] D. Shasha and M. Snir. Ef.cient \nand correct execution of parallel programs that share memory. ACM Trans. Program. Lang. Syst., 10(2):282 \n312, 1988. [43] H. Sundell and P. Tsigas. Fast and lock-free concurrent priority queues for multi-thread \nsystems. J. Parallel Distrib. Comput., 65(5):609 627, 2005. [44] H. Sutter and J. Larus. Software and \nthe concurrency revolution. ACM Queue, 3(7):54 62, 2005. [45] O. Trachsel, C. von Praun, and T. Gross. \nOn the effectiveness of speculative and selective memory fences. In International Parallel and Distributed \nProcessing Symposium (IPDPS), 2006. [46] V. Vafeiadis, M. Herlihy, T. Hoare, and M. Shapiro. Proving \ncorrectness of highly-concurrent linearisable objects. In Principles and Practice of Parallel Programming \n(PPoPP), pages 129 136, 2006. [47] C. von Praun, T. Cain, J. Choi, and K. Ryu. Conditional memory ordering. \nIn International Symposium on Computer Architecture (ISCA), 2006. [48] D. Weaver and T. Germond, editors. \nThe SPARC Architecture Manual Version 9. PTR Prentice Hall, 1994. [49] M. Xu, R. Bodik, and M. Hill. \nA serializability violation detector for shared-memory server programs. In Programming Language Design \nand Implementation (PLDI), 2005. [50] E. Yahav and M. Sagiv. Automatically verifying concurrent queue \nalgorithms. Electr. Notes Theor. Comput. Sci., 89(3), 2003. [51] Y. Yang, G. Gopalakrishnan, G. Lindstrom, \nand K. Slind. Nemos: A framework for axiomatic and executable speci.cations of memory consistency models. \nIn International Parallel and Distributed Processing Symposium (IPDPS), 2004.  \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Concurrency libraries can facilitate the development of multi-threaded programs by providing concurrent implementations of familiar data types such as queues or sets. There exist many optimized algorithms that can achieve superior performance on multiprocessors by allowing concurrent data accesses without using locks. Unfortunately, such algorithms can harbor subtle concurrency bugs. Moreover, they requirememory ordering fences to function correctly on relaxed memory models.</p> <p>To address these difficulties, we propose a verification approach that can exhaustively check all concurrent executions of a given test program on a relaxed memory model and can verify that they are observationally equivalent to a sequential execution. Our <i>CheckFence</i> prototype automatically translates the C implementation code and the test program into a SAT formula, hands the latter to a standard SAT solver, and constructs counter example traces if there exist incorrect executions. Applying <i>CheckFence</i> to five previously published algorithms, we were able to (1) find several bugs (some not previously known), and (2) determine how to place memory ordering fences for relaxed memory models.</p>", "authors": [{"name": "Sebastian Burckhardt", "author_profile_id": "81350574118", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "P871690", "email_address": "", "orcid_id": ""}, {"name": "Rajeev Alur", "author_profile_id": "81100359539", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "P237979", "email_address": "", "orcid_id": ""}, {"name": "Milo M. K. Martin", "author_profile_id": "81100426086", "affiliation": "University of Pennsylvania, Philadelphia, PA", "person_id": "P201031", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250737", "year": "2007", "article_id": "1250737", "conference": "PLDI", "title": "CheckFence: checking consistency of concurrent data types on relaxed memory models", "url": "http://dl.acm.org/citation.cfm?id=1250737"}