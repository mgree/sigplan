{"article_publication_date": "06-10-2007", "fulltext": "\n The ExoVM System for Automatic VM and Application Reduction Ben L. Titzer Joshua Auerbach UCLA Compilers \nIBM T.J. Watson Group Research Center titzer@cs.ucla.edu josh@us.ibm.com Abstract Embedded systems pose \nunique challenges to Java application developers and virtual machine designers. Chief among these challenges \nis the memory footprint of both the virtual machine and the applications that run within it. With the \nrapidly increasing set of features provided by the Java language, virtual machine designers are often \nforced to build custom implementations that make various tradeoffs between the footprint of the virtual \nmachine and the subset of the Java language and class libraries that are supported. In this paper, we \npresent the ExoVM, a system in which an application is initialized in a fully featured virtual machine, \nand then the code, data, and virtual machine features necessary to execute it are packaged into a binary \nimage. Key to this process is feature analysis, a technique for computing the reachable code and data \nof a Java program and its implementation inside the VM simultaneously. The ExoVM reduces the need to \ndevelop customized embedded virtual machines by reusing a single VM infrastructure and automatically \neliding the implementation of unused Java features on a per-program basis. We present a constraint-based \ninstantiation of the analysis technique, an implementation in IBM s J9 Java VM, experiments evaluating \nour technique for the EEMBC benchmark suite, and some discussion of the individual costs of some of Java \ns features. Our evaluation shows that our system can reduce the non-heap memory allocation of the virtual \nmachine by as much as 75%. We discuss VM and language design decisions that our work shows are important \nin targeting embedded systems, supporting the long\u00adterm goal of a common VM infrastructure spanning from \nmotes to large servers. Categories and Subject Descriptors C.3 [Special-Purpose and Application-Based \nSystems]: Real-time and embedded systems; D.3.2 [Programming Languages]: Java; D.3.4 [Programming Languages]: \nProcessors run-time environments; F.3.2 [Logics and Meanings of Programs]: Semantics of Programming Languages \nprogram analysis. General Terms Performance, Design, Languages, Verification. Keywords pre-initialization, \nembedded systems, persistence, dead code elimination, static compilation, static analysis, VM design, \nVM modularity, feature analysis 1. INTRODUCTION Developers have long recognized the advantages of virtual \nmachines for embedded systems; in fact, the development of Java Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for profit or commercial advantage and that copies bear this notice and the \nfull citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute \nto lists, requires prior specific permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, CA, USA. \nCopyright &#38;#169; 2007 ACM 978-1-59593-633-2/07/0006 $5.00. David F. Bacon Jens Palsberg IBM T.J. \nWatson UCLA Compilers Research Center Group dfb@watson.ibm.com palsberg@cs.ucla.edu was originally motivated \nby the need to develop portable software for cable set-top boxes. Embedded platforms such as sensor nodes \nand cell phones are orders of magnitude smaller than desktop systems, making resource limitations of \nparamount importance to developers of both applications and virtual machines. The limitations of such \ndevices have slowed the adoption of Java and other modern languages that require a large runtime system. \nWe believe that this is because a quality Java virtual machine that supports dynamic class loading, JIT \ncompilation, advanced garbage collection, and the complete Java language specification and accompanying \nclass library is a dauntingly large piece of software. A number of specialized embedded virtual machines \nhave been developed [5][7][13][15] that target embedded systems and have investigated various subsets \nof the Java specification, and a number of standards have arisen, for example, the Connected Limited \nDevice Configuration [4]. To combat the space limitations of these embedded domains, researchers have \ninvestigated a number of techniques, including heap compression [3], class file reduction [16], and VM \nspecialization [7]. Many of these systems begin with a custom Java virtual machine implementation; i.e. \na virtual machine specifically designed for small footprint as opposed to feature completeness or performance. \nFor example, VM* [6] is an extremely bare-bones customizable Java interpreter with a very minimal class \nlibrary targeting mote class devices. KVM [13] is a specialized virtual machine with custom class libraries \ntargeting embedded devices with at least 192kb of RAM. While developing a customized virtual machine \nand class library for an embedded system domain has its advantages, it also has important disadvantages. \nFirst, though a small VM is comparatively less engineering effort than a fully featured one, software \ndevelopment and maintenance effort is inevitably duplicated. Secondly, both incremental improvements \nand significant advancements in the state of the art in implementation technology cannot be automatically \nutilized in the custom VM. Thirdly, evaluations of research ideas and implementation techniques inevitably \nhave narrower scope because results are not immediately comparable across domains that do not share a \ncommon virtual machine infrastructure. The ExoVM approaches this problem with the following philosophy: \nReuse existing VM technology; make the program as static and predictable as possible; and include only \nwhat is necessary on a per-program basis. The starting point of the ExoVM system is to reuse a complete \nJVM implementation and Java class library. This could be any industrial or research system that supports \na sufficient feature set. In our work, we chose an industrial strength virtual machine, IBM s J9 VM, \nbut we believe that the general techniques described here could be applicable to any virtual machine. \n The second part of the philosophy is to limit the dynamism of the program, or, almost equivalently, \nto restrict our attention to programs that are largely static. While Java has a number of dynamic features, \nin the embedded domain, many developers and applications already assume a closed world scenario. Applications \nare generally statically configured and then deployed onto the device; execution on the device often \ndoes not require dynamic class loading, reflection, etc. We believe this philosophy to be sound for a \nlarge, important set of embedded programs. The key insight in this paper is to recognize that the second \nand third philosophical points allow pre-initialization, closure, and persistence over both the program \nand the virtual machine implementation together. Normally, the virtual machine builds data structures \nfor itself and the program during VM startup, application loading, and also lazily during application \nexecution; with pre-initialization, all of these data structures are built before running the program. \nClosure is the process of computing the reachable portion of the complete system (both the VM and application) \nover any execution, including the program and VM s code and the pre-initialized data structures. Persistence \nis the process of copying these data structures from the pre-initialized environment to the environment \nin which the program will run. The ExoVM approach to each of these is to i.) perform pre\u00adinitialization \nof the program and VM by loading the program into the fully featured virtual machine and running the \nstatic initializers of the Java classes; ii.) compute the closure using feature analysis to analyze the \nprogram and VM simultaneously; and iii.) persist the data structures computed by the closure process \ninto an image file that can be loaded by a specialized boot VM that elides subsystems that are not needed \nto run the program. Our work is similar to previous work by Courbot and Grimaud [5], who built a customizable \nVM for the purpose of pre\u00adinitializing and reducing embedded programs prior to deployment. While the \napproaches share the same general philosophy, the work we present in this paper has three key differences. \nFirst, we begin with an existing industrial virtual machine implementation and class library, because \nwe believe in a larger goal of reusing the same VM infrastructure for all classes of devices. Secondly, \nwe do not modify the virtual machine or its internal representation of program quantities in order to \nsupport initialization or reduction, but instead build our analysis on top of the virtual machine without \ndisturbing its implementation. Thirdly, we have developed a constraint-based program analysis that allows \nour system to approximate the implementation of native code for the purpose of analysis and therefore \nexpress the interdependencies between the virtual machine, the class library, and the class libraries \nnative code in a seamless framework. The starting point for the system presented here is a development \nconfiguration of the J9 virtual machine that does not precisely correspond to a particular IBM product. \nWe based our ExoVM implementation on the CLDC 1.1 MT version of J9 and additionally included some minimal \nJava reflection support that is required to implement ExoVM pre-initialization and closure computation. \nWe developed the system on Linux x86, but the ideas and results reported here should transfer to similar \nconfigurations on different architectures, e.g. 32-bit ARM. We studied two variants of this VM: one using \nthe CLDC class library (j9cldc, approximately 190kb), and another using a much larger class library that \napproximates the J2SE 1.4 (j9max, approximately 1.6mb). 2. FIXED AND PROPORTIONAL COSTS The memory footprint \nof a Java application is not only comprised of its own code and data and that of libraries, but also \nthat of the virtual machine. We can classify the cost of the virtual machine into two main quantities: \na fixed cost and a proportional cost. The fixed cost corresponds to the VM s code and static data structures \nthat are independent of the application, such as a garbage collector, runtime class loading mechanism, \ninterpreter, JIT compiler, etc. The proportional cost corresponds to program s code and heap e.g. the \ninternal representation of its classes, bytecodes, dispatch tables, compiled code, object type information, \nmethod exception tables, Java objects, etc. For many embedded applications, the fixed cost of the JVM \nruntime system and its data structures may dwarf the size of the application. For example, the j9cldc \nVM executable has more than 600kb of native code, 40kb of static data, and 190kb of Java classes, while \nnone of the 6 EEMBC benchmarks (Section 6) requires more than 120kb for its class representations, and \n5 of 6 execute successfully with a heap less of just 128kb. We believe that this hampers the development \nof small Java applications for small devices. For larger applications, the fixed cost of the VM becomes \nless of an issue, and eventually the proportional cost will dominate. Thus an ideal situation would be \na small fixed cost for small, simple programs and a proportional cost that is related to the size and \ncharacteristics of the application so that simplifications and reductions of large programs produce predictable \nreductions in total footprint. Our observation is that the virtual machine s fixed cost is not (or should \nnot be) as fixed as previously thought, and the VM can be divided into fine-grained pieces of functionality \nthat can be related to features in the Java programming language. Dividing the VM along feature lines \nallows costs that were previously fixed to become proportional to the feature usage of the program. Automated \nprogram analysis can then produce the set of features used in a particular application and therefore \nallow a customized Java VM with a smaller fixed cost to run the application. 3. PRE-INITIALIZATION Many \nlarge programs have sophisticated initialization routines that build complex data structures for use \nthroughout the life of the program. In the case of a Java virtual machine, there are data structures \nto represent and manage the program and the program s state, including threads, Java classes and methods, \nlocks, the garbage collector, JIT compiler, the Java heap, etc. The insight of pre-initialization is \nthat these complex, often long-lived data structures that are normally built at the beginning of the \nprogram execution can instead be built offline and saved for use when the program begins execution. This \nsaves the cost of the initialization routines in both startup time and code footprint. Our first goal \nis to reuse an existing virtual machine rather than build a customized virtual machine. To support pre-initialization, \nthe data structures needed by the VM must be built offline somehow and saved. We began studying our fully \nfeatured VM and soon discovered that the mechanisms that build and maintain internal data structures \nboth at startup and throughout the execution of the program (e.g. resolving and loading a class) are \nremarkably complex. Our first approach was to attempt to replicate the construction of these VM data \nstructures in an offline manner, but this foundered due to the complexity of trying to replicate the \neffect of the startup routines. We quickly discovered that a more elegant solution is to simply reuse \nthe existing initialization routines by running them to a consistent state, and then taking a snapshot. \nThe ExoVM system implements this solution by loading the program into the fully featured virtual machine \nusing the standard startup and loading routines in a non-intrusive manner. This causes the virtual machine \nto initialize itself to a state that is ready to begin executing the program. In particular, the VM has \nalready built the internal representation of the first of the program s classes and methods as well as \nparts of the class library. The VM has already allocated threads, allocated some initial Java objects, \nand resolved important Java classes needed in the internal implementation of certain language features. \nThus the ExoVM analysis system has a complete picture of the initial data structures that are required \nto begin executing the program. Pre-initialization continues by forcing the VM to load rest of the application \nclasses (which would normally be dynamically loaded during application execution), which causes it to \nbuild the internal representations of these classes. 3.1 Class Initializers In Java, a class may define \nan optional class initializer (also called a static initializer), a static method that is executed upon \nthe first use of the class while the program is executing. While lazy initialization gives rises to some \nsemantic problems (e.g. nondeterminism in initialization, exceptions in initializers, cyclic dependencies, \nand dynamic incompatible class change exceptions), in this paper, we are concerned with program analysis \nand footprint, and this mechanism can be particularly troublesome. The dynamic resolution of class, method, \nand field references in Java code has definite implementation costs. First, it requires that the constant \npool references include the metadata needed for dynamic resolution, including the string names of methods, \nfields and classes. Second, dynamic resolution may trigger class loading and initialization. Third, the \nVM must also maintain more metadata for every declared class, field, and method to anticipate any new \nreferences in the future. Fourth, resolution mechanisms inevitably include hash tables and other such \nfast search data structures. Our view is that while dynamically loading application classes may reduce \nthe average case footprint for some applications, the basic classes in the Java library have dependencies \nthat trigger large numbers of classes to be loaded and initialized (many of which are never used by the \nprogram) which leads to the effect of a large fixed JVM cost. We consider dynamic resolution and initialization \nof classes as unwarranted complexity and resource consumption, which lead us to explore the implications \nof changing the model according to our original design philosophy of making the program more static. \nThus, the ExoVM aggressively executes all class initializers for the live classes of the program and \nresolves all constant pool references to classes and methods as part of the pre-initialization phase. \nChanging the model has advantages as well as disadvantages. First, it ensures that class initializers \nwill not need to be executed at runtime, which allows their code to be removed. Second, no dynamic resolution \nof class, method, or field references will occur, so the metadata that is needed for dynamic resolution \ncan be removed, and the mechanism can be removed from the VM. Third, this allows a program written with \nthe model in mind to pre-allocate needed data structures in its static initialization routines, which \nare discarded before runtime, yielding a staged computation model closer to that proposed in [12]. One \ndisadvantage of this approach is that it subtly alters the semantics of Java s class initializers, which \nsome programs may depend on. Also, eager initialization could trigger the execution of routines that \nmay not be triggered at runtime, which might allocate large data structures that waste space, destroy \nthe state of other classes, and generally interact in unintended and unpredictable ways. However, we \nbelieve that most programs for this domain do not depend on the order or laziness of initialization. \nFor example, in the EEMBC benchmark suite, only one program, Parallel, appears to do significant computation \nin its class initializers. This initializer does not depend on other classes, but simply allocates and \ninitializes a static matrix of data that is used during the benchmark. Moreover, we believe that the \nclosure technique described in the next section will automatically remove many data structures that are \nallocated by the initialization phase but are unused at runtime.  4. CLOSURE AND FEATURE ANALYSIS To \nensure the smallest possible program footprint, we would like to automatically compute the smallest set \nof classes and methods that are reachable over any execution of the program. There are a number of whole-program \ntechniques to address this problem, including RTA [2], CHA [6], RMA [12], and flow analyses such as 0-CFA, \nas well as whole-module analyses such as that used in Jax [10]. All of these techniques share a common \nconceptual approach to the problem, beginning at some entrypoint method(s) in the program and building \na static call graph that approximates the reachable code in the program. If a closed world assumption \nis made, code that is not reachable can be safely removed. If an open world is assumed, constraints can \nbe added to prevent unsafe removal of possibly live code. In the ExoVM system, we must compute reachability \nover not only classes and methods in the Java program, but over the initial Java heap as well as the \ndata structures and code in the virtual machine. Therefore our analysis builds on both RTA and RMA and \nextends the class of whole-program, closed world techniques that include live heap objects in the analysis. \nWhile RMA operates on the live heap of a program and its code together and removes code, objects and \nfields of objects, we need three new types of constraints that relate entities at the program level to \nentities at the implementation and VM level. 4.1 Feature Analysis Now we will discuss feature analysis, \nwhich extends the traditional approach of analysis over program entities to include analysis of entities \nthat are the explicit implementation of language features within the virtual machine. We will use the \nterm entity to refer to a single data structure instance, Java object instance, Java method, string constant, \nor VM native method that consumes either code or data space. Unfortunately, in discussions of programming \nlanguages, the term feature is perhaps the most loosely used and most ill defined. However, we will use \nthe term feature to refer to the members of or operations on entities. These definitions have the effect \nthat we restrict our attention to entities and features that have an isolatable implementation in the \nvirtual machine. Our analysis makes entities in the virtual machine explicitly analyzable and will only \ninclude entities in the final program image if they are reachable through feature usage in the program. \nFocusing in this way on entities and features with identifiable implementation artifacts, we can reason \nmore concretely about the language in terms of these implementation artifacts. For example, a large, \ncoarse-grained service might be garbage collection it has a well-defined set of entities in its implementation \nthat require metadata about classes, objects, methods, and threads in order support precise collection. \nAnother example might be the ability to invoke the getClass() method on an object, which allows inspection \nof the run-time type of an object. This feature also has an identifiable implementation; the VM has data \nstructures that represent classes that are exposed to the programs that call this method. Another example \nis the use of the Class.forName() static method; this method s implementation requires the VM a mapping \nbetween string names and class representations, as well as the ability to search for a class if it is \nnot already loaded. If the program does not invoke this method at any point, then the data structures \ncorresponding to implementing this feature can be removed. Other, finer-grained examples are floating \npoint arithmetic, explicit casts, synchronization operations, weak references, JNI, reference arrays, \nstatic initializers, and exceptions. Many of these features correspond almost directly to Java bytecodes, \nand some correspond to Java library methods and classes. But other features become apparent after some \nstudy of a virtual machine implementation, such as the ability to search for a method by its name in \na particular class, or to resolve constant pool entries, which though they do not have a direct language \nexpression, are demanded by the implementation of other features. For example, the ability to search \nfor a class by its name is necessary for the VM to resolve some internal Java classes such as the exception \nclasses. The key idea behind feature analysis is that by treating these VM data structures as first class \nentities in the closure process (just like Java classes, objects and methods), the analysis can express \nthe implementation of the language as members and features of these entities. Reachability over VM data \nstructure instances then becomes analogous to the familiar notion of reachability over heap objects; \nan entity is only reachable if it is referred to by another reachable entity through a feature. If an \nentity is not reachable through a chain of feature uses in the program and the virtual machine, then \nit can be safely removed from the image. 4.2 Constraint-based Analysis Constraint-based program analyses \nseparate the specification of a correct solution to a program analysis problem from the implementation \nof the algorithm that computes the best solution. For example, in a program analysis problem such as \nflow analysis or pointer analysis, the primary goal is to compute sets of program quantities, such as \nwhat variables may this pointer refer to over any execution of the program? or what method implementations \nare reachable at this call site in the program? . Constraint-based analyses usually have the property \nthat there is always a default, correct, but overly conservative solution such as this pointer might \npoint to anything . The art of getting a good and verifiably correct solution to the analysis problem \nis deriving a rule set that describes the minimal properties of a correct solution. Once the constraint \nsystem is set up for a particular program, a general constraint solver can compute the least solution \nto the constraints, giving the most precise answer. 4.3 Entities and VM Types The overall goal of our \nanalysis is to compute the set of live entities needed to implement the program, both at the Java level \nand at the VM level. Each entity in our analysis has an associated type, and each entity type has an \nassociated set of live instances, with the overall analysis result being the union of all entity sets. \nAn entity is considered live and should be included in the closure if it is contained in its associated \nentity set. Our analysis models Java-level entities such as methods, classes and objects in a manner \nthat is similar to RMA [12]. To simplify the constraints, Java methods with implementations have type \nmethod, classes have type Class, and each object instance s type is its dynamic Java type. Note that \neach of these Java-level entities may have one or more associated VM-level entities, not all of which \nmay be ultimately considered live. In addition to the Java entities of the program, our implementation \nmodels 24 different types of VM data structures that are listed in Figure 1. Among these types are: VMNative, \nwhich models the native code implementations of java methods such as Object.hashCode(); VMClass, the \nin-memory representation of a Java class; VMMethod, the in-memory representation of a method; VMROMClass, \nthe on-disk and in-memory representation of the read-only portion of a Java class such as string names, \nthe VMNative VMStackWalkState VMJavaVM VMHashTable VMClass VMMemorySegment VMArrayClass VMMemorySegmentList \nVMClassLoader VMPortLibrary VMROMClass VMThreadMonitor VMMethod VMJavaLangString VMROMMethod VMJavaLangThread \nVMConstantPool VMInternalVMFunctions VMROMConstantPool VMMemoryManagerFunctions VMITable VMInternalVMLabels \n VMTh d Figure 1. A list of the VM types that we model in our analysis. Each type has a list of associated \nfeatures that are used in implementing various language features. The VMNative entity models implementations \nof Java native methods from the class library that are supplied by the VM. constant pool, declared methods; \nVMThread, a representation of a Java thread; and the all-important VMJavaVM data structure, which contains \npointers to important classes, the heap, collections of classes, threads, and at least a dozen other \nsubsystems. Each pointer field within a native data structure is modeled as a feature. This allows fine-grained \nprecision in the analysis of the data structures of the VM. Our analysis models dozens of features for \nthese types; space limitations preclude a complete list. 4.4 Constraint Sets Our analysis uses two kinds \nof sets. The first kind of set, an E (entity) set, contains live entities such as Java objects, VM data \nstructure instances, or Java method implementations. For example, for a Java class C, the set EC represents \nthe set of all reachable objects of exact dynamic type C in the initial heap. The second kind of set \nis an F (feature) set, which is a set that contains the used features of a particular type. The set FC \nfor a Java class C contains the declared fields and methods of C that have been used explicitly within \nthe program. Similarly, the FT set for a VM type T contains the declared fields of T that are used by \nthe program and the VM. Consider the VMMethod type. It has declared fields name and signature that reference \nUTF8 strings. These fields are modeled as features of the VMMethod type, and if the fields (features) \nare used, then they will be added to the FVMMethod set. Further constraints will ensure that the strings \nto which these fields refer will be included in the closure. There is one EC set and one FC set for every \nJava class C in the program and one ET set and one FT set for every type T of VM data structure types. \nTo simplify the number of different types of constraints, our analysis models a Java method implementation \n(i.e. a method that contains code) as an entity of type method, and the set of all reachable method implementations \nwith Emethod. 4.5 Constraint Forms in Feature Analysis Our analysis generates 8 types of constraints. \nSome of these constraint forms should be familiar to readers who have prior experience with RTA [2] or \nRMA [12]. (1) Base case for entities: expresses initially reachable entities. If an entity e of type \nT is present at the beginning of the program execution, for example the main method, then e is reachable. \ne . ET (2) Call site: analyzes call sites in the code of reachable methods in the program. For each method \nM and each call site e.p() in the code of M, where the static type of e is C, we have the constraint: \nM . Emethod . p . FC (3) New object: analyzes allocation sites in the code of reachable methods in the \nprogram. We use dummyC to denote a dummy entity of type C. For each method M and each new C() in the \ncode of M, we have the constraint: M . Emethod . dummyC . EC (4) Feature use: approximates the result \nof using a feature of a type by using the feature on all live instances of that type. Specifically, if \nthe entity e0 of type S is live, and the feature f of type S is live, then the entity referred to by \ne.f is also live: f . FS . e0 . ES . e0.f . Etypeof(e0.f) (5) Subtyping: establishes the relationship \nbetween used features in a supertype to the used features in a subtype. Specifically, for types S and \nT in the Java program, where S is a subtype of T, we have the constraint: FT . FS (6) Feature implication: \nexpresses cases where the use of a feature entails that some other feature is also used. Specifically, \nfor a type S with feature f, and a type T with feature g we may have a constraint of the form: f . FS \n. g . FT (7) Entity implication: expresses cases where the reachability of one entity implies the reachability \nof some other entity. Specifically, for an entity d of type S, and another entity e of type T, we can \nhave constraints of the form: d . ES . e . ET (8) Entity implies feature: expresses cases where the reachability \nof one entity entails the use of a feature of some other type. Specifically, for an entity e of type \nS, and for a type T with feature f, we may have the constraint: e . ES . f . FT The constraints (1), \n(2), and (3) are basically equivalent to rapid type analysis, which maintains a set of possibly instantiated \nclasses RTAC and a set of reachable method implementations RTAM. We can take this view if we consider \nthe existence of dummyC in EC is equivalent to C being in the live set RTAC maintained in RTA. However, \nconstraints (4) and (5) extend this basic view with live entity sets that are similar to those maintained \nin the RMA [12] analysis. The key insight is that the new constraints (6), (7), and (8) extend the power \nof the analysis even further, allowing us to specify per-language and per-VM constraints that relate \nJava entities to their implementation and vice versa. (a) fillInStackTrace . EVMNative . dummy[I . E[I \n (b) fillInStackTrace . EVMNative . classSegmentList . FVMJavaVM (c) startThread . EVMNative . run \n. Fjava.lang.Runnable (d) startThread . EVMNative . J9VMInternals.threadCleanup . Emethod (e) forName \n. EVMNative . classTable . FVMClassLoader (f) indexOf . EVMNative . bytes . Fjava.lang.String (g) \njavaVM . EVMJavaVM (h) e . EVMJavaVM . mainThread . FVMJavaVM (i) m . Emethod  Figure 2: Example \nper-VM constraints that relate native methods to their implementation requirements. Natives can (a) allocate \nnew Java objects (b) use features of VM structures (c) invoke Java virtual methods, (d) invoke Java static \nmethods (f) use fields of Java objects. Default constraints assert certain entities (g) and features \n(h) to be live. The constraint (i) ensures that if a Java method implementation is live, then its representation \nin the VM is live. Figure 2 gives examples of some constraints that handle native method implementations \nin the class library. These constraints model the fact that native methods can trigger Java-level features \nsuch as creating new Java objects and arrays, as well as directly manipulating the VM s internal data \nstructures. Consider the example constraint (e) in Figure 2, which models the need for the class table, \na hashtable that maps strings to class representations in implementing the Class.forName Java native \nmethod. If this native method is never called (i.e. it never is added to the set EVMNative), then the \nclassTable pointer need not be analyzed, and consequently, this data structure can be removed. 4.6 Granularity \nand Natives vs. Sanity In our experience, writing the constraints for all of Java s bytecodes was comparatively \nlittle effort, as this problem is generally well understood and has already been explored in many previous \nanalysis techniques. If we make the assumption that the constant pool entries are resolved and that classes \nare loaded and initialized, then each bytecode amounts to little more than manipulating Java objects \nand the stack and performing calls to some simple VM services such as the allocator. At the bytecode \nlevel, it is easy to have confidence that our analysis constraints for each bytecode will force the inclusion \nof the necessary data structures into the image, and that pure Java programs will execute without problems \non the ExoVM. However, the bulk of Java its class library is not so simple. Java has dozens of classes \nin its standard library that are wormholes into the VM; many have native methods that manipulate internal \nVM data structures directly. In our development branch of J9, the VM and the native code that implements \nthe class library are developed separately but significantly interdependent. In the j9cldc class library, \nthere are 75 such native methods, many of which are implemented in assembly code. In the J2SE (j9max) \nclass library, there are more than 200. Some use JNI or internal services to call back into Java code \nor allocate Java objects. Each of these methods requires constraints that trigger the inclusion of Java \ncode and VM structures that are required to implement them. We were able to derive constraints for many \nof the most important ones. For some we simply coarsen the granularity of the analysis of data structures \nand conservatively include some possibly unreachable data structures. Otherwise, we forbid native methods \nthat we do not yet support by dynamically trapping calls to them. An example of tuning the analysis between \nfine-grained and coarse-grained is the idea of modeling every pointer in every data structure in the \nvirtual machine as a feature that is only used when certain constraints are triggered, such as the use \nof a particular native method or VM service. While the most fine-grained approach is attractive because \nit allows the maximum possible reduction of data structures, only including them under the most specific \ncircumstances, the VM is complex enough that determining the most specific constraints for each pointer \nbecomes infeasible. For many pointers, we were forced to simply assert them either dead or live, depending \non whether we intend to support the associated feature in the ExoVM. Asserting them live is always conservative \nand correct, provided that the data structure that they refer to is correctly identified and copied into \nthe image, but this may bloat the image with data structures unneeded for the particular program. However, \nasserting these pointers dead may be too aggressive because if the associated language feature or service \nis needed at runtime, the virtual machine or native libraries will crash due to the missing data structures. \nOur approach has taken the middle of the road, asserting many pointers to be dead that correspond to \nVM features that we do not intend to support, such as dynamic class loading, and asserting some pointers \nlive and always copying the referred data structures because the right constraints may be elusive. Some \ndata structures are always necessary, such as the VMJavaVM data structure and the VMThread structure \nfor the main java thread. We ve developed a suite of micro-programs that target individual features in \norder to expedite testing and debugging, allowing us to pinpoint the usage of many pointers of VM structures \nand relate them to language features. Individual tests cover the basic bytecode set of the JVM and target \nspecific native methods and language services. For more complex correctness validation including native \nmethods, we rely on running larger benchmark programs and verifying that each program computes the same \nresults as it does on the complete JVM. An industrial scale, feature-complete implementation of our technique \nwould have to test against the Java language compliance kit, since we do not believe that it is possible \nto directly prove the correctness of the analysis technique due to the sheer size and complexity of the \nVM s implementation of native methods and language services.  5. PERSISTENCE Persistence is the process \nof taking a snapshot of the fully initialized virtual machine, including the data structures that represent \nthe program and the program s state, and saving it to an image file or other persistent store to be loaded \nlater. Persistence has been studied widely in programming languages and database systems [19] and has \na number of compelling advantages for programming systems. Key issues are the transparency and efficiency \nof the persistence mechanism, as well as data evolution and versioning. In our system, we perform imaging \nof the VM only once as part of an offline analysis, so the efficiency considerations do not apply, and \nwe do not support data evolution simply because the kinds of data we are saving are heavily tied to one \nparticular VM implementation. As such, our persistence framework, which we refer to as the imager, need \nnot be as general as that in previous systems. After the closure process has computed a set of reachable \nJava methods, classes, objects, and VM data structures, the imager copies and relocates the data structures \nthat exist inside the virtual machine to a special region of memory which is then saved to the disk. \nThis image file is a compacted snapshot of the VM data structures that represents only the reachable \nparts of the program. The image file contains essentially a complete ready-to-go VM that can be used \nimmediately by simply mapping it into memory. 5.1 Persisting C-based Data Structures Once the closure \nprocess has computed the set of reachable data structures of the VM that are needed to correctly execute \nthe program, the imager must copy and relocate these data structures to persistent store. These data \nstructures are declared in C but are manipulated by C, C++, and assembly code. The imager therefore needs \nto persist C data structures in a way that preserves the invariants that are implicit in the code that \nmanipulates them. We began studying the layout of these data structures and the code that manipulates \nthem, discovering that many had implicit and complex structure and invariants. This manual process represents \na particularly unromantic but significant amount of our development time, approximately 3-5 man-months. \nFrom our efforts we were able to develop a description of each important data structure: its layout, \naddress alignment constraints, contents, and its pointers to other data structures. The imager uses the \ndescription to determine how to copy and relocate VM data structures of each type, which includes computing \nthe size and layout of a particular instance and where pointers to other data structures lie within the \nstructure. This is similar to the description of a Java object that a garbage collector needs in order \nto scan a Java object for references to other objects, but can be considerably more complicated. We discovered \na number of implicit constraints on data structures. Two constraints of note are implicit adjacency/layout \nrequirements, and strangely encoded pointers. Many kinds of data structures are segregated into segments, \nwhich allows mass allocation and deallocation as well as fast traversal over all data structures of a \ngiven type. The dependence on this layout is buried deep in the assembly and C code of the VM; to reuse \nthis code without modification requires preserving the invariants it expects. This requires the imager \nto collect certain structures into new segments during the copy process. Furthermore, some data structures \nhave grown very complex as they evolved over time. For example, the representation of a class has numerous \nadjacent, embedded members of variable size; code throughout the VM relies on being able to find known \nstructures at computed offsets from the beginning of the structure. Other data structures throughout \nthe VM point into the middle of the class structure. A correct description of this data structure for \nthe imager required a lot of manual analysis of the code to determine its undocumented layout and implicit \nconstraints. Some pointers are not only pointers, but contain some extra high or low-order bits that \nare used in implementation tricks for monitors [8], virtual tables, and object headers, etc. These pointers \nare assumed to point to structures aligned on addresses that are particular powers of two (most often \n8, 16, and 256 bytes), which allows the lower bits to be reused. To address this common undocumented \ntendency, the description of each data structure in the imager contains alignment constraints that are \nused when the imager chooses a new address for a data structure, making the undocumented constraint explicit. \nSimilarly, pointers that contain extra information bits have special types that instruct the imager to \npreserve the appropriate low-order bits; the type makes it obvious that the pointer contains extra information. \nAnother problematic feature of the system is the use of self-relative pointers within some data structures; \na self-relative pointer stores an offset instead of an actual address; instead, code that uses the pointer \ncomputes the actual address by adding the pointer s value to the pointer s location. This allows some \ndata structures to be copied to and from disk and shared across processes without relocation. Because \nthe imager moves pieces of these data structures around independently, to reuse the VM code unmodified \nthe imager must encode and decode self-relative pointers while moving data structures. Like pointers \nwith extra bits, self-relative pointers have a special type in the data structure description that documents \nthis fact and allows the imager to handle these pointers with equal ease as normal pointers. 5.2 Compilation \nBy completely initializing the VM before imaging, the system can also save any compiled code of the application \nthat has been produced by the JIT. In fact, because of the offline nature of the imaging process, we \ncan simply compile all of the reachable methods with the JIT compiler ahead of time. The JIT and its \ndata structures can then be removed completely from the ExoVM, effectively turning the original VM into \na static compiler albeit one which generates superior code because all classes are resolved and initialization \ncode has already been executed. Because the compilation takes place in a closed-world scenario, there \nis no need to invalidate code and recompile. The imaging process can support pre-compilation of all the \nmethods in the reachable program by running the JIT compiler after feature analysis and directing it \nto generate code into the image. Some small modifications to the JIT compiler are necessary to support \nthis; for example, the JIT often writes the absolute address of data structures and functions that it \nassumes do not move into the compiled code; the imager must make sure that these pointers are found and \nrelocated before the image is finished. We can support this simply by instrumenting the JIT to record \nwhere it writes absolute addresses into the compiled code, and then patching the addresses at image load \ntime. With this approach, there is no need to alter the machine code that the JIT generates. This feature \nwas not fully operational due to time constraints, and our experimental results use the interpreter and \ndo not include any compiled code. The size of the compiled code depends on the quality of the JIT compiler \nand the total amount of reachable code of the program. 5.3 Loading a VM Image Although the imager is \ncapable of producing an image that contains a complete collection of data structures that represent the \nprogram and the VM needed to run the program, the imager is not capable of actually copying the machine \ncode of the VM into the image. The implementation technology of the VM, particularly the linking model \nof C and C++, precludes this, and computed jumps and branches within machine code cannot be supported \nwithout linking information. Our approach to this problem is to separate the data structures (which are \nstored in the image file) from the boot VM, a specialized offline build of the fully featured VM that \ncontains little or no internal data structures. The boot VM lacks the normal VM initialization routines \nthat build these internal data structures, as well as mechanisms such as the JIT compiler and dynamic \nclass loader, but instead only contains VM subsystems that will be needed at runtime for each application, \nsuch as the interpreter, garbage collector, natives of the class library, etc. The boot VM loads all \nof the needed data structures from the image. Our imager produces image files that are intentionally \nnot relocatable; i.e. all of the internal data structures and code within an image file contain absolute \npointers to each other that assume the image starts at a fixed memory address. This simplifies both the \nimager and the boot VM, allowing the boot VM to simply memory map the image from the file to the specific \naddress and thus begin using the image in memory without relocating any internal pointers. Additionally, \nthe image header contains pointers to the main class, the main method of the program, and to important \nglobal VM data structures so that the boot VM need not search the image for where to begin execution. \n 5.4 Patching and Rebuilding The separation between the code and data of a VM instance is not perfectly \nclean, and many internal data structures that are saved in the image contain pointers to internal VM \nfunctions that do not exist in the image. The boot VM must supply the implementation of these functions \nby patching these pointers when the image is loaded into memory. For example, the VM-level method data \nstructure contains a pointer to code that implements the calling convention for that method when it is \ncalled. An interpreted method contains a pointer to machine code in the interpreter to set up the interpreter \nstate, while a synchronized method has a pointer to code that obtains the lock on its receiver object \nbefore executing the method, and so on. When the imager copies a data structure and encounters pointers \nto VM machine code or a C function, it uses a table of known VM routines to identify the target routine. \nAt load time the boot VM loads the image and replaces these pointers with pointers to its implementation \nof the corresponding routines. One further complication with the imaging process is that not all internal \ndata structures can be persisted. In particular, the VM has data structures that correspond to operating-system \nlevel resources such as threads that are not transferable from one process to the next. The boot VM rebuilds \ncertain data structures as necessary when it loads the image into memory.  6. EXPERIMENTS 6.1 Footprint \nWe have implemented pre-initialization, closure, and persistence in a J9-based virtual machine with the \nj9cldc and j9max class libraries to investigate the memory footprint of the VM and the application in \nan embedded scenario. These numbers are obtained on the x86 build of J9 running on Linux 2.6. We did \nnot specifically measure the execution time for the imaging process, but even with our completely untuned \nimplementation written mostly in Java and running in interpreted mode, the entire load, initialize, closure, \nand copy process of the ExoVM took less than 5 seconds on a fast Pentium IV workstation for all our benchmarks. \nTo evaluate the effectiveness of the ExoVM approach, we measured a number of footprint factors for our \nbenchmark programs. First, we evaluate the fixed cost of the VM in terms of the VM s static code and \ndata footprint for the two original VM configurations and the ExoVM specialized boot VM. The j9cldc configuration \nconsists of 600kb of compiled VM code and natives, 260k of read-only data (of which 190kb is the class \nlibrary compiled into the executable), 20kb of initialized data and 17kb of uninitialized data. The j9max \nconfiguration consists of 750kb of compiled VM code and natives, 90kb of read only data, J9CLDC Dynamic \nFootprint CLIB ROCL RWCL INH NHA IHEAP total Chess 188 74 60 0394 0716 -exo 0113 42 33 10 14 212 Crypto \n188 70 62 0466 0786 -exo 0114 46 25 10 41 236 kXML 188 56 58 0483 0785 -exo 0113 45 27 11 50 246 Parallel \n188 49 45 0415 0697 -exo 0 87 26 30 89 33 265 PNG 188 26 48 0383 0645 -exo 0 74 32 23 11 30 170 RegExp \n188 47 55 0389 0679 -exo 0 98 41 26 11 21 197 Figure 3 shows dynamic non-heap memory footprint for six \nbenchmarks on the j9cldc configuration. Each benchmark has two rows: one for its footprint in the standard \nVM, and the next row for its footprint using the ExoVM system. 25kb or initialized data, and 17kb of \nuninitialized data. To reduce the size of the boot VM, we statically compiled out some subsystems, including \nthe JIT compiler, bytecode parser and verifier, zip library support, and some initialization routines, \nsaving about 200kb of compiled code. We believe that there is more code that can be removed from this \nspecialized VM, but linking issues and time constraints limited our ability to explore this. In Figure \n3, we compare the dynamic memory footprint measurements for the data structures and loaded classes across \nour benchmarks for the j9cldc configuration. The first row of each benchmark contains the measurements \nof several footprint factors on the unmodified VM running the applications with the j9cldc class library. \nThese footprint factors are CLIB; the size of the j9cldc class library which is compiled into the binary \nexecutable; ROCL, or read-only portions of the application classes (VMROMClasses); RWCL, or the read-write \nportions of these same application classes (VMClasses); NHA, or non-heap allocations, which are data \nstructures allocated by the VM that are not Java objects and thus not part of the heap. Each of these \nnumbers is given in kilobytes. The two remaining footprint factors apply only to ExoVM images. These \nare INH, or imaged non\u00adheap data structures, which are non-heap data structures that were allocated during \npre-initialization and have been persisted; and IHEAP, which is the initial heap of Java objects, consisting \nof everything from string constants to application objects that have been determined to be reachable \nby the closure process. Note that we do not measure the heap of the program here; we were able to successfully \nexecute the benchmarks with just 128kb of heap (except kXML, which required 512kb), which makes the VM \ndata structures by far the dominating factor. These measurements show the effectiveness of pre-initializing \nthe virtual machine and the application. With a completely built image, the ExoVM has no need of an external \nclass library (CLIB). Feature analysis detects that a number of classes are unused and removes them, \nshowing a moderate reduction in the size of the read-write class representations (RWCL). The size of \nthe initial heap (IHEAP) generated by running the class initializers in the virtual machine is relatively \nsmall. But by far the J9MAX Dynamic Footprint CLIB ROCL RWCL INH NHA IHEAP total Chess 0 597 162 0 557 \n0 1316 -exo 0 619 172 27 10 171 999 Crypto 0 595 163 0 591 0 1349 -exo 0 615 173 26 10 195 1019 kXML \n0 588 159 0 646 0 1393 -exo 0 610 169 26 11 204 1020 Parallel 0 574 147 0 549 0 1270 -exo 00 0 0 0 0 \n0 PNG 0 549 148 0 504 0 1201 -exo 0 577 160 25 11 181 954 RegExp 0 571 156 0 518 0 1245 -exo 0 598 168 \n26 11 173 976 Figure 4 shows dynamic non-heap memory footprint for six benchmarks on the j9max configuration. \nEach benchmark has two rows: one for its footprint in the standard VM, and the next row for its footprint \nusing the ExoVM system. biggest factor is the reduction of the VM s dynamic non-heap memory allocations. \nThis shows that pre-initialization of the VM and feature analysis allow the ExoVM to remove the dominant \nfactor of space consumption in these benchmarks. The reduction of nonheap memory allocations is between \n62 and 73% for these six benchmark applications. Figure 4 evaluates the ExoVM system over the j9max configuration, \nwhich consists of the same VM, but a more complex, fully featured class library. In this scenario, the \nclass library is much larger and not compiled directly into the virtual machine s binary. However, we \ncan see that the dominant cost is now the size of loaded classes, because the more fully featured class \nlibrary has many more interdependencies that force many classes to be loaded and initialized. The most \nsurprising result is that running the feature analysis to produce an image for each of these programs \ndoes not yield a smaller ROM or RAM class footprint. We investigated the reason for this and discovered \nthat the j9max s Class.getName() implementation uses a HashMap that maps a class representation to its \nString name. Because our analysis is partly written in Java and runs on this underlying class library \nto compute the closure, if the program being analyzed calls the Class.getName() method, then the analyzer \nwill discover that this HashMap is reachable, and begin analyzing its contents. Because these classes \nare reachable through Java references, it therefore concludes that all loaded classes are live, and none \nare removed from the image. We were not able to successfully run the Parallel benchmark on the ExoVM \nbecause the larger class library demanded an implementation of protection domains. This highlights another \nproblem with a larger class library. Adding a security layer tends to demand reflective features from \nthe VM that thwart our program analysis. 6.2 Feature study During the course of developing the ExoVM \nsystem and testing feature analysis for correctness, we wrote a large number of Java micro-programs that \neach uses a specific language feature, such as virtual dispatch, throwing an exception, calling API methods, \nrunning threads, etc. While primarily intended for our internal use in testing correctness, they had \nthe side effect of exposing just how much of the class library and VM is tied to a particular language \nfeature. Though we don t claim that our micro-program suite is fully comprehensive of the Java language, \nit did highlight important issues. Our micro-programs were Image Size: microprograms all less than 25 \nlines of cldc max code and primarily target a empty 5 5 single language-level feature. We found a good \narrays 38 225 approximation of the cost checkcast 42 228 of a feature to be the size constructors 13 \n31 of the image generated by floating point 7 7 our analysis, which includes not only VM data nullptr \n13 31 structures, but also .getClass() 30 872 persisted classes and refarray 40 226 objects. As a starting \nHello world 75 872 point, we tested how small an image our system could generate for the empty Figure \n5 program; i.e. a single static main method that just returns. On both j9cldc and j9max, our system \ngenerates a 5kb image that contains the main class (1kb), java.lang.Object (1kb), the VMJavaVM structure \n(1.3kb), a thread (0.6kb), and a small number of other data structures. This is enough to reuse the existing \nVM code unmodified and execute successfully. From this starting point, we investigated the incremental \ncost of supporting individual languages features; Figure 5 shows several microprograms and the resulting \nimage size for the j9cldc and j9max configurations. From the table, we can see that several of the programs \nthat generate small images on the j9cldc configuration have large images on j9max. We were able to pinpoint \nthe problems that cause this phenomenon of feature explosion in j9max by using these unit feature tests. \nOur analysis revealed that the larger class library contains a small number of precarious dependencies, \nsuch as the HashMap in the Class.getName() implementation mentioned previously. When one such dependency \nis triggered, it tends to pull in a large subset of the class library as a whole. This can be seen in \nthe tests that construct and print exceptions: they tend to pull in a large portion of the class library, \nwhich ultimately dwarfs their small size. Our conclusion from this study is that future design of class \nlibraries and careful implementations should strive for modularity in features so as to avoid penalizing \nsmall programs and avoid precarious dependencies. Another approach might be to embed more special knowledge \ninto analysis about the Java-level entities that implement Java features, such as introducing a special \ncase for the Class.getName() s internal data structures. This remains as future work. 6.3 Experience \nIn our experience developing the ExoVM system in J9, we learned important specific lessons about its \nimplementation and virtual machine design in general that we think are valuable to others. The first \nis that complex and arcane data structures frustrate automated imaging techniques, and judging from the \nimplementation complexity that seems to replicate itself over and over throughout the virtual machine, \nwe simply do not believe they are worth whatever gain they intend. By far most of our manual effort was \ninferring implicit constraints of data structures and fixing problems with pointers and layout tricks, \nworking backwards from VM crashes. Although certain techniques have advantages for performance or space \nusage, our overwhelming sense after studying the code is that the most complicated data structures have \nevolved by accretion and their deep entanglement with the VM makes them particularly dangerous to migrate \nor refactor. We think that our work shows the value of persisting the internal VM data structures for \nan embedded domain, and simpler, more regular data structures make this technique far easier. The second \nlesson we learned from our experience is that there appears to be more modularity to source-level language \nfeatures than previously thought. This dimension of modularity does not seem to be borne out in current \nvirtual machine design and class library implementations, including J9 and those with which the authors \nhave previous experience. We believe that this dimension of modularity has important applications in \nthe embedded domain, and that valuing it more highly in the design of new virtual machines will have \npositive consequences for the ability to scale from small devices to server class machines. The third \nlesson that we learned is that the implementation technology of the virtual machine itself matters considerably. \nWe cannot achieve our ultimate goal of total automatic VM specialization given J9 s current implementation \ntechnology, in particular the static linking model inherent in C and C++ applications. A large amount \nof our development effort has been spent in recovering implicit usage patterns of data structures in \nthe virtual machine which is difficult to automate in these languages. Given our experience with large \napplications written in higher\u00adlevel, statically typed languages like Java, we believe that much of this \nanalysis can be streamlined, if not automated completely, if the VM itself were implemented in a language \nthat is more amenable to disciplined program analysis. Not surprisingly, we found that complexity of \nthe class library makes an important difference to the footprint of an application, especially with the \nimplementation of the basic language features such as exceptions. The CLDC implementation of the class \nlibrary contains not only fewer classes over all, but the implementation of basic classes such as exceptions \nhas fewer dependencies, resulting in smaller image sizes. The difference between the CLDC exceptions \nand those in j9max is many more live classes and consequently more used language features. Further, the \nimplementation of exceptions and I/O (particularly international formatting of strings) is significantly \nmore complex in the j9max library. For this technique to work well on such class libraries, more modularity \nin these implementations seems to be necessary, or the analysis must be improved. Java s dynamic invocation \nof class initializers may work well for a bigger domain, but our results with pre-initialization of the \nclasses in an image tends to suggest that for this domain, significant gains can be made by changing \nthe model.  7. CONCLUSION We believe the investigation of feature analysis contributes positively to \na grand challenge in virtual machine construction: the design and implementation of a language runtime \nand compilation model that seamlessly adapts across static and dynamic views of compilation and scales \nfrom extremely small systems up to very large systems. Our experimental results show that pre-initialization \ncoupled with feature analysis can reduce the non-heap footprint of the java virtual machine s data structures \nby as much as 73% and the VM code size by as much as 30% by removing unnecessary subsystems. This work \nalso has wider applicability because it can provide the basis for relating language features to their \nefficiency considerations more directly. We illustrated how feature analysis has shed light on the interconnectedness \nof the virtual machine and the class library implementation with constraints. We believe that this is \njust a first step to exposing the efficiency implications of feature use to application developers to \nwhom footprint matters, such as embedded system programmers. 8. FUTURE WORK Our VM persisting techniques \nare an artifact of the implementation technology of the virtual machine we chose for our research. We \nbelieve that much more would be possible if we could automate the derivation of constraints and the persistence \nmechanism. We believe there are more opportunities for static optimization such as in an ideally static \nclosed-world scenario, where the imaging process might be able to copy both the application s code, the \ninternal data structures of the VM, and also the live code of the VM into the image, producing a completely \ncustomized VM compiled together with the application into a standalone program. This would allow the \nVM and its JIT compiler to be reused as a static compilation system, perhaps allowing it to employ sophisticated \ncompiler optimizations like partial evaluation or static specialization to itself and the application \ncode together. Conversely, we believe this work might have applicability for dynamic languages as well, \nwhere in a dynamic open-world scenario, a more flexible VM infrastructure that was decomposed modularly \naccording the features of the language might employ a dynamic feature analysis so that parts of the program \nand VM infrastructure are loaded on demand as they are needed by the program. The VM might reduce the \ngranularity of dynamic loading to single methods rather than single classes, only loading methods as \nthey are used. Similarly, the VM might defer the construction of internal data structures until they \nare demanded by the first use of a particular programming language feature. This may significantly improve \nperformance for small dynamic programs and help combat large class libraries. Shorter-term work in this \narea would be to further extend the development of the analysis technique to larger sets of features \nand to a more powerful runtime and JIT compiler. 9. REFERENCES [1] C. Ananian and M. Rinard. Data Size \nOptimizations for Java Programs. In 2003 Workshop on Languages, Compilers, and Tools for Embedded Systems \n(LCTES 03). San Diego, CA. June 2003. [2] D. Bacon and P. Sweeney. Fast Static Analysis of C++ Virtual \nCalls. In Proceedings of the 11th Annual Conference on Object-Oriented Programming Systems, Languages \nand Applications (OOPSLA 96). San Jose, CA. Oct. 1996. [3] G. Chen, M. Kandemir, N. Vijaykrishnan, M. \nIrwin, B. Mathiske, and M. Wolczko. Heap Compression for Memory\u00adconstrained Java Environments. In Proceedings \nof the 18th Annual Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA \n03). Anaheim, CA. Oct 2003. [4] Connected Limited Device Configuration (CLDC). http://java.sun.com/j2me \n [5] A. Courbot, G. Grimaud, and J.-J. Vandewalle. Romization: Early Deployment and Customization of \nJava Systems for Constrained Devices. In Proceedings of Second International Workshop on Construction \nand Analysis of Safe, Secure, and Interoperable Smart Devices (CASSIS). Nice, France, Mar 2005. [6] J. \nDean, D. Grove, and C. Chambers. Optimization of Object-Oriented Programs using Static Class Hierarchy \nAnalysis. In the 9th European Conference on Object-Oriented Programming (ECOOP 95). Aarhus, Denmark. \nAug. 1995. [7] J. Koshy and R. Pandey. VM*: A Scalable Runtime Environment for Sensor Networks. In The \n3rd annual conference on Embedded Network Sensor Systems (SENSYS 05). San Diego, CA. Nov. 2005. [8] T. \nOnodera and K. Kawachiya. A study of locking objects with bimodal fields. In Proceedings of the 14th \nAnnual Conference on Object-Oriented Programming Systems, Languages and Applications (OOPSLA 99). New \nYork, New York. Nov. 1999. [9] D. Spoonhower, J. Auerbach, D. Bacon, P. Cheng, and D. Grove. Eventrons: \nA Safe Programming Construct for High-Frequency Hard Real-Time Applications. In Proceedings of the ACM \nConference on Programming Language Design and Implementation (PLDI 06) Ottawa, CN. June 2006. [10] F. \nTip, C. Laffra, P. Sweeney, and D. Streeter. Practical experience with an application extractor for Java. \nIn Proceedings of the 14th Annual Conference on Object-Oriented Programming Systems, Languages and Applications \n(OOPSLA 99). New York, New York. Nov. 1999. [11] F. Tip and J. Palsberg. Scalable Propagation-based Call \nGraph Construction Algorithms. In the 15th Annual Conference on Object-Oriented Programming, Systems, \nLanguages, and Applications (OOPSLA 00). Minneapolis, MN. Oct. 2000. [12] B. L. Titzer. Virgil: Objects \non the Head of a Pin. In Proceedings of the 21th Annual Conference on Object-Oriented Programming Systems, \nLanguages and Applications (OOPSLA 06). Portland, Oregon. Oct. 2006. [13] Sun Microsystems, J2ME Building \nBlocks for Mobile Devices, 2000. [14] D. Rayside and K. Kontogiannis, Extracting Java library subsets \nfor deployment on embedded systems,\" Sci. Comput. Program., vol. 45, no. 2-3, pp. 245-270, 2002. [15] \nZ. Chen, Java Card Technology for Smart Cards: Architecture and Programmer's Guide. Addison-Wesley Longman \nPublishing Co., Inc., 2000. [16] D. Rayside, E. Mamas, and E. Hons, Compact java binaries for embedded \nsystems,\" in Proceedings of the 1999 conference of the Centre for Advanced Studies on Collaborative research, \np. 9, IBM Press, 1999. [17] D.-W. Chang and R.-C. Chang, Ejvm: an economic java run\u00adtime environment \nfor embedded devices,\" Software Practice &#38; Experience, vol. 31, no. 2, pp. 129-146, 2001. [18] D. \nMulchandani, Java for embedded systems,\" Internet Computing, IEEE, vol. 2, no. 3, pp. 30-39, 1998. [19] \nM. P. Atkinson, M. Dmitriev, C. Hamilton, T. Printezis: Scalable and Recoverable Implementation of Object \nEvolution for the PJama1 Platform. POS 2000: 292-314.   \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Embedded systems pose unique challenges to Java application developers and virtual machine designers. Chief among these challenges is the memory footprint of both the virtual machine and the applications that run within it. With the rapidly increasing set of features provided by the Java language, virtual machine designers are often forced to build custom implementations that make various tradeoffs between the footprint of the virtual machine and the subset of the Java language and class libraries that are supported. In this paper, we present the ExoVM, a system in which an application is initialized in a fully featured virtual machine, and then the code, data, and virtual machine features necessary to execute it are packaged into a binary image. Key to this process is <i>feature analysis</i>, a technique for computing the reachable code and data of a Java program and its implementation inside the VM simultaneously. The ExoVM reduces the need to develop customized embedded virtual machines by reusing a single VM infrastructure and automatically eliding the implementation of unused Java features on a per-program basis. We present a constraint-based instantiation of the analysis technique, an implementation in IBM's J9 Java VM, experiments evaluating our technique for the EEMBC benchmark suite, and some discussion of the individual costs of some of Java's features. Our evaluation shows that our system can reduce the non-heap memory allocation of the virtual machine by as much as 75%. We discuss VM and language design decisions that our work shows are important in targeting embedded systems, supporting the long-term goal of a common VM infrastructure spanning from motes to large servers.</p>", "authors": [{"name": "Ben L. Titzer", "author_profile_id": "81100062616", "affiliation": "UCLA Compilers Group, Los Angeles, CA", "person_id": "P729736", "email_address": "", "orcid_id": ""}, {"name": "Joshua Auerbach", "author_profile_id": "81100247226", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY", "person_id": "P149649", "email_address": "", "orcid_id": ""}, {"name": "David F. Bacon", "author_profile_id": "81100628167", "affiliation": "IBM T.J. Watson Research Center, Hawthorne, NY", "person_id": "P60470", "email_address": "", "orcid_id": ""}, {"name": "Jens Palsberg", "author_profile_id": "81100375570", "affiliation": "UCLA Compilers Group, Los Angeles, CA", "person_id": "PP39040032", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250775", "year": "2007", "article_id": "1250775", "conference": "PLDI", "title": "The ExoVM system for automatic VM and application reduction", "url": "http://dl.acm.org/citation.cfm?id=1250775"}