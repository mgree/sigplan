{"article_publication_date": "06-10-2007", "fulltext": "\n Enforcing Isolation and Ordering in STM Tatiana Shpeisman1 Vijay Menon1 Ali-Reza Adl-Tabatabai1 Steven \nBalensiefer2 Dan Grossman2 Richard L. Hudson1 KatherineF. Moore2 Bratin Saha1 1Programming Systems Lab \n2Dept. of Computer Science and Engineering Intel Corporation UniversityofWashington Santa Clara,CA 95054 \nSeattle,WA98195 {tatiana.shpeisman,vijay.s.menon,ali-reza.adl-tabatabai,rick.hudson,bratin.saha}@intel.com \n{alaska,djg,kfm}@cs.washington.edu Abstract Transactional memory provides a new concurrencycontrol mech\u00adanism \nthat avoids manyof the pitfalls of lock-based synchroniza\u00adtion. High-performance software transactional \nmemory (STM) im\u00adplementations thus far provide weak atomicity: Accessing shared data both inside and \noutsidea transaction can resultin unexpected, implementation-dependent behavior. To guarantee isolation \nand consistent ordering in such a system, programmers are expected to enclose all shared-memory accesses \ninside transactions. A system that provides strong atomicity guarantees isolation even in the presence \nof threads thataccess shared data outside trans\u00adactions. A strongly-atomic system also orders transactions \nwith con.icting non-transactional memory operations in a consistent manner. In this paper, we discuss \nsome surprising pitfalls of weak atom\u00adicity, and we present an STM system that avoids these problems \nvia strong atomicity. We demonstrate how to implement non\u00adtransactional data accesses via ef.cient read \nand write barriers, and we present compiler optimizations that further reduce theover\u00adheads of these \nbarriers. We introduce a dynamic escape analysis that differentiates private and public data at runtime \nto make bar\u00adriers cheaper and a static not-accessed-in-transaction analysis that removesmanybarriers \ncompletely.Our resultsonasetofJavapro\u00adgrams show that strong atomicity can be implemented ef.ciently \nin a high-performance STM system. Categories and Subject Descriptors D.1.3[Programming tech\u00adniques]:Concurrent \nProgramming Parallel Programming; D.3.3 [Programming languages]: Language Constructs and Features Concurrent \nprogramming structures; D.3.4[Programming Lan\u00adguages]: Processors Code generation, Compilers, Optimization, \nRun-time environments General Terms Algorithms, Measurement, Performance, Design, Experimentation, Languages \nKeywords Transactional Memory,Strong Atomicity,Weak Atom\u00adicity, Isolation, Ordering, Escape Analysis, \nCompiler Optimiza\u00adtions, Code Generation,Virtual Machines Permission to make digital or hard copies of \nall or part of this work for personal or classroom use is granted without fee provided that copies are \nnot made or distributed for pro.t or commercial advantage and that copies bear this notice and the full \ncitation on the .rst page.To copyotherwise, to republish, to post on servers or to redistribute to lists, \nrequires prior speci.c permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, USA. \nCopyright c &#38;#169; 2007ACM 978-1-59593-633-2/07/0006...$5.00 Globally visible java.util.LinkedList \nlist Initially list == [Item{val1==0,val2==0}] Thread1 Thread2 Item item; synchronized(list) {synchronized(list) \n{ if(!list.isEmpty()) {item = (Item) Item item = (Item) list.removeFirst(); list.getFirst(); } item.val1++; \nint r1 = item.val1; item.val2++; int r2 = item.val2; }} Can r1!=r2? Figure 1. Thread1 privatizes the \npreviously shared object item. Can we safely replace synchronized with atomic? 1. Introduction Transactional \nmemory (TM) offers a simple concurrency control mechanism that avoids manyof the pitfalls associated \nwith locks. With TM, the programmer declares an atomic code block, and the underlying system guarantees \natomicity and isolation during execution, giving the illusion that the block executes as an atomic step \nwith respect to other concurrently executing operations. Prior software TM (STM) systems mostly implement \nweak atomicity [9], in which non-transactional memory accesses go di\u00adrectly to memory and bypass the \nSTM access protocols. Weak atomicity allows violation of a transaction s isolation if there is a data \nrace between transactional and non-transactional code; fur\u00adthermore, weak atomicity allows violation \nof established memory ordering rules if a thread outside of a transaction accesses a loca\u00adtion modi.edbya \ncommitted transaction.To ensure isolation and consistent ordering, it is suf.cient to manually segregate \nshared\u00admemory into memory accessed only in transactions and memory accessedonly outside transactions.As \nSection2 explainsin more detail, without this segregation, different weak-atomicity STM im\u00adplementation \ntechniques will exhibit different and surprising be\u00adhaviors. Strict segregation is error-prone especially \nas software evolves;but more disturbingly, weak atomicity can require segre\u00adgationeven in situations \nwhere lock-based critical sections do not. In such situations, weak atomicity is a step backwards from \nthe goal of reliable and ef.cient concurrent programming. Considerthe lock-basedJavaprograminFigure1,adaptedfrom \nLarus and Rajwar [35] and from Hudson et. al. [32]. Thread 1 removes an item from list and dereferences \nit twice. Because the item becomes private to Thread1 once it is removed, Thread 1 can dereference the \nitem outside the critical section. Thread 2, which properly synchronizes on the list, clearly cannot \ntouch the item once Thread1 removes it. In this lock-based case, it is clear that r1 == r2 as either \nboth .elds were incremented or neither were. The Java Memory Model [38] was designed to support such \nidioms; this program is correctly synchronized. Now consider Figure1with the locks replacedby weak atomic \nblocks. There is no segregation because .elds of item are ac\u00adcessed inside and outside transactions. \nMost of the existing multi\u00adprocessor STM implementations could violate isolation or ordering for reasons \ndepending on the implementation approach. On systems implementing eager versioning and lazy con.ict detection \n[27, 1], Thread2may speculatively update .elds of item even as Thread 1removes it and commits its transaction. \nAlthough Thread2will eventually abort, the unprotected dereference operations in Thread 1may see speculativevalues \nbefore this.On systems implementing lazyversioning [25, 28, 39, 21], Thread1 may commit its trans\u00adaction \nafter Thread2commits its transactionbut before Thread2 updates the .elds of item. Although Thread2willeventually \nup\u00addate these .elds from its private buffers, Thread 1 s unprotected dereference will see stale values \nbefore this. We believe the simplest way to avoid the morass of unpre\u00addictable and implementation-de.ned \nbehavior for such seemingly reasonable programming idioms is to provide strong atomicity [9], in which \nthe system provides isolation and consistent ordering without requiring segregation. Prior implementations \nof strong atomicity, however, use hardware support [30, 42, 43, 24], assume a uniprocessor [47, 37], \nenforce strict segregation statically [26], or do not demonstrate scalable parallelism [31, 6]. This \npaper presents a high-performance strong-atomicity STM system.We make the following contributions: 1. \nWe present the .rst scalable STM designed for multiprocessors that supports strong atomicity in an imperative \nlanguage. 2. We characterize the kinds of problems that occur in weakly\u00adatomic systems. Although past \nwork has illustrated some of the problems that occur with weak atomicity, none have provided the same \ndetail or as complete an analysis of the problems that different STM implementations exhibit. (Section \n2) 3. Wedemonstrate howto implement strong atomicity via ef.cient read and write barrier sequences for \nmemory accesses outside transactions. (Section 3) 4. We present new optimizations to reduce the cost \nof these read and write barriers (and often remove them entirely). First, dy\u00adnamic escape analysis (Section4) \ntracks thread-local objects at runtime to avoid unnecessary synchronization in the barriers. Second, \na whole-program static not-accessed-in-transaction analysis (Section 5) eliminates barriers for code \nthat cannot con.ict with transactional memory accesses. Third, intrapro\u00adcedural optimizations (Section \n6) such as barrier aggregation help amortize the cost of barriers. 5. We measure the performance and \nscalabilityof strong atomic\u00adity on both non-transactional benchmarks and a set of multi\u00adthreaded Java \nprograms modi.ed to use our atomic construct. We show that strong atomicity has no negative effect on \nscala\u00adbility and that our optimizations reduce the overhead of strong atomicity to a fraction of the \noverhead imposed by an unopti\u00admized implementation. (Section7)  2. Characterizing weak atomicity behaviors \nInasafe languagesuchasJava, language constructsneed semantics that precisely determine possible behaviors,butgiving \nprecise, for\u00admal semantics for transactions is beyond our present scope. Rather, we aim to describe as \nthoroughly as we can the various ways that existing STM systems for weak atomicity can violate isolation \nor ordering expectations, categorizing the issues with terminology from the database community [22] or \nprior memory-consistency work [2] where appropriate. Because strong atomicity has none of the pitfalls \nwe present, we believe it is a better starting point for developingacomprehensivememory model that includesTMeven \nthough memory-model questions remain open [23]. Asexpected,allunexpectedbehaviorsinvolvetransactionaland \nnon-transactional code accessing the same shared data with at least one write access. Section 2.1 presents \nwell-known isolation viola\u00adtions that also occur with locks. However,there are additional prob\u00adlems speci.c \nto weakly-atomic STMs. Section 2.2 presents isola\u00adtion anomalies that can result from the speculate-and-abort \nstrat\u00adegy of eager-versioning STM systems [1, 27], in which a transac\u00adtion updates shared memory directly \nand rolls back its writes if it aborts. Section 2.3 presents ordering anomalies that can result from \nlazy-versioning STM systems [25, 28, 39, 21], in which a trans\u00adaction computes with private versions \nof written-to data and up\u00addates shared memory after it commits. Section 2.4 presents anoma\u00adlies due to \nthe coarse granularity at which some lazy-and eager\u00adversioning STM systems manage multiple versions of \ndata. Some of the examples in this section illustrate programs that are properly synchronized using critical \nsections in lieu of atomic blocks, while others illustrate programs that have data races. We believe \nnot only that the properly synchronized programs should execute correctly using atomic blocks,but also \nthat in the spirit of the Java memory model, we should provide some guarantees for programs with data \nraces and prohibit out-of-thin-air values that may compromise safety and security [38]. Note that we \nuse the term weak atomicity in a more general fashion than Blundell, et.al., [9] have de.ned it. In contrast \nto their work, we do not assume a particular behavior when transactional and non-transactional code access \nthe same data. Instead, we refer to anySTM system as weakly atomic if it allows non-transactional accesses \nto access memory directly, bypassing the STM system s mechanisms for accessing shared memory. As shown \nbelow, differ\u00adenttypesof weakly-atomicSTM systemsbehaveverydifferently. 1 2.1 Problems shared with locks \nUnder weak atomicity, one typically expects that data races cause isolation violations just like with \nimproperly synchronized lock\u00adbased code. There are three issues, all demonstrated in Figure 2. Non-repeatable \nreads: Figure 2(a) illustrates a non-repeatable read (NR). Thread 1 s two reads should observe the same \nvalue for x since they are insidea transaction. Butif Thread2writes x between the two reads then Thread \n1 will observe two different values for the variable, violating transaction isolation. A similar problem \nhappensif Thread1.rst writesto x (say thevalue 10)and then reads x;Thread1will not observe thevalueit \nwrote(10)if Thread2writes x between Thread 1 s write and read. Intermediate lost updates: Figure 2(b) \nillustrates an intermediate lost update (ILU) where the same memory location is updated both inside and \noutside a transaction. In a serialized execution of the two threads, both updates should compose. The \nshared variable x should have the .nal value of either 10 (Thread2 executed last) or 11 (Thread2 executed \n.rst);but x will have the .nal value 1 (as if Thread2 s write never happened)if Thread2updates x between \nThread 1 s read and write operations. 1Blundell, et.al. [9], appear to assume that weak atomicity implies \nan eager\u00adversioning STM where transactional updates become immediately visible to non-transactional code. \nIn a lazy-versioning STM, such updates are visible only after commit. Thread1 atomic {r1 = x; r2 = x; \n} Initially x==0 Initially x is even Thread2 Thread1 atomic {x = 1; r = x; x = r + 1; Thread2 Thread1 \nThread2 atomic {x = 10; x++; r =x; x++; } } Can x==1? Can r be odd? (a) Non-repeatable reads (b) Lost \nupdates (c) Dirty reads Can r1!=r2? Figure 2. Isolation violations expected with data races. Intermediate \ndirty reads: Figure 2(c) illustrates an intermediate dirty read (IDR) where a non-transactional access \ncan observe the intermediate state of a transaction. Thread 1 maintains the invariant that x iseven,but \nThread2will observe an oddvalueifit reads x between Thread1 stwoincrements. Underlazyversioning, intermediate \ndirty reads cannot occur,but at the cost of ordering violations discussed in Section 2.3.  2.2 Eager-versioning \nanomalies Eager-versioning STM canexhibit dirty read and lost update behav\u00adiors that are not otherwise \npossible in lock-based code. These be\u00adhaviors areduetothe speculate-and-undo strategyof eagerversion\u00ading, \nin which a transaction speculatively updates shared memory in place and then on abort, rolls back these \nupdates witha compensat\u00ading write.Arolled-back transaction thus manufactures new shared memory writes \nthat are not present in any sequentially-consistent execution, resulting in new lost update and dirty \nread scenarios. Speculative lost updates: Figure 3(a) illustratesa speculative lost update (SLU) where \na non-transactional update is lost due to a write during transaction rollback. Assume Thread1updates \nx .rst, and then Thread2updates y and x. If Thread1 now rolls back, it will restore x s value back to \n0 and skip over the update to x on re-execution (because it now observes y==1), resulting in x==0. Speculative \ndirty reads: Figure 3(b) illustratesa speculative dirty read(SDR) whereanon-transactional read observes \nthe speculative stateofa transaction. Assume Thread1 updates x .rst, and then Thread 2 updates y after \nobserving x==1. If Thread 1 now rolls back, it will restore x s value back to zero and skip over the \nupdate to x on re-execution, resulting in x==0. 2.3 Lazy-versioning anomalies Lazy-versioning STM can \nexhibit memory ordering problems sim\u00adilar to memory consistency problems in shared-memory multi\u00adprocessors \n[2]. Lazy-versioning STMbuffers transactional updates privatelyandthen writesthebufferedupdatesbackto \nsharedmem\u00adory lazily when the transaction commits. The window of time between the transaction commit \nand the update to shared memory can cause memory ordering violations because non-transactional code does \nnot see all committed values during that time. Memory inconsistency: Figure 4 illustrates memory inconsis\u00adtency \n(MI) due to violation of established ordering rules. In Figure 4(a), Thread1initializesa .eldin the object \nel and then publishes the objectbywritingittoavolatile sharedvariable x. Thread2may nowsee the published \nobject in x butnotseethe initializedvalueof its .eld becausea lazy-versioning STM copiesbufferedvalues \nto memoryoneatatimeinno particularorder.Since x isvolatile, this ordering is inconsistent [38]. The same \nproblem can occur when a .nal .eldis initialized insidea transactionbutis reordered witha publishing \nwrite. This is similar to the multiple overlapped writes problem described in [2]. Figure 4(b) shows \nanother memory inconsistency example dis\u00adtilled from Figure1. Thread1takesa sharedvaluein x and makes \nit thread local. Once x is set to null, the object in r1 is not visible to other threads,andfromthe programmerspointofview,it \nshould be safe to access x outside an atomic region. In a lazy-versioning STM, Thread2maybuffer an update \nto x.val, validate itself, and commit.But beforeithas .ushedthenewvalueto memory, Thread 1 may execute \nits transaction and start accessing r1.val. Logi\u00adcally,Thread2 stransactionexecutes before Thread1 stransaction, \nand Thread 1 s accesses to r1.val execute after Thread 1 s trans\u00adaction. But because the STM updates \nshared memory lazily,Thread 1 s accesses to r1.val end up racing with the STM s update. This is similar \nto the buffered writesproblem described in [2].  2.4 Anomalies due to coarse-grained versioning When \nthe granularity at which the STM system manages data versions is greater than the granularity at which \nnon-transactional code writes data (e.g., if the STM logs orbuffers writes in 8-byte blocks whileanon-transactional \naccess writesa4-bytevalue within that block), then additional problems can occur in both lazy-and eager-versioning \nSTM systems. Granular lost updates: Figure 5(a) illustrates a granular lost update (GLU) where the non-transactional \nupdate to x.g is lost even though the transaction never accesses this .eld and there is no datarace. \nEager-versioning STM systems [27,1]maintain undo log entries that may be larger than individual object \n.elds (or array elements). If Thread1 s transaction creates an undo log entry that spans .elds f and \ng of x, Thread 2 s update to x.g could be lost if Thread1aborts and rolls back x.f.Asimilar problem can \nhappen in lazy-versioning STM sthatbuffervaluesatasimilar granularity; forexample,if Thread2updates x.g \nafter Thread1has createda private copythat spans .elds f and g, then the update will vanish after Thread1commitsand \nwritesbackitscopyto shared memory. Granular lost updates arise because the STM manufactures new writes \nto variables that lie adjacent to a variable updated inside a transaction.These writesdonotexistinanysequentially-consistent \nexecution of the program. Granular lost updates are similar to the problem of rewriting adjacent data \ndescribed by Boehm [10]. Granular inconsistent reads: Figure 5(b) illustrates a granular inconsistent \nread (GIR) where a transaction may see inconsis\u00adtent updates from a non-transactional thread. Granular \ninconsistent reads are similar to granular lost updates but may only occur in lazy versioning STMs. Here, \nthe shared variable y is volatile and imposes certain ordering constraints between Thread1and Thread \n2. In particular, if Thread 1 observes Thread 2 s update to y, it must also observe Thread 2 s update \nto x.g. In a lazy-versioning STM, however, Thread 1 s transaction (as in the earlier GLU ex\u00adample) may \nhave created a private copy on the write to .eld x.f that also spans x.g. In this case, the transaction \nwill later read its own stale copy of x.g and not observe Thread 2 s update as re\u00adquiredbytheJavamemory \nmodel.Notethatagranular inconsistent read is a memory inconsistencyanomaly akin to those described in \nSection 2.3. Initially x==0 and y==0 Initially x==0 and y==0 Thread1 Thread2 Thread1 Thread2 atomic { \natomic { if (y==0) x = 2; if (y==0) if (x==1) x= 1; y=1; x=1; y= 1; /*abort*/ /*abort*/ } } Can x==0? \nCan x==0? (a) Speculative lost updates (b) Speculative dirty reads Figure 3. More isolation violations \nfor eager versioning STM. Suppose x is volatile Initially x!=null Initially x==null and x.val==1 and \nel.val==0 Thread1 Thread2 Thread1 Thread2 atomic { atomic {atomic { r=-1; r1=x; if(x!=null) el.val=1; \nif(x!=null) x=null; x.val++; x=el; r=x.val; } }} r2=r1.val; Can r==0? r3=r1.val; (a) Overlapped writes \nr1.val=0; Can r2!=r3 or r1.val!=0? (b) Buffered writes Figure 4. Lazy-versioning ordering violations. \nBecause of granular lost updates and inconsistent reads, the pro\u00adgrammer must consider versioning granularity \nwhen segregating data in a weakly-atomic system, and the weak-atomicity program\u00adming interface must explicitly \nde.ne this granularity; otherwise, the STM must manage versions at the granularity of the individ\u00adual \n.elds updated insidea transaction.A strongly-atomic system hides this granularity,but optimizations such \nas our not-accessed\u00adin-transaction analysis must take the granularity into account when analyzing which \nvariables are updated inside transactions.  2.5 Discussion Figure6summarizes the behaviorof weak atomicity, \ncomparingit with locks. This table shows the behaviors for read-write, write\u00adwrite, and write-read accesses \nbetween transactional (Txn) and non-transactional (Non-Txn) code. The eager and lazy versioning columns \nrepresent weak atomicity for these version management policies, the Locks columns represents lock-based \ncritical sections. The Strong column represents strong atomicity, emphasizing that the techniques that \nwe present later avoid these behaviors. Revisiting the privatization example in Figure 1, the problem \nwitheagerversioningisanSDR(Thread2may incrementandthen decrement item.val++ due to an abort) and the \nproblem with lazy versioning is an MI since the non-transactional accesses see that the increments happen \nafter the transaction commits. 3. Enforcing isolation and ordering Enforcing memory ordering and isolation \nbetween transactional and non-transactional threads requires read and write isolation barriers in code \nthatexecutes outsideof atomic blocks.Avoiding dirty reads requires read barriers that detect simultaneous \nwrites by a transaction, avoiding non-repeatable reads and lost updates requires write barriers that \nprevent a simultaneous access by a transaction, and avoiding memory inconsistencies requires barriers \nthat detect pendingbuffered updatesbya transaction. Supposeyis volatile Initially x.g==0 and y==0 Initially \nx.g==0 Thread1 Thread2 Thread1 Thread2 r=-1; atomic { atomic { x.f=1; x.g=1; x.f=...; x.g=1; } if (y==1) \ny=1; Can x.g==0? r=x.g; (a) Granular lost updates } Can r==0? (b) Granular inconsistent reads Figure \n5. Anomalies due to coarse-grained versioning. Non-Txn Txn Anomaly Versioning Eager Lazy Locks Strong \nwrite read NR GIR yes no yes yes yes no no no write write ILU SLU GLU MI yes yes yes no yes no yes yes \nyes no no no no no no no read write IDR SDR MI yes yes no no no yes yes no no no no no Figure 6. Summary \nof weak atomicity behaviors. We have implemented our techniques in a high-performance STM system that \nextends Java with an atomic{ B } construct for declaring an atomic code block B [1]. Our system supports \na full range of transactional features including closed and open nesting [45] and user-initiated retry \noperations. The JIT com\u00adpiler automatically inserts and optimizes STM operations for code that executes \ninside a transaction and isolation barriers for non\u00adtransactional code. At the core of our system lies \nMcRT-STM [49], which implements optimistic concurrency control using version\u00ading [34] for reads and strict \ntwo-phase locking [22] and eager ver\u00adsioning for writes.For our whole-program static analysis we used \nthePaddle[7]extensionto Soot [56]. 3.1 Transaction records In the base STM system, a pointer-sized transaction \nrecord [1] tracks the state of each object accessed inside a transaction. The transaction record can \nbe in either the shared state, which allows read-only access by any number of transactions, or the exclusive \nstate, which allows read-write access by the single transaction that owns the record. In the shared state, \nthe record contains a version numberusedfor optimisticread concurrency.Intheexclusivestate, it contains \na pointer to the owning transaction s descriptor. Each object has a transaction .eld holding its transaction \nrecord. To support ef.cient strong atomicity, we extend the transaction recordtofour states encodedinits \nthree least-signi.cantbits(Fig\u00adure 7). The shared and exclusive states are as before. The exclusive anonymous \nstate indicates that some thread owns the object exclu\u00adsively for read-write access,but the record does \nnot indicate who ownsit.This statepreventsa transactionfrom accessingdatathata non-transactional thread \nis concurrently updating. The upper bits in this state contain the version number from the record s prior \nshared state. An object whose transaction .eld is in the private state is visible only to a single thread. \nThreads never contend for private objects so the runtime can avoid most of the barrier overheads on accesses \nto private objects. Encoding State Value in upper bits x..x011 Shared Version number x..xx00 Exclusive \nOwner address x..x010 Exclusive anonymous Version number 1..1111 Private All ones Figure 7. Transaction \nrecord encoding. This encoding enables ef.cient read and write barriers outside transactions. A non-transactional \nread can check whether it con\u00ad.icts with a transaction that is, detect dirty reads in an eager\u00adversioningSTMor \npending updatesbyacommitted transactionina lazy-versioning STM by inspecting only the second lowest \nbit.2 Anon-transactional write can acquire exclusive anonymous own\u00adership of a record by atomically .ipping \nthe lowest bit from one to zero withasingle IA32 bit-test-and-reset (BTR) instruction thus avoiding \nnon-repeatable reads and lost updates and can release ownership and at the same time increment the version \nnumber by incrementing the record by 9. Figure8 shows the state transition diagram for the transaction \nrecord. The write barrier detects pub\u00adlication of a private object and calls the publishObject function \n(described later) to transition its record to the shared state.Atrans\u00adaction acquires ownership of a \nrecord using an atomic compare\u00adand-swap operation (CAS) in its open-for-write barrier [1, 27] and releasesownershipand \nincrementstheversion numberwhenitends (Txn end). Figure 8. Transaction record state transitions. 3.2 \nRead and write barriers for enforcing isolation Figure9shows the read and write isolation barrier instruction \nse\u00adquences for non-transactional code. The read barrier .rst reads the transaction record followed by \nthe accessed address. If the object is not in the exclusive state, the barrier validates that the record \ndid not change, ensuring that no other thread acquired ownership of the record after the .rst read of \nthe record. If the record is in an ex\u00adclusive stateorifvalidationfails, thenthe read barrierinvokesthe \ncon.ict handler(handleConflict). By design, this barrier may not detect some con.icts between two non-transactional \nthreads as such con.icts do not violate anytransaction s isolation; it can de\u00adtect such con.icts by simply \nchecking the lowest-order bit. Thewrite barriertriestoacquireownershipoftherecordby.ip\u00adping the lowest \nbit of the record with an atomic BTR instruction.3 If the record is already in either of the exclusive \nstates, then the write barrier invokes the con.ict handler. After performing the write op\u00aderation, the \nwrite barrier increments the version number and sets the recordtothe shared stateby incrementingitby \n9. The barriers invoke the con.ict manager whenever multiple threads accessa shared location simultaneously \nwithat least oneof the accesses updating the location. The con.ict manager backs off 2We can also detect \ncon.icts with either concurrent transactional or con\u00adcurrent non-transactional writesby inspecting only \nthelowest bit. 3We can also use a compare-and-swap instruction. readBarrier: mov ecx, [TxRec] mov eax, \n[addr] test ecx, 2 jz readConflict cmp ecx, [TxRec] jne readConflict readDone: ... readConflict: push \nTxRec call handleConflict jmp readBarrier (a) Read isolation barrier writeBarrier: lock btr [TxRec],0 \njnc writeConflict mov [addr],val add [TxRec],9 writeDone: ... writeConflict: push TxRec call handleConflict \njmp writeBarrier (b) Write isolation barrier Figure 9. Read and write barriers for accessing shared data \nin a non-transactional thread. and returns so that the barriers retry. Alternatively, con.icts could \nsignala racebythrowinganexceptionor breakingtothedebugger. Isolation barriers can thus aid in debugging \nconcurrent programs. 3.3 Barriers for enforcing ordering Lazy-versioning STM systems acquire transaction \nrecords on com\u00admit and release them after writing back updates to shared memory (or after aborting if \ncommit fails). These systems do not need a read barrier to enforce isolation as dirty reads are never \nwritten to sharedmemory,buttheydoneedonetoenforce consistentordering (as shown in Figure 1). The read \nbarrier for enforcing ordering in a lazy-versioningSTMthussimply checksforapendingupdatebya committed \ntransaction: test [TxRec], 2 jz readConflict mov eax, [addr] Note that this read barrier does not need \nto recheck the transaction record after the read because it needs to make sure only that the pending \nupdates from the most recent transaction since the last synchronization action are done.  3.4 Quiescence \nfor respecting privatization Aquiescence mechanism can provide partialisolation and ordering guarantees \nand can handle the privatization problem illustrated in Figures1and 4(b) without requiring non-transactional \nreador write barriers. Recent work in the context of unmanaged languages [32, 18] uses quiescence to \nensure that doomed transactions(i.e., invalid transactions thathave notyet aborted)do not cause run-timefaults \ndue to an inconsistent view of memory. They guarantee that a thread does not free memory whileadoomed \ntransaction could still access it. 4 Other work [58, 52] demonstrates how to extend quiescence to handle \nthe privatization problem by requiring that a transac\u00adtion can complete only when all other transactions \nreach a con\u00adsistent state.In the transactional variantof Figure1, this ensures that, for an eager-versioning \nSTM, the transaction in Thread 1 waits until Thread2can no longer access item before committing. Quiescence \ncan also prevent the privatization problem in a lazy\u00adversioning STM. Here, a transaction must wait until \npreviously se\u00adrialized transactions .nish applying their updates to memory before completing itself. \nIn Figure 1, this ensures that, when the transac\u00adtion in Thread1completes, all updates from Thread2 are \nalready visible. 4With managed languages, an STM can rely ongarbage collection and type safety to avoid \nthese problems. readBarrier: mov ecx, [TxRec] mov eax, [addr] cmp ecx, -1 jeq readDone test ecx, 2 jz \nreadConflict cmp ecx, [TxRec] jne readConflict readDone: ... readConflict: push TxRec call handleConflict \njmp readBarrier (a) Read isolation barrier writeBarrier: cmp [TxRec], -1 jeq privateWrite lock btr [TxRec],0 \njnc writeConflict * cmp val,0 * jz publicWrite * cmp [val+txFld],-1 * jne publicWrite * push val \n * call publishObject publicWrite:  mov [addr],val add [TxRec],9 jmp writeDone privateWrite: mov [addr], \nval writeDone: .. . (b) Write isolation barrier Figure 10. Read and write isolation barriers with dynamic \nescape analysis. The italicized code shows instructions due to dynamic escape analysis. In the read barrier, \nthis code is optional. In the write barrier, the asterisked code is for reference types only. Quiescence \nand other solutions that focus on privatization [52] rather than strong atomicity, do not solve general \nisolation and ordering problems such as speculative dirty reads and memory inconsistency.We also note \nthat aggressive read-setvalidation[53, 18, 58] solves neither the general problems nor the privatization \nproblem. 4. Dynamic escape analysis Dynamic escape analysis detects if an object is private (visible \nto one thread) or public (visible to multiple threads). A freshly minted object is private and becomes \npublic (is published)only when a reference leading to the object is written into either another publicobjectorastatic \n.eld.Thereadandwrite barriersforprivate objects are shorter and never perform a synchronized operation. \nOnce an object is public, our analysis leaves it public. Thread objects become public prior to the thread \nbeing spawned since both the spawning thread and the spawned thread have access to the thread object. \nFigure 10 shows the instruction sequences for read and write isolation barriers with dynamic escape analysis. \nThe italicized code shows new instructions compared to Figure 9. The read barrier reads the transaction \nrecord and the accessed adress and then skips over the rest of the barrier if the object is private. \nThisprivacycheck is optional because, liketheexclusiveanonymous and shared states, the second-lowest \nbit of the transaction record is also set in the private state. The write barrier starts from doing the \nprivacycheck and skips the rest of the barrier if the object is private. For writes of reference types \nthe write barrier also contains the instructions to publish a private object that became public because \nof the write. (These instructions are marked with asterisk in Figure 10 and are not present for write \nbarriers of non-reference types.) If the new value that is being written references a non-null private \nobject then these insturctions call the function publishObject (Figure 11) to publish the written object \nbefore it is visible to other threads. Since the object is still private, publishObject does not concern \nitself with race conditions. Each object has associated with itavtable containingamapofthe object s.elds \nholding references (slots).The slots are iteratedover and the graph rootedbythe object void publishObject(object) \n{ mark object public markStackPush(object); while (obj = markStackPop()) { forall (slots in obj) { if \n(*slot is private) { mark *slot public markStackPush(*slot); }}}} Figure 11. Object publication algorithm. \nremove barrier outside atomic transactional access read write none yes yes only read yes no only written \nno no read and written no no Figure 12. The barrier removal allowed by our not-accessed-in-transaction(NAIT)analysis. \nis traversed marking any private object encountered as public. A mark stack similar to those used by \ngarbage collectors encoded the naturally recursive nature of the traversal. Once all reachable private \nobjects are marked as public the object can be published. The termination argument for the publishObject \nroutine is similar to the one that guarantees a garbage collector s stop-the\u00adworld heap traversal terminates. \nThe graph of private objects reach\u00adable from the root object is .nite and .xed. Since the graph is private, \nobjects cannot be added during the traversal. No private objects are reachable through public objects. \nPrivate objects are immediately annotated as public when .rst encountered. Later en\u00adcounters will not \ncontinue the traversal beyond the public object, eliminatingcyclesofprivate objects.Everyhopinthetraversalthat \ndiscovers a private object reduces the number of reachable private objects. Therefore the traversal will \nhave to visit a .nite number of nodes and needs to visit them a .nite number of times. In an eager-versioning, \noptimistic-read-concurrency STM sys\u00adtem such as ours, compiler and runtime optimizations must con\u00adsider \nthat one transaction may read the dirty data of another trans\u00adaction. Such a doomed transaction will \nabort eventually as it has read data speculatively written by another concurrently-executing transaction;but \nbeforeit aborts,it can access objects publishedby the other thread. The compiler and runtime cannot assume, \nthere\u00adfore, that a private object becomes visible to other threads only on commit inside a transaction, \na write of a reference into a public object immediately publishes anyreferenced private objects. Static \nescape analysis algorithms for detecting transaction-private objects must also take this into account. \n5. Static not-accessed-in-transaction analysis This section presents an effective whole-program static \nanalysis that operates on Java bytecodes to optimize away read and write isolation barriers. The analysis \nis based on the following obser\u00advation: A memory write does not need a barrier if the memory it writes \nis never accessed in a transaction. Amemory read does not need a barrier if the memory it reads is never \nwritten in a transac\u00adtion. Figure 12 summarizes this barrier-removal opportunity. Note that in a program \nnot using transactions the analysis would remove all barriers. Thereexists considerable priorwork on \nidentifying thread-local objects [3, 15, 8]. The not-accessed-in-transaction analysis (here\u00adafter NAIT) \ncomplements thread-local analysis (hereafter TL)in two ways. First, truly thread-shared data may never \nbe accessed in a transaction. A common example is data handoff, such as objects that are transferred \namong threads via shared queues. Of\u00adten the queues are accessed in critical sections, but not the ob\u00adjects \npassed through them. NAIT optimizes this situation naturally whereas TL requires complicated additions \nof limited effective\u00adness [12]. Another example is .elds in subtypes of Thread, which are never thread-local. \nSecond, NAIT and TL have complementary staticapproximations.Forexample, TLtypicallytreatsastatic .eld \nas thread-shared even if only one thread ever uses it. 5.1 Pointer Analysis For each .eld or array access \noutside a transaction, we need to know if it might access an object that is also accessed within a transaction, \nwhich is clearly an aliasing question. We use the Paddle[7]extensiontoSoot[56]to compute points-to setsforeach \nbytecode that accesses memory. The analysis is a sound whole\u00adprogram, .eld-sensitive, .ow-insensitive \nanalysis. (See Section 5.3 for discussion regarding whole-program analysis.) Conceptually, the analysis \nis context-insensitive (OCFA) after code duplication,whereforeachmethodthereisoneversioncalled during \ntransactions and one called otherwise. Afterthis duplication (a common implementation technique for transactions), \na program point is in a transaction if and only if it is in the transactional version of a method or \nit is lexically in an atomic block. However, we do not perform this duplication on bytecodes; it is simpler \nand more ef.cient to do it lazily in the JIT. Therefore, we simulate the effect of duplication by de.ning \na new form of context-sensitivity during pointer analysis: The con\u00adtext is just in transaction or not \nin transaction , so each method is analyzed in at most two contexts. (Hence ef.ciency is within afactor \nof two of OCFA and in practice, nowhere near the worst case.) All calls inherit the current context except \ncalls lexically in atomic always analyze the callee under in transaction. For the full effect of code \nduplication, we use heap specialization, mean\u00ading abstractobjectsarepairsof allocationsiteand context.Paddle \ns support for de.ning new kinds of contexts was crucial and elegant. Hence after pointer analysis, each \nbytecode instruction that ac\u00adcesses memory has two points-to sets (one for each context of the enclosing \nmethod). Except for our novel de.nition of contexts, we are simply clients of pointer analysis. 5.2 \nAnnotating Memory Operations Given the points-to sets, annotating bytecodes with barrier-removal information \nrequires only two more passes over the code. First, for each abstract object we compute how it may be \naccessed within transactions (the left column in Figure 12) by using (1) the in transaction points-to \nset for each load and store, as well as (2) the not in transaction points-to set for loads and stores \nlexically in atomic.5 Second, for each load and store not lexically in atomic, we use its not in transaction \npoints-to set and the result of the .rst passto determineif the non-transactionalversionof the instruction \nneedsan isolation barrier.No barrieris neededifthe instructionis a load and no object in the points-to \nset is written in a transaction, orif the instructionisa store and no objectin the points-to setis read \nor written in a transaction. Though our focus has been on removing strong-atomicity bar\u00adriers, the analysis \ninformation could also be used to remove STM operations within transactions. In particular, given weak \natomicity, we could remove transactional open-for-read barriers [1] for the in transaction version if \nthat points-to set contained no objects 5For the latter, the loads and storesare in transactions,but \nthe context for the enclosing method is not in transaction. program type total barrier removed by NAIT-TL \nTL-NAIT TL+NAIT JVM98 read 12671 8796 0 12671 write 9885 7961 0 9885 tsp read 106 89 0 93 write 36 16 \n0 17 OO7 read 300 279 0 292 write 136 114 2 117 JBB read 804 364 24 798 write 621 131 344 575 Figure \n13. Static counts of barriers removed in reachable non\u00adtransactional codeby NAIT but notTL (NAIT-TL),TL \nbut notNAIT (TL-NAIT), and both analyses applied together(TL +NAIT).  potentially written in a transaction. \nThis is unsound under strong atomicity because the instruction may have a con.ict with a non\u00adtransactional \nwrite. 5.3 Details If the .rst use of a class C might be in a transaction, then its static initializer \n(method clinit)could runinatransaction. This method includes at least a write (bytecode putstatic)to \neach static .eld in C,whichwould naively prevent NAITfrom removing anybarriers on accesses to these .elds. \nHowever, Java s class-initialization se\u00admantics prevents another thread fromaccessing these .elds while \nC isbeing initialized. Therefore,an accessofa static .eldof C within C s clinit need not count for NAIT, \nand our empirical results include this improvement. Soot/Paddle s whole-program pointer analysis is sound \nas is our specialized use of it. In general, Soot s soundness guarantee does require analysis users to \nprovide classes that may be dynamically loaded or .elds/methods that may be accessed fromCcode using \nJNI or via re.ection. The benchmarks we consider do not require doing so.6 Whole-program analysis is \nnot uncommon for concurrent pro\u00adgrams [44, 48]. We believe it is practical even in a Java setting because \none could modify a virtual machine to recompute analysis information incrementally when classes are dynamically \nloaded or C code uses JNI to access Java objects. In any case, our point is to show that NAIT is especially \neffective and should be exploited whenever possible.  5.4 Static Results To give a sense of NAIT s effectiveness, \nwe counted how many barriers were removed. (For benchmark descriptions and the effect on run-time, see \nSection7.)Wealsoimplementedastraightforward TL analysis using the same points-to information for comparison \npurposes. Our results (Figure 13) show that for our benchmarks NAIT removes signi.cantly more barriers \nand it removes almost all the barriers that TL removes. The numbers we report include the non-transactional \nbarriers for all object .eld, static .eld, and array accesses for nonlibrary classes, with two exceptions. \nFirst, we do not count instructions in methods the pointer analysis determines are unreachable. Second, \nin class initializers we do not count accesses to static .elds of the class being initialized. For the \nformer, barrier removal is always allowed but cannot affect performance. For the latter, barrier re\u00admoval \nis sound without anyanalysis. In both cases, including these instructions in our counts would make our \nresults appear better. 6jbb uses re.ection,but only with constant strings. The analysis is sound without \nuser intervention in this case. Code generated for the source a.x=0; a.y+=1; checknull a cmp a, 0 t1 \n= ldfldaddr a.x jz nullPtrException [t1] = stind.wb 0 lock btr [a.txnfld],0 t2 = ldfldaddr a.y jnc conflict \nt3 = ldind.rb [t2] mov [a.x],0 t4 = add t3,1 add [a.y],1 [t2] = stind.wb t4 add [a.txnfld],9 (a) Intermediate \nrepresentation (b) Generated code Figure 14. Barrier aggregation example Qualitatively, TL is ill-suited \nto common idioms that we see in tsp and 007; for example, tsp uses .elds of a subtype of Thread for data \nthat is actually thread-local and accessed only outside transactions,but these .elds are reachable fromtwothreads \n(the one running and the one that created the object).For jbb, TL does betterbut NAIT still provides \nsigni.cant and complementary bene.t. 6. JIT optimizations Our JIT represents the non-transactional read \nand write barriers by annotations on the memory accesses. Such accesses map directly to the IA32 code \nsequences shown earlier (which vary depending on whether dynamic escape analysis is enabled) unless the \nJIT s own optimizations can either eliminate the barriers or combine the barriers for multiple memory \naccesses(via barrier aggregation). The JIT does not insert barriers for accesses to immutable .elds (e.g., \n.nal .elds and internal .elds such as the virtual method table or array length .eld) orimmutable objects \n(e.g., ob\u00adjects of certain built-in classes such as java.lang.Integer or java.lang.String). The JIT also \ndetects and eliminates barriers to thread-local ob\u00adjects via a path-sensitive intraprocedural escape \nanalysis, a tradi\u00adtional static escape analysis in contrast to the dynamic escape anal\u00adysis of Section \n4. Allocated objects begin thread-local and an it\u00aderative, forward data.ow analysis .nds that objects \nescape when they are assigned to escaped locations (static variables or .elds of escaped objects) or \nare reachable from method-call arguments. Ag\u00adgressive inlining lowers the imprecision of the latter, \nand the use of types improves precision by ruling out incompatible assignments. The code generator lowers \nthe non-transactional read and write operations to the complete barrier sequences, exposing the opera\u00adtions \nwithin the barriers to further optimization at the basic-block level. Barrieraggregation then detects \nmultiple barriers to the same object in the same basic block and combines them into a single aggregated \nbarrier. Figure 14 shows an example that accesses the same object several times and thus is amenable \nto barrier aggre\u00adgation. The IR generated by the JIT (Figure 14(a)) has two write\u00adbarrier-annotated store \noperations and one read-barrier-annotated load operation. Figure 14(b) shows the code generated after \nbar\u00adrier aggregation. 7 The instruction sequence .rst performs a null pointer check and then attempts \nto acquire the transaction record. If it succeeds,it writes .eld x of object a,updates .eldy,and .nally \nreleasesownershipby incrementing the record sversion number. The code sequence in Figure 14(b) is almost \nidentical to that fora single write.We acquire the transaction record, perform op\u00aderations on the object, \nand .nally release ownership by setting the record to the incremented version number. Whereas unoptimized \ncode acquires the record for every modi.cation of an object, ag\u00adgregated barriers acquire the record \njust once per multiple reads 7For simplicity,we showacode sequence without dynamic escape analysis. and \nwrites to an object. In the presence of dynamic escape analy\u00adsis aggregated barriers skip acquire and \nrelease of the transaction record if the object is private; the barriers also publish the objects that \nbecome public due to writes of reference types. As with the standard barrier, aggregated barriers access \na single object and perform a .nite number of operations. To guarantee these properties and avoid deadlock, \nthe JIT does not aggregate across basic blocks and does not allow function calls or access to multiple \nobjects within an aggregated barrier. 7. Performance We investigate the cost of strong atomicity and \nthe effectiveness of our optimizations using both transactional and non-transactional workloads. For \nnon-transactional benchmarks, we measure the overhead of strong atomicity by running each benchmark with \nand without our read and write isolation barriers.For transactional benchmarks,weinvestigatethe performanceof(1)aweakly \natomic execution (with no isolation barriers), (2) a strongly atomic execu\u00adtion(with isolation barriers),and(3)alock-based \nsynchronizedex\u00adecution (with synchronized regions in the source instead of atomic ones).We show that \nenforcing strong atomicity has little effect on the scalabilityof multi-threaded transactional workloads.We \nalso show that our optimizations are extremely effective in mitigating the overhead of non-transactional \nand single-threaded workloads. We performed ourexperiments on an IBM xSeries 445 machine running Windows \n2003 Server Enterprise Edition. This machine has 16 2.2GHz Intel R\u00ae processors and 16GB of shared \u00ae Xeon \nRmemory arranged across4boards. Each processor has 8KB of L1 cache, 512KB of L2 cache, and 2MB of L3 \ncache, and each board hasa64MBL4cachesharedbyits4processors.Inallexperiments, we use an object-level \ncon.ict detection granularity in our STM.   We measure the cost of strong atomicity for non-transactional \nprograms using the SPEC JVM98 [54] suite of benchmarks. We use steady-state execution time measured as \nthe execution time of the third run of a benchmark during a single invocation. Figure 15 shows the overhead \ndue to read and write isolation barriers with various levels of optimization. The No Opts bars show the \nover\u00adhead with no optimizations. The remaining bars show the cumu\u00adlative in.uence of JIT and run-time \noptimizations: Barrier Elim shows the effect of barrier elimination for immutable object and .elds and \ndata detected to be thread-local by intra-procedural es\u00adcape analysis, + Barrier Aggr adds barrier aggregation, \nand + DEA adds dynamic escape analysis (DEA). We also measured the overhead of inserting only read or \nonly write barriers (Figures 16 and 17). These data both help to understand the nature of the strong \natomicityoverheadandprovideaninsightintothecostof enforcing different levels of isolation in an STM. \nWith no optimizations, the overhead of strong atomicity is sig\u00adni.cant -up to 8 times normal program \nexecution time; the ma\u00adjority of the overhead comes from the cost of write barrier, which contains an \nexpensive atomic instruction. Barrier elimination re\u00adduces the overhead by 30% on 227 mtrt, but has little \neffect on other benchmarks. Barrier aggregation signi.cantly reduces the overhead for manybenchmarks, \nespecially for 201 compress and 222 mpegaudio where it succeeds in aggregating multiple accessestoan \narray. DEA dramatically reducesthe remainingover\u00adhead for all benchmarks except 222 mpegaudio by practically \neliminating the cost of write barriers. (For 201 compress its ef\u00adfect is especially impressive -the overhead \ngoes down by an order of magnitude -from 700% to 40%.) DEA fails to remove the barrier overhead for 222 \nmpegaudio because that benchmark op\u00aderates mostly on static arrays and static data is visible to multiple \nthreads. The behavior of 222 mpegaudio shows that programming style can have signi.cant effect on the \nperformance of a strongly atomic STM system -unnecessarily exposing thread-private data to multiple threads \nmay have detrimental effect on performance. Notethat Figures15,16and17havenobarsfortheoverheadin the \npresence of the whole-program optimizations. This is because for non-transactional programs not-accessed-in-transaction \nanaly\u00adsis(NAIT)removes all the barriers, and, thus, completely eliminates the overhead of strong atomicity. \nWe investigate the effect of strong atomicity on scalability using three multi-threaded transactional \nbenchmarks -Tsp [57], OO7 [59] and SpecJBB [55].For all the benchmarks, we created transactional versions \nby replacing the original Java synchroniza\u00adtion with transactions.8 Tsp solves a traveling salesman problem. \nIn this benchmark, threads perform their searches independently, 8In SpecJBB we did not convert to transactions \nthe critical sections con\u00adtaining wait/notify and warehouse initialization Figure 18. Tsp execution time \nover multiple threads.  but share partially completed work and the best-answer-so-far via shared memory. \nOO7 performs a number of traversals over a syn\u00adthetic database organized asa tree.Traversals either lookup \n(read\u00adonly) or update the database. OO7 allows transactional access (or locking,inthe originalversionofthe \nbenchmark)atdifferentlevels of the tree. In our experiments we used root locking and a mixture of 80% \nlookups and 20% updates. SpecJBB, a well known Java server benchmark, emulates a 3-tier system for a \nwholesale com\u00adpanywith multiple warehouses. Figures 18, 19 and 20 show the performance of Tsp, OO7 and \nSpecJBB from1 to16 threads, where each threadis mappedtoa different processor. The Synch bars show the \nperformance of the lock-based versions, the Weak Atom bars show the performance of transactional versions \nunder weak atomicity, and the rest of the bars show the performance of the transactional versions under \nstrong atomicity with various levels of optimizations. The Strong Atom NoOpts bars show the performance \nwith no optimizations, +JitOpts add barrier elimination and barrier aggregation, +DEA adds DEA, and +Whole-Prog \nOpts add static whole-program op\u00adtimizations(NAIT andTL). The cost of unoptimized strong atomicity vs. \nweak atomicity for a single-threaded execution varies signi.cantly depending on the benchmark (Tsp, which \nperforms a lot of non-transactional ac\u00adcesses, is about 3 times slower; but there is less than 11% over\u00adhead \nfor OO7 and SpecJBB, which spend the majority of their time in transactional code). Optimizations (especially \nNAIT), reduce the overhead of strong atomicity to less than 27%. (OO7 with DEA and SpecJBB with DEAand \nwhole-program optimizations areeven slightlyfaster than their weakly atomicversions. This happens be\u00adcause \nfor OO7 dynamic escape analysis also speeds up some of the open-for-write operations [1] inside transactions.) \nAlso note that strong atomicity has no detrimental effect on scalability. For all three benchmarks strongly \natomic executions scale as well as weakly atomic executions and as well or better than lock-based versions \nof the benchmarks. (Lock-based OO7 does not scale due to coarse-grained synchronization.) Moreover, as \nthe number of threads increases, the cost of strong atomicity compared to weak atomicity drops further. \nWith 16 threads the strongly atomic versions of Tsp, OO7 and SpecJBB are only 2%, 12% and 1% slower than \ntheir weakly atomic counterparts. 8. Related work Several researchers [51, 21, 28, 39, 29] have implemented \nSTM APIs that allow a programmer to access memory transactionally. These systems guarantee transactional \nbehavior only for accesses that go through the STM API they do not guarantee isolation in the presence \nof con.icting accesses that do not go through the STM API. Other researchers [25, 27, 1] have introduced \n.rst-class transaction constructs into Java or C# and implemented them via weak-atomicity STMs. Harris \net.al., [26] add transactions to Concurrent Haskell, a functional language. Their approach uses Haskell \ns monadic type system to segregate transactional data from other mutable shared data, thereby ensuring \nthat transactional data is accessed only within a transaction. Neither the data segregation nor the monadic \ntype system map naturally to an imperative language such as Java. On a uniprocessor, one can implement \nstrong atomicity in soft\u00adware using scheduler-based techniques to ensure no transaction is active during \na non-transactional access [47, 37]. While extremely ef.cient on uniprocessors, the approach does not \nextend naturally to multiprocessors. The new HPCS language proposals Fortress [4], X10 [14], and Chapel \n[16] all de.ne a transactional memory construct in lieuof locks.Fortress[4] usesthe terms shared and \nlocal where we use public and private;it states that segregating the two will enable optimizations of \ntransactional reads and writes. The current X10 reference implementation implements atomic blocks as \na single mutual exclusion lock [14]. These languages are still in .ux and currently do not appear to \nrequire strong atomicity. Hardware transactional memory (HTM) systems [30, 24, 13, 41] provide strong \natomicity naturally because they leverage the existing cache coherence logic to implement transactions. \nRecent workhasprovidedwaysto support transactions with memory foot\u00adprints that do not .t in cache [46, \n5, 42, 43]. Hybrid transac\u00adtional memory [17, 33] provides architectural support for mixing HTMs and \nSTMs, relying on the latter when transactions become too large. Hardware accelerated STM (HASTM) provides \narchitec\u00adtural support to accelerate transactions executed entirely in soft\u00adware [50]. Our work establishes \nthat STMs can provide scalable strong atomicity, which is important when transactional hardware is unavailable \n(e.g., today), and to guide research on architectural support for transactional memory. Domani et al. \n[19] dynamically segregated thread local objects from globally visible objects, in much the same way \nwe do, to reduce the cost of garbage collection and synchronization. Lev and Maessen [36] sketch techniques \nsimilar to our dynamic escape analysis to implement strong atomicity. They do not describe an implementation \nand thus do not present implementation details and quantitative measurements. Compilers have used static \nescape analysis for removing syn\u00adchronization overheads and stack allocation of objects [11, 15, 8, 3, \n48]. These escape analysis techniques could also be used to eliminate strong atomicity barriers,but we \ndemonstrated that not\u00adaccessed-in-transaction is much more effectiveon our benchmarks. Whole-program \nanalysis is common in research on eliminat\u00ading synchronization overhead [48] or detecting data races \n[44, 20]. Autolocker [40] uses whole-program analysis to implement trans\u00adactions in terms of locks, using \nprogrammer annotations to guide what locks protect what data. Our whole-program not-accessed-in\u00adtransaction \nanalysis is novel because it targets lowering the cost of strong atomicity. Hindman and Grossman [31] \nbrie.y sketched a similar idea,but they had neither points-to information (relying only on type-based \nalias information) nor an optimized implemen\u00adtation of transactions. Theyalso performed the analysis \nafter creat\u00ading two versions of each method rather than treating in a transac\u00adtion as a new form of context-sensitivity. \n9. Conclusion The success of transactional memory depends on simple, intuitive rules and semantics. Isolation \nand consistent ordering are among the most importantof these.Wehaveshownhow strong atomicity meets the \nsimplicity criteria better than weak atomicity by catego\u00adrizing and characterizing non-intuitive weak \natomicity anomalies. We have shown how the cost of providing simpler and stronger semanticsis amelioratedby \nournovel optimizations, includingdy\u00adnamic escape analysis that leverages a conservative runtime ap\u00adproximation \nof thread local data to avoid barriers, and new static compiler optimizations that elide read and write \nbarriers for ob\u00adjects not used in transactions.We have implemented these seman\u00adtics and optimizations \nin the context of a high performance system and shown that strong atomicity is competitivewith weak atomicity \nin performance while retaining simple and intuitive semantics. References [1] A.-R. Adl-Tabatabai, B. \nT. Lewis, V. S. Menon, B. R. Murphy, B. Saha, and T. Shpeisman. Compiler and runtime support for ef.cient \nsoftware transactional memory. In PLDI 2006. [2] S. Adve and K. Gharachorloo. Shared memory consistencymodels: \nAtutorial. IEEE Computer, 29(12):66 76, 1996. [3] J. Aldrich, E. G. Sirer, C. Chambers, and S. Eggers. \nComprehensive synchronization elimination for Java. Sci. Comput. Programming, 47(2 3), May June 2003. \n[4]E. Allen,D. Chase,J. Hallett,V. Luchangco,J.-W. Maessen,S.Ryu, G.L.Steele,Jr.,andS.Tobin-Hochstadt.The \nFortresslanguagespeci\u00ad.cationversion 1.0a. http://research.sun.com/projects/plrg/fortress.pdf, 2006. \n[5] C. S. Ananian, K. Asanovic, B. C.Kuszmaul, C. E. Leiserson, and S. Lie. Unbounded transactional memory. \nIn HPCA 2005. [6] C. S. Ananian and M. Rinard. Ef.cient object-based software transactions. In SCOOL \n2005. [7]M. Berndl,O.Lhot\u00b4ak,F.Qian,L. Hendren,andN. Umanee. Points-to analysis using BDDs. In PLDI \n2003. [8] B. Blanchet. Escape analysis for object-oriented languages: Application to Java. In OOPSLA \n1999. [9] C. Blundell, E. C. Lewis, and M. Martin. Subtleties of transactional memory atomicity semantics. \nComputer Architecture Letters, 5(2), Nov. 2006. [10] H. Boehm. Threads cannot be implemented as a library. \nIn PLDI 2005. [11] J. Bogda and U.H\u00a8olzle. Removing unnecessary synchronization in Java. In OOPSLA 1999. \n[12] C. Boyapati, R. Lee, and M. Rinard. Ownership types for safe programming: Preventing data races \nand deadlocks. In OOPSLA 2002. [13] B. D. Carlstrom, J. Chung, A. McDonald, H. Cha., C.Kozyrakis, and \nK. Olukotun. The Atomos transactional programming language. In PLDI 2006. [14] P. Charles, C. Donawa, \nK. Ebcioglu, C. Grothoff, A. Kielstra, C. von Praun,V. Saraswat, andV. Sarkar. X10: an object-oriented \napproach to non-uniform cluster computing. In OOPSLA 2005. [15] J.-D.Choi,M.Gupta,M.J. Serrano,V.C. Sreedhar,andS.P. \nMidkiff. Escape analysis for Java. In OOPSLA 1999. [16] Cray Inc. Chapel Speci.cation 0.4. http://chapel.cs.washington.edu/ \nspeci.cation.pdf, 2005. [17] P. Damron, A. Fedorova, Y. Lev, V. Luchangco, M. Moir, and D. Nussbaum. \nHybrid transactional memory. In ASPLOS 2006. [18]D.Dice,O.Shalev,andN.Shavit.Transactional LockingII.In \nDISC 2006. [19]T. Domani,G. Goldshtein,E.K.Kolodner,E.Lewis,E. Petrank, and D. Sheinwald. Thread-local \nheaps for Java. In ISMM 2002. [20] C. Flanagan and S. N. Freund. Type inference against races. In SAS \n2004. [21] K. Fraser. Practical lockfreedom. PhD thesis, Cambridge University Computer Laboratory, 2003. \nTechnical Report UCAM-CL-TR-579. [22] J. Gray and A. Reuter. Transaction Processing: Concepts and Techniques. \nMorgan Kaufmann, 1993. [23]D. Grossman,J. Manson,andW.Pugh. Whatdo high-level memory models mean for \ntransactions? In MSPC 2006. [24] L. Hammond, B. D. Carlstrom,V.Wong, B. Hertzberg, M. Chen, C. Kozyrakis, \nand K. Olukotun. Programming with transactional coherence and consistency(tcc). In ASPLOS 2004. [25] \nT. Harris and K. Fraser. Language support for lightweight transac\u00adtions. In OOPSLA 2003. [26] T. Harris, \nS. Marlow, S. P. Jones, and M. Herlihy. Composable memory transactions. In PPoPP 2005. [27]T. Harris,M. \nPlesko,A. Shinnar, andD.Tarditi. Optimizing memory transactions. In PLDI 2006. [28] M. Herlihy, V. Luchangco, \nM. Moir, and I. William N. Scherer. Software transactional memory for dynamic-sized data structures. \nIn PODC 2003. [29] M. Herlihy,V. Luchangco,andM. Moir. A.exible framework for implementing software transactional \nmemory. In OOPSLA 2006. [30] M. Herlihyand J. E. B. Moss. Transactional memory: architectural support \nfor lock-free data structures. In ISCA 1993. [31] B. Hindman and D. Grossman. Atomicity via source-to-source \ntranslation. In MSPC 2006. [32] R. L. Hudson, B. Saha, A.-R. Adl-Tabatabai, and B. C. Hertzberg. Mcrt-malloc:Ascalable \ntransactional memory allocator. In ISMM 2006. [33] S.Kumar, M. Chu, C. J. Hughes,P.Kundu, and A. Nguyen. \nHybrid transactional memory. In PPoPP 2006. [34] H. T. Kung and J. T. Robinson. On optimistic methods \nfor concurrencycontrol. ACMTrans. Database Syst., 6(2), 1981. [35] J. Larus and R. Rajwar. Transactional \nMemory. Morgan&#38;Claypool Publishers, 2006. [36] Y. Lev and J.-W. Maessen. Towards a safer interaction \nwith transactional memoryby tracking object visibility. In SCOOL 2005. [37] J. Manson, J. Baker, A. Cunei, \nS. Jagannathan, M. Prochazka, B. Xin, andJ.Vitek. Preemptible atomic regions for real-timeJava. In IEEE \nReal-Time Systems Symposium 2005. [38] J. Manson,W. Pugh, and S.V. Adve. The Java memory model. In POPL \n2005. [39]V.J. Marathe,W.N. Scherer, andM.L. Scott. Adaptive software transactional memory. In International \nSymposium on Distributed Computing 2005. [40] B. McCloskey, F. Zhou, D. Gay, and E. Brewer. Autolocker: \nsynchronization inference for atomic sections. In POPL 2006. [41] A. McDonald, J. Chung, B. D. Carlstrom, \nC. Cao Minh, H. Cha., C.Kozyrakis, andK. Olukotun. Architectural semantics for practical transactional \nmemory. In ISCA 2006. [42]K.E. Moore,J. Bobba,M.J.Moravan,M.D.Hill,andD.A.Wood. LogTM: Log-based transactional \nmemory. In HPCA 2006. [43]M.J. Moravan,J. Bobba,K.E. Moore,L.Yen,M.D. Hill,B. Liblit, M. M. Swift, and \nD. A. Wood. Supporting nested transactional memory in LogTM. In ASPLOS 2006. [44] M. Naik, A. Aiken, \nand J. Whaley. Effective static race detection for Java. In PLDI 2006. [45]Y.Ni,V. Menon, A.-R. Adl-Tabatabai,A.L. \nHosking,R.L. Hudson, J.E.B. Moss,B. Saha, andT. Shpeisman. Open Nestingin Software Transactional Memory. \nInPPoPP 2007. [46]R.Rajwar,M. Herlihy,andK.Lai.Virtualizing transactional memory. In ISCA 2005. [47] \nM.F. RingenburgandD. Grossman. AtomCaml: .rst-class atomicity via rollback. In ICFP 2005. [48] E. Ruf. \nEffective synchronization removal for Java. In PLDI 2000. [49] B. Saha, A.-R. Adl-Tabatabai, R. Hudson, \nC. C. Minh, and B. Hertzberg. McRT-STM: A high performance software trans\u00adactional memory system for \na multi-core runtime. In PPoPP 2006. [50] B. Saha, A.-R. Adl-Tabatabai, andQ. Jacobson. Architectural \nsupport for software transactional memory. In MICRO2006. [51] N. Shavit andD.Touitou. Software transactional \nmemory. In PODC 1995. [52] M. F. Spear, V. J. Marathe, L. Dalessandro, and M. L. Scott. Privatization \ntechniques for software transactional memory.Technical Report 915, University of Rochester, Computer \nScience Dept., 2007. [53] M.F. Spear,V. J. Marathe,W. N. Scherer, and M. L. Scott. Con.ict detection \nandvalidation strategies for software transactional memory. In DISC 2006. [54] Standard Performance Evaluation \nCorporation. SPEC JVM98 Benchmarks. http://www.spec.org/osg/jvm98. [55] Standard Performance Evaluation \nCorporation. SPEC JBB2000, 2000. See http://www.spec.org/jbb2000. [56] R.Vall\u00b4ee-Rai, L. Hendren,V. Sundaresan,P. \nLam, E. Gagnon, and P. Co. Soot -a Java optimization framework. InCASCON 1999. [57] C. von Praun and \nT. R. Gross. Static con.ict analysis for multi\u00adthreaded object-oriented programs. In PLDI 2003. [58]C.Wang,W.-Y.Chen,Y.Wu,B.Saha,and \nA.-R. Adl-Tabatabai. Code generation and optimization for transactional memory constructs in an unmanaged \nlanguage. In CGO 2007. [59] A.Welc, S. Jagannathan, and A. L. Hosking. Revocation techniques for Java \nconcurrency. In Concurrency and Computation:Practice and Experience. JohnWileyand Sons, 2005.   \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Transactional memory provides a new concurrency control mechanism that avoids many of the pitfalls of lock-based synchronization. High-performance software transactional memory (STM) implementations thus far provide <i>weak atomicity</i>: Accessing shared data both inside and outside a transaction can result in unexpected, implementation-dependent behavior. To guarantee isolation and consistent ordering in such a system, programmers are expected to enclose all shared-memory accesses inside transactions.</p> <p>A system that provides <i>strong atomicity</i> guarantees isolation even in the presence of threads that access shared data outside transactions. A strongly-atomic system also orders transactions with conflicting non-transactional memory operations in a consistent manner.</p> <p>In this paper, we discuss some surprising pitfalls of weak atomicity, and we present an STM system that avoids these problems via strong atomicity. We demonstrate how to implement non-transactional data accesses via efficient read and write barriers, and we present compiler optimizations that further reduce the overheads of these barriers. We introduce a <i>dynamic escape analysis</i> that differentiates private and public data at runtime to make barriers cheaper and a <i>static not-accessed-in-transaction</i> analysis that removes many barriers completely. Our results on a set of Java programs show that strong atomicity can be implemented efficiently in a high-performance STM system.</p>", "authors": [{"name": "Tatiana Shpeisman", "author_profile_id": "81100439172", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "PP14154461", "email_address": "", "orcid_id": ""}, {"name": "Vijay Menon", "author_profile_id": "81100196596", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "P291114", "email_address": "", "orcid_id": ""}, {"name": "Ali-Reza Adl-Tabatabai", "author_profile_id": "81100032153", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "PP14023844", "email_address": "", "orcid_id": ""}, {"name": "Steven Balensiefer", "author_profile_id": "81100252268", "affiliation": "University of Washington, Seattle, WA", "person_id": "P731933", "email_address": "", "orcid_id": ""}, {"name": "Dan Grossman", "author_profile_id": "81405594870", "affiliation": "University of Washington, Seattle, WA", "person_id": "PP39070950", "email_address": "", "orcid_id": ""}, {"name": "Richard L. Hudson", "author_profile_id": "81100566849", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "P242189", "email_address": "", "orcid_id": ""}, {"name": "Katherine F. Moore", "author_profile_id": "81331499931", "affiliation": "University of Washington, Seattle, WA", "person_id": "P871679", "email_address": "", "orcid_id": ""}, {"name": "Bratin Saha", "author_profile_id": "81100311903", "affiliation": "Intel Corporation, Santa Clara, CA", "person_id": "P32179", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250744", "year": "2007", "article_id": "1250744", "conference": "PLDI", "title": "Enforcing isolation and ordering in STM", "url": "http://dl.acm.org/citation.cfm?id=1250744"}