{"article_publication_date": "06-10-2007", "fulltext": "\n Sound and Precise Analysis of Web Applications for Injection Vulnerabilities * Gary Wassermann Zhendong \nSu University of California, Davis {wassermg, su}@cs.ucdavis.edu Abstract Web applications are popular \ntargets of security attacks. One com\u00admon type of such attacks is SQL injection, where an attacker exploits \nfaulty application code to execute maliciously crafted database queries. Both static and dynamic approaches \nhave been proposed to detect or prevent SQL injections; while dynamic approaches provide protection for \ndeployed software, static ap\u00adproaches can detect potential vulnerabilities before software de\u00adployment. \nPrevious static approaches are mostly based on tainted information .ow tracking and have at least some \nof the following limitations: (1) they do not model the precise semantics of input sanitization routines; \n(2) they require manually written speci.ca\u00adtions, either for each query or for bug patterns; or (3) they \nare not fully automated and may require user intervention at various points in the analysis. In this \npaper, we address these limitations by proposing a precise, sound,and fully automated analysis technique \nfor SQL injection. Our technique avoids the need for speci.ca\u00adtions by considering as attacks those queries \nfor which user input changes the intended syntactic structure of the generated query. It checks conformance \nto this policy by conservatively characterizing the values a string variable may assume with a context \nfree gram\u00admar, tracking the nonterminals that represent user-modi.able data, and modeling string operations \nprecisely as language transducers. We have implemented the proposed technique for PHP, the most widely-used \nweb scripting language. Our tool successfully discov\u00adered previously unknown and sometimes subtle vulnerabilities \nin real-world programs, has a low false positive rate, and scales to large programs (with approx. 100K \nloc). Categories and Subject Descriptors D.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation \nValidation General Terms Languages, Security, Veri.cation Keywords Static Analysis, String Analysis, \nWeb Applications * This research was supported in part by NSF NeTS-NBD Grant No. 0520320, NSF CAREER \nGrant No. 0546844, NSF CyberTrust Grant No. 0627749, and a generous gift from Intel. The information \npresented here does not necessarily re.ect the position or the policy of the Government and no of.cial \nendorsement should be inferred. Permission to make digital or hard copies of all or part of this work \nfor personal or classroom use is granted without fee provided that copies are not made or distributed \nfor pro.t or commercial advantage and that copies bear this notice and the full citation on the .rst \npage. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior \nspeci.c permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, USA. Copyright c &#38;#169; \n2007 ACM 978-1-59593-633-2/07/0006. . . $5.00 1. Introduction Web applications enable much of today s \nonline business including banking, shopping, university admissions, and various governmen\u00adtal activities. \nAnyone with a web browser can access them, and the data they manage typically has signi.cant value both \nto the users and to the service providers. Consequently, vulnerabilities that al\u00adlow an attacker to compromise \na web application s control of its data pose a signi.cant threat. SQL command injection vulnerabil\u00adities \n(SQLCIVs) comprise most of this class. Not only are SQL-CIVs serious, but they are pervasive. In 2006, \n14% of the CVEs (i.e., reported vulnerabitilities) were SQLCIVs, making SQL injec\u00adtion the second most \nfrequently reported security threat [9]. Some web security analysts speculate that because web applications \nare highly accessible and databases often hold valuable information, the percentage of SQL injection \nattacks being executed is signi.\u00adcantly higher than the percentage of reported vulnerabilities would \nsuggest [26]. SQLCIVs are common primarily because applications typically communicate with backend databases \nby passing queries as strings. Figure 1 shows the typical three-tiered web application architecture and \nillustrates the communication among the tiers: web browsers provide a ubiquitous user interface, application \nservers manage the business logic, and back-end databases store the persistent data. Because the application \nlayer uses a low-level, queries-as-strings API to communicate with the database, the application constructs \nqueries via low-level string manipulation and treats untrusted user inputs as isolated lexical entities. \nThis is especially common in web applications written in scripting languages such as PHP, which generally \ndo not provide more sophisticated APIs and use strings as the default representation for data and code. \nConsequently, some paths in application code may incorporate user input unmodi.ed or unchecked into database \nqueries. The modi.cations/checks of user input on other paths may not adequately constrain the input \nto function in the generated query as the application programmer intended (see Figure 2 for an example). \n1.1 Existing Approaches Many approaches have been proposed for preventing SQL injection attacks, both \ndynamic [7, 23, 24, 25] and static [12, 18, 31]. Run\u00adtime approaches are useful for protecting deployed \nsoftware, but static approaches are desirable during software development and testing for a number of \nreasons. First, a single programming error often manifests itself as multiple different bugs, so statically \nveri\u00adfying code to be free from one kind of error (e.g., static type check\u00ading) helps to reduce the risk \nof other errors. Second, the overhead that general techniques incur signi.cantly exceeds the overhead \nof appropriate, well-placed checks on untrusted input. Even if the net\u00adwork latency dominates the overhead \nof a runtime check for a sin\u00adgle user, the added overhead can prevent a server from functioning Figure \n1. Web application architecture. effectively under a heavy load of requests. Finally, some runtime techniques \n[23, 24] require a modi.ed runtime system, which con\u00adstitutes a practical limitation in terms of deployment \nand upgrading. Static analyses to .nd SQLCIVs have also been proposed, but none of them runs without \nuser intervention and can guarantee the absence of SQLCIVs. String analysis-based techniques [3, 20] \nuse formal languages to characterize conservatively the set of values a string variable may assume at \nruntime. They do not track the source of string values, so they require a speci.cation, in the form of \na regular expression, for each query-generating point or hotspot in the program a tedious and error-prone \ntask that few program\u00admers are willing to do. Static taint analyses [12, 18, 31] track the .ow of tainted \n(i.e., untrusted) values through a program and re\u00adquire that no tainted values .ow into hotspots. Because \nthey use a binary classi.cation for data (tainted or untainted), they classify functions as either being \nsantitizers (i.e., all return values are un\u00adtainted) or being security irrelevant. Because the policy \nthat these techniques check is context-agnostic, it cannot guarantee the ab\u00adsence of SQLCIVs without \nbeing overly conservative. For exam\u00adple, if the escape quotes function (which precedes quotes with an \nescaping character so that they will be interpreted as charac\u00adter literals and not as string delimiters) \nis considered a sanitizer, an SQLCIV exists but would not be found in an application that con\u00adstructs \na query using escaped input to supply an expected numeric value, which need not be delimited by quotes. \nAdditionally, static taint analyses for PHP typically require user assistance to resolve dynamic includes \n(a construct in which the name of the included .le is generated dynamically). 1.2 Our Approach We propose \na sound, automated static analysis algorithm to over\u00adcome the limitations described above. It is grammar-based; \nwe model string values as context free grammars (CFGs) and string operations as language transducers \nfollowing Minamide [20]. This string analysis-based approach tracks the effects of string opera\u00adtions \nand retains the structure of the values that .ow into hotspots (i.e., where query construction occurs). \nIf all of each string in the language of a nonterminal comes from a source that can be in.u\u00adenced by \na user, we label the nonterminal with one of two labels. We assign a direct label if a user can in.uence \nthe source di\u00adrectly (as with GET parameters) and a indirect label if a user can in.uence the source \nindirectly (as with data returned by a database query). Such labeling tracks the source of string values. \nWe use a syntax-based de.nition of SQL injection attacks [25], which re\u00adquires that input from a user \nbe syntactically isolated within a gen\u00aderated query. This policy does not need user-provided speci.ca\u00adtions. \nFinally, we check policy conformance by .rst abstracting the labeled subgrammars out of the generated \nCFG to .nd their con\u00adtexts. We then use regular language containment and context free language derivability \n[28], to check that each subgrammar derives only syntactically isolated expressions. We have implemented \nthis analysis for PHP, and applied it to several real-world web applications. Our tool scales to large \ncode bases it successfully analyzes the largest PHP web application ... 01 isset ($ GET['userid']) ? \n02 $userid =$ GET['userid'] :$userid = ''; 03 if ($USER['groupid'] != 1) 04 { 05 // permission denied \n06 unp msg($gp permserror); 07 exit; 08 } 09 if ($userid == '') 10 { 11 unp msg($gp invalidrequest); \n12 exit; 13 } 14 if (!eregi('[0-9]+', $userid)) 15 { 16 unp msg('You entered an invalid user ID.'); 17 \nexit; 18 } 19 $getuser =$DB->query(\"SELECT * FROM `unp user`\" 20 .\"WHERE userid='$userid'\"); 21 if (!$DB->is \n single row($getuser)) 22 { 23 unp msg('You entered an invalid user ID.'); 24 exit; 25 } ... Figure 2. \nExample code with an SQLCIV. previously analyzed in the literature (about 100K loc). It discovered many \nvulnerabilities, some previously unknown and some based on insuf.cient .ltering, and generated few false \npositives.  2. Overview In order to motivate our analysis, we .rst present the policy that de.nes SQLCIVs, \nand then give an overview of how our analysis checks web applications against that policy. 2.1 SQL Command \nInjection Vulnerabilities This section illustrates SQLCIVs and formally de.nes them. 2.1.1 Example Vulnerability \nFigure 2 shows a code fragment excerpted from Utopia News Pro, a real-world news management system written \nin PHP; we will use this code to illustrate the key points of our algorithm. This code authenticates \nusers to perform sensitive operations, such as managing user accounts and editing news sources. Initially, \nthe variable $userid gets assigned data from a GET parameter, which a user can easily set to arbitrary \nvalues. The code then performs two checks on the value of $userid before incorporating it into an SQL \nquery. The query should return a single row for a legitimate user, and no rows otherwise. From line 14 \nit is clear that the programmer intends $userid to be numeric, and from line 20 it is clear that the \nprogrammer intends that $userid evaluate to a single value in the SQL query for comparison to the userid \ncolumn. However, because the regular expression on line 14 lacks anchors ( ^ and $ for the beginning \nand end of the string, respectively), any value for $userid that has at least one numeric character will \nbe included into the generated query. If a user sets the GET parameter to 1'; DROP TABLE unp user; -- \n, this code will send to the database the folloing query: SELECT * FROM `unp user` WHERE userid='1'; \nDROP TABLE unp user; --' and delete user account data.   Figure 3. SQLCIV analysis work.ow. 2.1.2 \nDe.nition of SQLCIVs This section presents the formal de.nition of command injection attacks that serves \nas the basis for the policy we seek to enforce. A web application takes input strings, which it may modify, \nand generates a query in the form of a string, usually by combining constant strings and .ltered inputs. \nTo re.ect this, we previously de.ned a web application as follows [25]: De.nition 2.1 (Web Application). \nA web application P : (S * ,...,S *). S * is a mapping from user inputs (over an alphabet S) to query \nstrings (over S). In particular, P is given by {(f1,...,fn),(s1,...,sm)}where: fi :S * .S * is an input \n.lter;  si :S * is a constant string.  The argument to P is an k-tuple of input strings (i1,...,ik),and \nP returns a query q =q1 +...+q\u00a3 where, for 1=j =e, j s where s.{s1,...,sm} qj =f(i) where f .{f1,...,fn}. \ni .{i1,...,ik} That is, each qj is either a static string or a .ltered input. De.nition 2.1 primarily \nserves to help de.ne SQL command injection attacks. This de.nition does not allow certain string oper\u00adations \nthat real web applications can do, but, signi.cant for a static analysis, it does allow arbitrary control \nconstructs, arbitrary .lter\u00ading, and concatenation. Sections 3.1.2 and 3.1.3 address other op\u00aderations \nthat web applications do and how to handle them with a static analysis. The syntactic structure of the \ngenerated query determines how it will be evaluated. We state here our de.nition of SQL command injection \nattacks [25] in terms of sentential forms. Let G =(V,S,S,R)be a context-free grammar with non\u00adterminals \nV,terminals S, a start symbol S, and productions R. Let .G denote derives in one step so that aA\u00df .G \na.\u00df if A .. .R,and let .G* denote the re.exive transitive closure of .G. If S .G * .,then . is a sentential \nform. The following de.nition formalizes syntactic con.nement: De.nition 2.2 (Syntactic Con.nement). \nGiven a grammar G = (V,S,S,R)and a string s = s1s2s3 . S * , s2 is syntactically con.ned in s iff there \nexists a sentential form s1Xs3 such that X .V and S .G * s1Xs3 .G * s1s2s3. In the attack shown in Section \n2.1.1, the user-provided sub\u00adstring is not syntactically con.ned. The criterion of syntactic con\u00ad.nement \neffectively distinguishes SQL injection attacks from safe queries [25]. We therefore attempt to enforce \nthe policy that user\u00adprovided substrings be syntactically con.ned. De.nition 2.3 (SQL Command Injection \nAttack). Given a web application P ={(f1,...,fn),(s1,...,sm)}and a query string qconstructed from the \ninput (i1,...,ik), qis a command injection attack if there exists i .{i1,...,ik}and f .{f1,...,fm}such \nthat q =q1 +f(i)+q2 and f(i)is not syntactically con.ned in q with respect to the SQL grammar. A web \napplication has an SQLCIV if it may generate an SQL command injection attack.  2.2 Analysis Overview \nOur analysis takes PHP .les as input and returns as output either a list of bug reports or the message \nveri.ed. In order to provide useful bug reports, we .rst categorize sources of untrusted input as being \neither direct or indirect. Direct sources, such as GET parameters, provide data immediately from users; \nindirect sources, such as results from a database query, pro\u00advide data from a source whose data may come \nfrom untrusted users. In practice, the rise of attacks from indirect sources is less severe than that \nof standard injection attacks for two reasons. First, pro\u00adgrams often regulate which data is allowed \nto go into the database (or other sources), and second, attackers must pass through more steps and take \nmore time to execute an indirect attack than to exe\u00adcute a standard injection attack. Figure 3 shows \na high-level overview of our analysis algorithm. It has two main phases. The .rst phase generates a conservative, \nannotated approximation of the query strings a program may gen\u00aderate; the annotations show which substrings \nin the query string are untrusted, i.e., are from either DIRECT or INDIRECT sources. This phase is based \non existing string analysis techniques [20] aug\u00admented to propagate taint information. The string-taint \nanalyzer takes as input a PHP .le that provides the top-level code for a web page (analogous to a main \nfunction in C). As it encounters dynamic include statements, it determines the possible string val\u00adues \nof the argument to the include, and analyzes those .les as well. The string-taint analyzer represents \nthe set of query strings using an annotated context free grammar (CFG) the nontermi\u00adnals whose sub-languages \nrepresent untrusted strings are labeled with direct or indirect, as appropriate. We choose to represent \nsets of strings with CFGs for several reasons: (1) tainted substring boundaries can be represented simply \nby labeling certain nonter\u00adminals; (2) our policy is grammar-based, and a CFG representation can capture \ncontext-free query construction that follows the policy; (3) regular expression-based string operations \n(common in PHP) can be represented as .nite state transducers (FSTs), and the image of a CFG over an \nFST is context free. The second phase of our analysis takes the annotated CFG pro\u00adduced by the .rst phase, \nand checks whether all strings in the lan\u00adguage of the CFG are safe, i.e., they are not SQL command in\u00adjection \nattacks according to De.nition 2.3. This analysis checks for common cases (of both SQL command injection \nattacks and attack\u00adfree grammars) ef.ciently by (1) abstracting the subgrammars that represent untrusted \nsubstrings out of the larger CFG, (2) determin\u00ading the syntactic contexts of those subgrammars within \nthe larger CFG, and (3) checking for (the absence of) policy violating strings in the languages of the \nsubgrammars. For large grammars, this is query . query1' query1 . query2 userid query2 . query3 WHERE \nuserid=' query3 . SELECT * FROM `unp user` userid . GETuid GETuid . S* [0 9] S* direct = {GETuid} indirect \n= {} Figure 4. Grammar productions of possible query strings from Figure 2. signi.cantly more ef.cient \nthan checking the language of the gen\u00aderated CFG as a whole. If the policy conformance checker .nds any \nviolations, it issues a bug report. Because this algorithm is sound, if it does not issue any bug reports, \nthe PHP code is guaranteed to be free from SQLCIVs. To illustrate this algorithm on the example code \nin Figure 2, the string-taint analysis will produce the grammar productions shown in Figure 4; the annotations \nare shown in terms of sets of nonter\u00adminals annotated with direct and indirect, respectively. The regular \nexpression notation on the right hand side of the last rule is notational shorthand intended to simplify \nthe presentation. The grammar for userid re.ects the regular expression match on line 14, because the \nstring-taint analyzer propogates the regular expression predicate. The nonterminal GETuid has the label \ndirect, because it represents strings from a GET parameter. The policy-conformance checker then receives \nthis labeled grammar. The check .rst replaces the annotated GETuid nonter\u00adminal with a new terminal t/. \nS. By intersecting this modi.ed grammar with an appropriate regular language, the checker .nds that for \nall sentential forms s1.GETuid.s2 derivable from query, GETuid is between quotes in the syntactic position \nof a string lit\u00aderal. The checker therefore uses another regular language intersec\u00adtion to check the \nlanguage rooted at GETuid for un-escaped quotes. When it .nds them, it issues a bug report. The checker \ndoes not only check for the case of string literals, but that suf.ces for this example.  3. Analysis \nAlgorithm This section describes our analysis algorithm in detail. 3.1 String-Taint Analysis The .rst \nphase of our analysis combines ideas from static taint analysis with string analysis. 3.1.1 Adapting \nString Analysis String analysis has the goal of producing a representation of all strings values that \na variable may assume at a given program point. This goal does not imply any relationship between the \nstructure of that representation and the way that the program produces those values. If the string analysis \nrepresents languages as .nite automata and it determinizes intermediate results, the .nal DFA will have \nlittle relation to the program s data.ow [3]. Our analysis has the goal of producing not only a representation \nof all string values that a variable may assume, but also a function from string values to substrings \nwhose values come from direct or indirect sources. In terms of De.nition 2.3, we need to identify occurences \nof f(i) in each query string q. Section 2.2 gives as one reason for using CFGs to represent sets of query \nstrings that tainted substring boundaries can be repre\u00adsented by labeling certain nonterminals thus the \nstrings deriva\u00adtions provide the function from strings to tainted substrings. In addition to that reason, \na natural way to design and implement (a) $X =$UNTRUSTED; (b) $X1 =$UNTRUSTED; if ($A) { if ($A) {$X \n=$X.\"s\"; $X2 =$X1.\"s\"; } else {} else {$X =$X.\"s\"; $X3 =$X1.\"s\"; } } $Z=$X; $X4= .($X2, $X3); $Z =$X4; \n(c) UNTRUSTED . S * X1 . UNTRUSTED X2 . X1s X3 . X1s X4 . X2 | X3 Z . X4 Figure 5. Grammar re.ects data.ow. \n'/. '/' '/'  A/'A A/A Figure 6. A .nite state transducer equivalent of the function str replace(\"''\", \n\"'\", $B); A . S \\{'}. a CFG-based string analysis produces CFGs that re.ect the pro\u00adgram s data.ow, so \ntaint annotations applied at untrusted sources appear in the .nal CFG. Minamide designed his string analysis \nthis way, so we review the main steps of his analysis here and show how to adapt it to track taint information \n[20]. The contrived example program in Figure 5a serves to show that the generated grammar re.ects the \nprogram s data.ow. The .rst step of the string analysis translates the program into static single assignment \nform, as shown in Figure 5b. SSA form makes data\u00addependencies explicit, so translating each assignment \nstatement into a grammar production yields a CFG that re.ects the program s data.ow, as in Figure 5c. \nBy simply annotating the nonterminals corresponding to direct and indirect sources appropriately, we \nhave a string-taint anlysis for programs with concatenation, assignments, and control .ow. In general, \nright hand sides of assignment statements may con\u00adtain string functions, such as escape quotes(), which \nadds a slash before each quote character in its argument. Translating as\u00adsignments into grammar productions \nthen yeilds an extended CFG that has functions in its productions right hand sides. Converting extended \nCFGs into standard CFGs requires some approximation, and Minamide models string operations as .nite state \ntransducers (FSTs) in order to capture their effects and make the approximation reasonably precise. Section \n3.1.2 describes how FSTs can model string operations and how we track annotated sources through them \nin more detail. 3.1.2 Tracking Substrings through Filters De.nition 2.1 speci.es that web applications \ncan apply functions on strings to untrusted inputs. In order to avoid reporting many false positives, \nthe string-taint analyzer must model the effects of .lters and propagate annotations through them. This \nsection reviews how Minamide s string analysis models the effects of .lters and then describes how we \nadapt these techniques.  A transducer is an automaton with output. A .nite state trans\u00adducer is similar \nto a Mealy machine, except that a .nite state trans\u00adducer has one or more .nal states and may be non-deterministic. \nMany string operations that PHP provides as library functions be\u00adhave as .nite state transducers. For \nexample, str replace takes three strings as arguments: a pattern, a replacement, and a subject. The FST \nin Figure 6 describes the effects of str replace when the pattern is '' and the replacement is '. The \nnotation c1/c2 on the transitions means that on input character c1, the transition can be taken and \nit will output c2. In Figure 6, Amatches any char\u00adacter except '. The string analysis converts a grammar \nproduction with a string operation, such as x.escape quotes(y) into a standard grammar production by \n.nding the image of the CFG rooted at the operation s argument (y) over the FST that the string operations \nrepresents. ACFG has a cycle if there exists a sentential form derivable from a nonterminal that contains \nthe nonterminals. If an extended grammar has the production shown above, and if y .G * ax\u00df then the escape \nquotes operation occurs in a cycle. String oper\u00adations that occur in cycles within the extended CFG must \nbe ap\u00adproximated because the complete CFG rooted at the operation s argument (y) cannot be constructed \nindependently of the string op\u00aderation. Some string operations are more expressive than .nite state, \nor even context free, transducers. For example, PHP provides a reg\u00adular expression-based replace function, \npreg replace. Its three arguments are: a regular expression pattern, a parameterized re\u00adplacement, and \na subject. Within the replacement, an occurence of \\n, where nis a number, represents the string matched \nby the ex\u00adpression between the n th open parenthesis and its matching close parenthesis in the pattern. \nAs an example, preg_replace(\"/a([0-9]*)b/\", \"x\\\\1\\\\1y\", \"a01ba234b\") = \"x0101yx234234y\" The \\\\1 puts \nthe substring matched by the expression within the .rst pair of parentheses (because the number is 1) \ninto the output. Although the image of a CFL under a regular expression replace\u00adment is not necessarily \ncontext free (because of the ability to insert multiple copies of a regular expression match, as above), \nMohri and Sproat describe how to approximate it using two FSTs [21]. The string analysis also uses a \nsimilar technique to maintain precision from conditional expressions when constructing the ex\u00adtended \nCFG. If the condition is a regular expression match, as on line 14 in Figure 2, the string analysis adds \nan intersection with the condition s regular expression to the beginning of the then branch and an intersection \nwith the complement of the regular expression to the else branch. An adaptation of the standard context \nfree language-reachability algorithm [19] computes the intersection of a CFG and an FSA as a CFG without \nconstructing an intermediate push-down automaton, and we add to the algorithm to propagate annotations. \nFigure 7 shows the algorithm with our additions: the function TAINTIF() and the two calls to it on lines \n20 and 28 of INTERSECT(). The following theorem states that this algorithm propagates annotations appropriately. \nTheorem 3.1. Given C' =INTERSECT(C,F),s .L(C)nL(F), and a parse tree pof sunder C,there exist s1, s2,and \ns3 such that s1s2s3 =s and s2 is derivable from a direct-labeled nonterminal in p iff there exists a \nparse tree p' of s under C' such that s2 is ' derivable from a direct-labeled nonterminal in p. INTERSECT(G=(V0,S0,S0,R0),FSA \n=(Q,S,d,q0,qf )) 1 (V,S,S,R).NORMALIZE((V0,S0,S0,R0)) 2 V' .\u00d8 3 R' .\u00d8 4 for each (qi,s,qj )in d 5 do \nV' .V' .{sij } 6 R' .R' .{sij .s} 7 /* |rhs|=0*/ 8 for each X .E in R 9 do for each qi in Q 10 do V' \n.V' .{Xii} 11 R' .R' .{Xii .E} 12 WkLst .V' 13 for each aij in WkLst 14 do WkLst .WkLst \\{aij } 15 /* \n|rhs|=1*/ 16 for each X .a in R 17 do if not (Xij in V') 18 then WkLst .WkLst .{Xij } 19 V' .V' .{Xij \n} 20 TAINTIF(X,Xij ) 21 R' .R' .{Xij .aij } 22 /* |rhs|=2*/ 23 for each X .a\u00df in R 24 do for each \u00dfjk \nin V' 25 do if not (Xik in V') 26 then WkLst .WkLst .{Xik } 27 V' .V' .{Xik} 28 TAINTIF(X,Xik) 29 R' \n.R' .{Xik .aij \u00dfjk } 30 if S0f in V' 31 then return (V',S,S0f ,R') 32 else return ({S'},{},S',{}) NORMALIZE(G=(V,S,S,R)) \n1 R' .\u00d8 2 WkLst .R 3 for each X .[.]in WkLst 4 do WkLst .WkLst \\{X .[.]}5 if length[.]>2 6 then X' .FRESHVAR() \n7 V .V .{X'} 8 R' .R' .{X .head[.]X'} 9 WkLst .WkLst .{X' .tail[.]} 10 else R' .R' .{X .[.]}11 return \n(V,S,S,R') TAINTIF(X1,X2) 1 if HASLABEL(X1,direct) 2 then ADDLABEL(X2,direct) 3 if HASLABEL(X1,indirect) \n4 then ADDLABEL(X2,indirect) Figure 7. Taint propagation in CFG-FSA intersection. The proof is by a straightforward \ninduction on the height of the derivation of s. Due to space constraints, we omit the proof here. The \ncase for INDIRECT is identical. The algorithm for .nding the image of a CFG over an FST is similar to \nthe CFG-FSA intersection algorithm, except that the FST s output symbols replace the CFG s terminals \nas they match the FST s input symbols. The modi.cations for propogating taint information are the same \nfor that algorithm as in Figure 7, and the proof of correctness is analogous to the proof of Theorem \n3.1. explode(s1, s2) = expld(s1, s2, [], E) expld(s1, s1, L, s) = L@[s] expld(s1, s2, L, s), |s2|=|s1| \n= L@[s^s2] expld(s1, s1^s2, L, s) = expld(s1, s2, L@[s], E) expld(s1, c^s2, L, s), |c|=1 = expld(s1, \ns2, L, s^c) Figure 8. Semantics of explode. De.nition 2.1 only allows string concatenation after input \n.l\u00adters. The taint-propagating algorithm in Figure 7 correctly propa\u00adgates tainted substring boundaries \neven for .lters that operate on inputs concatenated with other strings. Thus we extend the de.ni\u00adtion \nof SQLCIVs to web applications with operations beyond those that De.nition 2.1 allows and still check \nfor SQLCIVs with high precision. 3.1.3 Handling Other String Operations Real-world web applications \nalso perform operations involving strings that do not simply map strings to strings. For each such op\u00aderation, \nwe must determine how substrings in the input map to sub\u00adstrings in the output and propagate annotations \naccordingly. We use as a straightforward but representative example the explode func\u00adtion, which takes \ntwo string arguments: a delimiter and a subject. It returns an array of substrings formed by splitting \nthe subject on boundaries formed by the delimiter. Figure 8 shows the semantics of explode. Because the \nstrings that it returns are taken directly from the subject, the meaning of untrusted substring .ow is \nclear. The string analysis models the effects of explode accurately, except that it loses the order of \nthe strings in the returned array it produces a grammar whose language is that set of strings. The algo\u00adrithm \n(due to Minamide [20]) uses two FSTs constructed from the delimiter, and because we propagate labels \nthrough FSTs correctly (see Section 3.1.2), we track tainted substrings accurately through the explode \nfunction. Space limitations prevent us from giving a full presentation of the algorithm here.  3.2 Policy-Conformance \nAnalysis The second phase of our analysis checks the generated, annotated grammar for SQL injection attacks. \nIn most cases, programmers in\u00adtend that inputs take the syntactic position of literals. Section 3.2.1 \ndescribes our checks for this case, and Section 3.2.2 presents our approach for the case when the input \nmay be derived from an arbi\u00adtrary nonterminal in the reference (SQL) grammar. 3.2.1 Untrusted Substrings \nas Literals This section describes how we attempt for each annotated nonter\u00adminal X either to verify \nthat all strings derivable from X are syn\u00adtactically con.ned or to .nd that some string derivable from \nX are not syntactically con.ned. We apply the algorithm described in Section 3.2.2 to nonterminals for \nwhich the checks in this section fail to provide conclusive results. The .rst check attempts to .nd untrusted \nsubstrings that cannot be syntactically con.ned in any SQL query. In particular, because quotes delimit \nstring literals in SQL, if any untrusted substring has an odd number of un-escaped quotes (escaped quotes \nrepresent characters rather than delimiters in string literals), it cannot be syntactically con.ned. \nThe grammar generated by the string-taint analysis re.ects the program s data.ow, so the strings derivable \nfrom labeled nonterminals are the possible untrusted substrings in generated SQL queries. Let Vl be the \nset of labeled nonterminals in V. For each X .Vl,if \u00d8. =L(V,S,X,R)nL(/^(([^']|\\')*[^\\])?' ((([^']|\\')*[^\\])?' \n(([^']|\\')*[^\\])?')* ([^']|\\')*$/ ) then there exists a string derivable from X that is not syntactically \ncon.ned (the Perl regular expression matches strings with an odd number of unescaped quotes), and we \nremove X from Vl. The second check .nds the nonterminals in Vl that occur only in the syntactic position \nof string literals and, for each one, either veri.es it as safe or .nds that it derives some uncon.ned \nstring. The algorithm identi.es the syntactic position of labeled nonterminals by creating from the grammar \nproduction set R a new production set Rt: for each labeled nonterminal X . V, replace right-hand\u00adside \noccurences of X in R with a fresh terminal tX ./Sand add tX to S. For each labeled X . V, if for all \nstrings s1tX s2 . L(V,S,S,Rt), s1 has an odd number of unescaped quotes, then X only occurs in the syntactic \nposition of a string literal. The following implements this check: \u00d8=L(V,S,S,R ' )nL(/^[^']* ('(([^']|\\')* \n(([^\\][\\\\]+)|[^'\\]))? '[^']*)* tX .*$/ ) For each X . Vl for which the test above succeeds, if any s \n. L(V,S,X,R)has unescaped quotes in it, X derives uncon.ned strings; otherwise X is safe. We then remove \nX from Vl. The third check attempts to identify those remaining nontermi\u00adnals in Vl that only derive \nnumeric literals. For each X .Vl,if \u00d8=L(V,S,X,R)nL(/^(([^0-9.+-].*[^0-9.]/) |([.].*[.])) ) then X derives \nonly numeric literals and is safe; remove X from Vl. Finally, if X can produce a non-numeric string outside \nof quotes, it likely represents an SQLCIV. To con.rm this, we check whether X can derive any of a given \nset of strings that cannot be syntactically con.ned (e.g. DROP WHERE, --, etc.). If it can, then X is \nunsafe, and we remove it from Vl. 3.2.2 Untrusted Substrings Con.ned Arbitrarily If any nonterminals \nremain in Vl after the checks in Section 3.2.1, we wish to check whether each string derivable from them \nis deriv\u00adable from some nonterminal in the SQL grammar. In general, con\u00adtext free language inclusion \nis undecidable, but we can approxi\u00admate it by checking grammar derivability, i.e., whether the gener\u00adated \ngrammar is derivable from the SQL grammar [28]. De.nition 3.2 (Derivability). Grammar G1 =(V1,S,S1,R1)is \nderivable from grammar G2 =(V2,S,S2,R2)iff .F:(V1 .S).(V2 .S) F(S1)=S2 . .s.SF(s)=s. .(X ..).R1 F(X). \n* F * (.) G2 where F * is Flifted to (V1 .S) * , i.e., F * (E)= E F * (a)=F(a) for a.V1 .S * ** F(a\u00df)=F(a)F \n(\u00df) Lemma 3.3. If G1 is derivable from G2,then L(G1).L(G2). We check derivability using an extension \nof Earley s parsing al\u00adgorithm [4] that parses sentential forms and treats nonterminals in G1 as variables \nthat range over terminals and nonterminals. This al\u00adgorithm is inspired by and is similar to Thiemann \ns algorithm [28]. We do not require that the entire generated grammar be derivable from the SQL grammar; \nwe require derivability for the subgram\u00admar rooted at X and all sentential forms that include X.If the \nderivability check fails, we consider X to be unsafe.  3.3 Soundness We state and sketch the proof of \na soundness result here. Theorem 3.4 (Soundness). If our analysis algorithm does not report any SQLCIVs \nfor a given web application P ,then P has no SQLCIVs. Proof. The string analysis produces a CFG G from \nweb application P that derives all strings that P may generate as query strings [20]. The algorithm for \nconstructing G re.ects P s data.ow so that for assignments and concatenation, labels on nonterminals \nfrom un\u00adtrusted sources accurately identify untrusted substrings. By Theo\u00adrem 3.1, the CFGs constructed \nas the intersection of a CFG and an FSA, or the image of a CFG over an FST, is labeled to re.ect the \nboundaries of untrusted substrings. The conformance checking algorithm from Section 3.2 generates an \nerror message on each la\u00adbeled nonterminal unless the algorithm can verify it to derive only syntactically \ncon.ned strings, as required by De.nition 2.3.  4. Implementation We implemented our technique for PHP, \nusing and modifying Mi\u00adnamide s string analyzer. In addition to the changes described pre\u00adviously (adding \ninformation .ow tracking and checks on the gen\u00aderated grammars), we made the analyzer more automated \nin two ways. First, we added speci.cations for 243 PHP functions. Sec\u00adond, we enhanced its support for \ndynamic includes. Previously, the analyzer would fail if it reached an include statement, and the gram\u00admar \nit had generated for the include statement s argument had an in.nite language. For example, if the analyzer \nrecorded the possible values for $choice as being S *, the analyzer would fail at: include(\"e107_languages/lan_\".$choice.\".php\"); \nWe address this by considering the .le and directory layout to be part of the speci.cation. If the analyzer \nencounters such an in\u00adclude statement, it builds a regular expression representation of the directory \nlayout starting from the analyzed project s root. It then intersects the (.nite) language of this regular \nexpression with the language of the grammar to .nd the list of .les to include. This language-based approach \ndoes not model the full seman\u00adtics of paths (e.g., .. as parent directory), but we believe this choice \nto be appropriate for two reasons. First, we have not en\u00adcountered cases where the programmer-intended \nvalues of vari\u00adables like $choice include .. ; and second, security exploits on dynamic inclusion vulnerabilities \ngenerally reveal sensitive infor\u00admation stored in .les and do not facilitate SQL command injection attacks. \nThe string analyzer does not support all features for PHP. For example, it includes only limited support \nfor references. We plan to add support for these features, but until full-support is available, we manually \napproximate unsupported lines of PHP code and verify that the changes do not remove potential errors. \n 5. Evaluation This section presents the setup and results of our evaluation. 5.1 Test Subjects We evaluated \nour tool on .ve real-world PHP web applications in order to test its scalability and its false positive \nrate, and to see what kinds of errors it would .nd and what would cause false positives. We use the following \nsubjects in our evaluation: e107 and Warp Content Management System are content management systems; EVE \nActivity Tracker is an activity tracker for integration into existing IGB homepages; and Tiger PHP News \nSystem and Utopia News Pro are news management systems. Table 1 lists the isset($ GET['newsid']) ? $getnewsid \n=$ GET['newsid'] : $getnewsid = false; if (($getnewsid != false) &#38;&#38; (!preg match('/^[\\d]+$/', \n$getnewsid))) { unp msg('You entered an invalid news ID.'); exit; } ... if (!$showall &#38;&#38; $getnewsid) \n{ $getnews =$DB->query(\"SELECT * FROM `unp news`\" .\"WHERE `newsid`='$getnewsid'\" .\"ORDER BY `date`DESC \nLIMIT 1\"); } Figure 9. Source of a false positive. $newsposter =$USER['username']; $newsposterid =$USER['userid']; \n// Verification if (unp isEmpty($subject) || unp isEmpty($news)) { unp msg($gp allfields); exit; } if \n(!preg match('/^[\\d]+$/', $newsposterid)) { unp msg($gp invalidrequest); exit; } $submitnews =$DB->query(\"INSERT \nINTO `unp news`\" .\"(`date`, `subject`, `news`, `posterid`,\" .\"`poster`)\" .\" VALUES \" .\"('$posttime','$subject','$news',\" \n.\"'$newsposterid','$newsposter')\"); Figure 10. Source of an indirect error report. size of each of these \nweb applications in terms of the number of .les and the number of lines of PHP code. The test suite for \nanother PHP analysis tool [31] includes an earlier version of e107, and we do not know of any database-backed \nPHP web application with more lines of code. We ran the analysis on a machine with a 3GHz processor and \n8GB of RAM running Linux Fedora Core 5.  5.2 Accuracy and Bug Reports The code in Figure 2 shows a \nvulnerability that our tool found by modeling regular expressions precisely. Two others in Utopia News \nPro are similar to this one. Although some of the SQLCIVs that our tool found were trivial, others crossed \n.le and class boundaries. For example, the SQLCIV in e107 comes from a .eld read from a cookie, which \na user can modify, that is used in a query in a different .le. Across this test suite, our tool had a \n(5/(19+5)) = 20.8% false positive rate. This false positive rate demonstrate that our approach is effective \nfor .nding SQLCIVs and verifying the absence of them. Our tool produced the false positives that it did \nbecause of it does not track information with suf.cient precision through type conversions. Figure 9 \nshows one of the two false positives from Utopia News Pro (the other is similar). The PHP runtime system \nwill dynamically cast between any of the scalar types without com\u00adplaint. It casts a value of type string \nto a value of type boolean Name (version) Files Lines Grammar Size |V | |R| Time (h:m:s) String SQLCIV \nAnalysis Check Errors direct Real False indirect e107 (0.7.5) 741 132,850 62,350 377,348 3:39:26.23 35:36.12 \n1 0 4 EVE Activity Tracker (1.0) 8 905 57 1628 0.40 0.06 4 0 1 Tiger PHP News System (1.0 beta 39) 16 \n7,961 82,082 1,078,768 3:14:06.95 5.39 0 3 2 Utopia News Pro (1.3.0) 25 5,611 5,222 336,362 25:00.08 \n2:08.69 14 2 12 Warp Content MS (1.2.1) 42 23,003 1,025 73,543 21.10 0.08 0 0 0 Totals 19 5 17 Table \n1. Evaluation results. producing a value of false if the string is (empty) or 0, and true otherwise. \nTo avoid the false positive shown in Figure 9, the analyzer would have to model this conversion in the \n.rst condi\u00adtional expression and propagate its implications beyond the then branch. The three false positives \nfrom Tiger PHP News System re\u00adsulted from a hand-written string sanitizing routine. Depending on a character \ns ASCII value, this routine will either encode it or keep it as is. The string analyzer does not have \na map from characters to their ASCII values, so it failed to track the precise effects of this routine. \nBoth of these types of false positives could be avoided by equipping the string analyzer with more information \nabout type conversions. Evaluating whether indirect error reports represent real errors is dif.cult because \nit requires making assumptions about what data can .ow into the source (e.g., the database). However, \nFigure 10 shows one example of an indirect error report that seems to repre\u00adsent a true vulnerability. \nBoth $newsposter and $newsposterid are assigned from the $USER array, which is populated elsewhere from \nthe results of a database query. The fact that $newsposterid is checked and not $newsposter seems to \nindicate the possibil\u00adity of unexpected values, and at the least it represents inconsistent programming. \n 5.3 Scalability and Performance As stated in Section 4, our string analyzer currently has some lim\u00aditations \nin terms of the PHP constructs it supports. Nevertheless, on three of the subjects in our test suite \n(EVE Activity Tracker, Utopia News Pro, and Warp Content Management System) the an\u00adalyzer ran successfully. \nThe others include certain currently unsup\u00adported constructs, and we manually modi.ed the code to allow \nthe analyzer to continue but without causing any potential errors to be missed. The unsupported construct \nthat we encountered most frequently was the str replace function with array-type argu\u00adments, which were \ngenerally given statically. We expanded these str replace statements into sequences of str replace state\u00adments, \neach with scalar arguments. These unsupported constructs do not represent a shortcoming in our technique, \nbut only a current limitation in our prototype. Regarding scalability, we note .rst that our tool successfully \nanalyzed all of the web applications in our test suite. Table 1 lists the size of the grammars representing \nSQL queries that our tool generates in terms of the number of nonterminals (|V |)and the number of production \nrules (|R|). Next to the grammar size, it lists the time spent on string analysis and the time spent \nchecking the generated grammars for SQLCIVs. Analyzing web applications is different in one key respect. \nUnlike for many program analysis settings where a code base has a single top-level function that can \nbe passed to an analyzer, each .le that represents one page in a web application de.nes a top level function. \nIn many web applications, most .les de.ning top-level functions include and use the same helper functions \nin other .les, and our tool re-analyzes these included .les each time. In such cases, our tool analyzes \nmost of the code in a small fraction of the time required to analyze the whole web application. This \nalso illustrates that straightforward use of memorization or concurrent executions of the analyzer could \nimprove the performance dramatically in some cases. A few points are particularly noteworthy here. First, \nthe gram\u00admar size is not necessarily proportional to the web application size. The query grammar generated \nfrom Tiger PHP News System is sig\u00adni.cantly larger than that of e107, which is over an order of mag\u00adnitude \nlarger in terms of lines of code. This re.ects in some sense the size of the web application devoted \nto database queries. Second, the string analysis time is not necessarily proportional to the grammar \nsize. The grammar size reported is only for the grammar representing possible database queries. The string \nanaly\u00adsis works eagerly, analyzing some string expressions that have no in.uence on the generated database \nqueries. This eager analysis in\u00adtroduce signi.cant unnecessary overhead in web applications that process \nuser input for marked up display, such as in an online bul\u00adletin board or forum. Tiger PHP News System \nincludes such code, that substitutes html tags for forum equivalents (e.g., <bold> for [bold]) and designated \ncharacter sequences for emoticon links. Tiger PHP News System is designed to be secure, and it includes \na forum with such code. Each regular expression or string replace\u00adment function (potentially) causes \nits argument s grammar to in\u00adcrease by some factor, so that a sequence of these replacement ex\u00adpressions \nleads to a blow up that is exponential in the number of replacements. We removed two sections of such \ncode from Tiger PHP News System in order to speed up the analysis, but in principle the analyzer could \nuse a backward data.ow analysis to determine which variables may in.uence a database query, and refrain \nfrom analyzing the rest. We expect that this would speed up the analy\u00adsis signi.cantly. Additionally, \ndynamic .le inclusions can lead to a combinatorial blow up. Each time a .le is included, it is inserted \nin situ and its top-level scope is merged into the scope where it is included. If one .le has an include \nstatement whose argument is entirely unspeci.ed statically, the analyzer will try to include every other \n.le in the project and with each of them, which ever .les they may include. In the case of e107 with \n741 .les, we had to provide .le names for two include statements. Finally, the SQLCIV checking phase \nis relatively ef.cient. Al\u00adthough the grammars had more than one million production rules in some cases, \nSQLCIV checking never took more than a few min\u00adutes, and usually took less.  6. Related Work In this \nsection we survey closely related work. 6.1 Static String Analysis The study of static string analysis \ngrew out of the study of text processing programs. An early work to use formal languages (viz. regular \nlanguages) to represent string values is XDuce [10], a lan\u00adguage designed for XML transformations. Tabuchi \net al. designed regular expression types for strings in a functional language with a type system that \ncould handle certain programming constructs with greater precision than had been done before [27]. Christensen \net al. introduced the study of static string analy\u00adsis for imperative (and real-world) languages by showing \nthe use\u00adfulness of string analysis for analyzing re.ective code in Java programs and checking for errors \nin dynamically generated SQL queries [3]. They designed an analysis for Java that has FSAs as its target \nlanguage representation; they chose FSAs because FSAs are closed under the standard language operations. \nThey also ap\u00adplied techniques from computational linguistics to generate good FSA approximations of CFGs \n[21]. Their analysis, however, does not track the sourced of data, and because it must determinize the \nFSAs between each operation, it is less ef.cient than other string analyses and not practical for .nding \nSQLCIVs. Gould et al. used this analysis to type check dynamically generated queries, but made approximations \nthat would cause them to miss SQLCIVs [6]. Minamide borrowed techniques from Christensen et al. to de\u00adsign \na string analysis for PHP that does not approximate CFGs to FSAs, so it can be more ef.cient and more \naccurate [20]. He also utilized techniques from computational linguistics (viz. language transducers) \n[22] to improve the precision of his analysis and model the effects of string operations, which are used \nfrequently in script\u00ading languages. His analysis does not track the source of data explic\u00aditly, and it \nis designed to validate dynamically generated HTML, which has a .atter grammar than SQL. For both Minamide \nand Christensen et al. s analyses, the user must provide regular expres\u00adsion speci.cations of the permitted \nqueries at each query location. We avoid the need for manually written speci.cations .rst by using a \ngeneral policy based on both data.ow and string structure, and second by adding explicit data.ow information \nto the grammar s nonterminals in Minamide s analysis. 6.2 Static Taint Checking Static taint checking \nis essentially information .ow analysis spe\u00adcialized to determine whether data from an untrusted source \n.ows into a sensitive sink. Static taint checking has a long history, but Huang et al. were perhaps the \n.rst to apply it to SQLCIVs [11]. They used a CQual-like [5] type system to propagate taint informa\u00adtion \nthrough PHP programs. Livshits and Lam [17] used a precise points-to analysis for Java [30] and queries \nspeci.ed in PQL [16] to .nd paths in Java programs that allow raw input to .ow into SQL queries. Both \nof these tools are sound with respect to the policy they enforce and the language features they support, \nand both .nd many vulnerabilities, but both consider all values returned from desig\u00adnated .ltering functions \nto be safe. Because the policy they use says nothing about the context of the user input and the structure \nof the query, both techniques may miss real SQLCIVs. Additionally, Huang et al. s type system does not \nsupport some of PHP s more dynamic features, in part because it does not track string values at all and \nsupporting these features would result in too many false positives. Jovanovic et al. sought to address \nthis last shortcoming with Pixy [12, 13], a static taint analysis for PHP that propagates limited string \ninformation and implements a .nely tuned alias analysis. Xie and Aiken designed a more precise and scalable \nanalysis for .nding SQLCIVs in PHP by using block-and function-summaries [31]. The precision they gained \ncomes at the expense of automation the user must provide the .lenames when the analysis encounters a \ndynamic include statement, and the user must tell the analysis whether each regular expression encountered \nin a .ltering function is safe. We are able to make a stronger guarantee about the absence of SQLCIVs \nbecause we analyze the possible values of the strings and check conformance to a policy that takes into \naccount the query s structure. 6.3 Runtime Enforcement Because more information about data and program \nexecution is available at runtime, several groups have proposed techniques to enforce more expressive \npolicies than simply tracking the .ow of tainted input, which Perl s taint mode already provides [29]. \nAM-NESIA, by Halfond and Orso, uses Christensen et al. s Java string analyzer to construct a policy requiring \nuser inputs to be single to\u00adkens in constructed queries, and enforces that policy at runtime [8]. The \neffectiveness of this approach is limited by the string analy\u00adsis precision. Buehrer et al. also enforce \na policy that user in\u00adput must be a single token in the query, but they do not rely on a static analysis \n[2]. They bound user input, parse the query, and check whether the parse tree retains the same structure \nwhen the user input is replaced by a single dummy node. Java provides a PreparedStatement API, which \nforces inputs in queries built with it to be string or numeric literals. Boyd and Keromytis sought to \nenforce this via instruction set randomization [14], i.e.,by ran\u00addomizing the SQL keywords in the web \napplication, so that users could not guess the keywords [1]. This technique cannot provide guarantees, \nbecause the user may guess the randomization key. Both Nguyen-Tuong et al. [23] and Pietraszek and Berghe \n[24] propose to enforce the same policy for PHP more rigorously. They modify the PHP interpreter to track \ntaint information at the char\u00adacter level, tokenize the completed query, and check whether any tainted \ncharacters appear in any tainted characters. A modi.ed in\u00adterpreter has the advantage that it can add \nsecurity guarantees to arbitrary web applications, but practical issues of deployment and system maintenance \nlimit such a technique s effectiveness. Xu et al. propose a source-to-source translator for C that adds \ntaint track\u00ading [32]. It can be used to ameliorate the system maintenance prob\u00adlem by adding taint-tracking \nto new versions of the PHP inter\u00adpreter s source code. WASP, by Halfond et al., enforces approximately \nthe same pol\u00adicy for Java, but they use positive tainting, i.e., they taint trusted strings, and allow \nonly tainted characters in keywords unless the programmer speci.es with a regular expression that user \ninput may include certain keywords [7]. Additionally, instead of modifying the JVM, they provide a byte \ncode instrumenter. Su and Wasser\u00admann use delimiters to track user input into generated queries, and \nparse the queries based on a modi.ed grammar to check whether the user input is parsable under any of \na permitted set of nonter\u00adminals within the query [25]. The policy we enforce allows user input to be \nparsable under any nonterminal, but in principle we could limit the allowable nonterminals. Although \nthese runtime techniques to prevent SQL injection attacks are more precise than static analyses in general, \nsome SQLCIVs are indicative of larger programming errors. Static analysis can help to .nd and .x such \nerrors prior to deployment. Additionally, general runtime enforce\u00adment techniques incur more runtime \noverhead than appropriate, well-placed .lters, which static analysis can check.  7. Conclusion In this \npaper we have proposed a new static analysis algorithm to .nd SQLCIVs. It characterizes the sets of possible \ndatabase queries that a web application may generate using context free grammars, and tracks information \n.ow from untrusted sources into those grammars. By using a general de.nition of SQLCIVs based on the \ncontext of untrusted substrings, we avoid the need for manu\u00adally written policies. Our implementation \nworked well under eval\u00aduation. It was precise, detected unknown vulnerabilities in real\u00adworld web applications \nwith few false positives, demonstrating the effectiveness of our approach. We plan to make three improvements \nto our tool: .rst, we plan to extend it to support all of PHP s features; second, we plan to add a backward \ndata.ow analysis to prevent it from analyzing complex string expressions that do not in.uence database \nqueries; third, we plan to track line numbers from PHP source .les through to the grammars nonterminals \nin order to improve the quality of the bug reports. We would like to apply the same technique to detecting \nvulnerabilities that allow cross-site scripting attacks, in which a server may deliver untrusted JavaScript \ncode to be executed by a client browser with the full permissions of the trusted server. We are also \ninterested in integrating our analysis into a broader business logic analysis of web applications [15] \nin order to track session variables as they .ow from one page to another and provide more precise and \ninformative warnings.  Acknowledgments We thank the PLDI anonymous reviewers for their useful and detailed \ncomments, which helped improve the presentation of this work. We also thank Yasuhiko Minamide for developing \nthe PHP string analyzer that we used in this work and for answering our questions about his tool. References \n[1] S. W. Boyd and A. D. Keromytis. SQLrand: Preventing SQL injection attacks. In International Conference \non Applied Cryptography and Network Security (ACNS), LNCS, volume 2, 2004. [2] G. T. Buehrer, B. W. Weide, \nand P. A. Sivilotti. Using parse tree validation to prevent SQL injection attacks. In Proceedings of \nthe International Workshop on Software Engineering and Middleware (SEM) at Joint FSE and ESEC,Sept. 2005. \n[3] A. S. Christensen, A. M\u00f8ller, and M. I. Schwartzbach. Precise analysis of string expressions. In \nProceedings of the 10th International Static Analysis Symposium, SAS 03, volume 2694 of LNCS, pages 1 \n18. Springer-Verlag, June 2003. Available from http://www.brics.dk/JSA/. [4] J. Earley. An ef.cient context-free \nparsing algorithm. Communications of the Association for Compution Machinery, 13(2):94 102, 1970. [5] \nJ. S. Foster, T. Terauchi, and A. Aiken. Flow-sensitive type quali.ers. In PLDI 02: Proceedings of the \nACM SIGPLAN 2002 Conference on Programming language design and implementation, pages 1 12, New York, \nNY, USA, 2002. ACM Press. [6] C. Gould, Z. Su, and P. Devanbu. Static checking of dynamically generated \nqueries in database applications. In Proceedings of the 25th International Conference on Software Engineering \n(ICSE), pages 645 654, May 2004. [7] W. Halfond, A. Orso, and P. Manolios. Using Positive Tainting and \nSyntax-Aware Evaluation to Counter SQL Injection Attacks. In Proceedings of the ACM SIGSOFT Symposium \non the Foundations of Software Engineering (FSE 2006), Portland, Oregon, November 2006. [8] W. G. Halfond \nand A. Orso. AMNESIA: Analysis and Monitoring for NEutralizing SQL-Injection Attacks. In Proceedings \nof 20th ACM International Conference on Automated Software Engineering (ASE), Nov. 2005. [9] K. J. Higgins. \nCross-site scripting: Attackers new favorite .aw, Septem\u00adber 2006. http://www.darkreading.com/document.asp?doc_id= \n103774&#38;WT.svl=news1_1. [10] H. Hosoya and B. C. Pierce. Xduce: A typed xml processing language (preliminary \nreport). In Selected papers from the Third International Workshop WebDB 2000 on The World Wide Web and \nDatabases, pages 226 244, London, UK, 2001. Springer-Verlag. [11] Y.-W. Huang, F. Yu, C. Hang, C.-H. \nTsai, D.-T. Lee, and S.-Y. Kuo. Securing web application code by static analysis and runtime protection. \nIn WWW 04: Proceedings of the 13th international conference on World Wide Web, pages 40 52, New York, \nNY, USA, 2004. ACM Press. [12] N. Jovanovic, C. Kruegel, and E. Kirda. Pixy: A static analysis tool for \ndetecting web application vulnerabilities (short paper). In 2006 IEEE Symposium on Security and Privacy, \nOakland, CA, May 2006. [13] N. Jovanovic, C. Kruegel, and E. Kirda. Precise alias analysis for syntactic \ndetection of web application vulnerabilities. In ACM SIGPLAN Workshop on Programming Languages and Analysis \nfor Security, Ottowa, Canada, June 2006. [14] G. S. Kc, A. D. Keromytis, and V. Prevelakis. Countering \ncode-injection attacks with instruction-set randomization. In Proc. CCS 03, pages 272 280, 2003. [15] \nC. Kirkegaard and A. M\u00f8ller. Static analysis for Java Servlets and JSP. In Proceedings of the 13th International \nStatic Analysis Symposium, SAS 06, volume 4134 of LNCS. Springer-Verlag, August 2006. Full version available \nas BRICS RS-06-10. [16] M. S. Lam, J. Whaley, V.B.Livshits,M. C.Martin, D. Avots,M. Carbin, and C. Unkel. \nContext-sensitive program analysis as database queries. In Proceedings of the Twenty-fourth ACM SIGACT-SIGMOD-SIGART \nSymposium on Principles of Database Systems. ACM, June 2005. [17] V. B. Livshits and M. S. Lam. Finding \nsecurity errors in Java programs with static analysis. In Proceedings of the 14th Usenix Security Symposium, \npages 271 286, Aug. 2005. [18] M. Martin, B. Livshits, and M. S. Lam. Finding application errors and \nsecurity .aws using PQL: a program query language. In OOPSLA 05: Proceedings of the 20th annual ACM SIGPLAN \nconference on Object oriented programming systems languages and applications, pages 365 383, 2005. [19] \nD. Melski and T. Reps. Interconvertbility of set constraints and context-free language reachability. \nIn Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation, \npages 74 89, 1997. [20] Y. Minamide. Static Approximation of Dynamically Generated Web Pages. In WWW \n05: Proceedings of the 14th International Conference on the World Wide Web, pages 432 441, 2005. [21] \nM. Mohri and M. Nederhof. Regular approximation of context-free grammars through transformation. Robustness \nin Language and Speech Technology, pages 153 163, 2001. [22] M. Mohri and R. Sproat. An ef.cient compiler \nfor weighted rewrite rules. In Meeting of the Association for Computational Linguistics, pages 231 238, \n1996. [23] A. Nguyen-Tuong, S. Guarnieri, D. Greene, J. Shirley, and D. Evans. Automatically hardening \nweb applications using precise tainting. In Twentieth IFIP International Information Security Conference \n(SEC 05), 2005. [24] T. Pietraszek and C. V. Berghe. Defending against Injection Attacks through Context-Sensitive \nString Evaluation. In Proceedings of the 8th International Symposium on Recent Advances in Intrusion \nDetection (RAID), Sept. 2005. [25] Z. Su and G. Wassermann. The essence of command injection attacks \nin web applications. In Proceedings of the 33rd Annual Symposium on Principles of Programming Languages, \npages 372 382, Charleston, SC, Jan. 2006. ACM Press New York, NY, USA. [26] M. Sutton. How prevalent \nare sql injection vulnerabilities?, September 2006. http://portal.spidynamics.com/blogs/msutton/archive/2006/ \n09/26/How-Prevalent-Are-SQL-Injection-Vulnerabilities_ 3F00_.aspx. [27] N. Tabuchi, E. Sumii, and A. \nYonezawa. Regular expression types for strings in a text processing language (extended abstract). In \nProceedings of TIP 02 Workshop on Types in Programming, pages 1 18, July 2002. [28] P. Thiemann. Grammar-based \nanalysis of string expressions. In 2005 ACM SIGPLAN International Workshop on Types in Languages Design \nand Implementation (TLDI), pages 59 70, 2005. [29] L. Wall, T. Christiansen, and R. L. Schwartz. Programming \nPerl (3rd Edition). O Reilly, 2000. [30] J. Whaley and M. S. Lam. Cloning-based context-sensitive pointer \nalias analysis using binary decision diagrams. In PLDI 04: Proceedings of the ACM SIGPLAN 2004 conference \non Programming language design and implementation, pages 131 144, New York, NY, USA, 2004. ACM Press. \n[31] Y. Xie and A. Aiken. Static detection of security vulnerabilities in scripting languages. In Proceedings \nof the 15th USENIX Security Symposium, pages 179 192, July 2006. [32] W. Xu, S. Bhatkar, and R. Sekar. \nTaint-enhanced policy enforcement: A practical approach to defeat a wide range of attacks. In Proceedings \nof the 15th USENIX Security Symposium, Aug. 2006.  \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Web applications are popular targets of security attacks. One common type of such attacks is SQL injection, where an attacker exploits faulty application code to execute maliciously crafted database queries. Bothstatic and dynamic approaches have been proposed to detect or prevent SQL injections; while dynamic approaches provide protection for deployed software, static approaches can detect potential vulnerabilities before software deployment. Previous static approaches are mostly based on tainted information flow tracking and have at least some of the following limitations: (1) they do not model the precise semantics of input sanitization routines; (2) they require manually written specifications, either for each query or for bug patterns; or (3) they are not fully automated and may require user intervention at various points in the analysis. In this paper, we address these limitations by proposing a <i>precise, sound</i>, and <i>fully automated</i> analysis technique for SQL injection. Our technique avoids the need for specifications by consideringas attacks those queries for which user input changes the intended syntactic structure of the generated query. It checks conformance to this policy byconservatively characterizing the values a string variable may assume with a context free grammar, tracking the nonterminals that represent user-modifiable data, and modeling string operations precisely as language transducers. We have implemented the proposed technique for PHP, the most widely-used web scripting language. Our tool successfully discovered previously unknown and sometimes subtle vulnerabilities in real-world programs, has a low false positive rate, and scales to large programs (with approx. 100K loc).</p>", "authors": [{"name": "Gary Wassermann", "author_profile_id": "81309502583", "affiliation": "University of California: Davis, Davis, CA", "person_id": "P767498", "email_address": "", "orcid_id": ""}, {"name": "Zhendong Su", "author_profile_id": "81100108298", "affiliation": "University of California: Davis, Davis, CA", "person_id": "PP36031595", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250739", "year": "2007", "article_id": "1250739", "conference": "PLDI", "title": "Sound and precise analysis of web applications for injection vulnerabilities", "url": "http://dl.acm.org/citation.cfm?id=1250739"}