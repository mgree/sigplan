{"article_publication_date": "06-10-2007", "fulltext": "\n Thin Slicing Manu Sridharan Stephen J. Fink Rastislav Bod\u00edk University of California, Berkeley IBM \nT.J. Watson Research Center University of California, Berkeley manu_s@cs.berkeley.edu sj.nk@us.ibm.com \nbodik@cs.berkeley.edu Abstract Program slicing systematically identi.es parts of a program rele\u00advant \nto a seed statement. Unfortunately, slices of modern programs often grow too large for human consumption. \nWe argue that un\u00adwieldy slices arise primarily from an overly broad de.nition of rel\u00adevance, rather than \nfrom analysis imprecision. While a traditional slice includes all statements that may affect a point \nof interest, not all such statements appear equally relevant to a human. As an improved method of .nding \nrelevant statements, we pro\u00adpose thin slicing.Athin slice consists only of producer statements for the \nseed, i.e., those statements that help compute and copy a value to the seed. Statements that explain \nwhyproducers affect the seed areexcluded.Forexample, fora seed that readsavalue froma container object,athin \nslice includes statements that store thevalue intothe container,butexcludes statements that manipulate \npointers to the container itself. Thin slices can also be hierarchically ex\u00adpanded to include statements \nexplaining how producers affect the seed, yielding a traditional slice in the limit. We evaluated thin \nslicing for a set of debugging and program understanding tasks. Theevaluation showed that thin slices \nusually included the desired statements for the tasks(e.g., thebuggy state\u00admentforadebugging task). Furthermore,in \nsimulated useofa slic\u00ading tool, thin slices revealed desired statements after inspecting 3.3 times fewer \nstatements than traditional slicing for our debugging tasks and 9.4 times fewer statements for our program \nunderstand\u00ading tasks. Finally,our thin slicing algorithm scales well to relatively large Javabenchmarks, \nsuggesting that thin slicing represents an at\u00adtractive option for practical tools. Categories and Subject \nDescriptors D.2.5[Software Engineer\u00ading]:Testing and Debugging Debugging aids General Terms Languages, \nReliability Keywords slicing, debugging, program understanding 1. Introduction Thin-slicing is part of \nwhat makes the unconscious so dazzling. But it s also what we .nd most problematic about rapid cognition. \nHow is it possible to gather the necessary information for a sophisticated judgment in such a short time? \nMalcolm Gladwell, Blink: The Power of Thinking Without Thinking Permission to make digital or hard copies \nof all or part of this work for personal or classroom use is granted without fee provided that copies \nare not made or distributed for pro.t or commercial advantage and that copies bear this notice and the \nfull citation on the .rst page.To copyotherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, \nUSA. Copyright&#38;#169;2007ACM 978-1-59593-633-2/07/0006...$5.00. Motivation Large-scale object-oriented \nprograms canbevery hard to understand and debug. Pervasive use of heap-allocated data and complex data \nstructures in these programs causes much of this dif.culty. Multiple levels of pointer indirection in \ncommon data structures can make manually tracing the .ow of data through the heap prohibitively dif.cult.For \nthesesituations, programmers could bene.t from a tool that abstracts away irrelevant details of heap \nbehavior during code inspection and debugging. Programslicingisawell-known techniquefor identifyingasub\u00adset \nof the program that is relevant to a statement or value of in\u00adterest, called a seed1. Slicing applies \nto a variety of program un\u00ad derstanding tasks, ranging from testing and debugging to reverse engineering \n[27].Weiser [28] originally de.neda slice as an exe\u00adcutable program subset in which the seed statement \nperforms the same computationasinthe original program.Weiser s de.nitionis elegant and intuitive,but \nimposesa rather broad de.nitionof rel\u00adevance: anystatement t that could possibly affect the computation \natthe seed statement s must appear in the slice. This de.nition pol\u00adlutes slices with many statements \nthat indirectlyaffecta seedbut are not pertinent to typical program understanding tasks. Data structures \nare a key source of slice pollution. Slices of\u00adten include internal implementation details of these data \nstructures, which are almost always irrelevant to programmer tasks. Consider a value stored in a deeply \nnested data structure, e.g., a hash table whichholds treeswithlistsateachtreenode.Abackwardsslicefor \na read from onesuch list must include the statements that construct and manipulate all levels of this \ncomplex data structure.For many program understanding tasks, the programmer needs information aboutthevalues \nstoredinthe list,but doesn t care about otherde\u00adtails of nested data structures containing the value. \nFurthermore, modern programs typically rely heavily on well-tested data struc\u00adtures provided by standard \nlibraries, whose internal details rarely concern the end-user programmer. For these common cases, the \nbackwards slice presentsfar too much information for the task at hand. Our Approach This paper presents \nthin slicing, a program under\u00adstanding technique that rede.nes relevance in a manner aimed at only including \nstatements useful for developer tasks.For thin slic\u00ading, only producer statements for the seed are relevant, \ni.e., those statements that help compute and copy a value to the seed. State\u00adments that explain why producersaffecttheseed \nareexcludedfrom a thin slice. In practice, producer statements alone are suf.cient for manydebugging \nand program understanding tasks. We demonstrate the relevance notion of thin slicing on the Java program \nfragment of Figure 1, which manipulates Strings stored in a container. Given full names as input, the \nexample extracts the .rst names and stores them in a Vector (the readNames() func\u00adtion), and then later \nprints out the .rst names (the printNames() 1The seed is often termed the slicing criterion in the literature \n[27]; we use seed for brevity. 1 class Vector { 2 Object[] elems; int count; 3 Vector() { elems = new \nObject[10]; } 4 void add(Object p) { 5 this.elems[count++] = p; 6 } 7 Object get(int ind) { 8 return \nthis.elems[ind]; 9 } ... 10 } 11 Vector readNames(InputStream input) { 12 Vector firstNames = new Vector(); \n13 while (!eof(input)) { 14 String fullName = readFullName(input); 15 int spaceInd = fullName.indexOf( \n ); 16 String firstName = fullName.substring(0,spaceInd-1); 17 names.add(firstName); 18 } 19 return firstNames; \n20 } 21 void printNames(Vector firstNames) { 22 for (int i = 0; i < firstNames.size(); i++) { 23 String \nfirstName = (String)firstNames.get(i); 24 print( FIRST NAME: + firstName); 25 } 26 } 27 void main(String[] \nargs) { 28 Vector firstNames = readNames(new InputStream(args[0])); 29 SessionState s = getState(); 30 \ns.setNames(firstNames); 31 ...; 32 SessionState t = getState(); 33 printNames(t.getNames()); 34 } Figure \n1. Example showing the advantages of thin slicing. The six statements with underlined expressions are \nin the thin slice seeded with line 24, while the traditional slice for line 24 contains all displayed \ncode. The bodies of functions with inessential behavior (e.g., print())have been elided for clarity. \nfunction). The main() method illustratesauseofthecodeinaweb application, storing and retrieving the names \nfrom a SessionState object. The example contains a bug: when the program receives as input full name \nJohn Doe , line 24 erroneously prints FIRST NAME: Joh . Traditional slicing does not help in diagnosing \nthis bug, as a slice seeded with line 24 includes all the code in the example. The slice must include \nall the code to construct and populate the Vector passed to printNames() and the code in main() retrieving \nthe Vector from the SessionState object, which all affects line 24. As in this example, slices for Java \nprograms typically include most of the program. What lines of code are most relevant for the debugging \ntask in thisexample? Thebug lies at line 16, which incorrectly passes spaceInd-1 (rather than spaceInd)to \nString.substring(). See\u00ading howthis erroneous String .owsto whereitis printedwouldal\u00admost immediately \nlead the user to the problematic line. In this case, the .owtraversesa Vector:line 17 adds theString,and \nline 23 re\u00ad trieves it. Athin slice only includesproducer statements for the seed.We say statement s \nisaproducer for statement t if s is partofachainof assignments that computes and copiesavalueto t. In \nFigure 1, the producer statements for the seed, highlighted with underlining, are almostexactlythe statements \nmostrelevanttothebugin question. We are interested in the pointer value infirstName at line 24, and the \nthin slice allows us to easily trace its .ow (relevant expressions are underlined): Line 23 copies the \nvalue returned by Vector.get().  Vector.get() obtains the value from an array read (line 8).  The value \nis copied into the array in Vector.add() (line 5).  Vector.add() gets the value from the actual parameter \nat line 17.  Line17 passesthevalue returnedat line16,thebuggy state\u00ad ment.  Unlike a traditional slice, \nthe thin slice does not provide an exe\u00adcutable program; for example, statements initializing the Vector \ncontaining the erroneous String are not included. However, the thin slice more directly leads the user \nto thebug. Advantages of Thin Slicing One reason that thin slicing works wellisthatitignoresvalue.owintobasepointersofheap \naccesses, focusingjustonthevaluereadfromor writtentotheheap.Forex\u00adample, line8reads this.elems[ind].Athin \nslicer ignores theval\u00adues of the two dereferenced base pointers(this and this.elems), focusing solely \non statements that can write into the array(i.e., line5).In contrast,a traditional slicer includes statements \nin.uenc\u00ad ing both the base pointers this and this.elems (dereferenced to access the array contents), \ncontributing to the blowup in slice size. For manyprogram understanding tasks, base pointer manipulation \nmatters less than actual copying of the value through the heap. Thin slices have an intuitive semantic \nde.nition, making them easier to understand than some ad-hoc pruning of the traditional slice. Simply \nstated, a thin slice contains all statements .owing values to the seed, ignoring uses of base pointers. \nThese well\u00adde.ned semantics allow a user to reason about thin slices in a self\u00adcontained manner, since \nshe knows that all producer statements are included in a thin slice. If slices were shrunk using some \nad\u00adhoc method, such as setting a constant limit on slice size, the user could not easily characterize \nwhat is in the presented slice subset and what is missing. In cases where a thin slice aloneis insuf.cient \nfor some pro\u00adgrammer task,it canbeexpanded with additional thin slicesto ease the understanding of other \nrelevant statements. One case in which statements outside the thin slice may be needed is to explain \nheap\u00adbasedvalue .ow, established through pointer aliasing.Forexam\u00adple,givena .eld read x := y.f anda.eld \nwrite w.f:= z ina thin slice, a user may ask how aliasing between y and w arises, causing heap-based \n.owfrom z to x. This question can be answered via two more thin slices, respectively showing how some \nobject o .ows to both y and w.Thisexpansionofthethinslicecanberepeated recur\u00adsively for further aliasing \nquestions, yielding a structured method for studying the often large set of statements relevant to nested \ndata structures. A similar expansion technique applies to explaining why thin slice statements can execute, \ni.e., showing their transitive control dependences.Traditional slicers must include all transitive control \ndependences. Unfortunately, Java s semantics make many state\u00adments a type of conditional branch, often \nyielding a huge number of control dependences.Forexample,ifa statement might throw anexception,manystatementswillbe \ncontrol dependentonits suc\u00adcessfulexecution. Similarly,each virtual call x.m() isaconditional expression \nbecause it branches on the runtime type of x. In practice, we found that when control dependences are \nrele\u00advant, they can usually be identi.ed from browsing the source code sincetheyappearlexically nearathinslice \nstatement, making their discovery straightforward. Further thin slices can be taken to un\u00adderstand these \nimportant conditionals. In the limit, hierarchically expanding a thin slice to show control and aliasing \nexplanations yieldsatraditional slice; hence, anypossibly relevant statement can eventually be discovered. \nOf course, thin slicing does not provide a panacea: in certain cases, thin slices with expansion grow \ntoo large to effectively iden\u00adtify statements of interest. However, for most tasks we tested, thin slices \nwith little or noexpansionincluded the desired statements forthetaskwithmanyfewerextraneous statementsthan \ntraditional slices. The current paper focuses on static thin slicing forJava,but the technique is more \nbroadly applicable. Thin slicing itself relies on standard data dependence concepts [10] and hence should \napply to manyprogramming languages. Our hierarchicalexpansion tech\u00adnique relies on properties of Java \npointer accesses, however, and many notworkaswellfor languageslikeC(see Section4).Also note that dynamic \nthin slices can be de.ned in a straightforward manner using dynamic data dependences. Contributions This \npaper makes the following contributions: We de.ne a thin slice asproducer statements for a given seed. \n We present a method for hierarchically expanding thin slices to explain whyproducer statements affect \nthe seed, in the limit yielding a traditional slice.  We present simple modi.cationstoexisting slicing \nalgorithms for computing both context-insensitive and context-sensitive thin slices.  We present experiments \ncomparing thin slicing and traditional slicing for several debugging and program understanding tasks, \nusing a methodology that simulates realistic use of a slicing tool (details in Section 6). Our results \nshow that (1) thin slices usually included the desired statements for the tasks(e.g., the buggy statement \nfor a debugging task), and (2) thin slices re\u00advealed desired statements after inspecting 3.3 times fewer \nstate\u00adments than traditional slicing for debugging tasks and 9.4 times fewer statements for program understanding \ntasks. We also showed that our thin slicing algorithm scales to relatively large Java benchmarks.  The \nrestof this paperis organized as follows. Section2de.nes producer statements and the thin slicing process, \nand Section3de\u00ad .nes thin slices using traditional dependences. Section4describes our techniqueforexpandingthin \nslicestoexplain heap-basedvalue .ow and control dependences. Section 5 presents algorithms for computing \nthin slices as variants of a traditional slicing algorithm. Section 6 gives our experimental evaluation, \nSection 7 discusses relatedwork, and Section8concludes. 2. De.ning Thin Slices In this section, we de.ne \nthe producer statements included in a thin slice. We also show how statements excluded from the thin \nsliceexplainwhytheproducer statementsaffecttheseed.Asimple example, seen in Figure 2, is used to illustrate \nthese concepts. Section 3 de.nes the statements in a thin slice using traditional notions of dependence. \nSlicing determines the parts of a program relevant to some seed statement. In traditional slicing, relevance \nis de.ned as any statement possibly affecting the values computed by the seed. As originally statedbyWeiser \n[28], this relevance de.nition requires the slice to include an executable subset of the program in which \nthe seed always performs the same computation as in the original Figure 2. Asmall program to illustrate \nthin slicing. Directly-used locations(see Section2)inthethinsliceforline7 are underlined. 1 x = new A(); \n2 z = x; 3 y = new B(); 4 w = x; 5 w.f = y; 6 if (w == z) { 7 v = z.f; // the seed 8 } program. Thin \nslicing differs from classical slicing primarily in its more selective notion of relevance. With thin \nslicing, only producer statements for the seed are relevant.We de.ne producer statements in terms of \ndirect uses of memory locations(variablesor object .eldsinJava).Astatement s directly uses a location \nl iff s uses l for some computation other than a pointer dereference. For example, the statement y = \nx.f does not directly use x,but it does directly use o.f, where x points to o.Astatement t is a producer \nfor a seed s iff(1) s = t or (2) t writesavaluetoa location directly usedby some other producer. Consider \ncomputingathinsliceforline7inthetoy exampleof Figure2. Line7directly uses an object .eldwrittenat line5(since \nw and z are aliased),and therefore, line5isa producer. Similarly, line5 directly uses y, whichis writtenat \nline3, making line3 a producer as well. Hence, lines5and3 are comprise the thin slice for line7(along \nwith line7itself).In contrast, the traditional slice for line7is the entireexample. We call the non-producer \nstatements in the traditional slice explainer statements. These statements show why the producer statements \ncan affect the seed. Explainer statements can show one of two things about the producers: Heap-basedvalue \n.ow When values .ow between producers through heap locations, the locations are accessed using aliased \npointers. Explainer statements show how these base pointers may become aliased. Control .ow The remaining \nexplainer statements show the condi\u00ad tions(i.e.,theexpressionsin conditional branches) under which producer \nstatements actually execute. Consideragaintheexampleof Figure2. Lines2and4showthat w and z both point \nto the A object allocated at line 1. Hence, these lines areexplainers for the heap-basedvalue .ow between \nlines5 and7in the thin slice. Line6 explains control .ow, showing the condition under which the seed \nstatement actually executes. Thin slicing s separation of producer and explainer statements provides \na natural, structured method for exploring a traditional slice.Traditional slices must include transitive \nexplainer statements (i.e., explainers for the explainers and so on), since any statement possibly affecting \nthe seed is relevant for such a slice. While this transitivitycanleadtoanoverwhelming numberofexplainer \nstate\u00adments, thin slices structure them into a manageable hierarchy. Ex\u00adplainers for heap-based value \n.ow in a thin slice can be shown us\u00ading twoadditional thin slices, as shown in Section 4.1. The behavior \nof a conditional guarding a thin slice statement can also be under\u00adstood through an additional thin slice. \nIn this manner, more and more thin slices can be used to show explainers, in the limit yield\u00ading the \ntraditional slice. In practice, we have found that very few explainers are needed to accomplish typical \ndebugging and understanding tasks. In our evaluation, over half the tasks could be completed with a thin \nslice alone. In most other cases, only one or two explainer statements Figure 3. Adependence graph for \nthe program of Figure 2. Thick edges indicate non-base-pointer .ow dependences, used for thin slicing.Traditional \nslicingalso usesbasepointer.ow dependences (the dashed edges) and control dependences (the dotted edge). \n were required,andtheseexplainerswerelexicallyclosetothinslice statements (further discussedin Section \n4.2). Hence, thin slicing is highly effective at identifying the statements in a traditional slice most \nrelevant to developer tasks. 3. Thin Slices as Dependences In Section2,we de.nedthin slicesin termsof \nproducer statements. Here we de.ne thin slices in terms of the dependences typically used to de.ne traditional \nslices. The thin slice for a seed s is a subset of those statements upon which s is transitively .ow \ndependent (also known as data dependent), obtained by ignoring uses of base pointers in dereferences. \nAstatements is .ow dependent on statement t if the following three conditions hold [10]: 1. s can read \nfrom some storage location l. 2. t can write to l. 3. There exists a control-.ow path from t to s on \nwhich l is not re-de.ned.  ForJava-likelanguages, storage locations are eithervariables (local or global) \nor object .elds, with the latter accessed through some .eld dereference of the form x.f.Traditional slices \nmust include the transitive .ow dependences of the seed. Thin slices ignore base pointer .ow dependences, \nthereby excluding statements explaining heap-based value .ow. A base pointer .ow dependence is a .ow \ndependence due solely to the useofa pointerina .eld dereference.For the statement y = x.f, .ow dependences \ndue to the use of x are base pointer .ow depen\u00addences. Similarly,a statementoftheform p.f = q has base \npointer .ow dependences due to the use of p. Ignoring base pointer .ow dependences leaves only producer \n.ow dependences, which transi\u00adtively connecta statement to its producers.Forexample, y = x.f would have \na producer .ow dependence to some statement z.f = w, where x and z may be aliased. Figure 3 shows an \nexample dependence graph for the pro\u00ad gram of Figure 2. Nodes represent statements, and edges represent \ndependences between statements. As is standard for dependence graphs [11, 22], edges are drawn in the \ndirection opposite of the dependences, so thin slicing requires computing backwards reach\u00adability. In \nFigure 3, the solid edges indicate the producer .ow de\u00ad pendences, while the dashed edges indicate ignored \nbase pointer .ow dependences. The dotted edge is a control dependence, to be discussed shortly. The seed \nv = z.f is only reachable from w.f = y and y = new B() via solid edges, and these statements are the \nproducers for the seed, as expected. Note that thin slices also exclude control dependences, explain\u00aders \nof control .ow. Intuitively, statement s is control dependent on conditional e if e can affect how manytimes \ns executes (Tip s sur\u00advey[27] hasamore formal de.nition). Figure3hasadotted control dependence edge from \nconditional w == z to v = z.f, the state\u00adment in its if blockin Figure2. Section4describes our empirical \nobservation that important control dependences are nearly always Figure 4. An example for showing expansion \nof thin slices, simi\u00adlartoanexamplewesawin ourevaluation.Thebugisanexception thrownat line11,and understandingthebug \nrequiresanexplana\u00ad tion of aliasing (Section 4.1) and following a control dependence (Section 4.2).Weuse \nsingle underlinesto highlight relevantexpres\u00ad sions in the initial thin slice, and double underlines \nfor expressions in explainer statements for aliasing. 1 class File { 2 boolean open; 3 File() { ...; \nthis.open = true; } 4 isOpen() { return this.open; } 5 close() { ...; this.open = false; } 6 ... 7 } \n8 readFromFile(File f) { 9 boolean open = f.isOpen(); 10 if (!open) 11 throw new ClosedException(); 12 \n} ... 13 } 14 main() { 15 File f = new File(); 16 Vector files = new Vector(); 17 files.add(f); 18 ...; \n19 File g = (File)files.get(i); 20 g.close(); 21 ...; 22 File h = (File)files.get(i); 23 readFromFile(h); \n24 } lexically close to thin slice statements, and hence can be discovered easily. 4. Expanding Thin \nSlices Here, we discuss in more detail how thin slices can be expanded to showexplainer statements, as \ndiscussedin Section2.To review, explainer statements can answer questions of the following form about \na thin slice T : 1. Given statements x := y.f and w.f := z in T such that w and y are aliased (causing \nvalue .ow from z to x), what statements cause the aliasing? 2. Under what conditions can some statement \ns in T execute?  A thin slicing tool answers these questions when requested by the user. Section 4.1 \ndiscusses a technique for explaining aliasing using two additional thin slices. Section 4.2 discusses \nhow relevant control dependences are usually close to thin slice statements, making their discovery relatively \nstraightforward. Example We use the example in Figure 4, a simple program frag\u00ad ment manipulating a .le, \nto illustrate thin slice expansion. The ex\u00adample displays only a small part of the File implementation, \nthe tracking of whether the .le is open using a boolean .eld. The readFromFile() function throws an exception \nif the .le passed to it is not open. Finally,the main() method createsa.le, erroneously closes it, and \nthen passes it to readFromFile(), causing the excep\u00adtion. The File object is read from a Vector before \nbeing passed to close() and readFromFile(), complicating discoveryof thebug. 4.1 Question 1: Explaining \nAliasing When a thin slice includes statements that copy a value through the heap, sometimes the user \nneeds to understand whythose state\u00adments access the same heap location.For theexampleof Figure4, suppose \nthat the user asks for a thin slice from line 10 to determine why line 11 threw an exception. The computed \nthin slice will be {3, 4, 5, 9, 10} (highlighted with underlines), the only statements that can produce \nthe boolean open value. Clearly, these statements fail to diagnose the bug completely: the user still \ndoes not know which File is passed to close() before being passed to isOpen(). To diagnose this bug, \nthe user must determine which statements cause the this pointers of close() and isOpen() to be aliased. \nWe can expand thin slices to explain aliasing by computing additional thin slices for the base pointers \nin question. Given aliased base pointers x and y, we compute thin slices seeded with the statements de.ning \nx and y (unique assuming SSA form). These thin slices will show why some common object o can .ow to both \nx and y, causing them to be aliased. For Figure 4, the common object for the this parameters of close() \nand isOpen() is the File allocated at line 15. Double underlines in Figure4 indicate the statements added \nto explain the .ow of the File (the Vector class is elided for clarity). Note line 16 is still omitted, \nas it does not touch the File object. Given these thin slices, the user sees that line 20 closes the \nFile, and that thebug couldbe .xedby either not closing the .le or by removing it from the Vector. Explaining \naliasing using additional thin slices yields an intu\u00aditive hierarchical structure to heap-based .ow, \nmaking it more un\u00adderstandable for the user. Suppose that statements x := y.f and w.f:= z appearina thin \nslice. Expanding the thin slice to show .ow into x and w adds one more level of data dependences to the \nslice. If during expansion, statements a := b.g and c.g := d are added, the aliasing of b and c couldbeexplained \nwith anotherlevel of data dependences, and so on. If Figure4 were changed so that the .ow of the Vector \nto the add() and get() in main() was com\u00adplex(e.g., it got stored in a data structure), another level \nof thin slices would explain that .ow. The ability to show these different levelsof aliasingina structured \nmanner relies on thefact that only .eld reads and writes can dereference pointers in Java; in C, which \nallowsfor creating pointersto pointersand taking addressesofvari\u00adables,explanationsofwhytwostatements \naccessthe same memory location may not be so simple. Array accesses can require explainer statements \nbeyond those showing the aliasing of the array pointers. Say that we have state\u00adments a = b[i] and c[j] \n= d in the thin slice, such that there is value .owfromd to a. In trying to understand this heap-based \n.ow, the usermaywonderboth(1)how b and c can be aliased (the same question as with .eld accesses), and \nadditionally (2) how the array indices i and j can have the same value. The latter question can be answered \nthroughthin slicesoneachofthe arrayindexexpressions (with anynecessary expansion). Two additional technical \npoints about explaining aliasing merit mention. First, the thin slices explaining aliasing should be \nre\u00adstricted to only show the .ow of objects that can .ow to both base pointers, .ltering statements showing \n.ow of an object to just one of them. This .ltering eliminates some statements irrelevant to ex\u00adplaining \nthe aliasing. Second, context sensitivity may be necessary to focus the aliasingexplanationsin some cases. \nForexample,if thecodeofFigure4werepartofalarge programwheremany File objects were used, the userwould \nlikelywantto ask about aliasing this in isOpen() for the particular call at line 9, rather than for all \ncalls. We encountered one case in which an explanation of aliasing was necessary in our experiments, \nand we believe that manysim\u00adilar situations often arise in practice. In our programming experi\u00adence, \nwe have found that when suchbugs arise, they can be tricky to debug, as values can be mutated in unexpected \nplaces. Analyses that .nd typestatebugs [6, 8], e.g., reading from a .le after clos\u00adingit, could bene.tfromusingthin \nslicestoexplainbugsthatin\u00advolve aliasing. Such tools sometimes hide error reports that involve aliasing, \nsince there is no mechanism in the tool for explaining the aliasing succinctly [15].  4.2 Question 2: \nControl Dependence In our experience, when a debugging or program understanding task requires viewing \ncontrol dependences, the control-relevant statements usually lie lexically close to some statement in \nthe thin slice.In Figure4,thebug manifestsat line11, which throwsthe exception. As no value .ows into \nthe throw statement, a thin slice from the throw statement will not aid debugging. However, code inspectionimmediatelyshowsthatthe \nconditionofthe if statement at line 10 is relevant to thebug, as it directly controls whether the exceptionisthrown.Withthis \ninformation,theobviousnextstepis tothinslicefromline10tolearn moreaboutthebug,as described in Section \n4.1. While this example may seem contrived, our experiments show that Figure4re.ects the common case.For \nnearly all tasks in our evaluation, at most one or two control dependences were relevant, and theyall \nlay syntactically close to statements in the thin slice. We also found that the vast majority of control \ndependences are unnecessary for understanding the seed behavior. Hence, we be\u00adlieve that in practice, \nsimply showing the thin slice statements in the source code suf.ces for identifying anyrelevant control \ndepen\u00addences; the user can take additional thin slices from relevant con\u00additionals to understand their \nbehavior. Additional tool support may be useful for indicating non-obvious control dependences, e.g., \ndue to exceptions. 5. Computing Thin Slices Computing a thin slice entails computing a statement s transitive \n.ow dependences, ignoring uses of base pointers (as discussed in Section 3). As in previous work on slicing \n[11, 20], we compute thin slices using variants of graph reachability. Here, we .rst de\u00adscribe the basics \nof constructing our graph representation, a subset of system dependence graphs [11] (Section 5.1). Then, \nwe brie.y present two simple algorithms to compute thin slices, one context insensitive (Section 5.2) \nand one context sensitive (Section 5.3). 5.1 Graph Construction In both thin slice algorithms, we .rst \ncompute a subset of the sys\u00adtem dependence graph (SDG) program representation of Horwitz et al. [11]. \nPrevious work [3, 13] has described how to compute SDGs for Java-like languages, and we mostly re-use \nthose tech\u00adniques (slight differences are discussed in Section 7). Our imple\u00ad mentation handlesthefullJavaVirtual \nMachine bytecode language, excluding concurrency.Our representationdiffersinthatwe(1)ex\u00adclude control \ndependence edges and (2) handle heap-based .ow dependences differently, depending on the thin slicing \nalgorithm (details in Section 5.2 and Section 5.3). SDG construction relies on a pre-computed points-to \nanalysis. We use the points-to analysis to compute a call graph for the program, necessary for tracking \ninterprocedural dependences.We also use the points-to analysis to determine which heap locations canbe \nde.ned(used)by.eldwrites(reads),inordertotrackheap\u00adbasedvalue .ow. Section6shows that precise points-to \nanalysisis keyfor effective thin slicing of Java programs. Our representation of data dependences for \nlocal variables and method parametersis straightforward.Atahighlevel,we represent such dependences as \nfollows: 1. For a statement x=e, where x is a local, we add edges to all statements using x, excluding \nuses in pointer dereferences of the form x.f.We operate on an SSA representation, so these edges are \nadded .ow sensitively. 2.Foran actual parameternodeforacallto method m(),we query the pre-computed call \ngraph to .nd the possible call targets m1,...,mk. Then, for each mi,we add an edge from the actual parameter \nnode to the corresponding formal parameter node. Return values are handled similarly. Our thin slicing \nalgorithms differ from the standard SDG handling of data dependence, and from each other, in their treatment \nof de.nitions of heap locations(i.e., statements of the form x.f := e)as described below. 5.2 Context-Insensitive \nThin Slicing Our .rst algorithm computes traditional (context-insensitive)graph reachability on our SDG \nvariant to compute thin slices. In this ap\u00adproach, we represent data dependences for heap access statements \nas follows: For a statement x.f := e, we add an edge to each statement with an expression w.f on its \nright-hand side, such that the pre\u00adcomputed points-to analysis indicates x may-alias w. Note that we \nadd direct edges to statements in other procedures. Incontrast, the traditional SDG only includes interprocedural \nedges for parameter passing and return values. The advantage of this ap\u00adproach is that we need not model \nheap accesses using additional pa\u00adrameters and return values, as is done with traditional slicing [11]. \nIn practice, not using heap parameters dramatically increases scala\u00adbility without signi.cant loss in \nprecision (discussed further in Sec\u00ad tion 5.3 and Section 6). Having computed the graph,asimple transitiveclosuregives \nthe thin slice for a particular seed. It is straightforward to construct the graph anddo the traversalina \ndemand-drivenfashion.Apotential disadvantage of this approach is that it may return unrealizable paths[21]duetolackof \ncontextsensitivity(Section6showsthis issue is not signi.cant in practice).  5.3 Context-Sensitive Thin \nSlicing The context-sensitive thin slicing algorithm uses an SDG variant closer to that used in traditional \nslicing, created compositionally from program dependence graphs (PDGs) for each procedure. In\u00adtraprocedurally, \nthis approach handles heap accesses as follows: For a statement x.f := e, we add an edge to each statement \nwith an expression w.f on its right-hand side in the same pro\u00adcedure such that the pre-computed points-to \nanalysis indicates x may-alias w. We handle interprocedural heap .ow in the same way as the standard \nSDG, with heapreads and writes modeled asextra param\u00adeters and return values to each procedure [5, 11]. \nOur implementa\u00ad tion introduces such parameters using the same heap partitions used bythe preliminary \npointer analysis. Discovering the appropriate set of parameters for each procedure requires an interprocedural \nmod\u00adref analysis [24], computed using the result of the pre-computed points-to analysis. Having built \nthe graph, we compute context-sensitive reacha\u00adbility as a partially balanced parentheses problem [20]. \nOur imple\u00ad mentation relies on a backwards, demand-driven tabulation algo\u00adrithm [21]. In our experience, \nconstructing an SDG using heap parameters can be very expensive for large programs. Furthermore, we found \nthat for realistic usage patterns, context sensitivity did not provide much bene.t for thin slicing. \nSee Section6for details. 6. Evaluation We now present an empirical evaluation of thin slicing for debug\u00adging \nand program understanding tasks. Our experiments validate fourhypotheses: Thin slices lead the user \nto desired statements. For the tasks we considered, thin slices often contain the desired statements \n(e.g., thebuggy statement fora debugging task). When state\u00adments explaining pointer aliasing or control \n.ow were relevant, the statements were always lexically close to statements in the thin slice. Subjectively, \nwe also found a thin slicer very useful for understanding one set of benchmarks.  Thin slices focus \nbetter on desired statements than tra\u00additional slices. We compared context-insensitive thin slicing to \ncontext-insensitive traditional slicing (the context-sensitive con.gurations did not scale) with identical \nhandling of control dependences and a breadth-.rst strategy for inspecting state\u00adments, simulating real-world \nuse of a program understanding tool. The experiments showed that .nding desired statements in a traditional \nslice required inspecting 3.3 times more state\u00adments than a thin slice for the debugging tasks, and 9.4 \ntimes more statements for the program understanding tasks.  Aprecise pointer analysisiskeyto effective \nthin slicing.We used a pointer analysis with object-sensitive handling [16] of key collections classes \nfor the thin slicer. With a less precise pointer analysis, up to 17.2X more statements required inspec\u00adtion \nin thin slices to .nd desired statements.  Thin slices can be computed ef.ciently. Our context\u00adinsensitive \nthin slicing algorithm scaled well to large programs, with the cost of computing thin slices insigni.cant \ncompared to the pre-requisite call graph construction and pointer anal\u00adysis. We were unable to scale \na context-sensitive traditional slicer [11] to our larger benchmarks.  6.1 Con.guration and Methodology \nWe implemented the thin and traditional data slicers using the IBM T.J. Watson Libraries for Analysis \n(WALA) [2]. We utilized call graph construction and pointer analysis algorithms provided by WALA, along \nwith its tabulation solver for context-sensitive anal\u00adysis [21].We analyzed our benchmarks with the Sun \nJDK 1.4.2_09 standard library code, for which WALA provides models of im\u00adportant native methods.WALA \nuses heuristics to analyze the most common usesof re.ectioninJava,butin general re.ectionand na\u00adtivemethods \nmay still cause some unsoundness, as is typical in Java static analysis implementations. All experiments \nwere performed on a Lenovo ThinkPad t60p with dual 2.2GHz Intel T2600 proces\u00adsors and 2GB RAM. The analyzer \nran on the Sun JDK 1.5_07 using at most 1GB of heap space. Table 1 provides information about the programs \nused in our experiments.For pointer analysis and call graph construction, we used a variant of Andersen \ns analysis with on-the-.y call graph construction [4, 23], with fully object-sensitivecloning [16] for \nob\u00ad jectsofkeycollections classes,as describedin[8](the importance ofthis precisionis discussedlaterinthe \nsection).Weexcludedfrom the call graphs a few large standard libraries(e.g.,javax.swing, java.awt)which \nwe deemeda priori uninteresting for the tasks at hand, since noneof our tested tasksinvolved those libraries.For \nall experiments reported, call graph construction and pointer analysis ranin under5minutes. Scalability \nFor the dependence graph traversal, we considered both the context-insensitive (.at graph reachability) \nand context\u00adsensitive (tabulation) algorithms presented in Section 5. In all cases, the time and space \nto compute the thin slice or tradi\u00adtional slice with the context-insensitive algorithmwas insigni.cant \nSPECjvm98 nanoxml jtopas ant xmlsec 541 337 11147 11192 35 24 632 678 817 397 20164 17075 22205 23766 \n584155 525886 mtrt jess javac jack 470 1061 1610 592 32 67 118 55 514 1466 2127 1088 19699 46037 71041 \n38114 Table 1. Benchmark characteristics, derived from methods discov\u00adered during on-the-.y call graph \nconstruction, including Java li\u00adbrary methods.Thenumberofcallgraphnodesexceedsthenumber of distinct methods \ndue to limited cloning-based context-sensitivity in the points-to analysis. SDG Statements reports the \nnumber of scalar statements,butexcludes parameter passing statements intro\u00adduced to model the heap. compared \nto the preliminary pointer analysis. Context-insensitive thin slicing took under 6 seconds for all tests \nexcept ant, which took 47 seconds since a large number of interprocedural heap de\u00adpendence edges had \nto be added. These low running times are not surprising, as context-insensitive slicing (thin or traditional) \nre\u00adducestosimplegraph reachabilityonademand-driven construction of the SDG program representation. Our \nimplementation of context-sensitive traditional slicing [22] scales to handle most experiments on the \nsmaller test cases (nanoxml, jtopas, mtrt, jack). For the larger codes, our imple\u00admentation could not \ncompletein reasonable time and/or space.We believe our implementation is fairly well-tuned, as the analysis \nengine (based on tabulation [20]) has evolved over several years and been used in several studies reporting \nscalable interprocedural data.ow analyses(e.g., [8]).For slicing, thekeybottleneck comes from handling \nof the heap; as programs grow larger, the number of SDG statements introduced to model heap parameter-passing \nquickly explodes, dramatically increasing space and time require\u00adments.For ourlarger benchmarks,the fullSDGgrewtoover10 \nmillion nodes before exhausting available memory; we suspect the number of nodes would grow much larger \ngiven adequate space. Note that heap parameters are also a scalability bottleneck in a commercial slicing \ntool [26]. In all results reported, we compare results from the context\u00adinsensitive thin slicer to a \ncontext-insensitive traditional slicer, which scaled to all benchmarks. This provides an apples-to-apples \ncomparison, as all experimental parameters match exactly for the two algorithms; the only difference \nwas how each handled data dependences. Measuring Slice Size Nearly all existing work measures the precisionofaslicebyitsfullsize.However,in \npractice, onceauser of a program understanding tool has discovered all of the desired statements for \nher original problem(e.g., those causing somebug), she will not inspect the rest of the slice. Our experiments \naim to simulate this realistic usage pattern. For each task, we identify bothaseed statement for the \nslice and a set of desired statements, i.e., those statements whose discovery suf.ces for completing \nthe task.Forexample, fora debugging task, the seed is the point of failure, and the desired statement \nis the causeofthebug.Wethenaimto measurehowmanystatementsin the slice the user must inspect to discover \nthe desired statements. We use a breadth-.rst traversal strategy to simulate the order in which statements \nare inspected by the user, as in the work of Renieris and Reiss [19]. Intuitively, statements closer \nto the seed seem more likely to be relevant to its behavior. Hence, we assume the user gradually explores \nstatements of increasing dis\u00adtance (de.ned by the dependence graph of the technique) from the seed until \nthe desired statements are found; a breadth-.rst search of the dependence graph simulates this strategy. \nNote that CodeSurfer [1], perhaps the most widely-used slicing tool, supports such dependence-graph browsing \nfor viewing slices. The BFSeval\u00aduation metric has also been used in other recent work [19, 31, 34]. For \nthin and traditional slicing, our tables report the number of statements inspected using this breadth-.rst \ninspection strategy. Toourknowledge, oursisthe .rstworkto compare static slicing algorithms using a measure \nintended to simulate the usage of a realistic tool, rather than just comparing the full slice sizes. \nWe note that the two measures produce qualitatively different results. For example, in one of our smaller \ntest cases,nanoxml-1, context sensitivity reduces the traditional slice size from 8067 statements to \n381 statements, but the number of statements explored in the traversal decreasesonlyfrom32to26.We observed \nsimilar results for thin slices. Given these results, the context-sensitive algorithm of Section 5.3 \ndoes not seem bene.cial for thin slicing as likely used in practice. Control Dependence As discussed \nin Section 4.2, relevant control dependences were observed to be always lexically close to state\u00adments \nin the thin slice, as in the example of Figure 4. Furthermore, most control dependences were not useful \nfor the tested tasks, and it is not obvious how to automatically expose important control de\u00adpendences. \nHence, we manually pre-determined the important con\u00adtrol dependences for our tasks, and counted only \nthose control de\u00adpendences as inspected for both the thin and traditional slicers. This handling of control \ndependences allowed us to focus on the effec\u00adtiveness of thin slicing s handling of data dependences \ncompared with a traditional slicer s. Threats to Validity One threat to the validity of our results is \nthat our study of debugging tasks (Section 6.2) uses injected bugs from the SIR suite [7], which may \nnot accurately re.ect the characteristics of realbugs. Several techniques were used to make the injectedbugsintheSIR \nsuite realistic, describedin detailin[7]. Thebugs wereofa widevariety:theycould alter boththe control \nanddata.owofthe program,andthe resultingfailuresrangedfrom program crashesto incorrect output.Nevertheless,we \nintendtodoa futurestudywithrealbugsto con.rmthatthinslicingstillprovides a signi.cant bene.t. Our use \nof breadth-.rst search on the dependence graph to simulate programmer exploration of the slice may not \naccurately re.ect how developers would use a slicing tool. If most developers are able to very quickly \nprune statements in a traditional slice irrelevant to their tasks, then the BFS metric would overstate \nthe advantageofthin slicing.Inthe future,weaimtodoauserstudyto obtain more de.nitive answers on the productivity \nbene.ts of thin slicing. Finally, our use of whole-program pointer analysis and call graph construction \nfor the thin slicer may not scale to larger bench\u00admarks. These analyses also may not be suitable for \nuse inside a development environment, as code edits could require expensive re-computation of the pointer \nanalysis results.We plan to employ demand-driven, re.nement-based pointer analysis [25] in the next version \nof the thin slicer to overcome these drawbacks. 6.2 Experiment: Locating Bugs Our .rstexperiment testedlocatingseveralbugs,(1)to \nseeif thin slices include the buggy statement when slicing from the seed, and (2) to compare the number \nof inspected statements for thin and traditional slices.We investigated several injectedbugs in the Java \nprograms in the Software-Artifact Infrastructure Repository (SIR) [7]. SIR provides both several injectedbugs \nfor each program andtest suitesthatcanbeusedtoexposethebugs.Foreach injected bug, we ran the corresponding \ntestsuiteto discoverafailure. Then, we ran both thin and traditional slicing from the failure point, \nmeasuring how many statements had to be inspected to .nd the bug (as described in Section 6.1). Three \npoints should be noted about the SIR programs and in\u00adjectedbugs. First,we were unableto includetwoSIR \nprogramsin these experiments, jmeter and siena.We could not determine the appropriate library dependences \ntobuild jmeter, and in our runs, no test cases exposed the injected bugs in siena. Also, the suite providesseveralversionsofeach \nbenchmark;wechosebugsfrom the most recent versions. Finally, some of the injected bugs rep\u00adresentbugs \nof omission, i.e.,bugs that deleted necessary code. If the omissionbug removedan assignmenttoa localora \nconditional branch, we chose as the desired target statements the immediate data or control dependent \nsuccessor statements, respectively. We excludedbugs that deleted .eld writes, astherewas noobvious re\u00adlationship \nbetween the deleted write and the surrounding code in the method. Table2presents resultsfor ourdebuggingexperiment.Several \nof the injected buggy statements were quite close to the failure points of the programs, and hence both \nthe traditional and thin slicers found thebugsvery quickly.Forexample, with jtopas-1, the buggy statement \nitself fails with a NullPointerException. These sorts ofbugs can be easily debugged without tool support, \nbut we include them for completeness. Using the traditional slicer required inspecting1 to 4.52 times \nmore statements than thin slicing to .nd thebug. The total number of inspected statements for traditional \nslicing was 3.3 times higher thanwiththinslicing,ameasureofthetotal inspectioneffortsaved. The injectedbugsin \nnanoxml in particular often required tracing a value as it is inserted and later retrieved from one or \ntwo Vectors, as in the example of Figure 1. Tracing this .ow by hand can be dif.cult and time-consuming, \nand hence we think that thin slicing canhave the greatest impact for this typeofbug. Debugging nanoxml-5 \nrequired exposing statements causing aliasing (see Section 4.1), for reasons similar to those of the \nexam\u00ad ple in Figure 4.To simulate this user action, we ran the thin slicer in a con.guration that included \nstatements explaining one level of indirect aliasing.The resultsshowthatexposingsuch statementsin this \ncontrolled manner is useful, as we still inspected signi.cantly fewer statements than the traditional \nslice. Few control dependences were relevant for these debugging tests, validating our decision to ignore \ncontrol dependence in thin slices. For all but one bug, the number of control dependences that need to \nbe followed is 2 or less. These control dependences were always obvious from code surrounding the thin \nslice (as discussed in Section 4.2). The high number of control dependences for ant-3 is due to thefact \nthat thebuggy function has 12 return statements, and one of them is directly control dependent on the \nbug; we included one control dependence for each return, as it is notobvious which one causedthebug.Nevertheless,allthe \ncontrol dependences were still near statements in the thin slice. The precision of our preliminary points-to \nanalysis was key to the effectiveness of the thin slicer. The ThinNoObjSens and TradNoObjSens columns \ninTable2show our results to be con\u00ad siderably worse with a points-to analysis that does not treat con\u00adtainer \nclasses like Vector object sensitively. In cases involving such data structures, the number of statements \ninspected with the thin slice increasedbyuptoafactorof17.2Xwiththelesspreciseanal\u00adysis, likely making \nthe thin slicing tool unusable. 1 class Node { 2 final int op; 3 static int ADD_NODE_OP = 1; 4 Node(int \nop) { this.op = op; } 5 } 6 class AddNode extends Node { 7 AddNode(...) { 8 super(ADD_NODE_OP); ... 9 \n} 10 } 11 void simplify(Node n) { 12 int op = n.op; 13 switch (op) { 14 case ADD_NODE_OP: 15 AddNode \nadd = (AddNode) n; 16 ... 17 } 18 } Figure 5. An example illustrating a tough cast. Expressions in the \nthin slice used to understand the safety of the cast are underlined. Finally, for .vebugs in xml-security \nand onebug in ant, no type of slicing could help the user .nd thebug, and hence theydo not appear in \nthe table. The xml-security bugs all followed the same pattern: long hash = computeHash(input); // buggy \nassert hash == expectedHash; // fails In xml-security, the computeHash() equivalent is complex, span\u00adning \nseveral .class .les, and the injectedbugs wereburied in the algorithm internals. In such cases, slicing \nfrom this assertionfail\u00adure (whether static or dynamic) will inevitably bring in most or all of the code \nthat computes the hash function. This example illus\u00adtrates that slicing of course is not a panacea; delta \ndebugging [29] or refactoring to test at a .ner granularity may help in these situa\u00adtions.We.ndthefactthatthinslicingwas \nusefulfor13outof19 inspectedbugs encouraging. In summary, we found that for these injectedbugs, thin \nslices very often contain the buggy statements, and the bugs could be found more quickly witha thin slicer \nthana traditional slicer. Also, 11.5 statements on average required inspection with the thin slicer (ranging \nfrom 1 to 35), quite a manageable number; the average for the traditional slicer was signi.cantly larger \nat 54.8 statements, ranging from1to 156.  6.3 Experiment: UnderstandingTough Casts Our second experiment \ninvolved using slicing to hand-validate the safety of tough casts in the SPECjvm98 benchmarks.Atough \ncast is a downcast in a program that cannot be veri.ed by precise and scalable pointer analysis (we used \nthe same pointer analysis used to construct our call graph). For example, the cast at line 15 in Figure \n5, adapted from the javac benchmark,isa tough cast. This cast cannotfail becausethevalueofthe op .eld \nof AddNode objects is ADD_NODE_OP, as guaranteed by line 8, and no other subclasses of Node (not shown) \nhave ADD_NODE_OP in their op .eld.Typically, tough casts are those that (1) are not used to cast values \nretrieved fromacontainer(duetolackof generics)and(2)arenot dominated by an explicit instanceof check \nensuring their safety. Tough casts present a good test of the ef.cacyof thin slicing in aiding program \nunderstanding. The safety of tough castsis often due to some global invariant of a program. These invariants \nare of\u00adTable 2. Evaluationofthinslicingfordebugging.Foreachbug,weshowthe numberof statementsthatmustbe \ninspectedinthethinslice (the Thin column)andthe traditional slice(the Trad column)to discoverthebugusingBFStraversal(see \nSection6.1).Wealsogive the ratioof traditional statementstothin slice statements,andthe numberof control \ndependencesthat mustbeexposedto.ndthebug; the numbers for thin and traditional slices include these control \ndependences. Finally, we give the number of inspected statements for thin and traditional slicing when \ncontainer classes are not treated object sensitively [16] in the points-to analysis (the ThinNoObjSens \nand TradNoObjSens columns). Slicingof anykindwas not useful for.vebugsin xml-security and onebugin ant;thesebugsdo \nnot appear in the table. Bug #Thin #Trad. Ratio #Control #ThinNoObjSens #TradNoObjSens nanoxml-1 12 \n32 2.67 0 12 32 nanoxml-2 25 113 4.52 0 431 1675 nanoxml-3 29 123 4.24 0 472 1883 nanoxml-4 12 33 2.75 \n1 17 44 nanoxml-5 35 156 4.46 1 159 45 nanoxml-6 12 52 4.33 0 35 90 jtopas-1 1 1 1 0 1 1 jtopas-2 2 2 \n1 1 2 2 ant-1 2 2 1 1 2 2 ant-2 4 5 1.25 0 4 5 ant-3 34 55 1.62 15 251 501 ant-4 3 3 1 2 3 3 xml-security-1 \n2 2 1 1 2 2 ten (in our experience) undocumented, and discovering the invari\u00adants can aid the programmer \nin understanding the overall structure and behavior of the program. Furthermore, discovering these in\u00advariants \nby hand can be dif.cult, as it often requires tracing value .ow through several disparate parts of the \nprogram. Hence, easing the understanding of tough casts with tool support aids overall pro\u00adgram understanding \nand additionally can be useful for refactoring or adding parameterized types or annotations. Our experimental \ncon.guration involved .rst manually identi\u00adfying those statements that showed each tough cast could notfail \n(the desired statements of Section 6.1) with the help of the thin slicer, and then comparing the BFS \ntraversal sizes of the thin and traditional slices from the cast to these desired statements. In the \nexample of Figure 5, we can understand the tough cast through thin slicing by following a control dependence \nfrom the cast, and then computing a thin slice for line 12 to see what value op gets for different subclasses \nof Node.For each SPEC benchmark, we inves\u00adtigated 10 tough casts at random, or all tough casts if there \nwere fewer than 10. Note that the compress and db benchmarks had no tough casts, and mpegaudio was excluded \nsince its bytecodes are obfuscated, making understanding its casts dif.cult. Also, wefailed to deter\u00admine \nthe reason for cast safety for6 casts in javac and one cast in jess. In these cases, the safety of the \ncast relies on some subtle invariant that is not easy to determine for one unfamiliar with the code. \nThe thin slicer signi.cantly easedthe manual process of deter\u00admining the desired statements for each \ntough cast. Although the code was unfamiliar to us, our thin slicing tool guided us through heap-based \nvalue .ow, saving a great deal of time. The thin slicer was especially helpful when source code was not \navailable, e.g., for the jack benchmark, as we had to study a compiler representa\u00adtion of the bytecodes \nand could not use standard IDE-based source navigation tools. Resultsforthetough castsexperiment appearinTable3.Thin \nslicing helped understand tough casts more effectively than tradi\u00adtional slicing: the number of statements \nexamined using a tradi\u00adtional slice exceeded by 1.17 to 34.2 times the number examined using a thin slice. \nIn total, 9.4 times more statements were exam\u00adined with the traditional slicer than the thin slicer. \nIn javac, the casts resembledFigure5.Thecode includesalargenumberof Node subclasses used pervasively \nin the program, resulting in large num\u00adbers for the traditional slicer. The importance of object-sensitive \ncontainer handling in the points-to analysis is seen for the jack casts, wherethe numberof inspected \nstatements increasedbyfac\u00adtors of 5.9-16.9X with less precise analysis. The absolute numbers of inspected \nstatements exceeded those for the debugging tests,but theyremained manageable fora user. The thin slicer \nrequired inspecting an average of 29.3 statements (ranging from 6-65), while the traditional slicer required \nanaverage of 280 (ranging from6to 2224).For javac, manyof the thin slice statements were writesof opcodesinalarge \nnumberof constructors (likein Figure 5), which could be quickly inspected to ensure that a suitable constant \nis written. For jack, the BFS traversal over\u00adestimated the number of thin slice statements that needed \nto be inspected; once we understood the benchmark, we could terminate thesearchearlyatsome statementswhichweknewwouldnot \ncause the cast tofail. In summary, we conclude thin slicing can effectively provide tool support to identify \nstatements that ensure tough casts cannot fail.Atraversal based on thin slicing typically touches signi.cantly \nfewer statements thanatraversal based on traditional transitive.ow dependence. 7. RelatedWork Since .rst \nbeing de.ned by Weiser in 1979 [28], slicing has in\u00ad spired a large body of work on computing slices \nand on applica\u00adtionstoavarietyof software engineering tasks.We referthe reader toTip s survey [27] and \nKrinke s thesis [12] for broadoverviews of slicing technology and challenges. Here, we focus on the work \nmost relevant to our own. Our thin slicing algorithm is a straightforward adaptation of the SDG-based \napproach .rst presented by Horwitz et al. [11]. Our implementationofa traditional slicerisinfact tabulation-based, \nas suggested in [20] and the 20-year Retrospective to [11]. CodeSurfer[1]isa program understandingtoolforCandC++ \nbased on the analysis techniques of [11, 22]. CodeSurfer also uses pointer analysis to allow navigation \nfrom a use of a heap location to potential defs. Our evaluation metric of a breadth-.rst traversal strategy \naims to simulate use of a tool like CodeSurfer, which allows for navigating the dependence graph. While \nCodeSurfer Cast #Thin #Trad. Ratio #Control #ThinNoObjSens #TradNoObjSens mtrt-1 22 51 2.32 0 22 51 \nmtrt-2 23 52 2.26 0 23 52 jess-1 6 7 1.17 2 6 7 jess-2 13 39 3 0 25 93 jess-3 6 6 1 2 6 6 jess-4 6 7 \n1.17 2 6 7 jess-5 6 7 1.17 2 6 7 jess-6 6 6 1 2 6 6 javac-1 57 910 16 1 57 910 javac-2 43 853 19.8 1 \n43 853 javac-3 65 2224 34.2 1 65 2267 javac-4 45 855 19 1 45 855 jack-1 18 79 4.39 0 303 758 jack-2 57 \n151 2.65 0 339 647 jack-3 18 69 3.83 0 304 603 jack-4 18 79 4.39 0 304 759 jack-5 57 151 2.65 0 339 647 \njack-6 35 132 3.77 0 338 802 jack-7 35 132 3.77 0 338 802 jack-8 35 132 3.77 0 338 802 jack-9 30 79 2.63 \n0 304 759 jack-10 57 151 2.65 0 339 647 Table 3. Evaluationof thin slicing for understanding tough casts. \nThe typesof datain the table columns are described withTable2. allows navigation of all control and data \ndependences, thin slicing emphasizes producer statements and shows explainer statements using additional \nthin slices (see Section 2); our evaluation has shown that this technique quickly leads users to the \nmost relevant statements. Atkinson and Griswold [5] present a slicer relying on a prelim\u00ad inary .ow-insensitive \npointer analysis. This work targets C, and so had to deal with dif.culties arising from issues such as \nstack\u00addirected pointers and unsafe memory access, which do not arise in Java. Larsen and Harrold [13] \npresented one of the .rst slicing ap\u00ad proaches for object-oriented software, adding pseudo-parameters \nfor .elds to track dependencies through the heap. Our context-sen\u00adsitiveslicer implementation usesa similar \napproach,but relies on a partially context-sensitive preliminary pointer analysis to disam\u00adbiguate locations \nwith .eld-and object-sensitivity, and additional pseudo-parameters to soundly handle all .elds that may \nbe ac\u00adcessed transitively by callees. In recent years, several papers have improved precision by in\u00adtegrating \nmore precise static alias analysis into slicing. Liang and Harrold [14] present a novel approach to represent \nformal parame\u00ad ter objects with trees. Hammer and Snelting [9] present an enhance\u00ad ment to this approach, \nincluding a criterion for sound limiting of tree sizes for recursive data structures. Both these approaches \nare more powerful than relying solely on a preceding .ow-insensitive alias analysis, since must-alias \ninformation on parameters can al\u00adlow soundstrong updates.Itis not clearhowfar these algorithms scale; \nthe experimental results of Hammer and Snelting address programs signi.cantly smaller than the benchmarks \nconsidered here. In future work, we plan to incorporate aspects of Hammer and Snelting s approach for \nthin slices. Orsoetal.[18] presentaclassi.cationofdata dependenceedges in an SDG, based on certainty \nof may-alias information, and the span (scope) of a program over which a data dependence .ows. They propose \nan incremental slicing procedure to aid debugging, wherebya tool canprovide progressivelylarger slicesby \nincluding progressively more classes of data dependencies. Our thin slice expansion technique is similar \nin spirit, but goes in a different direction by expanding slices to include statements that indirectly \ngive rise to the primary alias relations. Mocketal.[17]showedthatforCprogramswithheavypointer use, using \ndynamic points-to data signi.cantly improved slice pre\u00adcisionoveraconservative.ow-insensitivepointer \nanalysis.Wesus\u00adpect Java programs resembleC programs with heavy pointer use with regard to data dependence. \nPSE [15] is a static analysis tool for localizing the causes of typestate errorsinCand C++ programsby \nessentially computing a variant of a backward slice, with extra .ltering based on the type of error. \nTheir system is able to perform strong updates on the heap in some situations, using a technique we plan \nto try in our thin slicer. Theirwork unsoundly ignores may-aliasingin some con.gurations, partly due \nto thefact that traces involving aliasing are hard for developers to understand. If applied to a Java-like \nlanguage, our technique for explaining aliases in thin slices may help solve this problem, as discussed \nin Section 4.1. Recently, Zhang et al. have considerably improved the state-of\u00adthe-art in dynamic slicing \n[30, 31, 32, 33]. Thin slicing applies nat\u00ad urally to dynamic data dependences, and we believe dynamic \nthin slices could provide bene.ts similar to static thin slices. Zhang et al. s work on improving scalability \n[32, 33] could be leveraged to create a more scalable dynamic thin slicer. Their recent work on pruning \ndynamic slices [30] is complementary to ours: thin slicing and their heuristics for determining when \na statement is unlikely to be relevant (based on which statements output good and bad val\u00adues) could \nbe fruitfully combined. Recent work [31] observes that using dynamic data dependences alone can often \nidentify buggy statementsinCprograms;we suspectthatinfactthosedatadepen\u00addences consideredbya thin slicerwould \nalsobe suf.cient. Finally, thiswork [31] also suggestsexploring statements closer to the seed .rst when \nviewing a slice, an idea we also use in our evaluation. 8. Conclusions Wehavedescribedthin slicing,anovel \napproachto.ndingrelevant statements for some seed computation. Thekeydifference between thin slicing \nand traditional slicing is the use of a more selective notion of relevance; thin slices only include \nstatements producing the value at the seed, rather than all statements that can possibly affect it. Our \nevaluation shows that desired statements could be found with thin slices while inspecting 3.3 times fewer \nstatements than traditional slices for debugging tasks and 9.4 times fewer state\u00adments for program understanding \ntasks. Furthermore, we showthat a context-insensitive thin slicer, based on precise pointer analysis \nand call graph construction, can scale to large benchmarks. Thin slicing provides the basis for a practical \nand effective program un\u00adderstanding tool, as it provides signi.cant help for .nding state\u00adments relevant \nto tasks and scales to large, realistic Java programs. Acknowledgements This work is supported in part \nby the IBM OCR program, the National ScienceFoundation with grants CCF\u00ad0085949, CCR-0105721, CCR-0243657, \nCNS-0225610, CCR\u00ad0326577, CNS-0524815, and CCF-0613997 the University of Cal\u00adifornia MICRO program, an \nOkawa Research Grant, a Hellman Family Faculty Fund Award, and a Microsoft Graduate Fellow\u00adship. This \nwork has also been supported in part by the Defense Advanced Research Projects Agency(DARPA) under contract \nNo. NBCHC020056. The views expressed herein are not necessarily those ofDARPA. We thank Susan Graham \nfor her suggestion of the name thin slicing. We also thank Dave Mandelin, Adam Chlipala, and the anonymous \nreviewers for their helpful comments. References [1] CodeSurfer. http://www.grammatech.com/products/codesurfer/. \n[2] T.J. Watson Libraries for Analysis. http://wala.sourceforge.net. [3] M. Allen and S. Horwitz. Slicing \nJava programs that throw and catch exceptions. In PEPM 03: Proceedings of the 2003ACM SIGPLAN workshop \nonPartialevaluation and semantics-basedprogram manip\u00adulation, pages 44 54,NewYork,NY, USA, 2003.ACM Press. \n[4] L. O. Andersen. Program Analysis and Specialization for the C Programming Language. PhD thesis, University \nof Copenhagen, DIKU, 1994. [5]D.C. AtkinsonandW.G.Griswold.Effectivewhole-program analysis in the presence \nof pointers. In Foundations of Software Engineering, pages 46 55, 1998. [6] M. Das, S. Lerner, and M. \nSeigle. ESP: path-sensitive program veri.\u00adcation in polynomial time. In Conference on Programming Language \nDesign and Implementation (PLDI), 2002. [7] H. Do, S. Elbaum, and G. Rothermel. Supporting controlled \nexperi\u00admentation with testing techniques: An infrastructure and its potential impact. Empirical Software \nEngineering, 10(4), October 2005. [8] S. Fink, E.Yahav, N. Dor, G. Ramalingam, and E. Geay. Effective \ntypestate veri.cation in the presence of aliasing. In International symposium on Software testing and \nanalysis (ISSTA), 2006. [9] C. Hammer and G. Snelting. An improved slicer for Java. In Proceed-ingsoftheACM-SIGPLAN-SIGSOFT \nworkshoponProgram analysis for software tools and engineering, pages 17 22, 2004. [10]S. Horwitz,P. Pfeiffer, \nandT. Reps. Dependence analysis for pointer variables. In Conference on Programming Language Design and \nImplementation (PLDI), 1989. [11] S. Horwitz, T. Reps, and D. Binkley. Interprocedural slicing using \ndependence graphs. In Conference on Programming LanguageDesign and Implementation (PLDI), 1988. [12] \nJ. Krinke. Advanced Slicing of Sequential and Concurrent Programs. PhD thesis, UniversityofPassau, 2003. \n[13] L. Larsen and M. J. Harrold. Slicing object-oriented software. In International Conference on Software \nEngineering (ICSE), 1996. [14] D. Liang and M. J. Harrold. Slicing objects using system dependence graphs. \nIn ICSM, pages 358 367, 1998. [15]R.Manevich,M. Sridharan,S.Adams,M.Das,andZ.Yang.PSE:ex\u00adplaining programfailures \nvia postmortem static analysis. In SIGSOFT 04/FSE-12: Proceedings of the 12thACM SIGSOFT twelfth interna\u00adtional \nsymposium onFoundations of software engineering, pages 63 72,NewYork,NY, USA, 2004.ACM Press. [16] A. \nMilanova, A. Rountev, and B. G. Ryder. Parameterized object sensitivity for points-to analysis for java. \nACM Trans. Softw. Eng. Methodol., 14(1):1 41, 2005. [17] M. Mock, D. C. Atkinson, C. Chambers, and S. \nJ. Eggers. Improving program slicing with dynamic points-to data. SIGSOFT Softw. Eng. Notes, 27(6):71 \n80, 2002. [18] A. Orso, S. Sinha, and M. J. Harrold. Classifying data dependences in the presence of \npointers for program comprehension, testing, and debugging. ACMTransactions on Software Engineering and \nMethod\u00adology (TOSEM), 13(2):199 239, 2004. [19]M. RenierisandS.P. Reiss. Fault localizationwith nearest \nneighbor queries. In IEEE International Conference on Automated Software Engineering (ASE), 2003. [20] \nT. Reps. Program analysis via graph reachability. Information and Software Technology, 40(11-12):701 \n726, November/December 1998. [21] T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural data.ow \nanalysis via graph reachability. In ACM Symposium on Principles of Programming Languages (POPL), 1995. \n[22] T. Reps, S. Horwitz, M. Sagiv, and G. Rosay. Speeding up slicing. In ACM SIGSOFT Symposium on theFoundationsof \nSoftware Engineer\u00ading (FSE), New Orleans, LA, December 1994. [23] A. Rountev, A. Milanova, and B. G. \nRyder. Points-to analysis for Java using annotated constraints. In Conference on Object-Oriented Pro\u00adgramming, \nSystems, Languages, and Applications (OOPSLA),Tampa Bay, Florida, October 2001. [24] B. G. Ryder,W. A. \nLandi,P. A. Stocks, S. Zhang, and R. Altucher. A schema for interprocedural modi.cation side-effect analysis \nwith pointer aliasing. ACMTrans. Program. Lang. Syst., 23(2):105 186, 2001. [25] M. Sridharan and R. \nBod\u00edk. Re.nement-based context-sensitive points-to analysis for Java. In Conference on Programming Language \nDesign and Implementation (PLDI), 2006. [26]T.Teitelbaum. Personal communication regarding CodeSurfer. \n2007. [27]F.Tip.A surveyof program slicing techniques. Journal of program\u00adming languages, 3:121 189, \n1995. [28] M. D.Weiser. Program slices: formal, psychological, and practical investigations of an automatic \nprogram abstraction method. PhD thesis, University of Michigan, Ann Arbor, 1979. [29] A. Zeller. Isolating \ncause-effect chains from computer programs. SIGSOFT Softw. Eng. Notes, 27(6):1 10, 2002. [30] X. Zhang, \nN. Gupta, and R. Gupta. Pruning dynamic slices with con.dence. In Conference on Programming Language \nDesign and Implementation (PLDI), 2006. [31] X. Zhang, N. Gupta, and R. Gupta. A study of effectiveness \nof dy\u00adnamic slicingin locating realfaults. Empirical Software Engineering, 2006. To appear. [32] X. Zhang, \nR. Gupta, andY. Zhang. Ef.cient forward computation of dynamic slices using reduced ordered binary decision \ndiagrams. In International Conference on Software Engineering (ICSE), 2004. [33] X. Zhang, S. Tallam, \nand R. Gupta. Dynamic slicing long running programs throughexecutionfast forwarding. In ACM SIGSOFT Sym\u00adposium \nonFoundationsof Software Engineering, 2006. [34] A. X. Zheng, M. I. Jordan, B. Liblit, M. Naik, and A. \nAiken. Statistical debugging: Simultaneous identi.cationof multiplebugs. In Proceed\u00adings of the 23rdInternational \nConference on Machine Learning,2006.   \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Program slicing systematically identifies parts of a program relevant to a seed statement. Unfortunately, slices of modern programs often grow too large for human consumption. We argue that unwieldy slices arise primarily from an overly broad definition of relevance, rather than from analysis imprecision. While a traditional slice includes all statements that may <i>affect</i> a point of interest, not all such statements appear equally relevant to a human.</p> <p>As an improved method of finding relevant statements, we propose <i>thin slicing</i>. A thin slice consists only of <i>producer statements</i> for the seed, <i>i.e.</i>, those statements that help compute and copy avalue to the seed. Statements that explain why producers affect the seed are excluded. For example, for a seed that reads a value from a container object, a thin slice includes statements that store the value into the container, but excludes statements that manipulate pointers to the container itself. Thin slices can also be hierarchically expanded to include statements explaining how producers affect the seed, yielding a traditional slice in the limit.</p> <p>We evaluated thin slicing for a set of debugging and program understanding tasks. The evaluation showed that thin slices usually included the desired statements for the tasks (<i>e.g.</i>, the buggy statement for a debugging task). Furthermore, in simulated use of a slicing tool, thin slices revealed desired statements after inspecting 3.3 times fewer statements than traditional slicing for our debugging tasks and 9.4 times fewer statements for our program understanding tasks. Finally, our thin slicing algorithm scales well to relatively large Java benchmarks, suggesting that thin slicing represents an attractive option for practical tools.</p>", "authors": [{"name": "Manu Sridharan", "author_profile_id": "81100641428", "affiliation": "University of California: Berkeley, Berkeley, CA", "person_id": "P186999", "email_address": "", "orcid_id": ""}, {"name": "Stephen J. Fink", "author_profile_id": "81100118324", "affiliation": "IBM T.J. Watson Research Center, Yorktown Heights, NY", "person_id": "PP39064602", "email_address": "", "orcid_id": ""}, {"name": "Rastislav Bodik", "author_profile_id": "81100033082", "affiliation": "University of California: Berkeley, Berkeley, CA", "person_id": "P338839", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250748", "year": "2007", "article_id": "1250748", "conference": "PLDI", "title": "Thin slicing", "url": "http://dl.acm.org/citation.cfm?id=1250748"}