{"article_publication_date": "06-10-2007", "fulltext": "\n Towards Locating Execution Omission Errors Xiangyu Zhang Purdue University, Department of Computer \nScience, West Lafayette, Indiana 47907 xyzhang@cs.purdue.edu Abstract Execution omission errors are \nknown to be dif.cult to locate using dynamic analysis. These errors lead to a failure at runtime because \nof the omission of execution of some statements that would have been executed if the program had no errors. \nSince dynamic anal\u00adysis is typically designed to focus on dynamic information arising from executed statements, \nand statements whose execution is omit\u00adted do not produce dynamic information, detection of execution \nomission errors becomes a challenging task. For example, while dynamic slices are very effective in capturing \nfaulty code for other types of errors, they fail to capture faulty code in presence of ex\u00adecution omission \nerrors. To address this issue relevant slices have been de.ned to consider certain static dependences \n(called poten\u00adtial dependences) in addition to dynamic dependences. However, due to the conservative \nnature of static analysis, overly large slices are produced. In this paper, we propose a fully dynamic \nsolution to locating execution omission errors using dynamic slices. We in\u00adtroduce the notion of implicit \ndependences which are dependences that are normally invisible to dynamic slicing due to the omission \nof execution of some statements. We design a dynamic method that forces the execution of the omitted \ncode by switching outcomes of relevant predicates such that those implicit dependences are ex\u00adposed and \nbecome available for dynamic slicing. Dynamic slices can be computed and effectively pruned to produce \nfault candi\u00addate sets containing the execution omission errors. We solve two main problems: verifying \nthe existence of a single implicit depen\u00addence through predicate switching, and recovering the implicit \nde\u00adpendences in a demand driven manner such that a small number of veri.cations are required before the \nroot cause is captured. Our experiments show that the proposed technique is highly effective in capturing \nexecution omission errors. Categories and Subject Descriptors D.2.5 [Software Engineer\u00ading]: Testing \nand Debugging Debugging aids, Testing tools, Trac\u00ading; D.3.4 [Programming Languages]: Processors Debuggers \nGeneral Terms Algorithms, Measurement, Reliability Keywords debugging, execution omission, relevant slicing, \nim\u00adplicit dependence, potential dependence, and predicate switching. Permission to make digital or hard \ncopies of all or part of this work for personal or classroom use is granted without fee provided that \ncopies are not made or distributed for pro.t or commercial advantage and that copies bear this notice \nand the full citation on the .rst page. To copy otherwise, to republish, to post on servers or to redistribute \nto lists, requires prior speci.c permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, \nUSA. Copyright c . 2007 ACM 978-1-59593-633-2/07/0006. . . $5.00. Sriraman Tallam Neelam Gupta Rajiv \nGupta The University of Arizona, Department of Computer Science, Tucson, Arizona 85721 {tmsriram,ngupta,gupta}@cs.arizona.edu \n1. Introduction Once a software error manifests itself at runtime as a failure, dy\u00adnamic program analysis, \nby observing the runtime symptoms of the failure, serves as a very natural means for identifying the \ner\u00adror. In recent years, a wide variety of dynamic analysis have been proposed for the purpose of debugging \nruntime errors [11, 9, 13, 7, 5, 10, 4, 6, 17]. Many employ machine learning or statistical tech\u00adniques \nto observe runtime deviations from certain invariants and raise alarms for any anomalies. Others try \nto understand bugs by searching the program state space. These techniques typically pro\u00adduce a fault \ncandidate set, which is basically a prioritized set of statements that includes the faulty code. Proposed \nas a debugging aid, dynamic slicing [8] has the advantage of capturing the cause\u00adeffect relations between \nthe faulty code and the failure through dy\u00adnamic dependences. Recently, it has been shown that dynamic \nslic\u00ading based techniques are quite effective in locating program errors [19, 20]. Common situations \nin which a dynamic slice captures a faulty statement are those where execution of a faulty statement \ncorrupts part of the program state, the effects of this corruption are propa\u00adgated along dynamic dependences, \nand eventually a failure is de\u00adtected due to the output of an incorrect value or the crashing of the \nprogram. However, an error may cause the execution of certain critical statements to be omitted, resulting \nin a failure. This type of error is called execution omission error. Dynamic slicing fails to capture \nexecution omission errors. flags |=ORIG_NAME; S5 : S6: outbuf[outcnt++] = (uch)flags; . . . S7: if (save_orig_name) \n{ . . . S8: outbuf[outcnt++]= (*p) &#38; 0x7F; . . . } . . . S9: printf ( %c , outbuf[i]); : printf ( \n%c , outbuf[i+1]); S10 . . .  Figure 1. An example of execution emission error (gzip). Figure 1 gives \nsuch an example. The code is taken from ver\u00adsion v3 run r1 of gzip available at the website [1]. The \nshaded statements are the ones that get executed. As shown by the .gure, the error resides in the assignment \nto save orig name.Since save orig name contains the wrong value false,branch S4 is not taken and thus \nflags has the wrong value 0 while it should have been de.ned as ORIG NAME at S5. This wrong flags value \nis eventually observed at S10. Let us assume we try to locate the error by computing the dynamic slice \nof the wrong value, i.e. .nd the set of executed statements that affect the wrong value through data \nand/or control dependence. The resulting dynamic slice con\u00adtains {S2, S3, S6, S10}, from which the root \ncause, S1, is missing. This happens because dynamic slicing is able to capture the fact that the de.nition \nat S2 reaches S6 but fails to discover that the branch outcome of S4 also affects the value of flags \nat S6.The dif.culty of analyzing an execution omission error is inherent lim\u00aditation of dynamic analysis \nas the analysis is based on information collected from executed statements, not the ones whose execution \nwas incorrectly omitted. To the best of our knowledge, relevant slicing [3] is the .rst and also the \nonly automatic technique which tries to tackle the problem of debugging execution omission errors. The \nbasic idea of relevant slicing is to introduce a potential dependence between predicate S4 and assignment \nS6. Now the root cause becomes reachable from the wrong output through dependence edges such that it \nis included in the dynamic slice. Potential dependence is essentially a static concept in the sense that \nan edge is conservatively added if potentially there is a dependence. For example, S10 potentially depends \non S7 as well because the de.nition at S8 could reach S10, even though in fact S7 does not affect the \nvalue at S10.Furthermore, potential dependence edges are uniformly introduced for all the nodes in a \ndynamic dependence graph before any relevant slices can be computed. Therefore, the conservative effects \naccumulate resulting in much larger slices being computed. In this paper, we propose a purely dynamic \nsolution for handling execution omission errors. The essence of this solution lies in adding a dependence \nedge between the predicate and the use only if the dependence can be made observable rather than just \nbeing potential. A dependence is observable only if changing the value at the predicate affects the use. \nTherefore, the basic idea of our approach is as follows. Given a predicate p and a use u such that p \nprecedes u,and u does not directly or indirectly data/control depend on p, we reexecute the program with \nthe same input and then switch the branch outcome of the predicate. If the point that corresponds to \nu is affected, we conclude that there is a dependence between p and u in the original execution. We also \nrefer to such dependence as an implicit dependence because even though this dependence exists, it is \nnot established via a chain of explicit data and/or control dependences. Let us consider the example \nin Figure 1. To verify if there is a dependence between S4 and S6,we reexecute gzip with the same input, \nand then switch the execution to take the true branch at S4. We observe that the value at S6 is altered \nby switching the predicate. Thus, we conclude that there is a dependence between S4 and S6. Likewise, \nwe .nd that there is no dependence between S7 and S10. In order to realize the above idea, we need to \naddress two major issues. The .rst issue is to recognize whether there exists an implicit dependence \ngiven a use and a predicate. We introduce the concept of implicit dependence, which is de.ned by observing \nthe switched execution. The main difference between implicit dependence and potential dependence is that \nthe former is observable while the lat\u00adter is only potential. The key challenge of this issue is to identify \nthe point in the switched execution that corresponds to u. Switch\u00ading the predicate may signi.cantly \nalter the execution, and hence .nding the corresponding instance of u in the new execution is no longer \nstraightforward. For example, switching the predicate at S7 may change the control .ow of the execution \nso much that S10 is not even reached or the same use of outbuf[i+1] may occur at a different execution \npoint. In such cases it becomes unclear how to observe whether the original value is affected by switching \nthe predicate or not. We propose a novel execution alignment algorithm which is able to align two executions \nbased upon execution regions instead of individual executed statements such that we are able to .nd the \npoint in the new execution that corresponds to a particular point in the original execution if there \nis one.   Thesecond issueis to ef.ciently discover implicit dependences such that the root cause can \nbe found with a minimal number of re\u00adexecutions. Verifying one implicit dependence requires reexecuting \nthe program once. Potentially, we need to verify the dependences between any use and each of its preceding \npredicates, which is ap\u00adparently not an option due to the prohibitively high runtime over\u00adhead. We propose \na demand driven strategy which gradually adds new statements to the dynamic slice through detected implicit \nde\u00adpendences, and in the mean time the new dynamic slice is pruned using a technique developed in [19, \n20]. The contributions of this paper are as follows: We introduce the concept of implicit dependence. \nIt compen\u00adsates for the inability of traditional dynamic data and control dependences to capture the \nexecution of omission errors. Since implicit dependence is a completely dynamic concept,itisa more appropriate \nbasis for dynamic analysis than the hybrid concept of potential dependence in [3].  We propose a demand \ndriven strategy to reduce the overhead caused by reexecutions that are required to detect implicit de\u00adpendences. \nThis demand driven strategy is integrated with a pruning technique introduced in [19] to achieve minimal \nin\u00adcrease in the size of the fault candidate set.  We experimentally evaluate our technique. The results \nshow that execution omission errors can be captured by performing a small number of veri.cation and adding \nvery few implicit dependence edges.  The remainder of the paper is organized as follows. In section \n2 we discuss the existing solution relevant slicing and describe its limitations. In section 3 we present \nthe proposed technique in detail. Experimental results are presented in section 4. Some issues about \nthe technique are discussed in section 5. Related work is described in section 6 and conclusions are \ngiven in section 7. 2. Relevant Slicing Relevant slicing [3] was proposed to handle execution omission \ner\u00adrors. Given a failed execution, relevant slicing .rst constructs a dy\u00adnamic dependence graph in the \nsame way as classic dynamic slic\u00ading does. In addition, it augments the dynamic dependence graph with \npotential dependence edges. A relevant slice is computed by taking the transitive closure of the wrong \noutput on the augmented dynamic dependence graph. In relevant slicing, a use u potentially depends on \na preceding predicate p if a different de.nition could potentially reach u if p were to evaluate differently, \ni.e. take the opposite branch. A more formal de.nition of potential dependence is given below: DEFINITION \n1. Givenause u,the potentially depends set PD(u) contains members of the form that specify predicates \nand their outcomes (i.e., p T or p F ). Predicate p T (p F )presents in PD(u) iff (i) the execution of \np precedes that of u; (ii) u is not control dependent on p;  (iii) the de.nition reaching u occurs \nbefore p; (iv) a different de.nition could potentially reach u if p were to evaluate to F (T). Dependence \nedges are added between any u and each element in PD(u). For the example in Figure 1, the potential dependence \nedges are as follows. PD(outbuf[i +1]@S10)= {save orig name@S7 T } PD(flags@S6)= {save orig name@S4 T \n} Conditions (i), (ii) and (iv) are straightforward. The third con\u00addition excludes the case illustrated \nbelow, in which p takes the F branch. Since x@4, the reaching de.nition of use x@6, occurs after predicate \np@1, de.nition x@2 would get killed even if p@1 were evaluated to T. Therefore, p@1T is not in PD(x@6). \n1: if(p) { 2: x=...; 3: } 4: x=...; 5: ...; 6: ...=x...; In Figure 1, three potential dependences are \nadded: S4 . S6, S7 . S9,and S7 . S10. The relevant slice of the wrong value is computed as {S1, S2, S3, \nS4, S6, S7, S10}, which contains the root cause S1. Despite the fact that relevant slicing reveals a \nvery promising direction to overcome the problem of debugging execution omis\u00adsion errors, it has its \ninherent limitations. First of all, condition (iv) in De.nition 1 implies that static points-to analysis \nhas to be con\u00adducted to disclose possible reaching de.nitions for a use. The con\u00adservative nature of \nsuch a static analysis inevitably gives rise to false dependences. In our motivation example, since DEFLATED \nand flags are printed at S9 and S10 respectively, the de.nition at S8 can only reach some output statement \nwhich gets executed after S10. In other words, the de.nition at S8 can never reach S9 and S10. Unfortunately, \na static points-to analysis fails to capture this fact and hence false dependences such as S7 . S9 and \nS7 . S10 are introduced. Second, the effects of the conservative nature of static analysis accumulate. \nThe initial introduction of false dependences creates new opportunities to bring in more and more false \ndependences. Eventually, the excessively expanded dependence graph might re\u00adsult in over sized relevant \nslices. In some earlier studies [3, 15], it was reported that relevant slicing only in.ates the sizes \nof classic dynamic slices by a very small ratio. However, those study only re\u00adported the number of unique \nstatic statements in a relevant slice, which may barely increase. In contrast, the number of dynamic \nstatements often increases by orders of magnitude. For example, let us assume an erroneous predicate \nis executed for 100 times and the fault gets exercised at the last execution instance. Ideally, the slice \nshould contain only the faulty instance. However, relevant slicing often includes all the 100 instances \ndue to its static nature. There\u00adfore, even though the number of static statements only increases by one, \nthe information that the programmer has to go through in order to .gure out the failure inducing relations \nmay increase by a much larger factor.  3. Dynamic Detection of Implicit Dependences As pointed out earlier, \nrelevant slicing is a hybrid analysis which has both static and dynamic components. The conservative \nnature of static analysis inevitably results in over sized slices, which is contrary to the goal of providing \na minimal fault candidate set con\u00adtaining the root cause. In this paper, we propose an aggressive solu\u00adtion. \nThe essence of this solution lies in adding a dependence edge between a predicate and a use only if the \ndependence is observ\u00adable rather than just being potential. To test whether a dependence is observable, \nwe switch the branch outcome of the predicate in a second execution and then observe if the use is affected. \n  As mentioned earlier, we are confronted by two challenges: how to recognize whether there exists \nan implicit dependence given a use and a predicate and how to ef.ciently discover implicit depen\u00addences \nsuch that the root cause can be found with a minimal num\u00adber of reexecutions. In this section, we describe \nhow these problems are solved. 3.1 Implicit Dependence In classical dynamic slicing, a data dependence \nrepresents the .ow of a value from the statement execution that de.nes it to the state\u00adment execution \nthat uses it such as the dependence between 1(1) dd and 6(1) in Figure 2, denoted as 1(1) -. 6(1). A \ncontrol depen\u00addence between two statement executions represents that the execu\u00adtion of one statement \ndepends on the branch outcome of a predicate in the other statement. For example, statement execution \n14 is con\u00ad . 14(1) trol dependent on 13 in execution (1), denoted as 13(1) -cd. These dependences are \nexplicit, or in other words, they are observ\u00adable and captured during the program execution. Execution \nomission errors happen when certain code should have been executed while it did not due to the error. \nThe barrier of locating an execution omission error lies in the dependences that are essential to the \nfailure are not explicit from the execution. For example in Figure 2, the dependence from 15 to 2 in \nexecution (1) is implicit. We have to capture this type of dependence in order to handle execution omission \nerrors. Before we proceed, let us .rst introduce the de.nition of this type of dependence. Theoretically, \nwe can de.ne a dependence exists between two statement executions if and only if disturbing the execution \nof one statement affects the execution of the other. This de.nition subsumes the previous de.nitions \nof data dependence and control dependence. However, tracking such dependence at runtime is not possible \nas information required must come from statements that are not executed. Next we de.ne the new type of \ndependence, implicit dependence, and show how to detect them. DEFINITION 2. Given an execution E, a predicate \np,andause u s.t. there is no explicit dependence path between p and u,let E' be the reexecution of the \nsame program with the same input as E except the branch outcome of p' being switched, p' and u' be the \nexecution points in E' that match p and u in E, respectively, u id implicitly depends on p, denoted as \np -. u,iff (i) u' is not found in E',or, ' (ii) there is an explicit dependence path between p' and \nu,  Explicit dependence is a dependence that can be observed dur\u00ading the execution including data dependence \nand control depen\u00addence. Note that implicit dependence is de.ned in terms of p and u in the original \nexecution even though it is veri.ed in the switched execution. The key challenge here is to .nd the point \nduring the switched execution that corresponds to u, a use in the original execution. Let us illustrate \nthe problem using an example in Figure 2. The source code is presented in the left column and execution \ntraces are presented in the right column. Let us assume that we are interested in verifying the dependence \nbetween the use of x at 15 in execution (1), denoted as 15(1), and predicate P at 2(1). According to \nour solution, we reexecute the program with the same input (the new execution is referred to as execution \n(2) in Figure 2 and then we switch the branch outcome of P at statement 2(2).In order to .nd out whether \nswitching P affects the use of x, we .rst need to .nd the corresponding use in execution (2). (1) Original \nexecution trace: 1: i = t = x = P = C1 = C2 =0; 1, 2, 6, 13, 14, 15, 16, 17, 18. 2: if(P) { 3: t =1; \n (2) Execution trace with the branch outcome of P being switched: 4: x=...; 1, 2, 3, 4, 5, 6, 7, 8, \n11, 12, 6, 13, 14, 15, 16, 17, 18. 5: } 6: while (i<t) { (3) Execution trace with P switched and statement \n3 is t = C2 =1: 7: ...; 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 6, 13, 14, 17, 18. 8: if(C1) { 9: ...; 10: } \n Matching 15 in traces (1) and (2): 11: i = i +1; 12: } 13: if (...) { 14: if(C2 == 0) { 15: ...=x; 16: \n} 17: ...; 18: }  In general, this problem is undecidable because deciding whether the execution terminates \nafter switching is a undecidable problem. Nonetheless, we are more interested in the cases that switched \nex\u00adecutions terminate. Therefore, in this paper we assume switched executions always terminate. In practice, \nwe set a timer which if expires, we aggressively conclude the veri.cation fails and thus there is no \ndependence between the predicate and the use. Even with the assumption of termination of the switched \nex\u00adecution, .nding the corresponding instance of u in the switched execution is not easy. In execution \n(2) of the example, switching P changes t, resulting in the statements inside the while loop to be executed. \nLet us assume statement 7 makes a recursive self call and then the resulting trace has the following \nform: 1, 2, 3, 4, 5, 6, 7, 1, 2, ..., 15,... 8, 11, 12, 6, 13, 14, 15, 16, 17, 18. A simple strategy \nthat looks for the .rst appearance of 15 after statement 2 does not work in this case. In a more complicated \nexample such as execution (3) in Fig\u00adure 2, 15(3) does not get executed as the result of P at 2(3) getting \n.ipped. Let us further assume statement 17(3) recursively calls the function and thus the trace produced \nbecomes the following: 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 6, 13, 14, 17, 1, 2, ..., 15, ... 18. Apparently, \na well designed matching algorithm should clearly recognize that there is no match of the original 15(1) \nin the new run rather than associating 15 in this run with 15(1). The dif.culty stems from the fact that \nwe were trying to align individual statement executions while statement executions may vary signi.cantly \ndue to the predicate switch. We observe that the two executions can actually be aligned in larger units. \nFor in\u00adstance in Figure 2, statement 6(1) corresponds to or matches the sequence of executed statements \n[6,7,8,11,12,6](2) in the switched execution. In other words, rather than matching the ex\u00adecutions inside \nthe while statements, we align them as a whole instead. Similarly, sequence [13,14,15,16,17,18](1) matches \n[13,14,17,18](3),and then [14,15,16](1) matches 14(3). Therefore, we conclude that 15(1) has no corresponding \nmatch in execution (3). Next we develop the algorithm for the above matching process. We begin by de.ning \nthe concept of a region which is the basis for performing matching. DEFINITION 3. An execution can be \ndecomposed into regions.A statement execution s and the statement executions that are control dependent \non s form a region. The following grammar captures the form of a region. Region ::= s CD (1) CD ::= . \n| Region | CD Region where s is a statement execution and given any statement execution e . CD, e is \ncontrol dependent on s. For instance, [13,14,15,16,17,18](1) forms a region, in\u00adside which [14,15,16](1) \nforms another region. Given the de.nition of region, the algorithm is described by Al\u00adgorithm 1. E and \nE denote the original execution and the switched execution, respectively. The algorithm .nds u in E that \nmatches u given the matching predicates of p and p . In the body of Match(), the algorithm .rst tries \nto identify the immediate sur\u00adrounding region r that includes both p and u and its corresponding instance \nr in E . Region(s/r) gives the immediate surround\u00ading region of a statement execution s or a region r. \nFor example, Region([15]) = [14,15,16] in execution (1). Since the two executions are identical till \nthey reach the points of p and p ,we can easily align r and r , the surrounding regions of p and p , \nrespectively. Next the algorithm calls MatchInsideRegion() to match u given r and r .In MatchInsideRegion(),the \nalgorithm begins with matching the .rst immediate subregions. FirstSubRegion(r) returns the .rst immediate \nsubregion that 5](2)) is inside r. For instance, FirstSubRegion ([2, 3, 4, = [3](2).The while loop in \nlines 17-20 traverses through the siblings to locate the subregion r that contains u. For instance, the \nsibling region of [3](2) is [4](2).Given the matching subregions r and r , at line 23, the algorithm \nchecks if the same branches are taken. If not, switching p actually al\u00adters the branch outcome of a predicate \nthat u is control dependent upon, which implies that we are not able to .nd u . Hence the al\u00adgorithm \nreturns failed. We will further illustrate this case with an example later on. If the same branches are \ntaken, the algorithm re\u00adcursively calls MatchInsideRegion() to further match sub\u00adregions that are one \nlevel below until u is found. Next let us show how to .nd the match of 15(1) in (2) using the algorithm. \nBoth (1) and (2) are .rst parsed into regions as depicted in Fig\u00ad Algorithm 1 Matching Algorithm Description: \nMatch() .nds the use in E ' that corresponds to uin Egiven pin Ecorresponds to p ' in E ' and uis not \nin Region(p). MatchInsideRegion() .nds the use in region R ' that matches uin R. 1: Match (p, u, p ' \n) 2: { 3: r=Region(p); 4: r ' =Region(p ' ); 5: while (!InRegion (u,r)) { 6: r= Region(r); 7: r ' = Region(r \n' ); 8: } 9: return MatchInsideRegion(r, u, r ); 10: } 11: 12: MatchInsideRegion (R, u, R ' ) 13: { 14: \nr=FirstSubRegion(R); 15: r ' =FirstSubRegion(R ' ); 16: if(r ' == NULL )return NULL; 17: while (!InRegion \n(u,r)) { 18: r= SiblingRegion(r); 19: r ' = SiblingRegion(r ' ); 20: if(r ' == NULL)return NULL; 21: \n} 22: if(FirstStmt(r)== u)return r ' ; 23: if(Branch (r)!= Branch (r ' ) ) return NULL; 24: return MatchInsideRegion \n(r, u, r ' ); 25: } ure 2. According to the algorithm, we .rst look for the region that covers both 2(1) \nand 15(1), which is the whole execution re\u00adgion, and its corresponding instance in (2). Then we match \nthe subregions of the whole execution regions as shown by the dotted lines in the .gure till we reach \nthe subregion that contains 15(1), which is [13,14,15,16,17,18](1). The matching subregion is [13,14,15,16,17,18](2). \nThe same branches are taken at statement 13 in both the executions, and thus we move forward to match \n15 in the subregions of [14,15,16](1/2) and so on. Even\u00adtually, 15 is located in (2). The above example \ndemonstrates how the algorithm works when the corresponding use exists. Now let us take a look at another \nexample that shows how it works for the case that the correspond\u00ading use does not exist. In this example, \nwe try to match 15(1) in (3). We are able to match in a similar manner till we reach the following two \nsubregions: [14,15,16](1) and [14](2). By looking at the branch outcomes at statement 14(1/2), we conclude \nthat we are not able to .nd15in(3). The algorithm has to take care of some special cases. In MatchInsideRegion(), \nthe sub-regions always match if their parents are single-entry-single-exit. In the case that the parents \nhave a single-entry-multiple-exit structure, different sequences of subregions may be exercised inside \nthe parents which increases the complexity of execution alignment. For example, in Figure 3, R and R \nmatch and we are looking for the match of 7. Since in the new execution, C0 takes the true branch such \nthat the control .ow exits the loop by a break. Line 16 and 20 in Algorithm 1 handle such cases. If a \ndifferent exit point is taken in the new run before a subregion contains u is reached, a sibling region \ncannot be found. In the example, we can see that the sibling of region [4] is NULL in the second run, \nwhich implies region R terminates. We conclude that the match of 7 is not found. 1: if(P)... 2: ... MatchInsideRegion(R,7, \nR ' ): 3: while (i<t) { . . . [3, [4], [6, [7]], ], [10. . . 4: if(C0) 5: break; R 6: if(C1) R 7: ...=x; \n8: i= i+1; 9: } . . . [3, [4] ], [10. . . 10: ...; Figure 3. An example of the single-entry-multiple-exit \ncase. Finally, according to De.nition 2, and the results of applying the alignment algorithm to execution \n(1) and (2), we conclude that idcddd 2(1) . 4(2) -. 15(1) because 2(2) --. 15(2). If statement 3 id is \nchanged to t=C2 =1; , 2(1) -. 15(1) holds since predicate at 14 takes the false branch resulting in 15 \ndoes not get executed as shownin execution(3). During the procedure of debugging, it is often the case \nthat the programmer knows what the correct value vexp when he observes the wrong value at o. This information \ncan be used to strongly suggest the implicit dependence edge that leads to the execution omission error. \nDEFINITION 4. Given an execution Eand an expected value vexp at an execution point of o,let o ' be the \npoint in the switched execution E ' that corresponds to o, VALUE(o ' ) be the right hand side value at \no ' ,there is a strong implicit dependence between a sid predicate pand a use u, denoted as p- . u,iff \nid (i) p-. u; (ii) vexp = VALUE(o ' ).  In other words, if the expected correct value can be produced \nat o ' , which corresponds to oin the original execution, the implicit dependence is a strong implicit \ndependence. We will see that a high priority is given to strong implicit dependences in producing the \nfault candidate set.  3.2 Demand Driven Strategy According to the de.nition of implicit dependence, \nverifying one implicit dependence requires reexecuting the program once. If an error is not captured \nby the dynamic slice because of the missing implicit dependences, potentially, we need to verify the \nimplicit dependences between each use in the slice and its preceding predi\u00adcates. Therefore, the technique \nmay become impractical without a sophisticated design. We reduce the number of veri.cations through a \ndemand driven strategy consisting of two iterative steps. First, we prune a dynamic slice as much as \npossible before we start verifying the related implicit dependences. Second, we pick one u from the pruned \nslice that is considered as the most promising one leading to the root cause and expand the slice by \nadding the executed statements that u implicitly depends on. These two steps are repeated until the root \ncause is found. Con.dence Analysis Based Pruning. In [19], a technique is proposed to compute for each \nexecuted statement the likelihood of it being faulty. The basic idea is derived from the observation \nthat some of the statements used in computing an incorrect value may also have been involved in computing \ncorrect values (e.g., a value produced by a statement in the dynamic slice of the incorrect value may \nalso have been used in computing a correct output value prior to the incorrect value). Hence, it is possible \nto estimate the 10. a=1; C =f(range(A)) ? ... v 20. b=a% 2; C =1 ... 30. c=a+2; C =0 \u00d7 ... v 40. printf(\"%d\",b); \nC =1 41. printf(\"%d\",c); C =0 \u00d7  Figure 4. An example of con.dence analysis likelihood of a statement \nexecution being faulty by looking at its relations to both the correct output and the wrong output. Such \na likelihood is represented by a con.dence value ranging from 0 to 1 a higher con.dence value corresponds \nto greater likelihood that the statement execution produced a correct value. This technique is also called \ncon.dence analysis. For example in Figure 4, let us assume that the user observes that statement 40 outputs \na correct value while 41 outputs a wrong one so that they are associated with the the con.dence values \nof 1 and 0, respectively. The goal of con.dence analysis is to automati\u00adcally infer the con.dence values \nof other statement executions. The de.nition at statement 30 cannot reach the correct output, which can \nbe interpreted as there is no evidence that indicates it produces a correct value. Therefore, it has \na con.dence of 0. The de.nition at 20 reaches both the correct and the wrong outputs. From the fact that \nb at 41 is observed to be correct, we can infer that 20 produces a correct value and hence its con.dence \nis 1. However, from 20 be\u00ading correct, we cannot infer that 10 is correct because the computa\u00adtion at \n20 represents a many-to-one mapping from a to b.For ex\u00adample, a=3,5,7,..., and so on produces the same \ncorrect value at 20. Therefore, the con.dence of 10 is computed based upon the range of a, which can \nbe approximated by the value pro.le. Con.dence values are used in both the iterative steps mentioned \nearlier. In the .rst step, the executed statements having a con.dence value of 1 can be pruned from the \ndynamic slice since they are not fault candidates. In the second step, we rank the executed state\u00adments \nin the pruned slice based on their con.dence values and their dependence distances to the failure point, \nand then pick the one with the highest rank to perform implicit dependence veri.ca\u00adtion. After implicit \ndependences are veri.ed, they are added to the dependence graph and then con.dence values are recomputed \nto incorporate the new dependence edges. A new ordered fault candi\u00addate set is produced accordingly. \nDemand Driven Procedure. Algorithm 2 presents the demand driven procedure. PruneSlicing () was an implementation \nof the con.dence analysis [19], which is able to compute a pruned and ranked slice. It is also an interactive \nprocedure, in which the system presents the statement instances in the slice in an order and the pro\u00adgrammer \ngives feedback to the system if he considers the presented statement instance contains benign program \nstate. This procedure terminates after a few interactions with the programmer such that the remaining \nstatement instances in the pruned slice have only cor\u00adrupted program state. Note that a statement whose \ninstances have corrupted program state is not necessarily the error. The purpose of calling PruneSlicing \n() is to have the smallest slice before the expansion along implicit dependence edges during each step. \nIn each iterative step of the while loop, a use u is selected from the pruned slice based on its ranking. \nThe algorithm makes use of the concept of potential dependence from relevant slicing. The set of statement \nexecutions on which u potentially depends on, denoted as PD(u), are used as candidates on which veri.cation \nis performed. Lines 7-8 group the predicates in PD(u) basedonthe veri.cation results. The existence of \nstrong implicit dependences Algorithm 2 Demand-Driven Algorithm Description: LocateFault() locates the \nroot cause by adding implicit dependences on demand, given G, Ov , o\u00d7, vexp as the dynamic dependence \ngraph, the set of correct output, , the wrong output, and the expected correct value at o\u00d7, respectively. \nVerify () tests the relation between p and u. It returns STRONG ID / ID sid/id if p ----. u,otherwise \nNOT ID. 1: LocateFault (G, Ov , o\u00d7, vexp) 2: { 3: PS=PruneSlicing (G, Ov , o\u00d7); 4: while (the root cause \nis not found) { 5: select a use u from PS; 6: S[...]={ f, f, f} ; 7: foreach p in PD (u) { 8: S[VerifyDep \n(p,u,o\u00d7, vexp)]+ = p; 9: } 10: if(S[STRONG ID]= f) type =STRONG ID; 11: else type =ID; 12: foreach p \nin S[type]{ 13: foreach t s.t. p . PD(t){ 14: if(VerifyDep (p,t, o\u00d7, vexp)==type) { 15: G=G+ p . t; 16: \n} 17: } 18: } 19: S=PruneSlicing (G, Ov , o\u00d7); 20: } 21: } 22: 23: VerifyDep (p, u, o\u00d7, vexp) 24: { 25: \nE ' = reexecute E with p s branch outcome altered; 26: p ' =the match of p in E ' ; 27: o ' = Match (p, \no\u00d7, p ' ); 28: if(o ' =NULL &#38;&#38; Value (o ' )== vexp)return STRONG ID; 29: u ' = Match (p, u, p \n' ); 30: if(u ' ==NULL)return ID; 31: else { 32: d ' =the de.nition of u ' ; 33: if(InRegion(d ' ,Region(p \n' ))) 34: return ID; 35: } 36: return NOT ID; 37: } PS implicit dep; Darker colors repesent lower confidence. \nFigure 5. Enable pruning by verifying more related implicit de\u00adpendences. overrides the existence of \nimplicit dependences, meaning that only strong implicit dependence edges will be added if there are any. \nNote that for each candidate p, the algorithm veri.es not only the dependence between p and u, but also \nthe dependences between p and any other uses that potentially depend upon p. The goal is to enable more \npruning during computation of the new fault candidate set. For example in Figure 5, the triangle represents \nthe the current pruned slice PS. Assume it does not contain the root cause, according to the algorithm, \nwe need to verify the potential id dependences that leads to u. Let us further assume p -. u and idid \np -. u are veri.ed. If we do not verify the dependence p -. t and add it to the dependence graph, the \nhigh con.dence of t can not be propagated to p ' and thus p ' has to be considered as a fault candidate. \nThe procedure of expanding and then pruning repeats until the root cause is captured in the slice. At \nthis moment, the dependence chains in the pruned slice clearly disclose the cause effect relations between \nthe root cause and the failure. VerifyDep() presents an algorithm to test whether or not there is a (strong) \nimplicit dependence between a predicate p and ause u based upon De.nition 2 and 4. The algorithm is derived \ndirectly from the de.nitions except in lines 32-34 it considers the implicit dependence is true only \nif a data dependence edge exists between u and d instead of an explicit dependence path as described \nby the de.nition. Considering paths but not edges substantially increases the number of fault candidates \nadded during each iterative step, which is not desirable because the programmer can be easily overwhelmed. \nMoreover, only minor degradation results from considering edges, meaning that the error will still be \ncontained eventually. For example, let us assume statement 7 in Figure 2 is x=.... id According to the \nde.nition, 2(1) -. 15(1), which matches our in\u00ad cdddcd tuition, because of the explicit dependence path \n2 -. 3 -. 6 -. dd 7 -. 15 in the switched run. According to the algorithm, there is no implicit dependence \nbetween 2(1) and 15(1) because switching P does not introduce an explicit data dependence. However, the \nal\u00ad . 6(1) and 6(1) . 15(1).In gorithm is able to identity 2(1) -id-id other words, 2(1) will eventually \nbe included in the fault candidate set through these two edges. We would like to point out that considering \nedges instead of paths in VerifyDep() makes this procedure unsafe under certain situations, meaning some \nexecuted statements may not be reach\u00ad able from u even though u implicitly depends on them. For in\u00ad stance, \nlet us assume statement 4 is C1=1; and statement 9 is x=.... The algorithm decides there is no implicit \ndependence either be\u00ad tween 2(1) and 15(1) or between 2(1) and 6(1), therefore, 2(1) is not reachable \nfrom 15(1). However, according to the de.nition, 2(1) id -. 15(1). The observation is that if switching \na predicate changes the branch outcomes of nested predicates, the algorithm is not safe. A safe algorithm \ncan be derived with the cost of much more veri.cations being performed in each iteration of the demand \ndriven process, which sacri.ces the merit of the process. We ar\u00adgue and later show by experimentation \nthat these situations are rare and the unsafe algorithm is ef.cient and effective enough for the application \nof debugging. Next let us revisit our motivation example in Figure 1 to demon\u00adstrate this algorithm. \nGiven the correct output and the wrong output observed at S9 and S10, respectively, the computation steps \nare pre\u00adsented as follows.  (1). Prune the dynamic slice of the wrong output from {S2,S3,S6,S10} to \n{S2,S6,S10}. S3 is removed from the dynamic slice because it has a one to one mapping to the correct \noutput; (2). S10 is selected for expansion. PD(S10)={S7}.Since Verif\u00ad yDep(S7,S10) returns NOT ID, no \ndependence edges are added; (3). This time S6 is selected for expansion. PD(S6)= {S4}. Since VerifyDep(S4,S6)returns \nSTRONG ID, dependence sid S4 - . S6 is added. According to the algorithm, the statement executions that \npotentially depends on S4 are also tested in order to facilitate pruning. In our case, there are other \nstatement executions potentially depend on S4. (4). After adding the implicit dependence, a new pruned \nslice is computed as {S1,S2,S4,S6,S10}, which contains the root cause and clearly explains how the failure \nis induced. A plausible alternative to our technique is to directly com\u00adbine relevant slicing and con.dence \nanalysis. Unfortunately, this straightforward solution is problematic. In relevant slicing, the edges \nadded to the dynamic dependence graph represent potential dependences. Propagating con.dence along these \npossibly false dependence edges may result in a faulty statement appearing non\u00adfaulty. For example in \nFigure 1, relevant slicing adds a dependence between S7 and S9, which is false. Such a false dependence \nen\u00adables propagation of the con.dence value 1 from S9 to S7 and then to S1, which eventually sanitizes \nthe root cause. This suggests that con.dence analysis can only be performed along veri.ed im\u00adplicit dependence \nedges. It also provides additional motivation for our technique of detecting implicit dependence through \npredicate switching.  4. Experimental Evaluation The prototype consists of three components. The online \ncom\u00ad ponent, which was built on top of valgrind-2.2.0 [14], constructs a dynamic dependence graph with \ncontrol .ow and timestamp annotations for an execution. In the static component, diablo-0.3 [2] was adapted \nto build the control .ow graph from a x86 binary and compute static control dependences. A union de\u00ad \npendence graph, which is static, is also construted by this compo\u00ad nent by unioning all the unique dependences \nthat were exercised during the execution of a large number of test cases. Such a graph is used to compute \npotential dependences. The debugging com\u00ad ponent implemented the con.dence analysis, the demand driven \ndebugging process, and the implicit dependence veri.cation. Given a x86 binary, the prototype .rst executes \nthe binary with a large set of test cases to construct the static dependence graph and collect value \npro.le for the con.dence analysis. Next, the prototype executes the speci.c failing run to construct \nthe dynamic depen\u00ad dence graph which contains only explicit dependences. The off\u00ad line debugging component \ntakes the dynamic dependence graph, the static dependence graph, the set of correct output, and the .rst \nwrong output to start the debugging process. Benchmarks. Table 1 presents the benchmarks used in our \nexper\u00adimentation. These programs are medium-sized linux utilities that belong to the Siemens suite [12]. \nLOC represents the lines of source code. Each program has multiple versions and each version has a number \nof real or seeded errors. Test cases are also provided to ex\u00adpose these errors. We did not use the benchmark \nmake in the suite because we were not able to expose any errors using the provided test cases. Execution \nOmission Errors. We .rst investigated all the errors in the suite and identi.ed the execution omission \nerrors. More pre\u00adcisely, we .ltered out all the errors that were captured by traditional dynamic slicing \ntechniques. The remaining errors are execution  Table 1. Characteristics of benchmarks Benchmark LOC \n# of procedures Error type Description .ex 10459 162 seeded a fast lexical analyzer generator grep 10068 \n146 seeded a unix utility to print lines matching a pattern gzip 5680 104 seeded a LZ77 based compressor \nsed 14427 255 real &#38; seeded a stream editor for .ltering and transforming text Table 2. Execution \nOmission Errors Benchmark Error RS (static/dynamic) DS (static/dynamic) PS (static/dynamic) RS/DS (static/dynamic) \nRS/PS (static/dynamic) .ex V1 - F9 963/88K 946/83K 13/31 1.02/1.06 74/2838 V2 - F14 849/157K 714/27K \n9/476 1.18/5.8 94/329 V3 - F10 600/103K 80/6.8K 8/294 7.5/15.1 75/350 V4 - F6 894/265K 629/29K 2/4 1.42/9.14 \n447/66250 V5 - F6 108/915 104/873 9/15 1.04/1.05 12/61 grep V4 - F2 489/32K 416/3K 416/3K 1.18/10.7 1.18/10.7 \ngzip V2 - F3 48/618 6/9 3/5 8/68.7 16/123 sed V3 - F2 575/392K 498/118K 18/76 1.15/3.32 31.9/5158 V3 \n- F3 222/5.0K 202/3.8K 202/3.8k 1.10/1.32 1.10/1.32 omission errors as presented in Table 2. Column \nerror displays the set of errors that are under study. Error Vx - Fy denotes the yth error in the x version \nof the speci.c program. RS represents the relevant slice. Static and dynamic give the number of unique \nsource code statements and the number of dynamic statement in\u00adstances in the slice. Note that a static \nstatement can be executed many times during an execution, resulting in multiple instances of the statement. \nDS and PS denote the traditional dynamic slice and the pruned dynamic slice, respectively. The last two \ncolumns com\u00adpare their sizes. From Table 2, we are able to make the following observations: RS captures \nall the execution omission errors, but the sizes of RS are very large, which simply make manual inspection \ninfeasible. DS misses all the errors, and PS, which is the pruned version of DS, misses all the errors \nas well.  The static sizes of RS and DS are comparable. However, the dynamic sizes of RS are substantially \nlarger than those of DS, which implies much more manual effort be required in the case that instance \ninformation is essential to understand the cause\u00adeffect relations.  The sizes of PS are signi.cantly \nsmaller than those of RS, which makes inspecting PS much easier. This strongly suggests that execution \nomission errors should be located by starting with small pruned slices and then gradually exploring implicit \ndependence edges.  Effectiveness. Table 3 shows the evaluation results of effective\u00adness. The column \nlabeled # of user prunings presents the number of times that we had to tell the system that a speci.c \nstate\u00adment instance is benign before the system can acquire the minimal pruned slice, in which all statement \ninstances had corrupted pro\u00adgram state. Zero user prunings indicates that the automatic prun\u00ading based \non Ov and o\u00d7 is able to produce the minimal pruned slice. The columns labeled # of verifications , #of \niterations , and # of expanded edges present the number of veri.cations performed in order to identify \nthe (strong) implicit dependence edges, the number of iterations before the er\u00adror was located, and the \nnumber of (strong) implicit dependence edges added, respectively. IPS denotes the .nal pruned expanded \nslice that contains the error. OS is the failure-inducing dependence chain from the error to the failure. \nIn other words, it is the lower bound for a slice that can be produced by dynamic slicing-based technique. \nWe manually identi.ed these chains in order to perform the evaluation. The observations from Table 3 \nare as follows. The numbers of user interactions that are required to achieve minimal pruned slices \nare small, which implies that pruning is very effective. In order to reduce the subjective factor of \nthe experiment, we .rst manually identi.ed the OS, which is the failure inducing chain, and then statement \ninstances not in OS were selected from the pruned slice in order as being benign.  The numbers of veri.cations \nare reasonable, showing that prun\u00ading and the demand driven process successfully control the number of \nedges that we need to verify.  The numbers of iterations and the numbers of added (strong) implicit \nedges are mostly very small. In most cases, we only need to expand the pruned slice once. This implies \nthat after we reduce the slice to its minimal form, the execution omission errors can be contained by \nadding very few implicit edges in one expansion. Note that adding one implicit edge to the depen\u00addence \ngraph can make a number of executed instances become reachable. In sed-V3 - F2, we expanded twice by \nadding two strong implicit dependences edges. Our experiment reveals that most execution omission errors \nonly propagate along very few implicit dependence edges before they manifest themselves. The results \nsupport our proposed method of .rst reducing the slice to its minimal form and then expanding along implicit \ndepen\u00addence edges.  The sizes of IPS are very close to those of OS, meaning that we were able to acquire \nnearly optimal slices.  While in Table 2, the dynamic sizes are mostly orders of magnitude larger than \nthe static sizes. The static and dynamic sizes of OS in Table 3 are comparable. It implies that manually \ninvestigating dynamic statement instances is fea\u00adsible. Instances contain much more proli.c information \nsuch as values and addresses which can greatly facilitate debugging than static statements do. Previously \npeople were reluctant to inspect instances because they believed that errors may propa\u00adgate through too \nmany instances and manually inspecting them is unrealistic. Our experiment supports the opposite.  \nTable 3. Effectiveness Benchmark Error #of user prunings #of veri.cations #of iterations # of expanded \nedges IPS (static/dynamic) OS (static/dynamic) .ex V1 - F9 2 5 1 5 17/51 7/16 V2 - F14 1 4 1 1 7/24 7/24 \nV3 - F10 1 1 1 1 4/2 4/2 V4 - F6 0 6 1 5 8/28 6/23 V5 - F6 1 2 1 2 10/27 10/27 grep V4 - F2 15 313 1 \n62 103/2177 93/1196 gzip V2 - F3 2 1 1 1 5/7 5/7 sed V3 - F2 9 36 2 2 25/74 23/69 V3 - F3 10 115 1 1 \n26/74 26/74 Grep-V4 - F2 is the most complicated error we have. The er\u00adror was propagated for a long \ntime before it was observed. As a consequence, a large portion of the program state was pol\u00adluted and \nthe resulting OS was quite large. That was actually decided by the characteristics of grep, which does \nnot display any intermediate program state before it terminates. Flex and gzip demonstrate the other \nextreme: results are emitted grad\u00adually during the execution, which makes debugging a lot easier. Table \n4. Performance Benchmark Error Plain (sec.) Graph (sec.) Verif. (sec.) Graph /Plain .ex V1 - F9 0.29 \n22.7 2.7 78.3 V2 - F14 0.28 22.3 1.92 79.6 V3 - F10 0.28 22.4 0.52 80 V4 - F6 0.34 15.6 3.6 45.9 V5 - \nF6 0.12 2.2 0.48 18.3 grep V4 - F2 0.43 66.6 43.3 154.9 gzip V2 - F3 0.41 13.5 0.68 32.9 sed V3 - F2 \n0.26 11.4 16.6 43.8 V3 - F3 0.14 4.7 32.2 33.6 Performance. The last experiment is about performance. \nThe run\u00adtime cost of this technique mainly stems from two procedures: the online dependence graph construction \nprocedure which also col\u00adlects control .ow and timestamp information in order to compute potential and \nimplicit dependences, referred to as Graph in Ta\u00adble 4; and the veri.cation procedure that entails reexecuting \nthe program and producing a partial predicate trace, referred to as Verif. in Table 4. Plain presents \nthe execution times on the valgrind engine without any instrumentation. The original exe\u00adcutions took \na few miliseconds, which were so small that they may skew the results because starting up the valgrind \nengine and dy\u00adnamically instrumenting the program takes much more time than the original execution. Therefore, \na more reasonable comparison should be performed between Plain and Graph. From Table 4, the online graph \nconstruction causes a slow down in execution by factors ranging from 18.3 to 154.9 due to the heavy\u00adweight \ninstrumentation. Note that the dynamic instrumentation en\u00adgine itself is slow to begin with. In the application \nof debugging, paying the high runtime cost once may be acceptable compared to the otherwise tedious manual \nefforts. The execution times pre\u00adsented in Verif. illustrate the cost of generating and aligning predicate \ntraces. They are mainly decided by the number of veri\u00ad.cations.  5. Discussion Feasibility. One concern \narises from the brute force predicate switching, which is about the feasibility of the switched path. \nCon\u00adsider the code shown in Table 5(a). Let us assume that we are S1: X=.. P1: if A>10 then S2: A=.. \nS1: X=.. P1: if A>10 then endif P2: if A>100 then P2: if A<5 then S3: X=.. S2: X=.. endif endif endif \nS3: ..=X S4: ..=X (a) Feasibility (b) Soundness Table 5. interested in .nding the dynamic slice of X \nat S3. Further assume that the value of A was 15 and therefore S1 is executed and S2 is not executed \nbefore arriving at S3. In other words, the use of X at S3 receives value of X de.ned at S1. By switching \nthe outcome of predicate P2, we determine that a different value of X (the one de.ned at S2) reaches \nS3. As a result in our method it is assumed that an implicit dependence between P2 and S3 has been exposed. \nHowever, it seems that if P1 evaluates to true, P2 cannot evalu\u00adate to true. By forcing P2 to evaluate \nto true we may introduce a spurious implicit dependence. Our argument is that we cannot completely exclude \nthe possi\u00adbility of P1 or P2 being the error. In other words, even though the path is infeasible in the \nfaulty program, it may be feasible in the correct version of the program. Soundness. We would like to \npoint out that in general the proposed method is not sound. In particular, it may miss an implicit dependence. \nNow let us consider another example in Table 5(b), in which our method fails to expose an implicit dependence. \nLet us assume that the value of A computed at statement S2 is 5, and as aresult P1 evaluates to false \nand P2 is not executed. Therefore the value of X at S4 comes from statement S1. When computing the dynamic \nslice of X at S4 we try to expose implicit dependence by forcing the outcome of predicate P1 to true. \nForcing outcome of P1 to true causes P2 to execute but P2 evaluates to false. As a result, S3 is not \nexecuted, and thus no implicit dependence is found between P1 and S4.Ifthe value of A is incorrect, then \nwe have actually failed to expose the implicit dependence between P1 and S4. The cause of this problem \nis that the branch outcomes of nested predicates depend on the same de.nition. Switching one predicate \nat a time may not suf.ce. While the example illustrates that we may fail to uncover an implicit dependence. \nWe have not encountered such a case in our study. Furthermore, to fully overcome this problem, we have \nto either resort to a conservative solution such as relevant slicing or perturb the value of A instead \nof the branch outcome, which is much more expensive because A has an integer domain while a predicate \nhas a binary domain. 6. Related Work Dynamic slicing [8] is a technique that captures the executed state\u00adments \nthat are involved in computation of a wrong value. Some previous work [20, 19] has shown that dynamic \nslicing is quite ef\u00adfective in locating many types of runtime errors. However, working by collecting \ndata/control dependence information from executed statements, dynamic slicing is not capable of handling \nexecution omission errors. Relevant slicing [3, 20] is a technique derived from dynamic slicing which \nconservatively adds dependence edges to the dynamic dependence graph if dependences could potentially \nhappen between the omitted part and executed statements. As a re\u00adsult, spurious dependences are introduced \nand eventually the effec\u00adtiveness of this technique is diminished. Our solution is based upon dynamic \nslicing as well. What distinguishes it from other work is that it veri.es the existence of dependences \nthat are implicit and edges are only added if the dependences are veri.ed. Predicate switching [18] is \na dynamic analysis which proac\u00adtively collects evidence about a software error. The basic idea is to \nswitch the branch outcome of a predicate instance in the failed execution and then observe if the correct \noutput can be produced at the end of the execution. If that happens, such a predicate is con\u00adsidered \nas critical to the error. In the proposed technique, we use predicate switching for a different purpose \nof disclosing implicit dependences. The switched execution does not need to run till the end and a small \nset of predicate are deliberately selected to switch in order to control the runtime overhead. In [16], \nTao et al. proposed an path selection technique to expose software errors which is sim\u00adilar to predicate \nswitching. They construct a successful program run which is closest to the failed run based on a distance \nmetric. Evidence can be collected by comparing these two runs. 7. Conclusions Execution omission errors \nare dif.cult to locate using traditional dynamic analysis because these analysis are typically designed \nto focus on what ever happened while execution omission errors are more related to what never happened. \nIn this paper, we introduce the concept of implicit dependences which are dependences that are normally \ninvisible due to the omission of execution of some statements. We design a novel dynamic method that \nenables de\u00adtection of implicit dependences, which consists of reexecuting the program while switching \na speci.c predicate instance, and aligning the original and switched executions. We also propose a demand \ndriven process, which utilizes the con.dence analysis to acquire the minimal pruned slice, and then identi.es \nimplicit dependences starting from the minimal slice, avoiding verifying a large number of potential \ndependences. Our results show that execution omission errors can be easily captured with the proposed \ntechniques. Only a few implicit dependence edges need to be identi.ed.  References [1] http://www.cse.unl.edu/~galileo/sir. \n[2] http://www.elis.ugent.be/diablo/. [3] Tibor Gyimothy, Arpad Beszedes, and Istan Forgacs. An ef.cient \nrelevant slicing method for debugging. In ESEC/FSE-7: Proceedings of the 7th European Software Engineering \nConference held jointly with the 7th ACM SIGSOFT International Symposium on Foundations of Software Engineering, \npages 303 321, Toulouse, France, 1999. [4] Sudheendra Hangal and Monica S. Lam. Tracking down software \nbugs using automatic anomaly detection. In ICSE 02: Proceedings of the International Conference on Software \nEngineering, pages 291 301, Orlando, Florida, 2002. [5] Mary Jean Harrold, Gregg Rothermel, Rui Wu, and \nLiu Yi. An empirical investigation of program spectra. In PASTE 98: Proceedings of the 1998 ACM SIGPLAN-SIGSOFT \nWorkshop on Program Analysis for Software Tools and Engineering, pages 83 90, Montreal, Quebec, Canada, \n1998. [6] Matthias Hauswirth and Trishul M. Chilimbi. Low-overhead memory leak detection using adaptive \nstatistical pro.ling. In ASPLOS-XI: Proceedings of the 11th International Conference on Architectural \nSupport for Programming Languages and Operating Systems, pages 156 164, Boston, MA, USA, 2004. [7] James \nA. Jones, Mary Jean Harrold, and John Stasko. Visualization of test information to assist fault localization. \nIn ICSE 02: Proceedings of the International Conference on Software Engineering,pages 467 477, Orlando, \nFlorida, 2002. [8] Bogdan Korel and J. Laski. Dynamic program slicing. Information Processing Letters, \n29(3):155 163, 1988. [9] Ben Liblit, Alex Aiken, Alice X. Zheng, and Michael I. Jordan. Bug isolation \nvia remote program sampling. In PLDI 03: Proceedings of the ACM SIGPLAN 2003 Conference on Programming \nLanguage Design and Implementation, pages 141 154, San Diego, California, USA, 2003. [10] Chao Liu, Xifeng \nYan, Long Fei, Jiawei Han, and Samuel P. Midkiff. Sober: statistical model-based bug localization. In \nESEC/FSE-13: Proceedings of the 10th European Software Engineering Conference held jointly with 13th \nACM SIGSOFT International Symposium on Foundations of Software Engineering, pages 286 295, Lisbon, Portugal, \n2005. [11] Manos Renieris and Steven Reiss. Fault localization with nearest neighbor queries. In ASE \n03: Proceedings of the IEEE/ACM International Conference on Automated Software Engineering, pages 30 \n39, Montreal, Canada, 2003. [12] G. Rothermel and M. Harrold. Empirical studies of a safe regression \ntest selection technique. IEEE Transaction on Software Engineering, 24(6):401 419, 1998. [13] Joseph \nR. Ruthruff, Margaret Burnett, and Gregg Rothermel. An empirical study of fault localization for end-user \nprogrammers. In ICSE 05: Proceedings of the International Conference on Software Engineering, pages 352 \n361, St. Louis, MO, USA, 2005. [14] J. Seward and N. Nethercote. Valgrind, an open-source memory debugger \nfor x86-gnu/linux. In http://valgrind.kde.org/. [15] Tao Wang and Abhik Roychoudhury. Using compressed \nbytecode traces for slicing java programs. In ICSE 04:Proceedings of the International Conference on \nSoftware Engineering, pages 512 521, Edinburgh, United Kingdom, 2004. [16] Tao Wang and Abhik Roychoudhury. \nAutomated path generation for software fault localization. In ASE 05: Proceedings of the 20th IEEE/ACM \ninternational Conference on Automated software engineering, pages 347 351, Long Beach, CA, USA, 2005. \nACM Press. [17] Andreas Zeller. Isolating cause-effect chains from computer programs. In SIGSOFT 02/FSE-10: \nProceedings of the 10th ACM SIGSOFT Symposium on Foundations of Software Engineering, pages 1 10, Charleston, \nSouth Carolina, USA, 2002. [18] Xiangyu Zhang, Neelam Gupta, and Rajiv Gupta. Locating faults through \nautomated predicate switching. In ICSE 06: Proceeding of the International Conference on Software Engineering, \npages 272 281, Shanghai, China, 2006. [19] Xiangyu Zhang, Neelam Gupta, and Rajiv Gupta. Pruning dynamic \nslices with con.dence. In PLDI 06: Proceedings of the ACM SIGPLAN 2006 Conference on Programming Language \nDesign and Implementation, pages 169 180, Chicago,IL, USA, 2006. ACM Press. [20] Xiangyu Zhang, Haifeng \nHe, Neelam Gupta, and Rajiv Gupta. Experimental evaluation of using dynamic slices for fault location. \nIn AADEBUG 05: Proceedings of the International Symposium on Automated Analysis-driven Debugging, pages \n33 42, Monterey, California, USA, 2005. \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Execution omission errors are known to be difficult to locate using dynamic analysis. These errors lead to a failure at runtime because of the omission of execution of some statements that would have been executed if the program had no errors. Since dynamic analysis is typically designed to focus on dynamic information arising from executed statements, and statements whose execution is omitted do not produce dynamic information, detection of execution omission errors becomes a challenging task. For example, while dynamic slices are very effective in capturing faulty code for other types of errors, they fail to capture faulty code in presence of execution omission errors. To address this issue relevant slices have been defined to consider certain static dependences (called potential dependences) in addition to dynamic dependences. However, due to the conservative nature of static analysis, overly large slices are produced. In this paper, we propose a <i>fully dynamic</i> solution to locating execution omission errors using dynamic slices. We introduce the notion of <i>implicit dependences</i> which are dependences that are normally invisible to dynamic slicing due to the omission of execution of some statements. We design a dynamic method that forces the execution of the omitted code by switching outcomes of relevant predicates such that those implicit dependences are exposed and become available for dynamic slicing. Dynamic slices can be computed and effectively pruned to produce fault candidate sets containing the execution omission errors. We solve two main problems: verifying the existence of a single implicit dependence through predicate switching, and recovering the implicit dependences in a demand driven manner such that a small number of verifications are required before the root cause is captured. Our experiments show that the proposed technique is highly effective in capturing execution omission errors.</p>", "authors": [{"name": "Xiangyu Zhang", "author_profile_id": "81384614270", "affiliation": "Purdue University, West Lafayette, IN", "person_id": "P514156", "email_address": "", "orcid_id": ""}, {"name": "Sriraman Tallam", "author_profile_id": "81100082535", "affiliation": "Universty of Arizona, Tucson, AZ", "person_id": "P414188", "email_address": "", "orcid_id": ""}, {"name": "Neelam Gupta", "author_profile_id": "81100020118", "affiliation": "University of Arizona, Tucson, AZ", "person_id": "PP14020142", "email_address": "", "orcid_id": ""}, {"name": "Rajiv Gupta", "author_profile_id": "81100027751", "affiliation": "University of Arizona, Tucson, AZ", "person_id": "PP39066852", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250782", "year": "2007", "article_id": "1250782", "conference": "PLDI", "title": "Towards locating execution omission errors", "url": "http://dl.acm.org/citation.cfm?id=1250782"}