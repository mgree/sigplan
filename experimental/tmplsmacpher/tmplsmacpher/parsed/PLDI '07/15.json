{"article_publication_date": "06-10-2007", "fulltext": "\n Sketching Stencils Armando Solar-Lezama, Gilad Arnold, Liviu Tancau, Rastislav Bodik, Vijay Saraswat,* \nSanjit Seshia University of California, Berkeley {asolar,arnold,tancau,bodik,sseshia}@eecs.berkeley.edu \nAbstract Performance of stencil computations can be signi.cantly improved through smart implementations \nthat improve memory locality, computation reuse, or parallelize the computation. Unfortunately, ef.cient \nimplementations are hard to obtain because they often in\u00advolve non-traditional transformations, which \nmeans that they can\u00adnot be produced by optimizing the reference stencil with a com\u00adpiler. In fact, many \nstencils are produced by code generators that were tediously handcrafted. In this paper, we show how \nstencil implementations can be produced with sketching. Sketching is a software synthesis ap\u00adproach where \nthe programmer develops a partial implementation a sketch and a separate speci.cation of the desired \nfunctionality given by a reference (unoptimized) stencil. The synthesizer then completes the sketch to \nbehave like the speci.cation, .lling in code fragments that are dif.cult to develop manually. Existing \nsketching systems work only for small .nite programs, i.e., programs that can be represented as small \nBoolean circuits. In this paper, we develop a sketching synthesizer that works for stencil computations, \na large class of programs that, unlike circuits, have unbounded inputs and outputs, as well as an unbounded \nnumber of computations. The key contribution is a reduction algorithm that turns a stencil into a circuit, \nallowing us to synthesize stencils using an existing sketching synthesizer. Categories and Subject Descriptors \nD.2.2 [Software Engineer\u00ading]: Software Architectures, Design Tools and Techniques; D.3.3 [Programming \nLanguages]: Language Constructs and Features General Terms Languages, Design, Performance Keywords Sketching, \nStencil, SAT 1. Introduction Sketching is a program synthesis paradigm in which a programmer expresses \nan outline of the implementation, called a sketch. The de\u00adtails missing in the sketch are .lled in by \nthe compiler such that the result is functionally equivalent to a separately provided speci.ca\u00adtion. \nProgramming by sketching is supported by the SKETCH lan\u00adguage [21], an imperative language with a hole \nconstruct. Holes can be used in place of hard-to-get-right expressions, such as index expressions and \nloop bounds. The SKETCH synthesizer infers the content of holes using a SAT-based combinatorial search \nover the Permission to make digital or hard copies of all or part of this work for personal or classroom \nuse is granted without fee provided that copies are not made or distributed for pro.t or commercial advantage \nand that copies bear this notice and the full citation on the .rst page. To copy otherwise, to republish, \nto post on servers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI \n07 June 11 13, 2007, San Diego, California, USA. Copyright c . 2007 ACM 978-1-59593-633-2/07/0006. . \n. $5.00 * IBM T. J. Watson Research Center vsaraswa@us.ibm.com space of possible sketch completions. \nThanks to the combinatorial search, the synthesizer requires no domain-speci.c knowledge and can therefore \nbe applied to a wide variety of programming prob\u00adlems, as long as they compute .nite programs, i.e., \nfunctions that take inputs of bounded size and perform a .nite computation. SKETCH has been used to synthesize \nef.cient implementations for non-trivial functions including ciphers (e.g., DES and AES), error-correction \ncodes, and long integer multiplication in only a fraction of the time required for coding a full and \ncorrect imple\u00admentation. Scienti.c computing codes could equally bene.t from sketch\u00ading. Despite advances \nin optimizing compilers, these codes are of\u00adten hand-crafted through a long and error-prone process. \nThe chal\u00adlenges arise in particular when transforming a loop iteration space for better locality and \ncomputation reuse. For example, a complex tiling strategy may entail index and loop bound expressions \nthat are hard to write and debug. Unfortunately, most scienti.c codes are not .nite programs: their input \nsize is unbounded, and hence SKETCH is unable to syn\u00adthesize them. While we can .nitize some scienti.c \nkernels by .xing their problem size, the combinatorial problem easily overwhelms the SAT solver. (In \nfact, SKETCH already fails to synthesize a sim\u00adple kernel on an 8x8 matrix.) This paper introduces sketching \nfor stencil-based scienti.c ker\u00adnels. Stencil kernels transform an arbitrarily large input grid into \nan output grid, mostly by applying constant-time, nearest-neighbors computations. This domain includes \nmany widely-used iterative PDE solvers, including the popular Jacobi and MultiGrid [3] meth\u00adods. These \nsolvers constitute the core of many structured grid ap\u00adplications, such as elasticity and .uid dynamics \nsimulations. In order to handle the unbounded nature of stencils, we develop a program transformation \nthat reduces a stencil into a .nite pro\u00adgram. The reduction is enabled by the internal boundedness of \na stencil, a property that each output grid element is a function of only a .nite (and small) number \nof input grid elements. The reduc\u00adtion process effectively extracts this function from an imperative \nprogram with loop nests. The reduced stencil is then synthesized using the .nite SKETCH synthesizer. \nBecause the reduction is loss\u00adless, we can plug the synthesized holes back into the original sketch to \nobtain a complete and correct implementation of the stencil. We have used sketching to implement a recursive, \ncache\u00adoblivious implementation of a 2-point stencil. The paper also de\u00adscribes our experience implementing \ntwo kernels from the Multi-Grid solver. The implementation of two MultiGrid kernels took less than two \nhours of work by one of the authors, including synthesis time, which did not exceed 5 minutes. Both sketches \nproduced im\u00adplementations that were 2 to 8-times faster than the corresponding naive stencil. In summary, \nthis paper makes the following contributions: It presents a sketching synthesizer for the class of stencil \ncom\u00adputations. It is the .rst system for sketching programs that go beyond the .nite programs of the \noriginal SKETCH language and synthesizer [21]. It develops and evaluates a reduction mechanism for transform\u00ading \nan unbounded stencil into a .nite function for which an ef\u00ad.cient synthesizer is available.  It shows \nthat the reduction based approach scales to real\u00adworld implementations of kernels of interest to the \nscienti.c\u00adcomputing community, and that it is able to synthesize imple\u00admentations which are beyond the \nreach of commercial optimiz\u00ading compilers.  2. The SKETCH Programming Language To give necessary background \nfor the sections that follow, this section summarizes the .nite sketch synthesis method introduced in \n[21] and implemented in the SKETCH language and compiler. The original SKETCH language allows the user \nto write a clean, behavioral speci.cation for an algorithm, and then sketch the out\u00adlines of a more ef.cient \nimplementation. The following example illustrates some of the key features of the language. The function \non the left is a speci.cation that computes the logarithm of an in\u00adteger by searching for the position \nof the most signi.cant non-zero element. The speci.cation is executable, so it can be debugged and tested \nlike any other program. The function on the right is a sketch. The implements clause in the function \nheader states that sklog2 should be resolved to be behaviorally equivalent to slog2.The ?? operators \nwill be replaced by the synthesizer with suitable constants to satisfy this equivalence. int W = 8, logW \n= 3; bit[W] sklog2(bit[W] in) bit[W] log2(bit[W]in) { implements log2 { bit[W]i= W; bit[W]ret=0; while \n(ret > 0) { loop (logW) i--; if (in &#38; ??){ if (in[i]) in >>= ??; break; ret |= ??; }} return i; return \nret; }} The sketch speci.es the key properties of the implementation: in particular, we state that it \napplies a binary search (with a logarith\u00admic number of steps) to .nd the most signi.cant non-zero, setting \nthe bits of the result accordingly. The ?? operator is being used in place of tedious details of the \nimplementation, such as the actual masks and shifts. The synthesizer will unroll loop constructs the \nappropriate number of times, inline all function calls (if such ex\u00adist), and then substitute all holes \nwith actual values to produce a .nal implementation that matches the behavior of the speci.cation for \nall inputs. bit[W] sklog2_resolved(bit[W] in) { bit[W] ret = 0; if (in &#38; 0xf0) { in >>= 4; ret |= \n4; } if (in &#38; 0xc0) { in >>= 2; ret |= 2; } if (in &#38; 0x02) { in >>= 1; ret |= 1; } return ret; \n} The sketch compiler completes the sketch by reducing the prob\u00adlem to a generalized Boolean satis.ability \nproblem. Having un\u00adrolled all loops and inlined all function calls, the compiler then replaces each hole \nin the resulting straight-line program with a dis\u00adtinct free variable, referred to as a control variable. \nThen it trans\u00adlates both the speci.cation and the sketch into Boolean functions of the inputs and the \ncontrol variables. At this point, the sketch resolution problem becomes a 2QBF Boolean satis.ability \nproblem (i.e., a satis.ability problem with two quanti.ers) of the form .c..x.P (x)=S(x, c) (2.1) where \nP is a Boolean function representing the spec, and S is a Boolean function representing the sketch. The \nvariables x and c correspond to the program inputs and the control variables respec\u00adtively. The formula \nspeci.es a search for a value c of the control variables that will make the sketch behave identically \nto the speci\u00ad.cations on all inputs x. The problem is then solved using a counterexample-driven search \nprocedure. The solver expects that there will be a small set of inputs E such that a solution c to the \nproblem .c..x . E.P (x)=S(x, c) (2.2) will also be a solution to Equation (2.1). Equation (2.2) can be \nex\u00adpanded and supplied to a SAT solver directly since the universal quanti.cation over the small set \nE can be expressed as a conjunc\u00adtion. The SKETCH solver starts by solving Equation (2.1) with E containing \nonly a single random input. It then veri.es that the syn\u00adthesized c actually solves Equation (2.1). If \nthe veri.er fails, it will produce a counterexample which is added to set E, and the process is repeated \nuntil a solution is found or the sketch is shown buggy (i.e., it cannot be completed to behave like the \nspeci.cation). The synthesis algorithm works remarkably well, but requires that both the spec and the \nsketch be .nite programs. This means that the number of iterations of all loops and the sizes of all \narrays must be bounded at compile time. In the rest of the paper, we describe how we have overcome this \nlimitation for the domain of stencils. 3. Sketching Stencil Kernels In the scienti.c computing literature, \na stencil is a nearest-neighbor computation on a grid, where the new value of a grid entry is computed \nas a function of the old values of some of its neighbors. Stencils are generally classi.ed by the number \nof neighbors they consider and the dimensions of the grid. For example, a typical new four-point stencil \nin two-dimensions computes a value ai,j as a old old old old linear combination of the values ai+1,j \n, ai,j+1, ai-1,j and ai,j-1. This paper uses a broader de.nition of stencils: we de.ne a stencil to be \na function that computes each element of an output grid by performing constant time operations on a bounded \nnumber of input grid elements. Stencils form the core of many scienti.c applications; in par\u00adticular, \nmost PDE solvers work through repeated applications of different stencils. Stencils are also important \nin signal processing, image analysis and even compression; for example, the wavelet transform that forms \nthe basis of the JPEG2000 image compression standard is implemented as a sequence of stencil computations. \nOur broader de.nition of stencils also covers data permutations, such as matrix transpositions, and even \ndata-dependent permutations such as scatter and gather operations. As be.ts such an important class of \nproblems, great efforts have been expended in automatically identifying and optimizing stencils, particularly \nin languages for high-performance computing, such as HPF [18] and ZPL [20]. Fully automatic optimization \napproaches, however, are constrained by the set of transformations built into the compiler, as well as \nthe analysis and heuristics used to decide if it is possible and convenient to apply a given one. These \nconstraints are relevant for production codes because stencil optimization is still an area of active \nresearch [10 12, 19]. For this reason, many production-level stencil codes are still hand-tuned in Fortran \nand C++. Hand-optimized stencil implementations can be .endishly com\u00adplicated despite their relatively \nsmall size. As one of the authors can int N; int T=3; // manipulate 3 rows at once void sten1d(float[N] \nin, float[T,N] X) { for (int i = 0; i < N; ++i) X[0, i] = in[i]; for (int t = 1; t < T; ++t) for (int \ni = 1; i < N-1; ++i) X[t, i] = X[t-1, i-1] + X[t-1, i+1] ; }  Figure 1. Speci.cation for 1-dimensional \n2-point stencil. (a)  (b)  (c)  (d)  5 6 7 8 1 2 3 4  Figure 2. (a) Grid with some of the data \ndependencies. The regions in the two ends correspond to the corner cases which the time\u00adskewed implementation \nwill have to handle differently. (b) Iteration direction for the spec. (c) Iteration direction for the \ntime-skewed implementation. (d) Iteration direction for the base case of the cache-oblivious scheme. \nattest from personal experience, one can easily spend several days hunting for a bug in two hundred lines \nof this low-level code. The complexity in these implementations arises from a large number of low-level \nexpressions controlling nested looping and multidimen\u00adsional indexing. These expressions have little \nintuitive meaning for the programmer because they do not resemble the speci.cation. To make matters worse, \nprogramming errors may have subtle effects which are hard to spot. For example, it is possible for iterative \nal\u00adgorithms that work by repeated applications of a stencil to produce the correct answer even when coded \nwith a buggy stencil; they al\u00adgorithm may just take much longer to converge. For these reasons, the domain \nof stencils is well suited for sketching: stencil speci.cations can usually be stated cleanly and concisely, \nin a few dozen lines of code, and the low-level ex\u00adpressions which complicate the implementations can \nbe ef.ciently synthesized by the compiler. As the following example illustrates, sketched implementations \nfor stencils allow the developer to pro\u00advide high-level insights about an implementation without getting \nbogged down in low-level implementation details. 3.1 Example The stencil we want to implement is a 2-point \n1-dimensional stencil Xt-1 + Xt-1 of the form Xt = . In order to improve temporal ii-1 i+1 locality, \nthe implementation will compute the next two iterations (called timesteps) of the stencil at once, instead \nof a single one. This is described by the full speci.cation shown in Figure 1. From this speci.cation, \nwe are going to create two implementations, the second one being an improvement of the .rst one. First, \nwe are going to implement time-skewing, as described in [23]. Then we are going to use this time-skewing \nimplementation as a reference to produce a recursive cache-oblivious implementation like the one described \nin [10]. The time-skewing transformation requires us to change the iter\u00adation pattern from the one in \nFigure 2(b) to the one in Figure 2(c). Note that in order to preserve the dependencies, we have to tra\u00adverse \nalong diagonals, which forces us to treat the cells close to the boundary as special cases, as shown \nin Figure 2(a). It is easy to see that one must write three separate loop nests, two for the corner cases \nand one for the steady state. However, determining the ex\u00adact expressions to use for the loop iteration \nbounds is a challenging task, especially for the corner cases, where the iteration bound for the inner \nloop depends on the outer loop. We can express the imple\u00admentation idea in a sketch that leaves all these \ndetails unspeci.ed. To understand the sketch shown below, recall that in SKETCH, functions that contain \nholes in them are inlined into their call site before the holes are resolved. In effect, we can think \nof these func\u00adtions as macros. The inlining semantics allow us to treat functions with holes as generators.Inthe \nsketch below, linexpG is a gener\u00adator that produces expressions involving sums and differences of its \narguments, and the generator loopNest can produce loop-nests with arbitrary loop conditions, but which \nfollow the diagonal pat\u00adtern we desire. In this example, each call to linexpG and loopNest expands into \na separate snippet of code, and the holes in each of these snippets are independent of each other. After \nthe holes are resolved, partial evaluation is applied to clean up the code by elim\u00adinating unnecessary \noperations and conditionals. int linexpG(int a, b, c= 0) { rv = ??; if (??)rv=(?? ?rv+a:rv-a); if (??)rv=(?? \n?rv+b:rv-b); if (??)rv=(?? ?rv+c:rv-c); return rv; } void loopNest(float[T,N] X) { for (int i = linexpG(N, \nT); i < linexpG(N, T); ++i) for (int t = linexpG(N, T, i); t < linexpG(N, T, i); ++t) X[t, i-t] = X[t-1, \ni-t-1] + X[t-1, i-t+1]; } void sten1dSK(float[N] in, float[T,N] X) implements sten1d { if (N >= 3) { \nfor (int i = 0; i < N; ++i) X[0, i] = in[i]; loopNest(X); // generate left corner case loopNest(X); // \ngenerate steady-state loop loopNest(X); // generate right corner case } else sten1d(in, X); // optimization \ninapplicable } The key idea of the implementation is expressed in the sketch = Xt-1 +Xt-1 by stating \nthat Xt , but the low-level details i-ti-t-1 i-t+1 of the loop iteration bounds are left for the compiler \nto discover. As an added bene.t, the sketch spares the programmer from the error\u00adprone task of having \nto code the three cases separately. Instead, all three loops are synthesized from the generator loopNest. \nThis sketch resolves to the correct implementation in less than 4 minutes, and produces the code shown \nbelow. The synthesized expressions are underlined. void sten1dSK(float[N] in, float[T,N] X) implements \nsten1d { if (N >= 3) { for (int i = 0; i < N; ++i) X[0, i] = in[i]; for (int i=0;i<T;++i) for (int t=1;t<i;++t) \nX[t, i-t] = X[t-1, i-t-1] + X[t-1, i-t+1]; for (int i=T;i<N;++i) for (int t=1;t<T;++t) X[t, i-t] = X[t-1, \ni-t-1] + X[t-1, i-t+1]; for (int i=N;i<N+T;++i) for (int t=i-N+2;t<T;++t) X[t, i-t] = X[t-1, i-t-1] + \nX[t-1, i-t+1]; } else sten1d(in, X); } This time-skewed implementation will serve to as a reference for \na cache-oblivious implementation of the middle loop, which handles the steady state behavior. The .rst \nstep will be to extract this loop and put it into a separate function as shown below. We will treat this \nfunction as a speci.cation. void mainLoop(float[T,N] X, int n1, int n2) { for (int i = n1; i < n2;++i) \nfor (int t=1; t<T;++t) X[t, i-t] = X[t-1, i-t-1] + X[t-1, i-t+1]; } The developer writes another sketch \nto implement this speci.\u00adcation with the recursive partitioning that yields a cache-oblivious behavior. \nFor the base case of the recursion, we are going to reverse the loops, since the block is small enough \nthat we believe we can get better cache behavior this way: it will result in consecutive reads instead \nof interleaved ones. Since we are not sure how the reversal is going to affect the index expressions, \nwe just replace them with the linexpG generator. On the other hand, we wish to retain control of the \nrecursive partitioning and the size of the base case, so that portion of the sketch is fully speci.ed. \nFrom the sketch, the synthe\u00adsizer produces the desired recursive implementation and proves its equivalence \nto the original spec. void mainLoopSK(float[T,N] X, int n1, int n2) implements mainLoop { if (n2-n1 < \n4) for (int t=1; t<T;++t) for (int i =n1; i < n2; ++i) X[t, i-t] = X[t-1, linexpG(i,t)] + X[t-1, linexpG(i,t)]; \nelse { int m=(n1 +n2)/2; X = mainLoopSK(X, n1, m); X = mainLoopSK(X, m, n2); } return X; } The cache-oblivious \nimplementation we have produced is known to be dif.cult to implement by hand, especially for higher dimensions. \nBut using the algorithms presented in this paper, the sketch compiler easily synthesizes the low-level \ndetails for this complex implementation. (Note that for a 3-D stencil, we would have to deal with 16 \ndifferent corner cases, making an optimization by hand extremely dif.cult [11].) Furthermore, no compiler \nwe know of will generate a recursive cache-oblivious implementation automatically.  4. Overview of Stencil \nSynthesis As mentioned before, the compiler resolves the sketches by .rst re\u00adducing the spec and the \nsketch to .nite programs, solving the .nite synthesis problem with the SKETCH compiler, and then mapping \nthe results of .nite synthesis onto the original sketch. This section presents the key ideas of the reduction \nprocess; the reduction algo\u00adrithm is described in detail in Section 5. The algorithm exploits domain-speci.c \nproperties to reduce both the spec and sketch into bounded programs without loss of information. In particular, \nthe reduction uses the fact that each element in the output grid is computed from a .nite number of input \ngrid elements. This property allows the compiler to represent the stencil as a function taking only a \nsmall number of grid elements as input and producing only a single element of the output. For example, \nthe compiler reduces a 2-point 1-D stencil s into a .nite program reduced_s: float[N] s(float[N] in); \nfloat reduced_s(float[4] v, int N, int idx); The reduced stencil reduced_s computes s(in)[idx], i.e.,the \nvalue of the idx-th element of the grid computed by the original stencil s. The .nite array v represents \nthe elements from the input grid in that are needed to compute s(in)[idx]. (This section will explain \nwhy four elements are needed for a 2-point stencil.) The function is a .nite program, and therefore a \nvalid input to the .nite SKETCH solver: the size of its input and output are .xed to small constants, \nand, as we will see shortly, the number of computations performed by the function is constant with respect \nto the input parameters. In particular, the value of N no longer determines the amount of computation; \nit is only passed because it may be needed to compute the output value, e.g., to identify if the desired \noutput element is close to the grid boundary. The reduction works in three steps; the same steps are \napplied to both the spec and the sketch. First, the reduction bounds the size of the program output by \nfocusing on a single element of the output grid. Second, it uses symbolic manipulation to bound the number \nof computations performed by the stencil. Finally, it uses abstraction to bound the size of the input. \nTo illustrate the process, we use the 2-point 1-D stencil, together with a somewhat contrived sketch \nwhich nonetheless hints at how more complex sketches are reduced. For the sake of simplicity, the sketch \ndiffers from the speci.cation only slightly: it uses holes to adjust its index expressions to compensate \nfor its loop bounds, which differ from those in the spec. The functions f, g,and h stand for arbitrary \nindex expressions (these functions do not have side effects): float[N] spec(float[N] in) { foreach i \n. [1, N-2] out[f(i)] = in[g(i)] + in[h(i)]; } float[N] sketch(float[N] in) implements spec { foreach \nk . [0, N-??] out[f(k+??)] = in[g(k+??)] + in[h(k+??)]; } Bounding the output. We replace the unbounded \noutput grid with a single scalar by making the program return the value of a single element of that output \ngrid. Speci.cally, a stencil func\u00adtion s is transformed to a function scalar_s in such a way that s(in)[idx]=scalar_s(in, \nidx). The transformation does not lose any information, and the behavior of the original program can \nbe obtained by invoking the scalar function of s as shown below for both the spec and the sketch. float[N] \nspec(int[N] in) { foreach j . [0, N-1] out[j] = scalar_spec(in, j); } float[N] sketch(int[N] in) implements \nspec { foreach j . [0, N-1] out[j] = scalar_sketch(in, j); } Note that aside from calling a different \nscalar function, the spec and the sketch are identical (both compute all elements of the output grid \nout). Hence, we reduced the stencil synthesis problem to the problem of making the scalar functions scalar_sketch \nand scalar_spec behave identically. The two scalar functions are shown below. Their goal is to express \nout[idx] in terms of the input grid. Both functions achieve this with a two-step symbolic back-substitution \nprocess. First, they compute the iteration in which the output element out[idx] was most recently assigned. \n(In our example, each output element was assigned at most once, but as we shall see in the next section \nthis is not required by the algorithm.) The number of this iteration is stored in variable last. Next, \nthe value of out[idx] is computed by evaluating the right-hand-side expression of the most recent assignment. \nIf the right-hand-side expression refers to values other than the input, the two-step process is repeated \n(not needed in our example). float scalar_spec1(float[N] in, int idx) { int last = UNDEFINED; foreach \ni . [1, N-2] if (idx == f(i)) last = i; if (last == UNDEFINED) return 0; return in[g(last)] + in[h(last)]; \n} float scalar_sketch1(float[N] in, int idx) { int last = UNDEFINED; foreach k . [0, N-??] if (idx == \nf(k+??)) last = k; if (last == UNDEFINED) return 0; return in[g(last+??)] + in[h(last+??)]; } Bounding \nthe number of computations. The scalar functions execute an unbounded number of computations because \nthey con\u00adtain loops controlled by the free variable N. However, the only purpose of the loops is to identify \nthe latest iteration that wrote to out[idx]. This operation can be expressed declaratively as last = \nmax({[1,N-2]nf-1(idx)}),where f-1 is the inverse of the index expression f. The advantage of this formulation \nis that it allows us to use a symbolic solver to reduce the evaluation of the latest iteration expression \ninto a .nite sequence of operations. Our current solver is quite rudimentary, but it has already been \nable to handle all the problems we have tried so far, including several from real-world benchmarks. For \nour running example, the declarative formulation allows us to write the scalar functions as follows. \nfloat scalar_spec2(float[N] in, int idx) { int last = max({[1,N-2] n f-1(idx)}); if (last == UNDEFINED) \nreturn 0; return in[g(last)] + in[h(last)]; } float scalar_sketch2(float[N] in, int idx) { int last = \nmax({k | k . [0,N-??] . k+?? . f-1(idx)}); if (last == UNDEFINED) return 0; return in[g(last+??)] + in[h(last+??)]; \n} If f is the identity function, for example, the symbolic solver will replace the last-iteration computation \nwith a few conditional assignments; the one in the spec is shown below. if (idx >= 1 &#38;&#38; idx <= \nN-2) last = idx; else last = UNDEFINED; After the replacement, the functions are already bounded in \nterms of computation, but the input is still an unbounded array. Bounding the input. For programs that \ndo not modify their in\u00adputs, the input array can be treated as an uninterpreted function. In other words, \nthe input array is an entity whose only discernible property is that accesses with the same index produce \nthe same value. Programs like the example in Section 3.1 that do modify their input array are modeled \nby the compiler as receiving an immutable array as input, copying it into a mutable array, and then returning \nthe modi.ed array as an output at the end of the computation. The next problem is to represent the uninterpreted \nfunction .nitely. We observe that the scalar functions scalar_spec2 and scalar_sketch2 read only a .nite \nnumber of input grid elements, which lets us borrow a technique originally proposed by Acker\u00adman [1] \nand used extensively in hardware veri.cation [4]. The function in_fn below implements the semantics of \nan uninterpreted function under the restriction that the function is called with at most four different \nvalues of the argument. (For this example, we can re\u00adstrict ourselves to four symbolic values because \nthe scalar functions reduced_spec and reduced_sketch, shown below, will together make no more than four \ndynamic calls to in_fn for a given value of their input parameter idx.) The function in_fn implements \nthe desired semantics by returning the same symbolic value whenever called with the same value of the \nargument in_idx. float in_fn(int in_idx) { if (in_idx == i0) return v0; if (in_idx == i1) return v1; \nif (in_idx == i2) return v2; if (in_idx == i3) return v3; } This use of uninterpreted functions is considered \na form of abstrac\u00adtion, because we are representing an unbounded grid using only four scalars by throwing \naway all the information about those cells that were not accessed on a particular invocation of the scalar \nfunc\u00adtions. The .nal step is to represent the symbolic values ik and vk with constructs from the SKETCH \nlanguage. (Recall that SKETCH relies on a Boolean satis.ability solver which does not support symbolic \nmanipulations.) The non-symbolic version of in_fn shown below, expressed entirely in SKETCH, implements \nthe symbolic values ik by remembering the concrete values of arguments in a global array. The symbolic \nvalues vk are implemented as function arguments. This treatment will make the synthesizer carry out its \nreasoning under all possible values of vk, which is equivalent to viewing vk as symbolic values. float \nin_fn(int in_idx, float[4] v) { static int[4] g; static int gi=0; // globals g[gi++] = in_idx; if (in_idx \n== g[0]) return v[0]; if (in_idx == g[1]) return v[1]; if (in_idx == g[2]) return v[2]; if (in_idx == \ng[3]) return v[3]; } As an optional optimization, our system allows the user to assert that the sketch \ncomputes out[idx] using only the input elements used by the spec, as opposed to arbitrary input elements. \nThat is, the array g is set only in the spec; the sketch only reads its values and asserts that one of \nthem matches. This is the case for almost all implementations, because if a sketch used any other entry, \nits value would have to get canceled out in order for the spec and the sketch to be equivalent. Using \nthis assumption, we can reduce the number of comparisons on each call to the uninterpreted function, \nsince we only need to compare the index to those indices used by the spec, but not with those used by \nthe sketch. With this optimization, the compiler will ignore any implementation that violates the assumption, \nwhile never producing an incorrect implementation. Putting it all together. Let us assume for the sake \nof simplicity that f, g,and h are identity functions. Then, the symbolic solver reduces the evaluation \nof the latest iteration expression to guarded assignments as shown below. float reduced_spec(float[4] \nv, int N, int idx) { if (idx < 1 || idx > N-2) return 0; return in_fn(idx, v) + in_fn(idx, v); } float \nreduced_sketch(float v[4], int N, int idx) { int last = idx -??1; if (last < 0 || last > N-??2) return \n0; return in_fn(last+??3, v) + in_fn(last+??4, v); } These functions de.ne a .nite sketch problem which \ncan be solved by the .nite SKETCH solver. In this case, the SKETCH solver can easily prove that the abstracted \nsketch and spec are equivalent for the following value assignments to holes: ??2 =3, ??1 = ??3 = ??4 \n=1. The control values can then be applied to the original sketch, and the construction will guarantee \nthat the resulting implementa\u00adtion is equivalent to the original spec. Abstracting integers and .oating \npoint values. Here, we focus on complications arising from modeling integer and .oating-point values. \nThe reduced functions produced by the above algorithm lead to intractable SAT problems if translated \ndirectly to Boolean circuits, mainly due to the presence of .oating point variables in the reduced programs. \nAdditionally, modeling .oating point values in their full IEEE glory would make the equivalence criterion \noverly strict, ruling out many optimizations employed by programmers who often choose to assume associativity \nof .oating point numbers. There are numerous approaches in the literature to handle .oat\u00ading point arithmetic \nin the context of model-checking and veri.ca\u00adtion, most of them relying on uninterpreted functions [6,15]. \nWhile it is relatively easy to replace .oating point operations with uninter\u00adpreted functions, there \nis a simpler approach that works remarkably well in our domain. The key observation is that the stencils \nwe are generating are often linear functions in their .oating point argu\u00adments: both the reduced spec \nand sketch have the property that if you set their integer inputs to any .xed value, the remaining func\u00adtion \nwill be a linear function (it may be a different linear function for different values of the integer \ninputs). The stencil appears linear to the solver because it performs veri.cation separately for each \ncombination of integer input values. It is trivial to verify this prop\u00aderty statically from a DAG representation \nof the reduced spec and reduced sketch. When this property holds as is the case with all the benchmarks \npresented in this paper the compiler can safely replace all .oating point inputs with 1-bit integers \nwithout losing soundness, provided that it grows the integer representation when\u00adever necessary to avoid \narithmetic over.ow. The soundness argu\u00adment should be obvious from the fact that in order to test the \nequiv\u00adalence of two k-dimensional linear functions over the reals, one only needs to test them with kindependent \nvectors. Floating point constants are treated as free variables, and are also represented with a single \nbit. This treatment is sound but not complete because it loses algebraic relationships among constants. \nFor example, after we replace 0.5 with a free variable v0.5, we can no longer prove that a*0.5+a*0.5 \n== a. This limitation did not prove to be an issue for any of the benchmarks we studied. After performing \nabstraction on the .oating point values, the remaining problems involve only integers and Booleans. Our \ncur\u00adrent approach is to translate these problems directly into circuits, which limits our scalability \nto representing integers with about 6 bits (3 bits for the hardest benchmarks). However, there are known \nscalable techniques that we can use to remove this limitation [5].  5. Algorithm Details Here, we presents \nin detail the stencil reduction algorithm outlined in Section 4, focusing mainly on the .rst two steps \n(bounding the output and bounding the computations). 5.1 Preliminaries We use standard compiler transformations \nto bring the input pro\u00adgrams (i.e., the speci.cation and the sketch) into an intermediate normal form \nbearing the following properties: Loops. All loops are normalized to the form for (int i=e1; i < e2; \n++i),where i is the uniquely named main induction variable of the loop. Remaining loop induction variables \nare expressed as a function of i. Function calls. All calls are inlined. Recursive calls to sketched \nfunctions are replaced with calls to their speci.cations (which must be non-recursive). Proving equivalence \nof the spec and a recursive sketch after this transformation constitutes a proof by induction, under \nthe assumption that the recursion is well founded (i.e., that all recursive calls eventually terminate). \nNormalized programs obey the following syntax: Expressions e ::= n | true | false | x | x[e] | e1 op \ne2 | f(e1, ...,ek) | switch ecase n1: e1; ...case nk: ek Statements c ::= x:= e| x[e1]:= e2 | skip | \nif e then c1 else c2 | c1; c2 | for (i = e1;i < e2; ++i) c Functions f ::= def f(x1, ...,xk) c return \ne An additional semantic restriction is that loop bounds must be invariant with respect to the induction \nvariable of their loop. The bounds can, of course, relate to outer induction variables. This restriction \ncould be relaxed, but the complications involved are not justi.ed in the domain of stencils. The domain \nis also restricted by the power of the algebraic solver used to eliminate the latest assignment expression \n(called RD in this section). If the program satis.es the aforementioned constraints, the re\u00adduction about \nto be described will be sound, but only under the as\u00adsumption that there is no integer over.ow in either \nthe spec or the sketch. This is because the symbolic solver used to eliminate the latest assignment expression \nmay assume algebraic properties that do not hold in the presence of over.ow (e.g., a-1<N .. a<N+1). \n 5.2 Synthesizing Scalar Functions We describe the algorithm that generates scalar functions and bounds \ntheir computation. These two steps are performed in an intertwined fashion and we describe them together. \nOne way to de.ne a scalar function is to view it as a slice of the original stencil. More precisely, \ngiven a stencil computation s(in) returning a grid out, and an index idx, the scalar function computes \na slice of s with respect to out[idx]. While the original computation may read the entire (unbounded) \ninput grid, the slice only reads a bounded number of input elements. The slice is expressed recursively, \nusing a functional language that resembles the one de.ned by the above syntax, but does not include statements. \nEach recursive call corresponds to a def-use edge in the slice of out[idx]. Since the slice incurs a \nbounded computation, the recursion is bounded. The result is thus .nite and can be accepted by the .nite \nSKETCH synthesizer.1. The slicing algorithm boils down to expressing out[idx] sym\u00adbolically in terms \nof program inputs. To this end, we recursively substitute non-input variables in the expression out[idx] \nwith the right-hand side values of their most recent assignments. We refer to most recent assignments \nas reaching de.nitions.In contrast with traditional reaching de.nitions, which offer a static approximation \nof the dynamic behavior of the program, our reach\u00ading de.nitions are concrete: they are de.ned on the \nexecution trace where each program point is reached by at most one de.nition for any program location. \nSince there is no ambiguity as to which de.\u00adnition most recently assigned the location, we obtain precise \nback\u00adsubstitution in the sense that the fully substituted symbolic expres\u00adsion is executable and computes \nthe value of out[idx]. The procedure RD, which lies at the heart of the algorithm, computes the concrete \nreaching de.nition of a memory location. RD :M \u00d7 P \u00d7 I . P The procedure maps a memory location m . M, \nan execution point p . P , and a program input i . I to the most recent execution point that de.ned the \nvalue of m prior to p, under the input i. The set of memory locations M consists of scalar variables \nand array elements. The set of execution points P is the cross product of static program points with \nthe loop iteration space. The input space I includes the input grid together with any scalar arguments. \nWe are now ready to describe the abstraction algorithm. For each scalar variable v we create a function \nv_fn :P \u00d7 I . T that computes the value n of v at execution point p . P under the input i . I. The type \nT is a primitive type (boolean, int,or double). The function will be expressed in the functional language \nshown above. Similarly, for an array a (for simplicity, we assume that arrays are one-dimensional) we \ncreate a function a_fn :Int \u00d7 P \u00d7 I . T that computes the value of a[idx] for an index idx . Int at point \np . P under the input i . I. These two functions are called v\u00adfunctions. The reduced function for a stencil \ns returning a grid out now becomes double reduced_s(int idx, double[N] in) { return out_fn(idx, Pe, in); \n} where Pe is the end point of the program execution trace. v-functions are constructed via syntactic \ntranslation of the orig\u00adinal program. A v-function .rst obtains the reaching de.nition and then (recursively) \nreplaces all array and variable references on the right-hand side of the reaching de.nition with calls \nto appropriate v-functions. A v-function for variable v (or array access a[idx])at execution point p \nunder input i, looks as follows. 1. Obtain the most recent execution point p' where v (respectively, \na[idx]) was de.ned prior to p under input i. 1 If the input program violates the boundedness assumption, \nthe algorithm described in this section will still produce a correct recursive representation of the \nslice, but the recursion will be unbounded and will depend on the inputs. When this program is fed to \nthe SKETCH synthesizer, the synthesizer will attempt to inline the recursive calls an increasing number \nof times, to no avail; after a few tries, it will reach a prede.ned threshold for function inlining, \nand will inform the user that the sketch can not be resolved. Crucially, though, a violation of the assumption \ncan not lead to a buggy implementation. 2. Extract the static program statement s executed at p', and \nthe right-hand side expression e in s.  3. Return a valuation of a transformed expression F (e)where \n ' (a) each variable sub-expression v is replaced with v _fn(p,i); (b) each array access sub-expression \na [e'] is replaced with  '' a _fn(F (e),p,i). To illustrate the process, consider the following example. \nThe example is acyclic so that the reader need not be concerned with execution point representation for \nnow. int[N] f(int[N] in, int a) { s1: int[N] out = 0; s2: int[N] A = in; s3: if (in[3] > in[4]) { s4: \nout[3] = A[3]; s5: A[a] = in[5]; } s6: if (A[5] > 0) s7: out[a] = A[out[a]]; return out; } The v-function \nof out for this example needs to handle three as\u00adsignments to out: out_fn(idx, p, i)) { p = RD((out,idx), \np, i); switch (P_s(p )) { // extract the statement at p case s1: return 0; case s4: return A_fn(3, p \n, i); case s7: return A_fn(out_fn(a, p , i), p , i); } } It remains to show how the function RD computes \nthe concrete reaching de.nitions. First, we need to de.ne the execution point p . P . As mentioned in \npassing above, an execution point p is a pair (s, t),where s is a (static instance of a) program statement \nand t is a point from the iteration space T of the program. The iteration point t is de.ned as a valuation \nof loop induction variables that are in scope at the statement s (these are exactly the induction variables \n''' of loops that enclose s). When p =(s,t),wede.ne P_s(p)=s ' and P_t(p)= t. In the following, we use \nT_map(t, j ,n) to denote binding of an induction variable j to some value n in iteration point t,and \nT_get(t, j ) to extract the currently bound value for j. Similarly, I_get(i, x ) extracts the value associated \nwith (non-induction) variablex at input state i. The trace of a program execution is a sequence of execution \npoints. We de.ne a total order <P on P such that p1 <P p2 iff p1 executed before p2.The execution order \np1 <P p2 is deter\u00admined by the lexicographic order of the iteration points P_t(p1) and P_t(p2); if there \nis a tie, then p1 and p2 must be in the same loop iteration and their execution order is determined by \ntheir po\u00adsition in the program. Internally, we represent the execution point such that the <P -test can \nbe performed as a single lexicographic test. We de.ne two execution point constants: Pb is the beginning \nof the execution and Pe is the end of the execution. As statement guarded by conditionals may not execute \nin ev\u00adery iteration, the execution order <P alone is insuf.cient for de\u00adtermining the most recent de.nition. \nTo re.ect control conditions under which the statement executes, we de.ne the predicate q(p, i), which \nholds iff the statement P_s(p) executes at iteration point P_t(p)under the input i. Formally speaking, \nq(p, i)is the disjunc\u00adtion of the path constraints for all paths that reach the execution point q(p, \ni). Programs in our domain have structured control .ow and loop bounds that are invariant with respect \nto their loop s in\u00adduction variable. Therefore, the predicate q(p, i) can be constructed syntactically \nas a conjunction of all the conditionals (including loop conditions) enclosing the statement P_s(p). \nFor example, consider statement s4 in the code below. Let p =(s4,t) be an execution point associated \nwith s4 for some iteration point t. We form the predicate q(p, i) for this execution point under some \ninput state i: the constraint corresponding to the if statement in s3 is A_fn(T_get(t, j ),p,i) > 0; \nthe constraint corresponding to the loop statement in s0 and s1 is T_get(t, j ) = 0 .T_get(t, j ) < I_get(i, \nN ). double[N] f(double[N] in) { int [N] A, out; s0: for (int j=0; s1: j<N; ++j) { s2: A[j] = in[j]; \ns3: if (A[j] > 0) s4: out[j] = in[j]; else s5: out[j] = -in[j]; s6: out[j] = sqrt(out[j]); } } We are \nnow ready to describe RD, the procedure for computing reaching de.nitions, for this case of an array \naccess. Given a pro\u00adgram location v[idx], an execution point p, and input i, the proce\u00addure considers \nall execution points p ' that precede p, execute under the input i, and assign into location v[e] for \nsome index expression e such that the value of e at execution point p ' equals idx. Among all such execution \npoints, it selects the most recent one; if none meets all criteria, there is no reaching de.nition, and \nRD returns Pb. RD((v,idx), p, i) { '' ' return max({Pb }.{p | p<P p . q(p,i) . P_s(p ' )=v[e]=e . e_fn(p \n' ,i)=idx}); } Our compiler uses algebraic reasoning to simplify procedure RD. The symbolic simpli.er \nreasons with equalities, inequalities, and logical connectives. The simpli.cation procedure relies on \nthe fact that when we have an assignment of the form x[g(j)] = e, the constraint g(j) = idx often suf.ces \nto fully de.ne the iter\u00adation space point in terms of idx,byinverting g. It then remains only to test \nwhether the values thus derived satisfy the remaining constraints for qualifying execution points. Also, \n.nding the most recent point of assignment is done in a staged manner, by .rst .nd\u00ading the most recent \npoint corresponding to each assigning statement and then picking the most recent among them. In the above \nexample, we can .nd the last program point prior to point p where out[idx] has been updated by the particular \nstatement s4 (if such a point exists), as follows: p = max({(s4,t) | (s4,t) <P p . (T_get(t, j )=0 . \nT_get(t, j )<I_get(i, N ) . A_fn(T_get(t, j ), (s3,t),i)> 0) . T_get(t, j )=idx}); Note that the constraint \nT_get(t, j ) = idx fully de.nes the value of j to be equal to idx, so the statement above can be replaced \nwith a couple of simple assignments. t = T_map(new T, j ,idx); p = (s7,t); int out_fn(int idx,Pp,Ii) \n{ T t = T_map(new T, j , idx); Pp4= new P(s4,t); if (! (p4 < p &#38;&#38; idx >= 0 &#38;&#38; idx < I_get(i, \nN ) &#38;&#38; A_fn(idx, new P(s3,t), i) > 0)) p4 = Pb; Pp5= new P(s5,t); if (! (p5 < p &#38;&#38; idx \n>= 0 &#38;&#38; idx < I_get(i, N ) &#38;&#38; ! A_fn(idx, new P(s3,t), i) > 0)) p5 = Pb; Pp6= new P(s6,t); \nif (! (p6 < p &#38;&#38; idx >= 0 &#38;&#38; idx < I_get(i, N ))) p6 = Pb; Pp =(p4 <p5? (p5<p6 ?p6:p5) \n: (p4 < p6 ? p6 : p4));  switch (P_s(p )) { case s4: return I_get(i, in , T_get(P_t(p ), j )); case \ns5: return -I_get(i, in , T_get(P_t(p ), j )); case s6: return sqrt(out_fn(T_get(P_t(p ), j ), p , i)); \n} } Figure 3. v-function for array out if (! (p < p &#38;&#38; idx >= 0 &#38;&#38; idx < I_get(i, N ) \n&#38;&#38; A_fn(idx, (s3,t), i) > 0)) p = Pb; To complete our example, we .nd statement-speci.c most \nrecent points for each assigning statement in a similar manner, and pick the most recent among these \npoints. The .nal v-function for out is showninFigure3.   6. Evaluation In this section, we present \nan empirical evaluation of our system using several kernels from the MultiGrid method as case studies. \nFrom the case studies, we were able to validate three basic claims. Scalability. We prove that the system \nscales to complex real-world implementations of important kernels. For example, we were able to synthesize \nin a matter of minutes an implementation for a kernel that involved 14 different loops from a sketch \nthat had 44 different holes. Usability. The case studies also allow us to describe a typical use scenario \nfor a sketching system. In particular, we describe how we were able to explore different implementation \nstrategies, discarding those that don t work and re.ning those that do, without the risk of introducing \nbugs. Performance of generated code. We show that creating these complex implementations is worth the \neffort. In particular, one of the implementations we sketched was over 8 times faster than the original \nreference implementation on a 1.3 GHz Itanium-2, even though they were compiled and optimized using the \nIntel Fortran compiler version 9.1, arguably one of the best com\u00adpilers commercially available on the \nItanium architecture. In other words, the sketch expressed optimization ideas which the compiler was \nunable to discover on its own. The results of the performance evaluation of the synthesizer are summarized \nin Table 1. The table lists all the benchmarks that appear in the paper together with their solution \ntime, and a Table 1. Solution time for the different benchmarks in the paper. Table columns specify: \nthe number of loops present in the .nal im\u00adplementation ( rec stands for recursive); the number of holes \nthe synthesizer .lled in; the number of bits used to represent integers; the number of Boolean and arithmetic \noperations in the reduced problem after some simpli.cation; the time (in seconds) spent in SAT solver \nqueries; and the total time (in seconds) required to re\u00adsolve the benchmark. Loop Holes i-bits Size SAT \nTotal timeSkew 3 12 expr 5 10469 137 269 cacheObv rec 2 expr 5 5313 141 165 interp1 3 111 3 1930 422 \n424 interp2 7 74 3 1954 85 88 rb3d1 6 36 5 2471 97 108 rb3d1Odd 14 43 3 27045 138 214 rb3d2 7 30 3 18994 \n82 145 rb2d1 4 16 6 1809 81 88 rb2d2 4 22 6 3868 72 78 few statistics regarding their complexity. The \nstatistics include the loops in the .nal implementation, the number of holes .lled by the synthesizer, \nand the number of integer and boolean operations in the spec and the sketch after reduction and some \nalgebraic simpli.cation. This last quantity is simply to give a measure of how complex the reduced problems \nare. The table also shows the solution time for each benchmark on an Intel Pentium M 1.6 GHz laptop, \nand what fraction of the time is spent solving SAT problems. It should be pointed out that SKETCH doesn \nt invoke a SAT solver directly, but instead uses the circuit equivalence checking engine from ABC [14], \nwhich has proven to be much more ef.cient. 6.1 Sketching for MultiGrid The MultiGrid algorithm is used \nfor solving partial differential equations for a wide range of domains, including .uid dynamics and solid \nmechanics. It is composed of three main kernels: relax, interpolate, and restrict [3]. Each application \nof the relaxation rou\u00adtine produces a closer approximation to the solution, but with a very .ne grid \nthe low frequency components of the error in the approxi\u00admation take too long to die out. To address \nthis problem, MultiGrid computes corrections to the solution by creating a coarser problem (restrict), \nsolving it recursively, and then mapping the correction back to a .ner grid (interpolate). We have sketched \nimplementa\u00adtions of relaxation and interpolation kernels in 3-D; the restrict ker\u00adnel is quite similar \nto interpolate. We sketched several implementation tricks from the literature and from hand optimized \nimplementations of these kernels. In a couple of cases, it took less than half an hour to write and synthesize \nimplementations that we estimate would have taken half a day if written by hand. Additionally, some of \nour sketched implementations were several times faster than the clean reference implementations, even \nafter the latter had been optimized by the Intel Fortran compiler. Relaxation. The relaxation phase of \nMultiGrid starts with an ap\u00adproximation to the solution of the problem and uses it to compute a closer \napproximation to the solution. For our case study, we imple\u00admented a Red-Black Gauss-Seidel relaxation \nscheme for both a 2-D grid and a 3-D grid following more or less the same implementation strategies. \nThe speci.cation for the 3-D benchmark is shown below. The algorithm assigns a color to each cell on \nthe grid in a check\u00adered pattern, and then applies a six point stencil on the red cells, followed by \nanother (same) stencil on the black cells. This widely used relaxation scheme has well known implementation \nstrategies to optimize it for different architectures [8]. // red for (int i = 1; i < N-1; ++i) for (int \nj = 1; j < N-1; ++j) for (int k = 1; k < N-1; ++k) if (i%2 == 0 ^ j%2 == 0 ^k%2 ==0) out[i,j,k] = F(i,j,k, \nin); // black for (int i = 1; i < N-1;++i) for (int j = 1; j < N-1; ++j) for (int k = 1; k < N-1; ++k) \nif (! (i%2 == 0 ^ j%2 == 0^ k%2 == 0)) out[i,j] = F(i,j,k, out); Here, F(i,j,k, prev) expands to f[i,j,k] \n+ v0*in[i,j,k] + v1*prev[i-1,j,k] +v2*prev[i+1,j,k] + v3*prev[i,j-1,k] +v4*prev[i,j+1,k] + v5*prev[i,j,k+1] \n+v6*prev[i,j,k-1]; The above speci.cation is written in the simplest possible way, using the xor expression \ni%2 ==0 ^ j%2 == 0 ^k%2 ==0 to decide the color of each cell. These types of conditions tend to confuse \ntraditional dependence analysis, so even a state-of-the-art compiler like the Intel compiler is unable \nto optimize the kernel fully. In order to produce a better implementation, we used two im\u00adplementation \nstrategies from [8]. In this paper, Douglas et al. pro\u00advide only high-level descriptions of their optimization \nstrategies (no pseudo-code), but those low-level details omitted in the paper are exactly what SKETCH \ncan synthesize. The .rst implementation we created is quite simple; it just eliminates the conditionals \nby computing the output in blocks of eight elements at a time: four red and four black. The sketch for \nthe case where N is even is very simple; it has two loop-nests with unspeci.ed bounds, each with four \nassignments of the form out[2*i-??,2*j-??,2*k-??]= F(2*i-??,2*j-??,2*k-??, in); The sketch describes \nthe high-level idea that we compute .rst all the red cells four at a time, and then all the black cells, \nalso four at a time. The sketches rb2d1 and rb3d1 from Table 1 correspond to the 2-D and 3-D instances \nof this sketch respectively. One can see that both sketches resolved quite fast despite having a large \nnumber of holes. Moreover, the resulting implementation is about 45% faster for the 3-D case and 70% \nfaster for the 2-D case. The implementation for the case where N is odd is considerably more complicated \nbecause one must cover a lot of corner cases, particularly in 3-D, where the .nal implementation is composed \nof 14 different loops. However, with the support of sketching, it is easy to construct the odd case from \nthe even case. To do this, we took the 3-D implementation for the even case produced by the previous \nsketch, and simply sketched the corner cases on top of it. Using the implementation generated from the \neven case as a starting point allowed the sketch to scale; a sketch for the odd case that left everything \nunspeci.ed proved to be intractable for the compiler. Fortunately, we did not have to start from scratch. \nWe were able to exploit the fact that we already had a solution for the even case to make the odd case \nmore tractable. The sketch for the red cells for the 2-D odd case is shown below. Statements 1 and 2 \ncame from the implementation of the even case, and on top of it, we added a corner case for the last \ncell in each row (3), and the last row (4), Since we are not sure if the last cell in the last row (5) \nneeds to be treated separately, we ask the solver to decide. for (int i= ??; i < N/2-??; ++i){ for (int \nj= ??; j < N/2-??; ++j){ out[2*i-1,2*j-1] = F(2*i-1,2*j-1, in); //1 out[2*i,2*j] = F(2*i,2*j, in); //2 \n} out[2*i-??,N-??] = F(2*i-??,N-??, in); //3 } for (int j= ??; j < N/2-??; ++j){ out[N-??,2*j-??] = \nF(N-??,2*j-??, in); //4 } if (??) out[N-??,N-??] = F(N-??,N-??,in); //5 Our second implementation for \nthis benchmark uses another strategy mentioned in [8], namely computing the red and black cells together \nin a single pass through the array. In this case, careful attention is required in order to preserve \nthe dependencies. We .rst implemented the trick in 2-D by creating a loop that updates both red and black \ncells as shown below, and then two more loops to handle the corner cases. for (int i= ??; i < N/2-??;++i){ \nfor (int j= ??; j < N/2-??; ++j) { // red out[2*i-??,2*j-??] = F(2*i-??,2*j-??,in); out[2*i-??,2*j-??] \n= F(2*i-??,2*j-??,in); //black out[2*i-??,2*j-??] = F(2*i-??,2*j-??, out); out[2*i-??,2*j-??] = F(2*i-??,2*j-??, \nout); } } From the sketch, the synthesizer was able to discover that it had to compute the black cells \nwith an offset with respect to the red cells in order to preserve dependencies. Note that neither the \nloop bounds nor the array access offsets are trivial; getting them right would have been quite challenging \nfor the programmer. for (int i = 2; i < N/2; ++i){ for (int j = 1; j < N/2; ++j) { // red out[2*i-1,2*j-1] \n= F(2*i-1,2*j-1, in); out[2*i,2*j] = F(2*i,2*j, in); //black out[2*i-3,2*j-0] = F(2*i-3,2*j, out); out[2*i-2,2*j-1] \n= F(2*i-2,2*j-1, out); } } As shown in Table 2, this optimization delivered a 60% perfor\u00admance improvement \ncompared to the previous optimization, which was already 70% faster than the spec. This shows that the \nopti\u00admizations we are able to sketch go beyond what the Intel compiler is able to do on its own given \na straightforward speci.cation. We tried to implement the same trick in 3-D. In this case, our sketch \nproduced an implementation that computed the black cells for the plane 2i after computing the red cells \nin the plane 2i +2. Unlike the 2-D case, however, this produced a performance degradation, probably due \nto the fact that the planes are too big to .t in the cache, so accessing too many of them at a time simply \nconfuses the prefetcher with no bene.t to performance. Interpolation. The interpolation routine maps \nthe values in a coarse grid to a .ner grid of size 2N \u00d7 2N \u00d7 2N, as illustrated in Figure 4. Points in \nthe .ne grid that correspond to points in the coarse one are copied, while the other points in the .ne \ngrid are computed by averaging the values of their neighbors in the coarse grid. As illustrated in Figure \n4, this leads to four different cases, depending on whether we average 1, 2, 4 or 8 points. The following \n1  k j i   3 1 B 0 A 1 0 a  (a) (b) Figure 4. (a) Stencil for interpolation distinguishes \nfour different cases. Either the new point matches a point in the coarse grid (1), is in an edge in the \nold grid (2), in a face (3), or in the center of a cube formed by consecutive points in the old grid \n(4). (b) The optimized version will precompute the sums a, b and c. code shows a fragment of the speci.cation, \ndescribing a few of the cases. for (int i=0; i<2*N-2; ++i) for (int j=0; j<2*N-2; ++j) for (int k=0; \nk<2*N-2; ++k) { if (i%2 == 0 &#38;&#38; j%2 == 0 &#38;&#38; k%2 == 0) // Case 1 out[i,j,k] = in[i/2,j/2,k/2]; \nif (i%2 == 1 &#38;&#38; j%2 == 0 &#38;&#38; k%2 == 0) // Case 2 out[i,j,k] =  0.5 (in[i/2,j/2,k/2] + \nin[i/2+1,j/2,k/2]); * ... if (i%2 == 1 &#38;&#38; j%2 == 1 &#38;&#38; k%2 == 0) // Case 3 out[i,j,k] \n= 0.25 (in[i/2,j/2,k/2] + in[i/2+1,j/2+1,k/2]* + in[i/2,j/2+1,k/2] + in[i/2+1,j/2,k/2]); ... } As in \nthe previous sketch, we started by blocking the computa\u00adtion to eliminate all the conditionals in the \nspeci.cation. For each point in the coarse grid, there is a 2 \u00d7 2 \u00d7 2 block in the .ne grid which constitutes \nthe smallest repeating pattern. Because the output grid is of size (2N)3, odd grid sizes are not a problem. \nThe sketch was very easy to write because we left every single array offset unspeci.ed, as well as the \nbounds of all loops. We only speci.ed that on each iteration of the innermost loop, there were 8 assignments \nto entries of out, 1 for case 1, 3 for case 2, 3 for case 3, and 1 for case 4. The individual cases are \nshown below. out[2*i+??,2*j+??,2*k+??] = in[i+??,j+??,k+??]; out[2*i+??,2*j+??,2*k+??]= 0.5 (in[i+??,j+??,k+??]+in[i+??,j+??,k+??]); \n* out[2*i+??,2*j+??,2*k+??]=  0.25 (in[i+??,j+??,k+??] + in[i+??,j+??,k+??]+ * in[i+??,j+??,k+??] + \nin[i+??,j+??,k+??]); out[2*i+??,2*j+??,2*k+??]= 0.125 (in[i+??,j+??,k+??] + in[i+??,j+??,k+??]+ * in[i+??,j+??,k+??] \n+ in[i+??,j+??,k+??]+ in[i+??,j+??,k+??] + in[i+??,j+??,k+??]+ in[i+??,j+??,k+??] + in[i+??,j+??,k+??]); \nAs shown in Table 2, this simple transformation allowed the imple\u00admentation to run 8 times faster than \nthe spec. The second sketch we did for this benchmark describes an optimization which is used by the \nHPF implementation of this kernel in the NAS benchmark suite [2]. The key insight behind this optimization \nis that a lot of the sums are computed more than once, so we can reuse some of them when computing different \nblocks. Figure 4(b) shows two consecutive blocks (A and B). The pairs a, b and c represent a partial \nsum of two points from the original grid. We can see that the partial sum a can be used to compute 6 \ndifferent points: A5, A7, B4, B5, B6, B7. Similarly, the partial sums b and c can be reused in computing \nmost of the other points. The implementation uses this insight by pre-computing the partial sums a, a+b \nand c; these are stored in temporary arrays for each value of (i, j), to make the rest of the computation \neasier to vectorize. We wrote the sketch for this implementation trick in less than one hour. As before, \nthe sketch leaves unspeci.ed every single array offset and every single loop iteration bound. Below, \none can see the loop that pre-computes the sub-expressions: for (int i= ??;i<N-??; ++i) { float ta = \nin[i+??,j+??,k+??]+in[i+??,j+??,k+??]; float tb = in[i+??,j+??,k+??]+in[i+??,j+??,k+??]; float tc = in[i+??,j+??,k+??]+in[i+??,j+??,k+??]; \naplusb[i] = ta + tb; a[i] = ta; c[i] = tc; } The code for each of the expressions was sketched following \nFig\u00adure 4(b). In particular, the picture shows that the three points corre\u00adsponding to case 2 are computed \none from a, one from c, and one by adding the two vertices labeled 0. Similarly, for points corre\u00adsponding \nto case 3, one is computed from two entries from c, one from two entries from a, and one is just a+b. \nAnd .nally, case 4 is the sum of two consecutive a+b. So the basic idea is clear from the picture, and \ncan be sketched directly with the statements shown below. Nonetheless, the details of which offsets to \nuse are not clear from the picture, so those are left unspeci.ed for the solver to com\u00adplete. The sketch \nresolves in less than three minutes. output[k*2+??,j*2+??,i*2+??] = in[k+??,j+??,i+??]; output[k*2+??,j*2+??,i*2+??]= \n 0.5 (in[k+??,j+??,i+??] + in[k+??,j+??,i+??]); * output[k*2+??,j*2+??,i*2+??] = 0.5 a[k+??]; * output[k*2+??,j*2+??,i*2+??] \n= 0.5 c[k+??]; * output[k*2+??,j*2+??,i*2+??]=  0.25 (c[k+??] + c[k+??]); * output[k*2+??,j*2+??,i*2+??]= \n 0.25 (a[k+??] + a[k+??]); * output[k*2+??,j*2+??,i*2+??] = 0.25 aplusb[k+??]; * output[k*2+??,j*2+??,i*2+??]= \n 0.125 (aplusb[k+??] + aplusb[k+??]); * On the Itanium-2, this optimization had a very minimal im\u00adpact \non the performance compared with simple blocking. However, what is important is the fact that we were \nable to sketch the imple\u00admentation trick, and get a complete implementation for it, all with\u00adout the \nrisk of introducing bugs. In fact, in the process of sketch\u00ading these optimizations, we tried many other \nvariations on the ba\u00adsic tricks. Some ideas were rejected by the compiler while others caused performance \ndegradations. Nevertheless, we were able to try them easily and without introducing bugs.  7. Related \nWork The algorithms described in this paper are implemented as an ex\u00adtension to the SKETCH system, and \nrely heavily on the combinato\u00adrial synthesis engine described in [22]. The original SKETCH com\u00adpiler \nhandled unbounded programs by arti.cially bounding the size of their input. This is completely unsuitable \nfor stencils, because the resulting formula would be proportional (by a very large factor) to the maximum \nsize of the input grids, leading to intractably large problems: even the simplest sketch examined in \nthis paper (rb2d1 from Section 6) causes the original SKETCH compiler to run out of memory when asked \nto consider grids of size N < 16.For thesame size problem (3 bit integers), the new algorithm resolves \nthe same sketch in 7 seconds. The reduction technique presented in this paper extracts a bounded representation \nof stencils, making the problem tractable for the combinatorial synthesizer. Thus it extends the domain \nof the SKETCH system by allowing it to reason about unbounded pro\u00adgrams. Additional techniques like those \npresented in [5] can be applied on top of the bounded representation in order to prove equivalence very \nef.ciently. Our reduction technique is based on exploiting the high-level structure of a program, together \nwith abstraction to make a com\u00adbinatorial analysis more tractable. These principles are well-rooted in \nthe research of model checking: for example, uninterpreted func\u00adtions and their representation using \ninput variables is widely used in verifying hardware and (more recently) software [4, 6], as is the idea \nof breaking the problem into cases that we apply to bounding the output [13]. 7.1 Alternative approaches \nWe .nd our approach to be complementary to more traditional forms of compiler optimization. On the one \nhand, having a very powerful optimizer available allows sketching-based efforts to fo\u00adcus only on higher-level \noptimization. On the other hand, sketches can be used to express implementations that are beyond the \ncapa\u00adbilities of traditional compiler optimization. Optimizers relying on dependence analysis such as \n[16] must be able to reason stati\u00adcally about all array reads and writes, so every array index expres\u00adsion \nmust have a clean algebraic form to ensure that no dependence will be violated after a transformation. \nAdditionally, dependence analysis must deal very conservatively with index expressions and conditionals \nthat depend on inputs. In contrast to dependence analysis, our reduction procedure only needs to reason \nabout array index expressions on the left\u00adhand side of an assignment, since these are used to symbolically \nderive the expression for the latest assignment to an array (see Sec\u00adtion 5). Therefore, complex conditionals, \nand even input dependent array accesses and looping structures, do not pose further complica\u00adtion; the \nreduced problem is delegated to the combinatorial engine, which analyzes it under all possible inputs. \nFinally, search-based optimization for performance-critical ker\u00adnels has gained increasing popularity \nin the high-performance com\u00admunity. Such approaches explore and test candidate implementa\u00adtions from \na suitably restricted implementation space, either by executing them on the target machine or by detailed \nsimulation. For example, FFTW [9] uses a planner to try many different ex\u00adecution plans for an FFT at \nrun-time, and pick the best one. SPI-RAL [17] generates high-performance DSP kernels by searching the \nspace of possible implementations, taking advantage of the structure of the algorithm and the implementation \nspace to speed up the search. Demmel et al. [7] also use search-based methods to generate dense and sparse \nlinear algebra kernels. These systems use hand-crafted code generators to produce candidate implemen\u00adtations, \nwhich makes building them a dif.cult and error-prone task. This in turn restricts the space of implementations \nthat these sys\u00adtems can explore. Sketching may bene.t from adopting search-based tuning: con\u00adceivably, \na sketch synthesizer can generate a set of correct comple\u00adtions of the sketch, and then search for the \nmost ef.cient one. Relax (Red-Black) 2-D N spec rb2d1 rb2d2 Relax 3-D N spec rb3d1 rb3d2 Interpolate \nN spec interp1 interp2 1000 17 10 6 100 15 10 9 75 141 18 18 2000 66 38 24 200 115 77 109 100 338 44 \n43 3000 153 84 54 300 385 236 634 150 1146 149 147 4000 264 148 97 400 923 585 1650 175 1935 238 232 \n500 1787 1174 2428 200 2822 339 335 Table 2. Running times of benchmarks implementations. The size of \nthe grid for the Red-Black code is N2 and N3 for 2-D and 3-D respectively. The size of the .ne grid for \nInterpolate is (2N)3. Time is in milliseconds.  8. Conclusion The paper describes a sketching synthesizer \nfor stencil computa\u00adtions. It is the .rst system for sketching programs that go beyond the .nite programs \nof the original SKETCH language and synthe\u00adsizer [21]. The synthesis is enabled with an abstraction that \nmakes the stencil synthesis problem .nite without sacri.cing precision, which allows reduction onto the \n.nite synthesizer. The resulting stencil synthesizer is surprisingly scalable. Acknowledgment We are \ngrateful to the anonymous referees for their helpful com\u00adments. This work is supported in part by the \nNational Science Foun\u00addation with grants CCF-0613997, CCF-0085949, CCR-0105721, CCR-0243657, CNS-0225610, \nCCR-0326577, and CNS-0524815, the University of California MICRO program, the MARCO Gi\u00adgascale Systems \nResearch Center, an Okawa Research Grant, an IBM Graduate Fellowship, and a Hellman Family Faculty Fund \nAward. This work has also been supported in part by the Defense Advanced Research Projects Agency (DARPA) \nunder contract No. NBCHC020056. The views expressed herein are not necessarily those of DARPA.  References \n[1] W. Ackermann. Solvable cases of the decision problem. Studies in Logic and the Foundations. of Mathematics. \nNorth . UHolland 1954. [2] D. H. Bailey, E. Barszcz, J. T. Barton, D. S. Browning, R. L. Carter, D. Dagum, \nR. A. Fatoohi, P. O. Frederickson, T. A. Lasinski, R. S. Schreiber, H. D. Simon, V. Venkatakrishnan, \nand S. K. Weeratunga. The nas parallel benchmarks. The International Journal of Supercomputer Applications, \n5(3):63 73, Fall 1991. [3] W. L. Briggs, V. E. Henson, and S. F. McCormick. A Multigrid Tutorial. SIAM, \n2000. [4] R. E. Bryant, S. German, and M. N. Velev. Processor veri.cation using ef.cient reductions of \nthe logic of uninterpreted functions to propositional logic. ACM Transactions on Computational Logic, \n2(1):1 41, January 2001. [5] R. E. Bryant, D. Kroening, J. Ouaknine, S. A. Seshia, O. Strichman, and \nB. Brady. Deciding bit-vector arithmetic with abstraction. In Proc. TACAS 2007, March 2007. [6] D. Currie, \nX. Feng, M. Fujita, A. J. Hu, M. Kwan, and S. Rajan. Embedded software veri.cation using symbolic execution \nand uninterpreted functions. Int. J. Parallel Program., 34(1):61 91, 2006. [7] J. Demmel, J. Dongarra, \nV. Eijkhout, E. Fuentes, A. Petitet, R. Vuduc, C. Whaley, and K. Yelick. Self adapting linear algebra \nalgorithms and software. Proceedings of the IEEE, 93(2), 2005. [8] C. C. Douglas, J. Hu, M. Kowarschik, \nU. R\u00fcde, and C. Weiss. Cache optimization for structured and unstructured grid multigrid. Elect. Trans. \nNumer. Anal., 10:21 40, 2000. [9] M. Frigo and S. Johnson. Fftw: An adaptive software architecture for \nthe fft. In ICASSP conference proceedings, volume 3, pages 1381 1384, 1998. [10] M. Frigo and V. Strumpen. \nThe memory behavior of cache oblivious stencil computations. The Journal of Supercomputing, 39(2):93 \n112, 2007. [11] S. Kamil, K. Datta, S. Williams, L. Oliker, J. Shalf, and K. Yelick. Implicit and explicit \noptimizations for stencil computations. In MSPC 06: Proceedings of the 2006 workshop on Memory system \nperformance and correctness, pages 51 60, New York, NY, USA, 2006. ACM Press. [12] S. Kamil, P. Husbands, \nL. Oliker, J. Shalf, and K. A. Yelick. Impact of modern memory subsystems on cache optimizations for \nstencil computations. In B. Calder and B. G. Zorn, editors, Memory System Performance, pages 36 43. ACM, \n2005. [13] K. McMillan. Veri.cation of in.nite state systems by compositional model checking. In Correct \nHardware Design and Veri.cation Meth\u00adods: 10th IFIP WG 10.5 Advanced Research Working Conference, CHARME \n99, Bad Herrenalb, Germany, September 1999., pages 219 237, 1999. [14] A. Mishchenko, S. Chatterjee, \nand R. Brayton. Dag-aware AIG rewriting: A fresh look at combinational logic synthesis. In DAC 06: Proceedings \nof the 43rd annual conference on Design automation, pages 532 535, New York, NY, USA, 2006. ACM Press. \n[15] A. Pnueli, O. Shtrichman, and M. Siegel. The code validation tool (cvt). International Journal on \nSoftware Tools for Technology Transfer (STTT), 2, December 1998. [16] W. Pugh. The omega test: a fast \nand practical integer programming algorithm for dependence analysis. In Supercomputing 91: Proceedings \nof the 1991 ACM/IEEE conference on Supercomputing, pages 4 13, New York, NY, USA, 1991. ACM Press. [17] \nM. P\u00fcschel, B. Singer, J. Xiong, J. Moura, J. Johnson, D. Padua, M. Veloso, and R. Johnson. Spiral: A \ngenerator for platform\u00adadapted libraries of signal processing algorithms. Journal of High Performance \nComputing and Applications, accepted for publication. [18] G. Roth, J. Mellor-Crummey, K. Kennedy, and \nR. G. Brickner. Com\u00adpiling stencils in high performance fortran. In Supercomputing 97: Proceedings of \nthe 1997 ACM/IEEE conference on Supercomputing (CDROM), pages 1 20, New York, NY, USA, 1997. ACM Press. \n[19] S. Sellappa and S. Chatterjee. Cache-ef.cient multigrid algorithms. Int. J. High Perform. Comput. \nAppl., 18(1):115 133, 2004. [20] L. Snyder. Programming Guide to ZPL. MIT Press, Cambridge, MA, 1999. \n[21] A. Solar-Lezama, L. Tancau, R. Bodik, V. Saraswat, and S. Seshia. Combinatorial sketching for .nite \nprograms. In 12th International Conference on Architectural Support for Programming Languages and Operating \nSystems (ASPLOS 2006), pages 404 415, New York, NY, USA, 2006. ACM Press. [22] A. Solar-Lezama, L. Tancau, \nR. Bodik, V. Saraswat, and S. Seshia. Combinatorial sketching for .nite programs. In ASPLOS 06,San Jose, \nCA, USA, 2006. ACM Press. [23] D. Wonnacott. Achieving scalable locality with time skewing. International \nJournal of Parallel Programming, 30(3):1 221, 2002. \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Performance of stencil computations can be significantly improved through smart implementations that improve memory locality, computation reuse, or parallelize the computation. Unfortunately, efficient implementations are hard to obtain because they often involve non-traditional transformations, which means that they cannot be produced by optimizing the reference stencil with a compiler. In fact, many stencils are produced by code generators that were tediously handcrafted.</p> <p>In this paper, we show how stencil implementations can be produced with sketching. Sketching is a software synthesis approach where the programmer develops a partial implementation--a sketch--and a separate specification of the desired functionality given by a reference (unoptimized) stencil. The synthesizer then completes the sketch to behave like the specification, filling in code fragments that are difficult to develop manually.</p> <p>Existing sketching systems work only for small finite programs, <i>i.e.,</i>, programs that can be represented as small Boolean circuits. In this paper, we develop a sketching synthesizer that works for stencil computations, a large class of programs that, unlike circuits, have unbounded inputs and outputs, as well as an unbounded number of computations. The key contribution is a reduction algorithm that turns a stencil into a circuit, allowing us to synthesize stencils using an existing sketching synthesizer.</p>", "authors": [{"name": "Armando Solar-Lezama", "author_profile_id": "81100173160", "affiliation": "UC Berkeley, Berkeley, CA", "person_id": "P728828", "email_address": "", "orcid_id": ""}, {"name": "Gilad Arnold", "author_profile_id": "81331488163", "affiliation": "UC Berkeley, Berkeley, CA", "person_id": "P871673", "email_address": "", "orcid_id": ""}, {"name": "Liviu Tancau", "author_profile_id": "81319502800", "affiliation": "UC Berkeley, Berkeley, CA", "person_id": "PP33029370", "email_address": "", "orcid_id": ""}, {"name": "Rastislav Bodik", "author_profile_id": "81100033082", "affiliation": "UC Berkeley, Berkeley, CA", "person_id": "P338839", "email_address": "", "orcid_id": ""}, {"name": "Vijay Saraswat", "author_profile_id": "81100152268", "affiliation": "IBM TJ Watson Research Center, Hawthorne, NY", "person_id": "PP14063135", "email_address": "", "orcid_id": ""}, {"name": "Sanjit Seshia", "author_profile_id": "81100358245", "affiliation": "UC Berkeley, Berkeley, CA", "person_id": "PP33034207", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250754", "year": "2007", "article_id": "1250754", "conference": "PLDI", "title": "Sketching stencils", "url": "http://dl.acm.org/citation.cfm?id=1250754"}