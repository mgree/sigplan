{"article_publication_date": "06-10-2007", "fulltext": "\n Mace: Language Support for Building Distributed Systems Charles Killian JamesW. Anderson Ryan Braud \nRanjit Jhala AminVahdat University of California, San Diego {ckillian,jwanderson,rbraud,jhala,vahdat}@cs.ucsd.edu \nAbstract Building distributed systems is particularly dif.cult because of the asyn\u00adchronous, heterogeneous, \nandfailure-prone environment where these sys\u00adtems must run.Tools forbuilding distributed systems must \nstrikea compro\u00admise between reducing programmer effort and increasing system ef.ciency. WepresentMace \n,aC++ languageextension and source-to-source compiler that translatesa concisebutexpressive distributed \nsystem speci.cation into a C++ implementation. Mace overcomes the limitations of low-level lan\u00adguages \nby providing a uni.ed framework for networking and event han\u00addling,andthe limitationsofhigh-level languagesbyallowing \nprogrammers to write program componentsinacontrolledand structured mannerin C++. By imposing structure \nand restrictions on how applications can be written, Mace supports debugging at a higher level, including \nsupport for ef.cient model checking and causal-path debugging. Because Mace programs com\u00adpiletoC++, programmerscanuseexistingC++tools, \nincluding optimizers, pro.lers, and debuggers to analyze their systems. Categories and Subject Descriptors \nD.3.2[Language Classi.ca\u00adtions]: Specialized application languages General Terms Languages, Reliability, \nPerformance Keywords Mace, domain speci.c languages, model checking, de\u00adbugging, distributed systems, \nconcurrency, event driven program\u00adming 1. Introduction Designing and implementing robust and high-performance \ndis\u00adtributed applications remains a challenging, tedious, and error\u00adprone task. Currently, there are \nthreewaysof specifying distributed systems. First, formalisms such as I/O Automata [24] or the Pi-Calculus \n[26] can be used to model distributed algorithms as col\u00adlections of .nite-state automata (or processes), \none for each node of the system that interact by sending and receiving messages. Though these formalisms \nsuccinctly capture the essence of many distributed protocols and algorithms, theyabstractaway and ignore \nthe low-level implementation details essential to deploying robust, high-performance systems. Second, \nhigher-level programming lan\u00adguages such as Java, Python, and Ruby have eased some of the te\u00addium associated \nwithbuilding distributed systems. However, they often introduce performance overheads and do not signi.cantly \nsimplify the task of ensuring system correctness or identifying in\u00adevitable performance problems. Thus, \ndevelopers seeking ef.ciencyresort to the third option of assembling applications in an ad-hoc, bottom-up \nmanner. While the Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page.To copyotherwise, \nto republish, to post on servers or to redistribute to lists, requires prior speci.c permission and/or \na fee. PLDI 07 June 11 13, 2007, San Diego, California, USA. Copyright c &#38;#169; 2007ACM 978-1-59593-633-2/07/0006...$5.00 \n resulting systems maybefast and reliable, theysacri.ce structure, readability,andextensibility.Thelackof \nstructurein particularsig\u00adni.cantly limits the ability to apply automated tools, such as model checkers, \nto .nd subtle performance and correctness problems. Our goal is to determine whether programming language, \ncom\u00adpiler, and runtime support can combine the elegance of high-level speci.cationswiththe performanceandfault-toleranceoflow-level \nimplementations.Weseekto drasticallylowerthe barriertodevel\u00adoping, maintaining, and extending robust, \nhigh-performance dis\u00adtributed applications that are readable and amenable to automatic analysis for performance \nand correctness problems. The main dif.culty in building these systems arises from the distributed, concurrent, \nasynchronous, and failure-prone environ\u00adment where distributed systems run. System complexity requires \nthat applications be layered ontopoffast routing protocols, which are built on top of ef.cient messaging \nlayers. Concurrency and asynchronyimplythatevents simultaneouslytakeplaceat multiple nodes in unpredictable \norders. Messages may be delivered in ar\u00adbitrary orders, dropped or delayed nearly inde.nitely. Nodes \nmay at any time have multiple outstanding messages in-.ight to other nodes and multiple pending received \nmessages ready to be pro\u00adcessed. Further, an arbitrary subset of nodes or links may fail at anytime, \nleaving the system as a whole in a temporarily inconsis\u00adtent state. These properties make maintaining \nperformance and correct\u00adness dif.cult.Asingle high-level system requestmay require com\u00admunication with \nmanynodes spread across the Internet. Often,even seemingly correct distributed system implementations \nperform an order of magnitude more slowly than expected. Analyzing execu\u00adtions to .nd the source of such \nproblems frequently reduces to searching for a needle in a haystack: among (at least) millions of individual \nmessage transmissions, algorithmic decisions, and the large number of participating nodes, which network \nlink, computer, or low-level algorithm resulted in performance degradation? While each of these problems \nhas well-known solutions, the task of addressing them simultaneously proves to be quite chal\u00adlenging \nbecauseof their subtle interactions.Forexample, object\u00adoriented design is the canonical way to build \nsystems from sub\u00adsystems,but for distributed systems hiding internal state from other layers results \nin serious performance penalties and duplicate effort. Similarly, thereare standardwaysto detectand handlefailures,but \nthe code for doing so must be interspersed (usually repeatedly at multiple points) with the code for \nhandling common case opera\u00adtion, not only obfuscating the codebut also eliminating the high\u00adlevel structure \nrequired to use techniques like model checking [13] and performance debugging [2, 4, 8]. In this paper, \nwe present Mace, a new C++ language extension and source-to-source compiler forbuilding distributed systems \nin C++. Mace seamlessly combines objects, events, and aspects to si\u00admultaneously address the problems \nof layering, concurrency,fail\u00adures, and analysis. While these are well known Programming Lan\u00adguage ideas,thekeyadvancesofMace \naretwofold. First,weunify in one development environment the diverse elements required to build robust \nand high-performance distributed systems. Second, and more importantly, by de.ning a language extension \nto write distributed systems, we are able to restrict the ways that such sys\u00adtems can bebuilt.For our \ndomain, this restriction is both expres\u00adsive enough to permit the compilation of readable high-level \nde\u00adscriptions into implementations matching the performance of hand\u00adcoded implementations and structured \nenough to enable the use of automatic, ef.cient, and comprehensive static and dynamic analy\u00adsis to locate \nand understand behavioral anomalies in deployed sys\u00adtems. By using a structured yet expressive approach \ntailored to distributed systems, Mace provides manyconcrete bene.ts: Mace allows the programmer to focus \non describing each layer of the distributed system as a reactive state transition system, using events \nand transitions as the basis for system speci.ca\u00adtion. Thisexplicitly maintains structuregivenby high-level \nfor\u00admalisms while enabling high-performance implementations.  Mace uses the semantic information embedded \nin the system speci.cation to automatically generate much of the code needed forfailure detection and \nhandling, signi.cantly improving read\u00adability and reducing the complexity of maintaining internal ap\u00adplication \nconsistency.  Mace supports automatic pro.ling of individual causal paths the sequence of computation \nand communication among nodes in a distributed system corresponding to some higher level op\u00aderation, \ne.g., a lookup in a distributed hash table. Mace exports a simple language that allows developers to \nmatch their expec\u00adtations of both system structure and performance against actual system behavior, thereby \nisolating performance anomalies.  Mace s state transition model enables practical model check\u00ading of \ndistributed systems implementations to .nd both safety andlivenessbugs.Webuilta model checker, MaceMC,to \nsuc\u00adcessfully .nd subtle bugs in a variety of complex distributed systems implementations. Most of the \nbugs were quite insid\u00adious, present in mature code, and could not be found without exploiting the structure \npreserved by Mace.  Mace is fully operational, has been in development for four years, is publicly available \nfor download, and has been used by re\u00adsearchers at UCSD, HP Labs, MSR-Asia, and a handful of univer\u00adsitiesworldwidein \nsupportof theirown researchanddevelopment. Wehaveimplemented more than ten signi.cant distributed systems \nin Mace, mostof which were originally proposedbyothers. This set includes Distributed HashTables [30, \n32, 35], Application Layer Multicast [7, 15, 20], and network measurement services [9] ready to run over \nthe Internet. Along with a summary of our implemen\u00adtations, we presenta detailed performance comparison \nbetween the publicly available version of Bamboo [30], a state-of-the-art DHT, and a Mace implementation \nwe wrote from scratch. Mace tools for isolating performance and correctness errors signi.cantly ease \nthe task of debugging complex distributed systems. By combining the outlined bene.ts, we havebuilt Mace \nimplementations in an or\u00adder of magnitude less code that outperform the original systems. 2. Overview \nDrawing from ourexperiencebuildingavarietyof distributed sys\u00adtems based on high-level speci.cations, \nwe categorize thegap be\u00adtween speci.cation and low-level features essential to real deploy\u00adments into \nthe following categories: Layers: To manage complexity, network services consist of a hierarchy of layers, \nwhere higher level layers are built upon lower levels. The canonical example is the Internet protocol \nstack where, for example, the physical layer is responsible for modulating bits on a medium, the link \nlayer delivers packets from one node to another on the same physical network, the network layer delivers \npackets between physical networks, and the transport layer provides higher level guarantees such as reliable, \nin-order delivery. Each layerbuilds upon well-de.ned functionality of the layer below it and can typically \nwork on a variety of implementations of the underlying layer s interface. Concurrency: A distributed \nimplementation must properly contend with and exploit concurrency to maximize perfor\u00admance.Forexample, \nanoverlay routing application must simul\u00adtaneously contend with the application layer sending requests \nto the routing layer, the networking layer receiving new mes\u00adsages that must be passed up to the routing \nlayer, and timers executing scheduled tasks. While these events may be inter\u00adleaved on a single node, \nthey can also be arbitrarily interleaved across nodes as well.  Failures: A robust implementation must \naccount for the in\u00adevitable failures of different components or nodes of the dis\u00adtributed system. Failures \nare often dif.cult to detect; for in\u00adstanceitis impossibleto distinguish betweenafailednodeand one thatis \nparticularly slow. Further,the remaining nodes must correctly update their state to re.ect the new con.guration, \nlest inconsistencies lead to further errors.  Analysis: Given the complex operating environment, there \nare always performance bottlenecks and correctness issues that arise because the developers overlooked \nsome subtle scenario or miscalculated some parameter like a message timeout. An implementation must be \nstructured and readable enough to per\u00admit the manual and automatic analyses required to .x such performance \nand correctness problems.  While well-known techniques address each of these issues in isolation, the \nprimary challenge in our setting is to devise mecha\u00adnisms that help the programmer resolve the tensions \narising from complex interactions between the four problems.Forexample, the standard solution to the \nproblem of layering is Object-Oriented de\u00adsign. However, for high-performance applications, treating \nlayers as black boxes that hide their internal state and maskfailures leads to performance bottlenecks.For \ninstance, higherlevel routing algo\u00adrithms greatly bene.t from lower level information about link laten\u00adciesandknowledge \nabout which nodesor linkshavefailed. Further, multiple sources of concurrencycomplicate the task of propagating \ninformation consistently between layers. Similarly,failuresmakeitdif.cultto designa layering mecha\u00adnism. \nThe approach of masking low-levelfailures while appeal\u00ading because it simpli.es higher layers is insuf.cient \nin distributed environments because it sacri.ces signi.cant performance gains available from notifying \nthe upper layers of the failure. For in\u00adstance, the transport layer could mask failures by buffering \nsent messages and attempting to resend them until it succeeds; however, doing sowould prevent higherlayers \nfrom adjusting theirown state to achieve better performance, such asa multicast layer recon.gur\u00ading its \ntree structure for higher throughput afterafailure. Unfortu\u00adnately, the task of notifying the upper layers \nis complicated by the fact thatfailures can happen concurrently with other systemevents. Further, concurrency \nmakes it tricky to cleanly separate the fail\u00adure detection and handling code from the rest of the common-case \ncode, obfuscating the resulting system and destroying structure. Finally, standard techniques such as \npro.ling to .nd perfor\u00admance bottlenecksandmodelcheckingto.nd perniciousbugstyp\u00adically cannot be applied \nto distributed systems implementations. In ad-hoc implementations, the code that handles concurrencyand \nfailures obscures code structure making manual and automated rea\u00ad Figure 1. Bamboo DHT design architecture. \nsoning dif.cult(but essential). The principle technique usedby de\u00advelopers to analyze deployed systems \nis tedious ad-hoc logging that clutters the code and often delivers only limited value because the programmer \nmust manually stitch together spatially and temporally scattered logs. Finally,concurrencymakes it dif.cult \nto reason about or to sim\u00adplyeven replicate behaviors (due to non-deterministicfactors like network latencies \nand scheduling decisions), thereby severely in\u00adcreasingthetimeandeffort requiredto.ndcomplexbugsvia test\u00ading.In \nourexperience, particularly subtlebugs may remain latent for weeksina deployed system. Further, because \nthesebugs often result from inconsistencies between the state at multiple nodes, the subsequent departure \norfailureofa node after thebug manifests itself can push the system back into a consistent state, masking \nthe bug and making it even more dif.cult to track. Thus, to develop high-performance systems from high-level \nspeci.cations, we must devise techniques to architect the system, to determine when failures have occurred, \nand to propagate and exploit information throughout the architecture. These techniques must operate in \na concurrent setting, enable modularity and reuse\u00adability, and explicate the high-level structure of \nthe algorithm, thereby enabling manual and automatic system level analyses. Mace Design Principles To \naddressthe challengesposedbythe domainof distributedappli\u00adcations, we base Mace on three fundamental \nconcepts. Objects: Mace structures systems as a hierarchyof service ob\u00adjects connectedviaexplicit interfaces.We \nusean objecttoim\u00adplement each layer of the system running on an individual node. The interface for each \nlayer speci.es both the functionality pro\u00advided by that layer as well as any requirements that must be \nsatis.ed to use that layer.  Events: Mace uses eventsasauni.ed concurrencymodel for all levels of the \nsystem: within an individual layer,across the layers at a single node, and across the nodes comprising \nthe entire system. Each event corresponds to a method implemented by a service object.  Aspects: Mace \nprovides aspects to describe computations that cut acrossthe objectandevent boundaries:in particular,aspects \nde.ne tasks that need to be performed when particular condi\u00adtions become satis.ed.  While eachof these \nideashavebeen studiedextensivelyin isola\u00adtion, we demonstrate thattheycombine synergistically to preserve \nthe high-level structure of the distributed system and simultane\u00adously address the complexity and challenges \nof building robust, high performance implementations.We usea popular Distributed HashTable(DHT)to illustratethe \nchallenges associatedwithbuild\u00ading distributed systems and our approach to addressing these chal\u00adlenges. \nDHTs support put and get operations on a logical hash table whose actual storage is spread across multiple \nphysical ma\u00adchines, and thus forma convenient abstraction forbuilding higher\u00adlevel applications like \ndistributed .le systems [10, 27]. The key properties of a DHT implementation are scalability and robustness \ntofailure.We considera DHTbuilt ontheBAMBOOrouting proto\u00adcol [30] (similar toCHORD [35] orPASTRY [32]). \n Layers NodesinBAMBOO self-organize intoa structure that enables rapid routing of messages using node \nidenti.ers. This protocol forms a single layer of the DHT shown in Figure 1. BAMBOO is built on top of \na TCP subsystem that maintains network connections and delivers messages and a UDP subsystem that sends \nlatency probes.Arecursive routing subsystem routes messages to the node owningagivenkeyby askingBAMBOO \nforthenexthoptowards the destination. The DHT application layer uses the lower layers to store and retrieve \ndata. Mace enables programmers tobuild layered systemsby using objects toimplement individual layers \nandevents tofacilitate in\u00adteraction across layers.For each layer, the programmer writes in\u00adterfaces specifying \nthe events that may be received from or sent to the layers both above and below.Alayer s implementation \nconsists of a service object that must be able to receive and may send all the events speci.ed in the \ninterfaces. Thus, Mace combines objects and events to enable programmers to build complex systems out \nof layered subsystems, thereby abstracting functionality into layers with speci.edinterfacesandallowingthesafereuseofdifferentim\u00adplementations \n(meeting the same interface) of a particular layer in different systems. Concurrency In BAMBOO, a key \nchallenge is to provide fast message routing while simultaneously dealing with node churn i.e. the arrival \nand departure of nodes from the system. To achieve this goal, the system must concurrently process network \nerrors, messages from newly created nodes, and periodically perform maintenance to ensure routing consistency. \nIn Mace, each service object consists of a state-transition sys\u00adtem beginning in some initial state. \nEach node progresses by se\u00adquentially processing external events originating from the applica\u00adtion, thephysical \nnetwork layer, or self-scheduled timers. Upon re\u00adceiving an event, the service object executes a corresponding \ntran\u00adsition to update its state, during which it may transitively send new events to the layers above \nand below, each of which are processed synchronously without blocking until completion. Furthermore, \na transition may queue new external events locally by scheduling timers and remotely by sending network \nmessages. Once process\u00ading for a given external event completes, the node picks the next queued external \nevent and repeats. The Mace event-driven model provides a uni.ed treatment of the diverse kinds of concurrency \nthat must be handled in an ef.\u00adcient implementation: the reception of messages from other nodes (via \nthe transport layer), the reception of high-level application re\u00adquests, timers .ring, and cross-layer \ncommunication all correspond toevents that the relevant layers must handle via appropriate transi\u00adtions. \nAdditionally, Mace ensures that the transitions execute with\u00adout preemption, freeing the programmer from \nworrying about ex\u00adponential interleavings of concurrent executions. Finally, because Mace automatically \ndispatches events through a carefully tuned scheduler, Mace systems can achieve the throughput necessary \nfor high performance applications with minimal programmer involve\u00ad ment. Thus, objects, events, and aspects \nenable Mace to describe each layer of a complex application with the simplicity and con\u00adciseness of high-level \nmodels; when combined with the modular layering mechanism, Mace provides a succinct representation of \nthe entire computation stackfor each node of the distributed sys\u00adtem. Failures BAMBOO builds anoverlay \nnetwork forminga logical ring among the nodes.To create and maintain this topology, each nodekeeps references \nto its adjacent peers in the ring. If one node fails, the application-level state corresponding to the \nrelationships between that node and its neighbors may become inconsistent, breaking the overlay structure. \nMace uses aspects to cleanly specify how to consistently up\u00addate local state in response to a variety \nof cross-layer events, such as node arrivals, departures, and application-levelfailures. The de\u00adveloper \ncan specify predicates over the variables of a given node that test for programmer-speci.ed inconsistencies. \nMace gener\u00adates code to evaluate the predicate whenever the relevant variables changeandtoexecutetheaspectwhenthe \npredicateis satis.ed.As\u00adpects provide an ideal mechanism for specifying and detectingfail\u00aduresand inconsistencies,as \nwithoutthemthedeveloperwouldhave to undertake the tedious and error-prone task of manually placing checking \ncode throughout the system, additionally reducing read\u00adability. When a failure occurs, the Mace runtime \nsends noti.ca\u00adtioneventstothe appropriate layers.Upon receivingtheseevents, the systemexecutes recovery \ntransitions. Thus, Mace combines ob\u00adjects, events, and aspects to provide clean mechanisms for specify\u00ading, \nnotifying, and handling various types of failures and for main\u00adtaining the consistent internal state \nnecessary for fault-tolerant im\u00adplementations. Analysis BAMBOO routes messages through several intermediary \nnodes, so tracing the forwarding path for a speci.c message manually, for instance to debug the timing \nof a request, involves inspecting mul\u00adtiple physically scattered log .les. Mace simpli.es such analysis \ntasks through preservationoftheexplicit high-level structureofthe distributed application with three \ntechniques. First, Mace uses as\u00adpects to separate code needed to log statistics, progress, or debug\u00adging \ninformation from the actual event handling implementation. By removing the distracting logging statements, \nMace keeps the system code readable. Second, Mace exploits the structuring of the computation into causally \nrelated event chains to generate event logs, which may be spatially and temporally scattered. These event \nlogs can be automatically aggregated into .ows describing high\u00adlevel tasks, extracting the events at \nindividualnodes corresponding to some higher-level operation.Thestructure preservedinthe.ows allows developers \nto use automated analysis techniques to .nd and .x performance anomalies. Third, the modular structure \nof Mace applications enables de\u00advelopers to test the system using simulated network layers thatfa\u00adcilitate \ndeterministic replay. We have built a tool, MaceMC, that combines these deterministic layers with a special \nscheduler that iterates over all possible event orderings. MaceMC systematically exploresthe spaceof \npossibleexecutionsto.nd subtlebugsinthe system. The event-driven nature of Mace applications reduces \nthe number of interleavings that must be analyzed, enabling MaceMC to search deep into the execution \nspace. Thus, objects, events, and aspects combine to structureMace implementations that enable au\u00adtomated \nanalysis techniques to improve the performance andrelia\u00adbility of the distributed application.  Figure \n2. Mace service composition for a DHT application using Recur\u00adsive Overlay Routing implemented with Bamboo. \nShaded boxes (dark for downcall, light for upcall) indicate the interfaces implemented by the ser\u00advice \nobjects. 3. Mace Wenowdescribethe detailsofhowMace combines objects,events, and aspectsto generatehigh \nperformance,fault-tolerant implemen\u00adtations from high-level speci.cations. Our C++ language exten\u00adsions \nstructure each service object asa state machine template with blocks for specifying the interface, lower \nlayers, messages, state variables, inconsistencydetection, and transitions containing C++ code implementing \nevent handlers. The template syntax allows the Mace compiler to enforce the architectural design by performing \na high-level validation of the service object. Additionally, the struc\u00adture gives the Mace compiler the \nnecessary information to auto\u00admatically generate ef.cient glue code for a variety of tasks that in previous, \nad-hoc implementations, had to be manually inserted by the developer. This section discusses how Mace \naddresses manyof the challenges associated withbuilding distributed systems. 3.1 Layers To specify a \ndistributed system in Mace, the programmer simply speci.es the set of layered service objects (abbreviated \nto services) that comprise a single node and the implementation of the required interface for each service \nobject. Figure2depictsa more detailed view of the BAMBOO architecture (shown earlier in Figure 1), including \nthe interfaces. Interfaces. An interface comprises a set of downcall events and a set of upcall events. \nUpper layers senddowncalls receivedbylower layers.Lower layers send upcalls receivedby the upper layers.We \nmodel events using methods sending corresponds to calling the appropriate method, and receiving corresponds \nto executing the method.In Figure2ontheleft,weshowtwo interfaces: Overlay and Route.For each interface, \nthe top half (lightly shaded box) corresponds to the upcall events, and the lower half (darkly shaded \nbox) shows the downcall events. Architecture. Developers layer service objects implementing higher layers \non top of service objects implementing lower lay\u00aders.Tofacilitate modular design and seamless replacement \nof one service object with another, we specify for each service object the set of lower-level interfaces \nit uses and the upper-level interface it provides. Used Interfaces: When specifying a service, the developer \ndeclares each lower-level service with a name and an interface. The service may send anyof the downcall \nevents speci.ed in the interface to anyof the lower layers, and it must implement all the upcall events \nto receive anycallbacks. BAMBOO uses two lower-level services of type Route, which it binds to local \nnames TCP and UDP. The BAMBOO imple\u00ad mentation can directly call TCP.route (resp. UDP.route) on the TCP \n(resp. UDP)service object implementing the lower level, as route is a downcall event in the used interface. \nSimilarly, the lower-level TCP and UDP services can invoke the deliver callback on BAMBOO, as it is an \nupcall in the Route interface. Provided Interface: When writing a service, the developer speci.es how \nupper layers can use the service via a provides interface.The service must implementalldowncallevents \nspec\u00adi.edintheprovides interfaceandmayalsosend callbackevents to upper layers, typically in response \nto some prior request. Figure2showsthatall arrows pointingtoBAMBOO havetype Overlay, indicating that \nBAMBOO provides the Overlay interface to upper-level services. Thus, the BAMBOO service object must be \nable to receive the getNextHop event from the upper layers, as it is a downcall event in the Overlay \ninterface. Likewise, the BAMBOO service may send an up\u00adcall notifyIdSpaceChanged event, which must be \nimple\u00admentedby anyupper layers usingBAMBOO. Static Checking. The Mace compiler performs two compile time \nchecks to enforce that each service object meets the requirements of the interfaces that it uses and \nprovides. First, the compiler checks that the object implements methods corresponding to all the upcall \nevents in the used interfaces and the downcall events in the pro\u00advided interface. Second, the compiler \nchecks that the object only calls methods corresponding to downcall events in the used inter\u00adfaces, and \nthe upcall events in the provided interface. The service speci.cation explicitly names lower-level services \nbecause this knowledge is required to build the service. For ex\u00adample, BAMBOO requires two transports: \none for sending protocol related messages(TCP by default) and one for probing(UDP by default).However, \nanyupper layers that useagiven service are un\u00adknown when specifying the service, hence those need not \nand can\u00adnotbeexplicitly named.We observe that the upcallevents sentto upper level services are in response \nto previous requests made by those services. Thus, the Mace compiler automatically generates codesuchthateverydowncallis \naccompaniedbya referencetothe source of the downcall, and the service employs this reference to determine \nthe destination of the subsequent upcall. By explicitly decomposing the whole system using layers and \ninterfaces, Mace allows implementations of subsystems to be easily reused across different systems, as \nany service implementation that meets the statically checked interface speci.cations can be used as the \nsubsystem.Forexample, our DHT application works equally wellby replacing theBAMBOO service object with \nservice objects implementing the CHORD or PASTRY algorithms, which also provide the Overlay interface. \n 3.2 Concurrency The standardwayof modeling distributed algorithmsatahigh-level is with state-transition \nsystems. Mace enables developers to reap the manybene.ts of this structured approach by requiring them \nto specify each service object as a state transition system where the transitions represent the execution \nof the methods corresponding to received events. Given speci.cations for individual service state machines, \nMace can automatically compose layers to obtain an ef\u00ad.cient, structured system implementation.Astate \nmachine speci.\u00adcation comprises two basic entities: states and transitions. states { init; preJoining; \njoining; joined; }state variables { NodeKey myhash; leafset myleafset; KeyRange range; 5 Table mytable; \ntimer global maintenance attribute((recur(MAINTENANCE TIMEOUT))); timer join timer; }transitions { 10 \n/* Other transitions . . . */ scheduler global maintenance() guard (state == joined){ NodeKey d = myhash; \nfor(int i = randint(ROWS); i < ROWS; i++) { 15 d.setNthDigit(randint(COLS), B); } NodeKey n = make routing \ndecision(d); TCP.route(n, GlobalSample(d)); } 20 upcall forward(const NodeKey&#38; src, const NodeKey&#38; \ndest, NodeKey&#38; nextHop, const GlobalSample&#38; msg) guard (state == joined){nextHop = make routing \ndecision(msg.key); return true; } 25 upcall deliver(const NodeKey&#38; src, const NodeKey&#38; dest, \nconst GlobalSample&#38; msg) guard (state == joined){TCP.route(src, GlobalSampleReply(msg.key, myhash)); \n} 30 upcall deliver(const NodeKey&#38; src, const NodeKey&#38; dest, const GlobalSampleReply&#38; msg) \nguard (state == joined){update state(src, msg.destHash, true/*known live*/, true/*do probe*/); } 35 } \nFigure 3. States andTransitions forBAMBOO Service Object States. States are a combination of the .nite \nhigh-level con\u00adtrol states of the service protocol, along with the (possibly in\u00ad.nite) data states corresponding \nto values taken by variables such as routing tables, peer sets, and timers. Figure 3 shows how the programmer \nspeci.es the high-level states and state variables of the BAMBOO service. The .nite high-level states, \ninit, preJoining, Joining, and Joined correspond to the four stages of joining the system. The state \nvariables myhash, myleafset, mytable, and range correspond to the node s unique identi.er, the set of \npeers and routing table maintained by the node, and the space ofkeys assigned to the node. In addition, \nBAMBOO uses two timers, one of which is automatically resched\u00aduled at MAINTENANCE TIMEOUT intervals by \nMace compiler generated code. Transitions. Therearethreekindsof transitionsand corresponding events: \nupcalls received from lower layers, downcalls received from upper layers, and scheduler events received \nfrom self-scheduled timers. Methods implement the transitions and update the state upon receiptof the \ncorrespondingevent. Figure3shows different kinds of transitions corresponding to events the BAMBOO service \nobject may receive.Akeyword labels each method and indicates its transition type. Each transition method \ncan be guarded by a predicate over the state variables. This condition may reference the current high-level \nservice state, service state variables, or event parameters. The transition only .res if the guard is \ntrue. To understand how the programmer structures the code for each service into events and transitions, \nconsider the high-level  Figure 5. Message diagram for global sampling. In response to a scheduled \ntimer, Node A routes a GlobalSample message to an identi.er id by sending it to node B, which is forwarded \nto its owner, node C. Node C responds with a GlobalSampleReply mes\u00adsage informing node A about node C, \npotentially caus\u00ading a routing table update. detect {guard =(range != pre(range)); error = notifyNewRange; \n} // local detection detect {guard =(state == joined); nodes = myleafset; send = { message = LeafsetPush(myhash, \nmyleafset); period = 5sec; }receive = { message = LeafsetPull; period = 5min; }error = leafFailed; } \n// distributed detection (across myleafset) Figure 6. Local and Distributed inconsis\u00adtencyandfailure \ndetectionin Mace. state machine for the BAMBOO object illustrated in Figure 4. The .gure shows what happens \nwhen BAMBOO receives events such as application join requests, network messages, or timers caus\u00ading reattempted \njoins. The system begins in the init state, and transitions to the preJoining state upon receiving a \ndowncall event init from the application. When it subsequently receives the downcall event joinOverlay, \nit transitions to the joining state if it is not its own peer (captured via a predicate guard\u00ading the \nevent), or to the joined state otherwise, in either case sending appropriate noti.cation events and scheduling \ntimers. In the joining state it periodically sends join messages to other nodes requesting to join the \nsystem, and .nally, when it receives a deliver(leafsetPull) message from another node, it moves into \nthe joined state. The rest of a node s life is spent in the joined state, where it periodically globally \nsamples the other nodes to improve its local routing information. Sequence diagrams are an informal technique \nprogrammers use to reason about low level interactions, such as those tak\u00ading place while in the joined \nstate. Figure 5 shows a se\u00adquence diagram depicting the interaction between nodes perform\u00ading global \nsampling to improve routing tables. The periodically scheduled global maintenance timer .res on node \nA caus\u00ading it to select a random routing identi.er id, and to then send a GlobalSample message to the \nnode B, which is the next hop along the route. This message gets (transitively) forwarded by B until \nit reaches C, which actually owns the identifer id. C then sends a GlobalSampleReply message back to \nA, which, upon receiving the reply, may update its routing information. Oncethe programmerhasworkedoutthe \ndetailsofthe protocol using the sequence diagram, it is straightforward to code in Mace using transitions \nand events. Figure 3 shows (in order) how the events correspondingtoi)the.ringoftheglobal maintenance \ntimer at A, ii) the forwarding of the GlobalSample message to B and C,iii) the .nal delivery message \nto the destination C, andiv) the delivery of the GlobalSampleReply back to A, are imple\u00admentedas transitionsintheBAMBOOservice \nobject.The bodiesof the respective transitions implement the actions taken upon receiv\u00ading the corresponding \nevents shown in Figure 5.  3.3 Failures Mace s use of service objects and events greatly simpli.es the \ntask of detecting, notifying, and handlingfailures and inconsistencies. While layering is essential forbuilding \ncomplex services, the in\u00adformation hiding endemic to layered systems often makes it dif\u00ad.cult to deliver \nthe best performance or the most agilefault han\u00addling.Forexample,whenaDHT application ssocketbreaksdueto \na nodefailure, the TCP transport layer could attempt to mask the error. However, doing so may prevent \nBAMBOO from being able to route around thefailed node, leading to degraded performance or incorrect message \ndelivery. Rather, the TCP transport layer must propagate the error to BAMBOO so that it can update its \nrouting table and leafset. BAMBOO, in turn, further propagates the error to the DHT application, so that \nit can redistribute thekeys stored on thefailed node. Mace provides clean mechanisms for layering network \nservices while also making it easy to deliver error noti.\u00adcations automatically from one layer to another \nwhen required for performance orfault tolerance. Mace employs upcalls to signal higher layers of potential \nper\u00adformance and correctness issues. It may be possible to correctly handlean issue entirelyatalower \nlayer,but with suboptimalper\u00adformance. If this is acceptable to upper layers, then theycan simply ignore \nthe corresponding upcall. However, for best performance it may be necessary to register handlers for \nsuch upcalls. While such cross-layer communication usuallyobfuscates code and eliminates manyofthe bene.tsof \nlayering,weleverage ourevent-based struc\u00adture to cleanly separate the noti.cation and recovery code from \nthe rest of the system that executes in the non-exceptional case. Mace addresses the remaining challenge \nof providing program\u00admers with a succinct but .exible mechanism for detecting both failures and inconsistencies \nthrough the use of aspects. Aspects provide a uni.ed way to maintain consistent state, regardless of \nwhether the state needs to be updated in response to an expected protocol event, such as a node arrival, \nor an unexpected event, such as a failure. Mace aspects check for two types of inconsis\u00adtency/failure \ndetection: those that involve purely local state and those that involve multiple nodes. Local Failure \nDetection. Failures occurring in distributed systems can be characterized via inconsistencies in the \nvalues of state vari\u00adables.A local failure occurs when the values of state variables at a single node \nare inconsistent.Forexample,in our DHT application builtontopofBAMBOO,thedatathateachnodeis responsiblefor \ndepends on thekeyspacespeci.edby the range variable. In other words, the views of the range of the DHT \nlayer and the BAMBOO layer must be synchronized, and if they are not, recovery action must be taken so \nthat the DHT relocates the data according to the new range, potentially involving communication with \nremote sys\u00adtem nodes. Such failures can be speci.ed using a predicate that charac\u00adterizes the inconsistent \nvalues, i.e., which becomes true when the valuesofthevariables are inconsistent. Thus, suchfailures canbe \nlocally detected by monitoring the predicate, and .ring an event when the predicate becomes true. In \nMace, the programmer speci\u00ad.eshowfailures shouldbe detectedandhowto reacttothefailure using a detection \naspect. A failure occurs when this predicate is true, which .res an error event and noti.es the upper \nlayers of the inconsistency. Consider the example in the top of Figure 6, showing a local detection aspect \nthat speci.es that an inconsistencyfailure occurs when thevalueof thevariable range changes (the pre() \nversion refers to the value of range before the last transition). When the change occurs, Mace sends \na notifyNewRange event to the upper DHT layer indicating that its portion of the key space has changed \nand prompting it to reorganize stored data appropriately. This aspect will correctly react to all events \nthat change the range, whether it be the arrival of a new peer adhering to the BAMBOO protocol or an \nunexpected peerfailure. The local detection aspect checks the predicate only at tran\u00adsition boundaries, \navoiding noti.cation of state that may become temporarily inconsistentinthe middleofatransition.Thus, \naspects andeventsprovideacleanwayto separatethefailure detection, no\u00adti.cation, and handling from the \nrest of the common-case code. We implement detectionbykeepinga shadow copyof monitored statevariables, \ncheckingand updatingthemaftereach transition.In ad-hoc implementations,built without language support, \nthe pro\u00adgrammer would have to manually insert the check and noti.cation each time the variables might \nbe modi.ed. In addition to greatly reducing readability, this task is error-prone, especially as the \ncode evolves or is maintained by multiple programmers. Distributed Failure Detection. Adistributed failure \noccurs when thevalues acrosstwoor more nodes are inconsistent.Forexample, in BAMBOO, each node maintains \nthe set of its immediate peers in the state variable myleafset. Each such peer, in turn, must includethenodeinitsownsetofknown \npeers.Adistributedfail\u00adure occurs if some element of a node s leafset does not include the node in its \nown set of peers. As a node cannot directly access the other nodes internal state, the only way to determine \nthe pres\u00adence of such a failure is to actively exchange information across nodes, checking that the received \ninformation is consistent, and if so, returning messages acknowledging consistency. If the originat\u00ading \nnode receives the acknowledgment before a timeout occurs, it con.rms that nofailure has occurred. Thesefailures \ncan alsobe captured via predicatesover the state variables of multiple nodes, and the Mace compiler automatically \ngenerates the periodic probe and acknowledgment messages. How\u00adever, it is pro.table to let the programmer \ncontrol how the probing happens to avoid .ooding the network with messages pertaining to failure detection. \nThe programmer speci.es how to detect and reactto distributed failures in Mace using the samedetection \naspect as for localfail\u00adures, but now de.nes more elements for the aspect, as shown at the bottom of \nFigure 6. The guard speci.es the conditions for performing a probe. The nodes are the set of nodes monitored \nby the aspect. In this example, it is the nodes stored in the set myleafset. The send .eld indicates \nhow the probes are sent to the elements of nodes. Here, the node sends LeafsetPush messages with the \ncurrent value of myhash and myleafset state variables to the elements of myleafset sequentially, once \nevery 5 seconds. The receive .eld indicates the response ex\u00adpected from the other nodes, together with \na timeout before which the response must arrive. Here, it stipulates that the node must re\u00adceive a LeafsetPull \nmessage from each of the other nodes in myleafset beforea timeout periodof5minutes elapses. Mace generatesextra \nstateandthecode neededtokeeptrackof the last time it has heard from each monitored node. It sets a timer \nto.re sometimeafteritexpectstoreceiveanacknowledgmentofa particular remote con.guration. If the timeout \noccurs and the guard is true, then Mace calls the event speci.ed in the error .eld, notifying upper layers \nof the failure. As in the case of the local failures,the transition correspondingtothe errorevent corresponds \nto the code that implements the recovery mechanism. Likewise, Mace simpli.es the detectionof distributedfailuresby \nseparating the detection code into an aspect and automating the process of sending the probe messages \nand detecting timeouts.  3.4 Analysis By using objects and events to preserve the high-level structure \nof the distributed system, Mace can automate a variety of post\u00addevelopment analyses that .nd performance \nor correctness prob\u00adlems. Execution Logging and Debugging. Mace uses aspects to gen\u00aderate debugging and \nlogging code without cluttering the service speci.cation. Mace exploits the preserved structure to enable \ndif\u00adferent levels of automatic logging. First, with event-level logging, the generated program logs the \nbeginning and end of each high\u00adlevel event. This captures the order and timing of events at each node.With \nstate-level logging,every timea transition .nishes, the generated program logs the node s complete state, \nwhich indicates the change caused by the transition. Finally, with message-level logging, the generated \nprogram additionally logs the content and transmission time for each message sent from or received by \nthe node. We have used the automatically generated logs to implement MDB, a replay debugger for Mace \ndistributed applications. MDB collects all individual node log .les centrally and allows the devel\u00adoper \nto single step, forward and backward, through the execution of individual nodes. The developer may move \nfrom node to node, inspecting global system state, in a manner similar to traditional single process \ndebuggers. Our ability to swap in a simulated mes\u00adsaging layer further allows the developer to explore \nalternate exe\u00adcution paths,diverging from somegiven pointina realexecution. Causal-Paths. Mace provides \na more advanced form of logging that aggregates execution events distributed across multiple nodes into \na set of causal paths. Each path starts at a given node, with a particular seed event, and contains the \nsequence of all events that are causally, transitively relatedtotheseedevent.Forexample,if the seed event \nis a request generated by a particular node, then the causalpath includesthe sequenceof messages(and \nresultingevents and transitions) that span the different nodes until the response returns to the requester. \nTo obtainsuch causalpathsinaMaceapplication,the program\u00admer speci.es the seed event where the path begins \nand the event that ends the path. Mace tags all the relevant, causally related ac\u00adtivity that occurs \nbetween the seed and the end(i.e.,allevents, tran\u00adsitions, messages sent and received) with a dynamically \ngenerated path identi.er and generates logs such thatevents distributed across multiple nodes can be \ncollected using their shared path identi.er. As a result, Mace enables logging at a semantic-level and \nallows programmers to understand and analyze the behavior of the system at a high level. In addition, \nprevious work [29] describes how the causal-path logging done by Mace can be automatically mined to .nd \nand .x performance anomalies,by comparing the causal paths resulting from actual executions with programmer-speci.ed \nhigh\u00adlevel expectations. While this earlier work on the bene.ts of causal paths to per\u00adformance debugging \nis independent of Mace, it requires signi.\u00adcant manual logging in standard, unstructured C++ applications. \nWe have found that the more than 90% of the logging required for causal path analysis can be automatically \ninserted by the Mace compiler, signi.cantly lowering the barrier for leveraging the ben\u00ade.ts of such \nperformance debugging tools. Model Checking. Ahigh-level model of a distributed system en\u00adablesexhaustive \nanalyses like model checking to .nd subtlebugs in either the protocol or implementation of a distributed \nsystem. Mace allows developers to use the same analysis to .nd subtle er\u00adrors in the actual implementation \nof the system by making it easy to systematically explore the space of executions of the implemen\u00adtation.Wehavebuilt \nMaceMC [17],amodel checker targetinglive\u00adness violations in Mace. While our techniques for .nding liveness \nviolations in real systems implementations are general (these tech\u00adniques are the focus of [17]), here \nwe describe the bene.ts of Mace language structure in integrating a software model checker: Mace s service \nlayering mechanism simpli.es integrating a simulation engine by replacing the services implementing the \nactual network with a simulated network of queues holding the messages between nodes. In ad hoc implementations, \nmessag\u00ading functionality may be spread throughout the code making it dif.cult to plug in the simulated \nmessaging layer necessary for model checking.  Mace sstate-event semantics ensures thatanode sstate \nchanges by processing a single event atomically, via a single transition. Thus, the model checker need \nonly considerevent interleavings across individual events at participating nodes, rather than, for instance, \nexploring all interleavings at a much .ner granular\u00adity or forcing the developer to manually identify \nappropriate transition points.  Mace s state-event semantics allow us to deterministically re\u00adplay an \nexecution (once the sequence of events is .xed) either forthe purposeof demonstratingabuggyexecution,ortoper\u00adform \na random simulation from a previously visited state. This allows MaceMC to exhaustively search the states \nup to a cer\u00adtain depth and to then perform deep random walks from the boundary states to look for liveness \nviolations.We have found that without such random walks it is impossible to distinguish between actual \n(permanent) liveness violations and temporary divergences from desired high-level system properties. \n After applying MaceMC to5signi.cant systems implementa\u00adtions (a subset of those mentioned in Section \n4), we were able to .nd 50 subtle protocolbugs. Most of thesebugs were present in systems that had already \nbeen hardened through live Internet de\u00adployment and manual debugging. 4. Experiences In this section, \nwe outline some of our experiences developing dis\u00adtributed applications with Mace. Mace itself is implemented \nas a source-to-source compiler in Perl using a recursive descent parsing module. The Mace compiler emits \nC++ code, which is then com\u00adpiled using anyC++ compiler such as g++.We have implemented over nine substantial \ndistributed systems in Mace, manyof which we have run across the Internet, including on testbeds such \nas Plan\u00adetLab [28]. In addition to the BAMBOO implementation discussed here, we have also implemented \nthe systems shown in Figure 7. These systems include CHORD [35], PASTRY [32], SCRIBE [33], SPLITSTREAM \n[7] (from the FreePastry [1] distribution), BUL-LETPRIME [20] (from theMACEDON [31] distribution),OVER\u00adCAST[15](notavailabletousforline \ncounting),andVIVALDI [9]. Excepting BULLETPRIME (which was written in the MACEDON language), each of \nthese services were originally developed in un\u00adstructured C++ or Java. The Mace compiler eliminates manytedious \ntasks that must oth\u00aderwise be hand-implemented to achieve high performance, such as message serialization \nand event dispatch, and correspondingly drastically reduces the implementation size.AMace service object \nimplementation contains a block for specifying message types (es\u00adsentiallya struct with optionaldefaultvalues),foreachofwhich \nthe compiler generates a class containing optimized methods to se\u00adrialize and deserialize the message \nto and from a byte string that can be sent across the network. The Mace compiler also generates methods \nto automatically perform event sequencing and dispatch. The generated code selects the next pending event, \nperforms lock\u00ading to prevent preemption, evaluates anyguard tests for the transi\u00adtion, executes the appropriate \nmethod implementing the event han\u00addler (assuming the guards succeeded), tests any aspect predicates that \nmight have been updated by the transition, and .nally releases the acquired locks. Overall, we .nd that \nthe structure imposed by Mace greatly simpli.es the implementation by allowing the pro\u00adgrammer to focus \nonly on the essential elements, without compro\u00admising performance or reliability. 4.1 Performance Evaluation \nTo evaluate the performance of Mace systems, we compare our BAMBOO implementation in Mace with its well-tested \ncounter\u00adpart [30].To distinguish the twoversions, for this section we will referto our implementationas \nMace-Bamboo.We choseBAMBOO because of its excellent performance, detailed published perfor\u00admance evaluation, \nand its publicly available and well documented code base. Bamboo is a highly optimized Java implementation \nof a distributed hash table, based originally onPastry [32].We com\u00adpare behavior of node lookups under \nchurn. Lookups operate by forwarding a message using increasing pre.x matching to nodes whose identi.ers \nare progressively closer to thekey. Bambooex\u00adplores the limitations of previous protocols in providing \nconsistent routing in the presence of node churn, and proposes several mod\u00adi.cations toPastry to allow \nit to deliver high consistencyand low latency even when nodes are entering and leaving the system at \na high rate. Consistencyis a measure that captures whether different nodes routing to the same identi.er \nwill reach the same destination. This is the most important requirement for correct performance of ap\u00adplications \nusing a DHT, since theyrely on being able to share data by using the same identi.er to store and retrieve \nvalues. Our exer\u00adcise of re-implementing Bamboo serves to show the simplicity of implementing distributed \nsystems in Mace and our ability to gener\u00adaterobust,ef.cient,andhigh performance code.Twoexperienced Mace \ndevelopers implemented the primary Bamboo algorithms in twelve hours (excluding the reliable UDP transport), \nstarting from anexisting MacePastry implementation. To compare against published Bamboo experimental \nresults (we attempted to reproduce the published resultsbut could never achieve them, most likely due \nto having fewer machines), we pre\u00adpare a framework that matches, to the best of our ability, the origi\u00adnalexperimental \nconditions.Theexperiment consistsof1000Bam\u00adboo nodes organized into groups of 10 performing simultaneous \nlookups of randomkeys.Alookup result is considered consistent if a majority of the 10 nodes return the \nsame result. Each group of 10 nodes performs lookups according to a Poisson process with anaverage inter-lookup \ndelayof1 second.For the runs, wevary the median churn rate also according to a Poisson process, ranging \nfromonaverage8deathsper secondto1deathper second. We run 1000 Bamboo instances on 16 physical machines \n(the published BAMBOO results used 40 machines), using the Model-Net [36] network emulator with a single \nFreeBSD core. Each of the physical machines is a dual Xeon 2.8Mhz processor with 2GB of RAM. During the \nruns, load averages ranged from 0.5 to 1.5. The emulated topology consists of an INET network with 10,000 \nnodes, 9,000 of them routers. Client bandwidths on the topologies ranged from 2-8Mbps. To start the experiment, \nnodes were stag\u00adgered, starting one on each machine each second for a minute. The churn and lookup schedules \nbegan as soon as all nodes were live. This experimental setup differs from the published Bamboo exper\u00adFigure \n7. Lines of code measured in semi\u00adcolons for various systems implemented in System Mace Distribution \nBamboo 500 1800 BulletPrime 1000 2800 Chord 250 3400 Overcast 450 NA Pastry 600 3600 Scribe 300 500 SplitStream \n200 331 Vivaldi 100 250  Figure 8. Percentage of lookups that return a Mace and other distributions. \nconsistent result. imentsinthatthe stagger-startisatamuchfasterrate,thatwedo not wait for the network \nto settle after starting all nodes, that we run with 1/3 the number of machines, and that our request \nload is 10 times higher. Figure8shows the consistencynumbers for the Java-Bamboo and Mace-Bamboo. The \npublished consistency values demonstrate near-perfect consistencyat all churn levels. While still above \n92% consistent, Mace-Bamboo nodes are slightly less consistent than their counterpart, though theytrack \nits performance closely. How\u00adever, as shown in Figure 9, the Mace-Bamboo latencyoutperforms Java-Bambooat \neachof these churnlevels,andbyafactorof5at high churn levels.  4.2 Undergraduate Course To aid in the \nevaluation and development of Mace, we have used it in two undergraduate networking courses, and it has \nalso been used in several graduate course projects. During the Spring Quarter 2005 and the Spring Quarter \n2006, students in advanced undergraduate networking classes were asked to program in Mace for a class \nproject.Noneofthe students enrolledintheclasshadbeenexposed to Mace previously. The project involved \nimplementing a peer-to\u00adpeer .le sharing program loosely based on the popularFastTrack protocol. The protocol \nincludes a number of distributed concepts such as .ood-based searching, distributed election, and random \nnetwork walks. To prepare for the project, students were given a one-hour introduction to Mace, a list \nof protocol messages (to support inter-operation), and a skeleton template for a basic Mace service. \n90% of the students successfully completed the project and a majority expressed a preference for programming \nin Mace relative to Java or C++. 5. Related Work Mace is closely connected to a large body of work in \nthe area of languages, libraries and toolkits for building concurrent systems. We focus our attention \non those speci.c to distributed systems. We build upon our earlier MACEDON [31] work a domain speci.c \nlanguage forfair comparisonsofoverlaysystems.MACE-DON also represents systems as I/O automata,but does \nnot con\u00adsider how compiler extensions that restrict speci.cations can sup\u00adport model checking, high performance, \ndebugging, etc. Whereas MACEDON focused on building prototype lab-experiments, we designed Mace as a \npractical, real-world environment for devel\u00adoping deployable high-performance, reliable applications. \nThe state-event-transition model Mace is founded on is closely related to other event-driven languages \nand libraries. NESC [12] isa language forbuilding sensor networks with limited resources requiring static \nmemory allocation. Broadly speaking, several re\u00adsearchers have investigated providing language support \nforbuild\u00ading concurrent systems out of interacting components, such as CLICK [19] forbuilding routers \nfrom modules and theFLUX OS-KIT [11] forbuilding Operating Systems. These approaches,how\u00adever, target \nconcurrent systems executing within one physical ma\u00adchine and not distributed systems scattered across \na network. P2[22] is a declarative, logic-programming based language for rapidly prototypingoverlay \nnetworks specifying data-.owbetween nodes using logical rules. WhileP2speci.cations are substantially \nmore succinct than those in Mace, the corresponding speci.cation is not as natural to programmers and \nsacri.ces performance. Also, while Mace is well-suited for building overlays, its applicability is broader. \nThere is a line of work in the functional programming community for advanced, type safe languages for \ndistributed com\u00adputation [34]. At the moment these languages are somewhat exper\u00adimental, emphasizing \nfully understanding the semantics of high\u00adlevel constructs for distributed programming and their interplay \nwith the type system rather than enabling the rapid deployment of robust, high-performance distributed \nsystems. Several libraries and toolkits also support manyof the common primitives required forbuilding \ndistributed systems.LIBASYNC[25] usesasingle-threadedevent driven model that makesextensive use of callbacks. \nLIBASYNC also provides some compiler support for dealing with Remote ProcedureCalls and for generating \nsome of the serialization code for messaging. Another instance, SEDA[37], provides an architecture for \nevent-based systems. Both of these systems focus on simplifying the implementation of event-driven code, \nrather than a structure for distributed systems. Mace uses ideas proposed by Aspect-Oriented Programming \n(AOP) [16]. One of the .rst examples of AOP was a domain\u00adspeci.c language for writing distributed software \n[23].Aprimary contributions of Mace is identifying the different concerns that comprise a distributed \nsystem e.g. the messages, events, transi\u00adtions,failures, and logging and designinga language that enables \nprogrammers to think about these in isolation. The Mace compiler seamlessly puts each of these together \nto create an ef.cient imple\u00admentation of the system. An immediate payoffof this separation is the easewithwhicha \nprogrammercanlogand monitor entireevent .ows without cluttering the code with print statements. There \nare several high-level languages for describing network protocols, rather than entire distributed systems. \nSome of these e.g. LOTOS[5],ESTELLE[6] are intended largely to formally specify protocols using .nite \nstate machines that communicate by passing messages.PROMELA[14]andTLA[21]aretwomoregen\u00aderal languages \nwhich can be used to model concurrent systems. Instead of producing executable systems, theycompile the \ndescrip\u00adtion into large .nite state machines to exhaustively analyze for er\u00adrors. RTAG [3] based on grammars \nand PROLAC [18] based on an object-oriented model are two examples of protocol descrip\u00adtion languages \nthat actually compile the description intoexecutable code. Mace combines the bene.ts of both by structuring \nthe de\u00adscription of the system such that the subsequent compiled imple\u00admentation is amenable to exhaustive \nanalysis. 6. Conclusions In this paper, we argued for the bene.ts of language support to construct robust, \nhigh-performance distributed systems. The prin\u00adciple challenge in this environment is resolving tensions \nbetween the tasks of developing a clean layering system, handling concur\u00adrencyandfailures, and preserving \nenough structure to enable auto\u00admated performance and correctness analyses. Thekeyinsight be\u00adhind Mace \nis that objects, events, and aspects can be seamlessly combined to simultaneously address the intertwined \nchallenges. Mace s language structure and restrictions enable a number of important features that are \notherwise dif.cult or impossible to ex\u00adpressinexisting languages: language support forfailure detection, \ncausal path performance and correctness debugging, and model checking unmodi.ed Mace code.Wehaveemployed \nMacetobuild ten signi.cant distributed applications, which have been success\u00adfully deployed over the \nInternet. Others are using Mace to support theirown independent researchanddevelopment.Using automated \ndebugging toolsthatexploittheMacestructureto.ndand.xprob\u00adlems,exploitingthe.exible architectureto reuse \noptimized subsys\u00adtems across applications, and leveraging the uniform and ef.cient event-driven concurrencymodel, \nMace system speci.cations were about a factor of .ve smaller than original versions in Java and C++, \nwhile delivering better performance and reliability. References [1] Freepastry: an open-source implementation \nof pastry intended for deployment in the internet. http://freepastry.rice.edu, 2006. [2] AGUILERA,M.K.,MOGUL,J.C.,WIENER,J.L.,REYNOLDS,P., \nAND MUTHITACHAROEN,A. Performance debugging for distributed systems of black boxes. In Proc. SOSP (2003). \n[3] ANDERSON,D.P. Automated protocol implementation withRTAG. IEEETrans. SoftwareEng.14,3(1988), 291 \n300. [4] BARHAM,P.T.,ISAACS,R.,MORTIER,R., AND NARAYANAN,D. Magpie: Online modelling and performance-aware \nsystems. In Proc. HotOS (2003). [5] BOLOGNESI, T., AND BRINKSMA, E. Introduction to the ISO speci.cation \nlanguage LOTOS. Computer Networks 14 (1987). [6]BUDKOWSKI,S., AND DEMBINSKI,P.An introductionto Estelle:A \nspeci.cation language for distributed systems. Computer Networks 14 (1987), 3 23. [7] CASTRO, M., DRUSCHEL, \nP., KERMARREC, A.-M., NANDI, A., ROWSTRON, A., AND SINGH, A. SplitStream: High-bandwidth content distribution \nin cooperative environments. In Proc. SOSP (2003). [8] CHEN,M.Y.,KICIMAN,E.,FRATKIN,E.,FOX,A., ANDBREWER, \nE. Pinpoint: Problem determination in large, dynamic internet services. In Proc. DSN (2002). [9] DABEK,F.,COX,R.,KAASHOEK,F., \nAND MORRIS,R.Vivaldi:A decentralized network coordinate system. In Proceedingsof theACM SIGCOMM 04 Conference \n(Portland, Oregon, 2004). [10] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area \ncooperative storage with cfs. In SOSP 01: Proceedingsof the eighteenthACM symposium on Operating systems \nprinciples (NewYork,NY, USA, 2001),ACM Press, pp. 202 215. [11] FORD, B., BACK, G., BENSON, G., LEPREAU, \nJ., LIN, A., AND SHIVERS,O. The Flux OSKit:Asubstrate forkernel and language research. In Proc. SOSP \n(1997). [12] GAY, D., LEVIS, P., VON BEHREN, R., WELSH, M., BREWER, E., AND CULLER,D. The nesC language:Aholistic \napproach to networked embedded systems. In Proc. PLDI (2003). [13] GODEFROID,P. Model checking for programming \nlanguages using VeriSoft. InProc. POPL (1997). [14] HOLZMANN, G. The Spin Model Checker: Primer and Reference \nManual. Addison-Wesley, 2003. [15] JANNOTTI, J., GIFFORD, D. K., JOHNSON, K. L., KAASHOEK, M.F.,AND JAMES \nW.O TOOLE,J.Overcast: Reliable multicasting with an overlay network. In Proc. OSDI (2000). [16] KICZALES, \nG. Aspect-oriented programming. ACM Computing Surveys 28, 4es (1996). [17] KILLIAN, C., ANDERSON, J. \nW., JHALA, R., AND VAHDAT, A. Life, death, and the critical transition: Detecting liveness bugs in systems \ncode. In NSDI (2007). [18] KOHLER, E., KAASHOEK, M. F., AND MONTGOMERY, D. R. A readable TCP in the Prolac \nprotocol language. In Proc. SIGCOMM (1999). [19] KOHLER, E., MORRIS, R., CHEN, B., JANNOTTI, J., AND \nKAASHOEK, M. F. The Click modular router. ACMTOCS 18,3 (2000), 263 297. [20] KOSTIC\u00b4, D., BRAUD, R., \nKILLIAN, C., VANDEKIEFT, E., ANDERSON,J.W.,SNOEREN,A.C., ANDVAHDAT,A. Maintaining high bandwidth under \ndynamic network conditions. In Proc. USENIX Tech(Anaheim, CA, Apr. 2005). [21] LAMPORT,L. Specifying \nSystems: the Tla+ Language andTools for Hardware and Software Engineers. Addison-Wesley, 2002. [22] LOO, \nB. T., CONDIE, T., HELLERSTEIN, J. M., MANIATIS, P., ROSCOE,T., AND STOICA,I. Implementing declarativeoverlays.In \nProc. SOSP (2005). [23] LOPES,C. D:ALanguageFrameworkfor DistributedProgramming. PhD thesis, Northeastern \nUniversity, 1996. [24] LYNCH,N. Distributed Algorithms. Morgan Kaufmann, 1996. [25] MAZIERES,D.Atoolkit \nfor user-level .le systems. InProc. USENIX Tech(2001). [26] MILNER,R. Communication and Concurrency. \nPrentice-Hall, 1989. [27] MUTHITACHAROEN, A., MORRIS, R., GIL, T. M., AND CHEN, B. Ivy: a read/write \npeer-to-peer .le system. In OSDI 02: Proceedings of the 5th symposium on Operating systems design and \nimplementation (NewYork,NY,USA,2002),ACMPress,pp. 31 44. [28] PETERSON, L., ANDERSON, T., CULLER, D., \nAND ROSCOE, T. ABlueprint for Introducing DisruptiveTechnology into the Internet. In Proceedings of the \n1st Workshop on Hot Topics in Networks (HotNets I) (Princeton, New Jersey, 2002). [29] REYNOLDS, P., \nKILLIAN, C., WIENER, J. L., MOGUL, J. C., SHAH,M.A., AND VAHDAT,A. Pip: Detectingthe unexpectedin distributed \nsystems. In NSDI (2006). [30] RHEA, S., GEELS, D., ROSCOE, T., AND KUBIATOWICZ, J. Handling churn in \na dht. In USENIXTech (2004). [31] RODRIGUEZ, A., KILLIAN, C., BHAT, S., KOSTIC\u00b4, D., AND VAHDAT,A. MACEDON: \nMethodology for automatically creating, evaluating, and designing overlay networks. In Proc. NSDI (2004). \n[32] ROWSTRON, A., AND DRUSCHEL, P. Pastry: Scalable, distributed object location and routing for large-scale \npeer-to-peer systems. In Proc. Middleware 2001 (2001). [33] ROWSTRON,A.,KERMARREC,A.-M.,CASTRO,M., AND \nDR-USCHEL,P. SCRIBE:The designofalarge-scaleevent noti.cation infrastructure. In Proc. ThirdInternationalWorkshop \non NGC (2001). [34] SEWELL,P.,LEIFER,J.J.,WANSBROUGH,K.,NARDELLI,F.Z., ALLEN-WILLIAMS,M.,HABOUZIT,P., \nANDVAFEIADIS,V. Acute: high-level programming language design for distributed computation. In Proc. ICFP \n(2005). [35] STOICA, I., MORRIS, R., KARGER, D., KAASHOEK, F., AND BALAKRISHNAN,H. Chord:Ascalable peer \nto peer lookup service for internet applications. In Proc. SIGCOMM (2001). [36] VAHDAT,A.,YOCUM,K.,WALSH,K.,MAHADEVAN,P.,KOSTIC\u00b4, \nD., CHASE, J., AND BECKER, D. Scalability and Accuracyin a Large-Scale Network Emulator. In Proc. OSDI \n(2002). [37] WELSH,M.,CULLER,D., AND BREWER,E. SEDA: an architecture for well-conditioned, scalable internet \nservices. In Proc. SOSP (2001).  \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Building distributed systems is particularly difficult because of the asynchronous, heterogeneous, and failure-prone environment where these systemsmust run. Tools for building distributed systems must strike a compromise between reducing programmer effort and increasing system efficiency. We present <i>Mace</i>, a C++ language extension and source-to-source compiler that translates a concise but expressive distributed system specification into a C++ implementation. Mace overcomes the limitations of low-level languages by providing a unified framework for networking and event handling, and the limitations of high-level languages by allowing programmers to write program components in a controlled and structured manner in C++. By imposing structure and restrictions on how applications can be written, Mace supports debugging at a higher level, including support for efficient model checking and causal-path debugging. Because Mace programs compile to C++, programmers can use existing C++ tools, including optimizers, profilers, and debuggers to analyze their systems.</p>", "authors": [{"name": "Charles Edwin Killian", "author_profile_id": "81452615019", "affiliation": "University of California: San Diego, La Jolla, CA", "person_id": "P871667", "email_address": "", "orcid_id": ""}, {"name": "James W. Anderson", "author_profile_id": "81330487442", "affiliation": "University of California: San Diego, La Jolla, CA", "person_id": "PP33032632", "email_address": "", "orcid_id": ""}, {"name": "Ryan Braud", "author_profile_id": "81331489344", "affiliation": "University of California: San Diego, La Jolla, CA", "person_id": "PP33033196", "email_address": "", "orcid_id": ""}, {"name": "Ranjit Jhala", "author_profile_id": "81100198278", "affiliation": "University of California: San Diego, La Jolla, CA", "person_id": "P343132", "email_address": "", "orcid_id": ""}, {"name": "Amin M. Vahdat", "author_profile_id": "81100104394", "affiliation": "University of California: San Diego, La Jolla, CA", "person_id": "P15975", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250755", "year": "2007", "article_id": "1250755", "conference": "PLDI", "title": "Mace: language support for building distributed systems", "url": "http://dl.acm.org/citation.cfm?id=1250755"}