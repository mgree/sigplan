{"article_publication_date": "06-10-2007", "fulltext": "\n Iterative Context Bounding for Systematic Testing of Multithreaded Programs Madan Musuvathi Shaz Qadeer \nMicrosoft Research {madanm,qadeer}@microsoft.com Abstract Multithreaded programs are dif.cult to get \nright because of un\u00adexpected interaction between concurrently executing threads. Tra\u00additional testing \nmethods are inadequate for catching subtle con\u00adcurrency errors which manifest themselves late in the \ndevelop\u00adment cycle and post-deployment. Model checking or systematic exploration of program behavior \nis a promising alternative to tra\u00additional testing methods. However, it is dif.cult to perform sys\u00adtematic \nsearch on large programs as the number of possible pro\u00adgram behaviors grows exponentially with the program \nsize. Con\u00adfronted with this state-explosion problem, traditional model check\u00aders perform iterative depth-bounded \nsearch. Although effective for message-passing software, iterative depth-bounding is inadequate for multithreaded \nsoftware. This paper proposes iterative context-bounding, a new search algorithm that systematically \nexplores the executions of a multi\u00adthreaded program in an order that prioritizes executions with fewer \ncontext switches. We distinguish between preempting and nonpre\u00adempting context switches, and show that \nbounding the number of preempting context switches to a small number signi.cantly allevi\u00adates the state \nexplosion, without limiting the depth of explored ex\u00adecutions. We show both theoretically and empirically \nthat context\u00adbounded search is an effective method for exploring the behaviors of multithreaded programs. \nWe have implemented our algorithm in two model checkers and applied it to a number of real-world mul\u00adtithreaded \nprograms. Our implementation uncovered 9 previously unknown bugs in our benchmarks, each of which was \nexposed by an execution with at most 2 preempting context switches. Our ini\u00adtial experience with the \ntechnique is encouraging and demonstrates that iterative context-bounding is a signi.cant improvement \nover existing techniques for testing multithreaded programs. Categories and Subject Descriptors D.2.4 \n[Software Engineer\u00ading]: Software/Program Veri.cation formal methods, validation; F.3.1 [Logics and \nMeanings of Programs]: Specifying and Veri\u00adfying and Reasoning about Programs mechanical veri.cation, \nspeci.cation techniques; D.2.5 [Software Engineering]: Testing and Debugging debugging aids, diagnostics, \nmonitors, tracing General Terms Algorithms, Reliability, Veri.cation Keywords Concurrency, context-bounding, \nmodel checking, multi\u00adthreading, partial-order reduction, shared-memory programs, soft\u00adware testing Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 07 June 11 \n13, 2007, San Diego, California, USA. Copyright c . 2007 ACM 978-1-59593-633-2/07/0006. . . $5.00. 1. \nIntroduction Multithreaded programs are dif.cult to get right. Speci.c thread interleavings, unexpected \neven to an expert programmer, lead to crashes that occur late in the software development cycle or even \nafter the software is released. The traditional method for testing concurrent software in the industry \nis stress-testing,in which the software is executed under heavy loads with the hope of producing an erroneous \ninterleaving. Empirical evidence clearly demonstrates that this form of testing is inadequate. Stress-testing \ndoes not pro\u00advide any notion of coverage with respect to concurrency; even after executing the tests \nfor days the fraction of explored schedules re\u00admains unknown and likely very low. A promising method \nto address the limitations of traditional testing methods is model checking [2, 21] or systematic exploration \nof program behavior. A model checker systematically executes each thread schedule, while verifying that \neach execution main\u00adtains desired properties of the program. The fundamental problem in applying model \nchecking to large programs is the well-known state-explosion problem, i.e., the number of possible program \nbe\u00adhaviors grows explosively (at least exponentially) with the size of the program. To combat the state-explosion \nproblem, researchers have inves\u00adtigated reduction techniques such as partial-order reduction [9] and \nsymmetry reduction [13, 12]. Although these reduction techniques help in controlling the state explosion, \nit remains practically im\u00adpossible for model checkers to fully explore the behaviors of large programs \nwithin reasonable resources of memory and time. For such large programs, model checkers typically resort \nto heuristics to maximize the number of errors found before running out of re\u00adsources. One such heuristic \nis depth-bounding [22], in which the search is limited to executions with a bounded number of steps. \nIf the search with a particular bound terminates, then it is repeated with an increased bound. Unlike \nother heuristics for partial state\u00adspace search, depth-bounded search provides a valuable coverage metric \nif search with depth-bound d terminates then there are no errors in executions with at most d steps. \nSince the number of possible behaviors of a program usu\u00adally grows exponentially with the depth-bound, \niterative depth\u00adbounding runs out of resources quickly as the depth is increased. Hence, depth-bounding \nis most useful when interesting behaviors of the program, and therefore bugs, manifest in small number \nof steps from the initial state. The state space of message-passing software has this property which \naccounts for the success of model checking on such systems [10, 16]. In contrast, depth-bounding does \nnot work well for multithreaded programs, where the threads in the program have .ne-grained interaction \nthrough shared mem\u00adory. While a step in a message-passing system is the send or receive of a message, \na step in a multithreaded system is a read or write of a shared variable. Typically, several orders of \nmagnitude more steps are required to get interesting behavior in a multithreaded program than in a message-passing \nprogram. This paper proposes a novel algorithm called iterative context\u00adbounding for effectively searching \nthe state space of a multi\u00adthreaded program. In an execution of a multithreaded program, a context switch \noccurs when a thread temporarily stops execu\u00adtion and a different thread starts. The iterative context-bounding \nalgorithm bounds the number of context switches in an execution. However, a thread in the program can \nexecute an arbitrary num\u00adber of steps between context switches, leaving the execution depth unbounded. \nFurthermore, the iterative context-bounding algorithm distin\u00adguishes between two kinds of context switches \n preempting and nonpreempting. A preempting context switch, or simply a preemp\u00adtion, occurs when the \nscheduler suspends the execution of the run\u00adning thread at an arbitrary point. This can happen, for instance, \nat the expiration of a time slice. On the other hand, a nonpreempting context switch occurs when the \nrunning thread voluntarily yields its execution, either at termination or when it blocks on an unavailable \nresource. The algorithm bounds the number of preemptions while leaving the number of nonpreempting context \nswitches unbounded. Limiting the number of preemptions has many powerful and de\u00adsirable consequences \nfor systematic state-space exploration of mul\u00adtithreaded programs. First, bounding the number of preemptions \ndoes not restrict the ability of the model checker to explore deep in the state space. This is due to \nthe fact that, starting from any state, it is always possible to drive a terminating program to completion \n(or to a deadlock state) without incurring a preemption. As a result, a model checker is able to explore \ninteresting program behaviors, even with a bound of zero! Second, we show (Section 2) that for a .xed \nnumber of preemp\u00adtions, the total number of executions in a program is polynomial in the number of steps \ntaken by each thread. This theoretical upper bound makes it practically feasible to scale systematic \nexploration to large programs without sacri.cing the ability to go deep in the state space. Finally, \niterative context-bounding has the important property that it .nds a trace with the smallest number of \npreemptions expos\u00ading the error. As most of the complexity of analyzing a concurrent error-trace arises \nfrom the interactions between the threads, the al\u00adgorithm naturally seeks to provide the simplest explanation \nfor the error. Moreover, when the search runs out of resources after explor\u00ading all executions with c \npreemptions, the algorithm guarantees that any error in the program requires at least c+1 preemptions. \nIn ad\u00addition to providing a valuable coverage metric, it also provides the programmer with an estimate \nof the complexity of bugs remaining in the system and the probability of their occurrence in practice. \nWe present our iterative context-bounding algorithm in Sec\u00adtion 3. To evaluate our algorithm, we implemented \nit in two model checkers, ZING and CHESS.ZING is an explicit-state model checker for concurrent programs \nspeci.ed in the ZING modeling language. CHESS is a stateless model checker that executes the pro\u00adgram \ndirectly, much along the lines of Verisoft [10], but designed for shared-memory multithreaded programs. \nAn important aspect of the CHESS implementation is its dy\u00adnamic partitioning of the set of program variables \ninto data and synchronization variables. Typical programs use synchronization variables, such as locks, \nevents, and semaphores, to ensure that there are no data-races on the data variables. Motivated by this \nob\u00adservation, CHESS introduces context switches only at accesses to synchronization variables and veri.es \nthat accesses to data vari\u00adables are ordered by accesses to synchronization variables in each explored \nexecution. In Section 3.1, we provide theoretical justi.ca\u00adtion for the soundness of this approach. Our \nevaluation (Section 4) provides empirical evidence that a small number of preemptions is suf.cient to \nexpose nontrivial con\u00adcurrency bugs. Our implementation uncovered 9 previously un\u00adknown bugs in several \nreal-world multithreaded programs. Each of these bugs was exposed by an execution with at most 2 pre\u00ademptions. \nAlso, for a set of programs for which complete search is possible, we show that few preemptions are suf.cient \nto cover most of the state space. This empirical evidence strongly suggests that when faced with limited \nresources, which is invariably the case with model checkers, focusing on the polynomially-bounded and \npotentially bug-yielding executions with a small preemption bound is a productive search strategy. In \nsummary, the technical contributions of the paper are as follows: The notion of iterative context-bounding \nand the concomitant argument that bounding the number of preemptions is superior to bounding the depth \nas a strategy for systematic exploration of multithreaded executions.  A combinatorial argument that \nfor a .xed number of preemp\u00adtions, the number of executions is polynomial in the total num\u00adber of steps \nexecuted by the program.  An iterative context-bounding algorithm that systematically enumerates program \nexecutions in increasing order of preemp\u00adtions.  Empirical evidence that context-bounded executions \nexpose in\u00adteresting behavior of the program, even when the number of preemptions is bounded by a small \nnumber.   2. Iterative context-bounding In the view of this paper, model checking a multithreaded pro\u00adgram \nis analogous to running the system on a nondeterministic scheduler and then systematically exploring \neach choice made by the scheduler. Each thread in the program executes a sequence of steps with each \nstep involving exactly one access to a shared vari\u00adable. After every step of the currently running thread, \nthe sched\u00aduler is allowed to choose the next thread to schedule. As a result, the number of possibilities \nexplodes exponentially with the num\u00adber of steps. To make this point concretely, suppose P is a termi\u00adnating \nmultithreaded program. Let P have n threads where each thread executes at most k steps of which at most \nb are potentially\u00adblocking. Then the total number of executions of P may be as large as (nk)! = (n!)k, \na dependence that is exponential in both (k!)n n and k. For most programs, although the number of threads \nmay be small, the number of steps performed by a thread is very large. Therefore, the exponential dependence \non k is especially problem\u00adatic. All previous heuristics for partial state-space search, including depth-bounding, \nsuffer from this problem. The fundamental and novel contribution of context-bounding is that it limits \nthe number of scheduler choices without limiting the depth of the execution. A context switch occurs \nat a schedule point if the scheduler chooses a thread different from the current running thread. This \ncontext switch is preempting if the running thread is enabled at the schedule point, otherwise it is \nnonpreempting. In context-bounding, we bound the number of preempting con\u00adtext switches (or preemptions) \nbut leave the number of nonpreempt\u00ading context switches unconstrained. It is very important to note that \nthe scheduler has a lot more choices in inserting preemptions it can choose any one of the n.k steps \nto preempt, and for each choice the scheduler can choose any of the enabled threads to run. In con\u00adtrast, \na nonpreempting context is forced on the scheduler when the running thread yields its choice is limited \nto deciding the next enabled thread to run. First, the number of steps within each context remains unbounded. \nTherefore, unlike depth-bounding there is no bound on the exe\u00adcution depth. Second, since the number \nof nonprempting context switches remains unbounded it is possible to get a complete termi\u00ad 80 90 70 \nnating execution even with a bound of zero. For instance, such a Covered 60 terminating execution can \nbe obtained from any state by schedul\u00ad e ing each thread in a round-robin fashion without preemption. \nThese 50Spac two observations clearly indicate that context bounding does not af\u00ad % State 40 fect the \nability of the search to go deep into the state space. 30 We show below that the number of executions \nof P with at most c preemptions is polynomial in k but exponential in c. An exponen\u00ad 20 tial dependence \non c is signi.cantly better than an exponential de\u00ad 10 pendence on k because k is much greater than \nc. Moreover, many 0 concurrency bugs are manifested when threads are preempted at 0 1 2 3 4 5 6 7 8 \n9 10 11 12 13 unexpected places. With this polynomial bound, it becomes feasi- Context Bound ble to apply \ncontext-bounded search to large programs, at least for small values of c. Figure 1. Coverage graph Let \nxCy denote the number of ways of choosing y objects out of aset of x objects. There are two important \nfacts to note about context-bounding. 100 THEOREM 1. Consider a terminating program P with n threads, \n1000000 where each thread executes at most k steps of which at most b are potentially-blocking. Then \nthere are at most nkCc(nb + c)! executions of P with c preemptions. 100000 PROOF. The length of each \nexecution of P is bounded by nk. Therefore, there are are at most nk points where a preemption can occur \nand at most nkCc ways of selecting c preemptions from these # States Exxplored icb 10000 dfs nk points. \nOnce the c preemptions have been chosen, we have a maximum of nb + c execution contexts which can be \narranged in at most (nb+c)! ways. Thus, we get the upper bound of nkCc(nb+c)! executions with c preemptions. \n0 Assuming that c is much smaller than both k and nb, the bound given in the theorem above is simpli.ed \nto (nk)c(nb)c(nb)! = (n 2kb)c(nb)!. This bound remains exponential in c, n,and b,but each of these values \nis signi.cantly smaller than k, with respect to which this bound is polynomial. It is also interesting \nto simplify this bound further for non-blocking multithreaded programs. In such programs, the only blocking \naction performed by a thread is the .ctitious action representing the termination of the thread. Therefore \nb =1 and the bound becomes (n 2k)c n!. 2.1 Empirical argument random db:40 db:20 1000 100 1 3 5 7 9 11 \n13 15 17 19 21 23 25 # Executions (x1000) Figure 2. Coverage growth with eleven preemptions although \nthe program has executions with at least 35 preemptions (see Table 1). Second, 90% state coverage is \nachieved within a context-switch bound of eight. These observa- To evaluate the ef.cacy of iterative \ncontext-bounding in exposing concurrency errors, we have implemented the algorithm and used it tions \nindicate that iterative context-bounding is good at achieving to test several real-world programs. We \ndescribe our evaluation in high coverage within bounds that are signi.cantly smaller than the detail \nin Section 4. Here we give a brief preview of the performance maximum number of possible preemptions. \nof our algorithm on an implementation [15] of a work-stealing Finally, we also compared the variation \nof coverage with time queue algorithm [8]. This implementation represents the queue for various methods \nof state-space search. Figure 2 plots the num\u00ad using a bounded circular buffer which is accessed concurrently \nby ber of distinct visited states on the y-axis against the number of ex\u00ad two threads in a non-blocking \nmanner. The implementor gave us the ecutions explored by different methods. Note that the y-axis is on \na test harness along with three variations of his implementation, each logarithmic scale. There are .ve \ncurves in the graph corresponding containing what he considered to be a subtle bug. The test harness \nto iterative context-bounding (icb), unbounded depth-.rst search has two threads that concurrently call \nfunctions in the work-stealing (dfs), random search (random), depth-.rst search with depth\u00ad queue API. \nOur model checker based on iterative context-bounding bound 40 (db:40), and depth-.rst search with depth-bound \n20 found each of those bugs within a context-switch bound of two. (db:20). As is evident from the graph, \niterative context-bounding We plotted the coverage graph for this implementation of the achieves signi.cantly \nbetter coverage at a faster rate compared to work-stealing queue. Unlike syntactic notions of coverage \nsuch as the other methods. In Section 4, we present a more detailed discus\u00ad line, branch or path coverage, \nwe have chosen the number of dis\u00adtinct visited states as our notion of coverage. We believe that state \nsion of the various graphs presented here.  3. Algorithm coverage is the most appropriate notion of \ncoverage for semantics\u00ad based safety checkers such as our model checker. Figure 1 plots In this section, \nwe describe an algorithm that effectively searches the fraction of reachable states covered on the y-axis \nagainst the the state space of a program by systematically bounding the number context-switch bound on \nthe x-axis. There are several interesting of preemptions. The algorithm takes as input the initial state \ns0, facts about this coverage graph. First, full state coverage is achieved and iteratively explores \nexecutions with increasing preemptions. In Input: initial state s0 .State 1 struct WorkItem {State state; \nTid tid; } 2 Queue(WorkItem)workQueue; 3 Queue(WorkItem)nextWorkQueue; 4 WorkItem w; 5 int currBound \n:= 0; 6 for t .enabled(s0)do 7 workQueue.Add(WorkItem (s0,t)); 8 end 9 while true do 10 while \u00acworkQueue.Empty() \ndo 11 w := workQueue.Front(); 12 workQueue.Pop(); 13 Search(w); 14 end 15 if nextWorkQueue.Empty() then \n 16 Exit(); 17 end 18 currBound := currBound +1; 19 workQueue:= nextWorkQueue; 20 nextWorkQueue.Clear(); \n21 end 22 Search(WorkItem w) begin 23 WorkItem x; 24 State s; 25 s := w.state.Execute(w.tid); 26 if \nw.tid .enabled(s)then 27 x := WorkItem(s, w.tid); 28 Search(x); 29 for t .enabled(s)\\{w.tid}do 30 x \n:= WorkItem(s, t); 31 nextWorkQueue.Push(x); 32 end 33 else 34 for t .enabled(s)do 35 x := WorkItem(s, \nt); 36 Search(x); 37 end 38 end 39 end Algorithm 1: Iterative context bounding algorithm other words, \nfor any i =0, the algorithm explores every execution with i preemptions before exploring any execution \nwith i +1 preemptions. This algorithm can be trivially modi.ed to stop when a particular preemption bound \nis reached. We now present a detailed description of the algorithm. The algorithm maintains two queues \nof work items. Each work item w contains a state and a thread identi.er and noti.es the model checker \nto schedule the thread w.tid from the state w.state. The variable workQueue contains work items that \ncan be ex\u00adplored within the current preemption bound set in the variable currBound. During this exploration, \nthe model checker inserts work items requiring an extra preemption into nextWorkQueue, postponing the \nprocessing of such work items after the exploration of the states within the current preemption bound. \nIn lines 6 8, workQueue is initialized with work items cor\u00adresponding to the initial state. One work \nitem is created for each thread enabled in the initial state. The loop in lines 10 14 removes a work \nitem from the queue, and invokes the procedure Search on it. Whenever control reaches line 15, the algorithm \nguarantees that all executions with at most currBound preemptions have been executed. In lines 15 20, \nthe algorithm continues the execution of work items in nextWorkQueue, if any, after incrementing the \ncurrBound. The recursive procedure Search processes a work item w and recursively explores all states \nreachable without introducing any preemptions. In line 25, the procedure executes the thread w.tid in \nw.state till the next scheduling point. In order to explore every behavior of the program, it is necessary \nto insert a scheduling point after each access to a shared variable. Essentially, this forces a thread \nto execute at most one shared-variable access in every step. Section 3.1 provides an improved strategy \nfor introducing scheduling points. If w.tid is enabled in the state s (line 26), the algorithm sched\u00adules \nw.tid for another step by calling Search recursively in line 28. At the same time, scheduling some other \nthread enabled in s re\u00adsults in a preemption of w.tid. In lines 29 32, the algorithm cre\u00adates a work \nitem for every such thread and inserts the item in the nextWorkQueue. If the thread w.tid is not enabled \nin s,then w.tid voluntarily yielded control in s. Therefore, the algorithm is free to schedule any enabled \nthread without incurring the cost of a preemption. The loop in lines 34 36 accomplishes this by creating \na work item for every enabled thread in s and calling Search on each one of them. State caching is orthogonal \nto the idea of context-bounding; our algorithm may be used with or without it. In fact, we have im\u00adplemented \nour algorithm in two different model checkers ZING, which caches states and CHESS, which does not cache \nstates. The description in this section has ignored the issue of state caching. It is easy enough to \nadd that feature by introducing a global variable: Set(WorkItem)table; The variable table is initialized \nto the empty set. We also add the following code at the very beginning of Search to prune the search \nif a state is revisited. if table.Contains(w)then return; end table.Add(w); 3.1 Strategy for introducing \npreemptions During program execution, the scheduler can preempt the current running thread at an arbitrary \npoint. Subtle concurrency errors arise when such preemptions occur exactly when the running thread temporarily \nviolates a global program invariant and subsequent threads require this invariant for correct execution. \nTo .nd such errors, the algorithm presented above schedules each thread for a single step, enabling a \npreemption opportunity after every access to a shared variable. In this section, we show that it is suf.cient \nto insert a schedul\u00ading point before a synchronization operation in the program, pro\u00advided the algorithm \nalso checks for data-races [1]. By scheduling all variable access between two synchronization operations \natomi\u00adcally, the algorithm signi.cantly reduces the state space explored. In addition, exploring this \nreduced state space is sound and the al\u00adgorithm does not miss any errors in the program. This strategy \nis essentially a kind of partial-order reduction [9, 18] and was .rst proposed in the form above by Bruening \nand Chapin [1]. Our con\u00adtribution here is in showing that this reduction is sound when per\u00adforming a \ncontext-bounded search. The formal soundness proof is fairly involved and is provided in Appendix A. \nWe only provide a high-level description of the proof in this section. Let us .x a multithreaded program \nfor the remainder of this sec\u00adtion. All the de.nitions and theorems that follow are with respect to this \nprogram. An execution a is a nonempty sequence of steps a(1),a(2),..., where a(i) is the identi.er of \nthe thread executing the ith step, for i = 1. We assume that each step in an execution accesses exactly \none variable. We denote by |a| the length of a. We assume that thread scheduling is the only source of \nnondeterminism in the program. Therefore, by executing a from the initial state of the program, we arrive \nat a unique state. Let enabled(a) denote the set of threads enabled in this state. The execution a is \nterminating if enabled(a)= \u00d8.Let L(a) be the thread executing the last step of a,and let V (a) be the \nvariable accessed by L(a) at the last step. Also, for t . enabled(a),let NV (a, t) be the variable thread \nt will access if scheduled from the state obtained by executing a. For all i . [1, |a|],we de.ne a|i \nto be the pre.x of a whose length is i. Note that a pre.x of an execution is also an execution. Given \nan execution a, the execution a \u00b7 \u00df is obtained by executing steps in \u00df from the state obtained by executing \na. Let SyncVar be the set of synchronization variables that the threads in the program use to communicate \nwith one another. All variables that are not in SyncVar belong to DataVar ,the setof data variables. \nOur implementation dynamically infers the vari\u00adables in SyncVar . We also assume that a thread in the \nprogram blocks only on accesses to synchronization variables. Given an execution a \u00b7 t, we say that a \npreemption occurred at a \u00b7 t if the last thread in a is enabled in a and is different from t. In this \ncase, the scheduler preempted the execution of L(a) and scheduled the thread t. Let the number of preemptions \nin a be denoted by NP(a). A preemption at a \u00b7 t occurs at an access to a synchronization variable if \nNV (a, L(a)) . SyncVar.In other words, the thread L(a) was preempted right before an access to a synchronization \nvariable. An execution is observable if all preemptions occur at accesses to synchronization variables. \nNote that if a model checker introduces preemptions only at accesses to synchronization variables, then \nit can explore only observable executions and detect observable races. Two steps a(i) and a(j) in an \nexecution a are dependent if they are either executed by the same thread or if they access the same synchronization \nvariable. Otherwise the two steps are independent. Given two dependent steps a(i) and a(j), a(i) happens \nbefore a(j) if i<j.The happens-before relation of an execution a, denoted by HB(a), is the transitive \nclosure of the happens-before ordering of all dependent steps in the execution. It is easy to see that \nHB(a) de.nes a partial-order on the steps of a. An execution is race-free if any two accesses to the \nsame data variable in a are ordered by HB(a). Two race-free executions a and \u00df are equivalent if HB(a)= \nHB(\u00df). Intuitively, two equivalent executions differ only on the order of independent steps and therefore \nresult in the same .nal state. A pair (a, t) is a race if a is race-free but a \u00b7 t is not. A race (a, \nt) is observable if a is an observable execution and L(a)= t. THEOREM 2. A terminating race-free execution \na is equivalent to an observable terminating race-free execution \u00df such that NP(\u00df) = NP(a). PROOF. Starting \nfrom a, the proof constructs a linearization \u00df of the partial-order HB(a) such that all preemptions in \n\u00df occur at accesses to synchronization variables. By construction, \u00df is equivalent to a. The key dif.culty \nin the proof is in showing that NP(\u00df) = NP(a). To do so, the proof constructs \u00df iteratively by changing \nthe order of two independents steps in a in such a way that the number of preemptions does not increase \nin each iteration. The details of this construction is presented in Appendix A. 0 THEOREM 3. If there \nis a race (a, t), then there is an observable race (\u00df, u) such that NP(\u00df) = NP(a). PROOF. The proof of \nthis theorem is similar to the proof of Theo\u00adrem 2 and relies on iteratively constructing \u00df from a without \nin\u00adcreasing the number of preemptions. The details are presented in Appendix A. 0 Theorem 3 allows us \nto conclude that for any context-bound c,if all observable executions a with NP(a) = c are race-free \nthen all executions \u00df (both observable and otherwise) with NP(\u00df) = c are also race-free. Thus, if no \nraces are reported on observable executions up to the bound c, then indeed the program is race-free up \nto the bound c. Finally, Theorem 2 allows us to to verify the absence of all errors expressible as predicates \non terminating states by evaluating only the observable executions. This is a broad class of errors including \nboth deadlocks and assertion failures.  4. Empirical evaluation We implemented the iterative-context \nbounding algorithm in two model checkers and evaluated the algorithm on a few realistic benchmarks. This \nsection describes our evaluation and the results. We now give brief descriptions of these two model checkers. \nZING has been designed for verifying models of concurrent soft\u00adware expressed in the ZING modeling language. \nThe models may be created manually or automatically using other tools. Currently, there exist translators \nfrom subsets of C# and X86 assembly code into the ZING modeling language. ZING is an explicit-state model \nchecker; it performs depth-.rst search with state caching. It main\u00adtains the stack compactly using state-delta \ncompression and per\u00adforms state-space reduction by exploiting heap-symmetry. CHESS is meant for verifying \nconcurrent programs directly and does not require a model to be created. Similar to the Verisoft [10] \nmodel checker, CHESS is stateless and runs program executables directly. However, Verisoft was designed \nfor message-passing soft\u00adware whereas CHESS is designed to verify shared-memory multi\u00adthreaded software. \nSince CHESS does not cache states, it expects the input program to have an acyclic state space and terminate \nunder all possible thread schedules. The ZING model checker de\u00adscribed earlier has no such restriction \nand can handle both cyclic and acyclic state spaces. CHESS introduces context switches only at accesses \nto synchronization variables, while using the Goldilocks algorithm [4] to check for data-races in each \nexecution. As shown in Section 3.1, this methodology is sound while signi.cantly in\u00adcreasing the effectiveness \nof the state space exploration. 4.1 Benchmarks We evaluated the iterative context-bounding algorithm \non a set of benchmark programs. Each program is an open library, requiring a test driver to close the \nsystem. The test driver allocates threads that concurrently call interesting sequences of library functions \nwith appropriate inputs. The input program together with the test driver forms a closed system that is \ngiven to the model checker for systematically exploring the behaviors. For the purpose of our experiments, \nwe assume that the only nondeterminism in the input program and the test driver is that induced by the \nscheduler, which the model checker controls. Obviously, a model checker can only explore behaviors of \nthe program triggered by the test driver. The quality of the state space search, and thus the bugs found \ndepends heavily upon good test drivers. When available, we used existing concurrent test cases for our \nexperiments. For programs with no existing test cases, we wrote our own drivers that, to our best knowledge, \nexplored interesting Table 1. Characteristics of the benchmarks. For each benchmark, this table reports \nthe number of lines, the number of threads allo\u00adcated by the test driver. For an execution, K is the \ntotal number of steps, B is the number of blocking instructions, and c is the num\u00adber of preemptions. \nThe table reports the maximum values of K, B,and c seen during our experiments. Programs LOC Max Num \nThreads Max K Max B Max c Bluetooth File System Model Work Stealing Q. APE Dryad Channels 400 84 1266 \n18947 16036 3 4 3 4 5 15 20 99 247 273 2 8 2 2 4 8 13 35 75 167 Bugs with Total Context Bound Programs \nBugs 0 1 2 3 Bluetooth 1 0 1 0 0 Work Stealing Queue 3 0 1 2 0 Transaction Manager 3 0 0 2 1 APE 4 2 \n1 1 0 Dryad Channels 5 1 4 0 0 Table 2. For a total of 14 bugs that our model checker found. this table \nshows the number of bugs exposed in executions with exactly c preemptions, for c ranging from 0 to 3.The \n7 bugs in the .rst three programs were previously known. Iterative context-bounding algorithm found the \n9 previously unknown bugs in Dryad and APE. behavior in the system. Comprehensively closing an open system \nto expose most of the bugs in the system is a challenging problem, beyond the scope of this paper. We \nprovide a brief description of the programs used for our evaluation below. Bluetooth: This program is \na sample Bluetooth Plug and Play (PnP) driver modi.ed to run as a library in user space. The sample driver \ndoes not contain hardware-speci.c code but captures the synchronization and logic required for basic \nPnP functionality. We wrote a test driver with three threads that emulated the scenario of the driver \nbeing stopped when worker threads are performing operations on the driver. File system model: This is \na simpli.ed model of a .le system derived used in prior work (see Figure 7 in [7]). The program emulates \nprocesses creating .les and thereby allocating inodes and blocks. Each inode and block is protected by \na lock. Work-stealing queue: This program is an implementation [15] of the work-stealing queue algorithm \noriginally designed for the Cilk multithreaded programming system [8]. The program has a queue of work \nitems implemented using a bounded circular buffer. Our test driver consists of two threads, a victim \nand a thief, that concurrently access the queue. The victim thread pushes work items to and pops them \nfrom the tail of the queue. The thief thread steals work items from the head of the queue. Potential \ninterference between the two threads is controlled by means of sophisticated non-blocking synchronization. \nAPE: APE is an acronym for Asynchronous Processing En\u00advironment. It contains a set of data structures \nand functions that provide logical structure and debugging support to asynchronous multithreaded code. \nAPE is currently used in the Windows operat\u00ading system. For our experiments, we compiled APE in user-mode \nand used a test driver provided by the implementor of APE. In the test, the main thread initializes APE \ns data structures, creates two // Function called by a worker thread // of RChannelReaderImpl void RChannelReaderImpl::AlertApplication( \nRChannelItem* item) { // Notify Application // XXX: Preempt here for the bug // Note: this == channel \nvariable in TestChannel EnterCriticalSection(&#38;m_baseCS); // process before exit LeaveCriticalSection(&#38;m_baseCS); \n} // Function called by the main thread void TestChannel(WorkQueue* workQueue, ...) { // Creating a channel \nallocates worker threads RChannelReader* channel = new RChannelReaderImpl(..., workQueue); // ... do \nwork here channel->Close(); // wrong assumption that channel->Close() waits // for worker threads to \nbe finished delete channel; // BUG: deleting the channel when // worker threads still have a valid reference \n// to the channel } Figure 3. Use after free bug in Dryad. The bug requires a context switch to happen \nright before the call to EnterCriticalSection in AlertApplication. This is the only preempting context \nswitch. The bug trace CHESS found involves 6 nonpreempting context switches. worker threads, and .nally \nwaits for them to .nish. The worker threads concurrently exercise certain parts of the interface provided \nby APE. Dryad channels: Dryad is a distributed execution engine for coarse-grained data-parallel applications \n[14]. A Dryad application combines computational vertices with communication chan\u00adnels to form a data-.ow \ngraph. Dryad runs the application by executing the vertices of this graph on a set of available proces\u00adsors \ncommunicating as appropriate through .les, TCP pipes, and shared-memory FIFOs. The test harness for Dryad \nfor our exper\u00adiments was provided by its lead developer. The test has 5 threads and exercises the shared-memory \nchannel library used for commu\u00adnication between the nodes in the data-.ow graph. Transaction manager: \nThis program provides transactions in a system for authoring web services on the Microsoft .NET platform. \nInternally, the in-.ight transactions are stored in a hashtable, access to which is synchronized using \n.ne-grained locking. We used ex\u00adisting test harnesses written by our colleagues for our experiments. \nEach test contains two threads. One thread performing an operation create, commit, or delete on a transaction. \nThe second thread is a timer thread that periodically .ushes from the hashtable all pending transactions \nthat have timed out. Except for the transaction manager, all the benchmarks used above are written in \na combination C and C++. Table 1 enumer\u00adates the characteristics of these benchmarks. The transaction \nman\u00ad  1000000 90 80 100 100000 70 % State Spa ce Covered 60 File System Model # States Covered icb \n5050 Bluetooth 10000 dfs 40 Transaction Manager idfs 100 idfs-100 idfs-200 idfs-150  Work Stealing \nQueue 30 20 10 0 0 1 2 3 4 5 6 7 8 910 11 12 13 Context Bound Figure 4. Figures shows the percentage \nof the entire state space (y axis) covered by executions with bounded number of preemptions (x axis). \nFor state spaces of programs small enough for our model checkers to completely search, the graph shows \nthat more than 90% of the state space is covered with executions with at most 8 preemptions. ager is \na ZING model constructed semi-automatically from the C# 1000 100 # Executions (x1000) Figure 5. Coverage \ngrowth for APE 1000000 100000 # Staates Covered implementation, and has roughly 7000 lines of code. \nIn the rest of the section, we will show that bounding the num\u00ad ber of preemptions is an effective method \nof exploring interesting behaviors of the system, while alleviating the state space explosion icb 10000 \n idfs-125 dfs dfs idfs-100 problem. Note, as described in Section 2, bounding the number of idfs-75 \n preemptions results in a state space polynomial in the number of 1000 steps in an execution. This allows \nus to scale systematic exploration techniques to larger programs. Speci.cally, we will use our experiments \nto demonstrate the 100 following two hypotheses: # Executions (x1000) 1. Many subtle bugs manifest themselves \nin executions with very small preemptions.  2. Most states can be covered with few preemptions Figure \n6. Coverage growth for Dryad  4.2 Small context bounds expose concurrency bugs Context bounding relies \non the intuition that many errors occur due to few context switches happening at the right places. To \nsubstan\u00adtiate this intuition, we ran the iterative context-bounding program for the .ve programs shown \nin Table 2. For the .rst three programs, namely Bluetooth, work-stealing queue, and the transaction man\u00adager, \nwe introduced 7 known bugs that the respective developers considered subtle concurrency errors. The iterative \ncontext bound\u00ading algorithm was able to .nd all such errors within a bound of 3. We also ran the iterative \ncontext-bounding algorithm on APE and Dryad, the largest programs currently handled by our model checker. \nWe found a total of 9 previously unknown concurrency errors. To provide the reader with an idea of the \ncomplexity of these errors, we describe one of the errors we found in Dryad below in detail. This error \ncould not be found by a depth-.rst search, even after running for a couple of hours. Dryad use-after-free \nbug: When deallocating a shared heap object, a concurrent program has to ensure that no existing thread \nin the system has a live reference to that object. This is a common concurrency problem that is very \nhard to get right. Figure 3 de\u00adscribes an error that requires only one preempting context switch, but \n6 nonpreempting context switches. The error involves a message channel, which contains a few worker threads \nthat process messages in the channel. When the function TestChannel calls the close function on the channel, \neach worker thread gets a STOP message, in response to which a worker thread calls the AlertApplication \nfunction, as part of its cleanup process. However, when there is an preempting context switch right before \nthe thread enters the m baseCS critical section, the main thread is able to return from the close function \nand subsequently delete the channel, which in this case is the current this pointer for the worker thread. \nThe use-after-free bug occurs when the worker thread is subsequently scheduled. When run with a context \nbound one, the iterative context-switch algorithm systematically tried its budgeted preempting context \nswitch at every step, and eventually found the small window in AlertApplication that found the error. \nIn contrast, a depth-.rst search is .ooded with an unbounded number of preemptions, and is thus unable \nto expose the error within reasonable time limits. 4.3 Few context bounds cover most states In the previous \nsection, we empirically showed that a small number of preemptions are suf.cient to expose concurrency \nerrors. In this section, we show that a fair percentage of state space is reached through executions \nwith few preemptions. Obviously, we are only able to demonstrate this on programs for which our model \ncheckers areableto complete the state space search. Figure 4 shows the cumulative percentage of the entire \nstate space covered by executions with increasing context bounds. The results for transaction manager \nbenchmark is from the ZING model checker, which is an explicit-state model checker. Thus, counting states \nis straightforward for this program. The remaining three pro\u00adgrams are executables run directly by the \nCHESS model checker. These programs make numerous calls to the synchronization prim\u00aditives provided by \nthe kernel. Capturing the state in this case would require accounting for this kernel state, apart from \nthe global vari\u00adables, the heap, and the stack. In fact, this dif.culty in captur\u00ading states of program \nexecutables is the main reason for design\u00ading CHESS as a stateless model checker. For these programs, \nwe use the happens-before relation of an execution, described in Sec\u00adtion 3.1 and formally de.ned in \nAppendix A, as a representation for the state at the end of the execution. Figure 4 shows that for both \nBluetooth and the .lesystem model, 4 preemptions are suf.cient to completely explore the en\u00adtire state \nspace. For the relatively larger transaction manager and the work-stealing queue benchmark, a context-bound \nof 6 and 8 re\u00adspectively are suf.cient to cover more than 90% of the state space. This strongly suggests \nthe advantage of iterative context bounding when systematically exploring the behavior of multithreaded \nprograms, model checkers can maximize state space coverage by focusing on the polynomial number of executions \nwith few pre\u00ademptions. For programs on which the model checker is unable to complete the state space \nsearch, we report the increase in the states visited by different search strategies. Figure 5 shows the \nnumber of states covered in the y axis with the number of complete executions of the program in the x \naxis for the APE benchmark. Figure 6 shows corresponding graph for the Dryad benchmark. These two graphs \ncompare the iterative context bounding algorithm with the depth\u00ad.rst (dfs) search strategy and the iterative \ndepth-bounding (idfs) strategy. For the idfs search, we selected different depth bounds and selected \nthe the depth bound with maximum, minimum, and median coverage. From the graph, it is very evident that \ncontext bounding is able to systematically achieve better state space cover\u00adage, even in the .rst 1000 \nexecutions.  5. Related work Context-bounding: The notion of context-bounding was intro\u00adduced by Qadeer \nand Wu [20] as a method for static analysis of concurrent programs by using static analysis techniques \ndeveloped for sequential programs. That work was followed by the theoret\u00adical result of Qadeer and Rehof \n[19] which showed that context\u00adbounded reachability analysis for concurrent boolean programs is decidable. \nOur work exploits the notion of context-bounding for systematic testing in contrast to these earlier \nresults which were fo\u00adcused on static analysis. The combinatorial argument of Section 2 and the distinction \nbetween preempting and nonpreempting context switches is a direct result of our focus on dynamic rather \nthan static analysis. State-space reduction techniques: Researchers have explored the use of partial-order \nreduction [9, 18, 17, 3] and symmetry reduction [13, 5, 12] to combat the state-space explosion prob\u00adlem. \nThese optimizations are orthogonal and complementary to the idea of context-bounding. In fact, our preliminary \nexperiments indicate that state-space coverage increases at an even faster rate when partial-order reduction \nis performed during iterative context\u00adbounding. Analysis tools: Researchers have developed many dynamic \nanalyses, such as data-race detection [23] and atomicity-violation detection [6], for .nding errors in \nmultithreaded software. Such analyses are again orthogonal and complementary to context\u00adbounding. They \nare essentially program monitors which can be applied to each execution explored by iterative context-bounding. \nHeuristic search: Confronted with limited computational re\u00adsources and large state spaces, researchers \nhave developed heuris\u00adtics for partial state-space search. Groce and Visser [11] pro\u00adposed the heuristic \nof prioritizing states with more enabled threads. Sivaraj and Gopalakrishnan [24] proposed the use of \na random walk through the search space. Unlike these heuristics, iterative context\u00adbounding provides \nan intuitive notion of coverage and a polynomial guarantee on the number of context-bounded executions. \n 6. Conclusions Model checking or systematic exploration of program behavior is a promising alternative \nto traditional testing methods for multi\u00adthreaded software. However, it is dif.cult to perform systematic \nsearch on large programs because the number of possible pro\u00adgram executions grows exponentially with \nthe length of the exe\u00adcution. Confronted with this state-explosion problem, traditional model checkers \nperform partial state-space search using techniques such as iterative depth-bounding. Although effective \nfor message\u00adpassing software, iterative depth-bounding is inadequate for multi\u00adthreaded software because \nseveral orders of magnitude more steps are required to get interesting behavior in a multithreaded program \nthan in a message-passing program. This paper proposes a novel algorithm called iterative context\u00adbounding \nfor effectively searching the state space of a multi\u00adthreaded program. Unlike iterative depth-bounding \nwhich gives pri\u00adority to executions with shorter length, iterative context-bounding gives priority to \nexecutions with fewer preemptions. We show that that by bounding the number of preemptions, the number \nof ex\u00adecutions becomes a polynomial function of the execution depth. Therefore, context-bounding allows \nsystematic exploration to scale to large programs without sacri.cing the ability to go deep in the state \nspace. We implemented iterative context-bounding in two model checkers and used our implementation to \nuncover 9 previously un\u00adknown bugs in realistic multithreaded benchmarks. Each of these bugs required \nat most 2 preemptions. Our experience with these benchmarks and other benchmarks with previously known \nbugs indicates that many bugs in multithreaded code are manifested in executions with a few preemptions. \nOur experiments also indicate that state coverage increases faster with iterative context-bounding than \nwith other search methods. Therefore, we believe that itera\u00adtive context-bounding signi.cantly improves \nupon existing search strategies. In future work, we would like to make our model checker even more scalable. \nWe believe that incorporating complementary state-reduction techniques, such as partial-order reduction, \ncould improve scalability. Yet another interesting direction for our work is to extend CHESS, which currently \nhandles user-mode programs written against the WIN32 API, to kernel-mode programs.  Acknowledgements \nWe would like to thank Michael Isard, Joseph Joy, and Daan Leijen for providing the benchmarks, and Iulian \nNeamtiu for helping with CHESS. We would like to thank Tom Ball and the anonymous reviewers for their \nfeedback on a prior version of this paper. References [1] Derek Bruening and John Chapin. Systematic \ntesting of multithreaded Java programs. Technical Report LCS-TM-607, MIT/LCS, 2000. [2] E. M. Clarke \nand E. A. Emerson. Synthesis of synchronization skeletons for branching time temporal logic. In Logic \nof Programs, LNCS 131, pages 52 71. Springer-Verlag, 1981. [3] Matthew B. Dwyer, John Hatcliff, Robby, \nand Venkatesh Prasad Ranganath. Exploiting object excape and locking information in partial-order reductions \nfor concurrent object-oriented programs. Formal Methods in System Design, 25:199 240, 2004. [4] Tayfun \nElmas, Shaz Qadeer, and Serdar Tasiran. Goldilocks: Ef.ciently computing the happens-before relation \nusing locksets. In FATES/RV 06: Formal Approaches to Testing and Runtime Veri.cation, volume 4262 of \nLecture Notes in Computer Science, pages 193 208. Springer-Verlag, 2006. [5] F. Allen Emerson and A. \nPrasad Sistla. Symmetry and model checking. Formal Methods in System Design, 9(1/2):105 131, August 1996. \n[6] C. Flanagan and S. N. Freund. Atomizer: A dynamic atomicity checker for multithreaded programs. In \nPOPL 04: Principles of Programming Languages, pages 256 267. ACM Press, 2004. [7] C. Flanagan and P. \nGodefroid. Dynamic partial-order reduction for model checking software. In POPL 05: Principles of Programming \nLanguages, pages 110 121. ACM Press, 2005. [8] Matteo Frigo, Charles E. Leiserson, and Keith H. Randall. \nThe implementation of the Cilk-5 multithreaded language. In PLDI 98: Programming Language Design and \nImplementation, pages 212 223. ACM Press, 1998. [9] Patrice Godefroid. Partial-Order Methods for the \nVeri.cation of Concurrent Systems: An Approach to the State-Explosion Problem. LNCS 1032. Springer-Verlag, \n1996. [10] Patrice Godefroid. Model checking for programming languages using Verisoft. In POPL 97: Principles \nof Programming Languages, pages 174 186. ACM Press, 1997. [11] Alex Groce and Willem Visser. Model checking \nJava programs using structural heuristics. In ISSTA 02: Software Testing and Analysis, pages 12 21, 2002. \n[12] Radu Iosif. Exploiting heap symmetries in explicit-state model checking of software. In ASE 01: \nAutomated Software Engineering, pages 254 261, 2001. [13] C. Norris Ip and David L. Dill. Better veri.cation \nthrough symmetry. Formal Methods in System Design, 9(1/2):41 75, 1996. [14] Michael Isard, Mihai Budiu, \nYuan Yu, Andrew Birrell, and Dennis Fetterly. Dryad: Distributed data-parallel programs from sequential \nbuilding blocks. Technical Report MSR-TR-2006-140, Microsoft Research, 2006. [15] Daan Leijen. Futures: \na concurrency library for C#. Technical Report MSR-TR-2006-162, Microsoft Research, 2006. [16] Madanlal \nMusuvathi, David Park, Andy Chou, Dawson R. Engler, and David L. Dill. CMC: A pragmatic approach to model \nchecking real code. In OSDI 02: Operating Systems Design and Implementation, pages 75 88, 2002. [17] \nRatan Nalumasu and Ganesh Gopalakrishnan. An ef.cient partial order reduction algorithm with an alternative \nproviso implementation. Formal Methods in System Design, 20(3):231 247, May 2002. [18] Doron Peled. Partial \norder reduction: Model-checking using representatives. In MFCS 96: Mathematical Foundations of Computer \nScience, pages 93 112. Springer-Verlag, 1996. [19] S. Qadeer and J. Rehof. Context-bounded model checking \nof concurrent software. In TACAS 05: Tools and Algorithms for the Construction and Analysis of Systems, \nvolume 3440 of Lecture Notes in Computer Science, pages 93 107. Springer-Verlag, 2005. [20] S. Qadeer \nand D. Wu. KISS: Keep it simple and sequential. In PLDI 04: Programming Language Design and Implementation, \npages 14 24. ACM Press, 2004. [21] J. Queille and J. Sifakis. Speci.cation and veri.cation of concurrent \nsystems in CESAR. In Fifth International Symposium on Program\u00adming, Lecture Notes in Computer Science \n137, pages 337 351. Springer-Verlag, 1981. [22] Stuart Russell and Peter Norvig. Arti.cial Intelligence: \nA Modern Approach (Second Edition). Prentice Hall, 2002. [23] Stefan Savage, Michael Burrows, Greg Nelson, \nPatrick Sobalvarro, and Thomas Anderson. Eraser: a dynamic data race detector for multithreaded programs. \nACM Transactions on Computer Systems, 15(4):391 411, 1997. [24] Hemanthkumar Sivaraj and Ganesh Gopalakrishnan. \nRandom walk based heuristic algorithms for distributed memory model checking. Electronic Notes in Theoretical \nComputer Science, 89(1), 2003. A. Appendix A.1 De.nitions The number of preemptions in a, denoted by \nNP(a),is de.ned recursively as follows: NP(t)=0 { NP(a) if t = L(a) . L(a). enabled(a) NP(a.t)= NP(a)+1 \notherwise The happens-before relation of an execution a, denoted by HB(a), is the transitive closure \nof the relation { (i, j) .{1,..., |a|} \u00d7 {1,..., |a|} | (i<j . ti = tj ) . (i<j . V (a|i)= V (a|j ) . \nV (a|j ) . SyncVar ) }. The execution a is race-free if and only if for all i, j . [1, |a|],if i<j and \nV (a|i)= V (a|j ) then (i, j) . HB(a). We assume that there is a special synchronization event vari\u00adable \net corresponding to each thread t. The .rst operation of t blocks on et until et is signaled by the parent \nof t in the operation that creates t. Thus, it is guaranteed that in any execution the .rst operation \nof any thread accesses a synchronization variable. Fur\u00adthermore, we also assume that a thread terminates \nby performing as its .nal operation a block on et that is never signaled. Thus, it is also guaranteed \nthat in the .nal state of any terminating execution all threads are accessing a synchronization variable. \nConsider an execution a, a thread t, and adatavariable d. We de.ne last(a, t) to be 0 if a(i) t for all \ni . [1, |a|]. = Otherwise, we de.ne last(a, t) to be the number i . [1, |a|] such that (1) a(i)= t,(2) \nV (a|i) . SyncVar , and (3) for all j . (i, |a|],if a(j)= t then V (a|j ) . DataVar.We de.ne last(a, \nd) to be 0 if V (a|i) d for all i . [1, |a|].Otherwise, = we de.ne last(a, d) to be the number i . [1, \n|a|] such that V (a|i)= d and V (a|j ) = d for all j . (i, |a|]. Apair (a, t) is a race if a is race-free, \nNV (a, t) . DataVar , and there exists i . [1, |a|] such that i = last(a, NV (a, t)), a(i) = t,and (i, \nlast(a, t)). HB(a). An execution a is k-nice if the following conditions hold: 1. For all i . [1, |a|), \neither a(i)= a(i +1) or V (a|i+1) . SyncVar. 2. There are exactly k threads in the set  {t | t . enabled(a) \n. t = L(a) . NV (a, t) . DataVar}. An observable execution is 0-nice. An execution is nice if it is k\u00adnice \nfor some k = 0. A race (a, t) is k-nice if a is k-nice and a(|a|)= t. A race is nice if it is k-nice \nfor some k = 0. A.2 Proofs LEMMA 1. If a is a nice execution, a \u00b7t is a race-free execution, and a \u00b7 \nt \u00b7 d is an execution, then there is a nice and race-free execution \u00df equivalent to a\u00b7t such that NP(\u00df \n\u00b7d)=NP(a\u00b7t\u00b7d). PROOF. If V (a\u00b7t).SyncVar or a(|a|)=t,then \u00df =a\u00b7t is nice and we are done. Otherwise V \n(a \u00b7t).DataVar and a(|a|)=t. Then, there exists i . [1, |a|)such that a(i)=t.Let l . [1, |a|) be such \nthat a(l)= t and a(j)= t for all j . (l, |a|].Let . be the nonempty sequence such that a = a|l \u00b7 ..Since \na \u00b7 t is race-free and V (a \u00b7t). DataVar, we know that a|l \u00b7t \u00b7. is an execution equivalent to a \u00b7 t.We \nlet \u00df = a|l \u00b7 t \u00b7 .. We know that both .(1) = t and .(|.|)= t.If t . enabled(a|l \u00b7 t), we have NP(\u00df)= \nNP(a|l \u00b7 .).If t . enabled(a|l \u00b7 t),we have NP(\u00df) < NP(a|l \u00b7 .). In either case, we have NP(\u00df) = NP(a|l \n\u00b7 .)= NP(a). In addition, since a(|a|)= t and t . enabled(a),we have NP(a)< NP(a \u00b7t). Therefore NP(\u00df)< \nNP(a \u00b7t).If d is empty, we are done. Otherwise, let d = u \u00b7d. for some d..We have NP(\u00df) = NP(\u00df \u00b7 u) = \nNP(\u00df)+1 and NP(a \u00b7 t) = NP(a \u00b7 t \u00b7 u) = NP(a \u00b7 t)+1. Therefore NP(\u00df \u00b7u)=NP(a \u00b7t \u00b7u).Since \u00df \u00b7u is equivalent \nto a \u00b7t \u00b7u,we conclude that NP(\u00df \u00b7u \u00b7d.)=NP(a \u00b7t \u00b7u \u00b7d.). 0 LEMMA 2. A race-free execution a is equivalent \nto a nice race-free execution \u00df such that NP(\u00df)=NP(a). PROOF. Let |a| = n. We construct a sequence of \nexecutions \u00df1,...,\u00dfn by repeated applications of Lemma 1. We let \u00df1 = a(1). For each i . [1,n), we obtain \n\u00dfi+1 is obtained by invoking Lemma 1 with a =\u00dfi, t =a(i +1),and d =a(i +2)\u00b7\u00b7\u00b7a(n). We let \u00df =\u00dfn. 0 THEOREM \n2. (Restatement) A terminating race-free execution a is equivalent to an observable terminating race-free \nexecution \u00df such that NP(\u00df)=NP(a). PROOF. By Lemma 2, we know that a is equivalent to a nice race-free \nexecution \u00df such that NP(\u00df) = NP(a).Since a is terminating, so is \u00df.If \u00df is k-nice for k> 0, then there \nexists i . [1, |\u00df|) such that \u00df(i)= \u00df(i +1)and NV (\u00df|i,\u00df(i)) . DataVar .Since \u00df is nice, we know that \nthread \u00df(i) is never scheduled after step i. Therefore NV (\u00df, \u00df(i)) . DataVar and \u00df(i).enabled(\u00df)which \nis a contradiction. Therefore \u00df is 0-nice. 0 LEMMA 3. If there is a race (a, t)such that a is nice, then \nthere is anicerace (\u00df, u)such that NP(\u00df)=NP(a). PROOF. Let NV (a, t)= d.Since d . DataVar and the .rst \naction of any thread accesses a synchronization variable, there exists i . [1, |a|]such that a(i)=t.Let \nl . [1, |a|]be such that a(l)=t and for all j . (l, |a|],we have a(j)=t.Since (a, t) is a race, we know \nthat last(a, d). [1,a], a(last(a, d))=t and therefore l =last(a, d). There are two cases: (l< last(a, \nd)): Since a is nice and a(l)=t =a(l+1),we have V (a|l+1) . SyncVar .Since V (a|last(a,d)) . DataVar,the \ninterval (l, last(a, d))is nonempty. Suppose n . (l, last(a, d)) is such that V (a|n+1)= d and for all \ni . (l, n],we have V (a|i)=d.Let \u00df =a|l \u00b7t\u00b7a(l+1)\u00b7\u00b7\u00b7a(n)and u =a(n+1). Then \u00df is nice and NP(\u00df) = NP(a|n) \n= NP(a).We have NV (a|l,t)=NV (a, t)=d. Therefore last(\u00df, d)=l +1.Since NV (a|n,u)= d,we have NV (\u00df, \nu)= d.Since V (\u00df|l+1) . DataVar , \u00df(l +1) =t,and a(i)=t for all i . [l +1,n],we have (l+1, last(\u00df, u)).HB(\u00df).Since \na is nice and V (a|n+1). DataVar ,we have a(n)= a(n +1) = u and consequently \u00df(|\u00df|)=u. Therefore (\u00df, \nu)is a nice race. (l> last(a, d)): Let \u00df =a|l.Since \u00df is a pre.x of a, we know that \u00df is nice, \u00df(|\u00df|)= \nt,and NP(\u00df) = NP(a).Since (a, t) is a race, we know that (last(a, d), last(a, t)) . HB(a).Since HB(\u00df) \n. HB(a),we have (last(a, d), last(a, t)) . HB(\u00df). We have last(a, d)= last(\u00df, d) and last(a, t)= last(\u00df, \nt). Therefore (last(\u00df, d),last(\u00df, t)). HB(\u00df). Finally NV (\u00df, t)= NV (a, t)=d, and we get that (\u00df, t)is \na nice race. 0 We de.ne a partial order .on nice executions as follows. Let a be a nice execution and \n. be the unique longest 0-nice pre.x of a. Let a = . \u00b7 d. Similarly, Let a. be a nice execution, .. be \nthe unique longest 0-nice pre.x of a.,and a. =.. \u00b7d..Now, a . a. iff |.|> |..|.|.|=|..|.|d|< |d.|. For \nterminating programs, the relation .is well-founded, that is, for every execution a there is a .nite \nsequence an .\u00b7\u00b7\u00b7 . a1 such that a1 =a and an is 0-nice. LEMMA 4. If there is a k-nice race (a, t)for \nsome k> 0,then there is a nice race (\u00df, u)such that \u00df .a and NP(\u00df)=NP(a). PROOF. Let . be the unique \nlongest 0-nice pre.x of a.Since k> 0, we know that . is a strict pre.x of a.Let l = |.| and x =a(l).If \n(.,x)is race, then we let \u00df =. and u =x.Since x = a(l)= .(l), (.,x)is a nice race. Since \u00df is 0-nice, \nwe have \u00df . a.Since \u00df is a pre.x of a,we have NP(\u00df)= NP(a). Otherwise, we have that (.,x)is not a race. \nLet d = NV (.,x). Then d .DataVar , x =a(i)for all i .(l, |a|],and x =t.There are two cases: (.j . (l, \n|a|].V (a|j )= d): Let n . [l, |a|) be such that V (a|n+1)= d and V (a|j )= d for all j . (l, n].Let \n\u00df = . \u00b7 x \u00b7 a(l +1)\u00b7\u00b7\u00b7a(n)and u = a(n +1).Then \u00df is nice and NP(\u00df) = NP(a|n) = NP(a). Moreover, . \u00b7 x \nis a pre.x of the unique longest 0-nice pre.x of \u00df. Therefore \u00df . a. We have NV (a|l,x)= NV (a, x)= d. \nTherefore last(\u00df, d)= l +1.Since NV (a|n,u)= d,we have NV (\u00df, u)= d.Since V (\u00df|l+1) . DataVar , \u00df(l +1) \n= x,and a(i)= x for all i . [l +1,n],we have (l +1, last(\u00df, u)). HB(\u00df).Since a is nice and V (a|n+1). \nDataVar,we have a(n)=a(n +1)=u and consequently \u00df(|\u00df|)=u. Therefore (\u00df, u)is a nice race. (.j . (l, |a|].V \n(a|j )= d): Let \u00df =. \u00b7x \u00b7a(l +1)\u00b7\u00b7\u00b7a(|a|) and u = t.Then \u00df is nice and NP(\u00df) = NP(a). Moreover, . \u00b7x \nis a pre.x of the unique longest 0-nice pre.x of \u00df. Therefore \u00df . a.Let e = NV (a, t)= NV (\u00df, t). There \nare two cases: d = e or d = e. Suppose d = e.Since V (\u00df|l+1) . DataVar , \u00df(l +1) = x, a(i)= x for all \ni . [l +1, |a|],and x = u, we have (l +1, last(\u00df, u)) . HB(\u00df). Suppose d = e.Since (a, t)is a race, we \nknow that (last(a, e),last(a, t)) . HB(a). Since \u00df contains a single additional event over a and this \nevent is an access of variable d = e by thread x = u, we get that (last(\u00df, e),last(\u00df, t)).HB(\u00df). Therefore \n(\u00df, u)is a race. Since . is a strict pre.x of a, we know that l< |a|. Therefore \u00df(|\u00df|)=u and we get that \n(\u00df, u)is a nice race. 0 THEOREM 3. (Restatement) If there is a race (a, t), then there is an observable \nrace (\u00df, u)such that NP(\u00df)=NP(a). PROOF. Suppose (a, t)is a race. Since a is race-free, by Lemma 2 we \nget a nice race-free execution a. such that NP(a.)= NP(a) and (a.,t)is a race. From the well-foundedness \nof .and repeated applications of Lemma 4, we obtain a .nite sequence of nice races (\u00df1,t1),..., (\u00dfn,tn)such \nthat (\u00df1,t1)=(a.,t), \u00dfn .\u00b7\u00b7\u00b7.\u00df1, NP(\u00dfn)= \u00b7\u00b7\u00b7 = NP(\u00df1),and \u00dfn is 0-nice. We let \u00df =\u00dfn and u =tn. 0  \n \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Multithreaded programs are difficult to get right because of unexpected interaction between concurrently executing threads. Traditional testing methods are inadequate for catching subtle concurrency errors which manifest themselves late in the development cycle and post-deployment. Model checking or systematic exploration of program behavior is a promising alternative to traditional testing methods. However, it is difficult to perform systematic search on large programs as the number of possible program behaviors grows exponentially with the program size. Confronted with this state-explosion problem, traditional model checkers perform iterative depth-bounded search. Although effective for message-passing software, iterative depth-bounding is inadequate for multithreaded software.</p> <p>This paper proposes iterative context-bounding, a new search algorithm that systematically explores the executions of a multithreaded program in an order that prioritizes executions with fewer <i>context switches</i>. We distinguish between preempting and nonpreempting context switches, and show that bounding the number of preempting context switches to a small number significantly alleviates the state explosion, without limiting the depth of explored executions. We show both theoretically and empirically that context-bounded search is an effective method for exploring the behaviors of multithreaded programs. We have implemented our algorithmin two model checkers and applied it to a number of real-world multithreaded programs. Our implementation uncovered 9 previously unknown bugs in our benchmarks, each of which was exposed by an execution with at most 2 preempting context switches. Our initial experience with the technique is encouraging and demonstrates that iterative context-bounding is a significant improvement over existing techniques for testing multithreaded programs.</p>", "authors": [{"name": "Madanlal Musuvathi", "author_profile_id": "81100333862", "affiliation": "Microsoft Research, Redmond, WA", "person_id": "P558946", "email_address": "", "orcid_id": ""}, {"name": "Shaz Qadeer", "author_profile_id": "81100286660", "affiliation": "Microsoft Research, Redmond, WA", "person_id": "PP14106781", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250785", "year": "2007", "article_id": "1250785", "conference": "PLDI", "title": "Iterative context bounding for systematic testing of multithreaded programs", "url": "http://dl.acm.org/citation.cfm?id=1250785"}