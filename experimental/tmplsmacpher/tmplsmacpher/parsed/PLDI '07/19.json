{"article_publication_date": "06-10-2007", "fulltext": "\n OptimisticParallelism Requires Abstractions * MilindKulkarni , Keshav Pingali Department of Computer \nScience, UniversityofTexas, Austin. {milind, pingali}@cs.utexas.edu Abstract Irregular applications, \nwhich manipulate large, pointer-based data structures like graphs, are dif.cult to parallelize manually. \nAuto\u00admatic tools and techniquessuch as restructuring compilers and run\u00adtime speculativeexecutionhavefailedto \nuncover much parallelism in these applications,inspiteofalotofeffortbythe research com\u00admunity. These \ndif.culties have even led some researchers to won\u00adder if there is anycoarse-grain parallelism worth exploiting \nin ir\u00adregular applications. In this paper, we describe two real-world irregular applications: a Delaunay \nmesh re.nement application anda graphics application that performs agglomerative clustering.By studying \nthe algorithms and data structures used in these applications, we show that there is substantial coarse-grain, \ndata parallelism in these applications, but that this parallelism is very dependent on the input data \nand therefore cannot be uncovered by compiler analysis. In principle, optimistic techniques such as thread-level \nspeculation can be used to uncover this parallelism, but we argue that current implemen\u00adtations cannot \naccomplish this because theydo not use the proper abstractions for the data structures in these programs. \nThese insights have informed our design of the Galois sys\u00adtem, an object-based optimistic parallelization \nsystem for irregu\u00adlarapplications. There are three main aspectsto Galois:(1)a small number of syntactic \nconstructs for packaging optimistic parallelism as iteration over ordered and unordered sets, (2) assertions \nabout methods in class libraries, and (3) a runtime scheme for detecting and recovering from potentially \nunsafe accesses to shared memory made by an optimistic computation. We show that Delaunay mesh generation \nand agglomerative clustering can be parallelized in a straight-forward way using the Galois approach, \nand we present experimental measurements to show that this approach is practical. These results suggest \nthat Galois is a practical approach to exploiting data parallelism in irregular programs. * This work \nis supported in part by NSF grants 0615240, 0541193, 0509307, 0509324, 0426787 and 0406380, as well as \ngrants from the IBM and Intel Corportations. MilindKulkarniis supportedby the DOE HPCS Fellowship. Kavita \nBalais supportedin partby NSF Career Grant 0644175 Permission to make digital or hard copies of all or \npart of this work for personal or classroom use is granted without fee provided that copies are not made \nor distributed for pro.t or commercial advantage and that copies bear this notice and the full citation \non the .rst page.To copyotherwise, to republish, to post on servers or to redistribute to lists, requires \nprior speci.c permission and/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, USA. Copyright \nc &#38;#169; 2007ACM 978-1-59593-633-2/07/0006...$5.00. BruceWalter, Ganesh Ramanarayanan, Kavita Bala \n,L.Paul Chew Department of Computer Science, Cornell University, Ithaca,NewYork. bjw@graphics.cornell.edu, \n{graman,kb,chew}@cs.cornell.edu Categories and Subject Descriptors D.1.3[ProgrammingTech\u00adniques]: Concurrent \nProgramming Parallel Programming GeneralTerms Languages Keywords Optimistic Parallelism, Abstractions, \nIrregular Pro\u00adgrams 1. Introduction Apessimist sees the dif.culty in every opportunity; an optimist sees \nthe opportunityineverydif.culty. SirWinston Churchill The advent of multicore processors has shifted \nthe burden of improving program execution speed from chip manufacturers to software developers. A particularly \nchallenging problem in this context is the parallelization of irregular applications that deal with complex, \npointer-based data structures such as trees, queues and graphs. In this paper, we describe two such applications: \na Delaunaymesh re.nementcode[8]andagraphics application[39] that performs agglomerative clustering [26]. \nIn principle, it is possible to use a thread library (e.g., pthreads) oracombinationofcompiler directives \nand libraries (e.g., OpenMP [25])to write threadedcodefor multicore processors,butitiswell known that \nwriting threaded code can be very trickybecause of the complexities of synchronization, data races, memory \nconsistency, etc.Tim Sweeney, who designed the multi-threadedUnreal3game engine, estimates that writing \nmulti-threading code tripled software costs at Epic Games (quoted in [9]). Another possibility is to \nuse compiler analyses such as points\u00adto and shape analysis [5, 31] to parallelize sequential irregular \npro\u00ad grams. Unfortunately,static analysesfailto uncoverthe parallelism in such applications because the \nparallel schedule is very data\u00addependent and cannot be computed at compile-time, as we argue in Section \n3. Optimistic parallelization [17]isapromising idea,but current implementations of optimistic parallelization \nsuch as thread-level speculation (TLS) [36, 43] cannot exploit the parallelism in these applications, \nas we discuss in Section 3. In this paper, we describe the Galois approach to parallelizing irregular \napplications. This approach is informed by the following beliefs. Optimistic parallelization is the \nonly plausible approach to par\u00adallelizing many, if not most, irregular applications.  For effective \noptimistic parallelization, it is crucial to exploit the abstractions providedby object-oriented languages(in \npar\u00adticular, the distinction between an abstract data type and its im\u00adplementation).  Concurrency should \nbe packaged, when possible, within syn\u00adtactic constructs that make it easy for the programmer to ex\u00adpress \nwhat might be done in parallel, and for the compiler and runtime system to determine what should be done \nin parallel.   Figure 1. ADelaunay mesh. Note that the circumcircle for each of the triangles does \nnot contain other points in the mesh. Thesyntactic constructsusedin Galoisarevery naturalandcan be addedeasily \nto anyobject-oriented programming language like Java. They are related to set iterators in SETL [19]. \nConcurrent accessto mutable sharedobjectsbymultiple threads is fundamental, and cannot be added to the \nsystem as an after\u00adthought as is done in current approaches to optimistic paral\u00adlelization. However, \ndiscipline needs to be imposed on concur\u00adrent accesses to shared objects to ensure correct execution. \nWe have implemented the Galois approach in C++ on two shared-memory platforms, and we have used this \nimplementation to write a number of complex applications including Delaunay mesh re.nement, agglomerative \nclustering, an image segmentation code that uses graph cuts [39], and an approximate SAT solver calledWalkSAT[33]. \nThis paper describes the Galois approach and its implementa\u00adtion, and presents performance results for \nsome of these applica\u00adtions. It is organized as follows. In Section 2, we present Delaunay mesh re.nement \nand agglomerativeclustering, and describe oppor\u00adtunities for exploiting parallelism in these codes. In \nSection 3, we give an overview of existing parallelization techniques and argue that they cannot exploit \nthe parallelism in these applications. In Section4, wediscuss the Galois programming model and run-time \nsystem.InSection5,weevaluatethe performanceof our systemon the two applications. Finally, in Section \n6, we discuss conclusions and ongoing work. 2. Two IrregularApplications To understand the nature of \nthe parallelism in irregular programs, it is useless to study the execution traces of irregular programs, \nas most studies in this area do; instead it is necessary to recall Niklaus Wirth s aphorismprogram = \nalgorithm+ data structure [41], and examine the relevant algorithms and data structures. In this sec\u00adtion, \nwe describe two irregular applications: Delaunay mesh re\u00ad.nement [8], and agglomerative clustering [26] \nas used within a graphics application [39]. These applications perform re.nement andcoarsening respectively, \nwhich arearguablythetwo most com\u00admon operations forbulk-modi.cation of irregular data structures. For \neach application, we describe the algorithm andkeydata struc\u00adtures, and describe opportunities for exploitingparallelism. \n2.1 Delaunay Mesh Re.nement Mesh generation is an important problem with applications in many areas such \nas the numerical solution of partial differential equations and graphics. The goal of mesh generation \nis to represent a surface or a volume as a tessellation composed of simple shapes like trian\u00adgles, tetrahedra, \netc. Although manytypes ofmeshes are used in practice, Delaunay meshes are particularly important since \nthey have a number of desirable mathematical properties [8]. The Delaunay triangulation forasetofpointsintheplaneisthe \ntriangulationsuchthatnopoint is inside the circumcircle of anytriangle (this property is called the empty \ncircle property). An example of such a mesh is shown in Figure 1. Figure 2. Fixing a bad element. 1: \nMesh m = /* read in initial mesh */ 2: WorkList wl; 3: wl.add(mesh.badTriangles()); 4: while (wl.size() \n!= 0) { 5: Element e = wl.get(); //get bad triangle 6: if (e no longer in mesh) continue; 7: Cavity c \n= new Cavity(e); 8: c.expand(); 9: c.retriangulate(); 10: mesh.update(c); 11: wl.add(c.badTriangles()); \n12: } Figure 3. Pseudocode of the mesh re.nement algorithm In practice, the Delaunay property alone is \nnot suf.cient, and it is necessary to impose quality constraints governing the shape and size of the \ntriangles. For a given Delaunay mesh, this is ac\u00adcomplished by iterative mesh re.nement, which successively \n.xes bad triangles (triangles that do not satisfy the quality constraints) by adding new points to the \nmesh and re-triangulating. Figure 2 illustrates this process; the shaded triangle in Figure 2(a) is as-sumedtobebad.To.xthisbad \ntriangle,anewpointis addedat the circumcenter of this triangle. Addingthis point may invalidate the empty \ncircle property for some neighboring triangles, so all af\u00adfected triangles are determined (this region \nis called the cavity of the bad triangle), and the cavity is re-triangulated, as shown in Fig\u00adure 2(c) \n(in this .gure, all triangles lie in the cavity of the shaded bad triangle). Re-triangulatinga cavity \nmay generate newbad tri\u00adanglesbutitcanbeshownthatthis iterativere.nementprocesswill ultimately terminate \nand produce a guaranteed-quality mesh. Dif\u00adferent orders ofprocessing bad elements lead to different \nmeshes, although all such meshes satisfy the quality constraints [8]. Figure3shows the pseudocode formesh \nre.nement. The input tothis programisaDelaunaymeshinwhich some trianglesmaybe bad, and the output is \na re.ned mesh in which all triangles satisfy the qualityconstraints. There aretwokey data structures \nusedin this algorithm. One is a worklist containing the badtriangles in the mesh. The other is a graph \nrepresenting the mesh structure; each triangle in the mesh is represented as one node, and edges in the \ngraph represent triangle adjacencies in the mesh. Opportunities for Exploiting Parallelism. The natural \nunit of work for parallel execution is the processing of a bad triangle. Our measurements show that on \nthe average, each unit of work takes about a million instructions of which about 10,000 are .oating\u00adpoint \noperations. Because a cavity is typically a small neighbor\u00adhoodofabad triangle,twobad trianglesthatarefarapartonthe \nmeshmayhavecavitiesthatdonotoverlap. Furthermore,the entire re.nement process(expansion, retriangulation \nandgraph updating) for the twotriangles is completely independent; thus, the two trian\u00adgles can be processedin \nparallel. This approach obviously extends to more than two triangles. If however the cavities of two \ntriangles overlap, the triangles canbe processedin either orderbut only one ofthem canbe processedata \ntime. Whetherornottwobad trian\u00adgles have overlapping cavities depends entirely on the structure of themesh,whichchanges \nthroughouttheexecutionofthe algorithm. How much parallelism is there in Delaunay mesh generation? The \nanswer obviously depends on the mesh and on the order in which bad triangles are processed, and may be \ndifferent at dif\u00ad Figure 4. Agglomerative clustering ferent points during the execution of the algorithm. \nOne study by Antonopoulos et al. [2] on a mesh of one million triangles found that there were more than \n256 cavities that could be expanded in parallel until almost the end of execution.  2.2 Agglomerative \nClustering The second problem is agglomerative clustering, a well-known data-mining algorithm [26]. This \nalgorithm is used in graphics applications for handling large numbers of light sources [39]. Theinputtothe \nclusteringalgorithmis(1)adata-set,and(2)a measureofthe distance between itemsinthedata-set. Intuitively, \nthis measure is an estimate of similarity the larger the distance between twodata items, the less similar \ntheyare believed to be. The goal of clustering is to construct a binary tree called a dendrogram whose \nhierarchical structure exposes the similarity between items in the data-set. Figure 4(a) shows a data-set \ncontaining points in the plane, for which the measure of distance between data points is the usual Euclidean \ndistance. The dendrogram for this data set is shown in Figures 4(b,c). Agglomerative clustering can be \nperformed by an iterative al\u00adgorithm: at each step, the twoclosest points in the data-set are clus\u00adtered \ntogetherandreplacedinthe data-setbyasinglenewpointthat represents the new cluster. The location of this \nnew point may be determined heuristically [26]. The algorithm terminates when there is only one point \nleft in the data-set. Pseudocode for the algorithm is shown in Figure 5. The central data structure is \na priority queue whose entries are ordered pairs of points <x,y>, such that y is the nearest neighbor \nof x (we call this nearest(x)). In each iteration of the while loop, the algorithm dequeues the top element \nof the priority queue to .nd a pair of points <p,n> that are closer to each other than anyother pair \nof points, and clusters them. These two points are then replaced by a new point that represents this \ncluster. The nearest neighbor of this new point is determined, and the pair is entered into the priority \nqueue. If there is only one point left, its nearest neighbor is the point at in.nity. To .nd the nearest \nneighbor of a point, we can scan the entire data-set at each step,but this is too inef.cient.Abetter \napproach is to sort the points by location, and search within this sorted set to .nd nearest neighbors. \nIf the points were all in a line, we could usea binary search tree. Since the points areinhigher dimensions, \na multi-dimensional analog called a kd-tree is used [3]. The kd\u00ad tree is built at the start of the algorithm, \nand it is updated by removing the points that are clustered, and then adding the new point representing \nthe cluster, as showninFigure5. Opportunities for Exploiting Parallelism. Since each iteration clusters \nthe two closest points in the current data-set, it may seem that the algorithm is inherently sequential. \nIn particular, an item <x,nearest(x)> inserted into the priority queue by iteration i at line 17 may \nbe the same item that is dequeued by iteration (i+1) in line 5; this will happen if the points in the \nnew pair are closer together than anyother pair of points in the current data-set. On the other hand, \nif we consider the data-set in Figure 4(a), we see that points a and b, and points c and d can be clustered \ncon\u00adcurrently since neither cluster affects the other. Intuitively, if the 1: kdTree := new KDTree(points) \n2: pq := new PriorityQueue() 3: foreach p in points {pq.add(<p,kdTree.nearest(p)>)} 4: while(pq.size() \n!= 0) do { 5: Pair <p,n> := pq.get();//return closest pair 6: if (p.isAlreadyClustered()) continue; 7: \nif (n.isAlreadyClustered()) { 8: pq.add(<p, kdTree.nearest(p)>); 9: continue; 10: } 11: Cluster c := \nnew Cluster(p,n); 12: dendrogram.add(c); 13: kdTree.remove(p); 14: kdTree.remove(n); 15: kdTree.add(c); \n16: Point m := kdTree.nearest(c); 17: if (m != ptAtInfinity) pq.add(<c,m>); 18: } Figure 5. Pseudocode \nfor agglomerative clustering dendrogram is a long andskinnytree, there may be few indepen\u00addent iterations, \nwhereasifthedendrogramisabushytree, thereis parallelism that can be exploited since the tree can be constructed \nbottom-up in parallel. As in the case of Delaunay mesh re.nement, the parallelism is very data-dependent. \nIn experiments on graphics sceneswith20,000lights,wehave foundthatonaverageabout100 clusters can be constructed \nconcurrently; thus, there is substantial parallelism that canbeexploited.For this application, each iteration \nof the while-loop in Figure5performs about 100,000 instructions of which roughly 4000 are .oating-pointoperations. \n3. Limitationsof CurrentApproaches Current approaches for parallelizing irregular applications can be \ndivided into static, semi-static, and dynamic approaches. Static Approaches. One approach to parallelization \nis to use a compiler to analyze and transform sequential programs into parallel ones, using techniques \nlike points-to analysis [5] and shape analy\u00adsis [31]. The weakness of this approach is that the parallel \nschedule produced by the compiler must be valid for all inputs to the pro\u00adgram. As we have seen, parallelism \nin irregular applications can bevery data-dependent, so compile-time parallelization techniques will \nserialize the entire execution. This conclusion holds even if dependence analysis is replaced with more \nsophisticated analysis techniques like commutativity analysis [10]. A Semi-static Approach. In the inspector-executor \napproach of Saltz et al [27], the computation is split into two phases, an inspec\u00adtor phasethat determines \ndependencies between unitsofwork,and an executor phase that uses the schedule to perform the compu\u00adtation \nin parallel. This approachis not useful for our applications since the data-sets, and therefore the dependences, \nchange as the codes execute. Dynamic Approaches. In dynamic approaches, parallelization is performed \nat runtime, and is known as speculative or optimistic parallelization.The programisexecutedin parallel \nassuming that dependences are not violated,but the system software or hardware detects dependence violations \nand takes appropriate corrective ac\u00adtion such as killing offthe offending portions of the program and \nre-executing them sequentially. If no dependence violations are de\u00adtected by the end of the speculative \ncomputation, the results of the speculative computation are committed and become available to other computations. \nFine-grain speculative parallelization forexploiting instruction\u00adlevel parallelismwas introduced around \n1970; forexample,Toma\u00adsulo s IBM 360/91 fetched instructions speculatively from both sides of a branch \nbefore the branch target was resolved [37]. Spec\u00ad ulative execution of instructions past branches was \nstudied in the abstractbyFoster and Risemanin 1972 [7], andwas made prac\u00ad tical by Josh Fisher when he \nintroduced the idea of using branch probabilities to guide speculation [11]. Branch speculation can ex\u00ad \npose instruction-level (.ne-grain) parallelism in programsbut not the data-dependent coarse-grain parallelism \nin applications likeDe\u00adlaunay mesh re.nement. One of the earliest implementations of coarse-grain optimistic \nparallelexecutionwasin Jefferson s 1985TimeWarp system for distributed discrete-event simulation [17]. \nIn 1999, Rauchwerger and Padua described the LRPD test for supporting speculative execution of FORTRAN \nDO-loops in which array subscripts were too complextobe disambiguatedbydependence analysis [30]. This \napproach can be extended to while-loops if an upper bound on the number of loop iterations can be determined \nbefore the loop begins execution [29]. More recent work has provided hardware support for this kind of \ncoarse-grain loop-level speculation, now known as thread-level speculation (TLS) [36, 43]. However, there \nare fundamental reasons why current TLS im\u00adplementations cannot exploit the parallelism in our applications. \nOne problem is that many of these applications, such as Delau\u00adnay mesh re.nement, have unbounded while-loops, \nwhich are not supported by most current TLS implementations since they target FORTRAN-style DO-loops \nwith .xed loop bounds.Amore funda\u00admental problem arises from thefact that current TLS implementa\u00adtions \ntrack dependences by monitoring the reads and writes made by loop iterations to memory locations. For \nexample, if iteration i+1 writestoalocation beforeitis readbyiteration i,adependence violation is reported, \nand iteration i+1 must be rolled back. For irregular applications that manipulate pointer-based data \nstructures, this is too strict and the program will perform poorly be\u00adcauseoffrequent roll-backs.Tounderstand \nthis, consider thework\u00adlistin Delaunaymesh generation.Regardlessofhowtheworklistis implemented, there \nmust be a memory location (call this location head)that points to a cell containing the next bad triangle \nto be handed out.The .rst iterationofthe whileloop removesabadtri\u00adanglefromtheworklist,soitreadsand writesto \nhead,but the result of this write is not committed until that iteration terminates suc\u00adcessfully.Athread \nthat attempts to start the second iteration con\u00adcurrently with the execution of the .rst iteration will \nalso attempt to read and write head, and since this happens before the updates from the .rst iteration \nhave been committed, a dependence con.ict will be reported (the precise point at which a dependence con.ict \nwill be reported depends on the TLS implementation). While this particular problem might be circumvented \nby inventing some ad hoc mechanism, it is unlikely that there is any such work-around for thefar more \ncomplex priority queue manipulations in agglom\u00aderative clustering. The manipulations of the graph and \nkd-tree in these applications may also create such con.icts. Thisisafundamental problem: for many irregular \napplications, tracking dependences by monitoring reads and writes to memory locationsis correctbut willresultin \npoor performance. Finally, Herlihy and Moss have proposed to simplify shared\u00admemory programming by eliminating \nlock-based synchronization constructs infavor of transactions [15]. There is growing interest in supporting \ntransactions ef.ciently with software and hardware im\u00adplementations of transactional memory [1, 12, 13, \n21, 34]. Most of this work is concerned with optimistic synchronization and not op\u00adtimistic parallelization;thatis,their \nstarting pointisa program that has already been parallelized (for example, the SPLASH bench\u00admarks [12] \nor the Linuxkernel [28]), and the goal is .nd an ef.\u00ad cient way to synchronize parallel threads. In contrast, \nour goal is to .ndtheright abstractionsforexpressing coarse-grain parallelismin irregular applications, \nand to support these abstractions ef.ciently; synchronization is one part of a bigger problem we are \naddressing in thispaper. Furthermore, most implementations of transactional Figure 6. High-level view \nof Galois execution model memory trackreads and writes to memory locations, so theysuf\u00adfer from the same \nproblems as current TLS implementations. Open nested transactions [22] have been proposed recently as \na solution to this problem, and theyare discussed in more detail in Section 4. 4. The GaloisApproach \nPerhaps the most important lesson from the past twenty-.ve years of parallel programming is that the \ncomplexity of parallel program\u00adming should be hidden from programmers asfar as possible.For example,itislikelythat \nmoreSQL programsareexecutedinparal\u00adlel than programs in anyother language. However, most SQL pro\u00adgrammers \ndo not write explicitly parallel code; insteadtheyobtain parallelism by invoking parallel library implementations \nof joins and otherrelational operations.A layered approachof this sortis also used in dense linear algebra, \nanother domain that has success\u00adfully mastered parallelism. In this spirit, programs in the Galois approach \nconsist of (i) a set of library classes and (ii) the top-level client code that creates and manipulates \nobjectsof these classes.Forexample,in Delaunay mesh re.nement, the relevant objects are the mesh and \nworklist, and the client code implements the Delaunay mesh re.nement algorithm discussed in Section 2. \nThis client code is executed concurrentlyby somenumberof threads,but as we will see,itis notexplicitly \nparallelandmakesno mentionof threads. Figure6is a pictorial view of this execution model. There are three \nmain aspects to the Galois approach: (1) two syntactic constructs called optimistic iterators for packaging \nopti\u00admistic parallelismasiterationoversets(Section4.1),(2) assertions about methods in class libraries \n(Section 4.2), and (3) a runtime scheme for detecting and recovering from potentially unsafe ac\u00adcesses \nto shared objects made by an optimistic computation (Sec\u00adtion 4.3). 4.1 Optimistic iterators As mentioned \nabove, the client code is not explicitly parallel; in\u00adstead parallelism is packaged into two constructs \nthat we call op\u00adtimistic iterators. In the compiler literature, it is standard to distin\u00adguish between \ndo-all loops and do-across loops [20]. The iterations of a do-all loop can be executed in anyorder because \nthe compiler or the programmer asserts that there are no dependences between iterations.In contrast,ado-acrossloopis \nonein which theremaybe dependences between iterations, so proper sequencing of iterations is essential.We \nintroduce two analogous constructs for packaging optimistic parallelism.  Set iterator: for each e in \nSet S do B(e) The loop body B(e) is executed for each element e of set S. Since set elements are not \nordered, this construct asserts that in a serial execution of the loop, the iterations can be executed \nin anyorder. There may be dependences between the iterations, as inthe caseof Delaunaymesh generation,butanyserial \norderof executing iterations is permitted. When an iteration executes, it may add elements to S.   \nOrdered-set iterator: for each e in Poset S do B(e)  1: Mesh m = /* read in initial mesh */ 2: Set wl; \n3: wl.add(mesh.badTriangles()); 4: foreacheinwldo{ 5: if (e no longer in mesh) continue; 6: Cavity c \n= new Cavity(e); 7: c.expand(); 8: c.retriangulate(); 9: m.update(c); 10: wl.add(c.badTriangles()); 11: \n} Figure 7. Delaunay mesh re.nement using set iterator This construct is an iterator over a partially-ordered \nset (Poset) S. It asserts that in a serial execution of the loop, the iterations must be performed in \nthe order dictated by the ordering of elements in the Poset S. There may be dependences between iterations, \nand as in the case of the set iterator, elements may be added to S during execution. The set iteratorisa \nspecial caseof the ordered-set iteratorbutit can be implemented more ef.ciently, as we see later in this \nsection. Figure7shows the client code for Delaunay mesh generation. Instead of a work list, this code \nuses a set and a set iterator. The Galoisversionisnotonly simplerbutalsomakesevidentthefact that the \nbad triangles can be processed in any order; this fact is absent from the more conventional code of Figure \n3 since it implementsa particular processing order.For lackof space, wedo notshowthe Galoisversionof \nagglomerative clustering,butit uses the ordered-set iterator in the obvious way. 4.1.1 Concurrent Execution \nModel Although the semantics of Galois iterators can be speci.ed without appealing to a parallel execution \nmodel, these iterators provide hints from the programmer to the Galois runtime system that it may be \npro.table to execute the iterations in parallel; of course anyparallelexecution mustbefaithfultothe sequential \nsemantics. The Galois concurrentexecution modelisthe following.Amas\u00adter thread begins the execution of \nthe program; it also executes the code outside iterators. When this master thread encounters an iter\u00adator, \nit enlists the assistance of some number of worker threads to execute iterations concurrently with itself. \nThe assignment of iter\u00adations to threads is under the control of a scheduling policyimple\u00admentedbythe \nruntime system; for now, we assume that this assign\u00adment is done dynamically to ensure load-balancing. \nAll threads are synchronized using barrier synchronization at the end of the itera\u00adtor. In our applications, \nwe havenot found it necessary to use nested iterators. There is no fundamental problem in supporting \nnested parallelism,but our current implementation does not support it; if a thread encounters an inner \niterator, it executes the entire inner iterator sequentially. Given this execution model, the main technical \nproblem is to ensure that the parallel execution respects the sequential semantics of the iterators. \nThis is a non-trivial problem because each itera\u00adtion may read and write to the objects in shared memory, \nand we must ensure that these reads and writes are properly coordinated. Section 4.2 describes the information \nthat must be speci.ed by the Galois class writer to enable this. Section 4.3 describes how the Galois \nruntime system uses this information to ensure that the se\u00adquential semantics of iterators are respected. \n  4.2 Writing Galois Classes To ensure that the sequential semantics of iterators are respected, there \nare two problems that must be solved, which we explain with reference to Figure 8. This .gure shows set \nobjects with methods Figure8. Interleaving method invocations from different iterations add(x), remove(x), \nget() and contains?(x) that have the usual semantics1. The .rst problem is the usual one of concurrencycontrol \n(also known in the database literature as ensuring consistency). Ifa method invocation from one iteration \nis performed concurrently with an invocation from another iteration, we must ensure that the two invocations \ndo not step on each other. One solution is to use a lock on object S; if this inhibits concurrency, we \ncan use .ne-grain locks within object S. These locks are acquired before the method is invoked and released \nwhen the method completes. However,this is not enough to ensure that the sequential seman\u00adticsofthe iteratorsarerespected. \nConsiderFigure8(a).IfSdoesnot contain x beforethe iterationsstart, noticethatinanysequentialex\u00adecution \nof the iterations, the method invocation contains?(x) will returnfalse. However, for one possible interleaving \nof opera\u00adtions add(x),contains?(x),remove(x) the invoca\u00adtion contains?(x) will return true, which is \nincorrect. This is the problem of ensuring isolation of the iterations. One solution for both problems \nis for an iteration to release its locks only at the end of the iteration: the well-known two-phase locking \nalgorithm used in databases is an optimized version of this simple idea. Transactional memory implementations \naccomplish the same goal by tracking the read and write sets of each iteration instead of locking them. \nWhile this solves the problem in Figure 8(a), it is not adequate for our applications. The program in \nFigure 8(b) is motivated by Delaunay mesh generation: each iteration gets a bad triangle at the beginning \nof the iteration, and may add some bad triangles to the work-set at the end. Regardless of how the set \nobject is implemented, there mustbealocation (callit head)that pointstoa cell containing the next triangle \nto be handed out. The .rst iteration to get work will read and write location head, and it will lock \nit for the duration of the iteration, preventing any other iterations fromgettingwork. Most current implementationsof \ntransactional memory will suffer from the same problem since the head location will be in the read and \nwrite sets of the .rst iteration for the duration of that iteration. The crux of the problem is that \nthe abstract set operations have useful semantics that are not available to an implementation that works \ndirectly on the representation of the setand tracks reads and writes to individual memory locations. \nThe problem therefore is to understand the semantics of set operations that must be exploited to permit \nparallel execution in our irregular applications, and to specify these semantics in some concise way. \n4.2.1 Semantic Commutativity The solution we have adopted exploits the commutativity of method invocations. \nIntuitively, it is obvious that the method in\u00advocations to a given object from two iterations can be \ninterleaved without losing isolation provided that these method invocations commute, since this ensures \nthat the .nal result is consistent with 1The method remove(x) removes a speci.c element from the set \nwhile get() returns an arbitrary element from the set, removing it from the set. some serial order of \niteration execution. In Figure 8(a), the invo\u00ad cation contains?(x) does not commute with the operations \nfrom the other thread, so the invocations from the two iterations must not be interleaved. In Figure \n8(b), (1) getoperations commute with each other,and(2)a getoperation commutes with an add operation provided \nthat the operand of add is not the element returnedby get. This allows multiple threads to pull work \nfrom the work-set while ensuring that sequential semantics of iterators are respected. It is important \nto note that what is relevant for our purpose is commutativity in the semantic sense. The internal state \nof the object may actually be different for different orders of method invocations evenif theseinvocations \ncommuteinthe semantic sense.Forexam\u00adple, if the set is implemented using a linked list and two elements \nare added to this set, the concrete state of the linked list will de\u00adpend in general on the order in \nwhich these elements were added to the list. However, what is relevant for parallelization is that the \nstate of the set abstract data type, which is being implemented by the linked list, is the same for both \norders. In other words, we are not concerned with concrete commutativity (that is, commutativ\u00adity with \nrespect to the implementation type of the class),but with semantic commutativity (that is, commutativity \nwith respect to the abstract data typeof the class).We also note that commutativityof method invocations \nmay depend on the arguments of those invo\u00adcations.Forexample, an add and a remove commute only if their \narguments are different. 4.2.2 Inverse Methods Because iterations are executed in parallel, it is possible \nfor com\u00admutativity con.icts to prevent an iteration from completing. Once a con.ict is detected, some \nrecovery mechanism must be invoked to allow execution of the program to continue despite the con.ict. \nBecause our execution model uses the paradigm of optimistic par\u00adallelism, our recovery mechanism rolls \nback the execution of the con.icting iteration.Toavoidlivelock,thelower priority iteration is rolled \nback in the case of the ordered-set iterator. To permit this, every method of a shared object that may \nmod\u00adify the state of that object must have an associated inverse method that undoes the side-effectsof \nthat methodinvocation.Forexam\u00adple, for a set, the inverse of add(x) is remove(x), and the inverse of \nremove(x) is add(x). As in the case of commutativity, what is rele\u00advant for our purpose is an inverse \nin the semantic sense; invoking a method and its inverse in succession may not restore the concrete data \nstructure to what it was. Note that when an iteration rolls back, all of the methods which it invokes \nduring roll-back must succeed. Thus, we must never en\u00adcounter con.icts when invoking inverse methods. \nWhen the Galois system checks commutativity, it also checks commutativity with the associated inverse \nmethod. 4.2.3 Puttingit AllTogether Since we are interested in semantic commutativity and undo, it is \nnecessary for the class designer to specify this information. Fig\u00adure 9 illustrates how this information \nis speci.ed in Galois for a class that implements sets. The interface speci.es two versions of each method: \nthe internal methods on the object, and the interface methods, called from within iterators, that perform \nthe commuta\u00adtivity checks, maintain the undo information and trigger roll backs when commutativity con.icts \nare detected. The speci.cation for an interface method consists of three main sections (with pseudo-code \nrepresenting these in the .gure): calls: This section ties the interface method to the internal method(s) \nit invokes.  commutes: This section speci.es which other interface meth\u00adods the current method commutes \nwith, andunder which con\u00ad  class Set { // interface methods void add(Element x); [calls] _add(x) : void \n[commutes] -add(y) {y != x} -remove(y) {y != x} -contains(y) {y != x} -get() : y {y != x} //get call \nthat returns y [inverse] _remove(x) void remove(Element x); [calls] _remove(x) : void [commutes] -add(y) \n{y != x} -remove(y) {y != x} -contains(y) {y != x} -get() : y {y != x} [inverse] _add(x) bool contains(Element \nx); [calls] _contains(x) : bool b [commutes] -add(y) {y != x} -remove(y) {y != x} -get() : y {y != x} \n-contains(*) //any call to contains Element get(); [calls] _get() : Element x [commutes] -add(y) {y \n!= x} -remove(y) {y != x} -contains(y) {y != x} -get() : y {y != x} [inverse] _add(x) //internal methods \nvoid _add(Element x); void _remove(Element x); bool _contains(Element x); Element _get(); } Figure 9. \nExample Galois class for a Set ditions.For example, remove(x) commutes with add(y), as long as theyelements \nare different. inverse:This section speci.es the inverse of the current method. The description of the \nGalois system in this section implicitly assumed that all calls to parallel objects are made from client \ncode. However,tofacilitate composition,wealsoallowparallelobjectsto invoke methods on other objects. \nThis is handled through a simple .attening approach. The iteration object is passed to the child invocation \nand hence all operations done in the child invocation are appended to the undo log of the iteration. \nSimilarly, the child invocation functions as an extension of the original method when detecting commutativity \ncon.icts. No changes need to be made to the Galois run-time to support this form of composition. The \nclass implementor must also ensure that each internal method invocation is atomic to ensure consistency. \nThis can be done using anytechnique desired, including locks or transactional memory. Recall that whatever \nlocks are acquired during method invocation (or memory locations placed in read/write sets during transactional \nexecution) are released as soon as the method com\u00adpletes, rather than being held throughout the execution \nof the it\u00aderation, since we rely on commutativity information to guarantee isolation. In our current \nimplementation, the internal methods are made atomic through the use of locks. 4.2.4 Asmall example \nConsidera programwritten usinga single shared object, an integer accumulator. The object supports two \noperations: accumulate and read, with the obvious semantics. It is clear that accumulates com\u00admute with \nother accumulates,and readscommute with otherreads, but thataccumulate does not commute with read. The \nmethods are made atomic with a single lock which is acquired at the beginning of the method and released \nat the end. Iteration A Iteration B Iteration C { } ... a.accumulate(5) ... { } ... a.accumulate(7) ... \n{ } ... a.read() ... Figure 10. Example accumulator code  There are three iterations executing concurrently, \nas seen in Figure 10. The progress of the execution is as follows: IterationA calls accumulate, acquiring \nthe lock, updating the accumulator and then releasing the lock and continuing.  IterationBcalls accumulate. \nBecause accumulatescommute,B can successfully make the call, acquiring the lock, updating the accumulator \nand releasing it. Note thatAhas already released the lock on the accumulator, thus allowingB to make \nforward progress without blocking on the accumulator s lock.  When iterationCattemptstoexecute read, \nit sees that it cannot, as read does not commute with the already executed accumu\u00adlates. Thus, C must \nroll back and try again. Note that this is not enforcedby the lock on the accumulator,but insteadby the \ncommutativity conditions on the accumulator.  When iterationsAandBcommit,C can then successfully call \nread and continue execution.  In [38], von Praun et al discuss the use of ordered transactions in parallelizing \nFORTRAN-style DO-loops, and theygive special treatment to reductions in such loops to avoid spurious \ncon.icts. Reductions do not require anyspecial treatment in the Galois ap\u00adproach since the programmer \ncould just use an object like the ac\u00adcumulator to implement reduction.  4.3 Runtime System The Galois \nruntime systemhastwo components:(1)aglobal struc\u00adture called the commit pool that is responsible for \ncreating, abort\u00ading, and committing iterations, and (2) per-object structures called con.ict logs which \ndetect when commutativity conditions are vio\u00adlated. Atahighlevel,the runtime systemsworksas follows.The \ncom\u00admit pool maintains an iterationrecord,shownin Figure 11, for each ongoing iteration in the system. \nThe status of an iteration can be RUNNING, RTC (ready-to-commit) or ABORTED. Threads go to the commit \npool to obtain an iteration. The commit pool creates a new iteration record, obtains the next element \nfrom the iterator, as\u00adsigns a priority to the iteration record based on the priority of the element (for \na set iterator, all elements have the same priority), and sets the status .eld of the iteration record \nto RUNNING. When an iteration invokes a method of a shared object, (i) the con.ict log of that object \nand the local log of the iteration record are up\u00addated, as described in more detail below, and (ii) a \ncallback to the associated inverse method is pushed onto the undo log of the it\u00aderation record. If a \ncommutativity con.ict is detected, the commit pool arbitrates between the con.icting iterations, and \naborts itera\u00adtions to permit the highest priority iteration to continue execution. Callbacks in the undo \nlogs of aborted iterations are executed to undo their effects on shared objects. Once a thread has completed \nan iteration, the status .eld of that iteration is changed to RTC, and the thread is allowed to begin \na new iteration. When the completed iteration has the highest priority in the system, it is allowed to \ncom\u00admit. It can be seen that the role of the commit pool is similar to that ofa reorderbufferin out-of-order \nprocessors [14]. IterationRecord { Status status; Priority p; UndoLog ul; list<LocalConflictLog> local_log; \nLock l; } Figure 11. Iteration record maintained by runtime system 4.3.1 Con.ict Logs The con.ict log \nis the mechanism for detecting commutativity con\u00ad.icts. There is one con.ict log associated with each \nshared object. Asimple implementation for the con.ict log of an object is a list containing the method \nsignatures (including the values of the input and output parameters) of all invocations on that object \nmade by currently executing iterations (called outstanding invocations ). When iteration i attempts to \ncall a method m1 on an object, the method signature is compared against all the outstanding invoca\u00adtions \nin the con.ict log. If one of the entries in the log does not commute with m1, then a commutativity con.ict \nis detected, and an arbitration process is begun to determine which iterations should be aborted, as \ndescribed below. If m1 commutes with all the entries in the log, the signature of m1 is appended to the \nlog. When i either abortsor commits,allthe entriesinthecon.ictlog insertedby i are removed from the con.ict \nlog. This model for con.ict logs, while simple, is not ef.cient since it requires a full scan of the \ncon.ict log whenever an iteration calls a method on the associated object. In our actual implementation, \ncon.ict logs consist of separate con.ict sets for each method in the class. Now when i calls m1, only \nthe con.ict sets for methods which m1 may con.ict with are checked; the rest are ignored. There are two \noptimizations that we have implemented for con\u00ad.ict logs. First, each iteration caches its own portion \nof the con.ict logs in a private log called its local log. This local log stores a record of all the \nmethods the iteration has successfully invoked on the object. When an iteration makes a call, it .rst \nchecks its local log. If this local log indicates that the invocation will succeed (either because that \nsame method has been called before or other methods, whose commutativity implies that the current method \nalso commutes, have been called before2), the iteration does not need to check the object s con.ict log. \nAsecond optimization is that not all objects have con.ict logs associated with them.Forexample, the triangles \ncontainedin the meshdonot;theirinformationismanagedbythe con.ictloginthe mesh. If this optimization is \nused, care must be taken that modi.\u00adcations to the triangle are only made through the mesh interface. \nIn general, program analysis is required to ensure that this optimiza\u00adtion is safe. 4.3.2 CommitPool \nWhen an iteration attempts to commit, the commit pool checks two things: (i) that the iteration is at \nthe head of the commit queue, and (ii) that the priority of the iteration is higher than all the elements \nleftinthe set/poSetbeing iteratedover3.Ifboth conditionsaremet, the iteration can successfully commit. \nIf the conditions are not met, the iteration mustwait untilithasthe highest priorityinthe system; its \nstatus is set to RTC, and the thread is allowed to begin another iteration. 2For example, if an iteration \nhas already successfully invoked add(x), then contains(x) will clearly commute with method invocations \nmade by other ongoing iterations. 3This is to guard against a situation where an earlier committed iteration \nadds a new element with high priority to the collection which has not yet been consumed by the iterator \nWhen an iteration successfully commits, the thread that was running that iteration also checks the commit \nqueue to see if more iterations in the RTC state canbe committed.Ifso,it commits those iterations before \nbeginning the execution of a new iteration. When an iteration has to be aborted, the status of its record \nis changed to ABORTED, but the commit pool takes no further action. Such iteration objects are lazily \nremoved from the commit queue when theyreach the head. Con.ict arbitration The other responsibility of \nthe commit pool is to arbitrate con.icts between iterations. When iterating over an unordered set, the \nchoice of which iteration to roll back in the eventofa con.ictis irrelevant.For simplicity, wealways \nchoose the iteration which detected the con.ict. However, when iterating over an ordered set, the lower \npriority iteration must be rolled back while the higher priority iteration must continue.Without doing \nso, there exists the possibility of deadlock. Thus, when iteration i1 calls a method on a shared object \nand a con.ict is detected with iteration i2, the commit pool arbitrates basedontheprioritiesofthetwo \niterations.If i1 has lower priority, it simply performs the standard rollback operations. The thread \nwhich was executing i1 then begins a new iteration. This situation is complicated when i2 is the iteration \nthat must be rolled back. Because the Galois run time systems functions purely at the user level, there \nis no simple way to abort an iteration running on another thread.To address this problem, each iteration \nrecord has an iteration lock as shown in Figure 11. When invoking methods on shared objects, each iteration \nmust own the iteration lock in its record. Thus, the thread running i1 does the following: 1. It attempts \nto obtain i2 s iteration lock. By doing so, it ensures that i2 is not modifying anyshared state. 2. \nIt aborts i2 by executing i2 s undo log and clearing the various con.ict logs of i2 s invocations. Note \nthat the control .ow of the thread executing i2 does not change; that thread continues as if no rollback \nis occurring. 3. It sets the status of i2 to ABORTED. 4. It then resumes its execution of i1, which \ncan now proceed as the con.ict has been resolved.  Ontheothersideofthis arbitration process,thethreadexecuting \ni2 will realize that i2 has been aborted when it attempts to invoke another method on a shared object \n(or attempts to commit). At this point, the thread will see that i2 sstatus is ABORTED and will cease \nexecution of i2 and begin a new iteration. When an iteration has tobe aborted, the callbacks in its undo \nlog are executed in LIFO order. Because the undo log must persist until an iteration commits, we must \nensure that all the arguments usedbythe callbacks remainvalid untilthe iterationcommits.Ifthe arguments \nare pass-by-value, there is no problem; they are copied when the callback is created. A more complex \nsituation is when arguments are pass-by-reference or pointers. The .rst problem is that the underlying \ndata which the reference or pointer points to may be changed during the course of execution. Thus, the \ncallback may be called with inappropriate arguments. However, as long as all changes to the underlying \ndata also occur through Galois interfaces, the LIFOnature of the undo log ensures that theywill be rolled \nbackas necessary before the callback uses them. The second problem occurswhenan iteration attemptstofreeapointer,asthere \nis no simple way to undo a call to free. The Galois run-time avoids thisproblemby delaying all calls \nto free until an iteration commits. This does not affect the semantics of the iteration, and avoids the \nproblem of rolling back memory deallocation.  4.4 Discussion Set iterators: Although the Galois set \niterators introduced in Sec\u00adtion 4.1 were motivated in this paper by the two applications dis\u00ad cussedin \nSection2,theyarevery general,andwehavefoundthem to be useful for writing other irregular applications \nsuch as advanc\u00ading front mesh generators [23], andWalkSATsolvers [33]. Many of these applications use \nwork-list -style algorithms, for which Galois iterators are natural, and the Galois approach allows us \nto exploit data-parallelism in these irregular applications. SETLwas probablythe .rst languageto introducean \nunordered set iterator [19],but this construct differs from its Galois counter\u00ad part in important ways. \nIn SETL, the set being iterated over can be modi.ed during theexecutionof the iterator,but these modi.ca\u00adtions \ndo not take effect until the execution of the entire iterator is complete. In our experience, this is \ntoo limiting because work-list algorithms usually involve data-structure traversals of some kind in which \nnew work is discovered during the traversal. The tuple iter\u00adator in SETL is similar to the Galois ordered-set \niterator,but the tuple cannotbe modi.ed duringtheexecutionofthe iterator, which limits its usefulness \nin irregular applications. Finally, SETL was a sequential programming language. DO-loops in FORTRAN are \na special case of the Galois ordered-set iterator in which iteration is performed over integers in some \ninterval. Amore complete design than ours would include iterators over multisets and maps, which are \neasy to add to Galois. MATLAB or FORTRAN-90-style notation like [low:step:high] for spec\u00adifying ordered \nand unordered integers within intervals would be useful.We believe it is also advisable to distinguish \nsyntactically between DO-ALL loops and unordered-set iterators over integer ranges, since in the former \ncase, the programmer can assert that run-time dependence checks are unnecessary, enabling more ef.\u00adcient \nexecution. For example, in the standard i-j-k loop nest for matrix-multiplication, the i and jloops are \nnot only Galois-style unordered-set iteratorsover integer intervalsbut theyareeven DO-ALL loops; the \nkloop is an ordered-set interator if the accumula\u00adtions to elements of the Cmatrix must be done in order. \nSemantic commutativity: Without commutativity information, an object can be accessed by at most one iteration \nat a time, and that iteration shuts out other iterations until it commits. In this case, inverse methods \ncanbe implemented automaticallybydatacopying as is done in software transactional memories. In the applications \nwe have looked at, most shared objects are instances of collections, which are variations of sets, so \nspecifying commutativity information and writing inverse methods has been straightforward.Forexample, \nthekd-treeis justa set with an ad\u00additional method for .nding the nearest neighbor of an element in the \nset. Note that the design of Galois makes it easy to replace sim\u00adple data structures with clever, hand-tuned \nconcurrent data struc\u00adtures [32] if necessary, without changing the rest of the program. The useof commutativityin \nparallel programexecutionwasex\u00adploredby Bernsteinasfar backas 1966[4].Inthe contextof con\u00ad current database \nsystems,Weihl describeda theoretical framework for using commutativity conditions for concurrency control \n[40]. HerlihyandWeihlextended thisworkbyleveraging ordering con\u00adstraints to increase concurrency but \nat the cost of more complex rollback schemes [16]. In the context of parallel programming, Steele described \na sys\u00adtem for exploiting commuting operations on memory locations in optimistic parallel execution [18]. \nHowever, commutativity is still tied to concrete memory locations and does not exploit properties of \nabstract data types likeGalois does. Diniz and Rinard performed static analysis to determine concrete \ncommutativity of methods for use in compile-time parallelization [10]. Semantic commutativity, as usedin \nGalois,is more generalbutit mustbe speci.edby the class designer.Wu andPaduahave proposed to use high \nlevel se\u00admanticsof container classes [42]. Theypropose makinga compiler aware ofproperties ofabstract \ndata types such as stacks and sets to permit more accurate dependence analysis. Recently, Ni et al [24] \nhave proposed to extend conventional transactional memory with a notion of abstract locking to intro\u00adduce \nthe notion of semantic con.icts. Carlstrom et al have taken a similar approach to the Java collections \nclasses [6]. Semantic com\u00ad mutativity provides another way of specifying open nesting. More experience \nis needed before the relative advantages of the two ap\u00adproaches become clear,but we believethat semantic \ncommutativity is an easier notion for programmers to understand. 5. Evaluation We have implemented the \nGalois system in C++ on two Linux platforms:(i)a4processor,1.5GHz Itanium2,with16KBofL1, 256KB of L2 \nand 3MB of L3 cache per processor, and (ii) a dual processor dual-core 3.0 GHz Xeon system, with 32KB \nof L1 per core and 4MB of L2 cache per processor. The threading library on both platforms was pthreads. \n5.1 Delaunay Mesh Re.nement We .rst wrote a sequential Delaunay mesh re.nement program without locks, \nthreads etc. to serve as a reference implementation. We then implemented a Galois version (which we callmeshgen), \nanda .ne-grain lockingversion(FGL)that uses locks on individ\u00adual triangles. The Galois version uses the \nset iterator, and the run\u00adtime system described in Section 4.3. In all three implementations, themeshwas \nrepresentedbyagraphthatwas implementedasaset of triangles, where each triangle maintained a set of its \nneighbors. This is essentially the same as the standard adjacency list repre\u00adsentation of graphs.For \nmeshgen, code for commutativity checks was added by hand to this graph class; ultimately, we would like \nto generate this code automatically from high level commutativity speci.cationslike thosein Figure9.WeusedanSTL \nqueuetoim\u00ad plementtheworkset.We referto thesedefault implementationsof meshgen and FGL as meshgen(d) \nand FGL(d). To understand the effect of scheduling policyon performance, we implemented two more versions, \nFGL(r) and meshgen(r), in which the work-set was implemented by a data structure that re\u00adturned a random \nelement of the current set. The input data set was generated automatically using Jonathan Shewchuk s \nTriangle program [35]. It had 10,156 triangles and boundary segments, of which 4,837 triangles were bad. \nExecution times and speed-ups. Execution times and self-relative speed-ups for the .ve implementations \non the Itanium machine are shownin Figure 12(a,b). The referenceversionis thefastest ona single processor. \nOn4processors, FGL(d) and FGL(r) differ only slightly in performance. Meshgen(r) performed almost as \nwell as FGL, although surprisingly,meshgen(d)was twice as slowas FGL. Statistics on committed and aborted \niterations. To understand these issues better, we determined the total number of committed and aborted \niterationsfordifferentversionsof meshgen,asshown in Figure 12(c). On 1 processor, meshgen executed and \ncommit\u00ad ted 21,918 iterations. Because of the inherent non-determinism of the set iterator, the number \nof iterations executed by meshgen in parallel varies from run to run (the same effect will be seen on \none processor if the scheduling policyis varied). Therefore, we ran the codes a large number of times, \nand determined a distribution for the numbers of committed and aborted iterations. Figure 12(c) shows \nthat on 4 processors, meshgen(d) committed roughly the same numberof iterations asit did on1processor,but \nalso aborted almost as manyiterationsdue to cavity con.icts. The abort ratio for meshgen(r) is much lower \nbecause the scheduling policy reduces (a) Execution times (b) Self-relative Speed-ups Committed Aborted \n#of proc. Max Min Avg Max Min Avg 1 21918 21918 21918 n/a n/a n/a 4(meshgen(d)) 22128 21458 21736 28929 \n27711 28290 4(meshgen(r)) 22101 21738 21909 265 151 188 (c) Committed and aborted iterations for meshgen \n (d) Instructions per iteration on a single processor (e) Breakdown of instructions and cycles in meshgen \n Instruction Type reference meshgen(r) Branch 38047 70741 FP 9946 10865 LD/ST 90064 165746 Int 304449 \n532884 Total 442506 780236  (f) Breakdown of Galois overhead #of procs Client Object Runtime Total 1 \n4 1.177 2.769 0.6208 3.600 0.6884 4.282 2.487 10.651 (g) L3 misses (in millions) for meshgen(r)  Figure \n12. Mesh re.nement results: 4-processor Itanium the likelihood of con.icts between processors. This accounts \nfor the performance difference between meshgen(d) and meshgen(r). Because the FGL code is carefully tuned \nby hand, the cost of an aborted iteration is substantially less than the corresponding cost in meshgen, \nso FGL(r) performs onlya littlebetter than FGL(d). It seems counterintuitive that a randomized scheduling \npolicy could be bene.cial, but a deeper investigation into the source of cavity con.icts showed that \nthe problem could be attributed to our useofanSTL queueto implementtheworkset.Whenabad triangle is re.nedbythe \nalgorithm,aclusterof smallerbad trianglesmaybe created within the cavity. In the queue data structure, \nthese new bad triangles are adjacent to each other, so it is likely that theywill be scheduled togetherfor \nre.nement on different processors, leading to cavity con.icts. One conclusion from these experiments \nis that domain knowl\u00adedge is invaluable for implementing a good scheduling policy. Instructions and cycles \nbreakdown. Figure 12(d) shows the breakdown of different types of instructions executed by the ref\u00aderence \nand meshgen versions of Delaunay mesh re.nement when they are run on one processor. The numbers shown \nare per itera\u00adtion; in sequential execution, there are no aborts, so these numbers give a pro.le of a \ntypical iteration in the two codes. Each itera\u00adtionof meshgen performs roughly10,000 .oating-point operations \nand executes almost a million instructions. These are relatively long-running computations. Meshgen executes \nalmost 80% more instructions than the ref\u00aderenceversion.To understandwhere theseextracycles were being \nspent, we instrumented the code usingPAPI. Figure 12(e) showsa breakdown of the total number of instructions \nand cycles between the clientcode(thecodeinFigure7),the sharedobjects(graphand workset), and the Galois \nruntime system. The4processor numbers are sums across all four processors. The referenceversion performs \nalmost 9.8 billion instructions, and this is roughly the same as the number of instructions executed \nin the client code and shared ob\u00adjects in the 1 processor version of meshgen and the 4 processor version \nof meshgen(r). Because meshgen(d) has a lot of aborts, it spends substantially more time in the client \ncode doing work that gets aborted and in the runtime layer to recover from aborts. Wefurtherbrokedownthe \nGaloisoverheadintofourcategories: commit and abort overheads, which are the time spent commit\u00adting iterations \nand aborting them, respectively; scheduleroverhead, which includes time spent arbitrating con.icts; and \ncommutativity overhead, which is the time spent performing con.ict checks. The results, as seen in Figure \n12(f), show that roughly three fourths of the Galois overhead goes in performing commutativity checks. \nIt is clearthatreducingthisoverheadiskey to reducingtheoverall overhead of the Galois run-time. The1processorversionof \nmeshgenexecutes roughly the same numberof instructions asthe4 processor version.Wedonotget perfect self-relative \nspeedup because some of these instructions takelongertoexecuteinthe4processorversionthaninthe1pro\u00adcessor \nversion. There are two reasons for this: contention for locks in shared objects and the runtime system, \nand cache misses due to invalidations. Contention is dif.cult to measure directly, so we lookedat cachemisses \ninstead.Onthe4processor Itanium, there is no shared cache, so we measured L3 cache misses. Figure 12(g) \nshowsL3 misses; the4processor numbers are sums across all pro\u00adcessors for meshgen(r). Most of the increase \nin cache misses arises from code in the shared object classes and in the Galois runtime. An L3 miss costs \nroughly 300 cycles on the Itanium, so it can be seen thatover halfoftheextracyclesexecutedbythe4processor \nversion, when comparedtothe1processorversion, are lostinL3 misses. The rest of the extra cycles are lost \nin contention. (a) Execution times (b) Self-relative speed-ups (c) Commit pool occupancyby RTC iterations \n (d) Committed and aborted iterationsin treebuild (e) Instructions per iteration on a single processor. \n Committed Aborted #of proc. Max Min Avg Max Min Avg 1 57846 57846 57846 n/a n/a n/a 4 57870 57849 57861 \n3128 1887 2528 Instruction Type reference treebuild Branch 7162 18187 FP 3601 3640 LD/ST 22519 48025 \nInt 70829 146716 Total 104111 216568 (f) Breakdown of instructions and cycles (g) Breakdown of Galois \noverhead #of procs User Object Runtime Total 1 4 0.5583 2.563 3.102 12.8052 0.883 5.177 4.544 20.545 \n (h) Number of L3 misses (in millions) on different numbers of processors. Figure 13. Agglomerative clustering \nresults: 4-processor Itanium Table 1. Results on dual-core, dual-processor Intel Xeon meshgen(p) treebuild \nCores Time (s) Speedup Time (s) Speedup 1 2(non-shared L2) 2(shared L2) 12.5 8.1 6.7 1.0 1.5 1.9 8.19 \n7.77 4.66 1.0 1.05 1.78  5.2 Agglomerative clustering For the agglomerative clustering problem, the \ntwo main data struc\u00adtures are the kd-tree and the priority queue. The kd-tree interface is essentially \nthe same as Set,but with the addition of the nearest neighbor(nearest)method. The priority queue is an \ninstance of a poSet. Since the priority queue is used to sequence iterations, the removal and insertion \noperations(get and add respectively) are orchestrated by the commit pool. To evaluate the agglomerative \nclustering algorithm, we modi\u00ad.ed anexisting graphics application called lightcuts that providesa scalable \napproachto illumination[39].Thiscodebuildsalighthier\u00ad archybased ona distance metric thatfactorsin Euclidean \ndistance, light intensity and light direction.We modi.ed the objects usedin the light clustering code \nto use Galois interfaces and the poSet it\u00aderator for tree construction. The overall structure of the \nresulting codewas discussedin Figure5.We will referto this Galoisversion as treebuild.We compared the \nrunning time of treebuild against a reference version which performed no threading or locking. Figure \n13 shows the results on the Itanium machine. These re\u00ad sults are similar to the Delaunay mesh generation \nresults discussed in Section 5.1, so we describe only the points of note. The self\u00ad relative speed-ups \nin Figure 13(b) show that despite the serial de\u00ad pendence order imposedbythe priority queue,the Galois \nsystemis able to expose a signi.cant amount of parallelism. The mechanism that allows us to do this is \nthe commit pool, which allows threads to begin execution of iterations even if earlier iterations have \nyet to commit.To understand the role of the commit pool quantitatively, we recordedthe number of iterations \nin RTC state every time the commit pool created, aborted or committed an iteration. This gives an idea \nof how deeply into the ordered set we are speculating to keep all the processorsbusy. Figure 13(c) showsa \nhistogramof this information (the x-axis is truncated to reveal detail around the origin). We see that \nmost of the time, we do not need to spec\u00adulate too deeply. However, on occasion, we must speculate over \n100 elements deep into the ordered set to continue making forward progress. Despite this deep speculation, \nthe number of aborted iter\u00adations is relatively small because of the high level of parallelism in this \napplication, as discussed in Section 2.2. Note that commit pool occupancy is not the same as parallelism \nin the problem because we create iteration records in the commit pool only when a thread needs work; \nthe priority queue is distinct from the commit pool. Wealsoseethatduetotheoverheadof managingthecommitpool, \nthe scheduler accounts for a signi.cant percentage of the overall Galois overhead, as seen in Figure \n13(g). Figure 13(h) shows that most of the loss in self-relative speedup whenexecutingon4processorsisdueto \nincreasedL3 cache misses from cache-line invalidations. 5.3 Results on Xeon To con.rm the role of cache \ninvalidation misses, we investigated the performanceofmeshgenandtreebuildonadual-core,dualpro\u00adcessor \nXeon system. In this asymmetric architecture, cores on the same package share the lowest level of cache \n(in this case, L2). Therefore,aprogramrunusingtwo coresonthesamepackagewill incur no L2 cache line invalidations, \nwhile the same program run\u00adning on two cores on separate packages will suffer from additional cache invalidation \nmisses (capacity misses may be reduced because the effective cache size doubles). Table1shows the performance \nof the two programs when run on a single core and on two cores. We see that when the two cores are on \nthe same package, we achieve near-perfect speedup, but the speedup is much less when the two cores are \non separate packages. This con.rms that a substantial portion of ef.ciencyloss arises from cache line \ninvalidations due to data sharing, so further improvements in performance require attendingto locality. \n6. Conclusions and OngoingWork The Galois system is the .rst practical approach we know of for exploiting \ndata-parallelism in work list based algorithms that deal with complex, pointer-based data structures \nlike graphs and trees. Our approachis basedon(1)asmall numberof syntactic constructs for packaging optimistic \nparallelization as iteration over mutable ordered and unordered sets, (2) assertions about methods in \nclass libraries, and (3) a runtime scheme for detecting and recovering from potentially unsafe accesses \nto shared memory made by an optimistic computation. The execution model is an object-based shared-memory \nmodel. By exploiting the high level semantics of abstract data types, the Galois system is able to allow \nconcurrent accessesand updatesto shared objects.Wehavesomeexperiencein massaging existing object-oriented \ncodes in C++ to use the Galois approach, and the effort has not been daunting at least for codes that \nuse collections of various sorts. Our experimental results show that (1) our approach is promis\u00ading, \n(2) schedulingiterations to reduce aborted computations is im\u00adportant, (3) domain knowledge may be important \nfor good schedul\u00ading, and (4) locality enhancement is critical for obtaining better performance than \nour current approach is able to provide. Our application studies suggest that the objective of compile\u00adtime \nanalysis techniques such as points-to and shape analysis should be to improve the ef.ciency of optimistic \nparallelization, rather than to perform static parallelization of irregular programs. These techniques \nmight also help in veri.cation of commutativity conditionsagainstaclass speci.cation. Static parallelizationworks \nfor regular programs because the parallelism in dense-matrix al\u00adgorithms is independent of the values \nin dense matrices. Irregular programs are fundamentally different, and no static analysis can uncover \nthe parallelism in manyif not most irregular applications. While exposing and exploiting parallelism \nis important, one of the central lessons of parallel programming is that exploiting lo\u00adcality is critical \nfor scalability. Most work in locality enhancement has focused on regular problems, so new ideas may \nbe required to makeprogress on this front.Webelievethat the approach described inthispaperforexposing \nparallelisminirregular applicationsisthe right foundation for solving the problem of exploiting parallelism \nin irregular applications in a scalable way. Acknowledgments We would like to thank Khubaib Khubaib in \nour group for his measurements of Galois overhead, and Ramesh Peri and David Levinthal at Intel, Austin \nDivision for their help with VTune. Fi\u00adnally,wewouldliketothankTim Harrisforbeingagood shepherd on behalf \nof the PLDI program committee. References [1] C. Scott Ananian, Krste Asanovic, BradleyC.Kuszmaul, Charles \nE. Leiserson, and Sean Lie. Unbounded transactional memory. In HPCA 05: Proceedings of the 11th International \nSymposium on High-Performance Computer Architecture, 2005. [2] Christos D. Antonopoulos, Xiaoning Ding, \nAndreyChernikov, Filip Blagojevic, Dimitrios S. Nikolopoulos, and Nikos Chrisochoides. Multigrain parallel \ndelaunay mesh generation: challenges and opportunities for multithreaded architectures. In ICS 05: Proceedings \nof the 19th annual international conference on Supercomputing,2005. [3] J.L. Bentley. Multidimensional \nbinary search trees used for associative searching. Communications of theACM, 18(9):509 517, 1975. [4] \nA. Bernstein. Analysis of programs for parallel processing. IEEE Transactions on Electronic Computers, \n1966. [5] Michael Burke,Paul Carini, and Jong-Deok Choi. Interprocedural pointer alias analysis. Technical \nReport IBM RC 21055, IBM Yorktown Heights, 1997. [6] Brian D. Carlstrom, Austen McDonald, Christos Kozyrakis, \nand Kunle Olukotun. Transactional collection classes. InPrinciples and PracticesofParallelProgramming \n(PPoPP), 2007. [7] C.C.Foster and E.M.Riseman. Percolation of code to enhance parallel dispatching andexecution. \nIEEE Transactions on Computers, 21(12):1411 1415, 1972. [8] L. Paul Chew. Guaranteed-quality mesh generation \nfor curved surfaces. In SCG 93: Proceedings of the ninth annual symposium on Computationalgeometry, pages \n274 280, 1993. [9] Johan de Galas. The quest for more processing power: is the single core CPU doomed? \nhttp://www.anandtech.com/cpuchipsets/ showdoc.aspx?i=2377, February 2005. [10] Pedro C. Diniz and Martin \nC. Rinard. Commutativity analysis: a new analysis technique for parallelizing compilers. ACMTrans. Program. \nLang. Syst., 19(6):942 991, 1997. [11] Joseph A. Fisher. Very long instruction word architectures and \nthe eli-512. In ISCA 98: 25 years of the international symposia on Computer architecture (selected papers), \n1998. [12] Lance Hammond, Vicky Wong, Mike Chen, Brian D. Carlstrom, JohnD.Davis, Ben Hertzberg, ManoharK. \nPrabhu, HonggoWijaya, ChristosKozyrakis, andKunle Olukotun. Transactional memory coherence and consistency. \nISCA 2004, 00:102, 2004. [13] Tim Harris and Keir Fraser. Language support for lightweight transactions. \nIn OOPSLA 03: Proceedings of the 18th annual ACM SIGPLAN conference on Object-oriented programing, systems, \nlanguages, and applications, pages 388 402, 2003. [14] John Hennessy andDavidPatterson, editors. Computer \nArchitecture: AQuantitative Approach. Morgan Kaufmann, 2003. [15] Maurice Herlihyand J. Eliot B. Moss. \nTransactional memory: ar\u00adchitectural support for lock-free data structures. In ISCA 93: Pro\u00adceedings \nof the 20th annual international symposium on Computer architecture,pages 289 300,NewYork,NY,USA, 1993.ACM \nPress. [16] Maurice P. Herlihy and William E. Weihl. Hybrid concurrency control for abstract data types. \nIn PODS 88: Proceedings of the seventhACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems, \npages 201 210,NewYork,NY, USA, 1988. [17] David R. Jefferson. Virtual time. ACMTrans. Program. Lang. \nSyst., 7(3):404 425, 1985. [18]GuyL.SteeleJr.Making asynchronous parallelismsafefortheworld. In Proceedings \nof the 17th symposium on Principles of Programming Languages, pages 218 231, 1990. [19] J.T.Schwartz, \nR.B.K. Dewar, E. Dubinsky, and E. Schonberg. Programming with sets: An introduction to SETL. Springer-Verlag \nPublishers, 1986. [20] Ken Kennedy and John Allen, editors. Optimizing compilers for modren architectures:a \ndependence-based approach. Morgan Kaufmann, 2001. [21] Kevin E. Moore, Jayaram Bobba, Michelle J. Moravan, \nMark D. Hill, and David A.Wood. Logtm: Log-based transactional memory. In HPCA 06: Proceedings of the \n12th International Symposium on HighPerformance ComputerArchitecture, 2006. [22] J. Eliot B. Moss and \nAntony L. Hosking. Nested transactional memory: Model and preliminary architectural sketches. In SCOOL \n05: Sychronization and Concurrency in Object-Oriented Languages, 2005. [23] J.B.C Neto,P.A.Wawrzynek, \nM.T.M. Carvalho, L.F. Martha, and A.R. Ingraffea. An algorithm for three-dimensional mesh generation \nfor arbitrary regions with cracks. Engineering with Computers, 17:75 91, 2001. [24]YangNi,Vijay Menon, \nAli-Reza Adl-Tabatabai, AntonyL. Hosking, Rick Hudson, J. Eliot B. Moss, Bratin Saha, andTatiana Shpeisman. \nOpen nesting in software transactional memory. In Principles and PracticesofParallelProgramming (PPoPP), \n2007. [25] Openmp: A proposed industry standard api for shared memory programming. See www.openmp.org, \nOctober 28, 1997. [26] Michael Steinbach Pang-Ning Tan and Vipin Kumar, editors. Introduction to Data \nMining. Pearson AddisonWesley, 2005. [27] R. Ponnusamy, J. Saltz, and A. Choudhary. Runtime compilation \ntechniques for data partitioning and communication schedule reuse. In Proceedings of the 1993 ACM/IEEE \nconference on Supercomputing, 1993. [28] Hany E. Ramadan, Donald E. Porter Christopher J. Rossbach, Owen \nS. Hofmann, Aditya Bhandari, and EmmettWitchel. Trans\u00adactional memory designs for an operating system. \nIn International Symposium on Computer Architecture (ISCA), 2007. [29] Lawrence Rauchwerger and David \nA. Padua. Parallelizing while loops for multiprocessor systems. In IPPS 95: Proceedings of the 9th International \nSymposium onParallelProcessing, 1995. [30] Lawrence Rauchwerger and David A. Padua. The lrpd test: Speculative \nrun-time parallelization of loops with privatization and reduction parallelization. IEEETrans.Parallel \nDistrib. Syst., 10(2):160 180, 1999. [31]M.Sagiv,T.Reps,andR.Wilhelm. Solving shape-analysis problems \nin languages with destructive updating. In Proceedings of the 23rd AnnualACM Symposium on the Principles \nof Programming Languages, St. PetersburgBeach, FL, January 1996. [32]William Scherer and Michael Scott. \nSimple,fast, and practical non\u00adblocking and blocking concurrent queue algorithms. In Proceedings of the \nFifteenth ACM Symposium on Principles of Distributed Computing, 1996. [33] B. Selman, H. Levesque, and \nD. Mitchell. A new method for solving hard satis.ability problems. In Proceedings of theTenth National \nConference on Arti.cial Intelligence, pages 440 446, 1992. [34] Nir Shavit and DanTouitou. Software transactional \nmemory. In PODC 95: Proceedings of the fourteenth annualACM Symposium on Principles of Distributed Computing, \npages 204 213, 1995. [35] Jonathan Richard Shewchuk. Triangle: Engineering a 2D Quality Mesh Generator \nand DelaunayTriangulator. In Applied Computa\u00adtional Geometry:Towards Geometric Engineering, volume 1148 \nof Lecture Notes in Computer Science, pages 203 222. May 1996. [36] J. Greggory Steffan, Christopher \nB. Colohan, Antonia Zhai, and Todd C. Mowry. Ascalable approach to thread-level speculation. In ISCA \n00: Proceedings of the 27th annual international symposium on Computer architecture, 2000. [37] RobertTomasulo. \nAn algorithm forexploiting multiple arithmetic units. IBMJournal, 11(1):25 33, 1967. [38] Christoph von \nPraun, Luis Ceze, and Calin Cascaval. Implicit parallelism with ordered transactions. In Principles and \nPractices ofParallel Programming (PPoPP), 2007. [39] Bruce Walter, Sebastian Fernandez, Adam Arbree, \nKavita Bala, Michael Donikian, and Donald Greenberg. Lightcuts: a scalable approach to illumination. \nACM Transactions on Graphics (SIG-GRAPH), 24(3):1098 1107, July 2005. [40]W.E.Weihl. Commutativity-based \nconcurrencycontrol for abstract data types. IEEETransactions on Computers, 37(12), 1988. [41] NiklausWirth. \nAlgorithms+ Data Structures = Programs. Prentice Hall PTR, Upper Saddle River, NJ, USA, 1978. [42] PengWu \nandDavidA.Padua. Beyond arrays -a container-centric approach for parallelization of real-world symbolic \napplications. In LCPC 98: Proceedings of the 11th InternationalWorkshop on Languages and Compilers forParallel \nComputing, 1999. [43] L. RauchwergerY. Zhan and J.Torrellas. Hardware for speculative run-time parallelization \nin distributed shared-memory multiproces\u00adsors. In HPCA 98: Proceedings of the 4th International Symposium \non High-Performance Computer Architecture, page 162, 1998.   \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Irregular applications, which manipulate large, pointer-based data structures like graphs, are difficult to parallelize manually. Automatic tools and techniques such as restructuring compilers and run-time speculative execution have failed to uncover much parallelism in these applications, in spite of a lot of effort by the research community. These difficulties have even led some researchers to wonder if there is any coarse-grain parallelism worth exploiting in irregular applications.</p> <p>In this paper, we describe two real-world irregular applications: a Delaunay mesh refinement application and a graphics application thatperforms agglomerative clustering. By studying the algorithms and data structures used in theseapplications, we show that there is substantial coarse-grain, data parallelism in these applications, but that this parallelism is very dependent on the input data and therefore cannot be uncoveredby compiler analysis. In principle, optimistic techniques such asthread-level speculation can be used to uncover this parallelism, but we argue that current implementations cannot accomplish thisbecause they do not use the proper abstractions for the data structuresin these programs.</p> <p>These insights have informed our design of the <i>Galois system</i>, an object-based optimistic parallelization system for irregular applications. There are three main aspects to Galois: (1) a small number of syntactic constructs for packaging optimistic parallelism as iteration over ordered and unordered sets, (2)assertions about methods in class libraries, and (3) a runtime scheme for detecting and recovering from potentially unsafe accesses to shared memory made by an optimistic computation.</p> <p>We show that Delaunay mesh generation and agglomerative clustering can be parallelized in a straight-forward way using the Galois approach, and we present experimental measurements to show that this approach is practical. These results suggest that Galois is a practical approach to exploiting data parallelismin irregular programs.</p>", "authors": [{"name": "Milind Kulkarni", "author_profile_id": "81331496893", "affiliation": "University of Texas, Austin, TX", "person_id": "P871685", "email_address": "", "orcid_id": ""}, {"name": "Keshav Pingali", "author_profile_id": "81100554731", "affiliation": "University of Texas, Austin, TX", "person_id": "PP39048331", "email_address": "", "orcid_id": ""}, {"name": "Bruce Walter", "author_profile_id": "81100010986", "affiliation": "Cornell University, Ithaca, TX", "person_id": "PP14016782", "email_address": "", "orcid_id": ""}, {"name": "Ganesh Ramanarayanan", "author_profile_id": "81320493826", "affiliation": "Cornell University, Ithaca, TX", "person_id": "P829711", "email_address": "", "orcid_id": ""}, {"name": "Kavita Bala", "author_profile_id": "81100081277", "affiliation": "Cornell University, Ithaca, TX", "person_id": "PP39026285", "email_address": "", "orcid_id": ""}, {"name": "L. Paul Chew", "author_profile_id": "81100237142", "affiliation": "Cornell University, Ithaca, TX", "person_id": "PP33024574", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250759", "year": "2007", "article_id": "1250759", "conference": "PLDI", "title": "Optimistic parallelism requires abstractions", "url": "http://dl.acm.org/citation.cfm?id=1250759"}