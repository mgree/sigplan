{"article_publication_date": "06-10-2007", "fulltext": "\n Fault-tolerant Typed Assembly Language Frances Perry Lester Mackey George A. Reis Jay Ligatti David \nI. August David Walker Departments of Computer Science and Electrical Engineering Department of Computer \nScience and Engineering Princeton University {frances, lmackey, gareis, august, dpw}@cs.princeton.edu \n Abstract A transient hardware fault occurs when an energetic particle strikes a transistor, causing \nit to change state. Although transient faults do not permanently damage the hardware, they may corrupt \ncomputa\u00adtions by altering stored values and signal transfers. In this paper, we propose a new scheme \nfor provably safe and reliable computing in the presence of transient hardware faults. In our scheme, \nsoftware computations are replicated to provide redundancy while special instructions compare the independently \ncomputed results to detect errors before writing critical data. In stark contrast to any previous efforts \nin this area, we have analyzed our fault tolerance scheme from a formal, theoretical perspective. To \nbe speci.c, .rst, we pro\u00advide an operational semantics for our assembly language, which includes a precise \nformal de.nition of our fault model. Second, we develop an assembly-level type system designed to detect \nreliabil\u00adity problems in compiled code. Third, we provide a formal speci.\u00adcation for program fault tolerance \nunder the given fault model and prove that all well-typed programs are indeed fault tolerant. In ad\u00addition \nto the formal analysis, we evaluate our detection scheme and show that it only takes 34% longer to execute \nthan the unreliable version. Categories and Subject Descriptors D.3.1 [Programming Lan\u00adguages]: Formal \nDe.nitions and Theory; B.8.1 [Performance and Reliability]: Reliability, Testing, and Fault-Tolerance \nGeneral Terms Languages, Reliability, Theory, Veri.cation Keywords transient hardware faults, soft faults, \nfault tolerance, type systems, typed assembly language 1. Introduction A transient fault or soft error \nis a temporary hardware failure that alters a signal transfer, a register value, or some other processor \ncomponent. While transient faults are temporary, they corrupt com\u00adputations and have led to costly failures \nin high-end systems in re\u00adcent years. For example, in 2000 there were reports that transient faults caused \ncrashes at a number of Sun s major customer sites, including America Online and eBay [2]. Later, Hewlett \nPackard admitted multiple problems in the Los Alamos Labs supercomput\u00aders due to transient faults [7]. \nFinally, Cypress Semiconductor has con.rmed The wake-up call came in the end of 2001 with a major Permission \nto make digital or hard copies of all or part of this work for personal or classroom use is granted without \nfee provided that copies are not made or distributed for pro.t or commercial advantage and that copies \nbear this notice and the full citation on the .rst page. To copy otherwise, to republish, to post on \nservers or to redistribute to lists, requires prior speci.c permission and/or a fee. PLDI 07 June 11 \n13, 2007, San Diego, California, USA. Copyright c . 2007 ACM 978-1-59593-633-2/07/0006. . . $5.00. University \nof South Florida ligatti@cse.usf.edu customer reporting havoc at a large telephone company. Techni\u00adcally, \nit was found that a single soft fail. . . was causing an inter\u00adleaved system farm to crash [28]. Unfortunately, \nwhile soft errors can already cause substantial reliability problems, current trends in hardware design \nsuggest that fault rates will increase in the future. More speci.cally, faster clock rates, increasing \ntransistor density, decreasing voltages and smaller feature sizes all contribute to increasing fault \nrates [1, 11, 21]. Due to a combination of these factors, fault rates in modern processors have been \nincreasing at a rate of approximately 8% per generation [3]. These trends are well known in the architecture \nand compiler communities, and, consequently, many solutions to the threat of soft errors have been proposed. \nAt a high level, all of these solutions involve adding redundancy to computations in one way or another, \nbut the speci.cs vary substantially. For instance, there are proposals involving hardware-only solutions \nsuch as error-correcting codes, watchdog co-processors [6] and redundant hardware threads [4, 9, 16, \n25] as well as software-only techniques that use both single and multiple cores [12, 13, 17, 18, 20, \n24]. Broadly speaking, if the technique can scale, hardware-only solutions are more ef.cient for a single, \n.xed reliability policy, but software-only solutions are more .exible (they may be deployed exactly when, \nwhere, and to the degree needed) and less costly in terms of hardware. In an at\u00adtempt to gain some of \nthe best of both worlds, researchers have also recently proposed hybrid software-hardware solutions involv\u00ading \nstrong fault tolerance mechanisms implemented in hardware but controlled by the software running on the \nprocessor [19]. Software-only and hybrid hardware-software techniques also possess at least one further, \nlittle-mentioned drawback they may not actually work. To be fair, many of these techniques appear ex\u00adtremely \npromising. However, as far as we are aware, the published transient fault-tolerance techniques come with \nno rigorous proofs that they guarantee any particular reliability properties. In gen\u00aderal, researchers \nsatisfy themselves with presenting an algorithm for fault-tolerance and leave the audience to judge for \nthemselves whether or not the algorithm is correct. In fact, the literature does not even precisely de.ne \nwhat it might mean for an assembly-level program to be fault tolerant. This paper tackles this gaping \nhole in the existing literature by de.ning a new hybrid hardware-software technique for tolerating transient \nfaults, and, unlike any previous work, actually proving it has strong fault-tolerance properties. The \nspeci.cation and proof of fault tolerance comes in several stages. First, before proving any particular \nproperties, it is neces\u00adsary to de.ne a fault model precisely. Most of the current litera\u00adture uses the \nSingle Event Upset (SEU) Model, which states that only one fault may occur during execution [16, 19, \n26]. However, the details of exactly where and when faults may occur are usually given in English. We \nalso assume the SEU model, but we specify exactly where by including faulty transitions as formal rules \nin the operational semantics of our assembly language. Second, it is necessary to state precisely what \nfault tolerance actually means. Abstractly, a program is fault-tolerant if no fault can change the observable \nbehavior of a program. More concretely, we assume our system operates in the presence of a memory\u00admapped \noutput device, and hence a program is not fault-tolerant if a fault can cause a deviation in the sequence \nof values written to memory. We formalize this property more precisely as a math\u00adematical theorem that \nrelates faulty and non-faulty executions of a program. Third, it is necessary to provide a technique \nfor actually proving that speci.c programs are fault tolerant relative to the fault model. Our proof \ntechnique is presented in the form of a type system. All well-typed programs satisfy variants of the \nstandard progress and preservation lemmas, even in the presence of transient faults, as well as the stronger \nfault tolerance property mentioned above. In addition to being theoretically important as a proof technique \nfor fault tolerance, the type system can be used to debug compilers that intend to generate reliable \ncode. If the output from these compilers type check, their code will have strong fault tolerance guarantees. \nIn the past, researchers have proposed testing compiler outputs using fault injection techniques that \nrandomly insert errors into programs. However, using a type checker in this case is a much better idea. \nIn principle, a conventional testing technique would need to test all combinations of features in conjunction \nwith all combinations of faults, causing an explosion in the number of test cases, and yet still failing \nto achieve perfect fault coverage in practice. By using the type checker we have designed, one achieves \nperfect fault coverage relative to the fault model without needing to increase the compiler test suite. \nThe rest of this paper presents the details of our hybrid hardware\u00adsoftware fault-tolerance technique. \nSection 2 presents the syntax and operational semantics of the new, idealized assembly language we have \ndesigned for fault tolerance. It is a RISC-based architecture with special instructions to facilitate \nreliable communication with memory and to detect control-.ow faults. Section 3 presents the key principles \nand formal de.nitions for the fault-tolerant assem\u00adbly language type system (TALFT for short). Though \nthe typing rules are speci.c to our particular setting, the underlying princi\u00adples are more general; \nwe believe many of these principles will apply to reasoning about related fault-tolerant systems. Our \ninno\u00advative combination of a TAL-like type-theory with concepts from classical Hoare Logics is a particularly \ngeneral and important tech\u00adnical contribution. Section 4 describes the key theorems we have proven including \nProgress, Preservation, No False Positives, and Fault Tolerance. Section 5 provides empirical evidence \nthat our new hybrid solution to fault tolerance is feasible for many appli\u00adcations by measuring performance \nresults on simulated hardware. Related work is discussed in more detail in Section 6. Due to space considerations, \nsome of the technical details and all of the proofs have been omitted. A companion technical report [15] \ncontains the complete speci.cation of our system and a relatively detailed proof outline. 2. The Faulty \nHardware The faulty hardware is based on a simple RISC architecture, ex\u00adtended with features to support \ndetection of control-.ow faults and safe interaction with memory-mapped output devices. Correct use of \nthese features makes it possible to detect all faults that might change a program s observable behavior. \nMost practical systems also need a fault recovery mechanism of some kind. However, since recovery is \nlargely orthogonal to detection, we omit the former, fo\u00adcusing only on the latter in this paper. The \ngeneral strategy of every fault-tolerant program is to main\u00adtain two redundant and independent threads \nof computation, a green (G) computation and a blue (B) computation. The green computation generally leads \nslightly, and the blue computation generally trails, though there is a fair amount of .exibility in how \nthe instructions in each computation may be interleaved. Prior to writing data out to a memory-mapped \noutput device, the results of the two computations are checked for equivalence. If the results are not \nequivalent, the machine will signal that a fault has been detected. The arguments to any control-.ow \ntransfer must also be checked for faults. This methodology has been show in the litera\u00adture as an effective \nimplementation of fault tolerance [13, 18], and we expand on this style of implementation by formalizing \nthe fault model and coverage. The execution of assembly programs is speci.ed using a small\u00adstep operational \nsemantics that maps machine states (S) to other machine states. These machine states are made up of a \nnumber of components. The .rst component is the machine s register bank R, which is a total function \nthat maps register names to the values contained therein. The meta variable a ranges over all sorts of \nregisters, and meta variable r ranges only over general-purpose registers (r1, r2, ...). In addition \nto general-purpose registers, there are two program counter registers (pcG and pcB ), which contain the \nsame value unless there has been the fault. There is one additional special register, the destination \nregister, d . Its role in control-.ow checking will be explained later. To facilitate proofs of certain \ntheorems, the value in each regis\u00adter is tagged with the color (either green or blue) of the computation \nto which it belongs. However, these tags have no effect on the run\u00adtime behavior of programs.1 In addition \nto a register bank, the machine state includes a code memory C, which we model as a function mapping \ninteger addresses n to instructions.2 The machine also has a value memory M, which maps addresses to \ninteger values. In between the value memory and the processor is a special store queue, Q, which is used \nto detect faults before data is written to a memory-mapped output device. The store queue is a queue \nof address-value pairs. We will discuss the role of the queue in greater detail later. Overall, an abstract \nmachine state (S) may have the form fault , indicating the hardware has detected a transient fault, or \nthe ordi\u00adnary state (R,C,M,Q,ir), where the .rst four components are as discussed above, and ir is either \nan instruction i to be executed, or \u00b7 indicating the next instruction should be fetched from code memory. \nFigure 1 summarizes the syntax of machine states. Here and elsewhere in the paper, we use overbar notation \nto indicate a sequence of objects. 2.1 The Fault Model The operational semantics is designed both to \nmodel proper exe\u00adcution of machine instructions and to make perfectly explicit, pre\u00adcise, and transparent \nall of our assumptions about when and where faults may occur. The central operational judgment has the \nform S1 -.sk S2 , which expresses a single step transition from state S1 to state S2 while incurring \nkfaults and writing data s to a memory\u00admapped output device. We will work under the standard assumption \nof a single upset event and hence kwill always be either 0 or 1. The data s is a (possibly empty) sequence \nof address-value pairs. While the operational semantics models the internal workings of the ma\u00adchine, \nthe only externally observable behavior of the machine is the sequence of writes s to the output device \nor the signaling of a hardware-detected fault. If faults cause the processor to have dras\u00adtically different \ninternal behavior, but the externally observable se\u00adquence s is unchanged, we consider the program to \nhave executed successfully. 1 In contrast, the tags on instruction opcodes, to be introduced momentarily, \ndo have an effect on evaluation. 2 Address 0 is not considered a valid code address. colors c ::= G|B \ncolored values v ::= c n registers r ::= rn generalregs a ::= r |d|pcc register file R ::= \u00b7 |R,a . v \ncode memory C ::= \u00b7 |C,n . i value memory M ::= \u00b7 |M,n . n store queue Q ::= (n,n) ALU ops op ::= add \n|sub |mul instructions i ::= op rd,rs,rt |op rd,rs,v | ldc rd,rs |stc rd,rs |mov rd,v | bzc rz ,rd |jmpc \nrd instregister ir ::= i|\u00b7 state S ::= (R,C,M,Q,ir)|fault Figure 1. Syntax of instructions and machine \nstates. Different fault-tolerance techniques protect different compo\u00adnents of machines. In the literature, \nthe protected areas are usually inside the Sphere of Replication (SoR) [16]. In our case, we tar\u00adget \nfaults that may occur in data manipulated within the processor. We assume that both code memory C and \nvalue memory M are fully protected. This is often the case since error-correcting codes can very ef.ciently \nprotect memory. To make these assumptions explicit, the following three operational rules specify exactly \nhow faults may occur within our system. R(a)= cn (reg-zap) ' (R,C,M,Q,ir)-.1 (R[a . cn],C,M,Q,ir) ''' \nQ1 =(n1,n1 ),(m1,m),(n2,n2) '' Q2 =(n1,n1 ),(m2,m' ),(n2,n2) (Q-zap1) (R,C,M,Q1,ir)-.1 (R,C,M,Q2,ir) \n''' Q1 =(n1 ,n1 ),(m,m1),(n2 ,n2 ) ''' Q2 =(n1 ,n1 ),(m,m2),(n2 ,n2 ) (Q-zap2) (R,C,M,Q1,ir)-.1 (R,C,M,Q2,ir) \nRule reg-zap nondeterministically introduces a fault into any regis\u00adter by replacing the value in that \nregister with some other arbitrary value. There are no restrictions on how the underlying value might \nbe changed. For instance, code pointers can be changed to arbitrary integer values; references may no \nlonger be in bounds. However, the color tag is preserved to facilitate fault-tolerance proofs. Since \nthe color tag is .ctional (has no effect on run-time behavior), this poses no limitation on the fault \nmodel. Rules Q1 -zap and Q2-zap alter the contents of the store queue in similar ways. Formally, these \nare the only faults that can occur. However, no\u00adtice that since the program counters and targets of indirect \njumps are susceptible to the reg-zap rule, we effectively capture many forms of control-.ow faults studied \npreviously. Notice also that we do not explicitly consider faults that occur during execution of an instruction. \nHowever, many such faults may easily be shown equivalent to correct execution of an instruction composed \nwith a fault either immediately before or afterwards. For example, con\u00adsider a simple register-to-register \nadd instruction. Any fault within the adder hardware during execution of the add is equivalent to a correct \nadd followed by a fault in the destination register. An important bene.t of our formal model is that \nthere is actually some precise, concrete speci.cation to analyze. Moreover, if a researcher wants to \nreason about the consequences of some fault that lives outside the formal model, this may be done by \nadding a new operational rule to the system and studying its semantic effect. Instruction Fetch: Rval(pcG)= \nRval(pcB ) Rval(pcG). Dom(C) (fetch) (R,C,M,Q,\u00b7)-.0 (R,C,M,Q,C(Rval(pcG))) Rval(pcG) = Rval(pcB ) (fetch-fail) \n(R,C,M,Q,\u00b7)-.0 fault Basic Instructions: R' = R++[rd . Rcol(rt)(Rval(rs)opRval(rt))] (op2r) (R,C,M,Q,op \nrd,rs,rt)-.0 (R' ,C,M,Q,\u00b7) R' = R++[rd . c (Rval(rs)op n)] (op1r) (R,C,M,Q,op rd,rs,cn)-.0 (R' ,C,M,Q,\u00b7) \nR' = R++[rd . v] (mov) (R,C,M,Q,mov rd,v)-.0 (R' ,C,M,Q,\u00b7) Figure 2. Operational rules for basic instructions. \n 2.2 Instruction Semantics The syntax of machine instructions was presented along with the rest of the \ncomponents of our abstract machine in Figure 1. The semantics is described formally by the inference \nrules in Figures 2, 3, and 4, and explained informally below. The formal rules use several notational \nconventions. For instance, if R is a register .le then R(a)is the contents of register a and R[a . v]is \nthe updated register .le with register a mapped to v. R++ is the register .le that results from incrementing \nboth pcG and pcB by 1. If R(a)is the colored value cn, we write Rval(a)to denote n and Rcol(a)to ' denote \nc. The function find(Q,n)produces the .rst pair (n,n) ' that appears in Q, or ()if no pair (n,n)appears \nin Q. Instruction Fetch. The machine operates by alternatively fetch\u00ading an instruction from code memory \nand executing that instruc\u00adtion. When there is no current instruction to execute (i.e. ir = \u00b7), the fetch \nrule should .re. This rule tests for equality of the two program counters to check for faults and loads \nthe appropriate in\u00adstruction from code memory. If pcG and pcB are the same but Rval(pcG)is not a valid \naddress in code memory, execution gets stuck (no rule .res). Fortunately, however, well-typed programs \nnever get stuck, even when a single fault occurs. On the other hand, a fault can render the two program \ncounters inequivalent. In this case, rule fetch-fail .res and causes a transition to the fault state. \nAbstractly, this transition represents hardware detection of a tran\u00adsient fault. Controlled program termination \nor perhaps recovery may follow. Fault recovery is an orthogonal issue to fault detection, so we leave \nit unspeci.ed here. The fault model does not allow for the instruction itself to be corrupted. Basic \nInstructions. The arithmetic and move instructions (rules op2r, op1r, and mov) are completely standard. \nThe .rst arithmetic operation op rd,rs,rt performs op on the values in rs and rt, stor\u00ading the result \nin rd. The second arithmetic operation uses a constant operand v in addition to rs and rd. All constants \nare annotated with the color of the computation they belong to. Likewise, the mov instruction loads an \nannotated constant into a register. Memory Instructions. Transient faults are problematic only when they \nchange the results of computations and those results are observed by an external user. In our model, \nthe only way a re\u00adsult can be observed is for a program to write it to memory, where a memory-mapped \noutput device may read and process it. S -.sk S ' Q ' =((Rval(rd),Rval(rs)),Q) (stG-queue) (R,C,M,Q,stG \nrd,rs)-.0 (R++,C,M,Q ' ,\u00b7) ' Rval(rd)= nl Rval(rs)= nl (stB -mem) (R,C,M,((n,n ' ),(nl,n ' l)),stB rd,rs) \n(nl ,n ) -.0 l . (R++,C,M[nl . nl' ],(n,n ' ),\u00b7) find(Q,Rval(rs))=(Rval(rs),n) R ' = R++[rd . Gn] (ldG-queue) \n(R,C,M,Q,ldG rd,rs)-.0 (R ' ,C,M,Q,\u00b7) find(Q,Rval(rs))=() Rval(rs). Dom(M) R ' = R++[rd . GM(Rval(rs))] \n(ldG-mem) (R,C,M,Q,ldG rd,rs)-.0 (R ' ,C,M,Q,\u00b7) Rval(rs). Dom(M) R ' = R++[rd . BM(Rval(rs))] (ldB -mem) \n(R,C,M,Q,ldB rd,rs)-.0 (R ' ,C,M,Q,\u00b7) Figure 3. Selected operational rules for memory instructions. Without \nspecial hardware it appears impossible to guarantee that storage operations guard access to memory properly. \nNo matter what sophisticated software checking is performed just before a conventional store instruction, \nit will be undone if a fault strikes between the check and execution of the store instruction. This is \nthe conundrum of the Time-Of-Check-Time-Of-Use (TOCTOU) fault. To avoid TOCTOU faults, our machine possesses \na modi.ed store buffer (the queue Q), which is similar to the store buffer used in previous hardware \n[16] and hybrid [19] fault tolerant sys\u00adtems. In addition, there are two special storage instructions, \neach tagged with a color. The green store instruction stG rd,rs places the address-value pair (Rval(rd),Rval(rs)) \non the front of the queue (rule stG-queue). The blue store instruction stB rd,rs re\u00adtrieves the pair \n(nl,n l' ) on the back of the queue, checks that it equals (Rval(rd),Rval(rs)), and then stores it in \nmemory (rule stB -mem). If the pairs are different, the hardware signals a fault. Failure rules appear \nin Appendix A.1. Since green stores must al\u00adways come before blue stores, instruction scheduling is somewhat \nconstrained. As we will show later in Section 5, we have evaluated the performance both with and without \nthis scheduling constraint and show that its performance impact is negligible. As an example, consider \nthe following straight-line sequence: 1 mov r1,G5 2 mov r2, G 256 3 stG r2 , r1 4 mov r3,B5 5 mov r4, \nB 256 6 stB r4 , r3 These six instruction have the effect of storing 5 into memory address 256. Moreover, \na fault at any point in execution, to either blue or green values or addresses, will be caught by the \nhardware when the blue store (instruction 6) compares its operands to those in the queue. In addition, \nour instruction set gives a compiler the freedom to allocate registers however it chooses (e.g., reusing \nregisters 1 and 2 in instructions 4-6 instead of registers 3 and 4) and to change the instruction schedule \nin various ways (e.g., moving instruction 3 to a position between instructions 5 and 6). Interestingly, \nhowever, not all conventional optimizations are sound, and, of course, this is why type checking generated \ncode can be so helpful in detecting compiler errors. For example, common subexpression elimination might \nresult in the following code: 1 mov r1,G5 2 mov r2, G 256 3 stG r2, r1 4 stB r2 , r1 In this case, a \nfault in r1 after instruction 1, or a fault in r2 after instruction 2 will cause both instructions 3 \nand 4 to manipulate the same, but incorrect, address-value pair. The result would be to store an incorrect \nvalue at the correct location or a correct value at an incorrect location. Fortunately, the TALFT type \nsystem catches reliability errors like this one. As mentioned in Section 2.1, many intra-instruction \nfaults can be modeled by modifying the register .le before or after the instruc\u00adtion. However, this is \nnot the case for a fault that occurs during the execution of the stB -mem rule in between the comparisons \nand the store. The hardware designer must implement structures that detect or mask any faults that occur \nhere. If the hardware designer can\u00adnot meet the speci.cation given by the operational semantics, he acknowledges \nthere may be a vulnerability. The load instructions also come in pairs: ldB and ldG. The only difference \nin their semantics is that ldG checks for a pending store in the queue before loading its value from \nmemory, whereas ldB goes directly to memory, ignoring the queue. This wrinkle increases the freedom in \ninstruction scheduling by allowing the green computation to load a value it may have recently stored \nbefore the blue computation has necessarily committed the store. Rules ldG-queue, ldG-mem, and ldB -mem \nspecify these behaviors. Notice that there is no mechanism for verifying the address used in loads. Hence, \na fault can result in an invalid address. In practice such a load might induce a hardware exception such \nas a segmentation fault or might result in loading some arbitrary value. Failure rules that model both \npossibilities appear in Appendix A.1. Control-Flow Instructions. Any change in the control-.ow of a program \nmay cause a different sequence of values to be stored and observed by an external user. Consequently, \nthe hardware contains mechanisms to detect faults in addresses that serve as jump targets. Intuitively, \nthese mechanisms mirror the solution to faults in stored data in that execution of a control-.ow transfer \nis accomplished through two instructions. Our solution uses a combination of soft\u00adware and hardware control-.ow \nprotection that is similar to watch\u00addog processors [6], but that makes both versions of the control .ow \nexplicit as in software-only control .ow protection [12, 18]. To achieve an unconditional jump, one executes \na jmpG instruc\u00adtion .rst and a related jmpB instruction at some point in the future. A jmpG r1 moves \nthe destination address from r1 into the special destination register d (rule jmpG). Like the store queue, \nthe desti\u00adnation register stores a programmer intention, initiated by the green computation. Later, when \nthe blue computation attempts to commit the jump by executing a jmpB r2 instruction, the contents of \nr2 are compared to the contents of the destination register and if they are equal, control jumps to that \nlocation (rule jmpB ). If the addresses are different, the hardware detects a fault (see rule jmpB -fail). \nSim\u00adilar to the constraint for the store queue, forcing green control .ow instructions to be executed \nbefore the corresponding blue version constrains the instruction schedule. Section 5 will show that this \nscheduling constraint has only a minimal performance impact. S -.sk S ' R ' Rval(d)=0 = R++[d . R(rd)] \n(jmpG) (R,C,M,Q,jmpG rd)-.0 (R ' ,C,M,Q,\u00b7) Rval(d)=0 (jmpG-fail) (R,C,M,Q,jmpG rd)-.0 fault Rval(d)=0 \nRval(rd)= Rval(d) R ' = R[pcG . R(d)][pcB . R(rd)][d . G0] (jmpB ) (R,C,M,Q,jmpB rd)-.0 (R ' ,C,M,Q,\u00b7) \nRval(rd)= Rval(d) orRval(d)=0 (jmpB -fail) (R,C,M,Q,jmpB rd)-.0 fault Rval(d)=0 Rval(rz )=0 (bz-untaken) \n(R,C,M,Q,bzc rz ,rd)-.0 (R++,C,M,Q,\u00b7) Rval(d)=0 Rval(rz)=0 R ' = R++[d . R(rd)] (bzG-taken) (R,C,M,Q,bzG \nrz,rd)-.0 (R ' ,C,M,Q,\u00b7) Rval(d)=0 Rval(rz )=0 Rval(rd)= Rval(d) R ' = R[pcG . R(d)][pcB . R(rd)][d \n. G0] (bzB -taken) (R,C,M,Q,bzB rz,rd)-.0 (R ' ,C,M,Q,\u00b7) Figure 4. Selected operational rules for control \n.ow instructions. The following code illustrates a typical control-.ow transfer. 1 ldG r1, r2 3 ldB r3, \nr4 2 jmpG r1 4 jmpB r3 Initially, registers r2 and r4 should point to the same memory location, which \ncontains a code pointer to jump to. The example illustrates some of the .exibility in scheduling jump \ninstructions. Conditional jumps are more complex, but follow the same prin\u00adciples. The green conditional \nbzG rz, rd tests rz and if it is 0, moves the contents of rd into destination register d (rules bz-untaken \nand bzG-taken). No control-.ow transfer occurs until a blue conditional '' ''' bzB r , r tests the contents \nof its r register. If r is 0 then r must zd zzd equal the contents of d, and if so, the control .ow transfer \noccurs (rule bzB -taken). If rz ' is not 0, it is not good enough merely to fall through the contents \nof rz ' might be faulty. To avoid this pos\u00adsibility, the instruction examines the destination register. \nIf it is 0 (and hence a prior bzG instruction did not store an address), the fall-through occurs (rule \nbz-untaken). The rules for the associated failure cases appear in Appendix A.1. Our metatheory will show \nthat this mechanism suf.ces to detect faults either in the green com\u00adputation (registers rz and rd) or \nthe blue computation (registers rz ' and rd' ). StaticExpressions expkinds . ::= .int |.mem expcontexts \n. ::= \u00b7|.,x : . exps E ::= x |n |E opE |selEm En |emp|updEm En1 En2 substitutions S ::= \u00b7|S,E/x Types \nzaptags Z ::= \u00b7|c basic types b ::= int |T . void |bref reg types t ::= (c,b,E)|E ' =0 .(c,b,E) regfile \ntypes G ::= \u00b7|G,a . t result types RT ::= T|void Contexts heaptyping . ::= \u00b7|.,n : b static context T \n::= .;G;(Ed,Es);Em Figure 5. TALFT type syntax.  3. Typing The primary goal of the TALFT type system \nis to ensure that well\u00adtyped programs exhibit fail-safe behavior in the presence of tran\u00adsient faults. \nIn other words, well-typed programs must guarantee that a memory-mapped output device can never read \na corrupt value and make it visible to a user. We call this property fault tolerance. In the following \nsections, we explain the intuitions and princi\u00adples behind the various elements of the type system. Throughout \nthe discussion, the reader will notice that our typing rules are not syntax-directed. Of course, as with \nother sorts of typed assembly language or proof-carrying code, this fact presents no particular dif\u00ad.culty \nin practice it is easy for a compiler to generate suf.cient typing hints to make type reconstruction \ntrivial. For the reader s reference, the objects used in the type system are presented in Fig\u00adure 5. \n3.1 Static Expressions Our type system is actually a combination of two theories, one being a relatively \nsimple type theory for assembly, inspired by previous work on TAL [8], and the second being a Hoare Logic, \ndesigned to enforce the more precise invariants required for strong fault tolerance. The latter component \nrequires we de.ne a language of static expressions for reasoning about values and storage. For the purposes \nof this paper, the static expressions are drawn from the standard theory of arithmetic and arrays used \nin many classical Hoare Logics (c.f., Necula s thesis [10]). These static ex\u00adpressions are classi.ed \nas either integers (kind .int) or memo\u00adries (kind .mem). The integer expressions include variables, con\u00adstants, \nsimple arithmetic operations, and values from a memory (selEm En is the integer located at address En \nin Em). The mem\u00adory expressions include variables, the empty memory (emp), and memory updates (updEm \nEn1 En2 is a memory Em updated so that address En1 stores value En2 ). The context . is a mapping from \nvariables to kinds, and the judgment . f E : . classi.es expression E as having kind .. The judgment \n. f S :. ' holds when the substitution S maps variables in Dom(. ' )to values well-formed in . with types \nin Rng(. ' ). The judgment . f E1 = E2 is valid when E1 and E2 are equal objects in the standard model. \nThe function [ E] supplies the denotation of the closed static expression E as either an integer or a \nmemory, depending on its kind. The de.nitions for [ E] and . f E1 = E2 are shown in Appendix A.2, and \nthe remaining judgments are de.ned in the companion technical report [15]. . f n : b (int-t)(base-t) \n. f n : int . f n : .(n) .;. fZ v : t . f n : b . f E = n (val-t) .;. fZ cn : (c,b,E) n =0 .;. fZ cn \n: (c,b,E) . f E ' =0 (cond-t) .;. fZ cn : E ' =0 .(c,b,E) . f E ' =0 (cond-t-n0) .;. fZ c 0: E ' =0 \n.(c,b,E) . f E : .int (val-zap-t) .;. fc cn : (c,b,E) . f E : .int (val-zap-cond) .;. fc cn : E ' =0 \n.(c,b,E) Figure 6. Value Typing. 3.2 Value Typing Since faults strike values, corrupting their bit patterns \nin arbitrary ways, the subtleties of value typing are a key concern. Informally, the type system maintains \nthree key pieces of information about every value: 1. A color (green or blue). The type system is organized \nto ensure that when a value is known to be green, its contents can only depend on the contents of other \ngreen values not blue ones, and likewise, blue can only depend upon blue. Hence, while a fault in a green \nvalue can eventually corrupt arbitrarily many other green values, it cannot corrupt any blue values, \nand vice versa. 2. A basic type . When no fault has occurred in the value s color, the value s basic \ntype describes its shape. Values with type int may have any bit pattern. Values with type T . void are \npointers to code (continuations). One must satisfy the precondition Tbefore jumping to them. Values with \ntype bref are pointers to values with type b. 3. A static expression. When there has been no fault in \na value s color, the value exactly equals the static expression. Static ex\u00adpressions are used to guarantee \nthat in the absence of faults, the green and blue computations produce equal values, and hence, dynamic \nfault detection checks always succeed.  To summarize, every value is typed using a triple (c,b,E), where \nc is a color, b is a basic type, and E is a static expression. The presence of the static expression \nmakes this type a kind of singleton type. Value Typing Judgment. The value typing judgment has the form \n.;. fZ v : t, where . maps heap addresses to basic types, and .contains the free expression variables. \nIn the rule val-t, a colored value cn is given the type (c,b,E)when the static expression E is equal \nto n, and . f n : b. The judgment . f n : b allows n to be given either the basic type int or the type \nof the address n in memory. The two rules cond-t and cond-t-n0 are used to type the con\u00additional type \n(E ' =0 .(G,T . void ,E r' )). When the static expression E ' is equal to zero, values of this type also \nhave type (G,T . void ,E r' ). When E ' is not equal to zero, values with this type must be 0. The .nal \ntwo rules for .;. fZ v : t make use of the zap tag Z, which is either empty or a color c. If the zap \ntag is a color c, then there may have been a fault affecting data of that color. Data colored the same \nas the zap tag can be given any type, as it may have been arbitrarily corrupted. The static expression \nused in this type may not contain any free expression variables. Value Subtyping. There is also a subtyping \nrelation . f t = t ' that allows all types (c,b,E1) to be subtypes of (c, int ,E2) when . f E1 = E2. \nThis relation is extended to register .le subtyping . f G1 = G2 , by requiring that the type of each \ngeneral\u00adpurpose register in G2 be a supertype of the corresponding register in G1. Note that here is \nno required relationship between the special registers d, pcG, and pcB . The rules for these judgments \nappear in the companion technical report [15].  3.3 Instruction Typing While many of the instruction \ntyping rules are quite complex, the essential principles guiding their construction may be summarized \nas follows. 1. In the absence of faults, standard type theoretic principles should be valid. In order \nto guarantee basic safety properties, the type system checks standard properties in much the same manner \nas previous typed assembly languages [8]. For exam\u00adple, jump targets must have code types, while loads \nand stores must operate over values with reference types. 2. Green values only depend on other green \nvalues, and blue val\u00adues only depend on blue values. When this invariant is main\u00adtained, a fault in a \nblue value can never corrupt a green value and vice versa. 3. Both green and blue computations have \nequal say in any dan\u00adgerous actions. Dangerous actions include storing values to memory-mapped output \ndevices and executing control-.ow op\u00aderations. When both blue and green computations are involved, a \nfault in just one color is insuf.cient to deceive the hardware fault detection mechanisms. 4. In the \nabsence of faults, green and blue computations must compute identical values. To be more precise, green \nand blue computations must store identical values to identical storage locations and must issue orders \nto transfer control to identical addresses. If not, the hardware will claim to detect faults when there \nhave been none, or alternatively, might exhibit incorrect behaviors when there is a fault.  The .rst \nthree principles are relatively straightforward to en\u00adforce. The fourth principle leads to the most technical \nchallenges as it requires we check equality constraints between values. Moreover, since construction \nof these values depends on storage, the type sys\u00adtem must maintain a relatively accurate static representation \nof stor\u00adage. We accomplish this latter challenge using techniques drawn from Hoare Logics. The former \nchallenge (testing values for equal\u00adity) is achieved through the use of the singleton types described \nearlier. The Instruction Typing Judgment. The judgment for typing in\u00adstructions has the form .;T f ir \n. RT. Unlike the context ., which only contains invariant heap typing assumptions, Tcontains .ne-grained \ncontext-sensitive information about the current state of memory and the register .le. More speci.cally, \nT consists of the following subcontexts: (1) ., which describes the free expres\u00ad .;T f ir . RT (\u00b7-t) \n .;(.;G;(Ed,Es);Em)f \u00b7 . (.;G;(Ed,Es);Em) G(rs)= (c, int ,E s' ) G(rt)= (c, int ,E t' ) (op2r-t) .;(.;G;(Ed,Es);Em)f \nop rd,rs,rt . (.;G++[rd .(c, int ,E s ' opE t' )];(Ed,Es);Em) G(rs)= (c, int ,E s' ) (op1r-t) .;(.;G;(Ed,Es);Em)f \nop rd,rs,cn . (.;G++[rd .(c, int ,E s ' op n)];(Ed,Es);Em) .;. f v : t (mov-t) .;(.;G;(Ed,Es);Em)f mov \nrd,v . (.;G++[rd . t];(Ed,Es);Em) G(rs)= (G,bref ,E s' ) E = sel (updEm (Ed,Es))Es ' (ldG-t) .;(.;G;(Ed,Es);Em)f \nldG rd rs . (.;G++[rd .(G,b,E)];(Ed,Es);Em) G(rs)= (B,bref ,E s' ) E = selEm Es ' (ldB -t) .;(.;G;(Ed,Es);Em)f \nldB rd rs . (.;G++[rd .(B,b,E)];(Ed,Es);Em) G(rd)= (G,bref ,E d' ) G(rs)= (G,b,E s' ) (stG-t) .;(.;G;(Ed,Es);Em)f \nstG rd rs . (.;G++;(Ed' ,E s' ),(Ed,Es);Em) '' '' G(rd)= (B,bref ,E d ) G(rs)= (B,b,E s ) ' '' ''' . \nf E = E . f E = E dd ss (stB -t) '' '' .;(.;G;(Ed,Es),(Ed,E s);Em)f stB rd rs . (.;G++;(Ed,Es);updEm \nEd Es) G(d)= (G,int ,0) G(rz)= (G,int ,Ez) '' '' G ' G(rd)= (G,T . void ,E d) T =(. ' ;G ' ;(Ed,Es);Em)(d)= \n(G,int ,0) (bzG-t) .;(.;G;(Ed,Es);Em)f bzG rz rd . (.;G++[d . Ez =0 .(G,T . void ,E d' )];(Ed,Es);Em) \n' ' G(rd)= (G,T . void ,Erd. ) T =(. ' ;G ' ;(E ,E);E ' ) dsm G ' G(d)= (G,int ,0) (d)= (G,int ,0) \n(jmpG-t) .;(.;G;(Ed,Es);Em)f jmpG rd . (.;G++[d .(G,T . void ,Erd. )];(Ed,Es);Em) G(rz)= (B,int ,Ez \n) '' ' G(rd)= (B,(. ' ;G ' ;(Ed,Es);Em). void ,Er) ' '' ' G(d)= Ez =0 .(G,(. ' ;G ' ;(E ,Es);Em). void \n,E r) ''' ' d'' G(d)= (G,(. ' ;G ' ;(Ed,Es);Em). void ,E r). f Ez = E z '' ' ' G(rd)= (B,(. ' ;G ' ;(Ed,Es);Em). \nvoid ,Er ) . f Er = Er ' . f Er = Er .S.. f S :. ' .S.. f S :. ' S(G ' )(d)= (G,int ,0) S(G ' )(d)= (G,int \n,0) S(G ' )(pcG)= (G,int ,E r' ) ' S(G ' )(pcG)= (G,int ,E r)S(G ' )(pcB )= (B,int ,Er) S(G ' )(pcB \n)= (B,int ,Er) . f G = S(G ' ) . f G = S(G ' ) ' . f (Ed,Es)= S((E ' ,E)) ds'' ' . f (Ed,Es)= S((Ed,Es)) \n. f Em = S(Em) ' . f Em = S(Em) (bzB -t) (jmpB -t) .;(.;G;(Ed,Es);Em)f bzB rz rd . .;(.;G;(Ed,Es);Em)f \njmpB rd . void (.;G++;(Ed,Es);Em) Figure 7. Instruction Typing. sion variables appearing in the other \ncontext-sensitive objects, (2) G, which describes the mapping of register names to types for reg\u00adister \nvalues, (3) (Ed,Es), which describes the values in the queue, and (4) Em, which describes memory, as \none does in Hoare Logic. The result of checking an instruction is a result type RT.A result type may \neither be void , indicating control does not proceed past the instruction (it is a jump), or a postcondition \nT ' , which describes the state of memory and the register .le after execution of the instruction. The \ntyping rules are de.ned using several notational abbrevi\u00adations. The notation G++ adds one to the static \nexpression asso\u00adciated with each program counter register in G. The expression upd Em (Ed,Es)is (upd \n(...(upd Em Edk Esk )...)Ed1 Es1 ) when (Ed,Es)=((Ed1 ,Es1 ),..., (Edk ,Esk )). Figure 7 presents the \ntyping rules for instructions, and the following paragraphs ex\u00adplain the main points of interest. Typing \nBasic Instructions. Basic arithmetic operations are not dangerous to execute, so the de.nitions of their \ntyping rules are driven by principles 1 and 2, mentioned earlier. Consider, for exam\u00adple, rule op2r-t \nfor an arithmetic operation op. This rule requires that the operand registers contain integers with the \nsame color c in accordance with principal 2 (green depends on green, blue de\u00adpends on blue). The result \nregister rd has a type colored c as well. In accordance with principle 1, the result has integer type. \nThe rule also states that the static expression describing the result register is Es ' opE t ' and that \nthe state of the queue and memory are unchanged by evaluation of the instruction. Typing Memory Instructions. \nStore operations are dangerous they make computed values observable by the outside world so we must \nbe particularly careful in the formulation of their typing rules. In accordance with principle 1, both \ngreen and blue store instructions (rules stG-t and stB -t) require that the address register has the \nbasic type bref and the value register has the corresponding basic type b. Intuitively, the store queue \nis a green object, and in accordance with principle 2, the green store instruction may push an address-value \npair onto the front the queue as long as both values are green. In accordance with principle 4, the rule \nfor the blue store checks that the address-value pair to be stored is exactly equal to the address-value \npair at the end of the queue. Since the arguments to the blue store have a blue type and the queue always \ncontains green objects, both blue and green computations contribute to the actual storage operation (in \naccordance with principle 3). The load operations are somewhat simpler than the store in\u00adstructions since \nthey are not dangerous in our model. However, like the store instructions, the operands of blue loads \nmust be blue and the operands of green loads must be green. Once again, in ac\u00adcordance with principle \n2, the result of a blue load is value with a blue type and likewise for a green load. Typing Control-Flow \nInstructions. While the typing rules for control-.ow instructions have many premises, they continue to \nfollow the same four principles as the other instructions. Much of the complexity is inherently due to \nprinciple 1, which mandates checking all the usual constraints associated with jumps in any typed assembly \nlanguage. The simplest rule involves the green unconditional jump. This instruction is just a move from \nregister rd to the special destination register d. The type of register d is updated to the type of rd \n(obeying both principles 1 and 2). The rule contains constraints that dmust be equal to 0in both Gand \nG ' since the hardware resets the destination register to 0after a jump. The blue unconditional jump \nis a true jump. According to prin\u00adciple 1, it checks the standard typing invariants needed to ensure \nsafety in any typed assembly language, including (1) that the jump target has code type (see the .rst \ntwo premises), and (2) that the current state, including register .le, memory, and queue, matches the \nexpected state at the jump target, modulo some substitution S of static expressions for universally quanti.ed \nvariables .from the code type (see the .nal seven premises). The typing of the conditional branches is \nquite similar to that of unconditional jumps. One difference is that the bzG instruction is now a conditional \nmove as opposed to an unconditional move. Hence, to represent the result of the move (unknown at compile \ntime) the conditional type (Ez ' =0 .(G,T . void ,E r' ))is used. In addition, since the conditional \nbranch may fall through, the result of typing the bzG instruction is a proper postcondition as opposed \nto void , like jmpG.  3.4 Machine State Typing In order to prove various properties of the type system, \nwe need to specify the invariants of machine states that are preserved during execution. The judgments \nfor typing a machine state S are shown in Figure 8 and explained below. Register File Typing. The judgment \n. fZ R :G states that the register .le Rhas the register .le type Gunder heap typing .and a zap tag Z. \nThe contents of each register must have the type given to that register by G. Each program counter must \nhave the appropriate color, and the program counters must compute equal values. (In the case where one \nprogram counter is corrupted, the zap tag Z in the .rst premise allows its actual value to differ from \nthe expected computed value.) Code Typing. The judgment . f C states that code memory C is well-formed \nwith respect to heap typing .. The address 0 is not a valid code address. Each address must have a code \ntype, and the code type must contain the precondition for the instruction at that address. If the instruction \ntyping results in a postcondition T ' (meaning that control may fall through to the next instruction) \nthen the subsequent instruction must be well typed using T ' as its precondition. Memory Typing. The \njudgment . f M : Em states that given heap typing . the value memory M is well-formed and can be described \nby the static expression Em. The static expression Em must have kind .mem, and M must be the denotation \nof Em. Each location in the domain of M must have a type bref and the contents of that location must \nhave type b. Queue Typing. The judgment . fZ Q :(Ed,Es)means that queue Q can be described by the sequence \nof static expressions (Ed,Es)given heap typing . and zap tag Z. When the queue is empty, it is described \nby the empty sequence. When the zap tag Z is not G, the .rst pair (n1 ,n2 )must consist of an address \nn1 with type b ref and a value n2 with type b. This pair is described by the static expression pair (Ed,Es)when \nEd evaluates to n1 and Es evaluates to n2 . The remainder of the queue must be described by the remainder \nof the static expression sequence. All values in the queue are considered to be green, so when the zap \ntag is G, these values may have been arbitrarily corrupted. Accordingly in this case, the only requirements \nare that each static expression must have kind .int and the length of the queue must be the same as the \nlength of the static expression sequence. Machine State Typing. The judgment fZ Sstates that a machine \nstate Sis well-typed under zap tag Z. This judgment holds when S is a .ve-tuple (R,C,M,Q,ir), and these \nelements are each well\u00adtyped and consistent with each other. Note that Sis not well-typed when it is \nthe fault state fault . . fZ R :G . f C fZ \u00b7f G(pcG)=(G,int,EG) \u00b7f G(pcB )=(B,int,EB ) \u00b7f EG = EB .a. \n.;\u00b7 R(a):G(a) (R-t) . fZ R :G 0 . Dom(C) .n . Dom(C). .(n)=T . void . .;T f C(n). RT T ' T ' .(RT = \nimplies.(n +1)= . void) (C-t) . f C . f M : Em \u00b7f Em : .mem [ Em] = M .. . Dom(M). . f . : bref . . f \nM(.): b (M-t) . f M : Em . fZ Q:(Ed,Es) (Q-emp-t) . fZ ():() Z = G . f n1 : bref . f n2 : b \u00b7f Ed = n1 \n\u00b7f Es = n2 . fZ '' '' (n1,n ):(E ,E)2 ds(Q-t) '' ' . fZ ' (n1 ,n2 ),(n1 ,n2 ):(Ed,Es),(Ed,Es) \u00b7f Ed : \n.int \u00b7f Es : .int . fG ' '' ' (n1 ,n ):(E ,E)2 ds(Q-zap-t) '' ' ' . fG (n1 ,n2 ),(n1 ,n2 ):(Ed,Es),(Ed,Es) \nfZ (R,C,M,Q,ir) Dom(.)= Dom(C).Dom(M) Z = G =. Dom(Q). Dom(M) . f C .c = Z.ir = \u00b7 =. C(Rval(pcc))= ir \n.c = Z. .(Rval(pcc))=T . void T =(.;G;(Ed,Es);Em) .S.\u00b7f S :. . f M : S(Em) . fZ Q: S(Ed,Es) . fZ R : \nS(G) (S-t) fZ (R,C,M,Q,ir) Figure 8. Machine State Typing.  4. Formal Results In order to prove properties \nof our type system, we extend our single-step transition S1 -.sk S2 from Section 2 to a sequence n of \nn transitions containing exactly k faults S1 --.ks S2 , where n is greater than or equal to zero, and \nk is still either 0 or 1. 4.1 Type Safety Progress states that well-typed states can take a step. In \nparticular, a machine state that is well-typed under the empty zap tag can take a non-faulty step to \nanother ordinary, non-faulty machine state. A machine state that is well-typed under a zap tag of color \nc can take a step, but the result of that step may either be another ordinary machine state or the fault \nstate. Theorem 1 (Progress) 1. If f S then S -.s 0 S ' and S ' = fault . fc 2. If S then S -.s 0 S. According \nto Preservation, if a machine state is well-typed under a zap tag Z, and it takes a non-faulty step to \nanother machine state, then that resulting state will also be well-typed under Z. Additionally, if a \nstate is well-typed under the empty zap tag, and it takes a faulty step, then there is some color c such \nthat the resulting state is well-typed under c. Theorem 2 (Preservation) 1. If fZ Sand S -.0 s S ' and \nS ' = fault then fZ S ' . 2. If f S and S -.1 s S ' then .c. fc S ' .  Progress and Preservation de.ne \nthe usual notion of type safety. In addition, part one of Progress, together with part one of Preser\u00advation \nentail the following important corollary: The hardware never claims to have detected a fault when no \nfault has occurred during execution of a well-typed program. Corollary 3 (No False Positives) n If f \nS then .n. S--. s 0S ' and f S ' . 4.2 Fault Tolerance A program is fault tolerant when all the faulty \nexecutions of that program simulate fault-free executions of the program. More pre\u00adcisely, the sequence \nof outputs from the faulty executions are re\u00adquired either to be identical to the fault-free execution \nor, in the case the hardware detects the fault, a pre.x of the fault-free execu\u00adtion. In order to reason \nabout pairs of faulty and fault-free executions, we de.ne similarity relations between values, register \n.les, queues and machine states. Each of these relations is de.ned relative to the zap tag Z. Intuitively, \nif Z is empty, the related objects must be identical. If Z is a color c, the objects must be identical \nmodulo val\u00adues colored c. In the latter case, values colored c may be corrupted, and there is no hope \nthey satisfy any particular relation. The formal de.nitions of these relations are shown in Figure 9. \nUsing the similarity relations, we can state and prove the fault tolerance theorem for well-typed programs \nprecisely. Assume that machine state S is well-typed under the empty zap tag, and non\u00adfaulty execution \nof S for n steps results in a state S ' and outputs a sequence of value-address pairs s. If somewhere \nduring that execution a single fault is encountered, the faulty execution will either run for n +1 steps \nor terminate in the fault state during that time. If the faulty execution takes n +1 steps and reaches \nthe non-faulty state S ' f , then S ' simulates S ' f and the sequence of output pairs is identical the \noriginal execution. Alternatively, if the faulty execution reaches the fault state then the output pairs \nwill be a pre.x of the non-faulty output pairs. v1 simZ v2 (sim-val)(sim-val-zap) C n simZ Cn CnsimC \nCn ' R simZ R ' .a.R(a)simZ R ' (a) (sim-R) R simZ R ' QsimZ Q ' (sim-Q-empty) \u00b7 simZ \u00b7 Gn1 simZ Gn ' \n1 Gn2 simZ Gn ' 2 QsimZ Q ' (sim-Q) ((n1 ,n2 ),Q) simZ ((n1' ,n 2 ' ),Q ' ) S1 simZ S2 RsimZ R ' QsimZ \nQ ' (sim-S) (R,C,M,Q,ir)simZ (R ' ,C,M,Q ' ,ir) Figure 9. Similarity of Machine States. Theorem 4 (Fault \nTolerance) s . ns (n+1) If f Sand S-. 0S ' then either S--. 1 Sf ' m or .m = (n+1) . S--. s 1 fault , \nand s (n+1) 1. For all derivations S--. 1 S ' f where S ' f = fault . ' S ' s = s and .c. S ' simcf . \nm 2. For all derivations S--. 1 s . fault where m = (n+1). s ' is a pre.x of s.  5. Performance To better \nunderstand how TALFT can be applied to real world sit\u00aduations, we simulated the TALFT hardware in the \nframework of a current computer architecture, the Intel Itanium 2 ISA. The in\u00adstruction set of the Itanium \n2 contains many more types of instruc\u00adtions than those speci.ed in TALFT . While not an exact represen\u00adtation \nof the performance of TALFT, simulating the performance of TALFT applied to this architecture will give \nguidance as to the feasibility of this system in a real architecture. To evaluate the performance impact \nof our techniques, a ver\u00adsion of the VELOCITY compiler [23] was modi.ed to add the re\u00adliability techniques \nof TALFT and was used to compile the SPEC CINT2000 and MediaBench benchmark suites. These executions \nwere compared against binaries generated by the original VELOC-ITY compiler, which have no fault detection. \nThe reliability trans\u00adformation was compiled into the low level code immediately before register allocation \nand scheduling. To simulate the new hardware structures of TALFT , extra instructions were inserted to \nemulate the timing and dependences of the hardware structure accesses. Performance metrics were obtained \nby running the resulting binaries with reference inputs on an HP workstation zx6000 with 2 900Mhz Intel \nItanium 2 processors running Redhat Advanced Workstation 2.1 with 4Gb of memory. The perfmon utility \nwas used to measure the CPU time. Figure 10 presents the execution time of the fault-tolerant code relative \nto baseline binaries with no fault detection. Na\u00a8ively, one might expect the fault-tolerant code to run \ntwice as slowly as the fault intolerant code since the number of instructions is essentially doubled. \nHowever, we .nd that smart instruction scheduling and ef.cient allocation of resources reduces the execution \ntime to only 34% more than the fault-intolerant baseline average. These simula\u00adtions are in line with \npreviously published software-only reliability performance experiments [18] that show the degradation \ndue to re\u00addundant code to be less than double. As alluded to in Section 2.2, Figure 10 compares the perfor\u00admance \ndegradation both with and without the scheduling constraint that green memory and control .ow instructions \nmust be executed before the corresponding blue versions. In order to perform the sec\u00adond set of experiments, \nour compiler was modi.ed to produce code that had more .exibility in the scheduling of the green and \nblue versions. We then simulated a more aggressive hardware imple\u00admentation that could correlate the \noriginal and redundant memory operations regardless of the executed order. As expected, this ver\u00adsion \nhas better performance (in most cases) than the unconstrained code. Comparing both to the unprotected \ncode, the version with\u00adout the ordering constraint increases execution time by 30% while the version \nwith the ordering increases execution time by 34%. Al\u00adthough the colored ordering restriction of TALFT \nmay seem costly, removing this restriction provides only a small improvement.  6. Related Work Fault \ntolerance based on software replication is a well-populated .eld with decades of history. TALFT differs \nfrom previous ap\u00adproaches in that it provides a type-theoretic framework for obtain\u00ading strong guarantees \nabout the reliability of machine code. Most closely related to TALFT is our previous work on .zap,a highly \nabstract type-theoretic model for studying the basic prin\u00adciples of fault tolerance in the lambda calculus \n[26]. There are two important distinctions between TALFT and .zap. First, .zap , working at the level \nof the lambda calculus, is very far removed from real machine code. For instance, it lacks a program \ncounter, a register .le, memory, and load or store instructions. Memory references in particular constitute \na key challenge in the current technical work. Second, the properties of the .zap type system are relatively \nweak compared with the properties of the current type system. The end-to-end fault tolerance property \nproven for .zap depends not only on the type system but also the nature of the trans\u00adlation from the \nordinary simply-typed lambda calculus. In contrast, the type system of TALFT is much stronger, capable \nof ensuring a strong fault tolerance property independently of the process that compiles the code. Also \nclosely related to TALFT is the original TAL system, which .rst applied strong type checking to machine \ncode to guaran\u00adtee its safety [8]. TAL operates under the assumption of nonfaulty hardware and therefore \nignores the major issues of reliability on which this paper has focused. There have been various implementations \nof software-only, hardware-only, and hybrid techniques for transient fault mitiga\u00adtion. Hardware techniques \nhave a long history of using very lo\u00adcalized bit-level techniques like error correcting codes or parity \nbits additions. These techniques are ef.cient for storage structures like memory, but are costly or impossible \nto apply to other pro\u00adcessor elements like pipeline latches or arithmetic units. Higher level techniques \nare used when protection is necessary for larger segments of the processor. These techniques include \nthe duplica\u00adtion of coarse-grained structures such as functional units, processor cores [5, 22, 27], \nor hardware contexts [9, 16, 25]. To provide protection when the hardware costs of these ap\u00adproaches \nare prohibitive, software-only approaches have been pro\u00adposed as alternatives [12, 13, 17, 18, 20, 24]. \nWhile software-only systems are cheaper to deploy and can be con.gured after deploy\u00adment, they cannot \nachieve the same performance or reliability as TAL-FT TAL-FT without ordering  Figure 10. Performance \nNormalized to Unprotected Version. hardware-based techniques, since they have to execute additional instructions \nand are unable to examine microarchitectural state. Despite these limitations, software-only techniques \nhave shown promise, in the sense that they can signi.cantly improve reliabil\u00adity with reasonable performance \noverhead [12, 13, 18]. TALFT attempts to exploit the bene.ts of both sorts of systems by using a hybrid \napproach to fault tolerance. There have been pre\u00advious hybrid approaches to transient fault tolerance, \nsome focusing solely on control-.ow protection [14] and recently others looking at full processor protection \n[19]. This work differs from those pre\u00advious approaches because regardless of the type of implementation, \nsoftware, hardware, or hybrid, none of those previous approaches have given rigorous formal proofs of \nthe correctness of their sys\u00adtems.  7. Conclusions In conclusion, transient faults are already a signi.cant \ncause for concern at major semiconductor manufacturers and threaten to be more so in the coming years \nand decades. This paper takes one step forward for the science of fault tolerance by presenting a principled \nand practical hybrid software-hardware scheme for detecting tran\u00adsient faults. More speci.cally, we identify \nfour general principles for verifying correctness of fault tolerant systems and capture these in an assembly \nlanguage type system. From a theoretical perspec\u00adtive, the type system acts as a sound proof technique \nfor verifying reliability properties of programs. From a practical perspective, it can be used as a debugging \naid within a compiler, strictly dominat\u00ading any conventional testing technique. Our two main formal results \nshow that a single fault affecting observable behavior in a well\u00adtype program will always be detected, \nand that the system will not claim to have detected a fault when none has occurred. Despite the fact \nthat well-typed programs essentially duplicate all computation, we provide simulation results showing \na performance overhead of 1.34x.  Acknowledgments This research is funded in part by NSF awards CNS-0627650, \nCNS-0615250, and CCF 0633268. Any opinions, .ndings, and conclusions or recommendations expressed in \nthis material are those of the author(s) and do not necessarily re.ect the views of the NSF.  References \n[1] R. C. Baumann. Soft errors in advanced semiconductor devices-part I: the three radiation sources. \nIEEE Transactions on Device and Materials Reliability, 1(1):17 22, March 2001. [2] R. C. Baumann. Soft \nerrors in commercial semiconductor technology: Overview and scaling trends. In IEEE 2002 Reliability \nPhysics Tu\u00adtorial Notes, Reliability Fundamentals, pages 121 01.1 121 01.14, April 2002. [3] S. Borkar. \nDesigning reliable systems from unreliable components: the challenges of transistor variability and degradation. \nIn IEEE Micro, volume 25, pages 10 16, December 2005. [4] M. Gomaa, C. Scarbrough, T. N. Vijaykumar, \nand I. Pomeranz. Transient-fault recovery for chip multiprocessors. In Proceedings of the 30th annual \ninternational symposium on Computer architecture, pages 98 109. ACM Press, 2003. [5] R. W. Horst, R. \nL. Harris, and R. L. Jardine. Multiple instruction issue in the NonStop Cyclone processor. In Proceedings \nof the 17th International Symposium on Computer Architecture, pages 216 226, May 1990. [6] A. Mahmood \nand E. J. McCluskey. Concurrent error detection using watchdog processors-a survey. IEEE Transactions \non Computers, 37(2):160 174, 1988. [7] S. E. Michalak, K. W. Harris, N. W. Hengartner, B. E. Takala, \nand S. A. Wender. Predicting the number of fatal soft errors in Los Alamos National Labratory s ASC Q \ncomputer. IEEE Transactions on Device and Materials Reliability, 5(3):329 335, September 2005. [8] G. \nMorrisett, D. Walker, K. Crary, and N. Glew. From System F to Typed Assembly Language. ACM Transactions \non Programming Languages and Systems, 3(21):528 569, May 1999. [9] S. S. Mukherjee, M. Kontz, and S. \nK. Reinhardt. Detailed design and evaluation of redundant multithreading alternatives. In Proceedings \nof the 29th Annual International Symposium on Computer Architecture, pages 99 110. IEEE Computer Society, \n2002. [10] G. C. Necula. Compiling with Proofs. PhD thesis, Carnegie Mellon University, 1998. [11] T. \nJ. O Gorman, J. M. Ross, A. H. Taber, J. F. Ziegler, H. P. Muhlfeld, I. C. J. Montrose, H. W. Curtis, \nand J. L. Walsh. Field testing for cosmic ray soft errors in semiconductor memories. In IBM Journal of \nResearch and Development, pages 41 49, January 1996. [12] N. Oh, P. P. Shirvani, and E. J. McCluskey. \nControl-.ow checking by software signatures. In IEEE Transactions on Reliability, volume 51, pages 111 \n122, March 2002. [13] N. Oh, P. P. Shirvani, and E. J. McCluskey. Error detection by duplicated instructions \nin super-scalar processors. In IEEE Transactions on Reliability, volume 51, pages 63 75, March 2002. \n[14] J. Ohlsson and M. Rimen. Implicit signature checking. In International Conference on Fault-Tolerant \nComputing, June 1995. [15] F. Perry, L. Mackey, G. A. Reis, J. Ligatti, D. I. August, and D. Walker. \nFault-tolerant typed assembly language. Technical Report TR-776\u00ad07, Princeton University, 2007. [16] \nS. K. Reinhardt and S. S. Mukherjee. Transient fault detection via simultaneous multithreading. In Proceedings \nof the 27th Annual International Symposium on Computer Architecture, pages 25 36. ACM Press, 2000. [17] \nG. A. Reis, J. Chang, and D. I. August. Automatic instruction\u00adlevel software-only recovery methods. In \nIEEE Micro Top Picks, volume 27, January 2007. [18] G. A. Reis, J. Chang, N. Vachharajani, R. Rangan, \nand D. I. August. SWIFT: Software implemented fault tolerance. In Proceedings of the 3rd International \nSymposium on Code Generation and Optimization, March 2005. [19] G. A. Reis, J. Chang, N. Vachharajani, \nR. Rangan, D. I. August, and S. S. Mukherjee. Design and evaluation of hybrid fault-detection systems. \nIn Proceedings of the 32th Annual International Symposium on Computer Architecture, pages 148 159, June \n2005. [20] P. P. Shirvani, N. Saxena, and E. J. McCluskey. Software\u00adimplemented EDAC protection against \nSEUs. In IEEE Transactions on Reliability, volume 49, pages 273 284, 2000. [21] P. Shivakumar, M. Kistler, \nS. W. Keckler, D. Burger, and L. Alvisi. Modeling the effect of technology trends on the soft error rate \nof combinational logic. In Proceedings of the 2002 International Conference on Dependable Systems and \nNetworks, pages 389 399, June 2002. [22] T. J. Slegel, R. M. Averill III, M. A. Check, B. C. Giamei, \nB. W. Krumm, C. A. Krygowski, W. H. Li, J. S. Liptay, J. D. MacDougall, T. J. McPherson, J. A. Navarro, \nE. M. Schwarz, K. Shum, and C. F. Webb. IBM s S/390 G5 Microprocessor design. In IEEE Micro, volume 19, \npages 12 23, March 1999. [23] S. Triantafyllis, M. J. Bridges, E. Raman, G. Ottoni, and D. I. August. \nA framework for unrestricted whole-program optimization. In ACM SIGPLAN 2006 Conference on Programming \nLanguage Design and Implementation, pages 61 71, June 2006. [24] R. Venkatasubramanian, J. P. Hayes, \nand B. T. Murray. Low-cost on-line fault detection using control .ow assertions. In Proceedings of the \n9th IEEE International On-Line Testing Symposium, pages 137 143, July 2003. [25] T. N. Vijaykumar, I. \nPomeranz, and K. Cheng. Transient-fault recovery using simultaneous multithreading. In Proceedings of \nthe 29th Annual International Symposium on Computer Architecture, pages 87 98. IEEE Computer Society, \n2002. [26] D. Walker, L. Mackey, J. Ligatti, G. Reis, and D. I. August. Static typing for a faulty lambda \ncalculus. In ACM International Conference on Functional Programming, Portland, Oregon, Sept. 2006. [27] \nY. Yeh. Triple-triple redundant 777 primary .ight computer. In Proceedings of the 1996 IEEE Aerospace \nApplications Conference, volume 1, pages 293 307, February 1996. [28] J. F. Ziegler and H. Puchner. SER \n-History, Trends, and Challenges: A Guide for Designing with Memory ICs. 2004. A. Appendix A.1 Failure \nRules Operational rules omitted from Figures 2, 3, and 4. find(Q,Rval(rs))=() Rval(rs)./Dom(M) (ldG-fail) \n(R,C,M,Q,ldG rd,rs)-.0 fault find(Q,Rval(rs))=() Rval(rs)./Dom(M) R ' = R++[rd . Gn] (ldG-rand) (R,C,M,Q,ldG \nrd,rs)-.0 (R ' ,C,M,Q,\u00b7) Rval(rs)./Dom(M) R ' = R++[rd . Bn] (ldB -rand) (R,C,M,Q,ldB rd,rs)-.0 (R ' \n,C,M,Q,\u00b7) (stB -queue-fail) (R,C,M,\u00b7,stB rd,rs)-.0 fault Q=((n,n ' ),(nl,nl' )) ' Rval(rd)= nl orRval(rs)= \nnl (stB -mem-fail) (R,C,M,Q,stB rd,rs)-.0 fault Rval(rz)=0 Rval(d)=0 (bz-untaken-fail) (R,C,M,Q,bzc rz,rd)-.0 \nfault Rval(rz )= 0 Rval(d)= 0 (R,C,M,Q,bzG rz ,rd)-.0 fault (bzG-taken-fail) Rval(rz)= 0 Rval(rd)= Rval(d) \nor Rval(d)= (R,C,M,Q,bzB rz ,rd)-.0 fault 0 (bzB -taken-fail) A.2 Semantics of Static Expressions [ \nE] [ n] = n [ E1 opE2] =[ E1] op[ E2] [ emp] = \u00b7 [ selEm En] =[ Em] ([ En] ) [ updEm E1 E2] =[ Em] [[ \nE1 ] . [ E2] ] . f E1 = E2 . f E1 : .int . f E2 : .int .S.\u00b7f S :. =. [ S(E1)] =[ S(E2)] (E-eq) . f E1 \n= E2 . f E1 : .int . f E2 : .int .S.\u00b7f S :. =. [ S(E1)] =[ S(E2)] (E-neq) . f E1 = E2 . f E1 : .mem \n. f E2 : .mem Dom([ S(E1)] )= Dom([ S(E2)] ) .. . Dom([ S(E1)] ). [ S(E1)] (.)=[ S(E2 )] (.) (E-mem-eq) \n. f E1 = E2 Rval(rs)./Dom(M) (ldB -fail) (R,C,M,Q,ldB rd,rs)-.0 fault   \n\t\t\t", "proc_id": "1250734", "abstract": "<p>A <i>transient hardware fault</i> occurs when an energetic particle strikes a transistor, causing it to change state. Although transient faults do not permanently damage the hardware, they may corrupt computations by altering stored values and signal transfers. In this paper, we propose a new scheme for provably safe and reliable computing in the presence of transient hardware faults. In our scheme, software computations are replicated to provide redundancy while special instructions compare the independently computed results to detect errors before writing critical data. In stark contrast to any previous efforts in this area, we have analyzed our fault tolerance scheme from a formal, theoretical perspective. To be specific, first, we provide an operational semantics for our assembly language, which includes a precise formal definition of our fault model. Second, we develop an assembly-level type system designed to detect reliability problems in compiled code. Third, we provide a formal specification for program fault tolerance under the given fault model and prove that all well-typed programs are indeed fault tolerant. In addition to the formal analysis, we evaluate our detection scheme and show that it only takes 34% longer to execute than the unreliable version.</p>", "authors": [{"name": "Frances Perry", "author_profile_id": "81333490569", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP33036491", "email_address": "", "orcid_id": ""}, {"name": "Lester Mackey", "author_profile_id": "81331498860", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP33032566", "email_address": "", "orcid_id": ""}, {"name": "George A. Reis", "author_profile_id": "81100071253", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP33034145", "email_address": "", "orcid_id": ""}, {"name": "Jay Ligatti", "author_profile_id": "81100429229", "affiliation": "University of South Florida, Tampa, FL", "person_id": "PP33032540", "email_address": "", "orcid_id": ""}, {"name": "David I. August", "author_profile_id": "81100388492", "affiliation": "Princeton University, Princeton, NJ", "person_id": "P60452", "email_address": "", "orcid_id": ""}, {"name": "David Walker", "author_profile_id": "81100426485", "affiliation": "Princeton University, Princeton, NJ", "person_id": "PP39042257", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250741", "year": "2007", "article_id": "1250741", "conference": "PLDI", "title": "Fault-tolerant typed assembly language", "url": "http://dl.acm.org/citation.cfm?id=1250741"}