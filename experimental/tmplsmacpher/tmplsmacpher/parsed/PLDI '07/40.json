{"article_publication_date": "06-10-2007", "fulltext": "\n Static Error Detection using Semantic Inconsistency Inference * Isil Dillig Thomas Dillig Alex Aiken \nComputer Science Department Stanford University {isil, tdillig, aiken}@cs.stanford.edu Abstract Inconsistency \nchecking is a method for detecting software errors that relies only onexamining multiple usesofavalue.We \npropose that inconsistencyinference is best understood as a variant of the older and better understood \nproblem of type inference. Using this insight, we describe a precise and formal framework for discover\u00ading \ninconsistency errors. Unlike previous approaches to the prob\u00adlem, our technique for .nding inconsistency \nerrors is purely se\u00admantic and can deal with complex aliasing and path-sensitive con\u00additions. We have \nbuilt a null dereference analysis of C programs based on semantic inconsistencyinference and have used \nit to .nd hundreds of previously unknown null dereference errors in widely usedCprograms. Categories \nand Subject Descriptors D.2.4[Software Engineer\u00ading]: Software/ProgramVeri.cation; D.2.5[Software Engineer\u00ading]:Testing \nand Debugging General Terms Languages, Reliability,Veri.cation, Experimen\u00adtation Keywords Static analysis, \nerror detection, satis.ability, inconsis\u00adtency 1. Introduction Much recent work in static analysis focuses \non source-sink proper\u00adties:For safety policy S, if S is violated when a value constructed at location \nl1 is consumed at location l2, then is there a feasible path from l1 to l2?If the answer is yes, then \nthe program has a bug (violates policyS). Some typical speci.cations are: Does a null value assigned \nto a pointer or reference reach a pointer dereference?  Does anyclosed .le reach a .le read?  Does \na tainted input reach a security critical operation?  To be concrete, consider the following C-like \ncode: * This work was supported by grants from DARPA, NSF (CCF-0430378 and SA4899-10808PG-1), and equipment \ngrants from Dell and Intel. Permission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are not made or distributed for \npro.t or commercial advantage and that copies bear this notice and the full citation on the .rst page.To \ncopyotherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, USA. Copyright c . 2007ACM 978-1-59593-633-2/07/0006...$5.00. \nfoo(...) { if (Q) p = NULL; (1) ... bar(p); } bar(x) { if (R) *x; (2) ... } Thenullvalue assignedat(1) \nreachesthe dereferenceat(2)ifpred\u00adicates Q and R can bothbe true, resultinginaprogram crash.Several model \ncheckers incorporating predicate abstraction and re.nement [2,3] and type-based systems [10] target such \nspeci.cations. These systems work by searching for a path from a source to a sink vio\u00adlating the speci.cation. \nThere is a complementary approach to these problems. Instead oftryingtoprovethatasourcecanreachasink,wecanlookataset \nof sinks that a value x reaches and see if they express inconsistent beliefs about x [6]. In the example \nabove, assume we did not have the function foo available,but that the function bar is: bar(x) { if (x \n!= NULL) *x; (2) ... *x; (3) ... } Something is clearly not quite right with this function. At best bar \nis never called with a null value, in which case the test at (2) is just unnecessary and might confuse \nreaders of the code about the actual possiblevalues of x. Atworst bar hasalatent crashingbugwaiting to \nhappen, as the unprotected dereference at line (3) must cause an error if x is null. Previous work on \ninconsistencychecking is informal in nature, and it is not clear how it relates to standard semantics-based \nap\u00adproaches to software analysis [6],but it is clear that relying only on the uses of a value for clues \nabout program errors is something different from what source-sink systems do. The purpose of this pa\u00adper \nis to clarify what inconsistencychecking is, how it is different from source-sink analysis, and to illustratebyexample \nits potential in practice. We propose that inconsistencychecking is best thought of as a form of an older \nand better developed idea, type inference. Type inference systems already .nd type errors based only \non the use of values;forexample,inanyfunctional languagewithtype inference (e.g., ML or Haskell) the \nfollowing code will be .agged as having a type error just because the two uses of x are type inconsistent \n(one as a number and the other as a list); note that the type declaration of x (the source) is not needed \nto discover this error. From this starting point we make the following contributions: The insight that \nchecking consistency of uses is a type infer\u00adence problem shows a fundamental difference between type \nin\u00adference and source-sink systems, such as most model check\u00aders. Type inference systems .nd inconsistency \nerrors in open programs, such as libraries (e.g., the second instance of func\u00adtion bar above, considered \nwithout a caller foo)that cannot be found by source-sink analyzers simply because no source ex\u00adists. \n Casting many inconsistency checking problems as type infer\u00adence problems requires non-standard types. \nThe core issue is when the values at two usage sites x and y are considered to be the same , so that \nx and y are checked for consistency.A particularly problematic case is pointers; we propose that if two \npointerspointtothesamevaluesunderthesame conditionsthen those two pointers are really the same pointer \n(see Section 5.1).  For path-sensitive analyses there is a dif.culty of how to con\u00adstruct appropriate \npredicates when there is no one source-sink pathto useasa sourceof counterexamplesfor re.nement.We present \na method based on computing correlations between program predicates and values of interest.  We conduct \nan extensive experiment, analyzing over 8 mil\u00adlion lines of C source (including the entire Linux kernel) \nfor null dereference errors.Wehave implemented bothsource-sink checking and inconsistencychecking and \nfound over 600 pre\u00adviously unknown null dereferences,theoverwhelming majority of which are found by inconsistencychecking. \nWhile there are limitations to our experiment (in particular, our implemented analyzer is unsound, which \nmay affect the ratio of source-sink to inconsistency errors detected), based on the results, we be\u00adlieve \nthat inconsistency checking is valuable both because it works for open programs and because the discoveredbugs \nare often local whereas understanding a source-sink path for the samebug appears daunting.  We begin \nour presentation with a small, paradigmatic language in which we develop our formal results (Section \n2). We present both (intraprocedural) source-sink and inconsistencychecking for this language (Section3)andalsoextendour \ntechniquetoaninter\u00adprocedural analysis (Section4).Wethen describeanull dereference analysis and necessaryextensions \nforCprograms (Section5) and present our experimental results (Section 6). 2. Language and Inference System \nThis section describes a simple .rst order, call-by-value language we use for the formal development. \nProgramP ::= F + FunctionF ::= deff(x1,...,xn)= s StatementS ::= x .. Ci | x .. y | check. b | f(x1,...,xn). \n| s1;. s2 |if. b then s1 else s2 ConditionB ::= x = Ci The language has standard function de.nitions, \nassignments, state\u00adment sequences, and conditionals; the semantics is also standard and we omit a formal \nsemantics for brevity. The only values in the language are nullary constructors (constants) C1,...,Cn.A \ncondition x = Ci is true if x has the value Ci. A statement check. x = Ci checks whether variable x is \nCi.We use check statements to model requirements that a variable must have a cer\u00adtainvalueata particular \nprogram point.Inexamples we sometimes need a no-op statement (e.g., to .ll in a branch of an if); in \nsuch cases we write skip. to abbreviate the assignment y .. y.We also assume for simplicity that all \nvariables that are not function arguments are assigned to before they are read, so we do not need to \nde.ne how local variables are initialized. The superscript . s on statements are labels. We assume all \nlabels in a program are distinct, uniquely identifying statements. We often abuse our notation slightly \nby writings . to refer to the top-level label . of statement s. The only sources (constructors) in this \nlanguage are constants Ci and the only sinks (destructors) are the check statements.For example, the \nfollowing program has a source-sink error: the source assigned at .0 reaches the con.icting sink at .4. \nEXAMPLE 1. (x ..0 C1 ;.1 if.2 (y = C2 ) then y ..3 C3 else check.4x = C2 );.5 if.6 (y = C1 ) then skip.7 \nelse check.8x = C1 The language syntax allows us to de.ne algorithms via struc\u00adtural induction,butitisalsohandytobeabletoviewa \nfunction de.nition asa control-.ow graph.For each statement label . there are two program points .- and \n.+ representing the points immedi\u00adately before and after the statement executes, respectively. De.ni\u00adtion1de.nes \nthe possible orderofevaluationof statements within a function. DEFINITION 1(Partial Orderon Program Points).Fora \nfunction deff(x1,...,xn)= s, let .f be the smallest relation on program points in f satisfying for each \nsub-statement of s: x .. ... . .- .f .+ check. ... . .- .f .+ 8 .- .- < 0 .f 1 .1 .0 .2 s ; s . .+ .f \n.- 12 12 : .+ .+ 2 .f 0 j .- .- .1 .2 0 .fi if.0 b then s1 else s2 ..i=1,2 .+ .+ i .f 0 Let . * f be \nthe transitive closure of .f .A path from .0 to .n is a sequence of labels .0,...,.n in f such that (1) \n.- . * .- for 0 = i = n - 1 i fi+1 (2) the sequence is maximal between the endpoints: inserting any additional \nlabel after .0 and before .n violates (1). Apath is complete if it cannot be extended either by adding \nnew labels before the .rst label or after the lastlabel; a complete path is apath throughthe entire functionbody.For \ninstance,in Example1, . .+ . .- . .- there is a path .0,.2,.4 because .- 0024 . This path can be extended \nin both directions to form a complete path .5,.1,.0,.2,.4,.6,.7. 2.1 Guards To allow for path-sensitivity \nin our static analysis, we construct guards that express program constraints. We use boolean satis.\u00adability \n(SAT) as the underlying decision procedure for solving con\u00adstraints; hence guards are represented as \nboolean formulas. In this section, we describe how to compute two kinds of guards: statement guards \nthat describe the conditions under which a statement executes,  constructor guards that describe the \ncondition under which a variable x at a given program point evaluates to a constructor Ci. In addition, \na constructor guard also encodes the source of the value Ci.  (1) G,. . x .. Ci : G[x . F ] where F \n= .(r, j).if (r, j)=(., i) then . else false (2) G,. . x .. y : G[x . .(r, j).G(y)(r, j) . .]  (3) \nG,. . check. x = Ci :G (4) G,. . f(x1,...,xn). :G G0,. . s1 :G1 G1,. . s2 :G2 (5) G0,. . s1;. s2 :G2 \nW p = r G0(x)(r, i) G0,. . p . s1 :G1 G0,. .\u00acp . s2 :G2 (6) G0,. . if. x = Ci then s1 else s2 :G1 . G2 \n.xi.Dxi , true . s :G (7) . deff(x1,...,xn)= s Figure 1. Computing guards. Constructor guards are functions \nof type CG =(Source \u00d7 Int) . Guard The Int in the function signature corresponds to a constructor index, \nand the Source in function def f(x1 ,..., xn ) is either a label . of an assignment statement z .. Ci \nin f or one of the function arguments x1 ,..., xn . Sources used in constructor guards track the origin \nof every value in a function in terms of function arguments or constructor assignments within that function.We \nuse r, r . ,r1,... to range over sources. Consider an assignment x .. Ci with statement guard .. The \nconstructor guard gx for x after the assignment is gx(., i)= ., where . is the statement guard for ., \nand gx(r, j)= false for all r .. and j = i. Thus, the constructor guard encodes that immediately after \nthe assignment the value of x is Ci from source . if . is satis.ed, and no other value/source combinations \nare possible. We require that the formulas in the range of a constructor guard be pairwise disjoint: \nif g is a constructor guard and g(r, i)= .1 and g(r .,j)= .2, then .1 . .2 = false if r .= r . or i .= \nj. This condition captures the idea thatavalue cannot simultaneously be two distinct constructors or \ncome from two different sources. Wecanalways enforcethis conditionbyaddingnewunconstrained booleanvariablesto \nguards.Forexample,if there areonlytwocon\u00adstructors C1 and C2, then the constructor guard g with g(r, \n1) = a and g(r, 2) = \u00aca enforces disjointness; for more constructors we can use additional fresh variables. \nWe write Dx for a fresh con\u00adstructor guard associated with function argument x. By fresh, we mean that \nthe formulas in the range of Dx share no variables with Dy for distinct variables x and y. Furthermore, \nDx(r, j)= false for all r .is x. = x;i.e., the only source of values inDx Figure 1 gives inference rules \nfor computing both statement guards and constructor guards resulting fromexecutingastatement. An environment \nG: Var . CG is a map from program variables to constructor guards.Fora statement s and initial environment \nG and statement guard ., the system proves sentences of the form G,. . s :G., where G. is the .nal environment \nafter execution of s. Note that the inference system is purely structural; in anyproof there is exactly \none conclusion associated with statement s, which we can rewrite as: .- .+ G,.. . s . :G Inthiswaywecanrefertotheenvironmentsforthe \nprogrampoints before and after . as well as the statement guard under which s . is executed. Webrie.yexplainthe \nrulesin Figure1.Whenavariablex is as\u00adsigned a constructor Ci (rule (1)), x s constructor guard shows \nthat it cannot have any value other than Ci from source . (guards for all other constructors and all \nother sources are false). Furthermore, x only has value Ci if the assignment executes (the guard . on \nthe assignment statement holds). The second form of assignment (rule (2)) says that the possible sources/values \nof x after the assignment are the possible sources/values of y before the assignment,but only if the \nassignment executes the statement guard . is added to the guard of every possible source/value pair. \nA check. x = Ci statement (rule (3)) tests the predicate (x = Ci) at run-time. These are the sinks in \nour language. The purpose of our analyses is to characterize when the run-time test can evaluate to false; \nthis can model, for example, the implicit assertion that a pointer is non-null before it is dereferenced, \nor more generally that a value of a discriminated union type has the correct constructor (our choice \nof the term constructor is meant to suggest discriminated unions), or that a value is in the correct \ntype-state before some operationis performed.As our interestisin when the testis false and not what happens \nas a result of the test, we de.ne check statements to have no effect on the environment. Function calls \n(rule (4)) also have no effect on the environment; because there are no visible side-effects of a function \nand no return value, function calls have no effect on the callee s state. Of course, this rule also gives \nus no information about check statements that may fail in the called function; thus, Figure 1 de.nes \nan intraprocedural analysis.We discussextensionsto interprocedural analysis in Section 4. Rules (5) and \n(6) deal with compound statements. The rule for statement sequences(rule(5))is standard.Foran if statement \n(rule (6)) with statement guard .,the guardp combines all the conditions under which x = Ci from any \nsource. The true branch is analyzed with statement guard . . p and thefalse branch is analyzed with statement \nguard . .\u00acp. The .nal result is a join G1 . G2 of the .nal environments of the two branches, de.ned as \n(G1 . G2)(x)(r, i)=G1(x)(r, i) . G2(x)(r, i) Finally, a function body (rule (7)) is analyzed in an environment \nwhere nothing is known about a function argument except that it evaluates to a single constructor at \na given call site (recall that for each argument x, the guards in the range of the constructor guard \nfor x are all disjoint). Notice that statement guards and constructor guards are mutu\u00adally dependent \n(e.g., rules (1) and (6)) and thus are computed simul\u00adtaneously. The reason for this design decision \nis that the computa\u00adtion of statement guards is affected by side-effects of statements, which are in \nturn implicitly captured by constructor guards. Con\u00adversely, the condition under which a statement causes \na particular side-effect to happen depends on the condition under which that statement executes; hence \nthe computation of constructor guards makes use of statement guards. As an illustration of guard compu\u00adtation, \nconsider the example: EXAMPLE 2. if.0 (x = C1 ) then ( x ..1 C2 ;.6 if.2 (x = C1 ) then check.3x = C2 \nelse skip.4 ) else skip.5 Suppose that we are interested in knowing the statement guard associated with \nthe check statement at program point .3. Suppose .0 is the entry point of a function, and let a1 and \na2 be formu\u00adlas that represent the conditions under which function argument x evaluates to C1 and C2 \nat function entry respectively. After execut\u00ading the assignment statement at program point .1, the guard \nunder which x evaluates to C1 is false by Rule (1) of Figure 1, and the guard under which x evaluates \nto C2 is a1, which is the statement guard at this program point. The statement guard at program point \n.3 is computed using Rule (6), where . = a1 and p = false;hence the statement guard at .3 is a1 . false \n= false. Since the statement guard at .3 is false, the path from the function entry .0 to program point \n.3 is not feasible. Asthisexample illustrates,the computationof statementguards directly allows the discovery \nof infeasible paths in a program. DEFINITION 2 (Feasibility). Let .0,...,.n be a path. Then the V path \nis feasible if SAT( ..i ). 0=i=n Returningto Example1,thepathofthe source-sink error .0,.2,.4 is feasible \nfor an appropriate initial environment, but the path .0,.2,.3,.6,.7 is not feasible in anyenvironment. \nThe following lemma captures some simplebut very usefulfacts about feasible paths. LEMMA 1. AssumeG,. \n. s :G. and let s be anyassignment that satis.es ..Then thereisa unique complete, feasiblepath including \ns such that s satis.es all the statement guards on the path. PROOF. The proof is by induction on the \nstructure of s. The inter\u00adesting case is when s =(if. x = Ci then s1 else s2). From rule (6) of Figure \n1, the .nal step of the derivation must be: W p = r G(x)(r, i) G,. . p . s1 :G1 G,. .\u00acp . s2 :G2 G,. \n. if. x = Ci then s1 else s2 :G1 . G2 Now either s(. . p) is true or s(. .\u00acp) is true. Assume that s(. \n. p) is true. Then G,. . p . s1 :G1 satis.es the inductionhypothesis with assignment s,and so there is \na unique complete feasible path .1,...,.n for s1 such that s(..i ) is true for all 1 = i = n. Then ., \n.1,...,.n is the desired path for s. The case where s(. .\u00acp) is true is symmetric. 3. Error Detection \nIn this section we present techniques for identifying source-sink and inconsistency errors using the \nmachinery developed in Sec\u00adtion 2. Only intraprocedural techniques are discussed here; Sec\u00adtion4 extends \nthe approach across function boundaries. 3.1 Source-Sink Errors Source-sink errors arise when a value \nconstructed at one program point reachesan unexpected destructoratadifferent program point. Most errors \nuncovered by model checking tools, and particularly model checkers based on counter-example driven re.nement, \nare source-sink errors. This class of errors includes, for example, type\u00adstate properties, such as errors \nthat arise from dereferencing a pointer that has been assigned to null, or using a tainted input in a \nsecurity critical operation. DEFINITION 3 (Source-Sink Error). Consider the sub-derivation for a check \nstatement: .- .. .+ G,.. checkx = Ci :G The check canfail becauseofavalue from source .. if the state\u00adment \nis reachable when constructor Cj originating from .. is in the constructor guard of x for some j .= i. \nMore formally, a source\u00adsink error arises if there is a label .. of an assignment statement y ... Cj \nsuch that _ ..- . SAT(.. G(x)(.,j)) j. =i The following lemma shows that there is always at least one \nfeasi\u00adble path corresponding to anysource-sink error. LEMMA 2. Every source-sink error is included on \nat least one complete feasible path. W G.- PROOF. Let .. = .. . (x)(..,j), and let s be any .. j=.i assignment \nsatisfying ... . . Since the formula ... . is satis.able there is at least one such s. By Lemma 1, s \nde.nes a unique, complete feasible path. By expanding the de.nition of ... . and using thefact that rule(1)in \nFigure1includes the statement guard in the constructor guard after the assignment, we can show that ... \n. satis.es both statement guards ... and ... Thus, both the assignment statement and the check are on \nthe path. Consider once more the programinExample1. Assignment state\u00adment .0 gives x a constructor guard \nwhere C1 from source .0 has guard true (just because x is assigned C1 at .0). The constructor guard of \nx is not affected by the check statement at .4. Since the check is whether x = C2, one of the tests for \na source-sink error is: _ - .4 . SAT(.G.4 (x)(.0,j)) j. =2 - Because ..4 is satis.able and G.4 (x)(.0, \n1) is true, we have shown a source-sink error in the program. Note that De.nition3requires that the sourcebe \nthe labelof an assignment statement we do not consider function arguments as sources in computing source-sink \nerrors, because we do not know what actual values a function argument may have while analyzing only the \nfunction body. Source-sink errors may arise if a function is called with certain arguments that cause \nthe check statement tofail. Interprocedural analysis is required in this case to .nd the matching source, \nif any, that actually causes the sink to fail; we address interprocedural source-sink errors in Section \n4. 3.2 Inconsistency Errors In this section, we de.ne inconsistencies and describe a technique for semantically \ndetecting inconsistency errors. Consider the following motivating example: EXAMPLE 3. def f(a) = (x ..0a;.1 \nif.2 (x = C1 ) then check.3x = C1 else y ..4x);.5 check.6a = C1 In this example, a and x are aliases \nfor the same value because of the assignment at .0. At .3, x is asserted to have the value C1 andthis \nstatementis protectedbythe conditionalat .2. Thevariable a is also asserted to be C1 at .6,but without \nthe protecting test. Thus, if there actually is an environment in which this function can be called where \na .C1 , an error is sure to occur at .6. The = presence of the test at .2 protecting the check at .3 \nis evidence that some programmer believes there are such environments. Thus, without knowing anything \nabout the rest of the program, it is likely that there is something wrong in this function because of \nthe inconsistent assumptions about a and x. This example illustrates that inconsistency errors can involve \naliasing if multiple names for the same value are used inconsis\u00adtently. Finding inconsistency errors \nmeans identifying a set of uses of the same value that should be compared. If we are to take alias\u00ading \ninto account, we cannot rely on uses of the same variable name or (more generally) syntactically identical \nprogram expressions to identify the set of uses a semantic test for sameness is needed. ~ More formally, \nwe de.ne a congruence relation v1 = v2 that captures when two quantities v1 and v2 should be checked \nfor consistency.Theexact de.nitionof ~ = varies with the programming language. For our toy language, \nan appropriate de.nition is that two variables at given program points are congruent if they have the \nsame values under the same guards at those points. DEFINITION 4 (Congruence). Let v1 and v2 be two variables \nin EXAMPLE 4. def f(a) = if(a=C1) then x . C1 else x . C2; if(a=C1) then y . C1 else y . C2; check(x=C2 \n); if(y=C2) then check(y=C2 ) else skip; In this example, x and y have the same values under the same \nconditions,but not from the same sources. The conditional if(y =C2 ) indicates that some programmer believes \nthere is some call site where a can be C1 ; otherwise, y would always be C1 . But if - 1 and . - 2 be \nprogram points in f. this is the case, then x can also be C1 , and there is at least one the same function \nf, and let . - - execution trace where check(x=C2 ) will fail. Hence, the above example should be classi.ed \nas an inconsistency, justifying our . ~. = 1 2 Then v , meaning variable v1 at program point .1 is v \n1 2 congruent to variable v2 at program point .2, if de.nition of congruence. Finally, note that while \nsource-sink errors are characterized by a single feasible path, inconsistency errors are characterized \nby a _ G . - 1 (v1)(r, i) = _ - . 2 (v2)(r, i) .i. G rr feasible path (condition (3)) and the absence \nof anyfeasible path to a different program point (condition (2)). Thus, inconsistency in\u00ad herently requires \nreasoning about the relationships among multiple paths, unlike source-sink error detection. Notice that \nwe do not require that the sources of congruent vari\u00ad ables be the same. Thus x and y can be congruent \neven if they are constructed completely independently; we return to this point shortly. DEFINITION 5 \n(InconsistencyError). Consider two check state\u00adments check.0 x = Ci and check.1 y = Ci. There is an inconsis\u00adtency \nerror between the two statements if the variables are congru\u00adent and one check canfail while the other \ncannot.Formally, there is an inconsistencyif the following three conditions are satis.ed:  3.3 Intersection \nof Source-Sink and Inconsistency Errors Our discussion sofar highlights that source-sink and inconsistency \nerror detection techniques are fundamentally different: First, detec\u00adtion of source-sink errors involves \nreasoning about a single pro\u00adgram path, while the detection of inconsistencies can require rea\u00adsoning \nabout multiple paths. Second, source-sink error detection requires the source to be explicit in the source \ncode, while incon\u00ad -- ~ .. 0 1 (1) x sistency detection infers errors only from usage sites, i.e., sinks, \n= y WW \u00acSAT(..0 . W r W - G. and can therefore .nd errors even when the source comes from the environment. \nDespite these differences, some errors can be seen both as (2) 0 (x)(r, j)) =i =i Condition (2) says \nthat it is not the case that the statement guard at j - SAT(..1 . (G.(3) 1 (x)(r, j)) jr source-sinkand \ninconsistencyerrors;thefollowingexampleispro\u00ad totypical: EXAMPLE 5. .0 can hold and x has somevalue other \nthan Ci. Condition (3) says that there is at least one solution where the statement guard at .1 holds \nand y has some value other than Ci. if.0 (x = C1 ) then check.1x = C2 Returning to Example3 above, at \npoint . - 6 the variable a has else skip.2 constructor guard Da (the original guards for a, as there \nare no assignments to a in the function) and at point . - 3 the variable x has the same guards because \nof the assignment at .0. Thus This example has an obvious error since the conditional if(x = -.6 ~ = \nx . C1 ) ensures that the check statement at program point .1 fails. 3 , satisfying condition (1). Now \nthe statement guard at Despite thefact that thereis noexplicit source (i.e.,a constructor - 3 (x)(a, \n1), which is disjoint with any - 3 (x)(r, j) for j .1 (recall Section 2.1). Hence, the = check statement \nat .3 cannot fail, and condition (2) is satis.ed. .. statement, adding an extra assignment of the form \nx - is just true, and so condition (3) As noted above, our de.nition of congruence does not require \nany data.ow relationship between the two variables variables tency. Using the intuition that inconsistency \ndetection is a gener\u00adwith different sources may still be congruent. Thus, unlike in Ex\u00ad ample 3, two \ncongruent variables may not even have a common source. At .rst look, this de.nition of congruence seems \ntoo per\u00adPOSSIBLY C1, while the unprotected check statement assigns the exists. Consider the following \nexample: tors C1 and C2 , adding the check statements check.. x = C1 and check... x = C2 in the true \nandfalse branchesof the if statement respectively preserves the semantics of the above program, yield\u00ading \nthe semantically equivalent code: if.0 (x = C1 ) then ( = C1 ;.... check.. x check.1x = C2 ) else check... \nx = C2 This directly exposes the inconsistency in the program according to De.nition5, becausethe check \nstatementat .1 canfail while the one at ... cannot. 4. Interprocedural Error Detection In this section \nwe discuss interprocedural extensions to our ap\u00adproach for detecting both source-sink and inconsistencyerrors. \nBe\u00adfore presenting our interprocedural analysis we .rst revisit what we meanby inconsistencyerrors; unlike \nsource-sink errors, the de.ni\u00adtion of inconsistency must be reconsidered in the interprocedural case. \nConsider the following example: EXAMPLE 6. def f(x)= if.0 (x = C1 ) then check.1x = C1 else skip.2 ;.3 \ng(x).4 def g(y)= check.5y = C1 This program clearly has an inconsistency error: The check at .1 is protected \nby a test at .0, but the check in g on the same value is unprotected. Nowconsider the following, slightly \ndifferent, example: EXAMPLE 7. def f(x)= g(x).0 ;.1 check.2x = C1 def g(y)= if.0 (y = C1 ) then check.1y \n= C1 else skip.2 This example simply interchanges the protected and unprotected check statements: The \ncheck in the caller is now unprotected while the callee guards the check. Extending our intraprocedural \nde.nition of inconsistency errors in the obvious way leads us to conclude that this example also has \nan inconsistency error, but this de.nition of inconsistency results in large numbers of false positives \non real programs. The issue is that g may have other callers besides f. That is, while f may be safe \nin relying on x = C1 , other callers of g may pass arguments other than C1. Defensive programming of \nthis sort is very common in practice. A typical example is a library that does extensive checking of \narguments, while client code may be written with the knowledge that certain values cannot arise.1 In \nsummary, Example6should be considered an inconsistency error,while Example7should not. Thus, when comparingtwouses \n1Asimilar problem arises with our de.nition of inconsistencyin the pres\u00adence of function macros. Since \nmacros are used in manydifferent contexts, they are often written with defensive checks. In our implementation, \ncode resultingfroma macroexpansionistaggedintheparsetreeascomingfrom a macro and treated as an inlined \nfunction. of a value between a caller and a callee, we only consider pairs of uses where the callee check \ncanfail. This decision implies that we do not need to track check statements that are guaranteed to suc\u00adceed \noutside of their containing function; the onlyinterprocedural information we need is knowledge of when \na check statement in a function canfail. We use function summaries for interprocedural analysis:a sum\u00admary \nis computed of the conditions under which a function f can fail, and this summary is then used at each \ncall site off to model f s behavior for the purpose of detecting source-sink and inconsistency errors. \nThis approach is context-sensitive, since the summaries are applied separatelyatevery call site.Wedescribehowfunction \nsum\u00admaries are de.ned and used in a basic form (Sections 4.1 and 4.3) and introduce a signi.cant improvement \n(Section 4.2). 4.1 Function Summaries Afunction summary describes the preconditions on the execution \nofa functionthat,if satis.ed,mayleadto errors. Computing sound and very precise preconditions is easy \nin our framework; the dis\u00adjunctionofallthefailure conditionsforevery check statement in a function characterizes \nexactly the condition under which some check willfail. Unfortunately, propagating such precise informa\u00adtion \ninterprocedurallyis prohibitivelyexpensive;the formulasgrow very rapidly as conditions are propagated \nthrough a series of func\u00adtion calls. We take a different approach to function summaries that is designed \nto scale while still expressing all the possible conditions under which a check ina function mayfail. \nThe price we payis a loss of precision in the general case; one can construct examples for which our \nsummaries greatly overestimate the precondition for failure.However,our summariesdo precisely summarizethefailure \nprecondition of the vast majority of functions we have observed in practice. Afunction summary S has \nthe same signature as a constructor guard: a map from sources (in this case just function arguments) \nand constructor indices to guards: S =(Source \u00d7 Int) . Guard The interpretation of summaries is different, \nhowever. The idea is that if S(a, k)= p, then a call of f where formal parameter a is Ck canfail if the \ninitial state of the callalso satis.es predicate p. For example, in Example 6,Sg(y, 1) = false and Sg(y, \ni)= true for i .1 captures that when the argument is Ci for any i .1 == function g may fail. In Example \n7, Sg(y, i)= false for all i expresses that the function can neverfail. DEFINITION 6 (Function Summary). \nConsiderafunctionf where .xi.Dxi , true . s .0 :G . deff(x1,...,xn)= s.0 Then (Sf (xi,j)= p) . .(xi, \nj, p) where .(xi, j, p) = (1) .(check.1 . x = Ck) in f where k = j. - (2) if SAT(..1 . G.1 (x)(xi,j)) \nthen - (3) (..1 . G.1 (x)(xi,j)) . p In words, for each function argument xi and constructor Cj , on \nline (1) we consider the set S of all statements check.1 x = Ck such that the check fails ifx = Cj (i.e., \nthe condition k =.j). On line (2) we further restrict our focus to the subset S. of statements in S where \nthe check canfail because the sourceof constructor Cj is argument xi.On line (3), forevery check in this \nsmaller set S., we are looking for a necessary condition p that holds whenever one of the checks in S. \nfails. As a result,p gives an over-approximation of the condition under which a check statement in f \nwill fail if argument xi is constructor Cj at some call site. In other words, if SAT (p . (xi = Cj )) \nfor some call site, a check mayfail in f. Itis easyto seethat setting p to true always satis.es the condi\u00adtions, \nso that Sf (xi,j)= true for all xi and Cj isalwaysacorrect, if very imprecise, function summary. If Sf \n(xi,j)= false then no check in f canfail when xi = Cj . One simple strategy for computing function summaries \nis: j false if .(xi, j, false) Sf (xi,j)= true otherwise The reader may easily con.rm that this algorithm \nyields Sg(y, 2) = true and Sg(y, 1) = false for Example 6. In Section 4.2 we con\u00adsider how to compute \nguards p other than true and false. Now consider a more involved example: EXAMPLE 8. def foo(a1 , a2 \n)= if.0 (a2 = C2 ) then x ..1 a2 else x ..2 a1 ;.3 check.4x = C2 Assume that the only constructors are \nC1 and C2. Applying the testgivenin De.nition6to Sfoo (a1, 1), we have: The single check statement satis.es \nline (1) of De.nition 6 with k =2. - For line (2),..4 is true and G.4 (x)(a1, 1) is satis.able because \nof the assignment at .2.  For line (3), settingp = true satis.es the implication.   4.2 Correlation \nAnalysis The summary generation strategy described in Section 4.1 has two principal strengths. First, \nit captures the common case where an error in the body of a function is triggered by the value of a single \nfunction argument. Second, if the only possibilities for p are true and false, then the size of summaries \nis guaranteed to be bounded bythe product of the number of function arguments and the number of distinct \nconstructors. However,there are manyrealisticexamples where this approach is not expressive enough, because \nthere are times when program\u00admers use two or more correlated arguments to a function; consider, for example, \nwhen one argument serves as a .ag describing the state of another argument. The following example encodes \nsuch an idiom in our toylanguage: EXAMPLE 9. def f(a1 , a2 )= if.0 (a2 = C1 ) then check.1 a1 = C1 else \nskip.2 If the predicates of Sf are limited to true and false, then the best we can do in this example \nis Sf (a1 , 2)= true, which is rather coarse as f s check does not unconditionallyfail when a1 =.C1 . \nA better summary would record that Sf (a1 , 2) = (a2 = C1 ), precisely capturing the necessary condition \nforfailure when a1 = C2 .We perform a correlation analysis to discover such additional predicates: DEFINITION \n7 (Correlation Analysis). Considerafunction de.ni\u00adtion def f(x1 ,..., xn )= s. Let fk,h be a formula \nfor the expres\u00adsion (xk = Ch ). ^ Sf (xi,j)= {fk,h|.(xi, j, fk,h)} In Example 9, we have ..1 = (a2 = \nC1 ), and so Sf (a1 , 2) = (a2 = C1 ) using the algorithm in De.nition 7. Similarly, using the correlation \nanalysis for computing a more precise summary for Example 8, we obtain Sfoo (a1 , 1) = (a2 = C1 ). It \nis instructive to compare our approach to interprocedural path sensitivity with source-sink error detectors. \nWhile full interproce\u00addural path sensitivity may be intractable for large programs, model checking techniques \nhave shown that computing path sensitivity in ademand-drivenfashion canavoid tracking unnecessary predicates \nand allowanalysesto scale[3,2,5].However,such model checkers rely on having a full path from source to \nsink to drive the process of discovering the needed predicates, information we do not have available \nboth in an inconsistencyanalysis and a compositional in\u00adterprocedural source-sink analysis. Correlation \nanalysis allows us to .nd relevant predicates that play a role in interprocedural com\u00admunication by computing \nnecessary conditions for errors to occur. The price we payisthat we restrict the spaceof predicates consid\u00aderedto \nensure scalability;forexample,in ourtoylanguageweonly consider the predicates fk,h.  4.3 Summary Application \nConsider a function de.nition def f(a1 ,..., an )= s and call site f(x1 ,..., xn ) and a summary Sf .We \nuse the summary of f to model f s behavior at the call site as follows.We de.nea new function fsummary \n(a1 ,..., an )= s . where s . = ... ; sij ; ... is a sequence of statements, one for every argument ai \nand construc\u00adtor Cj . From De.nition 7, Sf (ai , j) must have the form Sf (ai , j)= fk1 ,l1 . ... . fkm \n,lm Abusing our syntax slightly, we de.ne sij to be: if.ij (ai = Cj ) then check((ak1 .) . ... . (akm \n= clm )) = cl1 .else skip; At the call site we simply replace the statement f(x1 ,..., xn ) by s .[x1 \n/a1 ,..., xn /an ]. This approach, which inlines a stub func\u00adtion that approximates the error behavior \nof the original func\u00adtion, allows us to reuse the intraprocedural algorithms for detecting source-sink \nand inconsistency errors from Section3unchanged. 5. A Null Dereference Analysis In this section, we apply \nour approach to the problem of detecting null dereference errorsinCprograms.We .rst presentan encoding \nof the null dereference problem in our framework and then discuss extensions needed to analyze C. Toapplythe \ntechniques in Sections 2-4 to the problem of detect\u00ading unsafe null dereferences, we need only de.ne \nthe constructors and an appropriate congruence relation. Null dereference analysis is about understanding \nwhat pointers can be null, which in turn re\u00adquires a reasonably precise model of all the possible values \nof all pointersina program. OurCimplementation incorporatesa sound context-, .ow-and partially path-sensitive \npoints-to analysis forC [11]. Most points-to analyses compute a graph where the nodes V are the set of \nabstract locations and there is an edge (v, v .) . E if location v may point to v .. The points-to analysis \nwe use labels each points-to edge with a guard (v, v .)g, where g is a formula specifying under what \nconditions v points to v .. The value NULL is treated as a node in the graph, so (v, NULL)g means that \nv may be a NULL pointer whenever guard g is satis.ed. For the congruence relation, given a guarded points-to \ngraph ~ (V,E), we say that v1,v2 . V are congruent, v1 = v2, if .v3 . V.(((v1,v3)g1 . E . (v2,v3)g2 . \nE ) . g1 = g2) That is, two pointers are equivalent if they are aliases of one an\u00adother: theypoint to \nthe same locations under the same conditions. To model constructors, we classify all pointers as NULL \nor NOT-NULL (i.e., everything except NULL). Before each pointer dereference *x we insert a check: . checkx \n= NOT-NULL The check succeeds only if the NULL guard in x s points-to graph is unsatis.able at point \n.- . To illustrate how we detect null inconsistencyerrors in C, con\u00adsider the following example: EXAMPLE \n10. void foo(int* p, int* q, bool flag) { P1. flag = (p!= NULL); P2. q=p; P3. if (flag) P4. *p=8; P5. \n*q =4; } The assignment at P2 ensures p and q have the same guarded ~ points-to relationships; thus p \n= q. The dereference of p at P4 cannot fail because the statement guard (the test on flag at P3) guarantees \nthat p is non-null. However, the dereference of q at P5 canfail because the statement guardis just true. \nThus, we detect a null inconsistencyin foo. 5.1 Extensions for C Thereare featuresinCthatarenotinthetoylanguagewehaveused \nto present our techniques.We brie.y discuss the most signi.cant extensions that are requiredto support \nanalysisofCprograms. The biggest technical difference between the toylanguage and C is that C functions \ncan have externally visible side-effects. In particular,foranull dereference analysis,itis necessaryto \nestimate the set of function side-effects making locations either null or not null.We address this problemby \nusinga separate side-effect analysis to compute sources of null (both in the return value and as a result \nof function side-effects) as well as to track modi.cations to function arguments. However,this side-effect \nanalysis is best effort and unsound; it tracks side-effects that must result in a location being assignednull,butitdoesnot \ncaptureallassignmentsthatjust might result in a location being assigned null. In our opinion, this is \nthe major source of unsoundness in our implementation. The dif.culty in estimating function side-effect \ninformation lies in resolving the tension between two competing goals. First, the quantity of side-effect \ninformation is potentially enormous; com\u00adputing even simple use/mod information for every function (i.e., \njust the set of abstract locations the function reads or writes) in a large program is intractable if \nthe result is represented naively, because the set of side-effects of a function includes all the side\u00adeffects \nof functions it can call either directly or indirectly. Thus, it is necessary to aggressively summarize \ninterprocedural side-effect information to avoid consuming space quadratic (or worse) in the size of \nthe program. Second, the resulting information must be pre\u00adcise enoughto yield useful results, becauseeven \nsmall imprecisions can leadtooverwhelming numbersoffalse positives.We are not aware of any general results \non ef.ciently computing interproce\u00addural side-effect information; the problem appears to be unsolved. \nPrevious null dereference analyzers have focused on intraprocedu\u00adral checking (see Section 7). Another \nseparate issue is what predicates are used by the corre\u00adlation analysis to compute function summaries. \nIn De.nition 7, we considered only predicates fk,h corresponding to conditions of the form (xk = Ch ). \nUnfortunately, in a real programming language, there are arbitrarily manypredicatesof this form.Forexample,if \na function argument x is an integer, it is obvious that we cannot test x = c for every possible integer \nconstant. Our approach is to consider only the predicates that occur inside if statements inthe computation \nof p. An orthogonal issue is the modeling of loops and recursivefunc\u00adtions. The system de.ned in Sections \n2-4 can be used to analyze recursive functions in a sound manner by a standard iterative .xed point computation. \nIn our implementation forC we analyze each function only once and do not attempt to compute .xed points, \nin part to limit the growth in interprocedural side-effect information.2 We have observed that the function \nsummary guards inferred by correlation analysis are almost always very simple; in fact, con\u00adjunctions \nof more than two simple atomic predicates are exceed\u00adingly rare,ifinfacttheyever occur(wehaveyetto notice \nonewith more than two clauses). Thus, we believe that very simple restric\u00adtions on the size and form \nof function summary guards (along with conservative approximation if those limits are exceeded) would \nbe suf.cient to ensure that a .xed point computation terminates with useful (i.e., suf.ciently precise) \nresults. Finally, as discussed above, our system builds upon a may\u00adalias analysis for C. This underlying \nanalysis is sound assuming theCprogramis memory safe(a standard assumptionin may-alias analysis), a condition \nthat is not checked by the alias analysis or our system. 6. Results We have run our null dereference \nanalysis on seven widely used open source projects and identi.ed 616 null dereference issues with 149 \nfalse positive reports (an overall 19.5% false positive rate). These projects receive regular source \ncode checking from multiple commercialbug-.nding tools, andso we sought to learn whether thesebugshadbeenpreviously \nreported.Developersforthe Samba project con.rmedthat noneofthe Samba bugs had been previously found. \nFor the other projects we did not receive such an explicit acknowledgment that thebugs were new; however, \nwe judge from thefactthat.xeswere releasedquicklyformanyofthebugsshortly afterour reports were.ledthatatleastthe \nmajorityofthebugswe found were previously unknown. The large majorityof thesebugs, 518, were found by \nour inconsistencyanalysis. We ran our null dereference analysis on a compute cluster. Analyzing the Linuxkernel \nwithover6 MLOC required about4 hoursusing30CPU s,whichwasbyfarthelongesttime required for any of the \nprojects. The smallest project we analyzed was OpenSSH, which took 2 minutes and 33 seconds to analyze \non the same cluster. Our system makes manycalls to a boolean SAT solver to test the satis.ability of \nthe various predicates used in our analyses, and for Linux the number of SAT queries numbers in the millions. \nWe impose a 60 second time limit for analyzing anyindividual function; if the analysis of a function \ntimes out, its function summary is incomplete. Figure2summarizes ourexperimental results. The .rst column \ngives the number of lines of code for each project, the second column presents the total number of reports, \nwhich is classi.ed in the following three columns into correct reports, false positives, and undecided \nreports (reports that we could not classify as either correct reports or asfalse positives, because the \ninterpretation of these reports required a more global understanding of the code base than we had). The \nsixth columngives thefalse positive rate, which is calculated without including the undecided reports. \nThe second group of three columns breaks down the correct reports by kind: the count of inconsistency \nerrors excluding those also found by source-sink detection, the number of source-sink errors found 2Cycles \nof mutually recursive functions are analyzed once in an arbitrary order. LOC Total Correct Undecided \nFalse Pos % False Pos Inconsistent Source-Sink Both % Interproc % Alias OpenSSL 0.9.8b 339319 55 47 2 \n6 11.3% 40 6 1 38.3% 34.0% Samba 3.0.23b 515689 68 46 3 19 29.2% 40 4 2 34.8% 17.4% OpenSSH 4.3p2 154660 \n9 8 0 1 11.1% 6 2 0 37.4% 0.0% Pine 4.64 372458 150 119 3 28 19.0% 105 10 4 42.0% 6.7% MPlayer 1.0pre8 \n761708 119 89 2 28 23.9% 71 16 2 41.6% 30.3% Sendmail 8.13.8 364569 9 8 0 1 11.1% 7 1 0 62.5% 12.5% Linux \n2.6.17.1 6275017 373 299 8 66 18.1% 249 38 12 27.8% 12.0% Total 8783420 783 616 18 149 19.5% 518 77 21 \n34.1% 15.4 % Figure 2. Experimental Results alsoas inconsistencies,andthe numberof errors identi.edby \nboth. The last group of two columns show the percentages of correct reports that were interprocedural \nand that involved pointer aliasing, respectively. Many currentbug .nders ignore pointer aliasing and \ninterprocedural analysis; at least for null dereference analysis, our results show that both features \nare important. We used the following methodology in classifying the error re\u00adports. First, source-sink \nerrors resulting from dereferences of return values of functions which can potentially return null were \ncounted once per function, not once per call site. Return values of malloc wrappers that can return null \nare often used unsafely at manycall sites, resulting in a misleadingly large number of correct reports \nif eachsuchcallsiteis countedasabug. Second,we classi.ed incon\u00adsistencyreports as correct reports if \nthere was actually an inconsis\u00adtency, not if we could prove that the inconsistency would lead to a run-time \ncrash. Lacking a detailed global understanding of these large projects, we could often not differentiate \nbetween redundant nullchecksandpotentialcrashingbugs.Inour correspondencewith project developers, we \nwere told that some of the inconsistency er\u00adrors are due to redundant null checks. However, a large majority \nof developers deemedevery inconsistency,including those believedto be redundant null checks, worth .xing. \nThe majority view was that inconsistency errors represented misunderstandings of the incon\u00adsistent function \ns interface and shouldbe .xed.Alarge numberof error reports we classi.ed as correct were con.rmed by \nthe devel\u00adopers; however not all project developersgave us feedback about thevalidityof error reports.In \nsuch cases, the numbersin Figure2 represent our best effort to classify these errors. Figure2shows that \nthe large majority (87.5%)of the errors are inconsistency errors (including conditional misuse errors). \nSince most of these inconsistency errors were immediately .xed by de\u00advelopers, it is our belief that \nsemantic inconsistency detection is able to identify real errors and important interface violations in \nreal code.Figure2alsorevealsthatroughlyathirdoftheoverall correct reports involve interprocedural dependencies, \nsometimes involving many function calls, especially in the case of source-sink errors. Our initial experiments \nwith the tool also highlight the importance of selective path-sensitivity: A .rst version of the analysis \nwith\u00adout path-sensitivity resultedinahighfalse positive rate, whileex\u00adperiments with full path-sensitivity \nhad unacceptably high time-out rates. However, using the correlation analysis, the time-out rate in our \nexperiments stayed between 0.71% and 6.4% of all functions with an acceptablefalse positive rate. Another \ninteresting observation from Figure 2 is that a non\u00adnegligible number of errors (roughly one-third in \nOpenSSL and MPlayer) involve pointer aliasing. Pointer aliasing contributes to a signi.cant source of \nnull pointer errors, especially inconsistency errors, in two common programming patterns. The .rst pattern \nwe observed is that generic void* pointers are often aliased by typed pointers and aliases with different \ntypes are used with inconsistent null pointer assumptions. The other pattern is that array elements are \noften assigned to convenience pointers, which denote current, head, or tail elements of a data structure. \nProgrammers sometimes make different null pointer assumptions when they alternate, for example, between \nusing array[0] and head. Themain sourceoffalsepositivesis imprecisioninthepointer analysis we used, which \ncollapses aggregate structures (e.g., arrays, lists)toasingle abstract location.Ifanullpointeris assignedtoany \nelement of an aggregate data structure, it contaminates other ele\u00admentsofthe samedata structure,causingthe \nanalysistoraisefalse alarms whenever an element of such a contaminated data struc\u00adture is dereferenced. \nOther contributing factors to false positives are some unmodeled constructs, such as inline assembly. \nWe conclude this section by presenting two sample errors re\u00adported by the analysis, which we believe \nto be representative of manyof the error reports generatedby the tool: /* Linux, net/sctp/output.c, line \n270 */ 236 pmtu = ((packet->transport->asoc) ? 237 (packet->transport->asoc->pathmtu) : 238 (packet->transport->pathmtu)); \n... 269 if (sctp chunk is data(chunk)) { 270 retval = sctp packet append data(packet, chunk); ... 286 \n} 538 sctp xmit t sctp packet append data (struct sctp packet *packet,...) 540 {... 543 struct sctp \ntransport *transport = packet->transport; ... 545 struct sctp association *asoc = transport->asoc; ... \n562 rwnd = asoc->peer.rwnd; This example illustrates an interprocedural inconsistency error involving \npointer aliasing, which might potentially cause a null dereference at line 562. On line 236, the pointer \npacket-> transport->asoc is compared against null and packet is later passed to a function which .rst \naliases packet->transport as transport and then aliases transport->asoc as asoc, which is .nally dereferenced \nat line 562. Despite these aliasing relation\u00adships, the caller function assumes that packet->transport->asoc \nmay be null, while the called function dereferences the same pointer without ensuring it is non-null, \ncausing the analysis to gen\u00aderate an inconsistencywarning. The next error illustrates an inconsistency \nerror involving two mutually exclusive paths: /* OpenSSL, e_chil.c line 1040 */ static int hwcrhk_rsa_mod_exp(BIGNUM \n*r, const BIGNUM *I,  RSA *rsa, BN_CTX *ctx) 967 { 985 if ((hptr = RSA_get_ex_data(rsa, hndidx_rsa))!= \nNULL) 987 { 990 if(!rsa->n){ 994 goto err; 995 } 997 /* Prepare the params */ 998 bn_expand2(r, rsa->n->top); \n/* Check for error !! */ ... 1027 } 1028 else 1029 { ... 1039 /* Prepare the params */ 1040 bn_expand2(r, \nrsa->n->top); /* Check for error !! */ ... 1080 } In the true branch of the if statement, the pointer \nrsa->n is checked for being null and subsequently dereferenced at line 998. On the other hand, the same \npointer is dereferenced without a null checkinthefalse branchofthe same if statement at line 1040. The \nimportant point about thisexampleis that detecting inconsistencies requires reasoning about multiple \npaths simultaneously. 7. Related Work The various program analysis traditions appear to have equivalent \npower; for example, there is an equivalence between type systems and model checking [15]. However,these \nresults are for closed pro\u00adgrams.We observe that for open programs techniques that search only for a \nsingle source-sink path cannot express inconsistency er\u00adrors requiring simultaneous reasoning about multiple \ndistinct paths. We view semantic inconsistency checking as complementary to source-sink error detection; \ninconsistency checking can .ndbugs where there are multiple sinks but no sources, while source-sink checking \ncan detectbugs betweenasingle source andasingle sink. Our choice of the terms constructor and destructor \nis inspired by work on detecting uncaught exceptions in functional programs [18, 17] and soft typing \n[4, 1]. A core issue in both bodies of work is tracking which datatype constructors a program value may \nactuallyhaveat run-time. Null dereference analysisisaspecial case where there are only two constructors \nNULL and NON-NULL; our techniques could be adapted to give very precise analysis for these other applications \nas well. FindBugs [12] is a widely used tool for Java that has paid par\u00adticular attention to .nding null \ndereference errors [13]. FindBugs pattern-matches on constructs that are common sources of certain error \nclasses and performs some data-.owcomputation. As our im\u00adplementation is for C, it is not possible to \ndo a direct comparison. Nevertheless, it is clear that FindBugs would not .nd the many path-sensitive, \ninterprocedural, and alias-dependentbugs our more semantic analyses uncover. One can also interpret our \nresults as in\u00addicating that, at least for tools requiring no user annotations, one must move to computationally \nintensive models (incorporating at least path sensitivity) to do signi.cantly better than tools like \nFind-Bugs without unusably highfalse positive rates. Some approaches attack null dereferences using user \nannota\u00adtions on function parameters and local checking of each function body. LCLint [7] uses an unsound \nprocedure to check the safety of dereferences of parameters annotated as may-be-null. More recent annotation-based \nsystems are much closer to being sound [9, 8]. Current annotation languages, which mark a single parameter \nas possibly null or de.nitely not null, are not expressive enough to capture the more complex path-sensitive \nand interprocedural rela\u00adtionships we observed in our experiments. Another approach, exempli.ed by CCured \n[16], is to use a rel\u00adatively inexpensive static analysis to verify the safety of many pointer dereferences \nstatically and then to introduce dynamic checks to enforce the remaining dereferences at run-time. The \nuni.cation-based type inference used in CCured would not .nd mostof thebugs our tool detected, and while \nthe programwouldat leastfailina well-de.nedwayifthenulldereferencewas triggered at run-time,itwould stillfail. \nEngler et al. were the .rst to explicitly propose a method for .nding null dereference errors based on \ninconsistencychecking [6]. Theyargue that inconsistencies suggest programmer confusion and the presenceofbugs,andtheygivesome \ntechniquesfor discovering inconsistencies. We observe that their notion of inconsistency is essentially \nthe same as the idea underlying type inference systems, where inconsistent type constraints from multiple \nuses of a value result in a type error. Our inconsistencyanalysis adopts this more semantic point of \nview and we give purely semantic conditions for inconsistencychecking, which allows our system to uncover \nsubtler bugs involving, e.g., pointer aliasing. Our approach to selective inter-procedural path-sensitivity \nis reminiscent of some selectively path-sensitive model-checking techniques. ESP, for example, only accurately \ntracks branches that affect relevant properties within that branch [5]. Unlike ESP, our approach is fully \npath-sensitive intraprocedurally, and more im\u00adportantly, our analysis infers correlated predicates by \ncomputing implication relations between predicates and guards of relevant events. Model checking tools \nbased on predicate abstraction and re.nement [2, 3, 14] also achieve selective path-sensitivity by dis\u00adcovering \nrelevant predicates. Such tools start with a coarse ab\u00adstraction whichis re.nedby tracking additional \nrelevant predicates until a path is shown to be feasible or infeasible or until no new useful predicates \ncan be discovered. As discussed in Section 4, our approach differs because inconsistency analysis does \nnot have a source-sink path to use as a source of counterexamples. 8. Conclusion We have proposed semantic \ninconsistency inference for .nding errors and interface violations in large software systems.We have \npresented the results of experiments on a number of open source applications, showing that semantic inconsistency \nchecking can uncover a large number of previously undiscovered errors. References [1] A. Aiken, E. Wimmers, \nand T. K. Lakshman. Soft typing with conditional types. In Proceedings of the Symposium on Principles \nof Programming Languages, pages 163 173, 1994. [2] T. Ball and S. Rajamani. The SLAM project: Debugging \nsystem software via static analysis. In Proc. of the Symp. on Principles of Prog. Languages, pages 1 \n3, January 2002. [3] D. Beyer, T. Henzinger, R. Jhala, and R. Majumdar. Checking memory safety with Blast. \nIn Proc. of the Conf. on Fundamental Approaches to Software Engineering, pages 2 18, 2005. [4] R. Cartwright \nand M.Fagan. Soft typing. In Proc. of the Conf. on Prog. Language Design and Implementation, pages 278 \n292, 1991. [5] M. Das, S. Lerner, and M. Seigle. ESP: Path-sensitive program veri.cation in polynomial \ntime. In Proc. of the Conf. on Prog. Language Design and Implementation, pages 57 68, 2002. [6] D. Engler, \nD. Chen, S. Hallem, A. Chou, and B. Chelf. Bugs as deviant behavior:Ageneral approach to inferring errors \nin systems code. Operating Systems Review, 35(5):57 72, 2001. [7] D. Evans. Static detection of dynamic \nmemory errors. In Proc. of the Conf. on Prog. Language Design and Implementation, pages 44 53, 1996. \n[8] M.FaehndrichandK. RustanM. Leino. Declaringand checking non\u00adnull types in an object-oriented language. \nIn Proc. of the Conf. on Object-Oriented Programing, Systems, Languages and Applications, pages 302 312, \n2003. [9] C. Flanagan, R. Leino, M. Lillibridge, G. Nelson, J. B. Saxe, and R. Stata. Extended static \nchecking for Java. In Proc. of the Conf. on Prog. Language Design and Implementation, pages 234 245, \n2002. [10]J.Foster,M.Faehndrich,andA.Aiken. Atheoryoftype quali.ers. In Proc. of the Conf. on Prog. Language \nDesign and Implementation, pages 192 203, 1999. [11] B. Hackett and A. Aiken. How is aliasing used in \nsystems software? In Proceedingsof theACM International Symposium onFoundations of Software Engineering, \npages 69 80, 2006. [12] D. Hovemeyer andW. Pugh. Findingbugs is easy. SIGPLAN Not., 39(12):92 106, December \n2004. [13]D.Hovemeyer,J. Spacco,andW. Pugh. Evaluatingand tuninga static analysis to .nd null pointerbugs. \nIn Proc. of theWorkshop on Program Analysis for SoftwareTools and Engineering, pages 13 19, 2005. [14] \nR. Jhala and K. McMillan. Interpolant-based transition relation approximation. In Proc. of the International \nConf. on Computer AidedVeri.cation, pages 39 51, 2005. [15]M.NaikandJ.Palsberg.Atype systemequivalenttoamodel \nchecker. In Proc. of the European Symp. on Prog., pages 374 388, 2005. [16]G.Necula,S.McPeak,andW.Weimer. \nCCured:Type-safe retro.tting of legacy code. In Proc. of the Symp. on Principles of Prog. Languages, \npages 128 139, 2002. [17]F.PessauxandX.Leroy.Type-based analysisof uncaughtexceptions. In Proc. of the \nSymp. on Principles of Prog. Languages, pages 276 290, 1999. [18]K.YiandS.Ryu.Towardsa cost-effective \nestimationof uncaught exceptions in SML programs. In Proc. of the International Symp. on Static Analysis, \npages 98 113, 1997.   \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Inconsistency checking is a method for detecting software errors that relies only on examining multiple uses of a value. We propose that inconsistency inference is best understood as a variant of the older and better understood problem of type inference. Using this insight, we describe a precise and formal framework for discovering inconsistency errors. Unlike previous approaches to the problem, our technique for finding inconsistency errors is purely semantic and can deal with complex aliasing and path-sensitive conditions. We have built a nullde reference analysis of C programs based on semantic inconsistency inference and have used it to find hundreds of previously unknown null dereference errors in widely used C programs.</p>", "authors": [{"name": "Isil Dillig", "author_profile_id": "81331491247", "affiliation": "Stanford University, Stanford, CA", "person_id": "P871676", "email_address": "", "orcid_id": ""}, {"name": "Thomas Dillig", "author_profile_id": "81331491149", "affiliation": "Stanford University, Stanford, CA", "person_id": "P871691", "email_address": "", "orcid_id": ""}, {"name": "Alex Aiken", "author_profile_id": "81100399954", "affiliation": "Stanford University, Stanford, CA", "person_id": "PP39041079", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250784", "year": "2007", "article_id": "1250784", "conference": "PLDI", "title": "Static error detection using semantic inconsistency inference", "url": "http://dl.acm.org/citation.cfm?id=1250784"}