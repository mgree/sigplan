{"article_publication_date": "06-10-2007", "fulltext": "\n Valgrind: A Framework for Heavyweight Dynamic Binary Instrumentation Nicholas Nethercote National ICT \nAustralia, Melbourne, Australia njn@csse.unimelb.edu.au Abstract Dynamic binary instrumentation (DBI) \nframeworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and pro.lers. Much \nof the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. \nAs a result, we believe the potential of DBI has not been fully exploited. In this paper we describe \nValgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique sup\u00adport \nfor shadow values a powerful but previously little-studied and dif.cult-to-implement DBA technique, which \nrequires a tool to shadow every register and memory value with another value that describes it. This \nsupport accounts for several crucial design fea\u00adtures that distinguish Valgrind from other DBI frameworks. \nBe\u00adcause of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind \ncan be used to build more in\u00adteresting, heavyweight tools that are dif.cult or impossible to build with \nother DBI frameworks such as Pin and DynamoRIO. Categories and Subject Descriptors D.2.5 [Software Engineer\u00ading]: \nTesting and Debugging debugging aids, monitors; D.3.4 [Programming Languages]: Processors incremental \ncompilers General Terms Design, Performance, Experimentation Keywords Valgrind, Memcheck, dynamic binary \ninstrumentation, dynamic binary analysis, shadow values 1. Introduction Valgrind is a dynamic binary \ninstrumentation (DBI) framework that occupies a unique part of the DBI framework design space. This paper \ndescribes how it works, and how it differs from other frameworks. 1.1 Dynamic Binary Analysis and Instrumentation \nMany programmers use program analysis tools, such as error checkers and pro.lers, to improve the quality \nof their software. Dynamic binary analysis (DBA) tools are one such class of tools; they analyse programs \nat run-time at the level of machine code. DBA tools are often implemented using dynamic binary instru\u00admentation \n(DBI), whereby the analysis code is added to the original code of the client program at run-time. This \nis convenient for users, Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, USA. Copyright c &#38;#169; 2007 ACM 978-1-59593-633-2/07/0006. \n. . $5.00 Julian Seward OpenWorks LLP, Cambridge, UK julian@open-works.co.uk as no preparation (such \nas recompiling or relinking) is needed. Also, it gives 100% instrumentation coverage of user-mode code, \nwithout requiring source code. Several generic DBI frameworks ex\u00adist, such as Pin [11], DynamoRIO [3], \nand Valgrind [18, 15]. They provide a base system that can instrument and run code, plus an environment \nfor writing tools that plug into the base system. The performance of DBI frameworks has been studied \nclosely [1, 2, 9]. Less attention has been paid to their instrumentation capabil\u00adities, and the tools \nbuilt with them. This is a shame, as it is the tools that make DBI frameworks useful, and complex tools \nare more in\u00adteresting than simple tools. As a result, we believe the potential of DBI has not been fully \nexploited. 1.2 Shadow Value Tools and Heavyweight DBA One interesting group of DBA tools are those that \nuse shadow values. These tools shadow, purely in software, every register and memory value with another \nvalue that says something about it. We call these shadow value tools. Consider the following motivating \nlist of shadow value tools; the descriptions are brief but demonstrate that shadow values (a) can be \nused in a wide variety of ways, and (b) are powerful and interesting. Memcheck [25] uses shadow values \nto track which bit values are unde.ned (i.e. uninitialised, or derived from unde.ned values) and can \nthus detect dangerous uses of unde.ned values. It is used by thousands of C and C++ programmers, and \nis probably the most widely-used DBA tool in existence.1 TaintCheck [20] tracks which byte values are \ntainted (i.e. from an untrusted source, or derived from tainted values) and can thus detect dangerous \nuses of tainted values. TaintTrace [6] and LIFT [23] are similar tools. McCamant and Ernst s secret-tracking \ntool [13] tracks which bit values are secret (e.g. passwords), and determines how much information about \nsecret inputs is revealed by public outputs. Hobbes [4] tracks each value s type (determined from opera\u00adtions \nperformed on the value) and can thus detect subsequent oper\u00adations inappropriate for a value of that \ntype. DynCompB [7] similarly determines abstract types of byte val\u00adues, for program comprehension and \ninvariant detection purposes. Annelid [16] tracks which word values are array pointers, and from this \ncan detect bounds errors. Redux [17] creates a dynamic data.ow graph, a visualisation of a program s \nentire computation; from the graph one can see all the prior operations that contributed to the each \nvalue s creation. In these tools each shadow value records a simple approxi\u00admation of each value s history \ne.g. one shadow bit per bit, one 1 Purify [8] is a memory-checking tool similar to Memcheck. However, \nPurify is not a shadow value tool as it does not does not track de.nedness of values through registers. \nAs a result, it detects unde.ned value errors less accurately than Memcheck. shadow byte per byte, or \none shadow word per word which the tool uses in a useful way; in four of the above seven cases, the tool \ndetects operations on values that indicate a likely program defect. Shadow value tools are a perfect \nexample of what we call heavyweight DBA tools. They involve large amounts of analysis data that is accessed \nand updated in irregular patterns. They instru\u00adment many operations (instructions and system calls) in \na variety of ways for example, loads, adds, shifts, integer and FP opera\u00adtions, and allocations and deallocations \nare all handled differently. For heavyweight tools, the structure and maintenance of the tool s analysis \ndata is comparably complex to that of the client program s original data. In other words, a heavyweight \ntool s execution is as complex as the client program s. In comparison, more lightweight tools such as \ntrace collectors and pro.lers add a lot of highly uni\u00adform analysis code that updates analysis data in \nmuch simpler ways (e.g. appending events to a trace, or incrementing counters). Shadow value tools are \npowerful, but dif.cult to implement. Most existing ones have slow-down factors of 10x 100x or even more, \nwhich is high but bearable if they are suf.ciently useful. Some are faster, but applicable in more limited \ncircumstances, as we will see. 1.3 Contributions This paper makes the following contributions. Characterises \nshadow value tools. Tools using shadow values are not new, but the similarities they share have received \nlittle attention. This introduction has identi.ed these similarities, and Section 2 formalises them by \nspecifying the requirements of shadow value tools in detail.  Shows how to support shadow values in \na DBI framework.  Section 3 describes how Valgrind works, emphasising its fea\u00adtures that support robust \nheavyweight tools, such as its code representation, its .rst-class shadow registers, its events sys\u00adtem, \nand its handling of threaded programs. This section does not delve deeply into well-studied topics, such \nas code cache management and trace formation, that do not relate to shadow values and instrumentation \ncapabilities. Section 4 then shows how Valgrind supports each of the shadow value requirements from Section \n2.2 Shows that DBI frameworks are not all alike. Section 5 eval\u00aduates Valgrind s ease-of-tool-writing, \nrobustness, instrumenta\u00adtion capabilities and performance. It involves some detailed comparisons between \nValgrind and Pin, and between Mem\u00adcheck and various other shadow value tools. Section 6 dis\u00adcusses additional \nrelated work. These two sections, along with some details from earlier parts of the paper especially \nSec\u00adtion 3.5 s novel identi.cation of two basic code represen\u00adtations (disassemble-and-resynthesise vs. \ncopy-and-annotate) for DBI show that different DBI frameworks have different strengths and weaknesses. \nIn particular, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used \nto build more interesting, robust, heavyweight tools that are dif.cult or impossible to build with other \nDBI frameworks such as Pin and DynamoRIO. These contributions show that there is great potential for \nnew DBA tools that help programmers improve their programs, and that Val\u00ad 2 Two prior publications [18, \n15] described earlier versions of Valgrind. However, they discussed shadow values in much less detail, \nand most of Valgrind s internals have changed since they were published: the old x86\u00adspeci.c JIT compiler \nhas been replaced, its basic structure and start-up sequence has changed, its handling of threads, system \ncalls, signals, and self-modifying code has improved, and function wrapping has been added. grind provides \na good platform for building these tools. At the pa\u00adper s end, Section 7 describes future work and concludes. \n 2. Shadow Value Requirements This section describes what a tool must do to support shadow values. We \nstart here because (a) it shows that these requirements are generic and not tied to Valgrind, and (b) \nknowledge of shadow values is crucial to understanding how Valgrind differs from other DBI frameworks. \nNot until Sections 3 and 4 will we describe Valgrind and show how it supports these requirements. Then \nin Sections 5 and 6 we will explain in detail how Valgrind s support for these requirements is unique \namong DBI frameworks. There are three characteristics of program execution that are relevant to shadow \nvalue tools: (a) programs maintain state, S,a .nite set of locations that can hold values (e.g. registers \nand the user-mode address space), (b) programs execute operations that read and write S, and (c) programs \nexecute operations (allocations and deallocations) that make memory locations active or inactive. We \ngroup the nine shadow value requirements accordingly. Shadow State. A shadow value tool maintains a shadow \nstate, S. , which contains a shadow value for every value in S. R1: Provide shadow registers. A shadow \nvalue tool must ma\u00adnipulate shadow register values (integer, FP and SIMD) from S. just like normal register \nvalues, in which case it must mul\u00adtiplex two sets of register values original and shadow onto the machine \ns register .le, without perturbing execution.  R2: Provide shadow memory. S. must hold shadow values \nfor all memory locations in S. To do this a shadow value tool must partition the address space between \nthe original memory state and the shadow memory state. It also must access shadow memory safely in the \npresence of multiple threads.  Read and write operations. A shadow value tool must instrument some or \nall operations that read/write S with shadow operations that read/write S. . R3: Instrument read/write \ninstructions. Most instructions ac\u00adcess registers and many access memory. A shadow value tool must instrument \nsome or all of them appropriately, and so must know which locations are accessed by every one of the \nmany (hundreds of) distinct instructions, preferably in a way that is portable across different instruction \nsets.  R4: Instrument read/write system calls. All system calls ac\u00adcess registers and/or memory: they \nread their arguments from registers and/or the stack, and they write their return value to a register \nor memory location. Many system calls also access user-mode memory via pointer arguments. A shadow value \ntool must instrument some or all of these accesses appropriately, and so must know which locations are \naccessed by every one of the many (hundreds of) different system calls.  Allocation and deallocation \noperations. A shadow value tool may instrument some or all allocation and deallocation operations with \nshadow operations that update S. appropriately. R5: Instrument start-up allocations. At program start-up, \nall the registers are allocated , as are statically allocated memory locations. A shadow value tool must \ncreate suitable shadow values for these locations. It must also create suitable shadow values for memory \nlocations not allocated at this time (in case they are later accessed erroneously before being allocated). \n R6: Instrument system call (de)allocations. Some system calls allocate memory (e.g. brk, mmap), and \nsome deallocate memory  (e.g. munmap), and again some shadow value tools must instru\u00adment these operations. \nAlso, mremap can cause memory values to be copied, in which case the corresponding shadow memory values \nmay have to be copied as well. R7: Instrument stack (de)allocations. Stack pointer updates also allocate \nand deallocate memory, and some shadow value tools must instrument these operations. This can be expen\u00adsive \nbecause stack pointer updates are so frequent. Also, some programs switch between multiple stacks. Some \nshadow value tools need to distinguish these from large stack allocations or deallocations, which can \nbe dif.cult at the binary level.  R8: Instrument heap (de)allocations. Most programs use a heap allocator \nfrom a library that hands out heap blocks from larger chunks allocated with a system call (brk and/or \nmmap). Each heap block typically has book-keeping data attached  (e.g. the block size) which the client \nprogram should not ac\u00adcess (reading it may be safe, but overwriting it may crash the allocator). Thus \nthere is a notion of library-level addressability which overlays the kernel-level addressability. Therefore, \na shadow value tool may need to also track heap allocations and deallocations, and consider the book-keeping \ndata as not active. It should also treat the heap operations as atomic, ignoring the underlying kernel-level \nallocations of large chunks, instead waiting until the allocated bytes are handed to the client by the \nallocator before considering them to be active. Also, realloc needs to be handled the same way as mremap. \nTransparent execution, but with extra output. We assume that shadow value tools do not affect the client \ns behaviour other than producing auxiliary output. This leads to our .nal requirement. R9: Extra output. \nA shadow value tool must use a side-channel for its output, such as a little-used .le descriptor (e.g. \nstderr) or a .le. No other functional perturbation should occur. Summary. These nine requirements are \ndif.cult to implement correctly. Clearly, tools that do these tasks purely in software will be slow if \nnot implemented carefully. One thing to note about these requirements: shadow value tools are among the \nmost heavyweight of DBA tools, and most DBA tools involve a subset of these requirements (for example, \nalmost every DBA tool involves R9). Therefore, a DBI framework that supports shadow values well will \nalso support most conceivable DBA tools. Now that we know what shadow value tools do, we can describe \nValgrind, paying particular attention to its support for the nine shadow value requirements. In Sections \n5 and 6, we will see that other DBI frameworks do not support shadow values as well as Valgrind does. \n 3. How Valgrind Works Valgrind is a DBI framework designed for building heavyweight DBA tools. It was \n.rst released in 2002. The Valgrind distribution [28] contains four tools, the most popular of which \nis Memcheck. Valgrind has also been used to build several experimental tools. It is available under the \nGNU General Public License (GPL), and runs on x86/Linux, AMD64/Linux, and PPC{32,64}/{Linux,AIX}. 3.1 \nBasic Architecture Valgrind tools are created as plug-ins, written in C, to Valgrind s core. The basic \nview is: Valgrind core + tool plug-in = Valgrind tool. A tool plug-in s main task is to instrument code \nfragments that the core passes to it. Writing a new tool plug-in (and thus a new Valgrind tool) is much \neasier than writing a new DBA tool from scratch. Valgrind s core does most of the work, and also provides \nservices to make common tool tasks such as recording errors easier. 3.2 Execution Overview Valgrind \nuses dynamic binary re-compilation, similar to many other DBI frameworks. A Valgrind tool is invoked \nby adding valgrind --tool=<toolname> (plus any Valgrind or tool options) before a command. The named \ntool starts up, loads the client program into the same process, and then (re)compiles the client s machine \ncode, one small code block at a time, in a just-in-time, execution-driven fashion. The core disassembles \nthe code block into an intermediate representation (IR) which is instrumented with analysis code by the \ntool plug-in, and then converted by the core back into machine code. The resulting translation is stored \nin a code cache to be rerun as necessary. Valgrind s core spends most of its time making, .nding, and \nrunning translations. None of the client s original code is run. Code handled correctly includes: normal \nexecutable code, dy\u00adnamically linked libraries, shared libraries, and dynamically gener\u00adated code. Only \nself-modifying code can cause problems (see Sec\u00adtion 3.16). The only code not under a tool s control \nis that within system calls, but system call side-effects can be indirectly observed, as Section 3.12 \nwill show. Many complications arise from squeezing two programs the client and the tool into a single \nprocess. They must share many resources such as registers and memory. Also, Valgrind must be careful \nnot to relinquish its control over the client in the presence of system calls, signals and threads, as \nwe will see. 3.3 Starting Up The goal of start-up is to load Valgrind s core, the tool, and the client \ninto a single process, sharing the same address space. Each tool is a statically-linked executable that \ncontains the tool code plus the core code. Having one copy of the core for every tool wastes a little \ndisk space (the core is about 2.5MB), but makes things simple. The executable is linked to load at a \nnon-standard address that is usually free at program start-up (on x86/Linux it is 0x38000000). If this \naddress is not free an exceptionally rare case, in our experience Valgrind can be recompiled to use a \ndifferent address. The valgrind executable invoked by the user is a small wrap\u00adper program that scans \nits command-line for a --tool option, and then loads the selected tool s static executable using execve. \nValgrind s core .rst initialises some sub-systems, such as the the address space manager and its own \ninternal memory allocator. It then loads the client executable (text and data), which can be an ELF executable \nor a script (in which case the script interpreter is loaded). It then sets up the client s stack and \ndata segment. The core then tells the tool to initialise itself. The command-line is parsed and core \nand tool options are dealt with. Finally, more core sub-systems are initialised: the translation table, \nthe signal\u00adhandling machinery, the thread scheduler, and debug information for the client is loaded. \nAt this point, the Valgrind tool is in com\u00adplete control and everything is in place to begin translating \nand ex\u00adecuting the client from its .rst instruction. This is the third structure and start-up approach \nthat has been used for Valgrind, and is by far the most reliable. The .rst one [18] used the dynamic \nlinker s LD_PRELOAD mechanism to inject Val\u00adgrind s core and the tool (both built as shared objects) \ninto the client. This did not work with statically compiled executables, al\u00adlowed some client code to \nrun natively before Valgrind gained con\u00adtrol, and was not widely portable. The second one [15] was sim\u00adilar \nto the current approach, but required the use of large empty memory mappings to force components into \nthe right place, which turned out to be somewhat unreliable. Most DBI frameworks use injection-style \nmethods rather than having their own program loader. As well as avoiding the problems encountered by \nthe prior two approaches, our third approach has two other advantages. First, it gives Valgrind great \ncontrol over memory layout. Second, it it avoids dependencies on other tools such as the dynamic linker, \nwhich we have found to be an excellent strategy for improving robustness.3 3.4 Guest and Host Registers \nValgrind itself runs on the machine s real or host CPU, and (con\u00adceptually) runs the client program on \na simulated or guest CPU. We refer to registers in the host CPU as host registers and those of the simulated \nCPU as guest registers. Due to the dynamic binary recompilation process, a guest register s value may \nreside in one of the host s registers, or it may be spilled to memory for a variety of reasons. Shadow \nregisters are shadows of guest registers. Valgrind provides a block of memory per client thread called \nthe ThreadState. Each one contains space for all the thread s guest and shadow registers and is used \nto hold them at various times, in particular between each code block. Storing guest registers in memory \nbetween code blocks sounds like a bad idea at .rst, be\u00adcause it means that they must be moved between \nmemory and the host registers frequently, but it is reasonable for heavyweight tools with high host register \npressure for which the bene.ts of a more optimistic strategy are greatly diminished. 3.5 Representation \nof code: D&#38;R vs. C&#38;A There are two fundamental ways for a DBI framework to represent code and \nallow instrumentation. Valgrind uses disassemble-and-resynthesise (D&#38;R): machine code is converted \nto an IR in which each instruction becomes one or more IR operations. This IR is instrumented (by adding \nmore IR) and then converted back to machine code. All of the original code s effects on guest state (e.g. \ncondition code setting) must be explicitly represented in the IR because the original client instructions \nare discarded and the .nal code is generated purely from the IR. Valgrind s use of D&#38;R is the single \nfeature that most distinguishes it from other DBI frameworks. Other DBI frameworks use copy-and-annotate \n(C&#38;A): incom\u00ading instructions are copied through verbatim except for necessary control .ow changes. \nEach instruction is annotated with a descrip\u00adtion of its effects, via data structures (e.g. DynamoRIO) \nor an instruction-querying API (e.g. Pin). Tools use the annotations to guide their instrumentation. \nThe added analysis code must must be interleaved with the original code without perturbing its effects. \nHybrid approaches are possible. For example, earlier versions of Valgrind used D&#38;R for integer instructions \nand C&#38;A for FP and SIMD instructions (this was more by accident than design). Vari\u00adations are also \npossible; for example, DynamoRIO allows instruc\u00adtion bytes to be modi.ed in-place before being copied \nthrough. Each approach has its pros and cons, depending on the instru\u00admentation requirements. D&#38;R \nmay require more up-front design and implementation effort, because a D&#38;R representation is ar\u00adguably \nmore complex. Also, generating good code at the end re\u00adquires more development effort Valgrind s JIT \nuses a lot of con\u00adventional compiler technology. In contrast, for C&#38;A, good client code stays good \nwith less effort. A D&#38;R JIT compiler will proba\u00adbly also translate code more slowly. D&#38;R may \nnot suitable for some tools that require low-level in\u00adformation. For example, the exact opcode used by \neach instruc\u00ad 3 For example, Valgrind no longer uses the standard C library, but has a small version \nof its own. This has avoided any potential complications caused by having two copies of the C library \nin the address space one for the client, and and for Valgrind and the tool. It also made the AIX port \nmuch easier, because AIX s C library is substantially different to Linux s. tion may be lost. IR annotations \ncan help, however for example, Valgrind has marker statements that indicate the boundaries, ad\u00addresses \nand lengths of original instructions. C&#38;A can suffer the same problem if the annotations are not \ncomprehensive. D&#38;R s strengths emerge when complex analysis code must be added. First, D&#38;R s \nuse of the same IR for both client and analysis code guarantees that analysis code is as expressive and \npowerful as client code. Making all side-effects explicit (e.g. condition code computations) can make \ninstrumentation easier. The performance dynamics also change. The JIT compiler can optimise analysis \ncode and client code equally well, and naturally tightly interleaves the two. In contrast, C&#38;A must \nprovide a sep\u00adarate way to describe analysis code (so C&#38;A requires some kind of IR after all). This \ncode must then be .tted around the original instructions, which requires effort (either by the framework \nor the tool-writer) to do safely and with good performance. For example, Pin analysis code is written \nas C functions (i.e. the analysis code IR is C), which are compiled with an external C compiler, and \nPin then inlines them if possible, or inserts calls to them. Finally, D&#38;R is more veri.able any error \nconverting machine code to IR is likely to cause visibly wrong behaviour, whereas a C&#38;A annotation \nerror will result in incorrect analysis of a correctly behaving client.4 D&#38;R also permits binary \ntranslation from one platform to another (although Valgrind does not do this). D&#38;R also allows the \noriginal code s behaviour to be arbitrarily changed. In summary, D&#38;R requires more effort up-front \nand is overkill for lightweight instrumentation. However, it naturally supports heavyweight instrumentation \nsuch as that required by shadow value tools, and so is a natural .t for Valgrind. 3.6 Valgrind s IR \nPrior to version 3.0.0 (August 2005), Valgrind had an x86-speci.c, part D&#38;R, part C&#38;A, assembly-code-like \nIR in which the units of translation were basic blocks. Since then Valgrind has had an architecture-neutral, \nD&#38;R, single-static-assignment (SSA) IR that is more similar to what might be used in a compiler. \nIR blocks are superblocks: single-entry, multiple-exit stretches of code. Each IR block contains a list \nof statements, which are opera\u00adtions with side-effects, such as register writes, memory stores, and assignments \nto temporaries. Statements contain expressions, which represent pure (no side effects) values such as \nconstants, register reads, memory loads, and arithmetic operations. For example, a store statement contains \none expression for the store address and another for the store value. Expressions can be arbitrarily \ncompli\u00adcated trees (tree IR), but they can also be .attened by introducing statements that write intermediate \nvalues to temporaries (.at IR). The IR has some RISC-like features: it is load/store, each primi\u00adtive \noperation only does one thing (many CISC instructions are bro\u00adken up into multiple operations), and when \n.attened, all operations operate only on temporaries and literals. Nonetheless, supporting all the standard \ninteger, FP and SIMD operations of different sizes requires more than 200 primitive arithmetic/logical \noperations. The IR is architecture-independent. Valgrind handles unusual architecture-speci.c instructions, \nsuch as cpuid on x86, with a call to a C function that emulates the instruction. These calls have annotations \nthat say which guest registers and memory locations they access, so that a tool can see some of their \neffects while avoiding the need for Valgrind to represent the instruction explicitly in the IR. This \nis another case (like the marker statements) where Valgrind uses IR annotations to facilitate instrumentation \n(but it is not C&#38;A, because the instruction is emulated, not copied through). 4 This is not just \na theoretical concern. Valgrind s old IR used C&#38;A for SIMD instructions; some SIMD loads were mis-annotated \nas stores, and some SIMD stores as loads, for more than a year before being noticed. 0x24F275: movl -16180(%ebx,%eax,4),%eax \n1: ------IMark(0x24F275, 7) -----\u00ad 2: t0 = Add32(Add32(GET:I32(12),# get %ebx and Shl32(GET:I32(0),0x2:I8)), \n# %eax, and 0xFFFFC0CC:I32) # compute addr 3: PUT(0) = LDle:I32(t0) # put %eax 0x24F27C: addl %ebx,%eax \n4: ------IMark(0x24F27C, 2) -----\u00ad 5: PUT(60) = 0x24F27C:I32 # put %eip 6: t3 = GET:I32(0) # get %eax \n7: t2 = GET:I32(12) # get %ebx 8: t1 = Add32(t3,t2) # addl 9: PUT(32) = 0x3:I32 # put eflags val1 10: \nPUT(36) = t3 # put eflags val2 11: PUT(40) = t2 # put eflags val3 12: PUT(44) = 0x0:I32 # put eflags \nval4 13: PUT(0) = t1 # put %eax 0x24F27E: jmp*l %eax 14: ------IMark(0x24F27E, 2) -----\u00ad 15: PUT(60) \n= 0x24F27E:I32 # put %eip 16: t4 = GET:I32(0) # get %eax 17: goto {Boring} t4 Figure 1. Disassembly: \nmachine code . tree IR 3.7 Translating a Single Code Block Valgrind translates code blocks on demand. \nTo create a translation of a code block, Valgrind follows instructions until one of the following conditions \nis met: (a) an instruction limit is reached (about 50, depending on the architecture), (b) a conditional \nbranch is hit, (c) a branch to an unknown target is hit, or (d) more than three unconditional branches \nto known targets have been hit. This policy is less sophisticated than those used by frameworks like \nPin and DynamoRIO; in particular, Valgrind does not recompile hot code. There are eight translation phases. \nThis high number is a con\u00adsequence of Valgrind using D&#38;R. They are described by the fol\u00adlowing paragraphs. \nAll phases are performed by the core, except instrumentation, which is performed by the tool. Phases \nmarked with a * are architecture-speci.c. Phase 1. Disassembly*: machine code . tree IR. The disas\u00adsembler \nconverts machine code into (unoptimised) tree IR. Each instruction is disassembled independently into \none or more state\u00adments. These statements fully update the affected guest registers in memory: guest \nregisters are pulled from the ThreadState into tem\u00adporaries, operated on, and then written back. Figure \n1 gives an example for x86 machine code. Three x86 instructions are disassembled into 17 tree IR statements. \n Statements 1, 4 and 14 are IMarks: no-ops that indicate where an instruction started, its address and \nlength in bytes. These are used by pro.ling tools that need to see instruction boundaries.  Statement \n2 assigns an expression tree to a temporary t0;it shows how a CISC instruction can become multiple operations \nin the IR. GET:I32 fetches a 32-bit integer guest register from the ThreadState; the offsets 12 and 0 \nare for guest registers %ebx and %eax. Add32 is a 32-bit add, Shl32 is a 32-bit left-shift. Statement \n16 is a simpler assignment.  Statement 3 writes a guest register (%eax) value back to its slot in the \nThreadState (the LDle is a little-endian load). State\u00adments 5 and 15 update the guest program counter \n(%eip)in the ThreadState.  Statements 9 12 write four values to the ThreadState. Many x86 instructions \naffect the condition codes (%eflags), and Val\u00adgrind computes them from these four values when they are \nused. Often %eflags is clobbered without being used, so most of these PUTs can be optimised away later. \nDBI frameworks that use C&#38;A do not synthesise the condition codes like this, but instead obtain them \nfor free as a side-effect of running the code. But when heavyweight analysis code is added they must \nbe saved and restored frequently, which involves expen\u00adsive instructions on x86. In contrast, Valgrind \ns approach is more costly to begin with, but does not degrade badly in such cases. Also, knowing precisely \nthe operation and operands most recently used to set the condition codes is helpful for some tools. For \nexample, Memcheck s de.nedness tracking of condi\u00adtion codes was less accurate with with Valgrind s old \nIR, which used C&#38;A for %eflags.  Statement 17 is an unconditional jump to the address in t4.  Phase \n2. Optimisation 1: tree IR . .at IR. The .rst optimisa\u00adtion phase .attens the IR and does several optimisations: \nredundant get and put elimination (to remove unnecessary copying of guest registers to/from the ThreadState), \ncopy and constant propagation, constant folding, dead code removal, common sub-expression elim\u00adination, \nand even simple loop unrolling for intra-block loops. It is also possible to pass in callback functions \nthat can partially eval\u00aduate certain platform-speci.c C helper calls. On x86 and AMD64 this is used to \noptimise the %eflags handling. This phase updates the IR shown in Figure 1 in several ways. The complex \nexpression tree in statement 2 is .attened into .ve assignments to temporaries: two using GET,two using \nAdd32, one using Shl32.  Statement 3 is changed from a PUT to an assignment to a temporary; this is \npossible because the PUT is made redundant by the PUT in statement 13.  Statement 5 is removed. This \nis possible because statement 15 writes a new value for %eip and there are no intervening statements \nthat could cause a memory exception (if there were, it could not be removed because a guest signal handler \nthat inspects the %eip value in the ThreadState could be invoked).  Statements 6, 7 and 16 are removed, \nbecause they are made redundant by the GET statements introduced by the .attening of statement 2.  Phase \n3. Instrumentation: .at IR . .at IR. The code block is then passed to the tool, which can transform it \narbitrarily. It is im\u00adportant that the IR is .attened at this point as it makes instrumen\u00adtation easier, \nparticularly for shadow value tools. Figure 2 shows IR for the movl instruction from Figure 1 af\u00adter \nit has been instrumented by Memcheck. Memcheck s shadow values track the de.nedness of values; its instrumentation \nhas been described previously [25] and the details are beyond the scope of this paper. However, we make \nthe following observations. Of the 18 statements, 11 were added by Memcheck the added analysis code \nis larger and more complex than the original code.  Shadow registers are stored in the ThreadState just \nlike guest registers. For example, guest register %eax is stored at offset 0 in the ThreadState, and \nits shadow is stored at offset 320.  Every operation involving guest values is preceded by a corre\u00adsponding \noperation on shadow values.  In some cases the shadow operation is a single statement,  e.g. statements \n2, 4 and 6. Even without understanding how Memcheck works it is easy to see what they are doing. For \nex\u00ad * 1: ------IMark(0x24F275, 7) -----\u00ad 2: t11 = GET:I32(320) # get sh(%eax) * 3: t8 = GET:I32(0) # \n*get %eax 4: t14 = Shl32(t11,0x2:I8) # shadow shll * 5: t7 = Shl32(t8,0x2:I8) # *shll 6: t18 = GET:I32(332) \n# get sh(%ebx) * 7: t9 = GET:I32(12) # *get %ebx 8: t19 = Or32(t18,t14) # shadow addl 1/3 9: t20 = Neg32(t19) \n# shadow addl 2/3 10: t21 = Or32(t19,t20) # shadow addl 3/3 *11: t6 = Add32(t9,t7) # *addl 12: t24 = \nNeg32(t21) # shadow addl 1/2 13: t25 = Or32(t21,t24) # shadow addl 2/2 *14: t5 = Add32(t6,0xFFFFC0CC:I32) \n# *addl 15: t27 = CmpNEZ32(t25) # shadow loadl 1/3 16: DIRTY t27 RdFX-gst(16,4) RdFX-gst(60,4) ::: helperc_value_check4_fail{0x380035f4}() \n# shadow loadl 2/3 17: t29 = DIRTY 1:I1 RdFX-gst(16,4) RdFX-gst(60,4) ::: helperc_LOADV32le{0x38006504}(t5) \n# shadow loadl 3/3 *18: t10 = LDle:I32(t5) # *loadl Figure 2. Instrumented .at IR. The statements that \nwere present before instrumentation took place are pre.xed with a * . ample, when the original code GETs \n%eax from the ThreadState into a temporary, the analysis code GETs the shadow of %eax from the ThreadState \ninto another temporary. In some cases the shadow operation is larger than the original operation, as \nseen in statements 8 10 and 12 13. The shadow load operation in statements 15 17 is larger still. Statement \n15 tests the de.nedness of the pointer value by comparing its shadow value to zero, and statement 16 \nis a conditional call (conditional on the value in t27) to an error-reporting function that is only called \nif the test fails, i.e. if the load uses an address value that is not fully de.ned. (The DIRTY and RdFX \nannotations indicate that some guest registers are read from the ThreadState by the function, and so \nthese values must be up-to-date. 0x380035f4 is the address of the called function.) Statement 17 calls \nanother C function, helperc_LOADV32le, which does a shadow load to complement the original load in statement \n18. The shadow load is implemented using a C function because it is too complex to be written inline \n[19]. Phase 4. Optimisation 2: .at IR . .at IR. A second, simpler op\u00adtimisation pass performs constant \nfolding and dead code removal. Figure 2 is a case in point it actually shows the instrumented code after \nthis second optimisation phase is run (which reduced it from 48 statements to 18). This optimisation \nmakes life easier for tools by allowing them to be somewhat simple-minded, knowing that the code will \nbe subsequently improved. Phase 5. Tree building: .at IR . tree IR. The tree builder con\u00adverts .at IR \nback to tree IR in preparation for instruction selection. Expressions assigned to temporaries which are \nused only once are usually substituted into the temporary s use point, and the assign\u00adment is deleted. \nThe resulting code may perform loads in a different order to the original code, but loads are never moved \npast stores. Phase 6. Instruction selection*: tree IR . instruction list. The instruction selector converts \nthe tree IR into a list of instructions which use virtual registers (except for those instructions that \nare hard-wired to use particular registers; these are common on x86 and AMD64). The instruction selector \nuses a simple, greedy, top\u00addown tree-matching algorithm. --t21 = Or32(t19,Neg32(t19)) movl %%vr19,%%vr41 \nmovl %edx,%edi negl %%vr41 negl %edi movl %%vr19,%%vr40 orl %%vr41,%%vr40 orl %edi,%edx movl %%vr40,%%vr21 \n Figure 3. Register allocation, before and after. Virtual registers are named %%vrNN. Phase 7. Register \nallocation: instruction list . instruction list. The linear-scan register allocator [26] replaces virtual \nregisters with host registers, inserting spills as necessary. One general-purpose host register is always \nreserved to point to the ThreadState. Although the instructions are platform-speci.c, the register al\u00adlocator \nis platform-independent; it uses some callback functions to .nd out which registers are read and written \nby each instruction. Figure 3 shows an example of register allocation. The statement at the top is created \nby the tree builder from statements 9 and 10 in Figure 2. The .gure shows that the register allocator \ncan remove many register-to-register moves, which makes life easier for the instruction selector. Phase \n8. Assembly*: instruction list . machine code. The .nal assembly phase simply encodes the selected instructions \nappropri\u00adately and writes them to a block of memory. 3.8 Storing Translations Valgrind s code storage \nsystem is simple and warrants only a brief description. Translations are stored in the translation table,a \n.xed\u00adsize, linear-probe hash table. The translation table is large (about 400,000 entries) so it rarely \ngets full. If the table gets more than 80% full, translations are evicted in chunks, 1/8th of the table \nat a time, using a FIFO (.rst-in, .rst-out) policy this was chosen over the more obvious LRU (least recently \nused) policy because it is simpler and it still does a fairly good job. Translations are also evicted \nwhen code in shared objects is unloaded (by munmap), or made obsolete by self-modifying code (see Section \n3.16). 3.9 Executing Translations Once a translation is made it can be executed. What happens be\u00adtween \ncode blocks? Control .ows from one translation to the next via one of two routes: the dispatcher (fast), \nor the scheduler (slow). At a translation s end, control falls back to the dispatcher, a hand-crafted \nassembly code loop. At this point all guest registers are in the ThreadState. Only two host registers \nare live: one holds the guest program counter, and the other holds a value that is only used for unusual \nevents, explained shortly, when control must fall back into the scheduler. The dispatcher looks for the \nappropriate translation in a small direct-mapped cache which holds addresses of recently-used translations. \nIf that look-up succeeds (the hit-rate is around 98%), the translation is executed immediately. This \nfast case takes only fourteen instructions on x86. When the fast look-up fails, control falls back to \nthe scheduler, which is written in C. It searches the full translation table. If a translation is not \nfound, a new translation is made. In either case, the direct-mapped cache is updated to store the translation \naddress for the code block. The dispatcher is re-entered, and the fast direct\u00admapped look-up will this \ntime de.nitely succeed. There are certain unusual events upon which control falls back to the scheduler. \nFor example, the core periodically checks whether a thread switch is due (see Section 3.14) or whether \nthere are any outstanding signals to be handled (see Section 3.15). To support this, the dispatcher causes \ncontrol to fall out to the scheduler every few thousand translation executions. Control is similarly \nreturned to the scheduler when system calls (see Section 3.10) and client requests (see Section 3.11) \noccur. Valgrind does not perform chaining (also known as linking) a technique that patches branch instructions \nin order to link trans\u00adlations directly, which avoids many visits to the dispatcher. Ear\u00adlier versions \ndid, but it has not yet been implemented in the new JIT compiler. The lack of chaining hurts Valgrind \ns speed less than for other DBI frameworks; we believe this is because Valgrind s dispatcher is fast,5 \nand Valgrind chases across many unconditional branches. 3.10 System Calls Valgrind cannot trace into \nthe kernel. When a system call happens, control falls back into the scheduler, which: (a) saves the tool \ns stack pointer; (b) copies the guest registers into the host registers, except the program counter; \n(c) calls the system call; (d) copies the guest registers back out to memory, except the program counter; \n(e) restores the tool s stack pointer. Note that the system call is run on the client s stack, as it \nshould be (the host stack pointer normally points to the tool s stack). System calls involving partitioned \nresources such as memory (e.g. mmap) and .le descriptors (e.g. open) are pre-checked to ensure they do \nnot cause con.icts with the tool. For example, if the client tries to mmap memory currently used by the \ntool, Valgrind will make it fail without even consulting the kernel. 3.11 Client Requests Valgrind s \ncore has a simple trap-door mechanism that allows a client program to pass messages and queries, called \nclient requests, to the core or a tool plug-in. Client requests are embedded in client programs using \npre-de.ned macros from a header .le provided by Valgrind. The mechanism is described in previous publications \nabout Valgrind [18, 15] and so we omit the details here. We will see in Sections 3.12 and 3.16 examples \nof the use of client requests. 3.12 The Events System Valgrind s IR is expressive, but fails to describe \nto tools certain changes to guest register and memory state done by clients. It also does not convey \nany details of memory allocations and dealloca\u00adtions. Valgrind provides an events system to describe \nsuch changes. Let us .rst consider the accesses done by system calls. All sys\u00adtem calls access registers: \nthey read their arguments from registers and/or memory, and they write their return value to a register. \nMany system calls also access user-mode memory via pointer arguments, e.g. settimeofday is passed pointers \nto two structs which it reads from, and gettimeofday .lls in two structs with data. Knowing which registers \nand memory locations are accessed by every sys\u00adtem call is dif.cult because there are many system calls \n(around 300 for Linux), some of which have tens or hundreds of sub-cases, and there are many differences \nacross platforms. Several things must be known for each system call: how many arguments it takes, each \nargument s size, which ones are pointers (and which of those can be NULL), which ones indicate buffer \nlengths, which ones are null\u00adterminated strings, which ones are not read in certain cases (e.g. the third \nargument of open is only read if the second argument has cer\u00adtain values), and the sizes of various types \n(e.g. struct timeval used by gettimeofday and settimeofday). Valgrind does not encode this information \nabout system calls in its IR, because there are too many system calls and too much variation across platforms \nto do so cleanly. Instead it provides the events system to inform tools about register and memory accesses \n5 In comparison, chaining improved Strata s basic slow-down factor from 22.1x to 4.1x, because dispatching \ntakes about 250 cycles [24]. Valgrind s slow-down even without chaining is 4.3x. that are not directly \nvisible from the IR. For each event, a tool can register a callback function to be called each time the \nevent occurs. The events list is given in Table 1. A tool can use the pre_* events to know when system \ncalls are about to read registers and memory locations, and the post_* events to know when to update \nthe shadow state after system calls have written new values. The register events pass to their callbacks \nthe size of the accessed register and its offset in the ThreadState; the memory events pass in the address \nand size of the accessed memory region. How are these six events triggered? Valgrind provides a wrapper \nfor every system call, which invokes these callbacks as needed. Every system call has different arguments \nand thus a different wrapper. Because there are so many cases, Valgrind s wrappers are almost 15,000 \nlines of tedious C code (in Valgrind 3.2.1), partly generic, partly platform-speci.c, aggregated over \nseveral years of development. In comparison, Memcheck is 10,509 lines of code. The wrappers save a great \ndeal of work for tools that need to know about system call accesses, and also make the system call handling \nplatform-independent for tools. No other DBI framework has such system call wrappers. This mechanism \nis crucial for many shadow value tools. For ex\u00adample, Memcheck critically relies on it for its bit-precise \nde.ned\u00adness tracking. Indeed, several bugs in Valgrind s wrappers were found because they caused Memcheck \nto give false positives or false negatives. A similar case involves stack allocations and deallocations. \nA tool could detect them just by detecting changes to the stack pointer from the IR. However, because \nit is a common requirement, Val\u00adgrind provides events (new_mem_stack and die_mem_stack)for these cases. \nThe core instruments the code with calls to the event callbacks on the tool s behalf. This makes things \neasier for tools. It also provides a canned solution to a tricky part of the problem as Section 2 noted, \nit is hard to distinguish large stack alloca\u00adtions and deallocations from stack-switches, but doing so \nis vital for some shadow value tools. Valgrind (and hence tools using the stack events) uses a heuristic: \nif the stack pointer changes by more than 2MB, a stack switch has occurred. The 2MB value is change\u00adable \nwith a command line option. Sometimes this heuristic is too crude, so Valgrind also provides three client \nrequests which let the client register, de-register and resize stacks with Valgrind. So even in tricky \ncases, with a small amount of help from the programmer all stack switches can be detected. The remaining \nevents in Table 1 inform tools about allocations done at program start-up and via system calls. 3.13 \nFunction Replacement and Function Wrapping Valgrind supports function replacement, i.e. it allows a tool \nto replace any function in a program with an alternative function. A replacement function can also call \nthe function it has replaced. This allows function wrapping, which is particularly useful for inspecting \nthe arguments and return value of a function.  3.14 Threads Threads pose a particular challenge for \nshadow value tools. The reason is that loads and stores become non-atomic: each load/store translates \ninto the original load/store plus a shadow load/store. On a uni-processor machine, a thread switch might \noccur between these two operations. On a multi-processor machine, concurrent memory accesses to the same \nmemory location may complete in a different order to their corresponding shadow memory accesses. It is \nunclear how to best deal with this, as a .ne-grained locking approach would likely be slow. To sidestep \nthis problem, Valgrind serialises thread execution with a thread locking mechanism. Only the thread holding \nthe lock can run, and threads drop the lock before they call a blocking Req. Valgrind events Called \nfrom Memcheck callbacks R4 pre_reg_read, post_reg_write pre_mem_read{,_asciiz}pre_mem_write, post_mem_write \nEvery system call wrapper Many system call wrappers Many system call wrappers check_reg_is_defined, make_reg_defined \ncheck_mem_is_defined{,_asciiz}check_mem_is_addressable, make_mem_defined R5 new_mem_startup Valgrind \ns code loader make_mem_defined R6 new_mem_mmap, die_mem_munmap mmap wrapper, munmap wrapper make_mem_defined, \nmake_mem_noaccess new_mem_brk, die_mem_brk brk wrapper make_mem_undefined, make_mem_noaccess copy_mem_mremap \nmremap wrapper copy_range R7 new_mem_stack, die_mem_stack Instrumentation of SP changes make_mem_undefined, \nmake_mem_noaccess Table 1. Valgrind events, their trigger locations, and Memcheck s callbacks for handling \nthem. system call,6 or after they have been running for a while (100,000 code blocks). The lock is implemented \nusing a pipe which holds a single character; each thread tries to read the pipe, only one thread will \nbe successful, and the others will block until the running thread relinquishes the lock by putting a \ncharacter back in the pipe. Thus the kernel still chooses which thread is to run next, but Valgrind dictates \nwhen thread-switches occur and prevents more than one thread from running at a time. This is the third \nthread serialisation mechanism that has been used in Valgrind, and is by far the most robust. The .rst \none [18, 15] involved Valgrind providing a serialised version of the libpthread library. This only worked \nwith programs using pthreads. It also caused many problems because on Linux systems, glibc and the pthreads \nlibrary are tightly bound and interact in various ways un\u00adder the covers that are dif.cult to replicate.7 \nThe second one was more like the current one, but was more complex, requiring extra kernel threads to \ncope with blocking I/O. This serialisation is a unique Valgrind feature not shared by other DBI frameworks. \nIt has both pros and cons: it means that Val\u00adgrind tools using shadow memory can ignore the atomicity \nissue. However, as multi-processor machines become more popular, the resulting performance shortcomings \nfor multi-threaded programs will worsen. How to best overcome this problem remains an open research question. \n 3.15 Signals Unix signal handling presents a problem for all DBI frameworks when an application sets \na signal handler, it is giving the kernel a callback (code) address in the application s space which \nwill be used to deliver the signal. This would allow the client s original handler code to be executed \nnatively. Even worse, if the handler did not return but instead did a longjmp, the tool would permanently \nlose control. Therefore, Valgrind intercepts all system calls that register signal handlers. It also \ncatches all signals and delivers them appropriately to the client. This standard technique is tedious \nbut unavoidable. Also, Valgrind takes advantage of it to ensure that asynchronous signals are delivered \nonly between code blocks, and can thus never separate loads/stores from shadow loads/stores. 3.16 Self-modifying \nCode Self-modifying code is always a challenge for DBI frameworks. On architectures such as PowerPC it \nis easy to detect because an explicit .ush instruction must be used when code is modi.ed, but the x86 \nand AMD64 architectures do not have this feature. Therefore, Valgrind has a mechanism to handle self-modifying \ncode. A code block using this mechanism records a hash of the original code it was derived from. Each \ntime the block executes, 6 Thus kernel code can run in parallel with user code. This is allowable because \nthe kernel code does not affect shadow memory. 7 This is another example where avoiding dependencies \non other software improved robustness. the hash is recomputed and checked, and if it does not match, \nthe block is discarded and the code retranslated. This has a high run-time cost. Therefore, by default \nValgrind only uses this mechanism for code that is on the stack. This is enough to handle the trampolines \nthat some compilers (e.g. GCC) put on the stack when running nested functions, which we have found to \nbe the main cause of self-modifying code.8 This minimises the cost, as only code on the stack is slowed \ndown. The mechanism can also be turned off altogether or turned on for every block. Valgrind also provides \nanother mechanism for handling self\u00admodifying code a client request which tells it to discard any translations \nof instructions in a certain address range. It is most useful for dynamic code generators such as JIT \ncompilers.  4. Valgrind s Shadow Value Support This section describes how the features described in \nthe previous section support all nine shadow value requirements. Because these requirements are a superset \nof most DBA tools requirements, Valgrind supports most conceivable DBA tools. R1: Provide shadow registers. \nValgrind has three noteworthy features that make shadow registers easy to use. First, shadow registers \nare .rst-class entities: (a) space is provided for them in the ThreadState, (b) they can be accessed \njust as easily as guest registers, (c) they can be manipulated and operated on in the same ways. This \nmakes complex shadow operations code natural and easy to write, even those involving FP and SIMD registers. \nSecond, the IR provides an unlimited supply of temporaries in which guest registers, shadow registers, \nand intermediate values can be manipulated. This is invaluable for ease-of-use because shadow operations \ncan introduce many extra intermediate values. Third, the IR s RISC-ness exposes all implicit intermediate \nvalues, such as those computed by complex addressing modes, which can make instrumentation easier, particularly \non a CISC architecture like x86. Fourth, all code is treated equally. Shadow operations bene\u00ad.t fully \nfrom Valgrind s post-instrumentation IR optimiser and in\u00adstruction selector. This makes them easy to \nwrite, because one can rely on obvious redundancies being optimised away. This is a con\u00adsequence of using \nD&#38;R. This third feature is also crucial for performance, because it means that client code and analysis \ncode can be interleaved arbi\u00adtrarily by the back-end. For example, Valgrind s register allocator works \nwith guest and shadow registers equally to minimise spilling. Also, no special tricks are required to \nprevent analysis code from perturbing condition codes, because they are already computed ex\u00adplicitly \nrather than as a side-effect of client code. R2: Provide shadow memory. Valgrind provides no overt sup\u00adport \nfor shadow memory, such as built-in data structures, because 8 Ada programs use them particularly often, \nand Valgrind was more or less unusable with Ada programs until this was implemented. shadow memory varies \nenough from tool to tool [19] that it is dif\u00ad.cult to factor out any common supporting operations. However, \nValgrind does provide two crucial features to avoid problems with the non-atomicity of loads/stores and \nshadow loads/stores: its seri\u00adalisation of threads, and its guaranteed delivery of asynchronous signals \nonly between code blocks. Together they allow shadow value tools to run any multi-threaded program correctly \nand ef.\u00adciently on uni-processors, and correctly on multi-processors, with\u00adout any need for shadow memory \nlocking. R3: Instrument read/write instructions. Valgrind supports this requirement all reads and writes \nof registers and memory are vis\u00adible in the IR and instrumentable. The IR s load/store nature makes instrumentation \nof memory accesses particularly easy. Also, the splitting of complex CISC instructions into multiple \ndistinct opera\u00adtions helps some tools, e.g. by exposing intermediate values such as addresses computed \nwith complex addressing modes, and making condition code computations explicit. Again, this is a consequence \nof using D&#38;R. As for the added analysis code: the ability to write it as inline IR helps with ef.ciency \nand ensures that analysis code is as expressive (e.g. can use FP and SIMD operations) as client code; \nthe ability to write it in separate C functions also allows more complex analysis code to be written \neasily. R4 R7. These requirements (instrument read/write system calls, instrument start-up allocations, \ninstrument system call (de)allocations, and instrument stack (de)allocations) are all supported by Val\u00adgrind \ns events system. The left-most column of Table 1 shows which events are used for each requirement. R8: \nInstrument heap (de)allocations. Valgrind does not track heap allocations and deallocations with its \nevents system. (It could, this is due to historical reasons.) Instead, tools that need to track these \nevents can use function wrappers or function replacements for the relevant functions (e.g. malloc, free). \nR9: Extra Output. Valgrind allows a shadow value tool to print error messages during execution and at \ntermination using its I/O routines, which send output to a .le descriptor (stderr by default), .le, or \nsocket, as speci.ed by a command line option. Tools can also write additional data to .les. Valgrind \nprovides other useful output-related services: error recording, the ability to suppress (ig\u00adnore) uninteresting/un.xable \nerrors via suppressions listed in .les, stack tracing, and debug information reading.  5. Evaluation \nWe now quantify how easy it is to write Valgrind tools, discuss their robustness and capabilities, and \nmeasure their performance. 5.1 Tool-writing Ease We can use code sizes to roughly measure the amount \nof effort that went into Valgrind s core and various tools. In Valgrind 3.2.1, the core contains 170,280 \nlines of C and 3,207 lines of assembly code (including comments and blank lines). In comparison, Memcheck \ncontains 10,509 lines of C, Cachegrind (a cache pro.ler) is 2,431 lines of C, Massif (a heap pro.ler) \nis 1,764, and Nulgrind (the null tool that adds no analysis code) is 39. Even though lines of code is \nnot a good measure of coding effort, the bene.t of using Valgrind is clear, compared to writing a new \ntool from scratch. Having said that, heavyweight tools like Memcheck are still not trivial to write, \nand require a reasonable amount of code. Valgrind s use of D&#38;R can make simple tools more dif.cult \nto write than in C&#38;A frameworks. For example, a tool that traces memory accesses would be about 30 \nlines of code in Pin, and about 100 in Valgrind. However, in our experience, for the most interest\u00ading \ntools most of the development effort goes not into extracting ba\u00adsic data (such as run-time addresses \nand values), but into analysing and presenting that data in useful ways to the user it makes lit\u00adtle \ndifference whether it takes 30 lines or 100 lines of code to ex\u00adtract a memory access trace if a tool \ncontains 2,000 lines devoted to analysing it. In contrast, for heavyweight tools D&#38;R makes instrumentation \neasier for tools like Memcheck because of the reasons explained in Sections 3.5 and 4. 5.2 Tool Robustness \nBy robustness , we mean how many different programs a tool can correctly run. For tools built with DBI \nframeworks, this covers both the framework and the tool it is possible to build a non-robust tool on \ntop of a robust framework. Robustness is not easy to quantify. We provide anecdotal ev\u00adidence for the \nrobustness of Valgrind and Memcheck: their large number of users; and the range of programs with which \nthey have been successfully used; the range of platforms they support; and some design decisions we have \nmade to improve robustness. Valgrind has become a standard C and C++ development tool on Linux. Memcheck \nis the most popular Valgrind tool, accounting for about 80% of all Valgrind tool use [27]. The Valgrind \nwebsite [28] averages more than 1,000 unique visitors per day. Valgrind tools are used by the developers \nof many large projects, such as Firefox, OpenOf.ce, KDE, GNOME, Qt, libstdc++, MySQL, Perl, Python, PHP, \nSamba, RenderMan, and Unreal Tournament.9 They have successfully been used on a wide range of different \nsoftware types, implemented using many different languages and compilers, on programs containing up to \n25 million lines of code. They also successfully handle multi-threaded programs. Valgrind and Memcheck \nrun on multiple platforms, 32-bit and 64-bit: x86/Linux, AMD64/Linux, and PPC{32,64}/{Linux,AIX}. There \nare also experimental ports to x86/MacOS X, x86/FreeBSD, and x86/Solaris. We believe Valgrind is suitable \nfor porting to any typical RISC or CISC architecture, such as ARM or SPARC. VLIW architectures such as \nIA64 would be possible but Valgrind s use of D&#38;R would make reasonable performance harder to attain, \nas VLIW code generation is more dif.cult. We also believe it can be ported to any Unix-style OS; a port \nto Windows may be possible but would be much more challenging. Porting to a new architecture requires \nwriting new code for the JIT compiler, such as an instruc\u00adtion encoder and decoder, and code to describe \nthe new machine state (i.e. register layout). Porting to a new OS requires some new code for handling \ndetails such as signals and address space manage\u00adment. Porting to a new architecture and/or OS requires \nsome new system call wrappers to be written. Memcheck (and other shadow value tools) usually do not need \nto be changed if Valgrind is ported to new platforms. The robustness of Valgrind and Memcheck has slowly \nimproved over time. Earlier sections of this paper showed that several Val\u00adgrind sub-systems have been \nre-implemented once or twice in an effort to make them more robust. Also, we have gradually removed all \ndependencies on external libraries, even the C library. Indeed, since mid-2005 Valgrind has been able \nto run itself, which is no mean feat considering how many strange things it does. 9 The SPEC benchmarks \nare sometimes used as a measure of robustness. They are actually not particularly dif.cult to run they \nstress a DBA tool s code generation well, but they are all single-threaded, compute-bound, not particularly \nlarge, do not use many system calls, and do not do tricky things with memory layout or signals. The large \nprojects listed above stress a DBA tool much more than the SPEC benchmarks. 5.3 Tool Instrumentation \nCapabilities In this section, we compare Valgrind s support for all nine shadow value requirements against \nPin [11], because Pin is the best known of the currently available DBI frameworks, and the one that has \nthe most support for shadow values (after Valgrind). The following comparison is based on discussions \nwith two Pin developers [10]. Pin supports R5 (instrument start-up allocations), R8 (instru\u00adment heap \n(de)allocations) and R9 (extra output) directly. It does not support R6 (instrument system call (de)allocations) \nand R7 (in\u00adstrument stack (de)allocations) directly, but provides features that allow a Pin tool to manually \nsupport them fairly easily. For R1 (provide shadow registers) Pin provides virtual regis\u00adters which are \nregister-allocated along with guest registers and saved in memory when a thread is not running. Shadow \nregisters could be stored in them. However, virtual registers are not fully .rst-class citizens. For \nexample, there are no 128-bit virtual regis\u00adters, so 128-bit SIMD registers cannot be fully shadowed, \nwhich would prevent some tools (e.g. Memcheck) from working fully. Pin provides no built-in support for \nR2 (provide shadow mem\u00adory), so tools must cope with the non-atomicity of loads/stores and shadow loads/stores \nthemselves.10 For example, the Pin tool called pinSEL [14], which uses shadow memory but not full shadow \nval\u00adues, sets and checks an extra interference bit on every shadow load. This lets it handle any thread \nswitches or asynchronous signals that occur between a load/store and a shadow load/store (both of which \ncan occur even on uni-processors under Pin). Multi-threaded pro\u00adgrams running on multi-processors are \neven trickier, and pinSEL does not handle them. In comparison, Valgrind s thread serialisa\u00adtion and asynchronous \nsignal treatment frees shadow value tools from having to deal with this issue. For R3 (instrument read/write \ninstructions) Pin allows all regis\u00adter and memory accesses to be seen. However, analysis code in Pin \nis written as C functions, which can be inlined if they contain no control .ow. This means that SIMD \ninstructions are again a prob\u00adlem; if a tool needs to use SIMD instructions in its analysis code (as \nMemcheck does), these would have to be written in Pin using (platform-speci.c) inline assembly code. \nThis is caused by Pin us\u00ading C&#38;A and its method for writing analysis code (C code) having less expressivity \nthan client code (machine code). R4 (instrument read/write system calls) is another stumbling block; \nit can be done manually within a tool via Pin s system call instrumentation, but would require a large \neffort each shadow value tool would essentially need to reimplement Valgrind s system call wrappers. \n 5.4 Tool Performance We performed experiments on 25 of the 26 SPEC CPU2000 bench\u00admarks (we could not \nrun galgel as gfortran failed to compile it). We ran them with the reference inputs in 32-bit mode on \na 2.4 GHz Intel Core 2 Duo with 1GB RAM and a 4MB L2 cache run\u00adning SUSE Linux 10.2, kernel 2.6.18.2. \nWe compared several tools built with Valgrind 3.2.1: (a) Nulgrind, the no instrumentation tool; (b) ICntI, \nan instruction counter which uses inline code to in\u00adcrement a counter for every instruction executed; \n(c) ICntC, like ICntI but uses a C function call to increment the counter; and (d) Memcheck (with leak-checking \noff, because it runs at program ter\u00admination and so would cloud the comparison). Table 2 shows the slow-down \nfactors of these tools. Lightweight tools. The mean slow-down of 4.3x for the no\u00adinstrumentation case \n(Nulgrind) is high compared to other frame\u00adworks. This is consistent with other researchers .ndings a \npre\u00ad 10 It does have thread-locking primitives, but they would be too coarse\u00adgrained to be practical \nfor use with shadow memory. Program Nat. (s) Nulg. ICntI ICntC Memc. bzip2 192.7 3.5 7.2 10.5 16.1 crafty \n92.4 6.9 12.3 22.5 36.0 eon 408.5 7.5 11.8 21.0 51.4 gap 131.3 4.0 9.1 13.5 25.5 gcc 90.0 5.3 9.0 14.1 \n39.0 gzip 212.1 3.2 5.9 9.0 14.7 mcf 87.0 2.0 3.5 5.4 7.0 parser 218.9 3.6 7.0 10.4 17.8 perlbmk 179.6 \n4.8 9.6 14.6 27.1 twolf 262.5 3.1 6.5 10.7 16.0 vortex 86.7 6.5 11.4 17.8 38.7 vpr 149.4 4.1 7.7 11.3 \n16.4 ammp 345.2 3.4 6.5 9.1 32.7 applu 583.0 5.2 14.1 28.1 19.7 apsi 469.0 3.4 8.2 12.5 16.4 art 100.4 \n4.7 9.4 13.7 24.0 equake 118.2 3.8 8.4 12.4 17.1 facerec 280.9 4.7 8.2 12.2 17.4 fma3d 284.7 4.1 9.4 \n16.2 26.0 lucas 183.5 3.7 7.1 10.8 24.8 mesa 148.9 5.9 10.3 15.9 57.9 mgrid 809.1 3.5 9.8 14.4 16.9 sixtrack \n355.7 5.6 13.4 18.3 20.2 swim 388.2 3.2 11.9 15.3 10.7 wupwise 192.1 7.4 11.8 17.3 26.7 geo. mean 4.3 \n8.8 13.5 22.1 Table 2. Performance of four Valgrind tools on SPEC CPU2000. Column 1 gives the program \nname; integer programs are listed be\u00adfore .oating-point programs. Column 2 gives the native execution \ntime in seconds. Columns 3 6 give the slow-down factors for each tool. The .nal row shows each column \ns geometric mean. vious comparison [11] showed that Valgrind is 4.0x slower than Pin and 4.4x slower \nthan DynamoRIO on the SPEC CPU2000 inte\u00adger benchmarks in the no-instrumentation case, and 3.3x and 2.0x \nslower for a lightweight basic block counting tool.11 Re-implementing chaining in Valgrind would improve \nthese cases somewhat. However, these lightweight tools are exactly the kinds of tools that Valgrind is \nnot targeted at, and Valgrind will never be as fast as Pin or DynamoRIO for these cases. For example, \nconsider Valgrind s use of a D&#38;R representation. For a simple tool like a basic block counter, D&#38;R \nmakes no sense. Rather, the use of D&#38;R is targeted towards heavyweight tools. For this reason, we \ndo not repeat such comparisons with lightweight tools. The difference between ICntI and ICntC shows the \nadvantage of inline code over C calls. ICntI could be further improved by batching counter increments \ntogether. Heavyweight tools built with Valgrind. Memcheck s mean slow\u00addown factor is 22.2x. Other shadow \nvalue tools built with Valgrind have similar or worse slow-downs. TaintCheck ran 37x slower on an invocation \nof bzip2 [20], but had better performance on an I/O\u00adbound invocation of the Apache web server. Annelid \nran a subset of the SPEC CPU2000 benchmarks ( train inputs) 35.2x slower than native [16]. McCamant and \nErnst s secret tracker has slow-downs similar to Memcheck... 10 100x for CPU-bound programs [13]. Redux \ndid much more expensive analysis and was not practical for anything more than toy programs [17]. Slow-down \n.gures are not available for DynCompB [7]. 11 But the measured Valgrind tool used a C function to increment \nthe counter; the use of inline code would have narrowed the gap. None of these tools are as optimised \nas Memcheck, particularly their handling of shadow memory; more aggressive implementa\u00adtions would have \nslow-downs closer to Memcheck s. Other heavyweight tools. Hobbes slow-down factors for SPEC CPU2000 integer \nprograms were in the range 30 187x. However, Hobbes used a built-from-scratch binary interpreter rather \nthan a JIT compiler, so this is a poor comparison point. TaintTrace [6] is built with DynamoRIO, implements \nshadow registers within the tool itself, and has an mean slow-down factor of 5.5x for a subset of the \nSPEC CPU2000 benchmarks. LIFT [23] is built with StarDBT, a dynamic binary translation/instrumentation \nframework developed by Intel. It has a mean slow-down fac\u00adtor of 3.5x for a similar subset of the SPEC \nCPU2000 integer benchmarks. These two tools are much faster than Memcheck and TaintCheck. This is partly \nbecause they are doing a simpler analysis they track one taintedness bit per byte, whereas Mem\u00adcheck \ntracks one de.nedness bit per bit and does various other kinds of checking, and TaintCheck records four \nbytes per byte in order to record origins of tainted values. More importantly, they are faster because \nthey are less robust and have more limited instrumentation capabilities, in several ways. TaintTrace \nreserves the entire upper half of the address space for shadow memory, which makes shadow memory accesses \ntrivial and inlinable, but: (a) it wastes 7/8 of that space (7/16 of the total address space) because \neach shadow byte holds only a single taintedness bit, and (b) reserving large areas of address space \nworks most of the time on Linux, but is untenable on many other OSes e.g. Mac OS X, AIX, and many embedded \nOSes put a lot of code and data in the top half of the address space [19]. In comparison, Memcheck instead \nuses a shadow memory layout that is slower largely because it requires calls to C functions for shadow \nloads and stores but more .exible and thus more robust, and shadow memory operations account for close \nto half of Memcheck s overhead [19].  LIFT translates 32-bit x86 code to run on x86-64 machines. x86-64 \nmachines have eight extra integer registers which are not used by x86 programs which make shadow registers \nvery easy to implement. The translation also avoids the problems of .tting shadow memory into the 32-bit \naddress space, as LIFT has a 64-bit address space to work in. In one way, this is the ideal approach \nhaving twice the registers and (more than) twice as much memory is perfect for shadow values. However, \nit is only narrowly applicable. If LIFT was implemented without binary translation the extra register \npressure would not be great its shadow values are compact (one bit per byte) and so eight shadow registers \ncan be squeezed into a single host register and so the slow-down might be moderate, particularly on a \nplatform with lots of reg\u00adisters such as PowerPC. But for Memcheck, TaintCheck, or any other tool that \nhas larger shadow register values, the slow-down would be greater.  Neither TaintTrace nor LIFT handle \nprograms that use FP or SIMD code [5, 22]. We have found that handling these cases by adding them later \nis more dif.cult than it might seem. The hybrid IR used by Valgrind (mentioned in Sections 3.5 and 3.6) \nhad FP/SIMD handling added (via C&#38;A) only once the integer D&#38;R part was working. This meant that \nthe Valgrind and Mem\u00adcheck s performance on FP/SIMD code was much worse than on integer code because \nthe x86 FP/SIMD state had to be fre\u00adquently saved and restored (even though we optimised away re\u00addundant \nones whenever possible). Also, the instrumentation ca\u00adpabilities were worse for FP/SIMD code, and Memcheck \nhan\u00addled such code less accurately [25]. The rotating x87 FP regis\u00ad  ter stack is particularly dif.cult \nto handle well with C&#38;A code representation. Neither TaintTrace nor LIFT handle multi-threaded programs. \nTaintTrace and LIFT show that shadow value tools can be im\u00adplemented in frameworks other than Valgrind, \nand have better per\u00adformance than Memcheck, if they use techniques that are applica\u00adble to a narrower \nrange of programs. We believe that the robust\u00adness and instrumentation capabilities of TaintTrace and \nLIFT could be improved somewhat, and that such changes would reduce their performance. But in general, \nwe believe that making these tools as robust and accurate as Memcheck would be very dif.cult given that \nthey are built with DBI frameworks that do not support all nine shadow value requirements. Nonetheless, \nresearch prototypes with a narrower focus can identify new techniques that are applicable in real-world \ntools. For example, LIFT uses clever techniques to avoid performing some shadow operations; these might \nbe adaptable for use in Memcheck. Although there is some scope for improving Memcheck s per\u00adformance \n(by adding chaining to Valgrind s core and using LIFT s techniques for skipping shadow operations), given \nits other charac\u00adteristics, we believe that its performance is reasonable considering how much analysis \nit does [25, 19]. Memcheck s popularity shows that programmers are willing to use a tool with a large \nslow-down if its bene.ts are high enough, and it is easily the fastest shadow value tool we know of that \nis also robust and general. We also believe and that Valgrind s design features such as its unique D&#38;R \nIR with .rst-class shadow registers are crucial in achieving this reason\u00adable performance despite the \nchallenging requirements of shadow values. 5.5 Summary Every DBI framework has a number of important \ncharacteristics: ease of tool-writing, robustness, instrumentation capabilities, and performance. Robustness \nand performance are also important for DBA tools built with DBI frameworks, and tool designs crucially \naffect these characteristics. Performance has traditionally received the most attention, but the other \ncharacteristics are equally impor\u00adtant. Trade-offs must be made in any framework or tool, and all relevant \ncharacteristics should be considered in any comparisons between frameworks and/or tools. For lightweight \nDBA, Valgrind is less suitable than more performance-oriented frameworks such as Pin and DynamoRIO. For \nheavyweight DBA, Valgrind has a uniquely suitable combina\u00adtion of characteristics: it makes tools relatively \neasy to write, allows them to be robust, provides powerful instrumentation capabilities, and allows reasonable \nperformance. These characteristics are ex\u00adempli.ed by Memcheck, which is highly accurate, widely used, \nand reasonably fast.  6. Related Work There are many DBI frameworks; Nethercote [15] compares eleven \nin detail (that publication also discusses shadow values, but in less detail than this paper). They vary \nin numerous ways: platforms supported, instrumentation mechanisms, kinds of analysis code supported, \nrobustness, speed, and availability. Judging by recent literature, those that are both widely-used and \nactively maintained are Pin [11], DynamoRIO [3], DIOTA [12], and Valgrind. We compared Valgrind to Pin \nin Section 5. As for other DBI frameworks, they all provide less shadow value support than Pin; in particular, \nthey provide no support for R1 (provide shadow registers), such as virtual registers or register re-allocation. \nWe believe R1 is the hardest requirement for a tool to ful.l without help from its framework; without \nsuch support, tools have to .nd ways to steal extra registers for themselves. This is possible to some \nextent, but very dif.cult to do on the scale required for shadow values in a manner that is robust and \ngives reasonable performance. The nine shadow value tools we know of were discussed in Section 1.2 and \n5.4. Six of them were built with Valgrind. Shadow value tools are not only applicable at the binary level. \nFor example, Perl s taint mode [29] and Patil and Fischer s bounds checker for C [21] implement analyses \nsimilar to those of TaintCheck and Annelid (see Section 1) at the level of source code. The underlying \ntool ideas are very similar, but the implementation details are completely different. 7. Future Work \nand Conclusion Valgrind is a widely-used DBI framework. It is designed to support DBA heavyweight tools, \nsuch as shadow value tools, and therefore can be used to build most conceivable DBA tools. This paper \nhas identi.ed the requirements of shadow value tools and how Valgrind supports them, and shown that Valgrind \ninhabits a unique part of the DBI framework design space. We have focused more on Valgrind s instrumentation \ncapabilities than its performance, because (a) they are an equally important but less-studied topic, \nand (b) they distinguish Valgrind from other related frameworks. We think there are two main areas of \nfuture research for Val\u00adgrind. First, we want to .nd a way to avoid forcing serial thread execution in \na way that does not compromise the correctness of shadow value tools. This will become increasingly important \nas multi-core machines proliferate. Second, Memcheck has already shown that heavyweight DBA tools can \nhelp programmers greatly improve their programs. We think there is plenty of scope for new heavyweight \nDBA tools, particularly shadow value tools, and we hope Valgrind will be used to build some of these \ntools.  Acknowledgments Thanks to: Greg Lueck for his Pin expertise; Mike Bond, Kim Hazelwood and the \nanonymous reviewers for reviewing this paper; and everyone who has contributed to Valgrind over the years, \npar\u00adticularly Jeremy Fitzhardinge, Tom Hughes and Donna Robinson. References [1] V. Bala, E. Duesterwald, \nand S. Banerjia. Dynamo: A transparent dynamic optimization system. In Proceedings of PLDI 2000, pages \n1 12, Vancouver, Canada, June 2000. [2] D. Bruening. Ef.cient, Transparent, and Comprehensive Runtime \nCode Manipulation. PhD thesis, MIT, Cambridge, Mass., USA, September 2004. [3] D. Bruening, T. Garnett, \nand S. Amarasinghe. An infrastructure for adaptive dynamic optimization. In Proceedings of CGO 03, pages \n265 276, San Francisco, California, USA, March 2003. [4] M. Burrows, S. N. Freund, and J. L. Wiener. \nRun-time type checking for binary programs. In Proceedings of CC 2003, pages 90 105, Warsaw, Poland, \nApril 2003. [5] W. Cheng. Personal communication, November 2006. [6] W. Cheng, Q. Zhao, B. Yu, and S. \nHiroshige. TaintTrace: Ef.cient .ow tracing with dynamic binary rewriting. In Proceedings of ISCC 2006, \npages 749 754, Cagliari, Sardinia, Italy, June 2006. [7] P. J. Guo, J. H. Perkins, S. McCamant, and M. \nD. Ernst. Dynamic inference of abstract types. In Proceedings of ISSTA 2006, pages 255 265, Portland, \nMaine, USA, July 2006. [8] R. Hastings and B. Joyce. Purify: Fast detection of memory leaks and access \nerrors. In Proceedings of the Winter USENIX Conference, pages 125 136, San Francisco, California, USA, \nJanuary 1992. [9] K. Hazelwood. Code Cache Management in Dynamic Optimization Systems. PhD thesis, Harvard \nUniversity, Cambridge, Mass., USA, May 2004. [10] G. Lueck and R. Cohn. Personal communication, September \nNovember 2006. [11] C.-K. Luk, R. Cohn, R. Muth, H. Patil, A. Klauser, G. Lowney, S. Wallace, V. J. Reddi, \nand K. Hazelwood. Pin: Building customized program analysis tools with dynamic instrumentation. In Proceedings \nof PLDI 2005, pages 191 200, Chicago, Illinois, USA, June 2005. [12] J. Maebe, M. Ronsse, and K. De Bosschere. \nDIOTA: Dynamic instrumentation, optimization and transformation of applications. In Proceedings of WBT-2002, \nCharlottesville, Virginia, USA, September 2002. [13] S. McCamant and M. D. Ernst. Quantitative information-.ow \ntracking for C and related languages. Technical Report MIT-CSAIL\u00adTR-2006-076, MIT, Cambridge, Mass., \nUSA, 2006. [14] S. Narayanasamy, C. Pereira, H. Patil, R. Cohn, and B. Calder. Au\u00adtomatic logging of \noperation system effects to guide application-level architecture simulation. In Proceedings of SIGMetrics/Performance \n2006, pages 216 227, St. Malo, France, June 2006. [15] N. Nethercote. Dynamic Binary Analysis and Instrumentation.PhD \nthesis, University of Cambridge, United Kingdom, November 2004. [16] N. Nethercote and J. Fitzhardinge. \nBounds-checking entire programs without recompiling. In Informal Proceedings of SPACE 2004, Venice, Italy, \nJanuary 2004. [17] N. Nethercote and A. Mycroft. Redux: A dynamic data.ow tracer. ENTCS, 89(2), 2003. \n[18] N. Nethercote and J. Seward. Valgrind: A program supervision framework. ENTCS, 89(2), 2003. [19] \nN. Nethercote and J. Seward. How to shadow every byte of memory used by a program. In Proceedings of \nVEE 2007, San Diego, California, USA, June 2007. [20] J. Newsome and D. Song. Dynamic taint analysis \nfor automatic de\u00adtection, analysis, and signature generation of exploits on commodity software. In Proceedings \nof NDSS 05, San Diego, California, USA, February 2005. [21] H. Patil and C. Fischer. Low-cost, concurrent \nchecking of pointer and array accesses in C programs. Software Practice and Experience, 27(1):87 110, \nJanuary 1997. [22] F. Qin. Personal communication, March 2007. [23] F. Qin, C. Wang, Z. Li, H. Kim, Y. \nZhou, and Y. Wu. Lift: A low-oeverhead practical information .ow tracking system for detecting security \nattacks. In Proceedings of the Annual IEEE/ACM International Symposium on Microarchitecture (Micro 06), \nOrlando, Florida, USA, December 2006. [24] K. Scott, J. W. Davidson, and K. Skadron. Low-overhead software \ndynamic translation. Technical Report CS-2001-18, University of Virginia, Charlottesville, Virginia, \nUSA, 2001. [25] J. Seward and N. Nethercote. Using Valgrind to detect unde.ned value errors with bit-precision. \nIn Proceedings of the USENIX 05 Annual Technical Conference, Anaheim, California, USA, April 2005. [26] \nO. Traub, G. Holloway, and M. D. Smith. Quality and speed in linear\u00adscan register allocation. In Proceedings \nof PLDI 98, pages 142 151, Montreal, Canada, June 1998. [27] The Valgrind Developers. 2nd of.cial Valgrind \nsurvey, September 2005: full report. http://www.valgrind.org/gallery/survey 05/report. txt. [28] The \nValgrind Developers. Valgrind. http://www.valgrind.org/. [29] L. Wall, T. Christiansen, and J. Orwant. \nProgramming Perl. O Reilly, 3rd edition, 2000.  \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Dynamic binary instrumentation (DBI) frameworks make it easy to build dynamic binary analysis (DBA) tools such as checkers and profilers. Much of the focus on DBI frameworks has been on performance; little attention has been paid to their capabilities. As a result, we believe the potential of DBI has not been fully exploited.</p> <p>In this paper we describe Valgrind, a DBI framework designed for building heavyweight DBA tools. We focus on its unique support for <i>shadow values</i>-a powerful but previously little-studied and difficult-to-implement DBA technique, which requires a tool to shadow every register and memory value with another value that describes it. This support accounts for several crucial design features that distinguish Valgrind from other DBI frameworks. Because of these features, lightweight tools built with Valgrind run comparatively slowly, but Valgrind can be used to build more interesting, heavyweight tools that are difficult or impossible to build with other DBI frameworks such as Pin and DynamoRIO.</p>", "authors": [{"name": "Nicholas Nethercote", "author_profile_id": "81331500269", "affiliation": "National ICT Australia, Melbourne, Australia", "person_id": "PP39067721", "email_address": "", "orcid_id": ""}, {"name": "Julian Seward", "author_profile_id": "81100309951", "affiliation": "OpenWorks LLP, Cambridge, United Kingdom", "person_id": "PP33031888", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250746", "year": "2007", "article_id": "1250746", "conference": "PLDI", "title": "Valgrind: a framework for heavyweight dynamic binary instrumentation", "url": "http://dl.acm.org/citation.cfm?id=1250746"}