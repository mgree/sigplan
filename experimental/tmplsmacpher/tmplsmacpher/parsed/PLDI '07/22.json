{"article_publication_date": "06-10-2007", "fulltext": "\n Goldilocks: A Race and Transaction-Aware Java Runtime Tayfun Elmas Shaz Qadeer Serdar Tasiran Koc University, \nIstanbul, Turkey Microsoft Research, Redmond, WA Koc University, Istanbul, Turkey telmas@ku.edu.tr qadeer@microsoft.com \nstasiran@ku.edu.tr Abstract Data races often result in unexpected and erroneous behavior. In ad\u00addition \nto causing data corruption and leading programs to crash, the presence of data races complicates the \nsemantics of an execution which might no longer be sequentially consistent. Motivated by these observations, \nwe have designed and implemented a Java run\u00adtime system that monitors program executions and throws a \nData-RaceException when a data race is about to occur. Analogous to other runtime exceptions, the DataRaceException \nprovides two key bene.ts. First, accesses causing race conditions are interrupted and handled before \nthey cause errors that may be dif.cult to diag\u00adnose later. Second, if no DataRaceException is thrown \nin an ex\u00adecution, it is guaranteed to be sequentially consistent. This strong guarantee helps to rule \nout many concurrency-related possibilities as the cause of erroneous behavior. When a DataRaceException \nis caught, the operation, thread, or program causing it can be termi\u00adnated gracefully. Alternatively, \nthe DataRaceException can serve as a con.ict-detection mechanism in optimistic uses of concur\u00adrency. \nWe start with the de.nition of data-race-free executions in the Java memory model. We generalize this \nde.nition to executions that use transactions in addition to locks and volatile variables for synchronization. \nWe present a precise and ef.cient algorithm for dynamically verifying that an execution is free of data \nraces. This algorithm generalizes the Goldilocks algorithm for data-race de\u00adtection by handling transactions \nand providing the ability to distin\u00adguish between read and write accesses. We have implemented our algorithm \nand the DataRaceException in the Kaffe Java Virtual Machine. We have evaluated our system on a variety \nof publicly available Java benchmarks and a few microbenchmarks that com\u00adbine lock-based and transaction-based \nsynchronization. Our exper\u00adiments indicate that our implementation has reasonable overhead. Therefore, \nwe believe that in addition to being a debugging tool, the DataRaceException may be a viable mechanism \nto enforce the safety of executions of multithreaded Java programs. Categories and Subject Descriptors \nD.2.4 [Software Engineer\u00ading]: Software/Program Veri.cation formal methods, reliability, validation; \nD.2.5 [Software Engineering]: Testing and Debugging debugging aids, diagnostics, error handling and recovery, \nmon\u00aditors; F.3.1 [Logics and Meanings of Programs]: Specifying and Verifying and Reasoning about Programs \n mechanical veri.ca\u00adtion Permission to make digital or hard copies of all or part of this work for personal \nor classroom use is granted without fee provided that copies are not made or distributed for pro.t or \ncommercial advantage and that copies bear this notice and the full citation on the .rst page. To copy \notherwise, to republish, to post on servers or to redistribute to lists, requires prior speci.c permission \nand/or a fee. PLDI 07 June 11 13, 2007, San Diego, California, USA. Copyright c &#38;#169; 2007 ACM 978-1-59593-633-2/07/0006. \n. . $5.00 General Terms Algorithms, Languages, Reliability, Veri.cation Keywords Data-race Detection, \nJava Runtime, Runtime Monitor\u00ading, Software Transactions 1. Introduction Data races in concurrent programs \nare often symptomatic of a bug and may have unintended consequences. Unanticipated data races may have \nnon-deterministic effects and are not desired. Detection and/or elimination of race conditions has been \nan area of active research. This paper presents a novel approach to detecting data\u00adrace conditions in \nJava programs and makes the following technical contributions. We present Goldilocks: a novel, precise \nlockset-based dynamic race detection algorithm. Goldilocks, unlike previous variants of lockset algorithms, \ncan uniformly and naturally handle all synchronization idioms such as thread-local data that later be\u00adcomes \nshared, shared data protected by different locks at dif\u00adferent points in time, and data protected indirectly \nby locks on container objects. This paper presents a generalized version of the Goldilocks race-detection \nalgorithm [8] that adds to it two key capabilities: explicitly handling software transactions [22] as \na high-level synchronization idiom, and distinguishing be\u00adtween read and write accesses.  An implementation \nof the generalized Goldilocks algorithm was carried out inside the Kaffe Java virtual machine. This implementation \nincorporates two techniques that signi.cantly enhance its performance: partially-lazy evaluation and \nimplicit representation of locksets, and a sequence of cheap and suf.\u00adcient checks for race freedom which \nallow bypassing of lockset computation.  To reduce the runtime overhead of race detection, we apply \nex\u00adisting sound static race analysis tools beforehand to determine and record in Java class .les the \nvariables and accesses that are guaranteed to be race free. The capability to skip checks on these accesses \nin a sound manner, combined with the im\u00adplementation optimizations result in a precise dynamic race checker \nwhose performance on benchmarks is competitive with or, in some cases, signi.cantly better than existing \ndynamic race checkers for Java programs.  We present the .rst formalization of race conditions for pro\u00adgrams \nthat use software transactions along with other Java syn\u00adchronization primitives. The extended Goldilocks \nalgorithm and its implementation in the Kaffe JVM explicitly handle transactions.  Our Java runtime \nprovides a new runtime exception, Data-RaceException, that is thrown precisely when an access that causes \nan actual race condition is about to be executed. This brings races to the awareness of the programmer \nand allows him to explicitly handle them.  The Java memory model (JMM) precisely de.nes the seman\u00adtics \nfor executions including races. We view the primary purpose of this to be specifying constraints for \nJava compilers and virtual machines in order to provide sanity and security guarantees. Other\u00adwise, the \nsemantics of Java executions with races are very dif.cult to make use of. The JMM de.nes well-synchronized \nprograms to be free of data races. We expect that programmers will strive to ensure that their programs \nare race free and want to operate un\u00adder sequential consistency semantics. In this view, an actual race \ncondition is analogous to an out-of-bounds array access or a null pointer dereference. The Java runtime \npresented in this paper raises a DataRaceException when an actual (not potential) race condi\u00adtion is \nabout to occur. This provides a mechanism for the program to always operate under sequentially consistent \nsemantics. If the programmer has provided exception handling code, the program continues execution with \nsequentially consistent semantics, other\u00adwise the thread that threw the exception is terminated. It is \nup to the programmer to interpret the race condition as symptomatic of a bug and gracefully terminate \nan operation or the entire program and .x the bug, or, to make more optimistic use of the DataRace-Exception \nas a mechanism for con.ict detection between threads, and, say, roll back the effects of the block of \ncode that triggered the DataRaceException. To support DataRaceException, a race detection algorithm needs \nto be precise, i.e., not produce false alarms or warnings about potential races. It is not acceptable \nto interrupt an execution be\u00adcause of a potential or false race. Our dynamic race detection al\u00adgorithm \ngeneralizes Goldilocks, the .rst precise lockset-based al\u00adgorithm for dynamic race detection. The lockset \nupdate rules in Goldilocks uniformly handle all synchronization disciplines. The preliminary version \nof Goldilocks, while being as precise as a vector-clock-based algorithm, was found to be comparable in \nper\u00adformance overhead to a prototype implementation of a lockset\u00adbased algorithm from the literature \n[20]. In this paper, we gener\u00adalize Goldilocks to distinguish between read and write accesses and to \nhandle software transactions explicitly. We implemented this race detection algorithm as part of the \nKaffe Java virtual ma\u00adchine [24] which now provides a precise DataRaceException.A number of performance \noptimizations and new implementation fea\u00adtures improve the performance of Goldilocks signi.cantly beyond \nwhat was reported in [8]. To reduce the runtime overhead, we apply static analyses [1, 17] to eliminate \ndynamic checks on variables that can be proved to be race free statically. With this pre-elimination, \nthe overheads we obtained on Java benchmarks are competitive with or better than other dynamic race detection \nalgorithms in the literature. These results indicate that the precision of our algorithm does not come \nat a performance cost. For many benchmark programs, we found the overhead of precise race detection with \nour approach to be low enough to be possibly tolerable even for deployed code. In other benchmarks and \nfor programs in which performance is of utmost importance, the safety-performance trade-off provided \nby Data-RaceException may not be acceptable. For these programs, our Java runtime can serve as a debugging \ntool that produces no false alarms. We imagine, at least in the near future, that programmers will use \nsoftware transactions [22] to manage only some of the accesses to shared data1 and other Java synchronization \nprimitives to man\u00adage the rest possibly to some of the same variables that were ac\u00adcessed within transactions \nat other points in the execution. We pro\u00advide the .rst formalization of race conditions for executions \nthat use software transactions in addition to other Java synchroniza\u00ad 1 Because most existing transaction \nimplementations do not support I/O and may require libraries to be re-compiled [4] tion primitives. \nWe extended Goldilocks lockset update rules in order to handle transactions and also extended our implementation \nin Kaffe to provide DataRaceException support for executions with software transactions. The nature of \nthe lockset rules and the implementation made it possible to integrate this feature without signi.cant \nrestructuring. We require that the semantics of software transactions to spec\u00adify when a happens-before \nrelationship exists between two trans\u00adactions without reference to the particular transactions implemen\u00adtation. \nFor instance, in this paper, we use the speci.cation that there is a happens-before edge between transactions \nthat access at least one common variable. Our formulation of race conditions fa\u00adcilitates a modular check \nfor races and strong atomicity for pro\u00adgrams that use software transactions. The implementer of software \ntransactions veri.es that the implementation provides the happens\u00adbefore edges in the transactions speci.cation. \nOur race checker as\u00adsumes that these happens-before edges are implemented properly, and checks for race-freedom \nof all accesses, but disregards the in\u00adternal operation of the transactions implementation. The transac\u00adtion \nimplementation is only required to provide a list of the shared variables accessed by each transaction \nand a commit point. If no DataRaceException is thrown, then sequential consistency and strong atomicity \nare guaranteed. Further, the speci.cation rather than the implementation of transactions is used in order \nto make this check cheaper. We demonstrate this way of handling transac\u00adtions in our runtime on a hand-coded \ntransactional data structure. Section 2 provides examples that motivate the new features of the Java \nruntime we built. Section 3 introduces our mathemati\u00adcal model of Java program executions and de.nes \nrace conditions for executions that contain transactions. Section 4 presents our dy\u00adnamic race-detection \nalgorithm. Section 5 describes the implemen\u00adtation of the algorithm and optimizations for reducing runtime \nover\u00adhead. Section 6 presents results of experiments using our Java run\u00adtime. 2. Motivating examples \nExample 1: This example demonstrates the use of DataRace-Exception to terminate gracefully a thread about \nto perform an access that would have caused a data race before the race leads to an error. Pseudocode \nfor this example is given in Figure 1 and is adapted from the Apache ftp-server benchmark used in [17]. \nThe run() and close() methods shown belong to an object represent\u00ading an ftp connection and are executed \nby two separate threads. The thread executing the run() method, in a do .. while loop services requests \nissued by the user on the command line, one com\u00admand per iteration of the loop. A time-out thread executes \nthe close() method of connection objects that have been idle too long. In the original benchmark, which \ndid not contain the try ... catch block for DataRaceException, it is possible for the time-out thread \nto run the close() method and set, for instance, the m writer .eld of the connection object to null right \nbefore the other thread accesses it at line 10 of the run() method. This race condition causes a NullPointerException.Making \nrun() a synchronized method would make it impossible for the time-out thread to execute close(), thus, \nin a correct implementation, .ner\u00adgrain synchronization needs to be used. In the modi.ed code that uses \nDataRaceException, when the thread executing run() is about to access m writer in line 10 after the unsynchronized \naccess by the thread running close(), a DataRaceException is thrown. The run() thread catches this exception, \nstops processing commands on this connection, exits the do...while loop and allows the time-out thread \nto close the connection. Note that, although in this example a race condition has an immediately noticeable \nconsequence, in other examples 1 public void run() { 2// ... 3 // Initialize connection 4try { 5 do { \n6 String commandLine = m_reader.readLine(); 7 ... 8 m_request.parse(commandLine); 9 if(!hasPermission()) \n{ 10 m_writer.send(530, \"permission\", null); 11 continue; 12 } 13 // execute command 14 service(m_request, \nm_writer); 15 } while(!m_isConnectionClosed); 16 } catch (DataRaceException e) { 17 // Error message: \n\"Connection closed!\" 18 break; 29 } 30 } 1 public void close() { 2 3 synchronized(this) { 4 if(m_isConnectionClosed) \nreturn; 5 m_isConnectionClosed = true; 6} 7 ... 8 m_request = null; 9 m_writer = null; 10 m_reader = \nnull; 11 } Figure 1. Example 1: Demonstrating use of DataRaceException Class IntBox { int data; } IntBox \na, b; // Global variables Thread 1: Thread 2: Thread 3: tmp1 = new IntBox(); acq(ma); acq(mb); tmp1.data \n= 0; tmp2 = a; b.data = 2; acq(ma) rel(ma); tmp3 = b; a = tmp1; acq(mb); rel(mb); rel(ma); b = tmp2; \ntmp3.data = 3; rel(mb); Figure 2. Example 2 the observable manifestation of the race condition may occur \nfar enough in the execution to make it very dif.cult to trace its origin. Example 2: To support DataRaceException, \na precise and ef.\u00adcient dynamic race analysis is needed. Purely vector-clock-based algorithms are precise \nbut typically computationally expensive [16]. Lockset-based algorithms are ef.cient, but are not precise. \nThey check adherence to a particular synchronization discipline and declare false races when this discipline \nis violated. Example 2 (Figure 2) makes use of two idioms typically not handled by ear\u00adlier lockset algorithms: \nobjects that are local to different threads at different points in the execution, and objects protected \nby locks of container objects. The Goldilocks race detection algorithm de\u00adclares no false alarms in this \nexample while other lockset-based algorithms do. Consider an execution in which all actions of Thread \n1 happen .rst, followed by all actions of Thread 2 andthenof Thread 3. This example mimics a scenario \nin which an object is created and initialized and then made visible globally by Thread 1.This IntBox \nobject (referred to as o from now on) is a container object Foo {int data; Foo nxt}; Thread 1: Thread \n2: Thread 3: -----------------\u00ad ------------\u00ad ------------ Foo t1 = new Foo(); Foo iter; Foo t3; t1.data \n= 42; atomic { atomic { atomic { for (iter = head; t3 = head; t1.nxt = head; iter != null; head = head \n= t1; iter = iter.nxt) t3.nxt; } iter.data = 0; } } t3.data++; Figure 3. Example 3 public class Account \n{ double bal; public synchronized withdraw(int amt) { bal -= amt;}} Account savings, checking; Thread \n1: Thread 2: ------------------------\u00ad -----------------------\u00ad 1 atomic { 1 checking.withdraw(42); 2 \nsavings.bal -= 42; 3 checking.bal += 42; 4} Figure 4. Example 4 for its data .eld, and, is referred \nto by different global variables at different points in this execution. Furthermore, the contained variable \no.data is protected by synchronization on the container object o, and ownership transfer of o.data from \none thread to another sometimes takes place without the o.data .eld being accessed at all. How our algorithm \ncorrectly captures the absence of a race in this case is explained in Section 4.1. Example 3: In this \nexample (Figure 3), software transactions and thread-locality are used at different times in the execution \nto protect access to the same shared data. A race checking algorithm that does not take into account \ntransactions as a synchronization primitive would declare a false race in this example. Here, Foo objects \nform a linked-list, and while a Foo object is a member of the linked list, access to it is managed by \nsoftware transactions. A Foo object referred to by t1 is created and initialized by Thread 1, during \nwhich time it is thread-local. Then, in an atomic transaction, it is added to the head of the linked \nlist by Thread 1. While in the linked list, this Foo object is modi.ed by the loop in Thread 2, which, \nin an atomic software transaction, modi.es the data .elds of all Foo objects in the list. Thread 3 removes \nthe Foo object from the list in an atomic transaction. After this, the object is local to Thread 3. Observe \nthat it is possible to make this example more sophisticated, for instance, by having the Foo object be \nshared among threads and making it lock-protected after its removal from the list. A correct implementation \nof software transactions would create a happens-before relationship between the transactions in Thread \n1, 2 and 3. A race checking algorithm that is not aware of these happens-before edges would falsely declare \na race between the accesses to the data .eld of the Foo object in Thread 1 and Thread 3. Section 4.2 \nexplains how the generalized Goldilocks algorithm handles this example. Example 4: In this example (Figure \n4), shared data is either pro\u00adtected by an object lock or is accessed within a transaction, which might \nlead one to believe at .rst glance that there should be no race conditions. checking and savings are \nAccount objects with a synchronized withdraw method. Thread 1 contains a soft\u00adware transaction that transfers \nmoney from savings to checking. Thread 2 simply performs a withdrawal using the synchronized withdraw \nmethod. Since the software transaction implementa\u00adtion might be using a mechanism other than the object \nlocks on checking and savings to implement the atomic transaction, there is a potential race condition \nbetween Thread 1 and 2 s accesses to checking.bal. This race condition should be signaled regardless \nof the synchronization mechanism used by the transaction imple\u00admentation, since this mechanism should \nnot be visible to the pro\u00adgrammer. Observe that completely ignoring accesses inside trans\u00adactions while \nperforming dynamic race checking would overlook the race in this case. 3. Preliminaries This section \npresents the formalism required to explain the Goldilocks algorithm in Section 4. The reader may skip \nahead to Sections 4.1 and 4.2 for an informal understanding of Goldilocks lockset up\u00addate rules applied \nto Examples 2 and 3 in the previous section. Tid represents the set of thread identi.ers and Addr represents \nthe set of object identi.ers. Each object has a .nite collection of .elds. Field represents the set of \nall .elds and is a union of two disjoint sets, the set Data of data .elds and the set Volatile of volatile \n.elds. A data variable is a pair (o, d) consisting of an object o and a data .eld d.A synchronization \nvariable is a pair (o, v)consisting of an object o and a volatile .eld v. Each thread in a program executes \na sequence of actions. Actions are categorized into the following kinds: SyncKind = { acq(o), rel (o)| \no . Addr}. { read (o, v), write(o, v)| o . Addr . v . Volatile}. { fork(u), join(u)| u . Tid}. { commit(R, \nW )| R, W . Addr \u00d7 Data}  DataKind =  { read (o, d)| o . Addr . d . Data}. { write(o, d)| o . Addr \n. d . Data}  AllocKind ={ alloc(o)| o . Addr}  Kind =SyncKind . DataKind . AllocKind  The action \nkind alloc(o)represents allocation of a new object o. The action kinds read (o, d)and write(o, d)respectively \nread and write the data .eld d of an object o. A thread is said to access a variable (o, d)if it executes \nan action of kind either read (o, d)or write(o, d). Of course, other kinds of actions (such as arithmetic \ncomputation, function calls, etc.) also occur in a real execution of a Java program but these actions \nare irrelevant for our exposition of race conditions and have consequently been elided. The action kinds \nacq(o) and rel (o) respectively represent a thread acquiring and releasing a lock on object o. We use \na special .eld l . Volatile containing values from Tid .{ null} to model the semantics of an object lock. \nAn action of kind acq(o)being performed by thread t blocks until o.l =null and then atomically sets o.l \nto t. An action of kind rel (o)being performed by thread t fails if o.l t, otherwise it atomically sets \no.l to null. Although =we assume non-reentrant locks for ease of exposition in this paper, our techniques \nare easily extended to handle reentrant locks. The action kind commit(R, W )represents the committing \nof a trans\u00adaction that reads and writes the sets of shared data variables R and W respectively. We do \nnot allow transaction bodies to include syn\u00adchronization, therefore R, W . Addr \u00d7 Data. The commit action \nis explained in more detail in Sections 4 and 5. The action kinds read (o, v)and write(o, v)respectively \nrepre\u00adsent a read of and a write to the volatile .eld v of an object o.An action of kind fork(u)creates \na new thread with identi.er u.An action of kind join(u)blocks until the thread with identi.er u ter\u00adminates. \nIn this paper, when referring to an action, we sometimes only name its kind when the rest of the information \nis clear from the context. eso An execution S=(s, -. )of a program consists of a func\u00ad eso tion s : \nTid .N . Kind and a total order -. (extended synchronization order) on the set { (t, n)| s(t, n). SyncKind} \n. eso If commit actions are projected out of -. , the remaining total order is required to be the synchronization \norder associated with the execution as given by the Java memory model. Since we view transactions as \nhigh-level synchronization operations, we include the commit action for each transaction in the extended \nsynchro\u00adnization order to represent the ordering of the transaction with re\u00adspect to other synchronization \noperations. We use s to de.ne the popo program order of thread t denoted by -. t. The relation -. t \nis po a total order on the set { t}\u00d7N such that (t, m) -. t (t, n)iff eso m<n. The relation -. is a \ntotal order on the subset of actions that perform synchronization. The extended synchronizes-with par\u00ad \nesw tial order -. is de.ned to be the smallest transitively-closed rela\u00adtion that satis.es the following \nconditions: eso If s(t, m)=rel (o), s(u, n)=acq(o),and (t, m)-. (u, n), esw then (t, m)-. (u, n). eso \nIf s(t, m)=write(o, v), s(u, n)=read (o, v),and (t, m)-. esw (u, n),then (t, m)-. (u, n). esw If s(t, \nm)=fork(u),then (t, m)-. (u, n)for all n .N . esw If s(t, m)=join(u),then (u, n)-. (t, m)for all n .N \n.  If s(t, m)= commit(R, W ), s(u, n)= commit(R',W '), (t, m) -. (u, n),and (R . W )n ()  esoR' . W \n'= \u00d8 ,then esw (t, m)-. (u, n). The last item above expresses an interpretation of software trans\u00adactions \nin which a transaction synchronizes with (and happens be\u00adfore) another iff they access at least one common \nvariable. In this view, two transactions that access disjoint sets of variables do not synchronize with \neach other. ehb The extended happens-before relation, denoted by -. ,is a relation on the set Tid \u00d7N \n. It is the transitive closure of the union esw po of -. with the program order -. t for each thread \nt . Tid. There is an extended race on data variable (o, d) if there exist ehb t, u . Tid and m, n .N \nsuch that both (t, m)-. (u, n)and ehb (u, n) -. (t, m)are false and one of the following conditions \nhold: 1. s(t, m)=write(o, d)and s(u, n).{ read (o, d), write(o, d)} 2. s(t, m)= write(o, d), s(u, n)= \ncommit(R, W ),and (o, d). R . W 3. s(t, m)= read (o, d), s(u, n)= commit(R, W ),and (o, d). W  Observe \nthat for executions that contain no transaction com\u00admit actions, the extended synchronization order, \nthe extended synchronizes-with relation, and the extended happens-before re\u00adlation coincide with the \nsynchronization order, the synchronizes\u00adwith relation and the happens-before relation as de.ned in the \nJava eso memory model. The projection of the -. order onto the commit actions corresponds to the atomic \norder of transactions as de.ned in [11]. Our treatment of transactions simply formalizes one possible \nsemantics of transactions and does not introduce any extra syn\u00adchronization or serialization to transaction \nimplementations. In the transaction semantics we model using the extended happens-before relation, pairs \nof shared variable accesses where both accesses be\u00adlong to some transaction are considered to be race-free. \n1. s(t, n).{ read (o, d), write(o, d)} : if LS(o, d)=\u00d8 and t . LS(o, d) report data race on (o, d) LS(o, \nd):={ t} 2. s(t, n)=read (o, v): foreach (o ' ,d): if (o, v). LS(o ' ,d)add t to LS(o ' ,d) 3. s(t, \nn)=write(o, v): foreach (o ' ,d): if t . LS(o ' ,d)add (o, v)to LS(o ' ,d) 4. s(t, n)=acq(o): foreach \n(o ' ,d): if (o, l). LS(o ' ,d)add t to LS(o ' ,d) 5. s(t, n)=rel (o): foreach (o ' ,d): if t . LS(o \n' ,d)add (o, l)to LS(o ' ,d) 6. s(t, n)=fork(u): foreach (o ' ,d): if t . LS(o ' ,d)add u to LS(o ' \n,d)  7. s(t, n)=join(u): foreach (o ' ,d): if u . LS(o ' ,d)add t to LS(o ' ,d)  8. s(t, n)=alloc(x): \nforeach d . Data: LS(x, d):=\u00d8 9. s(t, n)=commit(R, W ):  foreach (o ' ,d): if LS(o ' ,d)n (R . W )=\u00d8 \nadd t to LS(o ' ,d) if (o ' ,d). R . W : if LS (o ' ,d)=\u00d8 and { t, TL}n LS(o ' ,d)=\u00d8 report data race \non (o ' ,d) LS(o ' ,d):={ t, TL}if t . LS(o ' ,d) add R . W to LS(o ' ,d) Figure 5. The lockset update \nrules for the Goldilocks algorithm Other ways of specifying the interaction between strongly\u00adatomic transactions \nand the Java memory model can easily be incorporated into our de.nition of extended races. For instance, \none can choose to de.ne the extended synchronizes-with order to include all atomic order edges, or to \ninclude a synchronizes- R '' with edge from transaction commit(R, W )to commit(,W ) if R ' n W =\u00d8 . The \nalgorithms and tools presented in this paper can easily be adapted to such alternative interpretations \nof strong\u00adatomicity.  4. The generalized Goldilocks algorithm In this section, we describe our algorithm \nfor detecting data races eso in an execution S=(s, -. ). The algorithm assumes that the execution is \nprovided to it as some linearization of the extended ehb happens-before relation -. . Formally, a linearization \nof an execu\u00adtion Sis a function p that maps N one-one to Tid \u00d7N such that ehbp-1 if (t, m) -. (u, n)then \np-1(t, m) = (u, n). If an execu\u00adtion contains a data-race between a pair of accesses, our algorithm declares \na race at one of these accesses regardless of which lin\u00adearization is picked. For simplicity, the exposition \nin this section does not distinguish between read and write accesses. This distinc\u00adtion and its effect \non the Goldilocks algorithm is explained in the next section. The algorithm uses an auxiliary map LS \nfrom (Addr\u00d7 Data)to Powerset((Addr \u00d7 Volatile. Data). Tid.{ TL} ). For each data variable (o, d),the \nlockset LS(o, d)may contain volatile variables, data variables, thread identi.ers, or a special value \nTL (Transaction Lock). The value TL models a .ctitious global lock that is acquired and released at the \ncommit point of each transaction. Initially, the map LS assigns the empty set to every data variable \n(o, d).The algorithm updates LS as each element in the linearization of s is processed. The set of rules \nfor these updates is shown in Figure 5. The intuitive interpretation of a lockset LS(o, d)is as follows: \n If LS (o, d) is empty, it indicates that (o, d) is a fresh vari\u00adable which has not been accessed so \nfar. Therefore, an ac\u00adcess to (o, d)when LS(o, d)is empty is necessarily race-free. LS(o, d)is initialized \nto the empty set and is reset to the empty set whenever o is an object returned by a memory allocation. \n If a thread identi.er t is in LS (o, d),then t is an owner of (o, d) and an access by t to (o, d)is \nrace-free.  If a lock (o ' ,l)is in LS(o, d), a thread can become an owner of (o, d)by acquiring the \nlock (o ' ,l). This is because the thread that last accessed (o, d)released (o ' ,l)subsequently.  If \na volatile variable (o ' ,v)is in LS (o, d), a thread can become an owner of (o, d)by reading (o ' ,v). \nThis is because the thread that last accessed (o, d)wrote to (o ' ,v)subsequently.  If TL is in LS(o, \nd), then the last access to (o, d)was per\u00adformed inside a transaction. Hence, there will be no race on \n(o, d)if the next access is also performed inside a transaction.  If adatavariable (o ' ,d ' )is in \nLS(o, d), a thread can become an owner of (o, d)by accessing (o ' ,d ' )inside a transaction. This is \nbecause the thread that last accessed (o, d)also accessed (o ' ,d ' )in a transaction subsequently. \n Given this interpretation of LS(o, d), we conclude that an access of (o, d)by a thread t outside any \ntransaction is race-free if and only if at that point in the execution either LS(o, d) is empty or t \n. LS(o, d). After this access, LS (o, d) contains only t, representing the constraint that between this \naccess and any future accesses to (o, d)by other threads, there must be synchronization actions to hand \nover ownership of (o, d). Similarly, an access of (o, d)by a thread t inside a transaction is race-free \nif and only if at that point in the execution either LS(o, d)is empty or t . LS(o, d) or TL . LS(o, d). \nAfter this access, LS(o, d)contains only t and TL, representing the constraint that the next access to \n(o, d)by a thread t ' different from t must either be inside a transaction or there must be synchronization \nactions to hand over ownership of (o, d) to t ' . The rules in Figure 5 take as input a linearization \np of S= eso (s, -. ). The pair (t, n) used in the rules represents the value of p(i)for an arbitrary \ni .N . Note that each of the rules 2 7 and 9 requires updating the lockset of each data variable. A naive \nimplementation of this algorithm would be too expensive for pro\u00adgrams that manipulate large heaps. In \nSection 5, we present an ef.\u00adcient scheme to implement our algorithm by applying these updates lazily. \nThe following theorem expresses the fact that our algorithm is eso both sound and precise. Given an \nexecution S=(s, -. ),we write that (t, n) accesses the data variable (o, d) in S if either T1 T2 T3 \ntmp1 = new IntBox() tmp1.data = 0 acq(ma) a= tmp1 rel(ma)  LS(o.data) = \u00d8 First access LS(o.data) = \n{T1} (T1 . LS) (add ma to LS) LS(o.data) = {T1, ma} (ma . LS) (add T2 to LS) LS(o.data) = {T1, ma, \nT2} (T2 . LS) (add ma to LS) LS(o.data) = {T1, ma, T2} acq(mb) tmp3.data = 3 (T2 . LS) (add mb \nto LS) LS(o.data) = {T1, ma, T2, mb} (mb . LS) (add T3 to LS) LS(o.data) = {T1, ma, T2, mb, T3} (T3 \n. LS) (No race) LS(o.data) = {T3} (T3 . LS) (add mb to LS) LS(o.data) = {T3, mb} (T3 . LS) (No race) \nLS(o.data) = {T3} Figure 6. Evolution of LS(o.data)on Example 2 (Section 2). s(t, n).{ read (o, d), \nwrite(o, d)} or s(t, n)=commit(R, W ) and (o, d). R . W . eso THEOREM 1 (Correctness). Let S=(s, -. )be \nan execution, p a linearization of S, and (o, d)a data variable. Let LSb be the value of the lockset \nmap LS as computed by the generalized Goldilocks algorithm just before processing the b-th element of \np. Suppose a, b .N are such that a<b, p(a)and p(b)access (o, d) in S, and p(j)does not access (o, d)in \nSfor all j . [a +1,b - 1]. Suppose pa =(t, m)and pb =(u, n). Then the following statements are true: \nehb 1. u . LSb(o, d)iff p(a)-. p(b). 2. TL . LSb(o, d)iff s(t, m)=commit(R, W )and (o, d). R . W . \n The proof of this theorem is an extension of the proof of correctness of the original Goldilocks algorithm \n[9]. The extension to deal with transactions is mostly straightforward. Using the lockset update rules \nabove, Goldilocks is able to uniformly handle various approaches to synchronization such as dynamically \nchanging locksets, permanent or temporary thread\u00adlocality of objects, container-protected objects, ownership \ntransfer of variable without accessing the variable (as in the example in Sec\u00adtion 4.1). Furthermore, \nGoldilocks can also handle wait/notify(All), and the synchronization idioms the java.util.concurrent \npackage such as semaphores and barriers, since these primitives are built using locks and volatile variables. \n 4.1 Precise data-race detection In this section, we use an execution (Figure 6) of the program in Example \n2 from Section 2 to demonstrate the precision of the Goldilocks algorithm compared to other lockset-based \nalgorithms from the literature. Unlike Goldilocks which is both sound and precise, other lockset algorithms \nbased on the Eraser algorithm [20] are sound but not precise. The most straightforward lockset algorithm \nis based on the as\u00adsumption that each shared variable is protected by a .xed set of locks throughout \nthe execution. Let LH (t)represent the set of locks held by thread t at a given point in an execution. \nThis algo\u00adrithm attempts to infer this set by updating the lockset LS(o, d)of a data variable (o, d)to \nbe the intersection LH (t)n LS(o, d)at each access to (o, d)by a thread t. If this intersection becomes \nempty, a race is reported. This approach is too conservative since it reports a false race in many situations, \nsuch as during unprotected variable initialization and when the lock protecting a variable changes over \ntime. For instance, this basic algorithm will report a data-race on o.data at the very .rst access of \nthe execution in Figure 6. Variants of lockset algorithms in the literature use additional mechanisms \nsuch as a state machine per shared variable in order to handle special cases such as thread locality \nand object initialization. However, these variants are neither sound nor precise, and they all report \nfalse alarms in scenarios similar to the one in the example above. For instance, in spite of using the \nstate-machine accompa\u00adnying the Eraser algorithm [20], a data-race will be reported at the last access \n(tmp3.data = 3)to o.data in the execution. The fundamental limitation of existing lockset algorithms \nis that the lockset of a variable only becomes smaller with time. On the other hand, our algorithm s \nlockset update rules allow a variable s locksets to grow during the execution; in fact, the lockset of \na variable may be modi.ed even without the variable being accessed. These aspects of our algorithm are \ncrucial for detecting changes of ownership during the execution. The evolution of the lockset of o.data \ndue to our update rules is illustrated in Figure 6. The vector-clock algorithm does not declare a false \nrace in this example and similar scenarios. However, it accomplishes this at signi.cantly increased computational \ncost compared to our opti\u00admized implementation of the lockset update rules. 4.2 Handling transactions \nIn this section, we use the program in Example 3 from Section 2 to demonstrate how Goldilocks handles \nsynchronization due to trans\u00adactions. Consider an execution of this program shown in Figure 7. This execution \nbegins in a state in which head =null and conse\u00adquently the linked list of Foo objects is empty. Let \no denote the ad\u00address of the object allocated by the .rst statement. The transaction of Thread 1 happens-before \nthe transaction of Thread 2 because both transactions access the variables head (address denoted by &#38;head)and \no.data. The transaction of Thread 2 happens-before the transaction of Thread 3 for exactly the same reason. \nConse\u00adquently, the accesses to o.data at t1.data = 42 by Thread 1, at iter.data = 0 by Thread 2,and at \nt3.data++ by Thread 3 are ordered by the happens-before relation. Goldilocks is able to detect these \nhappens-before edges and verify that there is no data\u00adrace between the three accesses. Figure 7 shows \nthe evolution of the lockset for o.data. The .gure treats the end of a transaction as its commit point \nand shows the application of rule 9 from Figure 5 there. t1 = new Foo() LS(o.data) = \u00d8 t1.data = 42 \nFirst access LS(o.data) = {T1} begin_tr T1 t1.nxt = head head = t1 end_tr (T1 .LS) (add {o.nxt, &#38;head} \nto LS) LS(o.data) = {T1, o.nxt, &#38;head} begin_tr iter = head iter != null T2 iter.data = 0 iter \n= iter.nxt ({&#38;head,o.data,o.nxt} nLS .\u00d8) (add T2 to LS) LS(o.data) = {T1, o.nxt, &#38;head, T2} \niter == null ({TL,T2} nLS .\u00d8) (No race) LS(o.data) = {TL, T2} end_tr (T2 .LS) (add {&#38;head,o.data,o.nxt} \nto LS) LS(o.data) = {TL, T2, &#38;head, o.data, o.nxt} begin_tr t3 = head T3 head = t3.nxt ({&#38;head, \no.nxt} nLS .\u00d8) (add T3 to LS) LS(o.data) = {TL, T2, &#38;head, o.data, o.nxt,T3} end_tr (T3 .LS) (add \n{&#38;head, o.nxt} to LS) LS(o.data) = {TL, T2, &#38;head, o.data, o.nxt,T3} t3.data++ (T3 .LS) (No \nrace) LS(o.data) = {T3} Figure 7. Evolution of LS(o.data) on Example 3 (Section 2).  5. Implementation \nWe implemented the generalized Goldilocks algorithm in Kaffe [24], a clean room implementation of the \nJava virtual machine in C. Our implementation is integrated into the interpreting mode of Kaffe s runtime \nengine2. The pseudocode for the Goldilocks implementa\u00adtion is given in Figure 8. We defer the explanation \nof how transac\u00adtions are handled in the implementation to Section 5.3 to make the initial presentation \nsimpler. We store synchronization events in a linked list called the syn\u00adchronization event list and \nrepresented by its head and tail pointers in Figure 8. Events are stored in this list in the synchronization \nor\u00adder as de.ned in the Java Memory Model. Synchronization events are represented by the Cell data structure, \nwhich stores the synchro\u00adnization action kind and the thread performing the action. When a thread performs \na synchronization action, it atomically appends (see Enqueue-Synch-Event) the corresponding cell to the \nsynchro\u00adnization event list. The race-freedom check presented in this paper is implemented in a decentralized \nfashion. For each action a that a thread performs, it calls Handle-Action(t, a). For each shared data \nvariable (o, d),to serialize the lockset update and race-freedom checks for each ac\u00adcess to (o, d), our \nimplementation uses a unique lock KL(o, d). Before a thread accesses (o, d), it acquires KL(o, d) and \nperforms the lockset update (computes the lockset associated with the ac\u00adcess) and race-freedom check \nexplained in Theorem 1. In this way, each thread carries out the race-freedom check for the accesses \nit performs, and these checks are linearly ordered by KL(o, d).The implementation of the variable access \nin Kaffe is not protected by KL(o, d). The lockset update rules in our race-detection algorithm may require \nLS(o, d) to be updated for each synchronization event. This potentially expensive operation and the memory \ncost of explicitly representing the individual locksets is avoided by performing lazy evaluation of locksets \nas described below. The record Info corresponds to an access to a data variable (o,d) during the execution. \nThe owner .eld of Info is the id of the thread performed the access. pos is a pointer into the synchronization \nevent list, to the cell representing the last synchronization event 2 An implementation of our algorithm \nin the just-in-time compilation mode is straightforward but requires a lot more code. record Cell {thread: \nTid; record Info {pos: ref (Cell); action: Action; owner: Tid; next: ref (Cell);} alock: Addr; ls: P(Addr \n\u00d7 Volatile . Data) . Tid .{TL}xact: Boolean; } head, tail: ref (Cell); ReadInfo: (Addr \u00d7 Data \u00d7 Tid) \n-. Info; WriteInfo: (Addr \u00d7 Data) -. Info; Initially head := new Cell; tail := head; ReadInfo := EmptyMap; \nWriteInfo := EmptyMap; Enqueue-Synch-Event (t, a): 1 tail.thread := t; 2 tail.action := a; 3 tail.next \n:= newCell(); 4 tail := tail.next; Check-Happens-Before (info1, info2): 1 if (info1.xact . info2.xact) \n2 return; // no race for transactional variables 3 if ((info2.owner =.info1.owner) 4 . (info1.alock is \nnot held by info2.owner)) { 5 Apply-Lockset-Rules (info1.ls, info1.pos, info2.pos, info2.owner); 6 info2.alock \n:= (choose randomly a lock held by info1.owner); 7 } Handle-Action (t, a): 1 if (a .{acq(o), rel(o), \nfork(u), join(u), read(o, v) write(o, v) .nalize(x), terminate(t)}) {2 Enqueue-Synch-Event (t, a); 3 \n} else if (a = read(o, d)) { 4 info := newInfo (); 5 info.owner := t; 6 info.pos := tail; 7 info.xact \n:= Is-In-Transaction (t); 8 info.ls := {t}; 9 ReadInfo(o, d, t):= info 10 Check-Happens-Before (WriteInfo(o, \nd), info); 11} else if (a = write(o, d)) { 12 info := newInfo (); 13 info.owner := t; 14 info.pos := \ntail; 15 info.xact := Is-In-Transaction (t); 16 info.ls := {t}; 17 for each (t . Tid) 18 if (ReadInfo(o, \nd, t)=.null) 19 Check-Happens-Before (ReadInfo(o, d, t), info); 20 if (WriteInfo(o, d)=.null) 21 Check-Happens-Before \n(WriteInfo(o, d), info); 22 WriteInfo(o, d) := info 23 for each (t . Tid) ReadInfo(o, d, t) := null \n24} else if (a = commit(R, W )) { 25 Enqueue-Synch-Event (t, a); 26 for each a in (W . R) 27 Handle-Action \n(t, a ); // Check race freedom as regular access 28 } 29} Figure 8. Implementation of the Goldilocks \nalgorithm that the access comes after. The ls.eld contains the lockset of the variable just after the \naccess. The .elds alock and xact will be explained below while discussing the short-circuit checks and \nthe transactions. After an access a1 to a variable, a new Info instance, say info1, that represents the \ncurrent access is created. info1.pos is simply set to the current tail of the list (see lines 6,14 of \nHandle-Action). At this point, according to the variable access rule in Figure 5, the lockset of the \nvariable should contain only the id of the currently accessor thread. info1.ls is set after the access \nin order to re.ect this (see lines 8 and 16 of Handle-Action). We perform the lockset computation and \nrace-freedom check lazily, only when an access to a variable happens. At a subsequent access a2 to (o,d), \nrepresented by, say, info2,the lockset LS(o, d) of (o,d) after a2 is computed and implicitly represented \nby applying to the lockset of the last access, info1.ls, the lockset update rules for the events in the \nsynchronization list between info1.pos and the current tail of the synchronization list. A race is reported \nif the lockset after a2 does not contain the id of the current accessor thread. The Check-Happens-Before \nprocedure determines whether there is a happens before relationship between two accesses represented \nby two info data structures. Before applying the lockset update rules of Figure 5, Check-Happens-Before \n.rst applies three cheaper checks that are suf.cient conditions for race-freedom between the two accesses. \nThese short-circuit checks are described in the next section. Our experimental results indicate that \nthe short\u00adcircuit checks succeed most of the time, and the lockset update rules are only applied in the \ncase of more elaborate ownership transfer scenarios. If all the short-circuit checks fail to prove the \nhappens-before edge, the lockset of the variable is computed lazily in Apply-Lockset-Rules as described \nabove. To distinguish between read and write accesses, the implemen\u00adtation maintains the Info records \nfor the last write access to each shared data variable (o, d) (WriteInfo(o, d)) and the last read ac\u00adcess \nto (o, d) by thread t (ReadInfo(o, d, t)) if this access came after the last write access. These maps \nare updated after each ac\u00adcess to (o,d). Note that, for each data variable, there are poten\u00adtially as \nmany pointers into the synchronization event list from ReadInfo as the number of active threads, although, \nin practice, we rarely encounter this situation. In this case, instead of checking the happens-before \nedge between any two accesses to (o,d), our al\u00adgorithm checks 1) for each read access whether it happened \nbefore WriteInfo(o, d), and 2) for each write access whether it happened before ReadInfo(o, d, t) for \neach thread t. 5.1 Short circuit checks The .rst constant-time short-circuit check is effective when \ntwo consecutive accesses to a shared variable are performed by the same thread. In this case, the happens-before \nrelationship is guaranteed by program order. This is detected in constant time by checking whether the \nthread .eld of the info data structure is the same as the thread performing the current access (see line \n3 of Check-Happens-Before). The second constant-time short-circuit check requires checking whether a \nrandom element of LS(o, d) at the last access, kept in the alock .eld of Info, is also held by the current \nthread. If these two locks happen to be the same, then the current access is race free (see line 4 of \nCheck-Happens-Before). The last short-circuit involves the Apply-Lockset-Rules subrou\u00adtine and consists \nof considering only the subset of synchronization events executed by the current and last accessing thread \nwhen ex\u00adamining the portion of the synchronization event list between info1 and info2. This check is \nnot constant time, but we found that it saves on the runtime of Apply-Lockset-Rules when the happens\u00adbefore \nedge between info1 and info2 is immediate, i.e., is accom\u00adplished by a direct transfer of ownership from \none thread to another.  5.2 Sound static race analysis to reduce overhead As is apparent from the implementation \npseudocode, the runtime overhead of race detection is directly related to the number of data variable \naccesses checked and the synchronization events that oc\u00adcur. In the worst-case, this overhead is proportional \nto the product of the following two quantities: (i) the sum of the number of syn\u00adchronization events \nand shared variable accesses, (ii) the number of data variables in the execution. This overhead is amortized \nover the total number of accesses. In practice, we do not encounter this worst-case behavior and see \na constant-time overhead per access. To reduce the number of accesses checked at runtime, we use exist\u00ading \nstatic analysis methods at compile time to determine accesses or access pairs that are guaranteed to \nbe race-free. We worked with two static analysis tools for this purpose: a newer version of the Chord \ntool [17] and the RccJava static race detection tool [1]. The output of RccJava is a list of .elds that \nmay be involved in a race condition. The output of Chord is a list R of pairs of accesses (line numbers \nin the source code) that may be involved in a race, i.e., if any execution of the program ever produces \na race, the pair of accesses (a1,a2) is guaranteed to be in R. Our runtime makes use of R by parsing \nChord s output and inferring from it the sets of object .elds (F) and methods (M)that are guaranteed \nto never be involved in a race. It then annotates the Java class .les using the reserved bits of the \naccess .ags of classes, .elds and methods to enable/disable race checking on the particular class, .eld \nor method. 5.3 Transactions To detect races at runtime, our approach requires a transaction man\u00adager \nto provide or make possible for the runtime to collect for each transaction commit(R, W ) the sets R \nand W and the place of commit point of the transaction in the global synchronization or\u00adder. Note that \ntransaction implementations need to ensure such an order to implement the required semantics correctly, \nthus to provide the latter information, transaction implementations do not need to perform any additional \nsynchronization. For the transaction im\u00adplementations in LibSTM [12] and LibCMT [13], this information \nis readily available to the runtime, and can be collected easily in SXM [14] at runtime. In our implementation \n(Figure 8), when a transaction commit action is encountered, we .rst insert the commit action a (that \ncon\u00adtains the list of read and write accesses R and W ) as a synchro\u00adnization action into the synchronization \nevent list. Then, all shared variable reads and writes within the transaction (i.e., in R and W ) are \nchecked for race-freedom (lines 24-28 of Handle-Action)in the same way as accesses outside transactions. \nNote that the collec\u00adtion of R and W is done in a distributed fashion by each transac\u00adtion and does not \nintroduce extra synchronization between transac\u00adtions. We use the xact .eld of Info in order to indicate \nwhether an access happened inside a transaction or not (see lines 7,15 of Handle-Action). xact is used \nin another short-circuit check (line 1of Check-Happens-Before); as long as the accesses to (o,d) are \ninside transactions, the lockset computation is skipped. This way of handling the happens-before relationships \ninduced by transactions avoids processing the synchronization operations performed by a transactions \nmanager that has already been proven correct. It infers exactly the desired set of happens-before edges, \nand accomplishes this at less of a computational cost than treat\u00ading transactions implementations as \npart of the application pro\u00adgram. This approach can be viewed as a modular way of check\u00ading race-freedom \nand thus sequential consistency. The implementor of software transactions guarantees the happens-before \nedges be\u00adtween transactions as described in Section 3 and race-freedom for accesses within transactions. \nOur Java runtime performs the race\u00adfreedom check for the rest of the accesses using the happens-before \nedges provided by the transactions implementation. 5.4 Garbage collection of synchronization events \nand partially-eager evaluation The synchronization events list is periodically garbage collected when \nthere are entries in the beginning of the list that are not Uninstrumented Runtime Without static information \nWith Chord outputs With RccJava outputs Short-circuit checks (%) Benchmarks #Lines # Threads Just-in-time \nInterpreted Runtime Slowdown Runtime Slowdown Runtime Slowdown Chord RccJava colt - 10 6.3 6.8 13.2 1.9 \n7.8 1.2 - - 66.67 - hedc 2.5K 10 3.1 7.5 14.5 1.9 11.0 1.5 - - 31.94 - lufact 1K 10 0.2 0.5 2.0 4.1 0.9 \n1.8 - - 12.73 - moldyn 650 5 21.6 135.2 730.2 5.4 712.9 5.3 217.8 1.6 99.53 99.99 montecarlo 3K 5 43.8 \n44.1 97.2 2.2 47.0 1.1 44.8 1.0 99.93 99.98 philo 86 8 2.9 2.6 2.7 1.0 2.7 1.0 - - 6.62 - raytracer 1.2K \n5 0.4 3.4 61.7 17.9 39.0 11.4 7.4 2.1 51.01 51.01 series 380 10 87.9 88.4 94.1 1.0 93.3 1.0 - - 10.17 \n- sor 220 5 31.5 32.8 44.1 1.3 31.5 1.0 - - 16.97 - sor2 252 10 0.6 11.2 70.8 6.3 25.8 2.3 12.4 1.1 0.00 \n99.00 tsp 700 10 1.6 2.5 5.5 2.2 3.4 1.3 3.1 1.2 64.54 37.28 Table 1. Results of experiments with the \nrace-aware Kaffe runtime relevant for the lockset computation of any variable. This is the case when \nan entry in the list is not reachable from the lockset pointer (pos)for any info data structure. We keep \ntrack of this information by maintaining a reference count in every cell data structure. We periodically \ndiscard pre.x of the list up to the .rst cell with non\u00adzero reference count. While running Goldilocks \non long executions, sometimes the synchronization event list gets too long. It is not possible to garbage-collect \nstarting from the head of the list when a variable is accessed early in an execution but is not used \nafterwards. In this case, a long pre.x of the list is reachable from the info data struc\u00adture representing \nthis early access, which prevents garbage collec\u00adtion of the entire rest of the list. This phenomenon \nis a side effect of the initial Goldilocks implementation performing completely lazy evaluation. Below, \nwe describe a technique, partially-eager lockset evaluation, that we used to address this problem. For \nsim\u00adplicity, partially-eager evaluation is explained only for write lock\u00adsets. The procedure is the same \nfor each read lockset of each thread for each shared data variable. Suppose that the initial cell 0 has \na non-zero reference count, followed by a long sequence of entries with zero reference counts. Let InfoSet \n. WriteInfo be the set of Info records whose pos .elds refer to cell0.Let cell1 be a later cell in the \nsynchronization event list. For each variable (o, d) such that WriteInfo(o, d) . InfoSet, no later write \naccess to (o, d) has occurred (otherwise the WriteInfo data structure would point to a later list entry). \nThus, for each such (o, d), we 1) perform the lockset computation up to cell1, and store this intermediate \nresult in WriteInfo(o, d).ls, and 2) reset WriteInfo(o, d).pos to point to cell1.Ifthere is a later write \naccess to (o, d), the lockset computation starts with this intermediate lockset (instead of {WriteInfo(o, \nd).owner})and at cell1. We perform this partial computation of locksets for all info data structures \nthat refer to cell0. After the reference count of cell 0 reaches 0, we garbage-collect the pre.x of the \nlist up to cell 1.We repeat this pre.x-trimming operation starting with the new head of the list until \nthe list size is down to a pre-speci.ed number. This partially-eager lockset evaluation scheme provides \na running time-memory trade off and is necessary for continuously-running programs which may have very \nlong synchronization event lists otherwise. Currently we trigger the partially-eager lockset computation \nscheme to trim the .rst 10% of the entries in the synchronization event list when garbage collection \nis triggered in the Kaffe JVM. We explicitly trigger a garbage collection when the event list grows longer \nthan one million entries.  6. Experiments We ran on our race-and transaction-aware JVM a set of bench\u00admarks \nwell known in the literature. A Linux machine with Intel Pentium-4 2.80GHz CPU was used. The initial \nand the maximum Java heap space were set to 16 MB and 512 MB, respectively. These limits triggered a \nmoderate number of garbage collection runs which were necessary for proper trimming of the synchroniza\u00adtion \nevent list by partially-eager lockset propagation. The experi\u00adments were run on the interpreter mode \nof the Kaffe Virtual Ma\u00adchine version 1.1.6. We collected the runtime statistics using the PAPI interface \nto the hardware performance counters [2]. Arrays were checked by treating each array element as a separate \nvariable. To provide a reasonable idea of race checking overhead in our experiments, when a race was \ndetected on a variable, race checking for that variable was turned off during the rest of the execution. \nChecks for all the indices of an array were disabled when a race is detected on any index of the array. \nThe Java benchmarks we worked on do not have handlers for DataRaceExceptions. It is common in these benchmarks \nfor many more races to occur on a variable once one race has occurred. Turning off race checking after \nthe .rst detected race provides a more reasonable idea of overhead in these cases because, in normal \noperation, we do not expect a program to continuously detect and recover from races on the same variable. \nWe used eleven benchmark programs to evaluate the perfor\u00admance of our implementation in Kaffe. Six of \nour benchmarks are from the Java Grande Forum Benchmark Suite. We reduced the size of inputs to the Grande \nbenchmarks because of the long run\u00adning time of the applications. The remaining four benchmarks are from \n[23]. We were able to apply the Chord static race analysis tool to all of the benchmarks and used the \nresulting race-prone access pairs as described in Section 5. We only had access to RccJava output for \nthe following benchmarks: moldyn, montecarlo, raytracer, sor2,and tsp. In most of these cases, the checks \nthat RccJava was able to eliminate subsumed those that Chord was able to. Table 1 presents the performance \nstatistics of the Goldilocks al\u00adgorithm in different settings of the benchmark programs. The col\u00adumn \ntitled Uninstrumented reports the total runtime of the pro\u00adgrams in the JIT-compilation and the interpreter \nmodes of JVM with the race detection feature disabled. The other columns present the running times and \nthe slowdown ratios of the programs on JVM with race checking enabled. The runtime measurements are given \nin seconds. The slowdown ratio is the ratio of the runtime with the race checking enabled to the uninstrumented \nruntime of the pro\u00adgram (both in interpreted mode). For the results in the columns titled with Chord \noutputs , with RccJava outputs , and short\u00adcircuit checks , the standard libraries were instrumented \nas well. For the results in the columns titled without static information the libraries were not instrumented. \nFor these experiments, instru\u00admenting libraries at most doubles overhead. Table 1 also reports the percentages \nof succeeding short-circuit checks when the outputs of Chord or RccJava are used. The rest of the accesses \nrequire full lockset computations by traversal of the Variables checked (%) Accessed checked (%) Benchmarks \nChord RccJava Chord RccJava colt 0.1 - 0.0 - hedc 0.0 - 0.0 - lufact 1.1 - 2.1 - moldyn 84.1 83.5 56.6 \n49.1 montecarlo 15.4 13.7 13.0 39.9 philo 0.2 - 0.1 - raytracer 80.5 35.3 5.2 1.3 series 0.3 - 2.0 - \nsor 0.3 - 0.9 - sor2 1.3 0.0 36.9 0.0 tsp 60.1 80.0 42.0 23.7 Table 2. Statistics on experiments with \nstatic analyses synchronization event list. These results clearly indicate that for some programs, most \nof the happens-before edges can be captured by using cheaper short-circuit checks, which signi.cantly \nreduces overhead. The high percentage of lockset computations for sor2 explains the high overhead incurred \nfor this benchmark. In lufact, philo, series and sor the percentage of successful short-circuit checks \nis high, which led to low runtime overhead. The short\u00adcircuit checks do not help to reduce the overhead \nwith Chord out\u00adputs for moldyn and raytracer. This is because moldyn and raytracer use barrier synchronization \nwhich is not captured by Chord, and thus, each volatile variable read and write used to imple\u00adment barriers \nis processed separately in the lockset computations. The overhead for these examples is much lower when \nRccJava out\u00adputs are used, because RccJava eliminates checks for most of the variables whose accesses \nare synchronized using barriers. Note that Eraser-based algorithms do not handle barrier synchronization \nand would have declared false alarms for moldyn and raytracer. Table 2 reports the percentage values \nfor the variables checked among all the variables created, and the variable accesses checked among all \nthe accesses that take place during the execution. Us\u00ading the output of Chord reduces the slowdown to \na small value be\u00adtween 1 and 2 for most of the benchmarks. Using RccJava outputs decreases the slowdown \nfor moldyn and raytracer to similar lev\u00adels, whereas overhead remained high with the outputs of Chord \nfor these examples. These experiments demonstrate that, with proper prior static analysis, the overhead \nof precise race checking at run\u00adtime can be reduced signi.cantly. These results also indicate that, to \nbe practical, precise race detection at runtime must be preceded by sound static techniques for determining \nrace-free variables. 6.1 Experiments with transactions To measure the performance of our implementation \nof a transaction\u00adaware race checker, we mimicked the transactions implementa\u00adtion by source-to-source \ntranslation of Grossman et. al. [15] for a concurrently-accessed data structure. We did this as we did \nnot have access to the source code for a Java implementation of soft\u00adware transactions. The implementation \nof transactions in [15] uses Java s object locks for synchronization. All shared variable reads and writes \nin an atomic transaction are protected by the object locks for the objects accessed. All shared variable \nreads and writes that are part of a transaction take place between the .rst lock acquire and the .rst \nlock release associated with the transaction. The .rst lock release also constitutes the commit point \nof the transaction. The data structure we worked on is a Multiset, based on the benchmark with the same \nname in [10]. The test program for Multiset consists of a number of threads accessing a multiset of integers \nconcurrently by performing insertions, deletions and queries. The representation for a multiset is an \narray elements of objects where each object potentially stores an element of the mul\u00adTable 3. Performance \nof checking races for transactional Multiset #ThreadsUninstrumented Goldilocks with transactions #Accesses#Transactions \nRuntime Runtime Slowdown x1000 x1000 5 0.35 0.51 1.46 215 21 10 0.66 0.80 1.21 381 45 20 1.11 1.60 1.44 \n660 87 50 2.89 3.55 1.23 1460 206 100 5.57 8.19 1.47 2819 407 200 12.15 15.30 1.26 5493 802 500 31.78 \n40.84 1.29 13648 2006  tiset. The Insert(int[] a) operation attempts to .rst allocate space for the \na.length entries in elements using a transaction for each allocation. If this allocation is successful \nfor all a.length entries, then all of the new multiset elements are made visible to other threads in \nan atomic transaction. If the allocation is unsuc\u00adcessful because of space contention with concurrent \nthreads, the space allocated in elements is freed in a single atomic transac\u00adtion. This mimics transaction \nrollback. To mimic the use of transac\u00adtions mixed with other synchronization primitives, the arrays used \nas arguments to Insert were generated by a factory object shared among threads. This object and the array \nobjects were manipulated outside transactions. To imitate what our JVM expects of a transactions implemen\u00adtation, \nshared variable reads and writes between the .rst lock ac\u00adquire and the .rst lock release in each transaction \nwere recorded by instrumentation code in the JVM to form the sets R and W associated with a commit(R, \nW ) action. This commit action was inserted in the synchronization event list where the .rst lock release \nin a transaction would have been inserted if we were not explicitly considering transactions. We measured, \nfor different numbers of threads sharing a multi\u00adset of size 10, the runtime with race checking enabled \nfor the trans\u00adactions as described in Sections 4 and 5 (Table 3). The table also reports the number of \nshared variable accesses and the number of transactions in the executions. The results indicate that \nthe runtime overhead of our approach (which includes the overhead of keep\u00ading track of the read and write \nsets of transactions) when explic\u00aditly handling transactions is moderate. When we analyze Multiset executions \nwithout taking transactions into account we incur slow\u00addown factors of more than ten3. This indicates \nthat treatingsoftware transactions as high-level synchronization primitives may reduce the runtime overhead \nof race checking.  7. Related work There are two approaches to dynamic data-race detection, one based \non locksets and the other based on the happens-before re\u00adlation. Eraser [20] is a well-known lockset-based \nalgorithm for de\u00adtecting race conditions dynamically by enforcing the locking dis\u00adcipline that every \nshared variable is protected by a unique lock. In spite of the numerous papers that re.ned the Eraser \nalgorithm to reduce the number of false alarms, there are still cases, such as dy\u00adnamically changing \nlocksets, that cannot be handled precisely. Pre\u00adcise lockset algorithms exist for Cilk programs [3] but \nthey cannot handle concurrency patterns implemented using volatile variables such as barrier synchronization. \nThe other approach to dynamic data-race detection is based on computing the happens-before relation [7, \n19, 21] using vec\u00adtor clocks [16]. Hybrid techniques [18, 25] combine lockset and happens-before analysis. \nFor example, RaceTrack [25] uses a basic 3 This overhead is not representative as Multiset executions \nconsist entirely of shared variable accesses each involving a separate lock acquire and release. vector-clock \nalgorithm to capture thread-local accesses to objects thereby eliminating unnecessary and imprecise applications \nof the Eraser algorithm. Our technique, for the .rst time, computes a pre\u00adcise happens-before relation \nusing an implementation that makes use of only locksets. There is also prior work that used the result \nof static analysis to eliminate unnecessary runtime checks. Choi et al. [6] present an unsound runtime \nalgorithm for data-race detection. They used a static race reporting algorithm [5] to eliminate unnecessary \nchecks for well-protected variables. The work on software transactional memory (STM) is orthog\u00adonal to \nour work; our algorithm can be integrated with all the im\u00adplementations we are aware of. Our de.nition \nof data-races in the presence of transactions was in.uenced in part by a study of the interaction between \nthe synchronization induced by software trans\u00adactions and weaker memory models [11].  8. Conclusion \nWe present the .rst formulation of data-races in the presence of software transactions and a race-and \ntransaction-aware runtime for Java. We have designed and implemented a precise and ef.cient algorithm \nfor detecting data races in dynamic executions. Our al\u00adgorithm uniformly supports a variety of synchronization \nmecha\u00adnisms including software transactions. Through a combination of static analysis and an ef.cient \nimplementation of our data-race de\u00adtection algorithm, we have demonstrated that the runtime overhead \nof precise data-race detection required for supporting a DataRace-Exception can be made reasonable. With \nimprovement of static analysis techniques and further optimizations in the implementa\u00adtion, we believe \nthat the runtime overhead can be reduced enough to be acceptable for continuous monitoring of program \nexecutions during debugging and during deployment for critical programs.  References [1] Martin Abadi, \nCormac Flanagan, and Stephen N. Freund. Types for Safe Locking: Static Race Detection for Java. ACM Transactions \non Programming Languages and Systems, 28(2):207 255, 2006. [2] S. Browne, J. Dongarra, N. Garner, G. \nHo, and P. Mucci. A Portable Programming Interface for Performance Evaluation on Modern Processors. The \nIntl. Journal of High Performance Computing Applications, 14(3):189 204, Fall 2000. [3] Guang-Ien Cheng, \nMingdong Feng, Charles E. Leiserson, Keith H. Randall, and Andrew F. Stark. Detecting Data Races in Cilk \nPrograms That Use Locks. In SPAA 98: Annual ACM Symposium on Parallel Algorithms and Architectures. pages \n298309, Puerto Vallarta, Mexico, June 28-July 2, 1998. [4] James R. Larus and Ravi Rajwar. Transactional \nMemory. Synthesis Lectures on Computer Architecture. 1(1):1 226. 2006. [5] Jong-Deok Choi, Alexey Loginov, \nand Vivek Sarkar. Static Datarace Analysis for Multithreaded Object-oriented Programs. Technical Report, \nRC22146. IBM Research. 2001. [6] Jong-Deok Choi, Keunwoo Lee, Alexey Loginov, Robert O Callahan, Vivek \nSarkar, and Manu Sridharan. Ef.cient and Precise Datarace Detection for Multithreaded Object-oriented \nPrograms. In PLDI 02: Proc. ACM SIGPLAN 2002 Conf. on Programming Language Design and Implementation, \npp. 258 269, New York, NY, USA, ACM 2002. [7] Mark Christiaens and Koenraad De Bosschere. TRaDe: Data \nrace detection for Java. In Proc. of the Intl. Conference on Computational Science -ICCS2001, number \n2074, pp. 761 770, San Francisco, May 2001. Springer Verlag. [8] Tayfun Elmas, Shaz Qadeer, and Serdar \nTasiran. Goldilocks: Ef.ciently Computing the Happens-before Relation Using Locksets. In Proc. of the \nWorkshop on Formal Approaches to Testing and Runtime Veri.cation (FATES/RV 2006). 2006. [9] Tayfun Elmas, \nShaz Qadeer, and Serdar Tasiran. Goldilocks: Ef.ciently Computing the Happens-before Relation Using Locksets. \nTechnical Report MSR-TR-2006-163, Microsoft Research, 2006. [10] Tayfun Elmas, Serdar Tasiran, and Shaz \nQadeer. Vyrd: Verifying Concurrent Programs by Runtime Re.nement-Violation Detection. In PLDI 05: Proc. \nof the 2005 ACM SIGPLAN Conference on Programming Language Design and Implementation, pp. 27 37, New \nYork, NY, USA, ACM 2005. [11] Dan Grossman, Jeremy Manson, and William Pugh. What Do High\u00adlevel Memory \nModels Mean for Transactions? In MSPC 06: Proc. of the 2006 Workshop on Memory System Performance and \nCorrectness, pp. 62 69, New York, NY, USA, 2006. ACM Press. [12] Tim Harris and Keir Fraser. Language \nSupport for Lightweight Transactions. In OOPSLA 03: Proc. of the 18th annual ACM SIGPLAN Conference on \nObject-oriented Programing, Systems, Languages, and Applications, pp. 388 402, New York, NY, USA, ACM \n2003. [13] Tim Harris, Simon Marlow, Simon Peyton-Jones, and Maurice Herlihy. Composable Memory Transactions. \nIn PPoPP 05: Proc. of the 10th ACM SIGPLAN symposium on Principles and practice of parallel programming, \npp. 48 60, New York, NY, USA, ACM 2005. [14] Maurice Herlihy. SXM1.1: Software Transactional Memory Package \nfor C#. Technical Report, Brown University &#38; Microsoft Research, May, 2005. [15] Benjamin Hindman \nand Dan Grossman. Atomicity via Source-to\u00adsource Translation. In MSPC 06: Proc. of the 2006 Workshop \non Memory System Performance and Correctness, pp. 82 91, New York, NY, USA, 2006. ACM Press. [16] Friedemann \nMattern. Virtual Time and Global States of Distributed Systems. In Parallel and Distributed Algorithms: \nProceedings of the Intl. Workshop on Parallel and Distributed Algorithms. 1988. [17] Mayur Naik, Alex \nAiken, and John Whaley. Effective Static Race Detection for Java. In PLDI 06: Proc. of the 2006 ACM SIGPLAN \nConference on Programming Language Design and Implementation, pp. 308 319, New York, NY, USA, ACM 2006. \n[18] Eli Pozniansky and Assaf Schuster. Ef.cient On-the-.y Data Race Detection in Multithreaded C++ Programs. \nIn PPoPP 03: Proc. of the 9th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, \npp. 179 190, New York, NY, USA, ACM 2003. [19] Michiel Ronsse and Koen De Bosschere. RecPlay: A Fully \nIntegrated Practical Record/Replay System. ACM Transactions on Computer Systems, 17(2):133 152, 1999. \n[20] Stefan Savage, Michael Burrows, Greg Nelson, Patrick Sobalvarro, and Thomas Anderson. Eraser: A \nDynamic Data Race Detector for Multithreaded Programs. ACM Transactions on Computer Systems, 15(4):391 \n411, 1997. [21] Edmond Schonberg. On-the-.y Detection of Access Anomalies. In Proc. of the ACM SIGPLAN \n89 Conference on Programming Language Design and Implementation, volume 24, pp. 285 297, Portland, OR, \nJune 1989. [22] Nir Shavit and Dan Touitou. Software Transactional Memory. In Proc. of the 14th Annual \nACM Symposium on Principles of Distributed Computing, pp. 204 213, ACM 1995. [23] Christoph von Praun \nand Thomas R. Gross. Object race detection. In OOPSLA 01: Proc. of the 16th ACM SIGPLAN Conference on \nObject\u00adoriented Programming, Systems, Languages, and Applications, pp. 70 82, New York, NY, USA, ACM \n2001. [24] Tim Wilkinson. Kaffe: A JIT and Interpreting Virtual Machine to Run Java Code. http://www.transvirtual.com/, \n1998. [25] Yuan Yu, Tom Rodeheffer, and Wei Chen. Racetrack: Ef.cient Detection of Data Race Conditions \nvia Adaptive Tracking. In SOSP 05: Proc. of the 20th ACM symposium on Operating systems principles, pp. \n221 234, New York, NY, USA, ACM 2005. \n\t\t\t", "proc_id": "1250734", "abstract": "<p>Data races often result in unexpected and erroneous behavior. In addition to causing data corruption and leading programs to crash, the presence of data races complicates the semantics of an execution which might no longer be sequentially consistent. Motivated by these observations, we have designed and implemented a Java runtime system that monitors program executions and throws a DataRaceException when a data race is about to occur. Analogous to other runtime exceptions, the DataRaceException provides two key benefits. First, accesses causing race conditions are interruptedand handled before they cause errors that may be difficult to diagnose later. Second, if no DataRaceException is thrown in an execution, it is guaranteed to be sequentially consistent. This strong guarantee helps to rule out many concurrency-related possibilities as the cause of erroneous behavior. When a DataRaceException is caught, the operation, thread, or program causing it can be terminated gracefully. Alternatively, the DataRaceException can serve as a conflict-detection mechanism inoptimistic uses of concurrency.</p> <p>We start with the definition of data-race-free executions in the Java memory model. We generalize this definition to executions that use transactions in addition to locks and volatile variables for synchronization. We present a precise and efficient algorithm for dynamically verifying that an execution is free of data races. This algorithm generalizes the Goldilocks algorithm for data-race detectionby handling transactions and providing the ability to distinguish between read and write accesses. We have implemented our algorithm and the DataRaceException in the Kaffe Java Virtual Machine. We have evaluated our system on a variety of publicly available Java benchmarks and a few microbenchmarks that combine lock-based and transaction-based synchronization. Our experiments indicate that our implementation has reasonable overhead. Therefore, we believe that inaddition to being a debugging tool, the DataRaceException may be a viable mechanism to enforce the safety of executions of multithreaded Java programs.</p>", "authors": [{"name": "Tayfun Elmas", "author_profile_id": "81100211898", "affiliation": "Koc University, Istanbul, Turkey", "person_id": "P728840", "email_address": "", "orcid_id": ""}, {"name": "Shaz Qadeer", "author_profile_id": "81100286660", "affiliation": "Microsoft Research, Redmond, WA", "person_id": "PP14106781", "email_address": "", "orcid_id": ""}, {"name": "Serdar Tasiran", "author_profile_id": "81100391292", "affiliation": "Koc University, Istanbul, Turkey", "person_id": "P261829", "email_address": "", "orcid_id": ""}], "doi_number": "10.1145/1250734.1250762", "year": "2007", "article_id": "1250762", "conference": "PLDI", "title": "Goldilocks: a race and transaction-aware java runtime", "url": "http://dl.acm.org/citation.cfm?id=1250762"}